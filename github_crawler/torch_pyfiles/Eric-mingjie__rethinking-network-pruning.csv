file_path,api_count,code
cifar/l1-norm-pruning/compute_flops.py,9,"b""# Code from https://github.com/simochen/model-tools.\nimport numpy as np\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef print_model_param_nums(model=None, multiply_adds=True):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() for param in model.parameters()])\n    print('  + Number of params: %.2fM' % (total / 1e6))\n\ndef print_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2['names'] = np.prod(input[0].shape)\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n        flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    input = Variable(torch.rand(3, 3, input_res, input_res), requires_grad = True)\n    out = model(input)\n\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print('  + Number of FLOPs: %.5fG' % (total_flops / 3 / 1e9))\n    \n    return total_flops / 3\n"""
cifar/l1-norm-pruning/main.py,13,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\ndef train(epoch):\n    model.train()\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [args.epochs*0.5, args.epochs*0.75]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n    prec1 = test()\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n'"
cifar/l1-norm-pruning/main_B.py,14,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\nfrom compute_flops import print_model_param_flops\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.scratch:\n    checkpoint = torch.load(args.scratch)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n\nmodel_ref = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nflops_std = print_model_param_flops(model_ref, 32)\nflops_small = print_model_param_flops(model, 32)\nargs.epochs = int(160 * (flops_std / flops_small))\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\ndef train(epoch):\n    model.train()\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [int(args.epochs*0.5), int(args.epochs*0.75)]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n    prec1 = test()\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n'"
cifar/l1-norm-pruning/main_E.py,14,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.scratch:\n    checkpoint = torch.load(args.scratch)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\ndef train(epoch):\n    model.train()\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [args.epochs*0.5, args.epochs*0.75]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n    prec1 = test()\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n'"
cifar/l1-norm-pruning/main_finetune.py,14,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--refine\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=40, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.001, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.refine:\n    checkpoint = torch.load(args.refine)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n    model.load_state_dict(checkpoint[\'state_dict\'])\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\ndef train(epoch):\n    model.train()\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    train(epoch)\n    prec1 = test()\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n'"
cifar/l1-norm-pruning/res110prune.py,10,"b'import argparse\nimport numpy as np\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=110,\n                    help=\'depth of the resnet\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\nparser.add_argument(\'-v\', default=\'A\', type=str, \n                    help=\'version of the model\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = resnet(depth=args.depth, dataset=args.dataset)\n\nif args.cuda:\n    model.cuda()\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\n\nskip = {\n    \'A\': [36],\n    \'B\': [36, 38, 74],\n}\n\nprune_prob = {\n    \'A\': [0.5, 0.0, 0.0],\n    \'B\': [0.5, 0.4, 0.3],\n}\n\nlayer_id = 1\ncfg = []\ncfg_mask = []\nfor m in model.modules():\n    if isinstance(m, nn.Conv2d):\n        out_channels = m.weight.data.shape[0]\n        if layer_id in skip[args.v]:\n            cfg_mask.append(torch.ones(out_channels))\n            cfg.append(out_channels)\n            layer_id += 1\n            continue\n        if layer_id % 2 == 0:\n            stage = layer_id // 36\n            if layer_id <= 36:\n                stage = 0\n            elif layer_id <= 72:\n                stage = 1\n            elif layer_id <= 108:\n                stage = 2\n            prune_prob_stage = prune_prob[args.v][stage]\n            weight_copy = m.weight.data.abs().clone().cpu().numpy()\n            L1_norm = np.sum(weight_copy, axis=(1,2,3))\n            num_keep = int(out_channels * (1 - prune_prob_stage))\n            arg_max = np.argsort(L1_norm)\n            arg_max_rev = arg_max[::-1][:num_keep]\n            mask = torch.zeros(out_channels)\n            mask[arg_max_rev.tolist()] = 1\n            cfg_mask.append(mask)\n            cfg.append(num_keep)\n            layer_id += 1\n            continue\n        layer_id += 1\n\nnewmodel = resnet(dataset=args.dataset, depth=args.depth, cfg=cfg)\nif args.cuda:\n    newmodel.cuda()\n\nstart_mask = torch.ones(3)\nlayer_id_in_cfg = 0\nconv_count = 1\nfor [m0, m1] in zip(model.modules(), newmodel.modules()):\n    if isinstance(m0, nn.Conv2d):\n        if conv_count == 1:\n            m1.weight.data = m0.weight.data.clone()\n            conv_count += 1\n            continue\n        if conv_count % 2 == 0:\n            mask = cfg_mask[layer_id_in_cfg]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            w = m0.weight.data[idx.tolist(), :, :, :].clone()\n            m1.weight.data = w.clone()\n            layer_id_in_cfg += 1\n            conv_count += 1\n            continue\n        if conv_count % 2 == 1:\n            mask = cfg_mask[layer_id_in_cfg-1]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            w = m0.weight.data[:, idx.tolist(), :, :].clone()\n            m1.weight.data = w.clone()\n            conv_count += 1\n            continue\n    elif isinstance(m0, nn.BatchNorm2d):\n        if conv_count % 2 == 1:\n            mask = cfg_mask[layer_id_in_cfg-1]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            m1.weight.data = m0.weight.data[idx.tolist()].clone()\n            m1.bias.data = m0.bias.data[idx.tolist()].clone()\n            m1.running_mean = m0.running_mean[idx.tolist()].clone()\n            m1.running_var = m0.running_var[idx.tolist()].clone()\n            continue\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n        m1.running_mean = m0.running_mean.clone()\n        m1.running_var = m0.running_var.clone()\n    elif isinstance(m0, nn.Linear):\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n\ntorch.save({\'cfg\': cfg, \'state_dict\': newmodel.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\n\nprint(newmodel)\nmodel = newmodel\nacc = test(model)\n\nnum_parameters = sum([param.nelement() for param in newmodel.parameters()])\nprint(""number of parameters: ""+str(num_parameters))\nwith open(os.path.join(args.save, ""prune.txt""), ""w"") as fp:\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test Accuracy: \\n""+str(acc)+""\\n"")'"
cifar/l1-norm-pruning/res56prune.py,10,"b'import argparse\nimport numpy as np\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=56,\n                    help=\'depth of the resnet\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\nparser.add_argument(\'-v\', default=\'A\', type=str, \n                    help=\'version of the model\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = resnet(depth=args.depth, dataset=args.dataset)\n\nif args.cuda:\n    model.cuda()\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\n\nskip = {\n    \'A\': [16, 20, 38, 54],\n    \'B\': [16, 18, 20, 34, 38, 54],\n}\n\nprune_prob = {\n    \'A\': [0.1, 0.1, 0.1],\n    \'B\': [0.6, 0.3, 0.1],\n}\n\nlayer_id = 1\ncfg = []\ncfg_mask = []\nfor m in model.modules():\n    if isinstance(m, nn.Conv2d):\n        out_channels = m.weight.data.shape[0]\n        if layer_id in skip[args.v]:\n            cfg_mask.append(torch.ones(out_channels))\n            cfg.append(out_channels)\n            layer_id += 1\n            continue\n        if layer_id % 2 == 0:\n            if layer_id <= 18:\n                stage = 0\n            elif layer_id <= 36:\n                stage = 1\n            else:\n                stage = 2\n            prune_prob_stage = prune_prob[args.v][stage]\n            weight_copy = m.weight.data.abs().clone().cpu().numpy()\n            L1_norm = np.sum(weight_copy, axis=(1,2,3))\n            num_keep = int(out_channels * (1 - prune_prob_stage))\n            arg_max = np.argsort(L1_norm)\n            arg_max_rev = arg_max[::-1][:num_keep]\n            mask = torch.zeros(out_channels)\n            mask[arg_max_rev.tolist()] = 1\n            cfg_mask.append(mask)\n            cfg.append(num_keep)\n            layer_id += 1\n            continue\n        layer_id += 1\n\nnewmodel = resnet(dataset=args.dataset, depth=args.depth, cfg=cfg)\nif args.cuda:\n    newmodel.cuda()\n\nstart_mask = torch.ones(3)\nlayer_id_in_cfg = 0\nconv_count = 1\nfor [m0, m1] in zip(model.modules(), newmodel.modules()):\n    if isinstance(m0, nn.Conv2d):\n        if conv_count == 1:\n            m1.weight.data = m0.weight.data.clone()\n            conv_count += 1\n            continue\n        if conv_count % 2 == 0:\n            mask = cfg_mask[layer_id_in_cfg]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            w = m0.weight.data[idx.tolist(), :, :, :].clone()\n            m1.weight.data = w.clone()\n            layer_id_in_cfg += 1\n            conv_count += 1\n            continue\n        if conv_count % 2 == 1:\n            mask = cfg_mask[layer_id_in_cfg-1]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            w = m0.weight.data[:, idx.tolist(), :, :].clone()\n            m1.weight.data = w.clone()\n            conv_count += 1\n            continue\n    elif isinstance(m0, nn.BatchNorm2d):\n        if conv_count % 2 == 1:\n            mask = cfg_mask[layer_id_in_cfg-1]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            m1.weight.data = m0.weight.data[idx.tolist()].clone()\n            m1.bias.data = m0.bias.data[idx.tolist()].clone()\n            m1.running_mean = m0.running_mean[idx.tolist()].clone()\n            m1.running_var = m0.running_var[idx.tolist()].clone()\n            continue\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n        m1.running_mean = m0.running_mean.clone()\n        m1.running_var = m0.running_var.clone()\n    elif isinstance(m0, nn.Linear):\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n\ntorch.save({\'cfg\': cfg, \'state_dict\': newmodel.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\n\nnum_parameters = sum([param.nelement() for param in newmodel.parameters()])\nprint(newmodel)\nmodel = newmodel\nacc = test(model)\n\nprint(""number of parameters: ""+str(num_parameters))\nwith open(os.path.join(args.save, ""prune.txt""), ""w"") as fp:\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc)+""\\n"")'"
cifar/l1-norm-pruning/vggprune.py,10,"b'import argparse\nimport numpy as np\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=16,\n                    help=\'depth of the vgg\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = vgg(dataset=args.dataset, depth=args.depth)\nif args.cuda:\n    model.cuda()\n\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\ncfg = [32, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 256, 256, 256, \'M\', 256, 256, 256]\n\ncfg_mask = []\nlayer_id = 0\nfor m in model.modules():\n    if isinstance(m, nn.Conv2d):\n        out_channels = m.weight.data.shape[0]\n        if out_channels == cfg[layer_id]:\n            cfg_mask.append(torch.ones(out_channels))\n            layer_id += 1\n            continue\n        weight_copy = m.weight.data.abs().clone()\n        weight_copy = weight_copy.cpu().numpy()\n        L1_norm = np.sum(weight_copy, axis=(1, 2, 3))\n        arg_max = np.argsort(L1_norm)\n        arg_max_rev = arg_max[::-1][:cfg[layer_id]]\n        assert arg_max_rev.size == cfg[layer_id], ""size of arg_max_rev not correct""\n        mask = torch.zeros(out_channels)\n        mask[arg_max_rev.tolist()] = 1\n        cfg_mask.append(mask)\n        layer_id += 1\n    elif isinstance(m, nn.MaxPool2d):\n        layer_id += 1\n\n\nnewmodel = vgg(dataset=args.dataset, cfg=cfg)\nif args.cuda:\n    newmodel.cuda()\n\nstart_mask = torch.ones(3)\nlayer_id_in_cfg = 0\nend_mask = cfg_mask[layer_id_in_cfg]\nfor [m0, m1] in zip(model.modules(), newmodel.modules()):\n    if isinstance(m0, nn.BatchNorm2d):\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n        if idx1.size == 1:\n            idx1 = np.resize(idx1,(1,))\n        m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n        m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n        m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n        m1.running_var = m0.running_var[idx1.tolist()].clone()\n        layer_id_in_cfg += 1\n        start_mask = end_mask\n        if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n            end_mask = cfg_mask[layer_id_in_cfg]\n    elif isinstance(m0, nn.Conv2d):\n        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n        print(\'In shape: {:d}, Out shape {:d}.\'.format(idx0.size, idx1.size))\n        if idx0.size == 1:\n            idx0 = np.resize(idx0, (1,))\n        if idx1.size == 1:\n            idx1 = np.resize(idx1, (1,))\n        w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n        w1 = w1[idx1.tolist(), :, :, :].clone()\n        m1.weight.data = w1.clone()\n    elif isinstance(m0, nn.Linear):\n        if layer_id_in_cfg == len(cfg_mask):\n            idx0 = np.squeeze(np.argwhere(np.asarray(cfg_mask[-1].cpu().numpy())))\n            if idx0.size == 1:\n                idx0 = np.resize(idx0, (1,))\n            m1.weight.data = m0.weight.data[:, idx0].clone()\n            m1.bias.data = m0.bias.data.clone()\n            layer_id_in_cfg += 1\n            continue\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n    elif isinstance(m0, nn.BatchNorm1d):\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n        m1.running_mean = m0.running_mean.clone()\n        m1.running_var = m0.running_var.clone()\n\ntorch.save({\'cfg\': cfg, \'state_dict\': newmodel.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\nprint(newmodel)\nmodel = newmodel\nacc = test(model)\n\nnum_parameters = sum([param.nelement() for param in newmodel.parameters()])\nwith open(os.path.join(args.save, ""prune.txt""), ""w"") as fp:\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc)+""\\n"")'"
cifar/network-slimming/compute_flops.py,9,"b""# Code from https://github.com/simochen/model-tools.\nimport numpy as np\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef print_model_param_nums(model=None):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n    print('  + Number of params: %.2fM' % (total / 1e6))\n    return total\n\ndef print_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2['names'] = np.prod(input[0].shape)\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n        flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True)\n    out = model(input)\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print('  + Number of FLOPs: %.2fG' % (total_flops / 1e9))\n\n    return total_flops"""
cifar/network-slimming/denseprune.py,13,"b'import argparse\nimport numpy as np\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=40,\n                    help=\'depth of the resnet\')\nparser.add_argument(\'--percent\', type=float, default=0.5,\n                    help=\'scale sparse rate (default: 0.5)\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = densenet(depth=args.depth, dataset=args.dataset)\n\nif args.cuda:\n    model.cuda()\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\ntotal = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n        total += m.weight.data.shape[0]\n\nbn = torch.zeros(total)\nindex = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n        size = m.weight.data.shape[0]\n        bn[index:(index+size)] = m.weight.data.abs().clone()\n        index += size\n\ny, i = torch.sort(bn)\nthre_index = int(total * args.percent)\nthre = y[thre_index]\n\npruned = 0\ncfg = []\ncfg_mask = []\nfor k, m in enumerate(model.modules()):\n    if isinstance(m, nn.BatchNorm2d):\n        weight_copy = m.weight.data.abs().clone()\n        mask = weight_copy.gt(thre).float().cuda()\n        pruned = pruned + mask.shape[0] - torch.sum(mask)\n        m.weight.data.mul_(mask)\n        m.bias.data.mul_(mask)\n        cfg.append(int(torch.sum(mask)))\n        cfg_mask.append(mask.clone())\n        print(\'layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}\'.\n            format(k, mask.shape[0], int(torch.sum(mask))))\n    elif isinstance(m, nn.MaxPool2d):\n        cfg.append(\'M\')\n\npruned_ratio = pruned/total\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\n\nprint(""Cfg:"")\nprint(cfg)\n\nnewmodel = densenet(depth=args.depth, dataset=args.dataset, cfg=cfg)\n\nif args.cuda:\n    newmodel.cuda()\n\nnum_parameters = sum([param.nelement() for param in newmodel.parameters()])\nsavepath = os.path.join(args.save, ""prune.txt"")\nwith open(savepath, ""w"") as fp:\n    fp.write(""Configuration: \\n""+str(cfg)+""\\n"")\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc))\n\nold_modules = list(model.modules())\nnew_modules = list(newmodel.modules())\n\nlayer_id_in_cfg = 0\nstart_mask = torch.ones(3)\nend_mask = cfg_mask[layer_id_in_cfg]\nfirst_conv = True\n\nfor layer_id in range(len(old_modules)):\n    m0 = old_modules[layer_id]\n    m1 = new_modules[layer_id]\n    if isinstance(m0, nn.BatchNorm2d):\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n        if idx1.size == 1:\n            idx1 = np.resize(idx1,(1,))\n\n        if isinstance(old_modules[layer_id + 1], channel_selection):\n            # If the next layer is the channel selection layer, then the current batch normalization layer won\'t be pruned.\n            m1.weight.data = m0.weight.data.clone()\n            m1.bias.data = m0.bias.data.clone()\n            m1.running_mean = m0.running_mean.clone()\n            m1.running_var = m0.running_var.clone()\n\n            # We need to set the mask parameter `indexes` for the channel selection layer.\n            m2 = new_modules[layer_id + 1]\n            m2.indexes.data.zero_()\n            m2.indexes.data[idx1.tolist()] = 1.0\n\n            layer_id_in_cfg += 1\n            start_mask = end_mask.clone()\n            if layer_id_in_cfg < len(cfg_mask):\n                end_mask = cfg_mask[layer_id_in_cfg]\n            continue\n\n    elif isinstance(m0, nn.Conv2d):\n        if first_conv:\n            # We don\'t change the first convolution layer.\n            m1.weight.data = m0.weight.data.clone()\n            first_conv = False\n            continue\n        if isinstance(old_modules[layer_id - 1], channel_selection):\n            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n            print(\'In shape: {:d}, Out shape {:d}.\'.format(idx0.size, idx1.size))\n            if idx0.size == 1:\n                idx0 = np.resize(idx0, (1,))\n            if idx1.size == 1:\n                idx1 = np.resize(idx1, (1,))\n\n            # If the last layer is channel selection layer, then we don\'t change the number of output channels of the current\n            # convolutional layer.\n            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n            m1.weight.data = w1.clone()\n            continue\n\n    elif isinstance(m0, nn.Linear):\n        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n        if idx0.size == 1:\n            idx0 = np.resize(idx0, (1,))\n\n        m1.weight.data = m0.weight.data[:, idx0].clone()\n        m1.bias.data = m0.bias.data.clone()\n\ntorch.save({\'cfg\': cfg, \'state_dict\': newmodel.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\n\nprint(newmodel)\nmodel = newmodel\ntest(model)'"
cifar/network-slimming/main.py,14,"b'from __future__ import print_function\nimport os\nimport argparse\nimport shutil\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--sparsity-regularization\', \'-sr\', dest=\'sr\', action=\'store_true\',\n                    help=\'train with channel sparsity regularization\')\nparser.add_argument(\'--s\', type=float, default=0.0001,\n                    help=\'scale sparse rate (default: 0.0001)\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=19, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nhistory_score = np.zeros((args.epochs - args.start_epoch + 1, 3))\n\n# additional subgradient descent on the sparsity-induced penalty term\ndef updateBN():\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.weight.grad.data.add_(args.s*torch.sign(m.weight.data))  # L1\n\ndef train(epoch):\n    model.train()\n    global history_score\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        if args.sr:\n            updateBN()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n    history_score[epoch][0] = avg_loss / len(train_loader)\n    history_score[epoch][1] = train_acc / float(len(train_loader))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [args.epochs*0.5, args.epochs*0.75]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n    prec1 = test()\n    history_score[epoch][2] = prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n    }, is_best, filepath=args.save)\n\nprint(""Best accuracy: ""+str(best_prec1))\nhistory_score[-1][0] = best_prec1\nnp.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n'"
cifar/network-slimming/main_B.py,15,"b'from __future__ import print_function\nimport os\nimport argparse\nimport shutil\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\nfrom compute_flops import print_model_param_flops\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--sparsity-regularization\', \'-sr\', dest=\'sr\', action=\'store_true\',\n                    help=\'train with channel sparsity regularization\')\nparser.add_argument(\'--s\', type=float, default=0.0001,\n                    help=\'scale sparse rate (default: 0.0001)\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--scratch\',default=\'\', type=str,\n                    help=\'the PATH to the pruned model\')\nparser.add_argument(\'--depth\', default=19, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.scratch:\n    checkpoint = torch.load(args.scratch)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n    model_ref = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n    model_ref.load_state_dict(checkpoint[\'state_dict\'])\n    for m0, m1 in zip(model.modules(), model_ref.modules()):\n        if isinstance(m0, models.channel_selection):\n            m0.indexes.data = m1.indexes.data.clone()\n\n    model_base = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n    base_flops = print_model_param_flops(model_base, 32)\n    pruned_flops = print_model_param_flops(model, 32)\n    args.epochs = int(160 * (base_flops / pruned_flops))\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nhistory_score = np.zeros((args.epochs - args.start_epoch + 1, 3))\n\n# additional subgradient descent on the sparsity-induced penalty term\ndef updateBN():\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.weight.grad.data.add_(args.s*torch.sign(m.weight.data))  # L1\n\ndef train(epoch):\n    model.train()\n    global history_score\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        if args.sr:\n            updateBN()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n    history_score[epoch][0] = avg_loss / len(train_loader)\n    history_score[epoch][1] = train_acc / float(len(train_loader))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [int(args.epochs*0.5), int(args.epochs*0.75)]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n    prec1 = test()\n    history_score[epoch][2] = prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n    }, is_best, filepath=args.save)\n\nprint(""Best accuracy: ""+str(best_prec1))\nhistory_score[-1][0] = best_prec1\nnp.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n'"
cifar/network-slimming/main_E.py,15,"b'from __future__ import print_function\nimport os\nimport argparse\nimport shutil\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--sparsity-regularization\', \'-sr\', dest=\'sr\', action=\'store_true\',\n                    help=\'train with channel sparsity regularization\')\nparser.add_argument(\'--s\', type=float, default=0.0001,\n                    help=\'scale sparse rate (default: 0.0001)\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--scratch\',default=\'\', type=str,\n                    help=\'the PATH to the pruned model\')\nparser.add_argument(\'--depth\', default=19, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.scratch:\n    checkpoint = torch.load(args.scratch)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n    model_ref = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n    model_ref.load_state_dict(checkpoint[\'state_dict\'])\n    for m0, m1 in zip(model.modules(), model_ref.modules()):\n        if isinstance(m0, models.channel_selection):\n            m0.indexes.data = m1.indexes.data.clone()\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nhistory_score = np.zeros((args.epochs - args.start_epoch + 1, 3))\n\n# additional subgradient descent on the sparsity-induced penalty term\ndef updateBN():\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.weight.grad.data.add_(args.s*torch.sign(m.weight.data))  # L1\n\ndef train(epoch):\n    model.train()\n    global history_score\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        if args.sr:\n            updateBN()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n    history_score[epoch][0] = avg_loss / len(train_loader)\n    history_score[epoch][1] = train_acc / float(len(train_loader))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [args.epochs*0.5, args.epochs*0.75]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n    prec1 = test()\n    history_score[epoch][2] = prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n    }, is_best, filepath=args.save)\n\nprint(""Best accuracy: ""+str(best_prec1))\nhistory_score[-1][0] = best_prec1\nnp.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n'"
cifar/network-slimming/main_finetune.py,15,"b'from __future__ import print_function\nimport os\nimport argparse\nimport shutil\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--sparsity-regularization\', \'-sr\', dest=\'sr\', action=\'store_true\',\n                    help=\'train with channel sparsity regularization\')\nparser.add_argument(\'--s\', type=float, default=0.0001,\n                    help=\'scale sparse rate (default: 0.0001)\')\nparser.add_argument(\'--refine\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=40, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.001, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=19, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nif args.refine:\n    checkpoint = torch.load(args.refine)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n    model.load_state_dict(checkpoint[\'state_dict\'])\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nhistory_score = np.zeros((args.epochs - args.start_epoch + 1, 3))\n\n# additional subgradient descent on the sparsity-induced penalty term\ndef updateBN():\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.weight.grad.data.add_(args.s*torch.sign(m.weight.data))  # L1\n\ndef train(epoch):\n    model.train()\n    global history_score\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        if args.sr:\n            updateBN()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n    history_score[epoch][0] = avg_loss / len(train_loader)\n    history_score[epoch][1] = train_acc / float(len(train_loader))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    train(epoch)\n    prec1 = test()\n    history_score[epoch][2] = prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n    }, is_best, filepath=args.save)\n\nprint(""Best accuracy: ""+str(best_prec1))\nhistory_score[-1][0] = best_prec1\nnp.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')'"
cifar/network-slimming/resprune.py,13,"b'import argparse\nimport numpy as np\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=164,\n                    help=\'depth of the resnet\')\nparser.add_argument(\'--percent\', type=float, default=0.5,\n                    help=\'scale sparse rate (default: 0.5)\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = resnet(depth=args.depth, dataset=args.dataset)\n\nif args.cuda:\n    model.cuda()\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\ntotal = 0\n\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n        total += m.weight.data.shape[0]\n\nbn = torch.zeros(total)\nindex = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n        size = m.weight.data.shape[0]\n        bn[index:(index+size)] = m.weight.data.abs().clone()\n        index += size\n\ny, i = torch.sort(bn)\nthre_index = int(total * args.percent)\nthre = y[thre_index]\n\n\npruned = 0\ncfg = []\ncfg_mask = []\nfor k, m in enumerate(model.modules()):\n    if isinstance(m, nn.BatchNorm2d):\n        weight_copy = m.weight.data.abs().clone()\n        mask = weight_copy.gt(thre).float().cuda()\n        pruned = pruned + mask.shape[0] - torch.sum(mask)\n        m.weight.data.mul_(mask)\n        m.bias.data.mul_(mask)\n        cfg.append(int(torch.sum(mask)))\n        cfg_mask.append(mask.clone())\n        print(\'layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}\'.\n            format(k, mask.shape[0], int(torch.sum(mask))))\n    elif isinstance(m, nn.MaxPool2d):\n        cfg.append(\'M\')\n\npruned_ratio = pruned/total\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\n\nprint(""Cfg:"")\nprint(cfg)\n\nnewmodel = resnet(depth=args.depth, dataset=args.dataset, cfg=cfg)\nif args.cuda:\n    newmodel.cuda()\n\nnum_parameters = sum([param.nelement() for param in newmodel.parameters()])\nsavepath = os.path.join(args.save, ""prune.txt"")\nwith open(savepath, ""w"") as fp:\n    fp.write(""Configuration: \\n""+str(cfg)+""\\n"")\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc))\n\nold_modules = list(model.modules())\nnew_modules = list(newmodel.modules())\nlayer_id_in_cfg = 0\nstart_mask = torch.ones(3)\nend_mask = cfg_mask[layer_id_in_cfg]\nconv_count = 0\n\nfor layer_id in range(len(old_modules)):\n    m0 = old_modules[layer_id]\n    m1 = new_modules[layer_id]\n    if isinstance(m0, nn.BatchNorm2d):\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n        if idx1.size == 1:\n            idx1 = np.resize(idx1,(1,))\n\n        if isinstance(old_modules[layer_id + 1], channel_selection):\n            # If the next layer is the channel selection layer, then the current batchnorm 2d layer won\'t be pruned.\n            m1.weight.data = m0.weight.data.clone()\n            m1.bias.data = m0.bias.data.clone()\n            m1.running_mean = m0.running_mean.clone()\n            m1.running_var = m0.running_var.clone()\n\n            # We need to set the channel selection layer.\n            m2 = new_modules[layer_id + 1]\n            m2.indexes.data.zero_()\n            m2.indexes.data[idx1.tolist()] = 1.0\n\n            layer_id_in_cfg += 1\n            start_mask = end_mask.clone()\n            if layer_id_in_cfg < len(cfg_mask):\n                end_mask = cfg_mask[layer_id_in_cfg]\n        else:\n            m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n            m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n            m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n            m1.running_var = m0.running_var[idx1.tolist()].clone()\n            layer_id_in_cfg += 1\n            start_mask = end_mask.clone()\n            if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n                end_mask = cfg_mask[layer_id_in_cfg]\n    elif isinstance(m0, nn.Conv2d):\n        if conv_count == 0:\n            m1.weight.data = m0.weight.data.clone()\n            conv_count += 1\n            continue\n        if isinstance(old_modules[layer_id-1], channel_selection) or isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n            # This convers the convolutions in the residual block.\n            # The convolutions are either after the channel selection layer or after the batch normalization layer.\n            conv_count += 1\n            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n            print(\'In shape: {:d}, Out shape {:d}.\'.format(idx0.size, idx1.size))\n            if idx0.size == 1:\n                idx0 = np.resize(idx0, (1,))\n            if idx1.size == 1:\n                idx1 = np.resize(idx1, (1,))\n            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n\n            # If the current convolution is not the last convolution in the residual block, then we can change the \n            # number of output channels. Currently we use `conv_count` to detect whether it is such convolution.\n            if conv_count % 3 != 1:\n                w1 = w1[idx1.tolist(), :, :, :].clone()\n            m1.weight.data = w1.clone()\n            continue\n\n        # We need to consider the case where there are downsampling convolutions. \n        # For these convolutions, we just copy the weights.\n        m1.weight.data = m0.weight.data.clone()\n    elif isinstance(m0, nn.Linear):\n        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n        if idx0.size == 1:\n            idx0 = np.resize(idx0, (1,))\n\n        m1.weight.data = m0.weight.data[:, idx0].clone()\n        m1.bias.data = m0.bias.data.clone()\n\ntorch.save({\'cfg\': cfg, \'state_dict\': newmodel.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\n\nprint(newmodel)\nmodel = newmodel\ntest(model)'"
cifar/network-slimming/vggprune.py,13,"b'import argparse\nimport numpy as np\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=19,\n                    help=\'depth of the vgg\')\nparser.add_argument(\'--percent\', type=float, default=0.5,\n                    help=\'scale sparse rate (default: 0.5)\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = vgg(dataset=args.dataset, depth=args.depth)\nif args.cuda:\n    model.cuda()\n\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(model)\ntotal = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n        total += m.weight.data.shape[0]\n\nbn = torch.zeros(total)\nindex = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n        size = m.weight.data.shape[0]\n        bn[index:(index+size)] = m.weight.data.abs().clone()\n        index += size\n\ny, i = torch.sort(bn)\nthre_index = int(total * args.percent)\nthre = y[thre_index]\n\npruned = 0\ncfg = []\ncfg_mask = []\nfor k, m in enumerate(model.modules()):\n    if isinstance(m, nn.BatchNorm2d):\n        weight_copy = m.weight.data.abs().clone()\n        mask = weight_copy.gt(thre).float().cuda()\n        pruned = pruned + mask.shape[0] - torch.sum(mask)\n        m.weight.data.mul_(mask)\n        m.bias.data.mul_(mask)\n        cfg.append(int(torch.sum(mask)))\n        cfg_mask.append(mask.clone())\n        print(\'layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}\'.\n            format(k, mask.shape[0], int(torch.sum(mask))))\n    elif isinstance(m, nn.MaxPool2d):\n        cfg.append(\'M\')\n\npruned_ratio = pruned/total\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\n\n# Make real prune\nprint(cfg)\nnewmodel = vgg(dataset=args.dataset, cfg=cfg)\nif args.cuda:\n    newmodel.cuda()\n\nnum_parameters = sum([param.nelement() for param in newmodel.parameters()])\nsavepath = os.path.join(args.save, ""prune.txt"")\nwith open(savepath, ""w"") as fp:\n    fp.write(""Configuration: \\n""+str(cfg)+""\\n"")\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc))\n\nlayer_id_in_cfg = 0\nstart_mask = torch.ones(3)\nend_mask = cfg_mask[layer_id_in_cfg]\nfor [m0, m1] in zip(model.modules(), newmodel.modules()):\n    if isinstance(m0, nn.BatchNorm2d):\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n        if idx1.size == 1:\n            idx1 = np.resize(idx1,(1,))\n        m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n        m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n        m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n        m1.running_var = m0.running_var[idx1.tolist()].clone()\n        layer_id_in_cfg += 1\n        start_mask = end_mask.clone()\n        if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n            end_mask = cfg_mask[layer_id_in_cfg]\n    elif isinstance(m0, nn.Conv2d):\n        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n        print(\'In shape: {:d}, Out shape {:d}.\'.format(idx0.size, idx1.size))\n        if idx0.size == 1:\n            idx0 = np.resize(idx0, (1,))\n        if idx1.size == 1:\n            idx1 = np.resize(idx1, (1,))\n        w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n        w1 = w1[idx1.tolist(), :, :, :].clone()\n        m1.weight.data = w1.clone()\n    elif isinstance(m0, nn.Linear):\n        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n        if idx0.size == 1:\n            idx0 = np.resize(idx0, (1,))\n        m1.weight.data = m0.weight.data[:, idx0].clone()\n        m1.bias.data = m0.bias.data.clone()\n\ntorch.save({\'cfg\': cfg, \'state_dict\': newmodel.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\n\nprint(newmodel)\nmodel = newmodel\ntest(model)'"
cifar/soft-filter-pruning/compute_flops.py,9,"b'# Code from https://github.com/simochen/model-tools.\nimport numpy as np\nimport os\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport models.cifar as models\n\n\ndef print_model_param_nums(model=None):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total -= (m.weight.data == 0).sum()\n    print(\'  + Number of params: %.2fM\' % (total / 1e6))\n    return total\n\ndef count_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2[\'names\'] = np.prod(input[0].shape)\n\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n        # flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        num_weight_params = (self.weight.data != 0).float().sum()\n        assert self.weight.numel() == kernel_ops * output_channels, ""Not match""\n        flops = (num_weight_params * (2 if multiply_adds else 1) + bias_ops * output_channels) * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True)\n    out = model(input)\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print(\'  + Number of FLOPs: %.2fG\' % (total_flops / 1e9))\n\n    return total_flops'"
cifar/soft-filter-pruning/pruning_cifar10_pretrain.py,25,"b'from __future__ import division\n\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\nimport models\nimport numpy as np\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\nparser.add_argument(\'--arch\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names, help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnext29_8_64)\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=128, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.1, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--ngpu\', type=int, default=1, help=\'0 = CPU.\')\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\n#compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--layer_begin\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--use_state_dict\', dest=\'use_state_dict\', action=\'store_true\', help=\'use state dcit or not\')\n\n\nargs = parser.parse_args()\nargs.use_cuda = args.ngpu>0 and torch.cuda.is_available()\n\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n    # Init logger\n    if not os.path.isdir(args.save_path):\n        os.makedirs(args.save_path)\n    log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n    print_log(\'save path : {}\'.format(args.save_path), log)\n    state = {k: v for k, v in args._get_kwargs()}\n    print_log(state, log)\n    print_log(""Random Seed: {}"".format(args.manualSeed), log)\n    print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""torch  version : {}"".format(torch.__version__), log)\n    print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    # Init dataset\n    if not os.path.isdir(args.data_path):\n        os.makedirs(args.data_path)\n\n    if args.dataset == \'cifar10\':\n        mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n        std = [x / 255 for x in [63.0, 62.1, 66.7]]\n    elif args.dataset == \'cifar100\':\n        mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n        std = [x / 255 for x in [68.2, 65.4, 70.4]]\n    else:\n        assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n    train_transform = transforms.Compose(\n        [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n         transforms.Normalize(mean, std)])\n    test_transform = transforms.Compose(\n        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n    if args.dataset == \'cifar10\':\n        train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'cifar100\':\n        train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 100\n    elif args.dataset == \'svhn\':\n        train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'stl10\':\n        train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'imagenet\':\n        assert False, \'Do not finish imagenet code\'\n    else:\n        assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                                                 num_workers=args.workers, pin_memory=True)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                                                num_workers=args.workers, pin_memory=True)\n\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    # Init model, criterion, and optimizer\n    net = models.__dict__[args.arch](num_classes)\n    print_log(""=> network :\\n {}"".format(net), log)\n\n    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n\n    # define loss function (criterion) and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                                weight_decay=state[\'decay\'], nesterov=True)\n\n    if args.use_cuda:\n        net.cuda()\n        criterion.cuda()\n\n    recorder = RecorderMeter(args.epochs)\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            if args.use_state_dict:\n                net.load_state_dict(checkpoint[\'state_dict\'])\n            else:\n                net = checkpoint[\'state_dict\']\n\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n    else:\n        print_log(""=> do not use any checkpoint for {} model"".format(args.arch), log)\n\n    if args.evaluate:\n        time1 = time.time()\n        validate(test_loader, net, criterion, log)\n        time2 = time.time()\n        print (\'function took %0.3f ms\' % ((time2-time1)*1000.0))\n        return\n\n    comp_rate =  args.rate\n    print(""-""*10+""one epoch begin""+""-""*10)\n    print(""the compression rate now is %f"" % comp_rate)\n\n    val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n\n    print("" accu before is: %.3f %%"" % val_acc_1)\n\n    # Main loop\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n        print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n        # train for one epoch\n        train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n        # evaluate on validation set\n        val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n        \n        is_best = recorder.update(epoch, train_los, train_acc, val_los_1, val_acc_1)\n\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': net,\n            \'recorder\': recorder,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n\n    log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n                        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n                        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n                        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n                        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n                        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n                        epoch, i, len(train_loader), batch_time=batch_time,\n                        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n    print_log(\'  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n    return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    for i, (input, target) in enumerate(val_loader):\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n    print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n    return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n    filename = os.path.join(save_path, filename)\n    torch.save(state, filename)\n    if is_best:\n        bestname = os.path.join(save_path, \'model_best.pth.tar\')\n        shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.learning_rate\n    assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n    for (gamma, step) in zip(gammas, schedule):\n        if (epoch >= step):\n            lr = lr * gamma\n        else:\n            break\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass Mask:\n    def __init__(self,model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n        \n    \n    def get_codebook(self, weight_torch,compress_rate,length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n    \n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n        \n        threshold = weight_sort[int (length * (1-compress_rate) )]\n        weight_np [weight_np <= -threshold  ] = 1\n        weight_np [weight_np >= threshold  ] = 1\n        weight_np [weight_np !=1  ] = 0\n        \n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch,compress_rate,length):\n        codebook = np.ones(length)\n        if len( weight_torch.size())==4:\n            filter_pruned_num = int(weight_torch.size()[0]*(1-compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0],-1)\n            norm2 = torch.norm(weight_vec,2,1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n#            norm1_sort = np.sort(norm1_np)\n#            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n            kernel_length = weight_torch.size()[1] *weight_torch.size()[2] *weight_torch.size()[3]\n            for x in range(0,len(filter_index)):\n                codebook [filter_index[x] *kernel_length : (filter_index[x]+1) *kernel_length] = 0\n\n            print(""filter codebook done"")\n        else:\n            pass\n        return codebook\n    \n    def convert2tensor(self,x):\n        x = torch.FloatTensor(x)\n        return x\n    \n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size [index] = item.size()\n        \n        for index1 in self.model_size:\n            for index2 in range(0,len(self.model_size[index1])):\n                if index2 ==0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n                    \n    def init_rate(self, layer_rate):\n        for index, item in enumerate(self.model.parameters()):\n            self.compress_rate [index] = 1\n        for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n            self.compress_rate[key]= layer_rate\n        #different setting for  different architecture\n        if args.arch == \'resnet20\':\n            last_index = 57\n        elif args.arch == \'resnet32\':\n            last_index = 93\n        elif args.arch == \'resnet56\':\n            last_index = 165\n        elif args.arch == \'resnet110\':\n            last_index = 327\n        self.mask_index =  [x for x in range (0,last_index,3)]\n        \n    def init_mask(self,layer_rate):\n        self.init_rate(layer_rate)\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],self.model_length[index] )\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.use_cuda:\n                    self.mat[index] = self.mat[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n#            if(index in self.mask_index):\n            if(index ==0):\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n                \n                print(""number of nonzero weight is %d, zero is %d"" %( np.count_nonzero(b),len(b)- np.count_nonzero(b)))\n        \nif __name__ == \'__main__\':\n    main()'"
cifar/soft-filter-pruning/pruning_cifar10_resnet.py,24,"b'from __future__ import division\n\nimport argparse, os, sys, shutil, time, random\nimport numpy as np\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nimport models\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\nparser.add_argument(\'--arch\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names, help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnext29_8_64)\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=128, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.1, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--ngpu\', type=int, default=1, help=\'0 = CPU.\')\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\n#compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--layer_begin\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--use_state_dict\', dest=\'use_state_dict\', action=\'store_true\', help=\'use state dcit or not\')\n\n\nargs = parser.parse_args()\nargs.use_cuda = args.ngpu>0 and torch.cuda.is_available()\n\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n    # Init logger\n    if not os.path.isdir(args.save_path):\n        os.makedirs(args.save_path)\n    log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n    print_log(\'save path : {}\'.format(args.save_path), log)\n    state = {k: v for k, v in args._get_kwargs()}\n    print_log(state, log)\n    print_log(""Random Seed: {}"".format(args.manualSeed), log)\n    print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""torch  version : {}"".format(torch.__version__), log)\n    print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    # Init dataset\n    if not os.path.isdir(args.data_path):\n        os.makedirs(args.data_path)\n\n    if args.dataset == \'cifar10\':\n        mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n        std = [x / 255 for x in [63.0, 62.1, 66.7]]\n    elif args.dataset == \'cifar100\':\n        mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n        std = [x / 255 for x in [68.2, 65.4, 70.4]]\n    else:\n        assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n    train_transform = transforms.Compose(\n        [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n         transforms.Normalize(mean, std)])\n    test_transform = transforms.Compose(\n        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n    if args.dataset == \'cifar10\':\n        train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'cifar100\':\n        train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 100\n    elif args.dataset == \'svhn\':\n        train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'stl10\':\n        train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'imagenet\':\n        assert False, \'Do not finish imagenet code\'\n    else:\n        assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                                                 num_workers=args.workers, pin_memory=True)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                                                num_workers=args.workers, pin_memory=True)\n\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    # Init model, criterion, and optimizer\n    net = models.__dict__[args.arch](num_classes)\n    print_log(""=> network :\\n {}"".format(net), log)\n\n    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n\n    recorder = RecorderMeter(args.epochs)\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            # recorder = checkpoint[\'recorder\']\n            # args.start_epoch = checkpoint[\'epoch\']\n            if args.use_state_dict:\n                net.load_state_dict(checkpoint[\'state_dict\'])\n            else:\n                net = checkpoint[\'state_dict\']\n                \n            # optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n    else:\n        print_log(""=> do not use any checkpoint for {} model"".format(args.arch), log)\n\n    # define loss function (criterion) and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                                weight_decay=state[\'decay\'], nesterov=True)\n\n    if args.use_cuda:\n        net.cuda()\n        criterion.cuda()\n\n    if args.evaluate:\n        time1 = time.time()\n        validate(test_loader, net, criterion, log)\n        time2 = time.time()\n        print (\'function took %0.3f ms\' % ((time2-time1)*1000.0))\n        return\n\n    m=Mask(net)\n\n    m.init_length()\n\n    comp_rate =  args.rate\n    print(""-""*10+""one epoch begin""+""-""*10)\n    print(""the compression rate now is %f"" % comp_rate)\n\n    val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n\n    print("" accu before is: %.3f %%"" % val_acc_1)\n\n    m.model = net\n\n    m.init_mask(comp_rate)\n    m.do_mask()\n    net = m.model\n    if args.use_cuda:\n        net = net.cuda()    \n    val_acc_2,   val_los_2   = validate(test_loader, net, criterion, log)\n    print("" accu after is: %s %%"" % val_acc_2)\n\n    # Main loop\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n        print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n        # train for one epoch\n        train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n        # evaluate on validation set\n        val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n        if (epoch % args.epoch_prune ==0 or epoch == args.epochs-1):\n            m.model = net\n            m.if_zero()\n            m.init_mask(comp_rate)\n            m.do_mask()\n            m.if_zero()\n            net = m.model \n            if args.use_cuda:\n                net = net.cuda()  \n\n        val_acc_2,   val_los_2   = validate(test_loader, net, criterion, log)\n\n        is_best = recorder.update(epoch, train_los, train_acc, val_los_2, val_acc_2)\n\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': net,\n            \'recorder\': recorder,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n\n    log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n                        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n                        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n                        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n                        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n                        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n                        epoch, i, len(train_loader), batch_time=batch_time,\n                        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n    print_log(\'  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n    return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    for i, (input, target) in enumerate(val_loader):\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n    print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n    return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n    filename = os.path.join(save_path, filename)\n    torch.save(state, filename)\n    if is_best:\n        bestname = os.path.join(save_path, \'model_best.pth.tar\')\n        shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.learning_rate\n    assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n    for (gamma, step) in zip(gammas, schedule):\n        if (epoch >= step):\n            lr = lr * gamma\n        else:\n            break\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nclass Mask:\n    def __init__(self,model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n\n    def get_codebook(self, weight_torch,compress_rate,length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n\n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n\n        threshold = weight_sort[int (length * (1-compress_rate) )]\n        weight_np [weight_np <= -threshold  ] = 1\n        weight_np [weight_np >= threshold  ] = 1\n        weight_np [weight_np !=1  ] = 0\n\n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch,compress_rate,length):\n        codebook = np.ones(length)\n        if len( weight_torch.size())==4:\n            filter_pruned_num = int(weight_torch.size()[0]*(1-compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0],-1)\n            norm2 = torch.norm(weight_vec,2,1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n            kernel_length = weight_torch.size()[1] *weight_torch.size()[2] *weight_torch.size()[3]\n            for x in range(0,len(filter_index)):\n                codebook [filter_index[x] *kernel_length : (filter_index[x]+1) *kernel_length] = 0\n\n            print(""filter codebook done"")\n        else:\n            pass\n        return codebook\n\n    def convert2tensor(self,x):\n        x = torch.FloatTensor(x)\n        return x\n\n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size [index] = item.size()\n        \n        for index1 in self.model_size:\n            for index2 in range(0,len(self.model_size[index1])):\n                if index2 ==0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n\n    def init_rate(self, layer_rate):\n        for index, item in enumerate(self.model.parameters()):\n            self.compress_rate [index] = 1\n        for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n            self.compress_rate[key]= layer_rate\n        #different setting for  different architecture\n        if args.arch == \'resnet20\':\n            last_index = 57\n        elif args.arch == \'resnet32\':\n            last_index = 93\n        elif args.arch == \'resnet56\':\n            last_index = 165\n        elif args.arch == \'resnet110\':\n            last_index = 327\n        self.mask_index =  [x for x in range (0,last_index,3)]\n        \n    def init_mask(self,layer_rate):\n        self.init_rate(layer_rate)\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],self.model_length[index] )\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.use_cuda:\n                    self.mat[index] = self.mat[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n            if(index ==0):\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n                \n                print(""number of nonzero weight is %d, zero is %d"" %( np.count_nonzero(b),len(b)- np.count_nonzero(b)))\n        \nif __name__ == \'__main__\':\n    main()'"
cifar/soft-filter-pruning/pruning_resnet_longer_scratch.py,27,"b'from __future__ import division\n\nimport argparse, math, os, sys, shutil, time, random\nimport numpy as np\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nimport models\n\nfrom compute_flops import count_model_param_flops\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\nparser.add_argument(\'--arch\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names, help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnext29_8_64)\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=128, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.1, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--ngpu\', type=int, default=1, help=\'0 = CPU.\')\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\n#compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--layer_begin\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--use_state_dict\', dest=\'use_state_dict\', action=\'store_true\', help=\'use state dcit or not\')\n\n\nargs = parser.parse_args()\nargs.use_cuda = args.ngpu>0 and torch.cuda.is_available()\n\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n    # Init logger\n    if not os.path.isdir(args.save_path):\n        os.makedirs(args.save_path)\n    log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n    print_log(\'save path : {}\'.format(args.save_path), log)\n    state = {k: v for k, v in args._get_kwargs()}\n    print_log(state, log)\n    print_log(""Random Seed: {}"".format(args.manualSeed), log)\n    print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""torch  version : {}"".format(torch.__version__), log)\n    print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    # Init dataset\n    if not os.path.isdir(args.data_path):\n        os.makedirs(args.data_path)\n\n    if args.dataset == \'cifar10\':\n        mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n        std = [x / 255 for x in [63.0, 62.1, 66.7]]\n    elif args.dataset == \'cifar100\':\n        mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n        std = [x / 255 for x in [68.2, 65.4, 70.4]]\n    else:\n        assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n    train_transform = transforms.Compose(\n        [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n         transforms.Normalize(mean, std)])\n    test_transform = transforms.Compose(\n        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n    if args.dataset == \'cifar10\':\n        train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'cifar100\':\n        train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 100\n    elif args.dataset == \'svhn\':\n        train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'stl10\':\n        train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'imagenet\':\n        assert False, \'Do not finish imagenet code\'\n    else:\n        assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                                                 num_workers=args.workers, pin_memory=True)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                                                num_workers=args.workers, pin_memory=True)\n\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    # Init model, criterion, and optimizer\n    net = models.__dict__[args.arch](num_classes)\n    net_ref = models.__dict__[args.arch](num_classes)\n    print_log(""=> network :\\n {}"".format(net), log)\n\n    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n    net_ref = torch.nn.DataParallel(net_ref, device_ids=list(range(args.ngpu)))\n\n\n    # define loss function (criterion) and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                                weight_decay=state[\'decay\'], nesterov=True)\n\n    if args.use_cuda:\n        net.cuda()\n        criterion.cuda()\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            net_ref = checkpoint[\'state_dict\']\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n    else:\n        print_log(""=> do not use any checkpoint for {} model"".format(args.arch), log)\n\n    flops_std = count_model_param_flops(net, 32)\n    flops_small = count_model_param_flops(net_ref, 32)\n\n    ratio = flops_std / flops_small\n    args.epochs = int(400 * ratio)\n    print(""Total epochs %d""%args.epochs)\n    schedule = args.schedule\n    args.schedule = [1, int(schedule[1] * ratio), int(schedule[2] * ratio), int(schedule[3] * ratio)]\n    print(args.schedule)\n\n    recorder = RecorderMeter(args.epochs)\n    ###################################################################################################################\n    for m, m_ref in zip(net.modules(), net_ref.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m_ref.weight.data.abs().clone()\n            mask = weight_copy.gt(0).float().cuda()\n            n = mask.sum() / float(m.in_channels)\n            m.weight.data.normal_(0, math.sqrt(2. / n))\n            m.weight.data.mul_(mask)\n    ###################################################################################################################\n\n    if args.evaluate:\n        time1 = time.time()\n        validate(test_loader, net, criterion, log)\n        time2 = time.time()\n        print (\'function took %0.3f ms\' % ((time2-time1)*1000.0))\n        return\n\n    m=Mask(net)\n    \n    m.init_length()\n\n    comp_rate =  args.rate\n    print(""-""*10+""one epoch begin""+""-""*10)\n    print(""the compression rate now is %f"" % comp_rate)\n\n    val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n\n    print("" accu before is: %.3f %%"" % val_acc_1)\n\n    if args.use_cuda:\n        net = net.cuda()    \n    val_acc_2,   val_los_2   = validate(test_loader, net, criterion, log)\n    print("" accu after is: %s %%"" % val_acc_2)\n\n    # Main loop\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n        print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n        num_parameters = get_conv_zero_param(net)\n        print_log(\'Zero parameters: {}\'.format(num_parameters), log)\n        num_parameters = sum([param.nelement() for param in net.parameters()])\n        print_log(\'Parameters: {}\'.format(num_parameters), log)\n\n        # train for one epoch\n        train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n        # evaluate on validation set\n        val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n\n        is_best = recorder.update(epoch, train_los, train_acc, val_los_2, val_acc_2)\n\n        save_checkpoint({\n            \'arch\': args.arch,\n            \'state_dict\': net.state_dict(),\n            \'recorder\': recorder,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n\n    log.close()\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n                        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n                        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n                        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n                        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n                        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n                        epoch, i, len(train_loader), batch_time=batch_time,\n                        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n    print_log(\'  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n    return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    for i, (input, target) in enumerate(val_loader):\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n    print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n    return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n    filename = os.path.join(save_path, filename)\n    torch.save(state, filename)\n    if is_best:\n        bestname = os.path.join(save_path, \'model_best.pth.tar\')\n        shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.learning_rate\n    assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n    for (gamma, step) in zip(gammas, schedule):\n        if (epoch >= step):\n            lr = lr * gamma\n        else:\n            break\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass Mask:\n    def __init__(self,model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n        \n    \n    def get_codebook(self, weight_torch,compress_rate,length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n    \n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n        \n        threshold = weight_sort[int (length * (1-compress_rate) )]\n        weight_np [weight_np <= -threshold  ] = 1\n        weight_np [weight_np >= threshold  ] = 1\n        weight_np [weight_np !=1  ] = 0\n        \n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch,compress_rate,length):\n        codebook = np.ones(length)\n        if len( weight_torch.size())==4:\n            filter_pruned_num = int(weight_torch.size()[0]*(1-compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0],-1)\n            norm2 = torch.norm(weight_vec,2,1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n            kernel_length = weight_torch.size()[1] *weight_torch.size()[2] *weight_torch.size()[3]\n            for x in range(0,len(filter_index)):\n                codebook [filter_index[x] *kernel_length : (filter_index[x]+1) *kernel_length] = 0\n\n            print(""filter codebook done"")\n        else:\n            pass\n        return codebook\n    \n    def convert2tensor(self,x):\n        x = torch.FloatTensor(x)\n        return x\n    \n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size [index] = item.size()\n        \n        for index1 in self.model_size:\n            for index2 in range(0,len(self.model_size[index1])):\n                if index2 ==0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n                    \n    def init_rate(self, layer_rate):\n        for index, item in enumerate(self.model.parameters()):\n            self.compress_rate [index] = 1\n        for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n            self.compress_rate[key]= layer_rate\n        #different setting for  different architecture\n        if args.arch == \'resnet20\':\n            last_index = 57\n        elif args.arch == \'resnet32\':\n            last_index = 93\n        elif args.arch == \'resnet56\':\n            last_index = 165\n        elif args.arch == \'resnet110\':\n            last_index = 327\n        self.mask_index =  [x for x in range (0,last_index,3)]\n        \n    def init_mask(self,layer_rate):\n        self.init_rate(layer_rate)\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],self.model_length[index] )\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.use_cuda:\n                    self.mat[index] = self.mat[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n            if(index ==0):\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n                \n                print(""number of nonzero weight is %d, zero is %d"" %( np.count_nonzero(b),len(b)- np.count_nonzero(b)))\n        \nif __name__ == \'__main__\':\n    main()'"
cifar/soft-filter-pruning/pruning_resnet_scratch.py,27,"b'from __future__ import division\n\nimport argparse, math, os, sys, shutil, time, random\nimport numpy as np\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nimport models\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\nparser.add_argument(\'--arch\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names, help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnext29_8_64)\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=128, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.1, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--ngpu\', type=int, default=1, help=\'0 = CPU.\')\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\n#compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--layer_begin\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--use_state_dict\', dest=\'use_state_dict\', action=\'store_true\', help=\'use state dcit or not\')\n\n\nargs = parser.parse_args()\nargs.use_cuda = args.ngpu>0 and torch.cuda.is_available()\n\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n    # Init logger\n    if not os.path.isdir(args.save_path):\n        os.makedirs(args.save_path)\n    log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n    print_log(\'save path : {}\'.format(args.save_path), log)\n    state = {k: v for k, v in args._get_kwargs()}\n    print_log(state, log)\n    print_log(""Random Seed: {}"".format(args.manualSeed), log)\n    print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""torch  version : {}"".format(torch.__version__), log)\n    print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    # Init dataset\n    if not os.path.isdir(args.data_path):\n        os.makedirs(args.data_path)\n\n    if args.dataset == \'cifar10\':\n        mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n        std = [x / 255 for x in [63.0, 62.1, 66.7]]\n    elif args.dataset == \'cifar100\':\n        mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n        std = [x / 255 for x in [68.2, 65.4, 70.4]]\n    else:\n        assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n    train_transform = transforms.Compose(\n        [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n         transforms.Normalize(mean, std)])\n    test_transform = transforms.Compose(\n        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n    if args.dataset == \'cifar10\':\n        train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'cifar100\':\n        train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 100\n    elif args.dataset == \'svhn\':\n        train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'stl10\':\n        train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'imagenet\':\n        assert False, \'Do not finish imagenet code\'\n    else:\n        assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                                                 num_workers=args.workers, pin_memory=True)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                                                num_workers=args.workers, pin_memory=True)\n\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    # Init model, criterion, and optimizer\n    net = models.__dict__[args.arch](num_classes)\n    net_ref = models.__dict__[args.arch](num_classes)\n    print_log(""=> network :\\n {}"".format(net), log)\n\n    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n    net_ref = torch.nn.DataParallel(net_ref, device_ids=list(range(args.ngpu)))\n\n\n    # define loss function (criterion) and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                                weight_decay=state[\'decay\'], nesterov=True)\n\n    if args.use_cuda:\n        net.cuda()\n        criterion.cuda()\n\n    recorder = RecorderMeter(args.epochs)\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            net_ref = checkpoint[\'state_dict\']\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n    else:\n        print_log(""=> do not use any checkpoint for {} model"".format(args.arch), log)\n\n    ###################################################################################################################\n    for m, m_ref in zip(net.modules(), net_ref.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m_ref.weight.data.abs().clone()\n            mask = weight_copy.gt(0).float().cuda()\n            n = mask.sum() / float(m.in_channels)\n            m.weight.data.normal_(0, math.sqrt(2. / n))\n            m.weight.data.mul_(mask)\n    ###################################################################################################################\n\n    if args.evaluate:\n        time1 = time.time()\n        validate(test_loader, net, criterion, log)\n        time2 = time.time()\n        print (\'function took %0.3f ms\' % ((time2-time1)*1000.0))\n        return\n\n    m=Mask(net)\n    \n    m.init_length()\n    \n    comp_rate =  args.rate\n    print(""-""*10+""one epoch begin""+""-""*10)\n    print(""the compression rate now is %f"" % comp_rate)\n\n    val_acc_1,   val_los_1   = validate(test_loader, net_ref, criterion, log)\n\n    print("" accu before is: %.3f %%"" % val_acc_1)\n\n    if args.use_cuda:\n        net = net.cuda()    \n    val_acc_2,   val_los_2   = validate(test_loader, net, criterion, log)\n    print("" accu after is: %s %%"" % val_acc_2)\n\n\n    # Main loop\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n        print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n        num_parameters = get_conv_zero_param(net)\n        print_log(\'Zero parameters: {}\'.format(num_parameters), log)\n        num_parameters = sum([param.nelement() for param in net.parameters()])\n        print_log(\'Parameters: {}\'.format(num_parameters), log)\n\n        # train for one epoch\n        train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n        # evaluate on validation set\n        val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n\n        is_best = recorder.update(epoch, train_los, train_acc, val_los_2, val_acc_2)\n\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': net,\n            \'recorder\': recorder,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n\n    log.close()\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n                        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n                        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n                        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n                        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n                        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n                        epoch, i, len(train_loader), batch_time=batch_time,\n                        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n    print_log(\'  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n    return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    for i, (input, target) in enumerate(val_loader):\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n    print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n    return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n    filename = os.path.join(save_path, filename)\n    torch.save(state, filename)\n    if is_best:\n        bestname = os.path.join(save_path, \'model_best.pth.tar\')\n        shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.learning_rate\n    assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n    for (gamma, step) in zip(gammas, schedule):\n        if (epoch >= step):\n            lr = lr * gamma\n        else:\n            break\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass Mask:\n    def __init__(self,model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n        \n    \n    def get_codebook(self, weight_torch,compress_rate,length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n    \n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n        \n        threshold = weight_sort[int (length * (1-compress_rate) )]\n        weight_np [weight_np <= -threshold  ] = 1\n        weight_np [weight_np >= threshold  ] = 1\n        weight_np [weight_np !=1  ] = 0\n        \n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch,compress_rate,length):\n        codebook = np.ones(length)\n        if len( weight_torch.size())==4:\n            filter_pruned_num = int(weight_torch.size()[0]*(1-compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0],-1)\n            norm2 = torch.norm(weight_vec,2,1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n            kernel_length = weight_torch.size()[1] *weight_torch.size()[2] *weight_torch.size()[3]\n            for x in range(0,len(filter_index)):\n                codebook [filter_index[x] *kernel_length : (filter_index[x]+1) *kernel_length] = 0\n\n            print(""filter codebook done"")\n        else:\n            pass\n        return codebook\n    \n    def convert2tensor(self,x):\n        x = torch.FloatTensor(x)\n        return x\n    \n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size [index] = item.size()\n        \n        for index1 in self.model_size:\n            for index2 in range(0,len(self.model_size[index1])):\n                if index2 ==0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n                    \n    def init_rate(self, layer_rate):\n        for index, item in enumerate(self.model.parameters()):\n            self.compress_rate [index] = 1\n        for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n            self.compress_rate[key]= layer_rate\n        #different setting for  different architecture\n        if args.arch == \'resnet20\':\n            last_index = 57\n        elif args.arch == \'resnet32\':\n            last_index = 93\n        elif args.arch == \'resnet56\':\n            last_index = 165\n        elif args.arch == \'resnet110\':\n            last_index = 327\n        self.mask_index =  [x for x in range (0,last_index,3)]\n        \n    def init_mask(self,layer_rate):\n        self.init_rate(layer_rate)\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],self.model_length[index] )\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.use_cuda:\n                    self.mat[index] = self.mat[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n            if(index ==0):\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n                \n                print(""number of nonzero weight is %d, zero is %d"" %( np.count_nonzero(b),len(b)- np.count_nonzero(b)))\n        \nif __name__ == \'__main__\':\n    main()'"
cifar/soft-filter-pruning/utils.py,0,"b'import os, random, sys, time\nimport numpy as np\n\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n'"
cifar/weight-level/cifar.py,13,"b'from __future__ import print_function\n\nimport argparse\nimport os\nimport random\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=160, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=64, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=50, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[80, 120],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'results/\', type=str)\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\n# Use CUDA\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n\n    if not os.path.isdir(args.save_dir):\n        mkdir_p(args.save_dir)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n\n    model = torch.nn.DataParallel(model).cuda()\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Resuming from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        args.save_dir = os.path.dirname(args.resume)\n        checkpoint = torch.load(args.resume)\n        best_acc = checkpoint[\'best_acc\']\n        start_epoch = checkpoint[\'epoch\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        logger = Logger(os.path.join(args.save_dir, \'log.txt\'), title=title, resume=True)\n    else:\n        logger = Logger(os.path.join(args.save_dir, \'log.txt\'), title=title)\n        logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    if args.evaluate:\n        print(\'\\nEvaluation only\')\n        test_loss, test_acc = test(testloader, model, criterion, start_epoch, use_cuda)\n        print(\' Test Loss:  %.8f, Test Acc:  %.2f\' % (test_loss, test_acc))\n        return\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n\n        train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.save_dir)\n\n    logger.close()\n\n    print(\'Best acc:\')\n    print(best_acc)\n\ndef train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(trainloader))\n    print(args)\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'checkpoint.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n    if is_best:\n        shutil.copyfile(filepath, os.path.join(checkpoint, \'model_best.pth.tar\'))\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/weight-level/cifar_B.py,14,"b'from __future__ import print_function\n\nimport argparse\nimport math\nimport os\nimport random\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\nfrom count_flops import count_model_param_flops\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\nfrom utils.misc import get_conv_zero_param\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=160, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=64, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=50, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[80, 120],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'results/\', type=str)\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\n# Use CUDA\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 100000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n\n    if not os.path.isdir(args.save_dir):\n        mkdir_p(args.save_dir)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n        model_ref = models.__dict__[args.arch](num_classes=num_classes)\n\n    flops_large = count_model_param_flops(model, 32)\n    flops_small = count_model_param_flops(model_ref, 32)\n    args.epochs = int(args.epochs*flops_large / flops_small)\n    args.schedule = [int(args.epochs * 0.5), int(args.epochs * 0.75)]\n    print(""Scratch-B epoch number: %d""%args.epochs)\n    print(""Scratch-B learning rate schedule %s""%args,schedule)\n\n    model = torch.nn.DataParallel(model).cuda()\n    model_ref = torch.nn.DataParallel(model_ref).cuda()\n\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay) # default is 0.001\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Getting reference model from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        checkpoint = torch.load(args.resume)\n        model_ref.load_state_dict(checkpoint[\'state_dict\'])\n\n    logger = Logger(os.path.join(args.save_dir, \'log_scratch.txt\'), title=title)\n    logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    # set some weights to zero, according to model_ref ---------------------------------\n    for m, m_ref in zip(model.modules(), model_ref.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m_ref.weight.data.abs().clone()\n            mask = weight_copy.gt(0).float().cuda()\n            n = mask.sum() / float(m.in_channels)\n            m.weight.data.normal_(0, math.sqrt(2. / n))\n            m.weight.data.mul_(mask)\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n        num_parameters = get_conv_zero_param(model)\n        print(\'Zero parameters: {}\'.format(num_parameters))\n        num_parameters = sum([param.nelement() for param in model.parameters()])\n        print(\'Parameters: {}\'.format(num_parameters))\n\n        train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.save_dir)\n\n    logger.close()\n\n    print(\'Best acc:\')\n    print(best_acc)\n\n\n\ndef train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(trainloader))\n    print(args)\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'scratch.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/weight-level/cifar_E.py,14,"b'from __future__ import print_function\n\nimport argparse\nimport math\nimport os\nimport random\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\nfrom utils.misc import get_conv_zero_param\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=160, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=64, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=50, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[80, 120],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'results/\', type=str)\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\n# Use CUDA\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 100000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n\n    if not os.path.isdir(args.save_dir):\n        mkdir_p(args.save_dir)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n        model_ref = models.__dict__[args.arch](num_classes=num_classes)\n\n    model = torch.nn.DataParallel(model).cuda()\n    model_ref = torch.nn.DataParallel(model_ref).cuda()\n\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay) # default is 0.001\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Getting reference model from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        checkpoint = torch.load(args.resume)\n        model_ref.load_state_dict(checkpoint[\'state_dict\'])\n\n    logger = Logger(os.path.join(args.save_dir, \'log_scratch.txt\'), title=title)\n    logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    # set some weights to zero, according to model_ref ---------------------------------\n    for m, m_ref in zip(model.modules(), model_ref.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m_ref.weight.data.abs().clone()\n            mask = weight_copy.gt(0).float().cuda()\n            n = mask.sum() / float(m.in_channels)\n            m.weight.data.normal_(0, math.sqrt(2. / n))\n            m.weight.data.mul_(mask)\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n        num_parameters = get_conv_zero_param(model)\n        print(\'Zero parameters: {}\'.format(num_parameters))\n        num_parameters = sum([param.nelement() for param in model.parameters()])\n        print(\'Parameters: {}\'.format(num_parameters))\n\n        train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.save_dir)\n\n    logger.close()\n\n    print(\'Best acc:\')\n    print(best_acc)\n\n\n\ndef train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(trainloader))\n    print(args)\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'scratch.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/weight-level/cifar_finetune.py,13,"b'from __future__ import print_function\n\nimport argparse\nimport os\nimport random\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\nfrom utils.misc import get_conv_zero_param\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=40, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=64, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=50, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.001, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[41, 42],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'test_checkpoint/\', type=str)\n#Device options\nparser.add_argument(\'--percent\', default=0.6, type=float)\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\n# Use CUDA\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n\n    if not os.path.isdir(args.save_dir):\n        mkdir_p(args.save_dir)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n\n    model = torch.nn.DataParallel(model).cuda()\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay) # default is 0.001\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Resuming from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        checkpoint = torch.load(args.resume)\n        model.load_state_dict(checkpoint[\'state_dict\'])\n\n    logger = Logger(os.path.join(args.save_dir, \'log_finetune.txt\'), title=title)\n    logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n        num_parameters = get_conv_zero_param(model)\n        print(\'Zero parameters: {}\'.format(num_parameters))\n        num_parameters = sum([param.nelement() for param in model.parameters()])\n        print(\'Parameters: {}\'.format(num_parameters))\n\n        train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.save_dir)\n\n    logger.close()\n\n    print(\'Best acc:\')\n    print(best_acc)\n\ndef train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(trainloader))\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        #-----------------------------------------\n        for k, m in enumerate(model.modules()):\n            # print(k, m)\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n        #-----------------------------------------\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'finetuned.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/weight-level/cifar_prune.py,17,"b'from __future__ import print_function\n\nimport argparse\nimport os\nimport random\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=300, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=128, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=100, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'test_checkpoint/\', type=str)\nparser.add_argument(\'--percent\', default=0.6, type=float, help=\'percentage of weight to prune\')\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\n# Use CUDA\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n\n    if not os.path.isdir(args.save_dir):\n        mkdir_p(args.save_dir)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n\n    model = torch.nn.DataParallel(model).cuda()\n    model.cuda()\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Resuming from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        checkpoint = torch.load(args.resume)\n        model.load_state_dict(checkpoint[\'state_dict\'])\n    else:\n        logger = Logger(os.path.join(args.save_dir, \'log.txt\'), title=title)\n        logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    print(\'\\nEvaluation only\')\n    test_loss0, test_acc0 = test(testloader, model, criterion, start_epoch, use_cuda)\n    print(\'Before pruning: Test Loss:  %.8f, Test Acc:  %.2f\' % (test_loss0, test_acc0))\n\n# -------------------------------------------------------------\n    #pruning \n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += m.weight.data.numel()\n    conv_weights = torch.zeros(total)\n    index = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            size = m.weight.data.numel()\n            conv_weights[index:(index+size)] = m.weight.data.view(-1).abs().clone()\n            index += size\n\n    y, i = torch.sort(conv_weights)\n    thre_index = int(total * args.percent)\n    thre = y[thre_index]\n    pruned = 0\n    print(\'Pruning threshold: {}\'.format(thre))\n    zero_flag = False\n    for k, m in enumerate(model.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m.weight.data.abs().clone()\n            mask = weight_copy.gt(thre).float().cuda()\n            pruned = pruned + mask.numel() - torch.sum(mask)\n            m.weight.data.mul_(mask)\n            if int(torch.sum(mask)) == 0:\n                zero_flag = True\n            print(\'layer index: {:d} \\t total params: {:d} \\t remaining params: {:d}\'.\n                format(k, mask.numel(), int(torch.sum(mask))))\n    print(\'Total conv params: {}, Pruned conv params: {}, Pruned ratio: {}\'.format(total, pruned, pruned/total))\n# -------------------------------------------------------------\n\n    print(\'\\nTesting\')\n    test_loss1, test_acc1 = test(testloader, model, criterion, start_epoch, use_cuda)\n    print(\'After Pruning: Test Loss:  %.8f, Test Acc:  %.2f\' % (test_loss1, test_acc1))\n    save_checkpoint({\n            \'epoch\': 0,\n            \'state_dict\': model.state_dict(),\n            \'acc\': test_acc1,\n            \'best_acc\': 0.,\n        }, False, checkpoint=args.save_dir)\n\n    with open(os.path.join(args.save_dir, \'prune.txt\'), \'w\') as f:\n        f.write(\'Before pruning: Test Loss:  %.8f, Test Acc:  %.2f\\n\' % (test_loss0, test_acc0))\n        f.write(\'Total conv params: {}, Pruned conv params: {}, Pruned ratio: {}\\n\'.format(total, pruned, pruned/total))\n        f.write(\'After Pruning: Test Loss:  %.8f, Test Acc:  %.2f\\n\' % (test_loss1, test_acc1))\n\n        if zero_flag:\n            f.write(""There exists a layer with 0 parameters left."")\n    return\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'pruned.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/weight-level/count_flops.py,9,"b'# Code from https://github.com/simochen/model-tools.\nimport numpy as np\nimport os\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport models.cifar as models\n\n\ndef print_model_param_nums(model=None):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total -= (m.weight.data == 0).sum()\n    print(\'  + Number of params: %.2fM\' % (total / 1e6))\n    return total\n\ndef count_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2[\'names\'] = np.prod(input[0].shape)\n\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n        # flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        num_weight_params = (self.weight.data != 0).float().sum()\n        assert self.weight.numel() == kernel_ops * output_channels, ""Not match""\n        flops = (num_weight_params * (2 if multiply_adds else 1) + bias_ops * output_channels) * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True)\n    out = model(input)\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print(\'  + Number of FLOPs: %.2fG\' % (total_flops / 1e9))\n\n    return total_flops'"
imagenet/l1-norm-pruning/compute_flops.py,9,"b""# Code from https://github.com/simochen/model-tools.\nimport numpy as np\nimport os\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef print_model_param_nums(model=None):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n    print('  + Number of params: %.4fM' % (total / 1e6))\n\ndef count_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2['names'] = np.prod(input[0].shape)\n\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n        # flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        num_weight_params = (self.weight.data != 0).float().sum()\n        flops = (num_weight_params * (2 if multiply_adds else 1) + bias_ops * output_channels) * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True)\n    out = model(input)\n\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print('  + Number of FLOPs: %.2fG' % (total_flops / 1e9))\n\n    return total_flops"""
imagenet/l1-norm-pruning/main_B.py,21,"b'import argparse\nimport os\nimport numpy as np\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom resnet import resnet34\nfrom compute_flops import count_model_param_flops\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet34\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--s\', type=float, default=0,\n                    help=\'scale sparse rate (default: 0)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'the PATH to the pruned model\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    if args.scratch:\n        checkpoint = torch.load(args.scratch)\n        model = resnet34(cfg=checkpoint[\'cfg\'])\n\n    model_ref = resnet34()\n\n    flops_std = count_model_param_flops(model_ref)\n    flops_small = count_model_param_flops(model)\n    ratio = flops_std / flops_small\n    if ratio >= 2:\n        args.epochs = 180\n        step_size = 60\n    else:\n        args.epochs = int(90 * ratio)\n        step_size = int(args.epochs / 3)\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    history_score = np.zeros((args.epochs + 1, 1))\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, step_size)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n        history_score[epoch] = prec1\n        np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save)\n\n    history_score[-1] = best_prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch, step_size=30):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // step_size))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/l1-norm-pruning/main_E.py,21,"b'import argparse\nimport os\nimport numpy as np\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom resnet import resnet34\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet34\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--s\', type=float, default=0,\n                    help=\'scale sparse rate (default: 0)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'the PATH to the pruned model\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    if args.scratch:\n        checkpoint = torch.load(args.scratch)\n        model = resnet34(cfg=checkpoint[\'cfg\'])\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    history_score = np.zeros((args.epochs + 1, 1))\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n        history_score[epoch] = prec1\n        np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save)\n\n    history_score[-1] = best_prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/l1-norm-pruning/main_finetune.py,21,"b'import argparse\nimport os\nimport numpy as np\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom resnet import resnet34\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet34\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=20, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.001, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--s\', type=float, default=0,\n                    help=\'scale sparse rate (default: 0)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--refine\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'the PATH to pruned model\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    if args.refine:\n        checkpoint = torch.load(args.refine)\n        model = resnet34(cfg=checkpoint[\'cfg\'])\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    if args.refine:\n        model.load_state_dict(checkpoint[\'state_dict\'])\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    history_score = np.zeros((args.epochs + 1, 1))\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n        history_score[epoch] = prec1\n        np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save)\n\n    history_score[-1] = best_prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/l1-norm-pruning/prune.py,13,"b'import argparse\nimport numpy as np\nimport os\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom resnet import resnet34\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'Pruning filters for efficient ConvNets\')\nparser.add_argument(\'--data\', type=str, default=\'/scratch/zhuangl/datasets/imagenet\',\n                    help=\'Path to imagenet validation data\')\nparser.add_argument(\'--test-batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for testing (default: 64)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: none)\')\nparser.add_argument(\'-j\', \'--workers\', default=20, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 20)\')\nparser.add_argument(\'-v\', default=\'A\', type=str, \n                    help=\'version of the pruned model\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = resnet34(pretrained=True)\nmodel = torch.nn.DataParallel(model).cuda()\ncudnn.benchmark = True\n\nprint(\'Pre-processing Successful!\')\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(os.path.join(args.data,\'val\'), transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.test_batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    model.eval()\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n    return top1.avg, top5.avg\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\nskip = {\n    \'A\': [2, 8, 14, 16, 26, 28, 30, 32],\n    \'B\': [2, 8, 14, 16, 26, 28, 30, 32],\n}\n\nprune_prob = {\n    \'A\': [0.3, 0.3, 0.3, 0.0],\n    \'B\': [0.5, 0.6, 0.4, 0.0],\n}\n\nlayer_id = 1\ncfg = []\ncfg_mask = []\nfor m in model.modules():\n    if isinstance(m, nn.Conv2d):\n        if m.kernel_size == (1,1):\n            continue\n        out_channels = m.weight.data.shape[0]\n        if layer_id in skip[args.v]:\n            cfg_mask.append(torch.ones(out_channels))\n            cfg.append(out_channels)\n            layer_id += 1\n            continue\n        if layer_id % 2 == 0:\n            if layer_id <= 6:\n                stage = 0\n            elif layer_id <= 14:\n                stage = 1\n            elif layer_id <= 26:\n                stage = 2\n            else:\n                stage = 3\n            prune_prob_stage = prune_prob[args.v][stage]\n            weight_copy = m.weight.data.abs().clone().cpu().numpy()\n            L1_norm = np.sum(weight_copy, axis=(1,2,3))\n            num_keep = int(out_channels * (1 - prune_prob_stage))\n            arg_max = np.argsort(L1_norm)\n            arg_max_rev = arg_max[::-1][:num_keep]\n            mask = torch.zeros(out_channels)\n            mask[arg_max_rev.tolist()] = 1\n            cfg_mask.append(mask)\n            cfg.append(num_keep)\n            layer_id += 1\n            continue\n        layer_id += 1\n\nassert len(cfg) == 16, ""Length of cfg variable is not correct.""\n\nnewmodel = resnet34(cfg=cfg)\nnewmodel = torch.nn.DataParallel(newmodel).cuda()\n\nstart_mask = torch.ones(3)\nlayer_id_in_cfg = 0\nconv_count = 1\nfor [m0, m1] in zip(model.modules(), newmodel.modules()):\n    if isinstance(m0, nn.Conv2d):\n        if m0.kernel_size == (1,1):\n            # Cases for down-sampling convolution.\n            m1.weight.data = m0.weight.data.clone()\n            continue\n        if conv_count == 1:\n            m1.weight.data = m0.weight.data.clone()\n            conv_count += 1\n            continue\n        if conv_count % 2 == 0:\n            mask = cfg_mask[layer_id_in_cfg]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            w = m0.weight.data[idx.tolist(), :, :, :].clone()\n            m1.weight.data = w.clone()\n            layer_id_in_cfg += 1\n            conv_count += 1\n            continue\n        if conv_count % 2 == 1:\n            mask = cfg_mask[layer_id_in_cfg-1]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            w = m0.weight.data[:, idx.tolist(), :, :].clone()\n            m1.weight.data = w.clone()\n            conv_count += 1\n            continue\n    elif isinstance(m0, nn.BatchNorm2d):\n        assert isinstance(m1, nn.BatchNorm2d), ""There should not be bn layer here.""\n        if conv_count % 2 == 1:\n            mask = cfg_mask[layer_id_in_cfg-1]\n            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n            if idx.size == 1:\n                idx = np.resize(idx, (1,))\n            m1.weight.data = m0.weight.data[idx.tolist()].clone()\n            m1.bias.data = m0.bias.data[idx.tolist()].clone()\n            m1.running_mean = m0.running_mean[idx.tolist()].clone()\n            m1.running_var = m0.running_var[idx.tolist()].clone()\n            continue\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n        m1.running_mean = m0.running_mean.clone()\n        m1.running_var = m0.running_var.clone()\n    elif isinstance(m0, nn.Linear):\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n\ntorch.save({\'cfg\': cfg, \'state_dict\': newmodel.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\n\nacc_top1, acc_top5 = test(model)\nnew_acc_top1, new_acc_top5 = test(newmodel)\nnum_parameters1 = sum([param.nelement() for param in model.parameters()])\nnum_parameters2 = sum([param.nelement() for param in newmodel.parameters()])\nwith open(os.path.join(args.save, ""prune.txt""), ""w"") as fp:\n    fp.write(""Before pruning: ""+""\\n"")\n    fp.write(""acc@1: ""+str(acc_top1)+""\\n""+""acc@5: ""+str(acc_top5)+""\\n"")\n    fp.write(""Number of parameters: \\n""+str(num_parameters1)+""\\n"")\n    fp.write(""==========================================\\n"")\n    fp.write(""After pruning: ""+""\\n"")\n    fp.write(""cfg :""+""\\n"")\n    fp.write(str(cfg)+""\\n"")\n    fp.write(""acc@1: ""+str(new_acc_top1)+""\\n""+""acc@5: ""+str(new_acc_top5)+""\\n"")\n    fp.write(""Number of parameters: \\n""+str(num_parameters2)+""\\n"")'"
imagenet/l1-norm-pruning/resnet.py,4,"b'import math\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\n\nmodel_urls = {\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n}\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None):\n        # cfg should be a number in this case\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, cfg, stride)\n        self.bn1 = nn.BatchNorm2d(cfg)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(cfg, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, cfg=None, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        if cfg == None:\n            cfg = [[64] * layers[0], [128]*layers[1], [256]*layers[2], [512]*layers[3]]\n            cfg = [item for sub_list in cfg for item in sub_list]\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        count = 0\n        self.layer1 = self._make_layer(block, 64, layers[0], cfg[:layers[0]])\n        count += layers[0]\n        self.layer2 = self._make_layer(block, 128, layers[1], cfg[count:count+layers[1]], stride=2)\n        count += layers[1]\n        self.layer3 = self._make_layer(block, 256, layers[2], cfg[count:count+layers[2]], stride=2)\n        count += layers[2]\n        self.layer4 = self._make_layer(block, 512, layers[3], cfg[count:count+layers[3]], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n        self.fc = nn.Linear(cfg[-1], num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, cfg, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, cfg[0],stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, cfg[i]))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ndef resnet34(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model'"
imagenet/network-slimming/compute_flops.py,10,"b""# Code from https://github.com/simochen/model-tools.\nimport numpy as np\nimport os\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef print_model_param_nums(model=None):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n    print('  + Number of params: %.2fM' % (total / 1e6))\n\ndef count_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2['names'] = np.prod(input[0].shape)\n\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n        # flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        num_weight_params = (self.weight.data != 0).float().sum()\n        flops = (num_weight_params * (2 if multiply_adds else 1) + bias_ops * output_channels) * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    # input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True)\n    input = Variable(torch.rand(3,3,input_res,input_res), requires_grad = True)\n    out = model(input)\n\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print('  + Number of FLOPs: %.2fG' % (total_flops / 1e9))\n\n    return total_flops\n"""
imagenet/network-slimming/main.py,21,"b'import argparse\nimport numpy as np\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom vgg import slimmingvgg as vgg11\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--s\', type=float, default=0,\n                    help=\'scale sparse rate (default: 0)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save model (default: current directory)\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n    print(args)\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    model = vgg11()\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, args.s)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save)\n\ndef updateBN(model, sparsity):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n            m.weight.grad.data.add_(sparsity * torch.sign(m.weight.data))\n\ndef BN_grad_zero(model):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n            mask = (m.weight.data != 0)\n            mask = mask.float().cuda()\n            m.weight.grad.data.mul_(mask)\n            m.bias.grad.data.mul_(mask)\n\ndef train(train_loader, model, criterion, optimizer, epoch, sparsity=0):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        if sparsity != 0:\n            updateBN(model, sparsity)\n        BN_grad_zero(model)\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath, name=\'checkpoint.pth.tar\'):\n    torch.save(state, os.path.join(filepath, name))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, name), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/network-slimming/main_B.py,22,"b'import argparse\nimport numpy as np\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom vgg import slimmingvgg as vgg11\nfrom compute_flops import count_model_param_flops\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--s\', type=float, default=0,\n                    help=\'scale sparse rate (default: 0)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save model (default: current directory)\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'the PATH to the pruned model\')\n\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n    print(args)\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    model = vgg11()\n\n    if args.scratch:\n        checkpoint = torch.load(args.scratch)\n        model = vgg11(pretrained=False, config=checkpoint[\'cfg\'])\n        model_ref = vgg11()\n\n        flops_std = count_model_param_flops(model_ref, 224)\n        flops_small = count_model_param_flops(model, 224)\n        args.epochs = int(90 * (flops_std / flops_small))\n        step_size = int(args.epochs / 3)\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, step_size)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, args.s)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save)\n\ndef updateBN(model, sparsity):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n            m.weight.grad.data.add_(sparsity * torch.sign(m.weight.data))\n\ndef BN_grad_zero(model):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n            mask = (m.weight.data != 0)\n            mask = mask.float().cuda()\n            m.weight.grad.data.mul_(mask)\n            m.bias.grad.data.mul_(mask)\n\ndef train(train_loader, model, criterion, optimizer, epoch, sparsity=0):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        if sparsity != 0:\n            updateBN(model, sparsity)\n        BN_grad_zero(model)\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath, name=\'checkpoint.pth.tar\'):\n    torch.save(state, os.path.join(filepath, name))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, name), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch, step_size=30):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // step_size))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/network-slimming/main_E.py,22,"b'import argparse\nimport numpy as np\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom vgg import slimmingvgg as vgg11\nfrom compute_flops import count_model_param_flops\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--s\', type=float, default=0,\n                    help=\'scale sparse rate (default: 0)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save model (default: current directory)\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'the PATH to the pruned model\')\n\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n    print(args)\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    model = vgg11()\n\n    if args.scratch:\n        checkpoint = torch.load(args.scratch)\n        model = vgg11(pretrained=False, config=checkpoint[\'cfg\'])\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, step_size)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, args.s)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save)\n\ndef updateBN(model, sparsity):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n            m.weight.grad.data.add_(sparsity * torch.sign(m.weight.data))\n\ndef BN_grad_zero(model):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n            mask = (m.weight.data != 0)\n            mask = mask.float().cuda()\n            m.weight.grad.data.mul_(mask)\n            m.bias.grad.data.mul_(mask)\n\ndef train(train_loader, model, criterion, optimizer, epoch, sparsity=0):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        if sparsity != 0:\n            updateBN(model, sparsity)\n        BN_grad_zero(model)\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath, name=\'checkpoint.pth.tar\'):\n    torch.save(state, os.path.join(filepath, name))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, name), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch, step_size=30):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // step_size))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/network-slimming/main_finetune.py,22,"b'import argparse\nimport numpy as np\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom vgg import slimmingvgg as vgg11\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=5, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.001, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--s\', type=float, default=0,\n                    help=\'scale sparse rate (default: 0)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save model (default: current directory)\')\nparser.add_argument(\'--refine\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n    print(args)\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    model = vgg11()\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    if args.refine:\n        checkpoint = torch.load(args.refine)\n        model.load_state_dict(checkpoint[\'state_dict\'])\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, args.s)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save)\n\ndef updateBN(model, sparsity):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n            m.weight.grad.data.add_(sparsity * torch.sign(m.weight.data))\n\ndef BN_grad_zero(model):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n            mask = (m.weight.data != 0)\n            mask = mask.float().cuda()\n            m.weight.grad.data.mul_(mask)\n            m.bias.grad.data.mul_(mask)\n\ndef train(train_loader, model, criterion, optimizer, epoch, sparsity=0):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        if sparsity != 0:\n            updateBN(model, sparsity)\n        BN_grad_zero(model)\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath, name=\'checkpoint.pth.tar\'):\n    torch.save(state, os.path.join(filepath, name))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, name), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/network-slimming/prune.py,14,"b'import argparse\nimport numpy as np\nimport os\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom vgg import slimmingvgg as vgg11\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming Imagenet prune\')\nparser.add_argument(\'--data\', type=str, default=\'\',\n                    help=\'Path to imagenet validation data\')\nparser.add_argument(\'--test-batch-size\', type=int, default=16, metavar=\'N\',\n                    help=\'input batch size for testing (default: 64)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--percent\', type=float, default=0.5,\n                    help=\'scale sparse rate (default: 0.5)\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to raw trained model (default: none)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: none)\')\nparser.add_argument(\'-j\', \'--workers\', default=20, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 20)\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = vgg11()\nmodel.features = nn.DataParallel(model.features)\ncudnn.benchmark = True\n\nif args.cuda:\n    model.cuda()\n\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(model)\ntotal = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n        total += m.weight.data.shape[0]\n\nbn = torch.zeros(total)\nindex = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n        size = m.weight.data.shape[0]\n        bn[index:(index+size)] = m.weight.data.abs().clone()\n        index += size\n\ny, i = torch.sort(bn)\nthre_index = int(total * args.percent)\nthre = y[thre_index]\n\npruned = 0\ncfg = []\ncfg_mask = []\nfor k, m in enumerate(model.modules()):\n    if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n        weight_copy = m.weight.data.abs().clone()\n        mask = weight_copy.gt(thre)\n        mask = mask.float().cuda()\n        pruned = pruned + mask.shape[0] - torch.sum(mask)\n        m.weight.data.mul_(mask)\n        m.bias.data.mul_(mask)\n        cfg.append(int(torch.sum(mask)))\n        cfg_mask.append(mask.clone())\n        print(\'layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}\'.\n            format(k, mask.shape[0], int(torch.sum(mask))))\n    elif isinstance(m, nn.MaxPool2d):\n        cfg.append(\'M\')\n\ntorch.save({\'cfg\': cfg, \'state_dict\': model.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\n\npruned_ratio = pruned/total\n\nprint(\'Pre-processing Successful!\')\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test():\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(os.path.join(args.data,\'val\'), transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.test_batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    model.eval()\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n    return top1.avg, top5.avg\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\nacc = test()\n\nprint(cfg)\nprint(""Accuracy after pruning top1: %f top5: %f""%(acc[0], acc[1]))\n'"
imagenet/network-slimming/vgg.py,3,"b'import math\n\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\n\n\n__all__ = [\n    \'slimmingvgg\',\n]\n\nmodel_urls = {\n    \'vgg11_bn\': \'https://download.pytorch.org/models/vgg11_bn-6002323d.pth\',\n}\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, cfg, num_classes=1000, init_weights=True):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(cfg[0] * 7 * 7, cfg[1]),\n            nn.BatchNorm1d(cfg[1]),\n            nn.ReLU(True),\n            nn.Linear(cfg[1],cfg[2]),\n            nn.BatchNorm1d(cfg[2]),\n            nn.ReLU(True),\n            nn.Linear(cfg[2], num_classes)\n        )\n        if init_weights:\n            self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal(m.weight, mode=\'fan_out\')#, nonlinearity=\'relu\')\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm1d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\ncfg = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\', 4096, 4096]\n}\n\ndef slimmingvgg(pretrained=False, config=None, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    if pretrained:\n        kwargs[\'init_weights\'] = False\n    if config == None:\n        config = cfg[\'A\']\n    config2 = [config[-4],config[-2],config[-1]]\n    model = VGG(make_layers(config[:-2], batch_norm=True), config2, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg11_bn\']))\n    return model'"
imagenet/regression-pruning/compute_flops.py,9,"b""# Code from https://github.com/simochen/model-tools.\nimport numpy as np\nimport os\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef print_model_param_nums(model=None):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n    print('  + Number of params: %.4fM' % (total / 1e6))\n\ndef count_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2['names'] = np.prod(input[0].shape)\n\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n        # flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        num_weight_params = (self.weight.data != 0).float().sum()\n        flops = (num_weight_params * (2 if multiply_adds else 1) + bias_ops * output_channels) * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True)\n    out = model(input)\n\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print('  + Number of FLOPs: %.2fG' % (total_flops / 1e9))\n\n    return total_flops"""
imagenet/regression-pruning/main_B.py,20,"b'import argparse\nimport numpy as np\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom compute_flops import count_model_param_flops\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nimport models\n\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--model\',default=\'\',type=str,help=\'Model names: resnet-2x\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n    print(args)\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    #################################################################################\n    if args.model == \'resnet-2x\':\n        model = models.resnet_2x()\n        model_ref = models.resnet50_official()\n\n    if args.model == \'vgg-5x\':\n        model = models.vgg_5x()\n        model_ref = models.vgg_official()\n\n    flops_std = count_model_param_flops(model_ref, 224)\n    flops_small = count_model_param_flops(model, 224)\n    ratio = flops_std / flops_small\n    if ratio >= 2:\n        args.epochs = 180\n        step_size = 60\n    else:\n        args.epochs = int(90 * ratio)\n        step_size = int(args.epochs / 3)\n    #################################################################################\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, step_size)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save) \n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath, name=\'checkpoint.pth.tar\'):\n    torch.save(state, os.path.join(filepath, name))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, name), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch, step_size=30):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // step_size))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/regression-pruning/main_E.py,20,"b'import argparse\nimport numpy as np\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nimport models\n\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--model\',default=\'\',type=str,help=\'Model names: vgg-5x or resnet-2x\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n    print(args)\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    if args.model == \'vgg-5x\':\n        model = models.vgg_5x()\n    elif args.model == \'resnet-2x\':\n        model = models.resnet_2x()\n\n    step_size = int(args.epochs / 3.)\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, step_size)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save) \n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath, name=\'checkpoint.pth.tar\'):\n    torch.save(state, os.path.join(filepath, name))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, name), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch, step_size=30):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // step_size))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/thinet/compute_flops.py,9,"b""# Code from https://github.com/simochen/model-tools.\nimport numpy as np\nimport os\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef print_model_param_nums(model=None):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n    print('  + Number of params: %.4fM' % (total / 1e6))\n\ndef count_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2['names'] = np.prod(input[0].shape)\n\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n        # flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        num_weight_params = (self.weight.data != 0).float().sum()\n        flops = (num_weight_params * (2 if multiply_adds else 1) + bias_ops * output_channels) * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True)\n    out = model(input)\n\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print('  + Number of FLOPs: %.2fG' % (total_flops / 1e9))\n\n    return total_flops\n"""
imagenet/thinet/main_B.py,20,"b'import argparse\nimport numpy as np\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom compute_flops import count_model_param_flops\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nimport models\n\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--model\',default=\'\',type=str,help=\'Model names\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n    print(args)\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    if args.model == \'thinet-70\':\n        model = models.thinet70()\n        model_ref = models.resnet50_official()\n\n    if args.model == \'thinet-conv\':\n        model = models.thinet_conv()\n        model_ref = models.vgg_official()\n    elif args.model == \'thinet-gap\':\n        model = models.thinet_gap()\n        model_ref = models.vgg_official()\n    elif args.model == \'thinet-tiny\':\n        model = models.thinet_tiny()\n        model_ref = models.vgg_official()\n    elif args.model == \'thinet-30\':\n        model = models.thinet30()\n        model_ref = models.resnet50_official()\n    elif args.model == \'thinet-50\':\n        model = models.thinet50()\n        model_ref = models.resnet50_official()\n    elif args.model == \'thinet-70\':\n        model = models.thinet70()\n        model_ref = models.resnet50_official()\n\n    ###########################################################################################\n    flops_std = count_model_param_flops(model_ref)\n    flops_small = count_model_param_flops(model)\n    ratio = flops_std / flops_small\n    if ratio >= 2:\n        args.epochs = 180\n        stepz_size = 60\n    else:\n        args.epochs = int(90.*flops_std / flops_small)\n        step_size = int(args.epochs / 3)\n    ###########################################################################################\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, step_size)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save) \n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath, name=\'checkpoint.pth.tar\'):\n    torch.save(state, os.path.join(filepath, name))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, name), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch, step_size=30):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // step_size))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/thinet/main_E.py,20,"b'import argparse\nimport numpy as np\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nimport models\n\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--model\',default=\'\',type=str,help=\'Model names\')\nparser.add_argument(\'-j\', \'--workers\', default=25, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 25)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\n\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n    print(args)\n\n    args.distributed = args.world_size > 1\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    if args.model == \'thinet-conv\':\n        model = models.thinet_conv()\n    elif args.model == \'thinet-gap\':\n        model = models.thinet_gap()\n    elif args.model == \'thinet-tiny\':\n        model = models.thinet_tiny()\n    elif args.model == \'thinet-30\':\n        model = models.thinet30()\n    elif args.model == \'thinet-50\':\n        model = models.thinet50()\n    elif args.model == \'thinet-70\':\n        model = models.thinet70()\n\n    step_size = int(args.epochs / 3.)\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, step_size)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save) \n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filepath, name=\'checkpoint.pth.tar\'):\n    torch.save(state, os.path.join(filepath, name))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, name), os.path.join(filepath, \'model_best.pth.tar\'))\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef adjust_learning_rate(optimizer, epoch, step_size=30):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // step_size))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/weight-level/compute_flops.py,15,"b'# Code from https://github.com/simochen/model-tools.\nimport numpy as np\nimport os\nimport random\nimport shutil\nimport time\nimport warnings\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\n\ndef print_model_param_nums(model=None):\n    if model == None:\n        model = torchvision.models.alexnet()\n    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n    print(\'  + Number of params: %.2fM\' % (total / 1e6))\n\ndef count_model_param_flops(model=None, input_res=224, multiply_adds=True):\n\n    prods = {}\n    def save_hook(name):\n        def hook_per(self, input, output):\n            prods[name] = np.prod(input[0].shape)\n        return hook_per\n\n    list_1=[]\n    def simple_hook(self, input, output):\n        list_1.append(np.prod(input[0].shape))\n    list_2={}\n    def simple_hook2(self, input, output):\n        list_2[\'names\'] = np.prod(input[0].shape)\n\n\n    list_conv=[]\n    def conv_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n        bias_ops = 1 if self.bias is not None else 0\n\n        params = output_channels * (kernel_ops + bias_ops)\n\n        num_weight_params = (self.weight.data != 0).float().sum()\n        assert self.weight.numel() == kernel_ops * output_channels, ""Not match""\n        flops = (num_weight_params * (2 if multiply_adds else 1) + bias_ops * output_channels) * output_height * output_width * batch_size\n\n        list_conv.append(flops)\n\n    list_linear=[]\n    def linear_hook(self, input, output):\n        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n\n        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n        bias_ops = self.bias.nelement()\n\n        flops = batch_size * (weight_ops + bias_ops)\n        list_linear.append(flops)\n\n    list_bn=[]\n    def bn_hook(self, input, output):\n        list_bn.append(input[0].nelement() * 2)\n\n    list_relu=[]\n    def relu_hook(self, input, output):\n        list_relu.append(input[0].nelement())\n\n    list_pooling=[]\n    def pooling_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        kernel_ops = self.kernel_size * self.kernel_size\n        bias_ops = 0\n        params = 0\n        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n\n        list_pooling.append(flops)\n\n    list_upsample=[]\n    # For bilinear upsample\n    def upsample_hook(self, input, output):\n        batch_size, input_channels, input_height, input_width = input[0].size()\n        output_channels, output_height, output_width = output[0].size()\n\n        flops = output_height * output_width * output_channels * batch_size * 12\n        list_upsample.append(flops)\n\n    def foo(net):\n        childrens = list(net.children())\n        if not childrens:\n            if isinstance(net, torch.nn.Conv2d):\n                net.register_forward_hook(conv_hook)\n            if isinstance(net, torch.nn.Linear):\n                net.register_forward_hook(linear_hook)\n            if isinstance(net, torch.nn.BatchNorm2d):\n                net.register_forward_hook(bn_hook)\n            if isinstance(net, torch.nn.ReLU):\n                net.register_forward_hook(relu_hook)\n            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n                net.register_forward_hook(pooling_hook)\n            if isinstance(net, torch.nn.Upsample):\n                net.register_forward_hook(upsample_hook)\n            return\n        for c in childrens:\n            foo(c)\n\n    if model == None:\n        model = torchvision.models.alexnet()\n    foo(model)\n    input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True)\n    out = model(input)\n\n\n    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n\n    print(\'  + Number of FLOPs: %.2fG\' % (total_flops / 1e9))\n\n    return total_flops'"
imagenet/weight-level/main_B.py,23,"b'import argparse\nimport math\nimport os\nimport random\nimport shutil\nimport time\nimport warnings\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nfrom compute_flops import count_model_param_flops\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=40, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--seed\', default=None, type=int,\n                    help=\'seed for initializing training. \')\nparser.add_argument(\'--gpu\', default=None, type=int,\n                    help=\'GPU id to use.\')\nparser.add_argument(\'--percent\',default=0.1,type=float)\nparser.add_argument(\'--save\',default=\'\',type=str)\n\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n    if args.seed is not None:\n        random.seed(args.seed)\n        torch.manual_seed(args.seed)\n        cudnn.deterministic = True\n        warnings.warn(\'You have chosen to seed training. \'\n                      \'This will turn on the CUDNN deterministic setting, \'\n                      \'which can slow down your training considerably! \'\n                      \'You may see unexpected behavior when restarting \'\n                      \'from checkpoints.\')\n\n    if args.gpu is not None:\n        warnings.warn(\'You have chosen a specific GPU. This will completely \'\n                      \'disable data parallelism.\')\n\n    if not os.path.exists(args.save):\n        os.maskdit(args.save)\n\n    args.distributed = args.world_size > 1\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    # create model\n    if args.pretrained:\n        print(""=> using pre-trained model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch](pretrained=True)\n        model_ref = models.__dict__[args.arch](pretrained=True)\n    else:\n        print(""=> creating model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch]()\n        model_ref = models.__dict__[args.arch]()\n\n    ######################################################################################################\n    flops_std = count_model_param_flops(model)\n    flops_small = count_model_param_flops(model_ref)\n    args.epochs = int(90 * flops_std / flops_small)\n    step_size = int(args.epochs / 3)\n    print(""Scratch-B training total epochs %d""%args.epochs)\n    ######################################################################################################\n\n    if args.gpu is not None:\n        model = model.cuda(args.gpu)\n        model_ref = model_ref.cuda(args.gpu)\n    elif args.distributed:\n        model.cuda()\n        model_ref.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n        model_ref = torch.nn.parallel.DistributedDataParallel(model_ref)\n    else:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model_ref.features = torch.nn.DataParallel(model_ref.features)\n            model.cuda()\n            model_ref.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n            model_ref = torch.nn.DataParallel(model_ref).cuda()\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            model_ref.load_state_dict(checkpoint[\'state_dict\'])\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    # set some weights to zero, according to model_ref ---------------------------------\n    for m, m_ref in zip(model.modules(), model_ref.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m_ref.weight.data.abs().clone()\n            mask = weight_copy.gt(0).float().cuda()\n            n = mask.sum() / float(m.in_channels)\n            m.weight.data.normal_(0, math.sqrt(2. / n))\n            m.weight.data.mul_(mask)\n    # ----------------------------------------------------------------------------------\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, step_size)\n\n        #####################################################################################################\n        num_parameters = get_conv_zero_param(model)\n        print(\'Zero parameters: {}\'.format(num_parameters))\n        num_parameters = sum([param.nelement() for param in model.parameters()])\n        print(\'Parameters: {}\'.format(num_parameters))\n        #####################################################################################################\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best,checkpoint=args.save)\n    return\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.gpu is not None:\n            input = input.cuda(args.gpu, non_blocking=True)\n        target = target.cuda(args.gpu, non_blocking=True)\n\n        # compute output\n        output = model(input)\n        loss = criterion(output, target)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n        losses.update(loss.item(), input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            # print(k, m)\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef adjust_learning_rate(optimizer, epoch, step_size = 30):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // step_size))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        end = time.time()\n        for i, (input, target) in enumerate(val_loader):\n            if args.gpu is not None:\n                input = input.cuda(args.gpu, non_blocking=True)\n            target = target.cuda(args.gpu, non_blocking=True)\n\n            # compute output\n            output = model(input)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n            losses.update(loss.item(), input.size(0))\n            top1.update(prec1[0], input.size(0))\n            top5.update(prec5[0], input.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % args.print_freq == 0:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                       i, len(val_loader), batch_time=batch_time, loss=losses,\n                       top1=top1, top5=top5))\n\n        print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n              .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'scratch.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\nif __name__ == \'__main__\':\n    main()\n'"
imagenet/weight-level/main_E.py,23,"b'import argparse\nimport math\nimport os\nimport random\nimport shutil\nimport time\nimport warnings\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=40, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--seed\', default=None, type=int,\n                    help=\'seed for initializing training. \')\nparser.add_argument(\'--gpu\', default=None, type=int,\n                    help=\'GPU id to use.\')\nparser.add_argument(\'--percent\',default=0.1,type=float)\nparser.add_argument(\'--save\',default=\'\',type=str)\n\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n    if args.seed is not None:\n        random.seed(args.seed)\n        torch.manual_seed(args.seed)\n        cudnn.deterministic = True\n        warnings.warn(\'You have chosen to seed training. \'\n                      \'This will turn on the CUDNN deterministic setting, \'\n                      \'which can slow down your training considerably! \'\n                      \'You may see unexpected behavior when restarting \'\n                      \'from checkpoints.\')\n\n    if args.gpu is not None:\n        warnings.warn(\'You have chosen a specific GPU. This will completely \'\n                      \'disable data parallelism.\')\n\n    if not os.path.exists(args.save):\n        os.maskdit(args.save)\n\n    args.distributed = args.world_size > 1\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    # create model\n    if args.pretrained:\n        print(""=> using pre-trained model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch](pretrained=True)\n        model_ref = models.__dict__[args.arch](pretrained=True)\n    else:\n        print(""=> creating model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch]()\n        model_ref = models.__dict__[args.arch]()\n\n    if args.gpu is not None:\n        model = model.cuda(args.gpu)\n        model_ref = model_ref.cuda(args.gpu)\n    elif args.distributed:\n        model.cuda()\n        model_ref.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n        model_ref = torch.nn.parallel.DistributedDataParallel(model_ref)\n    else:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model_ref.features = torch.nn.DataParallel(model_ref.features)\n            model.cuda()\n            model_ref.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n            model_ref = torch.nn.DataParallel(model_ref).cuda()\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            model_ref.load_state_dict(checkpoint[\'state_dict\'])\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    # set some weights to zero, according to model_ref ---------------------------------\n    for m, m_ref in zip(model.modules(), model_ref.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m_ref.weight.data.abs().clone()\n            mask = weight_copy.gt(0).float().cuda()\n            n = mask.sum() / float(m.in_channels)\n            m.weight.data.normal_(0, math.sqrt(2. / n))\n            m.weight.data.mul_(mask)\n    # ----------------------------------------------------------------------------------\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch)\n\n        #####################################################################################################\n        num_parameters = get_conv_zero_param(model)\n        print(\'Zero parameters: {}\'.format(num_parameters))\n        num_parameters = sum([param.nelement() for param in model.parameters()])\n        print(\'Parameters: {}\'.format(num_parameters))\n        #####################################################################################################\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best,checkpoint=args.save)\n    return\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.gpu is not None:\n            input = input.cuda(args.gpu, non_blocking=True)\n        target = target.cuda(args.gpu, non_blocking=True)\n\n        # compute output\n        output = model(input)\n        loss = criterion(output, target)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n        losses.update(loss.item(), input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            # print(k, m)\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        end = time.time()\n        for i, (input, target) in enumerate(val_loader):\n            if args.gpu is not None:\n                input = input.cuda(args.gpu, non_blocking=True)\n            target = target.cuda(args.gpu, non_blocking=True)\n\n            # compute output\n            output = model(input)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n            losses.update(loss.item(), input.size(0))\n            top1.update(prec1[0], input.size(0))\n            top5.update(prec5[0], input.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % args.print_freq == 0:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                       i, len(val_loader), batch_time=batch_time, loss=losses,\n                       top1=top1, top5=top5))\n\n        print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n              .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'scratch.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\nif __name__ == \'__main__\':\n    main()\n'"
imagenet/weight-level/main_finetune.py,20,"b'import argparse\nimport os\nimport random\nimport shutil\nimport time\nimport warnings\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=40, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=10, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.001, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--seed\', default=None, type=int,\n                    help=\'seed for initializing training. \')\nparser.add_argument(\'--gpu\', default=None, type=int,\n                    help=\'GPU id to use.\')\nparser.add_argument(\'--percent\',default=0.1,type=float)\nparser.add_argument(\'--save\',default=\'\',type=str)\n\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n    if args.seed is not None:\n        random.seed(args.seed)\n        torch.manual_seed(args.seed)\n        cudnn.deterministic = True\n        warnings.warn(\'You have chosen to seed training. \'\n                      \'This will turn on the CUDNN deterministic setting, \'\n                      \'which can slow down your training considerably! \'\n                      \'You may see unexpected behavior when restarting \'\n                      \'from checkpoints.\')\n\n    if args.gpu is not None:\n        warnings.warn(\'You have chosen a specific GPU. This will completely \'\n                      \'disable data parallelism.\')\n\n    if not os.path.exists(args.save):\n        os.makedirs(args.save)\n\n    args.distributed = args.world_size > 1\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    # create model\n    if args.pretrained:\n        print(""=> using pre-trained model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch](pretrained=True)\n    else:\n        print(""=> creating model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch]()\n\n    if args.gpu is not None:\n        model = model.cuda(args.gpu)\n    elif args.distributed:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n    else:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            model.load_state_dict(checkpoint[\'state_dict\'])\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch)\n\n        #####################################################################################################\n        num_parameters = get_conv_zero_param(model)\n        print(\'Zero parameters: {}\'.format(num_parameters))\n        num_parameters = sum([param.nelement() for param in model.parameters()])\n        print(\'Parameters: {}\'.format(num_parameters))\n        #####################################################################################################\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best,checkpoint=args.save)\n    return\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.gpu is not None:\n            input = input.cuda(args.gpu, non_blocking=True)\n        target = target.cuda(args.gpu, non_blocking=True)\n\n        # compute output\n        output = model(input)\n        loss = criterion(output, target)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n        losses.update(loss.item(), input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            # print(k, m)\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        end = time.time()\n        for i, (input, target) in enumerate(val_loader):\n            if args.gpu is not None:\n                input = input.cuda(args.gpu, non_blocking=True)\n            target = target.cuda(args.gpu, non_blocking=True)\n\n            # compute output\n            output = model(input)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n            losses.update(loss.item(), input.size(0))\n            top1.update(prec1[0], input.size(0))\n            top5.update(prec5[0], input.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % args.print_freq == 0:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                       i, len(val_loader), batch_time=batch_time, loss=losses,\n                       top1=top1, top5=top5))\n\n        print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n              .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'scratch.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\nif __name__ == \'__main__\':\n    main()'"
imagenet/weight-level/prune.py,21,"b'import argparse\nimport os\nimport random\nimport shutil\nimport time\nimport warnings\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--seed\', default=None, type=int,\n                    help=\'seed for initializing training. \')\nparser.add_argument(\'--gpu\', default=None, type=int,\n                    help=\'GPU id to use.\')\nparser.add_argument(\'--percent\',default=0.1,type=float)\nparser.add_argument(\'--save\',default=\'\',type=str)\n\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n    if args.seed is not None:\n        random.seed(args.seed)\n        torch.manual_seed(args.seed)\n        cudnn.deterministic = True\n        warnings.warn(\'You have chosen to seed training. \'\n                      \'This will turn on the CUDNN deterministic setting, \'\n                      \'which can slow down your training considerably! \'\n                      \'You may see unexpected behavior when restarting \'\n                      \'from checkpoints.\')\n\n    if args.gpu is not None:\n        warnings.warn(\'You have chosen a specific GPU. This will completely \'\n                      \'disable data parallelism.\')\n\n    if not os.path.exists(args.save):\n        os.mkdir(args.save)\n\n    args.distributed = args.world_size > 1\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    # create model\n    if args.pretrained:\n        print(""=> using pre-trained model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch](pretrained=True)\n    else:\n        print(""=> creating model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch]()\n\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Resuming from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        checkpoint = torch.load(args.resume)\n        model.load_state_dict(checkpoint)\n\n    if args.gpu is not None:\n        model = model.cuda(args.gpu)\n    elif args.distributed:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n    else:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n\n    test_acc0 = validate(val_loader, model, criterion)\n    #############################################################################################################################\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += m.weight.data.numel()\n\n    conv_weights = torch.zeros(total).cuda()\n    index = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            size = m.weight.data.numel()\n            conv_weights[index:(index+size)] = m.weight.data.view(-1).abs().clone()\n            index += size\n\n    y, i = torch.sort(conv_weights)\n    thre_index = int(total * args.percent)\n    thre = y[thre_index]\n\n    pruned = 0\n    print(\'Pruning threshold: {}\'.format(thre))\n    zero_flag = False\n    for k, m in enumerate(model.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m.weight.data.abs().clone()\n            mask = weight_copy.gt(thre).float().cuda()\n            pruned = pruned + mask.numel() - torch.sum(mask)\n            m.weight.data.mul_(mask)\n            if int(torch.sum(mask)) == 0:\n                zero_flag = True\n            print(\'layer index: {:d} \\t total params: {:d} \\t remaining params: {:d}\'.\n                format(k, mask.numel(), int(torch.sum(mask))))\n    print(\'Total conv params: {}, Pruned conv params: {}, Pruned ratio: {}\'.format(total, pruned, pruned/total))\n    ##############################################################################################################################\n    test_acc1 = validate(val_loader, model, criterion)\n\n    save_checkpoint({\n            \'epoch\': 0,\n            \'state_dict\': model.state_dict(),\n            \'acc\': test_acc1,\n            \'best_acc\': 0.,\n        }, False, checkpoint=args.save)\n\n    with open(os.path.join(args.save, \'prune.txt\'), \'w\') as f:\n        f.write(\'Before pruning: Test Acc:  %.2f\\n\' % (test_acc0))\n        f.write(\'Total conv params: {}, Pruned conv params: {}, Pruned ratio: {}\\n\'.format(total, pruned, pruned/total))\n        f.write(\'After Pruning: Test Acc:  %.2f\\n\' % (test_acc1))\n\n        if zero_flag:\n            f.write(""There exists a layer with 0 parameters left."")\n    return\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        end = time.time()\n        for i, (input, target) in enumerate(val_loader):\n            if args.gpu is not None:\n                input = input.cuda(args.gpu, non_blocking=True)\n            target = target.cuda(args.gpu, non_blocking=True)\n\n            # compute output\n            output = model(input)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n            losses.update(loss.item(), input.size(0))\n            top1.update(prec1[0], input.size(0))\n            top5.update(prec5[0], input.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % args.print_freq == 0:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                       i, len(val_loader), batch_time=batch_time, loss=losses,\n                       top1=top1, top5=top5))\n\n        print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n              .format(top1=top1, top5=top5))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'pruned.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\nif __name__ == \'__main__\':\n    main()'"
cifar/l1-norm-pruning/models/__init__.py,0,b'from __future__ import absolute_import\n\nfrom .vgg import *\nfrom .resnet import *'
cifar/l1-norm-pruning/models/resnet.py,7,"b'from __future__ import absolute_import\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom functools import partial\nfrom torch.autograd import Variable\n\n\n__all__ = [\'resnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None):\n        # cfg should be a number in this case\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, cfg, stride)\n        self.bn1 = nn.BatchNorm2d(cfg)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(cfg, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\ndef downsample_basic_block(x, planes):\n    x = nn.AvgPool2d(2,2)(x)\n    zero_pads = torch.Tensor(\n        x.size(0), planes - x.size(1), x.size(2), x.size(3)).zero_()\n    if isinstance(x.data, torch.cuda.FloatTensor):\n        zero_pads = zero_pads.cuda()\n\n    out = Variable(torch.cat([x.data, zero_pads], dim=1))\n\n    return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, depth, dataset=\'cifar10\', cfg=None):\n        super(ResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        assert (depth - 2) % 6 == 0, \'depth should be 6n+2\'\n        n = (depth - 2) // 6\n\n        block = BasicBlock\n        if cfg == None:\n            cfg = [[16]*n, [32]*n, [64]*n]\n            cfg = [item for sub_list in cfg for item in sub_list]\n\n        self.cfg = cfg\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(block, 16, n, cfg=cfg[0:n])\n        self.layer2 = self._make_layer(block, 32, n, cfg=cfg[n:2*n], stride=2)\n        self.layer3 = self._make_layer(block, 64, n, cfg=cfg[2*n:3*n], stride=2)\n        self.avgpool = nn.AvgPool2d(8)\n        if dataset == \'cifar10\':\n            num_classes = 10\n        elif dataset == \'cifar100\':\n            num_classes = 100\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, cfg, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = partial(downsample_basic_block, planes=planes*block.expansion)\n\n        layers = []\n        layers.append(block(self.inplanes, planes, cfg[0], stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, cfg[i]))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)    # 32x32\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ndef resnet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return ResNet(**kwargs)\n\nif __name__ == \'__main__\':\n    net = resnet(depth=56)\n    x=Variable(torch.FloatTensor(16, 3, 32, 32))\n    y = net(x)\n    print(y.data.shape)'"
cifar/l1-norm-pruning/models/vgg.py,3,"b""import math\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\n__all__ = ['vgg']\n\ndefaultcfg = {\n    11 : [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n    13 : [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n    16 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n    19 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n}\n\nclass vgg(nn.Module):\n    def __init__(self, dataset='cifar10', depth=19, init_weights=True, cfg=None):\n        super(vgg, self).__init__()\n        if cfg is None:\n            cfg = defaultcfg[depth]\n\n        self.cfg = cfg\n\n        self.feature = self.make_layers(cfg, True)\n\n        if dataset == 'cifar10':\n            num_classes = 10\n        elif dataset == 'cifar100':\n            num_classes = 100\n        self.classifier = nn.Sequential(\n              nn.Linear(cfg[-1], 512),\n              nn.BatchNorm1d(512),\n              nn.ReLU(inplace=True),\n              nn.Linear(512, num_classes)\n            )\n        if init_weights:\n            self._initialize_weights()\n\n    def make_layers(self, cfg, batch_norm=False):\n        layers = []\n        in_channels = 3\n        for v in cfg:\n            if v == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.feature(x)\n        x = nn.AvgPool2d(2)(x)\n        x = x.view(x.size(0), -1)\n        y = self.classifier(x)\n        return y\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\nif __name__ == '__main__':\n    net = vgg()\n    x = Variable(torch.FloatTensor(16, 3, 40, 40))\n    y = net(x)\n    print(y.data.shape)"""
cifar/lottery-ticket/l1-norm-pruning/lottery_res110prune.py,9,"b'import os\nimport argparse\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=110,\n                    help=\'depth of the resnet\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\nparser.add_argument(\'-v\', default=\'A\', type=str, \n                    help=\'version of the model\')\nparser.add_argument(\'--prune\', default=\'large\', type=str,\n                    help=\'prune method to use\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = resnet(depth=args.depth, dataset=args.dataset)\n\nif args.cuda:\n    model.cuda()\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\n\nskip = {\n    \'A\': [36],\n    \'B\': [36, 38, 74],\n}\n\nprune_prob = {\n    \'A\': [0.5, 0.0, 0.0],\n    \'B\': [0.5, 0.4, 0.3],\n}\n\nlayer_id = 1\ncfg = []\ncfg_mask = []\nfor m in model.modules():\n    if isinstance(m, nn.Conv2d):\n        out_channels = m.weight.data.shape[0]\n        if layer_id in skip[args.v]:\n            cfg_mask.append(torch.ones(out_channels))\n            cfg.append(out_channels)\n            layer_id += 1\n            continue\n        if layer_id % 2 == 0:\n            stage = layer_id // 36\n            if layer_id <= 36:\n                stage = 0\n            elif layer_id <= 72:\n                stage = 1\n            elif layer_id <= 108:\n                stage = 2\n            prune_prob_stage = prune_prob[args.v][stage]\n            weight_copy = m.weight.data.abs().clone().cpu().numpy()\n            L1_norm = np.sum(weight_copy, axis=(1,2,3))\n            num_keep = int(out_channels * (1 - prune_prob_stage))\n            arg_max = np.argsort(L1_norm)\n            # arg_max_rev = arg_max[::-1][:num_keep]\n            if args.prune == \'large\':\n                arg_max_rev = arg_max[::-1][:num_keep]\n            elif args.prune == \'small\':\n                arg_max_rev = arg_max[:num_keep]\n            elif args.prune == \'random\':\n                arg_max_rev = np.random.choice(arg_max, num_keep, replace=False)\n            mask = torch.zeros(out_channels)\n            mask[arg_max_rev.tolist()] = 1\n\n            mask_neg = np.ones(out_channels)\n            mask_neg[arg_max_rev.tolist()] = 0\n            m.weight.data[mask_neg,:,:,:] = 0\n\n            cfg_mask.append(mask)\n            cfg.append(num_keep)\n            layer_id += 1\n            continue\n        layer_id += 1\n\ntorch.save({\'cfg\': cfg, \'state_dict\': model.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\nacc = test(model)\n\nnum_parameters = sum([param.nelement() for param in model.parameters()])\nwith open(os.path.join(args.save, ""prune.txt""), ""w"") as fp:\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc)+""\\n"")'"
cifar/lottery-ticket/l1-norm-pruning/lottery_resprune.py,9,"b'import os\nimport argparse\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=56,\n                    help=\'depth of the resnet\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\nparser.add_argument(\'-v\', default=\'A\', type=str, \n                    help=\'version of the model\')\nparser.add_argument(\'--prune\', default=\'large\', type=str,\n                    help=\'prune method to use\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = resnet(depth=args.depth, dataset=args.dataset)\n\nif args.cuda:\n    model.cuda()\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\n\nskip = {\n    \'A\': [16, 20, 38, 54],\n    \'B\': [16, 18, 20, 34, 38, 54],\n}\n\nprune_prob = {\n    \'A\': [0.1, 0.1, 0.1],\n    \'B\': [0.6, 0.3, 0.1],\n}\n\nlayer_id = 1\ncfg = []\ncfg_mask = []\nfor m in model.modules():\n    if isinstance(m, nn.Conv2d):\n        out_channels = m.weight.data.shape[0]\n        if layer_id in skip[args.v]:\n            cfg_mask.append(torch.ones(out_channels))\n            cfg.append(out_channels)\n            layer_id += 1\n            continue\n        if layer_id % 2 == 0:\n            if layer_id <= 18:\n                stage = 0\n            elif layer_id <= 36:\n                stage = 1\n            else:\n                stage = 2\n            prune_prob_stage = prune_prob[args.v][stage]\n            weight_copy = m.weight.data.abs().clone().cpu().numpy()\n            L1_norm = np.sum(weight_copy, axis=(1,2,3))\n            num_keep = int(out_channels * (1 - prune_prob_stage))\n            arg_max = np.argsort(L1_norm)\n            if args.prune == \'large\':\n                arg_max_rev = arg_max[::-1][:num_keep]\n            elif args.prune == \'small\':\n                arg_max_rev = arg_max[:num_keep]\n            elif args.prune == \'random\':\n                arg_max_rev = np.random.choice(arg_max, num_keep, replace=False)\n            mask = torch.zeros(out_channels)\n            mask[arg_max_rev.tolist()] = 1\n\n            mask_neg = np.ones(out_channels)\n            mask_neg[arg_max_rev.tolist()] = 0\n            m.weight.data[mask_neg,:,:,:] = 0\n\n            cfg_mask.append(mask)\n            cfg.append(num_keep)\n            layer_id += 1\n            continue\n        layer_id += 1\n\ntorch.save({\'cfg\': cfg, \'state_dict\': model.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\nacc = test(model)\n\nnum_parameters = sum([param.nelement() for param in model.parameters()])\nwith open(os.path.join(args.save, ""prune.txt""), ""w"") as fp:\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc)+""\\n"")'"
cifar/lottery-ticket/l1-norm-pruning/lottery_vggprune.py,9,"b'import os\nimport argparse\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=16,\n                    help=\'depth of the vgg\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\nparser.add_argument(\'--prune\', default=\'large\', type=str,\n                    help=\'prune method to use\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = vgg(dataset=args.dataset, depth=args.depth)\n\nif args.cuda:\n    model.cuda()\n\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\ncfg = [32, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 256, 256, 256, \'M\', 256, 256, 256]\n\ncfg_mask = []\nlayer_id = 0\nfor m in model.modules():\n    if isinstance(m, nn.Conv2d):\n        out_channels = m.weight.data.shape[0]\n        if out_channels == cfg[layer_id]:\n            cfg_mask.append(torch.ones(out_channels))\n            layer_id += 1\n            continue\n        weight_copy = m.weight.data.abs().clone()\n        weight_copy = weight_copy.cpu().numpy()\n        L1_norm = np.sum(weight_copy, axis=(1, 2, 3))\n        arg_max = np.argsort(L1_norm)\n        if args.prune == \'large\':\n            arg_max_rev = arg_max[::-1][:cfg[layer_id]]\n        elif args.prune == \'small\':\n            arg_max_rev = arg_max[:cfg[layer_id]]\n        elif args.prune == \'random\':\n            arg_max_rev = np.random.choice(arg_max, cfg[layer_id], replace=False)\n        assert arg_max_rev.size == cfg[layer_id], ""size of arg_max_rev not correct""\n        mask = torch.zeros(out_channels)\n        mask[arg_max_rev.tolist()] = 1\n\n        mask_neg = np.ones(out_channels)\n        mask_neg[arg_max_rev.tolist()] = 0\n        m.weight.data[mask_neg,:,:,:] = 0\n\n        cfg_mask.append(mask)\n        layer_id += 1\n    elif isinstance(m, nn.MaxPool2d):\n        layer_id += 1\n\ntorch.save({\'cfg\': cfg, \'state_dict\': model.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\nacc = test(model)\n\nnum_parameters = sum([param.nelement() for param in model.parameters()])\nwith open(os.path.join(args.save, ""prune.txt""), ""w"") as fp:\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc)+""\\n"")'"
cifar/lottery-ticket/l1-norm-pruning/main.py,17,"b'from __future__ import print_function\nimport os\nimport argparse\nimport shutil\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--sparsity-regularization\', \'-sr\', dest=\'sr\', action=\'store_true\',\n                    help=\'train with channel sparsity regularization\')\nparser.add_argument(\'--s\', type=float, default=0.0001,\n                    help=\'scale sparse rate (default: 0.0001)\')\nparser.add_argument(\'--refine\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nif args.refine:\n    checkpoint = torch.load(args.refine)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n    model.load_state_dict(checkpoint[\'state_dict\'])\nelse:\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.scratch:\n    checkpoint = torch.load(args.scratch)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nhistory_score = np.zeros((args.epochs, 3))\n\n# additional subgradient descent on the sparsity-induced penalty term\ndef updateBN():\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.weight.grad.data.add_(args.s*torch.sign(m.weight.data))  # L1\n\ndef train(epoch):\n    model.train()\n    global history_score\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        if args.sr:\n            updateBN()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n    history_score[epoch][0] = avg_loss / len(train_loader)\n    history_score[epoch][1] = train_acc / float(len(train_loader))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\ntorch.save({\'state_dict\': model.state_dict()}, os.path.join(args.save, \'init.pth.tar\'))\n\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [args.epochs*0.5, args.epochs*0.75]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n    prec1 = test()\n    history_score[epoch][2] = prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n\nprint(""Best accuracy: ""+str(best_prec1))\nhistory_score[-1][0] = best_prec1\nnp.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n'"
cifar/lottery-ticket/l1-norm-pruning/main_lottery.py,17,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--sparsity-regularization\', \'-sr\', dest=\'sr\', action=\'store_true\',\n                    help=\'train with channel sparsity regularization\')\nparser.add_argument(\'--s\', type=float, default=0.0001,\n                    help=\'scale sparse rate (default: 0.0001)\')\nparser.add_argument(\'--refine\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\nparser.add_argument(\'--model\', default=\'\', type=str)\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\nmodel_ref = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.cuda:\n    model.cuda()\n    model_ref.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        model_ref.load_state_dict(checkpoint[\'state_dict\'])\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nif args.model:\n    checkpoint = torch.load(args.model)\n    model.load_state_dict(checkpoint[\'state_dict\'])\n\nfor m, m_ref in zip(model.modules(), model_ref.modules()):\n    if isinstance(m, nn.Conv2d):\n        weight_copy = m_ref.weight.data.abs().clone()\n        mask = weight_copy.gt(0).float().cuda()\n        m.weight.data.mul_(mask)\n\nhistory_score = np.zeros((args.epochs, 3))\n\n# additional subgradient descent on the sparsity-induced penalty term\ndef updateBN():\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.weight.grad.data.add_(args.s*torch.sign(m.weight.data))  # L1\n\ndef train(epoch):\n    model.train()\n    global history_score\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            # print(k, m)\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n\n        if args.sr:\n            updateBN()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n    history_score[epoch][0] = avg_loss / len(train_loader)\n    history_score[epoch][1] = train_acc / float(len(train_loader))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\nbest_prec1 = 0.\ntorch.save({\'state_dict\': model.state_dict()}, os.path.join(args.save, \'init.pth.tar\'))\n\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [args.epochs*0.5, args.epochs*0.75]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n\n    num_parameters = get_conv_zero_param(model)\n    print(\'Zero parameters: {}\'.format(num_parameters))\n    num_parameters = sum([param.nelement() for param in model.parameters()])\n    print(\'Parameters: {}\'.format(num_parameters))\n\n    prec1 = test()\n    history_score[epoch][2] = prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n\nprint(""Best accuracy: ""+str(best_prec1))\nhistory_score[-1][0] = best_prec1\nnp.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n'"
cifar/lottery-ticket/l1-norm-pruning/main_scratch_mask.py,16,"b'from __future__ import print_function\nimport argparse\nimport math\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--sparsity-regularization\', \'-sr\', dest=\'sr\', action=\'store_true\',\n                    help=\'train with channel sparsity regularization\')\nparser.add_argument(\'--s\', type=float, default=0.0001,\n                    help=\'scale sparse rate (default: 0.0001)\')\nparser.add_argument(\'--refine\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--scratch\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\nparser.add_argument(\'--model\', default=\'\', type=str)\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data.cifar10\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data.cifar100\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\nmodel_ref = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.cuda:\n    model.cuda()\n    model_ref.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        model_ref.load_state_dict(checkpoint[\'state_dict\'])\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nfor m, m_ref in zip(model.modules(), model_ref.modules()):\n    if isinstance(m, nn.Conv2d):\n        weight_copy = m_ref.weight.data.abs().clone()\n        mask = weight_copy.gt(0).float().cuda()\n        n = mask.numel() / float(m.in_channels)\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        m.weight.data.mul_(mask)\n\nhistory_score = np.zeros((args.epochs, 3))\n\n# additional subgradient descent on the sparsity-induced penalty term\ndef updateBN():\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.weight.grad.data.add_(args.s*torch.sign(m.weight.data))  # L1\n\ndef train(epoch):\n    model.train()\n    global history_score\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            # print(k, m)\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n\n        if args.sr:\n            updateBN()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n    history_score[epoch][0] = avg_loss / len(train_loader)\n    history_score[epoch][1] = train_acc / float(len(train_loader))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\nbest_prec1 = 0.\ntorch.save({\'state_dict\': model.state_dict()}, os.path.join(args.save, \'init.pth.tar\'))\n\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [args.epochs*0.5, args.epochs*0.75]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n\n    num_parameters = get_conv_zero_param(model)\n    print(\'Zero parameters: {}\'.format(num_parameters))\n    num_parameters = sum([param.nelement() for param in model.parameters()])\n    print(\'Parameters: {}\'.format(num_parameters))\n\n    prec1 = test()\n    history_score[epoch][2] = prec1\n    np.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n\nprint(""Best accuracy: ""+str(best_prec1))\nhistory_score[-1][0] = best_prec1\nnp.savetxt(os.path.join(args.save, \'record.txt\'), history_score, fmt = \'%10.5f\', delimiter=\',\')\n'"
cifar/lottery-ticket/weight-level/cifar.py,11,"b'from __future__ import print_function\n\nimport argparse\nimport os\nimport random\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\n\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=160, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=64, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=50, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[80, 120],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\n# Checkpoints\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'results/\', type=str)\n#Device options\nparser.add_argument(\'--gpu-id\', default=\'0\', type=str,\n                    help=\'id(s) for CUDA_VISIBLE_DEVICES\')\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n\n    os.makedirs(args.save_dir, exist_ok=True)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n\n    model.cuda()\n\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Resuming from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        args.save_dir = os.path.dirname(args.resume)\n        checkpoint = torch.load(args.resume)\n        best_acc = checkpoint[\'best_acc\']\n        start_epoch = checkpoint[\'epoch\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        logger = Logger(os.path.join(args.save_dir, \'log.txt\'), title=title, resume=True)\n    else:\n        logger = Logger(os.path.join(args.save_dir, \'log.txt\'), title=title)\n        logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    if args.evaluate:\n        print(\'\\nEvaluation only\')\n        test_loss, test_acc = test(testloader, model, criterion, start_epoch, use_cuda)\n        print(\' Test Loss:  %.8f, Test Acc:  %.2f\' % (test_loss, test_acc))\n        return\n\n    save_checkpoint({\'state_dict\': model.state_dict()}, False, checkpoint=args.save_dir, filename=\'init.pth.tar\')\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n\n        train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.save_dir)\n\n    logger.close()\n\n    print(\'Best acc:\')\n    print(best_acc)\n\ndef train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(trainloader))\n    print(args)\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'checkpoint.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n    if is_best:\n        shutil.copyfile(filepath, os.path.join(checkpoint, \'model_best.pth.tar\'))\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/lottery-ticket/weight-level/cifar_prune_iterative.py,16,"b'from __future__ import print_function\n\nimport argparse\nimport os\nimport shutil\nimport time\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\n\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=300, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=128, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=100, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\n# Checkpoints\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'test_checkpoint/\', type=str)\n#Device options\nparser.add_argument(\'--gpu-id\', default=\'0\', type=str,\n                    help=\'id(s) for CUDA_VISIBLE_DEVICES\')\nparser.add_argument(\'--percent\', default=0.6, type=float)\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n    \n    os.makedirs(args.save_dir, exist_ok=True)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n\n    model.cuda()\n\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Resuming from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        checkpoint = torch.load(args.resume)\n        start_epoch = checkpoint[\'epoch\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n    else:\n        logger = Logger(os.path.join(args.save_dir, \'log.txt\'), title=title)\n        logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    print(\'\\nEvaluation only\')\n    test_loss0, test_acc0 = test(testloader, model, criterion, start_epoch, use_cuda)\n    print(\'Before pruning: Test Loss:  %.8f, Test Acc:  %.2f\' % (test_loss0, test_acc0))\n\n    # -------------------------------------------------------------\n    #pruning \n    total = 0\n    total_nonzero = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += m.weight.data.numel()\n            mask = m.weight.data.abs().clone().gt(0).float().cuda()\n            total_nonzero += torch.sum(mask)\n\n    conv_weights = torch.zeros(total)\n    index = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            size = m.weight.data.numel()\n            conv_weights[index:(index+size)] = m.weight.data.view(-1).abs().clone()\n            index += size\n\n    y, i = torch.sort(conv_weights)\n    # thre_index = int(total * args.percent)\n    thre_index = total - total_nonzero + int(total_nonzero * args.percent)\n    thre = y[int(thre_index)]\n    pruned = 0\n    print(\'Pruning threshold: {}\'.format(thre))\n    zero_flag = False\n    for k, m in enumerate(model.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m.weight.data.abs().clone()\n            mask = weight_copy.gt(thre).float().cuda()\n            pruned = pruned + mask.numel() - torch.sum(mask)\n            m.weight.data.mul_(mask)\n            if int(torch.sum(mask)) == 0:\n                zero_flag = True\n            print(\'layer index: {:d} \\t total params: {:d} \\t remaining params: {:d}\'.\n                format(k, mask.numel(), int(torch.sum(mask))))\n    print(\'Total conv params: {}, Pruned conv params: {}, Pruned ratio: {}\'.format(total, pruned, pruned/total))\n    # -------------------------------------------------------------\n\n    print(\'\\nTesting\')\n    test_loss1, test_acc1 = test(testloader, model, criterion, start_epoch, use_cuda)\n    print(\'After Pruning: Test Loss:  %.8f, Test Acc:  %.2f\' % (test_loss1, test_acc1))\n    save_checkpoint({\n            \'epoch\': 0,\n            \'state_dict\': model.state_dict(),\n            \'acc\': test_acc1,\n            \'best_acc\': 0.,\n            # \'optimizer\' : optimizer.state_dict(),\n        }, False, checkpoint=args.save_dir)\n\n    with open(os.path.join(args.save_dir, \'prune.txt\'), \'w\') as f:\n        f.write(\'Before pruning: Test Loss:  %.8f, Test Acc:  %.2f\\n\' % (test_loss0, test_acc0))\n        f.write(\'Total conv params: {}, Pruned conv params: {}, Pruned ratio: {}\\n\'.format(total, pruned, pruned/total))\n        f.write(\'After Pruning: Test Loss:  %.8f, Test Acc:  %.2f\\n\' % (test_loss1, test_acc1))\n\n        if zero_flag:\n            f.write(""There exists a layer with 0 parameters left."")\n    return\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'pruned.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/lottery-ticket/weight-level/cifar_scratch_no_longer.py,11,"b'from __future__ import print_function\n\nimport argparse\nimport math\nimport os\nimport random\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\n\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\nfrom utils.misc import get_conv_zero_param\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=160, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=64, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=50, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[80, 120],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\n# Checkpoints\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'results/\', type=str)\n#Device options\nparser.add_argument(\'--gpu-id\', default=\'0\', type=str,\n                    help=\'id(s) for CUDA_VISIBLE_DEVICES\')\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\n# Use CUDA\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 100000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n    \n    os.makedirs(args.save_dir, exist_ok=True)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n        model_ref = models.__dict__[args.arch](num_classes=num_classes)\n\n    model.cuda()\n    model_ref.cuda()\n\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay) # default is 0.001\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Getting reference model from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        # args.save_dir = os.path.dirname(args.resume)\n        checkpoint = torch.load(args.resume)\n        best_acc = checkpoint[\'best_acc\']\n        start_epoch = args.start_epoch\n        model_ref.load_state_dict(checkpoint[\'state_dict\'])\n\n    logger = Logger(os.path.join(args.save_dir, \'log_scratch.txt\'), title=title)\n    logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    # set some weights to zero, according to model_ref ---------------------------------\n    for m, m_ref in zip(model.modules(), model_ref.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m_ref.weight.data.abs().clone()\n            mask = weight_copy.gt(0).float().cuda()\n            n = mask.sum() / float(m.in_channels)\n            m.weight.data.normal_(0, math.sqrt(2. / n))\n            m.weight.data.mul_(mask)\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n        num_parameters = get_conv_zero_param(model)\n        print(\'Zero parameters: {}\'.format(num_parameters))\n        num_parameters = sum([param.nelement() for param in model.parameters()])\n        print(\'Parameters: {}\'.format(num_parameters))\n\n        train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.save_dir)\n\n    logger.close()\n\n    print(\'Best acc:\')\n    print(best_acc)\n\n\n\ndef train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(trainloader))\n    print(args)\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            # print(k, m)\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'scratch.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/lottery-ticket/weight-level/lottery_ticket.py,12,"b'from __future__ import print_function\n\nimport argparse\nimport math\nimport os\nimport random\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport models.cifar as models\n\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\nfrom utils.misc import get_conv_zero_param\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=160, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=64, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=50, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[80, 120],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\n# Checkpoints\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the initialization checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=1, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n\nparser.add_argument(\'--save_dir\', default=\'results/\', type=str)\n#Device options\nparser.add_argument(\'--gpu-id\', default=\'0\', type=str,\n                    help=\'id(s) for CUDA_VISIBLE_DEVICES\')\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 100000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n    \n    os.makedirs(args.save_dir, exist_ok=True)\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n        model_ref = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n        model_ref = models.__dict__[args.arch](num_classes=num_classes)\n\n    model.cuda()\n    model_ref.cuda()\n\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay) # default is 0.001\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Getting reference model from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        # args.save_dir = os.path.dirname(args.resume)\n        checkpoint = torch.load(args.resume)\n        best_acc = checkpoint[\'best_acc\']\n        start_epoch = args.start_epoch\n        model_ref.load_state_dict(checkpoint[\'state_dict\'])\n\n    logger = Logger(os.path.join(args.save_dir, \'log_scratch.txt\'), title=title)\n    logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n    # set some weights to zero, according to model_ref ---------------------------------\n    if args.model:\n        print(\'==> Loading init model from %s\'%args.model)\n        checkpoint = torch.load(args.model)\n        model.load_state_dict(checkpoint[\'state_dict\'])\n\n    for m, m_ref in zip(model.modules(), model_ref.modules()):\n        if isinstance(m, nn.Conv2d):\n            weight_copy = m_ref.weight.data.abs().clone()\n            mask = weight_copy.gt(0).float().cuda()\n            m.weight.data.mul_(mask)\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n        num_parameters = get_conv_zero_param(model)\n        print(\'Zero parameters: {}\'.format(num_parameters))\n        num_parameters = sum([param.nelement() for param in model.parameters()])\n        print(\'Parameters: {}\'.format(num_parameters))\n\n        train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.save_dir)\n\n    logger.close()\n\n    print(\'Best acc:\')\n    print(best_acc)\n\n\n\ndef train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(trainloader))\n    print(args)\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        for k, m in enumerate(model.modules()):\n            # print(k, m)\n            if isinstance(m, nn.Conv2d):\n                weight_copy = m.weight.data.abs().clone()\n                mask = weight_copy.gt(0).float().cuda()\n                m.weight.grad.data.mul_(mask)\n        optimizer.step()\n\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint, filename=\'scratch.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
cifar/network-slimming/models/__init__.py,0,b'from __future__ import absolute_import\n\nfrom .vgg import *\nfrom .preresnet import *\nfrom .densenet import *\nfrom .channel_selection import *'
cifar/network-slimming/models/channel_selection.py,2,"b'import numpy as np\n\nimport torch\nimport torch.nn as nn\n\n\nclass channel_selection(nn.Module):\n    """"""\n    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n    """"""\n    def __init__(self, num_channels):\n        """"""\n        Initialize the `indexes` with all one vector with the length same as the number of channels.\n        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n\t    """"""\n        super(channel_selection, self).__init__()\n        self.indexes = nn.Parameter(torch.ones(num_channels))\n\n    def forward(self, input_tensor):\n        """"""\n        Parameter\n        ---------\n        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n\t\t""""""\n        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n        if selected_index.size == 1:\n            selected_index = np.resize(selected_index, (1,)) \n        output = input_tensor[:, selected_index, :, :]\n        return output'"
cifar/network-slimming/models/densenet.py,4,"b'import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nfrom .channel_selection import channel_selection\n\n\n__all__ = [\'densenet\']\n\n""""""\ndensenet with basic block.\n""""""\n\nclass BasicBlock(nn.Module):\n    def __init__(self, inplanes, cfg, expansion=1, growthRate=12, dropRate=0):\n        super(BasicBlock, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.select = channel_selection(inplanes)\n        self.conv1 = nn.Conv2d(cfg, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.select(out)\n        out = self.relu(out)\n        out = self.conv1(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\nclass Transition(nn.Module):\n    def __init__(self, inplanes, outplanes, cfg):\n        super(Transition, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.select = channel_selection(inplanes)\n        self.conv1 = nn.Conv2d(cfg, outplanes, kernel_size=1,\n                               bias=False)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.select(out)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = F.avg_pool2d(out, 2)\n        return out\n\nclass densenet(nn.Module):\n\n    def __init__(self, depth=40, \n        dropRate=0, dataset=\'cifar10\', growthRate=12, compressionRate=1, cfg = None):\n        super(densenet, self).__init__()\n\n        assert (depth - 4) % 3 == 0, \'depth should be 3n+4\'\n        n = (depth - 4) // 3\n        block = BasicBlock\n\n        self.growthRate = growthRate\n        self.dropRate = dropRate\n\n        if cfg == None:\n            cfg = []\n            start = growthRate*2\n            for i in range(3):\n                cfg.append([start+12*i for i in range(n+1)])\n                start += growthRate*12\n            cfg = [item for sub_list in cfg for item in sub_list]\n\n        assert len(cfg) == 3*n+3, \'length of config variable cfg should be 3n+3\'\n\n        # self.inplanes is a global variable used across multiple\n        # helper functions\n        self.inplanes = growthRate * 2\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n                               bias=False)\n        self.dense1 = self._make_denseblock(block, n, cfg[0:n])\n        self.trans1 = self._make_transition(compressionRate, cfg[n])\n        self.dense2 = self._make_denseblock(block, n, cfg[n+1:2*n+1])\n        self.trans2 = self._make_transition(compressionRate, cfg[2*n+1])\n        self.dense3 = self._make_denseblock(block, n, cfg[2*n+2:3*n+2])\n        self.bn = nn.BatchNorm2d(self.inplanes)\n        self.select = channel_selection(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n\n        if dataset == \'cifar10\':\n            self.fc = nn.Linear(cfg[-1], 10)\n        elif dataset == \'cifar100\':\n            self.fc = nn.Linear(cfg[-1], 100)\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n\n    def _make_denseblock(self, block, blocks, cfg):\n        layers = []\n        assert blocks == len(cfg), \'Length of the cfg parameter is not right.\'\n        for i in range(blocks):\n            # Currently we fix the expansion ratio as the default value\n            layers.append(block(self.inplanes, cfg = cfg[i], growthRate=self.growthRate, dropRate=self.dropRate))\n            self.inplanes += self.growthRate\n\n        return nn.Sequential(*layers)\n\n    def _make_transition(self, compressionRate, cfg):\n        # cfg is a number in this case.\n        inplanes = self.inplanes\n        outplanes = int(math.floor(self.inplanes // compressionRate))\n        self.inplanes = outplanes\n        return Transition(inplanes, outplanes, cfg)\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.trans1(self.dense1(x))\n        x = self.trans2(self.dense2(x))\n        x = self.dense3(x)\n        x = self.bn(x)\n        x = self.select(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x'"
cifar/network-slimming/models/preresnet.py,1,"b'from __future__ import absolute_import\nimport math\n\nimport torch.nn as nn\n\nfrom .channel_selection import channel_selection\n\n\n__all__ = [\'resnet\']\n\n""""""\npreactivation resnet with bottleneck design.\n""""""\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.select = channel_selection(inplanes)\n        self.conv1 = nn.Conv2d(cfg[0], cfg[1], kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(cfg[1])\n        self.conv2 = nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(cfg[2])\n        self.conv3 = nn.Conv2d(cfg[2], planes * 4, kernel_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.select(out)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\nclass resnet(nn.Module):\n    def __init__(self, depth=164, dataset=\'cifar10\', cfg=None):\n        super(resnet, self).__init__()\n        assert (depth - 2) % 9 == 0, \'depth should be 9n+2\'\n\n        n = (depth - 2) // 9\n        block = Bottleneck\n\n        if cfg is None:\n            # Construct config variable.\n            cfg = [[16, 16, 16], [64, 16, 16]*(n-1), [64, 32, 32], [128, 32, 32]*(n-1), [128, 64, 64], [256, 64, 64]*(n-1), [256]]\n            cfg = [item for sub_list in cfg for item in sub_list]\n\n        self.inplanes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.layer1 = self._make_layer(block, 16, n, cfg = cfg[0:3*n])\n        self.layer2 = self._make_layer(block, 32, n, cfg = cfg[3*n:6*n], stride=2)\n        self.layer3 = self._make_layer(block, 64, n, cfg = cfg[6*n:9*n], stride=2)\n        self.bn = nn.BatchNorm2d(64 * block.expansion)\n        self.select = channel_selection(64 * block.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n\n        if dataset == \'cifar10\':\n            self.fc = nn.Linear(cfg[-1], 10)\n        elif dataset == \'cifar100\':\n            self.fc = nn.Linear(cfg[-1], 100)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, cfg, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, cfg[0:3], stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, cfg[3*i: 3*(i+1)]))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n        x = self.bn(x)\n        x = self.select(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x'"
cifar/network-slimming/models/vgg.py,3,"b""import math\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\n__all__ = ['vgg']\n\ndefaultcfg = {\n    11 : [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n    13 : [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n    16 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n    19 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n}\n\nclass vgg(nn.Module):\n    def __init__(self, dataset='cifar10', depth=19, init_weights=True, cfg=None):\n        super(vgg, self).__init__()\n        if cfg is None:\n            cfg = defaultcfg[depth]\n\n        self.feature = self.make_layers(cfg, True)\n\n        if dataset == 'cifar10':\n            num_classes = 10\n        elif dataset == 'cifar100':\n            num_classes = 100\n        self.classifier = nn.Linear(cfg[-1], num_classes)\n        if init_weights:\n            self._initialize_weights()\n\n    def make_layers(self, cfg, batch_norm=False):\n        layers = []\n        in_channels = 3\n        for v in cfg:\n            if v == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.feature(x)\n        x = nn.AvgPool2d(2)(x)\n        x = x.view(x.size(0), -1)\n        y = self.classifier(x)\n        return y\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\nif __name__ == '__main__':\n    net = vgg()\n    x = Variable(torch.FloatTensor(16, 3, 40, 40))\n    y = net(x)\n    print(y.data.shape)"""
cifar/weight-level/models/__init__.py,0,b''
cifar/weight-level/utils/__init__.py,0,"b'""""""Useful utils\n""""""\nfrom .misc import *\nfrom .logger import *\nfrom .visualize import *\nfrom .eval import *\n\n# progress bar\nimport os, sys\nsys.path.append(os.path.join(os.path.dirname(__file__), ""progress""))\nfrom progress.bar import Bar as Bar'"
cifar/weight-level/utils/eval.py,0,"b'from __future__ import print_function, absolute_import\n\n\n__all__ = [\'accuracy\']\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res'"
cifar/weight-level/utils/logger.py,0,"b'from __future__ import absolute_import\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport sys\n\n\n__all__ = [\'Logger\', \'LoggerMonitor\', \'savefig\']\n\ndef savefig(fname, dpi=None):\n    dpi = 150 if dpi == None else dpi\n    plt.savefig(fname, dpi=dpi)\n    \ndef plot_overlap(logger, names=None):\n    names = logger.names if names == None else names\n    numbers = logger.numbers\n    for _, name in enumerate(names):\n        x = np.arange(len(numbers[name]))\n        plt.plot(x, np.asarray(numbers[name]))\n    return [logger.title + \'(\' + name + \')\' for name in names]\n\nclass Logger(object):\n    \'\'\'Save training process to log file with simple plot function.\'\'\'\n    def __init__(self, fpath, title=None, resume=False): \n        self.file = None\n        self.resume = resume\n        self.title = \'\' if title == None else title\n        if fpath is not None:\n            if resume: \n                self.file = open(fpath, \'r\') \n                name = self.file.readline()\n                self.names = name.rstrip().split(\'\\t\')\n                self.numbers = {}\n                for _, name in enumerate(self.names):\n                    self.numbers[name] = []\n\n                for numbers in self.file:\n                    numbers = numbers.rstrip().split(\'\\t\')\n                    for i in range(0, len(numbers)):\n                        self.numbers[self.names[i]].append(numbers[i])\n                self.file.close()\n                self.file = open(fpath, \'a\')  \n            else:\n                self.file = open(fpath, \'w\')\n\n    def set_names(self, names):\n        if self.resume: \n            pass\n        # initialize numbers as empty list\n        self.numbers = {}\n        self.names = names\n        for _, name in enumerate(self.names):\n            self.file.write(name)\n            self.file.write(\'\\t\')\n            self.numbers[name] = []\n        self.file.write(\'\\n\')\n        self.file.flush()\n\n\n    def append(self, numbers):\n        assert len(self.names) == len(numbers), \'Numbers do not match names\'\n        for index, num in enumerate(numbers):\n            self.file.write(""{0:.6f}"".format(num))\n            self.file.write(\'\\t\')\n            self.numbers[self.names[index]].append(num)\n        self.file.write(\'\\n\')\n        self.file.flush()\n\n    def plot(self, names=None):   \n        names = self.names if names == None else names\n        numbers = self.numbers\n        for _, name in enumerate(names):\n            x = np.arange(len(numbers[name]))\n            plt.plot(x, np.asarray(numbers[name]))\n        plt.legend([self.title + \'(\' + name + \')\' for name in names])\n        plt.grid(True)\n\n    def close(self):\n        if self.file is not None:\n            self.file.close()\n\nclass LoggerMonitor(object):\n    \'\'\'Load and visualize multiple logs.\'\'\'\n    def __init__ (self, paths):\n        \'\'\'paths is a distionary with {name:filepath} pair\'\'\'\n        self.loggers = []\n        for title, path in paths.items():\n            logger = Logger(path, title=title, resume=True)\n            self.loggers.append(logger)\n\n    def plot(self, names=None):\n        plt.figure()\n        plt.subplot(121)\n        legend_text = []\n        for logger in self.loggers:\n            legend_text += plot_overlap(logger, names)\n        plt.legend(legend_text, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n        plt.grid(True)\n                    \nif __name__ == \'__main__\':\n    # # Example\n    # logger = Logger(\'test.txt\')\n    # logger.set_names([\'Train loss\', \'Valid loss\',\'Test loss\'])\n\n    # length = 100\n    # t = np.arange(length)\n    # train_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n    # valid_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n    # test_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n\n    # for i in range(0, length):\n    #     logger.append([train_loss[i], valid_loss[i], test_loss[i]])\n    # logger.plot()\n\n    # Example: logger monitor\n    paths = {\n    \'resadvnet20\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet20/log.txt\', \n    \'resadvnet32\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet32/log.txt\',\n    \'resadvnet44\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet44/log.txt\',\n    }\n\n    field = [\'Valid Acc.\']\n\n    monitor = LoggerMonitor(paths)\n    monitor.plot(names=field)\n    savefig(\'test.eps\')'"
cifar/weight-level/utils/misc.py,7,"b'import errno\nimport math\nimport os\nimport sys\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nfrom torch.autograd import Variable\n\n\n__all__ = [\'get_mean_and_std\', \'init_params\', \'mkdir_p\', \'AverageMeter\']\n\ndef get_mean_and_std(dataset):\n    \'\'\'Compute the mean and std value of dataset.\'\'\'\n    dataloader = trainloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print(\'==> Computing mean and std..\')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\ndef init_params(net):\n    \'\'\'Init layer parameters.\'\'\'\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode=\'fan_out\')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\ndef mkdir_p(path):\n    \'\'\'make dir if not exist\'\'\'\n    try:\n        os.makedirs(path)\n    except OSError as exc:  # Python >2.5\n        if exc.errno == errno.EEXIST and os.path.isdir(path):\n            pass\n        else:\n            raise\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value\n       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n    """"""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count'"
cifar/weight-level/utils/visualize.py,6,"b""import matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom .misc import *   \n\n\n__all__ = ['make_image', 'show_batch', 'show_mask', 'show_mask_single']\n\n# functions to show an image\ndef make_image(img, mean=(0,0,0), std=(1,1,1)):\n    for i in range(0, 3):\n        img[i] = img[i] * std[i] + mean[i]    # unnormalize\n    npimg = img.numpy()\n    return np.transpose(npimg, (1, 2, 0))\n\ndef gauss(x,a,b,c):\n    return torch.exp(-torch.pow(torch.add(x,-b),2).div(2*c*c)).mul(a)\n\ndef colorize(x):\n    ''' Converts a one-channel grayscale image to a color heatmap image '''\n    if x.dim() == 2:\n        torch.unsqueeze(x, 0, out=x)\n    if x.dim() == 3:\n        cl = torch.zeros([3, x.size(1), x.size(2)])\n        cl[0] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n        cl[1] = gauss(x,1,.5,.3)\n        cl[2] = gauss(x,1,.2,.3)\n        cl[cl.gt(1)] = 1\n    elif x.dim() == 4:\n        cl = torch.zeros([x.size(0), 3, x.size(2), x.size(3)])\n        cl[:,0,:,:] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n        cl[:,1,:,:] = gauss(x,1,.5,.3)\n        cl[:,2,:,:] = gauss(x,1,.2,.3)\n    return cl\n\ndef show_batch(images, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.imshow(images)\n    plt.show()\n\n\ndef show_mask_single(images, mask, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    im_size = images.size(2)\n\n    # save for adding mask\n    im_data = images.clone()\n    for i in range(0, 3):\n        im_data[:,i,:,:] = im_data[:,i,:,:] * Std[i] + Mean[i]    # unnormalize\n\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.subplot(2, 1, 1)\n    plt.imshow(images)\n    plt.axis('off')\n\n    # for b in range(mask.size(0)):\n    #     mask[b] = (mask[b] - mask[b].min())/(mask[b].max() - mask[b].min())\n    mask_size = mask.size(2)\n    # print('Max %f Min %f' % (mask.max(), mask.min()))\n    mask = (upsampling(mask, scale_factor=im_size/mask_size))\n    # mask = colorize(upsampling(mask, scale_factor=im_size/mask_size))\n    # for c in range(3):\n    #     mask[:,c,:,:] = (mask[:,c,:,:] - Mean[c])/Std[c]\n\n    # print(mask.size())\n    mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask.expand_as(im_data)))\n    # mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask), Mean, Std)\n    plt.subplot(2, 1, 2)\n    plt.imshow(mask)\n    plt.axis('off')\n\ndef show_mask(images, masklist, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    im_size = images.size(2)\n\n    # save for adding mask\n    im_data = images.clone()\n    for i in range(0, 3):\n        im_data[:,i,:,:] = im_data[:,i,:,:] * Std[i] + Mean[i]    # unnormalize\n\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.subplot(1+len(masklist), 1, 1)\n    plt.imshow(images)\n    plt.axis('off')\n\n    for i in range(len(masklist)):\n        mask = masklist[i].data.cpu()\n        # for b in range(mask.size(0)):\n        #     mask[b] = (mask[b] - mask[b].min())/(mask[b].max() - mask[b].min())\n        mask_size = mask.size(2)\n        # print('Max %f Min %f' % (mask.max(), mask.min()))\n        mask = (upsampling(mask, scale_factor=im_size/mask_size))\n        # mask = colorize(upsampling(mask, scale_factor=im_size/mask_size))\n        # for c in range(3):\n        #     mask[:,c,:,:] = (mask[:,c,:,:] - Mean[c])/Std[c]\n\n        # print(mask.size())\n        mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask.expand_as(im_data)))\n        # mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask), Mean, Std)\n        plt.subplot(1+len(masklist), 1, i+2)\n        plt.imshow(mask)\n        plt.axis('off')\n\n\n\n# x = torch.zeros(1, 3, 3)\n# out = colorize(x)\n# out_im = make_image(out)\n# plt.imshow(out_im)\n# plt.show()"""
imagenet/regression-pruning/models/__init__.py,0,"b'from .vgg_5x import vgg_5x, vgg_official\nfrom .resnet_2x import resnet_2x\nfrom .resnet import resnet50_official'"
imagenet/regression-pruning/models/channel_selection.py,3,"b'import numpy as np\n\nimport torch\nimport torch.nn as nn\n\n\nclass channel_selection(nn.Module):\n    """"""\n    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n    """"""\n    def __init__(self, num_channels, mask):\n        """"""\n        Initialize the `indexes` with all one vector with the length same as the number of channels.\n        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n        """"""\n        super(channel_selection, self).__init__()\n        self.indexes = nn.Parameter(torch.ones(num_channels))\n        assert len(mask) == num_channels\n        mask = torch.from_numpy(mask)\n        self.indexes.data.mul_(mask)\n\n    def forward(self, input_tensor):\n        """"""\n        Parameter\n        ---------\n        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n        """"""\n        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n        if selected_index.size == 1:\n            selected_index = np.resize(selected_index, (1,)) \n        output = input_tensor[:, selected_index, :, :]\n        return output'"
imagenet/regression-pruning/models/resnet.py,3,"b'import math\n\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\n\nfrom compute_flops import *\n\n\n__all__ = [\'resnet50_official\']\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(cfg[0], cfg[1], kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(cfg[1])\n        self.conv2 = nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(cfg[2])\n        self.conv3 = nn.Conv2d(cfg[2], planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, cfg, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, cfg[0:9], 64, layers[0])\n        self.layer2 = self._make_layer(block, cfg[9:21], 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, cfg[21:39], 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, cfg[39:48], 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                # m.weight.data.normal_(0, math.sqrt(2. / n))\n                nn.init.kaiming_normal(m.weight, mode=\'fan_out\')\n                # m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, cfg, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=True),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, cfg[:3], stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, cfg[3*i:3*(i+1)]))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ncfg_official = [[64, 64, 64], [256, 64, 64] * 2, [256, 128, 128], [512, 128, 128] * 3, \n                [512, 256, 256], [1024, 256, 256] * 5, [1024, 512, 512], [2048, 512, 512] * 2]\ncfg_official = [item for sublist in cfg_official for item in sublist]\nassert len(cfg_official) == 48, ""Length of cfg_official is not right""\n\n\ndef resnet50_official(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], cfg_official, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model'"
imagenet/regression-pruning/models/resnet_2x.py,4,"b'import math\nimport pickle\n\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\nfrom channel_selection import *\n\n\n__all__ = [\'resnet_2x\']\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\nwith open(""models/filter.pkl"",\'rb\') as f:\n    filter_index = pickle.load(f)\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, cfg, mask, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.selection = channel_selection(inplanes, mask)\n        self.conv1 = nn.Conv2d(cfg[0], cfg[1], kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(cfg[1])\n        self.conv2 = nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(cfg[2])\n        self.conv3 = nn.Conv2d(cfg[2], planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.selection(x)\n\n        out = self.conv1(out)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, cfg, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.count = 0\n        self.layer1 = self._make_layer(block, cfg[0:9], 64, layers[0])\n        self.layer2 = self._make_layer(block, cfg[9:21], 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, cfg[21:39], 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, cfg[39:48], 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                nn.init.kaiming_normal(m.weight, mode=\'fan_out\')\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, cfg, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=True),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        mask = filter_index[self.count]\n        layers.append(block(self.inplanes, planes, cfg[:3], mask, stride, downsample))\n        self.count += 1\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            mask = filter_index[self.count]\n            layers.append(block(self.inplanes, planes, cfg[3*i:3*(i+1)], mask))\n            self.count += 1\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ncfg_2x = [35, 64, 55, 101, 51, 39, 97, 50, 37, 144, 128, 106, 205, 105, 72, 198, 105, 72, 288, 128, 110, 278, 256, 225, 418, 209, 147,\n       407, 204, 158, 423, 212, 155, 412, 211, 148, 595, 256, 213, 606, 512, 433, 1222, 512, 437, 1147, 512, 440]\nassert len(cfg_2x) == 48, ""Length of cfg variable is not right.""\n\n\ndef resnet_2x(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], cfg_2x, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model'"
imagenet/regression-pruning/models/vgg_5x.py,4,"b'import math\n\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\n\n__all__ = [\n    \'vgg_5x\', \'vgg_official\',\n]\n\nmodel_urls = {\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n}\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000, init_weights=True):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes),\n        )\n        if init_weights:\n            self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal(m.weight, mode=\'fan_out\')#, nonlinearity=\'relu\')\n                if m.bias is not None:\n                    m.bias.data.zero_()  \n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\ncfg_5x = [24, 22, \'M\', 41, 51, \'M\', 108, 89, 111, \'M\', 184, 276, 228, \'M\', 512, 512, 512, \'M\']\ncfg_official = [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512, \'M\']\n\ndef vgg_5x(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    if pretrained:\n        kwargs[\'init_weights\'] = False\n    model = VGG(make_layers(cfg_5x, False), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model\n\ndef vgg_official(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    if pretrained:\n        kwargs[\'init_weights\'] = False\n    model = VGG(make_layers(cfg_official, False), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model'"
imagenet/thinet/models/__init__.py,0,"b'from thinetconv import thinet_conv, vgg_official\nfrom thinetvgg import thinet_gap, thinet_tiny\nfrom thinetresnet import thinet30, thinet50, thinet70, resnet50_official'"
imagenet/thinet/models/thinetconv.py,4,"b'import math\n\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\n\n__all__ = [\n    \'thinet_conv\'\n]\n\nmodel_urls = {\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n}\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000, init_weights=True):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes),\n        )\n        if init_weights:\n            self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal(m.weight, mode=\'fan_out\')#, nonlinearity=\'relu\')\n                if m.bias is not None:\n                    m.bias.data.zero_()  \n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\nconv = [32, 32, \'M\', 64, 64, \'M\', 128, 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\']\ncfg_official = [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512, \'M\']\n\ndef thinet_conv(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    if pretrained:\n        kwargs[\'init_weights\'] = False\n    model = VGG(make_layers(conv, False), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model\n\ndef vgg_official(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    if pretrained:\n        kwargs[\'init_weights\'] = False\n    model = VGG(make_layers(cfg_official, False), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model'"
imagenet/thinet/models/thinetresnet.py,3,"b'import math\n\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\n\nfrom compute_flops import *\n\n\n__all__ = [\'thinet30\', \'thinet50\', \'thinet70\', \'resnet50_official\']\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(cfg[0], cfg[1], kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(cfg[1])\n        self.conv2 = nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(cfg[2])\n        self.conv3 = nn.Conv2d(cfg[2], planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, cfg, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, cfg[0:9], 64, layers[0])\n        self.layer2 = self._make_layer(block, cfg[9:21], 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, cfg[21:39], 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, cfg[39:48], 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                # m.weight.data.normal_(0, math.sqrt(2. / n))\n                nn.init.kaiming_normal(m.weight, mode=\'fan_out\')\n                # m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, cfg, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=True),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, cfg[:3], stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, cfg[3*i:3*(i+1)]))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ncfg_thinet30 = [64, 19, 19, 256, 19, 19, 256, 19, 19, 256, 38, 38, 512, 38, 38, 512, 38, 38, 512, 38, 38, 512, 76, 76,\n            1024, 76, 76, 1024, 76, 76, 1024, 76, 76, 1024, 76, 76, 1024, 76, 76, 1024, 153, 153, 2048, 153, 153, \n            2048, 153, 153]\ncfg_thinet50 = [64, 32, 32, 256, 32, 32, 256, 32, 32, 256, 64, 64, 512, 64, 64, 512, 64, 64, 512, 64, 64, 512, \n                128, 128, 1024, 128, 128, 1024, 128, 128, 1024, 128, 128, 1024, 128, 128, 1024, 128, 128, 1024, 256,\n                256, 2048, 256, 256, 2048, 256, 256]\ncfg_thinet70 = [64, 44, 44, 256, 44, 44, 256, 44, 44, 256, 89, 89, 512, 89, 89, 512, 89, 89, 512, 89, 89, 512, 179, 179,\n                1024, 179, 179, 1024, 179, 179, 1024, 179, 179, 1024, 179, 179, 1024, 179, 179, 1024, 358, 358,\n                2048, 358, 358, 2048, 358, 358]\ncfg_official = [[64, 64, 64], [256, 64, 64] * 2, [256, 128, 128], [512, 128, 128] * 3, \n                [512, 256, 256], [1024, 256, 256] * 5, [1024, 512, 512], [2048, 512, 512] * 2]\ncfg_official = [item for sublist in cfg_official for item in sublist]\nassert len(cfg_official) == 48, ""Length of cfg_official is not right""\nassert len(cfg_thinet30) == 48, ""Length of cfg_thinet30 is not right""\nassert len(cfg_thinet50) == 48, ""Length of cfg_thinet50 is not right""\nassert len(cfg_thinet70) == 48, ""Length of cfg_thinet70 is not right""\n\n\ndef thinet30(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], cfg_thinet30, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\ndef thinet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], cfg_thinet50, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\ndef thinet70(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], cfg_thinet70, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\ndef resnet50_official(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], cfg_official, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model'"
imagenet/thinet/models/thinetvgg.py,4,"b'import math\n\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\n\n__all__ = [\n    \'thinet_gap\', \'thinet_tiny\'\n]\n\nmodel_urls = {\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n}\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, cfg, num_classes=1000, init_weights=True):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(cfg, num_classes),\n        )\n        if init_weights:\n            self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = nn.AvgPool2d(14,2)(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal(m.weight, mode=\'fan_out\')#, nonlinearity=\'relu\')\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\ngap = [32, 32, \'M\', 64, 64, \'M\', 128, 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512]\ntiny = [16, 16, \'M\', 32, 32, \'M\', 64, 64, 64, \'M\', 128, 128, 128, \'M\', 128, 128, 256]\n\ndef thinet_gap(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    if pretrained:\n        kwargs[\'init_weights\'] = False\n    model = VGG(make_layers(gap), 512, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model\n\ndef thinet_tiny(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    if pretrained:\n        kwargs[\'init_weights\'] = False\n    model = VGG(make_layers(tiny), 256, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model\n'"
cifar/lottery-ticket/l1-norm-pruning/models/__init__.py,0,b'from __future__ import absolute_import\n\nfrom .vgg import *\nfrom .resnet import *'
cifar/lottery-ticket/l1-norm-pruning/models/resnet.py,7,"b'from __future__ import absolute_import\n\n\'\'\'Resnet for cifar dataset.\nPorted form\nhttps://github.com/facebook/fb.resnet.torch\nand\nhttps://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n(c) YANG, Wei\n\'\'\'\nimport torch\nimport torch.nn as nn\nimport math\nimport torch.nn.functional as F\nfrom functools import partial\nfrom torch.autograd import Variable\n\n\n__all__ = [\'resnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None):\n        # cfg should be a number in this case\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, cfg, stride)\n        self.bn1 = nn.BatchNorm2d(cfg)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(cfg, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\ndef downsample_basic_block(x, planes):\n    x = nn.AvgPool2d(2,2)(x)\n    zero_pads = torch.Tensor(\n        x.size(0), planes - x.size(1), x.size(2), x.size(3)).zero_()\n    if isinstance(x.data, torch.cuda.FloatTensor):\n        zero_pads = zero_pads.cuda()\n\n    out = Variable(torch.cat([x.data, zero_pads], dim=1))\n\n    return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, depth, dataset=\'cifar10\', cfg=None):\n        super(ResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        assert (depth - 2) % 6 == 0, \'depth should be 6n+2\'\n        n = (depth - 2) // 6\n\n        block = BasicBlock\n        if cfg == None:\n            cfg = [[16]*n, [32]*n, [64]*n]\n            cfg = [item for sub_list in cfg for item in sub_list]\n\n        self.cfg = cfg\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(block, 16, n, cfg=cfg[0:n])\n        self.layer2 = self._make_layer(block, 32, n, cfg=cfg[n:2*n], stride=2)\n        self.layer3 = self._make_layer(block, 64, n, cfg=cfg[2*n:3*n], stride=2)\n        self.avgpool = nn.AvgPool2d(8)\n        if dataset == \'cifar10\':\n            num_classes = 10\n        elif dataset == \'cifar100\':\n            num_classes = 100\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, cfg, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = partial(downsample_basic_block, planes=planes*block.expansion)\n\n        layers = []\n        layers.append(block(self.inplanes, planes, cfg[0], stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, cfg[i]))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)    # 32x32\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ndef resnet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return ResNet(**kwargs)\n\nif __name__ == \'__main__\':\n    net = resnet(depth=56)\n    x=Variable(torch.FloatTensor(16, 3, 32, 32))\n    y = net(x)\n    print(y.data.shape)'"
cifar/lottery-ticket/l1-norm-pruning/models/vgg.py,3,"b""import math\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\n__all__ = ['vgg']\n\ndefaultcfg = {\n    11 : [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n    13 : [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n    16 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n    19 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n}\n\nclass vgg(nn.Module):\n    def __init__(self, dataset='cifar10', depth=19, init_weights=True, cfg=None):\n        super(vgg, self).__init__()\n        if cfg is None:\n            cfg = defaultcfg[depth]\n\n        self.cfg = cfg\n\n        self.feature = self.make_layers(cfg, True)\n\n        if dataset == 'cifar10':\n            num_classes = 10\n        elif dataset == 'cifar100':\n            num_classes = 100\n        self.classifier = nn.Sequential(\n              nn.Linear(cfg[-1], 512),\n              nn.BatchNorm1d(512),\n              nn.ReLU(inplace=True),\n              nn.Linear(512, num_classes)\n            )\n        if init_weights:\n            self._initialize_weights()\n\n    def make_layers(self, cfg, batch_norm=False):\n        layers = []\n        in_channels = 3\n        for v in cfg:\n            if v == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.feature(x)\n        x = nn.AvgPool2d(2)(x)\n        x = x.view(x.size(0), -1)\n        y = self.classifier(x)\n        return y\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\nif __name__ == '__main__':\n    net = vgg()\n    x = Variable(torch.FloatTensor(16, 3, 40, 40))\n    y = net(x)\n    print(y.data.shape)"""
cifar/lottery-ticket/weight-level/models/__init__.py,0,b''
cifar/lottery-ticket/weight-level/utils/__init__.py,0,"b'""""""Useful utils\n""""""\nfrom .misc import *\nfrom .logger import *\nfrom .visualize import *\nfrom .eval import *\n\n# progress bar\nimport os, sys\nsys.path.append(os.path.join(os.path.dirname(__file__), ""progress""))\nfrom progress.bar import Bar as Bar'"
cifar/lottery-ticket/weight-level/utils/eval.py,0,"b'from __future__ import print_function, absolute_import\n\n__all__ = [\'accuracy\']\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res'"
cifar/lottery-ticket/weight-level/utils/logger.py,0,"b'from __future__ import absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport sys\n\n__all__ = [\'Logger\', \'LoggerMonitor\', \'savefig\']\n\ndef savefig(fname, dpi=None):\n    dpi = 150 if dpi == None else dpi\n    plt.savefig(fname, dpi=dpi)\n    \ndef plot_overlap(logger, names=None):\n    names = logger.names if names == None else names\n    numbers = logger.numbers\n    for _, name in enumerate(names):\n        x = np.arange(len(numbers[name]))\n        plt.plot(x, np.asarray(numbers[name]))\n    return [logger.title + \'(\' + name + \')\' for name in names]\n\nclass Logger(object):\n    \'\'\'Save training process to log file with simple plot function.\'\'\'\n    def __init__(self, fpath, title=None, resume=False): \n        self.file = None\n        self.resume = resume\n        self.title = \'\' if title == None else title\n        if fpath is not None:\n            if resume: \n                self.file = open(fpath, \'r\') \n                name = self.file.readline()\n                self.names = name.rstrip().split(\'\\t\')\n                self.numbers = {}\n                for _, name in enumerate(self.names):\n                    self.numbers[name] = []\n\n                for numbers in self.file:\n                    numbers = numbers.rstrip().split(\'\\t\')\n                    for i in range(0, len(numbers)):\n                        self.numbers[self.names[i]].append(numbers[i])\n                self.file.close()\n                self.file = open(fpath, \'a\')  \n            else:\n                self.file = open(fpath, \'w\')\n\n    def set_names(self, names):\n        if self.resume: \n            pass\n        # initialize numbers as empty list\n        self.numbers = {}\n        self.names = names\n        for _, name in enumerate(self.names):\n            self.file.write(name)\n            self.file.write(\'\\t\')\n            self.numbers[name] = []\n        self.file.write(\'\\n\')\n        self.file.flush()\n\n\n    def append(self, numbers):\n        assert len(self.names) == len(numbers), \'Numbers do not match names\'\n        for index, num in enumerate(numbers):\n            self.file.write(""{0:.6f}"".format(num))\n            self.file.write(\'\\t\')\n            self.numbers[self.names[index]].append(num)\n        self.file.write(\'\\n\')\n        self.file.flush()\n\n    def plot(self, names=None):   \n        names = self.names if names == None else names\n        numbers = self.numbers\n        for _, name in enumerate(names):\n            x = np.arange(len(numbers[name]))\n            plt.plot(x, np.asarray(numbers[name]))\n        plt.legend([self.title + \'(\' + name + \')\' for name in names])\n        plt.grid(True)\n\n    def close(self):\n        if self.file is not None:\n            self.file.close()\n\nclass LoggerMonitor(object):\n    \'\'\'Load and visualize multiple logs.\'\'\'\n    def __init__ (self, paths):\n        \'\'\'paths is a distionary with {name:filepath} pair\'\'\'\n        self.loggers = []\n        for title, path in paths.items():\n            logger = Logger(path, title=title, resume=True)\n            self.loggers.append(logger)\n\n    def plot(self, names=None):\n        plt.figure()\n        plt.subplot(121)\n        legend_text = []\n        for logger in self.loggers:\n            legend_text += plot_overlap(logger, names)\n        plt.legend(legend_text, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n        plt.grid(True)\n                    \nif __name__ == \'__main__\':\n    # # Example\n    # logger = Logger(\'test.txt\')\n    # logger.set_names([\'Train loss\', \'Valid loss\',\'Test loss\'])\n\n    # length = 100\n    # t = np.arange(length)\n    # train_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n    # valid_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n    # test_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n\n    # for i in range(0, length):\n    #     logger.append([train_loss[i], valid_loss[i], test_loss[i]])\n    # logger.plot()\n\n    # Example: logger monitor\n    paths = {\n    \'resadvnet20\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet20/log.txt\', \n    \'resadvnet32\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet32/log.txt\',\n    \'resadvnet44\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet44/log.txt\',\n    }\n\n    field = [\'Valid Acc.\']\n\n    monitor = LoggerMonitor(paths)\n    monitor.plot(names=field)\n    savefig(\'test.eps\')'"
cifar/lottery-ticket/weight-level/utils/misc.py,7,"b'\'\'\'Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n\'\'\'\nimport errno\nimport os\nimport sys\nimport time\nimport torch\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\nfrom torch.autograd import Variable\n\n__all__ = [\'get_mean_and_std\', \'init_params\', \'mkdir_p\', \'AverageMeter\']\n\n\ndef get_mean_and_std(dataset):\n    \'\'\'Compute the mean and std value of dataset.\'\'\'\n    dataloader = trainloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print(\'==> Computing mean and std..\')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef get_conv_zero_param(model):\n    total = 0\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            total += torch.sum(m.weight.data.eq(0))\n    return total\n\ndef init_params(net):\n    \'\'\'Init layer parameters.\'\'\'\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode=\'fan_out\')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\ndef mkdir_p(path):\n    \'\'\'make dir if not exist\'\'\'\n    try:\n        os.makedirs(path)\n    except OSError as exc:  # Python >2.5\n        if exc.errno == errno.EEXIST and os.path.isdir(path):\n            pass\n        else:\n            raise\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value\n       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n    """"""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count'"
cifar/lottery-ticket/weight-level/utils/visualize.py,6,"b""import matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nfrom .misc import *   \n\n__all__ = ['make_image', 'show_batch', 'show_mask', 'show_mask_single']\n\n# functions to show an image\ndef make_image(img, mean=(0,0,0), std=(1,1,1)):\n    for i in range(0, 3):\n        img[i] = img[i] * std[i] + mean[i]    # unnormalize\n    npimg = img.numpy()\n    return np.transpose(npimg, (1, 2, 0))\n\ndef gauss(x,a,b,c):\n    return torch.exp(-torch.pow(torch.add(x,-b),2).div(2*c*c)).mul(a)\n\ndef colorize(x):\n    ''' Converts a one-channel grayscale image to a color heatmap image '''\n    if x.dim() == 2:\n        torch.unsqueeze(x, 0, out=x)\n    if x.dim() == 3:\n        cl = torch.zeros([3, x.size(1), x.size(2)])\n        cl[0] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n        cl[1] = gauss(x,1,.5,.3)\n        cl[2] = gauss(x,1,.2,.3)\n        cl[cl.gt(1)] = 1\n    elif x.dim() == 4:\n        cl = torch.zeros([x.size(0), 3, x.size(2), x.size(3)])\n        cl[:,0,:,:] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n        cl[:,1,:,:] = gauss(x,1,.5,.3)\n        cl[:,2,:,:] = gauss(x,1,.2,.3)\n    return cl\n\ndef show_batch(images, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.imshow(images)\n    plt.show()\n\n\ndef show_mask_single(images, mask, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    im_size = images.size(2)\n\n    # save for adding mask\n    im_data = images.clone()\n    for i in range(0, 3):\n        im_data[:,i,:,:] = im_data[:,i,:,:] * Std[i] + Mean[i]    # unnormalize\n\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.subplot(2, 1, 1)\n    plt.imshow(images)\n    plt.axis('off')\n\n    # for b in range(mask.size(0)):\n    #     mask[b] = (mask[b] - mask[b].min())/(mask[b].max() - mask[b].min())\n    mask_size = mask.size(2)\n    # print('Max %f Min %f' % (mask.max(), mask.min()))\n    mask = (upsampling(mask, scale_factor=im_size/mask_size))\n    # mask = colorize(upsampling(mask, scale_factor=im_size/mask_size))\n    # for c in range(3):\n    #     mask[:,c,:,:] = (mask[:,c,:,:] - Mean[c])/Std[c]\n\n    # print(mask.size())\n    mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask.expand_as(im_data)))\n    # mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask), Mean, Std)\n    plt.subplot(2, 1, 2)\n    plt.imshow(mask)\n    plt.axis('off')\n\ndef show_mask(images, masklist, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    im_size = images.size(2)\n\n    # save for adding mask\n    im_data = images.clone()\n    for i in range(0, 3):\n        im_data[:,i,:,:] = im_data[:,i,:,:] * Std[i] + Mean[i]    # unnormalize\n\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.subplot(1+len(masklist), 1, 1)\n    plt.imshow(images)\n    plt.axis('off')\n\n    for i in range(len(masklist)):\n        mask = masklist[i].data.cpu()\n        # for b in range(mask.size(0)):\n        #     mask[b] = (mask[b] - mask[b].min())/(mask[b].max() - mask[b].min())\n        mask_size = mask.size(2)\n        # print('Max %f Min %f' % (mask.max(), mask.min()))\n        mask = (upsampling(mask, scale_factor=im_size/mask_size))\n        # mask = colorize(upsampling(mask, scale_factor=im_size/mask_size))\n        # for c in range(3):\n        #     mask[:,c,:,:] = (mask[:,c,:,:] - Mean[c])/Std[c]\n\n        # print(mask.size())\n        mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask.expand_as(im_data)))\n        # mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask), Mean, Std)\n        plt.subplot(1+len(masklist), 1, i+2)\n        plt.imshow(mask)\n        plt.axis('off')\n\n\n\n# x = torch.zeros(1, 3, 3)\n# out = colorize(x)\n# out_im = make_image(out)\n# plt.imshow(out_im)\n# plt.show()"""
cifar/weight-level/models/cifar/__init__.py,1,"b'from __future__ import absolute_import\n\n""""""The models subpackage contains definitions for the following model for CIFAR10/CIFAR100\narchitectures:\n\n-  `AlexNet`_\n-  `VGG`_\n-  `ResNet`_\n-  `SqueezeNet`_\n-  `DenseNet`_\n\nYou can construct a model with random weights by calling its constructor:\n\n.. code:: python\n\n    import torchvision.models as models\n    resnet18 = models.resnet18()\n    alexnet = models.alexnet()\n    squeezenet = models.squeezenet1_0()\n    densenet = models.densenet_161()\n\nWe provide pre-trained models for the ResNet variants and AlexNet, using the\nPyTorch :mod:`torch.utils.model_zoo`. These can  constructed by passing\n``pretrained=True``:\n\n.. code:: python\n\n    import torchvision.models as models\n    resnet18 = models.resnet18(pretrained=True)\n    alexnet = models.alexnet(pretrained=True)\n\nImageNet 1-crop error rates (224x224)\n\n======================== =============   =============\nNetwork                  Top-1 error     Top-5 error\n======================== =============   =============\nResNet-18                30.24           10.92\nResNet-34                26.70           8.58\nResNet-50                23.85           7.13\nResNet-101               22.63           6.44\nResNet-152               21.69           5.94\nInception v3             22.55           6.44\nAlexNet                  43.45           20.91\nVGG-11                   30.98           11.37\nVGG-13                   30.07           10.75\nVGG-16                   28.41           9.62\nVGG-19                   27.62           9.12\nSqueezeNet 1.0           41.90           19.58\nSqueezeNet 1.1           41.81           19.38\nDensenet-121             25.35           7.83\nDensenet-169             24.00           7.00\nDensenet-201             22.80           6.43\nDensenet-161             22.35           6.20\n======================== =============   =============\n\n\n.. _AlexNet: https://arxiv.org/abs/1404.5997\n.. _VGG: https://arxiv.org/abs/1409.1556\n.. _ResNet: https://arxiv.org/abs/1512.03385\n.. _SqueezeNet: https://arxiv.org/abs/1602.07360\n.. _DenseNet: https://arxiv.org/abs/1608.06993\n""""""\n\nfrom .alexnet import *\nfrom .vgg import *\nfrom .resnet import *\nfrom .preresnet import *\nfrom .densenet import *\n'"
cifar/weight-level/models/cifar/alexnet.py,1,"b'import torch.nn as nn\n\n\n__all__ = [\'alexnet\']\n\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=10):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.classifier = nn.Linear(256, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\ndef alexnet(**kwargs):\n    r""""""AlexNet model architecture from the\n    `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.\n    """"""\n    model = AlexNet(**kwargs)\n    return model'"
cifar/weight-level/models/cifar/densenet.py,5,"b'import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n__all__ = [\'densenet\']\n\nclass Bottleneck(nn.Module):\n    def __init__(self, inplanes, expansion=4, growthRate=12, dropRate=0):\n        super(Bottleneck, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\nclass BasicBlock(nn.Module):\n    def __init__(self, inplanes, expansion=1, growthRate=12, dropRate=0):\n        super(BasicBlock, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\nclass Transition(nn.Module):\n    def __init__(self, inplanes, outplanes):\n        super(Transition, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1,\n                               bias=False)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = F.avg_pool2d(out, 2)\n        return out\n\nclass DenseNet(nn.Module):\n\n    def __init__(self, depth=22, block=BasicBlock, \n        dropRate=0, num_classes=10, growthRate=12, compressionRate=1):\n        super(DenseNet, self).__init__()\n\n        assert (depth - 4) % 3 == 0, \'depth should be 3n+4\'\n        n = (depth - 4) / 3 if block == BasicBlock else (depth - 4) // 6\n        n = int(n)\n\n        self.growthRate = growthRate\n        self.dropRate = dropRate\n\n        # self.inplanes is a global variable used across multiple\n        # helper functions\n        self.inplanes = growthRate * 2 \n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n                               bias=False)\n        self.dense1 = self._make_denseblock(block, n)\n        self.trans1 = self._make_transition(compressionRate)\n        self.dense2 = self._make_denseblock(block, n)\n        self.trans2 = self._make_transition(compressionRate)\n        self.dense3 = self._make_denseblock(block, n)\n        self.bn = nn.BatchNorm2d(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(self.inplanes, num_classes)\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_denseblock(self, block, blocks):\n        layers = []\n        for i in range(blocks):\n            # Currently we fix the expansion ratio as the default value\n            layers.append(block(self.inplanes, growthRate=self.growthRate, dropRate=self.dropRate))\n            self.inplanes += self.growthRate\n\n        return nn.Sequential(*layers)\n\n    def _make_transition(self, compressionRate):\n        inplanes = self.inplanes\n        outplanes = int(math.floor(self.inplanes // compressionRate))\n        self.inplanes = outplanes\n        return Transition(inplanes, outplanes)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.trans1(self.dense1(x)) \n        x = self.trans2(self.dense2(x)) \n        x = self.dense3(x)\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ndef densenet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return DenseNet(**kwargs)'"
cifar/weight-level/models/cifar/preresnet.py,1,"b'from __future__ import absolute_import\nimport math\n\nimport torch.nn as nn\n\n\n__all__ = [\'preresnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\nclass PreResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=10):\n        super(PreResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        assert (depth - 2) % 6 == 0, \'depth should be 6n+2\'\n        n = (depth - 2) // 9\n\n        block = Bottleneck if depth >=44 else BasicBlock\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.bn = nn.BatchNorm2d(64 * block.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ndef preresnet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return PreResNet(**kwargs)\n'"
cifar/weight-level/models/cifar/resnet.py,1,"b'from __future__ import absolute_import\nimport math\n\nimport torch.nn as nn\n\n\n__all__ = [\'resnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=1000):\n        super(ResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        assert (depth - 2) % 6 == 0, \'depth should be 6n+2\'\n        n = (depth - 2) // 6\n\n        block = Bottleneck if depth >=54 else BasicBlock\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)    # 32x32\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\ndef resnet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return ResNet(**kwargs)'"
cifar/weight-level/models/cifar/vgg.py,6,"b'\'\'\'VGG for CIFAR10. FC layers are removed.\n(c) YANG, Wei \n\'\'\'\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport math\n\n\n__all__ = [\n    \'VGG\', \'vgg11\', \'vgg11_bn\', \'vgg13\', \'vgg13_bn\', \'vgg16\', \'vgg16_bn\',\n    \'vgg19_bn\', \'vgg19\',\n]\n\n\nmodel_urls = {\n    \'vgg11\': \'https://download.pytorch.org/models/vgg11-bbd30ac9.pth\',\n    \'vgg13\': \'https://download.pytorch.org/models/vgg13-c768596a.pth\',\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n    \'vgg19\': \'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\',\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Linear(512, num_classes)\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = nn.AvgPool2d(2)(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * (m.in_channels)\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfg = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512],\n    \'B\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512],\n    \'D\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512],\n    \'E\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512],\n    # \'E\': [64, 128, \'M\', 128, 256, \'M\', 64, 128, 256, 512, 1024, \'M\', 64, 128, 256, 512, 1024, 2048,\'M\',256, 512, 1024, 512,\'M\']\n}\n\n\ndef vgg11(**kwargs):\n    """"""VGG 11-layer model (configuration ""A"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\']), **kwargs)\n    return model\n\n\ndef vgg11_bn(**kwargs):\n    """"""VGG 11-layer model (configuration ""A"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'A\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg13(**kwargs):\n    """"""VGG 13-layer model (configuration ""B"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\']), **kwargs)\n    return model\n\n\ndef vgg13_bn(**kwargs):\n    """"""VGG 13-layer model (configuration ""B"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'B\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg16(**kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\']), **kwargs)\n    return model\n\n\ndef vgg16_bn(**kwargs):\n    """"""VGG 16-layer model (configuration ""D"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'D\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg19(**kwargs):\n    """"""VGG 19-layer model (configuration ""E"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\']), **kwargs)\n    return model\n\n\ndef vgg19_bn(**kwargs):\n    """"""VGG 19-layer model (configuration \'E\') with batch normalization""""""\n    model = VGG(make_layers(cfg[\'E\'], batch_norm=True), **kwargs)\n    return model\n'"
cifar/lottery-ticket/weight-level/models/cifar/__init__.py,0,b'from __future__ import absolute_import\n\nfrom .alexnet import *\nfrom .vgg import *\nfrom .resnet import *\nfrom .resnext import *\nfrom .wrn import *\nfrom .preresnet import *\nfrom .densenet import *'
cifar/lottery-ticket/weight-level/models/cifar/alexnet.py,1,"b'import torch.nn as nn\n\n\n__all__ = [\'alexnet\']\n\n\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=10):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.classifier = nn.Linear(256, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\ndef alexnet(**kwargs):\n    r""""""AlexNet model architecture from the\n    `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.\n    """"""\n    model = AlexNet(**kwargs)\n    return model\n'"
cifar/lottery-ticket/weight-level/models/cifar/densenet.py,5,"b'import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = [\'densenet\']\n\n\nfrom torch.autograd import Variable\n\nclass Bottleneck(nn.Module):\n    def __init__(self, inplanes, expansion=4, growthRate=12, dropRate=0):\n        super(Bottleneck, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, inplanes, expansion=1, growthRate=12, dropRate=0):\n        super(BasicBlock, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\n\nclass Transition(nn.Module):\n    def __init__(self, inplanes, outplanes):\n        super(Transition, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1,\n                               bias=False)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = F.avg_pool2d(out, 2)\n        return out\n\n\nclass DenseNet(nn.Module):\n\n    def __init__(self, depth=22, block=BasicBlock, \n        dropRate=0, num_classes=10, growthRate=12, compressionRate=1):\n        super(DenseNet, self).__init__()\n\n        assert (depth - 4) % 3 == 0, \'depth should be 3n+4\'\n        n = (depth - 4) / 3 if block == BasicBlock else (depth - 4) // 6\n        n = int(n)\n\n        self.growthRate = growthRate\n        self.dropRate = dropRate\n\n        # self.inplanes is a global variable used across multiple\n        # helper functions\n        self.inplanes = growthRate * 2 \n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n                               bias=False)\n        self.dense1 = self._make_denseblock(block, n)\n        self.trans1 = self._make_transition(compressionRate)\n        self.dense2 = self._make_denseblock(block, n)\n        self.trans2 = self._make_transition(compressionRate)\n        self.dense3 = self._make_denseblock(block, n)\n        self.bn = nn.BatchNorm2d(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(self.inplanes, num_classes)\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_denseblock(self, block, blocks):\n        layers = []\n        for i in range(blocks):\n            # Currently we fix the expansion ratio as the default value\n            layers.append(block(self.inplanes, growthRate=self.growthRate, dropRate=self.dropRate))\n            self.inplanes += self.growthRate\n\n        return nn.Sequential(*layers)\n\n    def _make_transition(self, compressionRate):\n        inplanes = self.inplanes\n        outplanes = int(math.floor(self.inplanes // compressionRate))\n        self.inplanes = outplanes\n        return Transition(inplanes, outplanes)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.trans1(self.dense1(x)) \n        x = self.trans2(self.dense2(x)) \n        x = self.dense3(x)\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef densenet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return DenseNet(**kwargs)\n'"
cifar/lottery-ticket/weight-level/models/cifar/preresnet.py,1,"b'from __future__ import absolute_import\n\nimport math\n\nimport torch.nn as nn\n\n\n__all__ = [\'preresnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass PreResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=1000):\n        super(PreResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        assert (depth - 2) % 6 == 0, \'depth should be 6n+2\'\n        n = (depth - 2) // 6\n\n        block = Bottleneck if depth >=44 else BasicBlock\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.bn = nn.BatchNorm2d(64 * block.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef preresnet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return PreResNet(**kwargs)\n'"
cifar/lottery-ticket/weight-level/models/cifar/resnet.py,1,"b'from __future__ import absolute_import\n\nimport math\n\nimport torch.nn as nn\n\n\n__all__ = [\'resnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=1000):\n        super(ResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        assert (depth - 2) % 6 == 0, \'depth should be 6n+2\'\n        n = (depth - 2) // 6\n\n        block = Bottleneck if depth >=54 else BasicBlock\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)    # 32x32\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return ResNet(**kwargs)\n'"
cifar/lottery-ticket/weight-level/models/cifar/resnext.py,3,"b'from __future__ import division\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\n\n\n__all__ = [\'resnext\']\n\nclass ResNeXtBottleneck(nn.Module):\n    """"""\n    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n    """"""\n    def __init__(self, in_channels, out_channels, stride, cardinality, widen_factor):\n        """""" Constructor\n        Args:\n            in_channels: input channel dimensionality\n            out_channels: output channel dimensionality\n            stride: conv stride. Replaces pooling layer.\n            cardinality: num of convolution groups.\n            widen_factor: factor to reduce the input dimensionality before convolution.\n        """"""\n        super(ResNeXtBottleneck, self).__init__()\n        D = cardinality * out_channels // widen_factor\n        self.conv_reduce = nn.Conv2d(in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_reduce = nn.BatchNorm2d(D)\n        self.conv_conv = nn.Conv2d(D, D, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n        self.bn = nn.BatchNorm2d(D)\n        self.conv_expand = nn.Conv2d(D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_expand = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut.add_module(\'shortcut_conv\', nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False))\n            self.shortcut.add_module(\'shortcut_bn\', nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        bottleneck = self.conv_reduce.forward(x)\n        bottleneck = F.relu(self.bn_reduce.forward(bottleneck), inplace=True)\n        bottleneck = self.conv_conv.forward(bottleneck)\n        bottleneck = F.relu(self.bn.forward(bottleneck), inplace=True)\n        bottleneck = self.conv_expand.forward(bottleneck)\n        bottleneck = self.bn_expand.forward(bottleneck)\n        residual = self.shortcut.forward(x)\n        return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n    """"""\n    ResNext optimized for the Cifar dataset, as specified in\n    https://arxiv.org/pdf/1611.05431.pdf\n    """"""\n    def __init__(self, cardinality, depth, num_classes, widen_factor=4, dropRate=0):\n        """""" Constructor\n        Args:\n            cardinality: number of convolution groups.\n            depth: number of layers.\n            num_classes: number of classes\n            widen_factor: factor to adjust the channel dimensionality\n        """"""\n        super(CifarResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.depth = depth\n        self.block_depth = (self.depth - 2) // 9\n        self.widen_factor = widen_factor\n        self.num_classes = num_classes\n        self.output_size = 64\n        self.stages = [64, 64 * self.widen_factor, 128 * self.widen_factor, 256 * self.widen_factor]\n\n        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(64)\n        self.stage_1 = self.block(\'stage_1\', self.stages[0], self.stages[1], 1)\n        self.stage_2 = self.block(\'stage_2\', self.stages[1], self.stages[2], 2)\n        self.stage_3 = self.block(\'stage_3\', self.stages[2], self.stages[3], 2)\n        self.classifier = nn.Linear(1024, num_classes)\n        init.kaiming_normal(self.classifier.weight)\n\n        for key in self.state_dict():\n            if key.split(\'.\')[-1] == \'weight\':\n                if \'conv\' in key:\n                    init.kaiming_normal(self.state_dict()[key], mode=\'fan_out\')\n                if \'bn\' in key:\n                    self.state_dict()[key][...] = 1\n            elif key.split(\'.\')[-1] == \'bias\':\n                self.state_dict()[key][...] = 0\n\n    def block(self, name, in_channels, out_channels, pool_stride=2):\n        """""" Stack n bottleneck modules where n is inferred from the depth of the network.\n        Args:\n            name: string name of the current block.\n            in_channels: number of input channels\n            out_channels: number of output channels\n            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n        Returns: a Module consisting of n sequential bottlenecks.\n        """"""\n        block = nn.Sequential()\n        for bottleneck in range(self.block_depth):\n            name_ = \'%s_bottleneck_%d\' % (name, bottleneck)\n            if bottleneck == 0:\n                block.add_module(name_, ResNeXtBottleneck(in_channels, out_channels, pool_stride, self.cardinality,\n                                                          self.widen_factor))\n            else:\n                block.add_module(name_,\n                                 ResNeXtBottleneck(out_channels, out_channels, 1, self.cardinality, self.widen_factor))\n        return block\n\n    def forward(self, x):\n        x = self.conv_1_3x3.forward(x)\n        x = F.relu(self.bn_1.forward(x), inplace=True)\n        x = self.stage_1.forward(x)\n        x = self.stage_2.forward(x)\n        x = self.stage_3.forward(x)\n        x = F.avg_pool2d(x, 8, 1)\n        x = x.view(-1, 1024)\n        return self.classifier(x)\n\ndef resnext(**kwargs):\n    """"""Constructs a ResNeXt.\n    """"""\n    model = CifarResNeXt(**kwargs)\n    return model'"
cifar/lottery-ticket/weight-level/models/cifar/vgg.py,6,"b'import math\n\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\n\n\n__all__ = [\n    \'VGG\', \'vgg11\', \'vgg11_bn\', \'vgg13\', \'vgg13_bn\', \'vgg16\', \'vgg16_bn\',\n    \'vgg19_bn\', \'vgg19\',\n]\n\n\nmodel_urls = {\n    \'vgg11\': \'https://download.pytorch.org/models/vgg11-bbd30ac9.pth\',\n    \'vgg13\': \'https://download.pytorch.org/models/vgg13-c768596a.pth\',\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n    \'vgg19\': \'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\',\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Linear(512, num_classes)\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = nn.AvgPool2d(2)(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * (m.in_channels)\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfg = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512],\n    \'B\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512],\n    \'D\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512],\n    \'E\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512],\n    # \'E\': [64, 128, \'M\', 128, 256, \'M\', 64, 128, 256, 512, 1024, \'M\', 64, 128, 256, 512, 1024, 2048,\'M\',256, 512, 1024, 512,\'M\']\n}\n\n\ndef vgg11(**kwargs):\n    """"""VGG 11-layer model (configuration ""A"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\']), **kwargs)\n    return model\n\n\ndef vgg11_bn(**kwargs):\n    """"""VGG 11-layer model (configuration ""A"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'A\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg13(**kwargs):\n    """"""VGG 13-layer model (configuration ""B"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\']), **kwargs)\n    return model\n\n\ndef vgg13_bn(**kwargs):\n    """"""VGG 13-layer model (configuration ""B"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'B\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg16(**kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\']), **kwargs)\n    return model\n\n\ndef vgg16_bn(**kwargs):\n    """"""VGG 16-layer model (configuration ""D"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'D\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg19(**kwargs):\n    """"""VGG 19-layer model (configuration ""E"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\']), **kwargs)\n    return model\n\n\ndef vgg19_bn(**kwargs):\n    """"""VGG 19-layer model (configuration \'E\') with batch normalization""""""\n    model = VGG(make_layers(cfg[\'E\'], batch_norm=True), **kwargs)\n    return model\n'"
cifar/lottery-ticket/weight-level/models/cifar/wrn.py,3,"b'import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n__all__ = [\'wrn\']\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut:\n            x = self.relu1(self.bn1(x))\n        else:\n            out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super(NetworkBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x):\n        return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(WideResNet, self).__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert (depth - 4) % 6 == 0, \'depth should be 6n+4\'\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        # 1st block\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        # 2nd block\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        # 3rd block\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n\ndef wrn(**kwargs):\n    """"""\n    Constructs a Wide Residual Networks.\n    """"""\n    model = WideResNet(**kwargs)\n    return model\n'"
