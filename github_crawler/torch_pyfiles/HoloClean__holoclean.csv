file_path,api_count,code
__init__.py,0,"b'__author__  = ""HoloClean""\n__status__  = ""Development""\n__version__ = ""0.2.0""\n\nfrom .holoclean import HoloClean\n\n__all__ = [\'HoloClean\']'"
holoclean.py,2,"b'import logging\nimport os\nimport random\n\nimport torch\nimport numpy as np\n\nfrom dataset import Dataset\nfrom dcparser import Parser\nfrom domain import DomainEngine\nfrom detect import DetectEngine\nfrom repair import RepairEngine\nfrom evaluate import EvalEngine\n\nlogging.basicConfig(format=""%(asctime)s - [%(levelname)5s] - %(message)s"", datefmt=\'%H:%M:%S\')\nroot_logger = logging.getLogger()\ngensim_logger = logging.getLogger(\'gensim\')\nroot_logger.setLevel(logging.INFO)\ngensim_logger.setLevel(logging.WARNING)\n\n\n# Arguments for HoloClean\narguments = [\n    ((\'-u\', \'--db_user\'),\n        {\'metavar\': \'DB_USER\',\n         \'dest\': \'db_user\',\n         \'default\': \'holocleanuser\',\n         \'type\': str,\n         \'help\': \'User for DB used to persist state.\'}),\n    ((\'-p\', \'--db-pwd\', \'--pass\'),\n        {\'metavar\': \'DB_PWD\',\n         \'dest\': \'db_pwd\',\n         \'default\': \'abcd1234\',\n         \'type\': str,\n         \'help\': \'Password for DB used to persist state.\'}),\n    ((\'-h\', \'--db-host\'),\n        {\'metavar\': \'DB_HOST\',\n         \'dest\': \'db_host\',\n         \'default\': \'localhost\',\n         \'type\': str,\n         \'help\': \'Host for DB used to persist state.\'}),\n    ((\'-d\', \'--db_name\'),\n        {\'metavar\': \'DB_NAME\',\n         \'dest\': \'db_name\',\n         \'default\': \'holo\',\n         \'type\': str,\n         \'help\': \'Name of DB used to persist state.\'}),\n    ((\'-t\', \'--threads\'),\n     {\'metavar\': \'THREADS\',\n      \'dest\': \'threads\',\n      \'default\': 20,\n      \'type\': int,\n      \'help\': \'How many threads to use for parallel execution. If <= 1, then no pool workers are used.\'}),\n    ((\'-dbt\', \'--timeout\'),\n     {\'metavar\': \'TIMEOUT\',\n      \'dest\': \'timeout\',\n      \'default\': 60000,\n      \'type\': int,\n      \'help\': \'Timeout for expensive featurization queries.\'}),\n    ((\'-s\', \'--seed\'),\n     {\'metavar\': \'SEED\',\n      \'dest\': \'seed\',\n      \'default\': 45,\n      \'type\': int,\n      \'help\': \'The seed to be used for torch.\'}),\n    ((\'-l\', \'--learning-rate\'),\n     {\'metavar\': \'LEARNING_RATE\',\n      \'dest\': \'learning_rate\',\n      \'default\': 0.001,\n      \'type\': float,\n      \'help\': \'The learning rate used during training.\'}),\n    ((\'-o\', \'--optimizer\'),\n     {\'metavar\': \'OPTIMIZER\',\n      \'dest\': \'optimizer\',\n      \'default\': \'adam\',\n      \'type\': str,\n      \'help\': \'Optimizer used for learning.\'}),\n    ((\'-e\', \'--epochs\'),\n     {\'metavar\': \'LEARNING_EPOCHS\',\n      \'dest\': \'epochs\',\n      \'default\': 20,\n      \'type\': float,\n      \'help\': \'Number of epochs used for training.\'}),\n    ((\'-w\', \'--weight_decay\'),\n     {\'metavar\': \'WEIGHT_DECAY\',\n      \'dest\':  \'weight_decay\',\n      \'default\': 0.01,\n      \'type\': float,\n      \'help\': \'Weight decay across iterations.\'}),\n    ((\'-m\', \'--momentum\'),\n     {\'metavar\': \'MOMENTUM\',\n      \'dest\': \'momentum\',\n      \'default\': 0.0,\n      \'type\': float,\n      \'help\': \'Momentum for SGD.\'}),\n    ((\'-b\', \'--batch-size\'),\n     {\'metavar\': \'BATCH_SIZE\',\n      \'dest\': \'batch_size\',\n      \'default\': 1,\n      \'type\': int,\n      \'help\': \'The batch size during training.\'}),\n    ((\'-wlt\', \'--weak-label-thresh\'),\n     {\'metavar\': \'WEAK_LABEL_THRESH\',\n      \'dest\': \'weak_label_thresh\',\n      \'default\': 0.90,\n      \'type\': float,\n      \'help\': \'Threshold of posterior probability to assign weak labels.\'}),\n    ((\'-dt1\', \'--domain_thresh_1\'),\n     {\'metavar\': \'DOMAIN_THRESH_1\',\n      \'dest\': \'domain_thresh_1\',\n      \'default\': 0.1,\n      \'type\': float,\n      \'help\': \'Minimum co-occurrence probability threshold required for domain values in the first domain pruning stage. Between 0 and 1.\'}),\n    ((\'-dt2\', \'--domain-thresh-2\'),\n     {\'metavar\': \'DOMAIN_THRESH_2\',\n      \'dest\': \'domain_thresh_2\',\n      \'default\': 0,\n      \'type\': float,\n      \'help\': \'Threshold of posterior probability required for values to be included in the final domain in the second domain pruning stage. Between 0 and 1.\'}),\n    ((\'-md\', \'--max-domain\'),\n     {\'metavar\': \'MAX_DOMAIN\',\n      \'dest\': \'max_domain\',\n      \'default\': 1000000,\n      \'type\': int,\n      \'help\': \'Maximum number of values to include in the domain for a given cell.\'}),\n    ((\'-cs\', \'--cor-strength\'),\n     {\'metavar\': \'COR_STRENGTH\',\n      \'dest\': \'cor_strength\',\n      \'default\': 0.05,\n      \'type\': float,\n      \'help\': \'Correlation threshold (absolute) when selecting correlated attributes for domain pruning.\'}),\n    ((\'-cs\', \'--nb-cor-strength\'),\n     {\'metavar\': \'NB_COR_STRENGTH\',\n      \'dest\': \'nb_cor_strength\',\n      \'default\': 0.3,\n      \'type\': float,\n      \'help\': \'Correlation threshold for correlated attributes when using NaiveBayes estimator.\'}),\n    ((\'-fn\', \'--feature-norm\'),\n     {\'metavar\': \'FEATURE_NORM\',\n      \'dest\': \'feature_norm\',\n      \'default\': True,\n      \'type\': bool,\n      \'help\': \'Normalize the features before training.\'}),\n    ((\'-wn\', \'--weight_norm\'),\n     {\'metavar\': \'WEIGHT_NORM\',\n      \'dest\': \'weight_norm\',\n      \'default\': False,\n      \'type\': bool,\n      \'help\': \'Normalize the weights after every forward pass during training.\'}),\n    ((\'-ee\', \'--estimator_epochs\'),\n     {\'metavar\': \'ESTIMATOR_EPOCHS\',\n      \'dest\': \'estimator_epochs\',\n      \'default\': 3,\n      \'type\': int,\n      \'help\': \'Number of epochs to run the weak labelling and domain generation estimator.\'}),\n    ((\'-ebs\', \'--estimator_batch_size\'),\n     {\'metavar\': \'ESTIMATOR_BATCH_SIZE\',\n      \'dest\': \'estimator_batch_size\',\n      \'default\': 32,\n      \'type\': int,\n      \'help\': \'Size of batch used in SGD in the weak labelling and domain generation estimator.\'}),\n]\n\n# Flags for Holoclean mode\nflags = [\n    (tuple([\'--verbose\']),\n        {\'default\': False,\n         \'dest\': \'verbose\',\n         \'action\': \'store_true\',\n         \'help\': \'verbose\'}),\n    (tuple([\'--bias\']),\n        {\'default\': False,\n         \'dest\': \'bias\',\n         \'action\': \'store_true\',\n         \'help\': \'Use bias term\'}),\n    (tuple([\'--printfw\']),\n        {\'default\': False,\n         \'dest\': \'print_fw\',\n         \'action\': \'store_true\',\n         \'help\': \'print the weights of featurizers\'}),\n    (tuple([\'--debug-mode\']),\n        {\'default\': False,\n         \'dest\': \'debug_mode\',\n         \'action\': \'store_true\',\n         \'help\': \'dump a bunch of debug information to debug\\/\'}),\n]\n\n\nclass HoloClean:\n    """"""\n    Main entry point for HoloClean.\n    It creates a HoloClean Data Engine\n    """"""\n\n    def __init__(self, **kwargs):\n        """"""\n        Constructor for Holoclean\n        :param kwargs: arguments for HoloClean\n        """"""\n\n        # Initialize default execution arguments\n        arg_defaults = {}\n        for arg, opts in arguments:\n            if \'directory\' in arg[0]:\n                arg_defaults[\'directory\'] = opts[\'default\']\n            else:\n                arg_defaults[opts[\'dest\']] = opts[\'default\']\n\n        # Initialize default execution flags\n        for arg, opts in flags:\n            arg_defaults[opts[\'dest\']] = opts[\'default\']\n\n        # check env vars\n        for arg, opts in arguments:\n            # if env var is set use that\n            if opts[""metavar""] and opts[""metavar""] in os.environ.keys():\n                logging.debug(\n                    ""Overriding {} with env varible {} set to {}"".format(\n                        opts[\'dest\'],\n                        opts[""metavar""],\n                        os.environ[opts[""metavar""]])\n                )\n                arg_defaults[opts[\'dest\']] = os.environ[opts[""metavar""]]\n\n        # Override defaults with manual flags\n        for key in kwargs:\n            arg_defaults[key] = kwargs[key]\n\n        # Initialize additional arguments\n        for (arg, default) in arg_defaults.items():\n            setattr(self, arg, kwargs.get(arg, default))\n\n        # Init empty session collection\n        self.session = Session(arg_defaults)\n\n\nclass Session:\n    """"""\n    Session class controls the entire pipeline of HC\n    """"""\n\n    def __init__(self, env, name=""session""):\n        """"""\n        Constructor for Holoclean session\n        :param env: Holoclean environment\n        :param name: Name for the Holoclean session\n        """"""\n        # use DEBUG logging level if verbose enabled\n        if env[\'verbose\']:\n            root_logger.setLevel(logging.DEBUG)\n            gensim_logger.setLevel(logging.DEBUG)\n\n        logging.debug(\'initiating session with parameters: %s\', env)\n\n        # Initialize random seeds.\n        random.seed(env[\'seed\'])\n        torch.manual_seed(env[\'seed\'])\n        np.random.seed(seed=env[\'seed\'])\n\n        # Initialize members\n        self.name = name\n        self.env = env\n        self.ds = Dataset(name, env)\n        self.dc_parser = Parser(env, self.ds)\n        self.domain_engine = DomainEngine(env, self.ds)\n        self.detect_engine = DetectEngine(env, self.ds)\n        self.repair_engine = RepairEngine(env, self.ds)\n        self.eval_engine = EvalEngine(env, self.ds)\n\n\n    def load_data(self, name, fpath, na_values=None, entity_col=None, src_col=None):\n        """"""\n        load_data takes the filepath to a CSV file to load as the initial dataset.\n\n        :param name: (str) name to initialize dataset with.\n        :param fpath: (str) filepath to CSV file.\n        :param na_values: (str) value that identifies a NULL value\n        :param entity_col: (st) column containing the unique\n            identifier/ID of an entity.  For fusion tasks, rows with\n            the same ID will be fused together in the output.\n            If None, assumes every row is a unique entity.\n        :param src_col: (str) if not None, for fusion tasks\n            specifies the column containing the source for each ""mention"" of an\n            entity.\n        """"""\n        status, load_time = self.ds.load_data(name,\n                                              fpath,\n                                              na_values=na_values,\n                                              entity_col=entity_col,\n                                              src_col=src_col)\n        logging.info(status)\n        logging.debug(\'Time to load dataset: %.2f secs\', load_time)\n\n    def load_dcs(self, fpath):\n        """"""\n        load_dcs ingests the Denial Constraints for initialized dataset.\n\n        :param fpath: filepath to TXT file where each line contains one denial constraint.\n        """"""\n        status, load_time = self.dc_parser.load_denial_constraints(fpath)\n        logging.info(status)\n        logging.debug(\'Time to load dirty data: %.2f secs\', load_time)\n\n    def get_dcs(self):\n        return self.dc_parser.get_dcs()\n\n    def detect_errors(self, detect_list):\n        status, detect_time = self.detect_engine.detect_errors(detect_list)\n        logging.info(status)\n        logging.debug(\'Time to detect errors: %.2f secs\', detect_time)\n\n    def setup_domain(self):\n        status, domain_time = self.domain_engine.setup()\n        logging.info(status)\n        logging.debug(\'Time to setup the domain: %.2f secs\', domain_time)\n\n    def repair_errors(self, featurizers):\n        status, feat_time = self.repair_engine.setup_featurized_ds(featurizers)\n        logging.info(status)\n        logging.debug(\'Time to featurize data: %.2f secs\', feat_time)\n        status, setup_time = self.repair_engine.setup_repair_model()\n        logging.info(status)\n        logging.debug(\'Time to setup repair model: %.2f secs\', feat_time)\n        status, fit_time = self.repair_engine.fit_repair_model()\n        logging.info(status)\n        logging.debug(\'Time to fit repair model: %.2f secs\', fit_time)\n        status, infer_time = self.repair_engine.infer_repairs()\n        logging.info(status)\n        logging.debug(\'Time to infer correct cell values: %.2f secs\', infer_time)\n        status, time = self.ds.get_inferred_values()\n        logging.info(status)\n        logging.debug(\'Time to collect inferred values: %.2f secs\', time)\n        status, time = self.ds.get_repaired_dataset()\n        logging.info(status)\n        logging.debug(\'Time to store repaired dataset: %.2f secs\', time)\n        if self.env[\'print_fw\']:\n            status, time = self.repair_engine.get_featurizer_weights()\n            logging.info(status)\n            logging.debug(\'Time to store featurizer weights: %.2f secs\', time)\n            return status\n\n    def evaluate(self, fpath, tid_col, attr_col, val_col, na_values=None):\n        """"""\n        evaluate generates an evaluation report with metrics (e.g. precision,\n        recall) given a test set.\n\n        :param fpath: (str) filepath to test set (ground truth) CSV file.\n        :param tid_col: (str) column in CSV that corresponds to the TID.\n        :param attr_col: (str) column in CSV that corresponds to the attribute.\n        :param val_col: (str) column in CSV that corresponds to correct value\n            for the current TID and attribute (i.e. cell).\n        :param na_values: (Any) how na_values are represented in the data.\n\n        Returns an EvalReport named tuple containing the experiment results.\n        """"""\n        name = self.ds.raw_data.name + \'_clean\'\n        status, load_time = self.eval_engine.load_data(name, fpath, tid_col, attr_col, val_col, na_values=na_values)\n        logging.info(status)\n        logging.debug(\'Time to evaluate repairs: %.2f secs\', load_time)\n        status, report_time, eval_report = self.eval_engine.eval_report()\n        logging.info(status)\n        logging.debug(\'Time to generate report: %.2f secs\', report_time)\n        return eval_report\n'"
utils.py,0,"b'# Some constants.\n\n# How we represent nulls in holoclean.\nNULL_REPR = \'_nan_\'\n\n# A feature value to represent co-occurrence with NULLs, which is not applicable.\nNA_COOCCUR_FV = 0\n\n\ndef dictify_df(frame):\n    """"""\n    dictify_df converts a frame with columns\n\n      col1    | col2    | .... | coln   | value\n      ...\n    to a dictionary that maps values valX from colX\n\n    { val1 -> { val2 -> { ... { valn -> value } } } }\n    """"""\n    ret = {}\n    for row in frame.values:\n        cur_level = ret\n        for elem in row[:-2]:\n            if elem not in cur_level:\n                cur_level[elem] = {}\n            cur_level = cur_level[elem]\n        cur_level[row[-2]] = row[-1]\n    return ret\n'"
dataset/__init__.py,0,"b""from .dataset import Dataset\nfrom .dataset import AuxTables\nfrom .dataset import CellStatus\n\n__all__ = ['Dataset', 'AuxTables', 'CellStatus']\n"""
dataset/dataset.py,0,"b'from enum import Enum\nimport logging\nimport os\nimport time\n\nimport pandas as pd\n\nfrom .dbengine import DBengine\nfrom .table import Table, Source\nfrom utils import dictify_df, NULL_REPR\n\n\nclass AuxTables(Enum):\n    c_cells        = 1\n    dk_cells       = 2\n    cell_domain    = 3\n    pos_values     = 4\n    cell_distr     = 5\n    inf_values_idx = 6\n    inf_values_dom = 7\n\n\nclass CellStatus(Enum):\n    NOT_SET        = 0\n    WEAK_LABEL     = 1\n    SINGLE_VALUE   = 2\n\n\nclass Dataset:\n    """"""\n    This class keeps all dataframes and tables for a HC session.\n    """"""\n    def __init__(self, name, env):\n        self.id = name\n        self.raw_data = None\n        self.repaired_data = None\n        self.constraints = None\n        self.aux_table = {}\n        for tab in AuxTables:\n            self.aux_table[tab] = None\n        # start dbengine\n        self.engine = DBengine(\n            env[\'db_user\'],\n            env[\'db_pwd\'],\n            env[\'db_name\'],\n            env[\'db_host\'],\n            pool_size=env[\'threads\'],\n            timeout=env[\'timeout\']\n        )\n        # members to convert (tuple_id, attribute) to cell_id\n        self.attr_to_idx = {}\n        self.attr_count = 0\n        # dataset statistics\n        self.stats_ready = False\n        # Total tuples\n        self.total_tuples = 0\n        # Domain stats for single attributes\n        self.single_attr_stats = {}\n        # Domain stats for attribute pairs\n        self.pair_attr_stats = {}\n\n    # TODO(richardwu): load more than just CSV files\n    def load_data(self, name, fpath, na_values=None, entity_col=None, src_col=None):\n        """"""\n        load_data takes a CSV file of the initial data, adds tuple IDs (_tid_)\n        to each row to uniquely identify an \'entity\', and generates unique\n        index numbers for each attribute/column.\n\n        Creates a table with the user supplied \'name\' parameter (e.g. \'hospital\').\n\n        :param name: (str) name to initialize dataset with.\n        :param fpath: (str) filepath to CSV file.\n        :param na_values: (str) value that identifies a NULL value\n        :param entity_col: (str) column containing the unique\n            identifier/ID of an entity.  For fusion tasks, rows with\n            the same ID will be fused together in the output.\n            If None, assumes every row is a unique entity.\n        :param src_col: (str) if not None, for fusion tasks\n            specifies the column containing the source for each ""mention"" of an\n            entity.\n        """"""\n        tic = time.clock()\n        try:\n            # Do not include TID and source column as trainable attributes\n            exclude_attr_cols = [\'_tid_\']\n            if src_col is not None:\n                exclude_attr_cols.append(src_col)\n\n            # Load raw CSV file/data into a Postgres table \'name\' (param).\n            self.raw_data = Table(name, Source.FILE, na_values=na_values, exclude_attr_cols=exclude_attr_cols, fpath=fpath)\n\n            df = self.raw_data.df\n            # Add _tid_ column to dataset that uniquely identifies an entity.\n            # If entity_col is not supplied, use auto-incrementing values.\n            # Otherwise we use the entity values directly as _tid_\'s.\n            if entity_col is None:\n                # auto-increment\n                df.insert(0, \'_tid_\', range(0,len(df)))\n            else:\n                # use entity IDs as _tid_\'s directly\n                df.rename({entity_col: \'_tid_\'}, axis=\'columns\', inplace=True)\n\n            # Use NULL_REPR to represent NULL values\n            df.fillna(NULL_REPR, inplace=True)\n\n            logging.info(""Loaded %d rows with %d cells"", self.raw_data.df.shape[0], self.raw_data.df.shape[0] * self.raw_data.df.shape[1])\n\n            # Call to store to database\n            self.raw_data.store_to_db(self.engine.engine)\n            status = \'DONE Loading {fname}\'.format(fname=os.path.basename(fpath))\n\n            # Generate indexes on attribute columns for faster queries\n            for attr in self.raw_data.get_attributes():\n                # Generate index on attribute\n                self.raw_data.create_db_index(self.engine,[attr])\n\n            # Create attr_to_idx dictionary (assign unique index for each attribute)\n            # and attr_count (total # of attributes)\n            self.attr_to_idx = {attr: idx for idx, attr in enumerate(self.raw_data.get_attributes())}\n            self.attr_count = len(self.attr_to_idx)\n        except Exception:\n            logging.error(\'loading data for table %s\', name)\n            raise\n        toc = time.clock()\n        load_time = toc - tic\n        return status, load_time\n\n    def set_constraints(self, constraints):\n        self.constraints = constraints\n\n    def generate_aux_table(self, aux_table, df, store=False, index_attrs=False):\n        """"""\n        generate_aux_table writes/overwrites the auxiliary table specified by\n        \'aux_table\'.\n\n        It does:\n          1. stores/replaces the specified aux_table into Postgres (store=True), AND/OR\n          2. sets an index on the aux_table\'s internal Pandas DataFrame (index_attrs=[<columns>]), AND/OR\n          3. creates Postgres indexes for aux_table (store=True and index_attrs=[<columns>])\n\n        :param aux_table: (AuxTable) auxiliary table to generate\n        :param df: (DataFrame) dataframe to memoize/store for this auxiliary table\n        :param store: (bool) if true, creates/replaces Postgres table for this auxiliary table\n        :param index_attrs: (list[str]) list of attributes to create indexes on. If store is true,\n        also creates indexes on Postgres table.\n        """"""\n        try:\n            self.aux_table[aux_table] = Table(aux_table.name, Source.DF, df=df)\n            if store:\n                self.aux_table[aux_table].store_to_db(self.engine.engine)\n            if index_attrs:\n                self.aux_table[aux_table].create_df_index(index_attrs)\n            if store and index_attrs:\n                self.aux_table[aux_table].create_db_index(self.engine, index_attrs)\n        except Exception:\n            logging.error(\'generating aux_table %s\', aux_table.name)\n            raise\n\n    def generate_aux_table_sql(self, aux_table, query, index_attrs=False):\n        """"""\n        :param aux_table: (AuxTable) auxiliary table to generate\n        :param query: (str) SQL query whose result is used for generating the auxiliary table.\n        """"""\n        try:\n            self.aux_table[aux_table] = Table(aux_table.name, Source.SQL, table_query=query, db_engine=self.engine)\n            if index_attrs:\n                self.aux_table[aux_table].create_df_index(index_attrs)\n                self.aux_table[aux_table].create_db_index(self.engine, index_attrs)\n        except Exception:\n            logging.error(\'generating aux_table %s\', aux_table.name)\n            raise\n\n    def get_raw_data(self):\n        """"""\n        get_raw_data returns a pandas.DataFrame containing the raw data as it was initially loaded.\n        """"""\n        if self.raw_data is None:\n            raise Exception(\'ERROR No dataset loaded\')\n        return self.raw_data.df\n\n    def get_attributes(self):\n        """"""\n        get_attributes return the trainable/learnable attributes (i.e. exclude meta\n        columns like _tid_).\n        """"""\n        if self.raw_data is None:\n            raise Exception(\'ERROR No dataset loaded\')\n        return self.raw_data.get_attributes()\n\n    def get_cell_id(self, tuple_id, attr_name):\n        """"""\n        get_cell_id returns cell ID: a unique ID for every cell.\n\n        Cell ID: _tid_ * (# of attributes) + attr_idx\n        """"""\n        vid = tuple_id*self.attr_count + self.attr_to_idx[attr_name]\n        return vid\n\n    def get_statistics(self):\n        """"""\n        get_statistics returns:\n            1. self.total_tuples (total # of tuples)\n            2. self.single_attr_stats ({ attribute -> { value -> count } })\n              the frequency (# of entities) of a given attribute-value\n            3. self.pair_attr_stats ({ attr1 -> { attr2 -> {val1 -> {val2 -> count } } } })\n              the statistics for each pair of attributes, attr1 and attr2, where:\n                <attr1>: first attribute\n                <attr2>: second attribute\n                <val1>: all values of <attr1>\n                <val2>: values of <attr2> that appear at least once with <val1>.\n                <count>: frequency (# of entities) where attr1=val1 AND attr2=val2\n\n        NB: neither single_attr_stats nor pair_attr_stats contain frequencies\n            for values that are NULL (NULL_REPR). One would need to explicitly\n            check if the value is NULL before lookup.\n\n            Also, values that only co-occur with NULLs will NOT be in pair_attr_stats.\n        """"""\n        if not self.stats_ready:\n            logging.debug(\'computing frequency and co-occurrence statistics from raw data...\')\n            tic = time.clock()\n            self.collect_stats()\n            logging.debug(\'DONE computing statistics in %.2fs\', time.clock() - tic)\n\n        stats = (self.total_tuples, self.single_attr_stats, self.pair_attr_stats)\n        self.stats_ready = True\n        return stats\n\n    def collect_stats(self):\n        """"""\n        collect_stats memoizes:\n          1. self.single_attr_stats ({ attribute -> { value -> count } })\n            the frequency (# of entities) of a given attribute-value\n          2. self.pair_attr_stats ({ attr1 -> { attr2 -> {val1 -> {val2 -> count } } } })\n            where DataFrame contains 3 columns:\n              <attr1>: all possible values for attr1 (\'val1\')\n              <attr2>: all values for attr2 that appeared at least once with <val1> (\'val2\')\n              <count>: frequency (# of entities) where attr1: val1 AND attr2: val2\n            Also known as co-occurrence count.\n        """"""\n        logging.debug(""Collecting single/pair-wise statistics..."")\n        self.total_tuples = self.get_raw_data().shape[0]\n        # Single attribute-value frequency.\n        for attr in self.get_attributes():\n            self.single_attr_stats[attr] = self.get_stats_single(attr)\n        # Compute co-occurrence frequencies.\n        for cond_attr in self.get_attributes():\n            self.pair_attr_stats[cond_attr] = {}\n            for trg_attr in self.get_attributes():\n                if trg_attr != cond_attr:\n                    self.pair_attr_stats[cond_attr][trg_attr] = self.get_stats_pair(cond_attr, trg_attr)\n\n    def get_stats_single(self, attr):\n        """"""\n        Returns a dictionary where the keys are domain values for :param attr: and\n        the values contain the frequency count of that value for this attribute.\n        """"""\n        # need to decode values into unicode strings since we do lookups via\n        # unicode strings from Postgres\n        data_df = self.get_raw_data()\n        return data_df[[attr]].loc[data_df[attr] != NULL_REPR].groupby([attr]).size().to_dict()\n\n    def get_stats_pair(self, first_attr, second_attr):\n        """"""\n        Returns a dictionary {first_val -> {second_val -> count } } where:\n            <first_val>: all possible values for first_attr\n            <second_val>: all values for second_attr that appear at least once with <first_val>\n            <count>: frequency (# of entities) where first_attr=<first_val> AND second_attr=<second_val>\n        Filters out NULL values so no entries in the dictionary would have NULLs.\n        """"""\n        data_df = self.get_raw_data()\n        tmp_df = data_df[[first_attr, second_attr]]\\\n            .loc[(data_df[first_attr] != NULL_REPR) & (data_df[second_attr] != NULL_REPR)]\\\n            .groupby([first_attr, second_attr])\\\n            .size()\\\n            .reset_index(name=""count"")\n        return dictify_df(tmp_df)\n\n    def get_domain_info(self):\n        """"""\n        Returns (number of random variables, count of distinct values across all attributes).\n        """"""\n        query = \'SELECT count(_vid_), max(domain_size) FROM %s\'%AuxTables.cell_domain.name\n        res = self.engine.execute_query(query)\n        total_vars = int(res[0][0])\n        classes = int(res[0][1])\n        return total_vars, classes\n\n    def get_inferred_values(self):\n        tic = time.clock()\n        # index into domain with inferred_val_idx + 1 since SQL arrays begin at index 1.\n        query = ""SELECT t1._tid_, t1.attribute, domain[inferred_val_idx + 1] as rv_value "" \\\n                ""FROM "" \\\n                ""(SELECT _tid_, attribute, "" \\\n                ""_vid_, init_value, string_to_array(regexp_replace(domain, \\\'[{\\""\\""}]\\\', \\\'\\\', \\\'gi\\\'), \\\'|||\\\') as domain "" \\\n                ""FROM %s) as t1, %s as t2 "" \\\n                ""WHERE t1._vid_ = t2._vid_""%(AuxTables.cell_domain.name, AuxTables.inf_values_idx.name)\n        self.generate_aux_table_sql(AuxTables.inf_values_dom, query, index_attrs=[\'_tid_\'])\n        self.aux_table[AuxTables.inf_values_dom].create_db_index(self.engine, [\'attribute\'])\n        status = ""DONE collecting the inferred values.""\n        toc = time.clock()\n        total_time = toc - tic\n        return status, total_time\n\n    def get_repaired_dataset(self):\n        tic = time.clock()\n        init_records = self.raw_data.df.sort_values([\'_tid_\']).to_records(index=False)\n        t = self.aux_table[AuxTables.inf_values_dom]\n        repaired_vals = dictify_df(t.df.reset_index())\n        for tid in repaired_vals:\n            for attr in repaired_vals[tid]:\n                init_records[tid][attr] = repaired_vals[tid][attr]\n        repaired_df = pd.DataFrame.from_records(init_records)\n        name = self.raw_data.name+\'_repaired\'\n        self.repaired_data = Table(name, Source.DF, df=repaired_df)\n        self.repaired_data.store_to_db(self.engine.engine)\n        status = ""DONE generating repaired dataset""\n        toc = time.clock()\n        total_time = toc - tic\n        return status, total_time\n'"
dataset/dbengine.py,0,"b'from functools import partial\nimport logging\nfrom multiprocessing import Pool\nfrom string import Template\nimport time\n\nimport psycopg2\nimport sqlalchemy as sql\n\nindex_template = Template(\'CREATE INDEX $idx_title ON ""$table"" ($attrs)\')\ndrop_table_template = Template(\'DROP TABLE IF EXISTS ""$table""\')\ncreate_table_template = Template(\'CREATE TABLE ""$table"" AS ($stmt)\')\n\n\nclass DBengine:\n    """"""\n    A wrapper class for postgresql engine.\n    Maintains connections and executes queries.\n    """"""\n    def __init__(self, user, pwd, db, host=\'localhost\', port=5432, pool_size=20, timeout=60000):\n        self.timeout = timeout\n        self._pool = Pool(pool_size) if pool_size > 1 else None\n        url = \'postgresql+psycopg2://{}:{}@{}:{}/{}?client_encoding=utf8\'\n        url = url.format(user, pwd, host, port, db)\n        self.conn = url\n        con = \'dbname={} user={} password={} host={} port={}\'\n        con = con.format(db, user, pwd, host, port)\n        self.conn_args = con\n        self.engine = sql.create_engine(url, client_encoding=\'utf8\', pool_size=pool_size)\n\n    def execute_queries(self, queries):\n        """"""\n        Executes :param queries: in parallel.\n\n        :param queries: (list[str]) list of SQL queries to be executed\n        """"""\n        logging.debug(\'Preparing to execute %d queries.\', len(queries))\n        tic = time.clock()\n        results = self._apply_func(partial(_execute_query, conn_args=self.conn_args), [(idx, q) for idx, q in enumerate(queries)])\n        toc = time.clock()\n        logging.debug(\'Time to execute %d queries: %.2f secs\', len(queries), toc-tic)\n        return results\n\n    def execute_queries_w_backup(self, queries):\n        """"""\n        Executes :param queries: that have backups in parallel. Used in featurization.\n\n        :param queries: (list[str]) list of SQL queries to be executed\n        """"""\n        logging.debug(\'Preparing to execute %d queries.\', len(queries))\n        tic = time.clock()\n        results = self._apply_func(\n            partial(_execute_query_w_backup, conn_args=self.conn_args, timeout=self.timeout),\n            [(idx, q) for idx, q in enumerate(queries)])\n        toc = time.clock()\n        logging.debug(\'Time to execute %d queries: %.2f secs\', len(queries), toc-tic)\n        return results\n\n    def execute_query(self, query):\n        """"""\n        Executes a single :param query: using current connection.\n\n        :param query: (str) SQL query to be executed\n        """"""\n        tic = time.clock()\n        conn = self.engine.connect()\n        result = conn.execute(query).fetchall()\n        conn.close()\n        toc = time.clock()\n        logging.debug(\'Time to execute query: %.2f secs\', toc-tic)\n        return result\n\n    def create_db_table_from_query(self, name, query):\n        tic = time.clock()\n        drop = drop_table_template.substitute(table=name)\n        create = create_table_template.substitute(table=name, stmt=query)\n        conn = self.engine.connect()\n        conn.execute(drop)\n        conn.execute(create)\n        conn.close()\n        toc = time.clock()\n        logging.debug(\'Time to create table: %.2f secs\', toc-tic)\n        return True\n\n    def create_db_index(self, name, table, attr_list):\n        """"""\n        create_db_index creates a (multi-column) index on the columns/attributes\n        specified in :param attr_list: with the given :param name: on\n        :param table:.\n\n        :param name: (str) name of index\n        :param table: (str) name of table\n        :param attr_list: (list[str]) list of attributes/columns to create index on\n        """"""\n        # We need to quote each attribute since Postgres auto-downcases unquoted column references\n        quoted_attrs = map(lambda attr: \'""{}""\'.format(attr), attr_list)\n        stmt = index_template.substitute(idx_title=name, table=table, attrs=\',\'.join(quoted_attrs))\n        tic = time.clock()\n        conn = self.engine.connect()\n        result = conn.execute(stmt)\n        conn.close()\n        toc = time.clock()\n        logging.debug(\'Time to create index: %.2f secs\', toc-tic)\n        return result\n\n    def _apply_func(self, func, collection):\n        if self._pool is None:\n            return list(map(func, collection))\n        return self._pool.map(func, collection)\n\n\ndef _execute_query(args, conn_args):\n    query_id = args[0]\n    query = args[1]\n    logging.debug(""Starting to execute query %s with id %s"", query, query_id)\n    tic = time.clock()\n    con = psycopg2.connect(conn_args)\n    cur = con.cursor()\n    cur.execute(query)\n    res = cur.fetchall()\n    con.close()\n    toc = time.clock()\n    logging.debug(\'Time to execute query with id %d: %.2f secs\', query_id, (toc - tic))\n    return res\n\n\ndef _execute_query_w_backup(args, conn_args, timeout):\n    query_id = args[0]\n    query = args[1][0]\n    query_backup = args[1][1]\n    logging.debug(""Starting to execute query %s with id %s"", query, query_id)\n    tic = time.clock()\n    con = psycopg2.connect(conn_args)\n    cur = con.cursor()\n    cur.execute(""SET statement_timeout to %d;""%timeout)\n    try:\n        cur.execute(query)\n        res = cur.fetchall()\n    except psycopg2.extensions.QueryCanceledError as e:\n        logging.debug(""Failed to execute query %s with id %s. Timeout reached."", query, query_id)\n\n        # No backup query, simply return empty result\n        if not query_backup:\n            logging.warn(""no backup query to execute, returning empty query results"")\n            return []\n\n        logging.debug(""Starting to execute backup query %s with id %s"", query_backup, query_id)\n        con.close()\n        con = psycopg2.connect(conn_args)\n        cur = con.cursor()\n        cur.execute(query_backup)\n        res = cur.fetchall()\n        con.close()\n    toc = time.clock()\n    logging.debug(\'Time to execute query with id %d: %.2f secs\', query_id, toc - tic)\n    return res\n'"
dataset/table.py,0,"b'from enum import Enum\nimport logging\n\nimport pandas as pd\n\n\nclass Source(Enum):\n    FILE = 1\n    DF   = 2\n    DB   = 3\n    SQL  = 4\n\n\nclass Table:\n    """"""\n    A wrapper class for Dataset Tables.\n    """"""\n    def __init__(self, name, src, na_values=None, exclude_attr_cols=[\'_tid_\'],\n            fpath=None, df=None, schema_name=None, table_query=None, db_engine=None):\n        """"""\n        :param name: (str) name to assign to dataset.\n        :param na_values: (str or list[str]) values to interpret as NULL.\n        :param exclude_attr_cols: (list[str]) list of columns to NOT treat as\n            attributes during training/learning.\n        :param src: (Source) type of source to load from. Note additional\n            parameters MUST be provided for each specific source:\n                Source.FILE: :param fpath:, read from CSV file\n                Source.DF: :param df:, read from pandas DataFrame\n                Source.DB: :param db_engine:, read from database table with :param name:\n                Source.SQL: :param table_query: and :param db_engine:, use result\n                    from :param table_query:\n\n        :param fpath: (str) File path to CSV file containing raw data\n        :param df: (pandas.DataFrame) DataFrame contain the raw ingested data\n        :param schema_name: (str) Schema used while loading Source.DB\n        :param table_query: (str) sql query to construct table from\n        :param db_engine: (DBEngine) database engine object\n        """"""\n        self.name = name\n        self.index_count = 0\n        # Copy the list to memoize\n        self.exclude_attr_cols = list(exclude_attr_cols)\n        self.df = pd.DataFrame()\n\n        if src == Source.FILE:\n            if fpath is None:\n                raise Exception(""ERROR while loading table. File path for CSV file name expected. Please provide <fpath> param."")\n            # TODO(richardwu): use COPY FROM instead of loading this into memory\n            # TODO(richardwu): No support for numerical values. To be added.\n            self.df = pd.read_csv(fpath, dtype=str, na_values=na_values, encoding=\'utf-8\')\n            # Normalize the dataframe: drop null columns, convert to lowercase strings, and strip whitespaces.\n            for attr in self.df.columns.values:\n                if self.df[attr].isnull().all():\n                    logging.warning(""Dropping the following null column from the dataset: \'%s\'"", attr)\n                    self.df.drop(labels=[attr], axis=1, inplace=True)\n                    continue\n                if attr not in exclude_attr_cols:\n                    self.df[attr] = self.df[attr].str.strip().str.lower()\n        elif src == Source.DF:\n            if df is None:\n                raise Exception(""ERROR while loading table. Dataframe expected. Please provide <df> param."")\n            self.df = df\n        elif src == Source.DB:\n            if db_engine is None:\n                raise Exception(""ERROR while loading table. DB connection expected. Please provide <db_engine>."")\n            self.df = pd.read_sql_table(name, db_engine.conn, schema=schema_name)\n        elif src == Source.SQL:\n            if table_query is None or db_engine is None:\n                raise Exception(""ERROR while loading table. SQL Query and DB connection expected. Please provide <table_query> and <db_engine>."")\n            db_engine.create_db_table_from_query(self.name, table_query)\n            self.df = pd.read_sql_table(name, db_engine.conn)\n\n    def store_to_db(self, db_conn, if_exists=\'replace\', index=False, index_label=None):\n        # TODO: This version supports single session, single worker.\n        self.df.to_sql(self.name, db_conn, if_exists=if_exists, index=index, index_label=index_label)\n\n    def get_attributes(self):\n        """"""\n        get_attributes returns the columns that are trainable/learnable attributes\n        (i.e. exclude meta-columns like _tid_).\n        """"""\n        if self.df.empty:\n            raise Exception(""Empty Dataframe associated with table {name}. Cannot return attributes."".format(\n                name=self.name))\n        return list(col for col in self.df.columns if col not in self.exclude_attr_cols)\n\n    def create_df_index(self, attr_list):\n        self.df.set_index(attr_list, inplace=True)\n\n    def create_db_index(self, db_engine, attr_list):\n        index_name = \'{name}_{idx}\'.format(name=self.name, idx=self.index_count)\n        db_engine.create_db_index(index_name, self.name, attr_list)\n        self.index_count += 1\n'"
dcparser/__init__.py,0,"b""from .dcparser import Parser\n\n__all__ = ['Parser']\n"""
dcparser/constraint.py,0,"b'import logging\n\noperationsArr = [\'<>\', \'<=\', \'>=\', \'=\', \'<\', \'>\']\noperationSign = [\'IQ\', \'LTE\', \'GTE\', \'EQ\', \'LT\', \'GT\']\n\n\ndef is_symmetric(operation):\n    if operation in set([\'<>\', \'=\']):\n        return True\n    return False\n\n\ndef get_flip_operation(operation):\n    if operation == \'<=\':\n        return \'>=\'\n    elif operation == \'>=\':\n        return \'<=\'\n    elif operation == \'<\':\n        return \'>\'\n    elif operation == \'>\':\n        return \'<\'\n    else:\n        return operation\n\n\ndef contains_operation(string):\n    """"""\n    Method to check if a given string contains one of the operation signs.\n\n    :param string: given string\n    :return: operation index in list of pre-defined list of operations or\n    Null if string does not contain any\n    """"""\n    for i in range(len(operationSign)):\n        if string.find(operationSign[i]) != -1:\n            return i\n    return None\n\n\nclass DenialConstraint:\n    """"""\n    Class that defines the denial constraints.\n    """"""\n    def __init__(self, dc_string, schema):\n        """"""\n        Constructing denial constraint object.\n        This class contains a list of predicates and the tuple_names which define a Denial Constraint\n\n        :param dc_string: (str) string for denial constraint\n        :param schema: (list[str]) list of attribute\n        """"""\n        dc_string = dc_string.replace(\'""\', ""\'"")\n        split = dc_string.split(\'&\')\n        self.tuple_names = []\n        self.predicates = []\n        self.cnf_form = """"\n        self.components = []\n\n        # Find all tuple names used in DC\n        logging.debug(\'DONE pre-processing constraint: %s\', dc_string)\n        for component in split:\n            if contains_operation(component):\n                break\n            else:\n                self.tuple_names.append(component)\n        logging.debug(\'DONE extracting tuples from constraint: %s\', dc_string)\n\n        # Make a predicate for each component that\'s not a tuple name\n        for i in range(len(self.tuple_names), len(split)):\n            try:\n                self.predicates.append(Predicate(split[i], self.tuple_names, schema))\n            except Exception:\n                logging.error(\'predicate %s\', split[i])\n                raise\n        for p in self.predicates:\n            self.components.append(p.components[0][1])\n\n        # Create CNF form of the DC\n        cnf_forms = [predicate.cnf_form for predicate in self.predicates]\n        self.cnf_form = "" AND "".join(cnf_forms)\n\n\nclass Predicate:\n    """"""\n    This class represents predicates.\n    """"""\n    def __init__(self, predicate_string, tuple_names, schema):\n        """"""\n        Constructing predicate object by setting self.cnf_form to e.g. t1.""Attribute"" = t2.""Attribute"".\n\n        :param predicate_string: string shows the predicate\n        :param tuple_names: name of tuples in denial constraint\n        :param schema: list of attributes\n        """"""\n        self.schema = schema\n        self.tuple_names = tuple_names\n        self.cnf_form = """"\n        op_index = contains_operation(predicate_string)\n        if op_index is not None:\n            self.operation_string = operationSign[op_index]\n            self.operation = operationsArr[op_index]\n        else:\n            raise Exception(\'Cannot find operation in predicate\')\n        self.components = self.parse_components(predicate_string)\n        for i in range(len(self.components)):\n            component = self.components[i]\n            if isinstance(component, str):\n                self.cnf_form += component\n            else:\n                # Need to wrap column names in quotations for Postgres\n                self.cnf_form += \'{alias}.""{attr}""\'.format(\n                        alias=component[0],\n                        attr=component[1])\n            if i < len(self.components) - 1:\n                self.cnf_form += self.operation\n        logging.debug(""DONE parsing predicate: %s"", predicate_string)\n\n    def parse_components(self, predicate_string):\n        """"""\n        Parses the components of given predicate string\n        Example: \'EQ(t1.ZipCode,t2.ZipCode)\' returns [[\'t1\', \'ZipCode\'], [\'t2\',\'ZipCode\']]\n\n        :param predicate_string: predicate string\n        :return: list of predicate components\n        """"""\n        # HC currently only supports DCs with two tuples per predicate\n        # so raise an exception if a different number present\n        num_tuples = len(predicate_string.split(\',\'))\n        if num_tuples < 2:\n            raise Exception(\'Less than 2 tuples in predicate: \' +\n                                    predicate_string)\n        elif num_tuples > 2:\n            raise Exception(\'More than 2 tuples in predicate: \' +\n                                    predicate_string)\n\n        operation = self.operation_string\n        if predicate_string[0:len(operation)] != operation:\n            raise Exception(\'First string in predicate is not operation \' + predicate_string)\n        stack = []\n        components = []\n        current_component = []\n        str_so_far = """"\n        for i in range(len(operation), len(predicate_string)):\n            str_so_far += predicate_string[i]\n            if len(stack[-1:]) > 0 and stack[-1] == ""\'"":\n                if predicate_string[i] == ""\'"":\n                    if i == len(predicate_string) - 1 or \\\n                            predicate_string[i+1] != \')\':\n                        raise Exception(""Expected ) after end of literal"")\n                    components.append(str_so_far)\n                    current_component = []\n                    stack.pop()\n                    str_so_far = """"\n            elif str_so_far == ""\'"":\n                stack.append(""\'"")\n            elif str_so_far == \'(\':\n                str_so_far = \'\'\n                stack.append(\'(\')\n            elif str_so_far == \')\':\n                if stack.pop() == \'(\':\n                    str_so_far = \'\'\n                    if len(stack) == 0:\n                        break\n                else:\n                    raise Exception(\'Closed an unopened (\' + predicate_string)\n            elif predicate_string[i + 1] == \'.\':\n                if str_so_far in self.tuple_names:\n                    current_component.append(str_so_far)\n                    str_so_far = """"\n                else:\n                    raise Exception(\'Tuple name \' + str_so_far + \' not defined in \' + predicate_string)\n\n            elif (predicate_string[i + 1] == \',\' or\n                  predicate_string[i + 1] == \')\') and \\\n                    predicate_string[i] != ""\'"":\n\n                # Attribute specified in DC not found in schema\n                if str_so_far not in self.schema:\n                    raise Exception(\'Attribute name {} not in schema: {}\'.format(str_so_far, "","".join(self.schema)))\n\n                current_component.append(str_so_far)\n                str_so_far = """"\n                components.append(current_component)\n                current_component = []\n            elif str_so_far == \',\' or str_so_far == \'.\':\n                str_so_far = \'\'\n        return components\n\n    def __str__(self):\n        return self.cnf_form\n'"
dcparser/dcparser.py,0,"b'import logging\nimport os\nimport time\n\nfrom .constraint import DenialConstraint\n\n\nclass Parser:\n    """"""\n    This class creates interface for parsing denial constraints\n    """"""\n    def __init__(self, env, dataset):\n        """"""\n        Constructing parser interface object\n\n        :param session: session object\n        """"""\n        self.env = env\n        self.ds = dataset\n        self.dc_strings = []\n        self.dcs = []\n\n    def load_denial_constraints(self, fpath):\n        """"""\n        Loads denial constraints from line-separated TXT file\n        \n        :param fpath: filepath to TXT file containing denial constraints\n        """"""\n        tic = time.clock()\n        if not self.ds.raw_data:\n            status = \'No dataset specified\'\n            toc = time.clock()\n            return status, toc - tic\n        attrs = self.ds.raw_data.get_attributes()\n        try:\n            dc_file = open(fpath, \'r\')\n            status = ""OPENED constraints file successfully""\n            logging.debug(status)\n            for line in dc_file:\n                line = line.rstrip()\n                # Skip empty and comment lines.\n                if not line or line.startswith(\'#\'):\n                    continue\n                self.dc_strings.append(line)\n                self.dcs.append(DenialConstraint(line,attrs))\n            status = \'DONE Loading DCs from {fname}\'.format(fname=os.path.basename(fpath))\n        except Exception:\n            logging.error(\'FAILED to load constraints from file %s\', os.path.basename(fpath))\n            raise\n        toc = time.clock()\n        return status, toc - tic\n\n    def get_dcs(self):\n        return self.dcs\n'"
detect/__init__.py,0,"b""from .detect import DetectEngine\nfrom .detector import Detector\nfrom .nulldetector import NullDetector\nfrom .violationdetector import ViolationDetector\nfrom .errorloaderdetector import ErrorsLoaderDetector\n\n__all__ = ['DetectEngine', 'Detector', 'NullDetector', \n            'ViolationDetector', 'ErrorsLoaderDetector']\n"""
detect/detect.py,0,"b'import logging\nimport time\n\nimport pandas as pd\n\nfrom dataset import AuxTables\n\n\nclass DetectEngine:\n    def __init__(self, env, dataset):\n        self.env = env\n        self.ds = dataset\n\n    def detect_errors(self, detectors):\n        """"""\n        Detects errors using a list of detectors.\n        :param detectors: (list) of ErrorDetector objects\n        """"""\n        errors = []\n        tic_total = time.clock()\n\n        # Initialize all error detectors.\n        for detector in detectors:\n            detector.setup(self.ds, self.env)\n\n        # Run detection using each detector.\n        for detector in detectors:\n            tic = time.clock()\n            error_df = detector.detect_noisy_cells()\n            toc = time.clock()\n            logging.debug(""DONE with Error Detector: %s in %.2f secs"", detector.name, toc-tic)\n            errors.append(error_df)\n\n        # Get unique errors only that might have been detected from multiple detectors.\n        errors_df = pd.concat(errors, ignore_index=True).drop_duplicates().reset_index(drop=True)\n        errors_df[\'_cid_\'] = errors_df.apply(lambda x: self.ds.get_cell_id(x[\'_tid_\'], x[\'attribute\']), axis=1)\n        logging.info(""detected %d potentially erroneous cells"", errors_df.shape[0])\n\n        # Store errors to db.\n        self.store_detected_errors(errors_df)\n        status = ""DONE with error detection.""\n        toc_total = time.clock()\n        detect_time = toc_total - tic_total\n        return status, detect_time\n\n    def store_detected_errors(self, errors_df):\n        if errors_df.empty:\n            raise Exception(""ERROR: Detected errors dataframe is empty."")\n        self.ds.generate_aux_table(AuxTables.dk_cells, errors_df, store=True)\n        self.ds.aux_table[AuxTables.dk_cells].create_db_index(self.ds.engine, [\'_cid_\'])\n\n'"
detect/detector.py,0,"b'from abc import ABCMeta, abstractmethod\n\n\nclass Detector:\n    """"""\n    This class is an abstract class for general error detection,\n     it requires for every sub-class to implement the\n    setup and detect_noisy_cells method\n    """"""\n    __metaclass__ = ABCMeta\n\n    def __init__(self, name):\n        """"""\n        Construct error detection object\n        \n        :param name: The name of the error detector\n        """"""\n        self.name = name\n        self.ds = None\n\n    @abstractmethod\n    def setup(self, dataset, env):\n        raise NotImplementedError\n\n    @abstractmethod\n    def detect_noisy_cells(self):\n        """"""\n        This method creates a dataframe which has the information\n        (tuple index,attribute) for the dk_cells\n\n        :return dataframe  for the dk_cell\n        """"""\n        raise NotImplementedError'"
detect/errorloaderdetector.py,0,"b'import pandas as pd\n\nfrom dataset.table import Table, Source\nfrom .detector import Detector\n\n\nclass ErrorsLoaderDetector(Detector):\n    """"""\n    Detector that loads a table of constant errors with the columns:\n        id_col: entity ID\n        attr_col: attribute in violation\n        in the format id_col, attr_col\n    Can load these erros from a csv file, a relational table, or a pandas \n    dataframe with the same format.\n    """"""\n    def __init__(self, fpath=None, df=None,\n                 db_engine=None, table_name=None, schema_name=None,\n                 id_col=""_tid_"", attr_col=""attribute"", \n                 name=""ErrorLoaderDetector""):\n        """"""\n        :param fpath: (str) Path to source csv file to load errors\n        :param df: (DataFrame) datarame containing the errors\n        :param db_engine: (DBEngine) Database engine object\n        :param table_name: (str) Relational table considered for loading errors\n        :param schema_name: (str) Schema in which :param table_name: exists\n        :param id_col: (str) ID column name\n        :param attr_col: (str) Attribute column name\n        :param name: (str) name of the detector\n\n        To load from csv file, :param fpath: must be specified.\n        To load from a relational table, :param db_engine:, and \n        :param table_name: must be specified, optionally specifying :param schema_name:.\n        """"""\n        super(ErrorsLoaderDetector, self).__init__(name)\n        src = None\n        dataset_name = None\n        if fpath is not None:\n            dataset_name = ""errors_file""\n            src = Source.FILE\n        elif df is not None:\n            dataset_name = ""errors_df""\n            src = Source.DF\n        elif (db_engine is not None) and (table_name is not None):\n            dataset_name = table_name\n            src = Source.DB\n        else:\n            raise Exception(""ERROR while intializing ErrorsLoaderDetector. Please provide (<fpath>), (<db_engine> and <table_name>), OR <df>"")\n\n        self.errors_table = Table(dataset_name, src, \n                                  exclude_attr_cols=[attr_col],\n                                  fpath=fpath, df=df,\n                                  schema_name=schema_name, db_engine=db_engine)\n                                \n        expected_schema = [id_col, attr_col]\n        if list(self.errors_table.df.columns) != expected_schema:\n            raise Exception(""ERROR while intializing ErrorsLoaderDetector: The loaded errors table does not match the expected schema of {}"".format(expected_schema))\n        \n        self.errors_table.df = self.errors_table.df.astype({\n            id_col: int,\n            attr_col: str\n        })\n\n\n    def setup(self, dataset=None, env=None):\n        self.ds = dataset\n        self.env = env\n\n    def detect_noisy_cells(self):\n        """"""\n        Returns a pandas.DataFrame containing loaded errors from a source.\n\n        :return: pandas.DataFrame with columns:\n            id_col: entity ID\n            attr_col: attribute in violation\n        """"""\n        return self.errors_table.df\n'"
detect/nulldetector.py,0,"b'import pandas as pd\n\nfrom .detector import Detector\nfrom utils import NULL_REPR\n\n\nclass NullDetector(Detector):\n    """"""\n    An error detector that treats null values as errors.\n    """"""\n\n    def __init__(self, name=\'NullDetector\'):\n        super(NullDetector, self).__init__(name)\n\n    def setup(self, dataset, env):\n        self.ds = dataset\n        self.env = env\n        self.df = self.ds.get_raw_data()\n\n    def detect_noisy_cells(self):\n        """"""\n        detect_noisy_cells returns a pandas.DataFrame containing all cells with\n        NULL values.\n\n        :return: pandas.DataFrame with columns:\n            _tid_: entity ID\n            attribute: attribute with NULL value for this entity\n        """"""\n        attributes = self.ds.get_attributes()\n        errors = []\n        for attr in attributes:\n            tmp_df = self.df[self.df[attr] == NULL_REPR][\'_tid_\'].to_frame()\n            tmp_df.insert(1, ""attribute"", attr)\n            errors.append(tmp_df)\n        errors_df = pd.concat(errors, ignore_index=True)\n        return errors_df\n\n'"
detect/violationdetector.py,0,"b'from string import Template\n\nimport pandas as pd\n\nfrom .detector import Detector\n\nunary_template = Template(\'SELECT t1._tid_ FROM ""$table"" as t1 WHERE $cond\')\nmulti_template = Template(\'SELECT t1._tid_ FROM ""$table"" as t1 WHERE $cond1 $c EXISTS (SELECT t2._tid_ FROM ""$table"" as t2 WHERE $cond2)\')\n\n\nclass ViolationDetector(Detector):\n    """"""\n    Detector to detect violations of integrity constraints (mainly denial constraints).\n    """"""\n\n    def __init__(self, name=\'ViolationDetector\'):\n        super(ViolationDetector, self).__init__(name)\n\n    def setup(self, dataset, env):\n        self.ds = dataset\n        self.env = env\n        self.constraints = dataset.constraints\n\n    def detect_noisy_cells(self):\n        """"""\n        Returns a pandas.DataFrame containing all cells that\n         violate denial constraints contained in self.dataset.\n\n        :return: pandas.DataFrame with columns:\n            _tid_: entity ID\n            attribute: attribute violating any denial constraint.\n        """"""\n        # Convert  Constraints to SQL queries\n        tbl = self.ds.raw_data.name\n        queries = []\n        attrs = []\n        for c in self.constraints:\n            q = self.to_sql(tbl, c)\n            queries.append(q)\n            attrs.append(c.components)\n        # Execute Queries over the DBEngine of Dataset\n        results = self.ds.engine.execute_queries(queries)\n\n        # Generate final output\n        errors = []\n        for i in range(len(attrs)):\n            res = results[i]\n            attr_list = attrs[i]\n            tmp_df = self.gen_tid_attr_output(res, attr_list)\n            errors.append(tmp_df)\n        errors_df = pd.concat(errors, ignore_index=True).drop_duplicates().reset_index(drop=True)\n        return errors_df\n\n    def to_sql(self, tbl, c):\n        # Check tuples in constraint\n        unary = len(c.tuple_names)==1\n        if unary:\n            query = self.gen_unary_query(tbl, c)\n        else:\n            query = self.gen_mult_query(tbl, c)\n        return query\n\n    def gen_unary_query(self, tbl, c):\n        query = unary_template.substitute(table=tbl, cond=c.cnf_form)\n        return query\n\n    def gen_mult_query(self, tbl, c):\n        # Iterate over constraint predicates to identify cond1 and cond2\n        cond1_preds = []\n        cond2_preds = []\n        for pred in c.predicates:\n            if \'t1\' in pred.cnf_form:\n                if \'t2\' in pred.cnf_form:\n                    cond2_preds.append(pred.cnf_form)\n                else:\n                    cond1_preds.append(pred.cnf_form)\n            elif \'t2\' in pred.cnf_form:\n                cond2_preds.append(pred.cnf_form)\n            else:\n                raise Exception(""ERROR in violation detector. Cannot ground mult-tuple template."")\n        cond1 = "" AND "".join(cond1_preds)\n        cond2 = "" AND "".join(cond2_preds)\n        a = \',\'.join(c.components)\n        a = []\n        for b in c.components:\n            a.append(""\'""+b+""\'"")\n        a = \',\'.join(a)\n        if cond1 != \'\':\n            query = multi_template.substitute(table=tbl, cond1=cond1, c=\'AND\', cond2=cond2)\n        else:\n            query = multi_template.substitute(table=tbl, cond1=cond1, c=\'\', cond2=cond2)\n        return query\n\n    def gen_tid_attr_output(self, res, attr_list):\n        errors = []\n        for tuple in res:\n            tid = int(tuple[0])\n            for attr in attr_list:\n                errors.append({\'_tid_\': tid, \'attribute\': attr})\n        error_df  = pd.DataFrame(data=errors)\n        return error_df\n'"
domain/__init__.py,0,"b""from .domain import DomainEngine\n\n__all__ = ['DomainEngine']\n"""
domain/domain.py,0,"b'import logging\nimport pandas as pd\nimport time\n\nimport itertools\nimport numpy as np\nfrom pyitlib import discrete_random_variable as drv\nfrom tqdm import tqdm\n\nfrom dataset import AuxTables, CellStatus\nfrom .estimators import NaiveBayes\nfrom utils import NULL_REPR\n\n\nclass DomainEngine:\n    def __init__(self, env, dataset, max_sample=5):\n        """"""\n        :param env: (dict) contains global settings such as verbose\n        :param dataset: (Dataset) current dataset\n        :param max_sample: (int) maximum # of domain values from a random sample\n        """"""\n        self.env = env\n        self.ds = dataset\n        self.domain_thresh_1 = env[""domain_thresh_1""]\n        self.weak_label_thresh = env[""weak_label_thresh""]\n        self.domain_thresh_2 = env[""domain_thresh_2""]\n        self.max_domain = env[""max_domain""]\n        self.setup_complete = False\n        self.active_attributes = None\n        self.domain = None\n        self.total = None\n        self.correlations = None\n        self._corr_attrs = {}\n        self.cor_strength = env[""cor_strength""]\n        self.max_sample = max_sample\n        self.single_stats = {}\n        self.pair_stats = {}\n        self.all_attrs = {}\n\n    def setup(self):\n        """"""\n        setup initializes the in-memory and Postgres auxiliary tables (e.g.\n        \'cell_domain\', \'pos_values\').\n        """"""\n        tic = time.time()\n        self.compute_correlations()\n        self.setup_attributes()\n        domain = self.generate_domain()\n        self.store_domains(domain)\n        status = ""DONE with domain preparation.""\n        toc = time.time()\n        return status, toc - tic\n\n    def compute_correlations(self):\n        """"""\n        compute_correlations memoizes to self.correlations; a data structure\n        that contains pairwise correlations between attributes (values are treated as\n        discrete categories).\n        """"""\n        self.correlations = self._compute_norm_cond_entropy_corr()\n\n    def _compute_norm_cond_entropy_corr(self):\n        """"""\n        Computes the correlations between attributes by calculating\n        the normalized conditional entropy between them. The conditional\n        entropy is asymmetric, therefore we need pairwise computation.\n\n        The computed correlations are stored in a dictionary in the format:\n        {\n          attr_a: { cond_attr_i: corr_strength_a_i,\n                    cond_attr_j: corr_strength_a_j, ... },\n          attr_b: { cond_attr_i: corr_strength_b_i, ...}\n        }\n\n        :return a dictionary of correlations\n        """"""\n        data_df = self.ds.get_raw_data()\n        attrs = self.ds.get_attributes()\n\n        corr = {}\n        # Compute pair-wise conditional entropy.\n        for x in attrs:\n            corr[x] = {}\n            x_vals = data_df[x]\n            x_domain_size = x_vals.nunique()\n            for y in attrs:\n                # Set correlation to 0.0 if entropy of x is 1 (only one possible value).\n                if x_domain_size == 1:\n                    corr[x][y] = 0.0\n                    continue\n\n                # Set correlation to 1 for same attributes.\n                if x == y:\n                    corr[x][y] = 1.0\n                    continue\n\n                # Compute the conditional entropy H(x|y) = H(x,y) - H(y).\n                # H(x,y) denotes H(x U y).\n                # If H(x|y) = 0, then y determines x, i.e., y -> x.\n                # Use the domain size of x as a log base for normalization.\n                y_vals = data_df[y]\n                x_y_entropy = drv.entropy_conditional(x_vals, y_vals, base=x_domain_size)\n\n                # The conditional entropy is 0 for strongly correlated attributes and 1 for\n                # completely independent attributes. We reverse this to reflect the correlation.\n                corr[x][y] = 1.0 - x_y_entropy\n        return corr\n\n    def store_domains(self, domain):\n        """"""\n        store_domains stores the \'domain\' DataFrame as the \'cell_domain\'\n        auxiliary table as well as generates the \'pos_values\' auxiliary table,\n        a long-format of the domain values, in Postgres.\n\n        pos_values schema:\n            _tid_: entity/tuple ID\n            _cid_: cell ID\n            _vid_: random variable ID (all cells with more than 1 domain value)\n            _\n\n        """"""\n        if domain.empty:\n            raise Exception(""ERROR: Generated domain is empty."")\n        else:\n            self.ds.generate_aux_table(AuxTables.cell_domain, domain, store=True, index_attrs=[\'_vid_\'])\n            self.ds.aux_table[AuxTables.cell_domain].create_db_index(self.ds.engine, [\'_tid_\'])\n            self.ds.aux_table[AuxTables.cell_domain].create_db_index(self.ds.engine, [\'_cid_\'])\n            query = ""SELECT _vid_, _cid_, _tid_, attribute, a.rv_val, a.val_id from %s , unnest(string_to_array(regexp_replace(domain,\\\'[{\\""\\""}]\\\',\\\'\\\',\\\'gi\\\'),\\\'|||\\\')) WITH ORDINALITY a(rv_val,val_id)"" % AuxTables.cell_domain.name\n            self.ds.generate_aux_table_sql(AuxTables.pos_values, query, index_attrs=[\'_tid_\', \'attribute\'])\n\n    def setup_attributes(self):\n        self.active_attributes = self.get_active_attributes()\n        total, single_stats, pair_stats = self.ds.get_statistics()\n        self.total = total\n        self.single_stats = single_stats\n        logging.debug(""preparing pruned co-occurring statistics..."")\n        tic = time.clock()\n        self.pair_stats = self._pruned_pair_stats(pair_stats)\n        logging.debug(""DONE with pruned co-occurring statistics in %.2f secs"", time.clock() - tic)\n        self.setup_complete = True\n\n    def _pruned_pair_stats(self, pair_stats):\n        """"""\n        _pruned_pair_stats converts \'pair_stats\' which is a dictionary mapping\n            { attr1 -> { attr2 -> {val1 -> {val2 -> count } } } } where\n              <val1>: all possible values for attr1\n              <val2>: all values for attr2 that appeared at least once with <val1>\n              <count>: frequency (# of entities) where attr1: <val1> AND attr2: <val2>\n\n        to a flattened 4-level dictionary { attr1 -> { attr2 -> { val1 -> [pruned list of val2] } } }\n        i.e. maps to the co-occurring values for attr2 that exceed\n        the self.domain_thresh_1 co-occurrence probability for a given\n        attr1-val1 pair.\n        """"""\n\n        out = {}\n        for attr1 in tqdm(pair_stats.keys()):\n            out[attr1] = {}\n            for attr2 in pair_stats[attr1].keys():\n                out[attr1][attr2] = {}\n                for val1 in pair_stats[attr1][attr2].keys():\n                    denominator = self.single_stats[attr1][val1]\n                    # tau becomes a threshhold on co-occurrence frequency\n                    # based on the co-occurrence probability threshold\n                    # domain_thresh_1.\n                    tau = float(self.domain_thresh_1*denominator)\n                    top_cands = [val2 for (val2, count) in pair_stats[attr1][attr2][val1].items() if count > tau]\n                    out[attr1][attr2][val1] = top_cands\n        return out\n\n    def get_active_attributes(self):\n        """"""\n        get_active_attributes returns the attributes to be modeled.\n        These attributes correspond only to attributes that contain at least\n        one potentially erroneous cell.\n        """"""\n        query = \'SELECT DISTINCT attribute as attribute FROM {}\'.format(AuxTables.dk_cells.name)\n        result = self.ds.engine.execute_query(query)\n        if not result:\n            raise Exception(""No attribute contains erroneous cells."")\n        # Sort the active attributes to maintain the order of the ids of random variable.\n        return sorted(itertools.chain(*result))\n\n    def get_corr_attributes(self, attr, thres):\n        """"""\n        get_corr_attributes returns attributes from self.correlations\n        that are correlated with attr with magnitude at least self.cor_strength\n        (init parameter).\n\n        :param attr: (string) the original attribute to get the correlated attributes for.\n        :param thres: (float) correlation threshold (absolute) for returned attributes.\n        """"""\n        # Not memoized: find correlated attributes from correlation dictionary.\n        if (attr, thres) not in self._corr_attrs:\n            self._corr_attrs[(attr, thres)] = []\n\n            if attr in self.correlations:\n                attr_correlations = self.correlations[attr]\n                self._corr_attrs[(attr, thres)] = sorted([corr_attr\n                                                   for corr_attr, corr_strength in attr_correlations.items()\n                                                   if corr_attr != attr and corr_strength > thres])\n\n        return self._corr_attrs[(attr, thres)]\n\n    def generate_domain(self):\n        """"""\n        Generates the domain for each cell in the active attributes as well\n        as assigns a random variable ID (_vid_) for cells that have\n        a domain of size >= 2.\n\n        See get_domain_cell for how the domain is generated from co-occurrence\n        and correlated attributes.\n\n        If no values can be found from correlated attributes, return a random\n        sample of domain values.\n\n        :return: DataFrame with columns\n            _tid_: entity/tuple ID\n            _cid_: cell ID (one for every cell in the raw data in active attributes)\n            _vid_: random variable ID (one for every cell with a domain of at least size 2)\n            attribute: attribute name\n            domain: ||| separated string of domain values\n            domain_size: length of domain\n            init_value: initial value for this cell\n            init_value_idx: domain index of init_value\n            fixed: 1 if a random sample was taken since no correlated attributes/top K values\n        """"""\n\n        if not self.setup_complete:\n            raise Exception(\n                ""Call <setup_attributes> to setup active attributes. Error detection should be performed before setup."")\n\n        logging.debug(\'generating initial set of un-pruned domain values...\')\n        tic = time.clock()\n        # Iterate over dataset rows.\n        cells = []\n        vid = 0\n        records = self.ds.get_raw_data().to_records()\n        self.all_attrs = list(records.dtype.names)\n        for row in tqdm(list(records)):\n            tid = row[\'_tid_\']\n            for attr in self.active_attributes:\n                init_value, init_value_idx, dom = self.get_domain_cell(attr, row)\n                # We will use an estimator model for additional weak labelling\n                # below, which requires an initial pruned domain first.\n                # Weak labels will be trained on the init values.\n                cid = self.ds.get_cell_id(tid, attr)\n\n                # Originally, all cells have a NOT_SET status to be considered\n                # in weak labelling.\n                cell_status = CellStatus.NOT_SET.value\n\n                if len(dom) <= 1:\n                    # Initial  value is NULL and we cannot come up with\n                    # a domain; a random domain probably won\'t help us so\n                    # completely ignore this cell and continue.\n                    # Note if len(dom) == 1, then we generated a single correct\n                    # value (since NULL is not included in the domain).\n                    # This would be a ""SINGLE_VALUE"" example and we\'d still\n                    # like to generate a random domain for it.\n                    if init_value == NULL_REPR and len(dom) == 0:\n                        continue\n\n                    # Not enough domain values, we need to get some random\n                    # values (other than \'init_value\') for training. However,\n                    # this might still get us zero domain values.\n                    rand_dom_values = self.get_random_domain(attr, init_value)\n\n                    # rand_dom_values might still be empty. In this case,\n                    # there are no other possible values for this cell. There\n                    # is not point to use this cell for training and there is no\n                    # point to run inference on it since we cannot even generate\n                    # a random domain. Therefore, we just ignore it from the\n                    # final tensor.\n                    if len(rand_dom_values) == 0:\n                        continue\n\n                    # Otherwise, just add the random domain values to the domain\n                    # and set the cell status accordingly.\n                    dom.extend(rand_dom_values)\n\n                    # Set the cell status that this is a single value and was\n                    # randomly assigned other values in the domain. These will\n                    # not be modified by the estimator.\n                    cell_status = CellStatus.SINGLE_VALUE.value\n\n                cells.append({""_tid_"": tid,\n                              ""attribute"": attr,\n                              ""_cid_"": cid,\n                              ""_vid_"": vid,\n                              ""domain"": ""|||"".join(dom),\n                              ""domain_size"": len(dom),\n                              ""init_value"": init_value,\n                              ""init_index"": init_value_idx,\n                              ""weak_label"": init_value,\n                              ""weak_label_idx"": init_value_idx,\n                              ""fixed"": cell_status})\n                vid += 1\n        domain_df = pd.DataFrame(data=cells).sort_values(\'_vid_\')\n        logging.debug(\'DONE generating initial set of domain values in %.2f\', time.clock() - tic)\n\n        # Skip estimator model since we do not require any weak labelling or domain\n        # pruning based on posterior probabilities.\n        if self.env[\'weak_label_thresh\'] == 1 and self.env[\'domain_thresh_2\'] == 0:\n            return domain_df\n\n        # Run pruned domain values from correlated attributes above through\n        # posterior model for a naive probability estimation.\n        logging.debug(\'training posterior model for estimating domain value probabilities...\')\n        tic = time.clock()\n        estimator = NaiveBayes(self.env, self.ds, domain_df, self.correlations)\n        logging.debug(\'DONE training posterior model in %.2fs\', time.clock() - tic)\n\n        # Predict probabilities for all pruned domain values.\n        logging.debug(\'predicting domain value probabilities from posterior model...\')\n        tic = time.clock()\n        preds_by_cell = estimator.predict_pp_batch()\n        logging.debug(\'DONE predictions in %.2f secs, re-constructing cell domain...\', time.clock() - tic)\n\n        logging.debug(\'re-assembling final cell domain table...\')\n        tic = time.clock()\n        # iterate through raw/current data and generate posterior probabilities for\n        # weak labelling\n        num_weak_labels = 0\n        updated_domain_df = []\n        for preds, row in tqdm(zip(preds_by_cell, domain_df.to_records())):\n            # Do not re-label single valued cells.\n            if row[\'fixed\'] == CellStatus.SINGLE_VALUE.value:\n                updated_domain_df.append(row)\n                continue\n\n            # prune domain if any of the values are above our domain_thresh_2\n            preds = [[val, proba] for val, proba in preds if proba >= self.domain_thresh_2] or preds\n\n            # cap the maximum # of domain values to self.max_domain based on probabilities.\n            domain_values = [val for val, proba in sorted(preds, key=lambda pred: pred[1], reverse=True)[:self.max_domain]]\n\n            # ensure the initial value is included even if its probability is low.\n            if row[\'init_value\'] not in domain_values and row[\'init_value\'] != NULL_REPR:\n                domain_values.append(row[\'init_value\'])\n            domain_values = sorted(domain_values)\n            # update our memoized domain values for this row again\n            row[\'domain\'] = \'|||\'.join(domain_values)\n            row[\'domain_size\'] = len(domain_values)\n            # update init index based on new domain\n            if row[\'init_value\'] in domain_values:\n                row[\'init_index\'] = domain_values.index(row[\'init_value\'])\n            # update weak label index based on new domain\n            if row[\'weak_label\'] != NULL_REPR:\n                row[\'weak_label_idx\'] = domain_values.index(row[\'weak_label\'])\n\n            weak_label, weak_label_prob = max(preds, key=lambda pred: pred[1])\n\n            # Assign weak label if it is not the same as init AND domain value\n            # exceeds our weak label threshold.\n            if weak_label != row[\'init_value\'] and weak_label_prob >= self.weak_label_thresh:\n                num_weak_labels += 1\n\n                weak_label_idx = domain_values.index(weak_label)\n                row[\'weak_label\'] = weak_label\n                row[\'weak_label_idx\'] = weak_label_idx\n                row[\'fixed\'] = CellStatus.WEAK_LABEL.value\n\n            updated_domain_df.append(row)\n\n        # update our cell domain df with our new updated domain\n        domain_df = pd.DataFrame.from_records(updated_domain_df, columns=updated_domain_df[0].dtype.names).drop(\'index\', axis=1).sort_values(\'_vid_\')\n        logging.debug(\'DONE assembling cell domain table in %.2fs\', time.clock() - tic)\n\n        logging.info(\'number of (additional) weak labels assigned from posterior model: %d\', num_weak_labels)\n\n        logging.debug(\'DONE generating domain and weak labels\')\n        return domain_df\n\n    def get_domain_cell(self, attr, row):\n        """"""\n        get_domain_cell returns a list of all domain values for the given\n        entity (row) and attribute. The domain never has null as a possible value.\n\n        We define domain values as values in \'attr\' that co-occur with values\n        in attributes (\'cond_attr\') that are correlated with \'attr\' at least in\n        magnitude of self.cor_strength (init parameter).\n\n        For example:\n\n                cond_attr       |   attr\n                H                   B                   <-- current row\n                H                   C\n                I                   D\n                H                   E\n\n        This would produce [B,C,E] as domain values.\n\n        :return: (initial value of entity-attribute, domain values for entity-attribute).\n        """"""\n\n        domain = set()\n        init_value = row[attr]\n        correlated_attributes = self.get_corr_attributes(attr, self.cor_strength)\n        # Iterate through all correlated attributes and take the top K co-occurrence values\n        # for \'attr\' with the current row\'s \'cond_attr\' value.\n        for cond_attr in correlated_attributes:\n            # Ignore correlations with index, tuple id or the same attribute.\n            if cond_attr == attr or cond_attr == \'_tid_\':\n                continue\n            if not self.pair_stats[cond_attr][attr]:\n                logging.warning(""domain generation could not find pair_statistics between attributes: {}, {}"".format(cond_attr, attr))\n                continue\n            cond_val = row[cond_attr]\n            # Ignore co-occurrence with a NULL cond init value since we do not\n            # store them.\n            # Also it does not make sense to retrieve the top co-occuring\n            # values with a NULL value.\n            # It is possible for cond_val to not be in pair stats if it only co-occurs\n            # with NULL values.\n            if cond_val == NULL_REPR or cond_val not in self.pair_stats[cond_attr][attr]:\n                continue\n\n            # Update domain with top co-occuring values with the cond init value.\n            candidates = self.pair_stats[cond_attr][attr][cond_val]\n            domain.update(candidates)\n\n        # We should not have any NULLs since we do not store co-occurring NULL\n        # values.\n        assert NULL_REPR not in domain\n\n        # Add the initial value to the domain if it is not NULL.\n        if init_value != NULL_REPR:\n            domain.add(init_value)\n\n        # Convert to ordered list to preserve order.\n        domain_lst = sorted(list(domain))\n\n        # Get the index of the initial value.\n        # NULL values are not in the domain so we set their index to -1.\n        init_value_idx = -1\n        if init_value != NULL_REPR:\n            init_value_idx = domain_lst.index(init_value)\n\n        return init_value, init_value_idx, domain_lst\n\n    def get_random_domain(self, attr, cur_value):\n        """"""\n        get_random_domain returns a random sample of at most size\n        \'self.max_sample\' of domain values for \'attr\' that is NOT \'cur_value\'.\n        """"""\n        domain_pool = set(self.single_stats[attr].keys())\n        # We should not have any NULLs since we do not keep track of their\n        # counts.\n        assert NULL_REPR not in domain_pool\n        domain_pool.discard(cur_value)\n        domain_pool = sorted(list(domain_pool))\n        size = len(domain_pool)\n        if size > 0:\n            k = min(self.max_sample, size)\n            additional_values = np.random.choice(domain_pool, size=k, replace=False)\n        else:\n            additional_values = []\n        return sorted(additional_values)\n'"
domain/estimator.py,0,"b'from abc import ABCMeta, abstractmethod\n\n\nclass Estimator:\n    """"""\n    Estimator is an abstract class for posterior estimators that estimate\n    the posterior of p(value | other values) for the purpose of domain generation\n    and weak labelling.\n    """"""\n    __metaclass__ = ABCMeta\n\n    def __init__(self, env, dataset):\n        """"""\n        :param env: (dict) dict containing environment/parameters settings.\n        :param dataset: (Dataset)\n        """"""\n        self.env = env\n        self.ds = dataset\n        self.attrs = self.ds.get_attributes()\n\n    @abstractmethod\n    def train(self, **kwargs):\n        raise NotImplementedError\n\n    @abstractmethod\n    def predict_pp(self, row, attr, values):\n        """"""\n        :param row: (namedtuple) current values of the target row.\n        :param attr: (str) attribute of row (i.e. cell) to generate posteriors for.\n        :param values: (list[str]) list of values (for this attr) to generate posteriors for.\n\n        :return: iterator of tuples (value, proba) for each value in :param values:\n        """"""\n        raise NotImplementedError\n\n    @abstractmethod\n    def predict_pp_batch(self):\n        """"""\n        predict_pp_batch is like predict_pp but with a batch of cells.\n\n        :return: iterator of iterator of tuples (value, proba) (one iterator per cell/row in cell_domain_rows)\n        """"""\n        raise NotImplementedError\n'"
evaluate/__init__.py,0,"b""from .eval import EvalEngine\n\n__all__ = ['EvalEngine']\n"""
evaluate/eval.py,0,"b'from collections import namedtuple\nimport logging\nimport os\nfrom string import Template\nimport time\n\nimport pandas as pd\n\nfrom dataset import AuxTables\nfrom dataset.table import Table, Source\nfrom utils import NULL_REPR\n\nEvalReport = namedtuple(\'EvalReport\', [\'precision\', \'recall\', \'repair_recall\',\n    \'f1\', \'repair_f1\', \'detected_errors\', \'total_errors\', \'correct_repairs\',\n    \'total_repairs\',\n    \'total_repairs_grdt\', \'total_repairs_grdt_correct\', \'total_repairs_grdt_incorrect\'])\n\nerrors_template = Template(\'SELECT count(*) \' \\\n                           \'FROM  ""$init_table"" as t1, ""$grdt_table"" as t2 \' \\\n                           \'WHERE t1._tid_ = t2._tid_ \' \\\n                           \'  AND t2._attribute_ = \\\'$attr\\\' \' \\\n                           \'  AND t1.""$attr"" != t2._value_\')\n\n""""""\nThe \'errors\' aliased subquery returns the (_tid_, _attribute_, _value_)\nfrom the ground truth table for all cells that have an error in the original\nraw data.\n\nThe \'repairs\' aliased table contains the cells and values we\'ve inferred.\n\nWe then count the number of cells that we repaired to the correct ground\ntruth value.\n""""""\ncorrect_repairs_template = Template(\'SELECT COUNT(*) FROM \'\n                                    \'  (SELECT t2._tid_, t2._attribute_, t2._value_ \'\n                                    \'     FROM ""$init_table"" as t1, ""$grdt_table"" as t2 \'\n                                    \'    WHERE t1._tid_ = t2._tid_ \'\n                                    \'      AND t2._attribute_ = \\\'$attr\\\' \'\n                                    \'      AND t1.""$attr"" != t2._value_ ) as errors, $inf_dom as repairs \'\n                                    \'WHERE errors._tid_ = repairs._tid_ \'\n                                    \'  AND errors._attribute_ = repairs.attribute \'\n                                    \'  AND errors._value_ = repairs.rv_value\')\n\n\nclass EvalEngine:\n    def __init__(self, env, dataset):\n        self.env = env\n        self.ds = dataset\n\n    def load_data(self, name, fpath, tid_col, attr_col, val_col, na_values=None):\n        tic = time.clock()\n        try:\n            raw_data = pd.read_csv(fpath, na_values=na_values, encoding=\'utf-8\')\n            # We drop any ground truth values that are NULLs since we follow\n            # the closed-world assumption (if it\'s not there it\'s wrong).\n            # TODO: revisit this once we allow users to specify which\n            # attributes may be NULL.\n            raw_data.dropna(subset=[val_col], inplace=True)\n            raw_data.fillna(NULL_REPR, inplace=True)\n            raw_data.rename({tid_col: \'_tid_\',\n                             attr_col: \'_attribute_\',\n                             val_col: \'_value_\'},\n                            axis=\'columns\',\n                            inplace=True)\n            raw_data = raw_data[[\'_tid_\', \'_attribute_\', \'_value_\']]\n            # Normalize string to whitespaces.\n            raw_data[\'_value_\'] = raw_data[\'_value_\'].str.strip().str.lower()\n            self.clean_data = Table(name, Source.DF, df=raw_data)\n            self.clean_data.store_to_db(self.ds.engine.engine)\n            self.clean_data.create_db_index(self.ds.engine, [\'_tid_\'])\n            self.clean_data.create_db_index(self.ds.engine, [\'_attribute_\'])\n            status = \'DONE Loading {fname}\'.format(fname=os.path.basename(fpath))\n        except Exception:\n            logging.error(\'load_data for table %s\', name)\n            raise\n        toc = time.clock()\n        load_time = toc - tic\n        return status, load_time\n\n    def evaluate_repairs(self):\n        self.compute_total_repairs()\n        self.compute_total_repairs_grdt()\n        self.compute_total_errors()\n        self.compute_detected_errors()\n        self.compute_correct_repairs()\n        prec = self.compute_precision()\n        rec = self.compute_recall()\n        rep_recall = self.compute_repairing_recall()\n        f1 = self.compute_f1()\n        rep_f1 = self.compute_repairing_f1()\n\n        if self.env[\'verbose\']:\n            self.log_weak_label_stats()\n\n        return prec, rec, rep_recall, f1, rep_f1\n\n    def eval_report(self):\n        """"""\n        Returns an EvalReport named tuple containing the experiment results.\n        """"""\n        tic = time.clock()\n        try:\n            prec, rec, rep_recall, f1, rep_f1 = self.evaluate_repairs()\n            report = ""Precision = %.2f, Recall = %.2f, Repairing Recall = %.2f, F1 = %.2f, Repairing F1 = %.2f, Detected Errors = %d, Total Errors = %d, Correct Repairs = %d, Total Repairs = %d, Total Repairs on correct cells (Grdth present) = %d, Total Repairs on incorrect cells (Grdth present) = %d"" % (\n                      prec, rec, rep_recall, f1, rep_f1,\n                      self.detected_errors, self.total_errors, self.correct_repairs,\n                      self.total_repairs, self.total_repairs_grdt_correct, self.total_repairs_grdt_incorrect)\n            eval_report = EvalReport(prec, rec, rep_recall, f1, rep_f1, self.detected_errors, self.total_errors,\n                           self.correct_repairs, self.total_repairs, self.total_repairs_grdt,\n                           self.total_repairs_grdt_correct, self.total_repairs_grdt_incorrect)\n        except Exception as e:\n            logging.error(""ERROR generating evaluation report %s"" % e)\n            raise\n\n        toc = time.clock()\n        report_time = toc - tic\n        return report, report_time, eval_report\n\n    def compute_total_repairs(self):\n        """"""\n        compute_total_repairs memoizes the number of repairs:\n        the # of cells that were inferred and where the inferred value\n        is not equal to the initial value.\n        """"""\n\n        query = ""SELECT count(*) FROM "" \\\n                ""  (SELECT _vid_ "" \\\n                ""     FROM {} as t1, {} as t2 "" \\\n                ""    WHERE t1._tid_ = t2._tid_ "" \\\n                ""      AND t1.attribute = t2.attribute "" \\\n                ""      AND t1.init_value != t2.rv_value) AS t"".format(AuxTables.cell_domain.name,\n                                                                      AuxTables.inf_values_dom.name)\n        res = self.ds.engine.execute_query(query)\n        self.total_repairs = float(res[0][0])\n\n    def compute_total_repairs_grdt(self):\n        """"""\n        compute_total_repairs_grdt memoizes the number of repairs for cells\n        that are specified in the clean/ground truth data. Otherwise repairs\n        are defined the same as compute_total_repairs.\n\n        We also distinguish between repairs on correct cells and repairs on\n        incorrect cells (correct cells are cells where init == ground truth).\n        """"""\n        query = """"""\n        SELECT\n            (t1.init_value = t3._value_) AS is_correct,\n            count(*)\n        FROM   {} as t1, {} as t2, {} as t3\n        WHERE  t1._tid_ = t2._tid_\n          AND  t1.attribute = t2.attribute\n          AND  t1.init_value != t2.rv_value\n          AND  t1._tid_ = t3._tid_\n          AND  t1.attribute = t3._attribute_\n        GROUP BY is_correct\n          """""".format(AuxTables.cell_domain.name,\n                  AuxTables.inf_values_dom.name,\n                  self.clean_data.name)\n        res = self.ds.engine.execute_query(query)\n\n        # Memoize the number of repairs on correct cells and incorrect cells.\n        # Since we do a GROUP BY we need to check which row of the result\n        # corresponds to the correct/incorrect counts.\n        self.total_repairs_grdt_correct, self.total_repairs_grdt_incorrect = 0, 0\n        self.total_repairs_grdt = 0\n        if not res:\n            return\n\n        if res[0][0]:\n            correct_idx, incorrect_idx = 0, 1\n        else:\n            correct_idx, incorrect_idx = 1, 0\n        if correct_idx < len(res):\n            self.total_repairs_grdt_correct = float(res[correct_idx][1])\n        if incorrect_idx < len(res):\n            self.total_repairs_grdt_incorrect =  float(res[incorrect_idx][1])\n        self.total_repairs_grdt = self.total_repairs_grdt_correct + self.total_repairs_grdt_incorrect\n\n    def compute_total_errors(self):\n        """"""\n        compute_total_errors memoizes the number of cells that have a\n        wrong initial value: requires ground truth data.\n        """"""\n        queries = []\n        total_errors = 0.0\n        for attr in self.ds.get_attributes():\n            query = errors_template.substitute(init_table=self.ds.raw_data.name,\n                                               grdt_table=self.clean_data.name,\n                                               attr=attr)\n            queries.append(query)\n        results = self.ds.engine.execute_queries(queries)\n        for res in results:\n            total_errors += float(res[0][0])\n        self.total_errors = total_errors\n\n    def compute_detected_errors(self):\n        """"""\n        compute_detected_errors memoizes the number of error cells that\n        were detected in error detection: requires ground truth.\n\n        This value is always equal or less than total errors (see\n        compute_total_errors).\n        """"""\n        query = ""SELECT count(*) FROM "" \\\n                ""  (SELECT _vid_ "" \\\n                ""   FROM   %s as t1, %s as t2, %s as t3 "" \\\n                ""   WHERE  t1._tid_ = t2._tid_ AND t1._cid_ = t3._cid_ "" \\\n                ""     AND  t1.attribute = t2._attribute_ "" \\\n                ""     AND  t1.init_value != t2._value_) AS t"" \\\n                % (AuxTables.cell_domain.name, self.clean_data.name, AuxTables.dk_cells.name)\n        res = self.ds.engine.execute_query(query)\n        self.detected_errors = float(res[0][0])\n\n    def compute_correct_repairs(self):\n        """"""\n        compute_correct_repairs memoizes the number of error cells\n        that were correctly inferred.\n\n        This value is always equal or less than total errors (see\n        compute_total_errors).\n        """"""\n        queries = []\n        correct_repairs = 0.0\n        for attr in self.ds.get_attributes():\n            query = correct_repairs_template.substitute(init_table=self.ds.raw_data.name, grdt_table=self.clean_data.name,\n                                                        attr=attr, inf_dom=AuxTables.inf_values_dom.name)\n            queries.append(query)\n        results = self.ds.engine.execute_queries(queries)\n        for res in results:\n            correct_repairs += float(res[0][0])\n        self.correct_repairs = correct_repairs\n\n    def compute_recall(self):\n        """"""\n        Computes the recall (# of correct repairs / # of total errors).\n        """"""\n        if self.total_errors == 0:\n            return 0\n        return self.correct_repairs / self.total_errors\n\n    def compute_repairing_recall(self):\n        """"""\n        Computes the _repairing_ recall (# of correct repairs / # of total\n        _detected_ errors).\n        """"""\n        if self.detected_errors == 0:\n            return 0\n        return self.correct_repairs / self.detected_errors\n\n    def compute_precision(self):\n        """"""\n        Computes precision (# correct repairs / # of total repairs w/ ground truth)\n        """"""\n        if self.total_repairs_grdt == 0:\n            return 0\n        return self.correct_repairs / self.total_repairs_grdt\n\n    def compute_f1(self):\n        prec = self.compute_precision()\n        rec = self.compute_recall()\n        if prec+rec == 0:\n            return 0\n        f1 = 2*(prec*rec)/(prec+rec)\n        return f1\n\n    def compute_repairing_f1(self):\n        prec = self.compute_precision()\n        rec = self.compute_repairing_recall()\n        if prec+rec == 0:\n            return 0\n        f1 = 2*(prec*rec)/(prec+rec)\n        return f1\n\n    def log_weak_label_stats(self):\n        query = """"""\n        select\n            (t3._tid_ is NULL) as clean,\n            (t1.fixed) as status,\n            (t4._tid_ is NOT NULL) as inferred,\n            (t1.init_value = t2._value_) as init_eq_grdth,\n            (t1.init_value = t4.rv_value) as init_eq_infer,\n            (t1.weak_label = t1.init_value) as wl_eq_init,\n            (t1.weak_label = t2._value_) as wl_eq_grdth,\n            (t1.weak_label = t4.rv_value) as wl_eq_infer,\n            (t2._value_ = t4.rv_value) as infer_eq_grdth,\n            count(*) as count\n        from\n            {cell_domain} as t1,\n            {clean_data} as t2\n            left join {dk_cells} as t3 on t2._tid_ = t3._tid_ and t2._attribute_ = t3.attribute\n            left join {inf_values_dom} as t4 on t2._tid_ = t4._tid_ and t2._attribute_ = t4.attribute where t1._tid_ = t2._tid_ and t1.attribute = t2._attribute_\n        group by\n            clean,\n            status,\n            inferred,\n            init_eq_grdth,\n            init_eq_infer,\n            wl_eq_init,\n            wl_eq_grdth,\n            wl_eq_infer,\n            infer_eq_grdth\n        """""".format(cell_domain=AuxTables.cell_domain.name,\n                clean_data=self.clean_data.name,\n                dk_cells=AuxTables.dk_cells.name,\n                inf_values_dom=AuxTables.inf_values_dom.name)\n\n        res = self.ds.engine.execute_query(query)\n\n        df_stats = pd.DataFrame(res,\n                columns=[""is_clean"", ""cell_status"", ""is_inferred"",\n                    ""init = grdth"", ""init = inferred"",\n                    ""w. label = init"", ""w. label = grdth"", ""w. label = inferred"",\n                    ""infer = grdth"", ""count""])\n        df_stats = df_stats.sort_values(list(df_stats.columns)).reset_index(drop=True)\n        logging.debug(""weak label statistics:"")\n        pd.set_option(\'display.max_columns\', None)\n        pd.set_option(\'display.max_rows\', len(df_stats))\n        pd.set_option(\'display.max_colwidth\', -1)\n        logging.debug(""%s"", df_stats)\n        pd.reset_option(\'display.max_columns\')\n        pd.reset_option(\'display.max_rows\')\n        pd.reset_option(\'display.max_colwidth\')\n'"
examples/holoclean_repair_example.py,0,"b""import sys\nsys.path.append('../')\nimport holoclean\nfrom detect import NullDetector, ViolationDetector\nfrom repair.featurize import *\n\n\n# 1. Setup a HoloClean session.\nhc = holoclean.HoloClean(\n    db_name='holo',\n    domain_thresh_1=0,\n    domain_thresh_2=0,\n    weak_label_thresh=0.99,\n    max_domain=10000,\n    cor_strength=0.6,\n    nb_cor_strength=0.8,\n    epochs=10,\n    weight_decay=0.01,\n    learning_rate=0.001,\n    threads=1,\n    batch_size=1,\n    verbose=True,\n    timeout=3*60000,\n    feature_norm=False,\n    weight_norm=False,\n    print_fw=True\n).session\n\n# 2. Load training data and denial constraints.\nhc.load_data('hospital', '../testdata/hospital.csv')\nhc.load_dcs('../testdata/hospital_constraints.txt')\nhc.ds.set_constraints(hc.get_dcs())\n\n# 3. Detect erroneous cells using these two detectors.\ndetectors = [NullDetector(), ViolationDetector()]\nhc.detect_errors(detectors)\n\n# 4. Repair errors utilizing the defined features.\nhc.setup_domain()\nfeaturizers = [\n    InitAttrFeaturizer(),\n    OccurAttrFeaturizer(),\n    FreqFeaturizer(),\n    ConstraintFeaturizer(),\n]\n\nhc.repair_errors(featurizers)\n\n# 5. Evaluate the correctness of the results.\nhc.evaluate(fpath='../testdata/hospital_clean.csv',\n            tid_col='tid',\n            attr_col='attribute',\n            val_col='correct_val')\n"""
examples/holoclean_repair_example_db.py,0,"b""import sys\nsys.path.append('../')\nimport holoclean\nfrom detect import ErrorsLoaderDetector\nfrom repair.featurize import *\n\n\n# 1. Setup a HoloClean session.\nhc = holoclean.HoloClean(\n    db_name='holo',\n    domain_thresh_1=0,\n    domain_thresh_2=0,\n    weak_label_thresh=0.99,\n    max_domain=10000,\n    cor_strength=0.6,\n    nb_cor_strength=0.8,\n    epochs=10,\n    weight_decay=0.01,\n    learning_rate=0.001,\n    threads=1,\n    batch_size=1,\n    verbose=True,\n    timeout=3*60000,\n    feature_norm=False,\n    weight_norm=False,\n    print_fw=True\n).session\n\n# 2. Load training data and denial constraints.\nhc.load_data('hospital', '../testdata/hospital.csv')\nhc.load_dcs('../testdata/hospital_constraints.txt')\nhc.ds.set_constraints(hc.get_dcs())\n\n# 3. Detect erroneous cells.\nerror_loader = ErrorsLoaderDetector(\n        db_engine=hc.ds.engine,\n        schema_name='hospital',\n        table_name='dk_cells'\n)\nhc.detect_errors([error_loader])\n\n# 4. Repair errors utilizing the defined features.\nhc.setup_domain()\nfeaturizers = [\n    OccurAttrFeaturizer(),\n    FreqFeaturizer(),\n    ConstraintFeaturizer(),\n]\n\nhc.repair_errors(featurizers)\n\n# 5. Evaluate the correctness of the results.\nhc.evaluate(fpath='../testdata/hospital_clean.csv',\n            tid_col='tid',\n            attr_col='attribute',\n            val_col='correct_val')\n"""
repair/__init__.py,0,"b""from .repair import RepairEngine\n\n__all__ = ['RepairEngine']\n"""
repair/repair.py,0,"b'import logging\nimport time\n\nimport pandas as pd\n\nfrom .featurize import FeaturizedDataset\nfrom .learn import RepairModel\nfrom dataset import AuxTables\n\n\nclass RepairEngine:\n    def __init__(self, env, dataset):\n        self.ds = dataset\n        self.env = env\n\n    def setup_featurized_ds(self, featurizers):\n        tic = time.clock()\n        self.feat_dataset = FeaturizedDataset(self.ds, self.env, featurizers)\n        toc = time.clock()\n        status = ""DONE setting up featurized dataset.""\n        feat_time = toc - tic\n        return status, feat_time\n\n    def setup_repair_model(self):\n        tic = time.clock()\n        feat_info = self.feat_dataset.featurizer_info\n        output_dim = self.feat_dataset.classes\n        self.repair_model = RepairModel(self.env, feat_info, output_dim, bias=self.env[\'bias\'])\n        toc = time.clock()\n        status = ""DONE setting up repair model.""\n        setup_time = toc - tic\n        return status, setup_time\n\n    def fit_repair_model(self):\n        tic = time.clock()\n        X_train, Y_train, mask_train = self.feat_dataset.get_training_data()\n        logging.info(\'training with %d training examples (cells)\', X_train.shape[0])\n        self.repair_model.fit_model(X_train, Y_train, mask_train)\n        toc = time.clock()\n        status = ""DONE training repair model.""\n        train_time = toc - tic\n        return status, train_time\n\n    def infer_repairs(self):\n        tic = time.clock()\n        X_pred, mask_pred, infer_idx = self.feat_dataset.get_infer_data()\n        Y_pred = self.repair_model.infer_values(X_pred, mask_pred)\n        distr_df, infer_val_df = self.get_infer_dataframes(infer_idx, Y_pred)\n        self.ds.generate_aux_table(AuxTables.cell_distr, distr_df, store=True, index_attrs=[\'_vid_\'])\n        self.ds.generate_aux_table(AuxTables.inf_values_idx, infer_val_df, store=True, index_attrs=[\'_vid_\'])\n        toc = time.clock()\n        status = ""DONE inferring repairs.""\n        infer_time = toc - tic\n        return status, infer_time\n\n    def get_infer_dataframes(self, infer_idx, Y_pred):\n        distr = []\n        infer_val = []\n        Y_assign = Y_pred.data.numpy().argmax(axis=1)\n        domain_size = self.feat_dataset.var_to_domsize\n\n        # Need to map the inferred value index of the random variable to the actual value\n        # val_idx = val_id - 1 since val_id was numbered starting from 1 whereas\n        # val_idx starts at 0.\n        query = \'SELECT _vid_, val_id-1, rv_val FROM {pos_values}\'.format(pos_values=AuxTables.pos_values.name)\n        pos_values = self.ds.engine.execute_query(query)\n        # dict mapping _vid_ --> val_idx --> value\n        vid_to_val = {}\n        for vid, val_idx, val in pos_values:\n            vid_to_val[vid] = vid_to_val.get(vid, {})\n            vid_to_val[vid][val_idx] = val\n\n        for idx in range(Y_pred.shape[0]):\n            vid = int(infer_idx[idx])\n            rv_distr = list(Y_pred[idx].data.numpy())\n            rv_val_idx = int(Y_assign[idx])\n            rv_val = vid_to_val[vid][rv_val_idx]\n            rv_prob = Y_pred[idx].data.numpy().max()\n            d_size = domain_size[vid]\n            distr.append({\'_vid_\': vid, \'distribution\':[str(p) for p in rv_distr[:d_size]]})\n            infer_val.append({\'_vid_\': vid, \'inferred_val_idx\': rv_val_idx, \'inferred_val\': rv_val, \'prob\':rv_prob})\n        distr_df = pd.DataFrame(data=distr)\n        infer_val_df = pd.DataFrame(data=infer_val)\n        return distr_df, infer_val_df\n\n    def get_featurizer_weights(self):\n        tic = time.clock()\n        report = self.repair_model.get_featurizer_weights(self.feat_dataset.featurizer_info)\n        toc = time.clock()\n        report_time = toc - tic\n        return report, report_time\n'"
tests/__init__.py,0,"b""from .testutils import random_database, delete_database\n\n__all__ = ['random_database', 'delete_database']\n"""
tests/test_holoclean_repair.py,0,"b""from detect import NullDetector, ViolationDetector\nimport holoclean\nfrom repair.featurize import *\n\nfrom tests.testutils import random_database, delete_database\n\nTOL = 1e-9\n\n\ndef test_hospital_with_init():\n    db_name = random_database()\n\n    try:\n        # 1. Setup a HoloClean session.\n        hc = holoclean.HoloClean(\n            db_name=db_name,\n            domain_thresh_1=0.0,\n            domain_thresh_2=0.0,\n            weak_label_thresh=0.99,\n            max_domain=10000,\n            cor_strength=0.6,\n            nb_cor_strength=0.8,\n            epochs=10,\n            weight_decay=0.01,\n            learning_rate=0.001,\n            threads=1,\n            batch_size=1,\n            verbose=True,\n            timeout=3 * 60000,\n            feature_norm=False,\n            weight_norm=False,\n            print_fw=True\n        ).session\n\n        # 2. Load training data and denial constraints.\n        hc.load_data('hospital', '../testdata/hospital.csv')\n        hc.load_dcs('../testdata/hospital_constraints.txt')\n        hc.ds.set_constraints(hc.get_dcs())\n\n        # 3. Detect erroneous cells using these two detectors.\n        detectors = [NullDetector(), ViolationDetector()]\n        hc.detect_errors(detectors)\n\n        # 4. Repair errors utilizing the defined features.\n        hc.setup_domain()\n        featurizers = [\n            InitAttrFeaturizer(),\n            OccurAttrFeaturizer(),\n            FreqFeaturizer(),\n            ConstraintFeaturizer(),\n        ]\n\n        hc.repair_errors(featurizers)\n\n        # 5. Evaluate the correctness of the results.\n        report = hc.evaluate(fpath='../testdata/hospital_clean.csv',\n                    tid_col='tid',\n                    attr_col='attribute',\n                    val_col='correct_val')\n\n        # We assert that our key metrics are exactly as tested for hospital.\n        # If these assertions ever fail in a new change, the results should\n        # be comparable if not better than before, unless a clear and correct\n        # reason can be given.\n        assert report.correct_repairs == 232\n        assert report.total_repairs == 232\n        assert abs(report.precision - 1.) < TOL\n        assert abs(report.recall - 232. / 509) < TOL\n        assert abs(report.repair_recall - 232. / 435) < TOL\n        assert report.total_repairs_grdt_correct == 0\n    finally:\n        delete_database(db_name)\n\ndef test_hospital_without_init():\n    db_name = random_database()\n\n    try:\n        # 1. Setup a HoloClean session.\n        hc = holoclean.HoloClean(\n            db_name='holo',\n            domain_thresh_1=0.0,\n            domain_thresh_2=0.0,\n            weak_label_thresh=0.99,\n            max_domain=10000,\n            cor_strength=0.6,\n            nb_cor_strength=0.8,\n            epochs=10,\n            weight_decay=0.01,\n            learning_rate=0.001,\n            threads=1,\n            batch_size=1,\n            verbose=True,\n            timeout=3 * 60000,\n            feature_norm=False,\n            weight_norm=False,\n            print_fw=True\n        ).session\n\n        # 2. Load training data and denial constraints.\n        hc.load_data('hospital', '../testdata/hospital.csv')\n        hc.load_dcs('../testdata/hospital_constraints.txt')\n        hc.ds.set_constraints(hc.get_dcs())\n\n        # 3. Detect erroneous cells using these two detectors.\n        detectors = [NullDetector(), ViolationDetector()]\n        hc.detect_errors(detectors)\n\n        # 4. Repair errors utilizing the defined features.\n        hc.setup_domain()\n        featurizers = [\n            OccurAttrFeaturizer(),\n            FreqFeaturizer(),\n            ConstraintFeaturizer(),\n        ]\n\n        hc.repair_errors(featurizers)\n\n        # 5. Evaluate the correctness of the results.\n        report = hc.evaluate(fpath='../testdata/hospital_clean.csv',\n                    tid_col='tid',\n                    attr_col='attribute',\n                    val_col='correct_val')\n\n        # We assert that our key metrics are exactly as tested for hospital.\n        # If these assertions ever fail in a new change, the results should\n        # be comparable if not better than before, unless a clear and correct\n        # reason can be given.\n        assert report.correct_repairs == 434\n        assert report.total_repairs == 456\n        assert abs(report.precision - 434. / 456) < TOL\n        assert abs(report.recall - 434. / 509) < TOL\n        assert abs(report.repair_recall - 434. / 435) < TOL\n        assert report.total_repairs_grdt_correct == 22\n    finally:\n        delete_database(db_name)\n"""
tests/testutils.py,0,"b'import random\n\nfrom psycopg2 import connect\nfrom psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n\n\ndef random_database():\n    """"""\n    Creates a random database in the testing Postgres instance and returns the\n    name of the database.\n    """"""\n    # Setup connection with default credentials for testing.\n    with connect(dbname=\'holo\', user=\'holocleanuser\', password=\'abcd1234\', host=\'localhost\') as conn:\n        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n        with conn.cursor() as cur:\n            while True:\n                # Generate a random DB name that is not already in Postgres.\n                db_name = \'test_holo_{}\'.format(random.randint(0, 1e6))\n                cur.execute(""""""\n                    SELECT EXISTS(\n                        SELECT datname FROM pg_catalog.pg_database\n                        WHERE datname = \'{db_name}\'\n                    );\n                """""".format(db_name=db_name))\n                if cur.fetchall()[0][0]:\n                    continue\n\n                cur.execute(""CREATE DATABASE {db_name}"".format(db_name=db_name))\n                return db_name\n\ndef delete_database(db_name):\n    with connect(dbname=\'holo\', user=\'holocleanuser\', password=\'abcd1234\', host=\'localhost\') as conn:\n        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n        with conn.cursor() as cur:\n            # Terminate un-closed connections.\n            cur.execute(""""""\n            SELECT pid, pg_terminate_backend(pid)\n            FROM pg_stat_activity\n            WHERE datname = \'{db_name}\' AND pid <> pg_backend_pid();"""""".format(db_name=db_name))\n            # Drop the database.\n            cur.execute(""DROP DATABASE IF EXISTS {db_name}"".format(db_name=db_name))\n'"
domain/estimators/__init__.py,0,"b""from .logistic import Logistic\nfrom .naive_bayes import NaiveBayes\n\n\n__all__ = ['Logistic', 'NaiveBayes']\n"""
domain/estimators/logistic.py,14,"b'from abc import ABCMeta, abstractmethod\nimport logging\n\nimport time\nimport torch\nfrom torch.optim import Adam, SGD\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom tqdm import tqdm\n\nfrom ..estimator import Estimator\nfrom utils import NULL_REPR, NA_COOCCUR_FV\n\n\nclass Logistic(Estimator, torch.nn.Module):\n    """"""\n    Logistic is an Estimator that approximates posterior of\n    p(v_cur | v_init) by training a logistic regression model to predict the current\n    value in a cell given all other initial values using features\n    of the other initial values such as co-occurrence.\n    """"""\n    # We should not use weight decay for this posterior model since we\'d\n    # like to overfit as much as possible to the co-occurrence features.\n    # This is fine since we take only samples with high predicted probabilities.\n    WEIGHT_DECAY = 0\n\n    def __init__(self, env, dataset, domain_df, active_attrs):\n        """"""\n        :param dataset: (Dataset) original dataset\n        :param domain_df: (DataFrame) currently populated domain dataframe.\n            Required columns are: _vid_, _tid_, attribute, domain, domain_size, init_value\n        :param active_attrs: (list[str]) attributes that have random values\n        """"""\n        torch.nn.Module.__init__(self)\n        Estimator.__init__(self, env, dataset)\n\n        self.active_attrs = active_attrs\n\n        # Sorted records of the currently populated domain. This helps us\n        # align the final predicted probabilities.\n        self.domain_records = domain_df.sort_values(\'_vid_\')[[\'_vid_\', \'_tid_\', \'attribute\', \'domain\', \'init_value\']].to_records()\n\n        # self.dom maps tid --> attr --> list of domain values\n        # we need to find the number of domain values we will be generating\n        # a training sample for.\n        self.n_samples = int(domain_df[\'domain_size\'].sum())\n\n        # Create and initialize featurizers.\n        self.featurizers = [CooccurAttrFeaturizer(self.ds)]\n        for f in self.featurizers:\n            f.setup()\n        self.num_features = sum(feat.num_features() for feat in self.featurizers)\n\n        # Construct the X and Y tensors.\n        self._gen_training_data()\n\n        # Use pytorch logistic regression model.\n        self._W = torch.nn.Parameter(torch.zeros(self.num_features, 1))\n        torch.nn.init.xavier_uniform_(self._W)\n        self._B = torch.nn.Parameter(torch.Tensor([1e-6]))\n\n        self._loss = torch.nn.BCELoss()\n        if self.env[\'optimizer\'] == \'sgd\':\n            self._optimizer = SGD(self.parameters(), lr=self.env[\'learning_rate\'], momentum=self.env[\'momentum\'],\n                                  weight_decay=self.WEIGHT_DECAY)\n        else:\n            self._optimizer = Adam(self.parameters(), lr=self.env[\'learning_rate\'], weight_decay=self.WEIGHT_DECAY)\n\n    def _gen_training_data(self):\n        """"""\n        _gen_training_data memoizes the self._X and self._Y tensors\n        used for training and prediction.\n        """"""\n        logging.debug(\'Logistic: featurizing training data...\')\n        tic = time.clock()\n        # Each row corresponds to a possible value for a given attribute\n        # and given TID\n        self._X = torch.zeros(self.n_samples, self.num_features)\n        self._Y = torch.zeros(self.n_samples)\n        # Keeps track of cells with NULL init_value to ignore in training.\n        # We only train on cells when train_idx[idx] == 1.\n        self._train_idx = torch.zeros(self.n_samples)\n\n        """"""\n        Iterate through the domain for every cell and create a sample\n        to use in training. We assign Y as 1 if the value is the initial value.\n        """"""\n        sample_idx = 0\n        raw_data_dict = self.ds.raw_data.df.set_index(\'_tid_\').to_dict(\'index\')\n        # Keep track of which indices correspond to a VID so we can re-use\n        # self._X in prediction.\n        self.vid_to_idxs = {}\n        for rec in tqdm(list(self.domain_records)):\n            init_row = raw_data_dict[rec[\'_tid_\']]\n            domain_vals = rec[\'domain\'].split(\'|||\')\n\n            # Generate the feature tensor for all the domain values for this\n            # cell.\n            feat_tensor = self._gen_feat_tensor(init_row, rec[\'attribute\'], domain_vals)\n            assert(feat_tensor.shape[0] == len(domain_vals))\n            self._X[sample_idx:sample_idx+len(domain_vals)] = feat_tensor\n\n            self.vid_to_idxs[rec[\'_vid_\']] = (sample_idx, sample_idx+len(domain_vals))\n\n            # If the initial value is NULL, we do not want to train on it\n            # nor assign it a weak label.\n            if rec[\'init_value\'] == NULL_REPR:\n                sample_idx += len(domain_vals)\n                continue\n\n            # If the init value is not NULL, then we want to use these possible\n            # value samples during training.\n            self._train_idx[sample_idx:sample_idx + len(domain_vals)] = 1\n            # Assign the tensor corresponding to the initial value with\n            # a target label of 1.\n            init_idx = domain_vals.index(rec[\'init_value\'])\n            self._Y[sample_idx + init_idx] = 1\n\n            sample_idx += len(domain_vals)\n\n        # Convert this to a vector of indices rather than a vector mask.\n        self._train_idx = (self._train_idx == 1).nonzero()[:,0]\n\n        logging.debug(\'Logistic: DONE featurization in %.2fs\', time.clock() - tic)\n\n    def _gen_feat_tensor(self, init_row, attr, domain_vals):\n        """"""\n        Generates the feature tensor for the list of :param`domain_vals` from\n        all featurizers.\n\n        :param init_row: (namedtuple or dict) current initial values\n        :param attr: (str) attribute of row (i.e. cell) the :param values: correspond to\n            and the cell to generate a feature tensor for.\n        :param domain_vals: (list[str]) domain values to featurize for\n\n        :return: Tensor with dimensions (len(values), total # of features across all featurizers)\n        """"""\n\n        return torch.cat([f.create_tensor(init_row, attr, domain_vals) for f in self.featurizers], dim=1)\n\n    def forward(self, X):\n        linear = X.matmul(self._W) + self._B\n        return torch.sigmoid(linear)\n\n    def train(self, num_epochs=3, batch_size=32):\n        """"""\n        Trains the LR model.\n\n        :param num_epochs: (int) number of epochs.\n        """"""\n        batch_losses = []\n        # We train only on cells that do not have their initial value as NULL.\n        X_train, Y_train = self._X.index_select(0, self._train_idx), self._Y.index_select(0, self._train_idx)\n        torch_ds = TensorDataset(X_train, Y_train)\n\n        # Main training loop.\n        for epoch_idx in range(1, num_epochs+1):\n            logging.debug(""Logistic: epoch %d"", epoch_idx)\n            batch_cnt = 0\n            for batch_X, batch_Y in tqdm(DataLoader(torch_ds, batch_size=batch_size)):\n                batch_pred = self.forward(batch_X)\n                batch_loss = self._loss(batch_pred, batch_Y.reshape(-1,1))\n                batch_losses.append(float(batch_loss))\n                self.zero_grad()\n                batch_loss.backward()\n                self._optimizer.step()\n                batch_cnt += 1\n            logging.debug(\'Logistic: average batch loss: %f\', sum(batch_losses[-1 * batch_cnt:]) / batch_cnt)\n        return batch_losses\n\n    def predict_pp(self, row, attr=None, values=None):\n        """"""\n        predict_pp generates posterior probabilities for the domain values\n        corresponding to the cell/random variable row[\'_vid_\'].\n\n        That is: :param`attr` and :param`values` are ignored.\n\n        predict_pp_batch is much faster for Logistic since it simply does\n        a one-pass of the batch feature tensor.\n\n        :return: (list[2-tuple]) 2-tuples corresponding to (value, proba)\n        """"""\n        start_idx, end_idx = self.vid_to_idxs[row[\'_vid_\']]\n        pred_X = self._X[start_idx:end_idx]\n        pred_Y = self.forward(pred_X)\n        values = self.domain_records[row[\'_vid_\']][\'domain\'].split(\'|||\')\n        return zip(values, map(float, pred_Y))\n\n    def predict_pp_batch(self):\n        """"""\n        Performs batch prediction.\n        """"""\n        pred_Y = self.forward(self._X)\n        for rec in self.domain_records:\n            values = rec[\'domain\'].split(\'|||\')\n            start_idx, end_idx = self.vid_to_idxs[rec[\'_vid_\']]\n            yield zip(values, map(float, pred_Y[start_idx:end_idx]))\n\nclass Featurizer:\n    """"""\n    Feauturizer is an abstract class for featurizers that is able to generate\n    real-valued tensors (features) for a row from raw data.\n    Used in Logistic model.\n    """"""\n    __metaclass__ = ABCMeta\n\n    @abstractmethod\n    def setup(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def num_features(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def create_tensor(self, row, attr, values):\n        raise NotImplementedError\n\n\nclass CooccurAttrFeaturizer(Featurizer):\n    """"""\n    CooccurAttrFeaturizer computes the co-occurrence statistics for a cell\n    and its possible domain values with the other initial values in the tuple.\n    It breaks down each co-occurrence feature on a pairwise attr1 X attr2 basis.\n    """"""\n    name = \'CooccurAttrFeaturizer\'\n\n    def __init__(self, dataset):\n        """"""\n        :param data_df: (pandas.DataFrame) contains the data to compute co-occurrence features for.\n        :param attrs: attributes in columns of :param data_df: to compute feautres for.\n        :param freq: (dict { attr: { val: count } } }) if not None, uses these\n            frequency statistics instead of computing it from data_df.\n        :param cooccur_freq: (dict { attr1: { attr2: { val1: { val2: count } } } })\n            if not None, uses these co-occurrence statistics instead of\n            computing it from data_df.\n        """"""\n        self.ds = dataset\n        self.attrs = self.ds.get_attributes()\n        self.attr_to_idx = {attr: idx for idx, attr in enumerate(self.attrs)}\n        self.n_attrs = len(self.attrs)\n\n    def num_features(self):\n        return len(self.attrs) * len(self.attrs)\n\n    def setup(self):\n        _, self.freq, self.cooccur_freq = self.ds.get_statistics()\n\n    def create_tensor(self, row, attr, values):\n        """"""\n        :param row: (namedtuple or dict) current initial values\n        :param attr: (str) attribute of row (i.e. cell) the :param values: correspond to\n            and the cell to generate a feature tensor for.\n        :param values: (list[str]) values to generate\n\n        :return: Tensor with dimensions (len(values), # of features)\n        """"""\n        tensor = torch.zeros(len(values), self.num_features())\n        for val_idx, val in enumerate(values):\n            for other_attr_idx, other_attr in enumerate(self.attrs):\n                if attr == other_attr:\n                    continue\n\n                other_val = row[other_attr]\n\n                # calculate p(val | other_val)\n                # there may not be co-occurrence frequencies for some value pairs since\n                # our possible values were from correlation with only\n                # one other attribute\n                if val == NULL_REPR or other_val == NULL_REPR:\n                    fv = NA_COOCCUR_FV\n                else:\n                    cooccur = self.cooccur_freq[attr][other_attr].get(val, {}).get(other_val, NA_COOCCUR_FV)\n                    freq = self.freq[other_attr][row[other_attr]]\n                    fv = float(cooccur) / float(freq)\n\n                feat_idx = self.attr_to_idx[attr] * self.n_attrs + other_attr_idx\n                tensor[val_idx, feat_idx] = fv\n        return tensor\n'"
domain/estimators/naive_bayes.py,0,"b'import math\n\nfrom tqdm import tqdm\n\nfrom ..estimator import Estimator\nfrom utils import NULL_REPR\n\n\nclass NaiveBayes(Estimator):\n    """"""\n    NaiveBayes is an estimator of posterior probabilities using the naive\n    independence assumption where\n        p(v_cur | v_init) = p(v_cur) * \\prod_i (v_init_i | v_cur)\n    where v_init_i is the init value for corresponding to attribute i. This\n    probability is normalized over all values passed into predict_pp.\n    """"""\n    def __init__(self, env, dataset, domain_df, correlations):\n        Estimator.__init__(self, env, dataset)\n\n        self._n_tuples, self._freq, self._cooccur_freq = self.ds.get_statistics()\n        self.domain_df = domain_df\n        self._correlations = correlations\n        self._cor_strength = self.env[\'nb_cor_strength\']\n        self._corr_attrs = {}\n\n        # TID to raw data tuple for prediction.\n        self._raw_records_by_tid = {}\n        for row in self.ds.get_raw_data().to_records():\n            self._raw_records_by_tid[row[\'_tid_\']] = row\n\n    def train(self):\n        pass\n\n    def predict_pp(self, row, attr, values):\n        nb_score = []\n        correlated_attributes = self._get_corr_attributes(attr)\n        for val1 in values:\n            val1_count = self._freq[attr][val1]\n            log_prob = math.log(float(val1_count) / float(self._n_tuples))\n            for at in correlated_attributes:\n                # Ignore same attribute, index, and tuple id.\n                if at == attr or at == \'_tid_\':\n                    continue\n                val2 = row[at]\n                # Since we do not have co-occurrence stats with NULL values,\n                # we skip them.\n                # It also doesn\'t make sense for our likelihood to be conditioned\n                # on a NULL value.\n                if val2 == NULL_REPR:\n                    continue\n                val2_val1_count = 0.1\n                if val1 in self._cooccur_freq[attr][at]:\n                    if val2 in self._cooccur_freq[attr][at][val1]:\n                        val2_val1_count = max(self._cooccur_freq[attr][at][val1][val2] - 1.0, 0.1)\n                p = float(val2_val1_count) / float(val1_count)\n                log_prob += math.log(p)\n            nb_score.append((val1, log_prob))\n\n        denom = sum(map(math.exp, [log_prob for _, log_prob in nb_score]))\n\n        for val, log_prob in nb_score:\n            yield (val, math.exp(log_prob) / denom)\n\n    def predict_pp_batch(self):\n        """"""\n        Performs batch prediction.\n\n        This technically invokes predict_pp underneath.\n\n        Returns a List[List[Tuple]] where each List[Tuple] corresponds to\n        a cell (ordered by the order a cell appears in `self.domain_df`\n        during construction) and each Tuple is (val, proba) where\n        val is the domain value and proba is the estimator\'s posterior probability estimate.\n        """"""\n        for row in tqdm(self.domain_df.to_records()):\n            yield self.predict_pp(self._raw_records_by_tid[row[\'_tid_\']], row[\'attribute\'], row[\'domain\'].split(\'|||\'))\n\n    def _get_corr_attributes(self, attr):\n        """"""\n        TODO: refactor this with Domain::get_corr_attributes().\n        """"""\n        if (attr, self._cor_strength) not in self._corr_attrs:\n            self._corr_attrs[(attr, self._cor_strength)] = []\n\n            if attr in self._correlations:\n                attr_correlations = self._correlations[attr]\n                self._corr_attrs[(attr, self._cor_strength)] = [corr_attr\n                                                                for corr_attr, corr_strength in attr_correlations.items()\n                                                                if corr_attr != attr and corr_strength > self._cor_strength]\n\n        return self._corr_attrs[(attr, self._cor_strength)]\n'"
repair/featurize/__init__.py,0,"b""from .constraintfeat import ConstraintFeaturizer\nfrom .featurized_dataset import FeaturizedDataset\nfrom .featurizer import Featurizer\nfrom .freqfeat import FreqFeaturizer\nfrom .initattrfeat import InitAttrFeaturizer\nfrom .initsimfeat import InitSimFeaturizer\nfrom .langmodelfeat import LangModelFeaturizer\nfrom .occurattrfeat import OccurAttrFeaturizer\n\n__all__ = ['ConstraintFeaturizer',\n           'FeaturizedDataset',\n           'Featurizer',\n           'FreqFeaturizer',\n           'InitAttrFeaturizer',\n           'InitSimFeaturizer',\n           'LangModelFeaturizer',\n           'OccurAttrFeaturizer']\n"""
repair/featurize/constraintfeat.py,3,"b'from string import Template\nfrom functools import partial\n\nimport torch\nimport torch.nn.functional as F\n\nfrom .featurizer import Featurizer\nfrom dataset import AuxTables\nfrom dcparser.constraint import is_symmetric, get_flip_operation\n\n# unary_template is used for constraints where the current predicate\n# used for detecting violations in pos_values have a reference to only\n# one relation\'s (e.g. t1) attribute on one side and a fixed constant\n# value on the other side of the comparison.\nunary_template = Template(\'SELECT _vid_, val_id, count(*) violations \'\n                          \'FROM   ""$init_table"" as t1, $pos_values as t2 \'\n                          \'WHERE  t1._tid_ = t2._tid_ \'\n                          \'  AND  t2.attribute = \\\'$rv_attr\\\' \'\n                          \'  AND  $orig_predicates \'\n                          \'  AND  t2.rv_val $operation $rv_val \'\n                          \'GROUP BY _vid_, val_id\')\n\n# binary_template is used for constraints where the current predicate\n# used for detecting violations in pos_values have a reference to both\n# relations (t1, t2) i.e. no constant value in predicate.\nbinary_template = Template(\'SELECT _vid_, val_id, count(*) violations \'\n                           \'FROM   ""$init_table"" as t1, ""$init_table"" as t2, $pos_values as t3 \'\n                           \'WHERE  t1._tid_ != t2._tid_ \'\n                           \'  AND  $join_rel._tid_ = t3._tid_ \'\n                           \'  AND  t3.attribute = \\\'$rv_attr\\\' \'\n                           \'  AND  $orig_predicates \'\n                           \'  AND  t3.rv_val $operation $rv_val \'\n                           \'GROUP BY _vid_, val_id\')\n\n# ex_binary_template is used as a fallback for binary_template in case\n# binary_template takes too long to query. Instead of counting the # of violations\n# this returns simply a 0-1 indicator if the possible value violates the constraint.\nex_binary_template = Template(\'SELECT _vid_, val_id, 1 violations \'\n                              \'FROM   ""$init_table"" as $join_rel, $pos_values as t3 \'\n                              \'WHERE  $join_rel._tid_ = t3._tid_ \'\n                              \'  AND  t3.attribute = \\\'$rv_attr\\\' \'\n                              \'  AND EXISTS (SELECT $other_rel._tid_ \'\n                              \'              FROM   ""$init_table"" AS $other_rel \'\n                              \'              WHERE  $join_rel._tid_ != $other_rel._tid_ \'\n                              \'                AND  $orig_predicates \'\n                              \'                AND  t3.rv_val $operation $rv_val)\')\n\n\ndef gen_feat_tensor(violations, total_vars, classes):\n    tensor = torch.zeros(total_vars,classes,1)\n    if violations:\n        for entry in violations:\n            vid = int(entry[0])\n            val_id = int(entry[1]) - 1\n            feat_val = float(entry[2])\n            tensor[vid][val_id][0] = feat_val\n    return tensor\n\n\nclass ConstraintFeaturizer(Featurizer):\n    def specific_setup(self):\n        self.name = \'ConstraintFeaturizer\'\n        self.constraints = self.ds.constraints\n        self.init_table_name = self.ds.raw_data.name\n\n    def create_tensor(self):\n        queries = self.generate_relaxed_sql()\n        results = self.ds.engine.execute_queries_w_backup(queries)\n        tensors = self._apply_func(partial(gen_feat_tensor, total_vars=self.total_vars, classes=self.classes), results)\n        combined = torch.cat(tensors,2)\n        combined = F.normalize(combined, p=2, dim=1)\n        return combined\n\n    def generate_relaxed_sql(self):\n        query_list = []\n        for c in self.constraints:\n            # Check tuples in constraint\n            unary = (len(c.tuple_names) == 1)\n            if unary:\n                queries = self.gen_unary_queries(c)\n            else:\n                queries = self.gen_binary_queries(c)\n            query_list.extend(queries)\n        return query_list\n\n    def execute_queries(self,queries):\n        return self.ds.engine.execute_queries_w_backup(queries)\n\n    def relax_unary_predicate(self, predicate):\n        """"""\n        relax_binary_predicate returns the attribute, operation, and\n        tuple attribute reference.\n\n        :return: (attr, op, const), for example:\n            (""StateAvg"", ""<>"", \'t1.""StateAvg""\')\n        """"""\n        attr = predicate.components[0][1]\n        op = predicate.operation\n        comp = predicate.components[1]\n        # do not quote literals/constants in comparison\n        const = comp if comp.startswith(\'\\\'\') else \'""{}""\'.format(comp)\n        return attr, op, const\n\n    def relax_binary_predicate(self, predicate, rel_idx):\n        """"""\n        relax_binary_predicate returns the attribute, operation, and\n        tuple attribute reference.\n\n        :return: (attr, op, const), for example:\n            (""StateAvg"", ""<>"", \'t1.""StateAvg""\')\n        """"""\n        attr = predicate.components[rel_idx][1]\n        op = predicate.operation\n        # the latter one should flip the operation,\n        # if t3.rv_val is always on the left side in query template\n        if rel_idx == 1:\n            op = get_flip_operation(op)\n        const = \'{}.""{}""\'.format(\n                predicate.components[1-rel_idx][0],\n                predicate.components[1-rel_idx][1])\n\n        return attr, op, const\n\n    def get_binary_predicate_join_rel(self, predicate):\n        if \'t1\' in predicate.cnf_form and \'t2\' in predicate.cnf_form:\n            if is_symmetric(predicate.operation):\n                return True, [\'t1\'], [\'t2\']\n            else:\n                return True, [\'t1\',\'t2\'], [\'t2\', \'t1\']\n        elif \'t1\' in predicate.cnf_form and \'t2\' not in predicate.cnf_form:\n            return False, [\'t1\'], None\n        elif \'t1\' not in predicate.cnf_form and \'t2\' in predicate.cnf_form:\n            return False, [\'t2\'], None\n\n    def gen_unary_queries(self, constraint):\n        # Iterate over predicates and relax one predicate at a time\n        queries = []\n        predicates = constraint.predicates\n        for k in range(len(predicates)):\n            orig_cnf = self._orig_cnf(predicates, k)\n            # If there are no other predicates in the constraint,\n            # append TRUE to the WHERE condition. This avoids having\n            # multiple SQL templates.\n            if len(orig_cnf) == 0:\n                orig_cnf = \'TRUE\'\n            rv_attr, op, rv_val = self.relax_unary_predicate(predicates[k])\n            query = unary_template.substitute(init_table=self.init_table_name,\n                                              pos_values=AuxTables.pos_values.name,\n                                              orig_predicates=orig_cnf,\n                                              rv_attr=rv_attr,\n                                              operation=op,\n                                              rv_val=rv_val)\n            queries.append((query, \'\'))\n        return queries\n\n    def gen_binary_queries(self, constraint):\n        queries = []\n        predicates = constraint.predicates\n        for k in range(len(predicates)):\n            orig_cnf = self._orig_cnf(predicates, k)\n            # If there are no other predicates in the constraint,\n            # append TRUE to the WHERE condition. This avoids having\n            # multiple SQL templates.\n            if len(orig_cnf) == 0:\n                orig_cnf = \'TRUE\'\n            is_binary, join_rel, other_rel = self.get_binary_predicate_join_rel(predicates[k])\n            if not is_binary:\n                rv_attr, op, rv_val = self.relax_unary_predicate(predicates[k])\n                query = binary_template.substitute(init_table=self.init_table_name,\n                                                   pos_values=AuxTables.pos_values.name,\n                                                   join_rel=join_rel[0],\n                                                   orig_predicates=orig_cnf,\n                                                   rv_attr=rv_attr,\n                                                   operation=op,\n                                                   rv_val=rv_val)\n                queries.append((query, \'\'))\n            else:\n                for idx, rel in enumerate(join_rel):\n                    rv_attr, op, rv_val = self.relax_binary_predicate(predicates[k], idx)\n                    # count # of queries\n                    query = binary_template.substitute(init_table=self.init_table_name,\n                                                       pos_values=AuxTables.pos_values.name,\n                                                       join_rel=rel,\n                                                       orig_predicates=orig_cnf,\n                                                       rv_attr=rv_attr,\n                                                       operation=op,\n                                                       rv_val=rv_val)\n                    # fallback 0-1 query instead of count\n                    ex_query = ex_binary_template.substitute(init_table=self.init_table_name,\n                                                             pos_values=AuxTables.pos_values.name,\n                                                             join_rel=rel,\n                                                             orig_predicates=orig_cnf,\n                                                             rv_attr=rv_attr,\n                                                             operation=op,\n                                                             rv_val=rv_val,\n                                                             other_rel=other_rel[idx])\n                    queries.append((query, ex_query))\n        return queries\n\n    def _orig_cnf(self, predicates, idx):\n        """"""\n        _orig_cnf returns the CNF form of the predicates that does not include\n        the predicate at index :param idx:.\n\n        This CNF is usually used for the left relation when counting violations.\n        """"""\n        orig_preds = predicates[:idx] + predicates[(idx+1):]\n        orig_cnf = "" AND "".join([pred.cnf_form for pred in orig_preds])\n        return orig_cnf\n\n    def feature_names(self):\n        return [""fixed pred: {}, violation pred: {}"".format(self._orig_cnf(constraint.predicates, idx),\n                                                            constraint.predicates[idx].cnf_form)\n                for constraint in self.constraints\n                for idx in range(len(constraint.predicates))]\n'"
repair/featurize/featurized_dataset.py,5,"b'from collections import namedtuple\nimport logging\n\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\n\nfrom dataset import AuxTables, CellStatus\nfrom utils import NULL_REPR\n\nFeatInfo = namedtuple(\'FeatInfo\', [\'name\', \'size\', \'learnable\', \'init_weight\', \'feature_names\'])\n\n\nclass FeaturizedDataset:\n    def __init__(self, dataset, env, featurizers):\n        self.ds = dataset\n        self.env = env\n        self.total_vars, self.classes = self.ds.get_domain_info()\n        self.processes = self.env[\'threads\']\n        for f in featurizers:\n            f.setup_featurizer(self.ds, self.processes, self.env[\'batch_size\'])\n        logging.debug(\'featurizing training data...\')\n        tensors = [f.create_tensor() for f in featurizers]\n        self.featurizer_info = [FeatInfo(featurizer.name,\n                                         tensor.size()[2],\n                                         featurizer.learnable,\n                                         featurizer.init_weight,\n                                         featurizer.feature_names())\n                                for tensor, featurizer in zip(tensors, featurizers)]\n        tensor = torch.cat(tensors, 2)\n        self.tensor = tensor\n\n        logging.debug(\'DONE featurization.\')\n\n        if self.env[\'debug_mode\']:\n            weights_df = pd.DataFrame(self.tensor.reshape(-1, self.tensor.shape[-1]).numpy())\n            weights_df.columns = [""{}::{}"".format(f.name, featname) for f in featurizers for featname in f.feature_names()]\n            weights_df.insert(0, \'vid\', np.floor_divide(np.arange(weights_df.shape[0]), self.tensor.shape[1]) + 1)\n            weights_df.insert(1, \'val_idx\', np.tile(np.arange(self.tensor.shape[1]), self.tensor.shape[0]))\n            weights_df.to_pickle(\'debug/{}_train_features.pkl\'.format(self.ds.id))\n\n        # TODO: remove after we validate it is not needed.\n        self.in_features = self.tensor.shape[2]\n        logging.debug(""generating weak labels..."")\n        self.weak_labels, self.is_clean = self.generate_weak_labels()\n        logging.debug(""DONE generating weak labels."")\n        logging.debug(""generating mask..."")\n        self.var_class_mask, self.var_to_domsize = self.generate_var_mask()\n        logging.debug(""DONE generating mask."")\n\n        if self.env[\'feature_norm\']:\n            logging.debug(""normalizing features..."")\n            n_cells, n_classes, n_feats = self.tensor.shape\n            # normalize within each cell the features\n            self.tensor = F.normalize(self.tensor, p=2, dim=1)\n            logging.debug(""DONE feature normalization."")\n\n    def generate_weak_labels(self):\n        """"""\n        generate_weak_labels returns a tensor where for each VID we have the\n        domain index of the initial value.\n\n        :return: Torch.Tensor of size (# of variables) X 1 where tensor[i][0]\n            contains the domain index of the initial value for the i-th\n            variable/VID.\n        """"""\n        # Generate weak labels for clean cells AND cells that have been weak\n        # labelled. Do not train on cells with NULL weak labels (i.e.\n        # NULL init values that were not weak labelled).\n        query = """"""\n        SELECT _vid_, weak_label_idx, fixed, (t2._cid_ IS NULL) AS clean\n        FROM {cell_domain} AS t1 LEFT JOIN {dk_cells} AS t2 ON t1._cid_ = t2._cid_\n        WHERE weak_label != \'{null_repr}\' AND (t2._cid_ is NULL OR t1.fixed != {cell_status});\n        """""".format(cell_domain=AuxTables.cell_domain.name,\n                dk_cells=AuxTables.dk_cells.name,\n                null_repr=NULL_REPR,\n                cell_status=CellStatus.NOT_SET.value)\n        res = self.ds.engine.execute_query(query)\n        if len(res) == 0:\n            raise Exception(""No weak labels available. Reduce pruning threshold."")\n        labels = -1 * torch.ones(self.total_vars, 1).type(torch.LongTensor)\n        is_clean = torch.zeros(self.total_vars, 1).type(torch.LongTensor)\n        for tuple in tqdm(res):\n            vid = int(tuple[0])\n            label = int(tuple[1])\n            fixed = int(tuple[2])\n            clean = int(tuple[3])\n            labels[vid] = label\n            is_clean[vid] = clean\n        return labels, is_clean\n\n    def generate_var_mask(self):\n        """"""\n        generate_var_mask returns a mask tensor where invalid domain indexes\n        for a given variable/VID has value -10e6.\n\n        An invalid domain index is possible since domain indexes are expanded\n        to the maximum domain size of a given VID: e.g. if a variable A has\n        10 unique values and variable B has 6 unique values, then the last\n        4 domain indexes (index 6-9) of variable B are invalid.\n\n        :return: Torch.Tensor of size (# of variables) X (max domain)\n            where tensor[i][j] = 0 iff the value corresponding to domain index \'j\'\n            is valid for the i-th VID and tensor[i][j] = -10e6 otherwise.\n        """"""\n        var_to_domsize = {}\n        query = \'SELECT _vid_, domain_size FROM %s\' % AuxTables.cell_domain.name\n        res = self.ds.engine.execute_query(query)\n        mask = torch.zeros(self.total_vars,self.classes)\n        for tuple in tqdm(res):\n            vid = int(tuple[0])\n            max_class = int(tuple[1])\n            mask[vid, max_class:] = -10e6\n            var_to_domsize[vid] = max_class\n        return mask, var_to_domsize\n\n    def get_tensor(self):\n        return self.tensor\n\n    def get_training_data(self):\n        """"""\n        get_training_data returns X_train, y_train, and mask_train\n        where each row of each tensor is a variable/VID and\n        y_train are weak labels for each variable i.e. they are\n        set as the initial values.\n\n        This assumes that we have a larger proportion of correct initial values\n        and only a small amount of incorrect initial values which allow us\n        to train to convergence.\n        """"""\n        train_idx = (self.weak_labels != -1).nonzero()[:,0]\n        X_train = self.tensor.index_select(0, train_idx)\n        Y_train = self.weak_labels.index_select(0, train_idx)\n        mask_train = self.var_class_mask.index_select(0, train_idx)\n        return X_train, Y_train, mask_train\n\n    def get_infer_data(self):\n        """"""\n        Retrieves the samples to be inferred i.e. DK cells.\n        """"""\n        # only infer on those that are DK cells\n        infer_idx = (self.is_clean == 0).nonzero()[:, 0]\n        X_infer = self.tensor.index_select(0, infer_idx)\n        mask_infer = self.var_class_mask.index_select(0, infer_idx)\n        return X_infer, mask_infer, infer_idx\n'"
repair/featurize/featurizer.py,0,"b'from abc import ABCMeta, abstractmethod\nfrom multiprocessing import Pool\n\n\nclass Featurizer:\n    __metaclass__ = ABCMeta\n\n    def __init__(self, learnable=True, init_weight=1.0):\n        self.name = None\n        self.setup_done = False\n        self.learnable = learnable\n        self.init_weight = init_weight\n\n    def setup_featurizer(self, dataset, processes=20, batch_size=32):\n        self.ds = dataset\n        self.total_vars, self.classes = self.ds.get_domain_info()\n        # only create a pool if processes > 1\n        self._pool = Pool(processes) if processes > 1 else None\n        self._batch_size = batch_size\n        self.setup_done = True\n        self.specific_setup()\n\n    @abstractmethod\n    def specific_setup(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def create_tensor(self):\n        """"""\n         This method creates a tensor which has shape\n         (# of cells/rvs, max size of domain, # of features for this featurizer)\n\n        :return: PyTorch Tensor\n        """"""\n        raise NotImplementedError\n\n    @abstractmethod\n    def feature_names(self):\n        """"""\n        Returns list of human-readable description/names for each feature\n        this featurizer produces.\n        """"""\n        raise NotImplementedError\n\n    def _apply_func(self, func, collection):\n        if self._pool is None:\n            return list(map(func, collection))\n        return self._pool.map(func, collection, min(self._batch_size, len(collection)))\n\n'"
repair/featurize/freqfeat.py,2,"b""import torch\n\nfrom dataset import AuxTables\nfrom .featurizer import Featurizer\n\n\nclass FreqFeaturizer(Featurizer):\n    def specific_setup(self):\n        self.name = 'FreqFeaturizer'\n        self.all_attrs = self.ds.get_attributes()\n        self.attrs_number = len(self.ds.attr_to_idx)\n        total, single_stats, pair_stats = self.ds.get_statistics()\n        self.total = total\n        self.single_stats = single_stats\n\n    def gen_feat_tensor(self, input, classes):\n        vid = int(input[0])\n        attribute = input[1]\n        domain = input[2].split('|||')\n        attr_idx = self.ds.attr_to_idx[attribute]\n        tensor = torch.zeros(1, classes, self.attrs_number)\n        for idx, val in enumerate(domain):\n            prob = float(self.single_stats[attribute][val])/float(self.total)\n            tensor[0][idx][attr_idx] = prob\n        return tensor\n\n    def create_tensor(self):\n        query = 'SELECT _vid_, attribute, domain FROM %s ORDER BY _vid_' % AuxTables.cell_domain.name\n        results = self.ds.engine.execute_query(query)\n        tensors = [self.gen_feat_tensor(res, self.classes) for res in results]\n        combined = torch.cat(tensors)\n        return combined\n\n    def feature_names(self):\n        return self.all_attrs\n"""
repair/featurize/initattrfeat.py,4,"b'from functools import partial\n\nimport torch\n\nfrom dataset import AuxTables\nfrom .featurizer import Featurizer\n\n\ndef gen_feat_tensor(input, classes, total_attrs):\n    vid = int(input[0])\n    attr_idx = input[1]\n    init_idx = int(input[2])\n    tensor = -1 * torch.ones(1, classes, total_attrs)\n    tensor[0][init_idx][attr_idx] = 1.0\n    return tensor\n\n\nclass InitAttrFeaturizer(Featurizer):\n\n    def __init__(self, init_weight=1.0):\n        """"""\n        InitAttrFeaturizer cannot be learnable.\n\n        :param init_weight: (float or list of floats) a fixed weight for all attributes\n                            or a list of floats that represent the weights of attributes\n                            in the same order in the dataset.\n        """"""\n        if isinstance(init_weight, list):\n            # If init_weight is a list, we convert to a tensor to be correctly\n            # initialized in the TiedLinear model initialization, where init_weight\n            # is multiplied by a tensor of ones for initialization.\n            init_weight = torch.FloatTensor(init_weight)\n\n        Featurizer.__init__(self, learnable=False, init_weight=init_weight)\n\n    def specific_setup(self):\n        self.name = \'InitAttrFeaturizer\'\n        self.all_attrs = self.ds.get_attributes()\n        self.attr_to_idx = self.ds.attr_to_idx\n        self.total_attrs = len(self.ds.attr_to_idx)\n        # Make sure that the size of \'init_weight\' equals to the number of attributes\n        # in the dataset.\n        if isinstance(self.init_weight, torch.FloatTensor):\n            if self.init_weight.shape[0] != len(self.all_attrs):\n                raise ValueError(""The size of init_weight for InitAttrFeaturizer %d does not match the number of attributes %d."" %  (self.init_weight.shape[0], len(self.all_attrs)))\n\n    def create_tensor(self):\n        query = \'SELECT _vid_, attribute, init_index FROM %s ORDER BY _vid_\' % AuxTables.cell_domain.name\n        results = self.ds.engine.execute_query(query)\n        map_input = []\n        for res in results:\n            map_input.append((res[0], self.attr_to_idx[res[1]], res[2]))\n        tensors = self._apply_func(partial(gen_feat_tensor, classes=self.classes, total_attrs=self.total_attrs), map_input)\n        combined = torch.cat(tensors)\n        return combined\n\n    def feature_names(self):\n        return self.all_attrs\n'"
repair/featurize/initsimfeat.py,4,"b'from functools import partial\n\nimport torch\nimport Levenshtein\n\nfrom dataset import AuxTables\nfrom .featurizer import Featurizer\n\n\ndef gen_feat_tensor(input, classes, total_attrs):\n    vid = int(input[0])\n    attr_idx = input[1]\n    init_value = input[2]\n    # TODO: To add more similarity metrics increase the last dimension of tensor.\n    tensor = torch.zeros(1, classes, total_attrs)\n    domain = input[3].split(\'|||\')\n    for idx, val in enumerate(domain):\n        if val == init_value:\n            sim = -1.0\n        else:\n            sim = (2 * Levenshtein.ratio(val, init_value)) - 1\n        tensor[0][idx][attr_idx] = sim\n    return tensor\n\n\nclass InitSimFeaturizer(Featurizer):\n\n    def __init__(self, init_weight=1.0):\n        """"""\n        InitSimFeaturizer cannot be learnable.\n\n        :param init_weight: (float or list of floats) a fixed weight for all attributes\n                            or a list of floats that represent the weights of attributes\n                            in the same order in the dataset.\n        """"""\n        if isinstance(init_weight, list):\n            # If init_weight is a list, we convert to a tensor to be correctly\n            # initialized in the TiedLinear model initialization, where init_weight\n            # is multiplied by a tensor of ones for initialization.\n            init_weight = torch.FloatTensor(init_weight)\n\n        Featurizer.__init__(self, learnable=False, init_weight=init_weight)\n\n    def specific_setup(self):\n        self.name = \'InitSimFeaturizer\'\n        self.all_attrs = self.ds.get_attributes()\n        self.attr_to_idx = self.ds.attr_to_idx\n        self.total_attrs = len(self.ds.attr_to_idx)\n        # Make sure that the size of \'init_weight\' equals to the number of attributes\n        # in the dataset.\n        if isinstance(self.init_weight, torch.FloatTensor):\n            if self.init_weight.shape[0] != len(self.all_attrs):\n                raise ValueError(""The size of init_weight for InitSimFeaturizer %d does not match the number of attributes %d."" % (self.init_weight.shape[0], len(self.all_attrs)))\n\n    def create_tensor(self):\n        query = \'SELECT _vid_, attribute, init_value, domain FROM %s ORDER BY _vid_\' % AuxTables.cell_domain.name\n        results = self.ds.engine.execute_query(query)\n        map_input = []\n        for res in results:\n            map_input.append((res[0], self.attr_to_idx[res[1]], res[2], res[3]))\n        tensors = self._apply_func(partial(gen_feat_tensor, classes=self.classes, total_attrs=self.total_attrs), map_input)\n        combined = torch.cat(tensors)\n        return combined\n\n    def feature_names(self):\n        return self.all_attrs\n'"
repair/featurize/langmodelfeat.py,3,"b'import torch\nfrom gensim.models import FastText\n\nfrom dataset import AuxTables\nfrom .featurizer import Featurizer\n\n\nclass LangModelFeaturizer(Featurizer):\n    def specific_setup(self):\n        self.name = \'LangModelFeaturizer\'\n        self.emb_size = 10\n        self.all_attrs = self.ds.get_attributes()\n        self.attrs_number = len(self.all_attrs)\n        self.attr_language_model = {}\n        raw_data = self.ds.get_raw_data()\n        for attr in self.all_attrs:\n            attr_corpus = list(zip(raw_data[attr].tolist()))\n            model = FastText(attr_corpus, min_count=1, size=self.emb_size)\n            self.attr_language_model[attr] = model\n\n    def gen_feat_tensor(self, input, classes):\n        vid = int(input[0])\n        attribute = input[1]\n        domain = input[2].split(\'|||\')\n        attr_idx = self.ds.attr_to_idx[attribute]\n        model = self.attr_language_model[attribute]\n        tensor = torch.zeros(1, classes, self.attrs_number*self.emb_size)\n        for idx, val in enumerate(domain):\n            emb_val = model.wv[val]\n            start = attr_idx*self.emb_size\n            end = start+self.emb_size\n            tensor[0][idx][start:end] = torch.tensor(emb_val)\n        return tensor\n\n    def create_tensor(self):\n        query = \'SELECT _vid_, attribute, domain FROM %s ORDER BY _vid_\' % AuxTables.cell_domain.name\n        results = self.ds.engine.execute_query(query)\n        tensors = [self.gen_feat_tensor(res, self.classes) for res in results]\n        combined = torch.cat(tensors)\n        return combined\n\n    def feature_names(self):\n        return [""{}_emb_{}"".format(attr, emb_idx) for attr in self.all_attrs for emb_idx in range(self.emb_size)]\n'"
repair/featurize/occurattrfeat.py,2,"b'import logging\n\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\n\nfrom .featurizer import Featurizer\nfrom dataset import AuxTables\nfrom utils import NULL_REPR, NA_COOCCUR_FV\n\n\nclass OccurAttrFeaturizer(Featurizer):\n    def specific_setup(self):\n        self.name = \'OccurAttrFeaturizer\'\n        if not self.setup_done:\n            raise Exception(\'Featurizer {} is not properly setup.\'.format(self.name))\n        self.all_attrs = self.ds.get_attributes()\n        self.attrs_number = len(self.ds.attr_to_idx)\n        self.raw_data_dict = {}\n        self.total = None\n        self.single_stats = None\n        self.pair_stats = None\n        self.setup_stats()\n\n    def setup_stats(self):\n        self.raw_data_dict = self.ds.raw_data.df.set_index(\'_tid_\').to_dict(\'index\')\n        total, single_stats, pair_stats = self.ds.get_statistics()\n        self.total = float(total)\n        self.single_stats = single_stats\n        self.pair_stats = pair_stats\n\n    def create_tensor(self):\n        # Iterate over tuples in domain\n        tensors = []\n        # Set tuple_id index on raw_data\n        t = self.ds.aux_table[AuxTables.cell_domain]\n        sorted_domain = t.df.reset_index().sort_values(by=[\'_vid_\'])[[\'_tid_\', \'attribute\', \'_vid_\', \'domain\']]\n        records = sorted_domain.to_records()\n        for row in tqdm(list(records)):\n            # Get tuple from raw_dataset.\n            tid = row[\'_tid_\']\n            tuple = self.raw_data_dict[tid]\n            feat_tensor = self.gen_feat_tensor(row, tuple)\n            tensors.append(feat_tensor)\n        combined = torch.cat(tensors)\n        return combined\n\n    def gen_feat_tensor(self, row, tuple):\n        tensor = torch.zeros(1, self.classes, self.attrs_number * self.attrs_number)\n        rv_attr = row[\'attribute\']\n        domain = row[\'domain\'].split(\'|||\')\n        rv_domain_idx = {val: idx for idx, val in enumerate(domain)}\n        # We should not have any NULLs in our domain.\n        assert NULL_REPR not in rv_domain_idx\n        rv_attr_idx = self.ds.attr_to_idx[rv_attr]\n        for attr in self.all_attrs:\n            val = tuple[attr]\n\n            # Ignore co-occurrences of same attribute or with null values.\n            # It\'s possible a value is not in pair_stats if it only co-occurred\n            # with NULL values.\n            if attr == rv_attr \\\n                    or val == NULL_REPR \\\n                    or val not in self.pair_stats[attr][rv_attr]:\n                continue\n            attr_idx = self.ds.attr_to_idx[attr]\n            count1 = float(self.single_stats[attr][val])\n            all_vals = self.pair_stats[attr][rv_attr][val]\n            for rv_val in domain:\n                count2 = float(all_vals.get(rv_val, 0.0))\n                prob = count2 / count1\n                if rv_val in rv_domain_idx:\n                    index = rv_attr_idx * self.attrs_number + attr_idx\n                    tensor[0][rv_domain_idx[rv_val]][index] = prob\n        return tensor\n\n    def feature_names(self):\n        return [""{} X {}"".format(attr1, attr2) for attr1 in self.all_attrs for attr2 in self.all_attrs]\n'"
repair/learn/__init__.py,0,"b""from .learn import RepairModel\n\n__all__ = ['RepairModel']\n"""
repair/learn/learn.py,12,"b'import logging\nimport math\n\nimport torch\nfrom torch import optim\nfrom torch.autograd import Variable\nfrom torch.nn import Parameter, ParameterList\nfrom torch.nn.functional import softmax\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom tqdm import tqdm\nimport numpy as np\n\n\nclass TiedLinear(torch.nn.Module):\n    """"""\n    TiedLinear is a linear layer with shared parameters for features between\n    (output) classes that takes as input a tensor X with dimensions\n        (batch size) X (output_dim) X (in_features)\n        where:\n            output_dim is the desired output dimension/# of classes\n            in_features are the features with shared weights across the classes\n    """"""\n\n    def __init__(self, env, feat_info, output_dim, bias=False):\n        super(TiedLinear, self).__init__()\n        self.env = env\n        # Init parameters\n        self.in_features = 0.0\n        self.weight_list = ParameterList()\n        if bias:\n             self.bias_list = ParameterList()\n        else:\n             self.register_parameter(\'bias\', None)\n        self.output_dim = output_dim\n        self.bias_flag = bias\n        # Iterate over featurizer info list\n        for feat_entry in feat_info:\n            learnable = feat_entry.learnable\n            feat_size = feat_entry.size\n            init_weight = feat_entry.init_weight\n            self.in_features += feat_size\n            feat_weight = Parameter(init_weight*torch.ones(1, feat_size), requires_grad=learnable)\n            if learnable:\n                self.reset_parameters(feat_weight)\n            self.weight_list.append(feat_weight)\n            if bias:\n                feat_bias = Parameter(torch.zeros(1, feat_size), requires_grad=learnable)\n                if learnable:\n                    self.reset_parameters(feat_bias)\n                self.bias_list.append(feat_bias)\n\n    def reset_parameters(self, tensor):\n        stdv = 1. / math.sqrt(tensor.size(0))\n        tensor.data.uniform_(-stdv, stdv)\n\n    def concat_weights(self):\n        self.W = torch.cat([t for t in self.weight_list],-1)\n        # Normalize weights.\n        if self.env[\'weight_norm\']:\n            self.W = self.W.div(self.W.norm(p=2))\n        # expand so we can do matrix multiplication with each cell and their max # of domain values\n        self.W = self.W.expand(self.output_dim, -1)\n        if self.bias_flag:\n            self.B = torch.cat([t.expand(self.output_dim, -1) for t in self.bias_list],-1)\n\n    def forward(self, X, index, mask):\n        # Concatenates different featurizer weights - need to call during every pass.\n        self.concat_weights()\n        output = X.mul(self.W)\n        if self.bias_flag:\n            output += self.B\n        output = output.sum(2)\n        # Add our mask so that invalid domain classes for a given variable/VID\n        # has a large negative value, resulting in a softmax probability\n        # of de facto 0.\n        output.index_add_(0, index, mask)\n        return output\n\n\nclass RepairModel:\n\n    def __init__(self, env, feat_info, output_dim, bias=False):\n        self.env = env\n        # A list of tuples (name, is_featurizer_learnable, featurizer_output_size, init_weight, feature_names (list))\n        self.feat_info = feat_info\n        self.output_dim = output_dim\n        self.model = TiedLinear(self.env, feat_info, output_dim, bias)\n        self.featurizer_weights = {}\n\n    def fit_model(self, X_train, Y_train, mask_train):\n        n_examples, n_classes, n_features = X_train.shape\n\n        loss = torch.nn.CrossEntropyLoss()\n        trainable_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n        if self.env[\'optimizer\'] == \'sgd\':\n            optimizer = optim.SGD(trainable_parameters, lr=self.env[\'learning_rate\'], momentum=self.env[\'momentum\'],\n                                  weight_decay=self.env[\'weight_decay\'])\n        else:\n            optimizer = optim.Adam(trainable_parameters, lr=self.env[\'learning_rate\'], weight_decay=self.env[\'weight_decay\'])\n\n        # lr_sched = ReduceLROnPlateau(optimizer, \'min\', verbose=True, eps=1e-5, patience=5)\n\n        batch_size = self.env[\'batch_size\']\n        epochs = self.env[\'epochs\']\n        for i in tqdm(range(epochs)):\n            cost = 0.\n            num_batches = n_examples // batch_size\n            for k in range(num_batches):\n                start, end = k * batch_size, (k + 1) * batch_size\n                cost += self.__train__(loss, optimizer, X_train[start:end], Y_train[start:end], mask_train[start:end])\n\n            # Y_pred = self.__predict__(X_train, mask_train)\n            # train_loss = loss.forward(Y_pred, Variable(Y_train, requires_grad=False).squeeze(1))\n            # logging.debug(\'overall training loss: %f\', train_loss)\n            # lr_sched.step(train_loss)\n\n            if self.env[\'verbose\']:\n                # Compute and print accuracy at the end of epoch\n                grdt = Y_train.numpy().flatten()\n                Y_pred = self.__predict__(X_train, mask_train)\n                Y_assign = Y_pred.data.numpy().argmax(axis=1)\n                logging.debug(""Epoch %d, cost = %f, acc = %.2f%%"",\n                        i + 1, cost / num_batches,\n                        100. * np.mean(Y_assign == grdt))\n\n\n    def infer_values(self, X_pred, mask_pred):\n        logging.info(\'inferring on %d examples (cells)\', X_pred.shape[0])\n        output = self.__predict__(X_pred, mask_pred)\n        return output\n\n    def __train__(self, loss, optimizer, X_train, Y_train, mask_train):\n        X_var = Variable(X_train, requires_grad=False)\n        Y_var = Variable(Y_train, requires_grad=False)\n        mask_var = Variable(mask_train, requires_grad=False)\n\n        index = torch.LongTensor(range(X_var.size()[0]))\n        index_var = Variable(index, requires_grad=False)\n\n        optimizer.zero_grad()\n        # Fully-connected layer with shared parameters between output classes\n        # for linear combination of input features.\n        # Mask makes invalid output classes have a large negative value so\n        # to zero out softmax probability.\n        fx = self.model.forward(X_var, index_var, mask_var)\n        # loss is CrossEntropyLoss: combines log softmax + Negative log likelihood loss.\n        # Y_Var is just a single 1D tensor with value (0 - \'class\' - 1) i.e.\n        # index of the correct class (\'class\' = max domain)\n        # fx is a tensor of length \'class\' the linear activation going in the softmax.\n        output = loss.forward(fx, Y_var.squeeze(1))\n        output.backward()\n        optimizer.step()\n        cost = output.item()\n        return cost\n\n    def __predict__(self, X_pred, mask_pred):\n        X_var = Variable(X_pred, requires_grad=False)\n        index = torch.LongTensor(range(X_var.size()[0]))\n        index_var = Variable(index, requires_grad=False)\n        mask_var = Variable(mask_pred, requires_grad=False)\n        fx = self.model.forward(X_var, index_var, mask_var)\n        output = softmax(fx, 1)\n        return output\n\n    def get_featurizer_weights(self, feat_info):\n        report = """"\n        for i, f in enumerate(feat_info):\n            this_weight = self.model.weight_list[i].data.numpy()[0]\n            weight_str = ""\\n"".join(""{name} {weight}"".format(name=name, weight=weight)\n                                   for name, weight in\n                                   zip(f.feature_names, map(str, np.around(this_weight, 3))))\n            feat_name = f.name\n            feat_size = f.size\n            max_w = max(this_weight)\n            min_w = min(this_weight)\n            mean_w = float(np.mean(this_weight))\n            abs_mean_w = float(np.mean(np.absolute(this_weight)))\n            # Create report\n            report += ""featurizer %s,size %d,max %.4f,min %.4f,avg %.4f,abs_avg %.4f,weights:\\n%s\\n"" % (\n                feat_name, feat_size, max_w, min_w, mean_w, abs_mean_w, weight_str\n            )\n            # Wrap in a dictionary.\n            self.featurizer_weights[feat_name] = {\n                \'max\': max_w,\n                \'min\': min_w,\n                \'avg\': mean_w,\n                \'abs_avg\': abs_mean_w,\n                \'weights\': this_weight,\n                \'size\': feat_size\n            }\n        return report\n'"
tests/detection/test_errorsloaderdetector.py,0,"b""import csv\n\nimport pytest\nfrom tempfile import NamedTemporaryFile\n\nfrom detect.errorloaderdetector import ErrorsLoaderDetector\n\n\ndef test_errors_loader_valid_csv_file():\n    tmp_file = NamedTemporaryFile(delete=False)\n    with open(tmp_file.name, 'w') as csv_file:\n        csv_writer = csv.writer(csv_file, delimiter=',')\n        csv_writer.writerow(['_tid_', 'attribute'])  # Header.\n        csv_writer.writerow([1, 'attr1'])\n        csv_writer.writerow([1, 'attr2'])\n        csv_writer.writerow([2, 'attr1'])\n        csv_writer.writerow([3, 'attr2'])\n    errors_loader_detector = ErrorsLoaderDetector(fpath=tmp_file.name)\n    errors_df = errors_loader_detector.detect_noisy_cells()\n\n    assert errors_df is not None\n    assert errors_df.columns.tolist() == ['_tid_', 'attribute']\n    assert len(errors_df) == 4\n\n\ndef test_errors_loader_invalid_csv_file():\n    tmp_file = NamedTemporaryFile(delete=False)\n    with open(tmp_file.name, 'w') as csv_file:\n        csv_writer = csv.writer(csv_file, delimiter=',')\n        csv_writer.writerow(['_tid_', 'invalid_column'])  # Header.\n        csv_writer.writerow([1, 'val1'])\n\n    with pytest.raises(Exception) as invalid_file_error:\n        errors_loader_detector = ErrorsLoaderDetector(fpath=tmp_file.name)\n\n    assert 'The loaded errors table does not match the expected schema' in str(invalid_file_error.value)\n"""
