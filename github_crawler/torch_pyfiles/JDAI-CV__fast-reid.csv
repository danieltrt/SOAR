file_path,api_count,code
demo/demo.py,1,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport argparse\nimport glob\nimport os\nimport sys\n\nimport cv2\nimport numpy as np\nimport tqdm\nfrom torch.backends import cudnn\n\nsys.path.append(\'..\')\n\nfrom fastreid.config import get_cfg\nfrom fastreid.utils.file_io import PathManager\nfrom predictor import FeatureExtractionDemo\n\ncudnn.benchmark = True\n\n\ndef setup_cfg(args):\n    # load config from file and command-line arguments\n    cfg = get_cfg()\n    cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n    return cfg\n\n\ndef get_parser():\n    parser = argparse.ArgumentParser(description=""Feature extraction with reid models"")\n    parser.add_argument(\n        ""--config-file"",\n        metavar=""FILE"",\n        help=""path to config file"",\n    )\n    parser.add_argument(\n        \'--device\',\n        default=\'cuda: 1\',\n        help=\'CUDA device to use\'\n    )\n    parser.add_argument(\n        \'--parallel\',\n        action=\'store_true\',\n        help=\'If use multiprocess for feature extraction.\'\n    )\n    parser.add_argument(\n        ""--input"",\n        nargs=""+"",\n        help=""A list of space separated input images; ""\n             ""or a single glob pattern such as \'directory/*.jpg\'"",\n    )\n    parser.add_argument(\n        ""--output"",\n        default=\'demo_output\',\n        help=\'path to save features\'\n    )\n    parser.add_argument(\n        ""--opts"",\n        help=""Modify config options using the command-line \'KEY VALUE\' pairs"",\n        default=[],\n        nargs=argparse.REMAINDER,\n    )\n    return parser\n\n\nif __name__ == \'__main__\':\n    args = get_parser().parse_args()\n    cfg = setup_cfg(args)\n    demo = FeatureExtractionDemo(cfg, device=args.device, parallel=args.parallel)\n\n    PathManager.mkdirs(args.output)\n    if args.input:\n        if PathManager.isdir(args.input[0]):\n            args.input = glob.glob(os.path.expanduser(args.input[0]))\n            assert args.input, ""The input path(s) was not found""\n        for path in tqdm.tqdm(args.input):\n            img = cv2.imread(path)\n            feat = demo.run_on_image(img)\n            feat = feat.numpy()\n            np.save(os.path.join(args.output, path.replace(\'.jpg\', \'.npy\').split(\'/\')[-1]), feat)\n'"
demo/plot_roc_with_pickle.py,0,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nimport matplotlib.pyplot as plt\nimport sys\n\nsys.path.append(\'.\')\nfrom fastreid.utils.visualizer import Visualizer\n\nif __name__ == ""__main__"":\n    baseline_res = Visualizer.load_roc_info(""logs/duke_vis/roc_info.pickle"")\n    mgn_res = Visualizer.load_roc_info(""logs/mgn_duke_vis/roc_info.pickle"")\n\n    fig = Visualizer.plot_roc_curve(baseline_res[\'fpr\'], baseline_res[\'tpr\'], name=\'baseline\')\n    Visualizer.plot_roc_curve(mgn_res[\'fpr\'], mgn_res[\'tpr\'], name=\'mgn\', fig=fig)\n    plt.savefig(\'roc.jpg\')\n\n    fig = Visualizer.plot_distribution(baseline_res[\'pos\'], baseline_res[\'neg\'], name=\'baseline\')\n    Visualizer.plot_distribution(mgn_res[\'pos\'], mgn_res[\'neg\'], name=\'mgn\', fig=fig)\n    plt.savefig(\'dist.jpg\')\n'"
demo/predictor.py,3,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nimport atexit\nimport bisect\n\nimport cv2\nimport torch\nimport torch.multiprocessing as mp\nfrom collections import deque\n\nfrom fastreid.engine import DefaultPredictor\n\ntry:\n    mp.set_start_method(\'spawn\')\nexcept RuntimeError:\n    pass\n\n\nclass FeatureExtractionDemo(object):\n    def __init__(self, cfg, device=\'cuda:0\', parallel=False):\n        """"""\n        Args:\n            cfg (CfgNode):\n            parallel (bool) whether to run the model in different processes from visualization.:\n                Useful since the visualization logic can be slow.\n        """"""\n        self.cfg = cfg\n        self.parallel = parallel\n\n        if parallel:\n            self.num_gpus = torch.cuda.device_count()\n            self.predictor = AsyncPredictor(cfg, self.num_gpus)\n        else:\n            self.predictor = DefaultPredictor(cfg, device)\n\n    def run_on_image(self, original_image):\n        """"""\n\n        Args:\n            original_image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n                This is the format used by OpenCV.\n\n        Returns:\n            predictions (np.ndarray): normalized feature of the model.\n        """"""\n        # the model expects RGB inputs\n        original_image = original_image[:, :, ::-1]\n        # Apply pre-processing to image.\n        image = cv2.resize(original_image, tuple(self.cfg.INPUT.SIZE_TEST[::-1]), interpolation=cv2.INTER_CUBIC)\n        image = torch.as_tensor(image.astype(""float32"").transpose(2, 0, 1))[None]\n        predictions = self.predictor(image)\n        return predictions\n\n    def run_on_loader(self, data_loader):\n        if self.parallel:\n            buffer_size = self.predictor.default_buffer_size\n\n            batch_data = deque()\n\n            for cnt, batch in enumerate(data_loader):\n                batch_data.append(batch)\n                self.predictor.put(batch[""images""])\n\n                if cnt >= buffer_size:\n                    batch = batch_data.popleft()\n                    predictions = self.predictor.get()\n                    yield predictions, batch[\'targets\'].numpy(), batch[\'camid\'].numpy()\n\n            while len(batch_data):\n                batch = batch_data.popleft()\n                predictions = self.predictor.get()\n                yield predictions, batch[\'targets\'].numpy(), batch[\'camid\'].numpy()\n        else:\n            for batch in data_loader:\n                predictions = self.predictor(batch[""images""])\n                yield predictions, batch[\'targets\'].numpy(), batch[\'camid\'].numpy()\n\n\nclass AsyncPredictor:\n    """"""\n    A predictor that runs the model asynchronously, possibly on >1 GPUs.\n    Because when the amount of data is large.\n    """"""\n\n    class _StopToken:\n        pass\n\n    class _PredictWorker(mp.Process):\n        def __init__(self, cfg, device, task_queue, result_queue):\n            self.cfg = cfg\n            self.device = device\n            self.task_queue = task_queue\n            self.result_queue = result_queue\n            super().__init__()\n\n        def run(self):\n            predictor = DefaultPredictor(self.cfg, self.device)\n\n            while True:\n                task = self.task_queue.get()\n                if isinstance(task, AsyncPredictor._StopToken):\n                    break\n                idx, data = task\n                result = predictor(data)\n                self.result_queue.put((idx, result))\n\n    def __init__(self, cfg, num_gpus: int = 1):\n        """"""\n\n        Args:\n            cfg (CfgNode):\n            num_gpus (int): if 0, will run on CPU\n        """"""\n        num_workers = max(num_gpus, 1)\n        self.task_queue = mp.Queue(maxsize=num_workers * 3)\n        self.result_queue = mp.Queue(maxsize=num_workers * 3)\n        self.procs = []\n        for gpuid in range(max(num_gpus, 1)):\n            device = ""cuda:{}"".format(gpuid) if num_gpus > 0 else ""cpu""\n            self.procs.append(\n                AsyncPredictor._PredictWorker(cfg, device, self.task_queue, self.result_queue)\n            )\n\n        self.put_idx = 0\n        self.get_idx = 0\n        self.result_rank = []\n        self.result_data = []\n\n        for p in self.procs:\n            p.start()\n\n        atexit.register(self.shutdown)\n\n    def put(self, image):\n        self.put_idx += 1\n        self.task_queue.put((self.put_idx, image))\n\n    def get(self):\n        self.get_idx += 1\n        if len(self.result_rank) and self.result_rank[0] == self.get_idx:\n            res = self.result_data[0]\n            del self.result_data[0], self.result_rank[0]\n            return res\n\n        while True:\n            # Make sure the results are returned in the correct order\n            idx, res = self.result_queue.get()\n            if idx == self.get_idx:\n                return res\n            insert = bisect.bisect(self.result_rank, idx)\n            self.result_rank.insert(insert, idx)\n            self.result_data.insert(insert, res)\n\n    def __len__(self):\n        return self.put_idx - self.get_idx\n\n    def __call__(self, image):\n        self.put(image)\n        return self.get()\n\n    def shutdown(self):\n        for _ in self.procs:\n            self.task_queue.put(AsyncPredictor._StopToken())\n\n    @property\n    def default_buffer_size(self):\n        return len(self.procs) * 5\n'"
demo/visualize_result.py,3,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nimport argparse\nimport logging\nimport sys\n\nimport numpy as np\nimport torch\nimport tqdm\nfrom torch.backends import cudnn\n\nsys.path.append(\'.\')\n\nfrom fastreid.evaluation import evaluate_rank\nfrom fastreid.config import get_cfg\nfrom fastreid.utils.logger import setup_logger\nfrom fastreid.data import build_reid_test_loader\nfrom predictor import FeatureExtractionDemo\nfrom fastreid.utils.visualizer import Visualizer\n\ncudnn.benchmark = True\nlogger = logging.getLogger(\'fastreid.visualize_result\')\n\n\ndef setup_cfg(args):\n    # load config from file and command-line arguments\n    cfg = get_cfg()\n    cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n    return cfg\n\n\ndef get_parser():\n    parser = argparse.ArgumentParser(description=""Feature extraction with reid models"")\n    parser.add_argument(\n        ""--config-file"",\n        metavar=""FILE"",\n        help=""path to config file"",\n    )\n    parser.add_argument(\n        \'--device\',\n        default=\'cuda: 1\',\n        help=\'CUDA device to use\'\n    )\n    parser.add_argument(\n        \'--parallel\',\n        action=\'store_true\',\n        help=\'if use multiprocess for feature extraction.\'\n    )\n    parser.add_argument(\n        ""--dataset-name"",\n        help=""a test dataset name for visualizing ranking list.""\n    )\n    parser.add_argument(\n        ""--output"",\n        default=""./vis_rank_list"",\n        help=""a file or directory to save rankling list result."",\n\n    )\n    parser.add_argument(\n        ""--vis-label"",\n        action=\'store_true\',\n        help=""if visualize label of query instance""\n    )\n    parser.add_argument(\n        ""--num-vis"",\n        default=100,\n        help=""number of query images to be visualized"",\n    )\n    parser.add_argument(\n        ""--rank-sort"",\n        default=""ascending"",\n        help=""rank order of visualization images by AP metric"",\n    )\n    parser.add_argument(\n        ""--label-sort"",\n        default=""ascending"",\n        help=""label order of visualization images by cosine similarity metric"",\n    )\n    parser.add_argument(\n        ""--max-rank"",\n        default=10,\n        help=""maximum number of rank list to be visualized"",\n    )\n    parser.add_argument(\n        ""--opts"",\n        help=""Modify config options using the command-line \'KEY VALUE\' pairs"",\n        default=[],\n        nargs=argparse.REMAINDER,\n    )\n    return parser\n\n\nif __name__ == \'__main__\':\n    args = get_parser().parse_args()\n    logger = setup_logger()\n    cfg = setup_cfg(args)\n    test_loader, num_query = build_reid_test_loader(cfg, args.dataset_name)\n    demo = FeatureExtractionDemo(cfg, device=args.device, parallel=args.parallel)\n\n    logger.info(""Start extracting image features"")\n    feats = []\n    pids = []\n    camids = []\n    for (feat, pid, camid) in tqdm.tqdm(demo.run_on_loader(test_loader), total=len(test_loader)):\n        feats.append(feat)\n        pids.extend(pid)\n        camids.extend(camid)\n\n    feats = torch.cat(feats, dim=0)\n    q_feat = feats[:num_query]\n    g_feat = feats[num_query:]\n    q_pids = np.asarray(pids[:num_query])\n    g_pids = np.asarray(pids[num_query:])\n    q_camids = np.asarray(camids[:num_query])\n    g_camids = np.asarray(camids[num_query:])\n\n    # compute cosine distance\n    distmat = 1 - torch.mm(q_feat, g_feat.t())\n    distmat = distmat.numpy()\n\n    logger.info(""Computing APs for all query images ..."")\n    cmc, all_ap, all_inp = evaluate_rank(distmat, q_pids, g_pids, q_camids, g_camids)\n\n    visualizer = Visualizer(test_loader.dataset)\n    visualizer.get_model_output(all_ap, distmat, q_pids, g_pids, q_camids, g_camids)\n\n    logger.info(""Saving ROC curve ..."")\n    fpr, tpr, pos, neg = visualizer.vis_roc_curve(args.output)\n    visualizer.save_roc_info(args.output, fpr, tpr, pos, neg)\n\n    logger.info(""Saving rank list result ..."")\n    query_indices = visualizer.vis_rank_list(args.output, args.vis_label, args.num_vis,\n                                             args.rank_sort, args.label_sort, args.max_rank)\n'"
fastreid/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\n\n__version__ = ""0.1.0""'"
tests/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n'"
tests/dataset_test.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport sys\nsys.path.append(\'.\')\nfrom data import get_dataloader\nfrom config import cfg\nimport argparse\nfrom data.datasets import init_dataset\n# cfg.DATALOADER.SAMPLER = \'triplet\'\ncfg.DATASETS.NAMES = (""market1501"", ""dukemtmc"", ""cuhk03"", ""msmt17"",)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser(description=""ReID Baseline Training"")\n    parser.add_argument(\n        \'-cfg\', ""--config_file"",\n        default="""",\n        metavar=""FILE"",\n        help=""path to config file"",\n        type=str\n    )\n    # parser.add_argument(""--local_rank"", type=int, default=0)\n    parser.add_argument(""opts"", help=""Modify config options using the command-line"", default=None,\n                        nargs=argparse.REMAINDER)\n    args = parser.parse_args()\n    cfg.merge_from_list(args.opts)\n\n    # dataset = init_dataset(\'msmt17\', combineall=True)\n    get_dataloader(cfg)\n    # tng_dataloader, val_dataloader, num_classes, num_query = get_dataloader(cfg)\n    # def get_ex(): return open_image(\'datasets/beijingStation/query/000245_c10s2_1561732033722.000000.jpg\')\n    # im = get_ex()\n    # print(data.train_ds[0])\n    # print(data.test_ds[0])\n    # a = next(iter(data.train_dl))\n    # from IPython import embed; embed()\n    # from ipdb import set_trace; set_trace()\n    # im.apply_tfms(crop_pad(size=(300, 300)))\n'"
tests/interp_test.py,1,"b""import torch\nfrom fastai.vision import *\nfrom fastai.basic_data import *\nfrom fastai.layers import *\n\nimport sys\nsys.path.append('.')\nfrom engine.interpreter import ReidInterpretation\n\nfrom data import get_data_bunch\nfrom modeling import build_model\nfrom config import cfg\ncfg.DATASETS.NAMES = ('market1501',)\ncfg.DATASETS.TEST_NAMES = 'market1501'\ncfg.MODEL.BACKBONE = 'resnet50'\n\ndata_bunch, test_labels, num_query = get_data_bunch(cfg)\n\nmodel = build_model(cfg, 10)\nmodel.load_params_wo_fc(torch.load('logs/2019.8.14/market/baseline/models/model_149.pth')['model'])\nlearn = Learner(data_bunch, model)\n\nfeats, _ = learn.get_preds(DatasetType.Test, activ=Lambda(lambda x: x))"""
tests/lr_scheduler_test.py,0,"b""import sys\nimport unittest\n\nimport torch\nfrom torch import nn\n\nsys.path.append('.')\nfrom solver.lr_scheduler import WarmupMultiStepLR\nfrom solver.build import make_optimizer\nfrom config import cfg\n\n\nclass MyTestCase(unittest.TestCase):\n    def test_something(self):\n        net = nn.Linear(10, 10)\n        optimizer = make_optimizer(cfg, net)\n        lr_scheduler = WarmupMultiStepLR(optimizer, [20, 40], warmup_iters=10)\n        for i in range(50):\n            lr_scheduler.step()\n            for j in range(3):\n                print(i, lr_scheduler.get_lr()[0])\n                optimizer.step()\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
tests/model_test.py,2,"b""import unittest\n\nimport torch\n\nimport sys\nsys.path.append('.')\nfrom fastreid.config import cfg\nfrom fastreid.modeling.backbones import build_resnet_backbone\nfrom fastreid.modeling.backbones.resnet_ibn_a import se_resnet101_ibn_a\nfrom torch import nn\n\n\nclass MyTestCase(unittest.TestCase):\n    def test_se_resnet101(self):\n        cfg.MODEL.BACKBONE.NAME = 'resnet101'\n        cfg.MODEL.BACKBONE.DEPTH = 101\n        cfg.MODEL.BACKBONE.WITH_IBN = True\n        cfg.MODEL.BACKBONE.WITH_SE = True\n        cfg.MODEL.BACKBONE.PRETRAIN_PATH = '/export/home/lxy/.cache/torch/checkpoints/se_resnet101_ibn_a.pth.tar'\n\n        net1 = build_resnet_backbone(cfg)\n        net1.cuda()\n        net2 = nn.DataParallel(se_resnet101_ibn_a())\n        res = net2.load_state_dict(torch.load(cfg.MODEL.BACKBONE.PRETRAIN_PATH)['state_dict'], strict=False)\n        net2.cuda()\n        x = torch.randn(10, 3, 256, 128).cuda()\n        y1 = net1(x)\n        y2 = net2(x)\n        assert y1.sum() == y2.sum(), 'train mode problem'\n        net1.eval()\n        net2.eval()\n        y1 = net1(x)\n        y2 = net2(x)\n        assert y1.sum() == y2.sum(), 'eval mode problem'\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
tests/sampler_test.py,0,"b""import unittest\nimport sys\nsys.path.append('.')\nfrom fastreid.data.samplers import TrainingSampler\n\n\nclass SamplerTestCase(unittest.TestCase):\n    def test_training_sampler(self):\n        sampler = TrainingSampler(5)\n        for i in sampler:\n            from ipdb import set_trace; set_trace()\n            print(i)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
tools/export2tf.py,2,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport sys\n\nimport torch\nsys.path.append(\'../..\')\nfrom fastreid.config import get_cfg\nfrom fastreid.engine import default_argument_parser, default_setup\nfrom fastreid.modeling.meta_arch import build_model\nfrom fastreid.export.tensorflow_export import export_tf_reid_model\nfrom fastreid.export.tf_modeling import TfMetaArch\n\n\ndef setup(args):\n    """"""\n    Create configs and perform basic setups.\n    """"""\n    cfg = get_cfg()\n    # cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n    default_setup(cfg, args)\n    return cfg\n\n\nif __name__ == ""__main__"":\n    args = default_argument_parser().parse_args()\n    print(""Command Line Args:"", args)\n    cfg = setup(args)\n    cfg.defrost()\n    cfg.MODEL.BACKBONE.NAME = ""build_resnet_backbone""\n    cfg.MODEL.BACKBONE.DEPTH = 50\n    cfg.MODEL.BACKBONE.LAST_STRIDE = 1\n    # If use IBN block in backbone\n    cfg.MODEL.BACKBONE.WITH_IBN = False\n    cfg.MODEL.BACKBONE.PRETRAIN = False\n\n    from torchvision.models import resnet50\n    # model = TfMetaArch(cfg)\n    model = resnet50(pretrained=False)\n    # model.load_params_wo_fc(torch.load(\'logs/bjstation/res50_baseline_v0.4/ckpts/model_epoch80.pth\'))\n    model.eval()\n    dummy_inputs = torch.randn(1, 3, 256, 128)\n    export_tf_reid_model(model, dummy_inputs, \'reid_tf.pb\')\n'"
tools/train_net.py,0,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport os\nimport logging\nimport sys\n\nsys.path.append(\'.\')\n\nfrom torch import nn\n\nfrom fastreid.config import get_cfg\nfrom fastreid.engine import DefaultTrainer, default_argument_parser, default_setup\nfrom fastreid.utils.checkpoint import Checkpointer\nfrom fastreid.engine import hooks\nfrom fastreid.evaluation import ReidEvaluator\n\n\nclass Trainer(DefaultTrainer):\n    @classmethod\n    def build_evaluator(cls, cfg, num_query, output_folder=None):\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR, ""inference"")\n        return ReidEvaluator(cfg, num_query)\n\n\ndef setup(args):\n    """"""\n    Create configs and perform basic setups.\n    """"""\n    cfg = get_cfg()\n    cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n    default_setup(cfg, args)\n    return cfg\n\n\ndef main(args):\n    cfg = setup(args)\n\n    logger = logging.getLogger(\'fastreid.\' + __name__)\n    if args.eval_only:\n        cfg.defrost()\n        cfg.MODEL.BACKBONE.PRETRAIN = False\n        model = Trainer.build_model(cfg)\n        model = nn.DataParallel(model)\n        model = model.cuda()\n\n        Checkpointer(model, save_dir=cfg.OUTPUT_DIR).load(cfg.MODEL.WEIGHTS)  # load trained model\n        if cfg.TEST.PRECISE_BN.ENABLED and hooks.get_bn_modules(model):\n            prebn_cfg = cfg.clone()\n            prebn_cfg.DATALOADER.NUM_WORKERS = 0  # save some memory and time for PreciseBN\n            prebn_cfg.DATASETS.NAMES = tuple([cfg.TEST.PRECISE_BN.DATASET])  # set dataset name for PreciseBN\n            logger.info(""Prepare precise BN dataset"")\n            hooks.PreciseBN(\n                # Run at the same freq as (but before) evaluation.\n                model,\n                # Build a new data loader to not affect training\n                Trainer.build_train_loader(prebn_cfg),\n                cfg.TEST.PRECISE_BN.NUM_ITER,\n            ).update_stats()\n        res = Trainer.test(cfg, model)\n        return res\n\n    trainer = Trainer(cfg)\n    trainer.resume_or_load(resume=args.resume)\n    return trainer.train()\n\n\nif __name__ == ""__main__"":\n    args = default_argument_parser().parse_args()\n    print(""Command Line Args:"", args)\n    main(args)\n'"
fastreid/config/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom .config import CfgNode, get_cfg\nfrom .defaults import _C as cfg\n'"
fastreid/config/config.py,0,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport logging\nimport os\nfrom typing import Any\n\nimport yaml\nfrom yacs.config import CfgNode as _CfgNode\n\nfrom ..utils.file_io import PathManager\n\nBASE_KEY = ""_BASE_""\n\n\nclass CfgNode(_CfgNode):\n    """"""\n    Our own extended version of :class:`yacs.config.CfgNode`.\n    It contains the following extra features:\n    1. The :meth:`merge_from_file` method supports the ""_BASE_"" key,\n       which allows the new CfgNode to inherit all the attributes from the\n       base configuration file.\n    2. Keys that start with ""COMPUTED_"" are treated as insertion-only\n       ""computed"" attributes. They can be inserted regardless of whether\n       the CfgNode is frozen or not.\n    3. With ""allow_unsafe=True"", it supports pyyaml tags that evaluate\n       expressions in config. See examples in\n       https://pyyaml.org/wiki/PyYAMLDocumentation#yaml-tags-and-python-types\n       Note that this may lead to arbitrary code execution: you must not\n       load a config file from untrusted sources before manually inspecting\n       the content of the file.\n    """"""\n\n    @staticmethod\n    def load_yaml_with_base(filename: str, allow_unsafe: bool = False):\n        """"""\n        Just like `yaml.load(open(filename))`, but inherit attributes from its\n            `_BASE_`.\n        Args:\n            filename (str): the file name of the current config. Will be used to\n                find the base config file.\n            allow_unsafe (bool): whether to allow loading the config file with\n                `yaml.unsafe_load`.\n        Returns:\n            (dict): the loaded yaml\n        """"""\n        with PathManager.open(filename, ""r"") as f:\n            try:\n                cfg = yaml.safe_load(f)\n            except yaml.constructor.ConstructorError:\n                if not allow_unsafe:\n                    raise\n                logger = logging.getLogger(__name__)\n                logger.warning(\n                    ""Loading config {} with yaml.unsafe_load. Your machine may ""\n                    ""be at risk if the file contains malicious content."".format(\n                        filename\n                    )\n                )\n                f.close()\n                with open(filename, ""r"") as f:\n                    cfg = yaml.unsafe_load(f)\n\n        def merge_a_into_b(a, b):\n            # merge dict a into dict b. values in a will overwrite b.\n            for k, v in a.items():\n                if isinstance(v, dict) and k in b:\n                    assert isinstance(\n                        b[k], dict\n                    ), ""Cannot inherit key \'{}\' from base!"".format(k)\n                    merge_a_into_b(v, b[k])\n                else:\n                    b[k] = v\n\n        if BASE_KEY in cfg:\n            base_cfg_file = cfg[BASE_KEY]\n            if base_cfg_file.startswith(""~""):\n                base_cfg_file = os.path.expanduser(base_cfg_file)\n            if not any(\n                    map(base_cfg_file.startswith, [""/"", ""https://"", ""http://""])\n            ):\n                # the path to base cfg is relative to the config file itself.\n                base_cfg_file = os.path.join(\n                    os.path.dirname(filename), base_cfg_file\n                )\n            base_cfg = CfgNode.load_yaml_with_base(\n                base_cfg_file, allow_unsafe=allow_unsafe\n            )\n            del cfg[BASE_KEY]\n\n            merge_a_into_b(cfg, base_cfg)\n            return base_cfg\n        return cfg\n\n    def merge_from_file(self, cfg_filename: str, allow_unsafe: bool = False):\n        """"""\n        Merge configs from a given yaml file.\n        Args:\n            cfg_filename: the file name of the yaml config.\n            allow_unsafe: whether to allow loading the config file with\n                `yaml.unsafe_load`.\n        """"""\n        loaded_cfg = CfgNode.load_yaml_with_base(\n            cfg_filename, allow_unsafe=allow_unsafe\n        )\n        loaded_cfg = type(self)(loaded_cfg)\n        self.merge_from_other_cfg(loaded_cfg)\n\n    # Forward the following calls to base, but with a check on the BASE_KEY.\n    def merge_from_other_cfg(self, cfg_other):\n        """"""\n        Args:\n            cfg_other (CfgNode): configs to merge from.\n        """"""\n        assert (\n                BASE_KEY not in cfg_other\n        ), ""The reserved key \'{}\' can only be used in files!"".format(BASE_KEY)\n        return super().merge_from_other_cfg(cfg_other)\n\n    def merge_from_list(self, cfg_list: list):\n        """"""\n        Args:\n            cfg_list (list): list of configs to merge from.\n        """"""\n        keys = set(cfg_list[0::2])\n        assert (\n                BASE_KEY not in keys\n        ), ""The reserved key \'{}\' can only be used in files!"".format(BASE_KEY)\n        return super().merge_from_list(cfg_list)\n\n    def __setattr__(self, name: str, val: Any):\n        if name.startswith(""COMPUTED_""):\n            if name in self:\n                old_val = self[name]\n                if old_val == val:\n                    return\n                raise KeyError(\n                    ""Computed attributed \'{}\' already exists ""\n                    ""with a different value! old={}, new={}."".format(\n                        name, old_val, val\n                    )\n                )\n            self[name] = val\n        else:\n            super().__setattr__(name, val)\n\n\ndef get_cfg() -> CfgNode:\n    """"""\n    Get a copy of the default config.\n    Returns:\n        a detectron2 CfgNode instance.\n    """"""\n    from .defaults import _C\n\n    return _C.clone()\n'"
fastreid/config/defaults.py,0,"b'from .config import CfgNode as CN\n\n# -----------------------------------------------------------------------------\n# Convention about Training / Test specific parameters\n# -----------------------------------------------------------------------------\n# Whenever an argument can be either used for training or for testing, the\n# corresponding name will be post-fixed by a _TRAIN for a training parameter,\n# or _TEST for a test-specific parameter.\n# For example, the number of images during training will be\n# IMAGES_PER_BATCH_TRAIN, while the number of images for testing will be\n# IMAGES_PER_BATCH_TEST\n\n# -----------------------------------------------------------------------------\n# Config definition\n# -----------------------------------------------------------------------------\n\n_C = CN()\n\n# -----------------------------------------------------------------------------\n# MODEL\n# -----------------------------------------------------------------------------\n_C.MODEL = CN()\n_C.MODEL.META_ARCHITECTURE = \'Baseline\'\n_C.MODEL.OPEN_LAYERS = [\'\']\n\n# ---------------------------------------------------------------------------- #\n# Backbone options\n# ---------------------------------------------------------------------------- #\n_C.MODEL.BACKBONE = CN()\n\n_C.MODEL.BACKBONE.NAME = ""build_resnet_backbone""\n_C.MODEL.BACKBONE.DEPTH = 50\n_C.MODEL.BACKBONE.LAST_STRIDE = 1\n# Normalization method for the convolution layers.\n_C.MODEL.BACKBONE.NORM = ""BN""\n# Mini-batch split of Ghost BN\n_C.MODEL.BACKBONE.NORM_SPLIT = 1\n# If use IBN block in backbone\n_C.MODEL.BACKBONE.WITH_IBN = False\n# If use SE block in backbone\n_C.MODEL.BACKBONE.WITH_SE = False\n# If use Non-local block in backbone\n_C.MODEL.BACKBONE.WITH_NL = False\n# If use ImageNet pretrain model\n_C.MODEL.BACKBONE.PRETRAIN = True\n# Pretrain model path\n_C.MODEL.BACKBONE.PRETRAIN_PATH = \'\'\n\n# ---------------------------------------------------------------------------- #\n# REID HEADS options\n# ---------------------------------------------------------------------------- #\n_C.MODEL.HEADS = CN()\n_C.MODEL.HEADS.NAME = ""BNneckHead""\n\n# Normalization method for the convolution layers.\n_C.MODEL.HEADS.NORM = ""BN""\n# Mini-batch split of Ghost BN\n_C.MODEL.HEADS.NORM_SPLIT = 1\n# Number of identity\n_C.MODEL.HEADS.NUM_CLASSES = 751\n# Input feature dimension\n_C.MODEL.HEADS.IN_FEAT = 2048\n# Reduction dimension in head\n_C.MODEL.HEADS.REDUCTION_DIM = 512\n# Triplet feature using feature before(after) bnneck\n_C.MODEL.HEADS.NECK_FEAT = ""before""  # options: before, after\n# Pooling layer type\n_C.MODEL.HEADS.POOL_LAYER = ""avgpool""\n\n# Classification layer type\n_C.MODEL.HEADS.CLS_LAYER = ""linear""  # ""arcface"" or ""circle""\n\n# Margin and Scale for margin-based classification layer\n_C.MODEL.HEADS.MARGIN = 0.15\n_C.MODEL.HEADS.SCALE = 128\n\n\n# ---------------------------------------------------------------------------- #\n# REID LOSSES options\n# ---------------------------------------------------------------------------- #\n_C.MODEL.LOSSES = CN()\n_C.MODEL.LOSSES.NAME = (""CrossEntropyLoss"",)\n\n# Cross Entropy Loss options\n_C.MODEL.LOSSES.CE = CN()\n# if epsilon == 0, it means no label smooth regularization,\n# if epsilon == -1, it means adaptive label smooth regularization\n_C.MODEL.LOSSES.CE.EPSILON = 0.0\n_C.MODEL.LOSSES.CE.ALPHA = 0.3\n_C.MODEL.LOSSES.CE.SCALE = 1.0\n\n# Triplet Loss options\n_C.MODEL.LOSSES.TRI = CN()\n_C.MODEL.LOSSES.TRI.MARGIN = 0.3\n_C.MODEL.LOSSES.TRI.NORM_FEAT = False\n_C.MODEL.LOSSES.TRI.HARD_MINING = True\n_C.MODEL.LOSSES.TRI.USE_COSINE_DIST = False\n_C.MODEL.LOSSES.TRI.SCALE = 1.0\n\n# Focal Loss options\n_C.MODEL.LOSSES.FL = CN()\n_C.MODEL.LOSSES.FL.ALPHA = 0.25\n_C.MODEL.LOSSES.FL.GAMMA = 2\n_C.MODEL.LOSSES.FL.SCALE = 1.0\n\n# Path to a checkpoint file to be loaded to the model. You can find available models in the model zoo.\n_C.MODEL.WEIGHTS = """"\n\n# Values to be used for image normalization\n_C.MODEL.PIXEL_MEAN = [0.485*255, 0.456*255, 0.406*255]\n# Values to be used for image normalization\n_C.MODEL.PIXEL_STD = [0.229*255, 0.224*255, 0.225*255]\n#\n\n# -----------------------------------------------------------------------------\n# INPUT\n# -----------------------------------------------------------------------------\n_C.INPUT = CN()\n# Size of the image during training\n_C.INPUT.SIZE_TRAIN = [256, 128]\n# Size of the image during test\n_C.INPUT.SIZE_TEST = [256, 128]\n\n# Random probability for image horizontal flip\n_C.INPUT.DO_FLIP = True\n_C.INPUT.FLIP_PROB = 0.5\n\n# Value of padding size\n_C.INPUT.DO_PAD = True\n_C.INPUT.PADDING_MODE = \'constant\'\n_C.INPUT.PADDING = 10\n# Random color jitter\n_C.INPUT.DO_CJ = False\n# Auto augmentation\n_C.INPUT.DO_AUTOAUG = False\n# Augmix augmentation\n_C.INPUT.DO_AUGMIX = False\n# Random Erasing\n_C.INPUT.REA = CN()\n_C.INPUT.REA.ENABLED = False\n_C.INPUT.REA.PROB = 0.5\n_C.INPUT.REA.MEAN = [0.596*255, 0.558*255, 0.497*255]  # [0.485*255, 0.456*255, 0.406*255]\n# Random Patch\n_C.INPUT.RPT = CN()\n_C.INPUT.RPT.ENABLED = False\n_C.INPUT.RPT.PROB = 0.5\n\n# -----------------------------------------------------------------------------\n# Dataset\n# -----------------------------------------------------------------------------\n_C.DATASETS = CN()\n# List of the dataset names for training\n_C.DATASETS.NAMES = (""Market1501"",)\n# List of the dataset names for testing\n_C.DATASETS.TESTS = (""Market1501"",)\n# Combine trainset and testset joint training\n_C.DATASETS.COMBINEALL = False\n\n# -----------------------------------------------------------------------------\n# DataLoader\n# -----------------------------------------------------------------------------\n_C.DATALOADER = CN()\n# P/K Sampler for data loading\n_C.DATALOADER.PK_SAMPLER = True\n# Number of instance for each person\n_C.DATALOADER.NUM_INSTANCE = 4\n_C.DATALOADER.NUM_WORKERS = 8\n\n# ---------------------------------------------------------------------------- #\n# Solver\n# ---------------------------------------------------------------------------- #\n_C.SOLVER = CN()\n\n_C.SOLVER.OPT = ""Adam""\n\n_C.SOLVER.MAX_ITER = 40000\n\n_C.SOLVER.BASE_LR = 3e-4\n_C.SOLVER.BIAS_LR_FACTOR = 1.\n_C.SOLVER.HEADS_LR_FACTOR = 1.\n\n_C.SOLVER.MOMENTUM = 0.9\n\n_C.SOLVER.WEIGHT_DECAY = 0.0005\n_C.SOLVER.WEIGHT_DECAY_BIAS = 0.\n\n# Multi-step learning rate options\n_C.SOLVER.SCHED = ""WarmupMultiStepLR""\n_C.SOLVER.GAMMA = 0.1\n_C.SOLVER.STEPS = (30, 55)\n\n# Cosine annealing learning rate options\n_C.SOLVER.DELAY_ITERS = 100\n_C.SOLVER.ETA_MIN_LR = 3e-7\n\n# Warmup options\n_C.SOLVER.WARMUP_FACTOR = 0.1\n_C.SOLVER.WARMUP_ITERS = 10\n_C.SOLVER.WARMUP_METHOD = ""linear""\n\n_C.SOLVER.FREEZE_ITERS = 0\n\n# SWA options\n_C.SOLVER.SWA = CN()\n_C.SOLVER.SWA.ENABLED = False\n_C.SOLVER.SWA.ITER = 0\n_C.SOLVER.SWA.PERIOD = 10\n_C.SOLVER.SWA.LR_FACTOR = 10.\n_C.SOLVER.SWA.ETA_MIN_LR = 3.5e-6\n_C.SOLVER.SWA.LR_SCHED = False\n\n_C.SOLVER.CHECKPOINT_PERIOD = 5000\n\n_C.SOLVER.LOG_PERIOD = 30\n# Number of images per batch\n# This is global, so if we have 8 GPUs and IMS_PER_BATCH = 16, each GPU will\n# see 2 images per batch\n_C.SOLVER.IMS_PER_BATCH = 64\n\n# This is global, so if we have 8 GPUs and IMS_PER_BATCH = 16, each GPU will\n# see 2 images per batch\n_C.TEST = CN()\n\n_C.TEST.EVAL_PERIOD = 50\n_C.TEST.IMS_PER_BATCH = 128\n_C.TEST.METRIC = ""cosine""\n\n# Average query expansion\n_C.TEST.AQE = CN()\n_C.TEST.AQE.ENABLED = False\n_C.TEST.AQE.ALPHA = 3.0\n_C.TEST.AQE.QE_TIME = 1\n_C.TEST.AQE.QE_K = 5\n\n# Re-rank\n_C.TEST.RERANK = CN()\n_C.TEST.RERANK.ENABLED = False\n_C.TEST.RERANK.K1 = 20\n_C.TEST.RERANK.K2 = 6\n_C.TEST.RERANK.LAMBDA = 0.3\n\n# Precise batchnorm\n_C.TEST.PRECISE_BN = CN()\n_C.TEST.PRECISE_BN.ENABLED = False\n_C.TEST.PRECISE_BN.DATASET = \'Market1501\'\n_C.TEST.PRECISE_BN.NUM_ITER = 300\n\n# ---------------------------------------------------------------------------- #\n# Misc options\n# ---------------------------------------------------------------------------- #\n_C.OUTPUT_DIR = ""logs/""\n\n# Benchmark different cudnn algorithms.\n# If input images have very different sizes, this option will have large overhead\n# for about 10k iterations. It usually hurts total time, but can benefit for certain models.\n# If input images have the same or similar sizes, benchmark is often helpful.\n_C.CUDNN_BENCHMARK = False\n\n'"
fastreid/data/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom .build import build_reid_train_loader, build_reid_test_loader\n'"
fastreid/data/build.py,9,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nfrom torch._six import container_abcs, string_classes, int_classes\nfrom torch.utils.data import DataLoader\n\nfrom . import samplers\nfrom .common import CommDataset\nfrom .datasets import DATASET_REGISTRY\nfrom .transforms import build_transforms\n\n\ndef build_reid_train_loader(cfg):\n    train_transforms = build_transforms(cfg, is_train=True)\n\n    train_items = list()\n    for d in cfg.DATASETS.NAMES:\n        dataset = DATASET_REGISTRY.get(d)(combineall=cfg.DATASETS.COMBINEALL)\n        dataset.show_train()\n        train_items.extend(dataset.train)\n\n    train_set = CommDataset(train_items, train_transforms, relabel=True)\n\n    num_workers = cfg.DATALOADER.NUM_WORKERS\n    batch_size = cfg.SOLVER.IMS_PER_BATCH\n    num_instance = cfg.DATALOADER.NUM_INSTANCE\n\n    if cfg.DATALOADER.PK_SAMPLER:\n        data_sampler = samplers.RandomIdentitySampler(train_set.img_items, batch_size, num_instance)\n    else:\n        data_sampler = samplers.TrainingSampler(len(train_set))\n    batch_sampler = torch.utils.data.sampler.BatchSampler(data_sampler, batch_size, True)\n\n    train_loader = torch.utils.data.DataLoader(\n        train_set,\n        num_workers=num_workers,\n        batch_sampler=batch_sampler,\n        collate_fn=fast_batch_collator,\n    )\n    return train_loader\n\n\ndef build_reid_test_loader(cfg, dataset_name):\n    test_transforms = build_transforms(cfg, is_train=False)\n\n    dataset = DATASET_REGISTRY.get(dataset_name)()\n    dataset.show_test()\n    test_items = dataset.query + dataset.gallery\n\n    test_set = CommDataset(test_items, test_transforms, relabel=False)\n\n    num_workers = cfg.DATALOADER.NUM_WORKERS\n    batch_size = cfg.TEST.IMS_PER_BATCH\n    data_sampler = samplers.InferenceSampler(len(test_set))\n    batch_sampler = torch.utils.data.BatchSampler(data_sampler, batch_size, False)\n    test_loader = DataLoader(\n        test_set,\n        batch_sampler=batch_sampler,\n        num_workers=num_workers,\n        collate_fn=fast_batch_collator)\n    return test_loader, len(dataset.query)\n\n\ndef trivial_batch_collator(batch):\n    """"""\n    A batch collator that does nothing.\n    """"""\n    return batch\n\n\ndef fast_batch_collator(batched_inputs):\n    """"""\n    A simple batch collator for most common reid tasks\n    """"""\n    elem = batched_inputs[0]\n    if isinstance(elem, torch.Tensor):\n        out = torch.zeros((len(batched_inputs), *elem.size()), dtype=elem.dtype)\n        for i, tensor in enumerate(batched_inputs):\n            out[i] += tensor\n        return out\n\n    elif isinstance(elem, container_abcs.Mapping):\n        return {key: fast_batch_collator([d[key] for d in batched_inputs]) for key in elem}\n\n    elif isinstance(elem, float):\n        return torch.tensor(batched_inputs, dtype=torch.float64)\n    elif isinstance(elem, int_classes):\n        return torch.tensor(batched_inputs)\n    elif isinstance(elem, string_classes):\n        return batched_inputs\n'"
fastreid/data/common.py,1,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nfrom torch.utils.data import Dataset\n\nfrom .data_utils import read_image\n\n\nclass CommDataset(Dataset):\n    """"""Image Person ReID Dataset""""""\n\n    def __init__(self, img_items, transform=None, relabel=True):\n        self.transform = transform\n        self.relabel = relabel\n\n        self.pid_dict = {}\n        if self.relabel:\n            self.img_items = []\n            pids = set()\n            for i, item in enumerate(img_items):\n                pid = self.get_pids(item[0], item[1])\n                self.img_items.append((item[0], pid, item[2]))  # replace pid\n                pids.add(pid)\n            self.pids = pids\n            self.pid_dict = dict([(p, i) for i, p in enumerate(self.pids)])\n        else:\n            self.img_items = img_items\n\n    def __len__(self):\n        return len(self.img_items)\n\n    def __getitem__(self, index):\n        img_path, pid, camid = self.img_items[index]\n        img = read_image(img_path)\n\n        if self.transform is not None: img = self.transform(img)\n\n        if self.relabel: pid = self.pid_dict[pid]\n\n        return {\n            \'images\': img,\n            \'targets\': pid,\n            \'camid\': camid,\n            \'img_path\': img_path\n        }\n\n    @staticmethod\n    def get_pids(file_path, pid):\n        """""" Suitable for muilti-dataset training """"""\n        if \'cuhk03\' in file_path: prefix = \'cuhk\'\n        else:                     prefix = file_path.split(\'/\')[1]\n\n        return prefix + \'_\' + str(pid)\n\n    def update_pid_dict(self, pid_dict):\n        self.pid_dict = pid_dict\n'"
fastreid/data/data_utils.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nimport numpy as np\nfrom PIL import Image, ImageOps\n\nfrom fastreid.utils.file_io import PathManager\n\n\ndef read_image(file_name, format=None):\n    """"""\n    Read an image into the given format.\n    Will apply rotation and flipping if the image has such exif information.\n    Args:\n        file_name (str): image file path\n        format (str): one of the supported image modes in PIL, or ""BGR""\n    Returns:\n        image (np.ndarray): an HWC image\n    """"""\n    with PathManager.open(file_name, ""rb"") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = ImageOps.exif_transpose(image)\n        except Exception:\n            pass\n\n        if format is not None:\n            # PIL only supports RGB, so convert to RGB and flip channels over below\n            conversion_format = format\n            if format == ""BGR"":\n                conversion_format = ""RGB""\n            image = image.convert(conversion_format)\n        image = np.asarray(image)\n        if format == ""BGR"":\n            # flip channels if needed\n            image = image[:, :, ::-1]\n        # PIL squeezes out the channel dimension for ""L"", so make it HWC\n        if format == ""L"":\n            image = np.expand_dims(image, -1)\n        image = Image.fromarray(image)\n        return image\n'"
fastreid/engine/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nfrom .train_loop import *\n\n__all__ = [k for k in globals().keys() if not k.startswith(""_"")]\n\n\n# prefer to let hooks and defaults live in separate namespaces (therefore not in __all__)\n# but still make them available here\nfrom .hooks import *\nfrom .defaults import *\n'"
fastreid/engine/defaults.py,8,"b'# -*- coding: utf-8 -*-\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n\n""""""\nThis file contains components with some default boilerplate logic user may need\nin training / testing. They will not work for everyone, but many users may find them useful.\nThe behavior of functions/classes in this file is subject to change,\nsince they are meant to represent the ""common default behavior"" people need in their projects.\n""""""\n\nimport argparse\nimport logging\nimport os\nfrom collections import OrderedDict\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import DataParallel\n\nfrom fastreid.data import build_reid_test_loader, build_reid_train_loader\nfrom fastreid.evaluation import (DatasetEvaluator, ReidEvaluator,\n                                 inference_on_dataset, print_csv_format)\nfrom fastreid.modeling.meta_arch import build_model\nfrom fastreid.layers.sync_bn import patch_replication_callback\nfrom fastreid.solver import build_lr_scheduler, build_optimizer\nfrom fastreid.utils import comm\nfrom fastreid.utils.checkpoint import Checkpointer\nfrom fastreid.utils.events import CommonMetricPrinter, JSONWriter, TensorboardXWriter\nfrom fastreid.utils.file_io import PathManager\nfrom fastreid.utils.logger import setup_logger\nfrom . import hooks\nfrom .train_loop import SimpleTrainer\n\n__all__ = [""default_argument_parser"", ""default_setup"", ""DefaultPredictor"", ""DefaultTrainer""]\n\n\ndef default_argument_parser():\n    """"""\n    Create a parser with some common arguments used by detectron2 users.\n    Returns:\n        argparse.ArgumentParser:\n    """"""\n    parser = argparse.ArgumentParser(description=""fastreid Training"")\n    parser.add_argument(""--config-file"", default="""", metavar=""FILE"", help=""path to config file"")\n    parser.add_argument(\n        ""--resume"",\n        action=""store_true"",\n        help=""whether to attempt to resume from the checkpoint directory"",\n    )\n    parser.add_argument(""--eval-only"", action=""store_true"", help=""perform evaluation only"")\n    # parser.add_argument(""--num-gpus"", type=int, default=1, help=""number of gpus *per machine*"")\n    # parser.add_argument(""--num-machines"", type=int, default=1)\n    # parser.add_argument(\n    #     ""--machine-rank"", type=int, default=0, help=""the rank of this machine (unique per machine)""\n    # )\n\n    # PyTorch still may leave orphan processes in multi-gpu training.\n    # Therefore we use a deterministic way to obtain port,\n    # so that users are aware of orphan processes by seeing the port occupied.\n    # port = 2 ** 15 + 2 ** 14 + hash(os.getuid()) % 2 ** 14\n    # parser.add_argument(""--dist-url"", default=""tcp://127.0.0.1:{}"".format(port))\n    parser.add_argument(\n        ""opts"",\n        help=""Modify config options using the command-line"",\n        default=None,\n        nargs=argparse.REMAINDER,\n    )\n    return parser\n\n\ndef default_setup(cfg, args):\n    """"""\n    Perform some basic common setups at the beginning of a job, including:\n    1. Set up the detectron2 logger\n    2. Log basic information about environment, cmdline arguments, and config\n    3. Backup the config to the output directory\n    Args:\n        cfg (CfgNode): the full config to be used\n        args (argparse.NameSpace): the command line arguments to be logged\n    """"""\n    output_dir = cfg.OUTPUT_DIR\n    if comm.is_main_process() and output_dir:\n        PathManager.mkdirs(output_dir)\n\n    rank = comm.get_rank()\n    setup_logger(output_dir, distributed_rank=rank, name=""fvcore"")\n    logger = setup_logger(output_dir, distributed_rank=rank)\n\n    logger.info(""Rank of current process: {}. World size: {}"".format(rank, comm.get_world_size()))\n    # logger.info(""Environment info:\\n"" + collect_env_info())\n\n    logger.info(""Command line arguments: "" + str(args))\n    if hasattr(args, ""config_file"") and args.config_file != """":\n        logger.info(\n            ""Contents of args.config_file={}:\\n{}"".format(\n                args.config_file, PathManager.open(args.config_file, ""r"").read()\n            )\n        )\n\n    logger.info(""Running with full config:\\n{}"".format(cfg))\n    if comm.is_main_process() and output_dir:\n        # Note: some of our scripts may expect the existence of\n        # config.yaml in output directory\n        path = os.path.join(output_dir, ""config.yaml"")\n        with PathManager.open(path, ""w"") as f:\n            f.write(cfg.dump())\n        logger.info(""Full config saved to {}"".format(os.path.abspath(path)))\n\n    # cudnn benchmark has large overhead. It shouldn\'t be used considering the small size of\n    # typical validation set.\n    if not (hasattr(args, ""eval_only"") and args.eval_only):\n        torch.backends.cudnn.benchmark = cfg.CUDNN_BENCHMARK\n\n\nclass DefaultPredictor:\n    """"""\n    Create a simple end-to-end predictor with the given config.\n    The predictor takes an BGR image, resizes it to the specified resolution,\n    runs the model and produces a dict of predictions.\n    This predictor takes care of model loading and input preprocessing for you.\n    If you\'d like to do anything more fancy, please refer to its source code\n    as examples to build and use the model manually.\n    Attributes:\n    Examples:\n    .. code-block:: python\n        pred = DefaultPredictor(cfg)\n        inputs = cv2.imread(""input.jpg"")\n        outputs = pred(inputs)\n    """"""\n\n    def __init__(self, cfg, device=\'cpu\'):\n        self.cfg = cfg.clone()  # cfg can be modified by model\n        self.cfg.defrost()\n        self.cfg.MODEL.BACKBONE.PRETRAIN = False\n        self.device = device\n        self.model = build_model(self.cfg)\n        self.model.to(device)\n        self.model.eval()\n\n        checkpointer = Checkpointer(self.model)\n        checkpointer.load(cfg.MODEL.WEIGHTS)\n\n    def __call__(self, image):\n        """"""\n        Args:\n            image (torch.tensor): an image tensor of shape (B, C, H, W).\n        Returns:\n            predictions (torch.tensor): the output features of the model\n        """"""\n        with torch.no_grad():  # https://github.com/sphinx-doc/sphinx/issues/4258\n            image = image.to(self.device)\n            inputs = {""images"": image}\n            predictions = self.model(inputs)\n            # Normalize feature to compute cosine distance\n            pred_feat = F.normalize(predictions)\n            pred_feat = pred_feat.cpu().data\n            return pred_feat\n\n\nclass DefaultTrainer(SimpleTrainer):\n    """"""\n    A trainer with default training logic. Compared to `SimpleTrainer`, it\n    contains the following logic in addition:\n    1. Create model, optimizer, scheduler, dataloader from the given config.\n    2. Load a checkpoint or `cfg.MODEL.WEIGHTS`, if exists.\n    3. Register a few common hooks.\n    It is created to simplify the **standard model training workflow** and reduce code boilerplate\n    for users who only need the standard training workflow, with standard features.\n    It means this class makes *many assumptions* about your training logic that\n    may easily become invalid in a new research. In fact, any assumptions beyond those made in the\n    :class:`SimpleTrainer` are too much for research.\n    The code of this class has been annotated about restrictive assumptions it mades.\n    When they do not work for you, you\'re encouraged to:\n    1. Overwrite methods of this class, OR:\n    2. Use :class:`SimpleTrainer`, which only does minimal SGD training and\n       nothing else. You can then add your own hooks if needed. OR:\n    3. Write your own training loop similar to `tools/plain_train_net.py`.\n    Also note that the behavior of this class, like other functions/classes in\n    this file, is not stable, since it is meant to represent the ""common default behavior"".\n    It is only guaranteed to work well with the standard models and training workflow in detectron2.\n    To obtain more stable behavior, write your own training logic with other public APIs.\n    Attributes:\n        scheduler:\n        checkpointer (DetectionCheckpointer):\n        cfg (CfgNode):\n    Examples:\n    .. code-block:: python\n        trainer = DefaultTrainer(cfg)\n        trainer.resume_or_load()  # load last checkpoint or MODEL.WEIGHTS\n        trainer.train()\n    """"""\n\n    def __init__(self, cfg):\n        """"""\n        Args:\n            cfg (CfgNode):\n        """"""\n        self.cfg = cfg\n        logger = logging.getLogger(__name__)\n        if not logger.isEnabledFor(logging.INFO):  # setup_logger is not called for fastreid\n            setup_logger()\n        # Assume these objects must be constructed in this order.\n        model = self.build_model(cfg)\n        optimizer = self.build_optimizer(cfg, model)\n        logger.info(\'Prepare training set\')\n        data_loader = self.build_train_loader(cfg)\n        # For training, wrap with DP. But don\'t need this for inference.\n        model = DataParallel(model)\n        if cfg.MODEL.BACKBONE.NORM == ""syncBN"":\n            # Monkey-patching with syncBN\n            patch_replication_callback(model)\n        model = model.cuda()\n        super().__init__(model, data_loader, optimizer)\n\n        self.scheduler = self.build_lr_scheduler(cfg, optimizer)\n        # Assume no other objects need to be checkpointed.\n        # We can later make it checkpoint the stateful hooks\n        self.checkpointer = Checkpointer(\n            # Assume you want to save checkpoints together with logs/statistics\n            model,\n            self.data_loader.dataset,\n            cfg.OUTPUT_DIR,\n            optimizer=optimizer,\n            scheduler=self.scheduler,\n        )\n        self.start_iter = 0\n        if cfg.SOLVER.SWA.ENABLED:\n            self.max_iter = cfg.SOLVER.MAX_ITER + cfg.SOLVER.SWA.ITER\n        else:\n            self.max_iter = cfg.SOLVER.MAX_ITER\n        self.cfg = cfg\n\n        self.register_hooks(self.build_hooks())\n\n    def resume_or_load(self, resume=True):\n        """"""\n        If `resume==True`, and last checkpoint exists, resume from it.\n        Otherwise, load a model specified by the config.\n        Args:\n            resume (bool): whether to do resume or not\n        """"""\n        # The checkpoint stores the training iteration that just finished, thus we start\n        # at the next iteration (or iter zero if there\'s no checkpoint).\n        checkpoint = self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)\n\n        # Reinitialize dataloader iter because when we update dataset person identity dict\n        # to resume training, DataLoader won\'t update this dictionary when using multiprocess\n        # because of the function scope.\n        self._data_loader_iter = iter(self.data_loader)\n\n        self.start_iter = checkpoint.get(""iteration"", -1) if resume else -1\n        # The checkpoint stores the training iteration that just finished, thus we start\n        # at the next iteration (or iter zero if there\'s no checkpoint).\n        self.start_iter += 1\n\n    def build_hooks(self):\n        """"""\n        Build a list of default hooks, including timing, evaluation,\n        checkpointing, lr scheduling, precise BN, writing events.\n        Returns:\n            list[HookBase]:\n        """"""\n        logger = logging.getLogger(__name__)\n        cfg = self.cfg.clone()\n        cfg.defrost()\n        cfg.DATALOADER.NUM_WORKERS = 0  # save some memory and time for PreciseBN\n        cfg.DATASETS.NAMES = tuple([cfg.TEST.PRECISE_BN.DATASET])  # set dataset name for PreciseBN\n\n        ret = [\n            hooks.IterationTimer(),\n            hooks.LRScheduler(self.optimizer, self.scheduler),\n        ]\n\n        if cfg.SOLVER.SWA.ENABLED:\n            ret.append(\n                hooks.SWA(\n                    cfg.SOLVER.MAX_ITER,\n                    cfg.SOLVER.SWA.PERIOD,\n                    cfg.SOLVER.SWA.LR_FACTOR,\n                    cfg.SOLVER.SWA.ETA_MIN_LR,\n                    cfg.SOLVER.SWA.LR_SCHED,\n                )\n            )\n\n        if cfg.TEST.PRECISE_BN.ENABLED and hooks.get_bn_modules(self.model):\n            logger.info(""Prepare precise BN dataset"")\n            ret.append(hooks.PreciseBN(\n                # Run at the same freq as (but before) evaluation.\n                self.model,\n                # Build a new data loader to not affect training\n                self.build_train_loader(cfg),\n                cfg.TEST.PRECISE_BN.NUM_ITER,\n            ))\n\n        if cfg.MODEL.OPEN_LAYERS != [\'\'] and cfg.SOLVER.FREEZE_ITERS > 0:\n            open_layers = "","".join(cfg.MODEL.OPEN_LAYERS)\n            logger.info(f\'Open ""{open_layers}"" training for {cfg.SOLVER.FREEZE_ITERS:d} iters\')\n            ret.append(hooks.FreezeLayer(\n                self.model,\n                cfg.MODEL.OPEN_LAYERS,\n                cfg.SOLVER.FREEZE_ITERS,\n            ))\n        # Do PreciseBN before checkpointer, because it updates the model and need to\n        # be saved by checkpointer.\n        # This is not always the best: if checkpointing has a different frequency,\n        # some checkpoints may have more precise statistics than others.\n        # if comm.is_main_process():\n        ret.append(hooks.PeriodicCheckpointer(self.checkpointer, cfg.SOLVER.CHECKPOINT_PERIOD))\n\n        def test_and_save_results():\n            self._last_eval_results = self.test(self.cfg, self.model)\n            return self._last_eval_results\n\n        # Do evaluation after checkpointer, because then if it fails,\n        # we can use the saved checkpoint to debug.\n        ret.append(hooks.EvalHook(cfg.TEST.EVAL_PERIOD, test_and_save_results))\n\n        # run writers in the end, so that evaluation metrics are written\n        ret.append(hooks.PeriodicWriter(self.build_writers(), cfg.SOLVER.LOG_PERIOD))\n        return ret\n\n    def build_writers(self):\n        """"""\n        Build a list of writers to be used. By default it contains\n        writers that write metrics to the screen,\n        a json file, and a tensorboard event file respectively.\n        If you\'d like a different list of writers, you can overwrite it in\n        your trainer.\n        Returns:\n            list[EventWriter]: a list of :class:`EventWriter` objects.\n        It is now implemented by:\n        .. code-block:: python\n            return [\n                CommonMetricPrinter(self.max_iter),\n                JSONWriter(os.path.join(self.cfg.OUTPUT_DIR, ""metrics.json"")),\n                TensorboardXWriter(self.cfg.OUTPUT_DIR),\n            ]\n        """"""\n        # Assume the default print/log frequency.\n        return [\n            # It may not always print what you want to see, since it prints ""common"" metrics only.\n            CommonMetricPrinter(self.max_iter),\n            JSONWriter(os.path.join(self.cfg.OUTPUT_DIR, ""metrics.json"")),\n            TensorboardXWriter(self.cfg.OUTPUT_DIR),\n        ]\n\n    def train(self):\n        """"""\n        Run training.\n        Returns:\n            OrderedDict of results, if evaluation is enabled. Otherwise None.\n        """"""\n        super().train(self.start_iter, self.max_iter)\n        # if hasattr(self, ""_last_eval_results"") and comm.is_main_process():\n        #     verify_results(self.cfg, self._last_eval_results)\n        #     return self._last_eval_results\n\n    @classmethod\n    def build_model(cls, cfg):\n        """"""\n        Returns:\n            torch.nn.Module:\n        It now calls :func:`detectron2.modeling.build_model`.\n        Overwrite it if you\'d like a different model.\n        """"""\n        model = build_model(cfg)\n        logger = logging.getLogger(__name__)\n        logger.info(""Model:\\n{}"".format(model))\n        return model\n\n    @classmethod\n    def build_optimizer(cls, cfg, model):\n        """"""\n        Returns:\n            torch.optim.Optimizer:\n        It now calls :func:`detectron2.solver.build_optimizer`.\n        Overwrite it if you\'d like a different optimizer.\n        """"""\n        return build_optimizer(cfg, model)\n\n    @classmethod\n    def build_lr_scheduler(cls, cfg, optimizer):\n        """"""\n        It now calls :func:`detectron2.solver.build_lr_scheduler`.\n        Overwrite it if you\'d like a different scheduler.\n        """"""\n        return build_lr_scheduler(cfg, optimizer)\n\n    @classmethod\n    def build_train_loader(cls, cfg):\n        """"""\n        Returns:\n            iterable\n        It now calls :func:`fastreid.data.build_detection_train_loader`.\n        Overwrite it if you\'d like a different data loader.\n        """"""\n        return build_reid_train_loader(cfg)\n\n    @classmethod\n    def build_test_loader(cls, cfg, dataset_name):\n        """"""\n        Returns:\n            iterable\n        It now calls :func:`detectron2.data.build_detection_test_loader`.\n        Overwrite it if you\'d like a different data loader.\n        """"""\n        return build_reid_test_loader(cfg, dataset_name)\n\n    @classmethod\n    def build_evaluator(cls, cfg, num_query, output_dir=None):\n        return ReidEvaluator(cfg, num_query, output_dir)\n\n    @classmethod\n    def test(cls, cfg, model, evaluators=None):\n        """"""\n        Args:\n            cfg (CfgNode):\n            model (nn.Module):\n            evaluators (list[DatasetEvaluator] or None): if None, will call\n                :meth:`build_evaluator`. Otherwise, must have the same length as\n                `cfg.DATASETS.TEST`.\n        Returns:\n            dict: a dict of result metrics\n        """"""\n        logger = logging.getLogger(__name__)\n        if isinstance(evaluators, DatasetEvaluator):\n            evaluators = [evaluators]\n\n        if evaluators is not None:\n            assert len(cfg.DATASETS.TEST) == len(evaluators), ""{} != {}"".format(\n                len(cfg.DATASETS.TEST), len(evaluators)\n            )\n\n        results = OrderedDict()\n        for idx, dataset_name in enumerate(cfg.DATASETS.TESTS):\n            logger.info(f\'prepare test set\')\n            data_loader, num_query = cls.build_test_loader(cfg, dataset_name)\n            # When evaluators are passed in as arguments,\n            # implicitly assume that evaluators can be created before data_loader.\n            if evaluators is not None:\n                evaluator = evaluators[idx]\n            else:\n                try:\n                    evaluator = cls.build_evaluator(cfg, num_query)\n                except NotImplementedError:\n                    logger.warn(\n                        ""No evaluator found. Use `DefaultTrainer.test(evaluators=)`, ""\n                        ""or implement its `build_evaluator` method.""\n                    )\n                    results[dataset_name] = {}\n                    continue\n            results_i = inference_on_dataset(model, data_loader, evaluator)\n            results[dataset_name] = results_i\n            if comm.is_main_process():\n                assert isinstance(\n                    results_i, dict\n                ), ""Evaluator must return a dict on the main process. Got {} instead."".format(\n                    results_i\n                )\n                logger.info(""Evaluation results for {} in csv format:"".format(dataset_name))\n                print_csv_format(results_i)\n\n        if len(results) == 1:\n            results = list(results.values())[0]\n        return results\n'"
fastreid/engine/hooks.py,7,"b'# -*- coding: utf-8 -*-\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n\nimport datetime\nimport itertools\nimport logging\nimport warnings\nimport os\nimport tempfile\nimport time\nfrom collections import Counter\n\nimport torch\nfrom torch import nn\n\nfrom .train_loop import HookBase\nfrom fastreid.solver import optim\nfrom fastreid.evaluation.testing import flatten_results_dict\nfrom fastreid.utils import comm\nfrom fastreid.utils.checkpoint import PeriodicCheckpointer as _PeriodicCheckpointer\nfrom fastreid.utils.events import EventStorage, EventWriter\nfrom fastreid.utils.file_io import PathManager\nfrom fastreid.utils.precision_bn import update_bn_stats, get_bn_modules\nfrom fastreid.utils.timer import Timer\n\n__all__ = [\n    ""CallbackHook"",\n    ""IterationTimer"",\n    ""PeriodicWriter"",\n    ""PeriodicCheckpointer"",\n    ""LRScheduler"",\n    ""AutogradProfiler"",\n    ""EvalHook"",\n    ""PreciseBN"",\n    ""FreezeLayer"",\n]\n\n""""""\nImplement some common hooks.\n""""""\n\n\nclass CallbackHook(HookBase):\n    """"""\n    Create a hook using callback functions provided by the user.\n    """"""\n\n    def __init__(self, *, before_train=None, after_train=None, before_step=None, after_step=None):\n        """"""\n        Each argument is a function that takes one argument: the trainer.\n        """"""\n        self._before_train = before_train\n        self._before_step = before_step\n        self._after_step = after_step\n        self._after_train = after_train\n\n    def before_train(self):\n        if self._before_train:\n            self._before_train(self.trainer)\n\n    def after_train(self):\n        if self._after_train:\n            self._after_train(self.trainer)\n        # The functions may be closures that hold reference to the trainer\n        # Therefore, delete them to avoid circular reference.\n        del self._before_train, self._after_train\n        del self._before_step, self._after_step\n\n    def before_step(self):\n        if self._before_step:\n            self._before_step(self.trainer)\n\n    def after_step(self):\n        if self._after_step:\n            self._after_step(self.trainer)\n\n\nclass IterationTimer(HookBase):\n    """"""\n    Track the time spent for each iteration (each run_step call in the trainer).\n    Print a summary in the end of training.\n    This hook uses the time between the call to its :meth:`before_step`\n    and :meth:`after_step` methods.\n    Under the convention that :meth:`before_step` of all hooks should only\n    take negligible amount of time, the :class:`IterationTimer` hook should be\n    placed at the beginning of the list of hooks to obtain accurate timing.\n    """"""\n\n    def __init__(self, warmup_iter=3):\n        """"""\n        Args:\n            warmup_iter (int): the number of iterations at the beginning to exclude\n                from timing.\n        """"""\n        self._warmup_iter = warmup_iter\n        self._step_timer = Timer()\n\n    def before_train(self):\n        self._start_time = time.perf_counter()\n        self._total_timer = Timer()\n        self._total_timer.pause()\n\n    def after_train(self):\n        logger = logging.getLogger(__name__)\n        total_time = time.perf_counter() - self._start_time\n        total_time_minus_hooks = self._total_timer.seconds()\n        hook_time = total_time - total_time_minus_hooks\n\n        num_iter = self.trainer.iter + 1 - self.trainer.start_iter - self._warmup_iter\n\n        if num_iter > 0 and total_time_minus_hooks > 0:\n            # Speed is meaningful only after warmup\n            # NOTE this format is parsed by grep in some scripts\n            logger.info(\n                ""Overall training speed: {} iterations in {} ({:.4f} s / it)"".format(\n                    num_iter,\n                    str(datetime.timedelta(seconds=int(total_time_minus_hooks))),\n                    total_time_minus_hooks / num_iter,\n                )\n            )\n\n        logger.info(\n            ""Total training time: {} ({} on hooks)"".format(\n                str(datetime.timedelta(seconds=int(total_time))),\n                str(datetime.timedelta(seconds=int(hook_time))),\n            )\n        )\n\n    def before_step(self):\n        self._step_timer.reset()\n        self._total_timer.resume()\n\n    def after_step(self):\n        # +1 because we\'re in after_step\n        iter_done = self.trainer.iter - self.trainer.start_iter + 1\n        if iter_done >= self._warmup_iter:\n            sec = self._step_timer.seconds()\n            self.trainer.storage.put_scalars(time=sec)\n        else:\n            self._start_time = time.perf_counter()\n            self._total_timer.reset()\n\n        self._total_timer.pause()\n\n\nclass PeriodicWriter(HookBase):\n    """"""\n    Write events to EventStorage periodically.\n    It is executed every ``period`` iterations and after the last iteration.\n    """"""\n\n    def __init__(self, writers, period=20):\n        """"""\n        Args:\n            writers (list[EventWriter]): a list of EventWriter objects\n            period (int):\n        """"""\n        self._writers = writers\n        for w in writers:\n            assert isinstance(w, EventWriter), w\n        self._period = period\n\n    def after_step(self):\n        if (self.trainer.iter + 1) % self._period == 0 or (\n                self.trainer.iter == self.trainer.max_iter - 1\n        ):\n            for writer in self._writers:\n                writer.write()\n\n    def after_train(self):\n        for writer in self._writers:\n            writer.close()\n\n\nclass PeriodicCheckpointer(_PeriodicCheckpointer, HookBase):\n    """"""\n    Same as :class:`detectron2.checkpoint.PeriodicCheckpointer`, but as a hook.\n    Note that when used as a hook,\n    it is unable to save additional data other than what\'s defined\n    by the given `checkpointer`.\n    It is executed every ``period`` iterations and after the last iteration.\n    """"""\n\n    def before_train(self):\n        self.max_iter = self.trainer.max_iter\n\n    def after_step(self):\n        # No way to use **kwargs\n        self.step(self.trainer.iter)\n\n\nclass LRScheduler(HookBase):\n    """"""\n    A hook which executes a torch builtin LR scheduler and summarizes the LR.\n    It is executed after every iteration.\n    """"""\n\n    def __init__(self, optimizer, scheduler):\n        """"""\n        Args:\n            optimizer (torch.optim.Optimizer):\n            scheduler (torch.optim._LRScheduler)\n        """"""\n        self._optimizer = optimizer\n        self._scheduler = scheduler\n\n        # NOTE: some heuristics on what LR to summarize\n        # summarize the param group with most parameters\n        largest_group = max(len(g[""params""]) for g in optimizer.param_groups)\n\n        if largest_group == 1:\n            # If all groups have one parameter,\n            # then find the most common initial LR, and use it for summary\n            lr_count = Counter([g[""lr""] for g in optimizer.param_groups])\n            lr = lr_count.most_common()[0][0]\n            for i, g in enumerate(optimizer.param_groups):\n                if g[""lr""] == lr:\n                    self._best_param_group_id = i\n                    break\n        else:\n            for i, g in enumerate(optimizer.param_groups):\n                if len(g[""params""]) == largest_group:\n                    self._best_param_group_id = i\n                    break\n\n    def after_step(self):\n        lr = self._optimizer.param_groups[self._best_param_group_id][""lr""]\n        self.trainer.storage.put_scalar(""lr"", lr, smoothing_hint=False)\n        self._scheduler.step()\n\n\nclass AutogradProfiler(HookBase):\n    """"""\n    A hook which runs `torch.autograd.profiler.profile`.\n    Examples:\n    .. code-block:: python\n        hooks.AutogradProfiler(\n             lambda trainer: trainer.iter > 10 and trainer.iter < 20, self.cfg.OUTPUT_DIR\n        )\n    The above example will run the profiler for iteration 10~20 and dump\n    results to ``OUTPUT_DIR``. We did not profile the first few iterations\n    because they are typically slower than the rest.\n    The result files can be loaded in the ``chrome://tracing`` page in chrome browser.\n    Note:\n        When used together with NCCL on older version of GPUs,\n        autograd profiler may cause deadlock because it unnecessarily allocates\n        memory on every device it sees. The memory management calls, if\n        interleaved with NCCL calls, lead to deadlock on GPUs that do not\n        support `cudaLaunchCooperativeKernelMultiDevice`.\n    """"""\n\n    def __init__(self, enable_predicate, output_dir, *, use_cuda=True):\n        """"""\n        Args:\n            enable_predicate (callable[trainer -> bool]): a function which takes a trainer,\n                and returns whether to enable the profiler.\n                It will be called once every step, and can be used to select which steps to profile.\n            output_dir (str): the output directory to dump tracing files.\n            use_cuda (bool): same as in `torch.autograd.profiler.profile`.\n        """"""\n        self._enable_predicate = enable_predicate\n        self._use_cuda = use_cuda\n        self._output_dir = output_dir\n\n    def before_step(self):\n        if self._enable_predicate(self.trainer):\n            self._profiler = torch.autograd.profiler.profile(use_cuda=self._use_cuda)\n            self._profiler.__enter__()\n        else:\n            self._profiler = None\n\n    def after_step(self):\n        if self._profiler is None:\n            return\n        self._profiler.__exit__(None, None, None)\n        out_file = os.path.join(\n            self._output_dir, ""profiler-trace-iter{}.json"".format(self.trainer.iter)\n        )\n        if ""://"" not in out_file:\n            self._profiler.export_chrome_trace(out_file)\n        else:\n            # Support non-posix filesystems\n            with tempfile.TemporaryDirectory(prefix=""detectron2_profiler"") as d:\n                tmp_file = os.path.join(d, ""tmp.json"")\n                self._profiler.export_chrome_trace(tmp_file)\n                with open(tmp_file) as f:\n                    content = f.read()\n            with PathManager.open(out_file, ""w"") as f:\n                f.write(content)\n\n\nclass EvalHook(HookBase):\n    """"""\n    Run an evaluation function periodically, and at the end of training.\n    It is executed every ``eval_period`` iterations and after the last iteration.\n    """"""\n\n    def __init__(self, eval_period, eval_function):\n        """"""\n        Args:\n            eval_period (int): the period to run `eval_function`.\n            eval_function (callable): a function which takes no arguments, and\n                returns a nested dict of evaluation metrics.\n        Note:\n            This hook must be enabled in all or none workers.\n            If you would like only certain workers to perform evaluation,\n            give other workers a no-op function (`eval_function=lambda: None`).\n        """"""\n        self._period = eval_period\n        self._func = eval_function\n        self._done_eval_at_last = False\n\n    def _do_eval(self):\n        results = self._func()\n\n        if results:\n            assert isinstance(\n                results, dict\n            ), ""Eval function must return a dict. Got {} instead."".format(results)\n\n            flattened_results = flatten_results_dict(results)\n            for k, v in flattened_results.items():\n                try:\n                    v = float(v)\n                except Exception:\n                    raise ValueError(\n                        ""[EvalHook] eval_function should return a nested dict of float. ""\n                        ""Got \'{}: {}\' instead."".format(k, v)\n                    )\n            self.trainer.storage.put_scalars(**flattened_results, smoothing_hint=False)\n\n        # Evaluation may take different time among workers.\n        # A barrier make them start the next iteration together.\n        comm.synchronize()\n        torch.cuda.empty_cache()\n\n    def after_step(self):\n        next_iter = self.trainer.iter + 1\n        is_final = next_iter == self.trainer.max_iter\n        if is_final or (self._period > 0 and next_iter % self._period == 0):\n            self._do_eval()\n            if is_final:\n                self._done_eval_at_last = True\n\n    def after_train(self):\n        if not self._done_eval_at_last:\n            self._do_eval()\n        # func is likely a closure that holds reference to the trainer\n        # therefore we clean it to avoid circular reference in the end\n        del self._func\n\n\nclass PreciseBN(HookBase):\n    """"""\n    The standard implementation of BatchNorm uses EMA in inference, which is\n    sometimes suboptimal.\n    This class computes the true average of statistics rather than the moving average,\n    and put true averages to every BN layer in the given model.\n    It is executed after the last iteration.\n    """"""\n\n    def __init__(self, model, data_loader, num_iter):\n        """"""\n        Args:\n            model (nn.Module): a module whose all BN layers in training mode will be\n                updated by precise BN.\n                Note that user is responsible for ensuring the BN layers to be\n                updated are in training mode when this hook is triggered.\n            data_loader (iterable): it will produce data to be run by `model(data)`.\n            num_iter (int): number of iterations used to compute the precise\n                statistics.\n        """"""\n        self._logger = logging.getLogger(__name__)\n        if len(get_bn_modules(model)) == 0:\n            self._logger.info(\n                ""PreciseBN is disabled because model does not contain BN layers in training mode.""\n            )\n            self._disabled = True\n            return\n\n        self._model = model\n        self._data_loader = data_loader\n        self._num_iter = num_iter\n        self._disabled = False\n\n        self._data_iter = None\n\n    def after_step(self):\n        next_iter = self.trainer.iter + 1\n        is_final = next_iter == self.trainer.max_iter\n        if is_final:\n            self.update_stats()\n\n    def update_stats(self):\n        """"""\n        Update the model with precise statistics. Users can manually call this method.\n        """"""\n        if self._disabled:\n            return\n\n        if self._data_iter is None:\n            self._data_iter = iter(self._data_loader)\n\n        def data_loader():\n            for num_iter in itertools.count(1):\n                if num_iter % 100 == 0:\n                    self._logger.info(\n                        ""Running precise-BN ... {}/{} iterations."".format(num_iter, self._num_iter)\n                    )\n                # This way we can reuse the same iterator\n                yield next(self._data_iter)\n\n        with EventStorage():  # capture events in a new storage to discard them\n            self._logger.info(\n                ""Running precise-BN for {} iterations...  "".format(self._num_iter)\n                + ""Note that this could produce different statistics every time.""\n            )\n            update_bn_stats(self._model, data_loader(), self._num_iter)\n\n\nclass LRFinder(HookBase):\n    pass\n\n\nclass FreezeLayer(HookBase):\n    def __init__(self, model, open_layer_names, freeze_iters):\n        self._logger = logging.getLogger(__name__)\n\n        if isinstance(model, nn.DataParallel):\n            model = model.module\n        self.model = model\n\n        self.freeze_iters = freeze_iters\n\n        self.open_layer_names = open_layer_names\n\n        # previous requires grad status\n        param_grad = {}\n        for name, param in self.model.named_parameters():\n            param_grad[name] = param.requires_grad\n        self.param_grad = param_grad\n\n    def before_step(self):\n        # Freeze specific layers\n        if self.trainer.iter < self.freeze_iters:\n            self.freeze_specific_layer()\n\n        # Recover original layers status\n        elif self.trainer.iter == self.freeze_iters:\n            self.open_all_layer()\n\n    def freeze_specific_layer(self):\n        for layer in self.open_layer_names:\n            if not hasattr(self.model, layer):\n                self._logger.info(f\'""{layer}"" is not an attribute of the model, will skip this layer\')\n\n        for name, module in self.model.named_children():\n            if name in self.open_layer_names:\n                module.train()\n                for p in module.parameters():\n                    p.requires_grad = True\n            else:\n                module.eval()\n                for p in module.parameters():\n                    p.requires_grad = False\n\n    def open_all_layer(self):\n        self.model.train()\n        for name, param in self.model.named_parameters():\n            param.requires_grad = self.param_grad[name]\n\n\nclass SWA(HookBase):\n    def __init__(self, swa_start: int, swa_freq: int, swa_lr_factor: float, eta_min: float, lr_sched=False,):\n        self.swa_start = swa_start\n        self.swa_freq = swa_freq\n        self.swa_lr_factor = swa_lr_factor\n        self.eta_min = eta_min\n        self.lr_sched = lr_sched\n\n    def before_step(self):\n        is_swa = self.trainer.iter == self.swa_start\n        if is_swa:\n            # Wrapper optimizer with SWA\n            self.trainer.optimizer = optim.SWA(self.trainer.optimizer, self.swa_freq, self.swa_lr_factor)\n            self.trainer.optimizer.reset_lr_to_swa()\n\n            if self.lr_sched:\n                self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                    optimizer=self.trainer.optimizer,\n                    T_0=self.swa_freq,\n                    eta_min=self.eta_min,\n                )\n\n    def after_step(self):\n        next_iter = self.trainer.iter + 1\n\n        # Use Cyclic learning rate scheduler\n        if next_iter > self.swa_start and self.lr_sched:\n            self.scheduler.step()\n\n        is_final = next_iter == self.trainer.max_iter\n        if is_final:\n            self.trainer.optimizer.swap_swa_param()\n'"
fastreid/engine/train_loop.py,2,"b'# encoding: utf-8\n""""""\ncredit:\nhttps://github.com/facebookresearch/detectron2/blob/master/detectron2/engine/train_loop.py\n""""""\n\nimport logging\nimport numpy as np\nimport time\nimport weakref\nimport torch\nimport fastreid.utils.comm as comm\nfrom fastreid.utils.events import EventStorage\n\n__all__ = [""HookBase"", ""TrainerBase"", ""SimpleTrainer""]\n\n\nclass HookBase:\n    """"""\n    Base class for hooks that can be registered with :class:`TrainerBase`.\n    Each hook can implement 4 methods. The way they are called is demonstrated\n    in the following snippet:\n    .. code-block:: python\n        hook.before_train()\n        for iter in range(start_iter, max_iter):\n            hook.before_step()\n            trainer.run_step()\n            hook.after_step()\n        hook.after_train()\n    Notes:\n        1. In the hook method, users can access `self.trainer` to access more\n           properties about the context (e.g., current iteration).\n        2. A hook that does something in :meth:`before_step` can often be\n           implemented equivalently in :meth:`after_step`.\n           If the hook takes non-trivial time, it is strongly recommended to\n           implement the hook in :meth:`after_step` instead of :meth:`before_step`.\n           The convention is that :meth:`before_step` should only take negligible time.\n           Following this convention will allow hooks that do care about the difference\n           between :meth:`before_step` and :meth:`after_step` (e.g., timer) to\n           function properly.\n    Attributes:\n        trainer: A weak reference to the trainer object. Set by the trainer when the hook is\n            registered.\n    """"""\n\n    def before_train(self):\n        """"""\n        Called before the first iteration.\n        """"""\n        pass\n\n    def after_train(self):\n        """"""\n        Called after the last iteration.\n        """"""\n        pass\n\n    def before_step(self):\n        """"""\n        Called before each iteration.\n        """"""\n        pass\n\n    def after_step(self):\n        """"""\n        Called after each iteration.\n        """"""\n        pass\n\n\nclass TrainerBase:\n    """"""\n    Base class for iterative trainer with hooks.\n    The only assumption we made here is: the training runs in a loop.\n    A subclass can implement what the loop is.\n    We made no assumptions about the existence of dataloader, optimizer, model, etc.\n    Attributes:\n        iter(int): the current iteration.\n        start_iter(int): The iteration to start with.\n            By convention the minimum possible value is 0.\n        max_iter(int): The iteration to end training.\n        storage(EventStorage): An EventStorage that\'s opened during the course of training.\n    """"""\n\n    def __init__(self):\n        self._hooks = []\n\n    def register_hooks(self, hooks):\n        """"""\n        Register hooks to the trainer. The hooks are executed in the order\n        they are registered.\n        Args:\n            hooks (list[Optional[HookBase]]): list of hooks\n        """"""\n        hooks = [h for h in hooks if h is not None]\n        for h in hooks:\n            assert isinstance(h, HookBase)\n            # To avoid circular reference, hooks and trainer cannot own each other.\n            # This normally does not matter, but will cause memory leak if the\n            # involved objects contain __del__:\n            # See http://engineering.hearsaysocial.com/2013/06/16/circular-references-in-python/\n            h.trainer = weakref.proxy(self)\n        self._hooks.extend(hooks)\n\n    def train(self, start_iter: int, max_iter: int):\n        """"""\n        Args:\n            start_iter, max_iter (int): See docs above\n        """"""\n        logger = logging.getLogger(__name__)\n        logger.info(""Starting training from iteration {}"".format(start_iter))\n\n        self.iter = self.start_iter = start_iter\n        self.max_iter = max_iter\n\n        with EventStorage(start_iter) as self.storage:\n            try:\n                self.before_train()\n                for self.iter in range(start_iter, max_iter):\n                    self.before_step()\n                    self.run_step()\n                    self.after_step()\n            except Exception:\n                logger.exception(""Exception during training:"")\n            finally:\n                self.after_train()\n\n    def before_train(self):\n        for h in self._hooks:\n            h.before_train()\n\n    def after_train(self):\n        for h in self._hooks:\n            h.after_train()\n\n    def before_step(self):\n        for h in self._hooks:\n            h.before_step()\n\n    def after_step(self):\n        for h in self._hooks:\n            h.after_step()\n        # this guarantees, that in each hook\'s after_step, storage.iter == trainer.iter\n        self.storage.step()\n\n    def run_step(self):\n        raise NotImplementedError\n\n\nclass SimpleTrainer(TrainerBase):\n    """"""\n    A simple trainer for the most common type of task:\n    single-cost single-optimizer single-data-source iterative optimization.\n    It assumes that every step, you:\n    1. Compute the loss with a data from the data_loader.\n    2. Compute the gradients with the above loss.\n    3. Update the model with the optimizer.\n    If you want to do anything fancier than this,\n    either subclass TrainerBase and implement your own `run_step`,\n    or write your own training loop.\n    """"""\n\n    def __init__(self, model, data_loader, optimizer):\n        """"""\n        Args:\n            model: a torch Module. Takes a data from data_loader and returns a\n                dict of heads.\n            data_loader: an iterable. Contains data to be used to call model.\n            optimizer: a torch optimizer.\n        """"""\n        super().__init__()\n\n        """"""\n        We set the model to training mode in the trainer.\n        However it\'s valid to train a model that\'s in eval mode.\n        If you want your model (or a submodule of it) to behave\n        like evaluation during training, you can overwrite its train() method.\n        """"""\n        model.train()\n\n        self.model = model\n        self.data_loader = data_loader\n        self._data_loader_iter = iter(data_loader)\n        self.optimizer = optimizer\n\n    def run_step(self):\n        """"""\n        Implement the standard training logic described above.\n        """"""\n        assert self.model.training, ""[SimpleTrainer] model was changed to eval mode!""\n        start = time.perf_counter()\n        """"""\n        If your want to do something with the data, you can wrap the dataloader.\n        """"""\n        data = next(self._data_loader_iter)\n        data_time = time.perf_counter() - start\n        """"""\n        If your want to do something with the heads, you can wrap the model.\n        """"""\n        outputs = self.model(data)\n        loss_dict = self.model.module.losses(outputs)\n        losses = sum(loss for loss in loss_dict.values())\n        self._detect_anomaly(losses, loss_dict)\n\n        metrics_dict = loss_dict\n        metrics_dict[""data_time""] = data_time\n        self._write_metrics(metrics_dict)\n\n        """"""\n        If you need accumulate gradients or something similar, you can\n        wrap the optimizer with your custom `zero_grad()` method.\n        """"""\n        self.optimizer.zero_grad()\n        losses.backward()\n\n        """"""\n        If you need gradient clipping/scaling or other processing, you can\n        wrap the optimizer with your custom `step()` method.\n        """"""\n        self.optimizer.step()\n\n    def _detect_anomaly(self, losses, loss_dict):\n        if not torch.isfinite(losses).all():\n            raise FloatingPointError(\n                ""Loss became infinite or NaN at iteration={}!\\nloss_dict = {}"".format(\n                    self.iter, loss_dict\n                )\n            )\n\n    def _write_metrics(self, metrics_dict: dict):\n        """"""\n        Args:\n            metrics_dict (dict): dict of scalar metrics\n        """"""\n        metrics_dict = {\n            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n            for k, v in metrics_dict.items()\n        }\n        # gather metrics among all workers for logging\n        # This assumes we do DDP-style training, which is currently the only\n        # supported method in detectron2.\n        all_metrics_dict = comm.gather(metrics_dict)\n\n        # if comm.is_main_process():\n        if ""data_time"" in all_metrics_dict[0]:\n            # data_time among workers can have high variance. The actual latency\n            # caused by data_time is the maximum among workers.\n            data_time = np.max([x.pop(""data_time"") for x in all_metrics_dict])\n            self.storage.put_scalar(""data_time"", data_time)\n\n        # average the rest metrics\n        metrics_dict = {\n            k: np.mean([x[k] for x in all_metrics_dict]) for k in all_metrics_dict[0].keys()\n        }\n        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n\n        self.storage.put_scalar(""total_loss"", total_losses_reduced)\n        if len(metrics_dict) > 1:\n            self.storage.put_scalars(**metrics_dict)\n\n'"
fastreid/evaluation/__init__.py,0,"b'# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nfrom .evaluator import DatasetEvaluator, inference_context, inference_on_dataset\nfrom .rank import evaluate_rank\nfrom .reid_evaluation import ReidEvaluator\nfrom .testing import print_csv_format, verify_results\n\n__all__ = [k for k in globals().keys() if not k.startswith(""_"")]\n'"
fastreid/evaluation/evaluator.py,4,"b'# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nimport datetime\nimport logging\nimport time\nfrom contextlib import contextmanager\n\nimport torch\n\nfrom ..utils.logger import log_every_n_seconds\n\n\nclass DatasetEvaluator:\n    """"""\n    Base class for a dataset evaluator.\n    The function :func:`inference_on_dataset` runs the model over\n    all samples in the dataset, and have a DatasetEvaluator to process the inputs/outputs.\n    This class will accumulate information of the inputs/outputs (by :meth:`process`),\n    and produce evaluation results in the end (by :meth:`evaluate`).\n    """"""\n\n    def reset(self):\n        """"""\n        Preparation for a new round of evaluation.\n        Should be called before starting a round of evaluation.\n        """"""\n        pass\n\n    def preprocess_inputs(self, inputs):\n        pass\n\n    def process(self, output):\n        """"""\n        Process an input/output pair.\n        Args:\n            input: the input that\'s used to call the model.\n            output: the return value of `model(input)`\n        """"""\n        pass\n\n    def evaluate(self):\n        """"""\n        Evaluate/summarize the performance, after processing all input/output pairs.\n        Returns:\n            dict:\n                A new evaluator class can return a dict of arbitrary format\n                as long as the user can process the results.\n                In our train_net.py, we expect the following format:\n                * key: the name of the task (e.g., bbox)\n                * value: a dict of {metric name: score}, e.g.: {""AP50"": 80}\n        """"""\n        pass\n\n\n# class DatasetEvaluators(DatasetEvaluator):\n#     def __init__(self, evaluators):\n#         assert len(evaluators)\n#         super().__init__()\n#         self._evaluators = evaluators\n#\n#     def reset(self):\n#         for evaluator in self._evaluators:\n#             evaluator.reset()\n#\n#     def process(self, input, output):\n#         for evaluator in self._evaluators:\n#             evaluator.process(input, output)\n#\n#     def evaluate(self):\n#         results = OrderedDict()\n#         for evaluator in self._evaluators:\n#             result = evaluator.evaluate()\n#             if is_main_process() and result is not None:\n#                 for k, v in result.items():\n#                     assert (\n#                             k not in results\n#                     ), ""Different evaluators produce results with the same key {}"".format(k)\n#                     results[k] = v\n#         return results\n\n\ndef inference_on_dataset(model, data_loader, evaluator):\n    """"""\n    Run model on the data_loader and evaluate the metrics with evaluator.\n    The model will be used in eval mode.\n    Args:\n        model (nn.Module): a module which accepts an object from\n            `data_loader` and returns some outputs. It will be temporarily set to `eval` mode.\n            If you wish to evaluate a model in `training` mode instead, you can\n            wrap the given model and override its behavior of `.eval()` and `.train()`.\n        data_loader: an iterable object with a length.\n            The elements it generates will be the inputs to the model.\n        evaluator (DatasetEvaluator): the evaluator to run. Use\n            :class:`DatasetEvaluators([])` if you only want to benchmark, but\n            don\'t want to do any evaluation.\n    Returns:\n        The return value of `evaluator.evaluate()`\n    """"""\n    # num_devices = torch.distributed.get_world_size() if torch.distributed.is_initialized() else 1\n    logger = logging.getLogger(__name__)\n    logger.info(""Start inference on {} images"".format(len(data_loader.dataset)))\n\n    total = len(data_loader)  # inference data loader must have a fixed length\n    evaluator.reset()\n\n    num_warmup = min(5, total - 1)\n    start_time = time.perf_counter()\n    total_compute_time = 0\n    with inference_context(model), torch.no_grad():\n        for idx, inputs in enumerate(data_loader):\n            if idx == num_warmup:\n                start_time = time.perf_counter()\n                total_compute_time = 0\n\n            start_compute_time = time.perf_counter()\n            outputs = model(inputs)\n            if torch.cuda.is_available():\n                torch.cuda.synchronize()\n            total_compute_time += time.perf_counter() - start_compute_time\n            evaluator.process(outputs)\n\n            idx += 1\n            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n            seconds_per_img = total_compute_time / iters_after_start\n            if idx >= num_warmup * 2 or seconds_per_img > 30:\n                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n                log_every_n_seconds(\n                    logging.INFO,\n                    ""Inference done {}/{}. {:.4f} s / img. ETA={}"".format(\n                        idx + 1, total, seconds_per_img, str(eta)\n                    ),\n                    n=30,\n                )\n\n    # Measure the time only for this worker (before the synchronization barrier)\n    total_time = time.perf_counter() - start_time\n    total_time_str = str(datetime.timedelta(seconds=total_time))\n    # NOTE this format is parsed by grep\n    logger.info(\n        ""Total inference time: {} ({:.6f} s / img per device)"".format(\n            total_time_str, total_time / (total - num_warmup)\n        )\n    )\n    total_compute_time_str = str(datetime.timedelta(seconds=int(total_compute_time)))\n    logger.info(\n        ""Total inference pure compute time: {} ({:.6f} s / img per device)"".format(\n            total_compute_time_str, total_compute_time / (total - num_warmup)\n        )\n    )\n    results = evaluator.evaluate()\n    # An evaluator may return None when not in main process.\n    # Replace it by an empty dict instead to make it easier for downstream code to handle\n    if results is None:\n        results = {}\n    return results\n\n\n@contextmanager\ndef inference_context(model):\n    """"""\n    A context where the model is temporarily changed to eval mode,\n    and restored to previous mode afterwards.\n    Args:\n        model: a torch Module\n    """"""\n    training_mode = model.training\n    model.eval()\n    yield\n    model.train(training_mode)\n'"
fastreid/evaluation/query_expansion.py,9,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\n# based on\n# https://github.com/PyRetri/PyRetri/blob/master/pyretri/index/re_ranker/re_ranker_impl/query_expansion.py\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\n\ndef aqe(query_feat: torch.tensor, gallery_feat: torch.tensor,\n        qe_times: int = 1, qe_k: int = 10, alpha: float = 3.0):\n    """"""\n    Combining the retrieved topk nearest neighbors with the original query and doing another retrieval.\n    c.f. https://www.robots.ox.ac.uk/~vgg/publications/papers/chum07b.pdf\n    Args :\n        query_feat (torch.tensor):\n        gallery_feat (torch.tensor):\n        qe_times (int): number of query expansion times.\n        qe_k (int): number of the neighbors to be combined.\n        alpha (float):\n    """"""\n    num_query = query_feat.shape[0]\n    all_feat = torch.cat((query_feat, gallery_feat), dim=0)\n    norm_feat = F.normalize(all_feat, p=2, dim=1)\n\n    all_feat = all_feat.numpy()\n    for i in range(qe_times):\n        all_feat_list = []\n        sims = torch.mm(norm_feat, norm_feat.t())\n        sims = sims.data.cpu().numpy()\n        for sim in sims:\n            init_rank = np.argpartition(-sim, range(1, qe_k + 1))\n            weights = sim[init_rank[:qe_k]].reshape((-1, 1))\n            weights = np.power(weights, alpha)\n            all_feat_list.append(np.mean(all_feat[init_rank[:qe_k], :] * weights, axis=0))\n        all_feat = np.stack(all_feat_list, axis=0)\n        norm_feat = F.normalize(torch.from_numpy(all_feat), p=2, dim=1)\n\n    query_feat = torch.from_numpy(all_feat[:num_query])\n    gallery_feat = torch.from_numpy(all_feat[num_query:])\n    return query_feat, gallery_feat\n'"
fastreid/evaluation/rank.py,0,"b'# credits: https://github.com/KaiyangZhou/deep-person-reid/blob/master/torchreid/metrics/rank.py\n\nimport numpy as np\nimport warnings\nfrom collections import defaultdict\n\ntry:\n    from .rank_cylib.rank_cy import evaluate_cy\n\n    IS_CYTHON_AVAI = True\nexcept ImportError:\n    IS_CYTHON_AVAI = False\n    warnings.warn(\n        \'Cython evaluation (very fast so highly recommended) is \'\n        \'unavailable, now use python evaluation.\'\n    )\n\n\ndef eval_cuhk03(distmat, q_pids, g_pids, q_camids, g_camids, max_rank):\n    """"""Evaluation with cuhk03 metric\n    Key: one image for each gallery identity is randomly sampled for each query identity.\n    Random sampling is performed num_repeats times.\n    """"""\n    num_repeats = 10\n    num_q, num_g = distmat.shape\n\n    if num_g < max_rank:\n        max_rank = num_g\n        print(\n            \'Note: number of gallery samples is quite small, got {}\'.\n                format(num_g)\n        )\n\n    indices = np.argsort(distmat, axis=1)\n    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)\n\n    # compute cmc curve for each query\n    all_cmc = []\n    all_AP = []\n    num_valid_q = 0.  # number of valid query\n\n    for q_idx in range(num_q):\n        # get query pid and camid\n        q_pid = q_pids[q_idx]\n        q_camid = q_camids[q_idx]\n\n        # remove gallery samples that have the same pid and camid with query\n        order = indices[q_idx]\n        remove = (g_pids[order] == q_pid) & (g_camids[order] == q_camid)\n        keep = np.invert(remove)\n\n        # compute cmc curve\n        raw_cmc = matches[q_idx][\n            keep]  # binary vector, positions with value 1 are correct matches\n        if not np.any(raw_cmc):\n            # this condition is true when query identity does not appear in gallery\n            continue\n\n        kept_g_pids = g_pids[order][keep]\n        g_pids_dict = defaultdict(list)\n        for idx, pid in enumerate(kept_g_pids):\n            g_pids_dict[pid].append(idx)\n\n        cmc = 0.\n        for repeat_idx in range(num_repeats):\n            mask = np.zeros(len(raw_cmc), dtype=np.bool)\n            for _, idxs in g_pids_dict.items():\n                # randomly sample one image for each gallery person\n                rnd_idx = np.random.choice(idxs)\n                mask[rnd_idx] = True\n            masked_raw_cmc = raw_cmc[mask]\n            _cmc = masked_raw_cmc.cumsum()\n            _cmc[_cmc > 1] = 1\n            cmc += _cmc[:max_rank].astype(np.float32)\n\n        cmc /= num_repeats\n        all_cmc.append(cmc)\n        # compute AP\n        num_rel = raw_cmc.sum()\n        tmp_cmc = raw_cmc.cumsum()\n        tmp_cmc = [x / (i + 1.) for i, x in enumerate(tmp_cmc)]\n        tmp_cmc = np.asarray(tmp_cmc) * raw_cmc\n        AP = tmp_cmc.sum() / num_rel\n        all_AP.append(AP)\n        num_valid_q += 1.\n\n    assert num_valid_q > 0, \'Error: all query identities do not appear in gallery\'\n\n    all_cmc = np.asarray(all_cmc).astype(np.float32)\n    all_cmc = all_cmc.sum(0) / num_valid_q\n    mAP = np.mean(all_AP)\n\n    return all_cmc, mAP\n\n\ndef eval_market1501(distmat, q_pids, g_pids, q_camids, g_camids, max_rank):\n    """"""Evaluation with market1501 metric\n    Key: for each query identity, its gallery images from the same camera view are discarded.\n    """"""\n    num_q, num_g = distmat.shape\n\n    if num_g < max_rank:\n        max_rank = num_g\n        print(\'Note: number of gallery samples is quite small, got {}\'.format(num_g))\n\n    indices = np.argsort(distmat, axis=1)\n\n    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)\n\n    # compute cmc curve for each query\n    all_cmc = []\n    all_AP = []\n    all_INP = []\n    num_valid_q = 0.  # number of valid query\n\n    for q_idx in range(num_q):\n        # get query pid and camid\n        q_pid = q_pids[q_idx]\n        q_camid = q_camids[q_idx]\n\n        # remove gallery samples that have the same pid and camid with query\n        order = indices[q_idx]\n        remove = (g_pids[order] == q_pid) & (g_camids[order] == q_camid)\n        keep = np.invert(remove)\n\n        # compute cmc curve\n        raw_cmc = matches[q_idx][keep]  # binary vector, positions with value 1 are correct matches\n        if not np.any(raw_cmc):\n            # this condition is true when query identity does not appear in gallery\n            continue\n\n        cmc = raw_cmc.cumsum()\n\n        pos_idx = np.where(raw_cmc == 1)\n        max_pos_idx = np.max(pos_idx)\n        inp = cmc[max_pos_idx] / (max_pos_idx + 1.0)\n        all_INP.append(inp)\n\n        cmc[cmc > 1] = 1\n\n        all_cmc.append(cmc[:max_rank])\n        num_valid_q += 1.\n\n        # compute average precision\n        # reference: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision\n        num_rel = raw_cmc.sum()\n        tmp_cmc = raw_cmc.cumsum()\n        tmp_cmc = [x / (i + 1.) for i, x in enumerate(tmp_cmc)]\n        tmp_cmc = np.asarray(tmp_cmc) * raw_cmc\n        AP = tmp_cmc.sum() / num_rel\n        all_AP.append(AP)\n\n    assert num_valid_q > 0, \'Error: all query identities do not appear in gallery\'\n\n    all_cmc = np.asarray(all_cmc).astype(np.float32)\n    all_cmc = all_cmc.sum(0) / num_valid_q\n    mAP = np.mean(all_AP)\n    mINP = np.mean(all_INP)\n\n    return all_cmc, mAP, mINP\n\n\ndef evaluate_py(\n        distmat, q_pids, g_pids, q_camids, g_camids, max_rank, use_metric_cuhk03\n):\n    if use_metric_cuhk03:\n        return eval_cuhk03(\n            distmat, q_pids, g_pids, q_camids, g_camids, max_rank\n        )\n    else:\n        return eval_market1501(\n            distmat, q_pids, g_pids, q_camids, g_camids, max_rank\n        )\n\n\ndef evaluate_rank(\n        distmat,\n        q_pids,\n        g_pids,\n        q_camids,\n        g_camids,\n        max_rank=50,\n        use_metric_cuhk03=False,\n        use_cython=True\n):\n    """"""Evaluates CMC rank.\n    Args:\n        distmat (numpy.ndarray): distance matrix of shape (num_query, num_gallery).\n        q_pids (numpy.ndarray): 1-D array containing person identities\n            of each query instance.\n        g_pids (numpy.ndarray): 1-D array containing person identities\n            of each gallery instance.\n        q_camids (numpy.ndarray): 1-D array containing camera views under\n            which each query instance is captured.\n        g_camids (numpy.ndarray): 1-D array containing camera views under\n            which each gallery instance is captured.\n        max_rank (int, optional): maximum CMC rank to be computed. Default is 50.\n        use_metric_cuhk03 (bool, optional): use single-gallery-shot setting for cuhk03.\n            Default is False. This should be enabled when using cuhk03 classic split.\n        use_cython (bool, optional): use cython code for evaluation. Default is True.\n            This is highly recommended as the cython code can speed up the cmc computation\n            by more than 10x. This requires Cython to be installed.\n    """"""\n    if use_cython and IS_CYTHON_AVAI:\n        return evaluate_cy(\n            distmat, q_pids, g_pids, q_camids, g_camids, max_rank,\n            use_metric_cuhk03\n        )\n    else:\n        return evaluate_py(\n            distmat, q_pids, g_pids, q_camids, g_camids, max_rank,\n            use_metric_cuhk03\n        )\n'"
fastreid/evaluation/reid_evaluation.py,6,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nimport copy\nimport logging\nfrom collections import OrderedDict\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\nfrom .evaluator import DatasetEvaluator\nfrom .query_expansion import aqe\nfrom .rank import evaluate_rank\nfrom .roc import evaluate_roc\nfrom .rerank import re_ranking\n\nlogger = logging.getLogger(__name__)\n\n\nclass ReidEvaluator(DatasetEvaluator):\n    def __init__(self, cfg, num_query, output_dir=None):\n        self.cfg = cfg\n        self._num_query = num_query\n        self._output_dir = output_dir\n\n        self.features = []\n        self.pids = []\n        self.camids = []\n\n    def reset(self):\n        self.features = []\n        self.pids = []\n        self.camids = []\n\n    def process(self, outputs):\n        self.features.append(outputs[0].cpu())\n        self.pids.extend(outputs[1].cpu().numpy())\n        self.camids.extend(outputs[2].cpu().numpy())\n\n    @staticmethod\n    def cal_dist(metric: str, query_feat: torch.tensor, gallery_feat: torch.tensor):\n        assert metric in [""cosine"", ""euclidean""], ""must choose from [cosine, euclidean], but got {}"".format(metric)\n        if metric == ""cosine"":\n            query_feat = F.normalize(query_feat, dim=1)\n            gallery_feat = F.normalize(gallery_feat, dim=1)\n            dist = 1 - torch.mm(query_feat, gallery_feat.t())\n        else:\n            m, n = query_feat.size(0), gallery_feat.size(0)\n            xx = torch.pow(query_feat, 2).sum(1, keepdim=True).expand(m, n)\n            yy = torch.pow(gallery_feat, 2).sum(1, keepdim=True).expand(n, m).t()\n            dist = xx + yy\n            dist.addmm_(1, -2, query_feat, gallery_feat.t())\n            dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n        return dist.cpu().numpy()\n\n    def evaluate(self):\n        features = torch.cat(self.features, dim=0)\n\n        # query feature, person ids and camera ids\n        query_features = features[:self._num_query]\n        query_pids = np.asarray(self.pids[:self._num_query])\n        query_camids = np.asarray(self.camids[:self._num_query])\n\n        # gallery features, person ids and camera ids\n        gallery_features = features[self._num_query:]\n        gallery_pids = np.asarray(self.pids[self._num_query:])\n        gallery_camids = np.asarray(self.camids[self._num_query:])\n\n        self._results = OrderedDict()\n\n        if self.cfg.TEST.AQE.ENABLED:\n            logger.info(""Test with AQE setting"")\n            qe_time = self.cfg.TEST.AQE.QE_TIME\n            qe_k = self.cfg.TEST.AQE.QE_K\n            alpha = self.cfg.TEST.AQE.ALPHA\n            query_features, gallery_features = aqe(query_features, gallery_features, qe_time, qe_k, alpha)\n\n        dist = self.cal_dist(self.cfg.TEST.METRIC, query_features, gallery_features)\n\n        if self.cfg.TEST.RERANK.ENABLED:\n            logger.info(""Test with rerank setting"")\n            k1 = self.cfg.TEST.RERANK.K1\n            k2 = self.cfg.TEST.RERANK.K2\n            lambda_value = self.cfg.TEST.RERANK.LAMBDA\n            q_q_dist = self.cal_dist(self.cfg.TEST.METRIC, query_features, query_features)\n            g_g_dist = self.cal_dist(self.cfg.TEST.METRIC, gallery_features, gallery_features)\n            dist = re_ranking(dist, q_q_dist, g_g_dist, k1, k2, lambda_value)\n\n        cmc, all_AP, all_INP = evaluate_rank(dist, query_pids, gallery_pids, query_camids, gallery_camids)\n        mAP = np.mean(all_AP)\n        mINP = np.mean(all_INP)\n        for r in [1, 5, 10]:\n            self._results[\'Rank-{}\'.format(r)] = cmc[r - 1]\n        self._results[\'mAP\'] = mAP\n        self._results[\'mINP\'] = mINP\n\n        tprs = evaluate_roc(dist, query_pids, gallery_pids, query_camids, gallery_camids)\n        fprs = [1e-4, 1e-3, 1e-2]\n        for i in range(len(fprs)):\n            self._results[""TPR@FPR={}"".format(fprs[i])] = tprs[i]\n        return copy.deepcopy(self._results)\n'"
fastreid/evaluation/rerank.py,0,"b""# encoding: utf-8\n\n# based on:\n# https://github.com/zhunzhong07/person-re-ranking\n\n__all__ = ['re_ranking']\n\nimport numpy as np\n\n\ndef re_ranking(q_g_dist, q_q_dist, g_g_dist, k1: int = 20, k2: int = 6, lambda_value: float = 0.3):\n    original_dist = np.concatenate(\n        [np.concatenate([q_q_dist, q_g_dist], axis=1),\n         np.concatenate([q_g_dist.T, g_g_dist], axis=1)],\n        axis=0)\n    original_dist = np.power(original_dist, 2).astype(np.float32)\n    original_dist = np.transpose(1. * original_dist / np.max(original_dist, axis=0))\n    V = np.zeros_like(original_dist).astype(np.float32)\n    initial_rank = np.argsort(original_dist).astype(np.int32)\n\n    query_num = q_g_dist.shape[0]\n    gallery_num = q_g_dist.shape[0] + q_g_dist.shape[1]\n    all_num = gallery_num\n\n    for i in range(all_num):\n        # k-reciprocal neighbors\n        forward_k_neigh_index = initial_rank[i, :k1 + 1]\n        backward_k_neigh_index = initial_rank[forward_k_neigh_index, :k1 + 1]\n        fi = np.where(backward_k_neigh_index == i)[0]\n        k_reciprocal_index = forward_k_neigh_index[fi]\n        k_reciprocal_expansion_index = k_reciprocal_index\n        for j in range(len(k_reciprocal_index)):\n            candidate = k_reciprocal_index[j]\n            candidate_forward_k_neigh_index = initial_rank[candidate,\n                                              :int(np.around(k1 / 2.)) + 1]\n            candidate_backward_k_neigh_index = initial_rank[candidate_forward_k_neigh_index,\n                                               :int(np.around(k1 / 2.)) + 1]\n            fi_candidate = np.where(candidate_backward_k_neigh_index == candidate)[0]\n            candidate_k_reciprocal_index = candidate_forward_k_neigh_index[fi_candidate]\n            if len(np.intersect1d(candidate_k_reciprocal_index, k_reciprocal_index)) > 2. / 3 * len(\n                    candidate_k_reciprocal_index):\n                k_reciprocal_expansion_index = np.append(k_reciprocal_expansion_index, candidate_k_reciprocal_index)\n\n        k_reciprocal_expansion_index = np.unique(k_reciprocal_expansion_index)\n        weight = np.exp(-original_dist[i, k_reciprocal_expansion_index])\n        V[i, k_reciprocal_expansion_index] = 1. * weight / np.sum(weight)\n    original_dist = original_dist[:query_num, ]\n    if k2 != 1:\n        V_qe = np.zeros_like(V, dtype=np.float32)\n        for i in range(all_num):\n            V_qe[i, :] = np.mean(V[initial_rank[i, :k2], :], axis=0)\n        V = V_qe\n        del V_qe\n    del initial_rank\n    invIndex = []\n    for i in range(gallery_num):\n        invIndex.append(np.where(V[:, i] != 0)[0])\n\n    jaccard_dist = np.zeros_like(original_dist, dtype=np.float32)\n\n    for i in range(query_num):\n        temp_min = np.zeros(shape=[1, gallery_num], dtype=np.float32)\n        indNonZero = np.where(V[i, :] != 0)[0]\n        indImages = [invIndex[ind] for ind in indNonZero]\n        for j in range(len(indNonZero)):\n            temp_min[0, indImages[j]] = temp_min[0, indImages[j]] + np.minimum(V[i, indNonZero[j]],\n                                                                               V[indImages[j], indNonZero[j]])\n        jaccard_dist[i] = 1 - temp_min / (2. - temp_min)\n\n    final_dist = jaccard_dist * (1 - lambda_value) + original_dist * lambda_value\n    del original_dist, V, jaccard_dist\n    final_dist = final_dist[:query_num, query_num:]\n    return final_dist\n"""
fastreid/evaluation/roc.py,0,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport numpy as np\nfrom sklearn import metrics\n\n\ndef evaluate_roc(distmat, q_pids, g_pids, q_camids, g_camids):\n    r""""""Evaluation with ROC curve.\n    Key: for each query identity, its gallery images from the same camera view are discarded.\n\n    Args:\n        distmat (np.ndarray): cosine distance matrix\n    """"""\n    num_q, num_g = distmat.shape\n\n    indices = np.argsort(distmat, axis=1)\n    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)\n\n    pos = []\n    neg = []\n    for q_idx in range(num_q):\n        # get query pid and camid\n        q_pid = q_pids[q_idx]\n        q_camid = q_camids[q_idx]\n\n        # Remove gallery samples that have the same pid and camid with query\n        order = indices[q_idx]\n        remove = (g_pids[order] == q_pid) & (g_camids[order] == q_camid)\n        keep = np.invert(remove)\n        cmc = matches[q_idx][keep]\n        sort_idx = order[keep]\n\n        q_dist = distmat[q_idx]\n        ind_pos = np.where(cmc == 1)[0]\n        pos.extend(q_dist[sort_idx[ind_pos]])\n\n        ind_neg = np.where(cmc == 0)[0]\n        neg.extend(q_dist[sort_idx[ind_neg]])\n\n    scores = np.hstack((pos, neg))\n\n    labels = np.hstack((np.zeros(len(pos)), np.ones(len(neg))))\n    fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n    tprs = []\n    for i in [1e-4, 1e-3, 1e-2]:\n        ind = np.argmin(np.abs(fpr-i))\n        tprs.append(tpr[ind])\n    return tprs\n'"
fastreid/evaluation/testing.py,0,"b'# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nimport logging\nimport pprint\nimport sys\nfrom collections import Mapping, OrderedDict\n\nimport numpy as np\n\n\ndef print_csv_format(results):\n    """"""\n    Print main metrics in a format similar to Detectron,\n    so that they are easy to copypaste into a spreadsheet.\n    Args:\n        results (OrderedDict[dict]): task_name -> {metric -> score}\n    """"""\n    assert isinstance(results, OrderedDict), results  # unordered results cannot be properly printed\n    logger = logging.getLogger(__name__)\n    for task, res in results.items():\n        logger.info(""Task: {}"".format(task))\n        logger.info(""{:.1%}"".format(res))\n\n\ndef verify_results(cfg, results):\n    """"""\n    Args:\n        results (OrderedDict[dict]): task_name -> {metric -> score}\n    Returns:\n        bool: whether the verification succeeds or not\n    """"""\n    expected_results = cfg.TEST.EXPECTED_RESULTS\n    if not len(expected_results):\n        return True\n\n    ok = True\n    for task, metric, expected, tolerance in expected_results:\n        actual = results[task][metric]\n        if not np.isfinite(actual):\n            ok = False\n        diff = abs(actual - expected)\n        if diff > tolerance:\n            ok = False\n\n    logger = logging.getLogger(__name__)\n    if not ok:\n        logger.error(""Result verification failed!"")\n        logger.error(""Expected Results: "" + str(expected_results))\n        logger.error(""Actual Results: "" + pprint.pformat(results))\n\n        sys.exit(1)\n    else:\n        logger.info(""Results verification passed."")\n    return ok\n\n\ndef flatten_results_dict(results):\n    """"""\n    Expand a hierarchical dict of scalars into a flat dict of scalars.\n    If results[k1][k2][k3] = v, the returned dict will have the entry\n    {""k1/k2/k3"": v}.\n    Args:\n        results (dict):\n    """"""\n    r = {}\n    for k, v in results.items():\n        if isinstance(v, Mapping):\n            v = flatten_results_dict(v)\n            for kk, vv in v.items():\n                r[k + ""/"" + kk] = vv\n        else:\n            r[k] = v\n    return r\n'"
fastreid/export/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""'"
fastreid/export/tensorflow_export.py,12,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport warnings\n\nwarnings.filterwarnings(\'ignore\')  # Ignore all the warning messages in this tutorial\nfrom onnx_tf.backend import prepare\n\nimport tensorflow as tf\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\nimport onnx\nimport numpy as np\nimport torch\nfrom torch.backends import cudnn\nimport io\n\ncudnn.benchmark = True\n\n\ndef _export_via_onnx(model, inputs):\n    from ipdb import set_trace;\n    set_trace()\n\n    def _check_val(module):\n        assert not module.training\n\n    model.apply(_check_val)\n\n    # Export the model to ONNX\n    with torch.no_grad():\n        with io.BytesIO() as f:\n            torch.onnx.export(\n                model,\n                inputs,\n                f,\n                # verbose=True,  # NOTE: uncomment this for debugging\n                export_params=True,\n            )\n            onnx_model = onnx.load_from_string(f.getvalue())\n    # torch.onnx.export(model,  # model being run\n    #                   inputs,  # model input (or a tuple for multiple inputs)\n    #                   ""reid_test.onnx"",  # where to save the model (can be a file or file-like object)\n    # export_params=True,  # store the trained parameter weights inside the model file\n    # opset_version=10,  # the ONNX version to export the model to\n    # do_constant_folding=True,  # whether to execute constant folding for optimization\n    # input_names=[\'input\'],  # the model\'s input names\n    # output_names=[\'output\'],  # the model\'s output names\n    # dynamic_axes={\'input\': {0: \'batch_size\'},  # variable lenght axes\n    #               \'output\': {0: \'batch_size\'}})\n    # )\n\n    # Apply ONNX\'s Optimization\n    # all_passes = optimizer.get_available_passes()\n    # passes = [""fuse_bn_into_conv""]\n    # assert all(p in all_passes for p in passes)\n    # onnx_model = optimizer.optimize(onnx_model, passes)\n\n    # Convert ONNX Model to Tensorflow Model\n    tf_rep = prepare(onnx_model, strict=False)  # Import the ONNX model to Tensorflow\n    print(tf_rep.inputs)  # Input nodes to the model\n    print(\'-----\')\n    print(tf_rep.outputs)  # Output nodes from the model\n    print(\'-----\')\n    # print(tf_rep.tensor_dict)  # All nodes in the model\n    # """"""\n\n    # install onnx-tensorflow from github\xef\xbc\x8cand tf_rep = prepare(onnx_model, strict=False)\n    # Reference https://github.com/onnx/onnx-tensorflow/issues/167\n    # tf_rep = prepare(onnx_model) # whthout strict=False leads to KeyError: \'pyfunc_0\'\n\n    # debug, here using the same input to check onnx and tf.\n    # output_onnx_tf = tf_rep.run(to_numpy(img))\n    # print(\'output_onnx_tf = {}\'.format(output_onnx_tf))\n    # onnx --> tf.graph.pb\n    # tf_pb_path = \'reid_tf_graph.pb\'\n    # tf_rep.export_graph(tf_pb_path)\n\n    return tf_rep\n\n\ndef to_numpy(tensor):\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n\n\ndef _check_pytorch_tf_model(model: torch.nn.Module, tf_graph_path: str):\n    img = Image.open(""demo_imgs/dog.jpg"")\n\n    resize = transforms.Resize([384, 128])\n    img = resize(img)\n\n    to_tensor = transforms.ToTensor()\n    img = to_tensor(img)\n    img.unsqueeze_(0)\n    torch_outs = model(img)\n\n    with tf.Graph().as_default():\n        graph_def = tf.GraphDef()\n        with open(tf_graph_path, ""rb"") as f:\n            graph_def.ParseFromString(f.read())\n            tf.import_graph_def(graph_def, name="""")\n        with tf.Session() as sess:\n            # init = tf.initialize_all_variables()\n            # init = tf.global_variables_initializer()\n            # sess.run(init)\n\n            # print all ops, check input/output tensor name.\n            # uncomment it if you donnot know io tensor names.\n            \'\'\'\n            print(\'-------------ops---------------------\')\n            op = sess.graph.get_operations()\n            for m in op:\n                try:\n                    # if \'input\' in m.values()[0].name:\n                    #     print(m.values())\n                    if m.values()[0].shape.as_list()[1] == 2048: #and (len(m.values()[0].shape.as_list()) == 4):\n                        print(m.values())\n                except:\n                    pass\n            print(\'-------------ops done.---------------------\')\n            \'\'\'\n            input_x = sess.graph.get_tensor_by_name(\'input.1:0\')  # input\n            outputs = sess.graph.get_tensor_by_name(\'502:0\')  # 5\n            output_tf_pb = sess.run(outputs, feed_dict={input_x: to_numpy(img)})\n\n    print(\'output_pytorch = {}\'.format(to_numpy(torch_outs)))\n    print(\'output_tf_pb = {}\'.format(output_tf_pb))\n\n    np.testing.assert_allclose(to_numpy(torch_outs), output_tf_pb, rtol=1e-03, atol=1e-05)\n    print(""Exported model has been tested with tensorflow runtime, and the result looks good!"")\n\n\ndef export_tf_reid_model(model: torch.nn.Module, tensor_inputs: torch.Tensor, graph_save_path: str):\n    """"""\n    Export a reid model via ONNX.\n    Arg:\n        model: a tf_1.x-compatible version of detectron2 model, defined in caffe2_modeling.py\n        tensor_inputs: a list of tensors that caffe2 model takes as input.\n    """"""\n    # model = copy.deepcopy(model)\n    assert isinstance(model, torch.nn.Module)\n\n    # Export via ONNX\n    print(""Exporting a {} model via ONNX ..."".format(type(model).__name__))\n    predict_net = _export_via_onnx(model, tensor_inputs)\n    print(""ONNX export Done."")\n\n    print(""Saving graph of ONNX exported model to {} ..."".format(graph_save_path))\n    predict_net.export_graph(graph_save_path)\n\n    print(""Checking if tf.pb is right"")\n    _check_pytorch_tf_model(model, graph_save_path)\n\n# if __name__ == \'__main__\':\n# args = default_argument_parser().parse_args()\n# print(""Command Line Args:"", args)\n# cfg = setup(args)\n# cfg = cfg.defrost()\n# cfg.MODEL.BACKBONE.NAME = ""build_resnet_backbone""\n# cfg.MODEL.BACKBONE.DEPTH = 50\n# cfg.MODEL.BACKBONE.LAST_STRIDE = 1\n# # If use IBN block in backbone\n# cfg.MODEL.BACKBONE.WITH_IBN = True\n#\n# model = build_model(cfg)\n# # model.load_params_wo_fc(torch.load(\'logs/bjstation/res50_baseline_v0.4/ckpts/model_epoch80.pth\'))\n# model.cuda()\n# model.eval()\n# dummy_inputs = torch.randn(1, 3, 256, 128)\n# export_tf_reid_model(model, dummy_inputs, \'reid_tf.pb\')\n\n# inputs = torch.rand(1, 3, 384, 128).cuda()\n#\n# _export_via_onnx(model, inputs)\n# onnx_model = onnx.load(""reid_test.onnx"")\n# onnx.checker.check_model(onnx_model)\n#\n# from PIL import Image\n# import torchvision.transforms as transforms\n#\n# img = Image.open(""demo_imgs/dog.jpg"")\n#\n# resize = transforms.Resize([384, 128])\n# img = resize(img)\n#\n# to_tensor = transforms.ToTensor()\n# img = to_tensor(img)\n# img.unsqueeze_(0)\n# img = img.cuda()\n#\n# with torch.no_grad():\n#     torch_out = model(img)\n#\n# ort_session = onnxruntime.InferenceSession(""reid_test.onnx"")\n#\n# # compute ONNX Runtime output prediction\n# ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img)}\n# ort_outs = ort_session.run(None, ort_inputs)\n# img_out_y = ort_outs[0]\n#\n#\n# # compare ONNX Runtime and PyTorch results\n# np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n#\n# print(""Exported model has been tested with ONNXRuntime, and the result looks good!"")\n\n# img = Image.open(""demo_imgs/dog.jpg"")\n#\n# resize = transforms.Resize([384, 128])\n# img = resize(img)\n#\n# to_tensor = transforms.ToTensor()\n# img = to_tensor(img)\n# img.unsqueeze_(0)\n# img = torch.cat([img.clone(), img.clone()], dim=0)\n\n# ort_session = onnxruntime.InferenceSession(""reid_test.onnx"")\n\n# # compute ONNX Runtime output prediction\n# ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img)}\n# ort_outs = ort_session.run(None, ort_inputs)\n\n# model = onnx.load(\'reid_test.onnx\')  # Load the ONNX file\n# tf_rep = prepare(model, strict=False) # Import the ONNX model to Tensorflow\n# print(tf_rep.inputs)  # Input nodes to the model\n# print(\'-----\')\n# print(tf_rep.outputs)  # Output nodes from the model\n# print(\'-----\')\n# # print(tf_rep.tensor_dict)  # All nodes in the model\n\n# install onnx-tensorflow from github\xef\xbc\x8cand tf_rep = prepare(onnx_model, strict=False)\n# Reference https://github.com/onnx/onnx-tensorflow/issues/167\n# tf_rep = prepare(onnx_model) # whthout strict=False leads to KeyError: \'pyfunc_0\'\n\n# # debug, here using the same input to check onnx and tf.\n# # output_onnx_tf = tf_rep.run(to_numpy(img))\n# # print(\'output_onnx_tf = {}\'.format(output_onnx_tf))\n# # onnx --> tf.graph.pb\n# tf_pb_path = \'reid_tf_graph.pb\'\n# tf_rep.export_graph(tf_pb_path)\n\n# # step 3, check if tf.pb is right.\n# with tf.Graph().as_default():\n#     graph_def = tf.GraphDef()\n#     with open(tf_pb_path, ""rb"") as f:\n#         graph_def.ParseFromString(f.read())\n#         tf.import_graph_def(graph_def, name="""")\n#     with tf.Session() as sess:\n#         # init = tf.initialize_all_variables()\n#         init = tf.global_variables_initializer()\n#         # sess.run(init)\n\n#         # print all ops, check input/output tensor name.\n#         # uncomment it if you donnot know io tensor names.\n#         \'\'\'\n#         print(\'-------------ops---------------------\')\n#         op = sess.graph.get_operations()\n#         for m in op:\n#             try:\n#                 # if \'input\' in m.values()[0].name:\n#                 #     print(m.values())\n#                 if m.values()[0].shape.as_list()[1] == 2048: #and (len(m.values()[0].shape.as_list()) == 4):\n#                     print(m.values())\n#             except:\n#                 pass\n#         print(\'-------------ops done.---------------------\')\n#         \'\'\'\n#         input_x = sess.graph.get_tensor_by_name(\'input.1:0\')  # input\n#         outputs = sess.graph.get_tensor_by_name(\'502:0\')  # 5\n#         output_tf_pb = sess.run(outputs, feed_dict={input_x: to_numpy(img)})\n#         print(\'output_tf_pb = {}\'.format(output_tf_pb))\n# np.testing.assert_allclose(ort_outs[0], output_tf_pb, rtol=1e-03, atol=1e-05)\n\n# with tf.Graph().as_default():\n#     graph_def = tf.GraphDef()\n#     with open(tf_pb_path, ""rb"") as f:\n#         graph_def.ParseFromString(f.read())\n#         tf.import_graph_def(graph_def, name="""")\n#     with tf.Session() as sess:\n#         # init = tf.initialize_all_variables()\n#         init = tf.global_variables_initializer()\n#         # sess.run(init)\n#\n#         # print all ops, check input/output tensor name.\n#         # uncomment it if you donnot know io tensor names.\n#         \'\'\'\n#         print(\'-------------ops---------------------\')\n#         op = sess.graph.get_operations()\n#         for m in op:\n#             try:\n#                 # if \'input\' in m.values()[0].name:\n#                 #     print(m.values())\n#                 if m.values()[0].shape.as_list()[1] == 2048: #and (len(m.values()[0].shape.as_list()) == 4):\n#                     print(m.values())\n#             except:\n#                 pass\n#         print(\'-------------ops done.---------------------\')\n#         \'\'\'\n#         input_x = sess.graph.get_tensor_by_name(\'input.1:0\')  # input\n#         outputs = sess.graph.get_tensor_by_name(\'502:0\')  # 5\n#         output_tf_pb = sess.run(outputs, feed_dict={input_x: to_numpy(img)})\n#         from ipdb import set_trace;\n#\n#         set_trace()\n#         print(\'output_tf_pb = {}\'.format(output_tf_pb))\n'"
fastreid/export/tf_modeling.py,0,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nfrom torch import nn\nfrom ..modeling.backbones import build_backbone\nfrom ..modeling.heads import build_reid_heads\n\n\nclass TfMetaArch(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.backbone = build_backbone(cfg)\n        self.heads = build_reid_heads(cfg)\n\n    def forward(self, x):\n        global_feat = self.backbone(x)\n        pred_features = self.heads(global_feat)\n        return pred_features\n'"
fastreid/layers/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nfrom torch import nn\n\nfrom .batch_drop import BatchDrop\nfrom .attention import *\nfrom .batch_norm import *\nfrom .context_block import ContextBlock\nfrom .non_local import Non_local\nfrom .se_layer import SELayer\nfrom .frn import FRN, TLU\nfrom .activation import *\nfrom .gem_pool import GeneralizedMeanPoolingP, AdaptiveAvgMaxPool2d\nfrom .arcface import Arcface\nfrom .circle import Circle\nfrom .splat import SplAtConv2d\n\n\nclass Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n'"
fastreid/layers/activation.py,8,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n__all__ = [\n    \'Mish\',\n    \'Swish\',\n    \'MemoryEfficientSwish\',\n    \'GELU\']\n\n\nclass Mish(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        # inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!)\n        return x * (torch.tanh(F.softplus(x)))\n\n\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n\nclass SwishImplementation(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * torch.sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = torch.sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\n\nclass MemoryEfficientSwish(nn.Module):\n    def forward(self, x):\n        return SwishImplementation.apply(x)\n\n\nclass GELU(nn.Module):\n    """"""\n    Paper Section 3.4, last paragraph notice that BERT used the GELU instead of RELU\n    """"""\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n'"
fastreid/layers/arcface.py,6,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\n\nfrom fastreid.utils.one_hot import one_hot\n\n\nclass Arcface(nn.Module):\n    def __init__(self, cfg, in_feat, num_classes):\n        super().__init__()\n        self.in_feat = in_feat\n        self._num_classes = num_classes\n        self._s = cfg.MODEL.HEADS.SCALE\n        self._m = cfg.MODEL.HEADS.MARGIN\n\n        self.weight = Parameter(torch.Tensor(self._num_classes, in_feat))\n\n    def forward(self, features, targets):\n        # get cos(theta)\n        cosine = F.linear(F.normalize(features), F.normalize(self.weight))\n\n        # add margin\n        theta = torch.acos(torch.clamp(cosine, -1.0 + 1e-7, 1.0 - 1e-7))\n\n        phi = torch.cos(theta + self._m)\n\n        # --------------------------- convert label to one-hot ---------------------------\n        targets = one_hot(targets, self._num_classes)\n        pred_class_logits = targets * phi + (1.0 - targets) * cosine\n\n        # logits re-scale\n        pred_class_logits *= self._s\n\n        return pred_class_logits\n\n    def extra_repr(self):\n        return \'in_features={}, num_classes={}, scale={}, margin={}\'.format(\n            self.in_feat, self._num_classes, self._s, self._m\n        )\n'"
fastreid/layers/attention.py,9,"b'# encoding: utf-8\n""""""\n@author:  CASIA IVA\n@contact: jliu@nlpr.ia.ac.cn\n""""""\n\nimport torch\nfrom torch.nn import Module, Conv2d, Parameter, Softmax\nimport torch.nn as nn\n\n__all__ = [\'PAM_Module\', \'CAM_Module\', \'DANetHead\',]\n\n\nclass DANetHead(nn.Module):\n    def __init__(self,\n                 in_channels: int,\n                 out_channels: int,\n                 norm_layer: nn.Module,\n                 module_class: type,\n                 dim_collapsion: int=2):\n        super(DANetHead, self).__init__()\n\n        inter_channels = in_channels // dim_collapsion\n\n        self.conv5c = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                inter_channels,\n                3,\n                padding=1,\n                bias=False\n            ),\n            norm_layer(inter_channels),\n            nn.ReLU()\n        )\n\n        self.attention_module = module_class(inter_channels)\n        self.conv52 = nn.Sequential(\n            nn.Conv2d(\n                inter_channels,\n                inter_channels,\n                3,\n                padding=1,\n                bias=False\n            ),\n            norm_layer(inter_channels),\n            nn.ReLU()\n        )\n\n        self.conv7 = nn.Sequential(\n            nn.Dropout2d(0.1, False),\n            nn.Conv2d(inter_channels, out_channels, 1)\n        )\n\n    def forward(self, x):\n\n        feat2 = self.conv5c(x)\n        sc_feat = self.attention_module(feat2)\n        sc_conv = self.conv52(sc_feat)\n        sc_output = self.conv7(sc_conv)\n\n        return sc_output\n\n\nclass PAM_Module(nn.Module):\n    """""" Position attention module""""""\n    # Ref from SAGAN\n\n    def __init__(self, in_dim):\n        super(PAM_Module, self).__init__()\n        self.channel_in = in_dim\n\n        self.query_conv = Conv2d(\n            in_channels=in_dim,\n            out_channels=in_dim // 8,\n            kernel_size=1\n        )\n        self.key_conv = Conv2d(\n            in_channels=in_dim,\n            out_channels=in_dim // 8,\n            kernel_size=1\n        )\n        self.value_conv = Conv2d(\n            in_channels=in_dim,\n            out_channels=in_dim,\n            kernel_size=1\n        )\n        self.gamma = Parameter(torch.zeros(1))\n\n        self.softmax = Softmax(dim=-1)\n\n    def forward(self, x):\n        """"""\n            inputs :\n                x : input feature maps( B X C X H X W)\n            returns :\n                out : attention value + input feature\n                attention: B X (HxW) X (HxW)\n        """"""\n        m_batchsize, C, height, width = x.size()\n        proj_query = self.query_conv(x).view(m_batchsize, -1, width * height).permute(0, 2, 1)\n        proj_key = self.key_conv(x).view(m_batchsize, -1, width * height)\n        energy = torch.bmm(proj_query, proj_key)\n        attention = self.softmax(energy)\n        proj_value = self.value_conv(x).view(m_batchsize, -1, width * height)\n\n        out = torch.bmm(\n            proj_value,\n            attention.permute(0, 2, 1)\n        )\n        attention_mask = out.view(m_batchsize, C, height, width)\n\n        out = self.gamma * attention_mask + x\n        return out\n\n\nclass CAM_Module(nn.Module):\n    """""" Channel attention module""""""\n\n    def __init__(self, in_dim):\n        super().__init__()\n        self.channel_in = in_dim\n\n        self.gamma = Parameter(torch.zeros(1))\n        self.softmax = Softmax(dim=-1)\n\n    def forward(self, x):\n        """"""\n            inputs :\n                x : input feature maps( B X C X H X W)\n            returns :\n                out : attention value + input feature\n                attention: B X C X C\n        """"""\n        m_batchsize, C, height, width = x.size()\n        proj_query = x.view(m_batchsize, C, -1)\n        proj_key = x.view(m_batchsize, C, -1).permute(0, 2, 1)\n        energy = torch.bmm(proj_query, proj_key)\n        max_energy_0 = torch.max(energy, -1, keepdim=True)[0].expand_as(energy)\n        energy_new = max_energy_0 - energy\n        attention = self.softmax(energy_new)\n        proj_value = x.view(m_batchsize, C, -1)\n\n        out = torch.bmm(attention, proj_value)\n        out = out.view(m_batchsize, C, height, width)\n\n        gamma = self.gamma.to(out.device)\n        out = gamma * out + x\n        return out\n\n\n# def get_attention_module_instance(\n#     name: \'cam | pam | identity\',\n#     dim: int,\n#     *,\n#     out_dim=None,\n#     use_head: bool=False,\n#     dim_collapsion=2  # Used iff `used_head` set to True\n# ):\n#\n#     name = name.lower()\n#     assert name in (\'cam\', \'pam\', \'identity\')\n#\n#     module_class = name_module_class_mapping[name]\n#\n#     if out_dim is None:\n#         out_dim = dim\n#\n#     if use_head:\n#         return DANetHead(\n#             dim, out_dim,\n#             nn.BatchNorm2d,\n#             module_class,\n#             dim_collapsion=dim_collapsion\n#         )\n#     else:\n#         return module_class(dim)'"
fastreid/layers/batch_drop.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport random\n\nfrom torch import nn\n\n\nclass BatchDrop(nn.Module):\n    """"""ref: https://github.com/daizuozhuo/batch-dropblock-network/blob/master/models/networks.py\n    batch drop mask\n    """"""\n\n    def __init__(self, h_ratio, w_ratio):\n        super(BatchDrop, self).__init__()\n        self.h_ratio = h_ratio\n        self.w_ratio = w_ratio\n\n    def forward(self, x):\n        if self.training:\n            h, w = x.size()[-2:]\n            rh = round(self.h_ratio * h)\n            rw = round(self.w_ratio * w)\n            sx = random.randint(0, h - rh)\n            sy = random.randint(0, w - rw)\n            mask = x.new_ones(x.size())\n            mask[:, :, sx:sx + rh, sy:sy + rw] = 0\n            x = x * mask\n        return x\n'"
fastreid/layers/batch_norm.py,10,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport logging\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\n\nfrom .sync_bn import SynchronizedBatchNorm2d\n\n__all__ = [\n    ""BatchNorm"",\n    ""IBN"",\n    ""GhostBatchNorm"",\n    ""FrozenBatchNorm"",\n    ""SyncBatchNorm"",\n    ""get_norm"",\n]\n\n\nclass BatchNorm(nn.BatchNorm2d):\n    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight_freeze=False, bias_freeze=False, weight_init=1.0,\n                 bias_init=0.0):\n        super().__init__(num_features, eps=eps, momentum=momentum)\n        if weight_init is not None: self.weight.data.fill_(weight_init)\n        if bias_init is not None: self.bias.data.fill_(bias_init)\n        self.weight.requires_grad_(not weight_freeze)\n        self.bias.requires_grad_(not bias_freeze)\n\n\nclass SyncBatchNorm(SynchronizedBatchNorm2d):\n    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight_freeze=False, bias_freeze=False, weight_init=1.0,\n                 bias_init=0.0):\n        super().__init__(num_features, eps=eps, momentum=momentum, weight_freeze=weight_freeze, bias_freeze=bias_freeze)\n        if weight_init is not None: self.weight.data.fill_(weight_init)\n        if bias_init is not None: self.bias.data.fill_(bias_init)\n\n\nclass IBN(nn.Module):\n    def __init__(self, planes, bn_norm, num_splits):\n        super(IBN, self).__init__()\n        half1 = int(planes / 2)\n        self.half = half1\n        half2 = planes - half1\n        self.IN = nn.InstanceNorm2d(half1, affine=True)\n        self.BN = get_norm(bn_norm, half2, num_splits)\n\n    def forward(self, x):\n        split = torch.split(x, self.half, 1)\n        out1 = self.IN(split[0].contiguous())\n        out2 = self.BN(split[1].contiguous())\n        out = torch.cat((out1, out2), 1)\n        return out\n\n\nclass GhostBatchNorm(BatchNorm):\n    def __init__(self, num_features, num_splits=1, **kwargs):\n        super().__init__(num_features, **kwargs)\n        self.num_splits = num_splits\n        self.register_buffer(\'running_mean\', torch.zeros(num_features))\n        self.register_buffer(\'running_var\', torch.ones(num_features))\n\n    def forward(self, input):\n        N, C, H, W = input.shape\n        if self.training or not self.track_running_stats:\n            self.running_mean = self.running_mean.repeat(self.num_splits)\n            self.running_var = self.running_var.repeat(self.num_splits)\n            outputs = F.batch_norm(\n                input.view(-1, C * self.num_splits, H, W), self.running_mean, self.running_var,\n                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n                True, self.momentum, self.eps).view(N, C, H, W)\n            self.running_mean = torch.mean(self.running_mean.view(self.num_splits, self.num_features), dim=0)\n            self.running_var = torch.mean(self.running_var.view(self.num_splits, self.num_features), dim=0)\n            return outputs\n        else:\n            return F.batch_norm(\n                input, self.running_mean, self.running_var,\n                self.weight, self.bias, False, self.momentum, self.eps)\n\n\nclass FrozenBatchNorm(BatchNorm):\n    """"""\n    BatchNorm2d where the batch statistics and the affine parameters are fixed.\n    It contains non-trainable buffers called\n    ""weight"" and ""bias"", ""running_mean"", ""running_var"",\n    initialized to perform identity transformation.\n    The pre-trained backbone models from Caffe2 only contain ""weight"" and ""bias"",\n    which are computed from the original four parameters of BN.\n    The affine transform `x * weight + bias` will perform the equivalent\n    computation of `(x - running_mean) / sqrt(running_var) * weight + bias`.\n    When loading a backbone model from Caffe2, ""running_mean"" and ""running_var""\n    will be left unchanged as identity transformation.\n    Other pre-trained backbone models may contain all 4 parameters.\n    The forward is implemented by `F.batch_norm(..., training=False)`.\n    """"""\n\n    _version = 3\n\n    def __init__(self, num_features, eps=1e-5):\n        super().__init__(num_features, weight_freeze=True, bias_freeze=True)\n        self.num_features = num_features\n        self.eps = eps\n\n    def forward(self, x):\n        if x.requires_grad:\n            # When gradients are needed, F.batch_norm will use extra memory\n            # because its backward op computes gradients for weight/bias as well.\n            scale = self.weight * (self.running_var + self.eps).rsqrt()\n            bias = self.bias - self.running_mean * scale\n            scale = scale.reshape(1, -1, 1, 1)\n            bias = bias.reshape(1, -1, 1, 1)\n            return x * scale + bias\n        else:\n            # When gradients are not needed, F.batch_norm is a single fused op\n            # and provide more optimization opportunities.\n            return F.batch_norm(\n                x,\n                self.running_mean,\n                self.running_var,\n                self.weight,\n                self.bias,\n                training=False,\n                eps=self.eps,\n            )\n\n    def _load_from_state_dict(\n            self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs\n    ):\n        version = local_metadata.get(""version"", None)\n\n        if version is None or version < 2:\n            # No running_mean/var in early versions\n            # This will silent the warnings\n            if prefix + ""running_mean"" not in state_dict:\n                state_dict[prefix + ""running_mean""] = torch.zeros_like(self.running_mean)\n            if prefix + ""running_var"" not in state_dict:\n                state_dict[prefix + ""running_var""] = torch.ones_like(self.running_var)\n\n        if version is not None and version < 3:\n            logger = logging.getLogger(__name__)\n            logger.info(""FrozenBatchNorm {} is upgraded to version 3."".format(prefix.rstrip(""."")))\n            # In version < 3, running_var are used without +eps.\n            state_dict[prefix + ""running_var""] -= self.eps\n\n        super()._load_from_state_dict(\n            state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs\n        )\n\n    def __repr__(self):\n        return ""FrozenBatchNorm2d(num_features={}, eps={})"".format(self.num_features, self.eps)\n\n    @classmethod\n    def convert_frozen_batchnorm(cls, module):\n        """"""\n        Convert BatchNorm/SyncBatchNorm in module into FrozenBatchNorm.\n        Args:\n            module (torch.nn.Module):\n        Returns:\n            If module is BatchNorm/SyncBatchNorm, returns a new module.\n            Otherwise, in-place convert module and return it.\n        Similar to convert_sync_batchnorm in\n        https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py\n        """"""\n        bn_module = nn.modules.batchnorm\n        bn_module = (bn_module.BatchNorm2d, bn_module.SyncBatchNorm)\n        res = module\n        if isinstance(module, bn_module):\n            res = cls(module.num_features)\n            if module.affine:\n                res.weight.data = module.weight.data.clone().detach()\n                res.bias.data = module.bias.data.clone().detach()\n            res.running_mean.data = module.running_mean.data\n            res.running_var.data = module.running_var.data\n            res.eps = module.eps\n        else:\n            for name, child in module.named_children():\n                new_child = cls.convert_frozen_batchnorm(child)\n                if new_child is not child:\n                    res.add_module(name, new_child)\n        return res\n\n\ndef get_norm(norm, out_channels, num_splits=1, **kwargs):\n    """"""\n    Args:\n        norm (str or callable):\n    Returns:\n        nn.Module or None: the normalization layer\n    """"""\n    if isinstance(norm, str):\n        if len(norm) == 0:\n            return None\n        norm = {\n            ""BN"": BatchNorm(out_channels, **kwargs),\n            ""GhostBN"": GhostBatchNorm(out_channels, num_splits, **kwargs),\n            ""FrozenBN"": FrozenBatchNorm(out_channels),\n            ""GN"": nn.GroupNorm(32, out_channels),\n            ""syncBN"": SyncBatchNorm(out_channels, **kwargs),\n        }[norm]\n    return norm\n'"
fastreid/layers/circle.py,4,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\n\nfrom fastreid.utils.one_hot import one_hot\n\n\nclass Circle(nn.Module):\n    def __init__(self, cfg, in_feat, num_classes):\n        super().__init__()\n        self.in_feat = in_feat\n        self._num_classes = num_classes\n        self._s = cfg.MODEL.HEADS.SCALE\n        self._m = cfg.MODEL.HEADS.MARGIN\n\n        self.weight = Parameter(torch.Tensor(self._num_classes, in_feat))\n\n    def forward(self, features, targets):\n        sim_mat = F.linear(F.normalize(features), F.normalize(self.weight))\n        alpha_p = F.relu(-sim_mat.detach() + 1 + self._m)\n        alpha_n = F.relu(sim_mat.detach() + self._m)\n        delta_p = 1 - self._m\n        delta_n = self._m\n\n        s_p = self._s * alpha_p * (sim_mat - delta_p)\n        s_n = self._s * alpha_n * (sim_mat - delta_n)\n\n        targets = one_hot(targets, self._num_classes)\n\n        pred_class_logits = targets * s_p + (1.0 - targets) * s_n\n\n        return pred_class_logits\n\n    def extra_repr(self):\n        return \'in_features={}, num_classes={}, scale={}, margin={}\'.format(\n            self.in_feat, self._num_classes, self._s, self._m\n        )\n'"
fastreid/layers/context_block.py,2,"b""# copy from https://github.com/xvjiarui/GCNet/blob/master/mmdet/ops/gcb/context_block.py\n\nimport torch\nfrom torch import nn\n\n__all__ = ['ContextBlock']\n\n\ndef last_zero_init(m):\n    if isinstance(m, nn.Sequential):\n        nn.init.constant_(m[-1].weight, val=0)\n        if hasattr(m[-1], 'bias') and m[-1].bias is not None:\n            nn.init.constant_(m[-1].bias, 0)\n    else:\n        nn.init.constant_(m.weight, val=0)\n        if hasattr(m, 'bias') and m.bias is not None:\n            nn.init.constant_(m.bias, 0)\n\n\nclass ContextBlock(nn.Module):\n\n    def __init__(self,\n                 inplanes,\n                 ratio,\n                 pooling_type='att',\n                 fusion_types=('channel_add',)):\n        super(ContextBlock, self).__init__()\n        assert pooling_type in ['avg', 'att']\n        assert isinstance(fusion_types, (list, tuple))\n        valid_fusion_types = ['channel_add', 'channel_mul']\n        assert all([f in valid_fusion_types for f in fusion_types])\n        assert len(fusion_types) > 0, 'at least one fusion should be used'\n        self.inplanes = inplanes\n        self.ratio = ratio\n        self.planes = int(inplanes * ratio)\n        self.pooling_type = pooling_type\n        self.fusion_types = fusion_types\n        if pooling_type == 'att':\n            self.conv_mask = nn.Conv2d(inplanes, 1, kernel_size=1)\n            self.softmax = nn.Softmax(dim=2)\n        else:\n            self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        if 'channel_add' in fusion_types:\n            self.channel_add_conv = nn.Sequential(\n                nn.Conv2d(self.inplanes, self.planes, kernel_size=1),\n                nn.LayerNorm([self.planes, 1, 1]),\n                nn.ReLU(inplace=True),  # yapf: disable\n                nn.Conv2d(self.planes, self.inplanes, kernel_size=1))\n        else:\n            self.channel_add_conv = None\n        if 'channel_mul' in fusion_types:\n            self.channel_mul_conv = nn.Sequential(\n                nn.Conv2d(self.inplanes, self.planes, kernel_size=1),\n                nn.LayerNorm([self.planes, 1, 1]),\n                nn.ReLU(inplace=True),  # yapf: disable\n                nn.Conv2d(self.planes, self.inplanes, kernel_size=1))\n        else:\n            self.channel_mul_conv = None\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        if self.pooling_type == 'att':\n            nn.init.kaiming_normal_(self.conv_mask.weight, a=0, mode='fan_in', nonlinearity='relu')\n            if hasattr(self.conv_mask, 'bias') and self.conv_mask.bias is not None:\n                nn.init.constant_(self.conv_mask.bias, 0)\n            self.conv_mask.inited = True\n\n        if self.channel_add_conv is not None:\n            last_zero_init(self.channel_add_conv)\n        if self.channel_mul_conv is not None:\n            last_zero_init(self.channel_mul_conv)\n\n    def spatial_pool(self, x):\n        batch, channel, height, width = x.size()\n        if self.pooling_type == 'att':\n            input_x = x\n            # [N, C, H * W]\n            input_x = input_x.view(batch, channel, height * width)\n            # [N, 1, C, H * W]\n            input_x = input_x.unsqueeze(1)\n            # [N, 1, H, W]\n            context_mask = self.conv_mask(x)\n            # [N, 1, H * W]\n            context_mask = context_mask.view(batch, 1, height * width)\n            # [N, 1, H * W]\n            context_mask = self.softmax(context_mask)\n            # [N, 1, H * W, 1]\n            context_mask = context_mask.unsqueeze(-1)\n            # [N, 1, C, 1]\n            context = torch.matmul(input_x, context_mask)\n            # [N, C, 1, 1]\n            context = context.view(batch, channel, 1, 1)\n        else:\n            # [N, C, 1, 1]\n            context = self.avg_pool(x)\n\n        return context\n\n    def forward(self, x):\n        # [N, C, 1, 1]\n        context = self.spatial_pool(x)\n\n        out = x\n        if self.channel_mul_conv is not None:\n            # [N, C, 1, 1]\n            channel_mul_term = torch.sigmoid(self.channel_mul_conv(context))\n            out = out * channel_mul_term\n        if self.channel_add_conv is not None:\n            # [N, C, 1, 1]\n            channel_add_term = self.channel_add_conv(context)\n            out = out + channel_add_term\n\n        return out\n"""
fastreid/layers/frn.py,11,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nfrom torch import nn\nfrom torch.nn.modules.batchnorm import BatchNorm2d\nfrom torch.nn import ReLU, LeakyReLU\nfrom torch.nn.parameter import Parameter\n\n\nclass TLU(nn.Module):\n    def __init__(self, num_features):\n        """"""max(y, tau) = max(y - tau, 0) + tau = ReLU(y - tau) + tau""""""\n        super(TLU, self).__init__()\n        self.num_features = num_features\n        self.tau = Parameter(torch.Tensor(num_features))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.zeros_(self.tau)\n\n    def extra_repr(self):\n        return \'num_features={num_features}\'.format(**self.__dict__)\n\n    def forward(self, x):\n        return torch.max(x, self.tau.view(1, self.num_features, 1, 1))\n\n\nclass FRN(nn.Module):\n    def __init__(self, num_features, eps=1e-6, is_eps_leanable=False):\n        """"""\n        weight = gamma, bias = beta\n        beta, gamma:\n            Variables of shape [1, 1, 1, C]. if TensorFlow\n            Variables of shape [1, C, 1, 1]. if PyTorch\n        eps: A scalar constant or learnable variable.\n        """"""\n        super(FRN, self).__init__()\n\n        self.num_features = num_features\n        self.init_eps = eps\n        self.is_eps_leanable = is_eps_leanable\n\n        self.weight = Parameter(torch.Tensor(num_features))\n        self.bias = Parameter(torch.Tensor(num_features))\n        if is_eps_leanable:\n            self.eps = Parameter(torch.Tensor(1))\n        else:\n            self.register_buffer(\'eps\', torch.Tensor([eps]))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.ones_(self.weight)\n        nn.init.zeros_(self.bias)\n        if self.is_eps_leanable:\n            nn.init.constant_(self.eps, self.init_eps)\n\n    def extra_repr(self):\n        return \'num_features={num_features}, eps={init_eps}\'.format(**self.__dict__)\n\n    def forward(self, x):\n        """"""\n        0, 1, 2, 3 -> (B, H, W, C) in TensorFlow\n        0, 1, 2, 3 -> (B, C, H, W) in PyTorch\n        TensorFlow code\n            nu2 = tf.reduce_mean(tf.square(x), axis=[1, 2], keepdims=True)\n            x = x * tf.rsqrt(nu2 + tf.abs(eps))\n            # This Code include TLU function max(y, tau)\n            return tf.maximum(gamma * x + beta, tau)\n        """"""\n        # Compute the mean norm of activations per channel.\n        nu2 = x.pow(2).mean(dim=[2, 3], keepdim=True)\n\n        # Perform FRN.\n        x = x * torch.rsqrt(nu2 + self.eps.abs())\n\n        # Scale and Bias\n        x = self.weight.view(1, self.num_features, 1, 1) * x + self.bias.view(1, self.num_features, 1, 1)\n        # x = self.weight * x + self.bias\n        return x\n\n\ndef bnrelu_to_frn(module):\n    """"""\n    Convert \'BatchNorm2d + ReLU\' to \'FRN + TLU\'\n    """"""\n    mod = module\n    before_name = None\n    before_child = None\n    is_before_bn = False\n\n    for name, child in module.named_children():\n        if is_before_bn and isinstance(child, (ReLU, LeakyReLU)):\n            # Convert BN to FRN\n            if isinstance(before_child, BatchNorm2d):\n                mod.add_module(\n                    before_name, FRN(num_features=before_child.num_features))\n            else:\n                raise NotImplementedError()\n\n            # Convert ReLU to TLU\n            mod.add_module(name, TLU(num_features=before_child.num_features))\n        else:\n            mod.add_module(name, bnrelu_to_frn(child))\n\n        before_name = name\n        before_child = child\n        is_before_bn = isinstance(child, BatchNorm2d)\n    return mod\n\n\ndef convert(module, flag_name):\n    mod = module\n    before_ch = None\n    for name, child in module.named_children():\n        if hasattr(child, flag_name) and getattr(child, flag_name):\n            if isinstance(child, BatchNorm2d):\n                before_ch = child.num_features\n                mod.add_module(name, FRN(num_features=child.num_features))\n            # TODO bn is no good...\n            if isinstance(child, (ReLU, LeakyReLU)):\n                mod.add_module(name, TLU(num_features=before_ch))\n        else:\n            mod.add_module(name, convert(child, flag_name))\n    return mod\n\n\ndef remove_flags(module, flag_name):\n    mod = module\n    for name, child in module.named_children():\n        if hasattr(child, \'is_convert_frn\'):\n            delattr(child, flag_name)\n            mod.add_module(name, remove_flags(child, flag_name))\n        else:\n            mod.add_module(name, remove_flags(child, flag_name))\n    return mod\n\n\ndef bnrelu_to_frn2(model, input_size=(3, 128, 128), batch_size=2, flag_name=\'is_convert_frn\'):\n    forard_hooks = list()\n    backward_hooks = list()\n\n    is_before_bn = [False]\n\n    def register_forward_hook(module):\n        def hook(self, input, output):\n            if isinstance(module, (nn.Sequential, nn.ModuleList)) or (module == model):\n                is_before_bn.append(False)\n                return\n\n            # input and output is required in hook def\n            is_converted = is_before_bn[-1] and isinstance(self, (ReLU, LeakyReLU))\n            if is_converted:\n                setattr(self, flag_name, True)\n            is_before_bn.append(isinstance(self, BatchNorm2d))\n\n        forard_hooks.append(module.register_forward_hook(hook))\n\n    is_before_relu = [False]\n\n    def register_backward_hook(module):\n        def hook(self, input, output):\n            if isinstance(module, (nn.Sequential, nn.ModuleList)) or (module == model):\n                is_before_relu.append(False)\n                return\n            is_converted = is_before_relu[-1] and isinstance(self, BatchNorm2d)\n            if is_converted:\n                setattr(self, flag_name, True)\n            is_before_relu.append(isinstance(self, (ReLU, LeakyReLU)))\n\n        backward_hooks.append(module.register_backward_hook(hook))\n\n    # multiple inputs to the network\n    if isinstance(input_size, tuple):\n        input_size = [input_size]\n\n    # batch_size of 2 for batchnorm\n    x = [torch.rand(batch_size, *in_size) for in_size in input_size]\n\n    # register hook\n    model.apply(register_forward_hook)\n    model.apply(register_backward_hook)\n\n    # make a forward pass\n    output = model(*x)\n    output.sum().backward()  # Raw output is not enabled to use backward()\n\n    # remove these hooks\n    for h in forard_hooks:\n        h.remove()\n    for h in backward_hooks:\n        h.remove()\n\n    model = convert(model, flag_name=flag_name)\n    model = remove_flags(model, flag_name=flag_name)\n    return model\n'"
fastreid/layers/gem_pool.py,3,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\n\n\nclass GeneralizedMeanPooling(nn.Module):\n    r""""""Applies a 2D power-average adaptive pooling over an input signal composed of several input planes.\n    The function computed is: :math:`f(X) = pow(sum(pow(X, p)), 1/p)`\n        - At p = infinity, one gets Max Pooling\n        - At p = 1, one gets Average Pooling\n    The output is of size H x W, for any input size.\n    The number of output features is equal to the number of input planes.\n    Args:\n        output_size: the target output size of the image of the form H x W.\n                     Can be a tuple (H, W) or a single H for a square image H x H\n                     H and W can be either a ``int``, or ``None`` which means the size will\n                     be the same as that of the input.\n    """"""\n\n    def __init__(self, norm, output_size=1, eps=1e-6):\n        super(GeneralizedMeanPooling, self).__init__()\n        assert norm > 0\n        self.p = float(norm)\n        self.output_size = output_size\n        self.eps = eps\n\n    def forward(self, x):\n        x = x.clamp(min=self.eps).pow(self.p)\n        return torch.nn.functional.adaptive_avg_pool2d(x, self.output_size).pow(1. / self.p)\n\n    def __repr__(self):\n        return self.__class__.__name__ + \'(\' \\\n               + str(self.p) + \', \' \\\n               + \'output_size=\' + str(self.output_size) + \')\'\n\n\nclass GeneralizedMeanPoolingP(GeneralizedMeanPooling):\n    """""" Same, but norm is trainable\n    """"""\n\n    def __init__(self, norm=3, output_size=1, eps=1e-6):\n        super(GeneralizedMeanPoolingP, self).__init__(norm, output_size, eps)\n        self.p = nn.Parameter(torch.ones(1) * norm)\n\n\nclass AdaptiveAvgMaxPool2d(nn.Module):\n    def __init__(self, output_size):\n        super(AdaptiveAvgMaxPool2d, self).__init__()\n        self.output_size = output_size\n\n    def forward(self, x):\n        x_max = F.adaptive_avg_pool2d(x, self.output_size)\n        x_avg = F.adaptive_max_pool2d(x, self.output_size)\n        x = x_max + x_avg\n        return x\n\n'"
fastreid/layers/non_local.py,2,"b""# encoding: utf-8\n\n\nimport torch\nfrom torch import nn\nfrom .batch_norm import get_norm\n\n\nclass Non_local(nn.Module):\n    def __init__(self, in_channels, bn_norm, num_splits, reduc_ratio=2):\n        super(Non_local, self).__init__()\n\n        self.in_channels = in_channels\n        self.inter_channels = reduc_ratio // reduc_ratio\n\n        self.g = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n                           kernel_size=1, stride=1, padding=0)\n\n        self.W = nn.Sequential(\n            nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels,\n                      kernel_size=1, stride=1, padding=0),\n            get_norm(bn_norm, self.in_channels, num_splits),\n        )\n        nn.init.constant_(self.W[1].weight, 0.0)\n        nn.init.constant_(self.W[1].bias, 0.0)\n\n        self.theta = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n                               kernel_size=1, stride=1, padding=0)\n\n        self.phi = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n                             kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n        '''\n                :param x: (b, t, h, w)\n                :return x: (b, t, h, w)\n        '''\n        batch_size = x.size(0)\n        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n        g_x = g_x.permute(0, 2, 1)\n\n        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n        theta_x = theta_x.permute(0, 2, 1)\n        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n        f = torch.matmul(theta_x, phi_x)\n        N = f.size(-1)\n        f_div_C = f / N\n\n        y = torch.matmul(f_div_C, g_x)\n        y = y.permute(0, 2, 1).contiguous()\n        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n        W_y = self.W(y)\n        z = W_y + x\n        return z\n"""
fastreid/layers/se_layer.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom torch import nn\n\n\nclass SELayer(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, int(channel / reduction), bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(int(channel / reduction), channel, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n'"
fastreid/layers/splat.py,6,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.nn import Conv2d, ReLU\nfrom torch.nn.modules.utils import _pair\nfrom fastreid.layers import get_norm\n\n\nclass SplAtConv2d(nn.Module):\n    """"""Split-Attention Conv2d\n    """"""\n\n    def __init__(self, in_channels, channels, kernel_size, stride=(1, 1), padding=(0, 0),\n                 dilation=(1, 1), groups=1, bias=True,\n                 radix=2, reduction_factor=4,\n                 rectify=False, rectify_avg=False, norm_layer=None, num_splits=1,\n                 dropblock_prob=0.0, **kwargs):\n        super(SplAtConv2d, self).__init__()\n        padding = _pair(padding)\n        self.rectify = rectify and (padding[0] > 0 or padding[1] > 0)\n        self.rectify_avg = rectify_avg\n        inter_channels = max(in_channels * radix // reduction_factor, 32)\n        self.radix = radix\n        self.cardinality = groups\n        self.channels = channels\n        self.dropblock_prob = dropblock_prob\n        if self.rectify:\n            from rfconv import RFConv2d\n            self.conv = RFConv2d(in_channels, channels * radix, kernel_size, stride, padding, dilation,\n                                 groups=groups * radix, bias=bias, average_mode=rectify_avg, **kwargs)\n        else:\n            self.conv = Conv2d(in_channels, channels * radix, kernel_size, stride, padding, dilation,\n                               groups=groups * radix, bias=bias, **kwargs)\n        self.use_bn = norm_layer is not None\n        if self.use_bn:\n            self.bn0 = get_norm(norm_layer, channels * radix, num_splits)\n        self.relu = ReLU(inplace=True)\n        self.fc1 = Conv2d(channels, inter_channels, 1, groups=self.cardinality)\n        if self.use_bn:\n            self.bn1 = get_norm(norm_layer, inter_channels, num_splits)\n        self.fc2 = Conv2d(inter_channels, channels * radix, 1, groups=self.cardinality)\n\n        self.rsoftmax = rSoftMax(radix, groups)\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.use_bn:\n            x = self.bn0(x)\n        if self.dropblock_prob > 0.0:\n            x = self.dropblock(x)\n        x = self.relu(x)\n\n        batch, rchannel = x.shape[:2]\n        if self.radix > 1:\n            splited = torch.split(x, rchannel // self.radix, dim=1)\n            gap = sum(splited)\n        else:\n            gap = x\n        gap = F.adaptive_avg_pool2d(gap, 1)\n        gap = self.fc1(gap)\n\n        if self.use_bn:\n            gap = self.bn1(gap)\n        gap = self.relu(gap)\n\n        atten = self.fc2(gap)\n        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)\n\n        if self.radix > 1:\n            attens = torch.split(atten, rchannel // self.radix, dim=1)\n            out = sum([att * split for (att, split) in zip(attens, splited)])\n        else:\n            out = atten * x\n        return out.contiguous()\n\n\nclass rSoftMax(nn.Module):\n    def __init__(self, radix, cardinality):\n        super().__init__()\n        self.radix = radix\n        self.cardinality = cardinality\n\n    def forward(self, x):\n        batch = x.size(0)\n        if self.radix > 1:\n            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n            x = F.softmax(x, dim=1)\n            x = x.reshape(batch, -1)\n        else:\n            x = torch.sigmoid(x)\n        return x\n'"
fastreid/modeling/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom .meta_arch import build_model\n'"
fastreid/solver/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\n\nfrom .build import build_lr_scheduler, build_optimizer'"
fastreid/solver/build.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom . import lr_scheduler\nfrom . import optim\n\n\ndef build_optimizer(cfg, model):\n    params = []\n    for key, value in model.named_parameters():\n        if not value.requires_grad:\n            continue\n        lr = cfg.SOLVER.BASE_LR\n        weight_decay = cfg.SOLVER.WEIGHT_DECAY\n        if ""heads"" in key:\n            lr *= cfg.SOLVER.HEADS_LR_FACTOR\n        if ""bias"" in key:\n            lr *= cfg.SOLVER.BIAS_LR_FACTOR\n            weight_decay = cfg.SOLVER.WEIGHT_DECAY_BIAS\n        params += [{""params"": [value], ""lr"": lr, ""weight_decay"": weight_decay}]\n\n    solver_opt = cfg.SOLVER.OPT\n    if hasattr(optim, solver_opt):\n        if solver_opt == ""SGD"":\n            opt_fns = getattr(optim, solver_opt)(params, momentum=cfg.SOLVER.MOMENTUM)\n        else:\n            opt_fns = getattr(optim, solver_opt)(params)\n    else:\n        raise NameError(""optimizer {} not support"".format(cfg.SOLVER.OPT))\n    return opt_fns\n\n\ndef build_lr_scheduler(cfg, optimizer):\n    scheduler_args = {\n        ""optimizer"": optimizer,\n\n        # warmup options\n        ""warmup_factor"": cfg.SOLVER.WARMUP_FACTOR,\n        ""warmup_iters"": cfg.SOLVER.WARMUP_ITERS,\n        ""warmup_method"": cfg.SOLVER.WARMUP_METHOD,\n\n        # multi-step lr scheduler options\n        ""milestones"": cfg.SOLVER.STEPS,\n        ""gamma"": cfg.SOLVER.GAMMA,\n\n        # cosine annealing lr scheduler options\n        ""max_iters"": cfg.SOLVER.MAX_ITER,\n        ""delay_iters"": cfg.SOLVER.DELAY_ITERS,\n        ""eta_min_lr"": cfg.SOLVER.ETA_MIN_LR,\n\n    }\n    return getattr(lr_scheduler, cfg.SOLVER.SCHED)(**scheduler_args)\n'"
fastreid/solver/lr_scheduler.py,2,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom bisect import bisect_right\nfrom typing import List\n\nimport torch\nfrom torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR\n\n__all__ = [""WarmupMultiStepLR"", ""DelayedScheduler""]\n\n\nclass WarmupMultiStepLR(_LRScheduler):\n    def __init__(\n            self,\n            optimizer: torch.optim.Optimizer,\n            milestones: List[int],\n            gamma: float = 0.1,\n            warmup_factor: float = 0.001,\n            warmup_iters: int = 1000,\n            warmup_method: str = ""linear"",\n            last_epoch: int = -1,\n            **kwargs,\n    ):\n        if not list(milestones) == sorted(milestones):\n            raise ValueError(\n                ""Milestones should be a list of"" "" increasing integers. Got {}"", milestones\n            )\n        self.milestones = milestones\n        self.gamma = gamma\n        self.warmup_factor = warmup_factor\n        self.warmup_iters = warmup_iters\n        self.warmup_method = warmup_method\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self) -> List[float]:\n        warmup_factor = _get_warmup_factor_at_iter(\n            self.warmup_method, self.last_epoch, self.warmup_iters, self.warmup_factor\n        )\n        return [\n            base_lr * warmup_factor * self.gamma ** bisect_right(self.milestones, self.last_epoch)\n            for base_lr in self.base_lrs\n        ]\n\n    def _compute_values(self) -> List[float]:\n        # The new interface\n        return self.get_lr()\n\n\ndef _get_warmup_factor_at_iter(\n        method: str, iter: int, warmup_iters: int, warmup_factor: float\n) -> float:\n    """"""\n    Return the learning rate warmup factor at a specific iteration.\n    See https://arxiv.org/abs/1706.02677 for more details.\n    Args:\n        method (str): warmup method; either ""constant"" or ""linear"".\n        iter (int): iteration at which to calculate the warmup factor.\n        warmup_iters (int): the number of warmup iterations.\n        warmup_factor (float): the base warmup factor (the meaning changes according\n            to the method used).\n    Returns:\n        float: the effective warmup factor at the given iteration.\n    """"""\n    if iter >= warmup_iters:\n        return 1.0\n\n    if method == ""constant"":\n        return warmup_factor\n    elif method == ""linear"":\n        alpha = iter / warmup_iters\n        return warmup_factor * (1 - alpha) + alpha\n    else:\n        raise ValueError(""Unknown warmup method: {}"".format(method))\n\n\nclass DelayedScheduler(_LRScheduler):\n    """""" Starts with a flat lr schedule until it reaches N epochs the applies a scheduler\n    Args:\n        optimizer (Optimizer): Wrapped optimizer.\n        delay_iters: number of epochs to keep the initial lr until starting applying the scheduler\n        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n    """"""\n\n    def __init__(self, optimizer, delay_iters, after_scheduler, warmup_factor, warmup_iters, warmup_method):\n        self.delay_epochs = delay_iters\n        self.after_scheduler = after_scheduler\n        self.finished = False\n        self.warmup_factor = warmup_factor\n        self.warmup_iters = warmup_iters\n        self.warmup_method = warmup_method\n        super().__init__(optimizer)\n\n    def get_lr(self):\n        if self.last_epoch >= self.delay_epochs:\n            if not self.finished:\n                self.after_scheduler.base_lrs = self.base_lrs\n                self.finished = True\n            return self.after_scheduler.get_lr()\n\n        warmup_factor = _get_warmup_factor_at_iter(\n            self.warmup_method, self.last_epoch, self.warmup_iters, self.warmup_factor\n        )\n        return [base_lr * warmup_factor for base_lr in self.base_lrs]\n\n    def step(self, epoch=None):\n        if self.finished:\n            if epoch is None:\n                self.after_scheduler.step(None)\n            else:\n                self.after_scheduler.step(epoch - self.delay_epochs)\n        else:\n            return super(DelayedScheduler, self).step(epoch)\n\n\ndef DelayedCosineAnnealingLR(optimizer, delay_iters, max_iters, eta_min_lr, warmup_factor,\n                             warmup_iters, warmup_method, **kwargs, ):\n    cosine_annealing_iters = max_iters - delay_iters\n    base_scheduler = CosineAnnealingLR(optimizer, cosine_annealing_iters, eta_min_lr)\n    return DelayedScheduler(optimizer, delay_iters, base_scheduler, warmup_factor, warmup_iters, warmup_method)\n'"
fastreid/utils/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\n'"
fastreid/utils/checkpoint.py,9,"b'#!/usr/bin/env python3\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n\nimport collections\nimport copy\nimport logging\nimport os\nfrom collections import defaultdict\nfrom typing import Any\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom termcolor import colored\nfrom torch.nn.parallel import DataParallel, DistributedDataParallel\n\nfrom fastreid.utils.file_io import PathManager\n\n\nclass Checkpointer(object):\n    """"""\n    A checkpointer that can save/load model as well as extra checkpointable\n    objects.\n    """"""\n\n    def __init__(\n            self,\n            model: nn.Module,\n            dataset: Dataset = None,\n            save_dir: str = """",\n            *,\n            save_to_disk: bool = True,\n            **checkpointables: object,\n    ):\n        """"""\n        Args:\n            model (nn.Module): model.\n            save_dir (str): a directory to save and find checkpoints.\n            save_to_disk (bool): if True, save checkpoint to disk, otherwise\n                disable saving for this checkpointer.\n            checkpointables (object): any checkpointable objects, i.e., objects\n                that have the `state_dict()` and `load_state_dict()` method. For\n                example, it can be used like\n                `Checkpointer(model, ""dir"", optimizer=optimizer)`.\n        """"""\n        if isinstance(model, (DistributedDataParallel, DataParallel)):\n            model = model.module\n        self.model = model\n        self.dataset = dataset\n        self.checkpointables = copy.copy(checkpointables)\n        self.logger = logging.getLogger(__name__)\n        self.save_dir = save_dir\n        self.save_to_disk = save_to_disk\n\n    def save(self, name: str, **kwargs: dict):\n        """"""\n        Dump model and checkpointables to a file.\n        Args:\n            name (str): name of the file.\n            kwargs (dict): extra arbitrary data to save.\n        """"""\n        if not self.save_dir or not self.save_to_disk:\n            return\n\n        data = {}\n        data[""model""] = self.model.state_dict()\n        if self.dataset is not None:\n            data[""pid_dict""] = self.dataset.pid_dict\n        for key, obj in self.checkpointables.items():\n            data[key] = obj.state_dict()\n        data.update(kwargs)\n\n        basename = ""{}.pth"".format(name)\n        save_file = os.path.join(self.save_dir, basename)\n        assert os.path.basename(save_file) == basename, basename\n        self.logger.info(""Saving checkpoint to {}"".format(save_file))\n        with PathManager.open(save_file, ""wb"") as f:\n            torch.save(data, f)\n        self.tag_last_checkpoint(basename)\n\n    def load(self, path: str):\n        """"""\n        Load from the given checkpoint. When path points to network file, this\n        function has to be called on all ranks.\n        Args:\n            path (str): path or url to the checkpoint. If empty, will not load\n                anything.\n        Returns:\n            dict:\n                extra data loaded from the checkpoint that has not been\n                processed. For example, those saved with\n                :meth:`.save(**extra_data)`.\n        """"""\n        if not path:\n            # no checkpoint provided\n            self.logger.info(\n                ""No checkpoint found. Initializing model from scratch""\n            )\n            return {}\n        self.logger.info(""Loading checkpoint from {}"".format(path))\n        if not os.path.isfile(path):\n            path = PathManager.get_local_path(path)\n            assert os.path.isfile(path), ""Checkpoint {} not found!"".format(path)\n\n        checkpoint = self._load_file(path)\n        if self.dataset is not None:\n            self.logger.info(""Loading dataset pid dictionary from {}"".format(path))\n            self._load_dataset_pid_dict(checkpoint)\n        self._load_model(checkpoint)\n        for key, obj in self.checkpointables.items():\n            if key in checkpoint:\n                self.logger.info(""Loading {} from {}"".format(key, path))\n                obj.load_state_dict(checkpoint.pop(key))\n\n        # return any further checkpoint data\n        return checkpoint\n\n    def has_checkpoint(self):\n        """"""\n        Returns:\n            bool: whether a checkpoint exists in the target directory.\n        """"""\n        save_file = os.path.join(self.save_dir, ""last_checkpoint"")\n        return PathManager.exists(save_file)\n\n    def get_checkpoint_file(self):\n        """"""\n        Returns:\n            str: The latest checkpoint file in target directory.\n        """"""\n        save_file = os.path.join(self.save_dir, ""last_checkpoint"")\n        try:\n            with PathManager.open(save_file, ""r"") as f:\n                last_saved = f.read().strip()\n        except IOError:\n            # if file doesn\'t exist, maybe because it has just been\n            # deleted by a separate process\n            return """"\n        return os.path.join(self.save_dir, last_saved)\n\n    def get_all_checkpoint_files(self):\n        """"""\n        Returns:\n            list: All available checkpoint files (.pth files) in target\n                directory.\n        """"""\n        all_model_checkpoints = [\n            os.path.join(self.save_dir, file)\n            for file in PathManager.ls(self.save_dir)\n            if PathManager.isfile(os.path.join(self.save_dir, file))\n               and file.endswith("".pth"")\n        ]\n        return all_model_checkpoints\n\n    def resume_or_load(self, path: str, *, resume: bool = True):\n        """"""\n        If `resume` is True, this method attempts to resume from the last\n        checkpoint, if exists. Otherwise, load checkpoint from the given path.\n        This is useful when restarting an interrupted training job.\n        Args:\n            path (str): path to the checkpoint.\n            resume (bool): if True, resume from the last checkpoint if it exists.\n        Returns:\n            same as :meth:`load`.\n        """"""\n        if resume and self.has_checkpoint():\n            path = self.get_checkpoint_file()\n        return self.load(path)\n\n    def tag_last_checkpoint(self, last_filename_basename: str):\n        """"""\n        Tag the last checkpoint.\n        Args:\n            last_filename_basename (str): the basename of the last filename.\n        """"""\n        save_file = os.path.join(self.save_dir, ""last_checkpoint"")\n        with PathManager.open(save_file, ""w"") as f:\n            f.write(last_filename_basename)\n\n    def _load_file(self, f: str):\n        """"""\n        Load a checkpoint file. Can be overwritten by subclasses to support\n        different formats.\n        Args:\n            f (str): a locally mounted file path.\n        Returns:\n            dict: with keys ""model"" and optionally others that are saved by\n                the checkpointer dict[""model""] must be a dict which maps strings\n                to torch.Tensor or numpy arrays.\n        """"""\n        return torch.load(f, map_location=torch.device(""cpu""))\n\n    def _load_dataset_pid_dict(self, checkpoint: Any):\n        checkpoint_pid_dict = checkpoint.pop(""pid_dict"")\n        self.dataset.update_pid_dict(checkpoint_pid_dict)\n\n    def _load_model(self, checkpoint: Any):\n        """"""\n        Load weights from a checkpoint.\n        Args:\n            checkpoint (Any): checkpoint contains the weights.\n        """"""\n        checkpoint_state_dict = checkpoint.pop(""model"")\n        self._convert_ndarray_to_tensor(checkpoint_state_dict)\n\n        # if the state_dict comes from a model that was wrapped in a\n        # DataParallel or DistributedDataParallel during serialization,\n        # remove the ""module"" prefix before performing the matching.\n        _strip_prefix_if_present(checkpoint_state_dict, ""module."")\n\n        # work around https://github.com/pytorch/pytorch/issues/24139\n        model_state_dict = self.model.state_dict()\n        for k in list(checkpoint_state_dict.keys()):\n            if k in model_state_dict:\n                shape_model = tuple(model_state_dict[k].shape)\n                shape_checkpoint = tuple(checkpoint_state_dict[k].shape)\n                if shape_model != shape_checkpoint:\n                    self.logger.warning(\n                        ""\'{}\' has shape {} in the checkpoint but {} in the ""\n                        ""model! Skipped."".format(\n                            k, shape_checkpoint, shape_model\n                        )\n                    )\n                    checkpoint_state_dict.pop(k)\n\n        incompatible = self.model.load_state_dict(\n            checkpoint_state_dict, strict=False\n        )\n        if incompatible.missing_keys:\n            self.logger.info(\n                get_missing_parameters_message(incompatible.missing_keys)\n            )\n        if incompatible.unexpected_keys:\n            self.logger.info(\n                get_unexpected_parameters_message(incompatible.unexpected_keys)\n            )\n\n    def _convert_ndarray_to_tensor(self, state_dict: dict):\n        """"""\n        In-place convert all numpy arrays in the state_dict to torch tensor.\n        Args:\n            state_dict (dict): a state-dict to be loaded to the model.\n        """"""\n        # model could be an OrderedDict with _metadata attribute\n        # (as returned by Pytorch\'s state_dict()). We should preserve these\n        # properties.\n        for k in list(state_dict.keys()):\n            v = state_dict[k]\n            if not isinstance(v, np.ndarray) and not isinstance(\n                    v, torch.Tensor\n            ):\n                raise ValueError(\n                    ""Unsupported type found in checkpoint! {}: {}"".format(\n                        k, type(v)\n                    )\n                )\n            if not isinstance(v, torch.Tensor):\n                state_dict[k] = torch.from_numpy(v)\n\n\nclass PeriodicCheckpointer:\n    """"""\n    Save checkpoints periodically. When `.step(iteration)` is called, it will\n    execute `checkpointer.save` on the given checkpointer, if iteration is a\n    multiple of period or if `max_iter` is reached.\n    """"""\n\n    def __init__(self, checkpointer: Any, period: int, max_iter: int = None):\n        """"""\n        Args:\n            checkpointer (Any): the checkpointer object used to save\n            checkpoints.\n            period (int): the period to save checkpoint.\n            max_iter (int): maximum number of iterations. When it is reached,\n                a checkpoint named ""model_final"" will be saved.\n        """"""\n        self.checkpointer = checkpointer\n        self.period = int(period)\n        self.max_iter = max_iter\n\n    def step(self, iteration: int, **kwargs: Any):\n        """"""\n        Perform the appropriate action at the given iteration.\n        Args:\n            iteration (int): the current iteration, ranged in [0, max_iter-1].\n            kwargs (Any): extra data to save, same as in\n                :meth:`Checkpointer.save`.\n        """"""\n        iteration = int(iteration)\n        additional_state = {""iteration"": iteration}\n        additional_state.update(kwargs)\n        if (iteration + 1) % self.period == 0:\n            self.checkpointer.save(\n                ""model_{:07d}"".format(iteration), **additional_state\n            )\n        if iteration >= self.max_iter - 1:\n            self.checkpointer.save(""model_final"", **additional_state)\n\n    def save(self, name: str, **kwargs: Any):\n        """"""\n        Same argument as :meth:`Checkpointer.save`.\n        Use this method to manually save checkpoints outside the schedule.\n        Args:\n            name (str): file name.\n            kwargs (Any): extra data to save, same as in\n                :meth:`Checkpointer.save`.\n        """"""\n        self.checkpointer.save(name, **kwargs)\n\n\ndef get_missing_parameters_message(keys: list):\n    """"""\n    Get a logging-friendly message to report parameter names (keys) that are in\n    the model but not found in a checkpoint.\n    Args:\n        keys (list[str]): List of keys that were not found in the checkpoint.\n    Returns:\n        str: message.\n    """"""\n    groups = _group_checkpoint_keys(keys)\n    msg = ""Some model parameters are not in the checkpoint:\\n""\n    msg += ""\\n"".join(\n        ""  "" + colored(k + _group_to_str(v), ""blue"") for k, v in groups.items()\n    )\n    return msg\n\n\ndef get_unexpected_parameters_message(keys: list):\n    """"""\n    Get a logging-friendly message to report parameter names (keys) that are in\n    the checkpoint but not found in the model.\n    Args:\n        keys (list[str]): List of keys that were not found in the model.\n    Returns:\n        str: message.\n    """"""\n    groups = _group_checkpoint_keys(keys)\n    msg = ""The checkpoint contains parameters not used by the model:\\n""\n    msg += ""\\n"".join(\n        ""  "" + colored(k + _group_to_str(v), ""magenta"")\n        for k, v in groups.items()\n    )\n    return msg\n\n\ndef _strip_prefix_if_present(state_dict: collections.OrderedDict, prefix: str):\n    """"""\n    Strip the prefix in metadata, if any.\n    Args:\n        state_dict (OrderedDict): a state-dict to be loaded to the model.\n        prefix (str): prefix.\n    """"""\n    keys = sorted(state_dict.keys())\n    if not all(len(key) == 0 or key.startswith(prefix) for key in keys):\n        return\n\n    for key in keys:\n        newkey = key[len(prefix):]\n        state_dict[newkey] = state_dict.pop(key)\n\n    # also strip the prefix in metadata, if any..\n    try:\n        metadata = state_dict._metadata\n    except AttributeError:\n        pass\n    else:\n        for key in list(metadata.keys()):\n            # for the metadata dict, the key can be:\n            # \'\': for the DDP module, which we want to remove.\n            # \'module\': for the actual model.\n            # \'module.xx.xx\': for the rest.\n\n            if len(key) == 0:\n                continue\n            newkey = key[len(prefix):]\n            metadata[newkey] = metadata.pop(key)\n\n\ndef _group_checkpoint_keys(keys: list):\n    """"""\n    Group keys based on common prefixes. A prefix is the string up to the final\n    ""."" in each key.\n    Args:\n        keys (list[str]): list of parameter names, i.e. keys in the model\n            checkpoint dict.\n    Returns:\n        dict[list]: keys with common prefixes are grouped into lists.\n    """"""\n    groups = defaultdict(list)\n    for key in keys:\n        pos = key.rfind(""."")\n        if pos >= 0:\n            head, tail = key[:pos], [key[pos + 1:]]\n        else:\n            head, tail = key, []\n        groups[head].extend(tail)\n    return groups\n\n\ndef _group_to_str(group: list):\n    """"""\n    Format a group of parameter name suffixes into a loggable string.\n    Args:\n        group (list[str]): list of parameter name suffixes.\n    Returns:\n        str: formated string.\n    """"""\n    if len(group) == 0:\n        return """"\n\n    if len(group) == 1:\n        return ""."" + group[0]\n\n    return "".{"" + "", "".join(group) + ""}""\n'"
fastreid/utils/comm.py,12,"b'""""""\nThis file contains primitives for multi-gpu communication.\nThis is useful when doing distributed training.\n""""""\n\nimport functools\nimport logging\nimport numpy as np\nimport pickle\nimport torch\nimport torch.distributed as dist\n\n_LOCAL_PROCESS_GROUP = None\n""""""\nA torch process group which only includes processes that on the same machine as the current process.\nThis variable is set when processes are spawned by `launch()` in ""engine/launch.py"".\n""""""\n\n\ndef get_world_size() -> int:\n    if not dist.is_available():\n        return 1\n    if not dist.is_initialized():\n        return 1\n    return dist.get_world_size()\n\n\ndef get_rank() -> int:\n    if not dist.is_available():\n        return 0\n    if not dist.is_initialized():\n        return 0\n    return dist.get_rank()\n\n\ndef get_local_rank() -> int:\n    """"""\n    Returns:\n        The rank of the current process within the local (per-machine) process group.\n    """"""\n    if not dist.is_available():\n        return 0\n    if not dist.is_initialized():\n        return 0\n    assert _LOCAL_PROCESS_GROUP is not None\n    return dist.get_rank(group=_LOCAL_PROCESS_GROUP)\n\n\ndef get_local_size() -> int:\n    """"""\n    Returns:\n        The size of the per-machine process group,\n        i.e. the number of processes per machine.\n    """"""\n    if not dist.is_available():\n        return 1\n    if not dist.is_initialized():\n        return 1\n    return dist.get_world_size(group=_LOCAL_PROCESS_GROUP)\n\n\ndef is_main_process() -> bool:\n    return get_rank() == 0\n\n\ndef synchronize():\n    """"""\n    Helper function to synchronize (barrier) among all processes when\n    using distributed training\n    """"""\n    if not dist.is_available():\n        return\n    if not dist.is_initialized():\n        return\n    world_size = dist.get_world_size()\n    if world_size == 1:\n        return\n    dist.barrier()\n\n\n@functools.lru_cache()\ndef _get_global_gloo_group():\n    """"""\n    Return a process group based on gloo backend, containing all the ranks\n    The result is cached.\n    """"""\n    if dist.get_backend() == ""nccl"":\n        return dist.new_group(backend=""gloo"")\n    else:\n        return dist.group.WORLD\n\n\ndef _serialize_to_tensor(data, group):\n    backend = dist.get_backend(group)\n    assert backend in [""gloo"", ""nccl""]\n    device = torch.device(""cpu"" if backend == ""gloo"" else ""cuda"")\n\n    buffer = pickle.dumps(data)\n    if len(buffer) > 1024 ** 3:\n        logger = logging.getLogger(__name__)\n        logger.warning(\n            ""Rank {} trying to all-gather {:.2f} GB of data on device {}"".format(\n                get_rank(), len(buffer) / (1024 ** 3), device\n            )\n        )\n    storage = torch.ByteStorage.from_buffer(buffer)\n    tensor = torch.ByteTensor(storage).to(device=device)\n    return tensor\n\n\ndef _pad_to_largest_tensor(tensor, group):\n    """"""\n    Returns:\n        list[int]: size of the tensor, on each rank\n        Tensor: padded tensor that has the max size\n    """"""\n    world_size = dist.get_world_size(group=group)\n    assert (\n            world_size >= 1\n    ), ""comm.gather/all_gather must be called from ranks within the given group!""\n    local_size = torch.tensor([tensor.numel()], dtype=torch.int64, device=tensor.device)\n    size_list = [\n        torch.zeros([1], dtype=torch.int64, device=tensor.device) for _ in range(world_size)\n    ]\n    dist.all_gather(size_list, local_size, group=group)\n    size_list = [int(size.item()) for size in size_list]\n\n    max_size = max(size_list)\n\n    # we pad the tensor because torch all_gather does not support\n    # gathering tensors of different shapes\n    if local_size != max_size:\n        padding = torch.zeros((max_size - local_size,), dtype=torch.uint8, device=tensor.device)\n        tensor = torch.cat((tensor, padding), dim=0)\n    return size_list, tensor\n\n\ndef all_gather(data, group=None):\n    """"""\n    Run all_gather on arbitrary picklable data (not necessarily tensors).\n    Args:\n        data: any picklable object\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n    Returns:\n        list[data]: list of data gathered from each rank\n    """"""\n    if get_world_size() == 1:\n        return [data]\n    if group is None:\n        group = _get_global_gloo_group()\n    if dist.get_world_size(group) == 1:\n        return [data]\n\n    tensor = _serialize_to_tensor(data, group)\n\n    size_list, tensor = _pad_to_largest_tensor(tensor, group)\n    max_size = max(size_list)\n\n    # receiving Tensor from all ranks\n    tensor_list = [\n        torch.empty((max_size,), dtype=torch.uint8, device=tensor.device) for _ in size_list\n    ]\n    dist.all_gather(tensor_list, tensor, group=group)\n\n    data_list = []\n    for size, tensor in zip(size_list, tensor_list):\n        buffer = tensor.cpu().numpy().tobytes()[:size]\n        data_list.append(pickle.loads(buffer))\n\n    return data_list\n\n\ndef gather(data, dst=0, group=None):\n    """"""\n    Run gather on arbitrary picklable data (not necessarily tensors).\n    Args:\n        data: any picklable object\n        dst (int): destination rank\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n    Returns:\n        list[data]: on dst, a list of data gathered from each rank. Otherwise,\n            an empty list.\n    """"""\n    if get_world_size() == 1:\n        return [data]\n    if group is None:\n        group = _get_global_gloo_group()\n    if dist.get_world_size(group=group) == 1:\n        return [data]\n    rank = dist.get_rank(group=group)\n\n    tensor = _serialize_to_tensor(data, group)\n    size_list, tensor = _pad_to_largest_tensor(tensor, group)\n\n    # receiving Tensor from all ranks\n    if rank == dst:\n        max_size = max(size_list)\n        tensor_list = [\n            torch.empty((max_size,), dtype=torch.uint8, device=tensor.device) for _ in size_list\n        ]\n        dist.gather(tensor, tensor_list, dst=dst, group=group)\n\n        data_list = []\n        for size, tensor in zip(size_list, tensor_list):\n            buffer = tensor.cpu().numpy().tobytes()[:size]\n            data_list.append(pickle.loads(buffer))\n        return data_list\n    else:\n        dist.gather(tensor, [], dst=dst, group=group)\n        return []\n\n\ndef shared_random_seed():\n    """"""\n    Returns:\n        int: a random number that is the same across all workers.\n            If workers need a shared RNG, they can use this shared seed to\n            create one.\n    All workers must call this function, otherwise it will deadlock.\n    """"""\n    ints = np.random.randint(2 ** 31)\n    all_ints = all_gather(ints)\n    return all_ints[0]\n\n\ndef reduce_dict(input_dict, average=True):\n    """"""\n    Reduce the values in the dictionary from all processes so that process with rank\n    0 has the reduced results.\n    Args:\n        input_dict (dict): inputs to be reduced. All the values must be scalar CUDA Tensor.\n        average (bool): whether to do average or sum\n    Returns:\n        a dict with the same keys as input_dict, after reduction.\n    """"""\n    world_size = get_world_size()\n    if world_size < 2:\n        return input_dict\n    with torch.no_grad():\n        names = []\n        values = []\n        # sort the keys so that they are consistent across processes\n        for k in sorted(input_dict.keys()):\n            names.append(k)\n            values.append(input_dict[k])\n        values = torch.stack(values, dim=0)\n        dist.reduce(values, dst=0)\n        if dist.get_rank() == 0 and average:\n            # only main process gets accumulated, so only divide by\n            # world_size in this case\n            values /= world_size\n        reduced_dict = {k: v for k, v in zip(names, values)}\n    return reduced_dict\n'"
fastreid/utils/events.py,5,"b'# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nimport datetime\nimport json\nimport logging\nimport os\nfrom collections import defaultdict\nfrom contextlib import contextmanager\nimport torch\nfrom .file_io import PathManager\nfrom .history_buffer import HistoryBuffer\n\n_CURRENT_STORAGE_STACK = []\n\n\ndef get_event_storage():\n    """"""\n    Returns:\n        The :class:`EventStorage` object that\'s currently being used.\n        Throws an error if no :class`EventStorage` is currently enabled.\n    """"""\n    assert len(\n        _CURRENT_STORAGE_STACK\n    ), ""get_event_storage() has to be called inside a \'with EventStorage(...)\' context!""\n    return _CURRENT_STORAGE_STACK[-1]\n\n\nclass EventWriter:\n    """"""\n    Base class for writers that obtain events from :class:`EventStorage` and process them.\n    """"""\n\n    def write(self):\n        raise NotImplementedError\n\n    def close(self):\n        pass\n\n\nclass JSONWriter(EventWriter):\n    """"""\n    Write scalars to a json file.\n    It saves scalars as one json per line (instead of a big json) for easy parsing.\n    Examples parsing such a json file:\n    .. code-block:: none\n        $ cat metrics.json | jq -s \'.[0:2]\'\n        [\n          {\n            ""data_time"": 0.008433341979980469,\n            ""iteration"": 20,\n            ""loss"": 1.9228371381759644,\n            ""loss_box_reg"": 0.050025828182697296,\n            ""loss_classifier"": 0.5316952466964722,\n            ""loss_mask"": 0.7236229181289673,\n            ""loss_rpn_box"": 0.0856662318110466,\n            ""loss_rpn_cls"": 0.48198649287223816,\n            ""lr"": 0.007173333333333333,\n            ""time"": 0.25401854515075684\n          },\n          {\n            ""data_time"": 0.007216215133666992,\n            ""iteration"": 40,\n            ""loss"": 1.282649278640747,\n            ""loss_box_reg"": 0.06222952902317047,\n            ""loss_classifier"": 0.30682939291000366,\n            ""loss_mask"": 0.6970193982124329,\n            ""loss_rpn_box"": 0.038663312792778015,\n            ""loss_rpn_cls"": 0.1471673548221588,\n            ""lr"": 0.007706666666666667,\n            ""time"": 0.2490077018737793\n          }\n        ]\n        $ cat metrics.json | jq \'.loss_mask\'\n        0.7126231789588928\n        0.689423680305481\n        0.6776131987571716\n        ...\n    """"""\n\n    def __init__(self, json_file, window_size=20):\n        """"""\n        Args:\n            json_file (str): path to the json file. New data will be appended if the file exists.\n            window_size (int): the window size of median smoothing for the scalars whose\n                `smoothing_hint` are True.\n        """"""\n        self._file_handle = PathManager.open(json_file, ""a"")\n        self._window_size = window_size\n\n    def write(self):\n        storage = get_event_storage()\n        to_save = {""iteration"": storage.iter}\n        to_save.update(storage.latest_with_smoothing_hint(self._window_size))\n        self._file_handle.write(json.dumps(to_save, sort_keys=True) + ""\\n"")\n        self._file_handle.flush()\n        try:\n            os.fsync(self._file_handle.fileno())\n        except AttributeError:\n            pass\n\n    def close(self):\n        self._file_handle.close()\n\n\nclass TensorboardXWriter(EventWriter):\n    """"""\n    Write all scalars to a tensorboard file.\n    """"""\n\n    def __init__(self, log_dir: str, window_size: int = 20, **kwargs):\n        """"""\n        Args:\n            log_dir (str): the directory to save the output events\n            window_size (int): the scalars will be median-smoothed by this window size\n            kwargs: other arguments passed to `torch.utils.tensorboard.SummaryWriter(...)`\n        """"""\n        self._window_size = window_size\n        from torch.utils.tensorboard import SummaryWriter\n\n        self._writer = SummaryWriter(log_dir, **kwargs)\n\n    def write(self):\n        storage = get_event_storage()\n        for k, v in storage.latest_with_smoothing_hint(self._window_size).items():\n            self._writer.add_scalar(k, v, storage.iter)\n\n        if len(storage.vis_data) >= 1:\n            for img_name, img, step_num in storage.vis_data:\n                self._writer.add_image(img_name, img, step_num)\n            storage.clear_images()\n\n    def close(self):\n        if hasattr(self, ""_writer""):  # doesn\'t exist when the code fails at import\n            self._writer.close()\n\n\nclass CommonMetricPrinter(EventWriter):\n    """"""\n    Print **common** metrics to the terminal, including\n    iteration time, ETA, memory, all heads, and the learning rate.\n    To print something different, please implement a similar printer by yourself.\n    """"""\n\n    def __init__(self, max_iter):\n        """"""\n        Args:\n            max_iter (int): the maximum number of iterations to train.\n                Used to compute ETA.\n        """"""\n        self.logger = logging.getLogger(__name__)\n        self._max_iter = max_iter\n\n    def write(self):\n        storage = get_event_storage()\n        iteration = storage.iter\n\n        data_time, time = None, None\n        eta_string = ""N/A""\n        try:\n            data_time = storage.history(""data_time"").avg(20)\n            time = storage.history(""time"").global_avg()\n            eta_seconds = storage.history(""time"").median(1000) * (self._max_iter - iteration)\n            storage.put_scalar(""eta_seconds"", eta_seconds, smoothing_hint=False)\n            eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n        except KeyError:  # they may not exist in the first few iterations (due to warmup)\n            pass\n\n        try:\n            lr = ""{:.2e}"".format(storage.history(""lr"").latest())\n        except KeyError:\n            lr = ""N/A""\n\n        if torch.cuda.is_available():\n            max_mem_mb = torch.cuda.max_memory_allocated() / 1024.0 / 1024.0\n        else:\n            max_mem_mb = None\n\n        # NOTE: max_mem is parsed by grep in ""dev/parse_results.sh""\n        self.logger.info(\n            """"""\\\neta: {eta}  iter: {iter}  {losses}  \\\n{time}  {data_time}  \\\nlr: {lr}  {memory}\\\n"""""".format(\n                eta=eta_string,\n                iter=iteration,\n                losses=""  "".join(\n                    [\n                        ""{}: {:.3f}"".format(k, v.median(20))\n                        for k, v in storage.histories().items()\n                        if ""loss"" in k\n                    ]\n                ),\n                time=""time: {:.4f}"".format(time) if time is not None else """",\n                data_time=""data_time: {:.4f}"".format(data_time) if data_time is not None else """",\n                lr=lr,\n                memory=""max_mem: {:.0f}M"".format(max_mem_mb) if max_mem_mb is not None else """",\n            )\n        )\n\n\nclass EventStorage:\n    """"""\n    The user-facing class that provides metric storage functionalities.\n    In the future we may add support for storing / logging other types of data if needed.\n    """"""\n\n    def __init__(self, start_iter=0):\n        """"""\n        Args:\n            start_iter (int): the iteration number to start with\n        """"""\n        self._history = defaultdict(HistoryBuffer)\n        self._smoothing_hints = {}\n        self._latest_scalars = {}\n        self._iter = start_iter\n        self._current_prefix = """"\n        self._vis_data = []\n\n    def put_image(self, img_name, img_tensor):\n        """"""\n        Add an `img_tensor` to the `_vis_data` associated with `img_name`.\n        Args:\n            img_name (str): The name of the image to put into tensorboard.\n            img_tensor (torch.Tensor or numpy.array): An `uint8` or `float`\n                Tensor of shape `[channel, height, width]` where `channel` is\n                3. The image format should be RGB. The elements in img_tensor\n                can either have values in [0, 1] (float32) or [0, 255] (uint8).\n                The `img_tensor` will be visualized in tensorboard.\n        """"""\n        self._vis_data.append((img_name, img_tensor, self._iter))\n\n    def clear_images(self):\n        """"""\n        Delete all the stored images for visualization. This should be called\n        after images are written to tensorboard.\n        """"""\n        self._vis_data = []\n\n    def put_scalar(self, name, value, smoothing_hint=True):\n        """"""\n        Add a scalar `value` to the `HistoryBuffer` associated with `name`.\n        Args:\n            smoothing_hint (bool): a \'hint\' on whether this scalar is noisy and should be\n                smoothed when logged. The hint will be accessible through\n                :meth:`EventStorage.smoothing_hints`.  A writer may ignore the hint\n                and apply custom smoothing rule.\n                It defaults to True because most scalars we save need to be smoothed to\n                provide any useful signal.\n        """"""\n        name = self._current_prefix + name\n        history = self._history[name]\n        value = float(value)\n        history.update(value, self._iter)\n        self._latest_scalars[name] = value\n\n        existing_hint = self._smoothing_hints.get(name)\n        if existing_hint is not None:\n            assert (\n                    existing_hint == smoothing_hint\n            ), ""Scalar {} was put with a different smoothing_hint!"".format(name)\n        else:\n            self._smoothing_hints[name] = smoothing_hint\n\n    def put_scalars(self, *, smoothing_hint=True, **kwargs):\n        """"""\n        Put multiple scalars from keyword arguments.\n        Examples:\n            storage.put_scalars(loss=my_loss, accuracy=my_accuracy, smoothing_hint=True)\n        """"""\n        for k, v in kwargs.items():\n            self.put_scalar(k, v, smoothing_hint=smoothing_hint)\n\n    def history(self, name):\n        """"""\n        Returns:\n            HistoryBuffer: the scalar history for name\n        """"""\n        ret = self._history.get(name, None)\n        if ret is None:\n            raise KeyError(""No history metric available for {}!"".format(name))\n        return ret\n\n    def histories(self):\n        """"""\n        Returns:\n            dict[name -> HistoryBuffer]: the HistoryBuffer for all scalars\n        """"""\n        return self._history\n\n    def latest(self):\n        """"""\n        Returns:\n            dict[name -> number]: the scalars that\'s added in the current iteration.\n        """"""\n        return self._latest_scalars\n\n    def latest_with_smoothing_hint(self, window_size=20):\n        """"""\n        Similar to :meth:`latest`, but the returned values\n        are either the un-smoothed original latest value,\n        or a median of the given window_size,\n        depend on whether the smoothing_hint is True.\n        This provides a default behavior that other writers can use.\n        """"""\n        result = {}\n        for k, v in self._latest_scalars.items():\n            result[k] = self._history[k].median(window_size) if self._smoothing_hints[k] else v\n        return result\n\n    def smoothing_hints(self):\n        """"""\n        Returns:\n            dict[name -> bool]: the user-provided hint on whether the scalar\n                is noisy and needs smoothing.\n        """"""\n        return self._smoothing_hints\n\n    def step(self):\n        """"""\n        User should call this function at the beginning of each iteration, to\n        notify the storage of the start of a new iteration.\n        The storage will then be able to associate the new data with the\n        correct iteration number.\n        """"""\n        self._iter += 1\n        self._latest_scalars = {}\n\n    @property\n    def vis_data(self):\n        return self._vis_data\n\n    @property\n    def iter(self):\n        return self._iter\n\n    @property\n    def iteration(self):\n        # for backward compatibility\n        return self._iter\n\n    def __enter__(self):\n        _CURRENT_STORAGE_STACK.append(self)\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        assert _CURRENT_STORAGE_STACK[-1] == self\n        _CURRENT_STORAGE_STACK.pop()\n\n    @contextmanager\n    def name_scope(self, name):\n        """"""\n        Yields:\n            A context within which all the events added to this storage\n            will be prefixed by the name scope.\n        """"""\n        old_prefix = self._current_prefix\n        self._current_prefix = name.rstrip(""/"") + ""/""\n        yield\n        self._current_prefix = old_prefix\n'"
fastreid/utils/file_io.py,0,"b'#!/usr/bin/env python3\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n\nimport errno\nimport logging\nimport os\nimport shutil\nfrom collections import OrderedDict\nfrom typing import (\n    IO,\n    Any,\n    Callable,\n    Dict,\n    List,\n    MutableMapping,\n    Optional,\n    Union,\n)\n\n__all__ = [""PathManager"", ""get_cache_dir""]\n\n\ndef get_cache_dir(cache_dir: Optional[str] = None) -> str:\n    """"""\n    Returns a default directory to cache static files\n    (usually downloaded from Internet), if None is provided.\n    Args:\n        cache_dir (None or str): if not None, will be returned as is.\n            If None, returns the default cache directory as:\n        1) $FVCORE_CACHE, if set\n        2) otherwise ~/.torch/fvcore_cache\n    """"""\n    if cache_dir is None:\n        cache_dir = os.path.expanduser(\n            os.getenv(""FVCORE_CACHE"", ""~/.torch/fvcore_cache"")\n        )\n    return cache_dir\n\n\nclass PathHandler:\n    """"""\n    PathHandler is a base class that defines common I/O functionality for a URI\n    protocol. It routes I/O for a generic URI which may look like ""protocol://*""\n    or a canonical filepath ""/foo/bar/baz"".\n    """"""\n\n    _strict_kwargs_check = True\n\n    def _check_kwargs(self, kwargs: Dict[str, Any]) -> None:\n        """"""\n        Checks if the given arguments are empty. Throws a ValueError if strict\n        kwargs checking is enabled and args are non-empty. If strict kwargs\n        checking is disabled, only a warning is logged.\n        Args:\n            kwargs (Dict[str, Any])\n        """"""\n        if self._strict_kwargs_check:\n            if len(kwargs) > 0:\n                raise ValueError(""Unused arguments: {}"".format(kwargs))\n        else:\n            logger = logging.getLogger(__name__)\n            for k, v in kwargs.items():\n                logger.warning(\n                    ""[PathManager] {}={} argument ignored"".format(k, v)\n                )\n\n    def _get_supported_prefixes(self) -> List[str]:\n        """"""\n        Returns:\n            List[str]: the list of URI prefixes this PathHandler can support\n        """"""\n        raise NotImplementedError()\n\n    def _get_local_path(self, path: str, **kwargs: Any) -> str:\n        """"""\n        Get a filepath which is compatible with native Python I/O such as `open`\n        and `os.path`.\n        If URI points to a remote resource, this function may download and cache\n        the resource to local disk. In this case, this function is meant to be\n        used with read-only resources.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            local_path (str): a file path which exists on the local file system\n        """"""\n        raise NotImplementedError()\n\n    def _open(\n            self, path: str, mode: str = ""r"", buffering: int = -1, **kwargs: Any\n    ) -> Union[IO[str], IO[bytes]]:\n        """"""\n        Open a stream to a URI, similar to the built-in `open`.\n        Args:\n            path (str): A URI supported by this PathHandler\n            mode (str): Specifies the mode in which the file is opened. It defaults\n                to \'r\'.\n            buffering (int): An optional integer used to set the buffering policy.\n                Pass 0 to switch buffering off and an integer >= 1 to indicate the\n                size in bytes of a fixed-size chunk buffer. When no buffering\n                argument is given, the default buffering policy depends on the\n                underlying I/O implementation.\n        Returns:\n            file: a file-like object.\n        """"""\n        raise NotImplementedError()\n\n    def _copy(\n            self,\n            src_path: str,\n            dst_path: str,\n            overwrite: bool = False,\n            **kwargs: Any,\n    ) -> bool:\n        """"""\n        Copies a source path to a destination path.\n        Args:\n            src_path (str): A URI supported by this PathHandler\n            dst_path (str): A URI supported by this PathHandler\n            overwrite (bool): Bool flag for forcing overwrite of existing file\n        Returns:\n            status (bool): True on success\n        """"""\n        raise NotImplementedError()\n\n    def _exists(self, path: str, **kwargs: Any) -> bool:\n        """"""\n        Checks if there is a resource at the given URI.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            bool: true if the path exists\n        """"""\n        raise NotImplementedError()\n\n    def _isfile(self, path: str, **kwargs: Any) -> bool:\n        """"""\n        Checks if the resource at the given URI is a file.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            bool: true if the path is a file\n        """"""\n        raise NotImplementedError()\n\n    def _isdir(self, path: str, **kwargs: Any) -> bool:\n        """"""\n        Checks if the resource at the given URI is a directory.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            bool: true if the path is a directory\n        """"""\n        raise NotImplementedError()\n\n    def _ls(self, path: str, **kwargs: Any) -> List[str]:\n        """"""\n        List the contents of the directory at the provided URI.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            List[str]: list of contents in given path\n        """"""\n        raise NotImplementedError()\n\n    def _mkdirs(self, path: str, **kwargs: Any) -> None:\n        """"""\n        Recursive directory creation function. Like mkdir(), but makes all\n        intermediate-level directories needed to contain the leaf directory.\n        Similar to the native `os.makedirs`.\n        Args:\n            path (str): A URI supported by this PathHandler\n        """"""\n        raise NotImplementedError()\n\n    def _rm(self, path: str, **kwargs: Any) -> None:\n        """"""\n        Remove the file (not directory) at the provided URI.\n        Args:\n            path (str): A URI supported by this PathHandler\n        """"""\n        raise NotImplementedError()\n\n\nclass NativePathHandler(PathHandler):\n    """"""\n    Handles paths that can be accessed using Python native system calls. This\n    handler uses `open()` and `os.*` calls on the given path.\n    """"""\n\n    def _get_local_path(self, path: str, **kwargs: Any) -> str:\n        self._check_kwargs(kwargs)\n        return path\n\n    def _open(\n            self,\n            path: str,\n            mode: str = ""r"",\n            buffering: int = -1,\n            encoding: Optional[str] = None,\n            errors: Optional[str] = None,\n            newline: Optional[str] = None,\n            closefd: bool = True,\n            opener: Optional[Callable] = None,\n            **kwargs: Any,\n    ) -> Union[IO[str], IO[bytes]]:\n        """"""\n        Open a path.\n        Args:\n            path (str): A URI supported by this PathHandler\n            mode (str): Specifies the mode in which the file is opened. It defaults\n                to \'r\'.\n            buffering (int): An optional integer used to set the buffering policy.\n                Pass 0 to switch buffering off and an integer >= 1 to indicate the\n                size in bytes of a fixed-size chunk buffer. When no buffering\n                argument is given, the default buffering policy works as follows:\n                    * Binary files are buffered in fixed-size chunks; the size of\n                    the buffer is chosen using a heuristic trying to determine the\n                    underlying device\xe2\x80\x99s \xe2\x80\x9cblock size\xe2\x80\x9d and falling back on\n                    io.DEFAULT_BUFFER_SIZE. On many systems, the buffer will\n                    typically be 4096 or 8192 bytes long.\n            encoding (Optional[str]): the name of the encoding used to decode or\n                encode the file. This should only be used in text mode.\n            errors (Optional[str]): an optional string that specifies how encoding\n                and decoding errors are to be handled. This cannot be used in binary\n                mode.\n            newline (Optional[str]): controls how universal newlines mode works\n                (it only applies to text mode). It can be None, \'\', \'\\n\', \'\\r\',\n                and \'\\r\\n\'.\n            closefd (bool): If closefd is False and a file descriptor rather than\n                a filename was given, the underlying file descriptor will be kept\n                open when the file is closed. If a filename is given closefd must\n                be True (the default) otherwise an error will be raised.\n            opener (Optional[Callable]): A custom opener can be used by passing\n                a callable as opener. The underlying file descriptor for the file\n                object is then obtained by calling opener with (file, flags).\n                opener must return an open file descriptor (passing os.open as opener\n                results in functionality similar to passing None).\n            See https://docs.python.org/3/library/functions.html#open for details.\n        Returns:\n            file: a file-like object.\n        """"""\n        self._check_kwargs(kwargs)\n        return open(  # type: ignore\n            path,\n            mode,\n            buffering=buffering,\n            encoding=encoding,\n            errors=errors,\n            newline=newline,\n            closefd=closefd,\n            opener=opener,\n        )\n\n    def _copy(\n            self,\n            src_path: str,\n            dst_path: str,\n            overwrite: bool = False,\n            **kwargs: Any,\n    ) -> bool:\n        """"""\n        Copies a source path to a destination path.\n        Args:\n            src_path (str): A URI supported by this PathHandler\n            dst_path (str): A URI supported by this PathHandler\n            overwrite (bool): Bool flag for forcing overwrite of existing file\n        Returns:\n            status (bool): True on success\n        """"""\n        self._check_kwargs(kwargs)\n\n        if os.path.exists(dst_path) and not overwrite:\n            logger = logging.getLogger(__name__)\n            logger.error(""Destination file {} already exists."".format(dst_path))\n            return False\n\n        try:\n            shutil.copyfile(src_path, dst_path)\n            return True\n        except Exception as e:\n            logger = logging.getLogger(__name__)\n            logger.error(""Error in file copy - {}"".format(str(e)))\n            return False\n\n    def _exists(self, path: str, **kwargs: Any) -> bool:\n        self._check_kwargs(kwargs)\n        return os.path.exists(path)\n\n    def _isfile(self, path: str, **kwargs: Any) -> bool:\n        self._check_kwargs(kwargs)\n        return os.path.isfile(path)\n\n    def _isdir(self, path: str, **kwargs: Any) -> bool:\n        self._check_kwargs(kwargs)\n        return os.path.isdir(path)\n\n    def _ls(self, path: str, **kwargs: Any) -> List[str]:\n        self._check_kwargs(kwargs)\n        return os.listdir(path)\n\n    def _mkdirs(self, path: str, **kwargs: Any) -> None:\n        self._check_kwargs(kwargs)\n        try:\n            os.makedirs(path, exist_ok=True)\n        except OSError as e:\n            # EEXIST it can still happen if multiple processes are creating the dir\n            if e.errno != errno.EEXIST:\n                raise\n\n    def _rm(self, path: str, **kwargs: Any) -> None:\n        self._check_kwargs(kwargs)\n        os.remove(path)\n\n\nclass PathManager:\n    """"""\n    A class for users to open generic paths or translate generic paths to file names.\n    """"""\n\n    _PATH_HANDLERS: MutableMapping[str, PathHandler] = OrderedDict()\n    _NATIVE_PATH_HANDLER = NativePathHandler()\n\n    @staticmethod\n    def __get_path_handler(path: str) -> PathHandler:\n        """"""\n        Finds a PathHandler that supports the given path. Falls back to the native\n        PathHandler if no other handler is found.\n        Args:\n            path (str): URI path to resource\n        Returns:\n            handler (PathHandler)\n        """"""\n        for p in PathManager._PATH_HANDLERS.keys():\n            if path.startswith(p):\n                return PathManager._PATH_HANDLERS[p]\n        return PathManager._NATIVE_PATH_HANDLER\n\n    @staticmethod\n    def open(\n            path: str, mode: str = ""r"", buffering: int = -1, **kwargs: Any\n    ) -> Union[IO[str], IO[bytes]]:\n        """"""\n        Open a stream to a URI, similar to the built-in `open`.\n        Args:\n            path (str): A URI supported by this PathHandler\n            mode (str): Specifies the mode in which the file is opened. It defaults\n                to \'r\'.\n            buffering (int): An optional integer used to set the buffering policy.\n                Pass 0 to switch buffering off and an integer >= 1 to indicate the\n                size in bytes of a fixed-size chunk buffer. When no buffering\n                argument is given, the default buffering policy depends on the\n                underlying I/O implementation.\n        Returns:\n            file: a file-like object.\n        """"""\n        return PathManager.__get_path_handler(path)._open(  # type: ignore\n            path, mode, buffering=buffering, **kwargs\n        )\n\n    @staticmethod\n    def copy(\n            src_path: str, dst_path: str, overwrite: bool = False, **kwargs: Any\n    ) -> bool:\n        """"""\n        Copies a source path to a destination path.\n        Args:\n            src_path (str): A URI supported by this PathHandler\n            dst_path (str): A URI supported by this PathHandler\n            overwrite (bool): Bool flag for forcing overwrite of existing file\n        Returns:\n            status (bool): True on success\n        """"""\n\n        # Copying across handlers is not supported.\n        assert PathManager.__get_path_handler(  # type: ignore\n            src_path\n        ) == PathManager.__get_path_handler(dst_path)\n        return PathManager.__get_path_handler(src_path)._copy(\n            src_path, dst_path, overwrite, **kwargs\n        )\n\n    @staticmethod\n    def get_local_path(path: str, **kwargs: Any) -> str:\n        """"""\n        Get a filepath which is compatible with native Python I/O such as `open`\n        and `os.path`.\n        If URI points to a remote resource, this function may download and cache\n        the resource to local disk.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            local_path (str): a file path which exists on the local file system\n        """"""\n        return PathManager.__get_path_handler(  # type: ignore\n            path\n        )._get_local_path(path, **kwargs)\n\n    @staticmethod\n    def exists(path: str, **kwargs: Any) -> bool:\n        """"""\n        Checks if there is a resource at the given URI.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            bool: true if the path exists\n        """"""\n        return PathManager.__get_path_handler(path)._exists(  # type: ignore\n            path, **kwargs\n        )\n\n    @staticmethod\n    def isfile(path: str, **kwargs: Any) -> bool:\n        """"""\n        Checks if there the resource at the given URI is a file.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            bool: true if the path is a file\n        """"""\n        return PathManager.__get_path_handler(path)._isfile(  # type: ignore\n            path, **kwargs\n        )\n\n    @staticmethod\n    def isdir(path: str, **kwargs: Any) -> bool:\n        """"""\n        Checks if the resource at the given URI is a directory.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            bool: true if the path is a directory\n        """"""\n        return PathManager.__get_path_handler(path)._isdir(  # type: ignore\n            path, **kwargs\n        )\n\n    @staticmethod\n    def ls(path: str, **kwargs: Any) -> List[str]:\n        """"""\n        List the contents of the directory at the provided URI.\n        Args:\n            path (str): A URI supported by this PathHandler\n        Returns:\n            List[str]: list of contents in given path\n        """"""\n        return PathManager.__get_path_handler(path)._ls(  # type: ignore\n            path, **kwargs\n        )\n\n    @staticmethod\n    def mkdirs(path: str, **kwargs: Any) -> None:\n        """"""\n        Recursive directory creation function. Like mkdir(), but makes all\n        intermediate-level directories needed to contain the leaf directory.\n        Similar to the native `os.makedirs`.\n        Args:\n            path (str): A URI supported by this PathHandler\n        """"""\n        return PathManager.__get_path_handler(path)._mkdirs(  # type: ignore\n            path, **kwargs\n        )\n\n    @staticmethod\n    def rm(path: str, **kwargs: Any) -> None:\n        """"""\n        Remove the file (not directory) at the provided URI.\n        Args:\n            path (str): A URI supported by this PathHandler\n        """"""\n        return PathManager.__get_path_handler(path)._rm(  # type: ignore\n            path, **kwargs\n        )\n\n    @staticmethod\n    def register_handler(handler: PathHandler) -> None:\n        """"""\n        Register a path handler associated with `handler._get_supported_prefixes`\n        URI prefixes.\n        Args:\n            handler (PathHandler)\n        """"""\n        assert isinstance(handler, PathHandler), handler\n        for prefix in handler._get_supported_prefixes():\n            assert prefix not in PathManager._PATH_HANDLERS\n            PathManager._PATH_HANDLERS[prefix] = handler\n\n        # Sort path handlers in reverse order so longer prefixes take priority,\n        # eg: http://foo/bar before http://foo\n        PathManager._PATH_HANDLERS = OrderedDict(\n            sorted(\n                PathManager._PATH_HANDLERS.items(),\n                key=lambda t: t[0],\n                reverse=True,\n            )\n        )\n\n    @staticmethod\n    def set_strict_kwargs_checking(enable: bool) -> None:\n        """"""\n        Toggles strict kwargs checking. If enabled, a ValueError is thrown if any\n        unused parameters are passed to a PathHandler function. If disabled, only\n        a warning is given.\n        With a centralized file API, there\'s a tradeoff of convenience and\n        correctness delegating arguments to the proper I/O layers. An underlying\n        `PathHandler` may support custom arguments which should not be statically\n        exposed on the `PathManager` function. For example, a custom `HTTPURLHandler`\n        may want to expose a `cache_timeout` argument for `open()` which specifies\n        how old a locally cached resource can be before it\'s refetched from the\n        remote server. This argument would not make sense for a `NativePathHandler`.\n        If strict kwargs checking is disabled, `cache_timeout` can be passed to\n        `PathManager.open` which will forward the arguments to the underlying\n        handler. By default, checking is enabled since it is innately unsafe:\n        multiple `PathHandler`s could reuse arguments with different semantic\n        meanings or types.\n        Args:\n            enable (bool)\n        """"""\n        PathManager._NATIVE_PATH_HANDLER._strict_kwargs_check = enable\n        for handler in PathManager._PATH_HANDLERS.values():\n            handler._strict_kwargs_check = enable\n'"
fastreid/utils/history_buffer.py,0,"b'#!/usr/bin/env python3\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n\nimport numpy as np\nfrom typing import List, Tuple\n\n\nclass HistoryBuffer:\n    """"""\n    Track a series of scalar values and provide access to smoothed values over a\n    window or the global average of the series.\n    """"""\n\n    def __init__(self, max_length: int = 1000000):\n        """"""\n        Args:\n            max_length: maximal number of values that can be stored in the\n                buffer. When the capacity of the buffer is exhausted, old\n                values will be removed.\n        """"""\n        self._max_length: int = max_length\n        self._data: List[Tuple[float, float]] = []  # (value, iteration) pairs\n        self._count: int = 0\n        self._global_avg: float = 0\n\n    def update(self, value: float, iteration: float = None):\n        """"""\n        Add a new scalar value produced at certain iteration. If the length\n        of the buffer exceeds self._max_length, the oldest element will be\n        removed from the buffer.\n        """"""\n        if iteration is None:\n            iteration = self._count\n        if len(self._data) == self._max_length:\n            self._data.pop(0)\n        self._data.append((value, iteration))\n\n        self._count += 1\n        self._global_avg += (value - self._global_avg) / self._count\n\n    def latest(self):\n        """"""\n        Return the latest scalar value added to the buffer.\n        """"""\n        return self._data[-1][0]\n\n    def median(self, window_size: int):\n        """"""\n        Return the median of the latest `window_size` values in the buffer.\n        """"""\n        return np.median([x[0] for x in self._data[-window_size:]])\n\n    def avg(self, window_size: int):\n        """"""\n        Return the mean of the latest `window_size` values in the buffer.\n        """"""\n        return np.mean([x[0] for x in self._data[-window_size:]])\n\n    def global_avg(self):\n        """"""\n        Return the mean of all the elements in the buffer. Note that this\n        includes those getting removed due to limited buffer storage.\n        """"""\n        return self._global_avg\n\n    def values(self):\n        """"""\n        Returns:\n            list[(number, iteration)]: content of the current buffer.\n        """"""\n        return self._data\n'"
fastreid/utils/logger.py,0,"b'# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nimport functools\nimport logging\nimport os\nimport sys\nimport time\nfrom collections import Counter\nfrom .file_io import PathManager\nfrom termcolor import colored\n\n\nclass _ColorfulFormatter(logging.Formatter):\n    def __init__(self, *args, **kwargs):\n        self._root_name = kwargs.pop(""root_name"") + "".""\n        self._abbrev_name = kwargs.pop(""abbrev_name"", """")\n        if len(self._abbrev_name):\n            self._abbrev_name = self._abbrev_name + "".""\n        super(_ColorfulFormatter, self).__init__(*args, **kwargs)\n\n    def formatMessage(self, record):\n        record.name = record.name.replace(self._root_name, self._abbrev_name)\n        log = super(_ColorfulFormatter, self).formatMessage(record)\n        if record.levelno == logging.WARNING:\n            prefix = colored(""WARNING"", ""red"", attrs=[""blink""])\n        elif record.levelno == logging.ERROR or record.levelno == logging.CRITICAL:\n            prefix = colored(""ERROR"", ""red"", attrs=[""blink"", ""underline""])\n        else:\n            return log\n        return prefix + "" "" + log\n\n\n@functools.lru_cache()  # so that calling setup_logger multiple times won\'t add many handlers\ndef setup_logger(\n        output=None, distributed_rank=0, *, color=True, name=""fastreid"", abbrev_name=None\n):\n    """"""\n    Args:\n        output (str): a file name or a directory to save log. If None, will not save log file.\n            If ends with "".txt"" or "".log"", assumed to be a file name.\n            Otherwise, logs will be saved to `output/log.txt`.\n        name (str): the root module name of this logger\n        abbrev_name (str): an abbreviation of the module, to avoid long names in logs.\n            Set to """" to not log the root module in logs.\n            By default, will abbreviate ""detectron2"" to ""d2"" and leave other\n            modules unchanged.\n    """"""\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    logger.propagate = False\n\n    if abbrev_name is None:\n        abbrev_name = ""d2"" if name == ""detectron2"" else name\n\n    plain_formatter = logging.Formatter(\n        ""[%(asctime)s] %(name)s %(levelname)s: %(message)s"", datefmt=""%m/%d %H:%M:%S""\n    )\n    # stdout logging: master only\n    if distributed_rank == 0:\n        ch = logging.StreamHandler(stream=sys.stdout)\n        ch.setLevel(logging.DEBUG)\n        if color:\n            formatter = _ColorfulFormatter(\n                colored(""[%(asctime)s %(name)s]: "", ""green"") + ""%(message)s"",\n                datefmt=""%m/%d %H:%M:%S"",\n                root_name=name,\n                abbrev_name=str(abbrev_name),\n            )\n        else:\n            formatter = plain_formatter\n        ch.setFormatter(formatter)\n        logger.addHandler(ch)\n\n    # file logging: all workers\n    if output is not None:\n        if output.endswith("".txt"") or output.endswith("".log""):\n            filename = output\n        else:\n            filename = os.path.join(output, ""log.txt"")\n        if distributed_rank > 0:\n            filename = filename + "".rank{}"".format(distributed_rank)\n        PathManager.mkdirs(os.path.dirname(filename))\n\n        fh = logging.StreamHandler(_cached_log_stream(filename))\n        fh.setLevel(logging.DEBUG)\n        fh.setFormatter(plain_formatter)\n        logger.addHandler(fh)\n\n    return logger\n\n\n# cache the opened file object, so that different calls to `setup_logger`\n# with the same file name can safely write to the same file.\n@functools.lru_cache(maxsize=None)\ndef _cached_log_stream(filename):\n    return PathManager.open(filename, ""a"")\n\n\n""""""\nBelow are some other convenient logging methods.\nThey are mainly adopted from\nhttps://github.com/abseil/abseil-py/blob/master/absl/logging/__init__.py\n""""""\n\n\ndef _find_caller():\n    """"""\n    Returns:\n        str: module name of the caller\n        tuple: a hashable key to be used to identify different callers\n    """"""\n    frame = sys._getframe(2)\n    while frame:\n        code = frame.f_code\n        if os.path.join(""utils"", ""logger."") not in code.co_filename:\n            mod_name = frame.f_globals[""__name__""]\n            if mod_name == ""__main__"":\n                mod_name = ""detectron2""\n            return mod_name, (code.co_filename, frame.f_lineno, code.co_name)\n        frame = frame.f_back\n\n\n_LOG_COUNTER = Counter()\n_LOG_TIMER = {}\n\n\ndef log_first_n(lvl, msg, n=1, *, name=None, key=""caller""):\n    """"""\n    Log only for the first n times.\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller\'s module by default.\n        key (str or tuple[str]): the string(s) can be one of ""caller"" or\n            ""message"", which defines how to identify duplicated logs.\n            For example, if called with `n=1, key=""caller""`, this function\n            will only log the first call from the same caller, regardless of\n            the message content.\n            If called with `n=1, key=""message""`, this function will log the\n            same content only once, even if they are called from different places.\n            If called with `n=1, key=(""caller"", ""message"")`, this function\n            will not log only if the same caller has logged the same message before.\n    """"""\n    if isinstance(key, str):\n        key = (key,)\n    assert len(key) > 0\n\n    caller_module, caller_key = _find_caller()\n    hash_key = ()\n    if ""caller"" in key:\n        hash_key = hash_key + caller_key\n    if ""message"" in key:\n        hash_key = hash_key + (msg,)\n\n    _LOG_COUNTER[hash_key] += 1\n    if _LOG_COUNTER[hash_key] <= n:\n        logging.getLogger(name or caller_module).log(lvl, msg)\n\n\ndef log_every_n(lvl, msg, n=1, *, name=None):\n    """"""\n    Log once per n times.\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller\'s module by default.\n    """"""\n    caller_module, key = _find_caller()\n    _LOG_COUNTER[key] += 1\n    if n == 1 or _LOG_COUNTER[key] % n == 1:\n        logging.getLogger(name or caller_module).log(lvl, msg)\n\n\ndef log_every_n_seconds(lvl, msg, n=1, *, name=None):\n    """"""\n    Log no more than once per n seconds.\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller\'s module by default.\n    """"""\n    caller_module, key = _find_caller()\n    last_logged = _LOG_TIMER.get(key, None)\n    current_time = time.time()\n    if last_logged is None or current_time - last_logged >= n:\n        logging.getLogger(name or caller_module).log(lvl, msg)\n        _LOG_TIMER[key] = current_time\n\n# def create_small_table(small_dict):\n#     """"""\n#     Create a small table using the keys of small_dict as headers. This is only\n#     suitable for small dictionaries.\n#     Args:\n#         small_dict (dict): a result dictionary of only a few items.\n#     Returns:\n#         str: the table as a string.\n#     """"""\n#     keys, values = tuple(zip(*small_dict.items()))\n#     table = tabulate(\n#         [values],\n#         headers=keys,\n#         tablefmt=""pipe"",\n#         floatfmt="".3f"",\n#         stralign=""center"",\n#         numalign=""center"",\n#     )\n#     return table\n'"
fastreid/utils/one_hot.py,14,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nfrom typing import Optional\n\nimport torch\n\n\n# based on:\n# https://github.com/kornia/kornia/blob/master/kornia/utils/one_hot.py\n\n\ndef one_hot(labels: torch.Tensor,\n            num_classes: int,\n            dtype: Optional[torch.dtype] = None, ) -> torch.Tensor:\n    # eps: Optional[float] = 1e-6) -> torch.Tensor:\n    r""""""Converts an integer label x-D tensor to a one-hot (x+1)-D tensor.\n    Args:\n        labels (torch.Tensor) : tensor with labels of shape :math:`(N, *)`,\n                                where N is batch size. Each value is an integer\n                                representing correct classification.\n        num_classes (int): number of classes in labels.\n        device (Optional[torch.device]): the desired device of returned tensor.\n         Default: if None, uses the current device for the default tensor type\n         (see torch.set_default_tensor_type()). device will be the CPU for CPU\n         tensor types and the current CUDA device for CUDA tensor types.\n        dtype (Optional[torch.dtype]): the desired data type of returned\n         tensor. Default: if None, infers data type from values.\n    Returns:\n        torch.Tensor: the labels in one hot tensor of shape :math:`(N, C, *)`,\n    Examples::\n        >>> labels = torch.LongTensor([[[0, 1], [2, 0]]])\n        >>> one_hot(labels, num_classes=3)\n        tensor([[[[1., 0.],\n                  [0., 1.]],\n                 [[0., 1.],\n                  [0., 0.]],\n                 [[0., 0.],\n                  [1., 0.]]]]\n    """"""\n    if not torch.is_tensor(labels):\n        raise TypeError(""Input labels type is not a torch.Tensor. Got {}""\n                        .format(type(labels)))\n    if not labels.dtype == torch.int64:\n        raise ValueError(\n            ""labels must be of the same dtype torch.int64. Got: {}"".format(\n                labels.dtype))\n    if num_classes < 1:\n        raise ValueError(""The number of classes must be bigger than one.""\n                         "" Got: {}"".format(num_classes))\n    device = labels.device\n    shape = labels.shape\n    one_hot = torch.zeros(shape[0], num_classes, *shape[1:],\n                          device=device, dtype=dtype)\n    return one_hot.scatter_(1, labels.unsqueeze(1), 1.0)\n'"
fastreid/utils/precision_bn.py,8,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport itertools\n\nimport torch\n\nBN_MODULE_TYPES = (\n    torch.nn.BatchNorm1d,\n    torch.nn.BatchNorm2d,\n    torch.nn.BatchNorm3d,\n    torch.nn.SyncBatchNorm,\n)\n\n\n@torch.no_grad()\ndef update_bn_stats(model, data_loader, num_iters: int = 200):\n    """"""\n    Recompute and update the batch norm stats to make them more precise. During\n    training both BN stats and the weight are changing after every iteration, so\n    the running average can not precisely reflect the actual stats of the\n    current model.\n    In this function, the BN stats are recomputed with fixed weights, to make\n    the running average more precise. Specifically, it computes the true average\n    of per-batch mean/variance instead of the running average.\n    Args:\n        model (nn.Module): the model whose bn stats will be recomputed.\n            Note that:\n            1. This function will not alter the training mode of the given model.\n               Users are responsible for setting the layers that needs\n               precise-BN to training mode, prior to calling this function.\n            2. Be careful if your models contain other stateful layers in\n               addition to BN, i.e. layers whose state can change in forward\n               iterations.  This function will alter their state. If you wish\n               them unchanged, you need to either pass in a submodule without\n               those layers, or backup the states.\n        data_loader (iterator): an iterator. Produce data as inputs to the model.\n        num_iters (int): number of iterations to compute the stats.\n    """"""\n    bn_layers = get_bn_modules(model)\n    if len(bn_layers) == 0:\n        return\n\n    # In order to make the running stats only reflect the current batch, the\n    # momentum is disabled.\n    # bn.running_mean = (1 - momentum) * bn.running_mean + momentum * batch_mean\n    # Setting the momentum to 1.0 to compute the stats without momentum.\n    momentum_actual = [bn.momentum for bn in bn_layers]\n    for bn in bn_layers:\n        bn.momentum = 1.0\n\n    # Note that running_var actually means ""running average of variance""\n    running_mean = [torch.zeros_like(bn.running_mean) for bn in bn_layers]\n    running_var = [torch.zeros_like(bn.running_var) for bn in bn_layers]\n\n    for ind, inputs in enumerate(itertools.islice(data_loader, num_iters)):\n        # Change targets to zero to avoid error in circle(arcface) loss\n        # which will use targets in forward\n        inputs[\'targets\'].zero_()\n        with torch.no_grad():  # No need to backward\n            model(inputs)\n        for i, bn in enumerate(bn_layers):\n            # Accumulates the bn stats.\n            running_mean[i] += (bn.running_mean - running_mean[i]) / (ind + 1)\n            running_var[i] += (bn.running_var - running_var[i]) / (ind + 1)\n            # We compute the ""average of variance"" across iterations.\n    assert ind == num_iters - 1, (\n        ""update_bn_stats is meant to run for {} iterations, ""\n        ""but the dataloader stops at {} iterations."".format(num_iters, ind)\n    )\n\n    for i, bn in enumerate(bn_layers):\n        # Sets the precise bn stats.\n        bn.running_mean = running_mean[i]\n        bn.running_var = running_var[i]\n        bn.momentum = momentum_actual[i]\n\n\ndef get_bn_modules(model):\n    """"""\n    Find all BatchNorm (BN) modules that are in training mode. See\n    fvcore.precise_bn.BN_MODULE_TYPES for a list of all modules that are\n    included in this search.\n    Args:\n        model (nn.Module): a model possibly containing BN modules.\n    Returns:\n        list[nn.Module]: all BN modules in the model.\n    """"""\n    # Finds all the bn layers.\n    bn_layers = [\n        m for m in model.modules() if m.training and isinstance(m, BN_MODULE_TYPES)\n    ]\n    return bn_layers\n'"
fastreid/utils/registry.py,0,"b'#!/usr/bin/env python3\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n\nfrom typing import Dict, Optional\n\n\nclass Registry(object):\n    """"""\n    The registry that provides name -> object mapping, to support third-party\n    users\' custom modules.\n    To create a registry (e.g. a backbone registry):\n    .. code-block:: python\n        BACKBONE_REGISTRY = Registry(\'BACKBONE\')\n    To register an object:\n    .. code-block:: python\n        @BACKBONE_REGISTRY.register()\n        class MyBackbone():\n            ...\n    Or:\n    .. code-block:: python\n        BACKBONE_REGISTRY.register(MyBackbone)\n    """"""\n\n    def __init__(self, name: str) -> None:\n        """"""\n        Args:\n            name (str): the name of this registry\n        """"""\n        self._name: str = name\n        self._obj_map: Dict[str, object] = {}\n\n    def _do_register(self, name: str, obj: object) -> None:\n        assert (\n                name not in self._obj_map\n        ), ""An object named \'{}\' was already registered in \'{}\' registry!"".format(\n            name, self._name\n        )\n        self._obj_map[name] = obj\n\n    def register(self, obj: object = None) -> Optional[object]:\n        """"""\n        Register the given object under the the name `obj.__name__`.\n        Can be used as either a decorator or not. See docstring of this class for usage.\n        """"""\n        if obj is None:\n            # used as a decorator\n            def deco(func_or_class: object) -> object:\n                name = func_or_class.__name__  # pyre-ignore\n                self._do_register(name, func_or_class)\n                return func_or_class\n\n            return deco\n\n        # used as a function call\n        name = obj.__name__  # pyre-ignore\n        self._do_register(name, obj)\n\n    def get(self, name: str) -> object:\n        ret = self._obj_map.get(name)\n        if ret is None:\n            raise KeyError(\n                ""No object named \'{}\' found in \'{}\' registry!"".format(\n                    name, self._name\n                )\n            )\n        return ret\n'"
fastreid/utils/summary.py,8,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nfrom collections import OrderedDict\nimport numpy as np\n\n\ndef summary(model, input_size, batch_size=-1, device=""cuda""):\n    def register_hook(module):\n\n        def hook(module, input, output):\n            class_name = str(module.__class__).split(""."")[-1].split(""\'"")[0]\n            module_idx = len(summary)\n\n            m_key = ""%s-%i"" % (class_name, module_idx + 1)\n            summary[m_key] = OrderedDict()\n            summary[m_key][""input_shape""] = list(input[0].size())\n            summary[m_key][""input_shape""][0] = batch_size\n            if isinstance(output, (list, tuple)):\n                summary[m_key][""output_shape""] = [\n                    [-1] + list(o.size())[1:] for o in output\n                ]\n            else:\n                summary[m_key][""output_shape""] = list(output.size())\n                summary[m_key][""output_shape""][0] = batch_size\n\n            params = 0\n            if hasattr(module, ""weight"") and hasattr(module.weight, ""size""):\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n                summary[m_key][""trainable""] = module.weight.requires_grad\n            if hasattr(module, ""bias"") and hasattr(module.bias, ""size""):\n                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n            summary[m_key][""nb_params""] = params\n\n        if (\n                not isinstance(module, nn.Sequential)\n                and not isinstance(module, nn.ModuleList)\n                and not (module == model)\n        ):\n            hooks.append(module.register_forward_hook(hook))\n\n    device = device.lower()\n    assert device in [\n        ""cuda"",\n        ""cpu"",\n    ], ""Input device is not valid, please specify \'cuda\' or \'cpu\'""\n\n    if device == ""cuda"" and torch.cuda.is_available():\n        dtype = torch.cuda.FloatTensor\n    else:\n        dtype = torch.FloatTensor\n\n    # multiple inputs to the network\n    if isinstance(input_size, tuple):\n        input_size = [input_size]\n\n    # batch_size of 2 for batchnorm\n    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n    # print(type(x[0]))\n\n    # create properties\n    summary = OrderedDict()\n    hooks = []\n\n    # register hook\n    model.apply(register_hook)\n\n    # make a forward pass\n    # print(x.shape)\n    model(*x)\n\n    # remove these hooks\n    for h in hooks:\n        h.remove()\n\n    print(""----------------------------------------------------------------"")\n    line_new = ""{:>20}  {:>25} {:>15}"".format(""Layer (type)"", ""Output Shape"", ""Param #"")\n    print(line_new)\n    print(""================================================================"")\n    total_params = 0\n    total_output = 0\n    trainable_params = 0\n    for layer in summary:\n        # input_shape, output_shape, trainable, nb_params\n        line_new = ""{:>20}  {:>25} {:>15}"".format(\n            layer,\n            str(summary[layer][""output_shape""]),\n            ""{0:,}"".format(summary[layer][""nb_params""]),\n        )\n        total_params += summary[layer][""nb_params""]\n        total_output += np.prod(summary[layer][""output_shape""])\n        if ""trainable"" in summary[layer]:\n            if summary[layer][""trainable""] == True:\n                trainable_params += summary[layer][""nb_params""]\n        print(line_new)\n\n    # assume 4 bytes/number (float on cuda).\n    total_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\n    total_output_size = abs(2. * total_output * 4. / (1024 ** 2.))  # x2 for gradients\n    total_params_size = abs(total_params.numpy() * 4. / (1024 ** 2.))\n    total_size = total_params_size + total_output_size + total_input_size\n\n    print(""================================================================"")\n    print(""Total params: {0:,}"".format(total_params))\n    print(""Trainable params: {0:,}"".format(trainable_params))\n    print(""Non-trainable params: {0:,}"".format(total_params - trainable_params))\n    print(""----------------------------------------------------------------"")\n    print(""Input size (MB): %0.2f"" % total_input_size)\n    print(""Forward/backward pass size (MB): %0.2f"" % total_output_size)\n    print(""Params size (MB): %0.2f"" % total_params_size)\n    print(""Estimated Total Size (MB): %0.2f"" % total_size)\n    print(""----------------------------------------------------------------"")\n    # return summary\n'"
fastreid/utils/timer.py,0,"b'# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n# -*- coding: utf-8 -*-\n\nfrom time import perf_counter\nfrom typing import Optional\n\n\nclass Timer:\n    """"""\n    A timer which computes the time elapsed since the start/reset of the timer.\n    """"""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        """"""\n        Reset the timer.\n        """"""\n        self._start = perf_counter()\n        self._paused: Optional[float] = None\n        self._total_paused = 0\n        self._count_start = 1\n\n    def pause(self):\n        """"""\n        Pause the timer.\n        """"""\n        if self._paused is not None:\n            raise ValueError(""Trying to pause a Timer that is already paused!"")\n        self._paused = perf_counter()\n\n    def is_paused(self) -> bool:\n        """"""\n        Returns:\n            bool: whether the timer is currently paused\n        """"""\n        return self._paused is not None\n\n    def resume(self):\n        """"""\n        Resume the timer.\n        """"""\n        if self._paused is None:\n            raise ValueError(""Trying to resume a Timer that is not paused!"")\n        self._total_paused += perf_counter() - self._paused\n        self._paused = None\n        self._count_start += 1\n\n    def seconds(self) -> float:\n        """"""\n        Returns:\n            (float): the total number of seconds since the start/reset of the\n                timer, excluding the time when the timer is paused.\n        """"""\n        if self._paused is not None:\n            end_time: float = self._paused  # type: ignore\n        else:\n            end_time = perf_counter()\n        return end_time - self._start - self._total_paused\n\n    def avg_seconds(self) -> float:\n        """"""\n        Returns:\n            (float): the average number of seconds between every start/reset and\n            pause.\n        """"""\n        return self.seconds() / self._count_start\n'"
fastreid/utils/visualizer.py,2,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport os\nimport pickle\nimport random\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tqdm\nfrom scipy.stats import norm\nfrom sklearn import metrics\n\nfrom .file_io import PathManager\n\n\nclass Visualizer:\n    r""""""Visualize images(activation map) ranking list of features generated by reid models.""""""\n\n    def __init__(self, dataset):\n        self.dataset = dataset\n\n    def get_model_output(self, all_ap, dist, q_pids, g_pids, q_camids, g_camids):\n        self.all_ap = all_ap\n        self.dist = dist\n        self.sim = 1 - dist\n        self.q_pids = q_pids\n        self.g_pids = g_pids\n        self.q_camids = q_camids\n        self.g_camids = g_camids\n\n        self.indices = np.argsort(dist, axis=1)\n        self.matches = (g_pids[self.indices] == q_pids[:, np.newaxis]).astype(np.int32)\n\n        self.num_query = len(q_pids)\n\n    def get_matched_result(self, q_index):\n        q_pid = self.q_pids[q_index]\n        q_camid = self.q_camids[q_index]\n\n        order = self.indices[q_index]\n        remove = (self.g_pids[order] == q_pid) & (self.g_camids[order] == q_camid)\n        keep = np.invert(remove)\n        cmc = self.matches[q_index][keep]\n        sort_idx = order[keep]\n        return cmc, sort_idx\n\n    def save_rank_result(self, query_indices, output, max_rank=5, vis_label=False, label_sort=\'ascending\',\n                         actmap=False):\n        if vis_label:\n            fig, axes = plt.subplots(2, max_rank + 1, figsize=(3 * max_rank, 12))\n        else:\n            fig, axes = plt.subplots(1, max_rank + 1, figsize=(3 * max_rank, 6))\n        for cnt, q_idx in enumerate(tqdm.tqdm(query_indices)):\n            all_imgs = []\n            cmc, sort_idx = self.get_matched_result(q_idx)\n            query_info = self.dataset[q_idx]\n            query_img = query_info[\'images\']\n            cam_id = query_info[\'camid\']\n            query_name = query_info[\'img_path\'].split(\'/\')[-1]\n            all_imgs.append(query_img)\n            query_img = np.rollaxis(np.asarray(query_img.numpy(), dtype=np.uint8), 0, 3)\n            plt.clf()\n            ax = fig.add_subplot(1, max_rank + 1, 1)\n            ax.imshow(query_img)\n            ax.set_title(\'{}/{:.2f}/cam{}\'.format(query_name, self.all_ap[q_idx], cam_id))\n            ax.axis(""off"")\n            for i in range(max_rank):\n                if vis_label:\n                    ax = fig.add_subplot(2, max_rank + 1, i + 2)\n                else:\n                    ax = fig.add_subplot(1, max_rank + 1, i + 2)\n                g_idx = self.num_query + sort_idx[i]\n                gallery_info = self.dataset[g_idx]\n                gallery_img = gallery_info[\'images\']\n                cam_id = gallery_info[\'camid\']\n                all_imgs.append(gallery_img)\n                gallery_img = np.rollaxis(np.asarray(gallery_img, dtype=np.uint8), 0, 3)\n                if cmc[i] == 1:\n                    label = \'true\'\n                    ax.add_patch(plt.Rectangle(xy=(0, 0), width=gallery_img.shape[1] - 1,\n                                               height=gallery_img.shape[0] - 1, edgecolor=(1, 0, 0),\n                                               fill=False, linewidth=5))\n                else:\n                    label = \'false\'\n                    ax.add_patch(plt.Rectangle(xy=(0, 0), width=gallery_img.shape[1] - 1,\n                                               height=gallery_img.shape[0] - 1,\n                                               edgecolor=(0, 0, 1), fill=False, linewidth=5))\n                ax.imshow(gallery_img)\n                ax.set_title(f\'{self.sim[q_idx, sort_idx[i]]:.3f}/{label}/cam{cam_id}\')\n                ax.axis(""off"")\n            # if actmap:\n            #     act_outputs = []\n            #\n            #     def hook_fns_forward(module, input, output):\n            #         act_outputs.append(output.cpu())\n            #\n            #     all_imgs = np.stack(all_imgs, axis=0)  # (b, 3, h, w)\n            #     all_imgs = torch.from_numpy(all_imgs).float()\n            #     # normalize\n            #     all_imgs = all_imgs.sub_(self.mean).div_(self.std)\n            #     sz = list(all_imgs.shape[-2:])\n            #     handle = m.base.register_forward_hook(hook_fns_forward)\n            #     with torch.no_grad():\n            #         _ = m(all_imgs.cuda())\n            #     handle.remove()\n            #     acts = self.get_actmap(act_outputs[0], sz)\n            #     for i in range(top + 1):\n            #         axes.flat[i].imshow(acts[i], alpha=0.3, cmap=\'jet\')\n            if vis_label:\n                label_indice = np.where(cmc == 1)[0]\n                if label_sort == ""ascending"":   label_indice = label_indice[::-1]\n                label_indice = label_indice[:max_rank]\n                for i in range(max_rank):\n                    if i >= len(label_indice): break\n                    j = label_indice[i]\n                    g_idx = self.num_query + sort_idx[j]\n                    gallery_info = self.dataset[g_idx]\n                    gallery_img = gallery_info[\'images\']\n                    cam_id = gallery_info[\'camid\']\n                    gallery_img = np.rollaxis(np.asarray(gallery_img, dtype=np.uint8), 0, 3)\n                    ax = fig.add_subplot(2, max_rank + 1, max_rank + 3 + i)\n                    ax.add_patch(plt.Rectangle(xy=(0, 0), width=gallery_img.shape[1] - 1,\n                                               height=gallery_img.shape[0] - 1,\n                                               edgecolor=(1, 0, 0),\n                                               fill=False, linewidth=5))\n                    ax.imshow(gallery_img)\n                    ax.set_title(f\'{self.sim[q_idx, sort_idx[j]]:.3f}/cam{cam_id}\')\n                    ax.axis(""off"")\n\n            plt.tight_layout()\n            filepath = os.path.join(output, ""{}.jpg"".format(cnt))\n            fig.savefig(filepath)\n\n    def vis_rank_list(self, output, vis_label, num_vis=100, rank_sort=""ascending"", label_sort=""ascending"", max_rank=5,\n                      actmap=False):\n        r""""""Visualize rank list of query instance\n        Args:\n            output (str): a directory to save rank list result.\n            vis_label (bool): if visualize label of query\n            num_vis (int):\n            rank_sort (str): save visualization results by which order,\n                if rank_sort is ascending, AP from low to high, vice versa.\n            label_sort (bool):\n            max_rank (int): maximum number of rank result to visualize\n            actmap (bool):\n        """"""\n        assert rank_sort in [\'ascending\', \'descending\'], ""{} not match [ascending, descending]"".format(rank_sort)\n\n        query_indices = np.argsort(self.all_ap)\n        if rank_sort == \'descending\': query_indices = query_indices[::-1]\n\n        query_indices = query_indices[:num_vis]\n        self.save_rank_result(query_indices, output, max_rank, vis_label, label_sort, actmap)\n\n    def vis_roc_curve(self, output):\n        PathManager.mkdirs(output)\n        pos, neg = [], []\n        for i, q in enumerate(self.q_pids):\n            cmc, sort_idx = self.get_matched_result(i)  # remove same id in same camera\n            ind_pos = np.where(cmc == 1)[0]\n            q_dist = self.dist[i]\n            pos.extend(q_dist[sort_idx[ind_pos]])\n\n            ind_neg = np.where(cmc == 0)[0]\n            neg.extend(q_dist[sort_idx[ind_neg]])\n\n        scores = np.hstack((pos, neg))\n        labels = np.hstack((np.zeros(len(pos)), np.ones(len(neg))))\n\n        fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n\n        self.plot_roc_curve(fpr, tpr)\n        filepath = os.path.join(output, ""roc.jpg"")\n        plt.savefig(filepath)\n        self.plot_distribution(pos, neg)\n        filepath = os.path.join(output, ""pos_neg_dist.jpg"")\n        plt.savefig(filepath)\n        return fpr, tpr, pos, neg\n\n    @staticmethod\n    def plot_roc_curve(fpr, tpr, name=\'model\', fig=None):\n        if fig is None:\n            fig = plt.figure()\n            plt.semilogx(np.arange(0, 1, 0.01), np.arange(0, 1, 0.01), \'r\', linestyle=\'--\', label=\'Random guess\')\n        plt.semilogx(fpr, tpr, color=(random.uniform(0, 1), random.uniform(0, 1), random.uniform(0, 1)),\n                     label=\'ROC curve with {}\'.format(name))\n        plt.title(\'Receiver Operating Characteristic\')\n        plt.xlabel(\'False Positive Rate\')\n        plt.ylabel(\'True Positive Rate\')\n        plt.legend(loc=\'best\')\n        return fig\n\n    @staticmethod\n    def plot_distribution(pos, neg, name=\'model\', fig=None):\n        if fig is None:\n            fig = plt.figure()\n        pos_color = (random.uniform(0, 1), random.uniform(0, 1), random.uniform(0, 1))\n        n, bins, _ = plt.hist(pos, bins=80, alpha=0.7, density=True,\n                              color=pos_color,\n                              label=\'positive with {}\'.format(name))\n        mu = np.mean(pos)\n        sigma = np.std(pos)\n        y = norm.pdf(bins, mu, sigma)  # fitting curve\n        plt.plot(bins, y, color=pos_color)  # plot y curve\n\n        neg_color = (random.uniform(0, 1), random.uniform(0, 1), random.uniform(0, 1))\n        n, bins, _ = plt.hist(neg, bins=80, alpha=0.5, density=True,\n                              color=neg_color,\n                              label=\'negative with {}\'.format(name))\n        mu = np.mean(neg)\n        sigma = np.std(neg)\n        y = norm.pdf(bins, mu, sigma)  # fitting curve\n        plt.plot(bins, y, color=neg_color)  # plot y curve\n\n        plt.xticks(np.arange(0, 1.5, 0.1))\n        plt.title(\'positive and negative pairs distribution\')\n        plt.legend(loc=\'best\')\n        return fig\n\n    @staticmethod\n    def save_roc_info(output, fpr, tpr, pos, neg):\n        results = {\n            ""fpr"": np.asarray(fpr),\n            ""tpr"": np.asarray(tpr),\n            ""pos"": np.asarray(pos),\n            ""neg"": np.asarray(neg),\n        }\n        with open(os.path.join(output, ""roc_info.pickle""), ""wb"") as handle:\n            pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n    @staticmethod\n    def load_roc_info(path):\n        with open(path, \'rb\') as handle: res = pickle.load(handle)\n        return res\n\n    # def plot_camera_dist(self):\n    #     same_cam, diff_cam = [], []\n    #     for i, q in enumerate(self.q_pids):\n    #         q_camid = self.q_camids[i]\n    #\n    #         order = self.indices[i]\n    #         same = (self.g_pids[order] == q) & (self.g_camids[order] == q_camid)\n    #         diff = (self.g_pids[order] == q) & (self.g_camids[order] != q_camid)\n    #         sameCam_idx = order[same]\n    #         diffCam_idx = order[diff]\n    #\n    #         same_cam.extend(self.sim[i, sameCam_idx])\n    #         diff_cam.extend(self.sim[i, diffCam_idx])\n    #\n    #     fig = plt.figure(figsize=(10, 5))\n    #     plt.hist(same_cam, bins=80, alpha=0.7, density=True, color=\'red\', label=\'same camera\')\n    #     plt.hist(diff_cam, bins=80, alpha=0.5, density=True, color=\'blue\', label=\'diff camera\')\n    #     plt.xticks(np.arange(0.1, 1.0, 0.1))\n    #     plt.title(\'positive and negative pair distribution\')\n    #     return fig\n\n    # def get_actmap(self, features, sz):\n    #     """"""\n    #     :param features: (1, 2048, 16, 8) activation map\n    #     :return:\n    #     """"""\n    #     features = (features ** 2).sum(1)  # (1, 16, 8)\n    #     b, h, w = features.size()\n    #     features = features.view(b, h * w)\n    #     features = nn.functional.normalize(features, p=2, dim=1)\n    #     acts = features.view(b, h, w)\n    #     all_acts = []\n    #     for i in range(b):\n    #         act = acts[i].numpy()\n    #         act = cv2.resize(act, (sz[1], sz[0]))\n    #         act = 255 * (act - act.max()) / (act.max() - act.min() + 1e-12)\n    #         act = np.uint8(np.floor(act))\n    #         all_acts.append(act)\n    #     return all_acts\n'"
fastreid/utils/weight_init.py,0,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nimport math\nfrom torch import nn\n\n__all__ = [\n    \'weights_init_classifier\',\n    \'weights_init_kaiming\',\n]\n\n\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Linear\') != -1:\n        nn.init.normal_(m.weight, 0, 0.01)\n        if m.bias is not None:\n            nn.init.constant_(m.bias, 0.0)\n    elif classname.find(\'Conv\') != -1:\n        nn.init.kaiming_normal_(m.weight, mode=\'fan_out\', nonlinearity=\'relu\')\n        if m.bias is not None:\n            nn.init.constant_(m.bias, 0.0)\n    elif classname.find(\'BatchNorm\') != -1:\n        if m.affine:\n            nn.init.normal_(m.weight, 1.0, 0.02)\n            nn.init.constant_(m.bias, 0.0)\n\n\ndef weights_init_classifier(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Linear\') != -1:\n        nn.init.normal_(m.weight, std=0.001)\n        if m.bias is not None:\n            nn.init.constant_(m.bias, 0.0)\n    elif classname.find(""Arcface"") and classname.find(""Circle"") != -1:\n        nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n'"
projects/PartialReID/train_net.py,0,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport os\nimport logging\nimport sys\n\nsys.path.append(\'.\')\n\nfrom torch import nn\n\nfrom fastreid.config import get_cfg\nfrom fastreid.engine import DefaultTrainer, default_argument_parser, default_setup\nfrom fastreid.utils.checkpoint import Checkpointer\nfrom fastreid.engine import hooks\n\nfrom partialreid import *\n\n\nclass Trainer(DefaultTrainer):\n    @classmethod\n    def build_evaluator(cls, cfg, num_query, output_folder=None):\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR, ""inference"")\n        return DsrEvaluator(cfg, num_query)\n\n\ndef setup(args):\n    """"""\n    Create configs and perform basic setups.\n    """"""\n    cfg = get_cfg()\n    add_partialreid_config(cfg)\n    cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n    default_setup(cfg, args)\n    return cfg\n\n\ndef main(args):\n    cfg = setup(args)\n\n    logger = logging.getLogger(\'fastreid.\' + __name__)\n    if args.eval_only:\n        cfg.defrost()\n        cfg.MODEL.BACKBONE.PRETRAIN = False\n        model = Trainer.build_model(cfg)\n        model = nn.DataParallel(model)\n        model = model.cuda()\n\n        Checkpointer(model, save_dir=cfg.OUTPUT_DIR).load(cfg.MODEL.WEIGHTS)  # load trained model\n        if cfg.TEST.PRECISE_BN.ENABLED and hooks.get_bn_modules(model):\n            prebn_cfg = cfg.clone()\n            prebn_cfg.DATALOADER.NUM_WORKERS = 0  # save some memory and time for PreciseBN\n            prebn_cfg.DATASETS.NAMES = tuple([cfg.TEST.PRECISE_BN.DATASET])  # set dataset name for PreciseBN\n            logger.info(""Prepare precise BN dataset"")\n            hooks.PreciseBN(\n                # Run at the same freq as (but before) evaluation.\n                model,\n                # Build a new data loader to not affect training\n                Trainer.build_train_loader(prebn_cfg),\n                cfg.TEST.PRECISE_BN.NUM_ITER,\n            ).update_stats()\n        res = Trainer.test(cfg, model)\n        return res\n\n    trainer = Trainer(cfg)\n    trainer.resume_or_load(resume=args.resume)\n    return trainer.train()\n\n\nif __name__ == ""__main__"":\n    args = default_argument_parser().parse_args()\n    print(""Command Line Args:"", args)\n    main(args)\n'"
tools/deploy/caffe_export.py,1,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nimport argparse\n\nimport torch\nimport sys\nsys.path.append(\'../../\')\n\nimport pytorch_to_caffe\nfrom fastreid.config import get_cfg\nfrom fastreid.modeling.meta_arch import build_model\nfrom fastreid.utils.file_io import PathManager\nfrom fastreid.utils.checkpoint import Checkpointer\n\n\ndef setup_cfg(args):\n    cfg = get_cfg()\n    cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n    return cfg\n\n\ndef get_parser():\n    parser = argparse.ArgumentParser(description=""Convert Pytorch to Caffe model"")\n\n    parser.add_argument(\n        ""--config-file"",\n        metavar=""FILE"",\n        help=""path to config file"",\n    )\n    parser.add_argument(\n        ""--name"",\n        default=""baseline"",\n        help=""name for converted model""\n    )\n    parser.add_argument(\n        ""--output"",\n        default=\'caffe_model\',\n        help=\'path to save converted caffe model\'\n    )\n    parser.add_argument(\n        ""--opts"",\n        help=""Modify config options using the command-line \'KEY VALUE\' pairs"",\n        default=[],\n        nargs=argparse.REMAINDER,\n    )\n    return parser\n\n\nif __name__ == \'__main__\':\n    args = get_parser().parse_args()\n    cfg = setup_cfg(args)\n\n    cfg.defrost()\n    cfg.MODEL.BACKBONE.PRETRAIN = False\n    cfg.MODEL.HEADS.POOL_LAYER = ""identity""\n    cfg.MODEL.BACKBONE.WITH_NL = False\n\n    model = build_model(cfg)\n    Checkpointer(model).load(cfg.MODEL.WEIGHTS)\n    model.cuda()\n    model.eval()\n    print(model)\n\n    inputs = torch.randn(1, 3, cfg.INPUT.SIZE_TEST[0], cfg.INPUT.SIZE_TEST[1]).cuda()\n    PathManager.mkdirs(args.output)\n    pytorch_to_caffe.trans_net(model, inputs, args.name)\n    pytorch_to_caffe.save_prototxt(f""{args.output}/{args.name}.prototxt"")\n    pytorch_to_caffe.save_caffemodel(f""{args.output}/{args.name}.caffemodel"")\n'"
tools/deploy/caffe_inference.py,0,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nimport caffe\nimport tqdm\nimport glob\nimport os\nimport cv2\nimport numpy as np\n\ncaffe.set_mode_gpu()\n\nimport argparse\n\n\ndef get_parser():\n    parser = argparse.ArgumentParser(description=""Caffe model inference"")\n\n    parser.add_argument(\n        ""--model-def"",\n        default=""logs/test_caffe/baseline_R50.prototxt"",\n        help=""caffe model prototxt""\n    )\n    parser.add_argument(\n        ""--model-weights"",\n        default=""logs/test_caffe/baseline_R50.caffemodel"",\n        help=""caffe model weights""\n    )\n    parser.add_argument(\n        ""--input"",\n        nargs=""+"",\n        help=""A list of space separated input images; ""\n             ""or a single glob pattern such as \'directory/*.jpg\'"",\n    )\n    parser.add_argument(\n        ""--output"",\n        default=\'caffe_output\',\n        help=\'path to save converted caffe model\'\n    )\n    parser.add_argument(\n        ""--height"",\n        type=int,\n        default=384,\n        help=""height of image""\n    )\n    parser.add_argument(\n        ""--width"",\n        type=int,\n        default=128,\n        help=""width of image""\n    )\n    return parser\n\n\ndef preprocess(image_path, image_height, image_width):\n    original_image = cv2.imread(image_path)\n    # the model expects RGB inputs\n    original_image = original_image[:, :, ::-1]\n\n    # Apply pre-processing to image.\n    image = cv2.resize(original_image, (image_width, image_height), interpolation=cv2.INTER_CUBIC)\n    image = image.astype(""float32"").transpose(2, 0, 1)[np.newaxis]  # (1, 3, h, w)\n    image = (image - np.array([0.485 * 255, 0.456 * 255, 0.406 * 255]).reshape((1, -1, 1, 1))) / np.array(\n        [0.229 * 255, 0.224 * 255, 0.225 * 255]).reshape((1, -1, 1, 1))\n    return image\n\n\ndef normalize(nparray, order=2, axis=-1):\n    """"""Normalize a N-D numpy array along the specified axis.""""""\n    norm = np.linalg.norm(nparray, ord=order, axis=axis, keepdims=True)\n    return nparray / (norm + np.finfo(np.float32).eps)\n\n\nif __name__ == ""__main__"":\n    args = get_parser().parse_args()\n\n    net = caffe.Net(args.model_def, args.model_weights, caffe.TEST)\n    net.blobs[\'blob1\'].reshape(1, 3, args.height, args.width)\n\n    if not os.path.exists(args.output): os.makedirs(args.output)\n\n    if args.input:\n        if os.path.isdir(args.input[0]):\n            args.input = glob.glob(os.path.expanduser(args.input[0]))\n            assert args.input, ""The input path(s) was not found""\n        for path in tqdm.tqdm(args.input):\n            image = preprocess(path, args.height, args.width)\n            net.blobs[\'blob1\'].data[...] = image\n            feat = net.forward()[\'output\']\n            feat = normalize(feat[..., 0, 0], axis=1)\n            np.save(os.path.join(args.output, path.replace(\'.jpg\', \'.npy\').split(\'/\')[-1]), feat)\n\n'"
tools/deploy/export2tf.py,2,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport sys\n\nimport torch\nsys.path.append(\'../..\')\nfrom fastreid.config import get_cfg\nfrom fastreid.engine import default_argument_parser, default_setup\nfrom fastreid.modeling.meta_arch import build_model\nfrom fastreid.export.tensorflow_export import export_tf_reid_model\nfrom fastreid.export.tf_modeling import TfMetaArch\n\n\ndef setup(args):\n    """"""\n    Create configs and perform basic setups.\n    """"""\n    cfg = get_cfg()\n    # cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n    default_setup(cfg, args)\n    return cfg\n\n\nif __name__ == ""__main__"":\n    args = default_argument_parser().parse_args()\n    print(""Command Line Args:"", args)\n    cfg = setup(args)\n    cfg.defrost()\n    cfg.MODEL.BACKBONE.NAME = ""build_resnet_backbone""\n    cfg.MODEL.BACKBONE.DEPTH = 50\n    cfg.MODEL.BACKBONE.LAST_STRIDE = 1\n    # If use IBN block in backbone\n    cfg.MODEL.BACKBONE.WITH_IBN = False\n    cfg.MODEL.BACKBONE.PRETRAIN = False\n\n    from torchvision.models import resnet50\n    # model = TfMetaArch(cfg)\n    model = resnet50(pretrained=False)\n    # model.load_params_wo_fc(torch.load(\'logs/bjstation/res50_baseline_v0.4/ckpts/model_epoch80.pth\'))\n    model.eval()\n    dummy_inputs = torch.randn(1, 3, 256, 128)\n    export_tf_reid_model(model, dummy_inputs, \'reid_tf.pb\')\n'"
tools/deploy/pytorch_to_caffe.py,15,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport torch\nimport torch.nn as nn\nimport traceback\nfrom Caffe import caffe_net\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom Caffe import layer_param\nfrom torch.nn.modules.utils import _pair\nimport numpy as np\nimport math\nfrom torch.nn.modules.utils import _list_with_default\n\n""""""\nHow to support a new layer type:\n layer_name=log.add_layer(layer_type_name)\n top_blobs=log.add_blobs(<output of that layer>)\n layer=caffe_net.Layer_param(xxx)\n <set layer parameters>\n [<layer.add_data(*datas)>]\n log.cnet.add_layer(layer)\n\nPlease MUTE the inplace operations to avoid not find in graph\n""""""\n\n\n# TODO: support the inplace output of the layers\n\nclass Blob_LOG():\n    def __init__(self):\n        self.data = {}\n\n    def __setitem__(self, key, value):\n        self.data[key] = value\n\n    def __getitem__(self, key):\n        return self.data[key]\n\n    def __len__(self):\n        return len(self.data)\n\n\nNET_INITTED = False\n\n\n# \xe8\xbd\xac\xe6\x8d\xa2\xe5\x8e\x9f\xe7\x90\x86\xe8\xa7\xa3\xe6\x9e\x90\xef\xbc\x9a\xe9\x80\x9a\xe8\xbf\x87\xe8\xae\xb0\xe5\xbd\x95\nclass TransLog(object):\n    def __init__(self):\n        """"""\n        doing init() with inputs Variable before using it\n        """"""\n        self.layers = {}\n        self.detail_layers = {}\n        self.detail_blobs = {}\n        self._blobs = Blob_LOG()\n        self._blobs_data = []\n        self.cnet = caffe_net.Caffemodel(\'\')\n        self.debug = True\n\n    def init(self, inputs):\n        """"""\n        :param inputs: is a list of input variables\n        """"""\n        self.add_blobs(inputs)\n\n    def add_layer(self, name=\'layer\'):\n        if name in self.layers:\n            return self.layers[name]\n        if name not in self.detail_layers.keys():\n            self.detail_layers[name] = 0\n        self.detail_layers[name] += 1\n        name = \'{}{}\'.format(name, self.detail_layers[name])\n        self.layers[name] = name\n        if self.debug:\n            print(""{} was added to layers"".format(self.layers[name]))\n        return self.layers[name]\n\n    def add_blobs(self, blobs, name=\'blob\', with_num=True):\n        rst = []\n        for blob in blobs:\n            self._blobs_data.append(blob)  # to block the memory address be rewrited\n            blob_id = int(id(blob))\n            if name not in self.detail_blobs.keys():\n                self.detail_blobs[name] = 0\n            self.detail_blobs[name] += 1\n            if with_num:\n                rst.append(\'{}{}\'.format(name, self.detail_blobs[name]))\n            else:\n                rst.append(\'{}\'.format(name))\n            if self.debug:\n                print(""{}:{} was added to blobs"".format(blob_id, rst[-1]))\n            print(\'Add blob {} : {}\'.format(rst[-1].center(21), blob.size()))\n            self._blobs[blob_id] = rst[-1]\n        return rst\n\n    def blobs(self, var):\n        var = id(var)\n        if self.debug:\n            print(""{}:{} getting"".format(var, self._blobs[var]))\n        try:\n            return self._blobs[var]\n        except:\n            print(""WARNING: CANNOT FOUND blob {}"".format(var))\n            return None\n\n\nlog = TransLog()\n\nlayer_names = {}\n\n\ndef _conv2d(raw, input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1):\n    x = raw(input, weight, bias, stride, padding, dilation, groups)\n    name = log.add_layer(name=\'conv\')\n    log.add_blobs([x], name=\'conv_blob\')\n    layer = caffe_net.Layer_param(name=name, type=\'Convolution\',\n                                  bottom=[log.blobs(input)], top=[log.blobs(x)])\n    layer.conv_param(x.size()[1], weight.size()[2:], stride=_pair(stride),\n                     pad=_pair(padding), dilation=_pair(dilation), bias_term=bias is not None, groups=groups)\n    if bias is not None:\n        layer.add_data(weight.cpu().data.numpy(), bias.cpu().data.numpy())\n        #print(\'conv2d weight, bias: \',weight.cpu().data.numpy(), bias.cpu().data.numpy())\n\n    else:\n        layer.param.convolution_param.bias_term = False\n        layer.add_data(weight.cpu().data.numpy())\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _conv_transpose2d(raw, input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1):\n    x = raw(input, weight, bias, stride, padding, output_padding, groups, dilation)\n    name = log.add_layer(name=\'conv_transpose\')\n    log.add_blobs([x], name=\'conv_transpose_blob\')\n    layer = caffe_net.Layer_param(name=name, type=\'Deconvolution\',\n                                  bottom=[log.blobs(input)], top=[log.blobs(x)])\n    layer.conv_param(x.size()[1], weight.size()[2:], stride=_pair(stride),\n                     pad=_pair(padding), dilation=_pair(dilation), bias_term=bias is not None)\n    if bias is not None:\n        layer.add_data(weight.cpu().data.numpy(), bias.cpu().data.numpy())\n    else:\n        layer.param.convolution_param.bias_term = False\n        layer.add_data(weight.cpu().data.numpy())\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _linear(raw, input, weight, bias=None):\n    x = raw(input, weight, bias)\n    layer_name = log.add_layer(name=\'fc\')\n    top_blobs = log.add_blobs([x], name=\'fc_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'InnerProduct\',\n                                  bottom=[log.blobs(input)], top=top_blobs)\n    layer.fc_param(x.size()[1], has_bias=bias is not None)\n    if bias is not None:\n        layer.add_data(weight.cpu().data.numpy(), bias.cpu().data.numpy())\n    else:\n        layer.add_data(weight.cpu().data.numpy())\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _split(raw, tensor, split_size, dim=0):\n    # split in pytorch is slice in caffe\n    x = raw(tensor, split_size, dim)\n    layer_name = log.add_layer(\'split\')\n    top_blobs = log.add_blobs(x, name=\'split_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Slice\',\n                                  bottom=[log.blobs(tensor)], top=top_blobs)\n    slice_num = int(np.floor(tensor.size()[dim] / split_size))\n    slice_param = caffe_net.pb.SliceParameter(axis=dim, slice_point=[split_size * i for i in range(1, slice_num)])\n    layer.param.slice_param.CopyFrom(slice_param)\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _pool(type, raw, input, x, kernel_size, stride, padding, ceil_mode):\n    # TODO dilation,ceil_mode,return indices\n    layer_name = log.add_layer(name=\'{}_pool\'.format(type))\n    top_blobs = log.add_blobs([x], name=\'{}_pool_blob\'.format(type))\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Pooling\', bottom=[log.blobs(input)], top=top_blobs)\n\n    # TODO w,h different kernel, stride and padding\n    # processing ceil mode\n    layer.pool_param(kernel_size=kernel_size, stride=kernel_size if stride is None else stride,\n                     pad=padding, type=type.upper())\n    log.cnet.add_layer(layer)\n    if ceil_mode == False and stride is not None:\n        oheight = (input.size()[2] - _pair(kernel_size)[0] + 2 * _pair(padding)[0]) % (_pair(stride)[0])\n        owidth = (input.size()[3] - _pair(kernel_size)[1] + 2 * _pair(padding)[1]) % (_pair(stride)[1])\n        if oheight != 0 or owidth != 0:\n            caffe_out = raw(input, kernel_size, stride, padding, ceil_mode=False)\n            print(""WARNING: the output shape miss match at {}: ""\n\n                  ""input {} output---Pytorch:{}---Caffe:{}\\n""\n                  ""This is caused by the different implementation that ceil mode in caffe and the floor mode in pytorch.\\n""\n                  ""You can add the clip layer in caffe prototxt manually if shape mismatch error is caused in caffe. "".format(\n                layer_name, input.size(), x.size(), caffe_out.size()))\n\n\ndef _max_pool2d(raw, input, kernel_size, stride=None, padding=0, dilation=1,\n                ceil_mode=False, return_indices=False):\n    x = raw(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\n    _pool(\'max\', raw, input, x, kernel_size, stride, padding, ceil_mode)\n    return x\n\n\ndef _avg_pool2d(raw, input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True):\n    x = raw(input, kernel_size, stride, padding, ceil_mode, count_include_pad)\n    _pool(\'ave\', raw, input, x, kernel_size, stride, padding, ceil_mode)\n    return x\n\n\ndef _max(raw, *args):\n    x = raw(*args)\n    if len(args) == 1:\n        # TODO max in one tensor\n        assert NotImplementedError\n    else:\n        bottom_blobs = []\n        for arg in args:\n            bottom_blobs.append(log.blobs(arg))\n        layer_name = log.add_layer(name=\'max\')\n        top_blobs = log.add_blobs([x], name=\'max_blob\')\n        layer = caffe_net.Layer_param(name=layer_name, type=\'Eltwise\',\n                                      bottom=bottom_blobs, top=top_blobs)\n        layer.param.eltwise_param.operation = 2\n        log.cnet.add_layer(layer)\n    return x\n\n\ndef _cat(raw, inputs, dimension=0):\n    x = raw(inputs, dimension)\n    bottom_blobs = []\n    for input in inputs:\n        bottom_blobs.append(log.blobs(input))\n    layer_name = log.add_layer(name=\'cat\')\n    top_blobs = log.add_blobs([x], name=\'cat_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Concat\',\n                                  bottom=bottom_blobs, top=top_blobs)\n    layer.param.concat_param.axis = dimension\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _dropout(raw, input, p=0.5, training=False, inplace=False):\n    x = raw(input, p, training, inplace)\n    bottom_blobs = [log.blobs(input)]\n    layer_name = log.add_layer(name=\'dropout\')\n    top_blobs = log.add_blobs([x], name=bottom_blobs[0], with_num=False)\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Dropout\',\n                                  bottom=bottom_blobs, top=top_blobs)\n    layer.param.dropout_param.dropout_ratio = p\n    layer.param.include.extend([caffe_net.pb.NetStateRule(phase=0)])  # 1 for test, 0 for train\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _threshold(raw, input, threshold, value, inplace=False):\n    # for threshold or relu\n    if threshold == 0 and value == 0:\n        x = raw(input, threshold, value, inplace)\n        bottom_blobs = [log.blobs(input)]\n        name = log.add_layer(name=\'relu\')\n        log.add_blobs([x], name=\'relu_blob\')\n        layer = caffe_net.Layer_param(name=name, type=\'ReLU\',\n                                      bottom=bottom_blobs, top=[log.blobs(x)])\n        log.cnet.add_layer(layer)\n        return x\n    if value != 0:\n        raise NotImplemented(""value !=0 not implemented in caffe"")\n    x = raw(input, input, threshold, value, inplace)\n    bottom_blobs = [log.blobs(input)]\n    layer_name = log.add_layer(name=\'threshold\')\n    top_blobs = log.add_blobs([x], name=\'threshold_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Threshold\',\n                                  bottom=bottom_blobs, top=top_blobs)\n    layer.param.threshold_param.threshold = threshold\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _relu(raw, input, inplace=False):\n    # for threshold or prelu\n    x = raw(input, False)\n    name = log.add_layer(name=\'relu\')\n    log.add_blobs([x], name=\'relu_blob\')\n    layer = caffe_net.Layer_param(name=name, type=\'ReLU\',\n                                  bottom=[log.blobs(input)], top=[log.blobs(x)])\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _prelu(raw, input, weight):\n    # for threshold or prelu\n    x = raw(input, weight)\n    bottom_blobs = [log.blobs(input)]\n    name = log.add_layer(name=\'prelu\')\n    log.add_blobs([x], name=\'prelu_blob\')\n    layer = caffe_net.Layer_param(name=name, type=\'PReLU\',\n                                  bottom=bottom_blobs, top=[log.blobs(x)])\n    if weight.size()[0] == 1:\n        layer.param.prelu_param.channel_shared = True\n        layer.add_data(weight.cpu().data.numpy()[0])\n    else:\n        layer.add_data(weight.cpu().data.numpy())\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _leaky_relu(raw, input, negative_slope=0.01, inplace=False):\n    x = raw(input, negative_slope)\n    name = log.add_layer(name=\'leaky_relu\')\n    log.add_blobs([x], name=\'leaky_relu_blob\')\n    layer = caffe_net.Layer_param(name=name, type=\'ReLU\',\n                                  bottom=[log.blobs(input)], top=[log.blobs(x)])\n    layer.param.relu_param.negative_slope = negative_slope\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _tanh(raw, input):\n    # for tanh activation\n    x = raw(input)\n    name = log.add_layer(name=\'tanh\')\n    log.add_blobs([x], name=\'tanh_blob\')\n    layer = caffe_net.Layer_param(name=name, type=\'TanH\',\n                                  bottom=[log.blobs(input)], top=[log.blobs(x)])\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _softmax(raw, input, dim=None, _stacklevel=3):\n    # for F.softmax\n    x = raw(input, dim=dim)\n    if dim is None:\n        dim = F._get_softmax_dim(\'softmax\', input.dim(), _stacklevel)\n    bottom_blobs = [log.blobs(input)]\n    name = log.add_layer(name=\'softmax\')\n    log.add_blobs([x], name=\'softmax_blob\')\n    layer = caffe_net.Layer_param(name=name, type=\'Softmax\',\n                                  bottom=bottom_blobs, top=[log.blobs(x)])\n    layer.param.softmax_param.axis = dim\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _sigmoid(raw, input):\n    # for tanh activation\n    x = raw(input)\n    name = log.add_layer(name=\'Sigmoid\')\n    log.add_blobs([x], name=\'Sigmoid_blob\')\n    layer = caffe_net.Layer_param(name=name, type=\'Sigmoid\',\n                                  bottom=[log.blobs(input)], top=[log.blobs(x)])\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _batch_norm(raw, input, running_mean, running_var, weight=None, bias=None,\n                training=False, momentum=0.1, eps=1e-5):\n    # because the runing_mean and runing_var will be changed after the _batch_norm operation, we first save the parameters\n\n    x = raw(input, running_mean, running_var, weight, bias,\n            training, momentum, eps)\n    bottom_blobs = [log.blobs(input)]\n    layer_name1 = log.add_layer(name=\'batch_norm\')\n    top_blobs = log.add_blobs([x], name=\'batch_norm_blob\')\n    layer1 = caffe_net.Layer_param(name=layer_name1, type=\'BatchNorm\',\n                                   bottom=bottom_blobs, top=top_blobs)\n    if running_mean is None or running_var is None:\n        # not use global_stats, normalization is performed over the current mini-batch\n        layer1.batch_norm_param(use_global_stats=0, eps=eps)\n    else:\n        layer1.batch_norm_param(use_global_stats=1, eps=eps)\n        running_mean_clone = running_mean.clone()\n        running_var_clone = running_var.clone()\n        layer1.add_data(running_mean_clone.cpu().numpy(), running_var_clone.cpu().numpy(), np.array([1.0]))\n        #print(\'running_mean: \',running_mean_clone.cpu().numpy())\n        #print(\'running_var: \',running_var_clone.cpu().numpy())\n    log.cnet.add_layer(layer1)\n    if weight is not None and bias is not None:\n        layer_name2 = log.add_layer(name=\'bn_scale\')\n        layer2 = caffe_net.Layer_param(name=layer_name2, type=\'Scale\',\n                                       bottom=top_blobs, top=top_blobs)\n        layer2.param.scale_param.bias_term = True\n        layer2.add_data(weight.cpu().data.numpy(), bias.cpu().data.numpy())\n        log.cnet.add_layer(layer2)\n        #print(\'scale weight: \', weight.cpu().data.numpy())\n        #print(\'scale bias: \', bias.cpu().data.numpy())\n    return x\n\n\ndef _instance_norm(raw, input, running_mean=None, running_var=None, weight=None,\n                   bias=None, use_input_stats=True, momentum=0.1, eps=1e-5):\n    # TODO: the batch size!=1 view operations\n    print(""WARNING: The Instance Normalization transfers to Caffe using BatchNorm, so the batch size should be 1"")\n    if running_var is not None or weight is not None:\n        # TODO: the affine=True or track_running_stats=True case\n        raise NotImplementedError(""not implement the affine=True or track_running_stats=True case InstanceNorm"")\n    x = torch.batch_norm(\n        input, weight, bias, running_mean, running_var,\n        use_input_stats, momentum, eps, torch.backends.cudnn.enabled)\n    bottom_blobs = [log.blobs(input)]\n    layer_name1 = log.add_layer(name=\'instance_norm\')\n    top_blobs = log.add_blobs([x], name=\'instance_norm_blob\')\n    layer1 = caffe_net.Layer_param(name=layer_name1, type=\'BatchNorm\',\n                                   bottom=bottom_blobs, top=top_blobs)\n    if running_mean is None or running_var is None:\n        # not use global_stats, normalization is performed over the current mini-batch\n        layer1.batch_norm_param(use_global_stats=0, eps=eps)\n        running_mean = torch.zeros(input.size()[1])\n        running_var = torch.ones(input.size()[1])\n    else:\n        layer1.batch_norm_param(use_global_stats=1, eps=eps)\n    running_mean_clone = running_mean.clone()\n    running_var_clone = running_var.clone()\n    layer1.add_data(running_mean_clone.cpu().numpy(), running_var_clone.cpu().numpy(), np.array([1.0]))\n    log.cnet.add_layer(layer1)\n    if weight is not None and bias is not None:\n        layer_name2 = log.add_layer(name=\'bn_scale\')\n        layer2 = caffe_net.Layer_param(name=layer_name2, type=\'Scale\',\n                                       bottom=top_blobs, top=top_blobs)\n        layer2.param.scale_param.bias_term = True\n        layer2.add_data(weight.cpu().data.numpy(), bias.cpu().data.numpy())\n        log.cnet.add_layer(layer2)\n    return x\n\n\n# upsample layer\ndef _interpolate(raw, input, size=None, scale_factor=None, mode=\'nearest\', align_corners=None):\n    # \xe5\xae\x9a\xe4\xb9\x89\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\x8c\x85\xe6\x8b\xac scale,\xe5\x8d\xb3\xe8\xbe\x93\xe5\x87\xba\xe4\xb8\x8e\xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe5\xb0\xba\xe5\xaf\xb8\xe6\xaf\x94\xe4\xbe\x8b,\xe5\xa6\x82 2;scale_h\xe3\x80\x81scale_w,\n    # \xe5\x90\x8c scale,\xe5\x88\x86\xe5\x88\xab\xe4\xb8\xba h\xe3\x80\x81w \xe6\x96\xb9\xe5\x90\x91\xe4\xb8\x8a\xe7\x9a\x84\xe5\xb0\xba\xe5\xaf\xb8\xe6\xaf\x94\xe4\xbe\x8b;pad_out_h\xe3\x80\x81pad_out_w,\xe4\xbb\x85\xe5\x9c\xa8 scale \xe4\xb8\xba 2 \xe6\x97\xb6\n    # \xe6\x9c\x89\xe7\x94\xa8,\xe5\xaf\xb9\xe8\xbe\x93\xe5\x87\xba\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x9d\xe5\xa4\x96 padding \xe5\x9c\xa8 h\xe3\x80\x81w \xe6\x96\xb9\xe5\x90\x91\xe4\xb8\x8a\xe7\x9a\x84\xe6\x95\xb0\xe5\x80\xbc;upsample_h\xe3\x80\x81upsample_w,\xe8\xbe\x93\n    # \xe5\x87\xba\xe5\x9b\xbe\xe5\x83\x8f\xe5\xb0\xba\xe5\xaf\xb8\xe7\x9a\x84\xe6\x95\xb0\xe5\x80\xbc\xe3\x80\x82\xe5\x9c\xa8 Upsample \xe7\x9a\x84\xe7\x9b\xb8\xe5\x85\xb3\xe4\xbb\xa3\xe7\xa0\x81\xe4\xb8\xad,\xe6\x8e\xa8\xe8\x8d\x90\xe4\xbb\x85\xe4\xbb\x85\xe4\xbd\xbf\xe7\x94\xa8 upsample_h\xe3\x80\x81\n    # upsample_w \xe5\x87\x86\xe7\xa1\xae\xe5\xae\x9a\xe4\xb9\x89 Upsample \xe5\xb1\x82\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\xb0\xba\xe5\xaf\xb8,\xe5\x85\xb6\xe4\xbb\x96\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe9\x83\xbd\xe4\xb8\x8d\xe6\x8e\xa8\xe8\x8d\x90\xe7\xbb\xa7\xe7\xbb\xad\xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82\n    \'\'\'\n    if mode == \'bilinear\':      \n        x = raw(input, size, scale_factor, mode)\n        name = log.add_layer(name=\'conv_transpose\')\n        log.add_blobs([x], name=\'conv_transpose_blob\')\n        layer = caffe_net.Layer_param(name=name, type=\'Deconvolution\',\n                                  bottom=[log.blobs(input)], top=[log.blobs(x)])\n        print(\'Deconv: \', name)\n        print(input.shape)\n        print(x.size())\n        print(size)\n        factor = float(size[0]) / input.shape[2]\n        C = x.size()[1]\n        print(factor,C) \n        kernel_size = int(2 * factor - factor % 2)\n        stride = int(factor)\n        num_output = C\n        group = C\n        pad = math.ceil((factor-1) / 2.)\n        print(\'kernel_size, stride, num_output, group, pad\')\n        print(kernel_size, stride, num_output, group, pad)\n        layer.conv_param(num_output, kernel_size, stride=stride,\n                     pad=pad, weight_filler_type=\'bilinear\', bias_term=False, groups=group)\n\n        layer.param.convolution_param.bias_term = False\n        log.cnet.add_layer(layer)\n        return x\n    \'\'\'\n    # transfer bilinear align_corners=True to caffe-interp\n    if mode == ""bilinear"" and align_corners == True:\n        x = raw(input, size, scale_factor, mode)\n        name = log.add_layer(name=\'interp\')\n        log.add_blobs([x], name=\'interp_blob\')\n        layer = caffe_net.Layer_param(name=name, type=\'Interp\',\n                                  bottom=[log.blobs(input)], top=[log.blobs(x)])\n        layer.interp_param(size=size, scale_factor=scale_factor)\n        log.cnet.add_layer(layer)\n        return x\n\n    # for nearest _interpolate\n    if mode != ""nearest"" or align_corners != None:\n        raise NotImplementedError(""not implement F.interpolate totoaly"")\n    x = raw(input, size, scale_factor, mode)\n    layer_name = log.add_layer(name=\'upsample\')\n    top_blobs = log.add_blobs([x], name=\'upsample_blob\'.format(type))\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Upsample\',\n                                  bottom=[log.blobs(input)], top=top_blobs)\n    #layer.upsample_param(size=(input.size(2), input.size(3)), scale_factor=scale_factor)\n    #layer.upsample_param(size=size, scale_factor=scale_factor)\n    layer.upsample_param(size=None, scale_factor=size[0])\n    \n    log.cnet.add_layer(layer)\n    return x\n\n\n# ----- for Variable operations --------\n\ndef _view(input, *args):\n    x = raw_view(input, *args)\n    if not NET_INITTED:\n        return x\n    layer_name = log.add_layer(name=\'view\')\n    top_blobs = log.add_blobs([x], name=\'view_blob\')\n\n    # print(\'*\'*60)\n    # print(\'input={}\'.format(input))\n    # print(\'layer_name={}\'.format(layer_name))\n    # print(\'top_blobs={}\'.format(top_blobs))\n\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Reshape\', bottom=[log.blobs(input)], top=top_blobs)\n    # TODO: reshpae added to nn_tools layer\n    dims = list(args)\n    dims[0] = 0  # the first dim should be batch_size\n    layer.param.reshape_param.shape.CopyFrom(caffe_net.pb.BlobShape(dim=dims))\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _mean(input, *args, **kwargs):\n    x = raw_mean(input, *args, **kwargs)\n    if not NET_INITTED:\n        return x\n    layer_name = log.add_layer(name=\'mean\')\n    top_blobs = log.add_blobs([x], name=\'mean_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Reduction\',\n                                  bottom=[log.blobs(input)], top=top_blobs)\n    if len(args) == 1:\n        dim = args[0]\n    elif \'dim\' in kwargs:\n        dim = kwargs[\'dim\']\n    else:\n        raise NotImplementedError(\'mean operation must specify a dim\')\n    layer.param.reduction_param.operation = 4\n    layer.param.reduction_param.axis = dim\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _add(input, *args):\n    # check if add a const value\n    if isinstance(args[0], int):\n        print(\'value: \',args[0])\n        x = raw__add__(input, *args)\n        #x = raw(input)\n        layer_name = log.add_layer(name=\'scale\')\n        log.add_blobs([x], name=\'Scale_blob\')\n        layer = caffe_net.Layer_param(name=layer_name, type=\'Scale\',\n                                       bottom=[log.blobs(input)], top=[log.blobs(x)])\n        dim = x.shape[1]\n        layer.param.scale_param.bias_term = True\n        weight = np.ones(dim, dtype=np.float32)\n        bias = args[0] * np.ones(dim, dtype=np.float32)\n        layer.add_data(weight, bias)\n        log.cnet.add_layer(layer)\n        return x\n    # otherwise add a tensor\n    x = raw__add__(input, *args)\n    if not NET_INITTED:\n        return x\n    layer_name = log.add_layer(name=\'add\')\n    top_blobs = log.add_blobs([x], name=\'add_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Eltwise\',\n                                  bottom=[log.blobs(input), log.blobs(args[0])], top=top_blobs)\n    layer.param.eltwise_param.operation = 1  # sum is 1\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _iadd(input, *args):\n    x = raw__iadd__(input, *args)\n    if not NET_INITTED:\n        return x\n    x = x.clone()\n    layer_name = log.add_layer(name=\'add\')\n    top_blobs = log.add_blobs([x], name=\'add_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Eltwise\',\n                                  bottom=[log.blobs(input), log.blobs(args[0])], top=top_blobs)\n    layer.param.eltwise_param.operation = 1  # sum is 1\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _sub(input, *args):\n    x = raw__sub__(input, *args)\n    if not NET_INITTED:\n        return x\n    layer_name = log.add_layer(name=\'sub\')\n    top_blobs = log.add_blobs([x], name=\'sub_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Eltwise\',\n                                  bottom=[log.blobs(input), log.blobs(args[0])], top=top_blobs)\n    layer.param.eltwise_param.operation = 1  # sum is 1\n    layer.param.eltwise_param.coeff.extend([1., -1.])\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _isub(input, *args):\n    x = raw__isub__(input, *args)\n    if not NET_INITTED:\n        return x\n    x = x.clone()\n    layer_name = log.add_layer(name=\'sub\')\n    top_blobs = log.add_blobs([x], name=\'sub_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Eltwise\',\n                                  bottom=[log.blobs(input), log.blobs(args[0])], top=top_blobs)\n    layer.param.eltwise_param.operation = 1  # sum is 1\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _mul(input, *args):\n    x = raw__sub__(input, *args)\n    if not NET_INITTED:\n        return x\n    layer_name = log.add_layer(name=\'mul\')\n    top_blobs = log.add_blobs([x], name=\'mul_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Eltwise\',\n                                  bottom=[log.blobs(input), log.blobs(args[0])], top=top_blobs)\n    layer.param.eltwise_param.operation = 0  # product is 1\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _imul(input, *args):\n    x = raw__isub__(input, *args)\n    if not NET_INITTED:\n        return x\n    x = x.clone()\n    layer_name = log.add_layer(name=\'mul\')\n    top_blobs = log.add_blobs([x], name=\'mul_blob\')\n    layer = caffe_net.Layer_param(name=layer_name, type=\'Eltwise\',\n                                  bottom=[log.blobs(input), log.blobs(args[0])], top=top_blobs)\n    layer.param.eltwise_param.operation = 0  # product is 1\n    layer.param.eltwise_param.coeff.extend([1., -1.])\n    log.cnet.add_layer(layer)\n    return x\n\n\ndef _adaptive_avg_pool2d(raw, input, output_size):\n    _output_size = _list_with_default(output_size, input.size())\n    x = raw(input, _output_size)\n    _pool(\'ave\', raw, input, x, input.shape[2], input.shape[2], 0, False)\n    return x\n\n\n# \xe6\xa0\xb8\xe5\xbf\x83\xe7\xbb\x84\xe4\xbb\xb6\xef\xbc\x8c\xe9\x80\x9a\xe8\xbf\x87\xe8\xaf\xa5\xe7\xb1\xbb\xef\xbc\x8c\xe5\xae\x9e\xe7\x8e\xb0\xe5\xaf\xb9torch\xe7\x9a\x84function\xe4\xb8\xad\xe7\x9a\x84operators\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe8\xaf\xbb\xe5\x8f\x96\nclass Rp(object):\n    def __init__(self, raw, replace, **kwargs):\n        # replace the raw function to replace function\n        self.obj = replace\n        self.raw = raw\n\n    def __call__(self, *args, **kwargs):\n        if not NET_INITTED:\n            return self.raw(*args, **kwargs)\n        for stack in traceback.walk_stack(None):\n            if \'self\' in stack[0].f_locals:\n                layer = stack[0].f_locals[\'self\']\n                if layer in layer_names:\n                    log.pytorch_layer_name = layer_names[layer]\n                    print(layer_names[layer])\n                    break\n        out = self.obj(self.raw, *args, **kwargs)\n        # if isinstance(out,Variable):\n        #     out=[out]\n        return out\n\n\nF.conv2d = Rp(F.conv2d, _conv2d)\nF.linear = Rp(F.linear, _linear)\nF.relu = Rp(F.relu, _relu)\n\nF.leaky_relu = Rp(F.leaky_relu, _leaky_relu)\nF.max_pool2d = Rp(F.max_pool2d, _max_pool2d)\nF.avg_pool2d = Rp(F.avg_pool2d, _avg_pool2d)\nF.dropout = Rp(F.dropout, _dropout)\nF.threshold = Rp(F.threshold, _threshold)\nF.prelu = Rp(F.prelu, _prelu)\nF.batch_norm = Rp(F.batch_norm, _batch_norm)\nF.instance_norm = Rp(F.instance_norm, _instance_norm)\nF.softmax = Rp(F.softmax, _softmax)\nF.conv_transpose2d = Rp(F.conv_transpose2d, _conv_transpose2d)\nF.interpolate = Rp(F.interpolate, _interpolate)\nF.adaptive_avg_pool2d = Rp(F.adaptive_avg_pool2d, _adaptive_avg_pool2d)\n\ntorch.split = Rp(torch.split, _split)\ntorch.max = Rp(torch.max, _max)\ntorch.cat = Rp(torch.cat, _cat)\ntorch.sigmoid = Rp(torch.sigmoid, _sigmoid)\n\n# TODO: other types of the view function\ntry:\n    raw_view = Variable.view\n    Variable.view = _view\n    raw_mean = Variable.mean\n    Variable.mean = _mean\n    raw__add__ = Variable.__add__\n    Variable.__add__ = _add\n    raw__iadd__ = Variable.__iadd__\n    Variable.__iadd__ = _iadd\n    raw__sub__ = Variable.__sub__\n    Variable.__sub__ = _sub\n    raw__isub__ = Variable.__isub__\n    Variable.__isub__ = _isub\n    raw__mul__ = Variable.__mul__\n    Variable.__mul__ = _mul\n    raw__imul__ = Variable.__imul__\n    Variable.__imul__ = _imul\nexcept:\n    # for new version 0.4.0 and later version\n    for t in [torch.Tensor]:\n        raw_view = t.view\n        t.view = _view\n        raw_mean = t.mean\n        t.mean = _mean\n        raw__add__ = t.__add__\n        t.__add__ = _add\n        raw__iadd__ = t.__iadd__\n        t.__iadd__ = _iadd\n        raw__sub__ = t.__sub__\n        t.__sub__ = _sub\n        raw__isub__ = t.__isub__\n        t.__isub__ = _isub\n        raw__mul__ = t.__mul__\n        t.__mul__ = _mul\n        raw__imul__ = t.__imul__\n        t.__imul__ = _imul\n\n\ndef trans_net(net, input_var, name=\'TransferedPytorchModel\'):\n    print(\'Starting Transform, This will take a while\')\n    log.init([input_var])\n    log.cnet.net.name = name\n    log.cnet.net.input.extend([log.blobs(input_var)])\n    log.cnet.net.input_dim.extend(input_var.size())\n    global NET_INITTED\n    NET_INITTED = True\n    for name, layer in net.named_modules():\n        layer_names[layer] = name\n    print(""torch ops name:"", layer_names)\n    out = net.forward(input_var)\n    print(\'Transform Completed\')\n\n\ndef save_prototxt(save_name):\n    log.cnet.save_prototxt(save_name)\n\n\ndef save_caffemodel(save_name):\n    log.cnet.save(save_name)\n'"
fastreid/data/datasets/__init__.py,0,"b'# encoding: utf-8\r\n""""""\r\n@author:  liaoxingyu\r\n@contact: sherlockliao01@gmail.com\r\n""""""\r\n\r\nfrom ...utils.registry import Registry\r\n\r\nDATASET_REGISTRY = Registry(""DATASET"")\r\nDATASET_REGISTRY.__doc__ = """"""\r\nRegistry for datasets\r\nIt must returns an instance of :class:`Backbone`.\r\n""""""\r\n\r\nfrom .cuhk03 import CUHK03\r\nfrom .dukemtmcreid import DukeMTMC\r\nfrom .market1501 import Market1501\r\nfrom .msmt17 import MSMT17\r\nfrom .veri import VeRi\r\nfrom .vehicleid import VehicleID, SmallVehicleID, MediumVehicleID, LargeVehicleID\r\nfrom .veriwild import VeRiWild, SmallVeRiWild, MediumVeRiWild, LargeVeRiWild\r\n'"
fastreid/data/datasets/bases.py,2,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport copy\nimport os\n\nimport numpy as np\nimport torch\nimport logging\n\n\nclass Dataset(object):\n    """"""An abstract class representing a Dataset.\n    This is the base class for ``ImageDataset`` and ``VideoDataset``.\n    Args:\n        train (list): contains tuples of (img_path(s), pid, camid).\n        query (list): contains tuples of (img_path(s), pid, camid).\n        gallery (list): contains tuples of (img_path(s), pid, camid).\n        transform: transform function.\n        mode (str): \'train\', \'query\' or \'gallery\'.\n        combineall (bool): combines train, query and gallery in a\n            dataset for training.\n        verbose (bool): show information.\n    """"""\n    _junk_pids = []  # contains useless person IDs, e.g. background, false detections\n\n    def __init__(self, train, query, gallery, transform=None, mode=\'train\',\n                 combineall=False, verbose=True, **kwargs):\n        self.train = train\n        self.query = query\n        self.gallery = gallery\n        self.transform = transform\n        self.mode = mode\n        self.combineall = combineall\n        self.verbose = verbose\n\n        self.num_train_pids = self.get_num_pids(self.train)\n        self.num_train_cams = self.get_num_cams(self.train)\n\n        if self.combineall:\n            self.combine_all()\n\n        if self.mode == \'train\':\n            self.data = self.train\n        elif self.mode == \'query\':\n            self.data = self.query\n        elif self.mode == \'gallery\':\n            self.data = self.gallery\n        else:\n            raise ValueError(\'Invalid mode. Got {}, but expected to be \'\n                             \'one of [train | query | gallery]\'.format(self.mode))\n\n        # if self.verbose:\n        #     self.show_summary()\n\n    def __getitem__(self, index):\n        raise NotImplementedError\n\n    def __len__(self):\n        return len(self.data)\n\n    # def __add__(self, other):\n    #     """"""Adds two datasets together (only the train set).""""""\n    #     train = copy.deepcopy(self.train)\n    #\n    #     for img_path, pid, camid in other.train:\n    #         pid += self.num_train_pids\n    #         camid += self.num_train_cams\n    #         train.append((img_path, pid, camid))\n    #\n    #     ###################################\n    #     # Things to do beforehand:\n    #     # 1. set verbose=False to avoid unnecessary print\n    #     # 2. set combineall=False because combineall would have been applied\n    #     #    if it was True for a specific dataset, setting it to True will\n    #     #    create new IDs that should have been included\n    #     ###################################\n    #     if isinstance(train[0][0], str):\n    #         return ImageDataset(\n    #             train, self.query, self.gallery,\n    #             transform=self.transform,\n    #             mode=self.mode,\n    #             combineall=False,\n    #             verbose=False\n    #         )\n    #     else:\n    #         return VideoDataset(\n    #             train, self.query, self.gallery,\n    #             transform=self.transform,\n    #             mode=self.mode,\n    #             combineall=False,\n    #             verbose=False\n    #         )\n\n    def __radd__(self, other):\n        """"""Supports sum([dataset1, dataset2, dataset3]).""""""\n        if other == 0:\n            return self\n        else:\n            return self.__add__(other)\n\n    def parse_data(self, data):\n        """"""Parses data list and returns the number of person IDs\n        and the number of camera views.\n        Args:\n            data (list): contains tuples of (img_path(s), pid, camid)\n        """"""\n        pids = set()\n        cams = set()\n        for _, pid, camid in data:\n            pids.add(pid)\n            cams.add(camid)\n        return len(pids), len(cams)\n\n    def get_num_pids(self, data):\n        """"""Returns the number of training person identities.""""""\n        return self.parse_data(data)[0]\n\n    def get_num_cams(self, data):\n        """"""Returns the number of training cameras.""""""\n        return self.parse_data(data)[1]\n\n    def show_summary(self):\n        """"""Shows dataset statistics.""""""\n        pass\n\n    def combine_all(self):\n        """"""Combines train, query and gallery in a dataset for training.""""""\n        combined = copy.deepcopy(self.train)\n\n        def _combine_data(data):\n            for img_path, pid, camid in data:\n                if pid in self._junk_pids:\n                    continue\n                combined.append((img_path, pid, camid))\n\n        _combine_data(self.query)\n        _combine_data(self.gallery)\n\n        self.train = combined\n        self.num_train_pids = self.get_num_pids(self.train)\n\n    def check_before_run(self, required_files):\n        """"""Checks if required files exist before going deeper.\n        Args:\n            required_files (str or list): string file name(s).\n        """"""\n        if isinstance(required_files, str):\n            required_files = [required_files]\n\n        for fpath in required_files:\n            if not os.path.exists(fpath):\n                raise RuntimeError(\'""{}"" is not found\'.format(fpath))\n\n    def __repr__(self):\n        num_train_pids, num_train_cams = self.parse_data(self.train)\n        num_query_pids, num_query_cams = self.parse_data(self.query)\n        num_gallery_pids, num_gallery_cams = self.parse_data(self.gallery)\n\n        msg = \'  ----------------------------------------\\n\' \\\n              \'  subset   | # ids | # items | # cameras\\n\' \\\n              \'  ----------------------------------------\\n\' \\\n              \'  train    | {:5d} | {:7d} | {:9d}\\n\' \\\n              \'  query    | {:5d} | {:7d} | {:9d}\\n\' \\\n              \'  gallery  | {:5d} | {:7d} | {:9d}\\n\' \\\n              \'  ----------------------------------------\\n\' \\\n              \'  items: images/tracklets for image/video dataset\\n\'.format(\n            num_train_pids, len(self.train), num_train_cams,\n            num_query_pids, len(self.query), num_query_cams,\n            num_gallery_pids, len(self.gallery), num_gallery_cams\n        )\n\n        return msg\n\n\nclass ImageDataset(Dataset):\n    """"""A base class representing ImageDataset.\n    All other image datasets should subclass it.\n    ``__getitem__`` returns an image given index.\n    It will return ``img``, ``pid``, ``camid`` and ``img_path``\n    where ``img`` has shape (channel, height, width). As a result,\n    data in each batch has shape (batch_size, channel, height, width).\n    """"""\n\n    def __init__(self, train, query, gallery, **kwargs):\n        super(ImageDataset, self).__init__(train, query, gallery, **kwargs)\n\n    def show_train(self):\n        logger = logging.getLogger(__name__)\n        num_train_pids, num_train_cams = self.parse_data(self.train)\n        logger.info(\'=> Loaded {}\'.format(self.__class__.__name__))\n        logger.info(\'  ----------------------------------------\')\n        logger.info(\'  subset   | # ids | # images | # cameras\')\n        logger.info(\'  ----------------------------------------\')\n        logger.info(\'  train    | {:5d} | {:8d} | {:9d}\'.format(num_train_pids, len(self.train), num_train_cams))\n        logger.info(\'  ----------------------------------------\')\n\n    def show_test(self):\n        logger = logging.getLogger(__name__)\n        num_query_pids, num_query_cams = self.parse_data(self.query)\n        num_gallery_pids, num_gallery_cams = self.parse_data(self.gallery)\n        logger.info(\'=> Loaded {}\'.format(self.__class__.__name__))\n        logger.info(\'  ----------------------------------------\')\n        logger.info(\'  subset   | # ids | # images | # cameras\')\n        logger.info(\'  ----------------------------------------\')\n        logger.info(\'  query    | {:5d} | {:8d} | {:9d}\'.format(num_query_pids, len(self.query), num_query_cams))\n        logger.info(\'  gallery  | {:5d} | {:8d} | {:9d}\'.format(num_gallery_pids, len(self.gallery), num_gallery_cams))\n        logger.info(\'  ----------------------------------------\')\n\n# class VideoDataset(Dataset):\n#     """"""A base class representing VideoDataset.\n#     All other video datasets should subclass it.\n#     ``__getitem__`` returns an image given index.\n#     It will return ``imgs``, ``pid`` and ``camid``\n#     where ``imgs`` has shape (seq_len, channel, height, width). As a result,\n#     data in each batch has shape (batch_size, seq_len, channel, height, width).\n#     """"""\n#\n#     def __init__(self, train, query, gallery, seq_len=15, sample_method=\'evenly\', **kwargs):\n#         super(VideoDataset, self).__init__(train, query, gallery, **kwargs)\n#         self.seq_len = seq_len\n#         self.sample_method = sample_method\n#\n#         if self.transform is None:\n#             raise RuntimeError(\'transform must not be None\')\n#\n#     def __getitem__(self, index):\n#         img_paths, pid, camid = self.data[index]\n#         num_imgs = len(img_paths)\n#\n#         if self.sample_method == \'random\':\n#             # Randomly samples seq_len images from a tracklet of length num_imgs,\n#             # if num_imgs is smaller than seq_len, then replicates images\n#             indices = np.arange(num_imgs)\n#             replace = False if num_imgs >= self.seq_len else True\n#             indices = np.random.choice(indices, size=self.seq_len, replace=replace)\n#             # sort indices to keep temporal order (comment it to be order-agnostic)\n#             indices = np.sort(indices)\n#\n#         elif self.sample_method == \'evenly\':\n#             # Evenly samples seq_len images from a tracklet\n#             if num_imgs >= self.seq_len:\n#                 num_imgs -= num_imgs % self.seq_len\n#                 indices = np.arange(0, num_imgs, num_imgs / self.seq_len)\n#             else:\n#                 # if num_imgs is smaller than seq_len, simply replicate the last image\n#                 # until the seq_len requirement is satisfied\n#                 indices = np.arange(0, num_imgs)\n#                 num_pads = self.seq_len - num_imgs\n#                 indices = np.concatenate([indices, np.ones(num_pads).astype(np.int32) * (num_imgs - 1)])\n#             assert len(indices) == self.seq_len\n#\n#         elif self.sample_method == \'all\':\n#             # Samples all images in a tracklet. batch_size must be set to 1\n#             indices = np.arange(num_imgs)\n#\n#         else:\n#             raise ValueError(\'Unknown sample method: {}\'.format(self.sample_method))\n#\n#         imgs = []\n#         for index in indices:\n#             img_path = img_paths[int(index)]\n#             img = read_image(img_path)\n#             if self.transform is not None:\n#                 img = self.transform(img)\n#             img = img.unsqueeze(0)  # img must be torch.Tensor\n#             imgs.append(img)\n#         imgs = torch.cat(imgs, dim=0)\n#\n#         return imgs, pid, camid\n#\n#     def show_summary(self):\n#         num_train_pids, num_train_cams = self.parse_data(self.train)\n#         num_query_pids, num_query_cams = self.parse_data(self.query)\n#         num_gallery_pids, num_gallery_cams = self.parse_data(self.gallery)\n#\n#         print(\'=> Loaded {}\'.format(self.__class__.__name__))\n#         print(\'  -------------------------------------------\')\n#         print(\'  subset   | # ids | # tracklets | # cameras\')\n#         print(\'  -------------------------------------------\')\n#         print(\'  train    | {:5d} | {:11d} | {:9d}\'.format(num_train_pids, len(self.train), num_train_cams))\n#         print(\'  query    | {:5d} | {:11d} | {:9d}\'.format(num_query_pids, len(self.query), num_query_cams))\n#         print(\'  gallery  | {:5d} | {:11d} | {:9d}\'.format(num_gallery_pids, len(self.gallery), num_gallery_cams))\n#         print(\'  -------------------------------------------\')\n'"
fastreid/data/datasets/cuhk03.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: liaoxingyu2@jd.com\n""""""\n\nimport json\nimport os.path as osp\n\n# from utils.iotools import mkdir_if_missing, write_json, read_json\nfrom fastreid.utils.file_io import PathManager\nfrom .bases import ImageDataset\nfrom fastreid.data.datasets import DATASET_REGISTRY\n\n\n@DATASET_REGISTRY.register()\nclass CUHK03(ImageDataset):\n    """"""CUHK03.\n\n    Reference:\n        Li et al. DeepReID: Deep Filter Pairing Neural Network for Person Re-identification. CVPR 2014.\n\n    URL: `<http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html#!>`_\n\n    Dataset statistics:\n        - identities: 1360.\n        - images: 13164.\n        - cameras: 6.\n        - splits: 20 (classic).\n    """"""\n    dataset_dir = \'cuhk03\'\n    dataset_url = None\n\n    def __init__(self, root=\'datasets\', split_id=0, cuhk03_labeled=False, cuhk03_classic_split=False, **kwargs):\n        # self.root = osp.abspath(osp.expanduser(root))\n        self.root = root\n        self.dataset_dir = osp.join(self.root, self.dataset_dir)\n\n        self.data_dir = osp.join(self.dataset_dir, \'cuhk03_release\')\n        self.raw_mat_path = osp.join(self.data_dir, \'cuhk-03.mat\')\n\n        self.imgs_detected_dir = osp.join(self.dataset_dir, \'images_detected\')\n        self.imgs_labeled_dir = osp.join(self.dataset_dir, \'images_labeled\')\n\n        self.split_classic_det_json_path = osp.join(self.dataset_dir, \'splits_classic_detected.json\')\n        self.split_classic_lab_json_path = osp.join(self.dataset_dir, \'splits_classic_labeled.json\')\n\n        self.split_new_det_json_path = osp.join(self.dataset_dir, \'splits_new_detected.json\')\n        self.split_new_lab_json_path = osp.join(self.dataset_dir, \'splits_new_labeled.json\')\n\n        self.split_new_det_mat_path = osp.join(self.dataset_dir, \'cuhk03_new_protocol_config_detected.mat\')\n        self.split_new_lab_mat_path = osp.join(self.dataset_dir, \'cuhk03_new_protocol_config_labeled.mat\')\n\n        required_files = [\n            self.dataset_dir,\n            self.data_dir,\n            self.raw_mat_path,\n            self.split_new_det_mat_path,\n            self.split_new_lab_mat_path\n        ]\n        self.check_before_run(required_files)\n\n        self.preprocess_split()\n\n        if cuhk03_labeled:\n            split_path = self.split_classic_lab_json_path if cuhk03_classic_split else self.split_new_lab_json_path\n        else:\n            split_path = self.split_classic_det_json_path if cuhk03_classic_split else self.split_new_det_json_path\n\n        with PathManager.open(split_path) as f:\n            splits = json.load(f)\n        # splits = read_json(split_path)\n        assert split_id < len(splits), \'Condition split_id ({}) < len(splits) ({}) is false\'.format(split_id,\n                                                                                                    len(splits))\n        split = splits[split_id]\n\n        train = split[\'train\']\n        query = split[\'query\']\n        gallery = split[\'gallery\']\n\n        super(CUHK03, self).__init__(train, query, gallery, **kwargs)\n\n    def preprocess_split(self):\n        # This function is a bit complex and ugly, what it does is\n        # 1. extract data from cuhk-03.mat and save as png images\n        # 2. create 20 classic splits (Li et al. CVPR\'14)\n        # 3. create new split (Zhong et al. CVPR\'17)\n        if osp.exists(self.imgs_labeled_dir) \\\n                and osp.exists(self.imgs_detected_dir) \\\n                and osp.exists(self.split_classic_det_json_path) \\\n                and osp.exists(self.split_classic_lab_json_path) \\\n                and osp.exists(self.split_new_det_json_path) \\\n                and osp.exists(self.split_new_lab_json_path):\n            return\n\n        import h5py\n        from imageio import imwrite\n        from scipy.io import loadmat\n\n        PathManager.mkdirs(self.imgs_detected_dir)\n        PathManager.mkdirs(self.imgs_labeled_dir)\n\n        print(\'Extract image data from ""{}"" and save as png\'.format(self.raw_mat_path))\n        mat = h5py.File(self.raw_mat_path, \'r\')\n\n        def _deref(ref):\n            return mat[ref][:].T\n\n        def _process_images(img_refs, campid, pid, save_dir):\n            img_paths = []  # Note: some persons only have images for one view\n            for imgid, img_ref in enumerate(img_refs):\n                img = _deref(img_ref)\n                if img.size == 0 or img.ndim < 3:\n                    continue  # skip empty cell\n                # images are saved with the following format, index-1 (ensure uniqueness)\n                # campid: index of camera pair (1-5)\n                # pid: index of person in \'campid\'-th camera pair\n                # viewid: index of view, {1, 2}\n                # imgid: index of image, (1-10)\n                viewid = 1 if imgid < 5 else 2\n                img_name = \'{:01d}_{:03d}_{:01d}_{:02d}.png\'.format(campid + 1, pid + 1, viewid, imgid + 1)\n                img_path = osp.join(save_dir, img_name)\n                if not osp.isfile(img_path):\n                    imwrite(img_path, img)\n                img_paths.append(img_path)\n            return img_paths\n\n        def _extract_img(image_type):\n            print(\'Processing {} images ...\'.format(image_type))\n            meta_data = []\n            imgs_dir = self.imgs_detected_dir if image_type == \'detected\' else self.imgs_labeled_dir\n            for campid, camp_ref in enumerate(mat[image_type][0]):\n                camp = _deref(camp_ref)\n                num_pids = camp.shape[0]\n                for pid in range(num_pids):\n                    img_paths = _process_images(camp[pid, :], campid, pid, imgs_dir)\n                    assert len(img_paths) > 0, \'campid{}-pid{} has no images\'.format(campid, pid)\n                    meta_data.append((campid + 1, pid + 1, img_paths))\n                print(\'- done camera pair {} with {} identities\'.format(campid + 1, num_pids))\n            return meta_data\n\n        meta_detected = _extract_img(\'detected\')\n        meta_labeled = _extract_img(\'labeled\')\n\n        def _extract_classic_split(meta_data, test_split):\n            train, test = [], []\n            num_train_pids, num_test_pids = 0, 0\n            num_train_imgs, num_test_imgs = 0, 0\n            for i, (campid, pid, img_paths) in enumerate(meta_data):\n\n                if [campid, pid] in test_split:\n                    for img_path in img_paths:\n                        camid = int(osp.basename(img_path).split(\'_\')[2]) - 1  # make it 0-based\n                        test.append((img_path, num_test_pids, camid))\n                    num_test_pids += 1\n                    num_test_imgs += len(img_paths)\n                else:\n                    for img_path in img_paths:\n                        camid = int(osp.basename(img_path).split(\'_\')[2]) - 1  # make it 0-based\n                        train.append((img_path, num_train_pids, camid))\n                    num_train_pids += 1\n                    num_train_imgs += len(img_paths)\n            return train, num_train_pids, num_train_imgs, test, num_test_pids, num_test_imgs\n\n        print(\'Creating classic splits (# = 20) ...\')\n        splits_classic_det, splits_classic_lab = [], []\n        for split_ref in mat[\'testsets\'][0]:\n            test_split = _deref(split_ref).tolist()\n\n            # create split for detected images\n            train, num_train_pids, num_train_imgs, test, num_test_pids, num_test_imgs = \\\n                _extract_classic_split(meta_detected, test_split)\n            splits_classic_det.append({\n                \'train\': train,\n                \'query\': test,\n                \'gallery\': test,\n                \'num_train_pids\': num_train_pids,\n                \'num_train_imgs\': num_train_imgs,\n                \'num_query_pids\': num_test_pids,\n                \'num_query_imgs\': num_test_imgs,\n                \'num_gallery_pids\': num_test_pids,\n                \'num_gallery_imgs\': num_test_imgs\n            })\n\n            # create split for labeled images\n            train, num_train_pids, num_train_imgs, test, num_test_pids, num_test_imgs = \\\n                _extract_classic_split(meta_labeled, test_split)\n            splits_classic_lab.append({\n                \'train\': train,\n                \'query\': test,\n                \'gallery\': test,\n                \'num_train_pids\': num_train_pids,\n                \'num_train_imgs\': num_train_imgs,\n                \'num_query_pids\': num_test_pids,\n                \'num_query_imgs\': num_test_imgs,\n                \'num_gallery_pids\': num_test_pids,\n                \'num_gallery_imgs\': num_test_imgs\n            })\n\n        with PathManager.open(self.split_classic_det_json_path, \'w\') as f:\n            json.dump(splits_classic_det, f, indent=4, separators=(\',\', \': \'))\n        with PathManager.open(self.split_classic_lab_json_path, \'w\') as f:\n            json.dump(splits_classic_lab, f, indent=4, separators=(\',\', \': \'))\n\n        def _extract_set(filelist, pids, pid2label, idxs, img_dir, relabel):\n            tmp_set = []\n            unique_pids = set()\n            for idx in idxs:\n                img_name = filelist[idx][0]\n                camid = int(img_name.split(\'_\')[2]) - 1  # make it 0-based\n                pid = pids[idx]\n                if relabel:\n                    pid = pid2label[pid]\n                img_path = osp.join(img_dir, img_name)\n                tmp_set.append((img_path, int(pid), camid))\n                unique_pids.add(pid)\n            return tmp_set, len(unique_pids), len(idxs)\n\n        def _extract_new_split(split_dict, img_dir):\n            train_idxs = split_dict[\'train_idx\'].flatten() - 1  # index-0\n            pids = split_dict[\'labels\'].flatten()\n            train_pids = set(pids[train_idxs])\n            pid2label = {pid: label for label, pid in enumerate(train_pids)}\n            query_idxs = split_dict[\'query_idx\'].flatten() - 1\n            gallery_idxs = split_dict[\'gallery_idx\'].flatten() - 1\n            filelist = split_dict[\'filelist\'].flatten()\n            train_info = _extract_set(filelist, pids, pid2label, train_idxs, img_dir, relabel=True)\n            query_info = _extract_set(filelist, pids, pid2label, query_idxs, img_dir, relabel=False)\n            gallery_info = _extract_set(filelist, pids, pid2label, gallery_idxs, img_dir, relabel=False)\n            return train_info, query_info, gallery_info\n\n        print(\'Creating new split for detected images (767/700) ...\')\n        train_info, query_info, gallery_info = _extract_new_split(\n            loadmat(self.split_new_det_mat_path),\n            self.imgs_detected_dir\n        )\n        split = [{\n            \'train\': train_info[0],\n            \'query\': query_info[0],\n            \'gallery\': gallery_info[0],\n            \'num_train_pids\': train_info[1],\n            \'num_train_imgs\': train_info[2],\n            \'num_query_pids\': query_info[1],\n            \'num_query_imgs\': query_info[2],\n            \'num_gallery_pids\': gallery_info[1],\n            \'num_gallery_imgs\': gallery_info[2]\n        }]\n        write_json(split, self.split_new_det_json_path)\n\n        print(\'Creating new split for labeled images (767/700) ...\')\n        train_info, query_info, gallery_info = _extract_new_split(\n            loadmat(self.split_new_lab_mat_path),\n            self.imgs_labeled_dir\n        )\n        split = [{\n            \'train\': train_info[0],\n            \'query\': query_info[0],\n            \'gallery\': gallery_info[0],\n            \'num_train_pids\': train_info[1],\n            \'num_train_imgs\': train_info[2],\n            \'num_query_pids\': query_info[1],\n            \'num_query_imgs\': query_info[2],\n            \'num_gallery_pids\': gallery_info[1],\n            \'num_gallery_imgs\': gallery_info[2]\n        }]\n        write_json(split, self.split_new_lab_json_path)\n'"
fastreid/data/datasets/dukemtmcreid.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: liaoxingyu2@jd.com\n""""""\n\nimport glob\nimport os.path as osp\nimport re\n\nfrom .bases import ImageDataset\nfrom ..datasets import DATASET_REGISTRY\n\n\n@DATASET_REGISTRY.register()\nclass DukeMTMC(ImageDataset):\n    """"""DukeMTMC-reID.\n\n    Reference:\n        - Ristani et al. Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking. ECCVW 2016.\n        - Zheng et al. Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro. ICCV 2017.\n\n    URL: `<https://github.com/layumi/DukeMTMC-reID_evaluation>`_\n\n    Dataset statistics:\n        - identities: 1404 (train + query).\n        - images:16522 (train) + 2228 (query) + 17661 (gallery).\n        - cameras: 8.\n    """"""\n    dataset_dir = \'DukeMTMC-reID\'\n    dataset_url = \'http://vision.cs.duke.edu/DukeMTMC/data/misc/DukeMTMC-reID.zip\'\n\n    def __init__(self, root=\'datasets\', **kwargs):\n        # self.root = osp.abspath(osp.expanduser(root))\n        self.root = root\n        self.dataset_dir = osp.join(self.root, self.dataset_dir)\n        self.train_dir = osp.join(self.dataset_dir, \'bounding_box_train\')\n        self.query_dir = osp.join(self.dataset_dir, \'query\')\n        self.gallery_dir = osp.join(self.dataset_dir, \'bounding_box_test\')\n\n        required_files = [\n            self.dataset_dir,\n            self.train_dir,\n            self.query_dir,\n            self.gallery_dir,\n        ]\n        self.check_before_run(required_files)\n\n        train = self.process_dir(self.train_dir)\n        query = self.process_dir(self.query_dir)\n        gallery = self.process_dir(self.gallery_dir)\n\n        super(DukeMTMC, self).__init__(train, query, gallery, **kwargs)\n\n    def process_dir(self, dir_path):\n        img_paths = glob.glob(osp.join(dir_path, \'*.jpg\'))\n        pattern = re.compile(r\'([-\\d]+)_c(\\d)\')\n\n        data = []\n        for img_path in img_paths:\n            pid, camid = map(int, pattern.search(img_path).groups())\n            assert 1 <= camid <= 8\n            camid -= 1  # index starts from 0\n            data.append((img_path, pid, camid))\n\n        return data\n'"
fastreid/data/datasets/market1501.py,0,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport glob\nimport os.path as osp\nimport re\nimport warnings\n\nfrom .bases import ImageDataset\nfrom ..datasets import DATASET_REGISTRY\n\n\n@DATASET_REGISTRY.register()\nclass Market1501(ImageDataset):\n    """"""Market1501.\n\n    Reference:\n        Zheng et al. Scalable Person Re-identification: A Benchmark. ICCV 2015.\n\n    URL: `<http://www.liangzheng.org/Project/project_reid.html>`_\n\n    Dataset statistics:\n        - identities: 1501 (+1 for background).\n        - images: 12936 (train) + 3368 (query) + 15913 (gallery).\n    """"""\n    _junk_pids = [0, -1]\n    dataset_dir = \'\'\n    dataset_url = \'http://188.138.127.15:81/Datasets/Market-1501-v15.09.15.zip\'\n\n    def __init__(self, root=\'datasets\', market1501_500k=False, **kwargs):\n        # self.root = osp.abspath(osp.expanduser(root))\n        self.root = root\n        self.dataset_dir = osp.join(self.root, self.dataset_dir)\n\n        # allow alternative directory structure\n        self.data_dir = self.dataset_dir\n        data_dir = osp.join(self.data_dir, \'Market-1501-v15.09.15\')\n        if osp.isdir(data_dir):\n            self.data_dir = data_dir\n        else:\n            warnings.warn(\'The current data structure is deprecated. Please \'\n                          \'put data folders such as ""bounding_box_train"" under \'\n                          \'""Market-1501-v15.09.15"".\')\n\n        self.train_dir = osp.join(self.data_dir, \'bounding_box_train\')\n        self.query_dir = osp.join(self.data_dir, \'query\')\n        self.gallery_dir = osp.join(self.data_dir, \'bounding_box_test\')\n        self.extra_gallery_dir = osp.join(self.data_dir, \'images\')\n        self.market1501_500k = market1501_500k\n\n        required_files = [\n            self.data_dir,\n            self.train_dir,\n            self.query_dir,\n            self.gallery_dir,\n        ]\n        if self.market1501_500k:\n            required_files.append(self.extra_gallery_dir)\n        self.check_before_run(required_files)\n\n        train = self.process_dir(self.train_dir)\n        query = self.process_dir(self.query_dir)\n        gallery = self.process_dir(self.gallery_dir)\n        if self.market1501_500k:\n            gallery += self.process_dir(self.extra_gallery_dir)\n\n        super(Market1501, self).__init__(train, query, gallery, **kwargs)\n\n    def process_dir(self, dir_path):\n        img_paths = glob.glob(osp.join(dir_path, \'*.jpg\'))\n        pattern = re.compile(r\'([-\\d]+)_c(\\d)\')\n\n        data = []\n        for img_path in img_paths:\n            pid, camid = map(int, pattern.search(img_path).groups())\n            if pid == -1:\n                continue  # junk images are just ignored\n            assert 0 <= pid <= 1501  # pid == 0 means background\n            assert 1 <= camid <= 6\n            camid -= 1  # index starts from 0\n            data.append((img_path, pid, camid))\n\n        return data\n'"
fastreid/data/datasets/msmt17.py,0,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport sys\nimport os\nimport os.path as osp\n\nfrom .bases import ImageDataset\nfrom ..datasets import DATASET_REGISTRY\n##### Log #####\n# 22.01.2019\n# - add v2\n# - v1 and v2 differ in dir names\n# - note that faces in v2 are blurred\nTRAIN_DIR_KEY = \'train_dir\'\nTEST_DIR_KEY = \'test_dir\'\nVERSION_DICT = {\n    \'MSMT17_V1\': {\n        TRAIN_DIR_KEY: \'train\',\n        TEST_DIR_KEY: \'test\',\n    },\n    \'MSMT17_V2\': {\n        TRAIN_DIR_KEY: \'mask_train_v2\',\n        TEST_DIR_KEY: \'mask_test_v2\',\n    }\n}\n\n\n@DATASET_REGISTRY.register()\nclass MSMT17(ImageDataset):\n    """"""MSMT17.\n    Reference:\n        Wei et al. Person Transfer GAN to Bridge Domain Gap for Person Re-Identification. CVPR 2018.\n    URL: `<http://www.pkuvmc.com/publications/msmt17.html>`_\n\n    Dataset statistics:\n        - identities: 4101.\n        - images: 32621 (train) + 11659 (query) + 82161 (gallery).\n        - cameras: 15.\n    """"""\n    # dataset_dir = \'MSMT17_V2\'\n    dataset_url = None\n\n    def __init__(self, root=\'datasets\', **kwargs):\n        self.root = root\n        self.dataset_dir = self.root\n\n        has_main_dir = False\n        for main_dir in VERSION_DICT:\n            if osp.exists(osp.join(self.dataset_dir, main_dir)):\n                train_dir = VERSION_DICT[main_dir][TRAIN_DIR_KEY]\n                test_dir = VERSION_DICT[main_dir][TEST_DIR_KEY]\n                has_main_dir = True\n                break\n        assert has_main_dir, \'Dataset folder not found\'\n\n        self.train_dir = osp.join(self.dataset_dir, main_dir, train_dir)\n        self.test_dir = osp.join(self.dataset_dir, main_dir, test_dir)\n        self.list_train_path = osp.join(self.dataset_dir, main_dir, \'list_train.txt\')\n        self.list_val_path = osp.join(self.dataset_dir, main_dir, \'list_val.txt\')\n        self.list_query_path = osp.join(self.dataset_dir, main_dir, \'list_query.txt\')\n        self.list_gallery_path = osp.join(self.dataset_dir, main_dir, \'list_gallery.txt\')\n\n        required_files = [\n            self.dataset_dir,\n            self.train_dir,\n            self.test_dir\n        ]\n        self.check_before_run(required_files)\n\n        train = self.process_dir(self.train_dir, self.list_train_path)\n        val = self.process_dir(self.train_dir, self.list_val_path)\n        query = self.process_dir(self.test_dir, self.list_query_path)\n        gallery = self.process_dir(self.test_dir, self.list_gallery_path)\n\n        num_train_pids = self.get_num_pids(train)\n        query_tmp = []\n        for img_path, pid, camid in query:\n            query_tmp.append((img_path, pid+num_train_pids, camid))\n        del query\n        query = query_tmp\n\n        gallery_temp = []\n        for img_path, pid, camid in gallery:\n            gallery_temp.append((img_path, pid+num_train_pids, camid))\n        del gallery\n        gallery = gallery_temp\n\n        # Note: to fairly compare with published methods on the conventional ReID setting,\n        #       do not add val images to the training set.\n        if \'combineall\' in kwargs and kwargs[\'combineall\']:\n            train += val\n\n        super(MSMT17, self).__init__(train, query, gallery, **kwargs)\n\n    def process_dir(self, dir_path, list_path):\n        with open(list_path, \'r\') as txt:\n            lines = txt.readlines()\n\n        data = []\n\n        for img_idx, img_info in enumerate(lines):\n            img_path, pid = img_info.split(\' \')\n            pid = int(pid)  # no need to relabel\n            camid = int(img_path.split(\'_\')[2]) - 1  # index starts from 0\n            img_path = osp.join(dir_path, img_path)\n            data.append((img_path, pid, camid))\n\n        return data'"
fastreid/data/datasets/vehicleid.py,0,"b'# encoding: utf-8\r\n""""""\r\n@author:  Jinkai Zheng\r\n@contact: 1315673509@qq.com\r\n""""""\r\n\r\nimport os.path as osp\r\nimport random\r\n\r\nfrom .bases import ImageDataset\r\nfrom ..datasets import DATASET_REGISTRY\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass VehicleID(ImageDataset):\r\n    """"""VehicleID.\r\n\r\n    Reference:\r\n        Liu et al. Deep relative distance learning: Tell the difference between similar vehicles. CVPR 2016.\r\n\r\n    URL: `<https://pkuml.org/resources/pku-vehicleid.html>`_\r\n\r\n    Train dataset statistics:\r\n        - identities: 13164.\r\n        - images: 113346.\r\n    """"""\r\n    dataset_dir = \'vehicleid\'\r\n\r\n    def __init__(self, root=\'datasets\', test_list=\'\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n\r\n        self.image_dir = osp.join(self.dataset_dir, \'image\')\r\n        self.train_list = osp.join(self.dataset_dir, \'train_test_split/train_list.txt\')\r\n        if test_list:\r\n            self.test_list = test_list\r\n        else:\r\n            self.test_list = osp.join(self.dataset_dir, \'train_test_split/test_list_13164.txt\')\r\n\r\n        required_files = [\r\n            self.dataset_dir,\r\n            self.image_dir,\r\n            self.train_list,\r\n            self.test_list,\r\n        ]\r\n        self.check_before_run(required_files)\r\n\r\n        train = self.process_dir(self.train_list, is_train=True)\r\n        query, gallery = self.process_dir(self.test_list, is_train=False)\r\n\r\n        super(VehicleID, self).__init__(train, query, gallery, **kwargs)\r\n\r\n    def process_dir(self, list_file, is_train=True):\r\n        img_list_lines = open(list_file, \'r\').readlines()\r\n\r\n        dataset = []\r\n        for idx, line in enumerate(img_list_lines):\r\n            line = line.strip()\r\n            vid = line.split(\' \')[1]\r\n            imgid = line.split(\' \')[0]\r\n            img_path = osp.join(self.image_dir, imgid + \'.jpg\')\r\n            dataset.append((img_path, int(vid), int(imgid)))\r\n\r\n        random.shuffle(dataset)\r\n        vid_container = set()\r\n        if is_train:\r\n            return dataset\r\n        else:\r\n            query = []\r\n            gallery = []\r\n            for sample in dataset:\r\n                if sample[1] not in vid_container:\r\n                    vid_container.add(sample[1])\r\n                    gallery.append(sample)\r\n                else:\r\n                    query.append(sample)\r\n\r\n            return query, gallery\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass SmallVehicleID(VehicleID):\r\n    """"""VehicleID.\r\n    Small test dataset statistics:\r\n        - identities: 800.\r\n        - images: 6493.\r\n    """"""\r\n\r\n    def __init__(self, root=\'datasets\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n        self.test_list = osp.join(self.dataset_dir, \'train_test_split/test_list_800.txt\')\r\n\r\n        super(SmallVehicleID, self).__init__(root, self.test_list, **kwargs)\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass MediumVehicleID(VehicleID):\r\n    """"""VehicleID.\r\n    Medium test dataset statistics:\r\n        - identities: 1600.\r\n        - images: 13377.\r\n    """"""\r\n\r\n    def __init__(self, root=\'datasets\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n        self.test_list = osp.join(self.dataset_dir, \'train_test_split/test_list_1600.txt\')\r\n\r\n        super(MediumVehicleID, self).__init__(root, self.test_list, **kwargs)\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass LargeVehicleID(VehicleID):\r\n    """"""VehicleID.\r\n    Large test dataset statistics:\r\n        - identities: 2400.\r\n        - images: 19777.\r\n    """"""\r\n\r\n    def __init__(self, root=\'datasets\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n        self.test_list = osp.join(self.dataset_dir, \'train_test_split/test_list_2400.txt\')\r\n\r\n        super(LargeVehicleID, self).__init__(root, self.test_list, **kwargs)\r\n'"
fastreid/data/datasets/veri.py,0,"b'# encoding: utf-8\r\n""""""\r\n@author:  Jinkai Zheng\r\n@contact: 1315673509@qq.com\r\n""""""\r\n\r\nimport glob\r\nimport os.path as osp\r\nimport re\r\n\r\nfrom .bases import ImageDataset\r\nfrom ..datasets import DATASET_REGISTRY\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass VeRi(ImageDataset):\r\n    """"""VeRi.\r\n\r\n    Reference:\r\n        Liu et al. A Deep Learning based Approach for Progressive Vehicle Re-Identification. ECCV 2016.\r\n\r\n    URL: `<https://vehiclereid.github.io/VeRi/>`_\r\n\r\n    Dataset statistics:\r\n        - identities: 775.\r\n        - images: 37778 (train) + 1678 (query) + 11579 (gallery).\r\n    """"""\r\n    dataset_dir = \'veri\'\r\n\r\n    def __init__(self, root=\'datasets\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n\r\n        self.train_dir = osp.join(self.dataset_dir, \'image_train\')\r\n        self.query_dir = osp.join(self.dataset_dir, \'image_query\')\r\n        self.gallery_dir = osp.join(self.dataset_dir, \'image_test\')\r\n\r\n        required_files = [\r\n            self.dataset_dir,\r\n            self.train_dir,\r\n            self.query_dir,\r\n            self.gallery_dir,\r\n        ]\r\n        self.check_before_run(required_files)\r\n\r\n        train = self.process_dir(self.train_dir)\r\n        query = self.process_dir(self.query_dir)\r\n        gallery = self.process_dir(self.gallery_dir)\r\n\r\n        super(VeRi, self).__init__(train, query, gallery, **kwargs)\r\n\r\n    def process_dir(self, dir_path):\r\n        img_paths = glob.glob(osp.join(dir_path, \'*.jpg\'))\r\n        pattern = re.compile(r\'([\\d]+)_c(\\d\\d\\d)\')\r\n\r\n        data = []\r\n        for img_path in img_paths:\r\n            pid, camid = map(int, pattern.search(img_path).groups())\r\n            if pid == -1: continue  # junk images are just ignored\r\n            assert 1 <= pid <= 776\r\n            assert 1 <= camid <= 20\r\n            camid -= 1  # index starts from 0\r\n            data.append((img_path, pid, camid))\r\n\r\n        return data\r\n'"
fastreid/data/datasets/veriwild.py,0,"b'# encoding: utf-8\r\n""""""\r\n@author:  Jinkai Zheng\r\n@contact: 1315673509@qq.com\r\n""""""\r\n\r\nimport os.path as osp\r\n\r\nfrom .bases import ImageDataset\r\nfrom ..datasets import DATASET_REGISTRY\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass VeRiWild(ImageDataset):\r\n    """"""VeRi-Wild.\r\n\r\n    Reference:\r\n        Lou et al. A Large-Scale Dataset for Vehicle Re-Identification in the Wild. CVPR 2019.\r\n\r\n    URL: `<https://github.com/PKU-IMRE/VERI-Wild>`_\r\n\r\n    Train dataset statistics:\r\n        - identities: 30671.\r\n        - images: 277797.\r\n    """"""\r\n    dataset_dir = \'VERI-Wild\'\r\n\r\n    def __init__(self, root=\'datasets\', query_list=\'\', gallery_list=\'\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n\r\n        self.image_dir = osp.join(self.dataset_dir, \'images\')\r\n        self.train_list = osp.join(self.dataset_dir, \'train_test_split/train_list.txt\')\r\n        self.vehicle_info = osp.join(self.dataset_dir, \'train_test_split/vehicle_info.txt\')\r\n        if query_list and gallery_list:\r\n            self.query_list = query_list\r\n            self.gallery_list = gallery_list\r\n        else:\r\n            self.query_list = osp.join(self.dataset_dir, \'train_test_split/test_10000_query.txt\')\r\n            self.gallery_list = osp.join(self.dataset_dir, \'train_test_split/test_10000.txt\')\r\n\r\n        required_files = [\r\n            self.image_dir,\r\n            self.train_list,\r\n            self.query_list,\r\n            self.gallery_list,\r\n            self.vehicle_info,\r\n        ]\r\n        self.check_before_run(required_files)\r\n\r\n        self.imgid2vid, self.imgid2camid, self.imgid2imgpath = self.process_vehicle(self.vehicle_info)\r\n\r\n        train = self.process_dir(self.train_list)\r\n        query = self.process_dir(self.query_list)\r\n        gallery = self.process_dir(self.gallery_list)\r\n\r\n        super(VeRiWild, self).__init__(train, query, gallery, **kwargs)\r\n\r\n    def process_dir(self, img_list):\r\n        img_list_lines = open(img_list, \'r\').readlines()\r\n\r\n        dataset = []\r\n        for idx, line in enumerate(img_list_lines):\r\n            line = line.strip()\r\n            vid = line.split(\'/\')[0]\r\n            imgid = line.split(\'/\')[1]\r\n            dataset.append((self.imgid2imgpath[imgid], int(vid), int(self.imgid2camid[imgid])))\r\n\r\n        assert len(dataset) == len(img_list_lines)\r\n        return dataset\r\n\r\n    def process_vehicle(self, vehicle_info):\r\n        imgid2vid = {}\r\n        imgid2camid = {}\r\n        imgid2imgpath = {}\r\n        vehicle_info_lines = open(vehicle_info, \'r\').readlines()\r\n\r\n        for idx, line in enumerate(vehicle_info_lines[1:]):\r\n            vid = line.strip().split(\'/\')[0]\r\n            imgid = line.strip().split(\';\')[0].split(\'/\')[1]\r\n            camid = line.strip().split(\';\')[1]\r\n            img_path = osp.join(self.image_dir, vid, imgid + \'.jpg\')\r\n            imgid2vid[imgid] = vid\r\n            imgid2camid[imgid] = camid\r\n            imgid2imgpath[imgid] = img_path\r\n\r\n        assert len(imgid2vid) == len(vehicle_info_lines) - 1\r\n        return imgid2vid, imgid2camid, imgid2imgpath\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass SmallVeRiWild(VeRiWild):\r\n    """"""VeRi-Wild.\r\n    Small test dataset statistics:\r\n        - identities: 3000.\r\n        - images: 41861.\r\n    """"""\r\n\r\n    def __init__(self, root=\'datasets\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n        self.query_list = osp.join(self.dataset_dir, \'train_test_split/test_3000_query.txt\')\r\n        self.gallery_list = osp.join(self.dataset_dir, \'train_test_split/test_3000.txt\')\r\n\r\n        super(SmallVeRiWild, self).__init__(root, self.query_list, self.gallery_list, **kwargs)\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass MediumVeRiWild(VeRiWild):\r\n    """"""VeRi-Wild.\r\n    Medium test dataset statistics:\r\n        - identities: 5000.\r\n        - images: 69389.\r\n    """"""\r\n\r\n    def __init__(self, root=\'datasets\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n        self.query_list = osp.join(self.dataset_dir, \'train_test_split/test_5000_query.txt\')\r\n        self.gallery_list = osp.join(self.dataset_dir, \'train_test_split/test_5000.txt\')\r\n\r\n        super(MediumVeRiWild, self).__init__(root, self.query_list, self.gallery_list, **kwargs)\r\n\r\n\r\n@DATASET_REGISTRY.register()\r\nclass LargeVeRiWild(VeRiWild):\r\n    """"""VeRi-Wild.\r\n    Large test dataset statistics:\r\n        - identities: 10000.\r\n        - images: 138517.\r\n    """"""\r\n\r\n    def __init__(self, root=\'datasets\', **kwargs):\r\n        self.dataset_dir = osp.join(root, self.dataset_dir)\r\n        self.query_list = osp.join(self.dataset_dir, \'train_test_split/test_10000_query.txt\')\r\n        self.gallery_list = osp.join(self.dataset_dir, \'train_test_split/test_10000.txt\')\r\n\r\n        super(LargeVeRiWild, self).__init__(root, self.query_list, self.gallery_list, **kwargs)\r\n'"
fastreid/data/samplers/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom .triplet_sampler import RandomIdentitySampler\nfrom .data_sampler import TrainingSampler, InferenceSampler\n'"
fastreid/data/samplers/data_sampler.py,1,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nimport itertools\nfrom typing import Optional\n\nimport numpy as np\nfrom torch.utils.data import Sampler\n\n\nclass TrainingSampler(Sampler):\n    """"""\n    In training, we only care about the ""infinite stream"" of training data.\n    So this sampler produces an infinite stream of indices and\n    all workers cooperate to correctly shuffle the indices and sample different indices.\n    The samplers in each worker effectively produces `indices[worker_id::num_workers]`\n    where `indices` is an infinite stream of indices consisting of\n    `shuffle(range(size)) + shuffle(range(size)) + ...` (if shuffle is True)\n    or `range(size) + range(size) + ...` (if shuffle is False)\n    """"""\n\n    def __init__(self, size: int, shuffle: bool = True, seed: Optional[int] = None):\n        """"""\n        Args:\n            size (int): the total number of data of the underlying dataset to sample from\n            shuffle (bool): whether to shuffle the indices or not\n            seed (int): the initial seed of the shuffle. Must be the same\n                across all workers. If None, will use a random seed shared\n                among workers (require synchronization among all workers).\n        """"""\n        self._size = size\n        assert size > 0\n        self._shuffle = shuffle\n        if seed is None:\n            seed = np.random.randint(2 ** 31)\n        self._seed = int(seed)\n\n    def __iter__(self):\n        yield from itertools.islice(self._infinite_indices(), 0, None, 1)\n\n    def _infinite_indices(self):\n        np.random.seed(self._seed)\n        while True:\n            if self._shuffle:\n                yield from np.random.permutation(self._size)\n            else:\n                yield from np.arange(self._size)\n\n\nclass InferenceSampler(Sampler):\n    """"""\n    Produce indices for inference.\n    Inference needs to run on the __exact__ set of samples,\n    therefore when the total number of samples is not divisible by the number of workers,\n    this sampler produces different number of samples on different workers.\n    """"""\n\n    def __init__(self, size: int):\n        """"""\n        Args:\n            size (int): the total number of data of the underlying dataset to sample from\n        """"""\n        self._size = size\n        assert size > 0\n\n        begin = 0\n        end = self._size\n        self._local_indices = range(begin, end)\n\n    def __iter__(self):\n        yield from self._local_indices\n\n    def __len__(self):\n        return len(self._local_indices)'"
fastreid/data/samplers/triplet_sampler.py,1,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: liaoxingyu2@jd.com\n""""""\n\nimport random\nfrom collections import defaultdict\n\nimport numpy as np\nimport torch\nfrom torch.utils.data.sampler import Sampler\n\n\ndef No_index(a, b):\n    assert isinstance(a, list)\n    return [i for i, j in enumerate(a) if j != b]\n\n\nclass RandomIdentitySampler(Sampler):\n    def __init__(self, data_source, batch_size, num_instances=4):\n        self.data_source = data_source\n        self.batch_size = batch_size\n        self.num_instances = num_instances\n        self.num_pids_per_batch = batch_size // self.num_instances\n\n        self.index_pid = defaultdict(list)\n        self.pid_cam = defaultdict(list)\n        self.pid_index = defaultdict(list)\n\n        for index, info in enumerate(data_source):\n            pid = info[1]\n            camid = info[2]\n            self.index_pid[index] = pid\n            self.pid_cam[pid].append(camid)\n            self.pid_index[pid].append(index)\n\n        self.pids = list(self.pid_index.keys())\n        self.num_identities = len(self.pids)\n\n        self._seed = 0\n        self._shuffle = True\n\n    def __iter__(self):\n        indices = self._infinite_indices()\n        for kid in indices:\n            i = random.choice(self.pid_index[self.pids[kid]])\n            _, i_pid, i_cam = self.data_source[i]\n            ret = [i]\n            pid_i = self.index_pid[i]\n            cams = self.pid_cam[pid_i]\n            index = self.pid_index[pid_i]\n            select_cams = No_index(cams, i_cam)\n\n            if select_cams:\n                if len(select_cams) >= self.num_instances:\n                    cam_indexes = np.random.choice(select_cams, size=self.num_instances - 1, replace=False)\n                else:\n                    cam_indexes = np.random.choice(select_cams, size=self.num_instances - 1, replace=True)\n                for kk in cam_indexes:\n                    ret.append(index[kk])\n            else:\n                select_indexes = No_index(index, i)\n                if not select_indexes:\n                    # only one image for this identity\n                    ind_indexes = [0] * (self.num_instances - 1)\n                elif len(select_indexes) >= self.num_instances:\n                    ind_indexes = np.random.choice(select_indexes, size=self.num_instances - 1, replace=False)\n                else:\n                    ind_indexes = np.random.choice(select_indexes, size=self.num_instances - 1, replace=True)\n\n                for kk in ind_indexes:\n                    ret.append(index[kk])\n            yield from ret\n\n    def _infinite_indices(self):\n        np.random.seed(self._seed)\n        while True:\n            if self._shuffle:\n                identities = np.random.permutation(self.num_identities)\n            else:\n                identities = np.arange(self.num_identities)\n            drop_indices = self.num_identities % self.num_pids_per_batch\n            if drop_indices == 0:\n                yield from identities\n            yield from identities[:-drop_indices]\n\n'"
fastreid/data/transforms/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n""""""\n\n\nfrom .build import build_transforms\nfrom .transforms import *\nfrom .autoaugment import *\n'"
fastreid/data/transforms/autoaugment.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\n# ref: https://github.com/DeepVoltaire/AutoAugment/blob/master/autoaugment.py\n# fix some color augmentation methods for adaptation to reid task\n\nfrom PIL import Image, ImageEnhance, ImageOps\nimport numpy as np\nimport random\n\n__all__ = [\'ImageNetPolicy\', \'CIFAR10Policy\', \'SVHNPolicy\']\n\n\nclass ImageNetPolicy(object):\n    """""" Randomly choose one of the best 24 Sub-policies on ImageNet.\n        Example:\n        >>> policy = ImageNetPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     ImageNetPolicy(),\n        >>>     transforms.ToTensor()])\n    """"""\n\n    def __init__(self, total_iter, fillcolor=(128, 128, 128)):\n        self.total_iter = total_iter\n        self.gamma = 0\n        self.policies = [\n            SubPolicy(0.4, ""posterize"", 8, 0.6, ""rotate"", 9, fillcolor),\n            SubPolicy(0.6, ""solarize"", 5, 0.6, ""autocontrast"", 5, fillcolor),\n            SubPolicy(0.8, ""equalize"", 8, 0.6, ""equalize"", 3, fillcolor),\n            SubPolicy(0.6, ""posterize"", 7, 0.6, ""posterize"", 6, fillcolor),\n            SubPolicy(0.4, ""equalize"", 7, 0.2, ""solarize"", 4, fillcolor),\n\n            SubPolicy(0.4, ""equalize"", 4, 0.8, ""rotate"", 8, fillcolor),\n            SubPolicy(0.6, ""solarize"", 3, 0.6, ""equalize"", 7, fillcolor),\n            SubPolicy(0.8, ""posterize"", 5, 1.0, ""equalize"", 2, fillcolor),\n            SubPolicy(0.2, ""rotate"", 3, 0.6, ""solarize"", 8, fillcolor),\n            SubPolicy(0.6, ""equalize"", 8, 0.4, ""posterize"", 6, fillcolor),\n\n            SubPolicy(0.8, ""rotate"", 8, 0.4, ""color"", 0, fillcolor),\n            SubPolicy(0.4, ""rotate"", 9, 0.6, ""equalize"", 2, fillcolor),\n            SubPolicy(0.0, ""equalize"", 7, 0.8, ""equalize"", 8, fillcolor),\n            SubPolicy(0.6, ""invert"", 4, 1.0, ""equalize"", 8, fillcolor),\n            SubPolicy(0.6, ""color"", 4, 1.0, ""contrast"", 8, fillcolor),\n\n            SubPolicy(0.8, ""rotate"", 8, 1.0, ""color"", 2, fillcolor),\n            SubPolicy(0.8, ""color"", 8, 0.8, ""solarize"", 7, fillcolor),\n            SubPolicy(0.4, ""sharpness"", 7, 0.6, ""invert"", 8, fillcolor),\n            SubPolicy(0.6, ""shearX"", 5, 1.0, ""equalize"", 9, fillcolor),\n            SubPolicy(0.4, ""color"", 0, 0.6, ""equalize"", 3, fillcolor),\n\n            SubPolicy(0.4, ""equalize"", 7, 0.2, ""solarize"", 4, fillcolor),\n            SubPolicy(0.6, ""solarize"", 5, 0.6, ""autocontrast"", 5, fillcolor),\n            SubPolicy(0.6, ""invert"", 4, 1.0, ""equalize"", 8, fillcolor),\n            SubPolicy(0.6, ""color"", 4, 1.0, ""contrast"", 8, fillcolor),\n            SubPolicy(0.8, ""equalize"", 8, 0.6, ""equalize"", 3, fillcolor)\n        ]\n\n    def __call__(self, img):\n        if random.uniform(0, 1) > self.gamma:\n            policy_idx = random.randint(0, len(self.policies) - 1)\n            self.gamma = min(1.0, self.gamma + 1.0 / self.total_iter)\n            return self.policies[policy_idx](img)\n        else:\n            return img\n\n    def __repr__(self):\n        return ""AutoAugment ImageNet Policy""\n\n\nclass CIFAR10Policy(object):\n    """""" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n        Example:\n        >>> policy = CIFAR10Policy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     CIFAR10Policy(),\n        >>>     transforms.ToTensor()])\n    """"""\n\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.1, ""invert"", 7, 0.2, ""contrast"", 6, fillcolor),\n            SubPolicy(0.7, ""rotate"", 2, 0.3, ""translateX"", 9, fillcolor),\n            SubPolicy(0.8, ""sharpness"", 1, 0.9, ""sharpness"", 3, fillcolor),\n            SubPolicy(0.5, ""shearY"", 8, 0.7, ""translateY"", 9, fillcolor),\n            SubPolicy(0.5, ""autocontrast"", 8, 0.9, ""equalize"", 2, fillcolor),\n\n            SubPolicy(0.2, ""shearY"", 7, 0.3, ""posterize"", 7, fillcolor),\n            SubPolicy(0.4, ""color"", 3, 0.6, ""brightness"", 7, fillcolor),\n            SubPolicy(0.3, ""sharpness"", 9, 0.7, ""brightness"", 9, fillcolor),\n            SubPolicy(0.6, ""equalize"", 5, 0.5, ""equalize"", 1, fillcolor),\n            SubPolicy(0.6, ""contrast"", 7, 0.6, ""sharpness"", 5, fillcolor),\n\n            SubPolicy(0.7, ""color"", 7, 0.5, ""translateX"", 8, fillcolor),\n            SubPolicy(0.3, ""equalize"", 7, 0.4, ""autocontrast"", 8, fillcolor),\n            SubPolicy(0.4, ""translateY"", 3, 0.2, ""sharpness"", 6, fillcolor),\n            SubPolicy(0.9, ""brightness"", 6, 0.2, ""color"", 8, fillcolor),\n            SubPolicy(0.5, ""solarize"", 2, 0.0, ""invert"", 3, fillcolor),\n\n            SubPolicy(0.2, ""equalize"", 0, 0.6, ""autocontrast"", 0, fillcolor),\n            SubPolicy(0.2, ""equalize"", 8, 0.6, ""equalize"", 4, fillcolor),\n            SubPolicy(0.9, ""color"", 9, 0.6, ""equalize"", 6, fillcolor),\n            SubPolicy(0.8, ""autocontrast"", 4, 0.2, ""solarize"", 8, fillcolor),\n            SubPolicy(0.1, ""brightness"", 3, 0.7, ""color"", 0, fillcolor),\n\n            SubPolicy(0.4, ""solarize"", 5, 0.9, ""autocontrast"", 3, fillcolor),\n            SubPolicy(0.9, ""translateY"", 9, 0.7, ""translateY"", 9, fillcolor),\n            SubPolicy(0.9, ""autocontrast"", 2, 0.8, ""solarize"", 3, fillcolor),\n            SubPolicy(0.8, ""equalize"", 8, 0.1, ""invert"", 3, fillcolor),\n            SubPolicy(0.7, ""translateY"", 9, 0.9, ""autocontrast"", 1, fillcolor)\n        ]\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return ""AutoAugment CIFAR10 Policy""\n\n\nclass SVHNPolicy(object):\n    """""" Randomly choose one of the best 25 Sub-policies on SVHN.\n        Example:\n        >>> policy = SVHNPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     SVHNPolicy(),\n        >>>     transforms.ToTensor()])\n    """"""\n\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.9, ""shearX"", 4, 0.2, ""invert"", 3, fillcolor),\n            SubPolicy(0.9, ""shearY"", 8, 0.7, ""invert"", 5, fillcolor),\n            SubPolicy(0.6, ""equalize"", 5, 0.6, ""solarize"", 6, fillcolor),\n            SubPolicy(0.9, ""invert"", 3, 0.6, ""equalize"", 3, fillcolor),\n            SubPolicy(0.6, ""equalize"", 1, 0.9, ""rotate"", 3, fillcolor),\n\n            SubPolicy(0.9, ""shearX"", 4, 0.8, ""autocontrast"", 3, fillcolor),\n            SubPolicy(0.9, ""shearY"", 8, 0.4, ""invert"", 5, fillcolor),\n            SubPolicy(0.9, ""shearY"", 5, 0.2, ""solarize"", 6, fillcolor),\n            SubPolicy(0.9, ""invert"", 6, 0.8, ""autocontrast"", 1, fillcolor),\n            SubPolicy(0.6, ""equalize"", 3, 0.9, ""rotate"", 3, fillcolor),\n\n            SubPolicy(0.9, ""shearX"", 4, 0.3, ""solarize"", 3, fillcolor),\n            SubPolicy(0.8, ""shearY"", 8, 0.7, ""invert"", 4, fillcolor),\n            SubPolicy(0.9, ""equalize"", 5, 0.6, ""translateY"", 6, fillcolor),\n            SubPolicy(0.9, ""invert"", 4, 0.6, ""equalize"", 7, fillcolor),\n            SubPolicy(0.3, ""contrast"", 3, 0.8, ""rotate"", 4, fillcolor),\n\n            SubPolicy(0.8, ""invert"", 5, 0.0, ""translateY"", 2, fillcolor),\n            SubPolicy(0.7, ""shearY"", 6, 0.4, ""solarize"", 8, fillcolor),\n            SubPolicy(0.6, ""invert"", 4, 0.8, ""rotate"", 4, fillcolor),\n            SubPolicy(0.3, ""shearY"", 7, 0.9, ""translateX"", 3, fillcolor),\n            SubPolicy(0.1, ""shearX"", 6, 0.6, ""invert"", 5, fillcolor),\n\n            SubPolicy(0.7, ""solarize"", 2, 0.6, ""translateY"", 7, fillcolor),\n            SubPolicy(0.8, ""shearY"", 4, 0.8, ""invert"", 8, fillcolor),\n            SubPolicy(0.7, ""shearX"", 9, 0.8, ""translateY"", 3, fillcolor),\n            SubPolicy(0.8, ""shearY"", 5, 0.7, ""autocontrast"", 3, fillcolor),\n            SubPolicy(0.7, ""shearX"", 2, 0.1, ""invert"", 5, fillcolor)\n        ]\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return ""AutoAugment SVHN Policy""\n\n\nclass SubPolicy(object):\n    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n        ranges = {\n            ""shearX"": np.linspace(0, 0.3, 10),\n            ""shearY"": np.linspace(0, 0.3, 10),\n            ""translateX"": np.linspace(0, 150 / 331, 10),\n            ""translateY"": np.linspace(0, 150 / 331, 10),\n            ""rotate"": np.linspace(0, 30, 10),\n            ""color"": np.linspace(0.0, 0.9, 10),\n            ""posterize"": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n            ""solarize"": np.linspace(256, 0, 10),\n            ""contrast"": np.linspace(0.0, 0.9, 10),\n            ""sharpness"": np.linspace(0.0, 0.9, 10),\n            ""brightness"": np.linspace(0.0, 0.9, 10),\n            ""autocontrast"": [0] * 10,\n            ""equalize"": [0] * 10,\n            ""invert"": [0] * 10\n        }\n\n        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n        def rotate_with_fill(img, magnitude):\n            rot = img.convert(""RGBA"").rotate(magnitude)\n            return Image.composite(rot, Image.new(""RGBA"", rot.size, (128,) * 4), rot).convert(img.mode)\n\n        func = {\n            ""shearX"": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            ""shearY"": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            ""translateX"": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n                fillcolor=fillcolor),\n            ""translateY"": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n                fillcolor=fillcolor),\n            ""rotate"": lambda img, magnitude: rotate_with_fill(img, magnitude),\n            ""color"": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n            ""posterize"": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n            ""solarize"": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n            ""contrast"": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            ""sharpness"": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            ""brightness"": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            ""autocontrast"": lambda img, magnitude: ImageOps.autocontrast(img),\n            ""equalize"": lambda img, magnitude: ImageOps.equalize(img),\n            ""invert"": lambda img, magnitude: ImageOps.invert(img)\n        }\n\n        self.p1 = p1\n        self.operation1 = func[operation1]\n        self.magnitude1 = ranges[operation1][magnitude_idx1]\n        self.p2 = p2\n        self.operation2 = func[operation2]\n        self.magnitude2 = ranges[operation2][magnitude_idx2]\n\n    def __call__(self, img):\n        if random.random() < self.p1:\n            img = self.operation1(img, self.magnitude1)\n        if random.random() < self.p2:\n            img = self.operation2(img, self.magnitude2)\n        return img\n'"
fastreid/data/transforms/build.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torchvision.transforms as T\n\nfrom .transforms import *\nfrom .autoaugment import *\n\n\ndef build_transforms(cfg, is_train=True):\n    res = []\n\n    if is_train:\n        size_train = cfg.INPUT.SIZE_TRAIN\n\n        # augmix augmentation\n        do_augmix = cfg.INPUT.DO_AUGMIX\n\n        # auto augmentation\n        do_autoaug = cfg.INPUT.DO_AUTOAUG\n        total_iter = cfg.SOLVER.MAX_ITER\n\n        # horizontal filp\n        do_flip = cfg.INPUT.DO_FLIP\n        flip_prob = cfg.INPUT.FLIP_PROB\n\n        # padding\n        do_pad = cfg.INPUT.DO_PAD\n        padding = cfg.INPUT.PADDING\n        padding_mode = cfg.INPUT.PADDING_MODE\n\n        # color jitter\n        do_cj = cfg.INPUT.DO_CJ\n\n        # random erasing\n        do_rea = cfg.INPUT.REA.ENABLED\n        rea_prob = cfg.INPUT.REA.PROB\n        rea_mean = cfg.INPUT.REA.MEAN\n        # random patch\n        do_rpt = cfg.INPUT.RPT.ENABLED\n        rpt_prob = cfg.INPUT.RPT.PROB\n\n        if do_autoaug:\n            res.append(ImageNetPolicy(total_iter))\n        res.append(T.Resize(size_train, interpolation=3))\n        if do_flip:\n            res.append(T.RandomHorizontalFlip(p=flip_prob))\n        if do_pad:\n            res.extend([T.Pad(padding, padding_mode=padding_mode),\n                        T.RandomCrop(size_train)])\n        if do_cj:\n            res.append(T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0))\n        if do_augmix:\n            res.append(AugMix())\n        if do_rea:\n            res.append(RandomErasing(probability=rea_prob, mean=rea_mean))\n        if do_rpt:\n            res.append(RandomPatch(prob_happen=rpt_prob))\n    else:\n        size_test = cfg.INPUT.SIZE_TEST\n        res.append(T.Resize(size_test, interpolation=3))\n    res.append(ToTensor())\n    return T.Compose(res)\n'"
fastreid/data/transforms/functional.py,8,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport numpy as np\nimport torch\nfrom PIL import Image, ImageOps, ImageEnhance\n\n\ndef to_tensor(pic):\n    """"""Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n\n    See ``ToTensor`` for more details.\n\n    Args:\n        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n\n    Returns:\n        Tensor: Converted image.\n    """"""\n    if isinstance(pic, np.ndarray):\n        assert len(pic.shape) in (2, 3)\n        # handle numpy array\n        if pic.ndim == 2:\n            pic = pic[:, :, None]\n\n        img = torch.from_numpy(pic.transpose((2, 0, 1)))\n        # backward compatibility\n        if isinstance(img, torch.ByteTensor):\n            return img.float()\n        else:\n            return img\n\n    # handle PIL Image\n    if pic.mode == \'I\':\n        img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n    elif pic.mode == \'I;16\':\n        img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n    elif pic.mode == \'F\':\n        img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n    elif pic.mode == \'1\':\n        img = 255 * torch.from_numpy(np.array(pic, np.uint8, copy=False))\n    else:\n        img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n    # PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\n    if pic.mode == \'YCbCr\':\n        nchannel = 3\n    elif pic.mode == \'I;16\':\n        nchannel = 1\n    else:\n        nchannel = len(pic.mode)\n    img = img.view(pic.size[1], pic.size[0], nchannel)\n    # put it from HWC to CHW format\n    # yikes, this transpose takes 80% of the loading time/CPU\n    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n    if isinstance(img, torch.ByteTensor):\n        return img.float()\n    else:\n        return img\n\n\ndef int_parameter(level, maxval):\n    """"""Helper function to scale `val` between 0 and maxval .\n    Args:\n      level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n      maxval: Maximum value that the operation can have. This will be scaled to\n        level/PARAMETER_MAX.\n    Returns:\n      An int that results from scaling `maxval` according to `level`.\n    """"""\n    return int(level * maxval / 10)\n\n\ndef float_parameter(level, maxval):\n    """"""Helper function to scale `val` between 0 and maxval.\n    Args:\n      level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n      maxval: Maximum value that the operation can have. This will be scaled to\n        level/PARAMETER_MAX.\n    Returns:\n      A float that results from scaling `maxval` according to `level`.\n    """"""\n    return float(level) * maxval / 10.\n\n\ndef sample_level(n):\n    return np.random.uniform(low=0.1, high=n)\n\n\ndef autocontrast(pil_img, *args):\n    return ImageOps.autocontrast(pil_img)\n\n\ndef equalize(pil_img, *args):\n    return ImageOps.equalize(pil_img)\n\n\ndef posterize(pil_img, level, *args):\n    level = int_parameter(sample_level(level), 4)\n    return ImageOps.posterize(pil_img, 4 - level)\n\n\ndef rotate(pil_img, level, *args):\n    degrees = int_parameter(sample_level(level), 30)\n    if np.random.uniform() > 0.5:\n        degrees = -degrees\n    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n\n\ndef solarize(pil_img, level, *args):\n    level = int_parameter(sample_level(level), 256)\n    return ImageOps.solarize(pil_img, 256 - level)\n\n\ndef shear_x(pil_img, level, image_size):\n    level = float_parameter(sample_level(level), 0.3)\n    if np.random.uniform() > 0.5:\n        level = -level\n    return pil_img.transform(image_size,\n                             Image.AFFINE, (1, level, 0, 0, 1, 0),\n                             resample=Image.BILINEAR)\n\n\ndef shear_y(pil_img, level, image_size):\n    level = float_parameter(sample_level(level), 0.3)\n    if np.random.uniform() > 0.5:\n        level = -level\n    return pil_img.transform(image_size,\n                             Image.AFFINE, (1, 0, 0, level, 1, 0),\n                             resample=Image.BILINEAR)\n\n\ndef translate_x(pil_img, level, image_size):\n    level = int_parameter(sample_level(level), image_size[0] / 3)\n    if np.random.random() > 0.5:\n        level = -level\n    return pil_img.transform(image_size,\n                             Image.AFFINE, (1, 0, level, 0, 1, 0),\n                             resample=Image.BILINEAR)\n\n\ndef translate_y(pil_img, level, image_size):\n    level = int_parameter(sample_level(level), image_size[1] / 3)\n    if np.random.random() > 0.5:\n        level = -level\n    return pil_img.transform(image_size,\n                             Image.AFFINE, (1, 0, 0, 0, 1, level),\n                             resample=Image.BILINEAR)\n\n\n# operation that overlaps with ImageNet-C\'s test set\ndef color(pil_img, level, *args):\n    level = float_parameter(sample_level(level), 1.8) + 0.1\n    return ImageEnhance.Color(pil_img).enhance(level)\n\n\n# operation that overlaps with ImageNet-C\'s test set\ndef contrast(pil_img, level, *args):\n    level = float_parameter(sample_level(level), 1.8) + 0.1\n    return ImageEnhance.Contrast(pil_img).enhance(level)\n\n\n# operation that overlaps with ImageNet-C\'s test set\ndef brightness(pil_img, level, *args):\n    level = float_parameter(sample_level(level), 1.8) + 0.1\n    return ImageEnhance.Brightness(pil_img).enhance(level)\n\n\n# operation that overlaps with ImageNet-C\'s test set\ndef sharpness(pil_img, level, *args):\n    level = float_parameter(sample_level(level), 1.8) + 0.1\n    return ImageEnhance.Sharpness(pil_img).enhance(level)\n\n\naugmentations_reid = [\n    autocontrast, equalize, posterize, shear_x, shear_y,\n    color, contrast, brightness, sharpness\n]\n\naugmentations = [\n    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n    translate_x, translate_y\n]\n\naugmentations_all = [\n    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n    translate_x, translate_y, color, contrast, brightness, sharpness\n]\n'"
fastreid/data/transforms/transforms.py,1,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\n__all__ = [\'ToTensor\', \'RandomErasing\', \'RandomPatch\', \'AugMix\', ]\n\nimport math\nimport random\nfrom collections import deque\n\nimport numpy as np\nfrom PIL import Image\n\nfrom .functional import to_tensor, augmentations_reid\n\n\nclass ToTensor(object):\n    """"""Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n\n    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n    if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1)\n    or if the numpy.ndarray has dtype = np.uint8\n\n    In the other cases, tensors are returned without scaling.\n    """"""\n\n    def __call__(self, pic):\n        """"""\n        Args:\n            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n\n        Returns:\n            Tensor: Converted image.\n        """"""\n        return to_tensor(pic)\n\n    def __repr__(self):\n        return self.__class__.__name__ + \'()\'\n\n\nclass RandomErasing(object):\n    """""" Randomly selects a rectangle region in an image and erases its pixels.\n        \'Random Erasing Data Augmentation\' by Zhong et al.\n        See https://arxiv.org/pdf/1708.04896.pdf\n    Args:\n        probability: The probability that the Random Erasing operation will be performed.\n        sl: Minimum proportion of erased area against input image.\n        sh: Maximum proportion of erased area against input image.\n        r1: Minimum aspect ratio of erased area.\n        mean: Erasing value.\n    """"""\n\n    def __init__(self, probability=0.5, sl=0.02, sh=0.4, r1=0.3, mean=255 * (0.49735, 0.4822, 0.4465)):\n        self.probability = probability\n        self.mean = mean\n        self.sl = sl\n        self.sh = sh\n        self.r1 = r1\n\n    def __call__(self, img):\n        img = np.asarray(img, dtype=np.float32).copy()\n        if random.uniform(0, 1) > self.probability:\n            return img\n\n        for attempt in range(100):\n            area = img.shape[0] * img.shape[1]\n            target_area = random.uniform(self.sl, self.sh) * area\n            aspect_ratio = random.uniform(self.r1, 1 / self.r1)\n\n            h = int(round(math.sqrt(target_area * aspect_ratio)))\n            w = int(round(math.sqrt(target_area / aspect_ratio)))\n\n            if w < img.shape[1] and h < img.shape[0]:\n                x1 = random.randint(0, img.shape[0] - h)\n                y1 = random.randint(0, img.shape[1] - w)\n                if img.shape[2] == 3:\n                    img[x1:x1 + h, y1:y1 + w, 0] = self.mean[0]\n                    img[x1:x1 + h, y1:y1 + w, 1] = self.mean[1]\n                    img[x1:x1 + h, y1:y1 + w, 2] = self.mean[2]\n                else:\n                    img[x1:x1 + h, y1:y1 + w, 0] = self.mean[0]\n                return img\n        return img\n\n\nclass RandomPatch(object):\n    """"""Random patch data augmentation.\n    There is a patch pool that stores randomly extracted pathces from person images.\n    For each input image, RandomPatch\n        1) extracts a random patch and stores the patch in the patch pool;\n        2) randomly selects a patch from the patch pool and pastes it on the\n           input (at random position) to simulate occlusion.\n    Reference:\n        - Zhou et al. Omni-Scale Feature Learning for Person Re-Identification. ICCV, 2019.\n        - Zhou et al. Learning Generalisable Omni-Scale Representations\n          for Person Re-Identification. arXiv preprint, 2019.\n    """"""\n\n    def __init__(self, prob_happen=0.5, pool_capacity=50000, min_sample_size=100,\n                 patch_min_area=0.01, patch_max_area=0.5, patch_min_ratio=0.1,\n                 prob_rotate=0.5, prob_flip_leftright=0.5,\n                 ):\n        self.prob_happen = prob_happen\n\n        self.patch_min_area = patch_min_area\n        self.patch_max_area = patch_max_area\n        self.patch_min_ratio = patch_min_ratio\n\n        self.prob_rotate = prob_rotate\n        self.prob_flip_leftright = prob_flip_leftright\n\n        self.patchpool = deque(maxlen=pool_capacity)\n        self.min_sample_size = min_sample_size\n\n    def generate_wh(self, W, H):\n        area = W * H\n        for attempt in range(100):\n            target_area = random.uniform(self.patch_min_area, self.patch_max_area) * area\n            aspect_ratio = random.uniform(self.patch_min_ratio, 1. / self.patch_min_ratio)\n            h = int(round(math.sqrt(target_area * aspect_ratio)))\n            w = int(round(math.sqrt(target_area / aspect_ratio)))\n            if w < W and h < H:\n                return w, h\n        return None, None\n\n    def transform_patch(self, patch):\n        if random.uniform(0, 1) > self.prob_flip_leftright:\n            patch = patch.transpose(Image.FLIP_LEFT_RIGHT)\n        if random.uniform(0, 1) > self.prob_rotate:\n            patch = patch.rotate(random.randint(-10, 10))\n        return patch\n\n    def __call__(self, img):\n        if isinstance(img, np.ndarray):\n            img = Image.fromarray(img.astype(np.uint8))\n\n        W, H = img.size  # original image size\n\n        # collect new patch\n        w, h = self.generate_wh(W, H)\n        if w is not None and h is not None:\n            x1 = random.randint(0, W - w)\n            y1 = random.randint(0, H - h)\n            new_patch = img.crop((x1, y1, x1 + w, y1 + h))\n            self.patchpool.append(new_patch)\n\n        if len(self.patchpool) < self.min_sample_size:\n            return img\n\n        if random.uniform(0, 1) > self.prob_happen:\n            return img\n\n        # paste a randomly selected patch on a random position\n        patch = random.sample(self.patchpool, 1)[0]\n        patchW, patchH = patch.size\n        x1 = random.randint(0, W - patchW)\n        y1 = random.randint(0, H - patchH)\n        patch = self.transform_patch(patch)\n        img.paste(patch, (x1, y1))\n\n        return img\n\n\nclass AugMix(object):\n    """""" Perform AugMix augmentation and compute mixture.\n    Args:\n        aug_prob_coeff: Probability distribution coefficients.\n        mixture_width: Number of augmentation chains to mix per augmented example.\n        mixture_depth: Depth of augmentation chains. -1 denotes stochastic depth in [1, 3]\'\n        severity: Severity of underlying augmentation operators (between 1 to 10).\n    """"""\n\n    def __init__(self, aug_prob_coeff=1, mixture_width=3, mixture_depth=-1, severity=1):\n        self.aug_prob_coeff = aug_prob_coeff\n        self.mixture_width = mixture_width\n        self.mixture_depth = mixture_depth\n        self.severity = severity\n        self.aug_list = augmentations_reid\n\n    def __call__(self, image):\n        """"""Perform AugMix augmentations and compute mixture.\n        Returns:\n          mixed: Augmented and mixed image.\n        """"""\n        ws = np.float32(\n            np.random.dirichlet([self.aug_prob_coeff] * self.mixture_width))\n        m = np.float32(np.random.beta(self.aug_prob_coeff, self.aug_prob_coeff))\n\n        image = np.asarray(image, dtype=np.float32).copy()\n        mix = np.zeros_like(image)\n        h, w = image.shape[0], image.shape[1]\n        for i in range(self.mixture_width):\n            image_aug = Image.fromarray(image.copy().astype(np.uint8))\n            depth = self.mixture_depth if self.mixture_depth > 0 else np.random.randint(1, 4)\n            for _ in range(depth):\n                op = np.random.choice(self.aug_list)\n                image_aug = op(image_aug, self.severity, (w, h))\n            mix += ws[i] * np.asarray(image_aug, dtype=np.float32)\n\n        mixed = (1 - m) * image + m * mix\n        return mixed\n\n# class ColorJitter(object):\n#     """"""docstring for do_color""""""\n#\n#     def __init__(self, probability=0.5):\n#         self.probability = probability\n#\n#     def do_brightness_shift(self, image, alpha=0.125):\n#         image = image.astype(np.float32)\n#         image = image + alpha * 255\n#         image = np.clip(image, 0, 255).astype(np.uint8)\n#         return image\n#\n#     def do_brightness_multiply(self, image, alpha=1):\n#         image = image.astype(np.float32)\n#         image = alpha * image\n#         image = np.clip(image, 0, 255).astype(np.uint8)\n#         return image\n#\n#     def do_contrast(self, image, alpha=1.0):\n#         image = image.astype(np.float32)\n#         gray = image * np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n#         gray = (3.0 * (1.0 - alpha) / gray.size) * np.sum(gray)\n#         image = alpha * image + gray\n#         image = np.clip(image, 0, 255).astype(np.uint8)\n#         return image\n#\n#     # https://www.pyimagesearch.com/2015/10/05/opencv-gamma-correction/\n#     def do_gamma(self, image, gamma=1.0):\n#         table = np.array([((i / 255.0) ** (1.0 / gamma)) * 255\n#                           for i in np.arange(0, 256)]).astype(""uint8"")\n#\n#         return cv2.LUT(image, table)  # apply gamma correction using the lookup table\n#\n#     def do_clahe(self, image, clip=2, grid=16):\n#         grid = int(grid)\n#\n#         lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n#         gray, a, b = cv2.split(lab)\n#         gray = cv2.createCLAHE(clipLimit=clip, tileGridSize=(grid, grid)).apply(gray)\n#         lab = cv2.merge((gray, a, b))\n#         image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n#\n#         return image\n#\n#     def __call__(self, image):\n#         if random.uniform(0, 1) > self.probability:\n#             return image\n#\n#         image = np.asarray(image, dtype=np.uint8).copy()\n#         index = random.randint(0, 4)\n#         if index == 0:\n#             image = self.do_brightness_shift(image, 0.1)\n#         elif index == 1:\n#             image = self.do_gamma(image, 1)\n#         elif index == 2:\n#             image = self.do_clahe(image)\n#         elif index == 3:\n#             image = self.do_brightness_multiply(image)\n#         elif index == 4:\n#             image = self.do_contrast(image)\n#         return image\n\n\n# class random_shift(object):\n#     """"""docstring for do_color""""""\n#\n#     def __init__(self, probability=0.5):\n#         self.probability = probability\n#\n#     def __call__(self, image):\n#         if random.uniform(0, 1) > self.probability:\n#             return image\n#\n#         width, height, d = image.shape\n#         zero_image = np.zeros_like(image)\n#         w = random.randint(0, 20) - 10\n#         h = random.randint(0, 30) - 15\n#         zero_image[max(0, w): min(w + width, width), max(h, 0): min(h + height, height)] = \\\n#             image[max(0, -w): min(-w + width, width), max(-h, 0): min(-h + height, height)]\n#         image = zero_image.copy()\n#         return image\n#\n#\n# class random_scale(object):\n#     """"""docstring for do_color""""""\n#\n#     def __init__(self, probability=0.5):\n#         self.probability = probability\n#\n#     def __call__(self, image):\n#         if random.uniform(0, 1) > self.probability:\n#             return image\n#\n#         scale = random.random() * 0.1 + 0.9\n#         assert 0.9 <= scale <= 1\n#         width, height, d = image.shape\n#         zero_image = np.zeros_like(image)\n#         new_width = round(width * scale)\n#         new_height = round(height * scale)\n#         image = cv2.resize(image, (new_height, new_width))\n#         start_w = random.randint(0, width - new_width)\n#         start_h = random.randint(0, height - new_height)\n#         zero_image[start_w: start_w + new_width,\n#         start_h:start_h + new_height] = image\n#         image = zero_image.copy()\n#         return image\n'"
fastreid/evaluation/rank_cylib/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""'"
fastreid/evaluation/rank_cylib/setup.py,0,"b""from distutils.core import setup\nfrom distutils.extension import Extension\n\nimport numpy as np\nfrom Cython.Build import cythonize\n\n\ndef numpy_include():\n    try:\n        numpy_include = np.get_include()\n    except AttributeError:\n        numpy_include = np.get_numpy_include()\n    return numpy_include\n\n\next_modules = [\n    Extension(\n        'rank_cy',\n        ['rank_cy.pyx'],\n        include_dirs=[numpy_include()],\n    )\n]\n\nsetup(\n    name='Cython-based reid evaluation code',\n    ext_modules=cythonize(ext_modules)\n)\n"""
fastreid/evaluation/rank_cylib/test_cython.py,0,"b'import sys\nimport numpy as np\nimport timeit\nimport os.path as osp\n\n\nsys.path.insert(0, osp.dirname(osp.abspath(__file__)) + \'/../../..\')\n\n""""""\nTest the speed of cython-based evaluation code. The speed improvements\ncan be much bigger when using the real reid data, which contains a larger\namount of query and gallery images.\nNote: you might encounter the following error:\n  \'AssertionError: Error: all query identities do not appear in gallery\'.\nThis is normal because the inputs are random numbers. Just try again.\n""""""\n\nprint(\'*** Compare running time ***\')\n\nsetup = \'\'\'\nimport sys\nimport os.path as osp\nimport numpy as np\nsys.path.insert(0, osp.dirname(osp.abspath(__file__)) + \'/../../..\')\nfrom fastreid import evaluation\nnum_q = 30\nnum_g = 300\nmax_rank = 5\ndistmat = np.random.rand(num_q, num_g) * 20\nq_pids = np.random.randint(0, num_q, size=num_q)\ng_pids = np.random.randint(0, num_g, size=num_g)\nq_camids = np.random.randint(0, 5, size=num_q)\ng_camids = np.random.randint(0, 5, size=num_g)\n\'\'\'\n\n# print(\'=> Using market1501\\\'s metric\')\n# pytime = timeit.timeit(\n#     \'evaluation.evaluate_rank(distmat, q_pids, g_pids, q_camids, g_camids, max_rank, use_cython=False)\',\n#     setup=setup,\n#     number=20\n# )\n# cytime = timeit.timeit(\n#     \'evaluation.evaluate_rank(distmat, q_pids, g_pids, q_camids, g_camids, max_rank, use_cython=True)\',\n#     setup=setup,\n#     number=20\n# )\n# print(\'Python time: {} s\'.format(pytime))\n# print(\'Cython time: {} s\'.format(cytime))\n# print(\'Cython is {} times faster than python\\n\'.format(pytime / cytime))\n#\n# print(\'=> Using cuhk03\\\'s metric\')\n# pytime = timeit.timeit(\n#     \'evaluation.evaluate_rank(distmat, q_pids, g_pids, q_camids, g_camids, max_rank, use_metric_cuhk03=True, use_cython=False)\',\n#     setup=setup,\n#     number=20\n# )\n# cytime = timeit.timeit(\n#     \'evaluation.evaluate_rank(distmat, q_pids, g_pids, q_camids, g_camids, max_rank, use_metric_cuhk03=True, use_cython=True)\',\n#     setup=setup,\n#     number=20\n# )\n# print(\'Python time: {} s\'.format(pytime))\n# print(\'Cython time: {} s\'.format(cytime))\n# print(\'Cython is {} times faster than python\\n\'.format(pytime / cytime))\n\nfrom fastreid.evaluation import evaluate_rank\nprint(""=> Check precision"")\nnum_q = 30\nnum_g = 300\nmax_rank = 5\ndistmat = np.random.rand(num_q, num_g) * 20\nq_pids = np.random.randint(0, num_q, size=num_q)\ng_pids = np.random.randint(0, num_g, size=num_g)\nq_camids = np.random.randint(0, 5, size=num_q)\ng_camids = np.random.randint(0, 5, size=num_g)\ncmc, mAP, mINP = evaluate_rank(distmat, q_pids, g_pids, q_camids, g_camids, max_rank, use_cython=False)\nprint(""Python:\\nmAP = {} \\ncmc = {}\\nmINP = {}"".format(mAP, cmc, mINP))\ncmc, mAP, mINP = evaluate_rank(distmat, q_pids, g_pids, q_camids, g_camids, max_rank, use_cython=True)\nprint(""Cython:\\nmAP = {} \\ncmc = {}\\nmINP = {}"".format(mAP, cmc, mINP))\n'"
fastreid/layers/sync_bn/__init__.py,0,"b'# -*- coding: utf-8 -*-\n# File   : __init__.py\n# Author : Jiayuan Mao\n# Email  : maojiayuan@gmail.com\n# Date   : 27/01/2018\n#\n# This file is part of Synchronized-BatchNorm-PyTorch.\n# https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n# Distributed under MIT License.\n\nfrom .batchnorm import SynchronizedBatchNorm1d, SynchronizedBatchNorm2d, SynchronizedBatchNorm3d\nfrom .batchnorm import patch_sync_batchnorm, convert_model\nfrom .replicate import DataParallelWithCallback, patch_replication_callback\n'"
fastreid/layers/sync_bn/batchnorm.py,16,"b'# -*- coding: utf-8 -*-\n# File   : batchnorm.py\n# Author : Jiayuan Mao\n# Email  : maojiayuan@gmail.com\n# Date   : 27/01/2018\n#\n# This file is part of Synchronized-BatchNorm-PyTorch.\n# https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n# Distributed under MIT License.\n\nimport collections\nimport contextlib\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn.modules.batchnorm import _BatchNorm\n\ntry:\n    from torch.nn.parallel._functions import ReduceAddCoalesced, Broadcast\nexcept ImportError:\n    ReduceAddCoalesced = Broadcast = None\n\ntry:\n    from jactorch.parallel.comm import SyncMaster\n    from jactorch.parallel.data_parallel import JacDataParallel as DataParallelWithCallback\nexcept ImportError:\n    from .comm import SyncMaster\n    from .replicate import DataParallelWithCallback\n\n__all__ = [\n    \'SynchronizedBatchNorm1d\', \'SynchronizedBatchNorm2d\', \'SynchronizedBatchNorm3d\',\n    \'patch_sync_batchnorm\', \'convert_model\'\n]\n\n\ndef _sum_ft(tensor):\n    """"""sum over the first and last dimention""""""\n    return tensor.sum(dim=0).sum(dim=-1)\n\n\ndef _unsqueeze_ft(tensor):\n    """"""add new dimensions at the front and the tail""""""\n    return tensor.unsqueeze(0).unsqueeze(-1)\n\n\n_ChildMessage = collections.namedtuple(\'_ChildMessage\', [\'sum\', \'ssum\', \'sum_size\'])\n_MasterMessage = collections.namedtuple(\'_MasterMessage\', [\'sum\', \'inv_std\'])\n\n\nclass _SynchronizedBatchNorm(_BatchNorm):\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, weight_freeze=False, bias_freeze=False, affine=True):\n        assert ReduceAddCoalesced is not None, \'Can not use Synchronized Batch Normalization without CUDA support.\'\n\n        super(_SynchronizedBatchNorm, self).__init__(num_features, eps=eps, momentum=momentum, affine=affine)\n        self.weight.requires_grad_(not weight_freeze)\n        self.bias.requires_grad_(not bias_freeze)\n\n        self._sync_master = SyncMaster(self._data_parallel_master)\n\n        self._is_parallel = False\n        self._parallel_id = None\n        self._slave_pipe = None\n\n    def forward(self, input):\n        # If it is not parallel computation or is in evaluation mode, use PyTorch\'s implementation.\n        if not (self._is_parallel and self.training):\n            return F.batch_norm(\n                input, self.running_mean, self.running_var, self.weight, self.bias,\n                self.training, self.momentum, self.eps)\n\n        # Resize the input to (B, C, -1).\n        input_shape = input.size()\n        input = input.view(input.size(0), self.num_features, -1)\n\n        # Compute the sum and square-sum.\n        sum_size = input.size(0) * input.size(2)\n        input_sum = _sum_ft(input)\n        input_ssum = _sum_ft(input ** 2)\n\n        # Reduce-and-broadcast the statistics.\n        if self._parallel_id == 0:\n            mean, inv_std = self._sync_master.run_master(_ChildMessage(input_sum, input_ssum, sum_size))\n        else:\n            mean, inv_std = self._slave_pipe.run_slave(_ChildMessage(input_sum, input_ssum, sum_size))\n\n        # Compute the output.\n        if self.affine:\n            # MJY:: Fuse the multiplication for speed.\n            output = (input - _unsqueeze_ft(mean)) * _unsqueeze_ft(inv_std * self.weight) + _unsqueeze_ft(self.bias)\n        else:\n            output = (input - _unsqueeze_ft(mean)) * _unsqueeze_ft(inv_std)\n\n        # Reshape it.\n        return output.view(input_shape)\n\n    def __data_parallel_replicate__(self, ctx, copy_id):\n        self._is_parallel = True\n        self._parallel_id = copy_id\n\n        # parallel_id == 0 means master device.\n        if self._parallel_id == 0:\n            ctx.sync_master = self._sync_master\n        else:\n            self._slave_pipe = ctx.sync_master.register_slave(copy_id)\n\n    def _data_parallel_master(self, intermediates):\n        """"""Reduce the sum and square-sum, compute the statistics, and broadcast it.""""""\n\n        # Always using same ""device order"" makes the ReduceAdd operation faster.\n        # Thanks to:: Tete Xiao (http://tetexiao.com/)\n        intermediates = sorted(intermediates, key=lambda i: i[1].sum.get_device())\n\n        to_reduce = [i[1][:2] for i in intermediates]\n        to_reduce = [j for i in to_reduce for j in i]  # flatten\n        target_gpus = [i[1].sum.get_device() for i in intermediates]\n\n        sum_size = sum([i[1].sum_size for i in intermediates])\n        sum_, ssum = ReduceAddCoalesced.apply(target_gpus[0], 2, *to_reduce)\n        mean, inv_std = self._compute_mean_std(sum_, ssum, sum_size)\n\n        broadcasted = Broadcast.apply(target_gpus, mean, inv_std)\n\n        outputs = []\n        for i, rec in enumerate(intermediates):\n            outputs.append((rec[0], _MasterMessage(*broadcasted[i * 2:i * 2 + 2])))\n\n        return outputs\n\n    def _compute_mean_std(self, sum_, ssum, size):\n        """"""Compute the mean and standard-deviation with sum and square-sum. This method\n        also maintains the moving average on the master device.""""""\n        assert size > 1, \'BatchNorm computes unbiased standard-deviation, which requires size > 1.\'\n        mean = sum_ / size\n        sumvar = ssum - sum_ * mean\n        unbias_var = sumvar / (size - 1)\n        bias_var = sumvar / size\n\n        if hasattr(torch, \'no_grad\'):\n            with torch.no_grad():\n                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.data\n                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * unbias_var.data\n        else:\n            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.data\n            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * unbias_var.data\n\n        return mean, bias_var.clamp(self.eps) ** -0.5\n\n\nclass SynchronizedBatchNorm1d(_SynchronizedBatchNorm):\n    r""""""Applies Synchronized Batch Normalization over a 2d or 3d input that is seen as a\n    mini-batch.\n\n    .. math::\n\n        y = \\frac{x - mean[x]}{ \\sqrt{Var[x] + \\epsilon}} * gamma + beta\n\n    This module differs from the built-in PyTorch BatchNorm1d as the mean and\n    standard-deviation are reduced across all devices during training.\n\n    For example, when one uses `nn.DataParallel` to wrap the network during\n    training, PyTorch\'s implementation normalize the tensor on each device using\n    the statistics only on that device, which accelerated the computation and\n    is also easy to implement, but the statistics might be inaccurate.\n    Instead, in this synchronized version, the statistics will be computed\n    over all training samples distributed on multiple devices.\n\n    Note that, for one-GPU or CPU-only case, this module behaves exactly same\n    as the built-in PyTorch implementation.\n\n    The mean and standard-deviation are calculated per-dimension over\n    the mini-batches and gamma and beta are learnable parameter vectors\n    of size C (where C is the input size).\n\n    During training, this layer keeps a running estimate of its computed mean\n    and variance. The running sum is kept with a default momentum of 0.1.\n\n    During evaluation, this running mean/variance is used for normalization.\n\n    Because the BatchNorm is done over the `C` dimension, computing statistics\n    on `(N, L)` slices, it\'s common terminology to call this Temporal BatchNorm\n\n    Args:\n        num_features: num_features from an expected input of size\n            `batch_size x num_features [x width]`\n        eps: a value added to the denominator for numerical stability.\n            Default: 1e-5\n        momentum: the value used for the running_mean and running_var\n            computation. Default: 0.1\n        affine: a boolean value that when set to ``True``, gives the layer learnable\n            affine parameters. Default: ``True``\n\n    Shape::\n        - Input: :math:`(N, C)` or :math:`(N, C, L)`\n        - Output: :math:`(N, C)` or :math:`(N, C, L)` (same shape as input)\n\n    Examples:\n        >>> # With Learnable Parameters\n        >>> m = SynchronizedBatchNorm1d(100)\n        >>> # Without Learnable Parameters\n        >>> m = SynchronizedBatchNorm1d(100, affine=False)\n        >>> input = torch.autograd.Variable(torch.randn(20, 100))\n        >>> output = m(input)\n    """"""\n\n    def _check_input_dim(self, input):\n        if input.dim() != 2 and input.dim() != 3:\n            raise ValueError(\'expected 2D or 3D input (got {}D input)\'\n                             .format(input.dim()))\n        super(SynchronizedBatchNorm1d, self)._check_input_dim(input)\n\n\nclass SynchronizedBatchNorm2d(_SynchronizedBatchNorm):\n    r""""""Applies Batch Normalization over a 4d input that is seen as a mini-batch\n    of 3d inputs\n\n    .. math::\n\n        y = \\frac{x - mean[x]}{ \\sqrt{Var[x] + \\epsilon}} * gamma + beta\n\n    This module differs from the built-in PyTorch BatchNorm2d as the mean and\n    standard-deviation are reduced across all devices during training.\n\n    For example, when one uses `nn.DataParallel` to wrap the network during\n    training, PyTorch\'s implementation normalize the tensor on each device using\n    the statistics only on that device, which accelerated the computation and\n    is also easy to implement, but the statistics might be inaccurate.\n    Instead, in this synchronized version, the statistics will be computed\n    over all training samples distributed on multiple devices.\n\n    Note that, for one-GPU or CPU-only case, this module behaves exactly same\n    as the built-in PyTorch implementation.\n\n    The mean and standard-deviation are calculated per-dimension over\n    the mini-batches and gamma and beta are learnable parameter vectors\n    of size C (where C is the input size).\n\n    During training, this layer keeps a running estimate of its computed mean\n    and variance. The running sum is kept with a default momentum of 0.1.\n\n    During evaluation, this running mean/variance is used for normalization.\n\n    Because the BatchNorm is done over the `C` dimension, computing statistics\n    on `(N, H, W)` slices, it\'s common terminology to call this Spatial BatchNorm\n\n    Args:\n        num_features: num_features from an expected input of\n            size batch_size x num_features x height x width\n        eps: a value added to the denominator for numerical stability.\n            Default: 1e-5\n        momentum: the value used for the running_mean and running_var\n            computation. Default: 0.1\n        affine: a boolean value that when set to ``True``, gives the layer learnable\n            affine parameters. Default: ``True``\n\n    Shape::\n        - Input: :math:`(N, C, H, W)`\n        - Output: :math:`(N, C, H, W)` (same shape as input)\n\n    Examples:\n        >>> # With Learnable Parameters\n        >>> m = SynchronizedBatchNorm2d(100)\n        >>> # Without Learnable Parameters\n        >>> m = SynchronizedBatchNorm2d(100, affine=False)\n        >>> input = torch.autograd.Variable(torch.randn(20, 100, 35, 45))\n        >>> output = m(input)\n    """"""\n\n    def _check_input_dim(self, input):\n        if input.dim() != 4:\n            raise ValueError(\'expected 4D input (got {}D input)\'\n                             .format(input.dim()))\n        super(SynchronizedBatchNorm2d, self)._check_input_dim(input)\n\n\nclass SynchronizedBatchNorm3d(_SynchronizedBatchNorm):\n    r""""""Applies Batch Normalization over a 5d input that is seen as a mini-batch\n    of 4d inputs\n\n    .. math::\n\n        y = \\frac{x - mean[x]}{ \\sqrt{Var[x] + \\epsilon}} * gamma + beta\n\n    This module differs from the built-in PyTorch BatchNorm3d as the mean and\n    standard-deviation are reduced across all devices during training.\n\n    For example, when one uses `nn.DataParallel` to wrap the network during\n    training, PyTorch\'s implementation normalize the tensor on each device using\n    the statistics only on that device, which accelerated the computation and\n    is also easy to implement, but the statistics might be inaccurate.\n    Instead, in this synchronized version, the statistics will be computed\n    over all training samples distributed on multiple devices.\n\n    Note that, for one-GPU or CPU-only case, this module behaves exactly same\n    as the built-in PyTorch implementation.\n\n    The mean and standard-deviation are calculated per-dimension over\n    the mini-batches and gamma and beta are learnable parameter vectors\n    of size C (where C is the input size).\n\n    During training, this layer keeps a running estimate of its computed mean\n    and variance. The running sum is kept with a default momentum of 0.1.\n\n    During evaluation, this running mean/variance is used for normalization.\n\n    Because the BatchNorm is done over the `C` dimension, computing statistics\n    on `(N, D, H, W)` slices, it\'s common terminology to call this Volumetric BatchNorm\n    or Spatio-temporal BatchNorm\n\n    Args:\n        num_features: num_features from an expected input of\n            size batch_size x num_features x depth x height x width\n        eps: a value added to the denominator for numerical stability.\n            Default: 1e-5\n        momentum: the value used for the running_mean and running_var\n            computation. Default: 0.1\n        affine: a boolean value that when set to ``True``, gives the layer learnable\n            affine parameters. Default: ``True``\n\n    Shape::\n        - Input: :math:`(N, C, D, H, W)`\n        - Output: :math:`(N, C, D, H, W)` (same shape as input)\n\n    Examples:\n        >>> # With Learnable Parameters\n        >>> m = SynchronizedBatchNorm3d(100)\n        >>> # Without Learnable Parameters\n        >>> m = SynchronizedBatchNorm3d(100, affine=False)\n        >>> input = torch.autograd.Variable(torch.randn(20, 100, 35, 45, 10))\n        >>> output = m(input)\n    """"""\n\n    def _check_input_dim(self, input):\n        if input.dim() != 5:\n            raise ValueError(\'expected 5D input (got {}D input)\'\n                             .format(input.dim()))\n        super(SynchronizedBatchNorm3d, self)._check_input_dim(input)\n\n\n@contextlib.contextmanager\ndef patch_sync_batchnorm():\n    import torch.nn as nn\n\n    backup = nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d\n\n    nn.BatchNorm1d = SynchronizedBatchNorm1d\n    nn.BatchNorm2d = SynchronizedBatchNorm2d\n    nn.BatchNorm3d = SynchronizedBatchNorm3d\n\n    yield\n\n    nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d = backup\n\n\ndef convert_model(module):\n    """"""Traverse the input module and its child recursively\n       and replace all instance of torch.nn.modules.batchnorm.BatchNorm*N*d\n       to SynchronizedBatchNorm*N*d\n\n    Args:\n        module: the input module needs to be convert to SyncBN model\n\n    Examples:\n        >>> import torch.nn as nn\n        >>> import torchvision\n        >>> # m is a standard pytorch model\n        >>> m = torchvision.models.resnet18(True)\n        >>> m = nn.DataParallel(m)\n        >>> # after convert, m is using SyncBN\n        >>> m = convert_model(m)\n    """"""\n    if isinstance(module, torch.nn.DataParallel):\n        mod = module.module\n        mod = convert_model(mod)\n        mod = DataParallelWithCallback(mod)\n        return mod\n\n    mod = module\n    for pth_module, sync_module in zip([torch.nn.modules.batchnorm.BatchNorm1d,\n                                        torch.nn.modules.batchnorm.BatchNorm2d,\n                                        torch.nn.modules.batchnorm.BatchNorm3d],\n                                       [SynchronizedBatchNorm1d,\n                                        SynchronizedBatchNorm2d,\n                                        SynchronizedBatchNorm3d]):\n        if isinstance(module, pth_module):\n            mod = sync_module(module.num_features, module.eps, module.momentum, module.affine)\n            mod.running_mean = module.running_mean\n            mod.running_var = module.running_var\n            if module.affine:\n                mod.weight.data = module.weight.data.clone().detach()\n                mod.bias.data = module.bias.data.clone().detach()\n\n    for name, child in module.named_children():\n        mod.add_module(name, convert_model(child))\n\n    return mod\n'"
fastreid/layers/sync_bn/batchnorm_reimpl.py,6,"b'#! /usr/bin/env python3\n# -*- coding: utf-8 -*-\n# File   : batchnorm_reimpl.py\n# Author : acgtyrant\n# Date   : 11/01/2018\n#\n# This file is part of Synchronized-BatchNorm-PyTorch.\n# https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n# Distributed under MIT License.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\n\n__all__ = [\'BatchNorm2dReimpl\']\n\n\nclass BatchNorm2dReimpl(nn.Module):\n    """"""\n    A re-implementation of batch normalization, used for testing the numerical\n    stability.\n\n    Author: acgtyrant\n    See also:\n    https://github.com/vacancy/Synchronized-BatchNorm-PyTorch/issues/14\n    """"""\n    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n        super().__init__()\n\n        self.num_features = num_features\n        self.eps = eps\n        self.momentum = momentum\n        self.weight = nn.Parameter(torch.empty(num_features))\n        self.bias = nn.Parameter(torch.empty(num_features))\n        self.register_buffer(\'running_mean\', torch.zeros(num_features))\n        self.register_buffer(\'running_var\', torch.ones(num_features))\n        self.reset_parameters()\n\n    def reset_running_stats(self):\n        self.running_mean.zero_()\n        self.running_var.fill_(1)\n\n    def reset_parameters(self):\n        self.reset_running_stats()\n        init.uniform_(self.weight)\n        init.zeros_(self.bias)\n\n    def forward(self, input_):\n        batchsize, channels, height, width = input_.size()\n        numel = batchsize * height * width\n        input_ = input_.permute(1, 0, 2, 3).contiguous().view(channels, numel)\n        sum_ = input_.sum(1)\n        sum_of_square = input_.pow(2).sum(1)\n        mean = sum_ / numel\n        sumvar = sum_of_square - sum_ * mean\n\n        self.running_mean = (\n                (1 - self.momentum) * self.running_mean\n                + self.momentum * mean.detach()\n        )\n        unbias_var = sumvar / (numel - 1)\n        self.running_var = (\n                (1 - self.momentum) * self.running_var\n                + self.momentum * unbias_var.detach()\n        )\n\n        bias_var = sumvar / numel\n        inv_std = 1 / (bias_var + self.eps).pow(0.5)\n        output = (\n                (input_ - mean.unsqueeze(1)) * inv_std.unsqueeze(1) *\n                self.weight.unsqueeze(1) + self.bias.unsqueeze(1))\n\n        return output.view(channels, batchsize, height, width).permute(1, 0, 2, 3).contiguous()\n\n'"
fastreid/layers/sync_bn/comm.py,0,"b'# -*- coding: utf-8 -*-\n# File   : comm.py\n# Author : Jiayuan Mao\n# Email  : maojiayuan@gmail.com\n# Date   : 27/01/2018\n# \n# This file is part of Synchronized-BatchNorm-PyTorch.\n# https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n# Distributed under MIT License.\n\nimport queue\nimport collections\nimport threading\n\n__all__ = [\'FutureResult\', \'SlavePipe\', \'SyncMaster\']\n\n\nclass FutureResult(object):\n    """"""A thread-safe future implementation. Used only as one-to-one pipe.""""""\n\n    def __init__(self):\n        self._result = None\n        self._lock = threading.Lock()\n        self._cond = threading.Condition(self._lock)\n\n    def put(self, result):\n        with self._lock:\n            assert self._result is None, \'Previous result has\\\'t been fetched.\'\n            self._result = result\n            self._cond.notify()\n\n    def get(self):\n        with self._lock:\n            if self._result is None:\n                self._cond.wait()\n\n            res = self._result\n            self._result = None\n            return res\n\n\n_MasterRegistry = collections.namedtuple(\'MasterRegistry\', [\'result\'])\n_SlavePipeBase = collections.namedtuple(\'_SlavePipeBase\', [\'identifier\', \'queue\', \'result\'])\n\n\nclass SlavePipe(_SlavePipeBase):\n    """"""Pipe for master-slave communication.""""""\n\n    def run_slave(self, msg):\n        self.queue.put((self.identifier, msg))\n        ret = self.result.get()\n        self.queue.put(True)\n        return ret\n\n\nclass SyncMaster(object):\n    """"""An abstract `SyncMaster` object.\n\n    - During the replication, as the data parallel will trigger an callback of each module, all slave devices should\n    call `register(id)` and obtain an `SlavePipe` to communicate with the master.\n    - During the forward pass, master device invokes `run_master`, all messages from slave devices will be collected,\n    and passed to a registered callback.\n    - After receiving the messages, the master device should gather the information and determine to message passed\n    back to each slave devices.\n    """"""\n\n    def __init__(self, master_callback):\n        """"""\n\n        Args:\n            master_callback: a callback to be invoked after having collected messages from slave devices.\n        """"""\n        self._master_callback = master_callback\n        self._queue = queue.Queue()\n        self._registry = collections.OrderedDict()\n        self._activated = False\n\n    def __getstate__(self):\n        return {\'master_callback\': self._master_callback}\n\n    def __setstate__(self, state):\n        self.__init__(state[\'master_callback\'])\n\n    def register_slave(self, identifier):\n        """"""\n        Register an slave device.\n\n        Args:\n            identifier: an identifier, usually is the device id.\n\n        Returns: a `SlavePipe` object which can be used to communicate with the master device.\n\n        """"""\n        if self._activated:\n            assert self._queue.empty(), \'Queue is not clean before next initialization.\'\n            self._activated = False\n            self._registry.clear()\n        future = FutureResult()\n        self._registry[identifier] = _MasterRegistry(future)\n        return SlavePipe(identifier, self._queue, future)\n\n    def run_master(self, master_msg):\n        """"""\n        Main entry for the master device in each forward pass.\n        The messages were first collected from each devices (including the master device), and then\n        an callback will be invoked to compute the message to be sent back to each devices\n        (including the master device).\n\n        Args:\n            master_msg: the message that the master want to send to itself. This will be placed as the first\n            message when calling `master_callback`. For detailed usage, see `_SynchronizedBatchNorm` for an example.\n\n        Returns: the message to be sent back to the master device.\n\n        """"""\n        self._activated = True\n\n        intermediates = [(0, master_msg)]\n        for i in range(self.nr_slaves):\n            intermediates.append(self._queue.get())\n\n        results = self._master_callback(intermediates)\n        assert results[0][0] == 0, \'The first result should belongs to the master.\'\n\n        for i, res in results:\n            if i == 0:\n                continue\n            self._registry[i].result.put(res)\n\n        for i in range(self.nr_slaves):\n            assert self._queue.get() is True\n\n        return results[0][1]\n\n    @property\n    def nr_slaves(self):\n        return len(self._registry)\n'"
fastreid/layers/sync_bn/replicate.py,1,"b'# -*- coding: utf-8 -*-\n# File   : replicate.py\n# Author : Jiayuan Mao\n# Email  : maojiayuan@gmail.com\n# Date   : 27/01/2018\n# \n# This file is part of Synchronized-BatchNorm-PyTorch.\n# https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n# Distributed under MIT License.\n\nimport functools\n\nfrom torch.nn.parallel.data_parallel import DataParallel\n\n__all__ = [\n    \'CallbackContext\',\n    \'execute_replication_callbacks\',\n    \'DataParallelWithCallback\',\n    \'patch_replication_callback\'\n]\n\n\nclass CallbackContext(object):\n    pass\n\n\ndef execute_replication_callbacks(modules):\n    """"""\n    Execute an replication callback `__data_parallel_replicate__` on each module created by original replication.\n\n    The callback will be invoked with arguments `__data_parallel_replicate__(ctx, copy_id)`\n\n    Note that, as all modules are isomorphism, we assign each sub-module with a context\n    (shared among multiple copies of this module on different devices).\n    Through this context, different copies can share some information.\n\n    We guarantee that the callback on the master copy (the first copy) will be called ahead of calling the callback\n    of any slave copies.\n    """"""\n    master_copy = modules[0]\n    nr_modules = len(list(master_copy.modules()))\n    ctxs = [CallbackContext() for _ in range(nr_modules)]\n\n    for i, module in enumerate(modules):\n        for j, m in enumerate(module.modules()):\n            if hasattr(m, \'__data_parallel_replicate__\'):\n                m.__data_parallel_replicate__(ctxs[j], i)\n\n\nclass DataParallelWithCallback(DataParallel):\n    """"""\n    Data Parallel with a replication callback.\n\n    An replication callback `__data_parallel_replicate__` of each module will be invoked after being created by\n    original `replicate` function.\n    The callback will be invoked with arguments `__data_parallel_replicate__(ctx, copy_id)`\n\n    Examples:\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallelWithCallback(sync_bn, device_ids=[0, 1])\n        # sync_bn.__data_parallel_replicate__ will be invoked.\n    """"""\n\n    def replicate(self, module, device_ids):\n        modules = super(DataParallelWithCallback, self).replicate(module, device_ids)\n        execute_replication_callbacks(modules)\n        return modules\n\n\ndef patch_replication_callback(data_parallel):\n    """"""\n    Monkey-patch an existing `DataParallel` object. Add the replication callback.\n    Useful when you have customized `DataParallel` implementation.\n\n    Examples:\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallel(sync_bn, device_ids=[0, 1])\n        > patch_replication_callback(sync_bn)\n        # this is equivalent to\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallelWithCallback(sync_bn, device_ids=[0, 1])\n    """"""\n\n    assert isinstance(data_parallel, DataParallel)\n\n    old_replicate = data_parallel.replicate\n\n    @functools.wraps(old_replicate)\n    def new_replicate(module, device_ids):\n        modules = old_replicate(module, device_ids)\n        execute_replication_callbacks(modules)\n        return modules\n\n    data_parallel.replicate = new_replicate\n'"
fastreid/layers/sync_bn/unittest.py,1,"b""# -*- coding: utf-8 -*-\n# File   : unittest.py\n# Author : Jiayuan Mao\n# Email  : maojiayuan@gmail.com\n# Date   : 27/01/2018\n#\n# This file is part of Synchronized-BatchNorm-PyTorch.\n# https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n# Distributed under MIT License.\n\nimport unittest\nimport torch\n\n\nclass TorchTestCase(unittest.TestCase):\n    def assertTensorClose(self, x, y):\n        adiff = float((x - y).abs().max())\n        if (y == 0).all():\n            rdiff = 'NaN'\n        else:\n            rdiff = float((adiff / y).abs().max())\n\n        message = (\n            'Tensor close check failed\\n'\n            'adiff={}\\n'\n            'rdiff={}\\n'\n        ).format(adiff, rdiff)\n        self.assertTrue(torch.allclose(x, y), message)\n\n"""
fastreid/modeling/backbones/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom .build import build_backbone, BACKBONE_REGISTRY\n\nfrom .resnet import build_resnet_backbone\nfrom .osnet import build_osnet_backbone\nfrom .resnest import build_resnest_backbone\nfrom .resnext import build_resnext_backbone'"
fastreid/modeling/backbones/build.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom ...utils.registry import Registry\n\nBACKBONE_REGISTRY = Registry(""BACKBONE"")\nBACKBONE_REGISTRY.__doc__ = """"""\nRegistry for backbones, which extract feature maps from images\nThe registered object must be a callable that accepts two arguments:\n1. A :class:`detectron2.config.CfgNode`\n2. A :class:`detectron2.layers.ShapeSpec`, which contains the input shape specification.\nIt must returns an instance of :class:`Backbone`.\n""""""\n\n\ndef build_backbone(cfg):\n    """"""\n    Build a backbone from `cfg.MODEL.BACKBONE.NAME`.\n    Returns:\n        an instance of :class:`Backbone`\n    """"""\n\n    backbone_name = cfg.MODEL.BACKBONE.NAME\n    backbone = BACKBONE_REGISTRY.get(backbone_name)(cfg)\n    return backbone\n'"
fastreid/modeling/backbones/osnet.py,2,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\n# based on:\n# https://github.com/KaiyangZhou/deep-person-reid/blob/master/torchreid/models/osnet.py\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom .build import BACKBONE_REGISTRY\n\nmodel_urls = {\n    \'osnet_x1_0\':\n        \'https://drive.google.com/uc?id=1LaG1EJpHrxdAxKnSCJ_i0u-nbxSAeiFY\',\n    \'osnet_x0_75\':\n        \'https://drive.google.com/uc?id=1uwA9fElHOk3ZogwbeY5GkLI6QPTX70Hq\',\n    \'osnet_x0_5\':\n        \'https://drive.google.com/uc?id=16DGLbZukvVYgINws8u8deSaOqjybZ83i\',\n    \'osnet_x0_25\':\n        \'https://drive.google.com/uc?id=1rb8UN5ZzPKRc_xvtHlyDh-cSz88YX9hs\',\n    \'osnet_ibn_x1_0\':\n        \'https://drive.google.com/uc?id=1sr90V6irlYYDd4_4ISU2iruoRG8J__6l\'\n}\n\n\n##########\n# Basic layers\n##########\nclass ConvLayer(nn.Module):\n    """"""Convolution layer (conv + bn + relu).""""""\n\n    def __init__(\n            self,\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride=1,\n            padding=0,\n            groups=1,\n            IN=False\n    ):\n        super(ConvLayer, self).__init__()\n        self.conv = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride=stride,\n            padding=padding,\n            bias=False,\n            groups=groups\n        )\n        if IN:\n            self.bn = nn.InstanceNorm2d(out_channels, affine=True)\n        else:\n            self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass Conv1x1(nn.Module):\n    """"""1x1 convolution + bn + relu.""""""\n\n    def __init__(self, in_channels, out_channels, stride=1, groups=1):\n        super(Conv1x1, self).__init__()\n        self.conv = nn.Conv2d(\n            in_channels,\n            out_channels,\n            1,\n            stride=stride,\n            padding=0,\n            bias=False,\n            groups=groups\n        )\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass Conv1x1Linear(nn.Module):\n    """"""1x1 convolution + bn (w/o non-linearity).""""""\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(Conv1x1Linear, self).__init__()\n        self.conv = nn.Conv2d(\n            in_channels, out_channels, 1, stride=stride, padding=0, bias=False\n        )\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return x\n\n\nclass Conv3x3(nn.Module):\n    """"""3x3 convolution + bn + relu.""""""\n\n    def __init__(self, in_channels, out_channels, stride=1, groups=1):\n        super(Conv3x3, self).__init__()\n        self.conv = nn.Conv2d(\n            in_channels,\n            out_channels,\n            3,\n            stride=stride,\n            padding=1,\n            bias=False,\n            groups=groups\n        )\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass LightConv3x3(nn.Module):\n    """"""Lightweight 3x3 convolution.\n    1x1 (linear) + dw 3x3 (nonlinear).\n    """"""\n\n    def __init__(self, in_channels, out_channels):\n        super(LightConv3x3, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels, out_channels, 1, stride=1, padding=0, bias=False\n        )\n        self.conv2 = nn.Conv2d(\n            out_channels,\n            out_channels,\n            3,\n            stride=1,\n            padding=1,\n            bias=False,\n            groups=out_channels\n        )\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\n##########\n# Building blocks for omni-scale feature learning\n##########\nclass ChannelGate(nn.Module):\n    """"""A mini-network that generates channel-wise gates conditioned on input tensor.""""""\n\n    def __init__(\n            self,\n            in_channels,\n            num_gates=None,\n            return_gates=False,\n            gate_activation=\'sigmoid\',\n            reduction=16,\n            layer_norm=False\n    ):\n        super(ChannelGate, self).__init__()\n        if num_gates is None: num_gates = in_channels\n        self.return_gates = return_gates\n\n        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n\n        self.fc1 = nn.Conv2d(\n            in_channels,\n            in_channels // reduction,\n            kernel_size=1,\n            bias=True,\n            padding=0\n        )\n        self.norm1 = None\n        if layer_norm: self.norm1 = nn.LayerNorm((in_channels // reduction, 1, 1))\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Conv2d(\n            in_channels // reduction,\n            num_gates,\n            kernel_size=1,\n            bias=True,\n            padding=0\n        )\n        if gate_activation == \'sigmoid\':  self.gate_activation = nn.Sigmoid()\n        elif gate_activation == \'relu\':   self.gate_activation = nn.ReLU(inplace=True)\n        elif gate_activation == \'linear\': self.gate_activation = nn.Identity()\n        else:\n            raise RuntimeError(\n                ""Unknown gate activation: {}"".format(gate_activation)\n            )\n\n    def forward(self, x):\n        input = x\n        x = self.global_avgpool(x)\n        x = self.fc1(x)\n        if self.norm1 is not None: x = self.norm1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.gate_activation(x)\n        if self.return_gates: return x\n        return input * x\n\n\nclass OSBlock(nn.Module):\n    """"""Omni-scale feature learning block.""""""\n\n    def __init__(\n            self,\n            in_channels,\n            out_channels,\n            IN=False,\n            bottleneck_reduction=4,\n            **kwargs\n    ):\n        super(OSBlock, self).__init__()\n        mid_channels = out_channels // bottleneck_reduction\n        self.conv1 = Conv1x1(in_channels, mid_channels)\n        self.conv2a = LightConv3x3(mid_channels, mid_channels)\n        self.conv2b = nn.Sequential(\n            LightConv3x3(mid_channels, mid_channels),\n            LightConv3x3(mid_channels, mid_channels),\n        )\n        self.conv2c = nn.Sequential(\n            LightConv3x3(mid_channels, mid_channels),\n            LightConv3x3(mid_channels, mid_channels),\n            LightConv3x3(mid_channels, mid_channels),\n        )\n        self.conv2d = nn.Sequential(\n            LightConv3x3(mid_channels, mid_channels),\n            LightConv3x3(mid_channels, mid_channels),\n            LightConv3x3(mid_channels, mid_channels),\n            LightConv3x3(mid_channels, mid_channels),\n        )\n        self.gate = ChannelGate(mid_channels)\n        self.conv3 = Conv1x1Linear(mid_channels, out_channels)\n        self.downsample = None\n        if in_channels != out_channels:\n            self.downsample = Conv1x1Linear(in_channels, out_channels)\n        self.IN = None\n        if IN: self.IN = nn.InstanceNorm2d(out_channels, affine=True)\n        self.relu = nn.ReLU(True)\n\n    def forward(self, x):\n        identity = x\n        x1 = self.conv1(x)\n        x2a = self.conv2a(x1)\n        x2b = self.conv2b(x1)\n        x2c = self.conv2c(x1)\n        x2d = self.conv2d(x1)\n        x2 = self.gate(x2a) + self.gate(x2b) + self.gate(x2c) + self.gate(x2d)\n        x3 = self.conv3(x2)\n        if self.downsample is not None:\n            identity = self.downsample(identity)\n        out = x3 + identity\n        if self.IN is not None:\n            out = self.IN(out)\n        return self.relu(out)\n\n\n##########\n# Network architecture\n##########\nclass OSNet(nn.Module):\n    """"""Omni-Scale Network.\n\n    Reference:\n        - Zhou et al. Omni-Scale Feature Learning for Person Re-Identification. ICCV, 2019.\n        - Zhou et al. Learning Generalisable Omni-Scale Representations\n          for Person Re-Identification. arXiv preprint, 2019.\n    """"""\n\n    def __init__(\n            self,\n            blocks,\n            layers,\n            channels,\n            IN=False,\n            **kwargs\n    ):\n        super(OSNet, self).__init__()\n        num_blocks = len(blocks)\n        assert num_blocks == len(layers)\n        assert num_blocks == len(channels) - 1\n\n        # convolutional backbone\n        self.conv1 = ConvLayer(3, channels[0], 7, stride=2, padding=3, IN=IN)\n        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n        self.conv2 = self._make_layer(\n            blocks[0],\n            layers[0],\n            channels[0],\n            channels[1],\n            reduce_spatial_size=True,\n            IN=IN\n        )\n        self.conv3 = self._make_layer(\n            blocks[1],\n            layers[1],\n            channels[1],\n            channels[2],\n            reduce_spatial_size=True\n        )\n        self.conv4 = self._make_layer(\n            blocks[2],\n            layers[2],\n            channels[2],\n            channels[3],\n            reduce_spatial_size=False\n        )\n        self.conv5 = Conv1x1(channels[3], channels[3])\n\n        self._init_params()\n\n    def _make_layer(\n            self,\n            block,\n            layer,\n            in_channels,\n            out_channels,\n            reduce_spatial_size,\n            IN=False\n    ):\n        layers = []\n\n        layers.append(block(in_channels, out_channels, IN=IN))\n        for i in range(1, layer):\n            layers.append(block(out_channels, out_channels, IN=IN))\n\n        if reduce_spatial_size:\n            layers.append(\n                nn.Sequential(\n                    Conv1x1(out_channels, out_channels),\n                    nn.AvgPool2d(2, stride=2),\n                )\n            )\n\n        return nn.Sequential(*layers)\n\n    def _init_params(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(\n                    m.weight, mode=\'fan_out\', nonlinearity=\'relu\'\n                )\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        return x\n\n\ndef init_pretrained_weights(model, key=\'\'):\n    """"""Initializes model with pretrained weights.\n\n    Layers that don\'t match with pretrained layers in name or size are kept unchanged.\n    """"""\n    import os\n    import errno\n    import gdown\n    from collections import OrderedDict\n    import warnings\n    import logging\n\n    logger = logging.getLogger(__name__)\n\n    def _get_torch_home():\n        ENV_TORCH_HOME = \'TORCH_HOME\'\n        ENV_XDG_CACHE_HOME = \'XDG_CACHE_HOME\'\n        DEFAULT_CACHE_DIR = \'~/.cache\'\n        torch_home = os.path.expanduser(\n            os.getenv(\n                ENV_TORCH_HOME,\n                os.path.join(\n                    os.getenv(ENV_XDG_CACHE_HOME, DEFAULT_CACHE_DIR), \'torch\'\n                )\n            )\n        )\n        return torch_home\n\n    torch_home = _get_torch_home()\n    model_dir = os.path.join(torch_home, \'checkpoints\')\n    try:\n        os.makedirs(model_dir)\n    except OSError as e:\n        if e.errno == errno.EEXIST:\n            # Directory already exists, ignore.\n            pass\n        else:\n            # Unexpected OSError, re-raise.\n            raise\n    filename = key + \'_imagenet.pth\'\n    cached_file = os.path.join(model_dir, filename)\n\n    if not os.path.exists(cached_file):\n        gdown.download(model_urls[key], cached_file, quiet=False)\n\n    state_dict = torch.load(cached_file)\n    model_dict = model.state_dict()\n    new_state_dict = OrderedDict()\n    matched_layers, discarded_layers = [], []\n\n    for k, v in state_dict.items():\n        if k.startswith(\'module.\'):\n            k = k[7:]  # discard module.\n\n        if k in model_dict and model_dict[k].size() == v.size():\n            new_state_dict[k] = v\n            matched_layers.append(k)\n        else:\n            discarded_layers.append(k)\n\n    model_dict.update(new_state_dict)\n    model.load_state_dict(model_dict)\n\n    if len(matched_layers) == 0:\n        warnings.warn(\n            \'The pretrained weights from ""{}"" cannot be loaded, \'\n            \'please check the key names manually \'\n            \'(** ignored and continue **)\'.format(cached_file)\n        )\n    else:\n        logger.info(\n            \'Successfully loaded imagenet pretrained weights from ""{}""\'.\n                format(cached_file)\n        )\n        if len(discarded_layers) > 0:\n            logger.info(\n                \'** The following layers are discarded \'\n                \'due to unmatched keys or layer size: {}\'.\n                    format(discarded_layers)\n            )\n\n\n@BACKBONE_REGISTRY.register()\ndef build_osnet_backbone(cfg):\n    """"""\n    Create a OSNet instance from config.\n    Returns:\n        OSNet: a :class:`OSNet` instance\n    """"""\n\n    # fmt: off\n    pretrain = cfg.MODEL.BACKBONE.PRETRAIN\n    with_ibn = cfg.MODEL.BACKBONE.WITH_IBN\n\n    num_blocks_per_stage = [2, 2, 2]\n    num_channels_per_stage = [64, 256, 384, 512]\n    model = OSNet([OSBlock, OSBlock, OSBlock], num_blocks_per_stage, num_channels_per_stage, with_ibn)\n    pretrain_key = \'osnet_ibn_x1_0\' if with_ibn else \'osnet_x1_0\'\n    if pretrain:\n        init_pretrained_weights(model, pretrain_key)\n    return model\n'"
fastreid/modeling/backbones/resnest.py,3,"b'# encoding: utf-8\n# based on:\n# https://github.com/zhanghang1989/ResNeSt/blob/master/resnest/torch/resnest.py\n""""""ResNeSt models""""""\n\nimport logging\nimport math\n\nimport torch\nfrom torch import nn\n\nfrom fastreid.layers import (\n    IBN,\n    Non_local,\n    SplAtConv2d,\n    get_norm,\n)\n\nfrom fastreid.utils.checkpoint import get_unexpected_parameters_message, get_missing_parameters_message\n\nfrom .build import BACKBONE_REGISTRY\n\n_url_format = \'https://hangzh.s3.amazonaws.com/encoding/models/{}-{}.pth\'\n\n_model_sha256 = {name: checksum for checksum, name in [\n    (\'528c19ca\', \'resnest50\'),\n    (\'22405ba7\', \'resnest101\'),\n    (\'75117900\', \'resnest200\'),\n    (\'0cc87c48\', \'resnest269\'),\n]}\n\n\ndef short_hash(name):\n    if name not in _model_sha256:\n        raise ValueError(\'Pretrained model for {name} is not available.\'.format(name=name))\n    return _model_sha256[name][:8]\n\n\nmodel_urls = {name: _url_format.format(name, short_hash(name)) for\n              name in _model_sha256.keys()\n              }\n\n\nclass Bottleneck(nn.Module):\n    """"""ResNet Bottleneck\n    """"""\n    # pylint: disable=unused-argument\n    expansion = 4\n\n    def __init__(self, inplanes, planes, bn_norm, num_splits, with_ibn=False, stride=1, downsample=None,\n                 radix=1, cardinality=1, bottleneck_width=64,\n                 avd=False, avd_first=False, dilation=1, is_first=False,\n                 rectified_conv=False, rectify_avg=False,\n                 dropblock_prob=0.0, last_gamma=False):\n        super(Bottleneck, self).__init__()\n        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n        if with_ibn:\n            self.bn1 = IBN(group_width, bn_norm, num_splits)\n        else:\n            self.bn1 = get_norm(bn_norm, group_width, num_splits)\n        self.dropblock_prob = dropblock_prob\n        self.radix = radix\n        self.avd = avd and (stride > 1 or is_first)\n        self.avd_first = avd_first\n\n        if self.avd:\n            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n            stride = 1\n\n        if radix > 1:\n            self.conv2 = SplAtConv2d(\n                group_width, group_width, kernel_size=3,\n                stride=stride, padding=dilation,\n                dilation=dilation, groups=cardinality, bias=False,\n                radix=radix, rectify=rectified_conv,\n                rectify_avg=rectify_avg,\n                norm_layer=bn_norm, num_splits=num_splits,\n                dropblock_prob=dropblock_prob)\n        elif rectified_conv:\n            from rfconv import RFConv2d\n            self.conv2 = RFConv2d(\n                group_width, group_width, kernel_size=3, stride=stride,\n                padding=dilation, dilation=dilation,\n                groups=cardinality, bias=False,\n                average_mode=rectify_avg)\n            self.bn2 = get_norm(bn_norm, group_width, num_splits)\n        else:\n            self.conv2 = nn.Conv2d(\n                group_width, group_width, kernel_size=3, stride=stride,\n                padding=dilation, dilation=dilation,\n                groups=cardinality, bias=False)\n            self.bn2 = get_norm(bn_norm, group_width, num_splits)\n\n        self.conv3 = nn.Conv2d(\n            group_width, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = get_norm(bn_norm, planes * 4, num_splits)\n\n        if last_gamma:\n            from torch.nn.init import zeros_\n            zeros_(self.bn3.weight)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.dilation = dilation\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        if self.dropblock_prob > 0.0:\n            out = self.dropblock1(out)\n        out = self.relu(out)\n\n        if self.avd and self.avd_first:\n            out = self.avd_layer(out)\n\n        out = self.conv2(out)\n        if self.radix == 1:\n            out = self.bn2(out)\n            if self.dropblock_prob > 0.0:\n                out = self.dropblock2(out)\n            out = self.relu(out)\n\n        if self.avd and not self.avd_first:\n            out = self.avd_layer(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        if self.dropblock_prob > 0.0:\n            out = self.dropblock3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNest(nn.Module):\n    """"""ResNet Variants ResNest\n    Parameters\n    ----------\n    block : Block\n        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n    layers : list of int\n        Numbers of layers in each block\n    classes : int, default 1000\n        Number of classification classes.\n    dilated : bool, default False\n        Applying dilation strategy to pretrained ResNet yielding a stride-8 model,\n        typically used in Semantic Segmentation.\n    norm_layer : object\n        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;\n        for Synchronized Cross-GPU BachNormalization).\n    Reference:\n        - He, Kaiming, et al. ""Deep residual learning for image recognition."" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n        - Yu, Fisher, and Vladlen Koltun. ""Multi-scale context aggregation by dilated convolutions.""\n    """"""\n\n    # pylint: disable=unused-variable\n    def __init__(self, last_stride, bn_norm, num_splits, with_ibn, with_nl, block, layers, non_layers, radix=1, groups=1,\n                 bottleneck_width=64,\n                 dilated=False, dilation=1,\n                 deep_stem=False, stem_width=64, avg_down=False,\n                 rectified_conv=False, rectify_avg=False,\n                 avd=False, avd_first=False,\n                 final_drop=0.0, dropblock_prob=0,\n                 last_gamma=False):\n        self.cardinality = groups\n        self.bottleneck_width = bottleneck_width\n        # ResNet-D params\n        self.inplanes = stem_width * 2 if deep_stem else 64\n        self.avg_down = avg_down\n        self.last_gamma = last_gamma\n        # ResNeSt params\n        self.radix = radix\n        self.avd = avd\n        self.avd_first = avd_first\n\n        super().__init__()\n        self.rectified_conv = rectified_conv\n        self.rectify_avg = rectify_avg\n        if rectified_conv:\n            from rfconv import RFConv2d\n            conv_layer = RFConv2d\n        else:\n            conv_layer = nn.Conv2d\n        conv_kwargs = {\'average_mode\': rectify_avg} if rectified_conv else {}\n        if deep_stem:\n            self.conv1 = nn.Sequential(\n                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n                get_norm(bn_norm, stem_width, num_splits),\n                nn.ReLU(inplace=True),\n                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n                get_norm(bn_norm, stem_width, num_splits),\n                nn.ReLU(inplace=True),\n                conv_layer(stem_width, stem_width * 2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n            )\n        else:\n            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n                                    bias=False, **conv_kwargs)\n        self.bn1 = get_norm(bn_norm, self.inplanes, num_splits)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], 1, bn_norm, num_splits, with_ibn=with_ibn, is_first=False)\n        self.layer2 = self._make_layer(block, 128, layers[1], 2, bn_norm, num_splits, with_ibn=with_ibn)\n        if dilated or dilation == 4:\n            self.layer3 = self._make_layer(block, 256, layers[2], 1, bn_norm, num_splits, with_ibn=with_ibn,\n                                           dilation=2, dropblock_prob=dropblock_prob)\n            self.layer4 = self._make_layer(block, 512, layers[3], 1, bn_norm, num_splits, with_ibn=with_ibn,\n                                           dilation=4, dropblock_prob=dropblock_prob)\n        elif dilation == 2:\n            self.layer3 = self._make_layer(block, 256, layers[2], 2, bn_norm, num_splits, with_ibn=with_ibn,\n                                           dilation=1, dropblock_prob=dropblock_prob)\n            self.layer4 = self._make_layer(block, 512, layers[3], 1, bn_norm, num_splits, with_ibn=with_ibn,\n                                           dilation=2, dropblock_prob=dropblock_prob)\n        else:\n            self.layer3 = self._make_layer(block, 256, layers[2], 2, bn_norm, num_splits, with_ibn=with_ibn,\n                                           dropblock_prob=dropblock_prob)\n            self.layer4 = self._make_layer(block, 512, layers[3], last_stride, bn_norm, num_splits, with_ibn=with_ibn,\n                                           dropblock_prob=dropblock_prob)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n        if with_nl:\n            self._build_nonlocal(layers, non_layers, bn_norm, num_splits)\n        else:\n            self.NL_1_idx = self.NL_2_idx = self.NL_3_idx = self.NL_4_idx = []\n\n    def _make_layer(self, block, planes, blocks, stride=1, bn_norm=""BN"", num_splits=1, with_ibn=False,\n                    dilation=1, dropblock_prob=0.0, is_first=True):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            down_layers = []\n            if self.avg_down:\n                if dilation == 1:\n                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n                                                    ceil_mode=True, count_include_pad=False))\n                else:\n                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n                                                    ceil_mode=True, count_include_pad=False))\n                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n                                             kernel_size=1, stride=1, bias=False))\n            else:\n                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n                                             kernel_size=1, stride=stride, bias=False))\n            down_layers.append(get_norm(bn_norm, planes * block.expansion, num_splits))\n            downsample = nn.Sequential(*down_layers)\n\n        layers = []\n        if planes == 512:\n            with_ibn = False\n        if dilation == 1 or dilation == 2:\n            layers.append(block(self.inplanes, planes, bn_norm, num_splits, with_ibn, stride, downsample=downsample,\n                                radix=self.radix, cardinality=self.cardinality,\n                                bottleneck_width=self.bottleneck_width,\n                                avd=self.avd, avd_first=self.avd_first,\n                                dilation=1, is_first=is_first, rectified_conv=self.rectified_conv,\n                                rectify_avg=self.rectify_avg,\n                                dropblock_prob=dropblock_prob,\n                                last_gamma=self.last_gamma))\n        elif dilation == 4:\n            layers.append(block(self.inplanes, planes, bn_norm, num_splits, with_ibn, stride, downsample=downsample,\n                                radix=self.radix, cardinality=self.cardinality,\n                                bottleneck_width=self.bottleneck_width,\n                                avd=self.avd, avd_first=self.avd_first,\n                                dilation=2, is_first=is_first, rectified_conv=self.rectified_conv,\n                                rectify_avg=self.rectify_avg,\n                                dropblock_prob=dropblock_prob,\n                                last_gamma=self.last_gamma))\n        else:\n            raise RuntimeError(""=> unknown dilation size: {}"".format(dilation))\n\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, bn_norm, num_splits, with_ibn,\n                                radix=self.radix, cardinality=self.cardinality,\n                                bottleneck_width=self.bottleneck_width,\n                                avd=self.avd, avd_first=self.avd_first,\n                                dilation=dilation, rectified_conv=self.rectified_conv,\n                                rectify_avg=self.rectify_avg,\n                                dropblock_prob=dropblock_prob,\n                                last_gamma=self.last_gamma))\n\n        return nn.Sequential(*layers)\n\n    def _build_nonlocal(self, layers, non_layers, bn_norm, num_splits):\n        self.NL_1 = nn.ModuleList(\n            [Non_local(256, bn_norm, num_splits) for _ in range(non_layers[0])])\n        self.NL_1_idx = sorted([layers[0] - (i + 1) for i in range(non_layers[0])])\n        self.NL_2 = nn.ModuleList(\n            [Non_local(512, bn_norm, num_splits) for _ in range(non_layers[1])])\n        self.NL_2_idx = sorted([layers[1] - (i + 1) for i in range(non_layers[1])])\n        self.NL_3 = nn.ModuleList(\n            [Non_local(1024, bn_norm, num_splits) for _ in range(non_layers[2])])\n        self.NL_3_idx = sorted([layers[2] - (i + 1) for i in range(non_layers[2])])\n        self.NL_4 = nn.ModuleList(\n            [Non_local(2048, bn_norm, num_splits) for _ in range(non_layers[3])])\n        self.NL_4_idx = sorted([layers[3] - (i + 1) for i in range(non_layers[3])])\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        NL1_counter = 0\n        if len(self.NL_1_idx) == 0:\n            self.NL_1_idx = [-1]\n        for i in range(len(self.layer1)):\n            x = self.layer1[i](x)\n            if i == self.NL_1_idx[NL1_counter]:\n                _, C, H, W = x.shape\n                x = self.NL_1[NL1_counter](x)\n                NL1_counter += 1\n        # Layer 2\n        NL2_counter = 0\n        if len(self.NL_2_idx) == 0:\n            self.NL_2_idx = [-1]\n        for i in range(len(self.layer2)):\n            x = self.layer2[i](x)\n            if i == self.NL_2_idx[NL2_counter]:\n                _, C, H, W = x.shape\n                x = self.NL_2[NL2_counter](x)\n                NL2_counter += 1\n        # Layer 3\n        NL3_counter = 0\n        if len(self.NL_3_idx) == 0:\n            self.NL_3_idx = [-1]\n        for i in range(len(self.layer3)):\n            x = self.layer3[i](x)\n            if i == self.NL_3_idx[NL3_counter]:\n                _, C, H, W = x.shape\n                x = self.NL_3[NL3_counter](x)\n                NL3_counter += 1\n        # Layer 4\n        NL4_counter = 0\n        if len(self.NL_4_idx) == 0:\n            self.NL_4_idx = [-1]\n        for i in range(len(self.layer4)):\n            x = self.layer4[i](x)\n            if i == self.NL_4_idx[NL4_counter]:\n                _, C, H, W = x.shape\n                x = self.NL_4[NL4_counter](x)\n                NL4_counter += 1\n\n        return x\n\n\n@BACKBONE_REGISTRY.register()\ndef build_resnest_backbone(cfg):\n    """"""\n    Create a ResNest instance from config.\n    Returns:\n        ResNet: a :class:`ResNet` instance.\n    """"""\n\n    # fmt: off\n    pretrain = cfg.MODEL.BACKBONE.PRETRAIN\n    last_stride = cfg.MODEL.BACKBONE.LAST_STRIDE\n    bn_norm = cfg.MODEL.BACKBONE.NORM\n    num_splits = cfg.MODEL.BACKBONE.NORM_SPLIT\n    with_ibn = cfg.MODEL.BACKBONE.WITH_IBN\n    with_se = cfg.MODEL.BACKBONE.WITH_SE\n    with_nl = cfg.MODEL.BACKBONE.WITH_NL\n    depth = cfg.MODEL.BACKBONE.DEPTH\n\n    num_blocks_per_stage = {50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 200: [3, 24, 36, 3], 269: [3, 30, 48, 8]}[depth]\n    nl_layers_per_stage = {50: [0, 2, 3, 0], 101: [0, 2, 3, 0]}[depth]\n    stem_width = {50: 32, 101: 64, 200: 64, 269: 64}[depth]\n    model = ResNest(last_stride, bn_norm, num_splits, with_ibn, with_nl, Bottleneck, num_blocks_per_stage,\n                    nl_layers_per_stage, radix=2, groups=1, bottleneck_width=64,\n                    deep_stem=True, stem_width=stem_width, avg_down=True,\n                    avd=True, avd_first=False)\n    if pretrain:\n        # if not with_ibn:\n        # original resnet\n        state_dict = torch.hub.load_state_dict_from_url(\n            model_urls[\'resnest\' + str(depth)], progress=True, check_hash=True)\n        # else:\n        #     raise KeyError(\'Not implementation ibn in resnest\')\n        # # ibn resnet\n        # state_dict = torch.load(pretrain_path)[\'state_dict\']\n        # # remove module in name\n        # new_state_dict = {}\n        # for k in state_dict:\n        #     new_k = \'.\'.join(k.split(\'.\')[1:])\n        #     if new_k in model.state_dict() and (model.state_dict()[new_k].shape == state_dict[k].shape):\n        #         new_state_dict[new_k] = state_dict[k]\n        # state_dict = new_state_dict\n        incompatible = model.load_state_dict(state_dict, strict=False)\n        logger = logging.getLogger(__name__)\n        if incompatible.missing_keys:\n            logger.info(\n                get_missing_parameters_message(incompatible.missing_keys)\n            )\n        if incompatible.unexpected_keys:\n            logger.info(\n                get_unexpected_parameters_message(incompatible.unexpected_keys)\n            )\n    return model\n'"
fastreid/modeling/backbones/resnet.py,8,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport logging\nimport math\n\nimport torch\nfrom torch import nn\nfrom torch.utils import model_zoo\n\nfrom fastreid.layers import (\n    IBN,\n    SELayer,\n    Non_local,\n    get_norm,\n)\nfrom fastreid.utils.checkpoint import get_missing_parameters_message, get_unexpected_parameters_message\nfrom .build import BACKBONE_REGISTRY\n\nlogger = logging.getLogger(__name__)\nmodel_urls = {\n    18: \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    34: \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    50: \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    101: \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    152: \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n__all__ = [\'ResNet\', \'BasicBlock\', \'Bottleneck\']\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, bn_norm, num_splits, with_ibn=False, with_se=False,\n                 stride=1, downsample=None, reduction=16):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = get_norm(bn_norm, planes, num_splits)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = get_norm(bn_norm, planes, num_splits)\n        self.relu = nn.ReLU(inplace=True)\n        if with_se:\n            self.se = SELayer(planes, reduction)\n        else:\n            self.se = nn.Identity()\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, bn_norm, num_splits, with_ibn=False, with_se=False,\n                 stride=1, downsample=None, reduction=16):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        if with_ibn:\n            self.bn1 = IBN(planes, bn_norm, num_splits)\n        else:\n            self.bn1 = get_norm(bn_norm, planes, num_splits)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = get_norm(bn_norm, planes, num_splits)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = get_norm(bn_norm, planes * 4, num_splits)\n        self.relu = nn.ReLU(inplace=True)\n        if with_se:\n            self.se = SELayer(planes * 4, reduction)\n        else:\n            self.se = nn.Identity()\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        out = self.se(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, last_stride, bn_norm, num_splits, with_ibn, with_se, with_nl, block, layers, non_layers):\n        self.inplanes = 64\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = get_norm(bn_norm, 64, num_splits)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], 1, bn_norm, num_splits, with_ibn, with_se)\n        self.layer2 = self._make_layer(block, 128, layers[1], 2, bn_norm, num_splits, with_ibn, with_se)\n        self.layer3 = self._make_layer(block, 256, layers[2], 2, bn_norm, num_splits, with_ibn, with_se)\n        self.layer4 = self._make_layer(block, 512, layers[3], last_stride, bn_norm, num_splits, with_se=with_se)\n\n        self.random_init()\n\n        if with_nl:\n            self._build_nonlocal(layers, non_layers, bn_norm, num_splits)\n        else:\n            self.NL_1_idx = self.NL_2_idx = self.NL_3_idx = self.NL_4_idx = []\n\n    def _make_layer(self, block, planes, blocks, stride=1, bn_norm=""BN"", num_splits=1, with_ibn=False, with_se=False):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                get_norm(bn_norm, planes * block.expansion, num_splits),\n            )\n\n        layers = []\n        if planes == 512:\n            with_ibn = False\n        layers.append(block(self.inplanes, planes, bn_norm, num_splits, with_ibn, with_se, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, bn_norm, num_splits, with_ibn, with_se))\n\n        return nn.Sequential(*layers)\n\n    def _build_nonlocal(self, layers, non_layers, bn_norm, num_splits):\n        self.NL_1 = nn.ModuleList(\n            [Non_local(256, bn_norm, num_splits) for _ in range(non_layers[0])])\n        self.NL_1_idx = sorted([layers[0] - (i + 1) for i in range(non_layers[0])])\n        self.NL_2 = nn.ModuleList(\n            [Non_local(512, bn_norm, num_splits) for _ in range(non_layers[1])])\n        self.NL_2_idx = sorted([layers[1] - (i + 1) for i in range(non_layers[1])])\n        self.NL_3 = nn.ModuleList(\n            [Non_local(1024, bn_norm, num_splits) for _ in range(non_layers[2])])\n        self.NL_3_idx = sorted([layers[2] - (i + 1) for i in range(non_layers[2])])\n        self.NL_4 = nn.ModuleList(\n            [Non_local(2048, bn_norm, num_splits) for _ in range(non_layers[3])])\n        self.NL_4_idx = sorted([layers[3] - (i + 1) for i in range(non_layers[3])])\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        NL1_counter = 0\n        if len(self.NL_1_idx) == 0:\n            self.NL_1_idx = [-1]\n        for i in range(len(self.layer1)):\n            x = self.layer1[i](x)\n            if i == self.NL_1_idx[NL1_counter]:\n                _, C, H, W = x.shape\n                x = self.NL_1[NL1_counter](x)\n                NL1_counter += 1\n        # Layer 2\n        NL2_counter = 0\n        if len(self.NL_2_idx) == 0:\n            self.NL_2_idx = [-1]\n        for i in range(len(self.layer2)):\n            x = self.layer2[i](x)\n            if i == self.NL_2_idx[NL2_counter]:\n                _, C, H, W = x.shape\n                x = self.NL_2[NL2_counter](x)\n                NL2_counter += 1\n        # Layer 3\n        NL3_counter = 0\n        if len(self.NL_3_idx) == 0:\n            self.NL_3_idx = [-1]\n        for i in range(len(self.layer3)):\n            x = self.layer3[i](x)\n            if i == self.NL_3_idx[NL3_counter]:\n                _, C, H, W = x.shape\n                x = self.NL_3[NL3_counter](x)\n                NL3_counter += 1\n        # Layer 4\n        NL4_counter = 0\n        if len(self.NL_4_idx) == 0:\n            self.NL_4_idx = [-1]\n        for i in range(len(self.layer4)):\n            x = self.layer4[i](x)\n            if i == self.NL_4_idx[NL4_counter]:\n                _, C, H, W = x.shape\n                x = self.NL_4[NL4_counter](x)\n                NL4_counter += 1\n\n        return x\n\n    def random_init(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                nn.init.normal_(m.weight, 0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n\n@BACKBONE_REGISTRY.register()\ndef build_resnet_backbone(cfg):\n    """"""\n    Create a ResNet instance from config.\n    Returns:\n        ResNet: a :class:`ResNet` instance.\n    """"""\n\n    # fmt: off\n    pretrain = cfg.MODEL.BACKBONE.PRETRAIN\n    pretrain_path = cfg.MODEL.BACKBONE.PRETRAIN_PATH\n    last_stride = cfg.MODEL.BACKBONE.LAST_STRIDE\n    bn_norm = cfg.MODEL.BACKBONE.NORM\n    num_splits = cfg.MODEL.BACKBONE.NORM_SPLIT\n    with_ibn = cfg.MODEL.BACKBONE.WITH_IBN\n    with_se = cfg.MODEL.BACKBONE.WITH_SE\n    with_nl = cfg.MODEL.BACKBONE.WITH_NL\n    depth = cfg.MODEL.BACKBONE.DEPTH\n\n    num_blocks_per_stage = {34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], }[depth]\n    nl_layers_per_stage = {34: [3, 4, 6, 3], 50: [0, 2, 3, 0], 101: [0, 2, 9, 0]}[depth]\n    block = {34: BasicBlock, 50: Bottleneck, 101: Bottleneck}[depth]\n    model = ResNet(last_stride, bn_norm, num_splits, with_ibn, with_se, with_nl, block,\n                   num_blocks_per_stage, nl_layers_per_stage)\n    if pretrain:\n        if not with_ibn:\n            try:\n                state_dict = torch.load(pretrain_path)[\'model\']\n                # Remove module.encoder in name\n                new_state_dict = {}\n                for k in state_dict:\n                    new_k = \'.\'.join(k.split(\'.\')[2:])\n                    if new_k in model.state_dict() and (model.state_dict()[new_k].shape == state_dict[k].shape):\n                        new_state_dict[new_k] = state_dict[k]\n                state_dict = new_state_dict\n                logger.info(f""Loading pretrained model from {pretrain_path}"")\n            except FileNotFoundError or KeyError:\n                # original resnet\n                state_dict = model_zoo.load_url(model_urls[depth])\n                logger.info(""Loading pretrained model from torchvision"")\n        else:\n            state_dict = torch.load(pretrain_path)[\'state_dict\']  # ibn-net\n            # Remove module in name\n            new_state_dict = {}\n            for k in state_dict:\n                new_k = \'.\'.join(k.split(\'.\')[1:])\n                if new_k in model.state_dict() and (model.state_dict()[new_k].shape == state_dict[k].shape):\n                    new_state_dict[new_k] = state_dict[k]\n            state_dict = new_state_dict\n            logger.info(f""Loading pretrained model from {pretrain_path}"")\n        incompatible = model.load_state_dict(state_dict, strict=False)\n        if incompatible.missing_keys:\n            logger.info(\n                get_missing_parameters_message(incompatible.missing_keys)\n            )\n        if incompatible.unexpected_keys:\n            logger.info(\n                get_unexpected_parameters_message(incompatible.unexpected_keys)\n            )\n    return model\n'"
fastreid/modeling/backbones/resnext.py,4,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\n# based on:\n# https://github.com/XingangPan/IBN-Net/blob/master/models/imagenet/resnext_ibn_a.py\n\nimport math\nimport logging\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport torch\nfrom ...layers import IBN\nfrom .build import BACKBONE_REGISTRY\n\n\nclass Bottleneck(nn.Module):\n    """"""\n    RexNeXt bottleneck type C\n    """"""\n    expansion = 4\n\n    def __init__(self, inplanes, planes, with_ibn, baseWidth, cardinality, stride=1, downsample=None):\n        """""" Constructor\n        Args:\n            inplanes: input channel dimensionality\n            planes: output channel dimensionality\n            baseWidth: base width.\n            cardinality: num of convolution groups.\n            stride: conv stride. Replaces pooling layer.\n        """"""\n        super(Bottleneck, self).__init__()\n\n        D = int(math.floor(planes * (baseWidth / 64)))\n        C = cardinality\n        self.conv1 = nn.Conv2d(inplanes, D * C, kernel_size=1, stride=1, padding=0, bias=False)\n        if with_ibn:\n            self.bn1 = IBN(D * C)\n        else:\n            self.bn1 = nn.BatchNorm2d(D * C)\n        self.conv2 = nn.Conv2d(D * C, D * C, kernel_size=3, stride=stride, padding=1, groups=C, bias=False)\n        self.bn2 = nn.BatchNorm2d(D * C)\n        self.conv3 = nn.Conv2d(D * C, planes * 4, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.downsample = downsample\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNeXt(nn.Module):\n    """"""\n    ResNext optimized for the ImageNet dataset, as specified in\n    https://arxiv.org/pdf/1611.05431.pdf\n    """"""\n\n    def __init__(self, last_stride, with_ibn, block, layers, baseWidth=4, cardinality=32):\n        """""" Constructor\n        Args:\n            baseWidth: baseWidth for ResNeXt.\n            cardinality: number of convolution groups.\n            layers: config of layers, e.g., [3, 4, 6, 3]\n            num_classes: number of classes\n        """"""\n        super(ResNeXt, self).__init__()\n\n        self.cardinality = cardinality\n        self.baseWidth = baseWidth\n        self.inplanes = 64\n        self.output_size = 64\n\n        self.conv1 = nn.Conv2d(3, 64, 7, 2, 3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], with_ibn=with_ibn)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, with_ibn=with_ibn)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, with_ibn=with_ibn)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=last_stride, with_ibn=with_ibn)\n\n        self.random_init()\n\n    def _make_layer(self, block, planes, blocks, stride=1, with_ibn=False):\n        """""" Stack n bottleneck modules where n is inferred from the depth of the network.\n        Args:\n            block: block type used to construct ResNext\n            planes: number of output channels (need to multiply by block.expansion)\n            blocks: number of blocks to be built\n            stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n        Returns: a Module consisting of n sequential bottlenecks.\n        """"""\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        if planes == 512:\n            with_ibn = False\n        layers.append(block(self.inplanes, planes, with_ibn, self.baseWidth, self.cardinality, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, with_ibn, self.baseWidth, self.cardinality, 1, None))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool1(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        return x\n\n    def random_init(self):\n        self.conv1.weight.data.normal_(0, math.sqrt(2. / (7 * 7 * 64)))\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.InstanceNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n\n@BACKBONE_REGISTRY.register()\ndef build_resnext_backbone(cfg):\n    """"""\n    Create a ResNeXt instance from config.\n    Returns:\n        ResNeXt: a :class:`ResNeXt` instance.\n    """"""\n\n    # fmt: off\n    pretrain = cfg.MODEL.BACKBONE.PRETRAIN\n    pretrain_path = cfg.MODEL.BACKBONE.PRETRAIN_PATH\n    last_stride = cfg.MODEL.BACKBONE.LAST_STRIDE\n    with_ibn = cfg.MODEL.BACKBONE.WITH_IBN\n    with_se = cfg.MODEL.BACKBONE.WITH_SE\n    with_nl = cfg.MODEL.BACKBONE.WITH_NL\n    depth = cfg.MODEL.BACKBONE.DEPTH\n\n    num_blocks_per_stage = {50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], }[depth]\n    nl_layers_per_stage = {50: [0, 2, 3, 0], 101: [0, 2, 3, 0]}[depth]\n    model = ResNeXt(last_stride, with_ibn, Bottleneck, num_blocks_per_stage)\n    if pretrain:\n        # if not with_ibn:\n        # original resnet\n        # state_dict = model_zoo.load_url(model_urls[depth])\n        # else:\n        # ibn resnet\n        state_dict = torch.load(pretrain_path)[\'state_dict\']\n        # remove module in name\n        new_state_dict = {}\n        for k in state_dict:\n            new_k = \'.\'.join(k.split(\'.\')[1:])\n            if new_k in model.state_dict() and (model.state_dict()[new_k].shape == state_dict[k].shape):\n                new_state_dict[new_k] = state_dict[k]\n        state_dict = new_state_dict\n        res = model.load_state_dict(state_dict, strict=False)\n        logger = logging.getLogger(__name__)\n        logger.info(\'missing keys is {}\'.format(res.missing_keys))\n        logger.info(\'unexpected keys is {}\'.format(res.unexpected_keys))\n    return model\n'"
fastreid/modeling/heads/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom .build import REID_HEADS_REGISTRY, build_reid_heads\n\n# import all the meta_arch, so they will be registered\nfrom .linear_head import LinearHead\nfrom .bnneck_head import BNneckHead\nfrom .reduction_head import ReductionHead\n'"
fastreid/modeling/heads/bnneck_head.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom fastreid.layers import *\nfrom fastreid.utils.weight_init import weights_init_kaiming, weights_init_classifier\nfrom .build import REID_HEADS_REGISTRY\n\n\n@REID_HEADS_REGISTRY.register()\nclass BNneckHead(nn.Module):\n    def __init__(self, cfg, in_feat, num_classes, pool_layer=nn.AdaptiveAvgPool2d(1)):\n        super().__init__()\n        self.neck_feat = cfg.MODEL.HEADS.NECK_FEAT\n        self.pool_layer = pool_layer\n\n        self.bnneck = get_norm(cfg.MODEL.HEADS.NORM, in_feat, cfg.MODEL.HEADS.NORM_SPLIT, bias_freeze=True)\n        self.bnneck.apply(weights_init_kaiming)\n\n        # identity classification layer\n        cls_type = cfg.MODEL.HEADS.CLS_LAYER\n        if cls_type == \'linear\':    self.classifier = nn.Linear(in_feat, num_classes, bias=False)\n        elif cls_type == \'arcface\': self.classifier = Arcface(cfg, in_feat, num_classes)\n        elif cls_type == \'circle\':  self.classifier = Circle(cfg, in_feat, num_classes)\n        else:\n            raise KeyError(f""{cls_type} is invalid, please choose from ""\n                           f""\'linear\', \'arcface\' and \'circle\'."")\n\n        self.classifier.apply(weights_init_classifier)\n\n    def forward(self, features, targets=None):\n        """"""\n        See :class:`ReIDHeads.forward`.\n        """"""\n        global_feat = self.pool_layer(features)\n        bn_feat = self.bnneck(global_feat)\n        bn_feat = bn_feat[..., 0, 0]\n        # Evaluation\n        if not self.training: return bn_feat\n        # Training\n        try:              pred_class_logits = self.classifier(bn_feat)\n        except TypeError: pred_class_logits = self.classifier(bn_feat, targets)\n\n        if self.neck_feat == ""before"":  feat = global_feat[..., 0, 0]\n        elif self.neck_feat == ""after"": feat = bn_feat\n        else:\n            raise KeyError(""MODEL.HEADS.NECK_FEAT value is invalid, must choose from (\'after\' & \'before\')"")\n        return pred_class_logits, feat, targets\n'"
fastreid/modeling/heads/build.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom ...utils.registry import Registry\n\nREID_HEADS_REGISTRY = Registry(""HEADS"")\nREID_HEADS_REGISTRY.__doc__ = """"""\nRegistry for ROI heads in a generalized R-CNN model.\nROIHeads take feature maps and region proposals, and\nperform per-region computation.\nThe registered object will be called with `obj(cfg, input_shape)`.\nThe call is expected to return an :class:`ROIHeads`.\n""""""\n\n\ndef build_reid_heads(cfg, in_feat, num_classes, pool_layer):\n    """"""\n    Build REIDHeads defined by `cfg.MODEL.REID_HEADS.NAME`.\n    """"""\n    head = cfg.MODEL.HEADS.NAME\n    return REID_HEADS_REGISTRY.get(head)(cfg, in_feat, num_classes, pool_layer)\n'"
fastreid/modeling/heads/linear_head.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom fastreid.layers import *\nfrom .build import REID_HEADS_REGISTRY\nfrom fastreid.utils.weight_init import weights_init_classifier\n\n\n@REID_HEADS_REGISTRY.register()\nclass LinearHead(nn.Module):\n    def __init__(self, cfg, in_feat, num_classes, pool_layer=nn.AdaptiveAvgPool2d(1)):\n        super().__init__()\n        self.pool_layer = pool_layer\n\n        # identity classification layer\n        cls_type = cfg.MODEL.HEADS.CLS_LAYER\n        if cls_type == \'linear\':    self.classifier = nn.Linear(in_feat, num_classes, bias=False)\n        elif cls_type == \'arcface\': self.classifier = Arcface(cfg, in_feat, num_classes)\n        elif cls_type == \'circle\':  self.classifier = Circle(cfg, in_feat, num_classes)\n        else:\n            raise KeyError(f""{cls_type} is invalid, please choose from ""\n                           f""\'linear\', \'arcface\' and \'circle\'."")\n\n        self.classifier.apply(weights_init_classifier)\n\n    def forward(self, features, targets=None):\n        """"""\n        See :class:`ReIDHeads.forward`.\n        """"""\n        global_feat = self.pool_layer(features)\n        global_feat = global_feat[..., 0, 0]\n        if not self.training: return global_feat\n        # training\n        try:              pred_class_logits = self.classifier(global_feat)\n        except TypeError: pred_class_logits = self.classifier(global_feat, targets)\n        return pred_class_logits, global_feat, targets\n'"
fastreid/modeling/heads/reduction_head.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom fastreid.layers import *\nfrom fastreid.utils.weight_init import weights_init_kaiming, weights_init_classifier\nfrom .build import REID_HEADS_REGISTRY\n\n\n@REID_HEADS_REGISTRY.register()\nclass ReductionHead(nn.Module):\n    def __init__(self, cfg, in_feat, num_classes, pool_layer=nn.AdaptiveAvgPool2d(1)):\n        super().__init__()\n        reduction_dim = cfg.MODEL.HEADS.REDUCTION_DIM\n        self.neck_feat = cfg.MODEL.HEADS.NECK_FEAT\n\n        self.pool_layer = pool_layer\n\n        self.bottleneck = nn.Sequential(\n            nn.Conv2d(in_feat, reduction_dim, 1, 1, bias=False),\n            get_norm(cfg.MODEL.HEADS.NORM, reduction_dim, cfg.MODEL.HEADS.NORM_SPLIT),\n            nn.LeakyReLU(0.1, inplace=True),\n        )\n\n        self.bnneck = get_norm(cfg.MODEL.HEADS.NORM, reduction_dim, cfg.MODEL.HEADS.NORM_SPLIT, bias_freeze=True)\n\n        self.bottleneck.apply(weights_init_kaiming)\n        self.bnneck.apply(weights_init_kaiming)\n\n        # identity classification layer\n        cls_type = cfg.MODEL.HEADS.CLS_LAYER\n        if cls_type == \'linear\':    self.classifier = nn.Linear(reduction_dim, num_classes, bias=False)\n        elif cls_type == \'arcface\': self.classifier = Arcface(cfg, reduction_dim, num_classes)\n        elif cls_type == \'circle\':  self.classifier = Circle(cfg, reduction_dim, num_classes)\n        else:\n            raise KeyError(f""{cls_type} is invalid, please choose from ""\n                           f""\'linear\', \'arcface\' and \'circle\'."")\n\n        self.classifier.apply(weights_init_classifier)\n\n    def forward(self, features, targets=None):\n        """"""\n        See :class:`ReIDHeads.forward`.\n        """"""\n        features = self.pool_layer(features)\n        global_feat = self.bottleneck(features)\n        bn_feat = self.bnneck(global_feat)\n        bn_feat = bn_feat[..., 0, 0]\n        # Evaluation\n        if not self.training: return bn_feat\n        # Training\n        try:              pred_class_logits = self.classifier(bn_feat)\n        except TypeError: pred_class_logits = self.classifier(bn_feat, targets)\n\n        if self.neck_feat == ""before"":  feat = global_feat[..., 0, 0]\n        elif self.neck_feat == ""after"": feat = bn_feat\n        else:\n            raise KeyError(""MODEL.HEADS.NECK_FEAT value is invalid, must choose from (\'after\' & \'before\')"")\n        return pred_class_logits, feat, targets\n'"
fastreid/modeling/losses/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom .build_losses import reid_losses\nfrom .cross_entroy_loss import CrossEntropyLoss\nfrom .focal_loss import FocalLoss\nfrom .metric_loss import *\n'"
fastreid/modeling/losses/build_losses.py,0,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nfrom .. import losses as Loss\n\n\ndef reid_losses(cfg, pred_class_logits, global_features, gt_classes, prefix=\'\') -> dict:\n    loss_dict = {}\n    for loss_name in cfg.MODEL.LOSSES.NAME:\n        loss = getattr(Loss, loss_name)(cfg)(pred_class_logits, global_features, gt_classes)\n        loss_dict.update(loss)\n    # rename\n    named_loss_dict = {}\n    for name in loss_dict.keys():\n        named_loss_dict[prefix + name] = loss_dict[name]\n    del loss_dict\n    return named_loss_dict\n'"
fastreid/modeling/losses/center_loss.py,5,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nimport torch\nfrom torch import nn\n\n\nclass CenterLoss(nn.Module):\n    """"""Center loss.\n    Reference:\n    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n    Args:\n        num_classes (int): number of classes.\n        feat_dim (int): feature dimension.\n    """"""\n\n    def __init__(self, num_classes=751, feat_dim=2048, use_gpu=True):\n        super(CenterLoss, self).__init__()\n        self.num_classes,self.feat_dim = num_classes, feat_dim\n\n        if use_gpu: self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n        else:       self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n\n    def forward(self, x, labels):\n        """"""\n        Args:\n            x: feature matrix with shape (batch_size, feat_dim).\n            labels: ground truth labels with shape (num_classes).\n        """"""\n        assert x.size(0) == labels.size(0), ""features.size(0) is not equal to labels.size(0)""\n\n        batch_size = x.size(0)\n        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n        distmat.addmm_(1, -2, x, self.centers.t())\n\n        classes = torch.arange(self.num_classes).long()\n        classes = classes.to(x.device)\n        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n\n        dist = distmat * mask.float()\n        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n        return loss\n'"
fastreid/modeling/losses/cross_entroy_loss.py,4,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nimport torch\nimport torch.nn.functional as F\n\nfrom fastreid.utils.events import get_event_storage\n\n\nclass CrossEntropyLoss(object):\n    """"""\n    A class that stores information and compute losses about outputs of a Baseline head.\n    """"""\n\n    def __init__(self, cfg):\n        self._num_classes = cfg.MODEL.HEADS.NUM_CLASSES\n        self._eps = cfg.MODEL.LOSSES.CE.EPSILON\n        self._alpha = cfg.MODEL.LOSSES.CE.ALPHA\n        self._scale = cfg.MODEL.LOSSES.CE.SCALE\n\n        self._topk = (1,)\n\n    def _log_accuracy(self, pred_class_logits, gt_classes):\n        """"""\n        Log the accuracy metrics to EventStorage.\n        """"""\n        bsz = pred_class_logits.size(0)\n        maxk = max(self._topk)\n        _, pred_class = pred_class_logits.topk(maxk, 1, True, True)\n        pred_class = pred_class.t()\n        correct = pred_class.eq(gt_classes.view(1, -1).expand_as(pred_class))\n\n        ret = []\n        for k in self._topk:\n            correct_k = correct[:k].view(-1).float().sum(dim=0, keepdim=True)\n            ret.append(correct_k.mul_(1. / bsz))\n\n        storage = get_event_storage()\n        storage.put_scalar(""cls_accuracy"", ret[0])\n\n    def __call__(self, pred_class_logits, _, gt_classes):\n        """"""\n        Compute the softmax cross entropy loss for box classification.\n        Returns:\n            scalar Tensor\n        """"""\n        self._log_accuracy(pred_class_logits, gt_classes)\n        if self._eps >= 0:\n            smooth_param = self._eps\n        else:\n            # adaptive lsr\n            soft_label = F.softmax(pred_class_logits, dim=1)\n            smooth_param = self._alpha * soft_label[torch.arange(soft_label.size(0)), gt_classes].unsqueeze(1)\n\n        log_probs = F.log_softmax(pred_class_logits, dim=1)\n        with torch.no_grad():\n            targets = torch.ones_like(log_probs)\n            targets *= smooth_param / (self._num_classes - 1)\n            targets.scatter_(1, gt_classes.data.unsqueeze(1), (1 - smooth_param))\n\n        loss = (-targets * log_probs).mean(0).sum()\n        return {\n            ""loss_cls"": loss * self._scale,\n        }\n'"
fastreid/modeling/losses/focal_loss.py,14,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nimport torch.nn.functional as F\n\nfrom fastreid.utils.one_hot import one_hot\n\n\n# based on:\n# https://github.com/kornia/kornia/blob/master/kornia/losses/focal.py\n\ndef focal_loss(\n        input: torch.Tensor,\n        target: torch.Tensor,\n        alpha: float,\n        gamma: float = 2.0,\n        reduction: str = \'mean\', ) -> torch.Tensor:\n    r""""""Function that computes Focal loss.\n    See :class:`fastreid.modeling.losses.FocalLoss` for details.\n    """"""\n    if not torch.is_tensor(input):\n        raise TypeError(""Input type is not a torch.Tensor. Got {}""\n                        .format(type(input)))\n\n    if not len(input.shape) >= 2:\n        raise ValueError(""Invalid input shape, we expect BxCx*. Got: {}""\n                         .format(input.shape))\n\n    if input.size(0) != target.size(0):\n        raise ValueError(\'Expected input batch_size ({}) to match target batch_size ({}).\'\n                         .format(input.size(0), target.size(0)))\n\n    n = input.size(0)\n    out_size = (n,) + input.size()[2:]\n    if target.size()[1:] != input.size()[2:]:\n        raise ValueError(\'Expected target size {}, got {}\'.format(\n            out_size, target.size()))\n\n    if not input.device == target.device:\n        raise ValueError(\n            ""input and target must be in the same device. Got: {}"".format(\n                input.device, target.device))\n\n    # compute softmax over the classes axis\n    input_soft = F.softmax(input, dim=1)\n\n    # create the labels one hot tensor\n    target_one_hot = one_hot(\n        target, num_classes=input.shape[1],\n        dtype=input.dtype)\n\n    # compute the actual focal loss\n    weight = torch.pow(-input_soft + 1., gamma)\n\n    focal = -alpha * weight * torch.log(input_soft)\n    loss_tmp = torch.sum(target_one_hot * focal, dim=1)\n\n    if reduction == \'none\':\n        loss = loss_tmp\n    elif reduction == \'mean\':\n        loss = torch.mean(loss_tmp)\n    elif reduction == \'sum\':\n        loss = torch.sum(loss_tmp)\n    else:\n        raise NotImplementedError(""Invalid reduction mode: {}""\n                                  .format(reduction))\n    return loss\n\n\nclass FocalLoss(object):\n    r""""""Criterion that computes Focal loss.\n    According to [1], the Focal loss is computed as follows:\n    .. math::\n        \\text{FL}(p_t) = -\\alpha_t (1 - p_t)^{\\gamma} \\, \\text{log}(p_t)\n    where:\n       - :math:`p_t` is the model\'s estimated probability for each class.\n    Arguments:\n        alpha (float): Weighting factor :math:`\\alpha \\in [0, 1]`.\n        gamma (float): Focusing parameter :math:`\\gamma >= 0`.\n        reduction (str, optional): Specifies the reduction to apply to the\n         output: \xe2\x80\x98none\xe2\x80\x99 | \xe2\x80\x98mean\xe2\x80\x99 | \xe2\x80\x98sum\xe2\x80\x99. \xe2\x80\x98none\xe2\x80\x99: no reduction will be applied,\n         \xe2\x80\x98mean\xe2\x80\x99: the sum of the output will be divided by the number of elements\n         in the output, \xe2\x80\x98sum\xe2\x80\x99: the output will be summed. Default: \xe2\x80\x98none\xe2\x80\x99.\n    Shape:\n        - Input: :math:`(N, C, *)` where C = number of classes.\n        - Target: :math:`(N, *)` where each value is\n          :math:`0 \xe2\x89\xa4 targets[i] \xe2\x89\xa4 C\xe2\x88\x921`.\n    Examples:\n        >>> N = 5  # num_classes\n        >>> loss = FocalLoss(cfg)\n        >>> input = torch.randn(1, N, 3, 5, requires_grad=True)\n        >>> target = torch.empty(1, 3, 5, dtype=torch.long).random_(N)\n        >>> output = loss(input, target)\n        >>> output.backward()\n    References:\n        [1] https://arxiv.org/abs/1708.02002\n    """"""\n\n    # def __init__(self, alpha: float, gamma: float = 2.0,\n    #              reduction: str = \'none\') -> None:\n    def __init__(self, cfg):\n        self._alpha: float = cfg.MODEL.LOSSES.FL.ALPHA\n        self._gamma: float = cfg.MODEL.LOSSES.FL.GAMMA\n        self._scale: float = cfg.MODEL.LOSSES.FL.SCALE\n\n    def __call__(self, pred_class_logits: torch.Tensor, _, gt_classes: torch.Tensor) -> dict:\n        loss = focal_loss(pred_class_logits, gt_classes, self._alpha, self._gamma)\n        return {\n            \'loss_focal\': loss * self._scale,\n        }\n'"
fastreid/modeling/losses/metric_loss.py,19,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nimport torch.nn.functional as F\n\n__all__ = [\n    ""TripletLoss"",\n    ""CircleLoss"",\n]\n\n\ndef normalize(x, axis=-1):\n    """"""Normalizing to unit length along the specified dimension.\n    Args:\n      x: pytorch Variable\n    Returns:\n      x: pytorch Variable, same shape as input\n    """"""\n    x = 1. * x / (torch.norm(x, 2, axis, keepdim=True).expand_as(x) + 1e-12)\n    return x\n\n\ndef euclidean_dist(x, y):\n    m, n = x.size(0), y.size(0)\n    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n    yy = torch.pow(y, 2).sum(1, keepdim=True).expand(n, m).t()\n    dist = xx + yy\n    dist.addmm_(1, -2, x, y.t())\n    dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n    return dist\n\n\ndef cosine_dist(x, y):\n    bs1, bs2 = x.size(0), y.size(0)\n    frac_up = torch.matmul(x, y.transpose(0, 1))\n    frac_down = (torch.sqrt(torch.sum(torch.pow(x, 2), 1))).view(bs1, 1).repeat(1, bs2) * \\\n                (torch.sqrt(torch.sum(torch.pow(y, 2), 1))).view(1, bs2).repeat(bs1, 1)\n    cosine = frac_up / frac_down\n    return 1 - cosine\n\n\ndef softmax_weights(dist, mask):\n    max_v = torch.max(dist * mask, dim=1, keepdim=True)[0]\n    diff = dist - max_v\n    Z = torch.sum(torch.exp(diff) * mask, dim=1, keepdim=True) + 1e-6  # avoid division by zero\n    W = torch.exp(diff) * mask / Z\n    return W\n\n\ndef hard_example_mining(dist_mat, is_pos, is_neg):\n    """"""For each anchor, find the hardest positive and negative sample.\n    Args:\n      dist_mat: pytorch Variable, pair wise distance between samples, shape [N, N]\n      labels: pytorch LongTensor, with shape [N]\n      return_inds: whether to return the indices. Save time if `False`(?)\n    Returns:\n      dist_ap: pytorch Variable, distance(anchor, positive); shape [N]\n      dist_an: pytorch Variable, distance(anchor, negative); shape [N]\n      p_inds: pytorch LongTensor, with shape [N];\n        indices of selected hard positive samples; 0 <= p_inds[i] <= N - 1\n      n_inds: pytorch LongTensor, with shape [N];\n        indices of selected hard negative samples; 0 <= n_inds[i] <= N - 1\n    NOTE: Only consider the case in which all labels have same num of samples,\n      thus we can cope with all anchors in parallel.\n    """"""\n\n    assert len(dist_mat.size()) == 2\n    assert dist_mat.size(0) == dist_mat.size(1)\n    N = dist_mat.size(0)\n\n    # `dist_ap` means distance(anchor, positive)\n    # both `dist_ap` and `relative_p_inds` with shape [N, 1]\n    # pos_dist = dist_mat[is_pos].contiguous().view(N, -1)\n    # ap_weight = F.softmax(pos_dist, dim=1)\n    # dist_ap = torch.sum(ap_weight * pos_dist, dim=1)\n    dist_ap, relative_p_inds = torch.max(\n        dist_mat[is_pos].contiguous().view(N, -1), 1, keepdim=True)\n    # `dist_an` means distance(anchor, negative)\n    # both `dist_an` and `relative_n_inds` with shape [N, 1]\n    dist_an, relative_n_inds = torch.min(\n        dist_mat[is_neg].contiguous().view(N, -1), 1, keepdim=True)\n    # neg_dist = dist_mat[is_neg].contiguous().view(N, -1)\n    # an_weight = F.softmax(-neg_dist, dim=1)\n    # dist_an = torch.sum(an_weight * neg_dist, dim=1)\n\n    # shape [N]\n    dist_ap = dist_ap.squeeze(1)\n    dist_an = dist_an.squeeze(1)\n\n    return dist_ap, dist_an\n\n\ndef weighted_example_mining(dist_mat, is_pos, is_neg):\n    """"""For each anchor, find the weighted positive and negative sample.\n    Args:\n      dist_mat: pytorch Variable, pair wise distance between samples, shape [N, N]\n    Returns:\n      dist_ap: pytorch Variable, distance(anchor, positive); shape [N]\n      dist_an: pytorch Variable, distance(anchor, negative); shape [N]\n    """"""\n    assert len(dist_mat.size()) == 2\n    assert dist_mat.size(0) == dist_mat.size(1)\n\n    is_pos = is_pos.float()\n    is_neg = is_neg.float()\n    dist_ap = dist_mat * is_pos\n    dist_an = dist_mat * is_neg\n\n    weights_ap = softmax_weights(dist_ap, is_pos)\n    weights_an = softmax_weights(-dist_an, is_neg)\n\n    dist_ap = torch.sum(dist_ap * weights_ap, dim=1)\n    dist_an = torch.sum(dist_an * weights_an, dim=1)\n\n    return dist_ap, dist_an\n\n\nclass TripletLoss(object):\n    """"""Modified from Tong Xiao\'s open-reid (https://github.com/Cysu/open-reid).\n    Related Triplet Loss theory can be found in paper \'In Defense of the Triplet\n    Loss for Person Re-Identification\'.""""""\n\n    def __init__(self, cfg):\n        self._margin = cfg.MODEL.LOSSES.TRI.MARGIN\n        self._normalize_feature = cfg.MODEL.LOSSES.TRI.NORM_FEAT\n        self._scale = cfg.MODEL.LOSSES.TRI.SCALE\n        self._hard_mining = cfg.MODEL.LOSSES.TRI.HARD_MINING\n        self._use_cosine_dist = cfg.MODEL.LOSSES.TRI.USE_COSINE_DIST\n\n    def __call__(self, _, global_features, targets):\n        if self._normalize_feature:\n            global_features = normalize(global_features, axis=-1)\n\n        if self._use_cosine_dist:\n            dist_mat = cosine_dist(global_features, global_features)\n        else:\n            dist_mat = euclidean_dist(global_features, global_features)\n\n        N = dist_mat.size(0)\n        is_pos = targets.expand(N, N).eq(targets.expand(N, N).t())\n        is_neg = targets.expand(N, N).ne(targets.expand(N, N).t())\n\n        if self._hard_mining:\n            dist_ap, dist_an = hard_example_mining(dist_mat, is_pos, is_neg)\n        else:\n            dist_ap, dist_an = weighted_example_mining(dist_mat, is_pos, is_neg)\n\n        y = dist_an.new().resize_as_(dist_an).fill_(1)\n\n        if self._margin > 0:\n            loss = F.margin_ranking_loss(dist_an, dist_ap, y, margin=self._margin)\n        else:\n            loss = F.soft_margin_loss(dist_an - dist_ap, y)\n            if loss == float(\'Inf\'): loss = F.margin_ranking_loss(dist_an, dist_ap, y, margin=0.3)\n\n        return {\n            ""loss_triplet"": loss * self._scale,\n        }\n\n\nclass CircleLoss(object):\n    def __init__(self, cfg):\n        self._scale = cfg.MODEL.LOSSES.SCALE_TRI\n\n        self.m = 0.25\n        self.s = 128\n\n    def __call__(self, _, global_features, targets):\n        global_features = normalize(global_features, axis=-1)\n\n        sim_mat = torch.matmul(global_features, global_features.t())\n\n        N = sim_mat.size(0)\n        is_pos = targets.expand(N, N).eq(targets.expand(N, N).t()).float() - torch.eye(N).to(sim_mat.device)\n        is_pos = is_pos.bool()\n        is_neg = targets.expand(N, N).ne(targets.expand(N, N).t())\n\n        s_p = sim_mat[is_pos].contiguous().view(N, -1)\n        s_n = sim_mat[is_neg].contiguous().view(N, -1)\n\n        alpha_p = F.relu(-s_p.detach() + 1 + self.m)\n        alpha_n = F.relu(s_n.detach() + self.m)\n        delta_p = 1 - self.m\n        delta_n = self.m\n\n        logit_p = - self.s * alpha_p * (s_p - delta_p)\n        logit_n = self.s * alpha_n * (s_n - delta_n)\n\n        loss = F.softplus(torch.logsumexp(logit_p, dim=1) + torch.logsumexp(logit_n, dim=1)).mean()\n\n        return {\n            ""loss_circle"": loss * self._scale,\n        }\n'"
fastreid/modeling/meta_arch/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom .build import META_ARCH_REGISTRY, build_model\n\n\n# import all the meta_arch, so they will be registered\nfrom .baseline import Baseline\nfrom .mgn import MGN'"
fastreid/modeling/meta_arch/baseline.py,2,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nfrom torch import nn\n\nfrom fastreid.layers import GeneralizedMeanPoolingP, AdaptiveAvgMaxPool2d\nfrom fastreid.modeling.backbones import build_backbone\nfrom fastreid.modeling.heads import build_reid_heads\nfrom fastreid.modeling.losses import reid_losses\nfrom .build import META_ARCH_REGISTRY\n\n\n@META_ARCH_REGISTRY.register()\nclass Baseline(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.register_buffer(""pixel_mean"", torch.Tensor(cfg.MODEL.PIXEL_MEAN).view(1, -1, 1, 1))\n        self.register_buffer(""pixel_std"", torch.Tensor(cfg.MODEL.PIXEL_STD).view(1, -1, 1, 1))\n        self._cfg = cfg\n        # backbone\n        self.backbone = build_backbone(cfg)\n\n        # head\n        pool_type = cfg.MODEL.HEADS.POOL_LAYER\n        if pool_type == \'avgpool\':      pool_layer = nn.AdaptiveAvgPool2d(1)\n        elif pool_type == \'maxpool\':    pool_layer = nn.AdaptiveMaxPool2d(1)\n        elif pool_type == \'gempool\':    pool_layer = GeneralizedMeanPoolingP()\n        elif pool_type == ""avgmaxpool"": pool_layer = AdaptiveAvgMaxPool2d(1)\n        elif pool_type == ""identity"":   pool_layer = nn.Identity()\n        else:\n            raise KeyError(f""{pool_type} is invalid, please choose from ""\n                           f""\'avgpool\', \'maxpool\', \'gempool\', \'avgmaxpool\' and \'identity\'."")\n\n        in_feat = cfg.MODEL.HEADS.IN_FEAT\n        num_classes = cfg.MODEL.HEADS.NUM_CLASSES\n        self.heads = build_reid_heads(cfg, in_feat, num_classes, pool_layer)\n\n    @property\n    def device(self):\n        return self.pixel_mean.device\n\n    def forward(self, batched_inputs):\n        if not self.training:\n            pred_feat = self.inference(batched_inputs)\n            try:              return pred_feat, batched_inputs[""targets""], batched_inputs[""camid""]\n            except Exception: return pred_feat\n\n        images = self.preprocess_image(batched_inputs)\n        targets = batched_inputs[""targets""].long()\n\n        # training\n        features = self.backbone(images)  # (bs, 2048, 16, 8)\n        return self.heads(features, targets)\n\n    def inference(self, batched_inputs):\n        assert not self.training\n        images = self.preprocess_image(batched_inputs)\n        features = self.backbone(images)  # (bs, 2048, 16, 8)\n        pred_feat = self.heads(features)\n        return pred_feat\n\n    def preprocess_image(self, batched_inputs):\n        """"""\n        Normalize and batch the input images.\n        """"""\n        # images = [x[""images""] for x in batched_inputs]\n        images = batched_inputs[""images""]\n        # images = batched_inputs\n        images.sub_(self.pixel_mean).div_(self.pixel_std)\n        return images\n\n    def losses(self, outputs):\n        logits, feat, targets = outputs\n        return reid_losses(self._cfg, logits, feat, targets)\n'"
fastreid/modeling/meta_arch/build.py,0,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom ...utils.registry import Registry\n\nMETA_ARCH_REGISTRY = Registry(""META_ARCH"")  # noqa F401 isort:skip\nMETA_ARCH_REGISTRY.__doc__ = """"""\nRegistry for meta-architectures, i.e. the whole model.\nThe registered object will be called with `obj(cfg)`\nand expected to return a `nn.Module` object.\n""""""\n\n\ndef build_model(cfg):\n    """"""\n    Build the whole model architecture, defined by ``cfg.MODEL.META_ARCHITECTURE``.\n    Note that it does not load any weights from ``cfg``.\n    """"""\n    meta_arch = cfg.MODEL.META_ARCHITECTURE\n    return META_ARCH_REGISTRY.get(meta_arch)(cfg)\n'"
fastreid/modeling/meta_arch/mgn.py,9,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nimport copy\n\nimport torch\nfrom torch import nn\n\nfrom fastreid.layers import GeneralizedMeanPoolingP, get_norm, AdaptiveAvgMaxPool2d\nfrom fastreid.modeling.backbones import build_backbone\nfrom fastreid.modeling.backbones.resnet import Bottleneck\nfrom fastreid.modeling.heads import build_reid_heads\nfrom fastreid.modeling.losses import reid_losses, CrossEntropyLoss\nfrom fastreid.utils.weight_init import weights_init_kaiming\nfrom .build import META_ARCH_REGISTRY\n\n\n@META_ARCH_REGISTRY.register()\nclass MGN(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.register_buffer(""pixel_mean"", torch.Tensor(cfg.MODEL.PIXEL_MEAN).view(1, -1, 1, 1))\n        self.register_buffer(""pixel_std"", torch.Tensor(cfg.MODEL.PIXEL_STD).view(1, -1, 1, 1))\n        self._cfg = cfg\n\n        # backbone\n        bn_norm = cfg.MODEL.BACKBONE.NORM\n        num_splits = cfg.MODEL.BACKBONE.NORM_SPLIT\n        with_se = cfg.MODEL.BACKBONE.WITH_SE\n\n        backbone = build_backbone(cfg)\n        self.backbone = nn.Sequential(\n            backbone.conv1,\n            backbone.bn1,\n            backbone.relu,\n            backbone.maxpool,\n            backbone.layer1,\n            backbone.layer2,\n            backbone.layer3[0]\n        )\n        res_conv4 = nn.Sequential(*backbone.layer3[1:])\n        res_g_conv5 = backbone.layer4\n\n        res_p_conv5 = nn.Sequential(\n            Bottleneck(1024, 512, bn_norm, num_splits, False, with_se, downsample=nn.Sequential(\n                nn.Conv2d(1024, 2048, 1, bias=False), get_norm(bn_norm, 2048, num_splits))),\n            Bottleneck(2048, 512, bn_norm, num_splits, False, with_se),\n            Bottleneck(2048, 512, bn_norm, num_splits, False, with_se))\n        res_p_conv5.load_state_dict(backbone.layer4.state_dict())\n\n        pool_type = cfg.MODEL.HEADS.POOL_LAYER\n        if pool_type == \'avgpool\':      pool_layer = nn.AdaptiveAvgPool2d(1)\n        elif pool_type == \'maxpool\':    pool_layer = nn.AdaptiveMaxPool2d(1)\n        elif pool_type == \'gempool\':    pool_layer = GeneralizedMeanPoolingP()\n        elif pool_type == ""avgmaxpool"": pool_layer = AdaptiveAvgMaxPool2d(1)\n        elif pool_type == ""identity"":   pool_layer = nn.Identity()\n        else:\n            raise KeyError(f""{pool_type} is invalid, please choose from ""\n                           f""\'avgpool\', \'maxpool\', \'gempool\', \'avgmaxpool\' and \'identity\'."")\n\n        # head\n        in_feat = cfg.MODEL.HEADS.IN_FEAT\n        num_classes = cfg.MODEL.HEADS.NUM_CLASSES\n        # branch1\n        self.b1 = nn.Sequential(\n            copy.deepcopy(res_conv4), copy.deepcopy(res_g_conv5)\n        )\n        self.b1_pool = self._build_pool_reduce(pool_layer, bn_norm, num_splits, reduce_dim=in_feat)\n\n        self.b1_head = build_reid_heads(cfg, in_feat, num_classes, nn.Identity())\n\n        # branch2\n        self.b2 = nn.Sequential(\n            copy.deepcopy(res_conv4), copy.deepcopy(res_p_conv5)\n        )\n        self.b2_pool = self._build_pool_reduce(pool_layer, bn_norm, num_splits, reduce_dim=in_feat)\n        self.b2_head = build_reid_heads(cfg, in_feat, num_classes, nn.Identity())\n\n        self.b21_pool = self._build_pool_reduce(pool_layer, bn_norm, num_splits, reduce_dim=in_feat)\n        self.b21_head = build_reid_heads(cfg, in_feat, num_classes, nn.Identity())\n\n        self.b22_pool = self._build_pool_reduce(pool_layer, bn_norm, num_splits, reduce_dim=in_feat)\n        self.b22_head = build_reid_heads(cfg, in_feat, num_classes, nn.Identity())\n\n        # branch3\n        self.b3 = nn.Sequential(\n            copy.deepcopy(res_conv4), copy.deepcopy(res_p_conv5)\n        )\n        self.b3_pool = self._build_pool_reduce(pool_layer, bn_norm, num_splits, reduce_dim=in_feat)\n        self.b3_head = build_reid_heads(cfg, in_feat, num_classes, nn.Identity())\n\n        self.b31_pool = self._build_pool_reduce(pool_layer, bn_norm, num_splits, reduce_dim=in_feat)\n        self.b31_head = build_reid_heads(cfg, in_feat, num_classes, nn.Identity())\n\n        self.b32_pool = self._build_pool_reduce(pool_layer, bn_norm, num_splits, reduce_dim=in_feat)\n        self.b32_head = build_reid_heads(cfg, in_feat, num_classes, nn.Identity())\n\n        self.b33_pool = self._build_pool_reduce(pool_layer, bn_norm, num_splits, reduce_dim=in_feat)\n        self.b33_head = build_reid_heads(cfg, in_feat, num_classes, nn.Identity())\n\n    @staticmethod\n    def _build_pool_reduce(pool_layer, bn_norm, num_splits, input_dim=2048, reduce_dim=256):\n        pool_reduce = nn.Sequential(\n            pool_layer,\n            nn.Conv2d(input_dim, reduce_dim, 1, bias=False),\n            get_norm(bn_norm, reduce_dim, num_splits),\n            nn.ReLU(True),\n        )\n        pool_reduce.apply(weights_init_kaiming)\n        return pool_reduce\n\n    @property\n    def device(self):\n        return self.pixel_mean.device\n\n    def forward(self, batched_inputs):\n        if not self.training:\n            pred_feat = self.inference(batched_inputs)\n            try:              return pred_feat, batched_inputs[""targets""], batched_inputs[""camid""]\n            except Exception: return pred_feat\n\n        images = self.preprocess_image(batched_inputs)\n        targets = batched_inputs[""targets""].long()\n\n        # Training\n        features = self.backbone(images)  # (bs, 2048, 16, 8)\n\n        # branch1\n        b1_feat = self.b1(features)\n        b1_pool_feat = self.b1_pool(b1_feat)\n        b1_logits, b1_pool_feat, _ = self.b1_head(b1_pool_feat, targets)\n\n        # branch2\n        b2_feat = self.b2(features)\n        # global\n        b2_pool_feat = self.b2_pool(b2_feat)\n        b2_logits, b2_pool_feat, _ = self.b2_head(b2_pool_feat, targets)\n\n        b21_feat, b22_feat = torch.chunk(b2_feat, 2, dim=2)\n        # part1\n        b21_pool_feat = self.b21_pool(b21_feat)\n        b21_logits, b21_pool_feat, _ = self.b21_head(b21_pool_feat, targets)\n        # part2\n        b22_pool_feat = self.b22_pool(b22_feat)\n        b22_logits, b22_pool_feat, _ = self.b22_head(b22_pool_feat, targets)\n\n        # branch3\n        b3_feat = self.b3(features)\n        # global\n        b3_pool_feat = self.b3_pool(b3_feat)\n        b3_logits, b3_pool_feat, _ = self.b3_head(b3_pool_feat, targets)\n\n        b31_feat, b32_feat, b33_feat = torch.chunk(b3_feat, 3, dim=2)\n        # part1\n        b31_pool_feat = self.b31_pool(b31_feat)\n        b31_logits, b31_pool_feat, _ = self.b31_head(b31_pool_feat, targets)\n        # part2\n        b32_pool_feat = self.b32_pool(b32_feat)\n        b32_logits, b32_pool_feat, _ = self.b32_head(b32_pool_feat, targets)\n        # part3\n        b33_pool_feat = self.b33_pool(b33_feat)\n        b33_logits, b33_pool_feat, _ = self.b33_head(b33_pool_feat, targets)\n\n        return (b1_logits, b2_logits, b3_logits, b21_logits, b22_logits, b31_logits, b32_logits, b33_logits), \\\n               (b1_pool_feat, b2_pool_feat, b3_pool_feat,\n                torch.cat((b21_pool_feat, b22_pool_feat), dim=1),\n                torch.cat((b31_pool_feat, b32_pool_feat, b33_pool_feat), dim=1)), \\\n               targets\n\n    def inference(self, batched_inputs):\n        assert not self.training\n        images = self.preprocess_image(batched_inputs)\n        features = self.backbone(images)  # (bs, 2048, 16, 8)\n\n        # branch1\n        b1_feat = self.b1(features)\n        b1_pool_feat = self.b1_pool(b1_feat)\n        b1_pool_feat = self.b1_head(b1_pool_feat)\n\n        # branch2\n        b2_feat = self.b2(features)\n        # global\n        b2_pool_feat = self.b2_pool(b2_feat)\n        b2_pool_feat = self.b2_head(b2_pool_feat)\n\n        b21_feat, b22_feat = torch.chunk(b2_feat, 2, dim=2)\n        # part1\n        b21_pool_feat = self.b21_pool(b21_feat)\n        b21_pool_feat = self.b21_head(b21_pool_feat)\n        # part2\n        b22_pool_feat = self.b22_pool(b22_feat)\n        b22_pool_feat = self.b22_head(b22_pool_feat)\n\n        # branch3\n        b3_feat = self.b3(features)\n        # global\n        b3_pool_feat = self.b3_pool(b3_feat)\n        b3_pool_feat = self.b3_head(b3_pool_feat)\n\n        b31_feat, b32_feat, b33_feat = torch.chunk(b3_feat, 3, dim=2)\n        # part1\n        b31_pool_feat = self.b31_pool(b31_feat)\n        b31_pool_feat = self.b31_head(b31_pool_feat)\n        # part2\n        b32_pool_feat = self.b32_pool(b32_feat)\n        b32_pool_feat = self.b32_head(b32_pool_feat)\n        # part3\n        b33_pool_feat = self.b33_pool(b33_feat)\n        b33_pool_feat = self.b33_head(b33_pool_feat)\n\n        pred_feat = torch.cat([b1_pool_feat, b2_pool_feat, b3_pool_feat, b21_pool_feat,\n                               b22_pool_feat, b31_pool_feat, b32_pool_feat, b33_pool_feat], dim=1)\n        return pred_feat\n\n    def preprocess_image(self, batched_inputs):\n        """"""\n        Normalize and batch the input images.\n        """"""\n        # images = [x[""images""] for x in batched_inputs]\n        images = batched_inputs[""images""]\n        images.sub_(self.pixel_mean).div_(self.pixel_std)\n        return images\n\n    def losses(self, outputs):\n        logits, feats, targets = outputs\n        loss_dict = {}\n        loss_dict.update(reid_losses(self._cfg, logits[0], feats[0], targets, \'b1_\'))\n        loss_dict.update(reid_losses(self._cfg, logits[1], feats[1], targets, \'b2_\'))\n        loss_dict.update(reid_losses(self._cfg, logits[2], feats[2], targets, \'b3_\'))\n        loss_dict.update(reid_losses(self._cfg, logits[3], feats[3], targets, \'b21_\'))\n        loss_dict.update(reid_losses(self._cfg, logits[5], feats[4], targets, \'b31_\'))\n\n        part_ce_loss = [\n            (CrossEntropyLoss(self._cfg)(logits[4], None, targets), \'b22_\'),\n            (CrossEntropyLoss(self._cfg)(logits[6], None, targets), \'b32_\'),\n            (CrossEntropyLoss(self._cfg)(logits[7], None, targets), \'b33_\')\n        ]\n        named_ce_loss = {}\n        for item in part_ce_loss:\n            named_ce_loss[item[1] + [*item[0]][0]] = [*item[0].values()][0]\n        loss_dict.update(named_ce_loss)\n        return loss_dict\n'"
fastreid/solver/optim/__init__.py,1,"b'from .lamb import Lamb\nfrom .lookahead import Lookahead, LookaheadAdam\nfrom .novograd import Novograd\nfrom .over9000 import Over9000, RangerLars\nfrom .radam import RAdam, PlainRAdam, AdamW\nfrom .ralamb import Ralamb\nfrom .ranger import Ranger\nfrom .swa import SWA\n\nfrom torch.optim import *\n'"
fastreid/solver/optim/lamb.py,5,"b'####\n# CODE TAKEN FROM https://github.com/mgrankin/over9000\n####\n\nimport collections\n\nimport torch\nfrom torch.optim.optimizer import Optimizer\nfrom torch.utils.tensorboard import SummaryWriter\n\n\ndef log_lamb_rs(optimizer: Optimizer, event_writer: SummaryWriter, token_count: int):\n    """"""Log a histogram of trust ratio scalars in across layers.""""""\n    results = collections.defaultdict(list)\n    for group in optimizer.param_groups:\n        for p in group[\'params\']:\n            state = optimizer.state[p]\n            for i in (\'weight_norm\', \'adam_norm\', \'trust_ratio\'):\n                if i in state:\n                    results[i].append(state[i])\n\n    for k, v in results.items():\n        event_writer.add_histogram(f\'lamb/{k}\', torch.tensor(v), token_count)\n\n\nclass Lamb(Optimizer):\n    r""""""Implements Lamb algorithm.\n    It has been proposed in `Large Batch Optimization for Deep Learning: Training BERT in 76 minutes`_.\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        adam (bool, optional): always use trust ratio = 1, which turns this into\n            Adam. Useful for comparison purposes.\n    .. _Large Batch Optimization for Deep Learning: Training BERT in 76 minutes:\n        https://arxiv.org/abs/1904.00962\n    """"""\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-6,\n                 weight_decay=0, adam=False):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay)\n        self.adam = adam\n        super(Lamb, self).__init__(params, defaults)\n\n    def step(self, closure=None):\n        """"""Performs a single optimization step.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        """"""\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError(\'Lamb does not support sparse gradients, consider SparseAdam instad.\')\n\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state[\'step\'] = 0\n                    # Exponential moving average of gradient values\n                    state[\'exp_avg\'] = torch.zeros_like(p.data)\n                    # Exponential moving average of squared gradient values\n                    state[\'exp_avg_sq\'] = torch.zeros_like(p.data)\n\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                state[\'step\'] += 1\n\n                # Decay the first and second moment running average coefficient\n                # m_t\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n                # v_t\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n\n                # Paper v3 does not use debiasing.\n                # bias_correction1 = 1 - beta1 ** state[\'step\']\n                # bias_correction2 = 1 - beta2 ** state[\'step\']\n                # Apply bias to lr to avoid broadcast.\n                step_size = group[\'lr\']  # * math.sqrt(bias_correction2) / bias_correction1\n\n                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n\n                adam_step = exp_avg / exp_avg_sq.sqrt().add(group[\'eps\'])\n                if group[\'weight_decay\'] != 0:\n                    adam_step.add_(group[\'weight_decay\'], p.data)\n\n                adam_norm = adam_step.pow(2).sum().sqrt()\n                if weight_norm == 0 or adam_norm == 0:\n                    trust_ratio = 1\n                else:\n                    trust_ratio = weight_norm / adam_norm\n                state[\'weight_norm\'] = weight_norm\n                state[\'adam_norm\'] = adam_norm\n                state[\'trust_ratio\'] = trust_ratio\n                if self.adam:\n                    trust_ratio = 1\n\n                p.data.add_(-step_size * trust_ratio, adam_step)\n\n        return loss\n'"
fastreid/solver/optim/lookahead.py,4,"b'####\n# CODE TAKEN FROM https://github.com/lonePatient/lookahead_pytorch\n# Original paper: https://arxiv.org/abs/1907.08610\n####\n# Lookahead implementation from https://github.com/rwightman/pytorch-image-models/blob/master/timm/optim/lookahead.py\n\n"""""" Lookahead Optimizer Wrapper.\nImplementation modified from: https://github.com/alphadl/lookahead.pytorch\nPaper: `Lookahead Optimizer: k steps forward, 1 step back` - https://arxiv.org/abs/1907.08610\n""""""\nfrom collections import defaultdict\n\nimport torch\nfrom torch.optim import Adam\nfrom torch.optim.optimizer import Optimizer\n\n\nclass Lookahead(Optimizer):\n    def __init__(self, base_optimizer, alpha=0.5, k=6):\n        if not 0.0 <= alpha <= 1.0:\n            raise ValueError(f\'Invalid slow update rate: {alpha}\')\n        if not 1 <= k:\n            raise ValueError(f\'Invalid lookahead steps: {k}\')\n        defaults = dict(lookahead_alpha=alpha, lookahead_k=k, lookahead_step=0)\n        self.base_optimizer = base_optimizer\n        self.param_groups = self.base_optimizer.param_groups\n        self.defaults = base_optimizer.defaults\n        self.defaults.update(defaults)\n        self.state = defaultdict(dict)\n        # manually add our defaults to the param groups\n        for name, default in defaults.items():\n            for group in self.param_groups:\n                group.setdefault(name, default)\n\n    def update_slow(self, group):\n        for fast_p in group[""params""]:\n            if fast_p.grad is None:\n                continue\n            param_state = self.state[fast_p]\n            if \'slow_buffer\' not in param_state:\n                param_state[\'slow_buffer\'] = torch.empty_like(fast_p.data)\n                param_state[\'slow_buffer\'].copy_(fast_p.data)\n            slow = param_state[\'slow_buffer\']\n            slow.add_(group[\'lookahead_alpha\'], fast_p.data - slow)\n            fast_p.data.copy_(slow)\n\n    def sync_lookahead(self):\n        for group in self.param_groups:\n            self.update_slow(group)\n\n    def step(self, closure=None):\n        # print(self.k)\n        # assert id(self.param_groups) == id(self.base_optimizer.param_groups)\n        loss = self.base_optimizer.step(closure)\n        for group in self.param_groups:\n            group[\'lookahead_step\'] += 1\n            if group[\'lookahead_step\'] % group[\'lookahead_k\'] == 0:\n                self.update_slow(group)\n        return loss\n\n    def state_dict(self):\n        fast_state_dict = self.base_optimizer.state_dict()\n        slow_state = {\n            (id(k) if isinstance(k, torch.Tensor) else k): v\n            for k, v in self.state.items()\n        }\n        fast_state = fast_state_dict[\'state\']\n        param_groups = fast_state_dict[\'param_groups\']\n        return {\n            \'state\': fast_state,\n            \'slow_state\': slow_state,\n            \'param_groups\': param_groups,\n        }\n\n    def load_state_dict(self, state_dict):\n        fast_state_dict = {\n            \'state\': state_dict[\'state\'],\n            \'param_groups\': state_dict[\'param_groups\'],\n        }\n        self.base_optimizer.load_state_dict(fast_state_dict)\n\n        # We want to restore the slow state, but share param_groups reference\n        # with base_optimizer. This is a bit redundant but least code\n        slow_state_new = False\n        if \'slow_state\' not in state_dict:\n            print(\'Loading state_dict from optimizer without Lookahead applied.\')\n            state_dict[\'slow_state\'] = defaultdict(dict)\n            slow_state_new = True\n        slow_state_dict = {\n            \'state\': state_dict[\'slow_state\'],\n            \'param_groups\': state_dict[\'param_groups\'],  # this is pointless but saves code\n        }\n        super(Lookahead, self).load_state_dict(slow_state_dict)\n        self.param_groups = self.base_optimizer.param_groups  # make both ref same container\n        if slow_state_new:\n            # reapply defaults to catch missing lookahead specific ones\n            for name, default in self.defaults.items():\n                for group in self.param_groups:\n                    group.setdefault(name, default)\n\n\ndef LookaheadAdam(params, alpha=0.5, k=6, *args, **kwargs):\n    adam = Adam(params, *args, **kwargs)\n    return Lookahead(adam, alpha, k)\n'"
fastreid/solver/optim/novograd.py,11,"b'####\n# CODE TAKEN FROM https://github.com/mgrankin/over9000\n####\n\n# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch\nfrom torch.optim.optimizer import Optimizer\nimport math\n\n\nclass AdamW(Optimizer):\n    """"""Implements AdamW algorithm.\n  \n    It has been proposed in `Adam: A Method for Stochastic Optimization`_.\n  \n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n            algorithm from the paper `On the Convergence of Adam and Beyond`_\n  \n        Adam: A Method for Stochastic Optimization:\n        https://arxiv.org/abs/1412.6980\n        On the Convergence of Adam and Beyond:\n        https://openreview.net/forum?id=ryQu7f-RZ\n    """"""\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n                 weight_decay=0, amsgrad=False):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay, amsgrad=amsgrad)\n        super(AdamW, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(AdamW, self).__setstate__(state)\n        for group in self.param_groups:\n            group.setdefault(\'amsgrad\', False)\n\n    def step(self, closure=None):\n        """"""Performs a single optimization step.\n  \n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        """"""\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError(\'Adam does not support sparse gradients, please consider SparseAdam instead\')\n                amsgrad = group[\'amsgrad\']\n\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state[\'step\'] = 0\n                    # Exponential moving average of gradient values\n                    state[\'exp_avg\'] = torch.zeros_like(p.data)\n                    # Exponential moving average of squared gradient values\n                    state[\'exp_avg_sq\'] = torch.zeros_like(p.data)\n                    if amsgrad:\n                        # Maintains max of all exp. moving avg. of sq. grad. values\n                        state[\'max_exp_avg_sq\'] = torch.zeros_like(p.data)\n\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                if amsgrad:\n                    max_exp_avg_sq = state[\'max_exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                state[\'step\'] += 1\n                # Decay the first and second moment running average coefficient\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                if amsgrad:\n                    # Maintains the maximum of all 2nd moment running avg. till now\n                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n                    # Use the max. for normalizing running avg. of gradient\n                    denom = max_exp_avg_sq.sqrt().add_(group[\'eps\'])\n                else:\n                    denom = exp_avg_sq.sqrt().add_(group[\'eps\'])\n\n                bias_correction1 = 1 - beta1 ** state[\'step\']\n                bias_correction2 = 1 - beta2 ** state[\'step\']\n                step_size = group[\'lr\'] * math.sqrt(bias_correction2) / bias_correction1\n                p.data.add_(-step_size, torch.mul(p.data, group[\'weight_decay\']).addcdiv_(1, exp_avg, denom))\n\n        return loss\n\n\nclass Novograd(Optimizer):\n    """"""\n    Implements Novograd algorithm.\n\n    Args:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.95, 0))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        grad_averaging: gradient averaging\n        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n            algorithm from the paper `On the Convergence of Adam and Beyond`_\n            (default: False)\n    """"""\n\n    def __init__(self, params, lr=1e-3, betas=(0.95, 0), eps=1e-8,\n                 weight_decay=0, grad_averaging=False, amsgrad=False):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay,\n                        grad_averaging=grad_averaging,\n                        amsgrad=amsgrad)\n\n        super(Novograd, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(Novograd, self).__setstate__(state)\n        for group in self.param_groups:\n            group.setdefault(\'amsgrad\', False)\n\n    def step(self, closure=None):\n        """"""Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n            and returns the loss.\n        """"""\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError(\'Sparse gradients are not supported.\')\n                amsgrad = group[\'amsgrad\']\n\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state[\'step\'] = 0\n                    # Exponential moving average of gradient values\n                    state[\'exp_avg\'] = torch.zeros_like(p.data)\n                    # Exponential moving average of squared gradient values\n                    state[\'exp_avg_sq\'] = torch.zeros([]).to(state[\'exp_avg\'].device)\n                    if amsgrad:\n                        # Maintains max of all exp. moving avg. of sq. grad. values\n                        state[\'max_exp_avg_sq\'] = torch.zeros([]).to(state[\'exp_avg\'].device)\n\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                if amsgrad:\n                    max_exp_avg_sq = state[\'max_exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                state[\'step\'] += 1\n\n                norm = torch.sum(torch.pow(grad, 2))\n\n                if exp_avg_sq == 0:\n                    exp_avg_sq.copy_(norm)\n                else:\n                    exp_avg_sq.mul_(beta2).add_(1 - beta2, norm)\n\n                if amsgrad:\n                    # Maintains the maximum of all 2nd moment running avg. till now\n                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n                    # Use the max. for normalizing running avg. of gradient\n                    denom = max_exp_avg_sq.sqrt().add_(group[\'eps\'])\n                else:\n                    denom = exp_avg_sq.sqrt().add_(group[\'eps\'])\n\n                grad.div_(denom)\n                if group[\'weight_decay\'] != 0:\n                    grad.add_(group[\'weight_decay\'], p.data)\n                if group[\'grad_averaging\']:\n                    grad.mul_(1 - beta1)\n                exp_avg.mul_(beta1).add_(grad)\n\n                p.data.add_(-group[\'lr\'], exp_avg)\n\n        return loss\n'"
fastreid/solver/optim/over9000.py,0,"b'####\n# CODE TAKEN FROM https://github.com/mgrankin/over9000\n####\n\nfrom .lookahead import Lookahead\nfrom .ralamb import Ralamb\n\n\n# RAdam + LARS + LookAHead\n\n# Lookahead implementation from https://github.com/lonePatient/lookahead_pytorch/blob/master/optimizer.py\n# RAdam + LARS implementation from https://gist.github.com/redknightlois/c4023d393eb8f92bb44b2ab582d7ec20\n\ndef Over9000(params, alpha=0.5, k=6, *args, **kwargs):\n    ralamb = Ralamb(params, *args, **kwargs)\n    return Lookahead(ralamb, alpha, k)\n\n\nRangerLars = Over9000\n'"
fastreid/solver/optim/radam.py,7,"b'####\n# CODE TAKEN FROM https://github.com/LiyuanLucasLiu/RAdam\n# Paper: https://arxiv.org/abs/1908.03265\n####\n\nimport math\n\nimport torch\nfrom torch.optim.optimizer import Optimizer\n\n\nclass RAdam(Optimizer):\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n\n        self.degenerated_to_sgd = degenerated_to_sgd\n        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n            for param in params:\n                if \'betas\' in param and (param[\'betas\'][0] != betas[0] or param[\'betas\'][1] != betas[1]):\n                    param[\'buffer\'] = [[None, None, None] for _ in range(10)]\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n                        buffer=[[None, None, None] for _ in range(10)])\n        super(RAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(RAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError(\'RAdam does not support sparse gradients\')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state[\'step\'] = 0\n                    state[\'exp_avg\'] = torch.zeros_like(p_data_fp32)\n                    state[\'exp_avg_sq\'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state[\'exp_avg\'] = state[\'exp_avg\'].type_as(p_data_fp32)\n                    state[\'exp_avg_sq\'] = state[\'exp_avg_sq\'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                state[\'step\'] += 1\n                buffered = group[\'buffer\'][int(state[\'step\'] % 10)]\n                if state[\'step\'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state[\'step\']\n                    beta2_t = beta2 ** state[\'step\']\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state[\'step\'] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n\n                    # more conservative since it\'s an approximated value\n                    if N_sma >= 5:\n                        step_size = math.sqrt(\n                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n                                        N_sma_max - 2)) / (1 - beta1 ** state[\'step\'])\n                    elif self.degenerated_to_sgd:\n                        step_size = 1.0 / (1 - beta1 ** state[\'step\'])\n                    else:\n                        step_size = -1\n                    buffered[2] = step_size\n\n                # more conservative since it\'s an approximated value\n                if N_sma >= 5:\n                    if group[\'weight_decay\'] != 0:\n                        p_data_fp32.add_(-group[\'weight_decay\'] * group[\'lr\'], p_data_fp32)\n                    denom = exp_avg_sq.sqrt().add_(group[\'eps\'])\n                    p_data_fp32.addcdiv_(-step_size * group[\'lr\'], exp_avg, denom)\n                    p.data.copy_(p_data_fp32)\n                elif step_size > 0:\n                    if group[\'weight_decay\'] != 0:\n                        p_data_fp32.add_(-group[\'weight_decay\'] * group[\'lr\'], p_data_fp32)\n                    p_data_fp32.add_(-step_size * group[\'lr\'], exp_avg)\n                    p.data.copy_(p_data_fp32)\n\n        return loss\n\n\nclass PlainRAdam(Optimizer):\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n\n        self.degenerated_to_sgd = degenerated_to_sgd\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n\n        super(PlainRAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(PlainRAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError(\'RAdam does not support sparse gradients\')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state[\'step\'] = 0\n                    state[\'exp_avg\'] = torch.zeros_like(p_data_fp32)\n                    state[\'exp_avg_sq\'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state[\'exp_avg\'] = state[\'exp_avg\'].type_as(p_data_fp32)\n                    state[\'exp_avg_sq\'] = state[\'exp_avg_sq\'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                state[\'step\'] += 1\n                beta2_t = beta2 ** state[\'step\']\n                N_sma_max = 2 / (1 - beta2) - 1\n                N_sma = N_sma_max - 2 * state[\'step\'] * beta2_t / (1 - beta2_t)\n\n                # more conservative since it\'s an approximated value\n                if N_sma >= 5:\n                    if group[\'weight_decay\'] != 0:\n                        p_data_fp32.add_(-group[\'weight_decay\'] * group[\'lr\'], p_data_fp32)\n                    step_size = group[\'lr\'] * math.sqrt(\n                        (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n                                    N_sma_max - 2)) / (1 - beta1 ** state[\'step\'])\n                    denom = exp_avg_sq.sqrt().add_(group[\'eps\'])\n                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n                    p.data.copy_(p_data_fp32)\n                elif self.degenerated_to_sgd:\n                    if group[\'weight_decay\'] != 0:\n                        p_data_fp32.add_(-group[\'weight_decay\'] * group[\'lr\'], p_data_fp32)\n                    step_size = group[\'lr\'] / (1 - beta1 ** state[\'step\'])\n                    p_data_fp32.add_(-step_size, exp_avg)\n                    p.data.copy_(p_data_fp32)\n\n        return loss\n\n\nclass AdamW(Optimizer):\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup=0):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay, warmup=warmup)\n        super(AdamW, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(AdamW, self).__setstate__(state)\n\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError(\'Adam does not support sparse gradients, please consider SparseAdam instead\')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state[\'step\'] = 0\n                    state[\'exp_avg\'] = torch.zeros_like(p_data_fp32)\n                    state[\'exp_avg_sq\'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state[\'exp_avg\'] = state[\'exp_avg\'].type_as(p_data_fp32)\n                    state[\'exp_avg_sq\'] = state[\'exp_avg_sq\'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                state[\'step\'] += 1\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                denom = exp_avg_sq.sqrt().add_(group[\'eps\'])\n                bias_correction1 = 1 - beta1 ** state[\'step\']\n                bias_correction2 = 1 - beta2 ** state[\'step\']\n\n                if group[\'warmup\'] > state[\'step\']:\n                    scheduled_lr = 1e-8 + state[\'step\'] * group[\'lr\'] / group[\'warmup\']\n                else:\n                    scheduled_lr = group[\'lr\']\n\n                step_size = scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n\n                if group[\'weight_decay\'] != 0:\n                    p_data_fp32.add_(-group[\'weight_decay\'] * scheduled_lr, p_data_fp32)\n\n                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n\n                p.data.copy_(p_data_fp32)\n\n        return loss\n'"
fastreid/solver/optim/ralamb.py,3,"b""####\n# CODE TAKEN FROM https://github.com/mgrankin/over9000\n####\n\nimport torch, math\nfrom torch.optim.optimizer import Optimizer\n\n# RAdam + LARS\nclass Ralamb(Optimizer):\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n        self.buffer = [[None, None, None] for ind in range(10)]\n        super(Ralamb, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(Ralamb, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError('Ralamb does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                # Decay the first and second moment running average coefficient\n                # m_t\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n                # v_t\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n\n                state['step'] += 1\n                buffered = self.buffer[int(state['step'] % 10)]\n\n                if state['step'] == buffered[0]:\n                    N_sma, radam_step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n\n                    # more conservative since it's an approximated value\n                    if N_sma >= 5:\n                        radam_step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n                    else:\n                        radam_step_size = 1.0 / (1 - beta1 ** state['step'])\n                    buffered[2] = radam_step_size\n\n                if group['weight_decay'] != 0:\n                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n\n                # more conservative since it's an approximated value\n                radam_step = p_data_fp32.clone()\n                if N_sma >= 5:\n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    radam_step.addcdiv_(-radam_step_size * group['lr'], exp_avg, denom)\n                else:\n                    radam_step.add_(-radam_step_size * group['lr'], exp_avg)\n\n                radam_norm = radam_step.pow(2).sum().sqrt()\n                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n                if weight_norm == 0 or radam_norm == 0:\n                    trust_ratio = 1\n                else:\n                    trust_ratio = weight_norm / radam_norm\n\n                state['weight_norm'] = weight_norm\n                state['adam_norm'] = radam_norm\n                state['trust_ratio'] = trust_ratio\n\n                if N_sma >= 5:\n                    p_data_fp32.addcdiv_(-radam_step_size * group['lr'] * trust_ratio, exp_avg, denom)\n                else:\n                    p_data_fp32.add_(-radam_step_size * group['lr'] * trust_ratio, exp_avg)\n\n                p.data.copy_(p_data_fp32)\n\n        return loss"""
fastreid/solver/optim/ranger.py,5,"b'# Ranger deep learning optimizer - RAdam + Lookahead + Gradient Centralization, combined into one optimizer.\n\n# https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n# and/or\n# https://github.com/lessw2020/Best-Deep-Learning-Optimizers\n\n# Ranger has now been used to capture 12 records on the FastAI leaderboard.\n\n# This version = 20.4.11\n\n# Credits:\n# Gradient Centralization --> https://arxiv.org/abs/2004.01461v2 (a new optimization technique for DNNs), github:  https://github.com/Yonghongwei/Gradient-Centralization\n# RAdam -->  https://github.com/LiyuanLucasLiu/RAdam\n# Lookahead --> rewritten by lessw2020, but big thanks to Github @LonePatient and @RWightman for ideas from their code.\n# Lookahead paper --> MZhang,G Hinton  https://arxiv.org/abs/1907.08610\n\n# summary of changes:\n# 4/11/20 - add gradient centralization option.  Set new testing benchmark for accuracy with it, toggle with use_gc flag at init.\n# full code integration with all updates at param level instead of group, moves slow weights into state dict (from generic weights),\n# supports group learning rates (thanks @SHolderbach), fixes sporadic load from saved model issues.\n# changes 8/31/19 - fix references to *self*.N_sma_threshold;\n# changed eps to 1e-5 as better default than 1e-8.\n\nimport math\n\nimport torch\nfrom torch.optim.optimizer import Optimizer\n\n\nclass Ranger(Optimizer):\n\n    def __init__(self, params, lr=1e-3,  # lr\n                 alpha=0.5, k=6, N_sma_threshhold=5,  # Ranger options\n                 betas=(.95, 0.999), eps=1e-5, weight_decay=0,  # Adam options\n                 use_gc=True, gc_conv_only=False\n                 # Gradient centralization on or off, applied to conv layers only or conv + fc layers\n                 ):\n\n        # parameter checks\n        if not 0.0 <= alpha <= 1.0:\n            raise ValueError(f\'Invalid slow update rate: {alpha}\')\n        if not 1 <= k:\n            raise ValueError(f\'Invalid lookahead steps: {k}\')\n        if not lr > 0:\n            raise ValueError(f\'Invalid Learning Rate: {lr}\')\n        if not eps > 0:\n            raise ValueError(f\'Invalid eps: {eps}\')\n\n        # parameter comments:\n        # beta1 (momentum) of .95 seems to work better than .90...\n        # N_sma_threshold of 5 seems better in testing than 4.\n        # In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.\n\n        # prep defaults and init torch.optim base\n        defaults = dict(lr=lr, alpha=alpha, k=k, step_counter=0, betas=betas, N_sma_threshhold=N_sma_threshhold,\n                        eps=eps, weight_decay=weight_decay)\n        super().__init__(params, defaults)\n\n        # adjustable threshold\n        self.N_sma_threshhold = N_sma_threshhold\n\n        # look ahead params\n\n        self.alpha = alpha\n        self.k = k\n\n        # radam buffer for state\n        self.radam_buffer = [[None, None, None] for ind in range(10)]\n\n        # gc on or off\n        self.use_gc = use_gc\n\n        # level of gradient centralization\n        self.gc_gradient_threshold = 3 if gc_conv_only else 1\n\n        print(f""Ranger optimizer loaded. \\nGradient Centralization usage = {self.use_gc}"")\n        if (self.use_gc and self.gc_gradient_threshold == 1):\n            print(f""GC applied to both conv and fc layers"")\n        elif (self.use_gc and self.gc_gradient_threshold == 3):\n            print(f""GC applied to conv layers only"")\n\n    def __setstate__(self, state):\n        print(""set state called"")\n        super(Ranger, self).__setstate__(state)\n\n    def step(self, closure=None):\n        loss = None\n        # note - below is commented out b/c I have other work that passes back the loss as a float, and thus not a callable closure.\n        # Uncomment if you need to use the actual closure...\n\n        # if closure is not None:\n        # loss = closure()\n\n        # Evaluate averages and grad, update param tensors\n        for group in self.param_groups:\n\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n\n                if grad.is_sparse:\n                    raise RuntimeError(\'Ranger optimizer does not support sparse gradients\')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]  # get state dict for this param\n\n                if len(state) == 0:  # if first time to run...init dictionary with our desired entries\n                    # if self.first_run_check==0:\n                    # self.first_run_check=1\n                    # print(""Initializing slow buffer...should not see this at load from saved model!"")\n                    state[\'step\'] = 0\n                    state[\'exp_avg\'] = torch.zeros_like(p_data_fp32)\n                    state[\'exp_avg_sq\'] = torch.zeros_like(p_data_fp32)\n\n                    # look ahead weight storage now in state dict\n                    state[\'slow_buffer\'] = torch.empty_like(p.data)\n                    state[\'slow_buffer\'].copy_(p.data)\n\n                else:\n                    state[\'exp_avg\'] = state[\'exp_avg\'].type_as(p_data_fp32)\n                    state[\'exp_avg_sq\'] = state[\'exp_avg_sq\'].type_as(p_data_fp32)\n\n                # begin computations\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                # GC operation for Conv layers and FC layers\n                if grad.dim() > self.gc_gradient_threshold:\n                    grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n\n                state[\'step\'] += 1\n\n                # compute variance mov avg\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                # compute mean moving avg\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                buffered = self.radam_buffer[int(state[\'step\'] % 10)]\n\n                if state[\'step\'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state[\'step\']\n                    beta2_t = beta2 ** state[\'step\']\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state[\'step\'] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n                    if N_sma > self.N_sma_threshhold:\n                        step_size = math.sqrt(\n                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n                                    N_sma_max - 2)) / (1 - beta1 ** state[\'step\'])\n                    else:\n                        step_size = 1.0 / (1 - beta1 ** state[\'step\'])\n                    buffered[2] = step_size\n\n                if group[\'weight_decay\'] != 0:\n                    p_data_fp32.add_(-group[\'weight_decay\'] * group[\'lr\'], p_data_fp32)\n\n                # apply lr\n                if N_sma > self.N_sma_threshhold:\n                    denom = exp_avg_sq.sqrt().add_(group[\'eps\'])\n                    p_data_fp32.addcdiv_(-step_size * group[\'lr\'], exp_avg, denom)\n                else:\n                    p_data_fp32.add_(-step_size * group[\'lr\'], exp_avg)\n\n                p.data.copy_(p_data_fp32)\n\n                # integrated look ahead...\n                # we do it at the param level instead of group level\n                if state[\'step\'] % group[\'k\'] == 0:\n                    slow_p = state[\'slow_buffer\']  # get access to slow param tensor\n                    slow_p.add_(self.alpha, p.data - slow_p)  # (fast weights - slow weights) * alpha\n                    p.data.copy_(slow_p)  # copy interpolated weights to RAdam param tensor\n\n        return loss\n'"
fastreid/solver/optim/swa.py,7,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n# based on:\n# https://github.com/pytorch/contrib/blob/master/torchcontrib/optim/swa.py\n\nimport warnings\nfrom collections import defaultdict\n\nimport torch\nfrom torch.optim.optimizer import Optimizer\n\n\nclass SWA(Optimizer):\n    def __init__(self, optimizer, swa_freq=None, swa_lr_factor=None):\n        r""""""Implements Stochastic Weight Averaging (SWA).\n        Stochastic Weight Averaging was proposed in `Averaging Weights Leads to\n        Wider Optima and Better Generalization`_ by Pavel Izmailov, Dmitrii\n        Podoprikhin, Timur Garipov, Dmitry Vetrov and Andrew Gordon Wilson\n        (UAI 2018).\n        SWA is implemented as a wrapper class taking optimizer instance as input\n        and applying SWA on top of that optimizer.\n        SWA can be used in two modes: automatic and manual. In the automatic\n        mode SWA running averages are automatically updated every\n        :attr:`swa_freq` steps after :attr:`swa_start` steps of optimization. If\n        :attr:`swa_lr` is provided, the learning rate of the optimizer is reset\n        to :attr:`swa_lr` at every step starting from :attr:`swa_start`. To use\n        SWA in automatic mode provide values for both :attr:`swa_start` and\n        :attr:`swa_freq` arguments.\n        Alternatively, in the manual mode, use :meth:`update_swa` or\n        :meth:`update_swa_group` methods to update the SWA running averages.\n        In the end of training use `swap_swa_sgd` method to set the optimized\n        variables to the computed averages.\n        Args:\n            swa_freq (int): number of steps between subsequent updates of\n                SWA running averages in automatic mode; if None, manual mode is\n                selected (default: None)\n            swa_lr (float): learning rate to use starting from step swa_start\n                in automatic mode; if None, learning rate is not changed\n                (default: None)\n        Examples:\n            >>> # automatic mode\n            >>> base_opt = torch.optim.SGD(model.parameters(), lr=0.1)\n            >>> opt = SWA(base_opt, swa_start=10, swa_freq=5, swa_lr=0.05)\n            >>> for _ in range(100):\n            >>>     opt.zero_grad()\n            >>>     loss_fn(model(input), target).backward()\n            >>>     opt.step()\n            >>> opt.swap_swa_param()\n            >>> # manual mode\n            >>> opt = SWA(base_opt)\n            >>> for i in range(100):\n            >>>     opt.zero_grad()\n            >>>     loss_fn(model(input), target).backward()\n            >>>     opt.step()\n            >>>     if i > 10 and i % 5 == 0:\n            >>>         opt.update_swa()\n            >>> opt.swap_swa_param()\n        .. note::\n            SWA does not support parameter-specific values of :attr:`swa_start`,\n            :attr:`swa_freq` or :attr:`swa_lr`. In automatic mode SWA uses the\n            same :attr:`swa_start`, :attr:`swa_freq` and :attr:`swa_lr` for all\n            parameter groups. If needed, use manual mode with\n            :meth:`update_swa_group` to use different update schedules for\n            different parameter groups.\n        .. note::\n            Call :meth:`swap_swa_sgd` in the end of training to use the computed\n            running averages.\n        .. note::\n            If you are using SWA to optimize the parameters of a Neural Network\n            containing Batch Normalization layers, you need to update the\n            :attr:`running_mean` and :attr:`running_var` statistics of the\n            Batch Normalization module. You can do so by using\n            `torchcontrib.optim.swa.bn_update` utility.\n        .. note::\n            See the blogpost\n            https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/\n            for an extended description of this SWA implementation.\n        .. note::\n            The repo https://github.com/izmailovpavel/contrib_swa_examples\n            contains examples of using this SWA implementation.\n        .. _Averaging Weights Leads to Wider Optima and Better Generalization:\n            https://arxiv.org/abs/1803.05407\n        .. _Improving Consistency-Based Semi-Supervised Learning with Weight\n            Averaging:\n            https://arxiv.org/abs/1806.05594\n        """"""\n        self._auto_mode, (self.swa_freq,) = self._check_params(swa_freq)\n        self.swa_lr_factor = swa_lr_factor\n\n        if self._auto_mode:\n            if swa_freq < 1:\n                raise ValueError(""Invalid swa_freq: {}"".format(swa_freq))\n        else:\n            if self.swa_lr_factor is not None:\n                warnings.warn(\n                    ""Swa_freq is None, ignoring swa_lr"")\n            # If not in auto mode make all swa parameters None\n            self.swa_lr_factor = None\n            self.swa_freq = None\n\n        if self.swa_lr_factor is not None and self.swa_lr_factor < 0:\n            raise ValueError(""Invalid SWA learning rate factor: {}"".format(swa_lr_factor))\n\n        self.optimizer = optimizer\n\n        self.defaults = self.optimizer.defaults\n        self.param_groups = self.optimizer.param_groups\n        self.state = defaultdict(dict)\n        self.opt_state = self.optimizer.state\n        for group in self.param_groups:\n            group[\'n_avg\'] = 0\n            group[\'step_counter\'] = 0\n\n    @staticmethod\n    def _check_params(swa_freq):\n        params = [swa_freq]\n        params_none = [param is None for param in params]\n        if not all(params_none) and any(params_none):\n            warnings.warn(\n                ""Some of swa_start, swa_freq is None, ignoring other"")\n        for i, param in enumerate(params):\n            if param is not None and not isinstance(param, int):\n                params[i] = int(param)\n                warnings.warn(""Casting swa_start, swa_freq to int"")\n        return not any(params_none), params\n\n    def reset_lr_to_swa(self):\n        for param_group in self.param_groups:\n            param_group[\'initial_lr\'] = self.swa_lr_factor * param_group[\'lr\']\n\n    def update_swa_group(self, group):\n        r""""""Updates the SWA running averages for the given parameter group.\n        Arguments:\n            group (dict): Specifies for what parameter group SWA running\n                averages should be updated\n        Examples:\n            >>> # automatic mode\n            >>> base_opt = torch.optim.SGD([{\'params\': [x]},\n            >>>             {\'params\': [y], \'lr\': 1e-3}], lr=1e-2, momentum=0.9)\n            >>> opt = torchcontrib.optim.SWA(base_opt)\n            >>> for i in range(100):\n            >>>     opt.zero_grad()\n            >>>     loss_fn(model(input), target).backward()\n            >>>     opt.step()\n            >>>     if i > 10 and i % 5 == 0:\n            >>>         # Update SWA for the second parameter group\n            >>>         opt.update_swa_group(opt.param_groups[1])\n            >>> opt.swap_swa_param()\n        """"""\n        for p in group[\'params\']:\n            param_state = self.state[p]\n            if \'swa_buffer\' not in param_state:\n                param_state[\'swa_buffer\'] = torch.zeros_like(p.data)\n            buf = param_state[\'swa_buffer\']\n            virtual_decay = 1 / float(group[""n_avg""] + 1)\n            diff = (p.data - buf) * virtual_decay\n            buf.add_(diff)\n        group[""n_avg""] += 1\n\n    def update_swa(self):\n        r""""""Updates the SWA running averages of all optimized parameters.\n        """"""\n        for group in self.param_groups:\n            self.update_swa_group(group)\n\n    def swap_swa_param(self):\n        r""""""Swaps the values of the optimized variables and swa buffers.\n        It\'s meant to be called in the end of training to use the collected\n        swa running averages. It can also be used to evaluate the running\n        averages during training; to continue training `swap_swa_sgd`\n        should be called again.\n        """"""\n        for group in self.param_groups:\n            for p in group[\'params\']:\n                param_state = self.state[p]\n                if \'swa_buffer\' not in param_state:\n                    # If swa wasn\'t applied we don\'t swap params\n                    warnings.warn(\n                        ""SWA wasn\'t applied to param {}; skipping it"".format(p))\n                    continue\n                buf = param_state[\'swa_buffer\']\n                tmp = torch.empty_like(p.data)\n                tmp.copy_(p.data)\n                p.data.copy_(buf)\n                buf.copy_(tmp)\n\n    def step(self, closure=None):\n        r""""""Performs a single optimization step.\n        In automatic mode also updates SWA running averages.\n        """"""\n        loss = self.optimizer.step(closure)\n        for group in self.param_groups:\n            group[""step_counter""] += 1\n            steps = group[""step_counter""]\n            if self._auto_mode:\n                if steps % self.swa_freq == 0:\n                    self.update_swa_group(group)\n        return loss\n\n    def state_dict(self):\n        r""""""Returns the state of SWA as a :class:`dict`.\n        It contains three entries:\n            * opt_state - a dict holding current optimization state of the base\n                optimizer. Its content differs between optimizer classes.\n            * swa_state - a dict containing current state of SWA. For each\n                optimized variable it contains swa_buffer keeping the running\n                average of the variable\n            * param_groups - a dict containing all parameter groups\n        """"""\n        opt_state_dict = self.optimizer.state_dict()\n        swa_state = {(id(k) if isinstance(k, torch.Tensor) else k): v\n                     for k, v in self.state.items()}\n        opt_state = opt_state_dict[""state""]\n        param_groups = opt_state_dict[""param_groups""]\n        return {""opt_state"": opt_state, ""swa_state"": swa_state,\n                ""param_groups"": param_groups}\n\n    def load_state_dict(self, state_dict):\n        r""""""Loads the optimizer state.\n        Args:\n            state_dict (dict): SWA optimizer state. Should be an object returned\n                from a call to `state_dict`.\n        """"""\n        swa_state_dict = {""state"": state_dict[""swa_state""],\n                          ""param_groups"": state_dict[""param_groups""]}\n        opt_state_dict = {""state"": state_dict[""opt_state""],\n                          ""param_groups"": state_dict[""param_groups""]}\n        super(SWA, self).load_state_dict(swa_state_dict)\n        self.optimizer.load_state_dict(opt_state_dict)\n        self.opt_state = self.optimizer.state\n\n    def add_param_group(self, param_group):\n        r""""""Add a param group to the :class:`Optimizer` s `param_groups`.\n        This can be useful when fine tuning a pre-trained network as frozen\n        layers can be made trainable and added to the :class:`Optimizer` as\n        training progresses.\n        Args:\n            param_group (dict): Specifies what Tensors should be optimized along\n            with group specific optimization options.\n        """"""\n        param_group[\'n_avg\'] = 0\n        param_group[\'step_counter\'] = 0\n        self.optimizer.add_param_group(param_group)\n'"
projects/PartialReID/partialreid/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author:  xingyu liao\n@contact: liaoxingyu5@jd.com\n""""""\n\nfrom .partial_dataset import *\nfrom .partialbaseline import PartialBaseline\nfrom .dsr_head import DSRHead\nfrom .config import add_partialreid_config\nfrom .dsr_evaluation import DsrEvaluator\n'"
projects/PartialReID/partialreid/config.py,0,"b'# encoding: utf-8\n""""""\n@author:  l1aoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom fastreid.config import CfgNode as CN\n\n\ndef add_partialreid_config(cfg):\n    _C = cfg\n\n    _C.TEST.DSR = CN()\n    _C.TEST.DSR.ENABLED = True\n    _C.TEST.DSR.TOPK = 30\n\n'"
projects/PartialReID/partialreid/dsr_distance.py,4,"b'""""""Numpy version of euclidean distance, etc.\nNotice the input/output shape of methods, so that you can better understand\nthe meaning of these methods.""""""\n\nimport torch\nimport numpy as np\n\n\ndef normalize(nparray, order=2, axis=0):\n    """"""Normalize a N-D numpy array along the specified axis.""""""\n    norm = np.linalg.norm(nparray, ord=order, axis=axis, keepdims=True)\n    return nparray / (norm + np.finfo(np.float32).eps)\n\n\ndef compute_dsr_dist(array1, array2, distmat, scores, topk=30):\n    """""" Compute the sptial feature reconstruction of all pairs\n     array: [M, N, C] M: the number of query, N: the number of spatial feature, C: the dimension of each spatial feature\n     array2: [M, N, C] M: the number of gallery\n    :return:\n    numpy array with shape [m1, m2]\n    """"""\n\n    dist = 100 * torch.ones(len(array1), len(array2))\n    dist = dist.cuda()\n    index = np.argsort(distmat, axis=1)\n\n    for i in range(0, len(array1)):\n        q = torch.FloatTensor(array1[i])\n        q = q.view(q.size(0), q.size(1))\n        q = q.cuda()\n        score = scores[i]\n        for j in range(topk):\n            g = array2[index[i, j]]\n            g = torch.FloatTensor(g)\n            g = g.view(g.size(0), g.size(1))\n            g = g.cuda()\n            sim = torch.matmul(q.t(), g)\n            min_value, min_index = (1 - sim).min(1)\n            dist[i, index[i, j]] = (min_value * score).sum()\n    dist = dist.cpu()\n    dist = dist.numpy()\n\n    return dist\n'"
projects/PartialReID/partialreid/dsr_evaluation.py,4,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\nimport copy\nimport logging\nfrom collections import OrderedDict\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\nfrom fastreid.evaluation.evaluator import DatasetEvaluator\nfrom fastreid.evaluation.rank import evaluate_rank\nfrom fastreid.evaluation.roc import evaluate_roc\nfrom .dsr_distance import compute_dsr_dist\n\nlogger = logging.getLogger(\'fastreid.partialreid.dsr_evaluation\')\n\n\nclass DsrEvaluator(DatasetEvaluator):\n    def __init__(self, cfg, num_query, output_dir=None):\n        self.cfg = cfg\n        self._num_query = num_query\n        self._output_dir = output_dir\n\n        self.features = []\n        self.spatial_features = []\n        self.scores = []\n        self.pids = []\n        self.camids = []\n\n    def reset(self):\n        self.features = []\n        self.spatial_features = []\n        self.scores = []\n        self.pids = []\n        self.camids = []\n\n    def process(self, outputs):\n        self.features.append(F.normalize(outputs[0][0]).cpu())\n        outputs1 = F.normalize(outputs[0][1].data).cpu().numpy()\n        self.spatial_features.append(outputs1)\n        self.scores.append(outputs[0][2])\n        self.pids.extend(outputs[1].cpu().numpy())\n        self.camids.extend(outputs[2].cpu().numpy())\n\n    def evaluate(self):\n        features = torch.cat(self.features, dim=0)\n        spatial_features = np.vstack(self.spatial_features)\n        scores = torch.cat(self.scores, dim=0)\n\n        # query feature, person ids and camera ids\n        query_features = features[:self._num_query]\n        query_pids = np.asarray(self.pids[:self._num_query])\n        query_camids = np.asarray(self.camids[:self._num_query])\n\n        # gallery features, person ids and camera ids\n        gallery_features = features[self._num_query:]\n        gallery_pids = np.asarray(self.pids[self._num_query:])\n        gallery_camids = np.asarray(self.camids[self._num_query:])\n\n        dist = 1 - torch.mm(query_features, gallery_features.t()).numpy()\n        logger.info(""Testing without DSR setting"")\n        self._results = OrderedDict()\n        if self.cfg.TEST.DSR.ENABLED:\n            topk = self.cfg.TEST.DSR.TOPK\n            dist = compute_dsr_dist(spatial_features[:self._num_query], spatial_features[self._num_query:], dist,\n                                    scores[:self._num_query], topk)\n            logger.info(""Testing with DSR setting"")\n\n        cmc, all_AP, all_INP = evaluate_rank(dist, query_pids, gallery_pids, query_camids, gallery_camids)\n        mAP = np.mean(all_AP)\n        mINP = np.mean(all_INP)\n        for r in [1, 5, 10]:\n            self._results[\'Rank-{}\'.format(r)] = cmc[r - 1]\n        self._results[\'mAP\'] = mAP\n        self._results[\'mINP\'] = mINP\n\n        tprs = evaluate_roc(dist, query_pids, gallery_pids, query_camids, gallery_camids)\n        fprs = [1e-4, 1e-3, 1e-2]\n        for i in range(len(fprs)):\n            self._results[""TPR@FPR={}"".format(fprs[i])] = tprs[i]\n        return copy.deepcopy(self._results)\n'"
projects/PartialReID/partialreid/dsr_head.py,4,"b'# encoding: utf-8\n""""""\n@author:  lingxiao he\n@contact: helingxiao3@jd.com\n""""""\n\nimport torch\nimport torch.nn.functional as F\n\nfrom fastreid.layers import *\nfrom fastreid.modeling.heads.build import REID_HEADS_REGISTRY\nfrom fastreid.utils.weight_init import weights_init_classifier, weights_init_kaiming\n\n\nclass OcclusionUnit(nn.Module):\n    def __init__(self, in_planes=2048):\n        super(OcclusionUnit, self).__init__()\n        self.MaxPool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.MaxPool2 = nn.MaxPool2d(kernel_size=4, stride=2, padding=0)\n        self.MaxPool3 = nn.MaxPool2d(kernel_size=6, stride=2, padding=0)\n        self.MaxPool4 = nn.MaxPool2d(kernel_size=8, stride=2, padding=0)\n        self.mask_layer = nn.Linear(in_planes, 1, bias=False)\n\n    def forward(self, x):\n        SpaFeat1 = self.MaxPool1(x)  # shape: [n, c, h, w]\n        SpaFeat2 = self.MaxPool2(x)\n        SpaFeat3 = self.MaxPool3(x)\n        SpaFeat4 = self.MaxPool4(x)\n\n        Feat1 = SpaFeat1.view(SpaFeat1.size(0), SpaFeat1.size(1), SpaFeat1.size(2) * SpaFeat1.size(3))\n        Feat2 = SpaFeat2.view(SpaFeat2.size(0), SpaFeat2.size(1), SpaFeat2.size(2) * SpaFeat2.size(3))\n        Feat3 = SpaFeat3.view(SpaFeat3.size(0), SpaFeat3.size(1), SpaFeat3.size(2) * SpaFeat3.size(3))\n        Feat4 = SpaFeat4.view(SpaFeat4.size(0), SpaFeat4.size(1), SpaFeat4.size(2) * SpaFeat4.size(3))\n        SpatialFeatAll = torch.cat((Feat1, Feat2, Feat3, Feat4), 2)\n        SpatialFeatAll = SpatialFeatAll.transpose(1, 2)  # shape: [n, c, m]\n        y = self.mask_layer(SpatialFeatAll)\n        mask_weight = torch.sigmoid(y[:, :, 0])\n\n        mask_score = F.normalize(mask_weight[:, :48], p=1, dim=1)\n        mask_weight_norm = F.normalize(mask_weight, p=1, dim=1)\n        mask_score = mask_score.unsqueeze(1)\n\n        SpaFeat1 = SpaFeat1.transpose(1, 2)\n        SpaFeat1 = SpaFeat1.transpose(2, 3)  # shape: [n, h, w, c]\n        SpaFeat1 = SpaFeat1.view((SpaFeat1.size(0), SpaFeat1.size(1) * SpaFeat1.size(2), -1))  # shape: [n, h*w, c]\n\n        global_feats = mask_score.matmul(SpaFeat1).view(SpaFeat1.shape[0], -1, 1, 1)\n        return global_feats, mask_weight, mask_weight_norm\n\n\n@REID_HEADS_REGISTRY.register()\nclass DSRHead(nn.Module):\n    def __init__(self, cfg, in_feat, num_classes, pool_layer=nn.AdaptiveAvgPool2d(1)):\n        super().__init__()\n\n        self.pool_layer = pool_layer\n\n        self.occ_unit = OcclusionUnit(in_planes=in_feat)\n        self.MaxPool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.MaxPool2 = nn.MaxPool2d(kernel_size=4, stride=2, padding=0)\n        self.MaxPool3 = nn.MaxPool2d(kernel_size=6, stride=2, padding=0)\n        self.MaxPool4 = nn.MaxPool2d(kernel_size=8, stride=2, padding=0)\n\n        self.bnneck = get_norm(cfg.MODEL.HEADS.NORM, in_feat, cfg.MODEL.HEADS.NORM_SPLIT, bias_freeze=True)\n        self.bnneck.apply(weights_init_kaiming)\n\n        self.bnneck_occ = get_norm(cfg.MODEL.HEADS.NORM, in_feat, cfg.MODEL.HEADS.NORM_SPLIT, bias_freeze=True)\n        self.bnneck_occ.apply(weights_init_kaiming)\n\n        # identity classification layer\n        if cfg.MODEL.HEADS.CLS_LAYER == \'linear\':\n            self.classifier = nn.Linear(in_feat, num_classes, bias=False)\n            self.classifier_occ = nn.Linear(in_feat, num_classes, bias=False)\n            self.classifier.apply(weights_init_classifier)\n            self.classifier_occ.apply(weights_init_classifier)\n        elif cfg.MODEL.HEADS.CLS_LAYER == \'arcface\':\n            self.classifier = Arcface(cfg, in_feat)\n            self.classifier_occ = Arcface(cfg, in_feat)\n        elif cfg.MODEL.HEADS.CLS_LAYER == \'circle\':\n            self.classifier = Circle(cfg, in_feat)\n            self.classifier_occ = Circle(cfg, in_feat)\n        else:\n            self.classifier = nn.Linear(in_feat, num_classes, bias=False)\n            self.classifier_occ = nn.Linear(in_feat, num_classes, bias=False)\n            self.classifier.apply(weights_init_classifier)\n            self.classifier_occ.apply(weights_init_classifier)\n\n    def forward(self, features, targets=None):\n        """"""\n        See :class:`ReIDHeads.forward`.\n        """"""\n        SpaFeat1 = self.MaxPool1(features)  # shape: [n, c, h, w]\n        SpaFeat2 = self.MaxPool2(features)\n        SpaFeat3 = self.MaxPool3(features)\n        SpaFeat4 = self.MaxPool4(features)\n\n        Feat1 = SpaFeat1.view(SpaFeat1.size(0), SpaFeat1.size(1), SpaFeat1.size(2) * SpaFeat1.size(3))\n        Feat2 = SpaFeat2.view(SpaFeat2.size(0), SpaFeat2.size(1), SpaFeat2.size(2) * SpaFeat2.size(3))\n        Feat3 = SpaFeat3.view(SpaFeat3.size(0), SpaFeat3.size(1), SpaFeat3.size(2) * SpaFeat3.size(3))\n        Feat4 = SpaFeat4.view(SpaFeat4.size(0), SpaFeat4.size(1), SpaFeat4.size(2) * SpaFeat4.size(3))\n        SpatialFeatAll = torch.cat((Feat1, Feat2, Feat3, Feat4), dim=2)\n\n        foreground_feat, mask_weight, mask_weight_norm = self.occ_unit(features)\n        bn_foreground_feat = self.bnneck_occ(foreground_feat)\n        bn_foreground_feat = bn_foreground_feat[..., 0, 0]\n\n        # Evaluation\n        if not self.training:\n            return bn_foreground_feat, SpatialFeatAll, mask_weight_norm\n        # Training\n        global_feat = self.pool_layer(features)\n        bn_feat = self.bnneck(global_feat)\n        bn_feat = bn_feat[..., 0, 0]\n\n        try:\n            pred_class_logits = self.classifier(bn_feat)\n            fore_pred_class_legits = self.classifier_occ(bn_foreground_feat)\n        except TypeError:\n            pred_class_logits = self.classifier(bn_feat, targets)\n            fore_pred_class_legits = self.classifier_occ(bn_foreground_feat, targets)\n        return pred_class_logits, global_feat[..., 0, 0], fore_pred_class_legits, foreground_feat[..., 0, 0], targets\n'"
projects/PartialReID/partialreid/partial_dataset.py,0,"b'# encoding: utf-8\n\n""""""\n@author:  lingxiao he\n@contact: helingxiao3@jd.com\n""""""\n\nimport glob\nimport os\nimport os.path as osp\nimport re\n\nfrom fastreid.data.datasets import DATASET_REGISTRY\nfrom fastreid.data.datasets.bases import ImageDataset\n\n__all__ = [\'PartialREID\', \'PartialiLIDS\', \'OccludedREID\']\n\n\ndef process_test(query_path, gallery_path):\n    query_img_paths = glob.glob(os.path.join(query_path, \'*.jpg\'))\n    gallery_img_paths = glob.glob(os.path.join(gallery_path, \'*.jpg\'))\n    query_paths = []\n    pattern = re.compile(r\'([-\\d]+)_(\\d*)\')\n    for img_path in query_img_paths:\n        pid, camid = map(int, pattern.search(img_path).groups())\n        query_paths.append([img_path, pid, camid])\n    gallery_paths = []\n    for img_path in gallery_img_paths:\n        pid, camid = map(int, pattern.search(img_path).groups())\n        gallery_paths.append([img_path, pid, camid])\n    return query_paths, gallery_paths\n\n\n@DATASET_REGISTRY.register()\nclass PartialREID(ImageDataset):\n    def __init__(self, root=\'datasets\', ):\n        self.root = root\n\n        self.query_dir = osp.join(self.root, \'PartialREID/query\')\n        self.gallery_dir = osp.join(self.root, \'PartialREID/gallery\')\n        query, gallery = process_test(self.query_dir, self.gallery_dir)\n\n        ImageDataset.__init__(self, [], query, gallery)\n\n\n@DATASET_REGISTRY.register()\nclass PartialiLIDS(ImageDataset):\n    def __init__(self, root=\'datasets\', ):\n        self.root = root\n\n        self.query_dir = osp.join(self.root, \'PartialiLIDS/query\')\n        self.gallery_dir = osp.join(self.root, \'PartialiLIDS/gallery\')\n        query, gallery = process_test(self.query_dir, self.gallery_dir)\n\n        ImageDataset.__init__(self, [], query, gallery)\n\n\n@DATASET_REGISTRY.register()\nclass OccludedREID(ImageDataset):\n    def __init__(self, root=\'datasets\', ):\n        self.root = root\n\n        self.query_dir = osp.join(self.root, \'OccludedREID/query\')\n        self.gallery_dir = osp.join(self.root, \'OccludedREID/gallery\')\n        query, gallery = process_test(self.query_dir, self.gallery_dir)\n\n        ImageDataset.__init__(self, [], query, gallery)\n'"
projects/PartialReID/partialreid/partialbaseline.py,0,"b'# encoding: utf-8\n""""""\n@authorr:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nfrom fastreid.modeling.losses import reid_losses\nfrom fastreid.modeling.meta_arch import Baseline\nfrom fastreid.modeling.meta_arch.build import META_ARCH_REGISTRY\n\n\n@META_ARCH_REGISTRY.register()\nclass PartialBaseline(Baseline):\n    def losses(self, outputs):\n        pred_logits, global_feat, fore_pred_logits, fore_feat, targets = outputs\n        loss_dict = {}\n        loss_dict.update(reid_losses(self._cfg, pred_logits, global_feat, targets, \'avg_branch_\'))\n        loss_dict.update(reid_losses(self._cfg, fore_pred_logits, fore_feat, targets, \'fore_branch_\'))\n        return loss_dict\n'"
tools/deploy/Caffe/__init__.py,0,b''
tools/deploy/Caffe/caffe_lmdb.py,0,"b""import lmdb\nfrom Caffe import caffe_pb2 as pb2\nimport numpy as np\n\nclass Read_Caffe_LMDB():\n    def __init__(self,path,dtype=np.uint8):\n\n        self.env=lmdb.open(path, readonly=True)\n        self.dtype=dtype\n        self.txn=self.env.begin()\n        self.cursor=self.txn.cursor()\n\n    @staticmethod\n    def to_numpy(value,dtype=np.uint8):\n        datum = pb2.Datum()\n        datum.ParseFromString(value)\n        flat_x = np.fromstring(datum.data, dtype=dtype)\n        data = flat_x.reshape(datum.channels, datum.height, datum.width)\n        label=flat_x = datum.label\n        return data,label\n\n    def iterator(self):\n        while True:\n            key,value=self.cursor.key(),self.cursor.value()\n            yield self.to_numpy(value,self.dtype)\n            if not self.cursor.next():\n                return\n\n    def __iter__(self):\n        self.cursor.first()\n        it = self.iterator()\n        return it\n\n    def __len__(self):\n        return int(self.env.stat()['entries'])\n"""
tools/deploy/Caffe/caffe_net.py,0,"b'from __future__ import absolute_import\nfrom . import caffe_pb2 as pb\nimport google.protobuf.text_format as text_format\nimport numpy as np\nfrom .layer_param import Layer_param\n\nclass _Net(object):\n    def __init__(self):\n        self.net=pb.NetParameter()\n\n    def layer_index(self,layer_name):\n        # find a layer\'s index by name. if the layer was found, return the layer position in the net, else return -1.\n        for i, layer in enumerate(self.net.layer):\n            if layer.name == layer_name:\n                return i\n\n    def add_layer(self,layer_params,before=\'\',after=\'\'):\n        # find the before of after layer\'s position\n        index = -1\n        if after != \'\':\n            index = self.layer_index(after) + 1\n        if before != \'\':\n            index = self.layer_index(before)\n        new_layer = pb.LayerParameter()\n        new_layer.CopyFrom(layer_params.param)\n        #insert the layer into the layer protolist\n        if index != -1:\n            self.net.layer.add()\n            for i in range(len(self.net.layer) - 1, index, -1):\n                self.net.layer[i].CopyFrom(self.net.layer[i - 1])\n            self.net.layer[index].CopyFrom(new_layer)\n        else:\n            self.net.layer.extend([new_layer])\n\n    def remove_layer_by_name(self,layer_name):\n        for i,layer in enumerate(self.net.layer):\n            if layer.name == layer_name:\n                del self.net.layer[i]\n                return\n        raise(AttributeError, ""cannot found layer %s"" % str(layer_name))\n\n    def get_layer_by_name(self, layer_name):\n        # get the layer by layer_name\n        for layer in self.net.layer:\n            if layer.name == layer_name:\n                return layer\n        raise(AttributeError, ""cannot found layer %s"" % str(layer_name))\n\n    def save_prototxt(self,path):\n        prototxt=pb.NetParameter()\n        prototxt.CopyFrom(self.net)\n        for layer in prototxt.layer:\n            del layer.blobs[:]\n        with open(path,\'w\') as f:\n            f.write(text_format.MessageToString(prototxt))\n\n    def layer(self,layer_name):\n        return self.get_layer_by_name(layer_name)\n\n    def layers(self):\n        return list(self.net.layer)\n\n\n\nclass Prototxt(_Net):\n    def __init__(self,file_name=\'\'):\n        super(Prototxt,self).__init__()\n        self.file_name=file_name\n        if file_name!=\'\':\n            f = open(file_name,\'r\')\n            text_format.Parse(f.read(), self.net)\n            pass\n\n    def init_caffemodel(self,caffe_cmd_path=\'caffe\'):\n        """"""\n        :param caffe_cmd_path: The shell command of caffe, normally at <path-to-caffe>/build/tools/caffe\n        """"""\n        s=pb.SolverParameter()\n        s.train_net=self.file_name\n        s.max_iter=0\n        s.base_lr=1\n        s.solver_mode = pb.SolverParameter.CPU\n        s.snapshot_prefix=\'./nn\'\n        with open(\'/tmp/nn_tools_solver.prototxt\',\'w\') as f:\n            f.write(str(s))\n        import os\n        os.system(\'%s train --solver /tmp/nn_tools_solver.prototxt\'%caffe_cmd_path)\n\nclass Caffemodel(_Net):\n    def __init__(self, file_name=\'\'):\n        super(Caffemodel,self).__init__()\n        # caffe_model dir\n        if file_name!=\'\':\n            f = open(file_name,\'rb\')\n            self.net.ParseFromString(f.read())\n            f.close()\n\n    def save(self, path):\n        with open(path,\'wb\') as f:\n            f.write(self.net.SerializeToString())\n\n    def add_layer_with_data(self,layer_params,datas, before=\'\', after=\'\'):\n        """"""\n        Args:\n            layer_params:A Layer_Param object\n            datas:a fixed dimension numpy object list\n            after: put the layer after a specified layer\n            before: put the layer before a specified layer\n        """"""\n        self.add_layer(layer_params,before,after)\n        new_layer =self.layer(layer_params.name)\n\n        #process blobs\n        del new_layer.blobs[:]\n        for data in datas:\n            new_blob=new_layer.blobs.add()\n            for dim in data.shape:\n                new_blob.shape.dim.append(dim)\n            new_blob.data.extend(data.flatten().astype(float))\n\n    def get_layer_data(self,layer_name):\n        layer=self.layer(layer_name)\n        datas=[]\n        for blob in layer.blobs:\n            shape=list(blob.shape.dim)\n            data=np.array(blob.data).reshape(shape)\n            datas.append(data)\n        return datas\n\n    def set_layer_data(self,layer_name,datas):\n        # datas is normally a list of [weights,bias]\n        layer=self.layer(layer_name)\n        for blob,data in zip(layer.blobs,datas):\n            blob.data[:]=data.flatten()\n            pass\n\nclass Net():\n    def __init__(self,*args,**kwargs):\n        raise(TypeError,\'the class Net is no longer used, please use Caffemodel or Prototxt instead\')'"
tools/deploy/Caffe/caffe_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: caffe.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'caffe.proto\',\n  package=\'caffe\',\n  syntax=\'proto2\',\n  serialized_options=None,\n  serialized_pb=_b(\'\\n\\x0b\\x63\\x61\\x66\\x66\\x65.proto\\x12\\x05\\x63\\x61\\x66\\x66\\x65\\""\\x1c\\n\\tBlobShape\\x12\\x0f\\n\\x03\\x64im\\x18\\x01 \\x03(\\x03\\x42\\x02\\x10\\x01\\""\\xcc\\x01\\n\\tBlobProto\\x12\\x1f\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x05 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04\\x64iff\\x18\\x06 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_data\\x18\\x08 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_diff\\x18\\t \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x0e\\n\\x03num\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x13\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x11\\n\\x06height\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""2\\n\\x0f\\x42lobProtoVector\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\""\\x91\\x01\\n\\x05\\x44\\x61tum\\x12\\x10\\n\\x08\\x63hannels\\x18\\x01 \\x01(\\x05\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\x05\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\x05\\x12\\x0c\\n\\x04\\x64\\x61ta\\x18\\x04 \\x01(\\x0c\\x12\\r\\n\\x05label\\x18\\x05 \\x01(\\x05\\x12\\x12\\n\\nfloat_data\\x18\\x06 \\x03(\\x02\\x12\\x16\\n\\x07\\x65ncoded\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x0e\\n\\x06labels\\x18\\x08 \\x03(\\x02\\""A\\n\\x0cLabelMapItem\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05label\\x18\\x02 \\x01(\\x05\\x12\\x14\\n\\x0c\\x64isplay_name\\x18\\x03 \\x01(\\t\\""-\\n\\x08LabelMap\\x12!\\n\\x04item\\x18\\x01 \\x03(\\x0b\\x32\\x13.caffe.LabelMapItem\\""o\\n\\x07Sampler\\x12\\x14\\n\\tmin_scale\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x14\\n\\tmax_scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x1b\\n\\x10min_aspect_ratio\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x1b\\n\\x10max_aspect_ratio\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""\\xc0\\x01\\n\\x10SampleConstraint\\x12\\x1b\\n\\x13min_jaccard_overlap\\x18\\x01 \\x01(\\x02\\x12\\x1b\\n\\x13max_jaccard_overlap\\x18\\x02 \\x01(\\x02\\x12\\x1b\\n\\x13min_sample_coverage\\x18\\x03 \\x01(\\x02\\x12\\x1b\\n\\x13max_sample_coverage\\x18\\x04 \\x01(\\x02\\x12\\x1b\\n\\x13min_object_coverage\\x18\\x05 \\x01(\\x02\\x12\\x1b\\n\\x13max_object_coverage\\x18\\x06 \\x01(\\x02\\""\\xb2\\x01\\n\\x0c\\x42\\x61tchSampler\\x12 \\n\\x12use_original_image\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1f\\n\\x07sampler\\x18\\x02 \\x01(\\x0b\\x32\\x0e.caffe.Sampler\\x12\\x32\\n\\x11sample_constraint\\x18\\x03 \\x01(\\x0b\\x32\\x17.caffe.SampleConstraint\\x12\\x12\\n\\nmax_sample\\x18\\x04 \\x01(\\r\\x12\\x17\\n\\nmax_trials\\x18\\x05 \\x01(\\r:\\x03\\x31\\x30\\x30\\""\\x8a\\x01\\n\\x0e\\x45mitConstraint\\x12\\x39\\n\\temit_type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.EmitConstraint.EmitType:\\x06\\x43\\x45NTER\\x12\\x14\\n\\x0c\\x65mit_overlap\\x18\\x02 \\x01(\\x02\\""\\\'\\n\\x08\\x45mitType\\x12\\n\\n\\x06\\x43\\x45NTER\\x10\\x00\\x12\\x0f\\n\\x0bMIN_OVERLAP\\x10\\x01\\""\\x87\\x01\\n\\x0eNormalizedBBox\\x12\\x0c\\n\\x04xmin\\x18\\x01 \\x01(\\x02\\x12\\x0c\\n\\x04ymin\\x18\\x02 \\x01(\\x02\\x12\\x0c\\n\\x04xmax\\x18\\x03 \\x01(\\x02\\x12\\x0c\\n\\x04ymax\\x18\\x04 \\x01(\\x02\\x12\\r\\n\\x05label\\x18\\x05 \\x01(\\x05\\x12\\x11\\n\\tdifficult\\x18\\x06 \\x01(\\x08\\x12\\r\\n\\x05score\\x18\\x07 \\x01(\\x02\\x12\\x0c\\n\\x04size\\x18\\x08 \\x01(\\x02\\""I\\n\\nAnnotation\\x12\\x16\\n\\x0binstance_id\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12#\\n\\x04\\x62\\x62ox\\x18\\x02 \\x01(\\x0b\\x32\\x15.caffe.NormalizedBBox\\""M\\n\\x0f\\x41nnotationGroup\\x12\\x13\\n\\x0bgroup_label\\x18\\x01 \\x01(\\x05\\x12%\\n\\nannotation\\x18\\x02 \\x03(\\x0b\\x32\\x11.caffe.Annotation\\""\\xaf\\x01\\n\\x0e\\x41nnotatedDatum\\x12\\x1b\\n\\x05\\x64\\x61tum\\x18\\x01 \\x01(\\x0b\\x32\\x0c.caffe.Datum\\x12\\x32\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32$.caffe.AnnotatedDatum.AnnotationType\\x12\\x30\\n\\x10\\x61nnotation_group\\x18\\x03 \\x03(\\x0b\\x32\\x16.caffe.AnnotationGroup\\""\\x1a\\n\\x0e\\x41nnotationType\\x12\\x08\\n\\x04\\x42\\x42OX\\x10\\x00\\""C\\n\\tMTCNNBBox\\x12\\x0c\\n\\x04xmin\\x18\\x01 \\x01(\\x02\\x12\\x0c\\n\\x04ymin\\x18\\x02 \\x01(\\x02\\x12\\x0c\\n\\x04xmax\\x18\\x03 \\x01(\\x02\\x12\\x0c\\n\\x04ymax\\x18\\x04 \\x01(\\x02\\""U\\n\\nMTCNNDatum\\x12\\x1b\\n\\x05\\x64\\x61tum\\x18\\x01 \\x01(\\x0b\\x32\\x0c.caffe.Datum\\x12\\x1d\\n\\x03roi\\x18\\x02 \\x01(\\x0b\\x32\\x10.caffe.MTCNNBBox\\x12\\x0b\\n\\x03pts\\x18\\x03 \\x03(\\x02\\""\\x98\\x02\\n\\x0f\\x46illerParameter\\x12\\x16\\n\\x04type\\x18\\x01 \\x01(\\t:\\x08\\x63onstant\\x12\\x10\\n\\x05value\\x18\\x02 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03min\\x18\\x03 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03max\\x18\\x04 \\x01(\\x02:\\x01\\x31\\x12\\x0f\\n\\x04mean\\x18\\x05 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03std\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x06sparse\\x18\\x07 \\x01(\\x05:\\x02-1\\x12\\x42\\n\\rvariance_norm\\x18\\x08 \\x01(\\x0e\\x32#.caffe.FillerParameter.VarianceNorm:\\x06\\x46\\x41N_IN\\x12\\x0c\\n\\x04\\x66ile\\x18\\t \\x01(\\t\\""4\\n\\x0cVarianceNorm\\x12\\n\\n\\x06\\x46\\x41N_IN\\x10\\x00\\x12\\x0b\\n\\x07\\x46\\x41N_OUT\\x10\\x01\\x12\\x0b\\n\\x07\\x41VERAGE\\x10\\x02\\""\\x8e\\x02\\n\\x0cNetParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12%\\n\\x0binput_shape\\x18\\x08 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x11\\n\\tinput_dim\\x18\\x04 \\x03(\\x05\\x12\\x1d\\n\\x0e\\x66orce_backward\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1e\\n\\x05state\\x18\\x06 \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x19\\n\\ndebug_info\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12$\\n\\x05layer\\x18\\x64 \\x03(\\x0b\\x32\\x15.caffe.LayerParameter\\x12\\\'\\n\\x06layers\\x18\\x02 \\x03(\\x0b\\x32\\x17.caffe.V1LayerParameter\\""\\xc0\\n\\n\\x0fSolverParameter\\x12\\x0b\\n\\x03net\\x18\\x18 \\x01(\\t\\x12&\\n\\tnet_param\\x18\\x19 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12\\x11\\n\\ttrain_net\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x08test_net\\x18\\x02 \\x03(\\t\\x12,\\n\\x0ftrain_net_param\\x18\\x15 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12+\\n\\x0etest_net_param\\x18\\x16 \\x03(\\x0b\\x32\\x13.caffe.NetParameter\\x12$\\n\\x0btrain_state\\x18\\x1a \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12#\\n\\ntest_state\\x18\\x1b \\x03(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x11\\n\\ttest_iter\\x18\\x03 \\x03(\\x05\\x12\\x18\\n\\rtest_interval\\x18\\x04 \\x01(\\x05:\\x01\\x30\\x12 \\n\\x11test_compute_loss\\x18\\x13 \\x01(\\x08:\\x05\\x66\\x61lse\\x12!\\n\\x13test_initialization\\x18  \\x01(\\x08:\\x04true\\x12\\x0f\\n\\x07\\x62\\x61se_lr\\x18\\x05 \\x01(\\x02\\x12\\x0f\\n\\x07\\x64isplay\\x18\\x06 \\x01(\\x05\\x12\\x17\\n\\x0c\\x61verage_loss\\x18! \\x01(\\x05:\\x01\\x31\\x12\\x10\\n\\x08max_iter\\x18\\x07 \\x01(\\x05\\x12\\x14\\n\\titer_size\\x18$ \\x01(\\x05:\\x01\\x31\\x12\\x11\\n\\tlr_policy\\x18\\x08 \\x01(\\t\\x12\\r\\n\\x05gamma\\x18\\t \\x01(\\x02\\x12\\r\\n\\x05power\\x18\\n \\x01(\\x02\\x12\\x10\\n\\x08momentum\\x18\\x0b \\x01(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x0c \\x01(\\x02\\x12\\x1f\\n\\x13regularization_type\\x18\\x1d \\x01(\\t:\\x02L2\\x12\\x10\\n\\x08stepsize\\x18\\r \\x01(\\x05\\x12\\x11\\n\\tstepvalue\\x18\\"" \\x03(\\x05\\x12\\x0f\\n\\x07stagelr\\x18\\x32 \\x03(\\x02\\x12\\x11\\n\\tstageiter\\x18\\x33 \\x03(\\x05\\x12\\x1a\\n\\x0e\\x63lip_gradients\\x18# \\x01(\\x02:\\x02-1\\x12\\x13\\n\\x08snapshot\\x18\\x0e \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0fsnapshot_prefix\\x18\\x0f \\x01(\\t\\x12\\x1c\\n\\rsnapshot_diff\\x18\\x10 \\x01(\\x08:\\x05\\x66\\x61lse\\x12K\\n\\x0fsnapshot_format\\x18% \\x01(\\x0e\\x32%.caffe.SolverParameter.SnapshotFormat:\\x0b\\x42INARYPROTO\\x12;\\n\\x0bsolver_mode\\x18\\x11 \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverMode:\\x03GPU\\x12\\x14\\n\\tdevice_id\\x18\\x12 \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0brandom_seed\\x18\\x14 \\x01(\\x03:\\x02-1\\x12\\x11\\n\\x04type\\x18( \\x01(\\t:\\x03SGD\\x12\\x14\\n\\x05\\x64\\x65lta\\x18\\x1f \\x01(\\x02:\\x05\\x31\\x65-08\\x12\\x18\\n\\tmomentum2\\x18\\\' \\x01(\\x02:\\x05\\x30.999\\x12\\x11\\n\\trms_decay\\x18& \\x01(\\x02\\x12\\x19\\n\\ndebug_info\\x18\\x17 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x14snapshot_after_train\\x18\\x1c \\x01(\\x08:\\x04true\\x12;\\n\\x0bsolver_type\\x18\\x1e \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverType:\\x03SGD\\""+\\n\\x0eSnapshotFormat\\x12\\x08\\n\\x04HDF5\\x10\\x00\\x12\\x0f\\n\\x0b\\x42INARYPROTO\\x10\\x01\\""\\x1e\\n\\nSolverMode\\x12\\x07\\n\\x03\\x43PU\\x10\\x00\\x12\\x07\\n\\x03GPU\\x10\\x01\\""U\\n\\nSolverType\\x12\\x07\\n\\x03SGD\\x10\\x00\\x12\\x0c\\n\\x08NESTEROV\\x10\\x01\\x12\\x0b\\n\\x07\\x41\\x44\\x41GRAD\\x10\\x02\\x12\\x0b\\n\\x07RMSPROP\\x10\\x03\\x12\\x0c\\n\\x08\\x41\\x44\\x41\\x44\\x45LTA\\x10\\x04\\x12\\x08\\n\\x04\\x41\\x44\\x41M\\x10\\x05\\""l\\n\\x0bSolverState\\x12\\x0c\\n\\x04iter\\x18\\x01 \\x01(\\x05\\x12\\x13\\n\\x0blearned_net\\x18\\x02 \\x01(\\t\\x12!\\n\\x07history\\x18\\x03 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x17\\n\\x0c\\x63urrent_step\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""N\\n\\x08NetState\\x12!\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase:\\x04TEST\\x12\\x10\\n\\x05level\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\r\\n\\x05stage\\x18\\x03 \\x03(\\t\\""s\\n\\x0cNetStateRule\\x12\\x1b\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x11\\n\\tmin_level\\x18\\x02 \\x01(\\x05\\x12\\x11\\n\\tmax_level\\x18\\x03 \\x01(\\x05\\x12\\r\\n\\x05stage\\x18\\x04 \\x03(\\t\\x12\\x11\\n\\tnot_stage\\x18\\x05 \\x03(\\t\\""\\x90\\x02\\n\\x1bSpatialTransformerParameter\\x12\\x1e\\n\\x0etransform_type\\x18\\x01 \\x01(\\t:\\x06\\x61\\x66\\x66ine\\x12\\x1e\\n\\x0csampler_type\\x18\\x02 \\x01(\\t:\\x08\\x62ilinear\\x12\\x10\\n\\x08output_H\\x18\\x03 \\x01(\\x05\\x12\\x10\\n\\x08output_W\\x18\\x04 \\x01(\\x05\\x12\\x1b\\n\\rto_compute_dU\\x18\\x05 \\x01(\\x08:\\x04true\\x12\\x11\\n\\ttheta_1_1\\x18\\x06 \\x01(\\x01\\x12\\x11\\n\\ttheta_1_2\\x18\\x07 \\x01(\\x01\\x12\\x11\\n\\ttheta_1_3\\x18\\x08 \\x01(\\x01\\x12\\x11\\n\\ttheta_2_1\\x18\\t \\x01(\\x01\\x12\\x11\\n\\ttheta_2_2\\x18\\n \\x01(\\x01\\x12\\x11\\n\\ttheta_2_3\\x18\\x0b \\x01(\\x01\\""5\\n\\x0fSTLossParameter\\x12\\x10\\n\\x08output_H\\x18\\x01 \\x02(\\x05\\x12\\x10\\n\\x08output_W\\x18\\x02 \\x02(\\x05\\""\\xa3\\x01\\n\\tParamSpec\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\nshare_mode\\x18\\x02 \\x01(\\x0e\\x32\\x1d.caffe.ParamSpec.DimCheckMode\\x12\\x12\\n\\x07lr_mult\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ndecay_mult\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\x95%\\n\\x0eLayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x03 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x04 \\x03(\\t\\x12\\x1b\\n\\x05phase\\x18\\n \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x13\\n\\x0bloss_weight\\x18\\x05 \\x03(\\x02\\x12\\x1f\\n\\x05param\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.ParamSpec\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x07 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x16\\n\\x0epropagate_down\\x18\\x0b \\x03(\\x08\\x12$\\n\\x07include\\x18\\x08 \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18\\t \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12\\x37\\n\\x0ftransform_param\\x18\\x64 \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18\\x65 \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12<\\n\\x14\\x64\\x65tection_loss_param\\x18\\xc8\\x01 \\x01(\\x0b\\x32\\x1d.caffe.DetectionLossParameter\\x12<\\n\\x14\\x65val_detection_param\\x18\\xc9\\x01 \\x01(\\x0b\\x32\\x1d.caffe.EvalDetectionParameter\\x12\\x36\\n\\x11region_loss_param\\x18\\xca\\x01 \\x01(\\x0b\\x32\\x1a.caffe.RegionLossParameter\\x12+\\n\\x0breorg_param\\x18\\xcb\\x01 \\x01(\\x0b\\x32\\x15.caffe.ReorgParameter\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x66 \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18g \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12\\x34\\n\\x10\\x62\\x61tch_norm_param\\x18\\x8b\\x01 \\x01(\\x0b\\x32\\x19.caffe.BatchNormParameter\\x12)\\n\\nbias_param\\x18\\x8d\\x01 \\x01(\\x0b\\x32\\x14.caffe.BiasParameter\\x12,\\n\\x0c\\x63oncat_param\\x18h \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18i \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18j \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18k \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18l \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18m \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18n \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12\\\'\\n\\telu_param\\x18\\x8c\\x01 \\x01(\\x0b\\x32\\x13.caffe.ELUParameter\\x12+\\n\\x0b\\x65mbed_param\\x18\\x89\\x01 \\x01(\\x0b\\x32\\x15.caffe.EmbedParameter\\x12&\\n\\texp_param\\x18o \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12/\\n\\rflatten_param\\x18\\x87\\x01 \\x01(\\x0b\\x32\\x17.caffe.FlattenParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18p \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18q \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18r \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18s \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18t \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18u \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12+\\n\\x0binput_param\\x18\\x8f\\x01 \\x01(\\x0b\\x32\\x15.caffe.InputParameter\\x12\\\'\\n\\tlog_param\\x18\\x86\\x01 \\x01(\\x0b\\x32\\x13.caffe.LogParameter\\x12&\\n\\tlrn_param\\x18v \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18w \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18x \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18y \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18z \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12+\\n\\x0bprelu_param\\x18\\x83\\x01 \\x01(\\x0b\\x32\\x15.caffe.PReLUParameter\\x12-\\n\\x0cpython_param\\x18\\x82\\x01 \\x01(\\x0b\\x32\\x16.caffe.PythonParameter\\x12\\x33\\n\\x0frecurrent_param\\x18\\x92\\x01 \\x01(\\x0b\\x32\\x19.caffe.RecurrentParameter\\x12\\x33\\n\\x0freduction_param\\x18\\x88\\x01 \\x01(\\x0b\\x32\\x19.caffe.ReductionParameter\\x12(\\n\\nrelu_param\\x18{ \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12/\\n\\rreshape_param\\x18\\x85\\x01 \\x01(\\x0b\\x32\\x17.caffe.ReshapeParameter\\x12\\x38\\n\\x11roi_pooling_param\\x18\\xd7\\xc7\\xf8\\x03 \\x01(\\x0b\\x32\\x1a.caffe.ROIPoolingParameter\\x12+\\n\\x0bscale_param\\x18\\x8e\\x01 \\x01(\\x0b\\x32\\x15.caffe.ScaleParameter\\x12.\\n\\rsigmoid_param\\x18| \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12=\\n\\x14smooth_l1_loss_param\\x18\\xd8\\xc7\\xf8\\x03 \\x01(\\x0b\\x32\\x1c.caffe.SmoothL1LossParameter\\x12.\\n\\rsoftmax_param\\x18} \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12\\\'\\n\\tspp_param\\x18\\x84\\x01 \\x01(\\x0b\\x32\\x13.caffe.SPPParameter\\x12*\\n\\x0bslice_param\\x18~ \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18\\x7f \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x33\\n\\x0fthreshold_param\\x18\\x80\\x01 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12)\\n\\ntile_param\\x18\\x8a\\x01 \\x01(\\x0b\\x32\\x14.caffe.TileParameter\\x12\\x36\\n\\x11window_data_param\\x18\\x81\\x01 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\x12\\x35\\n\\x08st_param\\x18\\x94\\x01 \\x01(\\x0b\\x32\\"".caffe.SpatialTransformerParameter\\x12.\\n\\rst_loss_param\\x18\\x91\\x01 \\x01(\\x0b\\x32\\x16.caffe.STLossParameter\\x12\\\'\\n\\trpn_param\\x18\\x96\\x01 \\x01(\\x0b\\x32\\x13.caffe.RPNParameter\\x12\\x34\\n\\x10\\x66ocal_loss_param\\x18\\x9b\\x01 \\x01(\\x0b\\x32\\x19.caffe.FocalLossParameter\\x12\\x32\\n\\x0f\\x61sdn_data_param\\x18\\x9f\\x01 \\x01(\\x0b\\x32\\x18.caffe.AsdnDataParameter\\x12%\\n\\x08\\x62n_param\\x18\\xa0\\x01 \\x01(\\x0b\\x32\\x12.caffe.BNParameter\\x12\\x34\\n\\x10mtcnn_data_param\\x18\\xa1\\x01 \\x01(\\x0b\\x32\\x19.caffe.MTCNNDataParameter\\x12-\\n\\x0cinterp_param\\x18\\xa2\\x01 \\x01(\\x0b\\x32\\x16.caffe.InterpParameter\\x12:\\n\\x13psroi_pooling_param\\x18\\xa3\\x01 \\x01(\\x0b\\x32\\x1c.caffe.PSROIPoolingParameter\\x12<\\n\\x14\\x61nnotated_data_param\\x18\\xa4\\x01 \\x01(\\x0b\\x32\\x1d.caffe.AnnotatedDataParameter\\x12\\x32\\n\\x0fprior_box_param\\x18\\xa5\\x01 \\x01(\\x0b\\x32\\x18.caffe.PriorBoxParameter\\x12)\\n\\ncrop_param\\x18\\xa7\\x01 \\x01(\\x0b\\x32\\x14.caffe.CropParameter\\x12\\x44\\n\\x18\\x64\\x65tection_evaluate_param\\x18\\xa8\\x01 \\x01(\\x0b\\x32!.caffe.DetectionEvaluateParameter\\x12@\\n\\x16\\x64\\x65tection_output_param\\x18\\xa9\\x01 \\x01(\\x0b\\x32\\x1f.caffe.DetectionOutputParameter\\x12:\\n\\x13multibox_loss_param\\x18\\xab\\x01 \\x01(\\x0b\\x32\\x1c.caffe.MultiBoxLossParameter\\x12/\\n\\rpermute_param\\x18\\xac\\x01 \\x01(\\x0b\\x32\\x17.caffe.PermuteParameter\\x12\\x34\\n\\x10video_data_param\\x18\\xad\\x01 \\x01(\\x0b\\x32\\x19.caffe.VideoDataParameter\\x12G\\n\\x1amargin_inner_product_param\\x18\\xae\\x01 \\x01(\\x0b\\x32\\"".caffe.MarginInnerProductParameter\\x12\\x36\\n\\x11\\x63\\x65nter_loss_param\\x18\\xaf\\x01 \\x01(\\x0b\\x32\\x1a.caffe.CenterLossParameter\\x12L\\n\\x1c\\x64\\x65\\x66ormable_convolution_param\\x18\\xb0\\x01 \\x01(\\x0b\\x32%.caffe.DeformableConvolutionParameter\\x12\\x43\\n\\x18label_specific_add_param\\x18\\xb1\\x01 \\x01(\\x0b\\x32 .caffe.LabelSpecificAddParameter\\x12X\\n#additive_margin_inner_product_param\\x18\\xb2\\x01 \\x01(\\x0b\\x32*.caffe.AdditiveMarginInnerProductParameter\\x12\\x35\\n\\x11\\x63osin_add_m_param\\x18\\xb3\\x01 \\x01(\\x0b\\x32\\x19.caffe.CosinAddmParameter\\x12\\x35\\n\\x11\\x63osin_mul_m_param\\x18\\xb4\\x01 \\x01(\\x0b\\x32\\x19.caffe.CosinMulmParameter\\x12:\\n\\x13\\x63hannel_scale_param\\x18\\xb5\\x01 \\x01(\\x0b\\x32\\x1c.caffe.ChannelScaleParameter\\x12)\\n\\nflip_param\\x18\\xb6\\x01 \\x01(\\x0b\\x32\\x14.caffe.FlipParameter\\x12\\x38\\n\\x12triplet_loss_param\\x18\\xb7\\x01 \\x01(\\x0b\\x32\\x1b.caffe.TripletLossParameter\\x12G\\n\\x1a\\x63oupled_cluster_loss_param\\x18\\xb8\\x01 \\x01(\\x0b\\x32\\"".caffe.CoupledClusterLossParameter\\x12\\x43\\n\\x1ageneral_triplet_loss_param\\x18\\xb9\\x01 \\x01(\\x0b\\x32\\x1e.caffe.GeneralTripletParameter\\x12\\x32\\n\\x0froi_align_param\\x18\\xba\\x01 \\x01(\\x0b\\x32\\x18.caffe.ROIAlignParameter\\x12\\x32\\n\\x0eupsample_param\\x18\\xa3\\x8d\\x06 \\x01(\\x0b\\x32\\x18.caffe.UpsampleParameter\\x12.\\n\\x0cmatmul_param\\x18\\xa5\\x8d\\x06 \\x01(\\x0b\\x32\\x16.caffe.MatMulParameter\\x12\\x39\\n\\x12pass_through_param\\x18\\xa4\\x8d\\x06 \\x01(\\x0b\\x32\\x1b.caffe.PassThroughParameter\\x12/\\n\\nnorm_param\\x18\\xa1\\x8d\\x06 \\x01(\\x0b\\x32\\x19.caffe.NormalizeParameter\\""\\xa3\\x01\\n\\x11UpsampleParameter\\x12\\x10\\n\\x05scale\\x18\\x01 \\x01(\\r:\\x01\\x32\\x12\\x0f\\n\\x07scale_h\\x18\\x02 \\x01(\\r\\x12\\x0f\\n\\x07scale_w\\x18\\x03 \\x01(\\r\\x12\\x18\\n\\tpad_out_h\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x18\\n\\tpad_out_w\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x12\\n\\nupsample_h\\x18\\x06 \\x01(\\r\\x12\\x12\\n\\nupsample_w\\x18\\x07 \\x01(\\r\\"">\\n\\x0fMatMulParameter\\x12\\r\\n\\x05\\x64im_1\\x18\\x01 \\x01(\\r\\x12\\r\\n\\x05\\x64im_2\\x18\\x02 \\x01(\\r\\x12\\r\\n\\x05\\x64im_3\\x18\\x03 \\x01(\\r\\""^\\n\\x14PassThroughParameter\\x12\\x15\\n\\nnum_output\\x18\\x01 \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\x0c\\x62lock_height\\x18\\x02 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x0b\\x62lock_width\\x18\\x03 \\x01(\\r:\\x01\\x30\\""\\xa5\\x01\\n\\x12NormalizeParameter\\x12\\x1c\\n\\x0e\\x61\\x63ross_spatial\\x18\\x01 \\x01(\\x08:\\x04true\\x12,\\n\\x0cscale_filler\\x18\\x02 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1c\\n\\x0e\\x63hannel_shared\\x18\\x03 \\x01(\\x08:\\x04true\\x12\\x12\\n\\x03\\x65ps\\x18\\x04 \\x01(\\x02:\\x05\\x31\\x65-10\\x12\\x11\\n\\x06sqrt_a\\x18\\x05 \\x01(\\x02:\\x01\\x31\\""\\x95\\x01\\n\\x16\\x41nnotatedDataParameter\\x12*\\n\\rbatch_sampler\\x18\\x01 \\x03(\\x0b\\x32\\x13.caffe.BatchSampler\\x12\\x16\\n\\x0elabel_map_file\\x18\\x02 \\x01(\\t\\x12\\x37\\n\\tanno_type\\x18\\x03 \\x01(\\x0e\\x32$.caffe.AnnotatedDatum.AnnotationType\\""\\xab\\x01\\n\\x11\\x41sdnDataParameter\\x12\\x16\\n\\ncount_drop\\x18\\x01 \\x01(\\x05:\\x02\\x31\\x35\\x12\\x19\\n\\rpermute_count\\x18\\x02 \\x01(\\x05:\\x02\\x32\\x30\\x12\\x19\\n\\x0e\\x63ount_drop_neg\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x16\\n\\x08\\x63hannels\\x18\\x04 \\x01(\\x05:\\x04\\x31\\x30\\x32\\x34\\x12\\x14\\n\\titer_size\\x18\\x05 \\x01(\\x05:\\x01\\x32\\x12\\x1a\\n\\x0fmaintain_before\\x18\\x06 \\x01(\\x05:\\x01\\x31\\""\\x80\\x02\\n\\x12MTCNNDataParameter\\x12\\x17\\n\\taugmented\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x12\\n\\x04\\x66lip\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x18\\n\\x0cnum_positive\\x18\\x03 \\x01(\\x05:\\x02-1\\x12\\x18\\n\\x0cnum_negitive\\x18\\x04 \\x01(\\x05:\\x02-1\\x12\\x14\\n\\x08num_part\\x18\\x05 \\x01(\\x05:\\x02-1\\x12\\x17\\n\\x0cresize_width\\x18\\x06 \\x01(\\r:\\x01\\x30\\x12\\x18\\n\\rresize_height\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x1f\\n\\x12min_negitive_scale\\x18\\x08 \\x01(\\x02:\\x03\\x30.5\\x12\\x1f\\n\\x12max_negitive_scale\\x18\\t \\x01(\\x02:\\x03\\x31.5\\""\\x90\\x01\\n\\x0fInterpParameter\\x12\\x11\\n\\x06height\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x16\\n\\x0bzoom_factor\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\rshrink_factor\\x18\\x04 \\x01(\\x05:\\x01\\x31\\x12\\x12\\n\\x07pad_beg\\x18\\x05 \\x01(\\x05:\\x01\\x30\\x12\\x12\\n\\x07pad_end\\x18\\x06 \\x01(\\x05:\\x01\\x30\\""V\\n\\x15PSROIPoolingParameter\\x12\\x15\\n\\rspatial_scale\\x18\\x01 \\x02(\\x02\\x12\\x12\\n\\noutput_dim\\x18\\x02 \\x02(\\x05\\x12\\x12\\n\\ngroup_size\\x18\\x03 \\x02(\\x05\\""E\\n\\rFlipParameter\\x12\\x18\\n\\nflip_width\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1a\\n\\x0b\\x66lip_height\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x8b\\x02\\n\\x0b\\x42NParameter\\x12,\\n\\x0cslope_filler\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x02 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x15\\n\\x08momentum\\x18\\x03 \\x01(\\x02:\\x03\\x30.9\\x12\\x12\\n\\x03\\x65ps\\x18\\x04 \\x01(\\x02:\\x05\\x31\\x65-05\\x12\\x15\\n\\x06\\x66rozen\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x32\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x19.caffe.BNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xa2\\x01\\n\\x12\\x46ocalLossParameter\\x12\\x34\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.FocalLossParameter.Type:\\x06ORIGIN\\x12\\x10\\n\\x05gamma\\x18\\x02 \\x01(\\x02:\\x01\\x32\\x12\\x13\\n\\x05\\x61lpha\\x18\\x03 \\x01(\\x02:\\x04\\x30.25\\x12\\x0f\\n\\x04\\x62\\x65ta\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""\\x1e\\n\\x04Type\\x12\\n\\n\\x06ORIGIN\\x10\\x00\\x12\\n\\n\\x06LINEAR\\x10\\x01\\""\\xca\\x03\\n\\x17TransformationParameter\\x12\\x10\\n\\x05scale\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\x06mirror\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x14\\n\\tcrop_size\\x18\\x03 \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\x06\\x63rop_h\\x18\\x0b \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\x06\\x63rop_w\\x18\\x0c \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\tmean_file\\x18\\x04 \\x01(\\t\\x12\\x12\\n\\nmean_value\\x18\\x05 \\x03(\\x02\\x12\\x1a\\n\\x0b\\x66orce_color\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\nforce_gray\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12,\\n\\x0cresize_param\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.ResizeParameter\\x12*\\n\\x0bnoise_param\\x18\\t \\x01(\\x0b\\x32\\x15.caffe.NoiseParameter\\x12\\x31\\n\\rdistort_param\\x18\\r \\x01(\\x0b\\x32\\x1a.caffe.DistortionParameter\\x12/\\n\\x0c\\x65xpand_param\\x18\\x0e \\x01(\\x0b\\x32\\x19.caffe.ExpansionParameter\\x12.\\n\\x0f\\x65mit_constraint\\x18\\n \\x01(\\x0b\\x32\\x15.caffe.EmitConstraint\\""\\x90\\x04\\n\\x0fResizeParameter\\x12\\x0f\\n\\x04prob\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12=\\n\\x0bresize_mode\\x18\\x02 \\x01(\\x0e\\x32\\"".caffe.ResizeParameter.Resize_mode:\\x04WARP\\x12\\x11\\n\\x06height\\x18\\x03 \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x04 \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\x0cheight_scale\\x18\\x08 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x0bwidth_scale\\x18\\t \\x01(\\r:\\x01\\x30\\x12;\\n\\x08pad_mode\\x18\\x05 \\x01(\\x0e\\x32\\x1f.caffe.ResizeParameter.Pad_mode:\\x08\\x43ONSTANT\\x12\\x11\\n\\tpad_value\\x18\\x06 \\x03(\\x02\\x12\\x37\\n\\x0binterp_mode\\x18\\x07 \\x03(\\x0e\\x32\\"".caffe.ResizeParameter.Interp_mode\\""G\\n\\x0bResize_mode\\x12\\x08\\n\\x04WARP\\x10\\x01\\x12\\x12\\n\\x0e\\x46IT_SMALL_SIZE\\x10\\x02\\x12\\x1a\\n\\x16\\x46IT_LARGE_SIZE_AND_PAD\\x10\\x03\\"":\\n\\x08Pad_mode\\x12\\x0c\\n\\x08\\x43ONSTANT\\x10\\x01\\x12\\x0c\\n\\x08MIRRORED\\x10\\x02\\x12\\x12\\n\\x0eREPEAT_NEAREST\\x10\\x03\\""I\\n\\x0bInterp_mode\\x12\\n\\n\\x06LINEAR\\x10\\x01\\x12\\x08\\n\\x04\\x41REA\\x10\\x02\\x12\\x0b\\n\\x07NEAREST\\x10\\x03\\x12\\t\\n\\x05\\x43UBIC\\x10\\x04\\x12\\x0c\\n\\x08LANCZOS4\\x10\\x05\\""9\\n\\x13SaltPepperParameter\\x12\\x13\\n\\x08\\x66raction\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\r\\n\\x05value\\x18\\x02 \\x03(\\x02\\""\\xee\\x02\\n\\x0eNoiseParameter\\x12\\x0f\\n\\x04prob\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x16\\n\\x07hist_eq\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x16\\n\\x07inverse\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\ndecolorize\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\ngauss_blur\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x04jpeg\\x18\\x06 \\x01(\\x02:\\x02-1\\x12\\x18\\n\\tposterize\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x14\\n\\x05\\x65rode\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\nsaltpepper\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x34\\n\\x10saltpepper_param\\x18\\n \\x01(\\x0b\\x32\\x1a.caffe.SaltPepperParameter\\x12\\x14\\n\\x05\\x63lahe\\x18\\x0b \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1d\\n\\x0e\\x63onvert_to_hsv\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1d\\n\\x0e\\x63onvert_to_lab\\x18\\r \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xbd\\x02\\n\\x13\\x44istortionParameter\\x12\\x1a\\n\\x0f\\x62rightness_prob\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x1b\\n\\x10\\x62rightness_delta\\x18\\x02 \\x01(\\x02:\\x01\\x30\\x12\\x18\\n\\rcontrast_prob\\x18\\x03 \\x01(\\x02:\\x01\\x30\\x12\\x19\\n\\x0e\\x63ontrast_lower\\x18\\x04 \\x01(\\x02:\\x01\\x30\\x12\\x19\\n\\x0e\\x63ontrast_upper\\x18\\x05 \\x01(\\x02:\\x01\\x30\\x12\\x13\\n\\x08hue_prob\\x18\\x06 \\x01(\\x02:\\x01\\x30\\x12\\x14\\n\\thue_delta\\x18\\x07 \\x01(\\x02:\\x01\\x30\\x12\\x1a\\n\\x0fsaturation_prob\\x18\\x08 \\x01(\\x02:\\x01\\x30\\x12\\x1b\\n\\x10saturation_lower\\x18\\t \\x01(\\x02:\\x01\\x30\\x12\\x1b\\n\\x10saturation_upper\\x18\\n \\x01(\\x02:\\x01\\x30\\x12\\x1c\\n\\x11random_order_prob\\x18\\x0b \\x01(\\x02:\\x01\\x30\\""B\\n\\x12\\x45xpansionParameter\\x12\\x0f\\n\\x04prob\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x1b\\n\\x10max_expand_ratio\\x18\\x02 \\x01(\\x02:\\x01\\x31\\""\\xc2\\x01\\n\\rLossParameter\\x12\\x14\\n\\x0cignore_label\\x18\\x01 \\x01(\\x05\\x12\\x44\\n\\rnormalization\\x18\\x03 \\x01(\\x0e\\x32&.caffe.LossParameter.NormalizationMode:\\x05VALID\\x12\\x11\\n\\tnormalize\\x18\\x02 \\x01(\\x08\\""B\\n\\x11NormalizationMode\\x12\\x08\\n\\x04\\x46ULL\\x10\\x00\\x12\\t\\n\\x05VALID\\x10\\x01\\x12\\x0e\\n\\nBATCH_SIZE\\x10\\x02\\x12\\x08\\n\\x04NONE\\x10\\x03\\""L\\n\\x11\\x41\\x63\\x63uracyParameter\\x12\\x10\\n\\x05top_k\\x18\\x01 \\x01(\\r:\\x01\\x31\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x0cignore_label\\x18\\x03 \\x01(\\x05\\""M\\n\\x0f\\x41rgMaxParameter\\x12\\x1a\\n\\x0bout_max_val\\x18\\x01 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x05top_k\\x18\\x02 \\x01(\\r:\\x01\\x31\\x12\\x0c\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05\\""9\\n\\x0f\\x43oncatParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x15\\n\\nconcat_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""j\\n\\x12\\x42\\x61tchNormParameter\\x12\\x18\\n\\x10use_global_stats\\x18\\x01 \\x01(\\x08\\x12&\\n\\x17moving_average_fraction\\x18\\x02 \\x01(\\x02:\\x05\\x30.999\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-05\\""]\\n\\rBiasParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""L\\n\\x18\\x43ontrastiveLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x1d\\n\\x0elegacy_version\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xec\\x01\\n\\x16\\x44\\x65tectionLossParameter\\x12\\x0f\\n\\x04side\\x18\\x01 \\x01(\\r:\\x01\\x37\\x12\\x15\\n\\tnum_class\\x18\\x02 \\x01(\\r:\\x02\\x32\\x30\\x12\\x15\\n\\nnum_object\\x18\\x03 \\x01(\\r:\\x01\\x32\\x12\\x17\\n\\x0cobject_scale\\x18\\x04 \\x01(\\x02:\\x01\\x31\\x12\\x1b\\n\\x0enoobject_scale\\x18\\x05 \\x01(\\x02:\\x03\\x30.5\\x12\\x16\\n\\x0b\\x63lass_scale\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x16\\n\\x0b\\x63oord_scale\\x18\\x07 \\x01(\\x02:\\x01\\x35\\x12\\x12\\n\\x04sqrt\\x18\\x08 \\x01(\\x08:\\x04true\\x12\\x19\\n\\nconstriant\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x91\\x03\\n\\x13RegionLossParameter\\x12\\x10\\n\\x04side\\x18\\x01 \\x01(\\r:\\x02\\x31\\x33\\x12\\x15\\n\\tnum_class\\x18\\x02 \\x01(\\r:\\x02\\x32\\x30\\x12\\x15\\n\\nbias_match\\x18\\x03 \\x01(\\r:\\x01\\x31\\x12\\x11\\n\\x06\\x63oords\\x18\\x04 \\x01(\\r:\\x01\\x34\\x12\\x0e\\n\\x03num\\x18\\x05 \\x01(\\r:\\x01\\x35\\x12\\x12\\n\\x07softmax\\x18\\x06 \\x01(\\r:\\x01\\x31\\x12\\x13\\n\\x06jitter\\x18\\x07 \\x01(\\x02:\\x03\\x30.2\\x12\\x12\\n\\x07rescore\\x18\\x08 \\x01(\\r:\\x01\\x31\\x12\\x17\\n\\x0cobject_scale\\x18\\t \\x01(\\x02:\\x01\\x31\\x12\\x16\\n\\x0b\\x63lass_scale\\x18\\n \\x01(\\x02:\\x01\\x31\\x12\\x1b\\n\\x0enoobject_scale\\x18\\x0b \\x01(\\x02:\\x03\\x30.5\\x12\\x16\\n\\x0b\\x63oord_scale\\x18\\x0c \\x01(\\x02:\\x01\\x35\\x12\\x13\\n\\x08\\x61\\x62solute\\x18\\r \\x01(\\r:\\x01\\x31\\x12\\x13\\n\\x06thresh\\x18\\x0e \\x01(\\x02:\\x03\\x30.2\\x12\\x11\\n\\x06random\\x18\\x0f \\x01(\\r:\\x01\\x31\\x12\\x0e\\n\\x06\\x62iases\\x18\\x10 \\x03(\\x02\\x12\\x14\\n\\x0csoftmax_tree\\x18\\x11 \\x01(\\t\\x12\\x11\\n\\tclass_map\\x18\\x12 \\x01(\\t\\""8\\n\\x0eReorgParameter\\x12\\x0e\\n\\x06stride\\x18\\x01 \\x01(\\r\\x12\\x16\\n\\x07reverse\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xb3\\x02\\n\\x16\\x45valDetectionParameter\\x12\\x0f\\n\\x04side\\x18\\x01 \\x01(\\r:\\x01\\x37\\x12\\x15\\n\\tnum_class\\x18\\x02 \\x01(\\r:\\x02\\x32\\x30\\x12\\x15\\n\\nnum_object\\x18\\x03 \\x01(\\r:\\x01\\x32\\x12\\x16\\n\\tthreshold\\x18\\x04 \\x01(\\x02:\\x03\\x30.5\\x12\\x12\\n\\x04sqrt\\x18\\x05 \\x01(\\x08:\\x04true\\x12\\x18\\n\\nconstriant\\x18\\x06 \\x01(\\x08:\\x04true\\x12\\x45\\n\\nscore_type\\x18\\x07 \\x01(\\x0e\\x32\\\'.caffe.EvalDetectionParameter.ScoreType:\\x08MULTIPLY\\x12\\x0f\\n\\x03nms\\x18\\x08 \\x01(\\x02:\\x02-1\\x12\\x0e\\n\\x06\\x62iases\\x18\\t \\x03(\\x02\\"",\\n\\tScoreType\\x12\\x07\\n\\x03OBJ\\x10\\x00\\x12\\x08\\n\\x04PROB\\x10\\x01\\x12\\x0c\\n\\x08MULTIPLY\\x10\\x02\\""\\xfc\\x03\\n\\x14\\x43onvolutionParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x0b\\n\\x03pad\\x18\\x03 \\x03(\\r\\x12\\x13\\n\\x0bkernel_size\\x18\\x04 \\x03(\\r\\x12\\x0e\\n\\x06stride\\x18\\x06 \\x03(\\r\\x12\\x10\\n\\x08\\x64ilation\\x18\\x12 \\x03(\\r\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x08kernel_h\\x18\\x0b \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x0c \\x01(\\r\\x12\\x10\\n\\x08stride_h\\x18\\r \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x0e \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\x05 \\x01(\\r:\\x01\\x31\\x12-\\n\\rweight_filler\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12;\\n\\x06\\x65ngine\\x18\\x0f \\x01(\\x0e\\x32\\"".caffe.ConvolutionParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x10 \\x01(\\x05:\\x01\\x31\\x12\\x1e\\n\\x0f\\x66orce_nd_im2col\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""0\\n\\rCropParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x32\\x12\\x0e\\n\\x06offset\\x18\\x02 \\x03(\\r\\""\\xb2\\x02\\n\\rDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x31\\n\\x07\\x62\\x61\\x63kend\\x18\\x08 \\x01(\\x0e\\x32\\x17.caffe.DataParameter.DB:\\x07LEVELDB\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x13\\x66orce_encoded_color\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x13\\n\\x08prefetch\\x18\\n \\x01(\\r:\\x01\\x34\\x12\\x0c\\n\\x04side\\x18\\x0b \\x03(\\r\\""\\x1b\\n\\x02\\x44\\x42\\x12\\x0b\\n\\x07LEVELDB\\x10\\x00\\x12\\x08\\n\\x04LMDB\\x10\\x01\\""\\xdc\\x01\\n\\x1a\\x44\\x65tectionEvaluateParameter\\x12\\x13\\n\\x0bnum_classes\\x18\\x01 \\x01(\\r\\x12\\x1e\\n\\x13\\x62\\x61\\x63kground_label_id\\x18\\x02 \\x01(\\r:\\x01\\x30\\x12\\x1e\\n\\x11overlap_threshold\\x18\\x03 \\x01(\\x02:\\x03\\x30.5\\x12#\\n\\x15\\x65valuate_difficult_gt\\x18\\x04 \\x01(\\x08:\\x04true\\x12\\x16\\n\\x0ename_size_file\\x18\\x05 \\x01(\\t\\x12,\\n\\x0cresize_param\\x18\\x06 \\x01(\\x0b\\x32\\x16.caffe.ResizeParameter\\""[\\n\\x1eNonMaximumSuppressionParameter\\x12\\x1a\\n\\rnms_threshold\\x18\\x01 \\x01(\\x02:\\x03\\x30.3\\x12\\r\\n\\x05top_k\\x18\\x02 \\x01(\\x05\\x12\\x0e\\n\\x03\\x65ta\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""\\xd8\\x01\\n\\x13SaveOutputParameter\\x12\\x18\\n\\x10output_directory\\x18\\x01 \\x01(\\t\\x12\\x1a\\n\\x12output_name_prefix\\x18\\x02 \\x01(\\t\\x12\\x15\\n\\routput_format\\x18\\x03 \\x01(\\t\\x12\\x16\\n\\x0elabel_map_file\\x18\\x04 \\x01(\\t\\x12\\x16\\n\\x0ename_size_file\\x18\\x05 \\x01(\\t\\x12\\x16\\n\\x0enum_test_image\\x18\\x06 \\x01(\\r\\x12,\\n\\x0cresize_param\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.ResizeParameter\\""\\xc7\\x03\\n\\x18\\x44\\x65tectionOutputParameter\\x12\\x13\\n\\x0bnum_classes\\x18\\x01 \\x01(\\r\\x12\\x1c\\n\\x0eshare_location\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x13\\x62\\x61\\x63kground_label_id\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x38\\n\\tnms_param\\x18\\x04 \\x01(\\x0b\\x32%.caffe.NonMaximumSuppressionParameter\\x12\\x35\\n\\x11save_output_param\\x18\\x05 \\x01(\\x0b\\x32\\x1a.caffe.SaveOutputParameter\\x12<\\n\\tcode_type\\x18\\x06 \\x01(\\x0e\\x32!.caffe.PriorBoxParameter.CodeType:\\x06\\x43ORNER\\x12)\\n\\x1avariance_encoded_in_target\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x16\\n\\nkeep_top_k\\x18\\x07 \\x01(\\x05:\\x02-1\\x12\\x1c\\n\\x14\\x63onfidence_threshold\\x18\\t \\x01(\\x02\\x12\\x18\\n\\tvisualize\\x18\\n \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1b\\n\\x13visualize_threshold\\x18\\x0b \\x01(\\x02\\x12\\x11\\n\\tsave_file\\x18\\x0c \\x01(\\t\\""I\\n\\x10\\x44ropoutParameter\\x12\\x1a\\n\\rdropout_ratio\\x18\\x01 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0bscale_train\\x18\\x02 \\x01(\\x08:\\x04true\\""\\xa0\\x01\\n\\x12\\x44ummyDataParameter\\x12+\\n\\x0b\\x64\\x61ta_filler\\x18\\x01 \\x03(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1f\\n\\x05shape\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0b\\n\\x03num\\x18\\x02 \\x03(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x03 \\x03(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x03(\\r\\x12\\r\\n\\x05width\\x18\\x05 \\x03(\\r\\""\\xa5\\x01\\n\\x10\\x45ltwiseParameter\\x12\\x39\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32!.caffe.EltwiseParameter.EltwiseOp:\\x03SUM\\x12\\r\\n\\x05\\x63oeff\\x18\\x02 \\x03(\\x02\\x12\\x1e\\n\\x10stable_prod_grad\\x18\\x03 \\x01(\\x08:\\x04true\\""\\\'\\n\\tEltwiseOp\\x12\\x08\\n\\x04PROD\\x10\\x00\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x07\\n\\x03MAX\\x10\\x02\\"" \\n\\x0c\\x45LUParameter\\x12\\x10\\n\\x05\\x61lpha\\x18\\x01 \\x01(\\x02:\\x01\\x31\\""\\xac\\x01\\n\\x0e\\x45mbedParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x11\\n\\tinput_dim\\x18\\x02 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x03 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""D\\n\\x0c\\x45xpParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""9\\n\\x10\\x46lattenParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x08\\x65nd_axis\\x18\\x02 \\x01(\\x05:\\x02-1\\""O\\n\\x11HDF5DataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x02 \\x01(\\r\\x12\\x16\\n\\x07shuffle\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\""(\\n\\x13HDF5OutputParameter\\x12\\x11\\n\\tfile_name\\x18\\x01 \\x01(\\t\\""^\\n\\x12HingeLossParameter\\x12\\x30\\n\\x04norm\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.HingeLossParameter.Norm:\\x02L1\\""\\x16\\n\\x04Norm\\x12\\x06\\n\\x02L1\\x10\\x01\\x12\\x06\\n\\x02L2\\x10\\x02\\""\\x97\\x02\\n\\x12ImageDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\nbatch_size\\x18\\x04 \\x01(\\r:\\x01\\x31\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x07shuffle\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nnew_height\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x08is_color\\x18\\x0b \\x01(\\x08:\\x04true\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\x0c \\x01(\\t:\\x00\\""\\\'\\n\\x15InfogainLossParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\""\\xe5\\x01\\n\\x15InnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x05 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\ttranspose\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x18\\n\\tnormalize\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""1\\n\\x0eInputParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\""D\\n\\x0cLogParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""\\xb8\\x02\\n\\x0cLRNParameter\\x12\\x15\\n\\nlocal_size\\x18\\x01 \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x03 \\x01(\\x02:\\x04\\x30.75\\x12\\x44\\n\\x0bnorm_region\\x18\\x04 \\x01(\\x0e\\x32\\x1e.caffe.LRNParameter.NormRegion:\\x0f\\x41\\x43ROSS_CHANNELS\\x12\\x0c\\n\\x01k\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.LRNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""5\\n\\nNormRegion\\x12\\x13\\n\\x0f\\x41\\x43ROSS_CHANNELS\\x10\\x00\\x12\\x12\\n\\x0eWITHIN_CHANNEL\\x10\\x01\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x13MemoryDataParameter\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\""\\xe8\\x08\\n\\x15MultiBoxLossParameter\\x12J\\n\\rloc_loss_type\\x18\\x01 \\x01(\\x0e\\x32(.caffe.MultiBoxLossParameter.LocLossType:\\tSMOOTH_L1\\x12J\\n\\x0e\\x63onf_loss_type\\x18\\x02 \\x01(\\x0e\\x32).caffe.MultiBoxLossParameter.ConfLossType:\\x07SOFTMAX\\x12\\x15\\n\\nloc_weight\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x13\\n\\x0bnum_classes\\x18\\x04 \\x01(\\r\\x12\\x1c\\n\\x0eshare_location\\x18\\x05 \\x01(\\x08:\\x04true\\x12J\\n\\nmatch_type\\x18\\x06 \\x01(\\x0e\\x32&.caffe.MultiBoxLossParameter.MatchType:\\x0ePER_PREDICTION\\x12\\x1e\\n\\x11overlap_threshold\\x18\\x07 \\x01(\\x02:\\x03\\x30.5\\x12$\\n\\x16use_prior_for_matching\\x18\\x08 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x13\\x62\\x61\\x63kground_label_id\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x1e\\n\\x10use_difficult_gt\\x18\\n \\x01(\\x08:\\x04true\\x12\\x15\\n\\rdo_neg_mining\\x18\\x0b \\x01(\\x08\\x12\\x18\\n\\rneg_pos_ratio\\x18\\x0c \\x01(\\x02:\\x01\\x33\\x12\\x18\\n\\x0bneg_overlap\\x18\\r \\x01(\\x02:\\x03\\x30.5\\x12<\\n\\tcode_type\\x18\\x0e \\x01(\\x0e\\x32!.caffe.PriorBoxParameter.CodeType:\\x06\\x43ORNER\\x12(\\n\\x19\\x65ncode_variance_in_target\\x18\\x10 \\x01(\\x08:\\x05\\x66\\x61lse\\x12%\\n\\x16map_object_to_agnostic\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\x12)\\n\\x1aignore_cross_boundary_bbox\\x18\\x12 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x18\\n\\tbp_inside\\x18\\x13 \\x01(\\x08:\\x05\\x66\\x61lse\\x12J\\n\\x0bmining_type\\x18\\x14 \\x01(\\x0e\\x32\\\'.caffe.MultiBoxLossParameter.MiningType:\\x0cMAX_NEGATIVE\\x12\\x38\\n\\tnms_param\\x18\\x15 \\x01(\\x0b\\x32%.caffe.NonMaximumSuppressionParameter\\x12\\x17\\n\\x0bsample_size\\x18\\x16 \\x01(\\x05:\\x02\\x36\\x34\\x12 \\n\\x11use_prior_for_nms\\x18\\x17 \\x01(\\x08:\\x05\\x66\\x61lse\\""$\\n\\x0bLocLossType\\x12\\x06\\n\\x02L2\\x10\\x00\\x12\\r\\n\\tSMOOTH_L1\\x10\\x01\\"")\\n\\x0c\\x43onfLossType\\x12\\x0b\\n\\x07SOFTMAX\\x10\\x00\\x12\\x0c\\n\\x08LOGISTIC\\x10\\x01\\"".\\n\\tMatchType\\x12\\r\\n\\tBIPARTITE\\x10\\x00\\x12\\x12\\n\\x0ePER_PREDICTION\\x10\\x01\\"":\\n\\nMiningType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\x10\\n\\x0cMAX_NEGATIVE\\x10\\x01\\x12\\x10\\n\\x0cHARD_EXAMPLE\\x10\\x02\\""!\\n\\x10PermuteParameter\\x12\\r\\n\\x05order\\x18\\x01 \\x03(\\r\\""d\\n\\x0cMVNParameter\\x12 \\n\\x12normalize_variance\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x0f\\x61\\x63ross_channels\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-09\\""5\\n\\x12ParameterParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\""\\xbb\\x03\\n\\x10PoolingParameter\\x12\\x35\\n\\x04pool\\x18\\x01 \\x01(\\x0e\\x32\\"".caffe.PoolingParameter.PoolMethod:\\x03MAX\\x12\\x0e\\n\\x03pad\\x18\\x04 \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x0bkernel_size\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08kernel_h\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x06 \\x01(\\r\\x12\\x11\\n\\x06stride\\x18\\x03 \\x01(\\r:\\x01\\x31\\x12\\x10\\n\\x08stride_h\\x18\\x07 \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x08 \\x01(\\r\\x12\\x37\\n\\x06\\x65ngine\\x18\\x0b \\x01(\\x0e\\x32\\x1e.caffe.PoolingParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x1d\\n\\x0eglobal_pooling\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x17\\n\\tceil_mode\\x18\\r \\x01(\\x08:\\x04true\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""F\\n\\x0ePowerParameter\\x12\\x10\\n\\x05power\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""\\xb5\\x02\\n\\x11PriorBoxParameter\\x12\\x10\\n\\x08min_size\\x18\\x01 \\x03(\\x02\\x12\\x10\\n\\x08max_size\\x18\\x02 \\x03(\\x02\\x12\\x14\\n\\x0c\\x61spect_ratio\\x18\\x03 \\x03(\\x02\\x12\\x12\\n\\x04\\x66lip\\x18\\x04 \\x01(\\x08:\\x04true\\x12\\x13\\n\\x04\\x63lip\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x08variance\\x18\\x06 \\x03(\\x02\\x12\\x10\\n\\x08img_size\\x18\\x07 \\x01(\\r\\x12\\r\\n\\x05img_h\\x18\\x08 \\x01(\\r\\x12\\r\\n\\x05img_w\\x18\\t \\x01(\\r\\x12\\x0c\\n\\x04step\\x18\\n \\x01(\\x02\\x12\\x0e\\n\\x06step_h\\x18\\x0b \\x01(\\x02\\x12\\x0e\\n\\x06step_w\\x18\\x0c \\x01(\\x02\\x12\\x13\\n\\x06offset\\x18\\r \\x01(\\x02:\\x03\\x30.5\\""8\\n\\x08\\x43odeType\\x12\\n\\n\\x06\\x43ORNER\\x10\\x01\\x12\\x0f\\n\\x0b\\x43\\x45NTER_SIZE\\x10\\x02\\x12\\x0f\\n\\x0b\\x43ORNER_SIZE\\x10\\x03\\""g\\n\\x0fPythonParameter\\x12\\x0e\\n\\x06module\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05layer\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\tparam_str\\x18\\x03 \\x01(\\t:\\x00\\x12 \\n\\x11share_in_parallel\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xc0\\x01\\n\\x12RecurrentParameter\\x12\\x15\\n\\nnum_output\\x18\\x01 \\x01(\\r:\\x01\\x30\\x12-\\n\\rweight_filler\\x18\\x02 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x19\\n\\ndebug_info\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1c\\n\\rexpose_hidden\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xad\\x01\\n\\x12ReductionParameter\\x12=\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32%.caffe.ReductionParameter.ReductionOp:\\x03SUM\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05\\x63oeff\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""5\\n\\x0bReductionOp\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x08\\n\\x04\\x41SUM\\x10\\x02\\x12\\t\\n\\x05SUMSQ\\x10\\x03\\x12\\x08\\n\\x04MEAN\\x10\\x04\\""\\x8d\\x01\\n\\rReLUParameter\\x12\\x19\\n\\x0enegative_slope\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x34\\n\\x06\\x65ngine\\x18\\x02 \\x01(\\x0e\\x32\\x1b.caffe.ReLUParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x10ReshapeParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\x08num_axes\\x18\\x03 \\x01(\\x05:\\x02-1\\""Y\\n\\x13ROIPoolingParameter\\x12\\x13\\n\\x08pooled_h\\x18\\x01 \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x08pooled_w\\x18\\x02 \\x01(\\r:\\x01\\x30\\x12\\x18\\n\\rspatial_scale\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""\\xcb\\x01\\n\\x0eScaleParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x18\\n\\tbias_term\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x11\\n\\tmin_value\\x18\\x06 \\x01(\\x02\\x12\\x11\\n\\tmax_value\\x18\\x07 \\x01(\\x02\\""x\\n\\x10SigmoidParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SigmoidParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\"")\\n\\x15SmoothL1LossParameter\\x12\\x10\\n\\x05sigma\\x18\\x01 \\x01(\\x02:\\x01\\x31\\""L\\n\\x0eSliceParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x0bslice_point\\x18\\x02 \\x03(\\r\\x12\\x14\\n\\tslice_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""\\x89\\x01\\n\\x10SoftmaxParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SoftmaxParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""r\\n\\rTanHParameter\\x12\\x34\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1b.caffe.TanHParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""/\\n\\rTileParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\r\\n\\x05tiles\\x18\\x02 \\x01(\\x05\\""*\\n\\x12ThresholdParameter\\x12\\x14\\n\\tthreshold\\x18\\x01 \\x01(\\x02:\\x01\\x30\\""\\xc1\\x02\\n\\x13WindowDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\x0c\\x66g_threshold\\x18\\x07 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0c\\x62g_threshold\\x18\\x08 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0b\\x66g_fraction\\x18\\t \\x01(\\x02:\\x04\\x30.25\\x12\\x16\\n\\x0b\\x63ontext_pad\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\tcrop_mode\\x18\\x0b \\x01(\\t:\\x04warp\\x12\\x1b\\n\\x0c\\x63\\x61\\x63he_images\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\r \\x01(\\t:\\x00\\""\\xeb\\x01\\n\\x0cSPPParameter\\x12\\x16\\n\\x0epyramid_height\\x18\\x01 \\x01(\\r\\x12\\x31\\n\\x04pool\\x18\\x02 \\x01(\\x0e\\x32\\x1e.caffe.SPPParameter.PoolMethod:\\x03MAX\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.SPPParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xdc\\x14\\n\\x10V1LayerParameter\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x02 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x03 \\x03(\\t\\x12\\x0c\\n\\x04name\\x18\\x04 \\x01(\\t\\x12$\\n\\x07include\\x18  \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18! \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12/\\n\\x04type\\x18\\x05 \\x01(\\x0e\\x32!.caffe.V1LayerParameter.LayerType\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x0e\\n\\x05param\\x18\\xe9\\x07 \\x03(\\t\\x12>\\n\\x0f\\x62lob_share_mode\\x18\\xea\\x07 \\x03(\\x0e\\x32$.caffe.V1LayerParameter.DimCheckMode\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x07 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x08 \\x03(\\x02\\x12\\x13\\n\\x0bloss_weight\\x18# \\x03(\\x02\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x1b \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18\\x17 \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12,\\n\\x0c\\x63oncat_param\\x18\\t \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18( \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18\\n \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18\\x0b \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18\\x0c \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18\\x1a \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18\\x18 \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12&\\n\\texp_param\\x18) \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18\\r \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18\\x0e \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18\\x1d \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18\\x0f \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18\\x10 \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18\\x11 \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12&\\n\\tlrn_param\\x18\\x12 \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18\\x16 \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18\\"" \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18\\x13 \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18\\x15 \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12(\\n\\nrelu_param\\x18\\x1e \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12.\\n\\rsigmoid_param\\x18& \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18\\\' \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12*\\n\\x0bslice_param\\x18\\x1f \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18% \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x32\\n\\x0fthreshold_param\\x18\\x19 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12\\x35\\n\\x11window_data_param\\x18\\x14 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\x12\\x37\\n\\x0ftransform_param\\x18$ \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18* \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12<\\n\\x14\\x64\\x65tection_loss_param\\x18\\xc8\\x01 \\x01(\\x0b\\x32\\x1d.caffe.DetectionLossParameter\\x12<\\n\\x14\\x65val_detection_param\\x18\\xc9\\x01 \\x01(\\x0b\\x32\\x1d.caffe.EvalDetectionParameter\\x12&\\n\\x05layer\\x18\\x01 \\x01(\\x0b\\x32\\x17.caffe.V0LayerParameter\\""\\xd8\\x04\\n\\tLayerType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\n\\n\\x06\\x41\\x42SVAL\\x10#\\x12\\x0c\\n\\x08\\x41\\x43\\x43URACY\\x10\\x01\\x12\\n\\n\\x06\\x41RGMAX\\x10\\x1e\\x12\\x08\\n\\x04\\x42NLL\\x10\\x02\\x12\\n\\n\\x06\\x43ONCAT\\x10\\x03\\x12\\x14\\n\\x10\\x43ONTRASTIVE_LOSS\\x10%\\x12\\x0f\\n\\x0b\\x43ONVOLUTION\\x10\\x04\\x12\\x08\\n\\x04\\x44\\x41TA\\x10\\x05\\x12\\x11\\n\\rDECONVOLUTION\\x10\\\'\\x12\\x0b\\n\\x07\\x44ROPOUT\\x10\\x06\\x12\\x0e\\n\\nDUMMY_DATA\\x10 \\x12\\x12\\n\\x0e\\x45UCLIDEAN_LOSS\\x10\\x07\\x12\\x0b\\n\\x07\\x45LTWISE\\x10\\x19\\x12\\x07\\n\\x03\\x45XP\\x10&\\x12\\x0b\\n\\x07\\x46LATTEN\\x10\\x08\\x12\\r\\n\\tHDF5_DATA\\x10\\t\\x12\\x0f\\n\\x0bHDF5_OUTPUT\\x10\\n\\x12\\x0e\\n\\nHINGE_LOSS\\x10\\x1c\\x12\\n\\n\\x06IM2COL\\x10\\x0b\\x12\\x0e\\n\\nIMAGE_DATA\\x10\\x0c\\x12\\x11\\n\\rINFOGAIN_LOSS\\x10\\r\\x12\\x11\\n\\rINNER_PRODUCT\\x10\\x0e\\x12\\x07\\n\\x03LRN\\x10\\x0f\\x12\\x0f\\n\\x0bMEMORY_DATA\\x10\\x1d\\x12\\x1d\\n\\x19MULTINOMIAL_LOGISTIC_LOSS\\x10\\x10\\x12\\x07\\n\\x03MVN\\x10\\""\\x12\\x0b\\n\\x07POOLING\\x10\\x11\\x12\\t\\n\\x05POWER\\x10\\x1a\\x12\\x08\\n\\x04RELU\\x10\\x12\\x12\\x0b\\n\\x07SIGMOID\\x10\\x13\\x12\\x1e\\n\\x1aSIGMOID_CROSS_ENTROPY_LOSS\\x10\\x1b\\x12\\x0b\\n\\x07SILENCE\\x10$\\x12\\x0b\\n\\x07SOFTMAX\\x10\\x14\\x12\\x10\\n\\x0cSOFTMAX_LOSS\\x10\\x15\\x12\\t\\n\\x05SPLIT\\x10\\x16\\x12\\t\\n\\x05SLICE\\x10!\\x12\\x08\\n\\x04TANH\\x10\\x17\\x12\\x0f\\n\\x0bWINDOW_DATA\\x10\\x18\\x12\\r\\n\\tTHRESHOLD\\x10\\x1f\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\xfd\\x07\\n\\x10V0LayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x12\\n\\nnum_output\\x18\\x03 \\x01(\\r\\x12\\x16\\n\\x08\\x62iasterm\\x18\\x04 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x06 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0e\\n\\x03pad\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x12\\n\\nkernelsize\\x18\\x08 \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\t \\x01(\\r:\\x01\\x31\\x12\\x11\\n\\x06stride\\x18\\n \\x01(\\r:\\x01\\x31\\x12\\x35\\n\\x04pool\\x18\\x0b \\x01(\\x0e\\x32\\"".caffe.V0LayerParameter.PoolMethod:\\x03MAX\\x12\\x1a\\n\\rdropout_ratio\\x18\\x0c \\x01(\\x02:\\x03\\x30.5\\x12\\x15\\n\\nlocal_size\\x18\\r \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x0e \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x0f \\x01(\\x02:\\x04\\x30.75\\x12\\x0c\\n\\x01k\\x18\\x16 \\x01(\\x02:\\x01\\x31\\x12\\x0e\\n\\x06source\\x18\\x10 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x11 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x08meanfile\\x18\\x12 \\x01(\\t\\x12\\x11\\n\\tbatchsize\\x18\\x13 \\x01(\\r\\x12\\x13\\n\\x08\\x63ropsize\\x18\\x14 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x15 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x32 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x33 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x34 \\x03(\\x02\\x12\\x14\\n\\trand_skip\\x18\\x35 \\x01(\\r:\\x01\\x30\\x12\\x1d\\n\\x10\\x64\\x65t_fg_threshold\\x18\\x36 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x10\\x64\\x65t_bg_threshold\\x18\\x37 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x0f\\x64\\x65t_fg_fraction\\x18\\x38 \\x01(\\x02:\\x04\\x30.25\\x12\\x1a\\n\\x0f\\x64\\x65t_context_pad\\x18: \\x01(\\r:\\x01\\x30\\x12\\x1b\\n\\rdet_crop_mode\\x18; \\x01(\\t:\\x04warp\\x12\\x12\\n\\x07new_num\\x18< \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0cnew_channels\\x18= \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nnew_height\\x18> \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18? \\x01(\\x05:\\x01\\x30\\x12\\x1d\\n\\x0eshuffle_images\\x18@ \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nconcat_dim\\x18\\x41 \\x01(\\r:\\x01\\x31\\x12\\x36\\n\\x11hdf5_output_param\\x18\\xe9\\x07 \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""W\\n\\x0ePReLUParameter\\x12&\\n\\x06\\x66iller\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1d\\n\\x0e\\x63hannel_shared\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xa8\\x01\\n\\x0cRPNParameter\\x12\\x13\\n\\x0b\\x66\\x65\\x61t_stride\\x18\\x01 \\x01(\\r\\x12\\x10\\n\\x08\\x62\\x61sesize\\x18\\x02 \\x01(\\r\\x12\\r\\n\\x05scale\\x18\\x03 \\x03(\\r\\x12\\r\\n\\x05ratio\\x18\\x04 \\x03(\\x02\\x12\\x12\\n\\nboxminsize\\x18\\x05 \\x01(\\r\\x12\\x14\\n\\x0cper_nms_topn\\x18\\t \\x01(\\r\\x12\\x15\\n\\rpost_nms_topn\\x18\\x0b \\x01(\\r\\x12\\x12\\n\\nnms_thresh\\x18\\x08 \\x01(\\x02\\""\\xbb\\x01\\n\\x12VideoDataParameter\\x12?\\n\\nvideo_type\\x18\\x01 \\x01(\\x0e\\x32#.caffe.VideoDataParameter.VideoType:\\x06WEBCAM\\x12\\x14\\n\\tdevice_id\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x12\\n\\nvideo_file\\x18\\x03 \\x01(\\t\\x12\\x16\\n\\x0bskip_frames\\x18\\x04 \\x01(\\r:\\x01\\x30\\""\\""\\n\\tVideoType\\x12\\n\\n\\x06WEBCAM\\x10\\x00\\x12\\t\\n\\x05VIDEO\\x10\\x01\\""i\\n\\x13\\x43\\x65nterLossParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12-\\n\\rcenter_filler\\x18\\x02 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05:\\x01\\x31\\""\\xd9\\x02\\n\\x1bMarginInnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x43\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32-.caffe.MarginInnerProductParameter.MarginType:\\x06SINGLE\\x12-\\n\\rweight_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x04 \\x01(\\x05:\\x01\\x31\\x12\\x0f\\n\\x04\\x62\\x61se\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05gamma\\x18\\x06 \\x01(\\x02:\\x01\\x30\\x12\\x10\\n\\x05power\\x18\\x07 \\x01(\\x02:\\x01\\x31\\x12\\x14\\n\\titeration\\x18\\x08 \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nlambda_min\\x18\\t \\x01(\\x02:\\x01\\x30\\""?\\n\\nMarginType\\x12\\n\\n\\x06SINGLE\\x10\\x00\\x12\\n\\n\\x06\\x44OUBLE\\x10\\x01\\x12\\n\\n\\x06TRIPLE\\x10\\x02\\x12\\r\\n\\tQUADRUPLE\\x10\\x03\\""\\x8a\\x01\\n#AdditiveMarginInnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12-\\n\\rweight_filler\\x18\\x02 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x01m\\x18\\x03 \\x01(\\x02:\\x04\\x30.35\\x12\\x0f\\n\\x04\\x61xis\\x18\\x04 \\x01(\\x05:\\x01\\x31\\""\\xad\\x04\\n\\x1e\\x44\\x65\\x66ormableConvolutionParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x0b\\n\\x03pad\\x18\\x03 \\x03(\\r\\x12\\x13\\n\\x0bkernel_size\\x18\\x04 \\x03(\\r\\x12\\x0e\\n\\x06stride\\x18\\x06 \\x03(\\r\\x12\\x10\\n\\x08\\x64ilation\\x18\\x12 \\x03(\\r\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x08kernel_h\\x18\\x0b \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x0c \\x01(\\r\\x12\\x10\\n\\x08stride_h\\x18\\r \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x0e \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\x05 \\x01(\\r:\\x01\\x34\\x12\\x1b\\n\\x10\\x64\\x65\\x66ormable_group\\x18\\x19 \\x01(\\r:\\x01\\x34\\x12-\\n\\rweight_filler\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x45\\n\\x06\\x65ngine\\x18\\x0f \\x01(\\x0e\\x32,.caffe.DeformableConvolutionParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x10 \\x01(\\x05:\\x01\\x31\\x12\\x1e\\n\\x0f\\x66orce_nd_im2col\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""K\\n\\x19LabelSpecificAddParameter\\x12\\x0f\\n\\x04\\x62ias\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x1d\\n\\x0etransform_test\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xed\\x01\\n\\x15\\x43hannelScaleParameter\\x12\\x18\\n\\ndo_forward\\x18\\x01 \\x01(\\x08:\\x04true\\x12!\\n\\x13\\x64o_backward_feature\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x1f\\n\\x11\\x64o_backward_scale\\x18\\x03 \\x01(\\x08:\\x04true\\x12\\x1b\\n\\x0cglobal_scale\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1e\\n\\x10max_global_scale\\x18\\x05 \\x01(\\x02:\\x04\\x31\\x30\\x30\\x30\\x12\\x1b\\n\\x10min_global_scale\\x18\\x06 \\x01(\\x02:\\x01\\x30\\x12\\x1c\\n\\x11init_global_scale\\x18\\x07 \\x01(\\x02:\\x01\\x31\\""C\\n\\x12\\x43osinAddmParameter\\x12\\x0e\\n\\x01m\\x18\\x01 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x0etransform_test\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""A\\n\\x12\\x43osinMulmParameter\\x12\\x0c\\n\\x01m\\x18\\x01 \\x01(\\x02:\\x01\\x34\\x12\\x1d\\n\\x0etransform_test\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""r\\n\\x1b\\x43oupledClusterLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ngroup_size\\x18\\x02 \\x01(\\x05:\\x01\\x33\\x12\\x10\\n\\x05scale\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x17\\n\\x08log_flag\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""R\\n\\x14TripletLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ngroup_size\\x18\\x02 \\x01(\\x05:\\x01\\x33\\x12\\x10\\n\\x05scale\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""\\xe2\\x01\\n\\x17GeneralTripletParameter\\x12\\x13\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x03\\x30.2\\x12\\x1d\\n\\x0f\\x61\\x64\\x64_center_loss\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x1b\\n\\x0chardest_only\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1d\\n\\x0epositive_first\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1f\\n\\x14positive_upper_bound\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x1a\\n\\x0fpositive_weight\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x1a\\n\\x0fnegative_weight\\x18\\x07 \\x01(\\x02:\\x01\\x31\\""W\\n\\x11ROIAlignParameter\\x12\\x13\\n\\x08pooled_h\\x18\\x01 \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x08pooled_w\\x18\\x02 \\x01(\\r:\\x01\\x30\\x12\\x18\\n\\rspatial_scale\\x18\\x03 \\x01(\\x02:\\x01\\x31*\\x1c\\n\\x05Phase\\x12\\t\\n\\x05TRAIN\\x10\\x00\\x12\\x08\\n\\x04TEST\\x10\\x01\')\n)\n\n_PHASE = _descriptor.EnumDescriptor(\n  name=\'Phase\',\n  full_name=\'caffe.Phase\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TRAIN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TEST\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=29109,\n  serialized_end=29137,\n)\n_sym_db.RegisterEnumDescriptor(_PHASE)\n\nPhase = enum_type_wrapper.EnumTypeWrapper(_PHASE)\nTRAIN = 0\nTEST = 1\n\n\n_EMITCONSTRAINT_EMITTYPE = _descriptor.EnumDescriptor(\n  name=\'EmitType\',\n  full_name=\'caffe.EmitConstraint.EmitType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CENTER\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MIN_OVERLAP\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=1162,\n  serialized_end=1201,\n)\n_sym_db.RegisterEnumDescriptor(_EMITCONSTRAINT_EMITTYPE)\n\n_ANNOTATEDDATUM_ANNOTATIONTYPE = _descriptor.EnumDescriptor(\n  name=\'AnnotationType\',\n  full_name=\'caffe.AnnotatedDatum.AnnotationType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'BBOX\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=1645,\n  serialized_end=1671,\n)\n_sym_db.RegisterEnumDescriptor(_ANNOTATEDDATUM_ANNOTATIONTYPE)\n\n_FILLERPARAMETER_VARIANCENORM = _descriptor.EnumDescriptor(\n  name=\'VarianceNorm\',\n  full_name=\'caffe.FillerParameter.VarianceNorm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_IN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_OUT\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVERAGE\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=2058,\n  serialized_end=2110,\n)\n_sym_db.RegisterEnumDescriptor(_FILLERPARAMETER_VARIANCENORM)\n\n_SOLVERPARAMETER_SNAPSHOTFORMAT = _descriptor.EnumDescriptor(\n  name=\'SnapshotFormat\',\n  full_name=\'caffe.SolverParameter.SnapshotFormat\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BINARYPROTO\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=3568,\n  serialized_end=3611,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SNAPSHOTFORMAT)\n\n_SOLVERPARAMETER_SOLVERMODE = _descriptor.EnumDescriptor(\n  name=\'SolverMode\',\n  full_name=\'caffe.SolverParameter.SolverMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CPU\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'GPU\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=3613,\n  serialized_end=3643,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SOLVERMODE)\n\n_SOLVERPARAMETER_SOLVERTYPE = _descriptor.EnumDescriptor(\n  name=\'SolverType\',\n  full_name=\'caffe.SolverParameter.SolverType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SGD\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NESTEROV\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAGRAD\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RMSPROP\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADADELTA\', index=4, number=4,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAM\', index=5, number=5,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=3645,\n  serialized_end=3730,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SOLVERTYPE)\n\n_PARAMSPEC_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.ParamSpec.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=4491,\n  serialized_end=4533,\n)\n_sym_db.RegisterEnumDescriptor(_PARAMSPEC_DIMCHECKMODE)\n\n_BNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.BNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_BNPARAMETER_ENGINE)\n\n_FOCALLOSSPARAMETER_TYPE = _descriptor.EnumDescriptor(\n  name=\'Type\',\n  full_name=\'caffe.FocalLossParameter.Type\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ORIGIN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LINEAR\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=11083,\n  serialized_end=11113,\n)\n_sym_db.RegisterEnumDescriptor(_FOCALLOSSPARAMETER_TYPE)\n\n_RESIZEPARAMETER_RESIZE_MODE = _descriptor.EnumDescriptor(\n  name=\'Resize_mode\',\n  full_name=\'caffe.ResizeParameter.Resize_mode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'WARP\', index=0, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FIT_SMALL_SIZE\', index=1, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FIT_LARGE_SIZE_AND_PAD\', index=2, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=11899,\n  serialized_end=11970,\n)\n_sym_db.RegisterEnumDescriptor(_RESIZEPARAMETER_RESIZE_MODE)\n\n_RESIZEPARAMETER_PAD_MODE = _descriptor.EnumDescriptor(\n  name=\'Pad_mode\',\n  full_name=\'caffe.ResizeParameter.Pad_mode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CONSTANT\', index=0, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MIRRORED\', index=1, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'REPEAT_NEAREST\', index=2, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=11972,\n  serialized_end=12030,\n)\n_sym_db.RegisterEnumDescriptor(_RESIZEPARAMETER_PAD_MODE)\n\n_RESIZEPARAMETER_INTERP_MODE = _descriptor.EnumDescriptor(\n  name=\'Interp_mode\',\n  full_name=\'caffe.ResizeParameter.Interp_mode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'LINEAR\', index=0, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AREA\', index=1, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NEAREST\', index=2, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUBIC\', index=3, number=4,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LANCZOS4\', index=4, number=5,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=12032,\n  serialized_end=12105,\n)\n_sym_db.RegisterEnumDescriptor(_RESIZEPARAMETER_INTERP_MODE)\n\n_LOSSPARAMETER_NORMALIZATIONMODE = _descriptor.EnumDescriptor(\n  name=\'NormalizationMode\',\n  full_name=\'caffe.LossParameter.NormalizationMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FULL\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VALID\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BATCH_SIZE\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=13052,\n  serialized_end=13118,\n)\n_sym_db.RegisterEnumDescriptor(_LOSSPARAMETER_NORMALIZATIONMODE)\n\n_EVALDETECTIONPARAMETER_SCORETYPE = _descriptor.EnumDescriptor(\n  name=\'ScoreType\',\n  full_name=\'caffe.EvalDetectionParameter.ScoreType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'OBJ\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PROB\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MULTIPLY\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=14582,\n  serialized_end=14626,\n)\n_sym_db.RegisterEnumDescriptor(_EVALDETECTIONPARAMETER_SCORETYPE)\n\n_CONVOLUTIONPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ConvolutionParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_CONVOLUTIONPARAMETER_ENGINE)\n\n_DATAPARAMETER_DB = _descriptor.EnumDescriptor(\n  name=\'DB\',\n  full_name=\'caffe.DataParameter.DB\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVELDB\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LMDB\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=15469,\n  serialized_end=15496,\n)\n_sym_db.RegisterEnumDescriptor(_DATAPARAMETER_DB)\n\n_ELTWISEPARAMETER_ELTWISEOP = _descriptor.EnumDescriptor(\n  name=\'EltwiseOp\',\n  full_name=\'caffe.EltwiseParameter.EltwiseOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'PROD\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=16856,\n  serialized_end=16895,\n)\n_sym_db.RegisterEnumDescriptor(_ELTWISEPARAMETER_ELTWISEOP)\n\n_HINGELOSSPARAMETER_NORM = _descriptor.EnumDescriptor(\n  name=\'Norm\',\n  full_name=\'caffe.HingeLossParameter.Norm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'L1\', index=0, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'L2\', index=1, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=17430,\n  serialized_end=17452,\n)\n_sym_db.RegisterEnumDescriptor(_HINGELOSSPARAMETER_NORM)\n\n_LRNPARAMETER_NORMREGION = _descriptor.EnumDescriptor(\n  name=\'NormRegion\',\n  full_name=\'caffe.LRNParameter.NormRegion\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ACROSS_CHANNELS\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WITHIN_CHANNEL\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=18345,\n  serialized_end=18398,\n)\n_sym_db.RegisterEnumDescriptor(_LRNPARAMETER_NORMREGION)\n\n_LRNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.LRNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_LRNPARAMETER_ENGINE)\n\n_MULTIBOXLOSSPARAMETER_LOCLOSSTYPE = _descriptor.EnumDescriptor(\n  name=\'LocLossType\',\n  full_name=\'caffe.MultiBoxLossParameter.LocLossType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'L2\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SMOOTH_L1\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=19479,\n  serialized_end=19515,\n)\n_sym_db.RegisterEnumDescriptor(_MULTIBOXLOSSPARAMETER_LOCLOSSTYPE)\n\n_MULTIBOXLOSSPARAMETER_CONFLOSSTYPE = _descriptor.EnumDescriptor(\n  name=\'ConfLossType\',\n  full_name=\'caffe.MultiBoxLossParameter.ConfLossType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LOGISTIC\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=19517,\n  serialized_end=19558,\n)\n_sym_db.RegisterEnumDescriptor(_MULTIBOXLOSSPARAMETER_CONFLOSSTYPE)\n\n_MULTIBOXLOSSPARAMETER_MATCHTYPE = _descriptor.EnumDescriptor(\n  name=\'MatchType\',\n  full_name=\'caffe.MultiBoxLossParameter.MatchType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'BIPARTITE\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PER_PREDICTION\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=19560,\n  serialized_end=19606,\n)\n_sym_db.RegisterEnumDescriptor(_MULTIBOXLOSSPARAMETER_MATCHTYPE)\n\n_MULTIBOXLOSSPARAMETER_MININGTYPE = _descriptor.EnumDescriptor(\n  name=\'MiningType\',\n  full_name=\'caffe.MultiBoxLossParameter.MiningType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX_NEGATIVE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HARD_EXAMPLE\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=19608,\n  serialized_end=19666,\n)\n_sym_db.RegisterEnumDescriptor(_MULTIBOXLOSSPARAMETER_MININGTYPE)\n\n_POOLINGPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.PoolingParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=20213,\n  serialized_end=20259,\n)\n_sym_db.RegisterEnumDescriptor(_POOLINGPARAMETER_POOLMETHOD)\n\n_POOLINGPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.PoolingParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_POOLINGPARAMETER_ENGINE)\n\n_PRIORBOXPARAMETER_CODETYPE = _descriptor.EnumDescriptor(\n  name=\'CodeType\',\n  full_name=\'caffe.PriorBoxParameter.CodeType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CORNER\', index=0, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CENTER_SIZE\', index=1, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CORNER_SIZE\', index=2, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=20632,\n  serialized_end=20688,\n)\n_sym_db.RegisterEnumDescriptor(_PRIORBOXPARAMETER_CODETYPE)\n\n_REDUCTIONPARAMETER_REDUCTIONOP = _descriptor.EnumDescriptor(\n  name=\'ReductionOp\',\n  full_name=\'caffe.ReductionParameter.ReductionOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=0, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ASUM\', index=1, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUMSQ\', index=2, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEAN\', index=3, number=4,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=21111,\n  serialized_end=21164,\n)\n_sym_db.RegisterEnumDescriptor(_REDUCTIONPARAMETER_REDUCTIONOP)\n\n_RELUPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ReLUParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_RELUPARAMETER_ENGINE)\n\n_SIGMOIDPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SigmoidParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_SIGMOIDPARAMETER_ENGINE)\n\n_SOFTMAXPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SoftmaxParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_SOFTMAXPARAMETER_ENGINE)\n\n_TANHPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.TanHParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_TANHPARAMETER_ENGINE)\n\n_SPPPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.SPPParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=20213,\n  serialized_end=20259,\n)\n_sym_db.RegisterEnumDescriptor(_SPPPARAMETER_POOLMETHOD)\n\n_SPPPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SPPParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_SPPPARAMETER_ENGINE)\n\n_V1LAYERPARAMETER_LAYERTYPE = _descriptor.EnumDescriptor(\n  name=\'LayerType\',\n  full_name=\'caffe.V1LayerParameter.LayerType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ABSVAL\', index=1, number=35,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ACCURACY\', index=2, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ARGMAX\', index=3, number=30,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BNLL\', index=4, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONCAT\', index=5, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONTRASTIVE_LOSS\', index=6, number=37,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONVOLUTION\', index=7, number=4,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA\', index=8, number=5,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DECONVOLUTION\', index=9, number=39,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DROPOUT\', index=10, number=6,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DUMMY_DATA\', index=11, number=32,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EUCLIDEAN_LOSS\', index=12, number=7,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ELTWISE\', index=13, number=25,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EXP\', index=14, number=38,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FLATTEN\', index=15, number=8,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_DATA\', index=16, number=9,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_OUTPUT\', index=17, number=10,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HINGE_LOSS\', index=18, number=28,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IM2COL\', index=19, number=11,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE_DATA\', index=20, number=12,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INFOGAIN_LOSS\', index=21, number=13,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INNER_PRODUCT\', index=22, number=14,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LRN\', index=23, number=15,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEMORY_DATA\', index=24, number=29,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MULTINOMIAL_LOGISTIC_LOSS\', index=25, number=16,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MVN\', index=26, number=34,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POOLING\', index=27, number=17,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POWER\', index=28, number=26,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RELU\', index=29, number=18,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID\', index=30, number=19,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID_CROSS_ENTROPY_LOSS\', index=31, number=27,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SILENCE\', index=32, number=36,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX\', index=33, number=20,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX_LOSS\', index=34, number=21,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SPLIT\', index=35, number=22,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SLICE\', index=36, number=33,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TANH\', index=37, number=23,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WINDOW_DATA\', index=38, number=24,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'THRESHOLD\', index=39, number=31,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=24862,\n  serialized_end=25462,\n)\n_sym_db.RegisterEnumDescriptor(_V1LAYERPARAMETER_LAYERTYPE)\n\n_V1LAYERPARAMETER_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.V1LayerParameter.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=4491,\n  serialized_end=4533,\n)\n_sym_db.RegisterEnumDescriptor(_V1LAYERPARAMETER_DIMCHECKMODE)\n\n_V0LAYERPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.V0LayerParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=20213,\n  serialized_end=20259,\n)\n_sym_db.RegisterEnumDescriptor(_V0LAYERPARAMETER_POOLMETHOD)\n\n_VIDEODATAPARAMETER_VIDEOTYPE = _descriptor.EnumDescriptor(\n  name=\'VideoType\',\n  full_name=\'caffe.VideoDataParameter.VideoType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'WEBCAM\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VIDEO\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=26946,\n  serialized_end=26980,\n)\n_sym_db.RegisterEnumDescriptor(_VIDEODATAPARAMETER_VIDEOTYPE)\n\n_MARGININNERPRODUCTPARAMETER_MARGINTYPE = _descriptor.EnumDescriptor(\n  name=\'MarginType\',\n  full_name=\'caffe.MarginInnerProductParameter.MarginType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SINGLE\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DOUBLE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TRIPLE\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'QUADRUPLE\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=27372,\n  serialized_end=27435,\n)\n_sym_db.RegisterEnumDescriptor(_MARGININNERPRODUCTPARAMETER_MARGINTYPE)\n\n_DEFORMABLECONVOLUTIONPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.DeformableConvolutionParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=10905,\n  serialized_end=10948,\n)\n_sym_db.RegisterEnumDescriptor(_DEFORMABLECONVOLUTIONPARAMETER_ENGINE)\n\n\n_BLOBSHAPE = _descriptor.Descriptor(\n  name=\'BlobShape\',\n  full_name=\'caffe.BlobShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'caffe.BlobShape.dim\', index=0,\n      number=1, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22,\n  serialized_end=50,\n)\n\n\n_BLOBPROTO = _descriptor.Descriptor(\n  name=\'BlobProto\',\n  full_name=\'caffe.BlobProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.BlobProto.shape\', index=0,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.BlobProto.data\', index=1,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'diff\', full_name=\'caffe.BlobProto.diff\', index=2,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'double_data\', full_name=\'caffe.BlobProto.double_data\', index=3,\n      number=8, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'double_diff\', full_name=\'caffe.BlobProto.double_diff\', index=4,\n      number=9, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.BlobProto.num\', index=5,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.BlobProto.channels\', index=6,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.BlobProto.height\', index=7,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.BlobProto.width\', index=8,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=53,\n  serialized_end=257,\n)\n\n\n_BLOBPROTOVECTOR = _descriptor.Descriptor(\n  name=\'BlobProtoVector\',\n  full_name=\'caffe.BlobProtoVector\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.BlobProtoVector.blobs\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=259,\n  serialized_end=309,\n)\n\n\n_DATUM = _descriptor.Descriptor(\n  name=\'Datum\',\n  full_name=\'caffe.Datum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.Datum.channels\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.Datum.height\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.Datum.width\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.Datum.data\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.Datum.label\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'float_data\', full_name=\'caffe.Datum.float_data\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'encoded\', full_name=\'caffe.Datum.encoded\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'labels\', full_name=\'caffe.Datum.labels\', index=7,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=312,\n  serialized_end=457,\n)\n\n\n_LABELMAPITEM = _descriptor.Descriptor(\n  name=\'LabelMapItem\',\n  full_name=\'caffe.LabelMapItem\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.LabelMapItem.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.LabelMapItem.label\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'display_name\', full_name=\'caffe.LabelMapItem.display_name\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=459,\n  serialized_end=524,\n)\n\n\n_LABELMAP = _descriptor.Descriptor(\n  name=\'LabelMap\',\n  full_name=\'caffe.LabelMap\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'item\', full_name=\'caffe.LabelMap.item\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=526,\n  serialized_end=571,\n)\n\n\n_SAMPLER = _descriptor.Descriptor(\n  name=\'Sampler\',\n  full_name=\'caffe.Sampler\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'min_scale\', full_name=\'caffe.Sampler.min_scale\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_scale\', full_name=\'caffe.Sampler.max_scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min_aspect_ratio\', full_name=\'caffe.Sampler.min_aspect_ratio\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_aspect_ratio\', full_name=\'caffe.Sampler.max_aspect_ratio\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=573,\n  serialized_end=684,\n)\n\n\n_SAMPLECONSTRAINT = _descriptor.Descriptor(\n  name=\'SampleConstraint\',\n  full_name=\'caffe.SampleConstraint\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'min_jaccard_overlap\', full_name=\'caffe.SampleConstraint.min_jaccard_overlap\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_jaccard_overlap\', full_name=\'caffe.SampleConstraint.max_jaccard_overlap\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min_sample_coverage\', full_name=\'caffe.SampleConstraint.min_sample_coverage\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_sample_coverage\', full_name=\'caffe.SampleConstraint.max_sample_coverage\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min_object_coverage\', full_name=\'caffe.SampleConstraint.min_object_coverage\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_object_coverage\', full_name=\'caffe.SampleConstraint.max_object_coverage\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=687,\n  serialized_end=879,\n)\n\n\n_BATCHSAMPLER = _descriptor.Descriptor(\n  name=\'BatchSampler\',\n  full_name=\'caffe.BatchSampler\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'use_original_image\', full_name=\'caffe.BatchSampler.use_original_image\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sampler\', full_name=\'caffe.BatchSampler.sampler\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sample_constraint\', full_name=\'caffe.BatchSampler.sample_constraint\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_sample\', full_name=\'caffe.BatchSampler.max_sample\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_trials\', full_name=\'caffe.BatchSampler.max_trials\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=100,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=882,\n  serialized_end=1060,\n)\n\n\n_EMITCONSTRAINT = _descriptor.Descriptor(\n  name=\'EmitConstraint\',\n  full_name=\'caffe.EmitConstraint\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'emit_type\', full_name=\'caffe.EmitConstraint.emit_type\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'emit_overlap\', full_name=\'caffe.EmitConstraint.emit_overlap\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _EMITCONSTRAINT_EMITTYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1063,\n  serialized_end=1201,\n)\n\n\n_NORMALIZEDBBOX = _descriptor.Descriptor(\n  name=\'NormalizedBBox\',\n  full_name=\'caffe.NormalizedBBox\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'xmin\', full_name=\'caffe.NormalizedBBox.xmin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ymin\', full_name=\'caffe.NormalizedBBox.ymin\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'xmax\', full_name=\'caffe.NormalizedBBox.xmax\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ymax\', full_name=\'caffe.NormalizedBBox.ymax\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.NormalizedBBox.label\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'difficult\', full_name=\'caffe.NormalizedBBox.difficult\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'score\', full_name=\'caffe.NormalizedBBox.score\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'size\', full_name=\'caffe.NormalizedBBox.size\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1204,\n  serialized_end=1339,\n)\n\n\n_ANNOTATION = _descriptor.Descriptor(\n  name=\'Annotation\',\n  full_name=\'caffe.Annotation\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'instance_id\', full_name=\'caffe.Annotation.instance_id\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bbox\', full_name=\'caffe.Annotation.bbox\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1341,\n  serialized_end=1414,\n)\n\n\n_ANNOTATIONGROUP = _descriptor.Descriptor(\n  name=\'AnnotationGroup\',\n  full_name=\'caffe.AnnotationGroup\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'group_label\', full_name=\'caffe.AnnotationGroup.group_label\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'annotation\', full_name=\'caffe.AnnotationGroup.annotation\', index=1,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1416,\n  serialized_end=1493,\n)\n\n\n_ANNOTATEDDATUM = _descriptor.Descriptor(\n  name=\'AnnotatedDatum\',\n  full_name=\'caffe.AnnotatedDatum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'datum\', full_name=\'caffe.AnnotatedDatum.datum\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.AnnotatedDatum.type\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'annotation_group\', full_name=\'caffe.AnnotatedDatum.annotation_group\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _ANNOTATEDDATUM_ANNOTATIONTYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1496,\n  serialized_end=1671,\n)\n\n\n_MTCNNBBOX = _descriptor.Descriptor(\n  name=\'MTCNNBBox\',\n  full_name=\'caffe.MTCNNBBox\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'xmin\', full_name=\'caffe.MTCNNBBox.xmin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ymin\', full_name=\'caffe.MTCNNBBox.ymin\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'xmax\', full_name=\'caffe.MTCNNBBox.xmax\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ymax\', full_name=\'caffe.MTCNNBBox.ymax\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1673,\n  serialized_end=1740,\n)\n\n\n_MTCNNDATUM = _descriptor.Descriptor(\n  name=\'MTCNNDatum\',\n  full_name=\'caffe.MTCNNDatum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'datum\', full_name=\'caffe.MTCNNDatum.datum\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'roi\', full_name=\'caffe.MTCNNDatum.roi\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pts\', full_name=\'caffe.MTCNNDatum.pts\', index=2,\n      number=3, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1742,\n  serialized_end=1827,\n)\n\n\n_FILLERPARAMETER = _descriptor.Descriptor(\n  name=\'FillerParameter\',\n  full_name=\'caffe.FillerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.FillerParameter.type\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""constant"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'caffe.FillerParameter.value\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min\', full_name=\'caffe.FillerParameter.min\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max\', full_name=\'caffe.FillerParameter.max\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mean\', full_name=\'caffe.FillerParameter.mean\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'std\', full_name=\'caffe.FillerParameter.std\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sparse\', full_name=\'caffe.FillerParameter.sparse\', index=6,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'variance_norm\', full_name=\'caffe.FillerParameter.variance_norm\', index=7,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'file\', full_name=\'caffe.FillerParameter.file\', index=8,\n      number=9, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _FILLERPARAMETER_VARIANCENORM,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1830,\n  serialized_end=2110,\n)\n\n\n_NETPARAMETER = _descriptor.Descriptor(\n  name=\'NetParameter\',\n  full_name=\'caffe.NetParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.NetParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'caffe.NetParameter.input\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'input_shape\', full_name=\'caffe.NetParameter.input_shape\', index=2,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.NetParameter.input_dim\', index=3,\n      number=4, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'force_backward\', full_name=\'caffe.NetParameter.force_backward\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'caffe.NetParameter.state\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.NetParameter.debug_info\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.NetParameter.layer\', index=7,\n      number=100, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'layers\', full_name=\'caffe.NetParameter.layers\', index=8,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2113,\n  serialized_end=2383,\n)\n\n\n_SOLVERPARAMETER = _descriptor.Descriptor(\n  name=\'SolverParameter\',\n  full_name=\'caffe.SolverParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'net\', full_name=\'caffe.SolverParameter.net\', index=0,\n      number=24, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'net_param\', full_name=\'caffe.SolverParameter.net_param\', index=1,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'train_net\', full_name=\'caffe.SolverParameter.train_net\', index=2,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'test_net\', full_name=\'caffe.SolverParameter.test_net\', index=3,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'train_net_param\', full_name=\'caffe.SolverParameter.train_net_param\', index=4,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'test_net_param\', full_name=\'caffe.SolverParameter.test_net_param\', index=5,\n      number=22, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'train_state\', full_name=\'caffe.SolverParameter.train_state\', index=6,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'test_state\', full_name=\'caffe.SolverParameter.test_state\', index=7,\n      number=27, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'test_iter\', full_name=\'caffe.SolverParameter.test_iter\', index=8,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'test_interval\', full_name=\'caffe.SolverParameter.test_interval\', index=9,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'test_compute_loss\', full_name=\'caffe.SolverParameter.test_compute_loss\', index=10,\n      number=19, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'test_initialization\', full_name=\'caffe.SolverParameter.test_initialization\', index=11,\n      number=32, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'base_lr\', full_name=\'caffe.SolverParameter.base_lr\', index=12,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'display\', full_name=\'caffe.SolverParameter.display\', index=13,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'average_loss\', full_name=\'caffe.SolverParameter.average_loss\', index=14,\n      number=33, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_iter\', full_name=\'caffe.SolverParameter.max_iter\', index=15,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'iter_size\', full_name=\'caffe.SolverParameter.iter_size\', index=16,\n      number=36, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'lr_policy\', full_name=\'caffe.SolverParameter.lr_policy\', index=17,\n      number=8, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.SolverParameter.gamma\', index=18,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.SolverParameter.power\', index=19,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.SolverParameter.momentum\', index=20,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.SolverParameter.weight_decay\', index=21,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'regularization_type\', full_name=\'caffe.SolverParameter.regularization_type\', index=22,\n      number=29, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""L2"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stepsize\', full_name=\'caffe.SolverParameter.stepsize\', index=23,\n      number=13, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stepvalue\', full_name=\'caffe.SolverParameter.stepvalue\', index=24,\n      number=34, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stagelr\', full_name=\'caffe.SolverParameter.stagelr\', index=25,\n      number=50, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stageiter\', full_name=\'caffe.SolverParameter.stageiter\', index=26,\n      number=51, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'clip_gradients\', full_name=\'caffe.SolverParameter.clip_gradients\', index=27,\n      number=35, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot\', full_name=\'caffe.SolverParameter.snapshot\', index=28,\n      number=14, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_prefix\', full_name=\'caffe.SolverParameter.snapshot_prefix\', index=29,\n      number=15, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_diff\', full_name=\'caffe.SolverParameter.snapshot_diff\', index=30,\n      number=16, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_format\', full_name=\'caffe.SolverParameter.snapshot_format\', index=31,\n      number=37, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'solver_mode\', full_name=\'caffe.SolverParameter.solver_mode\', index=32,\n      number=17, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'device_id\', full_name=\'caffe.SolverParameter.device_id\', index=33,\n      number=18, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'random_seed\', full_name=\'caffe.SolverParameter.random_seed\', index=34,\n      number=20, type=3, cpp_type=2, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.SolverParameter.type\', index=35,\n      number=40, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""SGD"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'delta\', full_name=\'caffe.SolverParameter.delta\', index=36,\n      number=31, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-08),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'momentum2\', full_name=\'caffe.SolverParameter.momentum2\', index=37,\n      number=39, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.999),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'rms_decay\', full_name=\'caffe.SolverParameter.rms_decay\', index=38,\n      number=38, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.SolverParameter.debug_info\', index=39,\n      number=23, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_after_train\', full_name=\'caffe.SolverParameter.snapshot_after_train\', index=40,\n      number=28, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'solver_type\', full_name=\'caffe.SolverParameter.solver_type\', index=41,\n      number=30, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOLVERPARAMETER_SNAPSHOTFORMAT,\n    _SOLVERPARAMETER_SOLVERMODE,\n    _SOLVERPARAMETER_SOLVERTYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2386,\n  serialized_end=3730,\n)\n\n\n_SOLVERSTATE = _descriptor.Descriptor(\n  name=\'SolverState\',\n  full_name=\'caffe.SolverState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'iter\', full_name=\'caffe.SolverState.iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'learned_net\', full_name=\'caffe.SolverState.learned_net\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'history\', full_name=\'caffe.SolverState.history\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'current_step\', full_name=\'caffe.SolverState.current_step\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=3732,\n  serialized_end=3840,\n)\n\n\n_NETSTATE = _descriptor.Descriptor(\n  name=\'NetState\',\n  full_name=\'caffe.NetState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetState.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'level\', full_name=\'caffe.NetState.level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetState.stage\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=3842,\n  serialized_end=3920,\n)\n\n\n_NETSTATERULE = _descriptor.Descriptor(\n  name=\'NetStateRule\',\n  full_name=\'caffe.NetStateRule\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetStateRule.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min_level\', full_name=\'caffe.NetStateRule.min_level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_level\', full_name=\'caffe.NetStateRule.max_level\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetStateRule.stage\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'not_stage\', full_name=\'caffe.NetStateRule.not_stage\', index=4,\n      number=5, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=3922,\n  serialized_end=4037,\n)\n\n\n_SPATIALTRANSFORMERPARAMETER = _descriptor.Descriptor(\n  name=\'SpatialTransformerParameter\',\n  full_name=\'caffe.SpatialTransformerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform_type\', full_name=\'caffe.SpatialTransformerParameter.transform_type\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""affine"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sampler_type\', full_name=\'caffe.SpatialTransformerParameter.sampler_type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""bilinear"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'output_H\', full_name=\'caffe.SpatialTransformerParameter.output_H\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'output_W\', full_name=\'caffe.SpatialTransformerParameter.output_W\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'to_compute_dU\', full_name=\'caffe.SpatialTransformerParameter.to_compute_dU\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'theta_1_1\', full_name=\'caffe.SpatialTransformerParameter.theta_1_1\', index=5,\n      number=6, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'theta_1_2\', full_name=\'caffe.SpatialTransformerParameter.theta_1_2\', index=6,\n      number=7, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'theta_1_3\', full_name=\'caffe.SpatialTransformerParameter.theta_1_3\', index=7,\n      number=8, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'theta_2_1\', full_name=\'caffe.SpatialTransformerParameter.theta_2_1\', index=8,\n      number=9, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'theta_2_2\', full_name=\'caffe.SpatialTransformerParameter.theta_2_2\', index=9,\n      number=10, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'theta_2_3\', full_name=\'caffe.SpatialTransformerParameter.theta_2_3\', index=10,\n      number=11, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=4040,\n  serialized_end=4312,\n)\n\n\n_STLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'STLossParameter\',\n  full_name=\'caffe.STLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'output_H\', full_name=\'caffe.STLossParameter.output_H\', index=0,\n      number=1, type=5, cpp_type=1, label=2,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'output_W\', full_name=\'caffe.STLossParameter.output_W\', index=1,\n      number=2, type=5, cpp_type=1, label=2,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=4314,\n  serialized_end=4367,\n)\n\n\n_PARAMSPEC = _descriptor.Descriptor(\n  name=\'ParamSpec\',\n  full_name=\'caffe.ParamSpec\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.ParamSpec.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'share_mode\', full_name=\'caffe.ParamSpec.share_mode\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'lr_mult\', full_name=\'caffe.ParamSpec.lr_mult\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'decay_mult\', full_name=\'caffe.ParamSpec.decay_mult\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _PARAMSPEC_DIMCHECKMODE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=4370,\n  serialized_end=4533,\n)\n\n\n_LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'LayerParameter\',\n  full_name=\'caffe.LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.LayerParameter.bottom\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.LayerParameter.top\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.LayerParameter.phase\', index=4,\n      number=10, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.LayerParameter.loss_weight\', index=5,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.LayerParameter.param\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.LayerParameter.blobs\', index=7,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'propagate_down\', full_name=\'caffe.LayerParameter.propagate_down\', index=8,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.LayerParameter.include\', index=9,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.LayerParameter.exclude\', index=10,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.LayerParameter.transform_param\', index=11,\n      number=100, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.LayerParameter.loss_param\', index=12,\n      number=101, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'detection_loss_param\', full_name=\'caffe.LayerParameter.detection_loss_param\', index=13,\n      number=200, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eval_detection_param\', full_name=\'caffe.LayerParameter.eval_detection_param\', index=14,\n      number=201, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'region_loss_param\', full_name=\'caffe.LayerParameter.region_loss_param\', index=15,\n      number=202, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'reorg_param\', full_name=\'caffe.LayerParameter.reorg_param\', index=16,\n      number=203, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.LayerParameter.accuracy_param\', index=17,\n      number=102, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.LayerParameter.argmax_param\', index=18,\n      number=103, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'batch_norm_param\', full_name=\'caffe.LayerParameter.batch_norm_param\', index=19,\n      number=139, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_param\', full_name=\'caffe.LayerParameter.bias_param\', index=20,\n      number=141, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.LayerParameter.concat_param\', index=21,\n      number=104, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.LayerParameter.contrastive_loss_param\', index=22,\n      number=105, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.LayerParameter.convolution_param\', index=23,\n      number=106, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.LayerParameter.data_param\', index=24,\n      number=107, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.LayerParameter.dropout_param\', index=25,\n      number=108, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.LayerParameter.dummy_data_param\', index=26,\n      number=109, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.LayerParameter.eltwise_param\', index=27,\n      number=110, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'elu_param\', full_name=\'caffe.LayerParameter.elu_param\', index=28,\n      number=140, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'embed_param\', full_name=\'caffe.LayerParameter.embed_param\', index=29,\n      number=137, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.LayerParameter.exp_param\', index=30,\n      number=111, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'flatten_param\', full_name=\'caffe.LayerParameter.flatten_param\', index=31,\n      number=135, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.LayerParameter.hdf5_data_param\', index=32,\n      number=112, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.LayerParameter.hdf5_output_param\', index=33,\n      number=113, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.LayerParameter.hinge_loss_param\', index=34,\n      number=114, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.LayerParameter.image_data_param\', index=35,\n      number=115, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.LayerParameter.infogain_loss_param\', index=36,\n      number=116, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.LayerParameter.inner_product_param\', index=37,\n      number=117, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'input_param\', full_name=\'caffe.LayerParameter.input_param\', index=38,\n      number=143, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'log_param\', full_name=\'caffe.LayerParameter.log_param\', index=39,\n      number=134, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.LayerParameter.lrn_param\', index=40,\n      number=118, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.LayerParameter.memory_data_param\', index=41,\n      number=119, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.LayerParameter.mvn_param\', index=42,\n      number=120, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.LayerParameter.pooling_param\', index=43,\n      number=121, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.LayerParameter.power_param\', index=44,\n      number=122, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'prelu_param\', full_name=\'caffe.LayerParameter.prelu_param\', index=45,\n      number=131, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'python_param\', full_name=\'caffe.LayerParameter.python_param\', index=46,\n      number=130, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'recurrent_param\', full_name=\'caffe.LayerParameter.recurrent_param\', index=47,\n      number=146, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'reduction_param\', full_name=\'caffe.LayerParameter.reduction_param\', index=48,\n      number=136, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.LayerParameter.relu_param\', index=49,\n      number=123, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'reshape_param\', full_name=\'caffe.LayerParameter.reshape_param\', index=50,\n      number=133, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'roi_pooling_param\', full_name=\'caffe.LayerParameter.roi_pooling_param\', index=51,\n      number=8266711, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale_param\', full_name=\'caffe.LayerParameter.scale_param\', index=52,\n      number=142, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.LayerParameter.sigmoid_param\', index=53,\n      number=124, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'smooth_l1_loss_param\', full_name=\'caffe.LayerParameter.smooth_l1_loss_param\', index=54,\n      number=8266712, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.LayerParameter.softmax_param\', index=55,\n      number=125, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'spp_param\', full_name=\'caffe.LayerParameter.spp_param\', index=56,\n      number=132, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.LayerParameter.slice_param\', index=57,\n      number=126, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.LayerParameter.tanh_param\', index=58,\n      number=127, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.LayerParameter.threshold_param\', index=59,\n      number=128, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tile_param\', full_name=\'caffe.LayerParameter.tile_param\', index=60,\n      number=138, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.LayerParameter.window_data_param\', index=61,\n      number=129, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'st_param\', full_name=\'caffe.LayerParameter.st_param\', index=62,\n      number=148, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'st_loss_param\', full_name=\'caffe.LayerParameter.st_loss_param\', index=63,\n      number=145, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'rpn_param\', full_name=\'caffe.LayerParameter.rpn_param\', index=64,\n      number=150, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'focal_loss_param\', full_name=\'caffe.LayerParameter.focal_loss_param\', index=65,\n      number=155, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'asdn_data_param\', full_name=\'caffe.LayerParameter.asdn_data_param\', index=66,\n      number=159, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bn_param\', full_name=\'caffe.LayerParameter.bn_param\', index=67,\n      number=160, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mtcnn_data_param\', full_name=\'caffe.LayerParameter.mtcnn_data_param\', index=68,\n      number=161, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'interp_param\', full_name=\'caffe.LayerParameter.interp_param\', index=69,\n      number=162, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'psroi_pooling_param\', full_name=\'caffe.LayerParameter.psroi_pooling_param\', index=70,\n      number=163, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'annotated_data_param\', full_name=\'caffe.LayerParameter.annotated_data_param\', index=71,\n      number=164, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'prior_box_param\', full_name=\'caffe.LayerParameter.prior_box_param\', index=72,\n      number=165, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'crop_param\', full_name=\'caffe.LayerParameter.crop_param\', index=73,\n      number=167, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'detection_evaluate_param\', full_name=\'caffe.LayerParameter.detection_evaluate_param\', index=74,\n      number=168, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'detection_output_param\', full_name=\'caffe.LayerParameter.detection_output_param\', index=75,\n      number=169, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'multibox_loss_param\', full_name=\'caffe.LayerParameter.multibox_loss_param\', index=76,\n      number=171, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'permute_param\', full_name=\'caffe.LayerParameter.permute_param\', index=77,\n      number=172, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'video_data_param\', full_name=\'caffe.LayerParameter.video_data_param\', index=78,\n      number=173, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'margin_inner_product_param\', full_name=\'caffe.LayerParameter.margin_inner_product_param\', index=79,\n      number=174, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'center_loss_param\', full_name=\'caffe.LayerParameter.center_loss_param\', index=80,\n      number=175, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'deformable_convolution_param\', full_name=\'caffe.LayerParameter.deformable_convolution_param\', index=81,\n      number=176, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'label_specific_add_param\', full_name=\'caffe.LayerParameter.label_specific_add_param\', index=82,\n      number=177, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'additive_margin_inner_product_param\', full_name=\'caffe.LayerParameter.additive_margin_inner_product_param\', index=83,\n      number=178, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'cosin_add_m_param\', full_name=\'caffe.LayerParameter.cosin_add_m_param\', index=84,\n      number=179, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'cosin_mul_m_param\', full_name=\'caffe.LayerParameter.cosin_mul_m_param\', index=85,\n      number=180, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'channel_scale_param\', full_name=\'caffe.LayerParameter.channel_scale_param\', index=86,\n      number=181, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'flip_param\', full_name=\'caffe.LayerParameter.flip_param\', index=87,\n      number=182, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'triplet_loss_param\', full_name=\'caffe.LayerParameter.triplet_loss_param\', index=88,\n      number=183, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'coupled_cluster_loss_param\', full_name=\'caffe.LayerParameter.coupled_cluster_loss_param\', index=89,\n      number=184, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'general_triplet_loss_param\', full_name=\'caffe.LayerParameter.general_triplet_loss_param\', index=90,\n      number=185, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'roi_align_param\', full_name=\'caffe.LayerParameter.roi_align_param\', index=91,\n      number=186, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'upsample_param\', full_name=\'caffe.LayerParameter.upsample_param\', index=92,\n      number=100003, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'matmul_param\', full_name=\'caffe.LayerParameter.matmul_param\', index=93,\n      number=100005, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pass_through_param\', full_name=\'caffe.LayerParameter.pass_through_param\', index=94,\n      number=100004, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'norm_param\', full_name=\'caffe.LayerParameter.norm_param\', index=95,\n      number=100001, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=4536,\n  serialized_end=9293,\n)\n\n\n_UPSAMPLEPARAMETER = _descriptor.Descriptor(\n  name=\'UpsampleParameter\',\n  full_name=\'caffe.UpsampleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.UpsampleParameter.scale\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale_h\', full_name=\'caffe.UpsampleParameter.scale_h\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale_w\', full_name=\'caffe.UpsampleParameter.scale_w\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_out_h\', full_name=\'caffe.UpsampleParameter.pad_out_h\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_out_w\', full_name=\'caffe.UpsampleParameter.pad_out_w\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'upsample_h\', full_name=\'caffe.UpsampleParameter.upsample_h\', index=5,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'upsample_w\', full_name=\'caffe.UpsampleParameter.upsample_w\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9296,\n  serialized_end=9459,\n)\n\n\n_MATMULPARAMETER = _descriptor.Descriptor(\n  name=\'MatMulParameter\',\n  full_name=\'caffe.MatMulParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim_1\', full_name=\'caffe.MatMulParameter.dim_1\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dim_2\', full_name=\'caffe.MatMulParameter.dim_2\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dim_3\', full_name=\'caffe.MatMulParameter.dim_3\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9461,\n  serialized_end=9523,\n)\n\n\n_PASSTHROUGHPARAMETER = _descriptor.Descriptor(\n  name=\'PassThroughParameter\',\n  full_name=\'caffe.PassThroughParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.PassThroughParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'block_height\', full_name=\'caffe.PassThroughParameter.block_height\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'block_width\', full_name=\'caffe.PassThroughParameter.block_width\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9525,\n  serialized_end=9619,\n)\n\n\n_NORMALIZEPARAMETER = _descriptor.Descriptor(\n  name=\'NormalizeParameter\',\n  full_name=\'caffe.NormalizeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'across_spatial\', full_name=\'caffe.NormalizeParameter.across_spatial\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale_filler\', full_name=\'caffe.NormalizeParameter.scale_filler\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'channel_shared\', full_name=\'caffe.NormalizeParameter.channel_shared\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.NormalizeParameter.eps\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-10),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sqrt_a\', full_name=\'caffe.NormalizeParameter.sqrt_a\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9622,\n  serialized_end=9787,\n)\n\n\n_ANNOTATEDDATAPARAMETER = _descriptor.Descriptor(\n  name=\'AnnotatedDataParameter\',\n  full_name=\'caffe.AnnotatedDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'batch_sampler\', full_name=\'caffe.AnnotatedDataParameter.batch_sampler\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'label_map_file\', full_name=\'caffe.AnnotatedDataParameter.label_map_file\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'anno_type\', full_name=\'caffe.AnnotatedDataParameter.anno_type\', index=2,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9790,\n  serialized_end=9939,\n)\n\n\n_ASDNDATAPARAMETER = _descriptor.Descriptor(\n  name=\'AsdnDataParameter\',\n  full_name=\'caffe.AsdnDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'count_drop\', full_name=\'caffe.AsdnDataParameter.count_drop\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=15,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'permute_count\', full_name=\'caffe.AsdnDataParameter.permute_count\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=20,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'count_drop_neg\', full_name=\'caffe.AsdnDataParameter.count_drop_neg\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.AsdnDataParameter.channels\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1024,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'iter_size\', full_name=\'caffe.AsdnDataParameter.iter_size\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'maintain_before\', full_name=\'caffe.AsdnDataParameter.maintain_before\', index=5,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9942,\n  serialized_end=10113,\n)\n\n\n_MTCNNDATAPARAMETER = _descriptor.Descriptor(\n  name=\'MTCNNDataParameter\',\n  full_name=\'caffe.MTCNNDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'augmented\', full_name=\'caffe.MTCNNDataParameter.augmented\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'flip\', full_name=\'caffe.MTCNNDataParameter.flip\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_positive\', full_name=\'caffe.MTCNNDataParameter.num_positive\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_negitive\', full_name=\'caffe.MTCNNDataParameter.num_negitive\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_part\', full_name=\'caffe.MTCNNDataParameter.num_part\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'resize_width\', full_name=\'caffe.MTCNNDataParameter.resize_width\', index=5,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'resize_height\', full_name=\'caffe.MTCNNDataParameter.resize_height\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min_negitive_scale\', full_name=\'caffe.MTCNNDataParameter.min_negitive_scale\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_negitive_scale\', full_name=\'caffe.MTCNNDataParameter.max_negitive_scale\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10116,\n  serialized_end=10372,\n)\n\n\n_INTERPPARAMETER = _descriptor.Descriptor(\n  name=\'InterpParameter\',\n  full_name=\'caffe.InterpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.InterpParameter.height\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.InterpParameter.width\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'zoom_factor\', full_name=\'caffe.InterpParameter.zoom_factor\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shrink_factor\', full_name=\'caffe.InterpParameter.shrink_factor\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_beg\', full_name=\'caffe.InterpParameter.pad_beg\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_end\', full_name=\'caffe.InterpParameter.pad_end\', index=5,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10375,\n  serialized_end=10519,\n)\n\n\n_PSROIPOOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'PSROIPoolingParameter\',\n  full_name=\'caffe.PSROIPoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'spatial_scale\', full_name=\'caffe.PSROIPoolingParameter.spatial_scale\', index=0,\n      number=1, type=2, cpp_type=6, label=2,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'output_dim\', full_name=\'caffe.PSROIPoolingParameter.output_dim\', index=1,\n      number=2, type=5, cpp_type=1, label=2,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'group_size\', full_name=\'caffe.PSROIPoolingParameter.group_size\', index=2,\n      number=3, type=5, cpp_type=1, label=2,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10521,\n  serialized_end=10607,\n)\n\n\n_FLIPPARAMETER = _descriptor.Descriptor(\n  name=\'FlipParameter\',\n  full_name=\'caffe.FlipParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'flip_width\', full_name=\'caffe.FlipParameter.flip_width\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'flip_height\', full_name=\'caffe.FlipParameter.flip_height\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10609,\n  serialized_end=10678,\n)\n\n\n_BNPARAMETER = _descriptor.Descriptor(\n  name=\'BNParameter\',\n  full_name=\'caffe.BNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'slope_filler\', full_name=\'caffe.BNParameter.slope_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.BNParameter.bias_filler\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.BNParameter.momentum\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.9),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BNParameter.eps\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-05),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'frozen\', full_name=\'caffe.BNParameter.frozen\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.BNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _BNPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10681,\n  serialized_end=10948,\n)\n\n\n_FOCALLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'FocalLossParameter\',\n  full_name=\'caffe.FocalLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.FocalLossParameter.type\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.FocalLossParameter.gamma\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(2),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.FocalLossParameter.alpha\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.25),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.FocalLossParameter.beta\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _FOCALLOSSPARAMETER_TYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10951,\n  serialized_end=11113,\n)\n\n\n_TRANSFORMATIONPARAMETER = _descriptor.Descriptor(\n  name=\'TransformationParameter\',\n  full_name=\'caffe.TransformationParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.TransformationParameter.scale\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.TransformationParameter.mirror\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.TransformationParameter.crop_size\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'crop_h\', full_name=\'caffe.TransformationParameter.crop_h\', index=3,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'crop_w\', full_name=\'caffe.TransformationParameter.crop_w\', index=4,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.TransformationParameter.mean_file\', index=5,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mean_value\', full_name=\'caffe.TransformationParameter.mean_value\', index=6,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'force_color\', full_name=\'caffe.TransformationParameter.force_color\', index=7,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'force_gray\', full_name=\'caffe.TransformationParameter.force_gray\', index=8,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'resize_param\', full_name=\'caffe.TransformationParameter.resize_param\', index=9,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'noise_param\', full_name=\'caffe.TransformationParameter.noise_param\', index=10,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'distort_param\', full_name=\'caffe.TransformationParameter.distort_param\', index=11,\n      number=13, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'expand_param\', full_name=\'caffe.TransformationParameter.expand_param\', index=12,\n      number=14, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'emit_constraint\', full_name=\'caffe.TransformationParameter.emit_constraint\', index=13,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11116,\n  serialized_end=11574,\n)\n\n\n_RESIZEPARAMETER = _descriptor.Descriptor(\n  name=\'ResizeParameter\',\n  full_name=\'caffe.ResizeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'prob\', full_name=\'caffe.ResizeParameter.prob\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'resize_mode\', full_name=\'caffe.ResizeParameter.resize_mode\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.ResizeParameter.height\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.ResizeParameter.width\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'height_scale\', full_name=\'caffe.ResizeParameter.height_scale\', index=4,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width_scale\', full_name=\'caffe.ResizeParameter.width_scale\', index=5,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_mode\', full_name=\'caffe.ResizeParameter.pad_mode\', index=6,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_value\', full_name=\'caffe.ResizeParameter.pad_value\', index=7,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'interp_mode\', full_name=\'caffe.ResizeParameter.interp_mode\', index=8,\n      number=7, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _RESIZEPARAMETER_RESIZE_MODE,\n    _RESIZEPARAMETER_PAD_MODE,\n    _RESIZEPARAMETER_INTERP_MODE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11577,\n  serialized_end=12105,\n)\n\n\n_SALTPEPPERPARAMETER = _descriptor.Descriptor(\n  name=\'SaltPepperParameter\',\n  full_name=\'caffe.SaltPepperParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'fraction\', full_name=\'caffe.SaltPepperParameter.fraction\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'caffe.SaltPepperParameter.value\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12107,\n  serialized_end=12164,\n)\n\n\n_NOISEPARAMETER = _descriptor.Descriptor(\n  name=\'NoiseParameter\',\n  full_name=\'caffe.NoiseParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'prob\', full_name=\'caffe.NoiseParameter.prob\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hist_eq\', full_name=\'caffe.NoiseParameter.hist_eq\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'inverse\', full_name=\'caffe.NoiseParameter.inverse\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'decolorize\', full_name=\'caffe.NoiseParameter.decolorize\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'gauss_blur\', full_name=\'caffe.NoiseParameter.gauss_blur\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'jpeg\', full_name=\'caffe.NoiseParameter.jpeg\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'posterize\', full_name=\'caffe.NoiseParameter.posterize\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'erode\', full_name=\'caffe.NoiseParameter.erode\', index=7,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'saltpepper\', full_name=\'caffe.NoiseParameter.saltpepper\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'saltpepper_param\', full_name=\'caffe.NoiseParameter.saltpepper_param\', index=9,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'clahe\', full_name=\'caffe.NoiseParameter.clahe\', index=10,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'convert_to_hsv\', full_name=\'caffe.NoiseParameter.convert_to_hsv\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'convert_to_lab\', full_name=\'caffe.NoiseParameter.convert_to_lab\', index=12,\n      number=13, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12167,\n  serialized_end=12533,\n)\n\n\n_DISTORTIONPARAMETER = _descriptor.Descriptor(\n  name=\'DistortionParameter\',\n  full_name=\'caffe.DistortionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'brightness_prob\', full_name=\'caffe.DistortionParameter.brightness_prob\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'brightness_delta\', full_name=\'caffe.DistortionParameter.brightness_delta\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'contrast_prob\', full_name=\'caffe.DistortionParameter.contrast_prob\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'contrast_lower\', full_name=\'caffe.DistortionParameter.contrast_lower\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'contrast_upper\', full_name=\'caffe.DistortionParameter.contrast_upper\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hue_prob\', full_name=\'caffe.DistortionParameter.hue_prob\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hue_delta\', full_name=\'caffe.DistortionParameter.hue_delta\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'saturation_prob\', full_name=\'caffe.DistortionParameter.saturation_prob\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'saturation_lower\', full_name=\'caffe.DistortionParameter.saturation_lower\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'saturation_upper\', full_name=\'caffe.DistortionParameter.saturation_upper\', index=9,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'random_order_prob\', full_name=\'caffe.DistortionParameter.random_order_prob\', index=10,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12536,\n  serialized_end=12853,\n)\n\n\n_EXPANSIONPARAMETER = _descriptor.Descriptor(\n  name=\'ExpansionParameter\',\n  full_name=\'caffe.ExpansionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'prob\', full_name=\'caffe.ExpansionParameter.prob\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_expand_ratio\', full_name=\'caffe.ExpansionParameter.max_expand_ratio\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12855,\n  serialized_end=12921,\n)\n\n\n_LOSSPARAMETER = _descriptor.Descriptor(\n  name=\'LossParameter\',\n  full_name=\'caffe.LossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.LossParameter.ignore_label\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'normalization\', full_name=\'caffe.LossParameter.normalization\', index=1,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'normalize\', full_name=\'caffe.LossParameter.normalize\', index=2,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LOSSPARAMETER_NORMALIZATIONMODE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12924,\n  serialized_end=13118,\n)\n\n\n_ACCURACYPARAMETER = _descriptor.Descriptor(\n  name=\'AccuracyParameter\',\n  full_name=\'caffe.AccuracyParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.AccuracyParameter.top_k\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.AccuracyParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.AccuracyParameter.ignore_label\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13120,\n  serialized_end=13196,\n)\n\n\n_ARGMAXPARAMETER = _descriptor.Descriptor(\n  name=\'ArgMaxParameter\',\n  full_name=\'caffe.ArgMaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'out_max_val\', full_name=\'caffe.ArgMaxParameter.out_max_val\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.ArgMaxParameter.top_k\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ArgMaxParameter.axis\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13198,\n  serialized_end=13275,\n)\n\n\n_CONCATPARAMETER = _descriptor.Descriptor(\n  name=\'ConcatParameter\',\n  full_name=\'caffe.ConcatParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConcatParameter.axis\', index=0,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.ConcatParameter.concat_dim\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13277,\n  serialized_end=13334,\n)\n\n\n_BATCHNORMPARAMETER = _descriptor.Descriptor(\n  name=\'BatchNormParameter\',\n  full_name=\'caffe.BatchNormParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'use_global_stats\', full_name=\'caffe.BatchNormParameter.use_global_stats\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'moving_average_fraction\', full_name=\'caffe.BatchNormParameter.moving_average_fraction\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.999),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BatchNormParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-05),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13336,\n  serialized_end=13442,\n)\n\n\n_BIASPARAMETER = _descriptor.Descriptor(\n  name=\'BiasParameter\',\n  full_name=\'caffe.BiasParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.BiasParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.BiasParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.BiasParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13444,\n  serialized_end=13537,\n)\n\n\n_CONTRASTIVELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'ContrastiveLossParameter\',\n  full_name=\'caffe.ContrastiveLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.ContrastiveLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'legacy_version\', full_name=\'caffe.ContrastiveLossParameter.legacy_version\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13539,\n  serialized_end=13615,\n)\n\n\n_DETECTIONLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'DetectionLossParameter\',\n  full_name=\'caffe.DetectionLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'side\', full_name=\'caffe.DetectionLossParameter.side\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=7,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_class\', full_name=\'caffe.DetectionLossParameter.num_class\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=20,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_object\', full_name=\'caffe.DetectionLossParameter.num_object\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'object_scale\', full_name=\'caffe.DetectionLossParameter.object_scale\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'noobject_scale\', full_name=\'caffe.DetectionLossParameter.noobject_scale\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'class_scale\', full_name=\'caffe.DetectionLossParameter.class_scale\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'coord_scale\', full_name=\'caffe.DetectionLossParameter.coord_scale\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sqrt\', full_name=\'caffe.DetectionLossParameter.sqrt\', index=7,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'constriant\', full_name=\'caffe.DetectionLossParameter.constriant\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13618,\n  serialized_end=13854,\n)\n\n\n_REGIONLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'RegionLossParameter\',\n  full_name=\'caffe.RegionLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'side\', full_name=\'caffe.RegionLossParameter.side\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=13,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_class\', full_name=\'caffe.RegionLossParameter.num_class\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=20,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_match\', full_name=\'caffe.RegionLossParameter.bias_match\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'coords\', full_name=\'caffe.RegionLossParameter.coords\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.RegionLossParameter.num\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'softmax\', full_name=\'caffe.RegionLossParameter.softmax\', index=5,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'jitter\', full_name=\'caffe.RegionLossParameter.jitter\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.2),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'rescore\', full_name=\'caffe.RegionLossParameter.rescore\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'object_scale\', full_name=\'caffe.RegionLossParameter.object_scale\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'class_scale\', full_name=\'caffe.RegionLossParameter.class_scale\', index=9,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'noobject_scale\', full_name=\'caffe.RegionLossParameter.noobject_scale\', index=10,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'coord_scale\', full_name=\'caffe.RegionLossParameter.coord_scale\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'absolute\', full_name=\'caffe.RegionLossParameter.absolute\', index=12,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'thresh\', full_name=\'caffe.RegionLossParameter.thresh\', index=13,\n      number=14, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.2),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'random\', full_name=\'caffe.RegionLossParameter.random\', index=14,\n      number=15, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'biases\', full_name=\'caffe.RegionLossParameter.biases\', index=15,\n      number=16, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_tree\', full_name=\'caffe.RegionLossParameter.softmax_tree\', index=16,\n      number=17, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'class_map\', full_name=\'caffe.RegionLossParameter.class_map\', index=17,\n      number=18, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13857,\n  serialized_end=14258,\n)\n\n\n_REORGPARAMETER = _descriptor.Descriptor(\n  name=\'ReorgParameter\',\n  full_name=\'caffe.ReorgParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.ReorgParameter.stride\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'reverse\', full_name=\'caffe.ReorgParameter.reverse\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=14260,\n  serialized_end=14316,\n)\n\n\n_EVALDETECTIONPARAMETER = _descriptor.Descriptor(\n  name=\'EvalDetectionParameter\',\n  full_name=\'caffe.EvalDetectionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'side\', full_name=\'caffe.EvalDetectionParameter.side\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=7,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_class\', full_name=\'caffe.EvalDetectionParameter.num_class\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=20,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_object\', full_name=\'caffe.EvalDetectionParameter.num_object\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'threshold\', full_name=\'caffe.EvalDetectionParameter.threshold\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sqrt\', full_name=\'caffe.EvalDetectionParameter.sqrt\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'constriant\', full_name=\'caffe.EvalDetectionParameter.constriant\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'score_type\', full_name=\'caffe.EvalDetectionParameter.score_type\', index=6,\n      number=7, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'nms\', full_name=\'caffe.EvalDetectionParameter.nms\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'biases\', full_name=\'caffe.EvalDetectionParameter.biases\', index=8,\n      number=9, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _EVALDETECTIONPARAMETER_SCORETYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=14319,\n  serialized_end=14626,\n)\n\n\n_CONVOLUTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ConvolutionParameter\',\n  full_name=\'caffe.ConvolutionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.ConvolutionParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ConvolutionParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.ConvolutionParameter.pad\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.ConvolutionParameter.kernel_size\', index=3,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.ConvolutionParameter.stride\', index=4,\n      number=6, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dilation\', full_name=\'caffe.ConvolutionParameter.dilation\', index=5,\n      number=18, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.ConvolutionParameter.pad_h\', index=6,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.ConvolutionParameter.pad_w\', index=7,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.ConvolutionParameter.kernel_h\', index=8,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.ConvolutionParameter.kernel_w\', index=9,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.ConvolutionParameter.stride_h\', index=10,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.ConvolutionParameter.stride_w\', index=11,\n      number=14, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.ConvolutionParameter.group\', index=12,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.ConvolutionParameter.weight_filler\', index=13,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ConvolutionParameter.bias_filler\', index=14,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ConvolutionParameter.engine\', index=15,\n      number=15, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConvolutionParameter.axis\', index=16,\n      number=16, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'force_nd_im2col\', full_name=\'caffe.ConvolutionParameter.force_nd_im2col\', index=17,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CONVOLUTIONPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=14629,\n  serialized_end=15137,\n)\n\n\n_CROPPARAMETER = _descriptor.Descriptor(\n  name=\'CropParameter\',\n  full_name=\'caffe.CropParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.CropParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'offset\', full_name=\'caffe.CropParameter.offset\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=15139,\n  serialized_end=15187,\n)\n\n\n_DATAPARAMETER = _descriptor.Descriptor(\n  name=\'DataParameter\',\n  full_name=\'caffe.DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.DataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.DataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'backend\', full_name=\'caffe.DataParameter.backend\', index=3,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.DataParameter.scale\', index=4,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.DataParameter.mean_file\', index=5,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.DataParameter.crop_size\', index=6,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.DataParameter.mirror\', index=7,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'force_encoded_color\', full_name=\'caffe.DataParameter.force_encoded_color\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'prefetch\', full_name=\'caffe.DataParameter.prefetch\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'side\', full_name=\'caffe.DataParameter.side\', index=10,\n      number=11, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _DATAPARAMETER_DB,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=15190,\n  serialized_end=15496,\n)\n\n\n_DETECTIONEVALUATEPARAMETER = _descriptor.Descriptor(\n  name=\'DetectionEvaluateParameter\',\n  full_name=\'caffe.DetectionEvaluateParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_classes\', full_name=\'caffe.DetectionEvaluateParameter.num_classes\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'background_label_id\', full_name=\'caffe.DetectionEvaluateParameter.background_label_id\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'overlap_threshold\', full_name=\'caffe.DetectionEvaluateParameter.overlap_threshold\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'evaluate_difficult_gt\', full_name=\'caffe.DetectionEvaluateParameter.evaluate_difficult_gt\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'name_size_file\', full_name=\'caffe.DetectionEvaluateParameter.name_size_file\', index=4,\n      number=5, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'resize_param\', full_name=\'caffe.DetectionEvaluateParameter.resize_param\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=15499,\n  serialized_end=15719,\n)\n\n\n_NONMAXIMUMSUPPRESSIONPARAMETER = _descriptor.Descriptor(\n  name=\'NonMaximumSuppressionParameter\',\n  full_name=\'caffe.NonMaximumSuppressionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'nms_threshold\', full_name=\'caffe.NonMaximumSuppressionParameter.nms_threshold\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.3),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.NonMaximumSuppressionParameter.top_k\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eta\', full_name=\'caffe.NonMaximumSuppressionParameter.eta\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=15721,\n  serialized_end=15812,\n)\n\n\n_SAVEOUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'SaveOutputParameter\',\n  full_name=\'caffe.SaveOutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'output_directory\', full_name=\'caffe.SaveOutputParameter.output_directory\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'output_name_prefix\', full_name=\'caffe.SaveOutputParameter.output_name_prefix\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'output_format\', full_name=\'caffe.SaveOutputParameter.output_format\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'label_map_file\', full_name=\'caffe.SaveOutputParameter.label_map_file\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'name_size_file\', full_name=\'caffe.SaveOutputParameter.name_size_file\', index=4,\n      number=5, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_test_image\', full_name=\'caffe.SaveOutputParameter.num_test_image\', index=5,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'resize_param\', full_name=\'caffe.SaveOutputParameter.resize_param\', index=6,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=15815,\n  serialized_end=16031,\n)\n\n\n_DETECTIONOUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'DetectionOutputParameter\',\n  full_name=\'caffe.DetectionOutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_classes\', full_name=\'caffe.DetectionOutputParameter.num_classes\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'share_location\', full_name=\'caffe.DetectionOutputParameter.share_location\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'background_label_id\', full_name=\'caffe.DetectionOutputParameter.background_label_id\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'nms_param\', full_name=\'caffe.DetectionOutputParameter.nms_param\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'save_output_param\', full_name=\'caffe.DetectionOutputParameter.save_output_param\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'code_type\', full_name=\'caffe.DetectionOutputParameter.code_type\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'variance_encoded_in_target\', full_name=\'caffe.DetectionOutputParameter.variance_encoded_in_target\', index=6,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'keep_top_k\', full_name=\'caffe.DetectionOutputParameter.keep_top_k\', index=7,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'confidence_threshold\', full_name=\'caffe.DetectionOutputParameter.confidence_threshold\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'visualize\', full_name=\'caffe.DetectionOutputParameter.visualize\', index=9,\n      number=10, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'visualize_threshold\', full_name=\'caffe.DetectionOutputParameter.visualize_threshold\', index=10,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'save_file\', full_name=\'caffe.DetectionOutputParameter.save_file\', index=11,\n      number=12, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=16034,\n  serialized_end=16489,\n)\n\n\n_DROPOUTPARAMETER = _descriptor.Descriptor(\n  name=\'DropoutParameter\',\n  full_name=\'caffe.DropoutParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.DropoutParameter.dropout_ratio\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale_train\', full_name=\'caffe.DropoutParameter.scale_train\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=16491,\n  serialized_end=16564,\n)\n\n\n_DUMMYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'DummyDataParameter\',\n  full_name=\'caffe.DummyDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data_filler\', full_name=\'caffe.DummyDataParameter.data_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.DummyDataParameter.shape\', index=1,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.DummyDataParameter.num\', index=2,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.DummyDataParameter.channels\', index=3,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.DummyDataParameter.height\', index=4,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.DummyDataParameter.width\', index=5,\n      number=5, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=16567,\n  serialized_end=16727,\n)\n\n\n_ELTWISEPARAMETER = _descriptor.Descriptor(\n  name=\'EltwiseParameter\',\n  full_name=\'caffe.EltwiseParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.EltwiseParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.EltwiseParameter.coeff\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stable_prod_grad\', full_name=\'caffe.EltwiseParameter.stable_prod_grad\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _ELTWISEPARAMETER_ELTWISEOP,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=16730,\n  serialized_end=16895,\n)\n\n\n_ELUPARAMETER = _descriptor.Descriptor(\n  name=\'ELUParameter\',\n  full_name=\'caffe.ELUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.ELUParameter.alpha\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=16897,\n  serialized_end=16929,\n)\n\n\n_EMBEDPARAMETER = _descriptor.Descriptor(\n  name=\'EmbedParameter\',\n  full_name=\'caffe.EmbedParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.EmbedParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.EmbedParameter.input_dim\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.EmbedParameter.bias_term\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.EmbedParameter.weight_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.EmbedParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=16932,\n  serialized_end=17104,\n)\n\n\n_EXPPARAMETER = _descriptor.Descriptor(\n  name=\'ExpParameter\',\n  full_name=\'caffe.ExpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.ExpParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ExpParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.ExpParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17106,\n  serialized_end=17174,\n)\n\n\n_FLATTENPARAMETER = _descriptor.Descriptor(\n  name=\'FlattenParameter\',\n  full_name=\'caffe.FlattenParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.FlattenParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'end_axis\', full_name=\'caffe.FlattenParameter.end_axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17176,\n  serialized_end=17233,\n)\n\n\n_HDF5DATAPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5DataParameter\',\n  full_name=\'caffe.HDF5DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.HDF5DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.HDF5DataParameter.batch_size\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.HDF5DataParameter.shuffle\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17235,\n  serialized_end=17314,\n)\n\n\n_HDF5OUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5OutputParameter\',\n  full_name=\'caffe.HDF5OutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'file_name\', full_name=\'caffe.HDF5OutputParameter.file_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17316,\n  serialized_end=17356,\n)\n\n\n_HINGELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'HingeLossParameter\',\n  full_name=\'caffe.HingeLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'norm\', full_name=\'caffe.HingeLossParameter.norm\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _HINGELOSSPARAMETER_NORM,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17358,\n  serialized_end=17452,\n)\n\n\n_IMAGEDATAPARAMETER = _descriptor.Descriptor(\n  name=\'ImageDataParameter\',\n  full_name=\'caffe.ImageDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.ImageDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.ImageDataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.ImageDataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.ImageDataParameter.shuffle\', index=3,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.ImageDataParameter.new_height\', index=4,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.ImageDataParameter.new_width\', index=5,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'is_color\', full_name=\'caffe.ImageDataParameter.is_color\', index=6,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ImageDataParameter.scale\', index=7,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.ImageDataParameter.mean_file\', index=8,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.ImageDataParameter.crop_size\', index=9,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.ImageDataParameter.mirror\', index=10,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.ImageDataParameter.root_folder\', index=11,\n      number=12, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17455,\n  serialized_end=17734,\n)\n\n\n_INFOGAINLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'InfogainLossParameter\',\n  full_name=\'caffe.InfogainLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.InfogainLossParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17736,\n  serialized_end=17775,\n)\n\n\n_INNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'InnerProductParameter\',\n  full_name=\'caffe.InnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.InnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.InnerProductParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.InnerProductParameter.weight_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.InnerProductParameter.bias_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.InnerProductParameter.axis\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'transpose\', full_name=\'caffe.InnerProductParameter.transpose\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'normalize\', full_name=\'caffe.InnerProductParameter.normalize\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17778,\n  serialized_end=18007,\n)\n\n\n_INPUTPARAMETER = _descriptor.Descriptor(\n  name=\'InputParameter\',\n  full_name=\'caffe.InputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.InputParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=18009,\n  serialized_end=18058,\n)\n\n\n_LOGPARAMETER = _descriptor.Descriptor(\n  name=\'LogParameter\',\n  full_name=\'caffe.LogParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.LogParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.LogParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.LogParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=18060,\n  serialized_end=18128,\n)\n\n\n_LRNPARAMETER = _descriptor.Descriptor(\n  name=\'LRNParameter\',\n  full_name=\'caffe.LRNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.LRNParameter.local_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.LRNParameter.alpha\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.LRNParameter.beta\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.75),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'norm_region\', full_name=\'caffe.LRNParameter.norm_region\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.LRNParameter.k\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.LRNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LRNPARAMETER_NORMREGION,\n    _LRNPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=18131,\n  serialized_end=18443,\n)\n\n\n_MEMORYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'MemoryDataParameter\',\n  full_name=\'caffe.MemoryDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.MemoryDataParameter.batch_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.MemoryDataParameter.channels\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.MemoryDataParameter.height\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.MemoryDataParameter.width\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=18445,\n  serialized_end=18535,\n)\n\n\n_MULTIBOXLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'MultiBoxLossParameter\',\n  full_name=\'caffe.MultiBoxLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'loc_loss_type\', full_name=\'caffe.MultiBoxLossParameter.loc_loss_type\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'conf_loss_type\', full_name=\'caffe.MultiBoxLossParameter.conf_loss_type\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'loc_weight\', full_name=\'caffe.MultiBoxLossParameter.loc_weight\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_classes\', full_name=\'caffe.MultiBoxLossParameter.num_classes\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'share_location\', full_name=\'caffe.MultiBoxLossParameter.share_location\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'match_type\', full_name=\'caffe.MultiBoxLossParameter.match_type\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'overlap_threshold\', full_name=\'caffe.MultiBoxLossParameter.overlap_threshold\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'use_prior_for_matching\', full_name=\'caffe.MultiBoxLossParameter.use_prior_for_matching\', index=7,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'background_label_id\', full_name=\'caffe.MultiBoxLossParameter.background_label_id\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'use_difficult_gt\', full_name=\'caffe.MultiBoxLossParameter.use_difficult_gt\', index=9,\n      number=10, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'do_neg_mining\', full_name=\'caffe.MultiBoxLossParameter.do_neg_mining\', index=10,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'neg_pos_ratio\', full_name=\'caffe.MultiBoxLossParameter.neg_pos_ratio\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(3),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'neg_overlap\', full_name=\'caffe.MultiBoxLossParameter.neg_overlap\', index=12,\n      number=13, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'code_type\', full_name=\'caffe.MultiBoxLossParameter.code_type\', index=13,\n      number=14, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'encode_variance_in_target\', full_name=\'caffe.MultiBoxLossParameter.encode_variance_in_target\', index=14,\n      number=16, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'map_object_to_agnostic\', full_name=\'caffe.MultiBoxLossParameter.map_object_to_agnostic\', index=15,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_cross_boundary_bbox\', full_name=\'caffe.MultiBoxLossParameter.ignore_cross_boundary_bbox\', index=16,\n      number=18, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bp_inside\', full_name=\'caffe.MultiBoxLossParameter.bp_inside\', index=17,\n      number=19, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mining_type\', full_name=\'caffe.MultiBoxLossParameter.mining_type\', index=18,\n      number=20, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'nms_param\', full_name=\'caffe.MultiBoxLossParameter.nms_param\', index=19,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sample_size\', full_name=\'caffe.MultiBoxLossParameter.sample_size\', index=20,\n      number=22, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=64,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'use_prior_for_nms\', full_name=\'caffe.MultiBoxLossParameter.use_prior_for_nms\', index=21,\n      number=23, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _MULTIBOXLOSSPARAMETER_LOCLOSSTYPE,\n    _MULTIBOXLOSSPARAMETER_CONFLOSSTYPE,\n    _MULTIBOXLOSSPARAMETER_MATCHTYPE,\n    _MULTIBOXLOSSPARAMETER_MININGTYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=18538,\n  serialized_end=19666,\n)\n\n\n_PERMUTEPARAMETER = _descriptor.Descriptor(\n  name=\'PermuteParameter\',\n  full_name=\'caffe.PermuteParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'order\', full_name=\'caffe.PermuteParameter.order\', index=0,\n      number=1, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=19668,\n  serialized_end=19701,\n)\n\n\n_MVNPARAMETER = _descriptor.Descriptor(\n  name=\'MVNParameter\',\n  full_name=\'caffe.MVNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'normalize_variance\', full_name=\'caffe.MVNParameter.normalize_variance\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'across_channels\', full_name=\'caffe.MVNParameter.across_channels\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.MVNParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-09),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=19703,\n  serialized_end=19803,\n)\n\n\n_PARAMETERPARAMETER = _descriptor.Descriptor(\n  name=\'ParameterParameter\',\n  full_name=\'caffe.ParameterParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ParameterParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=19805,\n  serialized_end=19858,\n)\n\n\n_POOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'PoolingParameter\',\n  full_name=\'caffe.PoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.PoolingParameter.pool\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.PoolingParameter.pad\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.PoolingParameter.pad_h\', index=2,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.PoolingParameter.pad_w\', index=3,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.PoolingParameter.kernel_size\', index=4,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.PoolingParameter.kernel_h\', index=5,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.PoolingParameter.kernel_w\', index=6,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.PoolingParameter.stride\', index=7,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.PoolingParameter.stride_h\', index=8,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.PoolingParameter.stride_w\', index=9,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.PoolingParameter.engine\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'global_pooling\', full_name=\'caffe.PoolingParameter.global_pooling\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ceil_mode\', full_name=\'caffe.PoolingParameter.ceil_mode\', index=12,\n      number=13, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _POOLINGPARAMETER_POOLMETHOD,\n    _POOLINGPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=19861,\n  serialized_end=20304,\n)\n\n\n_POWERPARAMETER = _descriptor.Descriptor(\n  name=\'PowerParameter\',\n  full_name=\'caffe.PowerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.PowerParameter.power\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.PowerParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.PowerParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=20306,\n  serialized_end=20376,\n)\n\n\n_PRIORBOXPARAMETER = _descriptor.Descriptor(\n  name=\'PriorBoxParameter\',\n  full_name=\'caffe.PriorBoxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'min_size\', full_name=\'caffe.PriorBoxParameter.min_size\', index=0,\n      number=1, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_size\', full_name=\'caffe.PriorBoxParameter.max_size\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'aspect_ratio\', full_name=\'caffe.PriorBoxParameter.aspect_ratio\', index=2,\n      number=3, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'flip\', full_name=\'caffe.PriorBoxParameter.flip\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'clip\', full_name=\'caffe.PriorBoxParameter.clip\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'variance\', full_name=\'caffe.PriorBoxParameter.variance\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'img_size\', full_name=\'caffe.PriorBoxParameter.img_size\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'img_h\', full_name=\'caffe.PriorBoxParameter.img_h\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'img_w\', full_name=\'caffe.PriorBoxParameter.img_w\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'step\', full_name=\'caffe.PriorBoxParameter.step\', index=9,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'step_h\', full_name=\'caffe.PriorBoxParameter.step_h\', index=10,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'step_w\', full_name=\'caffe.PriorBoxParameter.step_w\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'offset\', full_name=\'caffe.PriorBoxParameter.offset\', index=12,\n      number=13, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _PRIORBOXPARAMETER_CODETYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=20379,\n  serialized_end=20688,\n)\n\n\n_PYTHONPARAMETER = _descriptor.Descriptor(\n  name=\'PythonParameter\',\n  full_name=\'caffe.PythonParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'module\', full_name=\'caffe.PythonParameter.module\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.PythonParameter.layer\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'param_str\', full_name=\'caffe.PythonParameter.param_str\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'share_in_parallel\', full_name=\'caffe.PythonParameter.share_in_parallel\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=20690,\n  serialized_end=20793,\n)\n\n\n_RECURRENTPARAMETER = _descriptor.Descriptor(\n  name=\'RecurrentParameter\',\n  full_name=\'caffe.RecurrentParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.RecurrentParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.RecurrentParameter.weight_filler\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.RecurrentParameter.bias_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.RecurrentParameter.debug_info\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'expose_hidden\', full_name=\'caffe.RecurrentParameter.expose_hidden\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=20796,\n  serialized_end=20988,\n)\n\n\n_REDUCTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ReductionParameter\',\n  full_name=\'caffe.ReductionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.ReductionParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReductionParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.ReductionParameter.coeff\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _REDUCTIONPARAMETER_REDUCTIONOP,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=20991,\n  serialized_end=21164,\n)\n\n\n_RELUPARAMETER = _descriptor.Descriptor(\n  name=\'ReLUParameter\',\n  full_name=\'caffe.ReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'negative_slope\', full_name=\'caffe.ReLUParameter.negative_slope\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ReLUParameter.engine\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _RELUPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=21167,\n  serialized_end=21308,\n)\n\n\n_RESHAPEPARAMETER = _descriptor.Descriptor(\n  name=\'ReshapeParameter\',\n  full_name=\'caffe.ReshapeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ReshapeParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReshapeParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ReshapeParameter.num_axes\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=21310,\n  serialized_end=21400,\n)\n\n\n_ROIPOOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'ROIPoolingParameter\',\n  full_name=\'caffe.ROIPoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pooled_h\', full_name=\'caffe.ROIPoolingParameter.pooled_h\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pooled_w\', full_name=\'caffe.ROIPoolingParameter.pooled_w\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'spatial_scale\', full_name=\'caffe.ROIPoolingParameter.spatial_scale\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=21402,\n  serialized_end=21491,\n)\n\n\n_SCALEPARAMETER = _descriptor.Descriptor(\n  name=\'ScaleParameter\',\n  full_name=\'caffe.ScaleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ScaleParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ScaleParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.ScaleParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ScaleParameter.bias_term\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ScaleParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min_value\', full_name=\'caffe.ScaleParameter.min_value\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_value\', full_name=\'caffe.ScaleParameter.max_value\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=21494,\n  serialized_end=21697,\n)\n\n\n_SIGMOIDPARAMETER = _descriptor.Descriptor(\n  name=\'SigmoidParameter\',\n  full_name=\'caffe.SigmoidParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SigmoidParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SIGMOIDPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=21699,\n  serialized_end=21819,\n)\n\n\n_SMOOTHL1LOSSPARAMETER = _descriptor.Descriptor(\n  name=\'SmoothL1LossParameter\',\n  full_name=\'caffe.SmoothL1LossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'sigma\', full_name=\'caffe.SmoothL1LossParameter.sigma\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=21821,\n  serialized_end=21862,\n)\n\n\n_SLICEPARAMETER = _descriptor.Descriptor(\n  name=\'SliceParameter\',\n  full_name=\'caffe.SliceParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SliceParameter.axis\', index=0,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'slice_point\', full_name=\'caffe.SliceParameter.slice_point\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'slice_dim\', full_name=\'caffe.SliceParameter.slice_dim\', index=2,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=21864,\n  serialized_end=21940,\n)\n\n\n_SOFTMAXPARAMETER = _descriptor.Descriptor(\n  name=\'SoftmaxParameter\',\n  full_name=\'caffe.SoftmaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SoftmaxParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SoftmaxParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOFTMAXPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=21943,\n  serialized_end=22080,\n)\n\n\n_TANHPARAMETER = _descriptor.Descriptor(\n  name=\'TanHParameter\',\n  full_name=\'caffe.TanHParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.TanHParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TANHPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22082,\n  serialized_end=22196,\n)\n\n\n_TILEPARAMETER = _descriptor.Descriptor(\n  name=\'TileParameter\',\n  full_name=\'caffe.TileParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.TileParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tiles\', full_name=\'caffe.TileParameter.tiles\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22198,\n  serialized_end=22245,\n)\n\n\n_THRESHOLDPARAMETER = _descriptor.Descriptor(\n  name=\'ThresholdParameter\',\n  full_name=\'caffe.ThresholdParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'threshold\', full_name=\'caffe.ThresholdParameter.threshold\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22247,\n  serialized_end=22289,\n)\n\n\n_WINDOWDATAPARAMETER = _descriptor.Descriptor(\n  name=\'WindowDataParameter\',\n  full_name=\'caffe.WindowDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.WindowDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.WindowDataParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.WindowDataParameter.mean_file\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.WindowDataParameter.batch_size\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.WindowDataParameter.crop_size\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.WindowDataParameter.mirror\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'fg_threshold\', full_name=\'caffe.WindowDataParameter.fg_threshold\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bg_threshold\', full_name=\'caffe.WindowDataParameter.bg_threshold\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'fg_fraction\', full_name=\'caffe.WindowDataParameter.fg_fraction\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.25),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'context_pad\', full_name=\'caffe.WindowDataParameter.context_pad\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'crop_mode\', full_name=\'caffe.WindowDataParameter.crop_mode\', index=10,\n      number=11, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""warp"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'cache_images\', full_name=\'caffe.WindowDataParameter.cache_images\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.WindowDataParameter.root_folder\', index=12,\n      number=13, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22292,\n  serialized_end=22613,\n)\n\n\n_SPPPARAMETER = _descriptor.Descriptor(\n  name=\'SPPParameter\',\n  full_name=\'caffe.SPPParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pyramid_height\', full_name=\'caffe.SPPParameter.pyramid_height\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.SPPParameter.pool\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SPPParameter.engine\', index=2,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SPPPARAMETER_POOLMETHOD,\n    _SPPPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22616,\n  serialized_end=22851,\n)\n\n\n_V1LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V1LayerParameter\',\n  full_name=\'caffe.V1LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.V1LayerParameter.bottom\', index=0,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.V1LayerParameter.top\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V1LayerParameter.name\', index=2,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.V1LayerParameter.include\', index=3,\n      number=32, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.V1LayerParameter.exclude\', index=4,\n      number=33, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V1LayerParameter.type\', index=5,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V1LayerParameter.blobs\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.V1LayerParameter.param\', index=7,\n      number=1001, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'blob_share_mode\', full_name=\'caffe.V1LayerParameter.blob_share_mode\', index=8,\n      number=1002, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V1LayerParameter.blobs_lr\', index=9,\n      number=7, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V1LayerParameter.weight_decay\', index=10,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.V1LayerParameter.loss_weight\', index=11,\n      number=35, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.V1LayerParameter.accuracy_param\', index=12,\n      number=27, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.V1LayerParameter.argmax_param\', index=13,\n      number=23, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.V1LayerParameter.concat_param\', index=14,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.V1LayerParameter.contrastive_loss_param\', index=15,\n      number=40, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.V1LayerParameter.convolution_param\', index=16,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.V1LayerParameter.data_param\', index=17,\n      number=11, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.V1LayerParameter.dropout_param\', index=18,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.V1LayerParameter.dummy_data_param\', index=19,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.V1LayerParameter.eltwise_param\', index=20,\n      number=24, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.V1LayerParameter.exp_param\', index=21,\n      number=41, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.V1LayerParameter.hdf5_data_param\', index=22,\n      number=13, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V1LayerParameter.hdf5_output_param\', index=23,\n      number=14, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.V1LayerParameter.hinge_loss_param\', index=24,\n      number=29, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.V1LayerParameter.image_data_param\', index=25,\n      number=15, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.V1LayerParameter.infogain_loss_param\', index=26,\n      number=16, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.V1LayerParameter.inner_product_param\', index=27,\n      number=17, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.V1LayerParameter.lrn_param\', index=28,\n      number=18, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.V1LayerParameter.memory_data_param\', index=29,\n      number=22, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.V1LayerParameter.mvn_param\', index=30,\n      number=34, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.V1LayerParameter.pooling_param\', index=31,\n      number=19, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.V1LayerParameter.power_param\', index=32,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.V1LayerParameter.relu_param\', index=33,\n      number=30, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.V1LayerParameter.sigmoid_param\', index=34,\n      number=38, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.V1LayerParameter.softmax_param\', index=35,\n      number=39, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.V1LayerParameter.slice_param\', index=36,\n      number=31, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.V1LayerParameter.tanh_param\', index=37,\n      number=37, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.V1LayerParameter.threshold_param\', index=38,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.V1LayerParameter.window_data_param\', index=39,\n      number=20, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.V1LayerParameter.transform_param\', index=40,\n      number=36, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.V1LayerParameter.loss_param\', index=41,\n      number=42, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'detection_loss_param\', full_name=\'caffe.V1LayerParameter.detection_loss_param\', index=42,\n      number=200, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'eval_detection_param\', full_name=\'caffe.V1LayerParameter.eval_detection_param\', index=43,\n      number=201, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.V1LayerParameter.layer\', index=44,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V1LAYERPARAMETER_LAYERTYPE,\n    _V1LAYERPARAMETER_DIMCHECKMODE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22854,\n  serialized_end=25506,\n)\n\n\n_V0LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V0LayerParameter\',\n  full_name=\'caffe.V0LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V0LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V0LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.V0LayerParameter.num_output\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'biasterm\', full_name=\'caffe.V0LayerParameter.biasterm\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.V0LayerParameter.weight_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.V0LayerParameter.bias_filler\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.V0LayerParameter.pad\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernelsize\', full_name=\'caffe.V0LayerParameter.kernelsize\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.V0LayerParameter.group\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.V0LayerParameter.stride\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.V0LayerParameter.pool\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.V0LayerParameter.dropout_ratio\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.V0LayerParameter.local_size\', index=12,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.V0LayerParameter.alpha\', index=13,\n      number=14, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.V0LayerParameter.beta\', index=14,\n      number=15, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.75),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.V0LayerParameter.k\', index=15,\n      number=22, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.V0LayerParameter.source\', index=16,\n      number=16, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.V0LayerParameter.scale\', index=17,\n      number=17, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'meanfile\', full_name=\'caffe.V0LayerParameter.meanfile\', index=18,\n      number=18, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'batchsize\', full_name=\'caffe.V0LayerParameter.batchsize\', index=19,\n      number=19, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'cropsize\', full_name=\'caffe.V0LayerParameter.cropsize\', index=20,\n      number=20, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.V0LayerParameter.mirror\', index=21,\n      number=21, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V0LayerParameter.blobs\', index=22,\n      number=50, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V0LayerParameter.blobs_lr\', index=23,\n      number=51, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V0LayerParameter.weight_decay\', index=24,\n      number=52, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.V0LayerParameter.rand_skip\', index=25,\n      number=53, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_threshold\', full_name=\'caffe.V0LayerParameter.det_fg_threshold\', index=26,\n      number=54, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'det_bg_threshold\', full_name=\'caffe.V0LayerParameter.det_bg_threshold\', index=27,\n      number=55, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_fraction\', full_name=\'caffe.V0LayerParameter.det_fg_fraction\', index=28,\n      number=56, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.25),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'det_context_pad\', full_name=\'caffe.V0LayerParameter.det_context_pad\', index=29,\n      number=58, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'det_crop_mode\', full_name=\'caffe.V0LayerParameter.det_crop_mode\', index=30,\n      number=59, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""warp"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'new_num\', full_name=\'caffe.V0LayerParameter.new_num\', index=31,\n      number=60, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'new_channels\', full_name=\'caffe.V0LayerParameter.new_channels\', index=32,\n      number=61, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.V0LayerParameter.new_height\', index=33,\n      number=62, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.V0LayerParameter.new_width\', index=34,\n      number=63, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle_images\', full_name=\'caffe.V0LayerParameter.shuffle_images\', index=35,\n      number=64, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.V0LayerParameter.concat_dim\', index=36,\n      number=65, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V0LayerParameter.hdf5_output_param\', index=37,\n      number=1001, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V0LAYERPARAMETER_POOLMETHOD,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=25509,\n  serialized_end=26530,\n)\n\n\n_PRELUPARAMETER = _descriptor.Descriptor(\n  name=\'PReLUParameter\',\n  full_name=\'caffe.PReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.PReLUParameter.filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'channel_shared\', full_name=\'caffe.PReLUParameter.channel_shared\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=26532,\n  serialized_end=26619,\n)\n\n\n_RPNPARAMETER = _descriptor.Descriptor(\n  name=\'RPNParameter\',\n  full_name=\'caffe.RPNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'feat_stride\', full_name=\'caffe.RPNParameter.feat_stride\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'basesize\', full_name=\'caffe.RPNParameter.basesize\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.RPNParameter.scale\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ratio\', full_name=\'caffe.RPNParameter.ratio\', index=3,\n      number=4, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'boxminsize\', full_name=\'caffe.RPNParameter.boxminsize\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'per_nms_topn\', full_name=\'caffe.RPNParameter.per_nms_topn\', index=5,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'post_nms_topn\', full_name=\'caffe.RPNParameter.post_nms_topn\', index=6,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'nms_thresh\', full_name=\'caffe.RPNParameter.nms_thresh\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=26622,\n  serialized_end=26790,\n)\n\n\n_VIDEODATAPARAMETER = _descriptor.Descriptor(\n  name=\'VideoDataParameter\',\n  full_name=\'caffe.VideoDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'video_type\', full_name=\'caffe.VideoDataParameter.video_type\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'device_id\', full_name=\'caffe.VideoDataParameter.device_id\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'video_file\', full_name=\'caffe.VideoDataParameter.video_file\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'skip_frames\', full_name=\'caffe.VideoDataParameter.skip_frames\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _VIDEODATAPARAMETER_VIDEOTYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=26793,\n  serialized_end=26980,\n)\n\n\n_CENTERLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'CenterLossParameter\',\n  full_name=\'caffe.CenterLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.CenterLossParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'center_filler\', full_name=\'caffe.CenterLossParameter.center_filler\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.CenterLossParameter.axis\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=26982,\n  serialized_end=27087,\n)\n\n\n_MARGININNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'MarginInnerProductParameter\',\n  full_name=\'caffe.MarginInnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.MarginInnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.MarginInnerProductParameter.type\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.MarginInnerProductParameter.weight_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.MarginInnerProductParameter.axis\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.MarginInnerProductParameter.base\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.MarginInnerProductParameter.gamma\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.MarginInnerProductParameter.power\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'iteration\', full_name=\'caffe.MarginInnerProductParameter.iteration\', index=7,\n      number=8, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'lambda_min\', full_name=\'caffe.MarginInnerProductParameter.lambda_min\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _MARGININNERPRODUCTPARAMETER_MARGINTYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=27090,\n  serialized_end=27435,\n)\n\n\n_ADDITIVEMARGININNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'AdditiveMarginInnerProductParameter\',\n  full_name=\'caffe.AdditiveMarginInnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.AdditiveMarginInnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.AdditiveMarginInnerProductParameter.weight_filler\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'m\', full_name=\'caffe.AdditiveMarginInnerProductParameter.m\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.35),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.AdditiveMarginInnerProductParameter.axis\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=27438,\n  serialized_end=27576,\n)\n\n\n_DEFORMABLECONVOLUTIONPARAMETER = _descriptor.Descriptor(\n  name=\'DeformableConvolutionParameter\',\n  full_name=\'caffe.DeformableConvolutionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.DeformableConvolutionParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.DeformableConvolutionParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.DeformableConvolutionParameter.pad\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.DeformableConvolutionParameter.kernel_size\', index=3,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.DeformableConvolutionParameter.stride\', index=4,\n      number=6, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dilation\', full_name=\'caffe.DeformableConvolutionParameter.dilation\', index=5,\n      number=18, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.DeformableConvolutionParameter.pad_h\', index=6,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.DeformableConvolutionParameter.pad_w\', index=7,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.DeformableConvolutionParameter.kernel_h\', index=8,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.DeformableConvolutionParameter.kernel_w\', index=9,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.DeformableConvolutionParameter.stride_h\', index=10,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.DeformableConvolutionParameter.stride_w\', index=11,\n      number=14, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.DeformableConvolutionParameter.group\', index=12,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'deformable_group\', full_name=\'caffe.DeformableConvolutionParameter.deformable_group\', index=13,\n      number=25, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.DeformableConvolutionParameter.weight_filler\', index=14,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.DeformableConvolutionParameter.bias_filler\', index=15,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.DeformableConvolutionParameter.engine\', index=16,\n      number=15, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.DeformableConvolutionParameter.axis\', index=17,\n      number=16, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'force_nd_im2col\', full_name=\'caffe.DeformableConvolutionParameter.force_nd_im2col\', index=18,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _DEFORMABLECONVOLUTIONPARAMETER_ENGINE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=27579,\n  serialized_end=28136,\n)\n\n\n_LABELSPECIFICADDPARAMETER = _descriptor.Descriptor(\n  name=\'LabelSpecificAddParameter\',\n  full_name=\'caffe.LabelSpecificAddParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bias\', full_name=\'caffe.LabelSpecificAddParameter.bias\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'transform_test\', full_name=\'caffe.LabelSpecificAddParameter.transform_test\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=28138,\n  serialized_end=28213,\n)\n\n\n_CHANNELSCALEPARAMETER = _descriptor.Descriptor(\n  name=\'ChannelScaleParameter\',\n  full_name=\'caffe.ChannelScaleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'do_forward\', full_name=\'caffe.ChannelScaleParameter.do_forward\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'do_backward_feature\', full_name=\'caffe.ChannelScaleParameter.do_backward_feature\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'do_backward_scale\', full_name=\'caffe.ChannelScaleParameter.do_backward_scale\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'global_scale\', full_name=\'caffe.ChannelScaleParameter.global_scale\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_global_scale\', full_name=\'caffe.ChannelScaleParameter.max_global_scale\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1000),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min_global_scale\', full_name=\'caffe.ChannelScaleParameter.min_global_scale\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'init_global_scale\', full_name=\'caffe.ChannelScaleParameter.init_global_scale\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=28216,\n  serialized_end=28453,\n)\n\n\n_COSINADDMPARAMETER = _descriptor.Descriptor(\n  name=\'CosinAddmParameter\',\n  full_name=\'caffe.CosinAddmParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'m\', full_name=\'caffe.CosinAddmParameter.m\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'transform_test\', full_name=\'caffe.CosinAddmParameter.transform_test\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=28455,\n  serialized_end=28522,\n)\n\n\n_COSINMULMPARAMETER = _descriptor.Descriptor(\n  name=\'CosinMulmParameter\',\n  full_name=\'caffe.CosinMulmParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'m\', full_name=\'caffe.CosinMulmParameter.m\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(4),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'transform_test\', full_name=\'caffe.CosinMulmParameter.transform_test\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=28524,\n  serialized_end=28589,\n)\n\n\n_COUPLEDCLUSTERLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'CoupledClusterLossParameter\',\n  full_name=\'caffe.CoupledClusterLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.CoupledClusterLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'group_size\', full_name=\'caffe.CoupledClusterLossParameter.group_size\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=3,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.CoupledClusterLossParameter.scale\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'log_flag\', full_name=\'caffe.CoupledClusterLossParameter.log_flag\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=28591,\n  serialized_end=28705,\n)\n\n\n_TRIPLETLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'TripletLossParameter\',\n  full_name=\'caffe.TripletLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.TripletLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'group_size\', full_name=\'caffe.TripletLossParameter.group_size\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=3,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.TripletLossParameter.scale\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=28707,\n  serialized_end=28789,\n)\n\n\n_GENERALTRIPLETPARAMETER = _descriptor.Descriptor(\n  name=\'GeneralTripletParameter\',\n  full_name=\'caffe.GeneralTripletParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.GeneralTripletParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.2),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'add_center_loss\', full_name=\'caffe.GeneralTripletParameter.add_center_loss\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hardest_only\', full_name=\'caffe.GeneralTripletParameter.hardest_only\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'positive_first\', full_name=\'caffe.GeneralTripletParameter.positive_first\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'positive_upper_bound\', full_name=\'caffe.GeneralTripletParameter.positive_upper_bound\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'positive_weight\', full_name=\'caffe.GeneralTripletParameter.positive_weight\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'negative_weight\', full_name=\'caffe.GeneralTripletParameter.negative_weight\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=28792,\n  serialized_end=29018,\n)\n\n\n_ROIALIGNPARAMETER = _descriptor.Descriptor(\n  name=\'ROIAlignParameter\',\n  full_name=\'caffe.ROIAlignParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pooled_h\', full_name=\'caffe.ROIAlignParameter.pooled_h\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pooled_w\', full_name=\'caffe.ROIAlignParameter.pooled_w\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'spatial_scale\', full_name=\'caffe.ROIAlignParameter.spatial_scale\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=29020,\n  serialized_end=29107,\n)\n\n_BLOBPROTO.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_BLOBPROTOVECTOR.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_LABELMAP.fields_by_name[\'item\'].message_type = _LABELMAPITEM\n_BATCHSAMPLER.fields_by_name[\'sampler\'].message_type = _SAMPLER\n_BATCHSAMPLER.fields_by_name[\'sample_constraint\'].message_type = _SAMPLECONSTRAINT\n_EMITCONSTRAINT.fields_by_name[\'emit_type\'].enum_type = _EMITCONSTRAINT_EMITTYPE\n_EMITCONSTRAINT_EMITTYPE.containing_type = _EMITCONSTRAINT\n_ANNOTATION.fields_by_name[\'bbox\'].message_type = _NORMALIZEDBBOX\n_ANNOTATIONGROUP.fields_by_name[\'annotation\'].message_type = _ANNOTATION\n_ANNOTATEDDATUM.fields_by_name[\'datum\'].message_type = _DATUM\n_ANNOTATEDDATUM.fields_by_name[\'type\'].enum_type = _ANNOTATEDDATUM_ANNOTATIONTYPE\n_ANNOTATEDDATUM.fields_by_name[\'annotation_group\'].message_type = _ANNOTATIONGROUP\n_ANNOTATEDDATUM_ANNOTATIONTYPE.containing_type = _ANNOTATEDDATUM\n_MTCNNDATUM.fields_by_name[\'datum\'].message_type = _DATUM\n_MTCNNDATUM.fields_by_name[\'roi\'].message_type = _MTCNNBBOX\n_FILLERPARAMETER.fields_by_name[\'variance_norm\'].enum_type = _FILLERPARAMETER_VARIANCENORM\n_FILLERPARAMETER_VARIANCENORM.containing_type = _FILLERPARAMETER\n_NETPARAMETER.fields_by_name[\'input_shape\'].message_type = _BLOBSHAPE\n_NETPARAMETER.fields_by_name[\'state\'].message_type = _NETSTATE\n_NETPARAMETER.fields_by_name[\'layer\'].message_type = _LAYERPARAMETER\n_NETPARAMETER.fields_by_name[\'layers\'].message_type = _V1LAYERPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'test_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'test_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'snapshot_format\'].enum_type = _SOLVERPARAMETER_SNAPSHOTFORMAT\n_SOLVERPARAMETER.fields_by_name[\'solver_mode\'].enum_type = _SOLVERPARAMETER_SOLVERMODE\n_SOLVERPARAMETER.fields_by_name[\'solver_type\'].enum_type = _SOLVERPARAMETER_SOLVERTYPE\n_SOLVERPARAMETER_SNAPSHOTFORMAT.containing_type = _SOLVERPARAMETER\n_SOLVERPARAMETER_SOLVERMODE.containing_type = _SOLVERPARAMETER\n_SOLVERPARAMETER_SOLVERTYPE.containing_type = _SOLVERPARAMETER\n_SOLVERSTATE.fields_by_name[\'history\'].message_type = _BLOBPROTO\n_NETSTATE.fields_by_name[\'phase\'].enum_type = _PHASE\n_NETSTATERULE.fields_by_name[\'phase\'].enum_type = _PHASE\n_PARAMSPEC.fields_by_name[\'share_mode\'].enum_type = _PARAMSPEC_DIMCHECKMODE\n_PARAMSPEC_DIMCHECKMODE.containing_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'phase\'].enum_type = _PHASE\n_LAYERPARAMETER.fields_by_name[\'param\'].message_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'detection_loss_param\'].message_type = _DETECTIONLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'eval_detection_param\'].message_type = _EVALDETECTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'region_loss_param\'].message_type = _REGIONLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reorg_param\'].message_type = _REORGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'batch_norm_param\'].message_type = _BATCHNORMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bias_param\'].message_type = _BIASPARAMETER\n_LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'elu_param\'].message_type = _ELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'embed_param\'].message_type = _EMBEDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'flatten_param\'].message_type = _FLATTENPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'input_param\'].message_type = _INPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'log_param\'].message_type = _LOGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'prelu_param\'].message_type = _PRELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'python_param\'].message_type = _PYTHONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'recurrent_param\'].message_type = _RECURRENTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reduction_param\'].message_type = _REDUCTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reshape_param\'].message_type = _RESHAPEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'roi_pooling_param\'].message_type = _ROIPOOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'scale_param\'].message_type = _SCALEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'smooth_l1_loss_param\'].message_type = _SMOOTHL1LOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'spp_param\'].message_type = _SPPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tile_param\'].message_type = _TILEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'st_param\'].message_type = _SPATIALTRANSFORMERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'st_loss_param\'].message_type = _STLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'rpn_param\'].message_type = _RPNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'focal_loss_param\'].message_type = _FOCALLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'asdn_data_param\'].message_type = _ASDNDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bn_param\'].message_type = _BNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mtcnn_data_param\'].message_type = _MTCNNDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'interp_param\'].message_type = _INTERPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'psroi_pooling_param\'].message_type = _PSROIPOOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'annotated_data_param\'].message_type = _ANNOTATEDDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'prior_box_param\'].message_type = _PRIORBOXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'crop_param\'].message_type = _CROPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'detection_evaluate_param\'].message_type = _DETECTIONEVALUATEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'detection_output_param\'].message_type = _DETECTIONOUTPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'multibox_loss_param\'].message_type = _MULTIBOXLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'permute_param\'].message_type = _PERMUTEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'video_data_param\'].message_type = _VIDEODATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'margin_inner_product_param\'].message_type = _MARGININNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'center_loss_param\'].message_type = _CENTERLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'deformable_convolution_param\'].message_type = _DEFORMABLECONVOLUTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'label_specific_add_param\'].message_type = _LABELSPECIFICADDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'additive_margin_inner_product_param\'].message_type = _ADDITIVEMARGININNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'cosin_add_m_param\'].message_type = _COSINADDMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'cosin_mul_m_param\'].message_type = _COSINMULMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'channel_scale_param\'].message_type = _CHANNELSCALEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'flip_param\'].message_type = _FLIPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'triplet_loss_param\'].message_type = _TRIPLETLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'coupled_cluster_loss_param\'].message_type = _COUPLEDCLUSTERLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'general_triplet_loss_param\'].message_type = _GENERALTRIPLETPARAMETER\n_LAYERPARAMETER.fields_by_name[\'roi_align_param\'].message_type = _ROIALIGNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'upsample_param\'].message_type = _UPSAMPLEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'matmul_param\'].message_type = _MATMULPARAMETER\n_LAYERPARAMETER.fields_by_name[\'pass_through_param\'].message_type = _PASSTHROUGHPARAMETER\n_LAYERPARAMETER.fields_by_name[\'norm_param\'].message_type = _NORMALIZEPARAMETER\n_NORMALIZEPARAMETER.fields_by_name[\'scale_filler\'].message_type = _FILLERPARAMETER\n_ANNOTATEDDATAPARAMETER.fields_by_name[\'batch_sampler\'].message_type = _BATCHSAMPLER\n_ANNOTATEDDATAPARAMETER.fields_by_name[\'anno_type\'].enum_type = _ANNOTATEDDATUM_ANNOTATIONTYPE\n_BNPARAMETER.fields_by_name[\'slope_filler\'].message_type = _FILLERPARAMETER\n_BNPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_BNPARAMETER.fields_by_name[\'engine\'].enum_type = _BNPARAMETER_ENGINE\n_BNPARAMETER_ENGINE.containing_type = _BNPARAMETER\n_FOCALLOSSPARAMETER.fields_by_name[\'type\'].enum_type = _FOCALLOSSPARAMETER_TYPE\n_FOCALLOSSPARAMETER_TYPE.containing_type = _FOCALLOSSPARAMETER\n_TRANSFORMATIONPARAMETER.fields_by_name[\'resize_param\'].message_type = _RESIZEPARAMETER\n_TRANSFORMATIONPARAMETER.fields_by_name[\'noise_param\'].message_type = _NOISEPARAMETER\n_TRANSFORMATIONPARAMETER.fields_by_name[\'distort_param\'].message_type = _DISTORTIONPARAMETER\n_TRANSFORMATIONPARAMETER.fields_by_name[\'expand_param\'].message_type = _EXPANSIONPARAMETER\n_TRANSFORMATIONPARAMETER.fields_by_name[\'emit_constraint\'].message_type = _EMITCONSTRAINT\n_RESIZEPARAMETER.fields_by_name[\'resize_mode\'].enum_type = _RESIZEPARAMETER_RESIZE_MODE\n_RESIZEPARAMETER.fields_by_name[\'pad_mode\'].enum_type = _RESIZEPARAMETER_PAD_MODE\n_RESIZEPARAMETER.fields_by_name[\'interp_mode\'].enum_type = _RESIZEPARAMETER_INTERP_MODE\n_RESIZEPARAMETER_RESIZE_MODE.containing_type = _RESIZEPARAMETER\n_RESIZEPARAMETER_PAD_MODE.containing_type = _RESIZEPARAMETER\n_RESIZEPARAMETER_INTERP_MODE.containing_type = _RESIZEPARAMETER\n_NOISEPARAMETER.fields_by_name[\'saltpepper_param\'].message_type = _SALTPEPPERPARAMETER\n_LOSSPARAMETER.fields_by_name[\'normalization\'].enum_type = _LOSSPARAMETER_NORMALIZATIONMODE\n_LOSSPARAMETER_NORMALIZATIONMODE.containing_type = _LOSSPARAMETER\n_BIASPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_EVALDETECTIONPARAMETER.fields_by_name[\'score_type\'].enum_type = _EVALDETECTIONPARAMETER_SCORETYPE\n_EVALDETECTIONPARAMETER_SCORETYPE.containing_type = _EVALDETECTIONPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'engine\'].enum_type = _CONVOLUTIONPARAMETER_ENGINE\n_CONVOLUTIONPARAMETER_ENGINE.containing_type = _CONVOLUTIONPARAMETER\n_DATAPARAMETER.fields_by_name[\'backend\'].enum_type = _DATAPARAMETER_DB\n_DATAPARAMETER_DB.containing_type = _DATAPARAMETER\n_DETECTIONEVALUATEPARAMETER.fields_by_name[\'resize_param\'].message_type = _RESIZEPARAMETER\n_SAVEOUTPUTPARAMETER.fields_by_name[\'resize_param\'].message_type = _RESIZEPARAMETER\n_DETECTIONOUTPUTPARAMETER.fields_by_name[\'nms_param\'].message_type = _NONMAXIMUMSUPPRESSIONPARAMETER\n_DETECTIONOUTPUTPARAMETER.fields_by_name[\'save_output_param\'].message_type = _SAVEOUTPUTPARAMETER\n_DETECTIONOUTPUTPARAMETER.fields_by_name[\'code_type\'].enum_type = _PRIORBOXPARAMETER_CODETYPE\n_DUMMYDATAPARAMETER.fields_by_name[\'data_filler\'].message_type = _FILLERPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_ELTWISEPARAMETER.fields_by_name[\'operation\'].enum_type = _ELTWISEPARAMETER_ELTWISEOP\n_ELTWISEPARAMETER_ELTWISEOP.containing_type = _ELTWISEPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_HINGELOSSPARAMETER.fields_by_name[\'norm\'].enum_type = _HINGELOSSPARAMETER_NORM\n_HINGELOSSPARAMETER_NORM.containing_type = _HINGELOSSPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_INPUTPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_LRNPARAMETER.fields_by_name[\'norm_region\'].enum_type = _LRNPARAMETER_NORMREGION\n_LRNPARAMETER.fields_by_name[\'engine\'].enum_type = _LRNPARAMETER_ENGINE\n_LRNPARAMETER_NORMREGION.containing_type = _LRNPARAMETER\n_LRNPARAMETER_ENGINE.containing_type = _LRNPARAMETER\n_MULTIBOXLOSSPARAMETER.fields_by_name[\'loc_loss_type\'].enum_type = _MULTIBOXLOSSPARAMETER_LOCLOSSTYPE\n_MULTIBOXLOSSPARAMETER.fields_by_name[\'conf_loss_type\'].enum_type = _MULTIBOXLOSSPARAMETER_CONFLOSSTYPE\n_MULTIBOXLOSSPARAMETER.fields_by_name[\'match_type\'].enum_type = _MULTIBOXLOSSPARAMETER_MATCHTYPE\n_MULTIBOXLOSSPARAMETER.fields_by_name[\'code_type\'].enum_type = _PRIORBOXPARAMETER_CODETYPE\n_MULTIBOXLOSSPARAMETER.fields_by_name[\'mining_type\'].enum_type = _MULTIBOXLOSSPARAMETER_MININGTYPE\n_MULTIBOXLOSSPARAMETER.fields_by_name[\'nms_param\'].message_type = _NONMAXIMUMSUPPRESSIONPARAMETER\n_MULTIBOXLOSSPARAMETER_LOCLOSSTYPE.containing_type = _MULTIBOXLOSSPARAMETER\n_MULTIBOXLOSSPARAMETER_CONFLOSSTYPE.containing_type = _MULTIBOXLOSSPARAMETER\n_MULTIBOXLOSSPARAMETER_MATCHTYPE.containing_type = _MULTIBOXLOSSPARAMETER\n_MULTIBOXLOSSPARAMETER_MININGTYPE.containing_type = _MULTIBOXLOSSPARAMETER\n_PARAMETERPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_POOLINGPARAMETER.fields_by_name[\'pool\'].enum_type = _POOLINGPARAMETER_POOLMETHOD\n_POOLINGPARAMETER.fields_by_name[\'engine\'].enum_type = _POOLINGPARAMETER_ENGINE\n_POOLINGPARAMETER_POOLMETHOD.containing_type = _POOLINGPARAMETER\n_POOLINGPARAMETER_ENGINE.containing_type = _POOLINGPARAMETER\n_PRIORBOXPARAMETER_CODETYPE.containing_type = _PRIORBOXPARAMETER\n_RECURRENTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_RECURRENTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_REDUCTIONPARAMETER.fields_by_name[\'operation\'].enum_type = _REDUCTIONPARAMETER_REDUCTIONOP\n_REDUCTIONPARAMETER_REDUCTIONOP.containing_type = _REDUCTIONPARAMETER\n_RELUPARAMETER.fields_by_name[\'engine\'].enum_type = _RELUPARAMETER_ENGINE\n_RELUPARAMETER_ENGINE.containing_type = _RELUPARAMETER\n_RESHAPEPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_SCALEPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_SCALEPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_SIGMOIDPARAMETER.fields_by_name[\'engine\'].enum_type = _SIGMOIDPARAMETER_ENGINE\n_SIGMOIDPARAMETER_ENGINE.containing_type = _SIGMOIDPARAMETER\n_SOFTMAXPARAMETER.fields_by_name[\'engine\'].enum_type = _SOFTMAXPARAMETER_ENGINE\n_SOFTMAXPARAMETER_ENGINE.containing_type = _SOFTMAXPARAMETER\n_TANHPARAMETER.fields_by_name[\'engine\'].enum_type = _TANHPARAMETER_ENGINE\n_TANHPARAMETER_ENGINE.containing_type = _TANHPARAMETER\n_SPPPARAMETER.fields_by_name[\'pool\'].enum_type = _SPPPARAMETER_POOLMETHOD\n_SPPPARAMETER.fields_by_name[\'engine\'].enum_type = _SPPPARAMETER_ENGINE\n_SPPPARAMETER_POOLMETHOD.containing_type = _SPPPARAMETER\n_SPPPARAMETER_ENGINE.containing_type = _SPPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'type\'].enum_type = _V1LAYERPARAMETER_LAYERTYPE\n_V1LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V1LAYERPARAMETER.fields_by_name[\'blob_share_mode\'].enum_type = _V1LAYERPARAMETER_DIMCHECKMODE\n_V1LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'detection_loss_param\'].message_type = _DETECTIONLOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'eval_detection_param\'].message_type = _EVALDETECTIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'layer\'].message_type = _V0LAYERPARAMETER\n_V1LAYERPARAMETER_LAYERTYPE.containing_type = _V1LAYERPARAMETER\n_V1LAYERPARAMETER_DIMCHECKMODE.containing_type = _V1LAYERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'pool\'].enum_type = _V0LAYERPARAMETER_POOLMETHOD\n_V0LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V0LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V0LAYERPARAMETER_POOLMETHOD.containing_type = _V0LAYERPARAMETER\n_PRELUPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_VIDEODATAPARAMETER.fields_by_name[\'video_type\'].enum_type = _VIDEODATAPARAMETER_VIDEOTYPE\n_VIDEODATAPARAMETER_VIDEOTYPE.containing_type = _VIDEODATAPARAMETER\n_CENTERLOSSPARAMETER.fields_by_name[\'center_filler\'].message_type = _FILLERPARAMETER\n_MARGININNERPRODUCTPARAMETER.fields_by_name[\'type\'].enum_type = _MARGININNERPRODUCTPARAMETER_MARGINTYPE\n_MARGININNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_MARGININNERPRODUCTPARAMETER_MARGINTYPE.containing_type = _MARGININNERPRODUCTPARAMETER\n_ADDITIVEMARGININNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_DEFORMABLECONVOLUTIONPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_DEFORMABLECONVOLUTIONPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_DEFORMABLECONVOLUTIONPARAMETER.fields_by_name[\'engine\'].enum_type = _DEFORMABLECONVOLUTIONPARAMETER_ENGINE\n_DEFORMABLECONVOLUTIONPARAMETER_ENGINE.containing_type = _DEFORMABLECONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'BlobShape\'] = _BLOBSHAPE\nDESCRIPTOR.message_types_by_name[\'BlobProto\'] = _BLOBPROTO\nDESCRIPTOR.message_types_by_name[\'BlobProtoVector\'] = _BLOBPROTOVECTOR\nDESCRIPTOR.message_types_by_name[\'Datum\'] = _DATUM\nDESCRIPTOR.message_types_by_name[\'LabelMapItem\'] = _LABELMAPITEM\nDESCRIPTOR.message_types_by_name[\'LabelMap\'] = _LABELMAP\nDESCRIPTOR.message_types_by_name[\'Sampler\'] = _SAMPLER\nDESCRIPTOR.message_types_by_name[\'SampleConstraint\'] = _SAMPLECONSTRAINT\nDESCRIPTOR.message_types_by_name[\'BatchSampler\'] = _BATCHSAMPLER\nDESCRIPTOR.message_types_by_name[\'EmitConstraint\'] = _EMITCONSTRAINT\nDESCRIPTOR.message_types_by_name[\'NormalizedBBox\'] = _NORMALIZEDBBOX\nDESCRIPTOR.message_types_by_name[\'Annotation\'] = _ANNOTATION\nDESCRIPTOR.message_types_by_name[\'AnnotationGroup\'] = _ANNOTATIONGROUP\nDESCRIPTOR.message_types_by_name[\'AnnotatedDatum\'] = _ANNOTATEDDATUM\nDESCRIPTOR.message_types_by_name[\'MTCNNBBox\'] = _MTCNNBBOX\nDESCRIPTOR.message_types_by_name[\'MTCNNDatum\'] = _MTCNNDATUM\nDESCRIPTOR.message_types_by_name[\'FillerParameter\'] = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'NetParameter\'] = _NETPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverParameter\'] = _SOLVERPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverState\'] = _SOLVERSTATE\nDESCRIPTOR.message_types_by_name[\'NetState\'] = _NETSTATE\nDESCRIPTOR.message_types_by_name[\'NetStateRule\'] = _NETSTATERULE\nDESCRIPTOR.message_types_by_name[\'SpatialTransformerParameter\'] = _SPATIALTRANSFORMERPARAMETER\nDESCRIPTOR.message_types_by_name[\'STLossParameter\'] = _STLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ParamSpec\'] = _PARAMSPEC\nDESCRIPTOR.message_types_by_name[\'LayerParameter\'] = _LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'UpsampleParameter\'] = _UPSAMPLEPARAMETER\nDESCRIPTOR.message_types_by_name[\'MatMulParameter\'] = _MATMULPARAMETER\nDESCRIPTOR.message_types_by_name[\'PassThroughParameter\'] = _PASSTHROUGHPARAMETER\nDESCRIPTOR.message_types_by_name[\'NormalizeParameter\'] = _NORMALIZEPARAMETER\nDESCRIPTOR.message_types_by_name[\'AnnotatedDataParameter\'] = _ANNOTATEDDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'AsdnDataParameter\'] = _ASDNDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'MTCNNDataParameter\'] = _MTCNNDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'InterpParameter\'] = _INTERPPARAMETER\nDESCRIPTOR.message_types_by_name[\'PSROIPoolingParameter\'] = _PSROIPOOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'FlipParameter\'] = _FLIPPARAMETER\nDESCRIPTOR.message_types_by_name[\'BNParameter\'] = _BNPARAMETER\nDESCRIPTOR.message_types_by_name[\'FocalLossParameter\'] = _FOCALLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'TransformationParameter\'] = _TRANSFORMATIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ResizeParameter\'] = _RESIZEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SaltPepperParameter\'] = _SALTPEPPERPARAMETER\nDESCRIPTOR.message_types_by_name[\'NoiseParameter\'] = _NOISEPARAMETER\nDESCRIPTOR.message_types_by_name[\'DistortionParameter\'] = _DISTORTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ExpansionParameter\'] = _EXPANSIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'LossParameter\'] = _LOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'AccuracyParameter\'] = _ACCURACYPARAMETER\nDESCRIPTOR.message_types_by_name[\'ArgMaxParameter\'] = _ARGMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConcatParameter\'] = _CONCATPARAMETER\nDESCRIPTOR.message_types_by_name[\'BatchNormParameter\'] = _BATCHNORMPARAMETER\nDESCRIPTOR.message_types_by_name[\'BiasParameter\'] = _BIASPARAMETER\nDESCRIPTOR.message_types_by_name[\'ContrastiveLossParameter\'] = _CONTRASTIVELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'DetectionLossParameter\'] = _DETECTIONLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'RegionLossParameter\'] = _REGIONLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReorgParameter\'] = _REORGPARAMETER\nDESCRIPTOR.message_types_by_name[\'EvalDetectionParameter\'] = _EVALDETECTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConvolutionParameter\'] = _CONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'CropParameter\'] = _CROPPARAMETER\nDESCRIPTOR.message_types_by_name[\'DataParameter\'] = _DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'DetectionEvaluateParameter\'] = _DETECTIONEVALUATEPARAMETER\nDESCRIPTOR.message_types_by_name[\'NonMaximumSuppressionParameter\'] = _NONMAXIMUMSUPPRESSIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'SaveOutputParameter\'] = _SAVEOUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DetectionOutputParameter\'] = _DETECTIONOUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DropoutParameter\'] = _DROPOUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DummyDataParameter\'] = _DUMMYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'EltwiseParameter\'] = _ELTWISEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ELUParameter\'] = _ELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'EmbedParameter\'] = _EMBEDPARAMETER\nDESCRIPTOR.message_types_by_name[\'ExpParameter\'] = _EXPPARAMETER\nDESCRIPTOR.message_types_by_name[\'FlattenParameter\'] = _FLATTENPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5DataParameter\'] = _HDF5DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5OutputParameter\'] = _HDF5OUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'HingeLossParameter\'] = _HINGELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ImageDataParameter\'] = _IMAGEDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'InfogainLossParameter\'] = _INFOGAINLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'InnerProductParameter\'] = _INNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'InputParameter\'] = _INPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'LogParameter\'] = _LOGPARAMETER\nDESCRIPTOR.message_types_by_name[\'LRNParameter\'] = _LRNPARAMETER\nDESCRIPTOR.message_types_by_name[\'MemoryDataParameter\'] = _MEMORYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'MultiBoxLossParameter\'] = _MULTIBOXLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'PermuteParameter\'] = _PERMUTEPARAMETER\nDESCRIPTOR.message_types_by_name[\'MVNParameter\'] = _MVNPARAMETER\nDESCRIPTOR.message_types_by_name[\'ParameterParameter\'] = _PARAMETERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PoolingParameter\'] = _POOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'PowerParameter\'] = _POWERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PriorBoxParameter\'] = _PRIORBOXPARAMETER\nDESCRIPTOR.message_types_by_name[\'PythonParameter\'] = _PYTHONPARAMETER\nDESCRIPTOR.message_types_by_name[\'RecurrentParameter\'] = _RECURRENTPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReductionParameter\'] = _REDUCTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReLUParameter\'] = _RELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReshapeParameter\'] = _RESHAPEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ROIPoolingParameter\'] = _ROIPOOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'ScaleParameter\'] = _SCALEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SigmoidParameter\'] = _SIGMOIDPARAMETER\nDESCRIPTOR.message_types_by_name[\'SmoothL1LossParameter\'] = _SMOOTHL1LOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'SliceParameter\'] = _SLICEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SoftmaxParameter\'] = _SOFTMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'TanHParameter\'] = _TANHPARAMETER\nDESCRIPTOR.message_types_by_name[\'TileParameter\'] = _TILEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ThresholdParameter\'] = _THRESHOLDPARAMETER\nDESCRIPTOR.message_types_by_name[\'WindowDataParameter\'] = _WINDOWDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'SPPParameter\'] = _SPPPARAMETER\nDESCRIPTOR.message_types_by_name[\'V1LayerParameter\'] = _V1LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'V0LayerParameter\'] = _V0LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PReLUParameter\'] = _PRELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'RPNParameter\'] = _RPNPARAMETER\nDESCRIPTOR.message_types_by_name[\'VideoDataParameter\'] = _VIDEODATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'CenterLossParameter\'] = _CENTERLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'MarginInnerProductParameter\'] = _MARGININNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'AdditiveMarginInnerProductParameter\'] = _ADDITIVEMARGININNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DeformableConvolutionParameter\'] = _DEFORMABLECONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'LabelSpecificAddParameter\'] = _LABELSPECIFICADDPARAMETER\nDESCRIPTOR.message_types_by_name[\'ChannelScaleParameter\'] = _CHANNELSCALEPARAMETER\nDESCRIPTOR.message_types_by_name[\'CosinAddmParameter\'] = _COSINADDMPARAMETER\nDESCRIPTOR.message_types_by_name[\'CosinMulmParameter\'] = _COSINMULMPARAMETER\nDESCRIPTOR.message_types_by_name[\'CoupledClusterLossParameter\'] = _COUPLEDCLUSTERLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'TripletLossParameter\'] = _TRIPLETLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'GeneralTripletParameter\'] = _GENERALTRIPLETPARAMETER\nDESCRIPTOR.message_types_by_name[\'ROIAlignParameter\'] = _ROIALIGNPARAMETER\nDESCRIPTOR.enum_types_by_name[\'Phase\'] = _PHASE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nBlobShape = _reflection.GeneratedProtocolMessageType(\'BlobShape\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBSHAPE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobShape)\n  ))\n_sym_db.RegisterMessage(BlobShape)\n\nBlobProto = _reflection.GeneratedProtocolMessageType(\'BlobProto\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBPROTO,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobProto)\n  ))\n_sym_db.RegisterMessage(BlobProto)\n\nBlobProtoVector = _reflection.GeneratedProtocolMessageType(\'BlobProtoVector\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBPROTOVECTOR,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobProtoVector)\n  ))\n_sym_db.RegisterMessage(BlobProtoVector)\n\nDatum = _reflection.GeneratedProtocolMessageType(\'Datum\', (_message.Message,), dict(\n  DESCRIPTOR = _DATUM,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.Datum)\n  ))\n_sym_db.RegisterMessage(Datum)\n\nLabelMapItem = _reflection.GeneratedProtocolMessageType(\'LabelMapItem\', (_message.Message,), dict(\n  DESCRIPTOR = _LABELMAPITEM,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LabelMapItem)\n  ))\n_sym_db.RegisterMessage(LabelMapItem)\n\nLabelMap = _reflection.GeneratedProtocolMessageType(\'LabelMap\', (_message.Message,), dict(\n  DESCRIPTOR = _LABELMAP,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LabelMap)\n  ))\n_sym_db.RegisterMessage(LabelMap)\n\nSampler = _reflection.GeneratedProtocolMessageType(\'Sampler\', (_message.Message,), dict(\n  DESCRIPTOR = _SAMPLER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.Sampler)\n  ))\n_sym_db.RegisterMessage(Sampler)\n\nSampleConstraint = _reflection.GeneratedProtocolMessageType(\'SampleConstraint\', (_message.Message,), dict(\n  DESCRIPTOR = _SAMPLECONSTRAINT,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SampleConstraint)\n  ))\n_sym_db.RegisterMessage(SampleConstraint)\n\nBatchSampler = _reflection.GeneratedProtocolMessageType(\'BatchSampler\', (_message.Message,), dict(\n  DESCRIPTOR = _BATCHSAMPLER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BatchSampler)\n  ))\n_sym_db.RegisterMessage(BatchSampler)\n\nEmitConstraint = _reflection.GeneratedProtocolMessageType(\'EmitConstraint\', (_message.Message,), dict(\n  DESCRIPTOR = _EMITCONSTRAINT,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.EmitConstraint)\n  ))\n_sym_db.RegisterMessage(EmitConstraint)\n\nNormalizedBBox = _reflection.GeneratedProtocolMessageType(\'NormalizedBBox\', (_message.Message,), dict(\n  DESCRIPTOR = _NORMALIZEDBBOX,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NormalizedBBox)\n  ))\n_sym_db.RegisterMessage(NormalizedBBox)\n\nAnnotation = _reflection.GeneratedProtocolMessageType(\'Annotation\', (_message.Message,), dict(\n  DESCRIPTOR = _ANNOTATION,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.Annotation)\n  ))\n_sym_db.RegisterMessage(Annotation)\n\nAnnotationGroup = _reflection.GeneratedProtocolMessageType(\'AnnotationGroup\', (_message.Message,), dict(\n  DESCRIPTOR = _ANNOTATIONGROUP,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AnnotationGroup)\n  ))\n_sym_db.RegisterMessage(AnnotationGroup)\n\nAnnotatedDatum = _reflection.GeneratedProtocolMessageType(\'AnnotatedDatum\', (_message.Message,), dict(\n  DESCRIPTOR = _ANNOTATEDDATUM,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AnnotatedDatum)\n  ))\n_sym_db.RegisterMessage(AnnotatedDatum)\n\nMTCNNBBox = _reflection.GeneratedProtocolMessageType(\'MTCNNBBox\', (_message.Message,), dict(\n  DESCRIPTOR = _MTCNNBBOX,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MTCNNBBox)\n  ))\n_sym_db.RegisterMessage(MTCNNBBox)\n\nMTCNNDatum = _reflection.GeneratedProtocolMessageType(\'MTCNNDatum\', (_message.Message,), dict(\n  DESCRIPTOR = _MTCNNDATUM,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MTCNNDatum)\n  ))\n_sym_db.RegisterMessage(MTCNNDatum)\n\nFillerParameter = _reflection.GeneratedProtocolMessageType(\'FillerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _FILLERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.FillerParameter)\n  ))\n_sym_db.RegisterMessage(FillerParameter)\n\nNetParameter = _reflection.GeneratedProtocolMessageType(\'NetParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _NETPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetParameter)\n  ))\n_sym_db.RegisterMessage(NetParameter)\n\nSolverParameter = _reflection.GeneratedProtocolMessageType(\'SolverParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SOLVERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SolverParameter)\n  ))\n_sym_db.RegisterMessage(SolverParameter)\n\nSolverState = _reflection.GeneratedProtocolMessageType(\'SolverState\', (_message.Message,), dict(\n  DESCRIPTOR = _SOLVERSTATE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SolverState)\n  ))\n_sym_db.RegisterMessage(SolverState)\n\nNetState = _reflection.GeneratedProtocolMessageType(\'NetState\', (_message.Message,), dict(\n  DESCRIPTOR = _NETSTATE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetState)\n  ))\n_sym_db.RegisterMessage(NetState)\n\nNetStateRule = _reflection.GeneratedProtocolMessageType(\'NetStateRule\', (_message.Message,), dict(\n  DESCRIPTOR = _NETSTATERULE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetStateRule)\n  ))\n_sym_db.RegisterMessage(NetStateRule)\n\nSpatialTransformerParameter = _reflection.GeneratedProtocolMessageType(\'SpatialTransformerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SPATIALTRANSFORMERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SpatialTransformerParameter)\n  ))\n_sym_db.RegisterMessage(SpatialTransformerParameter)\n\nSTLossParameter = _reflection.GeneratedProtocolMessageType(\'STLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _STLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.STLossParameter)\n  ))\n_sym_db.RegisterMessage(STLossParameter)\n\nParamSpec = _reflection.GeneratedProtocolMessageType(\'ParamSpec\', (_message.Message,), dict(\n  DESCRIPTOR = _PARAMSPEC,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ParamSpec)\n  ))\n_sym_db.RegisterMessage(ParamSpec)\n\nLayerParameter = _reflection.GeneratedProtocolMessageType(\'LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LayerParameter)\n  ))\n_sym_db.RegisterMessage(LayerParameter)\n\nUpsampleParameter = _reflection.GeneratedProtocolMessageType(\'UpsampleParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _UPSAMPLEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.UpsampleParameter)\n  ))\n_sym_db.RegisterMessage(UpsampleParameter)\n\nMatMulParameter = _reflection.GeneratedProtocolMessageType(\'MatMulParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MATMULPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MatMulParameter)\n  ))\n_sym_db.RegisterMessage(MatMulParameter)\n\nPassThroughParameter = _reflection.GeneratedProtocolMessageType(\'PassThroughParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PASSTHROUGHPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PassThroughParameter)\n  ))\n_sym_db.RegisterMessage(PassThroughParameter)\n\nNormalizeParameter = _reflection.GeneratedProtocolMessageType(\'NormalizeParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _NORMALIZEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NormalizeParameter)\n  ))\n_sym_db.RegisterMessage(NormalizeParameter)\n\nAnnotatedDataParameter = _reflection.GeneratedProtocolMessageType(\'AnnotatedDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ANNOTATEDDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AnnotatedDataParameter)\n  ))\n_sym_db.RegisterMessage(AnnotatedDataParameter)\n\nAsdnDataParameter = _reflection.GeneratedProtocolMessageType(\'AsdnDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ASDNDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AsdnDataParameter)\n  ))\n_sym_db.RegisterMessage(AsdnDataParameter)\n\nMTCNNDataParameter = _reflection.GeneratedProtocolMessageType(\'MTCNNDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MTCNNDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MTCNNDataParameter)\n  ))\n_sym_db.RegisterMessage(MTCNNDataParameter)\n\nInterpParameter = _reflection.GeneratedProtocolMessageType(\'InterpParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INTERPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InterpParameter)\n  ))\n_sym_db.RegisterMessage(InterpParameter)\n\nPSROIPoolingParameter = _reflection.GeneratedProtocolMessageType(\'PSROIPoolingParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PSROIPOOLINGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PSROIPoolingParameter)\n  ))\n_sym_db.RegisterMessage(PSROIPoolingParameter)\n\nFlipParameter = _reflection.GeneratedProtocolMessageType(\'FlipParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _FLIPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.FlipParameter)\n  ))\n_sym_db.RegisterMessage(FlipParameter)\n\nBNParameter = _reflection.GeneratedProtocolMessageType(\'BNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BNParameter)\n  ))\n_sym_db.RegisterMessage(BNParameter)\n\nFocalLossParameter = _reflection.GeneratedProtocolMessageType(\'FocalLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _FOCALLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.FocalLossParameter)\n  ))\n_sym_db.RegisterMessage(FocalLossParameter)\n\nTransformationParameter = _reflection.GeneratedProtocolMessageType(\'TransformationParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TRANSFORMATIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TransformationParameter)\n  ))\n_sym_db.RegisterMessage(TransformationParameter)\n\nResizeParameter = _reflection.GeneratedProtocolMessageType(\'ResizeParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RESIZEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ResizeParameter)\n  ))\n_sym_db.RegisterMessage(ResizeParameter)\n\nSaltPepperParameter = _reflection.GeneratedProtocolMessageType(\'SaltPepperParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SALTPEPPERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SaltPepperParameter)\n  ))\n_sym_db.RegisterMessage(SaltPepperParameter)\n\nNoiseParameter = _reflection.GeneratedProtocolMessageType(\'NoiseParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _NOISEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NoiseParameter)\n  ))\n_sym_db.RegisterMessage(NoiseParameter)\n\nDistortionParameter = _reflection.GeneratedProtocolMessageType(\'DistortionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DISTORTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DistortionParameter)\n  ))\n_sym_db.RegisterMessage(DistortionParameter)\n\nExpansionParameter = _reflection.GeneratedProtocolMessageType(\'ExpansionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _EXPANSIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ExpansionParameter)\n  ))\n_sym_db.RegisterMessage(ExpansionParameter)\n\nLossParameter = _reflection.GeneratedProtocolMessageType(\'LossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LossParameter)\n  ))\n_sym_db.RegisterMessage(LossParameter)\n\nAccuracyParameter = _reflection.GeneratedProtocolMessageType(\'AccuracyParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ACCURACYPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AccuracyParameter)\n  ))\n_sym_db.RegisterMessage(AccuracyParameter)\n\nArgMaxParameter = _reflection.GeneratedProtocolMessageType(\'ArgMaxParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ARGMAXPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ArgMaxParameter)\n  ))\n_sym_db.RegisterMessage(ArgMaxParameter)\n\nConcatParameter = _reflection.GeneratedProtocolMessageType(\'ConcatParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONCATPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ConcatParameter)\n  ))\n_sym_db.RegisterMessage(ConcatParameter)\n\nBatchNormParameter = _reflection.GeneratedProtocolMessageType(\'BatchNormParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BATCHNORMPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BatchNormParameter)\n  ))\n_sym_db.RegisterMessage(BatchNormParameter)\n\nBiasParameter = _reflection.GeneratedProtocolMessageType(\'BiasParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BIASPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BiasParameter)\n  ))\n_sym_db.RegisterMessage(BiasParameter)\n\nContrastiveLossParameter = _reflection.GeneratedProtocolMessageType(\'ContrastiveLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONTRASTIVELOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ContrastiveLossParameter)\n  ))\n_sym_db.RegisterMessage(ContrastiveLossParameter)\n\nDetectionLossParameter = _reflection.GeneratedProtocolMessageType(\'DetectionLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DETECTIONLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DetectionLossParameter)\n  ))\n_sym_db.RegisterMessage(DetectionLossParameter)\n\nRegionLossParameter = _reflection.GeneratedProtocolMessageType(\'RegionLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _REGIONLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.RegionLossParameter)\n  ))\n_sym_db.RegisterMessage(RegionLossParameter)\n\nReorgParameter = _reflection.GeneratedProtocolMessageType(\'ReorgParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _REORGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReorgParameter)\n  ))\n_sym_db.RegisterMessage(ReorgParameter)\n\nEvalDetectionParameter = _reflection.GeneratedProtocolMessageType(\'EvalDetectionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _EVALDETECTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.EvalDetectionParameter)\n  ))\n_sym_db.RegisterMessage(EvalDetectionParameter)\n\nConvolutionParameter = _reflection.GeneratedProtocolMessageType(\'ConvolutionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONVOLUTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ConvolutionParameter)\n  ))\n_sym_db.RegisterMessage(ConvolutionParameter)\n\nCropParameter = _reflection.GeneratedProtocolMessageType(\'CropParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CROPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.CropParameter)\n  ))\n_sym_db.RegisterMessage(CropParameter)\n\nDataParameter = _reflection.GeneratedProtocolMessageType(\'DataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DataParameter)\n  ))\n_sym_db.RegisterMessage(DataParameter)\n\nDetectionEvaluateParameter = _reflection.GeneratedProtocolMessageType(\'DetectionEvaluateParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DETECTIONEVALUATEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DetectionEvaluateParameter)\n  ))\n_sym_db.RegisterMessage(DetectionEvaluateParameter)\n\nNonMaximumSuppressionParameter = _reflection.GeneratedProtocolMessageType(\'NonMaximumSuppressionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _NONMAXIMUMSUPPRESSIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NonMaximumSuppressionParameter)\n  ))\n_sym_db.RegisterMessage(NonMaximumSuppressionParameter)\n\nSaveOutputParameter = _reflection.GeneratedProtocolMessageType(\'SaveOutputParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SAVEOUTPUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SaveOutputParameter)\n  ))\n_sym_db.RegisterMessage(SaveOutputParameter)\n\nDetectionOutputParameter = _reflection.GeneratedProtocolMessageType(\'DetectionOutputParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DETECTIONOUTPUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DetectionOutputParameter)\n  ))\n_sym_db.RegisterMessage(DetectionOutputParameter)\n\nDropoutParameter = _reflection.GeneratedProtocolMessageType(\'DropoutParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DROPOUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DropoutParameter)\n  ))\n_sym_db.RegisterMessage(DropoutParameter)\n\nDummyDataParameter = _reflection.GeneratedProtocolMessageType(\'DummyDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DUMMYDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DummyDataParameter)\n  ))\n_sym_db.RegisterMessage(DummyDataParameter)\n\nEltwiseParameter = _reflection.GeneratedProtocolMessageType(\'EltwiseParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ELTWISEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.EltwiseParameter)\n  ))\n_sym_db.RegisterMessage(EltwiseParameter)\n\nELUParameter = _reflection.GeneratedProtocolMessageType(\'ELUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ELUParameter)\n  ))\n_sym_db.RegisterMessage(ELUParameter)\n\nEmbedParameter = _reflection.GeneratedProtocolMessageType(\'EmbedParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _EMBEDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.EmbedParameter)\n  ))\n_sym_db.RegisterMessage(EmbedParameter)\n\nExpParameter = _reflection.GeneratedProtocolMessageType(\'ExpParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _EXPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ExpParameter)\n  ))\n_sym_db.RegisterMessage(ExpParameter)\n\nFlattenParameter = _reflection.GeneratedProtocolMessageType(\'FlattenParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _FLATTENPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.FlattenParameter)\n  ))\n_sym_db.RegisterMessage(FlattenParameter)\n\nHDF5DataParameter = _reflection.GeneratedProtocolMessageType(\'HDF5DataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HDF5DATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HDF5DataParameter)\n  ))\n_sym_db.RegisterMessage(HDF5DataParameter)\n\nHDF5OutputParameter = _reflection.GeneratedProtocolMessageType(\'HDF5OutputParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HDF5OUTPUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HDF5OutputParameter)\n  ))\n_sym_db.RegisterMessage(HDF5OutputParameter)\n\nHingeLossParameter = _reflection.GeneratedProtocolMessageType(\'HingeLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HINGELOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HingeLossParameter)\n  ))\n_sym_db.RegisterMessage(HingeLossParameter)\n\nImageDataParameter = _reflection.GeneratedProtocolMessageType(\'ImageDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _IMAGEDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ImageDataParameter)\n  ))\n_sym_db.RegisterMessage(ImageDataParameter)\n\nInfogainLossParameter = _reflection.GeneratedProtocolMessageType(\'InfogainLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INFOGAINLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InfogainLossParameter)\n  ))\n_sym_db.RegisterMessage(InfogainLossParameter)\n\nInnerProductParameter = _reflection.GeneratedProtocolMessageType(\'InnerProductParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INNERPRODUCTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InnerProductParameter)\n  ))\n_sym_db.RegisterMessage(InnerProductParameter)\n\nInputParameter = _reflection.GeneratedProtocolMessageType(\'InputParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INPUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InputParameter)\n  ))\n_sym_db.RegisterMessage(InputParameter)\n\nLogParameter = _reflection.GeneratedProtocolMessageType(\'LogParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LOGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LogParameter)\n  ))\n_sym_db.RegisterMessage(LogParameter)\n\nLRNParameter = _reflection.GeneratedProtocolMessageType(\'LRNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LRNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LRNParameter)\n  ))\n_sym_db.RegisterMessage(LRNParameter)\n\nMemoryDataParameter = _reflection.GeneratedProtocolMessageType(\'MemoryDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MEMORYDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MemoryDataParameter)\n  ))\n_sym_db.RegisterMessage(MemoryDataParameter)\n\nMultiBoxLossParameter = _reflection.GeneratedProtocolMessageType(\'MultiBoxLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MULTIBOXLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MultiBoxLossParameter)\n  ))\n_sym_db.RegisterMessage(MultiBoxLossParameter)\n\nPermuteParameter = _reflection.GeneratedProtocolMessageType(\'PermuteParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PERMUTEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PermuteParameter)\n  ))\n_sym_db.RegisterMessage(PermuteParameter)\n\nMVNParameter = _reflection.GeneratedProtocolMessageType(\'MVNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MVNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MVNParameter)\n  ))\n_sym_db.RegisterMessage(MVNParameter)\n\nParameterParameter = _reflection.GeneratedProtocolMessageType(\'ParameterParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PARAMETERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ParameterParameter)\n  ))\n_sym_db.RegisterMessage(ParameterParameter)\n\nPoolingParameter = _reflection.GeneratedProtocolMessageType(\'PoolingParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _POOLINGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PoolingParameter)\n  ))\n_sym_db.RegisterMessage(PoolingParameter)\n\nPowerParameter = _reflection.GeneratedProtocolMessageType(\'PowerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _POWERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PowerParameter)\n  ))\n_sym_db.RegisterMessage(PowerParameter)\n\nPriorBoxParameter = _reflection.GeneratedProtocolMessageType(\'PriorBoxParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PRIORBOXPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PriorBoxParameter)\n  ))\n_sym_db.RegisterMessage(PriorBoxParameter)\n\nPythonParameter = _reflection.GeneratedProtocolMessageType(\'PythonParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PYTHONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PythonParameter)\n  ))\n_sym_db.RegisterMessage(PythonParameter)\n\nRecurrentParameter = _reflection.GeneratedProtocolMessageType(\'RecurrentParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RECURRENTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.RecurrentParameter)\n  ))\n_sym_db.RegisterMessage(RecurrentParameter)\n\nReductionParameter = _reflection.GeneratedProtocolMessageType(\'ReductionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _REDUCTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReductionParameter)\n  ))\n_sym_db.RegisterMessage(ReductionParameter)\n\nReLUParameter = _reflection.GeneratedProtocolMessageType(\'ReLUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReLUParameter)\n  ))\n_sym_db.RegisterMessage(ReLUParameter)\n\nReshapeParameter = _reflection.GeneratedProtocolMessageType(\'ReshapeParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RESHAPEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReshapeParameter)\n  ))\n_sym_db.RegisterMessage(ReshapeParameter)\n\nROIPoolingParameter = _reflection.GeneratedProtocolMessageType(\'ROIPoolingParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ROIPOOLINGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ROIPoolingParameter)\n  ))\n_sym_db.RegisterMessage(ROIPoolingParameter)\n\nScaleParameter = _reflection.GeneratedProtocolMessageType(\'ScaleParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SCALEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ScaleParameter)\n  ))\n_sym_db.RegisterMessage(ScaleParameter)\n\nSigmoidParameter = _reflection.GeneratedProtocolMessageType(\'SigmoidParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SIGMOIDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SigmoidParameter)\n  ))\n_sym_db.RegisterMessage(SigmoidParameter)\n\nSmoothL1LossParameter = _reflection.GeneratedProtocolMessageType(\'SmoothL1LossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SMOOTHL1LOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SmoothL1LossParameter)\n  ))\n_sym_db.RegisterMessage(SmoothL1LossParameter)\n\nSliceParameter = _reflection.GeneratedProtocolMessageType(\'SliceParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SLICEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SliceParameter)\n  ))\n_sym_db.RegisterMessage(SliceParameter)\n\nSoftmaxParameter = _reflection.GeneratedProtocolMessageType(\'SoftmaxParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SOFTMAXPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SoftmaxParameter)\n  ))\n_sym_db.RegisterMessage(SoftmaxParameter)\n\nTanHParameter = _reflection.GeneratedProtocolMessageType(\'TanHParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TANHPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TanHParameter)\n  ))\n_sym_db.RegisterMessage(TanHParameter)\n\nTileParameter = _reflection.GeneratedProtocolMessageType(\'TileParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TILEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TileParameter)\n  ))\n_sym_db.RegisterMessage(TileParameter)\n\nThresholdParameter = _reflection.GeneratedProtocolMessageType(\'ThresholdParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _THRESHOLDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ThresholdParameter)\n  ))\n_sym_db.RegisterMessage(ThresholdParameter)\n\nWindowDataParameter = _reflection.GeneratedProtocolMessageType(\'WindowDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _WINDOWDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.WindowDataParameter)\n  ))\n_sym_db.RegisterMessage(WindowDataParameter)\n\nSPPParameter = _reflection.GeneratedProtocolMessageType(\'SPPParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SPPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SPPParameter)\n  ))\n_sym_db.RegisterMessage(SPPParameter)\n\nV1LayerParameter = _reflection.GeneratedProtocolMessageType(\'V1LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _V1LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.V1LayerParameter)\n  ))\n_sym_db.RegisterMessage(V1LayerParameter)\n\nV0LayerParameter = _reflection.GeneratedProtocolMessageType(\'V0LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _V0LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.V0LayerParameter)\n  ))\n_sym_db.RegisterMessage(V0LayerParameter)\n\nPReLUParameter = _reflection.GeneratedProtocolMessageType(\'PReLUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PRELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PReLUParameter)\n  ))\n_sym_db.RegisterMessage(PReLUParameter)\n\nRPNParameter = _reflection.GeneratedProtocolMessageType(\'RPNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RPNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.RPNParameter)\n  ))\n_sym_db.RegisterMessage(RPNParameter)\n\nVideoDataParameter = _reflection.GeneratedProtocolMessageType(\'VideoDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _VIDEODATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.VideoDataParameter)\n  ))\n_sym_db.RegisterMessage(VideoDataParameter)\n\nCenterLossParameter = _reflection.GeneratedProtocolMessageType(\'CenterLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CENTERLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.CenterLossParameter)\n  ))\n_sym_db.RegisterMessage(CenterLossParameter)\n\nMarginInnerProductParameter = _reflection.GeneratedProtocolMessageType(\'MarginInnerProductParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MARGININNERPRODUCTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MarginInnerProductParameter)\n  ))\n_sym_db.RegisterMessage(MarginInnerProductParameter)\n\nAdditiveMarginInnerProductParameter = _reflection.GeneratedProtocolMessageType(\'AdditiveMarginInnerProductParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ADDITIVEMARGININNERPRODUCTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AdditiveMarginInnerProductParameter)\n  ))\n_sym_db.RegisterMessage(AdditiveMarginInnerProductParameter)\n\nDeformableConvolutionParameter = _reflection.GeneratedProtocolMessageType(\'DeformableConvolutionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DEFORMABLECONVOLUTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DeformableConvolutionParameter)\n  ))\n_sym_db.RegisterMessage(DeformableConvolutionParameter)\n\nLabelSpecificAddParameter = _reflection.GeneratedProtocolMessageType(\'LabelSpecificAddParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LABELSPECIFICADDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LabelSpecificAddParameter)\n  ))\n_sym_db.RegisterMessage(LabelSpecificAddParameter)\n\nChannelScaleParameter = _reflection.GeneratedProtocolMessageType(\'ChannelScaleParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CHANNELSCALEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ChannelScaleParameter)\n  ))\n_sym_db.RegisterMessage(ChannelScaleParameter)\n\nCosinAddmParameter = _reflection.GeneratedProtocolMessageType(\'CosinAddmParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _COSINADDMPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.CosinAddmParameter)\n  ))\n_sym_db.RegisterMessage(CosinAddmParameter)\n\nCosinMulmParameter = _reflection.GeneratedProtocolMessageType(\'CosinMulmParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _COSINMULMPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.CosinMulmParameter)\n  ))\n_sym_db.RegisterMessage(CosinMulmParameter)\n\nCoupledClusterLossParameter = _reflection.GeneratedProtocolMessageType(\'CoupledClusterLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _COUPLEDCLUSTERLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.CoupledClusterLossParameter)\n  ))\n_sym_db.RegisterMessage(CoupledClusterLossParameter)\n\nTripletLossParameter = _reflection.GeneratedProtocolMessageType(\'TripletLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TRIPLETLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TripletLossParameter)\n  ))\n_sym_db.RegisterMessage(TripletLossParameter)\n\nGeneralTripletParameter = _reflection.GeneratedProtocolMessageType(\'GeneralTripletParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _GENERALTRIPLETPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.GeneralTripletParameter)\n  ))\n_sym_db.RegisterMessage(GeneralTripletParameter)\n\nROIAlignParameter = _reflection.GeneratedProtocolMessageType(\'ROIAlignParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ROIALIGNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ROIAlignParameter)\n  ))\n_sym_db.RegisterMessage(ROIAlignParameter)\n\n\n_BLOBSHAPE.fields_by_name[\'dim\']._options = None\n_BLOBPROTO.fields_by_name[\'data\']._options = None\n_BLOBPROTO.fields_by_name[\'diff\']._options = None\n_BLOBPROTO.fields_by_name[\'double_data\']._options = None\n_BLOBPROTO.fields_by_name[\'double_diff\']._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tools/deploy/Caffe/layer_param.py,0,"b'from __future__ import absolute_import\nfrom . import caffe_pb2 as pb\nimport numpy as np\n\ndef pair_process(item,strict_one=True):\n    if hasattr(item,\'__iter__\'):\n        for i in item:\n            if i!=item[0]:\n                if strict_one:\n                    raise ValueError(""number in item {} must be the same"".format(item))\n                else:\n                    print(""IMPORTANT WARNING: number in item {} must be the same"".format(item))\n        return item[0]\n    return item\n\ndef pair_reduce(item):\n    if hasattr(item,\'__iter__\'):\n        for i in item:\n            if i!=item[0]:\n                return item\n        return [item[0]]\n    return [item]\n\nclass Layer_param():\n    def __init__(self,name=\'\',type=\'\',top=(),bottom=()):\n        self.param=pb.LayerParameter()\n        self.name=self.param.name=name\n        self.type=self.param.type=type\n\n        self.top=self.param.top\n        self.top.extend(top)\n        self.bottom=self.param.bottom\n        self.bottom.extend(bottom)\n\n    def fc_param(self, num_output, weight_filler=\'xavier\', bias_filler=\'constant\',has_bias=True):\n        if self.type != \'InnerProduct\':\n            raise TypeError(\'the layer type must be InnerProduct if you want set fc param\')\n        fc_param = pb.InnerProductParameter()\n        fc_param.num_output = num_output\n        fc_param.weight_filler.type = weight_filler\n        fc_param.bias_term = has_bias\n        if has_bias:\n            fc_param.bias_filler.type = bias_filler\n        self.param.inner_product_param.CopyFrom(fc_param)\n\n    def conv_param(self, num_output, kernel_size, stride=(1), pad=(0,),\n                   weight_filler_type=\'xavier\', bias_filler_type=\'constant\',\n                   bias_term=True, dilation=None,groups=None):\n        """"""\n        add a conv_param layer if you spec the layer type ""Convolution""\n        Args:\n            num_output: a int\n            kernel_size: int list\n            stride: a int list\n            weight_filler_type: the weight filer type\n            bias_filler_type: the bias filler type\n        Returns:\n        """"""\n        if self.type not in [\'Convolution\',\'Deconvolution\']:\n            raise TypeError(\'the layer type must be Convolution or Deconvolution if you want set conv param\')\n        conv_param=pb.ConvolutionParameter()\n        conv_param.num_output=num_output\n        conv_param.kernel_size.extend(pair_reduce(kernel_size))\n        conv_param.stride.extend(pair_reduce(stride))\n        conv_param.pad.extend(pair_reduce(pad))\n        conv_param.bias_term=bias_term\n        conv_param.weight_filler.type=weight_filler_type\n        if bias_term:\n            conv_param.bias_filler.type = bias_filler_type\n        if dilation:\n            conv_param.dilation.extend(pair_reduce(dilation))\n        if groups:\n            conv_param.group=groups\n        self.param.convolution_param.CopyFrom(conv_param)\n\n    def pool_param(self,type=\'MAX\',kernel_size=2,stride=2,pad=None, ceil_mode = False):\n        pool_param=pb.PoolingParameter()\n        pool_param.pool=pool_param.PoolMethod.Value(type)\n        pool_param.kernel_size=pair_process(kernel_size)\n        pool_param.stride=pair_process(stride)\n        pool_param.ceil_mode=ceil_mode\n        if pad:\n            if isinstance(pad,tuple):\n                pool_param.pad_h = pad[0]\n                pool_param.pad_w = pad[1]\n            else:\n                pool_param.pad=pad\n        self.param.pooling_param.CopyFrom(pool_param)\n\n    def batch_norm_param(self,use_global_stats=0,moving_average_fraction=None,eps=None):\n        bn_param=pb.BatchNormParameter()\n        bn_param.use_global_stats=use_global_stats\n        if moving_average_fraction:\n            bn_param.moving_average_fraction=moving_average_fraction\n        if eps:\n            bn_param.eps = eps\n        self.param.batch_norm_param.CopyFrom(bn_param)\n\n    # layer\n    # {\n    #     name: ""upsample_layer""\n    #     type: ""Upsample""\n    #     bottom: ""some_input_feature_map""\n    #     bottom: ""some_input_pool_index""\n    #     top: ""some_output""\n    #     upsample_param {\n    #         upsample_h: 224\n    #         upsample_w: 224\n    #     }\n    # }\n    def upsample_param(self,size=None, scale_factor=None):\n        upsample_param=pb.UpsampleParameter()\n        if scale_factor:\n            if isinstance(scale_factor,int):\n                upsample_param.scale = scale_factor\n            else:\n                upsample_param.scale_h = scale_factor[0]\n                upsample_param.scale_w = scale_factor[1]\n\n        if size:\n            if isinstance(size,int):\n                upsample_param.upsample_h = size\n            else:\n                upsample_param.upsample_h = size[0]\n                upsample_param.upsample_w = size[1]\n                #upsample_param.upsample_h = size[0] * scale_factor\n                #upsample_param.upsample_w = size[1] * scale_factor\n        self.param.upsample_param.CopyFrom(upsample_param)\n    def interp_param(self,size=None, scale_factor=None):\n        interp_param=pb.InterpParameter()\n        if scale_factor:\n            if isinstance(scale_factor,int):\n                interp_param.zoom_factor = scale_factor\n\n        if size:\n            print(\'size:\', size)\n            interp_param.height = size[0]\n            interp_param.width = size[1]\n        self.param.interp_param.CopyFrom(interp_param)\n\n    def add_data(self,*args):\n        """"""Args are data numpy array\n        """"""\n        del self.param.blobs[:]\n        for data in args:\n            new_blob = self.param.blobs.add()\n            for dim in data.shape:\n                new_blob.shape.dim.append(dim)\n            new_blob.data.extend(data.flatten().astype(float))\n\n    def set_params_by_dict(self,dic):\n        pass\n\n    def copy_from(self,layer_param):\n        pass\n\ndef set_enum(param,key,value):\n    setattr(param,key,param.Value(value))\n'"
tools/deploy/Caffe/net.py,0,"b""raise ImportError,'the nn_tools.Caffe.net is no longer used, please use nn_tools.Caffe.caffe_net'"""
