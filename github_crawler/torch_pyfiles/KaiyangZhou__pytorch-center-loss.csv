file_path,api_count,code
center_loss.py,6,"b'import torch\nimport torch.nn as nn\n\nclass CenterLoss(nn.Module):\n    """"""Center loss.\n    \n    Reference:\n    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n    \n    Args:\n        num_classes (int): number of classes.\n        feat_dim (int): feature dimension.\n    """"""\n    def __init__(self, num_classes=10, feat_dim=2, use_gpu=True):\n        super(CenterLoss, self).__init__()\n        self.num_classes = num_classes\n        self.feat_dim = feat_dim\n        self.use_gpu = use_gpu\n\n        if self.use_gpu:\n            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n        else:\n            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n\n    def forward(self, x, labels):\n        """"""\n        Args:\n            x: feature matrix with shape (batch_size, feat_dim).\n            labels: ground truth labels with shape (batch_size).\n        """"""\n        batch_size = x.size(0)\n        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n        distmat.addmm_(1, -2, x, self.centers.t())\n\n        classes = torch.arange(self.num_classes).long()\n        if self.use_gpu: classes = classes.cuda()\n        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n\n        dist = distmat * mask.float()\n        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n\n        return loss\n'"
datasets.py,3,"b'import torch\nimport torchvision\nfrom torch.utils.data import DataLoader\n\nimport transforms\n\nclass MNIST(object):\n    def __init__(self, batch_size, use_gpu, num_workers):\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))\n        ])\n\n        pin_memory = True if use_gpu else False\n\n        trainset = torchvision.datasets.MNIST(root=\'./data/mnist\', train=True, download=True, transform=transform)\n        \n        trainloader = torch.utils.data.DataLoader(\n            trainset, batch_size=batch_size, shuffle=True,\n            num_workers=num_workers, pin_memory=pin_memory,\n        )\n        \n        testset = torchvision.datasets.MNIST(root=\'./data/mnist\', train=False, download=True, transform=transform)\n        \n        testloader = torch.utils.data.DataLoader(\n            testset, batch_size=batch_size, shuffle=False,\n            num_workers=num_workers, pin_memory=pin_memory,\n        )\n\n        self.trainloader = trainloader\n        self.testloader = testloader\n        self.num_classes = 10\n\n__factory = {\n    \'mnist\': MNIST,\n}\n\ndef create(name, batch_size, use_gpu, num_workers):\n    if name not in __factory.keys():\n        raise KeyError(""Unknown dataset: {}"".format(name))\n    return __factory[name](batch_size, use_gpu, num_workers)'"
main.py,9,"b'import os\nimport sys\nimport argparse\nimport datetime\nimport time\nimport os.path as osp\nimport matplotlib\nmatplotlib.use(\'Agg\')\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\n\nimport datasets\nimport models\nfrom utils import AverageMeter, Logger\nfrom center_loss import CenterLoss\n\nparser = argparse.ArgumentParser(""Center Loss Example"")\n# dataset\nparser.add_argument(\'-d\', \'--dataset\', type=str, default=\'mnist\', choices=[\'mnist\'])\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int,\n                    help=""number of data loading workers (default: 4)"")\n# optimization\nparser.add_argument(\'--batch-size\', type=int, default=128)\nparser.add_argument(\'--lr-model\', type=float, default=0.001, help=""learning rate for model"")\nparser.add_argument(\'--lr-cent\', type=float, default=0.5, help=""learning rate for center loss"")\nparser.add_argument(\'--weight-cent\', type=float, default=1, help=""weight for center loss"")\nparser.add_argument(\'--max-epoch\', type=int, default=100)\nparser.add_argument(\'--stepsize\', type=int, default=20)\nparser.add_argument(\'--gamma\', type=float, default=0.5, help=""learning rate decay"")\n# model\nparser.add_argument(\'--model\', type=str, default=\'cnn\')\n# misc\nparser.add_argument(\'--eval-freq\', type=int, default=10)\nparser.add_argument(\'--print-freq\', type=int, default=50)\nparser.add_argument(\'--gpu\', type=str, default=\'0\')\nparser.add_argument(\'--seed\', type=int, default=1)\nparser.add_argument(\'--use-cpu\', action=\'store_true\')\nparser.add_argument(\'--save-dir\', type=str, default=\'log\')\nparser.add_argument(\'--plot\', action=\'store_true\', help=""whether to plot features for every epoch"")\n\nargs = parser.parse_args()\n\ndef main():\n    torch.manual_seed(args.seed)\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = args.gpu\n    use_gpu = torch.cuda.is_available()\n    if args.use_cpu: use_gpu = False\n\n    sys.stdout = Logger(osp.join(args.save_dir, \'log_\' + args.dataset + \'.txt\'))\n\n    if use_gpu:\n        print(""Currently using GPU: {}"".format(args.gpu))\n        cudnn.benchmark = True\n        torch.cuda.manual_seed_all(args.seed)\n    else:\n        print(""Currently using CPU"")\n\n    print(""Creating dataset: {}"".format(args.dataset))\n    dataset = datasets.create(\n        name=args.dataset, batch_size=args.batch_size, use_gpu=use_gpu,\n        num_workers=args.workers,\n    )\n\n    trainloader, testloader = dataset.trainloader, dataset.testloader\n\n    print(""Creating model: {}"".format(args.model))\n    model = models.create(name=args.model, num_classes=dataset.num_classes)\n\n    if use_gpu:\n        model = nn.DataParallel(model).cuda()\n\n    criterion_xent = nn.CrossEntropyLoss()\n    criterion_cent = CenterLoss(num_classes=dataset.num_classes, feat_dim=2, use_gpu=use_gpu)\n    optimizer_model = torch.optim.SGD(model.parameters(), lr=args.lr_model, weight_decay=5e-04, momentum=0.9)\n    optimizer_centloss = torch.optim.SGD(criterion_cent.parameters(), lr=args.lr_cent)\n\n    if args.stepsize > 0:\n        scheduler = lr_scheduler.StepLR(optimizer_model, step_size=args.stepsize, gamma=args.gamma)\n\n    start_time = time.time()\n\n    for epoch in range(args.max_epoch):\n        print(""==> Epoch {}/{}"".format(epoch+1, args.max_epoch))\n        train(model, criterion_xent, criterion_cent,\n              optimizer_model, optimizer_centloss,\n              trainloader, use_gpu, dataset.num_classes, epoch)\n\n        if args.stepsize > 0: scheduler.step()\n\n        if args.eval_freq > 0 and (epoch+1) % args.eval_freq == 0 or (epoch+1) == args.max_epoch:\n            print(""==> Test"")\n            acc, err = test(model, testloader, use_gpu, dataset.num_classes, epoch)\n            print(""Accuracy (%): {}\\t Error rate (%): {}"".format(acc, err))\n\n    elapsed = round(time.time() - start_time)\n    elapsed = str(datetime.timedelta(seconds=elapsed))\n    print(""Finished. Total elapsed time (h:m:s): {}"".format(elapsed))\n\ndef train(model, criterion_xent, criterion_cent,\n          optimizer_model, optimizer_centloss,\n          trainloader, use_gpu, num_classes, epoch):\n    model.train()\n    xent_losses = AverageMeter()\n    cent_losses = AverageMeter()\n    losses = AverageMeter()\n    \n    if args.plot:\n        all_features, all_labels = [], []\n\n    for batch_idx, (data, labels) in enumerate(trainloader):\n        if use_gpu:\n            data, labels = data.cuda(), labels.cuda()\n        features, outputs = model(data)\n        loss_xent = criterion_xent(outputs, labels)\n        loss_cent = criterion_cent(features, labels)\n        loss_cent *= args.weight_cent\n        loss = loss_xent + loss_cent\n        optimizer_model.zero_grad()\n        optimizer_centloss.zero_grad()\n        loss.backward()\n        optimizer_model.step()\n        # by doing so, weight_cent would not impact on the learning of centers\n        for param in criterion_cent.parameters():\n            param.grad.data *= (1. / args.weight_cent)\n        optimizer_centloss.step()\n        \n        losses.update(loss.item(), labels.size(0))\n        xent_losses.update(loss_xent.item(), labels.size(0))\n        cent_losses.update(loss_cent.item(), labels.size(0))\n\n        if args.plot:\n            if use_gpu:\n                all_features.append(features.data.cpu().numpy())\n                all_labels.append(labels.data.cpu().numpy())\n            else:\n                all_features.append(features.data.numpy())\n                all_labels.append(labels.data.numpy())\n\n        if (batch_idx+1) % args.print_freq == 0:\n            print(""Batch {}/{}\\t Loss {:.6f} ({:.6f}) XentLoss {:.6f} ({:.6f}) CenterLoss {:.6f} ({:.6f})"" \\\n                  .format(batch_idx+1, len(trainloader), losses.val, losses.avg, xent_losses.val, xent_losses.avg, cent_losses.val, cent_losses.avg))\n\n    if args.plot:\n        all_features = np.concatenate(all_features, 0)\n        all_labels = np.concatenate(all_labels, 0)\n        plot_features(all_features, all_labels, num_classes, epoch, prefix=\'train\')\n\ndef test(model, testloader, use_gpu, num_classes, epoch):\n    model.eval()\n    correct, total = 0, 0\n    if args.plot:\n        all_features, all_labels = [], []\n\n    with torch.no_grad():\n        for data, labels in testloader:\n            if use_gpu:\n                data, labels = data.cuda(), labels.cuda()\n            features, outputs = model(data)\n            predictions = outputs.data.max(1)[1]\n            total += labels.size(0)\n            correct += (predictions == labels.data).sum()\n            \n            if args.plot:\n                if use_gpu:\n                    all_features.append(features.data.cpu().numpy())\n                    all_labels.append(labels.data.cpu().numpy())\n                else:\n                    all_features.append(features.data.numpy())\n                    all_labels.append(labels.data.numpy())\n\n    if args.plot:\n        all_features = np.concatenate(all_features, 0)\n        all_labels = np.concatenate(all_labels, 0)\n        plot_features(all_features, all_labels, num_classes, epoch, prefix=\'test\')\n\n    acc = correct * 100. / total\n    err = 100. - acc\n    return acc, err\n\ndef plot_features(features, labels, num_classes, epoch, prefix):\n    """"""Plot features on 2D plane.\n\n    Args:\n        features: (num_instances, num_features).\n        labels: (num_instances). \n    """"""\n    colors = [\'C0\', \'C1\', \'C2\', \'C3\', \'C4\', \'C5\', \'C6\', \'C7\', \'C8\', \'C9\']\n    for label_idx in range(num_classes):\n        plt.scatter(\n            features[labels==label_idx, 0],\n            features[labels==label_idx, 1],\n            c=colors[label_idx],\n            s=1,\n        )\n    plt.legend([\'0\', \'1\', \'2\', \'3\', \'4\', \'5\', \'6\', \'7\', \'8\', \'9\'], loc=\'upper right\')\n    dirname = osp.join(args.save_dir, prefix)\n    if not osp.exists(dirname):\n        os.mkdir(dirname)\n    save_name = osp.join(dirname, \'epoch_\' + str(epoch+1) + \'.png\')\n    plt.savefig(save_name, bbox_inches=\'tight\')\n    plt.close()\n\nif __name__ == \'__main__\':\n    main()\n\n\n\n\n\n'"
models.py,2,"b'import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nimport math\n\nclass ConvNet(nn.Module):\n    """"""LeNet++ as described in the Center Loss paper.""""""\n    def __init__(self, num_classes):\n        super(ConvNet, self).__init__()\n        self.conv1_1 = nn.Conv2d(1, 32, 5, stride=1, padding=2)\n        self.prelu1_1 = nn.PReLU()\n        self.conv1_2 = nn.Conv2d(32, 32, 5, stride=1, padding=2)\n        self.prelu1_2 = nn.PReLU()\n        \n        self.conv2_1 = nn.Conv2d(32, 64, 5, stride=1, padding=2)\n        self.prelu2_1 = nn.PReLU()\n        self.conv2_2 = nn.Conv2d(64, 64, 5, stride=1, padding=2)\n        self.prelu2_2 = nn.PReLU()\n        \n        self.conv3_1 = nn.Conv2d(64, 128, 5, stride=1, padding=2)\n        self.prelu3_1 = nn.PReLU()\n        self.conv3_2 = nn.Conv2d(128, 128, 5, stride=1, padding=2)\n        self.prelu3_2 = nn.PReLU()\n        \n        self.fc1 = nn.Linear(128*3*3, 2)\n        self.prelu_fc1 = nn.PReLU()\n        self.fc2 = nn.Linear(2, num_classes)\n\n    def forward(self, x):\n        x = self.prelu1_1(self.conv1_1(x))\n        x = self.prelu1_2(self.conv1_2(x))\n        x = F.max_pool2d(x, 2)\n        \n        x = self.prelu2_1(self.conv2_1(x))\n        x = self.prelu2_2(self.conv2_2(x))\n        x = F.max_pool2d(x, 2)\n        \n        x = self.prelu3_1(self.conv3_1(x))\n        x = self.prelu3_2(self.conv3_2(x))\n        x = F.max_pool2d(x, 2)\n        \n        x = x.view(-1, 128*3*3)\n        x = self.prelu_fc1(self.fc1(x))\n        y = self.fc2(x)\n\n        return x, y\n\n__factory = {\n    \'cnn\': ConvNet,\n}\n\ndef create(name, num_classes):\n    if name not in __factory.keys():\n        raise KeyError(""Unknown model: {}"".format(name))\n    return __factory[name](num_classes)\n\nif __name__ == \'__main__\':\n    pass'"
transforms.py,0,"b'from torchvision.transforms import *\nfrom PIL import Image\n\nclass ToGray(object):\n    """"""\n    Convert image from RGB to gray level.\n    """"""\n    def __call__(self, img):\n        return img.convert(\'L\')'"
utils.py,1,"b'import os\nimport sys\nimport errno\nimport shutil\nimport os.path as osp\n\nimport torch\n\ndef mkdir_if_missing(directory):\n    if not osp.exists(directory):\n        try:\n            os.makedirs(directory)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value.\n       \n       Code imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n    """"""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef save_checkpoint(state, is_best, fpath=\'checkpoint.pth.tar\'):\n    mkdir_if_missing(osp.dirname(fpath))\n    torch.save(state, fpath)\n    if is_best:\n        shutil.copy(fpath, osp.join(osp.dirname(fpath), \'best_model.pth.tar\'))\n\nclass Logger(object):\n    """"""\n    Write console output to external text file.\n    \n    Code imported from https://github.com/Cysu/open-reid/blob/master/reid/utils/logging.py.\n    """"""\n    def __init__(self, fpath=None):\n        self.console = sys.stdout\n        self.file = None\n        if fpath is not None:\n            mkdir_if_missing(os.path.dirname(fpath))\n            self.file = open(fpath, \'w\')\n\n    def __del__(self):\n        self.close()\n\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args):\n        self.close()\n\n    def write(self, msg):\n        self.console.write(msg)\n        if self.file is not None:\n            self.file.write(msg)\n\n    def flush(self):\n        self.console.flush()\n        if self.file is not None:\n            self.file.flush()\n            os.fsync(self.file.fileno())\n\n    def close(self):\n        self.console.close()\n        if self.file is not None:\n            self.file.close()'"
