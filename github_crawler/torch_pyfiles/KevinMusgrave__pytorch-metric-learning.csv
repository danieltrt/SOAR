file_path,api_count,code
setup.py,0,"b'import setuptools\n\nwith open(""README.md"", ""r"") as fh:\n    long_description = fh.read()\n\n# Requirements for testing and development\nextras_require_dev = [\n    ""pytest > 3.8"",\n    ""pytest-cov ~= 2.8"",\n]\n\nextras_require_with_hooks = [""record-keeper >= 0.9.25"", ""faiss-gpu >= 1.6.3"", ""tensorboard""]\nextras_require_with_hooks_cpu = [""record-keeper >= 0.9.25"", ""faiss-cpu >= 1.6.3"", ""tensorboard""]\n\nsetuptools.setup(\n    name=""pytorch-metric-learning"",\n    version=""0.9.87.dev4"",\n    author=""Kevin Musgrave"",\n    author_email=""tkm45@cornell.edu"",\n    description=""The easiest way to use deep metric learning in your application. Modular, flexible, and extensible. Written in PyTorch."",\n    long_description=long_description,\n    long_description_content_type=""text/markdown"",\n    url=""https://github.com/KevinMusgrave/pytorch-metric-learning"",\n    package_dir={"""": ""src""},\n    packages=setuptools.find_packages(where=""src""),\n    classifiers=[\n        ""Programming Language :: Python :: 3"",\n        ""License :: OSI Approved :: MIT License"",\n        ""Operating System :: OS Independent"",\n    ],\n    python_requires=\'>=3.0\',\n    install_requires=[\n          \'numpy\',\n          \'scikit-learn\',\n          \'tqdm\',\n          \'torch\',\n          \'torchvision\',\n    ],\n    extras_require={\n        ""dev"": extras_require_dev,\n        ""with-hooks"": extras_require_with_hooks,\n        ""with-hooks-cpu"": extras_require_with_hooks_cpu\n    },\n)'"
tests/__init__.py,0,b''
src/pytorch_metric_learning/__init__.py,0,"b'__version__ = ""0.9.87.dev4""'"
tests/losses/__init__.py,0,b''
tests/losses/test_angular_loss.py,9,"b'import unittest\nimport torch\nimport numpy as np\nfrom pytorch_metric_learning.losses import AngularLoss\nfrom pytorch_metric_learning.utils import common_functions as c_f\n\nclass TestAngularLoss(unittest.TestCase):\n    def test_angular_loss(self):\n        loss_func = AngularLoss(alpha=40)\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 0, 1, 1, 2])\n\n        loss = loss_func(embeddings, labels)\n        sq_tan_alpha = torch.tan(torch.tensor(np.radians(40)))**2\n        triplets = [(0,1,2), (0,1,3), (0,1,4), (1,0,2), (1,0,3), (1,0,4), (2,3,0), (2,3,1), (2,3,4), (3,2,0), (3,2,1), (3,2,4)]\n\n        correct_losses = [0,0,0,0]\n        for a, p, n in triplets:\n            anchor, positive, negative = embeddings[a], embeddings[p], embeddings[n]\n            exponent = 4*sq_tan_alpha*torch.matmul(anchor+positive,negative) - 2*(1+sq_tan_alpha)*torch.matmul(anchor, positive)\n            correct_losses[a] += torch.exp(exponent)\n        total_loss = 0\n        for c in correct_losses:\n            total_loss += torch.log(1+c)\n        total_loss /= len(correct_losses)\n        self.assertTrue(torch.isclose(loss, total_loss))\n\n\n    def test_with_no_valid_triplets(self):\n        loss_func = AngularLoss(alpha=40)\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 1, 2, 3, 4])\n        loss = loss_func(embeddings, labels)\n        self.assertEqual(loss, 0)'"
tests/losses/test_arcface_loss.py,7,"b'import unittest\nimport torch\nimport numpy as np\nfrom pytorch_metric_learning.losses import ArcFaceLoss\nfrom pytorch_metric_learning.utils import common_functions as c_f\n\nclass TestArcFaceLoss(unittest.TestCase):\n    def test_arcface_loss(self):\n        margin = 30\n        scale = 64\n        loss_func = ArcFaceLoss(margin=margin, scale=scale, num_classes=10, embedding_size=2)\n\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 0, 1, 1, 2])\n\n        loss = loss_func(embeddings, labels)\n\n        weights = torch.nn.functional.normalize(loss_func.W, p=2, dim=0)\n        logits = torch.matmul(embeddings, weights)\n        for i, c in enumerate(labels):\n            logits[i, c] = torch.cos(torch.acos(logits[i, c]) + torch.tensor(np.radians(margin)))\n        \n        correct_loss = torch.nn.functional.cross_entropy(logits*scale, labels)\n        self.assertTrue(torch.isclose(loss, correct_loss))'"
tests/losses/test_contrastive_loss.py,12,"b'import unittest\nimport torch\nfrom pytorch_metric_learning.losses import ContrastiveLoss\nfrom pytorch_metric_learning.utils import common_functions as c_f\n\nclass TestContrastiveLoss(unittest.TestCase):\n    def test_contrastive_loss(self):\n        loss_funcA = ContrastiveLoss(pos_margin=0.25, neg_margin=1.5, use_similarity=False, avg_non_zero_only=True, squared_distances=True)\n        loss_funcB = ContrastiveLoss(pos_margin=1.5, neg_margin=0.6, use_similarity=True, avg_non_zero_only=True)\n        loss_funcC = ContrastiveLoss(pos_margin=0.25, neg_margin=1.5, use_similarity=False, avg_non_zero_only=False, squared_distances=True)\n        loss_funcD = ContrastiveLoss(pos_margin=1.5, neg_margin=0.6, use_similarity=True, avg_non_zero_only=False)\n\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 0, 1, 1, 2])\n\n        lossA = loss_funcA(embeddings, labels)\n        lossB = loss_funcB(embeddings, labels)\n        lossC = loss_funcC(embeddings, labels)\n        lossD = loss_funcD(embeddings, labels)\n\n        pos_pairs = [(0,1), (1,0), (2,3), (3,2)]\n        neg_pairs = [(0,2), (0,3), (0,4), (1,2), (1,3), (1,4), (2,0), (2,1), (2,4), (3,0), (3,1), (3,4), (4,0), (4,1), (4,2), (4,3)]\n\n        correct_pos_losses = [0,0,0,0]\n        correct_neg_losses = [0,0,0,0]\n        num_non_zero_pos = [0,0,0,0]\n        num_non_zero_neg = [0,0,0,0]\n        for a,p in pos_pairs:\n            anchor, positive = embeddings[a], embeddings[p]\n            correct_lossA = torch.relu(torch.sum((anchor-positive)**2) - 0.25)\n            correct_lossB = torch.relu(1.5-torch.matmul(anchor, positive))\n            correct_pos_losses[0] += correct_lossA\n            correct_pos_losses[1] += correct_lossB\n            correct_pos_losses[2] += correct_lossA\n            correct_pos_losses[3] += correct_lossB\n            if correct_lossA > 0:\n                num_non_zero_pos[0] += 1\n                num_non_zero_pos[2] += 1\n            if correct_lossB > 0:\n                num_non_zero_pos[1] += 1\n                num_non_zero_pos[3] += 1          \n\n        for a,n in neg_pairs:\n            anchor, negative = embeddings[a], embeddings[n]\n            correct_lossA = torch.relu(1.5 - torch.sum((anchor-negative)**2))\n            correct_lossB = torch.relu(torch.matmul(anchor, negative)-0.6)\n            correct_neg_losses[0] += correct_lossA\n            correct_neg_losses[1] += correct_lossB\n            correct_neg_losses[2] += correct_lossA\n            correct_neg_losses[3] += correct_lossB\n            if correct_lossA > 0:\n                num_non_zero_neg[0] += 1\n                num_non_zero_neg[2] += 1\n            if correct_lossB > 0:\n                num_non_zero_neg[1] += 1\n                num_non_zero_neg[3] += 1\n                \n        for i in range(2):\n            if num_non_zero_pos[i] > 0:\n                correct_pos_losses[i] /= num_non_zero_pos[i]\n            if num_non_zero_neg[i] > 0:\n                correct_neg_losses[i] /= num_non_zero_neg[i]\n        \n        for i in range(2,4):\n            correct_pos_losses[i] /= len(pos_pairs)\n            correct_neg_losses[i] /= len(neg_pairs)\n\n        correct_losses = [0,0,0,0]\n        for i in range(4):\n            correct_losses[i] = correct_pos_losses[i] + correct_neg_losses[i]\n\n        self.assertTrue(torch.isclose(lossA, correct_losses[0]))\n        self.assertTrue(torch.isclose(lossB, correct_losses[1]))\n        self.assertTrue(torch.isclose(lossC, correct_losses[2]))\n        self.assertTrue(torch.isclose(lossD, correct_losses[3]))\n\n\n    def test_with_no_valid_pairs(self):\n        lossA = ContrastiveLoss(use_similarity=False)\n        lossB = ContrastiveLoss(use_similarity=True)\n        embedding_angles = [0]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0])\n        self.assertEqual(lossA(embeddings, labels), 0)\n        self.assertEqual(lossB(embeddings, labels), 0)'"
tests/losses/test_cross_batch_memory.py,33,"b""import unittest\r\nimport torch\r\nfrom pytorch_metric_learning.utils import loss_and_miner_utils as lmu\r\nfrom pytorch_metric_learning.utils import common_functions as c_f\r\nfrom pytorch_metric_learning.losses import CrossBatchMemory, ContrastiveLoss\r\nfrom pytorch_metric_learning.miners import PairMarginMiner, TripletMarginMiner\r\n\r\nclass TestCrossBatchMemory(unittest.TestCase):\r\n\r\n    @classmethod\r\n    def setUpClass(self):\r\n        self.embedding_size = 128\r\n        self.memory_size = 321\r\n\r\n    def test_queue(self):\r\n        batch_size = 32\r\n        self.loss = CrossBatchMemory(loss=ContrastiveLoss(), embedding_size=self.embedding_size, memory_size=self.memory_size)\r\n        for i in range(30):\r\n            embeddings = torch.randn(batch_size, self.embedding_size)\r\n            labels = torch.arange(batch_size)\r\n            q = self.loss.queue_idx\r\n            self.assertTrue(q==(i*batch_size)%self.memory_size)\r\n            loss = self.loss(embeddings, labels)\r\n\r\n            start_idx = q\r\n            if q+batch_size == self.memory_size:\r\n                end_idx = self.memory_size\r\n            else:\r\n                end_idx = (q+batch_size)%self.memory_size\r\n            if start_idx < end_idx:\r\n                self.assertTrue(torch.equal(embeddings, self.loss.embedding_memory[start_idx:end_idx]))\r\n                self.assertTrue(torch.equal(labels, self.loss.label_memory[start_idx:end_idx]))\r\n            else:\r\n                correct_embeddings = torch.cat([self.loss.embedding_memory[start_idx:], self.loss.embedding_memory[:end_idx]], dim=0)\r\n                correct_labels = torch.cat([self.loss.label_memory[start_idx:], self.loss.label_memory[:end_idx]], dim=0)\r\n                self.assertTrue(torch.equal(embeddings, correct_embeddings))\r\n                self.assertTrue(torch.equal(labels, correct_labels))\r\n\r\n    def test_shift_indices_tuple(self):\r\n        batch_size = 32\r\n        pair_miner = PairMarginMiner(pos_margin=0, neg_margin=1, use_similarity=False)\r\n        triplet_miner = TripletMarginMiner(margin=1)\r\n        self.loss = CrossBatchMemory(loss=ContrastiveLoss(), embedding_size=self.embedding_size, memory_size=self.memory_size)\r\n        for i in range(30):\r\n            embeddings = torch.randn(batch_size, self.embedding_size)\r\n            labels = torch.arange(batch_size)\r\n            loss = self.loss(embeddings, labels)\r\n            all_labels = torch.cat([labels, self.loss.label_memory], dim=0)\r\n\r\n            indices_tuple = lmu.get_all_pairs_indices(labels, self.loss.label_memory)\r\n            shifted = c_f.shift_indices_tuple(indices_tuple, batch_size)\r\n            self.assertTrue(torch.equal(indices_tuple[0], shifted[0]))\r\n            self.assertTrue(torch.equal(indices_tuple[2], shifted[2]))\r\n            self.assertTrue(torch.equal(indices_tuple[1], shifted[1]-batch_size))\r\n            self.assertTrue(torch.equal(indices_tuple[3], shifted[3]-batch_size))\r\n            a1, p, a2, n = shifted\r\n            self.assertTrue(not torch.any((all_labels[a1]-all_labels[p]).bool()))\r\n            self.assertTrue(torch.all((all_labels[a2]-all_labels[n]).bool()))\r\n            \r\n            indices_tuple = pair_miner(embeddings, labels, self.loss.embedding_memory, self.loss.label_memory)\r\n            shifted = c_f.shift_indices_tuple(indices_tuple, batch_size)\r\n            self.assertTrue(torch.equal(indices_tuple[0], shifted[0]))\r\n            self.assertTrue(torch.equal(indices_tuple[2], shifted[2]))\r\n            self.assertTrue(torch.equal(indices_tuple[1], shifted[1]-batch_size))\r\n            self.assertTrue(torch.equal(indices_tuple[3], shifted[3]-batch_size))\r\n            a1, p, a2, n = shifted\r\n            self.assertTrue(not torch.any((all_labels[a1]-all_labels[p]).bool()))\r\n            self.assertTrue(torch.all((all_labels[a2]-all_labels[n]).bool()))\r\n\r\n            indices_tuple = triplet_miner(embeddings, labels, self.loss.embedding_memory, self.loss.label_memory)\r\n            shifted = c_f.shift_indices_tuple(indices_tuple, batch_size)\r\n            self.assertTrue(torch.equal(indices_tuple[0], shifted[0]))\r\n            self.assertTrue(torch.equal(indices_tuple[1], shifted[1]-batch_size))\r\n            self.assertTrue(torch.equal(indices_tuple[2], shifted[2]-batch_size))\r\n            a, p, n = shifted\r\n            self.assertTrue(not torch.any((all_labels[a]-all_labels[p]).bool()))\r\n            self.assertTrue(torch.all((all_labels[p]-all_labels[n]).bool()))\r\n\r\n\r\n    def test_input_indices_tuple(self):\r\n        batch_size = 32\r\n        pair_miner = PairMarginMiner(pos_margin=0, neg_margin=1, use_similarity=False)\r\n        triplet_miner = TripletMarginMiner(margin=1)\r\n        self.loss = CrossBatchMemory(loss=ContrastiveLoss(), embedding_size=self.embedding_size, memory_size=self.memory_size)\r\n        for i in range(30):\r\n            embeddings = torch.randn(batch_size, self.embedding_size)\r\n            labels = torch.arange(batch_size)\r\n            self.loss(embeddings, labels)\r\n            for curr_miner in [pair_miner, triplet_miner]:\r\n                input_indices_tuple = curr_miner(embeddings, labels)\r\n                all_labels = torch.cat([labels, self.loss.label_memory], dim=0)\r\n                a1ii, pii, a2ii, nii = lmu.convert_to_pairs(input_indices_tuple, labels)\r\n                a1i, pi, a2i, ni = lmu.get_all_pairs_indices(labels, self.loss.label_memory)\r\n                a1, p, a2, n = self.loss.create_indices_tuple(batch_size, embeddings, labels, self.loss.embedding_memory, self.loss.label_memory, input_indices_tuple)\r\n                self.assertTrue(not torch.any((all_labels[a1]-all_labels[p]).bool()))\r\n                self.assertTrue(torch.all((all_labels[a2]-all_labels[n]).bool()))\r\n                self.assertTrue(len(a1) == len(a1i)+len(a1ii))\r\n                self.assertTrue(len(p) == len(pi)+len(pii))\r\n                self.assertTrue(len(a2) == len(a2i)+len(a2ii))\r\n                self.assertTrue(len(n) == len(ni)+len(nii))\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    unittest.main()"""
tests/losses/test_margin_loss.py,7,"b'import unittest\nimport torch\nfrom pytorch_metric_learning.losses import MarginLoss\nfrom pytorch_metric_learning.utils import common_functions as c_f\n\nclass TestMarginLoss(unittest.TestCase):\n    def test_margin_loss(self):\n        margin, nu, beta = 0.1, 0, 1\n        loss_func = MarginLoss(margin=margin, nu=nu, beta=beta)\n\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 0, 1, 1, 2])\n\n        loss = loss_func(embeddings, labels)\n\n        triplets = [(0,1,2), (0,1,3), (0,1,4), (1,0,2), (1,0,3), (1,0,4), (2,3,0), (2,3,1), (2,3,4), (3,2,0), (3,2,1), (3,2,4)]\n\n        correct_total_loss = 0\n        num_non_zero = 0\n        for a, p, n in triplets:\n            anchor, positive, negative = embeddings[a], embeddings[p], embeddings[n]\n            pos_loss = torch.relu(torch.sqrt(torch.sum((anchor-positive)**2)) - beta + margin)\n            neg_loss = torch.relu(beta - torch.sqrt(torch.sum((anchor-negative)**2)) + margin)\n            correct_total_loss += pos_loss + neg_loss\n            if pos_loss > 0:\n                num_non_zero += 1\n            if neg_loss > 0:\n                num_non_zero += 1\n                \n        if num_non_zero > 0:\n            correct_total_loss /= num_non_zero\n\n        self.assertTrue(torch.isclose(loss, correct_total_loss))\n\n\n    def test_with_no_valid_triplets(self):\n        margin, nu, beta = 0.1, 0, 1\n        loss_func = MarginLoss(margin=margin, nu=nu, beta=beta)\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 1, 2, 3, 4])\n        self.assertEqual(loss_func(embeddings, labels), 0)'"
tests/losses/test_multi_similarity_loss.py,10,"b'import unittest\nimport torch\nfrom pytorch_metric_learning.losses import MultiSimilarityLoss\nfrom pytorch_metric_learning.utils import common_functions as c_f\n\nclass TestMultiSimilarityLoss(unittest.TestCase):\n    def test_multi_similarity_loss(self):\n        alpha, beta, base = 0.1, 40, 0.5\n        loss_func = MultiSimilarityLoss(alpha=alpha, beta=beta, base=base)\n\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 0, 1, 1, 2])\n\n        loss = loss_func(embeddings, labels)\n\n        pos_pairs = [(0,1), (1,0), (2,3), (3,2)]\n        neg_pairs = [(0,2), (0,3), (0,4), (1,2), (1,3), (1,4), (2,0), (2,1), (2,4), (3,0), (3,1), (3,4), (4,0), (4,1), (4,2), (4,3)]\n\n        correct_total = 0\n        for i in range(len(embeddings)):\n            correct_pos_loss = 0\n            correct_neg_loss = 0\n            for a,p in pos_pairs:\n                if a == i:\n                    anchor, positive = embeddings[a], embeddings[p]\n                    correct_pos_loss += torch.exp(-alpha*(torch.matmul(anchor,positive)-base))\n            if correct_pos_loss > 0:\n                correct_pos_loss = (1/alpha) * torch.log(1+correct_pos_loss)\n\n            for a,n in neg_pairs:\n                if a == i:\n                    anchor, negative = embeddings[a], embeddings[n]\n                    correct_neg_loss += torch.exp(beta*(torch.matmul(anchor,negative)-base))\n            if correct_neg_loss > 0:\n                correct_neg_loss = (1/beta) * torch.log(1+correct_neg_loss)\n            correct_total += correct_pos_loss + correct_neg_loss\n\n        correct_total /= embeddings.size(0)\n        self.assertTrue(torch.isclose(loss, correct_total))\n\n\n    def test_with_no_valid_pairs(self):\n        alpha, beta, base = 0.1, 40, 0.5\n        loss_func = MultiSimilarityLoss(alpha=alpha, beta=beta, base=base)\n        embedding_angles = [0]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0])\n        self.assertTrue(torch.isclose(loss_func(embeddings, labels), torch.tensor(0.), atol=1e-06)) #tolerance required due to logsumexp floating point errors'"
tests/losses/test_ntxent_loss.py,8,"b'import unittest\nimport torch\nfrom pytorch_metric_learning.losses import NTXentLoss\nfrom pytorch_metric_learning.utils import common_functions as c_f\n\nclass TestNTXentLoss(unittest.TestCase):\n    def test_ntxent_loss(self):\n        temperature = 0.1\n        loss_func = NTXentLoss(temperature=temperature)\n\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 0, 1, 1, 2])\n\n        loss = loss_func(embeddings, labels)\n\n        pos_pairs = [(0,1), (1,0), (2,3), (3,2)]\n        neg_pairs = [(0,2), (0,3), (0,4), (1,2), (1,3), (1,4), (2,0), (2,1), (2,4), (3,0), (3,1), (3,4), (4,0), (4,1), (4,2), (4,3)]\n\n        total_loss = 0\n        for a1,p in pos_pairs:\n            anchor, positive = embeddings[a1], embeddings[p]\n            numerator = torch.exp(torch.matmul(anchor, positive)/temperature)\n            denominator = numerator.clone()\n            for a2,n in neg_pairs:\n                if a2 == a1:\n                    negative = embeddings[n]\n                else:\n                    continue\n                denominator += torch.exp(torch.matmul(anchor, negative)/temperature)\n            curr_loss = -torch.log(numerator/denominator)\n            total_loss += curr_loss\n        \n        total_loss /= len(pos_pairs)\n        self.assertTrue(torch.isclose(loss, total_loss))\n\n\n    def test_with_no_valid_pairs(self):\n        loss = NTXentLoss(temperature=0.1)\n        embedding_angles = [0]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0])\n        self.assertEqual(loss(embeddings, labels), 0)'"
tests/losses/test_triplet_margin_loss.py,7,"b'import unittest\nimport torch\nfrom pytorch_metric_learning.losses import TripletMarginLoss\nfrom pytorch_metric_learning.utils import common_functions as c_f\n\nclass TestTripletMarginLoss(unittest.TestCase):\n    def test_triplet_margin_loss(self):\n        margin = 0.2\n        loss_funcA = TripletMarginLoss(margin=margin, avg_non_zero_only=True)\n        loss_funcB = TripletMarginLoss(margin=margin, avg_non_zero_only=False)\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 0, 1, 1, 2])\n\n        lossA = loss_funcA(embeddings, labels)\n        lossB = loss_funcB(embeddings, labels)\n        \n        triplets = [(0,1,2), (0,1,3), (0,1,4), (1,0,2), (1,0,3), (1,0,4), (2,3,0), (2,3,1), (2,3,4), (3,2,0), (3,2,1), (3,2,4)]\n\n        correct_loss = 0\n        num_non_zero_triplets = 0\n        for a, p, n in triplets:\n            anchor, positive, negative = embeddings[a], embeddings[p], embeddings[n]\n            curr_loss = torch.relu(torch.sqrt(torch.sum((anchor-positive)**2)) - torch.sqrt(torch.sum((anchor-negative)**2)) + margin)\n            if curr_loss > 0:\n                num_non_zero_triplets += 1\n            correct_loss += curr_loss\n        self.assertTrue(torch.isclose(lossA, correct_loss/num_non_zero_triplets))\n        self.assertTrue(torch.isclose(lossB, correct_loss/len(triplets)))\n\n\n    def test_with_no_valid_triplets(self):\n        loss_funcA = TripletMarginLoss(margin=0.2, avg_non_zero_only=True)\n        loss_funcB = TripletMarginLoss(margin=0.2, avg_non_zero_only=False)\n        embedding_angles = [0, 20, 40, 60, 80]\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in embedding_angles]) #2D embeddings\n        labels = torch.LongTensor([0, 1, 2, 3, 4])\n        self.assertEqual(loss_funcA(embeddings, labels), 0)\n        self.assertEqual(loss_funcB(embeddings, labels), 0)'"
tests/miners/__init__.py,0,b''
tests/miners/test_batch_hard_miner.py,17,"b""import unittest\r\nimport torch\r\nfrom pytorch_metric_learning.miners import BatchHardMiner\r\nfrom pytorch_metric_learning.utils import common_functions as c_f\r\nimport numpy as np\r\n\r\nclass TestBatchHardMiner(unittest.TestCase):\r\n\r\n    @classmethod\r\n    def setUpClass(self):\r\n        self.dist_miner = BatchHardMiner(use_similarity=False, normalize_embeddings=False)\r\n        self.normalized_dist_miner = BatchHardMiner(use_similarity=False, normalize_embeddings=True)\r\n        self.normalized_dist_miner_squared = BatchHardMiner(use_similarity=False, normalize_embeddings=True, squared_distances=True)\r\n        self.sim_miner = BatchHardMiner(use_similarity=True, normalize_embeddings=True)\r\n        self.labels = torch.LongTensor([0, 0, 1, 1, 0, 2, 1, 1, 1])\r\n        self.correct_a = torch.LongTensor([0, 1, 2, 3, 4, 6, 7, 8])\r\n        self.correct_p = torch.LongTensor([4, 4, 8, 8, 0, 2, 2, 2])\r\n        self.correct_n = [torch.LongTensor([2, 2, 1, 4, 3, 5, 5, 5]), torch.LongTensor([2, 2, 1, 4, 5, 5, 5, 5])]\r\n\r\n    def test_dist_mining(self):\r\n        embeddings = torch.arange(9).float().unsqueeze(1)\r\n        a, p, n = self.dist_miner(embeddings, self.labels)\r\n        self.helper(a, p, n)\r\n        self.assertTrue(self.dist_miner.hardest_pos_pair_dist == 6)\r\n        self.assertTrue(self.dist_miner.hardest_neg_pair_dist == 1)\r\n\r\n    def test_normalized_dist_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100, 120, 140, 160]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a, p, n = self.normalized_dist_miner(embeddings, self.labels)\r\n        self.helper(a, p, n)\r\n        correct_hardest_pos_pair_dist = torch.sqrt(torch.sum((embeddings[2]-embeddings[8])**2)).item()\r\n        correct_hardest_neg_pair_dist = torch.sqrt(torch.sum((embeddings[1]-embeddings[2])**2)).item()\r\n        self.assertAlmostEqual(self.normalized_dist_miner.hardest_pos_pair_dist, correct_hardest_pos_pair_dist, places=5)\r\n        self.assertAlmostEqual(self.normalized_dist_miner.hardest_neg_pair_dist, correct_hardest_neg_pair_dist, places=5)\r\n\r\n    def test_normalized_dist_squared_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100, 120, 140, 160]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a, p, n = self.normalized_dist_miner_squared(embeddings, self.labels)\r\n        self.helper(a, p, n)\r\n        correct_hardest_pos_pair_dist = torch.sum((embeddings[2]-embeddings[8])**2).item()\r\n        correct_hardest_neg_pair_dist = torch.sum((embeddings[1]-embeddings[2])**2).item()\r\n        self.assertAlmostEqual(self.normalized_dist_miner_squared.hardest_pos_pair_dist, correct_hardest_pos_pair_dist, places=5)\r\n        self.assertAlmostEqual(self.normalized_dist_miner_squared.hardest_neg_pair_dist, correct_hardest_neg_pair_dist, places=5)            \r\n\r\n    def test_sim_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100, 120, 140, 160]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a, p, n = self.sim_miner(embeddings, self.labels)\r\n        self.helper(a, p, n)\r\n        self.assertAlmostEqual(self.sim_miner.hardest_pos_pair_dist, np.cos(np.radians(120)), places=5)\r\n        self.assertAlmostEqual(self.sim_miner.hardest_neg_pair_dist, np.cos(np.radians(20)), places=5)\r\n\r\n    def helper(self, a, p, n):\r\n        self.assertTrue(torch.equal(a, self.correct_a))\r\n        self.assertTrue(torch.equal(p, self.correct_p))\r\n        self.assertTrue(any(torch.equal(n, cn) for cn in self.correct_n))\r\n\r\n    def test_empty_output(self):\r\n        batch_size = 32\r\n        embeddings = torch.randn(batch_size, 64)\r\n        labels = torch.arange(batch_size)\r\n        for miner in [self.dist_miner, self.normalized_dist_miner, self.normalized_dist_miner_squared, self.sim_miner]:\r\n            a, p, n = miner(embeddings, labels)\r\n            self.assertTrue(len(a)==0)\r\n            self.assertTrue(len(p)==0)\r\n            self.assertTrue(len(n)==0)\r\n            self.assertTrue(miner.hardest_pos_pair_dist == 0)\r\n            self.assertTrue(miner.hardest_neg_pair_dist == 0)\r\n\r\nif __name__ == '__main__':\r\n    unittest.main()"""
tests/miners/test_hdc_miner.py,23,"b""import unittest\r\nimport torch\r\nfrom pytorch_metric_learning.miners import HDCMiner\r\nfrom pytorch_metric_learning.utils import common_functions as c_f\r\n\r\nclass TestHDCMiner(unittest.TestCase):\r\n\r\n    @classmethod\r\n    def setUpClass(self):\r\n        self.dist_miner = HDCMiner(filter_percentage=0.3, use_similarity=False, normalize_embeddings=False)\r\n        self.normalized_dist_miner = HDCMiner(filter_percentage=0.3, use_similarity=False, normalize_embeddings=True)\r\n        self.normalized_dist_miner_squared = HDCMiner(filter_percentage=0.3, use_similarity=False, normalize_embeddings=True, squared_distances=True)\r\n        self.sim_miner = HDCMiner(filter_percentage=0.3, use_similarity=True, normalize_embeddings=True)\r\n        self.labels = torch.LongTensor([0, 0, 1, 1, 1, 0])\r\n        correct_a1 = torch.LongTensor([0, 5, 1, 5])\r\n        correct_p = torch.LongTensor([5, 0, 5, 1])\r\n        self.correct_pos_pairs = torch.stack([correct_a1, correct_p], dim=1)\r\n        correct_a2 = torch.LongTensor([1, 2, 4, 5, 0, 2])\r\n        correct_n = torch.LongTensor([2, 1, 5, 4, 2, 0])\r\n        self.correct_neg_pairs = torch.stack([correct_a2, correct_n], dim=1)\r\n\r\n    def test_dist_mining(self):\r\n        embeddings = torch.arange(6).float().unsqueeze(1)\r\n        a1, p, a2, n = self.dist_miner(embeddings, self.labels)\r\n        pos_pairs = torch.stack([a1, p], dim=1)\r\n        neg_pairs = torch.stack([a2, n], dim=1)\r\n        self.helper(pos_pairs, neg_pairs)\r\n\r\n    def test_normalized_dist_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a1, p, a2, n = self.normalized_dist_miner(embeddings, self.labels)\r\n        pos_pairs = torch.stack([a1, p], dim=1)\r\n        neg_pairs = torch.stack([a2, n], dim=1)\r\n        self.helper(pos_pairs, neg_pairs)\r\n\r\n    def test_normalized_dist_squared_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a1, p, a2, n = self.normalized_dist_miner_squared(embeddings, self.labels)\r\n        pos_pairs = torch.stack([a1, p], dim=1)\r\n        neg_pairs = torch.stack([a2, n], dim=1)\r\n        self.helper(pos_pairs, neg_pairs)\r\n\r\n    def test_sim_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a1, p, a2, n = self.sim_miner(embeddings, self.labels)\r\n        pos_pairs = torch.stack([a1, p], dim=1)\r\n        neg_pairs = torch.stack([a2, n], dim=1)\r\n        self.helper(pos_pairs, neg_pairs)\r\n\r\n    def helper(self, pos_pairs, neg_pairs):\r\n        self.assertTrue(len(pos_pairs) == 4)\r\n        self.assertTrue(len(neg_pairs) == 6) \r\n\r\n        diffs = pos_pairs[:,0] - pos_pairs[:,1]\r\n        correct_diffs = self.correct_pos_pairs[:,0] - self.correct_pos_pairs[:,1]\r\n        self.assertTrue(torch.equal(torch.abs(diffs), torch.abs(correct_diffs)))\r\n\r\n        diffs = neg_pairs[:,0] - neg_pairs[:,1]\r\n        correct_diffs = self.correct_neg_pairs[:,0] - self.correct_neg_pairs[:,1]\r\n        self.assertTrue(torch.equal(torch.abs(diffs), torch.abs(correct_diffs)))\r\n\r\n    def test_empty_output(self):\r\n        batch_size = 32\r\n        embeddings = torch.randn(batch_size, 64)\r\n        labels = torch.arange(batch_size)\r\n        for miner in [self.dist_miner, self.normalized_dist_miner, self.normalized_dist_miner_squared, self.sim_miner]:\r\n            a1, p, _, _ = miner(embeddings, labels)\r\n            self.assertTrue(len(a1)==0)\r\n            self.assertTrue(len(p)==0)\r\n\r\n\r\nif __name__ == '__main__':\r\n    unittest.main()"""
tests/miners/test_pair_margin_miner.py,15,"b""import unittest\r\nimport torch\r\nfrom pytorch_metric_learning.miners import PairMarginMiner\r\nfrom pytorch_metric_learning.utils import common_functions as c_f\r\n\r\nclass TestPairMarginMiner(unittest.TestCase):\r\n\r\n    @classmethod\r\n    def setUpClass(self):\r\n        self.dist_miner = PairMarginMiner(pos_margin=4, neg_margin=4, use_similarity=False, normalize_embeddings=False)\r\n        self.normalized_dist_miner = PairMarginMiner(pos_margin=1.29, neg_margin=1.28, use_similarity=False, normalize_embeddings=True)\r\n        self.normalized_dist_miner_squared = PairMarginMiner(pos_margin=1.66, neg_margin=1.64, use_similarity=False, normalize_embeddings=True, squared_distances=True)\r\n        self.sim_miner = PairMarginMiner(pos_margin=0.17, neg_margin=0.18, use_similarity=True, normalize_embeddings=True)\r\n        self.labels = torch.LongTensor([0, 0, 1, 1, 0, 2, 1, 1, 1])\r\n        self.correct_a1 = torch.LongTensor([2, 2, 3, 7, 8, 8])\r\n        self.correct_p = torch.LongTensor([7, 8, 8, 2, 2, 3])\r\n        self.correct_a2 = torch.LongTensor([0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 8])\r\n        self.correct_n = torch.LongTensor([2, 3, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 5, 6, 7, 2, 3, 4, 6, 7, 8, 4, 5, 4, 5, 5])\r\n\r\n    def test_dist_mining(self):\r\n        embeddings = torch.arange(9).float().unsqueeze(1)\r\n        a1, p, a2, n = self.dist_miner(embeddings, self.labels)\r\n        self.helper(a1, p, a2, n, self.dist_miner)\r\n\r\n    def test_normalized_dist_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100, 120, 140, 160]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a1, p, a2, n = self.normalized_dist_miner(embeddings, self.labels)\r\n        self.helper(a1, p, a2, n, self.normalized_dist_miner)\r\n\r\n    def test_normalized_dist_squared_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100, 120, 140, 160]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a1, p, a2, n = self.normalized_dist_miner_squared(embeddings, self.labels)\r\n        self.helper(a1, p, a2, n, self.normalized_dist_miner_squared)    \r\n\r\n    def test_sim_mining(self):\r\n        angles = [0, 20, 40, 60, 80, 100, 120, 140, 160]\r\n        embeddings = torch.FloatTensor([c_f.angle_to_coord(a) for a in angles])\r\n        a1, p, a2, n = self.sim_miner(embeddings, self.labels)\r\n        self.helper(a1, p, a2, n, self.sim_miner)\r\n\r\n    def helper(self, a1, p, a2, n, miner):\r\n        self.assertTrue(torch.equal(a1, self.correct_a1))\r\n        self.assertTrue(torch.equal(p, self.correct_p))\r\n        self.assertTrue(torch.equal(a2, self.correct_a2))\r\n        self.assertTrue(torch.equal(n, self.correct_n))\r\n        self.assertTrue(miner.pos_pair_dist>0)\r\n        self.assertTrue(miner.neg_pair_dist>0)\r\n\r\n    def test_empty_output(self):\r\n        batch_size = 32\r\n        embeddings = torch.randn(batch_size, 64)\r\n        labels = torch.arange(batch_size)\r\n        for miner in [self.dist_miner, self.normalized_dist_miner, self.normalized_dist_miner_squared, self.sim_miner]:\r\n            a1, p, _, _ = miner(embeddings, labels)\r\n            self.assertTrue(len(a1)==0)\r\n            self.assertTrue(len(p)==0)\r\n            self.assertTrue(miner.pos_pair_dist==0)\r\n\r\nif __name__ == '__main__':\r\n    unittest.main()"""
tests/utils/__init__.py,0,b''
tests/utils/test_calculate_accuracies.py,0,"b'import unittest\r\nfrom pytorch_metric_learning.utils import accuracy_calculator\r\nimport numpy as np\r\n\r\nclass TestCalculateAccuracies(unittest.TestCase):\r\n\r\n    def test_accuracy_calculator(self):\r\n        query_labels = np.array([0, 1, 2, 3, 4])\r\n        knn_labels = np.array([[0, 1, 1, 2, 2],\r\n                                    [1, 0, 1, 1, 3],\r\n                                    [4, 4, 4, 4, 2],\r\n                                    [3, 1, 3, 1, 3],\r\n                                    [0, 0, 4, 2, 2]])\r\n        label_counts = {0:2, 1:3, 2:5, 3:4, 4:5}\r\n        AC = accuracy_calculator.AccuracyCalculator(exclude=(""NMI"", ""AMI""))\r\n        kwargs = {""query_labels"": query_labels,\r\n                ""label_counts"": label_counts,\r\n                ""knn_labels"": knn_labels,\r\n                ""not_lone_query_idx"": range(5)}\r\n\r\n        function_dict = AC.get_function_dict()\r\n\r\n        for ecfss in [False, True]:\r\n            if ecfss:\r\n                kwargs[""knn_labels""] = kwargs[""knn_labels""][:, 1:]\r\n            kwargs[""embeddings_come_from_same_source""] = ecfss\r\n            acc = AC._get_accuracy(function_dict, **kwargs)\r\n            self.assertTrue(acc[""precision_at_1""]==self.correct_precision_at_1(ecfss))\r\n            self.assertTrue(acc[""r_precision""]==self.correct_r_precision(ecfss))\r\n            self.assertTrue(acc[""mean_average_precision_at_r""]==self.correct_mean_average_precision_at_r(ecfss))\r\n\r\n\r\n    def correct_precision_at_1(self, embeddings_come_from_same_source):\r\n        if not embeddings_come_from_same_source:\r\n            return 0.6\r\n        return 0\r\n        \r\n    def correct_r_precision(self, embeddings_come_from_same_source):\r\n        if not embeddings_come_from_same_source:\r\n            return np.mean([1./2, 2./3, 1./5, 2./4, 1./5])\r\n        return np.mean([0./1, 1./2, 1./4, 1./3, 1./4])\r\n\r\n    def correct_mean_average_precision_at_r(self, embeddings_come_from_same_source):\r\n        if not embeddings_come_from_same_source:\r\n            acc0 = (1) / 2\r\n            acc1 = (1 + 2./3) / 3\r\n            acc2 = (1./5) / 5\r\n            acc3 = (1 + 2./3) / 4\r\n            acc4 = (1./3) / 5\r\n            return np.mean([acc0, acc1, acc2, acc3, acc4])\r\n        else:\r\n            acc0 = 0\r\n            acc1 = (1./2) / 2\r\n            acc2 = (1./4) / 4\r\n            acc3 = (1./2) / 3\r\n            acc4 = (1./2) / 4\r\n            return np.mean([acc0, acc1, acc2, acc3, acc4])\r\n\r\n    def test_get_label_counts(self):\r\n        label_counts, num_k = accuracy_calculator.get_label_counts([0,1,3,2,3,1,3,3,4,6,5,10,4,4,4,4,6,6,5])\r\n        self.assertTrue(label_counts=={0:1, 1:2, 2:1, 3:4, 4:5, 5:2, 6:3, 10:1})\r\n        self.assertTrue(num_k==5)\r\n\r\n\r\n    def test_get_lone_query_labels(self):\r\n        query_labels = np.array([0, 1, 2, 3, 4, 5, 6])\r\n        reference_labels = np.array([0,0,0,1,2,2,3,4,5,6])\r\n        reference_label_counts, _ = accuracy_calculator.get_label_counts(reference_labels)\r\n\r\n        lone_query_labels = accuracy_calculator.get_lone_query_labels(query_labels, reference_labels, reference_label_counts, True)\r\n        self.assertTrue(np.all(np.unique(lone_query_labels) == np.array([1, 3, 4, 5, 6])))\r\n\r\n        query_labels = np.array([0, 1, 2, 3, 4])\r\n        reference_labels = np.array([0,0,0,1,2,2,4,5,6])\r\n\r\n        lone_query_labels = accuracy_calculator.get_lone_query_labels(query_labels, reference_labels, reference_label_counts, False)\r\n        self.assertTrue(np.all(np.unique(lone_query_labels) == np.array([3])))\r\n\r\n\r\n\r\nclass TestCalculateAccuraciesAndFaiss(unittest.TestCase):\r\n    \r\n    def test_accuracy_calculator_and_faiss(self):\r\n        AC = accuracy_calculator.AccuracyCalculator(exclude=(""NMI"", ""AMI""))\r\n\r\n        query = np.arange(10)[:,None].astype(np.float32)\r\n        reference = np.arange(10)[:,None].astype(np.float32)\r\n        query_labels = np.arange(10).astype(np.int)\r\n        reference_labels = np.arange(10).astype(np.int)\r\n        acc = AC.get_accuracy(query, reference, query_labels, reference_labels, False)\r\n        self.assertTrue(acc[""precision_at_1""] == 1)\r\n        self.assertTrue(acc[""r_precision""] == 1)\r\n        self.assertTrue(acc[""mean_average_precision_at_r""] == 1)\r\n\r\n        reference = (np.arange(20)/2.)[:,None].astype(np.float32)\r\n        reference_labels = np.zeros(20).astype(np.int)\r\n        reference_labels[::2] = query_labels\r\n        reference_labels[1::2] = np.ones(10).astype(np.int)\r\n        acc = AC.get_accuracy(query, reference, query_labels, reference_labels, True)\r\n        self.assertTrue(acc[""precision_at_1""] == 1)\r\n        self.assertTrue(acc[""r_precision""] == 0.5)\r\n        self.assertTrue(acc[""mean_average_precision_at_r""] == (1 + 2./2 + 3./5 + 4./7 + 5./9) / 10)\r\n\r\n\r\n    def test_accuracy_calculator_and_faiss_avg_of_avgs(self):\r\n        AC_global_average = accuracy_calculator.AccuracyCalculator(exclude=(""NMI"", ""AMI""), avg_of_avgs=False)\r\n        AC_per_class_average = accuracy_calculator.AccuracyCalculator(exclude=(""NMI"", ""AMI""), avg_of_avgs=True)\r\n        query = np.arange(10)[:,None].astype(np.float32)\r\n        reference = np.arange(10)[:,None].astype(np.float32)\r\n        query[-1] = 100\r\n        reference[0] = -100\r\n        query_labels = np.array([0,0,0,0,0,0,0,0,0,1])\r\n        reference_labels = np.array([1,0,0,0,0,0,0,0,0,0])\r\n        acc = AC_global_average.get_accuracy(query, reference, query_labels, reference_labels, False)\r\n        self.assertTrue(acc[""precision_at_1""] == 0.9)\r\n        self.assertTrue(acc[""r_precision""] == 0.9)\r\n        self.assertTrue(acc[""mean_average_precision_at_r""] == 0.9)\r\n\r\n        acc = AC_per_class_average.get_accuracy(query, reference, query_labels, reference_labels, False)\r\n        self.assertTrue(acc[""precision_at_1""] == 0.5)\r\n        self.assertTrue(acc[""r_precision""] == 0.5)\r\n        self.assertTrue(acc[""mean_average_precision_at_r""] == 0.5)\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    unittest.main()'"
tests/utils/test_loss_and_miner_utils.py,27,"b""import unittest\r\nfrom pytorch_metric_learning.utils import loss_and_miner_utils as lmu\r\nimport torch\r\n\r\nclass TestLossAndMinerUtils(unittest.TestCase):\r\n\r\n    def test_logsumexp(self):\r\n        mat = torch.FloatTensor([[-1, 0, 1, 10, 50],\r\n                                [-30, -20, 0, 20, 30],\r\n                                [10, 20, 30, 40, 50],\r\n                                [0,0,0,0,0]])\r\n        result = lmu.logsumexp(mat, keep_mask=None, add_one=False, dim=1)\r\n        correct_result = torch.logsumexp(mat, dim=1, keepdim=True)\r\n        self.assertTrue(torch.equal(result, correct_result))\r\n\r\n        result = lmu.logsumexp(mat, keep_mask=None, add_one=True, dim=1)\r\n        correct_result = torch.logsumexp(torch.cat([mat, torch.zeros(mat.size(0)).unsqueeze(1)], dim=1), dim=1, keepdim=True)\r\n        self.assertTrue(torch.equal(result, correct_result))\r\n\r\n        keep_mask = torch.FloatTensor([[1, 1, 0, 0, 0],\r\n                                        [0, 1, 1, 1, 0],\r\n                                        [0, 0, 0, 0, 0],\r\n                                        [0, 1, 1, 0, 0]])\r\n        result = lmu.logsumexp(mat, keep_mask=keep_mask, add_one=False, dim=1)\r\n\r\n        row0 = torch.log(torch.sum(torch.exp(torch.FloatTensor([-1, 0])))).unsqueeze(0)\r\n        row1 = torch.log(torch.sum(torch.exp(torch.FloatTensor([-20, 0, 20])))).unsqueeze(0)\r\n        row2 = torch.FloatTensor([0.])\r\n        row3 = torch.log(torch.sum(torch.exp(torch.FloatTensor([0, 0])))).unsqueeze(0)\r\n        correct_result = torch.stack([row0, row1, row2, row3], dim=0)\r\n        self.assertTrue(torch.allclose(result, correct_result))\r\n\r\n\r\n    def test_get_all_pairs_triplets_indices(self):\r\n        original_x = torch.arange(10)\r\n\r\n        for i in range(1, 11):\r\n            x = original_x.repeat(i)\r\n            correct_num_pos = len(x)*(i-1)\r\n            correct_num_neg = len(x)*(len(x)-i)\r\n            a1, p, a2, n = lmu.get_all_pairs_indices(x)\r\n            self.assertTrue(len(a1) == len(p) == correct_num_pos)\r\n            self.assertTrue(len(a2) == len(n) == correct_num_neg)\r\n\r\n            correct_num_triplets = len(x)*(i-1)*(len(x)-i)\r\n            a, p, n = lmu.get_all_triplets_indices(x)\r\n            self.assertTrue(len(a) == len(p) == len(n) == correct_num_triplets)\r\n\r\n\r\n    def test_convert_to_triplets(self):\r\n        a1 = torch.LongTensor([0,1,2,3])\r\n        p = torch.LongTensor([4,4,4,4])\r\n        a2 = torch.LongTensor([4,5,6,7])\r\n        n = torch.LongTensor([5,5,6,6])\r\n        triplets = lmu.convert_to_triplets((a1,p,a2,n), labels=torch.arange(7))\r\n        self.assertTrue(all(len(x)==0 for x in triplets))\r\n\r\n        a2 = torch.LongTensor([0,4,5,6])\r\n        triplets = lmu.convert_to_triplets((a1,p,a2,n), labels=torch.arange(7))\r\n        self.assertTrue(triplets==[torch.LongTensor([0]),torch.LongTensor([4]), torch.LongTensor([5])])\r\n\r\n    def test_convert_to_weights(self):\r\n        a = torch.LongTensor([0,1,2,3])\r\n        p = torch.LongTensor([4,4,4,4])\r\n        n = torch.LongTensor([5,5,6,6])\r\n        weights = lmu.convert_to_weights((a,p,n), labels=torch.arange(7))\r\n        correct_weights = torch.FloatTensor([0.25,0.25,0.25,0.25,1,0.5,0.5])\r\n        self.assertTrue(torch.all(weights==correct_weights))\r\n\r\n            \r\nif __name__ == '__main__':\r\n    unittest.main()"""
src/pytorch_metric_learning/losses/__init__.py,0,"b'from .base_metric_loss_function import BaseMetricLossFunction, MultipleLosses\r\nfrom .angular_loss import AngularLoss\r\nfrom .arcface_loss import ArcFaceLoss\r\nfrom .circle_loss import CircleLoss\r\nfrom .contrastive_loss import ContrastiveLoss\r\nfrom .cosface_loss import CosFaceLoss\r\nfrom .cross_batch_memory import CrossBatchMemory\r\nfrom .fast_ap_loss import FastAPLoss\r\nfrom .generic_pair_loss import GenericPairLoss\r\nfrom .intra_pair_variance_loss import IntraPairVarianceLoss\r\nfrom .large_margin_softmax_loss import LargeMarginSoftmaxLoss\r\nfrom .lifted_structure_loss import GeneralizedLiftedStructureLoss\r\nfrom .margin_loss import MarginLoss\r\nfrom .multi_similarity_loss import MultiSimilarityLoss\r\nfrom .nca_loss import NCALoss\r\nfrom .normalized_softmax_loss import NormalizedSoftmaxLoss\r\nfrom .ntxent_loss import NTXentLoss\r\nfrom .n_pairs_loss import NPairsLoss\r\nfrom .proxy_anchor_loss import ProxyAnchorLoss\r\nfrom .proxy_losses import ProxyNCALoss\r\nfrom .signal_to_noise_ratio_losses import SignalToNoiseRatioContrastiveLoss\r\nfrom .soft_triple_loss import SoftTripleLoss\r\nfrom .sphereface_loss import SphereFaceLoss\r\nfrom .triplet_margin_loss import TripletMarginLoss\r\nfrom .tuplet_margin_loss import TupletMarginLoss\r\nfrom .weight_regularizer_mixin import WeightRegularizerMixin\r\n'"
src/pytorch_metric_learning/losses/angular_loss.py,9,"b'#! /usr/bin/env python3\n\nfrom .base_metric_loss_function import BaseMetricLossFunction\nimport numpy as np\nimport torch\nfrom ..utils import loss_and_miner_utils as lmu\n\nclass AngularLoss(BaseMetricLossFunction):\n    """"""\n    Implementation of https://arxiv.org/abs/1708.01682\n    Args:\n        alpha: The angle (as described in the paper), specified in degrees.\n    """"""\n    def __init__(self, alpha, **kwargs):\n        super().__init__(**kwargs)\n        self.alpha = torch.tensor(np.radians(alpha))\n        self.add_to_recordable_attributes(list_of_names=[""average_angle""])\n        \n    def compute_loss(self, embeddings, labels, indices_tuple):\n        anchors, positives, keep_mask = self.set_stats_get_pairs(embeddings, labels, indices_tuple)\n        if anchors is None: return 0\n\n        sq_tan_alpha = torch.tan(self.alpha) ** 2\n        ap_dot = torch.sum(anchors * positives, dim=1, keepdim=True)\n        ap_matmul_embeddings = torch.matmul((anchors + positives),(embeddings.unsqueeze(2)))\n        ap_matmul_embeddings = ap_matmul_embeddings.squeeze(2).t()\n\n        final_form = (4 * sq_tan_alpha * ap_matmul_embeddings) - (2 * (1 + sq_tan_alpha) * ap_dot)\n        final_form = self.maybe_modify_loss(final_form)\n        return torch.mean(lmu.logsumexp(final_form, keep_mask=keep_mask, add_one=True))\n\n    def set_stats_get_pairs(self, embeddings, labels, indices_tuple):\n        a1, p, a2, _ = lmu.convert_to_pairs(indices_tuple, labels)\n        if len(a1) == 0 or len(a2) == 0:\n            return [None]*3\n        anchors, positives = embeddings[a1], embeddings[p]\n        keep_mask = (labels[a1].unsqueeze(1) != labels.unsqueeze(0)).float()\n\n        centers = (anchors + positives) / 2\n        ap_dist = torch.nn.functional.pairwise_distance(anchors, positives, 2)\n        nc_dist = torch.norm(centers - embeddings.unsqueeze(1), p=2, dim=2).t()\n        angles = torch.atan(ap_dist.unsqueeze(1) / (2*nc_dist))\n        average_angle = torch.sum(angles*keep_mask) / torch.sum(keep_mask)\n        self.average_angle = np.degrees(average_angle.item())\n        return anchors, positives, keep_mask\n\n    def maybe_modify_loss(self, x):\n        return x\n'"
src/pytorch_metric_learning/losses/arcface_loss.py,1,"b'#! /usr/bin/env python3\r\n\r\nfrom .large_margin_softmax_loss import LargeMarginSoftmaxLoss\r\nimport numpy as np\r\nimport torch\r\n\r\nclass ArcFaceLoss(LargeMarginSoftmaxLoss):\r\n    """"""\r\n    Implementation of https://arxiv.org/pdf/1801.07698.pdf\r\n    """"""\r\n    def __init__(self, scale=64, **kwargs):\r\n        kwargs.pop(""normalize_weights"", None)\r\n        super().__init__(scale=scale, normalize_weights=True, **kwargs)\r\n\r\n    def init_margin(self):\r\n        self.margin = np.radians(self.margin)\r\n\r\n    def modify_cosine_of_target_classes(self, cosine_of_target_classes, *args):\r\n        angles = self.get_angles(cosine_of_target_classes)\r\n        return torch.cos(angles + self.margin)\r\n\r\n'"
src/pytorch_metric_learning/losses/base_metric_loss_function.py,8,"b'#! /usr/bin/env python3\n\nimport torch\nfrom ..utils import common_functions as c_f\n\nclass BaseMetricLossFunction(torch.nn.Module):\n    """"""\n    All loss functions extend this class\n    Args:\n        normalize_embeddings: type boolean. If True then normalize embeddins\n                                to have norm = 1 before computing the loss\n        num_class_per_param: type int. The number of classes for each parameter.\n                            If your parameters don\'t have a separate value for each class,\n                            then leave this at None\n        learnable_param_names: type list of strings. Each element is the name of\n                            attributes that should be converted to nn.Parameter \n    """"""\n    def __init__(\n        self,\n        normalize_embeddings=True,\n        num_class_per_param=None,\n        learnable_param_names=None,\n    ):\n        super().__init__()\n        self.normalize_embeddings = normalize_embeddings\n        self.num_class_per_param = num_class_per_param\n        self.learnable_param_names = learnable_param_names\n        self.initialize_learnable_parameters()\n        self.add_to_recordable_attributes(name=""avg_embedding_norm"")\n\n    def compute_loss(self, embeddings, labels, indices_tuple=None):\n        """"""\n        This has to be implemented and is what actually computes the loss.\n        """"""\n        raise NotImplementedError\n\n    def forward(self, embeddings, labels, indices_tuple=None):\n        """"""\n        Args:\n            embeddings: tensor of size (batch_size, embedding_size)\n            labels: tensor of size (batch_size)\n            indices_tuple: tuple of size 3 for triplets (anchors, positives, negatives)\n                            or size 4 for pairs (anchor1, postives, anchor2, negatives)\n                            Can also be left as None\n        Returns: the loss (float)\n        """"""\n        c_f.assert_embeddings_and_labels_are_same_size(embeddings, labels)\n        labels = labels.to(embeddings.device)\n        if self.normalize_embeddings:\n            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n        self.embedding_norms = torch.norm(embeddings, p=2, dim=1)\n        self.avg_embedding_norm = torch.mean(self.embedding_norms)\n\n        loss = self.compute_loss(embeddings, labels, indices_tuple)\n        if loss == 0:\n            loss = torch.sum(embeddings*0)\n        return loss\n\n    def initialize_learnable_parameters(self):\n        """"""\n        To learn hyperparams, create an attribute called learnable_param_names.\n        This should be a list of strings which are the names of the\n        hyperparameters to be learned\n        """"""\n        if self.learnable_param_names is not None:\n            for k in self.learnable_param_names:\n                v = getattr(self, k)\n                setattr(self, k, self.create_learnable_parameter(v))\n\n    def create_learnable_parameter(self, init_value, unsqueeze=False):\n        """"""\n        Returns nn.Parameter with an initial value of init_value\n        and size of num_labels\n        """"""\n        vec_len = self.num_class_per_param if self.num_class_per_param else 1\n        if unsqueeze:\n            vec_len = (vec_len, 1)\n        p = torch.nn.Parameter(torch.ones(vec_len) * init_value)\n        return p\n\n    def maybe_mask_param(self, param, labels):\n        """"""\n        This returns the hyperparameters corresponding to class labels (if applicable).\n        If there is a hyperparameter for each class, then when computing the loss,\n        the class hyperparameter has to be matched to the corresponding embedding.\n        """"""\n        if self.num_class_per_param:\n            return param[labels]\n        return param\n\n    def add_to_recordable_attributes(self, name=None, list_of_names=None):\n        c_f.add_to_recordable_attributes(self, name=name, list_of_names=list_of_names)\n\n\n\nclass MultipleLosses(torch.nn.Module):\n    def __init__(self, losses, weights=None):\n        super().__init__()\n        self.losses = torch.nn.ModuleList(losses)\n        self.weights = weights if weights is not None else [1]*len(self.losses)\n\n    def forward(self, embeddings, labels, indices_tuple=None):\n        total_loss = 0\n        for i, loss in enumerate(self.losses):\n            total_loss += loss(embeddings, labels, indices_tuple)*self.weights[i]\n        return total_loss'"
src/pytorch_metric_learning/losses/circle_loss.py,8,"b'#! /usr/bin/env python3\n\nfrom .base_metric_loss_function import BaseMetricLossFunction\nimport torch \nimport torch.nn.functional as F \nfrom ..utils import loss_and_miner_utils as lmu \n\n\nclass CircleLoss(BaseMetricLossFunction):\n    """"""\n    Circle loss for pairwise labels only. Support for class-level labels will be added \n    in the future.\n    \n    Args:\n    m:  The relaxation factor that controls the radious of the decision boundary.\n    gamma: The scale factor that determines the largest scale of each similarity score.\n\n    According to the paper, the suggested default values of m and gamma are:\n\n    Face Recognition: m = 0.25, gamma = 256\n    Person Reidentification: m = 0.25, gamma = 256\n    Fine-grained Image Retrieval: m = 0.4, gamma = 80\n\n    By default, we set m = 0.4 and gamma = 80\n    """"""\n    def __init__(\n        self, \n        m=0.4,\n        gamma=80,\n        triplets_per_anchor=\'all\',\n        **kwargs\n    ):\n        super(CircleLoss, self).__init__(**kwargs)\n        self.m = m \n        self.gamma = gamma \n        self.triplets_per_anchor = triplets_per_anchor\n        self.add_to_recordable_attributes(list_of_names=[""num_unique_anchors"", ""num_triplets""])\n        self.soft_plus = torch.nn.Softplus(beta=1)\n\n        assert self.normalize_embeddings, ""Embeddings must be normalized in circle loss!""\n\n    def compute_loss(self, embeddings, labels, indices_tuple):\n        indices_tuple = lmu.convert_to_triplets(indices_tuple, labels, t_per_anchor=self.triplets_per_anchor)\n        anchor_idx, positive_idx, negative_idx = indices_tuple \n        self.num_triplets = len(anchor_idx)\n        if self.num_triplets == 0:\n            self.num_unique_anchors = 0\n            return 0\n        anchors, positives, negatives = embeddings[anchor_idx], embeddings[positive_idx], embeddings[negative_idx]\n        \n        # compute cosine similarities\n        # since embeddings are normalized, we only need to compute dot product \n        sp = torch.sum(anchors * positives, dim=1)\n        sn = torch.sum(anchors * negatives, dim=1)\n        \n        # compute some constants\n        loss = 0.\n        op = 1 + self.m \n        on = -self.m\n        delta_p = 1-self.m \n        delta_n = self.m \n\n        # find unique anchor index \n        # for each unique anchor index, we have (sp1, sp2, ..., spK) (sn1, sn2, ..., snL)\n        unique_anchor_idx = torch.unique(anchor_idx)\n        self.num_unique_anchors = len(unique_anchor_idx)\n\n        for anchor in unique_anchor_idx:\n            mask = anchor_idx == anchor \n            sp_for_this_anchor = sp[mask]\n            sn_for_this_anchor = sn[mask]\n            alpha_p = torch.clamp(op - sp_for_this_anchor.detach(), min=0.)\n            alpha_n = torch.clamp(sn_for_this_anchor.detach() - on, min=0.)\n\n            logit_p = -self.gamma * alpha_p * (sp_for_this_anchor - delta_p)\n            logit_n = self.gamma * alpha_n * (sn_for_this_anchor - delta_n)\n\n            loss_for_this_anchor = self.soft_plus(\n                torch.logsumexp(logit_n, dim=0) + torch.logsumexp(logit_p, dim=0))\n            loss += loss_for_this_anchor\n        \n        loss /= len(unique_anchor_idx)\n        return loss\n\n\n\n\n\n\n'"
src/pytorch_metric_learning/losses/contrastive_loss.py,6,"b'#! /usr/bin/env python3\n\nimport torch\n\nfrom .generic_pair_loss import GenericPairLoss\n\n\nclass ContrastiveLoss(GenericPairLoss):\n    """"""\n    Contrastive loss using either distance or similarity.\n    Args:\n        pos_margin: The distance (or similarity) over (under) which positive pairs will contribute to the loss.\n        neg_margin: The distance (or similarity) under (over) which negative pairs will contribute to the loss.  \n        use_similarity: If True, will use dot product between vectors instead of euclidean distance\n        power: Each pair\'s loss will be raised to this power.\n        avg_non_zero_only: Only pairs that contribute non-zero loss will be used in the final loss. \n    """"""\n    def __init__(\n        self,\n        pos_margin=0,\n        neg_margin=1,\n        use_similarity=False,\n        power=1,\n        avg_non_zero_only=True,\n        **kwargs\n    ):\n        super().__init__(use_similarity=use_similarity, mat_based_loss=False, **kwargs)\n        self.pos_margin = pos_margin\n        self.neg_margin = neg_margin\n        self.avg_non_zero_only = avg_non_zero_only\n        self.power = power\n        self.add_to_recordable_attributes(list_of_names=[""num_non_zero_pos_pairs"", ""num_non_zero_neg_pairs""])\n        \n\n    def _compute_loss(self, pos_pair_dist, neg_pair_dist, *_):\n        pos_loss, neg_loss = 0, 0\n        self.num_non_zero_pos_pairs, self.num_non_zero_neg_pairs = 0, 0\n        if len(pos_pair_dist) > 0:\n            pos_loss, self.num_non_zero_pos_pairs = self.mask_margin_and_calculate_loss(pos_pair_dist, ""pos"")\n        if len(neg_pair_dist) > 0:\n            neg_loss, self.num_non_zero_neg_pairs = self.mask_margin_and_calculate_loss(neg_pair_dist, ""neg"")\n        return pos_loss + neg_loss\n\n    def mask_margin_and_calculate_loss(self, pair_dists, pos_or_neg):\n        loss_calc_func = self.pos_calc if pos_or_neg == ""pos"" else self.neg_calc\n        margin = self.pos_margin if pos_or_neg == ""pos"" else self.neg_margin\n        per_pair_loss = loss_calc_func(pair_dists, margin) ** self.power\n        num_non_zero_pairs = (per_pair_loss > 0).nonzero().size(0)\n        if self.avg_non_zero_only:\n            if num_non_zero_pairs > 0:\n                loss = torch.sum(per_pair_loss) / num_non_zero_pairs\n            else:\n                loss = 0\n        else:\n            loss = torch.mean(per_pair_loss)\n        return loss, num_non_zero_pairs\n\n    def pos_calc(self, pos_pair_dist, margin):\n        return (\n            torch.nn.functional.relu(margin - pos_pair_dist)\n            if self.use_similarity\n            else torch.nn.functional.relu(pos_pair_dist - margin)\n        )\n\n    def neg_calc(self, neg_pair_dist, margin):\n        return (\n            torch.nn.functional.relu(neg_pair_dist - margin)\n            if self.use_similarity\n            else torch.nn.functional.relu(margin - neg_pair_dist)\n        )\n'"
src/pytorch_metric_learning/losses/cosface_loss.py,0,"b'#! /usr/bin/env python3\r\n\r\nfrom .large_margin_softmax_loss import LargeMarginSoftmaxLoss\r\nimport numpy as np\r\nimport torch\r\n\r\nclass CosFaceLoss(LargeMarginSoftmaxLoss):\r\n    """"""\r\n    Implementation of https://arxiv.org/pdf/1801.07698.pdf\r\n    """"""\r\n    def __init__(self, scale=64, **kwargs):\r\n        kwargs.pop(""normalize_weights"", None)\r\n        super().__init__(scale=scale, normalize_weights=True, **kwargs)\r\n\r\n    def init_margin(self):\r\n        pass\r\n\r\n    def modify_cosine_of_target_classes(self, cosine_of_target_classes, *args):\r\n        self.get_angles(cosine_of_target_classes) # For analysis purposes\r\n        return cosine_of_target_classes - self.margin\r\n'"
src/pytorch_metric_learning/losses/cross_batch_memory.py,6,"b'import torch\r\nfrom ..utils import common_functions as c_f, loss_and_miner_utils as lmu\r\n\r\nclass CrossBatchMemory(torch.nn.Module):\r\n    def __init__(self, loss, embedding_size, memory_size=1024, miner=None):\r\n        super().__init__()\r\n        self.loss = loss\r\n        self.miner = miner\r\n        self.memory_size = memory_size\r\n        self.embedding_memory = torch.zeros(self.memory_size, embedding_size)\r\n        self.label_memory = torch.zeros(self.memory_size).long()\r\n        self.has_been_filled = False\r\n        self.queue_idx = 0\r\n\r\n    def forward(self, embeddings, labels, input_indices_tuple=None):\r\n        assert embeddings.size(0) <= self.embedding_memory.size(0)\r\n        batch_size = embeddings.size(0)\r\n        labels = labels.to(embeddings.device)\r\n        self.embedding_memory = self.embedding_memory.to(embeddings.device)\r\n        self.label_memory = self.label_memory.to(labels.device)\r\n        self.add_to_memory(embeddings, labels, batch_size)\r\n        \r\n        if not self.has_been_filled:\r\n            E_mem = self.embedding_memory[:self.queue_idx]\r\n            L_mem = self.label_memory[:self.queue_idx] \r\n        else:\r\n            E_mem = self.embedding_memory\r\n            L_mem = self.label_memory\r\n\r\n        indices_tuple = self.create_indices_tuple(batch_size, embeddings, labels, E_mem, L_mem, input_indices_tuple)\r\n        combined_embeddings = torch.cat([embeddings, E_mem], dim=0)\r\n        combined_labels = torch.cat([labels, L_mem], dim=0)\r\n        loss = self.loss(combined_embeddings, combined_labels, indices_tuple)\r\n        return loss\r\n\r\n    def add_to_memory(self, embeddings, labels, batch_size):\r\n        end_idx = ((self.queue_idx + batch_size - 1) % (self.memory_size)) + 1\r\n\r\n        if end_idx > self.queue_idx:\r\n            self.embedding_memory[self.queue_idx:end_idx] = embeddings.detach()\r\n            self.label_memory[self.queue_idx:end_idx] = labels.detach()            \r\n        else:\r\n            se = self.memory_size-self.queue_idx\r\n            self.embedding_memory[self.queue_idx:] = embeddings[:se].detach()\r\n            self.embedding_memory[:end_idx] = embeddings[se:].detach()\r\n            self.label_memory[self.queue_idx:] = labels[:se].detach()\r\n            self.label_memory[:end_idx] = labels[se:].detach()\r\n            \r\n\r\n        prev_queue_idx = self.queue_idx\r\n        self.queue_idx = (self.queue_idx + batch_size) % self.memory_size\r\n\r\n        if (not self.has_been_filled) and (self.queue_idx <= prev_queue_idx):\r\n            self.has_been_filled = True\r\n\r\n\r\n    def create_indices_tuple(self, batch_size, embeddings, labels, E_mem, L_mem, input_indices_tuple):\r\n        if self.miner:\r\n        \tindices_tuple = self.miner(embeddings, labels, E_mem, L_mem)\r\n        else:\r\n        \tindices_tuple = lmu.get_all_pairs_indices(labels, L_mem)\r\n        \r\n        indices_tuple = c_f.shift_indices_tuple(indices_tuple, batch_size)\r\n\r\n        if input_indices_tuple is not None:\r\n            if len(input_indices_tuple) == 3 and len(indices_tuple) == 4:\r\n                input_indices_tuple = lmu.convert_to_pairs(input_indices_tuple, labels)\r\n            elif len(input_indices_tuple) == 4 and len(indices_tuple) == 3:\r\n                input_indices_tuple = lmu.convert_to_triplets(input_indices_tuple, labels)\r\n            indices_tuple = tuple([torch.cat([x,y.to(x.device)], dim=0) for x,y in zip(indices_tuple, input_indices_tuple)])\r\n\r\n        return indices_tuple'"
src/pytorch_metric_learning/losses/fast_ap_loss.py,15,"b'import torch\r\nfrom .base_metric_loss_function import BaseMetricLossFunction\r\nfrom ..utils import loss_and_miner_utils as lmu\r\n\r\nclass FastAPLoss(BaseMetricLossFunction):\r\n    def __init__(self, num_bins, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.num_bins = int(num_bins)\r\n        self.num_edges = self.num_bins + 1\r\n\r\n    """"""\r\n    Adapted from https://github.com/kunhe/FastAP-metric-learning\r\n    """"""\r\n    def compute_loss(self, embeddings, labels, indices_tuple):\r\n        miner_weights = lmu.convert_to_weights(indices_tuple, labels)\r\n        N = labels.size(0)\r\n        a1_idx, p_idx, a2_idx, n_idx = lmu.get_all_pairs_indices(labels)\r\n        I_pos = torch.zeros(N, N).to(embeddings.device)\r\n        I_neg = torch.zeros(N, N).to(embeddings.device)\r\n        I_pos[a1_idx, p_idx] = 1\r\n        I_neg[a2_idx, n_idx] = 1\r\n        N_pos = torch.sum(I_pos, dim=1)\r\n        dist_mat = lmu.dist_mat(embeddings, squared=True)\r\n\r\n        histogram_max = 4. if self.normalize_embeddings else torch.max(dist_mat).item()\r\n        histogram_delta = histogram_max / self.num_bins\r\n        mid_points = torch.linspace(0., histogram_max, steps=self.num_edges).view(-1,1,1).to(embeddings.device)\r\n        pulse = torch.nn.functional.relu(1 - torch.abs(dist_mat-mid_points)/histogram_delta)\r\n        pos_hist = torch.t(torch.sum(pulse * I_pos, dim=2))\r\n        neg_hist = torch.t(torch.sum(pulse * I_neg, dim=2))\r\n\r\n        total_pos_hist = torch.cumsum(pos_hist, dim=1)\r\n        total_hist = torch.cumsum(pos_hist + neg_hist, dim=1)\r\n        \r\n        loss = 0\r\n        h_pos_product = pos_hist * total_pos_hist\r\n        safe_H = (h_pos_product > 0) & (total_hist > 0)\r\n        if torch.sum(safe_H) > 0:\r\n            FastAP = torch.zeros_like(pos_hist).to(embeddings.device)\r\n            FastAP[safe_H] = h_pos_product[safe_H] / total_hist[safe_H]\r\n            FastAP = torch.sum(FastAP, dim=1)\r\n            safe_N = (N_pos > 0)\r\n            if torch.sum(safe_N) > 0:\r\n                FastAP = FastAP[safe_N] / N_pos[safe_N]\r\n                FastAP = (1-FastAP)*miner_weights[safe_N]\r\n                loss = torch.mean(FastAP)\r\n        return loss\r\n\r\n'"
src/pytorch_metric_learning/losses/generic_pair_loss.py,1,"b'#! /usr/bin/env python3\n\n\nimport torch\nfrom ..utils import loss_and_miner_utils as lmu\nfrom .base_metric_loss_function import BaseMetricLossFunction\n\n\nclass GenericPairLoss(BaseMetricLossFunction):\n    """"""\n    The function pair_based_loss has to be implemented by the child class.\n    By default, this class extracts every positive and negative pair within a\n    batch (based on labels) and passes the pairs to the loss function.\n    The pairs can be passed to the loss function all at once (self.loss_once)\n    or pairs can be passed iteratively (self.loss_loop) by going through each\n    sample in a batch, and selecting just the positive and negative pairs\n    containing that sample.\n    Args:\n        use_similarity: set to True if the loss function uses pairwise similarity\n                        (dot product of each embedding pair). Otherwise,\n                        euclidean distance will be used\n        iterate_through_loss: set to True to use self.loss_loop and False otherwise\n        squared_distances: if True, then the euclidean distance will be squared.\n    """"""\n\n    def __init__(\n        self, use_similarity, mat_based_loss, squared_distances=False, **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.use_similarity = use_similarity\n        self.squared_distances = squared_distances\n        self.loss_method = self.mat_based_loss if mat_based_loss else self.pair_based_loss\n        \n    def compute_loss(self, embeddings, labels, indices_tuple):\n        mat = lmu.get_pairwise_mat(embeddings, embeddings, self.use_similarity, self.squared_distances)\n        if self.use_similarity and not self.normalize_embeddings:\n            embedding_norms_mat = self.embedding_norms.unsqueeze(0)*self.embedding_norms.unsqueeze(1)\n            mat = mat / (embedding_norms_mat)\n        indices_tuple = lmu.convert_to_pairs(indices_tuple, labels)\n        return self.loss_method(mat, labels, indices_tuple)\n\n    def _compute_loss(self):\n        raise NotImplementedError\n\n    def mat_based_loss(self, mat, labels, indices_tuple):\n        a1, p, a2, n = indices_tuple\n        pos_mask, neg_mask = torch.zeros_like(mat), torch.zeros_like(mat)\n        pos_mask[a1, p] = 1\n        neg_mask[a2, n] = 1\n        return self._compute_loss(mat, pos_mask, neg_mask)\n\n    def pair_based_loss(self, mat, labels, indices_tuple):\n        a1, p, a2, n = indices_tuple\n        pos_pair, neg_pair = [], []\n        if len(a1) > 0:\n            pos_pair = mat[a1, p]\n        if len(a2) > 0:\n            neg_pair = mat[a2, n]\n        return self._compute_loss(pos_pair, neg_pair, indices_tuple)\n'"
src/pytorch_metric_learning/losses/intra_pair_variance_loss.py,4,"b'#! /usr/bin/env python3\r\n\r\nfrom ..losses import GenericPairLoss\r\nimport torch\r\nfrom ..utils import loss_and_miner_utils as lmu\r\n\r\nclass IntraPairVarianceLoss(GenericPairLoss):\r\n\r\n    def __init__(self, pos_eps=0.01, neg_eps=0.01, **kwargs):\r\n        super().__init__(**kwargs, use_similarity=True, mat_based_loss=False)        \r\n        self.pos_eps = pos_eps\r\n        self.neg_eps = neg_eps\r\n        self.add_to_recordable_attributes(list_of_names=[""pos_loss"", ""neg_loss""])\r\n    \r\n    # pos_pairs and neg_pairs already represent cos(theta)\r\n    def _compute_loss(self, pos_pairs, neg_pairs, indices_tuple):\r\n        self.pos_loss, self.neg_loss = 0, 0\r\n        if len(pos_pairs) > 0:\r\n            mean_pos_sim = torch.mean(pos_pairs)\r\n            pos_var = (1-self.pos_eps)*mean_pos_sim - pos_pairs\r\n            self.pos_loss = torch.mean(torch.nn.functional.relu(pos_var)**2)\r\n        if len(neg_pairs) > 0:\r\n            mean_neg_sim = torch.mean(neg_pairs)\r\n            neg_var = neg_pairs - (1+self.neg_eps)*mean_neg_sim\r\n            self.neg_loss = torch.mean(torch.nn.functional.relu(neg_var)**2)\r\n        return self.pos_loss+self.neg_loss\r\n\r\n'"
src/pytorch_metric_learning/losses/large_margin_softmax_loss.py,16,"b'#! /usr/bin/env python3\r\n\r\nfrom .weight_regularizer_mixin import WeightRegularizerMixin\r\nfrom .base_metric_loss_function import BaseMetricLossFunction\r\nfrom ..utils import loss_and_miner_utils as lmu\r\nimport scipy.special\r\nimport torch\r\nimport math\r\nimport numpy as np\r\n\r\nclass LargeMarginSoftmaxLoss(WeightRegularizerMixin, BaseMetricLossFunction):\r\n    """"""\r\n    Implementation of https://arxiv.org/pdf/1612.02295.pdf\r\n    """"""\r\n    def __init__(self, margin, num_classes, embedding_size, scale=1, normalize_weights=False, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.margin = margin\r\n        self.num_classes = num_classes\r\n        self.scale = scale\r\n        self.normalize_weights = normalize_weights\r\n        self.add_to_recordable_attributes(name=""avg_angle"")\r\n        self.init_margin()\r\n        self.W = torch.nn.Parameter(torch.randn(embedding_size, num_classes))\r\n        self.cross_entropy = torch.nn.CrossEntropyLoss(reduction=\'none\')\r\n\r\n    def init_margin(self):\r\n        self.margin = int(self.margin)\r\n        self.max_n = (self.margin // 2)\r\n        ## For the trigonometric multiple-angle formula ##\r\n        self.n_range = torch.FloatTensor([n for n in range(0, self.max_n+1)])\r\n        self.margin_choose_n = torch.FloatTensor([scipy.special.binom(self.margin, 2*n) for n in self.n_range])\r\n        self.cos_powers = torch.FloatTensor([self.margin-(2*n) for n in self.n_range])\r\n        self.alternating = torch.FloatTensor([(-1)**n for n in self.n_range])\r\n\r\n    def get_cos_with_margin(self, cosine):\r\n        cosine = cosine.unsqueeze(1)\r\n        for attr in [""n_range"", ""margin_choose_n"", ""cos_powers"", ""alternating""]:\r\n            setattr(self, attr, getattr(self, attr).to(cosine.device))\r\n        cos_powered = cosine**self.cos_powers\r\n        sin_powered = (1-cosine**2)**self.n_range\r\n        terms = self.alternating*self.margin_choose_n*cos_powered*sin_powered # Equation 7 in the paper\r\n        return torch.sum(terms, dim=1)\r\n\r\n    def get_weights(self):\r\n        if self.normalize_weights:\r\n            return torch.nn.functional.normalize(self.W, p=2, dim=0)\r\n        return self.W\r\n\r\n    def get_cosine(self, embeddings):\r\n        weights = self.get_weights()\r\n        self.weight_norms = torch.norm(weights, p=2, dim=0)\r\n        # self.embedding_norms is computed in BaseMetricLossFunction\r\n        return torch.matmul(embeddings, weights) / (self.weight_norms.unsqueeze(0)*self.embedding_norms.unsqueeze(1)) \r\n\r\n    def get_angles(self, cosine_of_target_classes):\r\n        angles = torch.acos(torch.clamp(cosine_of_target_classes, -1 + 1e-7, 1 - 1e-7))\r\n        self.avg_angle = np.degrees(torch.mean(angles).item())\r\n        return angles\r\n\r\n    def get_target_mask(self, embeddings, labels):\r\n        batch_size = labels.size(0)\r\n        mask = torch.zeros(batch_size, self.num_classes).to(embeddings.device)\r\n        mask[torch.arange(batch_size), labels] = 1\r\n        return mask\r\n\r\n    def modify_cosine_of_target_classes(self, cosine_of_target_classes, *args):\r\n        _, _, labels, _ = args\r\n        cos_with_margin = self.get_cos_with_margin(cosine_of_target_classes)\r\n        angles = self.get_angles(cosine_of_target_classes)\r\n        with torch.no_grad():\r\n            k = (angles / (math.pi / self.margin)).floor() # Equation 6: angles needs to be between [k*pi/m and (k+1)*pi/m]\r\n        phi = ((-1)**k)*cos_with_margin - (2*k)\r\n        target_weight_norms = self.weight_norms[labels]\r\n        return phi*target_weight_norms*self.embedding_norms\r\n\r\n    def compute_loss(self, embeddings, labels, indices_tuple):\r\n        miner_weights = lmu.convert_to_weights(indices_tuple, labels)\r\n        mask = self.get_target_mask(embeddings, labels)\r\n        cosine = self.get_cosine(embeddings)\r\n        cosine_of_target_classes = cosine[mask == 1]\r\n        modified_cosine_of_target_classes = self.modify_cosine_of_target_classes(cosine_of_target_classes, cosine, embeddings, labels, mask)\r\n        diff = (modified_cosine_of_target_classes - cosine_of_target_classes).unsqueeze(1)\r\n        cosine = cosine + (mask*diff)\r\n        unweighted_loss = self.cross_entropy(cosine * self.scale, labels)\r\n        return torch.mean(unweighted_loss*miner_weights) + self.regularization_loss(self.W.t())'"
src/pytorch_metric_learning/losses/lifted_structure_loss.py,1,"b'#! /usr/bin/env python3\n\nimport torch\n\nfrom .generic_pair_loss import GenericPairLoss\nfrom ..utils import loss_and_miner_utils as lmu\n\n\nclass GeneralizedLiftedStructureLoss(GenericPairLoss):\n    # The \'generalized\' lifted structure loss shown on page 4\n    # of the ""in defense of triplet loss"" paper\n    # https://arxiv.org/pdf/1703.07737.pdf\n    def __init__(self, neg_margin, **kwargs):\n        super().__init__(use_similarity=False, mat_based_loss=True, **kwargs)\n        self.neg_margin = neg_margin\n\n    def _compute_loss(self, mat, pos_mask, neg_mask):\n        pos_loss = lmu.logsumexp(mat, keep_mask=pos_mask, add_one=False)\n        neg_loss = lmu.logsumexp(self.neg_margin - mat, keep_mask=neg_mask, add_one=False)\n        return torch.mean(torch.relu(pos_loss+neg_loss))\n'"
src/pytorch_metric_learning/losses/margin_loss.py,6,"b'#! /usr/bin/env python3\n\nfrom .base_metric_loss_function import BaseMetricLossFunction\nimport torch\nfrom ..utils import loss_and_miner_utils as lmu, common_functions as c_f\n\n\nclass MarginLoss(BaseMetricLossFunction):\n\n    def __init__(self, margin, nu, beta, triplets_per_anchor=""all"", **kwargs):\n        self.margin = margin\n        self.nu = nu\n        self.beta = beta\n        self.triplets_per_anchor = triplets_per_anchor\n        self.add_to_recordable_attributes(list_of_names=[""num_pos_pairs"", ""num_neg_pairs"", ""margin_loss"", ""beta_reg_loss""])\n        super().__init__(**kwargs)\n\n    def compute_loss(self, embeddings, labels, indices_tuple):\n        anchor_idx, positive_idx, negative_idx = lmu.convert_to_triplets(indices_tuple, labels, self.triplets_per_anchor)\n        if len(anchor_idx) == 0:\n            self.num_pos_pairs = 0\n            self.num_neg_pairs = 0\n            return 0\n        anchors, positives, negatives = embeddings[anchor_idx], embeddings[positive_idx], embeddings[negative_idx]\n        beta = self.maybe_mask_param(self.beta, labels[anchor_idx])\n        self.beta_reg_loss = self.compute_reg_loss(beta)\n\n        d_ap = torch.nn.functional.pairwise_distance(positives, anchors, p=2)\n        d_an = torch.nn.functional.pairwise_distance(negatives, anchors, p=2)\n\n        pos_loss = torch.nn.functional.relu(d_ap - beta + self.margin)\n        neg_loss = torch.nn.functional.relu(beta - d_an + self.margin)\n\n        self.num_pos_pairs = (pos_loss > 0.0).nonzero().size(0)\n        self.num_neg_pairs = (neg_loss > 0.0).nonzero().size(0)\n\n        pair_count = self.num_pos_pairs + self.num_neg_pairs \n\n        if pair_count > 0:\n            self.margin_loss = torch.sum(pos_loss + neg_loss) / pair_count\n            self.beta_reg_loss = self.beta_reg_loss / pair_count\n        else:\n            self.margin_loss, self.beta_reg_loss = 0, 0\n            \n        return self.margin_loss + self.beta_reg_loss\n\n    def compute_reg_loss(self, beta):\n        if self.nu > 0:\n            beta_sum = c_f.try_torch_operation(torch.sum, beta)\n            return beta_sum * self.nu\n        return 0'"
src/pytorch_metric_learning/losses/multi_similarity_loss.py,1,"b'#! /usr/bin/env python3\n\nimport torch\n\nfrom .generic_pair_loss import GenericPairLoss\nfrom ..utils import common_functions as c_f, loss_and_miner_utils as lmu\n\nclass MultiSimilarityLoss(GenericPairLoss):\n    """"""\n    modified from https://github.com/MalongTech/research-ms-loss/\n    Args:\n        alpha: The exponential weight for positive pairs\n        beta: The exponential weight for negative pairs\n        base: The shift in the exponent applied to both positive and negative pairs\n    """"""\n    def __init__(self, alpha, beta, base=0.5, **kwargs):\n        super().__init__(use_similarity=True, mat_based_loss=True, **kwargs)\n        self.alpha = alpha\n        self.beta = beta\n        self.base = base\n\n    def _compute_loss(self, mat, pos_mask, neg_mask):\n        pos_loss = (1.0/self.alpha) * lmu.logsumexp(-self.alpha * (mat - self.base), keep_mask=pos_mask, add_one=True)\n        neg_loss = (1.0/self.beta) * lmu.logsumexp(self.beta * (mat - self.base), keep_mask=neg_mask, add_one=True)\n        return torch.mean(pos_loss + neg_loss)'"
src/pytorch_metric_learning/losses/n_pairs_loss.py,5,"b'#! /usr/bin/env python3\n\nfrom .base_metric_loss_function import BaseMetricLossFunction\nimport torch\nfrom ..utils import loss_and_miner_utils as lmu\n\n\nclass NPairsLoss(BaseMetricLossFunction):\n    """"""\n    Implementation of https://arxiv.org/abs/1708.01682\n    Args:\n        l2_reg_weight: The L2 regularizer weight (multiplier)\n    """"""\n    def __init__(self, l2_reg_weight=0, **kwargs):\n        super().__init__(**kwargs)\n        self.l2_reg_weight = l2_reg_weight\n        self.add_to_recordable_attributes(name=""num_pairs"")\n        self.cross_entropy = torch.nn.CrossEntropyLoss()\n\n    def compute_loss(self, embeddings, labels, indices_tuple):\n        self.avg_embedding_norm = torch.mean(torch.norm(embeddings, p=2, dim=1))\n        anchor_idx, positive_idx = lmu.convert_to_pos_pairs_with_unique_labels(indices_tuple, labels)\n        self.num_pairs = len(anchor_idx)\n        if self.num_pairs == 0:\n            return 0\n        anchors, positives = embeddings[anchor_idx], embeddings[positive_idx]\n        targets = torch.arange(self.num_pairs).to(embeddings.device)\n        sim_mat = torch.matmul(anchors, positives.t())\n        s_loss = self.cross_entropy(sim_mat, targets)\n        if self.l2_reg_weight > 0:\n            l2_reg = torch.mean(torch.norm(embeddings, p=2, dim=1))\n            return s_loss + l2_reg * self.l2_reg_weight\n        return s_loss\n'"
src/pytorch_metric_learning/losses/nca_loss.py,4,"b""#! /usr/bin/env python3\n\nfrom .base_metric_loss_function import BaseMetricLossFunction\nfrom ..utils import loss_and_miner_utils as lmu\nimport torch\n\nclass NCALoss(BaseMetricLossFunction):\n    def __init__(self, softmax_scale=1, **kwargs):\n        super().__init__(**kwargs)\n        self.softmax_scale = softmax_scale\n\n    # https://www.cs.toronto.edu/~hinton/absps/nca.pdf\n    def compute_loss(self, embeddings, labels, indices_tuple):\n        return self.nca_computation(embeddings, embeddings, labels, labels, indices_tuple)\n\n    def nca_computation(self, query, reference, query_labels, reference_labels, indices_tuple):\n        miner_weights = lmu.convert_to_weights(indices_tuple, query_labels)\n        x = -lmu.dist_mat(query, reference, squared=True)\n        if query is reference:\n            diag_idx = torch.arange(query.size(0))\n            x[diag_idx, diag_idx] = float('-inf')\n        same_labels = (query_labels.unsqueeze(1) == reference_labels.unsqueeze(0)).float()\n        exp = torch.nn.functional.softmax(self.softmax_scale*x, dim=1)\n        exp = torch.sum(exp * same_labels, dim=1)\n        non_zero = exp!=0\n        return -torch.mean(torch.log(exp[non_zero])*miner_weights[non_zero])"""
src/pytorch_metric_learning/losses/normalized_softmax_loss.py,5,"b""from .weight_regularizer_mixin import WeightRegularizerMixin\r\nfrom .base_metric_loss_function import BaseMetricLossFunction\r\nimport torch\r\nfrom ..utils import loss_and_miner_utils as lmu\r\n\r\nclass NormalizedSoftmaxLoss(WeightRegularizerMixin, BaseMetricLossFunction):\r\n    def __init__(self, temperature, embedding_size, num_classes, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.temperature = temperature\r\n        self.W = torch.nn.Parameter(torch.randn(embedding_size, num_classes))\r\n        self.cross_entropy = torch.nn.CrossEntropyLoss(reduction='none')\r\n        \r\n    def compute_loss(self, embeddings, labels, indices_tuple):\r\n        miner_weights = lmu.convert_to_weights(indices_tuple, labels)\r\n        normalized_W = torch.nn.functional.normalize(self.W, p=2, dim=0)\r\n        exponent = torch.matmul(embeddings, normalized_W) / self.temperature\r\n        unweighted_loss = self.cross_entropy(exponent, labels)\r\n        return torch.mean(unweighted_loss*miner_weights) + self.regularization_loss(self.W.t())"""
src/pytorch_metric_learning/losses/ntxent_loss.py,5,"b""import torch\r\nfrom .generic_pair_loss import GenericPairLoss\r\n\r\nclass NTXentLoss(GenericPairLoss):\r\n\r\n    def __init__(self, temperature, **kwargs):\r\n        super().__init__(**kwargs, use_similarity=True, mat_based_loss=False)\r\n        self.temperature = temperature\r\n\r\n    def _compute_loss(self, pos_pairs, neg_pairs, indices_tuple):\r\n        a1, _, a2, _ = indices_tuple\r\n\r\n        if len(a1) > 0 and len(a2) > 0:\r\n            pos_pairs = pos_pairs.unsqueeze(1) / self.temperature\r\n            neg_pairs = neg_pairs / self.temperature\r\n            n_per_p = (a2.unsqueeze(0) == a1.unsqueeze(1)).float()\r\n            neg_pairs = neg_pairs*n_per_p\r\n            neg_pairs[n_per_p==0] = float('-inf')\r\n\r\n            max_val = torch.max(pos_pairs, torch.max(neg_pairs, dim=1, keepdim=True)[0])\r\n            numerator = torch.exp(pos_pairs - max_val).squeeze(1)\r\n            denominator = torch.sum(torch.exp(neg_pairs - max_val), dim=1) + numerator\r\n            log_exp = torch.log((numerator/denominator) + 1e-20)\r\n            return torch.mean(-log_exp)\r\n        return 0\r\n\r\n\r\n\r\n"""
src/pytorch_metric_learning/losses/proxy_anchor_loss.py,8,"b""from .weight_regularizer_mixin import WeightRegularizerMixin\r\nfrom .base_metric_loss_function import BaseMetricLossFunction\r\nimport torch\r\nfrom ..utils import loss_and_miner_utils as lmu\r\n\r\n# adapted from \r\n# https://github.com/tjddus9597/Proxy-Anchor-CVPR2020/blob/master/code/losses.py\r\n# https://github.com/geonm/proxy-anchor-loss/blob/master/pytorch-proxy-anchor.py\r\n# suggested in this issue: https://github.com/KevinMusgrave/pytorch-metric-learning/issues/32\r\nclass ProxyAnchorLoss(WeightRegularizerMixin, BaseMetricLossFunction):\r\n    def __init__(self, num_classes, embedding_size, margin = 0.1, alpha = 32, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.proxies = torch.nn.Parameter(torch.randn(num_classes, embedding_size))\r\n        torch.nn.init.kaiming_normal_(self.proxies, mode='fan_out')\r\n        self.num_classes = num_classes\r\n        self.margin = margin\r\n        self.alpha = alpha\r\n        \r\n    def compute_loss(self, embeddings, labels, indices_tuple):\r\n        miner_weights = lmu.convert_to_weights(indices_tuple, labels).unsqueeze(1)\r\n        prox = torch.nn.functional.normalize(self.proxies, p=2, dim=1) if self.normalize_embeddings else self.proxies\r\n        cos = lmu.sim_mat(embeddings, prox)\r\n\r\n        if not self.normalize_embeddings:\r\n            embedding_norms_mat = self.embedding_norms.unsqueeze(0)*torch.norm(prox, p=2, dim=1, keepdim=True)\r\n            cos = cos / (embedding_norms_mat.t())\r\n\r\n        pos_mask = torch.nn.functional.one_hot(labels, self.num_classes).float()\r\n        neg_mask = 1 - pos_mask\r\n\r\n        with_pos_proxies = torch.nonzero(torch.sum(pos_mask, dim=0) != 0).squeeze(1)\r\n\r\n        pos_term = lmu.logsumexp(-self.alpha * (cos - self.margin), keep_mask=pos_mask*miner_weights, add_one=True, dim=0)\r\n        neg_term = lmu.logsumexp(self.alpha * (cos + self.margin), keep_mask=neg_mask*miner_weights, add_one=True, dim=0)\r\n        \r\n        pos_term = torch.sum(pos_term) / len(with_pos_proxies)\r\n        neg_term = torch.sum(neg_term) / self.num_classes\r\n           \r\n        return pos_term + neg_term + self.regularization_loss(self.proxies)\r\n"""
src/pytorch_metric_learning/losses/proxy_losses.py,3,"b'#! /usr/bin/env python3\n\nfrom .nca_loss import NCALoss\nfrom .weight_regularizer_mixin import WeightRegularizerMixin\nfrom ..utils import loss_and_miner_utils as lmu\nimport torch\n\nclass ProxyNCALoss(WeightRegularizerMixin, NCALoss):\n    def __init__(self, num_classes, embedding_size, **kwargs):\n        super().__init__(**kwargs)\n        self.proxies = torch.nn.Parameter(torch.randn(num_classes, embedding_size))\n        self.proxy_labels = torch.arange(num_classes)\n        \n    def compute_loss(self, embeddings, labels, indices_tuple):\n        if self.normalize_embeddings:\n            prox = torch.nn.functional.normalize(self.proxies, p=2, dim=1)\n        else:\n            prox = self.proxies\n        nca_loss = self.nca_computation(embeddings, prox, labels, self.proxy_labels.to(labels.device), indices_tuple)\n        reg_loss = self.regularization_loss(self.proxies)\n        return nca_loss + reg_loss\n'"
src/pytorch_metric_learning/losses/signal_to_noise_ratio_losses.py,5,"b'#! /usr/bin/env python3\r\n\r\n\r\nimport torch\r\nfrom ..utils import loss_and_miner_utils as lmu\r\nfrom .base_metric_loss_function import BaseMetricLossFunction\r\n\r\n\r\ndef SNR_dist(x, y, dim):\r\n    return torch.var(x-y, dim=dim) / torch.var(x, dim=dim)\r\n\r\n\r\nclass SignalToNoiseRatioContrastiveLoss(BaseMetricLossFunction):\r\n\r\n    def __init__(self, pos_margin, neg_margin, regularizer_weight, avg_non_zero_only=True, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.pos_margin = pos_margin\r\n        self.neg_margin = neg_margin\r\n        self.regularizer_weight = regularizer_weight\r\n        self.avg_non_zero_only = avg_non_zero_only\r\n        self.add_to_recordable_attributes(list_of_names=[""num_non_zero_pos_pairs"", ""num_non_zero_neg_pairs"", ""feature_distance_from_zero_mean_distribution""])\r\n        \r\n    def compute_loss(self, embeddings, labels, indices_tuple):\r\n        a1, p, a2, n = lmu.convert_to_pairs(indices_tuple, labels)\r\n        pos_loss, neg_loss, reg_loss = 0, 0, 0\r\n        if len(a1) > 0:\r\n            pos_loss, self.num_non_zero_pos_pairs = self.mask_margin_and_calculate_loss(embeddings[a1], embeddings[p], labels[a1], self.pos_margin, 1)\r\n        if len(a2) > 0:\r\n            neg_loss, self.num_non_zero_neg_pairs = self.mask_margin_and_calculate_loss(embeddings[a2], embeddings[n], labels[a2], self.neg_margin, -1)\r\n        self.feature_distance_from_zero_mean_distribution = torch.mean(torch.abs(torch.sum(embeddings, dim=1)))\r\n        if self.regularizer_weight > 0:\r\n            reg_loss = self.regularizer_weight * self.feature_distance_from_zero_mean_distribution\r\n        return pos_loss + neg_loss + reg_loss\r\n\r\n\r\n    def mask_margin_and_calculate_loss(self, anchors, others, labels, margin, before_relu_multiplier):\r\n        d = SNR_dist(anchors, others, dim=1)\r\n        d = torch.nn.functional.relu((d-margin)*before_relu_multiplier)\r\n        num_non_zero_pairs = (d > 0).nonzero().size(0)\r\n        if self.avg_non_zero_only:\r\n            if num_non_zero_pairs > 0:\r\n                d = torch.sum(d) / num_non_zero_pairs\r\n            else:\r\n                d = 0\r\n        else:\r\n            d = torch.mean(d)\r\n        return d, num_non_zero_pairs'"
src/pytorch_metric_learning/losses/soft_triple_loss.py,15,"b'from .base_metric_loss_function import BaseMetricLossFunction\r\nfrom ..utils import loss_and_miner_utils as lmu\r\nimport math\r\nimport torch\r\nimport torch.nn.functional as F\r\n\r\n###### modified from https://github.com/idstcv/SoftTriple/blob/master/loss/SoftTriple.py ######\r\n###### Original code is Copyright@Alibaba Group ######\r\n###### ICCV\'19: ""SoftTriple Loss: Deep Metric Learning Without Triplet Sampling"" ######\r\nclass SoftTripleLoss(BaseMetricLossFunction):\r\n    def __init__(self, embedding_size, num_classes, centers_per_class, la=20, gamma=0.1, reg_weight=0.2, margin=0.01, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.la = la\r\n        self.gamma = 1./gamma\r\n        self.reg_weight = reg_weight\r\n        self.margin = margin\r\n        self.num_classes = num_classes\r\n        self.centers_per_class = centers_per_class\r\n        self.total_num_centers = num_classes * centers_per_class\r\n        self.fc = torch.nn.Parameter(torch.Tensor(embedding_size, self.total_num_centers))\r\n        self.set_class_masks(num_classes, centers_per_class)\r\n        torch.nn.init.kaiming_uniform_(self.fc, a=math.sqrt(5))\r\n        self.add_to_recordable_attributes(list_of_names=[""same_class_center_similarity"", ""diff_class_center_similarity""])\r\n\r\n    def compute_loss(self, embeddings, labels, indices_tuple):\r\n        miner_weights = lmu.convert_to_weights(indices_tuple, labels)\r\n        centers = F.normalize(self.fc, p=2, dim=0) if self.normalize_embeddings else self.fc\r\n        sim_to_centers = torch.matmul(embeddings, centers)\r\n        sim_to_centers = sim_to_centers.view(-1, self.num_classes, self.centers_per_class)\r\n        prob = F.softmax(sim_to_centers*self.gamma, dim=2)\r\n        sim_to_classes = torch.sum(prob*sim_to_centers, dim=2)\r\n        margin = torch.zeros(sim_to_classes.shape).to(embeddings.device)\r\n        margin[torch.arange(0, margin.shape[0]), labels] = self.margin\r\n        loss = F.cross_entropy(self.la*(sim_to_classes-margin), labels, reduction=\'none\')\r\n        loss = torch.mean(loss*miner_weights)\r\n\r\n        #regularization which encourages the centers of a class to be close to each other\r\n        reg = 0\r\n        if self.reg_weight > 0 and self.centers_per_class > 1:\r\n            center_similarities = centers.t().matmul(centers)\r\n            reg = torch.sum(torch.sqrt(2.0+1e-5-2.*center_similarities[self.same_class_mask]))/(torch.sum(self.same_class_mask))\r\n            self.set_stats(center_similarities)\r\n            \r\n        return loss+self.reg_weight*reg\r\n\r\n    def set_class_masks(self, num_classes, centers_per_class):\r\n        self.diff_class_mask = torch.ones(self.total_num_centers, self.total_num_centers, dtype=torch.bool)\r\n        if centers_per_class > 1:\r\n            self.same_class_mask = torch.zeros(self.total_num_centers, self.total_num_centers, dtype=torch.bool)\r\n        for i in range(num_classes):\r\n            s, e = i*centers_per_class, (i+1)*centers_per_class\r\n            if centers_per_class > 1:\r\n                curr_block = torch.ones(centers_per_class, centers_per_class)\r\n                curr_block = torch.triu(curr_block, diagonal=1)\r\n                self.same_class_mask[s:e, s:e] = curr_block\r\n            self.diff_class_mask[s:e, s:e] = 0\r\n\r\n    def set_stats(self, center_similarities):\r\n        if self.centers_per_class > 1:\r\n            self.same_class_center_similarity = torch.mean(center_similarities[self.same_class_mask])\r\n        self.diff_class_center_similarity = torch.mean(center_similarities[self.diff_class_mask])\r\n'"
src/pytorch_metric_learning/losses/sphereface_loss.py,0,"b'from .large_margin_softmax_loss import LargeMarginSoftmaxLoss\r\n\r\nclass SphereFaceLoss(LargeMarginSoftmaxLoss):\r\n\t# implementation of https://arxiv.org/pdf/1704.08063.pdf\r\n    def __init__(self, **kwargs):\r\n        kwargs.pop(""normalize_weights"", None)\r\n        super().__init__(normalize_weights=True, **kwargs)'"
src/pytorch_metric_learning/losses/triplet_margin_loss.py,6,"b'#! /usr/bin/env python3\n\nfrom .base_metric_loss_function import BaseMetricLossFunction\nimport torch\nimport torch.nn.functional as F\nfrom ..utils import loss_and_miner_utils as lmu\n\n\nclass TripletMarginLoss(BaseMetricLossFunction):\n    """"""\n    Args:\n        margin: The desired difference between the anchor-positive distance and the\n                anchor-negative distance.\n        distance_norm: The norm used when calculating distance between embeddings\n        power: Each pair\'s loss will be raised to this power.\n        swap: Use the positive-negative distance instead of anchor-negative distance,\n              if it violates the margin more.\n        smooth_loss: Use the log-exp version of the triplet loss\n        avg_non_zero_only: Only pairs that contribute non-zero loss will be used in the final loss.\n    """"""\n    def __init__(\n        self,\n        margin=0.05,\n        distance_norm=2,\n        power=1,\n        swap=False,\n        smooth_loss=False,\n        avg_non_zero_only=True,\n        triplets_per_anchor=""all"",\n        **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.margin = margin\n        self.distance_norm = distance_norm\n        self.power = power\n        self.swap = swap\n        self.smooth_loss = smooth_loss\n        self.avg_non_zero_only = avg_non_zero_only\n        self.triplets_per_anchor = triplets_per_anchor\n        self.add_to_recordable_attributes(name=""num_non_zero_triplets"")\n        \n    def compute_loss(self, embeddings, labels, indices_tuple):\n        indices_tuple = lmu.convert_to_triplets(indices_tuple, labels, t_per_anchor=self.triplets_per_anchor)\n        anchor_idx, positive_idx, negative_idx = indices_tuple\n        if len(anchor_idx) == 0:\n            self.num_non_zero_triplets = 0\n            return 0\n        anchors, positives, negatives = embeddings[anchor_idx], embeddings[positive_idx], embeddings[negative_idx]\n        a_p_dist = F.pairwise_distance(anchors, positives, self.distance_norm)\n        a_n_dist = F.pairwise_distance(anchors, negatives, self.distance_norm)\n        if self.swap:\n            p_n_dist = F.pairwise_distance(positives, negatives, self.distance_norm)\n            a_n_dist = torch.min(a_n_dist, p_n_dist)\n        a_p_dist = a_p_dist ** self.power\n        a_n_dist = a_n_dist ** self.power\n        if self.smooth_loss:\n            inside_exp = a_p_dist - a_n_dist\n            inside_exp = self.maybe_modify_loss(inside_exp)\n            return torch.mean(torch.log(1 + torch.exp(inside_exp)))\n        else:\n            dist = a_p_dist - a_n_dist\n            loss_modified = self.maybe_modify_loss(dist + self.margin)\n            relued = torch.nn.functional.relu(loss_modified)\n            self.num_non_zero_triplets = (relued > 0).nonzero().size(0)\n            if self.avg_non_zero_only:\n                if self.num_non_zero_triplets > 0:\n                    return torch.sum(relued) / self.num_non_zero_triplets\n                return 0\n            return torch.mean(relued)\n\n    def maybe_modify_loss(self, x):\n        return x\n\n'"
src/pytorch_metric_learning/losses/tuplet_margin_loss.py,6,"b'import torch\r\nfrom .generic_pair_loss import GenericPairLoss\r\nimport numpy as np\r\nfrom ..utils import loss_and_miner_utils as lmu\r\n\r\nclass TupletMarginLoss(GenericPairLoss):\r\n\r\n    def __init__(self, margin, scale=64, **kwargs):\r\n        super().__init__(**kwargs, use_similarity=True, mat_based_loss=False)\r\n        self.margin = np.radians(margin)\r\n        self.scale = scale\r\n        self.add_to_recordable_attributes(list_of_names=[""avg_pos_angle"", ""avg_neg_angle""])\r\n\r\n    # pos_pairs and neg_pairs already represent cos(theta)\r\n    def _compute_loss(self, pos_pairs, neg_pairs, indices_tuple):\r\n        a1, _, a2, _ = indices_tuple\r\n\r\n        if len(a1) > 0 and len(a2) > 0:\r\n            pos_angles = torch.acos(pos_pairs)\r\n            neg_angles = torch.acos(neg_pairs)\r\n            self.avg_pos_angle = np.degrees(torch.mean(pos_angles).item())\r\n            self.avg_neg_angle = np.degrees(torch.mean(neg_angles).item())\r\n            pos_pairs = torch.cos(pos_angles - self.margin)\r\n            pos_pairs = pos_pairs.unsqueeze(1)\r\n            neg_pairs = neg_pairs.repeat(pos_pairs.size(0), 1)\r\n            inside_exp = self.scale*(neg_pairs - pos_pairs)\r\n            keep_mask = (a2.unsqueeze(0) == a1.unsqueeze(1)).float()\r\n            return torch.mean(lmu.logsumexp(inside_exp, keep_mask=keep_mask, add_one=True, dim=1))\r\n        return 0\r\n\r\n\r\n\r\n'"
src/pytorch_metric_learning/losses/weight_regularizer_mixin.py,0,"b'class WeightRegularizerMixin:\r\n    def __init__(self, regularizer=None, reg_weight=1, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.regularizer = regularizer\r\n        self.reg_weight = reg_weight\r\n\r\n    def regularization_loss(self, weights):\r\n        if self.regularizer is None:\r\n            return 0\r\n        return self.regularizer(weights) * self.reg_weight'"
src/pytorch_metric_learning/miners/__init__.py,0,"b'from .base_miner import BaseMiner, BaseTupleMiner, BaseSubsetBatchMiner\r\nfrom .angular_miner import AngularMiner\r\nfrom .batch_hard_miner import BatchHardMiner\r\nfrom .distance_weighted_miner import DistanceWeightedMiner\r\nfrom .embeddings_already_packaged_as_triplets import EmbeddingsAlreadyPackagedAsTriplets\r\nfrom .hdc_miner import HDCMiner\r\nfrom .maximum_loss_miner import MaximumLossMiner\r\nfrom .multi_similarity_miner import MultiSimilarityMiner\r\nfrom .pair_margin_miner import PairMarginMiner\r\nfrom .triplet_margin_miner import TripletMarginMiner\r\n\r\n\r\n'"
src/pytorch_metric_learning/miners/angular_miner.py,11,"b'#! /usr/bin/env python3\r\n\r\nfrom .base_miner import BaseTupleMiner\r\nimport torch\r\nfrom ..utils import loss_and_miner_utils as lmu\r\nimport numpy as np\r\n\r\nclass AngularMiner(BaseTupleMiner):\r\n    """"""\r\n    Returns triplets that form an angle greater than some threshold (angle).\r\n    The angle is computed as defined in the angular loss paper:\r\n    https://arxiv.org/abs/1708.01682\r\n    """"""\r\n    def __init__(self, angle, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.angle = np.radians(angle)\r\n        self.add_to_recordable_attributes(list_of_names=[""average_angle"", \r\n                                                        ""average_angle_above_threshold"", \r\n                                                        ""average_angle_below_threshold"",\r\n                                                        ""min_angle"", ""max_angle"", ""std_of_angle""])\r\n\r\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\r\n        anchor_idx, positive_idx, negative_idx = lmu.get_all_triplets_indices(labels, ref_labels)\r\n        anchors, positives, negatives = embeddings[anchor_idx], ref_emb[positive_idx], ref_emb[negative_idx]\r\n        centers = (anchors + positives) / 2\r\n        ap_dist = torch.nn.functional.pairwise_distance(anchors, positives, 2)\r\n        nc_dist = torch.nn.functional.pairwise_distance(negatives, centers, 2)\r\n        angles = torch.atan(ap_dist / (2*nc_dist))\r\n        threshold_condition = angles > self.angle\r\n        self.set_stats(angles, threshold_condition)\r\n        return anchor_idx[threshold_condition], positive_idx[threshold_condition], negative_idx[threshold_condition]\r\n\r\n    def set_stats(self, angles, threshold_condition):\r\n        self.average_angle = np.degrees(torch.mean(angles).item())\r\n        self.min_angle = np.degrees(torch.min(angles).item())\r\n        self.max_angle = np.degrees(torch.max(angles).item())\r\n        self.std_of_angle = np.degrees(torch.std(angles).item())\r\n        self.average_angle_above_threshold = 0\r\n        self.average_angle_below_threshold = 0\r\n        if torch.sum(threshold_condition) > 0:\r\n            self.average_angle_above_threshold = np.degrees(torch.mean(angles[threshold_condition]).item())\r\n        negated_condition = ~threshold_condition\r\n        if torch.sum(negated_condition) > 0:\r\n            self.average_angle_below_threshold = np.degrees(torch.mean(angles[~threshold_condition]).item())\r\n\r\n'"
src/pytorch_metric_learning/miners/base_miner.py,5,"b'#! /usr/bin/env python3\n\nimport torch\nfrom ..utils import common_functions as c_f\n\nclass BaseMiner(torch.nn.Module):\n    def __init__(self, normalize_embeddings=True):\n        super().__init__()\n        self.normalize_embeddings = normalize_embeddings\n\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\n        """"""\n        Args:\n            embeddings: tensor of size (batch_size, embedding_size)\n            labels: tensor of size (batch_size)\n        Returns: a tuple where each element is an array of indices.\n        """"""\n        raise NotImplementedError\n\n    def output_assertion(self, output):\n        raise NotImplementedError\n\n    def forward(self, embeddings, labels, ref_emb=None, ref_labels=None):\n        """"""\n        Args:\n            embeddings: tensor of size (batch_size, embedding_size)\n            labels: tensor of size (batch_size)\n        Does any necessary preprocessing, then does mining, and then checks the\n        shape of the mining output before returning it\n        """"""\n        with torch.no_grad():\n            c_f.assert_embeddings_and_labels_are_same_size(embeddings, labels)\n            labels = labels.to(embeddings.device)\n            if self.normalize_embeddings:\n                embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n            ref_emb, ref_labels = self.set_ref_emb(embeddings, labels, ref_emb, ref_labels)\n            mining_output = self.mine(embeddings, labels, ref_emb, ref_labels)\n        self.output_assertion(mining_output)\n        return mining_output\n\n    def set_ref_emb(self, embeddings, labels, ref_emb, ref_labels):\n        if ref_emb is not None:\n            if self.normalize_embeddings:\n                ref_emb = torch.nn.functional.normalize(ref_emb, p=2, dim=1)\n            ref_labels = ref_labels.to(ref_emb.device)\n        else:\n            ref_emb, ref_labels = embeddings, labels\n        c_f.assert_embeddings_and_labels_are_same_size(ref_emb, ref_labels)\n        return ref_emb, ref_labels\n\n\n    def add_to_recordable_attributes(self, name=None, list_of_names=None):\n        c_f.add_to_recordable_attributes(self, name=name, list_of_names=list_of_names)\n        \n\nclass BaseTupleMiner(BaseMiner):\n    """"""\n    Args:\n        normalize_embeddings: type boolean, if True then normalize embeddings\n                                to have norm = 1 before mining\n    """"""\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.add_to_recordable_attributes(list_of_names=[""num_pos_pairs"", ""num_neg_pairs"", ""num_triplets""])\n\n\n    def output_assertion(self, output):\n        """"""\n        Args:\n            output: the output of self.mine\n        This asserts that the mining function is outputting\n        properly formatted indices. The default is to require a tuple representing\n        a,p,n indices or a1,p,a2,n indices within a batch of embeddings.\n        For example, a tuple of (anchors, positives, negatives) will be\n        (torch.tensor, torch.tensor, torch.tensor)\n        """"""\n        if len(output) == 3:\n            self.num_triplets = len(output[0])\n            assert self.num_triplets == len(output[1]) == len(output[2])\n        elif len(output) == 4:\n            self.num_pos_pairs = len(output[0])\n            self.num_neg_pairs = len(output[2])\n            assert self.num_pos_pairs == len(output[1])\n            assert self.num_neg_pairs == len(output[3])\n        else:\n            raise BaseException\n\n\nclass BaseSubsetBatchMiner(BaseMiner):\n    """"""\n    Args:\n        output_batch_size: type int. The size of the subset that the miner\n                            will output.\n        normalize_embeddings: type boolean, if True then normalize embeddings\n                                to have norm = 1 before mining\n    """"""\n\n    def __init__(self, output_batch_size, **kwargs):\n        super().__init__(**kwargs)\n        self.output_batch_size = output_batch_size\n\n    def output_assertion(self, output):\n        assert len(output) == self.output_batch_size'"
src/pytorch_metric_learning/miners/batch_hard_miner.py,11,"b'#! /usr/bin/env python3\r\n\r\nfrom .base_miner import BaseTupleMiner\r\nimport torch\r\nfrom ..utils import loss_and_miner_utils as lmu\r\n\r\n\r\nclass BatchHardMiner(BaseTupleMiner):\r\n    def __init__(self, use_similarity=False, squared_distances=False, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.use_similarity = use_similarity\r\n        self.squared_distances = squared_distances\r\n        self.add_to_recordable_attributes(list_of_names=[""hardest_triplet_dist"", ""hardest_pos_pair_dist"", ""hardest_neg_pair_dist""])\r\n\r\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\r\n        mat = lmu.get_pairwise_mat(embeddings, ref_emb, self.use_similarity, self.squared_distances)\r\n        a1_idx, p_idx, a2_idx, n_idx = lmu.get_all_pairs_indices(labels, ref_labels)\r\n\r\n        pos_func = self.get_min_per_row if self.use_similarity else self.get_max_per_row\r\n        neg_func = self.get_max_per_row if self.use_similarity else self.get_min_per_row\r\n\r\n        (hardest_positive_dist, hardest_positive_indices), a1p_keep = pos_func(mat, a1_idx, p_idx)\r\n        (hardest_negative_dist, hardest_negative_indices), a2n_keep = neg_func(mat, a2_idx, n_idx)\r\n        a_keep_idx = torch.where(a1p_keep & a2n_keep)\r\n        self.set_stats(hardest_positive_dist[a_keep_idx], hardest_negative_dist[a_keep_idx])\r\n        a = torch.arange(mat.size(0)).to(hardest_positive_indices.device)[a_keep_idx]\r\n        p = hardest_positive_indices[a_keep_idx]\r\n        n = hardest_negative_indices[a_keep_idx]        \r\n        return a, p, n \r\n\r\n    def get_max_per_row(self, mat, anchor_idx, other_idx):\r\n        mask = torch.zeros_like(mat)\r\n        mask[anchor_idx, other_idx] = 1\r\n        non_zero_rows = torch.any(mask!=0, dim=1)\r\n        mat_masked = mat * mask \r\n        return torch.max(mat_masked, dim=1), non_zero_rows\r\n\r\n    def get_min_per_row(self, mat, anchor_idx, other_idx):\r\n        mask = torch.ones_like(mat) * float(\'inf\')\r\n        mask[anchor_idx, other_idx] = 1\r\n        non_inf_rows = torch.any(mask!=float(\'inf\'), dim=1)\r\n        mat_masked = mat * mask\r\n        mat_masked[torch.isnan(mat_masked) | torch.isinf(mat_masked)] = float(\'inf\')\r\n        return torch.min(mat_masked, dim=1), non_inf_rows\r\n        \r\n    def set_stats(self, hardest_positive_dist, hardest_negative_dist):\r\n        pos_func = torch.min if self.use_similarity else torch.max\r\n        neg_func = torch.max if self.use_similarity else torch.min\r\n        try:\r\n            self.hardest_triplet_dist = pos_func(hardest_positive_dist - hardest_negative_dist).item()\r\n            self.hardest_pos_pair_dist = pos_func(hardest_positive_dist).item()\r\n            self.hardest_neg_pair_dist = neg_func(hardest_negative_dist).item()\r\n        except RuntimeError:\r\n            self.hardest_triplet_dist = 0\r\n            self.hardest_pos_pair_dist = 0\r\n            self.hardest_neg_pair_dist = 0'"
src/pytorch_metric_learning/miners/distance_weighted_miner.py,7,"b'#! /usr/bin/env python3\n\nfrom .base_miner import BaseTupleMiner\nimport torch\nfrom ..utils import loss_and_miner_utils as lmu\n\n\n# adapted from\n# https://github.com/chaoyuaw/incubator-mxnet/blob/master/example/gluon/embedding_learning/model.py\nclass DistanceWeightedMiner(BaseTupleMiner):\n    def __init__(self, cutoff, nonzero_loss_cutoff, **kwargs):\n        super().__init__(**kwargs)\n        self.cutoff = float(cutoff)\n        self.nonzero_loss_cutoff = float(nonzero_loss_cutoff)\n        self.mat_type = ""dist""\n\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\n        d = embeddings.size(1)\n        dist_mat = lmu.dist_mat(embeddings, ref_emb)\n        \n        if embeddings is ref_emb:\n            # so that we don\'t get log(0). We mask the diagonal out later anyway\n            dist_mat = dist_mat + torch.eye(dist_mat.size(0)).to(embeddings.device)  \n        # Cut off to avoid high variance.\n        dist_mat = torch.max(dist_mat, torch.tensor(self.cutoff).to(dist_mat.device))\n\n        # Subtract max(log(distance)) for stability.\n        # See the first equation from Section 4 of the paper\n        log_weights = (2.0 - float(d)) * torch.log(dist_mat) - (\n            float(d - 3) / 2\n        ) * torch.log(1.0 - 0.25 * (dist_mat ** 2.0))\n        weights = torch.exp(log_weights - torch.max(log_weights))\n\n        # Sample only negative examples by setting weights of\n        # the same-class examples to 0.\n        mask = torch.ones(weights.size()).to(embeddings.device)\n        same_class = labels.unsqueeze(1) == ref_labels.unsqueeze(0)\n        mask[same_class] = 0\n\n        weights = weights * mask * ((dist_mat < self.nonzero_loss_cutoff).float())\n        weights = weights / torch.sum(weights, dim=1, keepdim=True)\n\n        np_weights = weights.cpu().numpy()\n        return lmu.get_random_triplet_indices(labels, weights=np_weights)\n'"
src/pytorch_metric_learning/miners/embeddings_already_packaged_as_triplets.py,3,"b'#! /usr/bin/env python3\n\nfrom .base_miner import BaseTupleMiner\nimport torch\n\n\nclass EmbeddingsAlreadyPackagedAsTriplets(BaseTupleMiner):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    # If the embeddings are grouped by triplet,\n    # then use this miner to force the loss function to use the already-formed triplets\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\n        batch_size = embeddings.size(0)\n        a = torch.arange(0, batch_size, 3)\n        p = torch.arange(1, batch_size, 3)\n        n = torch.arange(2, batch_size, 3)\n        return a, p, n        \n'"
src/pytorch_metric_learning/miners/hdc_miner.py,1,"b'#! /usr/bin/env python3\nfrom .base_miner import BaseTupleMiner\nimport torch\nfrom ..utils import loss_and_miner_utils as lmu\nimport math\n\n# mining method used in Hard Aware Deeply Cascaded Embeddings\n# https://arxiv.org/abs/1611.05720\nclass HDCMiner(BaseTupleMiner):\n    def __init__(self, filter_percentage, use_similarity=False, squared_distances=False, **kwargs):\n        super().__init__(**kwargs)\n        self.filter_percentage = filter_percentage\n        self.use_similarity = use_similarity\n        self.squared_distances = squared_distances\n        self.reset_idx()\n\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\n        mat = lmu.get_pairwise_mat(embeddings, ref_emb, self.use_similarity, self.squared_distances)\n        self.set_idx(labels, ref_labels)\n\n        for name, (anchor, other) in {""pos"": (self.a1, self.p), ""neg"": (self.a2, self.n)}.items():\n            if len(anchor) > 0:\n                pairs = mat[anchor, other]\n                num_pairs = len(pairs)\n                k = int(math.ceil(self.filter_percentage * num_pairs))\n                largest = self.should_select_largest(name)\n                _, idx = torch.topk(pairs, k=k, largest=largest)\n                self.filter_original_indices(name, idx)\n\n        return self.a1, self.p, self.a2, self.n\n\n    def should_select_largest(self, name):\n        if self.use_similarity:\n            return False if name == ""pos"" else True\n        return True if name == ""pos"" else False\n\n    def set_idx(self, labels, ref_labels):\n        if not self.was_set_externally:\n            self.a1, self.p, self.a2, self.n = lmu.get_all_pairs_indices(labels, ref_labels)\n\n    def set_idx_externally(self, external_indices_tuple, labels):\n        self.a1, self.p, self.a2, self.n = lmu.convert_to_pairs(external_indices_tuple, labels)\n        self.was_set_externally = True\n\n    def reset_idx(self):\n        self.a1, self.p, self.a2, self.n = None, None, None, None\n        self.was_set_externally = False\n\n    def filter_original_indices(self, name, idx):\n        if name == ""pos"":\n            self.a1 = self.a1[idx]\n            self.p = self.p[idx]\n        else:\n            self.a2 = self.a2[idx]\n            self.n = self.n[idx]'"
src/pytorch_metric_learning/miners/maximum_loss_miner.py,1,"b'#! /usr/bin/env python3\r\n\r\n\r\nfrom .base_miner import BaseSubsetBatchMiner\r\nfrom ..utils import loss_and_miner_utils as lmu, common_functions as c_f\r\nimport numpy as np\r\nimport torch\r\n\r\nclass MaximumLossMiner(BaseSubsetBatchMiner):\r\n    def __init__(self, loss, miner=None, num_trials=5, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.loss = loss\r\n        self.miner = miner\r\n        self.num_trials = num_trials\r\n        self.add_to_recordable_attributes(list_of_names=[""avg_loss"", ""max_loss""])\r\n\r\n    def mine(self, embeddings, labels, *_):\r\n        losses = []\r\n        all_subset_idx = []\r\n        for i in range(self.num_trials):\r\n            rand_subset_idx = c_f.NUMPY_RANDOM.choice(len(embeddings), size=self.output_batch_size, replace=False)\r\n            rand_subset_idx = torch.from_numpy(rand_subset_idx)\r\n            all_subset_idx.append(rand_subset_idx)\r\n            curr_embeddings, curr_labels = embeddings[rand_subset_idx], labels[rand_subset_idx]\r\n            indices_tuple = self.inner_miner(curr_embeddings, curr_labels)\r\n            losses.append(self.loss(curr_embeddings, curr_labels, indices_tuple).item())\r\n        max_idx = np.argmax(losses)\r\n        self.avg_loss = np.mean(losses)\r\n        self.max_loss = losses[max_idx]\r\n        return all_subset_idx[max_idx]\r\n\r\n    def inner_miner(self, embeddings, labels):\r\n        if self.miner:\r\n            return self.miner(embeddings, labels)\r\n        return None'"
src/pytorch_metric_learning/miners/multi_similarity_miner.py,3,"b""#! /usr/bin/env python3\n\nfrom .base_miner import BaseTupleMiner\nfrom ..utils import loss_and_miner_utils as lmu\nimport torch\n\n\nclass MultiSimilarityMiner(BaseTupleMiner):\n    def __init__(self, epsilon, **kwargs):\n        super().__init__(**kwargs)\n        self.epsilon = epsilon\n\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\n        sim_mat = lmu.sim_mat(embeddings, ref_emb)\n        a1, p, a2, n = lmu.get_all_pairs_indices(labels, ref_labels)\n\n        if len(a1) == 0 or len(a2) == 0:\n            empty = torch.LongTensor([]).to(labels.device)\n            return empty.clone(), empty.clone(), empty.clone(), empty.clone()\n\n        sim_mat_neg_sorting = sim_mat.clone()\n        sim_mat_pos_sorting = sim_mat.clone()\n\n        sim_mat_pos_sorting[a2, n] = float('inf')\n        sim_mat_neg_sorting[a1, p] = -float('inf')\n        if embeddings is ref_emb:\n            sim_mat_neg_sorting[range(len(labels)), range(len(labels))] = -float('inf')\n\n        pos_sorted, pos_sorted_idx = torch.sort(sim_mat_pos_sorting, dim=1)\n        neg_sorted, neg_sorted_idx = torch.sort(sim_mat_neg_sorting, dim=1)\n\n        hard_pos_idx = (pos_sorted - self.epsilon < neg_sorted[:, -1].unsqueeze(1)).nonzero()\n        hard_neg_idx = (neg_sorted + self.epsilon > pos_sorted[:, 0].unsqueeze(1)).nonzero()\n\n        a1 = hard_pos_idx[:,0] \n        p = pos_sorted_idx[a1, hard_pos_idx[:,1]]\n        a2 = hard_neg_idx[:,0]\n        n = neg_sorted_idx[a2, hard_neg_idx[:,1]]\n        \n        return a1, p, a2, n\n"""
src/pytorch_metric_learning/miners/pair_margin_miner.py,6,"b'#! /usr/bin/env python3\n\nfrom .base_miner import BaseTupleMiner\nfrom ..utils import loss_and_miner_utils as lmu\nimport torch\n\n\nclass PairMarginMiner(BaseTupleMiner):\n    """"""\n    Returns positive pairs that have distance greater than a margin and negative\n    pairs that have distance less than a margin\n    """"""\n\n    def __init__(\n        self, pos_margin, neg_margin, use_similarity, squared_distances=False, **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.pos_margin = pos_margin\n        self.neg_margin = neg_margin\n        self.use_similarity = use_similarity\n        self.squared_distances = squared_distances\n        self.add_to_recordable_attributes(list_of_names=[""pos_pair_dist"", ""neg_pair_dist""])\n\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\n        mat = lmu.get_pairwise_mat(embeddings, ref_emb, self.use_similarity, self.squared_distances)\n        a1, p, a2, n = lmu.get_all_pairs_indices(labels, ref_labels)\n        pos_pair = mat[a1, p]\n        neg_pair = mat[a2, n]\n        self.pos_pair_dist = torch.mean(pos_pair).item() if len(pos_pair) > 0 else 0\n        self.neg_pair_dist = torch.mean(neg_pair).item() if len(neg_pair) > 0 else 0\n        pos_mask_condition = self.pos_filter(pos_pair, self.pos_margin)\n        neg_mask_condition = self.neg_filter(neg_pair, self.neg_margin)\n        a1 = torch.masked_select(a1, pos_mask_condition)\n        p = torch.masked_select(p, pos_mask_condition)\n        a2 = torch.masked_select(a2, neg_mask_condition)\n        n = torch.masked_select(n, neg_mask_condition)\n        return a1, p, a2, n\n\n    def pos_filter(self, pos_pair, margin):\n        return pos_pair < margin if self.use_similarity else pos_pair > margin\n\n    def neg_filter(self, neg_pair, margin):\n        return neg_pair > margin if self.use_similarity else neg_pair < margin\n'"
src/pytorch_metric_learning/miners/triplet_margin_miner.py,5,"b'#! /usr/bin/env python3\r\n\r\nfrom .base_miner import BaseTupleMiner\r\nfrom ..utils import loss_and_miner_utils as lmu\r\nimport torch\r\n\r\n\r\nclass TripletMarginMiner(BaseTupleMiner):\r\n    """"""\r\n    Returns triplets that violate the margin\r\n    Args:\r\n    \tmargin\r\n    \ttype_of_triplets: options are ""all"", ""hard"", or ""semihard"".\r\n    \t\t""all"" means all triplets that violate the margin\r\n    \t\t""hard"" is a subset of ""all"", but the negative is closer to the anchor than the positive\r\n    \t\t""semihard"" is a subset of ""all"", but the negative is further from the anchor than the positive\r\n    """"""\r\n    def __init__(self, margin, type_of_triplets=""all"", **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.margin = margin\r\n        self.add_to_recordable_attributes(list_of_names=[""avg_triplet_margin"", ""pos_pair_dist"", ""neg_pair_dist""])\r\n        self.type_of_triplets = type_of_triplets\r\n        self.idx_type = ""triplet""\r\n\r\n    def mine(self, embeddings, labels, ref_emb, ref_labels):\r\n        anchor_idx, positive_idx, negative_idx  = lmu.get_all_triplets_indices(labels, ref_labels)\r\n        anchors, positives, negatives = embeddings[anchor_idx], ref_emb[positive_idx], ref_emb[negative_idx]\r\n        ap_dist = torch.nn.functional.pairwise_distance(anchors, positives, 2)\r\n        an_dist = torch.nn.functional.pairwise_distance(anchors, negatives, 2)\r\n        triplet_margin = ap_dist - an_dist\r\n        self.pos_pair_dist = torch.mean(ap_dist).item()\r\n        self.neg_pair_dist = torch.mean(an_dist).item()\r\n        self.avg_triplet_margin = torch.mean(-triplet_margin).item()\r\n        threshold_condition = triplet_margin > -self.margin\r\n        if self.type_of_triplets == ""hard"":\r\n        \tthreshold_condition &= an_dist < ap_dist\r\n        elif self.type_of_triplets == ""semihard"":\r\n        \tthreshold_condition &= an_dist > ap_dist\r\n        return anchor_idx[threshold_condition], positive_idx[threshold_condition], negative_idx[threshold_condition]'"
src/pytorch_metric_learning/regularizers/__init__.py,0,b'from .base_weight_regularizer import BaseWeightRegularizer\r\nfrom .center_invariant_regularizer import CenterInvariantRegularizer\r\nfrom .regular_face_regularizer import RegularFaceRegularizer'
src/pytorch_metric_learning/regularizers/base_weight_regularizer.py,5,"b'#! /usr/bin/env python3\r\n\r\nimport torch\r\nfrom ..utils import common_functions as c_f\r\n\r\nclass BaseWeightRegularizer(torch.nn.Module):\r\n    def __init__(self, normalize_weights=True):\r\n        super().__init__()\r\n        self.normalize_weights = normalize_weights\r\n        self.add_to_recordable_attributes(name=""avg_weight_norm"")\r\n\r\n    def compute_loss(self, weights):\r\n        raise NotImplementedError\r\n\r\n    def forward(self, weights):\r\n        """"""\r\n        weights should have shape (num_classes, embedding_size)\r\n        """"""\r\n        if self.normalize_weights:\r\n            weights = torch.nn.functional.normalize(weights, p=2, dim=1)\r\n        self.weight_norms = torch.norm(weights, p=2, dim=1)\r\n        self.avg_weight_norm = torch.mean(self.weight_norms)\r\n        loss = self.compute_loss(weights)\r\n        if loss == 0:\r\n            loss = torch.sum(weights*0)\r\n        return loss\r\n\r\n    def add_to_recordable_attributes(self, name=None, list_of_names=None):\r\n        c_f.add_to_recordable_attributes(self, name=name, list_of_names=list_of_names)'"
src/pytorch_metric_learning/regularizers/center_invariant_regularizer.py,2,"b'from .base_weight_regularizer import BaseWeightRegularizer\r\nimport torch\r\n\r\nclass CenterInvariantRegularizer(BaseWeightRegularizer):\r\n    def __init__(self, normalize_weights=False):\r\n        super().__init__(normalize_weights)\r\n        assert not self.normalize_weights, ""normalize_weights must be False for CenterInvariantRegularizer""\r\n  \r\n    def compute_loss(self, weights):\r\n        squared_weight_norms = self.weight_norms**2\r\n        deviations_from_mean = squared_weight_norms - torch.mean(squared_weight_norms)\r\n        return torch.mean((deviations_from_mean**2) / 4)'"
src/pytorch_metric_learning/regularizers/regular_face_regularizer.py,6,"b""from .base_weight_regularizer import BaseWeightRegularizer\r\nimport torch\r\n\r\n# modified from http://kaizhao.net/regularface\r\nclass RegularFaceRegularizer(BaseWeightRegularizer):\r\n  \r\n    def compute_loss(self, weights):\r\n        num_classes = weights.size(0)\r\n        cos = torch.mm(weights, weights.t())\r\n        if not self.normalize_weights:\r\n            norms = self.weight_norms.unsqueeze(1)\r\n            cos = cos / (norms*norms.t())\r\n\r\n        cos1 = cos.clone()\r\n        with torch.no_grad():\r\n            row_nums = torch.arange(num_classes).long().to(weights.device)\r\n            cos1[row_nums, row_nums] = -float('inf')\r\n            _, indices = torch.max(cos1, dim=1)\r\n            mask = torch.zeros((num_classes, num_classes)).to(weights.device)\r\n            mask[row_nums, indices] = 1\r\n        \r\n        return torch.sum(cos*mask) / num_classes"""
src/pytorch_metric_learning/samplers/__init__.py,0,b'from .m_per_class_sampler import MPerClassSampler\r\nfrom .fixed_set_of_triplets import FixedSetOfTriplets'
src/pytorch_metric_learning/samplers/fixed_set_of_triplets.py,2,"b'import torch\r\nfrom torch.utils.data.sampler import Sampler\r\nfrom ..utils import common_functions as c_f\r\nimport numpy as np\r\n\r\nclass FixedSetOfTriplets(Sampler):\r\n    """"""\r\n    Upon initialization, this will create num_triplets triplets based on\r\n    the labels provided in labels_to_indices. This is for experimental purposes,\r\n    to see how algorithms perform when the only ground truth is a set of\r\n    triplets, rather than having explicit labels.\r\n    """"""\r\n\r\n    def __init__(self, labels, num_triplets):\r\n        if isinstance(labels, torch.Tensor):\r\n            labels = labels.numpy()\r\n        self.labels_to_indices = c_f.get_labels_to_indices(labels)\r\n        self.num_triplets = int(num_triplets)\r\n        self.create_fixed_set_of_triplets()\r\n\r\n    def __len__(self):\r\n        return self.fixed_set_of_triplets.shape[0] * 3\r\n\r\n    def __iter__(self):\r\n        c_f.NUMPY_RANDOM.shuffle(self.fixed_set_of_triplets)\r\n        flattened = self.fixed_set_of_triplets.flatten().tolist()\r\n        return iter(flattened)\r\n\r\n    def create_fixed_set_of_triplets(self):\r\n        """"""\r\n        This creates self.fixed_set_of_triplets, which is a numpy array of size\r\n        (num_triplets, 3). Each row is a triplet of indices: (a, p, n), where\r\n        a=anchor, p=positive, and n=negative. Each triplet is created by first\r\n        randomly sampling two classes, then randomly sampling an anchor, positive,\r\n        and negative.\r\n        """"""\r\n        assert self.num_triplets > 0\r\n        self.fixed_set_of_triplets = np.ones((self.num_triplets, 3), dtype=np.int) * -1\r\n        label_list = list(self.labels_to_indices.keys())\r\n        for i in range(self.num_triplets):\r\n            anchor_label, negative_label = c_f.NUMPY_RANDOM.choice(label_list, size=2, replace=False)\r\n            anchor_list = self.labels_to_indices[anchor_label]\r\n            negative_list = self.labels_to_indices[negative_label]\r\n            anchor, positive = c_f.safe_random_choice(anchor_list, size=2)\r\n            negative = c_f.NUMPY_RANDOM.choice(negative_list, replace=False)\r\n            self.fixed_set_of_triplets[i, :] = np.array([anchor, positive, negative])'"
src/pytorch_metric_learning/samplers/m_per_class_sampler.py,2,"b'import torch\r\nfrom torch.utils.data.sampler import Sampler\r\nfrom ..utils import common_functions as c_f\r\n\r\n# modified from\r\n# https://raw.githubusercontent.com/bnulihaixia/Deep_metric/master/utils/sampler.py\r\nclass MPerClassSampler(Sampler):\r\n    """"""\r\n    At every iteration, this will return m samples per class. For example,\r\n    if dataloader\'s batchsize is 100, and m = 5, then 20 classes with 5 samples\r\n    each will be returned\r\n    """"""\r\n    def __init__(self, labels, m, length_before_new_iter=100000):\r\n        if isinstance(labels, torch.Tensor):\r\n            labels = labels.numpy()\r\n        self.m_per_class = int(m)\r\n        self.labels_to_indices = c_f.get_labels_to_indices(labels)\r\n        self.labels = list(self.labels_to_indices.keys())\r\n        self.length_of_single_pass = self.m_per_class*len(self.labels)\r\n        self.list_size = length_before_new_iter\r\n        if self.length_of_single_pass < self.list_size:\r\n            self.list_size -= (self.list_size) % (self.length_of_single_pass)\r\n\r\n    def __len__(self):\r\n        return self.list_size\r\n\r\n    def __iter__(self):\r\n        idx_list = [0]*self.list_size\r\n        i = 0\r\n        num_iters = self.list_size // self.length_of_single_pass if self.length_of_single_pass < self.list_size else 1\r\n        for _ in range(num_iters):\r\n            c_f.NUMPY_RANDOM.shuffle(self.labels)\r\n            for label in self.labels:\r\n                t = self.labels_to_indices[label]\r\n                idx_list[i:i+self.m_per_class] = c_f.safe_random_choice(t, size=self.m_per_class)\r\n                i += self.m_per_class\r\n        return iter(idx_list)'"
src/pytorch_metric_learning/testers/__init__.py,0,b'from .base_tester import BaseTester\r\nfrom .global_embedding_space import GlobalEmbeddingSpaceTester\r\nfrom .global_twostream_embedding_space import GlobalTwoStreamEmbeddingSpaceTester\r\nfrom .with_same_parent_label import WithSameParentLabelTester'
src/pytorch_metric_learning/testers/base_tester.py,4,"b'#! /usr/bin/env python3\r\n\r\nimport tqdm\r\nimport torch\r\nimport numpy as np\r\nfrom ..utils import stat_utils\r\nfrom ..utils import common_functions as c_f\r\nfrom ..utils.accuracy_calculator import AccuracyCalculator\r\nimport logging\r\nfrom sklearn.preprocessing import normalize, StandardScaler\r\nfrom collections import defaultdict\r\n\r\nclass BaseTester:\r\n    def __init__(\r\n        self, \r\n        reference_set=""compared_to_self"", \r\n        normalize_embeddings=True, \r\n        use_trunk_output=False, \r\n        batch_size=32, \r\n        dataloader_num_workers=32, \r\n        pca=None, \r\n        data_device=None,  \r\n        data_and_label_getter=None, \r\n        label_hierarchy_level=0, \r\n        end_of_testing_hook=None,\r\n        dataset_labels=None,\r\n        set_min_label_to_zero=False,\r\n        accuracy_calculator=None,\r\n        visualizer=None,\r\n        visualizer_hook=None\r\n    ):\r\n        self.reference_set = reference_set\r\n        self.normalize_embeddings = normalize_embeddings\r\n        self.pca = int(pca) if pca else None\r\n        self.use_trunk_output = use_trunk_output\r\n        self.batch_size = int(batch_size)\r\n        self.data_device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"") if data_device is None else data_device\r\n        self.dataloader_num_workers = dataloader_num_workers\r\n        self.data_and_label_getter = c_f.return_input if data_and_label_getter is None else data_and_label_getter\r\n        self.label_hierarchy_level = label_hierarchy_level\r\n        self.end_of_testing_hook = end_of_testing_hook\r\n        self.dataset_labels = dataset_labels\r\n        self.set_min_label_to_zero = set_min_label_to_zero\r\n        self.accuracy_calculator = accuracy_calculator\r\n        self.visualizer = visualizer\r\n        self.original_visualizer_hook = visualizer_hook\r\n        self.initialize_label_mapper()\r\n        self.initialize_accuracy_calculator()\r\n\r\n    def initialize_label_mapper(self):\r\n        self.label_mapper = c_f.LabelMapper(self.set_min_label_to_zero, self.dataset_labels).map\r\n\r\n    def initialize_accuracy_calculator(self):\r\n        if self.accuracy_calculator is None:\r\n            self.accuracy_calculator = AccuracyCalculator()\r\n\r\n    def visualizer_hook(self, *args, **kwargs):\r\n        if self.original_visualizer_hook is not None:\r\n            self.original_visualizer_hook(*args, **kwargs)\r\n\r\n    def maybe_normalize(self, embeddings):\r\n        if self.pca:\r\n            for_pca = StandardScaler().fit_transform(embeddings)\r\n            embeddings = stat_utils.run_pca(for_pca, self.pca)\r\n        if self.normalize_embeddings:\r\n            embeddings = normalize(embeddings)\r\n        return embeddings\r\n\r\n    def compute_all_embeddings(self, dataloader, trunk_model, embedder_model):\r\n        num_batches = len(dataloader)\r\n        s, e = 0, 0\r\n        with torch.no_grad():\r\n            for i, data in enumerate(tqdm.tqdm(dataloader)):\r\n                img, label = self.data_and_label_getter(data)\r\n                label = c_f.process_label(label, ""all"", self.label_mapper)\r\n                q = self.get_embeddings_for_eval(trunk_model, embedder_model, img)\r\n                if label.dim() == 1:\r\n                    label = label.unsqueeze(1)\r\n                if i == 0:\r\n                    labels = torch.zeros(len(dataloader.dataset), label.size(1))\r\n                    all_q = torch.zeros(len(dataloader.dataset), q.size(1))\r\n                e = s + q.size(0)\r\n                all_q[s:e] = q\r\n                labels[s:e] = label\r\n                s = e\r\n            labels = labels.cpu().numpy()\r\n            all_q = all_q.cpu().numpy()\r\n\r\n        return all_q, labels\r\n\r\n    def get_all_embeddings(self, dataset, trunk_model, embedder_model=None, collate_fn=None, eval=True):\r\n        if embedder_model is None: embedder_model = c_f.Identity()\r\n        if eval:\r\n            trunk_model.eval()\r\n            embedder_model.eval()\r\n        dataloader = c_f.get_eval_dataloader(dataset, self.batch_size, self.dataloader_num_workers, collate_fn)\r\n        embeddings, labels = self.compute_all_embeddings(dataloader, trunk_model, embedder_model)\r\n        embeddings = self.maybe_normalize(embeddings)\r\n        return embeddings, labels\r\n\r\n    def get_embeddings_for_eval(self, trunk_model, embedder_model, input_imgs):\r\n        trunk_output = trunk_model(input_imgs.to(self.data_device))\r\n        if self.use_trunk_output:\r\n            return trunk_output\r\n        return embedder_model(trunk_output)\r\n\r\n    def maybe_visualize(self, embeddings_and_labels, epoch):\r\n        self.dim_reduced_embeddings = defaultdict(dict)\r\n        if self.visualizer:\r\n            visualizer_name = self.visualizer.__class__.__name__\r\n            for split_name, (embeddings, labels) in embeddings_and_labels.items():\r\n                logging.info(""Running {} on the {} set"".format(visualizer_name, split_name))\r\n                dim_reduced = self.visualizer.fit_transform(embeddings)\r\n                logging.info(""Finished {}"".format(visualizer_name))\r\n                for L in self.label_levels_to_evaluate(labels):\r\n                    label_scheme = labels[:, L]\r\n                    keyname = self.accuracies_keyname(visualizer_name, label_hierarchy_level=L)\r\n                    self.dim_reduced_embeddings[split_name][keyname] = (dim_reduced, label_scheme)\r\n                    self.visualizer_hook(self.visualizer, dim_reduced, label_scheme, split_name, keyname, epoch)\r\n\r\n    def description_suffixes(self, base_name):\r\n        if self.pca:\r\n            base_name += ""_pca%d""%self.pca\r\n        if self.normalize_embeddings:\r\n            base_name += ""_normalized""\r\n        if self.use_trunk_output:\r\n            base_name += ""_trunk""\r\n        base_name += ""_""+self.reference_set\r\n        base_name += ""_""+self.__class__.__name__\r\n        base_name += ""_level_""+self.label_hierarchy_level_to_str(self.label_hierarchy_level)\r\n        accuracy_calculator_descriptor = self.accuracy_calculator.description()\r\n        if accuracy_calculator_descriptor != """":\r\n            base_name += ""_""+accuracy_calculator_descriptor\r\n        return base_name\r\n\r\n    def label_hierarchy_level_to_str(self, label_hierarchy_level):\r\n        if c_f.is_list_or_tuple(label_hierarchy_level):\r\n            return ""_"".join(str(x) for x in label_hierarchy_level)\r\n        else:\r\n            return str(label_hierarchy_level)\r\n\r\n    def accuracies_keyname(self, metric, label_hierarchy_level=0, average=False):\r\n        if average:\r\n            return ""AVERAGE_%s""%metric\r\n        if (label_hierarchy_level==""all"" or c_f.is_list_or_tuple(label_hierarchy_level)) and len(self.label_levels) == 1:\r\n            label_hierarchy_level = self.label_levels[0]\r\n        return ""%s_level%s""%(metric, self.label_hierarchy_level_to_str(label_hierarchy_level))\r\n\r\n    def all_splits_combined(self, embeddings_and_labels):\r\n        eee, lll = list(zip(*list(embeddings_and_labels.values())))\r\n        curr_embeddings = np.concatenate(eee, axis=0)\r\n        curr_labels = np.concatenate(lll, axis=0)\r\n        return curr_embeddings, curr_labels\r\n\r\n    def set_reference_and_query(self, embeddings_and_labels, curr_split):\r\n        query_embeddings, query_labels = embeddings_and_labels[curr_split]\r\n        if self.reference_set == ""compared_to_self"":\r\n            reference_embeddings, reference_labels = query_embeddings, query_labels\r\n        elif self.reference_set == ""compared_to_sets_combined"":\r\n            reference_embeddings, reference_labels = self.all_splits_combined(embeddings_and_labels)\r\n        elif self.reference_set == ""compared_to_training_set"":\r\n            reference_embeddings, reference_labels = embeddings_and_labels[""train""]\r\n        else:\r\n            raise BaseException \r\n        return query_embeddings, query_labels, reference_embeddings, reference_labels\r\n\r\n    def embeddings_come_from_same_source(self, embeddings_and_labels):\r\n        return self.reference_set in [""compared_to_self"", ""compared_to_sets_combined""]\r\n\r\n    def label_levels_to_evaluate(self, query_labels):\r\n        num_levels_available = query_labels.shape[1]\r\n        if self.label_hierarchy_level == ""all"":\r\n            return range(num_levels_available)\r\n        elif isinstance(self.label_hierarchy_level, int):\r\n            assert self.label_hierarchy_level < num_levels_available\r\n            return [self.label_hierarchy_level]\r\n        elif c_f.is_list_or_tuple(self.label_hierarchy_level):\r\n            assert max(self.label_hierarchy_level) < num_levels_available\r\n            return self.label_hierarchy_level\r\n\r\n    def calculate_average_accuracies(self, accuracies, metrics, label_levels):\r\n        for m in metrics:\r\n            keyname = self.accuracies_keyname(m, average=True)\r\n            summed_accuracy = 0\r\n            for L in label_levels:\r\n                curr_key = self.accuracies_keyname(m, label_hierarchy_level=L)\r\n                summed_accuracy += accuracies[curr_key]\r\n            accuracies[keyname] = summed_accuracy / len(label_levels)\r\n\r\n    def get_splits_to_compute_embeddings(self, dataset_dict, splits_to_eval):\r\n        splits_to_eval = list(dataset_dict.keys()) if splits_to_eval is None else splits_to_eval\r\n        if self.reference_set in [""compared_to_self"", ""compared_to_sets_combined""]:\r\n            return splits_to_eval, splits_to_eval\r\n        if self.reference_set == ""compared_to_training_set"":\r\n            return splits_to_eval, list(set(splits_to_eval).add(""train""))\r\n\r\n    def get_all_embeddings_for_all_splits(self, dataset_dict, trunk_model, embedder_model, splits_to_compute_embeddings, collate_fn):\r\n        embeddings_and_labels = {}\r\n        for split_name in splits_to_compute_embeddings:\r\n            logging.info(\'Getting embeddings for the %s split\'%split_name)\r\n            embeddings_and_labels[split_name] = self.get_all_embeddings(dataset_dict[split_name], trunk_model, embedder_model, collate_fn)\r\n        return embeddings_and_labels\r\n\r\n    def do_knn_and_accuracies(self, accuracies, embeddings_and_labels, split_name):\r\n        raise NotImplementedError\r\n\r\n    def test(self, dataset_dict, epoch, trunk_model, embedder_model=None, splits_to_eval=None, collate_fn=None, **kwargs):\r\n        logging.info(""Evaluating epoch {}"".format(epoch))\r\n        if embedder_model is None: embedder_model = c_f.Identity()\r\n        trunk_model.eval()\r\n        embedder_model.eval()\r\n        splits_to_eval, splits_to_compute_embeddings = self.get_splits_to_compute_embeddings(dataset_dict, splits_to_eval)\r\n        self.embeddings_and_labels = self.get_all_embeddings_for_all_splits(dataset_dict, trunk_model, embedder_model, splits_to_compute_embeddings, collate_fn)\r\n        self.maybe_visualize(self.embeddings_and_labels, epoch)\r\n        self.all_accuracies = defaultdict(dict)\r\n        for split_name in splits_to_eval:\r\n            logging.info(\'Computing accuracy for the %s split\'%split_name)\r\n            self.all_accuracies[split_name][""epoch""] = epoch \r\n            self.do_knn_and_accuracies(self.all_accuracies[split_name], self.embeddings_and_labels, split_name)\r\n        self.end_of_testing_hook(self) if self.end_of_testing_hook else logging.info(self.all_accuracies)'"
src/pytorch_metric_learning/testers/global_embedding_space.py,0,"b'#! /usr/bin/env python3\r\nfrom ..utils import common_functions as c_f\r\n\r\nfrom .base_tester import BaseTester\r\n\r\n\r\nclass GlobalEmbeddingSpaceTester(BaseTester):\r\n\r\n    def do_knn_and_accuracies(self, accuracies, embeddings_and_labels, split_name):\r\n        query_embeddings, query_labels, reference_embeddings, reference_labels = self.set_reference_and_query(embeddings_and_labels, split_name)\r\n        self.label_levels = self.label_levels_to_evaluate(query_labels)\r\n\r\n        for L in self.label_levels:\r\n            curr_query_labels = query_labels[:, L]\r\n            curr_reference_labels = reference_labels[:, L]\r\n            a = self.accuracy_calculator.get_accuracy(\r\n                query_embeddings,\r\n                reference_embeddings,\r\n                curr_query_labels,\r\n                curr_reference_labels,\r\n                self.embeddings_come_from_same_source(embeddings_and_labels),\r\n            )\r\n            for metric, v in a.items():\r\n                keyname = self.accuracies_keyname(metric, label_hierarchy_level=L)\r\n                accuracies[keyname] = v\r\n\r\n        if len(self.label_levels) > 1:\r\n            self.calculate_average_accuracies(accuracies, self.accuracy_calculator.get_curr_metrics(), self.label_levels)'"
src/pytorch_metric_learning/testers/global_twostream_embedding_space.py,4,"b'#! /usr/bin/env python3\r\nfrom ..utils import common_functions as c_f\r\nfrom .base_tester import BaseTester\r\nfrom .global_embedding_space import GlobalEmbeddingSpaceTester\r\nimport torch\r\nimport tqdm\r\nimport numpy as np\r\n\r\nclass GlobalTwoStreamEmbeddingSpaceTester(GlobalEmbeddingSpaceTester):\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        assert self.reference_set == ""compared_to_self"", ""compared_to_self is the only supported reference_set type for {}"".format(self.__class__.__name__)\r\n        \r\n    def compute_all_embeddings(self, dataloader, trunk_model, embedder_model):\r\n        num_batches = len(dataloader)\r\n        s, e = 0, 0\r\n        with torch.no_grad():\r\n            for i, data in enumerate(tqdm.tqdm(dataloader)):\r\n                anchors, posnegs, label = self.data_and_label_getter(data)\r\n                label = c_f.process_label(label, self.label_hierarchy_level, self.label_mapper)\r\n                a = self.get_embeddings_for_eval(trunk_model, embedder_model, anchors)\r\n                pns = self.get_embeddings_for_eval(trunk_model, embedder_model, posnegs)\r\n                if label.dim() == 1:\r\n                    label = label.unsqueeze(1)\r\n                if i == 0:\r\n                    labels = torch.zeros(len(dataloader.dataset), label.size(1))\r\n                    all_anchors = torch.zeros(len(dataloader.dataset), pns.size(1))\r\n                    all_posnegs = torch.zeros(len(dataloader.dataset), pns.size(1))\r\n                \r\n                e = s + pns.size(0)\r\n                all_anchors[s:e] = a\r\n                all_posnegs[s:e] = pns\r\n                labels[s:e] = label\r\n                s = e\r\n            labels = labels.cpu().numpy()\r\n            all_posnegs = all_posnegs.cpu().numpy()\r\n            all_anchors = all_anchors.cpu().numpy()\r\n\r\n        return all_anchors, all_posnegs, labels\r\n    \r\n    def get_all_embeddings(self, dataset, trunk_model, embedder_model, collate_fn):\r\n        dataloader = c_f.get_eval_dataloader(dataset, self.batch_size, self.dataloader_num_workers, collate_fn)\r\n        anchor_embeddings, posneg_embeddings, labels = self.compute_all_embeddings(dataloader, trunk_model, embedder_model)\r\n        anchor_embeddings, posneg_embeddings = self.maybe_normalize(anchor_embeddings), self.maybe_normalize(posneg_embeddings)\r\n        return np.concatenate([anchor_embeddings, posneg_embeddings], axis=0), np.concatenate([labels, labels], axis=0)\r\n    \r\n    def set_reference_and_query(self, embeddings_and_labels, curr_split):\r\n        embeddings, labels = embeddings_and_labels[curr_split]\r\n        half = int(embeddings.shape[0] / 2)\r\n        anchors_embeddings = embeddings[:half]\r\n        posneg_embeddings = embeddings[half:]\r\n        query_labels = labels[:half]\r\n        return anchors_embeddings, query_labels, posneg_embeddings, query_labels\r\n    \r\n    def embeddings_come_from_same_source(self, embeddings_and_labels):\r\n        return False'"
src/pytorch_metric_learning/testers/with_same_parent_label.py,0,"b'#! /usr/bin/env python3\nfrom collections import defaultdict\nimport numpy as np\nfrom ..utils import common_functions as c_f\nfrom .base_tester import BaseTester\nimport logging\n\n\nclass WithSameParentLabelTester(BaseTester):\n    def do_knn_and_accuracies(self, accuracies, embeddings_and_labels, split_name, tag_suffix=\'\'):\n        query_embeddings, query_labels, reference_embeddings, reference_labels = self.set_reference_and_query(embeddings_and_labels, split_name)\n        self.label_levels = [L for L in self.label_levels_to_evaluate(query_labels) if L < query_labels.shape[1] - 1]\n        assert len(self.label_levels) > 0, """"""There are no valid label levels to evaluate. Make sure you\'ve set label_hierarchy_level correctly. \n            If it is an integer, it must be less than the number of hierarchy levels minus 1.""""""\n\n        for L in self.label_levels:\n            curr_query_parent_labels = query_labels[:, L + 1]\n            curr_reference_parent_labels = reference_labels[:, L + 1]\n            average_accuracies = defaultdict(list)\n            for parent_label in np.unique(curr_query_parent_labels):\n                logging.info(""Label level {} and parent label {}"".format(L, parent_label))\n                query_match = curr_query_parent_labels == parent_label\n                reference_match = curr_reference_parent_labels == parent_label\n                curr_query_labels = query_labels[:, L][query_match]\n                curr_reference_labels = reference_labels[:, L][reference_match]\n                curr_query_embeddings = query_embeddings[query_match]\n                curr_reference_embeddings = reference_embeddings[reference_match]\n                a = self.accuracy_calculator.get_accuracy(\n                    curr_query_embeddings,\n                    curr_reference_embeddings,\n                    curr_query_labels,\n                    curr_reference_labels,\n                    self.embeddings_come_from_same_source(embeddings_and_labels),\n                )\n                for metric, v in a.items():\n                    average_accuracies[metric].append(v)\n            for metric, v in average_accuracies.items():\n                keyname = self.accuracies_keyname(metric, label_hierarchy_level=L)\n                accuracies[keyname] = np.mean(v)\n\n        if len(self.label_levels) > 1:\n            self.calculate_average_accuracies(accuracies, self.accuracy_calculator.get_curr_metrics(), self.label_levels)\n        '"
src/pytorch_metric_learning/trainers/__init__.py,0,b'from .base_trainer import BaseTrainer\r\nfrom .metric_loss_only import MetricLossOnly\r\nfrom .train_with_classifier import TrainWithClassifier\r\nfrom .cascaded_embeddings import CascadedEmbeddings\r\nfrom .deep_adversarial_metric_learning import DeepAdversarialMetricLearning\r\nfrom .unsupervised_embeddings_using_augmentations import UnsupervisedEmbeddingsUsingAugmentations\r\nfrom .twostream_metric_loss import TwoStreamMetricLoss'
src/pytorch_metric_learning/trainers/base_trainer.py,2,"b'#! /usr/bin/env python3\n\nimport torch\nfrom ..utils import common_functions as c_f, loss_tracker as l_t\nimport tqdm\nimport logging\nimport numpy as np\n\nclass BaseTrainer:\n    def __init__(\n        self,\n        models,\n        optimizers,\n        batch_size,\n        loss_funcs,\n        mining_funcs,\n        dataset,\n        iterations_per_epoch=None,\n        data_device=None,\n        loss_weights=None,\n        sampler=None,\n        collate_fn=None,\n        lr_schedulers=None,\n        gradient_clippers=None,\n        freeze_these=(),\n        freeze_trunk_batchnorm=False,\n        label_hierarchy_level=0,\n        dataloader_num_workers=32,\n        data_and_label_getter=None,\n        dataset_labels=None,\n        set_min_label_to_zero=False,\n        end_of_iteration_hook=None,\n        end_of_epoch_hook=None\n    ):\n        self.models = models\n        self.optimizers = optimizers\n        self.batch_size = batch_size\n        self.loss_funcs = loss_funcs\n        self.mining_funcs = mining_funcs\n        self.dataset = dataset\n        self.iterations_per_epoch = iterations_per_epoch\n        self.data_device = data_device\n        self.sampler = sampler\n        self.collate_fn = collate_fn\n        self.lr_schedulers = lr_schedulers\n        self.gradient_clippers = gradient_clippers\n        self.freeze_these = freeze_these\n        self.freeze_trunk_batchnorm = freeze_trunk_batchnorm\n        self.label_hierarchy_level = label_hierarchy_level\n        self.dataloader_num_workers = dataloader_num_workers\n        self.loss_weights = loss_weights\n        self.data_and_label_getter = data_and_label_getter\n        self.dataset_labels = dataset_labels\n        self.set_min_label_to_zero = set_min_label_to_zero\n        self.end_of_iteration_hook = end_of_iteration_hook\n        self.end_of_epoch_hook = end_of_epoch_hook\n        self.loss_names = list(self.loss_funcs.keys())\n        self.custom_setup()\n        self.verify_dict_keys()\n        self.initialize_models()\n        self.initialize_data_device()\n        self.initialize_label_mapper()\n        self.initialize_loss_tracker()\n        self.initialize_loss_weights()\n        self.initialize_data_and_label_getter()\n        self.initialize_hooks()\n        self.initialize_lr_schedulers()\n        \n    def custom_setup(self):\n        pass\n\n    def calculate_loss(self):\n        raise NotImplementedError\n\n    def update_loss_weights(self):\n        pass\n\n    def train(self, start_epoch=1, num_epochs=1):\n        self.initialize_dataloader()\n        for self.epoch in range(start_epoch, num_epochs+1):\n            self.set_to_train()\n            logging.info(""TRAINING EPOCH %d"" % self.epoch)\n            pbar = tqdm.tqdm(range(self.iterations_per_epoch))\n            for self.iteration in pbar:\n                self.forward_and_backward()\n                self.end_of_iteration_hook(self)\n                pbar.set_description(""total_loss=%.5f"" % self.losses[""total_loss""])\n                self.step_lr_schedulers(end_of_epoch=False)\n            self.step_lr_schedulers(end_of_epoch=True)\n            if self.end_of_epoch_hook(self) is False:\n                break\n\n    def initialize_dataloader(self):\n        logging.info(""Initializing dataloader"")\n        self.dataloader = c_f.get_train_dataloader(\n            self.dataset,\n            self.batch_size,\n            self.sampler,\n            self.dataloader_num_workers,\n            self.collate_fn,\n        )\n        if not self.iterations_per_epoch:\n            self.iterations_per_epoch = len(self.dataloader)\n        logging.info(""Initializing dataloader iterator"")\n        self.dataloader_iter = iter(self.dataloader)\n        logging.info(""Done creating dataloader iterator"")\n\n    def forward_and_backward(self):\n        self.zero_losses()\n        self.zero_grad()\n        self.update_loss_weights()\n        self.calculate_loss(self.get_batch())\n        self.loss_tracker.update(self.loss_weights)\n        self.backward()\n        self.clip_gradients()\n        self.step_optimizers()\n\n    def zero_losses(self):\n        for k in self.losses.keys():\n            self.losses[k] = 0\n\n    def zero_grad(self):\n        for v in self.models.values():\n            v.zero_grad()\n        for v in self.optimizers.values():\n            v.zero_grad()\n\n    def get_batch(self):\n        self.dataloader_iter, curr_batch = c_f.try_next_on_generator(self.dataloader_iter, self.dataloader)\n        data, labels = self.data_and_label_getter(curr_batch)\n        labels = c_f.process_label(labels, self.label_hierarchy_level, self.label_mapper)\n        return self.maybe_do_batch_mining(data, labels)\n\n    def compute_embeddings(self, data):\n        trunk_output = self.get_trunk_output(data)\n        embeddings = self.get_final_embeddings(trunk_output)\n        return embeddings\n\n    def get_final_embeddings(self, base_output):\n        return self.models[""embedder""](base_output)\n\n    def get_trunk_output(self, data):\n        return self.models[""trunk""](data.to(self.data_device))\n\n    def maybe_mine_embeddings(self, embeddings, labels):\n        if ""tuple_miner"" in self.mining_funcs:\n            return self.mining_funcs[""tuple_miner""](embeddings, labels)\n        return None\n\n    def maybe_do_batch_mining(self, data, labels):\n        if ""subset_batch_miner"" in self.mining_funcs:\n            with torch.no_grad():\n                self.set_to_eval()\n                embeddings = self.compute_embeddings(data)\n                idx = self.mining_funcs[""subset_batch_miner""](embeddings, labels)\n                self.set_to_train()\n                data, labels = data[idx], labels[idx]\n        return data, labels\n\n    def backward(self):\n        self.losses[""total_loss""].backward()\n\n    def get_global_iteration(self):\n        return self.iteration + self.iterations_per_epoch * (self.epoch - 1)\n\n    def step_lr_schedulers(self, end_of_epoch=False):\n        if self.lr_schedulers is not None:\n            for k, v in self.lr_schedulers.items():\n                if end_of_epoch and k.endswith(self.allowed_lr_scheduler_key_suffixes[""epoch""]):\n                    v.step()\n                elif not end_of_epoch and k.endswith(self.allowed_lr_scheduler_key_suffixes[""iteration""]):\n                    v.step()\n\n    def step_lr_plateau_schedulers(self, validation_info):\n        if self.lr_schedulers is not None:\n            for k, v in self.lr_schedulers.items():\n                if k.endswith(self.allowed_lr_scheduler_key_suffixes[""plateau""]):\n                    v.step(validation_info)\n\n    def step_optimizers(self):\n        for k, v in self.optimizers.items():\n            if c_f.regex_replace(""_optimizer$"", """", k) not in self.freeze_these:\n                v.step()\n\n    def clip_gradients(self):\n        if self.gradient_clippers is not None:\n            for v in self.gradient_clippers.values():\n                v()\n\n    def maybe_freeze_trunk_batchnorm(self):\n        if self.freeze_trunk_batchnorm:\n            self.models[""trunk""].apply(c_f.set_layers_to_eval(""BatchNorm""))\n\n    def initialize_data_device(self):\n        if self.data_device is None:\n            self.data_device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\n    def initialize_label_mapper(self):\n        self.label_mapper = c_f.LabelMapper(self.set_min_label_to_zero, self.dataset_labels).map\n        \n    def initialize_loss_tracker(self):\n        self.loss_tracker = l_t.LossTracker(self.loss_names)\n        self.losses = self.loss_tracker.losses\n\n    def initialize_data_and_label_getter(self):\n        if self.data_and_label_getter is None:\n            self.data_and_label_getter = c_f.return_input\n\n    def set_to_train(self):\n        trainable = [self.models, self.loss_funcs]\n        for T in trainable:\n            for k, v in T.items():\n                if k in self.freeze_these:\n                    c_f.set_requires_grad(v, requires_grad=False)\n                    v.eval()\n                else:\n                    v.train()\n        self.maybe_freeze_trunk_batchnorm()\n\n    def set_to_eval(self):\n        for k, v in self.models.items():\n            v.eval()\n\n    def initialize_loss_weights(self):\n        if self.loss_weights is None:\n            self.loss_weights = {k: 1 for k in self.loss_names}\n\n    def initialize_hooks(self):\n        if self.end_of_iteration_hook is None:\n            self.end_of_iteration_hook = c_f.return_input\n        if self.end_of_epoch_hook is None:\n            self.end_of_epoch_hook = c_f.return_input\n\n    def initialize_lr_schedulers(self):\n        if self.lr_schedulers is None:\n            self.lr_schedulers = {}\n\n    def initialize_models(self):\n        if ""embedder"" not in self.models:\n            self.models[""embedder""] = c_f.Identity()\n\n    def verify_dict_keys(self):\n        self.allowed_lr_scheduler_key_suffixes = {""iteration"": ""_scheduler_by_iteration"", ""epoch"": ""_scheduler_by_epoch"", ""plateau"": ""_scheduler_by_plateau""}\n        self.verify_models_keys()\n        self.verify_optimizers_keys()\n        self.verify_loss_funcs_keys()\n        self.verify_mining_funcs_keys()\n        self.verify_lr_schedulers_keys()\n        self.verify_loss_weights_keys()\n        self.verify_gradient_clippers_keys()\n        self.verify_freeze_these_keys()\n\n    def _verify_dict_keys(self, obj_name, allowed_keys, warn_if_empty, important_keys=(), essential_keys=()):\n        obj = getattr(self, obj_name, None)\n        if obj in [None, {}]:\n            if warn_if_empty:\n                logging.warn(""%s is empty""%obj_name)\n        else:\n            for k in obj.keys():\n                assert any(pattern.match(k) for pattern in c_f.regex_wrapper(allowed_keys)), ""%s keys must be one of %s""%(obj_name, "", "".join(allowed_keys))\n            for imp_key in important_keys:\n                if not any(c_f.regex_wrapper(imp_key).match(k) for k in obj):\n                    logging.warn(""%s is missing \\""%s\\""""%(obj_name, imp_key))\n            for ess_key in essential_keys:\n                assert any(c_f.regex_wrapper(ess_key).match(k) for k in obj), ""%s must contain \\""%s\\""""%(obj_name, ess_key)\n\n    def allowed_model_keys(self):\n        return [""trunk"", ""embedder""]\n\n    def allowed_optimizer_keys(self):\n        return [x+""_optimizer"" for x in self.allowed_model_keys() + self.allowed_loss_funcs_keys()]\n\n    def allowed_loss_funcs_keys(self):\n        return [""metric_loss""]\n\n    def allowed_mining_funcs_keys(self):\n        return [""subset_batch_miner"", ""tuple_miner""]\n\n    def allowed_lr_scheduers_keys(self):\n        return [x+y for y in self.allowed_lr_scheduler_key_suffixes.values()  for x in self.allowed_model_keys() + self.allowed_loss_funcs_keys()]\n\n    def allowed_gradient_clippers_keys(self):\n        return [x+""_grad_clipper"" for x in self.allowed_model_keys() + self.allowed_loss_funcs_keys()]\n\n    def allowed_freeze_these_keys(self):\n        return self.allowed_model_keys() + self.allowed_loss_funcs_keys()\n\n    def verify_models_keys(self):\n        self._verify_dict_keys(""models"", self.allowed_model_keys(), warn_if_empty=True, essential_keys=[""trunk""], important_keys = [x for x in self.allowed_model_keys() if x != ""trunk""])\n\n    def verify_optimizers_keys(self):\n        self._verify_dict_keys(""optimizers"", self.allowed_optimizer_keys(), warn_if_empty=True, important_keys=[x+""_optimizer"" for x in self.models.keys()])\n\n    def verify_loss_funcs_keys(self):\n        self._verify_dict_keys(""loss_funcs"", self.allowed_loss_funcs_keys(), warn_if_empty=True, important_keys=self.allowed_loss_funcs_keys())\n\n    def verify_mining_funcs_keys(self):\n        self._verify_dict_keys(""mining_funcs"", self.allowed_mining_funcs_keys(), warn_if_empty=False)\n\n    def verify_lr_schedulers_keys(self):\n        self._verify_dict_keys(""lr_schedulers"", self.allowed_lr_scheduers_keys(), warn_if_empty=False)\n\n    def verify_loss_weights_keys(self):\n        self._verify_dict_keys(""loss_weights"", self.loss_names, warn_if_empty=False, essential_keys=self.loss_names)\n\n    def verify_gradient_clippers_keys(self):\n        self._verify_dict_keys(""gradient_clippers"", self.allowed_gradient_clippers_keys(), warn_if_empty=False)\n\n    def verify_freeze_these_keys(self):\n        for k in self.freeze_these:\n            assert k in self.allowed_freeze_these_keys(), ""freeze_these keys must be one of {}"".format("", "".join(self.allowed_freeze_these_keys()))\n            if k+""_optimizer"" in self.optimizers.keys():\n                logging.warn(""You have passed in an optimizer for {}, but are freezing its parameters."".format(k))'"
src/pytorch_metric_learning/trainers/cascaded_embeddings.py,0,"b'#! /usr/bin/env python3\n\n\nfrom .base_trainer import BaseTrainer\nfrom .. import miners\n\n\nclass CascadedEmbeddings(BaseTrainer):\n    def __init__(self, embedding_sizes, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.embedding_sizes = embedding_sizes\n\n    def calculate_loss(self, curr_batch):\n        data, labels = curr_batch\n        embeddings = self.compute_embeddings(data)\n        s = 0\n        logits = []\n        indices_tuple = None\n        for i, curr_size in enumerate(self.embedding_sizes):\n            curr_loss_name = ""metric_loss_%d""%i \n            curr_miner_name = ""tuple_miner_%d""%i\n            curr_classifier_name = ""classifier_%d""%i\n\n            e = embeddings[:, s : s + curr_size]\n            indices_tuple = self.maybe_mine_embeddings(e, labels, indices_tuple, curr_miner_name)\n            self.losses[curr_loss_name] += self.maybe_get_metric_loss(e, labels, indices_tuple, curr_loss_name)\n            logits.append(self.maybe_get_logits(e, curr_classifier_name))\n            s += curr_size\n\n        for i, L in enumerate(logits):\n            if L is None:\n                continue\n            curr_loss_name = ""classifier_loss_%d""%i\n            self.losses[curr_loss_name] += self.maybe_get_classifier_loss(L, labels, curr_loss_name)\n\n    def maybe_get_metric_loss(self, embeddings, labels, indices_tuple, curr_loss_name):\n        if self.loss_weights.get(curr_loss_name, 0) > 0:\n            return self.loss_funcs[curr_loss_name](embeddings, labels, indices_tuple)\n        return 0\n\n    def maybe_mine_embeddings(self, embeddings, labels, prev_indices_tuple, curr_miner_name):\n        if curr_miner_name in self.mining_funcs:\n            curr_miner = self.mining_funcs[curr_miner_name]\n            if isinstance(curr_miner, miners.HDCMiner):\n                curr_miner.set_idx_externally(prev_indices_tuple, labels)\n                curr_indices_tuple = curr_miner(embeddings, labels)\n                curr_miner.reset_idx()\n            else:\n                curr_indices_tuple = curr_miner(embeddings, labels) \n            return curr_indices_tuple\n        return None\n\n    def maybe_get_logits(self, embeddings, curr_classifier_name):\n        if self.models.get(curr_classifier_name, None):\n            return self.models[curr_classifier_name](embeddings)\n        return None\n\n    def maybe_get_classifier_loss(self, logits, labels, curr_loss_name):\n        if self.loss_weights.get(curr_loss_name, 0) > 0:\n            return self.loss_funcs[curr_loss_name](logits, labels.to(logits.device))\n        return 0\n\n\n    def allowed_model_keys(self):\n        return super().allowed_model_keys() + [""classifier_[0-9]+""]\n\n    def allowed_loss_funcs_keys(self):\n        return [""metric_loss_[0-9]+"", ""classifier_loss_[0-9]+""]\n\n    def allowed_mining_funcs_keys(self):\n        return [""tuple_miner_[0-9]+""]'"
src/pytorch_metric_learning/trainers/deep_adversarial_metric_learning.py,8,"b'#! /usr/bin/env python3\n\nfrom .. import miners\nimport torch\nfrom ..utils import common_functions as c_f, loss_and_miner_utils as lmu\n\nfrom .train_with_classifier import TrainWithClassifier\nimport copy\n\nclass DeepAdversarialMetricLearning(TrainWithClassifier):\n    def __init__(\n        self,\n        metric_alone_epochs=0,\n        g_alone_epochs=0,\n        g_triplets_per_anchor=100,\n        *args,\n        **kwargs\n    ):\n        super().__init__(*args, **kwargs)\n        self.original_loss_weights = copy.deepcopy(self.loss_weights)\n        self.metric_alone_epochs = metric_alone_epochs\n        self.g_alone_epochs = g_alone_epochs\n        self.loss_funcs[""g_adv_loss""].maybe_modify_loss = self.maybe_modify_loss\n        self.g_triplets_per_anchor = g_triplets_per_anchor\n\n    def maybe_modify_loss(self, x):\n        return x*-1\n\n    def custom_setup(self):\n        synth_packaged_as_triplets = miners.EmbeddingsAlreadyPackagedAsTriplets(normalize_embeddings=False)\n        self.mining_funcs[""synth_packaged_as_triplets""] = synth_packaged_as_triplets\n        self.loss_names += [""g_hard_loss"", ""g_reg_loss""]\n\n    def calculate_loss(self, curr_batch):\n        data, labels = curr_batch\n        penultimate_embeddings = self.get_trunk_output(data)\n\n        if self.do_metric:\n            authentic_final_embeddings = self.get_final_embeddings(penultimate_embeddings)\n            indices_tuple = self.maybe_mine_embeddings(authentic_final_embeddings, labels)\n            self.losses[""metric_loss""] = self.loss_funcs[""metric_loss""](authentic_final_embeddings, labels, indices_tuple)\n            logits = self.maybe_get_logits(authentic_final_embeddings)\n            self.losses[""classifier_loss""] = self.maybe_get_classifier_loss(logits, labels)\n\n        if self.do_adv:\n            self.calculate_synth_loss(penultimate_embeddings, labels)\n\n    def update_loss_weights(self):\n        self.do_metric_alone = self.epoch <= self.metric_alone_epochs\n        self.do_adv_alone = self.metric_alone_epochs < self.epoch <= self.metric_alone_epochs + self.g_alone_epochs\n        self.do_both = not self.do_adv_alone and not self.do_metric_alone\n        self.do_adv = self.do_adv_alone or self.do_both\n        self.do_metric = self.do_metric_alone or self.do_both\n\n        non_zero_weight_list = []\n        if self.do_adv:\n            non_zero_weight_list += [""g_hard_loss"", ""g_reg_loss"", ""g_adv_loss""]\n        if self.do_metric:\n            non_zero_weight_list += [""metric_loss"", ""classifier_loss""]\n        if self.do_both:\n            non_zero_weight_list += [""synth_loss""]\n\n        for k in self.loss_weights.keys():\n            if k in non_zero_weight_list:\n                self.loss_weights[k] = self.original_loss_weights[k]\n            else:\n                self.loss_weights[k] = 0\n\n        self.maybe_exclude_networks_from_gradient()\n\n    def maybe_exclude_networks_from_gradient(self):\n        self.set_to_train()\n        if self.do_adv_alone:\n            no_grad_list = [""trunk"", ""classifier""]\n        elif self.do_metric_alone:\n            no_grad_list = [""generator""]\n        else:\n            no_grad_list = []\n        for k in self.models.keys():\n            if k in no_grad_list:\n                c_f.set_requires_grad(self.models[k], requires_grad=False)\n                self.models[k].eval()\n            else:\n                c_f.set_requires_grad(self.models[k], requires_grad=True)\n\n\n    def step_optimizers(self):\n        step_list = []\n        if self.do_metric:\n            step_list += [""trunk_optimizer"", ""embedder_optimizer"", ""classifier_optimizer""]\n        if self.do_adv:\n            step_list += [""generator_optimizer""]\n        for k in self.optimizers.keys():\n            if k in step_list:\n                self.optimizers[k].step()\n\n    def calculate_synth_loss(self, penultimate_embeddings, labels):\n        a_indices, p_indices, n_indices = lmu.convert_to_triplets(None, labels, t_per_anchor=self.g_triplets_per_anchor)\n        real_anchors = penultimate_embeddings[a_indices]\n        real_positives = penultimate_embeddings[p_indices]\n        real_negatives = penultimate_embeddings[n_indices]\n        penultimate_embeddings_cat = torch.cat([real_anchors, real_positives, real_negatives], dim=1)\n        synthetic_negatives = self.models[""generator""](penultimate_embeddings_cat.to(self.data_device))\n        penultimate_embeddings_with_negative_synth = c_f.unslice_by_n([real_anchors, real_positives, synthetic_negatives])\n        final_embeddings = self.get_final_embeddings(penultimate_embeddings_with_negative_synth)\n\n        labels = torch.tensor(\n            [\n                val\n                for tup in zip(\n                    *[labels[a_indices], labels[p_indices], labels[n_indices]]\n                )\n                for val in tup\n            ]\n        )\n\n        indices_tuple = self.mining_funcs[""synth_packaged_as_triplets""](final_embeddings, labels)\n\n        if self.do_both:\n            self.losses[""synth_loss""] = self.loss_funcs[""synth_loss""](\n                final_embeddings, labels, indices_tuple\n            )\n\n        self.losses[""g_adv_loss""] = self.loss_funcs[""g_adv_loss""](\n            final_embeddings, labels, indices_tuple\n        )\n        self.losses[""g_hard_loss""] = torch.nn.functional.mse_loss(\n            torch.nn.functional.normalize(synthetic_negatives, p=2, dim=1),\n            torch.nn.functional.normalize(real_anchors, p=2, dim=1),\n        )\n        self.losses[""g_reg_loss""] = torch.nn.functional.mse_loss(\n            torch.nn.functional.normalize(synthetic_negatives, p=2, dim=1),\n            torch.nn.functional.normalize(real_negatives, p=2, dim=1),\n        )\n\n\n    def allowed_model_keys(self):\n        return super().allowed_model_keys()+[""generator""]\n\n    def allowed_loss_funcs_keys(self):\n        return super().allowed_loss_funcs_keys()+[""synth_loss"", ""g_adv_loss""]\n\n    def allowed_mining_funcs_keys(self):\n        return super().allowed_mining_funcs_keys()+[""synth_packaged_as_triplets""]\n\n    def verify_models_keys(self):\n        self._verify_dict_keys(""models"", self.allowed_model_keys(), True, essential_keys=[""trunk"", ""generator""])\n\n    def verify_loss_funcs_keys(self):\n        self._verify_dict_keys(""loss_funcs"", self.allowed_loss_funcs_keys(), True, important_keys=self.allowed_loss_funcs_keys(), essential_keys=[""synth_loss"", ""g_adv_loss""])'"
src/pytorch_metric_learning/trainers/metric_loss_only.py,0,"b'#! /usr/bin/env python3\n\n\nfrom .base_trainer import BaseTrainer\n\n\nclass MetricLossOnly(BaseTrainer):\n    def calculate_loss(self, curr_batch):\n        data, labels = curr_batch\n        embeddings = self.compute_embeddings(data)\n        indices_tuple = self.maybe_mine_embeddings(embeddings, labels)\n        self.losses[""metric_loss""] = self.maybe_get_metric_loss(embeddings, labels, indices_tuple)\n        \n    def maybe_get_metric_loss(self, embeddings, labels, indices_tuple):\n        if self.loss_weights.get(""metric_loss"", 0) > 0:\n            return self.loss_funcs[""metric_loss""](embeddings, labels, indices_tuple)\n        return 0\n\n'"
src/pytorch_metric_learning/trainers/train_with_classifier.py,0,"b'#! /usr/bin/env python3\n\nfrom .metric_loss_only import MetricLossOnly\n\n\nclass TrainWithClassifier(MetricLossOnly):\n    def calculate_loss(self, curr_batch):\n        data, labels = curr_batch\n        embeddings = self.compute_embeddings(data)\n        logits = self.maybe_get_logits(embeddings)\n        indices_tuple = self.maybe_mine_embeddings(embeddings, labels)\n        self.losses[""metric_loss""] = self.maybe_get_metric_loss(embeddings, labels, indices_tuple)\n        self.losses[""classifier_loss""] = self.maybe_get_classifier_loss(logits, labels)\n\n    def maybe_get_classifier_loss(self, logits, labels):\n        if logits is not None:\n            return self.loss_funcs[""classifier_loss""](logits, labels.to(logits.device))\n        return 0\n\n    def maybe_get_logits(self, embeddings):\n        if self.models.get(""classifier"", None) and self.loss_weights.get(""classifier_loss"", 0) > 0:\n            return self.models[""classifier""](embeddings)\n        return None\n\n    def allowed_model_keys(self):\n        return super().allowed_model_keys()+[""classifier""]\n\n    def allowed_loss_funcs_keys(self):\n        return super().allowed_loss_funcs_keys()+[""classifier_loss""]'"
src/pytorch_metric_learning/trainers/twostream_metric_loss.py,2,"b'#! /usr/bin/env python3\n\n\nfrom .base_trainer import BaseTrainer\nfrom ..utils import common_functions as c_f, loss_and_miner_utils as lmu\nimport logging\nimport torch\n\nclass TwoStreamMetricLoss(BaseTrainer):\n\n    def calculate_loss(self, curr_batch):\n        (anchors, posnegs), labels = curr_batch\n        embeddings = (self.compute_embeddings(anchors), self.compute_embeddings(posnegs))\n\n        indices_tuple = self.maybe_mine_embeddings(embeddings, labels)\n        self.losses[""metric_loss""] = self.maybe_get_metric_loss(embeddings, labels, indices_tuple)\n    \n    def get_batch(self):\n        self.dataloader_iter, curr_batch = c_f.try_next_on_generator(self.dataloader_iter, self.dataloader)\n        anchors, posnegs, labels = self.data_and_label_getter(curr_batch)\n        data = (anchors,posnegs)\n        labels = c_f.process_label(labels, self.label_hierarchy_level, self.label_mapper)\n        return self.maybe_do_batch_mining(data, labels)\n\n    def maybe_get_metric_loss(self, embeddings, labels, indices_tuple):\n        if self.loss_weights.get(""metric_loss"", 0) > 0:\n            current_batch_size = embeddings[0].shape[0]\n            indices_tuple = c_f.shift_indices_tuple(indices_tuple, current_batch_size)\n            all_labels = torch.cat([labels, labels], dim=0)\n            all_embeddings = torch.cat(embeddings, dim=0)\n            return self.loss_funcs[""metric_loss""](all_embeddings, all_labels, indices_tuple)\n        return 0\n\n    def maybe_mine_embeddings(self, embeddings, labels):\n        # for both get_all_triplets_indices and mining_funcs\n        # we need to clone labels and pass them as ref_labels \n        # to ensure triplets are generated between anchors and posnegs\n        if ""tuple_miner"" in self.mining_funcs:\n            (anchors_embeddings, posnegs_embeddings) = embeddings\n            return self.mining_funcs[""tuple_miner""](anchors_embeddings, labels, posnegs_embeddings, labels.clone())\n        else:\n            return lmu.get_all_triplets_indices(labels, labels.clone())\n\n    def allowed_mining_funcs_keys(self):\n        return [""tuple_miner""]'"
src/pytorch_metric_learning/trainers/unsupervised_embeddings_using_augmentations.py,1,"b'from .metric_loss_only import MetricLossOnly\r\nimport logging\r\nfrom ..utils import common_functions as c_f\r\nimport torch\r\n\r\nclass UnsupervisedEmbeddingsUsingAugmentations(MetricLossOnly):\r\n    def __init__(self, transforms, data_and_label_setter=None, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.data_and_label_setter = data_and_label_setter\r\n        self.initialize_data_and_label_setter()\r\n        self.transforms = transforms\r\n        self.collate_fn = self.custom_collate_fn\r\n        self.initialize_dataloader()\r\n        logging.info(""Transforms: %s""%transforms)\r\n\r\n    def initialize_data_and_label_setter(self):\r\n        if self.data_and_label_setter is None:\r\n            self.data_and_label_setter = c_f.return_input\r\n\r\n    def custom_collate_fn(self, data):\r\n        transformed_data, labels = [], []\r\n        for i, d in enumerate(data):\r\n            img, _ = self.data_and_label_getter(d)\r\n            for t in self.transforms:\r\n                transformed_data.append(t(img))\r\n                labels.append(i)\r\n        return self.data_and_label_setter((torch.stack(transformed_data, dim=0), torch.LongTensor(labels)))'"
src/pytorch_metric_learning/utils/__init__.py,0,b''
src/pytorch_metric_learning/utils/accuracy_calculator.py,0,"b'#! /usr/bin/env python3\n\nimport numpy as np\nfrom sklearn.metrics import normalized_mutual_info_score, adjusted_mutual_info_score\nfrom . import stat_utils\n\ndef maybe_get_avg_of_avgs(accuracy_per_sample, sample_labels, avg_of_avgs):\n    if avg_of_avgs:\n        unique_labels = np.unique(sample_labels)\n        mask = sample_labels == unique_labels[None, :]\n        acc_sum_per_class = np.sum(accuracy_per_sample[:, None]*mask, axis=0)\n        mask_sum_per_class = np.sum(mask, axis=0)\n        average_per_class = acc_sum_per_class / mask_sum_per_class\n        return np.mean(average_per_class)\n    return np.mean(accuracy_per_sample)\n\ndef get_relevance_mask(shape, gt_labels, embeddings_come_from_same_source, label_counts):\n    relevance_mask = np.zeros(shape=shape, dtype=np.int)\n    for k,v in label_counts.items():\n        matching_rows = np.where(gt_labels==k)[0]\n        max_column = v-1 if embeddings_come_from_same_source else v\n        relevance_mask[matching_rows, :max_column] = 1\n    return relevance_mask\n\ndef r_precision(knn_labels, gt_labels, embeddings_come_from_same_source, label_counts, average_per_class):\n    relevance_mask = get_relevance_mask(knn_labels.shape, gt_labels, embeddings_come_from_same_source, label_counts)\n    matches_per_row = np.sum((knn_labels == gt_labels) * relevance_mask.astype(bool), axis=1) \n    max_possible_matches_per_row = np.sum(relevance_mask, axis=1)\n    accuracy_per_sample = matches_per_row / max_possible_matches_per_row\n    return maybe_get_avg_of_avgs(accuracy_per_sample, gt_labels, average_per_class)\n\ndef mean_average_precision_at_r(knn_labels, gt_labels, embeddings_come_from_same_source, label_counts, average_per_class):\n    relevance_mask = get_relevance_mask(knn_labels.shape, gt_labels, embeddings_come_from_same_source, label_counts)\n    num_samples, num_k = knn_labels.shape\n    equality = (knn_labels == gt_labels) * relevance_mask.astype(bool)\n    cumulative_correct = np.cumsum(equality, axis=1)\n    k_idx = np.tile(np.arange(1, num_k + 1), (num_samples, 1))\n    precision_at_ks = (cumulative_correct * equality) / k_idx\n    summed_precision_per_row = np.sum(precision_at_ks * relevance_mask, axis=1)\n    max_possible_matches_per_row = np.sum(relevance_mask, axis=1)\n    accuracy_per_sample = summed_precision_per_row / max_possible_matches_per_row\n    return maybe_get_avg_of_avgs(accuracy_per_sample, gt_labels, average_per_class)\n\ndef precision_at_k(knn_labels, gt_labels, k, average_per_class):\n    curr_knn_labels = knn_labels[:, :k]\n    accuracy_per_sample = np.sum(curr_knn_labels == gt_labels, axis=1) / k\n    return maybe_get_avg_of_avgs(accuracy_per_sample, gt_labels, average_per_class)\n\ndef get_label_counts(reference_labels):\n    unique_labels, label_counts = np.unique(reference_labels, return_counts=True)\n    num_k = min(1023, int(np.max(label_counts))) # faiss can only do a max of k=1024, and we have to do k+1\n    return {k:v for k,v in zip(unique_labels, label_counts)}, num_k\n\ndef get_lone_query_labels(query_labels, reference_labels, reference_label_counts, embeddings_come_from_same_source):\n    if embeddings_come_from_same_source:\n        return np.array([k for k,v in reference_label_counts.items() if v <= 1])\n    else:\n        return np.setdiff1d(query_labels, reference_labels)\n\nclass AccuracyCalculator:\n    def __init__(self, include=(), exclude=(), avg_of_avgs=False, k=None):\n        self.function_keyword = ""calculate_""\n        function_names = [x for x in dir(self) if x.startswith(self.function_keyword)]\n        metrics = [x.replace(self.function_keyword, """", 1) for x in function_names]\n        self.original_function_dict = {x:getattr(self, y) for x,y in zip(metrics, function_names)}\n        self.check_primary_metrics(include, exclude)\n        self.original_function_dict = self.get_function_dict(include, exclude)\n        self.curr_function_dict = self.get_function_dict()\n        self.avg_of_avgs = avg_of_avgs\n        self.k = k\n\n    def get_function_dict(self, include=(), exclude=()):\n        if len(include) == 0:\n            include = list(self.original_function_dict.keys())\n        included_metrics = [k for k in include if k not in exclude] \n        return {k:v for k,v in self.original_function_dict.items() if k in included_metrics}\n\n    def get_curr_metrics(self):\n        return [k for k in self.curr_function_dict.keys()]\n\n    def requires_clustering(self):\n        return [""NMI"", ""AMI""]\n\n    def requires_knn(self):\n        return [""precision_at_1"", ""mean_average_precision_at_r"", ""r_precision""]\n\n    def get_cluster_labels(self, query, query_labels, **kwargs):\n        num_clusters = len(np.unique(query_labels.flatten()))\n        return stat_utils.run_kmeans(query, num_clusters)\n\n    def calculate_NMI(self, query_labels, cluster_labels, **kwargs):\n        return normalized_mutual_info_score(query_labels, cluster_labels)\n\n    def calculate_AMI(self, query_labels, cluster_labels, **kwargs):\n        return adjusted_mutual_info_score(query_labels, cluster_labels)\n\n    def calculate_precision_at_1(self, knn_labels, query_labels, not_lone_query_idx, **kwargs):\n        knn_labels, query_labels = knn_labels[not_lone_query_idx], query_labels[not_lone_query_idx]\n        return precision_at_k(knn_labels, query_labels[:, None], 1, self.avg_of_avgs)\n        \n    def calculate_mean_average_precision_at_r(self, knn_labels, query_labels, not_lone_query_idx, embeddings_come_from_same_source, label_counts, **kwargs):\n        knn_labels, query_labels = knn_labels[not_lone_query_idx], query_labels[not_lone_query_idx]\n        return mean_average_precision_at_r(knn_labels, query_labels[:, None], embeddings_come_from_same_source, label_counts, self.avg_of_avgs)\n\n    def calculate_r_precision(self, knn_labels, query_labels, not_lone_query_idx, embeddings_come_from_same_source, label_counts, **kwargs):\n        knn_labels, query_labels = knn_labels[not_lone_query_idx], query_labels[not_lone_query_idx]\n        return r_precision(knn_labels, query_labels[:, None], embeddings_come_from_same_source, label_counts, self.avg_of_avgs)\n\n    def get_accuracy(self, query, reference, query_labels, reference_labels, embeddings_come_from_same_source, include=(), exclude=()):\n        embeddings_come_from_same_source = embeddings_come_from_same_source or (query is reference)\n\n        self.curr_function_dict = self.get_function_dict(include, exclude)\n\n        kwargs = {""query"": query, \n                ""reference"": reference,\n                ""query_labels"": query_labels,\n                ""reference_labels"": reference_labels,\n                ""embeddings_come_from_same_source"": embeddings_come_from_same_source}\n\n        if any(x in self.requires_knn() for x in self.get_curr_metrics()):\n            label_counts, num_k = get_label_counts(reference_labels)\n            if self.k is not None: num_k = self.k\n            knn_indices, knn_distances = stat_utils.get_knn(reference, query, num_k, embeddings_come_from_same_source)\n            knn_labels = reference_labels[knn_indices]\n            lone_query_labels = get_lone_query_labels(query_labels, reference_labels, label_counts, embeddings_come_from_same_source)\n            not_lone_query_idx = ~np.isin(query_labels, lone_query_labels)\n            kwargs[""label_counts""] = label_counts\n            kwargs[""knn_labels""] = knn_labels\n            kwargs[""knn_distances""] = knn_distances\n            kwargs[""lone_query_labels""] = lone_query_labels\n            kwargs[""not_lone_query_idx""] = not_lone_query_idx\n\n        if any(x in self.requires_clustering() for x in self.get_curr_metrics()):\n            kwargs[""cluster_labels""] = self.get_cluster_labels(**kwargs)                \n\n        return self._get_accuracy(self.curr_function_dict, **kwargs)\n\n    def _get_accuracy(self, function_dict, **kwargs):\n        return {k:v(**kwargs) for k,v in function_dict.items()}\n\n    def check_primary_metrics(calc, include=(), exclude=()):\n        primary_metrics = list(calc.original_function_dict.keys())\n        for met in [include, exclude]:\n            if not isinstance(met, (tuple, list)):\n                raise TypeError(""Arguments must be of type tuple, not {}."".format(type(met)))\n            if not set(met).issubset(set(primary_metrics)):\n                raise ValueError(""Primary metrics must be one or more of: {}."".format(primary_metrics))\n\n    def description(self):\n        return ""avg_of_avgs"" if self.avg_of_avgs else """"\n'"
src/pytorch_metric_learning/utils/common_functions.py,12,"b'import collections\r\nimport torch\r\nimport numpy as np\r\nimport os\r\nimport logging\r\nimport glob\r\nimport scipy.stats\r\nimport re\r\n\r\nNUMPY_RANDOM = np.random\r\n\r\nclass Identity(torch.nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n    def forward(self, x):\r\n        return x\r\n\r\n\r\ndef is_list_or_tuple(x):\r\n    return isinstance(x, (list, tuple))\r\n\r\n\r\ndef try_next_on_generator(gen, iterable):\r\n    try:\r\n        return gen, next(gen)\r\n    except StopIteration:\r\n        gen = iter(iterable)\r\n        return gen, next(gen)\r\n\r\n\r\ndef numpy_to_torch(v):\r\n    try:\r\n        return torch.from_numpy(v)\r\n    except AttributeError:\r\n        return v\r\n\r\ndef to_numpy(v):\r\n    if is_list_or_tuple(v):\r\n        return np.stack([to_numpy(sub_v) for sub_v in v], axis=1)\r\n    try:\r\n        return v.cpu().numpy()\r\n    except AttributeError:\r\n        return v\r\n\r\n\r\ndef get_hierarchy_label(batch_labels, hierarchy_level):\r\n    if hierarchy_level == ""all"":\r\n        return batch_labels\r\n    if is_list_or_tuple(hierarchy_level):\r\n        max_hierarchy_level = max(hierarchy_level)\r\n    else:\r\n        max_hierarchy_level = hierarchy_level\r\n    if max_hierarchy_level > 0:\r\n        assert (batch_labels.ndim == 2) and batch_labels.shape[1] > max_hierarchy_level\r\n    if batch_labels.ndim == 2:\r\n        batch_labels = batch_labels[:, hierarchy_level]\r\n    return batch_labels\r\n\r\n\r\ndef map_labels(label_map, labels):\r\n    labels = to_numpy(labels)\r\n    if labels.ndim == 2:\r\n        for h in range(labels.shape[1]):\r\n            labels[:, h] = label_map(labels[:, h], h)\r\n    else:\r\n        labels = label_map(labels, 0)\r\n    return labels\r\n\r\ndef process_label(labels, hierarchy_level, label_map):\r\n    labels = map_labels(label_map, labels)\r\n    labels = get_hierarchy_label(labels, hierarchy_level)\r\n    labels = numpy_to_torch(labels)\r\n    return labels\r\n\r\ndef set_requires_grad(model, requires_grad):\r\n    for param in model.parameters():\r\n        param.requires_grad = requires_grad\r\n\r\ndef shift_indices_tuple(indices_tuple, batch_size):\r\n    """"""\r\n    Shifts indices of positives and negatives of pairs or triplets by batch_size\r\n    \r\n    if len(indices_tuple) != 3 or len(indices_tuple) != 4, it will return indices_tuple\r\n    Args:\r\n        indices_tuple is a tuple with torch.Tensor\r\n        batch_size is an int \r\n    Returns:\r\n        A tuple with shifted indices\r\n    """"""\r\n\r\n    if len(indices_tuple) == 3:\r\n        indices_tuple = (indices_tuple[0],) + tuple([x+batch_size if len(x) > 0 else x for x in indices_tuple[1:]])\r\n    elif len(indices_tuple) == 4:\r\n        indices_tuple = tuple([x+batch_size if len(x) > 0 and i%2==1 else x for i,x in enumerate(indices_tuple)])\r\n    return indices_tuple\r\n\r\ndef safe_random_choice(input_data, size):\r\n    """"""\r\n    Randomly samples without replacement from a sequence. It is ""safe"" because\r\n    if len(input_data) < size, it will randomly sample WITH replacement\r\n    Args:\r\n        input_data is a sequence, like a torch tensor, numpy array,\r\n                        python list, tuple etc\r\n        size is the number of elements to randomly sample from input_data\r\n    Returns:\r\n        An array of size ""size"", randomly sampled from input_data\r\n    """"""\r\n    replace = len(input_data) < size\r\n    return NUMPY_RANDOM.choice(input_data, size=size, replace=replace)\r\n\r\n\r\ndef longest_list(list_of_lists):\r\n    return max(list_of_lists, key=len)\r\n\r\n\r\ndef slice_by_n(input_array, n):\r\n    output = []\r\n    for i in range(n):\r\n        output.append(input_array[i::n])\r\n    return output\r\n\r\n\r\ndef unslice_by_n(input_tensors):\r\n    n = len(input_tensors)\r\n    rows, cols = input_tensors[0].size()\r\n    output = torch.zeros((rows * n, cols)).to(input_tensors[0].device)\r\n    for i in range(n):\r\n        output[i::n] = input_tensors[i]\r\n    return output\r\n\r\n\r\ndef set_layers_to_eval(layer_name):\r\n    def set_to_eval(m):\r\n        classname = m.__class__.__name__\r\n        if classname.find(layer_name) != -1:\r\n            m.eval()\r\n    return set_to_eval\r\n\r\n\r\ndef get_train_dataloader(dataset, batch_size, sampler, num_workers, collate_fn):\r\n    return torch.utils.data.DataLoader(\r\n        dataset,\r\n        batch_size=int(batch_size),\r\n        sampler=sampler,\r\n        drop_last=True,\r\n        num_workers=num_workers,\r\n        collate_fn=collate_fn,\r\n        shuffle=sampler is None,\r\n        pin_memory=False\r\n    )\r\n\r\ndef get_eval_dataloader(dataset, batch_size, num_workers, collate_fn):\r\n    return torch.utils.data.DataLoader(\r\n        dataset,\r\n        batch_size=int(batch_size),\r\n        drop_last=False,\r\n        num_workers=num_workers,\r\n        collate_fn=collate_fn,\r\n        shuffle=False,\r\n        pin_memory=False\r\n    )\r\n\r\n\r\ndef try_torch_operation(torch_op, input_val):\r\n    return torch_op(input_val) if torch.is_tensor(input_val) else input_val \r\n\r\n\r\ndef get_labels_to_indices(labels):\r\n    """"""\r\n    Creates labels_to_indices, which is a dictionary mapping each label\r\n    to a numpy array of indices that will be used to index into self.dataset\r\n    """"""\r\n    labels_to_indices = collections.defaultdict(list)\r\n    for i, label in enumerate(labels):\r\n        labels_to_indices[label].append(i)\r\n    for k, v in labels_to_indices.items():\r\n        labels_to_indices[k] = np.array(v, dtype=np.int)\r\n    return labels_to_indices\r\n\r\n\r\ndef make_label_to_rank_dict(label_set):\r\n    """"""\r\n    Args:\r\n        label_set: type sequence, a set of integer labels\r\n                    (no duplicates in the sequence)\r\n    Returns:\r\n        A dictionary mapping each label to its numeric rank in the original set\r\n    """"""\r\n    ranked = scipy.stats.rankdata(label_set)-1\r\n    return {k: v for k, v in zip(label_set, ranked)}\r\n\r\n\r\ndef get_label_map(labels):\r\n    # Returns a nested dictionary. \r\n    # First level of dictionary represents label hierarchy level.\r\n    # Second level is the label map for that hierarchy level\r\n    labels = np.array(labels)\r\n    if labels.ndim == 2:\r\n        label_map = {}\r\n        for hierarchy_level in range(labels.shape[1]):\r\n            label_map[hierarchy_level] = make_label_to_rank_dict(list(set(labels[:, hierarchy_level])))\r\n        return label_map\r\n    return {0: make_label_to_rank_dict(list(set(labels)))} \r\n\r\n\r\nclass LabelMapper:\r\n    def __init__(self, set_min_label_to_zero=False, dataset_labels=None):\r\n        self.set_min_label_to_zero = set_min_label_to_zero\r\n        if dataset_labels is not None:\r\n            self.label_map = get_label_map(dataset_labels)\r\n\r\n    def map(self, labels, hierarchy_level):\r\n        if not self.set_min_label_to_zero:\r\n            return labels\r\n        else:\r\n            return np.array([self.label_map[hierarchy_level][x] for x in labels], dtype=np.int)\r\n        \r\n\r\n\r\ndef add_to_recordable_attributes(input_obj, name=None, list_of_names=None):\r\n    if not hasattr(input_obj, ""record_these""):\r\n        input_obj.record_these = []\r\n    if name is not None:\r\n        if name not in input_obj.record_these:\r\n            input_obj.record_these.append(name)\r\n        if not hasattr(input_obj, name):\r\n            setattr(input_obj, name, 0)\r\n    if list_of_names is not None and isinstance(list_of_names, list):\r\n        for n in list_of_names:\r\n            add_to_recordable_attributes(input_obj, name=n)\r\n\r\n\r\ndef modelpath_creator(folder, basename, identifier, extension="".pth""):\r\n    if identifier is None:\r\n        return os.path.join(folder, basename+extension)\r\n    else:\r\n        return os.path.join(folder, ""%s_%s%s"" % (basename, str(identifier), extension))\r\n\r\n\r\ndef save_model(model, model_name, filepath):\r\n    if any(isinstance(model, x) for x in [torch.nn.DataParallel, torch.nn.parallel.DistributedDataParallel]):\r\n        torch.save(model.module.state_dict(), filepath)\r\n    else:\r\n        torch.save(model.state_dict(), filepath)\r\n\r\n\r\ndef load_model(model_def, model_filename, device):\r\n    try:\r\n        model_def.load_state_dict(torch.load(model_filename, map_location=device))\r\n    except KeyError:\r\n        # original saved file with DataParallel\r\n        state_dict = torch.load(model_filename)\r\n        # create new OrderedDict that does not contain `module.`\r\n        from collections import OrderedDict\r\n\r\n        new_state_dict = OrderedDict()\r\n        for k, v in state_dict.items():\r\n            name = k[7:]  # remove `module.`\r\n            new_state_dict[name] = v\r\n        # load params\r\n        model_def.load_state_dict(new_state_dict)\r\n\r\n\r\ndef operate_on_dict_of_models(input_dict, suffix, folder, operation, logging_string=\'\', log_if_successful=False, assert_success=False):\r\n    for k, v in input_dict.items():\r\n        model_path = modelpath_creator(folder, k, suffix)\r\n        try:\r\n            operation(k, v, model_path)\r\n            if log_if_successful:\r\n                logging.info(""%s %s""%(logging_string, model_path))\r\n        except IOError:\r\n            logging.warn(""Could not %s %s""%(logging_string, model_path))\r\n            if assert_success:\r\n                raise IOError\r\n\r\ndef save_dict_of_models(input_dict, suffix, folder, **kwargs):\r\n    def operation(k, v, model_path):\r\n        save_model(v, k, model_path)\r\n    operate_on_dict_of_models(input_dict, suffix, folder, operation, ""SAVE"", **kwargs)\r\n\r\n\r\ndef load_dict_of_models(input_dict, suffix, folder, device, **kwargs):\r\n    def operation(k, v, model_path):\r\n        load_model(v, model_path, device)\r\n    operate_on_dict_of_models(input_dict, suffix, folder, operation, ""LOAD"", **kwargs)\r\n\r\n\r\ndef delete_dict_of_models(input_dict, suffix, folder, **kwargs):\r\n    def operation(k, v, model_path):\r\n        if os.path.exists(model_path): os.remove(model_path)\r\n    operate_on_dict_of_models(input_dict, suffix, folder, operation, ""DELETE"", **kwargs)\r\n\r\n\r\ndef regex_wrapper(x):\r\n    if isinstance(x, list):\r\n        return [re.compile(z) for z in x]\r\n    return re.compile(x)\r\n\r\ndef regex_replace(search, replace, contents):\r\n    return re.sub(search, replace, contents)\r\n\r\n\r\ndef latest_version(folder, string_to_glob=""trunk_*.pth"", best=False):\r\n    items = glob.glob(os.path.join(folder, string_to_glob))\r\n    if items == []:\r\n        return (0, None)\r\n    model_regex = regex_wrapper(""best[0-9]+\\.pth$"") if best else regex_wrapper(""[0-9]+\\.pth$"")\r\n    epoch_regex = regex_wrapper(""[0-9]+\\.pth$"")\r\n    items = [x for x in items if model_regex.search(x)]\r\n    version = [int(epoch_regex.findall(x)[-1].split(""."")[0]) for x in items]\r\n    resume_epoch = max(version)\r\n    suffix = ""best%d""%resume_epoch if best else resume_epoch\r\n    return resume_epoch, suffix\r\n\r\ndef return_input(x):\r\n    return x\r\n\r\ndef angle_to_coord(angle):\r\n    x = np.cos(np.radians(angle))\r\n    y = np.sin(np.radians(angle))\r\n    return x, y\r\n\r\ndef assert_embeddings_and_labels_are_same_size(embeddings, labels):\r\n    assert embeddings.size(0) == labels.size(0), ""Number of embeddings must equal number of labels""'"
src/pytorch_metric_learning/utils/inference.py,8,"b'from . import loss_and_miner_utils as lmu, common_functions as c_f\nimport numpy as np\nimport torch\n\nclass MatchFinder:\n    def __init__(self, mode=""dist"", threshold=None):\n        assert mode in [""dist"", ""squared_dist"", ""sim""]\n        self.mode = mode\n        self.threshold = threshold\n\n    def operate_on_emb(self, input_func, query_emb, ref_emb=None, *args, **kwargs):\n        if ref_emb is None:\n            ref_emb = query_emb\n        return input_func(query_emb, ref_emb, *args, **kwargs)\n\n    # for a batch of queries\n    def get_matching_pairs(self, query_emb, ref_emb=None, threshold=None, return_tuples=False):\n        with torch.no_grad():\n            threshold = threshold if self.threshold is None else self.threshold\n            return self.operate_on_emb(self._get_matching_pairs, query_emb, ref_emb, threshold, return_tuples)\n\n    def _get_matching_pairs(self, query_emb, ref_emb, threshold, return_tuples):\n        if self.mode == ""dist"":\n            mat = lmu.dist_mat(query_emb, ref_emb, squared=False)\n        elif self.mode == ""squared_dist"":\n            mat = lmu.dist_mat(query_emb, ref_emb, squared=True)\n        elif self.mode == ""sim"":\n            mat = lmu.sim_mat(query_emb, ref_emb)\n        \n        if self.mode == ""sim"":\n            matches = mat >= threshold\n        else:\n            matches = mat <= threshold\n        \n        matches = matches.cpu().numpy()\n\n        if return_tuples:\n            return list(zip(*np.where(matches)))\n        return matches\n\n    # where x and y are already matched pairs\n    def is_match(self, x, y, threshold=None):\n        threshold = threshold if self.threshold is None else self.threshold\n        with torch.no_grad():\n            if self.mode == ""dist"":\n                dist = torch.nn.functional.pairwise_distance(x, y)\n            elif self.mode == ""squared_dist"":\n                dist = torch.nn.functional.pairwise_distance(x, y) ** 2\n            elif self.mode == ""sim"":\n                dist = torch.sum(x*y, dim=1)\n            output = dist >= threshold if self.mode == ""sim"" else dist <= threshold\n            if output.nelement() == 1:\n                return output.detach().item()\n            return output.cpu().numpy()\n\n\n\nclass InferenceModel:\n    def __init__(self, trunk, embedder=None, match_finder=None, normalize_embeddings=True):\n        self.trunk = trunk\n        self.embedder = c_f.Identity() if embedder is None else embedder\n        self.match_finder = MatchFinder(mode=""sim"", threshold=0.9) if match_finder is None else match_finder \n        self.normalize_embeddings = normalize_embeddings\n        \n    def get_embeddings(self, query, ref):\n        self.trunk.eval()\n        self.embedder.eval()\n        with torch.no_grad():\n            query_emb = self.embedder(self.trunk(query))\n            ref_emb = query_emb if ref is None else self.embedder(self.trunk(ref))\n        if self.normalize_embeddings:\n            query_emb = torch.nn.functional.normalize(query_emb, p=2, dim=1)\n            ref_emb = torch.nn.functional.normalize(ref_emb, p=2, dim=1)\n        return query_emb, ref_emb\n\n    # for a batch of queries\n    def get_matches(self, query, ref=None, threshold=None, return_tuples=False):\n        query_emb, ref_emb = self.get_embeddings(query, ref)\n        return self.match_finder.get_matching_pairs(query_emb, ref_emb, threshold, return_tuples)\n\n    # where x and y are already matched pairs\n    def is_match(self, x, y, threshold=None):\n        x, y = self.get_embeddings(x, y)\n        return self.match_finder.is_match(x, y, threshold)\n\n'"
src/pytorch_metric_learning/utils/logging_presets.py,3,"b'import logging\r\nfrom . import common_functions as c_f\r\nimport os\r\nimport torch\r\nfrom collections import defaultdict\r\nimport sqlite3\r\n\r\n# You can write your own hooks for logging.\r\n# But if you\'d like something that just works, then use this HookContainer.\r\n# You\'ll need to install record-keeper and tensorboard.\r\n# pip install record-keeper tensorboard\r\n\r\nclass HookContainer: \r\n\r\n    def __init__(self, record_keeper, \r\n                        record_group_name_prefix=None, \r\n                        primary_metric=""mean_average_precision_at_r"", \r\n                        validation_split_name=""val""):\r\n        self.record_keeper = record_keeper\r\n        self.record_group_name_prefix = record_group_name_prefix\r\n        self.saveable_trainer_objects = [""models"", ""optimizers"", ""lr_schedulers"", ""loss_funcs"", ""mining_funcs""]\r\n        self.primary_metric = primary_metric\r\n        self.validation_split_name = validation_split_name\r\n\r\n    ############################################\r\n    ############################################\r\n    ##################  HOOKS  #################\r\n    ############################################\r\n    ############################################\r\n\r\n    ### Define the end_of_iteration hook. This will be executed at the end of every iteration. ###\r\n    def end_of_iteration_hook(self, trainer):\r\n        record_these = [[trainer.loss_tracker.losses, {""input_group_name_for_non_objects"": ""loss_histories""}],\r\n                        [trainer.loss_tracker.loss_weights, {""input_group_name_for_non_objects"": ""loss_weights""}],\r\n                        [trainer.loss_funcs, {""recursive_types"": [torch.nn.Module]}],\r\n                        [trainer.mining_funcs, {}],\r\n                        [trainer.models, {}],\r\n                        [trainer.optimizers, {""custom_attr_func"": self.optimizer_custom_attr_func}]]\r\n        for record, kwargs in record_these:\r\n            self.record_keeper.update_records(record, trainer.get_global_iteration(), **kwargs)\r\n\r\n    # This hook will be passed into the trainer and will be executed at the end of every epoch.\r\n    def end_of_epoch_hook(self, tester, dataset_dict, model_folder, test_interval=1, patience=None, test_collate_fn=None):\r\n        if not self.primary_metric in tester.accuracy_calculator.get_curr_metrics():\r\n            raise ValueError(""HookContainer `primary_metric` must be one of: {}"".format(tester.accuracy_calculator.get_curr_metrics()))\r\n        if not os.path.exists(model_folder): os.makedirs(model_folder)\r\n        def actual_hook(trainer):\r\n            continue_training = True\r\n            self.record_keeper.maybe_add_multi_line_plots_to_tensorboard(trainer.get_global_iteration())\r\n            if trainer.epoch % test_interval == 0:\r\n                best_epoch = self.save_models_and_eval(trainer, dataset_dict, model_folder, test_interval, tester, test_collate_fn)\r\n                continue_training = self.patience_remaining(trainer.epoch, best_epoch, patience)\r\n            return continue_training\r\n        return actual_hook\r\n\r\n    def end_of_testing_hook(self, tester):\r\n        for split_name, accuracies in tester.all_accuracies.items():\r\n            epoch = accuracies[""epoch""]\r\n            self.record_keeper.update_records(accuracies, epoch, input_group_name_for_non_objects=self.record_group_name(tester, split_name))\r\n            _, _, best_epoch, best_accuracy = self.is_new_best_accuracy(tester, split_name, epoch)\r\n            best = {""best_epoch"":best_epoch, ""best_accuracy"": best_accuracy}\r\n            self.record_keeper.update_records(best, epoch, input_group_name_for_non_objects=self.record_group_name(tester, split_name)) \r\n\r\n        for split_name, u in tester.dim_reduced_embeddings.items():\r\n            for k, (dim_reduced, labels) in u.items():\r\n                tag = \'%s/%s\'%(self.record_group_name(tester, split_name), k)\r\n                self.record_keeper.add_embedding_plot(dim_reduced, labels, tag, epoch)\r\n\r\n\r\n\r\n    ############################################\r\n    ############################################\r\n    ######### MODEL LOADING AND SAVING #########\r\n    ############################################\r\n    ############################################\r\n\r\n    def load_latest_saved_models(self, trainer, model_folder, device=None, best=False):\r\n        if device is None: device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\r\n        resume_epoch, model_suffix = c_f.latest_version(model_folder, ""trunk_*.pth"", best=best)\r\n        if resume_epoch > 0:\r\n            for obj_dict in [getattr(trainer, x, {}) for x in self.saveable_trainer_objects]:\r\n                c_f.load_dict_of_models(obj_dict, model_suffix, model_folder, device, log_if_successful=True)\r\n        return resume_epoch + 1\r\n\r\n\r\n    def save_models(self, trainer, model_folder, curr_suffix, prev_suffix=None):\r\n        for obj_dict in [getattr(trainer, x, {}) for x in self.saveable_trainer_objects]:\r\n            c_f.save_dict_of_models(obj_dict, curr_suffix, model_folder)\r\n            if prev_suffix is not None:\r\n                c_f.delete_dict_of_models(obj_dict, prev_suffix, model_folder) \r\n\r\n    def save_models_and_eval(self, trainer, dataset_dict, model_folder, test_interval, tester, collate_fn):\r\n        epoch = trainer.epoch\r\n        tester.test(dataset_dict, epoch, trainer.models[""trunk""], trainer.models[""embedder""], list(dataset_dict.keys()), collate_fn)\r\n        prev_best_epoch, _ = self.get_best_epoch_and_accuracy(tester, self.validation_split_name)\r\n        is_new_best, curr_accuracy, best_epoch, best_accuracy = self.is_new_best_accuracy(tester, self.validation_split_name, epoch)\r\n        self.record_keeper.save_records()\r\n        trainer.step_lr_plateau_schedulers(curr_accuracy)\r\n        self.save_models(trainer, model_folder, epoch, epoch-test_interval) # save latest model\r\n        if is_new_best:\r\n            logging.info(""New best accuracy! {}"".format(curr_accuracy))\r\n            curr_suffix = ""best%d""%best_epoch\r\n            prev_suffix = ""best%d""%prev_best_epoch if prev_best_epoch is not None else None\r\n            self.save_models(trainer, model_folder, curr_suffix, prev_suffix) # save best model    \r\n        return best_epoch\r\n\r\n    def is_new_best_accuracy(self, tester, split_name, epoch):\r\n        curr_accuracy = self.get_curr_primary_metric(tester, split_name)\r\n        best_epoch, best_accuracy = self.get_best_epoch_and_accuracy(tester, split_name)\r\n        is_new_best = False\r\n        if (curr_accuracy > best_accuracy) or (best_epoch is None):\r\n            best_epoch, best_accuracy = epoch, curr_accuracy\r\n            is_new_best = True\r\n        return is_new_best, curr_accuracy, best_epoch, best_accuracy \r\n\r\n\r\n    ############################################\r\n    ############################################\r\n    ##### BEST EPOCH AND ACCURACY TRACKING #####\r\n    ############################################\r\n    ############################################\r\n\r\n\r\n    def get_loss_history(self, loss_names=()):\r\n        columns = ""*"" if len(loss_names) == 0 else "", "".join(loss_names)\r\n        table_name = ""loss_histories""\r\n        if not self.record_keeper.table_exists(table_name):\r\n            return {}\r\n        output = self.record_keeper.query(""SELECT {} FROM {}"".format(columns, table_name), return_dict=True)\r\n        output.pop(""id"", None)\r\n        return output\r\n\r\n\r\n    def get_accuracy_history(self, tester, split_name, return_all_metrics=False, metrics=()):\r\n        table_name = self.record_group_name(tester, split_name)\r\n\r\n        if not self.record_keeper.table_exists(table_name):\r\n            return {}\r\n\r\n        def get_accuracies(keys):\r\n            keys = ""*"" if return_all_metrics else ""epoch, %s""%keys\r\n            query = ""SELECT {} FROM {}"".format(keys, table_name)\r\n            return self.record_keeper.query(query, return_dict=True)\r\n\r\n        keys = metrics if len(metrics) > 0 else [self.primary_metric]\r\n        output = self.try_keys(keys, tester, get_accuracies)\r\n        output.pop(""id"", None)\r\n        return output\r\n\r\n\r\n    def get_curr_primary_metric(self, tester, split_name):\r\n        def get_curr(key):\r\n            return tester.all_accuracies[split_name][key]\r\n        return self.try_primary_metric(tester, get_curr)\r\n\r\n    def try_keys(self, input_keys, tester, input_func):\r\n        for average in [True, False]:\r\n            keys = "", "".join([tester.accuracies_keyname(k, average=average, label_hierarchy_level=tester.label_hierarchy_level) for k in input_keys])\r\n            try:\r\n                return input_func(keys)\r\n            except (KeyError, sqlite3.OperationalError):\r\n                pass\r\n        raise KeyError        \r\n\r\n    def try_primary_metric(self, tester, input_func):\r\n        return self.try_keys([self.primary_metric], tester, input_func)\r\n\r\n    # returns accuracies of a specified epoch\r\n    def get_accuracies_of_epoch(self, tester, split_name, epoch, select_all=True):\r\n        table_name = self.record_group_name(tester, split_name)\r\n        if not self.record_keeper.table_exists(table_name):\r\n            return []\r\n        def get_accuracies(key):\r\n            columns = ""*"" if select_all else ""epoch, %s""%key\r\n            query = ""SELECT %s FROM %s WHERE epoch=?""%(columns, table_name)\r\n            return self.record_keeper.query(query, (epoch, ))\r\n        return self.try_primary_metric(tester, get_accuracies)\r\n\r\n    # returns accuracies of best epoch and the metric name used to determine best acuracy\r\n    def get_accuracies_of_best_epoch(self, tester, split_name, select_all=True, ignore_epoch=(-1,)):\r\n        table_name = self.record_group_name(tester, split_name)\r\n        if not self.record_keeper.table_exists(table_name):\r\n            return [], None        \r\n        def get_accuracies(key):\r\n            columns = ""*"" if select_all else ""epoch, %s""%key\r\n            params = "", "".join([""?""]*len(ignore_epoch))\r\n            query = """"""SELECT {0} FROM {1} WHERE {2}=\r\n                        (SELECT max({2}) FROM {1} WHERE epoch NOT IN ({3}))\r\n                        AND epoch NOT IN ({3})"""""".format(columns, table_name, key, params)\r\n            output = self.record_keeper.query(query, ignore_epoch+ignore_epoch)\r\n            return output, key\r\n        return self.try_primary_metric(tester, get_accuracies)\r\n\r\n    def get_best_epoch_and_accuracy(self, tester, split_name, ignore_epoch=(-1,)):\r\n        accuracies, key = self.get_accuracies_of_best_epoch(tester, split_name, select_all=False, ignore_epoch=ignore_epoch)\r\n        if len(accuracies) > 0:\r\n            return accuracies[0][""epoch""], accuracies[0][key]\r\n        return None, 0\r\n\r\n    def patience_remaining(self, epoch, best_epoch, patience):\r\n        if patience is not None and best_epoch is not None:\r\n            if epoch - best_epoch > patience:\r\n                logging.info(""Validation accuracy has plateaued. Exiting."")\r\n                return False\r\n        return True\r\n\r\n    def run_tester_separately(self, tester, dataset_dict, epoch, trunk, embedder, splits_to_eval=None, collate_fn=None, skip_eval_if_already_done=True):\r\n        if skip_eval_if_already_done:\r\n            splits_to_eval = self.get_splits_to_eval(tester, dataset_dict, epoch, splits_to_eval)\r\n            if len(splits_to_eval) == 0:\r\n                logging.info(""Already evaluated"")\r\n                return False\r\n        tester.test(dataset_dict, epoch, trunk, embedder, splits_to_eval, collate_fn)\r\n        return True\r\n\r\n    def get_splits_to_eval(self, tester, dataset_dict, epoch, input_splits_to_eval):\r\n        input_splits_to_eval = list(dataset_dict.keys()) if input_splits_to_eval is None else input_splits_to_eval\r\n        splits_to_eval = []\r\n        for split in input_splits_to_eval:\r\n            if len(self.get_accuracies_of_epoch(tester, split, epoch)) == 0:\r\n                splits_to_eval.append(split)\r\n        return splits_to_eval\r\n\r\n    def base_record_group_name(self, tester):\r\n        base_record_group_name = ""%s_""%self.record_group_name_prefix if self.record_group_name_prefix else \'\'\r\n        base_record_group_name += tester.description_suffixes(""accuracies"")\r\n        return base_record_group_name\r\n\r\n    def record_group_name(self, tester, split_name):\r\n        base_record_group_name = self.base_record_group_name(tester)\r\n        return ""%s_%s""%(base_record_group_name, split_name.upper())\r\n\r\n    def optimizer_custom_attr_func(self, optimizer):\r\n        return {""lr"": optimizer.param_groups[0][""lr""]}\r\n\r\n\r\n\r\nclass EmptyContainer:\r\n    def end_of_epoch_hook(self, *args):\r\n        return None\r\n    end_of_iteration_hook = None\r\n    end_of_testing_hook = None\r\n\r\n\r\n\r\ndef get_record_keeper(csv_folder, tensorboard_folder, global_db_path=None, experiment_name=None, is_new_experiment=True, save_figures=False):\r\n    try:\r\n        import record_keeper as record_keeper_package\r\n        from torch.utils.tensorboard import SummaryWriter\r\n        record_writer = record_keeper_package.RecordWriter(csv_folder, global_db_path, experiment_name, is_new_experiment)\r\n        tensorboard_writer = SummaryWriter(log_dir=tensorboard_folder)\r\n        record_keeper = record_keeper_package.RecordKeeper(tensorboard_writer, record_writer, [""record_these"", ""learnable_param_names""], save_figures=save_figures)\r\n        return record_keeper, record_writer, tensorboard_writer\r\n\r\n    except ModuleNotFoundError as e:\r\n        logging.warn(e)\r\n        logging.warn(""There won\'t be any logging or model saving."")\r\n        logging.warn(""To fix this, pip install record-keeper tensorboard"")\r\n        return None, None, None\r\n\r\n\r\ndef get_hook_container(record_keeper, **kwargs):\r\n    if record_keeper:\r\n        return HookContainer(record_keeper, **kwargs)\r\n    else:\r\n        logging.warn(""No record_keeper, so no preset hooks are being returned."")\r\n        return EmptyContainer()\r\n'"
src/pytorch_metric_learning/utils/loss_and_miner_utils.py,26,"b'import torch\r\nimport numpy as np\r\nimport math\r\nfrom . import common_functions as c_f\r\n\r\n\r\ndef logsumexp(x, keep_mask=None, add_one=True, dim=1):\r\n    max_vals, _ = torch.max(x, dim=dim, keepdim=True)\r\n    inside_exp = x - max_vals\r\n    exp = torch.exp(inside_exp)\r\n    if keep_mask is not None:\r\n        exp = exp*keep_mask\r\n    inside_log = torch.sum(exp, dim=dim, keepdim=True)\r\n    if add_one: \r\n        inside_log = inside_log + torch.exp(-max_vals)\r\n    else:\r\n        # add one only if necessary\r\n        inside_log[inside_log==0] = torch.exp(-max_vals[inside_log==0])\r\n    return torch.log(inside_log) + max_vals\r\n\r\ndef sim_mat(x, y=None):\r\n    """"""\r\n    returns a matrix where entry (i,j) is the dot product of x[i] and x[j]\r\n    """"""\r\n    if y is None:\r\n        y = x\r\n    return torch.matmul(x, y.t())\r\n\r\n\r\n# https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065/7\r\ndef dist_mat(x, y=None, eps=1e-16, squared=False):\r\n    """"""\r\n    Input: x is a Nxd matrix\r\n           y is an optional Mxd matirx\r\n    Output: dist is a NxM matrix where dist[i,j]\r\n    is the square norm between x[i,:] and y[j,:]\r\n            if y is not given then use \'y=x\'.\r\n    i.e. dist[i,j] = ||x[i,:]-y[j,:]||\r\n    """"""\r\n    x_norm = (x ** 2).sum(1).view(-1, 1)\r\n    if y is not None:\r\n        y_t = torch.transpose(y, 0, 1)\r\n        y_norm = (y ** 2).sum(1).view(1, -1)\r\n    else:\r\n        y_t = torch.transpose(x, 0, 1)\r\n        y_norm = x_norm.view(1, -1)\r\n\r\n    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\r\n    # Ensure diagonal is zero if x=y\r\n    if y is None:\r\n        dist = dist - torch.diag(dist.diag())\r\n    dist = torch.clamp(dist, 0.0, np.inf)\r\n    if not squared:\r\n        mask = (dist == 0).float()\r\n        dist = dist + mask * eps\r\n        dist = torch.sqrt(dist)\r\n        dist = dist * (1.0 - mask)\r\n    return dist\r\n\r\ndef get_pairwise_mat(x, y, use_similarity, squared):\r\n    if x is y:\r\n        y = None\r\n    return sim_mat(x, y=y) if use_similarity else dist_mat(x, y=y, squared=squared)\r\n\r\ndef get_all_pairs_indices(labels, ref_labels=None):\r\n    """"""\r\n    Given a tensor of labels, this will return 4 tensors.\r\n    The first 2 tensors are the indices which form all positive pairs\r\n    The second 2 tensors are the indices which form all negative pairs\r\n    """"""\r\n    if ref_labels is None:\r\n        ref_labels = labels\r\n    labels1 = labels.unsqueeze(1)\r\n    labels2 = ref_labels.unsqueeze(0)\r\n    matches = (labels1 == labels2).byte()\r\n    diffs = matches ^ 1\r\n    if ref_labels is labels:\r\n        matches -= torch.eye(matches.size(0)).byte().to(labels.device)\r\n    a1_idx = matches.nonzero()[:, 0].flatten()\r\n    p_idx = matches.nonzero()[:, 1].flatten()\r\n    a2_idx = diffs.nonzero()[:, 0].flatten()\r\n    n_idx = diffs.nonzero()[:, 1].flatten()\r\n    return a1_idx, p_idx, a2_idx, n_idx\r\n\r\n\r\ndef convert_to_pairs(indices_tuple, labels):\r\n    """"""\r\n    This returns anchor-positive and anchor-negative indices,\r\n    regardless of what the input indices_tuple is\r\n    Args:\r\n        indices_tuple: tuple of tensors. Each tensor is 1d and specifies indices\r\n                        within a batch\r\n        labels: a tensor which has the label for each element in a batch\r\n    """"""\r\n    if indices_tuple is None:\r\n        return get_all_pairs_indices(labels)\r\n    elif len(indices_tuple) == 4:\r\n        return indices_tuple\r\n    else:\r\n        a, p, n = indices_tuple\r\n        return a, p, a, n\r\n\r\n\r\ndef convert_to_pos_pairs_with_unique_labels(indices_tuple, labels):\r\n    a, p, _, _ = convert_to_pairs(indices_tuple, labels)\r\n    _, unique_idx = np.unique(labels[a].cpu().numpy(), return_index=True) \r\n    return a[unique_idx], p[unique_idx]\r\n\r\n\r\ndef get_all_triplets_indices(labels, ref_labels=None):\r\n    if ref_labels is None:\r\n        ref_labels = labels\r\n    labels1 = labels.unsqueeze(1)\r\n    labels2 = ref_labels.unsqueeze(0)\r\n    matches = (labels1 == labels2).byte()\r\n    diffs = matches ^ 1\r\n    if ref_labels is labels:\r\n        matches -= torch.eye(matches.size(0)).byte().to(labels.device)\r\n    triplets = matches.unsqueeze(2)*diffs.unsqueeze(1)\r\n    a_idx = triplets.nonzero()[:, 0].flatten()\r\n    p_idx = triplets.nonzero()[:, 1].flatten()\r\n    n_idx = triplets.nonzero()[:, 2].flatten()\r\n    return a_idx, p_idx, n_idx\r\n\r\n\r\n\r\n# sample triplets, with a weighted distribution if weights is specified.\r\ndef get_random_triplet_indices(labels, ref_labels=None, t_per_anchor=None, weights=None):\r\n    a_idx, p_idx, n_idx = [], [], []\r\n    labels = labels.cpu().numpy()\r\n    ref_labels = labels if ref_labels is None else ref_labels.cpu().numpy()\r\n    batch_size = ref_labels.shape[0]\r\n    label_count = dict(zip(*np.unique(ref_labels, return_counts=True)))\r\n    indices = np.arange(batch_size)\r\n    for i, label in enumerate(labels):\r\n        curr_label_count = label_count[label]\r\n        if ref_labels is labels: curr_label_count -= 1\r\n        if curr_label_count == 0:\r\n            continue\r\n        k = curr_label_count if t_per_anchor is None else t_per_anchor\r\n\r\n        if weights is not None and not np.any(np.isnan(weights[i])):\r\n            n_idx += c_f.NUMPY_RANDOM.choice(batch_size, k, p=weights[i]).tolist()\r\n        else:\r\n            possible_n_idx = list(np.where(ref_labels != label)[0])\r\n            n_idx += c_f.NUMPY_RANDOM.choice(possible_n_idx, k).tolist()\r\n\r\n        a_idx.extend([i] * k)\r\n        curr_p_idx = c_f.safe_random_choice(np.where((ref_labels == label) & (indices != i))[0], k)\r\n        p_idx.extend(curr_p_idx.tolist())\r\n\r\n    return (\r\n        torch.LongTensor(a_idx),\r\n        torch.LongTensor(p_idx),\r\n        torch.LongTensor(n_idx),\r\n    )\r\n\r\n\r\ndef repeat_to_match_size(smaller_set, larger_size, smaller_size):\r\n    num_repeat = math.ceil(float(larger_size) / float(smaller_size))\r\n    return smaller_set.repeat(num_repeat)[:larger_size]\r\n\r\n\r\ndef matched_size_indices(curr_p_idx, curr_n_idx):\r\n    num_pos_pairs = len(curr_p_idx)\r\n    num_neg_pairs = len(curr_n_idx)\r\n    if num_pos_pairs > num_neg_pairs:\r\n        n_idx = repeat_to_match_size(curr_n_idx, num_pos_pairs, num_neg_pairs)\r\n        p_idx = curr_p_idx\r\n    else:\r\n        p_idx = repeat_to_match_size(curr_p_idx, num_neg_pairs, num_pos_pairs)\r\n        n_idx = curr_n_idx\r\n    return p_idx, n_idx\r\n\r\n\r\ndef convert_to_triplets(indices_tuple, labels, t_per_anchor=100):\r\n    """"""\r\n    This returns anchor-positive-negative triplets\r\n    regardless of what the input indices_tuple is\r\n    """"""\r\n    if indices_tuple is None:\r\n        if t_per_anchor == ""all"":\r\n            return get_all_triplets_indices(labels)\r\n        else:\r\n            return get_random_triplet_indices(labels, t_per_anchor=t_per_anchor)\r\n    elif len(indices_tuple) == 3:\r\n        return indices_tuple\r\n    else:\r\n        a_out, p_out, n_out = [], [], []\r\n        a1, p, a2, n = indices_tuple\r\n        empty_output = [torch.tensor([]).to(labels.device)] * 3\r\n        if len(a1) == 0 or len(a2) == 0:\r\n            return empty_output\r\n        for i in range(len(labels)):\r\n            pos_idx = (a1 == i).nonzero().flatten()\r\n            neg_idx = (a2 == i).nonzero().flatten()\r\n            if len(pos_idx) > 0 and len(neg_idx) > 0:\r\n                p_idx = p[pos_idx]\r\n                n_idx = n[neg_idx]\r\n                p_idx, n_idx = matched_size_indices(p_idx, n_idx)\r\n                a_idx = torch.ones_like(c_f.longest_list([p_idx, n_idx])) * i\r\n                a_out.append(a_idx)\r\n                p_out.append(p_idx)\r\n                n_out.append(n_idx)\r\n        try:\r\n            return [torch.cat(x, dim=0) for x in [a_out, p_out, n_out]]\r\n        except RuntimeError:\r\n            # assert that the exception was caused by disjoint a1 and a2\r\n            # otherwise something has gone wrong\r\n            assert len(np.intersect1d(a1, a2)) == 0\r\n            return empty_output\r\n\r\n\r\n\r\ndef convert_to_weights(indices_tuple, labels):\r\n    """"""\r\n    Returns a weight for each batch element, based on\r\n    how many times they appear in indices_tuple.\r\n    """"""\r\n    weights = torch.zeros_like(labels).float()\r\n    if indices_tuple is None:\r\n        return weights + 1\r\n    indices, counts = torch.unique(torch.cat(indices_tuple, dim=0), return_counts=True)\r\n    counts = (counts.float() / torch.sum(counts))\r\n    weights[indices] = counts / torch.max(counts)\r\n    return weights\r\n'"
src/pytorch_metric_learning/utils/loss_tracker.py,0,"b'#! /usr/bin/env python3\n\n\nclass LossTracker:\n    def __init__(self, loss_names):\n        if ""total_loss"" not in loss_names:\n            loss_names.append(""total_loss"")\n        self.losses = {key: 0 for key in loss_names}\n        self.loss_weights = {key: 1 for key in loss_names}\n\n    def weight_the_losses(self, exclude_loss=(""total_loss"")):\n        for k, _ in self.losses.items():\n            if k not in exclude_loss:\n                self.losses[k] *= self.loss_weights[k]\n\n    def get_total_loss(self, exclude_loss=(""total_loss"")):\n        self.losses[""total_loss""] = 0\n        for k, v in self.losses.items():\n            if k not in exclude_loss:\n                self.losses[""total_loss""] += v\n\n    def set_loss_weights(self, loss_weight_dict):\n        for k, _ in self.losses.items():\n            if k in loss_weight_dict:\n                w = loss_weight_dict[k]\n            else:\n                w = 1.0\n            self.loss_weights[k] = w\n\n    def update(self, loss_weight_dict):\n        self.set_loss_weights(loss_weight_dict)\n        self.weight_the_losses()\n        self.get_total_loss()\n'"
src/pytorch_metric_learning/utils/stat_utils.py,0,"b'#! /usr/bin/env python3\nimport sys\nimport logging\ntry:\n    import faiss\nexcept ModuleNotFoundError:\n    logging.warning(""""""The pytorch-metric-learning testing module requires faiss. You can install the GPU version with the command \'conda install faiss-gpu -c pytorch\' \n                        or the CPU version with \'conda install faiss-cpu -c pytorch\'. Learn more at https://github.com/facebookresearch/faiss/blob/master/INSTALL.md"""""")\nimport torch\nimport numpy as np\n\n# modified from https://github.com/facebookresearch/deepcluster\ndef get_knn(\n    reference_embeddings, test_embeddings, k, embeddings_come_from_same_source=False\n):\n    """"""\n    Finds the k elements in reference_embeddings that are closest to each\n    element of test_embeddings.\n    Args:\n        reference_embeddings: numpy array of size (num_samples, dimensionality).\n        test_embeddings: numpy array of size (num_samples2, dimensionality).\n        k: int, number of nearest neighbors to find\n        embeddings_come_from_same_source: if True, then the nearest neighbor of\n                                         each element (which is actually itself)\n                                         will be ignored.\n    Returns:\n        numpy array: indices of nearest k neighbors\n        numpy array: corresponding distances\n    """"""\n    d = reference_embeddings.shape[1]\n    logging.info(""running k-nn with k=%d""%k)\n    logging.info(""embedding dimensionality is %d""%d)\n    index = faiss.IndexFlatL2(d)\n    if faiss.get_num_gpus() > 0:\n        index = faiss.index_cpu_to_all_gpus(index)\n    index.add(reference_embeddings)\n    distances, indices = index.search(test_embeddings, k + 1)\n    if embeddings_come_from_same_source:\n        return indices[:, 1:], distances[:, 1:]\n    return indices[:, :k], distances[:, :k]\n\n\n# modified from https://raw.githubusercontent.com/facebookresearch/deepcluster/\ndef run_kmeans(x, nmb_clusters):\n    """"""\n    Args:\n        x: data\n        nmb_clusters (int): number of clusters\n    Returns:\n        list: ids of data in each cluster\n    """"""\n    n_data, d = x.shape\n    logging.info(""running k-means clustering with k=%d""%nmb_clusters)\n    logging.info(""embedding dimensionality is %d""%d)\n\n    # faiss implementation of k-means\n    clus = faiss.Clustering(d, nmb_clusters)\n    clus.niter = 20\n    clus.max_points_per_centroid = 10000000\n    index = faiss.IndexFlatL2(d)\n    if faiss.get_num_gpus() > 0:\n        index = faiss.index_cpu_to_all_gpus(index)\n    # perform the training\n    clus.train(x, index)\n    _, idxs = index.search(x, 1)\n\n    return [int(n[0]) for n in idxs]\n\n\n# modified from https://github.com/facebookresearch/faiss/wiki/Faiss-building-blocks:-clustering,-PCA,-quantization\ndef run_pca(x, output_dimensionality):\n    mat = faiss.PCAMatrix(x.shape[1], output_dimensionality)\n    mat.train(x)\n    assert mat.is_trained\n    return mat.apply_py(x)'"
