file_path,api_count,code
01-Linear Regression/Linear_Regression.py,6,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\n\nx_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],\n                    [9.779], [6.182], [7.59], [2.167], [7.042],\n                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n\ny_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573],\n                    [3.366], [2.596], [2.53], [1.221], [2.827],\n                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n\n\nx_train = torch.from_numpy(x_train)\n\ny_train = torch.from_numpy(y_train)\n\n\n# Linear Regression Model\nclass linearRegression(nn.Module):\n    def __init__(self):\n        super(linearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)  # input and output is 1 dimension\n\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n\n\nmodel = linearRegression()\n# \xe5\xae\x9a\xe4\xb9\x89loss\xe5\x92\x8c\xe4\xbc\x98\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nnum_epochs = 1000\nfor epoch in range(num_epochs):\n    inputs = x_train\n    target = y_train\n\n    # forward\n    out = model(inputs)\n    loss = criterion(out, target)\n    # backward\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if (epoch+1) % 20 == 0:\n        print(f\'Epoch[{epoch+1}/{num_epochs}], loss: {loss.item():.6f}\')\n\nmodel.eval()\nwith torch.no_grad():\n    predict = model(x_train)\npredict = predict.data.numpy()\n\nfig = plt.figure(figsize=(10, 5))\nplt.plot(x_train.numpy(), y_train.numpy(), \'ro\', label=\'Original data\')\nplt.plot(x_train.numpy(), predict, label=\'Fitting Line\')\n# \xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\xe4\xbe\x8b\nplt.legend() \nplt.show()\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\ntorch.save(model.state_dict(), \'./linear.pth\')\n'"
02-Logistic Regression/Logistic_Regression.py,8,"b'# encoding: utf-8\n""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\n\nimport time\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nbatch_size = 64\nlearning_rate = 1e-3\nnum_epochs = 100\n\n# \xe4\xb8\x8b\xe8\xbd\xbd\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86 MNIST \xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\ntrain_dataset = datasets.FashionMNIST(\n    root=\'../datasets\', train=True, transform=transforms.ToTensor(), download=True)\n\ntest_dataset = datasets.FashionMNIST(\n    root=\'../datasets\', train=False, transform=transforms.ToTensor())\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# \xe5\xae\x9a\xe4\xb9\x89 Logistic Regression \xe6\xa8\xa1\xe5\x9e\x8b\nclass Logistic_Regression(nn.Module):\n    def __init__(self, in_dim, n_class):\n        super(Logistic_Regression, self).__init__()\n        self.logistic = nn.Linear(in_dim, n_class)\n\n    def forward(self, x):\n        out = self.logistic(x)\n        return out\n\n\nmodel = Logistic_Regression(28 * 28, 10)  # \xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\xa7\xe5\xb0\x8f\xe6\x98\xaf28x28\nuse_gpu = torch.cuda.is_available()  # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89GPU\xe5\x8a\xa0\xe9\x80\x9f\nif use_gpu:\n    model = model.cuda()\n# \xe5\xae\x9a\xe4\xb9\x89loss\xe5\x92\x8coptimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nfor epoch in range(num_epochs):\n    print(\'*\' * 10)\n    print(f\'epoch {epoch+1}\')\n    since = time.time()\n    running_loss = 0.0\n    running_acc = 0.0\n    model.train()\n    for i, data in enumerate(train_loader, 1):\n        img, label = data\n        img = img.view(img.size(0), -1)  # \xe5\xb0\x86\xe5\x9b\xbe\xe7\x89\x87\xe5\xb1\x95\xe5\xbc\x80\xe6\x88\x90 28x28\n        if use_gpu:\n            img = img.cuda()\n            label = label.cuda()\n        # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n        out = model(img)\n        loss = criterion(out, label)\n        running_loss += loss.item()\n        _, pred = torch.max(out, 1)\n        running_acc += (pred==label).float().mean()\n        # \xe5\x90\x91\xe5\x90\x8e\xe4\xbc\xa0\xe6\x92\xad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if i % 300 == 0:\n            print(f\'[{epoch+1}/{num_epochs}] Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}\')\n    print(f\'Finish {epoch+1} epoch, Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}\')\n    model.eval()\n    eval_loss = 0.\n    eval_acc = 0.\n    for data in test_loader:\n        img, label = data\n        img = img.view(img.size(0), -1)\n        if use_gpu:\n            img = img.cuda()\n            label = label.cuda()\n        with torch.no_grad():\n            out = model(img)\n            loss = criterion(out, label)\n        eval_loss += loss.item()\n        _, pred = torch.max(out, 1)\n        eval_acc += (pred == label).float().mean()\n    print(f\'Test Loss: {eval_loss/len(test_loader):.6f}, Acc: {eval_acc/len(test_loader):.6f}\')\n    print(f\'Time:{(time.time()-since):.1f} s\')\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\ntorch.save(model.state_dict(), \'./logstic.pth\')\n'"
03-Neural Network/neural_network.py,7,"b'""""""\n@author:  liaoxingyu\n@contact: sherlockliao01@gmail.com\n""""""\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\nbatch_size = 64\nlearning_rate = 1e-2\nnum_epochs = 50\nuse_gpu = torch.cuda.is_available()\n\n# \xe4\xb8\x8b\xe8\xbd\xbd\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86 MNIST \xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\ntrain_dataset = datasets.FashionMNIST(\n    root=\'../datasets\', train=True, transform=transforms.ToTensor(), download=True)\n\ntest_dataset = datasets.FashionMNIST(\n    root=\'../datasets\', train=False, transform=transforms.ToTensor())\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe5\x89\x8d\xe9\xa6\x88\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\nclass neuralNetwork(nn.Module):\n    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n        super(neuralNetwork, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Linear(in_dim, n_hidden_1),\n            nn.ReLU(True))\n        self.layer2 = nn.Sequential(\n            nn.Linear(n_hidden_1, n_hidden_2),\n            nn.ReLU(True))\n        self.layer3 = nn.Sequential(\n            nn.Linear(n_hidden_2, out_dim),\n            nn.ReLU(True))\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        return x\n\nmodel = neuralNetwork(28 * 28, 300, 100, 10)\nif use_gpu:\n    model = model.cuda()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\nfor epoch in range(num_epochs):\n    print(\'*\' * 10)\n    print(f\'epoch {epoch+1}\')\n    running_loss = 0.0\n    running_acc = 0.0\n    for i, data in enumerate(train_loader, 1):\n        img, label = data\n        img = img.view(img.size(0), -1)\n        if use_gpu:\n            img = img.cuda()\n            label = label.cuda()\n        # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n        out = model(img)\n        loss = criterion(out, label)\n        running_loss += loss.item()\n        _, pred = torch.max(out, 1)\n        running_acc += (pred == label).float().mean()\n        # \xe5\x90\x91\xe5\x90\x8e\xe4\xbc\xa0\xe6\x92\xad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if i % 300 == 0:\n            print(f\'[{epoch+1}/{num_epochs}] Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}\')\n    print(f\'Finish {epoch+1} epoch, Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}\')\n    model.eval()\n    eval_loss = 0.\n    eval_acc = 0.\n    for data in test_loader:\n        img, label = data\n        img = img.view(img.size(0), -1)\n        if use_gpu:\n            img = img.cuda()\n            label = label.cuda()\n        with torch.no_grad():\n            out = model(img)\n            loss = criterion(out, label)\n        eval_loss += loss.item()\n        _, pred = torch.max(out, 1)\n        eval_acc += (pred == label).float().mean()\n    print(f\'Test Loss: {eval_loss/len(test_loader):.6f}, Acc: {eval_acc/len(test_loader):.6f}\\n\')\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\ntorch.save(model.state_dict(), \'./neural_network.pth\')\n'"
04-Convolutional Neural Network/convolution_network.py,7,"b""__author__ = 'SherlockLiao'\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision import datasets\nfrom logger import Logger\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nbatch_size = 128\nlearning_rate = 1e-2\nnum_epoches = 20\n\n\ndef to_np(x):\n    return x.cpu().data.numpy()\n\n\n# \xe4\xb8\x8b\xe8\xbd\xbd\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86 MNIST \xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\ntrain_dataset = datasets.MNIST(\n    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n\ntest_dataset = datasets.MNIST(\n    root='./data', train=False, transform=transforms.ToTensor())\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\n# \xe5\xae\x9a\xe4\xb9\x89 Convolution Network \xe6\xa8\xa1\xe5\x9e\x8b\nclass Cnn(nn.Module):\n    def __init__(self, in_dim, n_class):\n        super(Cnn, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_dim, 6, 3, stride=1, padding=1),\n            nn.ReLU(True),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n            nn.ReLU(True), nn.MaxPool2d(2, 2))\n\n        self.fc = nn.Sequential(\n            nn.Linear(400, 120), nn.Linear(120, 84), nn.Linear(84, n_class))\n\n    def forward(self, x):\n        out = self.conv(x)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out\n\n\nmodel = Cnn(1, 10)  # \xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\xa7\xe5\xb0\x8f\xe6\x98\xaf28x28\nuse_gpu = torch.cuda.is_available()  # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89GPU\xe5\x8a\xa0\xe9\x80\x9f\nif use_gpu:\n    model = model.cuda()\n# \xe5\xae\x9a\xe4\xb9\x89loss\xe5\x92\x8coptimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=learning_rate)\nlogger = Logger('./logs')\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nfor epoch in range(num_epoches):\n    print('epoch {}'.format(epoch + 1))\n    print('*' * 10)\n    running_loss = 0.0\n    running_acc = 0.0\n    for i, data in enumerate(train_loader, 1):\n        img, label = data\n        if use_gpu:\n            img = img.cuda()\n            label = label.cuda()\n        img = Variable(img)\n        label = Variable(label)\n        # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n        out = model(img)\n        loss = criterion(out, label)\n        running_loss += loss.data[0] * label.size(0)\n        _, pred = torch.max(out, 1)\n        num_correct = (pred == label).sum()\n        accuracy = (pred == label).float().mean()\n        running_acc += num_correct.data[0]\n        # \xe5\x90\x91\xe5\x90\x8e\xe4\xbc\xa0\xe6\x92\xad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        # ========================= Log ======================\n        step = epoch * len(train_loader) + i\n        # (1) Log the scalar values\n        info = {'loss': loss.data[0], 'accuracy': accuracy.data[0]}\n\n        for tag, value in info.items():\n            logger.scalar_summary(tag, value, step)\n\n        # (2) Log values and gradients of the parameters (histogram)\n        for tag, value in model.named_parameters():\n            tag = tag.replace('.', '/')\n            logger.histo_summary(tag, to_np(value), step)\n            logger.histo_summary(tag + '/grad', to_np(value.grad), step)\n\n        # (3) Log the images\n        info = {'images': to_np(img.view(-1, 28, 28)[:10])}\n\n        for tag, images in info.items():\n            logger.image_summary(tag, images, step)\n        if i % 300 == 0:\n            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n                epoch + 1, num_epoches, running_loss / (batch_size * i),\n                running_acc / (batch_size * i)))\n    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n        epoch + 1, running_loss / (len(train_dataset)), running_acc / (len(\n            train_dataset))))\n    model.eval()\n    eval_loss = 0\n    eval_acc = 0\n    for data in test_loader:\n        img, label = data\n        if use_gpu:\n            img = Variable(img, volatile=True).cuda()\n            label = Variable(label, volatile=True).cuda()\n        else:\n            img = Variable(img, volatile=True)\n            label = Variable(label, volatile=True)\n        out = model(img)\n        loss = criterion(out, label)\n        eval_loss += loss.data[0] * label.size(0)\n        _, pred = torch.max(out, 1)\n        num_correct = (pred == label).sum()\n        eval_acc += num_correct.data[0]\n    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n        test_dataset)), eval_acc / (len(test_dataset))))\n    print()\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\ntorch.save(model.state_dict(), './cnn.pth')\n"""
04-Convolutional Neural Network/logger.py,0,"b'\nimport tensorflow as tf\nimport numpy as np\nimport scipy.misc\ntry:\n    from StringIO import StringIO  # Python 2.7\nexcept ImportError:\n    from io import BytesIO         # Python 3.x\n\n\nclass Logger(object):\n\n    def __init__(self, log_dir):\n        """"""Create a summary writer logging to log_dir.""""""\n        self.writer = tf.summary.FileWriter(log_dir)\n\n    def scalar_summary(self, tag, value, step):\n        """"""Log a scalar variable.""""""\n        summary = tf.Summary(value=[tf.Summary.Value(tag=tag,\n                                                     simple_value=value)])\n        self.writer.add_summary(summary, step)\n\n    def image_summary(self, tag, images, step):\n        """"""Log a list of images.""""""\n\n        img_summaries = []\n        for i, img in enumerate(images):\n            # Write the image to a string\n            try:\n                s = StringIO()\n            except:\n                s = BytesIO()\n            scipy.misc.toimage(img).save(s, format=""png"")\n\n            # Create an Image object\n            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n                                       height=img.shape[0],\n                                       width=img.shape[1])\n            # Create a Summary value\n            img_summaries.append(\n                tf.Summary.Value(tag=\'%s/%d\' % (tag, i), image=img_sum))\n\n        # Create and write Summary\n        summary = tf.Summary(value=img_summaries)\n        self.writer.add_summary(summary, step)\n\n    def histo_summary(self, tag, values, step, bins=1000):\n        """"""Log a histogram of the tensor of values.""""""\n\n        # Create a histogram using numpy\n        counts, bin_edges = np.histogram(values, bins=bins)\n\n        # Fill the fields of the histogram proto\n        hist = tf.HistogramProto()\n        hist.min = float(np.min(values))\n        hist.max = float(np.max(values))\n        hist.num = int(np.prod(values.shape))\n        hist.sum = float(np.sum(values))\n        hist.sum_squares = float(np.sum(values**2))\n\n        # Drop the start of the first bin\n        bin_edges = bin_edges[1:]\n\n        # Add bin edges and counts\n        for edge in bin_edges:\n            hist.bucket_limit.append(edge)\n        for c in counts:\n            hist.bucket.append(c)\n\n        # Create and write Summary\n        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n        self.writer.add_summary(summary, step)\n        self.writer.flush()\n'"
05-Recurrent Neural Network/recurrent_network.py,10,"b""__author__ = 'SherlockLiao'\n\nimport torch\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision import datasets\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nbatch_size = 100\nlearning_rate = 1e-3\nnum_epoches = 20\n\n# \xe4\xb8\x8b\xe8\xbd\xbd\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86 MNIST \xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\ntrain_dataset = datasets.MNIST(\n    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n\ntest_dataset = datasets.MNIST(\n    root='./data', train=False, transform=transforms.ToTensor())\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\n# \xe5\xae\x9a\xe4\xb9\x89 Recurrent Network \xe6\xa8\xa1\xe5\x9e\x8b\nclass Rnn(nn.Module):\n    def __init__(self, in_dim, hidden_dim, n_layer, n_class):\n        super(Rnn, self).__init__()\n        self.n_layer = n_layer\n        self.hidden_dim = hidden_dim\n        self.lstm = nn.LSTM(in_dim, hidden_dim, n_layer, batch_first=True)\n        self.classifier = nn.Linear(hidden_dim, n_class)\n\n    def forward(self, x):\n        # h0 = Variable(torch.zeros(self.n_layer, x.size(1),\n        #   self.hidden_dim)).cuda()\n        # c0 = Variable(torch.zeros(self.n_layer, x.size(1),\n        #   self.hidden_dim)).cuda()\n        out, _ = self.lstm(x)\n        out = out[:, -1, :]\n        out = self.classifier(out)\n        return out\n\n\nmodel = Rnn(28, 128, 2, 10)  # \xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\xa7\xe5\xb0\x8f\xe6\x98\xaf28x28\nuse_gpu = torch.cuda.is_available()  # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89GPU\xe5\x8a\xa0\xe9\x80\x9f\nif use_gpu:\n    model = model.cuda()\n# \xe5\xae\x9a\xe4\xb9\x89loss\xe5\x92\x8coptimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nfor epoch in range(num_epoches):\n    print('epoch {}'.format(epoch + 1))\n    print('*' * 10)\n    running_loss = 0.0\n    running_acc = 0.0\n    for i, data in enumerate(train_loader, 1):\n        img, label = data\n        b, c, h, w = img.size()\n        assert c == 1, 'channel must be 1'\n        img = img.squeeze(1)\n        # img = img.view(b*h, w)\n        # img = torch.transpose(img, 1, 0)\n        # img = img.contiguous().view(w, b, -1)\n        if use_gpu:\n            img = Variable(img).cuda()\n            label = Variable(label).cuda()\n        else:\n            img = Variable(img)\n            label = Variable(label)\n        # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n        out = model(img)\n        loss = criterion(out, label)\n        running_loss += loss.data[0] * label.size(0)\n        _, pred = torch.max(out, 1)\n        num_correct = (pred == label).sum()\n        running_acc += num_correct.data[0]\n        # \xe5\x90\x91\xe5\x90\x8e\xe4\xbc\xa0\xe6\x92\xad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if i % 300 == 0:\n            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n                epoch + 1, num_epoches, running_loss / (batch_size * i),\n                running_acc / (batch_size * i)))\n    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n        epoch + 1, running_loss / (len(train_dataset)), running_acc / (len(\n            train_dataset))))\n    model.eval()\n    eval_loss = 0.\n    eval_acc = 0.\n    for data in test_loader:\n        img, label = data\n        b, c, h, w = img.size()\n        assert c == 1, 'channel must be 1'\n        img = img.squeeze(1)\n        # img = img.view(b*h, w)\n        # img = torch.transpose(img, 1, 0)\n        # img = img.contiguous().view(w, b, h)\n        if use_gpu:\n            img = Variable(img, volatile=True).cuda()\n            label = Variable(label, volatile=True).cuda()\n        else:\n            img = Variable(img, volatile=True)\n            label = Variable(label, volatile=True)\n        out = model(img)\n        loss = criterion(out, label)\n        eval_loss += loss.data[0] * label.size(0)\n        _, pred = torch.max(out, 1)\n        num_correct = (pred == label).sum()\n        eval_acc += num_correct.data[0]\n    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n        test_dataset)), eval_acc / (len(test_dataset))))\n    print()\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\ntorch.save(model.state_dict(), './rnn.pth')\n"""
06-Natural Language Process/N-Gram.py,6,"b'import torch\nimport torch.nn.functional as F\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\nCONTEXT_SIZE = 2\nEMBEDDING_DIM = 10\n# We will use Shakespeare Sonnet 2\ntest_sentence = """"""When forty winters shall besiege thy brow,\nAnd dig deep trenches in thy beauty\'s field,\nThy youth\'s proud livery so gazed on now,\nWill be a totter\'d weed of small worth held:\nThen being asked, where all thy beauty lies,\nWhere all the treasure of thy lusty days;\nTo say, within thine own deep sunken eyes,\nWere an all-eating shame, and thriftless praise.\nHow much more praise deserv\'d thy beauty\'s use,\nIf thou couldst answer \'This fair child of mine\nShall sum my count, and make my old excuse,\'\nProving his beauty by succession thine!\nThis were to be new made when thou art old,\nAnd see thy blood warm when thou feel\'st it cold."""""".split()\n\ntrigram = [((test_sentence[i], test_sentence[i + 1]), test_sentence[i + 2])\n           for i in range(len(test_sentence) - 2)]\n\nvocb = set(test_sentence)\nword_to_idx = {word: i for i, word in enumerate(vocb)}\nidx_to_word = {word_to_idx[word]: word for word in word_to_idx}\n\n\nclass NgramModel(nn.Module):\n    def __init__(self, vocb_size, context_size, n_dim):\n        super(NgramModel, self).__init__()\n        self.n_word = vocb_size\n        self.embedding = nn.Embedding(self.n_word, n_dim)\n        self.linear1 = nn.Linear(context_size * n_dim, 128)\n        self.linear2 = nn.Linear(128, self.n_word)\n\n    def forward(self, x):\n        emb = self.embedding(x)\n        emb = emb.view(1, -1)\n        out = self.linear1(emb)\n        out = F.relu(out)\n        out = self.linear2(out)\n        log_prob = F.log_softmax(out)\n        return log_prob\n\n\nngrammodel = NgramModel(len(word_to_idx), CONTEXT_SIZE, 100)\ncriterion = nn.NLLLoss()\noptimizer = optim.SGD(ngrammodel.parameters(), lr=1e-3)\n\nfor epoch in range(100):\n    print(\'epoch: {}\'.format(epoch + 1))\n    print(\'*\' * 10)\n    running_loss = 0\n    for data in trigram:\n        word, label = data\n        word = Variable(torch.LongTensor([word_to_idx[i] for i in word]))\n        label = Variable(torch.LongTensor([word_to_idx[label]]))\n        # forward\n        out = ngrammodel(word)\n        loss = criterion(out, label)\n        running_loss += loss.data[0]\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(\'Loss: {:.6f}\'.format(running_loss / len(word_to_idx)))\n\nword, label = trigram[3]\nword = Variable(torch.LongTensor([word_to_idx[i] for i in word]))\nout = ngrammodel(word)\n_, predict_label = torch.max(out, 1)\npredict_word = idx_to_word[predict_label.data[0][0]]\nprint(\'real word is {}, predict word is {}\'.format(label, predict_word))\n'"
06-Natural Language Process/bag-of-word.py,7,"b'__author__ = \'SherlockLiao\'\n\nimport torch\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\n# The Continuous Bag-of-Words model (CBOW) is frequently used in NLP deep learning. It is a model that tries to predict words given the context of a few words before and a few words after the target word. This is distinct from language modeling, since CBOW is not sequential and does not have to be probabilistic. Typcially, CBOW is used to quickly train word embeddings, and these embeddings are used to initialize the embeddings of some more complicated model. Usually, this is referred to as pretraining embeddings. It almost always helps performance a couple of percent.\n\nCONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\nraw_text = """"""We are about to study the idea of a computational process.\nComputational processes are abstract beings that inhabit computers.\nAs they evolve, processes manipulate other abstract things called data.\nThe evolution of a process is directed by a pattern of rules\ncalled a program. People create programs to direct processes. In effect,\nwe conjure the spirits of the computer with our spells."""""".split()\n\nvocab = set(raw_text)\nword_to_idx = {word: i for i, word in enumerate(vocab)}\n\ndata = []\nfor i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n    context = [\n        raw_text[i - 2], raw_text[i - 1], raw_text[i + 1], raw_text[i + 2]\n    ]\n    target = raw_text[i]\n    data.append((context, target))\n\n\nclass CBOW(nn.Module):\n    def __init__(self, n_word, n_dim, context_size):\n        super(CBOW, self).__init__()\n        self.embedding = nn.Embedding(n_word, n_dim)\n        self.project = nn.Linear(n_dim, n_dim, bias=False)\n        self.linear1 = nn.Linear(n_dim, 128)\n        self.linear2 = nn.Linear(128, n_word)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.project(x)\n        x = torch.sum(x, 0, keepdim=True)\n        x = self.linear1(x)\n        x = F.relu(x, inplace=True)\n        x = self.linear2(x)\n        x = F.log_softmax(x)\n        return x\n\n\nmodel = CBOW(len(word_to_idx), 100, CONTEXT_SIZE)\nif torch.cuda.is_available():\n    model = model.cuda()\n\ncriterion = nn.NLLLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\n\nfor epoch in range(100):\n    print(\'epoch {}\'.format(epoch))\n    print(\'*\' * 10)\n    running_loss = 0\n    for word in data:\n        context, target = word\n        context = Variable(torch.LongTensor([word_to_idx[i] for i in context]))\n        target = Variable(torch.LongTensor([word_to_idx[target]]))\n        if torch.cuda.is_available():\n            context = context.cuda()\n            target = target.cuda()\n        # forward\n        out = model(context)\n        loss = criterion(out, target)\n        running_loss += loss.data[0]\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(\'loss: {:.6f}\'.format(running_loss / len(data)))\n'"
06-Natural Language Process/seq-lstm.py,12,"b'__author__ = \'SherlockLiao\'\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\ntraining_data = [(""The dog ate the apple"".split(),\n                  [""DET"", ""NN"", ""V"", ""DET"", ""NN""]),\n                 (""Everybody read that book"".split(), [""NN"", ""V"", ""DET"",\n                                                       ""NN""])]\n\nword_to_idx = {}\ntag_to_idx = {}\nfor context, tag in training_data:\n    for word in context:\n        if word not in word_to_idx:\n            word_to_idx[word] = len(word_to_idx)\n    for label in tag:\n        if label not in tag_to_idx:\n            tag_to_idx[label] = len(tag_to_idx)\nalphabet = \'abcdefghijklmnopqrstuvwxyz\'\ncharacter_to_idx = {}\nfor i in range(len(alphabet)):\n    character_to_idx[alphabet[i]] = i\n\n\nclass CharLSTM(nn.Module):\n    def __init__(self, n_char, char_dim, char_hidden):\n        super(CharLSTM, self).__init__()\n        self.char_embedding = nn.Embedding(n_char, char_dim)\n        self.char_lstm = nn.LSTM(char_dim, char_hidden, batch_first=True)\n\n    def forward(self, x):\n        x = self.char_embedding(x)\n        _, h = self.char_lstm(x)\n        return h[0]\n\n\nclass LSTMTagger(nn.Module):\n    def __init__(self, n_word, n_char, char_dim, n_dim, char_hidden, n_hidden,\n                 n_tag):\n        super(LSTMTagger, self).__init__()\n        self.word_embedding = nn.Embedding(n_word, n_dim)\n        self.char_lstm = CharLSTM(n_char, char_dim, char_hidden)\n        self.lstm = nn.LSTM(n_dim + char_hidden, n_hidden, batch_first=True)\n        self.linear1 = nn.Linear(n_hidden, n_tag)\n\n    def forward(self, x, word):\n        char = torch.FloatTensor()\n        for each in word:\n            char_list = []\n            for letter in each:\n                char_list.append(character_to_idx[letter.lower()])\n            char_list = torch.LongTensor(char_list)\n            char_list = char_list.unsqueeze(0)\n            if torch.cuda.is_available():\n                tempchar = self.char_lstm(Variable(char_list).cuda())\n            else:\n                tempchar = self.char_lstm(Variable(char_list))\n            tempchar = tempchar.squeeze(0)\n            char = torch.cat((char, tempchar.cpu().data), 0)\n        if torch.cuda.is_available():\n            char = char.cuda()\n        char = Variable(char)\n        x = self.word_embedding(x)\n        x = torch.cat((x, char), 1)\n        x = x.unsqueeze(0)\n        x, _ = self.lstm(x)\n        x = x.squeeze(0)\n        x = self.linear1(x)\n        y = F.log_softmax(x)\n        return y\n\n\nmodel = LSTMTagger(\n    len(word_to_idx), len(character_to_idx), 10, 100, 50, 128, len(tag_to_idx))\nif torch.cuda.is_available():\n    model = model.cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-2)\n\n\ndef make_sequence(x, dic):\n    idx = [dic[i] for i in x]\n    idx = Variable(torch.LongTensor(idx))\n    return idx\n\n\nfor epoch in range(300):\n    print(\'*\' * 10)\n    print(\'epoch {}\'.format(epoch + 1))\n    running_loss = 0\n    for data in training_data:\n        word, tag = data\n        word_list = make_sequence(word, word_to_idx)\n        tag = make_sequence(tag, tag_to_idx)\n        if torch.cuda.is_available():\n            word_list = word_list.cuda()\n            tag = tag.cuda()\n        # forward\n        out = model(word_list, word)\n        loss = criterion(out, tag)\n        running_loss += loss.data[0]\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(\'Loss: {}\'.format(running_loss / len(data)))\nprint()\ninput = make_sequence(""Everybody ate the apple"".split(), word_to_idx)\nif torch.cuda.is_available():\n    input = input.cuda()\n\nout = model(input, ""Everybody ate the apple"".split())\nprint(out)\n'"
07-Language Model/data_utils.py,1,"b""__author__ = 'SherlockLiao'\n\nimport os\nimport torch\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word_to_idx = {}\n        self.idx_to_word = {}\n\n    def add_word(self, word_list):\n        for word in word_list:\n            if word not in self.word_to_idx:\n                self.word_to_idx[word] = len(self.word_to_idx)\n                self.idx_to_word[len(self.word_to_idx)-1] = word\n\n    def __len__(self):\n        return len(self.word_to_idx)\n\n\nclass Corpus(object):\n    def __init__(self, path='./data'):\n        self.dic = Dictionary()\n        self.train = os.path.join(path, 'train.txt')\n        self.valid = os.path.join(path, 'valid.txt')\n        self.test = os.path.join(path, 'test.txt')\n        self.path = path\n\n    def get_data(self, file, batch_size=20):\n        file = os.path.join(self.path, file)\n        # get the word dictionary\n        with open(file, 'r') as f:\n            num_word = 0\n            for line in f:\n                word_list = line.split() + ['<eos>']\n                num_word += len(word_list)\n                self.dic.add_word(word_list)\n\n        token = torch.LongTensor(num_word)\n        # get the whole sentence corpus\n        with open(file, 'r') as f:\n            index = 0\n            for line in f:\n                word_list = line.split() + ['<eos>']\n                for word in word_list:\n                    token[index] = self.dic.word_to_idx[word]\n                    index += 1\n        num_batch = index // batch_size\n        token = token[: num_batch*batch_size]\n        token = token.view(batch_size, -1)\n        return token\n"""
07-Language Model/language model.py,6,"b""__author__ = 'SherlockLiao'\n\nimport torch\nfrom torch.autograd import Variable\nfrom torch import nn, optim\nfrom data_utils import Corpus\n\nseq_length = 30\n\ntrain_file = 'train.txt'\nvalid_file = 'valid.txt'\ntest_file = 'test.txt'\ntrain_corpus = Corpus()\nvalid_corpus = Corpus()\ntest_corpus = Corpus()\n\ntrain_id = train_corpus.get_data(train_file)\nvalid_id = valid_corpus.get_data(valid_file)\ntest_id = test_corpus.get_data(test_file)\n\nvocab_size = len(train_corpus.dic)\nnum_batches = train_id.size(1) // seq_length\n\n\nclass languagemodel(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers):\n        super(languagemodel, self).__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers,\n                            batch_first=True)\n        self.linear = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x, h):\n        x = self.embed(x)\n        x, hi = self.lstm(x, h)\n        b, s, h = x.size()\n        x = x.contiguous().view(b*s, h)\n        x = self.linear(x)\n        return x, hi\n\n\nmodel = languagemodel(vocab_size, 128, 1024, 1)\nif torch.cuda.is_available():\n    model = model.cuda()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n\ndef detach(states):\n    return [Variable(state.data).cuda() for state in states]\n\n\nfor epoch in range(5):\n    print('epoch {}'.format(epoch+1))\n    print('*'*10)\n    running_loss = 0\n    states = (Variable(torch.zeros(1,\n                                   20,\n                                   1024)).cuda(),\n              Variable(torch.zeros(1,\n                                   20,\n                                   1024)).cuda())\n\n    for i in range(0, train_id.size(1)-2*seq_length, seq_length):\n        input_x = train_id[:, i:(i+seq_length)]\n        label = train_id[:, (i+seq_length):(i+2*seq_length)]\n        if torch.cuda.is_available():\n            input_x = Variable(input_x).cuda()\n            label = Variable(label).cuda()\n            label = label.view(label.size(0)*label.size(1), 1)\n        else:\n            input_x = Variabel(input_x)\n            label = Variable(label)\n            label = label.view(label.size(0)*label.size(1), 1)\n        # forward\n        states = detach(states)\n        out, states = model(input_x, states)\n        loss = criterion(out, label.view(-1))\n        running_loss += loss.data[0]\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n        optimizer.step()\n\n        step = (i+1) // seq_length\n        if step % 100 == 0:\n            print('Epoch [{}/{}], Step[{}/{}], Loss: {}'\n                  .format(epoch+1, 5, step, num_batches, loss.data[0]))\n    print('Loss: {}'.format(running_loss))\n"""
08-AutoEncoder/Variational_autoencoder.py,10,"b'__author__ = \'SherlockLiao\'\n\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torchvision.datasets import MNIST\nimport os\n\nif not os.path.exists(\'./vae_img\'):\n    os.mkdir(\'./vae_img\')\n\n\ndef to_img(x):\n    x = x.clamp(0, 1)\n    x = x.view(x.size(0), 1, 28, 28)\n    return x\n\n\nnum_epochs = 100\nbatch_size = 128\nlearning_rate = 1e-3\n\nimg_transform = transforms.Compose([\n    transforms.ToTensor()\n    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ndataset = MNIST(\'./data\', transform=img_transform, download=True)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n\nclass VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n\n        self.fc1 = nn.Linear(784, 400)\n        self.fc21 = nn.Linear(400, 20)\n        self.fc22 = nn.Linear(400, 20)\n        self.fc3 = nn.Linear(20, 400)\n        self.fc4 = nn.Linear(400, 784)\n\n    def encode(self, x):\n        h1 = F.relu(self.fc1(x))\n        return self.fc21(h1), self.fc22(h1)\n\n    def reparametrize(self, mu, logvar):\n        std = logvar.mul(0.5).exp_()\n        if torch.cuda.is_available():\n            eps = torch.cuda.FloatTensor(std.size()).normal_()\n        else:\n            eps = torch.FloatTensor(std.size()).normal_()\n        eps = Variable(eps)\n        return eps.mul(std).add_(mu)\n\n    def decode(self, z):\n        h3 = F.relu(self.fc3(z))\n        return F.sigmoid(self.fc4(h3))\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparametrize(mu, logvar)\n        return self.decode(z), mu, logvar\n\n\nmodel = VAE()\nif torch.cuda.is_available():\n    model.cuda()\n\nreconstruction_function = nn.MSELoss(size_average=False)\n\n\ndef loss_function(recon_x, x, mu, logvar):\n    """"""\n    recon_x: generating images\n    x: origin images\n    mu: latent mean\n    logvar: latent log variance\n    """"""\n    BCE = reconstruction_function(recon_x, x)  # mse loss\n    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n    KLD = torch.sum(KLD_element).mul_(-0.5)\n    # KL divergence\n    return BCE + KLD\n\n\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    for batch_idx, data in enumerate(dataloader):\n        img, _ = data\n        img = img.view(img.size(0), -1)\n        img = Variable(img)\n        if torch.cuda.is_available():\n            img = img.cuda()\n        optimizer.zero_grad()\n        recon_batch, mu, logvar = model(img)\n        loss = loss_function(recon_batch, img, mu, logvar)\n        loss.backward()\n        train_loss += loss.data[0]\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch,\n                batch_idx * len(img),\n                len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n                loss.data[0] / len(img)))\n\n    print(\'====> Epoch: {} Average loss: {:.4f}\'.format(\n        epoch, train_loss / len(dataloader.dataset)))\n    if epoch % 10 == 0:\n        save = to_img(recon_batch.cpu().data)\n        save_image(save, \'./vae_img/image_{}.png\'.format(epoch))\n\ntorch.save(model.state_dict(), \'./vae.pth\')\n'"
08-AutoEncoder/conv_autoencoder.py,4,"b""__author__ = 'SherlockLiao'\n\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torchvision.datasets import MNIST\nimport os\n\nif not os.path.exists('./dc_img'):\n    os.mkdir('./dc_img')\n\n\ndef to_img(x):\n    x = 0.5 * (x + 1)\n    x = x.clamp(0, 1)\n    x = x.view(x.size(0), 1, 28, 28)\n    return x\n\n\nnum_epochs = 100\nbatch_size = 128\nlearning_rate = 1e-3\n\nimg_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ndataset = MNIST('./data', transform=img_transform)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n\nclass autoencoder(nn.Module):\n    def __init__(self):\n        super(autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n            nn.ReLU(True),\n            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n            nn.ReLU(True),\n            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\n\nmodel = autoencoder().cuda()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n                             weight_decay=1e-5)\n\nfor epoch in range(num_epochs):\n    for data in dataloader:\n        img, _ = data\n        img = Variable(img).cuda()\n        # ===================forward=====================\n        output = model(img)\n        loss = criterion(output, img)\n        # ===================backward====================\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # ===================log========================\n    print('epoch [{}/{}], loss:{:.4f}'\n          .format(epoch+1, num_epochs, loss.data[0]))\n    if epoch % 10 == 0:\n        pic = to_img(output.cpu().data)\n        save_image(pic, './dc_img/image_{}.png'.format(epoch))\n\ntorch.save(model.state_dict(), './conv_autoencoder.pth')\n"""
08-AutoEncoder/simple_autoencoder.py,4,"b""__author__ = 'SherlockLiao'\n\nimport os\n\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import save_image\n\nif not os.path.exists('./mlp_img'):\n    os.mkdir('./mlp_img')\n\n\ndef to_img(x):\n    x = 0.5 * (x + 1)\n    x = x.clamp(0, 1)\n    x = x.view(x.size(0), 1, 28, 28)\n    return x\n\n\nnum_epochs = 100\nbatch_size = 128\nlearning_rate = 1e-3\n\nimg_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ndataset = MNIST('./data', transform=img_transform)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n\nclass autoencoder(nn.Module):\n    def __init__(self):\n        super(autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(28 * 28, 128),\n            nn.ReLU(True),\n            nn.Linear(128, 64),\n            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n        self.decoder = nn.Sequential(\n            nn.Linear(3, 12),\n            nn.ReLU(True),\n            nn.Linear(12, 64),\n            nn.ReLU(True),\n            nn.Linear(64, 128),\n            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\n\nmodel = autoencoder().cuda()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(\n    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n\nfor epoch in range(num_epochs):\n    for data in dataloader:\n        img, _ = data\n        img = img.view(img.size(0), -1)\n        img = Variable(img).cuda()\n        # ===================forward=====================\n        output = model(img)\n        loss = criterion(output, img)\n        # ===================backward====================\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # ===================log========================\n    print('epoch [{}/{}], loss:{:.4f}'\n          .format(epoch + 1, num_epochs, loss.data[0]))\n    if epoch % 10 == 0:\n        pic = to_img(output.cpu().data)\n        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n\ntorch.save(model.state_dict(), './sim_autoencoder.pth')\n"""
09-Generative Adversarial network/conv_gan.py,11,"b""__author__ = 'ShelockLiao'\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision import datasets\nfrom torchvision.utils import save_image\nimport os\n\nif not os.path.exists('./dc_img'):\n    os.mkdir('./dc_img')\n\n\ndef to_img(x):\n    out = 0.5 * (x + 1)\n    out = out.clamp(0, 1)\n    out = out.view(-1, 1, 28, 28)\n    return out\n\n\nbatch_size = 128\nnum_epoch = 100\nz_dimension = 100  # noise dimension\n\nimg_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\nmnist = datasets.MNIST('./data', transform=img_transform)\ndataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True,\n                        num_workers=4)\n\n\nclass discriminator(nn.Module):\n    def __init__(self):\n        super(discriminator, self).__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, 32, 5, padding=2),  # batch, 32, 28, 28\n            nn.LeakyReLU(0.2, True),\n            nn.AvgPool2d(2, stride=2),  # batch, 32, 14, 14\n            )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(32, 64, 5, padding=2),  # batch, 64, 14, 14\n            nn.LeakyReLU(0.2, True),\n            nn.AvgPool2d(2, stride=2)  # batch, 64, 7, 7\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(64*7*7, 1024),\n            nn.LeakyReLU(0.2, True),\n            nn.Linear(1024, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        '''\n        x: batch, width, height, channel=1\n        '''\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\nclass generator(nn.Module):\n    def __init__(self, input_size, num_feature):\n        super(generator, self).__init__()\n        self.fc = nn.Linear(input_size, num_feature)  # batch, 3136=1x56x56\n        self.br = nn.Sequential(\n            nn.BatchNorm2d(1),\n            nn.ReLU(True)\n        )\n        self.downsample1 = nn.Sequential(\n            nn.Conv2d(1, 50, 3, stride=1, padding=1),  # batch, 50, 56, 56\n            nn.BatchNorm2d(50),\n            nn.ReLU(True)\n        )\n        self.downsample2 = nn.Sequential(\n            nn.Conv2d(50, 25, 3, stride=1, padding=1),  # batch, 25, 56, 56\n            nn.BatchNorm2d(25),\n            nn.ReLU(True)\n        )\n        self.downsample3 = nn.Sequential(\n            nn.Conv2d(25, 1, 2, stride=2),  # batch, 1, 28, 28\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        x = x.view(x.size(0), 1, 56, 56)\n        x = self.br(x)\n        x = self.downsample1(x)\n        x = self.downsample2(x)\n        x = self.downsample3(x)\n        return x\n\n\nD = discriminator().cuda()  # discriminator model\nG = generator(z_dimension, 3136).cuda()  # generator model\n\ncriterion = nn.BCELoss()  # binary cross entropy\n\nd_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\ng_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)\n\n# train\nfor epoch in range(num_epoch):\n    for i, (img, _) in enumerate(dataloader):\n        num_img = img.size(0)\n        # =================train discriminator\n        real_img = Variable(img).cuda()\n        real_label = Variable(torch.ones(num_img)).cuda()\n        fake_label = Variable(torch.zeros(num_img)).cuda()\n\n        # compute loss of real_img\n        real_out = D(real_img)\n        d_loss_real = criterion(real_out, real_label)\n        real_scores = real_out  # closer to 1 means better\n\n        # compute loss of fake_img\n        z = Variable(torch.randn(num_img, z_dimension)).cuda()\n        fake_img = G(z)\n        fake_out = D(fake_img)\n        d_loss_fake = criterion(fake_out, fake_label)\n        fake_scores = fake_out  # closer to 0 means better\n\n        # bp and optimize\n        d_loss = d_loss_real + d_loss_fake\n        d_optimizer.zero_grad()\n        d_loss.backward()\n        d_optimizer.step()\n\n        # ===============train generator\n        # compute loss of fake_img\n        z = Variable(torch.randn(num_img, z_dimension)).cuda()\n        fake_img = G(z)\n        output = D(fake_img)\n        g_loss = criterion(output, real_label)\n\n        # bp and optimize\n        g_optimizer.zero_grad()\n        g_loss.backward()\n        g_optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print('Epoch [{}/{}], d_loss: {:.6f}, g_loss: {:.6f} '\n                  'D real: {:.6f}, D fake: {:.6f}'\n                  .format(epoch, num_epoch, d_loss.data[0], g_loss.data[0],\n                          real_scores.data.mean(), fake_scores.data.mean()))\n    if epoch == 0:\n        real_images = to_img(real_img.cpu().data)\n        save_image(real_images, './dc_img/real_images.png')\n\n    fake_images = to_img(fake_img.cpu().data)\n    save_image(fake_images, './dc_img/fake_images-{}.png'.format(epoch+1))\n\ntorch.save(G.state_dict(), './generator.pth')\ntorch.save(D.state_dict(), './discriminator.pth')\n"""
09-Generative Adversarial network/simple_Gan.py,13,"b""import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torch.autograd import Variable\nimport os\n\nif not os.path.exists('./img'):\n    os.mkdir('./img')\n\n\ndef to_img(x):\n    out = 0.5 * (x + 1)\n    out = out.clamp(0, 1)\n    out = out.view(-1, 1, 28, 28)\n    return out\n\n\nbatch_size = 128\nnum_epoch = 100\nz_dimension = 100\n\n# Image processing\nimg_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n])\n# MNIST dataset\nmnist = datasets.MNIST(\n    root='./data/', train=True, transform=img_transform, download=True)\n# Data loader\ndataloader = torch.utils.data.DataLoader(\n    dataset=mnist, batch_size=batch_size, shuffle=True)\n\n\n# Discriminator\nclass discriminator(nn.Module):\n    def __init__(self):\n        super(discriminator, self).__init__()\n        self.dis = nn.Sequential(\n            nn.Linear(784, 256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 256),\n            nn.LeakyReLU(0.2), nn.Linear(256, 1), nn.Sigmoid())\n\n    def forward(self, x):\n        x = self.dis(x)\n        return x\n\n\n# Generator\nclass generator(nn.Module):\n    def __init__(self):\n        super(generator, self).__init__()\n        self.gen = nn.Sequential(\n            nn.Linear(100, 256),\n            nn.ReLU(True),\n            nn.Linear(256, 256), nn.ReLU(True), nn.Linear(256, 784), nn.Tanh())\n\n    def forward(self, x):\n        x = self.gen(x)\n        return x\n\n\nD = discriminator()\nG = generator()\nif torch.cuda.is_available():\n    D = D.cuda()\n    G = G.cuda()\n# Binary cross entropy loss and optimizer\ncriterion = nn.BCELoss()\nd_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\ng_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)\n\n# Start training\nfor epoch in range(num_epoch):\n    for i, (img, _) in enumerate(dataloader):\n        num_img = img.size(0)\n        # =================train discriminator\n        img = img.view(num_img, -1)\n        real_img = Variable(img).cuda()\n        real_label = Variable(torch.ones(num_img)).cuda()\n        fake_label = Variable(torch.zeros(num_img)).cuda()\n\n        # compute loss of real_img\n        real_out = D(real_img)\n        d_loss_real = criterion(real_out, real_label)\n        real_scores = real_out  # closer to 1 means better\n\n        # compute loss of fake_img\n        z = Variable(torch.randn(num_img, z_dimension)).cuda()\n        fake_img = G(z)\n        fake_out = D(fake_img)\n        d_loss_fake = criterion(fake_out, fake_label)\n        fake_scores = fake_out  # closer to 0 means better\n\n        # bp and optimize\n        d_loss = d_loss_real + d_loss_fake\n        d_optimizer.zero_grad()\n        d_loss.backward()\n        d_optimizer.step()\n\n        # ===============train generator\n        # compute loss of fake_img\n        z = Variable(torch.randn(num_img, z_dimension)).cuda()\n        fake_img = G(z)\n        output = D(fake_img)\n        g_loss = criterion(output, real_label)\n\n        # bp and optimize\n        g_optimizer.zero_grad()\n        g_loss.backward()\n        g_optimizer.step()\n\n        if (i + 1) % 100 == 0:\n            print('Epoch [{}/{}], d_loss: {:.6f}, g_loss: {:.6f} '\n                  'D real: {:.6f}, D fake: {:.6f}'.format(\n                      epoch, num_epoch, d_loss.data[0], g_loss.data[0],\n                      real_scores.data.mean(), fake_scores.data.mean()))\n    if epoch == 0:\n        real_images = to_img(real_img.cpu().data)\n        save_image(real_images, './img/real_images.png')\n\n    fake_images = to_img(fake_img.cpu().data)\n    save_image(fake_images, './img/fake_images-{}.png'.format(epoch + 1))\n\ntorch.save(G.state_dict(), './generator.pth')\ntorch.save(D.state_dict(), './discriminator.pth')\n"""
10-Deep Q learning/reinforcement learning.py,15,"b'import gym\nimport math\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import namedtuple\nfrom itertools import count\nfrom copy import deepcopy\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torchvision import transforms\n\nenv = gym.make(\'CartPole-v0\').unwrapped\n\nuse_cuda = torch.cuda.is_available()\nFloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\nLongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\nByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n\nTransition = namedtuple(\'Transition\',\n                        (\'state\', \'action\', \'next_state\', \'reward\'))\n\n\nclass ReplayMemory(object):\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.memory = []\n        self.position = 0\n\n    def push(self, *args):\n        """"""Save a transition""""""\n        if len(self.memory) < self.capacity:\n            self.memory.append(None)\n        self.memory[self.position] = Transition(*args)\n        self.position = (self.position + 1) % self.capacity\n\n    def sample(self, batch_size):\n        return random.sample(self.memory, batch_size)\n\n    def __len__(self):\n        return len(self.memory)\n\n\nclass DQN(nn.Module):\n    def __init__(self):\n        super(DQN, self).__init__()\n        self.conv_bn1 = nn.Sequential(\n            nn.Conv2d(3, 16, 5, stride=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(True)\n        )\n        self.conv_bn2 = nn.Sequential(\n            nn.Conv2d(16, 32, 5, stride=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True)\n        )\n        self.conv_bn3 = nn.Sequential(\n            nn.Conv2d(32, 32, 5, stride=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True)\n        )\n        self.move = nn.Linear(448, 2)\n\n    def forward(self, x):\n        x = self.conv_bn1(x)\n        x = self.conv_bn2(x)\n        x = self.conv_bn3(x)\n        x = x.view(x.size(0), -1)\n        x = self.move(x)\n        return x\n\n\nresize_img = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Scale(40, interpolation=Image.CUBIC),\n    transforms.ToTensor()\n    ])\n\nscreen_width = 600  # this is default parameter in gym\n\n\ndef get_cart_location():\n    world_width = env.x_threshold * 2\n    scale = screen_width / world_width\n    return int(env.state[0] * scale + screen_width / 2.0)\n\n\ndef get_screen():\n    screen = env.render(mode=\'rgb_array\').transpose((2, 0, 1))\n    screen = screen[:, 160:320]\n    view_width = 320\n    cart_location = get_cart_location()\n    if cart_location < view_width // 2:\n        slice_range = slice(view_width)\n    elif cart_location > (screen_width - view_width // 2):\n        slice_range = slice(-view_width, None)\n    else:\n        slice_range = slice(cart_location - view_width // 2,\n                            cart_location + view_width // 2)\n\n    screen = screen[:, :, slice_range]\n    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n    screen = torch.from_numpy(screen)\n    return resize_img(screen).unsqueeze(0).type(FloatTensor)\n\n\nenv.reset()\nplt.figure()\nplt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n           interpolation=\'none\')\nplt.title(\'Example extracted screen\')\nplt.show()\n\nBATCH_SIZE = 128\nGAMMA = 0.999\nEPS_START = 0.9\nEPS_END = 0.05\nEPS_DECAY = 200\n\nmodel = DQN()\n\nif use_cuda:\n    model.cuda()\n\noptimizer = optim.RMSprop(model.parameters())\nmemory = ReplayMemory(10000)\n\nsteps_done = 0\n\n\ndef select_action(state):\n    global steps_done\n    sample = random.random()\n    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n        math.exp(-1 * steps_done / EPS_DECAY)\n    steps_done += 1\n    if sample > eps_threshold:\n        return model(\n            Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1]\n    else:\n        return LongTensor([[random.randrange(2)]])\n\n\nepisode_durations = []\n\n\ndef plot_durations():\n    plt.figure(2)\n    plt.clf()\n    durations_t = torch.FloatTensor(episode_durations)\n    plt.title(\'Training...\')\n    plt.xlabel(\'Episode\')\n    plt.ylabel(\'Duration\')\n    plt.plot(durations_t.numpy())\n\n    if len(durations_t) >= 100:\n        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n        plt.plot(means.numpy())\n\n    plt.pause(0.001)\n\n\nlast_sync = 0\n\n\ndef optimize_model():\n    global last_sync\n    if len(memory) < BATCH_SIZE:\n        return\n    transitions = memory.sample(BATCH_SIZE)\n    batch = Transition(*zip(*transitions))\n\n    non_final_mask = ByteTensor(tuple(map(lambda s: s is not None,\n                                          batch.next_state)))\n    non_final_next_states = Variable(torch.cat([s for s in batch.next_state\n                                                if s is not None]),\n                                     volatile=True)\n    state_batch = Variable(torch.cat(batch.state))\n    action_batch = Variable(torch.cat(batch.action))\n    reward_batch = Variable(torch.cat(batch.reward))\n\n    state_action_values = model(state_batch).gather(1, action_batch)\n\n    next_state_values = Variable(torch.zeros(BATCH_SIZE)).type(FloatTensor)\n    next_state_values[non_final_mask] = model(non_final_next_states).max(1)[0]\n\n    # next_state_values.volatile = False\n\n    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n\n    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n\n    optimizer.zero_grad()\n    loss.backward()\n    for param in model.parameters():\n        param.grad.data.clamp_(-1, 1)\n    optimizer.step()\n\n\nnum_episodes = 100\nfor i_episode in range(num_episodes):\n    env.reset()\n    last_screen = get_screen()\n    current_screen = get_screen()\n    state = current_screen - last_screen\n    for t in count():\n        action = select_action(state)\n        _, reward, done, _ = env.step(action[0, 0])\n        reward = FloatTensor([reward])\n\n        last_screen = current_screen\n        current_screen = get_screen()\n        if not done:\n            next_state = current_screen - last_screen\n        else:\n            next_state = None\n\n        memory.push(state, action, next_state, reward)\n\n        state = next_state\n\n        optimize_model()\n        if done:\n            episode_durations.append(t + 1)\n            plot_durations()\n            break\n\nprint(\'Complete\')\nenv.render(close=True)\nenv.close()\nplt.ioff()\nplt.show()\n'"
11-backward/backward.py,1,"b""import torch as t\nfrom torch.autograd import Variable as v\n\n# simple gradient\na = v(t.FloatTensor([2, 3]), requires_grad=True)\nb = a + 3\nc = b * b * 3\nout = c.mean()\nout.backward()\nprint('*'*10)\nprint('=====simple gradient======')\nprint('input')\nprint(a.data)\nprint('compute result is')\nprint(out.data[0])\nprint('input gradients are')\nprint(a.grad.data)\n\n# backward on non-scalar output\nm = v(t.FloatTensor([[2, 3]]), requires_grad=True)\nn = v(t.zeros(1, 2))\nn[0, 0] = m[0, 0] ** 2\nn[0, 1] = m[0, 1] ** 3\nn.backward(t.FloatTensor([[1, 1]]))\nprint('*'*10)\nprint('=====non scalar output======')\nprint('input')\nprint(m.data)\nprint('input gradients are')\nprint(m.grad.data)\n\n# jacobian\nj = t.zeros(2 ,2)\nk = v(t.zeros(1, 2))\nm.grad.data.zero_()\nk[0, 0] = m[0, 0] ** 2 + 3 * m[0 ,1]\nk[0, 1] = m[0, 1] ** 2 + 2 * m[0, 0]\nk.backward(t.FloatTensor([[1, 0]]), retain_variables=True)\nj[:, 0] = m.grad.data\nm.grad.data.zero_()\nk.backward(t.FloatTensor([[0, 1]]))\nj[:, 1] = m.grad.data\nprint('jacobian matrix is')\nprint(j)\n\n# compute jacobian matrix\nx = t.FloatTensor([2, 1]).view(1, 2)\nx = v(x, requires_grad=True)\ny = v(t.FloatTensor([[1, 2], [3, 4]]))\n\nz = t.mm(x, y)\njacobian = t.zeros((2, 2))\nz.backward(t.FloatTensor([[1, 0]]), retain_variables=True)  # dz1/dx1, dz1/dx2\njacobian[:, 0] = x.grad.data\nx.grad.data.zero_()\nz.backward(t.FloatTensor([[0, 1]]))  # dz2/dx1, dz2/dx2\njacobian[:, 1] = x.grad.data\nprint('=========jacobian========')\nprint('x')\nprint(x.data)\nprint('y')\nprint(y.data)\nprint('compute result')\nprint(z.data)\nprint('jacobian matrix is')\nprint(jacobian)\n"""
12-data io/custom_data_io.py,1,"b""from torch.utils.data import Dataset\nfrom PIL import Image\nimport os\n\n\ndef default_loader(img):\n    return Image.open(img)\n\n\nclass custom_dset(Dataset):\n    def __init__(self,\n                 img_path,\n                 txt_path,\n                 img_transform=None,\n                 loader=default_loader):\n        with open(txt_path, 'r') as f:\n            lines = f.readlines()\n            self.img_list = [\n                os.path.join(img_path, i.split()[0]) for i in lines\n            ]\n            self.label_list = [i.split()[1] for i in lines]\n        self.img_transform = img_transform\n        self.loader = loader\n\n    def __getitem__(self, index):\n        img_path = self.img_list[index]\n        label = self.label_list[index]\n        # img = self.loader(img_path)\n        img = img_path\n        if self.img_transform is not None:\n            img = self.img_transform(img)\n        return img, label\n\n    def __len__(self):\n        return len(self.label_list)\n\n\ndef collate_fn(batch):\n    batch.sort(key=lambda x: len(x[1]), reverse=True)\n    img, label = zip(*batch)\n    pad_label = []\n    lens = []\n    max_len = len(label[0])\n    for i in range(len(label)):\n        temp_label = [0] * max_len\n        temp_label[:len(label[i])] = label[i]\n        pad_label.append(temp_label)\n        lens.append(len(label[i]))\n    return img, pad_label, lens\n"""
