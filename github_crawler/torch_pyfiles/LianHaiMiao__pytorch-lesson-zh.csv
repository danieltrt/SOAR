file_path,api_count,code
CV/py/AlexNet.py,8,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\nclass AlextNet(nn.Module):\n    def __init__(self, in_channel, n_class):\n        super(AlextNet, self).__init__()\n        # \xe7\xac\xac\xe4\xb8\x80\xe9\x98\xb6\xe6\xae\xb5\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channel, 96, kernel_size=11, stride=4),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        # \xe7\xac\xac\xe4\xba\x8c\xe9\x98\xb6\xe6\xae\xb5\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        # \xe7\xac\xac\xe4\xb8\x89\xe9\x98\xb6\xe6\xae\xb5\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        # \xe7\xac\xac\xe5\x9b\x9b\xe9\x98\xb6\xe6\xae\xb5 \xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82\n        self.fc = nn.Sequential(\n            nn.Linear(1*1*256, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(4096, n_class) # AlexNet\xe4\xb8\x8a\xe9\x9d\xa2\xe6\x98\xaf1000 ...\xe5\xa6\x82\xe6\x9e\x9c\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe8\xaf\x9d\xe7\x94\xa8MNIST\xe5\x88\x99\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa810\n        )\n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    def forward(self, x):\n        con1_x = self.conv1(x)\n        con2_x = self.conv2(con1_x)\n        con3_x = self.conv3(con2_x)\n        lin_x = con3_x.view(con3_x.size(0), -1)\n        y_hat = self.fc(lin_x)\n        return y_hat\n\n\nalex = AlextNet(3, 10) # in_channel, class_num\nprint(alex)\n\n# \xe5\x9b\xbe\xe5\x83\x8f\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xbaAlex \xe6\x98\xaf\xe4\xbd\xbf\xe7\x94\xa8 227 * 227 \xe5\xa4\xa7\xe5\xb0\x8f\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf CIFAR10 \xe5\x8f\xaa\xe6\x9c\x89 32 * 32 ,\xe7\xbb\x8f\xe8\xbf\x87\xe6\xb5\x8b\xe8\xaf\x95\xef\xbc\x8c 227 * 227 \xe7\x9a\x84\xe6\x95\x88\xe6\x9e\x9c\xe4\xb8\x8d\xe5\xa5\xbd\xe3\x80\x82\n# \xe6\x89\x80\xe4\xbb\xa5\xe8\xbf\x99\xe9\x87\x8c\xef\xbc\x8c \xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x86\xe5\x9b\xbe\xe5\x83\x8f\xe6\x94\xbe\xe5\xa4\xa7\xe5\x88\xb0 96*96\ntransform = transforms.Compose([\n    transforms.Resize(96),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# \xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nDOWNLOAD = True\nBATCH_SIZE = 256\nEPOCH = 5\nlearning_rate = 0.001\n\n# \xe6\x98\xaf\xe5\x90\xa6\xe4\xbd\xbf\xe7\x94\xa8GPU\nuse_gpu = True\n\n# CIFAR10 dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root=\'./data/\', train=True, transform=transform, download=DOWNLOAD)\n\ntest_dataset = torchvision.datasets.CIFAR10(root=\'./data/\', train=False, transform=transform)\n\n# Data Loader\ntrain_loader = DataLoader(dataset=train_dataset,\n                            batch_size=BATCH_SIZE,\n                            shuffle=True)\n\ntest_loader = DataLoader(dataset=test_dataset,\n                            batch_size=BATCH_SIZE,\n                            shuffle=False)\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\xa8\xa1\xe5\x9e\x8b\nalex = AlextNet(3, 10)\nif use_gpu:\n    alex = alex.cuda()\n\n# loss and optimizer\n\nloss_fn = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(alex.parameters(), lr=learning_rate)\n\n# Training\nalex.train()\n\nfor epoch in range(EPOCH):\n    total = 0\n    correct = 0\n    for i, (images, labels) in enumerate(train_loader):\n        images = Variable(images)\n        labels = Variable(labels)\n\n        if use_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n        # forward + backward + optimize\n        optimizer.zero_grad()\n        y_pred = alex(images)\n\n        loss = loss_fn(y_pred, labels)\n\n        loss.backward()\n\n        optimizer.step()\n\n        if (i + 1) % 100 == 0:\n            print(""Epoch [%d/%d], Iter [%d/%d] Loss: %.4f"" % (epoch + 1, EPOCH, i + 1, 100, loss.data[0]))\n\n        # \xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\n        _, predicted = torch.max(y_pred.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels.data).sum()\n    print(\'Accuracy of the model on the train images: %d %%\' % (100 * correct / total))\n\n    # Decaying Learning Rate\n    if (epoch+1) % 2 == 0:\n        learning_rate /= 3\n        optimizer = torch.optim.Adam(alex.parameters(), lr=learning_rate)\n\n\n# Test\nalex.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    images = Variable(images)\n    labels = Variable(labels)\n    if use_gpu:\n        images = images.cuda()\n        labels = labels.cuda()\n\n    y_pred = alex(images)\n    _, predicted = torch.max(y_pred.data, 1)\n    total += labels.size(0)\n    temp = (predicted == labels.data).sum()\n    correct += temp\n\nprint(\'Accuracy of the model on the test images: %d %%\' % (100 * correct / total))\n\n\n'"
CV/py/NIN.py,8,"b'import torchvision\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\n\n\n# \xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\xe7\xb1\xbb\xef\xbc\x8c\xe7\x94\xa8\xe4\xba\x8e\xe6\x8e\xa7\xe5\x88\xb6\xe5\x90\x84\xe7\xa7\x8d\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nclass Config(object):\n    def __init__(self):\n        self.lr = 0.005\n        self.batch_size = 256\n        self.use_gpu = torch.cuda.is_available()\n        self.DOWNLOAD = True\n        self.epoch_num = 5 # \xe5\x9b\xa0\xe4\xb8\xba\xe5\x8f\xaa\xe6\x98\xafdemo\xef\xbc\x8c\xe5\xb0\xb1\xe8\xb7\x91\xe4\xba\x862\xe4\xb8\xaaepoch\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\x87\xaa\xe5\xb7\xb1\xe5\xa4\x9a\xe5\x8a\xa0\xe5\x87\xa0\xe6\xac\xa1\xe8\xaf\x95\xe8\xaf\x95\xe7\xbb\x93\xe6\x9e\x9c\n        self.class_num = 10 # CIFAR10 \xe5\x85\xb1\xe6\x9c\x8910\xe7\xb1\xbb\nconfig = Config()\n\n\n# NiN\xe6\x8f\x90\xe5\x87\xba\xe5\x8f\xaa\xe5\xaf\xb9\xe9\x80\x9a\xe9\x81\x93\xe5\xb1\x82\xe5\x81\x9a\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb9\xb6\xe4\xb8\x94\xe5\x83\x8f\xe7\xb4\xa0\xe4\xb9\x8b\xe9\x97\xb4\xe5\x85\xb1\xe4\xba\xab\xe6\x9d\x83\xe9\x87\x8d\xe6\x9d\xa5\xe8\xa7\xa3\xe5\x86\xb3\xe4\xb8\x8a\xe8\xbf\xb0\xe4\xb8\xa4\xe4\xb8\xaa\xe9\x97\xae\xe9\xa2\x98\n# \xe8\xbf\x99\xe7\xa7\x8d\xe2\x80\x9c\xe4\xb8\x80\xe5\x8d\xb7\xe5\x8d\xb7\xe5\x88\xb0\xe5\xba\x95\xe2\x80\x9d\xe6\x9c\x80\xe5\x90\x8e\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb9\xb3\xe5\x9d\x87\xe6\xb1\xa0\xe5\x8c\x96\xe5\xb1\x82\xe7\x9a\x84\xe5\x81\x9a\xe6\xb3\x95\xe4\xb9\x9f\xe6\x88\x90\xe4\xb8\xba\xe4\xba\x86\xe6\xb7\xb1\xe5\xba\xa6\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe5\xb8\xb8\xe7\x94\xa8\xe8\xae\xbe\xe8\xae\xa1\xe3\x80\x82\ndef mlpconv(in_chanels, out_chanels, kernel_size, padding, strides=1, max_pooling=True):\n    layers = []\n    layers += [nn.Conv2d(in_chanels, out_chanels, kernel_size=kernel_size, padding=padding, stride=strides), nn.ReLU(inplace=True)]\n    layers += [nn.Conv2d(out_chanels, out_chanels, kernel_size=1, padding=0, stride=1), nn.ReLU(inplace=True)]\n    layers += [nn.Conv2d(out_chanels, out_chanels, kernel_size=1, padding=0, stride=1), nn.ReLU(inplace=True)]\n    if max_pooling:\n        layers += [nn.MaxPool2d(kernel_size=3, stride=2)]\n    return nn.Sequential(*layers)\n\n\nclass NIN(nn.Module):\n    """"""\n       \xe8\xbe\x93\xe5\x85\xa5\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe5\xb0\xba\xe5\xaf\xb8\xe4\xb8\x80\xe5\xae\x9a\xe5\xbe\x97\xe6\x98\xaf 224 \xc3\x97 224 \xe7\x9a\x84\n    """"""\n    def __init__(self, class_num):\n        super(NIN, self).__init__()\n        self.net = nn.Sequential(\n            mlpconv(3, 96, 11, 0, strides=4),\n            mlpconv(96, 256, 5, 2),\n            mlpconv(256, 384, 3, 1),\n            nn.Dropout(0.5),\n            # \xe7\x9b\xae\xe6\xa0\x87\xe7\xb1\xbb\xe4\xb8\xba10\xe7\xb1\xbb\n            mlpconv(384, 10, 3, 1, max_pooling=False),\n            # \xe8\xbe\x93\xe5\x85\xa5\xe4\xb8\xba batch_size x 10 x 5 x 5, \xe9\x80\x9a\xe8\xbf\x87AvgPool2D\xe8\xbd\xac\xe6\x88\x90\n            # batch_size x 10 x 1 x 1\xe3\x80\x82\n            nn.AvgPool2d(kernel_size=5, stride=1)\n        )\n        self.class_num = class_num\n\n    def forward(self, x):\n        out = self.net(x)\n        out = out.view(-1, self.class_num )\n        return out\n\n\n# \xe5\x9b\xbe\xe5\x83\x8f\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xbaNIN\xe6\x98\xaf\xe4\xbd\xbf\xe7\x94\xa8224 * 224\xe5\xa4\xa7\xe5\xb0\x8f\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf CIFAR10 \xe5\x8f\xaa\xe6\x9c\x8932 * 32\ntransform = transforms.Compose([\n    transforms.Resize(224), # \xe7\xbc\xa9\xe6\x94\xbe\xe5\x88\xb0 224 * 224 \xe5\xa4\xa7\xe5\xb0\x8f\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n])\n\n\n# \xe4\xb8\x8b\xe8\xbd\xbd CIFAR10 dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root=\'./data/\', train=True, transform=transform, download=config.DOWNLOAD)\ntest_dataset = torchvision.datasets.CIFAR10(root=\'./data/\', train=False, transform=transform)\n\n# dataloader\n\ntrain_loader = DataLoader(dataset=train_dataset,\n                          batch_size=config.batch_size,\n                          shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset,\n                         batch_size=config.batch_size,\n                         shuffle=False)\n\n\nnin = NIN(config.class_num)\n\n# \xe6\x98\xaf\xe5\x90\xa6\xe4\xbd\xbf\xe7\x94\xa8GPU\nif config.use_gpu:\n    nin = nin.cuda()\n\n# loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(nin.parameters(), lr=config.lr)\n\nfor epoch in range(config.epoch_num):\n    total = 0\n    correct = 0\n    for i, (images, labels) in enumerate(train_loader):\n        images = Variable(images)\n        labels = Variable(labels)\n\n        if config.use_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n\n        # forward + backward + optimize\n        optimizer.zero_grad()\n        y_pred = nin(images)\n\n        loss = loss_fn(y_pred, labels)\n\n        loss.backward()\n\n        optimizer.step()\n        \n        if (i + 1) % 100 == 0:\n            print(""Epoch [%d/%d], Iter [%d/%d] Loss: %.4f"" % (epoch + 1, config.epoch_num, i + 1, 100, loss.data[0]))\n\n        # \xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\n        _, predicted = torch.max(y_pred.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels.data).sum()\n    # \xe7\xbb\x93\xe6\x9d\x9f\xe4\xb8\x80\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\n    print(\'Accuracy of the model on the train images: %d %%\' % (100 * correct / total))\n \n    # Decaying Learning Rate\n    if (epoch+1) % 2 == 0:\n        config.lr /= 3\n        optimizer = torch.optim.Adam(nin.parameters(), lr=config.lr)\n\n\n# Test\nnin.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    images = Variable(images)\n    labels = Variable(labels)\n    if config.use_gpu:\n        images = images.cuda()\n        labels = labels.cuda()\n    y_pred = nin(images)\n    _, predicted = torch.max(y_pred.data, 1)\n    total += labels.size(0)\n    temp = (predicted == labels.data).sum()\n    correct += temp\n\n\nprint(\'Accuracy of the model on the test images: %d %%\' % (100 * correct / total))'"
CV/py/ResNet.py,3,"b'import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.autograd import Variable\n# \xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x99\xe9\x87\x8c\xe4\xbb\xa5 ResNets34 \xe4\xb8\xba\xe4\xbe\x8b\xe5\xad\x90\n\n# \xe5\x85\x88\xe5\xae\x9e\xe7\x8e\xb0\xe4\xb8\x80\xe4\xb8\xaaBlock\nclass Block(nn.Module):\n    def __init__(self, in_channel, out_channel, strides=1, same_shape=True):\n        super(Block, self).__init__()\n        self.same_shape = same_shape\n        if not same_shape:\n            strides = 2\n        self.strides = strides\n        self.block = nn.Sequential(\n            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=strides, padding=1, bias=False),\n            nn.BatchNorm2d(out_channel),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channel)\n        )\n        if not same_shape:\n            self.conv3 = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=strides, bias=False)\n            self.bn3 = nn.BatchNorm2d(out_channel)\n    def forward(self, x):\n        out = self.block(x)\n        if not self.same_shape:\n            x = self.bn3(self.conv3(x))\n        return F.relu(out + x)\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe5\xae\x9e\xe7\x8e\xb0 ResNets34\nclass ResNet34(nn.Module):\n    def __init__(self, num_classes=10):\n        super(ResNet34, self).__init__()\n        # \xe6\x9c\x80\xe5\xbc\x80\xe5\xa7\x8b\xe7\x9a\x84\xe5\x87\xa0\xe5\xb1\x82\n        self.pre = nn.Sequential(\n                nn.Conv2d(3, 64, 7, 2, 3, bias=False),\n                nn.BatchNorm2d(64),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(3, 2, 1))\n        # \xe4\xbb\x8e\xe8\xae\xba\xe6\x96\x87\xe7\x9a\x84\xe5\x9b\xbe\xe4\xb8\xad\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x88\xb0\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x9c\x893\xef\xbc\x8c4\xef\xbc\x8c6\xef\xbc\x8c3\xe4\xb8\xaablock\n        self.layer1 = self._make_layer(64, 64, 3)\n        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n        self.layer3 = self._make_layer(128, 256, 6, stride=2)\n        self.layer4 = self._make_layer(256, 512, 3, stride=2)\n\n        # \xe5\x88\x86\xe7\xb1\xbb\xe7\x94\xa8\xe7\x9a\x84\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\n        self.fc = nn.Linear(512, num_classes)\n    \n    def _make_layer(self,  in_channel, out_channel, block_num, stride=1):\n        layers = []\n        if stride != 1:\n            layers.append(Block(in_channel, out_channel, stride, same_shape=False))\n        else:\n            layers.append(Block(in_channel, out_channel, stride))\n        \n        for i in range(1, block_num):\n            layers.append(Block(out_channel, out_channel))\n        return nn.Sequential(*layers)\n    \n    # \xe5\x9c\xa8jupyter notebook\xe4\xb8\xad\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x9d\xe8\xaf\x95\xe8\xbe\x93\xe5\x87\xba\xe6\xaf\x8f\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84size\xef\xbc\x8c\xe6\x9d\xa5\xe6\x9f\xa5\xe7\x9c\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe3\x80\x81\xe8\xbe\x93\xe5\x87\xba\xe6\x98\xaf\xe5\x90\xa6\xe6\xad\xa3\xe7\xa1\xae\xe3\x80\x82\n    def forward(self, x):\n        x = self.pre(x)\n        print(""pre\xe5\xb1\x82\xe7\x9a\x84size\xe6\x98\xaf\xef\xbc\x9a"", x.size())\n        x = self.layer1(x)\n        print(""layer1\xe7\x9a\x84size\xe6\x98\xaf\xef\xbc\x9a"", x.size())\n        x = self.layer2(x)\n        print(""layer2\xe7\x9a\x84size\xe6\x98\xaf\xef\xbc\x9a"", x.size())\n        x = self.layer3(x)\n        print(""layer3\xe7\x9a\x84size\xe6\x98\xaf\xef\xbc\x9a"", x.size())\n        x = self.layer4(x)\n        print(""layer4\xe7\x9a\x84size\xe6\x98\xaf\xef\xbc\x9a"", x.size())\n        x = F.avg_pool2d(x, 7)\n        x = x.view(x.size(0), -1)\n        print(""\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe6\x98\xaf\xef\xbc\x9a"", x.size())\n        return self.fc(x)\n\n\n\nresnet = ResNet34()\nx = Variable(torch.randn(1, 3, 224, 224))\nprint(resnet(x).size())\n\n# \xe5\xae\x9e\xe7\x8e\xb0 ResNets50 \xe4\xbb\xa5\xe4\xb8\x8a\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\x85\x88\xe5\xae\x9e\xe7\x8e\xb0\xe4\xb8\x80\xe4\xb8\xaaBlock\xef\xbc\x8c ResNets50 \xe5\x81\x9a\xe4\xb8\xba\xe7\xbb\x83\xe4\xb9\xa0\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x9d\xe8\xaf\x95\xe5\xae\x8c\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\x8b\xe3\x80\x82\nclass Bottleneck(nn.Module):\n    def __init__(self, in_channel, out_channel, strides=1, same_shape=True, bottle=True):\n        super(Bottleneck, self).__init__()\n        self.same_shape = same_shape\n        self.bottle = bottle\n        if not same_shape:\n            strides = 2\n        self.strides = strides\n        self.block = nn.Sequential(\n            nn.Conv2d(in_channel, out_channel, kernel_size=1, bias=False),\n            nn.BatchNorm2d(out_channel),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=strides, padding=1, bias=False),\n            nn.BatchNorm2d(out_channel),\n            nn.Conv2d(out_channel, out_channel*4, kernel_size=1, bias=False),\n            nn.BatchNorm2d(out_channel*4)\n        )\n        if not same_shape or not bottle:\n            self.conv4 = nn.Conv2d(in_channel, out_channel*4, kernel_size=1, stride=strides, bias=False)\n            self.bn4 = nn.BatchNorm2d(out_channel*4)\n            print(self.conv4)\n    def forward(self, x):\n        print(x.size())\n        out = self.block(x)\n        print(out.size())\n        if not self.same_shape or not self.bottle:\n            x = self.bn4(self.conv4(x))\n        return F.relu(out + x)'"
CV/py/VGG.py,7,"b'import torchvision\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\n\n\n# \xe5\x9b\xbe\xe5\x83\x8f\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xbaVGG\xe6\x98\xaf\xe4\xbd\xbf\xe7\x94\xa8224 * 224\xe5\xa4\xa7\xe5\xb0\x8f\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf CIFAR10 \xe5\x8f\xaa\xe6\x9c\x8932 * 32, \xe4\xb8\xba\xe4\xba\x86\xe8\x83\xbd\xe5\xbf\xab\xe7\x82\xb9\xe8\xb7\x91\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x8c\n# \xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x86\xe5\xae\x83\xe4\xbb\xac\xe6\x94\xbe\xe5\xa4\xa7\xe5\x88\xb096*96\xef\xbc\x8c\xe8\x80\x8c\xe4\xb8\x8d\xe6\x98\xaf\xe5\x8e\x9f\xe5\xa7\x8b\xe8\xae\xba\xe6\x96\x87\xe7\x9a\x84224 * 224\ntransform = transforms.Compose([\n    transforms.Resize(96), # \xe7\xbc\xa9\xe6\x94\xbe\xe5\x88\xb0 96 * 96 \xe5\xa4\xa7\xe5\xb0\x8f\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n])\n\n# \xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nDOWNLOAD = True\nBATCH_SIZE = 256\nEPOCH = 5\nlearning_rate = 0.001\n\n# \xe6\x98\xaf\xe5\x90\xa6\xe4\xbd\xbf\xe7\x94\xa8GPU\nuse_gpu = True\n\n# \xe4\xb8\x8b\xe8\xbd\xbd CIFAR10 dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root=\'./data/\', train=True, transform=transform, download=DOWNLOAD)\ntest_dataset = torchvision.datasets.CIFAR10(root=\'./data/\', train=False, transform=transform)\n\n# dataloader\n\ntrain_loader = DataLoader(dataset=train_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset,\n                         batch_size=BATCH_SIZE,\n                         shuffle=False)\n\n\nclass VGG(nn.Module):\n    \'\'\'\n    VGG model\n    \'\'\'\n    def __init__(self, conv_features):\n        super(VGG, self).__init__()\n        self.conv_features = conv_features\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(4608, 512),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(512, 512),\n            nn.ReLU(True),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.conv_features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# \xe6\x9e\x84\xe5\xbb\xba \xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84 conv\xe5\xb1\x82\ndef make_layers(struct, in_channels=1, batch_norm=False):\n    layers = []\n    for out_channels in struct:\n        if out_channels == \'pooling\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = out_channels\n    return nn.Sequential(*layers)\n\n\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96 \nvgg_conv_layers = [64, 64, \'pooling\', 128, 128, \'pooling\', 256, 256, 256, \'pooling\', 512, 512, 512, \'pooling\', 512, 512, 512, \'pooling\']\n\n# \xe5\x88\x9d\xe5\xa7\x8b\xe9\x80\x9a\xe9\x81\x93\xe2\x80\x94\xe2\x80\x94 \xe4\xb8\x89\xe9\x80\x9a\xe9\x81\x93\nvgg16 = VGG(make_layers(vgg_conv_layers, in_channels=3))\n\n# \xe6\x98\xaf\xe5\x90\xa6\xe4\xbd\xbf\xe7\x94\xa8GPU\nif use_gpu:\n    vgg16 = vgg16.cuda()\n    \n# loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(vgg16.parameters(), lr=learning_rate)\n\n# Training\nvgg16.train()\n\nfor epoch in range(EPOCH):\n    total = 0\n    correct = 0\n    for i, (images, labels) in enumerate(train_loader):\n        images = Variable(images)\n        labels = Variable(labels)\n        \n        if use_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n        \n        # forward + backward + optimize\n        optimizer.zero_grad()\n        y_pred = vgg16(images)\n\n        loss = loss_fn(y_pred, labels)\n\n        loss.backward()\n\n        optimizer.step()\n\n        if (i + 1) % 100 == 0:\n            print(""Epoch [%d/%d], Iter [%d/%d] Loss: %.4f"" % (epoch + 1, EPOCH, i + 1, 200, loss.data[0]))\n\n        # \xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\n        _, predicted = torch.max(y_pred.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels.data).sum()\n    \n    # \xe7\xbb\x93\xe6\x9d\x9f\xe4\xb8\x80\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\n    print(\'Accuracy of the model on the train images: %d %%\' % (100 * correct / total))\n    \n    # Decaying Learning Rate\n    if (epoch+1) % 2 == 0:\n        learning_rate /= 3\n        optimizer = torch.optim.Adam(vgg16.parameters(), lr=learning_rate)\n\n\n# Test\nvgg16.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    images = Variable(images)\n    labels = Variable(labels)\n    if use_gpu:\n        images = images.cuda()\n        labels = labels.cuda()\n    y_pred = vgg16(images)\n    _, predicted = torch.max(y_pred.data, 1)\n    total += labels.size(0)\n    temp = (predicted == labels.data).sum()\n    correct += temp\n\nprint(\'Accuracy of the model on the test images: %d %%\' % (100 * correct / total))\n\n\n\n\n\n'"
DRL/py/policy_gradients.py,11,"b'import gym\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass PolicyGradient:\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x97\xb6, \xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe7\xbb\x99\xe5\x87\xba\xe8\xbf\x99\xe4\xba\x9b\xe5\x8f\x82\xe6\x95\xb0, \xe5\xb9\xb6\xe5\x88\x9b\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c.\n    def __init__(self, n_actions, n_features, learning_rate=0.01, reward_decay=0.95):\n        self.n_actions = n_actions\n        self.n_features = n_features\n        self.lr = learning_rate  # \xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\n        self.gamma = reward_decay  # reward \xe9\x80\x90\xe6\xad\xa5\xe9\x80\x92\xe5\x87\x8f\n        self.ep_obs, self.ep_acs, self.ep_res = [], [], [] # \xe5\x88\x86\xe5\x88\xab\xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\xad\xa5\xe7\x9a\x84observation, action \xe5\x92\x8c reward\n        self.pnet = PGNet(n_features, n_actions) # \xe5\xbb\xba\xe7\xab\x8b policy network\n        self.optimizer = torch.optim.Adam(self.pnet.parameters(), lr=learning_rate) # \xe5\xbb\xba\xe7\xab\x8b\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\n        self.DEFAULT_TYPE = torch.float\n\n    # \xe6\xa0\xb9\xe6\x8d\xae\xe7\x8e\xaf\xe5\xa2\x83\xe9\x80\x89\xe6\x8b\xa9\xe8\xa1\x8c\xe4\xb8\xba; \xe5\x9b\xa0\xe4\xb8\xba\xe6\x98\xaf Policy Gradient \xe6\x89\x80\xe4\xbb\xa5\xe6\x98\xaf\xe6\x8c\x89\xe7\x85\xa7\xe6\xa6\x82\xe7\x8e\x87\xe4\xbb\x8e\xe5\xa4\xa7\xe5\x88\xb0\xe5\xb0\x8f\xe5\x8e\xbb\xe9\x80\x89\xe6\x8b\xa9\xe3\x80\x82\n    def choose_action(self, observation):\n        observation = self.to_tensor(observation, type=torch.float32)\n        act_prob = self.pnet.get_act_prob(observation)\n        act_prob = self.tesnsor2np(act_prob)\n        action = np.random.choice(range(self.n_actions), p=act_prob)\n        return action\n\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x9b\x9e\xe5\x90\x88\xe7\x9a\x84observation, action \xe5\x92\x8c reward, \xe5\xbd\x93\xe6\xaf\x8f\xe6\xac\xa1\xe6\xa8\xa1\xe6\x8b\x9f\xe7\xbb\x93\xe6\x9d\x9f\xe4\xb9\x8b\xe5\x90\x8e,\xe6\xb8\x85\xe7\xa9\xba\xe5\x88\x97\xe8\xa1\xa8\n    def store_transition(self, ob, a, r):\n        self.ep_obs.append(ob)\n        self.ep_acs.append(a)\n        self.ep_res.append(r)\n    # \xe5\xad\xa6\xe4\xb9\xa0\xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\n    def learn(self):\n        # \xe8\xa1\xb0\xe5\x87\x8f, \xe5\xb9\xb6\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe8\xbf\x99\xe5\x9b\x9e\xe5\x90\x88\xe7\x9a\x84 reward\n        discounted_ep_rs_norm = self._discount_and_norm_rewards()\n        # \xe5\x8f\x98\xe6\x88\x90tensor\n        observations = self.to_tensor(self.ep_obs, type=torch.float)\n        actions = self.to_tensor(self.ep_acs, type=torch.long)\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83,\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\n        loss = self.pnet(actions, observations, discounted_ep_rs_norm)\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n\n        # \xe8\xae\xad\xe7\xbb\x83\xe5\xae\x8c\xe6\xaf\x95,\xe6\xb8\x85\xe7\xa9\xba\xe8\xbf\x99\xe4\xb8\x80\xe5\x9b\x9e\xe5\x90\x88\xe7\x9a\x84data\n        self.ep_obs, self.ep_acs, self.ep_res = [], [], []\n        return discounted_ep_rs_norm  # \xe8\xbf\x94\xe5\x9b\x9e\xe8\xbf\x99\xe4\xb8\x80\xe5\x9b\x9e\xe5\x90\x88\xe7\x9a\x84 state-action value\n\n    # reward \xe7\x9a\x84\xe9\x80\x90\xe6\xad\xa5\xe8\xa1\xb0\xe5\x87\x8f\n    def _discount_and_norm_rewards(self):\n        # discount episode rewards\n        discounted_ep_res = np.zeros_like(self.ep_res)\n        running_add = 0\n        for t in reversed(range(0, len(self.ep_res))):\n            running_add = running_add * self.gamma + self.ep_res[t]\n            discounted_ep_res[t] = running_add\n\n        # normalize episode rewards\n        discounted_ep_res -= np.mean(discounted_ep_res)\n        discounted_ep_res /= np.std(discounted_ep_res)\n        dis_ep_res = torch.from_numpy(discounted_ep_res).to(dtype=self.DEFAULT_TYPE)\n        return dis_ep_res\n    # \xe5\x88\x97\xe8\xa1\xa8\xe6\x88\x96\xe8\x80\x85\xe5\x8d\x95\xe4\xb8\xaa\xe6\x95\xb0\xe5\x80\xbc\xe5\x8f\x98\xe6\x88\x90tensor\n    def to_tensor(self, l, type):\n        ten = torch.FloatTensor(l)\n        return ten.to(dtype=type)\n\n    def tesnsor2np(self, tens):\n        return tens.detach().numpy()\n\n# \xe7\x94\xa8\xe4\xba\x8e\xe5\x86\xb3\xe7\xad\x96\xe7\x9a\x84\xe7\xbd\x91\xe7\xbb\x9c\nclass PGNet(nn.Module):\n    def __init__(self, num_fea, num_act):\n        super(PGNet, self).__init__()\n        # \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\n        self.fc1 = nn.Linear(num_fea, 10)\n        # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\n        self.out = nn.Linear(10, num_act)\n        # initial\n        self.fc1.weight.data.normal_(0, 0.3)  # initial fc1 weight\n        self.out.weight.data.normal_(0, 0.3)  # initial out weight\n        self.neg_log = nn.CrossEntropyLoss(reduce=False)\n    def forward(self, acs, obs, res):\n        x = self.fc1(obs)\n        x = F.tanh(x)\n        x = self.out(x)\n        neg_log_prob = self.neg_log(x, acs)\n        # \xe6\x9c\x80\xe5\xa4\xa7\xe5\x8c\x96 \xe6\x80\xbb\xe4\xbd\x93 reward (log_p * R) \xe5\xb0\xb1\xe6\x98\xaf\xe5\x9c\xa8\xe6\x9c\x80\xe5\xb0\x8f\xe5\x8c\x96 -(log_p * R)\n        # neg_log_prob = F.cross_entropy(acs, res, reduce=False)\n        # (res = \xe5\x8e\x9f\xe6\x9c\xac\xe7\x9a\x84rewards + \xe8\xa1\xb0\xe5\x87\x8f\xe7\x9a\x84\xe6\x9c\xaa\xe6\x9d\xa5reward) \xe5\xbc\x95\xe5\xaf\xbc\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\n        # loss = torch.mean(neg_log_prob * res)\n        loss = torch.mean(neg_log_prob * res)\n        return loss\n\n    def get_act_prob(self, obs):\n        x = self.fc1(obs)\n        x = F.tanh(x)\n        act_prob = F.softmax(self.out(x), dim=0)\n        return act_prob\n\n\n\nif __name__ == \'__main__\':\n    # \xe5\xaf\xb9\xe4\xba\x8e Policy Gradient \xe6\x9d\xa5\xe8\xaf\xb4\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x98\xaf\xe5\x9c\xa8\xe5\xae\x83\xe4\xbb\xac\xe6\xaf\x8f\xe6\xac\xa1\xe6\xa8\xa1\xe6\x8b\x9f\xe7\xbb\x93\xe6\x9d\x9f\xe4\xb9\x8b\xe5\x90\x8e\xef\xbc\x8c\xe5\xaf\xb9 policy network \xe8\xbf\x9b\xe8\xa1\x8c\xe6\x9b\xb4\xe6\x96\xb0\n    # \xe7\xbb\x93\xe6\x9d\x9f\xe4\xb8\x80\xe6\xac\xa1\xe6\xa8\xa1\xe6\x8b\x9f\xef\xbc\x8c\xe5\xb0\xb1\xe6\x9b\xb4\xe6\x96\xb0\xe4\xb8\x80\xe6\xac\xa1\xe3\x80\x82\xe5\xb9\xb6\xe4\xb8\x8d\xe4\xbc\x9a\xe5\x9c\xa8\xe6\xa8\xa1\xe6\x8b\x9f\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x9b\xb4\xe6\x96\xb0\xe3\x80\x82\n\n    RENDER = False  # \xe5\x9c\xa8\xe5\xb1\x8f\xe5\xb9\x95\xe4\xb8\x8a\xe6\x98\xbe\xe7\xa4\xba\xe6\xa8\xa1\xe6\x8b\x9f\xe7\xaa\x97\xe5\x8f\xa3\xe4\xbc\x9a\xe6\x8b\x96\xe6\x85\xa2\xe8\xbf\x90\xe8\xa1\x8c\xe9\x80\x9f\xe5\xba\xa6, \xe6\x88\x91\xe4\xbb\xac\xe7\xad\x89\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\xba\xe5\xad\xa6\xe5\xbe\x97\xe5\xb7\xae\xe4\xb8\x8d\xe5\xa4\x9a\xe4\xba\x86\xe5\x86\x8d\xe6\x98\xbe\xe7\xa4\xba\xe6\xa8\xa1\xe6\x8b\x9f\n    DISPLAY_REWARD_THRESHOLD = 400  # \xe5\xbd\x93\xe5\x9b\x9e\xe5\x90\x88\xe6\x80\xbb reward \xe5\xa4\xa7\xe4\xba\x8e 400 \xe6\x97\xb6\xe6\x98\xbe\xe7\xa4\xba\xe6\xa8\xa1\xe6\x8b\x9f\xe7\xaa\x97\xe5\x8f\xa3\n\n    env = gym.make(\'CartPole-v0\')   #  \xe6\x9e\x84\xe5\xbb\xba CartPole \xe7\x8e\xaf\xe5\xa2\x83\n    env = env.unwrapped  # \xe5\x8f\x96\xe6\xb6\x88\xe9\x99\x90\xe5\x88\xb6\n    env.seed(1)     # \xe6\x99\xae\xe9\x80\x9a\xe7\x9a\x84 Policy gradient \xe6\x96\xb9\xe6\xb3\x95, \xe4\xbd\xbf\xe5\xbe\x97\xe5\x9b\x9e\xe5\x90\x88\xe7\x9a\x84 variance \xe6\xaf\x94\xe8\xbe\x83\xe5\xa4\xa7, \xe6\x89\x80\xe4\xbb\xa5\xe6\x88\x91\xe4\xbb\xac\xe9\x80\x89\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa\xe5\xa5\xbd\xe7\x82\xb9\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe7\xa7\x8d\xe5\xad\x90\n\n    print(env.action_space.n)     # \xe6\x98\xbe\xe7\xa4\xba\xe5\x8f\xaf\xe7\x94\xa8 action\n    print(env.observation_space)    # \xe6\x98\xbe\xe7\xa4\xba\xe5\x8f\xaf\xe7\x94\xa8 state \xe7\x9a\x84 observation\n    print(env.observation_space.high)   # \xe6\x98\xbe\xe7\xa4\xba observation \xe6\x9c\x80\xe9\xab\x98\xe5\x80\xbc\n    print(env.observation_space.low)    # \xe6\x98\xbe\xe7\xa4\xba observation \xe6\x9c\x80\xe4\xbd\x8e\xe5\x80\xbc\n\n    # \xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x80\xe4\xb8\xaaPolicy Graident\n    RL = PolicyGradient(\n        n_actions =  env.action_space.n,  # \xe5\xae\x9a\xe4\xb9\x89\xe5\x9c\xa8\xe4\xb8\x80\xe4\xb8\xaa Policy \xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x87\x87\xe5\x8f\x96\xe7\x9a\x84\xe7\xad\x96\xe7\x95\xa5\xe6\x9c\x89\xe5\x93\xaa\xe4\xba\x9b\n        n_features = env.observation_space.shape[0],  # \xe5\xae\x9a\xe4\xb9\x89\xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe5\xae\x9e\xe9\xaa\x8c\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xa7\x82\xe6\xb5\x8b\xe5\x88\xb0\xe7\x9a\x84\xe5\x80\xbc\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\n        learning_rate = 0.02, # \xe5\xae\x9a\xe4\xb9\x89\xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\n        reward_decay = 0.99  # \xe5\xa5\x96\xe5\x8a\xb1\xe9\x80\x90\xe6\xad\xa5\xe5\x87\x8f\xe5\xb0\x91\n    )\n\n    # \xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe5\xbc\x80\xe5\xa7\x8b\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa8\xa1\xe6\x8b\x9f\n\n    for i_episode in range(1000):\n        observation = env.reset()  # \xe6\x8a\x8a\xe7\x8e\xaf\xe5\xa2\x83\xe9\x87\x8d\xe7\xbd\xae\xe5\x88\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe7\x8a\xb6\xe6\x80\x81\n        # \xe4\xb8\x8d\xe6\xad\xbb\xe4\xba\xa1\xef\xbc\x8c\xe4\xb8\x8d\xe9\x87\x8d\xe6\x96\xb0\xe5\xbc\x80\xe5\xa7\x8b\n        while True:\n            if RENDER:\n                env.render()  # \xe5\x87\xbd\xe6\x95\xb0\xe7\x94\xa8\xe4\xba\x8e\xe6\xb8\xb2\xe6\x9f\x93\xe5\x87\xba\xe5\xbd\x93\xe5\x89\x8d\xe7\x9a\x84\xe6\x99\xba\xe8\x83\xbd\xe4\xbd\x93\xe4\xbb\xa5\xe5\x8f\x8a\xe7\x8e\xaf\xe5\xa2\x83\xe7\x9a\x84\xe7\x8a\xb6\xe6\x80\x81\n            # \xe6\xa0\xb9\xe6\x8d\xae\xe5\xbd\x93\xe5\x89\x8d\xe7\x9a\x84\xe8\xa7\x82\xe5\xaf\x9f\xef\xbc\x8c\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x80\xe4\xb8\xaa\xe5\x90\x88\xe9\x80\x82\xe7\x9a\x84action\n            action = RL.choose_action(observation)\n            # \xe9\x87\x87\xe5\x8f\x96\xe5\xae\x8caction\xe4\xb9\x8b\xe5\x90\x8e\xe8\xbf\x94\xe5\x9b\x9e\xe5\x9b\x9b\xe4\xb8\xaa\xe5\x80\xbc\n            # observation_(action\xe4\xb9\x8b\xe5\x90\x8e\xe7\x8e\xaf\xe5\xa2\x83\xe7\x9a\x84\xe7\x8a\xb6\xe6\x80\x81)\xe3\x80\x81reward(\xe5\xbd\x93\xe5\x89\x8dAction\xe5\x8d\xb3\xe6\x97\xb6\xe5\xa5\x96\xe5\x8a\xb1)\n            # done(\xe4\xbb\xbb\xe5\x8a\xa1\xe6\x98\xaf\xe5\x90\xa6\xe7\xbb\x93\xe6\x9d\x9f\xe6\xa0\x87\xe8\xae\xb0\xef\xbc\x8cTrue\xef\xbc\x8creset\xe4\xbb\xbb\xe5\x8a\xa1)\xe3\x80\x81info(\xe9\xa2\x9d\xe5\xa4\x96\xe8\xaf\x8a\xe6\x96\xad\xe4\xbf\xa1\xe6\x81\xaf)\n            observation_, reward, done, info = env.step(action)\n            # \xe5\xad\x98\xe5\x82\xa8\xe8\xbf\x99\xe4\xb8\x80\xe5\x9b\x9e\xe5\x90\x88\xe7\x9a\x84 transition\n            RL.store_transition(observation, action, reward)\n\n            # \xe5\xa6\x82\xe6\x9e\x9c\xe5\xbd\x93\xe5\x89\x8d\xe6\xa8\xa1\xe6\x8b\x9f\xe7\xbb\x93\xe6\x9d\x9f\n            if done:\n                # \xe8\xae\xa1\xe7\xae\x97\xe5\xbd\x93\xe5\x89\x8d\xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb4\xe4\xb8\xaa\xe8\xbf\x87\xe7\xa8\x8b\xe7\x9a\x84reward\n                ep_rs_sum = sum(RL.ep_res)\n                # \xe5\xa6\x82\xe6\x9e\x9c\xe5\xbd\x93\xe5\x89\x8d\xe5\x8f\x98\xe9\x87\x8f\xe4\xb8\xad\xe6\xb2\xa1\xe6\x9c\x89running_reward\n                if \'running_reward\' not in globals():\n                    running_reward = ep_rs_sum\n                else:\n                    running_reward = running_reward * 0.99 + ep_rs_sum * 0.01\n                # \xe5\xbd\x93reward\xe8\xb6\xb3\xe5\xa4\x9f\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xafaction\xe8\xa2\xab\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xb7\xae\xe4\xb8\x8d\xe5\xa4\x9a\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\xb8\xb2\xe6\x9f\x93\xe6\xaf\x8f\xe6\xac\xa1\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\n                if running_reward > DISPLAY_REWARD_THRESHOLD:\n                    RENDER = True\n\n                print(""episode:"", i_episode, ""  reward:"", int(running_reward))\n                # \xe5\xad\xa6\xe4\xb9\xa0, \xe8\xbe\x93\xe5\x87\xba vt\n                vt = RL.learn()\n\n                if i_episode % 100 == 0:\n                    plt.plot(vt)    # plot \xe8\xbf\x99\xe4\xb8\xaa\xe5\x9b\x9e\xe5\x90\x88\xe7\x9a\x84 vt\n                    plt.xlabel(\'episode steps\')\n                    plt.ylabel(\'normalized state-action value\')\n                    plt.show()\n                break\n\n            # \xe5\xa6\x82\xe6\x9e\x9c\xe6\xb8\xb8\xe6\x88\x8f\xe6\xb2\xa1\xe6\x9c\x89\xe7\xbb\x93\xe6\x9d\x9f\xef\xbc\x8c\xe5\xb0\xb1\xe7\xbb\xa7\xe7\xbb\xad\n            observation = observation_\n\n'"
GAN/py/DCGAN.py,11,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import transforms\nfrom torch.utils import data\nimport os\nfrom PIL import Image\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision.utils import save_image\n\n# \xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x9ahttps://pan.baidu.com/s/1eSifHcA \xe6\x8f\x90\xe5\x8f\x96\xe7\xa0\x81\xef\xbc\x9ag5qa\n# \xe8\xbf\x90\xe8\xa1\x8c\xe4\xbb\xa3\xe7\xa0\x81\xe5\x89\x8d\xef\xbc\x8c\xe8\xaf\xb7\xe5\x85\x88\xe7\xa1\xae\xe4\xbf\x9d\xe4\xb8\x8b\xe8\xbd\xbd\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\n\n# \xe6\x9e\x84\xe5\xbb\xba\xe7\x94\x9f\xe6\x88\x90\xe6\xa8\xa1\xe5\x9e\x8b\nclass Generator(nn.Module):\n    def __init__(self, noise_dim=100, conv_dim=64, g_img_size=64):\n        super(Generator, self).__init__()\n        self.fc = nn.ConvTranspose2d(noise_dim, conv_dim*16, kernel_size=int(g_img_size/16), stride=1, padding=0)\n        self.deconv2 = nn.ConvTranspose2d(conv_dim*16, conv_dim*8, kernel_size=4, stride=2, padding=1)\n        self.bn2 = nn.BatchNorm2d(conv_dim * 8)\n        self.deconv3 = nn.ConvTranspose2d(conv_dim*8, conv_dim*4, kernel_size=4, stride=2, padding=1)\n        self.bn3 = nn.BatchNorm2d(conv_dim * 4)\n        self.deconv4 = nn.ConvTranspose2d(conv_dim*4, conv_dim*2, kernel_size=4, stride=2, padding=1)\n        self.bn4 = nn.BatchNorm2d(conv_dim * 2)\n        self.deconv5 = nn.ConvTranspose2d(conv_dim*2, 3, kernel_size=4, stride=2, padding=1)\n\n\n    def forward(self, x):\n        x = x.view(x.size(0), x.size(1), 1, 1)\n        A1 = self.fc(x)\n        A2 = F.relu(self.bn2(self.deconv2(A1)))\n        A3 = F.relu(self.bn3(self.deconv3(A2)))\n        A4 = F.relu(self.bn4(self.deconv4(A3)))\n        y_hat = F.tanh(self.deconv5(A4))\n        return y_hat\n\n# \xe6\x9e\x84\xe5\xbb\xba\xe5\x88\xa4\xe5\x88\xab\xe6\xa8\xa1\xe5\x9e\x8b\nclass Discriminator(nn.Module):\n    def __init__(self, input_chanel=3, conv_dim=64, d_img_size=64):\n        super(Discriminator, self).__init__()\n        self.conv1 = nn.Conv2d(input_chanel, conv_dim * 2, kernel_size=4, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(conv_dim * 2, conv_dim * 4, kernel_size=4, stride=2, padding=1)\n        self.bn2 = nn.BatchNorm2d(conv_dim * 4)\n        self.conv3 = nn.Conv2d(conv_dim * 4, conv_dim * 8, kernel_size=4, stride=2, padding=1)\n        self.bn3 = nn.BatchNorm2d(conv_dim * 8)\n        self.conv4 = nn.Conv2d(conv_dim * 8, conv_dim * 16, kernel_size=4, stride=2, padding=1)\n        self.bn4 = nn.BatchNorm2d(conv_dim * 16)\n        self.fc = nn.Conv2d(conv_dim * 16, 1, int(d_img_size / 16), 1, 0)\n\n    def forward(self, x):\n        A1 = F.leaky_relu(self.conv1(x))\n        A2 = F.leaky_relu(self.bn2(self.conv2(A1)), 0.05)\n        A3 = F.leaky_relu(self.bn3(self.conv3(A2)), 0.05)\n        A4 = F.leaky_relu(self.bn4(self.conv4(A3)), 0.05)\n        y_hat = F.sigmoid(self.fc(A4).squeeze())\n        return y_hat\n\n\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xa4\x84\xe7\x90\x86\nclass ImageDataset(data.Dataset):\n    def __init__(self, path, transform=None):\n        """"""\n            path \xe6\x98\xaf\xe5\xad\x98\xe5\x9c\xa8\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xe3\x80\x82\n        """"""\n        self.images = list(map(lambda x: os.path.join(path, x), os.listdir(path)))\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image_file = self.images[index]\n        image = Image.open(image_file).convert(\'RGB\')\n        if self.transform is not None:\n            image = self.transform(image)\n        return image\n\n    def __len__(self):\n        return len(self.images)\n\n\ndef get_dataset(path, img_scale, batch_size):\n    transform = transforms.Compose([\n        transforms.Resize(img_scale),\n        # \xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8 Scale\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    dataset = ImageDataset(path, transform)\n    data_loader = data.DataLoader(dataset=dataset,\n                                  batch_size=batch_size,\n                                  shuffle=True,\n                                  drop_last=True)\n    return data_loader\n\n\n\n# \xe5\xb7\xa5\xe5\x85\xb7\xe5\x87\xbd\xe6\x95\xb0:\n\n# \xe7\x94\x9f\xe6\x88\x90 \xe5\x99\xaa\xe9\x9f\xb3 z\ndef gen_noisy(batch_size, noisy_dim):\n    return torch.randn(batch_size, noisy_dim)\n\n\n# tensor to variable\ndef to_variable(x):\n    x = Variable(x)\n    if torch.cuda.is_available():\n        x = x.cuda()\n    return x\n\n\n\n# \xe8\xbf\x99\xe9\x87\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x80\xe4\xb8\xaa Config \xe7\xb1\xbb\xef\xbc\x8c\xe7\x94\xa8\xe6\x9d\xa5\xe4\xbf\x9d\xe5\xad\x98\xe8\xbf\x99\xe4\xba\x9b\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nclass Config(object):\n    def __init__(self):\n        self.batch_size = 128\n        self.image_path = \'./faces/\' # \xe5\x9b\xbe\xe5\x83\x8f\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x98\xe6\x94\xbe\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe9\x9c\x80\xe8\xa6\x81\xe8\xaf\xb7\xe8\x87\xaa\xe8\xa1\x8c\xe8\xb0\x83\xe6\x95\xb4\xe3\x80\x82\n        self.noisy_dim = 100\n        self.G_lr = 2*1e-6\n        self.D_lr = 2*1e-6\n        self.EPOCH = 500\n        self.img_scale = 64\n        self.k_step = 5\n        self.use_gpu = True\n        self.g_img_size = 64\n        self.d_img_size = 64\n\n\n\n# \xe8\xae\xad\xe7\xbb\x83\xe9\x98\xb6\xe6\xae\xb5 \xe5\x9c\xa8\xe6\xad\xa3\xe5\xbc\x8f\xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\xe5\x89\x8d\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x85\x88\xe6\x9d\xa5\xe7\x9c\x8b\xe7\x9c\x8b\xe5\x86\x99\xe5\xae\x8c\xe7\x9a\x84 Generator \xe5\x92\x8c Discriminator\nconfig = Config()\n\nG = Generator(noise_dim=config.noisy_dim, g_img_size=config.g_img_size)\nif config.use_gpu:\n    G = G.cuda()\n    \nD = Discriminator(d_img_size=config.d_img_size)\nif config.use_gpu:\n    D = D.cuda()\n\nprint(""Generator\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\xe6\x98\xaf\xef\xbc\x9a"")\nprint(G)\nprint(""Discriminator\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\xe6\x98\xaf\xef\xbc\x9a"")\nprint(D)\n\n\n# \xe6\xad\xa3\xe5\xbc\x8f\xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe9\x98\xb6\xe6\xae\xb5\xef\xbc\x9a\n\ntrain_data_loader = get_dataset(config.image_path, config.img_scale, config.batch_size)\nloss_fn = torch.nn.BCELoss()\ng_optimizer = optim.Adam(G.parameters(), lr=config.G_lr)\nd_optimizer = optim.Adam(D.parameters(), lr=config.D_lr)\n\nfor epoch in range(config.EPOCH):\n    g_total_loss = torch.FloatTensor([0])\n    d_total_loss = torch.FloatTensor([0])\n    count = 0\n    \n    for i, data in enumerate(train_data_loader):\n        count += 1\n        true_inputs = data\n        images = to_variable(true_inputs)\n        batch_size = images.size(0)\n\n        z = to_variable(gen_noisy(batch_size, config.noisy_dim))\n\n        real_labels = to_variable(torch.ones(batch_size))\n        fake_labels = to_variable(torch.zeros(batch_size))\n\n\n        ###          train D           ###\n        outputs = D(images)\n        d_loss_real = loss_fn(outputs, real_labels)\n        real_score = outputs\n\n        fake_images = G(z)\n        outputs = D(fake_images)\n        d_loss_fake = loss_fn(outputs, fake_labels)\n        fake_score = outputs\n\n        d_loss = d_loss_real + d_loss_fake\n        # count total loss\n        d_total_loss += d_loss.data[0]\n        D.zero_grad()\n        d_loss.backward()\n        d_optimizer.step()\n\n\n        ###          train G           ###\n        z = to_variable(gen_noisy(batch_size, config.noisy_dim))\n        fake_images = G(z)\n        outputs = D(fake_images)\n        g_loss = loss_fn(outputs, real_labels)\n        g_total_loss += g_loss.data[0]\n        G.zero_grad()\n        g_loss.backward()\n        g_optimizer.step()\n\n        if (i + 1) % 150 == 0:\n            print(\'Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, \'\n                  \'g_loss: %.4f, D(x): %.2f, D(G(z)): %.2f\'\n                  % (epoch+1, config.EPOCH, i + 1, count, d_loss.data[0], g_loss.data[0],\n                     real_score.data.mean(), fake_score.data.mean()))\n    print(\'Epoch [%d/%d]\'% (epoch, config.EPOCH))\n    print(\'D \xe7\x9a\x84 total loss\', d_total_loss / count)\n    print(\'G \xe7\x9a\x84 total loss\', g_total_loss / count)\n    # Save real images\n\n    fake_images = fake_images.view(fake_images.size(0), 3, 64, 64)\n    # \xe6\xb3\xa8\xe6\x84\x8f \xe8\xbf\x99\xe9\x87\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x9b\xe5\xbb\xba test_DCGAN \xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xef\xbc\x8c\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\n    save_image(fake_images.data, \'./test_DCGAN/fake_images-%d.png\' % (epoch + 1))\n\n\n\n\n\n\n\n'"
GAN/py/GAN.py,13,"b""import torch\nimport torch.nn as nn\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\n\n# \xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nDOWNLOAD = True\nuse_GPU = torch.cuda.is_available()\nLearning_Rate = 0.0003\nEPOCH = 200\n\n# \xe5\x9b\xbe\xe5\x83\x8f\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\ntransform = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n\n# \xe4\xbd\xbf\xe7\x94\xa8 MNIST \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\nmnist = datasets.MNIST(root='./data/', train=True, transform=transform, download=DOWNLOAD)\n\n# \xe5\x8c\x85\xe8\xa3\x85\xe6\x88\x90 DataLoader\ndata_loader = DataLoader(dataset=mnist, batch_size=100, shuffle=True)\n\n# Discriminator Model\nD = nn.Sequential(\n    nn.Linear(784, 256),\n    nn.LeakyReLU(0.2),\n    nn.Linear(256, 256),\n    nn.LeakyReLU(0.2),\n    nn.Linear(256, 1),\n    nn.Sigmoid())\n\nif use_GPU:\n    D = D.cuda()\n\n# Generator Model\nG = nn.Sequential(\n    nn.Linear(64, 256),\n    nn.LeakyReLU(0.2),\n    nn.Linear(256, 256),\n    nn.LeakyReLU(0.2),\n    nn.Linear(256, 784),\n    nn.Tanh())\n\n\n\nif use_GPU:\n    G = G.cuda()\n\n\n# Loss and Optimizer\nloss_fn = nn.BCELoss()\n\nd_optimizer = torch.optim.Adam(D.parameters(), lr=Learning_Rate)\ng_optimizer = torch.optim.Adam(G.parameters(), lr=Learning_Rate)\n\n\n# Tensor to Variable\ndef to_var(x):\n    if torch.cuda.is_available():\n        x = x.cuda()\n    return Variable(x)\n\n# start training\nfor epoch in range(EPOCH):\n    for i, (images, _) in enumerate(data_loader):\n        batch_size = images.size(0)\n        images = to_var(images.view(batch_size, -1))\n\n        # \xe7\xbb\x99\xe5\x87\xba\xe6\xad\xa3\xe6\xa0\x87\xe7\xad\xbe\xe5\x92\x8c\xe8\xb4\x9f\xe6\xa0\x87\xe7\xad\xbe\n        real_labels = to_var(torch.ones(batch_size))\n        fake_labels = to_var(torch.zeros(batch_size))\n\n        ###             \xe8\xae\xad\xe7\xbb\x83 Discriminatro               ###\n        # BCEloss(x, y) = -y * log(D(x)) - (1-y) * log(1 - D(x))\n        # \xe5\xbd\x93\xe5\x89\x8d y = 1\xef\xbc\x8c \xe9\x82\xa3\xe4\xb9\x88\xe6\x88\x91\xe4\xbb\xac\xe6\xb1\x82\xe5\xbe\x97\xe7\x9a\x84Loss = -y * log(D(x)) \xe5\x85\xb6\xe4\xb8\xad x \xe6\x9d\xa5\xe8\x87\xaa\xe4\xba\x8e\xe7\x9c\x9f\xe5\xae\x9e\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n        outputs = D(images)\n        d_loss_real = loss_fn(outputs, real_labels)\n        real_score = outputs\n\n        # \xe5\xbd\x93\xe5\x89\x8d y = 0\xef\xbc\x8c \xe9\x82\xa3\xe4\xb9\x88\xe6\x88\x91\xe4\xbb\xac\xe6\xb1\x82\xe5\xbe\x97\xe7\x9a\x84Loss = -(1-y) * log(1-D(x)) \xe5\x85\xb6\xe4\xb8\xad x \xe6\x9d\xa5\xe8\x87\xaa\xe7\x94\x9f\xe6\x88\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n        z = to_var(torch.randn(batch_size, 64))\n        fake_images = G(z)\n        outputs = D(fake_images)\n        d_loss_fake = loss_fn(outputs, fake_labels)\n        fake_score = outputs\n\n        # \xe6\x8d\x9f\xe5\xa4\xb1\xe8\xae\xa1\xe7\xae\x97\xe5\xae\x8c\xe6\x88\x90\xef\xbc\x8c\xe5\xbc\x80\xe5\xa7\x8b\xe6\x96\xb9\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\n        d_loss = d_loss_real + d_loss_fake\n        D.zero_grad()\n        d_loss.backward()\n        d_optimizer.step()\n\n\n        ###             \xe8\xae\xad\xe7\xbb\x83 Generator               ###\n        z = to_var(torch.randn(batch_size, 64))\n        fake_images = G(z)\n        outputs = D(fake_images)\n\n\n        # \xe6\x9c\xac\xe6\x9d\xa5\xe6\x88\x91\xe4\xbb\xac\xe5\xba\x94\xe8\xaf\xa5\xe6\x98\xaf\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae \xe4\xbd\xbf\xe5\xbe\x97 log(D(G(z))) \xe6\x9c\x80\xe5\xa4\xa7\xe5\x8c\x96\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x87\x87\xe5\x8f\x96 minimzing log(1 - D(G(z)))\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe6\x9d\xa5\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xbb\xa3\xe6\x9b\xbf\n        # \xe8\xbf\x99\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x86\xe6\xad\xa4\xe6\x97\xb6\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\xe7\x9c\x8b\xe6\x88\x90\xe6\xad\xa3\xe4\xbe\x8b\xe5\x8d\xb3\xe5\x8f\xaf\xe3\x80\x82\n        g_loss = loss_fn(outputs, real_labels)\n\n\n        # \xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\n        D.zero_grad()\n        G.zero_grad()\n        g_loss.backward()\n        g_optimizer.step()\n\n\n        if (i + 1) % 300 == 0:\n            print('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, '\n                  'g_loss: %.4f, D(x): %.2f, D(G(z)): %.2f'\n                  % (epoch, 200, i + 1, 600, d_loss.data[0], g_loss.data[0],\n                     real_score.data.mean(), fake_score.data.mean()))\n\n    # Save real images\n    if (epoch + 1) == 1:\n        images = images.view(images.size(0), 1, 28, 28)\n        save_image((images.data), './data/test_GAN/real_images.png')\n\n    # Save sampled images\n    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n    save_image((fake_images.data), './data/test_GAN/fake_images-%d.png' % (epoch + 1))\n\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe8\xae\xad\xe7\xbb\x83\xe5\x8f\x82\xe6\x95\xb0\ntorch.save(G.state_dict(), './generator.pkl')\ntorch.save(D.state_dict(), './discriminator.pkl')\n"""
GAN/py/VAE.py,12,"b'import torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torch.utils import data\nimport os\nfrom PIL import Image\nimport torch.nn.functional as F\nfrom torchvision.utils import save_image\nimport torchvision\n\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe9\x98\xb6\xe6\xae\xb5\nclass ImageDataset(data.Dataset):\n    def __init__(self, path, transform=None):\n        """"""\n            path \xe6\x98\xaf\xe4\xbf\x9d\xe5\xad\x98\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xe3\x80\x82\n        """"""\n        self.images = list(map(lambda x: os.path.join(path, x), os.listdir(path)))\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image_file = self.images[index]\n        image = Image.open(image_file).convert(\'RGB\')\n        if self.transform is not None:\n            image = self.transform(image)\n        return image\n\n    def __len__(self):\n        return len(self.images)\n\n# \xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\ndef get_dataset(path, img_scale, batch_size):\n    # \xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x8c\xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x8a\x8a\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe4\xb8\xad\xe5\xa4\xae\xe8\xa3\x81\xe5\x89\xaa\xe5\x88\xb0 64x64 \xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\n    transform = transforms.Compose([\n        transforms.CenterCrop((img_scale, img_scale)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    datasets = ImageDataset(path, transform)\n    data_loader = data.DataLoader(dataset=datasets,\n                                  batch_size=batch_size,\n                                  shuffle=True,\n                                  drop_last=True)\n    return data_loader\n\n\n\n# \xe8\xbf\x99\xe9\x87\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x80\xe4\xb8\xaa Config \xe7\xb1\xbb\xef\xbc\x8c\xe7\x94\xa8\xe6\x9d\xa5\xe4\xbf\x9d\xe5\xad\x98\xe8\xbf\x99\xe4\xba\x9b\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nclass Config(object):\n    def __init__(self):\n        self.batch_size = 128\n        self.image_path = \'./celebA/\'  # \xe5\x9b\xbe\xe5\x83\x8f\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x98\xe6\x94\xbe\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe9\x9c\x80\xe8\xa6\x81\xe8\xaf\xb7\xe8\x87\xaa\xe8\xa1\x8c\xe8\xb0\x83\xe6\x95\xb4\xe3\x80\x82\n        self.z_dim = 512  # \xe9\x9a\x90\xe5\x90\xab\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\n        self.lr = 2*1e-6\n        self.EPOCH = 1000\n        self.img_scale = 64\n        self.use_gpu = torch.cuda.is_available()\n\n# VAE Model\nclass VAE(nn.Module):\n    def __init__(self, input_chanel=3, z_dim=512, img_size=64):\n        super(VAE, self).__init__()\n        self.z_dim = z_dim\n        # encoder part\n        self.encoder_conv1 = nn.Conv2d(input_chanel, z_dim//16, kernel_size=4, stride=2, padding=1)\n        self.encoder_bn1 = nn.BatchNorm2d(z_dim//16)\n        self.encoder_conv2 = nn.Conv2d(z_dim//16, z_dim//8, kernel_size=4, stride=2, padding=1)\n        self.encoder_bn2 = nn.BatchNorm2d(z_dim//8)\n        self.encoder_conv3 = nn.Conv2d(z_dim//8, z_dim//4, kernel_size=4, stride=2, padding=1)\n        self.encoder_bn3 = nn.BatchNorm2d(z_dim//4)\n        self.encoder_conv4 = nn.Conv2d(z_dim//4, z_dim//2, kernel_size=4, stride=2, padding=1)\n        self.encoder_bn4 = nn.BatchNorm2d(z_dim//2)\n        self.encoder_conv5 = nn.Conv2d(z_dim//2, z_dim, kernel_size=4, stride=2, padding=1)\n        self.encoder_bn5 = nn.BatchNorm2d(z_dim)\n        self.encoder_avg_pooling = nn.AvgPool2d(kernel_size=(2, 2))\n        self.encoder_means = nn.Linear(z_dim, z_dim)\n        self.encoder_log_var = nn.Linear(z_dim, z_dim)\n        #decoder part\n        self.decoder_conv1 = nn.ConvTranspose2d(z_dim, z_dim//2, kernel_size=4, stride=1, padding=0)\n        self.decoder_bn1 = nn.BatchNorm2d(z_dim//2)\n        self.decoder_conv2 = nn.ConvTranspose2d(z_dim//2, z_dim//4, kernel_size=4, stride=2, padding=1)\n        self.decoder_bn2 = nn.BatchNorm2d(z_dim//4)\n        self.decoder_conv3 = nn.ConvTranspose2d(z_dim//4, z_dim//8, kernel_size=4, stride=2, padding=1)\n        self.decoder_bn3 = nn.BatchNorm2d(z_dim//8)\n        self.decoder_conv4 = nn.ConvTranspose2d(z_dim//8, z_dim//16, kernel_size=4, stride=2, padding=1)\n        self.decoder_bn4 = nn.BatchNorm2d(z_dim//16)\n        self.decoder_conv5 = nn.ConvTranspose2d(z_dim//16, 3, kernel_size=4, stride=2, padding=1)\n        self.decoder_linear = nn.Linear(z_dim, z_dim)\n\n    def encode(self, x):\n        x1 = F.leaky_relu(self.encoder_bn1(self.encoder_conv1(x)), negative_slope=0.2)\n        x2 = F.leaky_relu(self.encoder_bn2(self.encoder_conv2(x1)), negative_slope=0.2)\n        x3 = F.leaky_relu(self.encoder_bn3(self.encoder_conv3(x2)), negative_slope=0.2)\n        x4 = F.leaky_relu(self.encoder_bn4(self.encoder_conv4(x3)), negative_slope=0.2)\n        x5 = F.leaky_relu(self.encoder_bn5(self.encoder_conv5(x4)), negative_slope=0.2)\n        x6 = self.encoder_avg_pooling(x5)  # batch*z_dim*1*1\n        encoder_means = self.encoder_means(x6.view(-1, self.z_dim))\n        encoder_log_var = self.encoder_log_var(x6.view(-1, self.z_dim))\n        return encoder_means, encoder_log_var\n\n\n    def decode(self, z):\n        # z: batch * z_dim -> batch * z_dim * 1 * 1\n        z_f = self.decoder_linear(z)\n        z0 = z_f.view(-1, self.z_dim, 1, 1)\n        z1 = F.relu(self.decoder_bn1(self.decoder_conv1(z0)))\n        z2 = F.relu(self.decoder_bn2(self.decoder_conv2(z1)))\n        z3 = F.relu(self.decoder_bn3(self.decoder_conv3(z2)))\n        z4 = F.relu(self.decoder_bn4(self.decoder_conv4(z3)))\n        z5 = torch.tanh(self.decoder_conv5(z4))\n        return z5\n\n    # \xe9\x87\x8d\xe5\x8f\x82\xe6\x95\xb0\xe6\x8a\x80\xe5\xb7\xa7\xef\xbc\x9a\xe6\x9c\xac\xe8\xb4\xa8\xe4\xb8\x8a\xe5\xb0\xb1\xe6\x98\xaf\xe9\x81\xbf\xe5\x85\x8d\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbb\x8e N(mu, sigma) \xe4\xb8\xad\xe9\x87\x87\xe6\xa0\xb7\xef\xbc\x9b \xe8\x80\x8c\xe6\x98\xaf\xe4\xbb\x8e N(0, 1) \xe4\xb8\xad\xe9\x87\x87\xe6\xa0\xb7 \xe5\xbe\x97\xe5\x88\xb0 epsilon\n    # \xe7\x84\xb6\xe5\x90\x8e\xe4\xbb\xa4 epsilon * variance + means \xe4\xb9\x9f\xe5\xb0\xb1\xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8e\xe4\xbb\x8e N(mu, sigma) \xe4\xb8\xad\xe9\x87\x87\xe6\xa0\xb7\n    def reparameterize(self, z_means, z_log_var):\n        var = torch.exp(z_log_var/2)  # log(sigma^2) -> sigma\n        epsilon = torch.randn_like(z_means)  # \xe4\xbb\x8e\xe6\xa0\x87\xe5\x87\x86\xe6\xad\xa3\xe6\x80\x81\xe5\x88\x86\xe5\xb8\x83\xe4\xb8\xad\xe9\x87\x87\xe6\xa0\xb7 epsilon\n        return z_means + var * epsilon\n\n\n    def forward(self, x):\n        # \xe9\x80\x9a\xe8\xbf\x87 encoder \xe6\xb1\x82\xe5\x87\xba\xe5\x9d\x87\xe5\x80\xbc\xe5\x92\x8c log(\xe6\x96\xb9\xe5\xb7\xae)\n        z_means, z_log_var = self.encode(x)  # batch*z_dim\n        z = self.reparameterize(z_means, z_log_var)\n        # \xe5\xb0\x86\xe9\x87\x87\xe6\xa0\xb7\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbf\x9b\xe8\xa1\x8c\xe9\x87\x8d\xe6\x9e\x84\n        x_reconst = self.decode(z)\n        return x_reconst, z_means, z_log_var\n\n\n\nconfig = Config()\n\ntrain_data_loader = get_dataset(config.image_path, config.img_scale, config.batch_size)\n\n# \xe5\x9c\xa8\xe5\xbd\x93\xe5\x89\x8d\xe7\x9b\xae\xe5\xbd\x95\xe4\xb8\x8b\xe5\x88\x9b\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa samples \xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xef\xbc\x8c\xe7\x94\xa8\xe6\x9d\xa5\xe4\xbf\x9d\xe5\xad\x98\xe9\x87\x87\xe6\xa0\xb7\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe3\x80\x82\nsample_dir = \'samples\'\nif not os.path.exists(sample_dir):\n    os.makedirs(sample_dir)\n\n\nmodel = VAE()\nif config.use_gpu:\n    model = model.cuda()\n\n# Loss and Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n\n# Start training\nfor epoch in range(config.EPOCH):\n    for i, data in enumerate(train_data_loader):\n        # Forward pass\n        x = data\n        # x_reconst, mu, log_var = model(x)\n        x_reconst, z_means, z_log_var = model(x)\n\n        # reconstruction loss\n        reconst_loss = F.mse_loss(x_reconst, x, reduction=""sum"")\n\n        # kl divergence\n        kl_div = - 0.5 * torch.sum(1 + z_log_var - z_means.pow(2) - z_log_var.exp())\n\n        # Backprop and optimize\n        loss = reconst_loss + kl_div\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (i + 1) % 10 == 0:\n            print(""Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}""\n                  .format(epoch + 1, config.EPOCH\n                          , i + 1, len(train_data_loader), reconst_loss.item(), kl_div.item()))\n\n    \n    # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x87\x87\xe6\xa0\xb7\xe4\xbf\x9d\xe5\xad\x98\xe5\x9b\xbe\xe7\x89\x87\n    with torch.no_grad():\n        # \xe4\xbf\x9d\xe5\xad\x98\xe9\x87\x87\xe6\xa0\xb7\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\n        z = torch.randn(config.batch_size, config.z_dim)\n        out = model.decode(z).view(-1, 3, 64, 64)\n        save_image(out, os.path.join(sample_dir, \'sampled-{}.png\'.format(epoch+1)))\n\n        # \xe4\xbf\x9d\xe5\xad\x98\xe9\x87\x8d\xe6\x9e\x84\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\x92\x8c\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe7\x89\x87\n        out, _, _ = model(x)\n        x_concat = torch.cat([x.view(-1, 3, 64, 64), out.view(-1, 3, 64, 64)], dim=3)\n        save_image(x_concat, os.path.join(sample_dir, \'reconst-{}.png\'.format(epoch+1)))\n\n'"
NLP/py/attention.py,12,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch import optim\nimport torch.nn.functional as F\nimport unicodedata, string, re, random, time, math\n\n\n\nclass Config():\n    def __init__(self):\n        self.data_path = ""../data/cmn-eng/cmn.txt"" # \xe6\x95\xb0\xe6\x8d\xae\xe6\x94\xbe\xe5\x9c\xa8 /data \xe7\x9b\xae\xe5\xbd\x95\xe4\xb8\x8b\n        self.use_gpu = True\n        self.hidden_size = 128\n        self.encoder_lr = 5*1e-4\n        self.decoder_lr = 5*1e-4\n        self.train_num = 150000 # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\x95\xb0\xe7\x9b\xae\n        self.print_epoch = 10000\n        self.MAX_Len = 15\nconfig = Config()\n\n\nSOS_token = 0\nEOS_token = 1\n\nclass Lang():\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.index2word = {0: ""SOS"", 1: ""EOS""}\n        self.word2count = {}\n        self.n_words = 2  # Count SOS and EOS\n    \n    def addSentence(self, sentence):\n        if self.name == ""Chinese"":\n            for word in sentence:\n                self.addWord(word)\n        else:\n            for word in sentence.split(\' \'):\n                self.addWord(word)\n    \n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1\n\n\ndef unicodeToAscii(s):\n    return \'\'.join(\n        c for c in unicodedata.normalize(\'NFD\', s)\n        if unicodedata.category(c) != \'Mn\'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    return s\n\n\n\ndef readLangs(lang1, lang2, pairs_file, reverse=False):\n    print(""Reading lines..."")\n\n    # Read the file and split into lines\n    lines = open(pairs_file, encoding=\'utf-8\').read().strip().split(\'\\n\')\n    # Split every line into pairs and normalize\n    pairs = []\n    for l in lines:\n        temp = l.split(\'\\t\')\n        eng_unit = normalizeString(temp[0])\n        chinese_unit = temp[1]\n        pairs.append([eng_unit, chinese_unit])\n    \n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n        \n    return input_lang, output_lang, pairs\n\nMAX_LENGTH = config.MAX_Len  # \xe9\x95\xbf\xe5\xba\xa6\xe5\xa4\xa7\xe4\xba\x8e15\xe7\x9a\x84\xe6\x88\x91\xe4\xbb\xac\xe7\xbb\x9f\xe7\xbb\x9f\xe8\x88\x8d\xe5\xbc\x83\n\neng_prefixes = (\n    ""i am "", ""i m "",\n    ""he is"", ""he s "",\n    ""she is"", ""she s"",\n    ""you are"", ""you re "",\n    ""we are"", ""we re "",\n    ""they are"", ""they re "",\n    ""i"", ""he"", \'you\', \'she\', \'we\',\n    \'they\', \'it\'\n)\n\ndef filterPair(p):\n    return len(p[0].split(\' \')) < MAX_LENGTH and \\\n        len(p[1]) < MAX_LENGTH and \\\n        p[0].startswith(eng_prefixes)\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]\n\n\ndef prepareData(lang1, lang2, pairs_file, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, pairs_file, reverse)\n    print(""Read %s sentence pairs"" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(""Trimmed to %s sentence pairs"" % len(pairs))\n    print(""Counting words..."")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(""Counted words:"")\n    print(input_lang.name, ""\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xb8\xba"", str(input_lang.n_words))\n    print(output_lang.name, ""\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xb8\xba"", str(output_lang.n_words))\n    return input_lang, output_lang, pairs\n\ninput_lang, output_lang, pairs = prepareData(\'Eng\', \'Chinese\', config.data_path)\nprint(random.choice(pairs))\n\n\ndef indexesFromSentence(lang, sentence):\n    if lang.name == ""Chinese"":\n        return [lang.word2index[word] for word in sentence]\n    else:\n        return [lang.word2index[word] for word in sentence.split(\' \')]\n\ndef variableFromSentence(lang, sentence, use_gpu):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    result = Variable(torch.LongTensor(indexes).view(-1, 1)) # seq*1\n    if use_gpu:\n        return result.cuda()\n    else:\n        return result\n\ndef variablesFromPair(pair, use_gpu):\n    input_variable = variableFromSentence(input_lang, pair[0], use_gpu)\n    target_variable = variableFromSentence(output_lang, pair[1], use_gpu)\n    return (input_variable, target_variable)\n\n\n\n# \xe9\x9a\x8f\xe6\x9c\xba\xe8\x8e\xb7\xe5\x8f\x962\xe4\xb8\xaa\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c \xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbe\x9d\xe6\x97\xa7\xe4\xb8\x8d\xe7\x94\xa8\xe8\xbf\x9b\xe8\xa1\x8c batch \xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe4\xb8\x8b\xe4\xb8\x80\xe7\xab\xa0\xe8\x8a\x82 attention \xe6\x9c\xba\xe5\x88\xb6\xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x86\x8d\xe8\xbf\x9b\xe8\xa1\x8c batch \xe5\xa4\x84\xe7\x90\x86\nexample_pairs = [variablesFromPair(random.choice(pairs), config.use_gpu)\n                      for i in range(2)]\nprint(example_pairs)\n\n\nclass Encoder(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n    \n    def forward(self, x, hidden):\n        embedded = self.embedding(x).view(1, x.size()[0], -1)\n        output = embedded  # batch*seq*feature\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n    \n    def initHidden(self, use_gpu):\n        result = Variable(torch.zeros(1, 1, self.hidden_size))\n        if use_gpu:\n            return result.cuda()\n        else:\n            return result\n\n\n\nclass AttentionDecoder(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n        super(AttentionDecoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n        \n        self.embedding = nn.Embedding(output_size, hidden_size)\n        \n        # attention \xe6\x9c\xba\xe5\x88\xb6\n        self.attn = nn.Sequential(\n            nn.Linear(self.hidden_size * 2, self.max_length),\n            nn.Tanh(),\n            nn.Linear(self.max_length, 1)\n        )\n        \n        # \xe7\xbb\x93\xe5\x90\x88\xe4\xb9\x8b\xe5\x90\x8e\xe7\x9a\x84\xe5\x80\xbc\n        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n        \n        # drop out \xe9\x98\xb2\xe6\xad\xa2\xe8\xbf\x87\xe6\x8b\x9f\xe5\x90\x88\n        self.dropout = nn.Dropout(self.dropout_p)\n        \n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax()\n\n    def forward(self, x, hidden, encoder_outputs):\n        """"""\n            x: 1*1\n            hidden: 1*1*embed_size\n            encoder_outputs: 1*seq_len*embed_size\n        """"""\n        cur_input_data = self.embedding(x).view(1, 1, -1) # 1*1*embed_size\n        \n        cur_seq_len = encoder_outputs.size()[1]\n        hidden_broadcast = hidden.expand(1, cur_seq_len, self.hidden_size)\n        \n        # concate \xe6\x93\x8d\xe4\xbd\x9c\xe6\xa0\xb9\xe6\x8d\xae hidden \xe5\x92\x8c encoder_outputs \xe6\x9d\xa5\xe6\xb1\x82\xe5\x87\xba\xe5\xbd\x93\xe5\x89\x8dcontext\xe7\x8e\xaf\xe5\xa2\x83\xe4\xb8\xad\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\n        encoder_outputs_and_hiddens = torch.cat((encoder_outputs, hidden_broadcast), dim=2)\n\n        # \xe8\xae\xa1\xe7\xae\x97 attention weights\n        attn_weights = F.softmax(\n            self.attn(encoder_outputs_and_hiddens)) # size: 1 * seq_len * 1\n        \n        decoder_context = torch.bmm(attn_weights.view(1, 1, -1), encoder_outputs) # size: 1*1*embed_size\n        \n        # \xe6\x8a\x8a context \xe5\x92\x8c input \xe7\xbb\x93\xe5\x90\x88\xe8\xb5\xb7\xe6\x9d\xa5\n        input_and_context = torch.cat((cur_input_data, decoder_context), dim=2) # size: 1*1*(embed_size+embed_size)\n        \n        concat_input = self.attn_combine(input_and_context) # size: 1*1*embed_size\n      \n        output, hidden = self.gru(concat_input, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden, attn_weights\n\n    def initHidden(self, use_gpu):\n        result = Variable(torch.zeros(1, 1, self.hidden_size))\n        if use_gpu:\n            return result.cuda()\n        else:\n            return result\n\n\n# \xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96\xe6\xa8\xa1\xe5\x9e\x8b\n\nencoder = Encoder(input_lang.n_words, config.hidden_size)\nencoder = encoder.cuda() if config.use_gpu else encoder\n\nattention_decoder = AttentionDecoder(config.hidden_size, input_lang.n_words)\nattention_decoder = attention_decoder.cuda() if config.use_gpu else attention_decoder\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\n\nencoder_optimizer = optim.Adam(encoder.parameters(), lr=config.encoder_lr)\n\ndecoder_optimizer = optim.Adam(attention_decoder.parameters(), lr=config.decoder_lr)\n\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n\nfn_loss = nn.NLLLoss()\n\ntraining_pairs = [variablesFromPair(random.choice(pairs), config.use_gpu)\n                      for i in range(config.train_num)]\n\n\n\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nfor iter in range(1, config.train_num+1):\n    training_pair = training_pairs[iter - 1]\n    input_variable = training_pair[0]  # seq_len * 1\n    target_variable = training_pair[1]  # seq_len * 1\n    \n    loss = 0\n    \n    # \xe5\x9b\xa0\xe4\xb8\xba\xe6\x9c\x89 dropout, \xe6\x89\x80\xe4\xbb\xa5\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe5\x8a\xa0\xe4\xb8\x8a train()\n    encoder.train()\n    attention_decoder.train()\n    \n    # \xe8\xae\xad\xe7\xbb\x83\xe8\xbf\x87\xe7\xa8\x8b\n    encoder_hidden = encoder.initHidden(config.use_gpu)\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_variable.size()[0]\n    target_length = target_variable.size()[0]\n    \n    # \xe4\xbc\xa0\xe5\x85\xa5 encoder\n    encoder_output, encoder_hidden = encoder(input_variable, encoder_hidden)\n    \n    # decoder \xe8\xb5\xb7\xe5\xa7\x8b\n    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n    decoder_input = decoder_input.cuda() if config.use_gpu else decoder_input\n    \n    decoder_hidden = encoder_hidden\n    \n    for di in range(target_length):\n        decoder_output, decoder_hidden, decoder_attention = attention_decoder(decoder_input, decoder_hidden, encoder_output)\n        targ = target_variable[di]\n        loss += fn_loss(decoder_output, targ)\n        decoder_input = targ\n    \n    # \xe5\x8f\x8d\xe5\x90\x91\xe6\xb1\x82\xe5\xaf\xbc\n    loss.backward()\n    # \xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n    \n    print_loss = loss.data[0] / target_length\n    \n    if iter % config.print_epoch == 0:\n        print(""loss is: %.4f"" % (print_loss))\n\n\ndef sampling(encoder, decoder):\n    # \xe6\xb5\x8b\xe8\xaf\x95\xe6\xa8\xa1\xe5\xbc\x8f\n    encoder.eval()\n    decoder.eval()\n    \n    # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\xa5\xe5\xad\x90\n    pair = random.choice(pairs)\n    print(\'>\', pair[0])\n    print(\'=\', pair[1])\n    # \xe6\x89\x94\xe8\xbf\x9b\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xbf\xbb\xe8\xaf\x91\n    input_variable = variableFromSentence(input_lang, pair[0], config.use_gpu)\n    input_length = input_variable.size()[0]\n    encoder_hidden = encoder.initHidden(config.use_gpu)\n    encoder_output, encoder_hidden = encoder(input_variable, encoder_hidden)\n    \n    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n    decoder_input = decoder_input.cuda() if config.use_gpu else decoder_input\n    decoder_hidden = encoder_hidden\n    \n    decoded_words = []\n    \n    for di in range(config.MAX_Len):\n        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output)\n        topv, topi = decoder_output.data.topk(1)\n        ni = topi[0][0]\n        if ni == EOS_token:\n            decoded_words.append(\'<EOS>\')\n            break\n        else:\n            decoded_words.append(output_lang.index2word[ni])\n        # \xe6\x8a\x8a\xe5\xbd\x93\xe5\x89\x8d\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\xbd\x93\xe5\x81\x9a\xe8\xbe\x93\xe5\x85\xa5\n        decoder_input = Variable(torch.LongTensor([ni]))\n        decoder_input = decoder_input.cuda() if config.use_gpu else decoder_input\n        \n    # \xe5\xaf\xb9 decoded_words \xe8\xbf\x9b\xe8\xa1\x8c\xe8\xbf\x9e\xe6\x8e\xa5\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\n    output_sentence = \' \'.join(decoded_words)\n    print(\'<\', output_sentence)\n    print(\'\')\n\n\nfor i in range(10):\n    sampling(encoder, attention_decoder)\n'"
NLP/py/encoder_decoder.py,9,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch import optim\nimport torch.nn.functional as F\nimport unicodedata, string, re, random, time, math\n\n\n\nclass Config():\n    def __init__(self):\n        self.data_path = ""../data/cmn-eng/cmn.txt""\n        self.use_gpu = True\n        self.hidden_size = 256\n        self.encoder_lr = 5*1e-5\n        self.decoder_lr = 5*1e-5\n        self.train_num = 100000 # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\x95\xb0\xe7\x9b\xae\n        self.print_epoch = 10000\n        self.MAX_Len = 15\nconfig = Config()\n\n\nSOS_token = 0\nEOS_token = 1\n\nclass Lang():\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.index2word = {0: ""SOS"", 1: ""EOS""}\n        self.word2count = {}\n        self.n_words = 2  # Count SOS and EOS\n    \n    def addSentence(self, sentence):\n        if self.name == ""Chinese"":\n            for word in sentence:\n                self.addWord(word)\n        else:\n            for word in sentence.split(\' \'):\n                self.addWord(word)\n    \n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1\n\ndef unicodeToAscii(s):\n    return \'\'.join(\n        c for c in unicodedata.normalize(\'NFD\', s)\n        if unicodedata.category(c) != \'Mn\'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    return s\n\n\n\ndef readLangs(lang1, lang2, pairs_file, reverse=False):\n    print(""Reading lines..."")\n\n    # Read the file and split into lines\n    lines = open(pairs_file, encoding=\'utf-8\').read().strip().split(\'\\n\')\n    # Split every line into pairs and normalize\n    pairs = []\n    for l in lines:\n        temp = l.split(\'\\t\')\n        eng_unit = normalizeString(temp[0])\n        chinese_unit = temp[1]\n        pairs.append([eng_unit, chinese_unit])\n    \n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n        \n    return input_lang, output_lang, pairs\n\n\n\nMAX_LENGTH = config.MAX_Len  # \xe9\x95\xbf\xe5\xba\xa6\xe5\xa4\xa7\xe4\xba\x8e15\xe7\x9a\x84\xe6\x88\x91\xe4\xbb\xac\xe7\xbb\x9f\xe7\xbb\x9f\xe8\x88\x8d\xe5\xbc\x83\n\neng_prefixes = (\n    ""i am "", ""i m "",\n    ""he is"", ""he s "",\n    ""she is"", ""she s"",\n    ""you are"", ""you re "",\n    ""we are"", ""we re "",\n    ""they are"", ""they re "",\n    ""i"", ""he"", \'you\', \'she\', \'we\',\n    \'they\', \'it\'\n)\n\ndef filterPair(p):\n    return len(p[0].split(\' \')) < MAX_LENGTH and \\\n        len(p[1]) < MAX_LENGTH and \\\n        p[0].startswith(eng_prefixes)\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]\n\n\n\ndef prepareData(lang1, lang2, pairs_file, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, pairs_file, reverse)\n    print(""Read %s sentence pairs"" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(""Trimmed to %s sentence pairs"" % len(pairs))\n    print(""Counting words..."")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(""Counted words:"")\n    print(input_lang.name, ""\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xb8\xba"", str(input_lang.n_words))\n    print(output_lang.name, ""\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xb8\xba"", str(output_lang.n_words))\n    return input_lang, output_lang, pairs\n\ninput_lang, output_lang, pairs = prepareData(\'Eng\', \'Chinese\', config.data_path)\nprint(random.choice(pairs))\n\n\n# \xe5\x88\xb0\xe7\x9b\xae\xe5\x89\x8d\xe4\xb8\xba\xe6\xad\xa2\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb7\xb2\xe7\xbb\x8f\xe6\x8a\x8a\xe5\xad\x97\xe5\x85\xb8\xe6\x9e\x84\xe5\xbb\xba\xe5\xa5\xbd\xe4\xba\x86\xef\xbc\x8c\xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa5\xe5\xb0\xb1\xe6\x98\xaf\xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\n\ndef indexesFromSentence(lang, sentence):\n    if lang.name == ""Chinese"":\n        return [lang.word2index[word] for word in sentence]\n    else:\n        return [lang.word2index[word] for word in sentence.split(\' \')]\n\ndef variableFromSentence(lang, sentence, use_gpu):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    result = Variable(torch.LongTensor(indexes).view(-1, 1)) # seq*1\n    if use_gpu:\n        return result.cuda()\n    else:\n        return result\n\ndef variablesFromPair(pair, use_gpu):\n    input_variable = variableFromSentence(input_lang, pair[0], use_gpu)\n    target_variable = variableFromSentence(output_lang, pair[1], use_gpu)\n    return (input_variable, target_variable)\n\n\n\n\n# \xe9\x9a\x8f\xe6\x9c\xba\xe8\x8e\xb7\xe5\x8f\x962\xe4\xb8\xaa\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c \xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbe\x9d\xe6\x97\xa7\xe4\xb8\x8d\xe7\x94\xa8\xe8\xbf\x9b\xe8\xa1\x8c batch \xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe4\xb8\x8b\xe4\xb8\x80\xe7\xab\xa0\xe8\x8a\x82 attention \xe6\x9c\xba\xe5\x88\xb6\xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x86\x8d\xe8\xbf\x9b\xe8\xa1\x8c batch \xe5\xa4\x84\xe7\x90\x86\nexample_pairs = [variablesFromPair(random.choice(pairs), config.use_gpu)\n                      for i in range(2)]\nprint(example_pairs)\n\n\n\n\n\n# \xe5\xbb\xba\xe6\xa8\xa1\n\nclass Encoder(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n    \n    def forward(self, x, hidden):\n        embedded = self.embedding(x).view(1, x.size()[0], -1)\n        output = embedded  # batch*seq*feature\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n    \n    def initHidden(self, use_gpu):\n        result = Variable(torch.zeros(1, 1, self.hidden_size))\n        if use_gpu:\n            return result.cuda()\n        else:\n            return result\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax()\n\n    def forward(self, x, hidden):\n        output = self.embedding(x).view(1, 1, -1)\n        output = F.relu(output)  \n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self, use_gpu):\n        result = Variable(torch.zeros(1, 1, self.hidden_size))\n        if use_gpu:\n            return result.cuda()\n        else:\n            return result\n\n\n# \xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96\xe6\xa8\xa1\xe5\x9e\x8b\n\nencoder = Encoder(input_lang.n_words, config.hidden_size)\nencoder = encoder.cuda() if config.use_gpu else encoder\n\ndecoder = Decoder(config.hidden_size, input_lang.n_words)\ndecoder = decoder.cuda() if config.use_gpu else decoder\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\n\nencoder_optimizer = optim.Adam(encoder.parameters(), lr=config.encoder_lr)\n\ndecoder_optimizer = optim.Adam(decoder.parameters(), lr=config.decoder_lr)\n\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n\nfn_loss = nn.NLLLoss()\n\ntraining_pairs = [variablesFromPair(random.choice(pairs), config.use_gpu)\n                      for i in range(config.train_num)]\n\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nfor iter in range(1, config.train_num+1):\n    training_pair = training_pairs[iter - 1]\n    input_variable = training_pair[0]  # seq_len * 1\n    target_variable = training_pair[1]  # seq_len * 1\n    \n    loss = 0\n    \n    # \xe8\xae\xad\xe7\xbb\x83\xe8\xbf\x87\xe7\xa8\x8b\n    encoder_hidden = encoder.initHidden(config.use_gpu)\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_variable.size()[0]\n    target_length = target_variable.size()[0]\n    \n    # \xe4\xbc\xa0\xe5\x85\xa5 encoder\n    encoder_output, encoder_hidden = encoder(input_variable, encoder_hidden)\n    \n    # decoder \xe8\xb5\xb7\xe5\xa7\x8b\n    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n    decoder_input = decoder_input.cuda() if config.use_gpu else decoder_input\n    \n    decoder_hidden = encoder_hidden\n    \n    for di in range(target_length):\n        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)          \n        targ = target_variable[di]\n        loss += fn_loss(decoder_output, targ)\n        decoder_input = targ\n    \n    # \xe5\x8f\x8d\xe5\x90\x91\xe6\xb1\x82\xe5\xaf\xbc\n    loss.backward()\n    # \xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n    \n    print_loss = loss.data[0] / target_length\n    \n    if iter % config.print_epoch == 0:\n        print(""loss is: %.4f"" % (print_loss))\n\n\ndef sampling(encoder, decoder):\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\xa5\xe5\xad\x90\n    pair = random.choice(pairs)\n    print(\'>\', pair[0])\n    print(\'=\', pair[1])\n    # \xe6\x89\x94\xe8\xbf\x9b\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xbf\xbb\xe8\xaf\x91\n    input_variable = variableFromSentence(input_lang, pair[0], config.use_gpu)\n    input_length = input_variable.size()[0]\n    encoder_hidden = encoder.initHidden(config.use_gpu)\n    encoder_output, encoder_hidden = encoder(input_variable, encoder_hidden)\n    \n    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n    decoder_input = decoder_input.cuda() if config.use_gpu else decoder_input\n    decoder_hidden = encoder_hidden\n    \n    decoded_words = []\n    \n    for di in range(config.MAX_Len):\n        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n        topv, topi = decoder_output.data.topk(1)\n        ni = topi[0][0]\n        if ni == EOS_token:\n            decoded_words.append(\'<EOS>\')\n            break\n        else:\n            decoded_words.append(output_lang.index2word[ni])\n        # \xe6\x8a\x8a\xe5\xbd\x93\xe5\x89\x8d\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\xbd\x93\xe5\x81\x9a\xe8\xbe\x93\xe5\x85\xa5\n        decoder_input = Variable(torch.LongTensor([ni]))\n        decoder_input = decoder_input.cuda() if config.use_gpu else decoder_input\n        \n    # \xe5\xaf\xb9 decoded_words \xe8\xbf\x9b\xe8\xa1\x8c\xe8\xbf\x9e\xe6\x8e\xa5\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\n    output_sentence = \' \'.join(decoded_words)\n    print(\'<\', output_sentence)\n    print(\'\')\n\n\n\n\nfor i in range(10):\n    sampling(encoder, decoder)'"
NLP/py/lstm.py,12,"b'import torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\nimport numpy as np\n\n\n\nclass Corpus(object):\n    """"""\n        \xe6\x9e\x84\xe5\xbb\xba\xe8\xaf\xad\xe6\x96\x99\xe5\xba\x93\xe7\x9a\x84\xe7\xb1\xbb\n        path: \xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\n    """"""\n    def __init__(self, path):\n        self.path = path\n        self.char2id = {}\n        self.id2char = {}\n        self.corpus_indices = None\n    def get_data(self):\n        with open(self.path, \'r\', encoding=\'utf8\') as f:\n            chars = f.read()\n        chars_list = chars.replace(\'\\n\', \' \').replace(\'\\r\', \' \')\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x88\x9b\xe5\xbb\xba\xe7\xb4\xa2\xe5\xbc\x95 word 2 id\n        idx = 0\n        for char in chars_list:\n            if not char in self.char2id:\n                self.char2id[char] = idx\n                self.id2char[idx] = char\n                idx += 1\n        # \xe5\xb0\x86 corpus \xe9\x87\x8c\xe9\x9d\xa2\xe7\x9a\x84 char \xe7\x94\xa8 index\xe8\xa1\xa8\xe7\xa4\xba\n        self.corpus_indices = [self.char2id[char] for char in chars_list]\n    \n    # \xe8\x8e\xb7\xe5\x8f\x96 corpus \xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\n    def __len__(self):\n        return len(self.char2id)\n\n\n# \xe6\x9e\x84\xe5\xbb\xba Config \xe7\xb1\xbb\xef\xbc\x8c\xe7\x94\xa8\xe4\xba\x8e\xe6\x8e\xa7\xe5\x88\xb6\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nclass Config(object):\n    def __init__(self):\n        self.embed_size = 128 # embedding size\n        self.hidden_size = 1024 # RNN\xe4\xb8\xad\xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xe7\x9a\x84 size\n        self.num_layers = 1 # RNN \xe4\xb8\xad\xe7\x9a\x84\xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xe6\x9c\x89\xe5\x87\xa0\xe5\xb1\x82\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\xbb\x98\xe8\xae\xa4\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba 1\xe5\xb1\x82\n        self.epoch_num = 50 # \xe8\xae\xad\xe7\xbb\x83\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\n        self.sample_num = 10 # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x87\x87\xe6\xa0\xb7\n        self.batch_size = 32 # batch size\n        self.seq_length = 35 # seq length\n        self.lr = 0.002 #learning rate\n        self.path = ""./LSTM/jaychou_lyrics.txt"" # \xe6\xad\x8c\xe8\xaf\x8d\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n        self.prefix = [\'\xe5\x88\x86\xe5\xbc\x80\', \'\xe6\x88\x98\xe4\xba\x89\xe4\xb8\xad\', \'\xe6\x88\x91\xe6\x83\xb3\'] # \xe6\xb5\x8b\xe8\xaf\x95\xe9\x98\xb6\xe6\xae\xb5\xef\xbc\x8c\xe7\xbb\x99\xe5\xae\x9a\xe7\x9a\x84\xe5\x89\x8d\xe7\xbc\x80\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\x94\xa8\xe5\xae\x83\xe6\x9d\xa5\xe7\x94\x9f\xe6\x88\x90\xe6\xad\x8c\xe8\xaf\x8d\n        self.pred_len = 50 # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\xad\x97\xe7\xac\xa6\xe9\x95\xbf\xe5\xba\xa6\n        self.use_gpu = True\n        \nconfig = Config()\n\n# \xe8\xbf\x99\xe9\x87\x8c\xe7\xae\x80\xe5\x8d\x95\xe4\xb8\x80\xe4\xba\x9b\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\x9b\xb4\xe6\x8e\xa5\xe7\x94\xa8\xe4\xb8\x80\xe4\xb8\xaa\xe5\x87\xbd\xe6\x95\xb0\xe6\x9d\xa5\xe4\xbd\x9c\xe4\xb8\xba\xe8\xbf\xad\xe4\xbb\xa3\xe5\x99\xa8\xe7\x94\x9f\xe6\x88\x90\xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\ndef getBatch(corpus_indices, batch_size, seq_length, config):\n    data_len = len(corpus_indices)\n    batch_len = data_len // config.batch_size\n    corpus_indices = torch.LongTensor(corpus_indices)\n    # \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84 size \xe5\x8f\x98\xe6\x88\x90 batch_size x seq_length\n    indices = corpus_indices[0: batch_size * batch_len].view(batch_size, batch_len)\n    for i in range(0, indices.size(1) - seq_length, seq_length):\n        input_data = Variable(indices[:, i: i + seq_length])\n        target_data = Variable(indices[:, (i + 1): (i + 1) + seq_length].contiguous())\n        # use GPU to train the model\n        if config.use_gpu:\n            input_data = input_data.cuda()\n            target_data = target_data.cuda()\n        yield(input_data, target_data)\n\n\n# \xe5\xb0\x86\xe5\xbd\x93\xe5\x89\x8d\xe7\x9a\x84\xe7\x8a\xb6\xe6\x80\x81\xe4\xbb\x8e\xe8\xae\xa1\xe7\xae\x97\xe5\x9b\xbe\xe4\xb8\xad\xe5\x88\x86\xe7\xa6\xbb\xef\xbc\x8c\xe5\x8a\xa0\xe5\xbf\xab\xe8\xae\xad\xe7\xbb\x83\xe9\x80\x9f\xe5\xba\xa6\ndef detach(states):\n    return [state.detach() for state in states] \n\n\n# \xe5\xae\x9a\xe4\xb9\x89 LSTM \xe6\xa8\xa1\xe5\x9e\x8b\nclass lstm(nn.Module):\n    # input: \n    # x: \xe5\xb0\xba\xe5\xaf\xb8\xe4\xb8\xba batch_size * seq_length \xe7\x9f\xa9\xe9\x98\xb5\xe3\x80\x82\n    # hidden: \xe5\xb0\xba\xe5\xaf\xb8\xe4\xb8\xba batch_size * hidden_dim \xe7\x9f\xa9\xe9\x98\xb5\xe3\x80\x82\n    # output:\n    # out: \xe5\xb0\xba\xe5\xaf\xb8\xe4\xb8\xba batch_size * vocab_size \xe7\x9f\xa9\xe9\x98\xb5\xe3\x80\x82\n    # h: \xe5\xb0\xba\xe5\xaf\xb8\xe4\xb8\xba batch_size * hidden_dim \xe7\x9f\xa9\xe9\x98\xb5\xe3\x80\x82\n    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n        super(lstm, self).__init__()\n        self.embed = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n        self.linear = nn.Linear(hidden_size, vocab_size)\n        self.init_weights()\n        \n    def forward(self, x, hidden):\n        embeds = self.embed(x)\n        \n        out, hidden = self.rnn(embeds, hidden)\n\n        out = out.contiguous().view(out.size(0)*out.size(1), -1) # out \xe7\x9a\x84 size \xe5\x8f\x98\xe6\x88\x90 (batch_size*sequence_length, hidden_size)\n        \n        out = self.linear(out) # (batch_size*sequence_length, hidden_size) -> (batch_size*sequence_length, vocab_size)\n        return out, hidden\n    \n    def init_weights(self):\n        self.embed.weight = nn.init.xavier_uniform(self.embed.weight)\n        self.linear.bias.data.fill_(0)\n        self.linear.weight = nn.init.xavier_uniform(self.linear.weight)\n\n\n# \xe6\x9e\x84\xe5\xbb\xba\xe8\xaf\xad\xe6\x96\x99\xe5\xba\x93\ncorpus = Corpus(config.path)\n# \xe5\xa4\x84\xe7\x90\x86 data\ncorpus.get_data()\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\nlstm = lstm(len(corpus), config.embed_size, config.hidden_size, config.num_layers)\n# \xe4\xbd\xbf\xe7\x94\xa8 gpu\nif config.use_gpu:\n    lstm = lstm.cuda()\n\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(lstm.parameters(), lr=config.lr)\n\n\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84 LSTM \xe5\x9c\xa8\xe7\xbb\x99\xe5\xae\x9a\xe5\x89\x8d\xe7\xbc\x80\xe7\x9a\x84\xe5\x89\x8d\xe6\x8f\x90\xe4\xb8\x8b\xef\xbc\x8c\xe8\x87\xaa\xe5\x8a\xa8\xe7\x94\x9f\xe6\x88\x90\xe6\xad\x8c\xe8\xaf\x8d\xe3\x80\x82\ndef predict(model, prefix, config, corpus):\n    """"""\n        model \xe6\x98\xaf\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c prefix\xe6\x98\xaf\xe5\x89\x8d\xe7\xbc\x80\xef\xbc\x8c config \xe6\x98\xaf\xe5\x8f\x82\xe6\x95\xb0\xe7\xb1\xbb\xef\xbc\x8c corpus\xe6\x98\xaf\xe8\xaf\xad\xe6\x96\x99\xe5\xba\x93\xe7\xb1\xbb\n    """"""\n    state_h = Variable(torch.zeros(config.num_layers, 1, config.hidden_size)) # \xe8\xb5\xb7\xe5\xa7\x8b\xe7\x9a\x84hidden status\n    state_c = Variable(torch.zeros(config.num_layers, 1, config.hidden_size)) # \xe8\xb5\xb7\xe5\xa7\x8b\xe7\x9a\x84cell status\n    \n    # use gpu\n    if config.use_gpu:\n        state_h = state_h.cuda()\n        state_c = state_c.cuda()\n    # become a tuple\n    state = (state_h, state_c)\n    output = [corpus.char2id[prefix[0]]]\n    for i in range(config.pred_len + len(prefix)):\n        X = Variable(torch.LongTensor(output)).unsqueeze(0)\n        # use gpu\n        if config.use_gpu:\n            X = X.cuda()\n        Y, state = model(X, state)\n        # \xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\x98\xe6\x88\x90\xe6\xa6\x82\xe7\x8e\x87\xef\xbc\x8c\xe9\x80\x89\xe6\x8b\xa9\xe5\x85\xb6\xe4\xb8\xad\xe6\xa6\x82\xe7\x8e\x87\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe4\xbd\x9c\xe4\xb8\xba\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\x8b\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\n        prob = Y.data[0].exp()\n        word_id = torch.multinomial(prob, 1)[0]\n        if i < len(prefix) - 1:\n            next_char = corpus.char2id[prefix[i+1]]\n        else:\n            next_char = int(word_id)\n        output.append(next_char)\n    print("""".join([corpus.id2char[id] for id in output]))\n    return \n\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nfor epoch in range(config.epoch_num):\n    # \xe7\x94\xb1\xe4\xba\x8e\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf lstm\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96 hidden status \xe5\x92\x8c cell\n    state_h = Variable(torch.zeros(config.num_layers, config.batch_size, config.hidden_size)) # \xe8\xb5\xb7\xe5\xa7\x8b\xe7\x9a\x84hidden status\n    state_c = Variable(torch.zeros(config.num_layers, config.batch_size, config.hidden_size)) # \xe8\xb5\xb7\xe5\xa7\x8b\xe7\x9a\x84cell status\n    # use gpu\n    if config.use_gpu:\n        state_h = state_h.cuda()\n        state_c = state_c.cuda()\n    \n    hidden = (state_h, state_c)\n    \n    train_loss = [] # \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe6\x80\xbb\xe8\xaf\xaf\xe5\xb7\xae\n    \n    for i,batch in enumerate(getBatch(corpus.corpus_indices, config.batch_size, config.seq_length, config)):\n        inputs, targets = batch\n        # Forward + Backward + Optimize\n        lstm.zero_grad()\n        hidden = detach(hidden)\n        \n        outputs, hidden = lstm(inputs, hidden)\n\n        loss = criterion(outputs, targets.view(-1))\n        train_loss.append(loss.data[0])\n        loss.backward()\n        torch.nn.utils.clip_grad_norm(lstm.parameters(), 0.5) # \xe6\xa2\xaf\xe5\xba\xa6\xe5\x89\xaa\xe8\xa3\x81\n        optimizer.step()\n    # \xe9\x87\x87\xe6\xa0\xb7\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b\n    if epoch % config.sample_num == 0:\n        print(""Epoch %d. Perplexity %f"" % (epoch, np.exp(np.mean(train_loss))))\n        # \xe5\xaf\xb9\xe7\xbb\x99\xe5\xae\x9a\xe7\x9a\x84\xe6\xad\x8c\xe8\xaf\x8d\xe5\xbc\x80\xe5\xa4\xb4\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\x87\xaa\xe5\x8a\xa8\xe7\x94\x9f\xe6\x88\x90\xe6\xad\x8c\xe8\xaf\x8d\n        for preseq in config.prefix:\n            predict(lstm, preseq, config, corpus)\n\n'"
NLP/py/word2vec.py,7,"b'import torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# \xe6\x9e\x84\xe5\xbb\xba skip-grams \xe6\xa8\xa1\xe5\x9e\x8b\n\nclass SkipGramModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim):\n        """"""\n            vocab_size: \xe8\xaf\xad\xe6\x96\x99\xe5\xba\x93\xe4\xb8\xad\xe7\x9a\x84\xe5\x8d\x95\xe8\xaf\x8d\xe7\x9a\x84\xe6\x95\xb0\xe9\x87\x8f\n            emb_dim: \xe5\x90\x91\xe9\x87\x8f\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\n        """"""\n        super(SkipGramModel, self).__init__()\n        self.vocab_size = vocab_size\n        self.emb_dim = emb_dim\n        self.embedding_v = nn.Embedding(vocab_size, emb_dim) # center word embedding\n        self.embedding_u = nn.Embedding(vocab_size, emb_dim) # out word embedding\n        self.init_emb()\n    \n    def forward(center_words, target_words, outer_words):\n        center_embeds = self.embedding_v(center_words) # B x 1 x D\n        target_embeds = self.embedding_u(target_words) # B x 1 x D\n        outer_embeds = self.embedding_u(outer_words) # B x V x D\n        \n        scores = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2) # Bx1xD * BxDx1 => Bx1 \n        norm_scores = outer_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2) # BxVxD * BxDx1 => BxV\n        \n        P_oc = torch.exp(scores) / torch.sum(torch.exp(norm_scores), 1).unsqueeze(1) # Bx1 * Bx1 => B*1 \xe8\xa1\xa8\xe7\xa4\xba B\xe4\xb8\xaa\xe5\x8d\x95\xe8\xaf\x8d\xe7\x9a\x84 P(o|c)\n        nll = -torch.mean(torch.log(P_oc)) # \xe6\xb1\x82 \xe8\xbf\x99 B \xe4\xb8\xaa\xe5\x8d\x95\xe8\xaf\x8d\xe7\x9a\x84 negative log likelihood\n\n        return nll \n    \n    def init_emb(self):\n        """"""\n            \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\xbd\x91\xe7\xbb\x9c\xe6\x9d\x83\xe9\x87\x8d\n        """"""\n        initrange = 0.5 / self.emb_dimension\n        self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n        self.v_embeddings.weight.data.uniform_(-0, 0)\n        return \n    \n    def prediction(self, inputs):\n        """"""\n            \xe7\xbb\x99\xe5\x87\xba word \xe7\x9a\x84 vector, \xe8\xbf\x99\xe9\x87\x8c\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\xb2\xa1\xe6\x9c\x89\xe7\x94\xa8\xe5\x88\xb0\xe5\x90\x8e\xe9\x9d\xa2\xe7\x9a\x84 embedding_u\xef\xbc\x8c\xe5\x85\xb6\xe5\xae\x9e\xe8\xbf\x99\xe9\x87\x8c\xe8\xbf\x98\xe6\x9c\x89\xe5\x87\xa0\xe7\xa7\x8d\xe5\x81\x9a\xe6\xb3\x95\xef\xbc\x9a\n            1\xe3\x80\x81embedding_v + embedding_u\xef\xbc\x9b \n            2\xe3\x80\x81embedding_v[:, N/2; :] + embedding_u[:; :, N/2] \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf embedding_v \xe5\x8f\x96\xe5\x89\x8d\xe4\xb8\x80\xe5\x8d\x8a\xef\xbc\x8c embedding_u\xe5\x8f\x96\xe5\x90\x8e\xe4\xb8\x80\xe5\x8d\x8a\xef\xbc\x8c\xe4\xb8\xa4\xe8\x80\x85\xe6\x8b\xbc\xe6\x8e\xa5\xe3\x80\x82\n        """"""\n        embeds = self.embedding_v(inputs)\n        return embeds \n\n\n\n# skip-grams\xe6\xa8\xa1\xe5\x9e\x8b + Negative sampling\n\nclass SkipgramNegSampling(nn.Module):\n    def __init__(self, vocab_size, emb_dim):\n        super(SkipgramNegSampling, self).__init__()\n        self.vocab_size = vocab_size\n        self.emb_dim = emb_dim\n        self.embedding_v = nn.Embedding(vocab_size, emb_dim) # center word embedding\n        self.embedding_u = nn.Embedding(vocab_size, emb_dim) # out word embedding\n        self.logsigmoid = nn.LogSigmoid()\n        self.init_emb()\n        \n    def forward(self, center_words, target_words, negative_words):\n        center_embeds = self.embedding_v(center_words) # B x 1 x D\n        target_embeds = self.embedding_u(target_words) # B x 1 x D\n        neg_embeds = -self.embedding_u(negative_words) # K\xe4\xb8\xaa\xe8\xb4\x9f\xe6\xa0\xb7\xe6\x9c\xac B x K x D  \n        \n        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2) # Bx1xD * BxDx1 -> Bx1\n        \n        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2) # BxKxD * BxDx1 -> BxK\n        \n        negative_score = torch.sum(negative_score, 1).view(negs.size(0), -1) # BxK -> Bx1\n        \n        loss = self.logsigmoid(positive_score) + self.logsigmoid(negative_score)\n        \n        return -torch.mean(loss) # \xe5\x8e\x9f\xe7\x9b\xae\xe6\xa0\x87\xe5\x87\xbd\xe6\x95\xb0\xe6\x98\xaf\xe6\x9c\x80\xe5\xa4\xa7\xe5\x8c\x96\xe7\x9a\x84\xef\xbc\x8c\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe8\xb4\x9f\xe5\x8f\xb7\xef\xbc\x8c\xe5\x8f\x98\xe6\x88\x90 min \xe7\x84\xb6\xe5\x90\x8e\xe5\xb0\xb1\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8SGD\xe7\xad\x89\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95\xe4\xba\x86\xe3\x80\x82\n    \n    \n    def prediction(self, inputs):\n        embeds = self.embedding_v(inputs)\n        return embeds\n\n    \n    def init_emb(self):\n        initrange = (2.0 / (self.vocab_size + self.emb_dim))**0.5 # Xavier init\n        self.embedding_v.weight.data.uniform_(-initrange, initrange) # init\n        self.embedding_u.weight.data.uniform_(-0.0, 0.0) # init\n        return '"
Nueral_Style/py/neural_style.py,8,"b'import torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision\n\nclass Config(object):\n    IMAGENET_MEAN = [0.485, 0.456, 0.406]  # IMAGENET\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n    IMAGENET_STD = [0.229, 0.224,  0.225]  # IMAGENET\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n    imsize = 512  # \xe7\xbb\x9f\xe4\xb8\x80 content image \xe5\x92\x8c style image \xe7\x9a\x84 size\n    style_image_path = \'../images/candy.jpg\' # \xe6\xa0\xb7\xe5\xbc\x8f\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\n    content_image_path = \'../images/hoovertowernight.jpg\' # \xe5\x86\x85\xe5\xae\xb9\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\n    DOWNLOAD = True  # \xe6\x98\xaf\xe5\x90\xa6\xe4\xb8\x8b\xe8\xbd\xbd\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\n    lr = 0.05  # \xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\n    epoches = 5000  # \xe8\xae\xad\xe7\xbb\x83epoch\n    show_epoch = 5  # \xe6\x98\xbe\xe7\xa4\xba\xe6\x8d\x9f\xe5\xa4\xb1\xe7\x9a\x84epoch\n    sample_epoch = 500  # \xe9\x87\x87\xe6\xa0\xb7\xe7\x9a\x84epoch\n    c_weight = 10  # content_loss \xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\n    s_weight = 1500  # style_loss\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\n    use_cuda = torch.cuda.is_available()\n    dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n    \n# \xe5\x8f\x82\xe6\x95\xb0\xe9\x85\x8d\xe7\xbd\xae\xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96\nconfig = Config()\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe5\x87\xbd\xe6\x95\xb0\n# \xe7\x94\xa8\xe4\xba\x8e\xe6\x8a\x8a\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe7\x89\x87\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xef\xbc\x8c\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x8e\xa5\xe6\x94\xb6\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe6\xa0\xbc\xe5\xbc\x8f\ndef preprocess(image_path, trasform=None):\n    image = Image.open(image_path)\n    image = trasform(image)\n    image = image.unsqueeze(0)\n    return image.type(config.dtype)\n\ntransformer = transforms.Compose([\n        transforms.Scale(config.imsize),\n        transforms.ToTensor()\n        transforms.Normalize(mean = config.IMAGENET_MEAN,std = config.IMAGENET_STD)\n    ])\n\npltshow = transforms.ToPILImage()\n\n# \xe5\x9b\xbe\xe7\x89\x87\xe5\xb1\x95\xe7\xa4\xba\ndef imshow(tensor, title=None):\n    image = tensor.clone().cpu()\n    image = image.view(3, config.imsize, config.imsize)\n    image = pltshow(image)\n    plt.imshow(image)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)\n\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\xa8\xa1\xe5\x9e\x8b\nclass VGG_extract(nn.Module):\n    def __init__(self):\n        super(VGG_extract, self).__init__()\n        self.style_layers = [0, 5, 10, 19, 28]\n        self.content_layers = [25]\n        self.net = models.vgg19(pretrained=config.DOWNLOAD).features\n\n    def forward(self, x):\n        # \xe7\x94\xb1\xe4\xba\x8e\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaa\xe9\x9c\x80\xe8\xa6\x81\xe6\x8c\x87\xe5\xae\x9a\xe5\xb1\x82\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x90\x8c\xe6\x97\xb6\xe6\x9e\x84\xe5\xbb\xba\xe7\x89\xb9\xe5\xbe\x81\xe6\x8f\x90\xe5\x8f\x96\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\xaa\xe4\xbf\x9d\xe7\x95\x99\xe5\x88\xb6\xe5\xae\x9a\xe5\xb1\x82\xe7\x9a\x84\xe5\x80\xbc\n        contents = []\n        styles = []\n        for i in range(len(self.net)):\n            x = self.net[i](x)\n            if i in self.style_layers:\n                styles.append(x)\n            if i in self.content_layers:\n                contents.append(x)\n        return contents, styles\n\n\n# \xe6\x9e\x84\xe5\xbb\xba\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0 \xef\xbc\x88\xe6\x9c\x80\xe9\xba\xbb\xe7\x83\xa6\xe7\x9a\x84\xe5\x9c\xb0\xe6\x96\xb9\xe4\xba\x86...\xef\xbc\x89\n\n# \xe5\x86\x85\xe5\xae\xb9\xe5\x8c\xb9\xe9\x85\x8d\xe5\x8f\xaa\xe6\xb6\x89\xe5\x8f\x8a\xe4\xb8\x80\xe5\xb1\x82\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe6\x88\x90\xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8\xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae\xe3\x80\x82\ndef content_loss(y_hat, y):\n    con_loss = 0\n    for y_i, y_j in zip(y_hat, y):\n        con_loss += torch.mean((y_i - y_j) ** 2)\n    return con_loss\n\n\n# \xe6\xa0\xb7\xe5\xbc\x8f\xe5\x8c\xb9\xe9\x85\x8d\xe5\x88\x99\xe6\x98\xaf\xe9\x80\x9a\xe8\xbf\x87\xe6\x8b\x9f\xe5\x90\x88Gram\xe7\x9f\xa9\xe9\x98\xb5\ndef gram(y):\n    b, c, h, w = y.size()\n    y = y.view(c, h * w)\n    norm = h * w\n    return torch.mm(y, y.t()) / norm\n\n# \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb7\xe5\xbc\x8f\xe6\x8d\x9f\xe5\xa4\xb1\ndef style_loss(y_hat, y):\n    sty_loss = 0\n    for y_i, y_j in zip(y_hat, y):\n        sty_loss += torch.mean((gram(y_i) - gram(y_j)) ** 2)\n    return sty_loss\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nstyle = preprocess(config.style_image_path, transformer)\n\ncontent = preprocess(config.content_image_path, transformer)\n\ntarget = Variable(content.clone(), requires_grad=True)  # \xe8\xbf\x99\xe5\xb0\xb1\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe6\x9b\xb4\xe6\x96\xb0\xe7\x9a\x84\xe6\x98\xaf\xe8\xbe\x93\xe5\x85\xa5 x\n\noptimizer = torch.optim.Adam([target], lr=config.lr, betas=[0.5, 0.999])\n\n# \xe5\x8a\xa0\xe8\xbd\xbd\xe6\xa8\xa1\xe5\x9e\x8b\nvgg = VGG_extract()\n\nif config.use_cuda:\n    vgg = vgg.cuda()\n\nfor epcho in range(config.epoches):\n    # \xe8\x8e\xb7\xe5\x8f\x96\xe7\x89\xb9\xe5\xbe\x81\n    t_c_fea, t_s_fea = vgg(target)\n    c_fea, _ = vgg(Variable(content))\n    _, s_fea = vgg(Variable(style))\n\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    c_loss = content_loss(t_c_fea, c_fea)\n    s_loss = style_loss(t_s_fea, s_fea)\n    loss = config.c_weight * c_loss + config.s_weight * s_loss\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    print(epcho)\n    if (epcho + 1) % config.show_epoch == 0:\n        print(\'Epcho [%d/%d], Content Loss: %.4f, Style Loss: %.4f\'\n              % (epcho + 1, config.epoches, c_loss.data[0], s_loss.data[0]))\n        # \xe4\xbf\x9d\xe5\xad\x98\xe5\x9b\xbe\xe7\x89\x87\n    if (epcho + 1) % config.sample_epoch == 0:\n        denorm = transforms.Normalize((-2.12, -2.04, -1.80), (4.37, 4.46, 4.44))\n        img = target.clone().cpu().squeeze()\n        img = denorm(img.data).clamp_(0, 1)\n        torchvision.utils.save_image(img, \'output-%d.png\' % (epcho + 1))\n\nprint(""Done!"")'"
Others/py/GCN.py,8,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport random\n\n# \xe5\x90\x84\xe4\xbd\x8d\xe8\xaf\xbb\xe8\x80\x85\xe5\xa4\xa7\xe5\xa4\xa7\xe8\xaf\xb7\xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x8c\xe8\xbf\x99\xe6\xae\xb5\xe4\xbb\xa3\xe7\xa0\x81\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\x8e\xaf\xe5\xa2\x83\xe6\x98\xaf pytorch 1.0\xef\xbc\x9b\n# 0.3.0 \xe5\x8f\x8a\xe4\xbb\xa5\xe4\xb8\x8b\xe7\x9a\x84\xe7\x89\x88\xe6\x9c\xac\xe4\xbc\x9a\xe9\x9c\x80\xe8\xa6\x81\xe5\x8a\xa0\xe4\xb8\x8a Variable \xe5\x8f\x98\xe9\x87\x8f\xe3\x80\x82\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\xe5\xb7\xa5\xe4\xbd\x9c\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8 karate \xe4\xbf\xb1\xe4\xb9\x90\xe9\x83\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n# \xe5\x89\x8d\xe6\x9c\x9f\xe7\x9a\x84\xe5\x87\x86\xe5\xa4\x87\xe5\xb7\xa5\xe4\xbd\x9c\xef\xbc\x8c\xe5\x85\xb6\xe5\xae\x9e\xe5\xb0\xb1\xe4\xb8\xa4\xe4\xb8\xaa\xef\xbc\x9a  1. \xe6\x9e\x84\xe5\xbb\xba\xe9\x82\xbb\xe6\x8e\xa5\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9b  2. \xe6\xb1\x82\xe5\x87\xba\xe5\xba\xa6\xe6\x95\xb0\xe7\x9f\xa9\xe9\x98\xb5\n# \xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\xa7\xe8\xa7\x84\xe6\xa8\xa1\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8 \xe7\xa8\x80\xe7\x96\x8f\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe5\x8e\xbb\xe5\xae\x8c\xe6\x88\x90\xe3\x80\x82\ndef construct_graph_data(path, num):\n    # \xe7\x94\xb1\xe4\xba\x8e GCN \xe4\xb8\xad\xe7\x9c\x9f\xe6\xad\xa3\xe4\xbd\xbf\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xb0\xb1\xe6\x98\xaf X \\in R^{N x C} \xe5\x92\x8c A \\in R^{N x N} \xe5\x92\x8c D \\in R^{N x C}\n    # \xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x8c\xe7\xbb\x99\xe5\xae\x9a\xe5\x9b\xbe\xe4\xb9\x8b\xe9\x97\xb4\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xbf\x9e\xe6\x8e\xa5\xe4\xbf\xa1\xe6\x81\xaf\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\xbe\x93\xe5\x87\xba A \xe5\x92\x8c D\n    # \xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe6\x8f\x90\xe5\x89\x8d\xe7\x9f\xa5\xe9\x81\x93\xe5\x9b\xbe\xe4\xb8\xad\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe7\x9b\xae\n    N = num\n    A = np.zeros((N, N), dtype=int)\n    with open(path, ""r"") as fr:\n        # \xe7\xac\xac\xe4\xb8\x80\xe8\xa1\x8c\xe4\xb8\x8d\xe8\xa6\x81\n        line = fr.readline()\n        line = fr.readline()\n        while line != None and line != """":\n            arr = line.strip().split("" "")\n            sou, tar = int(arr[0]), int(arr[1])\n            A[sou-1, tar-1] = 1\n            line = fr.readline()\n    # \xe5\xbe\x97\xe5\x88\xb0\xe4\xba\x86\xe9\x82\xbb\xe6\x8e\xa5\xe7\x9f\xa9\xe9\x98\xb5 A\xef\xbc\x8c\xe6\xa0\xb9\xe6\x8d\xae\xe9\x82\xbb\xe6\x8e\xa5\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8e\xbb\xe6\xb1\x82\xe5\xba\xa6\xe6\x95\xb0\xe7\x9f\xa9\xe9\x98\xb5 D\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x85\x88\xe8\xae\xa9\xe9\x82\xbb\xe6\x8e\xa5\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8a\xa0\xe4\xb8\x8a\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8d\x95\xe4\xbd\x8d\xe9\x98\xb5\n    I_N = np.eye(N, dtype=int)\n    A_tilde = A + I_N\n    # \xe6\x8e\xa5\xe7\x9d\x80\xe6\xa0\xb9\xe6\x8d\xae A_tilde \xe5\x8e\xbb\xe6\xb1\x82 D_tilde\n    each_node_degree = np.sum(A_tilde, axis=0)\n    D = np.power(each_node_degree, -0.5)\n    D_05 = np.power(D, -0.5)\n    D_tilde = np.diag(D_05)\n    return A_tilde, D_tilde\n\ndef get_train_test(path, train_num):\n    all_data = []\n    with open(path, ""r"") as fr:\n        # \xe7\xac\xac\xe4\xb8\x80\xe8\xa1\x8c\xe4\xb8\x8d\xe8\xa6\x81\n        line = fr.readline()\n        line = fr.readline()\n        while line != None and line != """":\n            arr = line.strip().split("" "")\n            all_data.append((int(arr[0]), int(arr[1])))\n            line = fr.readline()\n    data = [temp[0] for temp in all_data]\n    label = [temp[1] for temp in all_data]\n    return data, label\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe5\x87\x86\xe5\xa4\x87\xe6\x9e\x84\xe5\xbb\xba\xe6\xa8\xa1\xe5\x9e\x8b\nclass GCN(nn.Module):\n    def __init__(self, A_tilde, D_tilde, input_dim, output_class):\n        super(GCN, self).__init__()\n        self.A_hat = D_tilde.mm(A_tilde).mm(D_tilde)  # N*N\n        self.fc1 = nn.Linear(input_dim, input_dim // 2, bias=False)   # \xe8\xbf\x99\xe9\x87\x8c\xe9\x81\xb5\xe5\xbe\xaa\xe5\x8e\x9f\xe6\x96\x87\xe7\x9a\x84\xe5\x86\x99\xe6\xb3\x95\xef\xbc\x8c\xe4\xb8\x8d\xe5\x8a\xa0 bias\n        self.fc2 = nn.Linear(input_dim // 2, input_dim // 4, bias=False)  # \xe6\x84\x9f\xe8\xa7\x89\xe5\x8a\xa0\xe4\xb8\x8d\xe5\x8a\xa0\xe7\xbb\x93\xe6\x9e\x9c\xe6\xb2\xa1\xe5\x95\xa5\xe6\x94\xb9\xe5\x8f\x98...\xe5\xbd\x93\xe7\x84\xb6\xe6\x9c\x89\xe5\x8f\xaf\xe8\x83\xbd\xe6\x98\xaf\xe5\x9b\xa0\xe4\xb8\xba\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xa4\xaa\xe5\xb0\x8f\xe7\x9a\x84\xe5\x8e\x9f\xe5\x9b\xa0\n        # \xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\n        self.output_layer = nn.Linear(input_dim // 4, output_class, bias=False)\n\n    def forward(self, x):\n        # \xe4\xb8\xa4\xe5\xb1\x82 GCN\n        h1 = F.relu(self.fc1(self.A_hat.mm(x)))\n        h2 = F.relu(self.fc2(self.A_hat.mm(h1)))\n        res = self.output_layer(self.A_hat.mm(h2))\n        return res\n\n\nif __name__ == \'__main__\':\n    # \xe6\x9e\x84\xe9\x80\xa0\xe5\x9b\xbe\xe7\xbb\x93\xe6\x9e\x84\n    graph_path = ""../data/karate.txt""\n    node_num = 34\n    input_dim = node_num\n    output_class = 2\n    A_tilde, D_tilde = construct_graph_data(graph_path, node_num)\n    # \xe4\xbb\x8e numpy \xe6\xa0\xbc\xe5\xbc\x8f\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90 tensor \xe6\xa0\xbc\xe5\xbc\x8f\n    A = torch.tensor(A_tilde, dtype=torch.float32)\n    D = torch.tensor(D_tilde, dtype=torch.float32)\n    # \xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x86 label.txt \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe4\xb8\x80\xe4\xb8\x8b\xef\xbc\x8c\xe5\xbe\x97\xe5\x88\xb0\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xe3\x80\x82\n    label_path = ""../data/label.txt""\n    all_data, all_label = get_train_test(label_path, train_num=24)\n    # \xe7\xae\x80\xe5\x8d\x95\xe7\x82\xb9\xef\xbc\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8 one-hot encoding \xe6\x9d\xa5\xe8\xa1\xa8\xe7\xa4\xba\xe7\x89\xb9\xe5\xbe\x81\n    X_features = torch.eye(node_num, node_num)  # N*N\n    # \xe7\x94\xa8\xe4\xba\x8e\xe6\xaf\x94\xe8\xbe\x83\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\n    torch_all_label = torch.tensor(all_label, dtype=torch.int64)\n    # \xe6\x9e\x84\xe5\xbb\xba\xe6\xa8\xa1\xe5\x9e\x8b\n    gcn = GCN(A, D, input_dim, output_class)\n    # \xe7\xa1\xae\xe5\xae\x9a\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\n    optimizer = torch.optim.Adam(gcn.parameters())\n    # \xe7\xa1\xae\xe5\xae\x9a\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n    loss_fn = nn.CrossEntropyLoss()\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\n    for epoch in range(200):\n        y_pred = F.softmax(gcn(X_features), dim=1)\n        loss = loss_fn(y_pred, torch_all_label)\n        # \xe8\xae\xa1\xe7\xae\x97\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87\n        _, pred = torch.max(y_pred, 1)\n        num_correct = (pred == torch_all_label).sum()\n        # \xe5\x90\x91\xe5\x90\x8e\xe4\xbc\xa0\xe6\x92\xad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        # \xe6\xaf\x8f\xe9\x9a\x94 10 \xe6\xac\xa1\xef\xbc\x8c output \xe4\xb8\x80\xe6\xac\xa1\n        if epoch % 10 == 0:\n            print(\'Accuracy is {:.4f}\'.format(num_correct.item() / node_num))\n\n    print(""Done!"")\n\n'"
Others/py/attention_all.py,18,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import *\nfrom torch.nn.parameter import Parameter\nimport numpy as np\n\n# \xe8\xbf\x99\xe9\x87\x8c\xe4\xb8\x8d\xe5\x81\x9a mask\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\xbb\x98\xe8\xae\xa4 dk = dv\nclass ScaledDotProductAttention(nn.Module):\n\n    def __init__(self, d_model):\n        '''scaled-dot-product-attention\n            parameters: \n                d_model: A scalar. attention size\n        '''\n        super(ScaledDotProductAttention, self).__init__()\n        self.temper = np.power(d_model, 0.5)\n    \n    def forward(self, Q, K, V):\n        ''' forward step\n            parameters: \n                Q (batch*n*dk)\n                K (batch*m*dk)\n                V (batch*m*dv)\n            note: dv == dk\n        '''\n        qk = torch.bmm(Q, K.transpose(1, 2)) # (batch*n*dk) x (batch*dk*m) -> batch*n*m\n        weight = F.softmax(qk / self.temper, dim=1) # batch*n*m -> batch*n*m\n        attention_V = torch.matmul(weight, V) # (batch*n*m) x (batch*m*dv) -> batch*n*dv\n        return attention_V\n\n\n\n\n# \n# code reference from https://github.com/jadore801120/attention-is-all-you-need-pytorch\n# \n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import *\nfrom torch.nn.parameter import Parameter\nimport numpy as np\nimport math\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe6\xae\x8b\xe5\xb7\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe9\x93\xbe\xe6\x8e\xa5, no mask\nclass MultiHeadAttention(nn.Module):\n\n    def __init__(self, d_model, d_k_hat, d_v_hat, n_head=8, dropout_rate=0, mask=False):\n        '''multi-head-attention.\n            parameters:\n                d_model: A scalar. attention size.\n                d_k_hat: A scalar. linear project dimension of k.\n                d_v_hat: A scalar. linear project dimension of v.\n                num_heads: An int. Number of heads.\n                dropout_rate: A floating point number. drop_ou\n        '''\n        super(MultiHeadAttention, self).__init__()\n        \n        self.n_head = n_head\n        self.d_k_hat = d_k_hat # \xe9\x80\x9a\xe5\xb8\xb8 d_k_hat = d_model / n_head\n        self.d_v_hat = d_v_hat # \xe9\x80\x9a\xe5\xb8\xb8 d_v_hat = d_model / n_head\n        \n        self.w_qs = nn.Parameter(torch.FloatTensor(n_head, d_model, d_k_hat))\n        self.w_ks = nn.Parameter(torch.FloatTensor(n_head, d_model, d_k_hat))\n        self.w_vs = nn.Parameter(torch.FloatTensor(n_head, d_model, d_v_hat))\n        \n        self.attention_net = ScaledDotProductAttention(d_model)\n        \n        self.linear_proj = torch.nn.Linear(n_head*d_v_hat, d_model)\n        \n        self.dropout = nn.Dropout(dropout_rate)\n        \n        self.mask = mask\n\n    def forward(self, Q, K, V):\n        ''' forward step\n            parameters: Q (batch*n*d_model), K(batch*m*d_model), V(batch*m*d_model)\n        '''\n        d_k_hat, d_v_hat = self.d_k_hat, self.d_v_hat\n        \n        residual = Q # batch_size x len_q x d_model\n        \n        n_head = self.n_head\n        \n        batch_size, len_q, d_model = Q.size()\n        batch_size, len_k, d_model = K.size()\n        batch_size, len_v, d_model = V.size()\n        \n        # \xe9\x87\x8d\xe5\xa4\x8d multi-head \xe6\xac\xa1\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe4\xb9\x8b\xe5\x90\x8e\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\x98\xe6\x8d\xa2\n        q_s = Q.repeat(n_head, 1, 1).view(n_head, -1, d_model) # n_head*(batch_size*len_q)*d_model\n        k_s = K.repeat(n_head, 1, 1).view(n_head, -1, d_model) # n_head*(mb_size*len_k)*d_model\n        v_s = V.repeat(n_head, 1, 1).view(n_head, -1, d_model) # n_head*(mb_size*len_v)*d_model\n        \n        # \xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\x98\xe6\x8d\xa2\n        # bmm: (n_head*(batch_size*len_q)*d_model) x (n_head*d_model*d_k_hat) -> n_head*(batch_size*len_q)*d_k_hat\n        # view: n_head*(batch_size*len_q)*d_k_hat -> (n_head*batch_size)*len_q*d_k_hat\n        q_s = torch.bmm(q_s, self.w_qs).view(-1, len_q, d_k_hat) \n        k_s = torch.bmm(k_s, self.w_ks).view(-1, len_k, d_k_hat)\n        v_s = torch.bmm(v_s, self.w_vs).view(-1, len_v, d_v_hat)\n        \n        # \xe6\x89\x94\xe8\xbf\x9b Attention network \xe4\xb8\xad\n        outputs = self.attention_net(q_s, k_s, v_s) # (n_head*batch_size)*len_q*d_v_hat\n        \n        # concatenate \xe6\x93\x8d\xe4\xbd\x9c\xef\xbc\x8c\xe5\xa4\x8d\xe5\x8e\x9f\xe5\x88\xb0  batch_size x len_q x (n_head*d_v_hat)\n        # split: (n_head*batch_size)*len_q*d_v_hat ->  n_head \xe4\xb8\xaa [batch_size*len_q*d_v_hat]\n        # cat: n_head \xe4\xb8\xaa [batch_size*len_q*d_v_hat] -> batch_size x len_q x (n_head*d_v_hat)\n        outputs = torch.cat(torch.split(outputs, batch_size, dim=0), dim=-1)\n        \n        # \xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe4\xb8\xaa linear layer\n        outputs = self.linear_proj(outputs) # batch_size x len_q x (n_head*d_v_hat) -> batch_size x len_q x d_model\n        outputs = self.dropout(outputs)\n        \n        # \xe6\xae\x8b\xe5\xb7\xae\n        return outputs + residual"""
basis/py/autograd.py,3,"b'# \xe6\x8a\x8a\xe5\xbf\x85\xe8\xa6\x81\xe7\x9a\x84\xe5\x8c\x85\xe7\xbb\x99\xe5\xaf\xbc\xe5\x85\xa5\nimport torch\nfrom torch.autograd import Variable\n\n# \xe5\xa6\x82\xe6\x9e\x9c\xe6\x88\x91\xe4\xbb\xac\xe6\x83\xb3\xe8\xae\xa1\xe7\xae\x97  f=3\xc3\x97x3+4\xc3\x97x2+6f=3\xc3\x97x3+4\xc3\x97x2+6  \xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\xef\xbc\x8c\xe8\xaf\xa5\xe5\xa6\x82\xe4\xbd\x95\xe5\x81\x9a\xe5\x91\xa2\xef\xbc\x9f\n\ndef fn(x):\n    y = 3 * x.pow(3) + 4 * x.pow(2) + 6\n    return y\n\nx1 = Variable(torch.Tensor([1]), requires_grad=True)\n\ny1 = fn(x1)\n\nprint(y1)\n\ny1.backward() # \xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\n\nx1.grad # \xe6\x9f\xa5\xe7\x9c\x8b\xe6\xa2\xaf\xe5\xba\xa6\n\n\n# \xe9\x80\x9a\xe8\xbf\x87\xe8\xb0\x83\xe7\x94\xa8 backward() \xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\x87\xba\xe4\xba\x86\xe5\x9c\xa8 x = 1 \xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\n# \xe9\x9c\x80\xe8\xa6\x81\xe6\xb3\xa8\xe6\x84\x8f\xe7\x9a\x84\xe4\xb8\x80\xe7\x82\xb9\xe6\x98\xaf\xef\xbc\x9a\xe5\xa6\x82\xe6\x9e\x9c\xe6\x88\x91\xe4\xbb\xac\xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84 Tensor \xe4\xb8\x8d\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\x87\xe9\x87\x8f\xef\xbc\x8c\xe8\x80\x8c\xe6\x98\xaf\xe7\x9f\xa2\xe9\x87\x8f\xef\xbc\x88\xe5\xa4\x9a\xe4\xb8\xaa\xe5\x80\xbc\xef\xbc\x89\xe3\x80\x82\n# \xe9\x82\xa3\xe4\xb9\x88\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe8\xb0\x83\xe7\x94\xa8backward()\xe4\xb9\x8b\xe5\x89\x8d\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe8\xae\xa9\xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\x98\xe6\x88\x90\xe6\xa0\x87\xe9\x87\x8f \xe6\x89\x8d\xe8\x83\xbd\xe6\xb1\x82\xe5\x87\xba\xe5\xaf\xbc\xe6\x95\xb0\xe3\x80\x82\n# \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe8\xaf\xb4\xe5\xa6\x82\xe6\x9e\x9c\xe4\xb8\x8d\xe5\xb0\x86 Y \xe7\x9a\x84\xe5\x80\xbc\xe5\x8f\x98\xe6\x88\x90\xe6\xa0\x87\xe9\x87\x8f\xef\xbc\x8c\xe5\xb0\xb1\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\xe3\x80\x82\xef\xbc\x88\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x9d\xe8\xaf\x95\xe6\x8a\x8amean()\xe7\xbb\x99\xe5\x8f\x96\xe6\xb6\x88\xef\xbc\x8c\xe7\x9c\x8b\xe7\x9c\x8b\xe6\x98\xaf\xe4\xb8\x8d\xe6\x98\xaf\xe6\x8a\xa5\xe9\x94\x99\xe4\xba\x86\xef\xbc\x89\n\nx2 = Variable(torch.Tensor([[1, 2], [3, 4]]), requires_grad=True)\n\ny2 = fn(x2).mean() # \xe5\xb0\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\x98\xe6\x88\x90\xe6\xa0\x87\xe9\x87\x8f\xef\xbc\x8c\xe8\xbf\x99\xe6\xa0\xb7\xe5\xb0\xb1\xe4\xb8\x8d\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\xe4\xba\x86\n\ny2.backward() # \xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\n\nx2.grad # \xe6\x9f\xa5\xe7\x9c\x8b\xe6\xa2\xaf\xe5\xba\xa6'"
basis/py/dataset.py,9,"b'# DataLoader \xe5\x92\x8c Dataset\n# \xe6\x9e\x84\xe5\xbb\xba\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x9f\xba\xe6\x9c\xac\xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xba\x86\xe8\xa7\xa3\xe4\xba\x86\xe3\x80\x82\xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa5\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb0\xb1\xe8\xa6\x81\xe5\xbc\x84\xe6\x98\x8e\xe7\x99\xbd\xe6\x80\x8e\xe4\xb9\x88\xe5\xaf\xb9\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbb\xa5\xe5\x89\x8d\xe6\x89\x8b\xe5\x8a\xa8\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xef\xbc\x8c\n# \xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xe5\xb0\x8f\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe5\xb9\xb6\xe6\xb2\xa1\xe6\x9c\x89\xe5\xa4\xaa\xe5\xa4\xa7\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe5\x88\xb0\xe4\xba\x86\xe5\xa4\xa7\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe4\xbd\xbf\xe7\x94\xa8 shuffle, \xe5\x88\x86\xe5\x89\xb2\xe6\x88\x90mini-batch \xe7\xad\x89\xe6\x93\x8d\xe4\xbd\x9c\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8PyTorch\xe7\x9a\x84API\xe5\xbf\xab\xe9\x80\x9f\xe5\x9c\xb0\xe5\xae\x8c\xe6\x88\x90\xe8\xbf\x99\xe4\xba\x9b\xe6\x93\x8d\xe4\xbd\x9c\xe3\x80\x82\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torch.autograd import Variable\nimport numpy as np\n\nxy = np.loadtxt(\'../dataSet/diabetes.csv.gz\', delimiter=\',\', dtype=np.float32) # \xe4\xbd\xbf\xe7\x94\xa8numpy\xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\nx_data = torch.from_numpy(xy[:, 0:-1])\ny_data = torch.from_numpy(xy[:, [-1]])\n\nprint(x_data.shape, y_data.shape)\n\n# Dataset\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8c\x85\xe8\xa3\x85\xe7\xb1\xbb\xef\xbc\x8c\xe7\x94\xa8\xe6\x9d\xa5\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\x8c\x85\xe8\xa3\x85\xe4\xb8\xbaDataset\xe7\xb1\xbb\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe4\xbc\xa0\xe5\x85\xa5DataLoader\xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x86\x8d\xe4\xbd\xbf\xe7\x94\xa8DataLoader\xe8\xbf\x99\xe4\xb8\xaa\xe7\xb1\xbb\xe6\x9d\xa5\xe6\x9b\xb4\xe5\x8a\xa0\xe5\xbf\xab\xe6\x8d\xb7\xe7\x9a\x84\xe5\xaf\xb9\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x93\x8d\xe4\xbd\x9c\xe3\x80\x82\n# DataLoader\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xaf\x94\xe8\xbe\x83\xe9\x87\x8d\xe8\xa6\x81\xe7\x9a\x84\xe7\xb1\xbb\xef\xbc\x8c\xe5\xae\x83\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe5\xb8\xb8\xe7\x94\xa8\xe6\x93\x8d\xe4\xbd\x9c\xe6\x9c\x89\xef\xbc\x9abatch_size(\xe6\xaf\x8f\xe4\xb8\xaabatch\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f), shuffle(\xe6\x98\xaf\xe5\x90\xa6\xe8\xbf\x9b\xe8\xa1\x8cshuffle\xe6\x93\x8d\xe4\xbd\x9c), num_workers(\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xe4\xbd\xbf\xe7\x94\xa8\xe5\x87\xa0\xe4\xb8\xaa\xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b)\n# \xe7\x8e\xb0\xe5\x9c\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x85\x88\xe5\xb1\x95\xe7\xa4\xba\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8 TensorDataset \xe6\x9d\xa5\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\x8c\x85\xe8\xa3\x85\xe6\x88\x90Dataset\xe7\xb1\xbb\n\ndeal_dataset = TensorDataset(data_tensor=x_data, target_tensor=y_data)\n\ntrain_loader = DataLoader(dataset=deal_dataset,\n                          batch_size=32,\n                          shuffle=True,\n                          num_workers=2)\n\nfor epoch in range(2):\n    for i, data in enumerate(train_loader):\n        # \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe4\xbb\x8e train_loader \xe4\xb8\xad\xe8\xaf\xbb\xe5\x87\xba\xe6\x9d\xa5,\xe4\xb8\x80\xe6\xac\xa1\xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe6\x98\xaf32\xe4\xb8\xaa\n        inputs, labels = data\n\n        # \xe5\xb0\x86\xe8\xbf\x99\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90Variable\xe7\xb1\xbb\xe5\x9e\x8b\n        inputs, labels = Variable(inputs), Variable(labels)\n\n        # \xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa5\xe5\xb0\xb1\xe6\x98\xaf\xe8\xb7\x91\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe7\x8e\xaf\xe8\x8a\x82\xe4\xba\x86\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x99\xe9\x87\x8c\xe4\xbd\xbf\xe7\x94\xa8print\xe6\x9d\xa5\xe4\xbb\xa3\xe6\x9b\xbf\n        print(epoch, i, ""inputs"", inputs.data.size(), ""labels"", labels.data.size())\n\n\n# \xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa5\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x9d\xa5\xe7\xbb\xa7\xe6\x89\xbf Dataset\xe7\xb1\xbb \xef\xbc\x8c\xe5\x86\x99\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe6\x88\x90DataLoader\xe7\x9a\x84\xe7\xb1\xbb\xe3\x80\x82\n# \xe5\xbd\x93\xe6\x88\x91\xe4\xbb\xac\xe9\x9b\x86\xe6\x88\x90\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa Dataset\xe7\xb1\xbb\xe4\xb9\x8b\xe5\x90\x8e\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe9\x87\x8d\xe5\x86\x99 __len__ \xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x8c\xe8\xaf\xa5\xe6\x96\xb9\xe6\xb3\x95\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86dataset\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x9b __getitem__ \xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x8c \xe8\xaf\xa5\xe6\x96\xb9\xe6\xb3\x95\xe6\x94\xaf\xe6\x8c\x81\xe4\xbb\x8e 0 \xe5\x88\xb0 len(self)\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\n\nclass DealDataset(Dataset):\n    """"""\n        \xe4\xb8\x8b\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x81\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe9\x83\xbd\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\xae\x8c\xe6\x88\x90\n    """"""\n    def __init__(self):\n        xy = np.loadtxt(\'../dataSet/diabetes.csv.gz\', delimiter=\',\', dtype=np.float32) # \xe4\xbd\xbf\xe7\x94\xa8numpy\xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\n        self.x_data = torch.from_numpy(xy[:, 0:-1])\n        self.y_data = torch.from_numpy(xy[:, [-1]])\n        self.len = xy.shape[0]\n    \n    def __getitem__(self, index):\n        return self.x_data[index], self.y_data[index]\n\n    def __len__(self):\n        return self.len\n\n# \xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96\xe8\xbf\x99\xe4\xb8\xaa\xe7\xb1\xbb\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe6\x88\x91\xe4\xbb\xac\xe5\xb0\xb1\xe5\xbe\x97\xe5\x88\xb0\xe4\xba\x86Dataset\xe7\xb1\xbb\xe5\x9e\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xae\xb0\xe4\xb8\x8b\xe6\x9d\xa5\xe5\xb0\xb1\xe5\xb0\x86\xe8\xbf\x99\xe4\xb8\xaa\xe7\xb1\xbb\xe4\xbc\xa0\xe7\xbb\x99DataLoader\xef\xbc\x8c\xe5\xb0\xb1\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xba\x86\xe3\x80\x82    \ndealDataset = DealDataset()\n\ntrain_loader2 = DataLoader(dataset=dealDataset,\n                          batch_size=32,\n                          shuffle=True)\n\n\nfor epoch in range(2):\n    for i, data in enumerate(train_loader2):\n        # \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe4\xbb\x8e train_loader \xe4\xb8\xad\xe8\xaf\xbb\xe5\x87\xba\xe6\x9d\xa5,\xe4\xb8\x80\xe6\xac\xa1\xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe6\x98\xaf32\xe4\xb8\xaa\n        inputs, labels = data\n\n        # \xe5\xb0\x86\xe8\xbf\x99\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90Variable\xe7\xb1\xbb\xe5\x9e\x8b\n        inputs, labels = Variable(inputs), Variable(labels)\n\n        # \xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa5\xe5\xb0\xb1\xe6\x98\xaf\xe8\xb7\x91\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe7\x8e\xaf\xe8\x8a\x82\xe4\xba\x86\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x99\xe9\x87\x8c\xe4\xbd\xbf\xe7\x94\xa8print\xe6\x9d\xa5\xe4\xbb\xa3\xe6\x9b\xbf\n        print(""epoch\xef\xbc\x9a"", epoch, ""\xe7\x9a\x84\xe7\xac\xac"" , i, ""\xe4\xb8\xaainputs"", inputs.data.size(), ""labels"", labels.data.size())\n\n\n\n\n# torchvision \xe5\x8c\x85\xe7\x9a\x84\xe4\xbb\x8b\xe7\xbb\x8d\n# torchvision \xe6\x98\xafPyTorch\xe4\xb8\xad\xe4\xb8\x93\xe9\x97\xa8\xe7\x94\xa8\xe6\x9d\xa5\xe5\xa4\x84\xe7\x90\x86\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe5\xba\x93\xef\xbc\x8cPyTorch\xe5\xae\x98\xe7\xbd\x91\xe7\x9a\x84\xe5\xae\x89\xe8\xa3\x85\xe6\x95\x99\xe7\xa8\x8b\xef\xbc\x8c\xe4\xb9\x9f\xe4\xbc\x9a\xe8\xae\xa9\xe4\xbd\xa0\xe5\xae\x89\xe8\xa3\x85\xe4\xb8\x8a\xe8\xbf\x99\xe4\xb8\xaa\xe5\x8c\x85\xe3\x80\x82\n# \xe8\xbf\x99\xe4\xb8\xaa\xe5\x8c\x85\xe4\xb8\xad\xe6\x9c\x89\xe5\x9b\x9b\xe4\xb8\xaa\xe5\xa4\xa7\xe7\xb1\xbb\xe3\x80\x82\n# torchvision.datasets\n# torchvision.models\n# torchvision.transforms\n# torchvision.utils\n\n# \xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\xbb\xe8\xa6\x81\xe4\xbb\x8b\xe7\xbb\x8d\xe5\x89\x8d\xe4\xb8\x89\xe4\xb8\xaa\xe3\x80\x82\n# torchvision.datasets\n# torchvision.datasets \xe6\x98\xaf\xe7\x94\xa8\xe6\x9d\xa5\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\x8a\xa0\xe8\xbd\xbd\xe7\x9a\x84\xef\xbc\x8cPyTorch\xe5\x9b\xa2\xe9\x98\x9f\xe5\x9c\xa8\xe8\xbf\x99\xe4\xb8\xaa\xe5\x8c\x85\xe4\xb8\xad\xe5\xb8\xae\xe6\x88\x91\xe4\xbb\xac\xe6\x8f\x90\xe5\x89\x8d\xe5\xa4\x84\xe7\x90\x86\xe5\xa5\xbd\xe4\xba\x86\xe5\xbe\x88\xe5\xa4\x9a\xe5\xbe\x88\xe5\xa4\x9a\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x82\n# MNIST\n# COCO\n# Captions\n# Detection\n# LSUN\n# ImageFolder\n# Imagenet-12\n# CIFAR\n# STL10\n# SVHN\n# PhotoTour\n# \xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8\xef\xbc\x8c\xe7\xa4\xba\xe4\xbe\x8b\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x9a\n\nimport torchvision\n\nDOWNLOAD = True\n\ntrainset = torchvision.datasets.MNIST(root=\'./data\', # \xe8\xa1\xa8\xe7\xa4\xba MNIST \xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x8a\xa0\xe8\xbd\xbd\xe7\x9a\x84\xe7\x9b\xb8\xe5\xaf\xb9\xe7\x9b\xae\xe5\xbd\x95\n                                      train=True,  # \xe8\xa1\xa8\xe7\xa4\xba\xe6\x98\xaf\xe5\x90\xa6\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\xe5\xba\x93\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xef\xbc\x8cfalse\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xe5\x8a\xa0\xe8\xbd\xbd\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\n                                      download=DOWNLOAD, # \xe8\xa1\xa8\xe7\xa4\xba\xe6\x98\xaf\xe5\x90\xa6\xe8\x87\xaa\xe5\x8a\xa8\xe4\xb8\x8b\xe8\xbd\xbd MNIST \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n                                      transform=None) # \xe8\xa1\xa8\xe7\xa4\xba\xe6\x98\xaf\xe5\x90\xa6\xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8cnone\xe4\xb8\xba\xe4\xb8\x8d\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\n\n# \xe4\xb8\x8a\xe9\x9d\xa2\xe4\xbb\xa3\xe7\xa0\x81\xe5\xb0\xb1\xe5\xae\x8c\xe6\x88\x90\xe4\xba\x86MNIST\xe6\x95\xb0\xe6\x8d\xae \xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe7\x9a\x84\xe5\x8a\xa0\xe8\xbd\xbd\xe7\x8e\xaf\xe8\x8a\x82\xef\xbc\x8c\ntrain_loader2 = DataLoader(dataset=trainset,\n                          batch_size=32,\n                          shuffle=True)\nprint(""\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba\xef\xbc\x9a"" , len(trainset))\nprint(""\xe6\xaf\x8f\xe4\xb8\xaamini-batch\xe7\x9a\x84size \xe4\xb8\xba 32 , \xe4\xb8\x80\xe5\x85\xb1\xe6\x9c\x89\xef\xbc\x9a"" , len(train_loader2) , ""\xe4\xb8\xaa"")\n\n\n\n\n# torchvision.models\n# torchvision.models \xe4\xb8\xad\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86\xe5\xb7\xb2\xe7\xbb\x8f\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe8\xae\xa9\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x8a\xa0\xe8\xbd\xbd\xe4\xb9\x8b\xe5\x90\x8e\xef\xbc\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82\n# torchvision.models\xe6\xa8\xa1\xe5\x9d\x97\xe7\x9a\x84 \xe5\xad\x90\xe6\xa8\xa1\xe5\x9d\x97\xe4\xb8\xad\xe5\x8c\x85\xe5\x90\xab\xe4\xbb\xa5\xe4\xb8\x8b\xe6\xa8\xa1\xe5\x9e\x8b\xe7\xbb\x93\xe6\x9e\x84\xe3\x80\x82\n# AlexNet\n# VGG\n# ResNet\n# SqueezeNet\n# DenseNet\n# \xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8\xe5\xa6\x82\xe4\xb8\x8b\xe4\xbb\xa3\xe7\xa0\x81\xe6\x9d\xa5\xe5\xbf\xab\xe9\x80\x9f\xe5\x88\x9b\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9d\x83\xe9\x87\x8d\xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\n# import torchvision.models as models\n# resnet18 = models.resnet18()\n# alexnet = models.alexnet()\n# squeezenet = models.squeezenet1_0()\n# densenet = models.densenet_161()\n# \xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x80\x9a\xe8\xbf\x87\xe4\xbd\xbf\xe7\x94\xa8 pretrained=True \xe6\x9d\xa5\xe5\x8a\xa0\xe8\xbd\xbd\xe4\xb8\x80\xe4\xb8\xaa\xe5\x88\xab\xe4\xba\xba\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\n# import torchvision.models as models\n# resnet18 = models.resnet18(pretrained=True)\n# alexnet = models.alexnet(pretrained=True)\n\nimport torchvision.models as models\n# \xe5\x8a\xa0\xe8\xbd\xbd\xe4\xb8\x80\xe4\xb8\xaa resnet18 \xe6\xa8\xa1\xe5\x9e\x8b\nresnet18 = models.resnet18()\nprint(resnet18)\n\nimport torchvision.models as models\nresnet18 = models.resnet18(pretrained=True) # \xe5\x8a\xa0\xe8\xbd\xbd\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb7\xb2\xe7\xbb\x8f\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c \xe9\x9c\x80\xe8\xa6\x81\xe4\xb8\x8b\xe8\xbd\xbd\xe4\xb8\x80\xe6\xae\xb5\xe6\x97\xb6\xe9\x97\xb4... \n\n\n\n# torchvision.transforms\n# transforms \xe6\xa8\xa1\xe5\x9d\x97\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86\xe4\xb8\x80\xe8\x88\xac\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe8\xbd\xac\xe6\x8d\xa2\xe6\x93\x8d\xe4\xbd\x9c\xe7\xb1\xbb\xe3\x80\x82\n# \xe4\xb8\xbe\xe4\xb8\xa4\xe4\xb8\xaa\xe4\xbe\x8b\xe5\xad\x90\n# class torchvision.transforms.ToTensor \n# \xe6\x8a\x8ashape=(H x W x C)\xe7\x9a\x84\xe5\x83\x8f\xe7\xb4\xa0\xe5\x80\xbc\xe8\x8c\x83\xe5\x9b\xb4\xe4\xb8\xba[0, 255]\xe7\x9a\x84PIL.Image\xe6\x88\x96\xe8\x80\x85numpy.ndarray\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90shape=(C x H x W)\xe7\x9a\x84\xe5\x83\x8f\xe7\xb4\xa0\xe5\x80\xbc\xe8\x8c\x83\xe5\x9b\xb4\xe4\xb8\xba[0.0, 1.0]\xe7\x9a\x84torch.FloatTensor\xe3\x80\x82\n# class torchvision.transforms.Normalize(mean, std) \n# \xe7\xbb\x99\xe5\xae\x9a\xe5\x9d\x87\xe5\x80\xbc(R, G, B)\xe5\x92\x8c\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae(R, G, B)\xef\xbc\x8c\xe7\x94\xa8\xe5\x85\xac\xe5\xbc\x8fchannel = (channel - mean) / std\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xa7\x84\xe8\x8c\x83\xe5\x8c\x96\xe3\x80\x82\n# \xe5\xbd\x93\xe7\x84\xb6\xef\xbc\x8c\xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8\n# class torchvision.transforms.RandomCrop(size, padding=0)\n# \xe6\x88\x96\xe8\x80\x85\n# class torchvision.transforms.RandomSizedCrop(size, interpolation=2)\n# \xe6\x9d\xa5\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84 augment\n# \xe7\x84\xb6\xe5\x90\x8e\xe5\xa6\x82\xe6\x9e\x9c\xe9\x9c\x80\xe8\xa6\x81\xe5\x90\x8c\xe6\x97\xb6\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xbf\x99\xe4\xba\x9b\xe6\x93\x8d\xe4\xbd\x9c\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8\xe4\xb8\x80\xe4\xb8\xaa\n# class torchvision.transforms.Compose(transforms)\n# \xe6\x9d\xa5\xe6\x8a\x8a\xe5\xa4\x9a\xe4\xb8\xaatransform\xe7\xbb\x84\xe5\x90\x88\xe8\xb5\xb7\xe6\x9d\xa5\xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82\n# \xe5\xa6\x82\xe4\xb8\x8b\xe6\x89\x80\xe7\xa4\xba:\n\n# \xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x99\xe9\x87\x8c\xe8\xbf\x98\xe6\x98\xaf\xe5\xaf\xb9MNIST\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\x88\x9d\xe5\xa7\x8b\xe7\x9a\x84MNIST\xe6\x98\xaf 28 * 28\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x8a\x8a\xe5\xae\x83\xe5\xa4\x84\xe7\x90\x86\xe6\x88\x90 96 * 96 \xe7\x9a\x84torch.Tensor\xe7\x9a\x84\xe6\xa0\xbc\xe5\xbc\x8f\nfrom torchvision import transforms as transforms\nimport torchvision\nfrom torch.utils.data import DataLoader\n\n# \xe5\x9b\xbe\xe5\x83\x8f\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe6\xad\xa5\xe9\xaa\xa4\ntransform = transforms.Compose([\n    transforms.Resize(96), # \xe7\xbc\xa9\xe6\x94\xbe\xe5\x88\xb0 96 * 96 \xe5\xa4\xa7\xe5\xb0\x8f\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n])\n\nDOWNLOAD = True\nBATCH_SIZE = 32\n\ntrain_dataset = torchvision.datasets.MNIST(root=\'./data/\', train=True, transform=transform, download=DOWNLOAD)\n\n\ntrain_loader = DataLoader(dataset=train_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True)\n\nprint(len(train_dataset))\nprint(len(train_loader))'"
basis/py/fine_tune.py,5,"b'# 1.\xe5\xaf\xb9\xe5\xb1\x82\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xa4\x84\xe7\x90\x86\n\n# \xe7\x8e\xb0\xe5\x9c\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xbe\x97\xe5\x88\xb0\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa LeNet\xef\xbc\x8c\xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96\xe4\xb9\x8b\xe5\x90\x8e\xe6\x89\x93\xe5\x8d\xb0\xef\xbc\x8c\xe7\xbb\x93\xe6\x9e\x9c\xe5\xa6\x82\xe4\xb8\x8b\xe6\x89\x80\xe7\xa4\xba\xef\xbc\x9a\n\n# ```\n# LeNet5(\n#   (conv1): Conv2d(224, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n#   (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n#   (fc1): Linear(in_features=400, out_features=120, bias=True)\n#   (fc2): Linear(in_features=120, out_features=84, bias=True)\n#   (fc3): Linear(in_features=84, out_features=10, bias=True)\n# )\n# ```\n\n# \xe7\x84\xb6\xe5\x90\x8e\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\x8e\xb0\xe5\x9c\xa8\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\xb8\xa6\xe6\x9c\x89 ""conv"" \xe7\x9a\x84\xe5\xb1\x82\xe5\x85\xa8\xe9\x83\xa8\xe5\x88\xa0\xe9\x99\xa4\xef\xbc\x88\xe6\x9b\xbf\xe6\x8d\xa2\xef\xbc\x89\xe6\x88\x91\xe4\xbb\xac\xe8\xaf\xa5\xe6\x80\x8e\xe4\xb9\x88\xe5\x81\x9a\xe5\x91\xa2\xef\xbc\x9f\n\n# \xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe9\x87\x8d\xe6\x96\xb0\xe5\x86\x99\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x98\x9b\xef\xbc\x9f\n\n# NOOOOO\xef\xbc\x81\xef\xbc\x81\xef\xbc\x81\n\n# \xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xef\xbc\x8c Pytorch \xe7\x9a\x84\xe5\xb1\x82\xe6\x98\xaf\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x9a\x8f\xe6\x84\x8f\xe6\x9b\xbf\xe6\x8d\xa2\xe7\x9a\x84\xef\xbc\x81\xef\xbc\x81\xef\xbc\x81\xe6\x88\x91\xe4\xbb\xac\xe9\x9a\x8f\xe6\x97\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xa2\x9e\xe5\x8a\xa0\xef\xbc\x8c\xe4\xbf\xae\xe6\x94\xb9\xe3\x80\x82\n\n\n\n\nimport torch\nimport torch.nn as nn\n\nclass LeNet5(nn.Module):\n    def __init__(self, in_dim, n_class):\n        super(LeNet5, self).__init__()\n        self.conv1 = nn.Conv2d(in_dim, 6, 5, padding=2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, n_class)\n        \n        # \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\n        for p in self.modules():\n            if isinstance(p, nn.Conv2d):\n                nn.init.xavier_normal(p.weight.data)\n            elif isinstance(p, nn.Linear):\n                nn.init.normal(p.weight.data)\n\n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:]\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n\n\nimport re\n\n# \xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96 LeNet\n\nlenet = LeNet5(224, 10)\n\ndel_list = [] # \xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\xa0\xe9\x99\xa4\xe7\x9a\x84\xe5\xb1\x82\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe6\x94\xbe\xe8\xbf\x9b\xe8\xbf\x99\xe5\x88\x97\xe8\xa1\xa8\xe9\x87\x8c\xe9\x9d\xa2\nfor name, module in lenet.named_children():\n    # \xe5\xaf\xb9\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\xb1\x82\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8c\xb9\xe9\x85\x8d\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe5\xb1\x82\xe4\xb8\xad\xe5\x90\xab\xe6\x9c\x89conv\xe5\x88\x99\xe6\x8a\x8a\xe5\x90\x8d\xe5\xad\x97\xe6\x94\xbe\xe5\x85\xa5\xe7\xad\x89\xe5\xbe\x85\xe5\x88\xa0\xe9\x99\xa4\xe5\x88\x97\xe8\xa1\xa8\xe4\xb8\xad\n    if re.match(""conv"", name) != None:\n        del_list.append(name)\n\n# \xe8\x8e\xb7\xe5\x8f\x96\xe4\xba\x86\xe6\x89\x80\xe6\x9c\x89\xe5\xb8\xa6 ""conv"" \xe5\xb1\x82\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe4\xba\x86\xef\xbc\x8c\xe7\x8e\xb0\xe5\x9c\xa8\xe5\xbc\x80\xe5\xa7\x8b\xe5\x88\xa0\xe9\x99\xa4\nfor name in del_list:\n    delattr(lenet, name)\n\n\n\n\n# print(lenet) \xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xa6\x82\xe4\xb8\x8b\xe6\x89\x80\xe7\xa4\xba\n\n# ```\n# LeNet5(|\n#   (fc1): Linear(in_features=400, out_features=120, bias=True)\n#   (fc2): Linear(in_features=120, out_features=84, bias=True)\n#   (fc3): Linear(in_features=84, out_features=10, bias=True)\n# )\n# ```\n\n# ----------------------------------------------- \xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf ---------------------------------------------------------\n\n# 2.\xe6\x94\xb9\xe5\x8f\x98\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe7\x9a\x84\xe6\x9f\x90 sequential \xe5\xb1\x82\xe9\x87\x8c\xe9\x9d\xa2\xe7\x9a\x84\xe6\x9f\x90\xe4\xb8\x80\xe5\xb1\x82\n\n# \xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbb\xa5Alexnet\xe4\xb8\xba\xe4\xbe\x8b\n\n# ```\n# AlexNet(\n#   (features): Sequential(\n#     (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n#     (1): ReLU(inplace)\n#     (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n#     (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n#     (4): ReLU(inplace)\n#     (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n#     (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n#     (7): ReLU(inplace)\n#     (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n#     (9): ReLU(inplace)\n#     (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n#     (11): ReLU(inplace)\n#     (12): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n#   )\n#   (classifier): Sequential(\n#     (0): Dropout(p=0.5)\n#     (1): Linear(in_features=9216, out_features=4096, bias=True)\n#     (2): ReLU(inplace)\n#     (3): Dropout(p=0.5)\n#     (4): Linear(in_features=4096, out_features=4096, bias=True)\n#     (5): ReLU(inplace)\n#     (6): Linear(in_features=4096, out_features=1000, bias=True)\n#   )\n# )\n# ```\n\n# \xe6\x9f\x90\xe4\xb8\x80\xe5\xa4\xa9\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\xaa\x81\xe7\x84\xb6\xe5\x8f\x91\xe7\x8e\xb0\xe4\xba\x86 AvgPool \xe7\x9a\x84\xe6\x95\x88\xe6\x9e\x9c\xe6\xaf\x94 Maxpool \xe8\xa6\x81\xe5\xa5\xbd\xef\xbc\x8c\xe4\xba\x8e\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe6\x83\xb3\xe8\xa6\x81\xe6\x94\xb9\xe5\x8f\x98\xe6\x8a\x8a AlextNet\xe4\xb8\xad\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89 Maxpool \xe7\x94\xa8 AvgPool\xe6\x9d\xa5\xe4\xbb\xa3\xe6\x9b\xbf\xe8\xaf\xa5\xe6\x80\x8e\xe4\xb9\x88\xe5\x8a\x9e\xe5\x91\xa2\xef\xbc\x9f\n\n# > \xe6\x9f\xa5\xe7\x9c\x8b Alexnet \xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe7\x9a\x84 Maxpool \xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe6\xb8\x85\xe6\x99\xb0\xe7\x9a\x84\xe5\x8f\x91\xe7\x8e\xb0 Maxpool \xe5\xa4\x84\xe4\xba\x8e features \xe4\xb8\x8b\xe9\x9d\xa2\xe7\x9a\x84 (2)\xe3\x80\x81(5)\xe3\x80\x81(12)\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\xe4\xb8\x8a\n\n\n# \xe4\xba\x8e\xe6\x98\xaf\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x94\xb9\xe5\x8f\x98 features \xe5\xb1\x82\xe4\xb8\x8b\xe9\x9d\xa2\xe7\x9a\x84 (2)\xe3\x80\x81(5)\xe3\x80\x81(12) \xe5\xb0\xb1\xe8\xa1\x8c\xe4\xba\x86\xef\xbc\x8c\xe5\x85\xb7\xe4\xbd\x93\xe6\x93\x8d\xe4\xbd\x9c\xe5\xa6\x82\xe4\xb8\x8b\xe6\x89\x80\xe7\xa4\xba\n\n\n\n\nfrom torchvision import models, transforms, datasets\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch\nfrom torch.autograd import Variable\nimport torch.optim as optim\n\n\nalexnet = models.alexnet(pretrained=False)\n\n\n# \xe6\x94\xb9\xe5\x8f\x98\xe5\x89\x8d\xe7\x9a\x84 alexnet\nprint(alexnet)\n\n# \xe5\xbc\x80\xe5\xa7\x8b\xe6\x94\xb9\xe5\x8f\x98\n\nalexnet.features._modules[\'2\'] = nn.AvgPool2d(kernel_size=(3, 3), stride=(2, 2), ceil_mode=False)\nalexnet.features._modules[\'5\'] = nn.AvgPool2d(kernel_size=(3, 3), stride=(2, 2), ceil_mode=False)\nalexnet.features._modules[\'12\'] = nn.AvgPool2d(kernel_size=(3, 3), stride=(2, 2), ceil_mode=False)\n\n # \xe6\x94\xb9\xe5\x8f\x98\xe5\x90\x8e\xe7\x9a\x84 alexnet\nprint(alexnet)'"
basis/py/linear_regression.py,11,"b'# \xe5\xaf\xbc\xe5\x85\xa5\xe5\xbf\x85\xe8\xa6\x81\xe7\x9a\x84\xe5\x8c\x85\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn # \xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8c\x85\xef\xbc\x8c\xe9\x87\x8c\xe9\x9d\xa2\xe5\x8c\x85\xe5\x90\xab\xe4\xba\x86\xe5\x90\x84\xe7\xa7\x8d\xe5\x90\x84\xe6\xa0\xb7\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe6\x88\x91\xe4\xbb\xac\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8\nimport matplotlib.pyplot as plt\n\n\n# \xe7\x94\x9f\xe6\x88\x90\xe7\x94\xa8\xe6\x9d\xa5\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\nx = torch.unsqueeze(torch.linspace(-1, 1, 200), dim = 1)\ny = 5 * x + 0.8 * torch.rand(x.size())\n\n# \xe7\xbb\x98\xe5\x88\xb6\xe6\xa8\xa1\xe6\x8b\x9f\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\nplt.scatter(x.numpy(), y.numpy())\nplt.show()\n\n\n# \xe4\xb8\xba\xe4\xba\x86\xe8\x83\xbd\xe5\xa4\x9f\xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe5\xb0\x86 x, y \xe5\x8f\x98\xe6\x88\x90 Variable \xe5\xaf\xb9\xe8\xb1\xa1\nX = Variable(x) # PyTorch\xe4\xb8\xad\xe7\x9a\x84 Variable \xe9\xbb\x98\xe8\xae\xa4\xe6\x98\xaf\xe5\x85\x81\xe8\xae\xb8\xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\xe7\x9a\x84\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5 requires_grad=True \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xb8\x8d\xe5\x8a\xa0\nY = Variable(y) # \xe5\x90\x8c\xe4\xb8\x8a\n\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\ndef init_parameters():\n    W = Variable( torch.randn(1, 1), requires_grad=True)  # \xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96 w\n    b = Variable( torch.zeros(1, 1), requires_grad=True )  # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x81\x8f\xe5\xb7\xae\n    parameters = {""W"": W, ""b"": b}\n    return parameters\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\xa8\xa1\xe5\x9e\x8b\ndef model(X, parameters):\n    return X * parameters[""W""] + parameters[""b""]\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\ndef square_loss(y_hat, Y):\n    loss = (y_hat - Y).pow(2).sum()\n    return loss\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9d\xa5\xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\ndef update_parameters(parameters, lr):\n    parameters[""W""].data -= lr * parameters[""W""].grad.data\n    parameters[""b""].data -= lr * parameters[""b""].grad.data\n    return\n\n####     \xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0     ####\nEPOCH = 100 # \xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\nlearning_rate = 0.001 # \xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\n\nparameters = init_parameters() # \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\n\n####     \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83     ####\nfor t in range(EPOCH):\n    # \xe5\xaf\xb9x\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b\n    y_hat = model(X, parameters)\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    loss = square_loss(y_hat, Y)\n    # \xe5\x8f\x8d\xe5\x90\x91\xe6\xb1\x82\xe5\xaf\xbc\n    loss.backward()\n    # \xe9\x80\x9a\xe8\xbf\x87\xe6\xa2\xaf\xe5\xba\xa6\xef\xbc\x8c\xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\n    update_parameters(parameters, learning_rate)\n    if (t+1) % 20 == 0:\n        print(loss)\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\xe4\xbc\x9a\xe5\xaf\xb9\xe6\xa2\xaf\xe5\xba\xa6\xe8\x87\xaa\xe5\x8a\xa8\xe5\x9c\xb0\xe7\xa7\xaf\xe7\xb4\xaf\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe6\xb8\x85\xe9\x99\xa4\xe6\xa2\xaf\xe5\xba\xa6\n    parameters[""W""].grad.data.zero_()\n    parameters[""b""].grad.data.zero_()\n\n# \xe7\x94\xbb\xe5\x9b\xbe\nplt.scatter(X.data.numpy(), Y.data.numpy())\nplt.plot(X.data.numpy(), y_hat.data.numpy(), \'r-\', lw = 4)\nplt.show()\n\nprint(""\xe5\xae\x9e\xe9\x99\x85\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0w\xe6\x98\xaf\xef\xbc\x9a 5 \\n"" )\nprint(""\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0w\xe6\x98\xaf"", parameters[""W""])\nprint(""\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\xb8\xb8\xe6\x95\xb0\xe9\xa1\xb9\xe6\x98\xaf\xef\xbc\x9a"" , parameters[""b""])\n\n# \xe7\x94\xa8torch.nn\xe6\x9d\xa5\xe6\x9e\x84\xe5\xbb\xba\xe6\xa8\xa1\xe5\x9e\x8b\n# \xe5\x9c\xa8PyTorch\xe4\xb8\xad nn \xe5\x8c\x85\xe5\xae\x9a\xe4\xb9\x89\xe4\xba\x86\xe4\xb8\x80\xe7\xb3\xbb\xe5\x88\x97\xe5\x9f\xba\xe6\x9c\xac\xe7\xbb\x84\xe4\xbb\xb6\xef\xbc\x8c\xe8\xbf\x99\xe4\xba\x9b\xe7\xbb\x84\xe4\xbb\xb6\xef\xbc\x88Modules\xef\xbc\x89\xe6\xb6\xb5\xe7\x9b\x96\xe4\xba\x86\xe5\xa4\xa7\xe9\x83\xa8\xe5\x88\x86\xe6\x9e\x84\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe4\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe5\x90\x84\xe7\xa7\x8d\xe5\xb1\x82\xe3\x80\x82\n# \xe4\xb8\x80\xe4\xb8\xaa\xe7\xbb\x84\xe4\xbb\xb6\xef\xbc\x88Modules\xef\xbc\x89\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe6\x98\xafVariable\xef\xbc\x8c\xe7\xbb\x8f\xe8\xbf\x87\xe7\xbb\x84\xe4\xbb\xb6\xe4\xb9\x8b\xe5\x90\x8e\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe5\x8f\x88\xe6\x98\xaf\xe5\x8f\xa6\xe4\xb8\x80\xe4\xb8\xaa Variable\xe3\x80\x82\n# \n# \xe5\xbd\x93\xe7\x84\xb6nn\xe5\x8c\x85\xe4\xb8\xad\xe8\xbf\x98\xe5\x8c\x85\xe5\x90\xab\xe4\xba\x86\xe5\xa4\xa7\xe9\x83\xa8\xe5\x88\x86\xe6\x88\x91\xe4\xbb\xac\xe5\xb9\xb3\xe6\x97\xb6\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\xe3\x80\x82\n# \xe6\x9c\x80\xe5\x90\x8etorch.optim\xe4\xb8\xad\xe8\xbf\x98\xe5\x90\xab\xe6\x9c\x89\xe5\xbe\x88\xe5\xa4\x9a\xe6\x88\x91\xe4\xbb\xac\xe5\xb9\xb3\xe6\x97\xb6\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe7\x94\xa8\xe6\x9d\xa5\xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\xe3\x80\x82\xef\xbc\x88\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x8a\xe9\x9d\xa2\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe5\xb0\xb1\xe6\x98\xaf\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xef\xbc\x8c\xe5\x8f\xaa\xe4\xb8\x8d\xe8\xbf\x87\xe4\xb8\x8a\xe9\x9d\xa2\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe8\x87\xaa\xe5\xb7\xb1\xe6\x89\x8b\xe5\x86\x99\xef\xbc\x8c\xe7\x8e\xb0\xe5\x9c\xa8\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9b\xb4\xe6\x8e\xa5\xe8\xb0\x83\xe7\x94\xa8\xe4\xba\x86\xef\xbc\x89\n# \xe5\x88\x9a\xe6\x89\x8d\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xafTensor\xe5\x92\x8cautograd\xe6\x9d\xa5\xe6\x9e\x84\xe5\xbb\xba\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe7\x8e\xb0\xe5\x9c\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x9d\xa5\xe4\xbd\xbf\xe7\x94\xa8torch.nn\xe6\x9d\xa5\xe5\xbf\xab\xe9\x80\x9f\xe6\x9e\x84\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\n\n\n\n\n\n# \xe8\xbf\x98\xe6\x98\xaf\xe4\xbd\xbf\xe7\x94\xa8\xe4\xb8\x8a\xe8\xbf\xb0\xe7\x9a\x84X\xe5\x92\x8cY\n\nX = Variable(x) # PyTorch\xe4\xb8\xad\xe7\x9a\x84 Variable \xe9\xbb\x98\xe8\xae\xa4\xe6\x98\xaf\xe5\x85\x81\xe8\xae\xb8\xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\xe7\x9a\x84\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5 requires_grad=True \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xb8\x8d\xe5\x8a\xa0\nY = Variable(y) # \xe5\x90\x8c\xe4\xb8\x8a\n\n####     \xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0     ####\nEPOCH = 100 # \xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\nlearning_rate = 0.001 # \xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\n\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\xa8\xa1\xe5\x9e\x8b\n# \xe4\xbd\xbf\xe7\x94\xa8 nn\xe5\x8c\x85\xe6\x9d\xa5\xe5\xae\x9a\xe4\xb9\x89\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe8\xbf\x99\xe9\x87\x8c\xe7\x9a\x84Linear\xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84\xe6\x98\xaf\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe8\xbf\x99\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\n# \xe9\x9c\x80\xe8\xa6\x81\xe4\xbc\xa0\xe5\x85\xa5\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe6\x98\xaf: in_features, out_features \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe8\xbe\x93\xe5\x87\xba\xe7\x89\xb9\xe5\xbe\x81\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\x89\xb9\xe5\xbe\x81\n# \xe9\xbb\x98\xe8\xae\xa4\xe4\xbc\x9a\xe5\xb8\xae\xe6\x88\x91\xe4\xbb\xac\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x9d\x83\xe9\x87\x8d\xef\xbc\x8c\xe5\xbd\x93\xe7\x84\xb6\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x89\x8b\xe5\x8a\xa8\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x9d\x83\xe9\x87\x8d\xef\xbc\x88\xe8\xbf\x99\xe9\x87\x8c\xe6\x9a\x82\xe6\x97\xb6\xe4\xb8\x8d\xe8\xaf\xb4\xef\xbc\x89\nmodel = nn.Linear(1, 1)\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n# \xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8 Mean Square Loss\xe4\xbd\x9c\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n# size_average=False\xe8\xa1\xa8\xe7\xa4\xba\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe6\x98\xaf\xe6\x80\xbb\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe5\x8e\xbb\xe5\xb9\xb3\xe5\x9d\x87\xe8\xaf\xaf\xe5\xb7\xae\nsquare_loss = nn.MSELoss(size_average=False)\n\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe4\xbc\x98\xe5\x8c\x96\xe6\x96\xb9\xe6\xb3\x95\n# \xe4\xbb\xa5\xe5\x89\x8d\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xe9\x83\xbd\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe6\x89\x8b\xe5\x86\x99\xe7\x9a\x84\xef\xbc\x8c\xe7\x8e\xb0\xe5\x9c\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8nn\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x81\xe8\xa3\x85\xe5\xa5\xbd\xe7\x9a\x84\xe3\x80\x82\n# \xe4\xbd\xbf\xe7\x94\xa8optim\xe5\x8c\x85\xe6\x9d\xa5\xe5\xae\x9a\xe4\xb9\x89\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\x87\xaa\xe5\x8a\xa8\xe7\x9a\x84\xe5\xb8\xae\xe6\x88\x91\xe4\xbb\xac\xe5\xaf\xb9\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\n# model.parameters()\xe4\xbc\x9a\xe8\x87\xaa\xe5\x8a\xa8\xe7\x9a\x84\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x86\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe6\x8f\x90\xe5\x8f\x96\xe5\x87\xba\xe6\x9d\xa5\xe3\x80\x82\xe7\x84\xb6\xe5\x90\x8e\xe6\x88\x91\xe4\xbb\xac\xe5\x91\x8a\xe8\xaf\x89\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\xef\xbc\x8c\xe5\xae\x83\xe4\xbb\xac\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe6\x9b\xb4\xe6\x96\xb0\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe3\x80\x82\n# lr\xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84\xe6\x98\xaf\xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n####     \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83     ####\nfor t in range(EPOCH):\n    \n    # \xe6\xb2\xa1\xe6\x9c\x89\xe5\x8f\x98\xe5\x8c\x96\xef\xbc\x8c\xe8\xbf\x98\xe6\x98\xaf\xe8\xbf\x99\xe6\xa0\xb7\xe4\xbd\xbf\xe7\x94\xa8\xef\xbc\x9a\xe5\xaf\xb9x\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b\n    y_hat = model(X)\n    \n    # \xe6\xb2\xa1\xe6\x9c\x89\xe5\x8f\x98\xe5\x8c\x96\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    loss = square_loss(y_hat, Y)\n    \n    # \xe6\x89\x93\xe5\x8d\xb0\xe6\x8d\x9f\xe5\xa4\xb1\n    if (t+1) % 20 == 0:\n        print(loss)\n    # \xe5\x9c\xa8\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\x8d\xe5\x90\x91\xe6\xb1\x82\xe5\xaf\xbc\xe4\xb9\x8b\xe5\x89\x8d\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe6\xb8\x85\xe7\xa9\xba\xe7\xa7\xaf\xe7\xb4\xaf\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xef\xbc\x8c\xe7\x94\xb1\xe4\xba\x8e\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf torch.optim\xe5\x8c\x85\xe4\xb8\xad\xe7\x9a\x84\xe5\xaf\xb9\xe8\xb1\xa1\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9b\xb4\xe6\x8e\xa5\xe8\xb0\x83\xe7\x94\xa8\n    # \xe8\xaf\xa5\xe5\xaf\xb9\xe8\xb1\xa1\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x8c\xe6\x9d\xa5\xe8\x87\xaa\xe5\x8a\xa8\xe7\x9a\x84\xe6\xb8\x85\xe7\xa9\xba\xe7\xa7\xaf\xe7\xb4\xaf\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\n    optimizer.zero_grad()\n    \n    # \xe5\x8f\x8d\xe5\x90\x91\xe6\xb1\x82\xe5\xaf\xbc\xef\xbc\x8c\xe4\xb9\x9f\xe6\xb2\xa1\xe5\x8f\x98\n    loss.backward()\n    \n    # \xe5\x8f\x8d\xe5\x90\x91\xe6\xb1\x82\xe5\xaf\xbc\xe7\xbb\x93\xe6\x9d\x9f\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xbc\x80\xe5\xa7\x8b\xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\xef\xbc\x8c\xe4\xbb\xa5\xe5\x89\x8d\xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\xe9\x9c\x80\xe8\xa6\x81\xe6\x89\x8b\xe5\x8a\xa8\xe8\xbe\x93\xe5\x85\xa5w1.grad.data\xef\xbc\x8c\xe7\x8e\xb0\xe5\x9c\xa8\xe5\x8f\xaa\xe9\x9c\x80\xe8\xa6\x81\xe4\xb8\x80\xe8\xa1\x8c\xe4\xbb\xa3\xe7\xa0\x81\xe5\xb0\xb1\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x90\x9e\xe5\xae\x9a\xe4\xba\x86\xef\xbc\x81\n    optimizer.step()\n    \n\n\n# \xe7\x94\xbb\xe5\x9b\xbe\nplt.scatter(X.data.numpy(), Y.data.numpy())\nplt.plot(X.data.numpy(), y_hat.data.numpy(), \'r-\', lw = 4)\nplt.show()\n\nprint(""\xe5\xae\x9e\xe9\x99\x85\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0w\xe6\x98\xaf\xef\xbc\x9a 5 \\n"" )\nprint(""\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0w\xe6\x98\xaf"", parameters[""W""])\nprint(""\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\xb8\xb8\xe6\x95\xb0\xe9\xa1\xb9\xe6\x98\xaf\xef\xbc\x9a"" , parameters[""b""])'"
basis/py/mlp.py,31,"b'# \xe5\x85\x88\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe7\x83\xad\xe8\xba\xab\xe9\xa2\x98\xe7\x9b\xae\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8Tensor\xe6\x9e\x84\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa\xe4\xb8\xa4\xe5\xb1\x82\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\n# Tips:\xe9\x80\x9a\xe5\xb8\xb8\xe6\x9e\x84\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x9c\x89\xe5\xa6\x82\xe4\xb8\x8b\xe6\xad\xa5\xe9\xaa\xa4\n# 1\xe3\x80\x81\xe6\x9e\x84\xe5\xbb\xba\xe5\xa5\xbd\xe7\xbd\x91\xe7\xbb\x9c\xe6\xa8\xa1\xe5\x9e\x8b\n# 2\xe3\x80\x81\xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\n# 3\xe3\x80\x81\xe5\x89\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\n# 4\xe3\x80\x81\xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n# 5\xe3\x80\x81\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe6\xb1\x82\xe5\x87\xba\xe6\xa2\xaf\xe5\xba\xa6\n# 6\xe3\x80\x81\xe6\x9b\xb4\xe6\x96\xb0\xe6\x9d\x83\xe9\x87\x8d\n\n# \xe5\x9c\xa8\xe6\x88\x91\xe4\xbb\xac\xe6\x9e\x84\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe4\xb9\x8b\xe5\x89\x8d\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x85\x88\xe4\xbb\x8b\xe7\xbb\x8d\xe4\xb8\x80\xe4\xb8\xaaTensor\xe7\x9a\x84\xe5\x86\x85\xe7\xbd\xae\xe5\x87\xbd\xe6\x95\xb0 clamp()\n# \xe8\xaf\xa5\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x8a\x9f\xe8\x83\xbd\xe6\x98\xaf\xef\xbc\x9a\xe5\xb0\x86\xe8\xbe\x93\xe5\x85\xa5 Tensor \xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe5\xa4\xb9\xe7\xb4\xa7\xe5\x88\xb0\xe5\x8c\xba\xe9\x97\xb4 [min,max]\xe4\xb8\xad\xef\xbc\x8c\xe5\xb9\xb6\xe8\xbf\x94\xe5\x9b\x9e\xe7\xbb\x93\xe6\x9e\x9c\xe5\x88\xb0\xe4\xb8\x80\xe4\xb8\xaa\xe6\x96\xb0\xe7\x9a\x84Tensor\xe3\x80\x82\n# \xe8\xbf\x99\xe6\xa0\xb7\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb0\xb1\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8 x.clamp(min=0) \xe6\x9d\xa5\xe4\xbb\xa3\xe6\x9b\xbf relu\xe5\x87\xbd\xe6\x95\xb0\n\nimport torch\n# M\xe6\x98\xaf\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x8cinput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x85\xa5\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\n# hidden_size\xe6\x98\xaf\xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8coutput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\nM, input_size, hidden_size, output_size = 64, 1000, 100, 10\n\n# \xe7\x94\x9f\xe6\x88\x90\xe9\x9a\x8f\xe6\x9c\xba\xe6\x95\xb0\xe5\xbd\x93\xe4\xbd\x9c\xe6\xa0\xb7\xe6\x9c\xac\nx = torch.randn(M, input_size) #size(64, 1000)\ny = torch.randn(M, output_size) #size(64, 10)\n\n# \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\ndef init_parameters():\n    w1 = torch.randn(input_size, hidden_size)\n    w2 = torch.randn(hidden_size, output_size)\n    b1 = torch.randn(1, hidden_size)\n    b2 = torch.randn(1, output_size)\n    return {""w1"": w1, ""w2"":w2, ""b1"": b1, ""b2"": b2}\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\xa8\xa1\xe5\x9e\x8b\ndef model(x, parameters):\n    Z1 = x.mm(parameters[""w1""]) + parameters[""b1""] # \xe7\xba\xbf\xe6\x80\xa7\xe5\xb1\x82\n    A1 = Z1.clamp(min=0) # relu\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\n    Z2 = A1.mm(parameters[""w2""]) + parameters[""b2""] #\xe7\xba\xbf\xe6\x80\xa7\xe5\xb1\x82\n    # \xe4\xb8\xba\xe4\xba\x86\xe6\x96\xb9\xe4\xbe\xbf\xe5\x8f\x8d\xe5\x90\x91\xe6\xb1\x82\xe5\xaf\xbc\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbc\x9a\xe6\x8a\x8a\xe5\xbd\x93\xe5\x89\x8d\xe6\xb1\x82\xe5\xbe\x97\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe4\xbf\x9d\xe5\xad\x98\xe5\x9c\xa8\xe4\xb8\x80\xe4\xb8\xaacache\xe4\xb8\xad\n    cache = {""Z1"": Z1, ""A1"": A1}\n    return Z2, cache\n\n# \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\ndef loss_fn(y_pred, y):\n    loss = (y_pred - y).pow(2).sum() # \xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x99\xe9\x87\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8 MSE(\xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae) \xe4\xbd\x9c\xe4\xb8\xba\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n    return loss\n\n# \xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xef\xbc\x8c\xe6\xb1\x82\xe5\x87\xba\xe6\xa2\xaf\xe5\xba\xa6\ndef backpropogation(x, y, y_pred, cache, parameters):\n    m = y.size()[0] # m\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\n    # \xe4\xbb\xa5\xe4\xb8\x8b\xe6\x98\xaf\xe5\x8f\x8d\xe5\x90\x91\xe6\xb1\x82\xe5\xaf\xbc\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\xef\xbc\x9a\n    d_y_pred = 1/m * (y_pred - y)\n    d_w2 = 1/m * cache[""A1""].t().mm(d_y_pred)\n    d_b2 = 1/m * torch.sum(d_y_pred, 0, keepdim=True)\n    d_A1 = d_y_pred.mm(parameters[""w2""].t())\n    # \xe5\xaf\xb9 relu \xe5\x87\xbd\xe6\x95\xb0\xe6\xb1\x82\xe5\xaf\xbc: start\n    d_Z1 = d_A1.clone()\n    d_Z1[cache[""Z1""] < 0] = 0\n    # \xe5\xaf\xb9 relu \xe5\x87\xbd\xe6\x95\xb0\xe6\xb1\x82\xe5\xaf\xbc: end\n    d_w1 = 1/m * x.t().mm(d_Z1)\n    d_b1 = 1/m * torch.sum(d_Z1, 0, keepdim=True)\n    grads = {\n        ""d_w1"": d_w1, \n        ""d_b1"": d_b1, \n        ""d_w2"": d_w2, \n        ""d_b2"": d_b2\n    }\n    return grads\n\n# \xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\ndef update(lr, parameters, grads):\n    parameters[""w1""] -= lr * grads[""d_w1""]\n    parameters[""w2""] -= lr * grads[""d_w2""]\n    parameters[""b1""] -= lr * grads[""d_b1""]\n    parameters[""b2""] -= lr * grads[""d_b2""]\n    return parameters\n\n## \xe8\xae\xbe\xe7\xbd\xae\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0 ##\n\nlearning_rate = 1e-2\nEPOCH = 400\n\n# \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\nparameters = init_parameters()\n\n## \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83 ##\nfor t in range(EPOCH):    \n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    y_pred, cache = model(x, parameters)\n    \n    # \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    loss = loss_fn(y_pred, y)\n    if (t+1) % 50 == 0:\n        print(loss)\n    # \xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\n    grads = backpropogation(x, y, y_pred, cache, parameters)\n    # \xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\n    parameters = update(learning_rate, parameters, grads)\n\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n\n# \xe5\x8a\xa0\xe4\xb8\x8aVariable\xe6\x9d\xa5\xe5\x86\x99\xe5\xa4\x9a\xe5\xb1\x82\xe6\x84\x9f\xe7\x9f\xa5\xe6\x9c\xba\n# \xe7\x8e\xb0\xe5\x9c\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x9d\xa5\xe4\xbd\xbf\xe7\x94\xa8 Variable \xe9\x87\x8d\xe6\x96\xb0\xe6\x9e\x84\xe5\xbb\xba\xe4\xb8\x8a\xe8\xbf\xb0\xe7\x9a\x84\xe4\xb8\xa4\xe5\xb1\x82\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb7\xb2\xe7\xbb\x8f\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe5\x86\x8d\xe4\xbd\xbf\xe7\x94\xa8\xe6\x89\x8b\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\xe4\xba\x86\xef\xbc\x88\xe5\x9b\xa0\xe4\xb8\xba\xe6\x9c\x89\xe4\xba\x86\xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\xe7\x9a\x84\xe6\x9c\xba\xe5\x88\xb6\xe5\x95\x8a~\xef\xbc\x89\n# \xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x88\xb0\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe4\xb8\x8b\xe9\x9d\xa2\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe5\xb7\xb2\xe7\xbb\x8f\xe7\xb2\xbe\xe7\xae\x80\xe5\xbe\x88\xe5\xa4\x9a\xe4\xba\x86...\n\nimport torch\nfrom torch.autograd import Variable # \xe5\xaf\xbc\xe5\x85\xa5 Variable \xe5\xaf\xb9\xe8\xb1\xa1\n\n# M\xe6\x98\xaf\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x8cinput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x85\xa5\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\n# hidden_size\xe6\x98\xaf\xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8coutput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\nM, input_size, hidden_size, output_size = 64, 1000, 100, 10\n\n# \xe7\x94\x9f\xe6\x88\x90\xe9\x9a\x8f\xe6\x9c\xba\xe6\x95\xb0\xe5\xbd\x93\xe4\xbd\x9c\xe6\xa0\xb7\xe6\x9c\xac\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe7\x94\xa8Variable \xe6\x9d\xa5\xe5\x8c\x85\xe8\xa3\x85\xe8\xbf\x99\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xae\xbe\xe7\xbd\xae requires_grad=False \xe8\xa1\xa8\xe7\xa4\xba\xe5\x9c\xa8\xe6\x96\xb9\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\n# \xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\xb1\x82\xe8\xbf\x99\xe5\x87\xa0\xe4\xb8\xaa Variable \xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\nx = Variable(torch.randn(M, input_size), requires_grad=False)\ny = Variable(torch.randn(M, output_size), requires_grad=False)\n\n# \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe7\x94\xa8Variable \xe6\x9d\xa5\xe5\x8c\x85\xe8\xa3\x85\xe8\xbf\x99\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xae\xbe\xe7\xbd\xae requires_grad=True \xe8\xa1\xa8\xe7\xa4\xba\xe5\x9c\xa8\xe6\x96\xb9\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\n# \xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe8\xbf\x99\xe5\x87\xa0\xe4\xb8\xaa Variable \xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\ndef init_parameters():\n    w1 = Variable(torch.randn(input_size, hidden_size), requires_grad=True)\n    w2 = Variable(torch.randn(hidden_size, output_size), requires_grad=True)\n    b1 = Variable(torch.randn(1, hidden_size), requires_grad=True)\n    b2 = Variable(torch.randn(1, output_size), requires_grad=True)\n    return {""w1"": w1, ""w2"":w2, ""b1"": b1, ""b2"": b2}\n\n# \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\ndef model(x, parameters):\n    Z1 = x.mm(parameters[""w1""]) + parameters[""b1""] # \xe7\xba\xbf\xe6\x80\xa7\xe5\xb1\x82\n    A1 = Z1.clamp(min=0) # relu\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\n    Z2 = A1.mm(parameters[""w2""]) + parameters[""b2""] #\xe7\xba\xbf\xe6\x80\xa7\xe5\xb1\x82\n    return Z2\n\n# \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\ndef loss_fn(y_pred, y):\n    loss = (y_pred - y).pow(2).sum() # \xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x99\xe9\x87\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbd\xbf\xe7\x94\xa8 MSE(\xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae) \xe4\xbd\x9c\xe4\xb8\xba\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n    return loss\n\n## \xe8\xae\xbe\xe7\xbd\xae\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0 ##\nlearning_rate = 1e-6\nEPOCH = 300\n\n# \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\nparameters = init_parameters()\n\n## \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83 ##\nfor t in range(EPOCH):    \n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    y_pred= model(x, parameters)\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    loss = loss_fn(y_pred, y)\n    # \xe8\xae\xa1\xe7\xae\x97\xe5\x92\x8c\xe6\x89\x93\xe5\x8d\xb0\xe9\x83\xbd\xe6\x98\xaf\xe5\x9c\xa8 Variables \xe4\xb8\x8a\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x93\x8d\xe4\xbd\x9c\xe7\x9a\x84\xef\xbc\x8c\xe8\xbf\x99\xe6\x97\xb6\xe5\x80\x99\xe7\x9a\x84 loss \xe6\x97\xb6\xe4\xb8\x80\xe4\xb8\xaa Variable \xef\xbc\x8c\n    # \xe5\xae\x83\xe7\x9a\x84size() \xe6\x98\xaf (1,)\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5 loss.data \xe7\x9a\x84size() \xe4\xb9\x9f\xe6\x98\xaf (1,)\n    # \xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x8c loss.data[0] \xe6\x89\x8d\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe5\xae\x9e\xe5\x80\xbc\n    if (t+1) % 50 == 0:\n        print(loss.data[0])\n    # \xe4\xbd\xbf\xe7\x94\xa8\xe8\x87\xaa\xe5\x8a\xa8\xe6\xb1\x82\xe5\xaf\xbc\xe6\x9d\xa5\xe8\xae\xa1\xe7\xae\x97\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe6\x96\xb9\xe6\xb3\x95\xe4\xbc\x9a\xe6\x8a\x8a\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\xae\xbe\xe7\xbd\xae\xe4\xba\x86requires_grad=True \xe7\x9a\x84Variable \xe5\xaf\xb9\xe8\xb1\xa1\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe5\x85\xa8\xe9\x83\xa8\xe8\x87\xaa\xe5\x8a\xa8\xe5\x87\xba\xe6\x9d\xa5\n    # \xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xef\xbc\x8c\xe5\xb0\xb1\xe6\x98\xaf\xe6\xb1\x82\xe5\x87\xba\xe4\xba\x86 w1, w2, b1, b2\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\n    loss.backward()\n    \n    # \xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c .data \xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84\xe9\x83\xbd\xe6\x98\xafTensor\n    parameters[""w1""].data -= learning_rate * parameters[""w1""].grad.data\n    parameters[""w2""].data -= learning_rate * parameters[""w2""].grad.data\n    parameters[""b1""].data -= learning_rate * parameters[""b1""].grad.data\n    parameters[""b2""].data -= learning_rate * parameters[""b2""].grad.data\n    \n    # \xe7\x94\xb1\xe4\xba\x8ePyTorch\xe4\xb8\xad\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe6\x98\xaf\xe4\xbc\x9a\xe7\xb4\xaf\xe5\x8a\xa0\xe7\x9a\x84\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xa0\xe6\xb2\xa1\xe6\x9c\x89\xe6\x89\x8b\xe5\x8a\xa8\xe6\xb8\x85\xe7\xa9\xba\xe6\xa2\xaf\xe5\xba\xa6\xef\xbc\x8c\xe9\x82\xa3\xe4\xb9\x88\xe4\xb8\x8b\xe6\xac\xa1\xe4\xbd\xa0\xe5\xae\xb6\xe7\x9a\x84grad\xe5\xb0\xb1\xe6\x98\xaf\xe8\xbf\x99\xe6\xac\xa1\xe5\x92\x8c\xe4\xb8\x8a\xe6\xac\xa1\xe7\x9a\x84grad\xe7\x9a\x84\xe7\xb4\xaf\xe5\x8a\xa0\xe5\x92\x8c\xe3\x80\x82\n    # \xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe6\xaf\x8f\xe6\xac\xa1\xe9\x83\xbd\xe5\x8f\xaa\xe6\x98\xaf\xe4\xbd\xbf\xe7\x94\xa8\xe5\xbd\x93\xe5\x89\x8d\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe6\x89\x8b\xe5\x8a\xa8\xe6\xb8\x85\xe7\xa9\xba\xe6\xa2\xaf\xe5\xba\xa6\n    parameters[""w1""].grad.data.zero_()\n    parameters[""w2""].grad.data.zero_()\n    parameters[""b1""].grad.data.zero_()\n    parameters[""b2""].grad.data.zero_()\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n# \xe4\xbd\xbf\xe7\x94\xa8nn\xe5\x92\x8coptim\xe6\x9d\xa5\xe6\x9e\x84\xe5\xbb\xba\xe5\xa4\x9a\xe5\xb1\x82\xe6\x84\x9f\xe7\x9f\xa5\xe6\x9c\xba\n# \xe6\x88\x91\xe4\xbb\xac\xe4\xb9\x8b\xe5\x89\x8d\xe5\xb7\xb2\xe7\xbb\x8f\xe5\xad\xa6\xe8\xbf\x87\xe4\xba\x86\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8 nn \xe5\xbf\xab\xe9\x80\x9f\xe6\x90\xad\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa\xe7\xba\xbf\xe6\x80\xa7\xe6\xa8\xa1\xe5\x9e\x8b\xe3\x80\x82\n# \xe7\x8e\xb0\xe5\x9c\xa8\xe5\xb0\xb1\xe7\x94\xa8 nn \xe6\x9d\xa5\xe5\xbf\xab\xe9\x80\x9f\xe7\x9a\x84\xe6\x90\xad\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa\xe5\xa4\x9a\xe5\xb1\x82\xe6\x84\x9f\xe7\x9f\xa5\xe6\x9c\xba\xef\xbc\x8c\xe5\x90\x8c\xe6\xa0\xb7\xe7\x9a\x84optim\xe6\x9d\xa5\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe6\x8f\x90\xe4\xbe\x9b\xe4\xbc\x98\xe5\x8c\x96\xe5\x8a\x9f\xe8\x83\xbd\n\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\n\n# M\xe6\x98\xaf\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x8cinput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x85\xa5\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\n# hidden_size\xe6\x98\xaf\xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8coutput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\nM, input_size, hidden_size, output_size = 64, 1000, 100, 10\n\n# \xe7\x94\x9f\xe6\x88\x90\xe9\x9a\x8f\xe6\x9c\xba\xe6\x95\xb0\xe5\xbd\x93\xe4\xbd\x9c\xe6\xa0\xb7\xe6\x9c\xac\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe7\x94\xa8Variable \xe6\x9d\xa5\xe5\x8c\x85\xe8\xa3\x85\xe8\xbf\x99\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xae\xbe\xe7\xbd\xae requires_grad=False \xe8\xa1\xa8\xe7\xa4\xba\xe5\x9c\xa8\xe6\x96\xb9\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\n# \xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\xb1\x82\xe8\xbf\x99\xe5\x87\xa0\xe4\xb8\xaa Variable \xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\nx = Variable(torch.randn(M, input_size))\ny = Variable(torch.randn(M, output_size))\n\n# \xe4\xbd\xbf\xe7\x94\xa8 nn \xe5\x8c\x85\xe7\x9a\x84 Sequential \xe6\x9d\xa5\xe5\xbf\xab\xe9\x80\x9f\xe6\x9e\x84\xe5\xbb\xba\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8cSequential\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaa\xe7\xbb\x84\xe4\xbb\xb6\xe7\x9a\x84\xe5\xae\xb9\xe5\x99\xa8\xe3\x80\x82\n# \xe5\xae\x83\xe6\xb6\xb5\xe7\x9b\x96\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe4\xb8\xad\xe7\x9a\x84\xe5\xbe\x88\xe5\xa4\x9a\xe5\xb1\x82\xef\xbc\x8c\xe5\xb9\xb6\xe5\xb0\x86\xe8\xbf\x99\xe4\xba\x9b\xe5\xb1\x82\xe7\xbb\x84\xe5\x90\x88\xe5\x9c\xa8\xe4\xb8\x80\xe8\xb5\xb7\xe6\x9e\x84\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b.\n# \xe4\xb9\x8b\xe5\x90\x8e\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe4\xbc\x9a\xe6\x8c\x89\xe7\x85\xa7\xe8\xbf\x99\xe4\xb8\xaaSequential\xe7\x9a\x84\xe6\xb5\x81\xe7\xa8\x8b\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe4\xbc\xa0\xe8\xbe\x93\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\xb1\x82\xe5\xb0\xb1\xe6\x98\xaf\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe3\x80\x82\n# \xe9\xbb\x98\xe8\xae\xa4\xe4\xbc\x9a\xe5\xb8\xae\xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\nmodel = nn.Sequential(\n    nn.Linear(input_size, hidden_size),\n    nn.ReLU(),\n    nn.Linear(hidden_size, output_size),\n)\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\nloss_fn = nn.MSELoss(size_average=False)\n\n## \xe8\xae\xbe\xe7\xbd\xae\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0 ##\nlearning_rate = 1e-4\nEPOCH = 300\n\n# \xe4\xbd\xbf\xe7\x94\xa8optim\xe5\x8c\x85\xe6\x9d\xa5\xe5\xae\x9a\xe4\xb9\x89\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\x87\xaa\xe5\x8a\xa8\xe7\x9a\x84\xe5\xb8\xae\xe6\x88\x91\xe4\xbb\xac\xe5\xaf\xb9\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe3\x80\x82\xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xe3\x80\x82\n# \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe4\xbc\xa0\xe5\x85\xa5\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe6\x98\xaf\xe5\x91\x8a\xe8\xaf\x89\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe7\x9a\x84Variable \xe6\x98\xaf\xe5\x93\xaa\xe4\xba\x9b\xef\xbc\x8c\n# \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\xe4\xba\x86\xe3\x80\x82\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n\n## \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83 ##\nfor t in range(EPOCH):    \n    \n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    y_pred= model(x)\n    \n    # \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    loss = loss_fn(y_pred, y)\n    \n    # \xe6\x98\xbe\xe7\xa4\xba\xe6\x8d\x9f\xe5\xa4\xb1\n    if (t+1) % 50 == 0:\n        print(loss.data[0])\n    \n    # \xe5\x9c\xa8\xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe4\xb9\x8b\xe5\x89\x8d\xef\xbc\x8c\xe5\x85\x88\xe4\xbd\xbf\xe7\x94\xa8optimier\xe5\xaf\xb9\xe8\xb1\xa1\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe6\xb8\x85\xe9\x99\xa4\xe5\xb7\xb2\xe7\xbb\x8f\xe7\xa7\xaf\xe7\xb4\xaf\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe3\x80\x82\n    optimizer.zero_grad()\n    \n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\n    loss.backward()\n    \n    # \xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\n    optimizer.step()\n\n\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n\n# \xe8\x87\xaa\xe5\xb7\xb1\xe5\xae\x9a\xe5\x88\xb6\xe4\xb8\x80\xe4\xb8\xaa nn Modules\n# \xe5\xbe\x88\xe5\xa4\x9a\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\xa6\x81\xe5\xbb\xba\xe7\xab\x8b\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbc\x9a\xe6\xaf\x94PyTorch\xe7\x8e\xb0\xe6\x9c\x89\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9b\xb4\xe5\x8a\xa0\xe5\xa4\x8d\xe6\x9d\x82\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe4\xb8\xaa\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\n# \xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe8\x87\xaa\xe5\xb7\xb1\xe5\xae\x9a\xe5\x88\xb6\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84 nn.Module \xe8\xbf\x99\xe4\xb8\xaa\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xb9\x9f\xe9\x9c\x80\xe8\xa6\x81\xe5\xae\x9a\xe4\xb9\x89 forward \xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe6\x96\xb9\xe6\xb3\x95\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe6\x98\xafVariable\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe4\xb9\x9f\xe6\x98\xafVariable\xe3\x80\x82\n# \n# \xe5\xae\x9a\xe5\x88\xb6\xe4\xb8\x80\xe4\xb8\xaa\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84 nn Modules\xef\xbc\x8c\xe5\x85\xb6\xe5\xae\x9e\xe5\xb0\xb1\xe6\x98\xaf\xe5\x9c\xa8 init\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xef\xbc\x8c\xe5\xb0\x86\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x9c\x80\xe8\xa6\x81\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe5\xb1\x82\xe7\xbb\x99\xe5\xae\x9a\xe4\xb9\x89\xe5\xa5\xbd\xe4\xba\x86\xe3\x80\x82\n# \xe7\x84\xb6\xe5\x90\x8e\xe9\x87\x8d\xe5\x86\x99forward()\xef\xbc\x8c\xe5\x9c\xa8\xe9\x87\x8c\xe9\x9d\xa2\xe6\x8a\x8a\xe6\x95\xb0\xe6\x8d\xae\xe5\x9c\xa8\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe6\xb5\x81\xe5\x8a\xa8\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\xe7\xbb\x99\xe5\x86\x99\xe5\x87\xba\xe6\x9d\xa5\xef\xbc\x8c\xe5\xb0\xb1\xe5\xae\x8c\xe6\x88\x90\xe8\x87\xaa\xe5\xb7\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\xae\x9a\xe5\x88\xb6\xe4\xba\x86\xe3\x80\x82\n# \xe8\xbf\x98\xe6\x98\xaf\xe4\xbd\xbf\xe7\x94\xa8\xe4\xb8\x8a\xe9\x9d\xa2\xe7\x9a\x84\xe5\xa4\x9a\xe5\xb1\x82\xe6\x84\x9f\xe7\x9f\xa5\xe6\x9c\xba\xe7\x9a\x84\xe4\xbe\x8b\xe5\xad\x90\xe3\x80\x82\n\n\n###   \xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb1\x95\xe7\xa4\xba\xe4\xb8\xa4\xe7\xa7\x8d\xe5\xae\x9a\xe4\xb9\x89\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x86\x99\xe6\xb3\x95: \xe7\xac\xac\xe4\xb8\x80\xe7\xa7\x8d\xe5\xa6\x82\xe4\xb8\x8b   ###\n\nimport torch\nfrom torch.autograd import Variable\n\n# \xe4\xb8\x80\xe5\xae\x9a\xe8\xa6\x81\xe7\xbb\xa7\xe6\x89\xbf nn.Module\nclass TwoLayerNet(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        """"""\n        \xe5\x9c\xa8\xe6\x9e\x84\xe9\x80\xa0\xe5\x99\xa8\xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbc\x9a\xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96\xe4\xb8\xa4\xe4\xb8\xaa\xe7\xba\xbf\xe6\x80\xa7\xe5\xb1\x82\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x94\xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x8c\xe4\xb8\x8b\xe9\x9d\xa2\xe8\xbf\x99\xe5\x8f\xa5 super(TwoLayerNet, self).__init__()\n        \xe5\x8d\x83\xe4\xb8\x87\xe5\x88\xab\xe5\xbf\x98\xe8\xae\xb0\xe4\xba\x86\n        """"""\n        super(TwoLayerNet, self).__init__()\n        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n        self.relu1 = torch.nn.ReLU()\n        self.linear2 = torch.nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        """"""\n        \xe5\x9c\xa8forward\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbc\x9a\xe6\x8e\xa5\xe5\x8f\x97\xe4\xb8\x80\xe4\xb8\xaaVariable\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe6\x88\x91\xe4\xbb\xac\xe4\xb9\x9f\xe4\xbc\x9a\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x80\xe4\xb8\xaaVarible\n        """"""\n        Z1 = self.linear1(x)\n        A1 = self.relu1(Z1)\n        y_pred = self.linear2(A1)\n        return y_pred\n\n    \n# M\xe6\x98\xaf\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x8cinput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x85\xa5\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\n# hidden_size\xe6\x98\xaf\xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8coutput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\nM, input_size, hidden_size, output_size = 64, 1000, 100, 10\n\n# \xe7\x94\x9f\xe6\x88\x90\xe9\x9a\x8f\xe6\x9c\xba\xe6\x95\xb0\xe5\xbd\x93\xe4\xbd\x9c\xe6\xa0\xb7\xe6\x9c\xac\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe7\x94\xa8Variable \xe6\x9d\xa5\xe5\x8c\x85\xe8\xa3\x85\xe8\xbf\x99\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xae\xbe\xe7\xbd\xae requires_grad=False \xe8\xa1\xa8\xe7\xa4\xba\xe5\x9c\xa8\xe6\x96\xb9\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\n# \xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\xb1\x82\xe8\xbf\x99\xe5\x87\xa0\xe4\xb8\xaa Variable \xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\nx = Variable(torch.randn(M, input_size))\ny = Variable(torch.randn(M, output_size))\n\n\nmodel = TwoLayerNet(input_size, hidden_size, output_size)\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\nloss_fn = nn.MSELoss(size_average=False)\n\n## \xe8\xae\xbe\xe7\xbd\xae\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0 ##\nlearning_rate = 1e-4\nEPOCH = 300\n\n# \xe4\xbd\xbf\xe7\x94\xa8optim\xe5\x8c\x85\xe6\x9d\xa5\xe5\xae\x9a\xe4\xb9\x89\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\x87\xaa\xe5\x8a\xa8\xe7\x9a\x84\xe5\xb8\xae\xe6\x88\x91\xe4\xbb\xac\xe5\xaf\xb9\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe3\x80\x82\xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xe3\x80\x82\n# \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe4\xbc\xa0\xe5\x85\xa5\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe6\x98\xaf\xe5\x91\x8a\xe8\xaf\x89\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe7\x9a\x84Variable \xe6\x98\xaf\xe5\x93\xaa\xe4\xba\x9b\xef\xbc\x8c\n# \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\xe4\xba\x86\xe3\x80\x82\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n## \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83 ##\nfor t in range(EPOCH):    \n    \n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    y_pred= model(x)\n    \n    # \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    loss = loss_fn(y_pred, y)\n    \n    # \xe6\x98\xbe\xe7\xa4\xba\xe6\x8d\x9f\xe5\xa4\xb1\n    if (t+1) % 50 == 0:\n        print(loss.data[0])\n    \n    # \xe5\x9c\xa8\xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe4\xb9\x8b\xe5\x89\x8d\xef\xbc\x8c\xe5\x85\x88\xe4\xbd\xbf\xe7\x94\xa8optimier\xe5\xaf\xb9\xe8\xb1\xa1\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe6\xb8\x85\xe9\x99\xa4\xe5\xb7\xb2\xe7\xbb\x8f\xe7\xa7\xaf\xe7\xb4\xaf\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe3\x80\x82\n    optimizer.zero_grad()\n    \n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\n    loss.backward()\n    \n    # \xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\n    optimizer.step()\n\n\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n\n###   \xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb1\x95\xe7\xa4\xba\xe4\xb8\xa4\xe7\xa7\x8d\xe5\xae\x9a\xe4\xb9\x89\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x86\x99\xe6\xb3\x95: \xe7\xac\xac\xe4\xba\x8c\xe7\xa7\x8d\xe5\xa6\x82\xe4\xb8\x8b \xef\xbc\x88\xe6\x8e\xa8\xe8\x8d\x90\xef\xbc\x89 ###\n\nimport torch\nfrom torch.autograd import Variable\n\n# \xe4\xb8\x80\xe5\xae\x9a\xe8\xa6\x81\xe7\xbb\xa7\xe6\x89\xbf nn.Module\nclass TwoLayerNet(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        """"""\n            \xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe6\x9e\x84\xe5\xbb\xba\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe8\x83\xbd\xe5\xa4\x9f\xe4\xbd\xbf\xe7\x94\xa8nn.Sequential\xe7\x9a\x84\xe5\x9c\xb0\xe6\x96\xb9\xef\xbc\x8c\xe5\xb0\xbd\xe9\x87\x8f\xe4\xbd\xbf\xe7\x94\xa8\xe5\xae\x83\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe8\xbf\x99\xe6\xa0\xb7\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xa9\xe7\xbb\x93\xe6\x9e\x84\xe6\x9b\xb4\xe5\x8a\xa0\xe6\xb8\x85\xe6\x99\xb0\n        """"""\n        super(TwoLayerNet, self).__init__()\n        self.twolayernet = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, output_size),\n        )\n\n    def forward(self, x):\n        """"""\n        \xe5\x9c\xa8forward\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbc\x9a\xe6\x8e\xa5\xe5\x8f\x97\xe4\xb8\x80\xe4\xb8\xaaVariable\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe6\x88\x91\xe4\xbb\xac\xe4\xb9\x9f\xe4\xbc\x9a\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x80\xe4\xb8\xaaVarible\n        """"""\n        y_pred = self.twolayernet(x)\n        return y_pred\n\n    \n# M\xe6\x98\xaf\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x8cinput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x85\xa5\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\n# hidden_size\xe6\x98\xaf\xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8coutput_size\xe6\x98\xaf\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe5\xa4\xa7\xe5\xb0\x8f\nM, input_size, hidden_size, output_size = 64, 1000, 100, 10\n\n# \xe7\x94\x9f\xe6\x88\x90\xe9\x9a\x8f\xe6\x9c\xba\xe6\x95\xb0\xe5\xbd\x93\xe4\xbd\x9c\xe6\xa0\xb7\xe6\x9c\xac\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe7\x94\xa8Variable \xe6\x9d\xa5\xe5\x8c\x85\xe8\xa3\x85\xe8\xbf\x99\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xae\xbe\xe7\xbd\xae requires_grad=False \xe8\xa1\xa8\xe7\xa4\xba\xe5\x9c\xa8\xe6\x96\xb9\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\n# \xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\xb1\x82\xe8\xbf\x99\xe5\x87\xa0\xe4\xb8\xaa Variable \xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\nx = Variable(torch.randn(M, input_size))\ny = Variable(torch.randn(M, output_size))\n\n\nmodel = TwoLayerNet(input_size, hidden_size, output_size)\n\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\nloss_fn = nn.MSELoss(size_average=False)\n\n## \xe8\xae\xbe\xe7\xbd\xae\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0 ##\nlearning_rate = 1e-4\nEPOCH = 300\n\n# \xe4\xbd\xbf\xe7\x94\xa8optim\xe5\x8c\x85\xe6\x9d\xa5\xe5\xae\x9a\xe4\xb9\x89\xe4\xbc\x98\xe5\x8c\x96\xe7\xae\x97\xe6\xb3\x95\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe8\x87\xaa\xe5\x8a\xa8\xe7\x9a\x84\xe5\xb8\xae\xe6\x88\x91\xe4\xbb\xac\xe5\xaf\xb9\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe3\x80\x82\xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xe3\x80\x82\n# \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe4\xbc\xa0\xe5\x85\xa5\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe6\x98\xaf\xe5\x91\x8a\xe8\xaf\x89\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe7\x9a\x84Variable \xe6\x98\xaf\xe5\x93\xaa\xe4\xba\x9b\xef\xbc\x8c\n# \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\xe4\xba\x86\xe3\x80\x82\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n## \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83 ##\nfor t in range(EPOCH):    \n    \n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    y_pred= model(x)\n    \n    # \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    loss = loss_fn(y_pred, y)\n    \n    # \xe6\x98\xbe\xe7\xa4\xba\xe6\x8d\x9f\xe5\xa4\xb1\n    if (t+1) % 50 == 0:\n        print(loss.data[0])\n    \n    # \xe5\x9c\xa8\xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xe4\xb9\x8b\xe5\x89\x8d\xef\xbc\x8c\xe5\x85\x88\xe4\xbd\xbf\xe7\x94\xa8optimier\xe5\xaf\xb9\xe8\xb1\xa1\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe6\xb8\x85\xe9\x99\xa4\xe5\xb7\xb2\xe7\xbb\x8f\xe7\xa7\xaf\xe7\xb4\xaf\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe3\x80\x82\n    optimizer.zero_grad()\n    \n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\n    loss.backward()\n    \n    # \xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\n    optimizer.step()'"
basis/py/pretrain.py,12,"b'import torch\nimport torch.nn as nn\n\n# \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\nclass LeNet5(nn.Module):\n    def __init__(self, in_dim, n_class):\n        super(LeNet5, self).__init__()\n        self.conv1 = nn.Conv2d(in_dim, 6, 5, padding=2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, n_class)\n        \n        # \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe8\xbf\x98\xe6\x9c\x89\xe5\xbe\x88\xe5\xa4\x9a\xe5\xbe\x88\xe5\xa4\x9a\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xb8\x8a\xe5\xae\x98\xe7\xbd\x91\xe6\x9f\xa5api.\n        # torch.nn.init.constant(tensor, val)\n        # torch.nn.init.normal(tensor, mean=0, std=1)\n        # torch.nn.init.xavier_uniform(tensor, gain=1)\n        \n        for p in self.modules():\n            if isinstance(p, nn.Conv2d):\n                nn.init.xavier_normal(p.weight.data)\n            elif isinstance(p, nn.Linear):\n                nn.init.normal(p.weight.data)\n\n\n\n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:]\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84AlexNet\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9d\xa5\xe5\xaf\xb9CIFAR10\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\n# \xe7\x8e\xb0\xe5\x9c\xa8\xef\xbc\x8c\xe5\x81\x87\xe8\xae\xbe\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\x9f\xa5\xe9\x81\x93AlexNet\xe6\x98\xaf\xe4\xb8\xaa\xe5\xa5\xbd\xe7\x94\xa8\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x83\xb3\xe7\x94\xa8\xe5\xae\x83\xe6\x9d\xa5\xe5\xaf\xb9CIFAR10\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x8d\xe6\x83\xb3\xe8\x87\xaa\xe5\xb7\xb1\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe6\x83\xb3\xe7\x94\xa8\xe5\x88\xab\xe4\xba\xba\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe8\xaf\xa5\xe6\x80\x8e\xe4\xb9\x88\xe5\x81\x9a\xe5\x91\xa2\xef\xbc\x9f\n# \xe5\x88\x86\xe4\xb8\x89\xe6\xad\xa5\xef\xbc\x9a\n# 1\xe3\x80\x81\xe5\x8a\xa0\xe8\xbd\xbd\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\n# 2\xe3\x80\x81\xe5\xaf\xb9\xe6\xa8\xa1\xe5\x9e\x8b\xe7\xbb\x93\xe6\x9e\x84\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x9b\xb4\xe6\x94\xb9\n# 3\xe3\x80\x81\xe9\x87\x8d\xe6\x96\xb0\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe9\x82\xa3\xe5\x87\xa0\xe5\xb1\x82\n\nfrom torchvision import models, transforms, datasets\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch\nfrom torch.autograd import Variable\nimport torch.optim as optim\n\n# -----------------get Alexnet model-------------------------\ndef getAlexNet(DOWNLOAD=True):\n    alexnet = models.alexnet(pretrained=DOWNLOAD)\n    return alexnet\n\n\n# \xe6\x8a\x8a tensor \xe5\x8f\x98\xe6\x88\x90 Variable\ndef to_var(x):\n    x = Variable(x)\n    if torch.cuda.is_available():\n        x = x.cuda()\n    return x\n\n# \xe6\x98\xaf\xe5\x90\xa6\xe4\xb8\x8b\xe8\xbd\xbd\nDOWNLOAD = True\n\n# \xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\nCLASS_NUM = 10\n\n# \xe4\xb8\x8b\xe8\xbd\xbd\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84AlexNet\xe6\xa8\xa1\xe5\x9e\x8b\nalexnet = getAlexNet(DOWNLOAD)\n\n\n\n# -----------------\xe4\xbf\xae\xe6\x94\xb9\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84 Alexnet \xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe5\xb1\x82-------------------------\nalexnet.classifier = nn.Sequential(\n    nn.Dropout(p=0.5),\n    nn.Linear(in_features=9216, out_features=4096, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Dropout(p=0.5),\n    nn.Linear(in_features=4096, out_features=4096, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Linear(in_features=4096, out_features=CLASS_NUM, bias=True)\n)\n\n\n# \xe4\xbd\xbf\xe7\x94\xa8GPU\nif torch.cuda.is_available():\n    alexnet = alexnet.cuda()\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\ntransform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# \xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\ntrain_data = datasets.CIFAR10(\'./data\', train=True, transform=transform, download=True)\ntest_data = datasets.CIFAR10(\'./data\', train=False, transform=transform, download=False)\n\ntrain_data_loader = DataLoader(train_data, batch_size=256, shuffle=True)\ntest_data_loader = DataLoader(test_data, batch_size=256, shuffle=True)\n\n# optim\nlearning_rate = 0.0001\nnum_epoches = 5\ncriterion = nn.CrossEntropyLoss()\n\n# \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaa\xe6\x9b\xb4\xe6\x96\xb0 classifier \xe5\xb1\x82\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\noptimizer = optim.Adam(alexnet.classifier.parameters(), lr=learning_rate)\n\n# training\nalexnet.train()\nfor epoch in range(num_epoches):\n    print(\'epoch {}\'.format(epoch + 1))\n    runnin_acc = 0.0\n    running_loss = 0.0\n    for data, label in train_data_loader:\n        img = to_var(data)\n        label = to_var(label)\n        out = alexnet(img)\n        loss = criterion(out, label)\n        running_loss += loss.data[0] * label.size(0)\n        _, pred = torch.max(out, 1)\n        num_correct = (pred == label).sum()\n        accuracy = (pred == label).float().mean()\n        runnin_acc += num_correct.data[0]\n        # \xe5\x90\x91\xe5\x90\x8e\xe4\xbc\xa0\xe6\x92\xad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(""Acc: {:.6f}"".format(runnin_acc / len(train_data)))\n\n# evaluation\nalexnet.eval()\nrunnin_acc = 0.0\nfor data, label in test_data_loader:\n    img = to_var(data)\n    label = to_var(label)\n    out = alexnet(img)\n    loss = criterion(out, label)\n    _, pred = torch.max(out, 1)\n    num_correct = (pred == label).sum()\n    accuracy = (pred == label).float().mean()\n    runnin_acc += num_correct.data[0]\nprint(""Acc: {:.6f}"".format(runnin_acc / len(test_data)))\n\n\nprint(""Done!"")\n\n\n\n\n\n\n\n'"
basis/py/rnn.py,9,"b'import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.autograd import Variable\nimport numpy as np\n\n\n# \xe6\x9e\x84\xe5\xbb\xba config \xe7\xb1\xbb\xe6\x9d\xa5 \xe6\x8e\xa7\xe5\x88\xb6\xe6\x89\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\nclass Config(object):\n    def __init__(self):\n        self.path = \'../dataSet/dinos.txt\'\n        self.data_size = None\n        self.vocab_size = None\n        self.char_to_ix = None\n        self.ix_to_char = None\n        self.output_size = None\n        self.epoch = 100\n        self.lr = 0.01\n        self.hidden_size = 50\n        self.batch_size = 1\n        self.maxValue = 10 # \xe9\x98\xb2\xe6\xad\xa2\xe6\xa2\xaf\xe5\xba\xa6\xe7\x88\x86\xe7\x82\xb8\xe6\x89\x80\xe4\xbd\xbf\xe7\x94\xa8\n    \nconfig = Config()\n\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\ndata = open(config.path, \'r\').read()\n# \xe5\xad\x97\xe7\xac\xa6\xe5\x85\xa8\xe9\x83\xa8\xe5\xb0\x8f\xe5\x86\x99\ndata = data.lower()\n# \xe6\x9f\xa5\xe7\x9c\x8b\xe6\x9c\x89\xe5\xa4\x9a\xe5\xb0\x91\xe7\xa7\x8d\xe5\xad\x97\xe7\xac\xa6\nchars = list(set(data))\n\n# 27\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe8\xbe\x93\xe5\x87\xba\xe4\xb9\x9f\xe6\x98\xaf 27\nconfig.data_size, config.vocab_size, config.output_size = len(data), len(chars), len(chars)\n\nprint(\'\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\xad\xe4\xb8\x80\xe5\x85\xb1\xe6\x9c\x89 %d \xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\xef\xbc\x8c\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\x80\xe5\x85\xb1\xe6\x9c\x89 %d \xe4\xb8\xaa\xe3\x80\x82\' % (config.data_size, config.vocab_size))\n\nconfig.char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) } # \xe5\xad\x97\xe7\xac\xa6\xe5\x88\xb0\xe7\xb4\xa2\xe5\xbc\x95\xe7\x9a\x84\xe6\x98\xa0\xe5\xb0\x84\nconfig.ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) } # \xe7\xb4\xa2\xe5\xbc\x95\xe5\x88\xb0\xe5\xad\x97\xe7\xac\xa6\xe7\x9a\x84\xe6\x98\xa0\xe5\xb0\x84\nprint(config.ix_to_char)\n\n\n# one hot encoding\ndef one_hot(ids, vocab_size):\n    """"""\n        ids: list\n    """"""\n    ids = torch.LongTensor(ids).view(-1, 1)\n    out = torch.zeros(ids.size()[0], vocab_size).scatter_(1, ids, 1)\n    return out\n\n\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\ndef train_dataset(path, char_to_ix, vocab_size):\n    with open(path, \'r\') as f:\n        examples = f.readlines()\n    examples = [x.lower().strip() for x in examples]\n    for index in range(len(examples)):\n        X = [char_to_ix[ch] for ch in examples[index]] \n        Y = X[1:] + [char_to_ix[""\\n""]]\n        i_d = one_hot(X, vocab_size)\n        input_data = Variable(i_d.view(1, i_d.size()[0], i_d.size()[1])) # batch*seq_len*input_size\n        target_data = Variable(torch.LongTensor(Y))\n        yield input_data, target_data\n\n\n# \xe6\x9e\x84\xe9\x80\xa0\xe6\xa8\xa1\xe5\x9e\x8b\nclass DinosaurModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, batch_size, num_layers=1):\n        super(DinosaurModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.input_size = input_size\n        self.batch_size = batch_size\n        self.num_layers = num_layers\n\n        # \xe5\xb0\xb1\xe6\x98\xaf\xe4\xb8\x80\xe8\xa1\x8c\xe5\xb0\xb1\xe6\x9e\x84\xe5\xbb\xba\xe4\xba\x86 RNN \xe6\xa8\xa1\xe5\x9e\x8b\n        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n        # \xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xef\xbc\x8c\xe7\x94\xa8\xe4\xba\x8e\xe9\xa2\x84\xe6\xb5\x8b\xe5\xad\x97\xe7\xac\xa6\n        self.fc  = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x, h0):\n        # Propagate input through RNN\n        # Input: (batch, seq_len, input_size)\n        # hidden: (batch, num_layers * num_directions, hidden_size)\n        # out: (batch, seq_len, hidden_size)\n        out, hidden = self.rnn(x, h0)\n\n        # \xe6\x8a\x8a rnn \xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xa0\x86\xe6\x88\x90 (batch*seq_len, hidden_size) \xe5\xa4\xa7\xe5\xb0\x8f\n        out = out.view(out.size()[0]*out.size()[1], self.hidden_size)\n        y = self.fc(out)\n        return y\n    \n    def init_hidden(self):\n        # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\n        return Variable(torch.zeros(self.batch_size, self.num_layers, self.hidden_size))\n\n# \xe6\x9e\x84\xe5\xbb\xba\xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\xe5\x92\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe5\x89\xaa\xe8\xa3\x81\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xc2\xb6\ndef clip_and_update(parameters, lr, maxValue):\n    for p in parameters:\n        gradients = torch.clamp(p.grad.data, min=-maxValue, max=maxValue)\n        p.data.add_(-lr, gradients)\n    return\n\n\ndef sample(model, char_to_ix, ix_to_char, vocab_size):\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x80\xbc\n    random_int = random.randint(0, vocab_size-1)\n    i_d = one_hot([random_int], vocab_size)\n    a_input = Variable(i_d).view(1, 1, vocab_size)\n    indices = []\n    idx = -1\n    counter = 0\n    eos = char_to_ix[\'\\n\']\n    \n    while (idx != eos and counter != 30):\n        h0 = model.init_hidden()\n        out = model(a_input, h0)\n        # \xe9\x80\x9a\xe8\xbf\x87 softmax \xe6\xb1\x82\xe5\x87\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\n        p = F.softmax(out)\n        # \xe5\x8f\x96\xe5\x87\xba\xe6\xa6\x82\xe7\x8e\x87\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe5\xad\x97\xe7\xac\xa6\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\n        val, ids = torch.max(p, 1)\n        # \xe5\x8a\xa0\xe5\x85\xa5\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe6\x95\xb0\xe7\xbb\x84\xe9\x87\x8c\xe9\x9d\xa2\n        idx = ids.data[0]\n        indices.append(idx)\n        a_input = Variable(one_hot([idx], vocab_size).view(1, 1, vocab_size))\n        counter += 1\n    if (counter == 30):\n        indices.append(char_to_ix[\'\\n\'])\n    strl = [ix_to_char[i] for i in indices]\n    return """".join(strl)\n\n\ndinos = DinosaurModel(config.vocab_size, config.hidden_size, config.output_size, config.batch_size)\n\n# \xe6\x9c\x89\xe7\x9a\x84\xe6\x9c\x8b\xe5\x8f\x8b\xe5\x8f\xaf\xe8\x83\xbd\xe5\xbe\x88\xe5\xa5\xbd\xe5\xa5\x87\xef\xbc\x8c\xe6\x98\x8e\xe6\x98\x8e\xe5\xb0\xb1\xe6\x98\xafsoftmax + Negtive log-likelihood function \xe4\xb8\xba\xe5\x95\xa5\xe8\xa6\x81\xe7\x94\xa8 CrossEntropyLoss \xe5\x91\xa2\xef\xbc\x9f\n# \xe5\x9b\xa0\xe4\xb8\xba PyTorch \xe5\xb0\xb1\xe6\x98\xaf\xe8\xbf\x99\xe6\xa0\xb7\xe8\xae\xbe\xe8\xae\xa1\xe7\x9a\x84\xe5\x95\x8a~\nloss_fn = nn.CrossEntropyLoss()\n\nfor i in range(config.epoch):    \n    # \xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\n    total_loss = []\n    for input_data, target_data in train_dataset(config.path, config.char_to_ix, config.vocab_size):\n        dinos.zero_grad()\n        # \xe9\x9a\x90\xe5\x90\xab\xe5\xb1\x82\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\n        h0 = dinos.init_hidden()\n        # \xe6\x95\xb0\xe6\x8d\xae\xe6\x89\x94\xe8\xbf\x9b\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x87\x8c\xe9\x9d\xa2\n        y_pred = dinos(input_data, h0)\n        # \xe6\xb1\x82 loss\n        loss = loss_fn(y_pred, target_data)\n        total_loss.append(loss.data[0])\n        # \xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\n        loss.backward()\n        # \xe6\xa2\xaf\xe5\xba\xa6\xe5\x89\xaa\xe8\xa3\x81\xe5\x90\x8c\xe6\x97\xb6\xe6\x9b\xb4\xe6\x96\xb0\xe6\xa8\xa1\xe5\x9e\x8b\n        clip_and_update(dinos.parameters(), config.lr, config.maxValue)\n\n    if (i+1) % 20 == 0:\n        print(""loss is %.6f"" %(np.mean(total_loss)))\n        # \xe9\x87\x87\xe6\xa0\xb7\n        strl = sample(dinos, config.char_to_ix, config.ix_to_char, config.vocab_size)\n        print(strl)'"
basis/py/save_load.py,5,"b'import torch\nimport torch.nn as nn\n\nclass LeNet5(nn.Module):\n    def __init__(self, in_dim, n_class):\n        super(LeNet5, self).__init__()\n        self.conv1 = nn.Conv2d(in_dim, 6, 5, padding=2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, n_class)\n        \n        # \xe5\x8f\x82\xe6\x95\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\n        for p in self.modules():\n            if isinstance(p, nn.Conv2d):\n                nn.init.xavier_normal(p.weight.data)\n            elif isinstance(p, nn.Linear):\n                nn.init.normal(p.weight.data)\n\n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:]\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n# \xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96\xe6\xa8\xa1\xe5\x9e\x8b\nlenet = LeNet5(224, 10)\n\n# \xe8\xae\xa9\xe6\x88\x91\xe4\xbb\xac\xe5\x81\x87\xe8\xae\xbe\xef\xbc\x8c\xe7\xbb\x8f\xe8\xbf\x87\xe4\xba\x86\xe4\xb8\x80\xe8\xbf\x9e\xe4\xb8\xb2\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\n# \xe8\xbf\x99\xe6\x97\xb6\xe5\x80\x99\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xb7\xb2\xe7\xbb\x8f\xe8\xa2\xab\xe6\x88\x91\xe4\xbb\xac\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\n# \xe5\x8d\x81\xe5\x88\x86\xe5\xae\x8c\xe7\xbe\x8e\xe4\xba\x86\xe3\x80\x82\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe8\xb7\xaf\xe5\xbe\x84\nPATH = ""./test.pkl""\n\n# \xe7\xac\xac\xe4\xb8\x80\xe7\xa7\x8d\xef\xbc\x9a\xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\x92\x8c\xe7\xbb\x93\xe6\x9e\x84\n\n# \xe4\xbf\x9d\xe5\xad\x98\ntorch.save(lenet, PATH)\n\n# \xe5\x8a\xa0\xe8\xbd\xbd\nmodel = torch.load(PATH)\n\n\n# \xe7\xac\xac\xe4\xba\x8c\xe7\xa7\x8d\xef\xbc\x9a\xe4\xbb\x85\xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0(\xe5\xbc\xba\xe7\x83\x88\xe6\x8e\xa8\xe8\x8d\x90\xe4\xbd\xbf\xe7\x94\xa8\xe8\xbf\x99\xe7\xa7\x8d\xe6\x96\xb9\xe5\xbc\x8f)\n\ntorch.save(lenet.state_dict(), PATH)\n\nmodel2 = LeNet5(224, 10) # \xe5\xae\x9e\xe4\xbe\x8b\xe5\x8c\x96\xe6\xa8\xa1\xe5\x9e\x8b\nmodel2.load_state_dict(torch.load(PATH)) # \xe5\x8a\xa0\xe8\xbd\xbd\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8f\x82\xe6\x95\xb0'"
basis/py/simplecnn.py,7,"b'# \xe6\x9e\x84\xe5\xbb\xba\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a LeNet-5 \xe6\xa8\xa1\xe5\x9e\x8b\n# \xe6\x8e\xa5\xe4\xb8\x8b\xe6\x9d\xa5\xe6\x88\x91\xe4\xbb\xac\xe4\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8LeNet\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9d\xa5\xe5\xa4\x84\xe7\x90\x86MNIST\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x82\n# LeNet-5\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\xbb\x93\xe6\x9e\x84\xe5\xa6\x82\xe4\xb8\x8b\xe5\x9b\xbe\xe6\x89\x80\xe7\xa4\xba\xef\xbc\x9a\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\n\nclass LeNet5(nn.Module):\n    def __init__(self, in_dim, n_class):\n        super(LeNet5, self).__init__()\n        # \xe4\xbb\x8e\xe7\xbb\x93\xe6\x9e\x84\xe5\x9b\xbe\xe4\xb8\xad\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x87\xba\xef\xbc\x8c\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xef\xbc\x9a\xe5\x8d\xb7\xe7\xa7\xaf\xe5\xb1\x82\xe8\xbe\x93\xe5\x85\xa5\xe6\x98\xaf1 channel, \xe8\xbe\x93\xe5\x87\xba\xe6\x98\xaf 6 channel, kennel_size = (5,5)\n        self.conv1 = nn.Conv2d(in_dim, 6, 5, padding=2)\n        # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xef\xbc\x9a\xe4\xbe\x9d\xe6\x97\xa7\xe6\x98\xaf \xe5\x8d\xb7\xe7\xa7\xaf\xe5\xb1\x82\xef\xbc\x8c \xe8\xbe\x93\xe5\x85\xa5 6 channel \xe8\xbe\x93\xe5\x87\xba 6 channel , kennel_size = (5,5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # \xe7\xac\xac\xe4\xb8\x89\xe5\xb1\x82\xef\xbc\x9a\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82\xef\xbc\x88\xe7\xba\xbf\xe6\x80\xa7\xe8\xa1\xa8\xe7\xa4\xba\xef\xbc\x89\n        self.fc1 = nn.Linear(16*5*5, 120)\n        # \xe7\xac\xac\xe5\x9b\x9b\xe5\xb1\x82\xef\xbc\x9a\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82\n        self.fc2 = nn.Linear(120, 84)\n        # \xe7\xac\xac\xe4\xba\x94\xe5\xb1\x82\xef\xbc\x9a\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\n        self.fc3 = nn.Linear(84, n_class)\n    # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n    def forward(self, x):\n        # Subsampling 1 process\n        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n        \n        # Subsampling 2 process\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        \n        # -1\xe7\x9a\x84\xe8\xaf\x9d\xef\xbc\x8c\xe6\x84\x8f\xe5\x91\xb3\xe7\x9d\x80\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\x9b\xb8\xe4\xb9\x98\xe4\xb8\xba\xe7\xbb\xb4\xe6\x95\xb0\n        x = x.view(-1, self.num_flat_features(x))\n        # full connect 1\n        x = F.relu(self.fc1(x))\n        # full connect 2\n        x = F.relu(self.fc2(x))\n        # full connect 3\n        x = self.fc3(x)\n        return x\n    \n    # 6 channel \xe5\x8d\xb7\xe7\xa7\xaf\xe5\xb1\x82 \xe8\xbd\xac\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\n    def num_flat_features(self, x):\n        # \xe5\xbe\x97\xe5\x88\xb0 channel * iW * iH \xe7\x9a\x84\xe5\x80\xbc\n        size = x.size()[1:]\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\nleNet = LeNet5(1, 10)\nprint(leNet)\n\n# \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x98\xaf MNIST dataset\n# \xe6\x88\x91\xe4\xbb\xac\xe4\xbc\x9a\xe4\xbd\xbf\xe7\x94\xa8 torchvision \xe6\x9d\xa5\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision import datasets\n\n# mini-batch\nbatch_size = 128\n\n# \xe6\x9c\xaa\xe4\xb8\x8b\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8True\xe8\xa1\xa8\xe7\xa4\xba\xe4\xb8\x8b\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\nDOWNLOAD = False \n\ntrain_dataset = datasets.MNIST(\n    root=\'./data\', train=True, transform=transforms.ToTensor(), download=DOWNLOAD)\n\ntest_dataset = datasets.MNIST(\n    root=\'./data\', train=False, transform=transforms.ToTensor())\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\n# \xe7\x8e\xb0\xe5\x9c\xa8\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x9c\x89\xe4\xba\x86\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe4\xb9\x9f\xe6\x9c\x89\xe4\xba\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c\xe5\xb0\xb1\xe8\xae\xa9\xe6\x88\x91\xe4\xbb\xac\xe5\xbc\x80\xe5\xa7\x8b\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xb5\x8b\xe8\xaf\x95\n\nimport torch.optim as optim\n\n# hyper-parameters\nlearning_rate = 0.0001\nnum_epoches = 2\nuse_gpu = torch.cuda.is_available()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(leNet.parameters(), lr = learning_rate)\ntt = 0\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\nfor epoch in range(num_epoches):\n    print(\'epoch {}\'.format(epoch + 1))\n    print(\'*\' * 10)\n    running_loss = 0.0\n    running_acc = 0.0\n    for i, data in enumerate(train_loader, 1):\n        tt +=1\n        img, label = data\n        img = Variable(img)\n        label = Variable(label)\n        # \xe5\x90\x91\xe5\x89\x8d\xe4\xbc\xa0\xe6\x92\xad\n        out = leNet(img)\n        loss = criterion(out, label)\n        running_loss += loss.data[0] * label.size(0)\n        _, pred = torch.max(out, 1)\n        num_correct = (pred == label).sum()\n        accuracy = (pred == label).float().mean()\n        running_acc += num_correct.data[0]\n        # \xe5\x90\x91\xe5\x90\x8e\xe4\xbc\xa0\xe6\x92\xad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if i % 300 == 0:\n            print(\'[{}/{}] Loss: {:.6f}, Acc: {:.6f}\'.format(\n                epoch + 1, num_epoches, running_loss / (batch_size * i),\n                running_acc / (batch_size * i)))\nprint(""Done!"")'"
basis/py/tensor_basis.py,21,"b'import torch # \xe5\xaf\xbc\xe5\x85\xa5torch\xe5\x8c\x85\nimport numpy as np # \xe5\xaf\xbc\xe5\x85\xa5numpy\xe5\x8c\x85\n\n# \xe5\x88\x9b\xe5\xbb\xba\xe4\xb8\x80\xe4\xb8\xaa\xe9\x9a\x8f\xe6\x9c\xba\xe7\x9a\x84\xe4\xba\x8c\xe7\xbb\xb4\xe6\x95\xb0\xe7\xbb\x84\xef\xbc\x88\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x89\nexam1 = torch.randn(2, 3)\nprint(exam1)\n\n# \xe8\xb7\x9fnumpy\xe4\xb8\x80\xe6\xa0\xb7\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x9e\x84\xe9\x80\xa0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe4\xb8\xba0\xe3\x80\x811\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\nexam2 = torch.zeros(2, 3)\n\nexam3 = torch.ones(2, 3)\n\nprint(exam2)\n\nprint(exam3)\n\n\n# \xe5\xbd\x93\xe7\x84\xb6\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbb\x8epython\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\xe7\x9b\xb4\xe6\x8e\xa5\xe6\x9e\x84\xe9\x80\xa0\nexam4 = torch.Tensor([[1, 2, 4], [2, 3, 6] ])\nprint(exam4)\n\n\n# numpy \xe9\x80\x9a\xe5\xb8\xb8\xe6\x98\xaf\xe9\x80\x9a\xe8\xbf\x87 .shape \xe6\x9d\xa5\xe8\x8e\xb7\xe5\x8f\x96\xe6\x95\xb0\xe7\xbb\x84\xe7\x9a\x84\xe5\xbd\xa2\xe7\x8a\xb6\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe5\xaf\xb9\xe4\xba\x8etorch.Tensor\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf .size()\n# \xe5\xaf\xb9\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xbf\xe9\x97\xae\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x87\x87\xe5\x8f\x96\xe8\xae\xbf\xe9\x97\xae\xe5\x88\x97\xe8\xa1\xa8\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\n\nshape = exam4.size()\nprint(type(shape))\nprint(shape[0])\nprint(shape[1])\n\n# \xe6\x9c\x89\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe7\x8a\xb6\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x94\xb9\xe5\x8f\x98\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x87\x87\xe7\x94\xa8 .view() \xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\nexam5 = exam4.view(3, 2)\n\n# -1\xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84\xe6\x98\xaf\xe7\xb3\xbb\xe7\xbb\x9f\xe8\x87\xaa\xe5\x8a\xa8\xe8\xa1\xa5\xe9\xbd\x90\nexam6 = exam4.view(1, -1)\n\nprint(exam5)\nprint(exam6)\n\n# torch.Tensor \xe6\x94\xaf\xe6\x8c\x81\xe5\xa4\xa7\xe9\x87\x8f\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\xa6\xe6\x93\x8d\xe4\xbd\x9c\xe7\xac\xa6 + , - , * , / \xe9\x83\xbd\xe6\x98\xaf\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\xe7\x9a\x84\xe3\x80\x82\n# \xe5\xbd\x93\xe7\x84\xb6\xe4\xb9\x9f\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8Tensor\xe5\x86\x85\xe7\xbd\xae\xe7\x9a\x84 add() \xe7\xad\x89, \xe8\xbf\x99\xe9\x87\x8c\xe9\x9c\x80\xe8\xa6\x81\xe6\x8f\x90\xe4\xb8\x80\xe4\xb8\x8b\xe7\x9a\x84\xe5\xb0\xb1\xe6\x98\xaf add \xe5\x92\x8c add_ \xe7\x9a\x84\xe5\x8c\xba\xe5\x88\xab\n# \xe4\xbd\xbf\xe7\x94\xa8add\xe5\x87\xbd\xe6\x95\xb0\xe4\xbc\x9a\xe7\x94\x9f\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaa\xe6\x96\xb0\xe7\x9a\x84Tensor\xe5\x8f\x98\xe9\x87\x8f\xef\xbc\x8c add_ \xe5\x87\xbd\xe6\x95\xb0\xe4\xbc\x9a\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x86\x8d\xe5\xbd\x93\xe5\x89\x8dTensor\xe5\x8f\x98\xe9\x87\x8f\xe4\xb8\x8a\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x93\x8d\xe4\xbd\x9c\n# \xe6\x89\x80\xe4\xbb\xa5\xef\xbc\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe5\x87\xbd\xe6\x95\xb0\xe5\x90\x8d\xe6\x9c\xab\xe5\xb0\xbe\xe5\xb8\xa6\xe6\x9c\x89""_"" \xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xe9\x83\xbd\xe6\x98\xaf\xe4\xbc\x9a\xe5\xaf\xb9Tensor\xe5\x8f\x98\xe9\x87\x8f\xe6\x9c\xac\xe8\xba\xab\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x93\x8d\xe4\xbd\x9c\xe7\x9a\x84\n\nexam1.add(20)\nprint(exam1)\n\nexam1.add_(20)\nprint(exam1)\n\n\n# \xe5\xaf\xb9\xe4\xba\x8e\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe8\xbf\x90\xe7\xae\x97Tensor\xe4\xb9\x9f\xe6\x9c\x89\xe5\xbe\x88\xe5\xa5\xbd\xe7\x9a\x84\xe6\x94\xaf\xe6\x8c\x81\n\nexam7 = torch.Tensor([[1, 2, 3], [4, 5, 6]])\nexam8 = torch.randn(2, 3)\n\nprint(""exam7: "" , exam7)\nprint(""exam8: "" , exam8)\n\n\n# \xe7\x9f\xa9\xe9\x98\xb5\xe4\xb9\x98\xe6\xb3\x95, \xe5\x85\xb6\xe4\xb8\xad t() \xe8\xa1\xa8\xe7\xa4\xba\xe5\x8f\x96\xe8\xbd\xac\xe7\xbd\xae\ntorch.mm(exam7, exam8.t())\n\n\n# \xe7\x9f\xa9\xe9\x98\xb5\xe5\xaf\xb9\xe5\xba\x94\xe5\x85\x83\xe7\xb4\xa0\xe7\x9b\xb8\xe4\xb9\x98\nexam7 * exam8\n\n# \xe8\xb7\x9fnumpy\xe4\xb8\x80\xe6\xa0\xb7\xef\xbc\x8c\xe5\x86\x8dTensor\xe4\xb8\xad\xef\xbc\x8c\xe4\xb9\x9f\xe5\xad\x98\xe5\x9c\xa8Broadcasting\n# \xe5\xbd\x93\xe4\xba\x8c\xe5\x85\x83\xe6\x93\x8d\xe4\xbd\x9c\xe7\xac\xa6\xe5\xb7\xa6\xe5\x8f\xb3\xe4\xb8\xa4\xe8\xbe\xb9Tensor\xe5\xbd\xa2\xe7\x8a\xb6\xe4\xb8\x8d\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\n# \xe7\xb3\xbb\xe7\xbb\x9f\xe4\xbc\x9a\xe5\xb0\x9d\xe8\xaf\x95\xe5\xb0\x86\xe5\x85\xb6\xe5\xa4\x8d\xe5\x88\xb6\xe5\x88\xb0\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\xb1\xe5\x90\x8c\xe7\x9a\x84\xe5\xbd\xa2\xe7\x8a\xb6\xe3\x80\x82\xe4\xbe\x8b\xe5\xa6\x82a\xe7\x9a\x84\xe7\xac\xac0\xe7\xbb\xb4\xe6\x98\xaf3, b\xe7\x9a\x84\xe7\xac\xac0\xe7\xbb\xb4\xe6\x98\xaf1\xef\xbc\x8c\xe9\x82\xa3\xe4\xb9\x88 a + b\xe8\xbf\x99\xe4\xb8\xaa\xe6\x93\x8d\xe4\xbd\x9c\xe4\xbc\x9a\xe5\xb0\x86b\xe6\xb2\xbf\xe7\x9d\x80\xe7\xac\xac0\xe7\xbb\xb4\xe5\xa4\x8d\xe5\x88\xb63\xe9\x81\x8d\xe3\x80\x82\n\n\na = torch.arange(0, 3).view(3, 1)\nb = torch.arange(0, 2).view(1, 2)\nprint(""a:"", a)\nprint(""b:"", b)\nprint(""a+b:"", a + b)\n\n\n# Tensor\xe5\x92\x8cNumpy\xe7\x9a\x84\xe7\x9b\xb8\xe4\xba\x92\xe8\xbd\xac\xe6\x8d\xa2\n\n\nx = np.ones((2, 3))\ny = torch.from_numpy(x) # \xe4\xbb\x8enumpy -> torch.Tensor\nprint(y)\nz = y.numpy() # \xe4\xbb\x8etorch.Tensor -> numpy\nprint(z)\n\n# \xe5\xb8\xb8\xe7\x94\xa8\xe6\x93\x8d\xe4\xbd\x9c\n# unsqueeze() \xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xa9\xe6\x88\x91\xe4\xbb\xac\xe6\x8a\x8a\xe4\xb8\x80\xe4\xb8\xaa\xe5\x90\x91\xe9\x87\x8f\xe5\x8f\x98\xe6\x88\x90\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe9\x9d\x9e\xe5\xb8\xb8\xe6\x9c\x89\xe7\x94\xa8~\n\nx_u = torch.Tensor([1, 2, 3, 4])\nprint(x_u)\nx_u_1 = torch.unsqueeze(x_u, 0)\nprint(x_u_1)\nx_u_2 = torch.unsqueeze(x_u, 1)\nprint(x_u_2)\n\n# squeeze() \xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xa9\xe6\x88\x91\xe4\xbb\xac\xe6\x8a\x8a\xe4\xb8\x80\xe4\xb8\xaa\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8f\x98\xe6\x88\x90\xe5\x90\x91\xe9\x87\x8f\xe3\x80\x82\n\nx_sq = torch.Tensor([[1, 2, 3, 4]])\nprint(x_sq)\nx_sq_1 = torch.squeeze(x_u, 0)\nprint(x_sq_1)\n\n# stack() \xe5\x8f\xaf\xe4\xbb\xa5\xe8\xae\xa9\xe6\x88\x91\xe4\xbb\xac\xe6\x8a\x8a\xe5\xbe\x88\xe5\xa4\x9a\xe4\xb8\xaa\xe7\x9f\xa9\xe9\x98\xb5""\xe5\xa0\x86""\xe5\x9c\xa8\xe4\xb8\x80\xe8\xb5\xb7\xe5\xbd\xa2\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaa\xe6\x96\xb0\xe7\x9a\x84\xe9\xab\x98\xe7\xbb\xb4\xe7\x9f\xa9\xe9\x98\xb5\xe3\x80\x82\n# \xe6\xaf\x94\xe5\xa6\x82\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe6\x9c\x89 10 \xe4\xb8\xaa (5, 12)\xe7\x9a\x84 Tensor\xef\xbc\x8c \xe6\x88\x91\xe4\xbb\xac\xe5\xb8\x8c\xe6\x9c\x9b\xe6\x8a\x8a\xe4\xbb\x96\xe4\xbb\xac\xe5\xa0\x86\xe5\x9c\xa8\xe4\xb8\x80\xe8\xb5\xb7\xe5\xbd\xa2\xe6\x88\x90 (10, 5, 12)\xe7\x9a\x84Tensor\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\xb0\xb1\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8 stack\n\nx_sta = []\n\nnum = 10\n\nfor i in range(num):\n    temp = torch.randn((5, 12))\n    x_sta.append(temp)\n    if i == 5:\n        print(""\xe6\xaf\x8f\xe4\xb8\xaa tensor \xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\xe4\xb8\xba\xef\xbc\x9a"", temp.size())\n        \nprint(""\xe6\x95\xb4\xe4\xb8\xaa sequence \xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba"", len(x_sta))\n\nx_sta_1 = torch.stack(x_sta)\n\nprint(""stack \xe6\x95\xb4\xe4\xb8\xaa sequence \xe4\xb9\x8b\xe5\x90\x8e\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe4\xb8\xba\xef\xbc\x9a"", x_sta_1.size())\n\n# \xe6\x9c\x80\xe5\x90\x8e\xef\xbc\x8c\xe8\xbf\x99\xe9\x87\x8c\xe5\x8f\xaa\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe5\xbc\x95\xe5\xad\x90\xef\xbc\x8c\xe8\xbf\x98\xe6\x9c\x89\xe5\xbe\x88\xe5\xa4\x9a\xe5\xbe\x88\xe5\xa4\x9a\xe7\x9a\x84\xe6\x93\x8d\xe4\xbd\x9c\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8pyTorch\xe5\xae\x98\xe6\x96\xb9\xe6\x96\x87\xe6\xa1\xa3\xe4\xb8\x8a\xe6\x9f\xa5\xe9\x98\x85 torch.Tensor API\n'"
