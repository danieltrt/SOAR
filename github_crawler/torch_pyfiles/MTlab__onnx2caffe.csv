file_path,api_count,code
MyCaffe.py,0,"b'from collections import OrderedDict, Counter\n\nfrom caffe.proto import caffe_pb2\nfrom google import protobuf\nimport six\n\ndef param_name_dict():\n    """"""Find out the correspondence between layer names and parameter names.""""""\n\n    layer = caffe_pb2.LayerParameter()\n    # get all parameter names (typically underscore case) and corresponding\n    # type names (typically camel case), which contain the layer names\n    # (note that not all parameters correspond to layers, but we\'ll ignore that)\n    param_names = [f.name for f in layer.DESCRIPTOR.fields if f.name.endswith(\'_param\')]\n    param_type_names = [type(getattr(layer, s)).__name__ for s in param_names]\n    # strip the final \'_param\' or \'Parameter\'\n    param_names = [s[:-len(\'_param\')] for s in param_names]\n    param_type_names = [s[:-len(\'Parameter\')] for s in param_type_names]\n    return dict(zip(param_type_names, param_names))\n\ndef assign_proto(proto, name, val):\n    """"""Assign a Python object to a protobuf message, based on the Python\n    type (in recursive fashion). Lists become repeated fields/messages, dicts\n    become messages, and other types are assigned directly. For convenience,\n    repeated fields whose values are not lists are converted to single-element\n    lists; e.g., `my_repeated_int_field=3` is converted to\n    `my_repeated_int_field=[3]`.""""""\n\n    is_repeated_field = hasattr(getattr(proto, name), \'extend\')\n    if is_repeated_field and not isinstance(val, list):\n        val = [val]\n    if isinstance(val, list):\n        if isinstance(val[0], dict):\n            for item in val:\n                proto_item = getattr(proto, name).add()\n                for k, v in six.iteritems(item):\n                    assign_proto(proto_item, k, v)\n        else:\n            getattr(proto, name).extend(val)\n    elif isinstance(val, dict):\n        for k, v in six.iteritems(val):\n            assign_proto(getattr(proto, name), k, v)\n    else:\n        setattr(proto, name, val)\n\nclass Function(object):\n    """"""A Function specifies a layer, its parameters, and its inputs (which\n    are Tops from other layers).""""""\n\n    def __init__(self, type_name, layer_name, inputs,outputs, **params):\n        self.type_name = type_name\n        self.inputs = inputs\n        self.outputs = outputs\n        self.params = params\n        self.layer_name = layer_name\n        self.ntop = self.params.get(\'ntop\', 1)\n        # use del to make sure kwargs are not double-processed as layer params\n        if \'ntop\' in self.params:\n            del self.params[\'ntop\']\n        self.in_place = self.params.get(\'in_place\', False)\n        if \'in_place\' in self.params:\n            del self.params[\'in_place\']\n        # self.tops = tuple(Top(self, n) for n in range(self.ntop))l\n\n    def _get_name(self, names, autonames):\n        if self not in names and self.ntop > 0:\n            names[self] = self._get_top_name(self.tops[0], names, autonames)\n        elif self not in names:\n            autonames[self.type_name] += 1\n            names[self] = self.type_name + str(autonames[self.type_name])\n        return names[self]\n\n    def _get_top_name(self, top, names, autonames):\n        if top not in names:\n            autonames[top.fn.type_name] += 1\n            names[top] = top.fn.type_name + str(autonames[top.fn.type_name])\n        return names[top]\n\n    def _to_proto(self):\n        bottom_names = []\n        for inp in self.inputs:\n            # inp._to_proto(layers, names, autonames)\n            bottom_names.append(inp)\n        layer = caffe_pb2.LayerParameter()\n        layer.type = self.type_name\n        layer.bottom.extend(bottom_names)\n\n        if self.in_place:\n            layer.top.extend(layer.bottom)\n        else:\n            for top in self.outputs:\n                layer.top.append(top)\n        layer.name = self.layer_name\n        # print(self.type_name + ""..."")\n        for k, v in six.iteritems(self.params):\n            # special case to handle generic *params\n            # print(""generating ""+k+""..."")\n\n            if k.endswith(\'param\'):\n                assign_proto(layer, k, v)\n            else:\n                try:\n                    assign_proto(getattr(layer,\n                        _param_names[self.type_name] + \'_param\'), k, v)\n                except (AttributeError, KeyError):\n                    assign_proto(layer, k, v)\n\n        return layer\n\nclass Layers(object):\n    """"""A Layers object is a pseudo-module which generates functions that specify\n    layers; e.g., Layers().Convolution(bottom, kernel_size=3) will produce a Top\n    specifying a 3x3 convolution applied to bottom.""""""\n\n    def __getattr__(self, name):\n        def layer_fn(*args, **kwargs):\n            fn = Function(name, args, kwargs)\n            return fn\n        return layer_fn\n\n\n\n\n_param_names = param_name_dict()\n\n'"
convertCaffe.py,0,"b'from __future__ import print_function\nimport sys\nimport caffe\nimport onnx\nimport numpy as np\nfrom caffe.proto import caffe_pb2\ncaffe.set_mode_cpu()\nfrom onnx2caffe._transformers import ConvAddFuser,ConstantsToInitializers\nfrom onnx2caffe._graph import Graph\n\nimport onnx2caffe._operators as cvt\nimport onnx2caffe._weightloader as wlr\nfrom onnx2caffe._error_utils import ErrorHandling\nfrom collections import OrderedDict\nfrom onnx import shape_inference\nimport importlib\n\ntransformers = [\n    ConstantsToInitializers(),\n    ConvAddFuser(),\n]\n\ndef convertToCaffe(graph, prototxt_save_path, caffe_model_save_path):\n\n    exist_edges = []\n    layers = []\n    exist_nodes = []\n    err = ErrorHandling()\n    for i in graph.inputs:\n        edge_name = i[0]\n        input_layer = cvt.make_input(i)\n        layers.append(input_layer)\n        exist_edges.append(i[0])\n        graph.channel_dims[edge_name] = graph.shape_dict[edge_name][1]\n\n\n    for id, node in enumerate(graph.nodes):\n        node_name = node.name\n        op_type = node.op_type\n        inputs = node.inputs\n        inputs_tensor = node.input_tensors\n        input_non_exist_flag = False\n\n        for inp in inputs:\n            if inp not in exist_edges and inp not in inputs_tensor:\n                input_non_exist_flag = True\n                break\n        if input_non_exist_flag:\n            continue\n\n        if op_type not in cvt._ONNX_NODE_REGISTRY:\n            err.unsupported_op(node)\n            continue\n        converter_fn = cvt._ONNX_NODE_REGISTRY[op_type]\n        layer = converter_fn(node,graph,err)\n        if type(layer)==tuple:\n            for l in layer:\n                layers.append(l)\n        else:\n            layers.append(layer)\n        outs = node.outputs\n        for out in outs:\n            exist_edges.append(out)\n\n    net = caffe_pb2.NetParameter()\n    for id,layer in enumerate(layers):\n        layers[id] = layer._to_proto()\n    net.layer.extend(layers)\n\n    with open(prototxt_save_path, \'w\') as f:\n        print(net,file=f)\n\n    caffe.set_mode_cpu()\n    deploy = prototxt_save_path\n    net = caffe.Net(deploy,\n                    caffe.TEST)\n\n    for id, node in enumerate(graph.nodes):\n        node_name = node.name\n        op_type = node.op_type\n        inputs = node.inputs\n        inputs_tensor = node.input_tensors\n        input_non_exist_flag = False\n        if op_type not in wlr._ONNX_NODE_REGISTRY:\n            err.unsupported_op(node)\n            continue\n        converter_fn = wlr._ONNX_NODE_REGISTRY[op_type]\n        converter_fn(net, node, graph, err)\n\n    net.save(caffe_model_save_path)\n    return net\n\ndef getGraph(onnx_path):\n    model = onnx.load(onnx_path)\n    model = shape_inference.infer_shapes(model)\n    model_graph = model.graph\n    graph = Graph.from_onnx(model_graph)\n    graph = graph.transformed(transformers)\n    graph.channel_dims = {}\n\n    return graph\n\nif __name__ == ""__main__"":\n    onnx_path = sys.argv[1]\n    prototxt_path = sys.argv[2]\n    caffemodel_path = sys.argv[3]\n    graph = getGraph(onnx_path)\n    convertToCaffe(graph, prototxt_path, caffemodel_path)\n\n'"
test.py,0,"b'from __future__ import print_function\nimport onnx\nimport numpy as np\nimport caffe\ncaffe.set_mode_cpu()\nimport importlib\nfrom convertCaffe import convertToCaffe, getGraph\nimport os\n\ndef getPytorchModel(name):\n    py_model_path = \'model\'\n    module = importlib.import_module(""model_generator.""+name)\n    var, model = module.get_model_and_input(py_model_path)\n    return var, model\n\nmodule_name_list = [\n                    ""broadcast_mul"",\n                    ""broadcast_add"",\n                    ""googlenet"",\n                    ""resnet"",\n                    ""MobileNetV2"",\n                    ]\n\nmodel_save_dir = \'model\'\nif not os.path.isdir(model_save_dir):\n    os.makedirs(model_save_dir)\n\nfor module_name in module_name_list:\n    print(""export {} onnx model ..."".format(module_name))\n    module = importlib.import_module(""model_generator""+"".""+module_name)\n    module.export(model_save_dir)\n\n    var, pt_model = getPytorchModel(module_name)\n    var_numpy = var.data.numpy()\n    pt_model.eval()\n    pt_out = pt_model(var)\n    pt_out = pt_out.data.numpy()\n    onnx_path = os.path.join(""model"", module_name+\'.onnx\')\n    prototxt_path = os.path.join(""model"", module_name+\'.prototxt\')\n    caffemodel_path = os.path.join(""model"", module_name+\'.caffemodel\')\n\n    graph = getGraph(onnx_path)\n    print(""converting {} to caffe ..."".format(module_name))\n    caffe_model = convertToCaffe(graph, prototxt_path, caffemodel_path)\n\n    input_name = str(graph.inputs[0][0])\n    output_name = str(graph.outputs[0][0])\n\n    caffe_model.blobs[input_name].data[...] = var_numpy\n    net_output = caffe_model.forward()\n    caffe_out = net_output[output_name]\n\n    minus_result = caffe_out-pt_out\n    mse = np.sum(minus_result*minus_result)\n\n    print(""{} mse between caffe and pytorch model output: {}"".format(module_name,mse))\n\n\n\n    \n\n    \n\n'"
model_generator/MobileNetV2.py,7,"b'import torch.nn as nn\nimport math\nfrom torch.autograd import Variable\nimport torch\nimport torch.onnx as onnx\nimport os\n\ndef conv_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=True),\n        nn.BatchNorm2d(oup),\n        nn.ReLU(inplace=True)\n    )\n\n\ndef conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU(inplace=True)\n    )\n\n\nclass InvertedResidual(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio):\n        super(InvertedResidual, self).__init__()\n        self.stride = stride\n        assert stride in [1, 2]\n\n        self.use_res_connect = self.stride == 1 and inp == oup\n\n        self.conv = nn.Sequential(\n            # pw\n            nn.Conv2d(inp, inp * expand_ratio, 1, 1, 0, bias=False),\n            nn.BatchNorm2d(inp * expand_ratio),\n            nn.ReLU(inplace=True),\n            # dw\n            nn.Conv2d(inp * expand_ratio, inp * expand_ratio, 3, stride, 1, groups=inp * expand_ratio, bias=True),\n            nn.BatchNorm2d(inp * expand_ratio),\n            nn.ReLU(inplace=True),\n            # pw-linear\n            nn.Conv2d(inp * expand_ratio, oup, 1, 1, 0, bias=False),\n            nn.BatchNorm2d(oup),\n        )\n\n    def forward(self, x):\n        if self.use_res_connect:\n            return x + self.conv(x)\n        else:\n            return self.conv(x)\n\n\nclass MobileNetV2(nn.Module):\n    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n        super(MobileNetV2, self).__init__()\n        # setting of inverted residual blocks\n        self.interverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # building first layer\n        assert input_size % 32 == 0\n        input_channel = int(32 * width_mult)\n        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n        self.features = [conv_bn(3, input_channel, 2)]\n        # building inverted residual blocks\n        for t, c, n, s in self.interverted_residual_setting:\n            output_channel = int(c * width_mult)\n            for i in range(n):\n                if i == 0:\n                    self.features.append(InvertedResidual(input_channel, output_channel, s, t))\n                else:\n                    self.features.append(InvertedResidual(input_channel, output_channel, 1, t))\n                input_channel = output_channel\n        # building last several layers\n        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n        self.features.append(nn.AvgPool2d(int(input_size/32)))\n        # make it nn.Sequential\n        self.features = nn.Sequential(*self.features)\n\n        # building classifier\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(self.last_channel, n_class),\n        )\n\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(-1, self.last_channel)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\ndef export(dir):\n    dummy_input = Variable(torch.randn(1, 3, 224, 224))\n    model = MobileNetV2()\n    model.eval()\n    torch.save(model.state_dict(),os.path.join(dir,""MobileNetV2.pth""))\n    onnx.export(model, dummy_input,os.path.join(dir,""MobileNetV2.onnx""), verbose=True)\n\n\n\ndef get_model_and_input(model_save_dir):\n    model = MobileNetV2()\n    model.cpu()\n    model_path = os.path.join(model_save_dir,\'MobileNetV2.pth\')\n    model.load_state_dict(torch.load(model_path))\n    model.cpu()\n    model.eval()\n    batch_size = 1\n    channels = 3\n    height = 224\n    width = 224\n    images = Variable(torch.ones(batch_size, channels, height, width))\n    return images,model'"
model_generator/__init__.py,0,b''
model_generator/alexnet.py,9,"b'import os\nimport torch\nimport argparse\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\nimport torch.onnx as onnx\n\n\n__all__ = [\'AlexNet\', \'alexnet\']\n\n\nmodel_urls = {\n    \'alexnet\': \'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\',\n}\n\n\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=1000):\n        super(AlexNet, self).__init__()\n        self.featuresxxx = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            )\n\n\n        self.featuresa = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2, bias=False),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2, bias=False),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            )\n\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=2, stride=2, padding=4, bias=True),\n# nn.Conv2d(3, 2, kernel_size=11, stride=4, padding=2),\n#            nn.ReLU(inplace=True),\n#nn.MaxPool2d(kernel_size=3, stride=2),\n            )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n            )\n\n    def forward(self, x):\n        x = self.features(x)\n        return x\n        x = x.view(x.size(0), 256 * 6 * 6)\n        x = self.classifier(x)\n        return x\n        #return nn.functional.log_softmax(x)\n\n\n    def alexnet(pretrained=False, **kwargs):\n        r""""""AlexNet model architecture from the\n        `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.\n\n        Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n        model = AlexNet(**kwargs)\n        if pretrained:\n            model.load_state_dict(model_zoo.load_url(model_urls[\'alexnet\']))\n        return model\n\n\ndef export(dir):\n    file_path = os.path.realpath(__file__)\n    file_dir = os.path.dirname(file_path)\n    dummy_input = Variable(torch.randn(1, 3, 224, 224))\n    model = AlexNet()\n    # model = load_network(model,os.path.join(file_dir,\'..\',\'model\',\'pose_v02.pth\'))\n    model.eval()\n    torch.save(model.state_dict(),os.path.join(dir,""alexnet.pth""))\n    onnx.export(model, dummy_input,os.path.join(dir,""alexnet.onnx""), verbose=True)\n\ndef get_model_and_input(model_save_dir):\n    model = AlexNet()\n    model.cpu()\n    model_path = os.path.join(model_save_dir,\'alexnet.pth\')\n    model.load_state_dict(torch.load(model_path))\n    model.cpu()\n    model.eval()\n    batch_size = 1\n    channels = 3\n    height = 224\n    width = 224\n    images = Variable(torch.ones(batch_size, channels, height, width))\n    return images,model\n\n\n\n'"
model_generator/broadcast_add.py,7,"b'import torch.nn as nn\nfrom torch.autograd import Variable\nimport torch\nimport torch.onnx as onnx\nimport os\nimport numpy as np\ndef conv_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=True),\n        nn.BatchNorm2d(oup),\n        nn.ReLU(inplace=True)\n    )\nclass broadcast_add(nn.Module):\n    def __init__(self):\n        super(broadcast_add, self).__init__()\n        self.conv1 = conv_bn(3,128,1)\n        self.poo1 = nn.AvgPool2d(kernel_size=4)\n\n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.poo1(x1)\n        out = x1+x2\n        return out\n\ndef export(dir):\n    dummy_input = Variable(torch.randn(1, 3, 4, 4))\n    model = broadcast_add()\n    model.eval()\n    torch.save(model.state_dict(),os.path.join(dir,""broadcast_add.pth""))\n    onnx.export(model, dummy_input,os.path.join(dir,""broadcast_add.onnx""), verbose=True)\n\ndef get_model_and_input(model_save_dir):\n    model = broadcast_add()\n    model.cpu()\n    model_path = os.path.join(model_save_dir,\'broadcast_add.pth\')\n    model.load_state_dict(torch.load(model_path))\n    model.cpu()\n    model.eval()\n    batch_size = 1\n    channels = 3\n    height = 4\n    width = 4\n    images = Variable(torch.ones(batch_size, channels, height, width))\n    return images,model'"
model_generator/broadcast_mul.py,7,"b'import torch.nn as nn\nfrom torch.autograd import Variable\nimport torch\nimport torch.onnx as onnx\nimport os\nimport numpy as np\ndef conv_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=True),\n        nn.BatchNorm2d(oup),\n        nn.ReLU(inplace=True)\n    )\nclass broadcast_mul(nn.Module):\n    def __init__(self):\n        super(broadcast_mul, self).__init__()\n        self.conv1 = conv_bn(3,128,1)\n        self.poo1 = nn.AvgPool2d(kernel_size=4)\n\n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.poo1(x1)\n        # x2 = x2.view(x2.size(0), x2.size(1))\n        out = x1*x2\n        return out\n\ndef export(dir):\n    dummy_input = Variable(torch.randn(1, 3, 4, 4))\n    model = broadcast_mul()\n    model.eval()\n    torch.save(model.state_dict(),os.path.join(dir,""broadcast_mul.pth""))\n    onnx.export(model, dummy_input,os.path.join(dir,""broadcast_mul.onnx""), verbose=True)\n\n\ndef get_model_and_input(model_save_dir):\n    model = broadcast_mul()\n    model.cpu()\n    model_path = os.path.join(model_save_dir,\'broadcast_mul.pth\')\n    model.load_state_dict(torch.load(model_path))\n    model.cpu()\n    model.eval()\n    batch_size = 1\n    channels = 3\n    height = 4\n    width = 4\n    images = Variable(torch.ones(batch_size, channels, height, width))\n    return images,model\n'"
model_generator/googlenet.py,10,"b'\'\'\'GoogLeNet with PyTorch.\'\'\'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport os\nimport torch.onnx as onnx\n\nclass Inception(nn.Module):\n    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n        super(Inception, self).__init__()\n        # 1x1 conv branch\n        self.b1 = nn.Sequential(\n            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n            nn.BatchNorm2d(n1x1),\n            nn.ReLU(True),\n        )\n\n        # 1x1 conv -> 3x3 conv branch\n        self.b2 = nn.Sequential(\n            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n            nn.BatchNorm2d(n3x3red),\n            nn.ReLU(True),\n            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n            nn.BatchNorm2d(n3x3),\n            nn.ReLU(True),\n        )\n\n        # 1x1 conv -> 5x5 conv branch\n        self.b3 = nn.Sequential(\n            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n            nn.BatchNorm2d(n5x5red),\n            nn.ReLU(True),\n            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n            nn.BatchNorm2d(n5x5),\n            nn.ReLU(True),\n            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n            nn.BatchNorm2d(n5x5),\n            nn.ReLU(True),\n        )\n\n        # 3x3 pool -> 1x1 conv branch\n        self.b4 = nn.Sequential(\n            nn.MaxPool2d(3, stride=1, padding=1),\n            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n            nn.BatchNorm2d(pool_planes),\n            nn.ReLU(True),\n        )\n\n    def forward(self, x):\n        y1 = self.b1(x)\n        y2 = self.b2(x)\n        y3 = self.b3(x)\n        y4 = self.b4(x)\n        return torch.cat([y1,y2,y3,y4], 1)\n\n\nclass GoogLeNet(nn.Module):\n    def __init__(self):\n        super(GoogLeNet, self).__init__()\n        self.pre_layers = nn.Sequential(\n            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n            nn.BatchNorm2d(192),\n            nn.ReLU(True),\n        )\n\n        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n\n        self.maxpool = nn.MaxPool2d(2, stride=2, padding=0)\n\n        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n\n        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n\n        self.avgpool = nn.AvgPool2d(8, stride=1)\n        self.linear = nn.Linear(1024, 10)\n\n    def forward(self, x):\n        out = self.pre_layers(x)\n        out = self.a3(out)\n        out = self.b3(out)\n        out = self.maxpool(out)\n        out = self.a4(out)\n        out = self.b4(out)\n        out = self.c4(out)\n        out = self.d4(out)\n        out = self.e4(out)\n        out = self.maxpool(out)\n        out = self.a5(out)\n        out = self.b5(out)\n        out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\ndef export(dir):\n    file_path = os.path.realpath(__file__)\n    file_dir = os.path.dirname(file_path)\n    dummy_input = Variable(torch.randn(1, 3, 32, 32))\n    model = GoogLeNet()\n    # model = load_network(model,os.path.join(file_dir,\'..\',\'model\',\'pose_v02.pth\'))\n    model.eval()\n    torch.save(model.state_dict(),os.path.join(dir,""googlenet.pth""))\n    onnx.export(model, dummy_input,os.path.join(dir,""googlenet.onnx""), verbose=True)\n\ndef get_model_and_input(model_save_dir):\n    model = GoogLeNet()\n    model.cpu()\n    model_path = os.path.join(model_save_dir,\'googlenet.pth\')\n    model.load_state_dict(torch.load(model_path))\n    model.cpu()\n    model.eval()\n    batch_size = 1\n    channels = 3\n    height = 32\n    width = 32\n    images = Variable(torch.ones(batch_size, channels, height, width))\n    return images,model\n'"
model_generator/resnet.py,11,"b'\'\'\'ResNet18/34/50/101/152 in Pytorch.\'\'\'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport os\nimport torch.onnx as onnx\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = conv3x3(3,64)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2,2,2,2])\n\ndef ResNet34():\n    return ResNet(BasicBlock, [3,4,6,3])\n\ndef ResNet50():\n    return ResNet(Bottleneck, [3,4,6,3])\n\ndef ResNet101():\n    return ResNet(Bottleneck, [3,4,23,3])\n\ndef ResNet152():\n    return ResNet(Bottleneck, [3,8,36,3])\n\ndef test_resnet():\n    net = ResNet34()\n    y = net(Variable(torch.randn(1,3,32,32)))\n    print(""======================"")\n    print(y.size())\n\n\ndef export(dir):\n    file_path = os.path.realpath(__file__)\n    file_dir = os.path.dirname(file_path)\n    dummy_input = Variable(torch.randn(1, 3, 32, 32))\n    model = ResNet34()\n    # model = load_network(model,os.path.join(file_dir,\'..\',\'model\',\'pose_v02.pth\'))\n    model.eval()\n    torch.save(model.state_dict(),os.path.join(dir,""resnet.pth""))\n    onnx.export(model, dummy_input,os.path.join(dir,""resnet.onnx""), verbose=True)\n\ndef get_model_and_input(model_save_dir):\n    model = ResNet34()\n    model.cpu()\n    model_path = os.path.join(model_save_dir,\'resnet.pth\')\n    model.load_state_dict(torch.load(model_path))\n    model.cpu()\n    model.eval()\n    batch_size = 1\n    channels = 3\n    height = 32\n    width = 32\n    images = Variable(torch.ones(batch_size, channels, height, width))\n    return images,model'"
model_generator/resnet50.py,6,"b'# import torchvision.models as models\nfrom torch import onnx\nimport torch\nimport torch.nn as nn\nimport os\nimport math\n\n\n# model = models.resnet50(False)\n# dummy_input = torch.randn(1, 3, 224, 224)\n# onnx.export(model, dummy_input, ""resnet50.onnx"", verbose=True)\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet50():\n    """"""Constructs a ResNet-50 model.""""""\n    model = ResNet(Bottleneck, [3, 4, 6, 3])\n    return model\n\n\ndef export(dir):\n    file_path = os.path.realpath(__file__)\n    file_dir = os.path.dirname(file_path)\n    dummy_input = torch.randn(1, 3, 224, 224)\n    model = resnet50()\n    # model = load_network(model,os.path.join(file_dir,\'..\',\'model\',\'pose_v02.pth\'))\n    model.eval()\n    torch.save(model.state_dict(),os.path.join(dir,""resnet50.pth""))\n    onnx.export(model, dummy_input,os.path.join(dir,""resnet50.onnx""), verbose=True)\n\n\ndef get_model_and_input(model_save_dir=None):\n    model = resnet50()\n    model.cpu()\n    if model_save_dir is not None:\n        model_path = os.path.join(model_save_dir, \'resnet50.pth\')\n        model.load_state_dict(torch.load(model_path))\n    model.cpu()\n    model.eval()\n    batch_size = 1\n    channels = 3\n    height = 224\n    width = 224\n    images = torch.ones(batch_size, channels, height, width)\n    return images, model'"
onnx2caffe/__init__.py,0,b''
onnx2caffe/_error_utils.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, Text, Any, Callable\nfrom ._graph import Node, Graph\n\nclass ErrorHandling(object):\n  \'\'\'\n  To handle errors and addition of custom layers\n  \'\'\'\n\n  def __init__(self,\n               add_custom_layers = False, # type: bool\n               custom_conversion_functions = dict(), # type: Dict[Text, Any]\n               custom_layer_nodes = [], # type : List[Node]\n               ):\n      # type: (...) -> None\n      self.add_custom_layers = add_custom_layers\n      self.custom_conversion_functions = custom_conversion_functions\n      self.custom_layer_nodes = custom_layer_nodes\n\n\n  def unsupported_op(self,\n                     node,  # type: Node\n                    ):\n      # type: (...) -> Callable[[Any, Node, Graph, ErrorHandling], None]\n      \'\'\'\n      Either raise an error for an unsupported op type or return custom layer add function\n      \'\'\'\n      if self.add_custom_layers:\n        from ._operators import _convert_custom\n        return _convert_custom\n      else:\n        raise TypeError(\n          ""ONNX node of type {} is not supported.\\n"".format(node.op_type,)\n        )\n\n\n  def unsupported_op_configuration(self,\n                                   node, # type: Node\n                                   err_message, # type: Text\n                                   ):\n      raise TypeError(\n        ""Error while converting op of type: {}. Error message: {}\\n"".format(node.op_type, err_message, )\n      )\n\n\n  def missing_initializer(self,\n                          node, # type: Node\n                          err_message, # type: Text\n                          ):\n      # type: (...) -> None\n      \'\'\'\n      Missing initializer error\n      \'\'\'\n      raise ValueError(\n        ""Missing initializer error in op of type {}, with input name = {}, ""\n        ""output name = {}. Error message: {}\\n"".\n        format(node.op_type, node.inputs[0], node.outputs[0], err_message)\n      )\n\n\n\n'"
onnx2caffe/_graph.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom onnx import numpy_helper, ValueInfoProto, AttributeProto, GraphProto, NodeProto, TensorProto, TensorShapeProto\nfrom typing import Any, Text, Iterable, List, Dict, Sequence, Optional, Tuple, Union\nfrom typing_extensions import Protocol\nimport numpy as np\n\n\nclass Transformer(Protocol):\n    def __call__(self, graph):  # type: (Graph) -> Graph\n        pass\n\n\nEdgeInfo = Tuple[Text, Any, TensorShapeProto]\nAttributeValue = Any # TODO Union[Sequence[float], Sequence[int], Sequence[Text], Sequence[TensorProto], Sequence[GraphProto]]\n\ndef _input_from_onnx_input(input):  # type: (ValueInfoProto) -> EdgeInfo\n    name = input.name\n    type = input.type.tensor_type.elem_type\n    shape = tuple([d.dim_value for d in input.type.tensor_type.shape.dim])\n    return (name, type, shape)\n\n\ndef _convertAttributeProto(onnx_arg):  # type: (AttributeProto) -> AttributeValue\n    """"""\n    Convert an ONNX AttributeProto into an appropriate Python object\n    for the type.\n    NB: Tensor attribute gets returned as numpy array\n    """"""\n    if onnx_arg.HasField(\'f\'):\n        return onnx_arg.f\n    elif onnx_arg.HasField(\'i\'):\n        return onnx_arg.i\n    elif onnx_arg.HasField(\'s\'):\n        return onnx_arg.s\n    elif onnx_arg.HasField(\'t\'):\n        return numpy_helper.to_array(onnx_arg.t)\n    elif len(onnx_arg.floats):\n        return list(onnx_arg.floats)\n    elif len(onnx_arg.ints):\n        return list(onnx_arg.ints)\n    elif len(onnx_arg.strings):\n        return list(onnx_arg.strings)\n    else:\n        raise ValueError(""Unsupported ONNX attribute: {}"".format(onnx_arg))\n\n\nclass Attributes(Dict[Text, Any]):\n    @staticmethod\n    def from_onnx(args):  # type: (Iterable[AttributeProto]) -> Attributes\n        d = Attributes()\n        for arg in args:\n            d[arg.name] = _convertAttributeProto(arg)\n        return d\n\n\nclass Node(object):\n    def __init__(self,\n                 name,  # type: Optional[Text]\n                 op_type,  # type: Text\n                 attrs,  # type: Dict[Text, AttributeValue]\n                 inputs,  # type: List[Text]\n                 outputs,  # type: List[Text]\n                 ):\n        # type: (...) -> None\n        self.name = name\n        self.op_type = op_type\n        self.attrs = attrs\n        self.inputs = inputs\n        self.outputs = outputs\n        self.input_tensors = {}  # type: Dict[Text, np._ArrayLike[Any]]\n        self.parents = []  # type: List[Node]\n        self.children = []  # type: List[Node]\n        self.metadata = {}  # type: Dict[Any, Any]\n\n    def add_parent(self, parent_node):  # type: (Node) -> None\n        assert parent_node not in self.parents\n        self.parents.append(parent_node)\n        if self not in parent_node.children:\n            parent_node.children.append(self)\n\n    def add_child(self, child_node):  # type: (Node) -> None\n        assert child_node not in self.children\n        self.children.append(child_node)\n        if self not in child_node.parents:\n            child_node.parents.append(self)\n\n    def get_only_parent(self):  # type: () -> Node\n        if len(self.parents) != 1:\n            raise ValueError(\'Node ({}) expected to have 1 parent. Found {}.\'\n                             .format(self, len(self.parents)))\n        return self.parents[0]\n\n    @staticmethod\n    def from_onnx(node):  # type: (NodeProto) -> Node\n        attrs = Attributes.from_onnx(node.attribute)\n        name = Text(node.name)\n        if len(name) == 0:\n            name = ""_"".join(node.output)\n        return Node(\n            name, node.op_type, attrs, list(node.input), list(node.output)\n        )\n\n\nclass Graph(object):\n    def __init__(self,\n                 nodes,  # type: List[Node]\n                 inputs,  # type: List[EdgeInfo]\n                 outputs,  # type: List[EdgeInfo]\n                 shape_dict, # type: Dict[Text,Tuple[int,...]]\n                 ):\n        # type: (...) -> None\n        self.nodes = nodes\n        self.inputs = inputs\n        self.outputs = outputs\n        self.shape_dict = shape_dict  # data blob name to its shape\n\n        # data blob name to the list of op types it feeds into\n        self.blob_to_op_type = {} # type: Dict[Text, List[Text]]\n        # data blob name to the op_type that generates it\n        self.blob_from_op_type = {}  # type: Dict[Text, Text]\n\n        for node_ in nodes:\n            for input_ in node_.inputs:\n                if input_ in self.blob_to_op_type:\n                    self.blob_to_op_type[input_].append(node_.op_type)\n                else:\n                    self.blob_to_op_type[input_] = [node_.op_type]\n            for output_ in node_.outputs:\n                if output_ in self.blob_from_op_type:\n                    raise ValueError(""Data blob: %s, is generated by more than 1 op"" %(output_))\n                self.blob_from_op_type[output_] = node_.op_type\n\n\n    def transformed(self, transformers):  # type: (Iterable[Transformer]) -> Graph\n        graph = self\n        for transformer in transformers:\n            graph = transformer(graph)\n        return graph\n\n    def has_edge_name(self, name):  # type: (Text) -> bool\n        \'\'\'\n        Check if name is already used for graph inputs/outputs or for nodes\n        inputs/outputs\n        \'\'\'\n        names = set()\n        for input in self.inputs:\n            names.add(input[0])\n        for output in self.outputs:\n            names.add(output[0])\n        for node in self.nodes:\n            names.update(node.inputs)\n            names.update(node.outputs)\n        return name in names\n\n    def get_unique_edge_name(self, name):  # type: (Text) -> Text\n        n_ = name\n        i = 0\n        while self.has_edge_name(n_):\n            n_ = ""{}_{}"".format(name, i)\n            i += 1\n        return n_\n\n    @staticmethod\n    def from_onnx(graph):  # type: (GraphProto) -> Graph\n        input_tensors = {\n            t.name: numpy_helper.to_array(t) for t in graph.initializer\n        }\n        nodes_ = []\n        nodes_by_input = {}  # type: Dict[Text, List[Node]]\n        nodes_by_output = {}\n        for node in graph.node:\n            node_ = Node.from_onnx(node)\n            for input_ in node_.inputs:\n                if input_ in input_tensors:\n                    node_.input_tensors[input_] = input_tensors[input_]\n                else:\n                    if input_ in nodes_by_input:\n                        input_nodes = nodes_by_input[input_]\n                    else:\n                        input_nodes = []\n                        nodes_by_input[input_] = input_nodes\n                    input_nodes.append(node_)\n            for output_ in node_.outputs:\n                nodes_by_output[output_] = node_\n            nodes_.append(node_)\n\n        inputs = []\n        for i in graph.input:\n            if i.name not in input_tensors:\n                inputs.append(_input_from_onnx_input(i))\n\n        outputs = []\n        for o in graph.output:\n            outputs.append(_input_from_onnx_input(o))\n\n        for node_ in nodes_:\n            for input_ in node_.inputs:\n                if input_ in nodes_by_output:\n                    node_.parents.append(nodes_by_output[input_])\n            for output_ in node_.outputs:\n                if output_ in nodes_by_input:\n                    node_.children.extend(nodes_by_input[output_])\n\n        # Dictionary to hold the ""value_info"" field from ONNX graph\n        shape_dict = {} # type: Dict[Text,Tuple[int,...]]\n\n        def extract_value_info(shape_dict, # type: Dict[Text,Tuple[int,...]]\n                               value_info, # type: ValueInfoProto[...]\n                               ):\n            # type: (...) -> None\n            shape_dict[value_info.name] = tuple([int(dim.dim_value) for dim in value_info.type.tensor_type.shape.dim])\n\n        for value_info in graph.value_info:\n            extract_value_info(shape_dict, value_info)\n        for value_info in graph.input:\n            extract_value_info(shape_dict, value_info)\n        for value_info in graph.output:\n            extract_value_info(shape_dict, value_info)\n\n\n        return Graph(nodes_, inputs, outputs, shape_dict)\n'"
onnx2caffe/_operators.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom caffe import params as P\nimport math\nimport numpy as np\nfrom ._graph import Node, Graph\nfrom MyCaffe import Function as myf\n\ndef _compare(a, b, encoding=""utf8""): #type: (Text, Text, Text) -> bool\n    if isinstance(a, bytes):\n        a = a.decode(encoding)\n    if isinstance(b, bytes):\n        b = b.decode(encoding)\n    return a == b\n\ndef make_input(input):\n    name = input[0]\n    output = input[0]\n    output = [output]\n    shape = input[2]\n    shape = list(shape)\n    input_layer = myf(""Input"", name, [], output, input_param=dict(shape=dict(dim=shape)))\n    return input_layer\n\ndef _convert_conv(node, graph, err):\n    weight_name = node.inputs[1]\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    node_name = node.name\n    W = None\n    if weight_name in node.input_tensors:\n        W = node.input_tensors[weight_name]\n    else:\n        err.missing_initializer(node,\n                                ""Weight tensor: {} not found in the graph initializer"".format(weight_name,))\n    is_deconv = False\n    if node.op_type.endswith(""Transpose""):\n        is_deconv = True\n    bias_flag = False\n    bias = None\n    if len(node.inputs) > 2:\n        bias = node.input_tensors[node.inputs[2]]\n        bias_flag = True\n    dilations = node.attrs.get(""dilations"", [1, 1])\n    # groups = 1\n    groups = node.attrs.get(""group"", 1)\n    kernel_shape = node.attrs[""kernel_shape""]\n    pads = node.attrs.get(""pads"", [0, 0, 0, 0])\n    strides = node.attrs[""strides""]\n\n    layer = myf(""Convolution"", node_name, [input_name], [output_name],\n                kernel_h = kernel_shape[0],kernel_w = kernel_shape[1],\n                stride_h=strides[0], stride_w = strides[1], group = groups,\n                pad_h = pads[0], pad_w = pads[1],\n                num_output=W.shape[0],  dilation = dilations[0], bias_term = bias_flag)\n\n    graph.channel_dims[output_name] = W.shape[0]\n    return layer\n\ndef _convert_relu(node,graph,err):\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    name = str(node.name)\n\n    if input_name==output_name:\n        inplace = True\n    else:\n        inplace = False\n\n    layer = myf(""ReLU"",name,[input_name],[output_name],in_place=inplace)\n    # l_top_relu1 = L.ReLU(l_bottom, name=name, in_place=True)\n\n    graph.channel_dims[output_name] = graph.channel_dims[input_name]\n\n    return layer\n\ndef _convert_sigmoid(node,graph,err):\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    name = str(node.name)\n\n    if input_name==output_name:\n        inplace = True\n    else:\n        inplace = False\n\n    layer = myf(""Sigmoid"",name,[input_name],[output_name],in_place=inplace)\n    # l_top_relu1 = L.ReLU(l_bottom, name=name, in_place=True)\n\n    graph.channel_dims[output_name] = graph.channel_dims[input_name]\n\n    return layer\n\ndef _convert_BatchNorm(node,graph,err):\n    epsilon = node.attrs.get(""epsilon"", 1e-5)\n    scale = node.input_tensors[node.inputs[1]]\n    bias = node.input_tensors[node.inputs[2]]\n    mean = node.input_tensors[node.inputs[3]]\n    var = node.input_tensors[node.inputs[4]]\n    node_name = node.name\n\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n\n    if input_name==output_name:\n        inplace = True\n    else:\n        inplace = False\n\n    bn_layer = myf(""BatchNorm"", node_name+""_bn"",[input_name],[output_name],eps = epsilon, use_global_stats = True, in_place=inplace)\n    scale_layer = myf(""Scale"", node_name, [output_name],[output_name],in_place=True,bias_term=True)\n\n    graph.channel_dims[output_name] = graph.channel_dims[input_name]\n\n    return bn_layer,scale_layer\n\ndef _convert_Add(node,graph,err):\n    input_name_list = [str(i) for i in node.inputs]\n    output_name = str(node.outputs[0])\n    node_name = node.name\n\n    max_dim = 0\n    for name in input_name_list:\n        if graph.channel_dims[name]>max_dim:\n            max_dim = graph.channel_dims[name]\n\n    if \'broadcast\' in node.attrs:\n        if node.attrs[\'broadcast\'] == 1:\n            input_node_number = len(input_name_list)\n            if input_node_number !=2:\n                return err.unsupported_op_configuration(node, ""Broadcast Add must has 2 input, not {}"".format(input_node_number))\n            axis = node.attrs[\'axis\']\n            flat_layer = myf(""Flatten"",node_name+\'_flat\',[input_name_list[1]],[output_name+\'_flat\'])\n            layer = myf(""Bias"", node_name, [input_name_list[0],output_name+\'_flat\'], [output_name], axis = axis)\n            # layer = myf(""Bias"", node_name, input_name_list, [output_name], bias_term = False, axis = axis)\n            graph.channel_dims[output_name] = graph.channel_dims[input_name_list[0]]\n            return flat_layer,layer\n\n    layer = myf(""Eltwise"",node_name,input_name_list,[output_name],operation=P.Eltwise.SUM)\n    graph.channel_dims[output_name] = graph.channel_dims[input_name_list[0]]\n    return layer\n\ndef _convert_Mul(node,graph,err):\n    input_name_list = [str(i) for i in node.inputs]\n    output_name = str(node.outputs[0])\n    node_name = node.name\n\n    # max_dim = 0\n    # for name in input_name_list:\n    #     if graph.channel_dims[name]>max_dim:\n    #         max_dim = graph.channel_dims[name]\n\n    if \'broadcast\' in node.attrs:\n        if node.attrs[\'broadcast\'] == 1:\n            input_node_number = len(input_name_list)\n            if input_node_number !=2:\n                return err.unsupported_op_configuration(node, ""Broadcast Mul must has 2 input, not {}"".format(input_node_number))\n            axis = node.attrs[\'axis\']\n            flat_layer = myf(""Flatten"",node_name+\'_flat\',[input_name_list[1]],[output_name+\'_flat\'])\n            layer = myf(""Scale"", node_name, [input_name_list[0],output_name+\'_flat\'], [output_name], bias_term = False, axis = axis)\n            graph.channel_dims[output_name] = graph.channel_dims[input_name_list[0]]\n            return flat_layer,layer\n\n    layer = myf(""Eltwise"",node_name,input_name_list,[output_name],operation=P.Eltwise.PROD)\n    graph.channel_dims[output_name] = graph.channel_dims[input_name_list[0]]\n    return layer\n\ndef _convert_Reshape(node,graph,err):\n    node_name = node.name\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    if len(node.inputs)==1:\n        shape = tuple(node.attrs.get(\'shape\', ()))\n    else:\n        shape = tuple(node.input_tensors[node.inputs[1]])\n    # if shape == ():\n\n\n    if input_name==output_name:\n        inplace = True\n    else:\n        inplace = False\n    if len(shape) == 2:\n        layer = myf(""Flatten"",node_name,[input_name],[output_name],in_place=inplace)\n        graph.channel_dims[output_name] = shape[1]\n        return layer\n    elif len(shape) == 4:\n        graph.channel_dims[output_name] = shape[1]\n        layer = myf(""Reshape"", node_name, [input_name], [output_name], reshape_param = dict(shape=dict(dim=list(shape))))\n        return layer\n    else:\n        return err.unsupported_op_configuration(node, ""Reshape dimention number shall be 2 or 4"")\n\ndef _convert_Flatten(node,graph,err):\n    node_name = node.name\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    # shape = tuple(node.attrs.get(\'shape\', ()))\n    if input_name==output_name:\n        inplace = True\n    else:\n        inplace = False\n    layer = myf(""Flatten"", node_name, [input_name], [output_name], in_place=inplace)\n    # graph.channel_dims[output_name] = shape[1]\n    return layer\n\ndef _convert_pool(node,graph,err):\n    node_name = node.name\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    if node.op_type.endswith(""MaxPool""):\n        pool_type = P.Pooling.MAX\n    elif node.op_type.endswith(""AveragePool""):\n        pool_type = P.Pooling.AVE\n    else:\n        return err.unsupported_op_configuration(node,  ""Unsupported pool type"")\n\n    kernel_shape = node.attrs[""kernel_shape""]\n    strides = node.attrs.get(\'strides\', [1, 1])\n    pads = node.attrs.get(\'pads\', [0, 0, 0, 0])\n\n    layer = myf(""Pooling"",node_name,[input_name],[output_name],pooling_param = dict(pool = pool_type,\n                                                                                    kernel_h = kernel_shape[0],\n                                                                                    kernel_w = kernel_shape[1],\n                                                                                    stride_h = strides[0],\n                                                                                    stride_w = strides[1],\n                                                                                    pad_h = pads[0],\n                                                                                    pad_w = pads[1]))\n    graph.channel_dims[output_name] = graph.channel_dims[input_name]\n    return layer\n\ndef _convert_dropout(node,graph,err):\n    node_name = node.name\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    ratio = node.attrs.get(\'ratio\', 0.5)\n    layer = myf(""Dropout"", node_name, [input_name], [output_name], dropout_ratio =ratio)\n    graph.channel_dims[output_name] = graph.channel_dims[input_name]\n    return layer\n\ndef _convert_gemm(node,graph,err):\n    node_name = node.name\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    weight_name = node.inputs[1]\n    if weight_name in node.input_tensors:\n        W = node.input_tensors[weight_name]\n    else:\n        err.missing_initializer(node,\n                                ""Weight tensor: {} not found in the graph initializer"".format(weight_name, ))\n        return\n\n    if node.attrs[""broadcast""] != 1 or node.attrs[""transB""] != 1:\n        return err.unsupported_op_configuration(node,""Gemm is supported only for inner_product layer"")\n\n    b = None\n    bias_flag = False\n    if len(node.inputs) > 2:\n        b = node.input_tensors[node.inputs[2]]\n\n    if len(W.shape) != 2 or (b is not None and len(b.shape) != 1):\n        return err.unsupported_op_configuration(node, ""Gemm is supported only for inner_product layer"")\n    if b is not None:\n        bias_flag = True\n        if W.shape[0] != b.shape[0]:\n            return err.unsupported_op_configuration(node,\n                                                    ""Gemm is supported only for inner_product layer"")\n\n    layer = myf(""InnerProduct"",node_name,[input_name],[output_name],num_output = W.shape[0],bias_term = bias_flag)\n    graph.channel_dims[output_name] = W.shape[0]\n\n    return layer\n\ndef _convert_upsample(node,graph,err):\n    factor = int(node.attrs[""height_scale""])\n    node_name = node.name\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    # input_shape = graph.shape_dict[input_name]\n    # channels = input_shape[1]\n    channels = graph.channel_dims[input_name]\n    pad = int(math.ceil((factor - 1) / 2.))\n    # layer = myf(""Deconvolution"", node_name, [input_name], [output_name],\n    #             kernel_size=2 * factor - factor % 2,\n    #             stride=factor, group=channels,\n    #             pad = pad, num_output=channels, bias_term = False)\n    mode = node.attrs[""mode""]\n    #https://github.com/pytorch/pytorch/issues/6900\n    if mode==""bilinear"":\n        layer = myf(""Deconvolution"", node_name, [input_name], [output_name],\n                    convolution_param=dict(\n                        num_output=channels,\n                        kernel_size=2 * factor - factor % 2,\n                        stride=factor,\n                        pad=pad,\n                        group=channels,\n                        bias_term=False,\n                        weight_filler=dict(type=""bilinear_upsampling"")\n                    ))\n    else:\n        layer = myf(""Deconvolution"", node_name, [input_name], [output_name],\n                    convolution_param=dict(\n                        num_output=channels,\n                        kernel_size=factor,\n                        stride=factor,\n                        group=channels,\n                        bias_term=False,\n                    ))\n\n    graph.channel_dims[output_name] = graph.channel_dims[input_name]\n    return layer\n\ndef _convert_concat(node,graph,err):\n    node_name = node.name\n    input_name_list = [str(i) for i in node.inputs]\n    output_name = str(node.outputs[0])\n    axis = node.attrs.get(""axis"", 1)\n\n    layer = myf(\'Concat\', node_name, input_name_list, [output_name], axis = axis)\n    if axis == 1:\n        dim = 0\n        for name in input_name_list:\n            dim+=graph.channel_dims[name]\n        graph.channel_dims[output_name] = dim\n    else:\n        graph.channel_dims[output_name] = graph.channel_dims[input_name_list[0]]\n\n    return layer\n\ndef _convert_conv_transpose(node,graph,err):\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    node_name = node.name\n    weight_name = node.inputs[1]\n    W = None\n    if weight_name in node.input_tensors:\n        W = node.input_tensors[weight_name]\n    else:\n        err.missing_initializer(node,\n                                ""Weight tensor: {} not found in the graph initializer"".format(weight_name,))\n    bias_flag = False\n    bias = None\n    if len(node.inputs) > 2:\n        bias = node.input_tensors[node.inputs[2]]\n        bias_flag = True\n    dilations = node.attrs.get(""dilations"", [1, 1])\n    # groups = 1\n    groups = node.attrs.get(""group"", 1)\n    kernel_shape = node.attrs[""kernel_shape""]\n    pads = node.attrs.get(""pads"", [0, 0, 0, 0])\n    strides = node.attrs[""strides""]\n\n    layer = myf(\'Deconvolution\', node_name, [input_name], [output_name],\n                convolution_param=dict(\n                    num_output=W.shape[1],\n                    kernel_h=kernel_shape[0],kernel_w=kernel_shape[1],\n                    stride_h=strides[0],stride_w = strides[1],\n                    group=groups,\n                    pad_h=pads[0], pad_w=pads[1],\n                    bias_term=bias_flag,\n                ))\n\n    graph.channel_dims[output_name] = W.shape[1]\n    return layer\n\n    # l_top = L.Deconvolution(\n    #     l_bottom,\n    #     name=name,\n    #     convolution_param=dict(\n    #         num_output=W.shape[1],\n    #         kernel_h=kernel_h,\n    #         kernel_w=kernel_w,\n    #         stride_h=stride_h,\n    #         stride_w=stride_w,\n    #         pad_h=pad_h,\n    #         pad_w=pad_w,\n    #         group=groups,\n    #         bias_term=bias_term))\n\n\n\n_ONNX_NODE_REGISTRY = {\n    ""Conv"": _convert_conv,\n    ""Relu"": _convert_relu,\n    ""BatchNormalization"": _convert_BatchNorm,\n    ""Add"": _convert_Add,\n    ""Mul"": _convert_Mul,\n    ""Reshape"": _convert_Reshape,\n    ""MaxPool"": _convert_pool,\n    ""AveragePool"": _convert_pool,\n    ""Dropout"": _convert_dropout,\n    ""Gemm"": _convert_gemm,\n    ""Upsample"": _convert_upsample,\n    ""Concat"": _convert_concat,\n    ""ConvTranspose"": _convert_conv_transpose,\n    ""Sigmoid"": _convert_sigmoid,\n    ""Flatten"": _convert_Flatten,\n}\n'"
onnx2caffe/_transformers.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom typing import Sequence, Text, Dict, List\nimport numpy as np\n\nfrom onnx import TensorProto\n\nfrom ._graph import Graph, Node\n\n\nclass NodesFuser(object):\n    \'\'\'\n    An abstract helper for merging nodes\n    \'\'\'\n    def __init__(self,\n                 num_nodes,  # type: int\n                 ):\n        # type: (...) -> None\n        assert num_nodes >= 2, ""Algorithm only works if fusing multiple nodes""\n        self.num_nodes = num_nodes\n\n    def __call__(self, graph):  # type: (Graph) -> Graph\n        nodes = graph.nodes\n        merged_nodes = {}\n        for node in nodes:\n            nodes_window = []  # type: List[Node]\n            n = node\n            for _ in range(self.num_nodes - 1):\n                if len(n.parents) != 1:\n                    # We\'re only fusing nodes with single parents\n                    break\n                p = n.get_only_parent()\n                if len(p.children) != 1:\n                    # We can only fuse a node if its parent\'s\n                    # value isn\'t used by any other node.\n                    break\n                nodes_window.insert(0, n)\n                n = p\n            if len(nodes_window) > 0:\n                # add parent of chained nodes\n                first = nodes_window[0]\n                p = first.get_only_parent()\n                if len(p.children) == 1:\n                    nodes_window.insert(0, p)\n            if len(nodes_window) != self.num_nodes:\n                continue\n            if not self.is_eligible(graph, nodes_window):\n                continue\n            merged = self.merge(graph, nodes_window)\n            first, last = nodes_window[0], nodes_window[-1]\n            for parent in first.parents:\n                parent.children.remove(first)\n                if merged[0] not in parent.children:\n                    parent.add_child(merged[0])\n            for child in last.children:\n                child.parents.remove(last)\n                if merged[-1] not in child.parents:\n                    child.add_parent(merged[-1])\n            for n in nodes_window:\n                merged_nodes[n.name] = merged\n\n        transformed_nodes = []\n        added_merged = []  # type: List[Node]\n        for node in nodes:\n            if node.name in merged_nodes:\n                merged = merged_nodes[node.name]\n                if merged[0] not in added_merged:\n                    for n in merged:\n                        transformed_nodes.append(n)\n                    added_merged.append(merged[0])\n            else:\n                transformed_nodes.append(node)\n        return Graph(transformed_nodes, graph.inputs, graph.outputs, graph.shape_dict)\n\n    def is_eligible(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> bool\n        \'\'\'Returns true if this subset of nodes is eligible for fusion.\'\'\'\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n\n    def merge(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> Sequence[Node]\n        \'\'\'Merge nodes\'\'\'\n        nodes[0].outputs = nodes[-1].outputs\n        return [nodes[0]]\n\n\nclass ConvAddFuser(NodesFuser):\n    \'\'\'\n    Fuses Add layer into parent convolution layer.\n    \'\'\'\n    def __init__(self):  # type: () -> None\n        super(ConvAddFuser, self).__init__(2)\n\n    def is_eligible(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> bool\n        parent, child = nodes[0], nodes[1]\n        if parent.op_type != \'Conv\':\n            return False\n        if child.op_type != \'Add\':\n            return False\n        if \'broadcast\' not in child.attrs:\n            return False\n        if \'axis\' not in child.attrs:\n            return False\n        if parent.inputs[1] not in parent.input_tensors:\n            return False\n        if len(parent.inputs) > 2 and parent.inputs[2] not in parent.input_tensors:\n            return False\n        if child.inputs[1] not in child.input_tensors:\n            return False\n\n        broadcast = child.attrs[\'broadcast\']\n        if broadcast != 1:\n            return False\n\n        axis = child.attrs[\'axis\']\n        if axis != 1:\n            return False\n\n        return True\n\n    def merge(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> Sequence[Node]\n        parent, child = nodes[0], nodes[1]\n        output_channels = parent.input_tensors[parent.inputs[1]].shape[0]\n        if len(parent.inputs) > 2:\n            bias_input_name = parent.inputs[2]\n            bias = parent.input_tensors[bias_input_name]\n        else:\n            bias_input_name = ""{}_bias"".format(parent.name,)\n            parent.inputs.append(bias_input_name)\n            bias = np.zeros(\n                (output_channels,), dtype=np.float32\n            )\n            parent.input_tensors[bias_input_name] = bias\n        bias = bias + child.input_tensors[child.inputs[1]]\n        parent.input_tensors[bias_input_name] = bias\n        parent.outputs = child.outputs\n        parent.children.remove(child)\n        child.parents.remove(parent)\n        return [parent]\n\n\nclass BNBroadcastedMulFuser(NodesFuser):\n    \'\'\'\n    Fuses Mul into BatchNorm\n    \'\'\'\n    def __init__(self):  # type: () -> None\n        super(BNBroadcastedMulFuser, self).__init__(2)\n\n    def is_eligible(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> bool\n        parent, child = nodes[0], nodes[1]\n        if parent.op_type != \'BatchNormalization\':\n            return False\n        if child.op_type != \'Mul\':\n            return False\n        if ""broadcast"" not in child.attrs:\n            return False\n        if child.attrs[""broadcast""] != 1:\n            return False\n        if ""axis"" not in child.attrs:\n            return False\n        if child.attrs[""axis""] != 1:\n            return False\n        if child.inputs[1] not in child.input_tensors:\n            return False\n        if parent.inputs[1] not in parent.input_tensors:\n            return False\n        if parent.inputs[2] not in parent.input_tensors:\n            return False\n        return True\n\n    def merge(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> Sequence[Node]\n        parent, child = nodes[0], nodes[1]\n        weight = parent.input_tensors[parent.inputs[1]]\n        bias = parent.input_tensors[parent.inputs[2]]\n        W = child.input_tensors[child.inputs[1]]\n        parent.input_tensors[parent.inputs[1]] = np.multiply(weight, W)\n        parent.input_tensors[parent.inputs[2]] = np.multiply(bias, W)\n        parent.outputs = child.outputs\n        parent.children.remove(child)\n        child.parents.remove(parent)\n        return [parent]\n\n\nclass BNBroadcastedAddFuser(NodesFuser):\n    \'\'\'\n    Fuses Add into BatchNorm\n    \'\'\'\n    def __init__(self):  # type: () -> None\n        super(BNBroadcastedAddFuser, self).__init__(2)\n\n    def is_eligible(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> bool\n        parent, child = nodes[0], nodes[1]\n        if parent.op_type != \'BatchNormalization\':\n            return False\n        if child.op_type != \'Add\':\n            return False\n        if ""broadcast"" not in child.attrs:\n            return False\n        if child.attrs[""broadcast""] != 1:\n            return False\n        if ""axis"" not in child.attrs:\n            return False\n        if child.attrs[""axis""] != 1:\n            return False\n        if len(child.inputs) != 2:\n            return False\n        if child.inputs[1] not in child.input_tensors:\n            return False\n        if parent.inputs[2] not in parent.input_tensors:\n            return False\n        return True\n\n    def merge(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> Sequence[Node]\n        parent, child = nodes[0], nodes[1]\n        bias = parent.input_tensors[parent.inputs[2]]\n        b = child.input_tensors[child.inputs[1]]\n        parent.input_tensors[parent.inputs[2]] = bias + b\n        parent.outputs = child.outputs\n        parent.children.remove(child)\n        child.parents.remove(parent)\n        return [parent]\n\n\nclass DropoutRemover(NodesFuser):\n    \'\'\'\n    Removes Dropout layer\n    \'\'\'\n    def __init__(self):  # type: () -> None\n        super(DropoutRemover, self).__init__(2)\n\n    def is_eligible(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> bool\n        child = nodes[1]\n        return child.op_type == ""Dropout""\n\n    def merge(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> Sequence[Node]\n        parent, child = nodes[0], nodes[1]\n        parent.children.remove(child)\n        child.parents.remove(parent)\n        parent.outputs = child.outputs\n        return [parent]\n\n\nclass ReshapeInitTensorFuser(object):\n    \'\'\'\n    Fuses Reshape operator if it is used only to reshape blob in\n    graph initializer. We can reshape here instead of runtime.\n    \'\'\'\n\n    def __call__(self, graph):  # type: (Graph) -> Graph\n        nodes = graph.nodes\n        removed = []\n        for node in nodes:\n            if node.op_type != \'Reshape\':\n                continue\n            if not (len(node.input_tensors) == 2 or len(node.input_tensors) == 1):\n                continue\n            tensor_name = node.inputs[0]\n            if tensor_name not in node.input_tensors:\n                continue\n            if len(node.inputs) > 1:\n                shape_name = node.inputs[1]\n                if shape_name not in node.input_tensors:\n                    continue\n            is_non_constant_parent = False\n            if len(node.parents) > 0:\n                for parent in node.parents:\n                    if parent.op_type != \'Constant\':\n                        is_non_constant_parent = True\n                        break\n            if is_non_constant_parent:\n                continue\n\n            removed.append(node)\n            output_name = node.outputs[0]\n\n            tensor = node.input_tensors[tensor_name]\n            if \'shape\' in node.attrs:\n                shape = tuple(node.attrs[""shape""])\n            else:\n                shape = node.input_tensors[shape_name] # type: ignore\n\n            # ONNX spec supports setting dimension to \'0\', in which case\n            # it should be taken from old dimension.\n            # This isn\'t supported in numpy, so don\'t transform.\n            # TODO Should we support this case?\n            if any([s == 0 for s in shape]):\n                continue\n\n            reshaped_tensor = tensor.reshape(shape)\n\n            for child in node.children:\n                child.parents.remove(node)\n                child.input_tensors[output_name] = reshaped_tensor\n\n        transformed_nodes = [node for node in nodes if node not in removed]\n        return Graph(transformed_nodes, graph.inputs, graph.outputs, graph.shape_dict)\n\n\nclass OutputRenamer(object):\n    \'\'\'\n    Rename outputs according to mapping\n    \'\'\'\n    def __init__(self,\n                 mapping,  # type: Dict[Text, Text]\n                 ):\n        # type: (...) -> None\n        self.mapping = mapping\n\n    def __call__(self, graph):  # type: (Graph) -> Graph\n        mapping = self.mapping.copy()\n        nodes = graph.nodes\n        for node in nodes:\n            for i in range(len(node.outputs)):\n                output = node.outputs[i]\n                if output not in mapping:\n                    continue\n                node.outputs[i] = mapping[output]\n                for child in node.children:\n                    for j in range(len(child.inputs)):\n                        input_ = child.inputs[j]\n                        if input_ != output:\n                            continue\n                        child.inputs[j] = mapping[output]\n                del mapping[output]\n                if len(mapping) == 0:\n                    break\n        return graph\n\n\nclass PixelShuffleFuser(NodesFuser):\n    \'\'\'\n    Fuses 3 operators reshape->transpose->reshape which is equivalent to\n    pytorch\'s pixel_shuffle layer\n    \'\'\'\n    def __init__(self):  # type: () -> None\n        super(PixelShuffleFuser, self).__init__(3)\n        self.num_added = 0\n\n    def is_eligible(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> bool\n        if nodes[0].op_type != \'Reshape\':\n            return False\n        if nodes[1].op_type != \'Transpose\':\n            return False\n        if nodes[2].op_type != \'Reshape\':\n            return False\n        if nodes[0].inputs[1] not in nodes[0].input_tensors:\n            return False\n        if nodes[2].inputs[1] not in nodes[2].input_tensors:\n            return False\n\n        shape = nodes[0].input_tensors[nodes[0].inputs[1]]\n        if len(shape) != 6:\n            return False\n        if shape[0] != 1 or shape[2] != shape[3]:\n            return False\n\n        input_channels = shape[1]\n        scale_factor = shape[2]\n        input_height = shape[4]\n        input_width = shape[5]\n\n        if nodes[1].attrs.get(\'perm\', []) != [0, 1, 4, 2, 5, 3]:\n            return False\n\n        shape = nodes[2].input_tensors[nodes[2].inputs[1]]\n        if len(shape) != 4:\n            return False\n\n        output_channels = shape[1]\n        output_height = shape[2]\n        output_width = shape[3]\n        if input_channels != output_channels:\n            return False\n        if (input_height * scale_factor) != output_height:\n            return False\n        if (input_width * scale_factor) != output_width:\n            return False\n\n        return True\n\n    def get_unique_edge_name(self, graph, name):  # type: (Graph, Text) -> Text\n        self.num_added += 1\n        return graph.get_unique_edge_name(name + \'_\' + str(self.num_added))\n\n    def merge(self, graph, nodes):  # type: (Graph, Sequence[Node]) -> Sequence[Node]\n        \'\'\'\n        Pixel shuffle is implemented using 3 operators:\n            - Reshape(1, channels, scale, scale, height, width)\n            - Transpose(0, 1, 4, 2, 5, 3)\n            - Reshape(1, channels, height * scale, width * scale)\n        CoreML Reshape and Transpose layers don\'t support tensors with more\n        than 4 dimensions. Thus we change above sequence of operators to the\n        following equivalent sequence:\n            - Reshape(channels, scale * scale, height, width)\n            - Transpose(0, 2, 1, 3)\n            - Reshape(channels * height, scale, scale, width)\n            - Transpose(0, 1, 3, 2)\n            - Reshape(1, channels, height * scale, width * scale)\n        \'\'\'\n        reshape_1 = nodes[0]\n        transpose_1 = nodes[1]\n        transpose_1.children = []\n\n        shape = reshape_1.input_tensors[reshape_1.inputs[1]]\n\n        channels = shape[1]\n        scale = shape[2]\n        height = shape[4]\n        width = shape[5]\n\n        reshape_1.input_tensors[reshape_1.inputs[1]] = np.asarray([channels, scale * scale, height, width])\n        transpose_1.attrs[\'perm\'] = [0, 2, 1, 3]\n\n        reshape_output_name = \'pixel_shuffle_reshape\'\n        transpose_output_name = \'pixel_shuffle_transpose\'\n\n        transpose_1.outputs = [\n            self.get_unique_edge_name(graph, transpose_output_name)\n        ]\n\n        shape_name_second_reshape = self.get_unique_edge_name(graph, reshape_output_name)\n        output_name_second_reshape = self.get_unique_edge_name(graph, reshape_output_name)\n        reshape_2 = Node(\n            reshape_output_name,\n            \'Reshape\',\n            {},\n            [transpose_1.outputs[0], shape_name_second_reshape],\n            [output_name_second_reshape]\n        )\n        reshape_2.input_tensors[shape_name_second_reshape] = np.asarray([channels * height, scale, scale, width])\n        transpose_1.add_child(reshape_2)\n\n        transpose_2 = Node(\n            transpose_output_name,\n            \'Transpose\',\n            {\'perm\': [0, 1, 3, 2]},\n            reshape_2.outputs,\n            [self.get_unique_edge_name(graph, transpose_output_name)]\n        )\n        reshape_2.add_child(transpose_2)\n\n        final_reshape = nodes[2]\n        final_reshape.inputs = [transpose_2.outputs[0], nodes[2].inputs[1]]\n        final_reshape.parents = []\n        transpose_2.add_child(final_reshape)\n        return [reshape_1, transpose_1, reshape_2, transpose_2, final_reshape]\n\n\nclass AddModelInputsOutputs(object):\n    \'\'\'\n    Expose hidden states of recurrent layers as model inputs and outputs\n    \'\'\'\n    def __call__(self, graph):  # type: (Graph) -> Graph\n        input_names = [str(input_[0]) for input_ in graph.inputs]\n        output_names = [str(output_[0]) for output_ in graph.outputs]\n        for node in graph.nodes:\n            if str(node.op_type) == \'LSTM\':\n                input_h = node.inputs[5] if len(node.inputs) > 5 else node.inputs[0] + \'_h_input\'\n                input_c = node.inputs[6] if len(node.inputs) > 6 else node.inputs[0] + \'_c_input\'\n                output_h = node.outputs[1] if len(node.outputs) > 1 else node.outputs[0] + \'_h_output\'\n                output_c = node.outputs[2] if len(node.outputs) > 2 else node.outputs[0] + \'_c_output\'\n                h = node.attrs[""hidden_size""]\n                for input_ in [str(input_h), str(input_c)]:\n                    if input_ not in input_names:\n                        graph.inputs.append(tuple((input_, TensorProto.FLOAT, (h,))))  #type: ignore\n                    if input_ not in graph.blob_to_op_type:\n                        graph.blob_to_op_type[input_] = [\'LSTM\']\n                for output_ in [str(output_h), str(output_c)]:\n                    if output_ not in output_names:\n                        graph.outputs.append(tuple((output_, TensorProto.FLOAT, (h,))))  #type: ignore\n                    graph.blob_from_op_type[output_] = \'LSTM\'\n        return graph\n\n\nclass ConstantsToInitializers(object):\n    \'\'\'\n    Takes onnx Constant nodes and puts the tensor into graph initializers instead.\n    \'\'\'\n    def __call__(self, graph):  # type: (Graph) -> Graph\n        output_names = [str(output_[0]) for output_ in graph.outputs]\n        remaining_nodes = []\n        for node in graph.nodes:\n            if node.op_type != \'Constant\' or node.name in output_names:\n                remaining_nodes.append(node)\n                continue\n            for child in node.children:\n                child.input_tensors[node.outputs[0]] = node.attrs[""value""]\n\n        graph.nodes = remaining_nodes\n        return graph\n\n\nclass ImageScalerRemover(object):\n    \'\'\'\n    Removes ImageScaler layer if connected to a model input and single parent child nodes\n    \'\'\'\n\n    def __call__(self, graph):  # type: (Graph) -> Graph\n        input_names = [str(input_[0]) for input_ in graph.inputs]\n        nodes_to_be_removed = []\n        for node in graph.nodes:\n            if (node.op_type != \'ImageScaler\') or (len(node.parents) != 0) or (node.inputs[0] not in input_names):\n                continue\n            is_eligible = True\n            for child in node.children:\n                if not (len(child.parents) == 1 and child.inputs[0] == node.outputs[0]):\n                    is_eligible = False\n                    break\n                child.inputs[0] = node.inputs[0]\n                child.parents = []\n            if not is_eligible:\n                continue\n            nodes_to_be_removed.append(node.name)\n\n        transformed_nodes = []\n        for node in graph.nodes:\n            if node.name not in nodes_to_be_removed:\n                transformed_nodes.append(node)\n        return Graph(transformed_nodes, graph.inputs, graph.outputs, graph.shape_dict)'"
onnx2caffe/_weightloader.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n# from caffe import params as P\nimport numpy as np\nfrom ._graph import Node, Graph\n\ndef _convert_conv(net, node, graph, err):\n    weight_name = node.inputs[1]\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    node_name = node.name\n    W = None\n    if weight_name in node.input_tensors:\n        W = node.input_tensors[weight_name]\n    else:\n        err.missing_initializer(node,\n                                ""Weight tensor: {} not found in the graph initializer"".format(weight_name,))\n    bias_flag = False\n    bias = None\n    if len(node.inputs) > 2:\n        bias = node.input_tensors[node.inputs[2]]\n        bias_flag = True\n    # net.params[node_name][0].data = W\n    # if bias_flag:\n    #     net.params[node_name][1].data = bias\n    np.copyto(net.params[node_name][0].data,W,casting=\'same_kind\')\n    if bias_flag:\n        np.copyto(net.params[node_name][1].data, bias, casting=\'same_kind\')\n\ndef _convert_relu(net, node, graph, err):\n    pass\n\ndef _convert_sigmoid(net, node, graph, err):\n    pass\n\ndef _convert_BatchNorm(net, node, graph, err):\n    scale = node.input_tensors[node.inputs[1]]\n    bias = node.input_tensors[node.inputs[2]]\n    mean = node.input_tensors[node.inputs[3]]\n    var = node.input_tensors[node.inputs[4]]\n    node_name = node.name\n    np.copyto(net.params[node_name + \'_bn\'][0].data, mean, casting=\'same_kind\')\n    np.copyto(net.params[node_name + \'_bn\'][1].data, var, casting=\'same_kind\')\n    net.params[node_name + \'_bn\'][2].data[...] = 1.0\n    np.copyto(net.params[node_name][0].data, scale, casting=\'same_kind\')\n    np.copyto(net.params[node_name][1].data, bias, casting=\'same_kind\')\n    # net.params[node_name+\'_bn\'][1].data = var\n    # net.params[node_name][0].data = scale\n    # net.params[node_name][1].data = bias\n\ndef _convert_Add(net, node, graph, err):\n    pass\n\ndef _convert_Mul(net, node, graph, err):\n    pass\n\ndef _convert_Reshape(net, node, graph, err):\n    pass\n\ndef _convert_Flatten(net, node, graph, err):\n    pass\n\ndef _convert_pool(net, node, graph, err):\n    pass\n\ndef _convert_dropout(net, node, graph, err):\n    pass\n\ndef _convert_gemm(net, node, graph, err):\n    node_name = node.name\n    weight_name = node.inputs[1]\n    if weight_name in node.input_tensors:\n        W = node.input_tensors[weight_name]\n    else:\n        err.missing_initializer(node,\n                                ""Weight tensor: {} not found in the graph initializer"".format(weight_name, ))\n    if node.attrs[""broadcast""] != 1 or node.attrs[""transB""] != 1:\n        return err.unsupported_op_configuration(node, ""Gemm is supported only for inner_product layer"")\n    b = None\n    if len(node.inputs) > 2:\n        b = node.input_tensors[node.inputs[2]]\n    if len(W.shape) != 2 or (b is not None and len(b.shape) != 1):\n        return err.unsupported_op_configuration(node, ""Gemm is supported only for inner_product layer"")\n    if b is not None:\n        if W.shape[0] != b.shape[0]:\n            return err.unsupported_op_configuration(node, ""Gemm is supported only for inner_product layer"")\n    net.params[node_name][0].data[...] = W\n    net.params[node_name][1].data[...] = b\n\ndef _convert_upsample(net, node, graph, err):\n    mode = node.attrs[""mode""]\n    node_name = node.name\n    if mode == ""nearest"":\n        caffe_params = net.params[node_name][0].data\n        weights = np.ones(caffe_params.shape).astype(""float32"")\n        np.copyto(net.params[node_name][0].data, weights, casting=\'same_kind\')\n        # net.params[node_name][0].data[]\n\ndef _convert_concat(net, node, graph, err):\n    pass\n\ndef _convert_conv_transpose(net, node, graph, err):\n    weight_name = node.inputs[1]\n    input_name = str(node.inputs[0])\n    output_name = str(node.outputs[0])\n    node_name = node.name\n    W = None\n    if weight_name in node.input_tensors:\n        W = node.input_tensors[weight_name]\n    else:\n        err.missing_initializer(node,\n                                ""Weight tensor: {} not found in the graph initializer"".format(weight_name,))\n    bias_flag = False\n    bias = None\n    if len(node.inputs) > 2:\n        bias = node.input_tensors[node.inputs[2]]\n        bias_flag = True\n    # net.params[node_name][0].data = W\n    # if bias_flag:\n    #     net.params[node_name][1].data = bias\n    np.copyto(net.params[node_name][0].data,W,casting=\'same_kind\')\n    if bias_flag:\n        np.copyto(net.params[node_name][1].data, bias, casting=\'same_kind\')\n\n_ONNX_NODE_REGISTRY = {\n    ""Conv"": _convert_conv,\n    ""Relu"": _convert_relu,\n    ""BatchNormalization"": _convert_BatchNorm,\n    ""Add"": _convert_Add,\n    ""Mul"": _convert_Mul,\n    ""Reshape"": _convert_Reshape,\n    ""MaxPool"": _convert_pool,\n    ""AveragePool"": _convert_pool,\n    ""Dropout"": _convert_dropout,\n    ""Gemm"": _convert_gemm,\n    ""Upsample"": _convert_upsample,\n    ""Concat"": _convert_concat,\n    ""ConvTranspose"": _convert_conv_transpose,\n    ""Sigmoid"": _convert_sigmoid,\n    ""Flatten"": _convert_Flatten,\n}\n\n\n'"
