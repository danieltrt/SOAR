file_path,api_count,code
benchmark.py,4,"b'""""""\nThe MIT License (MIT)\n\nCopyright (c) 2017 Marvin Teichmann\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nimport numpy as np\nimport imageio\n# import scipy as scp\n# import scipy.misc\n\nimport argparse\n\nimport logging\n\nfrom convcrf import convcrf\nfrom fullcrf import fullcrf\n\nimport torch\nfrom torch.autograd import Variable\n\nfrom utils import pascal_visualizer as vis\nfrom utils import synthetic\n\nimport time\n\ntry:\n    import matplotlib.pyplot as plt\n    matplotlib = True\n    figure = plt.figure()\n    plt.close(figure)\nexcept:\n    matplotlib = False\n    pass\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\n\ndef do_crf_inference(image, unary, args):\n\n    if args.pyinn or not hasattr(torch.nn.functional, \'unfold\'):\n        # pytorch 0.3 or older requires pyinn.\n        args.pyinn = True\n        # Cheap and easy trick to make sure that pyinn is loadable.\n        import pyinn\n\n    # get basic hyperparameters\n    num_classes = unary.shape[2]\n    shape = image.shape[0:2]\n    config = convcrf.default_conf\n    config[\'filter_size\'] = 7\n    config[\'pyinn\'] = args.pyinn\n\n    if args.normalize:\n        # Warning, applying image normalization affects CRF computation.\n        # The parameter \'col_feats::schan\' needs to be adapted.\n\n        # Normalize image range\n        #     This changes the image features and influences CRF output\n        image = image / 255\n        # mean substraction\n        #    CRF is invariant to mean subtraction, output is NOT affected\n        image = image - 0.5\n        # std normalization\n        #       Affect CRF computation\n        image = image / 0.3\n\n        # schan = 0.1 is a good starting value for normalized images.\n        # The relation is f_i = image / schan\n        config[\'col_feats\'][\'schan\'] = 0.1\n\n    # make input pytorch compatible\n    img = image.transpose(2, 0, 1)  # shape: [3, hight, width]\n    # Add batch dimension to image: [1, 3, height, width]\n    img = img.reshape([1, 3, shape[0], shape[1]])\n    img_var = Variable(torch.Tensor(img)).cuda()\n\n    un = unary.transpose(2, 0, 1)  # shape: [3, hight, width]\n    # Add batch dimension to unary: [1, 21, height, width]\n    un = un.reshape([1, num_classes, shape[0], shape[1]])\n    unary_var = Variable(torch.Tensor(un)).cuda()\n\n    logging.debug(""Build ConvCRF."")\n    ##\n    # Create CRF module\n    gausscrf = convcrf.GaussCRF(conf=config, shape=shape, nclasses=num_classes)\n    # Cuda computation is required.\n    # A CPU implementation of our message passing is not provided.\n    gausscrf.cuda()\n\n    # Perform ConvCRF inference\n    """"""\n    \'Warm up\': Our implementation compiles cuda kernels during runtime.\n    The first inference call thus comes with some overhead.\n    """"""\n    logging.info(""Start Computation."")\n    prediction = gausscrf.forward(unary=unary_var, img=img_var)\n\n    if args.nospeed:\n\n        logging.info(""Doing speed benchmark with filter size: {}""\n                     .format(config[\'filter_size\']))\n        logging.info(""Running multiple iteration. This may take a while."")\n\n        # Our implementation compiles cuda kernels during runtime.\n        # The first inference run is those much slower.\n        # prediction = gausscrf.forward(unary=unary_var, img=img_var)\n\n        start_time = time.time()\n        for i in range(10):\n            # Running ConvCRF 10 times and report average total time\n            prediction = gausscrf.forward(unary=unary_var, img=img_var)\n\n        prediction.cpu()  # wait for all GPU computations to finish\n        duration = (time.time() - start_time) * 1000 / 10\n\n        logging.debug(""Finished running 10 predictions."")\n        logging.debug(""Avg Computation time: {} ms"".format(duration))\n\n    # Perform FullCRF inference\n    myfullcrf = fullcrf.FullCRF(config, shape, num_classes)\n    fullprediction = myfullcrf.compute(unary, image, softmax=False)\n\n    if args.nospeed:\n\n        start_time = time.time()\n        for i in range(5):\n            # Running FullCRF 5 times and report average total time\n            fullprediction = myfullcrf.compute(unary, image, softmax=False)\n\n        fullduration = (time.time() - start_time) * 1000 / 5\n\n        logging.debug(""Finished running 5 predictions."")\n        logging.debug(""Avg Computation time: {} ms"".format(fullduration))\n\n        logging.info(""Using FullCRF took {:4.0f} ms ({:2.2f} s)"".format(\n            fullduration, fullduration / 1000))\n\n        logging.info(""Using ConvCRF took {:4.0f} ms ({:2.2f} s)"".format(\n            duration, duration / 1000))\n\n        logging.info(""Congratulation. Using ConvCRF provids a speed-up""\n                     "" of {:.0f}."".format(fullduration / duration))\n\n        logging.info("""")\n\n    return prediction.data.cpu().numpy(), fullprediction\n\n\ndef plot_results(image, unary, conv_out, full_out, label, args):\n\n    logging.debug(""Plot results."")\n\n    # Create visualizer\n    myvis = vis.PascalVisualizer()\n\n    # Transform id image to coloured labels\n    coloured_label = myvis.id2color(id_image=label)\n\n    unary_hard = np.argmax(unary, axis=2)\n    coloured_unary = myvis.id2color(id_image=unary_hard)\n\n    conv_out = conv_out[0]  # Remove Batch dimension\n    conv_hard = np.argmax(conv_out, axis=0)\n    coloured_conv = myvis.id2color(id_image=conv_hard)\n\n    full_hard = np.argmax(full_out, axis=2)\n    coloured_full = myvis.id2color(id_image=full_hard)\n\n    if matplotlib:\n        # Plot results using matplotlib\n        figure = plt.figure()\n        figure.tight_layout()\n        # Plot parameters\n        num_rows = 2\n        num_cols = 3\n        off = 0\n\n        ax = figure.add_subplot(num_rows, num_cols, 1)\n        # img_name = os.path.basename(args.image)\n        ax.set_title(\'Image \')\n        ax.axis(\'off\')\n        ax.imshow(image)\n\n        ax = figure.add_subplot(num_rows, num_cols, 2)\n        ax.set_title(\'Label\')\n        ax.axis(\'off\')\n        ax.imshow(coloured_label.astype(np.uint8))\n\n        ax = figure.add_subplot(num_rows, num_cols, 3 - off)\n        ax.set_title(\'Unary\')\n        ax.axis(\'off\')\n        ax.imshow(coloured_unary.astype(np.uint8))\n\n        ax = figure.add_subplot(num_rows, num_cols, 4 - off)\n        ax.set_title(\'ConvCRF Output\')\n        ax.axis(\'off\')\n        ax.imshow(coloured_conv.astype(np.uint8))\n\n        ax = figure.add_subplot(num_rows, num_cols, 5 - off)\n        ax.set_title(\'FullCRF Output\')\n        ax.axis(\'off\')\n        ax.imshow(coloured_full.astype(np.uint8))\n\n        # plt.subplots_adjust(left=0.02, right=0.98,\n        #                    wspace=0.15, hspace=0.15)\n\n        plt.show()\n    else:\n        if args.output is None:\n            args.output = ""out.png""\n\n        logging.warning(""Matplotlib not found."")\n        logging.info(""Saving output to {} instead"".format(args.output))\n\n    if args.output is not None:\n        # Save results to disk\n        out_img = np.concatenate(\n            (image, coloured_label, coloured_unary, coloured_conv),\n            axis=1)\n\n        imageio.imwrite(args.output, out_img.astype(np.uint8))\n\n        logging.info(""Plot has been saved to {}"".format(args.output))\n\n    return\n\n\ndef get_parser():\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n\n    parser.add_argument(""image"", type=str,\n                        help=""input image"")\n\n    parser.add_argument(""label"", type=str,\n                        help=""Label file."")\n\n    parser.add_argument(""--gpu"", type=str, default=\'0\',\n                        help=""which gpu to use"")\n\n    parser.add_argument(\'--output\', type=str,\n                        help=""Optionally save output as img."")\n\n    parser.add_argument(\'--nospeed\', action=\'store_false\',\n                        help=""Skip speed evaluation."")\n\n    parser.add_argument(\'--normalize\', action=\'store_true\',\n                        help=""Normalize input image before inference."")\n\n    parser.add_argument(\'--pyinn\', action=\'store_true\',\n                        help=""Use pyinn based Cuda implementation""\n                             ""for message passing."")\n\n    return parser\n\n\nif __name__ == \'__main__\':\n    parser = get_parser()\n    args = parser.parse_args()\n\n    # Load data\n    image = imageio.imread(args.image)\n    label = imageio.imread(args.label)\n\n    # Produce unary by adding noise to label\n    unary = synthetic.augment_label(label, num_classes=21)\n    # Compute CRF inference\n\n    conv_out, full_out = do_crf_inference(image, unary, args)\n    plot_results(image, unary, conv_out, full_out, label, args)\n    logging.info(""Thank you for trying ConvCRFs."")\n'"
demo.py,4,"b'""""""\nThe MIT License (MIT)\n\nCopyright (c) 2017 Marvin Teichmann\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nimport numpy as np\nimport imageio\n# import scipy as scp\n# import scipy.misc\n\nimport argparse\n\nimport logging\nimport time\n\nfrom convcrf import convcrf\n\nimport torch\nfrom torch.autograd import Variable\n\nfrom utils import pascal_visualizer as vis\nfrom utils import synthetic\n\ntry:\n    import matplotlib.pyplot as plt\n    figure = plt.figure()\n    matplotlib = True\n    plt.close(figure)\nexcept:\n    matplotlib = False\n    pass\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\n\ndef do_crf_inference(image, unary, args):\n\n    if args.pyinn or not hasattr(torch.nn.functional, \'unfold\'):\n        # pytorch 0.3 or older requires pyinn.\n        args.pyinn = True\n        # Cheap and easy trick to make sure that pyinn is loadable.\n        import pyinn\n\n    # get basic hyperparameters\n    num_classes = unary.shape[2]\n    shape = image.shape[0:2]\n    config = convcrf.default_conf\n    config[\'filter_size\'] = 7\n    config[\'pyinn\'] = args.pyinn\n\n    if args.normalize:\n        # Warning, applying image normalization affects CRF computation.\n        # The parameter \'col_feats::schan\' needs to be adapted.\n\n        # Normalize image range\n        #     This changes the image features and influences CRF output\n        image = image / 255\n        # mean substraction\n        #    CRF is invariant to mean subtraction, output is NOT affected\n        image = image - 0.5\n        # std normalization\n        #       Affect CRF computation\n        image = image / 0.3\n\n        # schan = 0.1 is a good starting value for normalized images.\n        # The relation is f_i = image * schan\n        config[\'col_feats\'][\'schan\'] = 0.1\n\n    # make input pytorch compatible\n    image = image.transpose(2, 0, 1)  # shape: [3, hight, width]\n    # Add batch dimension to image: [1, 3, height, width]\n    image = image.reshape([1, 3, shape[0], shape[1]])\n    img_var = Variable(torch.Tensor(image)).cuda()\n\n    unary = unary.transpose(2, 0, 1)  # shape: [3, hight, width]\n    # Add batch dimension to unary: [1, 21, height, width]\n    unary = unary.reshape([1, num_classes, shape[0], shape[1]])\n    unary_var = Variable(torch.Tensor(unary)).cuda()\n\n    logging.info(""Build ConvCRF."")\n    ##\n    # Create CRF module\n    gausscrf = convcrf.GaussCRF(conf=config, shape=shape, nclasses=num_classes)\n    # Cuda computation is required.\n    # A CPU implementation of our message passing is not provided.\n    gausscrf.cuda()\n\n    logging.info(""Start Computation."")\n    # Perform CRF inference\n    prediction = gausscrf.forward(unary=unary_var, img=img_var)\n\n    if args.nospeed:\n        # Evaluate inference speed\n        logging.info(""Doing speed evaluation."")\n        start_time = time.time()\n        for i in range(10):\n            # Running ConvCRF 10 times and average total time\n            pred = gausscrf.forward(unary=unary_var, img=img_var)\n\n        pred.cpu()  # wait for all GPU computations to finish\n\n        duration = (time.time() - start_time) * 1000 / 10\n\n        logging.info(""Finished running 10 predictions."")\n        logging.info(""Avg. Computation time: {} ms"".format(duration))\n\n    return prediction.data.cpu().numpy()\n\n\ndef plot_results(image, unary, prediction, label, args):\n\n    logging.info(""Plot results."")\n\n    # Create visualizer\n    myvis = vis.PascalVisualizer()\n\n    # Transform id image to coloured labels\n    coloured_label = myvis.id2color(id_image=label)\n\n    unary_hard = np.argmax(unary, axis=2)\n    coloured_unary = myvis.id2color(id_image=unary_hard)\n\n    prediction = prediction[0]  # Remove Batch dimension\n    prediction_hard = np.argmax(prediction, axis=0)\n    coloured_crf = myvis.id2color(id_image=prediction_hard)\n\n    if matplotlib:\n        # Plot results using matplotlib\n        figure = plt.figure()\n        figure.tight_layout()\n\n        # Plot parameters\n        num_rows = 2\n        num_cols = 2\n\n        ax = figure.add_subplot(num_rows, num_cols, 1)\n        # img_name = os.path.basename(args.image)\n        ax.set_title(\'Image \')\n        ax.axis(\'off\')\n        ax.imshow(image)\n\n        ax = figure.add_subplot(num_rows, num_cols, 2)\n        ax.set_title(\'Label\')\n        ax.axis(\'off\')\n        ax.imshow(coloured_label.astype(np.uint8))\n\n        ax = figure.add_subplot(num_rows, num_cols, 3)\n        ax.set_title(\'Unary\')\n        ax.axis(\'off\')\n        ax.imshow(coloured_unary.astype(np.uint8))\n\n        ax = figure.add_subplot(num_rows, num_cols, 4)\n        ax.set_title(\'CRF Output\')\n        ax.axis(\'off\')\n        ax.imshow(coloured_crf.astype(np.uint8))\n\n        plt.show()\n    else:\n        if args.output is None:\n            args.output = ""out.png""\n\n        logging.warning(""Matplotlib not found."")\n        logging.info(""Saving output to {} instead"".format(args.output))\n\n    if args.output is not None:\n        # Save results to disk\n        out_img = np.concatenate(\n            (image, coloured_label, coloured_unary, coloured_crf),\n            axis=1)\n\n        imageio.imwrite(args.output, out_img.astype(np.uint8))\n\n        logging.info(""Plot has been saved to {}"".format(args.output))\n\n    return\n\n\ndef get_parser():\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n\n    parser.add_argument(""image"", type=str,\n                        help=""input image"")\n\n    parser.add_argument(""label"", type=str,\n                        help=""Label file."")\n\n    parser.add_argument(""--gpu"", type=str, default=\'0\',\n                        help=""which gpu to use"")\n\n    parser.add_argument(\'--output\', type=str,\n                        help=""Optionally save output as img."")\n\n    parser.add_argument(\'--nospeed\', action=\'store_false\',\n                        help=""Skip speed evaluation."")\n\n    parser.add_argument(\'--normalize\', action=\'store_true\',\n                        help=""Normalize input image before inference."")\n\n    parser.add_argument(\'--pyinn\', action=\'store_true\',\n                        help=""Use pyinn based Cuda implementation""\n                             ""for message passing."")\n\n    # parser.add_argument(\'--compare\', action=\'store_true\')\n    # parser.add_argument(\'--embed\', action=\'store_true\')\n\n    # args = parser.parse_args()\n\n    return parser\n\n\nif __name__ == \'__main__\':\n    parser = get_parser()\n    args = parser.parse_args()\n\n    # Load data\n    image = imageio.imread(args.image)\n    label = imageio.imread(args.label)\n\n    # Produce unary by adding noise to label\n    unary = synthetic.augment_label(label, num_classes=21)\n    # Compute CRF inference\n    prediction = do_crf_inference(image, unary, args)\n    # Plot output\n    plot_results(image, unary, prediction, label, args)\n    logging.info(""Thank you for trying ConvCRFs."")\n'"
convcrf/__init__.py,0,b''
convcrf/convcrf.py,31,"b'""""""\nThe MIT License (MIT)\n\nCopyright (c) 2017 Marvin Teichmann\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nimport numpy as np\nimport scipy as scp\nimport math\n\nimport logging\nimport warnings\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\ntry:\n    import pyinn as P\n    has_pyinn = True\nexcept ImportError:\n    #  PyInn is required to use our cuda based message-passing implementation\n    #  Torch 0.4 provides a im2col operation, which will be used instead.\n    #  It is ~15% slower.\n    has_pyinn = False\n    pass\n\nfrom utils import test_utils\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as nnfun\nfrom torch.autograd import Variable\nfrom torch.nn.parameter import Parameter\n\nimport torch.nn.functional as F\n\nimport gc\n\n\n# Default config as proposed by Philipp Kraehenbuehl and Vladlen Koltun,\ndefault_conf = {\n    \'filter_size\': 11,\n    \'blur\': 4,\n    \'merge\': True,\n    \'norm\': \'none\',\n    \'weight\': \'vector\',\n    ""unary_weight"": 1,\n    ""weight_init"": 0.2,\n\n    \'trainable\': False,\n    \'convcomp\': False,\n    \'logsoftmax\': True,  # use logsoftmax for numerical stability\n    \'softmax\': True,\n    \'final_softmax\': False,\n\n    \'pos_feats\': {\n        \'sdims\': 3,\n        \'compat\': 3,\n    },\n    \'col_feats\': {\n        \'sdims\': 80,\n        \'schan\': 13,   # schan depend on the input scale.\n                       # use schan = 13 for images in [0, 255]\n                       # for normalized images in [-0.5, 0.5] try schan = 0.1\n        \'compat\': 10,\n        \'use_bias\': False\n    },\n    ""trainable_bias"": False,\n\n    ""pyinn"": False\n}\n\n# Config used for test cases on 10 x 10 pixel greyscale inpu\ntest_config = {\n    \'filter_size\': 5,\n    \'blur\': 1,\n    \'merge\': False,\n    \'norm\': \'sym\',\n    \'trainable\': False,\n    \'weight\': \'scalar\',\n    ""unary_weight"": 1,\n    ""weight_init"": 0.5,\n    \'convcomp\': False,\n\n    \'trainable\': False,\n    \'convcomp\': False,\n    ""logsoftmax"": True,  # use logsoftmax for numerical stability\n    ""softmax"": True,\n\n    \'pos_feats\': {\n        \'sdims\': 1.5,\n        \'compat\': 3,\n    },\n\n    \'col_feats\': {\n        \'sdims\': 2,\n        \'schan\': 2,\n        \'compat\': 3,\n        \'use_bias\': True\n    },\n    ""trainable_bias"": False,\n}\n\n\nclass GaussCRF(nn.Module):\n    """""" Implements ConvCRF with hand-crafted features.\n\n        It uses the more generic ConvCRF class as basis and utilizes a config\n        dict to easily set hyperparameters and follows the design choices of:\n        Philipp Kraehenbuehl and Vladlen Koltun, ""Efficient Inference in Fully\n        ""Connected CRFs with Gaussian Edge Pots"" (arxiv.org/abs/1210.5644)\n    """"""\n\n    def __init__(self, conf, shape, nclasses=None):\n        super(GaussCRF, self).__init__()\n\n        self.conf = conf\n        self.shape = shape\n        self.nclasses = nclasses\n\n        self.trainable = conf[\'trainable\']\n\n        if not conf[\'trainable_bias\']:\n            self.register_buffer(\'mesh\', self._create_mesh())\n        else:\n            self.register_parameter(\'mesh\', Parameter(self._create_mesh()))\n\n        if self.trainable:\n            def register(name, tensor):\n                self.register_parameter(name, Parameter(tensor))\n        else:\n            def register(name, tensor):\n                self.register_buffer(name, Variable(tensor))\n\n        register(\'pos_sdims\', torch.Tensor([1 / conf[\'pos_feats\'][\'sdims\']]))\n\n        if conf[\'col_feats\'][\'use_bias\']:\n            register(\'col_sdims\',\n                     torch.Tensor([1 / conf[\'col_feats\'][\'sdims\']]))\n        else:\n            self.col_sdims = None\n\n        register(\'col_schan\', torch.Tensor([1 / conf[\'col_feats\'][\'schan\']]))\n        register(\'col_compat\', torch.Tensor([conf[\'col_feats\'][\'compat\']]))\n        register(\'pos_compat\', torch.Tensor([conf[\'pos_feats\'][\'compat\']]))\n\n        if conf[\'weight\'] is None:\n            weight = None\n        elif conf[\'weight\'] == \'scalar\':\n            val = conf[\'weight_init\']\n            weight = torch.Tensor([val])\n        elif conf[\'weight\'] == \'vector\':\n            val = conf[\'weight_init\']\n            weight = val * torch.ones(1, nclasses, 1, 1)\n\n        self.CRF = ConvCRF(\n            shape, nclasses, mode=""col"", conf=conf,\n            use_gpu=True, filter_size=conf[\'filter_size\'],\n            norm=conf[\'norm\'], blur=conf[\'blur\'], trainable=conf[\'trainable\'],\n            convcomp=conf[\'convcomp\'], weight=weight,\n            final_softmax=conf[\'final_softmax\'],\n            unary_weight=conf[\'unary_weight\'],\n            pyinn=conf[\'pyinn\'])\n\n        return\n\n    def forward(self, unary, img, num_iter=5):\n        """""" Run a forward pass through ConvCRF.\n\n        Arguments:\n            unary: torch.Tensor with shape [bs, num_classes, height, width].\n                The unary predictions. Logsoftmax is applied to the unaries\n                during inference. When using CNNs don\'t apply softmax,\n                use unnormalized output (logits) instead.\n\n            img: torch.Tensor with shape [bs, 3, height, width]\n                The input image. Default config assumes image\n                data in [0, 255]. For normalized images adapt\n                `schan`. Try schan = 0.1 for images in [-0.5, 0.5]\n        """"""\n\n        conf = self.conf\n\n        bs, c, x, y = img.shape\n\n        pos_feats = self.create_position_feats(sdims=self.pos_sdims, bs=bs)\n        col_feats = self.create_colour_feats(\n            img, sdims=self.col_sdims, schan=self.col_schan,\n            bias=conf[\'col_feats\'][\'use_bias\'], bs=bs)\n\n        compats = [self.pos_compat, self.col_compat]\n\n        self.CRF.add_pairwise_energies([pos_feats, col_feats],\n                                       compats, conf[\'merge\'])\n\n        prediction = self.CRF.inference(unary, num_iter=num_iter)\n\n        self.CRF.clean_filters()\n        return prediction\n\n    def _create_mesh(self, requires_grad=False):\n        hcord_range = [range(s) for s in self.shape]\n        mesh = np.array(np.meshgrid(*hcord_range, indexing=\'ij\'),\n                        dtype=np.float32)\n\n        return torch.from_numpy(mesh)\n\n    def create_colour_feats(self, img, schan, sdims=0.0, bias=True, bs=1):\n        norm_img = img * schan\n\n        if bias:\n            norm_mesh = self.create_position_feats(sdims=sdims, bs=bs)\n            feats = torch.cat([norm_mesh, norm_img], dim=1)\n        else:\n            feats = norm_img\n        return feats\n\n    def create_position_feats(self, sdims, bs=1):\n        if type(self.mesh) is Parameter:\n            return torch.stack(bs * [self.mesh * sdims])\n        else:\n            return torch.stack(bs * [Variable(self.mesh) * sdims])\n\n\ndef show_memusage(device=0, name=""""):\n    import gpustat\n    gc.collect()\n    gpu_stats = gpustat.GPUStatCollection.new_query()\n    item = gpu_stats.jsonify()[""gpus""][device]\n\n    logging.info(""{:>5}/{:>5} MB Usage at {}"".format(\n        item[""memory.used""], item[""memory.total""], name))\n\n\ndef exp_and_normalize(features, dim=0):\n    """"""\n    Aka ""softmax"" in deep learning literature\n    """"""\n    normalized = torch.nn.functional.softmax(features, dim=dim)\n    return normalized\n\n\ndef _get_ind(dz):\n    if dz == 0:\n        return 0, 0\n    if dz < 0:\n        return 0, -dz\n    if dz > 0:\n        return dz, 0\n\n\ndef _negative(dz):\n    """"""\n    Computes -dz for numpy indexing. Goal is to use as in array[i:-dz].\n\n    However, if dz=0 this indexing does not work.\n    None needs to be used instead.\n    """"""\n    if dz == 0:\n        return None\n    else:\n        return -dz\n\n\nclass MessagePassingCol():\n    """""" Perform the Message passing of ConvCRFs.\n\n    The main magic happens here.\n    """"""\n\n    def __init__(self, feat_list, compat_list, merge, npixels, nclasses,\n                 norm=""sym"",\n                 filter_size=5, clip_edges=0, use_gpu=False,\n                 blur=1, matmul=False, verbose=False, pyinn=False):\n\n        assert(use_gpu)\n\n        if not norm == ""sym"" and not norm == ""none"":\n            raise NotImplementedError\n\n        span = filter_size // 2\n        assert(filter_size % 2 == 1)\n        self.span = span\n        self.filter_size = filter_size\n        self.use_gpu = use_gpu\n        self.verbose = verbose\n        self.blur = blur\n        self.pyinn = pyinn\n\n        self.merge = merge\n\n        self.npixels = npixels\n\n        if not self.blur == 1 and self.blur % 2:\n            raise NotImplementedError\n\n        self.matmul = matmul\n\n        self._gaus_list = []\n        self._norm_list = []\n\n        for feats, compat in zip(feat_list, compat_list):\n            gaussian = self._create_convolutional_filters(feats)\n            if not norm == ""none"":\n                mynorm = self._get_norm(gaussian)\n                self._norm_list.append(mynorm)\n            else:\n                self._norm_list.append(None)\n\n            gaussian = compat * gaussian\n            self._gaus_list.append(gaussian)\n\n        if merge:\n            self.gaussian = sum(self._gaus_list)\n            if not norm == \'none\':\n                raise NotImplementedError\n\n    def _get_norm(self, gaus):\n        norm_tensor = torch.ones([1, 1, self.npixels[0], self.npixels[1]])\n        normalization_feats = torch.autograd.Variable(norm_tensor)\n        if self.use_gpu:\n            normalization_feats = normalization_feats.cuda()\n\n        norm_out = self._compute_gaussian(normalization_feats, gaussian=gaus)\n        return 1 / torch.sqrt(norm_out + 1e-20)\n\n    def _create_convolutional_filters(self, features):\n\n        span = self.span\n\n        bs = features.shape[0]\n\n        if self.blur > 1:\n            off_0 = (self.blur - self.npixels[0] % self.blur) % self.blur\n            off_1 = (self.blur - self.npixels[1] % self.blur) % self.blur\n            pad_0 = math.ceil(off_0 / 2)\n            pad_1 = math.ceil(off_1 / 2)\n            if self.blur == 2:\n                assert(pad_0 == self.npixels[0] % 2)\n                assert(pad_1 == self.npixels[1] % 2)\n\n            features = torch.nn.functional.avg_pool2d(features,\n                                                      kernel_size=self.blur,\n                                                      padding=(pad_0, pad_1),\n                                                      count_include_pad=False)\n\n            npixels = [math.ceil(self.npixels[0] / self.blur),\n                       math.ceil(self.npixels[1] / self.blur)]\n            assert(npixels[0] == features.shape[2])\n            assert(npixels[1] == features.shape[3])\n        else:\n            npixels = self.npixels\n\n        gaussian_tensor = features.data.new(\n            bs, self.filter_size, self.filter_size,\n            npixels[0], npixels[1]).fill_(0)\n\n        gaussian = Variable(gaussian_tensor)\n\n        for dx in range(-span, span + 1):\n            for dy in range(-span, span + 1):\n\n                dx1, dx2 = _get_ind(dx)\n                dy1, dy2 = _get_ind(dy)\n\n                feat_t = features[:, :, dx1:_negative(dx2), dy1:_negative(dy2)]\n                feat_t2 = features[:, :, dx2:_negative(dx1), dy2:_negative(dy1)] # NOQA\n\n                diff = feat_t - feat_t2\n                diff_sq = diff * diff\n                exp_diff = torch.exp(torch.sum(-0.5 * diff_sq, dim=1))\n\n                gaussian[:, dx + span, dy + span,\n                         dx2:_negative(dx1), dy2:_negative(dy1)] = exp_diff\n\n        return gaussian.view(\n            bs, 1, self.filter_size, self.filter_size,\n            npixels[0], npixels[1])\n\n    def compute(self, input):\n        if self.merge:\n            pred = self._compute_gaussian(input, self.gaussian)\n        else:\n            assert(len(self._gaus_list) == len(self._norm_list))\n            pred = 0\n            for gaus, norm in zip(self._gaus_list, self._norm_list):\n                pred += self._compute_gaussian(input, gaus, norm)\n\n        return pred\n\n    def _compute_gaussian(self, input, gaussian, norm=None):\n\n        if norm is not None:\n            input = input * norm\n\n        shape = input.shape\n        num_channels = shape[1]\n        bs = shape[0]\n\n        if self.blur > 1:\n            off_0 = (self.blur - self.npixels[0] % self.blur) % self.blur\n            off_1 = (self.blur - self.npixels[1] % self.blur) % self.blur\n            pad_0 = int(math.ceil(off_0 / 2))\n            pad_1 = int(math.ceil(off_1 / 2))\n            input = torch.nn.functional.avg_pool2d(input,\n                                                   kernel_size=self.blur,\n                                                   padding=(pad_0, pad_1),\n                                                   count_include_pad=False)\n            npixels = [math.ceil(self.npixels[0] / self.blur),\n                       math.ceil(self.npixels[1] / self.blur)]\n            assert(npixels[0] == input.shape[2])\n            assert(npixels[1] == input.shape[3])\n        else:\n            npixels = self.npixels\n\n        if self.verbose:\n            show_memusage(name=""Init"")\n\n        if self.pyinn:\n            input_col = P.im2col(input, self.filter_size, 1, self.span)\n        else:\n            # An alternative implementation of num2col.\n            #\n            # This has implementation uses the torch 0.4 im2col operation.\n            # This implementation was not avaible when we did the experiments\n            # published in our paper. So less ""testing"" has been done.\n            #\n            # It is around ~20% slower then the pyinn implementation but\n            # easier to use as it removes a dependency.\n            input_unfold = F.unfold(input, self.filter_size, 1, self.span)\n            input_unfold = input_unfold.view(\n                bs, num_channels, self.filter_size, self.filter_size,\n                npixels[0], npixels[1])\n            input_col = input_unfold\n\n        k_sqr = self.filter_size * self.filter_size\n\n        if self.verbose:\n            show_memusage(name=""Im2Col"")\n\n        product = gaussian * input_col\n        if self.verbose:\n            show_memusage(name=""Product"")\n\n        product = product.view([bs, num_channels,\n                                k_sqr, npixels[0], npixels[1]])\n\n        message = product.sum(2)\n\n        if self.verbose:\n            show_memusage(name=""FinalNorm"")\n\n        if self.blur > 1:\n            in_0 = self.npixels[0]\n            in_1 = self.npixels[1]\n            message = message.view(bs, num_channels, npixels[0], npixels[1])\n            with warnings.catch_warnings():\n                warnings.simplefilter(""ignore"")\n                # Suppress warning regarding corner alignment\n                message = torch.nn.functional.upsample(message,\n                                                       scale_factor=self.blur,\n                                                       mode=\'bilinear\')\n\n            message = message[:, :, pad_0:pad_0 + in_0, pad_1:in_1 + pad_1]\n            message = message.contiguous()\n\n            message = message.view(shape)\n            assert(message.shape == shape)\n\n        if norm is not None:\n            message = norm * message\n\n        return message\n\n\nclass ConvCRF(nn.Module):\n    """"""\n        Implements a generic CRF class.\n\n    This class provides tools to build\n    your own ConvCRF based model.\n    """"""\n\n    def __init__(self, npixels, nclasses, conf,\n                 mode=""conv"", filter_size=5,\n                 clip_edges=0, blur=1, use_gpu=False,\n                 norm=\'sym\', merge=False,\n                 verbose=False, trainable=False,\n                 convcomp=False, weight=None,\n                 final_softmax=True, unary_weight=10,\n                 pyinn=False):\n\n        super(ConvCRF, self).__init__()\n        self.nclasses = nclasses\n\n        self.filter_size = filter_size\n        self.clip_edges = clip_edges\n        self.use_gpu = use_gpu\n        self.mode = mode\n        self.norm = norm\n        self.merge = merge\n        self.kernel = None\n        self.verbose = verbose\n        self.blur = blur\n        self.final_softmax = final_softmax\n        self.pyinn = pyinn\n\n        self.conf = conf\n\n        self.unary_weight = unary_weight\n\n        if self.use_gpu:\n            if not torch.cuda.is_available():\n                logging.error(""GPU mode requested but not avaible."")\n                logging.error(""Please run using use_gpu=False."")\n                raise ValueError\n\n        self.npixels = npixels\n\n        if type(npixels) is tuple or type(npixels) is list:\n            self.height = npixels[0]\n            self.width = npixels[1]\n        else:\n            self.npixels = npixels\n\n        if trainable:\n            def register(name, tensor):\n                self.register_parameter(name, Parameter(tensor))\n        else:\n            def register(name, tensor):\n                self.register_buffer(name, Variable(tensor))\n\n        if weight is None:\n            self.weight = None\n        else:\n            register(\'weight\', weight)\n\n        if convcomp:\n            self.comp = nn.Conv2d(nclasses, nclasses,\n                                  kernel_size=1, stride=1, padding=0,\n                                  bias=False)\n\n            self.comp.weight.data.fill_(0.1 * math.sqrt(2.0 / nclasses))\n        else:\n            self.comp = None\n\n    def clean_filters(self):\n        self.kernel = None\n\n    def add_pairwise_energies(self, feat_list, compat_list, merge):\n        assert(len(feat_list) == len(compat_list))\n\n        assert(self.use_gpu)\n\n        self.kernel = MessagePassingCol(\n            feat_list=feat_list,\n            compat_list=compat_list,\n            merge=merge,\n            npixels=self.npixels,\n            filter_size=self.filter_size,\n            nclasses=self.nclasses,\n            use_gpu=True,\n            norm=self.norm,\n            verbose=self.verbose,\n            blur=self.blur,\n            pyinn=self.pyinn)\n\n    def inference(self, unary, num_iter=5):\n\n        if not self.conf[\'logsoftmax\']:\n            lg_unary = torch.log(unary)\n            prediction = exp_and_normalize(lg_unary, dim=1)\n        else:\n            lg_unary = nnfun.log_softmax(unary, dim=1, _stacklevel=5)\n            if self.conf[\'softmax\'] and False:\n                prediction = exp_and_normalize(lg_unary, dim=1)\n            else:\n                prediction = lg_unary\n\n        for i in range(num_iter):\n            message = self.kernel.compute(prediction)\n\n            if self.comp is not None:\n                # message_r = message.view(tuple([1]) + message.shape)\n                comp = self.comp(message)\n                message = message + comp\n\n            if self.weight is None:\n                prediction = lg_unary + message\n            else:\n                prediction = (self.unary_weight - self.weight) * lg_unary + \\\n                    self.weight * message\n\n            if not i == num_iter - 1 or self.final_softmax:\n                if self.conf[\'softmax\']:\n                    prediction = exp_and_normalize(prediction, dim=1)\n\n        return prediction\n\n    def start_inference(self):\n        pass\n\n    def step_inference(self):\n        pass\n\n\ndef get_test_conf():\n    return test_config.copy()\n\n\ndef get_default_conf():\n    return default_conf.copy()\n\nif __name__ == ""__main__"":\n    conf = get_test_conf()\n    tcrf = GaussCRF(conf, [10, 10], None).cuda()\n\n    unary = test_utils._get_simple_unary()\n    img = test_utils._get_simple_img()\n\n    img = np.transpose(img, [2, 0, 1])\n    img_torch = Variable(torch.Tensor(img), requires_grad=False).cuda()\n\n    unary_var = Variable(torch.Tensor(unary)).cuda()\n    unary_var = unary_var.view(2, 10, 10)\n    img_var = Variable(torch.Tensor(img)).cuda()\n\n    prediction = tcrf.forward(unary_var, img_var).cpu().data.numpy()\n    res = np.argmax(prediction, axis=0)\n    import scipy.misc\n    scp.misc.imsave(""out.png"", res)\n    # d.addPairwiseBilateral(2, 2, img, 3)\n'"
fullcrf/__init__.py,0,b''
fullcrf/fullcrf.py,9,"b'""""""\nThe MIT License (MIT)\n\nCopyright (c) 2017 Marvin Teichmann\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nimport numpy as np\nimport scipy as scp\nimport math\n\nimport logging\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\n\nfrom pydensecrf.utils import unary_from_labels, create_pairwise_bilateral\nfrom pydensecrf.utils import create_pairwise_gaussian\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as nnfun\nfrom torch.autograd import Variable\nfrom torch.nn.parameter import Parameter\n\nimport gc\n\nfrom pydensecrf import densecrf as dcrf\nfrom pydensecrf import utils\n\n\ndefault_conf = {\n    \'blur\': 4,\n    \'merge\': False,\n    \'norm\': \'none\',\n    \'trainable\': False,\n    \'weight\': \'scalar\',\n    \'weight_init\': 0.2,\n    \'convcomp\': False,\n\n    \'pos_feats\': {\n        \'sdims\': 3,\n        \'compat\': 3,\n    },\n    \'col_feats\': {\n        \'sdims\': 80,\n        \'schan\': 13,\n        \'compat\': 10,\n        \'use_bias\': False\n    },\n    ""trainable_bias"": False,\n}\n\n\ntest_config = {\n    \'filter_size\': 5,\n    \'blur\': 1,\n    \'merge\': False,\n    \'norm\': \'sym\',\n    \'trainable\': False,\n    \'weight\': None,\n    \'weight_init\': 5,\n    \'convcomp\': False,\n\n    \'pos_feats\': {\n        \'sdims\': 3,\n        \'compat\': 3,\n    },\n\n    \'col_feats\': {\n        \'sdims\': 80,\n        \'schan\': 13,\n        \'compat\': 10,\n        \'use_bias\': True\n    },\n    ""trainable_bias"": False,\n}\n\n\nclass FullCRF():\n    """""" Implements FullCRF with hand-crafted features.\n\n    This class uses pydensecrf to implement the CRF model proposed by:\n    Philipp Kraehenbuehl and Vladlen Koltun, ""Efficient Inference in Fully\n    ""Connected CRFs with Gaussian Edge Pots"" (arxiv.org/abs/1210.5644)\n    """"""\n\n    def __init__(self, conf, shape, num_classes=None):\n        self.crf = None\n        self.conf = conf\n        self.num_classes = num_classes\n        self.shape = shape\n\n    def compute_lattice(self, img, num_classes=None):\n        """"""\n        Compute indices for the lattice approximation.\n\n         Arguments:\n            img: np.array with shape [height, width, 3]\n                The input image. Default config assumes image\n                data in [0, 255]. For normalized images adapt\n                `schan`. Try schan = 0.1 for images in [-0.5, 0.5]\n        """"""\n\n        if num_classes is not None:\n            self.num_classes = num_classes\n\n        assert self.num_classes is not None\n\n        npixels = self.shape[0] * self.shape[1]\n        crf = dcrf.DenseCRF(npixels, self.num_classes)\n\n        sdims = self.conf[\'pos_feats\'][\'sdims\']\n\n        feats = utils.create_pairwise_gaussian(\n            sdims=(sdims, sdims),\n            shape=img.shape[:2])\n\n        self.smooth_feats = feats\n\n        self.crf = crf\n\n        self.crf.addPairwiseEnergy(\n            self.smooth_feats, compat=self.conf[\'pos_feats\'][\'compat\'])\n\n        sdims = self.conf[\'col_feats\'][\'sdims\']\n        schan = self.conf[\'col_feats\'][\'schan\']\n\n        feats = utils.create_pairwise_bilateral(sdims=(sdims, sdims),\n                                                schan=(schan, schan, schan),\n                                                img=img, chdim=2)\n\n        self.appear_feats = feats\n\n        self.crf.addPairwiseEnergy(\n            self.appear_feats, compat=self.conf[\'pos_feats\'][\'compat\'])\n\n    def compute_dcrf(self, unary):\n        """"""\n        Compute dcrf assuming compute_lattice was called.\n\n        Arguments:\n            unary: np.array with shape [height, width, num_classes]\n                The unary predictions.\n        """"""\n\n        eps = 1e-20\n        unary = unary + eps\n        unary = unary.reshape(-1, self.num_classes)\n        unary = np.transpose(unary)\n        unary = np.ascontiguousarray(unary, dtype=np.float32)\n        self.crf.setUnaryEnergy(-np.log(unary))\n\n        # Run five inference steps.\n        crfout = self.crf.inference(5)\n        crfout = np.transpose(crfout)\n        crfout = crfout.reshape(self.shape[0], self.shape[1], -1)\n\n        return crfout\n\n    def compute(self, unary, img, softmax=False):\n        """"""\n        Full forward pass on numpy arrays.\n\n        This function calls `compute_lattice` followed by compute_dcrf\n\n        Arguments:\n            unary: np.array with shape [height, width, num_classes]\n                The unary predictions.\n            img: np.array with shape [height, width, 3]\n                The input image. Default config assumes image\n                data in [0, 255]. For normalized images adapt\n                `schan`. Try schan = 0.1 for images in [-0.5, 0.5]\n\n            softmax: bool\n                Whether to apply softmax. Unaries need to be normalized.\n        """"""\n        if softmax:\n            unary = torch.nn.functional.softmax(\n                Variable(torch.Tensor(unary)), dim=2)\n            unary = unary.data.numpy()\n        self.compute_lattice(img)\n        return self.compute_dcrf(unary)\n\n    def batched_compute(self, unary, img, softmax=False):\n        """"""\n        Perform compute on batched torch.tensors.\n\n        Arguments:\n            unary: torch.Tensor with shape [bs, num_classes, height, width].\n                The unary predictions.\n\n            img: torch.Tensor with shape [bs, 3, height, width]\n                The input image. Default config assumes image\n                data in [0, 255]. For normalized images adapt\n                `schan`. Try schan = 0.1 for images in [-0.5, 0.5]\n\n            softmax: bool\n                Whether to apply softmax. Unaries need to be normalized.\n        """"""\n\n        img = img.data.cpu().numpy()\n        unary = unary.data.cpu().numpy()\n\n        img = img.transpose(0, 2, 3, 1)\n        unary = unary.transpose(0, 2, 3, 1)\n\n        results = []\n\n        for d in range(img.shape[0]):\n            img_d = img[d]\n            unary_d = unary[d]\n            res = self.compute(unary_d, img_d, softmax)\n            results.append(res)\n\n        return results\n'"
utils/__init__.py,0,b''
utils/pascal_visualizer.py,0,"b""import os\nimport collections\nfrom collections import OrderedDict\nimport json\nimport logging\nimport sys\nimport random\n\nimport numpy as np\nimport scipy as scp\nimport scipy.misc\n\ntry:\n    import matplotlib.pyplot as plt\nexcept ImportError:\n    pass\n\nfrom . import visualization as vis\n\nlogging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\nvoc_names = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n             'bottle', 'bus', 'car', 'cat',\n             'chair', 'cow', 'diningtable', 'dog',\n             'horse', 'motorbike', 'person', 'potted-plant',\n             'sheep', 'sofa', 'train', 'tv/monitor']\n\ncolor_list = [(0, 0, 0),\n              (128, 0, 0),\n              (0, 128, 0),\n              (128, 128, 0),\n              (0, 0, 128),\n              (128, 0, 128),\n              (0, 128, 128),\n              (128, 128, 128),\n              (64, 0, 0),\n              (192, 0, 0),\n              (64, 128, 0),\n              (192, 128, 0),\n              (64, 0, 128),\n              (192, 0, 128),\n              (64, 128, 128),\n              (192, 128, 128),\n              (0, 64, 0),\n              (128, 64, 0),\n              (0, 192, 0),\n              (128, 192, 0),\n              (0, 64, 128)]\n\n\nclass PascalVisualizer(vis.SegmentationVisualizer):\n\n    def __init__(self):\n        super(PascalVisualizer, self).__init__(\n            color_list=color_list, name_list=voc_names)\n\n    def plot_sample(self, sample):\n\n        image = sample['image'].transpose(1, 2, 0)\n        label = sample['label']\n        mask = label != -100\n\n        idx = eval(sample['load_dict'])['idx']\n\n        coloured_label = self.id2color(id_image=label,\n                                       mask=mask)\n\n        figure = plt.figure()\n        figure.tight_layout()\n\n        ax = figure.add_subplot(1, 2, 1)\n        ax.set_title('Image #{}'.format(idx))\n        ax.axis('off')\n        ax.imshow(image)\n\n        ax = figure.add_subplot(1, 2, 2)\n        ax.set_title('Label')\n        ax.axis('off')\n        ax.imshow(coloured_label.astype(np.uint8))\n\n        return figure\n\n    def plot_segmentation_batch(self, sample_batch, prediction):\n        figure = plt.figure()\n        figure.tight_layout()\n\n        batch_size = len(sample_batch['load_dict'])\n        figure.set_size_inches(12, 3 * batch_size)\n\n        for d in range(batch_size):\n            image = sample_batch['image'][d].numpy().transpose(1, 2, 0)\n            label = sample_batch['label'][d].numpy()\n\n            mask = label != -100\n\n            pred = prediction[d].cpu().data.numpy().transpose(1, 2, 0)\n            pred_hard = np.argmax(pred, axis=2)\n\n            idx = eval(sample_batch['load_dict'][d])['idx']\n\n            coloured_label = self.id2color(id_image=label,\n                                           mask=mask)\n\n            coloured_prediction = self.pred2color(pred_image=pred,\n                                                  mask=mask)\n\n            coloured_hard = self.id2color(id_image=pred_hard,\n                                          mask=mask)\n\n            ax = figure.add_subplot(batch_size, 4, batch_size * d + 1)\n            ax.set_title('Image #{}'.format(idx))\n            ax.axis('off')\n            ax.imshow(image)\n\n            ax = figure.add_subplot(batch_size, 4, batch_size * d + 2)\n            ax.set_title('Label')\n            ax.axis('off')\n            ax.imshow(coloured_label.astype(np.uint8))\n\n            ax = figure.add_subplot(batch_size, 4, batch_size * d + 3)\n            ax.set_title('Prediction (hard)')\n            ax.axis('off')\n            ax.imshow(coloured_hard.astype(np.uint8))\n\n            ax = figure.add_subplot(batch_size, 4, batch_size * d + 4)\n            ax.set_title('Prediction (soft)')\n            ax.axis('off')\n            ax.imshow(coloured_prediction.astype(np.uint8))\n\n        return figure\n\n    def plot_batch(self, sample_batch):\n\n        figure = plt.figure()\n        figure.tight_layout()\n\n        batch_size = len(sample_batch['load_dict'])\n\n        for d in range(batch_size):\n\n            image = sample_batch['image'][d].numpy().transpose(1, 2, 0)\n            label = sample_batch['label'][d].numpy()\n            mask = label != -100\n\n            idx = eval(sample_batch['load_dict'][d])['idx']\n\n            coloured_label = self.id2color(id_image=label,\n                                           mask=mask)\n\n            ax = figure.add_subplot(2, batch_size, d + 1)\n            ax.set_title('Image #{}'.format(idx))\n            ax.axis('off')\n            ax.imshow(image)\n\n            ax = figure.add_subplot(2, batch_size, d + batch_size + 1)\n            ax.set_title('Label')\n            ax.axis('off')\n            ax.imshow(coloured_label.astype(np.uint8))\n\n        return figure\n"""
utils/synthetic.py,0,"b'""""""\nThe MIT License (MIT)\n\nCopyright (c) 2017 Marvin Teichmann\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nimport numpy as np\nimport scipy as scp\n\nimport logging\n\nimport skimage\nimport skimage.transform\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\n\ndef np_onehot(label, num_classes):\n    return np.eye(num_classes)[label]\n\n\ndef augment_label(label, num_classes, scale=8, keep_prop=0.8):\n    """"""\n    Add noise to label for synthetic benchmark.\n    """"""\n\n    shape = label.shape\n    label = label.reshape(shape[0], shape[1])\n\n    onehot = np_onehot(label, num_classes)\n    lower_shape = (shape[0] // scale, shape[1] // scale)\n\n    label_down = skimage.transform.resize(\n        onehot, (lower_shape[0], lower_shape[1], num_classes),\n        order=1, preserve_range=True, mode=\'constant\')\n\n    onehot = skimage.transform.resize(label_down,\n                                      (shape[0], shape[1], num_classes),\n                                      order=1, preserve_range=True,\n                                      mode=\'constant\')\n\n    noise = np.random.randint(0, num_classes, lower_shape)\n\n    noise = np_onehot(noise, num_classes)\n\n    noise_up = skimage.transform.resize(noise,\n                                        (shape[0], shape[1], num_classes),\n                                        order=1, preserve_range=True,\n                                        mode=\'constant\')\n\n    mask = np.floor(keep_prop + np.random.rand(*lower_shape))\n    mask_up = skimage.transform.resize(mask, (shape[0], shape[1], 1),\n                                       order=1, preserve_range=True,\n                                       mode=\'constant\')\n\n    noised_label = mask_up * onehot + (1 - mask_up) * noise_up\n\n    return noised_label\n\n\nif __name__ == \'__main__\':\n    logging.info(""Hello World."")\n'"
utils/test_utils.py,0,"b'""""""\nThe MIT License (MIT)\n\nCopyright (c) 2017 Marvin Teichmann\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nimport numpy as np\nimport scipy as scp\n\nimport logging\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\n\nif __name__ == \'__main__\':\n    logging.info(""Hello World."")\n\n\ndef _get_simple_unary(batched=False):\n    unary1 = np.zeros((10, 10), dtype=np.float32)\n    unary1[:, [0, -1]] = unary1[[0, -1], :] = 1\n\n    unary2 = np.zeros((10, 10), dtype=np.float32)\n    unary2[4:7, 4:7] = 1\n\n    unary = np.vstack([unary1.flat, unary2.flat])\n    unary = (unary + 1) / (np.sum(unary, axis=0) + 2)\n\n    if batched:\n        unary = unary.reshape(tuple([1]) + unary)\n\n    return unary\n\n\ndef _get_simple_img(batched=False):\n\n    img = np.zeros((10, 10, 3), dtype=np.uint8)\n    img[2:8, 2:8, :] = 255\n\n    if batched:\n        img = img.reshape(tuple([1]) + img)\n\n    return img\n'"
utils/visualization.py,0,"b'""""""\nThe MIT License (MIT)\n\nCopyright (c) 2017 Marvin Teichmann\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nimport numpy as np\nimport scipy as scp\n\nimport logging\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\n\nclass SegmentationVisualizer(object):\n    """"""docstring for label_converter""""""\n    def __init__(self, color_list=None, name_list=None,\n                 mode=\'RGB\'):\n        super(SegmentationVisualizer, self).__init__()\n        self.color_list = color_list\n        self.name_list = name_list\n\n        self.mask_color = [0, 0, 0]\n\n        if mode == \'RGB\':\n            self.chan = 3\n\n    def id2color(self, id_image, mask=None, ignore_idx=-100):\n        """"""\n        Input: Int Array of shape [height, width]\n            Containing Integers 0 <= i <= num_classes.\n        """"""\n\n        if mask is None:\n            if np.any(id_image != ignore_idx):\n                mask = id_image != ignore_idx\n\n        shape = id_image.shape\n        gt_out = np.zeros([shape[0], shape[1], self.chan], dtype=np.int32)\n        id_image\n\n        for train_id, color in enumerate(self.color_list):\n            c_mask = id_image == train_id\n            c_mask = c_mask.reshape(c_mask.shape + tuple([1]))\n            gt_out = gt_out + color * c_mask\n\n        if mask is not None:\n            mask = mask.reshape(mask.shape + tuple([1]))\n            bg_color = [0, 0, 0]\n            mask2 = np.all(gt_out == bg_color, axis=2)\n            mask2 = mask2.reshape(mask2.shape + tuple([1]))\n            gt_out = gt_out + mask2 * (self.mask_color * (1 - mask))\n\n        return gt_out\n\n    def pred2color(self, pred_image, mask=None):\n\n        color_image = np.dot(pred_image, self.color_list)\n\n        if mask is not None:\n\n            if len(mask.shape) == 2:\n                mask = mask.reshape(mask.shape + tuple([1]))\n\n            color_image = mask * color_image + (1 - mask) * self.mask_color\n\n        return color_image\n\n    def color2id(self, color_gt):\n        assert(False)\n        shape = color_gt.shape\n        gt_reshaped = np.zeros([shape[0], shape[1]], dtype=np.int32)\n        mask = np.zeros([shape[0], shape[1]], dtype=np.int32)\n\n        for train_id, color in enumerate(self.color_list):\n            gt_label = np.all(color_gt == color, axis=2)\n            mask = mask + gt_label\n            gt_reshaped = gt_reshaped + 10 * train_id * gt_label\n\n        assert(np.max(mask) == 1)\n        np.unique(gt_reshaped)\n        assert(np.max(gt_reshaped) <= 200)\n\n        gt_reshaped = gt_reshaped + 255 * (1 - mask)\n        return gt_reshaped\n\n    def underlay2(self, image, gt_image, labels):\n        # TODO\n        color_img = self.id2color(gt_image)\n        color_labels = self.id2color(labels)\n\n        output = np.concatenate((image, color_img, color_labels), axis=0)\n\n        return output\n\n    def overlay(self, image, gt_image):\n        # TODO\n        color_img = self.id2color((gt_image))\n        output = 0.4 * color_img[:, :] + 0.6 * image\n\n        return output\n'"
