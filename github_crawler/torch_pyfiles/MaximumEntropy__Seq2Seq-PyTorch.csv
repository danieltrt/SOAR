file_path,api_count,code
beam_search.py,2,"b'""""""Beam search implementation in PyTorch.""""""\n#\n#\n#         hyp1#-hyp1---hyp1 -hyp1\n#                 \\             /\n#         hyp2 \\-hyp2 /-hyp2#hyp2\n#                               /      \\\n#         hyp3#-hyp3---hyp3 -hyp3\n#         ========================\n#\n# Takes care of beams, back pointers, and scores.\n\n# Code borrowed from PyTorch OpenNMT example\n# https://github.com/pytorch/examples/blob/master/OpenNMT/onmt/Beam.py\n\nimport torch\n\n\nclass Beam(object):\n    """"""Ordered beam of candidate outputs.""""""\n\n    def __init__(self, size, vocab, cuda=False):\n        """"""Initialize params.""""""\n        self.size = size\n        self.done = False\n        self.pad = vocab[\'<pad>\']\n        self.bos = vocab[\'<s>\']\n        self.eos = vocab[\'</s>\']\n        self.tt = torch.cuda if cuda else torch\n\n        # The score for each translation on the beam.\n        self.scores = self.tt.FloatTensor(size).zero_()\n\n        # The backpointers at each time-step.\n        self.prevKs = []\n\n        # The outputs at each time-step.\n        self.nextYs = [self.tt.LongTensor(size).fill_(self.pad)]\n        self.nextYs[0][0] = self.bos\n\n        # The attentions (matrix) for each time.\n        self.attn = []\n\n    # Get the outputs for the current timestep.\n    def get_current_state(self):\n        """"""Get state of beam.""""""\n        return self.nextYs[-1]\n\n    # Get the backpointers for the current timestep.\n    def get_current_origin(self):\n        """"""Get the backpointer to the beam at this step.""""""\n        return self.prevKs[-1]\n\n    #  Given prob over words for every last beam `wordLk` and attention\n    #   `attnOut`: Compute and update the beam search.\n    #\n    # Parameters:\n    #\n    #     * `wordLk`- probs of advancing from the last step (K x words)\n    #     * `attnOut`- attention at the last step\n    #\n    # Returns: True if beam search is complete.\n\n    def advance(self, workd_lk):\n        """"""Advance the beam.""""""\n        num_words = workd_lk.size(1)\n\n        # Sum the previous scores.\n        if len(self.prevKs) > 0:\n            beam_lk = workd_lk + self.scores.unsqueeze(1).expand_as(workd_lk)\n        else:\n            beam_lk = workd_lk[0]\n\n        flat_beam_lk = beam_lk.view(-1)\n\n        bestScores, bestScoresId = flat_beam_lk.topk(self.size, 0, True, True)\n        self.scores = bestScores\n\n        # bestScoresId is flattened beam x word array, so calculate which\n        # word and beam each score came from\n        prev_k = bestScoresId / num_words\n        self.prevKs.append(prev_k)\n        self.nextYs.append(bestScoresId - prev_k * num_words)\n\n        # End condition is when top-of-beam is EOS.\n        if self.nextYs[-1][0] == self.eos:\n            self.done = True\n\n        return self.done\n\n    def sort_best(self):\n        """"""Sort the beam.""""""\n        return torch.sort(self.scores, 0, True)\n\n    # Get the score of the best in the beam.\n    def get_best(self):\n        """"""Get the most likely candidate.""""""\n        scores, ids = self.sort_best()\n        return scores[1], ids[1]\n\n    # Walk back to construct the full hypothesis.\n    #\n    # Parameters.\n    #\n    #     * `k` - the position in the beam to construct.\n    #\n    # Returns.\n    #\n    #     1. The hypothesis\n    #     2. The attention at each time step.\n    def get_hyp(self, k):\n        """"""Get hypotheses.""""""\n        hyp = []\n        # print(len(self.prevKs), len(self.nextYs), len(self.attn))\n        for j in range(len(self.prevKs) - 1, -1, -1):\n            hyp.append(self.nextYs[j + 1][k])\n            k = self.prevKs[j][k]\n\n        return hyp[::-1]\n'"
data_utils.py,7,"b'""""""Data utilities.""""""\nimport torch\nfrom torch.autograd import Variable\nimport operator\nimport json\n\n\ndef hyperparam_string(config):\n    """"""Hyerparam string.""""""\n    exp_name = \'\'\n    exp_name += \'model_%s__\' % (config[\'data\'][\'task\'])\n    exp_name += \'src_%s__\' % (config[\'model\'][\'src_lang\'])\n    exp_name += \'trg_%s__\' % (config[\'model\'][\'trg_lang\'])\n    exp_name += \'attention_%s__\' % (config[\'model\'][\'seq2seq\'])\n    exp_name += \'dim_%s__\' % (config[\'model\'][\'dim\'])\n    exp_name += \'emb_dim_%s__\' % (config[\'model\'][\'dim_word_src\'])\n    exp_name += \'optimizer_%s__\' % (config[\'training\'][\'optimizer\'])\n    exp_name += \'n_layers_src_%d__\' % (config[\'model\'][\'n_layers_src\'])\n    exp_name += \'n_layers_trg_%d__\' % (1)\n    exp_name += \'bidir_%s\' % (config[\'model\'][\'bidirectional\'])\n\n    return exp_name\n\n\ndef read_config(file_path):\n    """"""Read JSON config.""""""\n    json_object = json.load(open(file_path, \'r\'))\n    return json_object\n\n\ndef construct_vocab(lines, vocab_size):\n    """"""Construct a vocabulary from tokenized lines.""""""\n    vocab = {}\n    for line in lines:\n        for word in line:\n            if word not in vocab:\n                vocab[word] = 1\n            else:\n                vocab[word] += 1\n\n    # Discard start, end, pad and unk tokens if already present\n    if \'<s>\' in vocab:\n        del vocab[\'<s>\']\n    if \'<pad>\' in vocab:\n        del vocab[\'<pad>\']\n    if \'</s>\' in vocab:\n        del vocab[\'</s>\']\n    if \'<unk>\' in vocab:\n        del vocab[\'<unk>\']\n\n    word2id = {\n        \'<s>\': 0,\n        \'<pad>\': 1,\n        \'</s>\': 2,\n        \'<unk>\': 3,\n    }\n\n    id2word = {\n        0: \'<s>\',\n        1: \'<pad>\',\n        2: \'</s>\',\n        3: \'<unk>\',\n    }\n\n    sorted_word2id = sorted(\n        vocab.items(),\n        key=operator.itemgetter(1),\n        reverse=True\n    )\n\n    sorted_words = [x[0] for x in sorted_word2id[:vocab_size]]\n\n    for ind, word in enumerate(sorted_words):\n        word2id[word] = ind + 4\n\n    for ind, word in enumerate(sorted_words):\n        id2word[ind + 4] = word\n\n    return word2id, id2word\n\n\ndef read_dialog_summarization_data(src, config, trg):\n    """"""Read data from files.""""""\n    print \'Reading source data ...\'\n    src_lines = []\n    with open(src, \'r\') as f:\n        for ind, line in enumerate(f):\n            src_lines.append(line.strip().split())\n\n    print \'Reading target data ...\'\n    trg_lines = []\n    with open(trg, \'r\') as f:\n        for line in f:\n            trg_lines.append(line.strip().split())\n\n    print \'Constructing common vocabulary ...\'\n    word2id, id2word = construct_vocab(\n        src_lines + trg_lines, config[\'data\'][\'n_words_src\']\n    )\n\n    src = {\'data\': src_lines, \'word2id\': word2id, \'id2word\': id2word}\n    trg = {\'data\': trg_lines, \'word2id\': word2id, \'id2word\': id2word}\n\n    return src, trg\n\n\ndef read_nmt_data(src, config, trg=None):\n    """"""Read data from files.""""""\n    print \'Reading source data ...\'\n    src_lines = []\n    with open(src, \'r\') as f:\n        for ind, line in enumerate(f):\n            src_lines.append(line.strip().split())\n\n    print \'Constructing source vocabulary ...\'\n    src_word2id, src_id2word = construct_vocab(\n        src_lines, config[\'data\'][\'n_words_src\']\n    )\n\n    src = {\'data\': src_lines, \'word2id\': src_word2id, \'id2word\': src_id2word}\n    del src_lines\n\n    if trg is not None:\n        print \'Reading target data ...\'\n        trg_lines = []\n        with open(trg, \'r\') as f:\n            for line in f:\n                trg_lines.append(line.strip().split())\n\n        print \'Constructing target vocabulary ...\'\n        trg_word2id, trg_id2word = construct_vocab(\n            trg_lines, config[\'data\'][\'n_words_trg\']\n        )\n\n        trg = {\'data\': trg_lines, \'word2id\': trg_word2id, \'id2word\': trg_id2word}\n    else:\n        trg = None\n\n    return src, trg\n\n\ndef read_summarization_data(src, trg):\n    """"""Read data from files.""""""\n    src_lines = [line.strip().split() for line in open(src, \'r\')]\n    trg_lines = [line.strip().split() for line in open(trg, \'r\')]\n    word2id, id2word = construct_vocab(src_lines + trg_lines, 30000)\n    src = {\'data\': src_lines, \'word2id\': word2id, \'id2word\': id2word}\n    trg = {\'data\': trg_lines, \'word2id\': word2id, \'id2word\': id2word}\n\n    return src, trg\n\n\ndef get_minibatch(\n    lines, word2ind, index, batch_size,\n    max_len, add_start=True, add_end=True\n):\n    """"""Prepare minibatch.""""""\n    if add_start and add_end:\n        lines = [\n            [\'<s>\'] + line + [\'</s>\']\n            for line in lines[index:index + batch_size]\n        ]\n    elif add_start and not add_end:\n        lines = [\n            [\'<s>\'] + line\n            for line in lines[index:index + batch_size]\n        ]\n    elif not add_start and add_end:\n        lines = [\n            line + [\'</s>\']\n            for line in lines[index:index + batch_size]\n        ]\n    elif not add_start and not add_end:\n        lines = [\n            line\n            for line in lines[index:index + batch_size]\n        ]\n    lines = [line[:max_len] for line in lines]\n\n    lens = [len(line) for line in lines]\n    max_len = max(lens)\n\n    input_lines = [\n        [word2ind[w] if w in word2ind else word2ind[\'<unk>\'] for w in line[:-1]] +\n        [word2ind[\'<pad>\']] * (max_len - len(line))\n        for line in lines\n    ]\n\n    output_lines = [\n        [word2ind[w] if w in word2ind else word2ind[\'<unk>\'] for w in line[1:]] +\n        [word2ind[\'<pad>\']] * (max_len - len(line))\n        for line in lines\n    ]\n\n    mask = [\n        ([1] * (l - 1)) + ([0] * (max_len - l))\n        for l in lens\n    ]\n\n    input_lines = Variable(torch.LongTensor(input_lines)).cuda()\n    output_lines = Variable(torch.LongTensor(output_lines)).cuda()\n    mask = Variable(torch.FloatTensor(mask)).cuda()\n\n    return input_lines, output_lines, lens, mask\n\n\ndef get_autoencode_minibatch(\n    lines, word2ind, index, batch_size,\n    max_len, add_start=True, add_end=True\n):\n    """"""Prepare minibatch.""""""\n    if add_start and add_end:\n        lines = [\n            [\'<s>\'] + line + [\'</s>\']\n            for line in lines[index:index + batch_size]\n        ]\n    elif add_start and not add_end:\n        lines = [\n            [\'<s>\'] + line\n            for line in lines[index:index + batch_size]\n        ]\n    elif not add_start and add_end:\n        lines = [\n            line + [\'</s>\']\n            for line in lines[index:index + batch_size]\n        ]\n    elif not add_start and not add_end:\n        lines = [\n            line\n            for line in lines[index:index + batch_size]\n        ]\n    lines = [line[:max_len] for line in lines]\n\n    lens = [len(line) for line in lines]\n    max_len = max(lens)\n\n    input_lines = [\n        [word2ind[w] if w in word2ind else word2ind[\'<unk>\'] for w in line[:-1]] +\n        [word2ind[\'<pad>\']] * (max_len - len(line))\n        for line in lines\n    ]\n\n    output_lines = [\n        [word2ind[w] if w in word2ind else word2ind[\'<unk>\'] for w in line[1:]] +\n        [word2ind[\'<pad>\']] * (max_len - len(line))\n        for line in lines\n    ]\n\n    mask = [\n        ([1] * (l)) + ([0] * (max_len - l))\n        for l in lens\n    ]\n\n    input_lines = Variable(torch.LongTensor(input_lines)).cuda()\n    output_lines = Variable(torch.LongTensor(output_lines)).cuda()\n    mask = Variable(torch.FloatTensor(mask)).cuda()\n\n    return input_lines, output_lines, lens, mask\n'"
decode.py,12,"b'""""""Decode Seq2Seq model with beam search.""""""\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom model import Seq2Seq, Seq2SeqAttention\nfrom data_utils import read_nmt_data, get_minibatch, read_config\nfrom beam_search import Beam\nfrom evaluate import get_bleu\n\n\nclass BeamSearchDecoder(object):\n    """"""Beam Search decoder.""""""\n\n    def __init__(\n        self,\n        config,\n        model_weights,\n        src,\n        trg,\n        beam_size=1\n    ):\n        """"""Initialize model.""""""\n        self.config = config\n        self.model_weights = model_weights\n        self.beam_size = beam_size\n\n        self.src = src\n        self.trg = trg\n        self.src_dict = src[\'word2id\']\n        self.tgt_dict = trg[\'word2id\']\n        self._load_model()\n\n    def _load_model(self):\n        print \'Loading pretrained model\'\n        if self.config[\'model\'][\'seq2seq\'] == \'vanilla\':\n            print \'Loading Seq2Seq Vanilla model\'\n\n            self.model = Seq2Seq(\n                src_emb_dim=self.config[\'model\'][\'dim_word_src\'],\n                trg_emb_dim=self.config[\'model\'][\'dim_word_trg\'],\n                src_vocab_size=len(self.src_dict),\n                trg_vocab_size=len(self.tgt_dict),\n                src_hidden_dim=self.config[\'model\'][\'dim\'],\n                trg_hidden_dim=self.config[\'model\'][\'dim\'],\n                batch_size=self.config[\'data\'][\'batch_size\'],\n                bidirectional=self.config[\'model\'][\'bidirectional\'],\n                pad_token_src=self.src_dict[\'<pad>\'],\n                pad_token_trg=self.tgt_dict[\'<pad>\'],\n                nlayers=self.config[\'model\'][\'n_layers_src\'],\n                nlayers_trg=self.config[\'model\'][\'n_layers_trg\'],\n                dropout=0.,\n            ).cuda()\n\n        elif self.config[\'model\'][\'seq2seq\'] == \'attention\':\n            print \'Loading Seq2Seq Attention model\'\n\n            self.model = Seq2SeqAttention(\n                src_emb_dim=self.config[\'model\'][\'dim_word_src\'],\n                trg_emb_dim=self.config[\'model\'][\'dim_word_trg\'],\n                src_vocab_size=len(self.src_dict),\n                trg_vocab_size=len(self.tgt_dict),\n                src_hidden_dim=self.config[\'model\'][\'dim\'],\n                trg_hidden_dim=self.config[\'model\'][\'dim\'],\n                ctx_hidden_dim=self.config[\'model\'][\'dim\'],\n                attention_mode=\'dot\',\n                batch_size=self.config[\'data\'][\'batch_size\'],\n                bidirectional=self.config[\'model\'][\'bidirectional\'],\n                pad_token_src=self.src_dict[\'<pad>\'],\n                pad_token_trg=self.tgt_dict[\'<pad>\'],\n                nlayers=self.config[\'model\'][\'n_layers_src\'],\n                nlayers_trg=self.config[\'model\'][\'n_layers_trg\'],\n                dropout=0.,\n            ).cuda()\n\n        self.model.load_state_dict(torch.load(\n            open(self.model_weights)\n        ))\n\n    def get_hidden_representation(self, input):\n        """"""Get hidden representation for a sentence.""""""\n        src_emb = self.model.src_embedding(input)\n        h0_encoder, c0_encoder = self.model.get_state(src_emb)\n        src_h, (src_h_t, src_c_t) = self.model.encoder(\n            src_emb, (h0_encoder, c0_encoder)\n        )\n\n        if self.model.bidirectional:\n            h_t = torch.cat((src_h_t[-1], src_h_t[-2]), 1)\n            c_t = torch.cat((src_c_t[-1], src_c_t[-2]), 1)\n        else:\n            h_t = src_h_t[-1]\n            c_t = src_c_t[-1]\n\n        return src_h, (h_t, c_t)\n\n    def get_init_state_decoder(self, input):\n        """"""Get init state for decoder.""""""\n        decoder_init_state = nn.Tanh()(self.model.encoder2decoder(input))\n        return decoder_init_state\n\n    def decode_batch(self, idx):\n        """"""Decode a minibatch.""""""\n        # Get source minibatch\n        input_lines_src, output_lines_src, lens_src, mask_src = get_minibatch(\n            self.src[\'data\'], self.src_dict, idx,\n            self.config[\'data\'][\'batch_size\'],\n            self.config[\'data\'][\'max_src_length\'], add_start=True, add_end=True\n        )\n\n        beam_size = self.beam_size\n\n        #  (1) run the encoder on the src\n\n        context_h, (context_h_t, context_c_t) = self.get_hidden_representation(\n            input_lines_src\n        )\n\n        context_h = context_h.transpose(0, 1)  # Make things sequence first.\n\n        #  (3) run the decoder to generate sentences, using beam search\n\n        batch_size = context_h.size(1)\n\n        # Expand tensors for each beam.\n        context = Variable(context_h.data.repeat(1, beam_size, 1))\n        dec_states = [\n            Variable(context_h_t.data.repeat(1, beam_size, 1)),\n            Variable(context_c_t.data.repeat(1, beam_size, 1))\n        ]\n\n        beam = [\n            Beam(beam_size, self.tgt_dict, cuda=True)\n            for k in range(batch_size)\n        ]\n\n        dec_out = self.get_init_state_decoder(dec_states[0].squeeze(0))\n        dec_states[0] = dec_out\n\n        batch_idx = list(range(batch_size))\n        remaining_sents = batch_size\n\n        for i in range(self.config[\'data\'][\'max_trg_length\']):\n\n            input = torch.stack(\n                [b.get_current_state() for b in beam if not b.done]\n            ).t().contiguous().view(1, -1)\n\n            trg_emb = self.model.trg_embedding(Variable(input).transpose(1, 0))\n            trg_h, (trg_h_t, trg_c_t) = self.model.decoder(\n                trg_emb,\n                (dec_states[0].squeeze(0), dec_states[1].squeeze(0)),\n                context\n            )\n\n            dec_states = (trg_h_t.unsqueeze(0), trg_c_t.unsqueeze(0))\n\n            dec_out = trg_h_t.squeeze(1)\n            out = F.softmax(self.model.decoder2vocab(dec_out)).unsqueeze(0)\n\n            word_lk = out.view(\n                beam_size,\n                remaining_sents,\n                -1\n            ).transpose(0, 1).contiguous()\n\n            active = []\n            for b in range(batch_size):\n                if beam[b].done:\n                    continue\n\n                idx = batch_idx[b]\n                if not beam[b].advance(word_lk.data[idx]):\n                    active += [b]\n\n                for dec_state in dec_states:  # iterate over h, c\n                    # layers x beam*sent x dim\n                    sent_states = dec_state.view(\n                        -1, beam_size, remaining_sents, dec_state.size(2)\n                    )[:, :, idx]\n                    sent_states.data.copy_(\n                        sent_states.data.index_select(\n                            1,\n                            beam[b].get_current_origin()\n                        )\n                    )\n\n            if not active:\n                break\n\n            # in this section, the sentences that are still active are\n            # compacted so that the decoder is not run on completed sentences\n            active_idx = torch.cuda.LongTensor([batch_idx[k] for k in active])\n            batch_idx = {beam: idx for idx, beam in enumerate(active)}\n\n            def update_active(t):\n                # select only the remaining active sentences\n                view = t.data.view(\n                    -1, remaining_sents,\n                    self.model.decoder.hidden_size\n                )\n                new_size = list(t.size())\n                new_size[-2] = new_size[-2] * len(active_idx) \\\n                    // remaining_sents\n                return Variable(view.index_select(\n                    1, active_idx\n                ).view(*new_size))\n\n            dec_states = (\n                update_active(dec_states[0]),\n                update_active(dec_states[1])\n            )\n            dec_out = update_active(dec_out)\n            context = update_active(context)\n\n            remaining_sents = len(active)\n\n        #  (4) package everything up\n\n        allHyp, allScores = [], []\n        n_best = 1\n\n        for b in range(batch_size):\n            scores, ks = beam[b].sort_best()\n\n            allScores += [scores[:n_best]]\n            hyps = zip(*[beam[b].get_hyp(k) for k in ks[:n_best]])\n            allHyp += [hyps]\n\n        return allHyp, allScores\n\n    def translate(self):\n        """"""Translate the whole dataset.""""""\n        trg_preds = []\n        trg_gold = []\n        for j in xrange(\n            0, len(self.src[\'data\']),\n            self.config[\'data\'][\'batch_size\']\n        ):\n            """"""Decode a single minibatch.""""""\n            print \'Decoding %d out of %d \' % (j, len(self.src[\'data\']))\n            hypotheses, scores = decoder.decode_batch(j)\n            all_hyp_inds = [[x[0] for x in hyp] for hyp in hypotheses]\n            all_preds = [\n                \' \'.join([trg[\'id2word\'][x] for x in hyp])\n                for hyp in all_hyp_inds\n            ]\n\n            # Get target minibatch\n            input_lines_trg_gold, output_lines_trg_gold, lens_src, mask_src = (\n                get_minibatch(\n                    self.trg[\'data\'], self.tgt_dict, j,\n                    self.config[\'data\'][\'batch_size\'],\n                    self.config[\'data\'][\'max_trg_length\'],\n                    add_start=True, add_end=True\n                )\n            )\n\n            output_lines_trg_gold = output_lines_trg_gold.data.cpu().numpy()\n            all_gold_inds = [[x for x in hyp] for hyp in output_lines_trg_gold]\n            all_gold = [\n                \' \'.join([trg[\'id2word\'][x] for x in hyp])\n                for hyp in all_gold_inds\n            ]\n\n            trg_preds += all_preds\n            trg_gold += all_gold\n\n        bleu_score = get_bleu(trg_preds, trg_gold)\n\n        print \'BLEU : %.5f \' % (bleu_score)\n\n\nclass GreedyDecoder(object):\n    """"""Beam Search decoder.""""""\n\n    def __init__(\n        self,\n        config,\n        model_weights,\n        src,\n        trg,\n        beam_size=1\n    ):\n        """"""Initialize model.""""""\n        self.config = config\n        self.model_weights = model_weights\n        self.beam_size = beam_size\n\n        self.src = src\n        self.trg = trg\n        self.src_dict = src[\'word2id\']\n        self.tgt_dict = trg[\'word2id\']\n        self._load_model()\n\n    def _load_model(self):\n        print \'Loading pretrained model\'\n        if self.config[\'model\'][\'seq2seq\'] == \'vanilla\':\n            print \'Loading Seq2Seq Vanilla model\'\n\n            self.model = Seq2Seq(\n                src_emb_dim=self.config[\'model\'][\'dim_word_src\'],\n                trg_emb_dim=self.config[\'model\'][\'dim_word_trg\'],\n                src_vocab_size=len(self.src_dict),\n                trg_vocab_size=len(self.tgt_dict),\n                src_hidden_dim=self.config[\'model\'][\'dim\'],\n                trg_hidden_dim=self.config[\'model\'][\'dim\'],\n                batch_size=self.config[\'data\'][\'batch_size\'],\n                bidirectional=self.config[\'model\'][\'bidirectional\'],\n                pad_token_src=self.src_dict[\'<pad>\'],\n                pad_token_trg=self.tgt_dict[\'<pad>\'],\n                nlayers=self.config[\'model\'][\'n_layers_src\'],\n                nlayers_trg=self.config[\'model\'][\'n_layers_trg\'],\n                dropout=0.,\n            ).cuda()\n\n        elif self.config[\'model\'][\'seq2seq\'] == \'attention\':\n            print \'Loading Seq2Seq Attention model\'\n\n            self.model = Seq2SeqAttention(\n                src_emb_dim=self.config[\'model\'][\'dim_word_src\'],\n                trg_emb_dim=self.config[\'model\'][\'dim_word_trg\'],\n                src_vocab_size=len(self.src_dict),\n                trg_vocab_size=len(self.tgt_dict),\n                src_hidden_dim=self.config[\'model\'][\'dim\'],\n                trg_hidden_dim=self.config[\'model\'][\'dim\'],\n                ctx_hidden_dim=self.config[\'model\'][\'dim\'],\n                attention_mode=\'dot\',\n                batch_size=self.config[\'data\'][\'batch_size\'],\n                bidirectional=self.config[\'model\'][\'bidirectional\'],\n                pad_token_src=self.src_dict[\'<pad>\'],\n                pad_token_trg=self.tgt_dict[\'<pad>\'],\n                nlayers=self.config[\'model\'][\'n_layers_src\'],\n                nlayers_trg=self.config[\'model\'][\'n_layers_trg\'],\n                dropout=0.,\n            ).cuda()\n\n        self.model.load_state_dict(torch.load(\n            open(self.model_weights)\n        ))\n\n    def decode_minibatch(\n        self,\n        input_lines_src,\n        input_lines_trg,\n        output_lines_trg_gold\n    ):\n        """"""Decode a minibatch.""""""\n        for i in xrange(self.config[\'data\'][\'max_trg_length\']):\n\n            decoder_logit = self.model(input_lines_src, input_lines_trg)\n            word_probs = self.model.decode(decoder_logit)\n            decoder_argmax = word_probs.data.cpu().numpy().argmax(axis=-1)\n            next_preds = Variable(\n                torch.from_numpy(decoder_argmax[:, -1])\n            ).cuda()\n\n            input_lines_trg = torch.cat(\n                (input_lines_trg, next_preds.unsqueeze(1)),\n                1\n            )\n\n        return input_lines_trg\n\n    def translate(self):\n        """"""Evaluate model.""""""\n        preds = []\n        ground_truths = []\n        for j in xrange(\n            0, len(self.src[\'data\']),\n            self.config[\'data\'][\'batch_size\']\n        ):\n\n            print \'Decoding : %d out of %d \' % (j, len(self.src[\'data\']))\n            # Get source minibatch\n            input_lines_src, output_lines_src, lens_src, mask_src = (\n                get_minibatch(\n                    self.src[\'data\'], self.src[\'word2id\'], j,\n                    self.config[\'data\'][\'batch_size\'],\n                    self.config[\'data\'][\'max_src_length\'],\n                    add_start=True, add_end=True\n                )\n            )\n\n            input_lines_src = Variable(input_lines_src.data, volatile=True)\n            output_lines_src = Variable(output_lines_src.data, volatile=True)\n            mask_src = Variable(mask_src.data, volatile=True)\n\n            # Get target minibatch\n            input_lines_trg_gold, output_lines_trg_gold, lens_src, mask_src = (\n                get_minibatch(\n                    self.trg[\'data\'], self.trg[\'word2id\'], j,\n                    self.config[\'data\'][\'batch_size\'],\n                    self.config[\'data\'][\'max_trg_length\'],\n                    add_start=True, add_end=True\n                )\n            )\n\n            input_lines_trg_gold = Variable(input_lines_trg_gold.data, volatile=True)\n            output_lines_trg_gold = Variable(output_lines_trg_gold.data, volatile=True)\n            mask_src = Variable(mask_src.data, volatile=True)\n\n            # Initialize target with <s> for every sentence\n            input_lines_trg = Variable(torch.LongTensor(\n                [\n                    [trg[\'word2id\'][\'<s>\']]\n                    for i in xrange(input_lines_src.size(0))\n                ]\n            ), volatile=True).cuda()\n\n            # Decode a minibatch greedily __TODO__ add beam search decoding\n            input_lines_trg = self.decode_minibatch(\n                input_lines_src, input_lines_trg,\n                output_lines_trg_gold\n            )\n\n            # Copy minibatch outputs to cpu and convert ids to words\n            input_lines_trg = input_lines_trg.data.cpu().numpy()\n            input_lines_trg = [\n                [self.trg[\'id2word\'][x] for x in line]\n                for line in input_lines_trg\n            ]\n\n            # Do the same for gold sentences\n            output_lines_trg_gold = output_lines_trg_gold.data.cpu().numpy()\n            output_lines_trg_gold = [\n                [self.trg[\'id2word\'][x] for x in line]\n                for line in output_lines_trg_gold\n            ]\n\n            # Process outputs\n            for sentence_pred, sentence_real, sentence_real_src in zip(\n                input_lines_trg,\n                output_lines_trg_gold,\n                output_lines_src\n            ):\n                if \'</s>\' in sentence_pred:\n                    index = sentence_pred.index(\'</s>\')\n                else:\n                    index = len(sentence_pred)\n                preds.append([\'<s>\'] + sentence_pred[:index + 1])\n\n                if \'</s>\' in sentence_real:\n                    index = sentence_real.index(\'</s>\')\n                else:\n                    index = len(sentence_real)\n\n                ground_truths.append([\'<s>\'] + sentence_real[:index + 1])\n\n        bleu_score = get_bleu(preds, ground_truths)\n        print \'BLEU score : %.5f \' % (bleu_score)\n\nif __name__ == \'__main__\':\n\n    model_config = \'/home/sandeep/Research/nmt-pytorch/config_local_en_de_attention_wmt15.json\'\n    model_weights = \'/home/sandeep/Models/torch_seq2seq/model_translation__src_en__trg_de__attention_attention__dim_1024__emb_dim_500__optimizer_adam__n_layers_src_2__n_layers_trg_1__bidir_True__epoch_6.model\'\n\n    config = read_config(model_config)\n\n    src, trg = read_nmt_data(\n        src=config[\'data\'][\'src\'],\n        config=config,\n        trg=config[\'data\'][\'trg\']\n    )\n\n    src_test, trg_test = read_nmt_data(\n        src=config[\'data\'][\'test_src\'],\n        config=config,\n        trg=config[\'data\'][\'test_trg\']\n    )\n\n    src_test[\'word2id\'] = src[\'word2id\']\n    src_test[\'id2word\'] = src[\'id2word\']\n\n    trg_test[\'word2id\'] = trg[\'word2id\']\n    trg_test[\'id2word\'] = trg[\'id2word\']\n\n    # decoder = BeamSearchDecoder(config, model_weights, src_test, trg_test)\n    # decoder.translate()\n\n    decoder = GreedyDecoder(config, model_weights, src_test, trg_test)\n    decoder.translate()\n    \'\'\'\n    allHyp, allScores = decoder.decode_batch(0)\n    all_hyp_inds = [[x[0] for x in hyp] for hyp in allHyp]\n    all_preds = [\' \'.join([trg[\'id2word\'][x] for x in hyp]) for hyp in all_hyp_inds]\n\n    input_lines_trg_gold, output_lines_trg_gold, lens_src, mask_src = (\n        get_minibatch(\n            trg[\'data\'], trg[\'word2id\'], 0,\n            80,\n            50,\n            add_start=True, add_end=True\n        )\n    )\n\n    output_lines_trg_gold = output_lines_trg_gold.data.cpu().numpy()\n    all_gold_inds = [[x for x in hyp] for hyp in output_lines_trg_gold]\n    all_gold = [\' \'.join([trg[\'id2word\'][x] for x in hyp]) for hyp in all_gold_inds]\n\n    for hyp, gt in zip(all_preds, all_gold):\n        print hyp, len(hyp.split())\n        print \'-------------------------------------------------\'\n        print gt\n        print \'=================================================\'\n    \'\'\'\n'"
dialog.py,8,"b'#!/u/subramas/miniconda2/bin/python\n""""""Main script to run things""""""\nimport sys\n\nsys.path.append(\'/u/subramas/Research/nmt-pytorch/\')\n\nfrom data_utils import read_nmt_data, get_minibatch, read_config, \\\n    hyperparam_string, read_summarization_data, read_dialog_summarization_data\nfrom model import Seq2Seq, Seq2SeqAttention, Seq2SeqFastAttention, Seq2SeqAttentionSharedEmbedding\nfrom evaluate import evaluate_model, model_perplexity\nimport math\nimport numpy as np\nimport logging\nimport argparse\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\n    ""--config"",\n    help=""path to json config"",\n    required=True\n)\nargs = parser.parse_args()\nconfig_file_path = args.config\nconfig = read_config(config_file_path)\nexperiment_name = hyperparam_string(config)\nsave_dir = config[\'data\'][\'save_dir\']\nload_dir = config[\'data\'][\'load_dir\']\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\'%(asctime)s - %(levelname)s - %(message)s\',\n    filename=\'log/%s\' % (experiment_name),\n    filemode=\'w\'\n)\n\n# define a new Handler to log to console as well\nconsole = logging.StreamHandler()\n# optional, set the logging level\nconsole.setLevel(logging.INFO)\n# set a format which is the same for console use\nformatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\n# tell the handler to use this format\nconsole.setFormatter(formatter)\n# add the handler to the root logger\nlogging.getLogger(\'\').addHandler(console)\n\n\nprint \'Reading data ...\'\n\nsrc, trg = read_dialog_summarization_data(\n    config[\'data\'][\'src\'],\n    config,\n    config[\'data\'][\'trg\']\n)\n\nsrc_test, trg_test = read_dialog_summarization_data(\n    config[\'data\'][\'test_src\'],\n    config,\n    config[\'data\'][\'test_trg\']\n)\n\nbatch_size = config[\'data\'][\'batch_size\']\nmax_length_src = config[\'data\'][\'max_src_length\']\nmax_length_trg = config[\'data\'][\'max_trg_length\']\nvocab_size = len(src[\'word2id\'])\n\nlogging.info(\'Model Parameters : \')\nlogging.info(\'Task : %s \' % (config[\'data\'][\'task\']))\nlogging.info(\'Model : %s \' % (config[\'model\'][\'seq2seq\']))\nlogging.info(\'Language : %s \' % (config[\'model\'][\'src_lang\']))\nlogging.info(\'Embedding Dim  : %s\' % (config[\'model\'][\'dim_word_src\']))\nlogging.info(\'Source RNN Hidden Dim  : %s\' % (config[\'model\'][\'dim\']))\nlogging.info(\'Target RNN Hidden Dim  : %s\' % (config[\'model\'][\'dim\']))\nlogging.info(\'Source RNN Depth : %d \' % (config[\'model\'][\'n_layers_src\']))\nlogging.info(\'Target RNN Depth : %d \' % (2))\nlogging.info(\'Source RNN Bidirectional  : %s\' % (config[\'model\'][\'bidirectional\']))\nlogging.info(\'Batch Size : %d \' % (config[\'data\'][\'batch_size\']))\nlogging.info(\'Optimizer : %s \' % (config[\'training\'][\'optimizer\']))\nlogging.info(\'Learning Rate : %f \' % (config[\'training\'][\'lrate\']))\n\nlogging.info(\'Found %d words \' % (vocab_size))\n\nweight_mask = torch.ones(vocab_size).cuda()\nweight_mask[trg[\'word2id\'][\'<pad>\']] = 0\nloss_criterion = nn.CrossEntropyLoss(weight=weight_mask).cuda()\n\nmodel = Seq2SeqAttentionSharedEmbedding(\n    emb_dim=config[\'model\'][\'dim_word_src\'],\n    vocab_size=vocab_size,\n    src_hidden_dim=config[\'model\'][\'dim\'],\n    trg_hidden_dim=config[\'model\'][\'dim\'],\n    ctx_hidden_dim=config[\'model\'][\'dim\'],\n    attention_mode=\'dot\',\n    batch_size=batch_size,\n    bidirectional=config[\'model\'][\'bidirectional\'],\n    pad_token_src=src[\'word2id\'][\'<pad>\'],\n    pad_token_trg=trg[\'word2id\'][\'<pad>\'],\n    nlayers=config[\'model\'][\'n_layers_src\'],\n    nlayers_trg=config[\'model\'][\'n_layers_trg\'],\n    dropout=0.,\n).cuda()\n\nif load_dir:\n    model.load_state_dict(torch.load(\n        open(load_dir)\n    ))\n\n# __TODO__ Make this more flexible for other learning methods.\nif config[\'training\'][\'optimizer\'] == \'adam\':\n    lr = config[\'training\'][\'lrate\']\n    optimizer = optim.Adam(model.parameters(), lr=lr)\nelif config[\'training\'][\'optimizer\'] == \'adadelta\':\n    optimizer = optim.Adadelta(model.parameters())\nelif config[\'training\'][\'optimizer\'] == \'sgd\':\n    lr = config[\'training\'][\'lrate\']\n    optimizer = optim.SGD(model.parameters(), lr=lr)\nelse:\n    raise NotImplementedError(""Learning method not recommend for task"")\n\nfor i in xrange(1000):\n    losses = []\n    for j in xrange(0, len(src[\'data\']), batch_size):\n\n        input_lines_src, _, lens_src, mask_src = get_minibatch(\n            src[\'data\'], src[\'word2id\'], j,\n            batch_size, max_length_src, add_start=True, add_end=False\n        )\n\n        input_lines_trg, output_lines_trg, lens_trg, mask_trg = get_minibatch(\n            trg[\'data\'], trg[\'word2id\'], j,\n            batch_size, max_length_trg, add_start=True, add_end=True\n        )\n\n        decoder_logit = model(input_lines_src, input_lines_trg)\n        optimizer.zero_grad()\n\n        loss = loss_criterion(\n            decoder_logit.contiguous().view(-1, vocab_size),\n            output_lines_trg.view(-1)\n        )\n        losses.append(loss.data[0])\n        loss.backward()\n        optimizer.step()\n\n        if j % config[\'management\'][\'monitor_loss\'] == 0:\n            logging.info(\'Epoch : %d Minibatch : %d Loss : %.5f\' % (\n                i, j, np.mean(losses))\n            )\n            losses = []\n\n        if (\n            config[\'management\'][\'print_samples\'] and\n            j % config[\'management\'][\'print_samples\'] == 0\n        ):\n            word_probs = model.decode(\n                decoder_logit\n            ).data.cpu().numpy().argmax(axis=-1)\n\n            output_lines_trg = output_lines_trg.data.cpu().numpy()\n            for sentence_pred, sentence_real in zip(\n                word_probs[:5], output_lines_trg[:5]\n            ):\n                sentence_pred = [trg[\'id2word\'][x] for x in sentence_pred]\n                sentence_real = [trg[\'id2word\'][x] for x in sentence_real]\n\n                if \'</s>\' in sentence_real:\n                    index = sentence_real.index(\'</s>\')\n                    sentence_real = sentence_real[:index]\n                    sentence_pred = sentence_pred[:index]\n\n                logging.info(\'Predicted : %s \' % (\' \'.join(sentence_pred)))\n                logging.info(\'-----------------------------------------------\')\n                logging.info(\'Real : %s \' % (\' \'.join(sentence_real)))\n                logging.info(\'===============================================\')\n\n        if j % config[\'management\'][\'checkpoint_freq\'] == 0:\n\n            logging.info(\'Computing Perplexity ... \')\n            perplexity = model_perplexity(\n                model, src, src_test, trg,\n                trg_test, config, loss_criterion,\n                verbose=False\n            )\n\n            logging.info(\'Epoch : %d : Perplexity : %.5f \' % (i, perplexity))\n\n            logging.info(\'Saving model ...\')\n\n            torch.save(\n                model.state_dict(),\n                open(os.path.join(\n                    save_dir,\n                    experiment_name + \'__epoch_%d\' % (i) + \'.model\'), \'wb\'\n                )\n            )\n\n    logging.info(\'Completed Epoch : %d \' % (i))\n    torch.save(\n        model.state_dict(),\n        open(os.path.join(\n            save_dir,\n            experiment_name + \'__epoch_%d\' % (i) + \'.model\'), \'wb\'\n        )\n    )\n\n    logging.info(\'Computing Perplexity ... \')\n    perplexity = model_perplexity(\n        model, src, src_test, trg,\n        trg_test, config, loss_criterion,\n        verbose=False\n    )\n\n    logging.info(\'Epoch : %d : Perplexity : %.5f \' % (i, perplexity))\n'"
evaluate.py,8,"b'""""""Evaluation utils.""""""\nimport sys\n\nsys.path.append(\'/u/subramas/Research/nmt-pytorch\')\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom data_utils import get_minibatch, get_autoencode_minibatch\nfrom collections import Counter\nimport math\nimport numpy as np\nimport subprocess\nimport sys\n\n\ndef bleu_stats(hypothesis, reference):\n    """"""Compute statistics for BLEU.""""""\n    stats = []\n    stats.append(len(hypothesis))\n    stats.append(len(reference))\n    for n in xrange(1, 5):\n        s_ngrams = Counter(\n            [tuple(hypothesis[i:i + n]) for i in xrange(len(hypothesis) + 1 - n)]\n        )\n        r_ngrams = Counter(\n            [tuple(reference[i:i + n]) for i in xrange(len(reference) + 1 - n)]\n        )\n        stats.append(max([sum((s_ngrams & r_ngrams).values()), 0]))\n        stats.append(max([len(hypothesis) + 1 - n, 0]))\n    return stats\n\n\ndef bleu(stats):\n    """"""Compute BLEU given n-gram statistics.""""""\n    if len(filter(lambda x: x == 0, stats)) > 0:\n        return 0\n    (c, r) = stats[:2]\n    log_bleu_prec = sum(\n        [math.log(float(x) / y) for x, y in zip(stats[2::2], stats[3::2])]\n    ) / 4.\n    return math.exp(min([0, 1 - float(r) / c]) + log_bleu_prec)\n\n\ndef get_bleu(hypotheses, reference):\n    """"""Get validation BLEU score for dev set.""""""\n    stats = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n    for hyp, ref in zip(hypotheses, reference):\n        stats += np.array(bleu_stats(hyp, ref))\n    return 100 * bleu(stats)\n\n\ndef get_bleu_moses(hypotheses, reference):\n    """"""Get BLEU score with moses bleu score.""""""\n    with open(\'tmp_hypotheses.txt\', \'w\') as f:\n        for hypothesis in hypotheses:\n            f.write(\' \'.join(hypothesis) + \'\\n\')\n\n    with open(\'tmp_reference.txt\', \'w\') as f:\n        for ref in reference:\n            f.write(\' \'.join(ref) + \'\\n\')\n\n    hypothesis_pipe = \'\\n\'.join([\' \'.join(hyp) for hyp in hypotheses])\n    pipe = subprocess.Popen(\n        [""perl"", \'multi-bleu.perl\', \'-lc\', \'tmp_reference.txt\'],\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE\n    )\n    pipe.stdin.write(hypothesis_pipe)\n    pipe.stdin.close()\n    return pipe.stdout.read()\n\n\ndef decode_minibatch(\n    config,\n    model,\n    input_lines_src,\n    input_lines_trg,\n    output_lines_trg_gold\n):\n    """"""Decode a minibatch.""""""\n    for i in xrange(config[\'data\'][\'max_trg_length\']):\n\n        decoder_logit = model(input_lines_src, input_lines_trg)\n        word_probs = model.decode(decoder_logit)\n        decoder_argmax = word_probs.data.cpu().numpy().argmax(axis=-1)\n        next_preds = Variable(\n            torch.from_numpy(decoder_argmax[:, -1])\n        ).cuda()\n\n        input_lines_trg = torch.cat(\n            (input_lines_trg, next_preds.unsqueeze(1)),\n            1\n        )\n\n    return input_lines_trg\n\n\ndef model_perplexity(\n    model, src, src_test, trg,\n    trg_test, config, loss_criterion,\n    src_valid=None, trg_valid=None, verbose=False,\n):\n    """"""Compute model perplexity.""""""\n    # Get source minibatch\n    losses = []\n    for j in xrange(0, len(src_test[\'data\']) // 100, config[\'data\'][\'batch_size\']):\n        input_lines_src, output_lines_src, lens_src, mask_src = get_minibatch(\n            src_test[\'data\'], src[\'word2id\'], j, config[\'data\'][\'batch_size\'],\n            config[\'data\'][\'max_src_length\'], add_start=True, add_end=True\n        )\n        input_lines_src = Variable(input_lines_src.data, volatile=True)\n        output_lines_src = Variable(input_lines_src.data, volatile=True)\n        mask_src = Variable(mask_src.data, volatile=True)\n\n        # Get target minibatch\n        input_lines_trg_gold, output_lines_trg_gold, lens_src, mask_src = (\n            get_minibatch(\n                trg_test[\'data\'], trg[\'word2id\'], j,\n                config[\'data\'][\'batch_size\'], config[\'data\'][\'max_trg_length\'],\n                add_start=True, add_end=True\n            )\n        )\n        input_lines_trg_gold = Variable(input_lines_trg_gold.data, volatile=True)\n        output_lines_trg_gold = Variable(output_lines_trg_gold.data, volatile=True)\n        mask_src = Variable(mask_src.data, volatile=True)\n\n        decoder_logit = model(input_lines_src, input_lines_trg_gold)\n\n        loss = loss_criterion(\n            decoder_logit.contiguous().view(-1, decoder_logit.size(2)),\n            output_lines_trg_gold.view(-1)\n        )\n\n        losses.append(loss.data[0])\n\n    return np.exp(np.mean(losses))\n\n\ndef evaluate_model(\n    model, src, src_test, trg,\n    trg_test, config, src_valid=None, trg_valid=None,\n    verbose=True, metric=\'bleu\'\n):\n    """"""Evaluate model.""""""\n    preds = []\n    ground_truths = []\n    for j in xrange(0, len(src_test[\'data\']), config[\'data\'][\'batch_size\']):\n\n        # Get source minibatch\n        input_lines_src, output_lines_src, lens_src, mask_src = get_minibatch(\n            src_test[\'data\'], src[\'word2id\'], j, config[\'data\'][\'batch_size\'],\n            config[\'data\'][\'max_src_length\'], add_start=True, add_end=True\n        )\n\n        # Get target minibatch\n        input_lines_trg_gold, output_lines_trg_gold, lens_src, mask_src = (\n            get_minibatch(\n                trg_test[\'data\'], trg[\'word2id\'], j,\n                config[\'data\'][\'batch_size\'], config[\'data\'][\'max_trg_length\'],\n                add_start=True, add_end=True\n            )\n        )\n\n        # Initialize target with <s> for every sentence\n        input_lines_trg = Variable(torch.LongTensor(\n            [\n                [trg[\'word2id\'][\'<s>\']]\n                for i in xrange(input_lines_src.size(0))\n            ]\n        )).cuda()\n\n        # Decode a minibatch greedily __TODO__ add beam search decoding\n        input_lines_trg = decode_minibatch(\n            config, model, input_lines_src,\n            input_lines_trg, output_lines_trg_gold\n        )\n\n        # Copy minibatch outputs to cpu and convert ids to words\n        input_lines_trg = input_lines_trg.data.cpu().numpy()\n        input_lines_trg = [\n            [trg[\'id2word\'][x] for x in line]\n            for line in input_lines_trg\n        ]\n\n        # Do the same for gold sentences\n        output_lines_trg_gold = output_lines_trg_gold.data.cpu().numpy()\n        output_lines_trg_gold = [\n            [trg[\'id2word\'][x] for x in line]\n            for line in output_lines_trg_gold\n        ]\n\n        # Process outputs\n        for sentence_pred, sentence_real, sentence_real_src in zip(\n            input_lines_trg,\n            output_lines_trg_gold,\n            output_lines_src\n        ):\n            if \'</s>\' in sentence_pred:\n                index = sentence_pred.index(\'</s>\')\n            else:\n                index = len(sentence_pred)\n            preds.append([\'<s>\'] + sentence_pred[:index + 1])\n\n            if verbose:\n                print \' \'.join([\'<s>\'] + sentence_pred[:index + 1])\n\n            if \'</s>\' in sentence_real:\n                index = sentence_real.index(\'</s>\')\n            else:\n                index = len(sentence_real)\n            if verbose:\n                print \' \'.join([\'<s>\'] + sentence_real[:index + 1])\n            if verbose:\n                print \'--------------------------------------\'\n            ground_truths.append([\'<s>\'] + sentence_real[:index + 1])\n\n    return get_bleu(preds, ground_truths)\n\n\ndef evaluate_autoencode_model(\n    model, src, src_test,\n    config, src_valid=None,\n    verbose=True, metric=\'bleu\'\n):\n    """"""Evaluate model.""""""\n    preds = []\n    ground_truths = []\n    for j in xrange(0, len(src_test[\'data\']), config[\'data\'][\'batch_size\']):\n\n        print \'Decoding batch : %d out of %d \' % (j, len(src_test[\'data\']))\n        input_lines_src, lens_src, mask_src = get_autoencode_minibatch(\n            src_test[\'data\'], src[\'word2id\'], j, config[\'data\'][\'batch_size\'],\n            config[\'data\'][\'max_src_length\'], add_start=True, add_end=True\n        )\n\n        input_lines_trg = Variable(torch.LongTensor(\n            [\n                [src[\'word2id\'][\'<s>\']]\n                for i in xrange(input_lines_src.size(0))\n            ]\n        )).cuda()\n\n        for i in xrange(config[\'data\'][\'max_src_length\']):\n\n            decoder_logit = model(input_lines_src, input_lines_trg)\n            word_probs = model.decode(decoder_logit)\n            decoder_argmax = word_probs.data.cpu().numpy().argmax(axis=-1)\n            next_preds = Variable(\n                torch.from_numpy(decoder_argmax[:, -1])\n            ).cuda()\n\n            input_lines_trg = torch.cat(\n                (input_lines_trg, next_preds.unsqueeze(1)),\n                1\n            )\n\n        input_lines_trg = input_lines_trg.data.cpu().numpy()\n\n        input_lines_trg = [\n            [src[\'id2word\'][x] for x in line]\n            for line in input_lines_trg\n        ]\n\n        output_lines_trg_gold = input_lines_src.data.cpu().numpy()\n        output_lines_trg_gold = [\n            [src[\'id2word\'][x] for x in line]\n            for line in output_lines_trg_gold\n        ]\n\n        for sentence_pred, sentence_real in zip(\n            input_lines_trg,\n            output_lines_trg_gold,\n        ):\n            if \'</s>\' in sentence_pred:\n                index = sentence_pred.index(\'</s>\')\n            else:\n                index = len(sentence_pred)\n            preds.append(sentence_pred[:index + 1])\n\n            if verbose:\n                print \' \'.join(sentence_pred[:index + 1])\n\n            if \'</s>\' in sentence_real:\n                index = sentence_real.index(\'</s>\')\n            else:\n                index = len(sentence_real)\n            if verbose:\n                print \' \'.join(sentence_real[:index + 1])\n            if verbose:\n                print \'--------------------------------------\'\n            ground_truths.append(sentence_real[:index + 1])\n\n    return get_bleu(preds, ground_truths)\n'"
model.py,55,"b'""""""Sequence to Sequence models.""""""\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport math\nimport torch.nn.functional as F\nimport numpy as np\n\n\nclass StackedAttentionLSTM(nn.Module):\n    """"""Deep Attention LSTM.""""""\n\n    def __init__(\n        self,\n        input_size,\n        rnn_size,\n        num_layers,\n        batch_first=True,\n        dropout=0.\n    ):\n        """"""Initialize params.""""""\n        super(StackedAttentionLSTM, self).__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.input_size = input_size\n        self.rnn_size = rnn_size\n        self.batch_first = batch_first\n\n        self.layers = []\n        for i in range(num_layers):\n            layer = LSTMAttentionDot(\n                input_size, rnn_size, batch_first=self.batch_first\n            )\n            self.add_module(\'layer_%d\' % i, layer)\n            self.layers += [layer]\n            input_size = rnn_size\n\n    def forward(self, input, hidden, ctx, ctx_mask=None):\n        """"""Propogate input through the layer.""""""\n        h_0, c_0 = hidden\n        h_1, c_1 = [], []\n        for i, layer in enumerate(self.layers):\n            if ctx_mask is not None:\n                ctx_mask = torch.ByteTensor(\n                    ctx_mask.data.cpu().numpy().astype(np.int32).tolist()\n                ).cuda()\n            output, (h_1_i, c_1_i) = layer(input, (h_0, c_0), ctx, ctx_mask)\n\n            input = output\n\n            if i != len(self.layers):\n                input = self.dropout(input)\n\n            h_1 += [h_1_i]\n            c_1 += [c_1_i]\n\n        h_1 = torch.stack(h_1)\n        c_1 = torch.stack(c_1)\n\n        return input, (h_1, c_1)\n\n\nclass DeepBidirectionalLSTM(nn.Module):\n    r""""""A Deep LSTM with the first layer being bidirectional.""""""\n\n    def __init__(\n        self, input_size, hidden_size,\n        num_layers, dropout, batch_first\n    ):\n        """"""Initialize params.""""""\n        super(DeepBidirectionalLSTM, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.dropout = dropout\n        self.batch_first = batch_first\n        self.num_layers = num_layers\n\n        self.bi_encoder = nn.LSTM(\n            self.input_size,\n            self.hidden_size // 2,\n            1,\n            bidirectional=True,\n            batch_first=True,\n            dropout=self.dropout\n        )\n\n        self.encoder = nn.LSTM(\n            self.hidden_size,\n            self.hidden_size,\n            self.num_layers - 1,\n            bidirectional=False,\n            batch_first=True,\n            dropout=self.dropout\n        )\n\n    def get_state(self, input):\n        """"""Get cell states and hidden states.""""""\n        batch_size = input.size(0) \\\n            if self.encoder.batch_first else input.size(1)\n        h0_encoder_bi = Variable(torch.zeros(\n            2,\n            batch_size,\n            self.hidden_size // 2\n        ))\n        c0_encoder_bi = Variable(torch.zeros(\n            2,\n            batch_size,\n            self.hidden_size // 2\n        ))\n\n        h0_encoder = Variable(torch.zeros(\n            self.num_layers - 1,\n            batch_size,\n            self.hidden_size\n        ))\n\n        c0_encoder = Variable(torch.zeros(\n            self.num_layers - 1,\n            batch_size,\n            self.hidden_size\n        ))\n\n        return (h0_encoder_bi.cuda(), c0_encoder_bi.cuda()), \\\n            (h0_encoder.cuda(), c0_encoder.cuda())\n\n    def forward(self, input):\n        """"""Propogate input forward through the network.""""""\n        hidden_bi, hidden_deep = self.get_state(input)\n        bilstm_output, (_, _) = self.bi_encoder(input, hidden_bi)\n        return self.encoder(bilstm_output, hidden_deep)\n\n\nclass LSTMAttention(nn.Module):\n    r""""""A long short-term memory (LSTM) cell with attention.""""""\n\n    def __init__(self, input_size, hidden_size, context_size):\n        """"""Initialize params.""""""\n        super(LSTMAttention, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.context_size = context_size\n        self.num_layers = 1\n\n        self.input_weights_1 = nn.Parameter(\n            torch.Tensor(4 * hidden_size, input_size)\n        )\n        self.hidden_weights_1 = nn.Parameter(\n            torch.Tensor(4 * hidden_size, hidden_size)\n        )\n        self.input_bias_1 = nn.Parameter(torch.Tensor(4 * hidden_size))\n        self.hidden_bias_1 = nn.Parameter(torch.Tensor(4 * hidden_size))\n\n        self.input_weights_2 = nn.Parameter(\n            torch.Tensor(4 * hidden_size, context_size)\n        )\n        self.hidden_weights_2 = nn.Parameter(\n            torch.Tensor(4 * hidden_size, hidden_size)\n        )\n        self.input_bias_2 = nn.Parameter(torch.Tensor(4 * hidden_size))\n        self.hidden_bias_2 = nn.Parameter(torch.Tensor(4 * hidden_size))\n\n        self.context2attention = nn.Parameter(\n            torch.Tensor(context_size, context_size)\n        )\n        self.bias_context2attention = nn.Parameter(torch.Tensor(context_size))\n\n        self.hidden2attention = nn.Parameter(\n            torch.Tensor(context_size, hidden_size)\n        )\n\n        self.input2attention = nn.Parameter(\n            torch.Tensor(input_size, context_size)\n        )\n\n        self.recurrent2attention = nn.Parameter(torch.Tensor(context_size, 1))\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        """"""Reset parameters.""""""\n        stdv = 1.0 / math.sqrt(self.hidden_size)\n        stdv_ctx = 1.0 / math.sqrt(self.context_size)\n\n        self.input_weights_1.data.uniform_(-stdv, stdv)\n        self.hidden_weights_1.data.uniform_(-stdv, stdv)\n        self.input_bias_1.data.fill_(0)\n        self.hidden_bias_1.data.fill_(0)\n\n        self.input_weights_2.data.uniform_(-stdv_ctx, stdv_ctx)\n        self.hidden_weights_2.data.uniform_(-stdv, stdv)\n        self.input_bias_2.data.fill_(0)\n        self.hidden_bias_2.data.fill_(0)\n\n        self.context2attention.data.uniform_(-stdv_ctx, stdv_ctx)\n        self.bias_context2attention.data.fill_(0)\n\n        self.hidden2attention.data.uniform_(-stdv_ctx, stdv_ctx)\n        self.input2attention.data.uniform_(-stdv_ctx, stdv_ctx)\n\n        self.recurrent2attention.data.uniform_(-stdv_ctx, stdv_ctx)\n\n    def forward(self, input, hidden, ctx, ctx_mask=None):\n        """"""Propogate input through the network.""""""\n        def recurrence(input, hidden, projected_input, projected_ctx):\n            """"""Recurrence helper.""""""\n            hx, cx = hidden  # n_b x hidden_dim\n\n            gates = F.linear(\n                input, self.input_weights_1, self.input_bias_1\n            ) + F.linear(hx, self.hidden_weights_1, self.hidden_bias_1)\n            ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n\n            ingate = F.sigmoid(ingate)\n            forgetgate = F.sigmoid(forgetgate)\n            cellgate = F.tanh(cellgate)\n            outgate = F.sigmoid(outgate)\n\n            cy = (forgetgate * cx) + (ingate * cellgate)\n            hy = outgate * F.tanh(cy)  # n_b x hidden_dim\n\n            # Attention mechanism\n\n            # Project current hidden state to context size\n            hidden_ctx = F.linear(hy, self.hidden2attention)\n\n            # Added projected hidden state to each projected context\n            hidden_ctx_sum = projected_ctx + hidden_ctx.unsqueeze(0).expand(\n                projected_ctx.size()\n            )\n\n            # Add this to projected input at this time step\n            hidden_ctx_sum = hidden_ctx_sum + \\\n                projected_input.unsqueeze(0).expand(hidden_ctx_sum.size())\n\n            # Non-linearity\n            hidden_ctx_sum = F.tanh(hidden_ctx_sum)\n\n            # Compute alignments\n            alpha = torch.bmm(\n                hidden_ctx_sum.transpose(0, 1),\n                self.recurrent2attention.unsqueeze(0).expand(\n                    hidden_ctx_sum.size(1),\n                    self.recurrent2attention.size(0),\n                    self.recurrent2attention.size(1)\n                )\n            ).squeeze()\n            alpha = F.softmax(alpha)\n            weighted_context = torch.mul(\n                ctx, alpha.t().unsqueeze(2).expand(ctx.size())\n            ).sum(0).squeeze()\n\n            gates = F.linear(\n                weighted_context, self.input_weights_2, self.input_bias_2\n            ) + F.linear(hy, self.hidden_weights_2, self.hidden_bias_2)\n            ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n\n            ingate = F.sigmoid(ingate)\n            forgetgate = F.sigmoid(forgetgate)\n            cellgate = F.tanh(cellgate)\n            outgate = F.sigmoid(outgate)\n\n            cy = (forgetgate * cy) + (ingate * cellgate)\n            hy = outgate * F.tanh(cy)  # n_b x hidden_dim\n\n            return hy, cy\n\n        input = input.transpose(0, 1)\n        projected_ctx = torch.bmm(\n            ctx,\n            self.context2attention.unsqueeze(0).expand(\n                ctx.size(0),\n                self.context2attention.size(0),\n                self.context2attention.size(1)\n            ),\n        )\n        projected_ctx += \\\n            self.bias_context2attention.unsqueeze(0).unsqueeze(0).expand(\n                projected_ctx.size()\n            )\n\n        projected_input = torch.bmm(\n            input,\n            self.input2attention.unsqueeze(0).expand(\n                input.size(0),\n                self.input2attention.size(0),\n                self.input2attention.size(1)\n            ),\n        )\n\n        output = []\n        steps = range(input.size(0))\n        for i in steps:\n            hidden = recurrence(\n                input[i], hidden, projected_input[i], projected_ctx\n            )\n            output.append(isinstance(hidden, tuple) and hidden[0] or hidden)\n\n        output = torch.cat(output, 0).view(input.size(0), *output[0].size())\n\n        return output, hidden\n\n\nclass SoftDotAttention(nn.Module):\n    """"""Soft Dot Attention.\n\n    Ref: http://www.aclweb.org/anthology/D15-1166\n    Adapted from PyTorch OPEN NMT.\n    """"""\n\n    def __init__(self, dim):\n        """"""Initialize layer.""""""\n        super(SoftDotAttention, self).__init__()\n        self.linear_in = nn.Linear(dim, dim, bias=False)\n        self.sm = nn.Softmax()\n        self.linear_out = nn.Linear(dim * 2, dim, bias=False)\n        self.tanh = nn.Tanh()\n        self.mask = None\n\n    def forward(self, input, context):\n        """"""Propogate input through the network.\n\n        input: batch x dim\n        context: batch x sourceL x dim\n        """"""\n        target = self.linear_in(input).unsqueeze(2)  # batch x dim x 1\n\n        # Get attention\n        attn = torch.bmm(context, target).squeeze(2)  # batch x sourceL\n        attn = self.sm(attn)\n        attn3 = attn.view(attn.size(0), 1, attn.size(1))  # batch x 1 x sourceL\n\n        weighted_context = torch.bmm(attn3, context).squeeze(1)  # batch x dim\n        h_tilde = torch.cat((weighted_context, input), 1)\n\n        h_tilde = self.tanh(self.linear_out(h_tilde))\n\n        return h_tilde, attn\n\n\nclass LSTMAttentionDot(nn.Module):\n    r""""""A long short-term memory (LSTM) cell with attention.""""""\n\n    def __init__(self, input_size, hidden_size, batch_first=True):\n        """"""Initialize params.""""""\n        super(LSTMAttentionDot, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = 1\n        self.batch_first = batch_first\n\n        self.input_weights = nn.Linear(input_size, 4 * hidden_size)\n        self.hidden_weights = nn.Linear(hidden_size, 4 * hidden_size)\n\n        self.attention_layer = SoftDotAttention(hidden_size)\n\n    def forward(self, input, hidden, ctx, ctx_mask=None):\n        """"""Propogate input through the network.""""""\n        def recurrence(input, hidden):\n            """"""Recurrence helper.""""""\n            hx, cx = hidden  # n_b x hidden_dim\n            gates = self.input_weights(input) + \\\n                self.hidden_weights(hx)\n            ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n\n            ingate = F.sigmoid(ingate)\n            forgetgate = F.sigmoid(forgetgate)\n            cellgate = F.tanh(cellgate)\n            outgate = F.sigmoid(outgate)\n\n            cy = (forgetgate * cx) + (ingate * cellgate)\n            hy = outgate * F.tanh(cy)  # n_b x hidden_dim\n            h_tilde, alpha = self.attention_layer(hy, ctx.transpose(0, 1))\n\n            return h_tilde, cy\n\n        if self.batch_first:\n            input = input.transpose(0, 1)\n\n        output = []\n        steps = range(input.size(0))\n        for i in steps:\n            hidden = recurrence(input[i], hidden)\n            output.append(isinstance(hidden, tuple) and hidden[0] or hidden)\n\n        output = torch.cat(output, 0).view(input.size(0), *output[0].size())\n\n        if self.batch_first:\n            output = output.transpose(0, 1)\n\n        return output, hidden\n\n\nclass Seq2Seq(nn.Module):\n    """"""Container module with an encoder, deocder, embeddings.""""""\n\n    def __init__(\n        self,\n        src_emb_dim,\n        trg_emb_dim,\n        src_vocab_size,\n        trg_vocab_size,\n        src_hidden_dim,\n        trg_hidden_dim,\n        batch_size,\n        pad_token_src,\n        pad_token_trg,\n        bidirectional=True,\n        nlayers=2,\n        nlayers_trg=1,\n        dropout=0.,\n    ):\n        """"""Initialize model.""""""\n        super(Seq2Seq, self).__init__()\n        self.src_vocab_size = src_vocab_size\n        self.trg_vocab_size = trg_vocab_size\n        self.src_emb_dim = src_emb_dim\n        self.trg_emb_dim = trg_emb_dim\n        self.src_hidden_dim = src_hidden_dim\n        self.trg_hidden_dim = trg_hidden_dim\n        self.batch_size = batch_size\n        self.bidirectional = bidirectional\n        self.nlayers = nlayers\n        self.dropout = dropout\n        self.num_directions = 2 if bidirectional else 1\n        self.pad_token_src = pad_token_src\n        self.pad_token_trg = pad_token_trg\n        self.src_hidden_dim = src_hidden_dim // 2 \\\n            if self.bidirectional else src_hidden_dim\n\n        self.src_embedding = nn.Embedding(\n            src_vocab_size,\n            src_emb_dim,\n            self.pad_token_src\n        )\n        self.trg_embedding = nn.Embedding(\n            trg_vocab_size,\n            trg_emb_dim,\n            self.pad_token_trg\n        )\n\n        self.encoder = nn.LSTM(\n            src_emb_dim,\n            self.src_hidden_dim,\n            nlayers,\n            bidirectional=bidirectional,\n            batch_first=True,\n            dropout=self.dropout\n        )\n\n        self.decoder = nn.LSTM(\n            trg_emb_dim,\n            trg_hidden_dim,\n            nlayers_trg,\n            dropout=self.dropout,\n            batch_first=True\n        )\n\n        self.encoder2decoder = nn.Linear(\n            self.src_hidden_dim * self.num_directions,\n            trg_hidden_dim\n        )\n        self.decoder2vocab = nn.Linear(trg_hidden_dim, trg_vocab_size).cuda()\n\n        self.init_weights()\n\n    def init_weights(self):\n        """"""Initialize weights.""""""\n        initrange = 0.1\n        self.src_embedding.weight.data.uniform_(-initrange, initrange)\n        self.trg_embedding.weight.data.uniform_(-initrange, initrange)\n        self.encoder2decoder.bias.data.fill_(0)\n        self.decoder2vocab.bias.data.fill_(0)\n\n    def get_state(self, input):\n        """"""Get cell states and hidden states.""""""\n        batch_size = input.size(0) \\\n            if self.encoder.batch_first else input.size(1)\n        h0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ))\n        c0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ))\n\n        return h0_encoder.cuda(), c0_encoder.cuda()\n\n    def forward(self, input_src, input_trg, ctx_mask=None, trg_mask=None):\n        """"""Propogate input through the network.""""""\n        src_emb = self.src_embedding(input_src)\n        trg_emb = self.trg_embedding(input_trg)\n\n        self.h0_encoder, self.c0_encoder = self.get_state(input_src)\n\n        src_h, (src_h_t, src_c_t) = self.encoder(\n            src_emb, (self.h0_encoder, self.c0_encoder)\n        )\n\n        if self.bidirectional:\n            h_t = torch.cat((src_h_t[-1], src_h_t[-2]), 1)\n            c_t = torch.cat((src_c_t[-1], src_c_t[-2]), 1)\n        else:\n            h_t = src_h_t[-1]\n            c_t = src_c_t[-1]\n\n        decoder_init_state = nn.Tanh()(self.encoder2decoder(h_t))\n\n        trg_h, (_, _) = self.decoder(\n            trg_emb,\n            (\n                decoder_init_state.view(\n                    self.decoder.num_layers,\n                    decoder_init_state.size(0),\n                    decoder_init_state.size(1)\n                ),\n                c_t.view(\n                    self.decoder.num_layers,\n                    c_t.size(0),\n                    c_t.size(1)\n                )\n            )\n        )\n\n        trg_h_reshape = trg_h.contiguous().view(\n            trg_h.size(0) * trg_h.size(1),\n            trg_h.size(2)\n        )\n\n        decoder_logit = self.decoder2vocab(trg_h_reshape)\n        decoder_logit = decoder_logit.view(\n            trg_h.size(0),\n            trg_h.size(1),\n            decoder_logit.size(1)\n        )\n\n        return decoder_logit\n\n    def decode(self, logits):\n        """"""Return probability distribution over words.""""""\n        logits_reshape = logits.view(-1, self.trg_vocab_size)\n        word_probs = F.softmax(logits_reshape)\n        word_probs = word_probs.view(\n            logits.size()[0], logits.size()[1], logits.size()[2]\n        )\n        return word_probs\n\n\nclass Seq2SeqAutoencoder(nn.Module):\n    """"""Container module with an encoder, deocder, embeddings.""""""\n\n    def __init__(\n        self,\n        src_emb_dim,\n        trg_emb_dim,\n        src_vocab_size,\n        src_hidden_dim,\n        trg_hidden_dim,\n        batch_size,\n        pad_token_src,\n        bidirectional=False,\n        nlayers=1,\n        nlayers_trg=1,\n        dropout=0.,\n    ):\n        """"""Initialize model.""""""\n        super(Seq2SeqAutoencoder, self).__init__()\n        self.src_vocab_size = src_vocab_size\n        self.src_emb_dim = src_emb_dim\n        self.trg_emb_dim = trg_emb_dim\n        self.src_hidden_dim = src_hidden_dim\n        self.trg_hidden_dim = trg_hidden_dim\n        self.batch_size = batch_size\n        self.bidirectional = bidirectional\n        self.nlayers = nlayers\n        self.dropout = dropout\n        self.num_directions = 2 if bidirectional else 1\n        self.pad_token_src = pad_token_src\n\n        self.src_embedding = nn.Embedding(\n            src_vocab_size,\n            src_emb_dim,\n            self.pad_token_src\n        )\n        self.trg_embedding = nn.Embedding(\n            src_vocab_size,\n            trg_emb_dim,\n            self.pad_token_src\n        )\n\n        if self.bidirectional and self.nlayers > 1:\n            self.encoder = DeepBidirectionalLSTM(\n                self.src_emb_dim,\n                self.src_hidden_dim,\n                self.nlayers,\n                self.dropout,\n                True\n            )\n\n        else:\n            hidden_dim = self.src_hidden_dim // 2 \\\n                if self.bidirectional else self.src_hidden_dim\n            self.encoder = nn.LSTM(\n                src_emb_dim,\n                hidden_dim,\n                nlayers,\n                bidirectional=bidirectional,\n                batch_first=True,\n                dropout=self.dropout\n            )\n\n        self.decoder = nn.LSTM(\n            trg_emb_dim,\n            trg_hidden_dim,\n            nlayers_trg,\n            dropout=self.dropout,\n            batch_first=True\n        )\n\n        self.encoder2decoder = nn.Linear(\n            self.src_hidden_dim,\n            trg_hidden_dim\n        )\n        self.decoder2vocab = nn.Linear(trg_hidden_dim, src_vocab_size).cuda()\n\n        self.init_weights()\n\n    def init_weights(self):\n        """"""Initialize weights.""""""\n        initrange = 0.1\n        self.src_embedding.weight.data.uniform_(-initrange, initrange)\n        self.trg_embedding.weight.data.uniform_(-initrange, initrange)\n        self.encoder2decoder.bias.data.fill_(0)\n        self.decoder2vocab.bias.data.fill_(0)\n\n    def get_state(self, input):\n        """"""Get cell states and hidden states.""""""\n        batch_size = input.size(0) \\\n            if self.encoder.batch_first else input.size(1)\n        h0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ))\n        c0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ))\n\n        return h0_encoder.cuda(), c0_encoder.cuda()\n\n    def forward(self, input, ctx_mask=None, trg_mask=None):\n        """"""Propogate input through the network.""""""\n        src_emb = self.src_embedding(input)\n        trg_emb = self.trg_embedding(input)\n\n        if self.bidirectional and self.nlayers > 1:\n            src_h, (src_h_t, src_c_t) = self.encoder(src_emb)\n\n        else:\n            self.h0_encoder, self.c0_encoder = self.get_state(input)\n\n            src_h, (src_h_t, src_c_t) = self.encoder(\n                src_emb, (self.h0_encoder, self.c0_encoder)\n            )\n\n        if self.bidirectional and self.nlayers == 1:\n            h_t = torch.cat((src_h_t[-1], src_h_t[-2]), 1)\n            c_t = torch.cat((src_c_t[-1], src_c_t[-2]), 1)\n        else:\n            h_t = src_h_t[-1]\n            c_t = src_c_t[-1]\n\n        decoder_init_state = nn.Tanh()(self.encoder2decoder(h_t))\n\n        trg_h, (_, _) = self.decoder(\n            trg_emb,\n            (\n                decoder_init_state.view(\n                    self.decoder.num_layers,\n                    decoder_init_state.size(0),\n                    decoder_init_state.size(1)\n                ),\n                c_t.view(\n                    self.decoder.num_layers,\n                    c_t.size(0),\n                    c_t.size(1)\n                )\n            )\n        )\n        trg_h_reshape = trg_h.contiguous().view(\n            trg_h.size(0) * trg_h.size(1),\n            trg_h.size(2)\n        )\n        decoder_logit = self.decoder2vocab(trg_h_reshape)\n        decoder_logit = decoder_logit.view(\n            trg_h.size(0),\n            trg_h.size(1),\n            decoder_logit.size(1)\n        )\n\n        return decoder_logit\n\n    def decode(self, logits):\n        """"""Return probability distribution over words.""""""\n        logits_reshape = logits.view(-1, self.src_vocab_size)\n        word_probs = F.softmax(logits_reshape)\n        word_probs = word_probs.view(\n            logits.size()[0], logits.size()[1], logits.size()[2]\n        )\n        return word_probs\n\n\nclass Seq2SeqAttention(nn.Module):\n    """"""Container module with an encoder, deocder, embeddings.""""""\n\n    def __init__(\n        self,\n        src_emb_dim,\n        trg_emb_dim,\n        src_vocab_size,\n        trg_vocab_size,\n        src_hidden_dim,\n        trg_hidden_dim,\n        ctx_hidden_dim,\n        attention_mode,\n        batch_size,\n        pad_token_src,\n        pad_token_trg,\n        bidirectional=True,\n        nlayers=2,\n        nlayers_trg=2,\n        dropout=0.,\n    ):\n        """"""Initialize model.""""""\n        super(Seq2SeqAttention, self).__init__()\n        self.src_vocab_size = src_vocab_size\n        self.trg_vocab_size = trg_vocab_size\n        self.src_emb_dim = src_emb_dim\n        self.trg_emb_dim = trg_emb_dim\n        self.src_hidden_dim = src_hidden_dim\n        self.trg_hidden_dim = trg_hidden_dim\n        self.ctx_hidden_dim = ctx_hidden_dim\n        self.attention_mode = attention_mode\n        self.batch_size = batch_size\n        self.bidirectional = bidirectional\n        self.nlayers = nlayers\n        self.dropout = dropout\n        self.num_directions = 2 if bidirectional else 1\n        self.pad_token_src = pad_token_src\n        self.pad_token_trg = pad_token_trg\n\n        self.src_embedding = nn.Embedding(\n            src_vocab_size,\n            src_emb_dim,\n            self.pad_token_src\n        )\n        self.trg_embedding = nn.Embedding(\n            trg_vocab_size,\n            trg_emb_dim,\n            self.pad_token_trg\n        )\n\n        self.src_hidden_dim = src_hidden_dim // 2 \\\n            if self.bidirectional else src_hidden_dim\n        self.encoder = nn.LSTM(\n            src_emb_dim,\n            self.src_hidden_dim,\n            nlayers,\n            bidirectional=bidirectional,\n            batch_first=True,\n            dropout=self.dropout\n        )\n\n        self.decoder = LSTMAttentionDot(\n            trg_emb_dim,\n            trg_hidden_dim,\n            batch_first=True\n        )\n\n        self.encoder2decoder = nn.Linear(\n            self.src_hidden_dim * self.num_directions,\n            trg_hidden_dim\n        )\n        self.decoder2vocab = nn.Linear(trg_hidden_dim, trg_vocab_size)\n\n        self.init_weights()\n\n    def init_weights(self):\n        """"""Initialize weights.""""""\n        initrange = 0.1\n        self.src_embedding.weight.data.uniform_(-initrange, initrange)\n        self.trg_embedding.weight.data.uniform_(-initrange, initrange)\n        self.encoder2decoder.bias.data.fill_(0)\n        self.decoder2vocab.bias.data.fill_(0)\n\n    def get_state(self, input):\n        """"""Get cell states and hidden states.""""""\n        batch_size = input.size(0) \\\n            if self.encoder.batch_first else input.size(1)\n        h0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ), requires_grad=False)\n        c0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ), requires_grad=False)\n\n        return h0_encoder.cuda(), c0_encoder.cuda()\n\n    def forward(self, input_src, input_trg, trg_mask=None, ctx_mask=None):\n        """"""Propogate input through the network.""""""\n        src_emb = self.src_embedding(input_src)\n        trg_emb = self.trg_embedding(input_trg)\n\n        self.h0_encoder, self.c0_encoder = self.get_state(input_src)\n\n        src_h, (src_h_t, src_c_t) = self.encoder(\n            src_emb, (self.h0_encoder, self.c0_encoder)\n        )\n\n        if self.bidirectional:\n            h_t = torch.cat((src_h_t[-1], src_h_t[-2]), 1)\n            c_t = torch.cat((src_c_t[-1], src_c_t[-2]), 1)\n        else:\n            h_t = src_h_t[-1]\n            c_t = src_c_t[-1]\n        decoder_init_state = nn.Tanh()(self.encoder2decoder(h_t))\n\n        ctx = src_h.transpose(0, 1)\n\n        trg_h, (_, _) = self.decoder(\n            trg_emb,\n            (decoder_init_state, c_t),\n            ctx,\n            ctx_mask\n        )\n\n        trg_h_reshape = trg_h.contiguous().view(\n            trg_h.size()[0] * trg_h.size()[1],\n            trg_h.size()[2]\n        )\n        decoder_logit = self.decoder2vocab(trg_h_reshape)\n        decoder_logit = decoder_logit.view(\n            trg_h.size()[0],\n            trg_h.size()[1],\n            decoder_logit.size()[1]\n        )\n        return decoder_logit\n\n    def decode(self, logits):\n        """"""Return probability distribution over words.""""""\n        logits_reshape = logits.view(-1, self.trg_vocab_size)\n        word_probs = F.softmax(logits_reshape)\n        word_probs = word_probs.view(\n            logits.size()[0], logits.size()[1], logits.size()[2]\n        )\n        return word_probs\n\n\nclass Seq2SeqAttentionSharedEmbedding(nn.Module):\n    """"""Container module with an encoder, deocder, embeddings.""""""\n\n    def __init__(\n        self,\n        emb_dim,\n        vocab_size,\n        src_hidden_dim,\n        trg_hidden_dim,\n        ctx_hidden_dim,\n        attention_mode,\n        batch_size,\n        pad_token_src,\n        pad_token_trg,\n        bidirectional=True,\n        nlayers=2,\n        nlayers_trg=2,\n        dropout=0.,\n    ):\n        """"""Initialize model.""""""\n        super(Seq2SeqAttentionSharedEmbedding, self).__init__()\n        self.vocab_size = vocab_size\n        self.emb_dim = emb_dim\n        self.src_hidden_dim = src_hidden_dim\n        self.trg_hidden_dim = trg_hidden_dim\n        self.ctx_hidden_dim = ctx_hidden_dim\n        self.attention_mode = attention_mode\n        self.batch_size = batch_size\n        self.bidirectional = bidirectional\n        self.nlayers = nlayers\n        self.dropout = dropout\n        self.num_directions = 2 if bidirectional else 1\n        self.pad_token_src = pad_token_src\n        self.pad_token_trg = pad_token_trg\n\n        self.embedding = nn.Embedding(\n            vocab_size,\n            emb_dim,\n            self.pad_token_src\n        )\n\n        self.src_hidden_dim = src_hidden_dim // 2 \\\n            if self.bidirectional else src_hidden_dim\n\n        self.encoder = nn.LSTM(\n            emb_dim,\n            self.src_hidden_dim,\n            nlayers,\n            bidirectional=bidirectional,\n            batch_first=True,\n            dropout=self.dropout\n        )\n\n        self.decoder = LSTMAttentionDot(\n            emb_dim,\n            trg_hidden_dim,\n            batch_first=True\n        )\n\n        self.encoder2decoder = nn.Linear(\n            self.src_hidden_dim * self.num_directions,\n            trg_hidden_dim\n        )\n        self.decoder2vocab = nn.Linear(trg_hidden_dim, vocab_size)\n\n        self.init_weights()\n\n    def init_weights(self):\n        """"""Initialize weights.""""""\n        initrange = 0.1\n        self.embedding.weight.data.uniform_(-initrange, initrange)\n        self.encoder2decoder.bias.data.fill_(0)\n        self.decoder2vocab.bias.data.fill_(0)\n\n    def get_state(self, input):\n        """"""Get cell states and hidden states.""""""\n        batch_size = input.size(0) \\\n            if self.encoder.batch_first else input.size(1)\n\n        h0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ), requires_grad=False)\n\n        c0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ), requires_grad=False)\n\n        return h0_encoder.cuda(), c0_encoder.cuda()\n\n    def forward(self, input_src, input_trg, trg_mask=None, ctx_mask=None):\n        """"""Propogate input through the network.""""""\n        src_emb = self.embedding(input_src)\n        trg_emb = self.embedding(input_trg)\n\n        self.h0_encoder, self.c0_encoder = self.get_state(input_src)\n\n        src_h, (src_h_t, src_c_t) = self.encoder(\n            src_emb, (self.h0_encoder, self.c0_encoder)\n        )\n\n        if self.bidirectional:\n            h_t = torch.cat((src_h_t[-1], src_h_t[-2]), 1)\n            c_t = torch.cat((src_c_t[-1], src_c_t[-2]), 1)\n        else:\n            h_t = src_h_t[-1]\n            c_t = src_c_t[-1]\n\n        decoder_init_state = nn.Tanh()(self.encoder2decoder(h_t))\n\n        ctx = src_h.transpose(0, 1)\n\n        trg_h, (_, _) = self.decoder(\n            trg_emb,\n            (decoder_init_state, c_t),\n            ctx,\n            ctx_mask\n        )\n\n        trg_h_reshape = trg_h.contiguous().view(\n            trg_h.size()[0] * trg_h.size()[1],\n            trg_h.size()[2]\n        )\n\n        decoder_logit = self.decoder2vocab(trg_h_reshape)\n        decoder_logit = decoder_logit.view(\n            trg_h.size()[0],\n            trg_h.size()[1],\n            decoder_logit.size()[1]\n        )\n        return decoder_logit\n\n    def decode(self, logits):\n        """"""Return probability distribution over words.""""""\n        logits_reshape = logits.view(-1, self.vocab_size)\n        word_probs = F.softmax(logits_reshape)\n        word_probs = word_probs.view(\n            logits.size()[0], logits.size()[1], logits.size()[2]\n        )\n        return word_probs\n\n\nclass Seq2SeqFastAttention(nn.Module):\n    """"""Container module with an encoder, deocder, embeddings.""""""\n\n    def __init__(\n        self,\n        src_emb_dim,\n        trg_emb_dim,\n        src_vocab_size,\n        trg_vocab_size,\n        src_hidden_dim,\n        trg_hidden_dim,\n        batch_size,\n        pad_token_src,\n        pad_token_trg,\n        bidirectional=True,\n        nlayers=2,\n        nlayers_trg=2,\n        dropout=0.,\n    ):\n        """"""Initialize model.""""""\n        super(Seq2SeqFastAttention, self).__init__()\n        self.src_vocab_size = src_vocab_size\n        self.trg_vocab_size = trg_vocab_size\n        self.src_emb_dim = src_emb_dim\n        self.trg_emb_dim = trg_emb_dim\n        self.src_hidden_dim = src_hidden_dim\n        self.trg_hidden_dim = trg_hidden_dim\n        self.batch_size = batch_size\n        self.bidirectional = bidirectional\n        self.nlayers = nlayers\n        self.dropout = dropout\n        self.num_directions = 2 if bidirectional else 1\n        self.pad_token_src = pad_token_src\n        self.pad_token_trg = pad_token_trg\n\n        assert trg_hidden_dim == src_hidden_dim\n        self.src_embedding = nn.Embedding(\n            src_vocab_size,\n            src_emb_dim,\n            self.pad_token_src\n        )\n        self.trg_embedding = nn.Embedding(\n            trg_vocab_size,\n            trg_emb_dim,\n            self.pad_token_trg\n        )\n\n        self.src_hidden_dim = src_hidden_dim // 2 \\\n            if self.bidirectional else src_hidden_dim\n        self.encoder = nn.LSTM(\n            src_emb_dim,\n            self.src_hidden_dim,\n            nlayers,\n            bidirectional=bidirectional,\n            batch_first=True,\n            dropout=self.dropout\n        )\n\n        self.decoder = nn.LSTM(\n            trg_emb_dim,\n            trg_hidden_dim,\n            nlayers_trg,\n            batch_first=True,\n            dropout=self.dropout\n        )\n\n        self.encoder2decoder = nn.Linear(\n            self.src_hidden_dim * self.num_directions,\n            trg_hidden_dim\n        )\n        self.decoder2vocab = nn.Linear(2 * trg_hidden_dim, trg_vocab_size)\n\n        self.init_weights()\n\n    def init_weights(self):\n        """"""Initialize weights.""""""\n        initrange = 0.1\n        self.src_embedding.weight.data.uniform_(-initrange, initrange)\n        self.trg_embedding.weight.data.uniform_(-initrange, initrange)\n        self.encoder2decoder.bias.data.fill_(0)\n        self.decoder2vocab.bias.data.fill_(0)\n\n    def get_state(self, input):\n        """"""Get cell states and hidden states.""""""\n        batch_size = input.size(0) \\\n            if self.encoder.batch_first else input.size(1)\n        h0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ), requires_grad=False)\n        c0_encoder = Variable(torch.zeros(\n            self.encoder.num_layers * self.num_directions,\n            batch_size,\n            self.src_hidden_dim\n        ), requires_grad=False)\n\n        return h0_encoder.cuda(), c0_encoder.cuda()\n\n    def forward(self, input_src, input_trg, trg_mask=None, ctx_mask=None):\n        """"""Propogate input through the network.""""""\n        src_emb = self.src_embedding(input_src)\n        trg_emb = self.trg_embedding(input_trg)\n\n        self.h0_encoder, self.c0_encoder = self.get_state(input_src)\n\n        src_h, (src_h_t, src_c_t) = self.encoder(\n            src_emb, (self.h0_encoder, self.c0_encoder)\n        )  # bsize x seqlen x dim\n\n        if self.bidirectional:\n            h_t = torch.cat((src_h_t[-1], src_h_t[-2]), 1)\n            c_t = torch.cat((src_c_t[-1], src_c_t[-2]), 1)\n        else:\n            h_t = src_h_t[-1]\n            c_t = src_c_t[-1]\n        decoder_init_state = nn.Tanh()(self.encoder2decoder(h_t))\n\n        trg_h, (_, _) = self.decoder(\n            trg_emb,\n            (\n                decoder_init_state.view(\n                    self.decoder.num_layers,\n                    decoder_init_state.size(0),\n                    decoder_init_state.size(1)\n                ),\n                c_t.view(\n                    self.decoder.num_layers,\n                    c_t.size(0),\n                    c_t.size(1)\n                )\n            )\n        )  # bsize x seqlen x dim\n\n        # Fast Attention dot product\n\n        # bsize x seqlen_src x seq_len_trg\n        alpha = torch.bmm(src_h, trg_h.transpose(1, 2))\n        # bsize x seq_len_trg x dim\n        alpha = torch.bmm(alpha.transpose(1, 2), src_h)\n        # bsize x seq_len_trg x (2 * dim)\n        trg_h_reshape = torch.cat((trg_h, alpha), 2)\n\n        trg_h_reshape = trg_h_reshape.view(\n            trg_h_reshape.size(0) * trg_h_reshape.size(1),\n            trg_h_reshape.size(2)\n        )\n        decoder_logit = self.decoder2vocab(trg_h_reshape)\n        decoder_logit = decoder_logit.view(\n            trg_h.size()[0],\n            trg_h.size()[1],\n            decoder_logit.size()[1]\n        )\n        return decoder_logit\n\n    def decode(self, logits):\n        """"""Return probability distribution over words.""""""\n        logits_reshape = logits.view(-1, self.trg_vocab_size)\n        word_probs = F.softmax(logits_reshape)\n        word_probs = word_probs.view(\n            logits.size()[0], logits.size()[1], logits.size()[2]\n        )\n        return word_probs\n'"
nmt.py,8,"b'#!/u/subramas/miniconda2/bin/python\n""""""Main script to run things""""""\nimport sys\n\nsys.path.append(\'/u/subramas/Research/nmt-pytorch/\')\n\nfrom data_utils import read_nmt_data, get_minibatch, read_config, hyperparam_string\nfrom model import Seq2Seq, Seq2SeqAttention, Seq2SeqFastAttention\nfrom evaluate import evaluate_model\nimport math\nimport numpy as np\nimport logging\nimport argparse\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\n    ""--config"",\n    help=""path to json config"",\n    required=True\n)\nargs = parser.parse_args()\nconfig_file_path = args.config\nconfig = read_config(config_file_path)\nexperiment_name = hyperparam_string(config)\nsave_dir = config[\'data\'][\'save_dir\']\nload_dir = config[\'data\'][\'load_dir\']\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\'%(asctime)s - %(levelname)s - %(message)s\',\n    filename=\'log/%s\' % (experiment_name),\n    filemode=\'w\'\n)\n\n# define a new Handler to log to console as well\nconsole = logging.StreamHandler()\n# optional, set the logging level\nconsole.setLevel(logging.INFO)\n# set a format which is the same for console use\nformatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\n# tell the handler to use this format\nconsole.setFormatter(formatter)\n# add the handler to the root logger\nlogging.getLogger(\'\').addHandler(console)\n\n\nprint \'Reading data ...\'\n\nsrc, trg = read_nmt_data(\n    src=config[\'data\'][\'src\'],\n    config=config,\n    trg=config[\'data\'][\'trg\']\n)\n\nsrc_test, trg_test = read_nmt_data(\n    src=config[\'data\'][\'test_src\'],\n    config=config,\n    trg=config[\'data\'][\'test_trg\']\n)\n\nbatch_size = config[\'data\'][\'batch_size\']\nmax_length = config[\'data\'][\'max_src_length\']\nsrc_vocab_size = len(src[\'word2id\'])\ntrg_vocab_size = len(trg[\'word2id\'])\n\nlogging.info(\'Model Parameters : \')\nlogging.info(\'Task : %s \' % (config[\'data\'][\'task\']))\nlogging.info(\'Model : %s \' % (config[\'model\'][\'seq2seq\']))\nlogging.info(\'Source Language : %s \' % (config[\'model\'][\'src_lang\']))\nlogging.info(\'Target Language : %s \' % (config[\'model\'][\'trg_lang\']))\nlogging.info(\'Source Word Embedding Dim  : %s\' % (config[\'model\'][\'dim_word_src\']))\nlogging.info(\'Target Word Embedding Dim  : %s\' % (config[\'model\'][\'dim_word_trg\']))\nlogging.info(\'Source RNN Hidden Dim  : %s\' % (config[\'model\'][\'dim\']))\nlogging.info(\'Target RNN Hidden Dim  : %s\' % (config[\'model\'][\'dim\']))\nlogging.info(\'Source RNN Depth : %d \' % (config[\'model\'][\'n_layers_src\']))\nlogging.info(\'Target RNN Depth : %d \' % (1))\nlogging.info(\'Source RNN Bidirectional  : %s\' % (config[\'model\'][\'bidirectional\']))\nlogging.info(\'Batch Size : %d \' % (config[\'model\'][\'n_layers_trg\']))\nlogging.info(\'Optimizer : %s \' % (config[\'training\'][\'optimizer\']))\nlogging.info(\'Learning Rate : %f \' % (config[\'training\'][\'lrate\']))\n\nlogging.info(\'Found %d words in src \' % (src_vocab_size))\nlogging.info(\'Found %d words in trg \' % (trg_vocab_size))\n\nweight_mask = torch.ones(trg_vocab_size).cuda()\nweight_mask[trg[\'word2id\'][\'<pad>\']] = 0\nloss_criterion = nn.CrossEntropyLoss(weight=weight_mask).cuda()\n\nif config[\'model\'][\'seq2seq\'] == \'vanilla\':\n\n    model = Seq2Seq(\n        src_emb_dim=config[\'model\'][\'dim_word_src\'],\n        trg_emb_dim=config[\'model\'][\'dim_word_trg\'],\n        src_vocab_size=src_vocab_size,\n        trg_vocab_size=trg_vocab_size,\n        src_hidden_dim=config[\'model\'][\'dim\'],\n        trg_hidden_dim=config[\'model\'][\'dim\'],\n        batch_size=batch_size,\n        bidirectional=config[\'model\'][\'bidirectional\'],\n        pad_token_src=src[\'word2id\'][\'<pad>\'],\n        pad_token_trg=trg[\'word2id\'][\'<pad>\'],\n        nlayers=config[\'model\'][\'n_layers_src\'],\n        nlayers_trg=config[\'model\'][\'n_layers_trg\'],\n        dropout=0.,\n    ).cuda()\n\nelif config[\'model\'][\'seq2seq\'] == \'attention\':\n\n    model = Seq2SeqAttention(\n        src_emb_dim=config[\'model\'][\'dim_word_src\'],\n        trg_emb_dim=config[\'model\'][\'dim_word_trg\'],\n        src_vocab_size=src_vocab_size,\n        trg_vocab_size=trg_vocab_size,\n        src_hidden_dim=config[\'model\'][\'dim\'],\n        trg_hidden_dim=config[\'model\'][\'dim\'],\n        ctx_hidden_dim=config[\'model\'][\'dim\'],\n        attention_mode=\'dot\',\n        batch_size=batch_size,\n        bidirectional=config[\'model\'][\'bidirectional\'],\n        pad_token_src=src[\'word2id\'][\'<pad>\'],\n        pad_token_trg=trg[\'word2id\'][\'<pad>\'],\n        nlayers=config[\'model\'][\'n_layers_src\'],\n        nlayers_trg=config[\'model\'][\'n_layers_trg\'],\n        dropout=0.,\n    ).cuda()\n\nelif config[\'model\'][\'seq2seq\'] == \'fastattention\':\n\n    model = Seq2SeqFastAttention(\n        src_emb_dim=config[\'model\'][\'dim_word_src\'],\n        trg_emb_dim=config[\'model\'][\'dim_word_trg\'],\n        src_vocab_size=src_vocab_size,\n        trg_vocab_size=trg_vocab_size,\n        src_hidden_dim=config[\'model\'][\'dim\'],\n        trg_hidden_dim=config[\'model\'][\'dim\'],\n        batch_size=batch_size,\n        bidirectional=config[\'model\'][\'bidirectional\'],\n        pad_token_src=src[\'word2id\'][\'<pad>\'],\n        pad_token_trg=trg[\'word2id\'][\'<pad>\'],\n        nlayers=config[\'model\'][\'n_layers_src\'],\n        nlayers_trg=config[\'model\'][\'n_layers_trg\'],\n        dropout=0.,\n    ).cuda()\n\nif load_dir:\n    model.load_state_dict(torch.load(\n        open(load_dir)\n    ))\n\n# __TODO__ Make this more flexible for other learning methods.\nif config[\'training\'][\'optimizer\'] == \'adam\':\n    lr = config[\'training\'][\'lrate\']\n    optimizer = optim.Adam(model.parameters(), lr=lr)\nelif config[\'training\'][\'optimizer\'] == \'adadelta\':\n    optimizer = optim.Adadelta(model.parameters())\nelif config[\'training\'][\'optimizer\'] == \'sgd\':\n    lr = config[\'training\'][\'lrate\']\n    optimizer = optim.SGD(model.parameters(), lr=lr)\nelse:\n    raise NotImplementedError(""Learning method not recommend for task"")\n\nfor i in xrange(1000):\n    losses = []\n    for j in xrange(0, len(src[\'data\']), batch_size):\n\n        input_lines_src, _, lens_src, mask_src = get_minibatch(\n            src[\'data\'], src[\'word2id\'], j,\n            batch_size, max_length, add_start=True, add_end=True\n        )\n        input_lines_trg, output_lines_trg, lens_trg, mask_trg = get_minibatch(\n            trg[\'data\'], trg[\'word2id\'], j,\n            batch_size, max_length, add_start=True, add_end=True\n        )\n\n        decoder_logit = model(input_lines_src, input_lines_trg)\n        optimizer.zero_grad()\n\n        loss = loss_criterion(\n            decoder_logit.contiguous().view(-1, trg_vocab_size),\n            output_lines_trg.view(-1)\n        )\n        losses.append(loss.data[0])\n        loss.backward()\n        optimizer.step()\n\n        if j % config[\'management\'][\'monitor_loss\'] == 0:\n            logging.info(\'Epoch : %d Minibatch : %d Loss : %.5f\' % (\n                i, j, np.mean(losses))\n            )\n            losses = []\n\n        if (\n            config[\'management\'][\'print_samples\'] and\n            j % config[\'management\'][\'print_samples\'] == 0\n        ):\n            word_probs = model.decode(\n                decoder_logit\n            ).data.cpu().numpy().argmax(axis=-1)\n\n            output_lines_trg = output_lines_trg.data.cpu().numpy()\n            for sentence_pred, sentence_real in zip(\n                word_probs[:5], output_lines_trg[:5]\n            ):\n                sentence_pred = [trg[\'id2word\'][x] for x in sentence_pred]\n                sentence_real = [trg[\'id2word\'][x] for x in sentence_real]\n\n                if \'</s>\' in sentence_real:\n                    index = sentence_real.index(\'</s>\')\n                    sentence_real = sentence_real[:index]\n                    sentence_pred = sentence_pred[:index]\n\n                logging.info(\'Predicted : %s \' % (\' \'.join(sentence_pred)))\n                logging.info(\'-----------------------------------------------\')\n                logging.info(\'Real : %s \' % (\' \'.join(sentence_real)))\n                logging.info(\'===============================================\')\n\n        if j % config[\'management\'][\'checkpoint_freq\'] == 0:\n\n            logging.info(\'Evaluating model ...\')\n            bleu = evaluate_model(\n                model, src, src_test, trg,\n                trg_test, config, verbose=False,\n                metric=\'bleu\',\n            )\n\n            logging.info(\'Epoch : %d Minibatch : %d : BLEU : %.5f \' % (i, j, bleu))\n\n            logging.info(\'Saving model ...\')\n\n            torch.save(\n                model.state_dict(),\n                open(os.path.join(\n                    save_dir,\n                    experiment_name + \'__epoch_%d__minibatch_%d\' % (i, j) + \'.model\'), \'wb\'\n                )\n            )\n\n    bleu = evaluate_model(\n        model, src, src_test, trg,\n        trg_test, config, verbose=False,\n        metric=\'bleu\',\n    )\n\n    logging.info(\'Epoch : %d : BLEU : %.5f \' % (i, bleu))\n\n    torch.save(\n        model.state_dict(),\n        open(os.path.join(\n            save_dir,\n            experiment_name + \'__epoch_%d\' % (i) + \'.model\'), \'wb\'\n        )\n    )\n'"
nmt_autoencoder.py,8,"b'#!/u/subramas/miniconda2/bin/python\n""""""Main script to run things""""""\nimport sys\n\nsys.path.append(\'/u/subramas/Research/nmt-pytorch/\')\n\nfrom data_utils import read_nmt_data, get_autoencode_minibatch, read_config, hyperparam_string\nfrom model import Seq2Seq, Seq2SeqAutoencoder\nfrom evaluate import evaluate_model, evaluate_autoencode_model\nimport math\nimport numpy as np\nimport logging\nimport argparse\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\n    ""--config"",\n    help=""path to json config"",\n    required=True\n)\nargs = parser.parse_args()\nconfig_file_path = args.config\nconfig = read_config(config_file_path)\nexperiment_name = hyperparam_string(config)\nsave_dir = config[\'data\'][\'save_dir\']\nload_dir = config[\'data\'][\'load_dir\']\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\'%(asctime)s - %(levelname)s - %(message)s\',\n    filename=\'log/%s\' % (experiment_name),\n    filemode=\'w\'\n)\n\n# define a new Handler to log to console as well\nconsole = logging.StreamHandler()\n# optional, set the logging level\nconsole.setLevel(logging.INFO)\n# set a format which is the same for console use\nformatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\n# tell the handler to use this format\nconsole.setFormatter(formatter)\n# add the handler to the root logger\nlogging.getLogger(\'\').addHandler(console)\n\n\nprint \'Reading data ...\'\n\nsrc, _ = read_nmt_data(\n    src=config[\'data\'][\'src\'],\n    trg=None\n)\n\nsrc_test, _ = read_nmt_data(\n    src=config[\'data\'][\'test_src\'],\n    trg=None\n)\n\nbatch_size = config[\'data\'][\'batch_size\']\nmax_length = config[\'data\'][\'max_src_length\']\nsrc_vocab_size = len(src[\'word2id\'])\n\nlogging.info(\'Model Parameters : \')\nlogging.info(\'Task : %s \' % (config[\'data\'][\'task\']))\nlogging.info(\'Model : %s \' % (config[\'model\'][\'seq2seq\']))\nlogging.info(\'Source Language : %s \' % (config[\'model\'][\'src_lang\']))\nlogging.info(\'Target Language : %s \' % (config[\'model\'][\'src_lang\']))\nlogging.info(\'Source Word Embedding Dim  : %s\' % (config[\'model\'][\'dim_word_src\']))\nlogging.info(\'Target Word Embedding Dim  : %s\' % (config[\'model\'][\'dim_word_trg\']))\nlogging.info(\'Source RNN Hidden Dim  : %s\' % (config[\'model\'][\'dim\']))\nlogging.info(\'Target RNN Hidden Dim  : %s\' % (config[\'model\'][\'dim\']))\nlogging.info(\'Source RNN Depth : %d \' % (config[\'model\'][\'n_layers_src\']))\nlogging.info(\'Target RNN Depth : %d \' % (config[\'model\'][\'n_layers_trg\']))\nlogging.info(\'Source RNN Bidirectional  : %s\' % (config[\'model\'][\'bidirectional\']))\nlogging.info(\'Batch Size : %d \' % (config[\'data\'][\'batch_size\']))\nlogging.info(\'Optimizer : %s \' % (config[\'training\'][\'optimizer\']))\nlogging.info(\'Learning Rate : %f \' % (config[\'training\'][\'lrate\']))\n\nlogging.info(\'Found %d words in src \' % (src_vocab_size))\n\nweight_mask = torch.ones(src_vocab_size).cuda()\nweight_mask[src[\'word2id\'][\'<pad>\']] = 0\nloss_criterion = nn.CrossEntropyLoss(weight=weight_mask).cuda()\n\nmodel = Seq2SeqAutoencoder(\n    src_emb_dim=config[\'model\'][\'dim_word_src\'],\n    trg_emb_dim=config[\'model\'][\'dim_word_trg\'],\n    src_vocab_size=src_vocab_size,\n    src_hidden_dim=config[\'model\'][\'dim\'],\n    trg_hidden_dim=config[\'model\'][\'dim\'],\n    batch_size=batch_size,\n    bidirectional=config[\'model\'][\'bidirectional\'],\n    pad_token_src=src[\'word2id\'][\'<pad>\'],\n    nlayers=config[\'model\'][\'n_layers_src\'],\n    nlayers_trg=config[\'model\'][\'n_layers_trg\'],\n    dropout=0.,\n).cuda()\n\nif load_dir:\n    model.load_state_dict(torch.load(\n        open(load_dir)\n    ))\n\n\ndef clip_gradient(model, clip):\n    """"""Compute a gradient clipping coefficient based on gradient norm.""""""\n    totalnorm = 0\n    for p in model.parameters():\n        modulenorm = p.grad.data.norm()\n        totalnorm += modulenorm ** 2\n    totalnorm = math.sqrt(totalnorm)\n    return min(1, clip / (totalnorm + 1e-6))\n\nif config[\'training\'][\'optimizer\'] == \'adam\':\n    lr = config[\'training\'][\'lrate\']\n    optimizer = optim.Adam(model.parameters(), lr=lr)\nelif config[\'training\'][\'optimizer\'] == \'adadelta\':\n    optimizer = optim.Adadelta(model.parameters())\nelif config[\'training\'][\'optimizer\'] == \'sgd\':\n    lr = config[\'training\'][\'lrate\']\n    optimizer = optim.SGD(model.parameters(), lr=lr)\nelse:\n    raise NotImplementedError(""Learning method not recommend for task"")\n\ntorch.save(\n    model.state_dict(),\n    open(os.path.join(\n        save_dir,\n        experiment_name + \'epoch_0.model\'), \'wb\'\n    )\n)\n\nbleu = evaluate_autoencode_model(\n    model, src, src_test, config, verbose=False,\n    metric=\'bleu\',\n)\nlogging.info(\'Epoch : %d : BLEU : %.5f \' % (0, bleu))\n\n\nfor i in xrange(1000):\n    losses = []\n    for j in xrange(0, len(src[\'data\']), batch_size):\n\n        input_lines_src, output_lines_src, lens_src, mask_src = get_autoencode_minibatch(\n            src[\'data\'], src[\'word2id\'], j,\n            batch_size, max_length, add_start=True, add_end=True\n        )\n\n        decoder_logit = model(input_lines_src)\n        optimizer.zero_grad()\n\n        loss = loss_criterion(\n            decoder_logit.contiguous().view(-1, src_vocab_size),\n            output_lines_src.view(-1)\n        )\n        losses.append(loss.data[0])\n        loss.backward()\n        optimizer.step()\n\n        if j % config[\'management\'][\'monitor_loss\'] == 0:\n            logging.info(\'Epoch : %d Minibatch : %d Loss : %.5f\' % (\n                i, j, np.mean(losses))\n            )\n            losses = []\n\n        if (\n            config[\'management\'][\'print_samples\'] and\n            j % config[\'management\'][\'print_samples\'] == 0\n        ):\n\n            word_probs = model.decode(\n                decoder_logit\n            ).data.cpu().numpy().argmax(axis=-1)\n            output_lines_trg = input_lines_src.data.cpu().numpy()\n            for sentence_pred, sentence_real in zip(\n                word_probs[:5], output_lines_trg[:5]\n            ):\n                sentence_pred = [src[\'id2word\'][x] for x in sentence_pred]\n                sentence_real = [src[\'id2word\'][x] for x in sentence_real]\n\n                if \'</s>\' in sentence_real:\n                    index = sentence_real.index(\'</s>\')\n                    sentence_real = sentence_real[:index]\n                    sentence_pred = sentence_pred[:index]\n\n                logging.info(\' \'.join(sentence_pred))\n                logging.info(\'-----------------------------------------------\')\n                logging.info(\' \'.join(sentence_real))\n                logging.info(\'===============================================\')\n\n    bleu = evaluate_autoencode_model(\n        model, src, src_test, config, verbose=False,\n        metric=\'bleu\',\n    )\n    logging.info(\'Epoch : %d : BLEU : %.5f \' % (i, bleu))\n\n    torch.save(\n        model.state_dict(),\n        open(os.path.join(\n            save_dir,\n            experiment_name + \'__epoch_%d\' % (i) + \'.model\'), \'wb\'\n        )\n    )\n'"
summarization.py,7,"b'#!/u/subramas/miniconda2/bin/python\n""""""Main script to run things""""""\nimport sys\n\nsys.path.append(\'/u/subramas/Research/nmt-pytorch/\')\n\nfrom data_utils import read_nmt_data, get_minibatch, read_config, hyperparam_string, read_summarization_data\nfrom model import Seq2Seq, Seq2SeqAttention, Seq2SeqFastAttention, Seq2SeqAttentionSharedEmbedding\nfrom evaluate import evaluate_model\nimport math\nimport numpy as np\nimport logging\nimport argparse\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\n    ""--config"",\n    help=""path to json config"",\n    required=True\n)\nargs = parser.parse_args()\nconfig_file_path = args.config\nconfig = read_config(config_file_path)\nexperiment_name = hyperparam_string(config)\nsave_dir = config[\'data\'][\'save_dir\']\nload_dir = config[\'data\'][\'load_dir\']\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\'%(asctime)s - %(levelname)s - %(message)s\',\n    filename=\'log/%s\' % (experiment_name),\n    filemode=\'w\'\n)\n\n# define a new Handler to log to console as well\nconsole = logging.StreamHandler()\n# optional, set the logging level\nconsole.setLevel(logging.INFO)\n# set a format which is the same for console use\nformatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\n# tell the handler to use this format\nconsole.setFormatter(formatter)\n# add the handler to the root logger\nlogging.getLogger(\'\').addHandler(console)\n\n\nprint \'Reading data ...\'\n\nsrc, trg = read_nmt_data(\n    src=config[\'data\'][\'src\'],\n    trg=config[\'data\'][\'trg\']\n)\n\nsrc_test, trg_test = read_nmt_data(\n    src=config[\'data\'][\'test_src\'],\n    trg=config[\'data\'][\'test_trg\']\n)\n\nbatch_size = config[\'data\'][\'batch_size\']\nmax_length = config[\'data\'][\'max_src_length\']\nvocab_size = len(src[\'word2id\'])\n\nlogging.info(\'Model Parameters : \')\nlogging.info(\'Task : %s \' % (config[\'data\'][\'task\']))\nlogging.info(\'Model : %s \' % (config[\'model\'][\'seq2seq\']))\nlogging.info(\'Language : %s \' % (config[\'model\'][\'src_lang\']))\nlogging.info(\'Embedding Dim  : %s\' % (config[\'model\'][\'dim_word_src\']))\nlogging.info(\'Source RNN Hidden Dim  : %s\' % (config[\'model\'][\'dim\']))\nlogging.info(\'Target RNN Hidden Dim  : %s\' % (config[\'model\'][\'dim\']))\nlogging.info(\'Source RNN Depth : %d \' % (config[\'model\'][\'n_layers_src\']))\nlogging.info(\'Target RNN Depth : %d \' % (1))\nlogging.info(\'Source RNN Bidirectional  : %s\' % (config[\'model\'][\'bidirectional\']))\nlogging.info(\'Batch Size : %d \' % (config[\'model\'][\'n_layers_trg\']))\nlogging.info(\'Optimizer : %s \' % (config[\'training\'][\'optimizer\']))\nlogging.info(\'Learning Rate : %f \' % (config[\'training\'][\'lrate\']))\n\nlogging.info(\'Found %d words \' % (vocab_size))\n\nweight_mask = torch.ones(vocab_size).cuda()\nweight_mask[trg[\'word2id\'][\'<pad>\']] = 0\nloss_criterion = nn.CrossEntropyLoss(weight=weight_mask).cuda()\n\nmodel = Seq2SeqAttentionSharedEmbedding(\n    emb_dim=config[\'model\'][\'dim_word_src\'],\n    vocab_size=vocab_size,\n    src_hidden_dim=config[\'model\'][\'dim\'],\n    trg_hidden_dim=config[\'model\'][\'dim\'],\n    ctx_hidden_dim=config[\'model\'][\'dim\'],\n    attention_mode=\'dot\',\n    batch_size=batch_size,\n    bidirectional=config[\'model\'][\'bidirectional\'],\n    pad_token_src=src[\'word2id\'][\'<pad>\'],\n    pad_token_trg=trg[\'word2id\'][\'<pad>\'],\n    nlayers=config[\'model\'][\'n_layers_src\'],\n    nlayers_trg=config[\'model\'][\'n_layers_trg\'],\n    dropout=0.,\n).cuda()\n\nif load_dir:\n    model.load_state_dict(torch.load(\n        open(load_dir)\n    ))\n\nbleu = evaluate_model(\n    model, src, src_test, trg,\n    trg_test, config, verbose=False,\n    metric=\'bleu\',\n)\n\n# __TODO__ Make this more flexible for other learning methods.\nif config[\'training\'][\'optimizer\'] == \'adam\':\n    lr = config[\'training\'][\'lrate\']\n    optimizer = optim.Adam(model.parameters(), lr=lr)\nelif config[\'training\'][\'optimizer\'] == \'adadelta\':\n    optimizer = optim.Adadelta(model.parameters())\nelif config[\'training\'][\'optimizer\'] == \'sgd\':\n    lr = config[\'training\'][\'lrate\']\n    optimizer = optim.SGD(model.parameters(), lr=lr)\nelse:\n    raise NotImplementedError(""Learning method not recommend for task"")\n\nfor i in xrange(1000):\n    losses = []\n    for j in xrange(0, len(src[\'data\']), batch_size):\n\n        input_lines_src, _, lens_src, mask_src = get_minibatch(\n            src[\'data\'], src[\'word2id\'], j,\n            batch_size, max_length, add_start=True, add_end=True\n        )\n        input_lines_trg, output_lines_trg, lens_trg, mask_trg = get_minibatch(\n            trg[\'data\'], trg[\'word2id\'], j,\n            batch_size, max_length, add_start=True, add_end=True\n        )\n\n        decoder_logit = model(input_lines_src, input_lines_trg)\n        optimizer.zero_grad()\n\n        loss = loss_criterion(\n            decoder_logit.contiguous().view(-1, vocab_size),\n            output_lines_trg.view(-1)\n        )\n        losses.append(loss.data[0])\n        loss.backward()\n        optimizer.step()\n\n        if j % config[\'management\'][\'monitor_loss\'] == 0:\n            logging.info(\'Epoch : %d Minibatch : %d Loss : %.5f\' % (\n                i, j, np.mean(losses))\n            )\n            losses = []\n\n        if (\n            config[\'management\'][\'print_samples\'] and\n            j % config[\'management\'][\'print_samples\'] == 0\n        ):\n            word_probs = model.decode(\n                decoder_logit\n            ).data.cpu().numpy().argmax(axis=-1)\n\n            output_lines_trg = output_lines_trg.data.cpu().numpy()\n            for sentence_pred, sentence_real in zip(\n                word_probs[:5], output_lines_trg[:5]\n            ):\n                sentence_pred = [trg[\'id2word\'][x] for x in sentence_pred]\n                sentence_real = [trg[\'id2word\'][x] for x in sentence_real]\n\n                if \'</s>\' in sentence_real:\n                    index = sentence_real.index(\'</s>\')\n                    sentence_real = sentence_real[:index]\n                    sentence_pred = sentence_pred[:index]\n\n                logging.info(\'Predicted : %s \' % (\' \'.join(sentence_pred)))\n                logging.info(\'-----------------------------------------------\')\n                logging.info(\'Real : %s \' % (\' \'.join(sentence_real)))\n                logging.info(\'===============================================\')\n\n    torch.save(\n        model.state_dict(),\n        open(os.path.join(\n            save_dir,\n            experiment_name + \'__epoch_%d\' % (i) + \'.model\'), \'wb\'\n        )\n    )\n\n    bleu = evaluate_model(\n        model, src, src_test, trg,\n        trg_test, config, verbose=False,\n        metric=\'bleu\',\n    )\n    logging.info(\'Epoch : %d : BLEU : %.5f \' % (i, bleu))\n'"
