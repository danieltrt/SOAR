file_path,api_count,code
setup.py,0,"b'import io\r\nimport os\r\n\r\nfrom setuptools import setup, find_packages\r\n\r\n\r\nhere = os.path.abspath(os.path.dirname(__file__))\r\n\r\n# Avoids IDE errors, but actual version is read from version.py\r\n__version__ = None\r\nexec(open(\'matchzoo/version.py\').read())\r\n\r\nshort_description = \'Facilitating the design, comparison and sharing\' \\\r\n                    \'of deep text matching models.\'\r\n\r\n# Get the long description from the README file\r\nwith io.open(os.path.join(here, \'README.md\'), encoding=\'utf-8\') as f:\r\n    long_description = f.read()\r\n\r\ninstall_requires = [\r\n    \'torch >= 1.2.0\',\r\n    \'pytorch-transformers >= 1.1.0\',\r\n    \'nltk >= 3.4.3\',\r\n    \'numpy >= 1.16.4\',\r\n    \'tqdm == 4.38.0\',\r\n    \'dill >= 0.2.9\',\r\n    \'pandas == 0.24.2\',\r\n    \'networkx >= 2.3\',\r\n    \'h5py >= 2.9.0\',\r\n    \'hyperopt == 0.1.2\'\r\n]\r\n\r\nextras_requires = {\r\n    \'tests\': [\r\n        \'coverage >= 4.5.3\',\r\n        \'codecov >= 2.0.15\',\r\n        \'pytest >= 4.6.3\',\r\n        \'pytest-cov >= 2.7.1\',\r\n        \'flake8 >= 3.7.7\',\r\n        \'flake8_docstrings >= 1.3.0\'],\r\n}\r\n\r\n\r\nsetup(\r\n    name=""matchzoo-py"",\r\n    version=__version__,\r\n    author=""MatchZoo-py Authors"",\r\n    author_email=""fanyixing@ict.ac.cn"",\r\n    description=(short_description),\r\n    license=""Apache 2.0"",\r\n    keywords=""text matching models"",\r\n    url=""https://github.com/NTMC-Community/MatchZoo-py"",\r\n    packages=find_packages(),\r\n    include_package_data=True,\r\n    long_description=long_description,\r\n    long_description_content_type=\'text/markdown\',\r\n    classifiers=[\r\n        ""Development Status :: 3 - Alpha"",\r\n        \'Environment :: Console\',\r\n        \'Operating System :: POSIX :: Linux\',\r\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\r\n        ""License :: OSI Approved :: Apache Software License"",\r\n        \'Programming Language :: Python :: 3.6\'\r\n    ],\r\n    install_requires=install_requires,\r\n    extras_require=extras_requires\r\n)\r\n'"
matchzoo/__init__.py,0,"b""from pathlib import Path\n\nUSER_DIR = Path.expanduser(Path('~')).joinpath('.matchzoo')\nif not USER_DIR.exists():\n    USER_DIR.mkdir()\nUSER_DATA_DIR = USER_DIR.joinpath('datasets')\nif not USER_DATA_DIR.exists():\n    USER_DATA_DIR.mkdir()\nUSER_TUNED_MODELS_DIR = USER_DIR.joinpath('tuned_models')\n\nfrom .version import __version__\n\nfrom .data_pack import DataPack\nfrom .data_pack import pack\nfrom .data_pack import load_data_pack\n\nfrom . import preprocessors\nfrom . import dataloader\n\nfrom .preprocessors.chain_transform import chain_transform\n\nfrom . import auto\nfrom . import tasks\nfrom . import metrics\nfrom . import losses\nfrom . import engine\nfrom . import models\nfrom . import trainers\nfrom . import embedding\nfrom . import datasets\nfrom . import modules\n\nfrom .engine import hyper_spaces\nfrom .engine.base_preprocessor import load_preprocessor\nfrom .engine.param import Param\nfrom .engine.param_table import ParamTable\n\nfrom .embedding.embedding import Embedding\n\nfrom .preprocessors.build_unit_from_data_pack import build_unit_from_data_pack\nfrom .preprocessors.build_vocab_unit import build_vocab_unit\n"""
matchzoo/version.py,0,"b'""""""Matchzoo version file.""""""\n\n__version__ = \'1.1.1\'\n'"
tests/__init__.py,0,b''
tests/test_datasets.py,0,"b""import pytest\n\nimport matchzoo as mz\n\n\n@pytest.mark.cron\ndef test_load_data():\n    train_data = mz.datasets.wiki_qa.load_data('train', task='ranking')\n    assert len(train_data) == 20360\n    train_data, _ = mz.datasets.wiki_qa.load_data('train',\n                                                  task='classification',\n                                                  return_classes=True)\n    assert len(train_data) == 20360\n\n    dev_data = mz.datasets.wiki_qa.load_data('dev', task='ranking',\n                                             filtered=False)\n    assert len(dev_data) == 2733\n    dev_data, tag = mz.datasets.wiki_qa.load_data('dev', task='classification',\n                                                  filtered=True,\n                                                  return_classes=True)\n    assert len(dev_data) == 1126\n    assert tag == [False, True]\n\n    test_data = mz.datasets.wiki_qa.load_data('test', task='ranking',\n                                              filtered=False)\n    assert len(test_data) == 6165\n    test_data, tag = mz.datasets.wiki_qa.load_data('test',\n                                                   task='classification',\n                                                   filtered=True,\n                                                   return_classes=True)\n    assert len(test_data) == 2341\n    assert tag == [False, True]\n\n\n@pytest.mark.cron\ndef test_load_snli():\n    train_data, classes = mz.datasets.snli.load_data('train',\n                                                     'classification',\n                                                     return_classes=True)\n    num_samples = 549361\n    assert len(train_data) == num_samples\n    x, y = train_data.unpack()\n    assert len(x['text_left']) == num_samples\n    assert len(x['text_right']) == num_samples\n    assert y.shape == (num_samples, 1)\n    assert classes == ['entailment', 'contradiction', 'neutral']\n    dev_data, classes = mz.datasets.snli.load_data('dev', 'classification',\n                                                   return_classes=True)\n    assert len(dev_data) == 9842\n    assert classes == ['entailment', 'contradiction', 'neutral']\n    test_data, classes = mz.datasets.snli.load_data('test', 'classification',\n                                                    return_classes=True)\n    assert len(test_data) == 9824\n    assert classes == ['entailment', 'contradiction', 'neutral']\n\n    train_data = mz.datasets.snli.load_data('train', 'ranking')\n    x, y = train_data.unpack()\n    assert len(x['text_left']) == num_samples\n    assert len(x['text_right']) == num_samples\n    assert y.shape == (num_samples, 1)\n\n\n@pytest.mark.cron\ndef test_load_quora_qp():\n    train_data = mz.datasets.quora_qp.load_data(task='classification')\n    assert len(train_data) == 363177\n\n    dev_data, tag = mz.datasets.quora_qp.load_data(\n        'dev',\n        task='classification',\n        return_classes=True)\n    assert tag == [False, True]\n    assert len(dev_data) == 40371\n    x, y = dev_data.unpack()\n    assert len(x['text_left']) == 40371\n    assert len(x['text_right']) == 40371\n    assert y.shape == (40371, 1)\n\n    test_data = mz.datasets.quora_qp.load_data('test')\n    assert len(test_data) == 390965\n\n    dev_data = mz.datasets.quora_qp.load_data('dev', 'ranking')\n    x, y = dev_data.unpack()\n    assert y.shape == (40371, 1)\n"""
tests/test_embedding.py,0,"b""import pytest\n\nimport matchzoo as mz\n\n\n@pytest.fixture\ndef term_index():\n    return {'G': 1, 'C': 2, 'D': 3, 'A': 4, '_PAD': 0}\n\n\ndef test_embedding(term_index):\n    embed = mz.embedding.load_from_file(mz.datasets.embeddings.EMBED_RANK)\n    matrix = embed.build_matrix(term_index)\n    assert matrix.shape == (len(term_index), 50)\n    embed = mz.embedding.load_from_file(mz.datasets.embeddings.EMBED_10_GLOVE,\n                                        mode='glove')\n    matrix = embed.build_matrix(term_index)\n    assert matrix.shape == (len(term_index), 10)\n"""
tests/test_losses.py,18,"b'import torch\nimport numpy as np\n\nfrom matchzoo import losses\n\n\ndef test_hinge_loss():\n    true_value = torch.Tensor([[1.2], [1], [1], [1]])\n    pred_value = torch.Tensor([[1.2], [0.1], [0], [-0.3]])\n    expected_loss = torch.Tensor([(0 + 1 - 0.3 + 0) / 2.0])\n    loss = losses.RankHingeLoss()(pred_value, true_value)\n    assert torch.isclose(expected_loss, loss)\n    expected_loss = torch.Tensor(\n        [(2 + 0.1 - 1.2 + 2 - 0.3 + 0) / 2.0])\n    loss = losses.RankHingeLoss(margin=2)(pred_value, true_value)\n    assert torch.isclose(expected_loss, loss)\n    true_value = torch.Tensor(\n        [[1.2], [1], [0.8], [1], [1], [0.8]])\n    pred_value = torch.Tensor(\n        [[1.2], [0.1], [-0.5], [0], [0], [-0.3]])\n    expected_loss = torch.Tensor(\n        [(0 + 1 - 0.15) / 2.0])\n    loss = losses.RankHingeLoss(num_neg=2, margin=1)(\n        pred_value, true_value)\n    assert torch.isclose(expected_loss, loss)\n\n\ndef test_rank_crossentropy_loss():\n    losses.neg_num = 1\n\n    def softmax(x):\n        return np.exp(x) / np.sum(np.exp(x), axis=0)\n\n    true_value = torch.Tensor([[1.], [0.], [0.], [1.]])\n    pred_value = torch.Tensor([[0.8], [0.1], [0.8], [0.1]])\n    expected_loss = torch.Tensor(\n        [(-np.log(softmax([0.8, 0.1])[0]) - np.log(\n            softmax([0.8, 0.1])[1])) / 2])\n    loss = losses.RankCrossEntropyLoss()(pred_value, true_value)\n    assert torch.isclose(expected_loss, loss)\n    true_value = torch.Tensor([[1.], [0.], [0.], [0.], [1.], [0.]])\n    pred_value = torch.Tensor([[0.8], [0.1], [0.1], [0.8], [0.1], [0.1]])\n    expected_loss = torch.Tensor(\n        [(-np.log(softmax([0.8, 0.1, 0.1])[0]) - np.log(\n            softmax([0.8, 0.1, 0.1])[1])) / 2])\n    loss = losses.RankCrossEntropyLoss(num_neg=2)(\n        pred_value, true_value)\n    assert torch.isclose(expected_loss, loss)\n'"
tests/test_metrics.py,0,"b'import numpy as np\n\nfrom matchzoo.engine.base_metric import sort_and_couple\nfrom matchzoo import metrics\n\n\ndef test_sort_and_couple():\n    l = [0, 1, 2]\n    s = [0.1, 0.4, 0.2]\n    c = sort_and_couple(l, s)\n    assert (c == np.array([(1, 0.4), (2, 0.2), (0, 0.1)])).all()\n\n\ndef test_mean_reciprocal_rank():\n    label = [0, 1, 2]\n    score = [0.1, 0.4, 0.2]\n    assert metrics.MeanReciprocalRank()(label, score) == 1\n\n\ndef test_precision_at_k():\n    label = [0, 1, 2]\n    score = [0.1, 0.4, 0.2]\n    assert metrics.Precision(k=1)(label, score) == 1.\n    assert metrics.Precision(k=2)(label, score) == 1.\n    assert round(metrics.Precision(k=3)(label, score), 2) == 0.67\n\n\ndef test_average_precision():\n    label = [0, 1, 2]\n    score = [0.1, 0.4, 0.2]\n    assert round(metrics.AveragePrecision()(label, score), 2) == 0.89\n\n\ndef test_mean_average_precision():\n    label = [0, 1, 2]\n    score = [0.1, 0.4, 0.2]\n    assert metrics.MeanAveragePrecision()(label, score) == 1.\n\n\ndef test_dcg_at_k():\n    label = [0, 1, 2]\n    score = [0.1, 0.4, 0.2]\n    dcg = metrics.DiscountedCumulativeGain\n    assert round(dcg(k=1)(label, score), 2) == 1.44\n    assert round(dcg(k=2)(label, score), 2) == 4.17\n    assert round(dcg(k=3)(label, score), 2) == 4.17\n\n\ndef test_ndcg_at_k():\n    label = [0, 1, 2]\n    score = [0.1, 0.4, 0.2]\n    ndcg = metrics.NormalizedDiscountedCumulativeGain\n    assert round(ndcg(k=1)(label, score), 2) == 0.33\n    assert round(ndcg(k=2)(label, score), 2) == 0.80\n    assert round(ndcg(k=3)(label, score), 2) == 0.80\n\n\ndef test_accuracy():\n    label = np.array([1])\n    score = np.array([[0, 1]])\n    assert metrics.Accuracy()(label, score) == 1\n\n\ndef test_cross_entropy():\n    label = [0, 1]\n    score = [[0.25, 0.25], [0.01, 0.90]]\n    assert round(metrics.CrossEntropy()(label, score), 2) == 0.75\n'"
tests/test_utils.py,0,"b'import os\nimport shutil\nfrom pathlib import Path\n\nimport matchzoo\nfrom matchzoo import utils\nfrom matchzoo.engine.base_model import BaseModel\n\n\ndef test_timer():\n    timer = utils.Timer()\n    start = timer.time\n    timer.stop()\n    assert timer.time\n    timer.resume()\n    assert timer.time > start\n\n\ndef test_list_recursive_subclasses():\n    assert utils.list_recursive_concrete_subclasses(\n        BaseModel\n    )\n\n\ndef test_average_meter():\n    am = utils.AverageMeter()\n    am.update(1)\n    assert am.avg == 1.0\n    am.update(val=2.5, n=2)\n    assert am.avg == 2.0\n\n\ndef test_early_stopping():\n    es = utils.EarlyStopping(\n        patience=1,\n        key=\'key\',\n    )\n    result = {\'key\': 1.0}\n    es.update(result)\n    assert es.should_stop_early is False\n    es.update(result)\n    assert es.should_stop_early is True\n    state = es.state_dict()\n    new_es = utils.EarlyStopping()\n    assert new_es.should_stop_early is False\n    new_es.load_state_dict(state)\n    assert new_es.best_so_far == 1.0\n    assert new_es.is_best_so_far is False\n    assert new_es.should_stop_early is True\n\n\ndef test_get_file():\n    _url = ""https://raw.githubusercontent.com/NTMC-Community/"" \\\n           ""MatchZoo-py/master/LICENSE""\n    file_path = utils.get_file(\n        \'LICENSE\', _url, extract=True,\n        cache_dir=matchzoo.USER_DATA_DIR,\n        cache_subdir=\'LICENSE\',\n        verbose=1\n    )\n    num_lines = 203\n    assert len(open(file_path, \'rb\').readlines()) == num_lines\n    file_hash = utils._hash_file(file_path, algorithm=\'md5\')\n\n    file_path2 = utils.get_file(\n        \'LICENSE\', _url, extract=False,\n        md5_hash=file_hash,\n        cache_dir=matchzoo.USER_DATA_DIR,\n        cache_subdir=\'LICENSE\',\n        verbose=1\n    )\n    file_hash2 = utils._hash_file(file_path2, algorithm=\'md5\')\n    assert file_hash == file_hash2\n\n    file_dir = matchzoo.USER_DATA_DIR.joinpath(\'LICENSE\')\n    if os.path.exists(file_dir):\n        shutil.rmtree(file_dir)\n'"
docs/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n\nsys.path.insert(0, os.path.abspath(\'../..\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/auto\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/data_pack\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/dataloader\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/datasets\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/engine\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/embedding\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/losses\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/models\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/modules\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/metrics\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/preprocessors\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/utils\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/tasks\'))\nsys.path.insert(0, os.path.abspath(\'../../matchzoo/trainers\'))\n\n# -- Project information -----------------------------------------------------\n\nproject = \'MatchZoo-py\'\ncopyright = \'2019, MatchZoo\'\nauthor = \'MatchZoo\'\n\n# The short X.Y version\nversion = \'\'\n# The full version, including alpha/beta/rc tags\nrelease = \'1.0\'\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\n\nextensions = [\n    \'autoapi.extension\',\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx_autodoc_typehints\',\n]\nautoapi_dirs = [\'../../matchzoo\']\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n# from recommonmark.parser import CommonMarkParser\n# source_parsers = {\n#     \'.md\':CommonMarkParser\n# }\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'MatchZoodoc\'\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'MatchZoo.tex\', \'MatchZoo Documentation\',\n     \'MatchZoo\', \'manual\'),\n]\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'matchzoo\', \'MatchZoo Documentation\',\n     [author], 1)\n]\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'MatchZoo\', \'MatchZoo Documentation\',\n     author, \'MatchZoo\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n# -- Extension configuration -------------------------------------------------\n'"
matchzoo/auto/__init__.py,0,b'from .preparer import prepare\nfrom .preparer import Preparer\n\nfrom .tuner import Tuner\nfrom .tuner import tune\n\nfrom . import tuner\n'
matchzoo/data_pack/__init__.py,0,"b'from .data_pack import DataPack, load_data_pack\nfrom .pack import pack\n'"
matchzoo/data_pack/data_pack.py,0,"b'""""""Matchzoo DataPack, pair-wise tuple (feature) and context as input.""""""\n\nimport typing\nimport inspect\nfrom pathlib import Path\nimport functools\n\nimport dill\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\n\nimport matchzoo\n\ntqdm.pandas()\n\n\ndef _convert_to_list_index(\n    index: typing.Union[int, slice, np.array],\n    length: int\n):\n    if isinstance(index, int):\n        index = [index]\n    elif isinstance(index, slice):\n        index = list(range(*index.indices(length)))\n    return index\n\n\nclass DataPack(object):\n    """"""\n    Matchzoo :class:`DataPack` data structure, store dataframe and context.\n\n    `DataPack` is a MatchZoo native data structure that most MatchZoo data\n    handling processes build upon. A `DataPack` consists of three parts:\n    `left`, `right` and `relation`, each one of is a `pandas.DataFrame`.\n\n    :param relation: Store the relation between left document\n        and right document use ids.\n    :param left: Store the content or features for id_left.\n    :param right: Store the content or features for\n        id_right.\n\n    Example:\n        >>> left = [\n        ...     [\'qid1\', \'query 1\'],\n        ...     [\'qid2\', \'query 2\']\n        ... ]\n        >>> right = [\n        ...     [\'did1\', \'document 1\'],\n        ...     [\'did2\', \'document 2\']\n        ... ]\n        >>> relation = [[\'qid1\', \'did1\', 1], [\'qid2\', \'did2\', 1]]\n        >>> relation_df = pd.DataFrame(relation)\n        >>> left = pd.DataFrame(left)\n        >>> right = pd.DataFrame(right)\n        >>> dp = DataPack(\n        ...     relation=relation_df,\n        ...     left=left,\n        ...     right=right,\n        ... )\n        >>> len(dp)\n        2\n    """"""\n\n    DATA_FILENAME = \'data.dill\'\n\n    def __init__(\n        self,\n        relation: pd.DataFrame,\n        left: pd.DataFrame,\n        right: pd.DataFrame\n    ):\n        """""":class:`DataPack` initializer.""""""\n        self._relation = relation\n        self._left = left\n        self._right = right\n\n    @property\n    def has_label(self) -> bool:\n        """""":return: `True` if `label` column exists, `False` other wise.""""""\n        return \'label\' in self._relation.columns\n\n    def __len__(self) -> int:\n        """"""Get numer of rows in the class:`DataPack` object.""""""\n        return self._relation.shape[0]\n\n    @property\n    def frame(self) -> \'DataPack.FrameView\':\n        """"""\n        View the data pack as a :class:`pandas.DataFrame`.\n\n        Returned data frame is created by merging the left data frame,\n        the right dataframe and the relation data frame. Use `[]` to access\n        an item or a slice of items.\n\n        :return: A :class:`matchzoo.DataPack.FrameView` instance.\n\n        Example:\n            >>> import matchzoo as mz\n            >>> data_pack = mz.datasets.toy.load_data()\n            >>> type(data_pack.frame)\n            <class \'matchzoo.data_pack.data_pack.DataPack.FrameView\'>\n            >>> frame_slice = data_pack.frame[0:5]\n            >>> type(frame_slice)\n            <class \'pandas.core.frame.DataFrame\'>\n            >>> list(frame_slice.columns)\n            [\'id_left\', \'text_left\', \'id_right\', \'text_right\', \'label\']\n            >>> full_frame = data_pack.frame()\n            >>> len(full_frame) == len(data_pack)\n            True\n\n        """"""\n        return DataPack.FrameView(self)\n\n    def unpack(self) -> typing.Tuple[typing.Dict[str, np.array],\n                                     typing.Optional[np.array]]:\n        """"""\n        Unpack the data for training.\n\n        The return value can be directly feed to `model.fit` or\n        `model.fit_generator`.\n\n        :return: A tuple of (X, y). `y` is `None` if `self` has no label.\n\n        Example:\n            >>> import matchzoo as mz\n            >>> data_pack = mz.datasets.toy.load_data()\n            >>> X, y = data_pack.unpack()\n            >>> type(X)\n            <class \'dict\'>\n            >>> sorted(X.keys())\n            [\'id_left\', \'id_right\', \'text_left\', \'text_right\']\n            >>> type(y)\n            <class \'numpy.ndarray\'>\n            >>> X, y = data_pack.drop_label().unpack()\n            >>> type(y)\n            <class \'NoneType\'>\n\n        """"""\n        frame = self.frame()\n\n        columns = list(frame.columns)\n        if self.has_label:\n            columns.remove(\'label\')\n            y = np.vstack(np.asarray(frame[\'label\']))\n        else:\n            y = None\n\n        x = frame[columns].to_dict(orient=\'list\')\n        for key, val in x.items():\n            x[key] = np.array(val)\n\n        return x, y\n\n    def __getitem__(self, index: typing.Union[int, slice, np.array]\n                    ) -> \'DataPack\':\n        """"""\n        Get specific item(s) as a new :class:`DataPack`.\n\n        The returned :class:`DataPack` will be a copy of the subset of the\n        original :class:`DataPack`.\n\n        :param index: Index of the item(s) to get.\n        :return: An instance of :class:`DataPack`.\n        """"""\n        index = _convert_to_list_index(index, len(self))\n        relation = self._relation.loc[index].reset_index(drop=True)\n        left = self._left.loc[relation[\'id_left\'].unique()]\n        right = self._right.loc[relation[\'id_right\'].unique()]\n        return DataPack(left=left.copy(),\n                        right=right.copy(),\n                        relation=relation.copy())\n\n    @property\n    def relation(self):\n        """"""`relation` getter.""""""\n        return self._relation\n\n    @relation.setter\n    def relation(self, value):\n        """"""`relation` setter.""""""\n        self._relation = value\n\n    @property\n    def left(self) -> pd.DataFrame:\n        """"""Get :meth:`left` of :class:`DataPack`.""""""\n        return self._left\n\n    @property\n    def right(self) -> pd.DataFrame:\n        """"""Get :meth:`right` of :class:`DataPack`.""""""\n        return self._right\n\n    def copy(self) -> \'DataPack\':\n        """""":return: A deep copy.""""""\n        return DataPack(left=self._left.copy(),\n                        right=self._right.copy(),\n                        relation=self._relation.copy())\n\n    def save(self, dirpath: typing.Union[str, Path]):\n        """"""\n        Save the :class:`DataPack` object.\n\n        A saved :class:`DataPack` is represented as a directory with a\n        :class:`DataPack` object (transformed user input as features and\n        context), it will be saved by `pickle`.\n\n        :param dirpath: directory path of the saved :class:`DataPack`.\n        """"""\n        dirpath = Path(dirpath)\n        data_file_path = dirpath.joinpath(self.DATA_FILENAME)\n\n        if not dirpath.exists():\n            dirpath.mkdir(parents=True)\n\n        dill.dump(self, open(data_file_path, mode=\'wb\'))\n\n    def _optional_inplace(func):\n        """"""\n        Decorator that adds `inplace` key word argument to a method.\n\n        Decorate any method that modifies inplace to make that inplace change\n        optional.\n        """"""\n        doc = "":param inplace: `True` to modify inplace, `False` to return "" \\\n              ""a modified copy. (default: `False`)""\n\n        def _clean(s):\n            return s.replace(\' \', \'\').replace(\'\\n\', \'\')\n\n        if _clean(doc) not in _clean(inspect.getdoc(func)):\n            raise NotImplementedError(\n                f""`inplace` parameter of {func} not documented.\\n""\n                f""Please add the following line to its documentation:\\n{doc}"")\n\n        @functools.wraps(func)\n        def wrapper(\n            self, *args, inplace: bool = False, **kwargs\n        ) -> typing.Optional[\'DataPack\']:\n\n            if inplace:\n                target = self\n            else:\n                target = self.copy()\n\n            func(target, *args, **kwargs)\n\n            if not inplace:\n                return target\n\n        return wrapper\n\n    @_optional_inplace\n    def drop_empty(self):\n        """"""\n        Process empty data by removing corresponding rows.\n\n        :param inplace: `True` to modify inplace, `False` to return a modified\n            copy. (default: `False`)\n        """"""\n        empty_left_id = self._left[\n            self._left[\'length_left\'] == 0].index.tolist()\n        empty_right_id = self._right[\n            self._right[\'length_right\'] == 0].index.tolist()\n        empty_id = self._relation[\n            self._relation[\'id_left\'].isin(empty_left_id) | self._relation[\n                \'id_right\'].isin(empty_right_id)\n        ].index.tolist()\n\n        self._left = self._left.drop(empty_left_id)\n        self._right = self._right.drop(empty_right_id)\n        self._relation = self._relation.drop(empty_id)\n        self._relation.reset_index(drop=True, inplace=True)\n\n    @_optional_inplace\n    def shuffle(self):\n        """"""\n        Shuffle the data pack by shuffling the relation column.\n\n        :param inplace: `True` to modify inplace, `False` to return a modified\n            copy. (default: `False`)\n\n        Example:\n            >>> import matchzoo as mz\n            >>> import numpy.random\n            >>> numpy.random.seed(0)\n            >>> data_pack = mz.datasets.toy.load_data()\n            >>> orig_ids = data_pack.relation[\'id_left\']\n            >>> shuffled = data_pack.shuffle()\n            >>> (shuffled.relation[\'id_left\'] != orig_ids).any()\n            True\n\n        """"""\n        self._relation = self._relation.sample(frac=1)\n        self._relation.reset_index(drop=True, inplace=True)\n\n    @_optional_inplace\n    def drop_label(self):\n        """"""\n        Remove `label` column from the data pack.\n\n        :param inplace: `True` to modify inplace, `False` to return a modified\n            copy. (default: `False`)\n\n        Example:\n            >>> import matchzoo as mz\n            >>> data_pack = mz.datasets.toy.load_data()\n            >>> data_pack.has_label\n            True\n            >>> data_pack.drop_label(inplace=True)\n            >>> data_pack.has_label\n            False\n        """"""\n        self._relation = self._relation.drop(columns=\'label\')\n\n    @_optional_inplace\n    def append_text_length(self, verbose=1):\n        """"""\n        Append `length_left` and `length_right` columns.\n\n        :param inplace: `True` to modify inplace, `False` to return a modified\n            copy. (default: `False`)\n        :param verbose: Verbosity.\n\n        Example:\n            >>> import matchzoo as mz\n            >>> data_pack = mz.datasets.toy.load_data()\n            >>> \'length_left\' in data_pack.frame[0].columns\n            False\n            >>> new_data_pack = data_pack.append_text_length(verbose=0)\n            >>> \'length_left\' in new_data_pack.frame[0].columns\n            True\n            >>> \'length_left\' in data_pack.frame[0].columns\n            False\n            >>> data_pack.append_text_length(inplace=True, verbose=0)\n            >>> \'length_left\' in data_pack.frame[0].columns\n            True\n\n        """"""\n        self.apply_on_text(len, rename=(\'length_left\', \'length_right\'),\n                           inplace=True, verbose=verbose)\n\n    @_optional_inplace\n    def apply_on_text(\n        self, func: typing.Callable,\n        mode: str = \'both\',\n        rename: typing.Optional[str] = None,\n        verbose: int = 1\n    ):\n        """"""\n        Apply `func` to text columns based on `mode`.\n\n        :param func: The function to apply.\n        :param mode: One of ""both"", ""left"" and ""right"".\n        :param rename: If set, use new names for results instead of replacing\n            the original columns. To set `rename` in ""both"" mode, use a tuple\n            of `str`, e.g. (""text_left_new_name"", ""text_right_new_name"").\n        :param inplace: `True` to modify inplace, `False` to return a modified\n            copy. (default: `False`)\n        :param verbose: Verbosity.\n\n        Examples::\n            >>> import matchzoo as mz\n            >>> data_pack = mz.datasets.toy.load_data()\n            >>> frame = data_pack.frame\n\n        To apply `len` on the left text and add the result as \'length_left\':\n            >>> data_pack.apply_on_text(len, mode=\'left\',\n            ...                         rename=\'length_left\',\n            ...                         inplace=True,\n            ...                         verbose=0)\n            >>> list(frame[0].columns) # noqa: E501\n            [\'id_left\', \'text_left\', \'length_left\', \'id_right\', \'text_right\', \'label\']\n\n        To do the same to the right text:\n            >>> data_pack.apply_on_text(len, mode=\'right\',\n            ...                         rename=\'length_right\',\n            ...                         inplace=True,\n            ...                         verbose=0)\n            >>> list(frame[0].columns) # noqa: E501\n            [\'id_left\', \'text_left\', \'length_left\', \'id_right\', \'text_right\', \'length_right\', \'label\']\n\n        To do the same to the both texts at the same time:\n            >>> data_pack.apply_on_text(len, mode=\'both\',\n            ...                         rename=(\'extra_left\', \'extra_right\'),\n            ...                         inplace=True,\n            ...                         verbose=0)\n            >>> list(frame[0].columns) # noqa: E501\n            [\'id_left\', \'text_left\', \'length_left\', \'extra_left\', \'id_right\', \'text_right\', \'length_right\', \'extra_right\', \'label\']\n\n        To suppress outputs:\n            >>> data_pack.apply_on_text(len, mode=\'both\', verbose=0,\n            ...                         inplace=True)\n\n        """"""\n        if mode == \'both\':\n            self._apply_on_text_both(func, rename, verbose=verbose)\n        elif mode == \'left\':\n            self._apply_on_text_left(func, rename, verbose=verbose)\n        elif mode == \'right\':\n            self._apply_on_text_right(func, rename, verbose=verbose)\n        else:\n            raise ValueError(f""{mode} is not a valid mode type.""\n                             f""Must be one of `left` `right` `both`."")\n\n    def _apply_on_text_right(self, func, rename, verbose=1):\n        name = rename or \'text_right\'\n        if verbose:\n            tqdm.pandas(desc=""Processing "" + name + "" with "" + func.__name__)\n            self._right[name] = self._right[\'text_right\'].progress_apply(func)\n        else:\n            self._right[name] = self._right[\'text_right\'].apply(func)\n\n    def _apply_on_text_left(self, func, rename, verbose=1):\n        name = rename or \'text_left\'\n        if verbose:\n            tqdm.pandas(desc=""Processing "" + name + "" with "" + func.__name__)\n            self._left[name] = self._left[\'text_left\'].progress_apply(func)\n        else:\n            self._left[name] = self._left[\'text_left\'].apply(func)\n\n    def _apply_on_text_both(self, func, rename, verbose=1):\n        left_name, right_name = rename or (\'text_left\', \'text_right\')\n        self._apply_on_text_left(func, rename=left_name, verbose=verbose)\n        self._apply_on_text_right(func, rename=right_name, verbose=verbose)\n\n    class FrameView(object):\n        """"""FrameView.""""""\n\n        def __init__(self, data_pack: \'DataPack\'):\n            """"""\n            View a data pack as a frame.\n\n            A slice of the view is genereated by merging three parts of the\n            data pack being viewed into a big table.\n\n            :param data_pack: :class:`DataPack` to view.\n\n            Examples::\n                >>> import matchzoo as mz\n                >>> data_pack = mz.datasets.toy.load_data()\n                >>> frame = data_pack.frame\n\n            Use `()` to get a full copy of the frame:\n                >>> list(frame().columns)\n                [\'id_left\', \'text_left\', \'id_right\', \'text_right\', \'label\']\n                >>> len(frame()) == len(data_pack)\n                True\n\n            Notice that a view is binded to the original data pack, so changing\n            contents of the data pack will affect a view previously created:\n                >>> data_pack.drop_label(inplace=True)\n                >>> list(frame().columns)\n                [\'id_left\', \'text_left\', \'id_right\', \'text_right\']\n\n            To slice the view:\n                >>> frame_slice = frame[3:5]\n                >>> len(frame_slice)\n                2\n\n            """"""\n            self._data_pack = data_pack\n\n        def __getitem__(self, index: typing.Union[int, slice, np.array]\n                        ) -> pd.DataFrame:\n            """"""Slicer.""""""\n            dp = self._data_pack\n            index = _convert_to_list_index(index, len(dp))\n            left_df = dp.left.loc[dp.relation[\'id_left\'][index]].reset_index()\n            right_df = dp.right.loc[\n                dp.relation[\'id_right\'][index]].reset_index()\n            joined_table = left_df.join(right_df)\n            for column in dp.relation.columns:\n                if column not in [\'id_left\', \'id_right\']:\n                    labels = dp.relation[column][index].to_frame()\n                    labels = labels.reset_index(drop=True)\n                    joined_table = joined_table.join(labels)\n            return joined_table\n\n        def __call__(self):\n            """""":return: A full copy. Equivalant to `frame[:]`.""""""\n            return self[:]\n\n\ndef load_data_pack(dirpath: typing.Union[str, Path]) -> DataPack:\n    """"""\n    Load a :class:`DataPack`. The reverse function of :meth:`save`.\n\n    :param dirpath: directory path of the saved model.\n    :return: a :class:`DataPack` instance.\n    """"""\n    dirpath = Path(dirpath)\n\n    data_file_path = dirpath.joinpath(DataPack.DATA_FILENAME)\n    dp = dill.load(open(data_file_path, \'rb\'))\n\n    return dp\n'"
matchzoo/data_pack/pack.py,0,"b'""""""Convert list of input into class:`DataPack` expected format.""""""\n\nimport typing\n\nimport pandas as pd\nimport numpy as np\n\nimport matchzoo\nfrom matchzoo.engine.base_task import BaseTask\n\n\ndef pack(\n    df: pd.DataFrame,\n    task: typing.Union[str, BaseTask] = \'ranking\',\n) -> \'matchzoo.DataPack\':\n    """"""\n    Pack a :class:`DataPack` using `df`.\n\n    The `df` must have `text_left` and `text_right` columns. Optionally,\n    the `df` can have `id_left`, `id_right` to index `text_left` and\n    `text_right` respectively. `id_left`, `id_right` will be automatically\n    generated if not specified.\n\n    :param df: Input :class:`pandas.DataFrame` to use.\n    :param task: Could be one of `ranking`, `classification` or a\n        :class:`matchzoo.engine.BaseTask` instance.\n\n    Examples::\n        >>> import matchzoo as mz\n        >>> import pandas as pd\n        >>> df = pd.DataFrame(data={\'text_left\': list(\'AABC\'),\n        ...                         \'text_right\': list(\'abbc\'),\n        ...                         \'label\': [0, 1, 1, 0]})\n        >>> mz.pack(df, task=\'classification\').frame()\n          id_left text_left id_right text_right  label\n        0     L-0         A      R-0          a      0\n        1     L-0         A      R-1          b      1\n        2     L-1         B      R-1          b      1\n        3     L-2         C      R-2          c      0\n        >>> mz.pack(df, task=\'ranking\').frame()\n          id_left text_left id_right text_right  label\n        0     L-0         A      R-0          a    0.0\n        1     L-0         A      R-1          b    1.0\n        2     L-1         B      R-1          b    1.0\n        3     L-2         C      R-2          c    0.0\n\n    """"""\n    if \'text_left\' not in df or \'text_right\' not in df:\n        raise ValueError(\n            \'Input data frame must have `text_left` and `text_right`.\')\n\n    df = df.dropna(axis=0, how=\'any\').reset_index(drop=True)\n\n    # Gather IDs\n    if \'id_left\' not in df:\n        id_left = _gen_ids(df, \'text_left\', \'L-\')\n    else:\n        id_left = df[\'id_left\']\n    if \'id_right\' not in df:\n        id_right = _gen_ids(df, \'text_right\', \'R-\')\n    else:\n        id_right = df[\'id_right\']\n\n    # Build Relation\n    relation = pd.DataFrame(data={\'id_left\': id_left, \'id_right\': id_right})\n    for col in df:\n        if col not in [\'id_left\', \'id_right\', \'text_left\', \'text_right\']:\n            relation[col] = df[col]\n    if \'label\' in relation:\n        if task == \'classification\' or isinstance(\n           task, matchzoo.tasks.Classification):\n            relation[\'label\'] = relation[\'label\'].astype(int)\n        elif task == \'ranking\' or isinstance(task, matchzoo.tasks.Ranking):\n            relation[\'label\'] = relation[\'label\'].astype(float)\n        else:\n            raise ValueError(f""{task} is not a valid task."")\n\n    # Build Left and Right\n    left = _merge(df, id_left, \'text_left\', \'id_left\')\n    right = _merge(df, id_right, \'text_right\', \'id_right\')\n    return matchzoo.DataPack(relation, left, right)\n\n\ndef _merge(data: pd.DataFrame, ids: typing.Union[list, np.array],\n           text_label: str, id_label: str):\n    left = pd.DataFrame(data={\n        text_label: data[text_label], id_label: ids\n    })\n    left.drop_duplicates(id_label, inplace=True)\n    left.set_index(id_label, inplace=True)\n    return left\n\n\ndef _gen_ids(data: pd.DataFrame, col: str, prefix: str):\n    lookup = {}\n    for text in data[col].unique():\n        lookup[text] = prefix + str(len(lookup))\n    return data[col].map(lookup)\n'"
matchzoo/dataloader/__init__.py,0,b'from . import callbacks\nfrom .dataset import Dataset\nfrom .dataloader import DataLoader\nfrom .dataloader_builder import DataLoaderBuilder\nfrom .dataset_builder import DatasetBuilder\n'
matchzoo/dataloader/dataloader.py,12,"b'""""""Basic data loader.""""""\r\nimport typing\r\nimport math\r\n\r\nimport numpy as np\r\nimport torch\r\nfrom torch.utils import data\r\n\r\nfrom matchzoo.dataloader.dataset import Dataset\r\nfrom matchzoo.engine.base_callback import BaseCallback\r\n\r\n\r\nclass DataLoader(object):\r\n    """"""\r\n    DataLoader that loads batches of data from a Dataset.\r\n\r\n    :param dataset: The Dataset object to load data from.\r\n    :param device: The desired device of returned tensor. Default: if None,\r\n        use the current device. If `torch.device` or int, use device specified\r\n        by user. If list, the first item will be used.\r\n    :param stage: One of ""train"", ""dev"", and ""test"". (default: ""train"")\r\n    :param callback: BaseCallback. See\r\n        `matchzoo.engine.base_callback.BaseCallback` for more details.\r\n    :param pin_momory: If set to `True`, tensors will be copied into\r\n        pinned memory. (default: `False`)\r\n    :param timeout: The timeout value for collecting a batch from workers. (\r\n        default: 0)\r\n    :param num_workers: The number of subprocesses to use for data loading. 0\r\n        means that the data will be loaded in the main process. (default: 0)\r\n    :param worker_init_fn: If not ``None``, this will be called on each\r\n        worker subprocess with the worker id (an int in [0, num_workers - 1])\r\n        as input, after seeding and before data loading. (default: None)\r\n\r\n    Examples:\r\n        >>> import matchzoo as mz\r\n        >>> data_pack = mz.datasets.toy.load_data(stage=\'train\')\r\n        >>> preprocessor = mz.preprocessors.BasicPreprocessor()\r\n        >>> data_processed = preprocessor.fit_transform(data_pack)\r\n        >>> dataset = mz.dataloader.Dataset(\r\n        ...     data_processed, mode=\'point\', batch_size=32)\r\n        >>> padding_callback = mz.dataloader.callbacks.BasicPadding()\r\n        >>> dataloader = mz.dataloader.DataLoader(\r\n        ...     dataset, stage=\'train\', callback=padding_callback)\r\n        >>> len(dataloader)\r\n        4\r\n\r\n    """"""\r\n\r\n    def __init__(\r\n        self,\r\n        dataset: Dataset,\r\n        device: typing.Union[torch.device, int, list, None] = None,\r\n        stage=\'train\',\r\n        callback: BaseCallback = None,\r\n        pin_memory: bool = False,\r\n        timeout: int = 0,\r\n        num_workers: int = 0,\r\n        worker_init_fn=None,\r\n    ):\r\n        """"""Init.""""""\r\n        if stage not in (\'train\', \'dev\', \'test\'):\r\n            raise ValueError(f""{stage} is not a valid stage type.""\r\n                             f""Must be one of `train`, `dev`, `test`."")\r\n\r\n        if isinstance(device, list) and len(device):\r\n            device = device[0]\r\n        elif not (isinstance(device, torch.device) or isinstance(device, int)):\r\n            device = torch.device(\r\n                ""cuda"" if torch.cuda.is_available() else ""cpu"")\r\n\r\n        self._dataset = dataset\r\n        self._pin_momory = pin_memory\r\n        self._timeout = timeout\r\n        self._num_workers = num_workers\r\n        self._worker_init_fn = worker_init_fn\r\n        self._device = device\r\n        self._stage = stage\r\n        self._callback = callback\r\n\r\n        self._dataloader = data.DataLoader(\r\n            self._dataset,\r\n            batch_size=None,\r\n            shuffle=False,\r\n            collate_fn=lambda x: x,\r\n            batch_sampler=None,\r\n            num_workers=self._num_workers,\r\n            pin_memory=self._pin_momory,\r\n            timeout=self._timeout,\r\n            worker_init_fn=self._worker_init_fn,\r\n        )\r\n\r\n    def __len__(self) -> int:\r\n        """"""Get the total number of batches.""""""\r\n        return len(self._dataset)\r\n\r\n    @property\r\n    def id_left(self) -> np.ndarray:\r\n        """"""`id_left` getter.""""""\r\n        x, _ = self._dataset[:]\r\n        return x[\'id_left\']\r\n\r\n    @property\r\n    def label(self) -> np.ndarray:\r\n        """"""`label` getter.""""""\r\n        _, y = self._dataset[:]\r\n        return y.squeeze() if y is not None else None\r\n\r\n    def __iter__(self) -> typing.Tuple[dict, torch.tensor]:\r\n        """"""Iteration.""""""\r\n        for batch_data in self._dataloader:\r\n            x, y = batch_data\r\n            self._handle_callbacks_on_batch_unpacked(x, y)\r\n\r\n            batch_x = {}\r\n            for key, value in x.items():\r\n                if key == \'id_left\' or key == \'id_right\':\r\n                    continue\r\n                batch_x[key] = torch.tensor(\r\n                    value, device=self._device)\r\n\r\n            if self._stage == \'test\':\r\n                yield batch_x, None\r\n            else:\r\n                if y.dtype == \'int\':  # task=\'classification\'\r\n                    batch_y = torch.tensor(\r\n                        y.squeeze(axis=-1), dtype=torch.long, device=self._device)\r\n                else:  # task=\'ranking\'\r\n                    batch_y = torch.tensor(\r\n                        y, dtype=torch.float, device=self._device)\r\n                yield batch_x, batch_y\r\n\r\n    def _handle_callbacks_on_batch_unpacked(self, x, y):\r\n        if self._callback is not None:\r\n            self._callback.on_batch_unpacked(x, y)\r\n'"
matchzoo/dataloader/dataloader_builder.py,0,"b'import matchzoo as mz\nfrom matchzoo.dataloader import DataLoader\n\n\nclass DataLoaderBuilder(object):\n    """"""\n    DataLoader Bulider. In essense a wrapped partial function.\n\n    Example:\n        >>> import matchzoo as mz\n        >>> padding_callback = mz.dataloader.callbacks.BasicPadding()\n        >>> builder = mz.dataloader.DataLoaderBuilder(\n        ...     stage=\'train\', callback=padding_callback\n        ... )\n        >>> data_pack = mz.datasets.toy.load_data()\n        >>> preprocessor = mz.preprocessors.BasicPreprocessor()\n        >>> data_processed = preprocessor.fit_transform(data_pack)\n        >>> dataset = mz.dataloader.Dataset(data_processed, mode=\'point\')\n        >>> dataloder = builder.build(dataset)\n        >>> type(dataloder)\n        <class \'matchzoo.dataloader.dataloader.DataLoader\'>\n\n    """"""\n\n    def __init__(self, **kwargs):\n        """"""Init.""""""\n        self._kwargs = kwargs\n\n    def build(self, dataset, **kwargs) -> DataLoader:\n        """"""\n        Build a DataLoader.\n\n        :param dataset: Dataset to build upon.\n        :param kwargs: Additional keyword arguments to override the keyword\n            arguments passed in `__init__`.\n        """"""\n        return mz.dataloader.DataLoader(\n            dataset, **{**self._kwargs, **kwargs}\n        )\n'"
matchzoo/dataloader/dataset.py,1,"b'""""""A basic class representing a Dataset.""""""\r\nimport typing\r\nimport math\r\nfrom collections import Iterable\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom torch.utils import data\r\n\r\nimport matchzoo as mz\r\nfrom matchzoo.engine.base_callback import BaseCallback\r\n\r\n\r\nclass Dataset(data.IterableDataset):\r\n    """"""\r\n    Dataset that is built from a data pack.\r\n\r\n    :param data_pack: DataPack to build the dataset.\r\n    :param mode: One of ""point"", ""pair"", and ""list"". (default: ""point"")\r\n    :param num_dup: Number of duplications per instance, only effective when\r\n        `mode` is ""pair"". (default: 1)\r\n    :param num_neg: Number of negative samples per instance, only effective\r\n        when `mode` is ""pair"". (default: 1)\r\n    :param batch_size: Batch size. (default: 32)\r\n    :param resample: Either to resample for each epoch, only effective when\r\n        `mode` is ""pair"". (default: `True`)\r\n    :param shuffle: Either to shuffle the samples/instances. (default: `True`)\r\n    :param sort: Whether to sort data according to length_right. (default: `False`)\r\n    :param callbacks: Callbacks. See `matchzoo.dataloader.callbacks` for more details.\r\n\r\n    Examples:\r\n        >>> import matchzoo as mz\r\n        >>> data_pack = mz.datasets.toy.load_data(stage=\'train\')\r\n        >>> preprocessor = mz.preprocessors.BasicPreprocessor()\r\n        >>> data_processed = preprocessor.fit_transform(data_pack)\r\n        >>> dataset_point = mz.dataloader.Dataset(\r\n        ...     data_processed, mode=\'point\', batch_size=32)\r\n        >>> len(dataset_point)\r\n        4\r\n        >>> dataset_pair = mz.dataloader.Dataset(\r\n        ...     data_processed, mode=\'pair\', num_dup=2, num_neg=2, batch_size=32)\r\n        >>> len(dataset_pair)\r\n        1\r\n\r\n    """"""\r\n\r\n    def __init__(\r\n        self,\r\n        data_pack: mz.DataPack,\r\n        mode=\'point\',\r\n        num_dup: int = 1,\r\n        num_neg: int = 1,\r\n        batch_size: int = 32,\r\n        resample: bool = False,\r\n        shuffle: bool = True,\r\n        sort: bool = False,\r\n        callbacks: typing.List[BaseCallback] = None\r\n    ):\r\n        """"""Init.""""""\r\n        if callbacks is None:\r\n            callbacks = []\r\n\r\n        if mode not in (\'point\', \'pair\', \'list\'):\r\n            raise ValueError(f""{mode} is not a valid mode type.""\r\n                             f""Must be one of `point`, `pair` or `list`."")\r\n\r\n        if shuffle and sort:\r\n            raise ValueError(f""parameters `shuffle` and `sort` conflict, ""\r\n                             f""should not both be `True`."")\r\n\r\n        data_pack = data_pack.copy()\r\n        self._mode = mode\r\n        self._num_dup = num_dup\r\n        self._num_neg = num_neg\r\n        self._batch_size = batch_size\r\n        self._resample = (resample if mode != \'point\' else False)\r\n        self._shuffle = shuffle\r\n        self._sort = sort\r\n        self._orig_relation = data_pack.relation\r\n        self._callbacks = callbacks\r\n\r\n        if mode == \'pair\':\r\n            data_pack.relation = self._reorganize_pair_wise(\r\n                relation=self._orig_relation,\r\n                num_dup=num_dup,\r\n                num_neg=num_neg\r\n            )\r\n\r\n        self._data_pack = data_pack\r\n        self._batch_indices = None\r\n\r\n        self.reset_index()\r\n\r\n    def __getitem__(self, item) -> typing.Tuple[dict, np.ndarray]:\r\n        """"""Get a batch from index idx.\r\n\r\n        :param item: the index of the batch.\r\n        """"""\r\n        if isinstance(item, slice):\r\n            indices = sum(self._batch_indices[item], [])\r\n        elif isinstance(item, Iterable):\r\n            indices = [self._batch_indices[i] for i in item]\r\n        else:\r\n            indices = self._batch_indices[item]\r\n        batch_data_pack = self._data_pack[indices]\r\n        self._handle_callbacks_on_batch_data_pack(batch_data_pack)\r\n        x, y = batch_data_pack.unpack()\r\n        self._handle_callbacks_on_batch_unpacked(x, y)\r\n        return x, y\r\n\r\n    def __len__(self) -> int:\r\n        """"""Get the total number of batches.""""""\r\n        return len(self._batch_indices)\r\n\r\n    def __iter__(self):\r\n        """"""Create a generator that iterate over the Batches.""""""\r\n        if self._resample or self._shuffle:\r\n            self.on_epoch_end()\r\n        for i in range(len(self)):\r\n            yield self[i]\r\n\r\n    def on_epoch_end(self):\r\n        """"""Reorganize the index array if needed.""""""\r\n        if self._resample:\r\n            self.resample_data()\r\n        self.reset_index()\r\n\r\n    def resample_data(self):\r\n        """"""Reorganize data.""""""\r\n        if self.mode != \'point\':\r\n            self._data_pack.relation = self._reorganize_pair_wise(\r\n                relation=self._orig_relation,\r\n                num_dup=self._num_dup,\r\n                num_neg=self._num_neg\r\n            )\r\n\r\n    def reset_index(self):\r\n        """"""\r\n        Set the :attr:`_batch_indices`.\r\n\r\n        Here the :attr:`_batch_indices` records the index of all the instances.\r\n        """"""\r\n        # index pool: index -> instance index\r\n        if self._mode == \'point\':\r\n            num_instances = len(self._data_pack)\r\n            index_pool = list(range(num_instances))\r\n        elif self._mode == \'pair\':\r\n            index_pool = []\r\n            step_size = self._num_neg + 1\r\n            num_instances = int(len(self._data_pack) / step_size)\r\n            for i in range(num_instances):\r\n                lower = i * step_size\r\n                upper = (i + 1) * step_size\r\n                indices = list(range(lower, upper))\r\n                if indices:\r\n                    index_pool.append(indices)\r\n        elif self._mode == \'list\':\r\n            raise NotImplementedError(\r\n                f\'{self._mode} dataset not implemented.\')\r\n        else:\r\n            raise ValueError(f""{self._mode} is not a valid mode type""\r\n                             f""Must be one of `point`, `pair` or `list`."")\r\n\r\n        if self._shuffle:\r\n            np.random.shuffle(index_pool)\r\n\r\n        if self._sort:\r\n            old_index_pool = index_pool\r\n\r\n            max_instance_right_length = []\r\n            for row in range(len(old_index_pool)):\r\n                instance = self._data_pack[old_index_pool[row]].unpack()[0]\r\n                max_instance_right_length.append(max(instance[\'length_right\']))\r\n            sort_index = np.argsort(max_instance_right_length)\r\n\r\n            index_pool = [old_index_pool[index] for index in sort_index]\r\n\r\n        # batch_indices: index -> batch of indices\r\n        self._batch_indices = []\r\n        for i in range(math.ceil(num_instances / self._batch_size)):\r\n            lower = self._batch_size * i\r\n            upper = self._batch_size * (i + 1)\r\n            candidates = index_pool[lower:upper]\r\n            if self._mode == \'pair\':\r\n                candidates = sum(candidates, [])\r\n            self._batch_indices.append(candidates)\r\n\r\n    def _handle_callbacks_on_batch_data_pack(self, batch_data_pack):\r\n        for callback in self._callbacks:\r\n            callback.on_batch_data_pack(batch_data_pack)\r\n\r\n    def _handle_callbacks_on_batch_unpacked(self, x, y):\r\n        for callback in self._callbacks:\r\n            callback.on_batch_unpacked(x, y)\r\n\r\n    @property\r\n    def callbacks(self):\r\n        """"""`callbacks` getter.""""""\r\n        return self._callbacks\r\n\r\n    @callbacks.setter\r\n    def callbacks(self, value):\r\n        """"""`callbacks` setter.""""""\r\n        self._callbacks = value\r\n\r\n    @property\r\n    def num_neg(self):\r\n        """"""`num_neg` getter.""""""\r\n        return self._num_neg\r\n\r\n    @num_neg.setter\r\n    def num_neg(self, value):\r\n        """"""`num_neg` setter.""""""\r\n        self._num_neg = value\r\n        self.resample_data()\r\n        self.reset_index()\r\n\r\n    @property\r\n    def num_dup(self):\r\n        """"""`num_dup` getter.""""""\r\n        return self._num_dup\r\n\r\n    @num_dup.setter\r\n    def num_dup(self, value):\r\n        """"""`num_dup` setter.""""""\r\n        self._num_dup = value\r\n        self.resample_data()\r\n        self.reset_index()\r\n\r\n    @property\r\n    def mode(self):\r\n        """"""`mode` getter.""""""\r\n        return self._mode\r\n\r\n    @property\r\n    def batch_size(self):\r\n        """"""`batch_size` getter.""""""\r\n        return self._batch_size\r\n\r\n    @batch_size.setter\r\n    def batch_size(self, value):\r\n        """"""`batch_size` setter.""""""\r\n        self._batch_size = value\r\n        self.reset_index()\r\n\r\n    @property\r\n    def shuffle(self):\r\n        """"""`shuffle` getter.""""""\r\n        return self._shuffle\r\n\r\n    @shuffle.setter\r\n    def shuffle(self, value):\r\n        """"""`shuffle` setter.""""""\r\n        self._shuffle = value\r\n        self.reset_index()\r\n\r\n    @property\r\n    def sort(self):\r\n        """"""`sort` getter.""""""\r\n        return self._sort\r\n\r\n    @sort.setter\r\n    def sort(self, value):\r\n        """"""`sort` setter.""""""\r\n        self._sort = value\r\n        self.reset_index()\r\n\r\n    @property\r\n    def resample(self):\r\n        """"""`resample` getter.""""""\r\n        return self._resample\r\n\r\n    @resample.setter\r\n    def resample(self, value):\r\n        """"""`resample` setter.""""""\r\n        self._resample = value\r\n        self.reset_index()\r\n\r\n    @property\r\n    def batch_indices(self):\r\n        """"""`batch_indices` getter.""""""\r\n        return self._batch_indices\r\n\r\n    @classmethod\r\n    def _reorganize_pair_wise(\r\n        cls,\r\n        relation: pd.DataFrame,\r\n        num_dup: int = 1,\r\n        num_neg: int = 1\r\n    ):\r\n        """"""Re-organize the data pack as pair-wise format.""""""\r\n        pairs = []\r\n        groups = relation.sort_values(\r\n            \'label\', ascending=False).groupby(\'id_left\')\r\n        for _, group in groups:\r\n            labels = group.label.unique()\r\n            for label in labels[:-1]:\r\n                pos_samples = group[group.label == label]\r\n                pos_samples = pd.concat([pos_samples] * num_dup)\r\n                neg_samples = group[group.label < label]\r\n                for _, pos_sample in pos_samples.iterrows():\r\n                    pos_sample = pd.DataFrame([pos_sample])\r\n                    neg_sample = neg_samples.sample(num_neg, replace=True)\r\n                    pairs.extend((pos_sample, neg_sample))\r\n        new_relation = pd.concat(pairs, ignore_index=True)\r\n        return new_relation\r\n'"
matchzoo/dataloader/dataset_builder.py,0,"b'import matchzoo as mz\nfrom matchzoo.dataloader import Dataset\n\n\nclass DatasetBuilder(object):\n    """"""\n    Dataset Bulider. In essense a wrapped partial function.\n\n    Example:\n        >>> import matchzoo as mz\n        >>> builder = mz.dataloader.DatasetBuilder(\n        ...     mode=\'point\'\n        ... )\n        >>> data = mz.datasets.toy.load_data()\n        >>> gen = builder.build(data)\n        >>> type(gen)\n        <class \'matchzoo.dataloader.dataset.Dataset\'>\n\n    """"""\n\n    def __init__(self, **kwargs):\n        """"""Init.""""""\n        self._kwargs = kwargs\n\n    def build(self, data_pack, **kwargs) -> Dataset:\n        """"""\n        Build a Dataset.\n\n        :param data_pack: DataPack to build upon.\n        :param kwargs: Additional keyword arguments to override the keyword\n            arguments passed in `__init__`.\n        """"""\n        return mz.dataloader.Dataset(\n            data_pack, **{**self._kwargs, **kwargs}\n        )\n'"
matchzoo/datasets/__init__.py,0,"b""from . import toy\nfrom . import wiki_qa\nfrom . import embeddings\nfrom . import snli\nfrom . import quora_qp\nfrom pathlib import Path\n\n\ndef list_available():\n    return [p.name for p in Path(__file__).parent.iterdir()\n            if p.is_dir() and not p.name.startswith('_')]\n"""
matchzoo/embedding/__init__.py,0,b'from .embedding import Embedding\nfrom .embedding import load_from_file\n'
matchzoo/embedding/embedding.py,0,"b'""""""Matchzoo toolkit for token embedding.""""""\n\nimport csv\nimport typing\n\nimport numpy as np\nimport pandas as pd\n\nimport matchzoo as mz\n\n\nclass Embedding(object):\n    """"""\n    Embedding class.\n\n    Examples::\n        >>> import matchzoo as mz\n        >>> train_raw = mz.datasets.toy.load_data()\n        >>> pp = mz.preprocessors.NaivePreprocessor()\n        >>> train = pp.fit_transform(train_raw, verbose=0)\n        >>> vocab_unit = mz.build_vocab_unit(train, verbose=0)\n        >>> term_index = vocab_unit.state[\'term_index\']\n        >>> embed_path = mz.datasets.embeddings.EMBED_RANK\n\n    To load from a file:\n        >>> embedding = mz.embedding.load_from_file(embed_path)\n        >>> matrix = embedding.build_matrix(term_index)\n        >>> matrix.shape[0] == len(term_index)\n        True\n\n    To build your own:\n        >>> data = {\'A\':[0, 1], \'B\':[2, 3]}\n        >>> embedding = mz.Embedding(data, 2)\n        >>> matrix = embedding.build_matrix({\'A\': 2, \'B\': 1, \'_PAD\': 0})\n        >>> matrix.shape == (3, 2)\n        True\n\n    """"""\n\n    def __init__(self, data: dict, output_dim: int):\n        """"""\n        Embedding.\n\n        :param data: Dictionary to use as term to vector mapping.\n        :param output_dim: The dimension of embedding.\n        """"""\n        self._data = data\n        self._output_dim = output_dim\n\n    def build_matrix(\n        self,\n        term_index: typing.Union[\n            dict, mz.preprocessors.units.Vocabulary.TermIndex]\n    ) -> np.ndarray:\n        """"""\n        Build a matrix using `term_index`.\n\n        :param term_index: A `dict` or `TermIndex` to build with.\n        :param initializer: A callable that returns a default value for missing\n            terms in data. (default: a random uniform distribution in range)\n            `(-0.2, 0.2)`).\n        :return: A matrix.\n        """"""\n        input_dim = len(term_index)\n        matrix = np.empty((input_dim, self._output_dim))\n\n        valid_keys = self._data.keys()\n        for term, index in term_index.items():\n            if term in valid_keys:\n                matrix[index] = self._data[term]\n            else:\n                matrix[index] = np.random.uniform(-0.2, 0.2, size=self._output_dim)\n\n        return matrix\n\n\ndef load_from_file(file_path: str, mode: str = \'word2vec\') -> Embedding:\n    """"""\n    Load embedding from `file_path`.\n\n    :param file_path: Path to file.\n    :param mode: Embedding file format mode, one of \'word2vec\', \'fasttext\'\n        or \'glove\'.(default: \'word2vec\')\n    :return: An :class:`matchzoo.embedding.Embedding` instance.\n    """"""\n    embedding_data = {}\n    output_dim = 0\n    if mode == \'word2vec\' or mode == \'fasttext\':\n        with open(file_path, \'r\') as f:\n            output_dim = int(f.readline().strip().split(\' \')[-1])\n            for line in f:\n                current_line = line.rstrip().split(\' \')\n                embedding_data[current_line[0]] = current_line[1:]\n    elif mode == \'glove\':\n        with open(file_path, \'r\') as f:\n            output_dim = len(f.readline().rstrip().split(\' \')) - 1\n            f.seek(0)\n            for line in f:\n                current_line = line.rstrip().split(\' \')\n                embedding_data[current_line[0]] = current_line[1:]\n    else:\n        raise TypeError(f""{mode} is not a supported embedding type.""\n                        f""`word2vec`, `fasttext` or `glove` expected."")\n    return Embedding(embedding_data, output_dim)\n'"
matchzoo/engine/__init__.py,0,"b""# `engine` dependencies span across the entire project, so it's better to\n# leave this __init__.py empty, and use `from matchzoo.engine.package import\n# x` or `from matchzoo.engine import package` instead of `from matchzoo\n# import engine`.\n"""
matchzoo/engine/base_callback.py,0,"b'""""""Base callback.""""""\nimport abc\n\nimport numpy as np\n\nimport matchzoo as mz\n\n\nclass BaseCallback(abc.ABC):\n    """"""\n    DataGenerator callback base class.\n\n    To build your own callbacks, inherit `mz.data_generator.callbacks.Callback`\n    and overrides corresponding methods.\n\n    A batch is processed in the following way:\n\n    - slice data pack based on batch index\n    - handle `on_batch_data_pack` callbacks\n    - unpack data pack into x, y\n    - handle `on_batch_x_y` callbacks\n    - return x, y\n\n    """"""\n\n    def on_batch_data_pack(self, data_pack: mz.DataPack):\n        """"""\n        `on_batch_data_pack`.\n\n        :param data_pack: a sliced DataPack before unpacking.\n        """"""\n\n    @abc.abstractmethod\n    def on_batch_unpacked(self, x: dict, y: np.ndarray):\n        """"""\n        `on_batch_unpacked`.\n\n        :param x: unpacked x.\n        :param y: unpacked y.\n        """"""\n'"
matchzoo/engine/base_metric.py,0,"b'""""""Metric base class and some related utilities.""""""\n\nimport abc\n\nimport numpy as np\n\n\nclass BaseMetric(abc.ABC):\n    """"""Metric base class.""""""\n\n    ALIAS = \'base_metric\'\n\n    @abc.abstractmethod\n    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n        """"""\n        Call to compute the metric.\n\n        :param y_true: An array of groud truth labels.\n        :param y_pred: An array of predicted values.\n        :return: Evaluation of the metric.\n        """"""\n\n    @abc.abstractmethod\n    def __repr__(self):\n        """""":return: Formated string representation of the metric.""""""\n\n    def __eq__(self, other):\n        """""":return: `True` if two metrics are equal, `False` otherwise.""""""\n        return (type(self) is type(other)) and (vars(self) == vars(other))\n\n    def __hash__(self):\n        """""":return: Hashing value using the metric as `str`.""""""\n        return str(self).__hash__()\n\n\nclass RankingMetric(BaseMetric):\n    """"""Ranking metric base class.""""""\n\n    ALIAS = \'ranking_metric\'\n\n\nclass ClassificationMetric(BaseMetric):\n    """"""Rangking metric base class.""""""\n\n    ALIAS = \'classification_metric\'\n\n\ndef sort_and_couple(labels: np.array, scores: np.array) -> np.array:\n    """"""Zip the `labels` with `scores` into a single list.""""""\n    couple = list(zip(labels, scores))\n    return np.array(sorted(couple, key=lambda x: x[1], reverse=True))\n'"
matchzoo/engine/base_model.py,3,"b'""""""Base Model.""""""\n\nimport abc\nimport typing\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\nfrom matchzoo.utils import parse_activation\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo import preprocessors\nfrom matchzoo import tasks\n\n\nclass BaseModel(nn.Module, abc.ABC):\n    """"""\n    Abstract base class of all MatchZoo models.\n\n    MatchZoo models are wrapped over pytorch models. `params` is a set of model\n    hyper-parameters that deterministically builds a model. In other words,\n    `params[\'model_class\'](params=params)` of the same `params` always create\n    models with the same structure.\n\n    :param params: Model hyper-parameters. (default: return value from\n        :meth:`get_default_params`)\n\n    Example:\n        >>> BaseModel()  # doctest: +ELLIPSIS\n        Traceback (most recent call last):\n        ...\n        TypeError: Can\'t instantiate abstract class BaseModel ...\n        >>> class MyModel(BaseModel):\n        ...     def build(self):\n        ...         pass\n        ...     def forward(self):\n        ...         pass\n        >>> isinstance(MyModel(), BaseModel)\n        True\n\n    """"""\n\n    def __init__(\n        self,\n        params: typing.Optional[ParamTable] = None\n    ):\n        """"""Init.""""""\n        super().__init__()\n        self._params = params or self.get_default_params()\n\n    @classmethod\n    def get_default_params(\n        cls,\n        with_embedding=False,\n        with_multi_layer_perceptron=False\n    ) -> ParamTable:\n        """"""\n        Model default parameters.\n\n        The common usage is to instantiate :class:`matchzoo.engine.ModelParams`\n            first, then set the model specific parametrs.\n\n        Examples:\n            >>> class MyModel(BaseModel):\n            ...     def build(self):\n            ...         print(self._params[\'num_eggs\'], \'eggs\')\n            ...         print(\'and\', self._params[\'ham_type\'])\n            ...     def forward(self, greeting):\n            ...         print(greeting)\n            ...\n            ...     @classmethod\n            ...     def get_default_params(cls):\n            ...         params = ParamTable()\n            ...         params.add(Param(\'num_eggs\', 512))\n            ...         params.add(Param(\'ham_type\', \'Parma Ham\'))\n            ...         return params\n            >>> my_model = MyModel()\n            >>> my_model.build()\n            512 eggs\n            and Parma Ham\n            >>> my_model(\'Hello MatchZoo!\')\n            Hello MatchZoo!\n\n        Notice that all parameters must be serialisable for the entire model\n        to be serialisable. Therefore, it\'s strongly recommended to use python\n        native data types to store parameters.\n\n        :return: model parameters\n\n        """"""\n        params = ParamTable()\n        params.add(Param(\n            name=\'model_class\', value=cls,\n            desc=""Model class. Used internally for save/load. ""\n                 ""Changing this may cause unexpected behaviors.""\n        ))\n        params.add(Param(\n            name=\'task\',\n            desc=""Decides model output shape, loss, and metrics.""\n        ))\n        params.add(Param(\n            name=\'out_activation_func\', value=None,\n            desc=""Activation function used in output layer.""\n        ))\n        if with_embedding:\n            params.add(Param(\n                name=\'with_embedding\', value=True,\n                desc=""A flag used help `auto` module. Shouldn\'t be changed.""\n            ))\n            params.add(Param(\n                name=\'embedding\',\n                desc=\'FloatTensor containing weights for the Embedding.\',\n                validator=lambda x: isinstance(x, np.ndarray)\n            ))\n            params.add(Param(\n                name=\'embedding_input_dim\',\n                desc=\'Usually equals vocab size + 1. Should be set manually.\'\n            ))\n            params.add(Param(\n                name=\'embedding_output_dim\',\n                desc=\'Should be set manually.\'\n            ))\n            params.add(Param(\n                name=\'padding_idx\', value=0,\n                desc=\'If given, pads the output with the embedding vector at\'\n                     \'padding_idx (initialized to zeros) whenever it encounters\'\n                     \'the index.\'\n            ))\n            params.add(Param(\n                name=\'embedding_freeze\', value=False,\n                desc=\'`True` to freeze embedding layer training, \'\n                     \'`False` to enable embedding parameters.\'\n            ))\n        if with_multi_layer_perceptron:\n            params.add(Param(\n                name=\'with_multi_layer_perceptron\', value=True,\n                desc=""A flag of whether a multiple layer perceptron is used. ""\n                     ""Shouldn\'t be changed.""\n            ))\n            params.add(Param(\n                name=\'mlp_num_units\', value=128,\n                desc=""Number of units in first `mlp_num_layers` layers."",\n                hyper_space=hyper_spaces.quniform(8, 256, 8)\n            ))\n            params.add(Param(\n                name=\'mlp_num_layers\', value=3,\n                desc=""Number of layers of the multiple layer percetron."",\n                hyper_space=hyper_spaces.quniform(1, 6)\n            ))\n            params.add(Param(\n                name=\'mlp_num_fan_out\', value=64,\n                desc=""Number of units of the layer that connects the multiple ""\n                     ""layer percetron and the output."",\n                hyper_space=hyper_spaces.quniform(4, 128, 4)\n            ))\n            params.add(Param(\n                name=\'mlp_activation_func\', value=\'relu\',\n                desc=\'Activation function used in the multiple \'\n                     \'layer perceptron.\'\n            ))\n        return params\n\n    def guess_and_fill_missing_params(self, verbose=1):\n        """"""\n        Guess and fill missing parameters in :attr:`params`.\n\n        Use this method to automatically fill-in other hyper parameters.\n        This involves some guessing so the parameter it fills could be\n        wrong. For example, the default task is `Ranking`, and if we do not\n        set it to `Classification` manaully for data packs prepared for\n        classification, then the shape of the model output and the data will\n        mismatch.\n\n        :param verbose: Verbosity.\n        """"""\n        self._params.get(\'task\').set_default(tasks.Ranking(), verbose)\n        if \'with_embedding\' in self._params:\n            self._params.get(\'embedding_input_dim\').set_default(300, verbose)\n            self._params.get(\'embedding_output_dim\').set_default(300, verbose)\n\n    def _set_param_default(self, name: str,\n                           default_val: str, verbose: int = 0):\n        if self._params[name] is None:\n            self._params[name] = default_val\n            if verbose:\n                print(f""Parameter \\""{name}\\"" set to {default_val}."")\n\n    @classmethod\n    def get_default_preprocessor(\n        cls,\n        truncated_mode: str = \'pre\',\n        truncated_length_left: typing.Optional[int] = None,\n        truncated_length_right: typing.Optional[int] = None,\n        filter_mode: str = \'df\',\n        filter_low_freq: float = 1,\n        filter_high_freq: float = float(\'inf\'),\n        remove_stop_words: bool = False,\n        ngram_size: typing.Optional[int] = None,\n    ) -> BasePreprocessor:\n        """"""\n        Model default preprocessor.\n\n        The preprocessor\'s transform should produce a correctly shaped data\n        pack that can be used for training.\n\n        :return: Default preprocessor.\n        """"""\n        return preprocessors.BasicPreprocessor(\n            truncated_mode=truncated_mode,\n            truncated_length_left=truncated_length_left,\n            truncated_length_right=truncated_length_right,\n            filter_mode=filter_mode,\n            filter_low_freq=filter_low_freq,\n            filter_high_freq=filter_high_freq,\n            remove_stop_words=remove_stop_words,\n            ngram_size=ngram_size\n        )\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = None,\n        fixed_length_right: int = None,\n        pad_word_value: typing.Union[int, str] = 0,\n        pad_word_mode: str = \'pre\',\n        with_ngram: bool = False,\n        fixed_ngram_length: int = None,\n        pad_ngram_value: typing.Union[int, str] = 0,\n        pad_ngram_mode: str = \'pre\'\n    ) -> BaseCallback:\n        """"""\n        Model default padding callback.\n\n        The padding callback\'s on_batch_unpacked would pad a batch of data to\n        a fixed length.\n\n        :return: Default padding callback.\n        """"""\n        return callbacks.BasicPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_word_value=pad_word_value,\n            pad_word_mode=pad_word_mode,\n            with_ngram=with_ngram,\n            fixed_ngram_length=fixed_ngram_length,\n            pad_ngram_value=pad_ngram_value,\n            pad_ngram_mode=pad_ngram_mode\n        )\n\n    @property\n    def params(self) -> ParamTable:\n        """""":return: model parameters.""""""\n        return self._params\n\n    @params.setter\n    def params(self, val):\n        self._params = val\n\n    @abc.abstractmethod\n    def build(self):\n        """"""Build model, each subclass need to implement this method.""""""\n        raise NotImplementedError(\n            ""Build method not implemented in the subclass.""\n        )\n\n    @abc.abstractmethod\n    def forward(self, *input):\n        """"""\n        Defines the computation performed at every call.\n\n        Should be overridden by all subclasses.\n        """"""\n        raise NotImplementedError(\n            ""Forward method not implemented in the subclass.""\n        )\n\n    def _make_embedding_layer(\n        self,\n        num_embeddings: int = 0,\n        embedding_dim: int = 0,\n        freeze: bool = True,\n        embedding: typing.Optional[np.ndarray] = None,\n        **kwargs\n    ) -> nn.Module:\n        """""":return: an embedding module.""""""\n        if isinstance(embedding, np.ndarray):\n            return nn.Embedding.from_pretrained(\n                embeddings=torch.Tensor(embedding),\n                freeze=freeze\n            )\n        else:\n            return nn.Embedding(\n                num_embeddings=num_embeddings,\n                embedding_dim=embedding_dim\n            )\n\n    def _make_default_embedding_layer(\n        self,\n        **kwargs\n    ) -> nn.Module:\n        """""":return: an embedding module.""""""\n        if isinstance(self._params[\'embedding\'], np.ndarray):\n            self._params[\'embedding_input_dim\'] = (\n                self._params[\'embedding\'].shape[0]\n            )\n            self._params[\'embedding_output_dim\'] = (\n                self._params[\'embedding\'].shape[1]\n            )\n            return nn.Embedding.from_pretrained(\n                embeddings=torch.Tensor(self._params[\'embedding\']),\n                freeze=self._params[\'embedding_freeze\'],\n                padding_idx=self._params[\'padding_idx\']\n            )\n        else:\n            return nn.Embedding(\n                num_embeddings=self._params[\'embedding_input_dim\'],\n                embedding_dim=self._params[\'embedding_output_dim\'],\n                padding_idx=self._params[\'padding_idx\']\n            )\n\n    def _make_output_layer(\n        self,\n        in_features: int = 0\n    ) -> nn.Module:\n        """""":return: a correctly shaped torch module for model output.""""""\n        task = self._params[\'task\']\n        if isinstance(task, tasks.Classification):\n            out_features = task.num_classes\n        elif isinstance(task, tasks.Ranking):\n            out_features = 1\n        else:\n            raise ValueError(f""{task} is not a valid task type. ""\n                             f""Must be in `Ranking` and `Classification`."")\n        if self._params[\'out_activation_func\']:\n            return nn.Sequential(\n                nn.Linear(in_features, out_features),\n                parse_activation(self._params[\'out_activation_func\'])\n            )\n        else:\n            return nn.Linear(in_features, out_features)\n\n    def _make_perceptron_layer(\n        self,\n        in_features: int = 0,\n        out_features: int = 0,\n        activation: nn.Module = nn.ReLU()\n    ) -> nn.Module:\n        """""":return: a perceptron layer.""""""\n        return nn.Sequential(\n            nn.Linear(in_features, out_features),\n            activation\n        )\n\n    def _make_multi_layer_perceptron_layer(self, in_features) -> nn.Module:\n        """""":return: a multiple layer perceptron.""""""\n        if not self._params[\'with_multi_layer_perceptron\']:\n            raise AttributeError(\n                \'Parameter `with_multi_layer_perception` not set.\')\n\n        activation = parse_activation(self._params[\'mlp_activation_func\'])\n        mlp_sizes = [\n            in_features,\n            *self._params[\'mlp_num_layers\'] * [self._params[\'mlp_num_units\']],\n            self._params[\'mlp_num_fan_out\']\n        ]\n        mlp = [\n            self._make_perceptron_layer(in_f, out_f, activation)\n            for in_f, out_f in zip(mlp_sizes, mlp_sizes[1:])\n        ]\n        return nn.Sequential(*mlp)\n'"
matchzoo/engine/base_preprocessor.py,0,"b'"""""":class:`BasePreprocessor` define input and ouutput for processors.""""""\n\nimport abc\nimport functools\nimport typing\nfrom pathlib import Path\n\nimport dill\n\nimport matchzoo as mz\n\n\ndef validate_context(func):\n    """"""Validate context in the preprocessor.""""""\n\n    @functools.wraps(func)\n    def transform_wrapper(self, *args, **kwargs):\n        if not self.context:\n            raise ValueError(\'Please call `fit` before calling `transform`.\')\n        return func(self, *args, **kwargs)\n\n    return transform_wrapper\n\n\nclass BasePreprocessor(metaclass=abc.ABCMeta):\n    """"""\n    :class:`BasePreprocessor` to input handle data.\n\n    A preprocessor should be used in two steps. First, `fit`, then,\n    `transform`. `fit` collects information into `context`, which includes\n    everything the preprocessor needs to `transform` together with other\n    useful information for later use. `fit` will only change the\n    preprocessor\'s inner state but not the input data. In contrast,\n    `transform` returns a modified copy of the input data without changing\n    the preprocessor\'s inner state.\n\n    """"""\n\n    DATA_FILENAME = \'preprocessor.dill\'\n\n    def __init__(self):\n        """"""Initialization.""""""\n        self._context = {}\n\n    @property\n    def context(self):\n        """"""Return context.""""""\n        return self._context\n\n    @abc.abstractmethod\n    def fit(\n        self,\n        data_pack: \'mz.DataPack\',\n        verbose: int = 1\n    ) -> \'BasePreprocessor\':\n        """"""\n        Fit parameters on input data.\n\n        This method is an abstract base method, need to be\n        implemented in the child class.\n\n        This method is expected to return itself as a callable\n        object.\n\n        :param data_pack: :class:`Datapack` object to be fitted.\n        :param verbose: Verbosity.\n        """"""\n\n    @abc.abstractmethod\n    def transform(\n        self,\n        data_pack: \'mz.DataPack\',\n        verbose: int = 1\n    ) -> \'mz.DataPack\':\n        """"""\n        Transform input data to expected manner.\n\n        This method is an abstract base method, need to be\n        implemented in the child class.\n\n        :param data_pack: :class:`DataPack` object to be transformed.\n        :param verbose: Verbosity.\n            or list of text-left, text-right tuples.\n        """"""\n\n    def fit_transform(\n        self,\n        data_pack: \'mz.DataPack\',\n        verbose: int = 1\n    ) -> \'mz.DataPack\':\n        """"""\n        Call fit-transform.\n\n        :param data_pack: :class:`DataPack` object to be processed.\n        :param verbose: Verbosity.\n        """"""\n        return self.fit(data_pack, verbose=verbose) \\\n            .transform(data_pack, verbose=verbose)\n\n    def save(self, dirpath: typing.Union[str, Path]):\n        """"""\n        Save the :class:`DSSMPreprocessor` object.\n\n        A saved :class:`DSSMPreprocessor` is represented as a directory with\n        the `context` object (fitted parameters on training data), it will\n        be saved by `pickle`.\n\n        :param dirpath: directory path of the saved :class:`DSSMPreprocessor`.\n        """"""\n        dirpath = Path(dirpath)\n        data_file_path = dirpath.joinpath(self.DATA_FILENAME)\n\n        if not dirpath.exists():\n            dirpath.mkdir(parents=True)\n\n        dill.dump(self, open(data_file_path, mode=\'wb\'))\n\n    @classmethod\n    def _default_units(cls) -> list:\n        """"""Prepare needed process units.""""""\n        return [\n            mz.preprocessors.units.tokenize.Tokenize(),\n            mz.preprocessors.units.lowercase.Lowercase(),\n            mz.preprocessors.units.punc_removal.PuncRemoval(),\n        ]\n\n\ndef load_preprocessor(dirpath: typing.Union[str, Path]) -> \'mz.DataPack\':\n    """"""\n    Load the fitted `context`. The reverse function of :meth:`save`.\n\n    :param dirpath: directory path of the saved model.\n    :return: a :class:`DSSMPreprocessor` instance.\n    """"""\n    dirpath = Path(dirpath)\n\n    data_file_path = dirpath.joinpath(BasePreprocessor.DATA_FILENAME)\n    return dill.load(open(data_file_path, \'rb\'))\n'"
matchzoo/engine/base_task.py,0,"b'""""""Base task.""""""\n\nimport typing\nimport abc\n\nimport torch\nfrom torch import nn\n\nfrom matchzoo.engine import base_metric\nfrom matchzoo.utils import parse_metric, parse_loss\n\n\nclass BaseTask(abc.ABC):\n    """"""Base Task, shouldn\'t be used directly.""""""\n\n    TYPE = \'base\'\n\n    def __init__(self, losses=None, metrics=None):\n        """"""\n        Base task constructor.\n\n        :param losses: Losses of task.\n        :param metrics: Metrics for evaluating.\n        """"""\n        self._losses = self._convert(losses, parse_loss)\n        self._metrics = self._convert(metrics, parse_metric)\n        self._assure_losses()\n        self._assure_metrics()\n\n    def _convert(self, identifiers, parse):\n        if not identifiers:\n            identifiers = []\n        elif not isinstance(identifiers, list):\n            identifiers = [identifiers]\n        return [\n            parse(identifier, self.__class__.TYPE)\n            for identifier in identifiers\n        ]\n\n    def _assure_losses(self):\n        if not self._losses:\n            first_available = self.list_available_losses()[0]\n            self._losses = self._convert(first_available, parse_loss)\n\n    def _assure_metrics(self):\n        if not self._metrics:\n            first_available = self.list_available_metrics()[0]\n            self._metrics = self._convert(first_available, parse_metric)\n\n    @property\n    def losses(self):\n        """""":return: Losses used in the task.""""""\n        return self._losses\n\n    @property\n    def metrics(self):\n        """""":return: Metrics used in the task.""""""\n        return self._metrics\n\n    @losses.setter\n    def losses(\n        self,\n        new_losses: typing.Union[\n            typing.List[str],\n            typing.List[nn.Module],\n            str,\n            nn.Module\n        ]\n    ):\n        self._losses = self._convert(new_losses, parse_loss)\n\n    @metrics.setter\n    def metrics(\n        self,\n        new_metrics: typing.Union[\n            typing.List[str],\n            typing.List[base_metric.BaseMetric],\n            str,\n            base_metric.BaseMetric\n        ]\n    ):\n        self._metrics = self._convert(new_metrics, parse_metric)\n\n    @classmethod\n    @abc.abstractmethod\n    def list_available_losses(cls) -> list:\n        """""":return: a list of available losses.""""""\n\n    @classmethod\n    @abc.abstractmethod\n    def list_available_metrics(cls) -> list:\n        """""":return: a list of available metrics.""""""\n\n    @property\n    @abc.abstractmethod\n    def output_shape(self) -> tuple:\n        """""":return: output shape of a single sample of the task.""""""\n\n    @property\n    @abc.abstractmethod\n    def output_dtype(self):\n        """""":return: output data type for specific task.""""""\n'"
matchzoo/engine/hyper_spaces.py,0,"b'""""""Hyper parameter search spaces wrapping `hyperopt`.""""""\nimport typing\nimport numbers\n\nimport hyperopt\nimport hyperopt.pyll.base\n\n\nclass HyperoptProxy(object):\n    """"""\n    Hyperopt proxy class.\n\n    See `hyperopt`\'s documentation for more details:\n    https://github.com/hyperopt/hyperopt/wiki/FMin\n\n    Reason of these wrappers:\n\n        A hyper space in `hyperopt` requires a `label` to instantiate. This\n        `label` is used later as a reference to original hyper space that is\n        sampled. In `matchzoo`, hyper spaces are used in\n        :class:`matchzoo.engine.Param`. Only if a hyper space\'s label\n        matches its parent :class:`matchzoo.engine.Param`\'s name, `matchzoo`\n        can correctly back-refrenced the parameter got sampled. This can be\n        done by asking the user always use the same name for a parameter and\n        its hyper space, but typos can occur. As a result, these wrappers\n        are created to hide hyper spaces\' `label`, and always correctly\n        bind them with its parameter\'s name.\n\n    Examples::\n        >>> import matchzoo as mz\n        >>> from hyperopt.pyll.stochastic import sample\n\n    Basic Usage:\n        >>> model = mz.models.DenseBaseline()\n        >>> sample(model.params.hyper_space)  # doctest: +SKIP\n         {\'mlp_num_layers\': 1.0, \'mlp_num_units\': 274.0}\n\n    Arithmetic Operations:\n        >>> new_space = 2 ** mz.hyper_spaces.quniform(2, 6)\n        >>> model.params.get(\'mlp_num_layers\').hyper_space = new_space\n        >>> sample(model.params.hyper_space)  # doctest: +SKIP\n        {\'mlp_num_layers\': 8.0, \'mlp_num_units\': 292.0}\n\n    """"""\n\n    def __init__(\n        self,\n        hyperopt_func: typing.Callable[..., hyperopt.pyll.Apply],\n        **kwargs\n    ):\n        """"""\n        :class:`HyperoptProxy` constructor.\n\n        :param hyperopt_func: Target `hyperopt.hp` function to proxy.\n        :param kwargs: Keyword arguments of the proxy function, must pass all\n            parameters in `hyperopt_func`.\n        """"""\n        self._func = hyperopt_func\n        self._kwargs = kwargs\n\n    def convert(self, name: str) -> hyperopt.pyll.Apply:\n        """"""\n        Attach `name` as `hyperopt.hp`\'s `label`.\n\n        :param name:\n        :return: a `hyperopt` ready search space\n        """"""\n        return self._func(name, **self._kwargs)\n\n    def __add__(self, other):\n        """"""__add__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: x + y)\n\n    def __radd__(self, other):\n        """"""__radd__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: x + y)\n\n    def __sub__(self, other):\n        """"""__sub__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: x - y)\n\n    def __rsub__(self, other):\n        """"""__rsub__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: y - x)\n\n    def __mul__(self, other):\n        """"""__mul__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: x * y)\n\n    def __rmul__(self, other):\n        """"""__rmul__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: x * y)\n\n    def __truediv__(self, other):\n        """"""__truediv__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: x / y)\n\n    def __rtruediv__(self, other):\n        """"""__rtruediv__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: y / x)\n\n    def __floordiv__(self, other):\n        """"""__floordiv__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: x // y)\n\n    def __rfloordiv__(self, other):\n        """"""__rfloordiv__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: y // x)\n\n    def __pow__(self, other):\n        """"""__pow__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: x ** y)\n\n    def __rpow__(self, other):\n        """"""__rpow__.""""""\n        return _wrap_as_composite_func(self, other, lambda x, y: y ** x)\n\n    def __neg__(self):\n        """"""__neg__.""""""\n        return _wrap_as_composite_func(self, None, lambda x, _: -x)\n\n\ndef _wrap_as_composite_func(self, other, func):\n    def _wrapper(name, **kwargs):\n        return func(self._func(name, **kwargs), other)\n\n    return HyperoptProxy(_wrapper, **self._kwargs)\n\n\nclass choice(HyperoptProxy):\n    """""":func:`hyperopt.hp.choice` proxy.""""""\n\n    def __init__(self, options: list):\n        """"""\n        :func:`hyperopt.hp.choice` proxy.\n\n        :param options: options to search from\n        """"""\n        super().__init__(hyperopt_func=hyperopt.hp.choice, options=options)\n        self._options = options\n\n    def __str__(self):\n        """""":return: `str` representation of the hyper space.""""""\n        return f\'choice in {self._options}\'\n\n\nclass quniform(HyperoptProxy):\n    """""":func:`hyperopt.hp.quniform` proxy.""""""\n\n    def __init__(\n        self,\n        low: numbers.Number,\n        high: numbers.Number,\n        q: numbers.Number = 1\n    ):\n        """"""\n        :func:`hyperopt.hp.quniform` proxy.\n\n        If using with integer values, then `high` is exclusive.\n\n        :param low: lower bound of the space\n        :param high: upper bound of the space\n        :param q: similar to the `step` in the python built-in `range`\n        """"""\n        super().__init__(hyperopt_func=hyperopt.hp.quniform,\n                         low=low,\n                         high=high, q=q)\n        self._low = low\n        self._high = high\n        self._q = q\n\n    def __str__(self):\n        """""":return: `str` representation of the hyper space.""""""\n        return f\'quantitative uniform distribution in  \' \\\n               f\'[{self._low}, {self._high}), with a step size of {self._q}\'\n\n\nclass uniform(HyperoptProxy):\n    """""":func:`hyperopt.hp.uniform` proxy.""""""\n\n    def __init__(\n        self,\n        low: numbers.Number,\n        high: numbers.Number\n    ):\n        """"""\n        :func:`hyperopt.hp.uniform` proxy.\n\n        :param low: lower bound of the space\n        :param high: upper bound of the space\n        """"""\n        super().__init__(hyperopt_func=hyperopt.hp.uniform, low=low, high=high)\n        self._low = low\n        self._high = high\n\n    def __str__(self):\n        """""":return: `str` representation of the hyper space.""""""\n        return f\'uniform distribution in  [{self._low}, {self._high})\'\n\n\ndef sample(space):\n    """"""\n    Take a sample in the hyper space.\n\n    This method is stateless, so the distribution of the samples is different\n    from that of `tune` call. This function just gives a general idea of what\n    a sample from the `space` looks like.\n\n    Example:\n        >>> import matchzoo as mz\n        >>> space = mz.models.DenseBaseline.get_default_params().hyper_space\n        >>> mz.hyper_spaces.sample(space)  # doctest: +ELLIPSIS\n        {\'mlp_num_fan_out\': ...}\n\n    """"""\n    return hyperopt.pyll.stochastic.sample(space)\n'"
matchzoo/engine/param.py,0,"b'""""""Parameter class.""""""\n\nimport inspect\nimport numbers\nimport typing\n\nimport hyperopt.pyll\n\nfrom matchzoo.engine import hyper_spaces\n\n# Both hyperopt native spaces and matchzoo proxies are valid spaces.\nSpaceType = typing.Union[hyperopt.pyll.Apply, hyper_spaces.HyperoptProxy]\n\n\nclass Param(object):\n    """"""\n    Parameter class.\n\n    Basic usages with a name and  value:\n\n        >>> param = Param(\'my_param\', 10)\n        >>> param.name\n        \'my_param\'\n        >>> param.value\n        10\n\n    Use with a validator to make sure the parameter always keeps a valid\n    value.\n\n        >>> param = Param(\n        ...     name=\'my_param\',\n        ...     value=5,\n        ...     validator=lambda x: 0 < x < 20\n        ... )\n        >>> param.validator  # doctest: +ELLIPSIS\n        <function <lambda> at 0x...>\n        >>> param.value\n        5\n        >>> param.value = 10\n        >>> param.value\n        10\n        >>> param.value = -1\n        Traceback (most recent call last):\n            ...\n        ValueError: Validator not satifised.\n        The validator\'s definition is as follows:\n        validator=lambda x: 0 < x < 20\n\n    Use with a hyper space. Setting up a hyper space for a parameter makes the\n    parameter tunable in a :class:`matchzoo.engine.Tuner`.\n\n        >>> from matchzoo.engine.hyper_spaces import quniform\n        >>> param = Param(\n        ...     name=\'positive_num\',\n        ...     value=1,\n        ...     hyper_space=quniform(low=1, high=5)\n        ... )\n        >>> param.hyper_space  # doctest: +ELLIPSIS\n        <matchzoo.engine.hyper_spaces.quniform object at ...>\n        >>> from hyperopt.pyll.stochastic import sample\n        >>> hyperopt_space = param.hyper_space.convert(param.name)\n        >>> samples = [sample(hyperopt_space) for _ in range(64)]\n        >>> set(samples) == {1, 2, 3, 4, 5}\n        True\n\n    The boolean value of a :class:`Param` instance is only `True`\n    when the value is not `None`. This is because some default falsy values\n    like zero or an empty list are valid parameter values. In other words,\n    the boolean value means to be ""if the parameter value is filled"".\n\n        >>> param = Param(\'dropout\')\n        >>> if param:\n        ...     print(\'OK\')\n        >>> param = Param(\'dropout\', 0)\n        >>> if param:\n        ...     print(\'OK\')\n        OK\n\n    A `_pre_assignment_hook` is initialized as a data type convertor if the\n    value is set as a number to keep data type consistency of the parameter.\n    This conversion supports python built-in numbers, `numpy` numbers, and\n    any number that inherits :class:`numbers.Number`.\n\n        >>> param = Param(\'float_param\', 0.5)\n        >>> param.value = 10\n        >>> param.value\n        10.0\n        >>> type(param.value)\n        <class \'float\'>\n\n    """"""\n\n    def __init__(\n        self,\n        name: str,\n        value: typing.Any = None,\n        hyper_space: typing.Optional[SpaceType] = None,\n        validator: typing.Optional[\n            typing.Callable[[typing.Any], bool]] = None,\n        desc: typing.Optional[str] = None,\n    ):\n        """"""\n        Parameter constructor.\n\n        :param name: Name of the parameter.\n        :param value: Value of the parameter, `None` by default, which means\n            ""this parameter is not filled yet.""\n        :param hyper_space: Hyper space of the parameter, `None` by default.\n            If set, then a :class:`matchzoo.engine.ParamTable` that has this\n            parameter will include this `hyper_space` as a part of the\n            parameter table\'s search space.\n        :param validator: Validator of the parameter, `None` by default. If\n            validation is needed, pass a callable that, given a value, returns\n            a `bool`. The definition of the validator is retrieved when the\n            validation fails, so either use a function or a `lambda` that\n            occupies its own line for better readability.\n        """"""\n        self._name = name\n        self._desc = desc\n\n        self._value = None\n        self._hyper_space = None\n        self._validator = None\n        self._pre_assignment_hook = None\n\n        self.validator = validator\n        self.hyper_space = hyper_space\n\n        if value is not None:  # bypass checking if no default\n            self.value = value\n\n    @property\n    def name(self) -> str:\n        """""":return: Name of the parameter.""""""\n        return self._name\n\n    @property\n    def value(self) -> typing.Any:\n        """""":return: Value of the parameter.""""""\n        return self._value\n\n    @value.setter\n    def value(self, new_value: typing.Any):\n        """"""\n        Set the value of parameter to `new_value`.\n\n        Notice that this setter validates `new_value` before assignment. As\n        a result, if the validaiton fails, the value of the parameter is not\n        changed.\n\n        :param new_value: New value of the parameter to set.\n        """"""\n        if self._pre_assignment_hook:\n            new_value = self._pre_assignment_hook(new_value)\n        self._validate(new_value)\n        self._value = new_value\n        if not self._pre_assignment_hook:\n            self._infer_pre_assignment_hook()\n\n    @property\n    def hyper_space(self) -> SpaceType:\n        """""":return: Hyper space of the parameter.""""""\n        return self._hyper_space\n\n    @hyper_space.setter\n    def hyper_space(self, new_space: SpaceType):\n        """""":param new_space: New space of the parameter to set.""""""\n        self._hyper_space = new_space\n\n    @property\n    def validator(self) -> typing.Callable[[typing.Any], bool]:\n        """""":return: Validator of the parameter.""""""\n        return self._validator\n\n    @validator.setter\n    def validator(self, new_validator: typing.Callable[[typing.Any], bool]):\n        """""":param new_validator: New space of the parameter to set.""""""\n        if new_validator and not callable(new_validator):\n            raise TypeError(""Validator must be a callable or None."")\n        self._validator = new_validator\n\n    @property\n    def desc(self) -> str:\n        """""":return: Parameter description.""""""\n        return self._desc\n\n    @desc.setter\n    def desc(self, value: str):\n        """""":param value: New description of the parameter.""""""\n        self._desc = value\n\n    def _infer_pre_assignment_hook(self):\n        if isinstance(self._value, numbers.Number):\n            self._pre_assignment_hook = lambda x: type(self._value)(x)\n\n    def _validate(self, value):\n        if self._validator:\n            valid = self._validator(value)\n            if not valid:\n                error_msg = ""Validator not satifised.\\n""\n                error_msg += ""The validator\'s definition is as follows:\\n""\n                error_msg += inspect.getsource(self._validator).strip()\n                raise ValueError(error_msg)\n\n    def __bool__(self):\n        """""":return: `False` when the value is `None`, `True` otherwise.""""""\n        return self._value is not None\n\n    def set_default(self, val, verbose=1):\n        """"""\n        Set default value, has no effect if already has a value.\n\n        :param val: Default value to set.\n        :param verbose: Verbosity.\n        """"""\n        if self._value is None:\n            self.value = val\n            if verbose:\n                print(f""Parameter \\""{self._name}\\"" set to {val}."")\n\n    def reset(self):\n        """"""\n        Set the parameter\'s value to `None`, which means ""not set"".\n\n        This method bypasses validator.\n\n        Example:\n            >>> import matchzoo as mz\n            >>> param = mz.Param(\n            ...     name=\'str\', validator=lambda x: isinstance(x, str))\n            >>> param.value = \'hello\'\n            >>> param.value = None\n            Traceback (most recent call last):\n                ...\n            ValueError: Validator not satifised.\n            The validator\'s definition is as follows:\n            name=\'str\', validator=lambda x: isinstance(x, str))\n            >>> param.reset()\n            >>> param.value is None\n            True\n\n        """"""\n        self._value = None\n'"
matchzoo/engine/param_table.py,0,"b'""""""Parameters table class.""""""\n\nimport typing\nimport pandas as pd\nimport collections.abc\n\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine import hyper_spaces\n\n\nclass ParamTable(object):\n    """"""\n    Parameter table class.\n\n    Example:\n\n        >>> params = ParamTable()\n        >>> params.add(Param(\'ham\', \'Parma Ham\'))\n        >>> params.add(Param(\'egg\', \'Over Easy\'))\n        >>> params[\'ham\']\n        \'Parma Ham\'\n        >>> params[\'egg\']\n        \'Over Easy\'\n        >>> print(params)\n        ham                           Parma Ham\n        egg                           Over Easy\n        >>> params.add(Param(\'egg\', \'Sunny side Up\'))\n        Traceback (most recent call last):\n            ...\n        ValueError: Parameter named egg already exists.\n        To re-assign parameter egg value, use `params[""egg""] = value` instead.\n    """"""\n\n    def __init__(self):\n        """"""Parameter table constrctor.""""""\n        self._params = {}\n\n    def add(self, param: Param):\n        """""":param param: parameter to add.""""""\n        if not isinstance(param, Param):\n            raise TypeError(""Only accepts a Param instance."")\n        if param.name in self._params:\n            msg = f""Parameter named {param.name} already exists.\\n"" \\\n                f""To re-assign parameter {param.name} value, "" \\\n                f""use `params[\\""{param.name}\\""] = value` instead.""\n            raise ValueError(msg)\n        self._params[param.name] = param\n\n    def get(self, key) -> Param:\n        """""":return: The parameter in the table named `key`.""""""\n        return self._params[key]\n\n    def set(self, key, param: Param):\n        """"""Set `key` to parameter `param`.""""""\n        if not isinstance(param, Param):\n            raise ValueError(""Only accepts a Param instance."")\n        self._params[key] = param\n\n    @property\n    def hyper_space(self) -> dict:\n        """""":return: Hyper space of the table, a valid `hyperopt` graph.""""""\n        full_space = {}\n        for param in self:\n            if param.hyper_space is not None:\n                param_space = param.hyper_space\n                if isinstance(param_space, hyper_spaces.HyperoptProxy):\n                    param_space = param_space.convert(param.name)\n                full_space[param.name] = param_space\n        return full_space\n\n    def to_frame(self) -> pd.DataFrame:\n        """"""\n        Convert the parameter table into a pandas data frame.\n\n        :return: A `pandas.DataFrame`.\n\n        Example:\n            >>> import matchzoo as mz\n            >>> table = mz.ParamTable()\n            >>> table.add(mz.Param(name=\'x\', value=10, desc=\'my x\'))\n            >>> table.add(mz.Param(name=\'y\', value=20, desc=\'my y\'))\n            >>> table.to_frame()\n              Name Description  Value Hyper-Space\n            0    x        my x     10        None\n            1    y        my y     20        None\n\n        """"""\n        df = pd.DataFrame(data={\n            \'Name\': [p.name for p in self],\n            \'Description\': [p.desc for p in self],\n            \'Value\': [p.value for p in self],\n            \'Hyper-Space\': [p.hyper_space for p in self]\n        }, columns=[\'Name\', \'Description\', \'Value\', \'Hyper-Space\'])\n        return df\n\n    def __getitem__(self, key: str) -> typing.Any:\n        """""":return: The value of the parameter in the table named `key`.""""""\n        return self._params[key].value\n\n    def __setitem__(self, key: str, value: typing.Any):\n        """"""\n        Set the value of the parameter named `key`.\n\n        :param key: Name of the parameter.\n        :param value: New value of the parameter to set.\n        """"""\n        self._params[key].value = value\n\n    def __str__(self):\n        """""":return: Pretty formatted parameter table.""""""\n        return \'\\n\'.join(param.name.ljust(30) + str(param.value)\n                         for param in self._params.values())\n\n    def __iter__(self) -> typing.Iterator:\n        """""":return: A iterator that iterates over all parameter instances.""""""\n        yield from self._params.values()\n\n    def completed(self, exclude: typing.Optional[list] = None) -> bool:\n        """"""\n        Check if all params are filled.\n\n        :param exclude: List of names of parameters that was excluded\n            from being computed.\n\n        :return: `True` if all params are filled, `False` otherwise.\n\n        Example:\n\n            >>> import matchzoo\n            >>> model = matchzoo.models.DenseBaseline()\n            >>> model.params.completed(\n            ...     exclude=[\'task\', \'out_activation_func\', \'embedding\',\n            ...              \'embedding_input_dim\', \'embedding_output_dim\']\n            ... )\n            True\n\n        """"""\n        return all(param for param in self if param.name not in exclude)\n\n    def keys(self) -> collections.abc.KeysView:\n        """""":return: Parameter table keys.""""""\n        return self._params.keys()\n\n    def __contains__(self, item):\n        """""":return: `True` if parameter in parameters.""""""\n        return item in self._params\n\n    def update(self, other: dict):\n        """"""\n        Update `self`.\n\n        Update `self` with the key/value pairs from other, overwriting\n        existing keys. Notice that this does not add new keys to `self`.\n\n        This method is usually used by models to obtain useful information\n        from a preprocessor\'s context.\n\n        :param other: The dictionary used update.\n\n        Example:\n            >>> import matchzoo as mz\n            >>> model = mz.models.DenseBaseline()\n            >>> prpr = model.get_default_preprocessor()\n            >>> _ = prpr.fit(mz.datasets.toy.load_data(), verbose=0)\n            >>> model.params.update(prpr.context)\n\n        """"""\n        for key in other:\n            if key in self:\n                self[key] = other[key]\n'"
matchzoo/losses/__init__.py,0,b'from .rank_cross_entropy_loss import RankCrossEntropyLoss\nfrom .rank_hinge_loss import RankHingeLoss\n'
matchzoo/losses/rank_cross_entropy_loss.py,7,"b'""""""The rank cross entropy loss.""""""\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass RankCrossEntropyLoss(nn.Module):\n    """"""Creates a criterion that measures rank cross entropy loss.""""""\n\n    __constants__ = [\'num_neg\']\n\n    def __init__(self, num_neg: int = 1):\n        """"""\n        :class:`RankCrossEntropyLoss` constructor.\n\n        :param num_neg: Number of negative instances in hinge loss.\n        """"""\n        super().__init__()\n        self.num_neg = num_neg\n\n    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor):\n        """"""\n        Calculate rank cross entropy loss.\n\n        :param y_pred: Predicted result.\n        :param y_true: Label.\n        :return: Rank cross loss.\n        """"""\n        logits = y_pred[::(self.num_neg + 1), :]\n        labels = y_true[::(self.num_neg + 1), :]\n        for neg_idx in range(self.num_neg):\n            neg_logits = y_pred[(neg_idx + 1)::(self.num_neg + 1), :]\n            neg_labels = y_true[(neg_idx + 1)::(self.num_neg + 1), :]\n            logits = torch.cat((logits, neg_logits), dim=-1)\n            labels = torch.cat((labels, neg_labels), dim=-1)\n        return -torch.mean(\n            torch.sum(\n                labels * torch.log(F.softmax(logits, dim=-1) + torch.finfo(float).eps),\n                dim=-1\n            )\n        )\n\n    @property\n    def num_neg(self):\n        """"""`num_neg` getter.""""""\n        return self._num_neg\n\n    @num_neg.setter\n    def num_neg(self, value):\n        """"""`num_neg` setter.""""""\n        self._num_neg = value\n'"
matchzoo/losses/rank_hinge_loss.py,5,"b'""""""The rank hinge loss.""""""\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass RankHingeLoss(nn.Module):\n    """"""\n    Creates a criterion that measures rank hinge loss.\n\n    Given inputs :math:`x1`, :math:`x2`, two 1D mini-batch `Tensors`,\n    and a label 1D mini-batch tensor :math:`y` (containing 1 or -1).\n\n    If :math:`y = 1` then it assumed the first input should be ranked\n    higher (have a larger value) than the second input, and vice-versa\n    for :math:`y = -1`.\n\n    The loss function for each sample in the mini-batch is:\n\n    .. math::\n        loss_{x, y} = max(0, -y * (x1 - x2) + margin)\n    """"""\n\n    __constants__ = [\'num_neg\', \'margin\', \'reduction\']\n\n    def __init__(self, num_neg: int = 1, margin: float = 1.,\n                 reduction: str = \'mean\'):\n        """"""\n        :class:`RankHingeLoss` constructor.\n\n        :param num_neg: Number of negative instances in hinge loss.\n        :param margin: Margin between positive and negative scores.\n            Float. Has a default value of :math:`0`.\n        :param reduction: String. Specifies the reduction to apply to\n            the output: ``\'none\'`` | ``\'mean\'`` | ``\'sum\'``.\n            ``\'none\'``: no reduction will be applied,\n            ``\'mean\'``: the sum of the output will be divided by the\n                number of elements in the output,\n            ``\'sum\'``: the output will be summed.\n        """"""\n        super().__init__()\n        self.num_neg = num_neg\n        self.margin = margin\n        self.reduction = reduction\n\n    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor):\n        """"""\n        Calculate rank hinge loss.\n\n        :param y_pred: Predicted result.\n        :param y_true: Label.\n        :return: Hinge loss computed by user-defined margin.\n        """"""\n        y_pos = y_pred[::(self.num_neg + 1), :]\n        y_neg = []\n        for neg_idx in range(self.num_neg):\n            neg = y_pred[(neg_idx + 1)::(self.num_neg + 1), :]\n            y_neg.append(neg)\n        y_neg = torch.cat(y_neg, dim=-1)\n        y_neg = torch.mean(y_neg, dim=-1, keepdim=True)\n        y_true = torch.ones_like(y_pos)\n        return F.margin_ranking_loss(\n            y_pos, y_neg, y_true,\n            margin=self.margin,\n            reduction=self.reduction\n        )\n\n    @property\n    def num_neg(self):\n        """"""`num_neg` getter.""""""\n        return self._num_neg\n\n    @num_neg.setter\n    def num_neg(self, value):\n        """"""`num_neg` setter.""""""\n        self._num_neg = value\n\n    @property\n    def margin(self):\n        """"""`margin` getter.""""""\n        return self._margin\n\n    @margin.setter\n    def margin(self, value):\n        """"""`margin` setter.""""""\n        self._margin = value\n'"
matchzoo/metrics/__init__.py,0,b'from .precision import Precision\nfrom .average_precision import AveragePrecision\nfrom .discounted_cumulative_gain import DiscountedCumulativeGain\nfrom .mean_reciprocal_rank import MeanReciprocalRank\nfrom .mean_average_precision import MeanAveragePrecision\nfrom .normalized_discounted_cumulative_gain import \\\n    NormalizedDiscountedCumulativeGain\n\nfrom .accuracy import Accuracy\nfrom .cross_entropy import CrossEntropy\n\n\ndef list_available() -> list:\n    from matchzoo.engine.base_metric import BaseMetric\n    from matchzoo.utils import list_recursive_concrete_subclasses\n    return list_recursive_concrete_subclasses(BaseMetric)\n'
matchzoo/metrics/accuracy.py,0,"b'""""""Accuracy metric for Classification.""""""\nimport numpy as np\n\nfrom matchzoo.engine.base_metric import ClassificationMetric\n\n\nclass Accuracy(ClassificationMetric):\n    """"""Accuracy metric.""""""\n\n    ALIAS = [\'accuracy\', \'acc\']\n\n    def __init__(self):\n        """""":class:`Accuracy` constructor.""""""\n\n    def __repr__(self) -> str:\n        """""":return: Formated string representation of the metric.""""""\n        return f""{self.ALIAS[0]}""\n\n    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n        """"""\n        Calculate accuracy.\n\n        Example:\n            >>> import numpy as np\n            >>> y_true = np.array([1])\n            >>> y_pred = np.array([[0, 1]])\n            >>> Accuracy()(y_true, y_pred)\n            1.0\n\n        :param y_true: The ground true label of each document.\n        :param y_pred: The predicted scores of each document.\n        :return: Accuracy.\n        """"""\n        y_pred = np.argmax(y_pred, axis=1)\n        return np.sum(y_pred == y_true) / float(y_true.size)\n'"
matchzoo/metrics/average_precision.py,0,"b'""""""Average precision metric for ranking.""""""\nimport numpy as np\n\nfrom matchzoo.engine.base_metric import RankingMetric\nfrom . import Precision\n\n\nclass AveragePrecision(RankingMetric):\n    """"""Average precision metric.""""""\n\n    ALIAS = [\'average_precision\', \'ap\']\n\n    def __init__(self, threshold: float = 0.):\n        """"""\n        :class:`AveragePrecision` constructor.\n\n        :param threshold: The label threshold of relevance degree.\n        """"""\n        self._threshold = threshold\n\n    def __repr__(self) -> str:\n        """""":return: Formated string representation of the metric.""""""\n        return f""{self.ALIAS[0]}({self._threshold})""\n\n    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n        """"""\n        Calculate average precision (area under PR curve).\n\n        Example:\n            >>> y_true = [0, 1]\n            >>> y_pred = [0.1, 0.6]\n            >>> round(AveragePrecision()(y_true, y_pred), 2)\n            0.75\n            >>> round(AveragePrecision()([], []), 2)\n            0.0\n\n        :param y_true: The ground true label of each document.\n        :param y_pred: The predicted scores of each document.\n        :return: Average precision.\n        """"""\n        precision_metrics = [Precision(k + 1) for k in range(len(y_pred))]\n        out = [metric(y_true, y_pred) for metric in precision_metrics]\n        if not out:\n            return 0.\n        return np.mean(out).item()\n'"
matchzoo/metrics/cross_entropy.py,0,"b'""""""CrossEntropy metric for Classification.""""""\nimport numpy as np\n\nfrom matchzoo.engine.base_metric import ClassificationMetric\nfrom matchzoo.utils import one_hot\n\n\nclass CrossEntropy(ClassificationMetric):\n    """"""Cross entropy metric.""""""\n\n    ALIAS = [\'cross_entropy\', \'ce\']\n\n    def __init__(self):\n        """""":class:`CrossEntropy` constructor.""""""\n\n    def __repr__(self) -> str:\n        """""":return: Formated string representation of the metric.""""""\n        return f""{self.ALIAS[0]}""\n\n    def __call__(\n        self,\n        y_true: np.array,\n        y_pred: np.array,\n        eps: float = 1e-12\n    ) -> float:\n        """"""\n        Calculate cross entropy.\n\n        Example:\n            >>> y_true = [0, 1]\n            >>> y_pred = [[0.25, 0.25], [0.01, 0.90]]\n            >>> CrossEntropy()(y_true, y_pred)\n            0.7458274358333028\n\n        :param y_true: The ground true label of each document.\n        :param y_pred: The predicted scores of each document.\n        :param eps: The Log loss is undefined for p=0 or p=1,\n            so probabilities are clipped to max(eps, min(1 - eps, p)).\n        :return: Average precision.\n        """"""\n        y_pred = np.clip(y_pred, eps, 1. - eps)\n        y_true = [\n            one_hot(y, num_classes=y_pred.shape[1]) for y in y_true\n        ]\n        return -np.sum(y_true * np.log(y_pred + 1e-9)) / y_pred.shape[0]\n'"
matchzoo/metrics/discounted_cumulative_gain.py,0,"b'""""""Discounted cumulative gain metric for ranking.""""""\nimport math\n\nimport numpy as np\n\nfrom matchzoo.engine.base_metric import (\n    BaseMetric, sort_and_couple, RankingMetric\n)\n\n\nclass DiscountedCumulativeGain(RankingMetric):\n    """"""Disconunted cumulative gain metric.""""""\n\n    ALIAS = [\'discounted_cumulative_gain\', \'dcg\']\n\n    def __init__(self, k: int = 1, threshold: float = 0.):\n        """"""\n        :class:`DiscountedCumulativeGain` constructor.\n\n        :param k: Number of results to consider.\n        :param threshold: the label threshold of relevance degree.\n        """"""\n        self._k = k\n        self._threshold = threshold\n\n    def __repr__(self) -> str:\n        """""":return: Formated string representation of the metric.""""""\n        return f""{self.ALIAS[0]}@{self._k}({self._threshold})""\n\n    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n        """"""\n        Calculate discounted cumulative gain (dcg).\n\n        Relevance is positive real values or binary values.\n\n        Example:\n            >>> y_true = [0, 1, 2, 0]\n            >>> y_pred = [0.4, 0.2, 0.5, 0.7]\n            >>> DiscountedCumulativeGain(1)(y_true, y_pred)\n            0.0\n            >>> round(DiscountedCumulativeGain(k=-1)(y_true, y_pred), 2)\n            0.0\n            >>> round(DiscountedCumulativeGain(k=2)(y_true, y_pred), 2)\n            2.73\n            >>> round(DiscountedCumulativeGain(k=3)(y_true, y_pred), 2)\n            2.73\n            >>> type(DiscountedCumulativeGain(k=1)(y_true, y_pred))\n            <class \'float\'>\n\n        :param y_true: The ground true label of each document.\n        :param y_pred: The predicted scores of each document.\n\n        :return: Discounted cumulative gain.\n        """"""\n        if self._k <= 0:\n            return 0.\n        coupled_pair = sort_and_couple(y_true, y_pred)\n        result = 0.\n        for i, (label, score) in enumerate(coupled_pair):\n            if i >= self._k:\n                break\n            if label > self._threshold:\n                result += (math.pow(2., label) - 1.) / math.log(2. + i)\n        return result\n'"
matchzoo/metrics/mean_average_precision.py,0,"b'""""""Mean average precision metric for ranking.""""""\nimport numpy as np\n\nfrom matchzoo.engine.base_metric import (\n    BaseMetric, sort_and_couple, RankingMetric\n)\n\n\nclass MeanAveragePrecision(RankingMetric):\n    """"""Mean average precision metric.""""""\n\n    ALIAS = [\'mean_average_precision\', \'map\']\n\n    def __init__(self, threshold: float = 0.):\n        """"""\n        :class:`MeanAveragePrecision` constructor.\n\n        :param threshold: The threshold of relevance degree.\n        """"""\n        self._threshold = threshold\n\n    def __repr__(self):\n        """""":return: Formated string representation of the metric.""""""\n        return f""{self.ALIAS[0]}({self._threshold})""\n\n    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n        """"""\n        Calculate mean average precision.\n\n        Example:\n            >>> y_true = [0, 1, 0, 0]\n            >>> y_pred = [0.1, 0.6, 0.2, 0.3]\n            >>> MeanAveragePrecision()(y_true, y_pred)\n            1.0\n\n        :param y_true: The ground true label of each document.\n        :param y_pred: The predicted scores of each document.\n        :return: Mean average precision.\n        """"""\n        result = 0.\n        pos = 0\n        coupled_pair = sort_and_couple(y_true, y_pred)\n        for idx, (label, score) in enumerate(coupled_pair):\n            if label > self._threshold:\n                pos += 1.\n                result += pos / (idx + 1.)\n        if pos == 0:\n            return 0.\n        else:\n            return result / pos\n'"
matchzoo/metrics/mean_reciprocal_rank.py,0,"b'""""""Mean reciprocal ranking metric.""""""\nimport numpy as np\n\nfrom matchzoo.engine.base_metric import (\n    BaseMetric, sort_and_couple, RankingMetric\n)\n\n\nclass MeanReciprocalRank(RankingMetric):\n    """"""Mean reciprocal rank metric.""""""\n\n    ALIAS = [\'mean_reciprocal_rank\', \'mrr\']\n\n    def __init__(self, threshold: float = 0.):\n        """"""\n        :class:`MeanReciprocalRankMetric`.\n\n        :param threshold: The label threshold of relevance degree.\n        """"""\n        self._threshold = threshold\n\n    def __repr__(self) -> str:\n        """""":return: Formated string representation of the metric.""""""\n        return f\'{self.ALIAS[0]}({self._threshold})\'\n\n    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n        """"""\n        Calculate reciprocal of the rank of the first relevant item.\n\n        Example:\n            >>> import numpy as np\n            >>> y_pred = np.asarray([0.2, 0.3, 0.7, 1.0])\n            >>> y_true = np.asarray([1, 0, 0, 0])\n            >>> MeanReciprocalRank()(y_true, y_pred)\n            0.25\n\n        :param y_true: The ground true label of each document.\n        :param y_pred: The predicted scores of each document.\n        :return: Mean reciprocal rank.\n        """"""\n        coupled_pair = sort_and_couple(y_true, y_pred)\n        for idx, (label, pred) in enumerate(coupled_pair):\n            if label > self._threshold:\n                return 1. / (idx + 1)\n        return 0.\n'"
matchzoo/metrics/normalized_discounted_cumulative_gain.py,0,"b'""""""Normalized discounted cumulative gain metric for ranking.""""""\nimport numpy as np\n\nfrom matchzoo.engine.base_metric import (\n    BaseMetric, sort_and_couple, RankingMetric\n)\nfrom .discounted_cumulative_gain import DiscountedCumulativeGain\n\n\nclass NormalizedDiscountedCumulativeGain(RankingMetric):\n    """"""Normalized discounted cumulative gain metric.""""""\n\n    ALIAS = [\'normalized_discounted_cumulative_gain\', \'ndcg\']\n\n    def __init__(self, k: int = 1, threshold: float = 0.):\n        """"""\n        :class:`NormalizedDiscountedCumulativeGain` constructor.\n\n        :param k: Number of results to consider\n        :param threshold: the label threshold of relevance degree.\n        """"""\n        self._k = k\n        self._threshold = threshold\n\n    def __repr__(self) -> str:\n        """""":return: Formated string representation of the metric.""""""\n        return f""{self.ALIAS[0]}@{self._k}({self._threshold})""\n\n    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n        """"""\n        Calculate normalized discounted cumulative gain (ndcg).\n\n        Relevance is positive real values or binary values.\n\n        Example:\n            >>> y_true = [0, 1, 2, 0]\n            >>> y_pred = [0.4, 0.2, 0.5, 0.7]\n            >>> ndcg = NormalizedDiscountedCumulativeGain\n            >>> ndcg(k=1)(y_true, y_pred)\n            0.0\n            >>> round(ndcg(k=2)(y_true, y_pred), 2)\n            0.52\n            >>> round(ndcg(k=3)(y_true, y_pred), 2)\n            0.52\n            >>> type(ndcg()(y_true, y_pred))\n            <class \'float\'>\n\n        :param y_true: The ground true label of each document.\n        :param y_pred: The predicted scores of each document.\n\n        :return: Normalized discounted cumulative gain.\n        """"""\n        dcg_metric = DiscountedCumulativeGain(k=self._k,\n                                              threshold=self._threshold)\n        idcg_val = dcg_metric(y_true, y_true)\n        dcg_val = dcg_metric(y_true, y_pred)\n        return dcg_val / idcg_val if idcg_val != 0 else 0\n'"
matchzoo/metrics/precision.py,0,"b'""""""Precision for ranking.""""""\nimport numpy as np\n\nfrom matchzoo.engine.base_metric import (\n    BaseMetric, sort_and_couple, RankingMetric\n)\n\n\nclass Precision(RankingMetric):\n    """"""Precision metric.""""""\n\n    ALIAS = \'precision\'\n\n    def __init__(self, k: int = 1, threshold: float = 0.):\n        """"""\n        :class:`PrecisionMetric` constructor.\n\n        :param k: Number of results to consider.\n        :param threshold: the label threshold of relevance degree.\n        """"""\n        self._k = k\n        self._threshold = threshold\n\n    def __repr__(self) -> str:\n        """""":return: Formated string representation of the metric.""""""\n        return f""{self.ALIAS}@{self._k}({self._threshold})""\n\n    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n        """"""\n        Calculate precision@k.\n\n        Example:\n            >>> y_true = [0, 0, 0, 1]\n            >>> y_pred = [0.2, 0.4, 0.3, 0.1]\n            >>> Precision(k=1)(y_true, y_pred)\n            0.0\n            >>> Precision(k=2)(y_true, y_pred)\n            0.0\n            >>> Precision(k=4)(y_true, y_pred)\n            0.25\n            >>> Precision(k=5)(y_true, y_pred)\n            0.2\n\n        :param y_true: The ground true label of each document.\n        :param y_pred: The predicted scores of each document.\n        :return: Precision @ k\n        :raises: ValueError: len(r) must be >= k.\n        """"""\n        if self._k <= 0:\n            raise ValueError(f""k must be greater than 0.""\n                             f""{self._k} received."")\n        coupled_pair = sort_and_couple(y_true, y_pred)\n        precision = 0.0\n        for idx, (label, score) in enumerate(coupled_pair):\n            if idx >= self._k:\n                break\n            if label > self._threshold:\n                precision += 1.\n        return precision / self._k\n'"
matchzoo/models/__init__.py,0,b'from .dense_baseline import DenseBaseline\nfrom .dssm import DSSM\nfrom .cdssm import CDSSM\nfrom .drmm import DRMM\nfrom .drmmtks import DRMMTKS\nfrom .esim import ESIM\nfrom .knrm import KNRM\nfrom .conv_knrm import ConvKNRM\nfrom .bimpm import BiMPM\nfrom .matchlstm import MatchLSTM\nfrom .arci import ArcI\nfrom .arcii import ArcII\nfrom .bert import Bert\nfrom .mvlstm import MVLSTM\nfrom .match_pyramid import MatchPyramid\nfrom .anmm import aNMM\nfrom .hbmp import HBMP\nfrom .duet import DUET\nfrom .diin import DIIN\nfrom .match_srnn import MatchSRNN\n\n\ndef list_available() -> list:\n    from matchzoo.engine.base_model import BaseModel\n    from matchzoo.utils import list_recursive_concrete_subclasses\n    return list_recursive_concrete_subclasses(BaseModel)\n'
matchzoo/models/anmm.py,5,"b'""""""An implementation of aNMM Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.modules import Attention, Matching\nfrom matchzoo.utils import parse_activation\n\n\nclass aNMM(BaseModel):\n    """"""\n    aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model.\n\n    Examples:\n        >>> model = aNMM()\n        >>> model.params[\'embedding_output_dim\'] = 300\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(with_embedding=True)\n        params.add(Param(name=\'mask_value\', value=0,\n                         desc=""The value to be masked from inputs.""))\n        params.add(Param(name=\'num_bins\', value=200,\n                         desc=""Integer, number of bins.""))\n        params.add(Param(name=\'hidden_sizes\', value=[100],\n                         desc=""Number of hidden size for each hidden layer""))\n        params.add(Param(name=\'activation\', value=\'relu\',\n                         desc=""The activation function.""))\n\n        params.add(Param(\n            \'dropout_rate\', 0.0,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""The dropout rate.""\n        ))\n        return params\n\n    def build(self):\n        """"""\n        Build model structure.\n\n        aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model.\n        """"""\n        self.embedding = self._make_default_embedding_layer()\n\n        # QA Matching\n        self.matching = Matching(matching_type=\'dot\', normalize=True)\n\n        # Value-shared Weighting\n        activation = parse_activation(self._params[\'activation\'])\n        in_hidden_size = [\n            self._params[\'num_bins\'],\n            *self._params[\'hidden_sizes\']\n        ]\n        out_hidden_size = [\n            *self._params[\'hidden_sizes\'],\n            1\n        ]\n\n        hidden_layers = [\n            nn.Sequential(\n                nn.Linear(in_size, out_size),\n                activation\n            )\n            for in_size, out_size, in zip(\n                in_hidden_size,\n                out_hidden_size\n            )\n        ]\n        self.hidden_layers = nn.Sequential(*hidden_layers)\n\n        # Query Attention\n        self.q_attention = Attention(self._params[\'embedding_output_dim\'])\n\n        self.dropout = nn.Dropout(p=self._params[\'dropout_rate\'])\n\n        # Build output\n        self.out = self._make_output_layer(1)\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   BI = number of bins\n\n        # Left input and right input\n        # shape = [B, L]\n        # shape = [B, R]\n        input_left, input_right = inputs[\'text_left\'], inputs[\'text_right\']\n\n        # Process left and right input\n        # shape = [B, L, D]\n        # shape = [B, R, D]\n        embed_left = self.embedding(input_left.long())\n        embed_right = self.embedding(input_right.long())\n\n        # Left and right input mask matrix\n        # shape = [B, L]\n        # shape = [B, R]\n        left_mask = (input_left == self._params[\'mask_value\'])\n        right_mask = (input_right == self._params[\'mask_value\'])\n\n        # Compute QA Matching matrix\n        # shape = [B, L, R]\n        qa_matching_matrix = self.matching(embed_left, embed_right)\n        qa_matching_matrix.masked_fill_(right_mask.unsqueeze(1), float(0))\n\n        # Bin QA Matching Matrix\n        B, L = qa_matching_matrix.shape[0], qa_matching_matrix.shape[1]\n        BI = self._params[\'num_bins\']\n        device = qa_matching_matrix.device\n        qa_matching_matrix = qa_matching_matrix.view(-1)\n        qa_matching_detach = qa_matching_matrix.detach()\n\n        bin_indexes = torch.floor((qa_matching_detach + 1.) / 2 * (BI - 1.)).long()\n        bin_indexes = bin_indexes.view(B * L, -1)\n\n        index_offset = torch.arange(start=0, end=(B * L * BI), step=BI,\n                                    device=device).long().unsqueeze(-1)\n        bin_indexes += index_offset\n        bin_indexes = bin_indexes.view(-1)\n\n        # shape = [B, L, BI]\n        bin_qa_matching = torch.zeros(B * L * BI, device=device)\n        bin_qa_matching.index_add_(0, bin_indexes, qa_matching_matrix)\n        bin_qa_matching = bin_qa_matching.view(B, L, -1)\n\n        # Apply dropout\n        bin_qa_matching = self.dropout(bin_qa_matching)\n\n        # MLP hidden layers\n        # shape = [B, L, 1]\n        hiddens = self.hidden_layers(bin_qa_matching)\n\n        # Query attention\n        # shape = [B, L, 1]\n        q_attention = self.q_attention(embed_left, left_mask).unsqueeze(-1)\n\n        # shape = [B, 1]\n        score = torch.sum(hiddens * q_attention, dim=1)\n        # shape = [B, *]\n        out = self.out(score)\n        return out\n'"
matchzoo/models/arci.py,4,"b'""""""An implementation of ArcI Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.utils import parse_activation\n\n\nclass ArcI(BaseModel):\n    """"""\n    ArcI Model.\n\n    Examples:\n        >>> model = ArcI()\n        >>> model.params[\'left_filters\'] = [32]\n        >>> model.params[\'right_filters\'] = [32]\n        >>> model.params[\'left_kernel_sizes\'] = [3]\n        >>> model.params[\'right_kernel_sizes\'] = [3]\n        >>> model.params[\'left_pool_sizes\'] = [2]\n        >>> model.params[\'right_pool_sizes\'] = [4]\n        >>> model.params[\'conv_activation_func\'] = \'relu\'\n        >>> model.params[\'mlp_num_layers\'] = 1\n        >>> model.params[\'mlp_num_units\'] = 64\n        >>> model.params[\'mlp_num_fan_out\'] = 32\n        >>> model.params[\'mlp_activation_func\'] = \'relu\'\n        >>> model.params[\'dropout_rate\'] = 0.5\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=True\n        )\n        params.add(Param(name=\'left_length\', value=10,\n                         desc=\'Length of left input.\'))\n        params.add(Param(name=\'right_length\', value=100,\n                         desc=\'Length of right input.\'))\n        params.add(Param(name=\'conv_activation_func\', value=\'relu\',\n                         desc=""The activation function in the ""\n                         ""convolution layer.""))\n        params.add(Param(name=\'left_filters\', value=[32],\n                         desc=""The filter size of each convolution ""\n                         ""blocks for the left input.""))\n        params.add(Param(name=\'left_kernel_sizes\', value=[3],\n                         desc=""The kernel size of each convolution ""\n                         ""blocks for the left input.""))\n        params.add(Param(name=\'left_pool_sizes\', value=[2],\n                         desc=""The pooling size of each convolution ""\n                         ""blocks for the left input.""))\n        params.add(Param(name=\'right_filters\', value=[32],\n                         desc=""The filter size of each convolution ""\n                         ""blocks for the right input.""))\n        params.add(Param(name=\'right_kernel_sizes\', value=[3],\n                         desc=""The kernel size of each convolution ""\n                         ""blocks for the right input.""))\n        params.add(Param(name=\'right_pool_sizes\', value=[2],\n                         desc=""The pooling size of each convolution ""\n                         ""blocks for the right input.""))\n        params.add(Param(\n            \'dropout_rate\', 0.0,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""The dropout rate.""\n        ))\n        return params\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = 10,\n        fixed_length_right: int = 100,\n        pad_word_value: typing.Union[int, str] = 0,\n        pad_word_mode: str = \'pre\',\n        with_ngram: bool = False,\n        fixed_ngram_length: int = None,\n        pad_ngram_value: typing.Union[int, str] = 0,\n        pad_ngram_mode: str = \'pre\'\n    ) -> BaseCallback:\n        """"""\n        Model default padding callback.\n\n        The padding callback\'s on_batch_unpacked would pad a batch of data to\n        a fixed length.\n\n        :return: Default padding callback.\n        """"""\n        return callbacks.BasicPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_word_value=pad_word_value,\n            pad_word_mode=pad_word_mode,\n            with_ngram=with_ngram,\n            fixed_ngram_length=fixed_ngram_length,\n            pad_ngram_value=pad_ngram_value,\n            pad_ngram_mode=pad_ngram_mode\n        )\n\n    def build(self):\n        """"""\n        Build model structure.\n\n        ArcI use Siamese arthitecture.\n        """"""\n        self.embedding = self._make_default_embedding_layer()\n\n        # Build conv\n        activation = parse_activation(self._params[\'conv_activation_func\'])\n        left_in_channels = [\n            self._params[\'embedding_output_dim\'],\n            *self._params[\'left_filters\'][:-1]\n        ]\n        right_in_channels = [\n            self._params[\'embedding_output_dim\'],\n            *self._params[\'right_filters\'][:-1]\n        ]\n        conv_left = [\n            self._make_conv_pool_block(ic, oc, ks, activation, ps)\n            for ic, oc, ks, ps in zip(left_in_channels,\n                                      self._params[\'left_filters\'],\n                                      self._params[\'left_kernel_sizes\'],\n                                      self._params[\'left_pool_sizes\'])\n        ]\n        conv_right = [\n            self._make_conv_pool_block(ic, oc, ks, activation, ps)\n            for ic, oc, ks, ps in zip(right_in_channels,\n                                      self._params[\'right_filters\'],\n                                      self._params[\'right_kernel_sizes\'],\n                                      self._params[\'right_pool_sizes\'])\n        ]\n        self.conv_left = nn.Sequential(*conv_left)\n        self.conv_right = nn.Sequential(*conv_right)\n\n        self.dropout = nn.Dropout(p=self._params[\'dropout_rate\'])\n\n        left_length = self._params[\'left_length\']\n        right_length = self._params[\'right_length\']\n        for ps in self._params[\'left_pool_sizes\']:\n            left_length = left_length // ps\n        for ps in self._params[\'right_pool_sizes\']:\n            right_length = right_length // ps\n        self.mlp = self._make_multi_layer_perceptron_layer(\n            left_length * self._params[\'left_filters\'][-1] + (\n                right_length * self._params[\'right_filters\'][-1])\n        )\n\n        self.out = self._make_output_layer(\n            self._params[\'mlp_num_fan_out\']\n        )\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   F = number of filters\n        #   P = pool size\n\n        # Left input and right input.\n        # shape = [B, L]\n        # shape = [B, R]\n        input_left, input_right = inputs[\'text_left\'], inputs[\'text_right\']\n\n        # Process left and right input.\n        # shape = [B, D, L]\n        # shape = [B, D, R]\n        embed_left = self.embedding(input_left.long()).transpose(1, 2)\n        embed_right = self.embedding(input_right.long()).transpose(1, 2)\n\n        # Convolution\n        # shape = [B, F, L // P]\n        # shape = [B, F, R // P]\n        conv_left = self.conv_left(embed_left)\n        conv_right = self.conv_right(embed_right)\n\n        # shape = [B, F * (L // P)]\n        # shape = [B, F * (R // P)]\n        rep_left = torch.flatten(conv_left, start_dim=1)\n        rep_right = torch.flatten(conv_right, start_dim=1)\n\n        # shape = [B, F * (L // P) + F * (R // P)]\n        concat = self.dropout(torch.cat((rep_left, rep_right), dim=1))\n\n        # shape = [B, *]\n        dense_output = self.mlp(concat)\n\n        out = self.out(dense_output)\n        return out\n\n    @classmethod\n    def _make_conv_pool_block(\n        cls,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int,\n        activation: nn.Module,\n        pool_size: int,\n    ) -> nn.Module:\n        """"""Make conv pool block.""""""\n        return nn.Sequential(\n            nn.ConstantPad1d((0, kernel_size - 1), 0),\n            nn.Conv1d(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=kernel_size\n            ),\n            activation,\n            nn.MaxPool1d(kernel_size=pool_size)\n        )\n'"
matchzoo/models/arcii.py,2,"b'""""""An implementation of ArcII Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.modules import Matching\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.utils import parse_activation\n\n\nclass ArcII(BaseModel):\n    """"""\n    ArcII Model.\n\n    Examples:\n        >>> model = ArcII()\n        >>> model.params[\'embedding_output_dim\'] = 300\n        >>> model.params[\'kernel_1d_count\'] = 32\n        >>> model.params[\'kernel_1d_size\'] = 3\n        >>> model.params[\'kernel_2d_count\'] = [16, 32]\n        >>> model.params[\'kernel_2d_size\'] = [[3, 3], [3, 3]]\n        >>> model.params[\'pool_2d_size\'] = [[2, 2], [2, 2]]\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(with_embedding=True)\n        params.add(Param(name=\'left_length\', value=10,\n                         desc=\'Length of left input.\'))\n        params.add(Param(name=\'right_length\', value=100,\n                         desc=\'Length of right input.\'))\n        params.add(Param(name=\'kernel_1d_count\', value=32,\n                         desc=""Kernel count of 1D convolution layer.""))\n        params.add(Param(name=\'kernel_1d_size\', value=3,\n                         desc=""Kernel size of 1D convolution layer.""))\n        params.add(Param(name=\'kernel_2d_count\', value=[32],\n                         desc=""Kernel count of 2D convolution layer in""\n                              ""each block""))\n        params.add(Param(name=\'kernel_2d_size\', value=[(3, 3)],\n                         desc=""Kernel size of 2D convolution layer in""\n                              "" each block.""))\n        params.add(Param(name=\'activation\', value=\'relu\',\n                         desc=""Activation function.""))\n        params.add(Param(name=\'pool_2d_size\', value=[(2, 2)],\n                         desc=""Size of pooling layer in each block.""))\n        params.add(Param(\n            \'dropout_rate\', 0.0,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""The dropout rate.""\n        ))\n        return params\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = 10,\n        fixed_length_right: int = 100,\n        pad_word_value: typing.Union[int, str] = 0,\n        pad_word_mode: str = \'pre\',\n        with_ngram: bool = False,\n        fixed_ngram_length: int = None,\n        pad_ngram_value: typing.Union[int, str] = 0,\n        pad_ngram_mode: str = \'pre\'\n    ) -> BaseCallback:\n        """"""\n        Model default padding callback.\n\n        The padding callback\'s on_batch_unpacked would pad a batch of data to\n        a fixed length.\n\n        :return: Default padding callback.\n        """"""\n        return callbacks.BasicPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_word_value=pad_word_value,\n            pad_word_mode=pad_word_mode,\n            with_ngram=with_ngram,\n            fixed_ngram_length=fixed_ngram_length,\n            pad_ngram_value=pad_ngram_value,\n            pad_ngram_mode=pad_ngram_mode\n        )\n\n    def build(self):\n        """"""\n        Build model structure.\n\n        ArcII has the desirable property of letting two sentences meet before\n        their own high-level representations mature.\n        """"""\n        self.embedding = self._make_default_embedding_layer()\n\n        # Phrase level representations\n        self.conv1d_left = nn.Sequential(\n            nn.ConstantPad1d((0, self._params[\'kernel_1d_size\'] - 1), 0),\n            nn.Conv1d(\n                in_channels=self._params[\'embedding_output_dim\'],\n                out_channels=self._params[\'kernel_1d_count\'],\n                kernel_size=self._params[\'kernel_1d_size\']\n            )\n        )\n        self.conv1d_right = nn.Sequential(\n            nn.ConstantPad1d((0, self._params[\'kernel_1d_size\'] - 1), 0),\n            nn.Conv1d(\n                in_channels=self._params[\'embedding_output_dim\'],\n                out_channels=self._params[\'kernel_1d_count\'],\n                kernel_size=self._params[\'kernel_1d_size\']\n            )\n        )\n\n        # Interaction\n        self.matching = Matching(matching_type=\'plus\')\n\n        # Build conv\n        activation = parse_activation(self._params[\'activation\'])\n        in_channel_2d = [\n            self._params[\'kernel_1d_count\'],\n            *self._params[\'kernel_2d_count\'][:-1]\n        ]\n        conv2d = [\n            self._make_conv_pool_block(ic, oc, ks, activation, ps)\n            for ic, oc, ks, ps in zip(in_channel_2d,\n                                      self._params[\'kernel_2d_count\'],\n                                      self._params[\'kernel_2d_size\'],\n                                      self._params[\'pool_2d_size\'])\n        ]\n        self.conv2d = nn.Sequential(*conv2d)\n\n        self.dropout = nn.Dropout(p=self._params[\'dropout_rate\'])\n\n        left_length = self._params[\'left_length\']\n        right_length = self._params[\'right_length\']\n        for ps in self._params[\'pool_2d_size\']:\n            left_length = left_length // ps[0]\n        for ps in self._params[\'pool_2d_size\']:\n            right_length = right_length // ps[1]\n\n        # Build output\n        self.out = self._make_output_layer(\n            left_length * right_length * self._params[\'kernel_2d_count\'][-1]\n        )\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   F = number of filters\n        #   P = pool size\n\n        # Left input and right input.\n        # shape = [B, L]\n        # shape = [B, R]\n        input_left, input_right = inputs[\'text_left\'], inputs[\'text_right\']\n\n        # Process left and right input.\n        # shape = [B, D, L]\n        # shape = [B, D, R]\n        embed_left = self.embedding(input_left.long()).transpose(1, 2)\n        embed_right = self.embedding(input_right.long()).transpose(1, 2)\n\n        # shape = [B, L, F1]\n        # shape = [B, R, F1]\n        conv1d_left = self.conv1d_left(embed_left).transpose(1, 2)\n        conv1d_right = self.conv1d_right(embed_right).transpose(1, 2)\n\n        # Compute matching signal\n        # shape = [B, L, R, F1]\n        embed_cross = self.matching(conv1d_left, conv1d_right)\n\n        # Convolution\n        # shape = [B, F2, L // P, R // P]\n        conv = self.conv2d(embed_cross.permute(0, 3, 1, 2))\n\n        # shape = [B, F2 * (L // P) * (R // P)]\n        embed_flat = self.dropout(torch.flatten(conv, start_dim=1))\n\n        # shape = [B, *]\n        out = self.out(embed_flat)\n        return out\n\n    @classmethod\n    def _make_conv_pool_block(\n        cls,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: tuple,\n        activation: nn.Module,\n        pool_size: tuple,\n    ) -> nn.Module:\n        """"""Make conv pool block.""""""\n        return nn.Sequential(\n            # Same padding\n            nn.ConstantPad2d(\n                (0, kernel_size[1] - 1, 0, kernel_size[0] - 1), 0\n            ),\n            nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=kernel_size\n            ),\n            activation,\n            nn.MaxPool2d(kernel_size=pool_size)\n        )\n'"
matchzoo/models/bert.py,1,"b'""""""An implementation of Bert Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nfrom pytorch_transformers import BertModel\n\nfrom matchzoo import preprocessors\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.modules import BertModule\n\n\nclass Bert(BaseModel):\n    """"""Bert Model.""""""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params()\n        params.add(Param(name=\'mode\', value=\'bert-base-uncased\',\n                         desc=""Pretrained Bert model.""))\n        params.add(Param(\n            \'dropout_rate\', 0.0,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""The dropout rate.""\n        ))\n        return params\n\n    @classmethod\n    def get_default_preprocessor(\n        cls,\n        mode: str = \'bert-base-uncased\'\n    ) -> BasePreprocessor:\n        """""":return: Default preprocessor.""""""\n        return preprocessors.BertPreprocessor(mode=mode)\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = None,\n        fixed_length_right: int = None,\n        pad_value: typing.Union[int, str] = 0,\n        pad_mode: str = \'pre\'\n    ):\n        """""":return: Default padding callback.""""""\n        return callbacks.BertPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_value=pad_value,\n            pad_mode=pad_mode)\n\n    def build(self):\n        """"""Build model structure.""""""\n        self.bert = BertModule(mode=self._params[\'mode\'])\n        self.dropout = nn.Dropout(p=self._params[\'dropout_rate\'])\n        if \'base\' in self._params[\'mode\']:\n            dim = 768\n        elif \'large\' in self._params[\'mode\']:\n            dim = 1024\n        self.out = self._make_output_layer(dim)\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        input_left, input_right = inputs[\'text_left\'], inputs[\'text_right\']\n\n        bert_output = self.bert(input_left, input_right)[1]\n\n        out = self.out(self.dropout(bert_output))\n\n        return out\n'"
matchzoo/models/bimpm.py,17,"b'""""""An implementation of BiMPM Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\n\n\nclass BiMPM(BaseModel):\n    """"""\n    BiMPM Model.\n\n    Reference:\n    - https://github.com/galsang/BIMPM-pytorch/blob/master/model/BIMPM.py\n\n    Examples:\n        >>> model = BiMPM()\n        >>> model.params[\'num_perspective\'] = 4\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=False\n        )\n        params.add(Param(name=\'mask_value\', value=0,\n                         desc=""The value to be masked from inputs.""))\n        params.add(Param(name=\'dropout\', value=0.2,\n                         desc=""Dropout rate.""))\n        params.add(Param(name=\'hidden_size\', value=100,\n                         hyper_space=hyper_spaces.quniform(\n                             low=100, high=300, q=100),\n                         desc=""Hidden size.""))\n\n        # BiMPM parameters\n        params.add(Param(name=\'num_perspective\', value=20,\n                         hyper_space=hyper_spaces.quniform(\n                             low=20, high=100, q=20),\n                         desc=\'num_perspective\'))\n\n        return params\n\n    def build(self):\n        """"""Make function layers.""""""\n\n        self.embedding = self._make_default_embedding_layer()\n\n        # Context Representation Layer\n        self.context_LSTM = nn.LSTM(\n            input_size=self._params[\'embedding_output_dim\'],\n            hidden_size=self._params[\'hidden_size\'],\n            num_layers=1,\n            bidirectional=True,\n            batch_first=True\n        )\n\n        # Matching Layer\n        for i in range(1, 9):\n            setattr(self, f\'mp_w{i}\',\n                    nn.Parameter(torch.rand(self._params[\'num_perspective\'],\n                                            self._params[\'hidden_size\'])))\n\n        # Aggregation Layer\n        self.aggregation_LSTM = nn.LSTM(\n            input_size=self._params[\'num_perspective\'] * 8,\n            hidden_size=self._params[\'hidden_size\'],\n            num_layers=1,\n            bidirectional=True,\n            batch_first=True\n        )\n\n        # Prediction Layer\n        self.pred_fc1 = nn.Linear(\n            self._params[\'hidden_size\'] * 4,\n            self._params[\'hidden_size\'] * 2)\n        self.pred_fc2 = self._make_output_layer(\n            self._params[\'hidden_size\'] * 2)\n\n        # parameters\n        self.reset_parameters()\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n        # Word Representation Layer\n        # (batch, seq_len) -> (batch, seq_len, word_dim)\n\n        # [B, L], [B, R]\n        p, h = inputs[\'text_left\'].long(), inputs[\'text_right\'].long()\n\n        # [B, L, D]\n        # [B, R, D]\n        p = self.embedding(p)\n        h = self.embedding(h)\n\n        p = self.dropout(p)\n        h = self.dropout(h)\n\n        # Context Representation Layer\n        # (batch, seq_len, hidden_size * 2)\n        con_p, _ = self.context_LSTM(p)\n        con_h, _ = self.context_LSTM(h)\n\n        con_p = self.dropout(con_p)\n        con_h = self.dropout(con_h)\n\n        # (batch, seq_len, hidden_size)\n        con_p_fw, con_p_bw = torch.split(con_p,\n                                         self._params[\'hidden_size\'],\n                                         dim=-1)\n        con_h_fw, con_h_bw = torch.split(con_h,\n                                         self._params[\'hidden_size\'],\n                                         dim=-1)\n\n        # 1. Full-Matching\n\n        # (batch, seq_len, hidden_size), (batch, hidden_size)\n        #   -> (batch, seq_len, l)\n        mv_p_full_fw = mp_matching_func(\n            con_p_fw, con_h_fw[:, -1, :], self.mp_w1)\n        mv_p_full_bw = mp_matching_func(\n            con_p_bw, con_h_bw[:, 0, :], self.mp_w2)\n        mv_h_full_fw = mp_matching_func(\n            con_h_fw, con_p_fw[:, -1, :], self.mp_w1)\n        mv_h_full_bw = mp_matching_func(\n            con_h_bw, con_p_bw[:, 0, :], self.mp_w2)\n\n        # 2. Maxpooling-Matching\n\n        # (batch, seq_len1, seq_len2, l)\n        mv_max_fw = mp_matching_func_pairwise(con_p_fw, con_h_fw, self.mp_w3)\n        mv_max_bw = mp_matching_func_pairwise(con_p_bw, con_h_bw, self.mp_w4)\n\n        # (batch, seq_len, l)\n        mv_p_max_fw, _ = mv_max_fw.max(dim=2)\n        mv_p_max_bw, _ = mv_max_bw.max(dim=2)\n        mv_h_max_fw, _ = mv_max_fw.max(dim=1)\n        mv_h_max_bw, _ = mv_max_bw.max(dim=1)\n\n        # 3. Attentive-Matching\n\n        # (batch, seq_len1, seq_len2)\n        att_fw = attention(con_p_fw, con_h_fw)\n        att_bw = attention(con_p_bw, con_h_bw)\n\n        # (batch, seq_len2, hidden_size) -> (batch, 1, seq_len2, hidden_size)\n        # (batch, seq_len1, seq_len2) -> (batch, seq_len1, seq_len2, 1)\n        # output:  -> (batch, seq_len1, seq_len2, hidden_size)\n        att_h_fw = con_h_fw.unsqueeze(1) * att_fw.unsqueeze(3)\n        att_h_bw = con_h_bw.unsqueeze(1) * att_bw.unsqueeze(3)\n        # (batch, seq_len1, hidden_size) -> (batch, seq_len1, 1, hidden_size)\n        # (batch, seq_len1, seq_len2) -> (batch, seq_len1, seq_len2, 1)\n        # output:  -> (batch, seq_len1, seq_len2, hidden_size)\n        att_p_fw = con_p_fw.unsqueeze(2) * att_fw.unsqueeze(3)\n        att_p_bw = con_p_bw.unsqueeze(2) * att_bw.unsqueeze(3)\n\n        # (batch, seq_len1, hidden_size) / (batch, seq_len1, 1)\n        # output:  -> (batch, seq_len1, hidden_size)\n        att_mean_h_fw = div_with_small_value(\n            att_h_fw.sum(dim=2),\n            att_fw.sum(dim=2, keepdim=True))\n        att_mean_h_bw = div_with_small_value(\n            att_h_bw.sum(dim=2),\n            att_bw.sum(dim=2, keepdim=True))\n        # (batch, seq_len2, hidden_size) / (batch, seq_len2, 1)\n        # output:  -> (batch, seq_len2, hidden_size)\n        att_mean_p_fw = div_with_small_value(\n            att_p_fw.sum(dim=1),\n            att_fw.sum(dim=1, keepdim=True).permute(0, 2, 1))\n        att_mean_p_bw = div_with_small_value(\n            att_p_bw.sum(dim=1),\n            att_bw.sum(dim=1, keepdim=True).permute(0, 2, 1))\n\n        # (batch, seq_len, l)\n        mv_p_att_mean_fw = mp_matching_func(\n            con_p_fw, att_mean_h_fw, self.mp_w5)\n        mv_p_att_mean_bw = mp_matching_func(\n            con_p_bw, att_mean_h_bw, self.mp_w6)\n        mv_h_att_mean_fw = mp_matching_func(\n            con_h_fw, att_mean_p_fw, self.mp_w5)\n        mv_h_att_mean_bw = mp_matching_func(\n            con_h_bw, att_mean_p_bw, self.mp_w6)\n\n        # 4. Max-Attentive-Matching\n\n        # (batch, seq_len1, hidden_size)\n        att_max_h_fw, _ = att_h_fw.max(dim=2)\n        att_max_h_bw, _ = att_h_bw.max(dim=2)\n        # (batch, seq_len2, hidden_size)\n        att_max_p_fw, _ = att_p_fw.max(dim=1)\n        att_max_p_bw, _ = att_p_bw.max(dim=1)\n\n        # (batch, seq_len, l)\n        mv_p_att_max_fw = mp_matching_func(con_p_fw, att_max_h_fw, self.mp_w7)\n        mv_p_att_max_bw = mp_matching_func(con_p_bw, att_max_h_bw, self.mp_w8)\n        mv_h_att_max_fw = mp_matching_func(con_h_fw, att_max_p_fw, self.mp_w7)\n        mv_h_att_max_bw = mp_matching_func(con_h_bw, att_max_p_bw, self.mp_w8)\n\n        # (batch, seq_len, l * 8)\n        mv_p = torch.cat(\n            [mv_p_full_fw, mv_p_max_fw, mv_p_att_mean_fw, mv_p_att_max_fw,\n             mv_p_full_bw, mv_p_max_bw, mv_p_att_mean_bw, mv_p_att_max_bw],\n            dim=2)\n        mv_h = torch.cat(\n            [mv_h_full_fw, mv_h_max_fw, mv_h_att_mean_fw, mv_h_att_max_fw,\n             mv_h_full_bw, mv_h_max_bw, mv_h_att_mean_bw, mv_h_att_max_bw],\n            dim=2)\n\n        mv_p = self.dropout(mv_p)\n        mv_h = self.dropout(mv_h)\n\n        # Aggregation Layer\n        # (batch, seq_len, l * 8) -> (2, batch, hidden_size)\n        _, (agg_p_last, _) = self.aggregation_LSTM(mv_p)\n        _, (agg_h_last, _) = self.aggregation_LSTM(mv_h)\n\n        # 2 * (2, batch, hidden_size) -> 2 * (batch, hidden_size * 2)\n        #   -> (batch, hidden_size * 4)\n        x = torch.cat(\n            [agg_p_last.permute(1, 0, 2).contiguous().view(\n                -1, self._params[\'hidden_size\'] * 2),\n                agg_h_last.permute(1, 0, 2).contiguous().view(\n                    -1, self._params[\'hidden_size\'] * 2)],\n            dim=1)\n        x = self.dropout(x)\n\n        # Prediction Layer\n        x = torch.tanh(self.pred_fc1(x))\n        x = self.dropout(x)\n        x = self.pred_fc2(x)\n\n        return x\n\n    def reset_parameters(self):\n        """"""Init Parameters.""""""\n\n        # Word Representation Layer\n\n        # <unk> vectors is randomly initialized\n        nn.init.uniform_(self.embedding.weight.data[0], -0.1, 0.1)\n\n        # Context Representation Layer\n        nn.init.kaiming_normal_(self.context_LSTM.weight_ih_l0)\n        nn.init.constant_(self.context_LSTM.bias_ih_l0, val=0)\n        nn.init.orthogonal_(self.context_LSTM.weight_hh_l0)\n        nn.init.constant_(self.context_LSTM.bias_hh_l0, val=0)\n\n        nn.init.kaiming_normal_(self.context_LSTM.weight_ih_l0_reverse)\n        nn.init.constant_(self.context_LSTM.bias_ih_l0_reverse, val=0)\n        nn.init.orthogonal_(self.context_LSTM.weight_hh_l0_reverse)\n        nn.init.constant_(self.context_LSTM.bias_hh_l0_reverse, val=0)\n\n        # Matching Layer\n        for i in range(1, 9):\n            w = getattr(self, f\'mp_w{i}\')\n            nn.init.kaiming_normal_(w)\n\n        # Aggregation Layer\n        nn.init.kaiming_normal_(self.aggregation_LSTM.weight_ih_l0)\n        nn.init.constant_(self.aggregation_LSTM.bias_ih_l0, val=0)\n        nn.init.orthogonal_(self.aggregation_LSTM.weight_hh_l0)\n        nn.init.constant_(self.aggregation_LSTM.bias_hh_l0, val=0)\n\n        nn.init.kaiming_normal_(self.aggregation_LSTM.weight_ih_l0_reverse)\n        nn.init.constant_(self.aggregation_LSTM.bias_ih_l0_reverse, val=0)\n        nn.init.orthogonal_(self.aggregation_LSTM.weight_hh_l0_reverse)\n        nn.init.constant_(self.aggregation_LSTM.bias_hh_l0_reverse, val=0)\n\n        # Prediction Layer ----\n        nn.init.uniform_(self.pred_fc1.weight, -0.005, 0.005)\n        nn.init.constant_(self.pred_fc1.bias, val=0)\n\n        # nn.init.uniform(self.pred_fc2.weight, -0.005, 0.005)\n        # nn.init.constant(self.pred_fc2.bias, val=0)\n\n    def dropout(self, v):\n        """"""Dropout Layer.""""""\n        return F.dropout(v, p=self._params[\'dropout\'], training=self.training)\n\n\ndef mp_matching_func(v1, v2, w):\n    """"""\n    Basic mp_matching_func.\n\n    :param v1: (batch, seq_len, hidden_size)\n    :param v2: (batch, seq_len, hidden_size) or (batch, hidden_size)\n    :param w: (num_psp, hidden_size)\n    :return: (batch, num_psp)\n    """"""\n\n    seq_len = v1.size(1)\n    num_psp = w.size(0)\n\n    # (1, 1, hidden_size, l)\n    w = w.transpose(1, 0).unsqueeze(0).unsqueeze(0)\n    # (batch, seq_len, hidden_size, l)\n    v1 = w * torch.stack([v1] * num_psp, dim=3)\n    if len(v2.size()) == 3:\n        v2 = w * torch.stack([v2] * num_psp, dim=3)\n    else:\n        v2 = w * torch.stack(\n            [torch.stack([v2] * seq_len, dim=1)] * num_psp, dim=3)\n\n    m = F.cosine_similarity(v1, v2, dim=2)\n\n    return m\n\n\ndef mp_matching_func_pairwise(v1, v2, w):\n    """"""\n    Basic mp_matching_func_pairwise.\n\n    :param v1: (batch, seq_len1, hidden_size)\n    :param v2: (batch, seq_len2, hidden_size)\n    :param w: (num_psp, hidden_size)\n    :param num_psp\n    :return: (batch, num_psp, seq_len1, seq_len2)\n    """"""\n\n    num_psp = w.size(0)\n\n    # (1, l, 1, hidden_size)\n    w = w.unsqueeze(0).unsqueeze(2)\n    # (batch, l, seq_len, hidden_size)\n    v1, v2 = (w * torch.stack([v1] * num_psp, dim=1),\n              w * torch.stack([v2] * num_psp, dim=1))\n    # (batch, l, seq_len, hidden_size->1)\n    v1_norm = v1.norm(p=2, dim=3, keepdim=True)\n    v2_norm = v2.norm(p=2, dim=3, keepdim=True)\n\n    # (batch, l, seq_len1, seq_len2)\n    n = torch.matmul(v1, v2.transpose(2, 3))\n    d = v1_norm * v2_norm.transpose(2, 3)\n\n    # (batch, seq_len1, seq_len2, l)\n    m = div_with_small_value(n, d).permute(0, 2, 3, 1)\n\n    return m\n\n\ndef attention(v1, v2):\n    """"""\n    Attention.\n\n    :param v1: (batch, seq_len1, hidden_size)\n    :param v2: (batch, seq_len2, hidden_size)\n    :return: (batch, seq_len1, seq_len2)\n    """"""\n\n    # (batch, seq_len1, 1)\n    v1_norm = v1.norm(p=2, dim=2, keepdim=True)\n    # (batch, 1, seq_len2)\n    v2_norm = v2.norm(p=2, dim=2, keepdim=True).permute(0, 2, 1)\n\n    # (batch, seq_len1, seq_len2)\n    a = torch.bmm(v1, v2.permute(0, 2, 1))\n    d = v1_norm * v2_norm\n\n    return div_with_small_value(a, d)\n\n\ndef div_with_small_value(n, d, eps=1e-8):\n    """"""\n    Small values are replaced by 1e-8 to prevent it from exploding.\n\n    :param n: tensor\n    :param d: tensor\n    :return: n/d: tensor\n    """"""\n    d = d * (d > eps).float() + eps * (d <= eps).float()\n    return n / d\n'"
matchzoo/models/cdssm.py,1,"b'""""""An implementation of CDSSM (CLSM) model.""""""\nimport typing\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nfrom matchzoo import preprocessors\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.utils import TensorType, parse_activation\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\n\n\nclass CDSSM(BaseModel):\n    """"""\n    CDSSM Model implementation.\n\n    Learning Semantic Representations Using Convolutional Neural Networks\n    for Web Search. (2014a)\n    A Latent Semantic Model with Convolutional-Pooling Structure for\n    Information Retrieval. (2014b)\n\n    Examples:\n        >>> import matchzoo as mz\n        >>> model = CDSSM()\n        >>> model.params[\'task\'] = mz.tasks.Ranking()\n        >>> model.params[\'vocab_size\'] = 4\n        >>> model.params[\'filters\'] =  32\n        >>> model.params[\'kernel_size\'] = 3\n        >>> model.params[\'conv_activation_func\'] = \'relu\'\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        # set :attr:`with_multi_layer_perceptron` to False to support\n        # user-defined variable dense layer units\n        params = super().get_default_params(with_multi_layer_perceptron=True)\n        params.add(Param(name=\'vocab_size\', value=419,\n                         desc=""Size of vocabulary.""))\n        params.add(Param(name=\'filters\', value=3,\n                         desc=""Number of filters in the 1D convolution ""\n                              ""layer.""))\n        params.add(Param(name=\'kernel_size\', value=3,\n                         desc=""Number of kernel size in the 1D ""\n                              ""convolution layer.""))\n        params.add(Param(name=\'conv_activation_func\', value=\'relu\',\n                         desc=""Activation function in the convolution""\n                              "" layer.""))\n        params.add(Param(name=\'dropout_rate\', value=0.3,\n                         desc=""The dropout rate.""))\n        return params\n\n    @classmethod\n    def get_default_preprocessor(\n        cls,\n        truncated_mode: str = \'pre\',\n        truncated_length_left: typing.Optional[int] = None,\n        truncated_length_right: typing.Optional[int] = None,\n        filter_mode: str = \'df\',\n        filter_low_freq: float = 1,\n        filter_high_freq: float = float(\'inf\'),\n        remove_stop_words: bool = False,\n        ngram_size: typing.Optional[int] = 3,\n    ) -> BasePreprocessor:\n        """"""\n        Model default preprocessor.\n\n        The preprocessor\'s transform should produce a correctly shaped data\n        pack that can be used for training.\n\n        :return: Default preprocessor.\n        """"""\n        return preprocessors.BasicPreprocessor(\n            truncated_mode=truncated_mode,\n            truncated_length_left=truncated_length_left,\n            truncated_length_right=truncated_length_right,\n            filter_mode=filter_mode,\n            filter_low_freq=filter_low_freq,\n            filter_high_freq=filter_high_freq,\n            remove_stop_words=remove_stop_words,\n            ngram_size=ngram_size\n        )\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = None,\n        fixed_length_right: int = None,\n        pad_word_value: typing.Union[int, str] = 0,\n        pad_word_mode: str = \'pre\',\n        with_ngram: bool = True,\n        fixed_ngram_length: int = None,\n        pad_ngram_value: typing.Union[int, str] = 0,\n        pad_ngram_mode: str = \'pre\'\n    ) -> BaseCallback:\n        """"""\n        Model default padding callback.\n\n        The padding callback\'s on_batch_unpacked would pad a batch of data to\n        a fixed length.\n\n        :return: Default padding callback.\n        """"""\n        return callbacks.BasicPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_word_value=pad_word_value,\n            pad_word_mode=pad_word_mode,\n            with_ngram=with_ngram,\n            fixed_ngram_length=fixed_ngram_length,\n            pad_ngram_value=pad_ngram_value,\n            pad_ngram_mode=pad_ngram_mode\n        )\n\n    def _create_base_network(self) -> nn.Module:\n        """"""\n        Apply conv and maxpooling operation towards to each letter-ngram.\n\n        The input shape is `fixed_text_length`*`number of letter-ngram`,\n        as described in the paper, `n` is 3, `number of letter-trigram`\n        is about 30,000 according to their observation.\n\n        :return: A :class:`nn.Module` of CDSSM network, tensor in tensor out.\n        """"""\n        pad = nn.ConstantPad1d((0, self._params[\'kernel_size\'] - 1), 0)\n        conv = nn.Conv1d(\n            in_channels=self._params[\'vocab_size\'],\n            out_channels=self._params[\'filters\'],\n            kernel_size=self._params[\'kernel_size\']\n        )\n        activation = parse_activation(\n            self._params[\'conv_activation_func\']\n        )\n        dropout = nn.Dropout(p=self._params[\'dropout_rate\'])\n        pool = nn.AdaptiveMaxPool1d(1)\n        squeeze = Squeeze()\n        mlp = self._make_multi_layer_perceptron_layer(\n            self._params[\'filters\']\n        )\n        return nn.Sequential(\n            pad, conv, activation, dropout, pool, squeeze, mlp\n        )\n\n    def build(self):\n        """"""\n        Build model structure.\n\n        CDSSM use Siamese architecture.\n        """"""\n        self.net_left = self._create_base_network()\n        self.net_right = self._create_base_network()\n        self.out = self._make_output_layer(1)\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n        # Process left & right input.\n        input_left, input_right = inputs[\'ngram_left\'], inputs[\'ngram_right\']\n        input_left = input_left.transpose(1, 2)\n        input_right = input_right.transpose(1, 2)\n        input_left = self.net_left(input_left)\n        input_right = self.net_right(input_right)\n\n        # Dot product with cosine similarity.\n        x = F.cosine_similarity(input_left, input_right)\n\n        out = self.out(x.unsqueeze(dim=1))\n        return out\n\n    def guess_and_fill_missing_params(self, verbose: int = 1):\n        """"""\n        Guess and fill missing parameters in :attr:`params`.\n\n        Use this method to automatically fill-in hyper parameters.\n        This involves some guessing so the parameter it fills could be\n        wrong. For example, the default task is `Ranking`, and if we do not\n        set it to `Classification` manually for data packs prepared for\n        classification, then the shape of the model output and the data will\n        mismatch.\n\n        :param verbose: Verbosity.\n        """"""\n        super().guess_and_fill_missing_params(verbose)\n\n\nclass Squeeze(nn.Module):\n    """"""Squeeze.""""""\n\n    def forward(self, x):\n        """"""Forward.""""""\n        return x.squeeze(dim=-1)\n'"
matchzoo/models/conv_knrm.py,5,"b'""""""An implementation of ConvKNRM Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.modules import GaussianKernel\nfrom matchzoo.utils import parse_activation\n\n\nclass ConvKNRM(BaseModel):\n    """"""\n    ConvKNRM Model.\n\n    Examples:\n        >>> model = ConvKNRM()\n        >>> model.params[\'filters\'] = 128\n        >>> model.params[\'conv_activation_func\'] = \'tanh\'\n        >>> model.params[\'max_ngram\'] = 3\n        >>> model.params[\'use_crossmatch\'] = True\n        >>> model.params[\'kernel_num\'] = 11\n        >>> model.params[\'sigma\'] = 0.1\n        >>> model.params[\'exact_sigma\'] = 0.001\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(with_embedding=True)\n        params.add(Param(\n            name=\'filters\',\n            value=128,\n            desc=""The filter size in the convolution layer.""\n        ))\n        params.add(Param(\n            name=\'conv_activation_func\',\n            value=\'relu\',\n            desc=""The activation function in the convolution layer.""))\n        params.add(Param(\n            name=\'max_ngram\',\n            value=3,\n            desc=""The maximum length of n-grams for the convolution ""\n                 ""layer.""))\n        params.add(Param(\n            name=\'use_crossmatch\',\n            value=True,\n            desc=""Whether to match left n-grams and right n-grams of ""\n                 ""different lengths""))\n        params.add(Param(\n            name=\'kernel_num\',\n            value=11,\n            hyper_space=hyper_spaces.quniform(low=5, high=20),\n            desc=""The number of RBF kernels.""\n        ))\n        params.add(Param(\n            name=\'sigma\',\n            value=0.1,\n            hyper_space=hyper_spaces.quniform(\n                low=0.01, high=0.2, q=0.01),\n            desc=""The `sigma` defines the kernel width.""\n        ))\n        params.add(Param(\n            name=\'exact_sigma\', value=0.001,\n            desc=""The `exact_sigma` denotes the `sigma` ""\n                 ""for exact match.""\n        ))\n        return params\n\n    def build(self):\n        """"""Build model structure.""""""\n        self.embedding = self._make_default_embedding_layer()\n\n        self.q_convs = nn.ModuleList()\n        self.d_convs = nn.ModuleList()\n        for i in range(self._params[\'max_ngram\']):\n            conv = nn.Sequential(\n                nn.ConstantPad1d((0, i), 0),\n                nn.Conv1d(\n                    in_channels=self._params[\'embedding_output_dim\'],\n                    out_channels=self._params[\'filters\'],\n                    kernel_size=i + 1\n                ),\n                parse_activation(\n                    self._params[\'conv_activation_func\']\n                )\n            )\n            self.q_convs.append(conv)\n            self.d_convs.append(conv)\n\n        self.kernels = nn.ModuleList()\n        for i in range(self._params[\'kernel_num\']):\n            mu = 1. / (self._params[\'kernel_num\'] - 1) + (2. * i) / (\n                self._params[\'kernel_num\'] - 1) - 1.0\n            sigma = self._params[\'sigma\']\n            if mu > 1.0:\n                sigma = self._params[\'exact_sigma\']\n                mu = 1.0\n            self.kernels.append(GaussianKernel(mu=mu, sigma=sigma))\n\n        dim = self._params[\'max_ngram\'] ** 2 * self._params[\'kernel_num\']\n        self.out = self._make_output_layer(dim)\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        query, doc = inputs[\'text_left\'], inputs[\'text_right\']\n\n        q_embed = self.embedding(query.long()).transpose(1, 2)\n        d_embed = self.embedding(doc.long()).transpose(1, 2)\n\n        q_convs = []\n        d_convs = []\n        for q_conv, d_conv in zip(self.q_convs, self.d_convs):\n            q_convs.append(q_conv(q_embed).transpose(1, 2))\n            d_convs.append(d_conv(d_embed).transpose(1, 2))\n\n        KM = []\n        for qi in range(self._params[\'max_ngram\']):\n            for di in range(self._params[\'max_ngram\']):\n                # do not match n-gram with different length if use crossmatch\n                if not self._params[\'use_crossmatch\'] and qi != di:\n                    continue\n                mm = torch.einsum(\n                    \'bld,brd->blr\',\n                    F.normalize(q_convs[qi], p=2, dim=-1),\n                    F.normalize(d_convs[di], p=2, dim=-1)\n                )\n                for kernel in self.kernels:\n                    K = torch.log1p(kernel(mm).sum(dim=-1)).sum(dim=-1)\n                    KM.append(K)\n\n        phi = torch.stack(KM, dim=1)\n\n        out = self.out(phi)\n        return out\n'"
matchzoo/models/dense_baseline.py,1,"b'""""""A simple densely connected baseline model.""""""\nimport typing\n\nimport torch\n\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine import hyper_spaces\n\n\nclass DenseBaseline(BaseModel):\n    """"""\n    A simple densely connected baseline model.\n\n    Examples:\n        >>> model = DenseBaseline()\n        >>> model.params[\'mlp_num_layers\'] = 2\n        >>> model.params[\'mlp_num_units\'] = 300\n        >>> model.params[\'mlp_num_fan_out\'] = 128\n        >>> model.params[\'mlp_activation_func\'] = \'relu\'\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=True\n        )\n        params[\'mlp_num_units\'] = 256\n        params.get(\'mlp_num_units\').hyper_space = \\\n            hyper_spaces.quniform(16, 512)\n        params.get(\'mlp_num_layers\').hyper_space = \\\n            hyper_spaces.quniform(1, 5)\n        return params\n\n    def build(self):\n        """"""Build.""""""\n        self.embeddinng = self._make_default_embedding_layer()\n        self.mlp = self._make_multi_layer_perceptron_layer(\n            2 * self._params[\'embedding_output_dim\']\n        )\n        self.out = self._make_output_layer(\n            self._params[\'mlp_num_fan_out\']\n        )\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n        input_left, input_right = inputs[\'text_left\'], inputs[\'text_right\']\n        input_left = self.embeddinng(input_left.long()).sum(1)\n        input_right = self.embeddinng(input_right.long()).sum(1)\n        x = torch.cat((input_left, input_right), dim=1)\n        return self.out(self.mlp(x))\n'"
matchzoo/models/diin.py,5,"b'""""""An implementation of DIIN Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\nfrom matchzoo import preprocessors\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.modules import CharacterEmbedding, SemanticComposite, Matching, DenseNet\n\n\nclass DIIN(BaseModel):\n    """"""\n    DIIN model.\n\n    Examples:\n        >>> model = DIIN()\n        >>> model.params[\'embedding_input_dim\'] = 10000\n        >>> model.params[\'embedding_output_dim\'] = 300\n        >>> model.params[\'mask_value\'] = 0\n        >>> model.params[\'char_embedding_input_dim\'] = 100\n        >>> model.params[\'char_embedding_output_dim\'] = 8\n        >>> model.params[\'char_conv_filters\'] = 100\n        >>> model.params[\'char_conv_kernel_size\'] = 5\n        >>> model.params[\'first_scale_down_ratio\'] = 0.3\n        >>> model.params[\'nb_dense_blocks\'] = 3\n        >>> model.params[\'layers_per_dense_block\'] = 8\n        >>> model.params[\'growth_rate\'] = 20\n        >>> model.params[\'transition_scale_down_ratio\'] = 0.5\n        >>> model.params[\'conv_kernel_size\'] = (3, 3)\n        >>> model.params[\'pool_kernel_size\'] = (2, 2)\n        >>> model.params[\'dropout_rate\'] = 0.2\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True\n        )\n        params.add(Param(name=\'mask_value\', value=0,\n                         desc=""The value to be masked from inputs.""))\n        params.add(Param(name=\'char_embedding_input_dim\', value=100,\n                         desc=""The input dimension of character embedding layer.""))\n        params.add(Param(name=\'char_embedding_output_dim\', value=8,\n                         desc=""The output dimension of character embedding layer.""))\n        params.add(Param(name=\'char_conv_filters\', value=100,\n                         desc=""The filter size of character convolution layer.""))\n        params.add(Param(name=\'char_conv_kernel_size\', value=5,\n                         desc=""The kernel size of character convolution layer.""))\n        params.add(Param(name=\'first_scale_down_ratio\', value=0.3,\n                         desc=""The channel scale down ratio of the convolution layer ""\n                              ""before densenet.""))\n        params.add(Param(name=\'nb_dense_blocks\', value=3,\n                         desc=""The number of blocks in densenet.""))\n        params.add(Param(name=\'layers_per_dense_block\', value=8,\n                         desc=""The number of convolution layers in dense block.""))\n        params.add(Param(name=\'growth_rate\', value=20,\n                         desc=""The filter size of each convolution layer in dense ""\n                              ""block.""))\n        params.add(Param(name=\'transition_scale_down_ratio\', value=0.5,\n                         desc=""The channel scale down ratio of the convolution layer ""\n                              ""in transition block.""))\n        params.add(Param(name=\'conv_kernel_size\', value=(3, 3),\n                         desc=""The kernel size of convolution layer in dense block.""))\n        params.add(Param(name=\'pool_kernel_size\', value=(2, 2),\n                         desc=""The kernel size of pooling layer in transition block.""))\n        params.add(Param(\n            \'dropout_rate\', 0.0,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""The dropout rate.""\n        ))\n        return params\n\n    @classmethod\n    def get_default_preprocessor(\n        cls,\n        truncated_mode: str = \'pre\',\n        truncated_length_left: typing.Optional[int] = None,\n        truncated_length_right: typing.Optional[int] = None,\n        filter_mode: str = \'df\',\n        filter_low_freq: float = 1,\n        filter_high_freq: float = float(\'inf\'),\n        remove_stop_words: bool = False,\n        ngram_size: typing.Optional[int] = 1,\n    ) -> BasePreprocessor:\n        """"""\n        Model default preprocessor.\n\n        The preprocessor\'s transform should produce a correctly shaped data\n        pack that can be used for training.\n\n        :return: Default preprocessor.\n        """"""\n        return preprocessors.BasicPreprocessor(\n            truncated_mode=truncated_mode,\n            truncated_length_left=truncated_length_left,\n            truncated_length_right=truncated_length_right,\n            filter_mode=filter_mode,\n            filter_low_freq=filter_low_freq,\n            filter_high_freq=filter_high_freq,\n            remove_stop_words=remove_stop_words,\n            ngram_size=ngram_size\n        )\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = 10,\n        fixed_length_right: int = 30,\n        pad_word_value: typing.Union[int, str] = 0,\n        pad_word_mode: str = \'pre\',\n        with_ngram: bool = True,\n        fixed_ngram_length: int = None,\n        pad_ngram_value: typing.Union[int, str] = 0,\n        pad_ngram_mode: str = \'pre\'\n    ) -> BaseCallback:\n        """"""\n        Model default padding callback.\n\n        The padding callback\'s on_batch_unpacked would pad a batch of data to\n        a fixed length.\n\n        :return: Default padding callback.\n        """"""\n        return callbacks.BasicPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_word_value=pad_word_value,\n            pad_word_mode=pad_word_mode,\n            with_ngram=with_ngram,\n            fixed_ngram_length=fixed_ngram_length,\n            pad_ngram_value=pad_ngram_value,\n            pad_ngram_mode=pad_ngram_mode\n        )\n\n    def build(self):\n        """"""Build model structure.""""""\n        # Embedding\n        self.embedding = self._make_default_embedding_layer()\n        self.char_embedding = CharacterEmbedding(\n            char_embedding_input_dim=self._params[\'char_embedding_input_dim\'],\n            char_embedding_output_dim=self._params[\'char_embedding_output_dim\'],\n            char_conv_filters=self._params[\'char_conv_filters\'],\n            char_conv_kernel_size=self._params[\'char_conv_kernel_size\']\n        )\n        self.exact_maching = Matching(matching_type=\'exact\')\n        all_embed_dim = self._params[\'embedding_output_dim\'] \\\n            + self._params[\'char_conv_filters\'] + 1\n\n        # Encoding\n        self.left_encoder = SemanticComposite(\n            all_embed_dim, self._params[\'dropout_rate\'])\n        self.right_encoder = SemanticComposite(\n            all_embed_dim, self._params[\'dropout_rate\'])\n\n        # Interaction\n        self.matching = Matching(matching_type=\'mul\')\n\n        # Feature Extraction\n        self.conv = nn.Conv2d(\n            in_channels=all_embed_dim,\n            out_channels=int(all_embed_dim * self._params[\'first_scale_down_ratio\']),\n            kernel_size=1\n        )\n        self.dense_net = DenseNet(\n            in_channels=int(all_embed_dim * self._params[\'first_scale_down_ratio\']),\n            nb_dense_blocks=self._params[\'nb_dense_blocks\'],\n            layers_per_dense_block=self._params[\'layers_per_dense_block\'],\n            growth_rate=self._params[\'growth_rate\'],\n            transition_scale_down_ratio=self._params[\'transition_scale_down_ratio\'],\n            conv_kernel_size=self._params[\'conv_kernel_size\'],\n            pool_kernel_size=self._params[\'pool_kernel_size\']\n        )\n        self.max_pooling = nn.AdaptiveMaxPool2d((1, 1))\n\n        # Output\n        self.out_layer = self._make_output_layer(self.dense_net.out_channels)\n\n        self.dropout = nn.Dropout(p=self._params[\'dropout_rate\'])\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   L = `input_word_left` sequence length\n        #   R = `input_word_right` sequence length\n        #   C = word length\n        #   D1 = word embedding size\n        #   D2 = character embedding size\n\n        # shape = [B, L]\n        # shape = [B, R]\n        input_word_left, input_word_right = inputs[\'text_left\'], inputs[\'text_right\']\n        mask_word_left = (input_word_left == self._params[\'mask_value\'])\n        mask_word_right = (input_word_right == self._params[\'mask_value\'])\n\n        # shape = [B, L, C]\n        # shape = [B, R, C]\n        input_char_left, input_char_right = inputs[\'ngram_left\'], inputs[\'ngram_right\']\n\n        # shape = [B, L, D1]\n        # shape = [B, R, D1]\n        embed_word_left = self.dropout(self.embedding(input_word_left.long()))\n        embed_word_right = self.dropout(self.embedding(input_word_right.long()))\n\n        # shape = [B, L, D2]\n        # shape = [B, R, D2]\n        embed_char_left = self.dropout(self.char_embedding(input_char_left.long()))\n        embed_char_right = self.dropout(self.char_embedding(input_char_right.long()))\n\n        # shape = [B, L, 1]\n        # shape = [B, R, 1]\n        exact_match_left, exact_match_right = self.exact_maching(\n            input_word_left, input_word_right)\n        exact_match_left = exact_match_left.masked_fill(mask_word_left, 0)\n        exact_match_right = exact_match_right.masked_fill(mask_word_right, 0)\n        exact_match_left = torch.unsqueeze(exact_match_left, dim=-1)\n        exact_match_right = torch.unsqueeze(exact_match_right, dim=-1)\n\n        # shape = [B, L, D]\n        # shape = [B, R, D]\n        embed_left = torch.cat(\n            [embed_word_left, embed_char_left, exact_match_left], dim=-1)\n        embed_right = torch.cat(\n            [embed_word_right, embed_char_right, exact_match_right], dim=-1)\n\n        encode_left = self.left_encoder(embed_left)\n        encode_right = self.right_encoder(embed_right)\n\n        # shape = [B, L, R, D]\n        interaction = self.matching(encode_left, encode_right)\n\n        interaction = self.conv(self.dropout(interaction.permute(0, 3, 1, 2)))\n        interaction = self.dense_net(interaction)\n        interaction = self.max_pooling(interaction).squeeze(dim=-1).squeeze(dim=-1)\n\n        output = self.out_layer(interaction)\n        return output\n'"
matchzoo/models/drmm.py,2,"b'""""""An implementation of DRMM Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.modules import Attention\n\n\nclass DRMM(BaseModel):\n    """"""\n    DRMM Model.\n\n    Examples:\n        >>> model = DRMM()\n        >>> model.params[\'mlp_num_layers\'] = 1\n        >>> model.params[\'mlp_num_units\'] = 5\n        >>> model.params[\'mlp_num_fan_out\'] = 1\n        >>> model.params[\'mlp_activation_func\'] = \'tanh\'\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=True\n        )\n        params.add(Param(name=\'mask_value\', value=0,\n                         desc=""The value to be masked from inputs.""))\n        params.add(Param(name=\'hist_bin_size\', value=30,\n                         desc=""The number of bin size of the histogram.""))\n        params[\'mlp_num_fan_out\'] = 1\n        return params\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = None,\n        fixed_length_right: int = None,\n        pad_value: typing.Union[int, str] = 0,\n        pad_mode: str = \'pre\'\n    ):\n        """""":return: Default padding callback.""""""\n        return callbacks.DRMMPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_value=pad_value,\n            pad_mode=pad_mode\n        )\n\n    def build(self):\n        """"""Build model structure.""""""\n        self.embedding = self._make_default_embedding_layer()\n        self.attention = Attention(\n            input_size=self._params[\'embedding_output_dim\']\n        )\n        self.mlp = self._make_multi_layer_perceptron_layer(\n            self._params[\'hist_bin_size\']\n        )\n        self.out = self._make_output_layer(1)\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   H = histogram size\n        #   K = size of top-k\n\n        # Left input and right input.\n        # query: shape = [B, L]\n        # doc: shape = [B, L, H]\n        # Note here, the doc is the matching histogram between original query\n        # and original document.\n\n        query, match_hist = inputs[\'text_left\'], inputs[\'match_histogram\']\n\n        # shape = [B, L]\n        mask_query = (query == self._params[\'mask_value\'])\n\n        # Process left input.\n        # shape = [B, L, D]\n        embed_query = self.embedding(query.long())\n\n        # shape = [B, L]\n        attention_probs = self.attention(embed_query, mask_query)\n\n        # shape = [B, L]\n        dense_output = self.mlp(match_hist).squeeze(dim=-1)\n\n        x = torch.einsum(\'bl,bl->b\', dense_output, attention_probs)\n\n        out = self.out(x.unsqueeze(dim=-1))\n        return out\n'"
matchzoo/models/drmmtks.py,5,"b'""""""An implementation of DRMMTKS Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.modules import Attention\n\n\nclass DRMMTKS(BaseModel):\n    """"""\n    DRMMTKS Model.\n\n    Examples:\n        >>> model = DRMMTKS()\n        >>> model.params[\'top_k\'] = 10\n        >>> model.params[\'mlp_num_layers\'] = 1\n        >>> model.params[\'mlp_num_units\'] = 5\n        >>> model.params[\'mlp_num_fan_out\'] = 1\n        >>> model.params[\'mlp_activation_func\'] = \'tanh\'\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=True\n        )\n        params.add(Param(name=\'mask_value\', value=0,\n                         desc=""The value to be masked from inputs.""))\n        params.add(Param(\n            \'top_k\', value=10,\n            hyper_space=hyper_spaces.quniform(low=2, high=100),\n            desc=""Size of top-k pooling layer.""\n        ))\n        params[\'mlp_num_fan_out\'] = 1\n        return params\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = 10,\n        fixed_length_right: int = 100,\n        pad_word_value: typing.Union[int, str] = 0,\n        pad_word_mode: str = \'pre\',\n        with_ngram: bool = False,\n        fixed_ngram_length: int = None,\n        pad_ngram_value: typing.Union[int, str] = 0,\n        pad_ngram_mode: str = \'pre\'\n    ) -> BaseCallback:\n        """"""\n        Model default padding callback.\n\n        The padding callback\'s on_batch_unpacked would pad a batch of data to\n        a fixed length.\n\n        :return: Default padding callback.\n        """"""\n        return callbacks.BasicPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_word_value=pad_word_value,\n            pad_word_mode=pad_word_mode,\n            with_ngram=with_ngram,\n            fixed_ngram_length=fixed_ngram_length,\n            pad_ngram_value=pad_ngram_value,\n            pad_ngram_mode=pad_ngram_mode\n        )\n\n    def build(self):\n        """"""Build model structure.""""""\n        self.embedding = self._make_default_embedding_layer()\n        self.attention = Attention(\n            input_size=self._params[\'embedding_output_dim\']\n        )\n        self.mlp = self._make_multi_layer_perceptron_layer(\n            self._params[\'top_k\']\n        )\n        self.out = self._make_output_layer(1)\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   K = size of top-k\n\n        # Left input and right input.\n        # shape = [B, L]\n        # shape = [B, R]\n        query, doc = inputs[\'text_left\'], inputs[\'text_right\']\n\n        # shape = [B, L]\n        mask_query = (query == self._params[\'mask_value\'])\n\n        # Process left input.\n        # shape = [B, L, D]\n        embed_query = self.embedding(query.long())\n        # shape = [B, R, D]\n        embed_doc = self.embedding(doc.long())\n\n        # Matching histogram of top-k\n        # shape = [B, L, R]\n        matching_matrix = torch.einsum(\n            \'bld,brd->blr\',\n            F.normalize(embed_query, p=2, dim=-1),\n            F.normalize(embed_doc, p=2, dim=-1)\n        )\n\n        # shape = [B, L, K]\n        matching_topk = torch.topk(\n            matching_matrix,\n            k=self._params[\'top_k\'],\n            dim=-1,\n            sorted=True\n        )[0]\n        # shape = [B, L]\n        attention_probs = self.attention(embed_query, mask_query)\n\n        # shape = [B, L]\n        dense_output = self.mlp(matching_topk).squeeze(dim=-1)\n\n        x = torch.einsum(\'bl,bl->b\', dense_output, attention_probs)\n\n        out = self.out(x.unsqueeze(dim=-1))\n        return out\n'"
matchzoo/models/dssm.py,1,"b'""""""An implementation of DSSM, Deep Structured Semantic Model.""""""\nimport typing\n\nimport torch\nimport torch.nn.functional as F\n\nfrom matchzoo import preprocessors\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\n\n\nclass DSSM(BaseModel):\n    """"""\n    Deep structured semantic model.\n\n    Examples:\n        >>> model = DSSM()\n        >>> model.params[\'mlp_num_layers\'] = 3\n        >>> model.params[\'mlp_num_units\'] = 300\n        >>> model.params[\'mlp_num_fan_out\'] = 128\n        >>> model.params[\'mlp_activation_func\'] = \'relu\'\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(with_multi_layer_perceptron=True)\n        params.add(Param(name=\'vocab_size\', value=419,\n                         desc=""Size of vocabulary.""))\n        return params\n\n    @classmethod\n    def get_default_preprocessor(\n        cls,\n        truncated_mode: str = \'pre\',\n        truncated_length_left: typing.Optional[int] = None,\n        truncated_length_right: typing.Optional[int] = None,\n        filter_mode: str = \'df\',\n        filter_low_freq: float = 1,\n        filter_high_freq: float = float(\'inf\'),\n        remove_stop_words: bool = False,\n        ngram_size: typing.Optional[int] = 3,\n    ) -> BasePreprocessor:\n        """"""\n        Model default preprocessor.\n\n        The preprocessor\'s transform should produce a correctly shaped data\n        pack that can be used for training.\n\n        :return: Default preprocessor.\n        """"""\n        return preprocessors.BasicPreprocessor(\n            truncated_mode=truncated_mode,\n            truncated_length_left=truncated_length_left,\n            truncated_length_right=truncated_length_right,\n            filter_mode=filter_mode,\n            filter_low_freq=filter_low_freq,\n            filter_high_freq=filter_high_freq,\n            remove_stop_words=remove_stop_words,\n            ngram_size=ngram_size\n        )\n\n    @classmethod\n    def get_default_padding_callback(cls):\n        """""":return: Default padding callback.""""""\n        return None\n\n    def build(self):\n        """"""\n        Build model structure.\n\n        DSSM use Siamese arthitecture.\n        """"""\n        self.mlp_left = self._make_multi_layer_perceptron_layer(\n            self._params[\'vocab_size\']\n        )\n        self.mlp_right = self._make_multi_layer_perceptron_layer(\n            self._params[\'vocab_size\']\n        )\n        self.out = self._make_output_layer(1)\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n        # Process left & right input.\n        input_left, input_right = inputs[\'ngram_left\'], inputs[\'ngram_right\']\n        input_left = self.mlp_left(input_left)\n        input_right = self.mlp_right(input_right)\n\n        # Dot product with cosine similarity.\n        x = F.cosine_similarity(input_left, input_right)\n\n        out = self.out(x.unsqueeze(dim=1))\n        return out\n'"
matchzoo/models/duet.py,9,"b'""""""An implementation of DUET Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom matchzoo import preprocessors\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.modules import Attention\nfrom matchzoo.utils import parse_activation\n\n\nclass DUET(BaseModel):\n    """"""\n    Duet Model.\n\n    Examples:\n        >>> model = DUET()\n        >>> model.params[\'left_length\'] = 10\n        >>> model.params[\'right_length\'] = 40\n        >>> model.params[\'lm_filters\'] = 300\n        >>> model.params[\'mlp_num_layers\'] = 2\n        >>> model.params[\'mlp_num_units\'] = 300\n        >>> model.params[\'mlp_num_fan_out\'] = 300\n        >>> model.params[\'mlp_activation_func\'] = \'relu\'\n        >>> model.params[\'vocab_size\'] = 2000\n        >>> model.params[\'dm_filters\'] = 300\n        >>> model.params[\'dm_conv_activation_func\'] = \'relu\'\n        >>> model.params[\'dm_kernel_size\'] = 3\n        >>> model.params[\'dm_right_pool_size\'] = 8\n        >>> model.params[\'dropout_rate\'] = 0.5\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=False,\n            with_multi_layer_perceptron=True\n        )\n        params.add(Param(name=\'mask_value\', value=0,\n                         desc=""The value to be masked from inputs.""))\n        params.add(Param(name=\'left_length\', value=10,\n                         desc=\'Length of left input.\'))\n        params.add(Param(name=\'right_length\', value=40,\n                         desc=\'Length of right input.\'))\n        params.add(Param(name=\'lm_filters\', value=300,\n                         desc=""Filter size of 1D convolution layer in ""\n                              ""the local model.""))\n        params.add(Param(name=\'vocab_size\', value=419,\n                         desc=""Vocabulary size of the tri-letters used in ""\n                              ""the distributed model.""))\n        params.add(Param(name=\'dm_filters\', value=300,\n                         desc=""Filter size of 1D convolution layer in ""\n                              ""the distributed model.""))\n        params.add(Param(name=\'dm_kernel_size\', value=3,\n                         desc=""Kernel size of 1D convolution layer in ""\n                              ""the distributed model.""))\n        params.add(Param(name=\'dm_conv_activation_func\', value=\'relu\',\n                         desc=""Activation functions of the convolution layer ""\n                              ""in the distributed model.""))\n        params.add(Param(name=\'dm_right_pool_size\', value=8,\n                         desc=""Kernel size of 1D convolution layer in ""\n                              ""the distributed model.""))\n        params.add(Param(\n            name=\'dropout_rate\', value=0.5,\n            hyper_space=hyper_spaces.quniform(low=0.0, high=0.8, q=0.02),\n            desc=""The dropout rate.""))\n        return params\n\n    @classmethod\n    def get_default_preprocessor(\n        cls,\n        truncated_mode: str = \'pre\',\n        truncated_length_left: int = 10,\n        truncated_length_right: int = 40,\n        filter_mode: str = \'df\',\n        filter_low_freq: float = 1,\n        filter_high_freq: float = float(\'inf\'),\n        remove_stop_words: bool = False,\n        ngram_size: int = 3\n    ):\n        """""":return: Default preprocessor.""""""\n        return preprocessors.BasicPreprocessor(\n            truncated_mode=truncated_mode,\n            truncated_length_left=truncated_length_left,\n            truncated_length_right=truncated_length_right,\n            filter_mode=filter_mode,\n            filter_low_freq=filter_low_freq,\n            filter_high_freq=filter_high_freq,\n            remove_stop_words=remove_stop_words,\n            ngram_size=ngram_size\n        )\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = 10,\n        fixed_length_right: int = 40,\n        pad_word_value: typing.Union[int, str] = 0,\n        pad_word_mode: str = \'pre\',\n        with_ngram: bool = True,\n        fixed_ngram_length: int = None,\n        pad_ngram_value: typing.Union[int, str] = 0,\n        pad_ngram_mode: str = \'pre\'\n    ) -> BaseCallback:\n        """"""\n        Model default padding callback.\n\n        The padding callback\'s on_batch_unpacked would pad a batch of data to\n        a fixed length.\n\n        :return: Default padding callback.\n        """"""\n        return callbacks.BasicPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_word_value=pad_word_value,\n            pad_word_mode=pad_word_mode,\n            with_ngram=with_ngram,\n            fixed_ngram_length=fixed_ngram_length,\n            pad_ngram_value=pad_ngram_value,\n            pad_ngram_mode=pad_ngram_mode\n        )\n\n    @classmethod\n    def _xor_match(cls, x, y):\n        """"""Xor match of two inputs.""""""\n        x_expand = torch.unsqueeze(x, 2).repeat(1, 1, y.shape[1])\n        y_expand = torch.unsqueeze(y, 1).repeat(1, x.shape[1], 1)\n        out = torch.eq(x_expand, y_expand).float()\n        return out\n\n    def build(self):\n        """"""Build model structure.""""""\n        self.lm_conv1d = nn.Conv1d(\n            in_channels=self._params[\'right_length\'],\n            out_channels=self.params[\'lm_filters\'],\n            kernel_size=1,\n            stride=1\n        )\n        lm_mlp_size = self._params[\'left_length\'] * self._params[\'lm_filters\']\n        self.lm_mlp = self._make_multi_layer_perceptron_layer(lm_mlp_size)\n        self.lm_linear = self._make_perceptron_layer(\n            in_features=self._params[\'mlp_num_fan_out\'],\n            out_features=1\n        )\n\n        self.dm_conv_activation_func = parse_activation(\n            self._params[\'dm_conv_activation_func\']\n        )\n        self.dm_conv_left = nn.Conv1d(\n            self._params[\'vocab_size\'],\n            self._params[\'dm_filters\'],\n            self._params[\'dm_kernel_size\']\n        )\n        self.dm_mlp_left = self._make_perceptron_layer(\n            in_features=self._params[\'dm_filters\'],\n            out_features=self._params[\'dm_filters\']\n        )\n        self.dm_conv1_right = nn.Conv1d(\n            self._params[\'vocab_size\'],\n            self._params[\'dm_filters\'],\n            self._params[\'dm_kernel_size\']\n        )\n        self.dm_conv2_right = nn.Conv1d(\n            self._params[\'dm_filters\'],\n            self._params[\'dm_filters\'],\n            1\n        )\n        dm_mp_size = (\n            (self._params[\'right_length\'] - self._params[\'dm_kernel_size\'] + 1) // (\n                self._params[\'dm_right_pool_size\']) * self._params[\'dm_filters\']\n        )\n        self.dm_mlp = self._make_multi_layer_perceptron_layer(dm_mp_size)\n        self.dm_linear = self._make_perceptron_layer(\n            in_features=self._params[\'mlp_num_fan_out\'],\n            out_features=1\n        )\n\n        self.dropout = nn.Dropout(self._params[\'dropout_rate\'])\n\n        self.out = self._make_output_layer(1)\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n\n        # Left input and right input.\n        # shape = [B, L]\n        # shape = [B, R]\n        query_word, doc_word = inputs[\'text_left\'], inputs[\'text_right\']\n\n        # shape = [B, L]\n        mask_query = (query_word != self._params[\'mask_value\']).float()\n        mask_doc = (doc_word != self._params[\'mask_value\']).float()\n\n        # shape = [B, ngram_size, L]\n        # shape = [B, ngram_size, R]\n        query_ngram, doc_ngram = inputs[\'ngram_left\'], inputs[\'ngram_right\']\n\n        query_ngram = F.normalize(query_ngram, p=2, dim=2)\n        doc_ngram = F.normalize(doc_ngram, p=2, dim=2)\n\n        # shape = [B, R, L]\n        matching_xor = self._xor_match(doc_word, query_word)\n        mask_xor = torch.einsum(\'bi, bj->bij\', mask_doc, mask_query)\n        xor_res = torch.einsum(\'bij, bij->bij\', matching_xor, mask_xor)\n\n        # Process local model\n        lm_res = self.lm_conv1d(xor_res)\n        lm_res = lm_res.flatten(start_dim=1, end_dim=-1)\n        lm_res = self.lm_mlp(lm_res)\n        lm_res = self.dropout(lm_res)\n        lm_res = self.lm_linear(lm_res)\n\n        # Process distributed model\n        dm_left = self.dm_conv_left(query_ngram.permute(0, 2, 1))\n        dm_left = self.dm_conv_activation_func(dm_left)\n        dm_left = torch.max(dm_left, dim=-1)[0]\n        dm_left = self.dm_mlp_left(dm_left)\n\n        dm_right = self.dm_conv1_right(doc_ngram.permute(0, 2, 1))\n        dm_right = F.max_pool2d(\n            self.dm_conv_activation_func(dm_right),\n            (1, self._params[\'dm_right_pool_size\'])\n        )\n        dm_right = self.dm_conv2_right(dm_right)\n\n        dm_res = torch.einsum(\'bl,blk->blk\', dm_left, dm_right)\n        dm_res = dm_res.flatten(start_dim=1, end_dim=-1)\n        dm_res = self.dm_mlp(dm_res)\n        dm_res = self.dropout(dm_res)\n        dm_res = self.dm_linear(dm_res)\n\n        x = lm_res + dm_res\n\n        out = self.out(x)\n        return out\n'"
matchzoo/models/esim.py,9,"b'""""""An implementation of ESIM Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.modules import RNNDropout\nfrom matchzoo.modules import BidirectionalAttention\nfrom matchzoo.modules import StackedBRNN\n\n\nclass ESIM(BaseModel):\n    """"""\n    ESIM Model.\n\n    Examples:\n        >>> model = ESIM()\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=False\n        )\n        params.add(Param(name=\'mask_value\', value=0,\n                         desc=""The value to be masked from inputs.""))\n        params.add(Param(name=\'dropout\', value=0.2,\n                         desc=""Dropout rate.""))\n        params.add(Param(name=\'hidden_size\', value=200,\n                         desc=""Hidden size.""))\n        params.add(Param(name=\'lstm_layer\', value=1,\n                         desc=""Number of LSTM layers""))\n        params.add(Param(name=\'drop_lstm\', value=False,\n                         desc=""Whether dropout LSTM.""))\n        params.add(Param(name=\'concat_lstm\', value=True,\n                         desc=""Whether concat intermediate outputs.""))\n        params.add(Param(name=\'rnn_type\', value=\'lstm\',\n                         desc=""Choose rnn type, lstm or gru.""))\n        return params\n\n    def build(self):\n        """"""Instantiating layers.""""""\n        rnn_mapping = {\'lstm\': nn.LSTM, \'gru\': nn.GRU}\n        self.embedding = self._make_default_embedding_layer()\n        self.rnn_dropout = RNNDropout(p=self._params[\'dropout\'])\n        lstm_size = self._params[\'hidden_size\']\n        if self._params[\'concat_lstm\']:\n            lstm_size /= self._params[\'lstm_layer\']\n        self.input_encoding = StackedBRNN(\n            self._params[\'embedding_output_dim\'],\n            int(lstm_size / 2),\n            self._params[\'lstm_layer\'],\n            dropout_rate=self._params[\'dropout\'],\n            dropout_output=self._params[\'drop_lstm\'],\n            rnn_type=rnn_mapping[self._params[\'rnn_type\'].lower()],\n            concat_layers=self._params[\'concat_lstm\'])\n        self.attention = BidirectionalAttention()\n        self.projection = nn.Sequential(\n            nn.Linear(\n                4 * self._params[\'hidden_size\'],\n                self._params[\'hidden_size\']),\n            nn.ReLU())\n        self.composition = StackedBRNN(\n            self._params[\'hidden_size\'],\n            int(lstm_size / 2),\n            self._params[\'lstm_layer\'],\n            dropout_rate=self._params[\'dropout\'],\n            dropout_output=self._params[\'drop_lstm\'],\n            rnn_type=rnn_mapping[self._params[\'rnn_type\'].lower()],\n            concat_layers=self._params[\'concat_lstm\'])\n        self.classification = nn.Sequential(\n            nn.Dropout(\n                p=self._params[\'dropout\']),\n            nn.Linear(\n                4 * self._params[\'hidden_size\'],\n                self._params[\'hidden_size\']),\n            nn.Tanh(),\n            nn.Dropout(\n                p=self._params[\'dropout\']))\n        self.out = self._make_output_layer(self._params[\'hidden_size\'])\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n        # Scalar dimensions referenced here:\n        # B = batch size (number of sequences)\n        # D = embedding size\n        # L = `input_left` sequence length\n        # R = `input_right` sequence length\n        # H = hidden size\n\n        # [B, L], [B, R]\n        query, doc = inputs[\'text_left\'].long(), inputs[\'text_right\'].long()\n\n        # [B, L]\n        # [B, R]\n        query_mask = (query == self._params[\'mask_value\'])\n        doc_mask = (doc == self._params[\'mask_value\'])\n\n        # [B, L, D]\n        # [B, R, D]\n        query = self.embedding(query)\n        doc = self.embedding(doc)\n\n        # [B, L, D]\n        # [B, R, D]\n        query = self.rnn_dropout(query)\n        doc = self.rnn_dropout(doc)\n\n        # [B, L, H]\n        # [B, R, H]\n        query = self.input_encoding(query, query_mask)\n        doc = self.input_encoding(doc, doc_mask)\n\n        # [B, L, H], [B, L, H]\n        attended_query, attended_doc = self.attention(\n            query, query_mask, doc, doc_mask)\n\n        # [B, L, 4 * H]\n        # [B, L, 4 * H]\n        enhanced_query = torch.cat([query,\n                                    attended_query,\n                                    query - attended_query,\n                                    query * attended_query],\n                                   dim=-1)\n        enhanced_doc = torch.cat([doc,\n                                  attended_doc,\n                                  doc - attended_doc,\n                                  doc * attended_doc],\n                                 dim=-1)\n        # [B, L, H]\n        # [B, L, H]\n        projected_query = self.projection(enhanced_query)\n        projected_doc = self.projection(enhanced_doc)\n\n        # [B, L, H]\n        # [B, L, H]\n        query = self.composition(projected_query, query_mask)\n        doc = self.composition(projected_doc, doc_mask)\n\n        # [B, L]\n        # [B, R]\n        reverse_query_mask = 1. - query_mask.float()\n        reverse_doc_mask = 1. - doc_mask.float()\n\n        # [B, H]\n        # [B, H]\n        query_avg = torch.sum(query * reverse_query_mask.unsqueeze(2), dim=1)\\\n            / (torch.sum(reverse_query_mask, dim=1, keepdim=True) + 1e-8)\n        doc_avg = torch.sum(doc * reverse_doc_mask.unsqueeze(2), dim=1)\\\n            / (torch.sum(reverse_doc_mask, dim=1, keepdim=True) + 1e-8)\n\n        # [B, L, H]\n        # [B, L, H]\n        query = query.masked_fill(query_mask.unsqueeze(2), -1e7)\n        doc = doc.masked_fill(doc_mask.unsqueeze(2), -1e7)\n\n        # [B, H]\n        # [B, H]\n        query_max, _ = query.max(dim=1)\n        doc_max, _ = doc.max(dim=1)\n\n        # [B, 4 * H]\n        v = torch.cat([query_avg, query_max, doc_avg, doc_max], dim=-1)\n\n        # [B, H]\n        hidden = self.classification(v)\n\n        # [B, num_classes]\n        out = self.out(hidden)\n\n        return out\n'"
matchzoo/models/hbmp.py,7,"b'""""""An implementation of HBMP Model.""""""\nimport typing\n\nimport copy\nimport torch\nimport torch.nn as nn\n\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\n\n\nclass HBMP(BaseModel):\n    """"""\n    HBMP model.\n\n    Examples:\n        >>> model = HBMP()\n        >>> model.params[\'embedding_input_dim\'] = 200\n        >>> model.params[\'embedding_output_dim\'] = 100\n        >>> model.params[\'mlp_num_layers\'] = 1\n        >>> model.params[\'mlp_num_units\'] = 10\n        >>> model.params[\'mlp_num_fan_out\'] = 10\n        >>> model.params[\'mlp_activation_func\'] = nn.LeakyReLU(0.1)\n        >>> model.params[\'lstm_hidden_size\'] = 5\n        >>> model.params[\'lstm_num\'] = 3\n        >>> model.params[\'num_layers\'] = 3\n        >>> model.params[\'dropout_rate\'] = 0.1\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True, with_multi_layer_perceptron=True)\n        params.add(Param(name=\'lstm_hidden_size\', value=5,\n                         desc=""Integer, the hidden size of the ""\n                              ""bi-directional LSTM layer.""))\n        params.add(Param(name=\'lstm_num\', value=3,\n                         desc=""Integer, number of LSTM units""))\n        params.add(Param(name=\'num_layers\', value=1,\n                         desc=""Integer, number of LSTM layers.""))\n        params.add(Param(\n            name=\'dropout_rate\', value=0.0,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""The dropout rate.""\n        ))\n        return params\n\n    def build(self):\n        """"""\n        Build model structure.\n\n        HBMP use Siamese arthitecture.\n        """"""\n        self.embedding = self._make_default_embedding_layer()\n\n        encoder_layer = nn.LSTM(\n            input_size=self._params[\'embedding_output_dim\'],\n            hidden_size=self._params[\'lstm_hidden_size\'],\n            num_layers=self._params[\'num_layers\'],\n            dropout=self._params[\'dropout_rate\'],\n            batch_first=True,\n            bidirectional=True)\n        self.encoder = nn.ModuleList(\n            [copy.deepcopy(encoder_layer)\n             for _ in range(self._params[\'lstm_num\'])])\n        self.max_pool = nn.AdaptiveMaxPool1d(1)\n\n        self.mlp = self._make_multi_layer_perceptron_layer(\n            self._params[\'lstm_hidden_size\'] * 24\n        )\n\n        self.out = self._make_output_layer(\n            self._params[\'mlp_num_fan_out\']\n        )\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   F = hidden size of LSTM layer\n\n        # Left input and right input.\n        # shape = [B, L]\n        # shape = [B, R]\n        input_left, input_right = inputs[\'text_left\'], inputs[\'text_right\']\n        batch_size = input_left.shape[0]\n        state_shape = (\n            2 * self._params[\'num_layers\'], batch_size,\n            self._params[\'lstm_hidden_size\']\n        )\n\n        # shape = [B, L, D]\n        # shape = [B, R, D]\n        embed_left = self.embedding(input_left.long())\n        embed_right = self.embedding(input_right.long())\n\n        out_left = []\n        h_left = c_left = torch.zeros(*state_shape, device=input_left.device)\n        for layer in self.encoder:\n            out, (h_left, c_left) = layer(embed_left, (h_left, c_left))\n            out_left.append(self.max_pool(out.transpose(1, 2)).squeeze(2))\n\n        out_right = []\n        h_right = c_right = torch.zeros(*state_shape, device=input_left.device)\n        for layer in self.encoder:\n            out, (h_right, c_right) = layer(embed_right, (h_right, c_right))\n            out_right.append(self.max_pool(out.transpose(1, 2)).squeeze(2))\n\n        # shape = [B, 6 * F]\n        encode_left = torch.cat(out_left, 1)\n        encode_right = torch.cat(out_right, 1)\n\n        embed_minus = torch.abs(encode_left - encode_right)\n        embed_multiply = encode_left * encode_right\n        encode_concat = torch.cat(\n            [encode_left, encode_right, embed_minus, embed_multiply], 1)\n\n        output = self.mlp(encode_concat)\n        output = self.out(output)\n\n        return output\n'"
matchzoo/models/knrm.py,5,"b'""""""An implementation of KNRM Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.modules import GaussianKernel\n\n\nclass KNRM(BaseModel):\n    """"""\n    KNRM Model.\n\n    Examples:\n        >>> model = KNRM()\n        >>> model.params[\'kernel_num\'] = 11\n        >>> model.params[\'sigma\'] = 0.1\n        >>> model.params[\'exact_sigma\'] = 0.001\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(with_embedding=True)\n        params.add(Param(\n            name=\'kernel_num\',\n            value=11,\n            hyper_space=hyper_spaces.quniform(low=5, high=20),\n            desc=""The number of RBF kernels.""\n        ))\n        params.add(Param(\n            name=\'sigma\',\n            value=0.1,\n            hyper_space=hyper_spaces.quniform(\n                low=0.01, high=0.2, q=0.01),\n            desc=""The `sigma` defines the kernel width.""\n        ))\n        params.add(Param(\n            name=\'exact_sigma\', value=0.001,\n            desc=""The `exact_sigma` denotes the `sigma` ""\n                 ""for exact match.""\n        ))\n        return params\n\n    def build(self):\n        """"""Build model structure.""""""\n        self.embedding = self._make_default_embedding_layer()\n\n        self.kernels = nn.ModuleList()\n        for i in range(self._params[\'kernel_num\']):\n            mu = 1. / (self._params[\'kernel_num\'] - 1) + (2. * i) / (\n                self._params[\'kernel_num\'] - 1) - 1.0\n            sigma = self._params[\'sigma\']\n            if mu > 1.0:\n                sigma = self._params[\'exact_sigma\']\n                mu = 1.0\n            self.kernels.append(GaussianKernel(mu=mu, sigma=sigma))\n\n        self.out = self._make_output_layer(self._params[\'kernel_num\'])\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   K = number of kernels\n\n        # Left input and right input.\n        # shape = [B, L]\n        # shape = [B, R]\n        query, doc = inputs[\'text_left\'], inputs[\'text_right\']\n\n        # Process left input.\n        # shape = [B, L, D]\n        embed_query = self.embedding(query.long())\n        # shape = [B, R, D]\n        embed_doc = self.embedding(doc.long())\n\n        # shape = [B, L, R]\n        matching_matrix = torch.einsum(\n            \'bld,brd->blr\',\n            F.normalize(embed_query, p=2, dim=-1),\n            F.normalize(embed_doc, p=2, dim=-1)\n        )\n\n        KM = []\n        for kernel in self.kernels:\n            # shape = [B]\n            K = torch.log1p(kernel(matching_matrix).sum(dim=-1)).sum(dim=-1)\n            KM.append(K)\n\n        # shape = [B, K]\n        phi = torch.stack(KM, dim=1)\n\n        out = self.out(phi)\n        return out\n'"
matchzoo/models/match_pyramid.py,2,"b'""""""An implementation of MatchPyramid Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.modules import Matching\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.utils import parse_activation\n\n\nclass MatchPyramid(BaseModel):\n    """"""\n    MatchPyramid Model.\n\n    Examples:\n        >>> model = MatchPyramid()\n        >>> model.params[\'embedding_output_dim\'] = 300\n        >>> model.params[\'kernel_count\'] = [16, 32]\n        >>> model.params[\'kernel_size\'] = [[3, 3], [3, 3]]\n        >>> model.params[\'dpool_size\'] = [3, 10]\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(with_embedding=True)\n        params.add(Param(name=\'kernel_count\', value=[32],\n                         desc=""The kernel count of the 2D convolution ""\n                              ""of each block.""))\n        params.add(Param(name=\'kernel_size\', value=[[3, 3]],\n                         desc=""The kernel size of the 2D convolution ""\n                              ""of each block.""))\n        params.add(Param(name=\'activation\', value=\'relu\',\n                         desc=""The activation function.""))\n        params.add(Param(name=\'dpool_size\', value=[3, 10],\n                         desc=""The max-pooling size of each block.""))\n\n        params.add(Param(\n            \'dropout_rate\', 0.0,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""The dropout rate.""\n        ))\n        return params\n\n    def build(self):\n        """"""\n        Build model structure.\n\n        MatchPyramid text matching as image recognition.\n        """"""\n        self.embedding = self._make_default_embedding_layer()\n\n        # Interaction\n        self.matching = Matching(matching_type=\'dot\')\n\n        # Build conv\n        activation = parse_activation(self._params[\'activation\'])\n        in_channel_2d = [\n            1,\n            *self._params[\'kernel_count\'][:-1]\n        ]\n        conv2d = [\n            self._make_conv_pool_block(ic, oc, ks, activation)\n            for ic, oc, ks, in zip(in_channel_2d,\n                                   self._params[\'kernel_count\'],\n                                   self._params[\'kernel_size\'])\n        ]\n        self.conv2d = nn.Sequential(*conv2d)\n\n        # Dynamic Pooling\n        self.dpool_layer = nn.AdaptiveAvgPool2d(self._params[\'dpool_size\'])\n\n        self.dropout = nn.Dropout(p=self._params[\'dropout_rate\'])\n\n        left_length = self._params[\'dpool_size\'][0]\n        right_length = self._params[\'dpool_size\'][1]\n\n        # Build output\n        self.out = self._make_output_layer(\n            left_length * right_length * self._params[\'kernel_count\'][-1]\n        )\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   F = number of filters\n        #   P = pool size\n\n        # Left input and right input.\n        # shape = [B, L]\n        # shape = [B, R]\n        input_left, input_right = inputs[\'text_left\'], inputs[\'text_right\']\n\n        # Process left and right input.\n        # shape = [B, L, D]\n        # shape = [B, R, D]\n        embed_left = self.embedding(input_left.long())\n        embed_right = self.embedding(input_right.long())\n\n        # Compute matching signal\n        # shape = [B, 1, L, R]\n        embed_cross = self.matching(embed_left, embed_right).unsqueeze(dim=1)\n\n        # Convolution\n        # shape = [B, F, L, R]\n        conv = self.conv2d(embed_cross)\n\n        # Dynamic Pooling\n        # shape = [B, F, P1, P2]\n        embed_pool = self.dpool_layer(conv)\n\n        # shape = [B, F * P1 * P2]\n        embed_flat = self.dropout(torch.flatten(embed_pool, start_dim=1))\n\n        # shape = [B, *]\n        out = self.out(embed_flat)\n        return out\n\n    @classmethod\n    def _make_conv_pool_block(\n        cls,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: tuple,\n        activation: nn.Module\n    ) -> nn.Module:\n        """"""Make conv pool block.""""""\n        return nn.Sequential(\n            # Same padding\n            nn.ConstantPad2d(\n                (0, kernel_size[1] - 1, 0, kernel_size[0] - 1), 0\n            ),\n            nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=kernel_size\n            ),\n            activation\n        )\n'"
matchzoo/models/match_srnn.py,2,"b'""""""An implementation of Match-SRNN Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.modules import MatchingTensor\nfrom matchzoo.modules import SpatialGRU\n\n\nclass MatchSRNN(BaseModel):\n    """"""\n    Match-SRNN Model.\n\n    Examples:\n        >>> model = MatchSRNN()\n        >>> model.params[\'channels\'] = 4\n        >>> model.params[\'units\'] = 10\n        >>> model.params[\'dropout\'] = 0.2\n        >>> model.params[\'direction\'] = \'lt\'\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=False\n        )\n        params.add(Param(name=\'channels\', value=4,\n                         desc=""Number of word interaction tensor channels""))\n        params.add(Param(name=\'units\', value=10,\n                         desc=""Number of SpatialGRU units""))\n        params.add(Param(name=\'direction\', value=\'lt\',\n                         desc=""Direction of SpatialGRU scanning""))\n        params.add(Param(\n            \'dropout\', 0.2,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""The dropout rate.""\n        ))\n        return params\n\n    def build(self):\n        """"""Build model structure.""""""\n\n        self.embedding = self._make_default_embedding_layer()\n        self.dropout = nn.Dropout(p=self._params[\'dropout\'])\n\n        self.matching_tensor = MatchingTensor(\n            self._params[\'embedding_output_dim\'],\n            channels=self._params[""channels""])\n\n        self.spatial_gru = SpatialGRU(\n            units=self._params[\'units\'],\n            direction=self._params[\'direction\'])\n\n        self.out = self._make_output_layer(self._params[\'units\'])\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   C = number of channels\n\n        # Left input and right input\n        # query = [B, L]\n        # doc = [B, R]\n        query, doc = inputs[""text_left""].long(), inputs[""text_right""].long()\n\n        # Process left and right input\n        # query = [B, L, D]\n        # doc = [B, R, D]\n        query = self.embedding(query)\n        doc = self.embedding(doc)\n\n        # query = [B, L, D]\n        # doc = [B, R, D]\n        query = self.dropout(query)\n        doc = self.dropout(doc)\n\n        # Get matching tensor\n        # matching_tensor = [B, C, L, R]\n        matching_tensor = self.matching_tensor(query, doc)\n\n        # Apply spatial GRU to the word level interaction tensor\n        # h_ij = [B, U]\n        h_ij = self.spatial_gru(matching_tensor)\n\n        # h_ij = [B, U]\n        h_ij = self.dropout(h_ij)\n\n        # Make output layer\n        out = self.out(h_ij)\n\n        return out\n'"
matchzoo/models/matchlstm.py,2,"b'""""""An implementation of Match LSTM Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.modules import MatchModule\nfrom matchzoo.modules import StackedBRNN\n\n\nclass MatchLSTM(BaseModel):\n    """"""\n    MatchLSTM Model.\n\n    https://github.com/shuohangwang/mprc/blob/master/qa/rankerReader.lua.\n\n    Examples:\n        >>> model = MatchLSTM()\n        >>> model.params[\'dropout\'] = 0.2\n        >>> model.params[\'hidden_size\'] = 200\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=False\n        )\n        params.add(Param(name=\'mask_value\', value=0,\n                         desc=""The value to be masked from inputs.""))\n        params.add(Param(name=\'dropout\', value=0.2,\n                         desc=""Dropout rate.""))\n        params.add(Param(name=\'hidden_size\', value=200,\n                         desc=""Hidden size.""))\n        params.add(Param(name=\'lstm_layer\', value=1,\n                         desc=""Number of LSTM layers""))\n        params.add(Param(name=\'drop_lstm\', value=False,\n                         desc=""Whether dropout LSTM.""))\n        params.add(Param(name=\'concat_lstm\', value=True,\n                         desc=""Whether concat intermediate outputs.""))\n        params.add(Param(name=\'rnn_type\', value=\'lstm\',\n                         desc=""Choose rnn type, lstm or gru.""))\n        return params\n\n    def build(self):\n        """"""Instantiating layers.""""""\n        rnn_mapping = {\'lstm\': nn.LSTM, \'gru\': nn.GRU}\n        self.embedding = self._make_default_embedding_layer()\n        self.dropout = nn.Dropout(p=self._params[\'dropout\'])\n        if self._params[\'concat_lstm\']:\n            lstm_layer = self._params[\'lstm_layer\']\n            lstm_size = self._params[\'hidden_size\'] / lstm_layer\n        self.input_proj = StackedBRNN(\n            self._params[\'embedding_output_dim\'],\n            int(lstm_size / 2),\n            self._params[\'lstm_layer\'],\n            dropout_rate=self._params[\'dropout\'],\n            dropout_output=self._params[\'drop_lstm\'],\n            rnn_type=rnn_mapping[self._params[\'rnn_type\'].lower()],\n            concat_layers=self._params[\'concat_lstm\'])\n        self.match_module = MatchModule(\n            self._params[\'hidden_size\'], dropout_rate=self._params[\'dropout\'])\n        self.mlstm_module = StackedBRNN(\n            2 * self._params[\'hidden_size\'],\n            int(lstm_size / 2),\n            self._params[\'lstm_layer\'],\n            dropout_rate=self._params[\'dropout\'],\n            dropout_output=self._params[\'drop_lstm\'],\n            rnn_type=rnn_mapping[self._params[\'rnn_type\'].lower()],\n            concat_layers=self._params[\'concat_lstm\'])\n        self.classification = nn.Sequential(\n            nn.Dropout(\n                p=self._params[\'dropout\']),\n            nn.Linear(\n                self._params[\'hidden_size\'],\n                self._params[\'hidden_size\']),\n            nn.Tanh())\n        self.out = self._make_output_layer(self._params[\'hidden_size\'])\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n        # Scalar dimensions referenced here:\n        # B = batch size (number of sequences)\n        # D = embedding size\n        # L = `input_left` sequence length\n        # R = `input_right` sequence length\n        # H = hidden size\n\n        # [B, L], [B, R]\n        query, doc = inputs[\'text_left\'].long(), inputs[\'text_right\'].long()\n\n        # [B, L]\n        # [B, R]\n        query_mask = (query == self._params[\'mask_value\'])\n        doc_mask = (doc == self._params[\'mask_value\'])\n\n        # [B, L, D]\n        # [B, R, D]\n        query = self.embedding(query)\n        doc = self.embedding(doc)\n\n        # [B, L, D]\n        # [B, R, D]\n        query = self.dropout(query)\n        doc = self.dropout(doc)\n\n        # [B, L, H]\n        # [B, R, H]\n        query = self.input_proj(query, query_mask)\n        doc = self.input_proj(doc, doc_mask)\n\n        # [B, L, H]\n        match_out = self.match_module(\n            query, doc, doc_mask)\n\n        # [B, L, H]\n        mlstm_out = self.mlstm_module(match_out, query_mask)\n\n        # [B, H]\n        max_pool_rep, _ = mlstm_out.max(dim=1)\n\n        # [B, H]\n        hidden = self.classification(max_pool_rep)\n\n        # [B, num_classes]\n        out = self.out(hidden)\n\n        return out\n'"
matchzoo/models/mvlstm.py,5,"b'""""""An implementation of MVLSTM Model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.engine import hyper_spaces\nfrom matchzoo.dataloader import callbacks\n\n\nclass MVLSTM(BaseModel):\n    """"""\n    MVLSTM Model.\n\n    Examples:\n        >>> model = MVLSTM()\n        >>> model.params[\'hidden_size\'] = 32\n        >>> model.params[\'top_k\'] = 50\n        >>> model.params[\'mlp_num_layers\'] = 2\n        >>> model.params[\'mlp_num_units\'] = 20\n        >>> model.params[\'mlp_num_fan_out\'] = 10\n        >>> model.params[\'mlp_activation_func\'] = \'relu\'\n        >>> model.params[\'dropout_rate\'] = 0.0\n        >>> model.guess_and_fill_missing_params(verbose=0)\n        >>> model.build()\n\n    """"""\n\n    @classmethod\n    def get_default_params(cls) -> ParamTable:\n        """""":return: model default parameters.""""""\n        params = super().get_default_params(\n            with_embedding=True,\n            with_multi_layer_perceptron=True\n        )\n        params.add(Param(name=\'hidden_size\', value=32,\n                         desc=""Integer, the hidden size in the ""\n                              ""bi-directional LSTM layer.""))\n        params.add(Param(name=\'num_layers\', value=1,\n                         desc=""Integer, number of recurrent layers.""))\n        params.add(Param(\n            \'top_k\', value=10,\n            hyper_space=hyper_spaces.quniform(low=2, high=100),\n            desc=""Size of top-k pooling layer.""\n        ))\n        params.add(Param(\n            \'dropout_rate\', 0.0,\n            hyper_space=hyper_spaces.quniform(\n                low=0.0, high=0.8, q=0.01),\n            desc=""Float, the dropout rate.""\n        ))\n        return params\n\n    @classmethod\n    def get_default_padding_callback(\n        cls,\n        fixed_length_left: int = 10,\n        fixed_length_right: int = 40,\n        pad_word_value: typing.Union[int, str] = 0,\n        pad_word_mode: str = \'pre\',\n        with_ngram: bool = False,\n        fixed_ngram_length: int = None,\n        pad_ngram_value: typing.Union[int, str] = 0,\n        pad_ngram_mode: str = \'pre\'\n    ) -> BaseCallback:\n        """"""\n        Model default padding callback.\n\n        The padding callback\'s on_batch_unpacked would pad a batch of data to\n        a fixed length.\n\n        :return: Default padding callback.\n        """"""\n        return callbacks.BasicPadding(\n            fixed_length_left=fixed_length_left,\n            fixed_length_right=fixed_length_right,\n            pad_word_value=pad_word_value,\n            pad_word_mode=pad_word_mode,\n            with_ngram=with_ngram,\n            fixed_ngram_length=fixed_ngram_length,\n            pad_ngram_value=pad_ngram_value,\n            pad_ngram_mode=pad_ngram_mode\n        )\n\n    def build(self):\n        """"""Build model structure.""""""\n        self.embedding = self._make_default_embedding_layer()\n\n        self.left_bilstm = nn.LSTM(\n            input_size=self._params[\'embedding_output_dim\'],\n            hidden_size=self._params[\'hidden_size\'],\n            num_layers=self._params[\'num_layers\'],\n            batch_first=True,\n            dropout=self._params[\'dropout_rate\'],\n            bidirectional=True\n        )\n        self.right_bilstm = nn.LSTM(\n            input_size=self._params[\'embedding_output_dim\'],\n            hidden_size=self._params[\'hidden_size\'],\n            num_layers=self._params[\'num_layers\'],\n            batch_first=True,\n            dropout=self._params[\'dropout_rate\'],\n            bidirectional=True\n        )\n\n        self.mlp = self._make_multi_layer_perceptron_layer(\n            self._params[\'top_k\']\n        )\n        self.dropout = nn.Dropout(p=self._params[\'dropout_rate\'])\n        self.out = self._make_output_layer(\n            self._params[\'mlp_num_fan_out\']\n        )\n\n    def forward(self, inputs):\n        """"""Forward.""""""\n\n        # Scalar dimensions referenced here:\n        #   B = batch size (number of sequences)\n        #   D = embedding size\n        #   L = `input_left` sequence length\n        #   R = `input_right` sequence length\n        #   H = LSTM hidden size\n        #   K = size of top-k\n\n        # Left input and right input.\n        # shape = [B, L]\n        # shape = [B, R]\n        query, doc = inputs[\'text_left\'], inputs[\'text_right\']\n\n        # Process left and right input.\n        # shape = [B, L, D]\n        # shape = [B, R, D]\n        embed_query = self.embedding(query.long())\n        embed_doc = self.embedding(doc.long())\n\n        # Bi-directional LSTM\n        # shape = [B, L, 2 * H]\n        # shape = [B, R, 2 * H]\n        rep_query, _ = self.left_bilstm(embed_query)\n        rep_doc, _ = self.right_bilstm(embed_doc)\n\n        # Top-k matching\n        # shape = [B, L, R]\n        matching_matrix = torch.einsum(\n            \'bld,brd->blr\',\n            F.normalize(rep_query, p=2, dim=-1),\n            F.normalize(rep_doc, p=2, dim=-1)\n        )\n        # shape = [B, L * R]\n        matching_signals = torch.flatten(matching_matrix, start_dim=1)\n        # shape = [B, K]\n        matching_topk = torch.topk(\n            matching_signals,\n            k=self._params[\'top_k\'],\n            dim=-1,\n            sorted=True\n        )[0]\n\n        # shape = [B, *]\n        dense_output = self.mlp(matching_topk)\n\n        # shape = [B, *]\n        out = self.out(self.dropout(dense_output))\n        return out\n'"
matchzoo/models/parameter_readme_generator.py,0,"b'""""""matchzoo/models/README.md generater.""""""\n\nfrom pathlib import Path\n\nimport tabulate\nimport inspect\nimport pandas as pd\n\nimport matchzoo\n\n\ndef _generate():\n    full = _make_title()\n    for model_class in matchzoo.models.list_available():\n        full += _make_model_class_subtitle(model_class)\n        full += _make_doc_section_subsubtitle()\n        full += _make_model_doc(model_class)\n        model = model_class()\n        full += _make_params_section_subsubtitle()\n        full += _make_model_params_table(model)\n    _write_to_files(full)\n\n\ndef _make_title():\n    title = \'MatchZoo Model Reference\'\n    line = \'*\' * len(title)\n    return line + \'\\n\' + title + \'\\n\' + line + \'\\n\\n\'\n\n\ndef _make_model_class_subtitle(model_class):\n    subtitle = model_class.__name__\n    line = \'#\' * len(subtitle)\n    return subtitle + \'\\n\' + line + \'\\n\\n\'\n\n\ndef _make_doc_section_subsubtitle():\n    subsubtitle = \'Model Documentation\'\n    line = \'*\' * len(subsubtitle)\n    return subsubtitle + \'\\n\' + line + \'\\n\\n\'\n\n\ndef _make_params_section_subsubtitle():\n    subsubtitle = \'Model Hyper Parameters\'\n    line = \'*\' * len(subsubtitle)\n    return subsubtitle + \'\\n\' + line + \'\\n\\n\'\n\n\ndef _make_model_doc(model_class):\n    return inspect.getdoc(model_class) + \'\\n\\n\'\n\n\ndef _make_model_params_table(model):\n    params = model.get_default_params()\n    df = params.to_frame()\n    df = df.rename({\n        \'Value\': \'Default Value\',\n        \'Hyper-Space\': \'Default Hyper-Space\'\n    }, axis=\'columns\')\n    return tabulate.tabulate(df, tablefmt=\'rst\', headers=\'keys\') + \'\\n\\n\'\n\n\ndef _write_to_files(full):\n    readme_file_path = Path(__file__).parent.joinpath(\'README.rst\')\n    doc_file_path = Path(__file__).parent.parent.parent. \\\n        joinpath(\'docs\').joinpath(\'source\').joinpath(\'model_reference.rst\')\n    for file_path in readme_file_path, doc_file_path:\n        with open(file_path, \'w\', encoding=\'utf-8\') as out_file:\n            out_file.write(full)\n\n\nif __name__ == \'__main__\':\n    _generate()\n'"
matchzoo/modules/__init__.py,0,b'from .attention import Attention\nfrom .attention import BidirectionalAttention\nfrom .attention import MatchModule\nfrom .dropout import RNNDropout\nfrom .stacked_brnn import StackedBRNN\nfrom .gaussian_kernel import GaussianKernel\nfrom .matching import Matching\nfrom .bert_module import BertModule\nfrom .character_embedding import CharacterEmbedding\nfrom .semantic_composite import SemanticComposite\nfrom .dense_net import DenseNet\nfrom .matching_tensor import MatchingTensor\nfrom .spatial_gru import SpatialGRU'
matchzoo/modules/attention.py,12,"b'""""""Attention module.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Attention(nn.Module):\n    """"""\n    Attention module.\n\n    :param input_size: Size of input.\n    :param mask: An integer to mask the invalid values. Defaults to 0.\n\n    Examples:\n        >>> import torch\n        >>> attention = Attention(input_size=10)\n        >>> x = torch.randn(4, 5, 10)\n        >>> x.shape\n        torch.Size([4, 5, 10])\n        >>> x_mask = torch.BoolTensor(4, 5)\n        >>> attention(x, x_mask).shape\n        torch.Size([4, 5])\n\n    """"""\n\n    def __init__(self, input_size: int = 100):\n        """"""Attention constructor.""""""\n        super().__init__()\n        self.linear = nn.Linear(input_size, 1, bias=False)\n\n    def forward(self, x, x_mask):\n        """"""Perform attention on the input.""""""\n        x = self.linear(x).squeeze(dim=-1)\n        x = x.masked_fill(x_mask, -float(\'inf\'))\n        return F.softmax(x, dim=-1)\n\n\nclass BidirectionalAttention(nn.Module):\n    """"""Computing the soft attention between two sequence.""""""\n\n    def __init__(self):\n        """"""Init.""""""\n        super().__init__()\n\n    def forward(self, v1, v1_mask, v2, v2_mask):\n        """"""Forward.""""""\n        similarity_matrix = v1.bmm(v2.transpose(2, 1).contiguous())\n\n        v2_v1_attn = F.softmax(\n            similarity_matrix.masked_fill(\n                v1_mask.unsqueeze(2), -1e-7), dim=1)\n        v1_v2_attn = F.softmax(\n            similarity_matrix.masked_fill(\n                v2_mask.unsqueeze(1), -1e-7), dim=2)\n\n        attended_v1 = v1_v2_attn.bmm(v2)\n        attended_v2 = v2_v1_attn.transpose(1, 2).bmm(v1)\n\n        attended_v1.masked_fill_(v1_mask.unsqueeze(2), 0)\n        attended_v2.masked_fill_(v2_mask.unsqueeze(2), 0)\n\n        return attended_v1, attended_v2\n\n\nclass MatchModule(nn.Module):\n    """"""\n    Computing the match representation for Match LSTM.\n\n    :param hidden_size: Size of hidden vectors.\n    :param dropout_rate: Dropout rate of the projection layer. Defaults to 0.\n\n    Examples:\n        >>> import torch\n        >>> attention = MatchModule(hidden_size=10)\n        >>> v1 = torch.randn(4, 5, 10)\n        >>> v1.shape\n        torch.Size([4, 5, 10])\n        >>> v2 = torch.randn(4, 5, 10)\n        >>> v2_mask = torch.ones(4, 5).to(dtype=torch.uint8)\n        >>> attention(v1, v2, v2_mask).shape\n        torch.Size([4, 5, 20])\n\n\n    """"""\n\n    def __init__(self, hidden_size, dropout_rate=0):\n        """"""Init.""""""\n        super().__init__()\n        self.v2_proj = nn.Linear(hidden_size, hidden_size)\n        self.proj = nn.Linear(hidden_size * 4, hidden_size * 2)\n        self.dropout = nn.Dropout(p=dropout_rate)\n\n    def forward(self, v1, v2, v2_mask):\n        """"""Computing attention vectors and projection vectors.""""""\n        proj_v2 = self.v2_proj(v2)\n        similarity_matrix = v1.bmm(proj_v2.transpose(2, 1).contiguous())\n\n        v1_v2_attn = F.softmax(\n            similarity_matrix.masked_fill(\n                v2_mask.unsqueeze(1).bool(), -1e-7), dim=2)\n        v2_wsum = v1_v2_attn.bmm(v2)\n        fusion = torch.cat([v1, v2_wsum, v1 - v2_wsum, v1 * v2_wsum], dim=2)\n        match = self.dropout(F.relu(self.proj(fusion)))\n        return match\n'"
matchzoo/modules/bert_module.py,5,"b'""""""Bert module.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nfrom pytorch_transformers import BertModel\n\n\nclass BertModule(nn.Module):\n    """"""\n    Bert module.\n\n    BERT (from Google) released with the paper BERT: Pre-training of Deep\n    Bidirectional Transformers for Language Understanding by Jacob Devlin,\n    Ming-Wei Chang, Kenton Lee and Kristina Toutanova.\n\n    :param mode: String, supported mode can be referred\n        https://huggingface.co/pytorch-transformers/pretrained_models.html.\n\n    """"""\n\n    def __init__(self, mode: str = \'bert-base-uncased\'):\n        """""":class:`BertModule` constructor.""""""\n        super().__init__()\n        self.bert = BertModel.from_pretrained(mode)\n\n    def forward(self, x, y):\n        """"""Forward.""""""\n        input_ids = torch.cat((x, y), dim=-1)\n        token_type_ids = torch.cat((\n            torch.zeros_like(x),\n            torch.ones_like(y)), dim=-1).long()\n        attention_mask = (input_ids != 0)\n        return self.bert(input_ids=input_ids, token_type_ids=token_type_ids,\n                         attention_mask=attention_mask)\n'"
matchzoo/modules/character_embedding.py,5,"b'""""""Character embedding module.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\n\nclass CharacterEmbedding(nn.Module):\n    """"""\n    Character embedding module.\n\n    :param char_embedding_input_dim: The input dimension of character embedding layer.\n    :param char_embedding_output_dim: The output dimension of character embedding layer.\n    :param char_conv_filters: The filter size of character convolution layer.\n    :param char_conv_kernel_size: The kernel size of character convolution layer.\n\n    Examples:\n        >>> import torch\n        >>> character_embedding = CharacterEmbedding()\n        >>> x = torch.ones(10, 32, 16, dtype=torch.long)\n        >>> x.shape\n        torch.Size([10, 32, 16])\n        >>> character_embedding(x).shape\n        torch.Size([10, 32, 100])\n\n    """"""\n\n    def __init__(\n        self,\n        char_embedding_input_dim: int = 100,\n        char_embedding_output_dim: int = 8,\n        char_conv_filters: int = 100,\n        char_conv_kernel_size: int = 5\n    ):\n        """"""Init.""""""\n        super().__init__()\n        self.char_embedding = nn.Embedding(\n            num_embeddings=char_embedding_input_dim,\n            embedding_dim=char_embedding_output_dim\n        )\n        self.conv = nn.Conv1d(\n            in_channels=char_embedding_output_dim,\n            out_channels=char_conv_filters,\n            kernel_size=char_conv_kernel_size\n        )\n\n    def forward(self, x):\n        """"""Forward.""""""\n        embed_x = self.char_embedding(x)\n\n        batch_size, seq_len, word_len, embed_dim = embed_x.shape\n\n        embed_x = embed_x.contiguous().view(-1, word_len, embed_dim)\n\n        embed_x = self.conv(embed_x.transpose(1, 2))\n        embed_x = torch.max(embed_x, dim=-1)[0]\n\n        embed_x = embed_x.view(batch_size, seq_len, -1)\n        return embed_x\n'"
matchzoo/modules/dense_net.py,2,"b'""""""DenseNet module.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\n\nclass DenseBlock(nn.Module):\n    """"""Dense block of DenseNet.""""""\n\n    def __init__(\n        self,\n        in_channels,\n        growth_rate: int = 20,\n        kernel_size: tuple = (2, 2),\n        layers_per_dense_block: int = 3\n    ):\n        """"""Init.""""""\n        super().__init__()\n        dense_block = []\n        for _ in range(layers_per_dense_block):\n            conv_block = self._make_conv_block(in_channels, growth_rate, kernel_size)\n            dense_block.append(conv_block)\n            in_channels += growth_rate\n        self._dense_block = nn.ModuleList(dense_block)\n\n    def forward(self, x):\n        """"""Forward.""""""\n        for layer in self._dense_block:\n            conv_out = layer(x)\n            x = torch.cat([x, conv_out], dim=1)\n        return x\n\n    @classmethod\n    def _make_conv_block(\n        cls,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: tuple\n    ) -> nn.Module:\n        """"""Make conv block.""""""\n        return nn.Sequential(\n            nn.ConstantPad2d(\n                (0, kernel_size[1] - 1, 0, kernel_size[0] - 1), 0\n            ),\n            nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=kernel_size\n            ),\n            nn.ReLU()\n        )\n\n\nclass DenseNet(nn.Module):\n    """"""\n    DenseNet module.\n\n    :param in_channels: Feature size of input.\n    :param nb_dense_blocks: The number of blocks in densenet.\n    :param layers_per_dense_block: The number of convolution layers in dense block.\n    :param growth_rate: The filter size of each convolution layer in dense block.\n    :param transition_scale_down_ratio: The channel scale down ratio of the convolution\n        layer in transition block.\n    :param conv_kernel_size: The kernel size of convolution layer in dense block.\n    :param pool_kernel_size: The kernel size of pooling layer in transition block.\n    """"""\n\n    def __init__(\n        self,\n        in_channels,\n        nb_dense_blocks: int = 3,\n        layers_per_dense_block: int = 3,\n        growth_rate: int = 10,\n        transition_scale_down_ratio: float = 0.5,\n        conv_kernel_size: tuple = (2, 2),\n        pool_kernel_size: tuple = (2, 2),\n    ):\n        """"""Init.""""""\n        super().__init__()\n        dense_blocks = []\n        transition_blocks = []\n        for _ in range(nb_dense_blocks):\n            dense_block = DenseBlock(\n                in_channels, growth_rate, conv_kernel_size, layers_per_dense_block)\n            in_channels += layers_per_dense_block * growth_rate\n            dense_blocks.append(dense_block)\n\n            transition_block = self._make_transition_block(\n                in_channels, transition_scale_down_ratio, pool_kernel_size)\n            in_channels = int(in_channels * transition_scale_down_ratio)\n            transition_blocks.append(transition_block)\n\n        self._dense_blocks = nn.ModuleList(dense_blocks)\n        self._transition_blocks = nn.ModuleList(transition_blocks)\n\n        self._out_channels = in_channels\n\n    @property\n    def out_channels(self) -> int:\n        """"""`out_channels` getter.""""""\n        return self._out_channels\n\n    def forward(self, x):\n        """"""Forward.""""""\n        for dense_block, trans_block in zip(self._dense_blocks, self._transition_blocks):\n            x = dense_block(x)\n            x = trans_block(x)\n        return x\n\n    @classmethod\n    def _make_transition_block(\n        cls,\n        in_channels: int,\n        transition_scale_down_ratio: float,\n        pool_kernel_size: tuple\n    ) -> nn.Module:\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=int(in_channels * transition_scale_down_ratio),\n                kernel_size=1\n            ),\n            nn.MaxPool2d(kernel_size=pool_kernel_size, stride=pool_kernel_size)\n        )\n'"
matchzoo/modules/dropout.py,1,"b'import torch.nn as nn\n\n\nclass RNNDropout(nn.Dropout):\n    """"""Dropout for RNN.""""""\n\n    def forward(self, sequences_batch):\n        """"""Masking whole hidden vector for tokens.""""""\n        # B: batch size\n        # L: sequence length\n        # D: hidden size\n\n        # sequence_batch: BxLxD\n        ones = sequences_batch.data.new_ones(sequences_batch.shape[0],\n                                             sequences_batch.shape[-1])\n        dropout_mask = nn.functional.dropout(ones, self.p, self.training,\n                                             inplace=False)\n        return dropout_mask.unsqueeze(1) * sequences_batch\n'"
matchzoo/modules/gaussian_kernel.py,5,"b'""""""Gaussian kernel module.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\n\nclass GaussianKernel(nn.Module):\n    """"""\n    Gaussian kernel module.\n\n    :param mu: Float, mean of the kernel.\n    :param sigma: Float, sigma of the kernel.\n\n    Examples:\n        >>> import torch\n        >>> kernel = GaussianKernel()\n        >>> x = torch.randn(4, 5, 10)\n        >>> x.shape\n        torch.Size([4, 5, 10])\n        >>> kernel(x).shape\n        torch.Size([4, 5, 10])\n\n    """"""\n\n    def __init__(self, mu: float = 1., sigma: float = 1.):\n        """"""Gaussian kernel constructor.""""""\n        super().__init__()\n        self.mu = mu\n        self.sigma = sigma\n\n    def forward(self, x):\n        """"""Forward.""""""\n        return torch.exp(\n            -0.5 * ((x - self.mu) ** 2) / (self.sigma ** 2)\n        )\n'"
matchzoo/modules/matching.py,9,"b'""""""Matching module.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Matching(nn.Module):\n    """"""\n    Module that computes a matching matrix between samples in two tensors.\n\n    :param normalize: Whether to L2-normalize samples along the\n        dot product axis before taking the dot product.\n        If set to `True`, then the output of the dot product\n        is the cosine proximity between the two samples.\n    :param matching_type: the similarity function for matching\n\n    Examples:\n        >>> import torch\n        >>> matching = Matching(matching_type=\'dot\', normalize=True)\n        >>> x = torch.randn(2, 3, 2)\n        >>> y = torch.randn(2, 4, 2)\n        >>> matching(x, y).shape\n        torch.Size([2, 3, 4])\n\n    """"""\n\n    def __init__(self, normalize: bool = False, matching_type: str = \'dot\'):\n        """""":class:`Matching` constructor.""""""\n        super().__init__()\n        self._normalize = normalize\n        self._validate_matching_type(matching_type)\n        self._matching_type = matching_type\n\n    @classmethod\n    def _validate_matching_type(cls, matching_type: str = \'dot\'):\n        valid_matching_type = [\'dot\', \'exact\', \'mul\', \'plus\', \'minus\', \'concat\']\n        if matching_type not in valid_matching_type:\n            raise ValueError(f""{matching_type} is not a valid matching type, ""\n                             f""{valid_matching_type} expected."")\n\n    def forward(self, x, y):\n        """"""Perform attention on the input.""""""\n        length_left = x.shape[1]\n        length_right = y.shape[1]\n        if self._matching_type == \'dot\':\n            if self._normalize:\n                x = F.normalize(x, p=2, dim=-1)\n                y = F.normalize(y, p=2, dim=-1)\n            return torch.einsum(\'bld,brd->blr\', x, y)\n        elif self._matching_type == \'exact\':\n            x = x.unsqueeze(dim=2).repeat(1, 1, length_right)\n            y = y.unsqueeze(dim=1).repeat(1, length_left, 1)\n            matching_matrix = (x == y)\n            x = torch.sum(matching_matrix, dim=2, dtype=torch.float)\n            y = torch.sum(matching_matrix, dim=1, dtype=torch.float)\n            return x, y\n        else:\n            x = x.unsqueeze(dim=2).repeat(1, 1, length_right, 1)\n            y = y.unsqueeze(dim=1).repeat(1, length_left, 1, 1)\n            if self._matching_type == \'mul\':\n                return x * y\n            elif self._matching_type == \'plus\':\n                return x + y\n            elif self._matching_type == \'minus\':\n                return x - y\n            elif self._matching_type == \'concat\':\n                return torch.cat((x, y), dim=3)\n'"
matchzoo/modules/matching_tensor.py,4,"b'""""""Matching Tensor module.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass MatchingTensor(nn.Module):\n    """"""\n    Module that captures the basic interactions between two tensors.\n\n    :param matching_dims: Word dimension of two interaction texts.\n    :param channels: Number of word interaction tensor channels.\n    :param normalize: Whether to L2-normalize samples along the\n        dot product axis before taking the dot product.\n        If set to True, then the output of the dot product\n        is the cosine proximity between the two samples.\n    :param init_diag: Whether to initialize the diagonal elements\n        of the matrix.\n\n    Examples:\n        >>> import matchzoo as mz\n        >>> matching_dim = 5\n        >>> matching_tensor = mz.modules.MatchingTensor(\n        ...    matching_dim,\n        ...    channels=4,\n        ...    normalize=True,\n        ...    init_diag=True\n        ... )\n\n    """"""\n\n    def __init__(\n        self,\n        matching_dim: int,\n        channels: int = 4,\n        normalize: bool = True,\n        init_diag: bool = True\n    ):\n        """""":class:`MatchingTensor` constructor.""""""\n        super().__init__()\n        self._matching_dim = matching_dim\n        self._channels = channels\n        self._normalize = normalize\n        self._init_diag = init_diag\n\n        self.interaction_matrix = torch.empty(\n            self._channels, self._matching_dim, self._matching_dim\n        )\n        if self._init_diag:\n            self.interaction_matrix = self.interaction_matrix.uniform_(-0.05, 0.05)\n            for channel_index in range(self._channels):\n                self.interaction_matrix[channel_index].fill_diagonal_(0.1)\n            self.interaction_matrix = nn.Parameter(self.interaction_matrix)\n        else:\n            self.interaction_matrix = nn.Parameter(self.interaction_matrix.uniform_())\n\n    def forward(self, x, y):\n        """"""\n        The computation logic of MatchingTensor.\n\n        :param inputs: two input tensors.\n        """"""\n\n        if self._normalize:\n            x = F.normalize(x, p=2, dim=-1)\n            y = F.normalize(y, p=2, dim=-1)\n\n        # output = [b, c, l, r]\n        output = torch.einsum(\n            \'bld,cde,bre->bclr\',\n            x, self.interaction_matrix, y\n        )\n        return output\n'"
matchzoo/modules/semantic_composite.py,12,"b'""""""Semantic composite module for DIIN model.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\n\n\nclass SemanticComposite(nn.Module):\n    """"""\n    SemanticComposite module.\n\n    Apply a self-attention layer and a semantic composite fuse gate to compute the\n    encoding result of one tensor.\n\n    :param in_features: Feature size of input.\n    :param dropout_rate: The dropout rate.\n\n    Examples:\n        >>> import torch\n        >>> module = SemanticComposite(in_features=10)\n        >>> x = torch.randn(4, 5, 10)\n        >>> x.shape\n        torch.Size([4, 5, 10])\n        >>> module(x).shape\n        torch.Size([4, 5, 10])\n\n    """"""\n\n    def __init__(self, in_features, dropout_rate: float = 0.0):\n        """"""Init.""""""\n        super().__init__()\n        self.att_linear = nn.Linear(3 * in_features, 1, False)\n        self.z_gate = nn.Linear(2 * in_features, in_features, True)\n        self.r_gate = nn.Linear(2 * in_features, in_features, True)\n        self.f_gate = nn.Linear(2 * in_features, in_features, True)\n\n        self.dropout = nn.Dropout(p=dropout_rate)\n\n    def forward(self, x):\n        """"""Forward.""""""\n        seq_length = x.shape[1]\n\n        x_1 = x.unsqueeze(dim=2).repeat(1, 1, seq_length, 1)\n        x_2 = x.unsqueeze(dim=1).repeat(1, seq_length, 1, 1)\n        x_concat = torch.cat([x_1, x_2, x_1 * x_2], dim=-1)\n\n        # Self-attention layer.\n        x_concat = self.dropout(x_concat)\n        attn_matrix = self.att_linear(x_concat).squeeze(dim=-1)\n        attn_weight = torch.softmax(attn_matrix, dim=2)\n        attn = torch.bmm(attn_weight, x)\n\n        # Semantic composite fuse gate.\n        x_attn_concat = self.dropout(torch.cat([x, attn], dim=-1))\n        x_attn_concat = torch.cat([x, attn], dim=-1)\n        z = torch.tanh(self.z_gate(x_attn_concat))\n        r = torch.sigmoid(self.r_gate(x_attn_concat))\n        f = torch.sigmoid(self.f_gate(x_attn_concat))\n        encoding = r * x + f * z\n\n        return encoding\n'"
matchzoo/modules/spatial_gru.py,8,"b'""""""Spatial GRU module.""""""\nimport typing\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom matchzoo.utils import parse_activation\n\n\nclass SpatialGRU(nn.Module):\n    """"""\n    Spatial GRU Module.\n\n    :param channels: Number of word interaction tensor channels.\n    :param units: Number of SpatialGRU units.\n    :param activation: Activation function to use, one of:\n            - String: name of an activation\n            - Torch Modele subclass\n            - Torch Module instance\n            Default: hyperbolic tangent (`tanh`).\n    :param recurrent_activation: Activation function to use for\n        the recurrent step, one of:\n            - String: name of an activation\n            - Torch Modele subclass\n            - Torch Module instance\n            Default: sigmoid activation (`sigmoid`).\n    :param direction: Scanning direction. `lt` (i.e., left top)\n        indicates the scanning from left top to right bottom, and\n        `rb` (i.e., right bottom) indicates the scanning from\n        right bottom to left top.\n\n    Examples:\n        >>> import matchzoo as mz\n        >>> channels, units= 4, 10\n        >>> spatial_gru = mz.modules.SpatialGRU(channels, units)\n\n    """"""\n\n    def __init__(\n        self,\n        channels: int = 4,\n        units: int = 10,\n        activation: typing.Union[str, typing.Type[nn.Module], nn.Module] = \'tanh\',\n        recurrent_activation: typing.Union[\n            str, typing.Type[nn.Module], nn.Module] = \'sigmoid\',\n        direction: str = \'lt\'\n    ):\n        """""":class:`SpatialGRU` constructor.""""""\n        super().__init__()\n        self._units = units\n        self._activation = parse_activation(activation)\n        self._recurrent_activation = parse_activation(recurrent_activation)\n        self._direction = direction\n        self._channels = channels\n\n        if self._direction not in (\'lt\', \'rb\'):\n            raise ValueError(f""Invalid direction. ""\n                             f""`{self._direction}` received. ""\n                             f""Must be in `lt`, `rb`."")\n\n        self._input_dim = self._channels + 3 * self._units\n\n        self._wr = nn.Linear(self._input_dim, self._units * 3)\n        self._wz = nn.Linear(self._input_dim, self._units * 4)\n        self._w_ij = nn.Linear(self._channels, self._units)\n        self._U = nn.Linear(self._units * 3, self._units, bias=False)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        """"""Initialize parameters.""""""\n        nn.init.xavier_normal_(self._wr.weight)\n        nn.init.xavier_normal_(self._wz.weight)\n        nn.init.orthogonal_(self._w_ij.weight)\n        nn.init.orthogonal_(self._U.weight)\n\n    def softmax_by_row(self, z: torch.tensor) -> tuple:\n        """"""Conduct softmax on each dimension across the four gates.""""""\n\n        # z_transform: [B, 4, U]\n        z_transform = z.reshape((-1, 4, self._units))\n        # zi, zl, zt, zd: [B, U]\n        zi, zl, zt, zd = F.softmax(z_transform, dim=1).unbind(dim=1)\n        return zi, zl, zt, zd\n\n    def calculate_recurrent_unit(\n        self,\n        inputs: torch.tensor,\n        states: list,\n        i: int,\n        j: int\n    ):\n        """"""\n        Calculate recurrent unit.\n\n        :param inputs: A tensor which contains interaction\n            between left text and right text.\n        :param states: An array of tensors which stores the hidden state\n            of every step.\n        :param i: Recurrent row index.\n        :param j: Recurrent column index.\n\n        """"""\n\n        # Get hidden state h_diag, h_top, h_left\n        # h = [B, U]\n        h_diag = states[i][j]\n        h_top = states[i][j + 1]\n        h_left = states[i + 1][j]\n\n        # Get interaction between word i, j: s_ij\n        # s = [B, C]\n        s_ij = inputs[i][j]\n\n        # Concatenate h_top, h_left, h_diag, s_ij\n        # q = [B, 3*U+C]\n        q = torch.cat([torch.cat([h_top, h_left], 1), torch.cat([h_diag, s_ij], 1)], 1)\n\n        # Calculate reset gate\n        # r = [B, 3*U]\n        r = self._recurrent_activation(self._wr(q))\n\n        # Calculate updating gate\n        # z: [B, 4*U]\n        z = self._wz(q)\n\n        # Perform softmax\n        # zi, zl, zt, zd: [B, U]\n        zi, zl, zt, zd = self.softmax_by_row(z)\n\n        # Get h_ij_\n        # h_ij_ = [B, U]\n        h_ij_l = self._w_ij(s_ij)\n        h_ij_r = self._U(r * (torch.cat([h_left, h_top, h_diag], 1)))\n        h_ij_ = self._activation(h_ij_l + h_ij_r)\n\n        # Calculate h_ij\n        # h_ij = [B, U]\n        h_ij = zl * h_left + zt * h_top + zd * h_diag + zi * h_ij_\n\n        return h_ij\n\n    def forward(self, inputs):\n        """"""\n        Perform SpatialGRU on word interation matrix.\n\n        :param inputs: input tensors.\n        """"""\n\n        batch_size, channels, left_length, right_length = inputs.shape\n\n        # inputs = [L, R, B, C]\n        inputs = inputs.permute([2, 3, 0, 1])\n        if self._direction == \'rb\':\n            # inputs = [R, L, B, C]\n            inputs = torch.flip(inputs, [0, 1])\n\n        # states = [L+1, R+1, B, U]\n        states = [\n            [torch.zeros([batch_size, self._units]).type_as(inputs)\n             for j in range(right_length + 1)] for i in range(left_length + 1)\n        ]\n\n        # Calculate h_ij\n        # h_ij = [B, U]\n        for i in range(left_length):\n            for j in range(right_length):\n                states[i + 1][j + 1] = self.calculate_recurrent_unit(inputs, states, i, j)\n        return states[left_length][right_length]\n'"
matchzoo/modules/stacked_brnn.py,7,"b'import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\n\nclass StackedBRNN(nn.Module):\n    """"""\n    Stacked Bi-directional RNNs.\n\n    Differs from standard PyTorch library in that it has the option to save\n    and concat the hidden states between layers. (i.e. the output hidden size\n    for each sequence input is num_layers * hidden_size).\n\n    Examples:\n        >>> import torch\n        >>> rnn = StackedBRNN(\n        ...     input_size=10,\n        ...     hidden_size=10,\n        ...     num_layers=2,\n        ...     dropout_rate=0.2,\n        ...     dropout_output=True,\n        ...     concat_layers=False\n        ... )\n        >>> x = torch.randn(2, 5, 10)\n        >>> x.size()\n        torch.Size([2, 5, 10])\n        >>> x_mask = (torch.ones(2, 5) == 1)\n        >>> rnn(x, x_mask).shape\n        torch.Size([2, 5, 20])\n\n    """"""\n\n    def __init__(self, input_size, hidden_size, num_layers,\n                 dropout_rate=0, dropout_output=False, rnn_type=nn.LSTM,\n                 concat_layers=False):\n        """"""Stacked Bidirectional LSTM.""""""\n        super().__init__()\n        self.dropout_output = dropout_output\n        self.dropout_rate = dropout_rate\n        self.num_layers = num_layers\n        self.concat_layers = concat_layers\n        self.rnns = nn.ModuleList()\n        for i in range(num_layers):\n            input_size = input_size if i == 0 else 2 * hidden_size\n            self.rnns.append(rnn_type(input_size, hidden_size,\n                                      num_layers=1,\n                                      bidirectional=True))\n\n    def forward(self, x, x_mask):\n        """"""Encode either padded or non-padded sequences.""""""\n        if x_mask.data.sum() == 0:\n            # No padding necessary.\n            output = self._forward_unpadded(x, x_mask)\n        output = self._forward_unpadded(x, x_mask)\n\n        return output.contiguous()\n\n    def _forward_unpadded(self, x, x_mask):\n        """"""Faster encoding that ignores any padding.""""""\n        # Transpose batch and sequence dims\n        x = x.transpose(0, 1)\n\n        # Encode all layers\n        outputs = [x]\n        for i in range(self.num_layers):\n            rnn_input = outputs[-1]\n\n            # Apply dropout to hidden input\n            if self.dropout_rate > 0:\n                rnn_input = F.dropout(rnn_input,\n                                      p=self.dropout_rate,\n                                      training=self.training)\n            # Forward\n            rnn_output = self.rnns[i](rnn_input)[0]\n            outputs.append(rnn_output)\n\n        # Concat hidden layers\n        if self.concat_layers:\n            output = torch.cat(outputs[1:], 2)\n        else:\n            output = outputs[-1]\n\n        # Transpose back\n        output = output.transpose(0, 1)\n\n        # Dropout on output layer\n        if self.dropout_output and self.dropout_rate > 0:\n            output = F.dropout(output,\n                               p=self.dropout_rate,\n                               training=self.training)\n        return output\n'"
matchzoo/preprocessors/__init__.py,0,b'from . import units\nfrom .naive_preprocessor import NaivePreprocessor\nfrom .basic_preprocessor import BasicPreprocessor\nfrom .bert_preprocessor import BertPreprocessor\n\n\ndef list_available() -> list:\n    from matchzoo.engine.base_preprocessor import BasePreprocessor\n    from matchzoo.utils import list_recursive_concrete_subclasses\n    return list_recursive_concrete_subclasses(BasePreprocessor)\n'
matchzoo/preprocessors/basic_preprocessor.py,0,"b'""""""Basic Preprocessor.""""""\n\nfrom tqdm import tqdm\nimport typing\n\nfrom . import units\nfrom matchzoo import DataPack\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\nfrom .build_vocab_unit import build_vocab_unit\nfrom .build_unit_from_data_pack import build_unit_from_data_pack\nfrom .chain_transform import chain_transform\n\ntqdm.pandas()\n\n\nclass BasicPreprocessor(BasePreprocessor):\n    """"""\n    Baisc preprocessor helper.\n\n    :param truncated_mode: String, mode used by :class:`TruncatedLength`.\n        Can be \'pre\' or \'post\'.\n    :param truncated_length_left: Integer, maximize length of :attr:`left`\n        in the data_pack.\n    :param truncated_length_right: Integer, maximize length of :attr:`right`\n        in the data_pack.\n    :param filter_mode: String, mode used by :class:`FrequenceFilterUnit`. Can\n        be \'df\', \'cf\', and \'idf\'.\n    :param filter_low_freq: Float, lower bound value used by\n        :class:`FrequenceFilterUnit`.\n    :param filter_high_freq: Float, upper bound value used by\n        :class:`FrequenceFilterUnit`.\n    :param remove_stop_words: Bool, use :class:`StopRemovalUnit` unit or not.\n\n    Example:\n        >>> import matchzoo as mz\n        >>> train_data = mz.datasets.toy.load_data(\'train\')\n        >>> test_data = mz.datasets.toy.load_data(\'test\')\n        >>> preprocessor = mz.preprocessors.BasicPreprocessor(\n        ...     truncated_length_left=10,\n        ...     truncated_length_right=20,\n        ...     filter_mode=\'df\',\n        ...     filter_low_freq=2,\n        ...     filter_high_freq=1000,\n        ...     remove_stop_words=True\n        ... )\n        >>> preprocessor = preprocessor.fit(train_data, verbose=0)\n        >>> preprocessor.context[\'vocab_size\']\n        226\n        >>> processed_train_data = preprocessor.transform(train_data,\n        ...                                               verbose=0)\n        >>> type(processed_train_data)\n        <class \'matchzoo.data_pack.data_pack.DataPack\'>\n        >>> test_data_transformed = preprocessor.transform(test_data,\n        ...                                                verbose=0)\n        >>> type(test_data_transformed)\n        <class \'matchzoo.data_pack.data_pack.DataPack\'>\n\n    """"""\n\n    def __init__(self,\n                 truncated_mode: str = \'pre\',\n                 truncated_length_left: int = None,\n                 truncated_length_right: int = None,\n                 filter_mode: str = \'df\',\n                 filter_low_freq: float = 1,\n                 filter_high_freq: float = float(\'inf\'),\n                 remove_stop_words: bool = False,\n                 ngram_size: typing.Optional[int] = None):\n        """"""Initialization.""""""\n        super().__init__()\n        self._truncated_mode = truncated_mode\n        self._truncated_length_left = truncated_length_left\n        self._truncated_length_right = truncated_length_right\n        if self._truncated_length_left:\n            self._left_truncatedlength_unit = units.TruncatedLength(\n                self._truncated_length_left, self._truncated_mode\n            )\n        if self._truncated_length_right:\n            self._right_truncatedlength_unit = units.TruncatedLength(\n                self._truncated_length_right, self._truncated_mode\n            )\n        self._filter_unit = units.FrequencyFilter(\n            low=filter_low_freq,\n            high=filter_high_freq,\n            mode=filter_mode\n        )\n        self._units = self._default_units()\n        if remove_stop_words:\n            self._units.append(units.stop_removal.StopRemoval())\n        self._ngram_size = ngram_size\n        if ngram_size:\n            self._context[\'ngram_process_unit\'] = units.NgramLetter(\n                ngram=ngram_size, reduce_dim=True\n            )\n\n    def fit(self, data_pack: DataPack, verbose: int = 1):\n        """"""\n        Fit pre-processing context for transformation.\n\n        :param data_pack: data_pack to be preprocessed.\n        :param verbose: Verbosity.\n        :return: class:`BasicPreprocessor` instance.\n        """"""\n        data_pack = data_pack.apply_on_text(chain_transform(self._units),\n                                            verbose=verbose)\n        fitted_filter_unit = build_unit_from_data_pack(self._filter_unit,\n                                                       data_pack,\n                                                       flatten=False,\n                                                       mode=\'right\',\n                                                       verbose=verbose)\n        data_pack = data_pack.apply_on_text(fitted_filter_unit.transform,\n                                            mode=\'right\', verbose=verbose)\n        self._context[\'filter_unit\'] = fitted_filter_unit\n\n        vocab_unit = build_vocab_unit(data_pack, verbose=verbose)\n        self._context[\'vocab_unit\'] = vocab_unit\n\n        vocab_size = len(vocab_unit.state[\'term_index\'])\n        self._context[\'vocab_size\'] = vocab_size\n        self._context[\'embedding_input_dim\'] = vocab_size\n\n        if self._ngram_size:\n            data_pack = data_pack.apply_on_text(\n                self._context[\'ngram_process_unit\'].transform,\n                mode=\'both\',\n                verbose=verbose\n            )\n            ngram_unit = build_vocab_unit(data_pack, verbose=verbose)\n            self._context[\'ngram_vocab_unit\'] = ngram_unit\n            self._context[\'ngram_vocab_size\'] = len(\n                ngram_unit.state[\'term_index\'])\n        return self\n\n    def transform(self, data_pack: DataPack, verbose: int = 1) -> DataPack:\n        """"""\n        Apply transformation on data, create truncated length representation.\n\n        :param data_pack: Inputs to be preprocessed.\n        :param verbose: Verbosity.\n\n        :return: Transformed data as :class:`DataPack` object.\n        """"""\n        data_pack = data_pack.copy()\n        data_pack.apply_on_text(chain_transform(self._units), inplace=True,\n                                verbose=verbose)\n\n        data_pack.apply_on_text(self._context[\'filter_unit\'].transform,\n                                mode=\'right\', inplace=True, verbose=verbose)\n        data_pack.apply_on_text(self._context[\'vocab_unit\'].transform,\n                                mode=\'both\', inplace=True, verbose=verbose)\n        if self._truncated_length_left:\n            data_pack.apply_on_text(self._left_truncatedlength_unit.transform,\n                                    mode=\'left\', inplace=True, verbose=verbose)\n        if self._truncated_length_right:\n            data_pack.apply_on_text(self._right_truncatedlength_unit.transform,\n                                    mode=\'right\', inplace=True,\n                                    verbose=verbose)\n        data_pack.append_text_length(inplace=True, verbose=verbose)\n\n        data_pack.drop_empty(inplace=True)\n        return data_pack\n'"
matchzoo/preprocessors/bert_preprocessor.py,0,"b'""""""Bert Preprocessor.""""""\n\nfrom pytorch_transformers import BertTokenizer\n\nfrom . import units\nfrom matchzoo import DataPack\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\n\n\nclass BertPreprocessor(BasePreprocessor):\n    """"""\n    Baisc preprocessor helper.\n\n    :param mode: String, supported mode can be referred\n        https://huggingface.co/pytorch-transformers/pretrained_models.html.\n\n    """"""\n\n    def __init__(self, mode: str = \'bert-base-uncased\'):\n        """"""Initialization.""""""\n        super().__init__()\n        self._tokenizer = BertTokenizer.from_pretrained(mode)\n\n    def fit(self, data_pack: DataPack, verbose: int = 1):\n        """"""Tokenizer is all BertPreprocessor\'s need.""""""\n        return\n\n    def transform(self, data_pack: DataPack, verbose: int = 1) -> DataPack:\n        """"""\n        Apply transformation on data.\n\n        :param data_pack: Inputs to be preprocessed.\n        :param verbose: Verbosity.\n\n        :return: Transformed data as :class:`DataPack` object.\n        """"""\n        data_pack = data_pack.copy()\n\n        data_pack.apply_on_text(self._tokenizer.encode,\n                                mode=\'both\', inplace=True, verbose=verbose)\n        data_pack.append_text_length(inplace=True, verbose=verbose)\n        data_pack.drop_empty(inplace=True)\n        return data_pack\n'"
matchzoo/preprocessors/build_unit_from_data_pack.py,0,"b'""""""Build unit from data pack.""""""\n\nfrom tqdm import tqdm\n\nimport matchzoo as mz\nfrom .units import StatefulUnit\n\n\ndef build_unit_from_data_pack(\n    unit: StatefulUnit,\n    data_pack: mz.DataPack, mode: str = \'both\',\n    flatten: bool = True, verbose: int = 1\n) -> StatefulUnit:\n    """"""\n    Build a :class:`StatefulUnit` from a :class:`DataPack` object.\n\n    :param unit: :class:`StatefulUnit` object to be built.\n    :param data_pack: The input :class:`DataPack` object.\n    :param mode: One of \'left\', \'right\', and \'both\', to determine the source\n            data for building the :class:`VocabularyUnit`.\n    :param flatten: Flatten the datapack or not. `True` to organize the\n        :class:`DataPack` text as a list, and `False` to organize\n        :class:`DataPack` text as a list of list.\n    :param verbose: Verbosity.\n    :return: A built :class:`StatefulUnit` object.\n\n    """"""\n    corpus = []\n    if flatten:\n        data_pack.apply_on_text(corpus.extend, mode=mode, verbose=verbose)\n    else:\n        data_pack.apply_on_text(corpus.append, mode=mode, verbose=verbose)\n    if verbose:\n        description = \'Building \' + unit.__class__.__name__ + \\\n                      \' from a datapack.\'\n        corpus = tqdm(corpus, desc=description)\n    unit.fit(corpus)\n    return unit\n'"
matchzoo/preprocessors/build_vocab_unit.py,0,"b'from matchzoo.data_pack import DataPack\nfrom .units import Vocabulary\nfrom .build_unit_from_data_pack import build_unit_from_data_pack\n\n\ndef build_vocab_unit(\n    data_pack: DataPack,\n    mode: str = \'both\',\n    verbose: int = 1\n) -> Vocabulary:\n    """"""\n    Build a :class:`preprocessor.units.Vocabulary` given `data_pack`.\n\n    The `data_pack` should be preprocessed forehand, and each item in\n    `text_left` and `text_right` columns of the `data_pack` should be a list\n    of tokens.\n\n    :param data_pack: The :class:`DataPack` to build vocabulary upon.\n    :param mode: One of \'left\', \'right\', and \'both\', to determine the source\n    data for building the :class:`VocabularyUnit`.\n    :param verbose: Verbosity.\n    :return: A built vocabulary unit.\n\n    """"""\n    return build_unit_from_data_pack(\n        unit=Vocabulary(),\n        data_pack=data_pack,\n        mode=mode,\n        flatten=True, verbose=verbose\n    )\n'"
matchzoo/preprocessors/chain_transform.py,0,"b'""""""Wrapper function organizes a number of transform functions.""""""\nimport typing\nimport functools\n\nfrom .units.unit import Unit\n\n\ndef chain_transform(units: typing.List[Unit]) -> typing.Callable:\n    """"""\n    Compose unit transformations into a single function.\n\n    :param units: List of :class:`matchzoo.StatelessUnit`.\n    """"""\n\n    @functools.wraps(chain_transform)\n    def wrapper(arg):\n        """"""Wrapper function of transformations composition.""""""\n        for unit in units:\n            arg = unit.transform(arg)\n        return arg\n\n    unit_names = \' => \'.join(unit.__class__.__name__ for unit in units)\n    wrapper.__name__ += \' of \' + unit_names\n    return wrapper\n'"
matchzoo/preprocessors/naive_preprocessor.py,0,"b'""""""Naive Preprocessor.""""""\n\nfrom tqdm import tqdm\n\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\nfrom matchzoo import DataPack\nfrom .chain_transform import chain_transform\nfrom .build_vocab_unit import build_vocab_unit\nfrom . import units\n\ntqdm.pandas()\n\n\nclass NaivePreprocessor(BasePreprocessor):\n    """"""\n    Naive preprocessor.\n\n    Example:\n        >>> import matchzoo as mz\n        >>> train_data = mz.datasets.toy.load_data()\n        >>> test_data = mz.datasets.toy.load_data(stage=\'test\')\n        >>> preprocessor = mz.preprocessors.NaivePreprocessor()\n        >>> train_data_processed = preprocessor.fit_transform(train_data,\n        ...                                                   verbose=0)\n        >>> type(train_data_processed)\n        <class \'matchzoo.data_pack.data_pack.DataPack\'>\n        >>> test_data_transformed = preprocessor.transform(test_data,\n        ...                                                verbose=0)\n        >>> type(test_data_transformed)\n        <class \'matchzoo.data_pack.data_pack.DataPack\'>\n\n    """"""\n\n    def fit(self, data_pack: DataPack, verbose: int = 1):\n        """"""\n        Fit pre-processing context for transformation.\n\n        :param data_pack: data_pack to be preprocessed.\n        :param verbose: Verbosity.\n        :return: class:`NaivePreprocessor` instance.\n        """"""\n        func = chain_transform(self._default_units())\n        data_pack = data_pack.apply_on_text(func, verbose=verbose)\n        vocab_unit = build_vocab_unit(data_pack, verbose=verbose)\n        self._context[\'vocab_unit\'] = vocab_unit\n        return self\n\n    def transform(self, data_pack: DataPack, verbose: int = 1) -> DataPack:\n        """"""\n        Apply transformation on data, create truncated length representation.\n\n        :param data_pack: Inputs to be preprocessed.\n        :param verbose: Verbosity.\n\n        :return: Transformed data as :class:`DataPack` object.\n        """"""\n        data_pack = data_pack.copy()\n\n        units_ = self._default_units()\n        units_.append(self._context[\'vocab_unit\'])\n        units_.append(\n            units.TruncatedLength(text_length=30, truncate_mode=\'post\'))\n        func = chain_transform(units_)\n        data_pack.apply_on_text(func, inplace=True, verbose=verbose)\n        data_pack.append_text_length(inplace=True, verbose=verbose)\n        data_pack.drop_empty(inplace=True)\n        return data_pack\n'"
matchzoo/tasks/__init__.py,0,b'from .classification import Classification\nfrom .ranking import Ranking\n'
matchzoo/tasks/classification.py,0,"b'""""""Classification task.""""""\n\nfrom matchzoo.engine.base_task import BaseTask\n\n\nclass Classification(BaseTask):\n    """"""Classification task.\n\n    Examples:\n        >>> classification_task = Classification(num_classes=2)\n        >>> classification_task.metrics = [\'acc\']\n        >>> classification_task.num_classes\n        2\n        >>> classification_task.output_shape\n        (2,)\n        >>> classification_task.output_dtype\n        <class \'int\'>\n        >>> print(classification_task)\n        Classification Task with 2 classes\n\n    """"""\n\n    TYPE = \'classification\'\n\n    def __init__(self, num_classes: int = 2, **kwargs):\n        """"""Classification task.""""""\n        super().__init__(**kwargs)\n        if not isinstance(num_classes, int):\n            raise TypeError(""Number of classes must be an integer."")\n        if num_classes < 2:\n            raise ValueError(""Number of classes can\'t be smaller than 2"")\n        self._num_classes = num_classes\n\n    @property\n    def num_classes(self) -> int:\n        """""":return: number of classes to classify.""""""\n        return self._num_classes\n\n    @classmethod\n    def list_available_losses(cls) -> list:\n        """""":return: a list of available losses.""""""\n        return [\'cross_entropy\']\n\n    @classmethod\n    def list_available_metrics(cls) -> list:\n        """""":return: a list of available metrics.""""""\n        return [\'acc\']\n\n    @property\n    def output_shape(self) -> tuple:\n        """""":return: output shape of a single sample of the task.""""""\n        return self._num_classes,\n\n    @property\n    def output_dtype(self):\n        """""":return: target data type, expect `int` as output.""""""\n        return int\n\n    def __str__(self):\n        """""":return: Task name as string.""""""\n        return f\'Classification Task with {self._num_classes} classes\'\n'"
matchzoo/tasks/ranking.py,0,"b'""""""Ranking task.""""""\n\nfrom matchzoo.engine import base_task\n\n\nclass Ranking(base_task.BaseTask):\n    """"""Ranking Task.\n\n    Examples:\n        >>> ranking_task = Ranking()\n        >>> ranking_task.metrics = [\'map\', \'ndcg\']\n        >>> ranking_task.output_shape\n        (1,)\n        >>> ranking_task.output_dtype\n        <class \'float\'>\n        >>> print(ranking_task)\n        Ranking Task\n\n    """"""\n\n    TYPE = \'ranking\'\n\n    @classmethod\n    def list_available_losses(cls) -> list:\n        """""":return: a list of available losses.""""""\n        return [\'mse\']\n\n    @classmethod\n    def list_available_metrics(cls) -> list:\n        """""":return: a list of available metrics.""""""\n        return [\'map\']\n\n    @property\n    def output_shape(self) -> tuple:\n        """""":return: output shape of a single sample of the task.""""""\n        return 1,\n\n    @property\n    def output_dtype(self):\n        """""":return: target data type, expect `float` as output.""""""\n        return float\n\n    def __str__(self):\n        """""":return: Task name as string.""""""\n        return \'Ranking Task\'\n'"
matchzoo/trainers/__init__.py,0,b'from .trainer import Trainer\n'
matchzoo/trainers/trainer.py,18,"b'""""""Base Trainer.""""""\n\nimport typing\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport matchzoo\nfrom matchzoo import tasks\nfrom matchzoo.dataloader import DataLoader\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.base_metric import BaseMetric\nfrom matchzoo.utils import AverageMeter, Timer, EarlyStopping\n\n\nclass Trainer:\n    """"""\n    MatchZoo tranier.\n\n    :param model: A :class:`BaseModel` instance.\n    :param optimizer: A :class:`optim.Optimizer` instance.\n    :param trainloader: A :class`DataLoader` instance. The dataloader\n        is used for training the model.\n    :param validloader: A :class`DataLoader` instance. The dataloader\n        is used for validating the model.\n    :param device: The desired device of returned tensor. Default:\n        if None, use the current device. If `torch.device` or int,\n        use device specified by user. If list, use data parallel.\n    :param start_epoch: Int. Number of starting epoch.\n    :param epochs: The maximum number of epochs for training.\n        Defaults to 10.\n    :param validate_interval: Int. Interval of validation.\n    :param scheduler: LR scheduler used to adjust the learning rate\n        based on the number of epochs.\n    :param clip_norm: Max norm of the gradients to be clipped.\n    :param patience: Number fo events to wait if no improvement and\n        then stop the training.\n    :param key: Key of metric to be compared.\n    :param checkpoint: A checkpoint from which to continue training.\n        If None, training starts from scratch. Defaults to None.\n        Should be a file-like object (has to implement read, readline,\n        tell, and seek), or a string containing a file name.\n    :param save_dir: Directory to save trainer.\n    :param save_all: Bool. If True, save `Trainer` instance; If False,\n        only save model. Defaults to False.\n    :param verbose: 0, 1, or 2. Verbosity mode. 0 = silent,\n        1 = verbose, 2 = one log line per epoch.\n    """"""\n\n    def __init__(\n        self,\n        model: BaseModel,\n        optimizer: optim.Optimizer,\n        trainloader: DataLoader,\n        validloader: DataLoader,\n        device: typing.Union[torch.device, int, list, None] = None,\n        start_epoch: int = 1,\n        epochs: int = 10,\n        validate_interval: typing.Optional[int] = None,\n        scheduler: typing.Any = None,\n        clip_norm: typing.Union[float, int] = None,\n        patience: typing.Optional[int] = None,\n        key: typing.Any = None,\n        checkpoint: typing.Union[str, Path] = None,\n        save_dir: typing.Union[str, Path] = None,\n        save_all: bool = False,\n        verbose: int = 1,\n        **kwargs\n    ):\n        """"""Base Trainer constructor.""""""\n        self._load_model(model, device)\n        self._load_dataloader(\n            trainloader, validloader, validate_interval\n        )\n\n        self._optimizer = optimizer\n        self._scheduler = scheduler\n        self._clip_norm = clip_norm\n        self._criterions = self._task.losses\n\n        if not key:\n            key = self._task.metrics[0]\n        self._early_stopping = EarlyStopping(\n            patience=patience,\n            key=key\n        )\n\n        self._start_epoch = start_epoch\n        self._epochs = epochs\n        self._iteration = 0\n        self._verbose = verbose\n        self._save_all = save_all\n\n        self._load_path(checkpoint, save_dir)\n\n    def _load_dataloader(\n        self,\n        trainloader: DataLoader,\n        validloader: DataLoader,\n        validate_interval: typing.Optional[int] = None\n    ):\n        """"""\n        Load trainloader and determine validate interval.\n\n        :param trainloader: A :class`DataLoader` instance. The dataloader\n            is used to train the model.\n        :param validloader: A :class`DataLoader` instance. The dataloader\n            is used to validate the model.\n        :param validate_interval: int. Interval of validation.\n        """"""\n        if not isinstance(trainloader, DataLoader):\n            raise ValueError(\n                \'trainloader should be a `DataLoader` instance.\'\n            )\n        if not isinstance(validloader, DataLoader):\n            raise ValueError(\n                \'validloader should be a `DataLoader` instance.\'\n            )\n        self._trainloader = trainloader\n        self._validloader = validloader\n        if not validate_interval:\n            self._validate_interval = len(self._trainloader)\n        else:\n            self._validate_interval = validate_interval\n\n    def _load_model(\n        self,\n        model: BaseModel,\n        device: typing.Union[torch.device, int, list, None] = None\n    ):\n        """"""\n        Load model.\n\n        :param model: :class:`BaseModel` instance.\n        :param device: The desired device of returned tensor. Default:\n            if None, use the current device. If `torch.device` or int,\n            use device specified by user. If list, use data parallel.\n        """"""\n        if not isinstance(model, BaseModel):\n            raise ValueError(\n                \'model should be a `BaseModel` instance.\'\n                f\' But got {type(model)}.\'\n            )\n\n        self._task = model.params[\'task\']\n        self._data_parallel = False\n        self._model = model\n\n        if isinstance(device, list) and len(device):\n            self._data_parallel = True\n            self._model = torch.nn.DataParallel(self._model, device_ids=device)\n            self._device = device[0]\n        else:\n            if not (isinstance(device, torch.device) or isinstance(device, int)):\n                device = torch.device(\n                    ""cuda"" if torch.cuda.is_available() else ""cpu"")\n            self._device = device\n\n        self._model.to(self._device)\n\n    def _load_path(\n        self,\n        checkpoint: typing.Union[str, Path],\n        save_dir: typing.Union[str, Path],\n    ):\n        """"""\n        Load save_dir and Restore from checkpoint.\n\n        :param checkpoint: A checkpoint from which to continue training.\n            If None, training starts from scratch. Defaults to None.\n            Should be a file-like object (has to implement read, readline,\n            tell, and seek), or a string containing a file name.\n        :param save_dir: Directory to save trainer.\n\n        """"""\n        if not save_dir:\n            save_dir = Path(\'.\').joinpath(\'save\')\n        if not Path(save_dir).exists():\n            Path(save_dir).mkdir(parents=True)\n\n        self._save_dir = Path(save_dir)\n        # Restore from checkpoint\n\n        if checkpoint:\n            if self._save_all:\n                self.restore(checkpoint)\n            else:\n                self.restore_model(checkpoint)\n\n    def _backward(self, loss):\n        """"""\n        Computes the gradient of current `loss` graph leaves.\n\n        :param loss: Tensor. Loss of model.\n\n        """"""\n        self._optimizer.zero_grad()\n        loss.backward()\n        if self._clip_norm:\n            nn.utils.clip_grad_norm_(\n                self._model.parameters(), self._clip_norm\n            )\n        self._optimizer.step()\n\n    def _run_scheduler(self):\n        """"""Run scheduler.""""""\n        if self._scheduler:\n            self._scheduler.step()\n\n    def run(self):\n        """"""\n        Train model.\n\n        The processes:\n            Run each epoch -> Run scheduler -> Should stop early?\n\n        """"""\n        self._model.train()\n        timer = Timer()\n        for epoch in range(self._start_epoch, self._epochs + 1):\n            self._epoch = epoch\n            self._run_epoch()\n            self._run_scheduler()\n            if self._early_stopping.should_stop_early:\n                break\n        if self._verbose:\n            tqdm.write(f\'Cost time: {timer.time}s\')\n\n    def _run_epoch(self):\n        """"""\n        Run each epoch.\n\n        The training steps:\n            - Get batch and feed them into model\n            - Get outputs. Caculate all losses and sum them up\n            - Loss backwards and optimizer steps\n            - Evaluation\n            - Update and output result\n\n        """"""\n        # Get total number of batch\n        num_batch = len(self._trainloader)\n        train_loss = AverageMeter()\n        with tqdm(enumerate(self._trainloader), total=num_batch,\n                  disable=not self._verbose) as pbar:\n            for step, (inputs, target) in pbar:\n                outputs = self._model(inputs)\n                # Caculate all losses and sum them up\n                loss = torch.sum(\n                    *[c(outputs, target) for c in self._criterions]\n                )\n                self._backward(loss)\n                train_loss.update(loss.item())\n\n                # Set progress bar\n                pbar.set_description(f\'Epoch {self._epoch}/{self._epochs}\')\n                pbar.set_postfix(loss=f\'{loss.item():.3f}\')\n\n                # Run validate\n                self._iteration += 1\n                if self._iteration % self._validate_interval == 0:\n                    pbar.update(1)\n                    if self._verbose:\n                        pbar.write(\n                            f\'[Iter-{self._iteration} \'\n                            f\'Loss-{train_loss.avg:.3f}]:\')\n                    result = self.evaluate(self._validloader)\n                    if self._verbose:\n                        pbar.write(\'  Validation: \' + \' - \'.join(\n                            f\'{k}: {round(v, 4)}\' for k, v in result.items()))\n                    # Early stopping\n                    self._early_stopping.update(result)\n                    if self._early_stopping.should_stop_early:\n                        self._save()\n                        pbar.write(\'Ran out of patience. Stop training...\')\n                        break\n                    elif self._early_stopping.is_best_so_far:\n                        self._save()\n\n    def evaluate(\n        self,\n        dataloader: DataLoader,\n    ):\n        """"""\n        Evaluate the model.\n\n        :param dataloader: A DataLoader object to iterate over the data.\n\n        """"""\n        result = dict()\n        y_pred = self.predict(dataloader)\n        y_true = dataloader.label\n        id_left = dataloader.id_left\n\n        if isinstance(self._task, tasks.Classification):\n            for metric in self._task.metrics:\n                result[metric] = metric(y_true, y_pred)\n        else:\n            for metric in self._task.metrics:\n                result[metric] = self._eval_metric_on_data_frame(\n                    metric, id_left, y_true, y_pred.squeeze(axis=-1))\n        return result\n\n    @classmethod\n    def _eval_metric_on_data_frame(\n        cls,\n        metric: BaseMetric,\n        id_left: typing.Any,\n        y_true: typing.Union[list, np.array],\n        y_pred: typing.Union[list, np.array]\n    ):\n        """"""\n        Eval metric on data frame.\n\n        This function is used to eval metrics for `Ranking` task.\n\n        :param metric: Metric for `Ranking` task.\n        :param id_left: id of input left. Samples with same id_left should\n            be grouped for evaluation.\n        :param y_true: Labels of dataset.\n        :param y_pred: Outputs of model.\n        :return: Evaluation result.\n\n        """"""\n        eval_df = pd.DataFrame(data={\n            \'id\': id_left,\n            \'true\': y_true,\n            \'pred\': y_pred\n        })\n        assert isinstance(metric, BaseMetric)\n        val = eval_df.groupby(by=\'id\').apply(\n            lambda df: metric(df[\'true\'].values, df[\'pred\'].values)\n        ).mean()\n        return val\n\n    def predict(\n        self,\n        dataloader: DataLoader\n    ) -> np.array:\n        """"""\n        Generate output predictions for the input samples.\n\n        :param dataloader: input DataLoader\n        :return: predictions\n\n        """"""\n        with torch.no_grad():\n            self._model.eval()\n            predictions = []\n            for batch in dataloader:\n                inputs = batch[0]\n                outputs = self._model(inputs).detach().cpu()\n                predictions.append(outputs)\n            self._model.train()\n            return torch.cat(predictions, dim=0).numpy()\n\n    def _save(self):\n        """"""Save.""""""\n        if self._save_all:\n            self.save()\n        else:\n            self.save_model()\n\n    def save_model(self):\n        """"""Save the model.""""""\n        checkpoint = self._save_dir.joinpath(\'model.pt\')\n        if self._data_parallel:\n            torch.save(self._model.module.state_dict(), checkpoint)\n        else:\n            torch.save(self._model.state_dict(), checkpoint)\n\n    def save(self):\n        """"""\n        Save the trainer.\n\n        `Trainer` parameters like epoch, best_so_far, model, optimizer\n        and early_stopping will be savad to specific file path.\n\n        :param path: Path to save trainer.\n\n        """"""\n        checkpoint = self._save_dir.joinpath(\'trainer.pt\')\n        if self._data_parallel:\n            model = self._model.module.state_dict()\n        else:\n            model = self._model.state_dict()\n        state = {\n            \'epoch\': self._epoch,\n            \'model\': model,\n            \'optimizer\': self._optimizer.state_dict(),\n            \'early_stopping\': self._early_stopping.state_dict(),\n        }\n        if self._scheduler:\n            state[\'scheduler\'] = self._scheduler.state_dict()\n        torch.save(state, checkpoint)\n\n    def restore_model(self, checkpoint: typing.Union[str, Path]):\n        """"""\n        Restore model.\n\n        :param checkpoint: A checkpoint from which to continue training.\n\n        """"""\n        state = torch.load(checkpoint, map_location=self._device)\n        if self._data_parallel:\n            self._model.module.load_state_dict(state)\n        else:\n            self._model.load_state_dict(state)\n\n    def restore(self, checkpoint: typing.Union[str, Path] = None):\n        """"""\n        Restore trainer.\n\n        :param checkpoint: A checkpoint from which to continue training.\n\n        """"""\n        state = torch.load(checkpoint, map_location=self._device)\n        if self._data_parallel:\n            self._model.module.load_state_dict(state[\'model\'])\n        else:\n            self._model.load_state_dict(state[\'model\'])\n        self._optimizer.load_state_dict(state[\'optimizer\'])\n        self._start_epoch = state[\'epoch\'] + 1\n        self._early_stopping.load_state_dict(state[\'early_stopping\'])\n        if self._scheduler:\n            self._scheduler.load_state_dict(state[\'scheduler\'])\n'"
matchzoo/utils/__init__.py,0,"b'from .one_hot import one_hot\nfrom .tensor_type import TensorType\nfrom .list_recursive_subclasses import list_recursive_concrete_subclasses\nfrom .parse import parse_loss, parse_activation, parse_metric, parse_optimizer\nfrom .average_meter import AverageMeter\nfrom .timer import Timer\nfrom .early_stopping import EarlyStopping\nfrom .get_file import get_file, _hash_file\n'"
matchzoo/utils/average_meter.py,0,"b'""""""Average meter.""""""\n\n\nclass AverageMeter(object):\n    """"""\n    Computes and stores the average and current value.\n\n    Examples:\n        >>> am = AverageMeter()\n        >>> am.update(1)\n        >>> am.avg\n        1.0\n        >>> am.update(val=2.5, n=2)\n        >>> am.avg\n        2.0\n\n    """"""\n\n    def __init__(self):\n        """"""Average meter constructor.""""""\n        self.reset()\n\n    def reset(self):\n        """"""Reset AverageMeter.""""""\n        self._val = 0.\n        self._avg = 0.\n        self._sum = 0.\n        self._count = 0.\n\n    def update(self, val, n=1):\n        """"""Update value.""""""\n        self._val = val\n        self._sum += val * n\n        self._count += n\n        self._avg = self._sum / self._count\n\n    @property\n    def avg(self):\n        """"""Get avg.""""""\n        return self._avg\n'"
matchzoo/utils/early_stopping.py,0,"b'""""""Early stopping.""""""\n\nimport typing\n\nimport torch\nimport numpy as np\n\n\nclass EarlyStopping:\n    """"""\n    EarlyStopping stops training if no improvement after a given patience.\n\n    :param patience: Number fo events to wait if no improvement and then\n        stop the training.\n    :param should_decrease: The way to judge the best so far.\n    :param key: Key of metric to be compared.\n    """"""\n\n    def __init__(\n        self,\n        patience: typing.Optional[int] = None,\n        should_decrease: bool = None,\n        key: typing.Any = None\n    ):\n        """"""Early stopping Constructor.""""""\n        self._patience = patience\n        self._key = key\n        self._best_so_far = 0\n        self._epochs_with_no_improvement = 0\n        self._is_best_so_far = False\n        self._early_stop = False\n\n    def state_dict(self) -> typing.Dict[str, typing.Any]:\n        """"""A `Trainer` can use this to serialize the state.""""""\n        return {\n            \'patience\': self._patience,\n            \'best_so_far\': self._best_so_far,\n            \'is_best_so_far\': self._is_best_so_far,\n            \'epochs_with_no_improvement\': self._epochs_with_no_improvement,\n        }\n\n    def load_state_dict(\n        self,\n        state_dict: typing.Dict[str, typing.Any]\n    ) -> None:\n        """"""Hydrate a early stopping from a serialized state.""""""\n        self._patience = state_dict[""patience""]\n        self._is_best_so_far = state_dict[""is_best_so_far""]\n        self._best_so_far = state_dict[""best_so_far""]\n        self._epochs_with_no_improvement = \\\n            state_dict[""epochs_with_no_improvement""]\n\n    def update(self, result: list):\n        """"""Call function.""""""\n        score = result[self._key]\n        if score > self._best_so_far:\n            self._best_so_far = score\n            self._is_best_so_far = True\n            self._epochs_with_no_improvement = 0\n        else:\n            self._is_best_so_far = False\n            self._epochs_with_no_improvement += 1\n\n    @property\n    def best_so_far(self) -> bool:\n        """"""Returns best so far.""""""\n        return self._best_so_far\n\n    @property\n    def is_best_so_far(self) -> bool:\n        """"""Returns true if it is the best so far.""""""\n        return self._is_best_so_far\n\n    @property\n    def should_stop_early(self) -> bool:\n        """"""Returns true if improvement has stopped for long enough.""""""\n        if not self._patience:\n            return False\n        else:\n            return self._epochs_with_no_improvement >= self._patience\n'"
matchzoo/utils/get_file.py,0,"b'""""""Download file.""""""\nimport typing\nfrom pathlib import Path\n\nimport os\nimport hashlib\nimport shutil\nimport sys\nimport tarfile\nimport time\nimport zipfile\nimport collections\nimport six\nfrom six.moves.urllib.error import HTTPError\nfrom six.moves.urllib.error import URLError\nfrom six.moves.urllib.request import urlretrieve\nimport numpy as np\n\nimport matchzoo\n\n\nclass Progbar(object):\n    """"""\n    Displays a progress bar.\n\n    :param target: Total number of steps expected, None if unknown.\n    :param width: Progress bar width on screen.\n    :param verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n    :param stateful_metrics: Iterable of string names of metrics that\n        should *not* be averaged over time. Metrics in this list\n        will be displayed as-is. All others will be averaged\n        by the progbar before display.\n    :param interval: Minimum visual progress update interval (in seconds).\n    """"""\n\n    def __init__(\n        self,\n        target,\n        width=30,\n        verbose=1,\n        interval=0.05,\n    ):\n        """"""Init.""""""\n        self.target = target\n        self.width = width\n        self.verbose = verbose\n        self.interval = interval\n\n        self._dynamic_display = ((hasattr(sys.stdout,\n                                  \'isatty\') and sys.stdout.isatty()\n                                  ) or \'ipykernel\' in sys.modules)\n        self._total_width = 0\n        self._seen_so_far = 0\n        self._start = time.time()\n        self._last_update = 0\n\n    def update(self, current):\n        """"""Updates the progress bar.""""""\n        self._seen_so_far = current\n\n        now = time.time()\n        info = \' - {0:.0f}s\'.format(now - self._start)\n        if self.verbose == 1:\n            if (now - self._last_update < self.interval and self.target is not\n               None and current < self.target):\n                return\n\n            prev_total_width = self._total_width\n            if self._dynamic_display:\n                sys.stdout.write(\'\\b\' * prev_total_width)\n                sys.stdout.write(\'\\r\')\n            else:\n                sys.stdout.write(\'\\n\')\n\n            if self.target is not None:\n                numdigits = int(np.floor(np.log10(self.target))) + 1\n                bar = \'{2:{0:d}d}/{1} [\'.format(\n                    numdigits, self.target, current)\n                prog = float(current) / self.target\n                prog_width = int(self.width * prog)\n                if prog_width > 0:\n                    bar += (\'=\' * (prog_width - 1))\n                    if current < self.target:\n                        bar += \'>\'\n                    else:\n                        bar += \'=\'\n                bar += (\'.\' * (self.width - prog_width))\n                bar += \']\'\n            else:\n                bar = \'{0:7d}/Unknown\'.format(current)\n\n            self._total_width = len(bar)\n            sys.stdout.write(bar)\n\n            if current:\n                time_per_unit = (now - self._start) / current\n            else:\n                time_per_unit = 0\n            if self.target is not None and current < self.target:\n                eta = int(time_per_unit * (self.target - current))\n                if eta > 3600:\n                    eta_format = (\'{0:d}:{1:02d}:{2:02d}\'.format(\n                        eta // 3600, (eta % 3600) // 60, eta % 60))\n                elif eta > 60:\n                    eta_format = \'{0:d}:{1:02d}\'.format(eta // 60, eta % 60)\n                else:\n                    eta_format = \'{0:d}s\'.format(eta)\n\n                info = \' - ETA: {0}\'.format(eta_format)\n            else:\n                if time_per_unit >= 1:\n                    info += \' {0:.0f}s/step\'.format(time_per_unit)\n                elif time_per_unit >= 1e-3:\n                    info += \' {0:.0f}ms/step\'.format(time_per_unit * 1e3)\n                else:\n                    info += \' {0:.0f}us/step\'.format(time_per_unit * 1e6)\n\n            self._total_width += len(info)\n            if prev_total_width > self._total_width:\n                info += (\' \' * (prev_total_width - self._total_width))\n\n            if self.target is not None and current >= self.target:\n                info += \'\\n\'\n\n            sys.stdout.write(info)\n            sys.stdout.flush()\n\n        elif self.verbose == 2:\n            if self.target is None or current >= self.target:\n                info += \'\\n\'\n                sys.stdout.write(info)\n                sys.stdout.flush()\n\n        self._last_update = now\n\n\ndef _extract_archive(file_path, path=\'.\', archive_format=\'auto\'):\n    """"""\n    Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n\n    :param file_path: path to the archive file\n    :param path: path to extract the archive file\n    :param archive_format: Archive format to try for extracting the file.\n        Options are \'auto\', \'tar\', \'zip\', and None.\n        \'tar\' includes tar, tar.gz, and tar.bz files.\n        The default \'auto\' is [\'tar\', \'zip\'].\n        None or an empty list will return no matches found.\n\n    :return: True if a match was found and an archive extraction was completed,\n        False otherwise.\n    """"""\n    if archive_format is None:\n        return False\n    if archive_format == \'auto\':\n        archive_format = [\'tar\', \'zip\']\n    if isinstance(archive_format, six.string_types):\n        archive_format = [archive_format]\n\n    for archive_type in archive_format:\n        if archive_type == \'tar\':\n            open_fn = tarfile.open\n            is_match_fn = tarfile.is_tarfile\n        if archive_type == \'zip\':\n            open_fn = zipfile.ZipFile\n            is_match_fn = zipfile.is_zipfile\n\n        if is_match_fn(file_path):\n            with open_fn(file_path) as archive:\n                try:\n                    archive.extractall(path)\n                except (tarfile.TarError, RuntimeError,\n                        KeyboardInterrupt):\n                    if os.path.exists(path):\n                        if os.path.isfile(path):\n                            os.remove(path)\n                        else:\n                            shutil.rmtree(path)\n                    raise\n            return True\n    return False\n\n\ndef get_file(\n    fname: str = None,\n    origin: str = None,\n    untar: bool = False,\n    extract: bool = False,\n    md5_hash: typing.Any = None,\n    file_hash: typing.Any = None,\n    hash_algorithm: str = \'auto\',\n    archive_format: str = \'auto\',\n    cache_subdir: typing.Union[Path, str] = \'data\',\n    cache_dir: typing.Union[Path, str] = matchzoo.USER_DATA_DIR,\n    verbose: int = 1\n) -> str:\n    """"""\n    Downloads a file from a URL if it not already in the cache.\n\n    By default the file at the url `origin` is downloaded to the\n    cache_dir `~/.matchzoo/datasets`, placed in the cache_subdir `data`,\n    and given the filename `fname`. The final location of a file\n    `example.txt` would therefore be `~/.matchzoo/datasets/data/example.txt`.\n\n    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n    Passing a hash will verify the file after download. The command line\n    programs `shasum` and `sha256sum` can compute the hash.\n\n    :param fname: Name of the file. If an absolute path `/path/to/file.txt` is\n        specified the file will be saved at that location.\n    :param origin: Original URL of the file.\n    :param untar: Deprecated in favor of \'extract\'. Boolean, whether the file\n        should be decompressed.\n    :param md5_hash: Deprecated in favor of \'file_hash\'. md5 hash of the file\n        for verification.\n    :param file_hash: The expected hash string of the file after download.\n        The sha256 and md5 hash algorithms are both supported.\n    :param cache_subdir: Subdirectory under the cache dir where the file is\n        saved. If an absolute path `/path/to/folder` is specified the file\n        will be saved at that location.\n    :param hash_algorithm: Select the hash algorithm to verify the file.\n        options are \'md5\', \'sha256\', and \'auto\'. The default \'auto\' detects\n        the hash algorithm in use.\n    :papram extract: True tries extracting the file as an Archive, like tar\n        or zip.\n    :param archive_format: Archive format to try for extracting the file.\n        Options are \'auto\', \'tar\', \'zip\', and None.\n        \'tar\' includes tar, tar.gz, and tar.bz files.\n        The default \'auto\' is [\'tar\', \'zip\'].\n        None or an empty list will return no matches found.\n    :param cache_dir: Location to store cached files, when None it defaults to\n        the [matchzoo.USER_DATA_DIR](~/.matchzoo/datasets).\n    :param verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n\n    :return: Path to the downloaded file.\n    """"""\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = \'md5\'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join(\'/tmp\', \'.matchzoo\')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    if not os.path.exists(datadir):\n        os.makedirs(datadir)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + \'.tar.gz\'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                print(\'A local file was found, but it seems to be \'\n                      \'incomplete or outdated because the file hash \'\n                      \'does not match the original value of file_hash.\'\n                      \' We will re-download the data.\')\n                download = True\n    else:\n        download = True\n\n    if download:\n        print(\'Downloading data from\', origin)\n\n        class ProgressTracker(object):\n            progbar = None\n\n        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size == -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(\n                    target=total_size, verbose=verbose)\n            else:\n                ProgressTracker.progbar.update(count * block_size)\n\n        error_msg = \'URL fetch failure on {} : {} -- {}\'\n        try:\n            try:\n                urlretrieve(origin, fpath, dl_progress)\n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n        except (Exception, KeyboardInterrupt):\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise\n        ProgressTracker.progbar = None\n\n    if untar:\n        if not os.path.exists(untar_fpath):\n            _extract_archive(fpath, datadir, archive_format=\'tar\')\n        return untar_fpath\n\n    if extract:\n        _extract_archive(fpath, datadir, archive_format)\n\n    return fpath\n\n\ndef validate_file(fpath, file_hash, algorithm=\'auto\', chunk_size=65535):\n    """"""\n    Validates a file against a sha256 or md5 hash.\n\n    :param fpath: path to the file being validated\n    :param file_hash:  The expected hash string of the file.\n        The sha256 and md5 hash algorithms are both supported.\n    :param algorithm: Hash algorithm, one of \'auto\', \'sha256\', or \'md5\'.\n        The default \'auto\' detects the hash algorithm in use.\n    :param chunk_size: Bytes to read at a time, important for large files.\n\n    :return: Whether the file is valid.\n    """"""\n    if ((algorithm == \'sha256\') or (algorithm == \'auto\' and len(\n                                    file_hash) == 64)):\n        hasher = \'sha256\'\n    else:\n        hasher = \'md5\'\n\n    if str(_hash_file(fpath, hasher, chunk_size)) == str(file_hash):\n        return True\n    else:\n        return False\n\n\ndef _hash_file(fpath, algorithm=\'sha256\', chunk_size=65535):\n    """"""\n    Calculates a file sha256 or md5 hash.\n\n    :param fpath: path to the file being validated\n    :param algorithm: hash algorithm, one of \'auto\', \'sha256\', or \'md5\'.\n        The default \'auto\' detects the hash algorithm in use.\n    :param chunk_size: Bytes to read at a time, important for large files.\n\n    :return: The file hash.\n    """"""\n    if algorithm == \'sha256\':\n        hasher = hashlib.sha256()\n    else:\n        hasher = hashlib.md5()\n\n    with open(fpath, \'rb\') as fpath_file:\n        for chunk in iter(lambda: fpath_file.read(chunk_size), b\'\'):\n            hasher.update(chunk)\n\n    return hasher.hexdigest()\n'"
matchzoo/utils/list_recursive_subclasses.py,0,"b'import inspect\n\n\ndef list_recursive_concrete_subclasses(base):\n    """"""List all concrete subclasses of `base` recursively.""""""\n    return _filter_concrete(_bfs(base))\n\n\ndef _filter_concrete(classes):\n    return list(filter(lambda c: not inspect.isabstract(c), classes))\n\n\ndef _bfs(base):\n    return base.__subclasses__() + sum([\n        _bfs(subclass)\n        for subclass in base.__subclasses__()\n    ], [])\n'"
matchzoo/utils/one_hot.py,0,"b'""""""One hot vectors.""""""\nimport numpy as np\n\n\ndef one_hot(indices: int, num_classes: int) -> np.ndarray:\n    """""":return: A one-hot encoded vector.""""""\n    vec = np.zeros((num_classes,), dtype=np.int64)\n    vec[indices] = 1\n    return vec\n'"
matchzoo/utils/parse.py,13,"b'import typing\n\nimport torch\nfrom torch import nn\nfrom torch import optim\n\nimport matchzoo\nfrom matchzoo.engine.base_metric import (\n    BaseMetric, RankingMetric, ClassificationMetric\n)\n\nactivation = nn.ModuleDict([\n    [\'relu\', nn.ReLU()],\n    [\'hardtanh\', nn.Hardtanh()],\n    [\'relu6\', nn.ReLU6()],\n    [\'sigmoid\', nn.Sigmoid()],\n    [\'tanh\', nn.Tanh()],\n    [\'softmax\', nn.Softmax()],\n    [\'softmax2d\', nn.Softmax2d()],\n    [\'logsoftmax\', nn.LogSoftmax()],\n    [\'elu\', nn.ELU()],\n    [\'selu\', nn.SELU()],\n    [\'celu\', nn.CELU()],\n    [\'hardshrink\', nn.Hardshrink()],\n    [\'leakyrelu\', nn.LeakyReLU()],\n    [\'logsigmoid\', nn.LogSigmoid()],\n    [\'softplus\', nn.Softplus()],\n    [\'softshrink\', nn.Softshrink()],\n    [\'prelu\', nn.PReLU()],\n    [\'softsign\', nn.Softsign()],\n    [\'softmin\', nn.Softmin()],\n    [\'tanhshrink\', nn.Tanhshrink()],\n    [\'rrelu\', nn.RReLU()],\n    [\'glu\', nn.GLU()],\n])\n\nloss = nn.ModuleDict([\n    [\'l1\', nn.L1Loss()],\n    [\'nll\', nn.NLLLoss()],\n    [\'kldiv\', nn.KLDivLoss()],\n    [\'mse\', nn.MSELoss()],\n    [\'bce\', nn.BCELoss()],\n    [\'bce_with_logits\', nn.BCEWithLogitsLoss()],\n    [\'cosine_embedding\', nn.CosineEmbeddingLoss()],\n    [\'ctc\', nn.CTCLoss()],\n    [\'hinge_embedding\', nn.HingeEmbeddingLoss()],\n    [\'margin_ranking\', nn.MarginRankingLoss()],\n    [\'multi_label_margin\', nn.MultiLabelMarginLoss()],\n    [\'multi_label_soft_margin\', nn.MultiLabelSoftMarginLoss()],\n    [\'multi_margin\', nn.MultiMarginLoss()],\n    [\'smooth_l1\', nn.SmoothL1Loss()],\n    [\'soft_margin\', nn.SoftMarginLoss()],\n    [\'cross_entropy\', nn.CrossEntropyLoss()],\n    [\'triplet_margin\', nn.TripletMarginLoss()],\n    [\'poisson_nll\', nn.PoissonNLLLoss()]\n])\n\noptimizer = dict({\n    \'adadelta\': optim.Adadelta,\n    \'adagrad\': optim.Adagrad,\n    \'adam\': optim.Adam,\n    \'sparse_adam\': optim.SparseAdam,\n    \'adamax\': optim.Adamax,\n    \'asgd\': optim.ASGD,\n    \'lbfgs\': optim.LBFGS,\n    \'rmsprop\': optim.RMSprop,\n    \'rprop\': optim.Rprop,\n    \'sgd\': optim.SGD\n})\n\n\ndef _parse(\n    identifier: typing.Union[str, typing.Type[nn.Module], nn.Module],\n    dictionary: nn.ModuleDict,\n    target: str\n) -> nn.Module:\n    """"""\n    Parse loss and activation.\n\n    :param identifier: activation identifier, one of\n            - String: name of a activation\n            - Torch Modele subclass\n            - Torch Module instance (it will be returned unchanged).\n    :param dictionary: nn.ModuleDict instance. Map string identifier to\n        nn.Module instance.\n    :return: A :class:`nn.Module` instance\n    """"""\n    if isinstance(identifier, str):\n        if identifier in dictionary:\n            return dictionary[identifier]\n        else:\n            raise ValueError(\n                f\'Could not interpret {target} identifier: \' + str(identifier)\n            )\n    elif isinstance(identifier, nn.Module):\n        return identifier\n    elif issubclass(identifier, nn.Module):\n        return identifier()\n    else:\n        raise ValueError(\n            f\'Could not interpret {target} identifier: \' + str(identifier)\n        )\n\n\ndef parse_activation(\n    identifier: typing.Union[str, typing.Type[nn.Module], nn.Module]\n) -> nn.Module:\n    """"""\n    Retrieves a torch Module instance.\n\n    :param identifier: activation identifier, one of\n            - String: name of a activation\n            - Torch Modele subclass\n            - Torch Module instance (it will be returned unchanged).\n    :return: A :class:`nn.Module` instance\n\n    Examples::\n        >>> from torch import nn\n        >>> from matchzoo.utils import parse_activation\n\n    Use `str` as activation:\n        >>> activation = parse_activation(\'relu\')\n        >>> type(activation)\n        <class \'torch.nn.modules.activation.ReLU\'>\n\n    Use :class:`torch.nn.Module` subclasses as activation:\n        >>> type(parse_activation(nn.ReLU))\n        <class \'torch.nn.modules.activation.ReLU\'>\n\n    Use :class:`torch.nn.Module` instances as activation:\n        >>> type(parse_activation(nn.ReLU()))\n        <class \'torch.nn.modules.activation.ReLU\'>\n\n    """"""\n\n    return _parse(identifier, activation, \'activation\')\n\n\ndef parse_loss(\n    identifier: typing.Union[str, typing.Type[nn.Module], nn.Module],\n    task: typing.Optional[str] = None\n) -> nn.Module:\n    """"""\n    Retrieves a torch Module instance.\n\n    :param identifier: loss identifier, one of\n            - String: name of a loss\n            - Torch Module subclass\n            - Torch Module instance (it will be returned unchanged).\n    :param task: Task type for determining specific loss.\n    :return: A :class:`nn.Module` instance\n\n    Examples::\n        >>> from torch import nn\n        >>> from matchzoo.utils import parse_loss\n\n    Use `str` as loss:\n        >>> loss = parse_loss(\'mse\')\n        >>> type(loss)\n        <class \'torch.nn.modules.loss.MSELoss\'>\n\n    Use :class:`torch.nn.Module` subclasses as loss:\n        >>> type(parse_loss(nn.MSELoss))\n        <class \'torch.nn.modules.loss.MSELoss\'>\n\n    Use :class:`torch.nn.Module` instances as loss:\n        >>> type(parse_loss(nn.MSELoss()))\n        <class \'torch.nn.modules.loss.MSELoss\'>\n\n    """"""\n    return _parse(identifier, loss, \'loss\')\n\n\ndef _parse_metric(\n    metric: typing.Union[str, typing.Type[BaseMetric], BaseMetric],\n    Metrix: typing.Type[BaseMetric]\n) -> BaseMetric:\n    """"""\n    Parse metric.\n\n    :param metrc: Input metric in any form.\n    :param Metrix: Base Metric class. Either\n        :class:`matchzoo.engine.base_metric.RankingMetric` or\n        :class:`matchzoo.engine.base_metric.ClassificationMetric`.\n    :return: A :class:`BaseMetric` instance\n    """"""\n    if isinstance(metric, str):\n        metric = metric.lower()  # ignore case\n        for subclass in Metrix.__subclasses__():\n            if metric == subclass.ALIAS or metric in subclass.ALIAS:\n                return subclass()\n    elif isinstance(metric, Metrix):\n        return metric\n    elif issubclass(metric, Metrix):\n        return metric()\n    raise ValueError(f\'`{metric}` can not be used in current task.\')\n\n\ndef parse_metric(\n    metric: typing.Union[str, typing.Type[BaseMetric], BaseMetric],\n    task: str\n) -> BaseMetric:\n    """"""\n    Parse input metric in any form into a :class:`BaseMetric` instance.\n\n    :param metric: Input metric in any form.\n    :param task: Task type for determining specific metric.\n    :return: A :class:`BaseMetric` instance\n\n    Examples::\n        >>> from matchzoo import metrics\n        >>> from matchzoo.utils import parse_metric\n\n    Use `str` as MatchZoo metrics:\n        >>> mz_metric = parse_metric(\'map\', \'ranking\')\n        >>> type(mz_metric)\n        <class \'matchzoo.metrics.mean_average_precision.MeanAveragePrecision\'>\n\n    Use :class:`matchzoo.engine.BaseMetric` subclasses as MatchZoo metrics:\n        >>> type(parse_metric(metrics.AveragePrecision, \'ranking\'))\n        <class \'matchzoo.metrics.average_precision.AveragePrecision\'>\n\n    Use :class:`matchzoo.engine.BaseMetric` instances as MatchZoo metrics:\n        >>> type(parse_metric(metrics.AveragePrecision(), \'ranking\'))\n        <class \'matchzoo.metrics.average_precision.AveragePrecision\'>\n\n    """"""\n    if task is None:\n        raise ValueError(\n            \'Should specify one `BaseTask`.\'\n        )\n    if task == \'ranking\':\n        return _parse_metric(metric, RankingMetric)\n    if task == \'classification\':\n        return _parse_metric(metric, ClassificationMetric)\n    else:\n        raise ValueError(\n            \'Should be a Ranking or Classification task.\'\n        )\n\n\ndef parse_optimizer(\n    identifier: typing.Union[str, typing.Type[optim.Optimizer]],\n) -> optim.Optimizer:\n    """"""\n    Parse input metric in any form into a :class:`Optimizer` class.\n\n    :param optimizer: Input optimizer in any form.\n    :return: A :class:`Optimizer` class\n\n    Examples::\n        >>> from torch import optim\n        >>> from matchzoo.utils import parse_optimizer\n\n    Use `str` as optimizer:\n        >>> parse_optimizer(\'adam\')\n        <class \'torch.optim.adam.Adam\'>\n\n    Use :class:`torch.optim.Optimizer` subclasses as optimizer:\n        >>> parse_optimizer(optim.Adam)\n        <class \'torch.optim.adam.Adam\'>\n\n    """"""\n    if isinstance(identifier, str):\n        identifier = identifier.lower()  # ignore case\n        if identifier in optimizer:\n            return optimizer[identifier]\n        else:\n            raise ValueError(\n                f\'Could not interpret optimizer identifier: \' + str(identifier)\n            )\n    elif issubclass(identifier, optim.Optimizer):\n        return identifier\n    else:\n        raise ValueError(\n            f\'Could not interpret optimizer identifier: \' + str(identifier)\n        )\n'"
matchzoo/utils/tensor_type.py,0,"b'""""""Define Keras tensor type.""""""\nimport typing\n\nTensorType = typing.Any\n'"
matchzoo/utils/timer.py,0,"b'""""""Timer.""""""\n\nimport time\n\n\nclass Timer(object):\n    """"""Computes elapsed time.""""""\n\n    def __init__(self):\n        """"""Timer constructor.""""""\n        self.reset()\n\n    def reset(self):\n        """"""Reset timer.""""""\n        self.running = True\n        self.total = 0\n        self.start = time.time()\n\n    def resume(self):\n        """"""Resume.""""""\n        if not self.running:\n            self.running = True\n            self.start = time.time()\n        return self\n\n    def stop(self):\n        """"""Stop.""""""\n        if self.running:\n            self.running = False\n            self.total += time.time() - self.start\n        return self\n\n    @property\n    def time(self):\n        """"""Return time.""""""\n        if self.running:\n            return self.total + time.time() - self.start\n        return self.total\n'"
tests/data_pack/test_datapack.py,0,"b""import shutil\n\nimport pandas as pd\nimport pytest\n\nfrom matchzoo import DataPack, load_data_pack\n\n\n@pytest.fixture\ndef data_pack():\n    relation = [['qid0', 'did0', 1], ['qid1', 'did1', 0]]\n    left = [['qid0', [1, 2]], ['qid1', [2, 3]]]\n    right = [['did0', [2, 3, 4]], ['did1', [3, 4, 5]]]\n    relation = pd.DataFrame(relation, columns=['id_left', 'id_right', 'label'])\n    left = pd.DataFrame(left, columns=['id_left', 'text_left'])\n    left.set_index('id_left', inplace=True)\n    right = pd.DataFrame(right, columns=['id_right', 'text_right'])\n    right.set_index('id_right', inplace=True)\n    return DataPack(relation=relation,\n                    left=left,\n                    right=right)\n\n\ndef test_length(data_pack):\n    num_examples = 2\n    assert len(data_pack) == num_examples\n\n\ndef test_getter(data_pack):\n    assert data_pack.relation.iloc[0].values.tolist() == ['qid0', 'did0', 1]\n    assert data_pack.relation.iloc[1].values.tolist() == ['qid1', 'did1', 0]\n    assert data_pack.left.loc['qid0', 'text_left'] == [1, 2]\n    assert data_pack.right.loc['did1', 'text_right'] == [3, 4, 5]\n\n\ndef test_save_load(data_pack):\n    dirpath = '.tmpdir'\n    data_pack.save(dirpath)\n    dp = load_data_pack(dirpath)\n    assert len(data_pack) == 2\n    assert len(dp) == 2\n    shutil.rmtree(dirpath)\n"""
tests/dataloader/test_callbacks.py,0,"b""import pytest\n\nimport matchzoo as mz\nfrom matchzoo import preprocessors\nfrom matchzoo.dataloader import callbacks\nfrom matchzoo.dataloader import Dataset, DataLoader\nfrom matchzoo.datasets import embeddings\nfrom matchzoo.embedding import load_from_file\n\n\n@pytest.fixture(scope='module')\ndef train_raw():\n    return mz.datasets.toy.load_data('test', task='ranking')[:5]\n\n\ndef test_basic_padding(train_raw):\n    preprocessor = preprocessors.BasicPreprocessor()\n    data_preprocessed = preprocessor.fit_transform(train_raw, verbose=0)\n    dataset = Dataset(data_preprocessed, batch_size=5, mode='point')\n\n    pre_fixed_padding = callbacks.BasicPadding(\n        fixed_length_left=5, fixed_length_right=5, pad_word_mode='pre', with_ngram=False)\n    dataloader = DataLoader(dataset, callback=pre_fixed_padding)\n    for batch in dataloader:\n        assert batch[0]['text_left'].shape == (5, 5)\n        assert batch[0]['text_right'].shape == (5, 5)\n\n    post_padding = callbacks.BasicPadding(pad_word_mode='post', with_ngram=False)\n    dataloader = DataLoader(dataset, callback=post_padding)\n    for batch in dataloader:\n        max_left_len = max(batch[0]['length_left'].detach().cpu().numpy())\n        max_right_len = max(batch[0]['length_right'].detach().cpu().numpy())\n        assert batch[0]['text_left'].shape == (5, max_left_len)\n        assert batch[0]['text_right'].shape == (5, max_right_len)\n\n\ndef test_drmm_padding(train_raw):\n    preprocessor = preprocessors.BasicPreprocessor()\n    data_preprocessed = preprocessor.fit_transform(train_raw, verbose=0)\n\n    embedding_matrix = load_from_file(embeddings.EMBED_10_GLOVE, mode='glove')\n    term_index = preprocessor.context['vocab_unit'].state['term_index']\n    embedding_matrix = embedding_matrix.build_matrix(term_index)\n    histgram_callback = callbacks.Histogram(\n        embedding_matrix=embedding_matrix, bin_size=30, hist_mode='LCH')\n    dataset = Dataset(\n        data_preprocessed, mode='point', batch_size=5, callbacks=[histgram_callback])\n\n    pre_fixed_padding = callbacks.DRMMPadding(\n        fixed_length_left=5, fixed_length_right=5, pad_mode='pre')\n    dataloader = DataLoader(dataset, callback=pre_fixed_padding)\n    for batch in dataloader:\n        assert batch[0]['text_left'].shape == (5, 5)\n        assert batch[0]['text_right'].shape == (5, 5)\n        assert batch[0]['match_histogram'].shape == (5, 5, 30)\n\n    post_padding = callbacks.DRMMPadding(pad_mode='post')\n    dataloader = DataLoader(dataset, callback=post_padding)\n    for batch in dataloader:\n        max_left_len = max(batch[0]['length_left'].detach().cpu().numpy())\n        max_right_len = max(batch[0]['length_right'].detach().cpu().numpy())\n        assert batch[0]['text_left'].shape == (5, max_left_len)\n        assert batch[0]['text_right'].shape == (5, max_right_len)\n        assert batch[0]['match_histogram'].shape == (5, max_left_len, 30)\n\n\ndef test_bert_padding(train_raw):\n    preprocessor = preprocessors.BertPreprocessor()\n    data_preprocessed = preprocessor.transform(train_raw, verbose=0)\n    dataset = Dataset(data_preprocessed, mode='point', batch_size=5)\n\n    pre_fixed_padding = callbacks.BertPadding(\n        fixed_length_left=5, fixed_length_right=5, pad_mode='pre')\n    dataloader = DataLoader(dataset, callback=pre_fixed_padding)\n    for batch in dataloader:\n        assert batch[0]['text_left'].shape == (5, 7)\n        assert batch[0]['text_right'].shape == (5, 6)\n\n    post_padding = callbacks.BertPadding(pad_mode='post')\n    dataloader = DataLoader(dataset, callback=post_padding)\n    for batch in dataloader:\n        max_left_len = max(batch[0]['length_left'].detach().cpu().numpy())\n        max_right_len = max(batch[0]['length_right'].detach().cpu().numpy())\n        assert batch[0]['text_left'].shape == (5, max_left_len + 2)\n        assert batch[0]['text_right'].shape == (5, max_right_len + 1)\n"""
tests/dataloader/test_dataset.py,0,"b""import matchzoo as mz\nfrom matchzoo import preprocessors\nfrom matchzoo.dataloader import Dataset\n\n\ndef test_dataset():\n    data_pack = mz.datasets.toy.load_data('train', task='ranking')\n    preprocessor = mz.preprocessors.BasicPreprocessor()\n    data_processed = preprocessor.fit_transform(data_pack)\n\n    dataset_point = mz.dataloader.Dataset(\n        data_processed,\n        mode='point',\n        batch_size=1,\n        resample=False,\n        shuffle=True,\n        sort=False\n    )\n    dataset_point.batch_size = 10\n    dataset_point.shuffle = not dataset_point.shuffle\n    dataset_point.sort = not dataset_point.sort\n    assert len(dataset_point.batch_indices) == 10\n\n    dataset_pair = mz.dataloader.Dataset(\n        data_processed,\n        mode='pair',\n        num_dup=1,\n        num_neg=1,\n        batch_size=1,\n        resample=True,\n        shuffle=False,\n        sort=False\n    )\n    assert len(dataset_pair) == 5\n    dataset_pair.num_dup = dataset_pair.num_dup + 1\n    assert len(dataset_pair) == 10\n    dataset_pair.num_neg = dataset_pair.num_neg + 2\n    assert len(dataset_pair) == 10\n    dataset_pair.batch_size = dataset_pair.batch_size + 1\n    assert len(dataset_pair) == 5\n    dataset_pair.resample = not dataset_pair.resample\n    assert len(dataset_pair) == 5\n"""
tests/engine/test_base_preprocessor.py,0,"b""import pytest\nimport shutil\n\nimport matchzoo as mz\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\n\n\n@pytest.fixture\ndef base_preprocessor():\n    BasePreprocessor.__abstractmethods__ = set()\n    base_processor = BasePreprocessor()\n    return base_processor\n\n\ndef test_save_load(base_preprocessor):\n    dirpath = '.tmpdir'\n    base_preprocessor.save(dirpath)\n    assert mz.load_preprocessor(dirpath)\n    shutil.rmtree(dirpath)\n"""
tests/engine/test_base_task.py,0,b'import pytest\nfrom matchzoo.engine.base_task import BaseTask\n\n\ndef test_base_task_instantiation():\n    with pytest.raises(TypeError):\n        BaseTask()\n'
tests/engine/test_hyper_spaces.py,0,"b""import pytest\nimport hyperopt.pyll.base\n\nfrom matchzoo.engine import hyper_spaces\n\n\n@pytest.fixture(scope='module', params=[\n    lambda x: x + 2,\n    lambda x: x - 2,\n    lambda x: x * 2,\n    lambda x: x / 2,\n    lambda x: x // 2,\n    lambda x: x ** 2,\n    lambda x: 2 + x,\n    lambda x: 2 - x,\n    lambda x: 2 * x,\n    lambda x: 2 / x,\n    lambda x: 2 // x,\n    lambda x: 2 ** x,\n    lambda x: -x\n])\ndef op(request):\n    return request.param\n\n\n@pytest.fixture(scope='module', params=[\n    hyper_spaces.choice(options=[0, 1]),\n    hyper_spaces.uniform(low=0, high=10),\n    hyper_spaces.quniform(low=0, high=10, q=2)\n])\ndef proxy(request):\n    return request.param\n\n\ndef test_init(proxy):\n    assert isinstance(proxy.convert('label'), hyperopt.pyll.base.Apply)\n\n\ndef test_op(proxy, op):\n    assert isinstance(op(proxy).convert('label'), hyperopt.pyll.base.Apply)\n\n\ndef test_str(proxy):\n    assert isinstance(str(proxy), str)\n"""
tests/engine/test_param_table.py,0,"b""import pytest\n\nfrom matchzoo.engine.param import Param\nfrom matchzoo.engine.param_table import ParamTable\nfrom matchzoo.engine.hyper_spaces import quniform\n\n\n@pytest.fixture\ndef param_table():\n    params = ParamTable()\n    params.add(Param('ham', 'Parma Ham'))\n    return params\n\n\ndef test_get(param_table):\n    assert param_table['ham'] == 'Parma Ham'\n\n\ndef test_set(param_table):\n    new_param = Param('egg', 'Over Easy')\n    param_table.set('egg', new_param)\n    assert 'egg' in param_table.keys()\n\n\ndef test_keys(param_table):\n    assert 'ham' in param_table.keys()\n\n\ndef test_hyper_space(param_table):\n    new_param = Param(\n        name='my_param',\n        value=1,\n        hyper_space=quniform(low=1, high=5)\n    )\n    param_table.add(new_param)\n    hyper_space = param_table.hyper_space\n    assert hyper_space\n"""
tests/models/test_base_model.py,0,"b""import pytest\n\nfrom matchzoo.engine.base_model import BaseModel\n\n\ndef test_base_model_abstract_instantiation():\n    with pytest.raises(TypeError):\n        model = BaseModel(BaseModel.get_default_params())\n        assert model\n\n\ndef test_base_model_concrete_instantiation():\n    class MyBaseModel(BaseModel):\n        def build(self):\n            self.a, self.b = 1, 2\n        def forward(self):\n            return self.a + self.b\n\n    model = MyBaseModel()\n    assert model.params\n    model.guess_and_fill_missing_params()\n    model.build()\n    assert model.params.completed(exclude=['out_activation_func'])\n"""
tests/models/test_models.py,1,"b'""""""\nThese tests are simplied because the original verion takes too much time to\nrun, making CI fails as it reaches the time limit.\n""""""\nimport torch\nimport pytest\nfrom pathlib import Path\nimport shutil\n\nimport matchzoo as mz\n\n\n@pytest.fixture(scope=\'module\', params=[\n    mz.tasks.Ranking(losses=mz.losses.RankCrossEntropyLoss(num_neg=2)),\n    mz.tasks.Classification(num_classes=2),\n])\ndef task(request):\n    return request.param\n\n\n@pytest.fixture(scope=\'module\')\ndef train_raw(task):\n    return mz.datasets.toy.load_data(\'train\', task)[:10]\n\n\n@pytest.fixture(scope=\'module\', params=mz.models.list_available())\ndef model_class(request):\n    return request.param\n\n\n@pytest.fixture(scope=\'module\')\ndef embedding():\n    return mz.datasets.toy.load_embedding()\n\n\n@pytest.fixture(scope=\'module\')\ndef setup(task, model_class, train_raw, embedding):\n    return mz.auto.prepare(\n        task=task,\n        model_class=model_class,\n        data_pack=train_raw,\n        embedding=embedding\n    )\n\n\n@pytest.fixture(scope=\'module\')\ndef model(setup):\n    return setup[0]\n\n\n@pytest.fixture(scope=\'module\')\ndef preprocessor(setup):\n    return setup[1]\n\n\n@pytest.fixture(scope=\'module\')\ndef dataset_builder(setup):\n    return setup[2]\n\n\n@pytest.fixture(scope=\'module\')\ndef dataloader_builder(setup):\n    return setup[3]\n\n\n@pytest.fixture(scope=\'module\')\ndef dataloader(train_raw, preprocessor, dataset_builder, dataloader_builder):\n    return dataloader_builder.build(\n        dataset_builder.build(preprocessor.transform(train_raw)))\n\n\n@pytest.fixture(scope=\'module\')\ndef optimizer(model):\n    return torch.optim.Adam(model.parameters())\n\n\n@pytest.fixture(scope=\'module\')\ndef save_dir():\n    return Path(\'.matchzoo_test_save_load_tmpdir\')\n\n\n@pytest.mark.slow\ndef test_model_fit_eval_predict(model, optimizer, dataloader, save_dir):\n    trainer = mz.trainers.Trainer(\n        model=model,\n        optimizer=optimizer,\n        trainloader=dataloader,\n        validloader=dataloader,\n        epochs=2,\n        save_dir=save_dir,\n        verbose=0\n    )\n    trainer.run()\n\n    if save_dir.exists():\n        shutil.rmtree(save_dir)\n'"
tests/modules/test_modules.py,3,"b""import torch\nimport pytest\n\nfrom matchzoo.modules import Matching\n\n\ndef test_matching():\n    x = torch.randn(2, 3, 2)\n    y = torch.randn(2, 4, 2)\n    z = torch.randn(2, 3, 3)\n    for matching_type in ['dot', 'mul', 'plus', 'minus', 'concat']:\n        Matching(matching_type=matching_type)(x, y)\n    with pytest.raises(ValueError):\n        Matching(matching_type='error')\n    with pytest.raises(RuntimeError):\n        Matching()(x, z)\n"""
tests/tasks/test_tasks.py,0,"b'import pytest\n\nfrom matchzoo import tasks\n\n\n@pytest.mark.parametrize(""task_type"", [\n    tasks.Ranking, tasks.Classification\n])\ndef test_task_listings(task_type):\n    assert task_type.list_available_losses()\n    assert task_type.list_available_metrics()\n\n\n@pytest.mark.parametrize(""arg"", [None, -1, 0, 1])\ndef test_classification_instantiation_failure(arg):\n    with pytest.raises(Exception):\n        tasks.Classification(num_classes=arg)\n\n\n@pytest.mark.parametrize(""arg"", [2, 10, 2048])\ndef test_classification_num_classes(arg):\n    task = tasks.Classification(num_classes=arg)\n    assert task.num_classes == arg\n'"
tests/trainer/test_trainer.py,2,"b""import torch\nimport pytest\nfrom pathlib import Path\nimport shutil\n\nimport matchzoo as mz\n\n\n@pytest.fixture(scope='module')\ndef task():\n    return mz.tasks.Ranking(losses=mz.losses.RankCrossEntropyLoss())\n\n\n@pytest.fixture(scope='module')\ndef train_raw(task):\n    return mz.datasets.toy.load_data('train', task)[:10]\n\n\n@pytest.fixture(scope='module')\ndef model_class():\n    return mz.models.DenseBaseline\n\n\n@pytest.fixture(scope='module')\ndef embedding():\n    return mz.datasets.toy.load_embedding()\n\n\n@pytest.fixture(scope='module')\ndef setup(task, model_class, train_raw, embedding):\n    return mz.auto.prepare(\n        task=task,\n        model_class=model_class,\n        data_pack=train_raw,\n        embedding=embedding\n    )\n\n\n@pytest.fixture(scope='module')\ndef model(setup):\n    return setup[0]\n\n\n@pytest.fixture(scope='module')\ndef preprocessor(setup):\n    return setup[1]\n\n\n@pytest.fixture(scope='module')\ndef dataset_builder(setup):\n    return setup[2]\n\n\n@pytest.fixture(scope='module')\ndef dataloader_builder(setup):\n    return setup[3]\n\n\n@pytest.fixture(scope='module')\ndef dataloader(train_raw, preprocessor, dataset_builder, dataloader_builder):\n    return dataloader_builder.build(\n        dataset_builder.build(preprocessor.transform(train_raw)))\n\n\n@pytest.fixture(scope='module')\ndef optimizer(model):\n    return torch.optim.Adam(model.parameters())\n\n\n@pytest.fixture(scope='module')\ndef scheduler(optimizer):\n    return torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)\n\n\n@pytest.fixture(scope='module')\ndef save_dir():\n    return Path('.matchzoo_test_save_load_tmpdir')\n\n\n@pytest.fixture(scope='module')\ndef trainer(\n    model, optimizer, dataloader, scheduler, save_dir\n):\n    return mz.trainers.Trainer(\n        model=model,\n        optimizer=optimizer,\n        trainloader=dataloader,\n        validloader=dataloader,\n        epochs=4,\n        validate_interval=2,\n        patience=1,\n        scheduler=scheduler,\n        clip_norm=10,\n        save_dir=save_dir,\n        save_all=True,\n        verbose=1,\n    )\n\n\n@pytest.mark.slow\ndef test_trainer(trainer, dataloader, save_dir):\n    trainer.run()\n    assert trainer.evaluate(dataloader)\n    assert trainer.predict(dataloader) is not None\n\n    # Save model\n    model_checkpoint = save_dir.joinpath('model.pt')\n    trainer.save_model()\n    trainer.restore_model(model_checkpoint)\n\n    # Save model\n    trainer_checkpoint = save_dir.joinpath('trainer.pt')\n    trainer.save()\n    trainer.restore(trainer_checkpoint)\n\n    if save_dir.exists():\n        shutil.rmtree(save_dir)\n"""
matchzoo/auto/preparer/__init__.py,0,b'from .preparer import Preparer\nfrom .prepare import prepare\n'
matchzoo/auto/preparer/prepare.py,0,"b'import typing\n\nimport matchzoo as mz\nfrom .preparer import Preparer\nfrom matchzoo.engine.base_task import BaseTask\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\n\n\ndef prepare(\n    task: BaseTask,\n    model_class: typing.Type[BaseModel],\n    data_pack: mz.DataPack,\n    callback: typing.Optional[BaseCallback] = None,\n    preprocessor: typing.Optional[BasePreprocessor] = None,\n    embedding: typing.Optional[\'mz.Embedding\'] = None,\n    config: typing.Optional[dict] = None,\n):\n    """"""\n    A simple shorthand for using :class:`matchzoo.Preparer`.\n\n    `config` is used to control specific behaviors. The default `config`\n    will be updated accordingly if a `config` dictionary is passed. e.g. to\n    override the default `bin_size`, pass `config={\'bin_size\': 15}`.\n\n    :param task: Task.\n    :param model_class: Model class.\n    :param data_pack: DataPack used to fit the preprocessor.\n    :param callback: Callback used to padding a batch.\n        (default: the default callback of `model_class`)\n    :param preprocessor: Preprocessor used to fit the `data_pack`.\n        (default: the default preprocessor of `model_class`)\n    :param embedding: Embedding to build a embedding matrix. If not set,\n        then a correctly shaped randomized matrix will be built.\n    :param config: Configuration of specific behaviors. (default: return\n        value of `mz.Preparer.get_default_config()`)\n\n    :return: A tuple of `(model, preprocessor, data_generator_builder,\n        embedding_matrix)`.\n\n    """"""\n    preparer = Preparer(task=task, config=config)\n    return preparer.prepare(\n        model_class=model_class,\n        data_pack=data_pack,\n        callback=callback,\n        preprocessor=preprocessor,\n        embedding=embedding\n    )\n'"
matchzoo/auto/preparer/preparer.py,0,"b'import typing\n\nimport numpy as np\n\nimport matchzoo as mz\nfrom matchzoo.engine.base_task import BaseTask\nfrom matchzoo.engine.base_model import BaseModel\nfrom matchzoo.engine.base_callback import BaseCallback\nfrom matchzoo.engine.base_preprocessor import BasePreprocessor\nfrom matchzoo.dataloader import DatasetBuilder\nfrom matchzoo.dataloader import DataLoaderBuilder\n\n\nclass Preparer(object):\n    """"""\n    Unified setup processes of all MatchZoo models.\n\n    `config` is used to control specific behaviors. The default `config`\n    will be updated accordingly if a `config` dictionary is passed. e.g. to\n    override the default `bin_size`, pass `config={\'bin_size\': 15}`.\n\n    See `tutorials/automation.ipynb` for a detailed walkthrough on usage.\n\n    Default `config`:\n\n    {\n        # pair generator builder kwargs\n        \'num_dup\': 1,\n\n        # histogram unit of DRMM\n        \'bin_size\': 30,\n        \'hist_mode\': \'LCH\',\n\n        # dynamic Pooling of MatchPyramid\n        \'compress_ratio_left\': 1.0,\n        \'compress_ratio_right\': 1.0,\n\n        # if no `matchzoo.Embedding` is passed to `tune`\n        \'embedding_output_dim\': 50\n    }\n\n    :param task: Task.\n    :param config: Configuration of specific behaviors.\n\n    Example:\n        >>> import matchzoo as mz\n        >>> task = mz.tasks.Ranking(losses=mz.losses.RankCrossEntropyLoss())\n        >>> preparer = mz.auto.Preparer(task)\n        >>> model_class = mz.models.DenseBaseline\n        >>> train_raw = mz.datasets.toy.load_data(\'train\', \'ranking\')\n        >>> model, prpr, dsb, dlb = preparer.prepare(model_class,\n        ...                                          train_raw)\n        >>> model.params.completed(exclude=[\'out_activation_func\'])\n        True\n\n    """"""\n\n    def __init__(\n        self,\n        task: BaseTask,\n        config: typing.Optional[dict] = None\n    ):\n        """"""Init.""""""\n        self._task = task\n        self._config = self.get_default_config()\n        if config:\n            self._config.update(config)\n\n        self._infer_num_neg()\n\n    def prepare(\n        self,\n        model_class: typing.Type[BaseModel],\n        data_pack: mz.DataPack,\n        callback: typing.Optional[BaseCallback] = None,\n        preprocessor: typing.Optional[BasePreprocessor] = None,\n        embedding: typing.Optional[\'mz.Embedding\'] = None,\n    ) -> typing.Tuple[\n        BaseModel,\n        BasePreprocessor,\n        DatasetBuilder,\n        DataLoaderBuilder,\n    ]:\n        """"""\n        Prepare.\n\n        :param model_class: Model class.\n        :param data_pack: DataPack used to fit the preprocessor.\n        :param callback: Callback used to padding a batch.\n            (default: the default callback of `model_class`)\n        :param preprocessor: Preprocessor used to fit the `data_pack`.\n            (default: the default preprocessor of `model_class`)\n\n        :return: A tuple of `(model, preprocessor, dataset_builder,\n            dataloader_builder)`.\n\n        """"""\n        if not callback:\n            callback = model_class.get_default_padding_callback()\n        if not preprocessor:\n            preprocessor = model_class.get_default_preprocessor()\n\n        preprocessor.fit(data_pack, verbose=0)\n\n        model, embedding_matrix = self._build_model(\n            model_class,\n            preprocessor,\n            embedding\n        )\n\n        dataset_builder = self._build_dataset_builder(\n            model,\n            embedding_matrix,\n            preprocessor\n        )\n\n        dataloader_builder = self._build_dataloader_builder(\n            model,\n            callback\n        )\n\n        return (\n            model,\n            preprocessor,\n            dataset_builder,\n            dataloader_builder\n        )\n\n    def _build_model(\n        self,\n        model_class,\n        preprocessor,\n        embedding\n    ) -> typing.Tuple[BaseModel, np.ndarray]:\n\n        model = model_class()\n        model.params[\'task\'] = self._task\n\n        if \'with_embedding\' in model.params:\n            embedding_matrix = self._build_matrix(preprocessor, embedding)\n            model.params[\'embedding\'] = embedding_matrix\n        else:\n            embedding_matrix = None\n\n        model.build()\n\n        return model, embedding_matrix\n\n    def _build_matrix(self, preprocessor, embedding):\n        if embedding is not None:\n            vocab_unit = preprocessor.context[\'vocab_unit\']\n            term_index = vocab_unit.state[\'term_index\']\n            return embedding.build_matrix(term_index)\n        else:\n            matrix_shape = (\n                preprocessor.context[\'vocab_size\'],\n                self._config[\'embedding_output_dim\']\n            )\n            return np.random.uniform(-0.2, 0.2, matrix_shape)\n\n    def _build_dataset_builder(self, model, embedding_matrix, preprocessor):\n        builder_kwargs = dict(\n            callbacks=[],\n            batch_size=self._config[\'batch_size\'],\n            shuffle=self._config[\'shuffle\'],\n            sort=self._config[\'sort\']\n        )\n\n        if isinstance(self._task.losses[0], (mz.losses.RankHingeLoss,\n                                             mz.losses.RankCrossEntropyLoss)):\n            builder_kwargs.update(dict(\n                mode=\'pair\',\n                num_dup=self._config[\'num_dup\'],\n                num_neg=self._config[\'num_neg\'],\n                resample=self._config[\'resample\'],\n            ))\n\n        if isinstance(model, mz.models.CDSSM):\n            triletter_callback = mz.dataloader.callbacks.Ngram(\n                preprocessor, mode=\'sum\')\n            builder_kwargs[\'callbacks\'].append(triletter_callback)\n\n        if isinstance(model, mz.models.DSSM):\n            triletter_callback = mz.dataloader.callbacks.Ngram(\n                preprocessor, mode=\'aggregate\')\n            builder_kwargs[\'callbacks\'].append(triletter_callback)\n\n        if isinstance(model, mz.models.DUET):\n            triletter_callback = mz.dataloader.callbacks.Ngram(\n                preprocessor, mode=\'sum\')\n            builder_kwargs[\'callbacks\'].append(triletter_callback)\n\n        if isinstance(model, mz.models.DIIN):\n            letter_callback = mz.dataloader.callbacks.Ngram(\n                preprocessor, mode=\'index\')\n            builder_kwargs[\'callbacks\'].append(letter_callback)\n\n        if isinstance(model, mz.models.DRMM):\n            histo_callback = mz.dataloader.callbacks.Histogram(\n                embedding_matrix=embedding_matrix,\n                bin_size=self._config[\'bin_size\'],\n                hist_mode=self._config[\'hist_mode\']\n            )\n            builder_kwargs[\'callbacks\'].append(histo_callback)\n\n        return DatasetBuilder(**builder_kwargs)\n\n    def _build_dataloader_builder(self, model, callback):\n        builder_kwargs = dict(\n            stage=self._config[\'stage\'],\n            callback=callback\n        )\n        return DataLoaderBuilder(**builder_kwargs)\n\n    def _infer_num_neg(self):\n        if isinstance(self._task.losses[0], (mz.losses.RankHingeLoss,\n                                             mz.losses.RankCrossEntropyLoss)):\n            self._config[\'num_neg\'] = self._task.losses[0].num_neg\n\n    @classmethod\n    def get_default_config(cls) -> dict:\n        """"""Default config getter.""""""\n        return {\n            # pair dataset builder kwargs\n            \'num_dup\': 1,\n\n            # dataloader builder kwargs\n            \'batch_size\': 8,\n            \'stage\': \'train\',\n            \'resample\': True,\n            \'shuffle\': False,\n            \'sort\': True,\n\n            # histogram unit of DRMM\n            \'bin_size\': 30,\n            \'hist_mode\': \'LCH\',\n\n            # dynamic Pooling of MatchPyramid\n            \'compress_ratio_left\': 1.0,\n            \'compress_ratio_right\': 1.0,\n\n            # if no `matchzoo.Embedding` is passed to `tune`\n            \'embedding_output_dim\': 100\n        }\n'"
matchzoo/auto/tuner/__init__.py,0,b'from .tuner import Tuner\nfrom .tune import tune\n'
matchzoo/auto/tuner/tune.py,0,"b'import typing\n\nimport numpy as np\n\nimport matchzoo as mz\nfrom matchzoo.engine.base_metric import BaseMetric\nfrom .tuner import Tuner\n\n\ndef tune(\n    params: \'mz.ParamTable\',\n    optimizer: str = \'adam\',\n    trainloader: mz.dataloader.DataLoader = None,\n    validloader: mz.dataloader.DataLoader = None,\n    embedding: np.ndarray = None,\n    fit_kwargs: dict = None,\n    metric: typing.Union[str, BaseMetric] = None,\n    mode: str = \'maximize\',\n    num_runs: int = 10,\n    verbose=1\n):\n    """"""\n    Tune model hyper-parameters.\n\n    A simple shorthand for using :class:`matchzoo.auto.Tuner`.\n\n    `model.params.hyper_space` reprensents the model\'s hyper-parameters\n    search space, which is the cross-product of individual hyper parameter\'s\n    hyper space. When a `Tuner` builds a model, for each hyper parameter in\n    `model.params`, if the hyper-parameter has a hyper-space, then a sample\n    will be taken in the space. However, if the hyper-parameter does not\n    have a hyper-space, then the default value of the hyper-parameter will\n    be used.\n\n    See `tutorials/model_tuning.ipynb` for a detailed walkthrough on usage.\n\n    :param params: A completed parameter table to tune. Usually `model.params`\n        of the desired model to tune. `params.completed()` should be `True`.\n    :param optimizer: Str or `Optimizer` class. Optimizer for optimizing model.\n    :param trainloader: Training data to use. Should be a `DataLoader`.\n    :param validloader: Testing data to use. Should be a `DataLoader`.\n    :param embedding: Embedding used by model.\n    :param fit_kwargs: Extra keyword arguments to pass to `fit`.\n        (default: `dict(epochs=10, verbose=0)`)\n    :param metric: Metric to tune upon. Must be one of the metrics in\n        `model.params[\'task\'].metrics`. (default: the first metric in\n        `params.[\'task\'].metrics`.\n    :param mode: Either `maximize` the metric or `minimize` the metric.\n        (default: \'maximize\')\n    :param num_runs: Number of runs. Each run takes a sample in\n        `params.hyper_space` and build a model based on the sample.\n        (default: 10)\n    :param callbacks: A list of callbacks to handle. Handled sequentially\n        at every callback point.\n    :param verbose: Verbosity. (default: 1)\n\n    Example:\n        >>> import matchzoo as mz\n        >>> import numpy as np\n        >>> train = mz.datasets.toy.load_data(\'train\')\n        >>> valid = mz.datasets.toy.load_data(\'dev\')\n        >>> prpr = mz.models.DenseBaseline.get_default_preprocessor()\n        >>> train = prpr.fit_transform(train, verbose=0)\n        >>> valid = prpr.transform(valid, verbose=0)\n        >>> trainset = mz.dataloader.Dataset(train)\n        >>> validset = mz.dataloader.Dataset(valid)\n        >>> padding = mz.models.DenseBaseline.get_default_padding_callback()\n        >>> trainloader = mz.dataloader.DataLoader(trainset, callback=padding)\n        >>> validloader = mz.dataloader.DataLoader(validset, callback=padding)\n        >>> model = mz.models.DenseBaseline()\n        >>> model.params[\'task\'] = mz.tasks.Ranking()\n        >>> optimizer = \'adam\'\n        >>> embedding = np.random.uniform(-0.2, 0.2,\n        ...     (prpr.context[\'vocab_size\'], 100))\n        >>> tuner = mz.auto.Tuner(\n        ...     params=model.params,\n        ...     optimizer=optimizer,\n        ...     trainloader=trainloader,\n        ...     validloader=validloader,\n        ...     embedding=embedding,\n        ...     num_runs=1,\n        ...     verbose=0\n        ... )\n        >>> results = tuner.tune()\n        >>> sorted(results[\'best\'].keys())\n        [\'#\', \'params\', \'sample\', \'score\']\n\n    """"""\n\n    tuner = Tuner(\n        params=params,\n        optimizer=optimizer,\n        trainloader=trainloader,\n        validloader=validloader,\n        embedding=embedding,\n        fit_kwargs=fit_kwargs,\n        metric=metric,\n        mode=mode,\n        num_runs=num_runs,\n        verbose=verbose\n    )\n    return tuner.tune()\n'"
matchzoo/auto/tuner/tuner.py,1,"b'import copy\nimport typing\nimport logging\n\nimport torch\nimport hyperopt\nimport numpy as np\n\nimport matchzoo as mz\nfrom matchzoo.engine.base_metric import BaseMetric\nfrom matchzoo.utils import parse_optimizer\n\n\nclass Tuner(object):\n    """"""\n    Model hyper-parameters tuner.\n\n    `model.params.hyper_space` reprensents the model\'s hyper-parameters\n    search space, which is the cross-product of individual hyper parameter\'s\n    hyper space. When a `Tuner` builds a model, for each hyper parameter in\n    `model.params`, if the hyper-parameter has a hyper-space, then a sample\n    will be taken in the space. However, if the hyper-parameter does not\n    have a hyper-space, then the default value of the hyper-parameter will\n    be used.\n\n    See `tutorials/model_tuning.ipynb` for a detailed walkthrough on usage.\n\n    :param params: A completed parameter table to tune. Usually `model.params`\n        of the desired model to tune. `params.completed()` should be `True`.\n    :param optimizer: Str or `Optimizer` class. Optimizer for optimizing model.\n    :param trainloader: Training data to use. Should be a `DataLoader`.\n    :param validloader: Testing data to use. Should be a `DataLoader`.\n    :param embedding: Embedding used by model.\n    :param fit_kwargs: Extra keyword arguments to pass to `fit`.\n        (default: `dict(epochs=10, verbose=0)`)\n    :param metric: Metric to tune upon. Must be one of the metrics in\n        `model.params[\'task\'].metrics`. (default: the first metric in\n        `params.[\'task\'].metrics`.\n    :param mode: Either `maximize` the metric or `minimize` the metric.\n        (default: \'maximize\')\n    :param num_runs: Number of runs. Each run takes a sample in\n        `params.hyper_space` and build a model based on the sample.\n        (default: 10)\n    :param verbose: Verbosity. (default: 1)\n\n    """"""\n\n    def __init__(\n        self,\n        params: \'mz.ParamTable\',\n        optimizer: str = \'adam\',\n        trainloader: mz.dataloader.DataLoader = None,\n        validloader: mz.dataloader.DataLoader = None,\n        embedding: np.ndarray = None,\n        fit_kwargs: dict = None,\n        metric: typing.Union[str, BaseMetric] = None,\n        mode: str = \'maximize\',\n        num_runs: int = 10,\n        verbose=1\n    ):\n        """"""Tuner.""""""\n        if fit_kwargs is None:\n            fit_kwargs = dict(epochs=5, verbose=0)\n\n        if \'with_embedding\' in params:\n            params[\'embedding\'] = embedding\n            params[\'embedding_input_dim\'] = embedding.shape[0]\n            params[\'embedding_output_dim\'] = embedding.shape[1]\n        self._validate_params(params)\n\n        metric = metric or params[\'task\'].metrics[0]\n        self._validate_optimizer(optimizer)\n        self._validate_dataloader(trainloader)\n        self._validate_dataloader(validloader)\n        self._validate_kwargs(fit_kwargs)\n        self._validate_mode(mode)\n        self._validate_metric(params, metric)\n\n        self.__curr_run_num = 0\n\n        # these variables should not change within the same `tune` call\n        self._params = params\n        self._optimizer = parse_optimizer(optimizer)\n        self._trainloader = trainloader\n        self._validloader = validloader\n        self._embedding = embedding\n        self._fit_kwargs = fit_kwargs\n        self._metric = metric\n        self._mode = mode\n        self._num_runs = num_runs\n        self._verbose = verbose\n\n    def tune(self):\n        """"""\n        Start tuning.\n\n        Notice that `tune` does not affect the tuner\'s inner state, so each\n        new call to `tune` starts fresh. In other words, hyperspaces are\n        suggestive only within the same `tune` call.\n        """"""\n        if self.__curr_run_num != 0:\n            print(\n                """"""WARNING: `tune` does not affect the tuner\'s inner state, so\n                each new call to `tune` starts fresh. In other words,\n                hyperspaces are suggestive only within the same `tune` call.""""""\n            )\n        self.__curr_run_num = 0\n        logging.getLogger(\'hyperopt\').setLevel(logging.CRITICAL)\n\n        trials = hyperopt.Trials()\n\n        self._fmin(trials)\n\n        return {\n            \'best\': trials.best_trial[\'result\'][\'mz_result\'],\n            \'trials\': [trial[\'result\'][\'mz_result\'] for trial in trials.trials]\n        }\n\n    def _fmin(self, trials):\n        # new version of hyperopt has keyword argument `show_progressbar` that\n        # breaks doctests, so here\'s a workaround\n        fmin_kwargs = dict(\n            fn=self._run,\n            space=self._params.hyper_space,\n            algo=hyperopt.tpe.suggest,\n            max_evals=self._num_runs,\n            trials=trials\n        )\n        try:\n            hyperopt.fmin(\n                **fmin_kwargs,\n                show_progressbar=False\n            )\n        except TypeError:\n            hyperopt.fmin(**fmin_kwargs)\n\n    def _run(self, sample):\n        self.__curr_run_num += 1\n\n        # build model\n        params = self._create_full_params(sample)\n        model = params[\'model_class\'](params=params)\n        model.build()\n\n        trainer = mz.trainers.Trainer(\n            model=model,\n            optimizer=self._optimizer(model.parameters()),\n            trainloader=self._trainloader,\n            validloader=self._validloader,\n            **self._fit_kwargs,\n        )\n\n        # fit & evaluate\n        trainer.run()\n\n        lookup = trainer.evaluate(self._validloader)\n        score = lookup[self._metric]\n\n        # collect result\n        # this result is for users, visible outside\n        mz_result = {\n            \'#\': self.__curr_run_num,\n            \'params\': params,\n            \'sample\': sample,\n            \'score\': score\n        }\n\n        if self._verbose:\n            self._log_result(mz_result)\n\n        return {\n            # these two items are for hyperopt\n            \'loss\': self._fix_loss_sign(score),\n            \'status\': hyperopt.STATUS_OK,\n\n            # this item is for storing matchzoo information\n            \'mz_result\': mz_result\n        }\n\n    def _create_full_params(self, sample):\n        params = copy.deepcopy(self._params)\n        params.update(sample)\n        return params\n\n    def _fix_loss_sign(self, loss):\n        if self._mode == \'maximize\':\n            loss = -loss\n        return loss\n\n    @classmethod\n    def _log_result(cls, result):\n        print(f""Run #{result[\'#\']}"")\n        print(f""Score: {result[\'score\']}"")\n        print(result[\'params\'])\n        print()\n\n    @property\n    def params(self):\n        """"""`params` getter.""""""\n        return self._params\n\n    @params.setter\n    def params(self, value):\n        """"""`params` setter.""""""\n        self._validate_params(value)\n        self._validate_metric(value, self._metric)\n        self._params = value\n\n    @property\n    def trainloader(self):\n        """"""`trainloader` getter.""""""\n        return self._trainloader\n\n    @trainloader.setter\n    def trainloader(self, value):\n        """"""`trainloader` setter.""""""\n        self._validate_dataloader(value)\n        self._trainloader = value\n\n    @property\n    def validloader(self):\n        """"""`validloader` getter.""""""\n        return self._validloader\n\n    @validloader.setter\n    def validloader(self, value):\n        """"""`validloader` setter.""""""\n        self._validate_dataloader(value)\n        self._validloader = value\n\n    @property\n    def fit_kwargs(self):\n        """"""`fit_kwargs` getter.""""""\n        return self._fit_kwargs\n\n    @fit_kwargs.setter\n    def fit_kwargs(self, value):\n        """"""`fit_kwargs` setter.""""""\n        self._validate_kwargs(value)\n        self._fit_kwargs = value\n\n    @property\n    def metric(self):\n        """"""`metric` getter.""""""\n        return self._metric\n\n    @metric.setter\n    def metric(self, value):\n        """"""`metric` setter.""""""\n        self._validate_metric(self._params, value)\n        self._metric = value\n\n    @property\n    def mode(self):\n        """"""`mode` getter.""""""\n        return self._mode\n\n    @mode.setter\n    def mode(self, value):\n        """"""`mode` setter.""""""\n        self._validate_mode(value)\n        self._mode = value\n\n    @property\n    def num_runs(self):\n        """"""`num_runs` getter.""""""\n        return self._num_runs\n\n    @num_runs.setter\n    def num_runs(self, value):\n        """"""`num_runs` setter.""""""\n        self._validate_num_runs(value)\n        self._num_runs = value\n\n    @property\n    def verbose(self):\n        """"""`verbose` getter.""""""\n        return self._verbose\n\n    @verbose.setter\n    def verbose(self, value):\n        """"""`verbose` setter.""""""\n        self._verbose = value\n\n    @classmethod\n    def _validate_params(cls, params):\n        if not isinstance(params, mz.ParamTable):\n            raise TypeError(""Only accepts a `ParamTable` instance."")\n        if not params.hyper_space:\n            raise ValueError(""Parameter hyper-space empty."")\n        if not params.completed(exclude=[\'out_activation_func\']):\n            raise ValueError(""Parameters not complete."")\n\n    @classmethod\n    def _validate_optimizer(cls, optimizer):\n        if not isinstance(optimizer, (str, torch.optim.Optimizer)):\n            raise TypeError(\n                ""Only accepts a `Optimizer` instance."")\n\n    @classmethod\n    def _validate_dataloader(cls, data):\n        if not isinstance(data, mz.dataloader.DataLoader):\n            raise TypeError(\n                ""Only accepts a `DataLoader` instance."")\n\n    @classmethod\n    def _validate_kwargs(cls, kwargs):\n        if not isinstance(kwargs, dict):\n            raise TypeError(\'Only accepts a `dict` instance.\')\n\n    @classmethod\n    def _validate_mode(cls, mode):\n        if mode not in (\'maximize\', \'minimize\'):\n            raise ValueError(\'`mode` should be one of `maximize`, `minimize`.\')\n\n    @classmethod\n    def _validate_metric(cls, params, metric):\n        if metric not in params[\'task\'].metrics:\n            raise ValueError(\'Target metric does not exist in the task.\')\n\n    @classmethod\n    def _validate_num_runs(cls, num_runs):\n        if not isinstance(num_runs, int):\n            raise TypeError(\'Only accepts an `int` value.\')\n'"
matchzoo/dataloader/callbacks/__init__.py,0,b'from .lambda_callback import LambdaCallback\nfrom .histogram import Histogram\nfrom .ngram import Ngram\nfrom .padding import BasicPadding\nfrom .padding import DRMMPadding\nfrom .padding import BertPadding\n'
matchzoo/dataloader/callbacks/histogram.py,0,"b'import numpy as np\n\nimport matchzoo as mz\nfrom matchzoo.engine.base_callback import BaseCallback\n\n\nclass Histogram(BaseCallback):\n    """"""\n    Generate data with matching histogram.\n\n    :param embedding_matrix: The embedding matrix used to generator match\n                             histogram.\n    :param bin_size: The number of bin size of the histogram.\n    :param hist_mode: The mode of the :class:`MatchingHistogramUnit`, one of\n                     `CH`, `NH`, and `LCH`.\n    """"""\n\n    def __init__(\n        self,\n        embedding_matrix: np.ndarray,\n        bin_size: int = 30,\n        hist_mode: str = \'CH\',\n    ):\n        """"""Init.""""""\n        self._match_hist_unit = mz.preprocessors.units.MatchingHistogram(\n            bin_size=bin_size,\n            embedding_matrix=embedding_matrix,\n            normalize=True,\n            mode=hist_mode\n        )\n\n    def on_batch_unpacked(self, x, y):\n        """"""Insert `match_histogram` to `x`.""""""\n        x[\'match_histogram\'] = _build_match_histogram(x, self._match_hist_unit)\n\n\ndef _trunc_text(input_text: list, length: list) -> list:\n    """"""\n    Truncating the input text according to the input length.\n\n    :param input_text: The input text need to be truncated.\n    :param length: The length used to truncated the text.\n    :return: The truncated text.\n    """"""\n    return [row[:length[idx]] for idx, row in enumerate(input_text)]\n\n\ndef _build_match_histogram(\n    x: dict,\n    match_hist_unit: mz.preprocessors.units.MatchingHistogram\n) -> np.ndarray:\n    """"""\n    Generate the matching hisogram for input.\n\n    :param x: The input `dict`.\n    :param match_hist_unit: The histogram unit :class:`MatchingHistogramUnit`.\n    :return: The matching histogram.\n    """"""\n    match_hist = []\n    text_left = x[\'text_left\'].tolist()\n    text_right = _trunc_text(x[\'text_right\'].tolist(),\n                             x[\'length_right\'].tolist())\n    for pair in zip(text_left, text_right):\n        match_hist.append(match_hist_unit.transform(list(pair)))\n    return np.asarray(match_hist)\n'"
matchzoo/dataloader/callbacks/lambda_callback.py,0,"b'from matchzoo.engine.base_callback import BaseCallback\n\n\nclass LambdaCallback(BaseCallback):\n    """"""\n    LambdaCallback. Just a shorthand for creating a callback class.\n\n    See :class:`matchzoo.engine.base_callback.BaseCallback` for more details.\n\n    Example:\n\n        >>> import matchzoo as mz\n        >>> from matchzoo.dataloader.callbacks import LambdaCallback\n        >>> data = mz.datasets.toy.load_data()\n        >>> batch_func = lambda x: print(type(x))\n        >>> unpack_func = lambda x, y: print(type(x), type(y))\n        >>> callback = LambdaCallback(on_batch_data_pack=batch_func,\n        ...                           on_batch_unpacked=unpack_func)\n        >>> dataset = mz.dataloader.Dataset(\n        ...     data, callbacks=[callback])\n        >>> _ = dataset[0]\n        <class \'matchzoo.data_pack.data_pack.DataPack\'>\n        <class \'dict\'> <class \'numpy.ndarray\'>\n\n    """"""\n\n    def __init__(self, on_batch_data_pack=None, on_batch_unpacked=None):\n        """"""Init.""""""\n        self._on_batch_unpacked = on_batch_unpacked\n        self._on_batch_data_pack = on_batch_data_pack\n\n    def on_batch_data_pack(self, data_pack):\n        """"""`on_batch_data_pack`.""""""\n        if self._on_batch_data_pack:\n            self._on_batch_data_pack(data_pack)\n\n    def on_batch_unpacked(self, x, y):\n        """"""`on_batch_unpacked`.""""""\n        if self._on_batch_unpacked:\n            self._on_batch_unpacked(x, y)\n'"
matchzoo/dataloader/callbacks/ngram.py,0,"b'import numpy as np\n\nimport matchzoo as mz\nfrom matchzoo.engine.base_callback import BaseCallback\n\n\nclass Ngram(BaseCallback):\n    """"""\n    Generate the character n-gram for data.\n\n    :param preprocessor: The fitted :class:`BasePreprocessor` object, which\n         contains the n-gram units information.\n    :param mode: It can be one of \'index\', \'onehot\', \'sum\' or \'aggregate\'.\n\n    Example:\n        >>> import matchzoo as mz\n        >>> from matchzoo.dataloader.callbacks import Ngram\n        >>> data = mz.datasets.toy.load_data()\n        >>> preprocessor = mz.preprocessors.BasicPreprocessor(ngram_size=3)\n        >>> data = preprocessor.fit_transform(data)\n        >>> callback = Ngram(preprocessor=preprocessor, mode=\'index\')\n        >>> dataset = mz.dataloader.Dataset(\n        ...     data, callbacks=[callback])\n        >>> _ = dataset[0]\n\n    """"""\n\n    def __init__(\n        self,\n        preprocessor: mz.preprocessors.BasicPreprocessor,\n        mode: str = \'index\'\n    ):\n        """"""Init.""""""\n        self._mode = mode\n        self._word_to_ngram = _build_word_ngram_map(\n            preprocessor.context[\'ngram_process_unit\'],\n            preprocessor.context[\'ngram_vocab_unit\'],\n            preprocessor.context[\'vocab_unit\'].state[\'index_term\'],\n            mode\n        )\n\n    def on_batch_unpacked(self, x, y):\n        """"""Insert `ngram_left` and `ngram_right` to `x`.""""""\n        batch_size = len(x[\'text_left\'])\n        x[\'ngram_left\'] = [[] for i in range(batch_size)]\n        x[\'ngram_right\'] = [[] for i in range(batch_size)]\n        for idx, row in enumerate(x[\'text_left\']):\n            for term in row:\n                x[\'ngram_left\'][idx].append(self._word_to_ngram[term])\n        for idx, row in enumerate(x[\'text_right\']):\n            for term in row:\n                x[\'ngram_right\'][idx].append(self._word_to_ngram[term])\n        if self._mode == \'aggregate\':\n            x[\'ngram_left\'] = [list(np.sum(row, axis=0))\n                               for row in x[\'ngram_left\']]\n            x[\'ngram_right\'] = [list(np.sum(row, axis=0))\n                                for row in x[\'ngram_right\']]\n            x[\'text_left\'] = x[\'ngram_left\']\n            x[\'text_right\'] = x[\'ngram_right\']\n\n\ndef _build_word_ngram_map(\n    ngram_process_unit: mz.preprocessors.units.NgramLetter,\n    ngram_vocab_unit: mz.preprocessors.units.Vocabulary,\n    index_term: dict,\n    mode: str = \'index\'\n) -> dict:\n    """"""\n    Generate the word to ngram vector mapping.\n\n    :param ngram_process_unit: The fitted :class:`NgramLetter` object.\n    :param ngram_vocab_unit: The fitted :class:`Vocabulary` object.\n    :param index_term: The index to term mapping dict.\n    :param mode:  It be one of \'index\', \'onehot\', \'sum\' or \'aggregate\'.\n\n    :return: the word to ngram vector mapping.\n    """"""\n    word_to_ngram = {}\n    ngram_size = len(ngram_vocab_unit.state[\'index_term\'])\n    for idx, word in index_term.items():\n        if idx == 0:\n            continue\n        elif idx == 1:  # OOV\n            word_ngram = [1]\n        else:\n            ngrams = ngram_process_unit.transform([word])\n            word_ngram = ngram_vocab_unit.transform(ngrams)\n        num_ngrams = len(word_ngram)\n        if mode == \'index\':\n            word_to_ngram[idx] = word_ngram\n        elif mode == \'onehot\':\n            onehot = np.zeros((num_ngrams, ngram_size))\n            onehot[np.arange(num_ngrams), word_ngram] = 1\n            word_to_ngram[idx] = onehot\n        elif mode == \'sum\' or mode == \'aggregate\':\n            onehot = np.zeros((num_ngrams, ngram_size))\n            onehot[np.arange(num_ngrams), word_ngram] = 1\n            sum_vector = np.sum(onehot, axis=0)\n            word_to_ngram[idx] = sum_vector\n        else:\n            raise ValueError(f\'mode error, it should be one of `index`, \'\n                             f\'`onehot`, `sum` or `aggregate`.\'\n                             )\n    return word_to_ngram\n'"
matchzoo/dataloader/callbacks/padding.py,0,"b'import typing\r\nfrom collections import Iterable\r\n\r\nimport numpy as np\r\n\r\nfrom matchzoo.engine.base_callback import BaseCallback\r\n\r\n\r\ndef _infer_dtype(value):\r\n    """"""Infer the dtype for the features.\r\n\r\n    It is required as the input is usually array of objects before padding.\r\n    """"""\r\n    while isinstance(value, (list, tuple)) and len(value) > 0:\r\n        value = value[0]\r\n\r\n    if not isinstance(value, Iterable):\r\n        return np.array(value).dtype\r\n\r\n    if value is not None and len(value) > 0 and np.issubdtype(\r\n            np.array(value).dtype, np.generic):\r\n        dtype = np.array(value[0]).dtype\r\n    else:\r\n        dtype = value.dtype\r\n\r\n    # Single Precision\r\n    if dtype == np.double:\r\n        dtype = np.float32\r\n\r\n    return dtype\r\n\r\n\r\ndef _padding_2D(input, output, mode: str = \'pre\'):\r\n    """"""\r\n    Pad the input 2D-tensor to the output 2D-tensor.\r\n\r\n    :param input: The input 2D-tensor contains the origin values.\r\n    :param output: The output is a shapped 2D-tensor which have filled with pad\r\n     value.\r\n    :param mode: The padding model, which can be \'pre\' or \'post\'.\r\n    """"""\r\n    batch_size = min(output.shape[0], len(input))\r\n    pad_length = output.shape[1]\r\n    if mode == \'post\':\r\n        for i in range(batch_size):\r\n            end_pos = min(len(input[i]), pad_length)\r\n            if end_pos > 0:\r\n                output[i][:end_pos] = input[i][:end_pos]\r\n    elif mode == \'pre\':\r\n        for i in range(batch_size):\r\n            start_pos = min(len(input[i]), pad_length)\r\n            if start_pos > 0:\r\n                output[i][-start_pos:] = input[i][-start_pos:]\r\n    else:\r\n        raise ValueError(\'{} is not a vaild pad mode.\'.format(mode))\r\n\r\n\r\ndef _padding_3D(input, output, mode: str = \'pre\'):\r\n    """"""\r\n    Pad the input 3D-tensor to the output 3D-tensor.\r\n\r\n    :param input: The input 3D-tensor contains the origin values.\r\n    :param output: The output is a shapped 3D-tensor which have filled with pad\r\n     value.\r\n    :param mode: The padding model, which can be \'pre\' or \'post\'.\r\n    """"""\r\n    batch_size = min(output.shape[0], len(input))\r\n    pad_1d_length = output.shape[1]\r\n    pad_2d_length = output.shape[2]\r\n    if mode == \'post\':\r\n        for i in range(batch_size):\r\n            len_d1 = min(len(input[i]), pad_1d_length)\r\n            for j in range(len_d1):\r\n                end_pos = min(len(input[i][j]), pad_2d_length)\r\n                if end_pos > 0:\r\n                    output[i][j][:end_pos] = input[i][j][:end_pos]\r\n    elif mode == \'pre\':\r\n        for i in range(batch_size):\r\n            len_d1 = min(len(input[i]), pad_1d_length)\r\n            for j in range(len_d1):\r\n                start_pos = min(len(input[i][j]), pad_2d_length)\r\n                if start_pos > 0:\r\n                    output[i][j][-start_pos:] = input[i][j][-start_pos:]\r\n    else:\r\n        raise ValueError(\'{} is not a vaild pad mode.\'.format(mode))\r\n\r\n\r\nclass BasicPadding(BaseCallback):\r\n    """"""\r\n    Pad data for basic preprocessor.\r\n\r\n    :param fixed_length_left: Integer. If set, `text_left` will be padded\r\n        to this length.\r\n    :param fixed_length_right: Integer. If set, `text_right` will be padded\r\n        to this length.\r\n    :param pad_word_value: the value to fill text.\r\n    :param pad_word_mode: String, `pre` or `post`:\r\n        pad either before or after each sequence.\r\n    :param with_ngram: Boolean. Whether to pad the n-grams.\r\n    :param fixed_ngram_length: Integer. If set, each word will be padded to\r\n        this length, or it will be set as the maximum length of words in\r\n        current batch.\r\n    :param pad_ngram_value: the value to fill empty n-grams.\r\n    :param pad_ngram_mode: String, `pre` or `post`: pad either before of after\r\n        each sequence.\r\n    """"""\r\n\r\n    def __init__(\r\n        self,\r\n        fixed_length_left: int = None,\r\n        fixed_length_right: int = None,\r\n        pad_word_value: typing.Union[int, str] = 0,\r\n        pad_word_mode: str = \'pre\',\r\n        with_ngram: bool = False,\r\n        fixed_ngram_length: int = None,\r\n        pad_ngram_value: typing.Union[int, str] = 0,\r\n        pad_ngram_mode: str = \'pre\'\r\n    ):\r\n        """"""Init.""""""\r\n        self._fixed_length_left = fixed_length_left\r\n        self._fixed_length_right = fixed_length_right\r\n        self._pad_word_value = pad_word_value\r\n        self._pad_word_mode = pad_word_mode\r\n        self._with_ngram = with_ngram\r\n        self._fixed_ngram_length = fixed_ngram_length\r\n        self._pad_ngram_value = pad_ngram_value\r\n        self._pad_ngram_mode = pad_ngram_mode\r\n\r\n    def on_batch_unpacked(self, x: dict, y: np.ndarray):\r\n        """"""Pad `x[\'text_left\']` and `x[\'text_right]`.""""""\r\n\r\n        batch_size = len(x[\'id_left\'])\r\n        pad_length_left = int(max(x[\'length_left\']))\r\n        pad_length_right = int(max(x[\'length_right\']))\r\n        if self._with_ngram:\r\n            ngram_length_left = max([len(w)\r\n                                     for k in x[\'ngram_left\'] for w in k])\r\n            ngram_length_right = max([len(w)\r\n                                      for k in x[\'ngram_right\'] for w in k])\r\n            ngram_length = max(ngram_length_left, ngram_length_right)\r\n            if self._fixed_ngram_length:\r\n                ngram_length = self._fixed_ngram_length\r\n\r\n        if self._fixed_length_left is not None:\r\n            pad_length_left = self._fixed_length_left\r\n        if self._fixed_length_right is not None:\r\n            pad_length_right = self._fixed_length_right\r\n\r\n        for key, value in x.items():\r\n            dtype = _infer_dtype(value)\r\n\r\n            if key == \'text_left\':\r\n                padded_value = np.full([batch_size, pad_length_left],\r\n                                       self._pad_word_value, dtype=dtype)\r\n                _padding_2D(value, padded_value, self._pad_word_mode)\r\n            elif key == \'text_right\':\r\n                padded_value = np.full([batch_size, pad_length_right],\r\n                                       self._pad_word_value, dtype=dtype)\r\n                _padding_2D(value, padded_value, self._pad_word_mode)\r\n            elif key == \'ngram_left\':\r\n                padded_value = np.full(\r\n                    [batch_size, pad_length_left, ngram_length],\r\n                    self._pad_ngram_value, dtype=dtype\r\n                )\r\n                _padding_3D(value, padded_value, self._pad_ngram_mode)\r\n            elif key == \'ngram_right\':\r\n                padded_value = np.full(\r\n                    [batch_size, pad_length_right, ngram_length],\r\n                    self._pad_ngram_value, dtype=dtype\r\n                )\r\n                _padding_3D(value, padded_value, self._pad_ngram_mode)\r\n            else:\r\n                continue\r\n            x[key] = padded_value\r\n\r\n\r\nclass DRMMPadding(BaseCallback):\r\n    """"""\r\n    Pad data for DRMM Model.\r\n\r\n    :param fixed_length_left: Integer. If set, `text_left` and\r\n        `match_histogram` will be padded to this length.\r\n    :param fixed_length_right: Integer. If set, `text_right` will be padded\r\n        to this length.\r\n    :param pad_value: the value to fill text.\r\n    :param pad_mode: String, `pre` or `post`:\r\n        pad either before or after each sequence.\r\n    """"""\r\n\r\n    def __init__(\r\n        self,\r\n        fixed_length_left: int = None,\r\n        fixed_length_right: int = None,\r\n        pad_value: typing.Union[int, str] = 0,\r\n        pad_mode: str = \'pre\',\r\n    ):\r\n        """"""Init.""""""\r\n        self._fixed_length_left = fixed_length_left\r\n        self._fixed_length_right = fixed_length_right\r\n        self._pad_value = pad_value\r\n        self._pad_mode = pad_mode\r\n\r\n    def on_batch_unpacked(self, x: dict, y: np.ndarray):\r\n        """"""\r\n        Padding.\r\n\r\n        Pad `x[\'text_left\']`, `x[\'text_right]` and `x[\'match_histogram\']`.\r\n        """"""\r\n        batch_size = len(x[\'id_left\'])\r\n        pad_length_left = max(x[\'length_left\'])\r\n        pad_length_right = max(x[\'length_right\'])\r\n        bin_size = len(x[\'match_histogram\'][0][0])\r\n\r\n        if self._fixed_length_left is not None:\r\n            pad_length_left = self._fixed_length_left\r\n        if self._fixed_length_right is not None:\r\n            pad_length_right = self._fixed_length_right\r\n\r\n        for key, value in x.items():\r\n            if key != \'text_left\' and key != \'text_right\' and \\\r\n                    key != \'match_histogram\':\r\n                continue\r\n\r\n            dtype = _infer_dtype(value)\r\n\r\n            if key == \'text_left\':\r\n                padded_value = np.full([batch_size, pad_length_left],\r\n                                       self._pad_value, dtype=dtype)\r\n                _padding_2D(value, padded_value, self._pad_mode)\r\n            elif key == \'text_right\':\r\n                padded_value = np.full([batch_size, pad_length_right],\r\n                                       self._pad_value, dtype=dtype)\r\n                _padding_2D(value, padded_value, self._pad_mode)\r\n            else:  # key == \'match_histogram\'\r\n                padded_value = np.full(\r\n                    [batch_size, pad_length_left, bin_size],\r\n                    self._pad_value, dtype=dtype)\r\n                _padding_3D(value, padded_value, self._pad_mode)\r\n            x[key] = padded_value\r\n\r\n\r\nclass BertPadding(BaseCallback):\r\n    """"""\r\n    Pad data for bert preprocessor.\r\n\r\n    :param fixed_length_left: Integer. If set, `text_left` will be padded\r\n        to this length.\r\n    :param fixed_length_right: Integer. If set, `text_right` will be padded\r\n        to this length.\r\n    :param pad_value: the value to fill text.\r\n    :param pad_mode: String, `pre` or `post`:\r\n        pad either before or after each sequence.\r\n    """"""\r\n\r\n    def __init__(\r\n        self,\r\n        fixed_length_left: int = None,\r\n        fixed_length_right: int = None,\r\n        pad_value: typing.Union[int, str] = 0,\r\n        pad_mode: str = \'pre\',\r\n    ):\r\n        """"""Init.""""""\r\n        self._padding = BasicPadding(fixed_length_left=fixed_length_left,\r\n                                     fixed_length_right=fixed_length_right,\r\n                                     pad_word_value=pad_value,\r\n                                     pad_word_mode=pad_mode)\r\n\r\n    def on_batch_unpacked(self, x: dict, y: np.ndarray):\r\n        """"""Pad `x[\'text_left\']` and `x[\'text_right]`.""""""\r\n        self._padding.on_batch_unpacked(x, y)\r\n        x[\'text_left\'] = np.insert(x[\'text_left\'], 0, 101, axis=1)\r\n        x[\'text_left\'] = np.insert(x[\'text_left\'], x[\'text_left\'][0].size, 102, axis=1)\r\n        x[\'text_right\'] = np.insert(x[\'text_right\'], x[\'text_right\'][0].size, 102, axis=1)\r\n'"
matchzoo/datasets/embeddings/__init__.py,0,"b""from pathlib import Path\nfrom .load_glove_embedding import load_glove_embedding\nfrom .load_fasttext_embedding import load_fasttext_embedding\n\nDATA_ROOT = Path(__file__).parent\nEMBED_RANK = DATA_ROOT.joinpath('embed_rank.txt')\nEMBED_10 = DATA_ROOT.joinpath('embed_10_word2vec.txt')\nEMBED_10_GLOVE = DATA_ROOT.joinpath('embed_10_glove.txt')\n"""
matchzoo/datasets/embeddings/load_fasttext_embedding.py,0,"b'""""""FastText embedding data loader.""""""\n\nfrom pathlib import Path\n\nimport matchzoo as mz\n\n_fasttext_embedding_url = ""https://dl.fbaipublicfiles.com/fasttext/vectors"" \\\n                          ""-wiki/wiki.{}.vec""\n\n\ndef load_fasttext_embedding(language: str = \'en\') -> mz.embedding.Embedding:\n    """"""\n    Return the pretrained fasttext embedding.\n\n    :param language: the language of embedding. Supported language can be\n        referred to ""https://github.com/facebookresearch/fastText/blob/master""\n        ""/docs/pretrained-vectors.md""\n    :return: The :class:`mz.embedding.Embedding` object.\n    """"""\n    file_name = _fasttext_embedding_url.split(\'/\')[-1].format(language)\n    file_path = (Path(mz.USER_DATA_DIR) / \'fasttext\').joinpath(file_name)\n    if not file_path.exists():\n        mz.utils.get_file(file_name,\n                          _fasttext_embedding_url.format(language),\n                          extract=False,\n                          cache_dir=mz.USER_DATA_DIR,\n                          cache_subdir=\'fasttext\')\n    return mz.embedding.load_from_file(file_path=str(file_path),\n                                       mode=\'fasttext\')\n'"
matchzoo/datasets/embeddings/load_glove_embedding.py,0,"b'""""""GloVe Embedding data loader.""""""\n\nfrom pathlib import Path\n\nimport matchzoo as mz\n\n_glove_embedding_url = ""http://nlp.stanford.edu/data/glove.6B.zip""\n\n\ndef load_glove_embedding(dimension: int = 50) -> mz.embedding.Embedding:\n    """"""\n    Return the pretrained glove embedding.\n\n    :param dimension: the size of embedding dimension, the value can only be\n        50, 100, or 300.\n    :return: The :class:`mz.embedding.Embedding` object.\n    """"""\n    file_name = \'glove.6B.\' + str(dimension) + \'d.txt\'\n    file_path = (Path(mz.USER_DATA_DIR) / \'glove\').joinpath(file_name)\n    if not file_path.exists():\n        mz.utils.get_file(\'glove_embedding\',\n                          _glove_embedding_url,\n                          extract=True,\n                          cache_dir=mz.USER_DATA_DIR,\n                          cache_subdir=\'glove\')\n    return mz.embedding.load_from_file(file_path=str(file_path), mode=\'glove\')\n'"
matchzoo/datasets/quora_qp/__init__.py,0,b'from .load_data import load_data\n'
matchzoo/datasets/quora_qp/load_data.py,0,"b'""""""Quora Question Pairs data loader.""""""\n\nimport typing\nfrom pathlib import Path\n\nimport pandas as pd\n\nimport matchzoo\nfrom matchzoo.engine.base_task import BaseTask\n\n_url = ""https://firebasestorage.googleapis.com/v0/b/mtl-sentence"" \\\n       ""-representations.appspot.com/o/data%2FQQP.zip?alt=media&"" \\\n       ""token=700c6acf-160d-4d89-81d1-de4191d02cb5""\n\n\ndef load_data(\n    stage: str = \'train\',\n    task: typing.Union[str, BaseTask] = \'classification\',\n    return_classes: bool = False,\n) -> typing.Union[matchzoo.DataPack, tuple]:\n    """"""\n    Load QuoraQP data.\n\n    :param path: `None` for download from quora, specific path for\n        downloaded data.\n    :param stage: One of `train`, `dev`, and `test`.\n    :param task: Could be one of `ranking`, `classification` or a\n        :class:`matchzoo.engine.BaseTask` instance.\n    :param return_classes: Whether return classes for classification task.\n    :return: A DataPack if `ranking`, a tuple of (DataPack, classes) if\n        `classification`.\n    """"""\n    if stage not in (\'train\', \'dev\', \'test\'):\n        raise ValueError(f""{stage} is not a valid stage.""\n                         f""Must be one of `train`, `dev`, and `test`."")\n\n    data_root = _download_data()\n    file_path = data_root.joinpath(f""{stage}.tsv"")\n    data_pack = _read_data(file_path, stage, task)\n\n    if task == \'ranking\' or isinstance(task, matchzoo.tasks.Ranking):\n        return data_pack\n    elif task == \'classification\' or isinstance(\n            task, matchzoo.tasks.Classification):\n        if return_classes:\n            return data_pack, [False, True]\n        else:\n            return data_pack\n    else:\n        raise ValueError(f""{task} is not a valid task."")\n\n\ndef _download_data():\n    ref_path = matchzoo.utils.get_file(\n        \'quora_qp\', _url, extract=True,\n        cache_dir=matchzoo.USER_DATA_DIR,\n        cache_subdir=\'quora_qp\'\n    )\n    return Path(ref_path).parent.joinpath(\'QQP\')\n\n\ndef _read_data(path, stage, task):\n    data = pd.read_csv(path, sep=\'\\t\', error_bad_lines=False, dtype=object)\n    data = data.dropna(axis=0, how=\'any\').reset_index(drop=True)\n    if stage in [\'train\', \'dev\']:\n        df = pd.DataFrame({\n            \'id_left\': data[\'qid1\'],\n            \'id_right\': data[\'qid2\'],\n            \'text_left\': data[\'question1\'],\n            \'text_right\': data[\'question2\'],\n            \'label\': data[\'is_duplicate\'].astype(int)\n        })\n    else:\n        df = pd.DataFrame({\n            \'text_left\': data[\'question1\'],\n            \'text_right\': data[\'question2\']\n        })\n    return matchzoo.pack(df, task)\n'"
matchzoo/datasets/snli/__init__.py,0,b'from .load_data import load_data\n'
matchzoo/datasets/snli/load_data.py,0,"b'""""""SNLI data loader.""""""\n\nimport typing\nfrom pathlib import Path\n\nimport pandas as pd\n\nimport matchzoo\nfrom matchzoo.engine.base_task import BaseTask\n\n_url = ""https://nlp.stanford.edu/projects/snli/snli_1.0.zip""\n\n\ndef load_data(\n    stage: str = \'train\',\n    task: typing.Union[str, BaseTask] = \'classification\',\n    target_label: str = \'entailment\',\n    return_classes: bool = False\n) -> typing.Union[matchzoo.DataPack, tuple]:\n    """"""\n    Load SNLI data.\n\n    :param stage: One of `train`, `dev`, and `test`. (default: `train`)\n    :param task: Could be one of `ranking`, `classification` or a\n        :class:`matchzoo.engine.BaseTask` instance. (default: `classification`)\n    :param target_label: If `ranking`, chose one of `entailment`,\n        `contradiction` and `neutral` as the positive label.\n        (default: `entailment`)\n    :param return_classes: `True` to return classes for classification task,\n        `False` otherwise.\n\n    :return: A DataPack unless `task` is `classificiation` and `return_classes`\n        is `True`: a tuple of `(DataPack, classes)` in that case.\n    """"""\n    if stage not in (\'train\', \'dev\', \'test\'):\n        raise ValueError(f""{stage} is not a valid stage.""\n                         f""Must be one of `train`, `dev`, and `test`."")\n\n    data_root = _download_data()\n    file_path = data_root.joinpath(f\'snli_1.0_{stage}.txt\')\n    data_pack = _read_data(file_path, task, target_label)\n\n    if task == \'ranking\' or isinstance(task, matchzoo.tasks.Ranking):\n        return data_pack\n    elif task == \'classification\' or isinstance(\n            task, matchzoo.tasks.Classification):\n        classes = [\'entailment\', \'contradiction\', \'neutral\']\n        if return_classes:\n            return data_pack, classes\n        else:\n            return data_pack\n    else:\n        raise ValueError(f""{task} is not a valid task.""\n                         f""Must be one of `Ranking` and `Classification`."")\n\n\ndef _download_data():\n    ref_path = matchzoo.utils.get_file(\n        \'snli\', _url, extract=True,\n        cache_dir=matchzoo.USER_DATA_DIR,\n        cache_subdir=\'snli\'\n    )\n    return Path(ref_path).parent.joinpath(\'snli_1.0\')\n\n\ndef _read_data(path, task, target_label):\n    table = pd.read_csv(path, sep=\'\\t\')\n    df = pd.DataFrame({\n        \'text_left\': table[\'sentence1\'],\n        \'text_right\': table[\'sentence2\'],\n        \'label\': table[\'gold_label\']\n    })\n    df = df.dropna(axis=0, how=\'any\').reset_index(drop=True)\n\n    filter_id = df[df[\'label\'] == \'-\'].index.tolist()\n    df.drop(filter_id, inplace=True)\n\n    if task == \'ranking\' or isinstance(task, matchzoo.tasks.Ranking):\n        if target_label not in [\'entailment\', \'contradiction\', \'neutral\']:\n            raise ValueError(f""{target_label} is not a valid target label.""\n                             f""Must be one of `entailment`, `contradiction`""\n                             f"" and `neutral`"")\n        df[\'label\'] = (df[\'label\'] == target_label)\n    elif task == \'classification\' or isinstance(\n            task, matchzoo.tasks.Classification):\n        classes = [\'entailment\', \'contradiction\', \'neutral\']\n        df[\'label\'] = df[\'label\'].apply(classes.index)\n    else:\n        raise ValueError(f""{task} is not a valid task.""\n                         f""Must be one of `Ranking` and `Classification`."")\n\n    return matchzoo.pack(df, task)\n'"
matchzoo/datasets/toy/__init__.py,0,"b'import typing\nfrom pathlib import Path\n\nimport pandas as pd\n\nimport matchzoo\nfrom matchzoo.engine.base_task import BaseTask\n\n\ndef load_data(\n    stage: str = \'train\',\n    task: typing.Union[str, BaseTask] = \'ranking\',\n    return_classes: bool = False\n) -> typing.Union[matchzoo.DataPack, typing.Tuple[matchzoo.DataPack, list]]:\n    """"""\n    Load toy data.\n\n    :param stage: One of `train`, `dev`, and `test`.\n    :param task: Could be one of `ranking`, `classification` or a\n        :class:`matchzoo.engine.BaseTask` instance.\n    :param return_classes: `True` to return classes for classification task,\n        `False` otherwise.\n\n    :return: A DataPack unless `task` is `classificiation` and `return_classes`\n        is `True`: a tuple of `(DataPack, classes)` in that case.\n\n    Example:\n        >>> import matchzoo as mz\n        >>> stages = \'train\', \'dev\', \'test\'\n        >>> tasks = \'ranking\', \'classification\'\n        >>> for stage in stages:\n        ...     for task in tasks:\n        ...         _ = mz.datasets.toy.load_data(stage, task)\n    """"""\n    if stage not in (\'train\', \'dev\', \'test\'):\n        raise ValueError(f""{stage} is not a valid stage.""\n                         f""Must be one of `train`, `dev`, and `test`."")\n\n    path = Path(__file__).parent.joinpath(f\'{stage}.csv\')\n    data_pack = matchzoo.pack(pd.read_csv(path, index_col=0), task)\n\n    if task == \'ranking\' or isinstance(task, matchzoo.tasks.Ranking):\n        return data_pack\n    elif task == \'classification\' or isinstance(\n            task, matchzoo.tasks.Classification):\n        if return_classes:\n            return data_pack, [False, True]\n        else:\n            return data_pack\n    else:\n        raise ValueError(f""{task} is not a valid task.""\n                         f""Must be one of `Ranking` and `Classification`."")\n\n\ndef load_embedding():\n    path = Path(__file__).parent.joinpath(\'embedding.2d.txt\')\n    return matchzoo.embedding.load_from_file(path, mode=\'glove\')\n'"
matchzoo/datasets/wiki_qa/__init__.py,0,b'from .load_data import load_data\n'
matchzoo/datasets/wiki_qa/load_data.py,0,"b'""""""WikiQA data loader.""""""\n\nimport typing\nimport csv\nfrom pathlib import Path\n\nimport pandas as pd\n\nimport matchzoo\nfrom matchzoo.engine.base_task import BaseTask\n\n_url = ""https://download.microsoft.com/download/E/5/F/"" \\\n       ""E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip""\n\n\ndef load_data(\n    stage: str = \'train\',\n    task: typing.Union[str, BaseTask] = \'ranking\',\n    filtered: bool = False,\n    return_classes: bool = False\n) -> typing.Union[matchzoo.DataPack, tuple]:\n    """"""\n    Load WikiQA data.\n\n    :param stage: One of `train`, `dev`, and `test`.\n    :param task: Could be one of `ranking`, `classification` or a\n        :class:`matchzoo.engine.BaseTask` instance.\n    :param filtered: Whether remove the questions without correct answers.\n    :param return_classes: `True` to return classes for classification task,\n        `False` otherwise.\n\n    :return: A DataPack unless `task` is `classificiation` and `return_classes`\n        is `True`: a tuple of `(DataPack, classes)` in that case.\n    """"""\n    if stage not in (\'train\', \'dev\', \'test\'):\n        raise ValueError(f""{stage} is not a valid stage.""\n                         f""Must be one of `train`, `dev`, and `test`."")\n\n    data_root = _download_data()\n    file_path = data_root.joinpath(f\'WikiQA-{stage}.tsv\')\n    data_pack = _read_data(file_path, task)\n    if filtered and stage in (\'dev\', \'test\'):\n        ref_path = data_root.joinpath(f\'WikiQA-{stage}.ref\')\n        filter_ref_path = data_root.joinpath(f\'WikiQA-{stage}-filtered.ref\')\n        with open(filter_ref_path, mode=\'r\') as f:\n            filtered_ids = set([line.split()[0] for line in f])\n        filtered_lines = []\n        with open(ref_path, mode=\'r\') as f:\n            for idx, line in enumerate(f.readlines()):\n                if line.split()[0] in filtered_ids:\n                    filtered_lines.append(idx)\n        data_pack = data_pack[filtered_lines]\n\n    if task == \'ranking\' or isinstance(task, matchzoo.tasks.Ranking):\n        return data_pack\n    elif task == \'classification\' or isinstance(\n            task, matchzoo.tasks.Classification):\n        if return_classes:\n            return data_pack, [False, True]\n        else:\n            return data_pack\n    else:\n        raise ValueError(f""{task} is not a valid task.""\n                         f""Must be one of `Ranking` and `Classification`."")\n\n\ndef _download_data():\n    ref_path = matchzoo.utils.get_file(\n        \'wikiqa\', _url, extract=True,\n        cache_dir=matchzoo.USER_DATA_DIR,\n        cache_subdir=\'wiki_qa\'\n    )\n    return Path(ref_path).parent.joinpath(\'WikiQACorpus\')\n\n\ndef _read_data(path, task):\n    table = pd.read_csv(path, sep=\'\\t\', header=0, quoting=csv.QUOTE_NONE)\n    df = pd.DataFrame({\n        \'text_left\': table[\'Question\'],\n        \'text_right\': table[\'Sentence\'],\n        \'id_left\': table[\'QuestionID\'],\n        \'id_right\': table[\'SentenceID\'],\n        \'label\': table[\'Label\']\n    })\n    return matchzoo.pack(df, task)\n'"
matchzoo/preprocessors/units/__init__.py,0,b'from .unit import Unit\nfrom .digit_removal import DigitRemoval\nfrom .frequency_filter import FrequencyFilter\nfrom .lemmatization import Lemmatization\nfrom .lowercase import Lowercase\nfrom .matching_histogram import MatchingHistogram\nfrom .ngram_letter import NgramLetter\nfrom .punc_removal import PuncRemoval\nfrom .stateful_unit import StatefulUnit\nfrom .stemming import Stemming\nfrom .stop_removal import StopRemoval\nfrom .tokenize import Tokenize\nfrom .vocabulary import Vocabulary\nfrom .word_hashing import WordHashing\nfrom .character_index import CharacterIndex\nfrom .word_exact_match import WordExactMatch\nfrom .truncated_length import TruncatedLength\n\n\ndef list_available() -> list:\n    from matchzoo.utils import list_recursive_concrete_subclasses\n    return list_recursive_concrete_subclasses(Unit)\n'
matchzoo/preprocessors/units/character_index.py,0,"b'import numpy as np\n\nfrom .unit import Unit\n\n\nclass CharacterIndex(Unit):\n    """"""\n    CharacterIndexUnit for DIIN model.\n\n    The input of :class:\'CharacterIndexUnit\' should be a list of word\n    character list extracted from a text. The output is the character\n    index representation of this text.\n\n    :class:`NgramLetterUnit` and :class:`VocabularyUnit` are two\n    essential prerequisite of :class:`CharacterIndexUnit`.\n\n    Examples:\n        >>> input_ = [[\'#\', \'a\', \'#\'],[\'#\', \'o\', \'n\', \'e\', \'#\']]\n        >>> character_index = CharacterIndex(\n        ...     char_index={\n        ...      \'<PAD>\': 0, \'<OOV>\': 1, \'a\': 2, \'n\': 3, \'e\':4, \'#\':5})\n        >>> index = character_index.transform(input_)\n        >>> index\n        [[5, 2, 5], [5, 1, 3, 4, 5]]\n\n    """"""\n\n    def __init__(\n        self,\n        char_index: dict,\n    ):\n        """"""\n        Class initialization.\n\n        :param char_index: character-index mapping generated by\n            :class:\'VocabularyUnit\'.\n        """"""\n        self._char_index = char_index\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Transform list of characters to corresponding indices.\n\n        :param input_: list of characters generated by\n            :class:\'NgramLetterUnit\'.\n\n        :return: character index representation of a text.\n        """"""\n        idx = []\n        for i in range(len(input_)):\n            current = [\n                self._char_index.get(input_[i][j], 1)\n                for j in range(len(input_[i]))]\n            idx.append(current)\n        return idx\n'"
matchzoo/preprocessors/units/digit_removal.py,0,"b'from .unit import Unit\n\n\nclass DigitRemoval(Unit):\n    """"""Process unit to remove digits.""""""\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Remove digits from list of tokens.\n\n        :param input_: list of tokens to be filtered.\n\n        :return tokens: tokens of tokens without digits.\n        """"""\n        return [token for token in input_ if not token.isdigit()]\n'"
matchzoo/preprocessors/units/frequency_filter.py,0,"b'import collections\nimport typing\n\nimport numpy as np\n\nfrom .stateful_unit import StatefulUnit\n\n\nclass FrequencyFilter(StatefulUnit):\n    """"""\n    Frequency filter unit.\n\n    :param low: Lower bound, inclusive.\n    :param high: Upper bound, exclusive.\n    :param mode: One of `tf` (term frequency), `df` (document frequency),\n        and `idf` (inverse document frequency).\n\n    Examples::\n        >>> import matchzoo as mz\n\n    To filter based on term frequency (tf):\n        >>> tf_filter = mz.preprocessors.units.FrequencyFilter(\n        ...     low=2, mode=\'tf\')\n        >>> tf_filter.fit([[\'A\', \'B\', \'B\'], [\'C\', \'C\', \'C\']])\n        >>> tf_filter.transform([\'A\', \'B\', \'C\'])\n        [\'B\', \'C\']\n\n    To filter based on document frequency (df):\n        >>> tf_filter = mz.preprocessors.units.FrequencyFilter(\n        ...     low=2, mode=\'df\')\n        >>> tf_filter.fit([[\'A\', \'B\'], [\'B\', \'C\']])\n        >>> tf_filter.transform([\'A\', \'B\', \'C\'])\n        [\'B\']\n\n    To filter based on inverse document frequency (idf):\n        >>> idf_filter = mz.preprocessors.units.FrequencyFilter(\n        ...     low=1.2, mode=\'idf\')\n        >>> idf_filter.fit([[\'A\', \'B\'], [\'B\', \'C\', \'D\']])\n        >>> idf_filter.transform([\'A\', \'B\', \'C\'])\n        [\'A\', \'C\']\n\n    """"""\n\n    def __init__(self, low: float = 0, high: float = float(\'inf\'),\n                 mode: str = \'df\'):\n        """"""Frequency filter unit.""""""\n        super().__init__()\n        self._low = low\n        self._high = high\n        self._mode = mode\n\n    def fit(self, list_of_tokens: typing.List[typing.List[str]]):\n        """"""Fit `list_of_tokens` by calculating `mode` states.""""""\n        valid_terms = set()\n        if self._mode == \'tf\':\n            stats = self._tf(list_of_tokens)\n        elif self._mode == \'df\':\n            stats = self._df(list_of_tokens)\n        elif self._mode == \'idf\':\n            stats = self._idf(list_of_tokens)\n        else:\n            raise ValueError(f""{self._mode} is not a valid filtering mode.""\n                             f""Mode must be one of `tf`, `df`, and `idf`."")\n\n        for k, v in stats.items():\n            if self._low <= v < self._high:\n                valid_terms.add(k)\n\n        self._context[self._mode] = valid_terms\n\n    def transform(self, input_: list) -> list:\n        """"""Transform a list of tokens by filtering out unwanted words.""""""\n        valid_terms = self._context[self._mode]\n        return list(filter(lambda token: token in valid_terms, input_))\n\n    @classmethod\n    def _tf(cls, list_of_tokens: list) -> dict:\n        stats = collections.Counter()\n        for tokens in list_of_tokens:\n            stats.update(tokens)\n        return stats\n\n    @classmethod\n    def _df(cls, list_of_tokens: list) -> dict:\n        stats = collections.Counter()\n        for tokens in list_of_tokens:\n            stats.update(set(tokens))\n        return stats\n\n    @classmethod\n    def _idf(cls, list_of_tokens: list) -> dict:\n        num_docs = len(list_of_tokens)\n        stats = cls._df(list_of_tokens)\n        for key, val in stats.most_common():\n            stats[key] = np.log((1 + num_docs) / (1 + val)) + 1\n        return stats\n'"
matchzoo/preprocessors/units/lemmatization.py,0,"b'import nltk\n\nfrom .unit import Unit\n\n\nclass Lemmatization(Unit):\n    """"""Process unit for token lemmatization.""""""\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Lemmatization a sequence of tokens.\n\n        :param input_: list of tokens to be lemmatized.\n\n        :return tokens: list of lemmatizd tokens.\n        """"""\n        lemmatizer = nltk.WordNetLemmatizer()\n        return [lemmatizer.lemmatize(token, pos=\'v\') for token in input_]\n'"
matchzoo/preprocessors/units/lowercase.py,0,"b'from .unit import Unit\n\n\nclass Lowercase(Unit):\n    """"""Process unit for text lower case.""""""\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Convert list of tokens to lower case.\n\n        :param input_: list of tokens.\n\n        :return tokens: lower-cased list of tokens.\n        """"""\n        return [token.lower() for token in input_]\n'"
matchzoo/preprocessors/units/matching_histogram.py,0,"b'import numpy as np\n\nfrom .unit import Unit\n\n\nclass MatchingHistogram(Unit):\n    """"""\n    MatchingHistogramUnit Class.\n\n    :param bin_size: The number of bins of the matching histogram.\n    :param embedding_matrix: The word embedding matrix applied to calculate\n                             the matching histogram.\n    :param normalize: Boolean, normalize the embedding or not.\n    :param mode: The type of the historgram, it should be one of \'CH\', \'NG\',\n                 or \'LCH\'.\n\n    Examples:\n        >>> embedding_matrix = np.array([[1.0, -1.0], [1.0, 2.0], [1.0, 3.0]])\n        >>> text_left = [0, 1]\n        >>> text_right = [1, 2]\n        >>> histogram = MatchingHistogram(3, embedding_matrix, True, \'CH\')\n        >>> histogram.transform([text_left, text_right])\n        [[3.0, 1.0, 1.0], [1.0, 2.0, 2.0]]\n\n    """"""\n\n    def __init__(self, bin_size: int = 30, embedding_matrix=None,\n                 normalize=True, mode: str = \'LCH\'):\n        """"""The constructor.""""""\n        self._hist_bin_size = bin_size\n        self._embedding_matrix = embedding_matrix\n        if normalize:\n            self._normalize_embedding()\n        self._mode = mode\n\n    def _normalize_embedding(self):\n        """"""Normalize the embedding matrix.""""""\n        l2_norm = np.sqrt(\n            (self._embedding_matrix * self._embedding_matrix).sum(axis=1)\n        )\n        self._embedding_matrix = \\\n            self._embedding_matrix / l2_norm[:, np.newaxis]\n\n    def transform(self, input_: list) -> list:\n        """"""Transform the input text.""""""\n        text_left, text_right = input_\n        matching_hist = np.ones((len(text_left), self._hist_bin_size),\n                                dtype=np.float32)\n        embed_left = self._embedding_matrix[text_left]\n        embed_right = self._embedding_matrix[text_right]\n        matching_matrix = embed_left.dot(np.transpose(embed_right))\n        for (i, j), value in np.ndenumerate(matching_matrix):\n            bin_index = int((value + 1.) / 2. * (self._hist_bin_size - 1.))\n            matching_hist[i][bin_index] += 1.0\n        if self._mode == \'NH\':\n            matching_sum = matching_hist.sum(axis=1)\n            matching_hist = matching_hist / matching_sum[:, np.newaxis]\n        elif self._mode == \'LCH\':\n            matching_hist = np.log(matching_hist)\n        return matching_hist.tolist()\n'"
matchzoo/preprocessors/units/ngram_letter.py,0,"b'from .unit import Unit\n\n\nclass NgramLetter(Unit):\n    """"""\n    Process unit for n-letter generation.\n\n    Triletter is used in :class:`DSSMModel`.\n    This processor is expected to execute before `Vocab`\n    has been created.\n\n    Examples:\n        >>> triletter = NgramLetter()\n        >>> rv = triletter.transform([\'hello\', \'word\'])\n        >>> len(rv)\n        9\n        >>> rv\n        [\'#he\', \'hel\', \'ell\', \'llo\', \'lo#\', \'#wo\', \'wor\', \'ord\', \'rd#\']\n        >>> triletter = NgramLetter(reduce_dim=False)\n        >>> rv = triletter.transform([\'hello\', \'word\'])\n        >>> len(rv)\n        2\n        >>> rv\n        [[\'#he\', \'hel\', \'ell\', \'llo\', \'lo#\'], [\'#wo\', \'wor\', \'ord\', \'rd#\']]\n\n    """"""\n\n    def __init__(self, ngram: int = 3, reduce_dim: bool = True):\n        """"""\n        Class initialization.\n\n        :param ngram: By default use 3-gram (tri-letter).\n        :param reduce_dim: Reduce to 1-D list for sentence representation.\n        """"""\n        self._ngram = ngram\n        self._reduce_dim = reduce_dim\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Transform token into tri-letter.\n\n        For example, `word` should be represented as `#wo`,\n        `wor`, `ord` and `rd#`.\n\n        :param input_: list of tokens to be transformed.\n\n        :return n_letters: generated n_letters.\n        """"""\n        n_letters = []\n        if len(input_) == 0:\n            token_ngram = []\n            if self._reduce_dim:\n                n_letters.extend(token_ngram)\n            else:\n                n_letters.append(token_ngram)\n        else:\n            for token in input_:\n                token = \'#\' + token + \'#\'\n                token_ngram = []\n                while len(token) >= self._ngram:\n                    token_ngram.append(token[:self._ngram])\n                    token = token[1:]\n                if self._reduce_dim:\n                    n_letters.extend(token_ngram)\n                else:\n                    n_letters.append(token_ngram)\n        return n_letters\n'"
matchzoo/preprocessors/units/punc_removal.py,0,"b'import re\n\nfrom .unit import Unit\n\n\nclass PuncRemoval(Unit):\n    """"""Process unit for remove punctuations.""""""\n\n    _MATCH_PUNC = re.compile(r\'[^\\w\\s]\')\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Remove punctuations from list of tokens.\n\n        :param input_: list of toekns.\n\n        :return rv: tokens  without punctuation.\n        """"""\n        return [token for token in input_ if\n                not self._MATCH_PUNC.search(token)]\n'"
matchzoo/preprocessors/units/stateful_unit.py,0,"b'import abc\nimport typing\n\nfrom .unit import Unit\n\n\nclass StatefulUnit(Unit, metaclass=abc.ABCMeta):\n    """"""\n    Unit with inner state.\n\n    Usually need to be fit before transforming. All information gathered in the\n    fit phrase will be stored into its `context`.\n    """"""\n\n    def __init__(self):\n        """"""Initialization.""""""\n        self._context = {}\n\n    @property\n    def state(self):\n        """"""\n        Get current context. Same as `unit.context`.\n\n        Deprecated since v2.2.0, and will be removed in the future.\n        Used `unit.context` instead.\n        """"""\n        return self._context\n\n    @property\n    def context(self):\n        """"""Get current context. Same as `unit.state`.""""""\n        return self._context\n\n    @abc.abstractmethod\n    def fit(self, input_: typing.Any):\n        """"""Abstract base method, need to be implemented in subclass.""""""\n'"
matchzoo/preprocessors/units/stemming.py,0,"b'import nltk\n\nfrom .unit import Unit\n\n\nclass Stemming(Unit):\n    """"""\n    Process unit for token stemming.\n\n    :param stemmer: stemmer to use, `porter` or `lancaster`.\n    """"""\n\n    def __init__(self, stemmer=\'porter\'):\n        """"""Initialization.""""""\n        self.stemmer = stemmer\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Reducing inflected words to their word stem, base or root form.\n\n        :param input_: list of string to be stemmed.\n        """"""\n        if self.stemmer == \'porter\':\n            porter_stemmer = nltk.stem.PorterStemmer()\n            return [porter_stemmer.stem(token) for token in input_]\n        elif self.stemmer == \'lancaster\' or self.stemmer == \'krovetz\':\n            lancaster_stemmer = nltk.stem.lancaster.LancasterStemmer()\n            return [lancaster_stemmer.stem(token) for token in input_]\n        else:\n            raise ValueError(\n                \'Not supported supported stemmer type: {}\'.format(\n                    self.stemmer))\n'"
matchzoo/preprocessors/units/stop_removal.py,0,"b'import nltk\n\nfrom .unit import Unit\n\n\nclass StopRemoval(Unit):\n    """"""\n    Process unit to remove stop words.\n\n    Example:\n        >>> unit = StopRemoval()\n        >>> unit.transform([\'a\', \'the\', \'test\'])\n        [\'test\']\n        >>> type(unit.stopwords)\n        <class \'list\'>\n    """"""\n\n    def __init__(self, lang: str = \'english\'):\n        """"""Initialization.""""""\n        self._lang = lang\n        self._stop = nltk.corpus.stopwords.words(self._lang)\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Remove stopwords from list of tokenized tokens.\n\n        :param input_: list of tokenized tokens.\n        :param lang: language code for stopwords.\n\n        :return tokens: list of tokenized tokens without stopwords.\n        """"""\n        return [token\n                for token\n                in input_\n                if token not in self._stop]\n\n    @property\n    def stopwords(self) -> list:\n        """"""\n        Get stopwords based on language.\n\n        :params lang: language code.\n        :return: list of stop words.\n        """"""\n        return self._stop\n'"
matchzoo/preprocessors/units/tokenize.py,0,"b'import nltk\n\nfrom .unit import Unit\n\n\nclass Tokenize(Unit):\n    """"""Process unit for text tokenization.""""""\n\n    def transform(self, input_: str) -> list:\n        """"""\n        Process input data from raw terms to list of tokens.\n\n        :param input_: raw textual input.\n\n        :return tokens: tokenized tokens as a list.\n        """"""\n        return nltk.word_tokenize(input_)\n'"
matchzoo/preprocessors/units/truncated_length.py,0,"b'import typing\r\n\r\nimport numpy as np\r\n\r\nfrom .unit import Unit\r\n\r\n\r\nclass TruncatedLength(Unit):\r\n    """"""\r\n    TruncatedLengthUnit Class.\r\n\r\n    Process unit to truncate the text that exceeds the set length.\r\n\r\n    Examples:\r\n        >>> from matchzoo.preprocessors.units import TruncatedLength\r\n        >>> truncatedlen = TruncatedLength(3)\r\n        >>> truncatedlen.transform(list(range(1, 6))) == [3, 4, 5]\r\n        True\r\n        >>> truncatedlen.transform(list(range(2))) == [0, 1]\r\n        True\r\n\r\n    """"""\r\n\r\n    def __init__(\r\n        self,\r\n        text_length: int,\r\n        truncate_mode: str = \'pre\'\r\n    ):\r\n        """"""\r\n        Class initialization.\r\n\r\n        :param text_length: the specified maximum length of text.\r\n        :param truncate_mode: String, `pre` or `post`:\r\n            remove values from sequences larger than :attr:`text_length`,\r\n            either at the beginning or at the end of the sequences.\r\n        """"""\r\n        self._text_length = text_length\r\n        self._truncate_mode = truncate_mode\r\n\r\n    def transform(self, input_: list) -> list:\r\n        """"""\r\n        Truncate the text that exceeds the specified maximum length.\r\n\r\n        :param input_: list of tokenized tokens.\r\n\r\n        :return tokens: list of tokenized tokens in fixed length\r\n            if its origin length larger than :attr:`text_length`.\r\n        """"""\r\n        if len(input_) <= self._text_length:\r\n            truncated_tokens = input_\r\n        else:\r\n            if self._truncate_mode == \'pre\':\r\n                truncated_tokens = input_[-self._text_length:]\r\n            elif self._truncate_mode == \'post\':\r\n                truncated_tokens = input_[:self._text_length]\r\n            else:\r\n                raise ValueError(\'{} is not a vaild \'\r\n                                 \'truncate mode.\'.format(self._truncate_mode))\r\n        return truncated_tokens\r\n'"
matchzoo/preprocessors/units/unit.py,0,"b'import abc\nimport typing\n\n\nclass Unit(metaclass=abc.ABCMeta):\n    """"""Process unit do not persive state (i.e. do not need fit).""""""\n\n    @abc.abstractmethod\n    def transform(self, input_: typing.Any):\n        """"""Abstract base method, need to be implemented in subclass.""""""\n'"
matchzoo/preprocessors/units/vocabulary.py,0,"b'from .stateful_unit import StatefulUnit\n\n\nclass Vocabulary(StatefulUnit):\n    """"""\n    Vocabulary class.\n\n    :param pad_value: The string value for the padding position.\n    :param oov_value: The string value for the out-of-vocabulary terms.\n\n    Examples:\n        >>> vocab = Vocabulary(pad_value=\'[PAD]\', oov_value=\'[OOV]\')\n        >>> vocab.fit([\'A\', \'B\', \'C\', \'D\', \'E\'])\n        >>> term_index = vocab.state[\'term_index\']\n        >>> term_index  # doctest: +SKIP\n        {\'[PAD]\': 0, \'[OOV]\': 1, \'D\': 2, \'A\': 3, \'B\': 4, \'C\': 5, \'E\': 6}\n        >>> index_term = vocab.state[\'index_term\']\n        >>> index_term  # doctest: +SKIP\n        {0: \'[PAD]\', 1: \'[OOV]\', 2: \'D\', 3: \'A\', 4: \'B\', 5: \'C\', 6: \'E\'}\n\n        >>> term_index[\'out-of-vocabulary-term\']\n        1\n        >>> index_term[0]\n        \'[PAD]\'\n        >>> index_term[42]\n        Traceback (most recent call last):\n            ...\n        KeyError: 42\n        >>> a_index = term_index[\'A\']\n        >>> c_index = term_index[\'C\']\n        >>> vocab.transform([\'C\', \'A\', \'C\']) == [c_index, a_index, c_index]\n        True\n        >>> vocab.transform([\'C\', \'A\', \'[OOV]\']) == [c_index, a_index, 1]\n        True\n        >>> indices = vocab.transform(list(\'ABCDDZZZ\'))\n        >>> \' \'.join(vocab.state[\'index_term\'][i] for i in indices)\n        \'A B C D D [OOV] [OOV] [OOV]\'\n\n    """"""\n\n    def __init__(self, pad_value: str = \'<PAD>\', oov_value: str = \'<OOV>\'):\n        """"""Vocabulary unit initializer.""""""\n        super().__init__()\n        self._pad = pad_value\n        self._oov = oov_value\n        self._context[\'term_index\'] = self.TermIndex()\n        self._context[\'index_term\'] = dict()\n\n    class TermIndex(dict):\n        """"""Map term to index.""""""\n\n        def __missing__(self, key):\n            """"""Map out-of-vocabulary terms to index 1.""""""\n            return 1\n\n    def fit(self, tokens: list):\n        """"""Build a :class:`TermIndex` and a :class:`IndexTerm`.""""""\n        self._context[\'term_index\'][self._pad] = 0\n        self._context[\'term_index\'][self._oov] = 1\n        self._context[\'index_term\'][0] = self._pad\n        self._context[\'index_term\'][1] = self._oov\n\n        terms = sorted(set(tokens))\n        for index, term in enumerate(terms):\n            self._context[\'term_index\'][term] = index + 2\n            self._context[\'index_term\'][index + 2] = term\n\n    def transform(self, input_: list) -> list:\n        """"""Transform a list of tokens to corresponding indices.""""""\n        return [self._context[\'term_index\'][token] for token in input_]\n'"
matchzoo/preprocessors/units/word_exact_match.py,0,"b'import numpy as np\n\nfrom .unit import Unit\n\n\nclass WordExactMatch(Unit):\n    """"""\n    WordExactUnit Class.\n\n    Process unit to get a binary match list of two word index lists. The\n    word index list is the word representation of a text.\n\n    Examples:\n        >>> import pandas\n        >>> input_ = pandas.DataFrame({\n        ...  \'text_left\':[[1, 2, 3],[4, 5, 7, 9]],\n        ...  \'text_right\':[[5, 3, 2, 7],[2, 3, 5]]}\n        ... )\n        >>> left_word_exact_match = WordExactMatch(\n        ...     match=\'text_left\', to_match=\'text_right\'\n        ... )\n        >>> left_out = input_.apply(left_word_exact_match.transform, axis=1)\n        >>> left_out[0]\n        [0, 1, 1]\n        >>> left_out[1]\n        [0, 1, 0, 0]\n        >>> right_word_exact_match = WordExactMatch(\n        ...     match=\'text_right\', to_match=\'text_left\'\n        ... )\n        >>> right_out = input_.apply(right_word_exact_match.transform, axis=1)\n        >>> right_out[0]\n        [0, 1, 1, 0]\n        >>> right_out[1]\n        [0, 0, 1]\n\n    """"""\n\n    def __init__(\n        self,\n        match: str,\n        to_match: str\n    ):\n        """"""\n        Class initialization.\n\n        :param match: the \'match\' column name.\n        :param to_match: the \'to_match\' column name.\n        """"""\n        self._match = match\n        self._to_match = to_match\n\n    def transform(self, input_) -> list:\n        """"""\n        Transform two word index lists into a binary match list.\n\n        :param input_: a dataframe include \'match\' column and\n            \'to_match\' column.\n\n        :return: a binary match result list of two word index lists.\n        """"""\n        match_binary = []\n        for i in range(len(input_[self._match])):\n            if input_[self._match][i] in set(input_[self._to_match]):\n                match_binary.append(1)\n            else:\n                match_binary.append(0)\n\n        return match_binary\n'"
matchzoo/preprocessors/units/word_hashing.py,0,"b'import collections\n\nimport numpy as np\n\nfrom .unit import Unit\n\n\nclass WordHashing(Unit):\n    """"""\n    Word-hashing layer for DSSM-based models.\n\n    The input of :class:`WordHashingUnit` should be a list of word\n    sub-letter list extracted from one document. The output of is\n    the word-hashing representation of this document.\n\n    :class:`NgramLetterUnit` and :class:`VocabularyUnit` are two\n    essential prerequisite of :class:`WordHashingUnit`.\n\n    Examples:\n       >>> letters = [[\'#te\', \'tes\',\'est\', \'st#\'], [\'oov\']]\n       >>> word_hashing = WordHashing(\n       ...     term_index={\n       ...      \'_PAD\': 0, \'OOV\': 1, \'st#\': 2, \'#te\': 3, \'est\': 4, \'tes\': 5\n       ...      })\n       >>> hashing = word_hashing.transform(letters)\n       >>> hashing[0]\n       [0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n       >>> hashing[1]\n       [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n\n    """"""\n\n    def __init__(\n        self,\n        term_index: dict,\n    ):\n        """"""\n        Class initialization.\n\n        :param term_index: term-index mapping generated by\n            :class:`VocabularyUnit`.\n        :param dim_triletter: dimensionality of tri_leltters.\n        """"""\n        self._term_index = term_index\n\n    def transform(self, input_: list) -> list:\n        """"""\n        Transform list of :attr:`letters` into word hashing layer.\n\n        :param input_: list of `tri_letters` generated by\n            :class:`NgramLetterUnit`.\n        :return: Word hashing representation of `tri-letters`.\n        """"""\n        if any([isinstance(elem, list) for elem in input_]):\n            # The input shape for CDSSM is\n            # [[word1 ngram, ngram], [word2, ngram, ngram], ...].\n            hashing = np.zeros((len(input_), len(self._term_index)))\n            for idx, word in enumerate(input_):\n                counted_letters = collections.Counter(word)\n                for key, value in counted_letters.items():\n                    letter_id = self._term_index.get(key, 1)\n                    hashing[idx, letter_id] = value\n        else:\n            # The input shape for DSSM model [ngram, ngram, ...].\n            hashing = np.zeros(len(self._term_index))\n            counted_letters = collections.Counter(input_)\n            for key, value in counted_letters.items():\n                letter_id = self._term_index.get(key, 1)\n                hashing[letter_id] = value\n\n        return hashing.tolist()\n'"
