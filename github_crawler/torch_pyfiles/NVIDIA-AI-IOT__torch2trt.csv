file_path,api_count,code
build.py,0,"b'import imp\nimport subprocess\nimport os\nfrom string import Template\n\nPLUGINS = [\n    \'interpolate\',\n]\n\nBASE_FOLDER = \'torch2trt/converters\'\n\nNINJA_TEMPLATE = Template((\n    ""rule link\\n""\n    ""  command = g++ -shared -o $$out $$in -L$torch_dir/lib -L$cuda_dir/lib64 -L$trt_lib_dir -lc10 -lc10_cuda -ltorch -lcudart -lprotobuf -lprotobuf-lite -pthread -lpthread -lnvinfer\\n""\n    ""rule protoc\\n""\n    ""  command = protoc $$in --cpp_out=. --python_out=.\\n""\n    ""rule cxx\\n""\n    ""  command = g++ -c -fPIC $$in -I$cuda_dir/include -I$torch_dir/include -I$torch_dir/include/torch/csrc/api/include -I. -std=c++11 -I$trt_inc_dir\\n""\n))\n\nPLUGIN_TEMPLATE = Template((\n    ""build $plugin_dir/$plugin.pb.h $plugin_dir/$plugin.pb.cc $plugin_dir/${plugin}_pb2.py: protoc $plugin_dir/$plugin.proto\\n""\n    ""build $plugin.pb.o: cxx $plugin_dir/$plugin.pb.cc\\n""\n    ""build $plugin.o: cxx $plugin_dir/$plugin.cpp\\n""\n))\n\n\ndef build(cuda_dir=""/usr/local/cuda"",\n          torch_dir=imp.find_module(\'torch\')[1],\n          trt_inc_dir=""/usr/include/aarch64-linux-gnu"",\n          trt_lib_dir=""/usr/lib/aarch64-linux-gnu""):\n\n    global PLUGINS, BASE_FOLDER, NINJA_TEMPLATE, PLUGIN_TEMPLATE\n\n    NINJA_STR = NINJA_TEMPLATE.substitute({\n        \'torch_dir\': torch_dir,\n        \'cuda_dir\': cuda_dir,\n        \'trt_inc_dir\': trt_inc_dir,\n        \'trt_lib_dir\': trt_lib_dir,\n    })\n\n\n    plugin_o_files = []\n    for plugin in PLUGINS:\n        NINJA_STR += \\\n            PLUGIN_TEMPLATE.substitute({\n                \'plugin\': plugin,\n                \'plugin_dir\': os.path.join(BASE_FOLDER, plugin),\n            })\n        plugin_o_files += [plugin + \'.pb.o\', plugin + \'.o\']\n\n    NINJA_STR += Template((\n        ""build torch2trt/libtorch2trt.so: link $o_files\\n""\n    )).substitute({\'o_files\': \' \'.join(plugin_o_files)})\n\n    with open(\'build.ninja\', \'w\') as f:\n        f.write(NINJA_STR)\n\n    subprocess.call([\'ninja\'])\n\n\nif __name__ == \'__main__\':\n    build()\n'"
setup.py,0,"b'import os\nimport glob\nimport shutil\nfrom setuptools import setup, find_packages\nfrom setuptools.command.install import install\nfrom setuptools.command.develop import develop\nfrom distutils.cmd import Command\nfrom build import build\n\npackage_data = {}\n\nplugins_user_options = [\n    (\'plugins\', None, \'Build plugins\'),\n    (\'cuda-dir=\', None, \'Location of CUDA (if not default location)\'),\n    (\'torch-dir=\', None, \'Location of PyTorch (if not default location)\'),\n    (\'trt-inc-dir=\', None, \'Location of TensorRT include files (if not default location)\'),\n    (\'trt-lib-dir=\', None, \'Location of TensorRT libraries (if not default location)\'),\n]\n\n\ndef initialize_plugins_options(cmd_obj):\n    cmd_obj.plugins = False\n    cmd_obj.cuda_dir = None\n    cmd_obj.torch_dir = None\n    cmd_obj.trt_inc_dir = None\n    cmd_obj.trt_lib_dir = None\n\n\ndef run_plugins_compilation(cmd_obj):\n    if cmd_obj.plugins:\n        build_args = {}\n        if cmd_obj.cuda_dir:\n            build_args[\'cuda_dir\'] = cmd_obj.cuda_dir\n        if cmd_obj.torch_dir:\n            build_args[\'torch_dir\'] = cmd_obj.torch_dir\n        if cmd_obj.trt_inc_dir:\n            build_args[\'trt_inc_dir\'] = cmd_obj.trt_inc_dir\n        if cmd_obj.trt_lib_dir:\n            build_args[\'trt_lib_dir\'] = cmd_obj.trt_lib_dir\n\n        print(\'Building in plugin support\')\n        build(**build_args)\n        package_data[\'torch2trt\'] = [\'libtorch2trt.so\']\n\n\nclass DevelopCommand(develop):\n    description = ""Builds the package and symlinks it into the PYTHONPATH""\n    user_options = develop.user_options + plugins_user_options\n\n    def initialize_options(self):\n        develop.initialize_options(self)\n        initialize_plugins_options(self)\n\n    def finalize_options(self):\n        develop.finalize_options(self)\n\n    def run(self):\n        run_plugins_compilation(self)\n        develop.run(self)\n\n\nclass InstallCommand(install):\n    description = ""Builds the package""\n    user_options = install.user_options + plugins_user_options\n\n    def initialize_options(self):\n        install.initialize_options(self)\n        initialize_plugins_options(self)\n\n    def finalize_options(self):\n        install.finalize_options(self)\n\n    def run(self):\n        run_plugins_compilation(self)\n        install.run(self)\n\n\nclass CleanCommand(Command):\n    """"""Custom clean command to tidy up the project root.""""""\n    PY_CLEAN_FILES = [\'./build\', \'./dist\', \'./__pycache__\', \'./*.pyc\', \'./*.tgz\', \'./*.egg-info\']\n    description = ""Command to tidy up the project root""\n    user_options = []\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        pass\n\n    def run(self):\n        root_dir = os.path.dirname(os.path.realpath(__file__))\n        for path_spec in self.PY_CLEAN_FILES:\n            # Make paths absolute and relative to this path\n            abs_paths = glob.glob(os.path.normpath(os.path.join(root_dir, path_spec)))\n            for path in [str(p) for p in abs_paths]:\n                if not path.startswith(root_dir):\n                    # Die if path in CLEAN_FILES is absolute + outside this directory\n                    raise ValueError(""%s is not a path inside %s"" % (path, root_dir))\n                print(\'Removing %s\' % os.path.relpath(path))\n                shutil.rmtree(path)\n\n        cmd_list = {\n            ""Removing generated protobuf cc files"": ""find . -name \'*.pb.cc\' -print0 | xargs -0 rm -f;"",\n            ""Removing generated protobuf h files"": ""find . -name \'*.pb.h\' -print0 | xargs -0 rm -f;"",\n            ""Removing generated protobuf py files"": ""find . -name \'*_pb2.py\' -print0 | xargs -0 rm -f;"",\n            ""Removing generated ninja files"": ""find . -name \'*.ninja*\' -print0 | xargs -0 rm -f;"",\n            ""Removing generated o files"": ""find . -name \'*.o\' -print0 | xargs -0 rm -f;"",\n            ""Removing generated so files"": ""find . -name \'*.so\' -print0 | xargs -0 rm -f;"",\n        }\n\n        for cmd, script in cmd_list.items():\n            print(""{}"".format(cmd))\n            os.system(script)\n\n\nsetup(\n    name=\'torch2trt\',\n    version=\'0.0.3\',\n    description=\'An easy to use PyTorch to TensorRT converter\',\n    cmdclass={\n        \'install\': InstallCommand,\n        \'clean\': CleanCommand,\n        \'develop\': DevelopCommand,\n    },\n    packages=find_packages(),\n    package_data=package_data\n)\n'"
torch2trt/__init__.py,0,"b""from .torch2trt import *\nfrom .converters import *\nimport tensorrt as trt\n\n\ndef load_plugins():\n    import os\n    import ctypes\n    ctypes.CDLL(os.path.join(os.path.dirname(__file__), 'libtorch2trt.so'))\n    \n    registry = trt.get_plugin_registry()\n    torch2trt_creators = [c for c in registry.plugin_creator_list if c.plugin_namespace == 'torch2trt']\n    for c in torch2trt_creators:\n        registry.register_creator(c, 'torch2trt')\n\n\ntry:\n    load_plugins()\n    PLUGINS_LOADED = True\nexcept OSError:\n    PLUGINS_LOADED = False\n"""
torch2trt/calibration.py,1,"b""import torch\nimport tensorrt as trt\n\n\nif trt.__version__ >= '5.1':\n    DEFAULT_CALIBRATION_ALGORITHM = trt.CalibrationAlgoType.ENTROPY_CALIBRATION_2\nelse:\n    DEFAULT_CALIBRATION_ALGORITHM = trt.CalibrationAlgoType.ENTROPY_CALIBRATION\n    \n\nclass TensorBatchDataset():\n    \n    def __init__(self, tensors):\n        self.tensors = tensors\n    \n    def __len__(self):\n        return len(self.tensors[0])\n    \n    def __getitem__(self, idx):\n        return [t[idx] for t in self.tensors]\n    \n    \nclass DatasetCalibrator(trt.IInt8Calibrator):\n    \n    def __init__(self, inputs, dataset, batch_size=1, algorithm=DEFAULT_CALIBRATION_ALGORITHM):\n        super(DatasetCalibrator, self).__init__()\n        \n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.algorithm = algorithm\n        \n        # create buffers that will hold data batches\n        self.buffers = []\n        for tensor in inputs:\n            size = (batch_size,) + tuple(tensor.shape[1:])\n            buf = torch.zeros(size=size, dtype=tensor.dtype, device=tensor.device).contiguous()\n            self.buffers.append(buf)\n            \n        self.count = 0\n        \n    def get_batch(self, *args, **kwargs):\n        if self.count < len(self.dataset):\n            \n            for i in range(self.batch_size):\n                \n                idx = self.count % len(self.dataset) # roll around if not multiple of dataset\n                inputs = self.dataset[idx]\n                \n                # copy data for (input_idx, dataset_idx) into buffer\n                for buffer, tensor in zip(self.buffers, inputs):\n                    buffer[i].copy_(tensor)\n                \n                self.count += 1\n                \n            return [int(buf.data_ptr()) for buf in self.buffers]\n        else:\n            return []\n        \n    def get_algorithm(self):\n        return self.algorithm\n    \n    def get_batch_size(self):\n        return self.batch_size\n    \n    def read_calibration_cache(self, *args, **kwargs):\n        return None\n    \n    def write_calibration_cache(self, cache, *args, **kwargs):\n        pass"""
torch2trt/module_test.py,0,"b""import torch\nimport torchvision\n\n\nclass ModuleTest(object):\n    def __init__(self, module_fn, dtype, device, input_shapes, **torch2trt_kwargs):\n        self.module_fn = module_fn\n        self.dtype = dtype\n        self.device = device\n        self.input_shapes = input_shapes\n        self.torch2trt_kwargs = torch2trt_kwargs\n        \n    def module_name(self):\n        return self.module_fn.__module__ + '.' + self.module_fn.__name__\n\n\nMODULE_TESTS = [\n]\n\n\ndef add_module_test(dtype, device, input_shapes, **torch2trt_kwargs):\n    def register_module_test(module):\n        global MODULE_TESTS\n        MODULE_TESTS += [ModuleTest(module, dtype, device, input_shapes, **torch2trt_kwargs)]\n        return module\n    return register_module_test"""
torch2trt/test.py,11,"b""from torch2trt import *\nfrom .module_test import ModuleTest, MODULE_TESTS\nimport time\nimport argparse\nimport re\nimport runpy\nfrom termcolor import colored\n\n\ndef run(self):\n    # create module\n    module = self.module_fn()\n    module = module.to(self.device)\n    module = module.type(self.dtype)\n    module = module.eval()\n    \n    # create inputs for conversion\n    inputs_conversion = ()\n    for shape in self.input_shapes:\n        inputs_conversion += (torch.zeros(shape).to(self.device).type(self.dtype), )\n        \n    # convert module\n    module_trt = torch2trt(module, inputs_conversion, **self.torch2trt_kwargs)\n\n    # create inputs for torch/trt.. copy of inputs to handle inplace ops\n    inputs = ()\n    for shape in self.input_shapes:\n        inputs += (torch.randn(shape).to(self.device).type(self.dtype), )\n    inputs_trt = tuple([tensor.clone() for tensor in inputs])\n\n\n    # test output against original\n    outputs = module(*inputs)\n    outputs_trt = module_trt(*inputs_trt)\n\n    if not isinstance(outputs, tuple):\n        outputs = (outputs, )\n    \n    # compute max error\n    max_error = 0\n    for i in range(len(outputs)):\n        max_error_i = torch.max(torch.abs(outputs[i] - outputs_trt[i]))\n        if max_error_i > max_error:\n            max_error = max_error_i\n    \n    # benchmark pytorch throughput\n    torch.cuda.current_stream().synchronize()\n    t0 = time.time()\n    for i in range(50):\n        outputs = module(*inputs)\n    torch.cuda.current_stream().synchronize()\n    t1 = time.time()\n    \n    fps = 50.0 / (t1 - t0)\n    \n    # benchmark tensorrt throughput\n    torch.cuda.current_stream().synchronize()\n    t0 = time.time()\n    for i in range(50):\n        outputs = module_trt(*inputs)\n    torch.cuda.current_stream().synchronize()\n    t1 = time.time()\n    \n    fps_trt = 50.0 / (t1 - t0)\n    \n    # benchmark pytorch latency\n    torch.cuda.current_stream().synchronize()\n    t0 = time.time()\n    for i in range(50):\n        outputs = module(*inputs)\n        torch.cuda.current_stream().synchronize()\n    t1 = time.time()\n    \n    ms = 1000.0 * (t1 - t0) / 50.0\n    \n    # benchmark tensorrt latency\n    torch.cuda.current_stream().synchronize()\n    t0 = time.time()\n    for i in range(50):\n        outputs = module_trt(*inputs)\n        torch.cuda.current_stream().synchronize()\n    t1 = time.time()\n    \n    ms_trt = 1000.0 * (t1 - t0) / 50.0\n    \n    return max_error, fps, fps_trt, ms, ms_trt\n        \n        \nif __name__ == '__main__':\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument('--output', '-o', help='Test output file path', type=str, default='torch2trt_test.md')\n    parser.add_argument('--name', help='Regular expression to filter modules to test by name', type=str, default='.*')\n    parser.add_argument('--tolerance', help='Maximum error to print warning for entry', type=float, default='-1')\n    parser.add_argument('--include', help='Addition python file to include defining additional tests', action='append', default=[])\n    args = parser.parse_args()\n    \n    for include in args.include:\n        runpy.run_module(include)\n        \n    for test in MODULE_TESTS:\n        \n        # filter by module name\n        name = test.module_name()\n        if not re.search(args.name, name):\n            continue\n            \n        # run test\n        max_error, fps, fps_trt, ms, ms_trt = run(test)\n        \n        # write entry\n        line = '| %s | %s | %s | %s | %.2E | %.3g | %.3g | %.3g | %.3g |' % (name, test.dtype.__repr__().split('.')[-1], str(test.input_shapes), str(test.torch2trt_kwargs), max_error, fps, fps_trt, ms, ms_trt)\n\n        if args.tolerance >= 0 and max_error > args.tolerance:\n            print(colored(line, 'yellow'))\n        else:\n            print(line)\n\n        with open(args.output, 'a+') as f:\n            f.write(line + '\\n')\n"""
torch2trt/torch2trt.py,20,"b'import torch\nimport tensorrt as trt\nfrom copy import copy\nimport numpy as np\nfrom .calibration import TensorBatchDataset, DatasetCalibrator, DEFAULT_CALIBRATION_ALGORITHM\n\n\n# UTILITY FUNCTIONS\n\n\ndef torch_dtype_to_trt(dtype):\n    if dtype == torch.int8:\n        return trt.int8\n    elif dtype == torch.int32:\n        return trt.int32\n    elif dtype == torch.float16:\n        return trt.float16\n    elif dtype == torch.float32:\n        return trt.float32\n    else:\n        raise TypeError(\'%s is not supported by tensorrt\' % dtype)\n\n\ndef torch_dtype_from_trt(dtype):\n    if dtype == trt.int8:\n        return torch.int8\n    elif dtype == trt.int32:\n        return torch.int32\n    elif dtype == trt.float16:\n        return torch.float16\n    elif dtype == trt.float32:\n        return torch.float32\n    else:\n        raise TypeError(\'%s is not supported by torch\' % dtype)\n\n\ndef torch_device_to_trt(device):\n    if device.type == torch.device(\'cuda\').type:\n        return trt.TensorLocation.DEVICE\n    elif device.type == torch.device(\'cpu\').type:\n        return trt.TensorLocation.HOST\n    else:\n        return TypeError(\'%s is not supported by tensorrt\' % device)\n\n\ndef torch_device_from_trt(device):\n    if device == trt.TensorLocation.DEVICE:\n        return torch.device(\'cuda\')\n    elif device == trt.TensorLocation.HOST:\n        return torch.device(\'cpu\')\n    else:\n        return TypeError(\'%s is not supported by torch\' % device)\n    \n\ndef trt_num_inputs(engine):\n    count = 0\n    for i in range(engine.num_bindings):\n        if engine.binding_is_input(i):\n            count += 1\n    return count\n    \n\ndef trt_num_outputs(engine):\n    count = 0\n    for i in range(engine.num_bindings):\n        if not engine.binding_is_input(i):\n            count += 1\n    return count\n\n\ndef torch_dim_to_trt_axes(dim):\n    """"""Converts torch dim, or tuple of dims to a tensorrt axes bitmask""""""\n    if not isinstance(dim, tuple):\n        dim = (dim, )\n        \n    # create axes bitmask for reduce layer\n    axes = 0\n    for d in dim:\n        axes |= 1 << (d - 1) # -1 to remove batch dimension\n        \n    return axes\n    \n    \ndef add_trt_constant(network, tensor):\n    shape = tuple(tensor.shape[1:])\n    array = tensor[0].detach().cpu().numpy()\n    layer = network.add_constant(shape, array)\n    return layer.get_output(0)\n\n\ndef check_torch_dtype(*tensors):\n    dtype = None\n    for t in tensors:\n        if isinstance(t, torch.Tensor):\n            if dtype is None:\n                dtype = t.dtype\n            else:\n                assert(dtype == t.dtype)#, \'Tensor data types must match\')\n    assert(dtype is not None)#, \'Data type could not be inferred from any item in list\')\n    return dtype\n    \n\ndef trt_(network, *tensors):\n    """"""Creates missing TensorRT tensors and adds shuffle layers to make tensors broadcastable""""""\n    trt_tensors = [None] * len(tensors)\n    \n    dtype = check_torch_dtype(*tensors)\n    \n    # get broadcast dimension\n    broadcast_num_dim = 0\n    for t in tensors:\n        if isinstance(t, torch.Tensor):\n            if not hasattr(t, \'_trt\'):\n                num_dim = len(t.shape) # don\'t exclude batch for constants\n            else:\n                num_dim = len(t._trt.shape) # non-leaf tensors must already have _trt, get shape from that\n            if num_dim > broadcast_num_dim:\n                broadcast_num_dim = num_dim\n    \n    \n    for i, t in enumerate(tensors):\n        trt_tensor = None\n        \n        # GET TRT TENSOR (OR CREATE TRT CONSTANT)\n        \n        # get tensor w/ _trt\n        if isinstance(t, torch.Tensor) and hasattr(t, \'_trt\'):\n            trt_tensor = t._trt\n            \n        # or... add constant for leaf tensor w/o _trt\n        elif isinstance(t, torch.Tensor) and not hasattr(t, \'_trt\'):\n            # add leaf tensor\n            shape = tuple(t.shape) #  don\'t exclude batch when adding constants...?\n            weight = t.detach().cpu().numpy()\n            t._trt = network.add_constant(shape, weight).get_output(0)\n            trt_tensor = t._trt\n        \n        # or... add constant for scalar primitive\n        elif isinstance(t, float) or isinstance(t, int):\n            shape = (1,) * broadcast_num_dim\n            scalar = t * torch.ones(shape, dtype=dtype).cpu().numpy()\n            trt_tensor = network.add_constant(shape, scalar).get_output(0)\n            \n        assert(trt_tensor is not None)\n            \n        # MAKE TRT TENSOR BROADCASTABLE IF IT IS NOT ALREADY\n        \n        if len(trt_tensor.shape) < broadcast_num_dim:\n            # append 1 size dims to front\n            diff = broadcast_num_dim - len(trt_tensor.shape)\n            shape = tuple([1] * diff + list(trt_tensor.shape))\n            layer = network.add_shuffle(trt_tensor)\n            layer.reshape_dims = shape\n            trt_tensor = layer.get_output(0)\n            \n        trt_tensors[i] = trt_tensor\n    \n    if len(trt_tensors) == 1:\n        return trt_tensors[0]\n    else:\n        return tuple(trt_tensors)\n        \n\n# CONVERSION REGISTRY AND HOOKS\n\n\nCONVERTERS = {}\n    \n    \ndef get_arg(ctx, name, pos, default):\n    if name in ctx.method_kwargs:\n        return ctx.method_kwargs[name]\n    elif len(ctx.method_args) > pos:\n        return ctx.method_args[pos]\n    else:\n        return default\n    \n\ndef attach_converter(ctx, method, converter, method_str):\n    """"""Gets a function that executes PyTorch method and TensorRT converter""""""\n    global DUMMY_CONVERTERS\n    \n    def wrapper(*args, **kwargs):\n        skip = True\n            \n        # check if another (parent) converter has lock\n        if not ctx.lock:\n            if converter[\'is_real\']:\n                ctx.lock = True  # only real converters can acquire lock\n            skip = False\n\n        # run original method\n        outputs = method(*args, **kwargs)\n        \n        if not skip:\n            ctx.method_args = args\n            ctx.method_kwargs = kwargs\n            ctx.method_return = outputs\n            ctx.method_str = method_str\n                \n#             print(\'%s\' % (converter.__name__,))\n            converter[\'converter\'](ctx)\n\n            # convert to None so conversion will fail for unsupported layers\n            ctx.method_args = None\n            ctx.method_kwargs = None\n            ctx.method_return = None\n            ctx.lock = False\n\n        return outputs\n\n    return wrapper\n\n\nclass ConversionHook(object):\n    """"""Attaches TensorRT converter to PyTorch method call""""""\n\n    def __init__(self, ctx, method, converter):\n        self.ctx = ctx\n        self.method_str = method\n        self.converter = converter\n\n    def _set_method(self, method):\n        exec(\'%s = method\' % self.method_str)\n\n    def __enter__(self):\n        try:\n            self.method_impl = eval(self.method_str)\n        except AttributeError:\n            self.method_impl = None\n        \n        if self.method_impl:\n            self._set_method(attach_converter(self.ctx, self.method_impl, self.converter, self.method_str))\n\n    def __exit__(self, type, val, tb):\n        if self.method_impl:\n            self._set_method(self.method_impl)\n\n\nclass ConversionContext(object):\n    def __init__(self, network, converters=CONVERTERS):\n        self.network = network\n        self.lock = False\n        self.method_args = None\n        self.method_kwargs = None\n        self.method_return = None\n        self.hooks = [\n            ConversionHook(self, method, converter)\n            for method, converter in converters.items()\n        ]\n\n    def __enter__(self):\n        for hook in self.hooks:\n            hook.__enter__()\n        return self\n\n    def __exit__(self, type, val, tb):\n        for hook in self.hooks:\n            hook.__exit__(type, val, tb)\n\n    def add_inputs(self, torch_inputs, names=None):\n        if names is None:\n            names = [\'input_%d\' % i for i in range(len(torch_inputs))]\n        self.input_names = names\n\n        for i, torch_input in enumerate(torch_inputs):\n            if not hasattr(torch_input, \'_trt\'):\n                trt_tensor = self.network.add_input(\n                    name=names[i],\n                    shape=tuple(torch_input.shape)[1:],\n                    dtype=torch_dtype_to_trt(torch_input.dtype),\n                )\n                trt_tensor.location = torch_device_to_trt(torch_input.device)\n                torch_input._trt = trt_tensor\n\n    def mark_outputs(self, torch_outputs, names=None):\n        if names is None:\n            names = [\'output_%d\' % i for i in range(len(torch_outputs))]\n        self.output_names = names\n\n        for i, torch_output in enumerate(torch_outputs):\n            trt_tensor = torch_output._trt\n            trt_tensor.name = names[i]\n            trt_tensor.location = torch_device_to_trt(torch_output.device)\n            trt_tensor.dtype = torch_dtype_to_trt(torch_output.dtype)\n            self.network.mark_output(trt_tensor)\n\n\nclass TRTModule(torch.nn.Module):\n    def __init__(self, engine=None, input_names=None, output_names=None):\n        super(TRTModule, self).__init__()\n        self._register_state_dict_hook(TRTModule._on_state_dict)\n        self.engine = engine\n        if self.engine is not None:\n            self.context = self.engine.create_execution_context()\n        self.input_names = input_names\n        self.output_names = output_names\n    \n    def _on_state_dict(self, state_dict, prefix, local_metadata):\n        state_dict[prefix + \'engine\'] = bytearray(self.engine.serialize())\n        state_dict[prefix + \'input_names\'] = self.input_names\n        state_dict[prefix + \'output_names\'] = self.output_names\n    \n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs):\n        engine_bytes = state_dict[prefix + \'engine\']\n        \n        with trt.Logger() as logger, trt.Runtime(logger) as runtime:\n            self.engine = runtime.deserialize_cuda_engine(engine_bytes)\n            self.context = self.engine.create_execution_context()\n            \n        self.input_names = state_dict[prefix + \'input_names\']\n        self.output_names = state_dict[prefix + \'output_names\']\n        \n    def forward(self, *inputs):\n        batch_size = inputs[0].shape[0]\n        bindings = [None] * (len(self.input_names) + len(self.output_names))\n\n        # create output tensors\n        outputs = [None] * len(self.output_names)\n        for i, output_name in enumerate(self.output_names):\n            idx = self.engine.get_binding_index(output_name)\n            dtype = torch_dtype_from_trt(self.engine.get_binding_dtype(idx))\n            shape = (batch_size, ) + tuple(self.engine.get_binding_shape(idx))\n            device = torch_device_from_trt(self.engine.get_location(idx))\n            output = torch.empty(size=shape, dtype=dtype, device=device)\n            outputs[i] = output\n            bindings[idx] = output.data_ptr()\n\n        for i, input_name in enumerate(self.input_names):\n            idx = self.engine.get_binding_index(input_name)\n            bindings[idx] = inputs[i].data_ptr()\n\n        self.context.execute_async(batch_size, bindings, torch.cuda.current_stream().cuda_stream)\n\n        outputs = tuple(outputs)\n        if len(outputs) == 1:\n            outputs = outputs[0]\n\n        return outputs\n    \n    def enable_profiling(self):\n        if not self.context.profiler:\n            self.context.profiler = trt.Profiler()\n\n\ndef torch2trt(module, \n              inputs, \n              input_names=None, \n              output_names=None, \n              log_level=trt.Logger.ERROR, \n              max_batch_size=1,\n              fp16_mode=False, \n              max_workspace_size=1<<25, \n              strict_type_constraints=False, \n              keep_network=True, \n              int8_mode=False, \n              int8_calib_dataset=None,\n              int8_calib_algorithm=DEFAULT_CALIBRATION_ALGORITHM):\n\n    inputs_in = inputs\n    \n    # copy inputs to avoid modifications to source data\n    inputs = [tensor.clone()[0:1] for tensor in inputs]  # only run single entry\n    \n    logger = trt.Logger(log_level)\n    builder = trt.Builder(logger)\n    network = builder.create_network()\n    \n    with ConversionContext(network) as ctx:\n\n        if isinstance(inputs, list):\n            inputs = tuple(inputs)\n        if not isinstance(inputs, tuple):\n            inputs = (inputs, )\n        ctx.add_inputs(inputs, input_names)\n\n        outputs = module(*inputs)\n\n        if not isinstance(outputs, tuple) and not isinstance(outputs, list):\n            outputs = (outputs, )\n        ctx.mark_outputs(outputs, output_names)\n\n    builder.max_workspace_size = max_workspace_size\n    builder.fp16_mode = fp16_mode\n    builder.max_batch_size = max_batch_size\n    builder.strict_type_constraints = strict_type_constraints\n    \n    if int8_mode:\n        \n        # default to use input tensors for calibration\n        if int8_calib_dataset is None:\n            int8_calib_dataset = TensorBatchDataset(inputs_in)\n        \n        builder.int8_mode = True\n        \n        # @TODO(jwelsh):  Should we set batch_size=max_batch_size?  Need to investigate memory consumption\n        builder.int8_calibrator = DatasetCalibrator(inputs, int8_calib_dataset, batch_size=1, algorithm=int8_calib_algorithm)\n\n    engine = builder.build_cuda_engine(network)\n    \n    module_trt = TRTModule(engine, ctx.input_names, ctx.output_names)\n        \n    if keep_network:\n        module_trt.network = network\n            \n    return module_trt\n\n\n# DEFINE ALL CONVERSION FUNCTIONS\n\n\ndef tensorrt_converter(method, is_real=True):\n    def register_converter(converter):\n        CONVERTERS[method] = {\'converter\': converter, \'is_real\': is_real}\n        return converter\n    return register_converter\n'"
torch2trt/utils.py,0,"b""import graphviz\n\n\ndef trt_network_to_dot_graph(network):\n    dot = graphviz.Digraph(comment='Network')\n    \n    # add nodes (layers)\n    for i in range(network.num_layers):\n        layer = network.get_layer(i)\n        dot.node(layer.name)\n        \n    # add nodes (inputs)\n    for i in range(network.num_inputs):\n        dot.node(network.get_input(i).name)\n        \n    # add nodes (outputs)\n    for i in range(network.num_outputs):\n        dot.node(network.get_output(i).name)\n        \n    # add layer->layer edges\n    for a in range(network.num_layers):\n        layer_a = network.get_layer(a)\n        \n        for b in range(network.num_layers):\n            layer_b = network.get_layer(b)\n            \n            for i in range(layer_a.num_outputs):\n                output_i = layer_a.get_output(i)\n                \n                for j in range(layer_b.num_inputs):\n                    input_j = layer_b.get_input(j)\n                    \n                    if output_i == input_j:\n                        dot.edge(layer_a.name, layer_b.name, label=str(input_j.shape))\n      \n    # add input->layer edges\n    for i in range(network.num_inputs):\n        input_i = network.get_input(i)\n        \n        for b in range(network.num_layers):\n            layer_b = network.get_layer(b)\n            \n            for j in range(layer_b.num_inputs):\n                input_j = layer_b.get_input(j)\n\n                if input_i == input_j:\n                    dot.edge(input_i.name, layer_b.name, label=str(input_j.shape))\n                    \n    # add layer->output edges\n    for i in range(network.num_outputs):\n        input_i = network.get_output(i)\n        \n        for b in range(network.num_layers):\n            layer_b = network.get_layer(b)\n            \n            for j in range(layer_b.num_outputs):\n                input_j = layer_b.get_output(j)\n\n                if input_i == input_j:\n                    dot.edge(layer_b.name, input_i.name, label=str(input_j.shape))\n                    \n    return dot"""
torch2trt/converters/AdaptiveAvgPool2d.py,7,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.AdaptiveAvgPool2d.forward')\ndef convert_AdaptiveAvgPool2d(ctx):\n    module = ctx.method_args[0]\n    input = ctx.method_args[1]\n    output = ctx.method_return\n    \n    input_trt = trt_(ctx.network, input)\n\n    output_size = module.output_size\n    if not isinstance(output_size, tuple):\n        output_size = (output_size, ) * 2\n\n    stride = (input_trt.shape[-2] // output_size[-2], input_trt.shape[-1] // output_size[-1])\n\n    kernel_size = stride\n    layer = ctx.network.add_pooling(\n        input=input_trt, type=trt.PoolingType.AVERAGE, window_size=kernel_size)\n    layer.stride = stride\n\n    output._trt = layer.get_output(0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_AdaptiveAvgPool2d_1x1():\n    return torch.nn.AdaptiveAvgPool2d((1, 1))\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_AdaptiveAvgPool2d_2x2():\n    return torch.nn.AdaptiveAvgPool2d((2, 2))\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_AdaptiveAvgPool2d_3x3():\n    return torch.nn.AdaptiveAvgPool2d((3, 3))\n"""
torch2trt/converters/BatchNorm1d.py,4,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.BatchNorm1d.forward')\ndef convert_BatchNorm2d(ctx):\n    module = ctx.method_args[0]\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    \n    scale = module.weight.detach().cpu().numpy() / np.sqrt(module.running_var.detach().cpu().numpy() + module.eps)\n    bias = module.bias.detach().cpu().numpy() - module.running_mean.detach().cpu().numpy() * scale\n    power = np.ones_like(scale)\n    \n    # reshape to 2D\n    layer = ctx.network.add_shuffle(input_trt)\n    \n    if len(input.shape) == 2:\n        layer.reshape_dims = (input.shape[1], 1, 1)\n    else:\n        layer.reshape_dims = (input.shape[1], input.shape[2], 1)\n    \n    layer = ctx.network.add_scale(layer.get_output(0), trt.ScaleMode.CHANNEL, bias, scale, power)\n\n    # reshape back to 1D\n    layer = ctx.network.add_shuffle(layer.get_output(0))\n    layer.reshape_dims = tuple(output.shape[1:])\n    \n    output._trt = layer.get_output(0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3)])\ndef test_BatchNorm1d_basic():\n    return torch.nn.BatchNorm1d(10)"""
torch2trt/converters/BatchNorm2d.py,1,"b""from torch2trt.torch2trt import *\n\n\n@tensorrt_converter('torch.nn.BatchNorm2d.forward')\ndef convert_BatchNorm2d(ctx):\n    module = ctx.method_args[0]\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    \n    scale = module.weight.detach().cpu().numpy() / np.sqrt(module.running_var.detach().cpu().numpy() + module.eps)\n    bias = module.bias.detach().cpu().numpy() - module.running_mean.detach().cpu().numpy() * scale\n    power = np.ones_like(scale)\n    \n    layer = ctx.network.add_scale(input_trt, trt.ScaleMode.CHANNEL, bias, scale, power)\n\n    output._trt = layer.get_output(0)"""
torch2trt/converters/Conv1d.py,9,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.Conv1d.forward')\ndef convert_Conv1d(ctx):\n    module = ctx.method_args[0]\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n\n    kernel_size = (module.kernel_size[0], 1)\n    stride = (module.stride[0], 1)\n    padding = (module.padding[0], 0)\n    dilation = (module.dilation[0], 1)\n\n    kernel = module.weight.detach().cpu().numpy()[..., None]\n    \n    bias = trt.Weights(torch_dtype_to_trt(module.weight.dtype))\n    if module.bias is not None:\n        bias = module.bias.detach().cpu().numpy()\n        \n    # reshape to 2D\n    layer = ctx.network.add_shuffle(input_trt)\n    layer.reshape_dims = (-1, input.shape[-1], 1)\n    \n    layer = ctx.network.add_convolution(\n        input=layer.get_output(0),\n        num_output_maps=module.out_channels,\n        kernel_shape=kernel_size,\n        kernel=kernel,\n        bias=bias)\n    layer.stride = stride\n    layer.padding = padding\n    layer.dilation = dilation\n\n    if module.groups is not None:\n        layer.num_groups = module.groups\n        \n    # reshape back to 1D\n    layer = ctx.network.add_shuffle(layer.get_output(0))\n    layer.reshape_dims = (-1, output.shape[-1])\n\n    output._trt = layer.get_output(0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 224)])\ndef test_Conv1d_basic():\n    return torch.nn.Conv1d(10, 5, kernel_size=1, stride=1, padding=0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 224)])\ndef test_Conv1d_stride2():\n    return torch.nn.Conv1d(10, 5, kernel_size=1, stride=2, padding=0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 224)])\ndef test_Conv1d_kernel3():\n    return torch.nn.Conv1d(10, 5, kernel_size=3, stride=2, padding=1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 224)])\ndef test_Conv1d_dilation2():\n    return torch.nn.Conv1d(10, 5, kernel_size=3, stride=1, padding=1, dilation=2)\n"""
torch2trt/converters/Conv2d.py,9,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.Conv2d.forward')\ndef convert_Conv2d(ctx):\n    module = ctx.method_args[0]\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n\n    kernel_size = module.kernel_size\n    if not isinstance(kernel_size, tuple):\n        kernel_size = (kernel_size, ) * 2\n\n    stride = module.stride\n    if not isinstance(stride, tuple):\n        stride = (stride, ) * 2\n\n    padding = module.padding\n    if not isinstance(padding, tuple):\n        padding = (padding, ) * 2\n\n    dilation = module.dilation\n    if not isinstance(dilation, tuple):\n        dilation = (dilation, ) * 2\n\n    kernel = module.weight.detach().cpu().numpy()\n    \n    bias = trt.Weights(torch_dtype_to_trt(module.weight.dtype))\n    if module.bias is not None:\n        bias = module.bias.detach().cpu().numpy()\n\n    layer = ctx.network.add_convolution(\n        input=input_trt,\n        num_output_maps=module.out_channels,\n        kernel_shape=kernel_size,\n        kernel=kernel,\n        bias=bias)\n    layer.stride = stride\n    layer.padding = padding\n    layer.dilation = dilation\n\n    if module.groups is not None:\n        layer.num_groups = module.groups\n\n    output._trt = layer.get_output(0)\n\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 224, 224)])\ndef test_Conv2d_basic():\n    return torch.nn.Conv2d(10, 5, kernel_size=1, stride=1, padding=0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 224, 224)])\ndef test_Conv2d_stride2():\n    return torch.nn.Conv2d(10, 5, kernel_size=1, stride=2, padding=0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 224, 224)])\ndef test_Conv2d_kernel3():\n    return torch.nn.Conv2d(10, 5, kernel_size=3, stride=2, padding=1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 224, 224)])\ndef test_Conv2d_dilation2():\n    return torch.nn.Conv2d(10, 5, kernel_size=3, stride=1, padding=1, dilation=2)\n"""
torch2trt/converters/ConvTranspose2d.py,10,"b'from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n@tensorrt_converter(\'torch.nn.ConvTranspose2d.forward\')\ndef convert_ConvTranspose2d(ctx):\n    module = ctx.method_args[0]\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n\n    kernel_size = module.kernel_size\n    if not isinstance(kernel_size, tuple):\n        kernel_size = (kernel_size, ) * 2\n\n    stride = module.stride\n    if not isinstance(stride, tuple):\n        stride = (stride, ) * 2\n\n    padding = module.padding\n    if not isinstance(padding, tuple):\n        padding = (padding, ) * 2\n        \n    kernel = module.weight.detach().cpu().numpy()\n    \n    bias = trt.Weights(torch_dtype_to_trt(module.weight.dtype))\n    if module.bias is not None:\n        bias = module.bias.detach().cpu().numpy()\n\n    layer = ctx.network.add_deconvolution(\n        input=input_trt,\n        num_output_maps=module.out_channels,\n        kernel_shape=kernel_size,\n        kernel=kernel,\n        bias=bias)\n    layer.stride = stride\n\n    # if output_padding in original pytorch layer is not 0, pre_padding and post_padding should be set respectively. Otherwise the output dimension of pytorch and tensorrt may be different.\n    output_padding = module.output_padding\n    if output_padding[0] + output_padding[1] > 0:\n        layer.pre_padding = padding\n        layer.post_padding = trt.tensorrt.DimsHW(padding[0] - output_padding[0], padding[1] - output_padding[1])\n    else:\n        layer.padding = padding\n    \n    if module.groups is not None:\n        layer.num_groups = module.groups\n\n    output._trt = layer.get_output(0)\n\n@add_module_test(torch.float32, torch.device(""cuda""), [(1,3,224,224)])\ndef test_square_kernel_equal_stride_mode():\n    return torch.nn.ConvTranspose2d(3,3,3,stride=2)\n\n@add_module_test(torch.float32, torch.device(""cuda""), [(1,3,224,224)])\ndef test_square_kernel_equal_stride_mode_unequal_op_size():\n    return torch.nn.ConvTranspose2d(3,6,3,stride=2)\n\n@add_module_test(torch.float32, torch.device(""cuda""), [(1,3,224,224)])\ndef test_unequal_stride_mode():\n    return torch.nn.ConvTranspose2d(3,3,3, stride=(2,1), padding=(4,2))\n\n@add_module_test(torch.float32, torch.device(""cuda""), [(1,3,112,112)])\n@add_module_test(torch.float32, torch.device(""cuda""), [(1,3,7,7)])\ndef test_kernelsize_4():\n    return torch.nn.ConvTranspose2d(3,3,4, stride=2, padding=1)\n'"
torch2trt/converters/Identity.py,3,"b""from torch2trt.torch2trt import *\n\n\n@tensorrt_converter('torch.nn.Dropout.forward')\n@tensorrt_converter('torch.nn.Dropout2d.forward')\n@tensorrt_converter('torch.nn.Dropout3d.forward')\ndef convert_Identity(ctx):\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    output._trt = input_trt"""
torch2trt/converters/Linear.py,9,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.Linear.forward')\ndef convert_Linear(ctx):\n    module = ctx.method_args[0]\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n\n    # reshape to ...xNx1x1\n    layer = ctx.network.add_shuffle(input_trt)\n    layer.reshape_dims = tuple(input_trt.shape) + (1, 1) \n\n    bias = trt.Weights(torch_dtype_to_trt(module.weight.dtype))\n    if module.bias is not None:\n        bias = module.bias.detach().cpu().numpy()\n        \n    # add fully connected\n    layer = ctx.network.add_fully_connected(\n        input=layer.get_output(0),\n        num_outputs=module.out_features,\n        kernel=module.weight.detach().cpu().numpy(),\n        bias=bias)\n\n    # reshape back to N\n    layer = ctx.network.add_shuffle(layer.get_output(0))\n    layer.reshape_dims = tuple(output.shape[1:])\n\n    output._trt = layer.get_output(0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 10)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 10)])\ndef test_Linear_basic():\n    return torch.nn.Linear(10, 5)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 10)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 10)])\ndef test_Linear_no_bias():\n    return torch.nn.Linear(10, 5, bias=False)"""
torch2trt/converters/LogSoftmax.py,1,"b""from torch2trt.torch2trt import *\n\n\n@tensorrt_converter('torch.nn.LogSoftmax.forward')\ndef convert_LogSoftmax(ctx):\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    layer = ctx.network.add_softmax(input=input_trt)\n    layer = ctx.network.add_unary(input=layer.get_output(0),\n            op=trt.UnaryOperation.LOG)\n    output._trt = layer.get_output(0)"""
torch2trt/converters/ReLU.py,1,"b""from torch2trt.torch2trt import *\n\n\n@tensorrt_converter('torch.nn.ReLU.forward')\ndef convert_ReLU(ctx):\n    input = ctx.method_args[1]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    layer = ctx.network.add_activation(\n        input=input_trt, type=trt.ActivationType.RELU)\n    output._trt = layer.get_output(0)"""
torch2trt/converters/ReLU6.py,3,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.ReLU6.forward')\ndef convert_ReLU6(ctx):\n    input = ctx.method_args[1]\n    output = ctx.method_return\n    \n    input_trt, trt_6 = trt_(ctx.network, input, 6)\n\n    layer = ctx.network.add_activation(\n        input=input_trt, type=trt.ActivationType.RELU)\n    layer = ctx.network.add_elementwise(\n        layer.get_output(0), trt_6, trt.ElementWiseOperation.MIN)\n\n    output._trt = layer.get_output(0)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 5)])\ndef test_relu6_basic():\n    return torch.nn.ReLU6()"""
torch2trt/converters/__init__.py,0,b'# dummy converters throw warnings method encountered\n\nfrom .dummy_converters import *\n\n# supported converters will override dummy converters\n\nfrom .activation import *\nfrom .adaptive_avg_pool2d import *\nfrom .adaptive_max_pool2d import *\nfrom .AdaptiveAvgPool2d import *\nfrom .add import *\nfrom .avg_pool2d import *\nfrom .mul import *\nfrom .div import *\nfrom .BatchNorm1d import *\nfrom .BatchNorm2d import *\nfrom .cat import *\nfrom .clamp import *\nfrom .Conv1d import *\nfrom .Conv2d import *\nfrom .ConvTranspose2d import *\nfrom .getitem import *\nfrom .identity import *\nfrom .Identity import *\nfrom .instance_norm import *\nfrom .Linear import *\nfrom .LogSoftmax import *\nfrom .max_pool2d import *\nfrom .max import *\nfrom .min import *\nfrom .normalize import *\nfrom .pad import *\nfrom .permute import *\nfrom .pow import *\nfrom .prelu import *\nfrom .prod import *\nfrom .relu import *\nfrom .ReLU import *\nfrom .relu6 import *\nfrom .ReLU6 import *\nfrom .sigmoid import *\nfrom .sub import *\nfrom .sum import *\nfrom .view import *\nfrom .tanh import *\nfrom .transpose import *\nfrom .mean import *\nfrom .softmax import *\nfrom .split import *\nfrom .chunk import *\nfrom .unary import *\n\n\ntry:\n    from .interpolate import *\nexcept:\n    pass\n'
torch2trt/converters/activation.py,20,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\nfrom .unary import UnaryModule\n\n\n# |    RELU : Rectified Linear activation (impl in relu.py)\n#  |    SIGMOID : Sigmoid activation  (impl in sigmoid.py)\n#  |    TANH : Hyperbolic Tangent activation  (impl in tanh.py)\n\n\n#  |    LEAKY_RELU : Leaky Relu activation: f(x) = x if x >= 0, f(x) = alpha * x if x < 0\n\n\n@tensorrt_converter('torch.nn.functional.leaky_relu')\n@tensorrt_converter('torch.nn.functional.leaky_relu_')\ndef convert_leaky_relu(ctx):\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    negative_slope = get_arg(ctx, 'negative_slope', pos=1, default=0.01)\n    output = ctx.method_return\n    \n    input_trt = trt_(ctx.network, input)\n    layer = ctx.network.add_activation(input_trt, trt.ActivationType.LEAKY_RELU)\n    layer.alpha = negative_slope\n    \n    output._trt = layer.get_output(0)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_leaky_relu():\n    return UnaryModule(lambda x: torch.nn.functional.leaky_relu(x))\n\n\n#  |    ELU : Elu activation: f(x) = x if x >= 0, f(x) = alpha * (exp(x) - 1) if x < 0\n\n\n@tensorrt_converter('torch.nn.functional.elu')\n@tensorrt_converter('torch.nn.functional.elu_')\ndef convert_elu(ctx):\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    alpha = get_arg(ctx, 'alpha', pos=1, default=1.0)\n    output = ctx.method_return\n    \n    input_trt = trt_(ctx.network, input)\n    layer = ctx.network.add_activation(input_trt, trt.ActivationType.ELU)\n    layer.alpha = alpha\n    \n    output._trt = layer.get_output(0)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_elu():\n    return UnaryModule(lambda x: torch.nn.functional.elu(x))\n\n\n#  |    SELU : Selu activation: f(x) = beta * x if x > 0, f(x) = beta * (alpha * exp(x) - alpha) if x <= 0\n\n@tensorrt_converter('torch.selu')\n@tensorrt_converter('torch.selu_')\n@tensorrt_converter('torch.nn.functional.selu')\n@tensorrt_converter('torch.nn.functional.selu_')\ndef convert_selu(ctx):\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    alpha = get_arg(ctx, 'alpha', pos=1, default=1.0)\n    output = ctx.method_return\n    \n    input_trt = trt_(ctx.network, input)\n    layer = ctx.network.add_activation(input_trt, trt.ActivationType.SELU)\n    layer.alpha = 1.6732632423543772848170429916717\n    layer.beta = 1.0507009873554804934193349852946\n    \n    output._trt = layer.get_output(0)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_selu():\n    return UnaryModule(lambda x: torch.nn.functional.selu(x))\n\n\n#  |    SOFTSIGN : Softsign activation: f(x) = x / (1 + \\|x\\|)\n\n\n@tensorrt_converter('torch.nn.functional.softsign')\ndef convert_softsign(ctx):\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    output = ctx.method_return\n    \n    input_trt = trt_(ctx.network, input)\n    layer = ctx.network.add_activation(input_trt, trt.ActivationType.SOFTSIGN)\n    \n    output._trt = layer.get_output(0)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_softsign():\n    return UnaryModule(lambda x: torch.nn.functional.softsign(x))\n\n\n#  |    SOFTPLUS : Softplus activation: f(x) = alpha * log(exp(beta * x) + 1)\n\n\n@tensorrt_converter('torch.nn.functional.softplus')\ndef convert_softplus(ctx):\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    output = ctx.method_return\n    \n    input_trt = trt_(ctx.network, input)\n    layer = ctx.network.add_activation(input_trt, trt.ActivationType.SOFTPLUS)\n    \n    output._trt = layer.get_output(0)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_softplus():\n    return UnaryModule(lambda x: torch.nn.functional.softplus(x))\n\n\n#  |    CLIP : Clip activation: f(x) = max(alpha, min(beta, x))  (impl in clamp.py)\n\n#  |    HARD_SIGMOID : Hard sigmoid activation: f(x) = max(0, min(1, alpha * x + beta)) (not sure if there is this in Pytorch?)\n#  |    SCALED_TANH : Scaled Tanh activation: f(x) = alpha * tanh(beta * x) (not sure if there is this in Pytorch?)\n#  |    THRESHOLDED_RELU : Thresholded Relu activation: f(x) = x if x > alpha, f(x) = 0 if x <= alpha (not sure if there is this in Pytorch?)"""
torch2trt/converters/adaptive_avg_pool2d.py,2,"b""from torch2trt.torch2trt import *\nfrom .AdaptiveAvgPool2d import *\n\n\n@tensorrt_converter('torch.nn.functional.adaptive_avg_pool2d')\ndef convert_adaptive_avg_pool2d(ctx):\n    ctx.method_args = (torch.nn.AdaptiveAvgPool2d(ctx.method_args[1]), ctx.method_args[0])\n    convert_AdaptiveAvgPool2d(ctx)\n"""
torch2trt/converters/adaptive_max_pool2d.py,7,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.adaptive_max_pool2d')\ndef convert_adaptive_max_pool2d(ctx):\n    input = ctx.method_args[0]\n    output = ctx.method_return\n\n    output_size = ctx.method_args[1]\n    if isinstance(output_size, int):\n        output_size = (output_size, ) * 2\n\n    stride = (input._trt.shape[-2] // output_size[-2], input._trt.shape[-1] // output_size[-1])\n\n    kernel_size = stride\n    layer = ctx.network.add_pooling(\n        input=input._trt, type=trt.PoolingType.MAX, window_size=kernel_size)\n    layer.stride = stride\n\n    output._trt = layer.get_output(0)\n\n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_adaptive_max_pool2d_1x1():\n    return torch.nn.AdaptiveMaxPool2d((1, 1))\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_adaptive_max_pool2d_2x2():\n    return torch.nn.AdaptiveMaxPool2d((2, 2))\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_adaptive_max_pool2d_3x3():\n    return torch.nn.AdaptiveMaxPool2d((3, 3))\n"""
torch2trt/converters/add.py,15,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.add')\n@tensorrt_converter('torch.Tensor.__iadd__')\n@tensorrt_converter('torch.Tensor.__add__')\n@tensorrt_converter('torch.Tensor.__radd__')\ndef convert_add(ctx):\n    input_a = ctx.method_args[0]\n    input_b = ctx.method_args[1]\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.SUM)\n    output._trt = layer.get_output(0)\n    \n\nclass Add(torch.nn.Module):\n    def __init__(self):\n        super(Add, self).__init__()\n\n    def forward(self, x, y):\n        return x + y\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_add_basic():\n    return Add()\n\n\nclass IAdd(torch.nn.Module):\n    def __init__(self):\n        super(IAdd, self).__init__()\n\n    def forward(self, x, y):\n        x += y\n        return x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_add_iadd():\n    return IAdd()\n\n\nclass TorchAdd(torch.nn.Module):\n    def __init__(self):\n        super(TorchAdd, self).__init__()\n\n    def forward(self, x, y):\n        return torch.add(x, y)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_add_torchadd():\n    return TorchAdd()\n\n\nclass RAddInt(torch.nn.Module):\n    def __init__(self):\n        super(RAddInt, self).__init__()\n\n    def forward(self, x):\n        return 1 + x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_add_radd_int():\n    return RAddInt()\n\n\nclass RAddFloat(torch.nn.Module):\n    def __init__(self):\n        super(RAddFloat, self).__init__()\n\n    def forward(self, x):\n        return 1.0 + x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_add_radd_float():\n    return RAddFloat()"""
torch2trt/converters/avg_pool2d.py,7,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.avg_pool2d')\ndef convert_avg_pool2d(ctx):\n    # parse args\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    kernel_size = get_arg(ctx, 'kernel_size', pos=1, default=None)\n    stride = get_arg(ctx, 'stride', pos=2, default=None)\n    padding = get_arg(ctx, 'padding', pos=3, default=0)\n    ceil_mode = get_arg(ctx, 'ceil_mode', pos=4, default=False)\n    count_include_pad = get_arg(ctx, 'count_include_pad', pos=5, default=True)\n    \n    # get input trt tensor (or create constant if it doesn't exist)\n    input_trt = trt_(ctx.network, input)\n    \n    output = ctx.method_return\n\n    # get kernel size\n    if not isinstance(kernel_size, tuple):\n        kernel_size = (kernel_size, ) * 2\n\n    # get stride\n    if not isinstance(stride, tuple):\n        stride = (stride, ) * 2\n\n    # get padding\n    if not isinstance(padding, tuple):\n        padding = (padding, ) * 2\n\n    layer = ctx.network.add_pooling(\n        input=input_trt, type=trt.PoolingType.AVERAGE, window_size=kernel_size)\n    \n    layer.stride = stride\n    layer.padding = padding\n    layer.average_count_excludes_padding = not count_include_pad\n    \n    if ceil_mode:\n        layer.padding_mode = trt.PaddingMode.EXPLICIT_ROUND_UP\n\n    output._trt = layer.get_output(0)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 6)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 5, 7)])\ndef test_avg_pool2d_without_ceil_mode():\n    return torch.nn.AvgPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 6)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 5, 7)])\ndef test_avg_pool2d_with_ceil_mode():\n    return torch.nn.AvgPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True, count_include_pad=False) # TRT does not support ceil_mode=True && count_include_pad=True\n"""
torch2trt/converters/cat.py,1,"b""from torch2trt.torch2trt import *\n\n\n@tensorrt_converter('torch.cat')\ndef convert_cat(ctx):\n    inputs = ctx.method_args[0]\n\n    if 'dim' in ctx.method_kwargs:\n        dim = ctx.method_kwargs['dim']\n    else:\n        dim = ctx.method_args[1]\n\n    output = ctx.method_return\n    trt_inputs = [trt_(ctx.network, i) for i in inputs]\n\n    layer = ctx.network.add_concatenation(inputs=trt_inputs)\n    layer.axis = dim - 1\n    output._trt = layer.get_output(0)"""
torch2trt/converters/chunk.py,14,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\nfrom .split import convert_split\n\n\n@tensorrt_converter('torch.chunk')\n@tensorrt_converter('torch.Tensor.chunk')\ndef convert_chunk(ctx):\n    convert_split(ctx)\n\n        \nclass TorchChunk(torch.nn.Module):\n    \n    def __init__(self, *args, **kwargs):\n        super(TorchChunk, self).__init__()\n        self.args = args\n        self.kwargs = kwargs\n        \n    def forward(self, x):\n        return torch.chunk(x, *self.args, **self.kwargs)\n    \n\nclass TensorChunk(torch.nn.Module):\n    \n    def __init__(self, *args, **kwargs):\n        super(TensorChunk, self).__init__()\n        self.args = args\n        self.kwargs = kwargs\n        \n    def forward(self, x):\n        return x.chunk(*self.args, **self.kwargs)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_torch_chunk_1_1():\n    return TorchChunk(1, 1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_torch_chunk_2_1():\n    return TorchChunk(2, 1)\n\n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_torch_chunk_3_1():\n    return TorchChunk(3, 1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_torch_chunk_3_2():\n    return TorchChunk(3, 2)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_tensor_chunk_3_2():\n    return TensorChunk(3, 2)"""
torch2trt/converters/clamp.py,37,"b'from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\ndef __add_clamp(network, trt_input, val, op):\n    \n    # create TensorRT constant for minimum value\n    val_shape = (1, ) * len(trt_input.shape)  # broadcast all dimensions\n    val_tensor = val * torch.ones(val_shape, dtype=torch_dtype_from_trt(trt_input.dtype)).cpu().numpy()\n    val_trt = network.add_constant(val_shape, val_tensor)\n    layer = network.add_elementwise(trt_input, val_trt.get_output(0), op)\n    \n    return layer\n\n    \n# CLAMP_MIN\n\n    \n@tensorrt_converter(\'torch.clamp_min\')\n@tensorrt_converter(\'torch.Tensor.clamp_min\')\ndef convert_clamp_min(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    val = ctx.method_args[1]\n    output = ctx.method_return\n    \n    layer = __add_clamp(ctx.network, input_trt, val, trt.ElementWiseOperation.MAX)\n    \n    output._trt = layer.get_output(0)\n\n    \nclass TorchClampMin(torch.nn.Module):\n    def forward(self, x):\n        return torch.clamp_min(x, -0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_torch_clamp_min():\n    return TorchClampMin()\n\n\nclass TensorClampMin(torch.nn.Module):\n    def forward(self, x):\n        return x.clamp_min(-0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_tensor_clamp_min():\n    return TensorClampMin()\n\n    \n# CLAMP_MAX\n\n\n@tensorrt_converter(\'torch.clamp_max\')\n@tensorrt_converter(\'torch.Tensor.clamp_max\')\ndef convert_clamp_max(ctx):\n    input = ctx.method_args[0]\n    val = ctx.method_args[1]\n    output = ctx.method_return\n    \n    layer = __add_clamp(ctx.network, input._trt, val, trt.ElementWiseOperation.MIN)\n    \n    output._trt = layer.get_output(0)\n    \n\nclass TorchClampMax(torch.nn.Module):\n    def forward(self, x):\n        return torch.clamp_max(x, 0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_torch_clamp_max():\n    return TorchClampMax()\n\n\nclass TensorClampMax(torch.nn.Module):\n    def forward(self, x):\n        return x.clamp_max(0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_tensor_clamp_max():\n    return TensorClampMax()\n\n\n# CLAMP\n    \n@tensorrt_converter(\'torch.clamp\')\n@tensorrt_converter(\'torch.Tensor.clamp\')\ndef convert_clamp(ctx):\n    input = ctx.method_args[0]\n    output = ctx.method_return\n    if ""min"" in ctx.method_kwargs and ""max"" in ctx.method_kwargs:\n        min_val = ctx.method_kwargs[""min""]\n        max_val = ctx.method_kwargs[""max""]\n        layer = __add_clamp(ctx.network, input._trt, min_val, trt.ElementWiseOperation.MAX)\n        layer = __add_clamp(ctx.network, layer.get_output(0), max_val, trt.ElementWiseOperation.MIN)\n    elif ""min"" in ctx.method_kwargs:\n        min_val = ctx.method_kwargs[""min""]\n        layer = __add_clamp(ctx.network, input._trt, min_val, trt.ElementWiseOperation.MAX)\n    elif ""max"" in ctx.method_kwargs:\n        max_val = ctx.method_kwargs[""max""]\n        layer = __add_clamp(ctx.network, input._trt, max_val, trt.ElementWiseOperation.MIN)\n    else:\n        min_val = ctx.method_args[1]\n        max_val = ctx.method_args[2]\n        layer = __add_clamp(ctx.network, input._trt, min_val, trt.ElementWiseOperation.MAX)\n        layer = __add_clamp(ctx.network, layer.get_output(0), max_val, trt.ElementWiseOperation.MIN)\n    \n    output._trt = layer.get_output(0)\n    \n\nclass TorchClamp(torch.nn.Module):\n    def forward(self, x):\n        return torch.clamp(x, -0.1, 0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_torch_clamp():\n    return TorchClamp()\n\n\nclass TensorClamp(torch.nn.Module):\n    def forward(self, x):\n        return x.clamp(-0.1, 0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_tensor_clamp():\n    return TensorClamp()\n\n\nclass TorchClampOptionMax(torch.nn.Module):\n    def forward(self, x):\n        return torch.clamp(x, max=0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_torch_clamp_option_max():\n    return TorchClampOptionMax()\n\nclass TorchClampOptionMin(torch.nn.Module):\n    def forward(self, x):\n        return torch.clamp(x, min=-0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_torch_clamp_option_min():\n    return TorchClampOptionMin()\n\n\nclass TorchClampOptionMaxMin(torch.nn.Module):\n    def forward(self, x):\n        return torch.clamp(x, min=-0.1, max=0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_torch_clamp_option_max_min():\n    return TorchClampOptionMaxMin()\n\n\nclass TensorClampOptionMax(torch.nn.Module):\n    def forward(self, x):\n        return x.clamp(max=0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_tensor_clamp_option_max():\n    return TensorClampOptionMax()\n\nclass TensorClampOptionMin(torch.nn.Module):\n    def forward(self, x):\n        return x.clamp(min=-0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_tensor_clamp_option_min():\n    return TensorClampOptionMin()\n\n\nclass TensorClampOptionMaxMin(torch.nn.Module):\n    def forward(self, x):\n        return x.clamp(min=-0.1, max=0.1)\n\n\n@add_module_test(torch.float32, torch.device(\'cuda\'), [(1, 3, 224, 224)])\ndef test_tensor_clamp_option_max_min():\n    return TensorClampOptionMaxMin()'"
torch2trt/converters/div.py,18,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.div')\n@tensorrt_converter('torch.Tensor.__div__') # py2\n@tensorrt_converter('torch.Tensor.__idiv__') # py2\n@tensorrt_converter('torch.Tensor.__truediv__') # py3\n@tensorrt_converter('torch.Tensor.__itruediv__') # py3\ndef convert_div(ctx):\n    input_a = ctx.method_args[0]\n    input_b = ctx.method_args[1]\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.DIV)\n    output._trt = layer.get_output(0)\n\n\n@tensorrt_converter('torch.Tensor.__rdiv__') # py2\n@tensorrt_converter('torch.Tensor.__rtruediv__') # py3\ndef convert_rdiv(ctx):\n    input_a = ctx.method_args[1]  # inputs switched for rdiv\n    input_b = ctx.method_args[0]\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.DIV)\n    output._trt = layer.get_output(0)\n    \n\nclass Div(torch.nn.Module):\n    def __init__(self):\n        super(Div, self).__init__()\n\n    def forward(self, x, y):\n        return x / y\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_div_basic():\n    return Div()\n\n\nclass IDiv(torch.nn.Module):\n    def __init__(self):\n        super(IDiv, self).__init__()\n\n    def forward(self, x, y):\n        x /= y\n        return x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_div_idiv():\n    return IDiv()\n\n\nclass TorchDiv(torch.nn.Module):\n    def __init__(self):\n        super(TorchDiv, self).__init__()\n\n    def forward(self, x, y):\n        return torch.div(x, y)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_div_torchdiv():\n    return TorchDiv()\n\n\nclass RDivInt(torch.nn.Module):\n    def __init__(self):\n        super(RDivInt, self).__init__()\n\n    def forward(self, x):\n        return 100 / x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_rdiv_int():\n    return RDivInt()\n\n\nclass RDivFloat(torch.nn.Module):\n    def __init__(self):\n        super(RDivFloat, self).__init__()\n\n    def forward(self, x):\n        return 100.0 / x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_rdiv_float():\n    return RDivFloat()"""
torch2trt/converters/dummy_converters.py,4,"b""from torch2trt.torch2trt import *\n\n\ndef is_private(method):\n    method = method.split('.')[-1]  # remove prefix\n    return method[0] == '_' and method[1] is not '_'\n\ndef is_function_type(method):\n    fntype =  eval(method + '.__class__.__name__')\n    return fntype == 'function' or fntype == 'builtin_function_or_method' or fntype == 'method_descriptor'\n\ndef get_methods(namespace):\n    methods = []\n    for method in dir(eval(namespace)):\n        full_method = namespace + '.' + method\n        if not is_private(full_method) and is_function_type(full_method):\n            methods.append(full_method)\n    return methods\n\n\nTORCH_METHODS = []\nTORCH_METHODS += get_methods('torch')\nTORCH_METHODS += get_methods('torch.Tensor')\nTORCH_METHODS += get_methods('torch.nn.functional')\n\n\nfor method in TORCH_METHODS:\n    \n    @tensorrt_converter(method, is_real=False)\n    def warn_method(ctx):\n        print('Warning: Encountered known unsupported method %s' % ctx.method_str)\n        \n\n@tensorrt_converter('torch.Tensor.dim', is_real=False)\n@tensorrt_converter('torch.Tensor.size', is_real=False)\ndef dont_warn(ctx):\n    pass"""
torch2trt/converters/getitem.py,12,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\ndef slice_to_trt(dim_size, dim_slice):\n    \n    start = 0 if dim_slice.start is None else dim_slice.start\n    stop = dim_size if dim_slice.stop is None else dim_slice.stop\n    stride = 1 if dim_slice.step is None else dim_slice.step\n    \n    size = (stop - start - 1) // stride + 1\n    \n    return start, size, stride\n\n\ndef num_slice_types(slices):\n    num_slice = 0\n    for s in slices:\n        if isinstance(s, slice) or isinstance(s, int):\n            num_slice += 1\n    return num_slice\n\n\n@tensorrt_converter('torch.Tensor.__getitem__')\ndef convert_tensor_getitem(ctx):\n    input = ctx.method_args[0]\n    slices = ctx.method_args[1]\n    output = ctx.method_return\n    \n    input_trt = input._trt\n    \n    # Step 1 - Replace ellipsis with expanded slices\n    \n    num_ellipsis = input.ndim - num_slice_types(slices)\n    \n    new_slices = []\n    for s in slices:\n        \n        if s == Ellipsis:\n            while num_ellipsis > 0:\n                new_slices.append(slice(None, None, None))\n                num_ellipsis -= 1\n        elif isinstance(s, slice):\n            new_slices.append(s)\n        elif s is None:\n            new_slices.append(None)\n        elif isinstance(s, int):\n            new_slices.append(s)\n            \n    # fill missing slices at end\n    while num_slice_types(new_slices) < len(input.shape):\n        new_slices.append(slice(None, None, None))\n            \n    # Step 2 - Remove batch from slices (TRT from this point)\n    \n    slices = tuple(new_slices[1:]) # remove batch\n    \n    \n    # Step 3 - Add slice layer (will currently ignore 'None' slices)\n    \n    starts = []\n    sizes = []\n    strides = []\n    \n    input_dim = 0\n    for s in slices:\n        \n        if input_dim >= len(input_trt.shape):\n            break\n            \n        input_size = int(input_trt.shape[input_dim])\n        \n        if isinstance(s, slice):\n            start, size, stride = slice_to_trt(input_size, s)\n            starts.append(start)\n            sizes.append(size)\n            strides.append(stride)\n            input_dim += 1\n            \n        elif isinstance(s, int):\n            starts.append(s)\n            sizes.append(1)\n            strides.append(1)\n            input_dim += 1\n    \n    output_trt = ctx.network.add_slice(input_trt, starts, sizes, strides).get_output(0)\n    \n    # Step 4 - Add shuffle layer to insert dimensions for 'None' slices and remove dimensions for 'int' slices\n    \n    num_non_slice = len([s for s in slices if not isinstance(s, slice)])\n    if num_non_slice > 0:\n        layer = ctx.network.add_shuffle(output_trt)\n        layer.reshape_dims = tuple(output.shape[1:]) # exclude batch\n        output_trt = layer.get_output(0)\n        \n    output._trt = output_trt\n    \n    \nclass LambdaModule(torch.nn.Module):\n    def __init__(self, fn):\n        super(LambdaModule, self).__init__()\n        self.fn = fn\n        \n    def forward(self, x):\n        return self.fn(x)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_tensor_getitem_1d_int():\n    return LambdaModule(lambda x: x[:, 0])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_int():\n    return LambdaModule(lambda x: x[:, 0])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_strided():\n    return LambdaModule(lambda x: x[:, ::2])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_strided_offset():\n    return LambdaModule(lambda x: x[:, 1::2])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_strided_range():\n    return LambdaModule(lambda x: x[:, 1:3:2])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_insert_dim():\n    return LambdaModule(lambda x: x[:, None])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_insert_dim_ellipsis():\n    return LambdaModule(lambda x: x[:, None, ...])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_append_dim():\n    return LambdaModule(lambda x: x[:, ..., None])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_append_2dim():\n    return LambdaModule(lambda x: x[:, ..., None, None])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 4, 3)])\ndef test_tensor_getitem_2d_weird_combo():\n    return LambdaModule(lambda x: x[:, 0:3:4, None, None, 1, ...])"""
torch2trt/converters/identity.py,4,"b""from torch2trt.torch2trt import *\n\n\n@tensorrt_converter('torch.Tensor.contiguous')\n@tensorrt_converter('torch.nn.functional.dropout')\n@tensorrt_converter('torch.nn.functional.dropout2d')\n@tensorrt_converter('torch.nn.functional.dropout3d')\ndef convert_identity(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    output._trt = input_trt\n"""
torch2trt/converters/instance_norm.py,26,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\ndef _add_scale_1d2d3d(network, x_trt, mode, offset, scale, power):\n    ndim = len(x_trt.shape)\n    \n    y_trt = x_trt\n    \n    # shape to 2D\n    if ndim != 3:\n        layer = network.add_shuffle(y_trt)\n        layer.reshape_dims = (x_trt.shape[0], x_trt.shape[1], -1)  # NCH -> NCHW\n        y_trt = layer.get_output(0)\n        \n    y_trt = network.add_scale(y_trt, mode, offset, scale, power).get_output(0)\n\n    # shape to original dimension\n    if ndim != 3:    \n        layer = network.add_shuffle(layer.get_output(0))\n        layer.reshape_dims = tuple(x_trt.shape)\n        y_trt = layer.get_output(0)\n    \n    return y_trt\n        \n@tensorrt_converter('torch.instance_norm')\n@tensorrt_converter('torch.nn.functional.instance_norm')\ndef convert_instance_norm(ctx):\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    running_mean = get_arg(ctx, 'running_mean', pos=1, default=None)\n    running_var = get_arg(ctx, 'running_var', pos=2, default=None)\n    weight = get_arg(ctx, 'weight', pos=3, default=None)\n    bias = get_arg(ctx, 'bias', pos=4, default=None)\n    use_input_stats = get_arg(ctx, 'use_input_stats', pos=5, default=True)\n    momentum = get_arg(ctx, 'momentum', pos=6, default=0.1)\n    eps = get_arg(ctx, 'eps', pos=7, default=1e-05)\n    output = ctx.method_return\n    \n    \n    # CASE 1 - USING RUNNING STATISTICS\n    if not use_input_stats:\n        \n        # equivalent to batch norm\n        scale = 1.0 / np.sqrt(running_var.detach().cpu().numpy() + eps)\n        offset = -running_mean.detach().cpu().numpy() * scale\n        power = np.ones_like(scale)\n        \n        if weight is not None:\n            scale *= weight.detach().cpu().numpy()\n            offset += bias.detach().cpu().numpy()\n            \n        result_trt = _add_scale_1d2d3d(ctx.network, input._trt, trt.ScaleMode.CHANNEL, offset, scale, power)\n    \n        output._trt = result_trt\n        \n    # CASE 2 - USING INPUT STATS\n    else:\n        \n        eps_np = np.array([eps], dtype=np.float32)\n        keep_dims = True\n        reduce_axes = torch_dim_to_trt_axes(tuple(range(2, input.ndim)))\n        \n        # compute mean over spatial\n        mean_trt = ctx.network.add_reduce(input._trt, trt.ReduceOperation.AVG, reduce_axes, keep_dims).get_output(0)\n        \n        # compute variance over spatial (include eps, to reduce layer count)\n        delta_trt = ctx.network.add_elementwise(input._trt, mean_trt, trt.ElementWiseOperation.SUB).get_output(0)\n        var_trt = ctx.network.add_scale(delta_trt, trt.ScaleMode.UNIFORM, np.zeros_like(eps_np), np.ones_like(eps_np), 2 * np.ones_like(eps_np)).get_output(0)\n        var_trt = ctx.network.add_reduce(var_trt, trt.ReduceOperation.AVG, reduce_axes, keep_dims).get_output(0)\n        \n        # compute sqrt(var + eps)\n        var_trt = ctx.network.add_scale(var_trt, trt.ScaleMode.UNIFORM, eps_np, np.ones_like(eps_np), 0.5 * np.ones_like(eps_np)).get_output(0)\n        \n        # compute final result\n        result_trt = ctx.network.add_elementwise(delta_trt, var_trt, trt.ElementWiseOperation.DIV).get_output(0)\n        \n        # compute affine (if applicable)\n        if weight is not None:\n            \n            weight_np = weight.detach().cpu().numpy()\n            bias_np = bias.detach().cpu().numpy()\n            \n            result_trt = _add_scale_1d2d3d(ctx.network, result_trt, trt.ScaleMode.CHANNEL, bias_np, weight_np, np.ones_like(bias_np))\n        \n        output._trt = result_trt\n        \n        \n# STATIC\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3)])\ndef test_instance_norm_1d_static():\n    return torch.nn.InstanceNorm1d(10, track_running_stats=True)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3, 3)])\ndef test_instance_norm_2d_static():\n    return torch.nn.InstanceNorm2d(10, track_running_stats=True)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3, 3, 3)])\ndef test_instance_norm_3d_static():\n    return torch.nn.InstanceNorm3d(10, track_running_stats=True)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3)])\ndef test_instance_norm_1d_static_affine():\n    return torch.nn.InstanceNorm1d(10, affine=True, track_running_stats=True)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3, 3)])\ndef test_instance_norm_2d_static_affine():\n    return torch.nn.InstanceNorm2d(10, affine=True, track_running_stats=True)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3, 3, 3)])\ndef test_instance_norm_3d_static_affine():\n    return torch.nn.InstanceNorm3d(10, affine=True, track_running_stats=True)\n\n# DYNAMIC\n\n# @TODO(jwelsh): 1D dynamic test failing\n# @add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3)])\n# def test_instance_norm_1d_dynamic():\n#     return torch.nn.InstanceNorm1d(10, track_running_stats=False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3, 3)])\ndef test_instance_norm_2d_dynamic():\n    return torch.nn.InstanceNorm2d(10, track_running_stats=False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3, 3, 3)])\ndef test_instance_norm_3d_dynamic():\n    return torch.nn.InstanceNorm3d(10, track_running_stats=False)\n\n\n# @TODO(jwelsh): 1D dynamic test failing\n# @add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3)])\n# def test_instance_norm_1d_dynamic_affine():\n#     return torch.nn.InstanceNorm1d(10, affine=True, track_running_stats=False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3, 3)])\ndef test_instance_norm_2d_dynamic_affine():\n    return torch.nn.InstanceNorm2d(10, affine=True, track_running_stats=False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 3, 3, 3)])\ndef test_instance_norm_3d_dynamic_affine():\n    return torch.nn.InstanceNorm3d(10, affine=True, track_running_stats=False)"""
torch2trt/converters/max.py,16,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\nfrom .unary import UnaryModule\n\n\ndef __convert_max_elementwise(ctx):\n    input_a = ctx.method_args[0]\n    input_b = ctx.method_args[1]\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.MAX)\n    output._trt = layer.get_output(0)\n    \n\ndef __convert_max_reduce(ctx):\n    input = ctx.method_args[0]\n    dim = get_arg(ctx, 'dim', pos=1, default=tuple(range(1, input.ndim)))\n    keepdim = get_arg(ctx, 'keepdim', pos=2, default=False)\n    input_trt= trt_(ctx.network, input)\n    output_val = ctx.method_return[0]\n    output_idx = ctx.method_return[1]\n    layer = ctx.network.add_reduce(input_trt,  trt.ReduceOperation.MAX, torch_dim_to_trt_axes(dim), keepdim)\n    output_val._trt = layer.get_output(0)\n    \n\n@tensorrt_converter('torch.max')\n@tensorrt_converter('torch.Tensor.max')\ndef convert_max(ctx):\n    if len(ctx.method_args) > 1 and isinstance(ctx.method_args[1], torch.Tensor):\n        __convert_max_elementwise(ctx)\n    else:\n        __convert_max_reduce(ctx)\n        \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_max_reduce_dim1():\n    return UnaryModule(lambda x: torch.max(x, 1)[0])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_max_reduce_dim22():\n    return UnaryModule(lambda x: torch.max(x, 2)[0])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_max_reduce_dim1_keepdim():\n    return UnaryModule(lambda x: torch.max(x, 1, keepdim=True)[0])\n\n\nclass MaxElementwise(torch.nn.Module):\n    def forward(self, x, y):\n        return torch.max(x, y)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3), (1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3), (1,)]) # broadcast\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3), (1, 3, 3)]) # broadcast\ndef test_max_elementwise():\n    return MaxElementwise()"""
torch2trt/converters/max_pool2d.py,7,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.max_pool2d')\ndef convert_max_pool2d(ctx):\n    # parse args\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    kernel_size = get_arg(ctx, 'kernel_size', pos=1, default=None)\n    stride = get_arg(ctx, 'stride', pos=2, default=None)\n    padding = get_arg(ctx, 'padding', pos=3, default=0)\n    dilation = get_arg(ctx, 'dilation', pos=4, default=1)\n    ceil_mode = get_arg(ctx, 'ceil_mode', pos=5, default=False)\n    \n    # get input trt tensor (or create constant if it doesn't exist)\n    input_trt = trt_(ctx.network, input)\n    \n    output = ctx.method_return\n\n    # get kernel size\n    if not isinstance(kernel_size, tuple):\n        kernel_size = (kernel_size, ) * 2\n\n    # get stride\n    if not isinstance(stride, tuple):\n        stride = (stride, ) * 2\n\n    # get padding\n    if not isinstance(padding, tuple):\n        padding = (padding, ) * 2\n\n    layer = ctx.network.add_pooling(\n        input=input_trt, type=trt.PoolingType.MAX, window_size=kernel_size)\n    \n    layer.stride = stride\n    layer.padding = padding\n    \n    if ceil_mode:\n        layer.padding_mode = trt.PaddingMode.EXPLICIT_ROUND_UP\n\n    output._trt = layer.get_output(0)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 6)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 5, 7)])\ndef test_MaxPool2d_without_ceil_mode():\n    return torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 6)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 5, 7)])\ndef test_MaxPool2d_with_ceil_mode():\n    return torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)"""
torch2trt/converters/mean.py,11,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.mean')\n@tensorrt_converter('torch.Tensor.mean')\ndef convert_mean(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    \n    # get dims from args or kwargs\n    if 'dim' in ctx.method_kwargs: \n        dim = ctx.method_kwargs['dim']\n    elif len(ctx.method_args) >= 2:\n        dim = ctx.method_args[1]\n        \n    # convert list to tuple\n    if isinstance(dim, list):\n        dim = tuple(dim)\n        \n    if not isinstance(dim, tuple):\n        dim = (dim, )\n        \n    # create axes bitmask for reduce layer\n    axes = 0\n    for d in dim:\n        axes |= 1 << (d - 1) # -1 to remove batch dimension\n        \n    # get whether to keep dimensions\n    if 'keepdim' in ctx.method_kwargs:\n        keep_dims = ctx.method_kwargs['keepdim']\n    elif len(ctx.method_args) == 3:\n        keep_dims = ctx.method_args[2]\n    else:\n        keep_dims = False\n        \n    layer = ctx.network.add_reduce(input_trt, trt.ReduceOperation.AVG, axes, keep_dims)\n    output._trt = layer.get_output(0)\n\n    \nclass Mean(torch.nn.Module):\n    def __init__(self, dim, keepdim):\n        super(Mean, self).__init__()\n        self.dim = dim\n        self.keepdim = keepdim\n    def forward(self, x):\n        return x.mean(self.dim, self.keepdim)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_mean_channel():\n    return Mean(1, False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_mean_tuple():\n    return Mean((1, 2), False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_mean_keepdim():\n    return Mean(1, True)"""
torch2trt/converters/min.py,16,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\nfrom .unary import UnaryModule\n\n\ndef __convert_min_elementwise(ctx):\n    input_a = ctx.method_args[0]\n    input_b = ctx.method_args[1]\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.MIN)\n    output._trt = layer.get_output(0)\n    \n\ndef __convert_min_reduce(ctx):\n    input = ctx.method_args[0]\n    dim = get_arg(ctx, 'dim', pos=1, default=tuple(range(1,input.ndim)))\n    keepdim = get_arg(ctx, 'keepdim', pos=2, default=False)\n    input_trt= trt_(ctx.network, input)\n    output_val = ctx.method_return[0]\n    output_idx = ctx.method_return[1]\n    layer = ctx.network.add_reduce(input_trt,  trt.ReduceOperation.MIN, torch_dim_to_trt_axes(dim), keepdim)\n    output_val._trt = layer.get_output(0)\n    \n\n@tensorrt_converter('torch.min')\n@tensorrt_converter('torch.Tensor.min')\ndef convert_min(ctx):\n    if len(ctx.method_args) > 1 and isinstance(ctx.method_args[1], torch.Tensor):\n        __convert_min_elementwise(ctx)\n    else:\n        __convert_min_reduce(ctx)\n        \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_min_reduce_dim1():\n    return UnaryModule(lambda x: torch.min(x, 1)[0])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_min_reduce_dim22():\n    return UnaryModule(lambda x: torch.min(x, 2)[0])\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_min_reduce_dim1_keepdim():\n    return UnaryModule(lambda x: torch.min(x, 1, keepdim=True)[0])\n\n\nclass MinElementwise(torch.nn.Module):\n    def forward(self, x, y):\n        return torch.min(x, y)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3), (1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3), (1,)]) # broadcast\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3), (1, 3, 3)]) # broadcast\ndef test_min_elementwise():\n    return MinElementwise()"""
torch2trt/converters/mul.py,15,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.mul')\n@tensorrt_converter('torch.Tensor.__imul__')\n@tensorrt_converter('torch.Tensor.__mul__')\n@tensorrt_converter('torch.Tensor.__rmul__')\ndef convert_mul(ctx):\n    input_a = ctx.method_args[0]\n    input_b = ctx.method_args[1]\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.PROD)\n    output._trt = layer.get_output(0)\n\n\nclass Mul(torch.nn.Module):\n    def __init__(self):\n        super(Mul, self).__init__()\n\n    def forward(self, x, y):\n        return x * y\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_mul_basic():\n    return Mul()\n\n\nclass IMul(torch.nn.Module):\n    def __init__(self):\n        super(IMul, self).__init__()\n\n    def forward(self, x, y):\n        x *= y\n        return x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_mul_imul():\n    return IMul()\n\n\nclass TorchMul(torch.nn.Module):\n    def __init__(self):\n        super(TorchMul, self).__init__()\n\n    def forward(self, x, y):\n        return torch.mul(x, y)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_mul_torchmul():\n    return TorchMul()\n\n\nclass RMulInt(torch.nn.Module):\n    def __init__(self):\n        super(RMulInt, self).__init__()\n\n    def forward(self, x):\n        return 10 * x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_rmul_int():\n    return RMulInt()\n\n\nclass RMulFloat(torch.nn.Module):\n    def __init__(self):\n        super(RMulFloat, self).__init__()\n\n    def forward(self, x):\n        return 10.0 * x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_rmul_float():\n    return RMulFloat()"""
torch2trt/converters/normalize.py,14,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.normalize')\ndef convert_normalize(ctx):\n    # get args\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    p = get_arg(ctx, 'p', pos=1, default=2)\n    dim = get_arg(ctx, 'dim', pos=2, default=1)\n    eps = get_arg(ctx, 'eps', pos=3, default=1e-12)\n    \n#     input_trt = input._trt\n    output = ctx.method_return\n    \n    # add broadcastable scalar constants to network\n    input_trt, eps_trt, p_trt, p_inv_trt = trt_(ctx.network, input, eps, p, 1.0 / p)\n    \n    # compute norm = sum(abs(x)**p, dim=dim)**(1./p)\n    norm = ctx.network.add_unary(input_trt, trt.UnaryOperation.ABS).get_output(0)\n    norm = ctx.network.add_elementwise(norm, p_trt, trt.ElementWiseOperation.POW).get_output(0)\n    norm = ctx.network.add_reduce(norm, trt.ReduceOperation.SUM, torch_dim_to_trt_axes(dim), keep_dims=True).get_output(0)\n    norm = ctx.network.add_elementwise(norm, p_inv_trt, trt.ElementWiseOperation.POW).get_output(0)\n    \n    # clamp norm = max(norm, eps)\n    norm = ctx.network.add_elementwise(norm, eps_trt, trt.ElementWiseOperation.MAX).get_output(0)\n    \n    # divide input by norm\n    output._trt = ctx.network.add_elementwise(input_trt, norm, trt.ElementWiseOperation.DIV).get_output(0)\n    \n\nclass Normalize(torch.nn.Module):\n    def __init__(self, *args, **kwargs):\n        super(Normalize, self).__init__()\n        self.args = args\n        self.kwargs = kwargs\n    \n    def forward(self, x):\n        return torch.nn.functional.normalize(x, *self.args, **self.kwargs)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_normalize_basic():\n    return Normalize()\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_normalize_l1_basic():\n    return Normalize(p=1.0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_normalize_l1p5_basic():\n    return Normalize(p=1.5)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_normalize_l2_height():\n    return Normalize(p=2.0, dim=2)"""
torch2trt/converters/pad.py,4,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.pad')\ndef convert_pad(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    \n    pad = ctx.method_args[1]\n    pre_padding = (pad[2], pad[0])\n    post_padding = (pad[3], pad[1])\n    \n    # mode / value are ignored since not supported by TensorRT\n    \n    layer = ctx.network.add_padding(input_trt, pre_padding, post_padding)\n    output._trt = layer.get_output(0)\n    \n\nclass Pad(torch.nn.Module):\n    \n    def __init__(self, pad):\n        super(Pad, self).__init__()\n        self.pad = pad\n        \n    def forward(self, x):\n        return torch.nn.functional.pad(x, self.pad)\n    \n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_pad_basic():\n    return Pad((1, 2, 3, 4))"""
torch2trt/converters/permute.py,8,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.Tensor.permute')\ndef convert_permute(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    \n    # permutation -1 because TRT does not include batch dim\n    if isinstance(ctx.method_args[1], int):\n        permutation = tuple(ctx.method_args[1:])  # handle permute(a, b, c)\n    else:\n        permutation = tuple(ctx.method_args[1])   # handle permute([a, b, c])\n        \n    assert(permutation[0] == 0)  # cannot move batch dim\n    \n    trt_permutation = tuple([p - 1 for p in permutation])[1:]\n    \n    layer = ctx.network.add_shuffle(input_trt)\n    layer.second_transpose = tuple(trt_permutation)\n    \n    output._trt = layer.get_output(0)\n\n\nclass Permute(torch.nn.Module):\n    def __init__(self, *args):\n        super(Permute, self).__init__()\n        self.args = args\n    def forward(self, x):\n        return x.permute(*self.args).contiguous()\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 5)])\ndef test_permute_2d_0123():\n    return Permute(0, 1, 2, 3)\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 5)])\ndef test_permute_2d_0312():\n    return Permute(0, 3, 1, 2)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 5, 6)])\ndef test_permute_3d_01234():\n    return Permute(0, 1, 2, 3, 4)\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 5, 6)])\ndef test_permute_3d_04132():\n    return Permute(0, 4, 1, 3, 2)\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 5, 6)])\ndef test_permute_list():\n    return Permute([0, 4, 1, 3, 2])\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 4, 5, 6)])\ndef test_permute_tuple():\n    return Permute((0, 4, 1, 3, 2))"""
torch2trt/converters/pow.py,15,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.pow')\n@tensorrt_converter('torch.Tensor.__ipow__')\n@tensorrt_converter('torch.Tensor.__pow__')\ndef convert_pow(ctx):\n    input_a = ctx.method_args[0]\n    input_b = ctx.method_args[1]\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.POW)\n    output._trt = layer.get_output(0)\n\n    \n@tensorrt_converter('torch.Tensor.__rpow__')\ndef convert_pow(ctx):\n    input_a = ctx.method_args[1]\n    input_b = ctx.method_args[0]  # flipped for rpow\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.POW)\n    output._trt = layer.get_output(0)\n    \n\nclass Pow(torch.nn.Module):\n    def __init__(self):\n        super(Pow, self).__init__()\n\n    def forward(self, x, y):\n        return x ** y\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_pow_basic():\n    return Pow()\n\n\n# __ipow__ not yet impl in torch\n# class IPow(torch.nn.Module):\n#     def __init__(self):\n#         super(IPow, self).__init__()\n\n#     def forward(self, x, y):\n#         x **= y\n#         return x\n\n\n# @add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\n# def test_pow_ipow():\n#     return IPow()\n\n\nclass TorchPow(torch.nn.Module):\n    def __init__(self):\n        super(TorchPow, self).__init__()\n\n    def forward(self, x, y):\n        return torch.pow(x, y)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_torch_pow():\n    return TorchPow()\n\n\nclass RpowInt(torch.nn.Module):\n    def __init__(self):\n        super(RpowInt, self).__init__()\n\n    def forward(self, x):\n        return 2 ** x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_rpow_int():\n    return RpowInt()\n\n\nclass RpowFloat(torch.nn.Module):\n    def __init__(self):\n        super(RpowFloat, self).__init__()\n\n    def forward(self, x):\n        return 2.0 ** x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_rpow_float():\n    return RpowFloat()"""
torch2trt/converters/prelu.py,10,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.prelu')\ndef convert_prelu(ctx):\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    weight = get_arg(ctx, 'weight', pos=1, default=None)\n    output = ctx.method_return\n    \n    weight_shape = [1] * (len(input.shape) - 1)\n    weight_shape[0] = weight.numel()\n    \n    input_trt = trt_(ctx.network, input)\n    \n   \n    # y = prelu(x) = relu(x) - alpha * relu(-x)\n    weight_trt = ctx.network.add_constant(weight_shape, -weight.detach().view(weight_shape).cpu().numpy()).get_output(0) # detach so considered leaf\n    \n    # x >= 0\n    a = ctx.network.add_activation(input_trt, trt.ActivationType.RELU).get_output(0)\n    \n    # x <= 0\n    b = ctx.network.add_unary(input_trt, trt.UnaryOperation.NEG).get_output(0)\n    b = ctx.network.add_activation(b, trt.ActivationType.RELU).get_output(0)\n    b = ctx.network.add_elementwise(b, weight_trt, trt.ElementWiseOperation.PROD).get_output(0)\n    \n    # y = a + b\n    y = ctx.network.add_elementwise(a, b, trt.ElementWiseOperation.SUM)\n    \n    output._trt = y.get_output(0)\n\n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3, 3)])\ndef test_prelu_scalar():\n    return torch.nn.PReLU()\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3, 3)])\ndef test_prelu_vector():\n    m = torch.nn.PReLU(5)\n    m.weight = torch.nn.Parameter(torch.randn(5)) # randn so each channel different\n    return m"""
torch2trt/converters/prod.py,13,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\nfrom .unary import UnaryModule\n    \n\n@tensorrt_converter('torch.prod')\n@tensorrt_converter('torch.Tensor.prod')\ndef convert_prod(ctx):\n    input = ctx.method_args[0]\n    dim = get_arg(ctx, 'dim', pos=1, default=tuple(range(1, input.ndim)))\n    keepdim = get_arg(ctx, 'keepdim', pos=2, default=False)\n    input_trt= trt_(ctx.network, input)\n    output = ctx.method_return\n    layer = ctx.network.add_reduce(input_trt,  trt.ReduceOperation.PROD, torch_dim_to_trt_axes(dim), keepdim)\n    output._trt = layer.get_output(0)\n        \n        \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_prod_reduce_all():\n    return UnaryModule(lambda x: torch.prod(x))     \n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_prod_reduce_dim1():\n    return UnaryModule(lambda x: torch.prod(x, 1))\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_prod_reduce_dim22():\n    return UnaryModule(lambda x: torch.prod(x, 2))\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_prod_reduce_dim1_keepdim():\n    return UnaryModule(lambda x: torch.prod(x, 1, keepdim=True))"""
torch2trt/converters/relu.py,5,"b""from torch2trt.torch2trt import *\nfrom .ReLU import *\n\n\n@tensorrt_converter('torch.relu')\n@tensorrt_converter('torch.relu_')\n@tensorrt_converter('torch.nn.functional.relu')\n@tensorrt_converter('torch.nn.functional.relu_')\ndef convert_relu(ctx):\n    ctx.method_args = (torch.nn.ReLU(),) + ctx.method_args\n    convert_ReLU(ctx)"""
torch2trt/converters/relu6.py,2,"b""from torch2trt.torch2trt import *\nfrom .ReLU6 import *\n\n\n@tensorrt_converter('torch.nn.functional.relu6')\ndef convert_relu6(ctx):\n    ctx.method_args = (torch.nn.ReLU6(),) + ctx.method_args\n    convert_ReLU6(ctx)"""
torch2trt/converters/sigmoid.py,4,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.sigmoid')\n@tensorrt_converter('torch.sigmoid')\ndef convert_sigmoid(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    \n    layer = ctx.network.add_activation(input_trt, trt.ActivationType.SIGMOID)\n    output._trt = layer.get_output(0)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_sigmoid_basic():\n    return torch.nn.Sigmoid()"""
torch2trt/converters/softmax.py,6,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.softmax')\ndef convert_softmax(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n\n    # get dims from args or kwargs\n    if 'dim' in ctx.method_kwargs:\n        dim = ctx.method_kwargs['dim']\n    elif len(ctx.method_args) >= 2:\n        dim = ctx.method_args[1]\n\n    axes = 1 << (dim - 1)\n\n    layer = ctx.network.add_softmax(input=input_trt)\n    layer.axes = axes\n\n    output._trt = layer.get_output(0)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_softmax_module():\n    return torch.nn.Softmax(1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_softmax_module_dim2():\n    return torch.nn.Softmax(2)\n"""
torch2trt/converters/split.py,14,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.split')\n@tensorrt_converter('torch.Tensor.split')\ndef convert_split(ctx):\n    input = get_arg(ctx, 'input', 0, None)\n    input_trt = trt_(ctx.network, input)\n    # we don't need to parse split/chunk (arg 1)\n    # since we infer size from output tensors\n    dim = get_arg(ctx, 'dim', 2, 0)\n    \n    outputs = ctx.method_return\n    \n    assert(dim >= 1)\n    \n    start = [0] * len(input.shape[1:]) # exclude batch\n    stride = [1] * len(start)\n    offset = 0\n    trt_dim = dim - 1\n    \n    # add slice layers\n    for i, output in enumerate(outputs):\n        shape = list(output.shape[1:]) # exclude batch dim\n        start[trt_dim] = offset\n        layer = ctx.network.add_slice(input_trt, start=start, shape=shape, stride=stride)\n        output._trt = layer.get_output(0)\n        offset = offset + shape[trt_dim]\n        \n\nclass TorchSplit(torch.nn.Module):\n    \n    def __init__(self, *args, **kwargs):\n        super(TorchSplit, self).__init__()\n        self.args = args\n        self.kwargs = kwargs\n        \n    def forward(self, x):\n        return torch.split(x, *self.args, **self.kwargs)\n    \n    \nclass TensorSplit(torch.nn.Module):\n    \n    def __init__(self, *args, **kwargs):\n        super(TensorSplit, self).__init__()\n        self.args = args\n        self.kwargs = kwargs\n        \n    def forward(self, x):\n        return x.split(*self.args, **self.kwargs)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_torch_split_1_1():\n    return TorchSplit(1, 1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_torch_split_2_1():\n    return TorchSplit(2, 1)\n\n    \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_torch_split_3_1():\n    return TorchSplit(3, 1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_torch_split_3_2():\n    return TorchSplit(3, 2)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_tensor_split_3_2():\n    return TensorSplit(3, 2)"""
torch2trt/converters/sub.py,15,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.sub')\n@tensorrt_converter('torch.Tensor.__isub__')\n@tensorrt_converter('torch.Tensor.__sub__')\ndef convert_sub(ctx):\n    input_a = ctx.method_args[0]\n    input_b = ctx.method_args[1]\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.SUB)\n    output._trt = layer.get_output(0)\n\n    \n@tensorrt_converter('torch.Tensor.__rsub__')\ndef convert_sub(ctx):\n    input_a = ctx.method_args[1]\n    input_b = ctx.method_args[0]  # flipped for rsub\n    input_a_trt, input_b_trt = trt_(ctx.network, input_a, input_b)\n    output = ctx.method_return\n    layer = ctx.network.add_elementwise(input_a_trt, input_b_trt, trt.ElementWiseOperation.SUB)\n    output._trt = layer.get_output(0)\n    \n\nclass Sub(torch.nn.Module):\n    def __init__(self):\n        super(Sub, self).__init__()\n\n    def forward(self, x, y):\n        return x - y\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_sub_basic():\n    return Sub()\n\n\nclass ISub(torch.nn.Module):\n    def __init__(self):\n        super(ISub, self).__init__()\n\n    def forward(self, x, y):\n        x -= y\n        return x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_sub_isub():\n    return ISub()\n\n\nclass TorchSub(torch.nn.Module):\n    def __init__(self):\n        super(TorchSub, self).__init__()\n\n    def forward(self, x, y):\n        return torch.sub(x, y)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224), (1, 3, 224, 224)])\ndef test_torch_sub():\n    return TorchSub()\n\n\nclass RSubInt(torch.nn.Module):\n    def __init__(self):\n        super(RSubInt, self).__init__()\n\n    def forward(self, x):\n        return 1 - x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_rsub_int():\n    return RSubInt()\n\n\nclass RSubFloat(torch.nn.Module):\n    def __init__(self):\n        super(RSubFloat, self).__init__()\n\n    def forward(self, x):\n        return 1.0 - x\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 224, 224)])\ndef test_rsub_float():\n    return RSubFloat()"""
torch2trt/converters/sum.py,13,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\nfrom .unary import UnaryModule\n    \n\n@tensorrt_converter('torch.sum')\n@tensorrt_converter('torch.Tensor.sum')\ndef convert_sum(ctx):\n    input = ctx.method_args[0]\n    dim = get_arg(ctx, 'dim', pos=1, default=tuple(range(1, input.ndim)))\n    keepdim = get_arg(ctx, 'keepdim', pos=2, default=False)\n    input_trt= trt_(ctx.network, input)\n    output = ctx.method_return\n    layer = ctx.network.add_reduce(input_trt,  trt.ReduceOperation.SUM, torch_dim_to_trt_axes(dim), keepdim)\n    output._trt = layer.get_output(0)\n        \n        \n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_sum_reduce_all():\n    return UnaryModule(lambda x: torch.sum(x))     \n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_sum_reduce_dim1():\n    return UnaryModule(lambda x: torch.sum(x, 1))\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_sum_reduce_dim22():\n    return UnaryModule(lambda x: torch.sum(x, 2))\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\ndef test_sum_reduce_dim1_keepdim():\n    return UnaryModule(lambda x: torch.sum(x, 1, keepdim=True))"""
torch2trt/converters/tanh.py,4,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.nn.functional.tanh')\n@tensorrt_converter('torch.tanh')\ndef convert_tanh(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    \n    layer = ctx.network.add_activation(input_trt, trt.ActivationType.TANH)\n    output._trt = layer.get_output(0)\n    \n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_tanh_basic():\n    return torch.nn.Tanh()"""
torch2trt/converters/transpose.py,5,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.transpose')\ndef convert_transpose(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    # permutation -1 because TRT does not include batch dim\n    permutation = list(range(len(input.shape) - 1))\n    dim0 = ctx.method_args[1] - 1\n    dim1 = ctx.method_args[2] - 1\n    permutation[dim0] = dim1\n    permutation[dim1] = dim0\n    layer = ctx.network.add_shuffle(input_trt)\n    layer.second_transpose = tuple(permutation)\n    output._trt = layer.get_output(0)\n\n\nclass Transpose(torch.nn.Module):\n    def __init__(self, dim0, dim1):\n        super(Transpose, self).__init__()\n        self.dim0 = dim0\n        self.dim1 = dim1\n    def forward(self, x):\n        return torch.transpose(x, self.dim0, self.dim1).contiguous()\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_transpose_12():\n    return Transpose(1, 2)\n"""
torch2trt/converters/unary.py,97,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n        \ndef __convert_unary(ctx, op):\n    input = get_arg(ctx, 'input', pos=0, default=None)\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    layer = ctx.network.add_unary(input_trt, op)\n    output._trt = layer.get_output(0)\n    \n\nclass UnaryModule(torch.nn.Module):\n    def __init__(self, fn):\n        super(UnaryModule, self).__init__()\n        self.fn = fn\n        \n    def forward(self, x):\n        return self.fn(x)\n    \n# EXP : Exponentiation\n\n\n@tensorrt_converter('torch.exp')\n@tensorrt_converter('torch.exp_')\n@tensorrt_converter('torch.Tensor.exp')\n@tensorrt_converter('torch.Tensor.exp_')\ndef convert_exp(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.EXP)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_exp():\n    return UnaryModule(lambda x: torch.exp(x))\n\n\n#  LOG : Log (base e)\n\n\n@tensorrt_converter('torch.log')\n@tensorrt_converter('torch.log_')\n@tensorrt_converter('torch.Tensor.log')\n@tensorrt_converter('torch.Tensor.log_')\ndef convert_log(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.LOG)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_log():\n    return UnaryModule(lambda x: torch.log(x))\n\n\n# SQRT : Square root\n\n\n@tensorrt_converter('torch.sqrt')\n@tensorrt_converter('torch.sqrt_')\n@tensorrt_converter('torch.Tensor.sqrt')\n@tensorrt_converter('torch.Tensor.sqrt_')\ndef convert_sqrt(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.SQRT)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_sqrt():\n    return UnaryModule(lambda x: torch.sqrt(x))\n\n\n# RECIP : Reciprocal\n\n\n@tensorrt_converter('torch.reciprocal')\n@tensorrt_converter('torch.reciprocal_')\n@tensorrt_converter('torch.Tensor.reciprocal')\n@tensorrt_converter('torch.Tensor.reciprocal_')\ndef convert_reciprocal(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.RECIP)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_reciprocal():\n    return UnaryModule(lambda x: torch.reciprocal(x))\n\n\n# ABS : Absolute value\n\n\n@tensorrt_converter('torch.abs')\n@tensorrt_converter('torch.abs_')\n@tensorrt_converter('torch.Tensor.abs')\n@tensorrt_converter('torch.Tensor.abs_')\ndef convert_abs(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.ABS)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_abs():\n    return UnaryModule(lambda x: torch.abs(x))\n\n\n#  NEG : Negation\n\n@tensorrt_converter('torch.neg')\n@tensorrt_converter('torch.neg_')\n@tensorrt_converter('torch.Tensor.neg')\n@tensorrt_converter('torch.Tensor.neg_')\ndef convert_neg(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.NEG)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_neg():\n    return UnaryModule(lambda x: torch.neg(x))\n\n\n#  SIN : Sine\n\n\n@tensorrt_converter('torch.sin')\n@tensorrt_converter('torch.sin_')\n@tensorrt_converter('torch.Tensor.sin')\n@tensorrt_converter('torch.Tensor.sin_')\ndef convert_sin(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.SIN)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_sin():\n    return UnaryModule(lambda x: torch.sin(x))\n\n\n#  COS : Cosine\n\n\n@tensorrt_converter('torch.cos')\n@tensorrt_converter('torch.cos_')\n@tensorrt_converter('torch.Tensor.cos')\n@tensorrt_converter('torch.Tensor.cos_')\ndef convert_cos(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.COS)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_cos():\n    return UnaryModule(lambda x: torch.cos(x))\n\n\n#  |    TAN : Tangent\n\n\n@tensorrt_converter('torch.tan')\n@tensorrt_converter('torch.tan_')\n@tensorrt_converter('torch.Tensor.tan')\n@tensorrt_converter('torch.Tensor.tan_')\ndef convert_cos(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.TAN)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_tan():\n    return UnaryModule(lambda x: torch.tan(x))\n\n\n#  |    SINH : Hyperbolic sine\n\n\n@tensorrt_converter('torch.sinh')\n@tensorrt_converter('torch.sinh_')\n@tensorrt_converter('torch.Tensor.sinh')\n@tensorrt_converter('torch.Tensor.sinh_')\ndef convert_sinh(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.SINH)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_sinh():\n    return UnaryModule(lambda x: torch.sinh(x))\n\n\n#  |    COSH : Hyperbolic cosine\n\n\n@tensorrt_converter('torch.cosh')\n@tensorrt_converter('torch.cosh_')\n@tensorrt_converter('torch.Tensor.cosh')\n@tensorrt_converter('torch.Tensor.cosh_')\ndef convert_cosh(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.COSH)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_cosh():\n    return UnaryModule(lambda x: torch.cosh(x))\n\n\n#  |    ASIN : Inverse sine\n\n\n@tensorrt_converter('torch.asin')\n@tensorrt_converter('torch.asin_')\n@tensorrt_converter('torch.Tensor.asin')\n@tensorrt_converter('torch.Tensor.asin_')\ndef convert_asin(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.ASIN)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_asin():\n    return UnaryModule(lambda x: torch.asin(x))\n\n\n#  |    ACOS : Inverse cosine\n\n\n@tensorrt_converter('torch.acos')\n@tensorrt_converter('torch.acos_')\n@tensorrt_converter('torch.Tensor.acos')\n@tensorrt_converter('torch.Tensor.acos_')\ndef convert_acos(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.ACOS)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_acos():\n    return UnaryModule(lambda x: torch.acos(x))\n\n\n#  |    ATAN : Inverse tangent\n\n\n@tensorrt_converter('torch.atan')\n@tensorrt_converter('torch.atan_')\n@tensorrt_converter('torch.Tensor.atan')\n@tensorrt_converter('torch.Tensor.atan_')\ndef convert_atan(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.ATAN)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_atan():\n    return UnaryModule(lambda x: torch.atan(x))\n\n\n#  |    ASINH : Inverse hyperbolic sine\n#  |  \n#  |    ACOSH : Inverse hyperbolic cosine\n#  |  \n#  |    ATANH : Inverse hyperbolic tangent\n#  |  \n\n#  CEIL : Ceiling\n\n\n@tensorrt_converter('torch.ceil')\n@tensorrt_converter('torch.ceil_')\n@tensorrt_converter('torch.Tensor.ceil')\n@tensorrt_converter('torch.Tensor.ceil_')\ndef convert_ceil(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.CEIL)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_ceil():\n    return UnaryModule(lambda x: torch.ceil(x))\n\n\n#  FLOOR : Floor\n        \n\n@tensorrt_converter('torch.floor')\n@tensorrt_converter('torch.floor_')\n@tensorrt_converter('torch.Tensor.floor')\n@tensorrt_converter('torch.Tensor.floor_')\ndef convert_floor(ctx):\n    __convert_unary(ctx, trt.UnaryOperation.FLOOR)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 5, 3)])\ndef test_floor():\n    return UnaryModule(lambda x: torch.floor(x))"""
torch2trt/converters/view.py,13,"b""from torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\n\n\n@tensorrt_converter('torch.flatten')\n@tensorrt_converter('torch.Tensor.reshape')\n@tensorrt_converter('torch.Tensor.view')\ndef convert_view(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n    layer = ctx.network.add_shuffle(input_trt)\n    layer.reshape_dims = tuple(output.shape[1:])\n    output._trt = layer.get_output(0)\n\n\nclass View(torch.nn.Module):\n    def __init__(self, *dims):\n        super(View, self).__init__()\n        self.dims = dims\n\n    def forward(self, x):\n        return x.view(*self.dims)\n\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_view_1d():\n    return View(1, -1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_view_2d():\n    return View(1, 1, -1)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3)])\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 3, 3, 3)])\ndef test_view_3d():\n    return View(1, 1, 1, -1)\n"""
torch2trt/tests/__init__.py,0,b''
torch2trt/converters/interpolate/__init__.py,0,b'from .interpolate import *\n'
torch2trt/converters/interpolate/interpolate.py,9,"b""import tensorrt as trt\nimport torch.nn.functional as F\nfrom torch2trt.torch2trt import *\nfrom torch2trt.module_test import add_module_test\nfrom .interpolate_pb2 import interpolate_Message\nimport torch.nn as nn \n\ndef get_interpolate_plugin(size, mode, align_corners):\n    PLUGIN_NAME = 'interpolate'\n    registry = trt.get_plugin_registry()\n    creator = [c for c in registry.plugin_creator_list if c.name == PLUGIN_NAME and c.plugin_namespace == 'torch2trt'][0]\n    message = interpolate_Message(size=size, mode=mode, align_corners=align_corners)\n    return creator.deserialize_plugin(PLUGIN_NAME, message.SerializeToString())\n\n\n@tensorrt_converter('torch.nn.functional.interpolate')\ndef convert_interpolate(ctx):\n    input = ctx.method_args[0]\n    input_trt = trt_(ctx.network, input)\n    output = ctx.method_return\n\n    try:\n        mode = get_arg(ctx, 'mode', pos=3, default='nearest')\n    except KeyError:\n        mode = 'nearest'\n\n    try:\n        align_corners = get_arg(ctx, 'align_corners', pos=4, default=None)\n    except KeyError:\n        align_corners = False\n\n    # currently only works for NCHW\n    size = list(output.shape[2:])\n\n    plugin = get_interpolate_plugin(size=size, mode=mode, align_corners=align_corners)\n\n    layer = ctx.network.add_plugin_v2([input_trt], plugin)\n\n    output._trt = layer.get_output(0)\n\n\nclass Interpolate(torch.nn.Module):\n    def __init__(self, size, mode, align_corners):\n        super(Interpolate, self).__init__()\n        self.size = size\n        self.mode = mode\n        self.align_corners = align_corners\n\n    def forward(self, x):\n        return F.interpolate(x, self.size, mode=self.mode, align_corners=self.align_corners)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 112, 112)])\ndef test_interpolate_nearest():\n    return Interpolate((224, 224), 'nearest', None)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 112, 112)])\ndef test_interpolate_bilinear():\n    return Interpolate((224, 224), 'bilinear', False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 112, 112)])\ndef test_interpolate_bicubic():\n    return Interpolate((224, 224), 'bicubic', False)\n\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 112, 112)])\ndef test_interpolate_area():\n    return Interpolate((56, 56), 'area', None)\n\n@add_module_test(torch.float32, torch.device('cuda'), [(1, 10, 112, 112)])\ndef test_upsample_scale_factor2():\n    return nn.Upsample(scale_factor=2, mode='bilinear',align_corners=False)"""
torch2trt/tests/torchvision/__init__.py,0,b''
torch2trt/tests/torchvision/classification.py,29,"b""import torch\nimport torchvision\nfrom torch2trt.module_test import add_module_test\n\n    \n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef alexnet():\n    return torchvision.models.alexnet(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef squeezenet1_0():\n    return torchvision.models.squeezenet1_0(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef squeezenet1_1():\n    return torchvision.models.squeezenet1_1(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef resnet18():\n    return torchvision.models.resnet18(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef resnet34():\n    return torchvision.models.resnet34(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef resnet50():\n    return torchvision.models.resnet50(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef resnet101():\n    return torchvision.models.resnet101(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef resnet152():\n    return torchvision.models.resnet152(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef densenet121():\n    return torchvision.models.densenet121(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef densenet169():\n    return torchvision.models.densenet169(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef densenet201():\n    return torchvision.models.densenet201(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef densenet161():\n    return torchvision.models.densenet161(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef vgg11():\n    return torchvision.models.vgg11(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef vgg13():\n    return torchvision.models.vgg13(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef vgg16():\n    return torchvision.models.vgg16(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef vgg19():\n    return torchvision.models.vgg19(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef vgg11_bn():\n    return torchvision.models.vgg11_bn(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef vgg13_bn():\n    return torchvision.models.vgg13_bn(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef vgg16_bn():\n    return torchvision.models.vgg16_bn(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef vgg19_bn():\n    return torchvision.models.vgg19_bn(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef mobilenet_v2():\n    return torchvision.models.mobilenet_v2(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef shufflenet_v2_x0_5():\n    return torchvision.models.shufflenet_v2_x0_5(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef shufflenet_v2_x1_0():\n    return torchvision.models.shufflenet_v2_x1_0(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef shufflenet_v2_x1_5():\n    return torchvision.models.shufflenet_v2_x1_5(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef shufflenet_v2_x2_0():\n    return torchvision.models.shufflenet_v2_x2_0(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef mnasnet0_5():\n    return torchvision.models.mnasnet0_5(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef mnasnet0_75():\n    return torchvision.models.mnasnet0_75(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef mnasnet1_0():\n    return torchvision.models.mnasnet1_0(pretrained=False)\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef mnasnet1_3():\n    return torchvision.models.mnasnet1_3(pretrained=False)"""
torch2trt/tests/torchvision/save_load.py,5,"b""from torch2trt import *\nimport torchvision\nimport torch\nfrom .segmentation import deeplabv3_resnet50\n\n\nif __name__ == '__main__':\n    model = deeplabv3_resnet50().cuda().eval().half()\n    data = torch.randn((1, 3, 224, 224)).cuda().half()\n    \n    print('Running torch2trt...')\n    model_trt = torch2trt(model, [data], fp16_mode=True, max_workspace_size=1<<25)\n\n    print('Saving model...')\n    torch.save(model_trt.state_dict(), '.test_model.pth')\n\n    print('Loading model...')\n    model_trt_2 = TRTModule()\n    model_trt_2.load_state_dict(torch.load('.test_model.pth'))\n\n    assert(model_trt_2.engine is not None)\n    \n    print(torch.max(torch.abs(model_trt_2(data) - model(data))))\n    print(torch.max(torch.abs(model_trt_2(data) - model_trt(data))))"""
torch2trt/tests/torchvision/segmentation.py,5,"b""import torch\nimport torchvision\nfrom torch2trt.module_test import add_module_test\n\n\nclass ModelWrapper(torch.nn.Module):\n    def __init__(self, model):\n        super(ModelWrapper, self).__init__()\n        self.model = model\n    def forward(self, x):\n        return self.model(x)['out']\n    \n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)  \ndef deeplabv3_resnet50():\n    bb = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False)\n    model = ModelWrapper(bb)\n    return model\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef deeplabv3_resnet101():\n    bb = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False)\n    model = ModelWrapper(bb)\n    return model\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef fcn_resnet50():\n    bb = torchvision.models.segmentation.fcn_resnet50(pretrained=False)\n    model = ModelWrapper(bb)\n    return model\n\n\n@add_module_test(torch.float16, torch.device('cuda'), [(1, 3, 224, 224)], fp16_mode=True)\ndef fcn_resnet101():\n    bb = torchvision.models.segmentation.fcn_resnet101(pretrained=False)\n    model = ModelWrapper(bb)\n    return model"""
