file_path,api_count,code
Caffe/proc_images.py,0,"b'#!/usr/bin/env python\nimport time\nimport glob,os,sys\nimport subprocess\nfrom math import ceil\nimport numpy as np\nimport PIL\nfrom PIL import Image, ImageDraw, ImageFont\nfrom scipy.misc import imread,imsave\n\n# to output the visualization, please download flow_io.py and viz_flow.py from https://github.com/jswulff/pcaflow/tree/master/pcaflow/utils\n# from flow_io import flow_read\n# from viz_flow import viz_flow \n\n\n# Please modify to your local caffe directory\ncaffe_bin = \'/mnt/zfs/projects/ml_flow/v2x/flownet2/build/tools/caffe.bin\'\n\ngpu_id = 0\n\n# =========================================================\ndef evaluate_model(template, model_filename, img1_filename, img2_filename, save_filenames, vis_save_filenames,  scale_ratio=1.0):\n    if not os.path.isfile(caffe_bin):\n        print(\'Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?\')\n        sys.exit(1)\n\n    with open(img1_filename, \'r\') as f:\n        images1 = [line.strip() for line in f.readlines() if len(line.strip()) > 0]\n    with open(img2_filename, \'r\') as f:\n        images2 = [line.strip() for line in f.readlines() if len(line.strip()) > 0]\n    if len(images1) != len(images2):\n        print(""Unequal amount of images in the given lists (%d vs. %d)"" % (len(images1), len(images2)))\n        sys.exit(1)\n\n    list_length = len(images1)\n    im1 = imread(images1[0])\n    im2 = imread(images2[0])\n    if im1.shape != im2.shape:\n        print(""The image pairs do not have equal sizes!"")\n        sys.exit(1)       \n    width  = im1.shape[1]\n    height = im1.shape[0]    \n    # print list_length\n\n\n    # Prepare prototxt\n    subprocess.call([\'cp\', img1_filename, \'tmp/img1.txt\'])\n    subprocess.call([\'cp\', img2_filename, \'tmp/img2.txt\'])\n\n    # set up width and height for processing\n    divisor = 64.\n    adapted_width   = ceil(width/divisor*scale_ratio) * divisor\n    adapted_height  = ceil(height/divisor*scale_ratio) * divisor        \n    rescale_coeff_x = width / adapted_width\n    rescale_coeff_y = height / adapted_height\n    replacement_list = {\n        \'$ADAPTED_WIDTH\': (\'%d\' % adapted_width),\n        \'$ADAPTED_HEIGHT\': (\'%d\' % adapted_height),\n        \'$TARGET_WIDTH\': (\'%d\' % width),\n        \'$TARGET_HEIGHT\': (\'%d\' % height),\n        \'$SCALE_WIDTH\': (\'%.8f\' % rescale_coeff_x),\n        \'$SCALE_HEIGHT\': (\'%.8f\' % rescale_coeff_y)\n    }\n    proto = \'\'\n    with open(template, ""r"") as tfile:\n        proto = tfile.read()\n    for r in replacement_list:\n        proto = proto.replace(r, replacement_list[r])\n    with open(\'tmp/deploy.prototxt\', ""w"") as tfile:\n        tfile.write(proto)\n\n\n    args = [caffe_bin, \'test\', \'-model\', \'tmp/deploy.prototxt\',\n            \'-weights\', model_filename,  \'-iterations\', str(list_length), \'-gpu\', str(gpu_id)]\n\n    cmd = str.join(\' \', args)\n    print(\'Executing %s\' % cmd)\n    subprocess.call(args)       \n    \n    if save_filenames != None:\n        for ifile in range(len(save_filenames)):\n            print save_filenames[ifile]\n            flow_fn = \'pwc-net-pred-\' + str(ifile).zfill(7) + \'.flo\'\n            if not os.path.exists(flow_fn): flow_fn = os.path.join(\'./tmp\', flow_fn)\n            # to output the visualization, please download flow_io.py and viz_flow.py from https://github.com/jswulff/pcaflow/tree/master/pcaflow/utils\n            # uv  = flow_read(flow_fn)\n            # I_flow = Image.fromarray(viz_flow(uv[0], uv[1]))\n            # imsave(vis_save_filenames[ifile], I_flow)    \n            os.system (""mv  %s %s"" % (flow_fn, save_filenames[ifile]) )\n\n###################\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\nif not os.path.exists(\'./tmp\'): os.mkdir(\'./tmp\')\n\ntemplate        = \'./model/pwc_net_test.prototxt\'\nmodel_filename  = \'./model/pwc_net.caffemodel\'   \n\n\nimage1_list     = \'./img1.txt\';\nimage2_list     = \'./img2.txt\';\nout_flow_file   = \'./out.txt\';\nout_vis_file    = None;\n\nif len(sys.argv) > 1:\n    image1_list = sys.argv[1]\nif len(sys.argv) > 2:\n    image2_list = sys.argv[2]\nif len(sys.argv) > 3:\n    out_flow_file = sys.argv[3]\nif len(sys.argv) > 4:\n    out_vis_file = sys.argv[4]\n\nwith open(out_flow_file, \'r\') as f:\n    out_flow_list = [line.strip() for line in f.readlines() if len(line.strip()) > 0]\nif out_vis_file != None:\n    with open(out_vis_file, \'r\') as f:\n        out_vis_list = [line.strip() for line in f.readlines() if len(line.strip()) > 0]\nelse:\n    out_vis_list = None\n\n# for small images, it better set the scale_ratio to be 2.0 or 3.0 so that the input has height/width around 1000\nscale_ratio = 1.0\nevaluate_model(template, model_filename, image1_list, image2_list, out_flow_list, out_vis_list, scale_ratio)\n\n'"
Caffe/train.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe' # PLEASE MODIFY TO YOUR LOCAL DIRECTORY\n\nos.system('mkdir training') \nos.chdir('training') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\t# start from scratch\n\targs = [caffe_bin, 'train', '-solver', '../model/solver.prototxt'] + sys.argv[1:]\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tlatest_iter = max(iters)\n\targs = [caffe_bin, 'train', '-solver', '../model/solver.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Multi_Frame_Flow/script_pwc.py,3,"b'#! /usr/bin/env python\n\n""""""\nCopyright (C) 2018 NVIDIA Corporation.  All rights reserved.\nLicensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).\n""""""\n\nimport sys\nimport cv2\nimport torch\nimport numpy as np\nfrom math import ceil\nfrom torch.autograd import Variable\nfrom scipy.ndimage import imread\nimport models\n\n\ndef writeFlowFile(filename, uv):\n\t""""""\n\tAccording to the matlab code of Deqing Sun and c++ source code of Daniel Scharstein  \n\tContact: dqsun@cs.brown.edu\n\tContact: schar@middlebury.edu\n\t""""""\n\tTAG_STRING = np.array(202021.25, dtype=np.float32)\n\tif uv.shape[2] != 2:\n\t\tsys.exit(""writeFlowFile: flow must have two bands!"");\n\tH = np.array(uv.shape[0], dtype=np.int32)\n\tW = np.array(uv.shape[1], dtype=np.int32)\n\twith open(filename, \'wb\') as f:\n\t\tf.write(TAG_STRING.tobytes())\n\t\tf.write(W.tobytes())\n\t\tf.write(H.tobytes())\n\t\tf.write(uv.tobytes())\n\n\nim1_fn = \'data/frame_0010.png\';\nim2_fn = \'data/frame_0011.png\';\nflow_fn = \'./tmp/frame_0010.flo\';\n\nif len(sys.argv) > 1:\n    im1_fn = sys.argv[1]\nif len(sys.argv) > 2:\n    im2_fn = sys.argv[2]\nif len(sys.argv) > 3:\n    flow_fn = sys.argv[3]\n\npwc_model_fn = \'./pwc_net.pth.tar\';\n\nim_all = [imread(img) for img in [im1_fn, im2_fn]]\nim_all = [im[:, :, :3] for im in im_all]\n\n# rescale the image size to be multiples of 64\ndivisor = 64.\nH = im_all[0].shape[0]\nW = im_all[0].shape[1]\n\nH_ = int(ceil(H/divisor) * divisor)\nW_ = int(ceil(W/divisor) * divisor)\nfor i in range(len(im_all)):\n\tim_all[i] = cv2.resize(im_all[i], (W_, H_))\n\nfor _i, _inputs in enumerate(im_all):\n\tim_all[_i] = im_all[_i][:, :, ::-1]\n\tim_all[_i] = 1.0 * im_all[_i]/255.0\n\t\n\tim_all[_i] = np.transpose(im_all[_i], (2, 0, 1))\n\tim_all[_i] = torch.from_numpy(im_all[_i])\n\tim_all[_i] = im_all[_i].expand(1, im_all[_i].size()[0], im_all[_i].size()[1], im_all[_i].size()[2])\t\n\tim_all[_i] = im_all[_i].float()\n    \nim_all = torch.autograd.Variable(torch.cat(im_all,1).cuda(), volatile=True)\n\nnet = models.pwc_dc_net(pwc_model_fn)\nnet = net.cuda()\nnet.eval()\n\nflo = net(im_all)\nflo = flo[0] * 20.0\nflo = flo.cpu().data.numpy()\n\n# scale the flow back to the input size \nflo = np.swapaxes(np.swapaxes(flo, 0, 1), 1, 2) # \nu_ = cv2.resize(flo[:,:,0],(W,H))\nv_ = cv2.resize(flo[:,:,1],(W,H))\nu_ *= W/ float(W_)\nv_ *= H/ float(H_)\nflo = np.dstack((u_,v_))\n\nwriteFlowFile(flow_fn, flo)\n'"
Multi_Frame_Flow/script_pwc_fusion.py,7,"b'#! /usr/bin/env python\n\n""""""\nCopyright (C) 2018 NVIDIA Corporation.  All rights reserved.\nLicensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).\n""""""\n\nimport sys\nimport cv2\nimport torch\nimport numpy as np\nfrom math import ceil\nfrom torch.autograd import Variable\nfrom scipy.ndimage import imread\nimport models\nimport pdb\n\ndef writeFlowFile(filename, uv):\n\t""""""\n\tAccording to the matlab code of Deqing Sun and c++ source code of Daniel Scharstein  \n\tContact: dqsun@cs.brown.edu\n\tContact: schar@middlebury.edu\n\t""""""\n\tTAG_STRING = np.array(202021.25, dtype=np.float32)\n\tif uv.shape[2] != 2:\n\t\tsys.exit(""writeFlowFile: flow must have two bands!"");\n\tH = np.array(uv.shape[0], dtype=np.int32)\n\tW = np.array(uv.shape[1], dtype=np.int32)\n\twith open(filename, \'wb\') as f:\n\t\tf.write(TAG_STRING.tobytes())\n\t\tf.write(W.tobytes())\n\t\tf.write(H.tobytes())\n\t\tf.write(uv.tobytes())\n\n# Default values if the function is called with no input parameters\nim0_fn = \'data/frame_0009.png\';\nim1_fn = \'data/frame_0010.png\';\nim2_fn = \'data/frame_0011.png\';\nflow_fn = \'./tmp/frame_0010_fusion.flo\';\n\nif len(sys.argv) > 1:\n\tim0_fn = sys.argv[1]\nif len(sys.argv) > 2:\n    im1_fn = sys.argv[2]\nif len(sys.argv) > 3:\n    im2_fn = sys.argv[3]\nif len(sys.argv) > 4:\n    flow_fn = sys.argv[4]\n\npwc_model_fn = \'./pwc_net.pth.tar\';\n\nim_all = [imread(img) for img in [im0_fn, im1_fn, im2_fn]]\nim_all = [im[:, :, :3] for im in im_all]\n\n# rescale the image size to be multiples of 64\ndivisor = 64.\nH = im_all[0].shape[0]\nW = im_all[0].shape[1]\n\nH_ = int(ceil(H/divisor) * divisor)\nW_ = int(ceil(W/divisor) * divisor)\nfor i in range(len(im_all)):\n\tim_all[i] = cv2.resize(im_all[i], (W_, H_))\n\nfor _i, _inputs in enumerate(im_all):\n\tim_all[_i] = im_all[_i][:, :, ::-1]\n\tim_all[_i] = 1.0 * im_all[_i]/255.0\n\t\n\tim_all[_i] = np.transpose(im_all[_i], (2, 0, 1))\n\tim_all[_i] = torch.from_numpy(im_all[_i])\n\tim_all[_i] = im_all[_i].expand(1, im_all[_i].size()[0], im_all[_i].size()[1], im_all[_i].size()[2])\t\n\tim_all[_i] = im_all[_i].float()\n    \n# compute two frame flows\ninput_01 = [im_all[0].cuda(), im_all[1].cuda()]\ninput_01_var = torch.autograd.Variable(torch.cat(input_01,1), volatile=True)\n\ninput_12 = [im_all[1].cuda(), im_all[2].cuda()]\ninput_12_var = torch.autograd.Variable(torch.cat(input_12,1), volatile=True)\n\ninput_10 = [im_all[1].cuda(), im_all[0].cuda()]\ninput_10_var = torch.autograd.Variable(torch.cat(input_10,1), volatile=True)\n\n\nnet = models.pwc_dc_net(pwc_model_fn)\nnet = net.cuda()\nnet.eval()\nfor p in net.parameters():\n    p.requires_grad = False\n\ncur_flow = net(input_12_var) * 20.0\nprev_flow = net(input_01_var) * 20.0\nprev_flow_back = net(input_10_var) * 20.0\n\n# perfom flow fusion\nnet_fusion = models.netfusion_custom(path=""./fusion_net.pth.tar"",\n                                     div_flow=20.0, \n                                     batchNorm=False)\nnet_fusion = net_fusion.cuda()\nnet_fusion.eval()\nfor p in net_fusion.parameters():\n    p.requires_grad = False\n\nupsample_layer = torch.nn.Upsample(scale_factor=4, mode=\'bilinear\')\n\ncur_flow = upsample_layer(cur_flow)\nprev_flow = upsample_layer(prev_flow)\nprev_flow_back = upsample_layer(prev_flow_back)\ninput_var_cat = torch.cat((input_12_var, cur_flow, prev_flow, prev_flow_back), dim=1)\nflo = net_fusion(input_var_cat)\n\nflo = flo[0] * 20.0\nflo = flo.cpu().data.numpy()\n\n# scale the flow back to the input size \nflo = np.swapaxes(np.swapaxes(flo, 0, 1), 1, 2) # \nu_ = cv2.resize(flo[:,:,0],(W,H))\nv_ = cv2.resize(flo[:,:,1],(W,H))\nu_ *= W/ float(W_)\nv_ *= H/ float(H_)\nflo = np.dstack((u_,v_))\n\nwriteFlowFile(flow_fn, flo)\n'"
PyTorch/script_pwc.py,3,"b'import sys\nimport cv2\nimport torch\nimport numpy as np\nfrom math import ceil\nfrom torch.autograd import Variable\nfrom scipy.ndimage import imread\nimport models\n""""""\nContact: Deqing Sun (deqings@nvidia.com); Zhile Ren (jrenzhile@gmail.com)\n""""""\ndef writeFlowFile(filename,uv):\n\t""""""\n\tAccording to the matlab code of Deqing Sun and c++ source code of Daniel Scharstein  \n\tContact: dqsun@cs.brown.edu\n\tContact: schar@middlebury.edu\n\t""""""\n\tTAG_STRING = np.array(202021.25, dtype=np.float32)\n\tif uv.shape[2] != 2:\n\t\tsys.exit(""writeFlowFile: flow must have two bands!"");\n\tH = np.array(uv.shape[0], dtype=np.int32)\n\tW = np.array(uv.shape[1], dtype=np.int32)\n\twith open(filename, \'wb\') as f:\n\t\tf.write(TAG_STRING.tobytes())\n\t\tf.write(W.tobytes())\n\t\tf.write(H.tobytes())\n\t\tf.write(uv.tobytes())\n\n\nim1_fn = \'data/frame_0010.png\';\nim2_fn = \'data/frame_0011.png\';\nflow_fn = \'./tmp/frame_0010.flo\';\n\nif len(sys.argv) > 1:\n    im1_fn = sys.argv[1]\nif len(sys.argv) > 2:\n    im2_fn = sys.argv[2]\nif len(sys.argv) > 3:\n    flow_fn = sys.argv[3]\n\npwc_model_fn = \'./pwc_net.pth.tar\';\n\nim_all = [imread(img) for img in [im1_fn, im2_fn]]\nim_all = [im[:, :, :3] for im in im_all]\n\n# rescale the image size to be multiples of 64\ndivisor = 64.\nH = im_all[0].shape[0]\nW = im_all[0].shape[1]\n\nH_ = int(ceil(H/divisor) * divisor)\nW_ = int(ceil(W/divisor) * divisor)\nfor i in range(len(im_all)):\n\tim_all[i] = cv2.resize(im_all[i], (W_, H_))\n\nfor _i, _inputs in enumerate(im_all):\n\tim_all[_i] = im_all[_i][:, :, ::-1]\n\tim_all[_i] = 1.0 * im_all[_i]/255.0\n\t\n\tim_all[_i] = np.transpose(im_all[_i], (2, 0, 1))\n\tim_all[_i] = torch.from_numpy(im_all[_i])\n\tim_all[_i] = im_all[_i].expand(1, im_all[_i].size()[0], im_all[_i].size()[1], im_all[_i].size()[2])\t\n\tim_all[_i] = im_all[_i].float()\n    \nim_all = torch.autograd.Variable(torch.cat(im_all,1).cuda(), volatile=True)\n\nnet = models.pwc_dc_net(pwc_model_fn)\nnet = net.cuda()\nnet.eval()\n\nflo = net(im_all)\nflo = flo[0] * 20.0\nflo = flo.cpu().data.numpy()\n\n# scale the flow back to the input size \nflo = np.swapaxes(np.swapaxes(flo, 0, 1), 1, 2) # \nu_ = cv2.resize(flo[:,:,0],(W,H))\nv_ = cv2.resize(flo[:,:,1],(W,H))\nu_ *= W/ float(W_)\nv_ *= H/ float(H_)\nflo = np.dstack((u_,v_))\n\nwriteFlowFile(flow_fn, flo)\n'"
Multi_Frame_Flow/models/NetFusion.py,5,"b'#! /usr/bin/env python\n\n""""""\nCopyright (C) 2018 NVIDIA Corporation.  All rights reserved.\nLicensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).\n""""""\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport os\nos.environ[\'PYTHON_EGG_CACHE\'] = \'tmp/\' # a writable directory \nfrom correlation_package.modules.corr import Correlation \nimport numpy as np\nimport torch.nn.init as nn_init\n\n__all__ = [\n \'NetFusion\'\n]\n\n\ndef deconv(in_planes, out_planes):\n    return nn.Sequential(\n        nn.ConvTranspose2d(in_planes, out_planes, kernel_size=4, stride=2, padding=1, bias=True),\n        nn.LeakyReLU(0.1,inplace=True)\n    )\n\n\ndef predict_flow(in_planes):\n    return nn.Conv2d(in_planes,2,kernel_size=3,stride=1,padding=1,bias=True)\n\n\ndef conv(batchNorm, in_planes, out_planes, kernel_size=3, stride=1):\n    if batchNorm:\n        return nn.Sequential(\n            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, \n                      stride=stride, padding=(kernel_size-1)//2, bias=False),\n            nn.BatchNorm2d(out_planes),\n            nn.LeakyReLU(0.1,inplace=True)\n        )\n    else:\n        return nn.Sequential(\n            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, \n                      stride=stride, padding=(kernel_size-1)//2, bias=True),\n            nn.LeakyReLU(0.1,inplace=True)\n        )\n\n\ndef i_conv(batchNorm, in_planes, out_planes, kernel_size=3, stride=1, bias = True):\n    if batchNorm:\n        return nn.Sequential(\n            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, \n                      stride=stride, padding=(kernel_size-1)//2, bias=bias),\n            nn.BatchNorm2d(out_planes),\n        )\n    else:\n        return nn.Sequential(\n            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, \n                      stride=stride, padding=(kernel_size-1)//2, bias=bias),\n        )\n    \n\nclass NetFusion(nn.Module):\n    def __init__(self, batchNorm=False, inPlanes=11):\n        super(NetFusion,self).__init__()\n\n        self.batchNorm = batchNorm\n        self.conv0   = conv(self.batchNorm,  inPlanes,   64)\n        self.conv1   = conv(self.batchNorm,  64,   64, stride=2)\n        self.conv1_1 = conv(self.batchNorm,  64,   128)\n        self.conv2   = conv(self.batchNorm,  128,  128, stride=2)\n        self.conv2_1 = conv(self.batchNorm,  128,  128)\n\n        self.deconv1 = deconv(128,32)\n        self.deconv0 = deconv(162,16)\n\n        self.inter_conv1 = i_conv(self.batchNorm,  162,   32)\n        self.inter_conv0 = i_conv(self.batchNorm,  82,   16)\n\n        self.predict_flow2 = predict_flow(128)\n        self.predict_flow1 = predict_flow(32)\n        self.predict_flow0 = predict_flow(16)\n\n        self.upsampled_flow2_to_1 = nn.ConvTranspose2d(2, 2, 4, 2, 1)\n        self.upsampled_flow1_to_0 = nn.ConvTranspose2d(2, 2, 4, 2, 1)\n\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n                nn.init.kaiming_normal(m.weight.data, mode=\'fan_in\')\n                if m.bias is not None:\n                    m.bias.data.zero_()\n        \n    def forward(self, x):\n        out_conv0 = self.conv0(x)\n        out_conv1 = self.conv1_1(self.conv1(out_conv0))\n        out_conv2 = self.conv2_1(self.conv2(out_conv1))\n\n        flow2       = self.predict_flow2(out_conv2)\n        flow2_up    = self.upsampled_flow2_to_1(flow2)\n        out_deconv1 = self.deconv1(out_conv2)\n        \n        concat1 = torch.cat((out_conv1,out_deconv1,flow2_up),1)\n        out_interconv1 = self.inter_conv1(concat1)\n        flow1       = self.predict_flow1(out_interconv1)\n        flow1_up    = self.upsampled_flow1_to_0(flow1)\n        out_deconv0 = self.deconv0(concat1)\n        \n        concat0 = torch.cat((out_conv0,out_deconv0,flow1_up),1)\n        out_interconv0 = self.inter_conv0(concat0)\n        flow0       = self.predict_flow0(out_interconv0)\n\n        return flow0\n'"
Multi_Frame_Flow/models/NetFusion_custom.py,11,"b'#! /usr/bin/env python\n\n""""""\nCopyright (C) 2018 NVIDIA Corporation.  All rights reserved.\nLicensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).\n""""""\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport os\nos.environ[\'PYTHON_EGG_CACHE\'] = \'tmp/\' # a writable directory \nfrom correlation_package.modules.corr import Correlation \nimport numpy as np\nimport sys\nsys.path.append(""../"")\nsys.path.append(""./external_packages/"")\nfrom channelnorm_package.modules.channelnorm import ChannelNorm\nimport pdb\nimport models\nimport NetFusion\nimport torch.nn.init as nn_init\n\n\n__all__ = [\n \'netfusion_custom\'\n]\n\n    \nclass NetFusion_custom(nn.Module):\n    def __init__(self, div_flow = 20.0, batchNorm=False):        \n        super(NetFusion_custom,self).__init__()\n\n        self.batchNorm = batchNorm\n        self.div_flow = div_flow\n\n        self.fusion = NetFusion.NetFusion(batchNorm=self.batchNorm, inPlanes=9)\n        self.channelnorm = ChannelNorm()\n\n    def warp_back(self, x, flo):\n        """"""\n        warp an image/tensor (im2) back to im1, according to the optical flow\n\n        x: [B, C, H, W] (im2)\n        flo: [B, 2, H, W] flow\n        """"""\n        B, C, H, W = x.size()\n\n        xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n        yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n        xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n        yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n        grid = torch.cat((xx,yy),1).float()\n\n        if x.is_cuda:\n            grid = grid.cuda()\n        vgrid = Variable(grid) + flo\n\n        vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:]/max(W-1,1)-1.0\n        vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:]/max(H-1,1)-1.0\n\n        vgrid = vgrid.permute(0,2,3,1)        \n        output = nn.functional.grid_sample(x, vgrid)\n        mask = torch.autograd.Variable(torch.ones(x.size())).cuda()\n        mask = nn.functional.grid_sample(mask, vgrid)\n        \n        mask[mask<0.999] = 0\n        mask[mask>0] = 1\n        \n        return output*mask\n            \n    def forward(self,x):        \n        im1 = x[:, :3,  :, :]\n        im2 = x[:, 3:6, :, :]\n        cur_flow = x[:, 6:8, :, :]\n        prev_flow = x[:, 8:10, :, :]\n        prev_flow_back = x[:, 10:12, :, :]\n\n        prev_flow = self.warp_back(prev_flow, prev_flow_back) #warp 0->1 to frame 1\n        \n        im2_warp_backward_cur_flow = self.warp_back(im2, cur_flow)  # im2 1->2 im1\n        im2_warp_backward_prev_flow = self.warp_back(im2, prev_flow) # im2 wapred 1->2 im1\n\n\n        mask_warp_cur_flow = torch.autograd.Variable(torch.ones(x.size()[0], 1, x.size()[2], x.size()[3]).float()).cuda()\n        mask_warp_prev_flow = torch.autograd.Variable(torch.ones(x.size()[0], 1, x.size()[2], x.size()[3]).float()).cuda()\n\n        mask_warp_cur_flow = self.warp_back(mask_warp_cur_flow, cur_flow)\n        mask_warp_prev_flow = self.warp_back(mask_warp_prev_flow, prev_flow)\n\n        \n        cur_flow = cur_flow / self.div_flow\n        prev_flow = prev_flow / self.div_flow\n        \n        norm_cur_flow = self.channelnorm(cur_flow)\n        norm_prev_flow = self.channelnorm(prev_flow)\n\n        diff_im1_cur_flow = self.channelnorm(im1-im2_warp_backward_cur_flow)\n        diff_im1_prev_flow = self.channelnorm(im1-im2_warp_backward_prev_flow)\n\n        diff_im1_cur_flow_comp = 0.5 - diff_im1_cur_flow\n        diff_im1_cur_flow_comp[mask_warp_cur_flow>0] = 0\n        diff_im1_prev_flow_comp = 0.5 - diff_im1_prev_flow\n        diff_im1_prev_flow_comp[mask_warp_prev_flow>0] = 0\n\n\n        diff_im1_cur_flow = diff_im1_cur_flow + diff_im1_cur_flow_comp\n        diff_im1_prev_flow = diff_im1_prev_flow + diff_im1_prev_flow_comp\n\n\n        concat_feat = torch.cat((im1, cur_flow, prev_flow, diff_im1_cur_flow, diff_im1_prev_flow), dim=1)\n        \n        flow_new = self.fusion(concat_feat)\n        \n        return flow_new\n\n\ndef netfusion_custom(path=None, div_flow = 20.0, batchNorm=False):\n    \n    model = NetFusion_custom(div_flow = div_flow, batchNorm=batchNorm)\n\n    if path is not None:\n        data = torch.load(path)\n        if \'state_dict\' in data.keys():\n            model.load_state_dict(data[\'state_dict\'])\n        else:\n            model.load_state_dict(data)\n\n    return model\n'"
Multi_Frame_Flow/models/PWCNet.py,70,"b'#! /usr/bin/env python\n\n""""""\nCopyright (C) 2018 NVIDIA Corporation.  All rights reserved.\nLicensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).\nAuthors: Patrick Wieschollek, Orazio Gallo, Jinwei Gu, and Jan Kautz\n""""""\n\n""""""\nImplementation of the PWC-DC network for optical flow estimation by Sun et al., 2018\nThanks Jinwei Gu for the help coding this.\n""""""\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport os\nos.environ[\'PYTHON_EGG_CACHE\'] = \'tmp/\' # a writable directory \nfrom correlation_package.modules.corr import Correlation \nimport numpy as np\n\n\n__all__ = [\n    \'pwc_dc_net\', \'pwc_dc_net_old\'\n    ]\n\n\ndef conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):   \n    return nn.Sequential(\n            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, \n                        padding=padding, dilation=dilation, bias=True),\n            nn.LeakyReLU(0.1))\n\n\ndef predict_flow(in_planes):\n    return nn.Conv2d(in_planes,2,kernel_size=3,stride=1,padding=1,bias=True)\n\n\ndef deconv(in_planes, out_planes, kernel_size=4, stride=2, padding=1):\n    return nn.ConvTranspose2d(in_planes, out_planes, kernel_size, stride, padding, bias=True)\n\n\nclass PWCDCNet(nn.Module):\n    """"""\n    PWC-DC net. add dilation convolution and densenet connections\n\n    """"""\n    def __init__(self, md=4):\n        """"""\n        input: md --- maximum displacement (for correlation. default: 4), after warpping\n\n        """"""\n        super(PWCDCNet,self).__init__()\n\n        self.conv1a  = conv(3,   16, kernel_size=3, stride=2)\n        self.conv1aa = conv(16,  16, kernel_size=3, stride=1)\n        self.conv1b  = conv(16,  16, kernel_size=3, stride=1)\n        self.conv2a  = conv(16,  32, kernel_size=3, stride=2)\n        self.conv2aa = conv(32,  32, kernel_size=3, stride=1)\n        self.conv2b  = conv(32,  32, kernel_size=3, stride=1)\n        self.conv3a  = conv(32,  64, kernel_size=3, stride=2)\n        self.conv3aa = conv(64,  64, kernel_size=3, stride=1)\n        self.conv3b  = conv(64,  64, kernel_size=3, stride=1)\n        self.conv4a  = conv(64,  96, kernel_size=3, stride=2)\n        self.conv4aa = conv(96,  96, kernel_size=3, stride=1)\n        self.conv4b  = conv(96,  96, kernel_size=3, stride=1)\n        self.conv5a  = conv(96, 128, kernel_size=3, stride=2)\n        self.conv5aa = conv(128,128, kernel_size=3, stride=1)\n        self.conv5b  = conv(128,128, kernel_size=3, stride=1)\n        self.conv6aa = conv(128,196, kernel_size=3, stride=2)\n        self.conv6a  = conv(196,196, kernel_size=3, stride=1)\n        self.conv6b  = conv(196,196, kernel_size=3, stride=1)\n\n        self.corr    = Correlation(pad_size=md, kernel_size=1, max_displacement=md, stride1=1, stride2=1, corr_multiply=1)\n        self.leakyRELU = nn.LeakyReLU(0.1)\n        \n        nd = (2*md+1)**2\n        dd = np.cumsum([128,128,96,64,32])\n\n        od = nd\n        self.conv6_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv6_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv6_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv6_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv6_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)        \n        self.predict_flow6 = predict_flow(od+dd[4])\n        self.deconv6 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat6 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+128+4\n        self.conv5_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv5_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv5_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv5_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv5_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow5 = predict_flow(od+dd[4]) \n        self.deconv5 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat5 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+96+4\n        self.conv4_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv4_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv4_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv4_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv4_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow4 = predict_flow(od+dd[4]) \n        self.deconv4 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat4 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+64+4\n        self.conv3_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv3_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv3_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv3_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv3_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow3 = predict_flow(od+dd[4]) \n        self.deconv3 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat3 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+32+4\n        self.conv2_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv2_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv2_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv2_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv2_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow2 = predict_flow(od+dd[4]) \n        self.deconv2 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        \n        self.dc_conv1 = conv(od+dd[4], 128, kernel_size=3, stride=1, padding=1,  dilation=1)\n        self.dc_conv2 = conv(128,      128, kernel_size=3, stride=1, padding=2,  dilation=2)\n        self.dc_conv3 = conv(128,      128, kernel_size=3, stride=1, padding=4,  dilation=4)\n        self.dc_conv4 = conv(128,      96,  kernel_size=3, stride=1, padding=8,  dilation=8)\n        self.dc_conv5 = conv(96,       64,  kernel_size=3, stride=1, padding=16, dilation=16)\n        self.dc_conv6 = conv(64,       32,  kernel_size=3, stride=1, padding=1,  dilation=1)\n        self.dc_conv7 = predict_flow(32)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n                nn.init.kaiming_normal(m.weight.data, mode=\'fan_in\')\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def warp(self, x, flo):\n        """"""\n        warp an image/tensor (im2) back to im1, according to the optical flow\n\n        x: [B, C, H, W] (im2)\n        flo: [B, 2, H, W] flow\n\n        """"""\n        B, C, H, W = x.size()\n        # mesh grid \n        xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n        yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n        xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n        yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n        grid = torch.cat((xx,yy),1).float()\n\n        if x.is_cuda:\n            grid = grid.cuda()\n        vgrid = Variable(grid) + flo\n\n        # scale grid to [-1,1] \n        vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:]/max(W-1,1)-1.0\n        vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:]/max(H-1,1)-1.0\n\n        vgrid = vgrid.permute(0,2,3,1)        \n        output = nn.functional.grid_sample(x, vgrid)\n        mask = torch.autograd.Variable(torch.ones(x.size())).cuda()\n        mask = nn.functional.grid_sample(mask, vgrid)\n\n        # if W==128:\n            # np.save(\'mask.npy\', mask.cpu().data.numpy())\n            # np.save(\'warp.npy\', output.cpu().data.numpy())\n        \n        mask[mask<0.9999] = 0\n        mask[mask>0] = 1\n        \n        return output*mask\n\n    def forward(self,x):\n        im1 = x[:,:3,:,:]\n        im2 = x[:,3:,:,:]\n        \n        c11 = self.conv1b(self.conv1aa(self.conv1a(im1)))\n        c21 = self.conv1b(self.conv1aa(self.conv1a(im2)))\n        c12 = self.conv2b(self.conv2aa(self.conv2a(c11)))\n        c22 = self.conv2b(self.conv2aa(self.conv2a(c21)))\n        c13 = self.conv3b(self.conv3aa(self.conv3a(c12)))\n        c23 = self.conv3b(self.conv3aa(self.conv3a(c22)))\n        c14 = self.conv4b(self.conv4aa(self.conv4a(c13)))\n        c24 = self.conv4b(self.conv4aa(self.conv4a(c23)))\n        c15 = self.conv5b(self.conv5aa(self.conv5a(c14)))\n        c25 = self.conv5b(self.conv5aa(self.conv5a(c24)))\n        c16 = self.conv6b(self.conv6a(self.conv6aa(c15)))\n        c26 = self.conv6b(self.conv6a(self.conv6aa(c25)))\n\n        corr6 = self.corr(c16, c26) \n        corr6 = self.leakyRELU(corr6)   \n\n        x = torch.cat((self.conv6_0(corr6), corr6),1)\n        x = torch.cat((self.conv6_1(x), x),1)\n        x = torch.cat((self.conv6_2(x), x),1)\n        x = torch.cat((self.conv6_3(x), x),1)\n        x = torch.cat((self.conv6_4(x), x),1)\n        flow6 = self.predict_flow6(x)\n        up_flow6 = self.deconv6(flow6)\n        up_feat6 = self.upfeat6(x)\n        \n        warp5 = self.warp(c25, up_flow6*0.625)\n        corr5 = self.corr(c15, warp5) \n        corr5 = self.leakyRELU(corr5)\n        x = torch.cat((corr5, c15, up_flow6, up_feat6), 1)\n        x = torch.cat((self.conv5_0(x), x),1)\n        x = torch.cat((self.conv5_1(x), x),1)\n        x = torch.cat((self.conv5_2(x), x),1)\n        x = torch.cat((self.conv5_3(x), x),1)\n        x = torch.cat((self.conv5_4(x), x),1)\n        flow5 = self.predict_flow5(x)\n        up_flow5 = self.deconv5(flow5)\n        up_feat5 = self.upfeat5(x)\n\n        warp4 = self.warp(c24, up_flow5*1.25)\n        corr4 = self.corr(c14, warp4)  \n        corr4 = self.leakyRELU(corr4)\n        x = torch.cat((corr4, c14, up_flow5, up_feat5), 1)\n        x = torch.cat((self.conv4_0(x), x),1)\n        x = torch.cat((self.conv4_1(x), x),1)\n        x = torch.cat((self.conv4_2(x), x),1)\n        x = torch.cat((self.conv4_3(x), x),1)\n        x = torch.cat((self.conv4_4(x), x),1)\n        flow4 = self.predict_flow4(x)\n        up_flow4 = self.deconv4(flow4)\n        up_feat4 = self.upfeat4(x)\n\n        warp3 = self.warp(c23, up_flow4*2.5)\n        corr3 = self.corr(c13, warp3) \n        corr3 = self.leakyRELU(corr3)\n        \n        x = torch.cat((corr3, c13, up_flow4, up_feat4), 1)\n        x = torch.cat((self.conv3_0(x), x),1)\n        x = torch.cat((self.conv3_1(x), x),1)\n        x = torch.cat((self.conv3_2(x), x),1)\n        x = torch.cat((self.conv3_3(x), x),1)\n        x = torch.cat((self.conv3_4(x), x),1)\n        flow3 = self.predict_flow3(x)\n        up_flow3 = self.deconv3(flow3)\n        up_feat3 = self.upfeat3(x)\n\n        warp2 = self.warp(c22, up_flow3*5.0) \n        corr2 = self.corr(c12, warp2)\n        corr2 = self.leakyRELU(corr2)\n        x = torch.cat((corr2, c12, up_flow3, up_feat3), 1)\n        x = torch.cat((self.conv2_0(x), x),1)\n        x = torch.cat((self.conv2_1(x), x),1)\n        x = torch.cat((self.conv2_2(x), x),1)\n        x = torch.cat((self.conv2_3(x), x),1)\n        x = torch.cat((self.conv2_4(x), x),1)\n        flow2 = self.predict_flow2(x)\n \n        x = self.dc_conv4(self.dc_conv3(self.dc_conv2(self.dc_conv1(x))))\n        flow2 += self.dc_conv7(self.dc_conv6(self.dc_conv5(x)))\n        \n        if self.training:\n            return flow2,flow3,flow4,flow5,flow6\n        else:\n            return flow2\n\n\nclass PWCDCNet_old(nn.Module):\n    """"""\n    PWC-DC net. add dilation convolution and densenet connections\n\n    """"""\n    def __init__(self, md=4):\n        """"""\n        input: md --- maximum displacement (for correlation. default: 4), after warpping\n\n        """"""\n        super(PWCDCNet_old,self).__init__()\n\n        self.conv1a  = conv(3,   16, kernel_size=3, stride=2)\n        self.conv1b  = conv(16,  16, kernel_size=3, stride=1)\n        self.conv2a  = conv(16,  32, kernel_size=3, stride=2)\n        self.conv2b  = conv(32,  32, kernel_size=3, stride=1)\n        self.conv3a  = conv(32,  64, kernel_size=3, stride=2)\n        self.conv3b  = conv(64,  64, kernel_size=3, stride=1)\n        self.conv4a  = conv(64,  96, kernel_size=3, stride=2)\n        self.conv4b  = conv(96,  96, kernel_size=3, stride=1)\n        self.conv5a  = conv(96, 128, kernel_size=3, stride=2)\n        self.conv5b  = conv(128,128, kernel_size=3, stride=1)\n        self.conv6a  = conv(128,196, kernel_size=3, stride=2)\n        self.conv6b  = conv(196,196, kernel_size=3, stride=1)\n\n        self.corr    = Correlation(pad_size=md, kernel_size=1, max_displacement=md, stride1=1, stride2=1, corr_multiply=1)\n        self.leakyRELU = nn.LeakyReLU(0.1)\n        \n        nd = (2*md+1)**2\n        dd = np.cumsum([128,128,96,64,32])\n\n        od = nd\n        self.conv6_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv6_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv6_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv6_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv6_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)        \n        self.predict_flow6 = predict_flow(od+dd[4])\n        self.deconv6 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat6 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+128+4\n        self.conv5_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv5_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv5_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv5_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv5_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow5 = predict_flow(od+dd[4]) \n        self.deconv5 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat5 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+96+4\n        self.conv4_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv4_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv4_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv4_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv4_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow4 = predict_flow(od+dd[4]) \n        self.deconv4 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat4 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+64+4\n        self.conv3_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv3_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv3_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv3_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv3_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow3 = predict_flow(od+dd[4]) \n        self.deconv3 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat3 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+32+4\n        self.conv2_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv2_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv2_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv2_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv2_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow2 = predict_flow(od+dd[4]) \n        self.deconv2 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        \n        self.dc_conv1 = conv(od+dd[4], 128, kernel_size=3, stride=1, padding=1,  dilation=1)\n        self.dc_conv2 = conv(128,      128, kernel_size=3, stride=1, padding=2,  dilation=2)\n        self.dc_conv3 = conv(128,      128, kernel_size=3, stride=1, padding=4,  dilation=4)\n        self.dc_conv4 = conv(128,      96,  kernel_size=3, stride=1, padding=8,  dilation=8)\n        self.dc_conv5 = conv(96,       64,  kernel_size=3, stride=1, padding=16, dilation=16)\n        self.dc_conv6 = conv(64,       32,  kernel_size=3, stride=1, padding=1,  dilation=1)\n        self.dc_conv7 = predict_flow(32)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n                nn.init.kaiming_normal(m.weight.data, mode=\'fan_in\')\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def warp(self, x, flo):\n        """"""\n        warp an image/tensor (im2) back to im1, according to the optical flow\n\n        x: [B, C, H, W] (im2)\n        flo: [B, 2, H, W] flow\n\n        """"""\n        B, C, H, W = x.size()\n        # mesh grid \n        xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n        yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n        xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n        yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n        grid = torch.cat((xx,yy),1).float()\n\n        if x.is_cuda:\n            grid = grid.cuda()\n        vgrid = Variable(grid) + flo\n\n        # scale grid to [-1,1] \n        vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:]/max(W-1,1)-1.0\n        vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:]/max(H-1,1)-1.0\n\n        vgrid = vgrid.permute(0,2,3,1)        \n        output = nn.functional.grid_sample(x, vgrid)\n        mask = torch.autograd.Variable(torch.ones(x.size())).cuda()\n        mask = nn.functional.grid_sample(mask, vgrid)\n        \n        mask[mask<0.999] = 0\n        mask[mask>0] = 1\n        \n        return output*mask\n\n\n    def forward(self,x):\n        im1 = x[:,:3,:,:]\n        im2 = x[:,3:,:,:]\n        \n        c11 = self.conv1b(self.conv1a(im1))\n        c21 = self.conv1b(self.conv1a(im2))\n        c12 = self.conv2b(self.conv2a(c11))\n        c22 = self.conv2b(self.conv2a(c21))\n        c13 = self.conv3b(self.conv3a(c12))\n        c23 = self.conv3b(self.conv3a(c22))\n        c14 = self.conv4b(self.conv4a(c13))\n        c24 = self.conv4b(self.conv4a(c23))        \n        c15 = self.conv5b(self.conv5a(c14))\n        c25 = self.conv5b(self.conv5a(c24))\n        c16 = self.conv6b(self.conv6a(c15))\n        c26 = self.conv6b(self.conv6a(c25))\n        \n        corr6 = self.corr(c16, c26) \n        corr6 = self.leakyRELU(corr6)        \n        x = torch.cat((corr6, self.conv6_0(corr6)),1)\n        x = torch.cat((self.conv6_1(x), x),1)\n        x = torch.cat((x, self.conv6_2(x)),1)\n        x = torch.cat((x, self.conv6_3(x)),1)\n        x = torch.cat((x, self.conv6_4(x)),1)\n        flow6 = self.predict_flow6(x)\n        up_flow6 = self.deconv6(flow6)\n        up_feat6 = self.upfeat6(x)\n        \n        warp5 = self.warp(c25, up_flow6*0.625)\n        corr5 = self.corr(c15, warp5) \n        corr5 = self.leakyRELU(corr5)\n        x = torch.cat((corr5, c15, up_flow6, up_feat6), 1)\n        x = torch.cat((x, self.conv5_0(x)),1)\n        x = torch.cat((self.conv5_1(x), x),1)\n        x = torch.cat((x, self.conv5_2(x)),1)\n        x = torch.cat((x, self.conv5_3(x)),1)\n        x = torch.cat((x, self.conv5_4(x)),1)\n        flow5 = self.predict_flow5(x)\n        up_flow5 = self.deconv5(flow5)\n        up_feat5 = self.upfeat5(x)\n        \n        warp4 = self.warp(c24, up_flow5*1.25)\n        corr4 = self.corr(c14, warp4)  \n        corr4 = self.leakyRELU(corr4)\n        x = torch.cat((corr4, c14, up_flow5, up_feat5), 1)\n        x = torch.cat((x, self.conv4_0(x)),1)\n        x = torch.cat((self.conv4_1(x), x),1)\n        x = torch.cat((x, self.conv4_2(x)),1)\n        x = torch.cat((x, self.conv4_3(x)),1)\n        x = torch.cat((x, self.conv4_4(x)),1)\n        flow4 = self.predict_flow4(x)\n        up_flow4 = self.deconv4(flow4)\n        up_feat4 = self.upfeat4(x)\n\n        warp3 = self.warp(c23, up_flow4*2.5)\n        corr3 = self.corr(c13, warp3) \n        corr3 = self.leakyRELU(corr3)\n        x = torch.cat((corr3, c13, up_flow4, up_feat4), 1)\n        x = torch.cat((x, self.conv3_0(x)),1)\n        x = torch.cat((self.conv3_1(x), x),1)\n        x = torch.cat((x, self.conv3_2(x)),1)\n        x = torch.cat((x, self.conv3_3(x)),1)\n        x = torch.cat((x, self.conv3_4(x)),1)\n        flow3 = self.predict_flow3(x)\n        up_flow3 = self.deconv3(flow3)\n        up_feat3 = self.upfeat3(x)\n        \n        warp2 = self.warp(c22, up_flow3*5.0) \n        corr2 = self.corr(c12, warp2)\n        corr2 = self.leakyRELU(corr2)\n        x = torch.cat((corr2, c12, up_flow3, up_feat3), 1)\n        x = torch.cat((x, self.conv2_0(x)),1)\n        x = torch.cat((self.conv2_1(x), x),1)\n        x = torch.cat((x, self.conv2_2(x)),1)\n        x = torch.cat((x, self.conv2_3(x)),1)\n        x = torch.cat((x, self.conv2_4(x)),1)\n        flow2 = self.predict_flow2(x)\n \n        x = self.dc_conv4(self.dc_conv3(self.dc_conv2(self.dc_conv1(x))))\n        flow2 += self.dc_conv7(self.dc_conv6(self.dc_conv5(x)))\n        \n        if self.training:\n            return flow2,flow3,flow4,flow5,flow6\n        else:\n            return flow2\n\n\ndef pwc_dc_net(path=None):\n\n    model = PWCDCNet()\n    if path is not None:\n        data = torch.load(path)\n        if \'state_dict\' in data.keys():\n            model.load_state_dict(data[\'state_dict\'])\n        else:\n            model.load_state_dict(data)\n    return model\n\n\ndef pwc_dc_net_old(path=None):\n\n    model = PWCDCNet_old()\n    if path is not None:\n        data = torch.load(path)\n        if \'state_dict\' in data.keys():\n            model.load_state_dict(data[\'state_dict\'])\n        else:\n            model.load_state_dict(data)\n    return model\n'"
Multi_Frame_Flow/models/__init__.py,0,b'from .PWCNet import *\nfrom .NetFusion import *\nfrom .NetFusion_custom import *'
PyTorch/models/PWCNet.py,70,"b'""""""\nimplementation of the PWC-DC network for optical flow estimation by Sun et al., 2018\n\nJinwei Gu and Zhile Ren\n\n""""""\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport os\nos.environ[\'PYTHON_EGG_CACHE\'] = \'tmp/\' # a writable directory \nfrom correlation_package.modules.corr import Correlation \nimport numpy as np\n\n\n\n\n\n__all__ = [\n    \'pwc_dc_net\', \'pwc_dc_net_old\'\n    ]\n\ndef conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):   \n    return nn.Sequential(\n            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, \n                        padding=padding, dilation=dilation, bias=True),\n            nn.LeakyReLU(0.1))\n\ndef predict_flow(in_planes):\n    return nn.Conv2d(in_planes,2,kernel_size=3,stride=1,padding=1,bias=True)\n\ndef deconv(in_planes, out_planes, kernel_size=4, stride=2, padding=1):\n    return nn.ConvTranspose2d(in_planes, out_planes, kernel_size, stride, padding, bias=True)\n\n\n\nclass PWCDCNet(nn.Module):\n    """"""\n    PWC-DC net. add dilation convolution and densenet connections\n\n    """"""\n    def __init__(self, md=4):\n        """"""\n        input: md --- maximum displacement (for correlation. default: 4), after warpping\n\n        """"""\n        super(PWCDCNet,self).__init__()\n\n        self.conv1a  = conv(3,   16, kernel_size=3, stride=2)\n        self.conv1aa = conv(16,  16, kernel_size=3, stride=1)\n        self.conv1b  = conv(16,  16, kernel_size=3, stride=1)\n        self.conv2a  = conv(16,  32, kernel_size=3, stride=2)\n        self.conv2aa = conv(32,  32, kernel_size=3, stride=1)\n        self.conv2b  = conv(32,  32, kernel_size=3, stride=1)\n        self.conv3a  = conv(32,  64, kernel_size=3, stride=2)\n        self.conv3aa = conv(64,  64, kernel_size=3, stride=1)\n        self.conv3b  = conv(64,  64, kernel_size=3, stride=1)\n        self.conv4a  = conv(64,  96, kernel_size=3, stride=2)\n        self.conv4aa = conv(96,  96, kernel_size=3, stride=1)\n        self.conv4b  = conv(96,  96, kernel_size=3, stride=1)\n        self.conv5a  = conv(96, 128, kernel_size=3, stride=2)\n        self.conv5aa = conv(128,128, kernel_size=3, stride=1)\n        self.conv5b  = conv(128,128, kernel_size=3, stride=1)\n        self.conv6aa = conv(128,196, kernel_size=3, stride=2)\n        self.conv6a  = conv(196,196, kernel_size=3, stride=1)\n        self.conv6b  = conv(196,196, kernel_size=3, stride=1)\n\n        self.corr    = Correlation(pad_size=md, kernel_size=1, max_displacement=md, stride1=1, stride2=1, corr_multiply=1)\n        self.leakyRELU = nn.LeakyReLU(0.1)\n        \n        nd = (2*md+1)**2\n        dd = np.cumsum([128,128,96,64,32])\n\n        od = nd\n        self.conv6_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv6_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv6_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv6_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv6_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)        \n        self.predict_flow6 = predict_flow(od+dd[4])\n        self.deconv6 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat6 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+128+4\n        self.conv5_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv5_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv5_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv5_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv5_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow5 = predict_flow(od+dd[4]) \n        self.deconv5 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat5 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+96+4\n        self.conv4_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv4_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv4_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv4_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv4_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow4 = predict_flow(od+dd[4]) \n        self.deconv4 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat4 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+64+4\n        self.conv3_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv3_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv3_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv3_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv3_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow3 = predict_flow(od+dd[4]) \n        self.deconv3 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat3 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+32+4\n        self.conv2_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv2_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv2_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv2_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv2_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow2 = predict_flow(od+dd[4]) \n        self.deconv2 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        \n        self.dc_conv1 = conv(od+dd[4], 128, kernel_size=3, stride=1, padding=1,  dilation=1)\n        self.dc_conv2 = conv(128,      128, kernel_size=3, stride=1, padding=2,  dilation=2)\n        self.dc_conv3 = conv(128,      128, kernel_size=3, stride=1, padding=4,  dilation=4)\n        self.dc_conv4 = conv(128,      96,  kernel_size=3, stride=1, padding=8,  dilation=8)\n        self.dc_conv5 = conv(96,       64,  kernel_size=3, stride=1, padding=16, dilation=16)\n        self.dc_conv6 = conv(64,       32,  kernel_size=3, stride=1, padding=1,  dilation=1)\n        self.dc_conv7 = predict_flow(32)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n                nn.init.kaiming_normal(m.weight.data, mode=\'fan_in\')\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n\n    def warp(self, x, flo):\n        """"""\n        warp an image/tensor (im2) back to im1, according to the optical flow\n\n        x: [B, C, H, W] (im2)\n        flo: [B, 2, H, W] flow\n\n        """"""\n        B, C, H, W = x.size()\n        # mesh grid \n        xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n        yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n        xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n        yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n        grid = torch.cat((xx,yy),1).float()\n\n        if x.is_cuda:\n            grid = grid.cuda()\n        vgrid = Variable(grid) + flo\n\n        # scale grid to [-1,1] \n        vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:].clone() / max(W-1,1)-1.0\n        vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:].clone() / max(H-1,1)-1.0\n\n        vgrid = vgrid.permute(0,2,3,1)        \n        output = nn.functional.grid_sample(x, vgrid)\n        mask = torch.autograd.Variable(torch.ones(x.size())).cuda()\n        mask = nn.functional.grid_sample(mask, vgrid)\n\n        # if W==128:\n            # np.save(\'mask.npy\', mask.cpu().data.numpy())\n            # np.save(\'warp.npy\', output.cpu().data.numpy())\n        \n        mask[mask<0.9999] = 0\n        mask[mask>0] = 1\n        \n        return output*mask\n\n\n    def forward(self,x):\n        im1 = x[:,:3,:,:]\n        im2 = x[:,3:,:,:]\n        \n        c11 = self.conv1b(self.conv1aa(self.conv1a(im1)))\n        c21 = self.conv1b(self.conv1aa(self.conv1a(im2)))\n        c12 = self.conv2b(self.conv2aa(self.conv2a(c11)))\n        c22 = self.conv2b(self.conv2aa(self.conv2a(c21)))\n        c13 = self.conv3b(self.conv3aa(self.conv3a(c12)))\n        c23 = self.conv3b(self.conv3aa(self.conv3a(c22)))\n        c14 = self.conv4b(self.conv4aa(self.conv4a(c13)))\n        c24 = self.conv4b(self.conv4aa(self.conv4a(c23)))\n        c15 = self.conv5b(self.conv5aa(self.conv5a(c14)))\n        c25 = self.conv5b(self.conv5aa(self.conv5a(c24)))\n        c16 = self.conv6b(self.conv6a(self.conv6aa(c15)))\n        c26 = self.conv6b(self.conv6a(self.conv6aa(c25)))\n\n\n        corr6 = self.corr(c16, c26) \n        corr6 = self.leakyRELU(corr6)   \n\n\n        x = torch.cat((self.conv6_0(corr6), corr6),1)\n        x = torch.cat((self.conv6_1(x), x),1)\n        x = torch.cat((self.conv6_2(x), x),1)\n        x = torch.cat((self.conv6_3(x), x),1)\n        x = torch.cat((self.conv6_4(x), x),1)\n        flow6 = self.predict_flow6(x)\n        up_flow6 = self.deconv6(flow6)\n        up_feat6 = self.upfeat6(x)\n\n        \n        warp5 = self.warp(c25, up_flow6*0.625)\n        corr5 = self.corr(c15, warp5) \n        corr5 = self.leakyRELU(corr5)\n        x = torch.cat((corr5, c15, up_flow6, up_feat6), 1)\n        x = torch.cat((self.conv5_0(x), x),1)\n        x = torch.cat((self.conv5_1(x), x),1)\n        x = torch.cat((self.conv5_2(x), x),1)\n        x = torch.cat((self.conv5_3(x), x),1)\n        x = torch.cat((self.conv5_4(x), x),1)\n        flow5 = self.predict_flow5(x)\n        up_flow5 = self.deconv5(flow5)\n        up_feat5 = self.upfeat5(x)\n\n       \n        warp4 = self.warp(c24, up_flow5*1.25)\n        corr4 = self.corr(c14, warp4)  \n        corr4 = self.leakyRELU(corr4)\n        x = torch.cat((corr4, c14, up_flow5, up_feat5), 1)\n        x = torch.cat((self.conv4_0(x), x),1)\n        x = torch.cat((self.conv4_1(x), x),1)\n        x = torch.cat((self.conv4_2(x), x),1)\n        x = torch.cat((self.conv4_3(x), x),1)\n        x = torch.cat((self.conv4_4(x), x),1)\n        flow4 = self.predict_flow4(x)\n        up_flow4 = self.deconv4(flow4)\n        up_feat4 = self.upfeat4(x)\n\n\n        warp3 = self.warp(c23, up_flow4*2.5)\n        corr3 = self.corr(c13, warp3) \n        corr3 = self.leakyRELU(corr3)\n        \n\n        x = torch.cat((corr3, c13, up_flow4, up_feat4), 1)\n        x = torch.cat((self.conv3_0(x), x),1)\n        x = torch.cat((self.conv3_1(x), x),1)\n        x = torch.cat((self.conv3_2(x), x),1)\n        x = torch.cat((self.conv3_3(x), x),1)\n        x = torch.cat((self.conv3_4(x), x),1)\n        flow3 = self.predict_flow3(x)\n        up_flow3 = self.deconv3(flow3)\n        up_feat3 = self.upfeat3(x)\n\n\n        warp2 = self.warp(c22, up_flow3*5.0) \n        corr2 = self.corr(c12, warp2)\n        corr2 = self.leakyRELU(corr2)\n        x = torch.cat((corr2, c12, up_flow3, up_feat3), 1)\n        x = torch.cat((self.conv2_0(x), x),1)\n        x = torch.cat((self.conv2_1(x), x),1)\n        x = torch.cat((self.conv2_2(x), x),1)\n        x = torch.cat((self.conv2_3(x), x),1)\n        x = torch.cat((self.conv2_4(x), x),1)\n        flow2 = self.predict_flow2(x)\n \n        x = self.dc_conv4(self.dc_conv3(self.dc_conv2(self.dc_conv1(x))))\n        flow2 = flow2 + self.dc_conv7(self.dc_conv6(self.dc_conv5(x)))\n        \n        if self.training:\n            return flow2,flow3,flow4,flow5,flow6\n        else:\n            return flow2\n\n\n\nclass PWCDCNet_old(nn.Module):\n    """"""\n    PWC-DC net. add dilation convolution and densenet connections\n\n    """"""\n    def __init__(self, md=4):\n        """"""\n        input: md --- maximum displacement (for correlation. default: 4), after warpping\n\n        """"""\n        super(PWCDCNet_old,self).__init__()\n\n        self.conv1a  = conv(3,   16, kernel_size=3, stride=2)\n        self.conv1b  = conv(16,  16, kernel_size=3, stride=1)\n        self.conv2a  = conv(16,  32, kernel_size=3, stride=2)\n        self.conv2b  = conv(32,  32, kernel_size=3, stride=1)\n        self.conv3a  = conv(32,  64, kernel_size=3, stride=2)\n        self.conv3b  = conv(64,  64, kernel_size=3, stride=1)\n        self.conv4a  = conv(64,  96, kernel_size=3, stride=2)\n        self.conv4b  = conv(96,  96, kernel_size=3, stride=1)\n        self.conv5a  = conv(96, 128, kernel_size=3, stride=2)\n        self.conv5b  = conv(128,128, kernel_size=3, stride=1)\n        self.conv6a  = conv(128,196, kernel_size=3, stride=2)\n        self.conv6b  = conv(196,196, kernel_size=3, stride=1)\n\n        self.corr    = Correlation(pad_size=md, kernel_size=1, max_displacement=md, stride1=1, stride2=1, corr_multiply=1)\n        self.leakyRELU = nn.LeakyReLU(0.1)\n        \n        nd = (2*md+1)**2\n        dd = np.cumsum([128,128,96,64,32])\n\n        od = nd\n        self.conv6_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv6_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv6_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv6_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv6_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)        \n        self.predict_flow6 = predict_flow(od+dd[4])\n        self.deconv6 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat6 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+128+4\n        self.conv5_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv5_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv5_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv5_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv5_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow5 = predict_flow(od+dd[4]) \n        self.deconv5 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat5 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+96+4\n        self.conv4_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv4_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv4_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv4_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv4_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow4 = predict_flow(od+dd[4]) \n        self.deconv4 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat4 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+64+4\n        self.conv3_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv3_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv3_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv3_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv3_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow3 = predict_flow(od+dd[4]) \n        self.deconv3 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        self.upfeat3 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n        \n        od = nd+32+4\n        self.conv2_0 = conv(od,      128, kernel_size=3, stride=1)\n        self.conv2_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n        self.conv2_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n        self.conv2_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n        self.conv2_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n        self.predict_flow2 = predict_flow(od+dd[4]) \n        self.deconv2 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n        \n        self.dc_conv1 = conv(od+dd[4], 128, kernel_size=3, stride=1, padding=1,  dilation=1)\n        self.dc_conv2 = conv(128,      128, kernel_size=3, stride=1, padding=2,  dilation=2)\n        self.dc_conv3 = conv(128,      128, kernel_size=3, stride=1, padding=4,  dilation=4)\n        self.dc_conv4 = conv(128,      96,  kernel_size=3, stride=1, padding=8,  dilation=8)\n        self.dc_conv5 = conv(96,       64,  kernel_size=3, stride=1, padding=16, dilation=16)\n        self.dc_conv6 = conv(64,       32,  kernel_size=3, stride=1, padding=1,  dilation=1)\n        self.dc_conv7 = predict_flow(32)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n                nn.init.kaiming_normal(m.weight.data, mode=\'fan_in\')\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n\n    def warp(self, x, flo):\n        """"""\n        warp an image/tensor (im2) back to im1, according to the optical flow\n\n        x: [B, C, H, W] (im2)\n        flo: [B, 2, H, W] flow\n\n        """"""\n        B, C, H, W = x.size()\n        # mesh grid \n        xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n        yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n        xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n        yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n        grid = torch.cat((xx,yy),1).float()\n\n        if x.is_cuda:\n            grid = grid.cuda()\n        vgrid = Variable(grid) + flo\n\n        # scale grid to [-1,1] \n        vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:].clone() / max(W-1,1)-1.0\n        vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:].clone() / max(H-1,1)-1.0\n\n        vgrid = vgrid.permute(0,2,3,1)        \n        output = nn.functional.grid_sample(x, vgrid)\n        mask = torch.autograd.Variable(torch.ones(x.size())).cuda()\n        mask = nn.functional.grid_sample(mask, vgrid)\n        \n        mask[mask<0.999] = 0\n        mask[mask>0] = 1\n        \n        return output*mask\n\n\n    def forward(self,x):\n        im1 = x[:,:3,:,:]\n        im2 = x[:,3:,:,:]\n        \n        c11 = self.conv1b(self.conv1a(im1))\n        c21 = self.conv1b(self.conv1a(im2))\n        c12 = self.conv2b(self.conv2a(c11))\n        c22 = self.conv2b(self.conv2a(c21))\n        c13 = self.conv3b(self.conv3a(c12))\n        c23 = self.conv3b(self.conv3a(c22))\n        c14 = self.conv4b(self.conv4a(c13))\n        c24 = self.conv4b(self.conv4a(c23))        \n        c15 = self.conv5b(self.conv5a(c14))\n        c25 = self.conv5b(self.conv5a(c24))\n        c16 = self.conv6b(self.conv6a(c15))\n        c26 = self.conv6b(self.conv6a(c25))\n        \n        corr6 = self.corr(c16, c26) \n        corr6 = self.leakyRELU(corr6)        \n        x = torch.cat((corr6, self.conv6_0(corr6)),1)\n        x = torch.cat((self.conv6_1(x), x),1)\n        x = torch.cat((x, self.conv6_2(x)),1)\n        x = torch.cat((x, self.conv6_3(x)),1)\n        x = torch.cat((x, self.conv6_4(x)),1)\n        flow6 = self.predict_flow6(x)\n        up_flow6 = self.deconv6(flow6)\n        up_feat6 = self.upfeat6(x)\n        \n        warp5 = self.warp(c25, up_flow6*0.625)\n        corr5 = self.corr(c15, warp5) \n        corr5 = self.leakyRELU(corr5)\n        x = torch.cat((corr5, c15, up_flow6, up_feat6), 1)\n        x = torch.cat((x, self.conv5_0(x)),1)\n        x = torch.cat((self.conv5_1(x), x),1)\n        x = torch.cat((x, self.conv5_2(x)),1)\n        x = torch.cat((x, self.conv5_3(x)),1)\n        x = torch.cat((x, self.conv5_4(x)),1)\n        flow5 = self.predict_flow5(x)\n        up_flow5 = self.deconv5(flow5)\n        up_feat5 = self.upfeat5(x)\n        \n        warp4 = self.warp(c24, up_flow5*1.25)\n        corr4 = self.corr(c14, warp4)  \n        corr4 = self.leakyRELU(corr4)\n        x = torch.cat((corr4, c14, up_flow5, up_feat5), 1)\n        x = torch.cat((x, self.conv4_0(x)),1)\n        x = torch.cat((self.conv4_1(x), x),1)\n        x = torch.cat((x, self.conv4_2(x)),1)\n        x = torch.cat((x, self.conv4_3(x)),1)\n        x = torch.cat((x, self.conv4_4(x)),1)\n        flow4 = self.predict_flow4(x)\n        up_flow4 = self.deconv4(flow4)\n        up_feat4 = self.upfeat4(x)\n\n        warp3 = self.warp(c23, up_flow4*2.5)\n        corr3 = self.corr(c13, warp3) \n        corr3 = self.leakyRELU(corr3)\n        x = torch.cat((corr3, c13, up_flow4, up_feat4), 1)\n        x = torch.cat((x, self.conv3_0(x)),1)\n        x = torch.cat((self.conv3_1(x), x),1)\n        x = torch.cat((x, self.conv3_2(x)),1)\n        x = torch.cat((x, self.conv3_3(x)),1)\n        x = torch.cat((x, self.conv3_4(x)),1)\n        flow3 = self.predict_flow3(x)\n        up_flow3 = self.deconv3(flow3)\n        up_feat3 = self.upfeat3(x)\n        \n        warp2 = self.warp(c22, up_flow3*5.0) \n        corr2 = self.corr(c12, warp2)\n        corr2 = self.leakyRELU(corr2)\n        x = torch.cat((corr2, c12, up_flow3, up_feat3), 1)\n        x = torch.cat((x, self.conv2_0(x)),1)\n        x = torch.cat((self.conv2_1(x), x),1)\n        x = torch.cat((x, self.conv2_2(x)),1)\n        x = torch.cat((x, self.conv2_3(x)),1)\n        x = torch.cat((x, self.conv2_4(x)),1)\n        flow2 = self.predict_flow2(x)\n \n        x = self.dc_conv4(self.dc_conv3(self.dc_conv2(self.dc_conv1(x))))\n        flow2 = flow2 + self.dc_conv7(self.dc_conv6(self.dc_conv5(x)))\n        \n        if self.training:\n            return flow2,flow3,flow4,flow5,flow6\n        else:\n            return flow2\n\n\n\n\n\ndef pwc_dc_net(path=None):\n\n    model = PWCDCNet()\n    if path is not None:\n        data = torch.load(path)\n        if \'state_dict\' in data.keys():\n            model.load_state_dict(data[\'state_dict\'])\n        else:\n            model.load_state_dict(data)\n    return model\n\n\n\n\ndef pwc_dc_net_old(path=None):\n\n    model = PWCDCNet_old()\n    if path is not None:\n        data = torch.load(path)\n        if \'state_dict\' in data.keys():\n            model.load_state_dict(data[\'state_dict\'])\n        else:\n            model.load_state_dict(data)\n    return model\n'"
PyTorch/models/__init__.py,0,b'from .PWCNet import *\n'
Caffe/model/PyCaffe/make_model.py,0,"b'#!/usr/bin/env python\n\nfrom __future__ import print_function\nimport caffe\nfrom caffe import layers as L, params as P, to_proto\nfrom caffe.proto import caffe_pb2\nimport subprocess\nfrom pwc_net_utils import *\n\n\ndef make_net():\n    # to modify to your local directory\n    lmdb_file  = \'../data/dispflownet-release/data/FlyingChairs_release_lmdb\'\n    split_list = \'../data/dispflownet-release/data/FlyingChairs_release_test_train_split.list\'        \n   \n    net_filename = \'./train.prototxt\';\n    with open(net_filename, \'w\') as f:\n        print(make_net_train(lmdb_file, split_list, 8), file=f)\n\n    net_filename = \'./test.txt\';\n    with open(net_filename, \'w\') as f:\n        print(make_net_test(), file=f)\n    # delete first 18 lines (unused image reading layer)        \n    lines = open(net_filename).readlines()\n    open(net_filename, \'w\').writelines(lines[18:-1]);\n\n    subprocess.call([""cat ./test_start.prototxt ./test.txt ./test_end.prototxt >./test.prototxt""], shell=True)\n\nif __name__ == \'__main__\':\n    make_net()'"
Caffe/model/PyCaffe/pwc_net_utils.py,0,"b'#!/usr/bin/env python\n\nfrom __future__ import print_function\nimport caffe\nfrom caffe import layers as L, params as P, to_proto\nfrom caffe.proto import caffe_pb2\nimport subprocess\n\n# helper function for common structures\ndef augment_first_image(bottom):    \n    img0_aug, img0_aug_params = L.DataAugmentation(bottom, propagate_down=False, ntop=2, \n            augmentation_param=dict(max_multiplier=1, augment_during_test=False, recompute_mean=1000, mean_per_pixel=False, \n            translate   = dict(rand_type=""uniform_bernoulli"", exp=False, mean= 0, spread= 0.4, prob= 1.0), \n            rotate      = dict(rand_type=""uniform_bernoulli"", exp=False, mean=0, spread=0.4, prob=1.0), \n            zoom        = dict(rand_type=""uniform_bernoulli"", exp=True, mean=0.2, spread=0.4, prob=1.0),\n            squeeze     = dict(rand_type=""uniform_bernoulli"", exp=True, mean=0, spread=0.3, prob=1.0 ),\n            lmult_pow   = dict(rand_type=""uniform_bernoulli"", exp=True, mean=-0.2, spread=0.4, prob=1.0 ), \n            lmult_mult  = dict(rand_type=""uniform_bernoulli"", exp=True, mean=0.0, spread=0.4, prob=1.0 ), \n            lmult_add   = dict(rand_type=""uniform_bernoulli"", exp=False, mean=0, spread=0.03, prob=1.0 ),\n            sat_pow     = dict(rand_type=""uniform_bernoulli"", exp=True, mean=0, spread=0.4, prob=1.0), \n            sat_mult    = dict(rand_type=""uniform_bernoulli"", exp=True, mean=-0.3, spread=0.5, prob=1.0), \n            sat_add     = dict(rand_type=""uniform_bernoulli"", exp=False, mean=0, spread=0.03, prob=1.0), \n            col_pow     = dict(rand_type=""gaussian_bernoulli"", exp=True, mean=0, spread=0.4, prob=1.0), \n            col_mult    = dict(rand_type=""gaussian_bernoulli"", exp=True, mean=0, spread=0.2, prob=1.0), \n            col_add     = dict(rand_type=""gaussian_bernoulli"", exp=False, mean=0, spread=0.02, prob=1.0), \n            ladd_pow    = dict(rand_type=""gaussian_bernoulli"", exp=True, mean=0, spread=0.4, prob=1.0), \n            ladd_mult   = dict(rand_type=""gaussian_bernoulli"", exp=True, mean=0.0, spread=0.4, prob=1.0), \n            ladd_add    = dict(rand_type=""gaussian_bernoulli"", exp=False, mean=0, spread=0.04, prob=1.0), \n            col_rotate  = dict(rand_type=""uniform_bernoulli"", exp=False, mean=0, spread=1, prob=1.0),\n            crop_width=448, crop_height=320, chromatic_eigvec= [0.51, 0.56, 0.65, 0.79, 0.01, -0.62, 0.35, -0.83, 0.44], \n            noise       =dict(rand_type=""uniform_bernoulli"", exp=False, mean=0.03, spread=0.03, prob=1.0 )\n        )   \n    )\n    return img0_aug, img0_aug_params\n\ndef generate_aug_params(img0_aug_params, img0_subtract, img0_aug):\n    return L.GenerateAugmentationParameters(img0_aug_params, img0_subtract, img0_aug,\n            augmentation_param=dict(augment_during_test=False,\n            translate   =dict(rand_type=""gaussian_bernoulli"", exp= False, mean= 0, spread= 0.03, prob= 1.0), \n            rotate      =dict(rand_type=""gaussian_bernoulli"", exp=False, mean=0, spread=0.03, prob=1.0), \n            zoom        =dict(rand_type=""gaussian_bernoulli"", exp=True, mean=0, spread=0.03, prob=1.0),\n            gamma       =dict(rand_type=""gaussian_bernoulli"", exp=True, mean=0, spread=0.02, prob=1.0), \n            brightness  =dict(rand_type=""gaussian_bernoulli"", exp=False, mean=0, spread=0.02, prob=1.0), \n            contrast    =dict(rand_type=""gaussian_bernoulli"", exp=True, mean=0, spread=0.02, prob=1.0), \n            color       =dict(rand_type=""gaussian_bernoulli"", exp=True, mean=0, spread=0.02, prob=1.0)),\n            coeff_schedule_param = dict(half_life=50000, initial_coeff=0.5, final_coeff=1)  )\n\ndef augment_second_image(img1_subtract, aug_params):\n    return L.DataAugmentation(img1_subtract, aug_params, propagate_down=[False, False], \n        augmentation_param=dict(max_multiplier=1, augment_during_test=False, recompute_mean=1000, mean_per_pixel=False,  \n        crop_width=448, crop_height=320, chromatic_eigvec= [0.51, 0.56, 0.65, 0.79, 0.01, -0.62, 0.35, -0.83, 0.44]) )\n\ndef conv_relu(bottom, num_output, kernel_size=3, pad=1, stride=1):\n    layer   = L.Convolution(bottom, param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=1, decay_mult=0)],\n        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, \n            weight_filler=dict(type=\'msra\'), bias_filler=dict(type=\'constant\'), engine=2 ) ) \n    return L.ReLU(layer, relu_param=dict(negative_slope=0.1), in_place=True)    \n\ndef conv(bottom, num_output, kernel_size=3, pad=1, stride=1):\n    return L.Convolution(bottom, param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=1, decay_mult=0)],\n        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, \n            weight_filler=dict(type=\'msra\'), bias_filler=dict(type=\'constant\'), engine=2 ) ) \n\ndef deconv_relu(bottom, num_output, kernel_size=3, pad=1, stride=1):\n    layer   = L.Deconvolution(bottom, param=[dict(lr_mult=1, decay_mult=0), dict(lr_mult=0, decay_mult=0)],\n        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, \n            weight_filler=dict(type=\'msra\'), bias_filler=dict(type=\'constant\'), engine=2 ) ) \n    return L.ReLU(layer, relu_param=dict(negative_slope=0.1))    \n\ndef deconv(bottom, num_output, kernel_size=3, pad=1, stride=1):\n    return L.Deconvolution(bottom, param=[dict(lr_mult=1, decay_mult=0), dict(lr_mult=0, decay_mult=0)],\n        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, \n            weight_filler=dict(type=\'msra\'), bias_filler=dict(type=\'constant\'), engine=2 ) ) \n\ndef net_conv_relu(net, conv_name, relu_name, bottom, num_output, kernel_size=3, pad=1, stride=1):\n    setattr(net, conv_name, L.Convolution(bottom, param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=1, decay_mult=0)],\n        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, \n            weight_filler=dict(type=\'msra\'), bias_filler=dict(type=\'constant\'), engine=2 ) )  )\n    setattr(net, relu_name, L.ReLU(getattr(net, conv_name), relu_param=dict(negative_slope=0.1), in_place=True) )\n    # setattr(net, relu_name, L.ReLU(getattr(net, conv_name), relu_param=dict(negative_slope=0.1)) )\n    return net, getattr(net, relu_name)\n\ndef net_deconv_relu(net, deconv_name, relu_name, bottom, num_output, kernel_size=3, pad=1, stride=1):\n    setattr(net, deconv_name, L.Deconvolution(bottom, param=[dict(lr_mult=1, decay_mult=0), dict(lr_mult=0, decay_mult=0)],\n        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, \n            weight_filler=dict(type=\'msra\'), bias_filler=dict(type=\'constant\'), engine=2 ) )  )\n    setattr(net, relu_name, L.ReLU(getattr(net, deconv_name), relu_param=dict(negative_slope=0.1), in_place=True) )\n    return net, getattr(net, relu_name)\n\ndef net_conv_relu2(net, input1, input2, num_output, kernel_size=3, pad=1, stride=1, level=1, aux=None):\n    output1, output2 =  L.Convolution(input1, input2, param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=1, decay_mult=0)],\n                        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, \n                        weight_filler=dict(type=\'msra\'), bias_filler=dict(type=\'constant\'), engine=2 ), ntop=2 )\n    conv_name0 = \'conv0_{}\'.format(level)+aux\n    conv_name1 = \'conv1_{}\'.format(level)+aux\n    relu_name0 = \'Relu0_{}\'.format(level)+aux\n    relu_name1 = \'Relu1_{}\'.format(level)+aux\n    setattr(net, conv_name0, output1)\n    setattr(net, conv_name1, output2)\n\n    setattr(net, relu_name0, L.ReLU(getattr(net, conv_name0), relu_param=dict(negative_slope=0.1), in_place=True) )\n    setattr(net, relu_name1, L.ReLU(getattr(net, conv_name1), relu_param=dict(negative_slope=0.1), in_place=True) )\n    return net\n\ndef bilinear_interpolation_fixed(net, input, level, num_output=1, pad=1, kernel_size=4, stride=2):\n\n    slice_namex = \'slice_x_{}\'.format(level)\n    slice_namey = \'slice_y_{}\'.format(level)\n    slice_conv_namex = \'slice_conv_x_{}\'.format(level)\n    slice_conv_namey = \'slice_conv_y{}\'.format(level)\n\n    input_x, input_y = L.Slice(input, slice_param=dict(axis=1, slice_point=1),  ntop=2)\n    setattr(net, slice_namex, input_x)\n    setattr(net, slice_namey, input_y)    \n\n    output_x, output_y = L.Deconvolution(input_x, input_y, param=dict(lr_mult=0, decay_mult=0),\n        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, \n            weight_filler=dict(type=\'bilinear\'), bias_term=False, engine=2 ),  ntop=2)  \n    setattr(net, slice_conv_namex, output_x)\n    setattr(net, slice_conv_namey, output_y)\n    output = L.Concat(output_x, output_y, concat_param=dict(axis=1))\n    return net, output\n\ndef bilinear_additive_upsampling(net, input, level, num_output=1, pad=1, kernel_size=4, stride=2):\n\n    # bilinear upsamling\n    net, output_b = bilinear_interpolation_fixed(net, input, level, num_output, pad, kernel_size, stride)\n    # deconvolutional upsampling\n    output_d = deconv(input, 2, 4, 1, 2)\n    # residual connection\n    output = L.Eltwise(output_b, output_d, eltwise_param=dict(operation=1))   \n    return net, output  \n\n#  dilated convolution\ndef net_dconv_relu(net, conv_name, relu_name, bottom, num_output, kernel_size=3, pad=1, stride=1, dilation=1):\n    setattr(net, conv_name, L.Convolution(bottom, param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=1, decay_mult=0)],\n        convolution_param=dict(num_output=num_output, pad=pad, kernel_size=kernel_size, stride=stride, dilation=dilation,\n            weight_filler=dict(type=\'msra\'), bias_filler=dict(type=\'constant\')) )  )\n    setattr(net, relu_name, L.ReLU(getattr(net, conv_name), relu_param=dict(negative_slope=0.1), in_place=True) )\n    return net, getattr(net, relu_name)\n\n\ndef make_pwc_net_encoder_plus(net, image0, image1):\n\n    # make core net that takes two input image and output predict_flow2\n    net = net_conv_relu2(net, image0, image1, 16, 3, 1, 2, level=1, aux = \'_a\')\n    net = net_conv_relu2(net, net.conv0_1_a, net.conv1_1_a, 16, 3, 1, 1, level=1, aux = \'_aa\')\n    net = net_conv_relu2(net, net.conv0_1_aa, net.conv1_1_aa, 16, 3, 1, 1, level=1, aux = \'_b\')\n\n    net = net_conv_relu2(net, net.conv0_1_b, net.conv1_1_b, 32, 3, 1, 2, level=2, aux = \'_a\')\n    net = net_conv_relu2(net, net.conv0_2_a, net.conv1_2_a, 32, 3, 1, 1, level=2, aux = \'_aa\')\n    net = net_conv_relu2(net, net.conv0_2_aa, net.conv1_2_aa, 32, 3, 1, 1, level=2, aux = \'_b\')\n\n    net = net_conv_relu2(net, net.conv0_2_b, net.conv1_2_b, 64, 3, 1, 2, level=3, aux = \'_a\')\n    net = net_conv_relu2(net, net.conv0_3_a, net.conv1_3_a, 64, 3, 1, 1, level=3, aux = \'_aa\')\n    net = net_conv_relu2(net, net.conv0_3_aa, net.conv1_3_aa, 64, 3, 1, 1, level=3, aux = \'_b\')\n\n    net = net_conv_relu2(net, net.conv0_3_b, net.conv1_3_b, 96, 3, 1, 2, level=4, aux = \'_a\') \n    net = net_conv_relu2(net, net.conv0_4_a, net.conv1_4_a, 96, 3, 1, 1, level=4, aux = \'_aa\')\n    net = net_conv_relu2(net, net.conv0_4_aa, net.conv1_4_aa, 96, 3, 1, 1, level=4, aux = \'_b\')\n\n    net = net_conv_relu2(net, net.conv0_4_b, net.conv1_4_b, 128, 3, 1, 2, level=5, aux = \'_a\')\n    net = net_conv_relu2(net, net.conv0_5_a, net.conv1_5_a, 128, 3, 1, 1, level=5, aux = \'_aa\')    \n    net = net_conv_relu2(net, net.conv0_5_aa, net.conv1_5_aa, 128, 3, 1, 1, level=5, aux = \'_b\')    \n\n    net = net_conv_relu2(net, net.conv0_5_b, net.conv1_5_b, 196, 3, 1, 2, level=6, aux = \'_a\')\n    net = net_conv_relu2(net, net.conv0_6_a, net.conv1_6_a, 196, 3, 1, 1, level=6, aux = \'_a\')\n    net = net_conv_relu2(net, net.conv0_6_a, net.conv1_6_a, 196, 3, 1, 1, level=6, aux = \'_b\')\n\n    net.corr6 = L.Correlation(net.conv0_6_b, net.conv1_6_b, correlation_param=dict(pad=4, kernel_size=1, max_displacement=4, stride_1=1, stride_2=1))\n    net.corr6 = L.ReLU(net.corr6, relu_param=dict(negative_slope=0.1), in_place=True)\n\n    # densenet level 6\n\n    # net = densenet(net, level=6)\n    net, layer = net_conv_relu(net, \'conv6_0\', \'relu6_0\', net.corr6, 128, 3, 1, 1) # 128 64 32 16 8 flow?\n    net.denseconcat6_0 = layer = L.Concat(net.conv6_0, net.corr6, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv6_1\', \'relu6_1\', layer, 128, 3, 1, 1)  \n    net.denseconcat6_1 = layer = L.Concat(net.conv6_1, net.denseconcat6_0, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv6_2\', \'relu6_2\', layer, 96, 3, 1, 1)\n    net.denseconcat6_2 = layer = L.Concat(net.conv6_2, net.denseconcat6_1, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv6_3\', \'relu6_3\', layer, 64, 3, 1, 1)\n    net.denseconcat6_3 = layer = L.Concat(net.conv6_3, net.denseconcat6_2, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv6_4\', \'relu6_4\', layer, 32, 3, 1, 1)\n    net.denseconcat6_4 = layer = L.Concat(net.conv6_4, net.denseconcat6_3, concat_param=dict(axis=1))\n    # net.denseconcat6_4 = layer = L.Concat(net.conv6_4, net.conv6_3, net.conv6_2, net.conv6_1, net.conv6_0, concat_param=dict(axis=1))\n    net.predict_flow6 = conv(layer, 2, 3, 1, 1)    \n\n    net.upsample_flow_6to5 = deconv(net.predict_flow6, 2, 4, 1, 2)\n    # net, net.upsample_flow_6to5 = bilinear_additive_upsampling(net, net.predict_flow6, 4) \n\n    net.upsample_feature_6to5 = deconv(net.denseconcat6_4, 2, 4, 1, 2) # upsample 2 features\n\n    net.scale_flow_6to5 = L.Eltwise(net.upsample_flow_6to5, eltwise_param=dict(operation=1, coeff=0.625))\n\n    net.warped_image5 = L.Warp(net.conv1_5_b, net.scale_flow_6to5)\n    net.corr5 = L.Correlation(net.conv0_5_b, net.warped_image5, correlation_param=dict(pad=4, kernel_size=1, max_displacement=4, stride_1=1, stride_2=1))\n    net.corr5 = L.ReLU(net.corr5, relu_param=dict(negative_slope=0.1), in_place=True)\n    net.concat5 = L.Concat(net.corr5, net.conv0_5_b, net.upsample_flow_6to5,  net.upsample_feature_6to5, concat_param=dict(axis=1))\n\n    net, layer = net_conv_relu(net, \'conv5_0\', \'relu5_0\', net.concat5, 128, 3, 1, 1) \n    net.denseconcat5_0 = layer = L.Concat(layer, net.concat5, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv5_1\', \'relu5_1\', layer, 128, 3, 1, 1)  \n    net.denseconcat5_1 = layer = L.Concat(layer, net.denseconcat5_0, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv5_2\', \'relu5_2\', layer, 96, 3, 1, 1)\n    net.denseconcat5_2 = layer = L.Concat(layer, net.denseconcat5_1, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv5_3\', \'relu5_3\', layer, 64, 3, 1, 1)\n    net.denseconcat5_3 = layer = L.Concat(layer, net.denseconcat5_2, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv5_4\', \'relu5_4\', layer, 32, 3, 1, 1)\n    net.denseconcat5_4 = layer = L.Concat(layer, net.denseconcat5_3, concat_param=dict(axis=1))\n\n    # net.denseconcat5_4 = layer = L.Concat(net.conv5_4, net.conv5_3, net.conv5_2, net.conv5_1, net.conv5_0, concat_param=dict(axis=1))\n    net.predict_flow5 = conv(layer, 2, 3, 1, 1)    \n\n\n    net.upsample_flow_5to4 = deconv(net.predict_flow5, 2, 4, 1, 2)\n    # net, net.upsample_flow_5to4 = bilinear_additive_upsampling(net, net.predict_flow5, 4) \n    net.upsample_feature_5to4 = deconv(net.denseconcat5_4, 2, 4, 1, 2) # upsample 2 features\n\n    net.scale_flow_5to4 = L.Eltwise(net.upsample_flow_5to4, eltwise_param=dict(operation=1, coeff=1.25))\n    net.warped_image4 = L.Warp(net.conv1_4_b, net.scale_flow_5to4)\n    net.corr4 = L.Correlation(net.conv0_4_b, net.warped_image4, correlation_param=dict(pad=4, kernel_size=1, max_displacement=4, stride_1=1, stride_2=1))\n    net.corr4 = L.ReLU(net.corr4, relu_param=dict(negative_slope=0.1), in_place=True)\n    net.concat4 = L.Concat(net.corr4, net.conv0_4_b, net.upsample_flow_5to4,  net.upsample_feature_5to4, concat_param=dict(axis=1))\n\n    net, layer = net_conv_relu(net, \'conv4_0\', \'relu4_0\', net.concat4, 128, 3, 1, 1) # 128 64 32 16 8 flow?\n    net.denseconcat4_0 = layer = L.Concat(layer, net.concat4, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv4_1\', \'relu4_1\', layer, 128, 3, 1, 1)  \n    net.denseconcat4_1 = layer = L.Concat(layer, net.denseconcat4_0, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv4_2\', \'relu4_2\', layer, 96, 3, 1, 1)\n    net.denseconcat4_2 = layer = L.Concat(layer, net.denseconcat4_1, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv4_3\', \'relu4_3\', layer, 64, 3, 1, 1)\n    net.denseconcat4_3 = layer = L.Concat(layer, net.denseconcat4_2, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv4_4\', \'relu4_4\', layer, 32, 3, 1, 1)\n    net.denseconcat4_4 = layer = L.Concat(layer, net.denseconcat4_3, concat_param=dict(axis=1))\n    # net.denseconcat4_4 = layer = L.Concat(net.conv4_4, net.conv4_3, net.conv4_2, net.conv4_1, net.conv4_0, concat_param=dict(axis=1))\n    net.predict_flow4 = conv(layer, 2, 3, 1, 1)    \n\n\n    net.upsample_flow_4to3 = deconv(net.predict_flow4, 2, 4, 1, 2)\n    # net, net.upsample_flow_4to3 = bilinear_additive_upsampling(net, net.predict_flow4, 4) \n\n    net.upsample_feature_4to3 = deconv(net.denseconcat4_4, 2, 4, 1, 2) # upsample 2 features\n\n    net.scale_flow_4to3 = L.Eltwise(net.upsample_flow_4to3, eltwise_param=dict(operation=1, coeff=2.5))\n\n    net.warped_image3 = L.Warp(net.conv1_3_b, net.scale_flow_4to3)\n    net.corr3 = L.Correlation(net.conv0_3_b, net.warped_image3, correlation_param=dict(pad=4, kernel_size=1, max_displacement=4, stride_1=1, stride_2=1))\n    net.corr3 = L.ReLU(net.corr3, relu_param=dict(negative_slope=0.1), in_place=True)\n    net.concat3 = L.Concat(net.corr3, net.conv0_3_b, net.upsample_flow_4to3,  net.upsample_feature_4to3, concat_param=dict(axis=1))\n\n    net, layer = net_conv_relu(net, \'conv3_0\', \'relu3_0\', net.concat3, 128, 3, 1, 1) # 128 64 32 16 8 flow?\n    net.denseconcat3_0 = layer = L.Concat(layer, net.concat3, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv3_1\', \'relu3_1\', layer, 128, 3, 1, 1)  \n    net.denseconcat3_1 = layer = L.Concat(layer, net.denseconcat3_0, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv3_2\', \'relu3_2\', layer, 96, 3, 1, 1)\n    net.denseconcat3_2 = layer = L.Concat(layer, net.denseconcat3_1, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv3_3\', \'relu3_3\', layer, 64, 3, 1, 1)\n    net.denseconcat3_3 = layer = L.Concat(layer, net.denseconcat3_2, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv3_4\', \'relu3_4\', layer, 32, 3, 1, 1)\n    net.denseconcat3_4 = layer = L.Concat(layer, net.denseconcat3_3, concat_param=dict(axis=1))\n    # net.denseconcat3_4 = layer = L.Concat(net.conv3_4, net.conv3_3, net.conv3_2, net.conv3_1, net.conv3_0, concat_param=dict(axis=1))\n    net.predict_flow3 = conv(layer, 2, 3, 1, 1)    \n\n\n\n    net.upsample_flow_3to2 = deconv(net.predict_flow3, 2, 4, 1, 2)\n    # net, net.upsample_flow_3to2 = bilinear_additive_upsampling(net, net.predict_flow3, 4) \n    net.upsample_feature_3to2 = deconv(net.denseconcat3_4, 2, 4, 1, 2) # upsample 2 features\n\n    net.scale_flow_3to2 = L.Eltwise(net.upsample_flow_3to2, eltwise_param=dict(operation=1, coeff=5.))\n    net.warped_image2 = L.Warp(net.conv1_2_b, net.scale_flow_3to2)\n    net.corr2 = L.Correlation(net.conv0_2_b, net.warped_image2, correlation_param=dict(pad=4, kernel_size=1, max_displacement=4, stride_1=1, stride_2=1))\n    net.corr2 = L.ReLU(net.corr2, relu_param=dict(negative_slope=0.1), in_place=True)\n    net.concat2 = L.Concat(net.corr2, net.conv0_2_b, net.upsample_flow_3to2,  net.upsample_feature_3to2, concat_param=dict(axis=1))\n\n    net, layer = net_conv_relu(net, \'conv2_0\', \'relu2_0\', net.concat2, 128, 3, 1, 1) # 128 64 32 16 8 flow?\n    net.denseconcat2_0 = layer = L.Concat(layer, net.concat2, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv2_1\', \'relu2_1\', layer, 128, 3, 1, 1)  \n    net.denseconcat2_1 = layer = L.Concat(layer, net.denseconcat2_0, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv2_2\', \'relu2_2\', layer, 96, 3, 1, 1)\n    net.denseconcat2_2 = layer = L.Concat(layer, net.denseconcat2_1, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv2_3\', \'relu2_3\', layer, 64, 3, 1, 1)\n    net.denseconcat2_3 = layer = L.Concat(layer, net.denseconcat2_2, concat_param=dict(axis=1))\n    net, layer = net_conv_relu(net, \'conv2_4\', \'relu2_4\', layer, 32, 3, 1, 1)\n    net.denseconcat2_4 = layer = L.Concat(layer, net.denseconcat2_3, concat_param=dict(axis=1))\n    # net.denseconcat2_4 = layer = L.Concat(net.conv2_4, net.conv2_3, net.conv2_2, net.conv2_1, net.conv2_0, concat_param=dict(axis=1))\n    \n    net.predict_flow_ini = conv(layer, 2, 3, 1, 1)    \n    # add dilated convolution as backend\n    net, layer = net_conv_relu(net, \'dc_conv1\', \'relu_dc1\', layer, 128, 3, 1, 1)\n    net, layer = net_dconv_relu(net, \'dc_conv2\', \'relu_dc2\', layer, 128, 3, 2, 1, dilation=2)\n    net, layer = net_dconv_relu(net, \'dc_conv3\', \'relu_dc3\', layer, 128, 3, 4, 1, dilation=4)\n    net, layer = net_dconv_relu(net, \'dc_conv4\', \'relu_dc4\', layer, 96, 3, 8, 1, dilation=8)\n    net, layer = net_dconv_relu(net, \'dc_conv5\', \'relu_dc5\', layer, 64, 3, 16, 1, dilation=16)\n    net, layer = net_conv_relu(net, \'dc_conv6\', \'relu_dc6\', layer, 32, 3, 1, 1)\n    net.predict_flow_inc = conv(layer, 2, 3, 1, 1)    \n\n    net.predict_flow2  = L.Eltwise(net.predict_flow_ini, net.predict_flow_inc, eltwise_param=dict(operation=1))  \n\n    return net\n\n\ndef make_net_train(lmdb, preselection, batch_size=8, weights = [0, 0, 0.005, 0.01, 0.02, 0.08, 0.32]):\n\n    net = caffe.NetSpec()\n\n    net.img0, net.img1, net.flow_gt, net.aux= L.CustomData(  \n        data_param=dict(source=lmdb, preselection_file = preselection, backend=P.Data.LMDB, batch_size=batch_size, \n            preselection_label=1, rand_permute=True, rand_permute_seed=77, slice_point=[3,6,8], encoding=[1,1,2,3], \n            verbose=True),  ntop=4, include=dict(phase=0))\n\n    net.img0_subtract = L.Eltwise(net.img0, eltwise_param=dict(operation=1,coeff=0.00392156862745))  \n    net.img1_subtract = L.Eltwise(net.img1, eltwise_param=dict(operation=1,coeff=0.00392156862745))  \n\n    net.img0_aug, net.img0_aug_params = augment_first_image(net.img0_subtract)\n\n    aug_params      = generate_aug_params(net.img0_aug_params, net.img0_subtract, net.img0_aug)    \n    net.img1_aug    = augment_second_image(net.img1_subtract, aug_params)\n\n    net.flow_gt_aug     = L.FlowAugmentation(net.flow_gt, net.img0_aug_params, aug_params, augmentation_param=dict(crop_width=448, crop_height=320))\n    net.scaled_flow_gt  = L.Eltwise(net.flow_gt_aug, eltwise_param=dict(operation=1,coeff=0.05))  \n\n    net = make_pwc_net_encoder_plus(net, net.img0_aug, net.img1_aug) \n    \n    for i in range(1, len(weights)):\n        if weights[i] > 0.:\n            scaled_flow_name  = \'scaled_flow_gt{}\'.format(i)\n            predict_flow_name = \'predict_flow{}\'.format(i)\n            loss_name         = \'loss{}\'.format(i)\n            setattr(net, scaled_flow_name, L.Downsample(net.scaled_flow_gt, getattr(net, predict_flow_name), propagate_down=[False, False]) )\n            setattr(net, loss_name, L.L1Loss(getattr(net, predict_flow_name), getattr(net, scaled_flow_name), loss_weight=weights[i], l1_loss_param=dict(l2_per_location=True)))\n    # loss at level 0: don\'t scale GT\n    if weights[0] > 0.:\n        net.loss0 = L.L1Loss(net.predict_flow0, net.scaled_flow_gt, loss_weight=weights[0] , l1_loss_param=dict(l2_per_location=True), propagate_down=[True, False])\n\n    net.Silence0 = L.Silence(net.img0, ntop=0)\n    net.Silence1 = L.Silence(net.img1, ntop=0)\n    net.Silence2 = L.Silence(net.flow_gt, ntop=0)\n    net.Silence3 = L.Silence(net.aux, ntop=0)\n    # net.Silence4 = L.Silence(net.predict_flow2_scale, ntop=0)\n\n    return net.to_proto()\n\ndef make_net_test(desired_level=2):\n    net = caffe.NetSpec()\n    net.img0_nomean_resize= L.ImageData(image_data_param=dict(source=""tmp/img1.txt"",batch_size=1))\n    net.img1_nomean_resize= L.ImageData(image_data_param=dict(source=""tmp/img2.txt"",batch_size=1))\n    \n    predict_flow_name = \'predict_flow{}\'.format(desired_level)\n\n    net = make_pwc_net_encoder_plus(net, net.img0_nomean_resize, net.img1_nomean_resize) \n    net.blob44 = L.Eltwise(getattr(net, predict_flow_name), eltwise_param=dict(operation=1, coeff=20.0))  \n\n    return net.to_proto()\n'"
Multi_Frame_Flow/external_packages/channelnorm_package/__init__.py,0,b''
Multi_Frame_Flow/external_packages/channelnorm_package/build.py,3,"b""import os\nimport torch\nimport torch.utils.ffi\n\nthis_folder = os.path.dirname(os.path.abspath(__file__)) + '/'\n\nHeaders = []\nSources = []\nDefines = []\nObjects = []\n\nif torch.cuda.is_available() == True:\n    Headers += ['src/ChannelNorm_cuda.h']\n    Sources += ['src/ChannelNorm_cuda.c']\n    Defines += [('WITH_CUDA', None)]\n    Objects += ['src/ChannelNorm_kernel.o']\n\nffi = torch.utils.ffi.create_extension(\n    name='_ext.channelnorm',\n    headers=Headers,\n    sources=Sources,\n    verbose=False,\n    with_cuda=True,\n    package=False,\n    relative_to=this_folder,\n    define_macros=Defines,\n    extra_objects=[os.path.join(this_folder, Object) for Object in Objects]\n)\n\nif __name__ == '__main__':\n    ffi.build()"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_kitti/train_1215.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe.bin'\n\nos.system('mkdir training') \nos.chdir('training') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_1215.prototxt', '-weights', './init.caffemodel'] + sys.argv[1:]\t\n\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tlatest_iter = max(iters)\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_1215.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_kitti/train_1215_ft2.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '/mnt/zfs/projects/ml_flow/v2x/flownet2/build/tools/caffe.bin'\n\nos.system('mkdir training_ft2') \nos.chdir('training_ft2') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_1215_ft2.prototxt', '-weights', '../training/flow_iter_150000.caffemodel'] + sys.argv[1:]\t\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tlatest_iter = max(iters)\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_1215_ft2.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_kitti/train_1215_ft3.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe.bin'\n\n\nos.system('mkdir training_ft3') \nos.chdir('training_ft3') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_1215_ft3.prototxt', '-weights', '../training_ft2/flow_iter_150000.caffemodel'] + sys.argv[1:]\t\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tlatest_iter = max(iters)\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_1215_ft3.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_kitti/train_1215_ft4.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe.bin'\n\n\nos.system('mkdir training_ft4') \nos.chdir('training_ft4') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_1215_ft4.prototxt', '-weights', '../training_ft3/flow_iter_150000.caffemodel'] + sys.argv[1:]\t\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tlatest_iter = max(iters)\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_1215_ft4.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_sintel/train_ft.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe.bin' \n\nos.system('mkdir training_ft') \nos.chdir('training_ft') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft.prototxt', '-weights', './training_things/things.caffemodel'] + sys.argv[1:]\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tif len(iters)==0:\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft.prototxt', '-weights', './training_things/things.caffemodel'] + sys.argv[1:]\n\telse:\n\t\tlatest_iter = max(iters)\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_sintel/train_ft2.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe.bin' \n\nos.system('mkdir training_ft2') \nos.chdir('training_ft2') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft2.prototxt', '-weights', './training_ft/flow_iter_150000.caffemodel'] + sys.argv[1:]\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tif len(iters)==0:\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft2.prototxt', '-weights', './training_ft/flow_iter_150000.caffemodel'] + sys.argv[1:]\n\telse:\n\t\tlatest_iter = max(iters)\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft2.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_sintel/train_ft3.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe.bin' \n\nos.system('mkdir training_ft3') \nos.chdir('training_ft3') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft3.prototxt', '-weights', './training_ft2/flow_iter_150000.caffemodel'] + sys.argv[1:]\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tif len(iters)==0:\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft3.prototxt', '-weights', './training_ft2/flow_iter_150000.caffemodel'] + sys.argv[1:]\n\telse:\n\t\tlatest_iter = max(iters)\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft3.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_sintel/train_ft4.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe.bin' \n\nos.system('mkdir training_ft4') \nos.chdir('training_ft4') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft4.prototxt', '-weights', './training_ft3/flow_iter_150000.caffemodel'] + sys.argv[1:]\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tif len(iters)==0:\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft4.prototxt', '-weights', './training_ft3/flow_iter_150000.caffemodel'] + sys.argv[1:]\n\telse:\n\t\tlatest_iter = max(iters)\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft4.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Caffe/model/PWC-Net_plus/PWC-Net_plus_sintel/train_ft5.py,0,"b""#!/usr/bin/env python\nimport os, sys\nimport subprocess\n\ncaffe_bin = '../../../build/tools/caffe.bin' \n\nos.system('mkdir training_ft5') \nos.chdir('training_ft5') \n\n# =========================================================\n\nmy_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(my_dir)\n\n\nif os.path.exists('./core'):\n\tos.remove('./core')\n\nif not os.path.isfile(caffe_bin):\n    print('Caffe tool binaries not found. Did you compile caffe with tools (make all tools)?')\n    sys.exit(1)\n\nprint('args:', sys.argv[1:])\n\ntrained_filenames = os.listdir('./')\n\nif len(trained_filenames)==0:\n\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft5.prototxt', '-weights', './training_ft4/flow_iter_150000.caffemodel'] + sys.argv[1:]\nelse:\n\t# start from the latest training result\n\titers = []\n\tfor i in range(len(trained_filenames)):\n\t\ti0 = trained_filenames[i].find('iter_')\n\t\tif  i0==-1:\n\t\t\tcontinue\n\t\ti1 = trained_filenames[i].find('.')\n\t\titers.append(int(trained_filenames[i][i0+5:i1]))\t\t\n\tif len(iters)==0:\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft5.prototxt', '-weights', './training_ft4/flow_iter_150000.caffemodel'] + sys.argv[1:]\n\telse:\n\t\tlatest_iter = max(iters)\n\t\targs = [caffe_bin, 'train', '-solver', '../model/solver_ft5.prototxt', '-snapshot', 'flow_iter_'+ str(latest_iter) + '.solverstate'] + sys.argv[1:]\n\t\n\t\ncmd = str.join(' ', args)\nprint('Executing %s' % cmd)\n\nsubprocess.call(args)\n"""
Multi_Frame_Flow/external_packages/channelnorm_package/_ext/__init__.py,0,b''
Multi_Frame_Flow/external_packages/channelnorm_package/functions/__init__.py,0,b''
Multi_Frame_Flow/external_packages/channelnorm_package/functions/channelnorm.py,3,"b'import torch\nfrom torch.autograd import Function\nfrom .._ext import channelnorm\n\n\nclass ChannelNormFunction(Function):\n\n    def __init__(self, norm_deg=2):\n        super(ChannelNormFunction, self).__init__()\n        self.norm_deg = norm_deg\n\n    def forward(self, input1):\n        # self.save_for_backward(input1)\n\n        assert(input1.is_contiguous() == True)\n\n        with torch.cuda.device_of(input1):\n            b, _, h, w = input1.size()\n            output = input1.new().resize_(b, 1, h, w).zero_()\n\n            channelnorm.ChannelNorm_cuda_forward(input1, output, self.norm_deg)\n        self.save_for_backward(input1, output)\n\n        return output\n\n    def backward(self, gradOutput):\n        input1, output = self.saved_tensors\n\n        with torch.cuda.device_of(input1):\n            b, c, h, w = input1.size()\n            gradInput1 = input1.new().resize_(b,c,h,w).zero_()\n\n            channelnorm.ChannelNorm_cuda_backward(input1, output, gradOutput, gradInput1, self.norm_deg)\n\n        return gradInput1'"
Multi_Frame_Flow/external_packages/channelnorm_package/modules/__init__.py,0,b''
Multi_Frame_Flow/external_packages/channelnorm_package/modules/channelnorm.py,1,"b'from torch.nn.modules.module import Module\n\nfrom ..functions.channelnorm import ChannelNormFunction\n\nclass ChannelNorm(Module):\n    def __init__(self, norm_deg=2):\n        super(ChannelNorm, self).__init__()\n        self.norm_deg = norm_deg\n\n    def forward(self, input1):\n\n        result = ChannelNormFunction(self.norm_deg)(input1)\n\n        return result\n'"
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/build.py,2,"b""import os\nimport torch\nfrom torch.utils.ffi import create_extension\n\n\nsources = ['correlation_package/src/corr.c']\nheaders = ['correlation_package/src/corr.h']\n\nsources += ['correlation_package/src/corr1d.c']\nheaders += ['correlation_package/src/corr1d.h']\n\ndefines = []\nwith_cuda = False\n\nif torch.cuda.is_available():\n    print('Including CUDA code.')\n    sources += ['correlation_package/src/corr_cuda.c']\n    headers += ['correlation_package/src/corr_cuda.h']\n\n    sources += ['correlation_package/src/corr1d_cuda.c']\n    headers += ['correlation_package/src/corr1d_cuda.h']\n \n    defines += [('WITH_CUDA', None)]\n    with_cuda = True\n\nthis_file = os.path.dirname(os.path.realpath(__file__))\nextra_objects = ['correlation_package/src/corr_cuda_kernel.cu.o']\nextra_objects += ['correlation_package/src/corr1d_cuda_kernel.cu.o']\nextra_objects = [os.path.join(this_file, fname) for fname in extra_objects]\n\nffi = create_extension(\n    'correlation_package._ext.corr',\n    package=True,\n    headers=headers,\n    sources=sources,\n    define_macros=defines,\n    relative_to=__file__,\n    with_cuda=with_cuda,\n    extra_objects=extra_objects,\n)\n\nif __name__ == '__main__':\n    ffi.build()\n"""
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/setup.py,0,"b'#!/usr/bin/env python\n\nimport os\n\nfrom setuptools import setup, find_packages\n\nthis_file = os.path.dirname(__file__)\n\nsetup(\n    name=""correlation_package"",\n    version=""0.1"",\n    description=""Correlation layer from FlowNetC"",\n    url=""https://github.com/jbarker-nvidia/pytorch-correlation"",\n    author=""Jon Barker"",\n    author_email=""jbarker@nvidia.com"",\n    # Require cffi\n    install_requires=[""cffi>=1.0.0""],\n    setup_requires=[""cffi>=1.0.0""],\n    # Exclude the build files.\n    packages=find_packages(exclude=[""build""]),\n    # Package where to put the extensions. Has to be a prefix of build.py\n    ext_package="""",\n    # Extensions to compile\n    cffi_modules=[\n        os.path.join(this_file, ""build.py:ffi"")\n    ],\n)\n'"
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/__init__.py,0,b''
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/build.py,2,"b""import os\nimport torch\nfrom torch.utils.ffi import create_extension\n\n\nsources = ['correlation_package/src/corr.c']\nheaders = ['correlation_package/src/corr.h']\n\nsources += ['correlation_package/src/corr1d.c']\nheaders += ['correlation_package/src/corr1d.h']\n\ndefines = []\nwith_cuda = False\n\nif torch.cuda.is_available():\n    print('Including CUDA code.')\n    sources += ['correlation_package/src/corr_cuda.c']\n    headers += ['correlation_package/src/corr_cuda.h']\n\n    sources += ['correlation_package/src/corr1d_cuda.c']\n    headers += ['correlation_package/src/corr1d_cuda.h']\n \n    defines += [('WITH_CUDA', None)]\n    with_cuda = True\n\nthis_file = os.path.dirname(os.path.realpath(__file__))\nextra_objects = ['correlation_package/src/corr_cuda_kernel.cu.o']\nextra_objects += ['correlation_package/src/corr1d_cuda_kernel.cu.o']\nextra_objects = [os.path.join(this_file, fname) for fname in extra_objects]\n\nffi = create_extension(\n    'correlation_package._ext.corr',\n    package=True,\n    headers=headers,\n    sources=sources,\n    define_macros=defines,\n    relative_to=__file__,\n    with_cuda=with_cuda,\n    extra_objects=extra_objects,\n)\n\nif __name__ == '__main__':\n    ffi.build()\n"""
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/setup.py,0,"b'#!/usr/bin/env python\n\nimport os\n\nfrom setuptools import setup, find_packages\n\nthis_file = os.path.dirname(__file__)\n\nsetup(\n    name=""correlation_package"",\n    version=""0.1"",\n    description=""Correlation layer from FlowNetC"",\n    url=""https://github.com/jbarker-nvidia/pytorch-correlation"",\n    author=""Jon Barker"",\n    author_email=""jbarker@nvidia.com"",\n    # Require cffi\n    install_requires=[""cffi>=1.0.0""],\n    setup_requires=[""cffi>=1.0.0""],\n    # Exclude the build files.\n    packages=find_packages(exclude=[""build""]),\n    # Package where to put the extensions. Has to be a prefix of build.py\n    ext_package="""",\n    # Extensions to compile\n    cffi_modules=[\n        os.path.join(this_file, ""build.py:ffi"")\n    ],\n)\n'"
Multi_Frame_Flow/external_packages/channelnorm_package/_ext/channelnorm/__init__.py,1,"b'\nfrom torch.utils.ffi import _wrap_function\nfrom ._channelnorm import lib as _lib, ffi as _ffi\n\n__all__ = []\ndef _import_symbols(locals):\n    for symbol in dir(_lib):\n        fn = getattr(_lib, symbol)\n        locals[symbol] = _wrap_function(fn, _ffi)\n        __all__.append(symbol)\n\n_import_symbols(locals())\n'"
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/test/test.py,21,"b""import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom correlation_package.modules.corr import Correlation, Correlation1d\nfrom correlation_package.functions.corr import correlation, correlation1d\n\nfrom torch.autograd import gradcheck\n\nimport numpy as np\n\ndef test_correlation():\n#    model = correlation(1, 1, 1, 1, 1, 1)\n#    A = Variable(torch.randn(1,1,3,3))\n#    A_ = A.cuda()\n#    B = Variable(torch.randn(1,1,3,3))\n#    B_ = B.cuda()\n#\n#   #import pdb; pdb.set_trace()\n#    #model = correlation1d(3, 1, 20, 1, 1, 1)\n#    y = model(A_, B_)\n#    print(y.size())\n#\n#    print(y)\n#    return\n\n\n    A = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    A_ = A.cuda()\n    B = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    B_ = B.cuda()\n\n    model = correlation(3, 3, 20, 1, 2, 1)\n    y = model(A_, B_)\n    print(y.size())\n\n    print('Functional interface test passed')\n\n    z = torch.mean(y)\n    z.backward()\n    print(A.grad.size())\n    print(B.grad.size())\n\n    if A.grad is not None and B.grad is not None:\n        print('Backward pass test passed')\n\n    A = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    A_ = A.cuda()\n    B = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    B_ = B.cuda()\n\n    y = Correlation(3, 3, 20, 1, 2, 1)(A_, B_)\n    print(y.size())\n\n    print('Module interface test passed')\n\n    z = torch.mean(y)\n    z.backward()\n    print(A.grad.size())\n    print(B.grad.size())\n\n    if A.grad is not None and B.grad is not None:\n        print('Backward pass test passed')\n\ndef test_correlation_0():\n    #model = correlation(0, 1, 0, 1, 1, 1)\n\n    A = torch.Tensor([[1,2],[3,4]])\n    B = torch.Tensor([[5,6],[7,8]])\n    A = A.view((1,1,2,2))\n    B = B.view((1,1,2,2))\n    A = Variable(A)\n    B = Variable(B)\n    A_ = A.cuda()\n    B_ = B.cuda()\n\n    #y = model(A_, B_)\n    #print(y) # should be 1x1x2x2 [[5,12],[21,32]]\n\n    model2 = correlation(1, 1, 1, 1, 1, 1)\n    y2 = model2(A_, B_)\n    print(y2) # should be 1x9x2x2\n\n\n\ndef test_correlation1d_0():\n    #model = correlation1d(0, 1, 0, 1, 1, 1)\n\n    A = torch.Tensor([[1,2],[3,4]])\n    B = torch.Tensor([[5,6],[7,8]])\n    A = A.view((1,1,2,2))\n    B = B.view((1,1,2,2))\n    A = Variable(A)\n    B = Variable(B)\n    A_ = A.cuda()\n    B_ = B.cuda()\n\n    #y = model(A_, B_)\n    #print(y) # should be 1x1x2x2 [[5,12],[21,32]]\n\n\n    model2 = correlation1d(1, 1, 1, 1, 1, 1)\n    y2 = model2(A_, B_)\n    print(y2) # should be 1x3x2x2\n\n    return\n\n\ndef test_correlation1d():\n    A = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    A_ = A.cuda()\n    B = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    B_ = B.cuda()\n\n    #import pdb; pdb.set_trace()\n    model = correlation1d(20, 1, 20, 1, 1, 1)\n    y = model(A_, B_)\n    print(y.size())\n\n    print('Functional interface test passed')\n\n    z = torch.mean(y)\n    z.backward()\n    print(A.grad.size())\n    print(B.grad.size())\n\n    if A.grad is not None and B.grad is not None:\n        print('Backward pass test passed')\n\n    A = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    A_ = A.cuda()\n    B = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    B_ = B.cuda()\n\n    y = Correlation1d(20, 1, 20, 1, 1, 1)(A_, B_)\n    print(y.size())\n\n    print('Module interface test passed')\n\n    z = torch.mean(y)\n    z.backward()\n    print(A.grad.size())\n    print(B.grad.size())\n\n    if A.grad is not None and B.grad is not None:\n        print('Backward pass test passed')\n\n\nif __name__=='__main__':\n\n    #test_correlation()\n\n    #test_correlation1d()\n\n    #test_correlation_0()\n\n    test_correlation1d_0()\n"""
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/__init__.py,0,b''
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/test/test.py,21,"b""import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom correlation_package.modules.corr import Correlation, Correlation1d\nfrom correlation_package.functions.corr import correlation, correlation1d\n\nfrom torch.autograd import gradcheck\n\nimport numpy as np\n\ndef test_correlation():\n#    model = correlation(1, 1, 1, 1, 1, 1)\n#    A = Variable(torch.randn(1,1,3,3))\n#    A_ = A.cuda()\n#    B = Variable(torch.randn(1,1,3,3))\n#    B_ = B.cuda()\n#\n#   #import pdb; pdb.set_trace()\n#    #model = correlation1d(3, 1, 20, 1, 1, 1)\n#    y = model(A_, B_)\n#    print(y.size())\n#\n#    print(y)\n#    return\n\n\n    A = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    A_ = A.cuda()\n    B = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    B_ = B.cuda()\n\n    model = correlation(3, 3, 20, 1, 2, 1)\n    y = model(A_, B_)\n    print(y.size())\n\n    print('Functional interface test passed')\n\n    z = torch.mean(y)\n    z.backward()\n    print(A.grad.size())\n    print(B.grad.size())\n\n    if A.grad is not None and B.grad is not None:\n        print('Backward pass test passed')\n\n    A = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    A_ = A.cuda()\n    B = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    B_ = B.cuda()\n\n    y = Correlation(3, 3, 20, 1, 2, 1)(A_, B_)\n    print(y.size())\n\n    print('Module interface test passed')\n\n    z = torch.mean(y)\n    z.backward()\n    print(A.grad.size())\n    print(B.grad.size())\n\n    if A.grad is not None and B.grad is not None:\n        print('Backward pass test passed')\n\ndef test_correlation_0():\n    #model = correlation(0, 1, 0, 1, 1, 1)\n\n    A = torch.Tensor([[1,2],[3,4]])\n    B = torch.Tensor([[5,6],[7,8]])\n    A = A.view((1,1,2,2))\n    B = B.view((1,1,2,2))\n    A = Variable(A)\n    B = Variable(B)\n    A_ = A.cuda()\n    B_ = B.cuda()\n\n    #y = model(A_, B_)\n    #print(y) # should be 1x1x2x2 [[5,12],[21,32]]\n\n    model2 = correlation(1, 1, 1, 1, 1, 1)\n    y2 = model2(A_, B_)\n    print(y2) # should be 1x9x2x2\n\n\n\ndef test_correlation1d_0():\n    #model = correlation1d(0, 1, 0, 1, 1, 1)\n\n    A = torch.Tensor([[1,2],[3,4]])\n    B = torch.Tensor([[5,6],[7,8]])\n    A = A.view((1,1,2,2))\n    B = B.view((1,1,2,2))\n    A = Variable(A)\n    B = Variable(B)\n    A_ = A.cuda()\n    B_ = B.cuda()\n\n    #y = model(A_, B_)\n    #print(y) # should be 1x1x2x2 [[5,12],[21,32]]\n\n\n    model2 = correlation1d(1, 1, 1, 1, 1, 1)\n    y2 = model2(A_, B_)\n    print(y2) # should be 1x3x2x2\n\n    return\n\n\ndef test_correlation1d():\n    A = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    A_ = A.cuda()\n    B = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    B_ = B.cuda()\n\n    #import pdb; pdb.set_trace()\n    model = correlation1d(20, 1, 20, 1, 1, 1)\n    y = model(A_, B_)\n    print(y.size())\n\n    print('Functional interface test passed')\n\n    z = torch.mean(y)\n    z.backward()\n    print(A.grad.size())\n    print(B.grad.size())\n\n    if A.grad is not None and B.grad is not None:\n        print('Backward pass test passed')\n\n    A = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    A_ = A.cuda()\n    B = Variable(torch.randn(2,3,100,100), requires_grad=True)\n    B_ = B.cuda()\n\n    y = Correlation1d(20, 1, 20, 1, 1, 1)(A_, B_)\n    print(y.size())\n\n    print('Module interface test passed')\n\n    z = torch.mean(y)\n    z.backward()\n    print(A.grad.size())\n    print(B.grad.size())\n\n    if A.grad is not None and B.grad is not None:\n        print('Backward pass test passed')\n\n\nif __name__=='__main__':\n\n    #test_correlation()\n\n    #test_correlation1d()\n\n    #test_correlation_0()\n\n    test_correlation1d_0()\n"""
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/_ext/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/functions/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/functions/corr.py,5,"b'import torch\nfrom torch.autograd import Function\nfrom .._ext import corr\n\nclass correlation(Function):\n\n    def __init__(self, pad_size=3, kernel_size=3, max_displacement=20, stride1=1, stride2=1, corr_multiply=1):\n        super(correlation, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def forward(self, input1, input2):\n\n        self.save_for_backward(input1, input2)\n        \n        rbot1 = input1.new()\n        rbot2 = input2.new()\n        output = input1.new()\n\n        corr.corr_cuda_forward(input1, input2,\n                               rbot1, rbot2,\n                               output,\n                               self.pad_size,\n                               self.kernel_size,\n                               self.max_displacement,\n                               self.stride1,\n                               self.stride2,\n                               self.corr_multiply)\n\n        return output\n\n    def backward(self, grad_output):\n\n        input1, input2 = self.saved_tensors\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n\n        grad_input1 = torch.zeros(input1.size()).cuda()\n        grad_input2 = torch.zeros(input2.size()).cuda()\n\n        corr.corr_cuda_backward(input1, input2,\n                                rbot1, rbot2,\n                                grad_output,\n                                grad_input1,\n                                grad_input2,\n                                self.pad_size,\n                                self.kernel_size,\n                                self.max_displacement,\n                                self.stride1,\n                                self.stride2,\n                                self.corr_multiply)\n\n        return grad_input1, grad_input2\n\n\n#----- 1D correlation (for disparity) Jinwei Gu -----\n\nclass correlation1d(Function):\n\n    def __init__(self, pad_size=3, kernel_size=3, max_displacement=20, stride1=1, stride2=1, corr_multiply=1):\n        super(correlation1d, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def forward(self, input1, input2):\n\n        self.save_for_backward(input1, input2)\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n        output = input1.new()\n\n        corr.corr1d_cuda_forward(input1, input2,\n                               rbot1, rbot2,\n                               output,\n                               self.pad_size,\n                               self.kernel_size,\n                               self.max_displacement,\n                               self.stride1,\n                               self.stride2,\n                               self.corr_multiply)\n\n        return output\n\n    def backward(self, grad_output):\n\n        input1, input2 = self.saved_tensors\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n\n        grad_input1 = torch.zeros(input1.size()).cuda()\n        grad_input2 = torch.zeros(input2.size()).cuda()\n\n        #grad_input1 = grad_output.new()\n        #grad_input2 = grad_output.new()\n\n        corr.corr1d_cuda_backward(input1, input2,\n                                rbot1, rbot2,\n                                grad_output,\n                                grad_input1,\n                                grad_input2,\n                                self.pad_size,\n                                self.kernel_size,\n                                self.max_displacement,\n                                self.stride1,\n                                self.stride2,\n                                self.corr_multiply)\n\n        return grad_input1, grad_input2\n'"
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/modules/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/modules/corr.py,1,"b'from torch.nn.modules.module import Module\nfrom ..functions.corr import correlation, correlation1d\n\nclass Correlation(Module):\n\n    def __init__(self, pad_size=None, kernel_size=None, max_displacement=None,\n                 stride1=None, stride2=None, corr_multiply=None):\n        super(Correlation, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def reset_params(self):\n        return\n\n    def forward(self, input1, input2):\n        return correlation(self.pad_size, self.kernel_size, self.max_displacement, self.stride1, self.stride2, self.corr_multiply)(input1, input2)\n\n    def __repr__(self):\n        return self.__class__.__name__\n\n\n#----- correlation in 1D (for disparity) Jinwei Gu -----\n\nclass Correlation1d(Module):\n\n    def __init__(self, pad_size=None, kernel_size=None, max_displacement=None,\n                 stride1=None, stride2=None, corr_multiply=None):\n        super(Correlation1d, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def reset_params(self):\n        return\n\n    def forward(self, input1, input2):\n        return correlation1d(self.pad_size, self.kernel_size, self.max_displacement, self.stride1, self.stride2, self.corr_multiply)(input1, input2)\n\n    def __repr__(self):\n        return self.__class__.__name__\n'"
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/_ext/__init__.py,0,b''
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/functions/__init__.py,0,b''
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/functions/corr.py,5,"b'import torch\nfrom torch.autograd import Function\nfrom .._ext import corr\n\nclass correlation(Function):\n\n    def __init__(self, pad_size=3, kernel_size=3, max_displacement=20, stride1=1, stride2=1, corr_multiply=1):\n        super(correlation, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def forward(self, input1, input2):\n\n        self.save_for_backward(input1, input2)\n        \n        rbot1 = input1.new()\n        rbot2 = input2.new()\n        output = input1.new()\n\n        corr.corr_cuda_forward(input1, input2,\n                               rbot1, rbot2,\n                               output,\n                               self.pad_size,\n                               self.kernel_size,\n                               self.max_displacement,\n                               self.stride1,\n                               self.stride2,\n                               self.corr_multiply)\n\n        return output\n\n    def backward(self, grad_output):\n\n        input1, input2 = self.saved_tensors\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n\n        grad_input1 = torch.zeros(input1.size()).cuda()\n        grad_input2 = torch.zeros(input2.size()).cuda()\n\n        corr.corr_cuda_backward(input1, input2,\n                                rbot1, rbot2,\n                                grad_output,\n                                grad_input1,\n                                grad_input2,\n                                self.pad_size,\n                                self.kernel_size,\n                                self.max_displacement,\n                                self.stride1,\n                                self.stride2,\n                                self.corr_multiply)\n\n        return grad_input1, grad_input2\n\n\n#----- 1D correlation (for disparity) Jinwei Gu -----\n\nclass correlation1d(Function):\n\n    def __init__(self, pad_size=3, kernel_size=3, max_displacement=20, stride1=1, stride2=1, corr_multiply=1):\n        super(correlation1d, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def forward(self, input1, input2):\n\n        self.save_for_backward(input1, input2)\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n        output = input1.new()\n\n        corr.corr1d_cuda_forward(input1, input2,\n                               rbot1, rbot2,\n                               output,\n                               self.pad_size,\n                               self.kernel_size,\n                               self.max_displacement,\n                               self.stride1,\n                               self.stride2,\n                               self.corr_multiply)\n\n        return output\n\n    def backward(self, grad_output):\n\n        input1, input2 = self.saved_tensors\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n\n        grad_input1 = torch.zeros(input1.size()).cuda()\n        grad_input2 = torch.zeros(input2.size()).cuda()\n\n        #grad_input1 = grad_output.new()\n        #grad_input2 = grad_output.new()\n\n        corr.corr1d_cuda_backward(input1, input2,\n                                rbot1, rbot2,\n                                grad_output,\n                                grad_input1,\n                                grad_input2,\n                                self.pad_size,\n                                self.kernel_size,\n                                self.max_displacement,\n                                self.stride1,\n                                self.stride2,\n                                self.corr_multiply)\n\n        return grad_input1, grad_input2\n'"
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/modules/__init__.py,0,b''
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/modules/corr.py,1,"b'from torch.nn.modules.module import Module\nfrom ..functions.corr import correlation, correlation1d\n\nclass Correlation(Module):\n\n    def __init__(self, pad_size=None, kernel_size=None, max_displacement=None,\n                 stride1=None, stride2=None, corr_multiply=None):\n        super(Correlation, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def reset_params(self):\n        return\n\n    def forward(self, input1, input2):\n        return correlation(self.pad_size, self.kernel_size, self.max_displacement, self.stride1, self.stride2, self.corr_multiply)(input1, input2)\n\n    def __repr__(self):\n        return self.__class__.__name__\n\n\n#----- correlation in 1D (for disparity) Jinwei Gu -----\n\nclass Correlation1d(Module):\n\n    def __init__(self, pad_size=None, kernel_size=None, max_displacement=None,\n                 stride1=None, stride2=None, corr_multiply=None):\n        super(Correlation1d, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def reset_params(self):\n        return\n\n    def forward(self, input1, input2):\n        return correlation1d(self.pad_size, self.kernel_size, self.max_displacement, self.stride1, self.stride2, self.corr_multiply)(input1, input2)\n\n    def __repr__(self):\n        return self.__class__.__name__\n'"
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/build/lib.linux-x86_64-2.7/correlation_package/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/_ext/corr/__init__.py,1,"b'\nfrom torch.utils.ffi import _wrap_function\nfrom ._corr import lib as _lib, ffi as _ffi\n\n__all__ = []\ndef _import_symbols(locals):\n    for symbol in dir(_lib):\n        fn = getattr(_lib, symbol)\n        locals[symbol] = _wrap_function(fn, _ffi)\n        __all__.append(symbol)\n\n_import_symbols(locals())\n'"
PyTorch/external_packages/correlation-pytorch-master/correlation-pytorch/correlation_package/_ext/corr/__init__.py,1,"b'\nfrom torch.utils.ffi import _wrap_function\nfrom ._corr import lib as _lib, ffi as _ffi\n\n__all__ = []\ndef _import_symbols(locals):\n    for symbol in dir(_lib):\n        fn = getattr(_lib, symbol)\n        locals[symbol] = _wrap_function(fn, _ffi)\n        __all__.append(symbol)\n\n_import_symbols(locals())\n'"
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/build/lib.linux-x86_64-2.7/correlation_package/_ext/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/build/lib.linux-x86_64-2.7/correlation_package/functions/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/build/lib.linux-x86_64-2.7/correlation_package/functions/corr.py,5,"b'import torch\nfrom torch.autograd import Function\nfrom .._ext import corr\n\nclass correlation(Function):\n\n    def __init__(self, pad_size=3, kernel_size=3, max_displacement=20, stride1=1, stride2=1, corr_multiply=1):\n        super(correlation, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def forward(self, input1, input2):\n\n        self.save_for_backward(input1, input2)\n        \n        rbot1 = input1.new()\n        rbot2 = input2.new()\n        output = input1.new()\n\n        corr.corr_cuda_forward(input1, input2,\n                               rbot1, rbot2,\n                               output,\n                               self.pad_size,\n                               self.kernel_size,\n                               self.max_displacement,\n                               self.stride1,\n                               self.stride2,\n                               self.corr_multiply)\n\n        return output\n\n    def backward(self, grad_output):\n\n        input1, input2 = self.saved_tensors\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n\n        grad_input1 = torch.zeros(input1.size()).cuda()\n        grad_input2 = torch.zeros(input2.size()).cuda()\n\n        corr.corr_cuda_backward(input1, input2,\n                                rbot1, rbot2,\n                                grad_output,\n                                grad_input1,\n                                grad_input2,\n                                self.pad_size,\n                                self.kernel_size,\n                                self.max_displacement,\n                                self.stride1,\n                                self.stride2,\n                                self.corr_multiply)\n\n        return grad_input1, grad_input2\n\n\n#----- 1D correlation (for disparity) Jinwei Gu -----\n\nclass correlation1d(Function):\n\n    def __init__(self, pad_size=3, kernel_size=3, max_displacement=20, stride1=1, stride2=1, corr_multiply=1):\n        super(correlation1d, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def forward(self, input1, input2):\n\n        self.save_for_backward(input1, input2)\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n        output = input1.new()\n\n        corr.corr1d_cuda_forward(input1, input2,\n                               rbot1, rbot2,\n                               output,\n                               self.pad_size,\n                               self.kernel_size,\n                               self.max_displacement,\n                               self.stride1,\n                               self.stride2,\n                               self.corr_multiply)\n\n        return output\n\n    def backward(self, grad_output):\n\n        input1, input2 = self.saved_tensors\n\n        rbot1 = input1.new()\n        rbot2 = input2.new()\n\n        grad_input1 = torch.zeros(input1.size()).cuda()\n        grad_input2 = torch.zeros(input2.size()).cuda()\n\n        #grad_input1 = grad_output.new()\n        #grad_input2 = grad_output.new()\n\n        corr.corr1d_cuda_backward(input1, input2,\n                                rbot1, rbot2,\n                                grad_output,\n                                grad_input1,\n                                grad_input2,\n                                self.pad_size,\n                                self.kernel_size,\n                                self.max_displacement,\n                                self.stride1,\n                                self.stride2,\n                                self.corr_multiply)\n\n        return grad_input1, grad_input2\n'"
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/build/lib.linux-x86_64-2.7/correlation_package/modules/__init__.py,0,b''
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/build/lib.linux-x86_64-2.7/correlation_package/modules/corr.py,1,"b'from torch.nn.modules.module import Module\nfrom ..functions.corr import correlation, correlation1d\n\nclass Correlation(Module):\n\n    def __init__(self, pad_size=None, kernel_size=None, max_displacement=None,\n                 stride1=None, stride2=None, corr_multiply=None):\n        super(Correlation, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def reset_params(self):\n        return\n\n    def forward(self, input1, input2):\n        return correlation(self.pad_size, self.kernel_size, self.max_displacement, self.stride1, self.stride2, self.corr_multiply)(input1, input2)\n\n    def __repr__(self):\n        return self.__class__.__name__\n\n\n#----- correlation in 1D (for disparity) Jinwei Gu -----\n\nclass Correlation1d(Module):\n\n    def __init__(self, pad_size=None, kernel_size=None, max_displacement=None,\n                 stride1=None, stride2=None, corr_multiply=None):\n        super(Correlation1d, self).__init__()\n        self.pad_size = pad_size\n        self.kernel_size = kernel_size\n        self.max_displacement = max_displacement\n        self.stride1 = stride1\n        self.stride2 = stride2\n        self.corr_multiply = corr_multiply\n\n    def reset_params(self):\n        return\n\n    def forward(self, input1, input2):\n        return correlation1d(self.pad_size, self.kernel_size, self.max_displacement, self.stride1, self.stride2, self.corr_multiply)(input1, input2)\n\n    def __repr__(self):\n        return self.__class__.__name__\n'"
Multi_Frame_Flow/external_packages/correlation-pytorch-master/correlation-pytorch/build/lib.linux-x86_64-2.7/correlation_package/_ext/corr/__init__.py,1,"b'\nfrom torch.utils.ffi import _wrap_function\nfrom ._corr import lib as _lib, ffi as _ffi\n\n__all__ = []\ndef _import_symbols(locals):\n    for symbol in dir(_lib):\n        fn = getattr(_lib, symbol)\n        locals[symbol] = _wrap_function(fn, _ffi)\n        __all__.append(symbol)\n\n_import_symbols(locals())\n'"
