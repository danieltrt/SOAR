file_path,api_count,code
config.py,0,"b""# Dictionary storing network parameters.\nparams = {\n    'batch_size': 128,# Batch size.\n    'num_epochs': 100,# Number of epochs to train for.\n    'learning_rate': 2e-4,# Learning rate.\n    'beta1': 0.5,\n    'beta2': 0.999,\n    'save_epoch' : 25,# After how many epochs to save checkpoints and generate test output.\n    'dataset' : 'MNIST'}# Dataset to use. Choose from {MNIST, SVHN, CelebA, FashionMNIST}. CASE MUST MATCH EXACTLY!!!!!"""
dataloader.py,1,"b""import torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\n\n# Directory containing the data.\nroot = 'data/'\n\ndef get_data(dataset, batch_size):\n\n    # Get MNIST dataset.\n    if dataset == 'MNIST':\n        transform = transforms.Compose([\n            transforms.Resize(28),\n            transforms.CenterCrop(28),\n            transforms.ToTensor()])\n\n        dataset = dsets.MNIST(root+'mnist/', train='train', \n                                download=True, transform=transform)\n\n    # Get SVHN dataset.\n    elif dataset == 'SVHN':\n        transform = transforms.Compose([\n            transforms.Resize(32),\n            transforms.CenterCrop(32),\n            transforms.ToTensor()])\n\n        dataset = dsets.SVHN(root+'svhn/', split='train', \n                                download=True, transform=transform)\n\n    # Get FashionMNIST dataset.\n    elif dataset == 'FashionMNIST':\n        transform = transforms.Compose([\n            transforms.Resize(28),\n            transforms.CenterCrop(28),\n            transforms.ToTensor()])\n\n        dataset = dsets.FashionMNIST(root+'fashionmnist/', train='train', \n                                download=True, transform=transform)\n\n    # Get CelebA dataset.\n    # MUST ALREADY BE DOWNLOADED IN THE APPROPRIATE DIRECTOR DEFINED BY ROOT PATH!\n    elif dataset == 'CelebA':\n        transform = transforms.Compose([\n            transforms.Resize(32),\n            transforms.CenterCrop(32),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5),\n                (0.5, 0.5, 0.5))])\n\n        dataset = dsets.ImageFolder(root=root+'celeba/', transform=transform)\n\n    # Create dataloader.\n    dataloader = torch.utils.data.DataLoader(dataset, \n                                            batch_size=batch_size, \n                                            shuffle=True)\n\n    return dataloader"""
mnist_generate.py,13,"b'import argparse\n\nimport torch\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'-load_path\', required=True, help=\'Checkpoint to load path from\')\nargs = parser.parse_args()\n\nfrom models.mnist_model import Generator\n\n# Load the checkpoint file\nstate_dict = torch.load(args.load_path)\n\n# Set the device to run on: GPU or CPU.\ndevice = torch.device(""cuda:0"" if(torch.cuda.is_available()) else ""cpu"")\n# Get the \'params\' dictionary from the loaded state_dict.\nparams = state_dict[\'params\']\n\n# Create the generator network.\nnetG = Generator().to(device)\n# Load the trained generator weights.\nnetG.load_state_dict(state_dict[\'netG\'])\nprint(netG)\n\nc = np.linspace(-2, 2, 10).reshape(1, -1)\nc = np.repeat(c, 10, 0).reshape(-1, 1)\nc = torch.from_numpy(c).float().to(device)\nc = c.view(-1, 1, 1, 1)\n\nzeros = torch.zeros(100, 1, 1, 1, device=device)\n\n# Continuous latent code.\nc2 = torch.cat((c, zeros), dim=1)\nc3 = torch.cat((zeros, c), dim=1)\n\nidx = np.arange(10).repeat(10)\ndis_c = torch.zeros(100, 10, 1, 1, device=device)\ndis_c[torch.arange(0, 100), idx] = 1.0\n# Discrete latent code.\nc1 = dis_c.view(100, -1, 1, 1)\n\nz = torch.randn(100, 62, 1, 1, device=device)\n\n# To see variation along c2 (Horizontally) and c1 (Vertically)\nnoise1 = torch.cat((z, c1, c2), dim=1)\n# To see variation along c3 (Horizontally) and c1 (Vertically)\nnoise2 = torch.cat((z, c1, c3), dim=1)\n\n# Generate image.\nwith torch.no_grad():\n    generated_img1 = netG(noise1).detach().cpu()\n# Display the generated image.\nfig = plt.figure(figsize=(10, 10))\nplt.axis(""off"")\nplt.imshow(np.transpose(vutils.make_grid(generated_img1, nrow=10, padding=2, normalize=True), (1,2,0)))\nplt.show()\n\n# Generate image.\nwith torch.no_grad():\n    generated_img2 = netG(noise2).detach().cpu()\n# Display the generated image.\nfig = plt.figure(figsize=(10, 10))\nplt.axis(""off"")\nplt.imshow(np.transpose(vutils.make_grid(generated_img2, nrow=10, padding=2, normalize=True), (1,2,0)))\nplt.show()'"
train.py,17,"b'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport time\nimport random\n\nfrom models.mnist_model import Generator, Discriminator, DHead, QHead\nfrom dataloader import get_data\nfrom utils import *\nfrom config import params\n\nif(params[\'dataset\'] == \'MNIST\'):\n    from models.mnist_model import Generator, Discriminator, DHead, QHead\nelif(params[\'dataset\'] == \'SVHN\'):\n    from models.svhn_model import Generator, Discriminator, DHead, QHead\nelif(params[\'dataset\'] == \'CelebA\'):\n    from models.celeba_model import Generator, Discriminator, DHead, QHead\nelif(params[\'dataset\'] == \'FashionMNIST\'):\n    from models.mnist_model import Generator, Discriminator, DHead, QHead\n\n# Set random seed for reproducibility.\nseed = 1123\nrandom.seed(seed)\ntorch.manual_seed(seed)\nprint(""Random Seed: "", seed)\n\n# Use GPU if available.\ndevice = torch.device(""cuda:0"" if(torch.cuda.is_available()) else ""cpu"")\nprint(device, "" will be used.\\n"")\n\ndataloader = get_data(params[\'dataset\'], params[\'batch_size\'])\n\n# Set appropriate hyperparameters depending on the dataset used.\n# The values given in the InfoGAN paper are used.\n# num_z : dimension of incompressible noise.\n# num_dis_c : number of discrete latent code used.\n# dis_c_dim : dimension of discrete latent code.\n# num_con_c : number of continuous latent code used.\nif(params[\'dataset\'] == \'MNIST\'):\n    params[\'num_z\'] = 62\n    params[\'num_dis_c\'] = 1\n    params[\'dis_c_dim\'] = 10\n    params[\'num_con_c\'] = 2\nelif(params[\'dataset\'] == \'SVHN\'):\n    params[\'num_z\'] = 124\n    params[\'num_dis_c\'] = 4\n    params[\'dis_c_dim\'] = 10\n    params[\'num_con_c\'] = 4\nelif(params[\'dataset\'] == \'CelebA\'):\n    params[\'num_z\'] = 128\n    params[\'num_dis_c\'] = 10\n    params[\'dis_c_dim\'] = 10\n    params[\'num_con_c\'] = 0\nelif(params[\'dataset\'] == \'FashionMNIST\'):\n    params[\'num_z\'] = 62\n    params[\'num_dis_c\'] = 1\n    params[\'dis_c_dim\'] = 10\n    params[\'num_con_c\'] = 2\n\n# Plot the training images.\nsample_batch = next(iter(dataloader))\nplt.figure(figsize=(10, 10))\nplt.axis(""off"")\nplt.imshow(np.transpose(vutils.make_grid(\n    sample_batch[0].to(device)[ : 100], nrow=10, padding=2, normalize=True).cpu(), (1, 2, 0)))\nplt.savefig(\'Training Images {}\'.format(params[\'dataset\']))\nplt.close(\'all\')\n\n# Initialise the network.\nnetG = Generator().to(device)\nnetG.apply(weights_init)\nprint(netG)\n\ndiscriminator = Discriminator().to(device)\ndiscriminator.apply(weights_init)\nprint(discriminator)\n\nnetD = DHead().to(device)\nnetD.apply(weights_init)\nprint(netD)\n\nnetQ = QHead().to(device)\nnetQ.apply(weights_init)\nprint(netQ)\n\n# Loss for discrimination between real and fake images.\ncriterionD = nn.BCELoss()\n# Loss for discrete latent code.\ncriterionQ_dis = nn.CrossEntropyLoss()\n# Loss for continuous latent code.\ncriterionQ_con = NormalNLLLoss()\n\n# Adam optimiser is used.\noptimD = optim.Adam([{\'params\': discriminator.parameters()}, {\'params\': netD.parameters()}], lr=params[\'learning_rate\'], betas=(params[\'beta1\'], params[\'beta2\']))\noptimG = optim.Adam([{\'params\': netG.parameters()}, {\'params\': netQ.parameters()}], lr=params[\'learning_rate\'], betas=(params[\'beta1\'], params[\'beta2\']))\n\n# Fixed Noise\nz = torch.randn(100, params[\'num_z\'], 1, 1, device=device)\nfixed_noise = z\nif(params[\'num_dis_c\'] != 0):\n    idx = np.arange(params[\'dis_c_dim\']).repeat(10)\n    dis_c = torch.zeros(100, params[\'num_dis_c\'], params[\'dis_c_dim\'], device=device)\n    for i in range(params[\'num_dis_c\']):\n        dis_c[torch.arange(0, 100), i, idx] = 1.0\n\n    dis_c = dis_c.view(100, -1, 1, 1)\n\n    fixed_noise = torch.cat((fixed_noise, dis_c), dim=1)\n\nif(params[\'num_con_c\'] != 0):\n    con_c = torch.rand(100, params[\'num_con_c\'], 1, 1, device=device) * 2 - 1\n    fixed_noise = torch.cat((fixed_noise, con_c), dim=1)\n\nreal_label = 1\nfake_label = 0\n\n# List variables to store results pf training.\nimg_list = []\nG_losses = []\nD_losses = []\n\nprint(""-""*25)\nprint(""Starting Training Loop...\\n"")\nprint(\'Epochs: %d\\nDataset: {}\\nBatch Size: %d\\nLength of Data Loader: %d\'.format(params[\'dataset\']) % (params[\'num_epochs\'], params[\'batch_size\'], len(dataloader)))\nprint(""-""*25)\n\nstart_time = time.time()\niters = 0\n\nfor epoch in range(params[\'num_epochs\']):\n    epoch_start_time = time.time()\n\n    for i, (data, _) in enumerate(dataloader, 0):\n        # Get batch size\n        b_size = data.size(0)\n        # Transfer data tensor to GPU/CPU (device)\n        real_data = data.to(device)\n\n        # Updating discriminator and DHead\n        optimD.zero_grad()\n        # Real data\n        label = torch.full((b_size, ), real_label, device=device)\n        output1 = discriminator(real_data)\n        probs_real = netD(output1).view(-1)\n        loss_real = criterionD(probs_real, label)\n        # Calculate gradients.\n        loss_real.backward()\n\n        # Fake data\n        label.fill_(fake_label)\n        noise, idx = noise_sample(params[\'num_dis_c\'], params[\'dis_c_dim\'], params[\'num_con_c\'], params[\'num_z\'], b_size, device)\n        fake_data = netG(noise)\n        output2 = discriminator(fake_data.detach())\n        probs_fake = netD(output2).view(-1)\n        loss_fake = criterionD(probs_fake, label)\n        # Calculate gradients.\n        loss_fake.backward()\n\n        # Net Loss for the discriminator\n        D_loss = loss_real + loss_fake\n        # Update parameters\n        optimD.step()\n\n        # Updating Generator and QHead\n        optimG.zero_grad()\n\n        # Fake data treated as real.\n        output = discriminator(fake_data)\n        label.fill_(real_label)\n        probs_fake = netD(output).view(-1)\n        gen_loss = criterionD(probs_fake, label)\n\n        q_logits, q_mu, q_var = netQ(output)\n        target = torch.LongTensor(idx).to(device)\n        # Calculating loss for discrete latent code.\n        dis_loss = 0\n        for j in range(params[\'num_dis_c\']):\n            dis_loss += criterionQ_dis(q_logits[:, j*10 : j*10 + 10], target[j])\n\n        # Calculating loss for continuous latent code.\n        con_loss = 0\n        if (params[\'num_con_c\'] != 0):\n            con_loss = criterionQ_con(noise[:, params[\'num_z\']+ params[\'num_dis_c\']*params[\'dis_c_dim\'] : ].view(-1, params[\'num_con_c\']), q_mu, q_var)*0.1\n\n        # Net loss for generator.\n        G_loss = gen_loss + dis_loss + con_loss\n        # Calculate gradients.\n        G_loss.backward()\n        # Update parameters.\n        optimG.step()\n\n        # Check progress of training.\n        if i != 0 and i%100 == 0:\n            print(\'[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\'\n                  % (epoch+1, params[\'num_epochs\'], i, len(dataloader), \n                    D_loss.item(), G_loss.item()))\n\n        # Save the losses for plotting.\n        G_losses.append(G_loss.item())\n        D_losses.append(D_loss.item())\n\n        iters += 1\n\n    epoch_time = time.time() - epoch_start_time\n    print(""Time taken for Epoch %d: %.2fs"" %(epoch + 1, epoch_time))\n    # Generate image after each epoch to check performance of the generator. Used for creating animated gif later.\n    with torch.no_grad():\n        gen_data = netG(fixed_noise).detach().cpu()\n    img_list.append(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True))\n\n    # Generate image to check performance of generator.\n    if((epoch+1) == 1 or (epoch+1) == params[\'num_epochs\']/2):\n        with torch.no_grad():\n            gen_data = netG(fixed_noise).detach().cpu()\n        plt.figure(figsize=(10, 10))\n        plt.axis(""off"")\n        plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n        plt.savefig(""Epoch_%d {}"".format(params[\'dataset\']) %(epoch+1))\n        plt.close(\'all\')\n\n    # Save network weights.\n    if (epoch+1) % params[\'save_epoch\'] == 0:\n        torch.save({\n            \'netG\' : netG.state_dict(),\n            \'discriminator\' : discriminator.state_dict(),\n            \'netD\' : netD.state_dict(),\n            \'netQ\' : netQ.state_dict(),\n            \'optimD\' : optimD.state_dict(),\n            \'optimG\' : optimG.state_dict(),\n            \'params\' : params\n            }, \'checkpoint/model_epoch_%d_{}\'.format(params[\'dataset\']) %(epoch+1))\n\ntraining_time = time.time() - start_time\nprint(""-""*50)\nprint(\'Training finished!\\nTotal Time for Training: %.2fm\' %(training_time / 60))\nprint(""-""*50)\n\n# Generate image to check performance of trained generator.\nwith torch.no_grad():\n    gen_data = netG(fixed_noise).detach().cpu()\nplt.figure(figsize=(10, 10))\nplt.axis(""off"")\nplt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\nplt.savefig(""Epoch_%d_{}"".format(params[\'dataset\']) %(params[\'num_epochs\']))\n\n# Save network weights.\ntorch.save({\n    \'netG\' : netG.state_dict(),\n    \'discriminator\' : discriminator.state_dict(),\n    \'netD\' : netD.state_dict(),\n    \'netQ\' : netQ.state_dict(),\n    \'optimD\' : optimD.state_dict(),\n    \'optimG\' : optimG.state_dict(),\n    \'params\' : params\n    }, \'checkpoint/model_final_{}\'.format(params[\'dataset\']))\n\n\n# Plot the training losses.\nplt.figure(figsize=(10,5))\nplt.title(""Generator and Discriminator Loss During Training"")\nplt.plot(G_losses,label=""G"")\nplt.plot(D_losses,label=""D"")\nplt.xlabel(""iterations"")\nplt.ylabel(""Loss"")\nplt.legend()\nplt.savefig(""Loss Curve {}"".format(params[\'dataset\']))\n\n# Animation showing the improvements of the generator.\nfig = plt.figure(figsize=(10,10))\nplt.axis(""off"")\nims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\nanim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\nanim.save(\'infoGAN_{}.gif\'.format(params[\'dataset\']), dpi=80, writer=\'imagemagick\')\nplt.show()'"
utils.py,7,"b'import torch\nimport torch.nn as nn\nimport numpy as np\n\ndef weights_init(m):\n    """"""\n    Initialise weights of the model.\n    """"""\n    if(type(m) == nn.ConvTranspose2d or type(m) == nn.Conv2d):\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif(type(m) == nn.BatchNorm2d):\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n\nclass NormalNLLLoss:\n    """"""\n    Calculate the negative log likelihood\n    of normal distribution.\n    This needs to be minimised.\n\n    Treating Q(cj | x) as a factored Gaussian.\n    """"""\n    def __call__(self, x, mu, var):\n        \n        logli = -0.5 * (var.mul(2 * np.pi) + 1e-6).log() - (x - mu).pow(2).div(var.mul(2.0) + 1e-6)\n        nll = -(logli.sum(1).mean())\n\n        return nll\n\ndef noise_sample(n_dis_c, dis_c_dim, n_con_c, n_z, batch_size, device):\n    """"""\n    Sample random noise vector for training.\n\n    INPUT\n    --------\n    n_dis_c : Number of discrete latent code.\n    dis_c_dim : Dimension of discrete latent code.\n    n_con_c : Number of continuous latent code.\n    n_z : Dimension of iicompressible noise.\n    batch_size : Batch Size\n    device : GPU/CPU\n    """"""\n\n    z = torch.randn(batch_size, n_z, 1, 1, device=device)\n\n    idx = np.zeros((n_dis_c, batch_size))\n    if(n_dis_c != 0):\n        dis_c = torch.zeros(batch_size, n_dis_c, dis_c_dim, device=device)\n        \n        for i in range(n_dis_c):\n            idx[i] = np.random.randint(dis_c_dim, size=batch_size)\n            dis_c[torch.arange(0, batch_size), i, idx[i]] = 1.0\n\n        dis_c = dis_c.view(batch_size, -1, 1, 1)\n\n    if(n_con_c != 0):\n        # Random uniform between -1 and 1.\n        con_c = torch.rand(batch_size, n_con_c, 1, 1, device=device) * 2 - 1\n\n    noise = z\n    if(n_dis_c != 0):\n        noise = torch.cat((z, dis_c), dim=1)\n    if(n_con_c != 0):\n        noise = torch.cat((noise, con_c), dim=1)\n\n    return noise, idx'"
models/celeba_model.py,5,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n""""""\nArchitecture based on InfoGAN paper.\n""""""\n\nclass Generator(nn.Module):\n\tdef __init__(self):\n\t\tsuper().__init__()\n\n\t\tself.tconv1 = nn.ConvTranspose2d(228, 448, 2, 1, bias=False)\n\t\tself.bn1 = nn.BatchNorm2d(448)\n\n\t\tself.tconv2 = nn.ConvTranspose2d(448, 256, 4, 2, padding=1, bias=False)\n\t\tself.bn2 = nn.BatchNorm2d(256)\n\n\t\tself.tconv3 = nn.ConvTranspose2d(256, 128, 4, 2, padding=1, bias=False)\n\n\t\tself.tconv4 = nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False)\n\n\t\tself.tconv5 = nn.ConvTranspose2d(64, 3, 4, 2, padding=1, bias=False)\n\n\tdef forward(self, x):\n\t\tx = F.relu(self.bn1(self.tconv1(x)))\n\t\tx = F.relu(self.bn2(self.tconv2(x)))\n\t\tx = F.relu(self.tconv3(x))\n\t\tx = F.relu(self.tconv4(x))\n\n\t\timg = torch.tanh(self.tconv5(x))\n\n\t\treturn img\n\nclass Discriminator(nn.Module):\n\tdef __init__(self):\n\t\tsuper().__init__()\n\n\t\tself.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n\n\t\tself.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n\t\tself.bn2 = nn.BatchNorm2d(128)\n\n\t\tself.conv3 = nn.Conv2d(128, 256, 4, 2, 1, bias=False)\n\t\tself.bn3 = nn.BatchNorm2d(256)\n\n\tdef forward(self, x):\n\t\tx = F.leaky_relu(self.conv1(x), 0.1, inplace=True)\n\t\tx = F.leaky_relu(self.bn2(self.conv2(x)), 0.1, inplace=True)\n\t\tx = F.leaky_relu(self.bn3(self.conv3(x)), 0.1, inplace=True)\n\n\t\treturn x\n\nclass DHead(nn.Module):\n\tdef __init__(self):\n\t\tsuper().__init__()\n\n\t\tself.conv = nn.Conv2d(256, 1, 4)\n\n\tdef forward(self, x):\n\t\toutput = torch.sigmoid(self.conv(x))\n\n\t\treturn output\n\nclass QHead(nn.Module):\n\tdef __init__(self):\n\t\tsuper().__init__()\n\n\t\tself.conv1 = nn.Conv2d(256, 128, 4, bias=False)\n\t\tself.bn1 = nn.BatchNorm2d(128)\n\n\t\tself.conv_disc = nn.Conv2d(128, 100, 1)\n\n\t\tself.conv_mu = nn.Conv2d(128, 1, 1)\n\t\tself.conv_var = nn.Conv2d(128, 1, 1)\n\n\tdef forward(self, x):\n\t\tx = F.leaky_relu(self.bn1(self.conv1(x)), 0.1, inplace=True)\n\n\t\tdisc_logits = self.conv_disc(x).squeeze()\n\n\t\t# Not used during training for celeba dataset.\n\t\tmu = self.conv_mu(x).squeeze()\n\t\tvar = torch.exp(self.conv_var(x).squeeze())\n\n\t\treturn disc_logits, mu, var\n'"
models/mnist_model.py,5,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n""""""\nArchitecture based on InfoGAN paper.\n""""""\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.tconv1 = nn.ConvTranspose2d(74, 1024, 1, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(1024)\n\n        self.tconv2 = nn.ConvTranspose2d(1024, 128, 7, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(128)\n\n        self.tconv3 = nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(64)\n\n        self.tconv4 = nn.ConvTranspose2d(64, 1, 4, 2, padding=1, bias=False)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.tconv1(x)))\n        x = F.relu(self.bn2(self.tconv2(x)))\n        x = F.relu(self.bn3(self.tconv3(x)))\n\n        img = torch.sigmoid(self.tconv4(x))\n\n        return img\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(1, 64, 4, 2, 1)\n\n        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(128)\n\n        self.conv3 = nn.Conv2d(128, 1024, 7, bias=False)\n        self.bn3 = nn.BatchNorm2d(1024)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.conv1(x), 0.1, inplace=True)\n        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.1, inplace=True)\n        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.1, inplace=True)\n\n        return x\n\nclass DHead(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.conv = nn.Conv2d(1024, 1, 1)\n\n    def forward(self, x):\n        output = torch.sigmoid(self.conv(x))\n\n        return output\n\nclass QHead(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(1024, 128, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(128)\n\n        self.conv_disc = nn.Conv2d(128, 10, 1)\n        self.conv_mu = nn.Conv2d(128, 2, 1)\n        self.conv_var = nn.Conv2d(128, 2, 1)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.1, inplace=True)\n\n        disc_logits = self.conv_disc(x).squeeze()\n\n        mu = self.conv_mu(x).squeeze()\n        var = torch.exp(self.conv_var(x).squeeze())\n\n        return disc_logits, mu, var\n'"
models/svhn_model.py,5,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n""""""\nArchitecture based on InfoGAN paper.\n""""""\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.tconv1 = nn.ConvTranspose2d(168, 448, 2, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(448)\n\n        self.tconv2 = nn.ConvTranspose2d(448, 256, 4, 2, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(256)\n\n        self.tconv3 = nn.ConvTranspose2d(256, 128, 4, 2, padding=1, bias=False)\n\n        self.tconv4 = nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False)\n\n        self.tconv5 = nn.ConvTranspose2d(64, 3, 4, 2, padding=1, bias=False)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.tconv1(x)))\n        x = F.relu(self.bn2(self.tconv2(x)))\n        x = F.relu(self.tconv3(x))\n        x = F.relu(self.tconv4(x))\n\n        img = torch.tanh(self.tconv5(x))\n\n        return img\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n\n        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(128)\n\n        self.conv3 = nn.Conv2d(128, 256, 4, 2, 1, bias=False)\n        self.bn3 = nn.BatchNorm2d(256)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.conv1(x), 0.1, inplace=True)\n        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.1, inplace=True)\n        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.1, inplace=True)\n\n        return x\n\nclass DHead(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.conv = nn.Conv2d(256, 1, 4)\n\n    def forward(self, x):\n        output = torch.sigmoid(self.conv(x))\n\n        return output\n\nclass QHead(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(256, 128, 4, bias=False)\n        self.bn1 = nn.BatchNorm2d(128)\n\n        self.conv_disc = nn.Conv2d(128, 40, 1)\n        self.conv_mu = nn.Conv2d(128, 4, 1)\n        self.conv_var = nn.Conv2d(128, 4, 1)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.1, inplace=True)\n\n        disc_logits = self.conv_disc(x).squeeze()\n\n        mu = self.conv_mu(x).squeeze()\n        var = torch.exp(self.conv_var(x).squeeze())\n\n        return disc_logits, mu, var\n'"
