file_path,api_count,code
maint/create_release.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport sys\nimport os\nimport subprocess\nimport tempfile\nimport tarfile\nimport zipfile\n\nassert sys.version_info >= (3, 4)\nswd = os.path.dirname(os.path.realpath(__file__))\nswd = swd + \'/..\'\nswd = os.path.realpath(swd)\nget_tag = subprocess.Popen([\'git\', \'describe\', \'--tags\', \'--abbrev=0\', \'--match\', \'v*.*.*\'],\n                           cwd=swd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\ntag = [line.strip().decode() for line in get_tag.stdout.readlines()]\nretval = get_tag.wait()\n\nget_files = subprocess.Popen([\'git\', \'ls-tree\', \'-r\', \'HEAD\', \'--name-only\'],\n                             cwd=swd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n\nfiles = [line.strip().decode() for line in get_files.stdout.readlines()]\nretval = get_files.wait()\n\n# create tarball for Linux and macOS\nwith tarfile.open(swd + \'/ngraph-\' + tag[0] + \'.tar.gz\', \'w:gz\') as tar:\n    for f in files:\n        file_path = swd + \'/\' + f\n        tar.add(file_path, arcname=\'ngraph-\' + tag[0][1:] + \'/\' + f)\n    with tempfile.NamedTemporaryFile() as tag_file:\n        tag_line = tag[0] + \'\\n\'\n        tag_file.write(tag_line.encode())\n        tag_file.flush()\n        tar.add(tag_file.name, arcname=\'ngraph-\' + tag[0][1:] + \'/TAG\')\n\n# create zipfile for Windows\nTO = b\'\\r\\n\'\nFROM = b\'\\n\'\n\nwith zipfile.ZipFile(swd + \'/ngraph-\' + tag[0] + \'.zip\', \'w\', zipfile.ZIP_DEFLATED) as zipf:\n    for f in files:\n        with open(file_path, \'rb\') as unix_file:\n            win_content = unix_file.read().replace(FROM, TO)\n        with tempfile.NamedTemporaryFile() as win_file:\n            win_file.write(win_content)\n            zipf.write(win_file.name, arcname=\'ngraph-\' + tag[0][1:] + \'/\' + f)\n    with tempfile.NamedTemporaryFile() as tag_file:\n        tag_line = tag[0] + \'\\r\\n\'\n        tag_file.write(tag_line.encode())\n        tag_file.flush()\n        zipf.write(tag_file.name, arcname=\'ngraph-\' + tag[0][1:] + \'/TAG\')\n'"
python/setup.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport distutils.ccompiler\nimport os\nimport re\nimport sys\n\nimport setuptools\nfrom setuptools import Extension, setup\nfrom setuptools.command.build_ext import build_ext\n\n__version__ = os.environ.get(""NGRAPH_VERSION"", ""0.0.0-dev"")\nPYNGRAPH_ROOT_DIR = os.path.abspath(os.path.dirname(__file__))\nPYNGRAPH_SRC_DIR = os.path.join(PYNGRAPH_ROOT_DIR, ""src"")\nNGRAPH_DEFAULT_INSTALL_DIR = os.environ.get(""HOME"")\nNGRAPH_ONNX_IMPORT_ENABLE = os.environ.get(""NGRAPH_ONNX_IMPORT_ENABLE"")\nNGRAPH_PYTHON_DEBUG = os.environ.get(""NGRAPH_PYTHON_DEBUG"")\n\n\ndef find_ngraph_dist_dir():\n    """"""Return location of compiled ngraph library home.""""""\n    if os.environ.get(""NGRAPH_CPP_BUILD_PATH""):\n        ngraph_dist_dir = os.environ.get(""NGRAPH_CPP_BUILD_PATH"")\n    else:\n        ngraph_dist_dir = os.path.join(NGRAPH_DEFAULT_INSTALL_DIR, ""ngraph_dist"")\n\n    found = os.path.exists(os.path.join(ngraph_dist_dir, ""include/ngraph""))\n    if not found:\n        print(\n            ""Cannot find nGraph library in {} make sure that ""\n            ""NGRAPH_CPP_BUILD_PATH is set correctly"".format(ngraph_dist_dir)\n        )\n        sys.exit(1)\n    else:\n        print(""nGraph library found in {}"".format(ngraph_dist_dir))\n        return ngraph_dist_dir\n\n\ndef find_pybind_headers_dir():\n    """"""Return location of pybind11 headers.""""""\n    if os.environ.get(""PYBIND_HEADERS_PATH""):\n        pybind_headers_dir = os.environ.get(""PYBIND_HEADERS_PATH"")\n    else:\n        pybind_headers_dir = os.path.join(PYNGRAPH_ROOT_DIR, ""pybind11"")\n\n    found = os.path.exists(os.path.join(pybind_headers_dir, ""include/pybind11""))\n    if not found:\n        print(\n            ""Cannot find pybind11 library in {} make sure that ""\n            ""PYBIND_HEADERS_PATH is set correctly"".format(pybind_headers_dir)\n        )\n        sys.exit(1)\n    else:\n        print(""pybind11 library found in {}"".format(pybind_headers_dir))\n        return pybind_headers_dir\n\n\nNGRAPH_CPP_DIST_DIR = find_ngraph_dist_dir()\nPYBIND11_INCLUDE_DIR = find_pybind_headers_dir() + ""/include""\nNGRAPH_CPP_INCLUDE_DIR = NGRAPH_CPP_DIST_DIR + ""/include""\nif os.path.exists(os.path.join(NGRAPH_CPP_DIST_DIR, ""lib"")):\n    NGRAPH_CPP_LIBRARY_DIR = os.path.join(NGRAPH_CPP_DIST_DIR, ""lib"")\nelif os.path.exists(os.path.join(NGRAPH_CPP_DIST_DIR, ""lib64"")):\n    NGRAPH_CPP_LIBRARY_DIR = os.path.join(NGRAPH_CPP_DIST_DIR, ""lib64"")\nelse:\n    print(\n        ""Cannot find library directory in {}, make sure that nGraph is installed ""\n        ""correctly"".format(NGRAPH_CPP_DIST_DIR)\n    )\n    sys.exit(1)\n\nif sys.platform == ""win32"":\n    NGRAPH_CPP_DIST_DIR = os.path.normpath(NGRAPH_CPP_DIST_DIR)\n    PYBIND11_INCLUDE_DIR = os.path.normpath(PYBIND11_INCLUDE_DIR)\n    NGRAPH_CPP_INCLUDE_DIR = os.path.normpath(NGRAPH_CPP_INCLUDE_DIR)\n    NGRAPH_CPP_LIBRARY_DIR = os.path.normpath(NGRAPH_CPP_LIBRARY_DIR)\n\nNGRAPH_CPP_LIBRARY_NAME = ""ngraph""\n""""""For some platforms OpenVINO adds \'d\' suffix to library names in debug configuration""""""\nif len([fn for fn in os.listdir(NGRAPH_CPP_LIBRARY_DIR) if re.search(""ngraphd"", fn)]):\n    NGRAPH_CPP_LIBRARY_NAME = ""ngraphd""\n\nONNX_IMPORTER_CPP_LIBRARY_NAME = ""onnx_importer""\nif len([fn for fn in os.listdir(NGRAPH_CPP_LIBRARY_DIR) if re.search(""onnx_importerd"", fn)]):\n    ONNX_IMPORTER_CPP_LIBRARY_NAME = ""onnx_importerd""\n\n\ndef parallelCCompile(\n    self,\n    sources,\n    output_dir=None,\n    macros=None,\n    include_dirs=None,\n    debug=0,\n    extra_preargs=None,\n    extra_postargs=None,\n    depends=None,\n):\n    """"""Build sources in parallel.\n\n    Reference link:\n    http://stackoverflow.com/questions/11013851/speeding-up-build-process-with-distutils\n    Monkey-patch for parallel compilation.\n    """"""\n    # those lines are copied from distutils.ccompiler.CCompiler directly\n    macros, objects, extra_postargs, pp_opts, build = self._setup_compile(\n        output_dir, macros, include_dirs, sources, depends, extra_postargs\n    )\n    cc_args = self._get_cc_args(pp_opts, debug, extra_preargs)\n\n    if NGRAPH_PYTHON_DEBUG in [""TRUE"", ""ON"", True]:\n        try:\n            # pybind11 is much more verbose without -DNDEBUG\n            self.compiler.remove(""-DNDEBUG"")\n            self.compiler.remove(""-O2"")\n            self.compiler_so.remove(""-DNDEBUG"")\n            self.compiler_so.remove(""-O2"")\n        except (AttributeError, ValueError):\n            pass\n    # parallel code\n    import multiprocessing.pool\n\n    def _single_compile(obj):\n        try:\n            src, ext = build[obj]\n        except KeyError:\n            return\n        self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n\n    # convert to list, imap is evaluated on-demand\n    pool = multiprocessing.pool.ThreadPool()\n    list(pool.imap(_single_compile, objects))\n    return objects\n\n\ndistutils.ccompiler.CCompiler.compile = parallelCCompile\n\n\ndef has_flag(compiler, flagname):\n    """"""Check whether a flag is supported by the specified compiler.\n\n    As of Python 3.6, CCompiler has a `has_flag` method.\n    cf http://bugs.python.org/issue26689\n    """"""\n    import tempfile\n\n    with tempfile.NamedTemporaryFile(""w"", suffix="".cpp"") as f:\n        f.write(""int main (int argc, char **argv) { return 0; }"")\n        try:\n            compiler.compile([f.name], extra_postargs=[flagname])\n        except setuptools.distutils.errors.CompileError:\n            return False\n    return True\n\n\ndef cpp_flag(compiler):\n    """"""Check and return the -std=c++11 compiler flag.""""""\n    if sys.platform == ""win32"":\n        return """"  # C++11 is on by default in MSVC\n    elif has_flag(compiler, ""-std=c++11""):\n        return ""-std=c++11""\n    else:\n        raise RuntimeError(""Unsupported compiler -- C++11 support is needed!"")\n\n\nsources = [\n    ""pyngraph/axis_set.cpp"",\n    ""pyngraph/axis_vector.cpp"",\n    ""pyngraph/coordinate.cpp"",\n    ""pyngraph/coordinate_diff.cpp"",\n    ""pyngraph/dimension.cpp"",\n    ""pyngraph/function.cpp"",\n    ""pyngraph/node.cpp"",\n    ""pyngraph/node_factory.cpp"",\n    ""pyngraph/ops/constant.cpp"",\n    ""pyngraph/ops/get_output_element.cpp"",\n    ""pyngraph/ops/op.cpp"",\n    ""pyngraph/ops/parameter.cpp"",\n    ""pyngraph/ops/regmodule_pyngraph_op.cpp"",\n    ""pyngraph/ops/result.cpp"",\n    ""pyngraph/ops/util/arithmetic_reduction.cpp"",\n    ""pyngraph/ops/util/binary_elementwise_arithmetic.cpp"",\n    ""pyngraph/ops/util/binary_elementwise_comparison.cpp"",\n    ""pyngraph/ops/util/binary_elementwise_logical.cpp"",\n    ""pyngraph/ops/util/index_reduction.cpp"",\n    ""pyngraph/ops/util/op_annotations.cpp"",\n    ""pyngraph/ops/util/regmodule_pyngraph_op_util.cpp"",\n    ""pyngraph/ops/util/unary_elementwise_arithmetic.cpp"",\n    ""pyngraph/passes/manager.cpp"",\n    ""pyngraph/passes/regmodule_pyngraph_passes.cpp"",\n    ""pyngraph/partial_shape.cpp"",\n    ""pyngraph/pyngraph.cpp"",\n    ""pyngraph/runtime/backend.cpp"",\n    ""pyngraph/runtime/executable.cpp"",\n    ""pyngraph/runtime/regmodule_pyngraph_runtime.cpp"",\n    ""pyngraph/runtime/tensor.cpp"",\n    ""pyngraph/serializer.cpp"",\n    ""pyngraph/shape.cpp"",\n    ""pyngraph/strides.cpp"",\n    ""pyngraph/types/element_type.cpp"",\n    ""pyngraph/types/regmodule_pyngraph_types.cpp"",\n    ""pyngraph/util.cpp"",\n]\n\npackages = [\n    ""ngraph"",\n    ""ngraph.utils"",\n    ""ngraph.impl"",\n    ""ngraph.impl.op"",\n    ""ngraph.impl.op.util"",\n    ""ngraph.impl.passes"",\n    ""ngraph.impl.runtime"",\n]\n\nsources = [PYNGRAPH_SRC_DIR + ""/"" + source for source in sources]\n\ninclude_dirs = [PYNGRAPH_SRC_DIR, NGRAPH_CPP_INCLUDE_DIR, PYBIND11_INCLUDE_DIR]\n\nlibrary_dirs = [NGRAPH_CPP_LIBRARY_DIR]\n\nlibraries = [NGRAPH_CPP_LIBRARY_NAME, ONNX_IMPORTER_CPP_LIBRARY_NAME]\n\nextra_compile_args = []\nif NGRAPH_ONNX_IMPORT_ENABLE in [""TRUE"", ""ON"", True]:\n    extra_compile_args.append(""-DNGRAPH_ONNX_IMPORT_ENABLE"")\n\nextra_link_args = []\n\ndata_files = [\n    (\n        ""lib"",\n        [\n            os.path.join(NGRAPH_CPP_LIBRARY_DIR, library)\n            for library in os.listdir(NGRAPH_CPP_LIBRARY_DIR)\n        ],\n    ),\n    (\n        ""licenses"",\n        [\n            os.path.join(NGRAPH_CPP_DIST_DIR, ""licenses"", license)\n            for license in os.listdir(os.path.join(NGRAPH_CPP_DIST_DIR, ""licenses""))\n        ],\n    ),\n    ("""", [os.path.join(NGRAPH_CPP_DIST_DIR, ""LICENSE"")],),\n]\n\nif NGRAPH_ONNX_IMPORT_ENABLE in [""TRUE"", ""ON"", True]:\n    onnx_sources = [\n        ""pyngraph/onnx_import/onnx_import.cpp"",\n    ]\n    onnx_sources = [PYNGRAPH_SRC_DIR + ""/"" + source for source in onnx_sources]\n    sources = sources + onnx_sources\n\n    packages.append(""ngraph.impl.onnx_import"")\n\next_modules = [\n    Extension(\n        ""_pyngraph"",\n        sources=sources,\n        include_dirs=include_dirs,\n        define_macros=[(""VERSION_INFO"", __version__)],\n        library_dirs=library_dirs,\n        libraries=libraries,\n        extra_compile_args=extra_compile_args,\n        extra_link_args=extra_link_args,\n        language=""c++"",\n    ),\n]\n\n\ndef add_platform_specific_link_args(link_args):\n    """"""Add linker flags specific for the OS detected during the build.""""""\n    if sys.platform.startswith(""linux""):\n        link_args += [""-Wl,-rpath,$ORIGIN/../..""]\n        link_args += [""-z"", ""noexecstack""]\n        link_args += [""-z"", ""relro""]\n        link_args += [""-z"", ""now""]\n    elif sys.platform == ""darwin"":\n        link_args += [""-Wl,-rpath,@loader_path/../..""]\n        link_args += [""-stdlib=libc++""]\n    elif sys.platform == ""win32"":\n        link_args += [""/LTCG""]\n\n\nclass BuildExt(build_ext):\n    """"""A custom build extension for adding compiler-specific options.""""""\n\n    def _add_extra_compile_arg(self, flag, compile_args):\n        """"""Return True if successfully added given flag to compiler args.""""""\n        if has_flag(self.compiler, flag):\n            compile_args += [flag]\n            return True\n        return False\n\n    def _add_debug_or_release_flags(self):\n        """"""Return compiler flags for Release and Debug build types.""""""\n        if NGRAPH_PYTHON_DEBUG in [""TRUE"", ""ON"", True]:\n            if sys.platform == ""win32"":\n                return [""/Od"", ""/Zi"", ""/RTC1""]\n            else:\n                return [""-O0"", ""-g""]\n        else:\n            if sys.platform == ""win32"":\n                return [""/O2""]\n            else:\n                return [""-O2"", ""-D_FORTIFY_SOURCE=2""]\n\n    def _add_win_compiler_flags(self, ext):\n        self._add_extra_compile_arg(""/GL"", ext.extra_compile_args)  # Whole Program Optimization\n        self._add_extra_compile_arg(""/analyze"", ext.extra_compile_args)\n\n    def _add_unix_compiler_flags(self, ext):\n        if not self._add_extra_compile_arg(""-fstack-protector-strong"", ext.extra_compile_args):\n            self._add_extra_compile_arg(""-fstack-protector"", ext.extra_compile_args)\n\n        self._add_extra_compile_arg(""-fvisibility=hidden"", ext.extra_compile_args)\n        self._add_extra_compile_arg(""-flto"", ext.extra_compile_args)\n        self._add_extra_compile_arg(""-fPIC"", ext.extra_compile_args)\n\n        ext.extra_compile_args += [""-Wformat"", ""-Wformat-security""]\n\n    def _customize_compiler_flags(self):\n        """"""Modify standard compiler flags.""""""\n        try:\n            # -Wstrict-prototypes is not a valid option for c++\n            self.compiler.compiler_so.remove(""-Wstrict-prototypes"")\n            if NGRAPH_PYTHON_DEBUG in [""TRUE"", ""ON"", True]:\n                # pybind11 is much more verbose without -DNDEBUG\n                self.compiler.compiler_so.remove(""-DNDEBUG"")\n                self.compiler.compiler_so.remove(""-O2"")\n        except (AttributeError, ValueError):\n            pass\n\n    def build_extensions(self):\n        """"""Build extension providing extra compiler flags.""""""\n        self._customize_compiler_flags()\n        for ext in self.extensions:\n            ext.extra_compile_args += [cpp_flag(self.compiler)]\n\n            if sys.platform == ""win32"":\n                self._add_win_compiler_flags(ext)\n            else:\n                self._add_unix_compiler_flags(ext)\n\n            add_platform_specific_link_args(ext.extra_link_args)\n\n            ext.extra_compile_args += self._add_debug_or_release_flags()\n\n            if sys.platform == ""darwin"":\n                ext.extra_compile_args += [""-stdlib=libc++""]\n\n        build_ext.build_extensions(self)\n\n\nwith open(os.path.join(PYNGRAPH_ROOT_DIR, ""requirements.txt"")) as req:\n    requirements = req.read().splitlines()\n    setup_requires = [item for item in requirements if item.strip().startswith(""numpy"")]\n\nsetup(\n    name=""ngraph-core"",\n    description=""nGraph - Intel\'s graph compiler and runtime for Neural Networks"",\n    version=__version__,\n    author=""Intel Corporation"",\n    author_email=""intelnervana@intel.com"",\n    url=""https://github.com/NervanaSystems/ngraph/"",\n    license=""License :: OSI Approved :: Apache Software License"",\n    long_description=open(os.path.join(PYNGRAPH_ROOT_DIR, ""README.md"")).read(),\n    long_description_content_type=""text/markdown"",\n    ext_modules=ext_modules,\n    package_dir={"""": PYNGRAPH_SRC_DIR},\n    packages=packages,\n    cmdclass={""build_ext"": BuildExt},\n    data_files=data_files,\n    setup_requires=setup_requires,\n    install_requires=requirements,\n    zip_safe=False,\n    extras_require={},\n)\n'"
.ci/buildkite/test_ngtf_build.py,0,"b'#!/usr/bin/env python3\n# ==============================================================================\n#  Copyright 2017-2020 Intel Corporation\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# ==============================================================================\nimport argparse\nimport errno\nimport os\nfrom subprocess import check_output, call\nimport sys\nimport shutil\nimport glob\nimport platform\nimport json\nimport shlex\n\ndef command_executor(cmd, verbose=False, msg=None, stdout=None):\n    \'\'\'\n    Executes the command.\n    Example: \n      - command_executor(\'ls -lrt\')\n      - command_executor([\'ls\', \'-lrt\'])\n    \'\'\'\n    if type(cmd) == type([]):  #if its a list, convert to string\n        cmd = \' \'.join(cmd)\n    if verbose:\n        tag = \'Running COMMAND: \' if msg is None else msg\n        print(tag + cmd)\n    if (call(shlex.split(cmd), stdout=stdout) != 0):\n        raise Exception(""Error running command: "" + cmd)\n\ndef download(target_name, repo, version):\n\n    # First download to a temp folder\n    call([""git"", ""clone"", repo, target_name])\n\n    # Next goto this folder nd determone the name of the root folder\n    pwd = os.getcwd()\n\n    # Go to the tree\n    os.chdir(target_name)\n\n    # checkout the specified branch\n    command_executor([""git"", ""fetch""], verbose=True)\n    command_executor([""git"", ""checkout"", version], verbose=True)\n\n    os.chdir(pwd)\n\n# Get me the current sha for this commit\ncurrent_sha = check_output([\'git\', \'rev-parse\', \'HEAD\']).strip().decode(""utf-8"")\nprint(""nGraph SHA: "", current_sha)\n\n# Download ngraph-bridge \ndownload(\'ngraph-bridge\', \'https://github.com/tensorflow/ngraph-bridge.git\', \'master\')\n\n# Run ngraph-bridge-build\npwd = os.getcwd()\nos.chdir(\'ngraph-bridge\')\ncommand_executor([\'./build_ngtf.py\', \'--ngraph_version\', current_sha])\n\n# Now run the tests\nos.environ[\'PYTHONPATH\'] = os.getcwd() \ncommand_executor([\n    \'python3\',\n    \'test/ci/buildkite/test_runner.py\',\n    \'--artifacts\',\n    \'build_cmake/artifacts\',\n    \'--test_cpp\'\n])\n\nos.chdir(pwd)\n'"
python/examples/basic.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""Usage example for the ngraph Pythonic API.""""""\n\nimport numpy as np\nimport ngraph as ng\n\nA = ng.parameter(shape=[2, 2], name=""A"", dtype=np.float32)\nB = ng.parameter(shape=[2, 2], name=""B"")\nC = ng.parameter(shape=[2, 2], name=""C"")\n# >>> print(A)\n# <Parameter: \'A\' ([2, 2], float)>\n\nmodel = (A + B) * C\n# >>> print(model)\n# <Multiply: \'Multiply_14\' ([2, 2])>\n\nruntime = ng.runtime(backend_name=""CPU"")\n# >>> print(runtime)\n# <Runtime: Backend=\'CPU\'>\n\ncomputation = runtime.computation(model, A, B, C)\n# >>> print(computation)\n# <Computation: Multiply_14(A, B, C)>\n\nvalue_a = np.array([[1, 2], [3, 4]], dtype=np.float32)\nvalue_b = np.array([[5, 6], [7, 8]], dtype=np.float32)\nvalue_c = np.array([[9, 10], [11, 12]], dtype=np.float32)\n\nresult = computation(value_a, value_b, value_c)\n# >>> print(result)\n# [[ 54.  80.]\n#  [110. 144.]]\n\nprint(""Result = "", result)\n'"
python/test/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\n# test.BACKEND_NAME is a configuration variable determining which\n# nGraph backend tests will use. It\'s set during pytest configuration time.\n# See `pytest_configure` hook in `conftest.py` for more details.\nBACKEND_NAME = None\n'"
python/test/conftest.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport pytest\nimport test\n\n\ndef pytest_addoption(parser):\n    parser.addoption(\n        ""--backend"",\n        default=""INTERPRETER"",\n        choices=[""INTERPRETER"", ""CPU"", ""IE""],\n        help=""Select from available backends"",\n    )\n\n\ndef pytest_configure(config):\n    backend_name = config.getvalue(""backend"")\n    test.BACKEND_NAME = backend_name\n\n\ndef pytest_collection_modifyitems(config, items):\n    backend_name = config.getvalue(""backend"")\n\n    keywords = {\n        ""CPU"": ""skip_on_cpu"",\n        ""INTERPRETER"": ""skip_on_interpreter"",\n        ""IE"": ""skip_on_inference_engine"",\n    }\n\n    skip_markers = {\n        ""CPU"": pytest.mark.skip(reason=""Skipping test on the CPU backend.""),\n        ""INTERPRETER"": pytest.mark.skip(reason=""Skipping test on the INTERPRETER backend.""),\n        ""IE"": pytest.mark.skip(reason=""Skipping test on the IE backend.""),\n    }\n\n    for item in items:\n        skip_this_backend = keywords[backend_name]\n        if skip_this_backend in item.keywords:\n            item.add_marker(skip_markers[backend_name])\n'"
python/test/test_ops.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n# flake8: noqa\nfrom __future__ import absolute_import\n\nimport pytest\nimport numpy as np\nimport ngraph as ng\n\nfrom ngraph.impl import util\nfrom ngraph.impl import Shape, Strides, CoordinateDiff, AxisSet, Coordinate\nfrom ngraph.impl import Type, Function\nfrom ngraph.impl.runtime import Backend\nfrom ngraph.impl.op import Parameter\nfrom ngraph.impl.op import Constant\n\nimport test\n\n\ndef binary_op(op_str, a, b):\n\n    if op_str == ""+"":\n        return a + b\n    elif op_str == ""Add"":\n        return ng.add(a, b)\n    elif op_str == ""-"":\n        return a - b\n    elif op_str == ""Sub"":\n        return ng.subtract(a, b)\n    elif op_str == ""*"":\n        return a * b\n    elif op_str == ""Mul"":\n        return ng.multiply(a, b)\n    elif op_str == ""/"":\n        return a / b\n    elif op_str == ""Div"":\n        return ng.divide(a, b)\n    elif op_str == ""Equal"":\n        return ng.equal(a, b)\n    elif op_str == ""Greater"":\n        return ng.greater(a, b)\n    elif op_str == ""GreaterEq"":\n        return ng.greater_equal(a, b)\n    elif op_str == ""Less"":\n        return ng.less(a, b)\n    elif op_str == ""LessEq"":\n        return ng.less_equal(a, b)\n    elif op_str == ""Maximum"":\n        return ng.maximum(a, b)\n    elif op_str == ""Minimum"":\n        return ng.minimum(a, b)\n    elif op_str == ""NotEqual"":\n        return ng.not_equal(a, b)\n    elif op_str == ""Power"":\n        return ng.power(a, b)\n\n\ndef binary_op_ref(op_str, a, b):\n\n    if op_str == ""+"" or op_str == ""Add"":\n        return a + b\n    elif op_str == ""-"" or op_str == ""Sub"":\n        return a - b\n    elif op_str == ""*"" or op_str == ""Mul"":\n        return a * b\n    elif op_str == ""/"" or op_str == ""Div"":\n        return a / b\n    elif op_str == ""Dot"":\n        return np.dot(a, b)\n    elif op_str == ""Equal"":\n        return np.equal(a, b)\n    elif op_str == ""Greater"":\n        return np.greater(a, b)\n    elif op_str == ""GreaterEq"":\n        return np.greater_equal(a, b)\n    elif op_str == ""Less"":\n        return np.less(a, b)\n    elif op_str == ""LessEq"":\n        return np.less_equal(a, b)\n    elif op_str == ""Maximum"":\n        return np.maximum(a, b)\n    elif op_str == ""Minimum"":\n        return np.minimum(a, b)\n    elif op_str == ""NotEqual"":\n        return np.not_equal(a, b)\n    elif op_str == ""Power"":\n        return np.power(a, b)\n\n\ndef binary_op_exec(op_str):\n\n    element_type = Type.f32\n    shape = Shape([2, 2])\n    A = Parameter(element_type, shape)\n    B = Parameter(element_type, shape)\n    parameter_list = [A, B]\n    function = Function([binary_op(op_str, A, B)], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, shape)\n    b = backend.create_tensor(element_type, shape)\n    result = backend.create_tensor(element_type, shape)\n\n    a.write(util.numpy_to_c(np.array([[1, 6], [7, 4]], dtype=np.float32)), 16)\n    b.write(util.numpy_to_c(np.array([[5, 2], [3, 8]], dtype=np.float32)), 16)\n\n    result_arr = np.array([[0, 0], [0, 0]], dtype=np.float32)\n    result.write(util.numpy_to_c(result_arr), 16)\n    handle = backend.compile(function)\n    handle.call([result], [a, b])\n    result.read(util.numpy_to_c(result_arr), 16)\n\n    a_arr = np.array([[1, 6], [7, 4]], dtype=np.float32)\n    b_arr = np.array([[5, 2], [3, 8]], dtype=np.float32)\n    result_arr_ref = binary_op_ref(op_str, a_arr, b_arr)\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef binary_op_comparison(op_str):\n\n    element_type = Type.f32\n    shape = Shape([2, 2])\n    A = Parameter(element_type, shape)\n    B = Parameter(element_type, shape)\n    parameter_list = [A, B]\n    function = Function([binary_op(op_str, A, B)], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, shape)\n    b = backend.create_tensor(element_type, shape)\n    result = backend.create_tensor(Type.boolean, shape)\n\n    a.write(util.numpy_to_c(np.array([[1, 5], [3, 2]], dtype=np.float32)), 16)\n    b.write(util.numpy_to_c(np.array([[2, 4], [3, 1]], dtype=np.float32)), 16)\n\n    result_arr = np.array([[False, False], [False, False]], dtype=np.bool)\n    result.write(util.numpy_to_c(result_arr), 4)\n    handle = backend.compile(function)\n    handle.call([result], [a, b])\n    result.read(util.numpy_to_c(result_arr), 4)\n\n    a_arr = np.array([[1, 5], [3, 2]], dtype=np.float32)\n    b_arr = np.array([[2, 4], [3, 1]], dtype=np.float32)\n    result_arr_ref = binary_op_ref(op_str, a_arr, b_arr)\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_add():\n    binary_op_exec(""+"")\n\n\ndef test_add_op():\n    binary_op_exec(""Add"")\n\n\ndef test_sub():\n    binary_op_exec(""-"")\n\n\ndef test_sub_op():\n    binary_op_exec(""Sub"")\n\n\ndef test_mul():\n    binary_op_exec(""*"")\n\n\ndef test_mul_op():\n    binary_op_exec(""Mul"")\n\n\ndef test_div():\n    binary_op_exec(""/"")\n\n\ndef test_div_op():\n    binary_op_exec(""Div"")\n\n\ndef test_maximum():\n    binary_op_exec(""Maximum"")\n\n\ndef test_minimum():\n    binary_op_exec(""Minimum"")\n\n\ndef test_power():\n    binary_op_exec(""Power"")\n\n\ndef test_greater():\n    binary_op_comparison(""Greater"")\n\n\ndef test_greater_eq():\n    binary_op_comparison(""GreaterEq"")\n\n\ndef test_less():\n    binary_op_comparison(""Less"")\n\n\ndef test_less_eq():\n    binary_op_comparison(""LessEq"")\n\n\ndef test_not_equal():\n    binary_op_comparison(""NotEqual"")\n\n\ndef test_add_with_mul():\n\n    element_type = Type.f32\n    shape = Shape([2, 2])\n    A = Parameter(element_type, shape)\n    B = Parameter(element_type, shape)\n    C = Parameter(element_type, shape)\n    parameter_list = [A, B, C]\n    function = Function([ng.multiply(ng.add(A, B), C)], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, shape)\n    b = backend.create_tensor(element_type, shape)\n    c = backend.create_tensor(element_type, shape)\n    result = backend.create_tensor(element_type, shape)\n\n    a.write(util.numpy_to_c(np.array([1, 2, 3, 4], dtype=np.float32)), 16)\n    b.write(util.numpy_to_c(np.array([5, 6, 7, 8], dtype=np.float32)), 16)\n    c.write(util.numpy_to_c(np.array([9, 10, 11, 12], dtype=np.float32)), 16)\n\n    result_arr = np.array([0, 0, 0, 0], dtype=np.float32)\n    result.write(util.numpy_to_c(result_arr), 16)\n    handle = backend.compile(function)\n    handle.call([result], [a, b, c])\n    result.read(util.numpy_to_c(result_arr), 16)\n\n    a_arr = np.array([1, 2, 3, 4], dtype=np.float32)\n    b_arr = np.array([5, 6, 7, 8], dtype=np.float32)\n    c_arr = np.array([9, 10, 11, 12], dtype=np.float32)\n    result_arr_ref = (a_arr + b_arr) * c_arr\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef unary_op(op_str, a):\n    if op_str == ""Abs"":\n        return ng.abs(a)\n    elif op_str == ""Acos"":\n        return ng.acos(a)\n    elif op_str == ""Asin"":\n        return ng.asin(a)\n    elif op_str == ""Atan"":\n        return ng.atan(a)\n    elif op_str == ""Ceiling"":\n        return ng.ceiling(a)\n    elif op_str == ""Cos"":\n        return ng.cos(a)\n    elif op_str == ""Cosh"":\n        return ng.cosh(a)\n    elif op_str == ""Floor"":\n        return ng.floor(a)\n    elif op_str == ""log"":\n        return ng.log(a)\n    elif op_str == ""exp"":\n        return ng.exp(a)\n    elif op_str == ""negative"":\n        return ng.negative(a)\n    elif op_str == ""Reverse"":\n        return ng.reverse(a, np.array([1]), ""index"")\n    elif op_str == ""Sign"":\n        return ng.sign(a)\n    elif op_str == ""Sin"":\n        return ng.sin(a)\n    elif op_str == ""Sinh"":\n        return ng.sinh(a)\n    elif op_str == ""Sqrt"":\n        return ng.sqrt(a)\n    elif op_str == ""Tan"":\n        return ng.tan(a)\n    elif op_str == ""Tanh"":\n        return ng.tanh(a)\n\n\ndef unary_op_ref(op_str, a):\n    if op_str == ""Abs"":\n        return np.abs(a)\n    elif op_str == ""Acos"":\n        return np.arccos(a)\n    elif op_str == ""Asin"":\n        return np.arcsin(a)\n    elif op_str == ""Atan"":\n        return np.arctan(a)\n    elif op_str == ""Ceiling"":\n        return np.ceil(a)\n    elif op_str == ""Cos"":\n        return np.cos(a)\n    elif op_str == ""Cosh"":\n        return np.cosh(a)\n    elif op_str == ""Floor"":\n        return np.floor(a)\n    elif op_str == ""log"":\n        return np.log(a)\n    elif op_str == ""exp"":\n        return np.exp(a)\n    elif op_str == ""negative"":\n        return np.negative(a)\n    elif op_str == ""Reverse"":\n        return np.fliplr(a)\n    elif op_str == ""Sign"":\n        return np.sign(a)\n    elif op_str == ""Sin"":\n        return np.sin(a)\n    elif op_str == ""Sinh"":\n        return np.sinh(a)\n    elif op_str == ""Sqrt"":\n        return np.sqrt(a)\n    elif op_str == ""Tan"":\n        return np.tan(a)\n    elif op_str == ""Tanh"":\n        return np.tanh(a)\n\n\ndef unary_op_exec(op_str, input_list):\n    """"""\n    input_list needs to have deep length of 4\n    """"""\n    element_type = Type.f32\n    shape = Shape(np.array(input_list).shape)\n    shape_np = np.array(input_list).shape\n    A = Parameter(element_type, shape)\n    parameter_list = [A]\n    function = Function([unary_op(op_str, A)], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, shape)\n    result = backend.create_tensor(element_type, shape)\n\n    a.write(util.numpy_to_c(np.array(input_list, dtype=np.float32)), 16)\n\n    result_arr = np.zeros(shape_np, dtype=np.float32)\n    result.write(util.numpy_to_c(result_arr), 16)\n    handle = backend.compile(function)\n    handle.call([result], [a])\n    result.read(util.numpy_to_c(result_arr), 16)\n\n    a_arr = np.array(input_list, dtype=np.float32)\n    result_arr_ref = unary_op_ref(op_str, a_arr)\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_abs():\n    input_list = [-1, 0, 1, 2]\n    op_str = ""Abs""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_acos():\n    input_list = [-1, 0, 0.5, 1]\n    op_str = ""Acos""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_asin():\n    input_list = [-1, 0, 0.5, 1]\n    op_str = ""Asin""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_atan():\n    input_list = [-1, 0, 0.5, 1]\n    op_str = ""Atan""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_ceiling():\n    input_list = [0.5, 0, 0.4, 0.5]\n    op_str = ""Ceiling""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_cos():\n    input_list = [0, 0.7, 1.7, 3.4]\n    op_str = ""Cos""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_cosh():\n    input_list = [-1, 0.0, 0.5, 1]\n    op_str = ""Cosh""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_floor():\n    input_list = [-0.5, 0, 0.4, 0.5]\n    op_str = ""Floor""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_log():\n    input_list = [1, 2, 3, 4]\n    op_str = ""log""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_exp():\n    input_list = [-1, 0, 1, 2]\n    op_str = ""exp""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_negative():\n    input_list = [-1, 0, 1, 2]\n    op_str = ""negative""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_sign():\n    input_list = [-1, 0, 0.5, 1]\n    op_str = ""Sign""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_sin():\n    input_list = [0, 0.7, 1.7, 3.4]\n    op_str = ""Sin""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_sinh():\n    input_list = [-1, 0.0, 0.5, 1]\n    op_str = ""Sinh""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_sqrt():\n    input_list = [0.0, 0.5, 1, 2]\n    op_str = ""Sqrt""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_tan():\n    input_list = [-np.pi / 4, 0, np.pi / 8, np.pi / 8]\n    op_str = ""Tan""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_tanh():\n    input_list = [-1, 0, 0.5, 1]\n    op_str = ""Tanh""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_reverse():\n    input_list = [[-1, 0], [0.5, 1]]\n    op_str = ""Reverse""\n    unary_op_exec(op_str, input_list)\n\n\ndef test_reshape():\n\n    element_type = Type.f32\n    shape = Shape([2, 3])\n    A = Parameter(element_type, shape)\n    parameter_list = [A]\n    function = Function([ng.reshape(A, Shape([3, 2]), special_zero=False)], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, shape)\n    result = backend.create_tensor(element_type, Shape([3, 2]))\n\n    a.write(util.numpy_to_c(np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)), 24)\n\n    result_arr = np.array([[0, 0], [0, 0], [0, 0]], dtype=np.float32)\n    result.write(util.numpy_to_c(result_arr), 24)\n    handle = backend.compile(function)\n    handle.call([result], [a])\n    result.read(util.numpy_to_c(result_arr), 24)\n\n    a_arr = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n    result_arr_ref = np.reshape(a_arr, (3, 2))\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_broadcast():\n\n    element_type = Type.f32\n    A = Parameter(element_type, Shape([3]))\n    parameter_list = [A]\n    function = Function([ng.broadcast(A, [3, 3])], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, Shape([3]))\n    result = backend.create_tensor(element_type, Shape([3, 3]))\n\n    a.write(util.numpy_to_c(np.array([1, 2, 3], dtype=np.float32)), 12)\n\n    result_arr = np.zeros((3, 3), dtype=np.float32)\n    result.write(util.numpy_to_c(result_arr), 36)\n    handle = backend.compile(function)\n    handle.call([result], [a])\n    result.read(util.numpy_to_c(result_arr), 36)\n\n    a_arr = np.array([[0], [0], [0]], dtype=np.float32)\n    b_arr = np.array([[1, 2, 3]], dtype=np.float32)\n    result_arr_ref = np.add(a_arr, b_arr)\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_constant():\n\n    element_type = Type.f32\n    parameter_list = []\n    function = Function(\n        [Constant(element_type, Shape([3, 3]), list(range(9)))], parameter_list, ""test""\n    )\n    backend = Backend.create(test.BACKEND_NAME)\n\n    result = backend.create_tensor(element_type, Shape([3, 3]))\n\n    result_arr = np.zeros((3, 3), dtype=np.float32)\n    result.write(util.numpy_to_c(result_arr), 36)\n    handle = backend.compile(function)\n    handle.call([result], [])\n    result.read(util.numpy_to_c(result_arr), 36)\n\n    result_arr_ref = np.arange(9).reshape(3, 3)\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_concat():\n\n    element_type = Type.f32\n    A = Parameter(element_type, Shape([1, 2]))\n    B = Parameter(element_type, Shape([1, 2]))\n    C = Parameter(element_type, Shape([1, 2]))\n    parameter_list = [A, B, C]\n    axis = 0\n    function = Function([ng.concat([A, B, C], axis)], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, Shape([1, 2]))\n    b = backend.create_tensor(element_type, Shape([1, 2]))\n    c = backend.create_tensor(element_type, Shape([1, 2]))\n    result = backend.create_tensor(element_type, Shape([3, 2]))\n\n    a.write(util.numpy_to_c(np.array([1, 2], dtype=np.float32)), 8)\n    b.write(util.numpy_to_c(np.array([5, 6], dtype=np.float32)), 8)\n    c.write(util.numpy_to_c(np.array([7, 8], dtype=np.float32)), 8)\n\n    result_arr = np.zeros(6, dtype=np.float32).reshape(3, 2)\n    result.write(util.numpy_to_c(result_arr), 24)\n    handle = backend.compile(function)\n    handle.call([result], [a, b, c])\n    result.read(util.numpy_to_c(result_arr), 24)\n\n    a_arr = np.array([[1, 2]], dtype=np.float32)\n    b_arr = np.array([[5, 6]], dtype=np.float32)\n    c_arr = np.array([[7, 8]], dtype=np.float32)\n    result_arr_ref = np.concatenate((a_arr, b_arr, c_arr), axis)\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_axisset():\n\n    set_axisset = AxisSet({1, 2, 3})\n    list_axisset = AxisSet([1, 2, 3])\n    tuple_axisset = AxisSet((1, 2, 3))\n\n    assert len(set_axisset) == 3\n    assert set(set_axisset) == {1, 2, 3}\n\n    assert len(list_axisset) == 3\n    assert set(list_axisset) == set(set_axisset)\n\n    assert len(tuple_axisset) == 3\n    assert set(tuple_axisset) == set(set_axisset)\n\n\ndef test_select():\n\n    element_type = Type.f32\n    A = Parameter(Type.boolean, Shape([1, 2]))\n    B = Parameter(element_type, Shape([1, 2]))\n    C = Parameter(element_type, Shape([1, 2]))\n    parameter_list = [A, B, C]\n\n    function = Function([ng.select(A, B, C)], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(Type.boolean, Shape([1, 2]))\n    b = backend.create_tensor(element_type, Shape([1, 2]))\n    c = backend.create_tensor(element_type, Shape([1, 2]))\n    result = backend.create_tensor(element_type, Shape([1, 2]))\n\n    a.write(util.numpy_to_c(np.array([[True, False]], dtype=np.bool)), 2)\n    b.write(util.numpy_to_c(np.array([[5, 6]], dtype=np.float32)), 8)\n    c.write(util.numpy_to_c(np.array([[7, 8]], dtype=np.float32)), 8)\n\n    result_arr = np.array([[0, 0]], dtype=np.float32)\n    result.write(util.numpy_to_c(result_arr), 8)\n    handle = backend.compile(function)\n    handle.call([result], [a, b, c])\n    result.read(util.numpy_to_c(result_arr), 8)\n\n    result_arr_ref = np.array([[5, 8]])\n\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_max_pool():\n    # test 1d\n    element_type = Type.f32\n    shape = Shape([1, 1, 10])\n    A = Parameter(element_type, shape)\n    parameter_list = [A]\n\n    input_arr = np.arange(10, dtype=np.float32).reshape(1, 1, 10)\n    window_shape = [3]\n\n    strides = [1] * len(window_shape)\n    pads_begin = [0] * len(window_shape)\n    pads_end = [0] * len(window_shape)\n\n    model = ng.max_pool(A, strides, pads_begin, pads_end, window_shape)\n    function = Function([model], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, shape)\n    result = backend.create_tensor(element_type, Shape([1, 1, 8]))\n\n    a.write(util.numpy_to_c(input_arr), 10 * 4)\n\n    result_arr = np.zeros(8, dtype=np.float32).reshape(1, 1, 8)\n    result.write(util.numpy_to_c(result_arr), 8 * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a])\n    result.read(util.numpy_to_c(result_arr), 32)\n\n    result_arr_ref = (np.arange(8) + 2).reshape(1, 1, 8)\n    assert np.allclose(result_arr, result_arr_ref)\n\n    # test 1d with strides\n    strides = [2]\n    pads_begin = [0] * len(window_shape)\n    pads_end = [0] * len(window_shape)\n\n    model = ng.max_pool(A, strides, pads_begin, pads_end, window_shape)\n    function = Function([model], parameter_list, ""test"")\n\n    size = 4\n    result = backend.create_tensor(element_type, Shape([1, 1, size]))\n    result_arr = np.zeros(size, dtype=np.float32).reshape(1, 1, size)\n\n    backend = Backend.create(test.BACKEND_NAME)\n    result.write(util.numpy_to_c(result_arr), size * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a])\n    result.read(util.numpy_to_c(result_arr), size * 4)\n\n    result_arr_ref = ((np.arange(size) + 1) * 2).reshape(1, 1, size)\n    assert np.allclose(result_arr, result_arr_ref)\n\n    # test 2d\n    element_type = Type.f32\n    shape = Shape([1, 1, 10, 10])\n    A = Parameter(element_type, shape)\n    parameter_list = [A]\n\n    input_arr = np.arange(100, dtype=np.float32).reshape(1, 1, 10, 10)\n    window_shape = [3, 3]\n\n    strides = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n\n    model = ng.max_pool(A, strides, pads_begin, pads_end, window_shape)\n    function = Function([model], parameter_list, ""test"")\n\n    backend = Backend.create(test.BACKEND_NAME)\n    a = backend.create_tensor(element_type, shape)\n    result = backend.create_tensor(element_type, Shape([1, 1, 8, 8]))\n\n    a.write(util.numpy_to_c(input_arr), 10 * 10 * 4)\n\n    result_arr = np.zeros(64, dtype=np.float32).reshape(1, 1, 8, 8)\n    result.write(util.numpy_to_c(result_arr), 8 * 8 * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a])\n    result.read(util.numpy_to_c(result_arr), 8 * 8 * 4)\n\n    result_arr_ref = ((np.arange(100).reshape(10, 10))[2:, 2:]).reshape(1, 1, 8, 8)\n    assert np.allclose(result_arr, result_arr_ref)\n\n    # test 2d with strides\n    strides = [2, 2]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n\n    model = ng.max_pool(A, strides, pads_begin, pads_end, window_shape)\n    function = Function([model], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    size = 4\n    result = backend.create_tensor(element_type, Shape([1, 1, size, size]))\n    result_arr = np.zeros(size * size, dtype=np.float32).reshape(1, 1, size, size)\n\n    result.write(util.numpy_to_c(result_arr), size * size * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a])\n    result.read(util.numpy_to_c(result_arr), size * size * 4)\n\n    result_arr_ref = ((np.arange(100).reshape(10, 10))[2::2, 2::2]).reshape(1, 1, size, size)\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef convolution2d(\n    image,\n    filterit,\n    strides=(1, 1),\n    dilation=(1, 1),\n    padding_below=(0, 0),\n    padding_above=(0, 0),\n    data_dilation=(1, 1),\n):\n    def dilate(arr, dil=(1, 1)):\n        m, n = arr.shape\n        new_m, new_n = (m - 1) * dil[0] + 1, (n - 1) * dil[1] + 1\n        new_arr = np.zeros(new_m * new_n, dtype=np.float32).reshape(new_m, new_n)\n        for i in range(m):\n            for j in range(n):\n                new_arr[dil[0] * i][dil[1] * j] = arr[i][j]\n        return new_arr\n\n    i_m, i_n = image.shape\n    new_image = np.zeros(\n        (i_m + padding_below[0] + padding_above[0]) * (i_n + padding_below[1] + padding_above[1]),\n        dtype=np.float32,\n    ).reshape(i_m + padding_below[0] + padding_above[0], i_n + padding_below[1] + padding_above[1])\n    new_image[\n        padding_below[0] : padding_below[0] + i_m, padding_below[1] : padding_below[1] + i_n\n    ] = image\n    image = new_image\n    image = image if data_dilation[0] == data_dilation[1] == 1 else dilate(image, data_dilation)\n    i_m, i_n = image.shape\n\n    filterit = filterit if dilation[0] == dilation[1] == 1 else dilate(filterit, dilation)\n    f_m, f_n = filterit.shape\n\n    # result_shape\n    r_m = i_m - f_m + 1\n    r_n = i_n - f_n + 1\n    r_m //= strides[0]\n    r_n //= strides[1]\n\n    result = np.zeros(r_m * r_n, dtype=np.float32).reshape(r_m, r_n)\n\n    for i in range(r_m):\n        for j in range(r_n):\n            sub_m = image[\n                i * strides[0] : i * strides[0] + f_m, j * strides[1] : j * strides[1] + f_n\n            ]\n            result[i][j] = np.sum(sub_m * filterit)\n    return result\n\n\ndef test_convolution_simple():\n\n    element_type = Type.f32\n    image_shape = Shape([1, 1, 16, 16])\n    filter_shape = Shape([1, 1, 3, 3])\n    data = Parameter(element_type, image_shape)\n    filters = Parameter(element_type, filter_shape)\n    parameter_list = [data, filters]\n\n    image_arr = np.arange(-128, 128, 1, dtype=np.float32).reshape(1, 1, 16, 16)\n    filter_arr = np.ones(9, dtype=np.float32).reshape(1, 1, 3, 3)\n    filter_arr[0][0][0][0] = -1\n    filter_arr[0][0][1][1] = -1\n    filter_arr[0][0][2][2] = -1\n    filter_arr[0][0][0][2] = -1\n    filter_arr[0][0][2][0] = -1\n    result_arr = np.zeros(196, dtype=np.float32).reshape(1, 1, 14, 14)\n\n    strides = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    dilations = [1, 1]\n\n    model = ng.convolution(data, filters, strides, pads_begin, pads_end, dilations)\n    function = Function([model], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, image_shape)\n    b = backend.create_tensor(element_type, filter_shape)\n\n    a.write(util.numpy_to_c(image_arr), 16 * 16 * 4)\n    b.write(util.numpy_to_c(filter_arr), 3 * 3 * 4)\n\n    result = backend.create_tensor(element_type, Shape([1, 1, 14, 14]))\n    result.write(util.numpy_to_c(result_arr), 14 * 14 * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a, b])\n    result.read(util.numpy_to_c(result_arr), 14 * 14 * 4)\n\n    result_arr_ref = convolution2d(image_arr[0][0], filter_arr[0][0]).reshape(1, 1, 14, 14)\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_convolution_with_strides():\n\n    element_type = Type.f32\n    image_shape = Shape([1, 1, 10, 10])\n    filter_shape = Shape([1, 1, 3, 3])\n    data = Parameter(element_type, image_shape)\n    filters = Parameter(element_type, filter_shape)\n    parameter_list = [data, filters]\n\n    image_arr = np.arange(100, dtype=np.float32).reshape(1, 1, 10, 10)\n    filter_arr = np.zeros(9, dtype=np.float32).reshape(1, 1, 3, 3)\n    filter_arr[0][0][1][1] = 1\n    strides = [2, 2]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    dilations = [1, 1]\n\n    model = ng.convolution(data, filters, strides, pads_begin, pads_end, dilations)\n    function = Function([model], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, image_shape)\n    b = backend.create_tensor(element_type, filter_shape)\n\n    a.write(util.numpy_to_c(image_arr), 10 * 10 * 4)\n    b.write(util.numpy_to_c(filter_arr), 3 * 3 * 4)\n\n    result_arr = np.zeros(16, dtype=np.float32).reshape(1, 1, 4, 4)\n    result = backend.create_tensor(element_type, Shape([1, 1, 4, 4]))\n    result.write(util.numpy_to_c(result_arr), 4 * 4 * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a, b])\n\n    result.read(util.numpy_to_c(result_arr), 4 * 4 * 4)\n    result_arr_ref = convolution2d(image_arr[0][0], filter_arr[0][0], strides).reshape(1, 1, 4, 4)\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_convolution_with_filter_dilation():\n\n    element_type = Type.f32\n    image_shape = Shape([1, 1, 10, 10])\n    filter_shape = Shape([1, 1, 3, 3])\n    data = Parameter(element_type, image_shape)\n    filters = Parameter(element_type, filter_shape)\n    parameter_list = [data, filters]\n\n    image_arr = np.arange(100, dtype=np.float32).reshape(1, 1, 10, 10)\n    filter_arr = np.ones(9, dtype=np.float32).reshape(1, 1, 3, 3)\n    strides = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    dilations = [2, 2]\n\n    model = ng.convolution(data, filters, strides, pads_begin, pads_end, dilations)\n    function = Function([model], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, image_shape)\n    b = backend.create_tensor(element_type, filter_shape)\n\n    a.write(util.numpy_to_c(image_arr), 10 * 10 * 4)\n    b.write(util.numpy_to_c(filter_arr), 3 * 3 * 4)\n\n    result_arr = np.zeros(36, dtype=np.float32).reshape(1, 1, 6, 6)\n    result = backend.create_tensor(element_type, Shape([1, 1, 6, 6]))\n    result.write(util.numpy_to_c(result_arr), 6 * 6 * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a, b])\n\n    result.read(util.numpy_to_c(result_arr), 6 * 6 * 4)\n    result_arr_ref = convolution2d(image_arr[0][0], filter_arr[0][0], strides, dilations).reshape(\n        1, 1, 6, 6\n    )\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_convolution_with_padding():\n\n    element_type = Type.f32\n    image_shape = Shape([1, 1, 10, 10])\n    filter_shape = Shape([1, 1, 3, 3])\n    data = Parameter(element_type, image_shape)\n    filters = Parameter(element_type, filter_shape)\n    parameter_list = [data, filters]\n\n    image_arr = np.arange(100, dtype=np.float32).reshape(1, 1, 10, 10)\n    filter_arr = np.zeros(9, dtype=np.float32).reshape(1, 1, 3, 3)\n    filter_arr[0][0][1][1] = 1\n    strides = [1, 1]\n    dilations = [2, 2]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n\n    model = ng.convolution(data, filters, strides, pads_begin, pads_end, dilations)\n    function = Function([model], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, image_shape)\n    b = backend.create_tensor(element_type, filter_shape)\n\n    a.write(util.numpy_to_c(image_arr), 10 * 10 * 4)\n    b.write(util.numpy_to_c(filter_arr), 3 * 3 * 4)\n\n    result_arr = np.zeros(36, dtype=np.float32).reshape(1, 1, 6, 6)\n    result = backend.create_tensor(element_type, Shape([1, 1, 6, 6]))\n    result.write(util.numpy_to_c(result_arr), 6 * 6 * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a, b])\n\n    result.read(util.numpy_to_c(result_arr), 6 * 6 * 4)\n    result_arr_ref = convolution2d(\n        image_arr[0][0], filter_arr[0][0], strides, dilations, pads_begin, pads_end\n    ).reshape(1, 1, 6, 6)\n    assert np.allclose(result_arr, result_arr_ref)\n\n\ndef test_convolution_with_non_zero_padding():\n    element_type = Type.f32\n    image_shape = Shape([1, 1, 10, 10])\n    filter_shape = Shape([1, 1, 3, 3])\n    data = Parameter(element_type, image_shape)\n    filters = Parameter(element_type, filter_shape)\n    parameter_list = [data, filters]\n\n    image_arr = np.arange(100, dtype=np.float32).reshape(1, 1, 10, 10)\n    filter_arr = (np.ones(9, dtype=np.float32).reshape(1, 1, 3, 3)) * -1\n    filter_arr[0][0][1][1] = 1\n    strides = [1, 1]\n    dilations = [2, 2]\n    pads_begin = [2, 1]\n    pads_end = [1, 2]\n\n    model = ng.convolution(data, filters, strides, pads_begin, pads_end, dilations)\n    function = Function([model], parameter_list, ""test"")\n    backend = Backend.create(test.BACKEND_NAME)\n\n    a = backend.create_tensor(element_type, image_shape)\n    b = backend.create_tensor(element_type, filter_shape)\n\n    a.write(util.numpy_to_c(image_arr), 10 * 10 * 4)\n    b.write(util.numpy_to_c(filter_arr), 3 * 3 * 4)\n\n    result_arr = np.zeros(81, dtype=np.float32).reshape(1, 1, 9, 9)\n    result = backend.create_tensor(element_type, Shape([1, 1, 9, 9]))\n    result.write(util.numpy_to_c(result_arr), 9 * 9 * 4)\n    handle = backend.compile(function)\n    handle.call([result], [a, b])\n\n    result.read(util.numpy_to_c(result_arr), 9 * 9 * 4)\n    result_arr_ref = convolution2d(\n        image_arr[0][0], filter_arr[0][0], strides, dilations, pads_begin, pads_end\n    ).reshape(1, 1, 9, 9)\n    assert np.allclose(result_arr, result_arr_ref)\n'"
test/mlir/lit.cfg.py,0,"b'#*****************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#*****************************************************************************\n""""""Lit runner configuration.""""""\n\nimport lit.formats\nfrom lit.llvm import llvm_config\nfrom lit.llvm.subst import ToolSubst\n\n# name: The name of this test suite.\nconfig.name = \'nGraph MLIR Compiler\'\n\nconfig.test_format = lit.formats.ShTest(not llvm_config.use_lit_shell)\n\n# test_source_root: The root path where tests are located.\nconfig.test_source_root = config.ngraph_mlir_test_src_dir\n\n# test_exec_root: The root path where tests should be run.\nconfig.test_exec_root = config.ngraph_mlir_test_build_dir\n\nllvm_config.use_default_substitutions()\n\n# Tweak the PATH to include the tools dir.\nllvm_config.with_environment(\'PATH\', config.llvm_tools_dir, append_path=True)\n\ntool_dirs = [\n    config.ngraph_mlir_tools_dir, config.mlir_tools_dir, config.llvm_tools_dir\n]\ntool_names = [\n    \'ngraph-opt\', \'mlir-opt\', \'mlir-translate\'\n]\ntools = [ToolSubst(s, unresolved=\'ignore\') for s in tool_names]\nllvm_config.add_tool_substitutions(tools, tool_dirs)\n'"
test/ref_generators/generate_convolution_ref.py,0,"b'#!/usr/bin/env python\n# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport sys\nimport numpy as np\nimport math\nimport random\nfrom operator import mul\n\n# Generates an array of random floating point literals of the given length, from a fixed seed.\n\n\ndef random_array_float_literals(length, seed=8086):\n    literals = []\n\n    random.seed(seed)\n\n    for i in range(0, length):\n        # generate numbers that can be exactly represented in binary\n        sig_bits = 6\n        range_bits = 2\n        literal_n = np.float32(random.randint(-pow(2, sig_bits-1),\n                                              pow(2, sig_bits-1))) / pow(2.0, sig_bits - range_bits)\n        literals.append(str(literal_n))\n\n    return literals\n\n# Elementwise addition on tuples.\n\n\ndef tuple_plus(t1, t2):\n    assert(len(t1) == len(t2))\n\n    res = ()\n\n    for (x, y) in zip(list(t1), list(t2)):\n        res = res + (x+y,)\n\n    return res\n\n# Elementwise multiplication on tuples.\n\n\ndef tuple_times(t1, t2):\n    assert(len(t1) == len(t2))\n\n    res = ()\n\n    for (x, y) in zip(list(t1), list(t2)):\n        res = res + (x*y,)\n\n    return res\n\n#\n# Convolution reference\n#\n#    Arguments:\n#    data_batch       : [N ][Ci][D1]...[Dn], n > 0\n#    filter           : [Co][Ci][W1]...[Wn]\n#    move_strides     = (s1,...,sn)\n#    filter_dilation  = (l1,...,ln)\n#    below_pads       = (p1,...,pn)\n#    above_pads       = (q1,...,qn)\n#    data_dilation    = (t1,...,tn)\n#\n#    Returns:\n#    output_batch     : [N ][Co][D\'1]...[D\'n]\n#\n# Where the D\'s are computed according to TensorFlow-style ""valid"" convolution rules, but *after* padding.\n# See https://www.tensorflow.org/api_docs/python/tf/nn/convolution.\n#\n\n\ndef convolution_ref(data_batch, filter, move_strides, filter_dilation, below_pads, above_pads, data_dilation):\n    assert(len(data_batch.shape) == len(filter.shape))\n    assert(len(data_batch.shape) > 2)\n    assert(len(data_batch.shape) <= 6)\n    assert(data_batch.shape[1] == filter.shape[1])\n    assert(len(move_strides) == len(data_batch.shape) - 2)\n    assert(len(filter_dilation) == len(data_batch.shape) - 2)\n    assert(len(data_dilation) == len(data_batch.shape) - 2)\n\n    # dilate the input batch\n    new_item_shape = (np.array(data_batch.shape[2:]) - 1) * data_dilation + 1\n    new_data_batch_shape = list(\n        np.array(data_batch.shape[:2])) + list(new_item_shape)\n    new_data_batch = np.zeros(new_data_batch_shape)\n\n    for n in range(0, new_data_batch_shape[0]):\n        for c in range(0, new_data_batch_shape[1]):\n            if new_data_batch.ndim == 3:\n                new_data_batch[n, c, 0::data_dilation[0]] = data_batch[n][c]\n            elif new_data_batch.ndim == 4:\n                new_data_batch[n, c, 0::data_dilation[0],\n                               0::data_dilation[1]] = data_batch[n][c]\n            elif new_data_batch.ndim == 5:\n                new_data_batch[n, c, 0::data_dilation[0],\n                               0::data_dilation[1], 0::data_dilation[2]] = data_batch[n][c]\n            elif new_data_batch.ndim == 6:\n                new_data_batch[n, c, 0::data_dilation[0], 0::data_dilation[1],\n                               0::data_dilation[2], 0::data_dilation[3]] = data_batch[n][c]\n            else:\n                assert(False)\n\n    data_batch = new_data_batch\n\n    # Pad the input batch wherever the pads are positive.\n    # Have to add values for the spatial and channel dims.\n    below_pads_pos = (0, 0) + tuple(np.clip(below_pads, 0, None))\n    # Have to add values for the spatial and channel dims.\n    above_pads_pos = (0, 0) + tuple(np.clip(above_pads, 0, None))\n    data_batch = np.pad(data_batch, list(\n        zip(below_pads_pos, above_pads_pos)), mode=\'constant\', constant_values=0)\n\n    # Slice the input batch wherever the pads are negative.\n    slice_bottoms = (0, 0) + tuple(-np.clip(below_pads, None, 0))\n    slice_tops = (0, 0) + tuple(np.clip(above_pads, None, 0))\n    slices = list(map(lambda p: slice(\n        p[0], p[1] if p[1] < 0 else None), zip(slice_bottoms, slice_tops)))\n    data_batch = data_batch[tuple(slices)]\n\n    item_count = data_batch.shape[0]               # N\n    ci_count = data_batch.shape[1]                 # Ci\n    co_count = filter.shape[0]                     # Co\n    input_item_shape = list(data_batch.shape[2:])  # D1, ..., Dn\n    window_virtual_shape = list(filter.shape[2:])  # W1, ..., Wn\n\n    # This is not used in computation but we will calculate it for a check to make sure the window fits.\n    window_physical_shape = []\n    for (d_in, d_virt, dil) in zip(input_item_shape, window_virtual_shape, filter_dilation):\n        d_phys = (d_virt - 1) * dil + 1\n        assert(d_phys <= d_in)\n        window_physical_shape.append(d_phys)\n\n    output_item_shape = []  # D\'1,...,D\'n\n    for (d_in, d_win, dil, mov) in zip(input_item_shape, window_virtual_shape, filter_dilation, move_strides):\n        # Formula is taken from TF\'s definition for VALID convolution.\n        d_out = int(\n            math.ceil((float(d_in) - (float(d_win) - 1.0) * float(dil))/float(mov)))\n        assert(d_out > 0)\n        output_item_shape.append(d_out)\n\n    output_shape = [item_count, co_count]+output_item_shape  # N,Co,D\'1,...,D\'n\n    output_batch = np.zeros(output_shape)\n\n    # Walk over the output batch space.\n    output_it = np.nditer(output_batch, flags=[\'multi_index\'])\n    while not output_it.finished:\n        # Break up the output coordinate to figure out where we are in terms of batch index, output channel, and spatial position.\n        output_index = output_it.multi_index\n        item, co, output_pos = output_index[0], output_index[1], output_index[2:]\n\n        # Walk over the filter for the current output channel.\n        filter_it = np.nditer(filter[co], flags=[\'multi_index\'])\n        while not filter_it.finished:\n            # Break up the filter coordinate to figure out where we are in terms of input channel and filter shape position.\n            filter_index = filter_it.multi_index\n            ci, filter_pos = filter_index[0], filter_index[1:]\n\n            # Build up the coordinate within the space N,Ci,D1,...,Dn that we need to read from in the input batch.\n            input_index = (item, ci) + (tuple_plus(tuple_times(output_pos,\n                                                               move_strides), tuple_times(filter_pos, filter_dilation)))\n\n            # Add to the sum-of-products.\n            output_batch[output_index] = output_batch[output_index] + \\\n                filter[(co,) + filter_index] * data_batch[input_index]\n\n            filter_it.iternext()\n\n        output_it.iternext()\n\n    return output_batch\n\n\ndef shape_str(shape):\n    result = \'\'\n    first = True\n    for d in shape:\n        if first:\n            result = (\'%d\' % d)\n            first = False\n        else:\n            result = result + (\',%d\' % d)\n    return result\n\n\ndef scalar_str(x):\n    result = (\'%.1000g\' % x)\n    # This next part is a bit stupid.\n    if ""."" not in result and ""e"" not in result:\n        result = result + "".0f""\n    else:\n        result = ""%.8ff"" % float(result)\n    return result\n\n\ndef data_str(data):\n    result = \'\'\n    first = True\n    for x in np.nditer(data):\n        if first:\n            result = scalar_str(x)\n            first = False\n        else:\n            result = result + \',\' + scalar_str(x)\n    return result\n\n\ndef shape_size(shape):\n    result = 1\n    for l in shape:\n        result = result * l\n    return result\n\n\ndef emit_test(t, f):\n    test_name, input_batch_shape, filters_shape, move_strides, filter_dilation, below_pads, above_pads, data_dilation, bprop = t\n\n    input_batch_literals = random_array_float_literals(\n        shape_size(input_batch_shape))\n    filters_literals = random_array_float_literals(shape_size(filters_shape))\n    input_batch_array = np.array(\n        list(map(lambda s: np.float32(s), input_batch_literals)))\n    input_batch_array.shape = input_batch_shape\n    filters_array = np.array(\n        list(map(lambda s: np.float32(s), filters_literals)))\n    filters_array.shape = filters_shape\n\n    print(""Generating convolution test \'%s\'..."" % test_name)\n\n    output_batch_data = convolution_ref(\n        input_batch_array, filters_array, move_strides, filter_dilation, below_pads, above_pads, data_dilation)\n\n    template = \'\'\'\n// !!!!!!!!!!!!!! THIS FILE IS AUTOGENERATED OUTSIDE OF THE BUILD PROCESS !!!!!!!!!!!!!!\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DO NOT EDIT THIS FILE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n//\n// DO NOT EDIT THIS FILE. If you want to add new tests, you should edit\n//  test/ref_generators/generate_convolution_ref.py and regenerate this file.\n//\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DO NOT EDIT THIS FILE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n// !!!!!!!!!!!!!! THIS FILE IS AUTOGENERATED OUTSIDE OF THE BUILD PROCESS !!!!!!!!!!!!!!\nNGRAPH_TEST (${BACKEND_NAME}, %s)\n{\n    Shape shape_a{%s};\n    Shape shape_b{%s};\n    Shape shape_r{%s};\n    auto make_graph = [shape_a, shape_b] {\n        auto A = make_shared<op::Parameter>(element::f32, shape_a);\n        auto B = make_shared<op::Parameter>(element::f32, shape_b);\n        return make_shared<Function>(make_shared<op::Convolution>(A, B,\n                                                                  Strides{%s},        // move_strides\n                                                                  Strides{%s},        // filter_dilation\n                                                                  CoordinateDiff{%s}, // below_pads\n                                                                  CoordinateDiff{%s}, // above_pads\n                                                                  Strides{%s}),       // data_dilation\n                                     ParameterVector{A, B});\n    };\n\n    auto backend = runtime::Backend::create(""${BACKEND_NAME}"");\n    auto function = make_graph();\n\n    // Create some tensors for input/output\n    auto a = backend->create_tensor(element::f32, shape_a);\n    copy_data(a, vector<float>{%s});\n    auto b = backend->create_tensor(element::f32, shape_b);\n    copy_data(b, vector<float>{%s});\n    auto result = backend->create_tensor(element::f32, shape_r);\n\n    vector<float> expected_result{%s};\n\n    auto handle = backend->compile(function);\n    handle->call_with_validate({result}, {a, b});\n    EXPECT_TRUE(test::all_close_f(vector<float>{expected_result}, read_vector<float>(result), tolerance));\n    // only test backprop for certain cases as it takes significant compute resources\n    %sEXPECT_TRUE(autodiff_numeric_compare<float>(backend.get(), make_graph, {a, b}, .01f, .01f));\n}\n\'\'\'\n    f.write(template % (test_name,\n                        shape_str(input_batch_shape),\n                        shape_str(filters_shape),\n                        shape_str(output_batch_data.shape),\n                        shape_str(move_strides),\n                        shape_str(filter_dilation),\n                        shape_str(below_pads),\n                        shape_str(above_pads),\n                        shape_str(data_dilation),\n                        "","".join(map(lambda s: ""%.8ff"" %\n                                     float(s), input_batch_literals)),\n                        "","".join(map(lambda s: ""%.8ff"" %\n                                     float(s), filters_literals)),\n                        data_str(output_batch_data),\n                        bprop))\n\n\n#                                                                              filter                                      data\n#         test name                                skip list   i             batch shape   filts shape   stride    dilation  below-pads  above-pads  dilation   bprop?\ntests = [\n    (""convolution_2d_1item"",                  (1, 1, 3, 5),    (2, 1, 2, 2),\n     (1, 1),    (1, 1),    (0, 0),      (0, 0),      (1, 1),     """"),\n    (""convolution_2d_1item_padded_1_1x1_1"",   (1, 1, 3, 5),    (2, 1, 2, 2),\n     (1, 1),    (1, 1),    (1, 1),      (1, 1),      (1, 1),     """"),\n    (""convolution_2d_1item_padded_2_3x4_5"",   (1, 1, 3, 5),    (2, 1, 2, 2),\n     (1, 1),    (1, 1),    (2, 3),      (4, 5),      (1, 1),     """"),\n    (""convolution_2d_2items"",                 (2, 1, 3, 5),    (2, 1, 2, 2),\n     (1, 1),    (1, 1),    (0, 0),      (0, 0),      (1, 1),     """"),\n    (""convolution_2d_2items_strided"",         (2, 1, 3, 5),    (2, 1, 2, 2),\n     (2, 2),    (1, 1),    (0, 0),      (0, 0),      (1, 1),     """"),\n    (""convolution_2d_2items_strided_padded"",  (2, 1, 3, 5),    (2, 1, 2, 2),\n     (2, 2),    (1, 1),    (4, 2),      (5, 7),      (1, 1),     """"),\n    (""convolution_2d_2items_strided_padded_same"", (2, 1, 3, 5), (2, 1, 2, 2),\n     (2, 2),    (1, 1),    (2, 2),      (2, 2),      (1, 1),     """"),\n    (""convolution_2d_2items_dilated"",         (2, 1, 3, 5),    (2, 1, 2, 2),\n     (1, 1),    (2, 2),    (0, 0),      (0, 0),      (1, 1),     """"),\n    (""convolution_2d_2items_dilated_padded"",  (2, 1, 3, 5),    (2, 1, 2, 2),\n     (1, 1),    (2, 2),    (4, 2),      (5, 7),      (1, 1),     """"),\n    (""convolution_3d_2items"",                 (2, 1, 3, 5, 8),  (2, 1, 2, 2, 3),\n     (1, 1, 1),  (1, 1, 1),  (0, 0, 0),    (0, 0, 0),    (1, 1, 1),   """"),\n    (""convolution_4d_2items"",                 (2, 1, 3, 5, 8, 7), (2, 1, 2, 2, 3, 1),\n     (1, 1, 1, 1), (1, 1, 1, 1), (0, 0, 0, 0),  (0, 0, 0, 0),  (1, 1, 1, 1), ""// ""),\n    (""convolution_4d_4items"",                 (4, 3, 3, 5, 8, 7), (4, 3, 2, 2, 3, 1),\n     (1, 1, 1, 1), (1, 1, 1, 1), (0, 0, 0, 0),  (0, 0, 0, 0),  (1, 1, 1, 1), ""// ""),\n    (""convolution_4d_4items_padded_neg"",      (4, 3, 3, 5, 8, 7), (4, 3, 2, 2, 3, 1),\n     (1, 1, 1, 1), (1, 1, 1, 1), (-1, 2, -3, 2), (1, 0, 0, -3), (1, 1, 1, 1), ""// ""),\n    (""convolution_4d_4items_strided"",         (4, 3, 3, 5, 8, 7), (4, 3, 2, 2, 3, 1),\n     (2, 1, 3, 2), (1, 1, 1, 1), (0, 0, 0, 0),  (0, 0, 0, 0),  (1, 1, 1, 1), ""// ""),\n    (""convolution_4d_4items_dilated"",         (4, 3, 3, 5, 8, 7), (4, 3, 2, 2, 3, 1),\n     (1, 1, 1, 1), (2, 1, 3, 2), (0, 0, 0, 0),  (0, 0, 0, 0),  (1, 1, 1, 1), ""// ""),\n    (""convolution_4d_4items_strided_dilated"", (4, 3, 8, 8, 8, 8), (4, 3, 2, 2, 3, 1),\n     (3, 2, 2, 3), (2, 1, 3, 2), (0, 0, 0, 0),  (0, 0, 0, 0),  (1, 1, 1, 1), ""// ""),\n    (""convolution_4d_4items_strided_dilated_padded"",\n     (4, 3, 8, 8, 8, 8), (4, 3, 2, 2, 3, 1), (3, 2, 2, 3), (2, 1, 3, 2), (2, 4, 6, 8),  (1, 3, 5, 7),  (1, 1, 1, 1), ""// ""),\n    (""convolution_4d_4items_strided_dilated_padded_neg"",\n     (4, 3, 8, 8, 8, 8), (4, 3, 2, 2, 3, 1), (3, 2, 2, 3), (2, 1, 3, 2), (-2, 4, 0, 5), (1, 3, -1, -4), (1, 1, 1, 1), ""// ""),\n    (""convolution_4d_4items_strided_dilated_padded_same"",\n     (4, 3, 8, 8, 8, 8), (4, 3, 2, 2, 3, 1), (3, 2, 2, 3), (2, 1, 3, 2), (3, 3, 3, 3),  (3, 3, 3, 3),  (1, 1, 1, 1), ""// ""),\n    (""convolution_2d_1item_1o1i_data_dilated"", (1, 1, 3, 5),    (1, 1, 2, 2),\n     (1, 1),    (1, 1),    (0, 0),      (0, 0),      (2, 2),     """"),\n    (""convolution_2d_1item_2o1i_data_dilated"", (1, 1, 3, 5),    (2, 1, 2, 2),\n     (1, 1),    (1, 1),    (0, 0),      (0, 0),      (2, 2),     """"),\n    (""convolution_2d_1item_2o2i_data_dilated"", (1, 2, 3, 5),    (2, 2, 2, 2),\n     (1, 1),    (1, 1),    (0, 0),      (0, 0),      (2, 2),     """"),\n    (""convolution_2d_1item_5o3i_data_dilated"", (1, 3, 3, 5),    (5, 3, 2, 2),\n     (1, 1),    (1, 1),    (0, 0),      (0, 0),      (2, 2),     """"),\n    (""convolution_2d_2item_5o3i_data_dilated"", (2, 3, 3, 5),    (5, 3, 2, 2),\n     (1, 1),    (1, 1),    (0, 0),      (0, 0),      (2, 2),     """"),\n    (""convolution_2d_8item_large_5o3i_data_dilated"",\n     (8, 3, 16, 16),  (5, 3, 2, 2),    (1, 1),    (1, 1),    (0, 0),      (0, 0),      (2, 2),     ""// ""),\n    (""convolution_2d_8item_large_5o3i_uneven_filter_data_dilated"",\n     (8, 3, 16, 16),  (5, 3, 2, 3),    (1, 1),    (1, 1),    (0, 0),      (0, 0),      (2, 2),     ""// ""),\n    (""convolution_2d_8item_large_5o3i_uneven_filter_uneven_data_dilation_data_dilated"",\n     (8, 3, 16, 16),  (5, 3, 2, 3),    (1, 1),    (1, 1),    (0, 0),      (0, 0),      (2, 3),     ""// ""),\n    (""convolution_3d_2item_large_5o3i_uneven_filter_uneven_data_dilation_data_dilated"",\n     (2, 3, 8, 8, 8),  (5, 3, 2, 3, 4),  (1, 1, 1),  (1, 1, 1),  (0, 0, 0),    (0, 0, 0),    (2, 3, 2),   ""// ""),\n    (""convolution_3d_1item_large_5o3i_padded_uneven_filter_uneven_data_dilation_data_dilated"",\n     (1, 3, 8, 8, 8),  (5, 3, 2, 3, 4),  (1, 1, 1),  (1, 1, 1),  (2, 1, 2),    (1, 2, 3),    (2, 3, 2),   ""// ""),\n    (""convolution_3d_2item_large_5o3i_padded_strided_uneven_filter_uneven_data_dilation_data_dilated"",\n     (2, 3, 8, 8, 8),  (5, 3, 2, 3, 4),  (2, 3, 2),  (1, 1, 1),  (2, 1, 2),    (1, 2, 3),    (2, 3, 2),   ""// ""),\n    (""convolution_3d_2item_large_5o3i_padded_strided_uneven_filter_uneven_data_dilation_filter_dilated_data_dilated"",\n     (2, 3, 8, 8, 8),  (5, 3, 2, 3, 4),  (2, 3, 2),  (3, 2, 2),  (2, 1, 2),    (1, 2, 3),    (2, 3, 2),   ""// ""),\n]\n\ndef main():\n    assert(len(sys.argv) > 1)\n\n    f = open(sys.argv[1], \'w\')\n    f.write(\'\'\'//*****************************************************************************\n// Copyright 2017-2020 Intel Corporation\n//\n// Licensed under the Apache License, Version 2.0 (the ""License"");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an ""AS IS"" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n//*****************************************************************************\n\n// !!!!!!!!!!!!!! THIS FILE IS AUTOGENERATED OUTSIDE OF THE BUILD PROCESS !!!!!!!!!!!!!!\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DO NOT EDIT THIS FILE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n//\n// It takes quite a while to compute the results.\n//\n// DO NOT EDIT THIS FILE. If you want to add new tests, you should edit\n//  test/ref_generators/generate_convolution_ref.py and regenerate this file.\n//\n// To regenerate:\n//\n//   $ cd <ngraph source dir>/test\n//   $ ./update_convolution_reference.sh\n//\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DO NOT EDIT THIS FILE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n// !!!!!!!!!!!!!! THIS FILE IS AUTOGENERATED OUTSIDE OF THE BUILD PROCESS !!!!!!!!!!!!!!\n//\n// clang-format off\n\n#include <cmath>\n\n#include ""gtest/gtest.h""\n\n#include ""ngraph/ngraph.hpp""\n#include ""util/test_tools.hpp""\n#include ""util/autodiff/numeric_compare.hpp""\n#include ""util/all_close_f.hpp""\n#include ""util/test_control.hpp""\n\nusing namespace std;\nusing namespace ngraph;\n\nstatic string s_manifest = ""${MANIFEST}"";\n\n// for float this will be 18 bits matching\n// for bfloat this will be 6 bits matching\nconstexpr int three_quarters_of_available_bits = (MAX_FLOAT_BITS * 3) / 4;\nconstexpr int tolerance = FLOAT_MANTISSA_BITS - three_quarters_of_available_bits;\n\n\'\'\')\n\n    for t in tests:\n        emit_test(t, f)\n\n    f.write(\'\'\'\n// clang-format on\n\'\'\')\n\n    f.close()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
test/ref_generators/generate_dyn_replace_slice_ref.py,0,"b'#!/usr/bin/env python\n# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\n#\n# Test case generator for DynReplaceSlice op.\n#\n# TODO(amprocte): de-duplicate lots of code in generate_dyn_slice_ref.py.\n#\n\nimport sys\nimport numpy as np\n\ndef make_iterable(x):\n    try:\n        _ = iter(x)\n    except TypeError as _:\n        return [x]\n    return x\n\ndef print_lb_values(slices):\n    slices = make_iterable(slices)\n\n    strs = []\n\n    for sl in slices:\n        try:\n            x = int(sl)\n            strs.append(str(x))\n        except TypeError as _:\n            if isinstance(sl, slice) and sl.start is not None:\n                strs.append(str(sl.start))\n            else:\n                strs.append(\'0\')\n    return \',\'.join(strs)\n\ndef print_ub_values(slices):\n    slices = make_iterable(slices)\n\n    strs = []\n\n    for sl in slices:\n        if isinstance(sl, slice) and sl.stop is not None:\n            strs.append(str(sl.stop))\n        else:\n            strs.append(\'0\')\n    return \',\'.join(strs)\n\ndef print_stride_values(slices):\n    slices = make_iterable(slices)\n\n    strs = []\n\n    for sl in slices:\n        if isinstance(sl, slice) and sl.step is not None:\n            strs.append(str(sl.step))\n        else:\n            strs.append(\'1\')\n    return \',\'.join(strs)\n\ndef print_lb_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        if isinstance(sl, slice) and sl.start is None:\n            mask_strs.append(str(i))\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef print_ub_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        if isinstance(sl, slice) and sl.stop is None:\n            mask_strs.append(str(i))\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef print_new_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        if sl is None:\n            mask_strs.append(str(i))\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef print_shrink_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        try:\n            _ = int(sl)\n            mask_strs.append(str(i))\n        except TypeError as _:\n            pass\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef print_ellipsis_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        if sl is Ellipsis:\n            mask_strs.append(str(i))\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef np_dt_to_c(dtype):\n    if dtype==\'int8\':\n        return \'int8_t\'\n    elif dtype==\'uint8\':\n        return \'uint8_t\'\n    elif dtype==\'int16\':\n        return \'int16_t\'\n    elif dtype==\'uint16\':\n        return \'uint16_t\'\n    elif dtype==\'int32\':\n        return \'int32_t\'\n    elif dtype==\'uint32\':\n        return \'uint32_t\'\n    elif dtype==\'int64\':\n        return \'int64_t\'\n    elif dtype==\'uint64\':\n        return \'uint64_t\'\n    elif dtype==\'float16\':\n        return \'float16\'\n    elif dtype==\'float32\':\n        return \'float\'\n    elif dtype==\'float64\':\n        return \'double\'\n    elif dtype==\'bool\':\n        return \'char\'\n    else:\n        raise ValueError(\'Unsupported numpy data type: %s\' % dtype)\n\ndef np_dt_to_ng(dtype):\n    if dtype==\'int8\':\n        return \'element::i8\'\n    elif dtype==\'uint8\':\n        return \'element::u8\'\n    elif dtype==\'int16\':\n        return \'element::i16\'\n    elif dtype==\'uint16\':\n        return \'element::u16\'\n    elif dtype==\'int32\':\n        return \'element::i32\'\n    elif dtype==\'uint32\':\n        return \'element::u32\'\n    elif dtype==\'int64\':\n        return \'element::i64\'\n    elif dtype==\'uint64\':\n        return \'element::u64\'\n    elif dtype==\'float16\':\n        return \'element::f16\'\n    elif dtype==\'float32\':\n        return \'element::f32\'\n    elif dtype==\'float64\':\n        return \'element::f64\'\n    elif dtype==\'bool\':\n        return \'element::boolean\'\n    else:\n        raise ValueError(\'Unsupported numpy data type: %s\' % dtype)\n\ndef print_values(values):\n    values = make_iterable(values)\n    strs = []\n\n    for v in values:\n        strs.append(str(v))\n\n    return \',\'.join(strs)\n\ndef print_shape(dims):\n    dims = make_iterable(dims)\n    strs = []\n\n    for d in dims:\n        strs.append(str(d))\n\n    return \'Shape{\' + \',\'.join(strs) + \'}\'\n\ndef print_slice(sl):\n    if sl is None:\n        return \'newaxis\'\n    elif sl is Ellipsis:\n        return ""...""\n    elif isinstance(sl, slice):\n        s = \'\'\n        if sl.start is not None:\n            s += str(sl.start)\n        s += \':\'\n        if sl.stop is not None:\n            s += str(sl.stop)\n        if sl.step is not None:\n            s += \':\'\n            s += str(sl.step)\n        return s\n    else:\n        return str(sl)\n\ndef print_slices(slices):\n    slices = make_iterable(slices)\n    strs = []\n\n    for sl in slices:\n        strs.append(print_slice(sl))\n\n    return \'[\' + \',\'.join(strs) + \']\'\n\n#\n# Class to intercept __setitem__ operations and write an nGraph C++ test case.\n# The generated test case will ensure that the output is identical to what\n# would be produced by numpy. Specifically, the numpy (and equivalent C++)\n# it will generate a ""linspaced"" array of the appropriate shape and dtype, and\n# attempt to overwrite it with the ""value"" argument of __setitem__. If the\n# value is None, it will auto-generate a replacement value of the appropriate\n# shape.\n#\n# We will attempt to catch any exceptions raised by numpy\'s __setitem__, and\n# generate a test that checks for erroring behavio.\n#\n# Example usage:\n#\n#    w = ReplaceSliceTestWriter(stream=sys.stdout)\n#\n#    # behave as if writing into a 4x5x6 input array of data type int32\n#    w.set_shape(4,5,6)\n#    w.set_dtype(\'int32\')\n#\n#    # generate test cases for various behaviors, writing C++ code to sys.stdout\n#    w[0,:,:]       = np.ones(shape=(5,6), dtype=\'int32\')\n#    w[0,:,:]       = None   # test will auto-generate something of shape (5,6)\n#    w[...,-1:-3,:] = np.zeros(shape=(4,0,6), dtype=\'int32\')\n#\n#    # generate test cases for some erroring behaviors, writing C++ code to\n#    # sys.stdout\n#    w[1,2,3,4] = 0                # too many indices\n#    w[7] = np.ones(shape=(5,6))   # index out of bounds\n#    w[1,1] = [2]                  # shape mismatch between slice and\n#                                  # replacement (NOTE: this example is\n#                                  # actually legal in np because it would\n#                                  # auto-broadcast, but not in nGraph.)\n#\nclass ReplaceSliceTestWriter:\n    def __init__(self, shape=(), dtype=\'int32\', stream=sys.stdout):\n        self._shape = shape\n        self._dtype = dtype\n        self._stream = stream\n        self._test_counter = 0\n\n    def __setitem__(self, slices, value):\n        self.write_test(slices, value)\n\n    def write_test(self, slices, value, value_shape=None):\n        # Generate some linspaced input data.\n        data_in = np.linspace(0,np.prod(self._shape)-1,np.prod(self._shape),dtype=self._dtype).reshape(self._shape)\n\n        failure_reasons = []\n\n        if value_shape is None:\n            try:\n                slice_shape = data_in.__getitem__(slices).shape\n            except Exception:\n                failure_reasons.append(\'numpy getitem failed\')\n                slice_shape = ()\n\n        if value_shape is None:\n            value_shape = slice_shape\n\n        # If `value` is None, we\'ll auto-generate some data. This will only\n        # work if value_shape is specified, OR if the slices are legal for the\n        # input.\n        #\n        # Generated value is linspaced, starting where data_in left off.\n        if value is None:\n            value = np.linspace(np.prod(self._shape), np.prod(self._shape) + np.prod(value_shape) - 1, np.prod(value_shape), dtype=self._dtype).reshape(value_shape)\n        else:\n            value = np.array(value)\n\n        # numpy allows autobroadcast of the replacement to match the slice\n        # shape, but we don\'t, so we would expect failure in that case\n        if value.shape != slice_shape:\n            failure_reasons.append(\'slice shape and replacement shape do not match\')\n\n        self._stream.write(\'\\n\')\n        self._stream.write(\'                                       // test %d\\n\' % self._test_counter)\n        self._stream.write(\'                                       // slices are: %s\\n\' % print_slices(slices))\n        self._stream.write(\'                                       // dtype is: %s\\n\' % self._dtype)\n        self._stream.write(\'                                       // input shape is: %s\\n\' % print_shape(self._shape))\n        self._stream.write(\'                                       // slice shape is: %s\\n\' % print_shape(slice_shape))\n        self._stream.write(\'                                       // replacement shape is: %s\\n\' % print_shape(value.shape))\n\n        # If numpy fails for any reason, we expect failure.\n        try:\n            data_out = data_in\n            data_out.__setitem__(slices, value)\n        except Exception:\n            failure_reasons.append(\'numpy setitem failed\')\n\n        # numpy allows implicit data type conversion, but we don\'t, so we\n        # expect failure if dtypes do not match.\n        if value.dtype != self._dtype:\n            failure_reasons.append(\'dtype mismatch\')\n\n        is_failed = (failure_reasons != [])\n\n        if is_failed:\n            result_values = np.array([], dtype=self._dtype)\n        else:\n            result_values = data_out\n\n        if is_failed:\n            self._stream.write(\'                                       // failure is expected (%s)\\n\' % \',\'.join(failure_reasons))\n        else:\n            self._stream.write(\'                                       // expected output shape is %s\\n\' % print_shape(data_in.shape))\n\n        self._stream.write(\'                                       make_shared<DynReplaceSliceTestParams<%s,%s>>(\\n\'\n                           \'                                           %s,\\n\'\n                           \'                                           %s,\\n\'\n                           \'                                           %s,\\n\'\n                           \'                                           %s,\\n\'\n                           \'                                           %s,\\n\'\n                           \'                                           std::vector<int64_t>{%s},\\n\'\n                           \'                                           std::vector<int64_t>{%s},\\n\'\n                           \'                                           std::vector<int64_t>{%s},\\n\'\n                           \'                                           AxisSet{%s},\\n\'\n                           \'                                           AxisSet{%s},\\n\'\n                           \'                                           AxisSet{%s},\\n\'\n                           \'                                           AxisSet{%s},\\n\'\n                           \'                                           AxisSet{%s},\\n\'\n                           \'                                           std::vector<%s>{%s},\\n\'\n                           \'                                           std::vector<%s>{%s}\\n\'\n                           \'                                       ),\\n\'\n                                % (np_dt_to_c(self._dtype), np_dt_to_c(value.dtype),\n\n                                    \'false\' if is_failed else \'true\',\n\n                                    np_dt_to_ng(self._dtype),\n                                    np_dt_to_ng(value.dtype),\n                                    print_shape(data_in.shape),\n                                    print_shape(value.shape),\n\n                                    print_lb_values(slices),\n                                    print_ub_values(slices),\n                                    print_stride_values(slices),\n\n                                    print_lb_mask_axes(slices),\n                                    print_ub_mask_axes(slices),\n                                    print_new_mask_axes(slices),\n                                    print_shrink_mask_axes(slices),\n                                    print_ellipsis_mask_axes(slices),\n\n                                    np_dt_to_c(self._dtype), print_values(result_values.reshape(-1)),\n                                    np_dt_to_c(value.dtype), print_values(value.reshape(-1))))\n\n        self._test_counter += 1\n\n    def set_shape(self,shape):\n        self._shape = shape\n\n    def set_dtype(self,dtype):\n        self._dtype = dtype\n\ndef write_header(f):\n    f.write(\'\'\'\\\n//*****************************************************************************\n// Copyright 2017-2020 Intel Corporation\n//\n// Licensed under the Apache License, Version 2.0 (the ""License"");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an ""AS IS"" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n//*****************************************************************************\n\n// !!!!!!!!!!!!!! THIS FILE IS AUTOGENERATED OUTSIDE OF THE BUILD PROCESS !!!!!!!!!!!!!!\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DO NOT EDIT THIS FILE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n//\n// DO NOT EDIT THIS FILE. If you want to add new tests, you should edit\n//  test/ref_generators/generate_dyn_replace_slice_ref.py and regenerate this file.\n//\n// To regenerate:\n//\n//   $ cd <ngraph source dir>/test\n//   $ ./update_dyn_replace_slice_reference.sh\n//\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DO NOT EDIT THIS FILE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n// !!!!!!!!!!!!!! THIS FILE IS AUTOGENERATED OUTSIDE OF THE BUILD PROCESS !!!!!!!!!!!!!!\n//\n// clang-format off\n\n#include <algorithm>\n#include <cmath>\n\n#include ""gtest/gtest.h""\n\n#include ""ngraph/ngraph.hpp""\n#include ""util/test_tools.hpp""\n#include ""util/autodiff/numeric_compare.hpp""\n#include ""util/all_close_f.hpp""\n#include ""util/test_control.hpp""\n\nusing namespace std;\nusing namespace ngraph;\n\nstatic string s_manifest = ""${MANIFEST}"";\n\nstruct DynReplaceSliceTestParamsBase\n{\n    bool success;\n    element::Type input_element_type;\n    element::Type replacement_element_type;\n    Shape input_shape;\n    Shape replacement_shape;\n    vector<int64_t> lb_values;\n    vector<int64_t> ub_values;\n    vector<int64_t> strides_values;\n    AxisSet lb_mask;\n    AxisSet ub_mask;\n    AxisSet new_mask;\n    AxisSet shrink_mask;\n    AxisSet ellipsis_mask;\n\n    virtual ~DynReplaceSliceTestParamsBase() {}\n\n    virtual void copy_input_values(const shared_ptr<runtime::Tensor>& input_tensor) = 0;\n    virtual void copy_replacement_values(const shared_ptr<runtime::Tensor>& replacement_tensor) = 0;\n    virtual void check_result_values(const std::shared_ptr<runtime::Tensor>& output_tensor) = 0;\n};\n\ntemplate <typename Tinput,typename Treplacement>\nstruct DynReplaceSliceTestParams : public DynReplaceSliceTestParamsBase\n{\n    DynReplaceSliceTestParams(\n        bool p_success,\n        element::Type p_input_element_type,\n        element::Type p_replacement_element_type,\n        const Shape& p_input_shape,\n        const Shape& p_replacement_shape,\n        const vector<int64_t>& p_lb_values,\n        const vector<int64_t>& p_ub_values,\n        const vector<int64_t>& p_strides_values,\n        const AxisSet& p_lb_mask,\n        const AxisSet& p_ub_mask,\n        const AxisSet& p_new_mask,\n        const AxisSet& p_shrink_mask,\n        const AxisSet& p_ellipsis_mask,\n        const vector<Tinput>& p_expected_result_values,\n        const vector<Treplacement>& p_replacement_values)\n    {\n        success = p_success;\n        input_element_type = p_input_element_type;\n        replacement_element_type = p_replacement_element_type;\n        input_shape = p_input_shape;\n        replacement_shape = p_replacement_shape;\n        lb_values = p_lb_values;\n        ub_values = p_ub_values;\n        strides_values = p_strides_values;\n        lb_mask = p_lb_mask;\n        ub_mask = p_ub_mask;\n        new_mask = p_new_mask;\n        shrink_mask = p_shrink_mask;\n        ellipsis_mask = p_ellipsis_mask;\n\n        expected_result_values = p_expected_result_values;\n        replacement_values = p_replacement_values;\n    }\n\n    vector<Tinput> expected_result_values;\n    vector<Treplacement> replacement_values;\n\n    virtual void copy_input_values(const shared_ptr<runtime::Tensor>& input_tensor) override\n    {\n        std::vector<Tinput> input_values(shape_size(input_shape));\n        std::iota(input_values.begin(), input_values.end(), static_cast<Tinput>(0));\n        copy_data(input_tensor, input_values);\n    }\n\n    virtual void copy_replacement_values(const shared_ptr<runtime::Tensor>& replacement_tensor) override\n    {\n        copy_data(replacement_tensor, replacement_values);\n    }\n\n    virtual void check_result_values(const std::shared_ptr<runtime::Tensor>& output_tensor) override\n    {\n        vector<Tinput> result_values = read_vector<Tinput>(output_tensor);\n        EXPECT_EQ(result_values, expected_result_values);\n    }\n};\n\n// We use a shared_ptr here because:\n//  (1) we cannot use the objects directly, since DynReplaceSliceTestParamsBase is abstract;\n//  (2) we cannot use references or raw pointers, since things won\'t get freed properly;\n//  (3) we cannot use unique_ptr, since gtest requires a copy constructor.\nstruct DynReplaceSliceTest : ::testing::TestWithParam<shared_ptr<DynReplaceSliceTestParamsBase>>\n{\n};\n\nNGRAPH_TEST_P(${BACKEND_NAME}, DynReplaceSliceTest, dyn_replace_slice)\n{\n    std::shared_ptr<DynReplaceSliceTestParamsBase> t = GetParam();\n\n    auto backend = runtime::Backend::create(""${BACKEND_NAME}"",true);\n    auto output = backend->create_dynamic_tensor(t->input_element_type, PartialShape::dynamic());\n\n    auto setup = [&t, &backend, &output]() {\n        auto arg = std::make_shared<op::Parameter>(t->input_element_type, t->input_shape);\n        auto repl = std::make_shared<op::Parameter>(t->replacement_element_type, t->replacement_shape);\n        auto lb = std::make_shared<op::Parameter>(element::i64, Shape{t->lb_values.size()});\n        auto ub = std::make_shared<op::Parameter>(element::i64, Shape{t->ub_values.size()});\n        auto strides = std::make_shared<op::Parameter>(element::i64, Shape{t->strides_values.size()});\n\n        auto rsl = std::make_shared<op::DynReplaceSlice>(arg, repl,\n                                                         lb, ub, strides,\n                                                         t->lb_mask, t->ub_mask, t->new_mask,\n                                                         t->shrink_mask, t->ellipsis_mask);\n\n        auto f = std::make_shared<Function>(OutputVector{rsl}, ParameterVector{arg, repl, lb, ub, strides});\n\n        auto ex = backend->compile(f);\n\n        auto input_arg = backend->create_tensor(t->input_element_type, t->input_shape);\n        auto input_repl = backend->create_tensor(t->replacement_element_type, t->replacement_shape);\n        auto input_lb = backend->create_tensor(element::i64, Shape{t->lb_values.size()});\n        auto input_ub = backend->create_tensor(element::i64, Shape{t->ub_values.size()});\n        auto input_strides = backend->create_tensor(element::i64, Shape{t->strides_values.size()});\n        t->copy_input_values(input_arg);\n        t->copy_replacement_values(input_repl);\n        copy_data(input_lb, t->lb_values);\n        copy_data(input_ub, t->ub_values);\n        copy_data(input_strides, t->strides_values);\n\n        ex->call_with_validate({output}, {input_arg, input_repl, input_lb, input_ub, input_strides});\n    };\n\n    if (t->success)\n    {\n        setup();\n        EXPECT_EQ(output->get_element_type(), t->input_element_type);\n        EXPECT_EQ(output->get_output_shape(0), t->input_shape);\n        t->check_result_values(output);\n    }\n    else\n    {\n        EXPECT_ANY_THROW({\n            setup();\n        });\n    }\n}\n\nNGRAPH_INSTANTIATE_TEST_CASE_P(${BACKEND_NAME},\n                               dyn_replace_slice,\n                               DynReplaceSliceTest,\n                               (::testing::ValuesIn(\n                                   std::vector<std::shared_ptr<DynReplaceSliceTestParamsBase>>{\'\'\')\n\ndef write_footer(f):\n    f.write(\'\'\'\\\n                                   })));\n// clang-format on\n\'\'\')\n\n\ndef main():\n    if len(sys.argv) < 2:\n        sys.stderr.write(\'Output filename is required\\n\')\n        sys.exit(1)\n\n    f = open(sys.argv[1], \'w\')\n    write_header(f)\n\n    t = ReplaceSliceTestWriter(stream=f)\n\n    t.set_shape((4,))\n    for dt in [\'int32\',\'int64\',\'float32\',\'uint32\']:\n        t.set_dtype(dt)\n\n        t[np.newaxis,3:0:-1] = None\n        t[...] = None\n        t[1:3] = None\n        t[2] = None\n        t[3:0:-2] = None\n        t[3::-2] = None\n        t[4::-2] = None\n        t[5::-2] = None\n        t[-9000:-8000:2] = None\n        t[-9000:8000:2] = None\n        t[-5:5:2] = None\n        t[np.newaxis] = None\n        t[np.newaxis,np.newaxis] = None\n        t[np.newaxis,np.newaxis,...,np.newaxis] = None\n\n        # Some tests with incorrect replacement shapes\n        t[2] = np.ones(shape=(2,2), dtype=dt)\n\n        t.set_shape((5,))\n        t[3:0:-2] = None\n        t[0:3:2] = None\n        t[0:4:2] = None\n        t[0:5:2] = None\n        t[0:6:2] = None\n        t[0:100:2] = None\n        t[4:0:-2] = None\n        t[4:0:-3] = None\n        t[3:2:1] = None\n        t[4::-2] = None\n\n        #\n        # A couple of tests for negative-stride slicing. The issue we want to\n        # be on the lookout for is this:\n        #\n        #  [ORIGINAL]\n        #   01234567\n        #   ..1..0..   [5:0:-3]  # suppose we start with this, want to convert\n        #    _____               # to pos stride. suppose that our stride is\n        #                        # ""uneven"" wrt the slicing region, i.e. the\n        #                        # start-to-end distance is not an even\n        #                        # multiple of the strides (e.g. here: we get\n        #                        # elements 5 and 2.)\n        #\n        #  [INCORRECT]\n        #   01234567\n        #   .0..1...   [1:6:3]   # if we just reverse the sign of the stride\n        #    _____               # and flip the start/end indices while\n        #                        # traversing, we will get out the wrong\n        #                        # elements. (e.g. here: we get elements 1 and\n        #                        # 4, which are not what we want.)\n        #\n        #  [CORRECT]\n        #   01234567\n        #   ..0..1..   [2:6:3]   # the correct thing to do is to adjust the\n        #     ____               # start of our reversed slice to be the last\n        #                        # element that is *actually* touched by the\n        #                        # original negative striding, not the\n        #                        # boundary of the region. (e.g. here: we get\n        #                        # elements 2 and 5, which are what we want.)\n        #\n        # There\'s some logic to do this transformation in DynElimination, but\n        # it feels a bit delicate.\n        #\n        t.set_shape((8,))\n        t[5:2:-3] = None\n        t[5:1:-3] = None\n        t[5:0:-3] = None\n        t[5::-3] = None\n        t[6:3:-3] = None\n        t[6:2:-3] = None\n        t[6:1:-3] = None\n        t[6::-3] = None\n        t[7:1:-3] = None\n        t[7:0:-3] = None\n        t[7::-3] = None\n\n    t.set_dtype(\'int32\')\n    t.set_shape((4, 5))\n    t[2:4, ...] = None\n    t[4:2, ...] = None\n    t[4:2:-3, ...] = None\n    t[-100:100, ...] = None\n    t[..., 2:] = None\n    t[..., 2:4] = None\n    t[..., :] = None\n    t[..., -100:100] = None\n    t.set_shape((5, 6, 10, 8))\n    t[2:4, ..., 1:7:3, 7:2:-2] = None\n    t[..., 1:7:3, 7:2:-2] = None\n    t[2:4, ..., :3, -3:2:-2] = None\n    t[2:4, ..., 1:7:-3, 7:2:-2] = None\n    t[2:4, ..., :, np.newaxis, 0] = None\n\n    t.set_shape((2, 2, 3, 2, 3, 3))\n    t[2:6:2, ..., :, 2:1:-1] = None\n    t[np.newaxis, 1, ..., np.newaxis, 2:1:-1] = None\n    t[1, ..., np.newaxis, 2:1:-1] = None\n    t[np.newaxis, np.newaxis, 2:1:-1, ...] = None\n\n    t.set_shape((3, 3, 3, 2, 3))\n    t[6:1:-2, ..., 1:2, 2:1:-1] = None\n\n    t.set_shape((3, 3, 3, 2, 3))\n    t[..., 1:2, 2:1:-1] = None\n\n    t.set_dtype(\'int32\')\n    t[80000] = None # error expected (shrink-axis OOB)\n    t[-80000] = None # error expected (shrink-axis OOB)\n    t[:,:] = None # error expected (too many indices)\n    t[0:0:0] = None # error expected (stride==0)\n    t[0:1:0] = None # error expected (stride==0)\n    t[0:2:0] = None # error expected (stride==0)\n    t[::0] = None # error expected (stride==0)\n\n    t.set_shape((2,3,4))\n\n    t.set_dtype(\'int32\')\n    # Test with incorrect DT\n    t[...] = np.ones(shape=(2,3,4), dtype=\'float32\')\n    # Test some cases where auto-broadcast would be required\n    t[...] = np.ones(shape=(1,3,4), dtype=\'int32\')\n    t[...] = np.ones(shape=(3,4), dtype=\'int32\')\n    t[0,...,0] = np.ones(shape=(1), dtype=\'int32\')\n\n    for dt in [\'int32\',\'int64\',\'float32\',\'uint32\']:\n        t.set_dtype(dt)\n\n        t[1,np.newaxis] = None\n        t[-1,-1,np.newaxis] = None\n\n    t.set_shape((2,4,6,8,2,2,2))\n    for dt in [\'int32\',\'int64\',\'float32\',\'uint32\']:\n        t.set_dtype(dt)\n        t[0:,:4,2:6:2,7:3:-2,np.newaxis,...,1] = None\n\n    t.set_dtype(\'int32\')\n    t[...,...] = None # error expected (too many ellipses)\n\n    write_footer(f)\n    f.close()\n\nif __name__ == ""__main__"":\n    main()\n'"
test/ref_generators/generate_dyn_slice_ref.py,0,"b'#!/usr/bin/env python\n# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\n#\n# Test case generator for DynSlice op.\n#\n# TODO(amprocte): refactor to use parameterized gtests.\n#\n\nimport sys\nimport numpy as np\n\ndef make_iterable(x):\n    try:\n        _ = iter(x)\n    except TypeError as _:\n        return [x]\n    return x\n\ndef print_lb_values(slices):\n    slices = make_iterable(slices)\n\n    strs = []\n\n    for sl in slices:\n        try:\n            x = int(sl)\n            strs.append(str(x))\n        except TypeError as _:\n            if isinstance(sl, slice) and sl.start is not None:\n                strs.append(str(sl.start))\n            else:\n                strs.append(\'0\')\n    return \',\'.join(strs)\n\ndef print_ub_values(slices):\n    slices = make_iterable(slices)\n\n    strs = []\n\n    for sl in slices:\n        if isinstance(sl, slice) and sl.stop is not None:\n            strs.append(str(sl.stop))\n        else:\n            strs.append(\'0\')\n    return \',\'.join(strs)\n\ndef print_stride_values(slices):\n    slices = make_iterable(slices)\n\n    strs = []\n\n    for sl in slices:\n        if isinstance(sl, slice) and sl.step is not None:\n            strs.append(str(sl.step))\n        else:\n            strs.append(\'1\')\n    return \',\'.join(strs)\n\ndef print_lb_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        if isinstance(sl, slice) and sl.start is None:\n            mask_strs.append(str(i))\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef print_ub_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        if isinstance(sl, slice) and sl.stop is None:\n            mask_strs.append(str(i))\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef print_new_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        if sl is None:\n            mask_strs.append(str(i))\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef print_shrink_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        try:\n            _ = int(sl)\n            mask_strs.append(str(i))\n        except TypeError as _:\n            pass\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef print_ellipsis_mask_axes(slices):\n    slices = make_iterable(slices)\n\n    mask_strs = []\n    i = 0\n\n    for sl in slices:\n        if sl is Ellipsis:\n            mask_strs.append(str(i))\n        i += 1\n    return \',\'.join(mask_strs)\n\ndef np_dt_to_c(dtype):\n    if dtype==\'int8\':\n        return \'int8_t\'\n    elif dtype==\'uint8\':\n        return \'uint8_t\'\n    elif dtype==\'int16\':\n        return \'int16_t\'\n    elif dtype==\'uint16\':\n        return \'uint16_t\'\n    elif dtype==\'int32\':\n        return \'int32_t\'\n    elif dtype==\'uint32\':\n        return \'uint32_t\'\n    elif dtype==\'int64\':\n        return \'int64_t\'\n    elif dtype==\'uint64\':\n        return \'uint64_t\'\n    elif dtype==\'float16\':\n        return \'float16\'\n    elif dtype==\'float32\':\n        return \'float\'\n    elif dtype==\'float64\':\n        return \'double\'\n    elif dtype==\'bool\':\n        return \'char\'\n    else:\n        raise ValueError(\'Unsupported numpy data type: %s\' % dtype)\n\ndef np_dt_to_ng(dtype):\n    if dtype==\'int8\':\n        return \'element::i8\'\n    elif dtype==\'uint8\':\n        return \'element::u8\'\n    elif dtype==\'int16\':\n        return \'element::i16\'\n    elif dtype==\'uint16\':\n        return \'element::u16\'\n    elif dtype==\'int32\':\n        return \'element::i32\'\n    elif dtype==\'uint32\':\n        return \'element::u32\'\n    elif dtype==\'int64\':\n        return \'element::i64\'\n    elif dtype==\'uint64\':\n        return \'element::u64\'\n    elif dtype==\'float16\':\n        return \'element::f16\'\n    elif dtype==\'float32\':\n        return \'element::f32\'\n    elif dtype==\'float64\':\n        return \'element::f64\'\n    elif dtype==\'bool\':\n        return \'element::boolean\'\n    else:\n        raise ValueError(\'Unsupported numpy data type: %s\' % dtype)\n\ndef print_values(values):\n    values = make_iterable(values)\n    strs = []\n\n    for v in values:\n        strs.append(str(v))\n\n    return \',\'.join(strs)\n\ndef print_shape(dims):\n    dims = make_iterable(dims)\n    strs = []\n\n    for d in dims:\n        strs.append(str(d))\n\n    return \'Shape{\' + \',\'.join(strs) + \'}\'\n\ndef print_slice(sl):\n    if sl is None:\n        return \'newaxis\'\n    elif sl is Ellipsis:\n        return ""...""\n    elif isinstance(sl, slice):\n        s = \'\'\n        if sl.start is not None:\n            s += str(sl.start)\n        s += \':\'\n        if sl.stop is not None:\n            s += str(sl.stop)\n        if sl.step is not None:\n            s += \':\'\n            s += str(sl.step)\n        return s\n    else:\n        return str(sl)\n\ndef print_slices(slices):\n    slices = make_iterable(slices)\n    strs = []\n\n    for sl in slices:\n        strs.append(print_slice(sl))\n\n    return \'[\' + \',\'.join(strs) + \']\'\n\n#\n# Class to intercept indexing operations and write an nGraph C++ test case. The\n# generated test case will ensure that the output is identical to that which\n# would be produced by numpy on a ""linspaced"" array of the given shape and\n# dtype. If numpy throws an exception when the slice is attempted, the test\n# checks that nGraph throws some exception somewhere in graph construction or\n# execution, but does not attempt to make sure that the exception is the\n# ""correct"" one.\n#\n# Example usage:\n#\n#    w = SliceTestWriter(stream=sys.stdout)\n#\n#    # behave as if slicing a 4x5x6 input array of data type int32\n#    w.set_shape(4,5,6)\n#    w.set_dtype(\'int32\')\n#\n#    # generate test cases for various behaviors, writing C++ code to sys.stdout\n#    w[0,:,:]\n#    w[...,-1:-3,:]\n#    w[-3,...,-1:-6:-3]\n#    w[1,2,3,4]        # note: in numpy this throws exception (too many\n#                      # indices), so generated test case will check that\n#                      # nGraph throws some exception too.\n#\nclass SliceTestWriter:\n    def __init__(self, shape=(), dtype=\'int32\', stream=sys.stdout):\n        self._shape = shape\n        self._dtype = dtype\n        self._stream = stream\n        self._test_counter = 0\n\n    def __getitem__(self, slices):\n        self.write_test(slices)\n\n    def write_test(self, slices):\n        data_in = np.linspace(0,np.prod(self._shape)-1,np.prod(self._shape),dtype=self._dtype).reshape(self._shape)\n\n        self._stream.write(\'\\n\')\n        self._stream.write(\'// slices are: %s\\n\' % print_slices(slices))\n        self._stream.write(\'// dtype is: %s\\n\' % self._dtype)\n        self._stream.write(\'// input shape is: %s\\n\' % print_shape(self._shape))\n\n        try:\n            data_out = data_in.__getitem__(slices)\n        except Exception:\n            self._stream.write(\'// failure is expected\\n\'\n                               \'NGRAPH_TEST(${BACKEND_NAME}, dyn_slice_%d)\\n\'\n                               \'{\\n\'\n                               \'    check_failure<%s>\\n\'\n                               \'                 (%s,\\n\'\n                               \'                  %s,\\n\'\n                               \'                  std::vector<int64_t>{%s},\\n\'\n                               \'                  std::vector<int64_t>{%s},\\n\'\n                               \'                  std::vector<int64_t>{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  AxisSet{%s});\\n\'\n                               \'}\\n\'\n                                  % (self._test_counter,\n                                     np_dt_to_c(self._dtype),\n                                     np_dt_to_ng(self._dtype),\n                                     print_shape(data_in.shape),\n                                     print_lb_values(slices),\n                                     print_ub_values(slices),\n                                     print_stride_values(slices),\n                                     print_lb_mask_axes(slices),\n                                     print_ub_mask_axes(slices),\n                                     print_new_mask_axes(slices),\n                                     print_shrink_mask_axes(slices),\n                                     print_ellipsis_mask_axes(slices)))\n        else:\n            self._stream.write(\'// expected output shape is %s\\n\'\n                               \'NGRAPH_TEST(${BACKEND_NAME}, dyn_slice_%d)\\n\'\n                               \'{\\n\'\n                               \'    check_success<%s>\\n\'\n                               \'                 (%s,\\n\'\n                               \'                  %s,\\n\'\n                               \'                  std::vector<int64_t>{%s},\\n\'\n                               \'                  std::vector<int64_t>{%s},\\n\'\n                               \'                  std::vector<int64_t>{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  AxisSet{%s},\\n\'\n                               \'                  %s,\\n\'\n                               \'                  std::vector<%s>{%s});\\n\'\n                               \'}\\n\'\n                                  % (print_shape(data_out.shape),\n                                     self._test_counter,\n                                     np_dt_to_c(self._dtype),\n                                     np_dt_to_ng(self._dtype),\n                                     print_shape(data_in.shape),\n                                     print_lb_values(slices),\n                                     print_ub_values(slices),\n                                     print_stride_values(slices),\n                                     print_lb_mask_axes(slices),\n                                     print_ub_mask_axes(slices),\n                                     print_new_mask_axes(slices),\n                                     print_shrink_mask_axes(slices),\n                                     print_ellipsis_mask_axes(slices),\n                                     print_shape(data_out.shape),\n                                     np_dt_to_c(self._dtype), print_values(data_out.reshape(-1))))\n\n        self._test_counter += 1\n\n    def set_shape(self,shape):\n        self._shape = shape\n\n    def set_dtype(self,dtype):\n        self._dtype = dtype\n\ndef write_header(f):\n    f.write(\'\'\'\\\n//*****************************************************************************\n// Copyright 2017-2020 Intel Corporation\n//\n// Licensed under the Apache License, Version 2.0 (the ""License"");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an ""AS IS"" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n//*****************************************************************************\n\n// !!!!!!!!!!!!!! THIS FILE IS AUTOGENERATED OUTSIDE OF THE BUILD PROCESS !!!!!!!!!!!!!!\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DO NOT EDIT THIS FILE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n//\n// DO NOT EDIT THIS FILE. If you want to add new tests, you should edit\n//  test/ref_generators/generate_dyn_slice_ref.py and regenerate this file.\n//\n// To regenerate:\n//\n//   $ cd <ngraph source dir>/test\n//   $ ./update_dyn_slice_reference.sh\n//\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DO NOT EDIT THIS FILE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n// !!!!!!!!!!!!!! THIS FILE IS AUTOGENERATED OUTSIDE OF THE BUILD PROCESS !!!!!!!!!!!!!!\n//\n// clang-format off\n\n#include <algorithm>\n#include <cmath>\n\n#include ""gtest/gtest.h""\n\n#include ""ngraph/ngraph.hpp""\n#include ""util/test_tools.hpp""\n#include ""util/autodiff/numeric_compare.hpp""\n#include ""util/all_close_f.hpp""\n#include ""util/test_control.hpp""\n\nusing namespace std;\nusing namespace ngraph;\n\nstatic string s_manifest = ""${MANIFEST}"";\n\nnamespace\n{\n    template <typename T>\n    void check_failure(const element::Type& input_element_type,\n                    const Shape& input_shape,\n                    const std::vector<int64_t>& lb_values,\n                    const std::vector<int64_t>& ub_values,\n                    const std::vector<int64_t>& strides_values,\n                    const AxisSet& lb_mask,\n                    const AxisSet& ub_mask,\n                    const AxisSet& new_mask,\n                    const AxisSet& shrink_mask,\n                    const AxisSet& ellipsis_mask)\n    {\n        auto arg = std::make_shared<op::Parameter>(input_element_type, input_shape);\n        auto lb = std::make_shared<op::Parameter>(element::i64, Shape{lb_values.size()});\n        auto ub = std::make_shared<op::Parameter>(element::i64, Shape{ub_values.size()});\n        auto strides = std::make_shared<op::Parameter>(element::i64, Shape{strides_values.size()});\n\n        std::vector<T> input_values(shape_size(input_shape));\n        std::iota(input_values.begin(), input_values.end(), static_cast<T>(0));\n\n        auto slice = std::make_shared<op::DynSlice>(\n            arg, lb, ub, strides, lb_mask, ub_mask, new_mask, shrink_mask, ellipsis_mask);\n\n        auto f = std::make_shared<Function>(OutputVector{slice}, ParameterVector{arg, lb, ub, strides});\n\n        auto backend = runtime::Backend::create(""${BACKEND_NAME}"", true);\n        auto ex = backend->compile(f);\n\n        auto input_arg = backend->create_tensor(input_element_type, input_shape);\n        auto input_lb = backend->create_tensor(element::i64, Shape{lb_values.size()});\n        auto input_ub = backend->create_tensor(element::i64, Shape{ub_values.size()});\n        auto input_strides = backend->create_tensor(element::i64, Shape{strides_values.size()});\n        copy_data(input_arg, input_values);\n        copy_data(input_lb, lb_values);\n        copy_data(input_ub, ub_values);\n        copy_data(input_strides, strides_values);\n\n        auto output = backend->create_dynamic_tensor(input_element_type, PartialShape::dynamic());\n\n        try\n        {\n            ex->call_with_validate({output}, {input_arg, input_lb, input_ub, input_strides});\n            FAIL() << ""No exception thrown"";\n        }\n        catch (exception& err)\n        {\n            string s = err.what();\n            s = s.substr(0, 5);\n            if (s != ""Check"")\n            {\n                auto p = std::current_exception();\n                rethrow_exception(p);\n            }\n        }\n    }\n\n    template <typename T>\n    void check_success(const element::Type& input_element_type,\n                    const Shape& input_shape,\n                    const std::vector<int64_t>& lb_values,\n                    const std::vector<int64_t>& ub_values,\n                    const std::vector<int64_t>& strides_values,\n                    const AxisSet& lb_mask,\n                    const AxisSet& ub_mask,\n                    const AxisSet& new_mask,\n                    const AxisSet& shrink_mask,\n                    const AxisSet& ellipsis_mask,\n                    const Shape& expected_output_shape,\n                    const std::vector<T>& expected_values)\n    {\n        auto arg = std::make_shared<op::Parameter>(input_element_type, input_shape);\n        auto lb = std::make_shared<op::Parameter>(element::i64, Shape{lb_values.size()});\n        auto ub = std::make_shared<op::Parameter>(element::i64, Shape{ub_values.size()});\n        auto strides = std::make_shared<op::Parameter>(element::i64, Shape{strides_values.size()});\n\n        std::vector<T> input_values(shape_size(input_shape));\n        std::iota(input_values.begin(), input_values.end(), static_cast<T>(0));\n\n        auto slice = std::make_shared<op::DynSlice>(\n            arg, lb, ub, strides, lb_mask, ub_mask, new_mask, shrink_mask, ellipsis_mask);\n\n        auto f = std::make_shared<Function>(OutputVector{slice}, ParameterVector{arg, lb, ub, strides});\n\n        auto backend = runtime::Backend::create(""${BACKEND_NAME}"", true);\n        auto ex = backend->compile(f);\n\n        auto input_arg = backend->create_tensor(input_element_type, input_shape);\n        auto input_lb = backend->create_tensor(element::i64, Shape{lb_values.size()});\n        auto input_ub = backend->create_tensor(element::i64, Shape{ub_values.size()});\n        auto input_strides = backend->create_tensor(element::i64, Shape{strides_values.size()});\n        copy_data(input_arg, input_values);\n        copy_data(input_lb, lb_values);\n        copy_data(input_ub, ub_values);\n        copy_data(input_strides, strides_values);\n\n        auto output = backend->create_dynamic_tensor(input_element_type, PartialShape::dynamic());\n\n        ex->call_with_validate({output}, {input_arg, input_lb, input_ub, input_strides});\n\n        EXPECT_EQ(output->get_element_type(), input_element_type);\n        EXPECT_EQ(output->get_output_shape(0), expected_output_shape);\n\n        auto output_values = read_vector<T>(output);\n\n        EXPECT_EQ(output_values, expected_values);\n    }\n}\n\'\'\')\n\ndef write_footer(f):\n    f.write(\'\'\'\\\n// clang-format on\n\'\'\')\n\n\ndef main():\n    if len(sys.argv) < 2:\n        sys.stderr.write(\'Output filename is required\\n\')\n        sys.exit(1)\n\n    f = open(sys.argv[1], \'w\')\n    write_header(f)\n\n    t = SliceTestWriter(stream=f)\n\n    t.set_shape((4,))\n    for dt in [\'int32\',\'int64\',\'float32\',\'uint32\']:\n        t.set_dtype(dt)\n\n        t[np.newaxis,3:0:-1]\n        t[...]\n        t[1:3]\n        t[2]\n        t[3:0:-2]\n        t[3::-2]\n        t[4::-2]\n        t[5::-2]\n        t[-9000:-8000:2]\n        t[-9000:8000:2]\n        t[-5:5:2]\n        t[np.newaxis]\n        t[np.newaxis,np.newaxis]\n        t[np.newaxis,np.newaxis,...,np.newaxis]\n\n        t.set_shape((5,))\n        t[3:0:-2]\n        t[0:3:2]\n        t[0:4:2]\n        t[0:5:2]\n        t[0:6:2]\n        t[0:100:2]\n        t[4:0:-2]\n        t[4:0:-3]\n        t[3:2:1]\n        t[4::-2]\n        t[1:-5:-1]\n        t[1:-1:-1]\n        t[1:None]\n        t[1:None:-1]\n        t[-5:5:2]\n        t[-1:5:1]\n        t[-1:1:1]\n\n        #\n        # A couple of tests for negative-stride slicing. The issue we want to\n        # be on the lookout for is this:\n        #\n        #  [ORIGINAL]\n        #   01234567\n        #   ..1..0..   [5:0:-3]  # suppose we start with this, want to convert\n        #    _____               # to pos stride. suppose that our stride is\n        #                        # ""uneven"" wrt the slicing region, i.e. the\n        #                        # start-to-end distance is not an even\n        #                        # multiple of the strides (e.g. here: we get\n        #                        # elements 5 and 2.)\n        #\n        #  [INCORRECT]\n        #   01234567\n        #   .0..1...   [1:6:3]   # if we just reverse the sign of the stride\n        #    _____               # and flip the start/end indices while\n        #                        # traversing, we will get out the wrong\n        #                        # elements. (e.g. here: we get elements 1 and\n        #                        # 4, which are not what we want.)\n        #\n        #  [CORRECT]\n        #   01234567\n        #   ..0..1..   [2:6:3]   # the correct thing to do is to adjust the\n        #     ____               # start of our reversed slice to be the last\n        #                        # element that is *actually* touched by the\n        #                        # original negative striding, not the\n        #                        # boundary of the region. (e.g. here: we get\n        #                        # elements 2 and 5, which are what we want.)\n        #\n        # There\'s some logic to do this transformation in DynElimination, but\n        # it feels a bit delicate.\n        #\n        t.set_shape((8,))\n        t[5:2:-3]\n        t[5:1:-3]\n        t[5:0:-3]\n        t[5::-3]\n        t[6:3:-3]\n        t[6:2:-3]\n        t[6:1:-3]\n        t[6::-3]\n        t[7:1:-3]\n        t[7:0:-3]\n        t[7::-3]\n\n    t.set_dtype(\'int32\')\n    t[80000] # error expected (shrink-axis OOB)\n    t[-80000] # error expected (shrink-axis OOB)\n    t[:,:] # error expected (too many indices)\n    t[0:0:0] # error expected (stride==0)\n    t[0:1:0] # error expected (stride==0)\n    t[0:2:0] # error expected (stride==0)\n    t[::0] # error expected (stride==0)\n\n    t.set_shape((2,3,4))\n    for dt in [\'int32\',\'int64\',\'float32\',\'uint32\']:\n        t.set_dtype(dt)\n\n        t[1,np.newaxis]\n        t[-1,-1,np.newaxis]\n\n    t.set_shape((2,4,6,8,2,2,2))\n    for dt in [\'int32\',\'int64\',\'float32\',\'uint32\']:\n        t.set_dtype(dt)\n        t[0:,:4,2:6:2,7:3:-2,np.newaxis,...,1]\n\n    t.set_dtype(\'int32\')\n    t[...,...] # error expected (too many ellipses)\n\n    write_footer(f)\n    f.close()\n\nif __name__ == ""__main__"":\n    main()\n'"
test/ref_generators/generate_lrn_across_axes.py,0,"b'#!/usr/bin/env python\n# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport copy\nimport numpy as np\n  \ndef LRN(input, size=3, bias=1.0, alpha=3.0, beta=0.5):\n    output = copy.deepcopy(input)\n    N = input.shape[0]\n    C = input.shape[1]\n    H = input.shape[2]\n    W = input.shape[3]\n    for n in range(N):\n        for c in range(C):\n            for h in range(H):\n                    begin_h = max(0, h - (size-1)/2)\n                    end_h = min(H, h + (size-1)/2 + 1)\n                    for w in range(W):\n                        begin_w = max(0, w - (size-1)/2)\n                        end_w = min(W, w + (size-1)/2 + 1)\n                        patch = input[n, c, begin_h:end_h, begin_w:end_w]\n                        output[n, c, h, w] /= (\n                            np.power(bias + (alpha/size) * np.sum(patch * patch), beta))\n    return output\n\ninput = np.arange(0, 12, 1).reshape(2, 3, 2, 1).astype(np.float32)\nresult = LRN(input)\nfor elem in np.nditer(result):\n    print(str(round(elem, 7)) + ""f, "")\n\n'"
test/ref_generators/generate_normalize_l2_ref.py,0,"b'#!/usr/bin/env python\n# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport numpy as np\n\ninput = np.arange(1, 25, 1).reshape(1, 2, 3, 4).astype(np.float32)\neps = np.array([1e-6]).astype(np.float32)\n# across chw axes\nnorm = np.sqrt(np.sum(np.power(input, 2), axis=(1), keepdims=True) + eps)\nresult = input/norm\n\nfor elem in np.nditer(result):\n    print(str(round(elem, 8)) + \'f, \')\n'"
doc/examples/onnx/onnx_example.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport onnx\n\nonnx_protobuf = onnx.load(\'/path/to/model/cntk_ResNet20_CIFAR10/model.onnx\')\n\n# Convert a serialized ONNX model to an ngraph model\nfrom ngraph_onnx.onnx_importer.importer import import_onnx_model\nng_model = import_onnx_model(onnx_protobuf)[0]\n\n\n# Using an ngraph runtime (CPU backend), create a callable computation\nimport ngraph as ng\nruntime = ng.runtime(backend_name=\'CPU\')\nresnet = runtime.computation(ng_model[\'output\'], *ng_model[\'inputs\'])\n\n# Load or create an image\nimport numpy as np\npicture = np.ones([1, 3, 32, 32])\n\n# Run ResNet inference on picture\nresnet(picture)\n\n'"
doc/examples/subgraph_snippets/mxnet-gluon-example.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport mxnet as mx\n\n# Convert gluon model to a static model\nfrom mxnet.gluon.model_zoo import vision\nimport time\n\nbatch_shape = (1, 3, 224, 224)\n\ninput_data = mx.nd.zeros(batch_shape)\n\nresnet_gluon = vision.resnet50_v2(pretrained=True)\nresnet_gluon.hybridize()\nresnet_gluon.forward(input_data)\nresnet_gluon.export(\'resnet50_v2\')\nresnet_sym, arg_params, aux_params = mx.model.load_checkpoint(\'resnet50_v2\', 0)\n\n# Load the model into nGraph as a static graph\nmodel = resnet_sym.simple_bind(ctx=mx.cpu(), data=batch_shape, grad_req=\'null\')\nmodel.copy_params_from(arg_params, aux_params)\n\n# To test the model\'s performance, we\'ve provided this helpful code snippet\n# customizable\n\ndry_run = 5\nnum_batches = 100\nfor i in range(dry_run + num_batches):\n   if i == dry_run:\n       start_time = time.time()\n   outputs = model.forward(data=input_data, is_train=False)\n   for output in outputs:\n       output.wait_to_read()\nprint(""Average Latency = "", (time.time() - start_time)/num_batches * 1000, ""ms"")\n'"
doc/sphinx/ngraph_theme/__init__.py,0,"b'""""""Sphinx ReadTheDocs theme.\n\nFrom https://github.com/ryan-roemer/sphinx-bootstrap-theme.\n\n""""""\nimport os\n\nVERSION = (0, 1, 9)\n\n__version__ = ""."".join(str(v) for v in VERSION)\n__version_full__ = __version__\n\n\ndef get_html_theme_path():\n    """"""Return list of HTML theme paths.""""""\n    cur_dir = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n    return cur_dir\n'"
doc/sphinx/source/conf.py,0,"b'\n\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Intel nGraph library documentation build configuration file, created by\n# sphinx-quickstart on Mon Dec 25 13:04:12 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n\nimport os\nimport sys\n\n# Add path to nGraph Python API.\n\nsys.path.insert(0, os.path.abspath(\'../../../python\'))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\nneeds_sphinx = \'1.7.9\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.ifconfig\',\n    \'sphinx.ext.viewcode\',\n    \'breathe\',\n    ]\n\n\n# source_suffix = \'.rst\'\nsource_suffix = [\'.rst\', \'.md\']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\nstatic_path = [\'static\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'nGraph Compiler Stack\'\ncopyright = \'2017-2020, Intel Corporation\'\nauthor = \'Intel Corporation\'\n\n# License specifics see LICENSE of component\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = \'0.29\'\n\n# The Documentation full version, including alpha/beta/rc tags. Some features\n# available in the latest code will not necessarily be documented first\nrelease = \'0.29.0\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = \'en\'\n\n#   \'da\', \'de\', \'en\', \'es\', \'fi\', \'fr\', \'hu\', \'it\', \'ja\'\n#   \'nl\', \'no\', \'pt\', \'ro\', \'ru\', \'sv\', \'tr\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = []\n\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\n\n# -- Options for HTML output ----------------------------------------------\n\nhtml_title = ""Documentation for the nGraph Library and Compiler Stack""\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'ngraph_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n# html_theme_options = {}\nhtml_logo = \'../ngraph_theme/static/logo.png\'\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\nhtml_favicon = \'../ngraph_theme/static/favicon.ico\'\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'../ngraph_theme/static\']\n\n# Add any paths that contain custom themes here, relative to this directory.\nhtml_theme_path = [""../""]\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# This is required for the alabaster theme\n# refs: http://alabaster.readthedocs.io/en/latest/installation.html#sidebars\nhtml_sidebars = {\n    \'**\': [\n        \'relations.html\',  # needs \'show_related\': True theme option to display\n        \'searchbox.html\',\n    ]\n}\n\nhtml_last_updated_fmt= \'\'\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'IntelnGraphlibrarydoc\'\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'nGraphCompilerStack.tex\', u\'nGraph Compiler Stack Documentation\',\n     u\'Intel Corporation\', \'manual\'),\n]\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'ngraphcompiler\', \'nGraph Compiler stack\',\n     [author], 1)\n]\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'IntelnGraphlibrary\', \'Intel nGraph Library\',\n     author, \'IntelnGraphlibrary\', \'Documentation for Intel nGraph Library code base\',\n     \'Miscellaneous\'),\n]\n\nbreathe_projects = {\n    ""ngraph"": ""../../doxygen/xml"",\n}\n\nrst_epilog = u""""""\n.. include:: /replacements.txt\n""""""\n\n# -- autodoc Extension configuration --------------------------------------\n\nautodoc_mock_imports = [\'ngraph.impl\', \'ngraph.utils\']\n'"
python/src/ngraph/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""ngraph module namespace, exposing factory functions for all ops and other classes.""""""\n# noqa: F401\n\nfrom pkg_resources import get_distribution, DistributionNotFound\n\ntry:\n    __version__ = get_distribution(""ngraph-core"").version\nexcept DistributionNotFound:\n    __version__ = ""0.0.0-dev""\n\n\nfrom ngraph.ops import absolute\nfrom ngraph.ops import absolute as abs\nfrom ngraph.ops import acos\nfrom ngraph.ops import add\nfrom ngraph.ops import asin\nfrom ngraph.ops import atan\nfrom ngraph.ops import avg_pool\nfrom ngraph.ops import batch_norm_inference\nfrom ngraph.ops import batch_to_space\nfrom ngraph.ops import binary_convolution\nfrom ngraph.ops import broadcast\nfrom ngraph.ops import bucketize\nfrom ngraph.ops import ceiling\nfrom ngraph.ops import ceiling as ceil\nfrom ngraph.ops import clamp\nfrom ngraph.ops import concat\nfrom ngraph.ops import constant\nfrom ngraph.ops import convert\nfrom ngraph.ops import convert_like\nfrom ngraph.ops import convolution\nfrom ngraph.ops import convolution_backprop_data\nfrom ngraph.ops import cos\nfrom ngraph.ops import cosh\nfrom ngraph.ops import ctc_greedy_decoder\nfrom ngraph.ops import cum_sum\nfrom ngraph.ops import cum_sum as cumsum\nfrom ngraph.ops import deformable_convolution\nfrom ngraph.ops import deformable_psroi_pooling\nfrom ngraph.ops import depth_to_space\nfrom ngraph.ops import detection_output\nfrom ngraph.ops import divide\nfrom ngraph.ops import elu\nfrom ngraph.ops import embedding_bag_offsets_sum\nfrom ngraph.ops import embedding_bag_packed_sum\nfrom ngraph.ops import embedding_segments_sum\nfrom ngraph.ops import equal\nfrom ngraph.ops import erf\nfrom ngraph.ops import exp\nfrom ngraph.ops import fake_quantize\nfrom ngraph.ops import floor\nfrom ngraph.ops import floor_mod\nfrom ngraph.ops import gather\nfrom ngraph.ops import gather_tree\nfrom ngraph.ops import gelu\nfrom ngraph.ops import get_output_element\nfrom ngraph.ops import greater\nfrom ngraph.ops import greater_equal\nfrom ngraph.ops import grn\nfrom ngraph.ops import group_convolution\nfrom ngraph.ops import group_convolution_backprop_data\nfrom ngraph.ops import gru_cell\nfrom ngraph.ops import hard_sigmoid\nfrom ngraph.ops import interpolate\nfrom ngraph.ops import less\nfrom ngraph.ops import less_equal\nfrom ngraph.ops import log\nfrom ngraph.ops import logical_and\nfrom ngraph.ops import logical_not\nfrom ngraph.ops import logical_or\nfrom ngraph.ops import logical_xor\nfrom ngraph.ops import lrn\nfrom ngraph.ops import lstm_cell\nfrom ngraph.ops import lstm_sequence\nfrom ngraph.ops import matmul\nfrom ngraph.ops import max_pool\nfrom ngraph.ops import maximum\nfrom ngraph.ops import minimum\nfrom ngraph.ops import mod\nfrom ngraph.ops import multiply\nfrom ngraph.ops import mvn\nfrom ngraph.ops import negative\nfrom ngraph.ops import non_max_suppression\nfrom ngraph.ops import non_zero\nfrom ngraph.ops import normalize_l2\nfrom ngraph.ops import not_equal\nfrom ngraph.ops import one_hot\nfrom ngraph.ops import pad\nfrom ngraph.ops import parameter\nfrom ngraph.ops import power\nfrom ngraph.ops import prelu\nfrom ngraph.ops import prior_box\nfrom ngraph.ops import prior_box_clustered\nfrom ngraph.ops import psroi_pooling\nfrom ngraph.ops import proposal\nfrom ngraph.ops import reduce_logical_and\nfrom ngraph.ops import reduce_logical_or\nfrom ngraph.ops import reduce_max\nfrom ngraph.ops import reduce_mean\nfrom ngraph.ops import reduce_min\nfrom ngraph.ops import reduce_prod\nfrom ngraph.ops import reduce_sum\nfrom ngraph.ops import region_yolo\nfrom ngraph.ops import reorg_yolo\nfrom ngraph.ops import relu\nfrom ngraph.ops import reshape\nfrom ngraph.ops import result\nfrom ngraph.ops import reverse\nfrom ngraph.ops import reverse_sequence\nfrom ngraph.ops import rnn_cell\nfrom ngraph.ops import roi_align\nfrom ngraph.ops import roi_pooling\nfrom ngraph.ops import scatter_elements_update\nfrom ngraph.ops import scatter_update\nfrom ngraph.ops import select\nfrom ngraph.ops import selu\nfrom ngraph.ops import shape_of\nfrom ngraph.ops import shuffle_channels\nfrom ngraph.ops import sigmoid\nfrom ngraph.ops import sign\nfrom ngraph.ops import sin\nfrom ngraph.ops import sinh\nfrom ngraph.ops import softmax\nfrom ngraph.ops import space_to_batch\nfrom ngraph.ops import space_to_depth\nfrom ngraph.ops import split\nfrom ngraph.ops import sqrt\nfrom ngraph.ops import squared_difference\nfrom ngraph.ops import squeeze\nfrom ngraph.ops import strided_slice\nfrom ngraph.ops import subtract\nfrom ngraph.ops import tan\nfrom ngraph.ops import tanh\nfrom ngraph.ops import tile\nfrom ngraph.ops import topk\nfrom ngraph.ops import transpose\nfrom ngraph.ops import unsqueeze\nfrom ngraph.ops import variadic_split\n\n\nfrom ngraph.runtime import runtime\n'"
python/src/ngraph/exceptions.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""ngraph exceptions hierarchy. All exceptions are descendants of NgraphError.""""""\n\n\nclass NgraphError(Exception):\n    """"""Base class for Ngraph exceptions.""""""\n\n\nclass UserInputError(NgraphError):\n    """"""User provided unexpected input.""""""\n\n\nclass NgraphTypeError(NgraphError, TypeError):\n    """"""Type mismatch error.""""""\n'"
python/src/ngraph/ops.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\n""""""Factory functions for all ngraph ops.""""""\nfrom typing import Callable, Iterable, List, Optional, Set, Union\n\nimport numpy as np\n\nfrom ngraph.impl import Node, Shape\nfrom ngraph.impl.op import Constant, GetOutputElement, Parameter\nfrom ngraph.utils.decorators import binary_op, nameable_op, unary_op\nfrom ngraph.utils.input_validation import (\n    assert_list_of_ints,\n    check_valid_attributes,\n    is_non_negative_value,\n    is_positive_value,\n)\nfrom ngraph.utils.node_factory import NodeFactory\nfrom ngraph.utils.types import (\n    NodeInput,\n    NumericData,\n    NumericType,\n    ScalarData,\n    TensorShape,\n    as_node,\n    as_nodes,\n    get_dtype,\n    get_element_type,\n    get_element_type_str,\n    make_constant_node,\n)\n\n\ndef _get_node_factory(opset_version: Optional[str] = None) -> NodeFactory:\n    """"""Return NodeFactory configured to create operators from specified opset version.""""""\n    if opset_version:\n        return NodeFactory(opset_version)\n    else:\n        return NodeFactory()\n\n\n@nameable_op\ndef parameter(\n    shape: TensorShape, dtype: NumericType = np.float32, name: Optional[str] = None\n) -> Parameter:\n    """"""Return an ngraph Parameter object.""""""\n    assert_list_of_ints(shape, ""Parameter shape must be a list of integer values."")\n    element_type = get_element_type(dtype)\n    return Parameter(element_type, Shape(shape))\n\n\n@nameable_op\ndef constant(value: NumericData, dtype: NumericType = None, name: Optional[str] = None) -> Constant:\n    """"""Create a Constant node from provided value.\n\n    :param value: One of: array of values or scalar to initialize node with.\n    :param dtype: The data type of provided data.\n    :param name: Optional name for output node.\n    :return: The Constant node initialized with provided data.\n    """"""\n    return make_constant_node(value, dtype)\n\n\n@nameable_op\ndef ctc_greedy_decoder(\n    data: NodeInput,\n    sequence_mask: NodeInput,\n    merge_repeated: bool = True,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform greedy decoding on the logits given in input (best path).\n\n    :param data: Logits on which greedy decoding is performed.\n    :param sequence_mask: The tensor with sequence masks for each sequence in the batch.\n    :param merge_repeated: The flag for merging repeated labels during the CTC calculation.\n    :param name: Optional name for output node.\n    :return: The new node performing an CTCGreedyDecoder operation on input tensor.\n    """"""\n    node_inputs = as_nodes(data, sequence_mask)\n    return _get_node_factory().create(\n        ""CTCGreedyDecoder"", node_inputs, {""ctc_merge_repeated"": merge_repeated}\n    )\n\n\n@nameable_op\ndef elu(data: NodeInput, alpha: NumericType, name: Optional[str] = None) -> Node:\n    """"""Perform Exponential Linear Unit operation element-wise on data from input node.\n\n    Computes exponential linear: alpha * (exp(data) - 1) if < 0, data otherwise.\n\n    For more information refer to:\n    `Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n    <http://arxiv.org/abs/1511.07289>`_\n\n    :param data: Input tensor. One of: input node, array or scalar.\n    :param alpha: Scalar multiplier for negative values.\n    :param name: Optional output node name.\n    :return: The new node performing an ELU operation on its input data element-wise.\n    """"""\n    return _get_node_factory().create(""Elu"", [as_node(data)], {""alpha"": alpha})\n\n\n@nameable_op\ndef shuffle_channels(data: Node, axis: int, groups: int, name: Optional[str] = None) -> Node:\n    """"""Perform permutation on data in the channel dimension of the input tensor.\n\n    The operation is the equivalent with the following transformation of the input tensor\n    :code:`data` of shape [N, C, H, W]:\n\n    :code:`data_reshaped` = reshape(:code:`data`, [N, group, C / group, H * W])\n\n    :code:`data_trnasposed` = transpose(:code:`data_reshaped`, [0, 2, 1, 3])\n\n    :code:`output` = reshape(:code:`data_trnasposed`, [N, C, H, W])\n\n    For example:\n\n    .. code-block:: python\n\n        Inputs: tensor of shape [1, 6, 2, 2]\n\n                data = [[[[ 0.,  1.], [ 2.,  3.]],\n                         [[ 4.,  5.], [ 6.,  7.]],\n                         [[ 8.,  9.], [10., 11.]],\n                         [[12., 13.], [14., 15.]],\n                         [[16., 17.], [18., 19.]],\n                         [[20., 21.], [22., 23.]]]]\n\n                axis = 1\n                groups = 3\n\n        Output: tensor of shape [1, 6, 2, 2]\n\n                output = [[[[ 0.,  1.], [ 2.,  3.]],\n                           [[ 8.,  9.], [10., 11.]],\n                           [[16., 17.], [18., 19.]],\n                           [[ 4.,  5.], [ 6.,  7.]],\n                           [[12., 13.], [14., 15.]],\n                           [[20., 21.], [22., 23.]]]]\n\n    :param data: The node with input tensor.\n    :param axis: Channel dimension index in the data tensor.\n                 A negative value means that the index should be calculated\n                 from the back of the input data shape.\n    :param group:The channel dimension specified by the axis parameter\n                 should be split into this number of groups.\n    :param name: Optional output node name.\n    :return: The new node performing a permutation on data in the channel dimension\n             of the input tensor.\n    """"""\n    return _get_node_factory().create(\n        ""ShuffleChannels"", [as_node(data)], {""axis"": axis, ""groups"": groups}\n    )\n\n\n@nameable_op\ndef squeeze(data: NodeInput, axes: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Perform squeeze operation on input tensor.\n\n    Remove single-dimensional entries from the shape of a tensor.\n    Takes a parameter :code:`axes` with a list of axes to squeeze.\n    If :code:`axes` is not provided, all the single dimensions will be removed from the shape.\n    If an :code:`axis` is selected with shape entry not equal to one, an error is raised.\n\n\n    For example:\n\n       Inputs: tensor with shape [1, 2, 1, 3, 1, 1], axes=[2, 4]\n\n       Result: tensor with shape [1, 2, 3, 1]\n\n    :param data: The node with data tensor.\n    :param axes: List of non-negative integers, indicate the dimensions to squeeze.\n                  One of: input node or array.\n    :param name: Optional new name for output node.\n    :return: The new node performing a squeeze operation on input tensor.\n    """"""\n    return _get_node_factory().create(""Squeeze"", as_nodes(data, axes))\n\n\ndef unsqueeze(data: NodeInput, axes: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Perform unsqueeze operation on input tensor.\n\n    Insert single-dimensional entries to the shape of a tensor. Takes one required argument axes,\n    a list of dimensions that will be inserted.\n    Dimension indices in axes are as seen in the output tensor.\n\n    For example: Inputs: tensor with shape [3, 4, 5], axes=[0, 4]\n                 Result: tensor with shape [1, 3, 4, 5, 1]\n\n    :param data: The node with data tensor.\n    :param axes: List of non-negative integers, indicate the dimensions to be inserted.\n                  One of: input node or array.\n    :return: The new node performing an unsqueeze operation on input tensor.\n    """"""\n    return _get_node_factory().create(""Unsqueeze"", as_nodes(data, axes))\n\n\ndef grn(data: Node, bias: float, name: Optional[str] = None) -> Node:\n    r""""""Perform Global Response Normalization with L2 norm (across channels only).\n\n    Computes GRN operation on channels for input tensor:\n\n    .. math:: output_i = \\dfrac{input_i}{\\sqrt{\\sum_{i}^{C} input_i}}\n\n    :param data: The node with data tensor.\n    :param bias: The bias added to the variance. Scalar value.\n    :param name: Optional output node name.\n    :return: The new node performing a GRN operation on tensor\'s channels.\n    """"""\n    return _get_node_factory().create(""GRN"", [data], {""bias"": bias})\n\n\n@nameable_op\ndef gather(\n    data: NodeInput, indices: NodeInput, axis: NodeInput, name: Optional[str] = None\n) -> Node:\n    """"""Return Gather node which takes slices from axis of data according to indices.\n\n    :param data: The tensor from which slices are gathered.\n    :param indices: Tensor with indexes to gather.\n    :param axis: The dimension index to gather data from.\n    :param name: Optional name for output node.\n    :return: The new node performing a Gather operation on the data input tensor.\n    """"""\n    node_inputs = as_nodes(data, indices, axis)\n    return _get_node_factory().create(""Gather"", node_inputs)\n\n\n@nameable_op\ndef gather_tree(\n    step_ids: NodeInput,\n    parent_idx: NodeInput,\n    max_seq_len: NodeInput,\n    end_token: NodeInput,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform GatherTree operation.\n\n    The GatherTree node generates the complete beams from the indices per each step\n    and the parent beam indices.\n    GatherTree uses the following logic:\n\n    .. code-block:: python\n\n        for batch in range(BATCH_SIZE):\n            for beam in range(BEAM_WIDTH):\n                max_sequence_in_beam = min(MAX_TIME, max_seq_len[batch])\n\n                parent = parent_idx[max_sequence_in_beam - 1, batch, beam]\n\n                for level in reversed(range(max_sequence_in_beam - 1)):\n                    final_idx[level, batch, beam] = step_idx[level, batch, parent]\n\n                    parent = parent_idx[level, batch, parent]\n\n\n    :param step_ids: The tensor with indices from per each step.\n    :param parent_idx: The tensor with with parent beam indices.\n    :param max_seq_len: The tensor with maximum lengths for each sequence in the batch.\n    :param end_token: The scalar tensor with value of the end marker in a sequence.\n    :param name: Optional name for output node.\n    :return: The new node performing a GatherTree operation.\n    """"""\n    node_inputs = as_nodes(step_ids, parent_idx, max_seq_len, end_token)\n    return _get_node_factory().create(""GatherTree"", node_inputs)\n\n\n@nameable_op\ndef group_convolution(\n    data: NodeInput,\n    filters: NodeInput,\n    strides: List[int],\n    pads_begin: List[int],\n    pads_end: List[int],\n    dilations: List[int],\n    auto_pad: str = ""EXPLICIT"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform Group Convolution operation on data from input node.\n\n    :param data:        The node producing input data.\n    :param filters:     The node producing filters data.\n    :param strides:     The distance (in pixels) to slide the filter on the feature map\n                        over the axes.\n    :param pads_begin:  The number of pixels to add at the beginning along each axis.\n    :param pads_end:    The number of pixels to add at the end along each axis.\n    :param dilations:   The distance in width and height between elements (weights) in the filter.\n    :param auto_pad:    Describes how to perform padding. Possible values:\n                        EXPLICIT:   Pad dimensions are explicity specified\n                        SAME_LOWER: Pad dimensions computed to match input shape\n                                    Ceil(num_dims/2) at the beginning and\n                                    Floor(num_dims/2) at the end\n                        SAME_UPPER: Pad dimensions computed to match input shape\n                                    Floor(num_dims/2) at the beginning and\n                                    Ceil(num_dims/2) at the end\n                        VALID:      No padding\n    :param name: Optional output node name.\n    :return: The new node performing a Group Convolution operation on tensor from input node.\n    """"""\n    return _get_node_factory().create(\n        ""GroupConvolution"",\n        as_nodes(data, filters),\n        {\n            ""strides"": strides,\n            ""pads_begin"": pads_begin,\n            ""pads_end"": pads_end,\n            ""dilations"": dilations,\n            ""auto_pad"": auto_pad.upper(),\n        },\n    )\n\n\n@nameable_op\ndef group_convolution_backprop_data(\n    data: NodeInput,\n    filters: NodeInput,\n    strides: List[int],\n    output_shape: Optional[NodeInput] = None,\n    pads_begin: Optional[List[int]] = None,\n    pads_end: Optional[List[int]] = None,\n    dilations: Optional[List[int]] = None,\n    auto_pad: str = ""EXPLICIT"",\n    output_padding: Optional[List[int]] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform Group Convolution operation on data from input node.\n\n    :param data:            The node producing input data.\n    :param filters:         The node producing filter data.\n    :param strides:         The distance (in pixels) to slide the filter on the feature map\n                            over the axes.\n    :param output_shape:    The node that specifies spatial shape of the output.\n    :param pads_begin:      The number of pixels to add at the beginning along each axis.\n    :param pads_end:        The number of pixels to add at the end along each axis.\n    :param dilations:       The distance in width and height between elements (weights)\n                            in the filter.\n    :param auto_pad:        Describes how to perform padding. Possible values:\n                            EXPLICIT:   Pad dimensions are explicity specified\n                            SAME_LOWER: Pad dimensions computed to match input shape\n                                        Ceil(num_dims/2) at the beginning and\n                                        Floor(num_dims/2) at the end\n                            SAME_UPPER: Pad dimensions computed to match input shape\n                                        Floor(num_dims/2) at the beginning and\n                                        Ceil(num_dims/2) at the end\n                            VALID:      No padding\n    :param output_padding:  The additional amount of paddings added per each spatial axis\n                            in the output tensor.\n    :param name: Optional output node name.\n    :return: The new node performing a Group Convolution operation on tensor from input node.\n    """"""\n    spatial_dim_count = len(strides)\n    if dilations is None:\n        dilations = [1] * spatial_dim_count\n    if output_padding is None:\n        output_padding = [0] * spatial_dim_count\n\n    attributes = {\n        ""strides"": strides,\n        ""dilations"": dilations,\n        ""auto_pad"": auto_pad.upper(),\n        ""output_padding"": output_padding,\n    }\n    args = as_nodes(data, filters)\n\n    if output_shape is not None:\n        args.append(as_node(output_shape))\n    else:\n        if pads_begin is None:\n            pads_begin = [0] * spatial_dim_count\n        if pads_end is None:\n            pads_end = [0] * spatial_dim_count\n        attributes[""pads_begin""] = pads_begin\n        attributes[""pads_end""] = pads_end\n\n    return _get_node_factory().create(""GroupConvolutionBackpropData"", args, attributes)\n\n\n@nameable_op\ndef lstm_cell(\n    X: NodeInput,\n    initial_hidden_state: NodeInput,\n    initial_cell_state: NodeInput,\n    W: NodeInput,\n    R: NodeInput,\n    B: NodeInput,\n    hidden_size: int,\n    activations: List[str] = None,\n    activations_alpha: List[float] = None,\n    activations_beta: List[float] = None,\n    clip: float = 0.0,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which performs LSTMCell operation.\n\n    :param X: The input tensor with shape: [batch_size, input_size].\n    :param initial_hidden_state: The hidden state tensor with shape: [batch_size, hidden_size].\n    :param initial_cell_state: The cell state tensor with shape: [batch_size, hidden_size].\n    :param W: The weight tensor with shape: [4*hidden_size, input_size].\n    :param R: The recurrence weight tensor with shape: [4*hidden_size, hidden_size].\n    :param B: The bias tensor for gates with shape: [4*hidden_size].\n    :param hidden_size: Specifies hidden state size.\n    :param activations: The list of three activation functions for gates.\n    :param activations_alpha: The list of alpha parameters for activation functions.\n    :param activations_beta: The list of beta parameters for activation functions.\n    :param clip: Specifies bound values [-C, C] for tensor clipping performed before activations.\n    :param name: An optional name of the output node.\n\n    :return: The new node represents LSTMCell. Node outputs count: 2.\n    """"""\n    if activations is None:\n        activations = [""sigmoid"", ""tanh"", ""tanh""]\n    if activations_alpha is None:\n        activations_alpha = []\n    if activations_beta is None:\n        activations_beta = []\n\n    node_inputs = as_nodes(X, initial_hidden_state, initial_cell_state, W, R, B)\n\n    # P - nGraph additional input, no such input in the OV spec\n    peepholes_count = 3  # nGraph default\n    peepholes_shape = [peepholes_count * hidden_size]\n    peepholes_array = np.zeros(peepholes_shape)  # nGraph default\n    data_dtype = get_dtype(node_inputs[0].get_output_element_type(0))\n    default_P = make_constant_node(peepholes_array, dtype=data_dtype)\n    node_inputs.append(default_P)\n\n    weights_format = ""fico""  # IE LSTMWeightsFormat, no such attribute in the OV spec\n    input_forget = False  # nGraph default, no such attribute in the OV spec\n\n    attributes = {\n        ""hidden_size"": hidden_size,\n        ""activations"": activations,\n        ""activations_alpha"": activations_alpha,\n        ""activations_beta"": activations_beta,\n        ""clip"": clip,\n        ""weights_format"": weights_format,\n        ""input_forget"": input_forget,\n    }\n    return _get_node_factory().create(""LSTMCell"", node_inputs, attributes)\n\n\n@nameable_op\ndef lstm_sequence(\n    X: NodeInput,\n    initial_hidden_state: NodeInput,\n    initial_cell_state: NodeInput,\n    sequence_lengths: NodeInput,\n    W: NodeInput,\n    R: NodeInput,\n    B: NodeInput,\n    hidden_size: int,\n    direction: str,\n    activations: List[str] = None,\n    activations_alpha: List[float] = None,\n    activations_beta: List[float] = None,\n    clip: float = 0.0,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which performs LSTMSequence operation.\n\n    :param X: The input tensor. Shape: [seq_length, batch_size, input_size].\n    :param initial_hidden_state:    The hidden state tensor.\n                                    Shape: [num_directions, batch_size, hidden_size].\n    :param initial_cell_state:      The cell state tensor.\n                                    Shape: [num_directions, batch_size, hidden_size].\n    :param sequence_lengths:        Specifies real sequence lengths for each batch element.\n                                    Shape: [batch_size]. Integer type.\n    :param W: Tensor with weights for matrix multiplication operation with input portion of data.\n              Shape: [num_directions, 4*hidden_size, input_size].\n    :param R: The tensor with weights for matrix multiplication operation with hidden state.\n              Shape: [num_directions, 4*hidden_size, input_size].\n    :param B: The tensor with biases.\n              Shape: [num_directions, 4*hidden_size, hidden_size].\n    :param hidden_size: Specifies hidden state size.\n    :param direction: Specifies if the RNN is forward, reverse, or bidirectional.\n    :param activations: The list of three activation functions for gates.\n    :param activations_alpha: The list of alpha parameters for activation functions.\n    :param activations_beta: The list of beta parameters for activation functions.\n    :param clip: Specifies bound values [-C, C] for tensor clipping performed before activations.\n    :param name: An optional name of the output node.\n\n    :return: The new node represents LSTMSequence. Node outputs count: 3.\n    """"""\n    if activations is None:\n        activations = [""sigmoid"", ""tanh"", ""tanh""]\n    if activations_alpha is None:\n        activations_alpha = []\n    if activations_beta is None:\n        activations_beta = []\n\n    node_inputs = as_nodes(X, initial_hidden_state, initial_cell_state, sequence_lengths, W, R, B)\n\n    # P - nGraph additional input, no such input in the OV spec\n    peepholes_count = 3  # nGraph default\n    if direction.lower() == ""bidirectional"":\n        num_directions = 2\n    else:\n        num_directions = 1\n    peepholes_shape = [num_directions, peepholes_count * hidden_size]\n    peepholes_array = np.zeros(peepholes_shape)  # nGraph default\n    data_dtype = get_dtype(node_inputs[0].get_output_element_type(0))\n    default_P = make_constant_node(peepholes_array, dtype=data_dtype)\n    node_inputs.append(default_P)\n\n    weights_format = ""fico""  # IE LSTMWeightsFormat, no such attribute in the OV spec\n    input_forget = False  # nGraph default, no such attribute in the OV spec\n\n    attributes = {\n        ""hidden_size"": hidden_size,\n        ""direction"": direction.lower(),\n        ""activations"": activations,\n        ""activations_alpha"": activations_alpha,\n        ""activations_beta"": activations_beta,\n        ""clip"": clip,\n        ""weights_format"": weights_format,\n        ""input_forget"": input_forget,\n    }\n    return _get_node_factory().create(""LSTMSequence"", node_inputs, attributes)\n\n\n@nameable_op\ndef gru_cell(\n    X: NodeInput,\n    initial_hidden_state: NodeInput,\n    W: NodeInput,\n    R: NodeInput,\n    B: NodeInput,\n    hidden_size: int,\n    activations: List[str] = None,\n    activations_alpha: List[float] = None,\n    activations_beta: List[float] = None,\n    clip: float = 0.0,\n    linear_before_reset: bool = False,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform GRUCell operation on the tensor from input node.\n\n    GRUCell represents a single GRU Cell that computes the output\n    using the formula described in the paper: https://arxiv.org/abs/1406.1078\n\n    Note this class represents only single *cell* and not whole *layer*.\n\n    :param X:                       The input tensor with shape: [batch_size, input_size].\n    :param initial_hidden_state:    The hidden state tensor at current time step with shape:\n                                    [batch_size, hidden_size].\n    :param W:                       The weights for matrix multiplication, gate order: zrh.\n                                    Shape: [3*hidden_size, input_size].\n    :param R:                       The recurrence weights for matrix multiplication.\n                                    Shape: [3*hidden_size, hidden_size].\n    :param B:                       The sum of biases (weight and recurrence).\n                                    For linear_before_reset set True the shape is [4*hidden_size].\n                                    Otherwise the shape is [3*hidden_size].\n    :param hidden_size:             The number of hidden units for recurrent cell.\n                                    Specifies hidden state size.\n    :param activations:             The vector of activation functions used inside recurrent cell.\n    :param activation_alpha:        The vector of alpha parameters for activation functions in\n                                    order respective to activation list.\n    :param activation_beta:         The vector of beta parameters for activation functions in order\n                                    respective to activation list.\n    :param clip:                    The value defining clipping range [-clip, clip] on input of\n                                    activation functions.\n    :param linear_before_reset:     Flag denotes if the layer behaves according to the modification\n                                    of GRUCell described in the formula in the ONNX documentation.\n    :param name:                    Optional output node name.\n    :returns:   The new node performing a GRUCell operation on tensor from input node.\n    """"""\n    if activations is None:\n        activations = [""relu"", ""sigmoid"", ""tanh""]\n    if activations_alpha is None:\n        activations_alpha = []\n    if activations_beta is None:\n        activations_beta = []\n\n    input_nodes = as_nodes(X, initial_hidden_state, W, R, B)\n    attributes = {\n        ""hidden_size"": hidden_size,\n        ""activations"": activations,\n        ""activations_alpha"": activations_alpha,\n        ""activations_beta"": activations_beta,\n        ""linear_before_reset"": linear_before_reset,\n        ""clip"": clip,\n    }\n    return _get_node_factory().create(""GRUCell"", input_nodes, attributes)\n\n\n@nameable_op\ndef rnn_cell(\n    X: NodeInput,\n    initial_hidden_state: NodeInput,\n    W: NodeInput,\n    R: NodeInput,\n    B: NodeInput,\n    hidden_size: int,\n    activations: List[str],\n    activations_alpha: List[float],\n    activations_beta: List[float],\n    clip: float = 0.0,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform RNNCell operation on tensor from input node.\n\n    It follows notation and equations defined as in ONNX standard:\n    https://github.com/onnx/onnx/blob/master/docs/Operators.md#RNN\n\n    Note this class represents only single *cell* and not whole RNN *layer*.\n\n    :param X:                       The input tensor with shape: [batch_size, input_size].\n    :param initial_hidden_state:    The hidden state tensor at current time step with shape:\n                                    [batch_size, hidden_size].\n    :param W:                       The weight tensor with shape: [hidden_size, input_size].\n    :param R:                       The recurrence weight tensor with shape: [hidden_size,\n                                    hidden_size].\n    :param B:                       The bias tensor for input gate with shape: [2*hidden_size].\n    :param hidden_size:             The number of hidden units for recurrent cell.\n                                    Specifies hidden state size.\n    :param activations:             The vector of activation functions used inside recurrent cell.\n    :param activation_alpha:        The vector of alpha parameters for activation functions in\n                                    order respective to activation list.\n    :param activation_beta:         The vector of beta parameters for activation functions in order\n                                    respective to activation list.\n    :param clip:                    The value defining clipping range [-clip, clip] on input of\n                                    activation functions.\n    :param name:                    Optional output node name.\n    :returns:   The new node performing a RNNCell operation on tensor from input node.\n    """"""\n    if activations is None:\n        activations = [""sigmoid"", ""tanh""]\n    if activations_alpha is None:\n        activations_alpha = []\n    if activations_beta is None:\n        activations_beta = []\n\n    input_nodes = as_nodes(X, initial_hidden_state, W, R, B)\n    attributes = {\n        ""hidden_size"": hidden_size,\n        ""activations"": activations,\n        ""activations_alpha"": activations_alpha,\n        ""activations_beta"": activations_beta,\n        ""clip"": clip,\n    }\n    return _get_node_factory().create(""RNNCell"", input_nodes, attributes)\n\n\n@nameable_op\ndef space_to_depth(data: Node, mode: str, block_size: int = 1, name: str = None) -> Node:\n    """"""Perform SpaceToDepth operation on the input tensor.\n\n    SpaceToDepth rearranges blocks of spatial data into depth.\n    The operator returns a copy of the input tensor where values from the height\n    and width dimensions are moved to the depth dimension.\n\n    :param data: The node with data tensor.\n    :param mode: Specifies how the output depth dimension is gathered from block coordinates.\n\n                 blocks_first: The output depth is gathered from [block_size, ..., block_size, C]\n                 depth_first: The output depth is gathered from [C, block_size, ..., block_size]\n\n    :param block_size: The size of the block of values to be moved. Scalar value.\n    :param name: Optional output node name.\n    :return: The new node performing a SpaceToDepth operation on input tensor.\n    """"""\n    return _get_node_factory().create(\n        ""SpaceToDepth"", [data], {""mode"": mode, ""block_size"": block_size},\n    )\n\n\n@nameable_op\ndef batch_to_space(\n    data: NodeInput,\n    block_shape: NodeInput,\n    crops_begin: NodeInput,\n    crops_end: NodeInput,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform BatchToSpace operation on the input tensor.\n\n    BatchToSpace permutes data from the batch dimension of the data tensor into spatial dimensions.\n\n    :param data: Node producing the data tensor.\n    :param block_shape: The sizes of the block of values to be moved.\n    :param crops_begin: Specifies the amount to crop from the beginning along each axis of `data`.\n    :param crops_end: Specifies the amount to crop from the end along each axis of `data`.\n    :param name: Optional output node name.\n    :return: The new node performing a BatchToSpace operation.\n    """"""\n    return _get_node_factory().create(\n        ""BatchToSpace"", as_nodes(data, block_shape, crops_begin, crops_end)\n    )\n\n\n@nameable_op\ndef space_to_batch(\n    data: NodeInput,\n    block_shape: NodeInput,\n    pads_begin: NodeInput,\n    pads_end: NodeInput,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform SpaceToBatch operation on the input tensor.\n\n    SpaceToBatch permutes data tensor blocks of spatial data into batch dimension.\n    The operator returns a copy of the input tensor where values from spatial blocks dimensions\n    are moved in the batch dimension\n\n    :param data: Node producing the data tensor.\n    :param block_shape: The sizes of the block of values to be moved.\n    :param pads_begin: Specifies the padding for the beginning along each axis of `data`.\n    :param pads_end: Specifies the padding for the ending along each axis of `data`.\n    :param name: Optional output node name.\n    :return: The new node performing a SpaceToBatch operation.\n    """"""\n    return _get_node_factory().create(\n        ""SpaceToBatch"", as_nodes(data, block_shape, pads_begin, pads_end)\n    )\n\n\n@nameable_op\ndef mvn(\n    data: Node,\n    across_channels: bool = False,\n    normalize_variance: bool = False,\n    eps: float = 1e-9,\n    name: str = None,\n) -> Node:\n    r""""""Perform Mean Variance Normalization operation on data from input node.\n\n    Computes MVN on the input tensor :code:`data` (called `X`) using formula:\n\n    .. math:: Y = \\dfrac{X-EX}{\\sqrt{E(X-EX)^2}}\n\n    :param data: The node with data tensor.\n    :param across_channels: Denotes if mean values are shared across channels.\n    :param normalize_variance: Denotes whether to perform variance normalization.\n    :param eps: The number added to the variance to avoid division by zero\n               when normalizing the value. Scalar value.\n    :param name: Optional output node name.\n    :return: The new node performing a MVN operation on input tensor.\n    """"""\n    return _get_node_factory().create(\n        ""MVN"",\n        [data],\n        {""across_channels"": across_channels, ""normalize_variance"": normalize_variance, ""eps"": eps},\n    )\n\n\n# Unary ops\n@unary_op\ndef absolute(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies f(x) = abs(x) to the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with Abs operation applied on it.\n    """"""\n    return _get_node_factory().create(""Abs"", [node])\n\n\n@unary_op\ndef acos(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Apply inverse cosine function on the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with arccos operation applied on it.\n    """"""\n    return _get_node_factory().create(""Acos"", [node])\n\n\n@unary_op\ndef asin(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Apply inverse sine function on the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with arcsin operation applied on it.\n    """"""\n    return _get_node_factory().create(""Asin"", [node])\n\n\n@unary_op\ndef atan(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Apply inverse tangent function on the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with arctan operation applied on it.\n    """"""\n    return _get_node_factory().create(""Atan"", [node])\n\n\n@unary_op\ndef cos(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Apply cosine function on the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with cos operation applied on it.\n    """"""\n    return _get_node_factory().create(""Cos"", [node])\n\n\n@unary_op\ndef cosh(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Apply hyperbolic cosine function on the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with cosh operation applied on it.\n    """"""\n    return _get_node_factory().create(""Cosh"", [node])\n\n\n@unary_op\ndef sqrt(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies square root to the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: The new node with sqrt operation applied element-wise.\n    """"""\n    return _get_node_factory().create(""Sqrt"", [node])\n\n\n@unary_op\ndef erf(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which calculates Gauss error function element-wise with given tensor.\n\n    :param node: The node providing data for operation.\n    :param name: The optional name for new output node.\n    :return: The new node performing element-wise Erf operation.\n    """"""\n    return _get_node_factory().create(""Erf"", [node])\n\n\n@unary_op\ndef exp(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies exponential function to the input node element-wise.\n\n    :param node: The node providing data for operation.\n    :param name: The optional name for new output node.\n    :return: The new node performing natural exponential operation.\n    """"""\n    return _get_node_factory().create(""Exp"", [node])\n\n\n@unary_op\ndef log(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies natural logarithm to the input node element-wise.\n\n    :param node: The input node providing data for operation.\n    :param name: The optional new name for output node.\n    :return: The new node performing log operation element-wise.\n    """"""\n    return _get_node_factory().create(""Log"", [node])\n\n\n@unary_op\ndef negative(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies f(x) = -x to the input node elementwise.""""""\n    return _get_node_factory().create(""Negative"", [node])\n\n\n@unary_op\ndef floor(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies floor to the input node element-wise.\n\n    :param node: The input node providing data.\n    :param name: The optional name for new output node.\n    :return: The node performing element-wise floor operation.\n    """"""\n    return _get_node_factory().create(""Floor"", [node])\n\n\n@unary_op\ndef ceiling(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies ceiling to the input node element-wise.\n\n    :param node: The node providing data to ceiling operation.\n    :param name: Optional name for output node.\n    :return: The node performing element-wise ceiling.\n    """"""\n    return _get_node_factory().create(""Ceiling"", [node])\n\n\n@nameable_op\ndef reshape(\n    node: NodeInput, output_shape: NodeInput, special_zero: bool, name: Optional[str] = None\n) -> Node:\n    """"""Return reshaped node according to provided parameters.\n\n    :param node: The tensor we want to reshape.\n    :param output_shape: The node with a new shape for input tensor.\n    :param special_zero: The boolean variable that controls how zero values in shape are\n                         interpreted. If special_zero is false, then 0 is interpreted as-is\n                         which means that output shape will contain a zero dimension at the\n                         specified location. Input and output tensors are empty in this case.\n                         If special_zero is true, then all zeros in shape implies the copying\n                         of corresponding dimensions from data.shape into the output shape.\n                         Range of values: False or True\n    """"""\n    return _get_node_factory().create(\n        ""Reshape"", as_nodes(node, output_shape), {""special_zero"": special_zero}\n    )\n\n\n@unary_op\ndef relu(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Perform rectified linear unit operation on input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: The optional output node name.\n    :return: The new node performing relu operation on its input element-wise.\n    """"""\n    return _get_node_factory().create(""Relu"", [node])\n\n\n@nameable_op\ndef selu(\n    data: NodeInput, alpha: NodeInput, lambda_value: NodeInput, name: Optional[str] = None\n) -> Node:\n    """"""Perform a Scaled Exponential Linear Unit (SELU) operation on input node element-wise.\n\n    :param data: input node, array or scalar.\n    :param alpha: Alpha coefficient of SELU operation\n    :param lambda_value: Lambda coefficient of SELU operation\n    :param name: The optional output node name.\n    :return: The new node performing relu operation on its input element-wise.\n    """"""\n    return _get_node_factory().create(""Selu"", as_nodes(data, alpha, lambda_value))\n\n\n@unary_op\ndef sign(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Perform element-wise sign operation.\n\n    :param node: One of: input node, array or scalar.\n    :param name: The optional new name for output node.\n    :return: The node with mapped elements of the input tensor to -1 (if it is negative),\n             0 (if it is zero), or 1 (if it is positive).\n    """"""\n    return _get_node_factory().create(""Sign"", [node])\n\n\n@unary_op\ndef sin(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Apply sine function on the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with sin operation applied on it.\n    """"""\n    return _get_node_factory().create(""Sin"", [node])\n\n\n@unary_op\ndef sinh(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Apply hyperbolic sine function on the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with sin operation applied on it.\n    """"""\n    return _get_node_factory().create(""Sinh"", [node])\n\n\n@unary_op\ndef tan(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Apply tangent function on the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with tan operation applied on it.\n    """"""\n    return _get_node_factory().create(""Tan"", [node])\n\n\n# Binary ops\n@binary_op\ndef divide(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which applies f(x) = A/B to the input nodes element-wise.\n\n    :param left_node: The node providing dividend data.\n    :param right_node: The node providing divisor data.\n    :param auto_broadcast: Specifies rules used for auto-broadcasting of input tensors.\n    :param name: Optional name for output node.\n    :return: The node performing element-wise division.\n    """"""\n    return _get_node_factory().create(\n        ""Divide"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef floor_mod(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node performing element-wise FloorMod (division reminder) with two given tensors.\n\n    :param left_node: The first input node for FloorMod operation.\n    :param right_node: The second input node for FloorMod operation.\n    :param auto_broadcast: Specifies rules used for auto-broadcasting of input tensors.\n    :param name: Optional name for output node.\n    :return: The node performing element-wise FloorMod operation.\n    """"""\n    return _get_node_factory().create(\n        ""FloorMod"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef mod(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node performing element-wise division reminder with two given tensors.\n\n    :param left_node: The first input node for mod operation.\n    :param right_node: The second input node for mod operation.\n    :param auto_broadcast: Specifies rules used for auto-broadcasting of input tensors.\n    :param name: Optional name for output node.\n    :return: The node performing element-wise Mod operation.\n    """"""\n    return _get_node_factory().create(\n        ""Mod"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef multiply(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which applies f(x) = A*B to the input nodes elementwise.""""""\n    return _get_node_factory().create(\n        ""Multiply"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef subtract(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which applies f(x) = A-B to the input nodes element-wise.\n\n    :param left_node: The node providing data for left hand side of operator.\n    :param right_node: The node providing data for right hand side of operator.\n    :param auto_broadcast: The type of broadcasting that specifies mapping of input tensor axes\n                           to output shape axes. Range of values: numpy, explicit.\n    :param name: The optional name for output node.\n    :return: The new output node performing subtraction operation on both tensors element-wise.\n    """"""\n    return _get_node_factory().create(\n        ""Subtract"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef add(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which applies f(x) = A+B to the input nodes element-wise.""""""\n    return _get_node_factory().create(\n        ""Add"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef minimum(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which applies the minimum operation to input nodes elementwise.""""""\n    return _get_node_factory().create(\n        ""Minimum"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef maximum(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which applies the maximum operation to input nodes elementwise.""""""\n    return _get_node_factory().create(\n        ""Maximum"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef power(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which perform element-wise exponentiation operation.\n\n    :param left_node: The node providing the base of operation.\n    :param right_node: The node providing the exponent of operation.\n    :param name: The optional name for the new output node.\n    :param auto_broadcast: The type of broadcasting specifies rules used for\n                           auto-broadcasting of input tensors.\n    :return: The new node performing element-wise exponentiation operation on input nodes.\n    """"""\n    return _get_node_factory().create(\n        ""Power"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n# Logical ops\n@binary_op\ndef equal(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which checks if input nodes are equal element-wise.\n\n    :param left_node: The first input node for equal operation.\n    :param right_node: The second input node for equal operation.\n    :param auto_broadcast: The type of broadcasting specifies rules used for\n                           auto-broadcasting of input tensors.\n    :param name: The optional name for output new node.\n    :return: The node performing element-wise equality check.\n    """"""\n    return _get_node_factory().create(\n        ""Equal"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef not_equal(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which checks if input nodes are unequal element-wise.\n\n    :param left_node: The first input node for not-equal operation.\n    :param right_node: The second input node for not-equal operation.\n    :param auto_broadcast: The type of broadcasting specifies rules used for\n                           auto-broadcasting of input tensors.\n    :param name: The optional name for output new node.\n    :return: The node performing element-wise inequality check.\n    """"""\n    return _get_node_factory().create(\n        ""NotEqual"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef greater(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which checks if left input node is greater than the right node element-wise.\n\n    :param left_node: The first input node providing data.\n    :param right_node: The second input node providing data.\n    :param auto_broadcast: The type of broadcasting specifies rules used for\n                           auto-broadcasting of input tensors.\n    :param name: The optional new name for output node.\n    :return: The node performing element-wise check whether left_node is greater than right_node.\n    """"""\n    return _get_node_factory().create(\n        ""Greater"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef greater_equal(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which checks if left node is greater or equal to the right node element-wise.\n\n    :param left_node: The first input node providing data.\n    :param right_node: The second input node providing data.\n    :param auto_broadcast: The type of broadcasting specifies rules used for\n                           auto-broadcasting of input tensors.\n    :param name: The optional new name for output node.\n    :return: The node performing element-wise check whether left_node is greater than or equal\n             right_node.\n    """"""\n    return _get_node_factory().create(\n        ""GreaterEqual"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef less(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which checks if left input node is less than the right node element-wise.\n\n    :param left_node: The first input node providing data.\n    :param right_node: The second input node providing data.\n    :param auto_broadcast: The type of broadcasting specifies rules used for\n                           auto-broadcasting of input tensors.\n    :param name: The optional new name for output node.\n    :return: The node performing element-wise check whether left_node is less than the right_node.\n    """"""\n    return _get_node_factory().create(\n        ""Less"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef less_equal(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which checks if left input node is less or equal the right node element-wise.\n\n    :param left_node: The first input node providing data.\n    :param right_node: The second input node providing data.\n    :param auto_broadcast: The type of broadcasting specifies rules used for\n                           auto-broadcasting of input tensors.\n    :param name: The optional new name for output node.\n    :return: The node performing element-wise check whether left_node is less than or equal the\n             right_node.\n    """"""\n    return _get_node_factory().create(\n        ""LessEqual"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef logical_and(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which perform logical and operation on input nodes element-wise.\n\n    :param left_node: The first input node providing data.\n    :param right_node: The second input node providing data.\n    :param auto_broadcast: The type of broadcasting that specifies mapping of input tensor axes\n                           to output shape axes. Range of values: numpy, explicit.\n    :param name: The optional new name for output node.\n    :return: The node performing logical and operation on input nodes corresponding elements.\n    """"""\n    return _get_node_factory().create(\n        ""LogicalAnd"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef logical_or(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which performs logical OR operation on input nodes element-wise.\n\n    :param left_node: The first input node providing data.\n    :param right_node: The second input node providing data.\n    :param auto_broadcast: The type of broadcasting that specifies mapping of input tensor axes\n                           to output shape axes. Range of values: numpy, explicit.\n    :param name: The optional new name for output node.\n    :return: The node performing logical or operation on input nodes corresponding elements.\n    """"""\n    return _get_node_factory().create(\n        ""LogicalOr"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@binary_op\ndef logical_xor(\n    left_node: NodeInput,\n    right_node: NodeInput,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node which performs logical XOR operation on input nodes element-wise.\n\n    :param left_node: The first input node providing data.\n    :param right_node: The second input node providing data.\n    :param auto_broadcast: The type of broadcasting that specifies mapping of input tensor axes\n                           to output shape axes. Range of values: numpy, explicit.\n    :param name: The optional new name for output node.\n    :return: The node performing logical or operation on input nodes corresponding elements.\n    """"""\n    return _get_node_factory().create(\n        ""LogicalXor"", [left_node, right_node], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n@unary_op\ndef logical_not(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies element-wise logical negation to the input node.\n\n    :param node: The input node providing data.\n    :param name: The optional new name for output node.\n    :return: The node performing element-wise logical NOT operation with given tensor.\n    """"""\n    return _get_node_factory().create(""LogicalNot"", [node])\n\n\n@binary_op\ndef squared_difference(\n    x1: NodeInput, x2: NodeInput, auto_broadcast: str = ""NUMPY"", name: Optional[str] = None\n) -> Node:\n    """"""Perform an element-wise squared difference between two tensors.\n\n    .. math:: y[i] = (x_1[i] - x_2[i])^2\n\n    :param x1: The node with first input tensor.\n    :param x2: The node with second input tensor.\n    :param auto_broadcast: The type of broadcasting that specifies mapping of input tensor axes\n                           to output shape axes. Range of values: numpy, explicit.\n    :param name: Optional new name for output node.\n    :return: The new node performing a squared difference between two tensors.\n    """"""\n    return _get_node_factory().create(\n        ""SquaredDifference"", [x1, x2], {""auto_broadcast"": auto_broadcast.upper()}\n    )\n\n\n# Extend Node class to support binary operators\nNode.__add__ = add\nNode.__sub__ = subtract\nNode.__mul__ = multiply\nNode.__div__ = divide\nNode.__truediv__ = divide\nNode.__radd__ = lambda left, right: add(right, left)\nNode.__rsub__ = lambda left, right: subtract(right, left)\nNode.__rmul__ = lambda left, right: multiply(right, left)\nNode.__rdiv__ = lambda left, right: divide(right, left)\nNode.__rtruediv__ = lambda left, right: divide(right, left)\nNode.__eq__ = equal\nNode.__ne__ = not_equal\nNode.__lt__ = less\nNode.__le__ = less_equal\nNode.__gt__ = greater\nNode.__ge__ = greater_equal\n\n\n# Custom ops\n@nameable_op\ndef broadcast(\n    data: NodeInput,\n    target_shape: NodeInput,\n    axes_mapping: Optional[NodeInput] = None,\n    broadcast_spec: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Create a node which broadcasts the input node\'s values along specified axes to a desired shape.\n\n    :param data: The node with input tensor data.\n    :param target_shape: The node with a new shape we want to broadcast tensor to.\n    :param axes_mapping: The node with a axis positions (0-based) in the result\n                           that are being broadcast.\n    :param broadcast_spec: The type of broadcasting that specifies mapping of input tensor axes\n                           to output shape axes. Range of values: NUMPY, EXPLICIT, BIDIRECTIONAL.\n    :param name: Optional new name for output node.\n    :return: New node with broadcast shape.\n    """"""\n    inputs = as_nodes(data, target_shape)\n    if broadcast_spec.upper() == ""EXPLICIT"":\n        inputs.append(as_node(axes_mapping))\n    return _get_node_factory().create(\n        ""Broadcast"", inputs, {""broadcast_spec"": broadcast_spec.upper()}\n    )\n\n\n@nameable_op\ndef fake_quantize(\n    data: NodeInput,\n    input_low: NodeInput,\n    input_high: NodeInput,\n    output_low: NodeInput,\n    output_high: NodeInput,\n    levels: int,\n    auto_broadcast: str = ""NUMPY"",\n    name: Optional[str] = None,\n) -> Node:\n    r""""""Perform an element-wise linear quantization on input data.\n\n    Input floating point values are quantized into a discrete set of floating point values.\n\n    .. code-block:: python\n        if x <= input_low:\n            output = output_low\n        if x > input_high:\n            output = output_high\n        else:\n            output = fake_quantize(output)\n\n    Fake quantize uses the following logic:\n\n    .. math:: output =\n            \\dfrac{round( \\dfrac{data - input\\_low}{(input\\_high - input\\_low)\\cdot (levels-1)})}\n            {(levels-1)\\cdot (output\\_high - output\\_low)} + output\\_low\n\n    :param data:           The node with data tensor.\n    :param input_low:      The node with the minimum for input values.\n    :param input_high:     The node with the maximum for input values.\n    :param output_low:     The node with the minimum quantized value.\n    :param output_high:    The node with the maximum quantized value.\n    :param levels:         The number of quantization levels. Integer value.\n    :param auto_broadcast: The type of broadcasting specifies rules used for\n                           auto-broadcasting of input tensors.\n    :return: New node with quantized value.\n    """"""\n    return _get_node_factory().create(\n        ""FakeQuantize"",\n        as_nodes(data, input_low, input_high, output_low, output_high),\n        {""levels"": levels, ""auto_broadcast"": auto_broadcast.upper()},\n    )\n\n\n@nameable_op\ndef convert(\n    data: NodeInput, destination_type: Union[str, NumericType], name: Optional[str] = None\n) -> Node:\n    """"""Return node which casts input node values to specified type.\n\n    :param data: Node which produces the input tensor.\n    :param destination_type: Provides the target type for the conversion.\n    :param name: Optional name for the output node.\n    :return: New node performing the conversion operation.\n    """"""\n    if not isinstance(destination_type, str):\n        destination_type = get_element_type_str(destination_type)\n    return _get_node_factory().create(\n        ""Convert"", [as_node(data)], {""destination_type"": destination_type.lower()}\n    )\n\n\n@binary_op\ndef convert_like(data: NodeInput, like: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which casts data node values to the type of another node.\n\n    :param data: Node which produces the input tensor\n    :param like: Node which provides the target type information for the conversion\n    :param name: Optional name for the output node.\n    :return: New node performing the conversion operation.\n    """"""\n    return _get_node_factory().create(""ConvertLike"", [data, like])\n\n\n@nameable_op\ndef depth_to_space(node: Node, mode: str, block_size: int = 1, name: str = None) -> Node:\n    """"""Rearranges input tensor from depth into blocks of spatial data.\n\n    Values from the height and width dimensions are moved to the depth dimension.\n\n    Input tensor has shape [N,C,H,W], where N is the batch axis, C is the channel or depth,\n    H is the height and W is the width.\n\n    Output node produces a tensor with shape:\n\n    [N, C * :code:`block_size` * :code:`block_size`, H / :code:`block_size`, W / :code:`block_size`]\n\n    :param node: The node with input tensor data.\n    :param mode: Specifies how the input depth dimension is split to block coordinates\n\n                 blocks_first: The input is divided to [block_size, ..., block_size, new_depth]\n                 depth_first: The input is divided to [new_depth, block_size, ..., block_size]\n\n    :param block_size: The size of the spatial block of values describing\n                       how the tensor\'s data is to be rearranged.\n    :param name: Optional output node name.\n    :return: The new node performing an DepthToSpace operation on its input tensor.\n    """"""\n    return _get_node_factory().create(\n        ""DepthToSpace"", [node], {""mode"": mode, ""block_size"": block_size},\n    )\n\n\n@unary_op\ndef gelu(node: NodeInput, name: Optional[str] = None) -> Node:\n    r""""""Perform Gaussian Error Linear Unit operation element-wise on data from input node.\n\n    Computes GELU function:\n\n    .. math:: f(x) = 0.5\\cdot x\\cdot(1 + erf( \\dfrac{x}{\\sqrt{2}})\n\n    For more information refer to:\n    `Gaussian Error Linear Unit (GELU) <https://arxiv.org/pdf/1606.08415.pdf>`_\n\n    :param node: Input tensor. One of: input node, array or scalar.\n    :param name: Optional output node name.\n    :return: The new node performing a GELU operation on its input data element-wise.\n    """"""\n    return _get_node_factory().create(""Gelu"", [node])\n\n\n@nameable_op\ndef select(\n    cond: NodeInput,\n    then_node: NodeInput,\n    else_node: NodeInput,\n    auto_broadcast: str = ""numpy"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform an element-wise selection operation on input tensors.\n\n    :param cond: Tensor with selection mask of type `boolean`.\n    :param then_node: Tensor providing data to be selected if respective `cond`\n                        item value is `True`.\n    :param else_node: Tensor providing data to be selected if respective `cond`\n                        item value is `False`.\n    :param auto_broadcast: Mode specifies rules used for auto-broadcasting of input tensors.\n    :param name: The optional new name for output node.\n    :return: The new node with values selected according to provided arguments.\n    """"""\n    inputs = as_nodes(cond, then_node, else_node)\n    return _get_node_factory().create(""Select"", inputs, {""auto_broadcast"": auto_broadcast.upper()})\n\n\n# Non-linear ops\n@unary_op\ndef tanh(node: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return node which applies hyperbolic tangent to the input node element-wise.\n\n    :param node: One of: input node, array or scalar.\n    :param name: Optional new name for output node.\n    :return: New node with tanh operation applied on it.\n    """"""\n    return _get_node_factory().create(""Tanh"", [node])\n\n\n@nameable_op\ndef clamp(\n    data: NodeInput, min_value: ScalarData, max_value: ScalarData, name: Optional[str] = None\n) -> Node:\n    """"""Perform clamp element-wise on data from input node.\n\n    Performs a clipping operation on an input value between a pair of boundary values.\n\n    For each element in :code:`data`, if the element\'s value is lower than :code:`min_value`,\n    it will be replaced with :code:`min_value`. If the value is higher than :code:`max_value`,\n    it will be replaced by :code:`max_value`.\n    Intermediate values of :code:`data` are returned without change.\n\n    Clamp uses the following logic:\n\n    .. code-block:: python\n\n        if data < min_value:\n            data=min_value\n        elif data > max_value:\n            data=max_value\n\n    :param data: Input tensor. One of: input node, array or scalar.\n    :param min_value: The lower bound of the <min_value;max_value> range. Scalar value.\n    :param max_value: The upper bound of the <min_value;max_value> range. Scalar value.\n    :param name: Optional output node name.\n    :return: The new node performing a clamp operation on its input data element-wise.\n    """"""\n    return _get_node_factory().create(\n        ""Clamp"", [as_node(data)], {""min"": min_value, ""max"": max_value}\n    )\n\n\n@nameable_op\ndef binary_convolution(\n    data: NodeInput,\n    filters: NodeInput,\n    strides: List[int],\n    pads_begin: List[int],\n    pads_end: List[int],\n    dilations: List[int],\n    mode: str,\n    pad_value: float,\n    auto_pad: str = ""EXPLICIT"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Create node performing convolution with binary weights, binary input and integer output.\n\n    :param data: The node providing data batch tensor.\n    :param filter: The node providing filters tensor.\n    :param strides: The kernel window movement strides.\n    :param pads_begin: The number of pixels to add to the beginning along each axis.\n    :param pads_end: The number of pixels to add to the end along each axis.\n    :param dilations: The distance in width and height between elements (weights) in the filter.\n    :param mode: Defines how input tensor 0/1 values and weights 0/1 are interpreted.\n    :param pad_value: Floating-point value used to fill pad area.\n    :param auto_pad: The type of padding. Range of values: explicit, same_upper, same_lower, valid.\n    :param name: The optional new name for output node.\n    :return: New node performing binary convolution operation.\n    """"""\n    return _get_node_factory().create(\n        ""BinaryConvolution"",\n        as_nodes(data, filters),\n        {\n            ""strides"": strides,\n            ""pads_begin"": pads_begin,\n            ""pads_end"": pads_end,\n            ""dilations"": dilations,\n            ""mode"": mode,\n            ""pad_value"": pad_value,\n            ""auto_pad"": auto_pad,\n        },\n    )\n\n\n# convpool ops\n@nameable_op\ndef convolution(\n    data: NodeInput,\n    filters: NodeInput,\n    strides: List[int],\n    pads_begin: List[int],\n    pads_end: List[int],\n    dilations: List[int],\n    auto_pad: str = ""EXPLICIT"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node performing batched convolution operation.\n\n    :param data: The node providing data batch tensor.\n    :param filter: The node providing filters tensor.\n    :param strides: The kernel window movement strides.\n    :param pads_begin: The number of zero padding elements to add on each axis below 0 coordinate.\n    :param pads_end: The number of zero padding elements to add on each axis above max coordinate\n    :param dilations: The data batch dilation strides.\n    :param auto_pad: The type of padding. Range of values: explicit, same_upper, same_lower, valid.\n    :param name: The optional new name for output node.\n    :return: New node performing batched convolution operation.\n    """"""\n    return _get_node_factory().create(\n        ""Convolution"",\n        as_nodes(data, filters),\n        {\n            ""strides"": strides,\n            ""pads_begin"": pads_begin,\n            ""pads_end"": pads_end,\n            ""dilations"": dilations,\n            ""auto_pad"": auto_pad,\n        },\n    )\n\n\n@nameable_op\ndef convolution_backprop_data(\n    data: NodeInput,\n    filters: NodeInput,\n    strides: List[int],\n    output_shape: Optional[NodeInput] = None,\n    pads_begin: Optional[List[int]] = None,\n    pads_end: Optional[List[int]] = None,\n    dilations: Optional[List[int]] = None,\n    auto_pad: Optional[str] = None,\n    output_padding: Optional[List[int]] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Create node performing a batched-convolution backprop data operation.\n\n    :param      data:         The node producing data from forward-prop\n    :param      filters:      The node producing the filters from forward-prop.\n    :param      output_shape: The node producing output delta.\n    :param      strides:      The distance (in pixels) to slide the filter on the feature map\n                              over the axes.\n    :param      pads_begin:   The number of pixels to add to the beginning along each axis.\n    :param      pads_end:     The number of pixels to add to the end along each axis.\n    :param      dilations:    The distance in width and height between elements (weights)\n                              in the filter.\n    :param      name:         The node name.\n\n    :returns:   The node object representing ConvolutionBackpropData  operation.\n    """"""\n    spatial_dim_count = len(strides)\n    if pads_begin is None:\n        pads_begin = [0] * spatial_dim_count\n    if pads_end is None:\n        pads_end = [0] * spatial_dim_count\n    if dilations is None:\n        dilations = [1] * spatial_dim_count\n    if auto_pad is None:\n        auto_pad = ""explicit""\n    if output_padding is None:\n        output_padding = [0] * spatial_dim_count\n    args = as_nodes(data, filters)\n    if output_shape is not None:\n        args.append(as_node(output_shape))\n\n    return _get_node_factory().create(\n        ""ConvolutionBackpropData"",\n        args,\n        {\n            ""strides"": strides,\n            ""pads_begin"": pads_begin,\n            ""pads_end"": pads_end,\n            ""dilations"": dilations,\n            ""auto_pad"": auto_pad.upper(),\n            ""output_padding"": output_padding,\n        },\n    )\n\n\n@nameable_op\ndef deformable_convolution(\n    data: NodeInput,\n    deformable_values: NodeInput,\n    filters: NodeInput,\n    strides: List[int],\n    pads_begin: List[int],\n    pads_end: List[int],\n    dilations: List[int],\n    auto_pad: str = ""EXPLICIT"",\n    group: int = 1,\n    deformable_group: int = 1,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Create node performing deformable convolution.\n\n    :param data: The node providing data batch tensor.\n    :param filter: The node providing filters tensor.\n    :param strides: The distance (in pixels) to slide the filter on the feature map over the axes.\n    :param pads_begin: The number of pixels to add to the beginning along each axis.\n    :param pads_end: The number of pixels to add to the end along each axis.\n    :param dilations: The distance in width and height between elements (weights) in the filter.\n    :param auto_pad: The type of padding. Range of values: explicit, same_upper, same_lower, valid.\n    :param group: The number of groups which both output and input should be split into.\n    :param deformable_group: The number of groups which deformable values and output should be split\n                             into along the channel axis.\n    :param name: The optional new name for output node.\n    :return: New node performing deformable convolution operation.\n    """"""\n    return _get_node_factory().create(\n        ""DeformableConvolution"",\n        as_nodes(data, deformable_values, filters),\n        {\n            ""strides"": strides,\n            ""pads_begin"": pads_begin,\n            ""pads_end"": pads_end,\n            ""dilations"": dilations,\n            ""auto_pad"": auto_pad,\n            ""group"": group,\n            ""deformable_group"": deformable_group,\n        },\n    )\n\n\n@nameable_op\ndef deformable_psroi_pooling(\n    feature_maps: NodeInput,\n    coords: NodeInput,\n    output_dim: int,\n    spatial_scale: float,\n    group_size: int = 1,\n    mode: str = ""bilinear_deformable"",\n    spatial_bins_x: int = 1,\n    spatial_bins_y: int = 1,\n    trans_std: float = 1.0,\n    part_size: int = 1,\n    offsets: Optional[NodeInput] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return node performing DeformablePSROIPooling operation.\n\n    DeformablePSROIPooling computes position-sensitive pooling\n    on regions of interest specified by input.\n\n    :param feature_maps: 4D tensor with feature maps.\n    :param coords: 2D tensor describing box consisting of tuples: [batch_id, x_1, y_1, x_2, y_2].\n    :param output_dim: A pooled output channel number.\n    :param spatial_scale: A multiplicative spatial scale factor to translate ROI.\n    :param group_size: The number of groups to encode position-sensitive score.\n    :param mode: Specifies mode for pooling. Range of values: [\'bilinear_deformable\'].\n    :param spatial_bins_x: Specifies numbers of bins to divide the input feature maps over width.\n    :param spatial_bins_y: Specifies numbers of bins to divide the input feature maps over height.\n    :param trans_std: The value that all transformation (offset) values are multiplied with.\n    :param part_size: The number of parts the output tensor spatial dimensions are divided into.\n    :param offsets: Optional node. 4D input blob with transformation values (offsets).\n    :param name: The optional new name for output node.\n    :return: New node performing DeformablePSROIPooling operation.\n    """"""\n    node_inputs = as_nodes(feature_maps, coords)\n    if offsets is not None:\n        node_inputs.append(as_node(offsets))\n\n    return _get_node_factory().create(\n        ""DeformablePSROIPooling"",\n        node_inputs,\n        {\n            ""output_dim"": output_dim,\n            ""spatial_scale"": spatial_scale,\n            ""group_size"": group_size,\n            ""mode"": mode,\n            ""spatial_bins_x"": spatial_bins_x,\n            ""spatial_bins_y"": spatial_bins_y,\n            ""trans_std"": trans_std,\n            ""part_size"": part_size,\n        },\n    )\n\n\n@nameable_op\ndef avg_pool(\n    data_batch: NodeInput,\n    strides: List[int],\n    pads_begin: TensorShape,\n    pads_end: TensorShape,\n    kernel_shape: TensorShape,\n    exclude_pad: bool,\n    rounding_type: str = ""floor"",\n    auto_pad: Optional[str] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return average pooling node.\n\n    :param data_batch:      The input node providing data.\n    :param strides:         The window movement strides.\n    :param pads_begin:      The input data optional padding below filled with zeros.\n    :param pads_end:        The input data optional padding below filled with zeros.\n    :param kernel_shape:    The pooling window shape.\n    :param exclude_pad:     Whether or not to include zero padding in average computations.\n    :param rounding_type:   Determines used rounding schema when computing output shape. Acceptable\n                            values are: [\'floor\', \'ceil\']\n    :param auto_pad:        Determines how the padding is calculated. Acceptable values:\n                            [None, \'same_upper\', \'same_lower\', \'valid\']\n    :param name:            Optional name for the new output node.\n\n    :return: New node with AvgPool operation applied on its data.\n    """"""\n    if auto_pad is None:\n        auto_pad = ""explicit""\n    return _get_node_factory().create(\n        ""AvgPool"",\n        [as_node(data_batch)],\n        {\n            ""strides"": strides,\n            ""pads_begin"": pads_begin,\n            ""pads_end"": pads_end,\n            ""kernel"": kernel_shape,\n            ""exclude_pad"": exclude_pad,\n            ""rounding_type"": rounding_type.upper(),\n            ""auto_pad"": auto_pad.upper(),\n        },\n    )\n\n\n@nameable_op\ndef max_pool(\n    data: NodeInput,\n    strides: List[int],\n    pads_begin: List[int],\n    pads_end: List[int],\n    kernel_shape: TensorShape,\n    rounding_type: str = ""floor"",\n    auto_pad: Optional[str] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform max pooling operation with given parameters on provided data.\n\n    :param  data:           The node providing input data.\n    :param  strides:        The distance (in pixels) to slide the filter on the feature map\n                            over the axes.\n    :param  pads_begin:     The number of pixels to add at the beginning along each axis.\n    :param  pads_end:       The number of pixels to add at the end along each axis.\n    :param  kernel_shape:   The pooling operation kernel shape.\n    :param  rounding_type:  Determines used rounding schema when computing output shape. Acceptable\n                            values are: [\'floor\', \'ceil\']\n    :param  auto_pad:       Determines how the padding is calculated. Acceptable values:\n                            [None, \'same_upper\', \'same_lower\', \'valid\']\n    :param  name:           The optional name for the created output node.\n\n    :returns:   The new node performing max pooling operation.\n    """"""\n    if auto_pad is None:\n        auto_pad = ""explicit""\n    return _get_node_factory().create(\n        ""MaxPool"",\n        [as_node(data)],\n        {\n            ""strides"": strides,\n            ""pads_begin"": pads_begin,\n            ""pads_end"": pads_end,\n            ""kernel"": kernel_shape,\n            ""rounding_type"": rounding_type.upper(),\n            ""auto_pad"": auto_pad.upper(),\n        },\n    )\n\n\n# reduction ops\n@nameable_op\ndef reduce_sum(\n    node: NodeInput, reduction_axes: NodeInput, keep_dims: bool = False, name: Optional[str] = None\n) -> Node:\n    """"""Perform element-wise sums of the input tensor, eliminating the specified reduction axes.\n\n    :param node:           The node providing data for operation.\n    :param reduction_axes: The axes to eliminate through summation.\n    :param keep_dims:      If set to True it holds axes that are used for reduction\n    :param name:           The optional new name for output node.\n    :return: The new node performing summation along `reduction_axes` element-wise.\n    """"""\n    return _get_node_factory().create(\n        ""ReduceSum"", as_nodes(node, reduction_axes), {""keep_dims"": keep_dims}\n    )\n\n\n@nameable_op\ndef reduce_max(\n    node: NodeInput, reduction_axes: NodeInput, keep_dims: bool = False, name: Optional[str] = None\n) -> Node:\n    """"""Max-reduction operation on input tensor, eliminating the specified reduction axes.\n\n    :param node:           The tensor we want to max-reduce.\n    :param reduction_axes: The axes to eliminate through max operation.\n    :param keep_dims:      If set to True it holds axes that are used for reduction\n    :param name: Optional name for output node.\n    """"""\n    return _get_node_factory().create(\n        ""ReduceMax"", as_nodes(node, reduction_axes), {""keep_dims"": keep_dims}\n    )\n\n\n@nameable_op\ndef reduce_min(\n    node: NodeInput, reduction_axes: NodeInput, keep_dims: bool = False, name: Optional[str] = None\n) -> Node:\n    """"""Min-reduction operation on input tensor, eliminating the specified reduction axes.\n\n    :param node:           The tensor we want to min-reduce.\n    :param reduction_axes: The axes to eliminate through min operation.\n    :param keep_dims:      If set to True it holds axes that are used for reduction\n    :param name:           Optional name for output node.\n    """"""\n    return _get_node_factory().create(\n        ""ReduceMin"", as_nodes(node, reduction_axes), {""keep_dims"": keep_dims}\n    )\n\n\n@nameable_op\ndef reduce_prod(\n    node: NodeInput, reduction_axes: NodeInput, keep_dims: bool = False, name: Optional[str] = None\n) -> Node:\n    """"""Product-reduction operation on input tensor, eliminating the specified reduction axes.\n\n    :param node:           The tensor we want to product-reduce.\n    :param reduction_axes: The axes to eliminate through product operation.\n    :param keep_dims:      If set to True it holds axes that are used for reduction\n    :param name:           Optional name for output node.\n    :return: The new node performing product-reduction operation.\n    """"""\n    return _get_node_factory().create(\n        ""ReduceProd"", as_nodes(node, reduction_axes), {""keep_dims"": keep_dims}\n    )\n\n\n@nameable_op\ndef reduce_mean(\n    node: NodeInput, reduction_axes: NodeInput, keep_dims: bool = False, name: Optional[str] = None\n) -> Node:\n    """"""Mean-reduction operation on input tensor, eliminating the specified reduction axes.\n\n    :param node:           The tensor we want to mean-reduce.\n    :param reduction_axes: The axes to eliminate through mean operation.\n    :param keep_dims:      If set to True it holds axes that are used for reduction\n    :param name:           Optional name for output node.\n    :return: The new node performing mean-reduction operation.\n    """"""\n    return _get_node_factory().create(\n        ""ReduceMean"", as_nodes(node, reduction_axes), {""keep_dims"": keep_dims}\n    )\n\n\n@nameable_op\ndef reduce_logical_and(\n    node: NodeInput, reduction_axes: NodeInput, keep_dims: bool = False, name: Optional[str] = None\n) -> Node:\n    """"""Logical AND reduction operation on input tensor, eliminating the specified reduction axes.\n\n    :param node:           The tensor we want to reduce.\n    :param reduction_axes: The axes to eliminate through AND operation.\n    :param keep_dims:      If set to True it holds axes that are used for reduction\n    :param name:           Optional name for output node.\n    :return: The new node performing reduction operation.\n    """"""\n    return _get_node_factory().create(\n        ""ReduceLogicalAnd"", as_nodes(node, reduction_axes), {""keep_dims"": keep_dims}\n    )\n\n\n@nameable_op\ndef reduce_logical_or(\n    node: NodeInput, reduction_axes: NodeInput, keep_dims: bool = False, name: Optional[str] = None\n) -> Node:\n    """"""Logical OR reduction operation on input tensor, eliminating the specified reduction axes.\n\n    :param node:           The tensor we want to reduce.\n    :param reduction_axes: The axes to eliminate through OR operation.\n    :param keep_dims:      If set to True it holds axes that are used for reduction\n    :param name:           Optional name for output node.\n    :return: The new node performing reduction operation.\n    """"""\n    return _get_node_factory().create(\n        ""ReduceLogicalOr"", as_nodes(node, reduction_axes), {""keep_dims"": keep_dims}\n    )\n\n\n@nameable_op\ndef cum_sum(\n    arg: NodeInput,\n    axis: NodeInput,\n    exclusive: bool = False,\n    reverse: bool = False,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Construct a cumulative summation operation.\n\n    :param arg: The tensor to be summed.\n    :param axis: zero dimension tensor specifying axis position along which sum will be performed.\n    :param exclusive: if set to true, the top element is not included\n    :param reverse: if set to true, will perform the sums in reverse direction\n    :return: New node performing the operation\n    """"""\n    return _get_node_factory().create(\n        ""CumSum"", as_nodes(arg, axis), {""exclusive"": exclusive, ""reverse"": reverse}\n    )\n\n\n@nameable_op\ndef prelu(data: NodeInput, slope: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Perform Parametrized Relu operation element-wise on data from input node.\n\n    PRelu uses the following logic:\n\n    .. code-block:: python\n\n        if data < 0:\n            data = data * slope\n        elif data >= 0:\n            data = data\n\n    :param data: The node with data tensor.\n    :param slope: The node with the multipliers for negative values.\n    :param name: Optional output node name.\n    :return: The new node performing a PRelu operation on tensor\'s channels.\n    """"""\n    return _get_node_factory().create(""PRelu"", as_nodes(data, slope))\n\n\n@nameable_op\ndef hard_sigmoid(data: Node, alpha: NodeInput, beta: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Perform Hard Sigmoid operation element-wise on data from input node.\n\n    Hard Sigmoid uses the following logic:\n\n    .. code-block:: python\n\n        y = max(0, min(1, alpha * data + beta))\n\n    :param data: The node with data tensor.\n    :param alpha: A node producing the alpha parameter.\n    :param beta: A node producing the beta parameter\n    :param name: Optional output node name.\n    :return: The new node performing a Hard Sigmoid element-wise on input tensor.\n    """"""\n    return _get_node_factory().create(""HardSigmoid"", [data, as_node(alpha), as_node(beta)])\n\n\n@nameable_op\ndef concat(nodes: List[NodeInput], axis: int, name: Optional[str] = None) -> Node:\n    """"""Concatenate input nodes into single new node along specified axis.\n\n    :param nodes: The nodes we want concatenate into single new node.\n    :param axis: The axis along which we want to concatenate input nodes.\n    :param name: The optional new name for output node.\n    :return: Return new node that is a concatenation of input nodes.\n    """"""\n    return _get_node_factory().create(""Concat"", as_nodes(*nodes), {""axis"": axis})\n\n\n@nameable_op\ndef softmax(data: NodeInput, axis: int, name: Optional[str] = None) -> Node:\n    """"""Apply softmax operation on each element of input tensor.\n\n    :param data: The tensor providing input data.\n    :param axis: An axis along which Softmax should be calculated\n    :return: The new node with softmax operation applied on each element.\n    """"""\n    return _get_node_factory().create(""Softmax"", [as_node(data)], {""axis"": axis})\n\n\n@nameable_op\ndef pad(\n    arg: NodeInput,\n    pads_begin: NodeInput,\n    pads_end: NodeInput,\n    pad_mode: str,\n    arg_pad_value: Optional[NodeInput] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a generic padding operation.\n\n    :param arg: The node producing input tensor to be padded.\n    :param pads_begin: number of padding elements to be added before position 0\n                       on each axis of arg.\n    :param pads_end: number of padding elements to be added after the last element.\n    :param pad_mode: ""constant"", ""edge"", ""reflect"" or ""symmetric""\n    :param arg_pad_value: value used for padding if pad_mode is ""constant""\n    :return: Pad operation node.\n    """"""\n    input_nodes = as_nodes(arg, pads_begin, pads_end)\n    if arg_pad_value:\n        input_nodes.append(as_node(arg_pad_value))\n\n    pad_mode = pad_mode.upper()\n    return _get_node_factory().create(""Pad"", input_nodes, {""pad_mode"": pad_mode})\n\n\n@nameable_op\ndef one_hot(\n    indices: NodeInput,\n    depth: NodeInput,\n    on_value: NodeInput,\n    off_value: NodeInput,\n    axis: int,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Create node performing one-hot encoding on input data.\n\n    :param indices: Input tensor of rank N with indices of any supported integer data type.\n    :param depth: Scalar of any supported integer type that specifies number of classes and\n                  the size of one-hot dimension.\n    :param on_value: Scalar of any type that is the value that the locations\n                     in output tensor represented by indices in input take.\n    :param off_value: Scalar of any type that is the value that the locations not represented\n                      by indices in input take.\n\n    :param name: The optional name for new output node.\n    :return: New node performing one-hot operation.\n    """"""\n    return _get_node_factory().create(\n        ""OneHot"", as_nodes(indices, depth, on_value, off_value), {""axis"": axis}\n    )\n\n\n@nameable_op\ndef reverse(data: NodeInput, axis: NodeInput, mode: str, name: Optional[str] = None) -> Node:\n    """"""Perform axis-reverse operation.\n\n    :param data: The input node on which operation will be carried out.\n    :param axis: The list of indices of axes to be reversed.\n    :param mode: The mode specifies how the second input tensor should be interpreted:\n                 as a set of indices or a mask. Range of values: index, mask.\n    :param name: The optional name of the output node.\n    :return: The new node with reversed axes.\n    """"""\n    return _get_node_factory(""opset1"").create(\n        ""Reverse"", as_nodes(data, axis), {""mode"": mode.lower()}\n    )\n\n\n@nameable_op\ndef batch_norm_inference(\n    data: NodeInput,\n    gamma: NodeInput,\n    beta: NodeInput,\n    mean: NodeInput,\n    variance: NodeInput,\n    epsilon: float,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Perform layer normalizes a input tensor by mean and variance with appling scale and offset.\n\n    :param data: The input tensor with data for normalization.\n    :param gamma: The scalar scaling for normalized value.\n    :param beta: The bias added to the scaled normalized value.\n    :param mean: The value for mean normalization.\n    :param variance: The value for variance normalization.\n    :param epsilon: The  number to be added to the variance to avoid division\n                    by zero when normalizing a value.\n    :param name: The optional name of the output node.\n    :return: The new node which performs BatchNormInference.\n    """"""\n    inputs = as_nodes(gamma, beta, data, mean, variance)\n    return _get_node_factory().create(""BatchNormInference"", inputs, {""epsilon"": epsilon})\n\n\n@nameable_op\ndef normalize_l2(\n    data: NodeInput, axes: NodeInput, eps: float, eps_mode: str, name: Optional[str] = None\n) -> Node:\n    """"""Construct an NormalizeL2 operation.\n\n    :param data: Node producing the input tensor\n    :param axes: Node indicating axes along which L2 reduction is calculated\n    :param eps: The epsilon added to L2 norm\n    :param eps_mode: how eps is combined with L2 value (`add` or `max`)\n    :return: New node which performs the L2 normalization.\n    """"""\n    return _get_node_factory().create(\n        ""NormalizeL2"", as_nodes(data, axes), {""eps"": eps, ""mode"": eps_mode}\n    )\n\n\n@nameable_op\ndef lrn(\n    data: NodeInput,\n    axes: NodeInput,\n    alpha: float = 1,\n    beta: float = 0.5,\n    bias: float = 1,\n    size: int = 5,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which performs element-wise Local Response Normalization (LRN) operation.\n\n    :param data: Input data.\n    :param alpha: A scale factor (usually positive).\n    :param beta: An exponent.\n    :param bias: An offset (usually positive) to avoid dividing by 0.\n    :param size: Width of the 1-D normalization window.\n    :param name: An optional name of the output node.\n    :return: The new node which performs LRN.\n    """"""\n    attributes = {""alpha"": alpha, ""beta"": beta, ""bias"": bias, ""size"": size}\n    return _get_node_factory().create(""LRN"", as_nodes(data, axes), attributes)\n\n\n@nameable_op\ndef embedding_bag_offsets_sum(\n    emb_table: Node,\n    indices: NodeInput,\n    offsets: NodeInput,\n    default_index: Optional[NodeInput] = None,\n    per_sample_weights: Optional[NodeInput] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which performs sums of bags of embeddings without the intermediate embeddings.\n\n    :param emb_table: Tensor containing the embedding lookup table.\n    :param indices: Tensor with indices.\n    :param offsets: Tensor containing the starting index positions of each bag in indices.\n    :param per_sample_weights: Tensor with weights for each sample.\n    :param default_index: Scalar containing default index in embedding table to fill empty bags.\n    :param name: Optional name for output node.\n    :return: The new node which performs EmbeddingBagOffsetsSum\n    """"""\n    inputs = [emb_table, as_node(indices), as_node(offsets)]\n    if per_sample_weights is not None:\n        inputs.append(default_index)\n        inputs.append(per_sample_weights)\n    elif default_index is not None:\n        inputs.append(default_index)\n\n    return _get_node_factory().create(""EmbeddingBagOffsetsSum"", inputs, {})\n\n\n@nameable_op\ndef embedding_segments_sum(\n    emb_table: Node,\n    indices: NodeInput,\n    segment_ids: NodeInput,\n    num_segments: Optional[NodeInput] = None,\n    default_index: Optional[NodeInput] = None,\n    per_sample_weights: Optional[NodeInput] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return an EmbeddingSegmentsSum node.\n\n    EmbeddingSegmentsSum constructs an output tensor by replacing every index in a given\n    input tensor with a row (from the weights matrix) at that index\n\n    :param emb_table: Tensor containing the embedding lookup table.\n    :param indices: Tensor with indices.\n    :param segment_ids: Tensor with indices into the output Tensor\n    :param num_segments: Tensor with number of segments.\n    :param default_index: Scalar containing default index in embedding table to fill empty bags.\n    :param per_sample_weights: Weights to be multiplied with embedding table.\n    :param name: Optional name for output node.\n    :return: EmbeddingSegmentsSum node\n    """"""\n    inputs = [as_node(emb_table), as_node(indices), as_node(segment_ids)]\n    if per_sample_weights is not None:\n        inputs.append(as_node(num_segments))\n        inputs.append(as_node(default_index))\n        inputs.append(as_node(per_sample_weights))\n    elif default_index is not None:\n        inputs.append(as_node(num_segments))\n        inputs.append(as_node(default_index))\n    elif num_segments is not None:\n        inputs.append(as_node(num_segments))\n\n    return _get_node_factory().create(""EmbeddingSegmentsSum"", inputs, {})\n\n\n@nameable_op\ndef embedding_bag_packed_sum(\n    emb_table: NodeInput,\n    indices: NodeInput,\n    per_sample_weights: Optional[NodeInput] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return an EmbeddingBagPackedSum node.\n\n    EmbeddingSegmentsSum constructs an output tensor by replacing every index in a given\n    input tensor with a row (from the weights matrix) at that index\n\n    :param emb_table: Tensor containing the embedding lookup table.\n    :param indices: Tensor with indices.\n    :param per_sample_weights: Weights to be multiplied with embedding table.\n    :param name: Optional name for output node.\n    :return: EmbeddingBagPackedSum node\n    """"""\n    inputs = [as_node(emb_table), as_node(indices)]\n    if per_sample_weights is not None:\n        inputs.append(as_node(per_sample_weights))\n\n    return _get_node_factory().create(""EmbeddingBagPackedSum"", inputs, {})\n\n\n@nameable_op\ndef non_max_suppression(\n    boxes: NodeInput,\n    scores: NodeInput,\n    max_output_boxes_per_class: Optional[NodeInput] = None,\n    iou_threshold: Optional[NodeInput] = None,\n    score_threshold: Optional[NodeInput] = None,\n    box_encoding: str = ""corner"",\n    sort_result_descending: bool = True,\n    output_type: str = ""i64"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which performs NonMaxSuppression.\n\n    :param boxes: Tensor with box coordinates.\n    :param scores: Tensor with box scores.\n    :param max_output_boxes_per_class: Tensor Specifying maximum number of boxes\n                                        to be selected per class.\n    :param iou_threshold: Tensor specifying intersection over union threshold\n    :param score_threshold: Tensor specifying minimum score to consider box for the processing.\n    :param box_encoding: Format of boxes data encoding.\n    :param sort_result_descending: Flag that specifies whenever it is necessary to sort selected\n                                   boxes across batches or not.\n    :param output_type: Output element type.\n    :return: The new node which performs NonMaxSuppression\n    """"""\n    if max_output_boxes_per_class is None:\n        max_output_boxes_per_class = make_constant_node(0, np.int64)\n    if iou_threshold is None:\n        iou_threshold = make_constant_node(0, np.float32)\n    if score_threshold is None:\n        score_threshold = make_constant_node(0, np.float32)\n\n    inputs = as_nodes(boxes, scores, max_output_boxes_per_class, iou_threshold, score_threshold)\n    attributes = {\n        ""box_encoding"": box_encoding,\n        ""sort_result_descending"": sort_result_descending,\n        ""output_type"": output_type,\n    }\n\n    return _get_node_factory().create(""NonMaxSuppression"", inputs, attributes)\n\n\n@nameable_op\ndef non_zero(data: NodeInput, output_type: str = ""i64"", name: Optional[str] = None,) -> Node:\n    """"""Return the indices of the elements that are non-zero.\n\n    :param data: Input data.\n    :param output_type: Output tensor type.\n\n    :return: The new node which performs NonZero\n    """"""\n    return _get_node_factory().create(""NonZero"", [as_node(data)], {""output_type"": output_type})\n\n\n@nameable_op\ndef topk(\n    data: NodeInput,\n    k: NodeInput,\n    axis: int,\n    mode: str,\n    sort: str,\n    index_element_type: str = ""i32"",\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which performs TopK.\n\n    :param data: Input data.\n    :param k: K.\n    :param axis: TopK Axis.\n    :param mode: Compute TopK largest (\'max\') or smallest (\'min\')\n    :param sort: Order of output elements (sort by: \'none\', \'index\' or \'value\')\n    :param index_element_type: Type of output tensor with indices.\n    :return: The new node which performs TopK (both indices and values)\n    """"""\n    return _get_node_factory().create(\n        ""TopK"",\n        as_nodes(data, k),\n        {""axis"": axis, ""mode"": mode, ""sort"": sort, ""index_element_type"": index_element_type},\n    )\n\n\n@nameable_op\ndef roi_align(\n    data: NodeInput,\n    rois: NodeInput,\n    batch_indices: NodeInput,\n    pooled_h: int,\n    pooled_w: int,\n    sampling_ratio: int,\n    spatial_scale: float,\n    mode: str,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which performs ROIAlign.\n\n    :param data: Input data.\n    :param rois: RoIs (Regions of Interest) to pool over.\n    :param batch_indices: Tensor with each element denoting the index of\n                          the corresponding image in the batch.\n    :param pooled_h: Height of the ROI output feature map.\n    :param pooled_w: Width of the ROI output feature map.\n    :param sampling_ratio: Number of bins over height and width to use to calculate\n                           each output feature map element.\n    :param spatial_scale: Multiplicative spatial scale factor to translate ROI coordinates.\n    :param mode: Method to perform pooling to produce output feature map elements.\n\n    :return: The new node which performs ROIAlign\n    """"""\n    inputs = as_nodes(data, rois, batch_indices)\n    attributes = {\n        ""pooled_h"": pooled_h,\n        ""pooled_w"": pooled_w,\n        ""sampling_ratio"": sampling_ratio,\n        ""spatial_scale"": spatial_scale,\n        ""mode"": mode,\n    }\n    return _get_node_factory().create(""ROIAlign"", inputs, attributes)\n\n\n@nameable_op\ndef get_output_element(data: NodeInput, index: int, name: Optional[str] = None) -> Node:\n    """"""Return the n-th element of the input tuple.""""""\n    return GetOutputElement(as_node(data), index)\n\n\n@nameable_op\ndef matmul(\n    data_a: NodeInput,\n    data_b: NodeInput,\n    transpose_a: bool,\n    transpose_b: bool,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return the Matrix Multiplication operation.\n\n    :param data_a: left-hand side matrix\n    :param data_b: right-hand side matrix\n    :param transpose_a: should the first matrix be transposed before operation\n    :param transpose_b: should the second matrix be transposed\n    :return: MatMul operation node\n    """"""\n    print(""transpose_a"", transpose_a, ""transpose_b"", transpose_b)\n    return _get_node_factory().create(\n        ""MatMul"", as_nodes(data_a, data_b), {""transpose_a"": transpose_a, ""transpose_b"": transpose_b}\n    )\n\n\n@nameable_op\ndef variadic_split(\n    data: NodeInput, axis: NodeInput, split_lengths: NodeInput, name: Optional[str] = None\n) -> Node:\n    """"""Return a node which splits the input tensor into variadic length slices.\n\n    :param data: The input tensor to be split\n    :param axis: Axis along which the input data will be split\n    :param split_lengths: Sizes of the output tensors along the split axis\n    :return: VariadicSplit node\n    """"""\n    return _get_node_factory().create(""VariadicSplit"", as_nodes(data, axis, split_lengths))\n\n\n@nameable_op\ndef transpose(data: NodeInput, input_order: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return a node which transposes the data in the input tensor.\n\n    :param data: The input tensor to be transposed\n    :param input_order: Permutation of axes to be applied to the input tensor\n    :return: Transpose node\n    """"""\n    return _get_node_factory().create(""Transpose"", as_nodes(data, input_order))\n\n\n@nameable_op\ndef tile(data: NodeInput, repeats: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return a node which dynamically repeats(replicates) the input data tensor.\n\n    :param data: The input tensor to be tiled\n    :param repeats: Per-dimension replication factors\n    :return: Tile node\n    """"""\n    return _get_node_factory().create(""Tile"", as_nodes(data, repeats))\n\n\n@nameable_op\ndef strided_slice(\n    data: NodeInput,\n    begin: NodeInput,\n    end: NodeInput,\n    strides: NodeInput,\n    begin_mask: List[int],\n    end_mask: List[int],\n    new_axis_mask: Optional[List[int]] = None,\n    shrink_axis_mask: Optional[List[int]] = None,\n    ellipsis_mask: Optional[List[int]] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which dynamically repeats(replicates) the input data tensor.\n\n    :param      data:              The tensor to be sliced\n    :param      begin:             1D tensor with begin indexes for input blob slicing\n    :param      end:               1D tensor with end indexes for input blob slicing\n    :param      strides:           The slicing strides\n    :param      begin_mask:        A mask applied to the \'begin\' input indicating which elements\n                                   shoud be ignored\n    :param      end_mask:          A mask applied to the \'end\' input indicating which elements\n                                   shoud be ignored\n    :param      new_axis_mask:     A mask indicating dimensions where \'1\' should be inserted\n    :param      shrink_axis_mask:  A mask indicating which dimensions should be deleted\n    :param      ellipsis_mask:     Indicates positions where missing dimensions should be inserted\n    :returns:   StridedSlice node\n    """"""\n    if new_axis_mask is None:\n        new_axis_mask = []\n    if shrink_axis_mask is None:\n        shrink_axis_mask = []\n    if ellipsis_mask is None:\n        ellipsis_mask = []\n    attributes = {\n        ""begin_mask"": begin_mask,\n        ""end_mask"": end_mask,\n        ""new_axis_mask"": new_axis_mask,\n        ""shrink_axis_mask"": shrink_axis_mask,\n        ""ellipsis_mask"": ellipsis_mask,\n    }\n\n    return _get_node_factory().create(\n        ""StridedSlice"", as_nodes(data, begin, end, strides), attributes\n    )\n\n\n@nameable_op\ndef split(data: NodeInput, axis: NodeInput, num_splits: int, name: Optional[str] = None) -> Node:\n    """"""Return a node which splits the input tensor into same-length slices.\n\n    :param data: The input tensor to be split\n    :param axis: Axis along which the input data will be split\n    :param num_splits: Number of the output tensors that should be produced\n    :return: Split node\n    """"""\n    return _get_node_factory().create(""Split"", as_nodes(data, axis), {""num_splits"": num_splits})\n\n\n@unary_op\ndef sigmoid(data: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return a node which applies the sigmoid function element-wise.\n\n    :param data: The tensor containing the input data\n    :return: Sigmoid node\n    """"""\n    return _get_node_factory().create(""Sigmoid"", [data])\n\n\n@nameable_op\ndef shape_of(data: NodeInput, output_type: str = ""i64"", name: Optional[str] = None) -> Node:\n    """"""Return a node which produces a tensor containing the shape of its input data.\n\n    :param data: The tensor containing the input data.\n    :para output_type: Output element type.\n    :return: ShapeOf node\n    """"""\n    return _get_node_factory().create(""ShapeOf"", [as_node(data)], {""output_type"": output_type})\n\n\n@unary_op\ndef result(data: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return a node which represents an output of a graph (Function).\n\n    :param data: The tensor containing the input data\n    :return: Result node\n    """"""\n    return _get_node_factory().create(""Result"", [data])\n\n\n@nameable_op\ndef scatter_update(\n    data: Node, indices: NodeInput, updates: NodeInput, axis: NodeInput, name: Optional[str] = None\n) -> Node:\n    """"""Return a node which produces a ScatterUpdate operation.\n\n    ScatterUpdate sets new values to slices from data addressed by indices.\n\n    :param data:    The input tensor to be updated.\n    :param indices: The tensor with indexes which will be updated.\n    :param updates: The tensor with update values.\n    :param axis:    The axis at which elements will be updated.\n    :return: ScatterUpdate node\n    """"""\n    return _get_node_factory().create(""ScatterUpdate"", as_nodes(data, indices, updates, axis))\n\n\n@nameable_op\ndef scatter_elements_update(\n    data: NodeInput,\n    indices: NodeInput,\n    updates: NodeInput,\n    axis: NodeInput,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which produces a ScatterElementsUpdate operation.\n\n    ScatterElementsUpdate creates a copy of the first input tensor with updated elements\n    specified with second and third input tensors.\n\n\n    For each entry in `updates`, the target index in `data` is obtained by combining\n    the corresponding entry in `indices` with the index of the entry itself: the\n    index-value for dimension equal to `axis` is obtained from the value of the\n    corresponding entry in `indices` and the index-value for dimension not equal\n    to `axis` is obtained from the index of the entry itself.\n\n    :param data:    The input tensor to be updated.\n    :param indices: The tensor with indexes which will be updated.\n    :param updates: The tensor with update values.\n    :param axis:    The axis for scatter.\n    :return: ScatterElementsUpdate node\n    """"""\n    return _get_node_factory().create(\n        ""ScatterElementsUpdate"", as_nodes(data, indices, updates, axis)\n    )\n\n\n@nameable_op\ndef roi_pooling(\n    input: NodeInput,\n    coords: NodeInput,\n    output_size: TensorShape,\n    spatial_scale: NumericData,\n    method: str,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which produces an ROIPooling operation.\n\n    :param input:          Input feature map {N, C, ...}\n    :param coords:         Coordinates of bounding boxes\n    :param output_size:    Height/Width of ROI output features (shape)\n    :param spatial_scale:  Ratio of input feature map over input image size (float)\n    :param method:         Method of pooling - string: ""max"" or ""bilinear""\n    :return:               ROIPooling node\n    """"""\n    method = method.lower()\n    return _get_node_factory().create(\n        ""ROIPooling"",\n        as_nodes(input, coords),\n        {""output_size"": Shape(output_size), ""spatial_scale"": spatial_scale, ""method"": method},\n    )\n\n\n@nameable_op\ndef psroi_pooling(\n    input: NodeInput,\n    coords: NodeInput,\n    output_dim: int,\n    group_size: int,\n    spatial_scale: float,\n    spatial_bins_x: int,\n    spatial_bins_y: int,\n    mode: str,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which produces a PSROIPooling operation.\n\n    :param input: Input feature map {N, C, ...}\n    :param coords: Coordinates of bounding boxes\n    :param output_dim: Output channel number\n    :param group_size: Number of groups to encode position-sensitive scores\n    :param spatial_scale: Ratio of input feature map over input image size\n    :param spatial_bins_x: Numbers of bins to divide the input feature maps over\n    :param spatial_bins_y: Numbers of bins to divide the input feature maps over\n    :param mode: Mode of pooling - ""avg"" or ""bilinear""\n    :return: PSROIPooling node\n    """"""\n    mode = mode.lower()\n    return _get_node_factory().create(\n        ""PSROIPooling"",\n        as_nodes(input, coords),\n        {\n            ""output_dim"": output_dim,\n            ""group_size"": group_size,\n            ""spatial_scale"": spatial_scale,\n            ""spatial_bins_x"": spatial_bins_x,\n            ""spatial_bins_y"": spatial_bins_y,\n            ""mode"": mode,\n        },\n    )\n\n\n@nameable_op\ndef reverse_sequence(\n    input: NodeInput,\n    seq_lengths: NodeInput,\n    batch_axis: NumericData,\n    seq_axis: NumericData,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which produces a ReverseSequence operation.\n\n    :param input: tensor with input data to reverse\n    :param seq_lengths: 1D tensor of integers with sequence lengths in the input tensor.\n    :param batch_axis: index of the batch dimension.\n    :param seq_axis: index of the sequence dimension.\n    :return: ReverseSequence node\n    """"""\n    return _get_node_factory().create(\n        ""ReverseSequence"",\n        as_nodes(input, seq_lengths),\n        {""batch_axis"": batch_axis, ""seq_axis"": seq_axis},\n    )\n\n\n@nameable_op\ndef bucketize(\n    data: Node,\n    buckets: NodeInput,\n    output_type: str = ""i64"",\n    with_right_bound: bool = True,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which produces the Bucketize operation.\n\n    :param data:              Input data to bucketize\n    :param buckets:           1-D of sorted unique boundaries for buckets\n    :param output_type:       Output tensor type, ""i64"" or ""i32"", defaults to i64\n    :param with_right_bound:  indicates whether bucket includes the right or left\n                              edge of interval. default true = includes right edge\n    :param name:              Optional name for output node.\n    :return: Bucketize node\n    """"""\n    return _get_node_factory().create(\n        ""Bucketize"",\n        [data, as_node(buckets)],\n        {""output_type"": output_type, ""with_right_bound"": with_right_bound},\n    )\n\n\n@nameable_op\ndef range(start: Node, stop: NodeInput, step: NodeInput, name: Optional[str] = None) -> Node:\n    """"""Return a node which produces the Range operation.\n\n    :param start:  The start value of the generated range\n    :param stop:   The stop value of the generated range\n    :param step:   The step value for the generated range\n    :param name:   Optional name for output node.\n    :return: Range node\n    """"""\n    return _get_node_factory().create(""Range"", as_nodes(start, stop, step))\n\n\n@nameable_op\ndef region_yolo(\n    input: Node,\n    coords: int,\n    classes: int,\n    num: int,\n    do_softmax: bool,\n    mask: List[int],\n    axis: int,\n    end_axis: int,\n    anchors: List[float] = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Return a node which produces the RegionYolo operation.\n\n    :param input:       Input data\n    :param coords:      Number of coordinates for each region\n    :param classes:     Number of classes for each region\n    :param num:         Number of regions\n    :param do_softmax:  Compute softmax\n    :param mask:        Mask\n    :param axis:        Axis to begin softmax on\n    :param end_axis:    Axis to end softmax on\n    :param anchors:     A flattened list of pairs `[width, height]` that describes prior box sizes\n    :param name:        Optional name for output node.\n    :return: RegionYolo node\n    """"""\n    if anchors is None:\n        anchors = []\n\n    return _get_node_factory().create(\n        ""RegionYolo"",\n        [input],\n        {\n            ""coords"": coords,\n            ""classes"": classes,\n            ""num"": num,\n            ""do_softmax"": do_softmax,\n            ""mask"": mask,\n            ""axis"": axis,\n            ""end_axis"": end_axis,\n            ""anchors"": anchors,\n        },\n    )\n\n\n@nameable_op\ndef reorg_yolo(input: Node, stride: List[int], name: Optional[str] = None) -> Node:\n    """"""Return a node which produces the ReorgYolo operation.\n\n    :param input:   Input data\n    :param stride:  Stride to reorganize input by\n    :param name:    Optional name for output node.\n    :return: ReorgYolo node\n    """"""\n    return _get_node_factory().create(""ReorgYolo"", [input], {""stride"": stride})\n\n\n@nameable_op\ndef interpolate(\n    image: Node, output_shape: NodeInput, attrs: dict, name: Optional[str] = None\n) -> Node:\n    """"""Perform interpolation of independent slices in input tensor.\n\n    :param  image:         The node providing input tensor with data for interpolation.\n    :param  output_shape:  1D tensor describing output shape for spatial axes.\n    :param  attrs:         The dictionary containing key, value pairs for attributes.\n    :param  name:          Optional name for the output node.\n\n    Available attributes are:\n\n    * axes              Specify spatial dimension indices where interpolation is applied.\n                        Type: List of non-negative integer numbers.\n                        Required: yes.\n\n    * mode              Specifies type of interpolation.\n                        Range of values: one of {nearest, linear, cubic, area}\n                        Type: string\n                        Required: yes\n\n    * align_corners     A flag that specifies whether to align corners or not. True means the\n                        alignment is applied, False means the alignment isn\'t applied.\n                        Range of values: True or False. Default: True.\n                        Required: no\n\n    * antialias         A flag that specifies whether to perform anti-aliasing.\n                        Range of values: False - do not perform anti-aliasing\n                                         True - perform anti-aliasing\n                        Default value: False\n                        Required: no\n\n    * pads_begin        Specify the number of pixels to add to the beginning of the image being\n                        interpolated. A scalar that specifies padding for each spatial dimension.\n                        Range of values: list of non-negative integer numbers. Default value: 0\n                        Required: no\n\n    * pads_end          Specify the number of pixels to add to the beginning of the image being\n                        interpolated. A scalar that specifies padding for each spatial dimension.\n                        Range of values: list of non-negative integer numbers. Default value: 0\n                        Required: no\n\n    Example of attribute dictionary:\n    .. code-block:: python\n\n        # just required ones\n        attrs = {\n            \'axes\': [2, 3],\n            \'mode\': \'cubic\',\n        }\n\n        attrs = {\n            \'axes\': [2, 3],\n            \'mode\': \'cubic\',\n            \'antialias\': True,\n            \'pads_begin\': [2, 2, 2],\n        }\n\n    Optional attributes which are absent from dictionary will be set with corresponding default.\n\n    :return: Node representing interpolation operation.\n    """"""\n    requirements = [\n        (""attrs.axes"", True, np.integer, is_non_negative_value),\n        (""attrs.mode"", True, np.str_, None),\n        (""attrs.align_corners"", False, np.bool_, None),\n        (""attrs.antialias"", False, np.bool_, None),\n        (""attrs.pads_begin"", False, np.integer, is_non_negative_value),\n        (""attrs.pads_end"", False, np.integer, is_non_negative_value),\n    ]\n\n    check_valid_attributes(""Interpolate"", attrs, requirements)\n\n    return _get_node_factory().create(""Interpolate"", [image, as_node(output_shape)], attrs)\n\n\n@nameable_op\ndef prior_box(\n    layer_shape: Node, image_shape: NodeInput, attrs: dict, name: Optional[str] = None\n) -> Node:\n    """"""Generate prior boxes of specified sizes and aspect ratios across all dimensions.\n\n    :param  layer_shape:  Shape of layer for which prior boxes are computed.\n    :param  image_shape:  Shape of image to which prior boxes are scaled.\n    :param  attrs:        The dictionary containing key, value pairs for attributes.\n    :param  name:         Optional name for the output node.\n\n    Available attributes are:\n\n    * min_size          The minimum box size (in pixels).\n                        Range of values: positive floating point numbers\n                        Default value: []\n                        Required: no\n\n    * max_size          The maximum box size (in pixels).\n                        Range of values: positive floating point numbers\n                        Default value: []\n                        Required: no\n\n    * aspect_ratio      Aspect ratios of prior boxes.\n                        Range of values: set of positive floating point numbers\n                        Default value: []\n                        Required: no\n\n    * flip              The flag that denotes that each aspect_ratio is duplicated and flipped.\n                        Range of values: {True, False}\n                        Default value: False\n                        Required: no\n\n    * clip              The flag that denotes if each value in the output tensor should be clipped\n                        to [0,1] interval.\n                        Range of values: {True, False}\n                        Default value: False\n                        Required: no\n\n    * step              The distance between box centers.\n                        Range of values: floating point non-negative number\n                        Default value: 0\n                        Required: no\n\n    * offset            This is a shift of box respectively to top left corner.\n                        Range of values: floating point non-negative number\n                        Default value: None\n                        Required: yes\n\n    * variance          The variance denotes a variance of adjusting bounding boxes. The attribute\n                        could contain 0, 1 or 4 elements.\n                        Range of values: floating point positive numbers\n                        Default value: []\n                        Required: no\n\n    * scale_all_sizes   The flag that denotes type of inference.\n                        Range of values: False - max_size is ignored\n                                         True  - max_size is used\n                        Default value: True\n                        Required: no\n\n    * fixed_ratio       This is an aspect ratio of a box.\n                        Range of values: a list of positive floating-point numbers\n                        Default value: None\n                        Required: no\n\n    * fixed_size        This is an initial box size (in pixels).\n                        Range of values: a list of positive floating-point numbers\n                        Default value: None\n                        Required: no\n\n    * density           This is the square root of the number of boxes of each type.\n                        Range of values: a list of positive floating-point numbers\n                        Default value: None\n                        Required: no\n\n    Example of attribute dictionary:\n    .. code-block:: python\n\n        # just required ones\n        attrs = {\n            \'offset\': 85,\n        }\n\n        attrs = {\n            \'offset\': 85,\n            \'flip\': True,\n            \'clip\': True,\n            \'fixed_size\': [32, 64, 128]\n        }\n\n    Optional attributes which are absent from dictionary will be set with corresponding default.\n\n    :return: Node representing prior box operation.\n    """"""\n    requirements = [\n        (""attrs.offset"", True, np.floating, is_non_negative_value),\n        (""attrs.min_size"", False, np.floating, is_positive_value),\n        (""attrs.max_size"", False, np.floating, is_positive_value),\n        (""attrs.aspect_ratio"", False, np.floating, is_positive_value),\n        (""attrs.flip"", False, np.bool_, None),\n        (""attrs.clip"", False, np.bool_, None),\n        (""attrs.step"", False, np.floating, is_non_negative_value),\n        (""attrs.variance"", False, np.floating, is_positive_value),\n        (""attrs.scale_all_sizes"", False, np.bool_, None),\n        (""attrs.fixed_ratio"", False, np.floating, is_positive_value),\n        (""attrs.fixed_size"", False, np.floating, is_positive_value),\n        (""attrs.density"", False, np.floating, is_positive_value),\n    ]\n\n    check_valid_attributes(""PriorBox"", attrs, requirements)\n\n    return _get_node_factory().create(""PriorBox"", [layer_shape, as_node(image_shape)], attrs)\n\n\n@nameable_op\ndef prior_box_clustered(\n    output_size: Node, image_size: NodeInput, attrs: dict, name: Optional[str] = None\n) -> Node:\n    """"""Generate prior boxes of specified sizes normalized to the input image size.\n\n    :param  output_size:    1D tensor with two integer elements [height, width]. Specifies the\n                            spatial size of generated grid with boxes.\n    :param  image_size:     1D tensor with two integer elements [image_height, image_width] that\n                            specifies shape of the image for which boxes are generated.\n    :param  attrs:          The dictionary containing key, value pairs for attributes.\n    :param  name:           Optional name for the output node.\n\n     Available attributes are:\n\n    * widths        Specifies desired boxes widths in pixels.\n                    Range of values: floating point positive numbers.\n                    Default value: 1.0\n                    Required: no\n\n    * heights       Specifies desired boxes heights in pixels.\n                    Range of values: floating point positive numbers.\n                    Default value: 1.0\n                    Required: no\n\n    * clip          The flag that denotes if each value in the output tensor should be clipped\n                    within [0,1].\n                    Range of values: {True, False}\n                    Default value: True\n                    Required: no\n\n    * step_widths   The distance between box centers.\n                    Range of values: floating point positive number\n                    Default value: 0.0\n                    Required: no\n\n    * step_heights  The distance between box centers.\n                    Range of values: floating point positive number\n                    Default value: 0.0\n                    Required: no\n\n    * offset        The shift of box respectively to the top left corner.\n                    Range of values: floating point positive number\n                    Default value: None\n                    Required: yes\n\n    * variance      Denotes a variance of adjusting bounding boxes.\n                    Range of values: floating point positive numbers\n                    Default value: []\n                    Required: no\n\n    Example of attribute dictionary:\n    .. code-block:: python\n\n        # just required ones\n        attrs = {\n            \'offset\': 85,\n        }\n\n        attrs = {\n            \'offset\': 85,\n            \'clip\': False,\n            \'step_widths\': [1.5, 2.0, 2.5]\n        }\n\n    Optional attributes which are absent from dictionary will be set with corresponding default.\n\n    :return: Node representing PriorBoxClustered operation.\n    """"""\n    requirements = [\n        (""attrs.widths"", False, np.floating, is_positive_value),\n        (""attrs.heights"", False, np.floating, is_positive_value),\n        (""attrs.clip"", False, np.bool_, None),\n        (""attrs.step_widths"", False, np.floating, is_positive_value),\n        (""attrs.step_heights"", False, np.floating, is_positive_value),\n        (""attrs.offset"", True, np.floating, is_positive_value),\n        (""attrs.variance"", False, np.floating, is_positive_value),\n    ]\n\n    check_valid_attributes(""PriorBoxClustered"", attrs, requirements)\n\n    return _get_node_factory().create(\n        ""PriorBoxClustered"", [output_size, as_node(image_size)], attrs\n    )\n\n\n@nameable_op\ndef detection_output(\n    box_logits: Node,\n    class_preds: Node,\n    proposals: Node,\n    attrs: dict,\n    aux_class_preds: NodeInput = None,\n    aux_box_preds: NodeInput = None,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Generate the detection output using information on location and confidence predictions.\n\n    :param  box_logits:         The 2D input tensor with box logits.\n    :param  class_preds:        The 2D input tensor with class predictions.\n    :param  proposals:          The 3D input tensor with proposals.\n    :param  attrs:              The dictionary containing key, value pairs for attributes.\n    :param  aux_class_preds:    The 2D input tensor with additional class predictions information.\n    :param  aux_box_preds:      The 2D input tensor with additional box predictions information.\n    :param  name:               Optional name for the output node.\n\n     Available attributes are:\n\n    * num_classes       The number of classes to be predicted.\n                        Range of values: positive integer number\n                        Default value: None\n                        Required: yes\n\n    * background_label_id   The background label id.\n                            Range of values: integer value\n                            Default value: 0\n                            Required: no\n\n    * top_k                 Maximum number of results to be kept per batch after NMS step.\n                            Range of values: integer value\n                            Default value: -1\n                            Required: no\n\n    * variance_encoded_in_target    The flag that denotes if variance is encoded in target.\n                                    Range of values: {False, True}\n                                    Default value: False\n                                    Required: no\n\n    * keep_top_k            Maximum number of bounding boxes per batch to be kept after NMS step.\n                            Range of values: integer values\n                            Default value: None\n                            Required: yes\n\n    * code_type             The type of coding method for bounding boxes.\n                            Range of values: {\'caffe.PriorBoxParameter.CENTER_SIZE\',\n                                             \'caffe.PriorBoxParameter.CORNER\'}\n                            Default value: \'caffe.PriorBoxParameter.CORNER\'\n                            Required: no\n\n    * share_location        The flag that denotes if bounding boxes are shared among different\n                            classes.\n                            Range of values: {True, False}\n                            Default value: True\n                            Required: no\n\n    * nms_threshold         The threshold to be used in the NMS stage.\n                            Range of values: floating point value\n                            Default value: None\n                            Required: yes\n\n    * confidence_threshold  Specifies the minimum confidence threshold for detection boxes to be\n                            considered.\n                            Range of values: floating point value\n                            Default value: 0\n                            Required: no\n\n    * clip_after_nms        The flag that denotes whether to perform clip bounding boxes after\n                            non-maximum suppression or not.\n                            Range of values: {True, False}\n                            Default value: False\n                            Required: no\n\n    * clip_before_nms       The flag that denotes whether to perform clip bounding boxes before\n                            non-maximum suppression or not.\n                            Range of values: {True, False}\n                            Default value: False\n                            Required: no\n\n    * decrease_label_id     The flag that denotes how to perform NMS.\n                            Range of values: False - perform NMS like in Caffe*.\n                                             True  - perform NMS like in MxNet*.\n\n                            Default value: False\n                            Required: no\n\n    * normalized            The flag that denotes whether input tensors with boxes are normalized.\n                            Range of values: {True, False}\n                            Default value: False\n                            Required: no\n\n    * input_height          The input image height.\n                            Range of values: positive integer number\n                            Default value: 1\n                            Required: no\n\n    * input_width           The input image width.\n                            Range of values: positive integer number\n                            Default value: 1\n                            Required: no\n\n    * objectness_score      The threshold to sort out confidence predictions.\n                            Range of values: non-negative float number\n                            Default value: 0\n                            Required: no\n\n    Example of attribute dictionary:\n    .. code-block:: python\n\n        # just required ones\n        attrs = {\n            \'num_classes\': 85,\n            \'keep_top_k\': [1, 2, 3],\n            \'nms_threshold\': 0.645,\n        }\n\n        attrs = {\n            \'num_classes\': 85,\n            \'keep_top_k\': [1, 2, 3],\n            \'nms_threshold\': 0.645,\n            \'normalized\': True,\n            \'clip_before_nms\': True,\n            \'input_height\': [32],\n            \'input_width\': [32],\n        }\n\n    Optional attributes which are absent from dictionary will be set with corresponding default.\n\n    :return: Node representing DetectionOutput operation.\n    """"""\n    requirements = [\n        (""attrs.num_classes"", True, np.integer, is_positive_value),\n        (""attrs.background_label_id"", False, np.integer, None),\n        (""attrs.top_k"", False, np.integer, None),\n        (""attrs.variance_encoded_in_target"", False, np.bool_, None),\n        (""attrs.keep_top_k"", True, np.integer, None),\n        (""attrs.code_type"", False, np.str_, None),\n        (""attrs.share_location"", False, np.bool_, None),\n        (""attrs.nms_threshold"", True, np.floating, None),\n        (""attrs.confidence_threshold"", False, np.floating, None),\n        (""attrs.clip_after_nms"", False, np.bool_, None),\n        (""attrs.clip_before_nms"", False, np.bool_, None),\n        (""attrs.decrease_label_id"", False, np.bool_, None),\n        (""attrs.normalized"", False, np.bool_, None),\n        (""attrs.input_height"", False, np.integer, is_positive_value),\n        (""attrs.input_width"", False, np.integer, is_positive_value),\n        (""attrs.objectness_score"", False, np.floating, is_non_negative_value),\n    ]\n\n    check_valid_attributes(""DetectionOutput"", attrs, requirements)\n\n    inputs = [box_logits, class_preds, proposals]\n    if aux_class_preds is not None:\n        inputs.append(aux_class_preds)\n    if aux_box_preds is not None:\n        inputs.append(aux_box_preds)\n\n    return _get_node_factory().create(""DetectionOutput"", inputs, attrs)\n\n\n@nameable_op\ndef proposal(\n    class_probs: Node,\n    box_logits: Node,\n    image_shape: NodeInput,\n    attrs: dict,\n    name: Optional[str] = None,\n) -> Node:\n    """"""Filter bounding boxes and outputs only those with the highest prediction confidence.\n\n    :param  class_probs:        4D input floating point tensor with class prediction scores.\n    :param  box_logits:         4D input floating point tensor with box logits.\n    :param  image_shape:        The 1D input tensor with 3 or 4 elements describing image shape.\n    :param  attrs:              The dictionary containing key, value pairs for attributes.\n    :param  name:               Optional name for the output node.\n\n    * base_size     The size of the anchor to which scale and ratio attributes are applied.\n                    Range of values: a positive unsigned integer number\n                    Default value: None\n                    Required: yes\n\n    * pre_nms_topn  The number of bounding boxes before the NMS operation.\n                    Range of values: a positive unsigned integer number\n                    Default value: None\n                    Required: yes\n\n    * post_nms_topn The number of bounding boxes after the NMS operation.\n                    Range of values: a positive unsigned integer number\n                    Default value: None\n                    Required: yes\n\n    * nms_thresh    The minimum value of the proposal to be taken into consideration.\n                    Range of values: a positive floating-point number\n                    Default value: None\n                    Required: yes\n\n    * feat_stride   The step size to slide over boxes (in pixels).\n                    Range of values: a positive unsigned integer\n                    Default value: None\n                    Required: yes\n\n    * min_size      The minimum size of box to be taken into consideration.\n                    Range of values: a positive unsigned integer number\n                    Default value: None\n                    Required: yes\n\n    * ratio         The ratios for anchor generation.\n                    Range of values: a list of floating-point numbers\n                    Default value: None\n                    Required: yes\n\n    * scale         The scales for anchor generation.\n                    Range of values: a list of floating-point numbers\n                    Default value: None\n                    Required: yes\n\n    * clip_before_nms   The flag that specifies whether to perform clip bounding boxes before\n                        non-maximum suppression or not.\n                        Range of values: True or False\n                        Default value: True\n                        Required: no\n\n    * clip_after_nms    The flag that specifies whether to perform clip bounding boxes after\n                        non-maximum suppression or not.\n                        Range of values: True or False\n                        Default value: False\n                        Required: no\n\n    * normalize     The flag that specifies whether to perform normalization of output boxes to\n                    [0,1] interval or not.\n                    Range of values: True or False\n                    Default value: False\n                    Required: no\n\n    * box_size_scale    Specifies the scale factor applied to logits of box sizes before decoding.\n                        Range of values: a positive floating-point number\n                        Default value: 1.0\n                        Required: no\n\n    * box_coordinate_scale  Specifies the scale factor applied to logits of box coordinates\n                            before decoding.\n                            Range of values: a positive floating-point number\n                            Default value: 1.0\n                            Required: no\n\n    * framework     Specifies how the box coordinates are calculated.\n                    Range of values: """" (empty string) - calculate box coordinates like in Caffe*\n                                     tensorflow - calculate box coordinates like in the TensorFlow*\n                                                  Object Detection API models\n                    Default value: """" (empty string)\n                    Required: no\n\n    Example of attribute dictionary:\n\n    .. code-block:: python\n\n        # just required ones\n        attrs = {\n            \'base_size\': 85,\n            \'pre_nms_topn\': 10,\n            \'post_nms_topn\': 20,\n            \'nms_thresh\': 0.34,\n            \'feat_stride\': 16,\n            \'min_size\': 32,\n            \'ratio\': [0.1, 1.5, 2.0, 2.5],\n            \'scale\': [2, 3, 3, 4],\n        }\n\n    Optional attributes which are absent from dictionary will be set with corresponding default.\n\n    :return: Node representing Proposal operation.\n    """"""\n    requirements = [\n        (""attrs.base_size"", True, np.unsignedinteger, is_positive_value),\n        (""attrs.pre_nms_topn"", True, np.unsignedinteger, is_positive_value),\n        (""attrs.post_nms_topn"", True, np.unsignedinteger, is_positive_value),\n        (""attrs.nms_thresh"", True, np.floating, is_positive_value),\n        (""attrs.feat_stride"", True, np.unsignedinteger, is_positive_value),\n        (""attrs.min_size"", True, np.unsignedinteger, is_positive_value),\n        (""attrs.ratio"", True, np.floating, None),\n        (""attrs.scale"", True, np.floating, None),\n        (""attrs.clip_before_nms"", False, np.bool_, None),\n        (""attrs.clip_after_nms"", False, np.bool_, None),\n        (""attrs.normalize"", False, np.bool_, None),\n        (""attrs.box_size_scale"", False, np.floating, is_positive_value),\n        (""attrs.box_coordinate_scale"", False, np.floating, is_positive_value),\n        (""attrs.framework"", False, np.str_, None),\n    ]\n\n    check_valid_attributes(""Proposal"", attrs, requirements)\n\n    return _get_node_factory().create(\n        ""Proposal"", [class_probs, box_logits, as_node(image_shape)], attrs\n    )\n'"
python/src/ngraph/runtime.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""Provide a layer of abstraction for the ngraph++ runtime environment.""""""\nimport logging\nfrom typing import Dict, List, Union\nfrom enum import Enum\n\nimport numpy as np\n\nfrom ngraph.exceptions import UserInputError\nfrom ngraph.impl import Function, Node, Shape, PartialShape, serialize, util\nfrom ngraph.impl.runtime import Backend, Executable, Tensor\nfrom ngraph.utils.types import NumericData, get_dtype\n\nlog = logging.getLogger(__name__)\n\n\nclass BackendMode(Enum):\n    """"""DYNAMIC mode enables backend\'s wrapper which supports dynamic shapes.""""""\n\n    STATIC = 0\n    DYNAMIC = 1\n\n\ndef runtime(backend_name: str = ""CPU"", mode: BackendMode = BackendMode.STATIC) -> ""Runtime"":\n    """"""Create a Runtime object (helper factory).\n\n    Use signature to parameterize runtime as needed.\n    """"""\n    return Runtime(backend_name, mode)\n\n\nclass Runtime:\n    """"""Represents the ngraph++ runtime environment.""""""\n\n    def __init__(self, backend_name: str, mode: BackendMode = BackendMode.STATIC) -> None:\n        self.backend_name = backend_name\n        if mode == BackendMode.DYNAMIC:\n            self.backend = Backend.create_dynamic(backend_name)\n        else:\n            self.backend = Backend.create(backend_name)\n\n    def __repr__(self) -> str:\n        return ""<Runtime: Backend=\'{}\'>"".format(self.backend_name)\n\n    def computation(self, node_or_function: Union[Node, Function], *inputs: Node) -> ""Computation"":\n        """"""Return a callable Computation object.""""""\n        if isinstance(node_or_function, Node):\n            ng_function = Function(node_or_function, inputs, node_or_function.name)\n            return Computation(self, ng_function)\n        elif isinstance(node_or_function, Function):\n            return Computation(self, node_or_function)\n        else:\n            raise TypeError(\n                ""Runtime.computation must be called with an nGraph Function object ""\n                ""or an nGraph node object an optionally Parameter node objects. ""\n                ""Called with: %s"",\n                node_or_function,\n            )\n\n\nclass Computation(object):\n    """"""ngraph callable computation object.""""""\n\n    def __init__(self, runtime: Runtime, ng_function: Function) -> None:\n        self.runtime = runtime\n        self.function = ng_function\n        self.parameters = ng_function.get_parameters()\n        self.results = ng_function.get_results()\n        self.handle = self.runtime.backend.compile(self.function)\n\n        self.tensor_views = []  # type: List[Tensor]\n        for parameter in self.parameters:\n            shape = parameter.get_output_shape(0)\n            element_type = parameter.get_output_element_type(0)\n            self.tensor_views.append(runtime.backend.create_tensor(element_type, shape))\n\n        self.result_views = []  # type: List[Tensor]\n        for result in self.results:\n            element_type = result.get_output_element_type(0)\n            if self.function.is_dynamic():\n                output_pshape = result.get_output_partial_shape(0)\n                output_tensor = runtime.backend.create_dynamic_tensor(element_type, output_pshape)\n                self.result_views.append(output_tensor)\n            else:\n                output_shape = result.get_output_shape(0)\n                output_tensor = runtime.backend.create_tensor(element_type, output_shape)\n                self.result_views.append(output_tensor)\n\n    def __repr__(self) -> str:\n        params_string = "", "".join([param.name for param in self.parameters])\n        return ""<Computation: {}({})>"".format(self.function.get_name(), params_string)\n\n    def __call__(self, *input_values: NumericData) -> List[NumericData]:\n        """"""Run computation on input values and return result.""""""\n        for tensor_view, value in zip(self.tensor_views, input_values):\n            if not isinstance(value, np.ndarray):\n                value = np.array(value)\n            Computation._write_ndarray_to_tensor_view(value, tensor_view)\n\n        if self.function.is_dynamic():\n            self.handle.call_with_validate(self.result_views, self.tensor_views)\n        else:\n            self.handle.call(self.result_views, self.tensor_views)\n\n        results = []\n        for result_view in self.result_views:\n            result = np.ndarray(result_view.shape, dtype=get_dtype(result_view.element_type))\n            Computation._read_tensor_view_to_ndarray(result_view, result)\n            results.append(result)\n\n        return results\n\n    def serialize(self, indent: int = 0) -> str:\n        """"""Serialize function (compute graph) to a JSON string.\n\n        :param indent: set indent of serialized output\n        :return: serialized model\n        """"""\n        return serialize(self.function, indent)\n\n    @staticmethod\n    def _get_buffer_size(element_type: Tensor, element_count: int) -> int:\n        return int((element_type.bitwidth / 8.0) * element_count)\n\n    @staticmethod\n    def _write_ndarray_to_tensor_view(value: np.ndarray, tensor_view: Tensor) -> None:\n        tensor_view_dtype = get_dtype(tensor_view.element_type)\n        if list(tensor_view.shape) != list(value.shape) and len(value.shape) > 0:\n            raise UserInputError(\n                ""Provided tensor\'s shape: %s does not match the expected: %s."",\n                list(value.shape),\n                list(tensor_view.shape),\n            )\n        if value.dtype != tensor_view_dtype:\n            log.warning(\n                ""Attempting to write a %s value to a %s tensor. Will attempt type conversion."",\n                value.dtype,\n                tensor_view.element_type,\n            )\n            value = value.astype(tensor_view_dtype)\n\n        buffer_size = Computation._get_buffer_size(\n            tensor_view.element_type, tensor_view.element_count\n        )\n\n        nparray = np.ascontiguousarray(value)\n        tensor_view.write(util.numpy_to_c(nparray), buffer_size)\n\n    @staticmethod\n    def _read_tensor_view_to_ndarray(tensor_view: Tensor, output: np.ndarray) -> None:\n        buffer_size = Computation._get_buffer_size(\n            tensor_view.element_type, tensor_view.element_count\n        )\n        tensor_view.read(util.numpy_to_c(output), buffer_size)\n'"
python/src/pyngraph/util.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n# flake8: noqa\n\nfrom _pyngraph import util\n\nnumpy_to_c = util.numpy_to_c\n'"
python/test/ngraph/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n'"
python/test/ngraph/test_basic.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\nimport json\n\nimport ngraph as ng\nfrom ngraph.impl import Function\nfrom ngraph.exceptions import UserInputError\n\nimport test\nfrom test.ngraph.util import get_runtime, run_op_node\n\n\ndef test_ngraph_function_api():\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, dtype=np.float32, name=""A"")\n    parameter_b = ng.parameter(shape, dtype=np.float32, name=""B"")\n    parameter_c = ng.parameter(shape, dtype=np.float32, name=""C"")\n    model = (parameter_a + parameter_b) * parameter_c\n    function = Function(model, [parameter_a, parameter_b, parameter_c], ""TestFunction"")\n\n    ordered_ops = function.get_ordered_ops()\n    op_types = [op.get_type_name() for op in ordered_ops]\n    assert op_types == [""Parameter"", ""Parameter"", ""Parameter"", ""Add"", ""Multiply"", ""Result""]\n    assert len(function.get_ops()) == 6\n    assert function.get_output_size() == 1\n    assert function.get_output_op(0).get_type_name() == ""Result""\n    assert function.get_output_element_type(0) == parameter_a.get_output_element_type(0)\n    assert list(function.get_output_shape(0)) == [2, 2]\n    assert len(function.get_parameters()) == 3\n    assert len(function.get_results()) == 1\n    assert function.get_name() == ""TestFunction""\n\n\n@pytest.mark.parametrize(\n    ""dtype"",\n    [\n        np.float32,\n        np.float64,\n        np.int8,\n        np.int16,\n        np.int32,\n        np.int64,\n        np.uint8,\n        np.uint16,\n        np.uint32,\n        np.uint64,\n    ],\n)\ndef test_simple_computation_on_ndarrays(dtype):\n    runtime = get_runtime()\n\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, dtype=dtype, name=""A"")\n    parameter_b = ng.parameter(shape, dtype=dtype, name=""B"")\n    parameter_c = ng.parameter(shape, dtype=dtype, name=""C"")\n    model = (parameter_a + parameter_b) * parameter_c\n    computation = runtime.computation(model, parameter_a, parameter_b, parameter_c)\n\n    value_a = np.array([[1, 2], [3, 4]], dtype=dtype)\n    value_b = np.array([[5, 6], [7, 8]], dtype=dtype)\n    value_c = np.array([[9, 10], [11, 12]], dtype=dtype)\n    result = computation(value_a, value_b, value_c)\n    assert np.allclose(result, np.array([[54, 80], [110, 144]], dtype=dtype))\n\n    value_a = np.array([[13, 14], [15, 16]], dtype=dtype)\n    value_b = np.array([[17, 18], [19, 20]], dtype=dtype)\n    value_c = np.array([[21, 22], [23, 24]], dtype=dtype)\n    result = computation(value_a, value_b, value_c)\n    assert np.allclose(result, np.array([[630, 704], [782, 864]], dtype=dtype))\n\n\ndef test_serialization():\n    dtype = np.float32\n    backend_name = test.BACKEND_NAME\n\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, dtype=dtype, name=""A"")\n    parameter_b = ng.parameter(shape, dtype=dtype, name=""B"")\n    parameter_c = ng.parameter(shape, dtype=dtype, name=""C"")\n    model = (parameter_a + parameter_b) * parameter_c\n    runtime = ng.runtime(backend_name=backend_name)\n    computation = runtime.computation(model, parameter_a, parameter_b, parameter_c)\n    try:\n        serialized = computation.serialize(2)\n        serial_json = json.loads(serialized)\n\n        assert serial_json[0][""name""] != """"\n        assert 10 == len(serial_json[0][""ops""])\n    except Exception:\n        pass\n\n\ndef test_broadcast_1():\n    input_data = np.array([1, 2, 3])\n\n    new_shape = [3, 3]\n    expected = [[1, 2, 3], [1, 2, 3], [1, 2, 3]]\n    result = run_op_node([input_data], ng.broadcast, new_shape)\n    assert np.allclose(result, expected)\n\n\ndef test_broadcast_2():\n    input_data = np.arange(4)\n    new_shape = [3, 4, 2, 4]\n    expected = np.broadcast_to(input_data, new_shape)\n    result = run_op_node([input_data], ng.broadcast, new_shape)\n    assert np.allclose(result, expected)\n\n\ndef test_broadcast_3():\n    input_data = np.array([1, 2, 3])\n    new_shape = [3, 3]\n    axis_mapping = [0]\n    expected = [[1, 1, 1], [2, 2, 2], [3, 3, 3]]\n\n    result = run_op_node([input_data], ng.broadcast, new_shape, axis_mapping, ""EXPLICIT"")\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""destination_type, input_data"",\n    [(bool, np.zeros((2, 2), dtype=int)), (""boolean"", np.zeros((2, 2), dtype=int))],\n)\ndef test_convert_to_bool(destination_type, input_data):\n    expected = np.array(input_data, dtype=bool)\n    result = run_op_node([input_data], ng.convert, destination_type)\n    assert np.allclose(result, expected)\n    assert np.array(result).dtype == bool\n\n\n@pytest.mark.parametrize(\n    ""destination_type, rand_range, in_dtype, expected_type"",\n    [\n        (np.float32, (-8, 8), np.int32, np.float32),\n        (np.float64, (-16383, 16383), np.int64, np.float64),\n        (""f32"", (-8, 8), np.int32, np.float32),\n        (""f64"", (-16383, 16383), np.int64, np.float64),\n    ],\n)\ndef test_convert_to_float(destination_type, rand_range, in_dtype, expected_type):\n    np.random.seed(133391)\n    input_data = np.random.randint(*rand_range, size=(2, 2), dtype=in_dtype)\n    expected = np.array(input_data, dtype=expected_type)\n    result = run_op_node([input_data], ng.convert, destination_type)\n    assert np.allclose(result, expected)\n    assert np.array(result).dtype == expected_type\n\n\n@pytest.mark.parametrize(\n    ""destination_type, expected_type"",\n    [\n        (np.int8, np.int8),\n        (np.int16, np.int16),\n        (np.int32, np.int32),\n        (np.int64, np.int64),\n        (""i8"", np.int8),\n        (""i16"", np.int16),\n        (""i32"", np.int32),\n        (""i64"", np.int64),\n    ],\n)\ndef test_convert_to_int(destination_type, expected_type):\n    np.random.seed(133391)\n    input_data = np.ceil(-8 + np.random.rand(2, 3, 4) * 16)\n    expected = np.array(input_data, dtype=expected_type)\n    result = run_op_node([input_data], ng.convert, destination_type)\n    assert np.allclose(result, expected)\n    assert np.array(result).dtype == expected_type\n\n\n@pytest.mark.parametrize(\n    ""destination_type, expected_type"",\n    [\n        (np.uint8, np.uint8),\n        (np.uint16, np.uint16),\n        (np.uint32, np.uint32),\n        (np.uint64, np.uint64),\n        (""u8"", np.uint8),\n        (""u16"", np.uint16),\n        (""u32"", np.uint32),\n        (""u64"", np.uint64),\n    ],\n)\ndef test_convert_to_uint(destination_type, expected_type):\n    np.random.seed(133391)\n    input_data = np.ceil(np.random.rand(2, 3, 4) * 16)\n    expected = np.array(input_data, dtype=expected_type)\n    result = run_op_node([input_data], ng.convert, destination_type)\n    assert np.allclose(result, expected)\n    assert np.array(result).dtype == expected_type\n\n\ndef test_bad_data_shape():\n    A = ng.parameter(shape=[2, 2], name=""A"", dtype=np.float32)\n    B = ng.parameter(shape=[2, 2], name=""B"")\n    model = A + B\n    runtime = ng.runtime(backend_name=""INTERPRETER"")\n    computation = runtime.computation(model, A, B)\n\n    value_a = np.array([[1, 2]], dtype=np.float32)\n    value_b = np.array([[5, 6], [7, 8]], dtype=np.float32)\n    with pytest.raises(UserInputError):\n        computation(value_a, value_b)\n\n\ndef test_constant_get_data_bool():\n    input_data = np.array([True, False, False, True])\n    node = ng.constant(input_data, dtype=np.bool)\n    retrieved_data = node.get_data()\n    assert np.allclose(input_data, retrieved_data)\n\n\n@pytest.mark.parametrize(""data_type"", [np.float32, np.float64])\ndef test_constant_get_data_floating_point(data_type):\n    np.random.seed(133391)\n    input_data = np.random.randn(2, 3, 4).astype(data_type)\n    min_value = -1.0e20\n    max_value = 1.0e20\n    input_data = min_value + input_data * max_value * data_type(2)\n    node = ng.constant(input_data, dtype=data_type)\n    retrieved_data = node.get_data()\n    assert np.allclose(input_data, retrieved_data)\n\n\n@pytest.mark.parametrize(""data_type"", [np.int64, np.int32, np.int16, np.int8])\ndef test_constant_get_data_signed_integer(data_type):\n    np.random.seed(133391)\n    input_data = np.random.randint(np.iinfo(data_type).min, np.iinfo(data_type).max,\n                                   size=[2, 3, 4], dtype=data_type)\n    node = ng.constant(input_data, dtype=data_type)\n    retrieved_data = node.get_data()\n    assert np.allclose(input_data, retrieved_data)\n\n\n@pytest.mark.parametrize(""data_type"", [np.uint64, np.uint32, np.uint16, np.uint8])\ndef test_constant_get_data_unsigned_integer(data_type):\n    np.random.seed(133391)\n    input_data = np.random.randn(2, 3, 4).astype(data_type)\n    input_data = (\n        np.iinfo(data_type).min\n        + input_data * np.iinfo(data_type).max\n        + input_data * np.iinfo(data_type).max\n    )\n    node = ng.constant(input_data, dtype=data_type)\n    retrieved_data = node.get_data()\n    assert np.allclose(input_data, retrieved_data)\n\n\ndef test_result():\n    node = [[11, 10], [1, 8], [3, 4]]\n\n    result = test.ngraph.util.run_op_node([node], ng.ops.result)\n    assert np.allclose(result, node)\n'"
python/test/ngraph/test_convolution.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport numpy as np\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime, run_op_node\nfrom test.test_ops import convolution2d\n\n\ndef test_convolution_2d():\n\n    # input_x should have shape N(batch) x C x H x W\n    input_x = np.array(\n        [\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n        ],\n        dtype=np.float32,\n    ).reshape(1, 1, 9, 9)\n\n    # filter weights should have shape M x C x kH x kW\n    input_filter = np.array(\n        [[1.0, 0.0, -1.0], [2.0, 0.0, -2.0], [1.0, 0.0, -1.0]], dtype=np.float32\n    ).reshape(1, 1, 3, 3)\n\n    strides = np.array([1, 1])\n    pads_begin = np.array([1, 1])\n    pads_end = np.array([1, 1])\n    dilations = np.array([1, 1])\n\n    # convolution with padding=1 should produce 9 x 9 output:\n    result = run_op_node(\n        [input_x, input_filter], ng.convolution, strides, pads_begin, pads_end, dilations\n    )\n\n    assert np.allclose(\n        result,\n        np.array(\n            [\n                [\n                    [\n                        [0.0, -15.0, -15.0, 15.0, 15.0, 0.0, 0.0, 0.0, 0.0],\n                        [0.0, -20.0, -20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0],\n                        [0.0, -20.0, -20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0],\n                        [0.0, -20.0, -20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0],\n                        [0.0, -20.0, -20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0],\n                        [0.0, -20.0, -20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0],\n                        [0.0, -20.0, -20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0],\n                        [0.0, -20.0, -20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0],\n                        [0.0, -15.0, -15.0, 15.0, 15.0, 0.0, 0.0, 0.0, 0.0],\n                    ]\n                ]\n            ],\n            dtype=np.float32,\n        ),\n    )\n\n    # convolution with padding=0 should produce 7 x 7 output:\n    strides = np.array([1, 1])\n    pads_begin = np.array([0, 0])\n    pads_end = np.array([0, 0])\n    dilations = np.array([1, 1])\n    result = run_op_node(\n        [input_x, input_filter], ng.convolution, strides, pads_begin, pads_end, dilations\n    )\n    assert np.allclose(\n        result,\n        np.array(\n            [\n                [\n                    [\n                        [-20, -20, 20, 20, 0, 0, 0],\n                        [-20, -20, 20, 20, 0, 0, 0],\n                        [-20, -20, 20, 20, 0, 0, 0],\n                        [-20, -20, 20, 20, 0, 0, 0],\n                        [-20, -20, 20, 20, 0, 0, 0],\n                        [-20, -20, 20, 20, 0, 0, 0],\n                        [-20, -20, 20, 20, 0, 0, 0],\n                    ]\n                ]\n            ],\n            dtype=np.float32,\n        ),\n    )\n\n    strides = np.array([2, 2])\n    pads_begin = np.array([0, 0])\n    pads_end = np.array([0, 0])\n    dilations = np.array([1, 1])\n\n    # convolution with strides=2 should produce 4 x 4 output:\n    result = run_op_node(\n        [input_x, input_filter], ng.convolution, strides, pads_begin, pads_end, dilations\n    )\n\n    assert np.allclose(\n        result,\n        np.array(\n            [\n                [\n                    [\n                        [-20.0, 20.0, 0.0, 0.0],\n                        [-20.0, 20.0, 0.0, 0.0],\n                        [-20.0, 20.0, 0.0, 0.0],\n                        [-20.0, 20.0, 0.0, 0.0],\n                    ]\n                ]\n            ],\n            dtype=np.float32,\n        ),\n    )\n\n    strides = np.array([1, 1])\n    pads_begin = np.array([0, 0])\n    pads_end = np.array([0, 0])\n    dilations = np.array([2, 2])\n\n    # convolution with dilation=2 should produce 5 x 5 output:\n    result = run_op_node(\n        [input_x, input_filter], ng.convolution, strides, pads_begin, pads_end, dilations\n    )\n    assert np.allclose(\n        result,\n        np.array(\n            [\n                [\n                    [\n                        [0, 0, 20, 20, 0],\n                        [0, 0, 20, 20, 0],\n                        [0, 0, 20, 20, 0],\n                        [0, 0, 20, 20, 0],\n                        [0, 0, 20, 20, 0],\n                    ]\n                ]\n            ],\n            dtype=np.float32,\n        ),\n    )\n\n\ndef test_convolution_backprop_data():\n    runtime = get_runtime()\n\n    output_spatial_shape = [9, 9]\n    filter_shape = [1, 1, 3, 3]\n    data_shape = [1, 1, 7, 7]\n    strides = [1, 1]\n\n    data_node = ng.parameter(shape=data_shape)\n    filter_node = ng.parameter(shape=filter_shape)\n    output_shape_node = ng.constant(np.array(output_spatial_shape, dtype=np.int64))\n\n    deconvolution = ng.convolution_backprop_data(data_node, filter_node, strides, output_shape_node)\n\n    input_data = np.array(\n        [\n            [\n                [\n                    [-20, -20, 20, 20, 0, 0, 0],\n                    [-20, -20, 20, 20, 0, 0, 0],\n                    [-20, -20, 20, 20, 0, 0, 0],\n                    [-20, -20, 20, 20, 0, 0, 0],\n                    [-20, -20, 20, 20, 0, 0, 0],\n                    [-20, -20, 20, 20, 0, 0, 0],\n                    [-20, -20, 20, 20, 0, 0, 0],\n                ]\n            ]\n        ],\n        dtype=np.float32,\n    )\n\n    filter_data = np.array(\n        [[1.0, 0.0, -1.0], [2.0, 0.0, -2.0], [1.0, 0.0, -1.0]], dtype=np.float32\n    ).reshape(1, 1, 3, 3)\n\n    model = runtime.computation(deconvolution, data_node, filter_node)\n    result = model(input_data, filter_data)\n    assert np.allclose(\n        result,\n        np.array(\n            [\n                [\n                    [\n                        [-20.0, -20.0, 40.0, 40.0, -20.0, -20.0, 0.0, 0.0, 0.0],\n                        [-60.0, -60.0, 120.0, 120.0, -60.0, -60.0, 0.0, 0.0, 0.0],\n                        [-80.0, -80.0, 160.0, 160.0, -80.0, -80.0, 0.0, 0.0, 0.0],\n                        [-80.0, -80.0, 160.0, 160.0, -80.0, -80.0, 0.0, 0.0, 0.0],\n                        [-80.0, -80.0, 160.0, 160.0, -80.0, -80.0, 0.0, 0.0, 0.0],\n                        [-80.0, -80.0, 160.0, 160.0, -80.0, -80.0, 0.0, 0.0, 0.0],\n                        [-80.0, -80.0, 160.0, 160.0, -80.0, -80.0, 0.0, 0.0, 0.0],\n                        [-60.0, -60.0, 120.0, 120.0, -60.0, -60.0, 0.0, 0.0, 0.0],\n                        [-20.0, -20.0, 40.0, 40.0, -20.0, -20.0, 0.0, 0.0, 0.0],\n                    ]\n                ]\n            ],\n            dtype=np.float32,\n        ),\n    )\n\n\ndef test_convolution_v1():\n    input_tensor = np.arange(-128, 128, 1, dtype=np.float32).reshape(1, 1, 16, 16)\n    filters = np.ones(9, dtype=np.float32).reshape(1, 1, 3, 3)\n    filters[0, 0, 0, 0] = -1\n    filters[0, 0, 1, 1] = -1\n    filters[0, 0, 2, 2] = -1\n    filters[0, 0, 0, 2] = -1\n    filters[0, 0, 2, 0] = -1\n    strides = np.array([1, 1])\n    pads_begin = np.array([0, 0])\n    pads_end = np.array([0, 0])\n    dilations = np.array([1, 1])\n\n    result = run_op_node(\n        [input_tensor, filters], ng.convolution, strides, pads_begin, pads_end, dilations\n    )\n\n    expected = convolution2d(input_tensor[0, 0], filters[0, 0]).reshape(1, 1, 14, 14)\n\n    assert np.allclose(result, expected)\n'"
python/test/ngraph/test_core.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nfrom ngraph.impl import Dimension, PartialShape, Shape\n\n\ndef test_dimension():\n    dim = Dimension()\n    assert dim.is_dynamic\n    assert not dim.is_static\n    assert repr(dim) == ""<Dimension: ?>""\n\n    dim = Dimension.dynamic()\n    assert dim.is_dynamic\n    assert not dim.is_static\n    assert repr(dim) == ""<Dimension: ?>""\n\n    dim = Dimension(10)\n    assert dim.is_static\n    assert len(dim) == 10\n    assert dim.get_length() == 10\n    assert dim.get_min_length() == 10\n    assert dim.get_max_length() == 10\n    assert repr(dim) == ""<Dimension: 10>""\n\n    dim = Dimension(5, 15)\n    assert dim.is_dynamic\n    assert dim.get_min_length() == 5\n    assert dim.get_max_length() == 15\n    assert repr(dim) == ""<Dimension: [5, 15]>""\n\n\ndef test_dimension_comparisons():\n    d1 = Dimension.dynamic()\n    d2 = Dimension.dynamic()\n    assert d1 == d2\n    assert d1 == -1\n    assert d1.refines(d2)\n    assert d1.relaxes(d2)\n    assert d2.refines(d1)\n    assert d2.relaxes(d1)\n    assert d2.compatible(d1)\n    assert d2.same_scheme(d1)\n\n    d1 = Dimension.dynamic()\n    d2 = Dimension(3)\n    assert d1 != d2\n    assert d2 == 3\n    assert not d1.refines(d2)\n    assert d1.relaxes(d2)\n    assert d2.refines(d1)\n    assert not d2.relaxes(d1)\n    assert d2.compatible(d1)\n    assert not d2.same_scheme(d1)\n\n    d1 = Dimension(3)\n    d2 = Dimension(3)\n    assert d1 == d2\n    assert d1.refines(d2)\n    assert d1.relaxes(d2)\n    assert d2.refines(d1)\n    assert d2.relaxes(d1)\n    assert d2.compatible(d1)\n    assert d2.same_scheme(d1)\n\n    d1 = Dimension(4)\n    d2 = Dimension(3)\n    assert d1 != d2\n    assert not d1.refines(d2)\n    assert not d1.relaxes(d2)\n    assert not d2.refines(d1)\n    assert not d2.relaxes(d1)\n    assert not d2.compatible(d1)\n    assert not d2.same_scheme(d1)\n\n\ndef test_partial_shape():\n    ps = PartialShape([1, 2, 3, 4])\n    assert ps.is_static\n    assert not ps.is_dynamic\n    assert ps.rank == 4\n    assert repr(ps) == ""<PartialShape: {1,2,3,4}>""\n\n    shape = Shape([1, 2, 3])\n    ps = PartialShape(shape)\n    assert ps.is_static\n    assert not ps.is_dynamic\n    assert ps.all_non_negative\n    assert ps.rank == 3\n    assert list(ps.get_shape()) == [1, 2, 3]\n    assert list(ps.get_max_shape()) == [1, 2, 3]\n    assert list(ps.get_min_shape()) == [1, 2, 3]\n    assert list(ps.to_shape()) == [1, 2, 3]\n    assert repr(shape) == ""<Shape{1, 2, 3}>""\n    assert repr(ps) == ""<PartialShape: {1,2,3}>""\n\n    ps = PartialShape([Dimension(1), Dimension(2), Dimension(3), Dimension.dynamic()])\n    assert not ps.is_static\n    assert ps.is_dynamic\n    assert ps.all_non_negative\n    assert ps.rank == 4\n    assert list(ps.get_min_shape()) == [1, 2, 3, 0]\n    assert list(ps.get_max_shape())[3] > 1000000000\n    assert repr(ps) == ""<PartialShape: {1,2,3,?}>""\n\n    ps = PartialShape([1, 2, 3, -1])\n    assert not ps.is_static\n    assert ps.is_dynamic\n    assert ps.all_non_negative\n    assert ps.rank == 4\n    assert list(ps.get_min_shape()) == [1, 2, 3, 0]\n    assert list(ps.get_max_shape())[3] > 1000000000\n    assert repr(ps) == ""<PartialShape: {1,2,3,?}>""\n\n    ps = PartialShape.dynamic()\n    assert not ps.is_static\n    assert ps.is_dynamic\n    assert ps.rank == Dimension.dynamic()\n    assert list(ps.get_min_shape()) == []\n    assert list(ps.get_max_shape()) == []\n    assert repr(ps) == ""<PartialShape: ?>""\n\n    ps = PartialShape.dynamic(r=Dimension(2))\n    assert not ps.is_static\n    assert ps.is_dynamic\n    assert ps.rank == 2\n    assert 2 == ps.rank\n    assert list(ps.get_min_shape()) == [0, 0]\n    assert list(ps.get_max_shape())[0] > 1000000000\n    assert repr(ps) == ""<PartialShape: {?,?}>""\n\n\ndef test_partial_shape_compatible():\n    ps1 = PartialShape.dynamic()\n    ps2 = PartialShape.dynamic()\n    assert ps1.compatible(ps2)\n\n    ps1 = PartialShape([3])\n    ps2 = PartialShape.dynamic()\n    assert ps1.compatible(ps2)\n\n    ps1 = PartialShape.dynamic()\n    ps2 = PartialShape([4])\n    assert ps1.compatible(ps2)\n\n    ps1 = PartialShape([2, -1, 3, -1, 5])\n    ps2 = PartialShape([2, -1, -1, 4, 5])\n    assert ps1.compatible(ps2)\n\n    ps1 = PartialShape([2, -1, 3, -1, 5])\n    ps2 = PartialShape([1, -1, -1, 4, 5])\n    assert not ps1.compatible(ps2)\n\n\ndef test_partial_shape_same_scheme():\n    ps1 = PartialShape([1, 2, -1])\n    ps2 = PartialShape([1, 3, -1])\n    assert not ps1.same_scheme(ps2)\n\n    ps1 = PartialShape([1, 2, -1])\n    ps2 = PartialShape([1, 2, -1])\n    assert ps1.same_scheme(ps2)\n\n    ps1 = PartialShape([1, 2, 3])\n    ps2 = PartialShape([1, 2, 3])\n    assert ps1.same_scheme(ps2)\n\n    ps1 = PartialShape([-1, 2, 3])\n    ps2 = PartialShape([1, -1, 3])\n    assert not ps1.same_scheme(ps2)\n\n    ps1 = PartialShape.dynamic()\n    ps2 = PartialShape.dynamic()\n    assert ps1.same_scheme(ps2)\n\n\ndef test_partial_shape_refinement():\n    ps1 = PartialShape.dynamic()\n    ps2 = PartialShape.dynamic()\n    assert ps1.refines(ps2)\n    assert ps1.relaxes(ps2)\n    assert ps2.refines(ps1)\n    assert ps2.relaxes(ps1)\n\n    ps1 = PartialShape.dynamic()\n    ps2 = PartialShape([3, -1, 7, 9])\n    assert not ps1.refines(ps2)\n    assert ps1.relaxes(ps2)\n    assert ps2.refines(ps1)\n    assert not ps2.relaxes(ps1)\n\n    ps1 = PartialShape.dynamic()\n    ps2 = PartialShape([3, 5, 7, 9])\n    assert not ps1.refines(ps2)\n    assert ps1.relaxes(ps2)\n    assert ps2.refines(ps1)\n    assert not ps2.relaxes(ps1)\n\n\ndef test_partial_shape_equals():\n    ps1 = PartialShape.dynamic()\n    ps2 = PartialShape.dynamic()\n    assert ps1 == ps2\n\n    ps1 = PartialShape([1, 2, 3])\n    ps2 = PartialShape([1, 2, 3])\n    assert ps1 == ps2\n\n    shape = Shape([1, 2, 3])\n    ps = PartialShape([1, 2, 3])\n    assert shape == ps\n'"
python/test/ngraph/test_create_op.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\n\nimport ngraph as ng\nfrom ngraph.impl import Type\nfrom _pyngraph import PartialShape\nimport test\n\nnp_types = [np.float32, np.int32]\nintegral_np_types = [\n    np.int8,\n    np.int16,\n    np.int32,\n    np.int64,\n    np.uint8,\n    np.uint16,\n    np.uint32,\n    np.uint64,\n]\n\n\n@pytest.mark.parametrize(""dtype"", np_types)\ndef test_binary_convolution(dtype):\n    strides = np.array([1, 1])\n    pads_begin = np.array([0, 0])\n    pads_end = np.array([0, 0])\n    dilations = np.array([1, 1])\n    mode = ""xnor-popcount""\n    pad_value = 0.0\n\n    input0_shape = [1, 1, 9, 9]\n    input1_shape = [1, 1, 3, 3]\n    expected_shape = [1, 1, 7, 7]\n\n    parameter_input0 = ng.parameter(input0_shape, name=""Input0"", dtype=dtype)\n    parameter_input1 = ng.parameter(input1_shape, name=""Input1"", dtype=dtype)\n\n    node = ng.binary_convolution(\n        parameter_input0,\n        parameter_input1,\n        strides,\n        pads_begin,\n        pads_end,\n        dilations,\n        mode,\n        pad_value,\n    )\n\n    assert node.get_type_name() == ""BinaryConvolution""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\n@pytest.mark.parametrize(""dtype"", np_types)\ndef test_ctc_greedy_decoder(dtype):\n    input0_shape = [20, 8, 128]\n    input1_shape = [20, 8]\n    expected_shape = [8, 20, 1, 1]\n\n    parameter_input0 = ng.parameter(input0_shape, name=""Input0"", dtype=dtype)\n    parameter_input1 = ng.parameter(input1_shape, name=""Input1"", dtype=dtype)\n\n    node = ng.ctc_greedy_decoder(parameter_input0, parameter_input1)\n\n    assert node.get_type_name() == ""CTCGreedyDecoder""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\n@pytest.mark.parametrize(""dtype"", np_types)\ndef test_deformable_convolution(dtype):\n    strides = np.array([1, 1])\n    pads_begin = np.array([0, 0])\n    pads_end = np.array([0, 0])\n    dilations = np.array([1, 1])\n\n    input0_shape = [1, 1, 9, 9]\n    input1_shape = [1, 1, 9, 9]\n    input2_shape = [1, 1, 3, 3]\n    expected_shape = [1, 1, 7, 7]\n\n    parameter_input0 = ng.parameter(input0_shape, name=""Input0"", dtype=dtype)\n    parameter_input1 = ng.parameter(input1_shape, name=""Input1"", dtype=dtype)\n    parameter_input2 = ng.parameter(input2_shape, name=""Input2"", dtype=dtype)\n\n    node = ng.deformable_convolution(\n        parameter_input0,\n        parameter_input1,\n        parameter_input2,\n        strides,\n        pads_begin,\n        pads_end,\n        dilations,\n    )\n\n    assert node.get_type_name() == ""DeformableConvolution""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\n@pytest.mark.parametrize(""dtype"", np_types)\ndef test_deformable_psroi_pooling(dtype):\n    output_dim = 8\n    spatial_scale = 0.0625\n    group_size = 7\n    mode = ""bilinear_deformable""\n    spatial_bins_x = 4\n    spatial_bins_y = 4\n    trans_std = 0.1\n    part_size = 7\n\n    input0_shape = [1, 392, 38, 63]\n    input1_shape = [300, 5]\n    input2_shape = [300, 2, 7, 7]\n    expected_shape = [300, 8, 7, 7]\n\n    parameter_input0 = ng.parameter(input0_shape, name=""Input0"", dtype=dtype)\n    parameter_input1 = ng.parameter(input1_shape, name=""Input1"", dtype=dtype)\n    parameter_input2 = ng.parameter(input2_shape, name=""Input2"", dtype=dtype)\n\n    node = ng.deformable_psroi_pooling(\n        parameter_input0,\n        parameter_input1,\n        output_dim,\n        spatial_scale,\n        group_size,\n        mode,\n        spatial_bins_x,\n        spatial_bins_y,\n        trans_std,\n        part_size,\n        offsets=parameter_input2,\n    )\n\n    assert node.get_type_name() == ""DeformablePSROIPooling""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\n@pytest.mark.parametrize(""dtype"", np_types)\ndef test_floor_mod(dtype):\n    input0_shape = [8, 1, 6, 1]\n    input1_shape = [7, 1, 5]\n    expected_shape = [8, 7, 6, 5]\n\n    parameter_input0 = ng.parameter(input0_shape, name=""Input0"", dtype=dtype)\n    parameter_input1 = ng.parameter(input1_shape, name=""Input1"", dtype=dtype)\n\n    node = ng.floor_mod(parameter_input0, parameter_input1)\n\n    assert node.get_type_name() == ""FloorMod""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\n@pytest.mark.parametrize(""dtype"", np_types)\ndef test_gather_tree(dtype):\n    input0_shape = [100, 1, 10]\n    input1_shape = [100, 1, 10]\n    input2_shape = [1]\n    input3_shape = []\n    expected_shape = [100, 1, 10]\n\n    parameter_input0 = ng.parameter(input0_shape, name=""Input0"", dtype=dtype)\n    parameter_input1 = ng.parameter(input1_shape, name=""Input1"", dtype=dtype)\n    parameter_input2 = ng.parameter(input2_shape, name=""Input2"", dtype=dtype)\n    parameter_input3 = ng.parameter(input3_shape, name=""Input3"", dtype=dtype)\n\n    node = ng.gather_tree(parameter_input0, parameter_input1, parameter_input2, parameter_input3)\n\n    assert node.get_type_name() == ""GatherTree""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\n@pytest.mark.parametrize(""dtype"", [np.float32, np.float64])\ndef test_lstm_cell_operator(dtype):\n    batch_size = 1\n    input_size = 16\n    hidden_size = 128\n\n    X_shape = [batch_size, input_size]\n    H_t_shape = [batch_size, hidden_size]\n    C_t_shape = [batch_size, hidden_size]\n    W_shape = [4 * hidden_size, input_size]\n    R_shape = [4 * hidden_size, hidden_size]\n    B_shape = [4 * hidden_size]\n\n    parameter_X = ng.parameter(X_shape, name=""X"", dtype=dtype)\n    parameter_H_t = ng.parameter(H_t_shape, name=""H_t"", dtype=dtype)\n    parameter_C_t = ng.parameter(C_t_shape, name=""C_t"", dtype=dtype)\n    parameter_W = ng.parameter(W_shape, name=""W"", dtype=dtype)\n    parameter_R = ng.parameter(R_shape, name=""R"", dtype=dtype)\n    parameter_B = ng.parameter(B_shape, name=""B"", dtype=dtype)\n\n    expected_shape = [1, 128]\n\n    node_default = ng.lstm_cell(\n        parameter_X,\n        parameter_H_t,\n        parameter_C_t,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n    )\n\n    assert node_default.get_type_name() == ""LSTMCell""\n    assert node_default.get_output_size() == 2\n    assert list(node_default.get_output_shape(0)) == expected_shape\n    assert list(node_default.get_output_shape(1)) == expected_shape\n\n    activations = [""tanh"", ""Sigmoid"", ""RELU""]\n    activation_alpha = [1.0, 2.0, 3.0]\n    activation_beta = [3.0, 2.0, 1.0]\n    clip = 0.5\n\n    node_param = ng.lstm_cell(\n        parameter_X,\n        parameter_H_t,\n        parameter_C_t,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        activations,\n        activation_alpha,\n        activation_beta,\n        clip,\n    )\n\n    assert node_param.get_type_name() == ""LSTMCell""\n    assert node_param.get_output_size() == 2\n    assert list(node_param.get_output_shape(0)) == expected_shape\n    assert list(node_param.get_output_shape(1)) == expected_shape\n\n\n@pytest.mark.parametrize(""dtype"", [np.float32, np.float64])\ndef test_lstm_sequence_operator_bidirectional(dtype):\n    batch_size = 1\n    input_size = 16\n    hidden_size = 128\n    num_directions = 2\n    seq_length = 2\n\n    X_shape = [seq_length, batch_size, input_size]\n    H_t_shape = [num_directions, batch_size, hidden_size]\n    C_t_shape = [num_directions, batch_size, hidden_size]\n    seq_len_shape = [batch_size]\n    W_shape = [num_directions, 4 * hidden_size, input_size]\n    R_shape = [num_directions, 4 * hidden_size, hidden_size]\n    B_shape = [num_directions, 4 * hidden_size]\n\n    parameter_X = ng.parameter(X_shape, name=""X"", dtype=dtype)\n    parameter_H_t = ng.parameter(H_t_shape, name=""H_t"", dtype=dtype)\n    parameter_C_t = ng.parameter(C_t_shape, name=""C_t"", dtype=dtype)\n    parameter_seq_len = ng.parameter(seq_len_shape, name=""seq_len"", dtype=np.int32)\n    parameter_W = ng.parameter(W_shape, name=""W"", dtype=dtype)\n    parameter_R = ng.parameter(R_shape, name=""R"", dtype=dtype)\n    parameter_B = ng.parameter(B_shape, name=""B"", dtype=dtype)\n\n    direction = ""BIDIRECTIONAL""\n    node = ng.lstm_sequence(\n        parameter_X,\n        parameter_H_t,\n        parameter_C_t,\n        parameter_seq_len,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        direction,\n    )\n\n    assert node.get_type_name() == ""LSTMSequence""\n    assert node.get_output_size() == 3\n\n    activations = [""RELU"", ""tanh"", ""Sigmoid""]\n    activation_alpha = [1.0, 2.0, 3.0]\n    activation_beta = [3.0, 2.0, 1.0]\n    clip = 1.22\n\n    node_param = ng.lstm_sequence(\n        parameter_X,\n        parameter_H_t,\n        parameter_C_t,\n        parameter_seq_len,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        direction,\n        activations,\n        activation_alpha,\n        activation_beta,\n        clip,\n    )\n\n    assert node_param.get_type_name() == ""LSTMSequence""\n    assert node_param.get_output_size() == 3\n\n\n@pytest.mark.parametrize(""dtype"", [np.float32, np.float64])\ndef test_lstm_sequence_operator_reverse(dtype):\n    batch_size = 2\n    input_size = 4\n    hidden_size = 3\n    num_directions = 1\n    seq_length = 2\n\n    X_shape = [seq_length, batch_size, input_size]\n    H_t_shape = [num_directions, batch_size, hidden_size]\n    C_t_shape = [num_directions, batch_size, hidden_size]\n    seq_len_shape = [batch_size]\n    W_shape = [num_directions, 4 * hidden_size, input_size]\n    R_shape = [num_directions, 4 * hidden_size, hidden_size]\n    B_shape = [num_directions, 4 * hidden_size]\n\n    parameter_X = ng.parameter(X_shape, name=""X"", dtype=dtype)\n    parameter_H_t = ng.parameter(H_t_shape, name=""H_t"", dtype=dtype)\n    parameter_C_t = ng.parameter(C_t_shape, name=""C_t"", dtype=dtype)\n    parameter_seq_len = ng.parameter(seq_len_shape, name=""seq_len"", dtype=np.int32)\n    parameter_W = ng.parameter(W_shape, name=""W"", dtype=dtype)\n    parameter_R = ng.parameter(R_shape, name=""R"", dtype=dtype)\n    parameter_B = ng.parameter(B_shape, name=""B"", dtype=dtype)\n\n    direction = ""REVERSE""\n\n    node_default = ng.lstm_sequence(\n        parameter_X,\n        parameter_H_t,\n        parameter_C_t,\n        parameter_seq_len,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        direction,\n    )\n\n    assert node_default.get_type_name() == ""LSTMSequence""\n    assert node_default.get_output_size() == 3\n\n    activations = [""RELU"", ""tanh"", ""Sigmoid""]\n    activation_alpha = [1.0, 2.0, 3.0]\n    activation_beta = [3.0, 2.0, 1.0]\n    clip = 1.22\n\n    node_param = ng.lstm_sequence(\n        parameter_X,\n        parameter_H_t,\n        parameter_C_t,\n        parameter_seq_len,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        direction,\n        activations,\n        activation_alpha,\n        activation_beta,\n        clip,\n    )\n\n    assert node_param.get_type_name() == ""LSTMSequence""\n    assert node_param.get_output_size() == 3\n\n\n@pytest.mark.parametrize(""dtype"", [np.float32, np.float64])\ndef test_lstm_sequence_operator_forward(dtype):\n    batch_size = 2\n    input_size = 4\n    hidden_size = 3\n    num_directions = 1\n    seq_length = 2\n\n    X_shape = [seq_length, batch_size, input_size]\n    H_t_shape = [num_directions, batch_size, hidden_size]\n    C_t_shape = [num_directions, batch_size, hidden_size]\n    seq_len_shape = [batch_size]\n    W_shape = [num_directions, 4 * hidden_size, input_size]\n    R_shape = [num_directions, 4 * hidden_size, hidden_size]\n    B_shape = [num_directions, 4 * hidden_size]\n\n    parameter_X = ng.parameter(X_shape, name=""X"", dtype=dtype)\n    parameter_H_t = ng.parameter(H_t_shape, name=""H_t"", dtype=dtype)\n    parameter_C_t = ng.parameter(C_t_shape, name=""C_t"", dtype=dtype)\n    parameter_seq_len = ng.parameter(seq_len_shape, name=""seq_len"", dtype=np.int32)\n    parameter_W = ng.parameter(W_shape, name=""W"", dtype=dtype)\n    parameter_R = ng.parameter(R_shape, name=""R"", dtype=dtype)\n    parameter_B = ng.parameter(B_shape, name=""B"", dtype=dtype)\n\n    direction = ""forward""\n\n    node_default = ng.lstm_sequence(\n        parameter_X,\n        parameter_H_t,\n        parameter_C_t,\n        parameter_seq_len,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        direction,\n    )\n\n    assert node_default.get_type_name() == ""LSTMSequence""\n    assert node_default.get_output_size() == 3\n\n    activations = [""RELU"", ""tanh"", ""Sigmoid""]\n    activation_alpha = [2.0]\n    activation_beta = [1.0]\n    clip = 0.5\n\n    node = ng.lstm_sequence(\n        parameter_X,\n        parameter_H_t,\n        parameter_C_t,\n        parameter_seq_len,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        direction,\n        activations,\n        activation_alpha,\n        activation_beta,\n        clip,\n    )\n\n    assert node.get_type_name() == ""LSTMSequence""\n    assert node.get_output_size() == 3\n\n\ndef test_gru_cell_operator():\n    batch_size = 1\n    input_size = 16\n    hidden_size = 128\n\n    X_shape = [batch_size, input_size]\n    H_t_shape = [batch_size, hidden_size]\n    W_shape = [3 * hidden_size, input_size]\n    R_shape = [3 * hidden_size, hidden_size]\n    B_shape = [3 * hidden_size]\n\n    parameter_X = ng.parameter(X_shape, name=""X"", dtype=np.float32)\n    parameter_H_t = ng.parameter(H_t_shape, name=""H_t"", dtype=np.float32)\n    parameter_W = ng.parameter(W_shape, name=""W"", dtype=np.float32)\n    parameter_R = ng.parameter(R_shape, name=""R"", dtype=np.float32)\n    parameter_B = ng.parameter(B_shape, name=""B"", dtype=np.float32)\n\n    expected_shape = [1, 128]\n\n    node_default = ng.gru_cell(\n        parameter_X, parameter_H_t, parameter_W, parameter_R, parameter_B, hidden_size\n    )\n\n    assert node_default.get_type_name() == ""GRUCell""\n    assert node_default.get_output_size() == 1\n    assert list(node_default.get_output_shape(0)) == expected_shape\n\n    activations = [""tanh"", ""relu""]\n    activations_alpha = [1.0, 2.0]\n    activations_beta = [1.0, 2.0]\n    clip = 0.5\n    linear_before_reset = True\n\n    # If *linear_before_reset* is set True, then B tensor shape must be [4 * hidden_size]\n    B_shape = [4 * hidden_size]\n    parameter_B = ng.parameter(B_shape, name=""B"", dtype=np.float32)\n\n    node_param = ng.gru_cell(\n        parameter_X,\n        parameter_H_t,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        activations,\n        activations_alpha,\n        activations_beta,\n        clip,\n        linear_before_reset,\n    )\n\n    assert node_param.get_type_name() == ""GRUCell""\n    assert node_param.get_output_size() == 1\n    assert list(node_param.get_output_shape(0)) == expected_shape\n\n\ndef test_roi_pooling():\n    inputs = ng.parameter([2, 3, 4, 5], dtype=np.float32)\n    coords = ng.parameter([150, 5], dtype=np.float32)\n    node = ng.roi_pooling(inputs, coords, [6, 6], 0.0625, ""Max"")\n\n    assert node.get_type_name() == ""ROIPooling""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [150, 3, 6, 6]\n    assert node.get_output_element_type(0) == Type.f32\n\n\ndef test_psroi_pooling():\n    inputs = ng.parameter([1, 3, 4, 5], dtype=np.float32)\n    coords = ng.parameter([150, 5], dtype=np.float32)\n    node = ng.psroi_pooling(inputs, coords, 2, 6, 0.0625, 0, 0, ""Avg"")\n\n    assert node.get_type_name() == ""PSROIPooling""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [150, 2, 6, 6]\n    assert node.get_output_element_type(0) == Type.f32\n\n\ndef test_convert_like():\n    parameter_data = ng.parameter([1, 2, 3, 4], name=""data"", dtype=np.float32)\n    like = ng.constant(1, dtype=np.int8)\n\n    node = ng.convert_like(parameter_data, like)\n\n    assert node.get_type_name() == ""ConvertLike""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [1, 2, 3, 4]\n    assert node.get_output_element_type(0) == Type.i8\n\n\ndef test_one_hot():\n    data = np.array([0, 1, 2], dtype=np.int32)\n    depth = 2\n    on_value = 5\n    off_value = 10\n    axis = -1\n    excepted = [[5, 10], [10, 5], [10, 10]]\n\n    result = test.ngraph.util.run_op_node([data, depth, on_value, off_value], ng.ops.one_hot, axis)\n    assert np.allclose(result, excepted)\n\n\ndef test_reverse():\n    parameter_data = ng.parameter([3, 10, 100, 200], name=""data"", dtype=np.float32)\n    parameter_axis = ng.parameter([1], name=""axis"", dtype=np.int64)\n    expected_shape = [3, 10, 100, 200]\n\n    node = ng.reverse(parameter_data, parameter_axis, ""index"")\n\n    assert node.get_type_name() == ""Reverse""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n    assert node.get_output_element_type(0) == Type.f32\n\n\ndef test_select():\n    cond = [[False, False], [True, False], [True, True]]\n    then_node = [[-1, 0], [1, 2], [3, 4]]\n    else_node = [[11, 10], [9, 8], [7, 6]]\n    excepted = [[11, 10], [1, 8], [3, 4]]\n\n    result = test.ngraph.util.run_op_node([cond, then_node, else_node], ng.ops.select)\n    assert np.allclose(result, excepted)\n\n\ndef test_result():\n    node = [[11, 10], [1, 8], [3, 4]]\n\n    result = test.ngraph.util.run_op_node([node], ng.ops.result)\n    assert np.allclose(result, node)\n\n\ndef test_bucketize():\n    data = ng.parameter([4, 3, 2, 1], name=""data"", dtype=np.float32)\n    buckets = ng.parameter([5], name=""buckets"", dtype=np.int64)\n\n    node = ng.bucketize(data, buckets, ""i32"")\n\n    assert node.get_type_name() == ""Bucketize""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [4, 3, 2, 1]\n    assert node.get_output_element_type(0) == Type.i32\n\n\ndef test_range():\n    start = 5\n    stop = 35\n    step = 5\n\n    result = test.ngraph.util.run_op_node([start, stop, step], ng.ops.range)\n    assert np.allclose(result, [5, 10, 15, 20, 25, 30])\n\n\ndef test_region_yolo():\n    data = ng.parameter([1, 125, 13, 13], name=""input"", dtype=np.float32)\n    num_coords = 4\n    num_classes = 80\n    num_regions = 1\n    mask = [6, 7, 8]\n    axis = 0\n    end_axis = 3\n    do_softmax = False\n\n    node = ng.region_yolo(data, num_coords, num_classes, num_regions,\n                          do_softmax, mask, axis, end_axis)\n\n    assert node.get_type_name() == ""RegionYolo""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [1, (80 + 4 + 1) * 3, 13, 13]\n    assert node.get_output_element_type(0) == Type.f32\n\n\ndef test_reorg_yolo():\n    data = ng.parameter([2, 24, 34, 62], name=""input"", dtype=np.int32)\n    stride = [2]\n\n    node = ng.reorg_yolo(data, stride)\n\n    assert node.get_type_name() == ""ReorgYolo""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [2, 96, 17, 31]\n    assert node.get_output_element_type(0) == Type.i32\n\n\ndef test_embedding_bag_offsets_sum_1():\n    emb_table = ng.parameter([5, 2], name=""emb_table"", dtype=np.float32)\n    indices = ng.parameter([4], name=""indices"", dtype=np.int64)\n    offsets = ng.parameter([3], name=""offsets"", dtype=np.int64)\n    default_index = ng.parameter([], name=""default_index"", dtype=np.int64)\n\n    node = ng.embedding_bag_offsets_sum(emb_table, indices, offsets, default_index)\n\n    assert node.get_type_name() == ""EmbeddingBagOffsetsSum""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [3, 2]\n    assert node.get_output_element_type(0) == Type.f32\n\n\ndef test_embedding_segments_sum_all_inputs():\n    emb_table = ng.parameter([5, 2], name=""emb_table"", dtype=np.float32)\n    indices = ng.parameter([4], name=""indices"", dtype=np.int64)\n    segment_ids = ng.parameter([4], name=""segment_ids"", dtype=np.int64)\n    num_segments = ng.parameter([], name=""num_segments"", dtype=np.int64)\n    default_index = ng.parameter([], name=""default_index"", dtype=np.int64)\n    per_sample_weights = ng.parameter([4], name=""per_sample_weights"", dtype=np.float32)\n\n    node = ng.embedding_segments_sum(\n        emb_table, indices, segment_ids, num_segments, default_index, per_sample_weights\n    )\n\n    assert node.get_type_name() == ""EmbeddingSegmentsSum""\n    assert node.get_output_size() == 1\n    assert node.get_output_partial_shape(0).same_scheme(PartialShape([-1, 2]))\n    assert node.get_output_element_type(0) == Type.f32\n\n\ndef test_embedding_segments_sum_with_some_opt_inputs():\n    emb_table = ng.parameter([5, 2], name=""emb_table"", dtype=np.float32)\n    indices = ng.parameter([4], name=""indices"", dtype=np.int64)\n    segment_ids = ng.parameter([4], name=""segment_ids"", dtype=np.int64)\n    num_segments = ng.parameter([], name=""num_segments"", dtype=np.int64)\n\n    # only 1 out of 3 optional inputs\n    node = ng.embedding_segments_sum(emb_table, indices, segment_ids, num_segments)\n\n    assert node.get_type_name() == ""EmbeddingSegmentsSum""\n    assert node.get_output_size() == 1\n    assert node.get_output_partial_shape(0).same_scheme(PartialShape([-1, 2]))\n    assert node.get_output_element_type(0) == Type.f32\n\n\ndef test_embedding_bag_packed_sum():\n    emb_table = ng.parameter([5, 2], name=""emb_table"", dtype=np.float32)\n    indices = ng.parameter([3, 3], name=""indices"", dtype=np.int64)\n    per_sample_weights = ng.parameter([3, 3], name=""per_sample_weights"", dtype=np.float32)\n\n    # only 1 out of 3 optional inputs\n    node = ng.embedding_bag_packed_sum(emb_table, indices, per_sample_weights)\n\n    assert node.get_type_name() == ""EmbeddingBagPackedSum""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [3, 2]\n    assert node.get_output_element_type(0) == Type.f32\n\n\n@pytest.mark.parametrize(""dtype"", integral_np_types)\ndef test_interpolate(dtype):\n    image_shape = [1, 3, 1024, 1024]\n    output_shape = [64, 64]\n    attributes = {\n        ""attrs.axes"": [2, 3],\n        ""attrs.mode"": ""cubic"",\n        ""attrs.pads_begin"": np.array([2, 2], dtype=dtype),\n    }\n\n    image_node = ng.parameter(image_shape, dtype, name=""Image"")\n\n    node = ng.interpolate(image_node, output_shape, attributes)\n    expected_shape = [1, 3, 64, 64]\n\n    assert node.get_type_name() == ""Interpolate""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\n@pytest.mark.parametrize(\n    ""int_dtype, fp_dtype"",\n    [\n        (np.int8, np.float32),\n        (np.int16, np.float32),\n        (np.int32, np.float32),\n        (np.int64, np.float32),\n        (np.uint8, np.float32),\n        (np.uint16, np.float32),\n        (np.uint32, np.float32),\n        (np.uint64, np.float32),\n        (np.int32, np.float16),\n        (np.int32, np.float64),\n    ],\n)\ndef test_prior_box(int_dtype, fp_dtype):\n    image_shape = np.array([64, 64], dtype=int_dtype)\n    attributes = {\n        ""attrs.offset"": fp_dtype(0),\n        ""attrs.min_size"": np.array([2, 3], dtype=fp_dtype),\n        ""attrs.aspect_ratio"": np.array([1.5, 2.0, 2.5], dtype=fp_dtype),\n    }\n\n    layer_shape = ng.constant(np.array([32, 32], dtype=int_dtype), int_dtype)\n\n    node = ng.prior_box(layer_shape, image_shape, attributes)\n\n    assert node.get_type_name() == ""PriorBox""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [2, 20480]\n\n\n@pytest.mark.parametrize(\n    ""int_dtype, fp_dtype"",\n    [\n        (np.int8, np.float32),\n        (np.int16, np.float32),\n        (np.int32, np.float32),\n        (np.int64, np.float32),\n        (np.uint8, np.float32),\n        (np.uint16, np.float32),\n        (np.uint32, np.float32),\n        (np.uint64, np.float32),\n        (np.int32, np.float16),\n        (np.int32, np.float64),\n    ],\n)\ndef test_prior_box_clustered(int_dtype, fp_dtype):\n    image_size = np.array([64, 64], dtype=int_dtype)\n    attributes = {\n        ""attrs.offset"": fp_dtype(0.5),\n        ""attrs.widths"": np.array([4.0, 2.0, 3.2], dtype=fp_dtype),\n        ""attrs.heights"": np.array([1.0, 2.0, 1.0], dtype=fp_dtype),\n    }\n\n    output_size = ng.constant(np.array([19, 19], dtype=int_dtype), int_dtype)\n\n    node = ng.prior_box_clustered(output_size, image_size, attributes)\n\n    assert node.get_type_name() == ""PriorBoxClustered""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [2, 4332]\n\n\n@pytest.mark.parametrize(\n    ""int_dtype, fp_dtype"",\n    [\n        (np.int8, np.float32),\n        (np.int16, np.float32),\n        (np.int32, np.float32),\n        (np.int64, np.float32),\n        (np.uint8, np.float32),\n        (np.uint16, np.float32),\n        (np.uint32, np.float32),\n        (np.uint64, np.float32),\n        (np.int32, np.float16),\n        (np.int32, np.float64),\n    ],\n)\ndef test_detection_output(int_dtype, fp_dtype):\n    attributes = {\n        ""attrs.num_classes"": int_dtype(85),\n        ""attrs.keep_top_k"": np.array([64], dtype=int_dtype),\n        ""attrs.nms_threshold"": fp_dtype(0.645),\n    }\n\n    box_logits = ng.parameter([4, 1, 5, 5], fp_dtype, ""box_logits"")\n    class_preds = ng.parameter([2, 1, 4, 5], fp_dtype, ""class_preds"")\n    proposals = ng.parameter([2, 1, 4, 5], fp_dtype, ""proposals"")\n    aux_class_preds = ng.parameter([2, 1, 4, 5], fp_dtype, ""aux_class_preds"")\n    aux_box_preds = ng.parameter([2, 1, 4, 5], fp_dtype, ""aux_box_preds"")\n\n    node = ng.detection_output(\n        box_logits, class_preds, proposals, attributes, aux_class_preds, aux_box_preds\n    )\n\n    assert node.get_type_name() == ""DetectionOutput""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [1, 1, 256, 7]\n\n\n@pytest.mark.parametrize(\n    ""int_dtype, fp_dtype"",\n    [\n        (np.uint8, np.float32),\n        (np.uint16, np.float32),\n        (np.uint32, np.float32),\n        (np.uint64, np.float32),\n        (np.uint32, np.float16),\n        (np.uint32, np.float64),\n    ],\n)\ndef test_proposal(int_dtype, fp_dtype):\n    attributes = {\n        ""attrs.base_size"": int_dtype(1),\n        ""attrs.pre_nms_topn"": int_dtype(20),\n        ""attrs.post_nms_topn"": int_dtype(64),\n        ""attrs.nms_thresh"": fp_dtype(0.34),\n        ""attrs.feat_stride"": int_dtype(16),\n        ""attrs.min_size"": int_dtype(32),\n        ""attrs.ratio"": np.array([0.1, 1.5, 2.0, 2.5], dtype=fp_dtype),\n        ""attrs.scale"": np.array([2, 3, 3, 4], dtype=fp_dtype),\n    }\n    batch_size = 7\n\n    class_probs = ng.parameter([batch_size, 12, 34, 62], fp_dtype, ""class_probs"")\n    class_logits = ng.parameter([batch_size, 24, 34, 62], fp_dtype, ""class_logits"")\n    image_shape = ng.parameter([3], fp_dtype, ""image_shape"")\n    node = ng.proposal(class_probs, class_logits, image_shape, attributes)\n\n    assert node.get_type_name() == ""Proposal""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [batch_size * attributes[""attrs.post_nms_topn""], 5]\n'"
python/test/ngraph/test_data_movement.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime, run_op_node\n\n\ndef test_reverse_sequence():\n    input_data = np.array(\n        [\n            0,\n            0,\n            3,\n            0,\n            6,\n            0,\n            9,\n            0,\n            1,\n            0,\n            4,\n            0,\n            7,\n            0,\n            10,\n            0,\n            2,\n            0,\n            5,\n            0,\n            8,\n            0,\n            11,\n            0,\n            12,\n            0,\n            15,\n            0,\n            18,\n            0,\n            21,\n            0,\n            13,\n            0,\n            16,\n            0,\n            19,\n            0,\n            22,\n            0,\n            14,\n            0,\n            17,\n            0,\n            20,\n            0,\n            23,\n            0,\n        ],\n        dtype=np.int32,\n    ).reshape([2, 3, 4, 2])\n    seq_lenghts = np.array([1, 2, 1, 2], dtype=np.int32)\n    batch_axis = 2\n    sequence_axis = 1\n\n    input_param = ng.parameter(input_data.shape, name=""input"", dtype=np.int32)\n    seq_lengths_param = ng.parameter(seq_lenghts.shape, name=""sequence lengths"", dtype=np.int32)\n    model = ng.reverse_sequence(input_param, seq_lengths_param, batch_axis, sequence_axis)\n\n    runtime = get_runtime()\n    computation = runtime.computation(model, input_param, seq_lengths_param)\n    result = computation(input_data, seq_lenghts)\n\n    expected = np.array(\n        [\n            0,\n            0,\n            4,\n            0,\n            6,\n            0,\n            10,\n            0,\n            1,\n            0,\n            3,\n            0,\n            7,\n            0,\n            9,\n            0,\n            2,\n            0,\n            5,\n            0,\n            8,\n            0,\n            11,\n            0,\n            12,\n            0,\n            16,\n            0,\n            18,\n            0,\n            22,\n            0,\n            13,\n            0,\n            15,\n            0,\n            19,\n            0,\n            21,\n            0,\n            14,\n            0,\n            17,\n            0,\n            20,\n            0,\n            23,\n            0,\n        ],\n    ).reshape([1, 2, 3, 4, 2])\n    assert np.allclose(result, expected)\n\n\ndef test_pad_edge():\n    input_data = np.arange(1, 13).reshape([3, 4])\n    pads_begin = np.array([0, 1], dtype=np.int32)\n    pads_end = np.array([2, 3], dtype=np.int32)\n\n    input_param = ng.parameter(input_data.shape, name=""input"", dtype=np.int32)\n    model = ng.pad(input_param, pads_begin, pads_end, ""edge"")\n\n    runtime = get_runtime()\n    computation = runtime.computation(model, input_param)\n    result = computation(input_data)\n\n    expected = np.array(\n        [\n            [1, 1, 2, 3, 4, 4, 4, 4],\n            [5, 5, 6, 7, 8, 8, 8, 8],\n            [9, 9, 10, 11, 12, 12, 12, 12],\n            [9, 9, 10, 11, 12, 12, 12, 12],\n            [9, 9, 10, 11, 12, 12, 12, 12],\n        ]\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_pad_constant():\n    input_data = np.arange(1, 13).reshape([3, 4])\n    pads_begin = np.array([0, 1], dtype=np.int32)\n    pads_end = np.array([2, 3], dtype=np.int32)\n\n    input_param = ng.parameter(input_data.shape, name=""input"", dtype=np.int64)\n    model = ng.pad(\n        input_param, pads_begin, pads_end, ""constant"", arg_pad_value=np.array(100, dtype=np.int64)\n    )\n\n    runtime = get_runtime()\n    computation = runtime.computation(model, input_param)\n    result = computation(input_data)\n\n    expected = np.array(\n        [\n            [100, 1, 2, 3, 4, 100, 100, 100],\n            [100, 5, 6, 7, 8, 100, 100, 100],\n            [100, 9, 10, 11, 12, 100, 100, 100],\n            [100, 100, 100, 100, 100, 100, 100, 100],\n            [100, 100, 100, 100, 100, 100, 100, 100],\n        ]\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_select():\n    cond = [[False, False], [True, False], [True, True]]\n    then_node = [[-1, 0], [1, 2], [3, 4]]\n    else_node = [[11, 10], [9, 8], [7, 6]]\n    excepted = [[11, 10], [1, 8], [3, 4]]\n\n    result = run_op_node([cond, then_node, else_node], ng.select)\n    assert np.allclose(result, excepted)\n'"
python/test/ngraph/test_input_validation.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\n\nfrom ngraph.exceptions import UserInputError\nfrom ngraph.utils.input_validation import (\n    _check_value,\n    check_valid_attribute,\n    check_valid_attributes,\n    is_positive_value,\n    is_non_negative_value,\n)\n\n\n@pytest.mark.parametrize(""dtype"", [np.int8, np.int16, np.int32, np.int64, np.float32, np.float64])\ndef test_is_positive_value_signed_type(dtype):\n    assert is_positive_value(dtype(16))\n    assert not is_positive_value(dtype(-16))\n\n\n@pytest.mark.parametrize(""dtype"", [np.uint8, np.uint16, np.uint32, np.uint64])\ndef test_is_positive_value_unsigned_type(dtype):\n    assert is_positive_value(dtype(16))\n\n\n@pytest.mark.parametrize(""dtype"", [np.int8, np.int16, np.int32, np.int64, np.float32, np.float64])\ndef test_is_non_negative_value_signed_type(dtype):\n    assert is_non_negative_value(dtype(16))\n    assert is_non_negative_value(dtype(0))\n    assert not is_non_negative_value(dtype(-1))\n    assert not is_non_negative_value(dtype(-16))\n\n\n@pytest.mark.parametrize(""dtype"", [np.uint8, np.uint16, np.uint32, np.uint64])\ndef test_is_non_negative_value_unsigned_type(dtype):\n    assert is_non_negative_value(dtype(16))\n    assert is_non_negative_value(dtype(0))\n\n\n@pytest.mark.parametrize(\n    ""value, val_type"",\n    [\n        (np.int8(64), np.integer),\n        (np.int16(64), np.integer),\n        (np.int32(64), np.integer),\n        (np.int64(64), np.integer),\n        (np.uint8(64), np.unsignedinteger),\n        (np.uint16(64), np.unsignedinteger),\n        (np.uint32(64), np.unsignedinteger),\n        (np.uint64(64), np.unsignedinteger),\n        (np.float32(64), np.floating),\n        (np.float64(64), np.floating),\n    ],\n)\ndef test_check_value(value, val_type):\n    def is_even(x):\n        return x % 2 == 0\n\n    assert _check_value(""TestOp"", ""test_attr"", value, val_type, is_even)\n\n\n@pytest.mark.parametrize(\n    ""value, val_type"",\n    [\n        (np.int8(64), np.floating),\n        (np.int16(64), np.floating),\n        (np.int32(64), np.floating),\n        (np.int64(64), np.floating),\n        (np.uint8(64), np.floating),\n        (np.uint16(64), np.floating),\n        (np.uint32(64), np.floating),\n        (np.uint64(64), np.floating),\n        (np.float32(64), np.integer),\n        (np.float64(64), np.integer),\n    ],\n)\ndef test_check_value_fail_type(value, val_type):\n    try:\n        _check_value(""TestOp"", ""test_attr"", value, val_type, None)\n    except UserInputError:\n        pass\n    else:\n        raise AssertionError(""Type validation has unexpectedly passed."")\n\n\n@pytest.mark.parametrize(\n    ""value, val_type"",\n    [\n        (np.int8(61), np.integer),\n        (np.int16(61), np.integer),\n        (np.int32(61), np.integer),\n        (np.int64(61), np.integer),\n        (np.uint8(61), np.unsignedinteger),\n        (np.uint16(61), np.unsignedinteger),\n        (np.uint32(61), np.unsignedinteger),\n        (np.uint64(61), np.unsignedinteger),\n        (np.float32(61), np.floating),\n        (np.float64(61), np.floating),\n    ],\n)\ndef test_check_value_fail_cond(value, val_type):\n    def is_even(x):\n        return x % 2 == 0\n\n    try:\n        _check_value(""TestOp"", ""test_attr"", value, val_type, is_even)\n    except UserInputError:\n        pass\n    else:\n        raise AssertionError(""Condition validation has unexpectedly passed."")\n\n\ndef test_check_valid_attribute():\n    attr_dict = {\n        ""mode"": ""bilinear"",\n        ""coefficients"": [1, 2, 3, 4, 5],\n    }\n\n    assert check_valid_attribute(""TestOp"", attr_dict, ""width"", np.unsignedinteger, required=False)\n    assert check_valid_attribute(""TestOp"", attr_dict, ""mode"", np.str_, required=True)\n    assert check_valid_attribute(""TestOp"", attr_dict, ""coefficients"", np.integer, required=True)\n\n    try:\n        check_valid_attribute(""TestOp"", attr_dict, ""alpha"", np.floating, required=True)\n    except UserInputError:\n        pass\n    else:\n        raise AssertionError(""Validation of missing required attribute has unexpectedly passed."")\n\n\ndef test_check_valid_attributes():\n    attr_dict = {\n        ""mode"": ""bilinear"",\n        ""coefficients"": [1, 2, 3, 4, 5],\n    }\n\n    def _is_supported_mode(x):\n        return x in [""linear"", ""area"", ""cubic"", ""bilinear""]\n\n    requirements = [\n        (""width"", False, np.unsignedinteger, None),\n        (""mode"", True, np.str_, _is_supported_mode),\n        (""coefficients"", True, np.integer, lambda x: x > 0),\n        (""alpha"", False, np.float64, None),\n    ]\n\n    assert check_valid_attributes(""TestOp"", attr_dict, requirements)\n\n    requirements[3] = (""alpha"", True, np.float64, None)\n    try:\n        check_valid_attributes(""TestOp"", attr_dict, requirements)\n    except UserInputError:\n        pass\n    else:\n        raise AssertionError(""Validation of missing required attribute has unexpectedly passed."")\n'"
python/test/ngraph/test_node_factory.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport ngraph as ng\n\nfrom _pyngraph import NodeFactory as _NodeFactory\n\n\ndef test_node_factory_add():\n    shape = [2, 2]\n    dtype = np.int8\n    parameter_a = ng.parameter(shape, dtype=dtype, name=""A"")\n    parameter_b = ng.parameter(shape, dtype=dtype, name=""B"")\n\n    factory = _NodeFactory(""opset1"")\n    node = factory.create(""Add"", [parameter_a, parameter_b], {})\n\n    assert node.get_type_name() == ""Add""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [2, 2]\n\n\ndef test_node_factory_wrapper_add():\n    shape = [2, 2]\n    dtype = np.int8\n    parameter_a = ng.parameter(shape, dtype=dtype, name=""A"")\n    parameter_b = ng.parameter(shape, dtype=dtype, name=""B"")\n\n    node = ng.add(parameter_a, parameter_b, name=""TestNode"")\n\n    assert node.get_type_name() == ""Add""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [2, 2]\n    assert node.name == ""TestNode""\n\n\ndef test_node_factory_topk():\n    dtype = np.int32\n    data = ng.parameter([2, 10], dtype=dtype, name=""A"")\n    k = ng.constant(3, dtype=dtype, name=""B"")\n    factory = _NodeFactory(""opset1"")\n    node = factory.create(""TopK"", [data, k], {""axis"": 1, ""mode"": ""max"", ""sort"": ""value""})\n\n    assert node.get_type_name() == ""TopK""\n    assert node.get_output_size() == 2\n    assert list(node.get_output_shape(0)) == [2, 3]\n'"
python/test/ngraph/test_normalization.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport numpy as np\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime\nimport test\n\n\ndef test_lrn():\n    input_image_shape = (2, 3, 2, 1)\n    input_image = np.arange(int(np.prod(input_image_shape))).reshape(input_image_shape).astype(""f"")\n    axes = np.array([1], dtype=np.int64)\n    runtime = get_runtime()\n    model = ng.lrn(\n        ng.constant(input_image), ng.constant(axes), alpha=1.0, beta=2.0, bias=1.0, size=3\n    )\n    computation = runtime.computation(model)\n    result = computation()\n    assert np.allclose(\n        result,\n        np.array(\n            [\n                [[[0.0], [0.05325444]], [[0.03402646], [0.01869806]], [[0.06805293], [0.03287071]]],\n                [\n                    [[0.00509002], [0.00356153]],\n                    [[0.00174719], [0.0012555]],\n                    [[0.00322708], [0.00235574]],\n                ],\n            ],\n            dtype=np.float32,\n        ),\n    )\n\n    # Test LRN default parameter values\n    model = ng.lrn(ng.constant(input_image), ng.constant(axes))\n    computation = runtime.computation(model)\n    result = computation()\n    assert np.allclose(\n        result,\n        np.array(\n            [\n                [[[0.0], [0.35355338]], [[0.8944272], [1.0606602]], [[1.7888544], [1.767767]]],\n                [\n                    [[0.93704253], [0.97827977]],\n                    [[1.2493901], [1.2577883]],\n                    [[1.5617375], [1.5372968]],\n                ],\n            ],\n            dtype=np.float32,\n        ),\n    )\n\n\ndef test_lrn_factory():\n    alpha = 0.0002\n    beta = 0.5\n    bias = 2.0\n    nsize = 3\n    axis = [1]\n    x = np.array(\n        [\n            [\n                [\n                    [0.31403765, -0.16793324, 1.388258, -0.6902954],\n                    [-0.3994045, -0.7833511, -0.30992958, 0.3557573],\n                    [-0.4682631, 1.1741459, -2.414789, -0.42783254],\n                ],\n                [\n                    [-0.82199496, -0.03900861, -0.43670088, -0.53810567],\n                    [-0.10769883, 0.75242394, -0.2507971, 1.0447186],\n                    [-1.4777364, 0.19993274, 0.925649, -2.282516],\n                ],\n            ]\n        ],\n        dtype=np.float32,\n    )\n    excepted = np.array(\n        [\n            [\n                [\n                    [0.22205527, -0.11874668, 0.98161197, -0.4881063],\n                    [-0.2824208, -0.553902, -0.21915273, 0.2515533],\n                    [-0.33109877, 0.8302269, -1.7073234, -0.3024961],\n                ],\n                [\n                    [-0.5812307, -0.02758324, -0.30878326, -0.38049328],\n                    [-0.07615435, 0.53203356, -0.17733987, 0.7387126],\n                    [-1.0448756, 0.14137045, 0.6544598, -1.6138376],\n                ],\n            ]\n        ],\n        dtype=np.float32,\n    )\n    result = test.ngraph.util.run_op_node([x, axis], ng.ops.lrn, alpha, beta, bias, nsize)\n\n    assert np.allclose(result, excepted)\n\n\ndef test_batch_norm_inference():\n    data = [[1.0, 2.0, 3.0], [-1.0, -2.0, -3.0]]\n    gamma = [2.0, 3.0, 4.0]\n    beta = [0.0, 0.0, 0.0]\n    mean = [0.0, 0.0, 0.0]\n    variance = [1.0, 1.0, 1.0]\n    epsilon = 9.99e-06\n    excepted = [[2.0, 6.0, 12.0], [-2.0, -6.0, -12.0]]\n\n    result = test.ngraph.util.run_op_node(\n        [data, gamma, beta, mean, variance], ng.ops.batch_norm_inference, epsilon\n    )\n    assert np.allclose(result, excepted)\n'"
python/test/ngraph/test_onnx_import.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport os\nimport numpy as np\n\nfrom test.ngraph.util import get_runtime\n\ntry:\n    from ngraph.impl.onnx_import import import_onnx_model_file\n\n    def test_import_onnx_function():\n        model_path = os.path.join(os.path.dirname(__file__), ""models/add_abc.onnx"")\n        ng_function = import_onnx_model_file(model_path)\n\n        dtype = np.float32\n        value_a = np.array([1.0], dtype=dtype)\n        value_b = np.array([2.0], dtype=dtype)\n        value_c = np.array([3.0], dtype=dtype)\n\n        runtime = get_runtime()\n        computation = runtime.computation(ng_function)\n        result = computation(value_a, value_b, value_c)\n        assert np.allclose(result, np.array([6], dtype=dtype))\n\n\nexcept ImportError:\n    # Do not test load_onnx_model_file if nGraph was build without ONNX support\n    pass\n'"
python/test/ngraph/test_ops_binary.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport operator\n\nimport numpy as np\nimport pytest\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime, run_op_node\n\n\n@pytest.mark.parametrize(\n    ""ng_api_helper,numpy_function"",\n    [\n        (ng.add, np.add),\n        (ng.divide, np.divide),\n        (ng.multiply, np.multiply),\n        (ng.subtract, np.subtract),\n        (ng.minimum, np.minimum),\n        (ng.maximum, np.maximum),\n        (ng.mod, np.mod),\n        (ng.equal, np.equal),\n        (ng.not_equal, np.not_equal),\n        (ng.greater, np.greater),\n        (ng.greater_equal, np.greater_equal),\n        (ng.less, np.less),\n        (ng.less_equal, np.less_equal),\n    ],\n)\ndef test_binary_op(ng_api_helper, numpy_function):\n    runtime = get_runtime()\n\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, name=""A"", dtype=np.float32)\n    parameter_b = ng.parameter(shape, name=""B"", dtype=np.float32)\n\n    model = ng_api_helper(parameter_a, parameter_b)\n    computation = runtime.computation(model, parameter_a, parameter_b)\n\n    value_a = np.array([[1, 2], [3, 4]], dtype=np.float32)\n    value_b = np.array([[5, 6], [7, 8]], dtype=np.float32)\n\n    result = computation(value_a, value_b)\n    expected = numpy_function(value_a, value_b)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""ng_api_helper,numpy_function"",\n    [\n        (ng.add, np.add),\n        (ng.divide, np.divide),\n        (ng.multiply, np.multiply),\n        (ng.subtract, np.subtract),\n        (ng.minimum, np.minimum),\n        (ng.maximum, np.maximum),\n        (ng.mod, np.mod),\n        (ng.equal, np.equal),\n        (ng.not_equal, np.not_equal),\n        (ng.greater, np.greater),\n        (ng.greater_equal, np.greater_equal),\n        (ng.less, np.less),\n        (ng.less_equal, np.less_equal),\n    ],\n)\ndef test_binary_op_with_scalar(ng_api_helper, numpy_function):\n    runtime = get_runtime()\n\n    value_a = np.array([[1, 2], [3, 4]], dtype=np.float32)\n    value_b = np.array([[5, 6], [7, 8]], dtype=np.float32)\n\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, name=""A"", dtype=np.float32)\n\n    model = ng_api_helper(parameter_a, value_b)\n    computation = runtime.computation(model, parameter_a)\n\n    result = computation(value_a)\n    expected = numpy_function(value_a, value_b)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""ng_api_helper,numpy_function"",\n    [\n        (ng.logical_and, np.logical_and),\n        (ng.logical_or, np.logical_or),\n        (ng.logical_xor, np.logical_xor),\n    ],\n)\ndef test_binary_logical_op(ng_api_helper, numpy_function):\n    runtime = get_runtime()\n\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, name=""A"", dtype=np.bool)\n    parameter_b = ng.parameter(shape, name=""B"", dtype=np.bool)\n\n    model = ng_api_helper(parameter_a, parameter_b)\n    computation = runtime.computation(model, parameter_a, parameter_b)\n\n    value_a = np.array([[True, False], [False, True]], dtype=np.bool)\n    value_b = np.array([[False, True], [False, True]], dtype=np.bool)\n\n    result = computation(value_a, value_b)\n    expected = numpy_function(value_a, value_b)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""ng_api_helper,numpy_function"",\n    [\n        (ng.logical_and, np.logical_and),\n        (ng.logical_or, np.logical_or),\n        (ng.logical_xor, np.logical_xor),\n    ],\n)\ndef test_binary_logical_op_with_scalar(ng_api_helper, numpy_function):\n    runtime = get_runtime()\n\n    value_a = np.array([[True, False], [False, True]], dtype=np.bool)\n    value_b = np.array([[False, True], [False, True]], dtype=np.bool)\n\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, name=""A"", dtype=np.bool)\n\n    model = ng_api_helper(parameter_a, value_b)\n    computation = runtime.computation(model, parameter_a)\n\n    result = computation(value_a)\n    expected = numpy_function(value_a, value_b)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""operator,numpy_function"",\n    [\n        (operator.add, np.add),\n        (operator.sub, np.subtract),\n        (operator.mul, np.multiply),\n        (operator.truediv, np.divide),\n        (operator.eq, np.equal),\n        (operator.ne, np.not_equal),\n        (operator.gt, np.greater),\n        (operator.ge, np.greater_equal),\n        (operator.lt, np.less),\n        (operator.le, np.less_equal),\n    ],\n)\ndef test_binary_operators(operator, numpy_function):\n    runtime = get_runtime()\n\n    value_a = np.array([[1, 2], [3, 4]], dtype=np.float32)\n    value_b = np.array([[4, 5], [1, 7]], dtype=np.float32)\n\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, name=""A"", dtype=np.float32)\n\n    model = operator(parameter_a, value_b)\n    computation = runtime.computation(model, parameter_a)\n\n    result = computation(value_a)\n    expected = numpy_function(value_a, value_b)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""operator,numpy_function"",\n    [\n        (operator.add, np.add),\n        (operator.sub, np.subtract),\n        (operator.mul, np.multiply),\n        (operator.truediv, np.divide),\n        (operator.eq, np.equal),\n        (operator.ne, np.not_equal),\n        (operator.gt, np.greater),\n        (operator.ge, np.greater_equal),\n        (operator.lt, np.less),\n        (operator.le, np.less_equal),\n    ],\n)\ndef test_binary_operators_with_scalar(operator, numpy_function):\n    runtime = get_runtime()\n\n    value_a = np.array([[1, 2], [3, 4]], dtype=np.float32)\n    value_b = np.array([[5, 6], [7, 8]], dtype=np.float32)\n\n    shape = [2, 2]\n    parameter_a = ng.parameter(shape, name=""A"", dtype=np.float32)\n\n    model = operator(parameter_a, value_b)\n    computation = runtime.computation(model, parameter_a)\n\n    result = computation(value_a)\n    expected = numpy_function(value_a, value_b)\n    assert np.allclose(result, expected)\n\n\ndef test_multiply():\n    A = np.arange(48).reshape((8, 1, 6, 1))\n    B = np.arange(35).reshape((7, 1, 5))\n\n    expected = np.multiply(A, B)\n    result = run_op_node([A, B], ng.multiply)\n\n    assert np.allclose(result, expected)\n\n\ndef test_power_v1():\n    A = np.arange(48, dtype=np.float32).reshape((8, 1, 6, 1))\n    B = np.arange(20, dtype=np.float32).reshape((4, 1, 5))\n\n    expected = np.power(A, B)\n    result = run_op_node([A, B], ng.power)\n\n    assert np.allclose(result, expected)\n'"
python/test/ngraph/test_ops_fused.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime\n\n\ndef test_elu_operator_with_scalar_and_array():\n    runtime = get_runtime()\n\n    data_value = np.array([[-5, 1], [-2, 3]], dtype=np.float32)\n    alpha_value = np.float32(3)\n\n    model = ng.elu(data_value, alpha_value)\n    computation = runtime.computation(model)\n\n    result = computation()\n    expected = np.array([[-2.9797862, 1.0], [-2.5939941, 3.0]], dtype=np.float32)\n    assert np.allclose(result, expected)\n\n\ndef test_elu_operator_with_scalar():\n    runtime = get_runtime()\n\n    data_value = np.array([[-5, 1], [-2, 3]], dtype=np.float32)\n    alpha_value = np.float32(3)\n\n    data_shape = [2, 2]\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    model = ng.elu(parameter_data, alpha_value)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n    expected = np.array([[-2.9797862, 1.0], [-2.5939941, 3.0]], dtype=np.float32)\n    assert np.allclose(result, expected)\n\n\ndef test_fake_quantize():\n    runtime = get_runtime()\n\n    data_value = np.arange(24.0, dtype=np.float32).reshape(1, 2, 3, 4)\n    input_low_value = np.float32(0)\n    input_high_value = np.float32(23)\n    output_low_value = np.float32(2)\n    output_high_value = np.float32(16)\n    levels = np.float32(4)\n\n    data_shape = [1, 2, 3, 4]\n    bound_shape = []\n    parameter_data = ng.parameter(data_shape, name=""data"", dtype=np.float32)\n    parameter_input_low = ng.parameter(bound_shape, name=""input_low"", dtype=np.float32)\n    parameter_input_high = ng.parameter(bound_shape, name=""input_high"", dtype=np.float32)\n    parameter_output_low = ng.parameter(bound_shape, name=""output_low"", dtype=np.float32)\n    parameter_output_high = ng.parameter(bound_shape, name=""output_high"", dtype=np.float32)\n\n    model = ng.fake_quantize(\n        parameter_data,\n        parameter_input_low,\n        parameter_input_high,\n        parameter_output_low,\n        parameter_output_high,\n        levels,\n    )\n    computation = runtime.computation(\n        model,\n        parameter_data,\n        parameter_input_low,\n        parameter_input_high,\n        parameter_output_low,\n        parameter_output_high,\n    )\n\n    result = computation(\n        data_value, input_low_value, input_high_value, output_low_value, output_high_value\n    )\n\n    expected = np.array(\n        [\n            [\n                [\n                    [\n                        [2.0, 2.0, 2.0, 2.0],\n                        [6.6666669, 6.6666669, 6.6666669, 6.6666669],\n                        [6.6666669, 6.6666669, 6.6666669, 6.6666669],\n                    ],\n                    [\n                        [11.33333301, 11.33333301, 11.33333301, 11.33333301],\n                        [11.33333301, 11.33333301, 11.33333301, 11.33333301],\n                        [16.0, 16.0, 16.0, 16.0],\n                    ],\n                ]\n            ]\n        ],\n        dtype=np.float32,\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_depth_to_space():\n    runtime = get_runtime()\n\n    data_value = np.array(\n        [\n            [\n                [[0, 1, 2], [3, 4, 5]],\n                [[6, 7, 8], [9, 10, 11]],\n                [[12, 13, 14], [15, 16, 17]],\n                [[18, 19, 20], [21, 22, 23]],\n            ]\n        ],\n        dtype=np.float32,\n    )\n    mode = ""blocks_first""\n    block_size = np.float32(2)\n\n    data_shape = [1, 4, 2, 3]\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    model = ng.depth_to_space(parameter_data, mode, block_size)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n    expected = np.array(\n        [\n            [\n                [\n                    [0, 6, 1, 7, 2, 8],\n                    [12, 18, 13, 19, 14, 20],\n                    [3, 9, 4, 10, 5, 11],\n                    [15, 21, 16, 22, 17, 23],\n                ]\n            ]\n        ],\n        dtype=np.float32,\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_space_to_batch():\n    runtime = get_runtime()\n\n    data_value = np.array([[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]], dtype=np.float32)\n    data_shape = data_value.shape\n\n    block_shape = np.array([1, 2, 3, 2], dtype=np.int64)\n    pads_begin = np.array([0, 0, 1, 0], dtype=np.int64)\n    pads_end = np.array([0, 0, 0, 1], dtype=np.int64)\n\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    model = ng.space_to_batch(parameter_data, block_shape, pads_begin, pads_end)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n    expected = np.array(\n        [\n            [[[0, 0]]],\n            [[[0, 0]]],\n            [[[0, 2]]],\n            [[[1, 0]]],\n            [[[3, 5]]],\n            [[[4, 0]]],\n            [[[0, 0]]],\n            [[[0, 0]]],\n            [[[6, 8]]],\n            [[[7, 0]]],\n            [[[9, 11]]],\n            [[[10, 0]]],\n        ],\n        dtype=np.float32,\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_batch_to_space():\n    runtime = get_runtime()\n\n    data = np.array(\n        [\n            [[[0, 0]]],\n            [[[0, 0]]],\n            [[[0, 2]]],\n            [[[1, 0]]],\n            [[[3, 5]]],\n            [[[4, 0]]],\n            [[[0, 0]]],\n            [[[0, 0]]],\n            [[[6, 8]]],\n            [[[7, 0]]],\n            [[[9, 11]]],\n            [[[10, 0]]],\n        ],\n        dtype=np.float32,\n    )\n    data_shape = data.shape\n\n    block_shape = np.array([1, 2, 3, 2], dtype=np.int64)\n    crops_begin = np.array([0, 0, 1, 0], dtype=np.int64)\n    crops_end = np.array([0, 0, 0, 1], dtype=np.int64)\n\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    model = ng.batch_to_space(parameter_data, block_shape, crops_begin, crops_end)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data)\n    expected = np.array([[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]], dtype=np.float32)\n\n    assert np.allclose(result, expected)\n\n\ndef test_gelu_operator_with_parameters():\n    runtime = get_runtime()\n\n    data_value = np.array([[-5, 1], [-2, 3]], dtype=np.float32)\n\n    data_shape = [2, 2]\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    model = ng.gelu(parameter_data)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n    expected = np.array(\n        [[-1.4901161e-06, 8.4134471e-01], [-4.5500278e-02, 2.9959502]], dtype=np.float32\n    )\n    assert np.allclose(result, expected, 0.007, 0.007)\n\n\ndef test_gelu_operator_with_array():\n    runtime = get_runtime()\n\n    data_value = np.array([[-5, 1], [-2, 3]], dtype=np.float32)\n\n    model = ng.gelu(data_value)\n    computation = runtime.computation(model)\n\n    result = computation()\n    expected = np.array(\n        [[-1.4901161e-06, 8.4134471e-01], [-4.5500278e-02, 2.9959502]], dtype=np.float32\n    )\n\n    assert np.allclose(result, expected, 0.007, 0.007)\n\n\ndef test_clamp_operator():\n    runtime = get_runtime()\n\n    data_shape = [2, 2]\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    min_value = np.float32(3)\n    max_value = np.float32(12)\n\n    model = ng.clamp(parameter_data, min_value, max_value)\n    computation = runtime.computation(model, parameter_data)\n\n    data_value = np.array([[-5, 9], [45, 3]], dtype=np.float32)\n\n    result = computation(data_value)\n    expected = np.clip(data_value, min_value, max_value)\n    assert np.allclose(result, expected)\n\n\ndef test_clamp_operator_with_array():\n    runtime = get_runtime()\n\n    data_value = np.array([[-5, 9], [45, 3]], dtype=np.float32)\n    min_value = np.float32(3)\n    max_value = np.float32(12)\n\n    model = ng.clamp(data_value, min_value, max_value)\n    computation = runtime.computation(model)\n\n    result = computation()\n    expected = np.clip(data_value, min_value, max_value)\n\n    assert np.allclose(result, expected)\n\n\ndef test_squeeze_operator():\n    runtime = get_runtime()\n\n    data_shape = [1, 2, 1, 3, 1, 1]\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    data_value = np.arange(6.0, dtype=np.float32).reshape(1, 2, 1, 3, 1, 1)\n    axes = [2, 4]\n    model = ng.squeeze(parameter_data, axes)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n    expected = np.arange(6.0, dtype=np.float32).reshape(1, 2, 3, 1)\n    assert np.allclose(result, expected)\n\n\ndef test_squared_difference_operator():\n    runtime = get_runtime()\n\n    x1_shape = [1, 2, 3, 4]\n    x2_shape = [2, 3, 4]\n\n    parameter_x1 = ng.parameter(x1_shape, name=""x1"", dtype=np.float32)\n    parameter_x2 = ng.parameter(x2_shape, name=""x2"", dtype=np.float32)\n\n    x1_value = np.arange(24.0, dtype=np.float32).reshape(x1_shape)\n    x2_value = np.arange(start=4.0, stop=28.0, step=1.0, dtype=np.float32).reshape(x2_shape)\n\n    model = ng.squared_difference(parameter_x1, parameter_x2)\n    computation = runtime.computation(model, parameter_x1, parameter_x2)\n\n    result = computation(x1_value, x2_value)\n    expected = np.square(np.subtract(x1_value, x2_value))\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.skip_on_cpu\n@pytest.mark.skip_on_interpreter\ndef test_shuffle_channels_operator():\n    runtime = get_runtime()\n\n    data_shape = [1, 15, 2, 2]\n    axis = 1\n    groups = 5\n\n    parameter = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    data_value = np.arange(60.0, dtype=np.float32).reshape(data_shape)\n\n    model = ng.shuffle_channels(parameter, axis, groups)\n    computation = runtime.computation(model, parameter)\n\n    result = computation(data_value)\n    expected = np.array(\n        [\n            [\n                [[0.0, 1.0], [2.0, 3.0]],\n                [[12.0, 13.0], [14.0, 15.0]],\n                [[24.0, 25.0], [26.0, 27.0]],\n                [[36.0, 37.0], [38.0, 39.0]],\n                [[48.0, 49.0], [50.0, 51.0]],\n                [[4.0, 5.0], [6.0, 7.0]],\n                [[16.0, 17.0], [18.0, 19.0]],\n                [[28.0, 29.0], [30.0, 31.0]],\n                [[40.0, 41.0], [42.0, 43.0]],\n                [[52.0, 53.0], [54.0, 55.0]],\n                [[8.0, 9.0], [10.0, 11.0]],\n                [[20.0, 21.0], [22.0, 23.0]],\n                [[32.0, 33.0], [34.0, 35.0]],\n                [[44.0, 45.0], [46.0, 47.0]],\n                [[56.0, 57.0], [58.0, 59.0]],\n            ]\n        ],\n        dtype=np.float32,\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_unsqueeze():\n    runtime = get_runtime()\n\n    data_shape = [3, 4, 5]\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    data_value = np.arange(60.0, dtype=np.float32).reshape(3, 4, 5)\n    axes = [0, 4]\n    model = ng.unsqueeze(parameter_data, axes)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n    expected = np.arange(60.0, dtype=np.float32).reshape(1, 3, 4, 5, 1)\n    assert np.allclose(result, expected)\n\n\ndef test_grn_operator():\n    runtime = get_runtime()\n\n    data_value = np.arange(start=1.0, stop=25.0, dtype=np.float32).reshape(1, 2, 3, 4)\n    bias = np.float32(1e-6)\n\n    data_shape = [1, 2, 3, 4]\n\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    model = ng.grn(parameter_data, bias)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n    expected = np.array(\n        [\n            [\n                [\n                    [0.0766965, 0.14142136, 0.19611613, 0.24253564],\n                    [0.28216633, 0.31622776, 0.34570536, 0.37139067],\n                    [0.39391932, 0.41380295, 0.4314555, 0.4472136],\n                ],\n                [\n                    [0.9970545, 0.98994946, 0.9805807, 0.97014254],\n                    [0.9593655, 0.9486833, 0.9383431, 0.9284767],\n                    [0.91914505, 0.9103665, 0.9021342, 0.8944272],\n                ],\n            ]\n        ],\n        dtype=np.float32,\n    )\n\n    assert np.allclose(result, expected)\n\n\ndef test_prelu_operator():\n    runtime = get_runtime()\n\n    data_shape = [1, 2, 3, 4]\n    slope_shape = [2, 3, 1]\n\n    data_value = np.arange(start=1.0, stop=25.0, dtype=np.float32).reshape(data_shape)\n    slope_value = np.arange(start=-10.0, stop=-4.0, dtype=np.float32).reshape(slope_shape)\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    parameter_slope = ng.parameter(slope_shape, name=""Slope"", dtype=np.float32)\n\n    model = ng.prelu(parameter_data, parameter_slope)\n    computation = runtime.computation(model, parameter_data, parameter_slope)\n\n    result = computation(data_value, slope_value)\n    expected = np.clip(data_value, 0, np.inf) + np.clip(data_value, -np.inf, 0) * slope_value\n    assert np.allclose(result, expected)\n\n\ndef test_selu_operator():\n    runtime = get_runtime()\n\n    data_shape = [4, 2, 3, 1]\n\n    data = np.arange(start=1.0, stop=25.0, dtype=np.float32).reshape(data_shape)\n    alpha = np.array(1.6733, dtype=np.float32)\n    lambda_value = np.array(1.0507, dtype=np.float32)\n\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    model = ng.selu(parameter_data, alpha, lambda_value)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data)\n    expected = lambda_value * ((data > 0) * data + (data <= 0) * (alpha * np.exp(data) - alpha))\n    assert np.allclose(result, expected)\n\n\ndef test_hard_sigmoid_operator():\n    runtime = get_runtime()\n\n    data_shape = [3]\n    alpha_value = np.float32(0.5)\n    beta_value = np.float32(0.6)\n\n    data_value = np.array([-1, 0, 1], dtype=np.float32)\n\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    parameter_alpha = ng.parameter([], name=""Alpha"", dtype=np.float32)\n    parameter_beta = ng.parameter([], name=""Beta"", dtype=np.float32)\n\n    model = ng.hard_sigmoid(parameter_data, parameter_alpha, parameter_beta)\n    computation = runtime.computation(model, parameter_data, parameter_alpha, parameter_beta)\n\n    result = computation(data_value, alpha_value, beta_value)\n    expected = [0.1, 0.6, 1.0]\n    assert np.allclose(result, expected)\n\n\ndef test_mvn_operator():\n    runtime = get_runtime()\n\n    data_shape = [3, 3, 3, 1]\n    across_channels = True\n    normalize_variance = True\n    eps = np.float32(1e-9)\n\n    data_value = np.array(\n        [\n            [\n                [[0.8439683], [0.5665144], [0.05836735]],\n                [[0.02916367], [0.12964272], [0.5060197]],\n                [[0.79538304], [0.9411346], [0.9546573]],\n            ],\n            [\n                [[0.17730942], [0.46192095], [0.26480448]],\n                [[0.6746842], [0.01665257], [0.62473077]],\n                [[0.9240844], [0.9722341], [0.11965699]],\n            ],\n            [\n                [[0.41356155], [0.9129373], [0.59330076]],\n                [[0.81929934], [0.7862604], [0.11799799]],\n                [[0.69248444], [0.54119414], [0.07513223]],\n            ],\n        ],\n        dtype=np.float32,\n    )\n\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    model = ng.mvn(parameter_data, across_channels, normalize_variance, eps)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n\n    expected = np.array(\n        [\n            [\n                [[0.9951074], [0.14548765], [-1.410561]],\n                [[-1.4999886], [-1.1923014], [-0.03975919]],\n                [[0.8463296], [1.2926502], [1.3340596]],\n            ],\n            [\n                [[-1.0463363], [-0.1747985], [-0.7784088]],\n                [[0.47672555], [-1.5383], [0.32375798]],\n                [[1.2404392], [1.3878832], [-1.2228798]],\n            ],\n            [\n                [[-0.3228847], [1.2063044], [0.22751297]],\n                [[0.91956615], [0.81839436], [-1.2279599]],\n                [[0.5312334], [0.067952], [-1.3592235]],\n            ],\n        ],\n    )\n\n    assert np.allclose(result, expected)\n\n\ndef test_space_to_depth_operator():\n    runtime = get_runtime()\n\n    data_shape = [1, 2, 4, 4]\n    data_value = np.arange(start=0, stop=32, step=1.0, dtype=np.float32).reshape(data_shape)\n    mode = ""blocks_first""\n    block_size = 2\n\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    model = ng.space_to_depth(parameter_data, mode, block_size)\n    computation = runtime.computation(model, parameter_data)\n\n    result = computation(data_value)\n    expected = np.array(\n        [\n            0,\n            2,\n            8,\n            10,\n            16,\n            18,\n            24,\n            26,\n            1,\n            3,\n            9,\n            11,\n            17,\n            19,\n            25,\n            27,\n            4,\n            6,\n            12,\n            14,\n            20,\n            22,\n            28,\n            30,\n            5,\n            7,\n            13,\n            15,\n            21,\n            23,\n            29,\n            31,\n        ],\n        dtype=np.float32,\n    ).reshape(1, 8, 2, 2)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.skip_on_cpu\ndef test_rnn_cell_operator():\n    runtime = get_runtime()\n\n    batch_size = 2\n    input_size = 3\n    hidden_size = 3\n\n    X_shape = [batch_size, input_size]\n    H_t_shape = [batch_size, hidden_size]\n    W_shape = [hidden_size, input_size]\n    R_shape = [hidden_size, hidden_size]\n    B_shape = [hidden_size]\n\n    parameter_X = ng.parameter(X_shape, name=""X"", dtype=np.float32)\n    parameter_H_t = ng.parameter(H_t_shape, name=""H_t"", dtype=np.float32)\n    parameter_W = ng.parameter(W_shape, name=""W"", dtype=np.float32)\n    parameter_R = ng.parameter(R_shape, name=""R"", dtype=np.float32)\n    parameter_B = ng.parameter(B_shape, name=""B"", dtype=np.float32)\n\n    X_value = np.array(\n        [0.3432185, 0.612268, 0.20272376, 0.9513413, 0.30585995, 0.7265472], dtype=np.float32\n    ).reshape(X_shape)\n    H_t_value = np.array(\n        [0.12444675, 0.52055854, 0.46489045, 0.4983964, 0.7730452, 0.28439692], dtype=np.float32\n    ).reshape(H_t_shape)\n    W_value = np.array(\n        [\n            0.41930267,\n            0.7872176,\n            0.89940447,\n            0.23659843,\n            0.24676207,\n            0.17101714,\n            0.3147149,\n            0.6555601,\n            0.4559603,\n        ],\n        dtype=np.float32,\n    ).reshape(W_shape)\n    R_value = np.array(\n        [\n            0.8374871,\n            0.86660194,\n            0.82114047,\n            0.71549815,\n            0.18775631,\n            0.3182116,\n            0.25392973,\n            0.38301638,\n            0.85531586,\n        ],\n        dtype=np.float32,\n    ).reshape(R_shape)\n    B_value = np.array([1.0289404, 1.6362579, 0.4370661], dtype=np.float32).reshape(B_shape)\n    activations = [""sigmoid""]\n    activation_alpha = []\n    activation_beta = []\n    clip = 2.88\n\n    model = ng.rnn_cell(\n        parameter_X,\n        parameter_H_t,\n        parameter_W,\n        parameter_R,\n        parameter_B,\n        hidden_size,\n        activations,\n        activation_alpha,\n        activation_beta,\n        clip,\n    )\n    computation = runtime.computation(\n        model, parameter_X, parameter_H_t, parameter_W, parameter_R, parameter_B\n    )\n\n    result = computation(X_value, H_t_value, W_value, R_value, B_value)\n    expected = np.array(\n        [0.94126844, 0.9036043, 0.841243, 0.9468489, 0.934215, 0.873708], dtype=np.float32\n    ).reshape(batch_size, hidden_size)\n\n    assert np.allclose(result, expected)\n\n\ndef test_group_convolution_operator():\n    runtime = get_runtime()\n\n    data_shape = [1, 4, 2, 2]\n    filters_shape = [2, 1, 2, 1, 1]\n\n    parameter_data = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    parameter_filters = ng.parameter(filters_shape, name=""Filters"", dtype=np.float32)\n\n    data_value = np.arange(start=1.0, stop=17.0, dtype=np.float32).reshape(data_shape)\n    filters_value = np.arange(start=1.0, stop=5.0, dtype=np.float32).reshape(filters_shape)\n    strides = [1, 1]\n    dilations = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n\n    model = ng.group_convolution(\n        parameter_data, parameter_filters, strides, pads_begin, pads_end, dilations\n    )\n    computation = runtime.computation(model, parameter_data, parameter_filters)\n    result = computation(data_value, filters_value)\n\n    expected = np.array([11, 14, 17, 20, 79, 86, 93, 100], dtype=np.float32).reshape(1, 2, 2, 2)\n\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.xfail(reason=""Computation mismatch"")\ndef test_group_convolution_backprop_data():\n    runtime = get_runtime()\n\n    data_shape = [1, 1, 3, 3]\n    filters_shape = [1, 1, 1, 3, 3]\n    strides = [2, 2]\n    output_padding = [1, 1]\n    pads_begin = [1, 1]\n    pads_end = [1, 1]\n\n    data_node = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    filters_node = ng.parameter(filters_shape, name=""Filters"", dtype=np.float32)\n    model = ng.group_convolution_backprop_data(\n        data_node, filters_node, strides, None, pads_begin, pads_end, output_padding=output_padding\n    )\n\n    data_value = np.array(\n        [\n            0.16857791,\n            -0.15161794,\n            0.08540368,\n            0.1820628,\n            -0.21746576,\n            0.08245695,\n            0.1431433,\n            -0.43156421,\n            0.30591947,\n        ],\n        dtype=np.float32,\n    ).reshape(data_shape)\n\n    filters_value = np.array(\n        [\n            -0.06230065,\n            0.37932432,\n            -0.25388849,\n            0.33878803,\n            0.43709868,\n            -0.22477469,\n            0.04118127,\n            -0.44696793,\n            0.06373066,\n        ],\n        dtype=np.float32,\n    ).reshape(filters_shape)\n\n    computation = runtime.computation(model, data_node, filters_node)\n    result = computation(data_value, filters_value)\n\n    expected = np.array(\n        [\n            0.07368518,\n            -0.08925839,\n            -0.06627201,\n            0.06301362,\n            0.03732984,\n            -0.01919658,\n            -0.00628807,\n            -0.02817563,\n            -0.01472169,\n            0.04392925,\n            -0.00689478,\n            -0.01549204,\n            0.07957941,\n            -0.11459791,\n            -0.09505399,\n            0.07681622,\n            0.03604182,\n            -0.01853423,\n            -0.0270785,\n            -0.00680824,\n            -0.06650258,\n            0.08004665,\n            0.07918708,\n            0.0724144,\n            0.06256775,\n            -0.17838378,\n            -0.18863615,\n            0.20064656,\n            0.133717,\n            -0.06876295,\n            -0.06398046,\n            -0.00864975,\n            0.19289537,\n            -0.01490572,\n            -0.13673618,\n            0.01949645,\n        ],\n        dtype=np.float32,\n    ).reshape(1, 1, 6, 6)\n\n    assert np.allclose(result, expected)\n\n\ndef test_group_convolution_backprop_data_output_shape():\n    runtime = get_runtime()\n\n    data_shape = [1, 1, 1, 10]\n    filters_shape = [1, 1, 1, 1, 5]\n    strides = [1, 1]\n\n    data_node = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    filters_node = ng.parameter(filters_shape, name=""Filters"", dtype=np.float32)\n    output_shape_node = ng.constant(np.array([1, 14], dtype=np.int64))\n\n    model = ng.group_convolution_backprop_data(\n        data_node, filters_node, strides, output_shape_node, auto_pad=""same_upper""\n    )\n\n    data_value = np.array(\n        [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], dtype=np.float32\n    ).reshape(data_shape)\n\n    filters_value = np.array([1.0, 2.0, 3.0, 2.0, 1.0], dtype=np.float32).reshape(filters_shape)\n\n    computation = runtime.computation(model, data_node, filters_node)\n    result = computation(data_value, filters_value)\n\n    expected = np.array(\n        [0.0, 1.0, 4.0, 10.0, 18.0, 27.0, 36.0, 45.0, 54.0, 63.0, 62.0, 50.0, 26.0, 9.0],\n        dtype=np.float32,\n    ).reshape(1, 1, 1, 14)\n\n    assert np.allclose(result, expected)\n'"
python/test/ngraph/test_ops_matmul.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\n\nimport ngraph as ng\nfrom test.ngraph.util import run_op_node\n\n\n@pytest.mark.parametrize(\n    ""shape_a, shape_b, transpose_a, transpose_b"",\n    [\n        # matrix, vector\n        ([2, 4], [4], False, False),\n        ([4], [4, 2], False, False),\n        # matrix, matrix\n        ([2, 4], [4, 2], False, False),\n        # tensor, vector\n        ([2, 4, 5], [5], False, False),\n        # # tensor, matrix\n        ([2, 4, 5], [5, 4], False, False),\n        # # tensor, tensor\n        ([2, 2, 4], [2, 4, 2], False, False),\n    ],\n)\ndef test_matmul(shape_a, shape_b, transpose_a, transpose_b):\n    np.random.seed(133391)\n    left_input = -100.0 + np.random.rand(*shape_a).astype(np.float32) * 200.0\n    right_input = -100.0 + np.random.rand(*shape_b).astype(np.float32) * 200.0\n\n    result = run_op_node([left_input, right_input], ng.matmul, transpose_a, transpose_b)\n\n    if transpose_a:\n        left_input = np.transpose(left_input)\n    if transpose_b:\n        right_input = np.transpose(right_input)\n\n    expected = np.matmul(left_input, right_input)\n    assert np.allclose(result, expected)\n'"
python/test/ngraph/test_ops_multioutput.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime\n\n\ndef test_split():\n    runtime = get_runtime()\n    input_tensor = ng.constant(np.array([0, 1, 2, 3, 4, 5], dtype=np.int32))\n    axis = ng.constant(0, dtype=np.int64)\n    splits = 3\n\n    split_node = ng.split(input_tensor, axis, splits)\n    computation = runtime.computation(split_node)\n    split_results = computation()\n    expected_results = np.array([[0, 1], [2, 3], [4, 5]], dtype=np.int32)\n    assert np.allclose(split_results, expected_results)\n\n\ndef test_variadic_split():\n    runtime = get_runtime()\n    input_tensor = ng.constant(np.array([[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11]], dtype=np.int32))\n    axis = ng.constant(1, dtype=np.int64)\n    splits = ng.constant(np.array([2, 4], dtype=np.int64))\n\n    v_split_node = ng.variadic_split(input_tensor, axis, splits)\n    computation = runtime.computation(v_split_node)\n    results = computation()\n    split0 = np.array([[0, 1], [6, 7]], dtype=np.int32)\n    split1 = np.array([[2, 3, 4, 5], [8, 9, 10, 11]], dtype=np.int32)\n\n    assert np.allclose(results[0], split0)\n    assert np.allclose(results[1], split1)\n'"
python/test/ngraph/test_ops_reshape.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime, run_op_node, run_op_numeric_data\n\n\ndef test_concat():\n    a = np.array([[1, 2], [3, 4]])\n    b = np.array([[5, 6]])\n    axis = 0\n    expected = np.concatenate((a, b), axis=0)\n\n    runtime = get_runtime()\n    parameter_a = ng.parameter(list(a.shape), name=""A"", dtype=np.float32)\n    parameter_b = ng.parameter(list(b.shape), name=""B"", dtype=np.float32)\n    node = ng.concat([parameter_a, parameter_b], axis)\n    computation = runtime.computation(node, parameter_a, parameter_b)\n    result = computation(a, b)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(""val_type, value"", [(bool, False), (bool, np.empty((2, 2), dtype=bool))])\ndef test_constant_from_bool(val_type, value):\n    expected = np.array(value, dtype=val_type)\n    result = run_op_numeric_data(value, ng.constant, val_type)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""val_type, value"",\n    [\n        (np.float32, np.float32(0.1234)),\n        (np.float64, np.float64(0.1234)),\n        (np.int8, np.int8(-63)),\n        (np.int16, np.int16(-12345)),\n        (np.int32, np.int32(-123456)),\n        (np.int64, np.int64(-1234567)),\n        (np.uint8, np.uint8(63)),\n        (np.uint16, np.uint16(12345)),\n        (np.uint32, np.uint32(123456)),\n        (np.uint64, np.uint64(1234567)),\n    ],\n)\ndef test_constant_from_scalar(val_type, value):\n    expected = np.array(value, dtype=val_type)\n    result = run_op_numeric_data(value, ng.constant, val_type)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(""val_type"", [np.float32, np.float64])\ndef test_constant_from_float_array(val_type):\n    np.random.seed(133391)\n    input_data = np.array(-1 + np.random.rand(2, 3, 4) * 2, dtype=val_type)\n    result = run_op_numeric_data(input_data, ng.constant, val_type)\n    assert np.allclose(result, input_data)\n\n\n@pytest.mark.parametrize(\n    ""val_type, range_start, range_end"",\n    [\n        (np.int8, -8, 8),\n        (np.int16, -64, 64),\n        (np.int32, -1024, 1024),\n        (np.int64, -16383, 16383),\n        (np.uint8, 0, 8),\n        (np.uint16, 0, 64),\n        (np.uint32, 0, 1024),\n        (np.uint64, 0, 16383),\n    ],\n)\ndef test_constant_from_integer_array(val_type, range_start, range_end):\n    np.random.seed(133391)\n    input_data = np.array(np.random.randint(range_start, range_end, size=(2, 2)), dtype=val_type)\n    result = run_op_numeric_data(input_data, ng.constant, val_type)\n    assert np.allclose(result, input_data)\n\n\ndef test_broadcast_numpy():\n    data_shape = [16, 1, 1]\n    target_shape_shape = [4]\n\n    data_parameter = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    target_shape_parameter = ng.parameter(target_shape_shape, name=""Target_shape"", dtype=np.int64)\n\n    node = ng.broadcast(data_parameter, target_shape_parameter)\n\n    assert node.get_type_name() == ""Broadcast""\n    assert node.get_output_size() == 1\n\n\ndef test_broadcast_bidirectional():\n    data_shape = [16, 1, 1]\n    target_shape_shape = [4]\n\n    data_parameter = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    target_shape_parameter = ng.parameter(target_shape_shape, name=""Target_shape"", dtype=np.int64)\n\n    node = ng.broadcast(data_parameter, target_shape_parameter, ""BIDIRECTIONAL"")\n\n    assert node.get_type_name() == ""Broadcast""\n    assert node.get_output_size() == 1\n\n\ndef test_gather():\n    input_data = np.array([1.0, 1.1, 1.2, 2.0, 2.1, 2.2, 3.0, 3.1, 3.2], np.float32).reshape((3, 3))\n    input_indices = np.array([0, 2], np.int64).reshape(1, 2)\n    input_axes = np.array([1], np.int64)\n\n    expected = np.array([1.0, 1.2, 2.0, 2.2, 3.0, 3.2], dtype=np.float32).reshape((3, 1, 2))\n\n    result = run_op_node([input_data, input_indices, input_axes], ng.gather)\n    assert np.allclose(result, expected)\n\n    result = run_op_numeric_data(input_data, ng.gather, input_indices, input_axes)\n    assert np.allclose(result, expected)\n\n\ndef test_transpose():\n    input_tensor = np.arange(3 * 3 * 224 * 224).reshape((3, 3, 224, 224))\n    input_order = np.array([0, 2, 3, 1])\n\n    result = run_op_node([input_tensor, input_order], ng.transpose)\n\n    expected = np.transpose(input_tensor, input_order)\n\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.skip_on_interpreter  # unsupported op\ndef test_tile():\n    input_tensor = np.arange(6).reshape((2, 1, 3))\n    repeats = np.array([2, 1])\n\n    result = run_op_node([input_tensor, repeats], ng.tile)\n\n    expected = np.array([0, 1, 2, 0, 1, 2, 3, 4, 5, 3, 4, 5]).reshape((2, 2, 3))\n\n    assert np.allclose(result, expected)\n\n\ndef test_strided_slice():\n    input_tensor = np.arange(2 * 3 * 4, dtype=np.float32).reshape((2, 3, 4))\n    begin = np.array([1, 0], dtype=np.int64)\n    end = np.array([0, 0], dtype=np.int64)\n    strides = np.array([1, 1], dtype=np.int64)\n    begin_mask = np.array([0, 0, 0], dtype=np.int64)\n    end_mask = np.array([0, 0, 0], dtype=np.int64)\n    new_axis_mask = np.array([0, 1, 0], dtype=np.int64)\n    shrink_axis_mask = np.array([1, 0, 0], dtype=np.int64)\n    ellipsis_mask = np.array([0, 0, 0], dtype=np.int64)\n\n    result = run_op_node(\n        [input_tensor, begin, end, strides],\n        ng.strided_slice,\n        begin_mask,\n        end_mask,\n        new_axis_mask,\n        shrink_axis_mask,\n        ellipsis_mask,\n    )\n\n    expected = np.array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n                        dtype=np.float32).reshape((1, 3, 4))\n\n    assert np.allclose(result, expected)\n\n\ndef test_reshape_v1():\n    A = np.arange(1200, dtype=np.float32).reshape((2, 5, 5, 24))\n    shape = np.array([0, -1, 4])\n    special_zero = True\n\n    expected_shape = np.array([2, 150, 4])\n    expected = np.reshape(A, expected_shape)\n    result = run_op_node([A, shape], ng.reshape, special_zero)\n\n    assert np.allclose(result, expected)\n\n\ndef test_shape_of():\n    input_tensor = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float32)\n\n    result = run_op_node([input_tensor], ng.shape_of)\n\n    assert np.allclose(result, [3, 3])\n'"
python/test/ngraph/test_ops_scatter.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport ngraph as ng\nfrom ngraph.impl import Type\n\n\ndef test_scatter_update_props():\n    dtype = np.int8\n    parameter_r = ng.parameter([2, 3, 4], dtype=dtype, name=""data"")\n    parameter_i = ng.parameter([2, 1], dtype=dtype, name=""indices"")\n    parameter_u = ng.parameter([2, 2, 1, 4], dtype=dtype, name=""updates"")\n    axis = np.array([1], dtype=np.int8)\n\n    node = ng.scatter_update(parameter_r, parameter_i, parameter_u, axis)\n    assert node.get_type_name() == ""ScatterUpdate""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [2, 3, 4]\n    assert node.get_output_element_type(0) == Type.i8\n\n\ndef test_scatter_update_elements_props():\n    dtype = np.int8\n    parameter_r = ng.parameter([2, 4, 5, 7], dtype=dtype, name=""data"")\n    parameter_i = ng.parameter([2, 2, 2, 2], dtype=dtype, name=""indices"")\n    parameter_u = ng.parameter([2, 2, 2, 2], dtype=dtype, name=""updates"")\n    axis = np.array([1], dtype=np.int8)\n\n    node = ng.scatter_elements_update(parameter_r, parameter_i, parameter_u, axis)\n    assert node.get_type_name() == ""ScatterElementsUpdate""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == [2, 4, 5, 7]\n    assert node.get_output_element_type(0) == Type.i8\n'"
python/test/ngraph/test_ops_unary.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\n\nimport ngraph as ng\nfrom test.ngraph.util import run_op_numeric_data, run_op_node\n\n\n@pytest.mark.parametrize(\n    ""ng_api_fn, numpy_fn, range_start, range_end"",\n    [\n        (ng.absolute, np.abs, -1, 1),\n        (ng.abs, np.abs, -1, 1),\n        (ng.acos, np.arccos, -1, 1),\n        (ng.asin, np.arcsin, -1, 1),\n        (ng.atan, np.arctan, -100.0, 100.0),\n        (ng.ceiling, np.ceil, -100.0, 100.0),\n        (ng.ceil, np.ceil, -100.0, 100.0),\n        (ng.cos, np.cos, -100.0, 100.0),\n        (ng.cosh, np.cosh, -100.0, 100.0),\n        (ng.exp, np.exp, -100.0, 100.0),\n        (ng.floor, np.floor, -100.0, 100.0),\n        (ng.log, np.log, 0, 100.0),\n        (ng.relu, lambda x: np.maximum(0, x), -100.0, 100.0),\n        (ng.sign, np.sign, -100.0, 100.0),\n        (ng.sin, np.sin, -100.0, 100.0),\n        (ng.sinh, np.sinh, -100.0, 100.0),\n        (ng.sqrt, np.sqrt, 0.0, 100.0),\n        (ng.tan, np.tan, -1.0, 1.0),\n        (ng.tanh, np.tanh, -100.0, 100.0),\n    ],\n)\ndef test_unary_op_array(ng_api_fn, numpy_fn, range_start, range_end):\n    np.random.seed(133391)\n    input_data = range_start + np.random.rand(2, 3, 4) * (range_end - range_start)\n    expected = numpy_fn(input_data)\n\n    result = run_op_node([input_data], ng_api_fn)\n    assert np.allclose(result, expected, rtol=0.001)\n\n    result = run_op_numeric_data(input_data, ng_api_fn)\n    assert np.allclose(result, expected, rtol=0.001)\n\n\n@pytest.mark.parametrize(\n    ""ng_api_fn, numpy_fn, input_data"",\n    [\n        (ng.absolute, np.abs, np.float32(-3)),\n        (ng.abs, np.abs, np.float32(-3)),\n        (ng.acos, np.arccos, np.float32(-0.5)),\n        (ng.asin, np.arcsin, np.float32(-0.5)),\n        (ng.atan, np.arctan, np.float32(-0.5)),\n        (ng.ceiling, np.ceil, np.float32(1.5)),\n        (ng.ceil, np.ceil, np.float32(1.5)),\n        (ng.cos, np.cos, np.float32(np.pi / 4.0)),\n        (ng.cosh, np.cosh, np.float32(np.pi / 4.0)),\n        (ng.exp, np.exp, np.float32(1.5)),\n        (ng.floor, np.floor, np.float32(1.5)),\n        (ng.log, np.log, np.float32(1.5)),\n        (ng.relu, lambda x: np.maximum(0, x), np.float32(-0.125)),\n        (ng.sign, np.sign, np.float32(0.0)),\n        (ng.sin, np.sin, np.float32(np.pi / 4.0)),\n        (ng.sinh, np.sinh, np.float32(0.0)),\n        (ng.sqrt, np.sqrt, np.float32(3.5)),\n        (ng.tan, np.tan, np.float32(np.pi / 4.0)),\n        (ng.tanh, np.tanh, np.float32(0.1234)),\n    ],\n)\ndef test_unary_op_scalar(ng_api_fn, numpy_fn, input_data):\n    expected = numpy_fn(input_data)\n\n    result = run_op_node([input_data], ng_api_fn)\n    assert np.allclose(result, expected)\n\n    result = run_op_numeric_data(input_data, ng_api_fn)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""input_data"", [(np.array([True, False, True, False])), (np.array(True)), (np.array(False))]\n)\ndef test_logical_not(input_data):\n    expected = np.logical_not(input_data)\n\n    result = run_op_node([input_data], ng.logical_not)\n\n    assert np.allclose(result, expected)\n    result = run_op_numeric_data(input_data, ng.logical_not)\n    assert np.allclose(result, expected)\n\n\ndef test_sigmoid():\n    input_data = np.array([-3.14, -1.0, 0.0, 2.71001, 1000.0], dtype=np.float32)\n    result = run_op_node([input_data], ng.sigmoid)\n\n    def sigmoid(x):\n        return 1.0 / (1.0 + np.exp(-x))\n\n    expected = np.array(list(map(sigmoid, input_data)))\n\n    assert np.allclose(result, expected)\n\n\ndef test_softmax():\n    axis = 0\n    input_tensor = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n\n    result = run_op_node([input_tensor], ng.ops.softmax, axis)\n\n    expected = [[0.00426978, 0.01160646, 0.03154963], [0.08576079, 0.23312202, 0.6336913]]\n\n    assert np.allclose(result, expected)\n\n\ndef test_erf():\n    input_tensor = np.array([-1.0, 0.0, 1.0, 2.5, 3.14, 4.0], dtype=np.float32)\n    expected = [-0.842701, 0.0, 0.842701, 0.999593, 0.999991, 1.0]\n\n    result = run_op_node([input_tensor], ng.erf)\n    assert np.allclose(result, expected)\n\n    result = run_op_numeric_data(input_tensor, ng.erf)\n    assert np.allclose(result, expected)\n'"
python/test/ngraph/test_pooling.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime\n\n\n@pytest.fixture\ndef _ndarray_1x1x4x4():\n    return np.arange(11, 27, dtype=np.float32).reshape(1, 1, 4, 4)\n\n\ndef test_avg_pool_2d(_ndarray_1x1x4x4):\n    runtime = get_runtime()\n    input_data = _ndarray_1x1x4x4\n    param = ng.parameter(input_data.shape, name=""A"", dtype=np.float32)\n\n    kernel_shape = [2, 2]\n    spatial_dim_count = len(kernel_shape)\n    pads_begin = [0] * spatial_dim_count\n    pads_end = [0] * spatial_dim_count\n    strides = [2, 2]\n    exclude_pad = True\n    expected = [[[[13.5, 15.5], [21.5, 23.5]]]]\n\n    avg_pool_node = ng.avg_pool(param, strides, pads_begin, pads_end, kernel_shape, exclude_pad)\n    computation = runtime.computation(avg_pool_node, param)\n    result = computation(input_data)\n    assert np.allclose(result, expected)\n\n    expected = [[[[13.5, 14.5, 15.5], [17.5, 18.5, 19.5], [21.5, 22.5, 23.5]]]]\n    strides = [1, 1]\n    avg_pool_node = ng.avg_pool(param, strides, pads_begin, pads_end, kernel_shape, exclude_pad)\n    computation = runtime.computation(avg_pool_node, param)\n    result = computation(input_data)\n    assert np.allclose(result, expected)\n\n    pads_begin = [1, 1]\n    pads_end = [1, 1]\n    strides = [2, 2]\n    exclude_pad = True\n\n    expected = [[[[11.0, 12.5, 14.0], [17.0, 18.5, 20.0], [23.0, 24.5, 26.0]]]]\n    avg_pool_node = ng.avg_pool(param, strides, pads_begin, pads_end, kernel_shape, exclude_pad)\n    computation = runtime.computation(avg_pool_node, param)\n    result = computation(input_data)\n    assert np.allclose(result, expected)\n\n    exclude_pad = False\n    expected = [[[[2.75, 6.25, 3.5], [8.5, 18.5, 10.0], [5.75, 12.25, 6.5]]]]\n    avg_pool_node = ng.avg_pool(param, strides, pads_begin, pads_end, kernel_shape, exclude_pad)\n    computation = runtime.computation(avg_pool_node, param)\n    result = computation(input_data)\n    assert np.allclose(result, expected)\n\n\ndef test_avg_pooling_3d(_ndarray_1x1x4x4):\n    rt = get_runtime()\n    data = _ndarray_1x1x4x4\n    data = np.broadcast_to(data, (1, 1, 4, 4, 4))\n    param = ng.parameter(list(data.shape))\n    kernel_shape = [2, 2, 2]\n    strides = [2, 2, 2]\n    spatial_dim_count = len(kernel_shape)\n    pads_begin = [0] * spatial_dim_count\n    pads_end = [0] * spatial_dim_count\n    exclude_pad = True\n\n    avgpool = ng.avg_pool(param, strides, pads_begin, pads_end, kernel_shape, exclude_pad)\n    comp = rt.computation(avgpool, param)\n    result = comp(data)\n    result_ref = [[[[[13.5, 15.5], [21.5, 23.5]], [[13.5, 15.5], [21.5, 23.5]]]]]\n    assert np.allclose(result, result_ref)\n\n\ndef test_max_pool_basic():\n    rt = get_runtime()\n\n    # array([[[[ 0.5,  1.5,  2.5,  3.5],\n    #          [ 4.5,  5.5,  6.5,  7.5],\n    #          [ 8.5,  9.5, 10.5, 11.5],\n    #          [12.5, 13.5, 14.5, 15.5]]]], dtype=float32)\n    data = np.arange(0.5, 16, dtype=np.float32).reshape((1, 1, 4, 4))\n    strides = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    kernel_shape = [2, 2]\n\n    data_node = ng.parameter(data.shape, name=""A"", dtype=np.float32)\n    avgpool_node = ng.max_pool(data_node, strides, pads_begin, pads_end, kernel_shape)\n    comp = rt.computation(avgpool_node, data_node)\n    result = comp(data)\n\n    expected = np.array(\n        [[[[5.5, 6.5, 7.5], [9.5, 10.5, 11.5], [13.5, 14.5, 15.5]]]], dtype=np.float32\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_max_pool_strides():\n    rt = get_runtime()\n\n    # array([[[[ 0.5,  1.5,  2.5,  3.5],\n    #          [ 4.5,  5.5,  6.5,  7.5],\n    #          [ 8.5,  9.5, 10.5, 11.5],\n    #          [12.5, 13.5, 14.5, 15.5]]]], dtype=float32)\n    data = np.arange(0.5, 16, dtype=np.float32).reshape((1, 1, 4, 4))\n    strides = [2, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    kernel_shape = [2, 2]\n\n    data_node = ng.parameter(data.shape, name=""A"", dtype=np.float32)\n    avgpool_node = ng.max_pool(data_node, strides, pads_begin, pads_end, kernel_shape)\n    comp = rt.computation(avgpool_node, data_node)\n    result = comp(data)\n\n    expected = np.array([[[[5.5, 6.5, 7.5], [13.5, 14.5, 15.5]]]], dtype=np.float32)\n    assert np.allclose(result, expected)\n\n\ndef test_max_pool_kernel_shape1d():\n    rt = get_runtime()\n\n    # array([[[[ 0.5,  1.5,  2.5,  3.5],\n    #          [ 4.5,  5.5,  6.5,  7.5],\n    #          [ 8.5,  9.5, 10.5, 11.5],\n    #          [12.5, 13.5, 14.5, 15.5]]]], dtype=float32)\n    data = np.arange(0.5, 16, dtype=np.float32).reshape((1, 1, 4, 4))\n    strides = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    kernel_shape = [1, 1]\n\n    data_node = ng.parameter(data.shape, name=""A"", dtype=np.float32)\n    avgpool_node = ng.max_pool(data_node, strides, pads_begin, pads_end, kernel_shape)\n    comp = rt.computation(avgpool_node, data_node)\n    result = comp(data)\n\n    assert np.allclose(result, data)\n\n\ndef test_max_pool_kernel_shape3d():\n    rt = get_runtime()\n\n    # array([[[[ 0.5,  1.5,  2.5,  3.5],\n    #          [ 4.5,  5.5,  6.5,  7.5],\n    #          [ 8.5,  9.5, 10.5, 11.5],\n    #          [12.5, 13.5, 14.5, 15.5]]]], dtype=float32)\n    data = np.arange(0.5, 16, dtype=np.float32).reshape((1, 1, 4, 4))\n    strides = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    kernel_shape = [3, 3]\n\n    data_node = ng.parameter(data.shape, name=""A"", dtype=np.float32)\n    avgpool_node = ng.max_pool(data_node, strides, pads_begin, pads_end, kernel_shape)\n    comp = rt.computation(avgpool_node, data_node)\n    result = comp(data)\n\n    expected = np.array([[[[10.5, 11.5], [14.5, 15.5]]]], dtype=np.float32)\n    assert np.allclose(result, expected)\n\n\ndef test_max_pool_non_zero_pads():\n    rt = get_runtime()\n\n    # array([[[[ 0.5,  1.5,  2.5,  3.5],\n    #          [ 4.5,  5.5,  6.5,  7.5],\n    #          [ 8.5,  9.5, 10.5, 11.5],\n    #          [12.5, 13.5, 14.5, 15.5]]]], dtype=float32)\n    data = np.arange(0.5, 16, dtype=np.float32).reshape((1, 1, 4, 4))\n    strides = [1, 1]\n    pads_begin = [1, 1]\n    pads_end = [1, 1]\n    #  0   0  ,  0  ,  0  ,  0,    0\n    #  0 [ 0.5,  1.5,  2.5,  3.5], 0,\n    #  0 [ 4.5,  5.5,  6.5,  7.5], 0,\n    #  0 [ 8.5,  9.5, 10.5, 11.5], 0,\n    #  0 [12.5, 13.5, 14.5, 15.5], 0\n    #  0   0  ,  0  ,  0  ,  0,    0\n    kernel_shape = [2, 2]\n\n    data_node = ng.parameter(data.shape, name=""A"", dtype=np.float32)\n    avgpool_node = ng.max_pool(data_node, strides, pads_begin, pads_end, kernel_shape)\n    comp = rt.computation(avgpool_node, data_node)\n    result = comp(data)\n\n    expected = np.array(\n        [\n            [\n                [\n                    [0.5, 1.5, 2.5, 3.5, 3.5],\n                    [4.5, 5.5, 6.5, 7.5, 7.5],\n                    [8.5, 9.5, 10.5, 11.5, 11.5],\n                    [12.5, 13.5, 14.5, 15.5, 15.5],\n                    [12.5, 13.5, 14.5, 15.5, 15.5],\n                ]\n            ]\n        ],\n        dtype=np.float32,\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_max_pool_same_upper_auto_pads():\n    rt = get_runtime()\n\n    # array([[[[ 0.5,  1.5,  2.5,  3.5],\n    #          [ 4.5,  5.5,  6.5,  7.5],\n    #          [ 8.5,  9.5, 10.5, 11.5],\n    #          [12.5, 13.5, 14.5, 15.5]]]], dtype=float32)\n    data = np.arange(0.5, 16, dtype=np.float32).reshape((1, 1, 4, 4))\n    strides = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    # [ 0.5,  1.5,  2.5,  3.5], 0,\n    # [ 4.5,  5.5,  6.5,  7.5], 0,\n    # [ 8.5,  9.5, 10.5, 11.5], 0,\n    # [12.5, 13.5, 14.5, 15.5], 0\n    #   0  ,  0  ,  0  ,  0,    0\n    kernel_shape = [2, 2]\n    auto_pad = ""same_upper""\n\n    data_node = ng.parameter(data.shape, name=""A"", dtype=np.float32)\n    avgpool_node = ng.max_pool(\n        data_node, strides, pads_begin, pads_end, kernel_shape, auto_pad=auto_pad\n    )\n    comp = rt.computation(avgpool_node, data_node)\n    result = comp(data)\n\n    expected = np.array(\n        [\n            [\n                [\n                    [5.5, 6.5, 7.5, 7.5],\n                    [9.5, 10.5, 11.5, 11.5],\n                    [13.5, 14.5, 15.5, 15.5],\n                    [13.5, 14.5, 15.5, 15.5],\n                ]\n            ]\n        ],\n        dtype=np.float32,\n    )\n    assert np.allclose(result, expected)\n\n\ndef test_max_pool_same_lower_auto_pads():\n    rt = get_runtime()\n\n    # array([[[[ 0.5,  1.5,  2.5,  3.5],\n    #          [ 4.5,  5.5,  6.5,  7.5],\n    #          [ 8.5,  9.5, 10.5, 11.5],\n    #          [12.5, 13.5, 14.5, 15.5]]]], dtype=float32)\n    data = np.arange(0.5, 16, dtype=np.float32).reshape((1, 1, 4, 4))\n    strides = [1, 1]\n    pads_begin = [0, 0]\n    pads_end = [0, 0]\n    #  0   0  ,  0  ,  0  ,  0,\n    #  0 [ 0.5,  1.5,  2.5,  3.5],\n    #  0 [ 4.5,  5.5,  6.5,  7.5],\n    #  0 [ 8.5,  9.5, 10.5, 11.5],\n    #  0 [12.5, 13.5, 14.5, 15.5],\n    kernel_shape = [2, 2]\n    auto_pad = ""same_lower""\n\n    data_node = ng.parameter(data.shape, name=""A"", dtype=np.float32)\n    avgpool_node = ng.max_pool(\n        data_node, strides, pads_begin, pads_end, kernel_shape, auto_pad=auto_pad\n    )\n    comp = rt.computation(avgpool_node, data_node)\n    result = comp(data)\n\n    expected = np.array(\n        [\n            [\n                [\n                    [0.5, 1.5, 2.5, 3.5],\n                    [4.5, 5.5, 6.5, 7.5],\n                    [8.5, 9.5, 10.5, 11.5],\n                    [12.5, 13.5, 14.5, 15.5],\n                ]\n            ]\n        ],\n        dtype=np.float32,\n    )\n    assert np.allclose(result, expected)\n'"
python/test/ngraph/test_reduction.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\nimport pytest\n\nimport ngraph as ng\nfrom test.ngraph.util import run_op_node, get_runtime\n\n\n@pytest.mark.parametrize(\n    ""ng_api_helper, numpy_function, reduction_axes"",\n    [\n        (ng.reduce_max, np.max, [0, 1, 2, 3]),\n        (ng.reduce_min, np.min, [0, 1, 2, 3]),\n        (ng.reduce_sum, np.sum, [0, 1, 2, 3]),\n        (ng.reduce_prod, np.prod, [0, 1, 2, 3]),\n        (ng.reduce_max, np.max, [0]),\n        (ng.reduce_min, np.min, [0]),\n        (ng.reduce_sum, np.sum, [0]),\n        (ng.reduce_prod, np.prod, [0]),\n        (ng.reduce_max, np.max, [0, 2]),\n        (ng.reduce_min, np.min, [0, 2]),\n        (ng.reduce_sum, np.sum, [0, 2]),\n        (ng.reduce_prod, np.prod, [0, 2]),\n    ],\n)\ndef test_reduction_ops(ng_api_helper, numpy_function, reduction_axes):\n    shape = [2, 4, 3, 2]\n    np.random.seed(133391)\n    input_data = np.random.randn(*shape).astype(np.float32)\n\n    expected = numpy_function(input_data, axis=tuple(reduction_axes))\n    result = run_op_node([input_data, reduction_axes], ng_api_helper)\n    assert np.allclose(result, expected)\n\n\n@pytest.mark.parametrize(\n    ""ng_api_helper, numpy_function, reduction_axes"",\n    [\n        (ng.reduce_logical_and, np.logical_and.reduce, [0]),\n        (ng.reduce_logical_or, np.logical_or.reduce, [0]),\n        (ng.reduce_logical_and, np.logical_and.reduce, [0, 2]),\n        (ng.reduce_logical_or, np.logical_or.reduce, [0, 2]),\n        (ng.reduce_logical_and, np.logical_and.reduce, [0, 1, 2, 3]),\n        (ng.reduce_logical_or, np.logical_or.reduce, [0, 1, 2, 3]),\n    ],\n)\n@pytest.mark.skip_on_interpreter\ndef test_reduction_logical_ops(ng_api_helper, numpy_function, reduction_axes):\n    shape = [2, 4, 3, 2]\n    np.random.seed(133391)\n    input_data = np.random.randn(*shape).astype(np.bool)\n\n    expected = numpy_function(input_data, axis=tuple(reduction_axes))\n    result = run_op_node([input_data, reduction_axes], ng_api_helper)\n    assert np.allclose(result, expected)\n\n\ndef test_topk():\n    data_shape = [6, 12, 10, 24]\n    data_parameter = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    K = np.int32(3)\n    axis = np.int32(1)\n    node = ng.topk(data_parameter, K, axis, ""max"", ""value"")\n    assert node.get_type_name() == ""TopK""\n    assert node.get_output_size() == 2\n    assert list(node.get_output_shape(0)) == [6, 3, 10, 24]\n    assert list(node.get_output_shape(1)) == [6, 3, 10, 24]\n\n\n@pytest.mark.parametrize(\n    ""ng_api_helper, numpy_function, reduction_axes"",\n    [\n        (ng.reduce_mean, np.mean, [0, 1, 2, 3]),\n        (ng.reduce_mean, np.mean, [0]),\n        (ng.reduce_mean, np.mean, [0, 2]),\n    ],\n)\n@pytest.mark.skip_on_cpu\n@pytest.mark.skip_on_interpreter\ndef test_reduce_mean_op(ng_api_helper, numpy_function, reduction_axes):\n    shape = [2, 4, 3, 2]\n    np.random.seed(133391)\n    input_data = np.random.randn(*shape).astype(np.float32)\n\n    expected = numpy_function(input_data, axis=tuple(reduction_axes))\n    result = run_op_node([input_data, reduction_axes], ng_api_helper)\n    assert np.allclose(result, expected)\n\n\ndef test_non_max_suppression():\n\n    boxes_shape = [1, 1000, 4]\n    scores_shape = [1, 1, 1000]\n    expected_shape = [0, 3]\n    boxes_parameter = ng.parameter(boxes_shape, name=""Boxes"", dtype=np.float32)\n    scores_parameter = ng.parameter(scores_shape, name=""Scores"", dtype=np.float32)\n\n    node = ng.non_max_suppression(boxes_parameter, scores_parameter)\n\n    assert node.get_type_name() == ""NonMaxSuppression""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\ndef test_non_zero():\n\n    data_shape = [3, 10, 100, 200]\n\n    data_parameter = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n\n    node = ng.non_zero(data_parameter)\n\n    assert node.get_type_name() == ""NonZero""\n    assert node.get_output_size() == 1\n\n\ndef test_roi_align():\n\n    data_shape = [7, 256, 200, 200]\n    rois = [1000, 4]\n    batch_indices = [1000]\n    expected_shape = [1000, 256, 6, 6]\n\n    data_parameter = ng.parameter(data_shape, name=""Data"", dtype=np.float32)\n    rois_parameter = ng.parameter(rois, name=""Rois"", dtype=np.float32)\n    batch_indices_parameter = ng.parameter(batch_indices, name=""Batch_indices"", dtype=np.int32)\n    pooled_h = 6\n    pooled_w = 6\n    sampling_ratio = 2\n    spatial_scale = np.float32(16)\n    mode = ""avg""\n\n    node = ng.roi_align(\n        data_parameter,\n        rois_parameter,\n        batch_indices_parameter,\n        pooled_h,\n        pooled_w,\n        sampling_ratio,\n        spatial_scale,\n        mode,\n    )\n\n    assert node.get_type_name() == ""ROIAlign""\n    assert node.get_output_size() == 1\n    assert list(node.get_output_shape(0)) == expected_shape\n\n\n@pytest.mark.parametrize(\n    ""input_shape, cumsum_axis, reverse"",\n    [([5, 2], 0, False), ([5, 2], 1, False), ([5, 2, 6], 2, False), ([5, 2], 0, True)],\n)\ndef test_cum_sum(input_shape, cumsum_axis, reverse):\n    input_data = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n    if reverse:\n        expected = np.cumsum(input_data[::-1], axis=cumsum_axis)[::-1]\n    else:\n        expected = np.cumsum(input_data, axis=cumsum_axis)\n\n    runtime = get_runtime()\n    node = ng.cum_sum(input_data, cumsum_axis, reverse=reverse)\n    computation = runtime.computation(node)\n    result = computation()\n    assert np.allclose(result, expected)\n\n\ndef test_normalize_l2():\n    input_shape = [1, 2, 3, 4]\n    input_data = np.arange(np.prod(input_shape)).reshape(input_shape).astype(np.float32)\n    input_data += 1\n    axes = np.array([1, 2, 3]).astype(np.int64)\n    eps = 1e-6\n    eps_mode = ""add""\n\n    runtime = get_runtime()\n    node = ng.normalize_l2(input_data, axes, eps, eps_mode)\n    computation = runtime.computation(node)\n    result = computation()\n\n    expected = np.array(\n        [\n            0.01428571,\n            0.02857143,\n            0.04285714,\n            0.05714286,\n            0.07142857,\n            0.08571429,\n            0.1,\n            0.11428571,\n            0.12857144,\n            0.14285715,\n            0.15714286,\n            0.17142858,\n            0.18571429,\n            0.2,\n            0.21428572,\n            0.22857143,\n            0.24285714,\n            0.25714287,\n            0.27142859,\n            0.2857143,\n            0.30000001,\n            0.31428573,\n            0.32857144,\n            0.34285715,\n        ]\n    ).reshape(input_shape)\n\n    assert np.allclose(result, expected)\n'"
python/test/ngraph/test_sequence_processing.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport numpy as np\n\nimport ngraph as ng\nfrom test.ngraph.util import get_runtime, run_op_node\n\n\ndef test_onehot():\n    runtime = get_runtime()\n    param = ng.parameter([3], dtype=np.int32)\n    model = ng.one_hot(param, 3, 1, 0, 0)\n    computation = runtime.computation(model, param)\n\n    expected = np.eye(3)[np.array([1, 0, 2])]\n    input_data = np.array([1, 0, 2], dtype=np.int32)\n    result = computation(input_data)\n    assert np.allclose(result, expected)\n\n\ndef test_one_hot():\n    data = np.array([0, 1, 2], dtype=np.int32)\n    depth = 2\n    on_value = 5\n    off_value = 10\n    axis = -1\n    excepted = [[5, 10], [10, 5], [10, 10]]\n\n    result = run_op_node([data, depth, on_value, off_value], ng.one_hot, axis)\n    assert np.allclose(result, excepted)\n'"
python/test/ngraph/util.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nimport numpy as np\nimport ngraph as ng\nfrom ngraph.utils.types import NumericData\nfrom typing import Any, Callable, List\nimport test\n\n\ndef _get_numpy_dtype(scalar):\n    return np.array([scalar]).dtype\n\n\ndef get_runtime():\n    """"""Return runtime object.""""""\n    return ng.runtime(backend_name=test.BACKEND_NAME)\n\n\ndef run_op_node(input_data, op_fun, *args):\n    # type: (NumericData, Callable, *Any) -> List[NumericData]\n    """"""Run computation on node performing `op_fun`.\n\n    `op_fun` has to accept a node as an argument.\n\n    This function converts passed raw input data to nGraph Constant Node and that form is passed\n    to `op_fun`.\n\n    :param input_data: The input data for performed computation.\n    :param op_fun: The function handler for operation we want to carry out.\n    :param args: The arguments passed to operation we want to carry out.\n    :return: The result from computations.\n    """"""\n    runtime = get_runtime()\n    comp_args = []\n    op_fun_args = []\n    comp_inputs = []\n    for data in input_data:\n        op_fun_args.append(ng.constant(data, _get_numpy_dtype(data)))\n    op_fun_args.extend(args)\n    node = op_fun(*op_fun_args)\n    computation = runtime.computation(node, *comp_args)\n    return computation(*comp_inputs)\n\n\ndef run_op_numeric_data(input_data, op_fun, *args):\n    # type: (NumericData, Callable, *Any) -> List[NumericData]\n    """"""Run computation on node performing `op_fun`.\n\n    `op_fun` has to accept a scalar or an array.\n\n    This function passess input data AS IS. This mean that in case they\'re a scalar (integral,\n    or floating point value) or a NumPy\'s ndarray object they will be automatically converted\n    to nGraph\'s Constant Nodes.\n\n    :param input_data: The input data for performed computation.\n    :param op_fun: The function handler for operation we want to carry out.\n    :param args: The arguments passed to operation we want to carry out.\n    :return: The result from computations.\n    """"""\n    runtime = get_runtime()\n    node = op_fun(input_data, *args)\n    computation = runtime.computation(node)\n    return computation()\n'"
test/models/onnx/onnx_prototxt_converter.py,0,"b'#!/usr/bin/env python\n# *****************************************************************************\n#  Copyright 2017-2020 Intel Corporation\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# *****************************************************************************\n""""""Converts protobuf files from binary message format into prototxt format and vice-versa.\n\nSupports files with only \'.onnx\' or \'.prototxt\' extensions. Application may accept only single\nargument denoting input file. In that case it converts it to the second message format based on the\nextension of argument.\n\nUsage:\n  onnx_prototxt_converter.py INPUT_FILE [OUTPUT_FILE]\n\nArguments:\n  INPUT_FILE   The path for the input model file.\n  OUTPUT_FILE  The path for the converted model file.\n\nOptions:\n  -h --help            show this help message and exit\n""""""\n\n\nfrom docopt import docopt\nfrom google.protobuf import text_format\nimport onnx\nimport os\n\nONNX_SUFFX = \'.onnx\'\nPROTOTXT_SUFFX = \'.prototxt\'\n\ndef _bin2txt(model):\n    return text_format.MessageToString(model, as_utf8=True, float_format=\'.17g\')\n\ndef _txt2bin(model):\n    m_proto = onnx.ModelProto()\n    text_format.Parse(model, m_proto, allow_field_number=True)\n    return m_proto\n\ndef _is_bin_file(path):\n    # check file extension\n    return os.path.splitext(path)[1] == ONNX_SUFFX\n\ndef _is_txt_file(path):\n    # check file extension\n    return os.path.splitext(path)[1] == PROTOTXT_SUFFX\n\n_ext_map = {\n    \'.onnx\': \'.prototxt\',\n    \'.prototxt\': \'.onnx\',\n}\n\ndef _get_output_file_path(path, extension):\n    return path + _ext_map[extension]\n\nif __name__ == \'__main__\':\n    args = docopt(__doc__)\n    input_file_path = args[\'INPUT_FILE\']\n    if not args[\'OUTPUT_FILE\']:\n        output_file_path = _get_output_file_path(*os.path.splitext(input_file_path))\n    else:\n        output_file_path = args[\'OUTPUT_FILE\']\n\n    print(\'Converting {} to {}.\'.format(input_file_path, output_file_path))\n\n    if not os.path.exists(input_file_path):\n        sys.exit(\'ERROR: Provided input model path does not exists: {}\'.format(input_file_path))\n\n    # convert from binary format to text format\n    if _is_bin_file(input_file_path) and _is_txt_file(output_file_path):\n        str_msg = _bin2txt(onnx.load_model(input_file_path))\n        with open(output_file_path, \'w\') as f:\n            f.write(str_msg)\n    # convert from text format to binary format\n    elif _is_txt_file(input_file_path) and _is_bin_file(output_file_path):\n        with open(input_file_path, \'r\') as f:\n            converted_model = _txt2bin(f.read())\n        onnx.save(converted_model, output_file_path)\n    else:\n        sys.exit(\'ERROR: Provided input or output file has unsupported format.\')\n'"
test/util/unit-test-execution/conftest.py,0,"b'import logging as log\nimport sys\nimport subprocess\nimport os\nimport pytest\n\n\ndef pytest_addoption(parser):\n    parser.addoption(\n        ""--gtest_filter"",\n        help=""Attributes to gtest"",\n        type=str,\n        required=True,\n    )\n\n\n@pytest.fixture(scope=""session"")\ndef gtest_filter(request):\n    return request.config.getoption(\'gtest_filter\')\n\n\ndef shell(cmd, env=None):\n    """"""\n    Run command execution in specified environment\n    :param cmd: list containing command and its parameters\n    :param env: set of environment variables to set for this command\n    :return:\n    """"""\n    if sys.platform.startswith(\'linux\') or sys.platform == \'darwin\':\n        cmd = [\'/bin/bash\', \'-c\', ""unset OMP_NUM_THREADS; "" + cmd]\n    else:\n        cmd = "" "".join(cmd)\n\n    sys.stdout.write(""Running command:\\n"" + """".join(cmd) + ""\\n"")\n    p = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n                         universal_newlines=True)\n    stdout = []\n    while True:\n        line = p.stdout.readline()\n        stdout.append(line)\n        print(line.rstrip())\n        if line == \'\' and p.poll() != None:\n            break\n    return p.returncode, \'\'.join(stdout)\n\n\ndef create_list_test(stdout):\n    # Example of stdout content:\n    # \'CPU\'\n    # \' zero_sized_abs\'\n    # \' zero_sized_ceiling\'\n    # ...\n    # So, list of test will be concatenation of \'CPU\' and the second part (starting with \' \'):\n    # \'CPU.zero_sized_abs\'\n    # \'CPU.zero_sized_ceiling\'\n    list_test = []\n    first_name, second_name = [\'\'] * 2\n    for line in stdout:\n        if not line.startswith(\' \'):\n            first_name = line\n        else:\n            second_name = line\n            # Several test has gtest mark \'DISABLED\' inside test - no test will be executed\n            if not \'DISABLED\' in line:\n                list_test.append(first_name + second_name.strip())\n    return list_test\n\n\ndef pytest_generate_tests(metafunc):\n    gtest_filter = metafunc.config.getoption(name=\'gtest_filter\')\n    if \'gtest_filter\' in metafunc.fixturenames and gtest_filter is not None:\n        executable = os.path.join(os.environ.get(\'PATH_TO_EXE\'), ""unit-test"")\n        cmd_line = executable + \' --gtest_filter=\' + gtest_filter + \' --gtest_list_tests\'\n        log.info(\'Executing {} for getting list of test\'.format(executable))\n        retcode, stdout = shell(cmd=cmd_line)\n        assert retcode == 0, ""unit-test --gtest_list_tests execution failed. Return code: {}"".format(retcode)\n        stdout = stdout.split(\'\\n\')\n        list_test = create_list_test(stdout)\n\n        # Find all opset1 operations: execute test \'opset.dump\'\n        cmd_line_all_op = executable + \' --gtest_filter=opset.dump\'\n        log.info(\'Executing {} for getting list of test\'.format(cmd_line_all_op))\n        retcode_op1, stdout_op1 = shell(cmd=cmd_line_all_op)\n        assert retcode_op1 == 0, ""unit-test --gtest_filter=opset.dump execution failed. Return code: {}"".format(retcode)\n        # Parsing stdout to storing name of opset1 operations\n        stdout_op1 = stdout_op1.split(\'\\n\')\n        operation_opset1 = []\n        for line in stdout_op1:\n            if \'All opset1 operations:\' in line:\n                operation_opset1 = list(set(line.replace(\'All opset1 operations:\', \'\').strip().split(\' \')))\n        for op in operation_opset1:\n            pytest.operation_dictionary[op] = {}\n        metafunc.parametrize(argnames=""gtest_filter"", argvalues=list_test)\n'"
test/util/unit-test-execution/unit_test_executable.py,0,"b'import logging as log\nimport sys\nimport os\nimport csv\nimport pytest\nimport re\nfrom conftest import shell\n\nlog.basicConfig(format=""[ %(levelname)s ]  %(msg)s"", stream=sys.stdout, level=log.INFO)\n\npytest.operation_dictionary = {}\npytest.avaliable_plugins = []\n\n\ndef save_coverage_to_csv(csv_path, header):\n    with open(csv_path, \'w\', newline=\'\') as f:\n        csv_writer = csv.writer(f, delimiter=\'|\', quotechar=\'|\', quoting=csv.QUOTE_MINIMAL)\n        csv_writer.writerow(i for i in header)\n        i = 1\n        for key in sorted(pytest.operation_dictionary):\n            line = [i, key]\n            for plugin in pytest.avaliable_plugins:\n                if not plugin in pytest.operation_dictionary[key]:\n                    line.append(\'0/0\')\n                else:\n                    line.append(\'/\'.join(str(x) for x in pytest.operation_dictionary[key][plugin]))\n            csv_writer.writerow(line)\n            i += 1\n\n\ndef get_color(value):\n    if \'/\' in value:\n        passed, total = [int(x.strip()) for x in value.split(\'/\')]\n        if passed == total and total != 0:\n            return ""#d1ffd3""\n        elif passed == total and total == 0:\n            return ""#dadada""\n        else:\n            return ""#ffdbdb""\n    else:\n        return ""white""\n\n\ndef csv_to_html_table(csv_path, html_path, headers=None, delimiter="",""):\n    with open(csv_path) as f:\n        content = f.readlines()\n\n    # reading file content into list\n    rows = [x.strip() for x in content]\n    table = ""<!DOCTYPE html><html><head><title>Opset1 operations results</title></head><body><table border=1>""\n\n    # creating HTML header row if header is provided\n    if headers is not None:\n        table += ""<tr>""\n        table += """".join([""<th>"" + cell + ""</th>"" for cell in headers])\n        table += ""</tr>""\n    else:\n        table += ""<tr>""\n        table += """".join([""<th>"" + cell + ""</th>"" for cell in rows[0].split(delimiter)])\n        table += ""</tr>""\n        rows = rows[1:]\n\n    # Converting csv to html row by row\n    for row in rows:\n        table += ""<tr>"" + """".join([""<td style=background-color:%s>"" % (get_color(cell)) + cell + ""</td>""\n                                   for cell in row.split(delimiter)]) + ""</tr>"" + ""\\n""\n    table += ""</table></body></html><br>""\n\n    # Saving html file\n    fh = open(html_path, ""w"")\n    fh.write(table)\n    fh.close()\n\n\ndef setup_module():\n    try:\n        os.environ.get(\'PATH_TO_EXE\')\n    except KeyError:\n        raise ImportError(\'PATH_TO_EXE is upsent in your environment variables. \'\n                          \'Please, do ""export PATH_TO_EXE=<path to unit-test>\')\n\n\ndef teardown_module():\n    """"""\n    Creating CSV file at the end of test with nGraph nodes coverage\n    :return:\n    """"""\n    csv_path = ""nodes_coverage.csv""\n    header = [""#"", ""Operation""] + [p + "" passed / total"" for p in pytest.avaliable_plugins]\n    save_coverage_to_csv(csv_path=csv_path, header=header)\n\n    # Convert csv file to html for better visualization\n    html_path = ""nodes_coverage.html""\n    csv_to_html_table(csv_path=csv_path, html_path=html_path, delimiter=""|"")\n\n\ndef test(gtest_filter):\n    executable = os.path.join(os.environ.get(\'PATH_TO_EXE\'), ""unit-test"")\n    cmd_line = executable + \' --gtest_filter=\' + gtest_filter\n    retcode, stdout = shell(cmd=cmd_line)\n\n    # Parsing output of single test\n    stdout = stdout.split(\'\\n\')\n    nodes_list = []\n    for line in stdout:\n        if \'UNSUPPORTED OPS DETECTED!\' in line:\n            pytest.skip(\'Skip from pytest because unit-test send error UNSUPPORTED OPS DETECTED!\')\n        elif \'Nodes in test:\' in line:\n            nodes_list = list(set(line.replace(\'Nodes in test:\', \'\').strip().split(\' \')))\n\n    if not nodes_list:\n        pytest.skip(\'Skip from pytest because inside test no one ngraph function created\')\n\n    # Added one more loop, because condition below must be executed only if some nodes_list found\n    # (it means that test includes opset1 operations)\n    for line in stdout:\n        if re.match(\'.*1 test from\\s([A-Z]+)\', line):\n            matches = re.search(r\'.*1 test from\\s([A-Z]+)\', line)\n            plugin = matches.group(1)\n            if plugin not in pytest.avaliable_plugins:\n                pytest.avaliable_plugins.append(plugin)\n\n    # Filling dictionary with operation coverage\n    # How many time one operation is tested\n    for n in nodes_list:\n        if plugin in pytest.operation_dictionary[n]:\n            numerator, denominator = pytest.operation_dictionary[n][plugin]\n            pytest.operation_dictionary[n][plugin] = (numerator if retcode != 0 else numerator + 1,\n                                                      denominator + 1)\n        else:\n            pytest.operation_dictionary[n][plugin] = (0, 1) if retcode != 0 else (1, 1)\n\n    # This check is at the end, because with 99% it will return 0 or 1 (when function check of test failed)\n    # Because the same cmd line executed by pytest_generate_tests with --gtest_list_tests.\n    # So, most of the issue cached there.\n    assert retcode == 0, ""unit-test execution failed. Gtest failed. Return code: {}"".format(retcode)\n\n\nif __name__ == \'__main__\':\n    log.warning(""Please run {} by pytest like so:\\npytest {} --gtest_filter=<attributes for gtest_filter>"")\n'"
python/src/ngraph/impl/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""\nPackage: ngraph\nLow level wrappers for the nGraph c++ api.\n""""""\n\n# flake8: noqa\n\nimport os\nimport sys\n\nif sys.platform == ""win32"":\n    # ngraph.dll is installed 3 directories above by default\n    # and this path needs to be visible to the _pyngraph module\n    #\n    # If you\'re using a custom installation of nGraph,\n    # add the location of ngraph.dll to your system PATH.\n    ngraph_dll = os.path.join(os.path.dirname(__file__), "".."", "".."", "".."")\n    os.environ[""PATH""] = os.path.abspath(ngraph_dll) + "";"" + os.environ[""PATH""]\n\nfrom _pyngraph import Dimension\nfrom _pyngraph import Function\nfrom _pyngraph import Node\nfrom _pyngraph import Type\nfrom _pyngraph import PartialShape\nfrom _pyngraph import Shape\nfrom _pyngraph import Strides\nfrom _pyngraph import CoordinateDiff\nfrom _pyngraph import AxisSet\nfrom _pyngraph import AxisVector\nfrom _pyngraph import Coordinate\n\nfrom _pyngraph import serialize\nfrom _pyngraph import util\n'"
python/src/ngraph/utils/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""Generic utilities. Factor related functions out to separate files.""""""\n'"
python/src/ngraph/utils/broadcasting.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nimport logging\nfrom typing import List\n\nimport ngraph as ng\nfrom ngraph.impl import AxisSet, Node\nfrom ngraph.utils.types import NodeInput, TensorShape, get_dtype, make_constant_node\n\nlog = logging.getLogger(__name__)\n\n\ndef get_broadcast_axes(\n    output_shape: TensorShape, input_shape: TensorShape, axis: int = None\n) -> AxisSet:\n    """"""Generate a list of broadcast axes for ngraph++ broadcast.\n\n    Informally, a broadcast ""adds"" axes to the input tensor,\n    replicating elements from the input tensor as needed to fill the new dimensions.\n    Function calculate which of the output axes are added in this way.\n\n    :param output_shape: The new shape for the output tensor.\n    :param input_shape: The shape of input tensor.\n    :param axis: The axis along which we want to replicate elements.\n    :return: The indices of added axes.\n    """"""\n    axes_indexes = list(range(0, len(output_shape)))\n    if axis is None:\n        output_begin = len(output_shape) - len(input_shape)\n    else:\n        output_begin = axis\n    right_axes_indexes = list(range(output_begin, output_begin + len(input_shape)))\n    for index in reversed(right_axes_indexes):\n        del axes_indexes[index]\n    return AxisSet(set(axes_indexes))\n'"
python/src/ngraph/utils/decorators.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\nfrom functools import wraps\nfrom typing import Any, Callable\n\nfrom ngraph.impl import Node\nfrom ngraph.utils.types import NodeInput, as_node, as_nodes\n\n\ndef _set_node_name(node: Node, **kwargs: Any) -> Node:\n    if ""name"" in kwargs:\n        node.name = kwargs[""name""]\n    return node\n\n\ndef nameable_op(node_factory_function: Callable) -> Callable:\n    """"""Set the name to the ngraph operator returned by the wrapped function.""""""\n\n    @wraps(node_factory_function)\n    def wrapper(*args: Any, **kwargs: Any) -> Node:\n        node = node_factory_function(*args, **kwargs)\n        node = _set_node_name(node, **kwargs)\n        return node\n\n    return wrapper\n\n\ndef unary_op(node_factory_function: Callable) -> Callable:\n    """"""Convert the first input value to a Constant Node if a numeric value is detected.""""""\n\n    @wraps(node_factory_function)\n    def wrapper(input_value: NodeInput, *args: Any, **kwargs: Any) -> Node:\n        input_node = as_node(input_value)\n        node = node_factory_function(input_node, *args, **kwargs)\n        node = _set_node_name(node, **kwargs)\n        return node\n\n    return wrapper\n\n\ndef binary_op(node_factory_function: Callable) -> Callable:\n    """"""Convert the first two input values to Constant Nodes if numeric values are detected.""""""\n\n    @wraps(node_factory_function)\n    def wrapper(left: NodeInput, right: NodeInput, *args: Any, **kwargs: Any) -> Node:\n        left, right = as_nodes(left, right)\n        node = node_factory_function(left, right, *args, **kwargs)\n        node = _set_node_name(node, **kwargs)\n        return node\n\n    return wrapper\n'"
python/src/ngraph/utils/input_validation.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\n""""""Helper functions for validating user input.""""""\n\nimport logging\nimport numpy as np\nfrom typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Type\n\nfrom ngraph.exceptions import UserInputError\n\nlog = logging.getLogger(__name__)\n\n\ndef assert_list_of_ints(value_list: Iterable[int], message: str) -> None:\n    """"""Verify that the provided value is an iterable of integers.""""""\n    try:\n        for value in value_list:\n            if not isinstance(value, int):\n                raise TypeError\n    except TypeError:\n        log.warning(message)\n        raise UserInputError(message, value_list)\n\n\ndef _check_value(op_name, attr_key, value, val_type, cond=None):\n    # type: (str, str, Any, Type, Optional[Callable[[Any], bool]]) -> bool\n    """"""Check whether provided value satisfies specified criteria.\n\n    :param      op_name:        The operator name which attributes are checked.\n    :param      attr_key:       The attribute name.\n    :param      value:          The value to check.\n    :param      val_type:       Required value type.\n    :param      cond:           The optional function running additional checks.\n\n    :raises     UserInputError:\n    :return:    True if attribute satisfies all criterias. Otherwise False.\n    """"""\n    if not np.issubdtype(type(value), val_type):\n        raise UserInputError(\n            \'{} operator attribute ""{}"" value must by of type {}.\'.format(\n                op_name, attr_key, val_type\n            )\n        )\n    if cond is not None and not cond(value):\n        raise UserInputError(\n            \'{} operator attribute ""{}"" value does not satisfy provided condition.\'.format(\n                op_name, attr_key\n            )\n        )\n    return True\n\n\ndef check_valid_attribute(op_name, attr_dict, attr_key, val_type, cond=None, required=False):\n    # type: (str, dict, str, Type, Optional[Callable[[Any], bool]], Optional[bool]) -> bool\n    """"""Check whether specified attribute satisfies given criteria.\n\n    :param  op_name:    The operator name which attributes are checked.\n    :param attr_dict:   Dictionary containing key-value attributes to check.\n    :param attr_key:    Key value for validated attribute.\n    :param val_type:    Value type for validated attribute.\n    :param cond:        Any callable wich accept attribute value and returns True or False.\n    :param required:    Whether provided attribute key is not required. This mean it may be missing\n                        from provided dictionary.\n\n    :raises     UserInputError:\n\n    :return: True if attribute satisfies all criterias. Otherwise False.\n    """"""\n    result = True\n\n    if required and attr_key not in attr_dict:\n        raise UserInputError(\n            \'Provided dictionary is missing {} operator required attribute ""{}""\'.format(\n                op_name, attr_key\n            )\n        )\n\n    if attr_key not in attr_dict:\n        return result\n\n    attr_value = attr_dict[attr_key]\n\n    if np.isscalar(attr_value):\n        result = result and _check_value(op_name, attr_key, attr_value, val_type, cond)\n    else:\n        for v in attr_value:\n            result = result and _check_value(op_name, attr_key, v, val_type, cond)\n\n    return result\n\n\ndef check_valid_attributes(\n    op_name,  # type: str\n    attributes,  # type: Dict[str, Any]\n    requirements,  # type: List[Tuple[str, bool, Type, Optional[Callable]]]\n):\n    # type: (...) -> bool\n    """"""Perform attributes validation according to specified type, value criteria.\n\n    :param  op_name:        The operator name which attributes are checked.\n    :param  attributes:     The dictionary with user provided attributes to check.\n    :param  requirements:   The list of tuples describing attributes\' requirements. The tuple should\n                            contain following values:\n                            (attr_name: str,\n                             is_required: bool,\n                             value_type: Type,\n                             value_condition: Callable)\n\n    :raises     UserInputError:\n    :return: True if all attributes satisfies criterias. Otherwise False.\n    """"""\n    for attr, required, val_type, cond in requirements:\n        check_valid_attribute(op_name, attributes, attr, val_type, cond, required)\n    return True\n\n\ndef is_positive_value(x):  # type: (Any) -> bool\n    """"""Determine whether the specified x is positive value.\n\n    :param      x:    The value to check.\n\n    :returns:   True if the specified x is positive value, False otherwise.\n    """"""\n    return x > 0\n\n\ndef is_non_negative_value(x):  # type: (Any) -> bool\n    """"""Determine whether the specified x is non-negative value.\n\n    :param      x:    The value to check.\n\n    :returns:   True if the specified x is non-negative value, False otherwise.\n    """"""\n    return x >= 0\n'"
python/src/ngraph/utils/node_factory.py,0,"b'from typing import Any, Dict, List, Optional\n\nfrom _pyngraph import NodeFactory as _NodeFactory\nfrom ngraph.impl import Node\n\nDEFAULT_OPSET = ""opset3""\n\n\nclass NodeFactory(object):\n    """"""Factory front-end to create node objects.""""""\n\n    def __init__(self, opset_version: str = DEFAULT_OPSET) -> None:\n        """"""Create the NodeFactory object.\n\n        :param      opset_version:  The opset version the factory will use to produce ops from.\n        """"""\n        self.factory = _NodeFactory(opset_version)\n\n    def create(\n        self, op_type_name: str, arguments: List[Node], attributes: Optional[Dict[str, Any]] = None\n    ) -> Node:\n        """"""Create node object from provided description.\n\n        :param      op_type_name:  The operator type name.\n        :param      arguments:     The operator arguments.\n        :param      attributes:    The operator attributes.\n\n        :returns:   Node object representing requested operator with attributes set.\n        """"""\n        if attributes is None:\n            attributes = {}\n        node = self.factory.create(op_type_name, arguments, attributes)\n        return node\n'"
python/src/ngraph/utils/reduction.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n\nfrom typing import Iterable, Optional\n\nfrom ngraph.impl import Node\n\n\ndef get_reduction_axes(node: Node, reduction_axes: Optional[Iterable[int]]) -> Iterable[int]:\n    """"""Get reduction axes if it is None and convert it to set if its type is different.\n\n    If reduction_axes is None we default to reduce all axes.\n\n    :param node: The node we fill reduction axes for.\n    :param reduction_axes: The collection of indices of axes to reduce. May be None.\n    :return: Set filled with indices of axes we want to reduce.\n    """"""\n    if reduction_axes is None:\n        reduction_axes = set(range(len(node.shape)))\n\n    if type(reduction_axes) is not set:\n        reduction_axes = set(reduction_axes)\n    return reduction_axes\n'"
python/src/ngraph/utils/types.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""Functions related to converting between Python and numpy types and ngraph types.""""""\n\nimport logging\nfrom typing import List, Union\n\nimport numpy as np\n\nfrom ngraph.exceptions import NgraphTypeError\nfrom ngraph.impl import Node, Shape\nfrom ngraph.impl import Type as NgraphType\nfrom ngraph.impl.op import Constant\n\nlog = logging.getLogger(__name__)\n\nTensorShape = List[int]\nNumericData = Union[int, float, np.ndarray]\nNumericType = Union[type, np.dtype]\nScalarData = Union[int, float]\nNodeInput = Union[Node, NumericData]\n\nngraph_to_numpy_types_map = [\n    (NgraphType.boolean, np.bool),\n    (NgraphType.f16, np.float16),\n    (NgraphType.f32, np.float32),\n    (NgraphType.f64, np.float64),\n    (NgraphType.i8, np.int8),\n    (NgraphType.i16, np.int16),\n    (NgraphType.i32, np.int32),\n    (NgraphType.i64, np.int64),\n    (NgraphType.u8, np.uint8),\n    (NgraphType.u16, np.uint16),\n    (NgraphType.u32, np.uint32),\n    (NgraphType.u64, np.uint64),\n]\n\nngraph_to_numpy_types_str_map = [\n    (""boolean"", np.bool),\n    # (\'bf16\', ???),\n    (""f16"", np.float16),\n    (""f32"", np.float32),\n    (""f64"", np.float64),\n    (""i8"", np.int8),\n    (""i16"", np.int16),\n    (""i32"", np.int32),\n    (""i64"", np.int64),\n    (""u8"", np.uint8),\n    (""u16"", np.uint16),\n    (""u32"", np.uint32),\n    (""u64"", np.uint64),\n]\n\n\ndef get_element_type(data_type: NumericType) -> NgraphType:\n    """"""Return an ngraph element type for a Python type or numpy.dtype.""""""\n    if data_type is int:\n        log.warning(""Converting int type of undefined bitwidth to 32-bit ngraph integer."")\n        return NgraphType.i32\n\n    if data_type is float:\n        log.warning(""Converting float type of undefined bitwidth to 32-bit ngraph float."")\n        return NgraphType.f32\n\n    ng_type = next(\n        (ng_type for (ng_type, np_type) in ngraph_to_numpy_types_map if np_type == data_type), None\n    )\n    if ng_type:\n        return ng_type\n\n    raise NgraphTypeError(""Unidentified data type %s"", data_type)\n\n\ndef get_element_type_str(data_type: NumericType) -> str:\n    """"""Return an ngraph element type string representation for a Python type or numpy dtype.""""""\n    if data_type is int:\n        log.warning(""Converting int type of undefined bitwidth to 32-bit ngraph integer."")\n        return ""i32""\n\n    if data_type is float:\n        log.warning(""Converting float type of undefined bitwidth to 32-bit ngraph float."")\n        return ""f32""\n\n    ng_type = next(\n        (ng_type for (ng_type, np_type) in ngraph_to_numpy_types_str_map if np_type == data_type),\n        None,\n    )\n    if ng_type:\n        return ng_type\n\n    raise NgraphTypeError(""Unidentified data type %s"", data_type)\n\n\ndef get_dtype(ngraph_type: NgraphType) -> np.dtype:\n    """"""Return a numpy.dtype for an ngraph element type.""""""\n    np_type = next(\n        (np_type for (ng_type, np_type) in ngraph_to_numpy_types_map if ng_type == ngraph_type),\n        None,\n    )\n\n    if np_type:\n        return np.dtype(np_type)\n\n    raise NgraphTypeError(""Unidentified data type %s"", ngraph_type)\n\n\ndef get_ndarray(data: NumericData) -> np.ndarray:\n    """"""Wrap data into a numpy ndarray.""""""\n    if type(data) == np.ndarray:\n        return data\n    return np.array(data)\n\n\ndef make_constant_node(value: NumericData, dtype: NumericType = None) -> Constant:\n    """"""Return an ngraph Constant node with the specified value.""""""\n    ndarray = get_ndarray(value)\n    if dtype:\n        element_type = get_element_type(dtype)\n    else:\n        element_type = get_element_type(ndarray.dtype)\n\n    return Constant(element_type, Shape(ndarray.shape), ndarray.flatten().tolist())\n\n\ndef as_node(input_value: NodeInput) -> Node:\n    """"""Return input values as nodes. Scalars will be converted to Constant nodes.""""""\n    if issubclass(type(input_value), Node):\n        return input_value\n    return make_constant_node(input_value)\n\n\ndef as_nodes(*input_values: NodeInput) -> List[Node]:\n    """"""Return input values as nodes. Scalars will be converted to Constant nodes.""""""\n    return [as_node(input_value) for input_value in input_values]\n'"
python/src/ngraph/impl/onnx_import/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""\nPackage: ngraph\nLow level wrappers for the nGraph c++ api in ngraph::onnx_import.\n""""""\n\n# flake8: noqa\n\nfrom _pyngraph import import_onnx_model\nfrom _pyngraph import import_onnx_model_file\n'"
python/src/ngraph/impl/op/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""\nPackage: ngraph.op\nLow level wrappers for the nGraph c++ api in ngraph::op.\n""""""\n\n# flake8: noqa\n\nimport numpy as np\n\nfrom _pyngraph.op import Constant\n\n"""""" Retrieve Constant inner data.\n\n    Internally uses PyBind11 Numpy\'s buffer protocol.\n\n    :return Numpy array containing internally stored constant data.\n""""""\nConstant.get_data = lambda self: np.array(self, copy=True)\n\nfrom _pyngraph.op import GetOutputElement\nfrom _pyngraph.op import Op\nfrom _pyngraph.op import Parameter\n'"
python/src/ngraph/impl/passes/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n# flake8: noqa\n\nfrom _pyngraph.passes import Manager\n'"
python/src/ngraph/impl/runtime/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n# flake8: noqa\n\nfrom _pyngraph.runtime import Backend\nfrom _pyngraph.runtime import Executable\nfrom _pyngraph.runtime import Tensor\n'"
python/src/ngraph/impl/op/util/__init__.py,0,"b'# ******************************************************************************\n# Copyright 2017-2020 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ******************************************************************************\n""""""\nPackage: ngraph.op.util\nLow level wrappers for the nGraph c++ api in ngraph::op::util.\n""""""\n# flake8: noqa\n\nfrom _pyngraph.op.util import UnaryElementwiseArithmetic\nfrom _pyngraph.op.util import BinaryElementwiseComparison\nfrom _pyngraph.op.util import BinaryElementwiseArithmetic\nfrom _pyngraph.op.util import BinaryElementwiseLogical\nfrom _pyngraph.op.util import OpAnnotations\nfrom _pyngraph.op.util import ArithmeticReduction\nfrom _pyngraph.op.util import IndexReduction\n'"
