file_path,api_count,code
ch3/pytorch_test.py,1,"b'#!/usr/bin/env python\n# Script to test if torch installation is successful | Praveen Palanisamy\n# Chapter 3, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport torch\nt = torch.Tensor(3,3)\nprint(t)\n'"
ch3/test_box2d.py,0,"b""#!/usr/bin/env python\n# Simple script to test a box2d environment | Praveen Palanisamy\n# Chapter 3, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport gym\nenv = gym.make('BipedalWalker-v2')\nenv.reset()\nfor _ in range(1000):\n    env.render()\n    env.step(env.action_space.sample())\n"""
ch4/get_observation_action_space.py,0,"b'#!/usr/bin/env python\n# Handy script for exploring Gym environment\'s spaces | Praveen Palanisamy\n# Chapter 4, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport sys\nimport gym\nfrom gym.spaces import *\n\ndef print_spaces(space):\n    print(space)\n    if isinstance(space, Box): # Print lower and upper bound if it\'s a Box space\n        print(""\\n space.low: "", space.low)\n        print(""\\n space.high: "", space.high)\n\n    \nif __name__ == ""__main__"":\n    env = gym.make(sys.argv[1])\n    print(""Observation Space:"")\n    print_spaces(env.observation_space)\n    print(""Action Space:"")\n    print_spaces(env.action_space)\n    try:\n        print(""Action description/meaning:"",env.unwrapped.get_action_meanings())\n    except AttributeError:\n        pass\n'"
ch4/list_gym_envs.py,0,"b'#!/usr/bin/env python\n# Handy script for listing all available Gym environments | Praveen Palanisamy\n# Chapter 4, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nfrom gym import envs\nenv_names = [spec.id for spec in envs.registry.all()]\nfor name in sorted(env_names):\n    print(name)\n'"
ch4/rl_gym_boilerplate_code.py,0,"b'#!/usr/bin/env python\n# Boilerplate code for Reinforcement Learning with Gym | Praveen Palanisamy\n# Chapter 4, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport gym\nenv = gym.make(""Qbert-v0"")\nMAX_NUM_EPISODES = 10\nMAX_STEPS_PER_EPISODE = 500\nfor episode in range(MAX_NUM_EPISODES):\n    obs = env.reset()\n    for step in range(MAX_STEPS_PER_EPISODE):\n        env.render()\n        action = env.action_space.sample()# Sample random action. This will be replaced by our agent\'s action when we start developing the agent algorithms\n        next_state, reward, done, info = env.step(action) # Send the action to the environment and receive the next_state, reward and whether done or not\n        obs = next_state\n\n        if done is True:\n            print(""\\n Episode #{} ended in {} steps."".format(episode, step+1))\n            break\n        \n'"
ch4/run_gym_env.py,0,"b'#!/usr/bin/env python\n# Handy script for exploring the available Gym environments | Praveen Palanisamy\n# Chapter 4, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport gym\nimport sys\n\ndef run_gym_env(argv):\n    env = gym.make(argv[1]) # Name of the environment supplied as 1st argument\n    env.reset()\n    for _ in range(int(argv[2])): # Number of steps to be run supplied as 2nd argument\n        env.render()\n        env.step(env.action_space.sample())\n    env.close()\n    \nif __name__ == ""__main__"":\n    run_gym_env(sys.argv)\n'"
ch5/Q_learner_MountainCar.py,0,"b'#!/usr/bin/env/ python\n""""""\nq_learner.py\nAn easy-to-follow script to train, test and evaluate a Q-learning agent on the Mountain Car\nproblem using the OpenAI Gym. |Praveen Palanisamy\n# Chapter 5, Hands-on Intelligent Agents with OpenAI Gym, 2018\n""""""\nimport gym\nimport numpy as np\n\nMAX_NUM_EPISODES = 50000\nSTEPS_PER_EPISODE = 200 #  This is specific to MountainCar. May change with env\nEPSILON_MIN = 0.005\nmax_num_steps = MAX_NUM_EPISODES * STEPS_PER_EPISODE\nEPSILON_DECAY = 500 * EPSILON_MIN / max_num_steps\nALPHA = 0.05  # Learning rate\nGAMMA = 0.98  # Discount factor\nNUM_DISCRETE_BINS = 30  # Number of bins to Discretize each observation dim\n\n\nclass Q_Learner(object):\n    def __init__(self, env):\n        self.obs_shape = env.observation_space.shape\n        self.obs_high = env.observation_space.high\n        self.obs_low = env.observation_space.low\n        self.obs_bins = NUM_DISCRETE_BINS  # Number of bins to Discretize each observation dim\n        self.bin_width = (self.obs_high - self.obs_low) / self.obs_bins\n        self.action_shape = env.action_space.n\n        # Create a multi-dimensional array (aka. Table) to represent the\n        # Q-values\n        self.Q = np.zeros((self.obs_bins + 1, self.obs_bins + 1,\n                           self.action_shape))  # (51 x 51 x 3)\n        self.alpha = ALPHA  # Learning rate\n        self.gamma = GAMMA  # Discount factor\n        self.epsilon = 1.0\n\n    def discretize(self, obs):\n        return tuple(((obs - self.obs_low) / self.bin_width).astype(int))\n\n    def get_action(self, obs):\n        discretized_obs = self.discretize(obs)\n        # Epsilon-Greedy action selection\n        if self.epsilon > EPSILON_MIN:\n            self.epsilon -= EPSILON_DECAY\n        if np.random.random() > self.epsilon:\n            return np.argmax(self.Q[discretized_obs])\n        else:  # Choose a random action\n            return np.random.choice([a for a in range(self.action_shape)])\n\n    def learn(self, obs, action, reward, next_obs):\n        discretized_obs = self.discretize(obs)\n        discretized_next_obs = self.discretize(next_obs)\n        td_target = reward + self.gamma * np.max(self.Q[discretized_next_obs])\n        td_error = td_target - self.Q[discretized_obs][action]\n        self.Q[discretized_obs][action] += self.alpha * td_error\n\ndef train(agent, env):\n    best_reward = -float(\'inf\')\n    for episode in range(MAX_NUM_EPISODES):\n        done = False\n        obs = env.reset()\n        total_reward = 0.0\n        while not done:\n            action = agent.get_action(obs)\n            next_obs, reward, done, info = env.step(action)\n            agent.learn(obs, action, reward, next_obs)\n            obs = next_obs\n            total_reward += reward\n        if total_reward > best_reward:\n            best_reward = total_reward\n        print(""Episode#:{} reward:{} best_reward:{} eps:{}"".format(episode,\n                                     total_reward, best_reward, agent.epsilon))\n    # Return the trained policy\n    return np.argmax(agent.Q, axis=2)\n\n\ndef test(agent, env, policy):\n    done = False\n    obs = env.reset()\n    total_reward = 0.0\n    while not done:\n        action = policy[agent.discretize(obs)]\n        next_obs, reward, done, info = env.step(action)\n        obs = next_obs\n        total_reward += reward\n    return total_reward\n\n\nif __name__ == ""__main__"":\n    env = gym.make(\'MountainCar-v0\')\n    agent = Q_Learner(env)\n    learned_policy = train(agent, env)\n    # Use the Gym Monitor wrapper to evalaute the agent and record video\n    gym_monitor_path = ""./gym_monitor_output""\n    env = gym.wrappers.Monitor(env, gym_monitor_path, force=True)\n    for _ in range(1000):\n        test(agent, env, learned_policy)\n    env.close()\n\n'"
ch5/rl_gym_boilerplate_code_v2.py,0,"b'#!/usr/bin/env python\n# Boilerplate code for Reinforcement Learning with Gym | Praveen Palanisamy\n# Chapter 5, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport gym\nenv = gym.make(""MountainCar-v0"")\nMAX_NUM_EPISODES = 5000\n\nfor episode in range(MAX_NUM_EPISODES):\n    done = False\n    obs = env.reset()\n    total_reward = 0.0 # To keep track of the total reward obtained in each episode\n    step = 0\n    while not done:\n        env.render()\n        action = env.action_space.sample()# Sample random action. This will be replaced by our agent\'s action when we start developing the agent algorithms\n        next_state, reward, done, info = env.step(action) # Send the action to the environment and receive the next_state, reward and whether done or not\n        total_reward += reward\n        step += 1\n        obs = next_state\n\n    print(""\\n Episode #{} ended in {} steps. total_reward={}"".format(episode, step+1, total_reward))\nenv.close()\n'"
ch6/deep_Q_learner.py,12,"b'#!/usr/bin/env python\n# Deep Q-learning agent implemented using PyTorch | Praveen Palanisamy\n# Chapter 6, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nfrom datetime import datetime\nfrom argparse import ArgumentParser\nimport gym\nimport torch\nimport random\nimport numpy as np\n\nimport environment.atari as Atari\nimport environment.utils as env_utils\nfrom utils.params_manager import ParamsManager\nfrom utils.decay_schedule import LinearDecaySchedule\nfrom utils.experience_memory import Experience, ExperienceMemory\nimport utils.weights_initializer\nfrom function_approximator.perceptron import SLP\nfrom function_approximator.cnn import CNN\nfrom tensorboardX import SummaryWriter\n\nargs = ArgumentParser(""deep_Q_learner"")\nargs.add_argument(""--params-file"", help=""Path to the parameters json file. Default is parameters.json"",\n                  default=""parameters.json"", metavar=""PFILE"")\nargs.add_argument(""--env"", help=""ID of the Atari environment available in OpenAI Gym.Default is SeaquestNoFrameskip-v4"",\n                  default=""SeaquestNoFrameskip-v4"", metavar=""ENV"")\nargs.add_argument(""--gpu-id"", help=""GPU device ID to use. Default=0"", default=0, type=int, metavar=""GPU_ID"")\nargs.add_argument(""--render"", help=""Render environment to Screen. Off by default"", action=""store_true"", default=False)\nargs.add_argument(""--test"", help=""Test mode. Used for playing without learning. Off by default"", action=""store_true"",\n                  default=False)\nargs.add_argument(""--record"", help=""Enable recording (video & stats) of the agent\'s performance"",\n                  action=""store_true"", default=False)\nargs.add_argument(""--recording-output-dir"", help=""Directory to store monitor outputs. Default=./trained_models/results"",\n                  default=""./trained_models/results"")\nargs = args.parse_args()\n\nparams_manager= ParamsManager(args.params_file)\nseed = params_manager.get_agent_params()[\'seed\']\nsummary_file_path_prefix = params_manager.get_agent_params()[\'summary_file_path_prefix\']\nsummary_file_path= summary_file_path_prefix + args.env+ ""_"" + datetime.now().strftime(""%y-%m-%d-%H-%M"")\nwriter = SummaryWriter(summary_file_path)\n# Export the parameters as json files to the log directory to keep track of the parameters used in each experiment\nparams_manager.export_env_params(summary_file_path + ""/"" + ""env_params.json"")\nparams_manager.export_agent_params(summary_file_path + ""/"" + ""agent_params.json"")\nglobal_step_num = 0\nuse_cuda = params_manager.get_agent_params()[\'use_cuda\']\n# new in PyTorch 0.4\ndevice = torch.device(""cuda:"" + str(args.gpu_id) if torch.cuda.is_available() and use_cuda else ""cpu"")\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available() and use_cuda:\n    torch.cuda.manual_seed_all(seed)\n\n\nclass Deep_Q_Learner(object):\n    def __init__(self, state_shape, action_shape, params):\n        """"""\n        self.Q is the Action-Value function. This agent represents Q using a Neural Network\n        If the input is a single dimensional vector, uses a Single-Layer-Perceptron else if the input is 3 dimensional\n        image, use a Convolutional-Neural-Network\n\n        :param state_shape: Shape (tuple) of the observation/state\n        :param action_shape: Shape (number) of the discrete action space\n        :param params: A dictionary containing various Agent configuration parameters and hyper-parameters\n        """"""\n        self.state_shape = state_shape\n        self.action_shape = action_shape\n        self.params = params\n        self.gamma = self.params[\'gamma\']  # Agent\'s discount factor\n        self.learning_rate = self.params[\'lr\']  # Agent\'s Q-learning rate\n        self.best_mean_reward = - float(""inf"") # Agent\'s personal best mean episode reward\n        self.best_reward = - float(""inf"")\n        self.training_steps_completed = 0  # Number of training batch steps completed so far\n\n        if len(self.state_shape) == 1:  # Single dimensional observation/state space\n            self.DQN = SLP\n        elif len(self.state_shape) == 3:  # 3D/image observation/state\n            self.DQN = CNN\n\n        self.Q = self.DQN(state_shape, action_shape, device).to(device)\n        self.Q.apply(utils.weights_initializer.xavier)\n\n        self.Q_optimizer = torch.optim.Adam(self.Q.parameters(), lr=self.learning_rate)\n        if self.params[\'use_target_network\']:\n            self.Q_target = self.DQN(state_shape, action_shape, device).to(device)\n        # self.policy is the policy followed by the agent. This agents follows\n        # an epsilon-greedy policy w.r.t it\'s Q estimate.\n        self.policy = self.epsilon_greedy_Q\n        self.epsilon_max = params[""epsilon_max""]\n        self.epsilon_min = params[""epsilon_min""]\n        self.epsilon_decay = LinearDecaySchedule(initial_value=self.epsilon_max,\n                                    final_value=self.epsilon_min,\n                                    max_steps= self.params[\'epsilon_decay_final_step\'])\n        self.step_num = 0\n\n        self.memory = ExperienceMemory(capacity=int(self.params[\'experience_memory_capacity\']))  # Initialize an Experience memory with 1M capacity\n\n    def get_action(self, observation):\n        observation = np.array(observation)  # Observations could be lazy frames. So force fetch before moving forward\n        observation = observation / 255.0  # Scale/Divide by max limit of obs\' dtype. 255 for uint8\n        if len(observation.shape) == 3: # Single image (not a batch)\n            if observation.shape[2] < observation.shape[0]:  # Probably observation is in W x H x C format\n                # NOTE: This is just an additional check. The env wrappers are taking care of this conversion already\n                # Reshape to C x H x W format as per PyTorch\'s convention\n                observation = observation.reshape(observation.shape[2], observation.shape[1], observation.shape[0])\n            observation = np.expand_dims(observation, 0)  # Create a batch dimension\n        return self.policy(observation)\n\n    def epsilon_greedy_Q(self, observation):\n        # Decay Epsilon/exploration as per schedule\n        writer.add_scalar(""DQL/epsilon"", self.epsilon_decay(self.step_num), self.step_num)\n        self.step_num +=1\n        if random.random() < self.epsilon_decay(self.step_num) and not self.params[""test""]:\n            action = random.choice([i for i in range(self.action_shape)])\n        else:\n            action = np.argmax(self.Q(observation).data.to(torch.device(\'cpu\')).numpy())\n        return action\n\n    def learn(self, s, a, r, s_next, done):\n        # TD(0) Q-learning\n        if done:  # End of episode\n            td_target = reward + 0.0  # Set the value of terminal state to zero\n        else:\n            td_target = r + self.gamma * torch.max(self.Q(s_next))\n        td_error = td_target - self.Q(s)[a]\n        # Update Q estimate\n        #self.Q(s)[a] = self.Q(s)[a] + self.learning_rate * td_error\n        self.Q_optimizer.zero_grad()\n        td_error.backward()\n        self.Q_optimizer.step()\n\n    def learn_from_batch_experience(self, experiences):\n        batch_xp = Experience(*zip(*experiences))\n        obs_batch = np.array(batch_xp.obs) / 255.0  # Scale/Divide by max limit of obs\'s dtype. 255 for uint8\n        action_batch = np.array(batch_xp.action)\n        reward_batch = np.array(batch_xp.reward)\n        # Clip the rewards\n        if self.params[""clip_rewards""]:\n            reward_batch = np.sign(reward_batch)\n        next_obs_batch = np.array(batch_xp.next_obs) / 255.0  # Scale/Divide by max limit of obs\' dtype. 255 for uint8\n        done_batch = np.array(batch_xp.done)\n\n        if self.params[\'use_target_network\']:\n            #if self.training_steps_completed % self.params[\'target_network_update_freq\'] == 0:\n            if self.step_num % self.params[\'target_network_update_freq\'] == 0:\n                # The *update_freq is the Num steps after which target net is updated.\n                # A schedule can be used instead to vary the update freq.\n                self.Q_target.load_state_dict(self.Q.state_dict())\n            td_target = reward_batch + ~done_batch * \\\n                np.tile(self.gamma, len(next_obs_batch)) * \\\n                self.Q_target(next_obs_batch).max(1)[0].data.cpu().numpy()\n        else:\n            td_target = reward_batch + ~done_batch * \\\n                np.tile(self.gamma, len(next_obs_batch)) * \\\n                self.Q(next_obs_batch).detach().max(1)[0].data.cpu().numpy()\n\n        td_target = torch.from_numpy(td_target).to(device)\n        action_idx = torch.from_numpy(action_batch).to(device)\n        td_error = torch.nn.functional.mse_loss( self.Q(obs_batch).gather(1, action_idx.view(-1, 1)),\n                                                       td_target.float().unsqueeze(1))\n\n        self.Q_optimizer.zero_grad()\n        td_error.mean().backward()\n        writer.add_scalar(""DQL/td_error"", td_error.mean(), self.step_num)\n        self.Q_optimizer.step()\n\n    def replay_experience(self, batch_size = None):\n        batch_size = batch_size if batch_size is not None else self.params[\'replay_batch_size\']\n        experience_batch = self.memory.sample(batch_size)\n        self.learn_from_batch_experience(experience_batch)\n        self.training_steps_completed += 1  # Increment the number of training batch steps complemented\n\n    def save(self, env_name):\n        file_name = self.params[\'save_dir\'] + ""DQL_"" + env_name + "".ptm""\n        agent_state = {""Q"": self.Q.state_dict(),\n                       ""best_mean_reward"": self.best_mean_reward,\n                       ""best_reward"": self.best_reward};\n        torch.save(agent_state, file_name)\n        print(""Agent\'s state saved to "", file_name)\n\n    def load(self, env_name):\n        file_name = self.params[\'load_dir\'] + ""DQL_"" + env_name + "".ptm""\n        agent_state = torch.load(file_name, map_location= lambda storage, loc: storage)\n        self.Q.load_state_dict(agent_state[""Q""])\n        self.Q.to(device)\n        self.best_mean_reward = agent_state[""best_mean_reward""]\n        self.best_reward = agent_state[""best_reward""]\n        print(""Loaded Q model state from"", file_name,\n              "" which fetched a best mean reward of:"", self.best_mean_reward,\n              "" and an all time best reward of:"", self.best_reward)\n\n\nif __name__ == ""__main__"":\n    env_conf = params_manager.get_env_params()\n    env_conf[""env_name""] = args.env\n    # In test mode, let the end of the game be the end of episode rather than ending episode at the end of every life.\n    # This helps to report out the (mean and max) episode rewards per game (rather than per life!)\n    if args.test:\n        env_conf[""episodic_life""] = False\n    # Specify the reward calculation type used for printing stats at the end of every episode.\n    # If ""episode_life"" is true, the printed stats (reward, mean reward, max reward) are per life. If ""episodic_life""\n    # is false, the printed stats/scores are per game in Atari environments\n    rew_type = ""LIFE"" if env_conf[""episodic_life""] else ""GAME""\n\n    # If a custom useful_region configuration for this environment ID is available, use it if not use the Default\n    custom_region_available = False\n    for key, value in env_conf[\'useful_region\'].items():\n        if key in args.env:\n            env_conf[\'useful_region\'] = value\n            custom_region_available = True\n            break\n    if custom_region_available is not True:\n        env_conf[\'useful_region\'] = env_conf[\'useful_region\'][\'Default\']\n\n    print(""Using env_conf:"", env_conf)\n    atari_env = False\n    for game in Atari.get_games_list():\n        if game.replace(""_"", """") in args.env.lower():\n            atari_env = True\n    if atari_env:\n        env = Atari.make_env(args.env, env_conf)\n    else:\n        print(""Given environment name is not an Atari Env. Creating a Gym env"")\n        # Resize the obs to w x h (84 x 84 by default) and then reshape it to be in the C x H x W format\n        env = env_utils.ResizeReshapeFrames(gym.make(args.env))\n\n    if args.record:  # If monitor is enabled, record stats and video of agent\'s performance\n        env = gym.wrappers.Monitor(env, args.recording_output_dir, force=True)\n\n    observation_shape = env.observation_space.shape\n    action_shape = env.action_space.n\n    agent_params = params_manager.get_agent_params()\n    agent_params[""test""] = args.test\n    agent = Deep_Q_Learner(observation_shape, action_shape, agent_params)\n\n    episode_rewards = list()\n    prev_checkpoint_mean_ep_rew = agent.best_mean_reward\n    num_improved_episodes_before_checkpoint = 0  # To keep track of the num of ep with higher perf to save model\n    print(""Using agent_params:"", agent_params)\n    if agent_params[\'load_trained_model\']:\n        try:\n            agent.load(env_conf[""env_name""])\n            prev_checkpoint_mean_ep_rew = agent.best_mean_reward\n        except FileNotFoundError:\n            print(""WARNING: No trained model found for this environment. Training from scratch."")\n\n    #for episode in range(agent_params[\'max_num_episodes\']):\n    episode = 0\n    while global_step_num <= agent_params[\'max_training_steps\']:\n        obs = env.reset()\n        cum_reward = 0.0  # Cumulative reward\n        done = False\n        step = 0\n        #for step in range(agent_params[\'max_steps_per_episode\']):\n        while not done:\n            if env_conf[\'render\'] or args.render:\n                env.render()\n            action = agent.get_action(obs)\n            next_obs, reward, done, info = env.step(action)\n            #agent.learn(obs, action, reward, next_obs, done)\n            agent.memory.store(Experience(obs, action, reward, next_obs, done))\n\n            obs = next_obs\n            cum_reward += reward\n            step += 1\n            global_step_num +=1\n\n            if done is True:\n                episode += 1\n                episode_rewards.append(cum_reward)\n                if cum_reward > agent.best_reward:\n                    agent.best_reward = cum_reward\n                if np.mean(episode_rewards) > prev_checkpoint_mean_ep_rew:\n                    num_improved_episodes_before_checkpoint += 1\n                if num_improved_episodes_before_checkpoint >= agent_params[""save_freq_when_perf_improves""]:\n                    prev_checkpoint_mean_ep_rew = np.mean(episode_rewards)\n                    agent.best_mean_reward = np.mean(episode_rewards)\n                    agent.save(env_conf[\'env_name\'])\n                    num_improved_episodes_before_checkpoint = 0\n                print(""\\nEpisode#{} ended in {} steps. Per {} stats: reward ={} ; mean_reward={:.3f} best_reward={}"".\n                      format(episode, step+1, rew_type, cum_reward, np.mean(episode_rewards), agent.best_reward))\n                writer.add_scalar(""main/ep_reward"", cum_reward, global_step_num)\n                writer.add_scalar(""main/mean_ep_reward"", np.mean(episode_rewards), global_step_num)\n                writer.add_scalar(""main/max_ep_rew"", agent.best_reward, global_step_num)\n                # Learn from batches of experience once a certain amount of xp is available unless in test only mode\n                if agent.memory.get_size() >= 2 * agent_params[\'replay_start_size\'] and not args.test:\n                    agent.replay_experience()\n\n                break\n    env.close()\n    writer.close()\n'"
ch8/a2c_agent.py,27,"b'#!/usr/bin/env python\n# n-step Advantage Actor-Critic Agent (A2C) | Praveen Palanisamy\n# Chapter 8, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nfrom argparse import ArgumentParser\nfrom datetime import datetime\nfrom collections import namedtuple\nimport numpy as np\nimport torch\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nfrom torch.distributions.categorical import Categorical\nimport torch.multiprocessing as mp\nimport torch.nn.functional as F\nimport gym\ntry:\n    import roboschool\nexcept ImportError:\n    pass\nfrom tensorboardX import SummaryWriter\nfrom utils.params_manager import ParamsManager\nfrom function_approximator.shallow import Actor as ShallowActor\nfrom function_approximator.shallow import DiscreteActor as ShallowDiscreteActor\nfrom function_approximator.shallow import Critic as ShallowCritic\nfrom function_approximator.deep import Actor as DeepActor\nfrom function_approximator.deep import DiscreteActor as DeepDiscreteActor\nfrom function_approximator.deep import Critic as DeepCritic\nfrom environment import carla_gym\nimport environment.atari as Atari\n\nparser = ArgumentParser(""deep_ac_agent"")\nparser.add_argument(""--env"", help=""Name of the Gym environment"",\n                    default=""Pendulum-v0"", metavar=""ENV_ID"")\nparser.add_argument(""--params-file"", default=""a2c_parameters.json"",\n                    help=""Path to parameters file.Default=a2c_parameters.json"",\n                    metavar=""a2c_parameters.json"")\nparser.add_argument(""--model-dir"", default=""trained_models/"", metavar=""MODEL_DIR"",\n                    help=""Directory to save/load trained model. Default= ./trained_models/"")\nparser.add_argument(""--render"", action=\'store_true\', default=False,\n                    help=""Whether to render the environment to the display. Default=False"")\nparser.add_argument(""--test"", action=\'store_true\', default=False,\n                    help=""Tests a saved Agent model to see the performance. Disables learning"")\nparser.add_argument(""--gpu-id"", type=int, default=0, metavar=""GPU_ID"",\n                    help=""GPU device ID to use. Default:0"")\nargs = parser.parse_args()\n\nglobal_step_num = 0\nparams_manager= ParamsManager(args.params_file)\nsummary_file_path_prefix = params_manager.get_agent_params()[\'summary_file_path_prefix\']\nsummary_file_path= summary_file_path_prefix + args.env + ""_"" + datetime.now().strftime(""%y-%m-%d-%H-%M"")\nwriter = SummaryWriter(summary_file_path)\n# Export the parameters as json files to the log directory to keep track of the parameters used in each experiment\nparams_manager.export_env_params(summary_file_path + ""/"" + ""env_params.json"")\nparams_manager.export_agent_params(summary_file_path + ""/"" + ""agent_params.json"")\nuse_cuda = params_manager.get_agent_params()[\'use_cuda\']\n# Introduced in PyTorch 0.4\ndevice = torch.device(""cuda:"" + str(args.gpu_id) if torch.cuda.is_available() and use_cuda else ""cpu"")\n\nseed = params_manager.get_agent_params()[\'seed\']  # With the intent to make the results reproducible\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available() and use_cuda:\n    torch.cuda.manual_seed_all(seed)\n\nTransition = namedtuple(""Transition"", [""s"", ""value_s"", ""a"", ""log_prob_a""])\n\nclass DeepActorCriticAgent(mp.Process):\n    def __init__(self, id, env_name, agent_params, env_params):\n        """"""\n        An Advantage Actor-Critic Agent that uses a Deep Neural Network to represent it\'s Policy and the Value function\n        :param id: An integer ID to identify the agent in case there are multiple agent instances\n        :param env_name: Name/ID of the environment\n        :param agent_params: Parameters to be used by the agent\n        """"""\n        super(DeepActorCriticAgent, self).__init__()\n        self.id = id\n        self.actor_name = ""actor"" + str(self.id)\n        self.env_name = env_name\n        self.params = agent_params\n        self.env_conf = env_params\n        self.policy = self.multi_variate_gaussian_policy\n        self.gamma = self.params[\'gamma\']\n        self.trajectory = []  # Contains the trajectory of the agent as a sequence of Transitions\n        self.rewards = []  #  Contains the rewards obtained from the env at every step\n        self.global_step_num = 0\n        self.best_mean_reward = - float(""inf"") # Agent\'s personal best mean episode reward\n        self.best_reward = - float(""inf"")\n        self.saved_params = False  # Whether or not the params have been saved along with the model to model_dir\n        self.continuous_action_space = True  #Assumption by default unless env.action_space is Discrete\n\n    def multi_variate_gaussian_policy(self, obs):\n        """"""\n        Calculates a multi-variate gaussian distribution over actions given observations\n        :param obs: Agent\'s observation\n        :return: policy, a distribution over actions for the given observation\n        """"""\n        mu, sigma = self.actor(obs)\n        value = self.critic(obs)\n        [ mu[:, i].clamp_(float(self.env.action_space.low[i]), float(self.env.action_space.high[i]))\n         for i in range(self.action_shape)]  # Clamp each dim of mu based on the (low,high) limits of that action dim\n        sigma = torch.nn.Softplus()(sigma).squeeze() + 1e-7  # Let sigma be (smoothly) +ve\n        self.mu = mu.to(torch.device(""cpu""))\n        self.sigma = sigma.to(torch.device(""cpu""))\n        self.value = value.to(torch.device(""cpu""))\n        if len(self.mu.shape) == 0: # See if mu is a scalar\n            #self.mu = self.mu.unsqueeze(0)  # This prevents MultivariateNormal from crashing with SIGFPE\n            self.mu.unsqueeze_(0)\n        self.action_distribution = MultivariateNormal(self.mu, torch.eye(self.action_shape) * self.sigma, validate_args=True)\n        return self.action_distribution\n\n    def discrete_policy(self, obs):\n        """"""\n        Calculates a discrete/categorical distribution over actions given observations\n        :param obs: Agent\'s observation\n        :return: policy, a distribution over actions for the given observation\n        """"""\n        logits = self.actor(obs)\n        value = self.critic(obs)\n        self.logits = logits.to(torch.device(""cpu""))\n        self.value = value.to(torch.device(""cpu""))\n        self.action_distribution = Categorical(logits=self.logits)\n        return self.action_distribution\n\n    def preproc_obs(self, obs):\n        obs = np.array(obs)  # Obs could be lazy frames. So, force fetch before moving forward\n        if len(obs.shape) == 3:\n            #  Reshape obs from (H x W x C) order to this order: C x W x H and resize to (C x 84 x 84)\n            obs = np.reshape(obs, (obs.shape[2], obs.shape[1], obs.shape[0]))\n            obs = np.resize(obs, (obs.shape[0], 84, 84))\n        #  Convert to torch Tensor, add a batch dimension, convert to float repr\n        obs = torch.from_numpy(obs).unsqueeze(0).float()\n        return obs\n\n    def process_action(self, action):\n        if self.continuous_action_space:\n            [action[:, i].clamp_(float(self.env.action_space.low[i]), float(self.env.action_space.high[i]))\n             for i in range(self.action_shape)]  # Limit the action to lie between the (low, high) limits of the env\n        action = action.to(torch.device(""cpu""))\n        return action.numpy().squeeze(0)  # Convert to numpy ndarray, squeeze and remove the batch dimension\n\n    def get_action(self, obs):\n        obs = self.preproc_obs(obs)\n        action_distribution = self.policy(obs)  # Call to self.policy(obs) also populates self.value with V(obs)\n        value = self.value\n        action = action_distribution.sample()\n        log_prob_a = action_distribution.log_prob(action)\n        action = self.process_action(action)\n        # Store the n-step trajectory while training. Skip storing the trajectories in test mode\n        if not self.params[""test""]:\n            self.trajectory.append(Transition(obs, value, action, log_prob_a))  # Construct the trajectory\n        return action\n\n    def calculate_n_step_return(self, n_step_rewards, final_state, done, gamma):\n        """"""\n        Calculates the n-step return for each state in the input-trajectory/n_step_transitions\n        :param n_step_rewards: List of rewards for each step\n        :param final_state: Final state in this n_step_transition/trajectory\n        :param done: True rf the final state is a terminal state if not, False\n        :return: The n-step return for each state in the n_step_transitions\n        """"""\n        g_t_n_s = list()\n        with torch.no_grad():\n            g_t_n = torch.tensor([[0]]).float() if done else self.critic(self.preproc_obs(final_state)).cpu()\n            for r_t in n_step_rewards[::-1]:  # Reverse order; From r_tpn to r_t\n                g_t_n = torch.tensor(r_t).float() + self.gamma * g_t_n\n                g_t_n_s.insert(0, g_t_n)  # n-step returns inserted to the left to maintain correct index order\n            return g_t_n_s\n\n    def calculate_loss(self, trajectory, td_targets):\n        """"""\n        Calculates the critic and actor losses using the td_targets and self.trajectory\n        :param td_targets:\n        :return:\n        """"""\n        n_step_trajectory = Transition(*zip(*trajectory))\n        v_s_batch = n_step_trajectory.value_s\n        log_prob_a_batch = n_step_trajectory.log_prob_a\n        actor_losses, critic_losses = [], []\n        for td_target, critic_prediction, log_p_a in zip(td_targets, v_s_batch, log_prob_a_batch):\n            td_err = td_target - critic_prediction\n            actor_losses.append(- log_p_a * td_err)  # td_err is an unbiased estimated of Advantage\n            critic_losses.append(F.smooth_l1_loss(critic_prediction, td_target))\n            #critic_loss.append(F.mse_loss(critic_pred, td_target))\n        if self.params[""use_entropy_bonus""]:\n            actor_loss = torch.stack(actor_losses).mean() - self.action_distribution.entropy().mean()\n        else:\n            actor_loss = torch.stack(actor_losses).mean()\n        critic_loss = torch.stack(critic_losses).mean()\n\n        writer.add_scalar(self.actor_name + ""/critic_loss"", critic_loss, self.global_step_num)\n        writer.add_scalar(self.actor_name + ""/actor_loss"", actor_loss, self.global_step_num)\n\n        return actor_loss, critic_loss\n\n    def learn(self, n_th_observation, done):\n        if self.params[""clip_rewards""]:\n            self.rewards = np.sign(self.rewards).tolist()  # Clip rewards to -1 or 0 or +1\n        td_targets = self.calculate_n_step_return(self.rewards, n_th_observation, done, self.gamma)\n        actor_loss, critic_loss = self.calculate_loss(self.trajectory, td_targets)\n\n        self.actor_optimizer.zero_grad()\n        actor_loss.backward(retain_graph=True)\n        self.actor_optimizer.step()\n\n        self.critic_optimizer.zero_grad()\n        critic_loss.backward()\n        self.critic_optimizer.step()\n\n        self.trajectory.clear()\n        self.rewards.clear()\n\n    def save(self):\n        model_file_name = self.params[""model_dir""] + ""A2C_"" + self.env_name + "".ptm""\n        agent_state = {""Actor"": self.actor.state_dict(),\n                       ""Critic"": self.critic.state_dict(),\n                       ""best_mean_reward"": self.best_mean_reward,\n                       ""best_reward"": self.best_reward}\n        torch.save(agent_state, model_file_name)\n        print(""Agent\'s state is saved to"", model_file_name)\n        # Export the params used if not exported already\n        if not self.saved_params:\n            params_manager.export_agent_params(model_file_name + "".agent_params"")\n            print(""The parameters have been saved to"", model_file_name + "".agent_params"")\n            self.saved_params = True\n\n    def load(self):\n        model_file_name = self.params[""model_dir""] + ""A2C_"" + self.env_name + "".ptm""\n        agent_state = torch.load(model_file_name, map_location= lambda storage, loc: storage)\n        self.actor.load_state_dict(agent_state[""Actor""])\n        self.critic.load_state_dict(agent_state[""Critic""])\n        self.actor.to(device)\n        self.critic.to(device)\n        self.best_mean_reward = agent_state[""best_mean_reward""]\n        self.best_reward = agent_state[""best_reward""]\n        print(""Loaded Advantage Actor-Critic model state from"", model_file_name,\n              "" which fetched a best mean reward of:"", self.best_mean_reward,\n              "" and an all time best reward of:"", self.best_reward)\n\n    def run(self):\n        # If a custom useful_region configuration for this environment ID is available, use it if not use the Default.\n        # Currently this is utilized for only the Atari env. Follows the same procedure as in Chapter 6\n        custom_region_available = False\n        for key, value in self.env_conf[\'useful_region\'].items():\n            if key in args.env:\n                self.env_conf[\'useful_region\'] = value\n                custom_region_available = True\n                break\n        if custom_region_available is not True:\n            self.env_conf[\'useful_region\'] = self.env_conf[\'useful_region\'][\'Default\']\n        atari_env = False\n        for game in Atari.get_games_list():\n            if game.replace(""_"", """") in args.env.lower():\n                atari_env = True\n        if atari_env:  # Use the Atari wrappers (like we did in Chapter 6) if it\'s an Atari env\n            self.env = Atari.make_env(self.env_name, self.env_conf)\n        else:\n            #print(""Given environment name is not an Atari Env. Creating a Gym env"")\n            self.env = gym.make(self.env_name)\n\n        self.state_shape = self.env.observation_space.shape\n        if isinstance(self.env.action_space.sample(), int):  # Discrete action space\n            self.action_shape = self.env.action_space.n\n            self.policy = self.discrete_policy\n            self.continuous_action_space = False\n\n        else:  # Continuous action space\n            self.action_shape = self.env.action_space.shape[0]\n            self.policy = self.multi_variate_gaussian_policy\n        self.critic_shape = 1\n        if len(self.state_shape) == 3:  # Screen image is the input to the agent\n            if self.continuous_action_space:\n                self.actor= DeepActor(self.state_shape, self.action_shape, device).to(device)\n            else:  # Discrete action space\n                self.actor = DeepDiscreteActor(self.state_shape, self.action_shape, device).to(device)\n            self.critic = DeepCritic(self.state_shape, self.critic_shape, device).to(device)\n        else:  # Input is a (single dimensional) vector\n            if self.continuous_action_space:\n                #self.actor_critic = ShallowActorCritic(self.state_shape, self.action_shape, 1, self.params).to(device)\n                self.actor = ShallowActor(self.state_shape, self.action_shape, device).to(device)\n            else:  # Discrete action space\n                self.actor = ShallowDiscreteActor(self.state_shape, self.action_shape, device).to(device)\n            self.critic = ShallowCritic(self.state_shape, self.critic_shape, device).to(device)\n        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=self.params[""learning_rate""])\n        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=self.params[""learning_rate""])\n\n        # Handle loading and saving of trained Agent models\n        episode_rewards = list()\n        prev_checkpoint_mean_ep_rew = self.best_mean_reward\n        num_improved_episodes_before_checkpoint = 0  # To keep track of the num of ep with higher perf to save model\n        #print(""Using agent_params:"", self.params)\n        if self.params[\'load_trained_model\']:\n            try:\n                self.load()\n                prev_checkpoint_mean_ep_rew = self.best_mean_reward\n            except FileNotFoundError:\n                if args.test:  # Test a saved model\n                    print(""FATAL: No saved model found. Cannot test. Press any key to train from scratch"")\n                    input()\n                else:\n                    print(""WARNING: No trained model found for this environment. Training from scratch."")\n\n        for episode in range(self.params[""max_num_episodes""]):\n            obs = self.env.reset()\n            done = False\n            ep_reward = 0.0\n            step_num = 0\n            while not done:\n                action = self.get_action(obs)\n                next_obs, reward, done, _ = self.env.step(action)\n                self.rewards.append(reward)\n                ep_reward += reward\n                step_num +=1\n                if not args.test and (step_num >= self.params[""learning_step_thresh""] or done):\n                    self.learn(next_obs, done)\n                    step_num = 0\n                    # Monitor performance and save Agent\'s state when perf improves\n                    if done:\n                        episode_rewards.append(ep_reward)\n                        if ep_reward > self.best_reward:\n                            self.best_reward = ep_reward\n                        if np.mean(episode_rewards) > prev_checkpoint_mean_ep_rew:\n                            num_improved_episodes_before_checkpoint += 1\n                        if num_improved_episodes_before_checkpoint >= self.params[""save_freq_when_perf_improves""]:\n                            prev_checkpoint_mean_ep_rew = np.mean(episode_rewards)\n                            self.best_mean_reward = np.mean(episode_rewards)\n                            self.save()\n                            num_improved_episodes_before_checkpoint = 0\n\n                obs = next_obs\n                self.global_step_num += 1\n                if args.render:\n                    self.env.render()\n                #print(self.actor_name + "":Episode#:"", episode, ""step#:"", step_num, ""\\t rew="", reward, end=""\\r"")\n                writer.add_scalar(self.actor_name + ""/reward"", reward, self.global_step_num)\n            print(""{}:Episode#:{} \\t ep_reward:{} \\t mean_ep_rew:{}\\t best_ep_reward:{}"".format(\n                self.actor_name, episode, ep_reward, np.mean(episode_rewards), self.best_reward))\n            writer.add_scalar(self.actor_name + ""/ep_reward"", ep_reward, self.global_step_num)\n\n\nif __name__ == ""__main__"":\n    agent_params = params_manager.get_agent_params()\n    agent_params[""model_dir""] = args.model_dir\n    agent_params[""test""] = args.test\n    env_params = params_manager.get_env_params()  # Used with Atari environments\n    env_params[""env_name""] = args.env\n    mp.set_start_method(\'spawn\')  # Prevents RuntimeError during cuda init\n\n    agent_procs =[DeepActorCriticAgent(id, args.env, agent_params, env_params)\n                  for id in range(agent_params[""num_agents""])]\n    [p.start() for p in agent_procs]\n    [p.join() for p in agent_procs]\n'"
ch8/async_a2c_agent.py,27,"b'#!/usr/bin/env python\n# n-step Asynchronous Advantage Actor-Critic Agent (A3C) | Praveen Palanisamy\n# Chapter 8, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nfrom argparse import ArgumentParser\nfrom datetime import datetime\nimport time\nfrom collections import namedtuple\nimport numpy as np\nimport torch\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nfrom torch.distributions.categorical import Categorical\nimport torch.multiprocessing as mp\nimport torch.nn.functional as F\n#from environment.utils import make_env\nimport gym\ntry:\n    import roboschool\nexcept ImportError:\n    pass\nfrom tensorboardX import SummaryWriter\nfrom utils.params_manager import ParamsManager\nfrom function_approximator.shallow import Actor as ShallowActor\nfrom function_approximator.shallow import DiscreteActor as ShallowDiscreteActor\nfrom function_approximator.shallow import Critic as ShallowCritic\nfrom function_approximator.deep import Actor as DeepActor\nfrom function_approximator.deep import DiscreteActor as DeepDiscreteActor\nfrom function_approximator.deep import Critic as DeepCritic\nfrom environment import carla_gym\nimport environment.atari as Atari\n\nparser = ArgumentParser(""deep_ac_agent"")\nparser.add_argument(""--env"", help=""Name of the Gym environment"", default=""Pendulum-v0"", metavar=""ENV_ID"")\nparser.add_argument(""--params-file"", help=""Path to the parameters file. Default= ./async_a2c_parameters.json"",\n                    default=""async_a2c_parameters.json"", metavar=""async_a2c_parameters.json"")\nparser.add_argument(""--model-dir"", default=""trained_models/"", metavar=""MODEL_DIR"",\n                    help=""Directory to save/load trained model. Default= ./trained_models/"")\nparser.add_argument(""--render"", action=\'store_true\', default=False,\n                    help=""Whether to render the environment to the display. Default=False"")\nparser.add_argument(""--test"", help=""Tests a saved Agent model to see the performance. Disables learning"",\n                    action=\'store_true\', default=False)\nparser.add_argument(""--gpu-id"", help=""GPU device ID to use. Default:0"", type=int, default=0, metavar=""GPU_ID"")\nargs = parser.parse_args()\n\nglobal_step_num = 0\nparams_manager= ParamsManager(args.params_file)\nsummary_file_path_prefix = params_manager.get_agent_params()[\'summary_file_path_prefix\']\nsummary_file_path= summary_file_path_prefix + args.env + ""_"" + datetime.now().strftime(""%y-%m-%d-%H-%M"")\nwriter = SummaryWriter(summary_file_path)\n# Export the parameters as json files to the log directory to keep track of the parameters used in each experiment\nparams_manager.export_env_params(summary_file_path + ""/"" + ""env_params.json"")\nparams_manager.export_agent_params(summary_file_path + ""/"" + ""agent_params.json"")\nuse_cuda = params_manager.get_agent_params()[\'use_cuda\']\n# Introduced in PyTorch 0.4\ndevice = torch.device(""cuda:"" + str(args.gpu_id) if torch.cuda.is_available() and use_cuda else ""cpu"")\n\nseed = params_manager.get_agent_params()[\'seed\']  # With the intent to make the results reproducible\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available() and use_cuda:\n    torch.cuda.manual_seed_all(seed)\n\nTransition = namedtuple(""Transition"", [""s"", ""value_s"", ""a"", ""log_prob_a""])\n\n\nclass DeepActorCriticAgent(mp.Process):\n    def __init__(self, id, env_name, agent_params, shared_state, env_params):\n        """"""\n        An Asynchronous implementation of an Advantage Actor-Critic Agent that uses a Deep Neural Network to represent it\'s Policy and the Value function\n        :param state_shape:\n        :param action_shape:\n        """"""\n        super(DeepActorCriticAgent, self).__init__()\n        self.id = id\n        if id == 0:\n            self.actor_name = ""global""\n        else:\n            self.actor_name = ""actor"" + str(self.id)\n        self.shared_state = shared_state\n        self.env_name = env_name\n        self.params = agent_params\n        self.env_conf = env_params\n        self.policy = self.multi_variate_gaussian_policy\n        self.gamma = self.params[\'gamma\']\n        self.trajectory = []  # Contains the trajectory of the agent as a sequence of Transitions\n        self.rewards = []  # Contains the rewards obtained from the env at every step\n        self.global_step_num = 0\n        self.best_mean_reward = - float(""inf"") # Agent\'s personal best mean episode reward\n        self.best_reward = - float(""inf"")\n        self.saved_params = False  # Whether or not the params have been saved along with the model to model_dir\n        self.continuous_action_space = True  # Assumption by default unless env.action_space is Discrete\n\n    def multi_variate_gaussian_policy(self, obs):\n        """"""\n        Calculates a multi-variate gaussian distribution over actions given observations\n        :param obs: Agent\'s observation\n        :return: policy, a distribution over actions for the given observation\n        """"""\n        mu, sigma = self.actor(obs)\n        value = self.critic(obs)\n        [ mu[:, i].clamp_(float(self.env.action_space.low[i]), float(self.env.action_space.high[i]))\n         for i in range(self.action_shape)]  # Clamp each dim of mu based on the (low,high) limits of that action dim\n        sigma = torch.nn.Softplus()(sigma).squeeze() + 1e-7  # Let sigma be (smoothly) +ve\n        self.mu = mu.to(torch.device(""cpu""))\n        self.sigma = sigma.to(torch.device(""cpu""))\n        self.value = value.to(torch.device(""cpu""))\n        if len(self.mu.shape) == 0: # See if mu is a scalar\n            # self.mu = self.mu.unsqueeze(0)  # This prevents MultivariateNormal from crashing with SIGFPE\n            self.mu.unsqueeze_(0)\n        self.action_distribution = MultivariateNormal(self.mu, torch.eye(self.action_shape) * self.sigma, validate_args=True)\n        return self.action_distribution\n\n    def discrete_policy(self, obs):\n        """"""\n        Calculates a discrete/categorical distribution over actions given observations\n        :param obs: Agent\'s observation\n        :return: policy, a distribution over actions for the given observation\n        """"""\n        logits = self.actor(obs)\n        value = self.critic(obs)\n        self.logits = logits.to(torch.device(""cpu""))\n        self.value = value.to(torch.device(""cpu""))\n        self.action_distribution = Categorical(logits=self.logits)\n        return self.action_distribution\n\n    def preproc_obs(self, obs):\n        obs = np.array(obs)  # Obs could be lazy frames. So, force fetch before moving forward\n        if len(obs.shape) == 3:\n            # Reshape obs from (H x W x C) order to this order: C x W x H and resize to (C x 84 x 84)\n            obs = np.reshape(obs, (obs.shape[2], obs.shape[1], obs.shape[0]))\n            obs = np.resize(obs, (obs.shape[0], 84, 84))\n        #  Convert to torch Tensor, add a batch dimension, convert to float repr\n        obs = torch.from_numpy(obs).unsqueeze(0).float()\n        return obs\n\n    def process_action(self, action):\n        if self.continuous_action_space:\n            [action[:, i].clamp_(float(self.env.action_space.low[i]), float(self.env.action_space.high[i]))\n             for i in range(self.action_shape)]  # Limit the action to lie between the (low, high) limits of the env\n        action = action.to(torch.device(""cpu""))\n        return action.numpy().squeeze(0)  # Convert to numpy ndarray, squeeze and remove the batch dimension\n\n    def get_action(self, obs):\n        obs = self.preproc_obs(obs)\n        action_distribution = self.policy(obs)  # Call to self.policy(obs) also populates self.value with V(obs)\n        value = self.value\n        action = action_distribution.sample()\n        log_prob_a = action_distribution.log_prob(action)\n        action = self.process_action(action)\n        # Store the n-step trajectory for learning. Skip storing the trajectories in test only mode\n        if not self.params[""test""]:\n            self.trajectory.append(Transition(obs, value, action, log_prob_a))  # Construct the trajectory\n        return action\n\n    def calculate_n_step_return(self, n_step_rewards, final_state, done, gamma):\n        """"""\n        Calculates the n-step return for each state in the input-trajectory/n_step_transitions\n        :param n_step_rewards: List of rewards for each step\n        :param final_state: Final state in this n_step_transition/trajectory\n        :param done: True rf the final state is a terminal state if not, False\n        :return: The n-step return for each state in the n_step_transitions\n        """"""\n        g_t_n_s = list()\n        with torch.no_grad():\n            g_t_n = torch.tensor([[0]]).float() if done else self.critic(self.preproc_obs(final_state)).cpu()\n            for r_t in n_step_rewards[::-1]:  # Reverse order; From r_tpn to r_t\n                g_t_n = torch.tensor(r_t).float() + self.gamma * g_t_n\n                g_t_n_s.insert(0, g_t_n)  # n-step returns inserted to the left to maintain correct index order\n            return g_t_n_s\n\n    def calculate_loss(self, trajectory, td_targets):\n        """"""\n        Calculates the critic and actor losses using the td_targets and self.trajectory\n        :param td_targets:\n        :return:\n        """"""\n        n_step_trajectory = Transition(*zip(*trajectory))\n        v_s_batch = n_step_trajectory.value_s\n        log_prob_a_batch = n_step_trajectory.log_prob_a\n        actor_losses, critic_losses = [], []\n        for td_target, critic_prediction, log_p_a in zip(td_targets, v_s_batch, log_prob_a_batch):\n            td_err = td_target - critic_prediction\n            actor_losses.append(- log_p_a * td_err)  # td_err is an unbiased estimated of Advantage\n            critic_losses.append(F.smooth_l1_loss(critic_prediction, td_target))\n            #critic_loss.append(F.mse_loss(critic_pred, td_target))\n        if self.params[""use_entropy_bonus""]:\n            actor_loss = torch.stack(actor_losses).mean() - self.action_distribution.entropy().mean()\n        else:\n            actor_loss = torch.stack(actor_losses).mean()\n        critic_loss = torch.stack(critic_losses).mean()\n\n        if self.actor_name == ""global"":\n            writer.add_scalar(self.actor_name + ""/critic_loss"", critic_loss, self.global_step_num)\n            writer.add_scalar(self.actor_name + ""/actor_loss"", actor_loss, self.global_step_num)\n\n        return actor_loss, critic_loss\n\n    def pull_params_from_global_agent(self):\n        # If this is the very beginning of the procs, the global agent may not have started yet.\n        # Wait for the global agent proc to start and make the shared state dict available\n        while ""actor_state_dict"" not in self.shared_state or ""critic_state_dict"" not in self.shared_state:\n            time.sleep(2)\n        self.actor.load_state_dict(self.shared_state[""actor_state_dict""])\n        self.critic.load_state_dict(self.shared_state[""critic_state_dict""])\n        self.actor.to(device)\n        self.critic.to(device)\n\n    def push_params_to_global_agent(self):\n        self.shared_state[""actor_state_dict""] = self.actor.cpu().state_dict()\n        self.shared_state[""critic_state_dict""] = self.critic.cpu().state_dict()\n        # To make sure that the actor & critic models are on the desired device\n        self.actor.to(device)\n        self.critic.to(device)\n\n    def learn(self, n_th_observation, done):\n        if self.params[""clip_rewards""]:\n            self.rewards = np.sign(self.rewards).tolist()  # Clip rewards to -1 or 0 or +1\n        td_targets = self.calculate_n_step_return(self.rewards, n_th_observation, done, self.gamma)\n        actor_loss, critic_loss = self.calculate_loss(self.trajectory, td_targets)\n\n        self.actor_optimizer.zero_grad()\n        actor_loss.backward(retain_graph=True)\n        self.actor_optimizer.step()\n\n        self.critic_optimizer.zero_grad()\n        critic_loss.backward()\n        self.critic_optimizer.step()\n\n        self.trajectory.clear()\n        self.rewards.clear()\n\n    def save(self):\n        model_file_name = self.params[""model_dir""] + ""Async-A2C_"" + self.env_name + "".ptm""\n        agent_state = {""Actor"": self.actor.state_dict(),\n                       ""Critic"": self.critic.state_dict(),\n                       ""best_mean_reward"": self.best_mean_reward,\n                       ""best_reward"": self.best_reward}\n        torch.save(agent_state, model_file_name)\n        print(""Agent\'s state is saved to"", model_file_name)\n        # Export the params used if not exported already\n        if not self.saved_params:\n            params_manager.export_agent_params(model_file_name + "".agent_params"")\n            print(""The parameters have been saved to"", model_file_name + "".agent_params"")\n            self.saved_params = True\n\n    def load(self):\n        model_file_name = self.params[""model_dir""] + ""Async-A2C_"" + self.env_name + "".ptm""\n        agent_state = torch.load(model_file_name, map_location= lambda storage, loc: storage)\n        self.actor.load_state_dict(agent_state[""Actor""])\n        self.critic.load_state_dict(agent_state[""Critic""])\n        self.actor.to(device)\n        self.critic.to(device)\n        self.best_mean_reward = agent_state[""best_mean_reward""]\n        self.best_reward = agent_state[""best_reward""]\n        print(""Loaded Advantage Actor-Critic model state from"", model_file_name,\n              "" which fetched a best mean reward of:"", self.best_mean_reward,\n              "" and an all time best reward of:"", self.best_reward)\n\n    def run(self):\n        # If a custom useful_region configuration for this environment ID is available, use it if not use the Default.\n        # Currently this is utilized for only the Atari env. Follows the same procedure as in Chapter 6\n        custom_region_available = False\n        for key, value in self.env_conf[\'useful_region\'].items():\n            if key in args.env:\n                self.env_conf[\'useful_region\'] = value\n                custom_region_available = True\n                break\n        if custom_region_available is not True:\n            self.env_conf[\'useful_region\'] = self.env_conf[\'useful_region\'][\'Default\']\n        atari_env = False\n        for game in Atari.get_games_list():\n            if game.replace(""_"", """") in args.env.lower():\n                atari_env = True\n        if atari_env:  # Use the Atari wrappers (like we did in Chapter 6) if it\'s an Atari env\n            self.env = Atari.make_env(self.env_name, self.env_conf)\n        else:\n            #print(""Given environment name is not an Atari Env. Creating a Gym env"")\n            self.env = gym.make(self.env_name)\n\n        self.state_shape = self.env.observation_space.shape\n        if isinstance(self.env.action_space.sample(), int):  # Discrete action space\n            self.action_shape = self.env.action_space.n\n            self.policy = self.discrete_policy\n            self.continuous_action_space = False\n\n        else:  # Continuous action space\n            self.action_shape = self.env.action_space.shape[0]\n            self.policy = self.multi_variate_gaussian_policy\n        self.critic_shape = 1\n        if len(self.state_shape) == 3:  # Screen image is the input to the agent\n            if self.continuous_action_space:\n                self.actor= DeepActor(self.state_shape, self.action_shape, device).to(device)\n            else:  # Discrete action space\n                self.actor = DeepDiscreteActor(self.state_shape, self.action_shape, device).to(device)\n            self.critic = DeepCritic(self.state_shape, self.critic_shape, device).to(device)\n        else:  # Input is a (single dimensional) vector\n            if self.continuous_action_space:\n                #self.actor_critic = ShallowActorCritic(self.state_shape, self.action_shape, 1, self.params).to(device)\n                self.actor = ShallowActor(self.state_shape, self.action_shape, device).to(device)\n            else:  # Discrete action space\n                self.actor = ShallowDiscreteActor(self.state_shape, self.action_shape, device).to(device)\n            self.critic = ShallowCritic(self.state_shape, self.critic_shape, device).to(device)\n\n        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=self.params[""learning_rate""])\n        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=self.params[""learning_rate""])\n\n        if self.actor_name == ""global"":\n\n            # Handle loading and saving of trained Agent\'s model\n            episode_rewards = list()\n            prev_checkpoint_mean_ep_rew = self.best_mean_reward\n            num_improved_episodes_before_checkpoint = 0  # To keep track of the num of ep with higher perf to save model\n            #print(""Using agent_params:"", self.params)\n            if self.params[\'load_trained_model\']:\n                try:\n                    self.load()\n                    prev_checkpoint_mean_ep_rew = self.best_mean_reward\n                except FileNotFoundError:\n                    if args.test:  # Test a saved model\n                        print(""FATAL: No saved model found. Cannot test. Press any key to train from scratch"")\n                        input()\n                    else:\n                        print(""WARNING: No trained model found for this environment. Training from scratch."")\n            self.actor.share_memory()\n            self.critic.share_memory()\n            # Initialize the global shared actor-critic parameters\n            self.shared_state[""actor_state_dict""] = self.actor.cpu().state_dict()\n            self.shared_state[""critic_state_dict""] = self.critic.cpu().state_dict()\n\n        for episode in range(self.params[""max_num_episodes""]):\n            obs = self.env.reset()\n            done = False\n            ep_reward = 0.0\n            step_num = 0\n            self.pull_params_from_global_agent()  # Synchronize local-agent specific parameters from the global\n            while not done:\n                action = self.get_action(obs)\n                next_obs, reward, done, _ = self.env.step(action)\n                self.rewards.append(reward)\n                ep_reward += reward\n                step_num += 1\n                if not args.test and (step_num >= self.params[""learning_step_thresh""] or done):\n                    self.learn(next_obs, done)\n                    step_num = 0\n                    # Async send updates to the global shared parameters\n                    self.push_params_to_global_agent()\n\n                    # Monitor performance and save Agent\'s state when perf improves\n                    if done and self.actor_name == ""global"":\n                        episode_rewards.append(ep_reward)\n                        if ep_reward > self.best_reward:\n                            self.best_reward = ep_reward\n                        if np.mean(episode_rewards) > prev_checkpoint_mean_ep_rew:\n                            num_improved_episodes_before_checkpoint += 1\n                        if num_improved_episodes_before_checkpoint >= self.params[""save_freq_when_perf_improves""]:\n                            prev_checkpoint_mean_ep_rew = np.mean(episode_rewards)\n                            self.best_mean_reward = np.mean(episode_rewards)\n                            self.save()\n                            num_improved_episodes_before_checkpoint = 0\n\n                obs = next_obs\n                self.global_step_num += 1\n                if self.actor_name == ""global"":\n                    if args.render:\n                        self.env.render()\n                    #print(self.actor_name + "":Episode#:"", episode, ""step#:"", step_num, ""\\t rew="", reward, end=""\\r"")\n                    writer.add_scalar(self.actor_name + ""/reward"", reward, self.global_step_num)\n            # Print stats at the end of episodes\n            if self.actor_name == ""global"":\n                print(""{}:Episode#:{} \\t ep_reward:{} \\t mean_ep_rew:{}\\t best_ep_reward:{}"".format(\n                            self.actor_name, episode, ep_reward, np.mean(episode_rewards), self.best_reward))\n                writer.add_scalar(self.actor_name + ""/ep_reward"", ep_reward, self.global_step_num)\n\n\nif __name__ == ""__main__"":\n    agent_params = params_manager.get_agent_params()\n    agent_params[""model_dir""] = args.model_dir\n    agent_params[""test""] = args.test\n    env_params = params_manager.get_env_params()  # Used with Atari environments\n    env_params[""env_name""] = args.env\n    mp.set_start_method(\'spawn\')  # Prevents RuntimeError during cuda init\n\n    manager = mp.Manager()\n    shared_state = manager.dict()\n    if not args.test:\n        agent_procs =[DeepActorCriticAgent(id, args.env, agent_params, shared_state, env_params)\n                      for id in range(agent_params[""num_agents""])]\n        [p.start() for p in agent_procs]\n        [p.join() for p in agent_procs]\n    else:\n        test_agent_proc = DeepActorCriticAgent(0, args.env, agent_params, shared_state, env_params)\n        test_agent_proc.start()\n        test_agent_proc.join()\n\n'"
ch8/batched_a2c_agent.py,36,"b'#!/usr/bin/env python\n# Batched n-step Advantage Actor-Critic Agent (A2C) | Praveen Palanisamy\n# Chapter 8, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nfrom argparse import ArgumentParser\nfrom datetime import datetime\nfrom collections import namedtuple\nimport numpy as np\nimport torch\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nfrom torch.distributions.categorical import Categorical\nimport torch.multiprocessing as mp\nimport torch.nn.functional as F\nfrom environment.utils import SubprocVecEnv\ntry:\n    import roboschool\nexcept ImportError:\n    pass\nfrom tensorboardX import SummaryWriter\nfrom utils.params_manager import ParamsManager\nfrom function_approximator.shallow import Actor as ShallowActor\nfrom function_approximator.shallow import DiscreteActor as ShallowDiscreteActor\nfrom function_approximator.shallow import Critic as ShallowCritic\nfrom function_approximator.deep import Actor as DeepActor\nfrom function_approximator.deep import DiscreteActor as DeepDiscreteActor\nfrom function_approximator.deep import Critic as DeepCritic\nfrom environment import carla_gym\n\nparser = ArgumentParser(""deep_ac_agent"")\nparser.add_argument(""--env"", help=""Name of the Gym environment"", default=""CarRacing-v0"", metavar=""ENV_ID"")\nparser.add_argument(""--params-file"", help=""Path to the parameters file. Default= ./parameters.json"",\n                    default=""parameters.json"", metavar=""PFILE.json"")\nparser.add_argument(""--model-dir"", help=""Directory to save/load trained model. Default= ./trained_models/"",\n                    default=""trained_models/"", metavar=""MODEL_DIR"")\nparser.add_argument(""--render"", help=""Whether to render the environment to the display. Default=False"",\n                    action=\'store_true\', default=False)\nparser.add_argument(""--test"", help=""Tests a saved Agent model to see the performance. Disables learning"",\n                    action=\'store_true\', default=False)\nparser.add_argument(""--gpu-id"", help=""GPU device ID to use. Default:0"", type=int, default=0, metavar=""GPU_ID"")\nargs = parser.parse_args()\n\nglobal_step_num = 0\nparams_manager= ParamsManager(args.params_file)\nsummary_file_path_prefix = params_manager.get_agent_params()[\'summary_file_path_prefix\']\nsummary_file_path= summary_file_path_prefix + args.env + ""_"" + datetime.now().strftime(""%y-%m-%d-%H-%M"")\nwriter = SummaryWriter(summary_file_path)\n# Export the parameters as json files to the log directory to keep track of the parameters used in each experiment\nparams_manager.export_env_params(summary_file_path + ""/"" + ""env_params.json"")\nparams_manager.export_agent_params(summary_file_path + ""/"" + ""agent_params.json"")\nuse_cuda = params_manager.get_agent_params()[\'use_cuda\']\n# Introduced in PyTorch 0.4\ndevice = torch.device(""cuda:"" + str(args.gpu_id) if torch.cuda.is_available() and use_cuda else ""cpu"")\n\nseed = params_manager.get_agent_params()[\'seed\']  # With the intent to make the results reproducible\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available() and use_cuda:\n    torch.cuda.manual_seed_all(seed)\n\nTransition = namedtuple(""Transition"", [""s"", ""value_s"", ""a"", ""log_prob_a""])\n\n\nclass DeepActorCriticAgent():\n    def __init__(self, id, env_names, agent_params):\n        """"""\n        An Actor-Critic Agent that uses a Deep Neural Network to represent it\'s Policy and the Value function\n        :param state_shape:\n        :param action_shape:\n        """"""\n        super(DeepActorCriticAgent, self).__init__()\n        self.id = id\n        self.actor_name = ""actor"" + str(self.id)\n        self.env_names = env_names\n        self.params = agent_params\n        self.policy = self.multi_variate_gaussian_policy\n        self.gamma = self.params[\'gamma\']\n        self.trajectory = []  # Contains the trajectory of the agent as a sequence of Transitions\n        self.rewards = []  #  Contains the rewards obtained from the env at every step\n        self.global_step_num = 0\n        self.best_mean_reward = - float(""inf"") # Agent\'s personal best mean episode reward\n        self.best_reward = - float(""inf"")\n        self.saved_params = False  # Whether or not the params have been saved along with the model to model_dir\n        self.continuous_action_space = True  # Assumption by default unless env.action_space is Discrete\n\n    def multi_variate_gaussian_policy(self, obs):\n        """"""\n        Calculates a multi-variate gaussian distribution over actions given observations\n        :param obs: Agent\'s observation\n        :return: policy, a distribution over actions for the given observation\n        """"""\n        mu, sigma = self.actor(obs)\n        value = self.critic(obs).squeeze()\n        [ mu[:, i].clamp_(float(self.envs.action_space.low[i]), float(self.envs.action_space.high[i]))\n         for i in range(self.action_shape)]  # Clamp each dim of mu based on the (low,high) limits of that action dim\n        sigma = torch.nn.Softplus()(sigma) + 1e-7  # Let sigma be (smoothly) +ve\n        self.mu = mu.to(torch.device(""cpu""))\n        self.sigma = sigma.to(torch.device(""cpu""))\n        self.value = value.to(torch.device(""cpu""))\n        if len(self.mu[0].shape) == 0: # See if mu is a scalar\n            self.mu = self.mu.unsqueeze(0)  # This prevents MultivariateNormal from crashing with SIGFPE\n        self.covariance = torch.stack([torch.eye(self.action_shape) * s for s in self.sigma])\n        if self.action_shape == 1:\n            self.covariance = self.sigma.unsqueeze(-1)  # Make the covariance a square mat to avoid RuntimeError with MultivariateNormal\n        self.action_distribution = MultivariateNormal(self.mu, self.covariance)\n        return self.action_distribution\n\n    def discrete_policy(self, obs):\n        """"""\n        Calculates a discrete/categorical distribution over actions given observations\n        :param obs: Agent\'s observation\n        :return: policy, a distribution over actions for the given observation\n        """"""\n        logits = self.actor(obs)\n        value = self.critic(obs).squeeze()\n        self.logits = logits.to(torch.device(""cpu""))\n        self.value = value.to(torch.device(""cpu""))\n        self.action_distribution = Categorical(logits=self.logits)\n        return self.action_distribution\n\n    def preproc_obs(self, obs):\n        if len(obs[0].shape) == 3:  # shape of obs:(num_agents, obs_im_height, obs_im_width, obs_num_channels)\n            #  Reshape obs from (B x H x W x C) order to this order: B x C x W x H and resize to (C x 84 x 84)\n            obs = np.reshape(obs, (-1, obs.shape[3], obs.shape[2], obs.shape[1]))\n            #  The environment wrapper already takes care of reshaping image obs into 84 x 84 x C. Can be skipped\n            obs = np.resize(obs, (-1, obs.shape[1], 84, 84))\n        #  Convert to torch Tensor, convert to float repr\n        obs = torch.from_numpy(obs).float()\n        return obs\n\n    def process_action(self, action):\n        if self.continuous_action_space:\n            [action[:, i].clamp_(float(self.envs.action_space.low[i]), float(self.envs.action_space.high[i]))\n             for i in range(self.action_shape)]  # Limit the action to lie between the (low, high) limits of the env\n        action = action.to(torch.device(""cpu""))\n        return action.numpy()\n\n    def get_action(self, obs):\n        obs = self.preproc_obs(obs)\n        action_distributions = self.policy(obs)  # Call to self.policy(obs) also populates self.value with V(obs)\n        value = self.value\n        actions = action_distributions.sample()\n        log_prob_a = action_distributions.log_prob(actions)\n        actions = self.process_action(actions)\n        # Store the n-step trajectory for learning. Skip storing the trajectory in test only mode\n        if not self.params[""test""]:\n            self.trajectory.append(Transition(obs, value, actions, log_prob_a))  # Construct the trajectory\n        return actions\n    # TODO: rename num_agents to num_actors in parameters.json file to be consistent with comments\n    def calculate_n_step_return(self, n_step_rewards, next_states, dones, gamma):\n        """"""\n        Calculates the n-step return for each state in the input-trajectory/n_step_transitions for the ""done"" actors\n        :param n_step_rewards: List of length=num_steps containing rewards of shape=(num_actors x 1)\n        :param next_states: list of length=num_actors containing next observations of shape=(obs_shape)\n        :param dones: list of length=num_actors containing True if the next_state is a terminal state if not, False\n        :return: The n-step return for each state in the n_step_transitions\n        """"""\n        g_t_n_s = list()\n        with torch.no_grad():\n            # 1. Calculate next-state values for each actor:\n            #    a. If next_state is terminal (done[actor_idx]=True), set g_t_n[actor_idx]=0\n            #    b. If next_state is non-terminal (done[actor_idx]=False), set g_t_n[actor_idx] to Critic\'s prediction\n            g_t_n = torch.tensor([[not d] for d  in dones]).float()  # 1. a.\n            # See if there is at least one non-terminal next-state\n            if np.where([not d for d in dones])[0].size > 0:\n                non_terminal_idxs = torch.tensor(np.where([not d for d in dones])).squeeze(0)\n                g_t_n[non_terminal_idxs] = self.critic(self.preproc_obs(next_states[non_terminal_idxs])).cpu()  # 1. b.\n            g_t_n_s_batch = []\n            n_step_rewards = torch.stack(n_step_rewards)  # tensor of shape (num_steps x num_actors x 1)\n            # For each actor\n            for actor_idx in range(n_step_rewards.shape[1]):\n                actor_n_step_rewards = n_step_rewards.index_select(1, torch.tensor([actor_idx]))  # shape:(num_steps,1)\n                g_t_n_s = []\n                # Calculate n number of n-step returns\n                for r_t in actor_n_step_rewards.numpy()[::-1]:  # Reverse order; From r_tpn to r_t; PyTorch can\'t slice in reverse #229\n                    g_t_n[actor_idx] = torch.tensor(r_t).float() + self.gamma * g_t_n[actor_idx]\n                    g_t_n_s.insert(0, g_t_n[actor_idx].clone())  # n-step returns inserted to the left to maintain correct index order\n                g_t_n_s_batch.append(g_t_n_s)\n            return torch.tensor(g_t_n_s_batch)  # tensor of shape:(num_actors, num_steps, 1)\n\n    def calculate_loss(self, trajectory, td_targets):\n        """"""\n        Calculates the critic and actor losses using the td_targets and self.trajectory\n        :param trajectory: List of trajectories from all the actors\n        :param td_targets: Tensor of shape:(num_actors, num_steps, 1)\n        :return:\n        """"""\n        n_step_trajectory = Transition(*zip(*trajectory))\n        # n_step_trajectory.x returns a list of length= num_steps containing num_actors x shape_of_x items\n        # 1. Create tensor of shape:(num_steps x num_actors x shape_of_x) (using torch.stack())\n        # 2. Reshape the tensor to be of shape:(num_actors x num_steps x shape_of_x) (using torch.transpose(1,0)\n        v_s_batch = torch.stack(n_step_trajectory.value_s).transpose(1, 0)  # shape:(num_actors, num_steps, 1)\n        log_prob_a_batch = torch.stack(n_step_trajectory.log_prob_a).transpose(1, 0)  # shape:(num_actors, num_steps, 1)\n        actor_losses, critic_losses = [], []\n        for td_targets, critic_predictions, log_p_a in zip(td_targets, v_s_batch, log_prob_a_batch):\n            td_err = td_targets - critic_predictions\n            actor_losses.append(- log_p_a * td_err)  # td_err is an unbiased estimated of Advantage\n            critic_losses.append(F.smooth_l1_loss(critic_predictions, td_targets))\n            #critic_loss.append(F.mse_loss(critic_pred, td_target))\n        if self.params[""use_entropy_bonus""]:\n            actor_loss = torch.stack(actor_losses).mean() - self.action_distribution.entropy().mean()\n        else:\n            actor_loss = torch.stack(actor_losses).mean()\n        critic_loss = torch.stack(critic_losses).mean()\n\n        writer.add_scalar(self.actor_name + ""/critic_loss"", critic_loss, self.global_step_num)\n        writer.add_scalar(self.actor_name + ""/actor_loss"", actor_loss, self.global_step_num)\n\n        return actor_loss, critic_loss\n\n    def learn(self, n_th_observations, dones):\n        td_targets = self.calculate_n_step_return(self.rewards, n_th_observations, dones, self.gamma)\n        actor_loss, critic_loss = self.calculate_loss(self.trajectory, td_targets)\n\n        self.actor_optimizer.zero_grad()\n        actor_loss.backward(retain_graph=True)\n        self.actor_optimizer.step()\n\n        self.critic_optimizer.zero_grad()\n        critic_loss.backward()\n        self.critic_optimizer.step()\n\n        self.trajectory.clear()\n        self.rewards.clear()\n\n    def save(self):\n        model_file_name = self.params[""model_dir""] + ""Batch-A2C_"" + self.env_names[0] + "".ptm""\n        agent_state = {""Actor"": self.actor.state_dict(),\n                       ""Critic"": self.critic.state_dict(),\n                       ""best_mean_reward"": self.best_mean_reward,\n                       ""best_reward"": self.best_reward}\n        torch.save(agent_state, model_file_name)\n        print(""Agent\'s state is saved to"", model_file_name)\n        # Export the params used if not exported already\n        if not self.saved_params:\n            params_manager.export_agent_params(model_file_name + "".agent_params"")\n            print(""The parameters have been saved to"", model_file_name + "".agent_params"")\n            self.saved_params = True\n\n    def load(self):\n        model_file_name = self.params[""model_dir""] + ""Batch-A2C_"" + self.env_names[0] + "".ptm""\n        agent_state = torch.load(model_file_name, map_location= lambda storage, loc: storage)\n        self.actor.load_state_dict(agent_state[""Actor""])\n        self.critic.load_state_dict(agent_state[""Critic""])\n        self.actor.to(device)\n        self.critic.to(device)\n        self.best_mean_reward = agent_state[""best_mean_reward""]\n        self.best_reward = agent_state[""best_reward""]\n        print(""Loaded Advantage Actor-Critic model state from"", model_file_name,\n              "" which fetched a best mean reward of:"", self.best_mean_reward,\n              "" and an all time best reward of:"", self.best_reward)\n\n    def run(self):\n        self.envs = SubprocVecEnv(self.env_names)\n        self.state_shape = self.envs.observation_space.shape\n        if isinstance(self.envs.action_space.sample(), int):  # Discrete action space\n            self.action_shape = self.envs.action_space.n\n            self.policy = self.discrete_policy\n            self.continuous_action_space = False\n\n        else:  # Continuous action space\n            self.action_shape = self.envs.action_space.shape[0]\n            self.policy = self.multi_variate_gaussian_policy\n        self.critic_shape = 1\n        if len(self.state_shape) == 3:  # Screen image is the input to the agent\n            if self.continuous_action_space:\n                self.actor= DeepActor(self.state_shape, self.action_shape, device).to(device)\n            else:  # Discrete action space\n                self.actor = DeepDiscreteActor(self.state_shape, self.action_shape, device).to(device)\n            self.critic = DeepCritic(self.state_shape, self.critic_shape, device).to(device)\n        else:  # Input is a (single dimensional) vector\n            if self.continuous_action_space:\n                #self.actor_critic = ShallowActorCritic(self.state_shape, self.action_shape, 1, self.params).to(device)\n                self.actor = ShallowActor(self.state_shape, self.action_shape, device).to(device)\n            else:  # Discrete action space\n                self.actor = ShallowDiscreteActor(self.state_shape, self.action_shape, device).to(device)\n            self.critic = ShallowCritic(self.state_shape, self.critic_shape, device).to(device)\n        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=self.params[""learning_rate""])\n        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=self.params[""learning_rate""])\n\n        # Handle loading and saving of trained Agent models\n        episode_rewards = list()\n        prev_checkpoint_mean_ep_rew = self.best_mean_reward\n        num_improved_episodes_before_checkpoint = 0  # To keep track of the num of ep with higher perf to save model\n        #print(""Using agent_params:"", self.params)\n        if self.params[\'load_trained_model\']:\n            try:\n                self.load()\n                prev_checkpoint_mean_ep_rew = self.best_mean_reward\n            except FileNotFoundError:\n                if args.test:  # Test a saved model\n                    print(""FATAL: No saved model found. Cannot test. Press any key to train from scratch"")\n                    input()\n                else:\n                    print(""WARNING: No trained model found for this environment. Training from scratch."")\n\n        #for episode in range(self.params[""max_num_episodes""]):\n        obs = self.envs.reset()\n        # TODO: Create appropriate masks to take care of envs that have set dones to True & learn() accordingly\n        episode = 0\n        cum_step_rewards = np.zeros(self.params[""num_agents""])\n        episode_rewards = []\n        step_num = 0\n        while True:\n            action = self.get_action(obs)\n            next_obs, rewards, dones, _ = self.envs.step(action)\n            self.rewards.append(torch.tensor(rewards))\n            done_env_idxs = np.where(dones)[0]\n            cum_step_rewards += rewards  # nd-array of shape=num_actors\n\n            step_num += self.params[""num_agents""]\n            episode += done_env_idxs.size  # Update the number of finished episodes\n            if not args.test and (step_num >= self.params[""learning_step_thresh""] or done_env_idxs.size):\n                self.learn(next_obs, dones)\n                step_num = 0\n                # Monitor performance and save Agent\'s state when perf improves\n                if done_env_idxs.size > 0:\n                    [episode_rewards.append(r) for r in cum_step_rewards[done_env_idxs] ]\n                    if np.max(cum_step_rewards[done_env_idxs]) > self.best_reward:\n                        self.best_reward = np.max(cum_step_rewards[done_env_idxs])\n                    if np.mean(episode_rewards) > prev_checkpoint_mean_ep_rew:\n                        num_improved_episodes_before_checkpoint += 1\n                    if num_improved_episodes_before_checkpoint >= self.params[""save_freq_when_perf_improves""]:\n                        prev_checkpoint_mean_ep_rew = np.mean(episode_rewards)\n                        self.best_mean_reward = np.mean(episode_rewards)\n                        self.save()\n                        num_improved_episodes_before_checkpoint = 0\n\n                    writer.add_scalar(self.actor_name + ""/mean_ep_rew"", np.mean(cum_step_rewards[done_env_idxs]),\n                                      self.global_step_num)\n                    # Reset the cum_step_rew for the done envs\n                    cum_step_rewards[done_env_idxs] = 0.0\n\n            obs = next_obs\n            self.global_step_num += self.params[""num_agents""]\n            if args.render:\n                self.envs.render()\n            #print(self.actor_name + "":Episode#:"", episode, ""step#:"", step_num, ""\\t rew="", reward, end=""\\r"")\n            writer.add_scalar(self.actor_name + ""/reward"", np.mean(cum_step_rewards), self.global_step_num)\n            print(""{}:Episode#:{} \\t avg_step_reward:{:.4} \\t mean_ep_rew:{:.4}\\t best_ep_reward:{:.4}"".format(\n                self.actor_name, episode, np.mean(cum_step_rewards), np.mean(episode_rewards), self.best_reward))\n\n\nif __name__ == ""__main__"":\n    agent_params = params_manager.get_agent_params()\n    agent_params[""model_dir""] = args.model_dir\n    agent_params[""test""] = args.test\n    mp.set_start_method(\'spawn\')\n\n    env_names = [args.env] * agent_params[""num_agents""]\n\n    agent = DeepActorCriticAgent(0, env_names , agent_params)\n    agent.run()\n'"
ch9/run_roboschool_env.py,0,"b'#!/usr/bin/env/ python\n# Script to run a random-acting agent in Roboschool environments\n# Chapter 9, Hands-on Intelligent Agents with OpenAI Gym | Praveen Palanisamy\n\nfrom argparse import ArgumentParser\nfrom OpenGL import GLU  # Temporary fix for roboschool issue #8\nimport roboschool\nimport gym\n\nargparser = ArgumentParser()\nargparser.add_argument(""--env"",\n                       help=""Roboschool environment name. Default:RoboschoolInvertedPendulum-v1"",\n                       default=""RoboschoolInvertedPendulum-v1"")\nargs = argparser.parse_args()\n\nenv = gym.make(args.env)\nobs = env.reset()\nenv = gym.wrappers.Monitor(env, ""./roboschool_clips/"" + args.env,\n                           video_callable=lambda episode_id: True,\n                           force=True)  #Rewrite prev recorded files if present\nprint(""Observation Space:"", env.observation_space)\nprint(""Action Space:"", env.action_space)\n\nfor episode in range(3):  # Run 3 episode\n    done = False\n    obs = env.reset()\n    while not done:  # So that Monitor can record at least 3 episodes\n        _, _, done, _ = env.step(env.action_space.sample())\n        #env.render()\n'"
ch6/environment/__init__.py,0,b''
ch6/environment/atari.py,0,"b'#!/usr/bin/env python\nimport gym\nimport atari_py\nimport numpy as np\nfrom collections import deque\nfrom gym.spaces.box import Box\nimport cv2\nimport random\n\n\ndef make_env(env_id, env_conf):\n    env = gym.make(env_id)\n    if \'NoFrameskip\' in env_id:\n        assert \'NoFrameskip\' in env.spec.id\n        env = NoopResetEnv(env, noop_max=30)\n        env = MaxAndSkipEnv(env, skip=env_conf[\'skip_rate\'])\n\n    if env_conf[\'episodic_life\']:\n        env = EpisodicLifeEnv(env)\n\n    try:\n        if \'FIRE\' in env.unwrapped.get_action_meanings():\n            env = FireResetEnv(env)\n    except AttributeError:\n        pass\n\n    env = AtariRescale(env, env_conf[\'useful_region\'])\n\n    if env_conf[\'normalize_observation\']:\n        env = NormalizedEnv(env)\n\n    env = FrameStack(env, env_conf[\'num_frames_to_stack\'])\n\n    #if env_conf[\'clip_reward\']:  # Reward clipping is done by the agent using the agent\'s params\n    #    env = ClipRewardEnv(env)\n    return env\n\ndef get_games_list():\n    return atari_py.list_games()\n\n\nclass ClipRewardEnv(gym.RewardWrapper):\n    def __init__(self, env):\n        gym.RewardWrapper.__init__(self, env)\n\n    def reward(self, reward):\n        """""" Clip rewards to be either -1, 0 or +1 based on the sign""""""\n        return np.sign(reward)\n\n\ndef process_frame_84(frame, conf):\n    frame = frame[conf[""crop1""]:conf[""crop2""] + 160, :160]\n    frame = frame.mean(2)\n    #frame = frame.astype(np.float32)\n    #frame *= (1.0 / 255.0)\n    frame = cv2.resize(frame, (84, conf[""dimension2""]))\n    frame = cv2.resize(frame, (84, 84))\n    frame = np.reshape(frame, [1, 84, 84])\n    return frame\n\n\nclass AtariRescale(gym.ObservationWrapper):\n    def __init__(self, env, env_conf):\n        gym.ObservationWrapper.__init__(self, env)\n        self.observation_space = Box(0, 255, [1, 84, 84], dtype=np.uint8)\n        self.conf = env_conf\n\n    def observation(self, observation):\n        return process_frame_84(observation, self.conf)\n\n\nclass NormalizedEnv(gym.ObservationWrapper):\n    def __init__(self, env=None):\n        gym.ObservationWrapper.__init__(self, env)\n        self.state_mean = 0\n        self.state_std = 0\n        self.alpha = 0.9999\n        self.num_steps = 0\n\n    def observation(self, observation):\n        self.num_steps += 1\n        self.state_mean = self.state_mean * self.alpha + \\\n            observation.mean() * (1 - self.alpha)\n        self.state_std = self.state_std * self.alpha + \\\n            observation.std() * (1 - self.alpha)\n\n        unbiased_mean = self.state_mean / (1 - pow(self.alpha, self.num_steps))\n        unbiased_std = self.state_std / (1 - pow(self.alpha, self.num_steps))\n\n        return (observation - unbiased_mean) / (unbiased_std + 1e-8)\n\n\nclass NoopResetEnv(gym.Wrapper):\n    def __init__(self, env, noop_max=30):\n        """"""Sample initial states by taking random number of no-ops on reset.\n        No-op is assumed to be action 0.\n        """"""\n        gym.Wrapper.__init__(self, env)\n        self.noop_max = noop_max\n        self.noop_action = 0\n        assert env.unwrapped.get_action_meanings()[0] == \'NOOP\'\n\n    def reset(self):\n        """""" Do no-op action for a number of steps in [1, noop_max].""""""\n        self.env.reset()\n        noops = random.randrange(1, self.noop_max + 1)  # pylint: disable=E1101\n        assert noops > 0\n        obs = None\n        for _ in range(noops):\n            obs, _, done, _ = self.env.step(self.noop_action)\n        return obs\n\n    def step(self, ac):\n        return self.env.step(ac)\n\n\nclass FireResetEnv(gym.Wrapper):\n    def __init__(self, env):\n        """"""Take action on reset for environments that are fixed until firing.""""""\n        gym.Wrapper.__init__(self, env)\n        assert env.unwrapped.get_action_meanings()[1] == \'FIRE\'\n        assert len(env.unwrapped.get_action_meanings()) >= 3\n\n    def reset(self):\n        self.env.reset()\n        obs, _, done, _ = self.env.step(1)\n        if done:\n            self.env.reset()\n        obs, _, done, _ = self.env.step(2)\n        if done:\n            self.env.reset()\n        return obs\n\n    def step(self, ac):\n        return self.env.step(ac)\n\n\nclass EpisodicLifeEnv(gym.Wrapper):\n    def __init__(self, env):\n        """"""Make end-of-life == end-of-episode, but only reset on true game over.\n        Done by DeepMind for the DQN and co. since it helps value estimation.\n        """"""\n        gym.Wrapper.__init__(self, env)\n        self.lives = 0\n        self.was_real_done = True\n\n    def step(self, action):\n        obs, reward, done, info = self.env.step(action)\n        self.was_real_done = True\n        # check current lives, make loss of life terminal,\n        # then update lives to handle bonus lives\n        lives = info[\'ale.lives\']\n        if lives < self.lives and lives > 0:\n            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n            # so its important to keep lives > 0, so that we only reset once\n            # the environment advertises done.\n            done = True\n            self.was_real_done = False\n        self.lives = lives\n        return obs, reward, done, info\n\n    def reset(self):\n        """"""Reset only when lives are exhausted.\n        This way all states are still reachable even though lives are episodic,\n        and the learner need not know about any of this behind-the-scenes.\n        """"""\n        if self.was_real_done:\n            obs = self.env.reset()\n            self.lives = 0\n        else:\n            # no-op step to advance from terminal/lost life state\n            obs, _, _, info = self.env.step(0)\n            self.lives = info[\'ale.lives\']\n        return obs\n\n\nclass MaxAndSkipEnv(gym.Wrapper):\n    def __init__(self, env=None, skip=4):\n        """"""Return only every `skip`-th frame""""""\n        gym.Wrapper.__init__(self, env)\n        # most recent raw observations (for max pooling across time steps)\n        self._obs_buffer = deque(maxlen=2)\n        self._skip = skip\n\n    def step(self, action):\n        total_reward = 0.0\n        done = None\n        for _ in range(self._skip):\n            obs, reward, done, info = self.env.step(action)\n            self._obs_buffer.append(obs)\n            total_reward += reward\n            if done:\n                break\n\n        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n        return max_frame, total_reward, done, info\n\n    def reset(self):\n        """"""Clear past frame buffer and init. to first obs. from inner env.""""""\n        self._obs_buffer.clear()\n        obs = self.env.reset()\n        self._obs_buffer.append(obs)\n        return obs\n\n\nclass FrameStack(gym.Wrapper):\n    def __init__(self, env, k):\n        """"""Stack k last frames.\n\n        Returns lazy array, which is much more memory efficient.\n        From baselines atari_wrapper\n        """"""\n        gym.Wrapper.__init__(self, env)\n        self.k = k\n        self.frames = deque([], maxlen=k)\n        shp = env.observation_space.shape\n        self.observation_space = Box(low=0, high=255, shape=(shp[0] * k , shp[1], shp[2]), dtype=np.uint8)\n\n    def reset(self):\n        ob = self.env.reset()\n        for _ in range(self.k):\n            self.frames.append(ob)\n        return self._get_ob()\n\n    def step(self, action):\n        ob, reward, done, info = self.env.step(action)\n        self.frames.append(ob)\n        return self._get_ob(), reward, done, info\n\n    def _get_ob(self):\n        assert len(self.frames) == self.k\n        return LazyFrames(list(self.frames))\n\n\nclass LazyFrames(object):\n    def __init__(self, frames):\n        """"""This object ensures that common frames between the observations are only stored once.\n        It exists purely to optimize memory usage which can be huge for DQN\'s 1M frames replay\n        buffers.\n        This object should only be converted to numpy array before being passed to the model.\n        """"""\n        self._frames = frames\n        self._out = None\n\n    def _force(self):\n        if self._out is None:\n            self._out = np.concatenate(self._frames, axis=0)\n            self._frames = None\n        return self._out\n\n    def __array__(self, dtype=None):\n        out = self._force()\n        if dtype is not None:\n            out = out.astype(dtype)\n        return out\n\n    def __len__(self):\n        return len(self._force())\n\n    def __getitem__(self, i):\n        return self._force()[i]\n'"
ch6/environment/utils.py,0,"b""import gym\nimport cv2\nimport numpy as np\n\n\nclass ResizeReshapeFrames(gym.ObservationWrapper):\n    def __init__(self, env):\n        super(ResizeReshapeFrames, self).__init__(env)\n        if len(self.observation_space.shape) == 3:  #  If observations are image frames\n            self.desired_width = 84\n            self.desired_height = 84\n            self.desired_channels = self.observation_space.shape[2]\n            # Convert the space to C x H x W format (as per PyTorch's convention)\n            self.observation_space = gym.spaces.Box(0, 255, (self.desired_channels, self.desired_height,\n                                                             self.desired_width), dtype=np.uint8)\n\n\n    def observation(self, obs):\n        if len(obs.shape) == 3:\n            obs = cv2.resize(obs, (self.desired_width, self.desired_height))\n            if obs.shape[2] < obs.shape[0]:\n                obs = np.reshape(obs, (obs.shape[2], obs.shape[1], obs.shape[0]))\n        return obs\n"""
ch6/function_approximator/__init__.py,0,b''
ch6/function_approximator/cnn.py,13,"b'# CNN implemented using PyTorch for Q function approximation | Praveen Palanisamy\n# Chapter 6, Hands-on Intelligent Agents with OpenAI Gym, 2018\nimport torch\n\n\nclass CNN(torch.nn.Module):\n    def __init__(self, input_shape, output_shape, device=torch.device(""cpu"")):\n        """"""\n        A Convolution Neural Network (CNN) class to approximate functions with visual/image inputs\n\n        :param input_shape:  Shape/dimension of the input image. Assumed to be resized to C x 84 x 84\n        :param output_shape: Shape/dimension of the output.\n        :param device: The device (cpu or cuda) that the CNN should use to store the inputs for the forward pass\n        """"""\n        #  input_shape: C x 84 x 84\n        super(CNN, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4, padding=0),\n            torch.nn.ReLU()\n        )\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0),\n            torch.nn.ReLU()\n        )\n        self.layer3 = torch.nn.Sequential(\n            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n            torch.nn.ReLU()\n        )\n        self.out = torch.nn.Linear(64 * 7 * 7, output_shape)\n\n    def forward(self, x):\n        x = torch.from_numpy(x).float().to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = x.view(x.shape[0], -1)\n        x = self.out(x)\n        return x'"
ch6/function_approximator/perceptron.py,6,"b'import torch\n\n\nclass SLP(torch.nn.Module):\n    """"""\n    A Single Layer Perceptron (SLP) class to approximate functions\n    """"""\n    def __init__(self, input_shape, output_shape, device=torch.device(""cpu"")):\n        """"""\n        :param input_shape: Shape/dimension of the input\n        :param output_shape: Shape/dimension of the output\n        :param device: The device (cpu or cuda) that the SLP should use to store the inputs for the forward pass\n        """"""\n        super(SLP, self).__init__()\n        self.device = device\n        self.input_shape = input_shape[0]\n        self.hidden_shape = 40\n        self.linear1 = torch.nn.Linear(self.input_shape, self.hidden_shape)\n        self.out = torch.nn.Linear(self.hidden_shape, output_shape)\n\n    def forward(self, x):\n        x = torch.from_numpy(x).float().to(self.device)\n        x = torch.nn.functional.relu(self.linear1(x))\n        x = self.out(x)\n        return x'"
ch6/utils/decay_schedule.py,0,"b'#!/usr/bin/env python\n\nclass LinearDecaySchedule(object):\n    def __init__(self, initial_value, final_value, max_steps):\n        assert initial_value > final_value, ""initial_value should be > final_value""\n        self.initial_value = initial_value\n        self.final_value = final_value\n        self.decay_factor = (initial_value - final_value) / max_steps\n\n    def __call__(self, step_num):\n        current_value = self.initial_value - self.decay_factor * step_num\n        if current_value < self.final_value:\n            current_value = self.final_value\n        return current_value\n\nif __name__ == ""__main__"":\n    import matplotlib.pyplot as plt\n    epsilon_initial = 1.0\n    epsilon_final = 0.05\n    MAX_NUM_EPISODES = 10000\n    MAX_STEPS_PER_EPISODE = 300\n    linear_sched = LinearDecaySchedule(initial_value = epsilon_initial,\n                                    final_value = epsilon_final,\n                                    max_steps = MAX_NUM_EPISODES * MAX_STEPS_PER_EPISODE)\n    epsilon = [linear_sched(step) for step in range(MAX_NUM_EPISODES * MAX_STEPS_PER_EPISODE)]\n    plt.plot(epsilon)\n    plt.show()\n'"
ch6/utils/experience_memory.py,0,"b'#!/usr/bin/env python\nfrom collections import namedtuple\nimport random\n\nExperience = namedtuple(""Experience"", [\'obs\', \'action\', \'reward\', \'next_obs\',\n                                       \'done\'])\n\n\nclass ExperienceMemory(object):\n    """"""\n    A cyclic/ring buffer based Experience Memory implementation\n    """"""\n    def __init__(self, capacity=int(1e6)):\n        """"""\n\n        :param capacity: Total capacity (Max number of Experiences)\n        :return:\n        """"""\n        self.capacity = capacity\n        self.mem_idx = 0  # Index of the current experience\n        self.memory = []\n\n    def store(self, experience):\n        """"""\n\n        :param experience: The Experience object to be stored into the memory\n        :return:\n        """"""\n        if self.mem_idx < self.capacity:\n            # Extend the memory and create space\n            self.memory.append(None)\n        self.memory[self.mem_idx % self.capacity] = experience\n        self.mem_idx += 1\n\n    def sample(self, batch_size):\n        """"""\n\n        :param batch_size:  Sample batch_size\n        :return: A list of batch_size number of Experiences sampled at random from mem\n        """"""\n        assert batch_size <= len(self.memory), ""Sample batch_size is more than available exp in mem""\n        return random.sample(self.memory, batch_size)\n\n    def get_size(self):\n        """"""\n\n        :return: Number of Experiences stored in the memory\n        """"""\n        return len(self.memory)\n'"
ch6/utils/params_manager.py,0,"b'#!/usr/bin/env python\nimport json\n\nclass ParamsManager(object):\n    def __init__(self, params_file):\n        """"""\n        A class to manage the Parameters. Parameters include configuration parameters and Hyper-parameters\n        :param params_file: Path to the parameters json file\n        """"""\n        self.params = json.load(open(params_file, \'r\'))\n    def get_params(self):\n        """"""\n        Returns all the parameters\n        :return: The whole parameter dictionary\n        """"""\n        return self.params\n    def get_env_params(self):\n        """"""\n        Returns the environment configuration parameters\n        :return: A dictionary of configuration parameters used for the environment\n        """"""\n        return self.params[\'env\']\n    def get_agent_params(self):\n        """"""\n        Returns the hyper-parameters and configuration parameters used by the agent\n        :return: A dictionary of parameters used by the agent\n        """"""\n        return self.params[\'agent\']\n    def update_agent_params(self, **kwargs):\n        """"""\n        Update the hyper-parameters (and configuration parameters) used by the agent\n        :param kwargs:  Comma-separated, hyper-parameter-key=value pairs. Eg.: lr=0.005, gamma=0.98\n        :return: None\n        """"""\n        for key, value in kwargs.items():\n            if key in self.params[\'agent\'].keys():\n                self.params[\'agent\'][key] = value\n    def export_env_params(self, file_name):\n        """"""\n        Export the environment parameters to the specified file. Useful for logging experiment specific parameters\n        :param file_name: Name of the file to write the environment parameters to\n        :return:\n        """"""\n        with open(file_name, \'w\') as f:\n            json.dump(self.params[\'env\'], f, indent=4, separators=(\',\',\': \'), sort_keys=True)\n            # Adding a trailing newline for POSIX compatibility\n            f.write(""\\n"")\n\n    def export_agent_params(self, file_name):\n        """"""\n        Export the agent parameters to the specified file. Useful for logging experiment specific parameters.\n        :param file_name: Name of the file to write the agent parameters to\n        :return:\n        """"""\n        with open(file_name, \'w\') as f:\n            json.dump(self.params[\'agent\'], f, indent=4, separators=(\',\', \': \'), sort_keys=True)\n            # Adding a trailing newline for POSIX compatibility\n            f.write(""\\n"")\n\n\nif __name__ == ""__main__"":\n    print(""Testing ParamsManager..."")\n    param_file = ""parameters.json""\n    params_manager = ParamsManager(param_file)\n    agent_params = params_manager.get_agent_params()\n    print(""Agent params:"")\n    for k, v in agent_params.items():\n        print(k, "":"", v)\n    env_params = params_manager.get_env_params()\n    print(""Environment parameters:"")\n    for k, v in env_params.items():\n        print(k, "":"", v)\n    params_manager.update_agent_params(lr=0.01, gamma=0.95)\n    updated_agent_params = params_manager.get_agent_params()\n    print(""Updated Agent params:"")\n    for k, v in updated_agent_params.items():\n        print(k, "":"", v)\n\n    print(""ParamsManager test completed."")\n'"
ch6/utils/weights_initializer.py,3,"b'import torch\n\ndef xavier(m):\n    """"""\n    Initialize weights of the network using method described in Xavier Glorot, Yoshua Bengio, ""Understanding the\n    difficulty of trianing deep feedforward neural networks"". Expected to be supplied to the `apply(...)` method on\n    an instance of torch.nn.Module to be recursively applied to each module/layer present in the neural network.\n    :param self:\n    :param m: nn.Module\n    :return:\n    """"""\n    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n        torch.nn.init.xavier_normal_(m.weight)\n'"
ch8/environment/__init__.py,0,b''
ch8/environment/atari.py,0,"b'#!/usr/bin/env python\n# Atari environment wrappers and utility functions | Praveen Palanisamy\n# based on OpenAI\'s implementation\n# Chapter 8, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport gym\nimport atari_py\nimport numpy as np\nfrom collections import deque\nfrom gym.spaces.box import Box\nimport cv2\nimport random\n\n\ndef make_env(env_id, env_conf):\n    env = gym.make(env_id)\n    if \'NoFrameskip\' in env_id:\n        assert \'NoFrameskip\' in env.spec.id\n        env = NoopResetEnv(env, noop_max=30)\n        env = MaxAndSkipEnv(env, skip=env_conf[\'skip_rate\'])\n\n    if env_conf[\'episodic_life\']:\n        env = EpisodicLifeEnv(env)\n\n    try:\n        if \'FIRE\' in env.unwrapped.get_action_meanings():\n            env = FireResetEnv(env)\n    except AttributeError:\n        pass\n\n    env = AtariRescale(env, env_conf[\'useful_region\'])\n\n    if env_conf[\'normalize_observation\']:\n        env = NormalizedEnv(env)\n\n    env = FrameStack(env, env_conf[\'num_frames_to_stack\'])\n\n    #if env_conf[\'clip_reward\']:  # Reward clipping is done by the agent using the agent\'s params\n    #    env = ClipRewardEnv(env)\n    return env\n\ndef get_games_list():\n    return atari_py.list_games()\n\n\nclass ClipRewardEnv(gym.RewardWrapper):\n    def __init__(self, env):\n        gym.RewardWrapper.__init__(self, env)\n\n    def reward(self, reward):\n        """""" Clip rewards to be either -1, 0 or +1 based on the sign""""""\n        return np.sign(reward)\n\n\ndef process_frame_84(frame, conf):\n    frame = frame[conf[""crop1""]:conf[""crop2""] + 160, :160]\n    frame = frame.mean(2)\n    #frame = frame.astype(np.float32)\n    #frame *= (1.0 / 255.0)\n    frame = cv2.resize(frame, (84, conf[""dimension2""]))\n    frame = cv2.resize(frame, (84, 84))\n    frame = np.reshape(frame, [1, 84, 84])\n    return frame\n\n\nclass AtariRescale(gym.ObservationWrapper):\n    def __init__(self, env, env_conf):\n        gym.ObservationWrapper.__init__(self, env)\n        self.observation_space = Box(0, 255, [1, 84, 84], dtype=np.uint8)\n        self.conf = env_conf\n\n    def observation(self, observation):\n        return process_frame_84(observation, self.conf)\n\n\nclass NormalizedEnv(gym.ObservationWrapper):\n    def __init__(self, env=None):\n        gym.ObservationWrapper.__init__(self, env)\n        self.state_mean = 0\n        self.state_std = 0\n        self.alpha = 0.9999\n        self.num_steps = 0\n\n    def observation(self, observation):\n        self.num_steps += 1\n        self.state_mean = self.state_mean * self.alpha + \\\n            observation.mean() * (1 - self.alpha)\n        self.state_std = self.state_std * self.alpha + \\\n            observation.std() * (1 - self.alpha)\n\n        unbiased_mean = self.state_mean / (1 - pow(self.alpha, self.num_steps))\n        unbiased_std = self.state_std / (1 - pow(self.alpha, self.num_steps))\n\n        return (observation - unbiased_mean) / (unbiased_std + 1e-8)\n\n\nclass NoopResetEnv(gym.Wrapper):\n    def __init__(self, env, noop_max=30):\n        """"""Sample initial states by taking random number of no-ops on reset.\n        No-op is assumed to be action 0.\n        """"""\n        gym.Wrapper.__init__(self, env)\n        self.noop_max = noop_max\n        self.noop_action = 0\n        assert env.unwrapped.get_action_meanings()[0] == \'NOOP\'\n\n    def reset(self):\n        """""" Do no-op action for a number of steps in [1, noop_max].""""""\n        self.env.reset()\n        noops = random.randrange(1, self.noop_max + 1)  # pylint: disable=E1101\n        assert noops > 0\n        obs = None\n        for _ in range(noops):\n            obs, _, done, _ = self.env.step(self.noop_action)\n        return obs\n\n    def step(self, ac):\n        return self.env.step(ac)\n\n\nclass FireResetEnv(gym.Wrapper):\n    def __init__(self, env):\n        """"""Take action on reset for environments that are fixed until firing.""""""\n        gym.Wrapper.__init__(self, env)\n        assert env.unwrapped.get_action_meanings()[1] == \'FIRE\'\n        assert len(env.unwrapped.get_action_meanings()) >= 3\n\n    def reset(self):\n        self.env.reset()\n        obs, _, done, _ = self.env.step(1)\n        if done:\n            self.env.reset()\n        obs, _, done, _ = self.env.step(2)\n        if done:\n            self.env.reset()\n        return obs\n\n    def step(self, ac):\n        return self.env.step(ac)\n\n\nclass EpisodicLifeEnv(gym.Wrapper):\n    def __init__(self, env):\n        """"""Make end-of-life == end-of-episode, but only reset on true game over.\n        Done by DeepMind for the DQN and co. since it helps value estimation.\n        """"""\n        gym.Wrapper.__init__(self, env)\n        self.lives = 0\n        self.was_real_done = True\n\n    def step(self, action):\n        obs, reward, done, info = self.env.step(action)\n        self.was_real_done = True\n        # check current lives, make loss of life terminal,\n        # then update lives to handle bonus lives\n        lives = info[\'ale.lives\']\n        if lives < self.lives and lives > 0:\n            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n            # so its important to keep lives > 0, so that we only reset once\n            # the environment advertises done.\n            done = True\n            self.was_real_done = False\n        self.lives = lives\n        return obs, reward, done, info\n\n    def reset(self):\n        """"""Reset only when lives are exhausted.\n        This way all states are still reachable even though lives are episodic,\n        and the learner need not know about any of this behind-the-scenes.\n        """"""\n        if self.was_real_done:\n            obs = self.env.reset()\n            self.lives = 0\n        else:\n            # no-op step to advance from terminal/lost life state\n            obs, _, _, info = self.env.step(0)\n            self.lives = info[\'ale.lives\']\n        return obs\n\n\nclass MaxAndSkipEnv(gym.Wrapper):\n    def __init__(self, env=None, skip=4):\n        """"""Return only every `skip`-th frame""""""\n        gym.Wrapper.__init__(self, env)\n        # most recent raw observations (for max pooling across time steps)\n        self._obs_buffer = deque(maxlen=2)\n        self._skip = skip\n\n    def step(self, action):\n        total_reward = 0.0\n        done = None\n        for _ in range(self._skip):\n            obs, reward, done, info = self.env.step(action)\n            self._obs_buffer.append(obs)\n            total_reward += reward\n            if done:\n                break\n\n        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n        return max_frame, total_reward, done, info\n\n    def reset(self):\n        """"""Clear past frame buffer and init. to first obs. from inner env.""""""\n        self._obs_buffer.clear()\n        obs = self.env.reset()\n        self._obs_buffer.append(obs)\n        return obs\n\n\nclass FrameStack(gym.Wrapper):\n    def __init__(self, env, k):\n        """"""Stack k last frames.\n\n        Returns lazy array, which is much more memory efficient.\n        From baselines atari_wrapper\n        """"""\n        gym.Wrapper.__init__(self, env)\n        self.k = k\n        self.frames = deque([], maxlen=k)\n        shp = env.observation_space.shape\n        self.observation_space = Box(low=0, high=255, shape=(shp[0] * k , shp[1], shp[2]), dtype=np.uint8)\n\n    def reset(self):\n        ob = self.env.reset()\n        for _ in range(self.k):\n            self.frames.append(ob)\n        return self._get_ob()\n\n    def step(self, action):\n        ob, reward, done, info = self.env.step(action)\n        self.frames.append(ob)\n        return self._get_ob(), reward, done, info\n\n    def _get_ob(self):\n        assert len(self.frames) == self.k\n        return LazyFrames(list(self.frames))\n\n\nclass LazyFrames(object):\n    def __init__(self, frames):\n        """"""This object ensures that common frames between the observations are only stored once.\n        It exists purely to optimize memory usage which can be huge for DQN\'s 1M frames replay\n        buffers.\n        This object should only be converted to numpy array before being passed to the model.\n        """"""\n        self._frames = frames\n        self._out = None\n\n    def _force(self):\n        if self._out is None:\n            self._out = np.concatenate(self._frames, axis=0)\n            self._frames = None\n        return self._out\n\n    def __array__(self, dtype=None):\n        out = self._force()\n        if dtype is not None:\n            out = out.astype(dtype)\n        return out\n\n    def __len__(self):\n        return len(self._force())\n\n    def __getitem__(self, i):\n        return self._force()[i]\n'"
ch8/environment/utils.py,0,"b'#!/usr/bin/env python\n# Vectorized environment implementation based on OpenAI Gym| Praveen Palanisamy\n# Chapter 8, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport multiprocessing as mp\nimport gym\nfrom abc import ABC, abstractmethod\nimport numpy as np\nimport cv2\n\nclass VecEnv(ABC):\n    """"""\n    An abstract asynchronous, vectorized environment.\n    """"""\n    def __init__(self, num_envs, observation_space, action_space):\n        self.num_envs = num_envs\n        self.observation_space = observation_space\n        self.action_space = action_space\n\n    @abstractmethod\n    def reset(self):\n        """"""\n        Reset all the environments and return an array of\n        observations, or a tuple of observation arrays.\n\n        If step_async is still doing work, that work will\n        be cancelled and step_wait() should not be called\n        until step_async() is invoked again.\n        """"""\n        pass\n\n    @abstractmethod\n    def step_async(self, actions):\n        """"""\n        Tell all the environments to start taking a step\n        with the given actions.\n        Call step_wait() to get the results of the step.\n\n        You should not call this if a step_async run is\n        already pending.\n        """"""\n        pass\n\n    @abstractmethod\n    def step_wait(self):\n        """"""\n        Wait for the step taken with step_async().\n\n        Returns (obs, rews, dones, infos):\n         - obs: an array of observations, or a tuple of\n                arrays of observations.\n         - rews: an array of rewards\n         - dones: an array of ""episode done"" booleans\n         - infos: a sequence of info objects\n        """"""\n        pass\n\n    @abstractmethod\n    def close(self):\n        """"""\n        Clean up the environments\' resources.\n        """"""\n        pass\n\n    def step(self, actions):\n        self.step_async(actions)\n        return self.step_wait()\n\n    def render(self):\n        print(\'WARNING:Render not defined for %s\'%self)\n\n    @property\n    def unwrapped(self):\n        return self\n\n\nclass ResizeFrame(gym.ObservationWrapper):\n    def __init__(self,env):\n        gym.ObservationWrapper.__init__(self, env)\n        self.desired_width = 84  # Change this as necessary. 84 is not a magic number.\n        self.desired_height = 84\n    def observation(self, obs):\n        if len(obs.shape) == 3:  # Observations are image frames\n            obs = cv2.resize(obs, (self.desired_width, self.desired_height))\n        return obs\n\ndef run_env_in_sep_proc(env_name, shared_pipe, parent_pipe, stack=False, scale_rew=False):\n    """"""\n    Create and run an environment instance (remote or local) in a separate proc\n    """"""\n    parent_pipe.close()\n\n    env = gym.make(env_name)\n    # Apply env pre-processing here if needed\n    #if scale_rew:\n    #    env = RewardScaler(env)\n    #env = CustomWarpFrame(env)\n    #env = NormalizedEnv(env)\n    env = ResizeFrame(env)\n\n    while True:\n        method, data = shared_pipe.recv()\n        if method == \'step\':\n            next_obs, rew, done, info = env.step(data)\n            if done:\n                next_obs = env.reset()\n            shared_pipe.send((next_obs, rew, done, info))\n\n        if method == \'reset\':\n            obs = env.reset()\n            shared_pipe.send(obs)\n\n        if method == \'get_spaces\':\n            shared_pipe.send((env.observation_space, env.action_space))\n\nclass SubprocVecEnv(VecEnv):\n    def __init__(self, env_names, spaces=None):\n        """"""\n        env_names: list of (gym) environments to run in sub/separate processes\n        """"""\n        self.waiting = False\n        self.closed = False\n        num_envs = len(env_names)\n        self.remotes, self.work_remotes = zip(*[mp.Pipe() for _ in range(num_envs)])\n        self.ps = []\n        for (env_name, worker_conn, parent_conn) in zip(env_names, self.work_remotes, self.remotes):\n            self.ps.append(mp.Process(target=run_env_in_sep_proc, args=(env_name, worker_conn, parent_conn)))\n        for p in self.ps:\n            p.daemon = True # if the main process crashes, we should not cause things to hang\n            p.start()\n\n        for remote in self.work_remotes:\n            remote.close()\n\n        self.remotes[0].send((\'get_spaces\', None))\n        observation_space, action_space = self.remotes[0].recv()\n        VecEnv.__init__(self, num_envs, observation_space, action_space)\n\n    def step_async(self, actions):\n        for remote, action in zip(self.remotes, actions):\n            remote.send((\'step\', action))\n        self.waiting = True\n\n    def step_wait(self):\n        results = [remote.recv() for remote in self.remotes]\n        self.waiting = False\n        obs, rews, dones, infos = zip(*results)\n        return np.stack(obs), np.stack(rews), np.stack(dones), infos\n\n    def reset(self):\n        for remote in self.remotes:\n            remote.send((\'reset\', None))\n        return np.stack([remote.recv() for remote in self.remotes])\n\n    def close(self):\n        if self.closed:\n            return\n        if self.waiting:\n            for remote in self.remotes:\n                remote.recv()\n        for remote in self.remotes:\n            remote.send((\'close\', None))\n        for p in self.ps:\n            p.join()\n        self.closed = True\n\n\nclass EnvProc(mp.Process):\n    def __init__(self, env_name, requests):\n        super(EnvProc, self).__init__()\n        self.env_name = env_name\n        self.requests= requests\n        self.terminate = False\n\n    def run(self):\n        self.env = gym.make(self.env_name)\n        while not self.terminate:\n            #while not self.request_queue.empty() or self.request_queue.qsize():\n            request = self.requests.recv()\n            result = self.call_env(request[""method""], request[""data""])\n            self.requests.send(result)\n\n    def call_env(self, method, data):\n        if method == ""step"":\n            next_obs, reward, done, info = self.env.step(data)\n            return (next_obs, reward, done, info)\n        elif method == ""reset"":\n            obs = self.env.reset()\n            return obs\n        elif method == ""render"":\n            self.env.render()\n        elif method == ""observation_space"":\n            return self.env.observation_space\n        elif method == ""action_space"":\n            return self.env.action_space\n        elif method == ""close"":\n            self.env.close()\n            self.terminate = True\n\n\nclass EnvProxy(object):\n    def __init__(self, env_name):\n        self.pipe, self.child_pipe = mp.Pipe()\n        self.env_proc = EnvProc(env_name, self.child_pipe)\n        self.env_proc.start()\n    def step(self, action):\n        self.pipe.send({""method"": ""step"", ""data"": action})\n        return self.pipe.recv()\n    def reset(self):\n        self.pipe.send({""method"": ""reset"", ""data"": None})\n        return self.pipe.recv()\n    def render(self):\n        self.pipe.send({""method"": ""render"", ""data"": None})\n    @property\n    def observation_space(self):\n        self.pipe.send({""method"": ""observation_space"", ""data"": None})\n        return self.pipe.recv()\n    @property\n    def action_space(self):\n        self.pipe.send({""method"": ""action_space"", ""data"": None})\n        return self.pipe.recv()\n    def close(self):\n        self.pipe.send({""method"": ""close"", ""data"": None})\n        self.env_proc.join()\n\n\ndef make_env(env_name):\n    env_proxy= EnvProxy(env_name)\n    return env_proxy\n'"
ch8/function_approximator/__init__.py,0,b''
ch8/function_approximator/deep.py,51,"b'# Actor-Critic deep neural networks implemented in PyTorch | Praveen Palanisamy\n# Chapter 8, Hands-on Intelligent Agents with OpenAI Gym, 2018\nimport torch\n\n\nclass Actor(torch.nn.Module):\n    def __init__(self, input_shape, actor_shape, device=torch.device(""cpu"")):\n        """"""\n        Deep convolutional Neural Network to represent Actor in an Actor-Critic algorithm\n        The Policy is parametrized using a Gaussian distribution with mean mu and variance sigma\n        The Actor\'s policy parameters (mu, sigma) are output by the deep CNN implemented\n        in this class.\n        :param input_shape: Shape of each of the observations\n        :param actor_shape: Shape of the actor\'s output. Typically the shape of the actions\n        :param device: The torch.device (cpu or cuda) where the inputs and the parameters are to be stored and operated\n        """"""\n        super(Actor, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(input_shape[2], 32, 8, stride=4, padding=0),\n                                          torch.nn.ReLU())\n        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, 3, stride=2, padding=0),\n                                          torch.nn.ReLU())\n        self.layer3 = torch.nn.Sequential(torch.nn.Conv2d(64, 64, 3, stride=1, padding=0),\n                                          torch.nn.ReLU())\n        self.layer4 = torch.nn.Sequential(torch.nn.Linear(64 * 7 * 7, 512),\n                                          torch.nn.ReLU())\n        self.actor_mu = torch.nn.Linear(512, actor_shape)\n        self.actor_sigma = torch.nn.Linear(512, actor_shape)\n\n    def forward(self, x):\n        """"""\n        Forward pass through the Actor network. Takes batch_size x observations as input and produces mu and sigma\n        as the outputs\n        :param x: The observations\n        :return: Mean (mu) and Sigma (sigma) for a Gaussian policy\n        """"""\n        x.requires_grad_()\n        x = x.to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = x.view(x.shape[0], -1)\n        x = self.layer4(x)\n        actor_mu = self.actor_mu(x)\n        actor_sigma = self.actor_sigma(x)\n        return actor_mu, actor_sigma\n\n\nclass DiscreteActor(torch.nn.Module):\n    def __init__(self, input_shape, actor_shape, device=torch.device(""cpu"")):\n        """"""\n        Deep convolutional Neural Network to represent Actor in an Actor-Critic algorithm\n        The Policy is parametrized using a categorical/discrete distribution with logits\n        The Actor\'s policy parameters (logits) are output by the deep CNN implemented\n        in this class.\n        :param input_shape: Shape of each of the observations\n        :param actor_shape: Shape of the actor\'s output. Typically the shape of the actions\n        :param device: The torch.device (cpu or cuda) where the inputs and the parameters are to be stored and operated\n        """"""\n        super(DiscreteActor, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(input_shape[2], 32, 8, stride=4, padding=0),\n                                          torch.nn.ReLU())\n        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, 3, stride=2, padding=0),\n                                          torch.nn.ReLU())\n        self.layer3 = torch.nn.Sequential(torch.nn.Conv2d(64, 64, 3, stride=1, padding=0),\n                                          torch.nn.ReLU())\n        self.layer4 = torch.nn.Sequential(torch.nn.Linear(64 * 7 * 7, 512),\n                                          torch.nn.ReLU())\n        self.logits = torch.nn.Linear(512, actor_shape)\n\n    def forward(self, x):\n        """"""\n        Forward pass through the Actor network. Takes batch_size x observations as input and produces mu and sigma\n        as the outputs\n        :param x: The observations\n        :return: Mean (mu) and Sigma (sigma) for a Gaussian policy\n        """"""\n        x.requires_grad_()\n        x = x.to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = x.view(x.shape[0], -1)\n        x = self.layer4(x)\n        logits = self.logits(x)\n        return logits\n\n\nclass Critic(torch.nn.Module):\n    def __init__(self, input_shape, critic_shape=1, device=torch.device(""cpu"")):\n        """"""\n        Deep convolutional Neural Network to represent the Critic in an Actor-Critic algorithm\n        :param input_shape: Shape of each of the observations\n        :param critic_shape: Shape of the Critic\'s output. Typically 1\n        :param device: The torch.device (cpu or cuda) where the inputs and the parameters are to be stored and operated\n        """"""\n        super(Critic, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(input_shape[2], 32, 8, stride=4, padding=0),\n                                          torch.nn.ReLU())\n        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, 3, stride=2, padding=0),\n                                          torch.nn.ReLU())\n        self.layer3 = torch.nn.Sequential(torch.nn.Conv2d(64, 64, 3, stride=1, padding=0),\n                                          torch.nn.ReLU())\n        self.layer4 = torch.nn.Sequential(torch.nn.Linear(64* 7 * 7, 512),\n                                          torch.nn.ReLU())\n        self.critic = torch.nn.Linear(512, critic_shape)\n\n    def forward(self, x):\n        """"""\n        Forward pass through the Critic network. Takes batch_size x observations as input and produces the value\n        estimate as the output\n        :param x: The observations\n        :return: Mean (mu) and Sigma (sigma) for a Gaussian policy\n        """"""\n        x.requires_grad_()\n        x = x.to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = x.view(x.shape[0], -1)\n        x = self.layer4(x)\n        critic = self.critic(x)\n        return critic\n\n\nclass ActorCritic(torch.nn.Module):\n    def __init__(self, input_shape, actor_shape, critic_shape, device=torch.device(""cpu"")):\n        """"""\n        Deep convolutional Neural Network to represent both policy  (Actor) and a value function (Critic).\n        The Policy is parametrized using a Gaussian distribution with mean mu and variance sigma\n        The Actor\'s policy parameters (mu, sigma) and the Critic\'s Value (value) are output by the deep CNN implemented\n        in this class.\n        :param input_shape: Shape of each of the observations\n        :param actor_shape: Shape of the actor\'s output. Typically the shape of the actions\n        :param critic_shape: Shape of the Critic\'s output. Typically 1\n        :param device: The torch.device (cpu or cuda) where the inputs and the parameters are to be stored and operated\n        """"""\n        super(ActorCritic, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(input_shape[2], 32, 8, stride=4, padding=0),\n                                          torch.nn.ReLU())\n        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, 3, stride=2, padding=0),\n                                          torch.nn.ReLU())\n        self.layer3 = torch.nn.Sequential(torch.nn.Conv2d(64, 64, 3, stride=1, padding=0),\n                                          torch.nn.ReLU())\n        self.layer4 = torch.nn.Sequential(torch.nn.Linear(64* 7 * 7, 512),\n                                          torch.nn.ReLU())\n        self.actor_mu = torch.nn.Linear(512, actor_shape)\n        self.actor_sigma = torch.nn.Linear(512, actor_shape)\n        self.critic = torch.nn.Linear(512, critic_shape)\n\n    def forward(self, x):\n        """"""\n        Forward pass through the Actor-Critic network. Takes batch_size x observations as input and produces\n        mu, sigma and the value estimate\n        as the outputs\n        :param x: The observations\n        :return: Mean (actor_mu), Sigma (actor_sigma) for a Gaussian policy and the Critic\'s value estimate (critic)\n        """"""\n        x.requires_grad_()\n        x = x.to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = x.view(x.shape[0], -1)\n        x = self.layer4(x)\n        actor_mu = self.actor_mu(x)\n        actor_sigma = self.actor_sigma(x)\n        critic = self.critic(x)\n        return actor_mu, actor_sigma, critic\n'"
ch8/function_approximator/shallow.py,35,"b'# Actor-Critic neural networks implemented in PyTorch | Praveen Palanisamy\n# Chapter 8, Hands-on Intelligent Agents with OpenAI Gym, 2018\n\nimport torch\n\n\nclass Actor(torch.nn.Module):\n    def __init__(self, input_shape, output_shape, device=torch.device(""cpu"")):\n        """"""\n        A feed forward neural network that produces two continuous values mean (mu) and sigma, each of output_shape\n        . Used to represent the Actor in an Actor-Critic algorithm\n        :param input_shape: Shape of the inputs. This is typically the shape of each of the observations for the Actor\n        :param output_shape: Shape of the outputs. This is the shape of the actions that the Actor should produce\n        :param device: The torch.device (cpu or cuda) where the inputs and the parameters are to be stored and operated\n        """"""\n        super(Actor, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(torch.nn.Linear(input_shape[0], 64),\n                                          torch.nn.ReLU())\n        self.layer2 = torch.nn.Sequential(torch.nn.Linear(64, 32),\n                                          torch.nn.ReLU())\n        self.actor_mu = torch.nn.Linear(32, output_shape)\n        self.actor_sigma = torch.nn.Linear(32, output_shape)\n\n    def forward(self, x):\n        """"""\n        Forward pass through the Actor network. Takes batch_size x observations as input and produces mu and sigma\n        as the outputs\n        :param x: The observations\n        :return: Mean (mu) and Sigma (sigma) for a Gaussian policy\n        """"""\n        x = x.to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        mu = self.actor_mu(x)\n        sigma = self.actor_sigma(x)\n        return mu, sigma\n\n\nclass DiscreteActor(torch.nn.Module):\n    def __init__(self, input_shape, output_shape, device=torch.device(""cpu"")):\n        """"""\n        A feed forward neural network that produces a logit for each action in the action space.\n        Used to represent the Actor in an Actor-Critic algorithm\n        :param input_shape: Shape of the inputs. This is typically the shape of each of the observations for the Actor\n        :param output_shape: Shape of the outputs. This is the shape of the actions that the Actor should produce\n        :param device: The torch.device (cpu or cuda) where the inputs and the parameters are to be stored and operated\n        """"""\n        super(DiscreteActor, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(torch.nn.Linear(input_shape[0], 64),\n                                          torch.nn.ReLU())\n        self.layer2 = torch.nn.Sequential(torch.nn.Linear(64, 32),\n                                          torch.nn.ReLU())\n        self.logits = torch.nn.Linear(32, output_shape)\n\n    def forward(self, x):\n        """"""\n        Forward pass through the Actor network. Takes batch_size x observations as input and produces mu and sigma\n        as the outputs\n        :param x: The observations\n        :return: Mean (mu) and Sigma (sigma) for a Gaussian policy\n        """"""\n        x = x.to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        logits = self.logits(x)\n        return logits\n\n\nclass Critic(torch.nn.Module):\n    def __init__(self, input_shape, output_shape=1, device=torch.device(""cpu"")):\n        """"""\n        A feed forward neural network that produces a continuous value. Used to represent the Critic\n        in an Actor-Critic algorithm that estimates the value of the current observation/state\n        :param input_shape: Shape of the inputs. This is typically the shape of the observations for the Actor\n        :param output_shape: Shape of the output. This is most often 1 as the Critic is expected to produce a single\n        value given given an observation/state\n        :param device: The torch.device (cpu or cuda) where the inputs and the parameters are to be stored and operated\n        """"""\n        super(Critic, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(torch.nn.Linear(input_shape[0], 64),\n                                          torch.nn.ReLU())\n        self.layer2 = torch.nn.Sequential(torch.nn.Linear(64, 32),\n                                          torch.nn.ReLU())\n        self.critic= torch.nn.Linear(32, output_shape)\n\n    def forward(self, x):\n        """"""\n        Forward pass through the Critic network. Takes batch_size x observations as input and produces the value\n        estimate as the output\n        :param x: The observations\n        :return: Mean (mu) and Sigma (sigma) for a Gaussian policy\n        """"""\n        x = x.to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        critic = self.critic(x)\n        return critic\n\n\nclass ActorCritic(torch.nn.Module):\n    def __init__(self, input_shape, actor_shape, critic_shape, device=torch.device(""cpu"")):\n        """"""\n        A feed forward neural network used to represent both an Actor and the Critic in an Actor-Critic algorithm.\n        :param input_shape: Shape of the inputs. This is typically the shape of the observations\n        :param actor_shape: Shape of the actor outputs. This is the shape of the actions that the Actor should produce\n        :param critic_shape: Shape of the critic output. This is most often 1 as the Critic is expected to produce a\n        single value given given an observation/state\n        :param device: The torch.device (cpu or cuda) where the inputs and the parameters are to be stored and operated\n        """"""\n        super(ActorCritic, self).__init__()\n        self.device = device\n        self.layer1 = torch.nn.Sequential(torch.nn.Linear(input_shape[0], 32),\n                                          torch.nn.ReLU())\n        self.layer2 = torch.nn.Sequential(torch.nn.Linear(32, 16),\n                                          torch.nn.ReLU())\n        self.actor_mu = torch.nn.Linear(16, actor_shape)\n        self.actor_sigma = torch.nn.Linear(16, actor_shape)\n        self.critic = torch.nn.Linear(16, critic_shape)\n\n    def forward(self, x):\n        """"""\n        Forward pass through the Actor-Critic network. Takes batch_size x observations as input and produces\n        mu, sigma and the value estimate\n        as the outputs\n        :param x: The observations\n        :return: Mean (actor_mu), Sigma (actor_sigma) for a Gaussian policy and the Critic\'s value estimate (critic)\n        """"""\n        x.requires_grad_()\n        x = x.to(self.device)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        actor_mu = self.actor_mu(x)\n        actor_sigma = self.actor_sigma(x)\n        critic = self.critic(x)\n        return actor_mu, actor_sigma, critic\n\n'"
ch8/utils/params_manager.py,0,"b'#!/usr/bin/env python\nimport json\n\nclass ParamsManager(object):\n    def __init__(self, params_file):\n        """"""\n        A class to manage the Parameters. Parameters include configuration parameters and Hyper-parameters\n        :param params_file: Path to the parameters json file\n        """"""\n        self.params = json.load(open(params_file, \'r\'))\n    def get_params(self):\n        """"""\n        Returns all the parameters\n        :return: The whole parameter dictionary\n        """"""\n        return self.params\n    def get_env_params(self):\n        """"""\n        Returns the environment configuration parameters\n        :return: A dictionary of configuration parameters used for the environment\n        """"""\n        return self.params[\'env\']\n    def get_agent_params(self):\n        """"""\n        Returns the hyper-parameters and configuration parameters used by the agent\n        :return: A dictionary of parameters used by the agent\n        """"""\n        return self.params[\'agent\']\n    def update_agent_params(self, **kwargs):\n        """"""\n        Update the hyper-parameters (and configuration parameters) used by the agent\n        :param kwargs:  Comma-separated, hyper-parameter-key=value pairs. Eg.: lr=0.005, gamma=0.98\n        :return: None\n        """"""\n        for key, value in kwargs.items():\n            if key in self.params[\'agent\'].keys():\n                self.params[\'agent\'][key] = value\n    def export_env_params(self, file_name):\n        """"""\n        Export the environment parameters to the specified file. Useful for logging experiment specific parameters\n        :param file_name: Name of the file to write the environment parameters to\n        :return:\n        """"""\n        with open(file_name, \'w\') as f:\n            json.dump(self.params[\'env\'], f, indent=4, separators=(\',\',\': \'), sort_keys=True)\n            # Adding a trailing newline for POSIX compatibility\n            f.write(""\\n"")\n\n    def export_agent_params(self, file_name):\n        """"""\n        Export the agent parameters to the specified file. Useful for logging experiment specific parameters.\n        :param file_name: Name of the file to write the agent parameters to\n        :return:\n        """"""\n        with open(file_name, \'w\') as f:\n            json.dump(self.params[\'agent\'], f, indent=4, separators=(\',\', \': \'), sort_keys=True)\n            # Adding a trailing newline for POSIX compatibility\n            f.write(""\\n"")\n\n\nif __name__ == ""__main__"":\n    print(""Testing ParamsManager..."")\n    param_file = ""parameters.json""\n    params_manager = ParamsManager(param_file)\n    agent_params = params_manager.get_agent_params()\n    print(""Agent params:"")\n    for k, v in agent_params.items():\n        print(k, "":"", v)\n    env_params = params_manager.get_env_params()\n    print(""Environment parameters:"")\n    for k, v in env_params.items():\n        print(k, "":"", v)\n    params_manager.update_agent_params(lr=0.01, gamma=0.95)\n    updated_agent_params = params_manager.get_agent_params()\n    print(""Updated Agent params:"")\n    for k, v in updated_agent_params.items():\n        print(k, "":"", v)\n\n    print(""ParamsManager test completed."")\n'"
setup/macOS/setup_test.py,0,"b'#!/usr/bin/env python\nimport gym\nenv = gym.make(""LunarLander-v2"")\n# Run a sample/random agent for 10 episodes\nfor _ in range(10):\n    _ = env.reset()\n    env.render()\n    done = False\n    while not done:\n        _, _, done, _ = env.step(env.action_space.sample())\n        env.render()\n'"
ch7/carla-gym/carla_gym/__init__.py,0,"b""from gym.envs.registration import register\n\nregister(\n    id='Carla-v0',\n    entry_point='carla_gym.envs:CarlaEnv',\n)"""
ch7/custom-environments/custom_environments/__init__.py,0,"b""from gym.envs.registration import register\n\nregister(\n    id='CustomEnv-v0',\n    entry_point='custom_environments.envs:CustomEnv',\n)"""
ch8/environment/carla_gym/__init__.py,0,"b""from gym.envs.registration import register\n\nregister(\n    id='Carla-v0',\n    entry_point='environment.carla_gym.envs:CarlaEnv',\n)"""
ch7/carla-gym/carla_gym/envs/__init__.py,0,b'from carla_gym.envs.carla_env import CarlaEnv\n'
ch7/carla-gym/carla_gym/envs/carla_env.py,0,"b'""""""\nOpenAI Gym compatible Driving simulation environment based on Carla.\nRequires the system environment variable CARLA_SERVER to be defined and be pointing to the\nCarlaUE4.sh file on your system. The default path is assumed to be at: ~/software/CARLA_0.8.2/CarlaUE4.sh\nChapter 7, Hands-on Intelligent Agents with OpenAI Gym, 2018| Praveen Palanisamy\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom datetime import datetime\nimport atexit\nimport cv2\nimport os\nimport random\nimport signal\nimport subprocess\nimport time\nimport traceback\nimport json\nimport numpy as np\nimport gym\nfrom gym.spaces import Box, Discrete, Tuple\n\n# Set this to the path to your Carla binary\nSERVER_BINARY = os.environ.get(\n    ""CARLA_SERVER"", os.path.expanduser(""~/software/CARLA_0.8.2/CarlaUE4.sh""))\nassert os.path.exists(SERVER_BINARY), ""CARLA_SERVER environment variable is not set properly. Please check and retry""\n\n\n# Import Carla python client API funcs\ntry:\n    from carla.client import CarlaClient\n    from carla.sensor import Camera\n    from carla.settings import CarlaSettings\n    from carla.planner.planner import Planner, REACH_GOAL, GO_STRAIGHT, \\\n        TURN_RIGHT, TURN_LEFT, LANE_FOLLOW\nexcept ImportError:\n    from .carla.client import CarlaClient\n    from .carla.sensor import Camera\n    from .carla.settings import CarlaSettings\n    from .carla.planner.planner import Planner, REACH_GOAL, GO_STRAIGHT, \\\n        TURN_RIGHT, TURN_LEFT, LANE_FOLLOW\n\n# Carla planner commands\nCOMMANDS_ENUM = {\n    REACH_GOAL: ""REACH_GOAL"",\n    GO_STRAIGHT: ""GO_STRAIGHT"",\n    TURN_RIGHT: ""TURN_RIGHT"",\n    TURN_LEFT: ""TURN_LEFT"",\n    LANE_FOLLOW: ""LANE_FOLLOW"",\n}\n\n# Mapping from string repr to one-hot encoding index to feed to the model\nCOMMAND_ORDINAL = {\n    ""REACH_GOAL"": 0,\n    ""GO_STRAIGHT"": 1,\n    ""TURN_RIGHT"": 2,\n    ""TURN_LEFT"": 3,\n    ""LANE_FOLLOW"": 4,\n}\n\n# Load scenario configuration parameters from scenarios.json\n__location__ = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))\nscenario_config = json.load(open(os.path.join(__location__, ""scenarios.json"")))\ncity = scenario_config[""city""][1]  # Town2\nweathers = [scenario_config[\'Weather\'][\'WetNoon\'], scenario_config[\'Weather\'][\'ClearSunset\'] ]\nscenario_config[\'Weather_distribution\'] = weathers\n\n# Default environment configuration\nENV_CONFIG = {\n    ""discrete_actions"": True,\n    ""use_image_only_observations"": True,  # Exclude high-level planner inputs & goal info from the observations\n    ""server_map"": ""/Game/Maps/"" + city,\n    ""scenarios"": [scenario_config[""Lane_Keep_Town2""]],\n    ""framestack"": 2,  # note: only [1, 2] currently supported\n    ""enable_planner"": True,\n    ""use_depth_camera"": False,\n    ""early_terminate_on_collision"": True,\n    ""verbose"": False,\n    ""render"" : True,  # Render to display if true\n    ""render_x_res"": 800,\n    ""render_y_res"": 600,\n    ""x_res"": 80,\n    ""y_res"": 80,\n    ""seed"": 1\n}\n\n# Number of retries if the server doesn\'t respond\nRETRIES_ON_ERROR = 4\n# Dummy Z coordinate to use when we only care about (x, y)\nGROUND_Z = 22\n\n# Define the discrete action space\nDISCRETE_ACTIONS = {\n    0: [0.0, 0.0],    # Coast\n    1: [0.0, -0.5],   # Turn Left\n    2: [0.0, 0.5],    # Turn Right\n    3: [1.0, 0.0],    # Forward\n    4: [-0.5, 0.0],   # Brake\n    5: [1.0, -0.5],   # Bear Left & accelerate\n    6: [1.0, 0.5],    # Bear Right & accelerate\n    7: [-0.5, -0.5],  # Bear Left & decelerate\n    8: [-0.5, 0.5],   # Bear Right & decelerate\n}\n\nlive_carla_processes = set()  # To keep track of all the Carla processes we launch to make the cleanup easier\ndef cleanup():\n    print(""Killing live carla processes"", live_carla_processes)\n    for pgid in live_carla_processes:\n        os.killpg(pgid, signal.SIGKILL)\natexit.register(cleanup)\n\n\nclass CarlaEnv(gym.Env):\n    def __init__(self, config=ENV_CONFIG):\n        """"""\n        Carla Gym Environment class implementation. Creates an OpenAI Gym compatible driving environment based on\n        Carla driving simulator.\n        :param config: A dictionary with environment configuration keys and values\n        """"""\n        self.config = config\n        self.city = self.config[""server_map""].split(""/"")[-1]\n        if self.config[""enable_planner""]:\n            self.planner = Planner(self.city)\n\n        if config[""discrete_actions""]:\n            self.action_space = Discrete(len(DISCRETE_ACTIONS))\n        else:\n            self.action_space = Box(-1.0, 1.0, shape=(2,), dtype=np.uint8)\n        if config[""use_depth_camera""]:\n            image_space = Box(\n                -1.0, 1.0, shape=(\n                    config[""y_res""], config[""x_res""],\n                    1 * config[""framestack""]), dtype=np.float32)\n        else:\n            image_space = Box(\n                0.0, 255.0, shape=(\n                    config[""y_res""], config[""x_res""],\n                    3 * config[""framestack""]), dtype=np.float32)\n        if self.config[""use_image_only_observations""]:\n            self.observation_space = image_space\n        else:\n            self.observation_space = Tuple(\n                [image_space,\n                 Discrete(len(COMMANDS_ENUM)),  # next_command\n                 Box(-128.0, 128.0, shape=(2,), dtype=np.float32)])  # forward_speed, dist to goal\n\n        self._spec = lambda: None\n        self._spec.id = ""Carla-v0""\n        self._seed = ENV_CONFIG[""seed""]\n\n        self.server_port = None\n        self.server_process = None\n        self.client = None\n        self.num_steps = 0\n        self.total_reward = 0\n        self.prev_measurement = None\n        self.prev_image = None\n        self.episode_id = None\n        self.measurements_file = None\n        self.weather = None\n        self.scenario = None\n        self.start_pos = None\n        self.end_pos = None\n        self.start_coord = None\n        self.end_coord = None\n        self.last_obs = None\n\n    def init_server(self):\n        print(""Initializing new Carla server..."")\n        # Create a new server process and start the client.\n        self.server_port = random.randint(10000, 60000)\n        if self.config[""render""]:\n            self.server_process = subprocess.Popen(\n                [SERVER_BINARY, self.config[""server_map""],\n                 ""-windowed"", ""-ResX=400"", ""-ResY=300"",\n                 ""-carla-server"",\n                 ""-carla-world-port={}"".format(self.server_port)],\n                preexec_fn=os.setsid, stdout=open(os.devnull, ""w""))\n        else:\n            self.server_process = subprocess.Popen(\n                (""SDL_VIDEODRIVER=offscreen SDL_HINT_CUDA_DEVICE={} {} "" +\n                 self.config[""server_map""] + "" -windowed -ResX=400 -ResY=300""\n                 "" -carla-server -carla-world-port={}"").format(0, SERVER_BINARY, self.server_port),\n                shell=True, preexec_fn=os.setsid, stdout=open(os.devnull, ""w""))\n\n        live_carla_processes.add(os.getpgid(self.server_process.pid))\n\n        for i in range(RETRIES_ON_ERROR):\n            try:\n                self.client = CarlaClient(""localhost"", self.server_port)\n                return self.client.connect()\n            except Exception as e:\n                print(""Error connecting: {}, attempt {}"".format(e, i))\n                time.sleep(2)\n\n    def clear_server_state(self):\n        print(""Clearing Carla server state"")\n        try:\n            if self.client:\n                self.client.disconnect()\n                self.client = None\n        except Exception as e:\n            print(""Error disconnecting client: {}"".format(e))\n            pass\n        if self.server_process:\n            pgid = os.getpgid(self.server_process.pid)\n            os.killpg(pgid, signal.SIGKILL)\n            live_carla_processes.remove(pgid)\n            self.server_port = None\n            self.server_process = None\n\n    def __del__(self):\n        self.clear_server_state()\n\n    def reset(self):\n        error = None\n        for _ in range(RETRIES_ON_ERROR):\n            try:\n                if not self.server_process:\n                    self.init_server()\n                return self.reset_env()\n            except Exception as e:\n                print(""Error during reset: {}"".format(traceback.format_exc()))\n                self.clear_server_state()\n                error = e\n        raise error\n\n    def reset_env(self):\n        self.num_steps = 0\n        self.total_reward = 0\n        self.prev_measurement = None\n        self.prev_image = None\n        self.episode_id = datetime.today().strftime(""%Y-%m-%d_%H-%M-%S_%f"")\n        self.measurements_file = None\n\n        # Create a CarlaSettings object. This object is a wrapper around\n        # the CarlaSettings.ini file. Here we set the configuration we\n        # want for the new episode.\n        settings = CarlaSettings()\n        # If config[""scenarios""] is a single scenario, then use it if it\'s an array of scenarios, randomly choose one and init\n        if isinstance(self.config[""scenarios""],dict):\n            self.scenario = self.config[""scenarios""]\n        else: #isinstance array of dict\n            self.scenario = random.choice(self.config[""scenarios""])\n        assert self.scenario[""city""] == self.city, (self.scenario, self.city)\n        self.weather = random.choice(self.scenario[""weather_distribution""])\n        settings.set(\n            SynchronousMode=True,\n            SendNonPlayerAgentsInfo=True,\n            NumberOfVehicles=self.scenario[""num_vehicles""],\n            NumberOfPedestrians=self.scenario[""num_pedestrians""],\n            WeatherId=self.weather)\n        settings.randomize_seeds()\n\n        if self.config[""use_depth_camera""]:\n            camera1 = Camera(""CameraDepth"", PostProcessing=""Depth"")\n            camera1.set_image_size(\n                self.config[""render_x_res""], self.config[""render_y_res""])\n            camera1.set_position(0.30, 0, 1.30)\n            settings.add_sensor(camera1)\n\n        camera2 = Camera(""CameraRGB"")\n        camera2.set_image_size(\n            self.config[""render_x_res""], self.config[""render_y_res""])\n        camera2.set_position(0.30, 0, 1.30)\n        settings.add_sensor(camera2)\n\n        # Setup start and end positions\n        scene = self.client.load_settings(settings)\n        positions = scene.player_start_spots\n        self.start_pos = positions[self.scenario[""start_pos_id""]]\n        self.end_pos = positions[self.scenario[""end_pos_id""]]\n        self.start_coord = [\n            self.start_pos.location.x // 100, self.start_pos.location.y // 100]\n        self.end_coord = [\n            self.end_pos.location.x // 100, self.end_pos.location.y // 100]\n        print(\n            ""Start pos {} ({}), end {} ({})"".format(\n                self.scenario[""start_pos_id""], self.start_coord,\n                self.scenario[""end_pos_id""], self.end_coord))\n\n        # Notify the server that we want to start the episode at the\n        # player_start index. This function blocks until the server is ready\n        # to start the episode.\n        print(""Starting new episode..."")\n        self.client.start_episode(self.scenario[""start_pos_id""])\n\n        image, py_measurements = self._read_observation()\n        self.prev_measurement = py_measurements\n        return self.encode_obs(self.preprocess_image(image), py_measurements)\n\n    def encode_obs(self, image, py_measurements):\n        assert self.config[""framestack""] in [1, 2]\n        prev_image = self.prev_image\n        self.prev_image = image\n        if prev_image is None:\n            prev_image = image\n        if self.config[""framestack""] == 2:\n            image = np.concatenate([prev_image, image], axis=2)\n        if self.config[""use_image_only_observations""]:\n            obs = image\n        else:\n            obs = (\n                image,\n                COMMAND_ORDINAL[py_measurements[""next_command""]],\n                [py_measurements[""forward_speed""],\n                 py_measurements[""distance_to_goal""]])\n        self.last_obs = obs\n        return obs\n\n    def step(self, action):\n        try:\n            obs = self.step_env(action)\n            return obs\n        except Exception:\n            print(\n                ""Error during step, terminating episode early"",\n                traceback.format_exc())\n            self.clear_server_state()\n            return (self.last_obs, 0.0, True, {})\n\n    def step_env(self, action):\n        if self.config[""discrete_actions""]:\n            action = DISCRETE_ACTIONS[int(action)]\n        assert len(action) == 2, ""Invalid action {}"".format(action)\n        throttle = float(np.clip(action[0], 0, 1))\n        brake = float(np.abs(np.clip(action[0], -1, 0)))\n        steer = float(np.clip(action[1], -1, 1))\n        reverse = False\n        hand_brake = False\n\n        if self.config[""verbose""]:\n            print(\n                ""steer"", steer, ""throttle"", throttle, ""brake"", brake,\n                ""reverse"", reverse)\n\n        self.client.send_control(\n            steer=steer, throttle=throttle, brake=brake, hand_brake=hand_brake,\n            reverse=reverse)\n\n        # Process observations\n        image, py_measurements = self._read_observation()\n        if self.config[""verbose""]:\n            print(""Next command"", py_measurements[""next_command""])\n        if type(action) is np.ndarray:\n            py_measurements[""action""] = [float(a) for a in action]\n        else:\n            py_measurements[""action""] = action\n        py_measurements[""control""] = {\n            ""steer"": steer,\n            ""throttle"": throttle,\n            ""brake"": brake,\n            ""reverse"": reverse,\n            ""hand_brake"": hand_brake,\n        }\n        reward = self.calculate_reward(py_measurements)\n        self.total_reward += reward\n        py_measurements[""reward""] = reward\n        py_measurements[""total_reward""] = self.total_reward\n        done = (self.num_steps > self.scenario[""max_steps""] or\n                py_measurements[""next_command""] == ""REACH_GOAL"" or\n                (self.config[""early_terminate_on_collision""] and\n                 check_collision(py_measurements)))\n        py_measurements[""done""] = done\n        self.prev_measurement = py_measurements\n\n        self.num_steps += 1\n        image = self.preprocess_image(image)\n        return (\n            self.encode_obs(image, py_measurements), reward, done,\n            py_measurements)\n\n\n    def preprocess_image(self, image):\n        if self.config[""use_depth_camera""]:\n            assert self.config[""use_depth_camera""]\n            data = (image.data - 0.5) * 2\n            data = data.reshape(\n                self.config[""render_y_res""], self.config[""render_x_res""], 1)\n            data = cv2.resize(\n                data, (self.config[""x_res""], self.config[""y_res""]),\n                interpolation=cv2.INTER_AREA)\n            data = np.expand_dims(data, 2)\n        else:\n            data = image.data.reshape(\n                self.config[""render_y_res""], self.config[""render_x_res""], 3)\n            data = cv2.resize(\n                data, (self.config[""x_res""], self.config[""y_res""]),\n                interpolation=cv2.INTER_AREA)\n            data = (data.astype(np.float32) - 128) / 128\n        return data\n\n    def _read_observation(self):\n        # Read the data produced by the server this frame.\n        measurements, sensor_data = self.client.read_data()\n\n        # Print some of the measurements.\n        if self.config[""verbose""]:\n            print_measurements(measurements)\n\n        observation = None\n        if self.config[""use_depth_camera""]:\n            camera_name = ""CameraDepth""\n        else:\n            camera_name = ""CameraRGB""\n        for name, image in sensor_data.items():\n            if name == camera_name:\n                observation = image\n\n        cur = measurements.player_measurements\n\n        if self.config[""enable_planner""]:\n            next_command = COMMANDS_ENUM[\n                self.planner.get_next_command(\n                    [cur.transform.location.x, cur.transform.location.y,\n                     GROUND_Z],\n                    [cur.transform.orientation.x, cur.transform.orientation.y,\n                     GROUND_Z],\n                    [self.end_pos.location.x, self.end_pos.location.y,\n                     GROUND_Z],\n                    [self.end_pos.orientation.x, self.end_pos.orientation.y,\n                     GROUND_Z])\n            ]\n        else:\n            next_command = ""LANE_FOLLOW""\n\n        if next_command == ""REACH_GOAL"":\n            distance_to_goal = 0.0  # avoids crash in planner\n        elif self.config[""enable_planner""]:\n            distance_to_goal = self.planner.get_shortest_path_distance(\n                [cur.transform.location.x, cur.transform.location.y, GROUND_Z],\n                [cur.transform.orientation.x, cur.transform.orientation.y,\n                 GROUND_Z],\n                [self.end_pos.location.x, self.end_pos.location.y, GROUND_Z],\n                [self.end_pos.orientation.x, self.end_pos.orientation.y,\n                 GROUND_Z]) / 100\n        else:\n            distance_to_goal = -1\n\n        distance_to_goal_euclidean = float(np.linalg.norm(\n            [cur.transform.location.x - self.end_pos.location.x,\n             cur.transform.location.y - self.end_pos.location.y]) / 100)\n\n        py_measurements = {\n            ""episode_id"": self.episode_id,\n            ""step"": self.num_steps,\n            ""x"": cur.transform.location.x,\n            ""y"": cur.transform.location.y,\n            ""x_orient"": cur.transform.orientation.x,\n            ""y_orient"": cur.transform.orientation.y,\n            ""forward_speed"": cur.forward_speed,\n            ""distance_to_goal"": distance_to_goal,\n            ""distance_to_goal_euclidean"": distance_to_goal_euclidean,\n            ""collision_vehicles"": cur.collision_vehicles,\n            ""collision_pedestrians"": cur.collision_pedestrians,\n            ""collision_other"": cur.collision_other,\n            ""intersection_offroad"": cur.intersection_offroad,\n            ""intersection_otherlane"": cur.intersection_otherlane,\n            ""weather"": self.weather,\n            ""map"": self.config[""server_map""],\n            ""start_coord"": self.start_coord,\n            ""end_coord"": self.end_coord,\n            ""current_scenario"": self.scenario,\n            ""x_res"": self.config[""x_res""],\n            ""y_res"": self.config[""y_res""],\n            ""num_vehicles"": self.scenario[""num_vehicles""],\n            ""num_pedestrians"": self.scenario[""num_pedestrians""],\n            ""max_steps"": self.scenario[""max_steps""],\n            ""next_command"": next_command,\n        }\n\n\n        assert observation is not None, sensor_data\n        return observation, py_measurements\n\n    def calculate_reward(self, current_measurement):\n        """"""\n        Calculate the reward based on the effect of the action taken using the previous and the current measurements\n        :param current_measurement: The measurement obtained from the Carla engine after executing the current action\n        :return: The scalar reward\n        """"""\n        reward = 0.0\n\n        cur_dist = current_measurement[""distance_to_goal""]\n\n        prev_dist = self.prev_measurement[""distance_to_goal""]\n\n        if self.config[""verbose""]:\n            print(""Cur dist {}, prev dist {}"".format(cur_dist, prev_dist))\n\n        # Distance travelled toward the goal in m\n        reward += np.clip(prev_dist - cur_dist, -10.0, 10.0)\n\n        # Change in speed (km/hr)\n        reward += 0.05 * (current_measurement[""forward_speed""] - self.prev_measurement[""forward_speed""])\n\n        # New collision damage\n        reward -= .00002 * (\n            current_measurement[""collision_vehicles""] + current_measurement[""collision_pedestrians""] +\n            current_measurement[""collision_other""] - self.prev_measurement[""collision_vehicles""] -\n            self.prev_measurement[""collision_pedestrians""] - self.prev_measurement[""collision_other""])\n\n        # New sidewalk intersection\n        reward -= 2 * (\n            current_measurement[""intersection_offroad""] - self.prev_measurement[""intersection_offroad""])\n\n        # New opposite lane intersection\n        reward -= 2 * (\n            current_measurement[""intersection_otherlane""] - self.prev_measurement[""intersection_otherlane""])\n\n        return reward\n\ndef print_measurements(measurements):\n    number_of_agents = len(measurements.non_player_agents)\n    player_measurements = measurements.player_measurements\n    message = ""Vehicle at ({pos_x:.1f}, {pos_y:.1f}), ""\n    message += ""{speed:.2f} km/h, ""\n    message += ""Collision: {{vehicles={col_cars:.0f}, ""\n    message += ""pedestrians={col_ped:.0f}, other={col_other:.0f}}}, ""\n    message += ""{other_lane:.0f}% other lane, {offroad:.0f}% off-road, ""\n    message += ""({agents_num:d} non-player agents in the scene)""\n    message = message.format(\n        pos_x=player_measurements.transform.location.x / 100,  # cm -> m\n        pos_y=player_measurements.transform.location.y / 100,\n        speed=player_measurements.forward_speed,\n        col_cars=player_measurements.collision_vehicles,\n        col_ped=player_measurements.collision_pedestrians,\n        col_other=player_measurements.collision_other,\n        other_lane=100 * player_measurements.intersection_otherlane,\n        offroad=100 * player_measurements.intersection_offroad,\n        agents_num=number_of_agents)\n    print(message)\n\n\ndef check_collision(py_measurements):\n    m = py_measurements\n    collided = (\n        m[""collision_vehicles""] > 0 or m[""collision_pedestrians""] > 0 or\n        m[""collision_other""] > 0)\n    return bool(collided or m[""total_reward""] < -100)\n\n\nif __name__ == ""__main__"":\n    for _ in range(5):\n        env = CarlaEnv()\n        obs = env.reset()\n        done = False\n        t = 0\n        total_reward = 0.0\n        while not done:\n            t += 1\n            if ENV_CONFIG[""discrete_actions""]:\n                obs, reward, done, info = env.step(3)  # Go Forward\n            else:\n                obs, reward, done, info = env.step([1.0, 0.0])  # Full throttle, zero steering angle\n            total_reward += reward\n            print(""step#:"", t, ""reward:"", round(reward, 4), ""total_reward:"", round(total_reward, 4), ""done:"", done)\n'"
ch7/custom-environments/custom_environments/envs/__init__.py,0,b'from custom_environments.envs.custom_env_template import CustomEnv\n'
ch7/custom-environments/custom_environments/envs/custom_env_template.py,0,"b'import gym\n\nclass CustomEnv(gym.Env):\n    """"""\n    A template to implement custom OpenAI Gym environments\n\n    """"""\n\n    metadata = {\'render.modes\': [\'human\']}\n    def __init__(self):\n        self.__version__ = ""0.0.1""\n        # Modify the observation space, low, high and shape values according to your custom environment\'s needs\n        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(3,))\n        # Modify the action space, and dimension according to your custom environment\'s needs\n        self.action_space = gym.spaces.Discrete(4)\n\n    def step(self, action):\n        """"""\n        Runs one time-step of the environment\'s dynamics. The reset() method is called at the end of every episode\n        :param action: The action to be executed in the environment\n        :return: (observation, reward, done, info)\n            observation (object):\n                Observation from the environment at the current time-step\n            reward (float):\n                Reward from the environment due to the previous action performed\n            done (bool):\n                a boolean, indicating whether the episode has ended\n            info (dict):\n                a dictionary containing additional information about the previous action\n        """"""\n        # Implement your step method here\n        # return (observation, reward, done, info)\n\n    def reset(self):\n        """"""\n        Reset the environment state and returns an initial observation\n\n        Returns\n        -------\n        observation (object): The initial observation for the new episode after reset\n        :return:\n        """"""\n\n        # Implement your reset method here\n        # return observation\n\n    def render(self, mode=\'human\', close=False):\n        """"""\n\n        :param mode:\n        :return:\n        """"""\n        return'"
ch8/environment/carla_gym/envs/__init__.py,0,b'from environment.carla_gym.envs.carla_env import CarlaEnv\n'
ch8/environment/carla_gym/envs/carla_env.py,0,"b'""""""\nOpenAI Gym compatible Driving simulation environment based on Carla.\nRequires the system environment variable CARLA_SERVER to be defined and be pointing to the\nCarlaUE4.sh file on your system. The default path is assumed to be at: ~/software/CARLA_0.8.2/CarlaUE4.sh\nChapter 7, Hands-on Intelligent Agents with OpenAI Gym, 2018| Praveen Palanisamy\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom datetime import datetime\nimport atexit\nimport cv2\nimport os\nimport random\nimport signal\nimport subprocess\nimport time\nimport traceback\nimport json\nimport numpy as np\nimport gym\nfrom gym.spaces import Box, Discrete, Tuple\n\n# Set this to the path to your Carla binary\nSERVER_BINARY = os.environ.get(\n    ""CARLA_SERVER"", os.path.expanduser(""~/software/CARLA_0.8.2/CarlaUE4.sh""))\nassert os.path.exists(SERVER_BINARY), ""CARLA_SERVER environment variable is not set properly. Please check and retry""\n\n\n# Import Carla python client API funcs\ntry:\n    from carla.client import CarlaClient\n    from carla.sensor import Camera\n    from carla.settings import CarlaSettings\n    from carla.planner.planner import Planner, REACH_GOAL, GO_STRAIGHT, \\\n        TURN_RIGHT, TURN_LEFT, LANE_FOLLOW\nexcept ImportError:\n    from .carla.client import CarlaClient\n    from .carla.sensor import Camera\n    from .carla.settings import CarlaSettings\n    from .carla.planner.planner import Planner, REACH_GOAL, GO_STRAIGHT, \\\n        TURN_RIGHT, TURN_LEFT, LANE_FOLLOW\n\n# Carla planner commands\nCOMMANDS_ENUM = {\n    REACH_GOAL: ""REACH_GOAL"",\n    GO_STRAIGHT: ""GO_STRAIGHT"",\n    TURN_RIGHT: ""TURN_RIGHT"",\n    TURN_LEFT: ""TURN_LEFT"",\n    LANE_FOLLOW: ""LANE_FOLLOW"",\n}\n\n# Mapping from string repr to one-hot encoding index to feed to the model\nCOMMAND_ORDINAL = {\n    ""REACH_GOAL"": 0,\n    ""GO_STRAIGHT"": 1,\n    ""TURN_RIGHT"": 2,\n    ""TURN_LEFT"": 3,\n    ""LANE_FOLLOW"": 4,\n}\n\n# Load scenario configuration parameters from scenarios.json\n__location__ = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))\nscenario_config = json.load(open(os.path.join(__location__, ""scenarios.json"")))\ncity = scenario_config[""city""][1]  # Town2\nweathers = [scenario_config[\'Weather\'][\'WetNoon\'], scenario_config[\'Weather\'][\'ClearSunset\'] ]\nscenario_config[\'Weather_distribution\'] = weathers\n\n# Default environment configuration\nENV_CONFIG = {\n    ""discrete_actions"": True,\n    ""use_image_only_observations"": True,  # Exclude high-level planner inputs & goal info from the observations\n    ""server_map"": ""/Game/Maps/"" + city,\n    ""scenarios"": [scenario_config[""Lane_Keep_Town2""]],\n    ""framestack"": 2,  # note: only [1, 2] currently supported\n    ""enable_planner"": True,\n    ""use_depth_camera"": False,\n    ""early_terminate_on_collision"": True,\n    ""verbose"": False,\n    ""render"" : True,  # Render to display if true\n    ""render_x_res"": 800,\n    ""render_y_res"": 600,\n    ""x_res"": 80,\n    ""y_res"": 80,\n    ""seed"": 1\n}\n\n# Number of retries if the server doesn\'t respond\nRETRIES_ON_ERROR = 4\n# Dummy Z coordinate to use when we only care about (x, y)\nGROUND_Z = 22\n\n# Define the discrete action space\nDISCRETE_ACTIONS = {\n    0: [0.0, 0.0],    # Coast\n    1: [0.0, -0.5],   # Turn Left\n    2: [0.0, 0.5],    # Turn Right\n    3: [1.0, 0.0],    # Forward\n    4: [-0.5, 0.0],   # Brake\n    5: [1.0, -0.5],   # Bear Left & accelerate\n    6: [1.0, 0.5],    # Bear Right & accelerate\n    7: [-0.5, -0.5],  # Bear Left & decelerate\n    8: [-0.5, 0.5],   # Bear Right & decelerate\n}\n\nlive_carla_processes = set()  # To keep track of all the Carla processes we launch to make the cleanup easier\ndef cleanup():\n    print(""Killing live carla processes"", live_carla_processes)\n    for pgid in live_carla_processes:\n        os.killpg(pgid, signal.SIGKILL)\natexit.register(cleanup)\n\n\nclass CarlaEnv(gym.Env):\n    def __init__(self, config=ENV_CONFIG):\n        """"""\n        Carla Gym Environment class implementation. Creates an OpenAI Gym compatible driving environment based on\n        Carla driving simulator.\n        :param config: A dictionary with environment configuration keys and values\n        """"""\n        self.config = config\n        self.city = self.config[""server_map""].split(""/"")[-1]\n        if self.config[""enable_planner""]:\n            self.planner = Planner(self.city)\n\n        if config[""discrete_actions""]:\n            self.action_space = Discrete(len(DISCRETE_ACTIONS))\n        else:\n            self.action_space = Box(-1.0, 1.0, shape=(2,), dtype=np.uint8)\n        if config[""use_depth_camera""]:\n            image_space = Box(\n                -1.0, 1.0, shape=(\n                    config[""y_res""], config[""x_res""],\n                    1 * config[""framestack""]), dtype=np.float32)\n        else:\n            image_space = Box(\n                0.0, 255.0, shape=(\n                    config[""y_res""], config[""x_res""],\n                    3 * config[""framestack""]), dtype=np.float32)\n        if self.config[""use_image_only_observations""]:\n            self.observation_space = image_space\n        else:\n            self.observation_space = Tuple(\n                [image_space,\n                 Discrete(len(COMMANDS_ENUM)),  # next_command\n                 Box(-128.0, 128.0, shape=(2,), dtype=np.float32)])  # forward_speed, dist to goal\n\n        self._spec = lambda: None\n        self._spec.id = ""Carla-v0""\n        self._seed = ENV_CONFIG[""seed""]\n\n        self.server_port = None\n        self.server_process = None\n        self.client = None\n        self.num_steps = 0\n        self.total_reward = 0\n        self.prev_measurement = None\n        self.prev_image = None\n        self.episode_id = None\n        self.measurements_file = None\n        self.weather = None\n        self.scenario = None\n        self.start_pos = None\n        self.end_pos = None\n        self.start_coord = None\n        self.end_coord = None\n        self.last_obs = None\n\n    def init_server(self):\n        print(""Initializing new Carla server..."")\n        # Create a new server process and start the client.\n        self.server_port = random.randint(10000, 60000)\n        if self.config[""render""]:\n            self.server_process = subprocess.Popen(\n                [SERVER_BINARY, self.config[""server_map""],\n                 ""-windowed"", ""-ResX=400"", ""-ResY=300"",\n                 ""-carla-server"",\n                 ""-carla-world-port={}"".format(self.server_port)],\n                preexec_fn=os.setsid, stdout=open(os.devnull, ""w""))\n        else:\n            self.server_process = subprocess.Popen(\n                (""SDL_VIDEODRIVER=offscreen SDL_HINT_CUDA_DEVICE={} {} "" +\n                 self.config[""server_map""] + "" -windowed -ResX=400 -ResY=300""\n                 "" -carla-server -carla-world-port={}"").format(0, SERVER_BINARY, self.server_port),\n                shell=True, preexec_fn=os.setsid, stdout=open(os.devnull, ""w""))\n\n        live_carla_processes.add(os.getpgid(self.server_process.pid))\n\n        for i in range(RETRIES_ON_ERROR):\n            try:\n                self.client = CarlaClient(""localhost"", self.server_port)\n                return self.client.connect()\n            except Exception as e:\n                print(""Error connecting: {}, attempt {}"".format(e, i))\n                time.sleep(2)\n\n    def clear_server_state(self):\n        print(""Clearing Carla server state"")\n        try:\n            if self.client:\n                self.client.disconnect()\n                self.client = None\n        except Exception as e:\n            print(""Error disconnecting client: {}"".format(e))\n            pass\n        if self.server_process:\n            pgid = os.getpgid(self.server_process.pid)\n            os.killpg(pgid, signal.SIGKILL)\n            live_carla_processes.remove(pgid)\n            self.server_port = None\n            self.server_process = None\n\n    def __del__(self):\n        self.clear_server_state()\n\n    def reset(self):\n        error = None\n        for _ in range(RETRIES_ON_ERROR):\n            try:\n                if not self.server_process:\n                    self.init_server()\n                return self.reset_env()\n            except Exception as e:\n                print(""Error during reset: {}"".format(traceback.format_exc()))\n                self.clear_server_state()\n                error = e\n        raise error\n\n    def reset_env(self):\n        self.num_steps = 0\n        self.total_reward = 0\n        self.prev_measurement = None\n        self.prev_image = None\n        self.episode_id = datetime.today().strftime(""%Y-%m-%d_%H-%M-%S_%f"")\n        self.measurements_file = None\n\n        # Create a CarlaSettings object. This object is a wrapper around\n        # the CarlaSettings.ini file. Here we set the configuration we\n        # want for the new episode.\n        settings = CarlaSettings()\n        # If config[""scenarios""] is a single scenario, then use it if it\'s an array of scenarios, randomly choose one and init\n        if isinstance(self.config[""scenarios""],dict):\n            self.scenario = self.config[""scenarios""]\n        else: #isinstance array of dict\n            self.scenario = random.choice(self.config[""scenarios""])\n        assert self.scenario[""city""] == self.city, (self.scenario, self.city)\n        self.weather = random.choice(self.scenario[""weather_distribution""])\n        settings.set(\n            SynchronousMode=True,\n            SendNonPlayerAgentsInfo=True,\n            NumberOfVehicles=self.scenario[""num_vehicles""],\n            NumberOfPedestrians=self.scenario[""num_pedestrians""],\n            WeatherId=self.weather)\n        settings.randomize_seeds()\n\n        if self.config[""use_depth_camera""]:\n            camera1 = Camera(""CameraDepth"", PostProcessing=""Depth"")\n            camera1.set_image_size(\n                self.config[""render_x_res""], self.config[""render_y_res""])\n            camera1.set_position(0.30, 0, 1.30)\n            settings.add_sensor(camera1)\n\n        camera2 = Camera(""CameraRGB"")\n        camera2.set_image_size(\n            self.config[""render_x_res""], self.config[""render_y_res""])\n        camera2.set_position(0.30, 0, 1.30)\n        settings.add_sensor(camera2)\n\n        # Setup start and end positions\n        scene = self.client.load_settings(settings)\n        positions = scene.player_start_spots\n        self.start_pos = positions[self.scenario[""start_pos_id""]]\n        self.end_pos = positions[self.scenario[""end_pos_id""]]\n        self.start_coord = [\n            self.start_pos.location.x // 100, self.start_pos.location.y // 100]\n        self.end_coord = [\n            self.end_pos.location.x // 100, self.end_pos.location.y // 100]\n        print(\n            ""Start pos {} ({}), end {} ({})"".format(\n                self.scenario[""start_pos_id""], self.start_coord,\n                self.scenario[""end_pos_id""], self.end_coord))\n\n        # Notify the server that we want to start the episode at the\n        # player_start index. This function blocks until the server is ready\n        # to start the episode.\n        print(""Starting new episode..."")\n        self.client.start_episode(self.scenario[""start_pos_id""])\n\n        image, py_measurements = self._read_observation()\n        self.prev_measurement = py_measurements\n        return self.encode_obs(self.preprocess_image(image), py_measurements)\n\n    def encode_obs(self, image, py_measurements):\n        assert self.config[""framestack""] in [1, 2]\n        prev_image = self.prev_image\n        self.prev_image = image\n        if prev_image is None:\n            prev_image = image\n        if self.config[""framestack""] == 2:\n            image = np.concatenate([prev_image, image], axis=2)\n        if self.config[""use_image_only_observations""]:\n            obs = image\n        else:\n            obs = (\n                image,\n                COMMAND_ORDINAL[py_measurements[""next_command""]],\n                [py_measurements[""forward_speed""],\n                 py_measurements[""distance_to_goal""]])\n        self.last_obs = obs\n        return obs\n\n    def step(self, action):\n        try:\n            obs = self.step_env(action)\n            return obs\n        except Exception:\n            print(\n                ""Error during step, terminating episode early"",\n                traceback.format_exc())\n            self.clear_server_state()\n            return (self.last_obs, 0.0, True, {})\n\n    def step_env(self, action):\n        if self.config[""discrete_actions""]:\n            action = DISCRETE_ACTIONS[int(action)]\n        assert len(action) == 2, ""Invalid action {}"".format(action)\n        throttle = float(np.clip(action[0], 0, 1))\n        brake = float(np.abs(np.clip(action[0], -1, 0)))\n        steer = float(np.clip(action[1], -1, 1))\n        reverse = False\n        hand_brake = False\n\n        if self.config[""verbose""]:\n            print(\n                ""steer"", steer, ""throttle"", throttle, ""brake"", brake,\n                ""reverse"", reverse)\n\n        self.client.send_control(\n            steer=steer, throttle=throttle, brake=brake, hand_brake=hand_brake,\n            reverse=reverse)\n\n        # Process observations\n        image, py_measurements = self._read_observation()\n        if self.config[""verbose""]:\n            print(""Next command"", py_measurements[""next_command""])\n        if type(action) is np.ndarray:\n            py_measurements[""action""] = [float(a) for a in action]\n        else:\n            py_measurements[""action""] = action\n        py_measurements[""control""] = {\n            ""steer"": steer,\n            ""throttle"": throttle,\n            ""brake"": brake,\n            ""reverse"": reverse,\n            ""hand_brake"": hand_brake,\n        }\n        reward = self.calculate_reward(py_measurements)\n        self.total_reward += reward\n        py_measurements[""reward""] = reward\n        py_measurements[""total_reward""] = self.total_reward\n        done = (self.num_steps > self.scenario[""max_steps""] or\n                py_measurements[""next_command""] == ""REACH_GOAL"" or\n                (self.config[""early_terminate_on_collision""] and\n                 check_collision(py_measurements)))\n        py_measurements[""done""] = done\n        self.prev_measurement = py_measurements\n\n        self.num_steps += 1\n        image = self.preprocess_image(image)\n        return (\n            self.encode_obs(image, py_measurements), reward, done,\n            py_measurements)\n\n\n    def preprocess_image(self, image):\n        if self.config[""use_depth_camera""]:\n            assert self.config[""use_depth_camera""]\n            data = (image.data - 0.5) * 2\n            data = data.reshape(\n                self.config[""render_y_res""], self.config[""render_x_res""], 1)\n            data = cv2.resize(\n                data, (self.config[""x_res""], self.config[""y_res""]),\n                interpolation=cv2.INTER_AREA)\n            data = np.expand_dims(data, 2)\n        else:\n            data = image.data.reshape(\n                self.config[""render_y_res""], self.config[""render_x_res""], 3)\n            data = cv2.resize(\n                data, (self.config[""x_res""], self.config[""y_res""]),\n                interpolation=cv2.INTER_AREA)\n            data = (data.astype(np.float32) - 128) / 128\n        return data\n\n    def _read_observation(self):\n        # Read the data produced by the server this frame.\n        measurements, sensor_data = self.client.read_data()\n\n        # Print some of the measurements.\n        if self.config[""verbose""]:\n            print_measurements(measurements)\n\n        observation = None\n        if self.config[""use_depth_camera""]:\n            camera_name = ""CameraDepth""\n        else:\n            camera_name = ""CameraRGB""\n        for name, image in sensor_data.items():\n            if name == camera_name:\n                observation = image\n\n        cur = measurements.player_measurements\n\n        if self.config[""enable_planner""]:\n            next_command = COMMANDS_ENUM[\n                self.planner.get_next_command(\n                    [cur.transform.location.x, cur.transform.location.y,\n                     GROUND_Z],\n                    [cur.transform.orientation.x, cur.transform.orientation.y,\n                     GROUND_Z],\n                    [self.end_pos.location.x, self.end_pos.location.y,\n                     GROUND_Z],\n                    [self.end_pos.orientation.x, self.end_pos.orientation.y,\n                     GROUND_Z])\n            ]\n        else:\n            next_command = ""LANE_FOLLOW""\n\n        if next_command == ""REACH_GOAL"":\n            distance_to_goal = 0.0  # avoids crash in planner\n        elif self.config[""enable_planner""]:\n            distance_to_goal = self.planner.get_shortest_path_distance(\n                [cur.transform.location.x, cur.transform.location.y, GROUND_Z],\n                [cur.transform.orientation.x, cur.transform.orientation.y,\n                 GROUND_Z],\n                [self.end_pos.location.x, self.end_pos.location.y, GROUND_Z],\n                [self.end_pos.orientation.x, self.end_pos.orientation.y,\n                 GROUND_Z]) / 100\n        else:\n            distance_to_goal = -1\n\n        distance_to_goal_euclidean = float(np.linalg.norm(\n            [cur.transform.location.x - self.end_pos.location.x,\n             cur.transform.location.y - self.end_pos.location.y]) / 100)\n\n        py_measurements = {\n            ""episode_id"": self.episode_id,\n            ""step"": self.num_steps,\n            ""x"": cur.transform.location.x,\n            ""y"": cur.transform.location.y,\n            ""x_orient"": cur.transform.orientation.x,\n            ""y_orient"": cur.transform.orientation.y,\n            ""forward_speed"": cur.forward_speed,\n            ""distance_to_goal"": distance_to_goal,\n            ""distance_to_goal_euclidean"": distance_to_goal_euclidean,\n            ""collision_vehicles"": cur.collision_vehicles,\n            ""collision_pedestrians"": cur.collision_pedestrians,\n            ""collision_other"": cur.collision_other,\n            ""intersection_offroad"": cur.intersection_offroad,\n            ""intersection_otherlane"": cur.intersection_otherlane,\n            ""weather"": self.weather,\n            ""map"": self.config[""server_map""],\n            ""start_coord"": self.start_coord,\n            ""end_coord"": self.end_coord,\n            ""current_scenario"": self.scenario,\n            ""x_res"": self.config[""x_res""],\n            ""y_res"": self.config[""y_res""],\n            ""num_vehicles"": self.scenario[""num_vehicles""],\n            ""num_pedestrians"": self.scenario[""num_pedestrians""],\n            ""max_steps"": self.scenario[""max_steps""],\n            ""next_command"": next_command,\n        }\n\n\n        assert observation is not None, sensor_data\n        return observation, py_measurements\n\n    def calculate_reward(self, current_measurement):\n        """"""\n        Calculate the reward based on the effect of the action taken using the previous and the current measurements\n        :param current_measurement: The measurement obtained from the Carla engine after executing the current action\n        :return: The scalar reward\n        """"""\n        reward = 0.0\n\n        cur_dist = current_measurement[""distance_to_goal""]\n\n        prev_dist = self.prev_measurement[""distance_to_goal""]\n\n        if self.config[""verbose""]:\n            print(""Cur dist {}, prev dist {}"".format(cur_dist, prev_dist))\n\n        # Distance travelled toward the goal in m\n        reward += np.clip(prev_dist - cur_dist, -10.0, 10.0)\n\n        # Change in speed (km/hr)\n        reward += 0.05 * (current_measurement[""forward_speed""] - self.prev_measurement[""forward_speed""])\n\n        # New collision damage\n        reward -= .00002 * (\n            current_measurement[""collision_vehicles""] + current_measurement[""collision_pedestrians""] +\n            current_measurement[""collision_other""] - self.prev_measurement[""collision_vehicles""] -\n            self.prev_measurement[""collision_pedestrians""] - self.prev_measurement[""collision_other""])\n\n        # New sidewalk intersection\n        reward -= 2 * (\n            current_measurement[""intersection_offroad""] - self.prev_measurement[""intersection_offroad""])\n\n        # New opposite lane intersection\n        reward -= 2 * (\n            current_measurement[""intersection_otherlane""] - self.prev_measurement[""intersection_otherlane""])\n\n        return reward\n\ndef print_measurements(measurements):\n    number_of_agents = len(measurements.non_player_agents)\n    player_measurements = measurements.player_measurements\n    message = ""Vehicle at ({pos_x:.1f}, {pos_y:.1f}), ""\n    message += ""{speed:.2f} km/h, ""\n    message += ""Collision: {{vehicles={col_cars:.0f}, ""\n    message += ""pedestrians={col_ped:.0f}, other={col_other:.0f}}}, ""\n    message += ""{other_lane:.0f}% other lane, {offroad:.0f}% off-road, ""\n    message += ""({agents_num:d} non-player agents in the scene)""\n    message = message.format(\n        pos_x=player_measurements.transform.location.x / 100,  # cm -> m\n        pos_y=player_measurements.transform.location.y / 100,\n        speed=player_measurements.forward_speed,\n        col_cars=player_measurements.collision_vehicles,\n        col_ped=player_measurements.collision_pedestrians,\n        col_other=player_measurements.collision_other,\n        other_lane=100 * player_measurements.intersection_otherlane,\n        offroad=100 * player_measurements.intersection_offroad,\n        agents_num=number_of_agents)\n    print(message)\n\n\ndef check_collision(py_measurements):\n    m = py_measurements\n    collided = (\n        m[""collision_vehicles""] > 0 or m[""collision_pedestrians""] > 0 or\n        m[""collision_other""] > 0)\n    return bool(collided or m[""total_reward""] < -100)\n\n\nif __name__ == ""__main__"":\n    for _ in range(5):\n        env = CarlaEnv()\n        obs = env.reset()\n        done = False\n        t = 0\n        total_reward = 0.0\n        while not done:\n            t += 1\n            if ENV_CONFIG[""discrete_actions""]:\n                obs, reward, done, info = env.step(3)  # Go Forward\n            else:\n                obs, reward, done, info = env.step([1.0, 0.0])  # Full throttle, zero steering angle\n            total_reward += reward\n            print(""step#:"", t, ""reward:"", round(reward, 4), ""total_reward:"", round(total_reward, 4), ""done:"", done)\n'"
ch7/carla-gym/carla_gym/envs/carla/__init__.py,0,b''
ch7/carla-gym/carla_gym/envs/carla/carla_server_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: carla_server.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'carla_server.proto\',\n  package=\'carla_server\',\n  syntax=\'proto3\',\n  serialized_pb=_b(\'\\n\\x12\\x63\\x61rla_server.proto\\x12\\x0c\\x63\\x61rla_server\\""+\\n\\x08Vector3D\\x12\\t\\n\\x01x\\x18\\x01 \\x01(\\x02\\x12\\t\\n\\x01y\\x18\\x02 \\x01(\\x02\\x12\\t\\n\\x01z\\x18\\x03 \\x01(\\x02\\""6\\n\\nRotation3D\\x12\\r\\n\\x05pitch\\x18\\x01 \\x01(\\x02\\x12\\x0b\\n\\x03yaw\\x18\\x02 \\x01(\\x02\\x12\\x0c\\n\\x04roll\\x18\\x03 \\x01(\\x02\\""\\x92\\x01\\n\\tTransform\\x12(\\n\\x08location\\x18\\x01 \\x01(\\x0b\\x32\\x16.carla_server.Vector3D\\x12/\\n\\x0borientation\\x18\\x02 \\x01(\\x0b\\x32\\x16.carla_server.Vector3DB\\x02\\x18\\x01\\x12*\\n\\x08rotation\\x18\\x03 \\x01(\\x0b\\x32\\x18.carla_server.Rotation3D\\""a\\n\\x0b\\x42oundingBox\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12&\\n\\x06\\x65xtent\\x18\\x02 \\x01(\\x0b\\x32\\x16.carla_server.Vector3D\\""\\x80\\x01\\n\\x06Sensor\\x12\\n\\n\\x02id\\x18\\x01 \\x01(\\x07\\x12\\\'\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x19.carla_server.Sensor.Type\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\""3\\n\\x04Type\\x12\\x0b\\n\\x07UNKNOWN\\x10\\x00\\x12\\n\\n\\x06\\x43\\x41MERA\\x10\\x01\\x12\\x12\\n\\x0eLIDAR_RAY_CAST\\x10\\x02\\""}\\n\\x07Vehicle\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12/\\n\\x0c\\x62ounding_box\\x18\\x04 \\x01(\\x0b\\x32\\x19.carla_server.BoundingBox\\x12\\x15\\n\\rforward_speed\\x18\\x03 \\x01(\\x02\\""\\x80\\x01\\n\\nPedestrian\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12/\\n\\x0c\\x62ounding_box\\x18\\x04 \\x01(\\x0b\\x32\\x19.carla_server.BoundingBox\\x12\\x15\\n\\rforward_speed\\x18\\x03 \\x01(\\x02\\""\\x94\\x01\\n\\x0cTrafficLight\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12/\\n\\x05state\\x18\\x02 \\x01(\\x0e\\x32 .carla_server.TrafficLight.State\\""\\\'\\n\\x05State\\x12\\t\\n\\x05GREEN\\x10\\x00\\x12\\n\\n\\x06YELLOW\\x10\\x01\\x12\\x07\\n\\x03RED\\x10\\x02\\""Q\\n\\x0eSpeedLimitSign\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12\\x13\\n\\x0bspeed_limit\\x18\\x02 \\x01(\\x02\\""\\xe5\\x01\\n\\x05\\x41gent\\x12\\n\\n\\x02id\\x18\\x01 \\x01(\\x07\\x12(\\n\\x07vehicle\\x18\\x02 \\x01(\\x0b\\x32\\x15.carla_server.VehicleH\\x00\\x12.\\n\\npedestrian\\x18\\x03 \\x01(\\x0b\\x32\\x18.carla_server.PedestrianH\\x00\\x12\\x33\\n\\rtraffic_light\\x18\\x04 \\x01(\\x0b\\x32\\x1a.carla_server.TrafficLightH\\x00\\x12\\x38\\n\\x10speed_limit_sign\\x18\\x05 \\x01(\\x0b\\x32\\x1c.carla_server.SpeedLimitSignH\\x00\\x42\\x07\\n\\x05\\x61gent\\""%\\n\\x11RequestNewEpisode\\x12\\x10\\n\\x08ini_file\\x18\\x01 \\x01(\\t\\""\\x80\\x01\\n\\x10SceneDescription\\x12\\x10\\n\\x08map_name\\x18\\x03 \\x01(\\t\\x12\\x33\\n\\x12player_start_spots\\x18\\x01 \\x03(\\x0b\\x32\\x17.carla_server.Transform\\x12%\\n\\x07sensors\\x18\\x02 \\x03(\\x0b\\x32\\x14.carla_server.Sensor\\""/\\n\\x0c\\x45pisodeStart\\x12\\x1f\\n\\x17player_start_spot_index\\x18\\x01 \\x01(\\r\\""\\x1d\\n\\x0c\\x45pisodeReady\\x12\\r\\n\\x05ready\\x18\\x01 \\x01(\\x08\\""^\\n\\x07\\x43ontrol\\x12\\r\\n\\x05steer\\x18\\x01 \\x01(\\x02\\x12\\x10\\n\\x08throttle\\x18\\x02 \\x01(\\x02\\x12\\r\\n\\x05\\x62rake\\x18\\x03 \\x01(\\x02\\x12\\x12\\n\\nhand_brake\\x18\\x04 \\x01(\\x08\\x12\\x0f\\n\\x07reverse\\x18\\x05 \\x01(\\x08\\""\\xd1\\x04\\n\\x0cMeasurements\\x12\\x14\\n\\x0c\\x66rame_number\\x18\\x05 \\x01(\\x04\\x12\\x1a\\n\\x12platform_timestamp\\x18\\x01 \\x01(\\r\\x12\\x16\\n\\x0egame_timestamp\\x18\\x02 \\x01(\\r\\x12J\\n\\x13player_measurements\\x18\\x03 \\x01(\\x0b\\x32-.carla_server.Measurements.PlayerMeasurements\\x12.\\n\\x11non_player_agents\\x18\\x04 \\x03(\\x0b\\x32\\x13.carla_server.Agent\\x1a\\xfa\\x02\\n\\x12PlayerMeasurements\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12/\\n\\x0c\\x62ounding_box\\x18\\x0c \\x01(\\x0b\\x32\\x19.carla_server.BoundingBox\\x12,\\n\\x0c\\x61\\x63\\x63\\x65leration\\x18\\x03 \\x01(\\x0b\\x32\\x16.carla_server.Vector3D\\x12\\x15\\n\\rforward_speed\\x18\\x04 \\x01(\\x02\\x12\\x1a\\n\\x12\\x63ollision_vehicles\\x18\\x05 \\x01(\\x02\\x12\\x1d\\n\\x15\\x63ollision_pedestrians\\x18\\x06 \\x01(\\x02\\x12\\x17\\n\\x0f\\x63ollision_other\\x18\\x07 \\x01(\\x02\\x12\\x1e\\n\\x16intersection_otherlane\\x18\\x08 \\x01(\\x02\\x12\\x1c\\n\\x14intersection_offroad\\x18\\t \\x01(\\x02\\x12\\x30\\n\\x11\\x61utopilot_control\\x18\\n \\x01(\\x0b\\x32\\x15.carla_server.ControlB\\x03\\xf8\\x01\\x01\\x62\\x06proto3\')\n)\n\n\n\n_SENSOR_TYPE = _descriptor.EnumDescriptor(\n  name=\'Type\',\n  full_name=\'carla_server.Sensor.Type\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'UNKNOWN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAMERA\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LIDAR_RAY_CAST\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=463,\n  serialized_end=514,\n)\n_sym_db.RegisterEnumDescriptor(_SENSOR_TYPE)\n\n_TRAFFICLIGHT_STATE = _descriptor.EnumDescriptor(\n  name=\'State\',\n  full_name=\'carla_server.TrafficLight.State\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'GREEN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'YELLOW\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RED\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=884,\n  serialized_end=923,\n)\n_sym_db.RegisterEnumDescriptor(_TRAFFICLIGHT_STATE)\n\n\n_VECTOR3D = _descriptor.Descriptor(\n  name=\'Vector3D\',\n  full_name=\'carla_server.Vector3D\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'x\', full_name=\'carla_server.Vector3D.x\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'y\', full_name=\'carla_server.Vector3D.y\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'z\', full_name=\'carla_server.Vector3D.z\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=36,\n  serialized_end=79,\n)\n\n\n_ROTATION3D = _descriptor.Descriptor(\n  name=\'Rotation3D\',\n  full_name=\'carla_server.Rotation3D\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pitch\', full_name=\'carla_server.Rotation3D.pitch\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'yaw\', full_name=\'carla_server.Rotation3D.yaw\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'roll\', full_name=\'carla_server.Rotation3D.roll\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=81,\n  serialized_end=135,\n)\n\n\n_TRANSFORM = _descriptor.Descriptor(\n  name=\'Transform\',\n  full_name=\'carla_server.Transform\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'location\', full_name=\'carla_server.Transform.location\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'orientation\', full_name=\'carla_server.Transform.orientation\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\030\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'rotation\', full_name=\'carla_server.Transform.rotation\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=138,\n  serialized_end=284,\n)\n\n\n_BOUNDINGBOX = _descriptor.Descriptor(\n  name=\'BoundingBox\',\n  full_name=\'carla_server.BoundingBox\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.BoundingBox.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'extent\', full_name=\'carla_server.BoundingBox.extent\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=286,\n  serialized_end=383,\n)\n\n\n_SENSOR = _descriptor.Descriptor(\n  name=\'Sensor\',\n  full_name=\'carla_server.Sensor\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'id\', full_name=\'carla_server.Sensor.id\', index=0,\n      number=1, type=7, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'carla_server.Sensor.type\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'carla_server.Sensor.name\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SENSOR_TYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=386,\n  serialized_end=514,\n)\n\n\n_VEHICLE = _descriptor.Descriptor(\n  name=\'Vehicle\',\n  full_name=\'carla_server.Vehicle\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.Vehicle.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bounding_box\', full_name=\'carla_server.Vehicle.bounding_box\', index=1,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'forward_speed\', full_name=\'carla_server.Vehicle.forward_speed\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=516,\n  serialized_end=641,\n)\n\n\n_PEDESTRIAN = _descriptor.Descriptor(\n  name=\'Pedestrian\',\n  full_name=\'carla_server.Pedestrian\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.Pedestrian.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bounding_box\', full_name=\'carla_server.Pedestrian.bounding_box\', index=1,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'forward_speed\', full_name=\'carla_server.Pedestrian.forward_speed\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=644,\n  serialized_end=772,\n)\n\n\n_TRAFFICLIGHT = _descriptor.Descriptor(\n  name=\'TrafficLight\',\n  full_name=\'carla_server.TrafficLight\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.TrafficLight.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'carla_server.TrafficLight.state\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TRAFFICLIGHT_STATE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=775,\n  serialized_end=923,\n)\n\n\n_SPEEDLIMITSIGN = _descriptor.Descriptor(\n  name=\'SpeedLimitSign\',\n  full_name=\'carla_server.SpeedLimitSign\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.SpeedLimitSign.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'speed_limit\', full_name=\'carla_server.SpeedLimitSign.speed_limit\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=925,\n  serialized_end=1006,\n)\n\n\n_AGENT = _descriptor.Descriptor(\n  name=\'Agent\',\n  full_name=\'carla_server.Agent\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'id\', full_name=\'carla_server.Agent.id\', index=0,\n      number=1, type=7, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'vehicle\', full_name=\'carla_server.Agent.vehicle\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pedestrian\', full_name=\'carla_server.Agent.pedestrian\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'traffic_light\', full_name=\'carla_server.Agent.traffic_light\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'speed_limit_sign\', full_name=\'carla_server.Agent.speed_limit_sign\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'agent\', full_name=\'carla_server.Agent.agent\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=1009,\n  serialized_end=1238,\n)\n\n\n_REQUESTNEWEPISODE = _descriptor.Descriptor(\n  name=\'RequestNewEpisode\',\n  full_name=\'carla_server.RequestNewEpisode\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ini_file\', full_name=\'carla_server.RequestNewEpisode.ini_file\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1240,\n  serialized_end=1277,\n)\n\n\n_SCENEDESCRIPTION = _descriptor.Descriptor(\n  name=\'SceneDescription\',\n  full_name=\'carla_server.SceneDescription\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'map_name\', full_name=\'carla_server.SceneDescription.map_name\', index=0,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'player_start_spots\', full_name=\'carla_server.SceneDescription.player_start_spots\', index=1,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sensors\', full_name=\'carla_server.SceneDescription.sensors\', index=2,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1280,\n  serialized_end=1408,\n)\n\n\n_EPISODESTART = _descriptor.Descriptor(\n  name=\'EpisodeStart\',\n  full_name=\'carla_server.EpisodeStart\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'player_start_spot_index\', full_name=\'carla_server.EpisodeStart.player_start_spot_index\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1410,\n  serialized_end=1457,\n)\n\n\n_EPISODEREADY = _descriptor.Descriptor(\n  name=\'EpisodeReady\',\n  full_name=\'carla_server.EpisodeReady\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ready\', full_name=\'carla_server.EpisodeReady.ready\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1459,\n  serialized_end=1488,\n)\n\n\n_CONTROL = _descriptor.Descriptor(\n  name=\'Control\',\n  full_name=\'carla_server.Control\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'steer\', full_name=\'carla_server.Control.steer\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'throttle\', full_name=\'carla_server.Control.throttle\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'brake\', full_name=\'carla_server.Control.brake\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hand_brake\', full_name=\'carla_server.Control.hand_brake\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reverse\', full_name=\'carla_server.Control.reverse\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1490,\n  serialized_end=1584,\n)\n\n\n_MEASUREMENTS_PLAYERMEASUREMENTS = _descriptor.Descriptor(\n  name=\'PlayerMeasurements\',\n  full_name=\'carla_server.Measurements.PlayerMeasurements\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.Measurements.PlayerMeasurements.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bounding_box\', full_name=\'carla_server.Measurements.PlayerMeasurements.bounding_box\', index=1,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'acceleration\', full_name=\'carla_server.Measurements.PlayerMeasurements.acceleration\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'forward_speed\', full_name=\'carla_server.Measurements.PlayerMeasurements.forward_speed\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'collision_vehicles\', full_name=\'carla_server.Measurements.PlayerMeasurements.collision_vehicles\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'collision_pedestrians\', full_name=\'carla_server.Measurements.PlayerMeasurements.collision_pedestrians\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'collision_other\', full_name=\'carla_server.Measurements.PlayerMeasurements.collision_other\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'intersection_otherlane\', full_name=\'carla_server.Measurements.PlayerMeasurements.intersection_otherlane\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'intersection_offroad\', full_name=\'carla_server.Measurements.PlayerMeasurements.intersection_offroad\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'autopilot_control\', full_name=\'carla_server.Measurements.PlayerMeasurements.autopilot_control\', index=9,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1802,\n  serialized_end=2180,\n)\n\n_MEASUREMENTS = _descriptor.Descriptor(\n  name=\'Measurements\',\n  full_name=\'carla_server.Measurements\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'frame_number\', full_name=\'carla_server.Measurements.frame_number\', index=0,\n      number=5, type=4, cpp_type=4, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'platform_timestamp\', full_name=\'carla_server.Measurements.platform_timestamp\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'game_timestamp\', full_name=\'carla_server.Measurements.game_timestamp\', index=2,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'player_measurements\', full_name=\'carla_server.Measurements.player_measurements\', index=3,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'non_player_agents\', full_name=\'carla_server.Measurements.non_player_agents\', index=4,\n      number=4, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[_MEASUREMENTS_PLAYERMEASUREMENTS, ],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1587,\n  serialized_end=2180,\n)\n\n_TRANSFORM.fields_by_name[\'location\'].message_type = _VECTOR3D\n_TRANSFORM.fields_by_name[\'orientation\'].message_type = _VECTOR3D\n_TRANSFORM.fields_by_name[\'rotation\'].message_type = _ROTATION3D\n_BOUNDINGBOX.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_BOUNDINGBOX.fields_by_name[\'extent\'].message_type = _VECTOR3D\n_SENSOR.fields_by_name[\'type\'].enum_type = _SENSOR_TYPE\n_SENSOR_TYPE.containing_type = _SENSOR\n_VEHICLE.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_VEHICLE.fields_by_name[\'bounding_box\'].message_type = _BOUNDINGBOX\n_PEDESTRIAN.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_PEDESTRIAN.fields_by_name[\'bounding_box\'].message_type = _BOUNDINGBOX\n_TRAFFICLIGHT.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_TRAFFICLIGHT.fields_by_name[\'state\'].enum_type = _TRAFFICLIGHT_STATE\n_TRAFFICLIGHT_STATE.containing_type = _TRAFFICLIGHT\n_SPEEDLIMITSIGN.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_AGENT.fields_by_name[\'vehicle\'].message_type = _VEHICLE\n_AGENT.fields_by_name[\'pedestrian\'].message_type = _PEDESTRIAN\n_AGENT.fields_by_name[\'traffic_light\'].message_type = _TRAFFICLIGHT\n_AGENT.fields_by_name[\'speed_limit_sign\'].message_type = _SPEEDLIMITSIGN\n_AGENT.oneofs_by_name[\'agent\'].fields.append(\n  _AGENT.fields_by_name[\'vehicle\'])\n_AGENT.fields_by_name[\'vehicle\'].containing_oneof = _AGENT.oneofs_by_name[\'agent\']\n_AGENT.oneofs_by_name[\'agent\'].fields.append(\n  _AGENT.fields_by_name[\'pedestrian\'])\n_AGENT.fields_by_name[\'pedestrian\'].containing_oneof = _AGENT.oneofs_by_name[\'agent\']\n_AGENT.oneofs_by_name[\'agent\'].fields.append(\n  _AGENT.fields_by_name[\'traffic_light\'])\n_AGENT.fields_by_name[\'traffic_light\'].containing_oneof = _AGENT.oneofs_by_name[\'agent\']\n_AGENT.oneofs_by_name[\'agent\'].fields.append(\n  _AGENT.fields_by_name[\'speed_limit_sign\'])\n_AGENT.fields_by_name[\'speed_limit_sign\'].containing_oneof = _AGENT.oneofs_by_name[\'agent\']\n_SCENEDESCRIPTION.fields_by_name[\'player_start_spots\'].message_type = _TRANSFORM\n_SCENEDESCRIPTION.fields_by_name[\'sensors\'].message_type = _SENSOR\n_MEASUREMENTS_PLAYERMEASUREMENTS.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_MEASUREMENTS_PLAYERMEASUREMENTS.fields_by_name[\'bounding_box\'].message_type = _BOUNDINGBOX\n_MEASUREMENTS_PLAYERMEASUREMENTS.fields_by_name[\'acceleration\'].message_type = _VECTOR3D\n_MEASUREMENTS_PLAYERMEASUREMENTS.fields_by_name[\'autopilot_control\'].message_type = _CONTROL\n_MEASUREMENTS_PLAYERMEASUREMENTS.containing_type = _MEASUREMENTS\n_MEASUREMENTS.fields_by_name[\'player_measurements\'].message_type = _MEASUREMENTS_PLAYERMEASUREMENTS\n_MEASUREMENTS.fields_by_name[\'non_player_agents\'].message_type = _AGENT\nDESCRIPTOR.message_types_by_name[\'Vector3D\'] = _VECTOR3D\nDESCRIPTOR.message_types_by_name[\'Rotation3D\'] = _ROTATION3D\nDESCRIPTOR.message_types_by_name[\'Transform\'] = _TRANSFORM\nDESCRIPTOR.message_types_by_name[\'BoundingBox\'] = _BOUNDINGBOX\nDESCRIPTOR.message_types_by_name[\'Sensor\'] = _SENSOR\nDESCRIPTOR.message_types_by_name[\'Vehicle\'] = _VEHICLE\nDESCRIPTOR.message_types_by_name[\'Pedestrian\'] = _PEDESTRIAN\nDESCRIPTOR.message_types_by_name[\'TrafficLight\'] = _TRAFFICLIGHT\nDESCRIPTOR.message_types_by_name[\'SpeedLimitSign\'] = _SPEEDLIMITSIGN\nDESCRIPTOR.message_types_by_name[\'Agent\'] = _AGENT\nDESCRIPTOR.message_types_by_name[\'RequestNewEpisode\'] = _REQUESTNEWEPISODE\nDESCRIPTOR.message_types_by_name[\'SceneDescription\'] = _SCENEDESCRIPTION\nDESCRIPTOR.message_types_by_name[\'EpisodeStart\'] = _EPISODESTART\nDESCRIPTOR.message_types_by_name[\'EpisodeReady\'] = _EPISODEREADY\nDESCRIPTOR.message_types_by_name[\'Control\'] = _CONTROL\nDESCRIPTOR.message_types_by_name[\'Measurements\'] = _MEASUREMENTS\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nVector3D = _reflection.GeneratedProtocolMessageType(\'Vector3D\', (_message.Message,), dict(\n  DESCRIPTOR = _VECTOR3D,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Vector3D)\n  ))\n_sym_db.RegisterMessage(Vector3D)\n\nRotation3D = _reflection.GeneratedProtocolMessageType(\'Rotation3D\', (_message.Message,), dict(\n  DESCRIPTOR = _ROTATION3D,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Rotation3D)\n  ))\n_sym_db.RegisterMessage(Rotation3D)\n\nTransform = _reflection.GeneratedProtocolMessageType(\'Transform\', (_message.Message,), dict(\n  DESCRIPTOR = _TRANSFORM,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Transform)\n  ))\n_sym_db.RegisterMessage(Transform)\n\nBoundingBox = _reflection.GeneratedProtocolMessageType(\'BoundingBox\', (_message.Message,), dict(\n  DESCRIPTOR = _BOUNDINGBOX,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.BoundingBox)\n  ))\n_sym_db.RegisterMessage(BoundingBox)\n\nSensor = _reflection.GeneratedProtocolMessageType(\'Sensor\', (_message.Message,), dict(\n  DESCRIPTOR = _SENSOR,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Sensor)\n  ))\n_sym_db.RegisterMessage(Sensor)\n\nVehicle = _reflection.GeneratedProtocolMessageType(\'Vehicle\', (_message.Message,), dict(\n  DESCRIPTOR = _VEHICLE,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Vehicle)\n  ))\n_sym_db.RegisterMessage(Vehicle)\n\nPedestrian = _reflection.GeneratedProtocolMessageType(\'Pedestrian\', (_message.Message,), dict(\n  DESCRIPTOR = _PEDESTRIAN,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Pedestrian)\n  ))\n_sym_db.RegisterMessage(Pedestrian)\n\nTrafficLight = _reflection.GeneratedProtocolMessageType(\'TrafficLight\', (_message.Message,), dict(\n  DESCRIPTOR = _TRAFFICLIGHT,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.TrafficLight)\n  ))\n_sym_db.RegisterMessage(TrafficLight)\n\nSpeedLimitSign = _reflection.GeneratedProtocolMessageType(\'SpeedLimitSign\', (_message.Message,), dict(\n  DESCRIPTOR = _SPEEDLIMITSIGN,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.SpeedLimitSign)\n  ))\n_sym_db.RegisterMessage(SpeedLimitSign)\n\nAgent = _reflection.GeneratedProtocolMessageType(\'Agent\', (_message.Message,), dict(\n  DESCRIPTOR = _AGENT,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Agent)\n  ))\n_sym_db.RegisterMessage(Agent)\n\nRequestNewEpisode = _reflection.GeneratedProtocolMessageType(\'RequestNewEpisode\', (_message.Message,), dict(\n  DESCRIPTOR = _REQUESTNEWEPISODE,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.RequestNewEpisode)\n  ))\n_sym_db.RegisterMessage(RequestNewEpisode)\n\nSceneDescription = _reflection.GeneratedProtocolMessageType(\'SceneDescription\', (_message.Message,), dict(\n  DESCRIPTOR = _SCENEDESCRIPTION,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.SceneDescription)\n  ))\n_sym_db.RegisterMessage(SceneDescription)\n\nEpisodeStart = _reflection.GeneratedProtocolMessageType(\'EpisodeStart\', (_message.Message,), dict(\n  DESCRIPTOR = _EPISODESTART,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.EpisodeStart)\n  ))\n_sym_db.RegisterMessage(EpisodeStart)\n\nEpisodeReady = _reflection.GeneratedProtocolMessageType(\'EpisodeReady\', (_message.Message,), dict(\n  DESCRIPTOR = _EPISODEREADY,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.EpisodeReady)\n  ))\n_sym_db.RegisterMessage(EpisodeReady)\n\nControl = _reflection.GeneratedProtocolMessageType(\'Control\', (_message.Message,), dict(\n  DESCRIPTOR = _CONTROL,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Control)\n  ))\n_sym_db.RegisterMessage(Control)\n\nMeasurements = _reflection.GeneratedProtocolMessageType(\'Measurements\', (_message.Message,), dict(\n\n  PlayerMeasurements = _reflection.GeneratedProtocolMessageType(\'PlayerMeasurements\', (_message.Message,), dict(\n    DESCRIPTOR = _MEASUREMENTS_PLAYERMEASUREMENTS,\n    __module__ = \'carla_server_pb2\'\n    # @@protoc_insertion_point(class_scope:carla_server.Measurements.PlayerMeasurements)\n    ))\n  ,\n  DESCRIPTOR = _MEASUREMENTS,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Measurements)\n  ))\n_sym_db.RegisterMessage(Measurements)\n_sym_db.RegisterMessage(Measurements.PlayerMeasurements)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(\'\\370\\001\\001\'))\n_TRANSFORM.fields_by_name[\'orientation\'].has_options = True\n_TRANSFORM.fields_by_name[\'orientation\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\030\\001\'))\n# @@protoc_insertion_point(module_scope)\n'"
ch7/carla-gym/carla_gym/envs/carla/client.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""CARLA Client.""""""\n\nimport logging\nimport struct\n\nfrom contextlib import contextmanager\n\nfrom . import sensor\nfrom . import tcp\nfrom . import util\n\ntry:\n    from . import carla_server_pb2 as carla_protocol\nexcept ImportError:\n    raise RuntimeError(\'cannot import ""carla_server_pb2.py"", run the protobuf compiler to generate this file\')\n\ntry:\n    import numpy\nexcept ImportError:\n    raise RuntimeError(\'cannot import numpy, make sure numpy package is installed.\')\n\n\nVehicleControl = carla_protocol.Control\n\n\n@contextmanager\ndef make_carla_client(host, world_port, timeout=15):\n    """"""Context manager for creating and connecting a CarlaClient.""""""\n    with util.make_connection(CarlaClient, host, world_port, timeout) as client:\n        yield client\n\n\nclass CarlaClient(object):\n    """"""The CARLA client. Manages communications with the CARLA server.""""""\n\n    def __init__(self, host, world_port, timeout=15):\n        self._world_client = tcp.TCPClient(host, world_port, timeout)\n        self._stream_client = tcp.TCPClient(host, world_port + 1, timeout)\n        self._control_client = tcp.TCPClient(host, world_port + 2, timeout)\n        self._current_settings = None\n        self._is_episode_requested = False\n        self._sensors = {}\n\n    def connect(self, connection_attempts=10):\n        """"""\n        Try to establish a connection to a CARLA server at the given host:port.\n        """"""\n        self._world_client.connect(connection_attempts)\n\n    def disconnect(self):\n        """"""Disconnect from server.""""""\n        self._control_client.disconnect()\n        self._stream_client.disconnect()\n        self._world_client.disconnect()\n\n    def connected(self):\n        """"""Return whether there is an active connection.""""""\n        return self._world_client.connected()\n\n    def load_settings(self, carla_settings):\n        """"""\n        Load new settings and request a new episode based on these settings.\n        carla_settings object must be convertible to a str holding the contents\n        of a CarlaSettings.ini file.\n\n        Return a protobuf object holding the scene description.\n        """"""\n        self._current_settings = carla_settings\n        return self._request_new_episode(carla_settings)\n\n    def start_episode(self, player_start_index):\n        """"""\n        Start the new episode at the player start given by the\n        player_start_index. The list of player starts is retrieved by\n        ""load_settings"".\n\n        The new episode is started based on the last settings loaded by\n        ""load_settings"".\n\n        This function waits until the server answers with an EpisodeReady.\n        """"""\n        if self._current_settings is None:\n            raise RuntimeError(\'no settings loaded, cannot start episode\')\n\n        # if no new settings are loaded, request new episode with previous\n        if not self._is_episode_requested:\n            self._request_new_episode(self._current_settings)\n\n        try:\n            pb_message = carla_protocol.EpisodeStart()\n            pb_message.player_start_spot_index = player_start_index\n            self._world_client.write(pb_message.SerializeToString())\n            # Wait for EpisodeReady.\n            data = self._world_client.read()\n            if not data:\n                raise RuntimeError(\'failed to read data from server\')\n            pb_message = carla_protocol.EpisodeReady()\n            pb_message.ParseFromString(data)\n            if not pb_message.ready:\n                raise RuntimeError(\'cannot start episode: server failed to start episode\')\n            # We can start the agent clients now.\n            self._stream_client.connect()\n            self._control_client.connect()\n            # Set again the status for no episode requested\n        finally:\n            self._is_episode_requested = False\n\n    def read_data(self):\n        """"""\n        Read the data sent from the server this frame. The episode must be\n        started. Return a pair containing the protobuf object containing the\n        measurements followed by the raw data of the sensors.\n        """"""\n        # Read measurements.\n        data = self._stream_client.read()\n        if not data:\n            raise RuntimeError(\'failed to read data from server\')\n        pb_message = carla_protocol.Measurements()\n        pb_message.ParseFromString(data)\n        # Read sensor data.\n        return pb_message, dict(x for x in self._read_sensor_data())\n\n    def send_control(self, *args, **kwargs):\n        """"""\n        Send the VehicleControl to be applied this frame.\n\n        If synchronous mode was requested, the server will pause the simulation\n        until this message is received.\n        """"""\n        if isinstance(args[0] if args else None, carla_protocol.Control):\n            pb_message = args[0]\n        else:\n            pb_message = carla_protocol.Control()\n            pb_message.steer = kwargs.get(\'steer\', 0.0)\n            pb_message.throttle = kwargs.get(\'throttle\', 0.0)\n            pb_message.brake = kwargs.get(\'brake\', 0.0)\n            pb_message.hand_brake = kwargs.get(\'hand_brake\', False)\n            pb_message.reverse = kwargs.get(\'reverse\', False)\n        self._control_client.write(pb_message.SerializeToString())\n\n    def _request_new_episode(self, carla_settings):\n        """"""\n        Internal function to request a new episode. Prepare the client for a new\n        episode by disconnecting agent clients.\n        """"""\n        # Disconnect agent clients.\n        self._stream_client.disconnect()\n        self._control_client.disconnect()\n        # Send new episode request.\n        pb_message = carla_protocol.RequestNewEpisode()\n        pb_message.ini_file = str(carla_settings)\n        self._world_client.write(pb_message.SerializeToString())\n        # Read scene description.\n        data = self._world_client.read()\n        if not data:\n            raise RuntimeError(\'failed to read data from server\')\n        pb_message = carla_protocol.SceneDescription()\n        pb_message.ParseFromString(data)\n        self._sensors = dict((sensor.id, sensor) \\\n            for sensor in _make_sensor_parsers(pb_message.sensors))\n        self._is_episode_requested = True\n        return pb_message\n\n    def _read_sensor_data(self):\n        while True:\n            data = self._stream_client.read()\n            if not data:\n                raise StopIteration\n            yield self._parse_sensor_data(data)\n\n    def _parse_sensor_data(self, data):\n        sensor_id = struct.unpack(\'<L\', data[0:4])[0]\n        parser = self._sensors[sensor_id]\n        return parser.name, parser.parse_raw_data(data[4:])\n\n\ndef _make_sensor_parsers(sensors):\n    image_types = [\'None\', \'SceneFinal\', \'Depth\', \'SemanticSegmentation\']\n    getimgtype = lambda id: image_types[id] if len(image_types) > id else \'Unknown\'\n    getint32 = lambda data, index: struct.unpack(\'<L\', data[index*4:index*4+4])[0]\n    getint64 = lambda data, index: struct.unpack(\'<Q\', data[index*4:index*4+8])[0]\n    getfloat = lambda data, index: struct.unpack(\'<f\', data[index*4:index*4+4])[0]\n\n    def parse_image(data):\n        frame_number = getint64(data, 0)\n        width = getint32(data, 2)\n        height = getint32(data, 3)\n        image_type = getimgtype(getint32(data, 4))\n        fov = getfloat(data, 5)\n        return sensor.Image(frame_number, width, height, image_type, fov, data[24:])\n\n    def parse_lidar(data):\n        frame_number = getint64(data, 0)\n        horizontal_angle = getfloat(data, 2)\n        channels = getint32(data, 3)\n        header_size = 16\n        point_count_by_channel = numpy.frombuffer(\n            data[header_size:header_size+channels*4],\n            dtype=numpy.dtype(\'uint32\'))\n        points = numpy.frombuffer(\n            data[header_size+channels*4:],\n            dtype=numpy.dtype(\'f4\'))\n        points = numpy.reshape(points, (int(points.shape[0]/3), 3))\n        return sensor.LidarMeasurement(\n            frame_number,\n            horizontal_angle,\n            channels,\n            point_count_by_channel,\n            sensor.PointCloud(frame_number, points))\n\n    class SensorDefinition(object):\n        def __init__(self, s):\n            self.id = s.id\n            self.name = s.name\n            self.type = s.type\n            self.parse_raw_data = lambda x: x\n\n    for s in sensors:\n        sensor_def = SensorDefinition(s)\n        if sensor_def.type == carla_protocol.Sensor.CAMERA:\n            sensor_def.parse_raw_data = parse_image\n        elif sensor_def.type == carla_protocol.Sensor.LIDAR_RAY_CAST:\n            sensor_def.parse_raw_data = parse_lidar\n        else:\n            logging.error(\'unknown sensor type %s\', sensor_def.type)\n        yield sensor_def\n'"
ch7/carla-gym/carla_gym/envs/carla/image_converter.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""\nHandy conversions for CARLA images.\n\nThe functions here are provided for real-time display, if you want to save the\nconverted images, save the images from Python without conversion and convert\nthem afterwards with the C++ implementation at ""Util/ImageConverter"" as it\nprovides considerably better performance.\n""""""\n\nimport math\n\ntry:\n    import numpy\n    from numpy.matlib import repmat\nexcept ImportError:\n    raise RuntimeError(\'cannot import numpy, make sure numpy package is installed\')\n\n\nfrom . import sensor\n\n\ndef to_bgra_array(image):\n    """"""Convert a CARLA raw image to a BGRA numpy array.""""""\n    if not isinstance(image, sensor.Image):\n        raise ValueError(""Argument must be a carla.sensor.Image"")\n    array = numpy.frombuffer(image.raw_data, dtype=numpy.dtype(""uint8""))\n    array = numpy.reshape(array, (image.height, image.width, 4))\n    return array\n\n\ndef to_rgb_array(image):\n    """"""Convert a CARLA raw image to a RGB numpy array.""""""\n    array = to_bgra_array(image)\n    # Convert BGRA to RGB.\n    array = array[:, :, :3]\n    array = array[:, :, ::-1]\n    return array\n\n\ndef labels_to_array(image):\n    """"""\n    Convert an image containing CARLA semantic segmentation labels to a 2D array\n    containing the label of each pixel.\n    """"""\n    return to_bgra_array(image)[:, :, 2]\n\n\ndef labels_to_cityscapes_palette(image):\n    """"""\n    Convert an image containing CARLA semantic segmentation labels to\n    Cityscapes palette.\n    """"""\n    classes = {\n        0: [0, 0, 0],         # None\n        1: [70, 70, 70],      # Buildings\n        2: [190, 153, 153],   # Fences\n        3: [72, 0, 90],       # Other\n        4: [220, 20, 60],     # Pedestrians\n        5: [153, 153, 153],   # Poles\n        6: [157, 234, 50],    # RoadLines\n        7: [128, 64, 128],    # Roads\n        8: [244, 35, 232],    # Sidewalks\n        9: [107, 142, 35],    # Vegetation\n        10: [0, 0, 255],      # Vehicles\n        11: [102, 102, 156],  # Walls\n        12: [220, 220, 0]     # TrafficSigns\n    }\n    array = labels_to_array(image)\n    result = numpy.zeros((array.shape[0], array.shape[1], 3))\n    for key, value in classes.items():\n        result[numpy.where(array == key)] = value\n    return result\n\n\ndef depth_to_array(image):\n    """"""\n    Convert an image containing CARLA encoded depth-map to a 2D array containing\n    the depth value of each pixel normalized between [0.0, 1.0].\n    """"""\n    array = to_bgra_array(image)\n    array = array.astype(numpy.float32)\n    # Apply (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1).\n    normalized_depth = numpy.dot(array[:, :, :3], [65536.0, 256.0, 1.0])\n    normalized_depth /= 16777215.0  # (256.0 * 256.0 * 256.0 - 1.0)\n    return normalized_depth\n\n\ndef depth_to_logarithmic_grayscale(image):\n    """"""\n    Convert an image containing CARLA encoded depth-map to a logarithmic\n    grayscale image array.\n    ""max_depth"" is used to omit the points that are far enough.\n    """"""\n    normalized_depth = depth_to_array(image)\n    # Convert to logarithmic depth.\n    logdepth = numpy.ones(normalized_depth.shape) + \\\n        (numpy.log(normalized_depth) / 5.70378)\n    logdepth = numpy.clip(logdepth, 0.0, 1.0)\n    logdepth *= 255.0\n    # Expand to three colors.\n    return numpy.repeat(logdepth[:, :, numpy.newaxis], 3, axis=2)\n\n\ndef depth_to_local_point_cloud(image, color=None, max_depth=0.9):\n    """"""\n    Convert an image containing CARLA encoded depth-map to a 2D array containing\n    the 3D position (relative to the camera) of each pixel and its corresponding\n    RGB color of an array.\n    ""max_depth"" is used to omit the points that are far enough.\n    """"""\n    far = 1000.0  # max depth in meters.\n    normalized_depth = depth_to_array(image)\n\n    # (Intrinsic) K Matrix\n    k = numpy.identity(3)\n    k[0, 2] = image.width / 2.0\n    k[1, 2] = image.height / 2.0\n    k[0, 0] = k[1, 1] = image.width / \\\n        (2.0 * math.tan(image.fov * math.pi / 360.0))\n\n    # 2d pixel coordinates\n    pixel_length = image.width * image.height\n    u_coord = repmat(numpy.r_[image.width-1:-1:-1],\n                     image.height, 1).reshape(pixel_length)\n    v_coord = repmat(numpy.c_[image.height-1:-1:-1],\n                     1, image.width).reshape(pixel_length)\n    if color is not None:\n        color = color.reshape(pixel_length, 3)\n    normalized_depth = numpy.reshape(normalized_depth, pixel_length)\n\n    # Search for pixels where the depth is greater than max_depth to\n    # delete them\n    max_depth_indexes = numpy.where(normalized_depth > max_depth)\n    normalized_depth = numpy.delete(normalized_depth, max_depth_indexes)\n    u_coord = numpy.delete(u_coord, max_depth_indexes)\n    v_coord = numpy.delete(v_coord, max_depth_indexes)\n    if color is not None:\n        color = numpy.delete(color, max_depth_indexes, axis=0)\n\n    # pd2 = [u,v,1]\n    p2d = numpy.array([u_coord, v_coord, numpy.ones_like(u_coord)])\n\n    # P = [X,Y,Z]\n    p3d = numpy.dot(numpy.linalg.inv(k), p2d)\n    p3d *= normalized_depth * far\n\n    # Formating the output to:\n    # [[X1,Y1,Z1,R1,G1,B1],[X2,Y2,Z2,R2,G2,B2], ... [Xn,Yn,Zn,Rn,Gn,Bn]]\n    if color is not None:\n        # numpy.concatenate((numpy.transpose(p3d), color), axis=1)\n        return sensor.PointCloud(\n            image.frame_number,\n            numpy.transpose(p3d),\n            color_array=color)\n    # [[X1,Y1,Z1],[X2,Y2,Z2], ... [Xn,Yn,Zn]]\n    return sensor.PointCloud(image.frame_number, numpy.transpose(p3d))\n'"
ch7/carla-gym/carla_gym/envs/carla/sensor.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""CARLA sensors.""""""\n\n\nimport os\n\nfrom collections import namedtuple\n\ntry:\n    import numpy\nexcept ImportError:\n    raise RuntimeError(\'cannot import numpy, make sure numpy package is installed.\')\n\nfrom .transform import Transform, Translation, Rotation, Scale\n\n\n# ==============================================================================\n# -- Helpers -------------------------------------------------------------------\n# ==============================================================================\n\n\nColor = namedtuple(\'Color\', \'r g b\')\nColor.__new__.__defaults__ = (0, 0, 0)\n\n\nPoint = namedtuple(\'Point\', \'x y z color\')\nPoint.__new__.__defaults__ = (0.0, 0.0, 0.0, None)\n\n\ndef _append_extension(filename, ext):\n    return filename if filename.lower().endswith(ext.lower()) else filename + ext\n\n\n# ==============================================================================\n# -- Sensor --------------------------------------------------------------------\n# ==============================================================================\n\n\nclass Sensor(object):\n    """"""\n    Base class for sensor descriptions. Used to add sensors to CarlaSettings.\n    """"""\n\n    def __init__(self, name, sensor_type):\n        self.SensorName = name\n        self.SensorType = sensor_type\n        self.PositionX = 0.2\n        self.PositionY = 0.0\n        self.PositionZ = 1.3\n        self.RotationPitch = 0.0\n        self.RotationRoll = 0.0\n        self.RotationYaw = 0.0\n\n    def set(self, **kwargs):\n        for key, value in kwargs.items():\n            if not hasattr(self, key):\n                raise ValueError(\'sensor.Sensor: no key named %r\' % key)\n            setattr(self, key, value)\n\n    def set_position(self, x, y, z):\n        self.PositionX = x\n        self.PositionY = y\n        self.PositionZ = z\n\n    def set_rotation(self, pitch, yaw, roll):\n        self.RotationPitch = pitch\n        self.RotationYaw = yaw\n        self.RotationRoll = roll\n\n    def get_transform(self):\n        \'\'\'\n        Returns the camera to [whatever the camera is attached to]\n        transformation.\n        \'\'\'\n        return Transform(\n            Translation(self.PositionX, self.PositionY, self.PositionZ),\n            Rotation(self.RotationPitch, self.RotationYaw, self.RotationRoll))\n\n    def get_unreal_transform(self):\n        \'\'\'\n        Returns the camera to [whatever the camera is attached to]\n        transformation with the Unreal necessary corrections applied.\n\n        @todo Do we need to expose this?\n        \'\'\'\n        to_unreal_transform = Transform(Rotation(roll=-90, yaw=90), Scale(x=-1))\n        return self.get_transform() * to_unreal_transform\n\n\nclass Camera(Sensor):\n    """"""\n    Camera description. This class can be added to a CarlaSettings object to add\n    a camera to the player vehicle.\n    """"""\n\n    def __init__(self, name, **kwargs):\n        super(Camera, self).__init__(name, sensor_type=""CAMERA"")\n        self.PostProcessing = \'SceneFinal\'\n        self.ImageSizeX = 720\n        self.ImageSizeY = 512\n        self.FOV = 90.0\n        self.set(**kwargs)\n\n    def set_image_size(self, pixels_x, pixels_y):\n        \'\'\'Sets the image size in pixels\'\'\'\n        self.ImageSizeX = pixels_x\n        self.ImageSizeY = pixels_y\n\n\nclass Lidar(Sensor):\n    """"""\n    Lidar description. This class can be added to a CarlaSettings object to add\n    a Lidar to the player vehicle.\n    """"""\n\n    def __init__(self, name, **kwargs):\n        super(Lidar, self).__init__(name, sensor_type=""LIDAR_RAY_CAST"")\n        self.Channels = 32\n        self.Range = 50.0\n        self.PointsPerSecond = 56000\n        self.RotationFrequency = 10.0\n        self.UpperFovLimit = 10.0\n        self.LowerFovLimit = -30.0\n        self.ShowDebugPoints = False\n        self.set(**kwargs)\n\n\n# ==============================================================================\n# -- SensorData ----------------------------------------------------------------\n# ==============================================================================\n\n\nclass SensorData(object):\n    """"""Base class for sensor data returned from the server.""""""\n    def __init__(self, frame_number):\n        self.frame_number = frame_number\n\n\nclass Image(SensorData):\n    """"""Data generated by a Camera.""""""\n\n    def __init__(self, frame_number, width, height, image_type, fov, raw_data):\n        super(Image, self).__init__(frame_number=frame_number)\n        assert len(raw_data) == 4 * width * height\n        self.width = width\n        self.height = height\n        self.type = image_type\n        self.fov = fov\n        self.raw_data = raw_data\n        self._converted_data = None\n\n    @property\n    def data(self):\n        """"""\n        Lazy initialization for data property, stores converted data in its\n        default format.\n        """"""\n        if self._converted_data is None:\n            from . import image_converter\n\n            if self.type == \'Depth\':\n                self._converted_data = image_converter.depth_to_array(self)\n            elif self.type == \'SemanticSegmentation\':\n                self._converted_data = image_converter.labels_to_array(self)\n            else:\n                self._converted_data = image_converter.to_rgb_array(self)\n        return self._converted_data\n\n    def save_to_disk(self, filename):\n        """"""Save this image to disk (requires PIL installed).""""""\n        filename = _append_extension(filename, \'.png\')\n\n        try:\n            from PIL import Image as PImage\n        except ImportError:\n            raise RuntimeError(\n                \'cannot import PIL, make sure pillow package is installed\')\n\n        image = PImage.frombytes(\n            mode=\'RGBA\',\n            size=(self.width, self.height),\n            data=self.raw_data,\n            decoder_name=\'raw\')\n        color = image.split()\n        image = PImage.merge(""RGB"", color[2::-1])\n\n        folder = os.path.dirname(filename)\n        if not os.path.isdir(folder):\n            os.makedirs(folder)\n        image.save(filename)\n\n\nclass PointCloud(SensorData):\n    """"""A list of points.""""""\n\n    def __init__(self, frame_number, array, color_array=None):\n        super(PointCloud, self).__init__(frame_number=frame_number)\n        self._array = array\n        self._color_array = color_array\n        self._has_colors = color_array is not None\n\n    @property\n    def array(self):\n        """"""The numpy array holding the point-cloud.\n\n        3D points format for n elements:\n        [ [X0,Y0,Z0],\n          ...,\n          [Xn,Yn,Zn] ]\n        """"""\n        return self._array\n\n    @property\n    def color_array(self):\n        """"""The numpy array holding the colors corresponding to each point.\n        It is None if there are no colors.\n\n        Colors format for n elements:\n        [ [R0,G0,B0],\n          ...,\n          [Rn,Gn,Bn] ]\n        """"""\n        return self._color_array\n\n    def has_colors(self):\n        """"""Return whether the points have color.""""""\n        return self._has_colors\n\n    def apply_transform(self, transformation):\n        """"""Modify the PointCloud instance transforming its points""""""\n        self._array = transformation.transform_points(self._array)\n\n    def save_to_disk(self, filename):\n        """"""Save this point-cloud to disk as PLY format.""""""\n        filename = _append_extension(filename, \'.ply\')\n\n        def construct_ply_header():\n            """"""Generates a PLY header given a total number of 3D points and\n            coloring property if specified\n            """"""\n            points = len(self)  # Total point number\n            header = [\'ply\',\n                      \'format ascii 1.0\',\n                      \'element vertex {}\',\n                      \'property float32 x\',\n                      \'property float32 y\',\n                      \'property float32 z\',\n                      \'property uchar diffuse_red\',\n                      \'property uchar diffuse_green\',\n                      \'property uchar diffuse_blue\',\n                      \'end_header\']\n            if not self._has_colors:\n                return \'\\n\'.join(header[0:6] + [header[-1]]).format(points)\n            return \'\\n\'.join(header).format(points)\n\n        if not self._has_colors:\n            ply = \'\\n\'.join([\'{:.2f} {:.2f} {:.2f}\'.format(\n                *p) for p in self._array.tolist()])\n        else:\n            points_3d = numpy.concatenate(\n                (self._array, self._color_array), axis=1)\n            ply = \'\\n\'.join([\'{:.2f} {:.2f} {:.2f} {:.0f} {:.0f} {:.0f}\'\n                             .format(*p) for p in points_3d.tolist()])\n\n        # Create folder to save if does not exist.\n        folder = os.path.dirname(filename)\n        if not os.path.isdir(folder):\n            os.makedirs(folder)\n\n        # Open the file and save with the specific PLY format.\n        with open(filename, \'w+\') as ply_file:\n            ply_file.write(\'\\n\'.join([construct_ply_header(), ply]))\n\n    def __len__(self):\n        return len(self.array)\n\n    def __getitem__(self, key):\n        color = None if self._color_array is None else Color(\n            *self._color_array[key])\n        return Point(*self._array[key], color=color)\n\n    def __iter__(self):\n        class PointIterator(object):\n            """"""Iterator class for PointCloud""""""\n\n            def __init__(self, point_cloud):\n                self.point_cloud = point_cloud\n                self.index = -1\n\n            def __next__(self):\n                self.index += 1\n                if self.index >= len(self.point_cloud):\n                    raise StopIteration\n                return self.point_cloud[self.index]\n\n            def next(self):\n                return self.__next__()\n\n        return PointIterator(self)\n\n    def __str__(self):\n        return str(self.array)\n\n\nclass LidarMeasurement(SensorData):\n    """"""Data generated by a Lidar.""""""\n\n    def __init__(self, frame_number, horizontal_angle, channels, point_count_by_channel, point_cloud):\n        super(LidarMeasurement, self).__init__(frame_number=frame_number)\n        assert numpy.sum(point_count_by_channel) == len(point_cloud.array)\n        self.horizontal_angle = horizontal_angle\n        self.channels = channels\n        self.point_count_by_channel = point_count_by_channel\n        self.point_cloud = point_cloud\n\n    @property\n    def data(self):\n        """"""The numpy array holding the point-cloud.\n\n        3D points format for n elements:\n        [ [X0,Y0,Z0],\n          ...,\n          [Xn,Yn,Zn] ]\n        """"""\n        return self.point_cloud.array\n\n    def save_to_disk(self, filename):\n        """"""Save point-cloud to disk as PLY format.""""""\n        self.point_cloud.save_to_disk(filename)\n'"
ch7/carla-gym/carla_gym/envs/carla/settings.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""CARLA Settings""""""\n\nimport io\nimport random\nimport sys\n\n\nif sys.version_info >= (3, 0):\n\n    from configparser import ConfigParser\n\nelse:\n\n    from ConfigParser import RawConfigParser as ConfigParser\n\n\nfrom . import sensor as carla_sensor\n\n\nMAX_NUMBER_OF_WEATHER_IDS = 14\n\n\nclass CarlaSettings(object):\n    """"""\n    The CarlaSettings object controls the settings of an episode.  The __str__\n    method retrieves an str with a CarlaSettings.ini file contents.\n    """"""\n\n    def __init__(self, **kwargs):\n        # [CARLA/Server]\n        self.SynchronousMode = True\n        self.SendNonPlayerAgentsInfo = False\n        # [CARLA/QualitySettings]\n        self.QualityLevel = \'Epic\'\n        # [CARLA/LevelSettings]\n        self.PlayerVehicle = None\n        self.NumberOfVehicles = 20\n        self.NumberOfPedestrians = 30\n        self.WeatherId = 1\n        self.SeedVehicles = None\n        self.SeedPedestrians = None\n        self.set(**kwargs)\n        self._sensors = []\n\n    def set(self, **kwargs):\n        for key, value in kwargs.items():\n            if not hasattr(self, key):\n                raise ValueError(\'CarlaSettings: no key named %r\' % key)\n            setattr(self, key, value)\n\n    def randomize_seeds(self):\n        """"""\n        Randomize the seeds of the new episode\'s pseudo-random number\n        generators.\n        """"""\n        self.SeedVehicles = random.getrandbits(16)\n        self.SeedPedestrians = random.getrandbits(16)\n\n    def randomize_weather(self):\n        """"""Randomized the WeatherId.""""""\n        self.WeatherId = random.randint(0, MAX_NUMBER_OF_WEATHER_IDS)\n\n    def add_sensor(self, sensor):\n        """"""Add a sensor to the player vehicle (see sensor.py).""""""\n        if not isinstance(sensor, carla_sensor.Sensor):\n            raise ValueError(\'Sensor not supported\')\n        self._sensors.append(sensor)\n\n    def __str__(self):\n        """"""Converts this object to an INI formatted string.""""""\n        ini = ConfigParser()\n        ini.optionxform = str\n        S_SERVER = \'CARLA/Server\'\n        S_QUALITY = \'CARLA/QualitySettings\'\n        S_LEVEL = \'CARLA/LevelSettings\'\n        S_SENSOR = \'CARLA/Sensor\'\n\n        def get_attribs(obj):\n            return [a for a in dir(obj) if not a.startswith(\'_\') and not callable(getattr(obj, a))]\n\n        def add_section(section, obj, keys):\n            for key in keys:\n                if hasattr(obj, key) and getattr(obj, key) is not None:\n                    if not ini.has_section(section):\n                        ini.add_section(section)\n                    ini.set(section, key, str(getattr(obj, key)))\n\n        add_section(S_SERVER, self, [\n            \'SynchronousMode\',\n            \'SendNonPlayerAgentsInfo\'])\n        add_section(S_QUALITY, self, [\n            \'QualityLevel\'])\n        add_section(S_LEVEL, self, [\n            \'NumberOfVehicles\',\n            \'NumberOfPedestrians\',\n            \'WeatherId\',\n            \'SeedVehicles\',\n            \'SeedPedestrians\'])\n\n        ini.add_section(S_SENSOR)\n        ini.set(S_SENSOR, \'Sensors\', \',\'.join(s.SensorName for s in self._sensors))\n\n        for sensor_def in self._sensors:\n            section = S_SENSOR + \'/\' + sensor_def.SensorName\n            add_section(section, sensor_def, get_attribs(sensor_def))\n\n        if sys.version_info >= (3, 0):\n            text = io.StringIO()\n        else:\n            text = io.BytesIO()\n\n        ini.write(text)\n        return text.getvalue().replace(\' = \', \'=\')\n'"
ch7/carla-gym/carla_gym/envs/carla/tcp.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""Basic TCP client.""""""\n\nimport logging\nimport socket\nimport struct\nimport time\n\nclass TCPConnectionError(Exception):\n    pass\n\n\nclass TCPClient(object):\n    """"""\n    Basic networking client for TCP connections. Errors occurred during\n    networking operations are raised as TCPConnectionError.\n\n    Received messages are expected to be prepended by a int32 defining the\n    message size. Messages are sent following this convention.\n    """"""\n\n    def __init__(self, host, port, timeout):\n        self._host = host\n        self._port = port\n        self._timeout = timeout\n        self._socket = None\n        self._logprefix = \'(%s:%s) \' % (self._host, self._port)\n\n    def connect(self, connection_attempts=10):\n        """"""Try to establish a connection to the given host:port.""""""\n        connection_attempts = max(1, connection_attempts)\n        error = None\n        for attempt in range(1, connection_attempts + 1):\n            try:\n                self._socket = socket.create_connection(address=(self._host, self._port), timeout=self._timeout)\n                self._socket.settimeout(self._timeout)\n                logging.debug(\'%sconnected\', self._logprefix)\n                return\n            except socket.error as exception:\n                error = exception\n                logging.debug(\'%sconnection attempt %d: %s\', self._logprefix, attempt, error)\n                time.sleep(1)\n        self._reraise_exception_as_tcp_error(\'failed to connect\', error)\n\n    def disconnect(self):\n        """"""Disconnect any active connection.""""""\n        if self._socket is not None:\n            logging.debug(\'%sdisconnecting\', self._logprefix)\n            self._socket.close()\n            self._socket = None\n\n    def connected(self):\n        """"""Return whether there is an active connection.""""""\n        return self._socket is not None\n\n    def write(self, message):\n        """"""Send message to the server.""""""\n        if self._socket is None:\n            raise TCPConnectionError(self._logprefix + \'not connected\')\n        header = struct.pack(\'<L\', len(message))\n        try:\n            self._socket.sendall(header + message)\n        except socket.error as exception:\n            self._reraise_exception_as_tcp_error(\'failed to write data\', exception)\n\n    def read(self):\n        """"""Read a message from the server.""""""\n        header = self._read_n(4)\n        if not header:\n            raise TCPConnectionError(self._logprefix + \'connection closed\')\n        length = struct.unpack(\'<L\', header)[0]\n        data = self._read_n(length)\n        return data\n\n    def _read_n(self, length):\n        """"""Read n bytes from the socket.""""""\n        if self._socket is None:\n            raise TCPConnectionError(self._logprefix + \'not connected\')\n        buf = bytes()\n        while length > 0:\n            try:\n                data = self._socket.recv(length)\n            except socket.error as exception:\n                self._reraise_exception_as_tcp_error(\'failed to read data\', exception)\n            if not data:\n                raise TCPConnectionError(self._logprefix + \'connection closed\')\n            buf += data\n            length -= len(data)\n        return buf\n\n    def _reraise_exception_as_tcp_error(self, message, exception):\n        raise TCPConnectionError(\'%s%s: %s\' % (self._logprefix, message, exception))\n'"
ch7/carla-gym/carla_gym/envs/carla/transform.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB), and the INTEL Visual Computing Lab.\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport math\n\nfrom collections import namedtuple\n\ntry:\n    import numpy\nexcept ImportError:\n    raise RuntimeError(\n        \'cannot import numpy, make sure numpy package is installed.\')\n\ntry:\n    from . import carla_server_pb2 as carla_protocol\nexcept ImportError:\n    raise RuntimeError(\'cannot import ""carla_server_pb2.py"", run \'\n                       \'the protobuf compiler to generate this file\')\n\n\nTranslation = namedtuple(\'Translation\', \'x y z\')\nTranslation.__new__.__defaults__ = (0.0, 0.0, 0.0)\n\nRotation = namedtuple(\'Rotation\', \'pitch yaw roll\')\nRotation.__new__.__defaults__ = (0.0, 0.0, 0.0)\n\nScale = namedtuple(\'Scale\', \'x y z\')\nScale.__new__.__defaults__ = (1.0, 1.0, 1.0)\n\n\nclass Transform(object):\n    """"""A 3D transformation.\n\n    The transformation is applied in the order: scale, rotation, translation.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        if \'matrix\' in kwargs:\n            self.matrix = kwargs[\'matrix\']\n            return\n        if isinstance(args[0], carla_protocol.Transform):\n            args = [\n                Translation(\n                    args[0].location.x,\n                    args[0].location.y,\n                    args[0].location.z),\n                Rotation(\n                    args[0].rotation.pitch,\n                    args[0].rotation.yaw,\n                    args[0].rotation.roll)\n            ]\n        self.matrix = numpy.matrix(numpy.identity(4))\n        self.set(*args, **kwargs)\n\n    def set(self, *args):\n        """"""Builds the transform matrix given a Translate, Rotation\n        and Scale.\n        """"""\n        translation = Translation()\n        rotation = Rotation()\n        scale = Scale()\n\n        if len(args) > 3:\n            raise ValueError(""\'Transform\' accepts 3 values as maximum."")\n\n        def get_single_obj_type(obj_type):\n            """"""Returns the unique object contained in the\n            arguments lists that is instance of \'obj_type\'.\n            """"""\n            obj = [x for x in args if isinstance(x, obj_type)]\n            if len(obj) > 1:\n                raise ValueError(""Transform only accepts one instances of "" +\n                                 str(obj_type) + "" as a parameter"")\n            elif not obj:\n                # Create an instance of the type that is \'obj_type\'\n                return obj_type()\n            return obj[0]\n\n        translation = get_single_obj_type(Translation)\n        rotation = get_single_obj_type(Rotation)\n        scale = get_single_obj_type(Scale)\n\n        for param in args:\n            if not isinstance(param, Translation) and \\\n               not isinstance(param, Rotation) and \\\n               not isinstance(param, Scale):\n                raise TypeError(\n                    ""\'"" + str(type(param)) + ""\' type not match with \\\n                    \'Translation\', \'Rotation\' or \'Scale\'"")\n\n        # Transformation matrix\n        cy = math.cos(numpy.radians(rotation.yaw))\n        sy = math.sin(numpy.radians(rotation.yaw))\n        cr = math.cos(numpy.radians(rotation.roll))\n        sr = math.sin(numpy.radians(rotation.roll))\n        cp = math.cos(numpy.radians(rotation.pitch))\n        sp = math.sin(numpy.radians(rotation.pitch))\n        self.matrix[0, 3] = translation.x\n        self.matrix[1, 3] = translation.y\n        self.matrix[2, 3] = translation.z\n        self.matrix[0, 0] = scale.x * (cp * cy)\n        self.matrix[0, 1] = scale.y * (cy * sp * sr - sy * cr)\n        self.matrix[0, 2] = -scale.z * (cy * sp * cr + sy * sr)\n        self.matrix[1, 0] = scale.x * (sy * cp)\n        self.matrix[1, 1] = scale.y * (sy * sp * sr + cy * cr)\n        self.matrix[1, 2] = scale.z * (cy * sr - sy * sp * cr)\n        self.matrix[2, 0] = scale.x * (sp)\n        self.matrix[2, 1] = -scale.y * (cp * sr)\n        self.matrix[2, 2] = scale.z * (cp * cr)\n\n    def inverse(self):\n        """"""Return the inverse transform.""""""\n        return Transform(matrix=numpy.linalg.inv(self.matrix))\n\n    def transform_points(self, points):\n        """"""\n        Given a 4x4 transformation matrix, transform an array of 3D points.\n        Expected point foramt: [[X0,Y0,Z0],..[Xn,Yn,Zn]]\n        """"""\n        # Needed foramt: [[X0,..Xn],[Z0,..Zn],[Z0,..Zn]]. So let\'s transpose\n        # the point matrix.\n        points = points.transpose()\n        # Add 0s row: [[X0..,Xn],[Y0..,Yn],[Z0..,Zn],[0,..0]]\n        points = numpy.append(points, numpy.ones((1, points.shape[1])), axis=0)\n        # Point transformation\n        points = self.matrix * points\n        # Return all but last row\n        return points[0:3].transpose()\n\n    def __mul__(self, other):\n        return Transform(matrix=numpy.dot(self.matrix, other.matrix))\n\n    def __str__(self):\n        return str(self.matrix)\n'"
ch7/carla-gym/carla_gym/envs/carla/util.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport datetime\nimport sys\n\nfrom contextlib import contextmanager\n\n\n@contextmanager\ndef make_connection(client_type, *args, **kwargs):\n    """"""Context manager to create and connect a networking client object.""""""\n    client = None\n    try:\n        client = client_type(*args, **kwargs)\n        client.connect()\n        yield client\n    finally:\n        if client is not None:\n            client.disconnect()\n\n\nclass StopWatch(object):\n    def __init__(self):\n        self.start = datetime.datetime.now()\n        self.end = None\n\n    def restart(self):\n        self.start = datetime.datetime.now()\n        self.end = None\n\n    def stop(self):\n        self.end = datetime.datetime.now()\n\n    def seconds(self):\n        return (self.end - self.start).total_seconds()\n\n    def milliseconds(self):\n        return 1000.0 * self.seconds()\n\n\ndef to_hex_str(header):\n    return \':\'.join(\'{:02x}\'.format(ord(c)) for c in header)\n\n\nif sys.version_info >= (3, 3):\n\n    import shutil\n\n    def print_over_same_line(text):\n        terminal_width = shutil.get_terminal_size((80, 20)).columns\n        empty_space = max(0, terminal_width - len(text))\n        sys.stdout.write(\'\\r\' + text + empty_space * \' \')\n        sys.stdout.flush()\n\nelse:\n\n    # Workaround for older Python versions.\n    def print_over_same_line(text):\n        line_length = max(print_over_same_line.last_line_length, len(text))\n        empty_space = max(0, line_length - len(text))\n        sys.stdout.write(\'\\r\' + text + empty_space * \' \')\n        sys.stdout.flush()\n        print_over_same_line.last_line_length = line_length\n    print_over_same_line.last_line_length = 0\n'"
ch8/environment/carla_gym/envs/carla/__init__.py,0,b''
ch8/environment/carla_gym/envs/carla/carla_server_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: carla_server.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'carla_server.proto\',\n  package=\'carla_server\',\n  syntax=\'proto3\',\n  serialized_pb=_b(\'\\n\\x12\\x63\\x61rla_server.proto\\x12\\x0c\\x63\\x61rla_server\\""+\\n\\x08Vector3D\\x12\\t\\n\\x01x\\x18\\x01 \\x01(\\x02\\x12\\t\\n\\x01y\\x18\\x02 \\x01(\\x02\\x12\\t\\n\\x01z\\x18\\x03 \\x01(\\x02\\""6\\n\\nRotation3D\\x12\\r\\n\\x05pitch\\x18\\x01 \\x01(\\x02\\x12\\x0b\\n\\x03yaw\\x18\\x02 \\x01(\\x02\\x12\\x0c\\n\\x04roll\\x18\\x03 \\x01(\\x02\\""\\x92\\x01\\n\\tTransform\\x12(\\n\\x08location\\x18\\x01 \\x01(\\x0b\\x32\\x16.carla_server.Vector3D\\x12/\\n\\x0borientation\\x18\\x02 \\x01(\\x0b\\x32\\x16.carla_server.Vector3DB\\x02\\x18\\x01\\x12*\\n\\x08rotation\\x18\\x03 \\x01(\\x0b\\x32\\x18.carla_server.Rotation3D\\""a\\n\\x0b\\x42oundingBox\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12&\\n\\x06\\x65xtent\\x18\\x02 \\x01(\\x0b\\x32\\x16.carla_server.Vector3D\\""\\x80\\x01\\n\\x06Sensor\\x12\\n\\n\\x02id\\x18\\x01 \\x01(\\x07\\x12\\\'\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x19.carla_server.Sensor.Type\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\""3\\n\\x04Type\\x12\\x0b\\n\\x07UNKNOWN\\x10\\x00\\x12\\n\\n\\x06\\x43\\x41MERA\\x10\\x01\\x12\\x12\\n\\x0eLIDAR_RAY_CAST\\x10\\x02\\""}\\n\\x07Vehicle\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12/\\n\\x0c\\x62ounding_box\\x18\\x04 \\x01(\\x0b\\x32\\x19.carla_server.BoundingBox\\x12\\x15\\n\\rforward_speed\\x18\\x03 \\x01(\\x02\\""\\x80\\x01\\n\\nPedestrian\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12/\\n\\x0c\\x62ounding_box\\x18\\x04 \\x01(\\x0b\\x32\\x19.carla_server.BoundingBox\\x12\\x15\\n\\rforward_speed\\x18\\x03 \\x01(\\x02\\""\\x94\\x01\\n\\x0cTrafficLight\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12/\\n\\x05state\\x18\\x02 \\x01(\\x0e\\x32 .carla_server.TrafficLight.State\\""\\\'\\n\\x05State\\x12\\t\\n\\x05GREEN\\x10\\x00\\x12\\n\\n\\x06YELLOW\\x10\\x01\\x12\\x07\\n\\x03RED\\x10\\x02\\""Q\\n\\x0eSpeedLimitSign\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12\\x13\\n\\x0bspeed_limit\\x18\\x02 \\x01(\\x02\\""\\xe5\\x01\\n\\x05\\x41gent\\x12\\n\\n\\x02id\\x18\\x01 \\x01(\\x07\\x12(\\n\\x07vehicle\\x18\\x02 \\x01(\\x0b\\x32\\x15.carla_server.VehicleH\\x00\\x12.\\n\\npedestrian\\x18\\x03 \\x01(\\x0b\\x32\\x18.carla_server.PedestrianH\\x00\\x12\\x33\\n\\rtraffic_light\\x18\\x04 \\x01(\\x0b\\x32\\x1a.carla_server.TrafficLightH\\x00\\x12\\x38\\n\\x10speed_limit_sign\\x18\\x05 \\x01(\\x0b\\x32\\x1c.carla_server.SpeedLimitSignH\\x00\\x42\\x07\\n\\x05\\x61gent\\""%\\n\\x11RequestNewEpisode\\x12\\x10\\n\\x08ini_file\\x18\\x01 \\x01(\\t\\""\\x80\\x01\\n\\x10SceneDescription\\x12\\x10\\n\\x08map_name\\x18\\x03 \\x01(\\t\\x12\\x33\\n\\x12player_start_spots\\x18\\x01 \\x03(\\x0b\\x32\\x17.carla_server.Transform\\x12%\\n\\x07sensors\\x18\\x02 \\x03(\\x0b\\x32\\x14.carla_server.Sensor\\""/\\n\\x0c\\x45pisodeStart\\x12\\x1f\\n\\x17player_start_spot_index\\x18\\x01 \\x01(\\r\\""\\x1d\\n\\x0c\\x45pisodeReady\\x12\\r\\n\\x05ready\\x18\\x01 \\x01(\\x08\\""^\\n\\x07\\x43ontrol\\x12\\r\\n\\x05steer\\x18\\x01 \\x01(\\x02\\x12\\x10\\n\\x08throttle\\x18\\x02 \\x01(\\x02\\x12\\r\\n\\x05\\x62rake\\x18\\x03 \\x01(\\x02\\x12\\x12\\n\\nhand_brake\\x18\\x04 \\x01(\\x08\\x12\\x0f\\n\\x07reverse\\x18\\x05 \\x01(\\x08\\""\\xd1\\x04\\n\\x0cMeasurements\\x12\\x14\\n\\x0c\\x66rame_number\\x18\\x05 \\x01(\\x04\\x12\\x1a\\n\\x12platform_timestamp\\x18\\x01 \\x01(\\r\\x12\\x16\\n\\x0egame_timestamp\\x18\\x02 \\x01(\\r\\x12J\\n\\x13player_measurements\\x18\\x03 \\x01(\\x0b\\x32-.carla_server.Measurements.PlayerMeasurements\\x12.\\n\\x11non_player_agents\\x18\\x04 \\x03(\\x0b\\x32\\x13.carla_server.Agent\\x1a\\xfa\\x02\\n\\x12PlayerMeasurements\\x12*\\n\\ttransform\\x18\\x01 \\x01(\\x0b\\x32\\x17.carla_server.Transform\\x12/\\n\\x0c\\x62ounding_box\\x18\\x0c \\x01(\\x0b\\x32\\x19.carla_server.BoundingBox\\x12,\\n\\x0c\\x61\\x63\\x63\\x65leration\\x18\\x03 \\x01(\\x0b\\x32\\x16.carla_server.Vector3D\\x12\\x15\\n\\rforward_speed\\x18\\x04 \\x01(\\x02\\x12\\x1a\\n\\x12\\x63ollision_vehicles\\x18\\x05 \\x01(\\x02\\x12\\x1d\\n\\x15\\x63ollision_pedestrians\\x18\\x06 \\x01(\\x02\\x12\\x17\\n\\x0f\\x63ollision_other\\x18\\x07 \\x01(\\x02\\x12\\x1e\\n\\x16intersection_otherlane\\x18\\x08 \\x01(\\x02\\x12\\x1c\\n\\x14intersection_offroad\\x18\\t \\x01(\\x02\\x12\\x30\\n\\x11\\x61utopilot_control\\x18\\n \\x01(\\x0b\\x32\\x15.carla_server.ControlB\\x03\\xf8\\x01\\x01\\x62\\x06proto3\')\n)\n\n\n\n_SENSOR_TYPE = _descriptor.EnumDescriptor(\n  name=\'Type\',\n  full_name=\'carla_server.Sensor.Type\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'UNKNOWN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAMERA\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LIDAR_RAY_CAST\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=463,\n  serialized_end=514,\n)\n_sym_db.RegisterEnumDescriptor(_SENSOR_TYPE)\n\n_TRAFFICLIGHT_STATE = _descriptor.EnumDescriptor(\n  name=\'State\',\n  full_name=\'carla_server.TrafficLight.State\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'GREEN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'YELLOW\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RED\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=884,\n  serialized_end=923,\n)\n_sym_db.RegisterEnumDescriptor(_TRAFFICLIGHT_STATE)\n\n\n_VECTOR3D = _descriptor.Descriptor(\n  name=\'Vector3D\',\n  full_name=\'carla_server.Vector3D\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'x\', full_name=\'carla_server.Vector3D.x\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'y\', full_name=\'carla_server.Vector3D.y\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'z\', full_name=\'carla_server.Vector3D.z\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=36,\n  serialized_end=79,\n)\n\n\n_ROTATION3D = _descriptor.Descriptor(\n  name=\'Rotation3D\',\n  full_name=\'carla_server.Rotation3D\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pitch\', full_name=\'carla_server.Rotation3D.pitch\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'yaw\', full_name=\'carla_server.Rotation3D.yaw\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'roll\', full_name=\'carla_server.Rotation3D.roll\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=81,\n  serialized_end=135,\n)\n\n\n_TRANSFORM = _descriptor.Descriptor(\n  name=\'Transform\',\n  full_name=\'carla_server.Transform\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'location\', full_name=\'carla_server.Transform.location\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'orientation\', full_name=\'carla_server.Transform.orientation\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\030\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'rotation\', full_name=\'carla_server.Transform.rotation\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=138,\n  serialized_end=284,\n)\n\n\n_BOUNDINGBOX = _descriptor.Descriptor(\n  name=\'BoundingBox\',\n  full_name=\'carla_server.BoundingBox\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.BoundingBox.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'extent\', full_name=\'carla_server.BoundingBox.extent\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=286,\n  serialized_end=383,\n)\n\n\n_SENSOR = _descriptor.Descriptor(\n  name=\'Sensor\',\n  full_name=\'carla_server.Sensor\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'id\', full_name=\'carla_server.Sensor.id\', index=0,\n      number=1, type=7, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'carla_server.Sensor.type\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'carla_server.Sensor.name\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SENSOR_TYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=386,\n  serialized_end=514,\n)\n\n\n_VEHICLE = _descriptor.Descriptor(\n  name=\'Vehicle\',\n  full_name=\'carla_server.Vehicle\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.Vehicle.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bounding_box\', full_name=\'carla_server.Vehicle.bounding_box\', index=1,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'forward_speed\', full_name=\'carla_server.Vehicle.forward_speed\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=516,\n  serialized_end=641,\n)\n\n\n_PEDESTRIAN = _descriptor.Descriptor(\n  name=\'Pedestrian\',\n  full_name=\'carla_server.Pedestrian\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.Pedestrian.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bounding_box\', full_name=\'carla_server.Pedestrian.bounding_box\', index=1,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'forward_speed\', full_name=\'carla_server.Pedestrian.forward_speed\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=644,\n  serialized_end=772,\n)\n\n\n_TRAFFICLIGHT = _descriptor.Descriptor(\n  name=\'TrafficLight\',\n  full_name=\'carla_server.TrafficLight\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.TrafficLight.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'carla_server.TrafficLight.state\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TRAFFICLIGHT_STATE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=775,\n  serialized_end=923,\n)\n\n\n_SPEEDLIMITSIGN = _descriptor.Descriptor(\n  name=\'SpeedLimitSign\',\n  full_name=\'carla_server.SpeedLimitSign\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.SpeedLimitSign.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'speed_limit\', full_name=\'carla_server.SpeedLimitSign.speed_limit\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=925,\n  serialized_end=1006,\n)\n\n\n_AGENT = _descriptor.Descriptor(\n  name=\'Agent\',\n  full_name=\'carla_server.Agent\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'id\', full_name=\'carla_server.Agent.id\', index=0,\n      number=1, type=7, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'vehicle\', full_name=\'carla_server.Agent.vehicle\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pedestrian\', full_name=\'carla_server.Agent.pedestrian\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'traffic_light\', full_name=\'carla_server.Agent.traffic_light\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'speed_limit_sign\', full_name=\'carla_server.Agent.speed_limit_sign\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'agent\', full_name=\'carla_server.Agent.agent\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=1009,\n  serialized_end=1238,\n)\n\n\n_REQUESTNEWEPISODE = _descriptor.Descriptor(\n  name=\'RequestNewEpisode\',\n  full_name=\'carla_server.RequestNewEpisode\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ini_file\', full_name=\'carla_server.RequestNewEpisode.ini_file\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1240,\n  serialized_end=1277,\n)\n\n\n_SCENEDESCRIPTION = _descriptor.Descriptor(\n  name=\'SceneDescription\',\n  full_name=\'carla_server.SceneDescription\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'map_name\', full_name=\'carla_server.SceneDescription.map_name\', index=0,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'player_start_spots\', full_name=\'carla_server.SceneDescription.player_start_spots\', index=1,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sensors\', full_name=\'carla_server.SceneDescription.sensors\', index=2,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1280,\n  serialized_end=1408,\n)\n\n\n_EPISODESTART = _descriptor.Descriptor(\n  name=\'EpisodeStart\',\n  full_name=\'carla_server.EpisodeStart\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'player_start_spot_index\', full_name=\'carla_server.EpisodeStart.player_start_spot_index\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1410,\n  serialized_end=1457,\n)\n\n\n_EPISODEREADY = _descriptor.Descriptor(\n  name=\'EpisodeReady\',\n  full_name=\'carla_server.EpisodeReady\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ready\', full_name=\'carla_server.EpisodeReady.ready\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1459,\n  serialized_end=1488,\n)\n\n\n_CONTROL = _descriptor.Descriptor(\n  name=\'Control\',\n  full_name=\'carla_server.Control\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'steer\', full_name=\'carla_server.Control.steer\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'throttle\', full_name=\'carla_server.Control.throttle\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'brake\', full_name=\'carla_server.Control.brake\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hand_brake\', full_name=\'carla_server.Control.hand_brake\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reverse\', full_name=\'carla_server.Control.reverse\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1490,\n  serialized_end=1584,\n)\n\n\n_MEASUREMENTS_PLAYERMEASUREMENTS = _descriptor.Descriptor(\n  name=\'PlayerMeasurements\',\n  full_name=\'carla_server.Measurements.PlayerMeasurements\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'carla_server.Measurements.PlayerMeasurements.transform\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bounding_box\', full_name=\'carla_server.Measurements.PlayerMeasurements.bounding_box\', index=1,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'acceleration\', full_name=\'carla_server.Measurements.PlayerMeasurements.acceleration\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'forward_speed\', full_name=\'carla_server.Measurements.PlayerMeasurements.forward_speed\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'collision_vehicles\', full_name=\'carla_server.Measurements.PlayerMeasurements.collision_vehicles\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'collision_pedestrians\', full_name=\'carla_server.Measurements.PlayerMeasurements.collision_pedestrians\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'collision_other\', full_name=\'carla_server.Measurements.PlayerMeasurements.collision_other\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'intersection_otherlane\', full_name=\'carla_server.Measurements.PlayerMeasurements.intersection_otherlane\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'intersection_offroad\', full_name=\'carla_server.Measurements.PlayerMeasurements.intersection_offroad\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'autopilot_control\', full_name=\'carla_server.Measurements.PlayerMeasurements.autopilot_control\', index=9,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1802,\n  serialized_end=2180,\n)\n\n_MEASUREMENTS = _descriptor.Descriptor(\n  name=\'Measurements\',\n  full_name=\'carla_server.Measurements\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'frame_number\', full_name=\'carla_server.Measurements.frame_number\', index=0,\n      number=5, type=4, cpp_type=4, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'platform_timestamp\', full_name=\'carla_server.Measurements.platform_timestamp\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'game_timestamp\', full_name=\'carla_server.Measurements.game_timestamp\', index=2,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'player_measurements\', full_name=\'carla_server.Measurements.player_measurements\', index=3,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'non_player_agents\', full_name=\'carla_server.Measurements.non_player_agents\', index=4,\n      number=4, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[_MEASUREMENTS_PLAYERMEASUREMENTS, ],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1587,\n  serialized_end=2180,\n)\n\n_TRANSFORM.fields_by_name[\'location\'].message_type = _VECTOR3D\n_TRANSFORM.fields_by_name[\'orientation\'].message_type = _VECTOR3D\n_TRANSFORM.fields_by_name[\'rotation\'].message_type = _ROTATION3D\n_BOUNDINGBOX.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_BOUNDINGBOX.fields_by_name[\'extent\'].message_type = _VECTOR3D\n_SENSOR.fields_by_name[\'type\'].enum_type = _SENSOR_TYPE\n_SENSOR_TYPE.containing_type = _SENSOR\n_VEHICLE.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_VEHICLE.fields_by_name[\'bounding_box\'].message_type = _BOUNDINGBOX\n_PEDESTRIAN.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_PEDESTRIAN.fields_by_name[\'bounding_box\'].message_type = _BOUNDINGBOX\n_TRAFFICLIGHT.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_TRAFFICLIGHT.fields_by_name[\'state\'].enum_type = _TRAFFICLIGHT_STATE\n_TRAFFICLIGHT_STATE.containing_type = _TRAFFICLIGHT\n_SPEEDLIMITSIGN.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_AGENT.fields_by_name[\'vehicle\'].message_type = _VEHICLE\n_AGENT.fields_by_name[\'pedestrian\'].message_type = _PEDESTRIAN\n_AGENT.fields_by_name[\'traffic_light\'].message_type = _TRAFFICLIGHT\n_AGENT.fields_by_name[\'speed_limit_sign\'].message_type = _SPEEDLIMITSIGN\n_AGENT.oneofs_by_name[\'agent\'].fields.append(\n  _AGENT.fields_by_name[\'vehicle\'])\n_AGENT.fields_by_name[\'vehicle\'].containing_oneof = _AGENT.oneofs_by_name[\'agent\']\n_AGENT.oneofs_by_name[\'agent\'].fields.append(\n  _AGENT.fields_by_name[\'pedestrian\'])\n_AGENT.fields_by_name[\'pedestrian\'].containing_oneof = _AGENT.oneofs_by_name[\'agent\']\n_AGENT.oneofs_by_name[\'agent\'].fields.append(\n  _AGENT.fields_by_name[\'traffic_light\'])\n_AGENT.fields_by_name[\'traffic_light\'].containing_oneof = _AGENT.oneofs_by_name[\'agent\']\n_AGENT.oneofs_by_name[\'agent\'].fields.append(\n  _AGENT.fields_by_name[\'speed_limit_sign\'])\n_AGENT.fields_by_name[\'speed_limit_sign\'].containing_oneof = _AGENT.oneofs_by_name[\'agent\']\n_SCENEDESCRIPTION.fields_by_name[\'player_start_spots\'].message_type = _TRANSFORM\n_SCENEDESCRIPTION.fields_by_name[\'sensors\'].message_type = _SENSOR\n_MEASUREMENTS_PLAYERMEASUREMENTS.fields_by_name[\'transform\'].message_type = _TRANSFORM\n_MEASUREMENTS_PLAYERMEASUREMENTS.fields_by_name[\'bounding_box\'].message_type = _BOUNDINGBOX\n_MEASUREMENTS_PLAYERMEASUREMENTS.fields_by_name[\'acceleration\'].message_type = _VECTOR3D\n_MEASUREMENTS_PLAYERMEASUREMENTS.fields_by_name[\'autopilot_control\'].message_type = _CONTROL\n_MEASUREMENTS_PLAYERMEASUREMENTS.containing_type = _MEASUREMENTS\n_MEASUREMENTS.fields_by_name[\'player_measurements\'].message_type = _MEASUREMENTS_PLAYERMEASUREMENTS\n_MEASUREMENTS.fields_by_name[\'non_player_agents\'].message_type = _AGENT\nDESCRIPTOR.message_types_by_name[\'Vector3D\'] = _VECTOR3D\nDESCRIPTOR.message_types_by_name[\'Rotation3D\'] = _ROTATION3D\nDESCRIPTOR.message_types_by_name[\'Transform\'] = _TRANSFORM\nDESCRIPTOR.message_types_by_name[\'BoundingBox\'] = _BOUNDINGBOX\nDESCRIPTOR.message_types_by_name[\'Sensor\'] = _SENSOR\nDESCRIPTOR.message_types_by_name[\'Vehicle\'] = _VEHICLE\nDESCRIPTOR.message_types_by_name[\'Pedestrian\'] = _PEDESTRIAN\nDESCRIPTOR.message_types_by_name[\'TrafficLight\'] = _TRAFFICLIGHT\nDESCRIPTOR.message_types_by_name[\'SpeedLimitSign\'] = _SPEEDLIMITSIGN\nDESCRIPTOR.message_types_by_name[\'Agent\'] = _AGENT\nDESCRIPTOR.message_types_by_name[\'RequestNewEpisode\'] = _REQUESTNEWEPISODE\nDESCRIPTOR.message_types_by_name[\'SceneDescription\'] = _SCENEDESCRIPTION\nDESCRIPTOR.message_types_by_name[\'EpisodeStart\'] = _EPISODESTART\nDESCRIPTOR.message_types_by_name[\'EpisodeReady\'] = _EPISODEREADY\nDESCRIPTOR.message_types_by_name[\'Control\'] = _CONTROL\nDESCRIPTOR.message_types_by_name[\'Measurements\'] = _MEASUREMENTS\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nVector3D = _reflection.GeneratedProtocolMessageType(\'Vector3D\', (_message.Message,), dict(\n  DESCRIPTOR = _VECTOR3D,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Vector3D)\n  ))\n_sym_db.RegisterMessage(Vector3D)\n\nRotation3D = _reflection.GeneratedProtocolMessageType(\'Rotation3D\', (_message.Message,), dict(\n  DESCRIPTOR = _ROTATION3D,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Rotation3D)\n  ))\n_sym_db.RegisterMessage(Rotation3D)\n\nTransform = _reflection.GeneratedProtocolMessageType(\'Transform\', (_message.Message,), dict(\n  DESCRIPTOR = _TRANSFORM,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Transform)\n  ))\n_sym_db.RegisterMessage(Transform)\n\nBoundingBox = _reflection.GeneratedProtocolMessageType(\'BoundingBox\', (_message.Message,), dict(\n  DESCRIPTOR = _BOUNDINGBOX,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.BoundingBox)\n  ))\n_sym_db.RegisterMessage(BoundingBox)\n\nSensor = _reflection.GeneratedProtocolMessageType(\'Sensor\', (_message.Message,), dict(\n  DESCRIPTOR = _SENSOR,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Sensor)\n  ))\n_sym_db.RegisterMessage(Sensor)\n\nVehicle = _reflection.GeneratedProtocolMessageType(\'Vehicle\', (_message.Message,), dict(\n  DESCRIPTOR = _VEHICLE,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Vehicle)\n  ))\n_sym_db.RegisterMessage(Vehicle)\n\nPedestrian = _reflection.GeneratedProtocolMessageType(\'Pedestrian\', (_message.Message,), dict(\n  DESCRIPTOR = _PEDESTRIAN,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Pedestrian)\n  ))\n_sym_db.RegisterMessage(Pedestrian)\n\nTrafficLight = _reflection.GeneratedProtocolMessageType(\'TrafficLight\', (_message.Message,), dict(\n  DESCRIPTOR = _TRAFFICLIGHT,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.TrafficLight)\n  ))\n_sym_db.RegisterMessage(TrafficLight)\n\nSpeedLimitSign = _reflection.GeneratedProtocolMessageType(\'SpeedLimitSign\', (_message.Message,), dict(\n  DESCRIPTOR = _SPEEDLIMITSIGN,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.SpeedLimitSign)\n  ))\n_sym_db.RegisterMessage(SpeedLimitSign)\n\nAgent = _reflection.GeneratedProtocolMessageType(\'Agent\', (_message.Message,), dict(\n  DESCRIPTOR = _AGENT,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Agent)\n  ))\n_sym_db.RegisterMessage(Agent)\n\nRequestNewEpisode = _reflection.GeneratedProtocolMessageType(\'RequestNewEpisode\', (_message.Message,), dict(\n  DESCRIPTOR = _REQUESTNEWEPISODE,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.RequestNewEpisode)\n  ))\n_sym_db.RegisterMessage(RequestNewEpisode)\n\nSceneDescription = _reflection.GeneratedProtocolMessageType(\'SceneDescription\', (_message.Message,), dict(\n  DESCRIPTOR = _SCENEDESCRIPTION,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.SceneDescription)\n  ))\n_sym_db.RegisterMessage(SceneDescription)\n\nEpisodeStart = _reflection.GeneratedProtocolMessageType(\'EpisodeStart\', (_message.Message,), dict(\n  DESCRIPTOR = _EPISODESTART,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.EpisodeStart)\n  ))\n_sym_db.RegisterMessage(EpisodeStart)\n\nEpisodeReady = _reflection.GeneratedProtocolMessageType(\'EpisodeReady\', (_message.Message,), dict(\n  DESCRIPTOR = _EPISODEREADY,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.EpisodeReady)\n  ))\n_sym_db.RegisterMessage(EpisodeReady)\n\nControl = _reflection.GeneratedProtocolMessageType(\'Control\', (_message.Message,), dict(\n  DESCRIPTOR = _CONTROL,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Control)\n  ))\n_sym_db.RegisterMessage(Control)\n\nMeasurements = _reflection.GeneratedProtocolMessageType(\'Measurements\', (_message.Message,), dict(\n\n  PlayerMeasurements = _reflection.GeneratedProtocolMessageType(\'PlayerMeasurements\', (_message.Message,), dict(\n    DESCRIPTOR = _MEASUREMENTS_PLAYERMEASUREMENTS,\n    __module__ = \'carla_server_pb2\'\n    # @@protoc_insertion_point(class_scope:carla_server.Measurements.PlayerMeasurements)\n    ))\n  ,\n  DESCRIPTOR = _MEASUREMENTS,\n  __module__ = \'carla_server_pb2\'\n  # @@protoc_insertion_point(class_scope:carla_server.Measurements)\n  ))\n_sym_db.RegisterMessage(Measurements)\n_sym_db.RegisterMessage(Measurements.PlayerMeasurements)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(\'\\370\\001\\001\'))\n_TRANSFORM.fields_by_name[\'orientation\'].has_options = True\n_TRANSFORM.fields_by_name[\'orientation\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\030\\001\'))\n# @@protoc_insertion_point(module_scope)\n'"
ch8/environment/carla_gym/envs/carla/client.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""CARLA Client.""""""\n\nimport logging\nimport struct\n\nfrom contextlib import contextmanager\n\nfrom . import sensor\nfrom . import tcp\nfrom . import util\n\ntry:\n    from . import carla_server_pb2 as carla_protocol\nexcept ImportError:\n    raise RuntimeError(\'cannot import ""carla_server_pb2.py"", run the protobuf compiler to generate this file\')\n\ntry:\n    import numpy\nexcept ImportError:\n    raise RuntimeError(\'cannot import numpy, make sure numpy package is installed.\')\n\n\nVehicleControl = carla_protocol.Control\n\n\n@contextmanager\ndef make_carla_client(host, world_port, timeout=15):\n    """"""Context manager for creating and connecting a CarlaClient.""""""\n    with util.make_connection(CarlaClient, host, world_port, timeout) as client:\n        yield client\n\n\nclass CarlaClient(object):\n    """"""The CARLA client. Manages communications with the CARLA server.""""""\n\n    def __init__(self, host, world_port, timeout=15):\n        self._world_client = tcp.TCPClient(host, world_port, timeout)\n        self._stream_client = tcp.TCPClient(host, world_port + 1, timeout)\n        self._control_client = tcp.TCPClient(host, world_port + 2, timeout)\n        self._current_settings = None\n        self._is_episode_requested = False\n        self._sensors = {}\n\n    def connect(self, connection_attempts=10):\n        """"""\n        Try to establish a connection to a CARLA server at the given host:port.\n        """"""\n        self._world_client.connect(connection_attempts)\n\n    def disconnect(self):\n        """"""Disconnect from server.""""""\n        self._control_client.disconnect()\n        self._stream_client.disconnect()\n        self._world_client.disconnect()\n\n    def connected(self):\n        """"""Return whether there is an active connection.""""""\n        return self._world_client.connected()\n\n    def load_settings(self, carla_settings):\n        """"""\n        Load new settings and request a new episode based on these settings.\n        carla_settings object must be convertible to a str holding the contents\n        of a CarlaSettings.ini file.\n\n        Return a protobuf object holding the scene description.\n        """"""\n        self._current_settings = carla_settings\n        return self._request_new_episode(carla_settings)\n\n    def start_episode(self, player_start_index):\n        """"""\n        Start the new episode at the player start given by the\n        player_start_index. The list of player starts is retrieved by\n        ""load_settings"".\n\n        The new episode is started based on the last settings loaded by\n        ""load_settings"".\n\n        This function waits until the server answers with an EpisodeReady.\n        """"""\n        if self._current_settings is None:\n            raise RuntimeError(\'no settings loaded, cannot start episode\')\n\n        # if no new settings are loaded, request new episode with previous\n        if not self._is_episode_requested:\n            self._request_new_episode(self._current_settings)\n\n        try:\n            pb_message = carla_protocol.EpisodeStart()\n            pb_message.player_start_spot_index = player_start_index\n            self._world_client.write(pb_message.SerializeToString())\n            # Wait for EpisodeReady.\n            data = self._world_client.read()\n            if not data:\n                raise RuntimeError(\'failed to read data from server\')\n            pb_message = carla_protocol.EpisodeReady()\n            pb_message.ParseFromString(data)\n            if not pb_message.ready:\n                raise RuntimeError(\'cannot start episode: server failed to start episode\')\n            # We can start the agent clients now.\n            self._stream_client.connect()\n            self._control_client.connect()\n            # Set again the status for no episode requested\n        finally:\n            self._is_episode_requested = False\n\n    def read_data(self):\n        """"""\n        Read the data sent from the server this frame. The episode must be\n        started. Return a pair containing the protobuf object containing the\n        measurements followed by the raw data of the sensors.\n        """"""\n        # Read measurements.\n        data = self._stream_client.read()\n        if not data:\n            raise RuntimeError(\'failed to read data from server\')\n        pb_message = carla_protocol.Measurements()\n        pb_message.ParseFromString(data)\n        # Read sensor data.\n        return pb_message, dict(x for x in self._read_sensor_data())\n\n    def send_control(self, *args, **kwargs):\n        """"""\n        Send the VehicleControl to be applied this frame.\n\n        If synchronous mode was requested, the server will pause the simulation\n        until this message is received.\n        """"""\n        if isinstance(args[0] if args else None, carla_protocol.Control):\n            pb_message = args[0]\n        else:\n            pb_message = carla_protocol.Control()\n            pb_message.steer = kwargs.get(\'steer\', 0.0)\n            pb_message.throttle = kwargs.get(\'throttle\', 0.0)\n            pb_message.brake = kwargs.get(\'brake\', 0.0)\n            pb_message.hand_brake = kwargs.get(\'hand_brake\', False)\n            pb_message.reverse = kwargs.get(\'reverse\', False)\n        self._control_client.write(pb_message.SerializeToString())\n\n    def _request_new_episode(self, carla_settings):\n        """"""\n        Internal function to request a new episode. Prepare the client for a new\n        episode by disconnecting agent clients.\n        """"""\n        # Disconnect agent clients.\n        self._stream_client.disconnect()\n        self._control_client.disconnect()\n        # Send new episode request.\n        pb_message = carla_protocol.RequestNewEpisode()\n        pb_message.ini_file = str(carla_settings)\n        self._world_client.write(pb_message.SerializeToString())\n        # Read scene description.\n        data = self._world_client.read()\n        if not data:\n            raise RuntimeError(\'failed to read data from server\')\n        pb_message = carla_protocol.SceneDescription()\n        pb_message.ParseFromString(data)\n        self._sensors = dict((sensor.id, sensor) \\\n            for sensor in _make_sensor_parsers(pb_message.sensors))\n        self._is_episode_requested = True\n        return pb_message\n\n    def _read_sensor_data(self):\n        while True:\n            data = self._stream_client.read()\n            if not data:\n                raise StopIteration\n            yield self._parse_sensor_data(data)\n\n    def _parse_sensor_data(self, data):\n        sensor_id = struct.unpack(\'<L\', data[0:4])[0]\n        parser = self._sensors[sensor_id]\n        return parser.name, parser.parse_raw_data(data[4:])\n\n\ndef _make_sensor_parsers(sensors):\n    image_types = [\'None\', \'SceneFinal\', \'Depth\', \'SemanticSegmentation\']\n    getimgtype = lambda id: image_types[id] if len(image_types) > id else \'Unknown\'\n    getint32 = lambda data, index: struct.unpack(\'<L\', data[index*4:index*4+4])[0]\n    getint64 = lambda data, index: struct.unpack(\'<Q\', data[index*4:index*4+8])[0]\n    getfloat = lambda data, index: struct.unpack(\'<f\', data[index*4:index*4+4])[0]\n\n    def parse_image(data):\n        frame_number = getint64(data, 0)\n        width = getint32(data, 2)\n        height = getint32(data, 3)\n        image_type = getimgtype(getint32(data, 4))\n        fov = getfloat(data, 5)\n        return sensor.Image(frame_number, width, height, image_type, fov, data[24:])\n\n    def parse_lidar(data):\n        frame_number = getint64(data, 0)\n        horizontal_angle = getfloat(data, 2)\n        channels = getint32(data, 3)\n        header_size = 16\n        point_count_by_channel = numpy.frombuffer(\n            data[header_size:header_size+channels*4],\n            dtype=numpy.dtype(\'uint32\'))\n        points = numpy.frombuffer(\n            data[header_size+channels*4:],\n            dtype=numpy.dtype(\'f4\'))\n        points = numpy.reshape(points, (int(points.shape[0]/3), 3))\n        return sensor.LidarMeasurement(\n            frame_number,\n            horizontal_angle,\n            channels,\n            point_count_by_channel,\n            sensor.PointCloud(frame_number, points))\n\n    class SensorDefinition(object):\n        def __init__(self, s):\n            self.id = s.id\n            self.name = s.name\n            self.type = s.type\n            self.parse_raw_data = lambda x: x\n\n    for s in sensors:\n        sensor_def = SensorDefinition(s)\n        if sensor_def.type == carla_protocol.Sensor.CAMERA:\n            sensor_def.parse_raw_data = parse_image\n        elif sensor_def.type == carla_protocol.Sensor.LIDAR_RAY_CAST:\n            sensor_def.parse_raw_data = parse_lidar\n        else:\n            logging.error(\'unknown sensor type %s\', sensor_def.type)\n        yield sensor_def\n'"
ch8/environment/carla_gym/envs/carla/image_converter.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""\nHandy conversions for CARLA images.\n\nThe functions here are provided for real-time display, if you want to save the\nconverted images, save the images from Python without conversion and convert\nthem afterwards with the C++ implementation at ""Util/ImageConverter"" as it\nprovides considerably better performance.\n""""""\n\nimport math\n\ntry:\n    import numpy\n    from numpy.matlib import repmat\nexcept ImportError:\n    raise RuntimeError(\'cannot import numpy, make sure numpy package is installed\')\n\n\nfrom . import sensor\n\n\ndef to_bgra_array(image):\n    """"""Convert a CARLA raw image to a BGRA numpy array.""""""\n    if not isinstance(image, sensor.Image):\n        raise ValueError(""Argument must be a carla.sensor.Image"")\n    array = numpy.frombuffer(image.raw_data, dtype=numpy.dtype(""uint8""))\n    array = numpy.reshape(array, (image.height, image.width, 4))\n    return array\n\n\ndef to_rgb_array(image):\n    """"""Convert a CARLA raw image to a RGB numpy array.""""""\n    array = to_bgra_array(image)\n    # Convert BGRA to RGB.\n    array = array[:, :, :3]\n    array = array[:, :, ::-1]\n    return array\n\n\ndef labels_to_array(image):\n    """"""\n    Convert an image containing CARLA semantic segmentation labels to a 2D array\n    containing the label of each pixel.\n    """"""\n    return to_bgra_array(image)[:, :, 2]\n\n\ndef labels_to_cityscapes_palette(image):\n    """"""\n    Convert an image containing CARLA semantic segmentation labels to\n    Cityscapes palette.\n    """"""\n    classes = {\n        0: [0, 0, 0],         # None\n        1: [70, 70, 70],      # Buildings\n        2: [190, 153, 153],   # Fences\n        3: [72, 0, 90],       # Other\n        4: [220, 20, 60],     # Pedestrians\n        5: [153, 153, 153],   # Poles\n        6: [157, 234, 50],    # RoadLines\n        7: [128, 64, 128],    # Roads\n        8: [244, 35, 232],    # Sidewalks\n        9: [107, 142, 35],    # Vegetation\n        10: [0, 0, 255],      # Vehicles\n        11: [102, 102, 156],  # Walls\n        12: [220, 220, 0]     # TrafficSigns\n    }\n    array = labels_to_array(image)\n    result = numpy.zeros((array.shape[0], array.shape[1], 3))\n    for key, value in classes.items():\n        result[numpy.where(array == key)] = value\n    return result\n\n\ndef depth_to_array(image):\n    """"""\n    Convert an image containing CARLA encoded depth-map to a 2D array containing\n    the depth value of each pixel normalized between [0.0, 1.0].\n    """"""\n    array = to_bgra_array(image)\n    array = array.astype(numpy.float32)\n    # Apply (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1).\n    normalized_depth = numpy.dot(array[:, :, :3], [65536.0, 256.0, 1.0])\n    normalized_depth /= 16777215.0  # (256.0 * 256.0 * 256.0 - 1.0)\n    return normalized_depth\n\n\ndef depth_to_logarithmic_grayscale(image):\n    """"""\n    Convert an image containing CARLA encoded depth-map to a logarithmic\n    grayscale image array.\n    ""max_depth"" is used to omit the points that are far enough.\n    """"""\n    normalized_depth = depth_to_array(image)\n    # Convert to logarithmic depth.\n    logdepth = numpy.ones(normalized_depth.shape) + \\\n        (numpy.log(normalized_depth) / 5.70378)\n    logdepth = numpy.clip(logdepth, 0.0, 1.0)\n    logdepth *= 255.0\n    # Expand to three colors.\n    return numpy.repeat(logdepth[:, :, numpy.newaxis], 3, axis=2)\n\n\ndef depth_to_local_point_cloud(image, color=None, max_depth=0.9):\n    """"""\n    Convert an image containing CARLA encoded depth-map to a 2D array containing\n    the 3D position (relative to the camera) of each pixel and its corresponding\n    RGB color of an array.\n    ""max_depth"" is used to omit the points that are far enough.\n    """"""\n    far = 1000.0  # max depth in meters.\n    normalized_depth = depth_to_array(image)\n\n    # (Intrinsic) K Matrix\n    k = numpy.identity(3)\n    k[0, 2] = image.width / 2.0\n    k[1, 2] = image.height / 2.0\n    k[0, 0] = k[1, 1] = image.width / \\\n        (2.0 * math.tan(image.fov * math.pi / 360.0))\n\n    # 2d pixel coordinates\n    pixel_length = image.width * image.height\n    u_coord = repmat(numpy.r_[image.width-1:-1:-1],\n                     image.height, 1).reshape(pixel_length)\n    v_coord = repmat(numpy.c_[image.height-1:-1:-1],\n                     1, image.width).reshape(pixel_length)\n    if color is not None:\n        color = color.reshape(pixel_length, 3)\n    normalized_depth = numpy.reshape(normalized_depth, pixel_length)\n\n    # Search for pixels where the depth is greater than max_depth to\n    # delete them\n    max_depth_indexes = numpy.where(normalized_depth > max_depth)\n    normalized_depth = numpy.delete(normalized_depth, max_depth_indexes)\n    u_coord = numpy.delete(u_coord, max_depth_indexes)\n    v_coord = numpy.delete(v_coord, max_depth_indexes)\n    if color is not None:\n        color = numpy.delete(color, max_depth_indexes, axis=0)\n\n    # pd2 = [u,v,1]\n    p2d = numpy.array([u_coord, v_coord, numpy.ones_like(u_coord)])\n\n    # P = [X,Y,Z]\n    p3d = numpy.dot(numpy.linalg.inv(k), p2d)\n    p3d *= normalized_depth * far\n\n    # Formating the output to:\n    # [[X1,Y1,Z1,R1,G1,B1],[X2,Y2,Z2,R2,G2,B2], ... [Xn,Yn,Zn,Rn,Gn,Bn]]\n    if color is not None:\n        # numpy.concatenate((numpy.transpose(p3d), color), axis=1)\n        return sensor.PointCloud(\n            image.frame_number,\n            numpy.transpose(p3d),\n            color_array=color)\n    # [[X1,Y1,Z1],[X2,Y2,Z2], ... [Xn,Yn,Zn]]\n    return sensor.PointCloud(image.frame_number, numpy.transpose(p3d))\n'"
ch8/environment/carla_gym/envs/carla/sensor.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""CARLA sensors.""""""\n\n\nimport os\n\nfrom collections import namedtuple\n\ntry:\n    import numpy\nexcept ImportError:\n    raise RuntimeError(\'cannot import numpy, make sure numpy package is installed.\')\n\nfrom .transform import Transform, Translation, Rotation, Scale\n\n\n# ==============================================================================\n# -- Helpers -------------------------------------------------------------------\n# ==============================================================================\n\n\nColor = namedtuple(\'Color\', \'r g b\')\nColor.__new__.__defaults__ = (0, 0, 0)\n\n\nPoint = namedtuple(\'Point\', \'x y z color\')\nPoint.__new__.__defaults__ = (0.0, 0.0, 0.0, None)\n\n\ndef _append_extension(filename, ext):\n    return filename if filename.lower().endswith(ext.lower()) else filename + ext\n\n\n# ==============================================================================\n# -- Sensor --------------------------------------------------------------------\n# ==============================================================================\n\n\nclass Sensor(object):\n    """"""\n    Base class for sensor descriptions. Used to add sensors to CarlaSettings.\n    """"""\n\n    def __init__(self, name, sensor_type):\n        self.SensorName = name\n        self.SensorType = sensor_type\n        self.PositionX = 0.2\n        self.PositionY = 0.0\n        self.PositionZ = 1.3\n        self.RotationPitch = 0.0\n        self.RotationRoll = 0.0\n        self.RotationYaw = 0.0\n\n    def set(self, **kwargs):\n        for key, value in kwargs.items():\n            if not hasattr(self, key):\n                raise ValueError(\'sensor.Sensor: no key named %r\' % key)\n            setattr(self, key, value)\n\n    def set_position(self, x, y, z):\n        self.PositionX = x\n        self.PositionY = y\n        self.PositionZ = z\n\n    def set_rotation(self, pitch, yaw, roll):\n        self.RotationPitch = pitch\n        self.RotationYaw = yaw\n        self.RotationRoll = roll\n\n    def get_transform(self):\n        \'\'\'\n        Returns the camera to [whatever the camera is attached to]\n        transformation.\n        \'\'\'\n        return Transform(\n            Translation(self.PositionX, self.PositionY, self.PositionZ),\n            Rotation(self.RotationPitch, self.RotationYaw, self.RotationRoll))\n\n    def get_unreal_transform(self):\n        \'\'\'\n        Returns the camera to [whatever the camera is attached to]\n        transformation with the Unreal necessary corrections applied.\n\n        @todo Do we need to expose this?\n        \'\'\'\n        to_unreal_transform = Transform(Rotation(roll=-90, yaw=90), Scale(x=-1))\n        return self.get_transform() * to_unreal_transform\n\n\nclass Camera(Sensor):\n    """"""\n    Camera description. This class can be added to a CarlaSettings object to add\n    a camera to the player vehicle.\n    """"""\n\n    def __init__(self, name, **kwargs):\n        super(Camera, self).__init__(name, sensor_type=""CAMERA"")\n        self.PostProcessing = \'SceneFinal\'\n        self.ImageSizeX = 720\n        self.ImageSizeY = 512\n        self.FOV = 90.0\n        self.set(**kwargs)\n\n    def set_image_size(self, pixels_x, pixels_y):\n        \'\'\'Sets the image size in pixels\'\'\'\n        self.ImageSizeX = pixels_x\n        self.ImageSizeY = pixels_y\n\n\nclass Lidar(Sensor):\n    """"""\n    Lidar description. This class can be added to a CarlaSettings object to add\n    a Lidar to the player vehicle.\n    """"""\n\n    def __init__(self, name, **kwargs):\n        super(Lidar, self).__init__(name, sensor_type=""LIDAR_RAY_CAST"")\n        self.Channels = 32\n        self.Range = 50.0\n        self.PointsPerSecond = 56000\n        self.RotationFrequency = 10.0\n        self.UpperFovLimit = 10.0\n        self.LowerFovLimit = -30.0\n        self.ShowDebugPoints = False\n        self.set(**kwargs)\n\n\n# ==============================================================================\n# -- SensorData ----------------------------------------------------------------\n# ==============================================================================\n\n\nclass SensorData(object):\n    """"""Base class for sensor data returned from the server.""""""\n    def __init__(self, frame_number):\n        self.frame_number = frame_number\n\n\nclass Image(SensorData):\n    """"""Data generated by a Camera.""""""\n\n    def __init__(self, frame_number, width, height, image_type, fov, raw_data):\n        super(Image, self).__init__(frame_number=frame_number)\n        assert len(raw_data) == 4 * width * height\n        self.width = width\n        self.height = height\n        self.type = image_type\n        self.fov = fov\n        self.raw_data = raw_data\n        self._converted_data = None\n\n    @property\n    def data(self):\n        """"""\n        Lazy initialization for data property, stores converted data in its\n        default format.\n        """"""\n        if self._converted_data is None:\n            from . import image_converter\n\n            if self.type == \'Depth\':\n                self._converted_data = image_converter.depth_to_array(self)\n            elif self.type == \'SemanticSegmentation\':\n                self._converted_data = image_converter.labels_to_array(self)\n            else:\n                self._converted_data = image_converter.to_rgb_array(self)\n        return self._converted_data\n\n    def save_to_disk(self, filename):\n        """"""Save this image to disk (requires PIL installed).""""""\n        filename = _append_extension(filename, \'.png\')\n\n        try:\n            from PIL import Image as PImage\n        except ImportError:\n            raise RuntimeError(\n                \'cannot import PIL, make sure pillow package is installed\')\n\n        image = PImage.frombytes(\n            mode=\'RGBA\',\n            size=(self.width, self.height),\n            data=self.raw_data,\n            decoder_name=\'raw\')\n        color = image.split()\n        image = PImage.merge(""RGB"", color[2::-1])\n\n        folder = os.path.dirname(filename)\n        if not os.path.isdir(folder):\n            os.makedirs(folder)\n        image.save(filename)\n\n\nclass PointCloud(SensorData):\n    """"""A list of points.""""""\n\n    def __init__(self, frame_number, array, color_array=None):\n        super(PointCloud, self).__init__(frame_number=frame_number)\n        self._array = array\n        self._color_array = color_array\n        self._has_colors = color_array is not None\n\n    @property\n    def array(self):\n        """"""The numpy array holding the point-cloud.\n\n        3D points format for n elements:\n        [ [X0,Y0,Z0],\n          ...,\n          [Xn,Yn,Zn] ]\n        """"""\n        return self._array\n\n    @property\n    def color_array(self):\n        """"""The numpy array holding the colors corresponding to each point.\n        It is None if there are no colors.\n\n        Colors format for n elements:\n        [ [R0,G0,B0],\n          ...,\n          [Rn,Gn,Bn] ]\n        """"""\n        return self._color_array\n\n    def has_colors(self):\n        """"""Return whether the points have color.""""""\n        return self._has_colors\n\n    def apply_transform(self, transformation):\n        """"""Modify the PointCloud instance transforming its points""""""\n        self._array = transformation.transform_points(self._array)\n\n    def save_to_disk(self, filename):\n        """"""Save this point-cloud to disk as PLY format.""""""\n        filename = _append_extension(filename, \'.ply\')\n\n        def construct_ply_header():\n            """"""Generates a PLY header given a total number of 3D points and\n            coloring property if specified\n            """"""\n            points = len(self)  # Total point number\n            header = [\'ply\',\n                      \'format ascii 1.0\',\n                      \'element vertex {}\',\n                      \'property float32 x\',\n                      \'property float32 y\',\n                      \'property float32 z\',\n                      \'property uchar diffuse_red\',\n                      \'property uchar diffuse_green\',\n                      \'property uchar diffuse_blue\',\n                      \'end_header\']\n            if not self._has_colors:\n                return \'\\n\'.join(header[0:6] + [header[-1]]).format(points)\n            return \'\\n\'.join(header).format(points)\n\n        if not self._has_colors:\n            ply = \'\\n\'.join([\'{:.2f} {:.2f} {:.2f}\'.format(\n                *p) for p in self._array.tolist()])\n        else:\n            points_3d = numpy.concatenate(\n                (self._array, self._color_array), axis=1)\n            ply = \'\\n\'.join([\'{:.2f} {:.2f} {:.2f} {:.0f} {:.0f} {:.0f}\'\n                             .format(*p) for p in points_3d.tolist()])\n\n        # Create folder to save if does not exist.\n        folder = os.path.dirname(filename)\n        if not os.path.isdir(folder):\n            os.makedirs(folder)\n\n        # Open the file and save with the specific PLY format.\n        with open(filename, \'w+\') as ply_file:\n            ply_file.write(\'\\n\'.join([construct_ply_header(), ply]))\n\n    def __len__(self):\n        return len(self.array)\n\n    def __getitem__(self, key):\n        color = None if self._color_array is None else Color(\n            *self._color_array[key])\n        return Point(*self._array[key], color=color)\n\n    def __iter__(self):\n        class PointIterator(object):\n            """"""Iterator class for PointCloud""""""\n\n            def __init__(self, point_cloud):\n                self.point_cloud = point_cloud\n                self.index = -1\n\n            def __next__(self):\n                self.index += 1\n                if self.index >= len(self.point_cloud):\n                    raise StopIteration\n                return self.point_cloud[self.index]\n\n            def next(self):\n                return self.__next__()\n\n        return PointIterator(self)\n\n    def __str__(self):\n        return str(self.array)\n\n\nclass LidarMeasurement(SensorData):\n    """"""Data generated by a Lidar.""""""\n\n    def __init__(self, frame_number, horizontal_angle, channels, point_count_by_channel, point_cloud):\n        super(LidarMeasurement, self).__init__(frame_number=frame_number)\n        assert numpy.sum(point_count_by_channel) == len(point_cloud.array)\n        self.horizontal_angle = horizontal_angle\n        self.channels = channels\n        self.point_count_by_channel = point_count_by_channel\n        self.point_cloud = point_cloud\n\n    @property\n    def data(self):\n        """"""The numpy array holding the point-cloud.\n\n        3D points format for n elements:\n        [ [X0,Y0,Z0],\n          ...,\n          [Xn,Yn,Zn] ]\n        """"""\n        return self.point_cloud.array\n\n    def save_to_disk(self, filename):\n        """"""Save point-cloud to disk as PLY format.""""""\n        self.point_cloud.save_to_disk(filename)\n'"
ch8/environment/carla_gym/envs/carla/settings.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""CARLA Settings""""""\n\nimport io\nimport random\nimport sys\n\n\nif sys.version_info >= (3, 0):\n\n    from configparser import ConfigParser\n\nelse:\n\n    from ConfigParser import RawConfigParser as ConfigParser\n\n\nfrom . import sensor as carla_sensor\n\n\nMAX_NUMBER_OF_WEATHER_IDS = 14\n\n\nclass CarlaSettings(object):\n    """"""\n    The CarlaSettings object controls the settings of an episode.  The __str__\n    method retrieves an str with a CarlaSettings.ini file contents.\n    """"""\n\n    def __init__(self, **kwargs):\n        # [CARLA/Server]\n        self.SynchronousMode = True\n        self.SendNonPlayerAgentsInfo = False\n        # [CARLA/QualitySettings]\n        self.QualityLevel = \'Epic\'\n        # [CARLA/LevelSettings]\n        self.PlayerVehicle = None\n        self.NumberOfVehicles = 20\n        self.NumberOfPedestrians = 30\n        self.WeatherId = 1\n        self.SeedVehicles = None\n        self.SeedPedestrians = None\n        self.set(**kwargs)\n        self._sensors = []\n\n    def set(self, **kwargs):\n        for key, value in kwargs.items():\n            if not hasattr(self, key):\n                raise ValueError(\'CarlaSettings: no key named %r\' % key)\n            setattr(self, key, value)\n\n    def randomize_seeds(self):\n        """"""\n        Randomize the seeds of the new episode\'s pseudo-random number\n        generators.\n        """"""\n        self.SeedVehicles = random.getrandbits(16)\n        self.SeedPedestrians = random.getrandbits(16)\n\n    def randomize_weather(self):\n        """"""Randomized the WeatherId.""""""\n        self.WeatherId = random.randint(0, MAX_NUMBER_OF_WEATHER_IDS)\n\n    def add_sensor(self, sensor):\n        """"""Add a sensor to the player vehicle (see sensor.py).""""""\n        if not isinstance(sensor, carla_sensor.Sensor):\n            raise ValueError(\'Sensor not supported\')\n        self._sensors.append(sensor)\n\n    def __str__(self):\n        """"""Converts this object to an INI formatted string.""""""\n        ini = ConfigParser()\n        ini.optionxform = str\n        S_SERVER = \'CARLA/Server\'\n        S_QUALITY = \'CARLA/QualitySettings\'\n        S_LEVEL = \'CARLA/LevelSettings\'\n        S_SENSOR = \'CARLA/Sensor\'\n\n        def get_attribs(obj):\n            return [a for a in dir(obj) if not a.startswith(\'_\') and not callable(getattr(obj, a))]\n\n        def add_section(section, obj, keys):\n            for key in keys:\n                if hasattr(obj, key) and getattr(obj, key) is not None:\n                    if not ini.has_section(section):\n                        ini.add_section(section)\n                    ini.set(section, key, str(getattr(obj, key)))\n\n        add_section(S_SERVER, self, [\n            \'SynchronousMode\',\n            \'SendNonPlayerAgentsInfo\'])\n        add_section(S_QUALITY, self, [\n            \'QualityLevel\'])\n        add_section(S_LEVEL, self, [\n            \'NumberOfVehicles\',\n            \'NumberOfPedestrians\',\n            \'WeatherId\',\n            \'SeedVehicles\',\n            \'SeedPedestrians\'])\n\n        ini.add_section(S_SENSOR)\n        ini.set(S_SENSOR, \'Sensors\', \',\'.join(s.SensorName for s in self._sensors))\n\n        for sensor_def in self._sensors:\n            section = S_SENSOR + \'/\' + sensor_def.SensorName\n            add_section(section, sensor_def, get_attribs(sensor_def))\n\n        if sys.version_info >= (3, 0):\n            text = io.StringIO()\n        else:\n            text = io.BytesIO()\n\n        ini.write(text)\n        return text.getvalue().replace(\' = \', \'=\')\n'"
ch8/environment/carla_gym/envs/carla/tcp.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""Basic TCP client.""""""\n\nimport logging\nimport socket\nimport struct\nimport time\n\nclass TCPConnectionError(Exception):\n    pass\n\n\nclass TCPClient(object):\n    """"""\n    Basic networking client for TCP connections. Errors occurred during\n    networking operations are raised as TCPConnectionError.\n\n    Received messages are expected to be prepended by a int32 defining the\n    message size. Messages are sent following this convention.\n    """"""\n\n    def __init__(self, host, port, timeout):\n        self._host = host\n        self._port = port\n        self._timeout = timeout\n        self._socket = None\n        self._logprefix = \'(%s:%s) \' % (self._host, self._port)\n\n    def connect(self, connection_attempts=10):\n        """"""Try to establish a connection to the given host:port.""""""\n        connection_attempts = max(1, connection_attempts)\n        error = None\n        for attempt in range(1, connection_attempts + 1):\n            try:\n                self._socket = socket.create_connection(address=(self._host, self._port), timeout=self._timeout)\n                self._socket.settimeout(self._timeout)\n                logging.debug(\'%sconnected\', self._logprefix)\n                return\n            except socket.error as exception:\n                error = exception\n                logging.debug(\'%sconnection attempt %d: %s\', self._logprefix, attempt, error)\n                time.sleep(1)\n        self._reraise_exception_as_tcp_error(\'failed to connect\', error)\n\n    def disconnect(self):\n        """"""Disconnect any active connection.""""""\n        if self._socket is not None:\n            logging.debug(\'%sdisconnecting\', self._logprefix)\n            self._socket.close()\n            self._socket = None\n\n    def connected(self):\n        """"""Return whether there is an active connection.""""""\n        return self._socket is not None\n\n    def write(self, message):\n        """"""Send message to the server.""""""\n        if self._socket is None:\n            raise TCPConnectionError(self._logprefix + \'not connected\')\n        header = struct.pack(\'<L\', len(message))\n        try:\n            self._socket.sendall(header + message)\n        except socket.error as exception:\n            self._reraise_exception_as_tcp_error(\'failed to write data\', exception)\n\n    def read(self):\n        """"""Read a message from the server.""""""\n        header = self._read_n(4)\n        if not header:\n            raise TCPConnectionError(self._logprefix + \'connection closed\')\n        length = struct.unpack(\'<L\', header)[0]\n        data = self._read_n(length)\n        return data\n\n    def _read_n(self, length):\n        """"""Read n bytes from the socket.""""""\n        if self._socket is None:\n            raise TCPConnectionError(self._logprefix + \'not connected\')\n        buf = bytes()\n        while length > 0:\n            try:\n                data = self._socket.recv(length)\n            except socket.error as exception:\n                self._reraise_exception_as_tcp_error(\'failed to read data\', exception)\n            if not data:\n                raise TCPConnectionError(self._logprefix + \'connection closed\')\n            buf += data\n            length -= len(data)\n        return buf\n\n    def _reraise_exception_as_tcp_error(self, message, exception):\n        raise TCPConnectionError(\'%s%s: %s\' % (self._logprefix, message, exception))\n'"
ch8/environment/carla_gym/envs/carla/transform.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB), and the INTEL Visual Computing Lab.\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport math\n\nfrom collections import namedtuple\n\ntry:\n    import numpy\nexcept ImportError:\n    raise RuntimeError(\n        \'cannot import numpy, make sure numpy package is installed.\')\n\ntry:\n    from . import carla_server_pb2 as carla_protocol\nexcept ImportError:\n    raise RuntimeError(\'cannot import ""carla_server_pb2.py"", run \'\n                       \'the protobuf compiler to generate this file\')\n\n\nTranslation = namedtuple(\'Translation\', \'x y z\')\nTranslation.__new__.__defaults__ = (0.0, 0.0, 0.0)\n\nRotation = namedtuple(\'Rotation\', \'pitch yaw roll\')\nRotation.__new__.__defaults__ = (0.0, 0.0, 0.0)\n\nScale = namedtuple(\'Scale\', \'x y z\')\nScale.__new__.__defaults__ = (1.0, 1.0, 1.0)\n\n\nclass Transform(object):\n    """"""A 3D transformation.\n\n    The transformation is applied in the order: scale, rotation, translation.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        if \'matrix\' in kwargs:\n            self.matrix = kwargs[\'matrix\']\n            return\n        if isinstance(args[0], carla_protocol.Transform):\n            args = [\n                Translation(\n                    args[0].location.x,\n                    args[0].location.y,\n                    args[0].location.z),\n                Rotation(\n                    args[0].rotation.pitch,\n                    args[0].rotation.yaw,\n                    args[0].rotation.roll)\n            ]\n        self.matrix = numpy.matrix(numpy.identity(4))\n        self.set(*args, **kwargs)\n\n    def set(self, *args):\n        """"""Builds the transform matrix given a Translate, Rotation\n        and Scale.\n        """"""\n        translation = Translation()\n        rotation = Rotation()\n        scale = Scale()\n\n        if len(args) > 3:\n            raise ValueError(""\'Transform\' accepts 3 values as maximum."")\n\n        def get_single_obj_type(obj_type):\n            """"""Returns the unique object contained in the\n            arguments lists that is instance of \'obj_type\'.\n            """"""\n            obj = [x for x in args if isinstance(x, obj_type)]\n            if len(obj) > 1:\n                raise ValueError(""Transform only accepts one instances of "" +\n                                 str(obj_type) + "" as a parameter"")\n            elif not obj:\n                # Create an instance of the type that is \'obj_type\'\n                return obj_type()\n            return obj[0]\n\n        translation = get_single_obj_type(Translation)\n        rotation = get_single_obj_type(Rotation)\n        scale = get_single_obj_type(Scale)\n\n        for param in args:\n            if not isinstance(param, Translation) and \\\n               not isinstance(param, Rotation) and \\\n               not isinstance(param, Scale):\n                raise TypeError(\n                    ""\'"" + str(type(param)) + ""\' type not match with \\\n                    \'Translation\', \'Rotation\' or \'Scale\'"")\n\n        # Transformation matrix\n        cy = math.cos(numpy.radians(rotation.yaw))\n        sy = math.sin(numpy.radians(rotation.yaw))\n        cr = math.cos(numpy.radians(rotation.roll))\n        sr = math.sin(numpy.radians(rotation.roll))\n        cp = math.cos(numpy.radians(rotation.pitch))\n        sp = math.sin(numpy.radians(rotation.pitch))\n        self.matrix[0, 3] = translation.x\n        self.matrix[1, 3] = translation.y\n        self.matrix[2, 3] = translation.z\n        self.matrix[0, 0] = scale.x * (cp * cy)\n        self.matrix[0, 1] = scale.y * (cy * sp * sr - sy * cr)\n        self.matrix[0, 2] = -scale.z * (cy * sp * cr + sy * sr)\n        self.matrix[1, 0] = scale.x * (sy * cp)\n        self.matrix[1, 1] = scale.y * (sy * sp * sr + cy * cr)\n        self.matrix[1, 2] = scale.z * (cy * sr - sy * sp * cr)\n        self.matrix[2, 0] = scale.x * (sp)\n        self.matrix[2, 1] = -scale.y * (cp * sr)\n        self.matrix[2, 2] = scale.z * (cp * cr)\n\n    def inverse(self):\n        """"""Return the inverse transform.""""""\n        return Transform(matrix=numpy.linalg.inv(self.matrix))\n\n    def transform_points(self, points):\n        """"""\n        Given a 4x4 transformation matrix, transform an array of 3D points.\n        Expected point foramt: [[X0,Y0,Z0],..[Xn,Yn,Zn]]\n        """"""\n        # Needed foramt: [[X0,..Xn],[Z0,..Zn],[Z0,..Zn]]. So let\'s transpose\n        # the point matrix.\n        points = points.transpose()\n        # Add 0s row: [[X0..,Xn],[Y0..,Yn],[Z0..,Zn],[0,..0]]\n        points = numpy.append(points, numpy.ones((1, points.shape[1])), axis=0)\n        # Point transformation\n        points = self.matrix * points\n        # Return all but last row\n        return points[0:3].transpose()\n\n    def __mul__(self, other):\n        return Transform(matrix=numpy.dot(self.matrix, other.matrix))\n\n    def __str__(self):\n        return str(self.matrix)\n'"
ch8/environment/carla_gym/envs/carla/util.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport datetime\nimport sys\n\nfrom contextlib import contextmanager\n\n\n@contextmanager\ndef make_connection(client_type, *args, **kwargs):\n    """"""Context manager to create and connect a networking client object.""""""\n    client = None\n    try:\n        client = client_type(*args, **kwargs)\n        client.connect()\n        yield client\n    finally:\n        if client is not None:\n            client.disconnect()\n\n\nclass StopWatch(object):\n    def __init__(self):\n        self.start = datetime.datetime.now()\n        self.end = None\n\n    def restart(self):\n        self.start = datetime.datetime.now()\n        self.end = None\n\n    def stop(self):\n        self.end = datetime.datetime.now()\n\n    def seconds(self):\n        return (self.end - self.start).total_seconds()\n\n    def milliseconds(self):\n        return 1000.0 * self.seconds()\n\n\ndef to_hex_str(header):\n    return \':\'.join(\'{:02x}\'.format(ord(c)) for c in header)\n\n\nif sys.version_info >= (3, 3):\n\n    import shutil\n\n    def print_over_same_line(text):\n        terminal_width = shutil.get_terminal_size((80, 20)).columns\n        empty_space = max(0, terminal_width - len(text))\n        sys.stdout.write(\'\\r\' + text + empty_space * \' \')\n        sys.stdout.flush()\n\nelse:\n\n    # Workaround for older Python versions.\n    def print_over_same_line(text):\n        line_length = max(print_over_same_line.last_line_length, len(text))\n        empty_space = max(0, line_length - len(text))\n        sys.stdout.write(\'\\r\' + text + empty_space * \' \')\n        sys.stdout.flush()\n        print_over_same_line.last_line_length = line_length\n    print_over_same_line.last_line_length = 0\n'"
ch7/carla-gym/carla_gym/envs/carla/agent/__init__.py,0,b'from .forward_agent import ForwardAgent\nfrom .agent import Agent\n'
ch7/carla-gym/carla_gym/envs/carla/agent/agent.py,0,"b'# -*- coding: utf-8 -*-\n# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n# @author: german,felipecode\n\n\nfrom __future__ import print_function\nimport abc\n\n\nclass Agent(object):\n    def __init__(self):\n        self.__metaclass__ = abc.ABCMeta\n\n    @abc.abstractmethod\n    def run_step(self, measurements, sensor_data, directions, target):\n        """"""\n        Function to be redefined by an agent.\n        :param The measurements like speed, the image data and a target\n        :returns A carla Control object, with the steering/gas/brake for the agent\n        """"""\n'"
ch7/carla-gym/carla_gym/envs/carla/agent/forward_agent.py,0,"b'\nfrom .agent import Agent\nfrom ..client import VehicleControl\n\n\nclass ForwardAgent(Agent):\n    """"""\n    Simple derivation of Agent Class,\n    A trivial agent agent that goes straight\n    """"""\n    def run_step(self, measurements, sensor_data, directions, target):\n        control = VehicleControl()\n        control.throttle = 0.9\n\n        return control\n'"
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/__init__.py,0,b''
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/driving_benchmark.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n\nimport abc\nimport logging\nimport math\nimport time\n\nfrom ..client import VehicleControl\nfrom ..client import make_carla_client\nfrom ..driving_benchmark.metrics import Metrics\nfrom ..planner.planner import Planner\nfrom ..settings import CarlaSettings\nfrom ..tcp import TCPConnectionError\n\nfrom . import results_printer\nfrom .recording import Recording\n\n\ndef sldist(c1, c2):\n    return math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2)\n\n\nclass DrivingBenchmark(object):\n    """"""\n    The Benchmark class, controls the execution of the benchmark interfacing\n    an Agent class with a set Suite.\n\n\n    The benchmark class must be inherited with a class that defines the\n    all the experiments to be run by the agent\n    """"""\n\n    def __init__(\n            self,\n            city_name=\'Town01\',\n            name_to_save=\'Test\',\n            continue_experiment=False,\n            save_images=False,\n            distance_for_success=2.0\n    ):\n\n        self.__metaclass__ = abc.ABCMeta\n\n        self._city_name = city_name\n        self._base_name = name_to_save\n        # The minimum distance for arriving into the goal point in\n        # order to consider ir a success\n        self._distance_for_success = distance_for_success\n        # The object used to record the benchmark and to able to continue after\n        self._recording = Recording(name_to_save=name_to_save,\n                                    continue_experiment=continue_experiment,\n                                    save_images=save_images\n                                    )\n\n        # We have a default planner instantiated that produces high level commands\n        self._planner = Planner(city_name)\n\n    def benchmark_agent(self, experiment_suite, agent, client):\n        """"""\n        Function to benchmark the agent.\n        It first check the log file for this benchmark.\n        if it exist it continues from the experiment where it stopped.\n\n\n        Args:\n            experiment_suite\n            agent: an agent object with the run step class implemented.\n            client:\n\n\n        Return:\n            A dictionary with all the metrics computed from the\n            agent running the set of experiments.\n        """"""\n\n        # Instantiate a metric object that will be used to compute the metrics for\n        # the benchmark afterwards.\n        metrics_object = Metrics(experiment_suite.metrics_parameters,\n                                 experiment_suite.dynamic_tasks)\n\n        # Function return the current pose and task for this benchmark.\n        start_pose, start_experiment = self._recording.get_pose_and_experiment(\n            experiment_suite.get_number_of_poses_task())\n\n        logging.info(\'START\')\n\n        for experiment in experiment_suite.get_experiments()[int(start_experiment):]:\n\n            positions = client.load_settings(\n                experiment.conditions).player_start_spots\n\n            self._recording.log_start(experiment.task)\n\n            for pose in experiment.poses[start_pose:]:\n                for rep in range(experiment.repetitions):\n\n                    start_index = pose[0]\n                    end_index = pose[1]\n\n                    client.start_episode(start_index)\n                    # Print information on\n                    logging.info(\'======== !!!! ==========\')\n                    logging.info(\' Start Position %d End Position %d \',\n                                 start_index, end_index)\n\n                    self._recording.log_poses(start_index, end_index,\n                                              experiment.Conditions.WeatherId)\n\n                    # Calculate the initial distance for this episode\n                    initial_distance = \\\n                        sldist(\n                            [positions[start_index].location.x, positions[start_index].location.y],\n                            [positions[end_index].location.x, positions[end_index].location.y])\n\n                    time_out = experiment_suite.calculate_time_out(\n                        self._get_shortest_path(positions[start_index], positions[end_index]))\n\n                    # running the agent\n                    (result, reward_vec, control_vec, final_time, remaining_distance) = \\\n                        self._run_navigation_episode(\n                            agent, client, time_out, positions[end_index],\n                            str(experiment.Conditions.WeatherId) + \'_\'\n                            + str(experiment.task) + \'_\' + str(start_index)\n                            + \'.\' + str(end_index))\n\n                    # Write the general status of the just ran episode\n                    self._recording.write_summary_results(\n                        experiment, pose, rep, initial_distance,\n                        remaining_distance, final_time, time_out, result)\n\n                    # Write the details of this episode.\n                    self._recording.write_measurements_results(experiment, rep, pose, reward_vec,\n                                                               control_vec)\n                    if result > 0:\n                        logging.info(\'+++++ Target achieved in %f seconds! +++++\',\n                                     final_time)\n                    else:\n                        logging.info(\'----- Timeout! -----\')\n\n            start_pose = 0\n\n        self._recording.log_end()\n\n        return metrics_object.compute(self._recording.path)\n\n    def get_path(self):\n        """"""\n        Returns the path were the log was saved.\n        """"""\n        return self._recording.path\n\n    def _get_directions(self, current_point, end_point):\n        """"""\n        Class that should return the directions to reach a certain goal\n        """"""\n\n        directions = self._planner.get_next_command(\n            (current_point.location.x,\n             current_point.location.y, 0.22),\n            (current_point.orientation.x,\n             current_point.orientation.y,\n             current_point.orientation.z),\n            (end_point.location.x, end_point.location.y, 0.22),\n            (end_point.orientation.x, end_point.orientation.y, end_point.orientation.z))\n        return directions\n\n    def _get_shortest_path(self, start_point, end_point):\n        """"""\n        Calculates the shortest path between two points considering the road netowrk\n        """"""\n\n        return self._planner.get_shortest_path_distance(\n            [\n                start_point.location.x, start_point.location.y, 0.22], [\n                start_point.orientation.x, start_point.orientation.y, 0.22], [\n                end_point.location.x, end_point.location.y, end_point.location.z], [\n                end_point.orientation.x, end_point.orientation.y, end_point.orientation.z])\n\n    def _run_navigation_episode(\n            self,\n            agent,\n            client,\n            time_out,\n            target,\n            episode_name):\n        """"""\n         Run one episode of the benchmark (Pose) for a certain agent.\n\n\n        Args:\n            agent: the agent object\n            client: an object of the carla client to communicate\n            with the CARLA simulator\n            time_out: the time limit to complete this episode\n            target: the target to reach\n            episode_name: The name for saving images of this episode\n\n        """"""\n\n        # Send an initial command.\n        measurements, sensor_data = client.read_data()\n        client.send_control(VehicleControl())\n\n        initial_timestamp = measurements.game_timestamp\n        current_timestamp = initial_timestamp\n\n        # The vector containing all measurements produced on this episode\n        measurement_vec = []\n        # The vector containing all controls produced on this episode\n        control_vec = []\n        frame = 0\n        distance = 10000\n        success = False\n\n        while (current_timestamp - initial_timestamp) < (time_out * 1000) and not success:\n\n            # Read data from server with the client\n            measurements, sensor_data = client.read_data()\n            # The directions to reach the goal are calculated.\n            directions = self._get_directions(measurements.player_measurements.transform, target)\n            # Agent process the data.\n            control = agent.run_step(measurements, sensor_data, directions, target)\n            # Send the control commands to the vehicle\n            client.send_control(control)\n\n            # save images if the flag is activated\n            self._recording.save_images(sensor_data, episode_name, frame)\n\n            current_x = measurements.player_measurements.transform.location.x\n            current_y = measurements.player_measurements.transform.location.y\n\n            logging.info(""Controller is Inputting:"")\n            logging.info(\'Steer = %f Throttle = %f Brake = %f \',\n                         control.steer, control.throttle, control.brake)\n\n            current_timestamp = measurements.game_timestamp\n            # Get the distance travelled until now\n            distance = sldist([current_x, current_y],\n                              [target.location.x, target.location.y])\n            # Write status of the run on verbose mode\n            logging.info(\'Status:\')\n            logging.info(\n                \'[d=%f] c_x = %f, c_y = %f ---> t_x = %f, t_y = %f\',\n                float(distance), current_x, current_y, target.location.x,\n                target.location.y)\n            # Check if reach the target\n            if distance < self._distance_for_success:\n                success = True\n\n            # Increment the vectors and append the measurements and controls.\n            frame += 1\n            measurement_vec.append(measurements.player_measurements)\n            control_vec.append(control)\n\n        if success:\n            return 1, measurement_vec, control_vec, float(\n                current_timestamp - initial_timestamp) / 1000.0, distance\n        return 0, measurement_vec, control_vec, time_out, distance\n\n\ndef run_driving_benchmark(agent,\n                          experiment_suite,\n                          city_name=\'Town01\',\n                          log_name=\'Test\',\n                          continue_experiment=False,\n                          host=\'127.0.0.1\',\n                          port=2000\n                          ):\n    while True:\n        try:\n\n            with make_carla_client(host, port) as client:\n                # Hack to fix for the issue 310, we force a reset, so it does not get\n                #  the positions on first server reset.\n                client.load_settings(CarlaSettings())\n                client.start_episode(0)\n\n                # We instantiate the driving benchmark, that is the engine used to\n                # benchmark an agent. The instantiation starts the log process, sets\n\n                benchmark = DrivingBenchmark(city_name=city_name,\n                                             name_to_save=log_name + \'_\'\n                                                          + type(experiment_suite).__name__\n                                                          + \'_\' + city_name,\n                                             continue_experiment=continue_experiment)\n                # This function performs the benchmark. It returns a dictionary summarizing\n                # the entire execution.\n\n                benchmark_summary = benchmark.benchmark_agent(experiment_suite, agent, client)\n\n                print("""")\n                print("""")\n                print(""----- Printing results for training weathers (Seen in Training) -----"")\n                print("""")\n                print("""")\n                results_printer.print_summary(benchmark_summary, experiment_suite.train_weathers,\n                                              benchmark.get_path())\n\n                print("""")\n                print("""")\n                print(""----- Printing results for test weathers (Unseen in Training) -----"")\n                print("""")\n                print("""")\n\n                results_printer.print_summary(benchmark_summary, experiment_suite.test_weathers,\n                                              benchmark.get_path())\n\n                break\n\n        except TCPConnectionError as error:\n            logging.error(error)\n            time.sleep(1)\n'"
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/experiment.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nfrom ..settings import CarlaSettings\n\n\nclass Experiment(object):\n    """"""\n    Experiment defines a certain task, under conditions\n    A task is associated with a set of poses, containing start and end pose.\n\n    Conditions are associated with a carla Settings and describe the following:\n\n    Number Of Vehicles\n    Number Of Pedestrians\n    Weather\n    Random Seed of the agents, describing their behaviour.\n\n    """"""\n\n    def __init__(self):\n        self.Task = 0\n        self.Conditions = CarlaSettings()\n        self.Poses = [[]]\n        self.Repetitions = 1\n\n    def set(self, **kwargs):\n        for key, value in kwargs.items():\n            if not hasattr(self, key):\n                raise ValueError(\'Experiment: no key named %r\' % key)\n            setattr(self, key, value)\n\n        if self.Repetitions != 1:\n            raise NotImplementedError()\n\n    @property\n    def task(self):\n        return self.Task\n\n    @property\n    def conditions(self):\n        return self.Conditions\n\n    @property\n    def poses(self):\n        return self.Poses\n\n    @property\n    def repetitions(self):\n        return self.Repetitions\n'"
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/metrics.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n\nimport numpy as np\nimport math\nimport os\n\nsldist = lambda c1, c2: math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2)\nflatten = lambda l: [item for sublist in l for item in sublist]\n\n\nclass Metrics(object):\n    """"""\n        The metrics class is made to take the driving measurements\n        and calculate some specific performance metrics.\n\n    """"""\n\n    def __init__(self, parameters, dynamic_tasks):\n        """"""\n        Args\n            parameters: A dictionary with the used parameters for checking how to count infractions\n            dynamic_tasks: A list of the all dynamic tasks (That contain dynamic objects)\n        """"""\n\n        self._parameters = parameters\n        self._parameters[\'dynamic_tasks\'] = dynamic_tasks\n\n    def _divide_by_episodes(self, measurements_matrix, header):\n\n        """"""\n            Divides the measurements matrix on different episodes.\n\n            Args:\n                measurements_matrix: The full measurements matrix\n                header: The header from the measurements matrix\n\n        """"""\n\n        # Read previous for position zero\n        prev_start = measurements_matrix[0, header.index(\'start_point\')]\n        prev_end = measurements_matrix[0, header.index(\'end_point\')]\n        prev_exp_id = measurements_matrix[0, header.index(\'exp_id\')]\n\n        # Start at the position 1.\n        i = 1\n        prev_i_position = 0\n        episode_matrix_metrics = []\n\n        while i < measurements_matrix.shape[0]:\n\n            current_start = measurements_matrix[i, header.index(\'start_point\')]\n            current_end = measurements_matrix[i, header.index(\'end_point\')]\n            current_exp_id = measurements_matrix[i, header.index(\'exp_id\')]\n\n            # If there is a change in the position it means it is a new episode for sure.\n            if (current_start != prev_start and current_end != prev_end) \\\n                    or current_exp_id != prev_exp_id:\n                episode_matrix_metrics.append(measurements_matrix[prev_i_position:i, :])\n                prev_i_position = i\n\n            prev_start = current_start\n            prev_end = current_end\n            prev_exp_id = current_exp_id\n\n            i += 1\n\n        episode_matrix_metrics.append(measurements_matrix[prev_i_position:-1, :])\n\n        return episode_matrix_metrics\n\n    def _get_collisions(self, selected_matrix, header):\n        """"""\n            Get the number of collisions for pedestrians, vehicles or other\n        Args:\n            selected_matrix: The matrix with all the experiments summary\n            header: The header , to know the positions of details\n\n\n        """"""\n        count_collisions_general = 0\n        count_collisions_pedestrian = 0\n        count_collisions_vehicle = 0\n        i = 1\n        # Computing general collisions\n        while i < selected_matrix.shape[0]:\n            if (selected_matrix[i, header.index(\'collision_other\')]\n                - selected_matrix[\n                    (i - self._parameters[\'collision_other\'][\'frames_skip\']), header.index(\n                        \'collision_other\')]) > \\\n                    self._parameters[\'collision_other\'][\'threshold\']:\n                count_collisions_general += 1\n                i += self._parameters[\'collision_other\'][\'frames_recount\']\n            i += 1\n\n        i = 1\n        # Computing collisions for vehicles\n        while i < selected_matrix.shape[0]:\n            if (selected_matrix[i, header.index(\'collision_vehicles\')]\n                - selected_matrix[\n                    (i - self._parameters[\'collision_vehicles\'][\'frames_skip\']), header.index(\n                        \'collision_vehicles\')]) > \\\n                    self._parameters[\'collision_vehicles\'][\'threshold\']:\n                count_collisions_vehicle += 1\n                i += self._parameters[\'collision_vehicles\'][\'frames_recount\']\n            i += 1\n\n        i = 1\n\n        # Computing the collisions for pedestrians\n        while i < selected_matrix.shape[0]:\n            if (selected_matrix[i, header.index(\'collision_pedestrians\')]\n                - selected_matrix[i - self._parameters[\'collision_pedestrians\'][\'frames_skip\'],\n                                  header.index(\'collision_pedestrians\')]) > \\\n                    self._parameters[\'collision_pedestrians\'][\'threshold\']:\n                count_collisions_pedestrian += 1\n                i += self._parameters[\'collision_pedestrians\'][\'frames_recount\']\n            i += 1\n\n        return count_collisions_general, count_collisions_vehicle, count_collisions_pedestrian\n\n    def _get_distance_traveled(self, selected_matrix, header):\n        """"""\n            Compute the total distance travelled\n        Args:\n            selected_matrix: The matrix with all the experiments summary\n            header: The header , to know the positions of details\n\n\n        """"""\n\n        prev_x = selected_matrix[0, header.index(\'pos_x\')]\n        prev_y = selected_matrix[0, header.index(\'pos_y\')]\n\n        i = 1\n        acummulated_distance = 0\n\n        while i < selected_matrix.shape[0]:\n            x = selected_matrix[i, header.index(\'pos_x\')]\n            y = selected_matrix[i, header.index(\'pos_y\')]\n\n            acummulated_distance += sldist((x, y), (prev_x, prev_y))\n\n            prev_x = x\n            prev_y = y\n\n            i += 1\n\n        return acummulated_distance / (1000.0)\n\n    def _get_out_of_road_lane(self, selected_matrix, header):\n\n        """"""\n            Check for the situations were the agent goes out of the road.\n        Args:\n            selected_matrix: The matrix with all the experiments summary\n            header: The header , to know the positions of details\n\n\n        """"""\n\n        count_sidewalk_intersect = 0\n        count_lane_intersect = 0\n\n        i = 0\n\n        while i < selected_matrix.shape[0]:\n\n            if (selected_matrix[i, header.index(\'intersection_offroad\')]\n                - selected_matrix[(i - self._parameters[\'intersection_offroad\'][\'frames_skip\']),\n                                  header.index(\'intersection_offroad\')]) \\\n                    > self._parameters[\'intersection_offroad\'][\'threshold\']:\n                count_sidewalk_intersect += 1\n                i += self._parameters[\'intersection_offroad\'][\'frames_recount\']\n            if i >= selected_matrix.shape[0]:\n                break\n\n            if (selected_matrix[i, header.index(\'intersection_otherlane\')]\n                - selected_matrix[(i - self._parameters[\'intersection_otherlane\'][\'frames_skip\']),\n                                  header.index(\'intersection_otherlane\')]) \\\n                    > self._parameters[\'intersection_otherlane\'][\'threshold\']:\n                count_lane_intersect += 1\n                i += self._parameters[\'intersection_otherlane\'][\'frames_recount\']\n\n            i += 1\n\n        return count_lane_intersect, count_sidewalk_intersect\n\n    def compute(self, path):\n\n        """"""\n            Compute a dictionary containing the following metrics\n\n            * Off Road Intersection: The number of times the agent goes out of the road.\n             The intersection is only counted if the area of the vehicle outside\n              of the road is bigger than a *threshold*.\n\n            * Other Lane Intersection: The number of times the agent goes to the other\n             lane. The intersection is only counted if the area of the vehicle on the\n             other lane is bigger than a *threshold*.\n\n            * Vehicle Collisions: The number of collisions with vehicles that have\n              an impact bigger than a *threshold*.\n\n            * Pedestrian Collisions: The number of collisions with pedestrians\n             that have an impact bigger than a threshold.\n\n            * General Collisions: The number of collisions with all other\n            objects.\n\n\n            Args:\n                path: Path where the log files are.\n\n        """"""\n\n        with open(os.path.join(path, \'summary.csv\'), ""rU"") as f:\n            header = f.readline()\n            header = header.split(\',\')\n            header[-1] = header[-1][:-1]\n\n        with open(os.path.join(path, \'measurements.csv\'), ""rU"") as f:\n\n            header_metrics = f.readline()\n            header_metrics = header_metrics.split(\',\')\n            header_metrics[-1] = header_metrics[-1][:-1]\n\n        result_matrix = np.loadtxt(os.path.join(path, \'summary.csv\'), delimiter="","", skiprows=1)\n\n        # Corner Case: The presented test just had one episode\n        if result_matrix.ndim == 1:\n            result_matrix = np.expand_dims(result_matrix, axis=0)\n\n        tasks = np.unique(result_matrix[:, header.index(\'exp_id\')])\n\n        all_weathers = np.unique(result_matrix[:, header.index(\'weather\')])\n\n        measurements_matrix = np.loadtxt(os.path.join(path, \'measurements.csv\'), delimiter="","",\n                                         skiprows=1)\n\n        metrics_dictionary = {\'episodes_completion\': {w: [0] * len(tasks) for w in all_weathers},\n                              \'intersection_offroad\': {w: [[] for i in range(len(tasks))] for w in\n                                                       all_weathers},\n                              \'intersection_otherlane\': {w: [[] for i in range(len(tasks))] for w in\n                                                         all_weathers},\n                              \'collision_pedestrians\': {w: [[] for i in range(len(tasks))] for w in\n                                                        all_weathers},\n                              \'collision_vehicles\': {w: [[] for i in range(len(tasks))] for w in\n                                                     all_weathers},\n                              \'collision_other\': {w: [[] for i in range(len(tasks))] for w in\n                                                  all_weathers},\n                              \'episodes_fully_completed\': {w: [0] * len(tasks) for w in\n                                                           all_weathers},\n                              \'average_speed\': {w: [0] * len(tasks) for w in all_weathers},\n                              \'driven_kilometers\': {w: [0] * len(tasks) for w in all_weathers}\n                              }\n\n        for t in range(len(tasks)):\n            experiment_results_matrix = result_matrix[\n                result_matrix[:, header.index(\'exp_id\')] == tasks[t]]\n\n            weathers = np.unique(experiment_results_matrix[:, header.index(\'weather\')])\n\n            for w in weathers:\n\n                experiment_results_matrix = result_matrix[\n                    np.logical_and(result_matrix[:, header.index(\n                        \'exp_id\')] == tasks[t], result_matrix[:, header.index(\'weather\')] == w)]\n\n                experiment_metrics_matrix = measurements_matrix[\n                    np.logical_and(measurements_matrix[:, header_metrics.index(\n                        \'exp_id\')] == float(tasks[t]),\n                                   measurements_matrix[:, header_metrics.index(\'weather\')] == float(\n                                       w))]\n\n                metrics_dictionary[\'episodes_fully_completed\'][w][t] = \\\n                    experiment_results_matrix[:, header.index(\'result\')].tolist()\n\n                metrics_dictionary[\'episodes_completion\'][w][t] = \\\n                    ((experiment_results_matrix[:, header.index(\'initial_distance\')]\n                      - experiment_results_matrix[:, header.index(\'final_distance\')])\n                     / experiment_results_matrix[:, header.index(\'initial_distance\')]).tolist()\n\n                # Now we divide the experiment metrics matrix\n\n                episode_experiment_metrics_matrix = self._divide_by_episodes(\n                    experiment_metrics_matrix, header_metrics)\n\n                count = 0\n\n                for episode_experiment_metrics in episode_experiment_metrics_matrix:\n\n                    km_run_episodes = self._get_distance_traveled(\n                        episode_experiment_metrics, header_metrics)\n                    metrics_dictionary[\'driven_kilometers\'][w][t] += km_run_episodes\n                    metrics_dictionary[\'average_speed\'][w][t] = \\\n                        km_run_episodes / (experiment_results_matrix[count,\n                                                                     header.index(\n                                                                         \'final_time\')] / 3600.0)\n                    count += 1\n\n                    lane_road = self._get_out_of_road_lane(\n                        episode_experiment_metrics, header_metrics)\n\n                    metrics_dictionary[\'intersection_otherlane\'][\n                        w][t].append(lane_road[0])\n                    metrics_dictionary[\'intersection_offroad\'][\n                        w][t].append(lane_road[1])\n\n                    if tasks[t] in set(self._parameters[\'dynamic_tasks\']):\n\n                        collisions = self._get_collisions(episode_experiment_metrics,\n                                                          header_metrics)\n\n                        metrics_dictionary[\'collision_pedestrians\'][\n                            w][t].append(collisions[2])\n                        metrics_dictionary[\'collision_vehicles\'][\n                            w][t].append(collisions[1])\n                        metrics_dictionary[\'collision_other\'][\n                            w][t].append(collisions[0])\n\n                    else:\n\n                        metrics_dictionary[\'collision_pedestrians\'][\n                            w][t].append(0)\n                        metrics_dictionary[\'collision_vehicles\'][\n                            w][t].append(0)\n                        metrics_dictionary[\'collision_other\'][\n                            w][t].append(0)\n\n        return metrics_dictionary\n'"
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/recording.py,0,"b'import csv\nimport datetime\nimport os\n\n\nclass Recording(object):\n\n    def __init__(self\n                 , name_to_save\n                 , continue_experiment\n                 , save_images\n                 ):\n\n        self._dict_summary = {\'exp_id\': -1,\n                              \'rep\': -1,\n                              \'weather\': -1,\n                              \'start_point\': -1,\n                              \'end_point\': -1,\n                              \'result\': -1,\n                              \'initial_distance\': -1,\n                              \'final_distance\': -1,\n                              \'final_time\': -1,\n                              \'time_out\': -1\n                              }\n        self._dict_measurements = {\'exp_id\': -1,\n                                   \'rep\': -1,\n                                   \'weather\': -1,\n                                   \'start_point\': -1,\n                                   \'end_point\': -1,\n                                   \'collision_other\': -1,\n                                   \'collision_pedestrians\': -1,\n                                   \'collision_vehicles\': -1,\n                                   \'intersection_otherlane\': -1,\n                                   \'intersection_offroad\': -1,\n                                   \'pos_x\': -1,\n                                   \'pos_y\': -1,\n                                   \'steer\': -1,\n                                   \'throttle\': -1,\n                                   \'brake\': -1\n                                   }\n\n        # Just in the case is the first time and there is no benchmark results folder\n        if not os.path.exists(\'_benchmarks_results\'):\n            os.mkdir(\'_benchmarks_results\')\n\n        # Generate the full path for the log files\n        self._path = os.path.join(\'_benchmarks_results\'\n                                  , name_to_save\n                                  )\n\n        # Check for continuation of experiment, also returns the last line, used for test purposes\n        # If you don\'t want to continue it will create a new path name with a number\n        self._path, _ = self._continue_experiment(continue_experiment)\n\n        self._create_log_files()\n\n        # A log with a date file: to show when was the last access and log what was tested,\n        now = datetime.datetime.now()\n        self._internal_log_name = os.path.join(self._path, \'log_\' + now.strftime(""%Y%m%d%H%M""))\n        open(self._internal_log_name, \'w\').close()\n\n        # store the save images flag, and already store the format for image saving\n        self._save_images = save_images\n        self._image_filename_format = os.path.join(\n            self._path, \'_images/episode_{:s}/{:s}/image_{:0>5d}.jpg\')\n\n    @property\n    def path(self):\n        return self._path\n\n    def log_poses(self, start_index, end_index, weather_id):\n        with open(self._internal_log_name, \'a+\') as log:\n            log.write(\' Start Poses  (%d  %d ) on weather %d \\n \' %\n                      (start_index, end_index, weather_id))\n\n    def log_poses_finish(self):\n        with open(self._internal_log_name, \'a+\') as log:\n            log.write(\'Finished Task\')\n\n    def log_start(self, id_experiment):\n\n        with open(self._internal_log_name, \'a+\') as log:\n            log.write(\'Start Task %d \\n\' % id_experiment)\n\n    def log_end(self):\n        with open(self._internal_log_name, \'a+\') as log:\n            log.write(\'====== Finished Entire Benchmark ======\')\n\n    def write_summary_results(self, experiment, pose, rep,\n                              path_distance, remaining_distance,\n                              final_time, time_out, result):\n        """"""\n        Method to record the summary of an episode(pose) execution\n        """"""\n\n        self._dict_summary[\'exp_id\'] = experiment.task\n        self._dict_summary[\'rep\'] = rep\n        self._dict_summary[\'weather\'] = experiment.Conditions.WeatherId\n        self._dict_summary[\'start_point\'] = pose[0]\n        self._dict_summary[\'end_point\'] = pose[1]\n        self._dict_summary[\'result\'] = result\n        self._dict_summary[\'initial_distance\'] = path_distance\n        self._dict_summary[\'final_distance\'] = remaining_distance\n        self._dict_summary[\'final_time\'] = final_time\n        self._dict_summary[\'time_out\'] = time_out\n\n        with open(os.path.join(self._path, \'summary.csv\'), \'a+\') as ofd:\n            w = csv.DictWriter(ofd, self._dict_summary.keys())\n\n            w.writerow(self._dict_summary)\n\n    def write_measurements_results(self, experiment, rep, pose, reward_vec, control_vec):\n        """"""\n        Method to record the measurements, sensors,\n        controls and status of the entire benchmark.\n        """"""\n        with open(os.path.join(self._path, \'measurements.csv\'), \'a+\') as rfd:\n            rw = csv.DictWriter(rfd, self._dict_measurements.keys())\n\n            for i in range(len(reward_vec)):\n                self._dict_measurements[\'exp_id\'] = experiment.task\n                self._dict_measurements[\'rep\'] = rep\n                self._dict_measurements[\'start_point\'] = pose[0]\n                self._dict_measurements[\'end_point\'] = pose[1]\n                self._dict_measurements[\'weather\'] = experiment.Conditions.WeatherId\n                self._dict_measurements[\'collision_other\'] = reward_vec[\n                    i].collision_other\n                self._dict_measurements[\'collision_pedestrians\'] = reward_vec[\n                    i].collision_pedestrians\n                self._dict_measurements[\'collision_vehicles\'] = reward_vec[\n                    i].collision_vehicles\n                self._dict_measurements[\'intersection_otherlane\'] = reward_vec[\n                    i].intersection_otherlane\n                self._dict_measurements[\'intersection_offroad\'] = reward_vec[\n                    i].intersection_offroad\n                self._dict_measurements[\'pos_x\'] = reward_vec[\n                    i].transform.location.x\n                self._dict_measurements[\'pos_y\'] = reward_vec[\n                    i].transform.location.y\n                self._dict_measurements[\'steer\'] = control_vec[\n                    i].steer\n                self._dict_measurements[\'throttle\'] = control_vec[\n                    i].throttle\n                self._dict_measurements[\'brake\'] = control_vec[\n                    i].brake\n\n                rw.writerow(self._dict_measurements)\n\n    def _create_log_files(self):\n        """"""\n        Just create the log files and add the necessary header for it.\n        """"""\n\n        if not self._experiment_exist():\n            os.mkdir(self._path)\n\n            with open(os.path.join(self._path, \'summary.csv\'), \'w\') as ofd:\n                w = csv.DictWriter(ofd, self._dict_summary.keys())\n                w.writeheader()\n\n            with open(os.path.join(self._path, \'measurements.csv\'), \'w\') as rfd:\n                rw = csv.DictWriter(rfd, self._dict_measurements.keys())\n                rw.writeheader()\n\n    def _continue_experiment(self, continue_experiment):\n        """"""\n        Get the line on the file for the experiment.\n        If continue_experiment is false and experiment exist, generates a new file path\n\n        """"""\n\n        def get_non_existent_path(f_name_path):\n            """"""\n            Get the path to a filename which does not exist by incrementing path.\n            """"""\n            if not os.path.exists(f_name_path):\n                return f_name_path\n            filename, file_extension = os.path.splitext(f_name_path)\n            i = 1\n            new_f_name = ""{}-{}{}"".format(filename, i, file_extension)\n            while os.path.exists(new_f_name):\n                i += 1\n                new_f_name = ""{}-{}{}"".format(filename, i, file_extension)\n            return new_f_name\n\n        # start the new path as the same one as before\n        new_path = self._path\n\n        # if the experiment exist\n        if self._experiment_exist():\n\n            # If you want to continue just get the last position\n            if continue_experiment:\n                line_on_file = self._get_last_position()\n\n            else:\n                # Get a new non_conflicting path name\n                new_path = get_non_existent_path(new_path)\n                line_on_file = 1\n\n        else:\n            line_on_file = 1\n        return new_path, line_on_file\n\n    def save_images(self, sensor_data, episode_name, frame):\n        """"""\n        Save a image during the experiment\n        """"""\n        if self._save_images:\n            for name, image in sensor_data.items():\n                image.save_to_disk(self._image_filename_format.format(\n                    episode_name, name, frame))\n\n    def get_pose_and_experiment(self, number_poses_task):\n        """"""\n        Based on the line in log file, return the current pose and experiment.\n        If the line is zero, create new log files.\n\n        """"""\n        # Warning: assumes that all tasks have the same size\n        line_on_file = self._get_last_position() - 1\n        if line_on_file == 0:\n            return 0, 0\n        else:\n            return line_on_file % number_poses_task, line_on_file // number_poses_task\n\n    def _experiment_exist(self):\n\n        return os.path.exists(self._path)\n\n    def _get_last_position(self):\n        """"""\n        Get the last position on the summary experiment file\n        With this you are able to continue from there\n\n        Returns:\n             int, position:\n        """"""\n        # Try to open, if the file is not found\n        try:\n            with open(os.path.join(self._path, \'summary.csv\')) as f:\n                return sum(1 for _ in f)\n        except IOError:\n            return 0\n'"
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/results_printer.py,0,"b'import os\nimport numpy as np\nimport json\n\n\ndef print_summary(metrics_summary, weathers, path):\n    """"""\n        We plot the summary of the testing for the set selected weathers.\n\n        We take the raw data and print the way it was described on CORL 2017 paper\n\n    """"""\n\n    # Improve readability by adding a weather dictionary\n    weather_name_dict = {1: \'Clear Noon\', 3: \'After Rain Noon\',\n                         6: \'Heavy Rain Noon\', 8: \'Clear Sunset\',\n                         4: \'Cloudy After Rain\', 14: \'Soft Rain Sunset\'}\n\n    # First we write the entire dictionary on the benchmark folder.\n    with open(os.path.join(path, \'metrics.json\'), \'w\') as fo:\n        fo.write(json.dumps(metrics_summary))\n\n    # Second we plot the metrics that are already ready by averaging\n\n    metrics_to_average = [\n        \'episodes_fully_completed\',\n        \'episodes_completion\'\n\n    ]\n    # We compute the number  of episodes based on size of average completion\n    number_of_episodes = len(list(metrics_summary[\'episodes_fully_completed\'].items())[0][1])\n\n    for metric in metrics_to_average:\n\n        if metric == \'episodes_completion\':\n            print (""Average Percentage of Distance to Goal Travelled "")\n        else:\n            print (""Percentage of Successful Episodes"")\n\n        print ("""")\n        values = metrics_summary[metric]\n\n        metric_sum_values = np.zeros(number_of_episodes)\n        for weather, tasks in values.items():\n            if weather in set(weathers):\n                print(\'  Weather: \', weather_name_dict[weather])\n                count = 0\n                for t in tasks:\n                    # if isinstance(t, np.ndarray) or isinstance(t, list):\n                    if t == []:\n                        print(\'    Metric Not Computed\')\n                    else:\n                        print(\'    Task:\', count, \' -> \', float(sum(t)) / float(len(t)))\n                        metric_sum_values[count] += (float(sum(t)) / float(len(t))) * 1.0 / float(\n                            len(weathers))\n\n                    count += 1\n\n        print (\'  Average Between Weathers\')\n        for i in range(len(metric_sum_values)):\n            print(\'    Task \', i, \' -> \', metric_sum_values[i])\n        print ("""")\n\n    infraction_metrics = [\n        \'collision_pedestrians\',\n        \'collision_vehicles\',\n        \'collision_other\',\n        \'intersection_offroad\',\n        \'intersection_otherlane\'\n\n    ]\n\n    # We need to collect the total number of kilometers for each task\n\n    for metric in infraction_metrics:\n        values_driven = metrics_summary[\'driven_kilometers\']\n        values = metrics_summary[metric]\n        metric_sum_values = np.zeros(number_of_episodes)\n        summed_driven_kilometers = np.zeros(number_of_episodes)\n\n        if metric == \'collision_pedestrians\':\n            print (\'Avg. Kilometers driven before a collision to a PEDESTRIAN\')\n        elif metric == \'collision_vehicles\':\n            print(\'Avg. Kilometers driven before a collision to a VEHICLE\')\n        elif metric == \'collision_other\':\n            print(\'Avg. Kilometers driven before a collision to a STATIC OBSTACLE\')\n        elif metric == \'intersection_offroad\':\n            print(\'Avg. Kilometers driven before going OUTSIDE OF THE ROAD\')\n        else:\n            print(\'Avg. Kilometers driven before invading the OPPOSITE LANE\')\n\n        # print (zip(values.items(), values_driven.items()))\n        for items_metric, items_driven in zip(values.items(), values_driven.items()):\n            weather = items_metric[0]\n            tasks = items_metric[1]\n            tasks_driven = items_driven[1]\n\n            if weather in set(weathers):\n                print(\'  Weather: \', weather_name_dict[weather])\n                count = 0\n                for t, t_driven in zip(tasks, tasks_driven):\n                    # if isinstance(t, np.ndarray) or isinstance(t, list):\n                    if t == []:\n                        print(\'Metric Not Computed\')\n                    else:\n                        if sum(t) > 0:\n                            print(\'    Task \', count, \' -> \', t_driven / float(sum(t)))\n                        else:\n                            print(\'    Task \', count, \' -> more than\', t_driven)\n\n                        metric_sum_values[count] += float(sum(t))\n                        summed_driven_kilometers[count] += t_driven\n\n                    count += 1\n        print (\'  Average Between Weathers\')\n        for i in range(len(metric_sum_values)):\n            if metric_sum_values[i] == 0:\n                print(\'    Task \', i, \' -> more than \', summed_driven_kilometers[i])\n            else:\n                print(\'    Task \', i, \' -> \', summed_driven_kilometers[i] / metric_sum_values[i])\n        print ("""")\n\n    print("""")\n    print("""")\n'"
ch7/carla-gym/carla_gym/envs/carla/planner/__init__.py,0,b''
ch7/carla-gym/carla_gym/envs/carla/planner/astar.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport heapq\n\n\nclass Cell(object):\n    def __init__(self, x, y, reachable):\n        """"""Initialize new cell.\n\n        @param reachable is cell reachable? not a wall?\n        @param x cell x coordinate\n        @param y cell y coordinate\n        @param g cost to move from the starting cell to this cell.\n        @param h estimation of the cost to move from this cell\n                 to the ending cell.\n        @param f f = g + h\n        """"""\n        self.reachable = reachable\n        self.x = x\n        self.y = y\n        self.parent = None\n        self.g = 0\n        self.h = 0\n        self.f = 0\n\n    def __lt__(self, other):\n        return self.g < other.g\n\n\nclass AStar(object):\n    def __init__(self):\n        # open list\n        self.opened = []\n        heapq.heapify(self.opened)\n        # visited cells list\n        self.closed = set()\n        # grid cells\n        self.cells = []\n        self.grid_height = None\n        self.grid_width = None\n        self.start = None\n        self.end = None\n\n    def init_grid(self, width, height, walls, start, end):\n        """"""Prepare grid cells, walls.\n\n        @param width grid\'s width.\n        @param height grid\'s height.\n        @param walls list of wall x,y tuples.\n        @param start grid starting point x,y tuple.\n        @param end grid ending point x,y tuple.\n        """"""\n        self.grid_height = height\n        self.grid_width = width\n        for x in range(self.grid_width):\n            for y in range(self.grid_height):\n                if (x, y) in walls:\n                    reachable = False\n                else:\n                    reachable = True\n                self.cells.append(Cell(x, y, reachable))\n        self.start = self.get_cell(*start)\n        self.end = self.get_cell(*end)\n\n    def get_heuristic(self, cell):\n        """"""Compute the heuristic value H for a cell.\n\n        Distance between this cell and the ending cell multiply by 10.\n\n        @returns heuristic value H\n        """"""\n        return 10 * (abs(cell.x - self.end.x) + abs(cell.y - self.end.y))\n\n    def get_cell(self, x, y):\n        """"""Returns a cell from the cells list.\n\n        @param x cell x coordinate\n        @param y cell y coordinate\n        @returns cell\n        """"""\n        return self.cells[x * self.grid_height + y]\n\n    def get_adjacent_cells(self, cell):\n        """"""Returns adjacent cells to a cell.\n\n        Clockwise starting from the one on the right.\n\n        @param cell get adjacent cells for this cell\n        @returns adjacent cells list.\n        """"""\n        cells = []\n        if cell.x < self.grid_width - 1:\n            cells.append(self.get_cell(cell.x + 1, cell.y))\n        if cell.y > 0:\n            cells.append(self.get_cell(cell.x, cell.y - 1))\n        if cell.x > 0:\n            cells.append(self.get_cell(cell.x - 1, cell.y))\n        if cell.y < self.grid_height - 1:\n            cells.append(self.get_cell(cell.x, cell.y + 1))\n        return cells\n\n    def get_path(self):\n        cell = self.end\n        path = [(cell.x, cell.y)]\n        while cell.parent is not self.start:\n            cell = cell.parent\n            path.append((cell.x, cell.y))\n\n        path.append((self.start.x, self.start.y))\n        path.reverse()\n        return path\n\n    def update_cell(self, adj, cell):\n        """"""Update adjacent cell.\n\n        @param adj adjacent cell to current cell\n        @param cell current cell being processed\n        """"""\n        adj.g = cell.g + 10\n        adj.h = self.get_heuristic(adj)\n        adj.parent = cell\n        adj.f = adj.h + adj.g\n\n    def solve(self):\n        """"""Solve maze, find path to ending cell.\n\n        @returns path or None if not found.\n        """"""\n        # add starting cell to open heap queue\n        heapq.heappush(self.opened, (self.start.f, self.start))\n        while len(self.opened):\n            # pop cell from heap queue\n            _, cell = heapq.heappop(self.opened)\n            # add cell to closed list so we don\'t process it twice\n            self.closed.add(cell)\n            # if ending cell, return found path\n            if cell is self.end:\n                return self.get_path()\n            # get adjacent cells for cell\n            adj_cells = self.get_adjacent_cells(cell)\n            for adj_cell in adj_cells:\n                if adj_cell.reachable and adj_cell not in self.closed:\n                    if (adj_cell.f, adj_cell) in self.opened:\n                        # if adj cell in open list, check if current path is\n                        # better than the one previously found\n                        # for this adj cell.\n                        if adj_cell.g > cell.g + 10:\n                            self.update_cell(adj_cell, cell)\n                    else:\n                        self.update_cell(adj_cell, cell)\n                        # add adj cell to open list\n                        heapq.heappush(self.opened, (adj_cell.f, adj_cell))\n'"
ch7/carla-gym/carla_gym/envs/carla/planner/city_track.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nfrom .graph import sldist\n\nfrom .astar import AStar\nfrom .map import CarlaMap\n\n\nclass CityTrack(object):\n\n    def __init__(self, city_name):\n\n        # These values are fixed for every city.\n        self._node_density = 50.0\n        self._pixel_density = 0.1643\n\n        self._map = CarlaMap(city_name, self._pixel_density, self._node_density)\n\n        self._astar = AStar()\n\n        # Refers to the start position of the previous route computation\n        self._previous_node = []\n\n        # The current computed route\n        self._route = None\n\n    def project_node(self, position):\n        """"""\n            Projecting the graph node into the city road\n        """"""\n\n        node = self._map.convert_to_node(position)\n\n        # To change the orientation with respect to the map standards\n\n        node = tuple([int(x) for x in node])\n\n        # Set to zero if it is less than zero.\n\n        node = (max(0, node[0]), max(0, node[1]))\n        node = (min(self._map.get_graph_resolution()[0] - 1, node[0]),\n                min(self._map.get_graph_resolution()[1] - 1, node[1]))\n\n        node = self._map.search_on_grid(node)\n\n        return node\n\n    def get_intersection_nodes(self):\n        return self._map.get_intersection_nodes()\n\n    def get_pixel_density(self):\n        return self._pixel_density\n\n    def get_node_density(self):\n        return self._node_density\n\n    def is_at_goal(self, source, target):\n        return source == target\n\n    def is_at_new_node(self, current_node):\n        return current_node != self._previous_node\n\n    def is_away_from_intersection(self, current_node):\n        return self._closest_intersection_position(current_node) > 1\n\n    def is_far_away_from_route_intersection(self, current_node):\n        # CHECK FOR THE EMPTY CASE\n        if self._route is None:\n            raise RuntimeError(\'Impossible to find route\'\n                               + \' Current planner is limited\'\n                               + \' Try to select start points away from intersections\')\n\n        return self._closest_intersection_route_position(current_node,\n                                                         self._route) > 4\n\n    def compute_route(self, node_source, source_ori, node_target, target_ori):\n\n        self._previous_node = node_source\n\n        a_star = AStar()\n        a_star.init_grid(self._map.get_graph_resolution()[0],\n                         self._map.get_graph_resolution()[1],\n                         self._map.get_walls_directed(node_source, source_ori,\n                                                      node_target, target_ori), node_source,\n                         node_target)\n\n        route = a_star.solve()\n\n        # JuSt a Corner Case\n        # Clean this to avoid having to use this function\n        if route is None:\n            a_star = AStar()\n            a_star.init_grid(self._map.get_graph_resolution()[0],\n                             self._map.get_graph_resolution()[1], self._map.get_walls(),\n                             node_source, node_target)\n\n            route = a_star.solve()\n\n        self._route = route\n\n        return route\n\n    def get_distance_closest_node_route(self, pos, route):\n        distance = []\n\n        for node_iter in route:\n\n            if node_iter in self._map.get_intersection_nodes():\n                distance.append(sldist(node_iter, pos))\n\n        if not distance:\n            return sldist(route[-1], pos)\n        return sorted(distance)[0]\n\n\n    def _closest_intersection_position(self, current_node):\n\n        distance_vector = []\n        for node_iterator in self._map.get_intersection_nodes():\n            distance_vector.append(sldist(node_iterator, current_node))\n\n        return sorted(distance_vector)[0]\n\n\n    def _closest_intersection_route_position(self, current_node, route):\n\n        distance_vector = []\n        for _ in route:\n            for node_iterator in self._map.get_intersection_nodes():\n                distance_vector.append(sldist(node_iterator, current_node))\n\n        return sorted(distance_vector)[0]\n\n'"
ch7/carla-gym/carla_gym/envs/carla/planner/converter.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport math\nimport numpy as np\n\nfrom .graph import string_to_floats\n\n# Constant definition enumeration\n\nPIXEL = 0\nWORLD = 1\nNODE = 2\n\n\nclass Converter(object):\n\n    def __init__(self, city_file,  pixel_density, node_density):\n\n        self._node_density = node_density\n        self._pixel_density = pixel_density\n        with open(city_file, \'r\') as f:\n            # The offset of the world from the zero coordinates ( The\n            # coordinate we consider zero)\n            self._worldoffset = string_to_floats(f.readline())\n\n            angles = string_to_floats(f.readline())\n\n            # If there is an rotation between the world and map coordinates.\n            self._worldrotation = np.array([\n                [math.cos(math.radians(angles[2])), -math.sin(math.radians(angles[2])), 0.0],\n                [math.sin(math.radians(angles[2])), math.cos(math.radians(angles[2])), 0.0],\n                [0.0, 0.0, 1.0]])\n\n            # Ignore for now, these are offsets for map coordinates and scale\n            # (not used).\n            _ = f.readline()\n\n            # The offset of the map zero coordinate.\n            self._mapoffset = string_to_floats(f.readline())\n\n    def convert_to_node(self, input_data):\n        """"""\n        Receives a data type (Can Be Pixel or World )\n        :param input_data: position in some coordinate\n        :return: A vector representing a node\n        """"""\n\n        input_type = self._check_input_type(input_data)\n        if input_type == PIXEL:\n            return self._pixel_to_node(input_data)\n        elif input_type == WORLD:\n            return self._world_to_node(input_data)\n        else:\n            raise ValueError(\'Invalid node to be converted\')\n\n    def convert_to_pixel(self, input_data):\n\n        """"""\n        Receives a data type (Can Be Node or World )\n        :param input_data: position in some coordinate\n        :return: A vector with pixel coordinates\n        """"""\n\n        input_type = self._check_input_type(input_data)\n\n        if input_type == NODE:\n            return self._node_to_pixel(input_data)\n        elif input_type == WORLD:\n            return self._world_to_pixel(input_data)\n        else:\n            raise ValueError(\'Invalid node to be converted\')\n\n    def convert_to_world(self, input_data):\n\n        """"""\n        Receives a data type (Can Be Pixel or Node )\n        :param input_data: position in some coordinate\n        :return: vector with world coordinates\n        """"""\n\n        input_type = self._check_input_type(input_data)\n        if input_type == NODE:\n            return self._node_to_world(input_data)\n        elif input_type == PIXEL:\n            return self._pixel_to_world(input_data)\n        else:\n            raise ValueError(\'Invalid node to be converted\')\n\n    def _node_to_pixel(self, node):\n        """"""\n        Conversion from node format (graph) to pixel (image)\n        :param node:\n        :return: pixel\n        """"""\n        pixel = [((node[0] + 2) * self._node_density)\n            , ((node[1] + 2) * self._node_density)]\n        return pixel\n\n    def _pixel_to_node(self, pixel):\n        """"""\n        Conversion from pixel format (image) to node (graph)\n        :param node:\n        :return: pixel\n        """"""\n        node = [int(((pixel[0]) / self._node_density) - 2)\n            , int(((pixel[1]) / self._node_density) - 2)]\n\n        return tuple(node)\n\n    def _pixel_to_world(self, pixel):\n        """"""\n        Conversion from pixel format (image) to world (3D)\n        :param pixel:\n        :return: world\n        """"""\n\n        relative_location = [pixel[0] * self._pixel_density,\n                             pixel[1] * self._pixel_density]\n\n        world = [\n            relative_location[0] + self._mapoffset[0] - self._worldoffset[0],\n            relative_location[1] + self._mapoffset[1] - self._worldoffset[1],\n            22\n        ]\n\n        return world\n\n    def _world_to_pixel(self, world):\n        """"""\n        Conversion from world format (3D) to pixel\n        :param world:\n        :return: pixel\n        """"""\n\n        rotation = np.array([world[0], world[1], world[2]])\n        rotation = rotation.dot(self._worldrotation)\n\n        relative_location = [rotation[0] + self._worldoffset[0] - self._mapoffset[0],\n                             rotation[1] + self._worldoffset[1] - self._mapoffset[1],\n                             rotation[2] + self._worldoffset[2] - self._mapoffset[2]]\n\n\n\n        pixel = [math.floor(relative_location[0] / float(self._pixel_density)),\n                 math.floor(relative_location[1] / float(self._pixel_density))]\n\n        return pixel\n\n    def _world_to_node(self, world):\n        return self._pixel_to_node(self._world_to_pixel(world))\n\n    def _node_to_world(self, node):\n\n        return self._pixel_to_world(self._node_to_pixel(node))\n\n    def _check_input_type(self, input_data):\n        if len(input_data) > 2:\n            return WORLD\n        elif type(input_data[0]) is int:\n            return NODE\n        else:\n            return PIXEL\n'"
ch7/carla-gym/carla_gym/envs/carla/planner/graph.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport math\nimport numpy as np\n\n\ndef string_to_node(string):\n    vec = string.split(\',\')\n    return (int(vec[0]), int(vec[1]))\n\n\ndef string_to_floats(string):\n    vec = string.split(\',\')\n    return (float(vec[0]), float(vec[1]), float(vec[2]))\n\n\ndef sldist(c1, c2):\n    return math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2)\n\n\ndef sldist3(c1, c2):\n    return math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1])\n                     ** 2 + (c2[2] - c1[2]) ** 2)\n\n\nclass Graph(object):\n    """"""\n    A simple directed, weighted graph\n    """"""\n\n    def __init__(self, graph_file=None, node_density=50):\n\n        self._nodes = set()\n        self._angles = {}\n        self._edges = {}\n        self._distances = {}\n        self._node_density = node_density\n\n        if graph_file is not None:\n            with open(graph_file, \'r\') as f:\n                # Skipe the first four lines that\n                lines_after_4 = f.readlines()[4:]\n\n                # the graph resolution.\n                linegraphres = lines_after_4[0]\n                self._resolution = string_to_node(linegraphres)\n                for line in lines_after_4[1:]:\n\n                    from_node, to_node, d = line.split()\n                    from_node = string_to_node(from_node)\n                    to_node = string_to_node(to_node)\n\n                    if from_node not in self._nodes:\n                        self.add_node(from_node)\n                    if to_node not in self._nodes:\n                        self.add_node(to_node)\n\n                    self._edges.setdefault(from_node, [])\n                    self._edges[from_node].append(to_node)\n                    self._distances[(from_node, to_node)] = float(d)\n\n    def add_node(self, value):\n        self._nodes.add(value)\n\n    def make_orientations(self, node, heading):\n\n        import collections\n        distance_dic = {}\n        for node_iter in self._nodes:\n            if node_iter != node:\n                distance_dic[sldist(node, node_iter)] = node_iter\n\n        distance_dic = collections.OrderedDict(\n            sorted(distance_dic.items()))\n\n        self._angles[node] = heading\n        for _, v in distance_dic.items():\n            start_to_goal = np.array([node[0] - v[0], node[1] - v[1]])\n\n            print(start_to_goal)\n\n            self._angles[v] = start_to_goal / np.linalg.norm(start_to_goal)\n\n    def add_edge(self, from_node, to_node, distance):\n        self._add_edge(from_node, to_node, distance)\n\n    def _add_edge(self, from_node, to_node, distance):\n        self._edges.setdefault(from_node, [])\n        self._edges[from_node].append(to_node)\n        self._distances[(from_node, to_node)] = distance\n\n    def get_resolution(self):\n        return self._resolution\n    def get_edges(self):\n        return self._edges\n\n    def intersection_nodes(self):\n\n        intersect_nodes = []\n        for node in self._nodes:\n            if len(self._edges[node]) > 2:\n                intersect_nodes.append(node)\n\n        return intersect_nodes\n\n    # This contains also the non-intersection turns...\n\n    def turn_nodes(self):\n\n        return self._nodes\n\n    def plot_ori(self, c):\n        from matplotlib import collections as mc\n\n        import matplotlib.pyplot as plt\n        line_len = 1\n\n        lines = [[(p[0], p[1]), (p[0] + line_len * self._angles[p][0],\n                                 p[1] + line_len * self._angles[p][1])] for p in self._nodes]\n        lc = mc.LineCollection(lines, linewidth=2, color=\'green\')\n        _, ax = plt.subplots()\n        ax.add_collection(lc)\n\n        ax.autoscale()\n        ax.margins(0.1)\n\n        xs = [p[0] for p in self._nodes]\n        ys = [p[1] for p in self._nodes]\n\n        plt.scatter(xs, ys, color=c)\n\n    def plot(self, c):\n        import matplotlib.pyplot as plt\n        xs = [p[0] for p in self._nodes]\n        ys = [p[1] for p in self._nodes]\n\n        plt.scatter(xs, ys, color=c)\n'"
ch7/carla-gym/carla_gym/envs/carla/planner/grid.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport copy\nimport numpy as np\n\n\ndef angle_between(v1, v2):\n    return np.arccos(np.dot(v1, v2) / np.linalg.norm(v1) / np.linalg.norm(v2))\n\n\nclass Grid(object):\n\n    def __init__(self, graph):\n\n        self._graph = graph\n        self._structure = self._make_structure()\n        self._walls = self._make_walls()\n\n    def search_on_grid(self, x, y):\n        visit = [[0, 1], [0, -1], [1, 0], [1, 1],\n                 [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n        c_x, c_y = x, y\n        scale = 1\n        while self._structure[c_x, c_y] != 0:\n            for offset in visit:\n                c_x, c_y = x + offset[0] * scale, y + offset[1] * scale\n\n                if c_x >= 0 and c_x < self._graph.get_resolution()[\n                    0] and c_y >= 0 and c_y < self._graph.get_resolution()[1]:\n                    if self._structure[c_x, c_y] == 0:\n                        break\n                else:\n                    c_x, c_y = x, y\n            scale += 1\n\n        return c_x, c_y\n    def get_walls(self):\n        return self._walls\n\n    def get_wall_source(self, pos, pos_ori, target):\n\n        free_nodes = self._get_adjacent_free_nodes(pos)\n        # print self._walls\n        final_walls = copy.copy(self._walls)\n        # print final_walls\n        heading_start = np.array([pos_ori[0], pos_ori[1]])\n        for adj in free_nodes:\n\n            start_to_goal = np.array([adj[0] - pos[0], adj[1] - pos[1]])\n            angle = angle_between(heading_start, start_to_goal)\n            if (angle > 1.6 and adj != target):\n                final_walls.add((adj[0], adj[1]))\n\n        return final_walls\n\n    def get_wall_target(self, pos, pos_ori, source):\n\n        free_nodes = self._get_adjacent_free_nodes(pos)\n        final_walls = copy.copy(self._walls)\n        heading_start = np.array([pos_ori[0], pos_ori[1]])\n        for adj in free_nodes:\n\n            start_to_goal = np.array([adj[0] - pos[0], adj[1] - pos[1]])\n            angle = angle_between(heading_start, start_to_goal)\n\n            if (angle < 1.0 and adj != source):\n                final_walls.add((adj[0], adj[1]))\n\n        return final_walls\n\n    def _draw_line(self, grid, xi, yi, xf, yf):\n\n        if xf < xi:\n            aux = xi\n            xi = xf\n            xf = aux\n\n        if yf < yi:\n            aux = yi\n            yi = yf\n            yf = aux\n\n        for i in range(xi, xf + 1):\n\n            for j in range(yi, yf + 1):\n                grid[i, j] = 0.0\n\n        return grid\n\n    def _make_structure(self):\n        structure = np.ones(\n            (self._graph.get_resolution()[0],\n             self._graph.get_resolution()[1]))\n\n        for key, connections in self._graph.get_edges().items():\n\n            # draw a line\n            for con in connections:\n                # print key[0],key[1],con[0],con[1]\n                structure = self._draw_line(\n                    structure, key[0], key[1], con[0], con[1])\n                # print grid\n        return structure\n\n    def _make_walls(self):\n        walls = set()\n\n        for i in range(self._structure.shape[0]):\n\n            for j in range(self._structure.shape[1]):\n                if self._structure[i, j] == 1.0:\n                    walls.add((i, j))\n\n        return walls\n\n    def _get_adjacent_free_nodes(self, pos):\n        """""" Eight nodes in total """"""\n        visit = [[0, 1], [0, -1], [1, 0], [1, 1],\n                 [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n\n        adjacent = set()\n        for offset in visit:\n            node = (pos[0] + offset[0], pos[1] + offset[1])\n\n            if (node[0] >= 0 and node[0] < self._graph.get_resolution()[0]\n                    and node[1] >= 0 and node[1] < self._graph.get_resolution()[1]):\n\n                if self._structure[node[0], node[1]] == 0.0:\n                    adjacent.add(node)\n\n        return adjacent\n'"
ch7/carla-gym/carla_gym/envs/carla/planner/map.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""Class used for operating the city map.""""""\n\nimport math\nimport os\n\ntry:\n    import numpy as np\nexcept ImportError:\n    raise RuntimeError(\'cannot import numpy, make sure numpy package is installed\')\n\ntry:\n    from PIL import Image\nexcept ImportError:\n    raise RuntimeError(\'cannot import PIL, make sure pillow package is installed\')\n\nfrom .graph import Graph\nfrom .graph import sldist\nfrom .grid import Grid\nfrom .converter import Converter\n\n\ndef color_to_angle(color):\n    return (float(color) / 255.0) * 2 * math.pi\n\n\nclass CarlaMap(object):\n\n    def __init__(self, city, pixel_density, node_density):\n        dir_path = os.path.dirname(__file__)\n        city_file = os.path.join(dir_path, city + \'.txt\')\n\n        city_map_file = os.path.join(dir_path, city + \'.png\')\n        city_map_file_lanes = os.path.join(dir_path, city + \'Lanes.png\')\n        city_map_file_center = os.path.join(dir_path, city + \'Central.png\')\n\n        # The built graph. This is the exact same graph that unreal builds. This\n        # is a generic structure used for many cases\n        self._graph = Graph(city_file, node_density)\n\n        self._pixel_density = pixel_density\n        self._grid = Grid(self._graph)\n        # The number of game units per pixel. For now this is fixed.\n\n        self._converter = Converter(city_file, pixel_density, node_density)\n\n        # Load the lanes image\n        self.map_image_lanes = Image.open(city_map_file_lanes)\n        self.map_image_lanes.load()\n        self.map_image_lanes = np.asarray(self.map_image_lanes, dtype=""int32"")\n        # Load the image\n        self.map_image = Image.open(city_map_file)\n        self.map_image.load()\n        self.map_image = np.asarray(self.map_image, dtype=""int32"")\n\n        # Load the lanes image\n        self.map_image_center = Image.open(city_map_file_center)\n        self.map_image_center.load()\n        self.map_image_center = np.asarray(self.map_image_center, dtype=""int32"")\n\n    def get_graph_resolution(self):\n\n        return self._graph.get_resolution()\n\n    def get_map(self, height=None):\n        if height is not None:\n            img = Image.fromarray(self.map_image.astype(np.uint8))\n\n            aspect_ratio = height / float(self.map_image.shape[0])\n\n            img = img.resize((int(aspect_ratio * self.map_image.shape[1]), height), Image.ANTIALIAS)\n            img.load()\n            return np.asarray(img, dtype=""int32"")\n        return np.fliplr(self.map_image)\n\n    def get_map_lanes(self, size=None):\n        if size is not None:\n            img = Image.fromarray(self.map_image_lanes.astype(np.uint8))\n            img = img.resize((size[1], size[0]), Image.ANTIALIAS)\n            img.load()\n            return np.fliplr(np.asarray(img, dtype=""int32""))\n        return np.fliplr(self.map_image_lanes)\n\n    def get_lane_orientation(self, world):\n        """"""Get the lane orientation of a certain world position.""""""\n        pixel = self.convert_to_pixel(world)\n\n        ori = self.map_image_lanes[int(pixel[1]), int(pixel[0]), 2]\n        ori = color_to_angle(ori)\n\n        return (-math.cos(ori), -math.sin(ori))\n\n    def convert_to_node(self, input_data):\n        """"""\n        Receives a data type (Can Be Pixel or World )\n        :param input_data: position in some coordinate\n        :return: A node object\n        """"""\n        return self._converter.convert_to_node(input_data)\n\n    def convert_to_pixel(self, input_data):\n        """"""\n        Receives a data type (Can Be Node or World )\n        :param input_data: position in some coordinate\n        :return: A node object\n        """"""\n        return self._converter.convert_to_pixel(input_data)\n\n    def convert_to_world(self, input_data):\n        """"""\n        Receives a data type (Can Be Pixel or Node )\n        :param input_data: position in some coordinate\n        :return: A node object\n        """"""\n        return self._converter.convert_to_world(input_data)\n\n    def get_walls_directed(self, node_source, source_ori, node_target, target_ori):\n        """"""\n        This is the most hacky function. Instead of planning on two ways,\n        we basically use a one way road and interrupt the other road by adding\n        an artificial wall.\n\n        """"""\n\n        final_walls = self._grid.get_wall_source(node_source, source_ori, node_target)\n\n        final_walls = final_walls.union(self._grid.get_wall_target(\n            node_target, target_ori, node_source))\n        return final_walls\n\n    def get_walls(self):\n\n        return self._grid.get_walls()\n\n    def get_distance_closest_node(self, pos):\n\n        distance = []\n        for node_iter in self._graph.intersection_nodes():\n            distance.append(sldist(node_iter, pos))\n\n        return sorted(distance)[0]\n\n    def get_intersection_nodes(self):\n        return self._graph.intersection_nodes()\n\n    def search_on_grid(self,node):\n        return self._grid.search_on_grid(node[0], node[1])\n'"
ch7/carla-gym/carla_gym/envs/carla/planner/planner.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport collections\nimport math\n\nimport numpy as np\n\nfrom . import city_track\n\n\ndef compare(x, y):\n    return collections.Counter(x) == collections.Counter(y)\n\n\n\n# Constants Used for the high level commands\n\n\nREACH_GOAL = 0.0\nGO_STRAIGHT = 5.0\nTURN_RIGHT = 4.0\nTURN_LEFT = 3.0\nLANE_FOLLOW = 2.0\n\n\n# Auxiliary algebra function\ndef angle_between(v1, v2):\n    return np.arccos(np.dot(v1, v2) / np.linalg.norm(v1) / np.linalg.norm(v2))\n\n\ndef sldist(c1, c2): return math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2)\n\n\ndef signal(v1, v2):\n    return np.cross(v1, v2) / np.linalg.norm(v1) / np.linalg.norm(v2)\n\n\nclass Planner(object):\n\n    def __init__(self, city_name):\n\n        self._city_track = city_track.CityTrack(city_name)\n\n        self._commands = []\n\n    def get_next_command(self, source, source_ori, target, target_ori):\n        """"""\n        Computes the full plan and returns the next command,\n        Args\n            source: source position\n            source_ori: source orientation\n            target: target position\n            target_ori: target orientation\n        Returns\n            a command ( Straight,Lane Follow, Left or Right)\n        """"""\n\n        track_source = self._city_track.project_node(source)\n        track_target = self._city_track.project_node(target)\n\n        # reach the goal\n\n        if self._city_track.is_at_goal(track_source, track_target):\n            return REACH_GOAL\n\n        if (self._city_track.is_at_new_node(track_source)\n                and self._city_track.is_away_from_intersection(track_source)):\n\n            route = self._city_track.compute_route(track_source, source_ori,\n                                                   track_target, target_ori)\n            if route is None:\n                raise RuntimeError(\'Impossible to find route\')\n\n            self._commands = self._route_to_commands(route)\n\n            if self._city_track.is_far_away_from_route_intersection(\n                    track_source):\n                return LANE_FOLLOW\n            else:\n                if self._commands:\n                    return self._commands[0]\n                else:\n                    return LANE_FOLLOW\n        else:\n\n            if self._city_track.is_far_away_from_route_intersection(\n                    track_source):\n                return LANE_FOLLOW\n\n            # If there is computed commands\n            if self._commands:\n                return self._commands[0]\n            else:\n                return LANE_FOLLOW\n\n    def get_shortest_path_distance(\n            self,\n            source,\n            source_ori,\n            target,\n            target_ori):\n\n        distance = 0\n        track_source = self._city_track.project_node(source)\n        track_target = self._city_track.project_node(target)\n\n        current_pos = track_source\n\n        route = self._city_track.compute_route(track_source, source_ori,\n                                               track_target, target_ori)\n        # No Route, distance is zero\n        if route is None:\n            return 0.0\n\n        for node_iter in route:\n            distance += sldist(node_iter, current_pos)\n            current_pos = node_iter\n\n        # We multiply by these values to convert distance to world coordinates\n        return distance * self._city_track.get_pixel_density() \\\n               * self._city_track.get_node_density()\n\n    def is_there_posible_route(self, source, source_ori, target, target_ori):\n\n        track_source = self._city_track.project_node(source)\n        track_target = self._city_track.project_node(target)\n\n        return not self._city_track.compute_route(\n            track_source, source_ori, track_target, target_ori) is None\n\n    def test_position(self, source):\n\n        node_source = self._city_track.project_node(source)\n\n        return self._city_track.is_away_from_intersection(node_source)\n\n    def _route_to_commands(self, route):\n\n        """"""\n        from the shortest path graph, transform it into a list of commands\n\n        :param route: the sub graph containing the shortest path\n        :return: list of commands encoded from 0-5\n        """"""\n\n        commands_list = []\n\n        for i in range(0, len(route)):\n            if route[i] not in self._city_track.get_intersection_nodes():\n                continue\n\n            current = route[i]\n            past = route[i - 1]\n            future = route[i + 1]\n\n            past_to_current = np.array(\n                [current[0] - past[0], current[1] - past[1]])\n            current_to_future = np.array(\n                [future[0] - current[0], future[1] - current[1]])\n            angle = signal(current_to_future, past_to_current)\n\n            if angle < -0.1:\n                command = TURN_RIGHT\n            elif angle > 0.1:\n                command = TURN_LEFT\n            else:\n                command = GO_STRAIGHT\n\n            commands_list.append(command)\n\n        return commands_list\n'"
ch8/environment/carla_gym/envs/carla/agent/__init__.py,0,b'from .forward_agent import ForwardAgent\nfrom .agent import Agent\n'
ch8/environment/carla_gym/envs/carla/agent/agent.py,0,"b'# -*- coding: utf-8 -*-\n# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n# @author: german,felipecode\n\n\nfrom __future__ import print_function\nimport abc\n\n\nclass Agent(object):\n    def __init__(self):\n        self.__metaclass__ = abc.ABCMeta\n\n    @abc.abstractmethod\n    def run_step(self, measurements, sensor_data, directions, target):\n        """"""\n        Function to be redefined by an agent.\n        :param The measurements like speed, the image data and a target\n        :returns A carla Control object, with the steering/gas/brake for the agent\n        """"""\n'"
ch8/environment/carla_gym/envs/carla/agent/forward_agent.py,0,"b'\nfrom .agent import Agent\nfrom ..client import VehicleControl\n\n\nclass ForwardAgent(Agent):\n    """"""\n    Simple derivation of Agent Class,\n    A trivial agent agent that goes straight\n    """"""\n    def run_step(self, measurements, sensor_data, directions, target):\n        control = VehicleControl()\n        control.throttle = 0.9\n\n        return control\n'"
ch8/environment/carla_gym/envs/carla/driving_benchmark/__init__.py,0,b''
ch8/environment/carla_gym/envs/carla/driving_benchmark/driving_benchmark.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n\nimport abc\nimport logging\nimport math\nimport time\n\nfrom ..client import VehicleControl\nfrom ..client import make_carla_client\nfrom ..driving_benchmark.metrics import Metrics\nfrom ..planner.planner import Planner\nfrom ..settings import CarlaSettings\nfrom ..tcp import TCPConnectionError\n\nfrom . import results_printer\nfrom .recording import Recording\n\n\ndef sldist(c1, c2):\n    return math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2)\n\n\nclass DrivingBenchmark(object):\n    """"""\n    The Benchmark class, controls the execution of the benchmark interfacing\n    an Agent class with a set Suite.\n\n\n    The benchmark class must be inherited with a class that defines the\n    all the experiments to be run by the agent\n    """"""\n\n    def __init__(\n            self,\n            city_name=\'Town01\',\n            name_to_save=\'Test\',\n            continue_experiment=False,\n            save_images=False,\n            distance_for_success=2.0\n    ):\n\n        self.__metaclass__ = abc.ABCMeta\n\n        self._city_name = city_name\n        self._base_name = name_to_save\n        # The minimum distance for arriving into the goal point in\n        # order to consider ir a success\n        self._distance_for_success = distance_for_success\n        # The object used to record the benchmark and to able to continue after\n        self._recording = Recording(name_to_save=name_to_save,\n                                    continue_experiment=continue_experiment,\n                                    save_images=save_images\n                                    )\n\n        # We have a default planner instantiated that produces high level commands\n        self._planner = Planner(city_name)\n\n    def benchmark_agent(self, experiment_suite, agent, client):\n        """"""\n        Function to benchmark the agent.\n        It first check the log file for this benchmark.\n        if it exist it continues from the experiment where it stopped.\n\n\n        Args:\n            experiment_suite\n            agent: an agent object with the run step class implemented.\n            client:\n\n\n        Return:\n            A dictionary with all the metrics computed from the\n            agent running the set of experiments.\n        """"""\n\n        # Instantiate a metric object that will be used to compute the metrics for\n        # the benchmark afterwards.\n        metrics_object = Metrics(experiment_suite.metrics_parameters,\n                                 experiment_suite.dynamic_tasks)\n\n        # Function return the current pose and task for this benchmark.\n        start_pose, start_experiment = self._recording.get_pose_and_experiment(\n            experiment_suite.get_number_of_poses_task())\n\n        logging.info(\'START\')\n\n        for experiment in experiment_suite.get_experiments()[int(start_experiment):]:\n\n            positions = client.load_settings(\n                experiment.conditions).player_start_spots\n\n            self._recording.log_start(experiment.task)\n\n            for pose in experiment.poses[start_pose:]:\n                for rep in range(experiment.repetitions):\n\n                    start_index = pose[0]\n                    end_index = pose[1]\n\n                    client.start_episode(start_index)\n                    # Print information on\n                    logging.info(\'======== !!!! ==========\')\n                    logging.info(\' Start Position %d End Position %d \',\n                                 start_index, end_index)\n\n                    self._recording.log_poses(start_index, end_index,\n                                              experiment.Conditions.WeatherId)\n\n                    # Calculate the initial distance for this episode\n                    initial_distance = \\\n                        sldist(\n                            [positions[start_index].location.x, positions[start_index].location.y],\n                            [positions[end_index].location.x, positions[end_index].location.y])\n\n                    time_out = experiment_suite.calculate_time_out(\n                        self._get_shortest_path(positions[start_index], positions[end_index]))\n\n                    # running the agent\n                    (result, reward_vec, control_vec, final_time, remaining_distance) = \\\n                        self._run_navigation_episode(\n                            agent, client, time_out, positions[end_index],\n                            str(experiment.Conditions.WeatherId) + \'_\'\n                            + str(experiment.task) + \'_\' + str(start_index)\n                            + \'.\' + str(end_index))\n\n                    # Write the general status of the just ran episode\n                    self._recording.write_summary_results(\n                        experiment, pose, rep, initial_distance,\n                        remaining_distance, final_time, time_out, result)\n\n                    # Write the details of this episode.\n                    self._recording.write_measurements_results(experiment, rep, pose, reward_vec,\n                                                               control_vec)\n                    if result > 0:\n                        logging.info(\'+++++ Target achieved in %f seconds! +++++\',\n                                     final_time)\n                    else:\n                        logging.info(\'----- Timeout! -----\')\n\n            start_pose = 0\n\n        self._recording.log_end()\n\n        return metrics_object.compute(self._recording.path)\n\n    def get_path(self):\n        """"""\n        Returns the path were the log was saved.\n        """"""\n        return self._recording.path\n\n    def _get_directions(self, current_point, end_point):\n        """"""\n        Class that should return the directions to reach a certain goal\n        """"""\n\n        directions = self._planner.get_next_command(\n            (current_point.location.x,\n             current_point.location.y, 0.22),\n            (current_point.orientation.x,\n             current_point.orientation.y,\n             current_point.orientation.z),\n            (end_point.location.x, end_point.location.y, 0.22),\n            (end_point.orientation.x, end_point.orientation.y, end_point.orientation.z))\n        return directions\n\n    def _get_shortest_path(self, start_point, end_point):\n        """"""\n        Calculates the shortest path between two points considering the road netowrk\n        """"""\n\n        return self._planner.get_shortest_path_distance(\n            [\n                start_point.location.x, start_point.location.y, 0.22], [\n                start_point.orientation.x, start_point.orientation.y, 0.22], [\n                end_point.location.x, end_point.location.y, end_point.location.z], [\n                end_point.orientation.x, end_point.orientation.y, end_point.orientation.z])\n\n    def _run_navigation_episode(\n            self,\n            agent,\n            client,\n            time_out,\n            target,\n            episode_name):\n        """"""\n         Run one episode of the benchmark (Pose) for a certain agent.\n\n\n        Args:\n            agent: the agent object\n            client: an object of the carla client to communicate\n            with the CARLA simulator\n            time_out: the time limit to complete this episode\n            target: the target to reach\n            episode_name: The name for saving images of this episode\n\n        """"""\n\n        # Send an initial command.\n        measurements, sensor_data = client.read_data()\n        client.send_control(VehicleControl())\n\n        initial_timestamp = measurements.game_timestamp\n        current_timestamp = initial_timestamp\n\n        # The vector containing all measurements produced on this episode\n        measurement_vec = []\n        # The vector containing all controls produced on this episode\n        control_vec = []\n        frame = 0\n        distance = 10000\n        success = False\n\n        while (current_timestamp - initial_timestamp) < (time_out * 1000) and not success:\n\n            # Read data from server with the client\n            measurements, sensor_data = client.read_data()\n            # The directions to reach the goal are calculated.\n            directions = self._get_directions(measurements.player_measurements.transform, target)\n            # Agent process the data.\n            control = agent.run_step(measurements, sensor_data, directions, target)\n            # Send the control commands to the vehicle\n            client.send_control(control)\n\n            # save images if the flag is activated\n            self._recording.save_images(sensor_data, episode_name, frame)\n\n            current_x = measurements.player_measurements.transform.location.x\n            current_y = measurements.player_measurements.transform.location.y\n\n            logging.info(""Controller is Inputting:"")\n            logging.info(\'Steer = %f Throttle = %f Brake = %f \',\n                         control.steer, control.throttle, control.brake)\n\n            current_timestamp = measurements.game_timestamp\n            # Get the distance travelled until now\n            distance = sldist([current_x, current_y],\n                              [target.location.x, target.location.y])\n            # Write status of the run on verbose mode\n            logging.info(\'Status:\')\n            logging.info(\n                \'[d=%f] c_x = %f, c_y = %f ---> t_x = %f, t_y = %f\',\n                float(distance), current_x, current_y, target.location.x,\n                target.location.y)\n            # Check if reach the target\n            if distance < self._distance_for_success:\n                success = True\n\n            # Increment the vectors and append the measurements and controls.\n            frame += 1\n            measurement_vec.append(measurements.player_measurements)\n            control_vec.append(control)\n\n        if success:\n            return 1, measurement_vec, control_vec, float(\n                current_timestamp - initial_timestamp) / 1000.0, distance\n        return 0, measurement_vec, control_vec, time_out, distance\n\n\ndef run_driving_benchmark(agent,\n                          experiment_suite,\n                          city_name=\'Town01\',\n                          log_name=\'Test\',\n                          continue_experiment=False,\n                          host=\'127.0.0.1\',\n                          port=2000\n                          ):\n    while True:\n        try:\n\n            with make_carla_client(host, port) as client:\n                # Hack to fix for the issue 310, we force a reset, so it does not get\n                #  the positions on first server reset.\n                client.load_settings(CarlaSettings())\n                client.start_episode(0)\n\n                # We instantiate the driving benchmark, that is the engine used to\n                # benchmark an agent. The instantiation starts the log process, sets\n\n                benchmark = DrivingBenchmark(city_name=city_name,\n                                             name_to_save=log_name + \'_\'\n                                                          + type(experiment_suite).__name__\n                                                          + \'_\' + city_name,\n                                             continue_experiment=continue_experiment)\n                # This function performs the benchmark. It returns a dictionary summarizing\n                # the entire execution.\n\n                benchmark_summary = benchmark.benchmark_agent(experiment_suite, agent, client)\n\n                print("""")\n                print("""")\n                print(""----- Printing results for training weathers (Seen in Training) -----"")\n                print("""")\n                print("""")\n                results_printer.print_summary(benchmark_summary, experiment_suite.train_weathers,\n                                              benchmark.get_path())\n\n                print("""")\n                print("""")\n                print(""----- Printing results for test weathers (Unseen in Training) -----"")\n                print("""")\n                print("""")\n\n                results_printer.print_summary(benchmark_summary, experiment_suite.test_weathers,\n                                              benchmark.get_path())\n\n                break\n\n        except TCPConnectionError as error:\n            logging.error(error)\n            time.sleep(1)\n'"
ch8/environment/carla_gym/envs/carla/driving_benchmark/experiment.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nfrom ..settings import CarlaSettings\n\n\nclass Experiment(object):\n    """"""\n    Experiment defines a certain task, under conditions\n    A task is associated with a set of poses, containing start and end pose.\n\n    Conditions are associated with a carla Settings and describe the following:\n\n    Number Of Vehicles\n    Number Of Pedestrians\n    Weather\n    Random Seed of the agents, describing their behaviour.\n\n    """"""\n\n    def __init__(self):\n        self.Task = 0\n        self.Conditions = CarlaSettings()\n        self.Poses = [[]]\n        self.Repetitions = 1\n\n    def set(self, **kwargs):\n        for key, value in kwargs.items():\n            if not hasattr(self, key):\n                raise ValueError(\'Experiment: no key named %r\' % key)\n            setattr(self, key, value)\n\n        if self.Repetitions != 1:\n            raise NotImplementedError()\n\n    @property\n    def task(self):\n        return self.Task\n\n    @property\n    def conditions(self):\n        return self.Conditions\n\n    @property\n    def poses(self):\n        return self.Poses\n\n    @property\n    def repetitions(self):\n        return self.Repetitions\n'"
ch8/environment/carla_gym/envs/carla/driving_benchmark/metrics.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n\nimport numpy as np\nimport math\nimport os\n\nsldist = lambda c1, c2: math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2)\nflatten = lambda l: [item for sublist in l for item in sublist]\n\n\nclass Metrics(object):\n    """"""\n        The metrics class is made to take the driving measurements\n        and calculate some specific performance metrics.\n\n    """"""\n\n    def __init__(self, parameters, dynamic_tasks):\n        """"""\n        Args\n            parameters: A dictionary with the used parameters for checking how to count infractions\n            dynamic_tasks: A list of the all dynamic tasks (That contain dynamic objects)\n        """"""\n\n        self._parameters = parameters\n        self._parameters[\'dynamic_tasks\'] = dynamic_tasks\n\n    def _divide_by_episodes(self, measurements_matrix, header):\n\n        """"""\n            Divides the measurements matrix on different episodes.\n\n            Args:\n                measurements_matrix: The full measurements matrix\n                header: The header from the measurements matrix\n\n        """"""\n\n        # Read previous for position zero\n        prev_start = measurements_matrix[0, header.index(\'start_point\')]\n        prev_end = measurements_matrix[0, header.index(\'end_point\')]\n        prev_exp_id = measurements_matrix[0, header.index(\'exp_id\')]\n\n        # Start at the position 1.\n        i = 1\n        prev_i_position = 0\n        episode_matrix_metrics = []\n\n        while i < measurements_matrix.shape[0]:\n\n            current_start = measurements_matrix[i, header.index(\'start_point\')]\n            current_end = measurements_matrix[i, header.index(\'end_point\')]\n            current_exp_id = measurements_matrix[i, header.index(\'exp_id\')]\n\n            # If there is a change in the position it means it is a new episode for sure.\n            if (current_start != prev_start and current_end != prev_end) \\\n                    or current_exp_id != prev_exp_id:\n                episode_matrix_metrics.append(measurements_matrix[prev_i_position:i, :])\n                prev_i_position = i\n\n            prev_start = current_start\n            prev_end = current_end\n            prev_exp_id = current_exp_id\n\n            i += 1\n\n        episode_matrix_metrics.append(measurements_matrix[prev_i_position:-1, :])\n\n        return episode_matrix_metrics\n\n    def _get_collisions(self, selected_matrix, header):\n        """"""\n            Get the number of collisions for pedestrians, vehicles or other\n        Args:\n            selected_matrix: The matrix with all the experiments summary\n            header: The header , to know the positions of details\n\n\n        """"""\n        count_collisions_general = 0\n        count_collisions_pedestrian = 0\n        count_collisions_vehicle = 0\n        i = 1\n        # Computing general collisions\n        while i < selected_matrix.shape[0]:\n            if (selected_matrix[i, header.index(\'collision_other\')]\n                - selected_matrix[\n                    (i - self._parameters[\'collision_other\'][\'frames_skip\']), header.index(\n                        \'collision_other\')]) > \\\n                    self._parameters[\'collision_other\'][\'threshold\']:\n                count_collisions_general += 1\n                i += self._parameters[\'collision_other\'][\'frames_recount\']\n            i += 1\n\n        i = 1\n        # Computing collisions for vehicles\n        while i < selected_matrix.shape[0]:\n            if (selected_matrix[i, header.index(\'collision_vehicles\')]\n                - selected_matrix[\n                    (i - self._parameters[\'collision_vehicles\'][\'frames_skip\']), header.index(\n                        \'collision_vehicles\')]) > \\\n                    self._parameters[\'collision_vehicles\'][\'threshold\']:\n                count_collisions_vehicle += 1\n                i += self._parameters[\'collision_vehicles\'][\'frames_recount\']\n            i += 1\n\n        i = 1\n\n        # Computing the collisions for pedestrians\n        while i < selected_matrix.shape[0]:\n            if (selected_matrix[i, header.index(\'collision_pedestrians\')]\n                - selected_matrix[i - self._parameters[\'collision_pedestrians\'][\'frames_skip\'],\n                                  header.index(\'collision_pedestrians\')]) > \\\n                    self._parameters[\'collision_pedestrians\'][\'threshold\']:\n                count_collisions_pedestrian += 1\n                i += self._parameters[\'collision_pedestrians\'][\'frames_recount\']\n            i += 1\n\n        return count_collisions_general, count_collisions_vehicle, count_collisions_pedestrian\n\n    def _get_distance_traveled(self, selected_matrix, header):\n        """"""\n            Compute the total distance travelled\n        Args:\n            selected_matrix: The matrix with all the experiments summary\n            header: The header , to know the positions of details\n\n\n        """"""\n\n        prev_x = selected_matrix[0, header.index(\'pos_x\')]\n        prev_y = selected_matrix[0, header.index(\'pos_y\')]\n\n        i = 1\n        acummulated_distance = 0\n\n        while i < selected_matrix.shape[0]:\n            x = selected_matrix[i, header.index(\'pos_x\')]\n            y = selected_matrix[i, header.index(\'pos_y\')]\n\n            acummulated_distance += sldist((x, y), (prev_x, prev_y))\n\n            prev_x = x\n            prev_y = y\n\n            i += 1\n\n        return acummulated_distance / (1000.0)\n\n    def _get_out_of_road_lane(self, selected_matrix, header):\n\n        """"""\n            Check for the situations were the agent goes out of the road.\n        Args:\n            selected_matrix: The matrix with all the experiments summary\n            header: The header , to know the positions of details\n\n\n        """"""\n\n        count_sidewalk_intersect = 0\n        count_lane_intersect = 0\n\n        i = 0\n\n        while i < selected_matrix.shape[0]:\n\n            if (selected_matrix[i, header.index(\'intersection_offroad\')]\n                - selected_matrix[(i - self._parameters[\'intersection_offroad\'][\'frames_skip\']),\n                                  header.index(\'intersection_offroad\')]) \\\n                    > self._parameters[\'intersection_offroad\'][\'threshold\']:\n                count_sidewalk_intersect += 1\n                i += self._parameters[\'intersection_offroad\'][\'frames_recount\']\n            if i >= selected_matrix.shape[0]:\n                break\n\n            if (selected_matrix[i, header.index(\'intersection_otherlane\')]\n                - selected_matrix[(i - self._parameters[\'intersection_otherlane\'][\'frames_skip\']),\n                                  header.index(\'intersection_otherlane\')]) \\\n                    > self._parameters[\'intersection_otherlane\'][\'threshold\']:\n                count_lane_intersect += 1\n                i += self._parameters[\'intersection_otherlane\'][\'frames_recount\']\n\n            i += 1\n\n        return count_lane_intersect, count_sidewalk_intersect\n\n    def compute(self, path):\n\n        """"""\n            Compute a dictionary containing the following metrics\n\n            * Off Road Intersection: The number of times the agent goes out of the road.\n             The intersection is only counted if the area of the vehicle outside\n              of the road is bigger than a *threshold*.\n\n            * Other Lane Intersection: The number of times the agent goes to the other\n             lane. The intersection is only counted if the area of the vehicle on the\n             other lane is bigger than a *threshold*.\n\n            * Vehicle Collisions: The number of collisions with vehicles that have\n              an impact bigger than a *threshold*.\n\n            * Pedestrian Collisions: The number of collisions with pedestrians\n             that have an impact bigger than a threshold.\n\n            * General Collisions: The number of collisions with all other\n            objects.\n\n\n            Args:\n                path: Path where the log files are.\n\n        """"""\n\n        with open(os.path.join(path, \'summary.csv\'), ""rU"") as f:\n            header = f.readline()\n            header = header.split(\',\')\n            header[-1] = header[-1][:-1]\n\n        with open(os.path.join(path, \'measurements.csv\'), ""rU"") as f:\n\n            header_metrics = f.readline()\n            header_metrics = header_metrics.split(\',\')\n            header_metrics[-1] = header_metrics[-1][:-1]\n\n        result_matrix = np.loadtxt(os.path.join(path, \'summary.csv\'), delimiter="","", skiprows=1)\n\n        # Corner Case: The presented test just had one episode\n        if result_matrix.ndim == 1:\n            result_matrix = np.expand_dims(result_matrix, axis=0)\n\n        tasks = np.unique(result_matrix[:, header.index(\'exp_id\')])\n\n        all_weathers = np.unique(result_matrix[:, header.index(\'weather\')])\n\n        measurements_matrix = np.loadtxt(os.path.join(path, \'measurements.csv\'), delimiter="","",\n                                         skiprows=1)\n\n        metrics_dictionary = {\'episodes_completion\': {w: [0] * len(tasks) for w in all_weathers},\n                              \'intersection_offroad\': {w: [[] for i in range(len(tasks))] for w in\n                                                       all_weathers},\n                              \'intersection_otherlane\': {w: [[] for i in range(len(tasks))] for w in\n                                                         all_weathers},\n                              \'collision_pedestrians\': {w: [[] for i in range(len(tasks))] for w in\n                                                        all_weathers},\n                              \'collision_vehicles\': {w: [[] for i in range(len(tasks))] for w in\n                                                     all_weathers},\n                              \'collision_other\': {w: [[] for i in range(len(tasks))] for w in\n                                                  all_weathers},\n                              \'episodes_fully_completed\': {w: [0] * len(tasks) for w in\n                                                           all_weathers},\n                              \'average_speed\': {w: [0] * len(tasks) for w in all_weathers},\n                              \'driven_kilometers\': {w: [0] * len(tasks) for w in all_weathers}\n                              }\n\n        for t in range(len(tasks)):\n            experiment_results_matrix = result_matrix[\n                result_matrix[:, header.index(\'exp_id\')] == tasks[t]]\n\n            weathers = np.unique(experiment_results_matrix[:, header.index(\'weather\')])\n\n            for w in weathers:\n\n                experiment_results_matrix = result_matrix[\n                    np.logical_and(result_matrix[:, header.index(\n                        \'exp_id\')] == tasks[t], result_matrix[:, header.index(\'weather\')] == w)]\n\n                experiment_metrics_matrix = measurements_matrix[\n                    np.logical_and(measurements_matrix[:, header_metrics.index(\n                        \'exp_id\')] == float(tasks[t]),\n                                   measurements_matrix[:, header_metrics.index(\'weather\')] == float(\n                                       w))]\n\n                metrics_dictionary[\'episodes_fully_completed\'][w][t] = \\\n                    experiment_results_matrix[:, header.index(\'result\')].tolist()\n\n                metrics_dictionary[\'episodes_completion\'][w][t] = \\\n                    ((experiment_results_matrix[:, header.index(\'initial_distance\')]\n                      - experiment_results_matrix[:, header.index(\'final_distance\')])\n                     / experiment_results_matrix[:, header.index(\'initial_distance\')]).tolist()\n\n                # Now we divide the experiment metrics matrix\n\n                episode_experiment_metrics_matrix = self._divide_by_episodes(\n                    experiment_metrics_matrix, header_metrics)\n\n                count = 0\n\n                for episode_experiment_metrics in episode_experiment_metrics_matrix:\n\n                    km_run_episodes = self._get_distance_traveled(\n                        episode_experiment_metrics, header_metrics)\n                    metrics_dictionary[\'driven_kilometers\'][w][t] += km_run_episodes\n                    metrics_dictionary[\'average_speed\'][w][t] = \\\n                        km_run_episodes / (experiment_results_matrix[count,\n                                                                     header.index(\n                                                                         \'final_time\')] / 3600.0)\n                    count += 1\n\n                    lane_road = self._get_out_of_road_lane(\n                        episode_experiment_metrics, header_metrics)\n\n                    metrics_dictionary[\'intersection_otherlane\'][\n                        w][t].append(lane_road[0])\n                    metrics_dictionary[\'intersection_offroad\'][\n                        w][t].append(lane_road[1])\n\n                    if tasks[t] in set(self._parameters[\'dynamic_tasks\']):\n\n                        collisions = self._get_collisions(episode_experiment_metrics,\n                                                          header_metrics)\n\n                        metrics_dictionary[\'collision_pedestrians\'][\n                            w][t].append(collisions[2])\n                        metrics_dictionary[\'collision_vehicles\'][\n                            w][t].append(collisions[1])\n                        metrics_dictionary[\'collision_other\'][\n                            w][t].append(collisions[0])\n\n                    else:\n\n                        metrics_dictionary[\'collision_pedestrians\'][\n                            w][t].append(0)\n                        metrics_dictionary[\'collision_vehicles\'][\n                            w][t].append(0)\n                        metrics_dictionary[\'collision_other\'][\n                            w][t].append(0)\n\n        return metrics_dictionary\n'"
ch8/environment/carla_gym/envs/carla/driving_benchmark/recording.py,0,"b'import csv\nimport datetime\nimport os\n\n\nclass Recording(object):\n\n    def __init__(self\n                 , name_to_save\n                 , continue_experiment\n                 , save_images\n                 ):\n\n        self._dict_summary = {\'exp_id\': -1,\n                              \'rep\': -1,\n                              \'weather\': -1,\n                              \'start_point\': -1,\n                              \'end_point\': -1,\n                              \'result\': -1,\n                              \'initial_distance\': -1,\n                              \'final_distance\': -1,\n                              \'final_time\': -1,\n                              \'time_out\': -1\n                              }\n        self._dict_measurements = {\'exp_id\': -1,\n                                   \'rep\': -1,\n                                   \'weather\': -1,\n                                   \'start_point\': -1,\n                                   \'end_point\': -1,\n                                   \'collision_other\': -1,\n                                   \'collision_pedestrians\': -1,\n                                   \'collision_vehicles\': -1,\n                                   \'intersection_otherlane\': -1,\n                                   \'intersection_offroad\': -1,\n                                   \'pos_x\': -1,\n                                   \'pos_y\': -1,\n                                   \'steer\': -1,\n                                   \'throttle\': -1,\n                                   \'brake\': -1\n                                   }\n\n        # Just in the case is the first time and there is no benchmark results folder\n        if not os.path.exists(\'_benchmarks_results\'):\n            os.mkdir(\'_benchmarks_results\')\n\n        # Generate the full path for the log files\n        self._path = os.path.join(\'_benchmarks_results\'\n                                  , name_to_save\n                                  )\n\n        # Check for continuation of experiment, also returns the last line, used for test purposes\n        # If you don\'t want to continue it will create a new path name with a number\n        self._path, _ = self._continue_experiment(continue_experiment)\n\n        self._create_log_files()\n\n        # A log with a date file: to show when was the last access and log what was tested,\n        now = datetime.datetime.now()\n        self._internal_log_name = os.path.join(self._path, \'log_\' + now.strftime(""%Y%m%d%H%M""))\n        open(self._internal_log_name, \'w\').close()\n\n        # store the save images flag, and already store the format for image saving\n        self._save_images = save_images\n        self._image_filename_format = os.path.join(\n            self._path, \'_images/episode_{:s}/{:s}/image_{:0>5d}.jpg\')\n\n    @property\n    def path(self):\n        return self._path\n\n    def log_poses(self, start_index, end_index, weather_id):\n        with open(self._internal_log_name, \'a+\') as log:\n            log.write(\' Start Poses  (%d  %d ) on weather %d \\n \' %\n                      (start_index, end_index, weather_id))\n\n    def log_poses_finish(self):\n        with open(self._internal_log_name, \'a+\') as log:\n            log.write(\'Finished Task\')\n\n    def log_start(self, id_experiment):\n\n        with open(self._internal_log_name, \'a+\') as log:\n            log.write(\'Start Task %d \\n\' % id_experiment)\n\n    def log_end(self):\n        with open(self._internal_log_name, \'a+\') as log:\n            log.write(\'====== Finished Entire Benchmark ======\')\n\n    def write_summary_results(self, experiment, pose, rep,\n                              path_distance, remaining_distance,\n                              final_time, time_out, result):\n        """"""\n        Method to record the summary of an episode(pose) execution\n        """"""\n\n        self._dict_summary[\'exp_id\'] = experiment.task\n        self._dict_summary[\'rep\'] = rep\n        self._dict_summary[\'weather\'] = experiment.Conditions.WeatherId\n        self._dict_summary[\'start_point\'] = pose[0]\n        self._dict_summary[\'end_point\'] = pose[1]\n        self._dict_summary[\'result\'] = result\n        self._dict_summary[\'initial_distance\'] = path_distance\n        self._dict_summary[\'final_distance\'] = remaining_distance\n        self._dict_summary[\'final_time\'] = final_time\n        self._dict_summary[\'time_out\'] = time_out\n\n        with open(os.path.join(self._path, \'summary.csv\'), \'a+\') as ofd:\n            w = csv.DictWriter(ofd, self._dict_summary.keys())\n\n            w.writerow(self._dict_summary)\n\n    def write_measurements_results(self, experiment, rep, pose, reward_vec, control_vec):\n        """"""\n        Method to record the measurements, sensors,\n        controls and status of the entire benchmark.\n        """"""\n        with open(os.path.join(self._path, \'measurements.csv\'), \'a+\') as rfd:\n            rw = csv.DictWriter(rfd, self._dict_measurements.keys())\n\n            for i in range(len(reward_vec)):\n                self._dict_measurements[\'exp_id\'] = experiment.task\n                self._dict_measurements[\'rep\'] = rep\n                self._dict_measurements[\'start_point\'] = pose[0]\n                self._dict_measurements[\'end_point\'] = pose[1]\n                self._dict_measurements[\'weather\'] = experiment.Conditions.WeatherId\n                self._dict_measurements[\'collision_other\'] = reward_vec[\n                    i].collision_other\n                self._dict_measurements[\'collision_pedestrians\'] = reward_vec[\n                    i].collision_pedestrians\n                self._dict_measurements[\'collision_vehicles\'] = reward_vec[\n                    i].collision_vehicles\n                self._dict_measurements[\'intersection_otherlane\'] = reward_vec[\n                    i].intersection_otherlane\n                self._dict_measurements[\'intersection_offroad\'] = reward_vec[\n                    i].intersection_offroad\n                self._dict_measurements[\'pos_x\'] = reward_vec[\n                    i].transform.location.x\n                self._dict_measurements[\'pos_y\'] = reward_vec[\n                    i].transform.location.y\n                self._dict_measurements[\'steer\'] = control_vec[\n                    i].steer\n                self._dict_measurements[\'throttle\'] = control_vec[\n                    i].throttle\n                self._dict_measurements[\'brake\'] = control_vec[\n                    i].brake\n\n                rw.writerow(self._dict_measurements)\n\n    def _create_log_files(self):\n        """"""\n        Just create the log files and add the necessary header for it.\n        """"""\n\n        if not self._experiment_exist():\n            os.mkdir(self._path)\n\n            with open(os.path.join(self._path, \'summary.csv\'), \'w\') as ofd:\n                w = csv.DictWriter(ofd, self._dict_summary.keys())\n                w.writeheader()\n\n            with open(os.path.join(self._path, \'measurements.csv\'), \'w\') as rfd:\n                rw = csv.DictWriter(rfd, self._dict_measurements.keys())\n                rw.writeheader()\n\n    def _continue_experiment(self, continue_experiment):\n        """"""\n        Get the line on the file for the experiment.\n        If continue_experiment is false and experiment exist, generates a new file path\n\n        """"""\n\n        def get_non_existent_path(f_name_path):\n            """"""\n            Get the path to a filename which does not exist by incrementing path.\n            """"""\n            if not os.path.exists(f_name_path):\n                return f_name_path\n            filename, file_extension = os.path.splitext(f_name_path)\n            i = 1\n            new_f_name = ""{}-{}{}"".format(filename, i, file_extension)\n            while os.path.exists(new_f_name):\n                i += 1\n                new_f_name = ""{}-{}{}"".format(filename, i, file_extension)\n            return new_f_name\n\n        # start the new path as the same one as before\n        new_path = self._path\n\n        # if the experiment exist\n        if self._experiment_exist():\n\n            # If you want to continue just get the last position\n            if continue_experiment:\n                line_on_file = self._get_last_position()\n\n            else:\n                # Get a new non_conflicting path name\n                new_path = get_non_existent_path(new_path)\n                line_on_file = 1\n\n        else:\n            line_on_file = 1\n        return new_path, line_on_file\n\n    def save_images(self, sensor_data, episode_name, frame):\n        """"""\n        Save a image during the experiment\n        """"""\n        if self._save_images:\n            for name, image in sensor_data.items():\n                image.save_to_disk(self._image_filename_format.format(\n                    episode_name, name, frame))\n\n    def get_pose_and_experiment(self, number_poses_task):\n        """"""\n        Based on the line in log file, return the current pose and experiment.\n        If the line is zero, create new log files.\n\n        """"""\n        # Warning: assumes that all tasks have the same size\n        line_on_file = self._get_last_position() - 1\n        if line_on_file == 0:\n            return 0, 0\n        else:\n            return line_on_file % number_poses_task, line_on_file // number_poses_task\n\n    def _experiment_exist(self):\n\n        return os.path.exists(self._path)\n\n    def _get_last_position(self):\n        """"""\n        Get the last position on the summary experiment file\n        With this you are able to continue from there\n\n        Returns:\n             int, position:\n        """"""\n        # Try to open, if the file is not found\n        try:\n            with open(os.path.join(self._path, \'summary.csv\')) as f:\n                return sum(1 for _ in f)\n        except IOError:\n            return 0\n'"
ch8/environment/carla_gym/envs/carla/driving_benchmark/results_printer.py,0,"b'import os\nimport numpy as np\nimport json\n\n\ndef print_summary(metrics_summary, weathers, path):\n    """"""\n        We plot the summary of the testing for the set selected weathers.\n\n        We take the raw data and print the way it was described on CORL 2017 paper\n\n    """"""\n\n    # Improve readability by adding a weather dictionary\n    weather_name_dict = {1: \'Clear Noon\', 3: \'After Rain Noon\',\n                         6: \'Heavy Rain Noon\', 8: \'Clear Sunset\',\n                         4: \'Cloudy After Rain\', 14: \'Soft Rain Sunset\'}\n\n    # First we write the entire dictionary on the benchmark folder.\n    with open(os.path.join(path, \'metrics.json\'), \'w\') as fo:\n        fo.write(json.dumps(metrics_summary))\n\n    # Second we plot the metrics that are already ready by averaging\n\n    metrics_to_average = [\n        \'episodes_fully_completed\',\n        \'episodes_completion\'\n\n    ]\n    # We compute the number  of episodes based on size of average completion\n    number_of_episodes = len(list(metrics_summary[\'episodes_fully_completed\'].items())[0][1])\n\n    for metric in metrics_to_average:\n\n        if metric == \'episodes_completion\':\n            print (""Average Percentage of Distance to Goal Travelled "")\n        else:\n            print (""Percentage of Successful Episodes"")\n\n        print ("""")\n        values = metrics_summary[metric]\n\n        metric_sum_values = np.zeros(number_of_episodes)\n        for weather, tasks in values.items():\n            if weather in set(weathers):\n                print(\'  Weather: \', weather_name_dict[weather])\n                count = 0\n                for t in tasks:\n                    # if isinstance(t, np.ndarray) or isinstance(t, list):\n                    if t == []:\n                        print(\'    Metric Not Computed\')\n                    else:\n                        print(\'    Task:\', count, \' -> \', float(sum(t)) / float(len(t)))\n                        metric_sum_values[count] += (float(sum(t)) / float(len(t))) * 1.0 / float(\n                            len(weathers))\n\n                    count += 1\n\n        print (\'  Average Between Weathers\')\n        for i in range(len(metric_sum_values)):\n            print(\'    Task \', i, \' -> \', metric_sum_values[i])\n        print ("""")\n\n    infraction_metrics = [\n        \'collision_pedestrians\',\n        \'collision_vehicles\',\n        \'collision_other\',\n        \'intersection_offroad\',\n        \'intersection_otherlane\'\n\n    ]\n\n    # We need to collect the total number of kilometers for each task\n\n    for metric in infraction_metrics:\n        values_driven = metrics_summary[\'driven_kilometers\']\n        values = metrics_summary[metric]\n        metric_sum_values = np.zeros(number_of_episodes)\n        summed_driven_kilometers = np.zeros(number_of_episodes)\n\n        if metric == \'collision_pedestrians\':\n            print (\'Avg. Kilometers driven before a collision to a PEDESTRIAN\')\n        elif metric == \'collision_vehicles\':\n            print(\'Avg. Kilometers driven before a collision to a VEHICLE\')\n        elif metric == \'collision_other\':\n            print(\'Avg. Kilometers driven before a collision to a STATIC OBSTACLE\')\n        elif metric == \'intersection_offroad\':\n            print(\'Avg. Kilometers driven before going OUTSIDE OF THE ROAD\')\n        else:\n            print(\'Avg. Kilometers driven before invading the OPPOSITE LANE\')\n\n        # print (zip(values.items(), values_driven.items()))\n        for items_metric, items_driven in zip(values.items(), values_driven.items()):\n            weather = items_metric[0]\n            tasks = items_metric[1]\n            tasks_driven = items_driven[1]\n\n            if weather in set(weathers):\n                print(\'  Weather: \', weather_name_dict[weather])\n                count = 0\n                for t, t_driven in zip(tasks, tasks_driven):\n                    # if isinstance(t, np.ndarray) or isinstance(t, list):\n                    if t == []:\n                        print(\'Metric Not Computed\')\n                    else:\n                        if sum(t) > 0:\n                            print(\'    Task \', count, \' -> \', t_driven / float(sum(t)))\n                        else:\n                            print(\'    Task \', count, \' -> more than\', t_driven)\n\n                        metric_sum_values[count] += float(sum(t))\n                        summed_driven_kilometers[count] += t_driven\n\n                    count += 1\n        print (\'  Average Between Weathers\')\n        for i in range(len(metric_sum_values)):\n            if metric_sum_values[i] == 0:\n                print(\'    Task \', i, \' -> more than \', summed_driven_kilometers[i])\n            else:\n                print(\'    Task \', i, \' -> \', summed_driven_kilometers[i] / metric_sum_values[i])\n        print ("""")\n\n    print("""")\n    print("""")\n'"
ch8/environment/carla_gym/envs/carla/planner/__init__.py,0,b''
ch8/environment/carla_gym/envs/carla/planner/astar.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport heapq\n\n\nclass Cell(object):\n    def __init__(self, x, y, reachable):\n        """"""Initialize new cell.\n\n        @param reachable is cell reachable? not a wall?\n        @param x cell x coordinate\n        @param y cell y coordinate\n        @param g cost to move from the starting cell to this cell.\n        @param h estimation of the cost to move from this cell\n                 to the ending cell.\n        @param f f = g + h\n        """"""\n        self.reachable = reachable\n        self.x = x\n        self.y = y\n        self.parent = None\n        self.g = 0\n        self.h = 0\n        self.f = 0\n\n    def __lt__(self, other):\n        return self.g < other.g\n\n\nclass AStar(object):\n    def __init__(self):\n        # open list\n        self.opened = []\n        heapq.heapify(self.opened)\n        # visited cells list\n        self.closed = set()\n        # grid cells\n        self.cells = []\n        self.grid_height = None\n        self.grid_width = None\n        self.start = None\n        self.end = None\n\n    def init_grid(self, width, height, walls, start, end):\n        """"""Prepare grid cells, walls.\n\n        @param width grid\'s width.\n        @param height grid\'s height.\n        @param walls list of wall x,y tuples.\n        @param start grid starting point x,y tuple.\n        @param end grid ending point x,y tuple.\n        """"""\n        self.grid_height = height\n        self.grid_width = width\n        for x in range(self.grid_width):\n            for y in range(self.grid_height):\n                if (x, y) in walls:\n                    reachable = False\n                else:\n                    reachable = True\n                self.cells.append(Cell(x, y, reachable))\n        self.start = self.get_cell(*start)\n        self.end = self.get_cell(*end)\n\n    def get_heuristic(self, cell):\n        """"""Compute the heuristic value H for a cell.\n\n        Distance between this cell and the ending cell multiply by 10.\n\n        @returns heuristic value H\n        """"""\n        return 10 * (abs(cell.x - self.end.x) + abs(cell.y - self.end.y))\n\n    def get_cell(self, x, y):\n        """"""Returns a cell from the cells list.\n\n        @param x cell x coordinate\n        @param y cell y coordinate\n        @returns cell\n        """"""\n        return self.cells[x * self.grid_height + y]\n\n    def get_adjacent_cells(self, cell):\n        """"""Returns adjacent cells to a cell.\n\n        Clockwise starting from the one on the right.\n\n        @param cell get adjacent cells for this cell\n        @returns adjacent cells list.\n        """"""\n        cells = []\n        if cell.x < self.grid_width - 1:\n            cells.append(self.get_cell(cell.x + 1, cell.y))\n        if cell.y > 0:\n            cells.append(self.get_cell(cell.x, cell.y - 1))\n        if cell.x > 0:\n            cells.append(self.get_cell(cell.x - 1, cell.y))\n        if cell.y < self.grid_height - 1:\n            cells.append(self.get_cell(cell.x, cell.y + 1))\n        return cells\n\n    def get_path(self):\n        cell = self.end\n        path = [(cell.x, cell.y)]\n        while cell.parent is not self.start:\n            cell = cell.parent\n            path.append((cell.x, cell.y))\n\n        path.append((self.start.x, self.start.y))\n        path.reverse()\n        return path\n\n    def update_cell(self, adj, cell):\n        """"""Update adjacent cell.\n\n        @param adj adjacent cell to current cell\n        @param cell current cell being processed\n        """"""\n        adj.g = cell.g + 10\n        adj.h = self.get_heuristic(adj)\n        adj.parent = cell\n        adj.f = adj.h + adj.g\n\n    def solve(self):\n        """"""Solve maze, find path to ending cell.\n\n        @returns path or None if not found.\n        """"""\n        # add starting cell to open heap queue\n        heapq.heappush(self.opened, (self.start.f, self.start))\n        while len(self.opened):\n            # pop cell from heap queue\n            _, cell = heapq.heappop(self.opened)\n            # add cell to closed list so we don\'t process it twice\n            self.closed.add(cell)\n            # if ending cell, return found path\n            if cell is self.end:\n                return self.get_path()\n            # get adjacent cells for cell\n            adj_cells = self.get_adjacent_cells(cell)\n            for adj_cell in adj_cells:\n                if adj_cell.reachable and adj_cell not in self.closed:\n                    if (adj_cell.f, adj_cell) in self.opened:\n                        # if adj cell in open list, check if current path is\n                        # better than the one previously found\n                        # for this adj cell.\n                        if adj_cell.g > cell.g + 10:\n                            self.update_cell(adj_cell, cell)\n                    else:\n                        self.update_cell(adj_cell, cell)\n                        # add adj cell to open list\n                        heapq.heappush(self.opened, (adj_cell.f, adj_cell))\n'"
ch8/environment/carla_gym/envs/carla/planner/city_track.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nfrom .graph import sldist\n\nfrom .astar import AStar\nfrom .map import CarlaMap\n\n\nclass CityTrack(object):\n\n    def __init__(self, city_name):\n\n        # These values are fixed for every city.\n        self._node_density = 50.0\n        self._pixel_density = 0.1643\n\n        self._map = CarlaMap(city_name, self._pixel_density, self._node_density)\n\n        self._astar = AStar()\n\n        # Refers to the start position of the previous route computation\n        self._previous_node = []\n\n        # The current computed route\n        self._route = None\n\n    def project_node(self, position):\n        """"""\n            Projecting the graph node into the city road\n        """"""\n\n        node = self._map.convert_to_node(position)\n\n        # To change the orientation with respect to the map standards\n\n        node = tuple([int(x) for x in node])\n\n        # Set to zero if it is less than zero.\n\n        node = (max(0, node[0]), max(0, node[1]))\n        node = (min(self._map.get_graph_resolution()[0] - 1, node[0]),\n                min(self._map.get_graph_resolution()[1] - 1, node[1]))\n\n        node = self._map.search_on_grid(node)\n\n        return node\n\n    def get_intersection_nodes(self):\n        return self._map.get_intersection_nodes()\n\n    def get_pixel_density(self):\n        return self._pixel_density\n\n    def get_node_density(self):\n        return self._node_density\n\n    def is_at_goal(self, source, target):\n        return source == target\n\n    def is_at_new_node(self, current_node):\n        return current_node != self._previous_node\n\n    def is_away_from_intersection(self, current_node):\n        return self._closest_intersection_position(current_node) > 1\n\n    def is_far_away_from_route_intersection(self, current_node):\n        # CHECK FOR THE EMPTY CASE\n        if self._route is None:\n            raise RuntimeError(\'Impossible to find route\'\n                               + \' Current planner is limited\'\n                               + \' Try to select start points away from intersections\')\n\n        return self._closest_intersection_route_position(current_node,\n                                                         self._route) > 4\n\n    def compute_route(self, node_source, source_ori, node_target, target_ori):\n\n        self._previous_node = node_source\n\n        a_star = AStar()\n        a_star.init_grid(self._map.get_graph_resolution()[0],\n                         self._map.get_graph_resolution()[1],\n                         self._map.get_walls_directed(node_source, source_ori,\n                                                      node_target, target_ori), node_source,\n                         node_target)\n\n        route = a_star.solve()\n\n        # JuSt a Corner Case\n        # Clean this to avoid having to use this function\n        if route is None:\n            a_star = AStar()\n            a_star.init_grid(self._map.get_graph_resolution()[0],\n                             self._map.get_graph_resolution()[1], self._map.get_walls(),\n                             node_source, node_target)\n\n            route = a_star.solve()\n\n        self._route = route\n\n        return route\n\n    def get_distance_closest_node_route(self, pos, route):\n        distance = []\n\n        for node_iter in route:\n\n            if node_iter in self._map.get_intersection_nodes():\n                distance.append(sldist(node_iter, pos))\n\n        if not distance:\n            return sldist(route[-1], pos)\n        return sorted(distance)[0]\n\n\n    def _closest_intersection_position(self, current_node):\n\n        distance_vector = []\n        for node_iterator in self._map.get_intersection_nodes():\n            distance_vector.append(sldist(node_iterator, current_node))\n\n        return sorted(distance_vector)[0]\n\n\n    def _closest_intersection_route_position(self, current_node, route):\n\n        distance_vector = []\n        for _ in route:\n            for node_iterator in self._map.get_intersection_nodes():\n                distance_vector.append(sldist(node_iterator, current_node))\n\n        return sorted(distance_vector)[0]\n\n'"
ch8/environment/carla_gym/envs/carla/planner/converter.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport math\nimport numpy as np\n\nfrom .graph import string_to_floats\n\n# Constant definition enumeration\n\nPIXEL = 0\nWORLD = 1\nNODE = 2\n\n\nclass Converter(object):\n\n    def __init__(self, city_file,  pixel_density, node_density):\n\n        self._node_density = node_density\n        self._pixel_density = pixel_density\n        with open(city_file, \'r\') as f:\n            # The offset of the world from the zero coordinates ( The\n            # coordinate we consider zero)\n            self._worldoffset = string_to_floats(f.readline())\n\n            angles = string_to_floats(f.readline())\n\n            # If there is an rotation between the world and map coordinates.\n            self._worldrotation = np.array([\n                [math.cos(math.radians(angles[2])), -math.sin(math.radians(angles[2])), 0.0],\n                [math.sin(math.radians(angles[2])), math.cos(math.radians(angles[2])), 0.0],\n                [0.0, 0.0, 1.0]])\n\n            # Ignore for now, these are offsets for map coordinates and scale\n            # (not used).\n            _ = f.readline()\n\n            # The offset of the map zero coordinate.\n            self._mapoffset = string_to_floats(f.readline())\n\n    def convert_to_node(self, input_data):\n        """"""\n        Receives a data type (Can Be Pixel or World )\n        :param input_data: position in some coordinate\n        :return: A vector representing a node\n        """"""\n\n        input_type = self._check_input_type(input_data)\n        if input_type == PIXEL:\n            return self._pixel_to_node(input_data)\n        elif input_type == WORLD:\n            return self._world_to_node(input_data)\n        else:\n            raise ValueError(\'Invalid node to be converted\')\n\n    def convert_to_pixel(self, input_data):\n\n        """"""\n        Receives a data type (Can Be Node or World )\n        :param input_data: position in some coordinate\n        :return: A vector with pixel coordinates\n        """"""\n\n        input_type = self._check_input_type(input_data)\n\n        if input_type == NODE:\n            return self._node_to_pixel(input_data)\n        elif input_type == WORLD:\n            return self._world_to_pixel(input_data)\n        else:\n            raise ValueError(\'Invalid node to be converted\')\n\n    def convert_to_world(self, input_data):\n\n        """"""\n        Receives a data type (Can Be Pixel or Node )\n        :param input_data: position in some coordinate\n        :return: vector with world coordinates\n        """"""\n\n        input_type = self._check_input_type(input_data)\n        if input_type == NODE:\n            return self._node_to_world(input_data)\n        elif input_type == PIXEL:\n            return self._pixel_to_world(input_data)\n        else:\n            raise ValueError(\'Invalid node to be converted\')\n\n    def _node_to_pixel(self, node):\n        """"""\n        Conversion from node format (graph) to pixel (image)\n        :param node:\n        :return: pixel\n        """"""\n        pixel = [((node[0] + 2) * self._node_density)\n            , ((node[1] + 2) * self._node_density)]\n        return pixel\n\n    def _pixel_to_node(self, pixel):\n        """"""\n        Conversion from pixel format (image) to node (graph)\n        :param node:\n        :return: pixel\n        """"""\n        node = [int(((pixel[0]) / self._node_density) - 2)\n            , int(((pixel[1]) / self._node_density) - 2)]\n\n        return tuple(node)\n\n    def _pixel_to_world(self, pixel):\n        """"""\n        Conversion from pixel format (image) to world (3D)\n        :param pixel:\n        :return: world\n        """"""\n\n        relative_location = [pixel[0] * self._pixel_density,\n                             pixel[1] * self._pixel_density]\n\n        world = [\n            relative_location[0] + self._mapoffset[0] - self._worldoffset[0],\n            relative_location[1] + self._mapoffset[1] - self._worldoffset[1],\n            22\n        ]\n\n        return world\n\n    def _world_to_pixel(self, world):\n        """"""\n        Conversion from world format (3D) to pixel\n        :param world:\n        :return: pixel\n        """"""\n\n        rotation = np.array([world[0], world[1], world[2]])\n        rotation = rotation.dot(self._worldrotation)\n\n        relative_location = [rotation[0] + self._worldoffset[0] - self._mapoffset[0],\n                             rotation[1] + self._worldoffset[1] - self._mapoffset[1],\n                             rotation[2] + self._worldoffset[2] - self._mapoffset[2]]\n\n\n\n        pixel = [math.floor(relative_location[0] / float(self._pixel_density)),\n                 math.floor(relative_location[1] / float(self._pixel_density))]\n\n        return pixel\n\n    def _world_to_node(self, world):\n        return self._pixel_to_node(self._world_to_pixel(world))\n\n    def _node_to_world(self, node):\n\n        return self._pixel_to_world(self._node_to_pixel(node))\n\n    def _check_input_type(self, input_data):\n        if len(input_data) > 2:\n            return WORLD\n        elif type(input_data[0]) is int:\n            return NODE\n        else:\n            return PIXEL\n'"
ch8/environment/carla_gym/envs/carla/planner/graph.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport math\nimport numpy as np\n\n\ndef string_to_node(string):\n    vec = string.split(\',\')\n    return (int(vec[0]), int(vec[1]))\n\n\ndef string_to_floats(string):\n    vec = string.split(\',\')\n    return (float(vec[0]), float(vec[1]), float(vec[2]))\n\n\ndef sldist(c1, c2):\n    return math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2)\n\n\ndef sldist3(c1, c2):\n    return math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1])\n                     ** 2 + (c2[2] - c1[2]) ** 2)\n\n\nclass Graph(object):\n    """"""\n    A simple directed, weighted graph\n    """"""\n\n    def __init__(self, graph_file=None, node_density=50):\n\n        self._nodes = set()\n        self._angles = {}\n        self._edges = {}\n        self._distances = {}\n        self._node_density = node_density\n\n        if graph_file is not None:\n            with open(graph_file, \'r\') as f:\n                # Skipe the first four lines that\n                lines_after_4 = f.readlines()[4:]\n\n                # the graph resolution.\n                linegraphres = lines_after_4[0]\n                self._resolution = string_to_node(linegraphres)\n                for line in lines_after_4[1:]:\n\n                    from_node, to_node, d = line.split()\n                    from_node = string_to_node(from_node)\n                    to_node = string_to_node(to_node)\n\n                    if from_node not in self._nodes:\n                        self.add_node(from_node)\n                    if to_node not in self._nodes:\n                        self.add_node(to_node)\n\n                    self._edges.setdefault(from_node, [])\n                    self._edges[from_node].append(to_node)\n                    self._distances[(from_node, to_node)] = float(d)\n\n    def add_node(self, value):\n        self._nodes.add(value)\n\n    def make_orientations(self, node, heading):\n\n        import collections\n        distance_dic = {}\n        for node_iter in self._nodes:\n            if node_iter != node:\n                distance_dic[sldist(node, node_iter)] = node_iter\n\n        distance_dic = collections.OrderedDict(\n            sorted(distance_dic.items()))\n\n        self._angles[node] = heading\n        for _, v in distance_dic.items():\n            start_to_goal = np.array([node[0] - v[0], node[1] - v[1]])\n\n            print(start_to_goal)\n\n            self._angles[v] = start_to_goal / np.linalg.norm(start_to_goal)\n\n    def add_edge(self, from_node, to_node, distance):\n        self._add_edge(from_node, to_node, distance)\n\n    def _add_edge(self, from_node, to_node, distance):\n        self._edges.setdefault(from_node, [])\n        self._edges[from_node].append(to_node)\n        self._distances[(from_node, to_node)] = distance\n\n    def get_resolution(self):\n        return self._resolution\n    def get_edges(self):\n        return self._edges\n\n    def intersection_nodes(self):\n\n        intersect_nodes = []\n        for node in self._nodes:\n            if len(self._edges[node]) > 2:\n                intersect_nodes.append(node)\n\n        return intersect_nodes\n\n    # This contains also the non-intersection turns...\n\n    def turn_nodes(self):\n\n        return self._nodes\n\n    def plot_ori(self, c):\n        from matplotlib import collections as mc\n\n        import matplotlib.pyplot as plt\n        line_len = 1\n\n        lines = [[(p[0], p[1]), (p[0] + line_len * self._angles[p][0],\n                                 p[1] + line_len * self._angles[p][1])] for p in self._nodes]\n        lc = mc.LineCollection(lines, linewidth=2, color=\'green\')\n        _, ax = plt.subplots()\n        ax.add_collection(lc)\n\n        ax.autoscale()\n        ax.margins(0.1)\n\n        xs = [p[0] for p in self._nodes]\n        ys = [p[1] for p in self._nodes]\n\n        plt.scatter(xs, ys, color=c)\n\n    def plot(self, c):\n        import matplotlib.pyplot as plt\n        xs = [p[0] for p in self._nodes]\n        ys = [p[1] for p in self._nodes]\n\n        plt.scatter(xs, ys, color=c)\n'"
ch8/environment/carla_gym/envs/carla/planner/grid.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport copy\nimport numpy as np\n\n\ndef angle_between(v1, v2):\n    return np.arccos(np.dot(v1, v2) / np.linalg.norm(v1) / np.linalg.norm(v2))\n\n\nclass Grid(object):\n\n    def __init__(self, graph):\n\n        self._graph = graph\n        self._structure = self._make_structure()\n        self._walls = self._make_walls()\n\n    def search_on_grid(self, x, y):\n        visit = [[0, 1], [0, -1], [1, 0], [1, 1],\n                 [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n        c_x, c_y = x, y\n        scale = 1\n        while self._structure[c_x, c_y] != 0:\n            for offset in visit:\n                c_x, c_y = x + offset[0] * scale, y + offset[1] * scale\n\n                if c_x >= 0 and c_x < self._graph.get_resolution()[\n                    0] and c_y >= 0 and c_y < self._graph.get_resolution()[1]:\n                    if self._structure[c_x, c_y] == 0:\n                        break\n                else:\n                    c_x, c_y = x, y\n            scale += 1\n\n        return c_x, c_y\n    def get_walls(self):\n        return self._walls\n\n    def get_wall_source(self, pos, pos_ori, target):\n\n        free_nodes = self._get_adjacent_free_nodes(pos)\n        # print self._walls\n        final_walls = copy.copy(self._walls)\n        # print final_walls\n        heading_start = np.array([pos_ori[0], pos_ori[1]])\n        for adj in free_nodes:\n\n            start_to_goal = np.array([adj[0] - pos[0], adj[1] - pos[1]])\n            angle = angle_between(heading_start, start_to_goal)\n            if (angle > 1.6 and adj != target):\n                final_walls.add((adj[0], adj[1]))\n\n        return final_walls\n\n    def get_wall_target(self, pos, pos_ori, source):\n\n        free_nodes = self._get_adjacent_free_nodes(pos)\n        final_walls = copy.copy(self._walls)\n        heading_start = np.array([pos_ori[0], pos_ori[1]])\n        for adj in free_nodes:\n\n            start_to_goal = np.array([adj[0] - pos[0], adj[1] - pos[1]])\n            angle = angle_between(heading_start, start_to_goal)\n\n            if (angle < 1.0 and adj != source):\n                final_walls.add((adj[0], adj[1]))\n\n        return final_walls\n\n    def _draw_line(self, grid, xi, yi, xf, yf):\n\n        if xf < xi:\n            aux = xi\n            xi = xf\n            xf = aux\n\n        if yf < yi:\n            aux = yi\n            yi = yf\n            yf = aux\n\n        for i in range(xi, xf + 1):\n\n            for j in range(yi, yf + 1):\n                grid[i, j] = 0.0\n\n        return grid\n\n    def _make_structure(self):\n        structure = np.ones(\n            (self._graph.get_resolution()[0],\n             self._graph.get_resolution()[1]))\n\n        for key, connections in self._graph.get_edges().items():\n\n            # draw a line\n            for con in connections:\n                # print key[0],key[1],con[0],con[1]\n                structure = self._draw_line(\n                    structure, key[0], key[1], con[0], con[1])\n                # print grid\n        return structure\n\n    def _make_walls(self):\n        walls = set()\n\n        for i in range(self._structure.shape[0]):\n\n            for j in range(self._structure.shape[1]):\n                if self._structure[i, j] == 1.0:\n                    walls.add((i, j))\n\n        return walls\n\n    def _get_adjacent_free_nodes(self, pos):\n        """""" Eight nodes in total """"""\n        visit = [[0, 1], [0, -1], [1, 0], [1, 1],\n                 [1, -1], [-1, 0], [-1, 1], [-1, -1]]\n\n        adjacent = set()\n        for offset in visit:\n            node = (pos[0] + offset[0], pos[1] + offset[1])\n\n            if (node[0] >= 0 and node[0] < self._graph.get_resolution()[0]\n                    and node[1] >= 0 and node[1] < self._graph.get_resolution()[1]):\n\n                if self._structure[node[0], node[1]] == 0.0:\n                    adjacent.add(node)\n\n        return adjacent\n'"
ch8/environment/carla_gym/envs/carla/planner/map.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n""""""Class used for operating the city map.""""""\n\nimport math\nimport os\n\ntry:\n    import numpy as np\nexcept ImportError:\n    raise RuntimeError(\'cannot import numpy, make sure numpy package is installed\')\n\ntry:\n    from PIL import Image\nexcept ImportError:\n    raise RuntimeError(\'cannot import PIL, make sure pillow package is installed\')\n\nfrom .graph import Graph\nfrom .graph import sldist\nfrom .grid import Grid\nfrom .converter import Converter\n\n\ndef color_to_angle(color):\n    return (float(color) / 255.0) * 2 * math.pi\n\n\nclass CarlaMap(object):\n\n    def __init__(self, city, pixel_density, node_density):\n        dir_path = os.path.dirname(__file__)\n        city_file = os.path.join(dir_path, city + \'.txt\')\n\n        city_map_file = os.path.join(dir_path, city + \'.png\')\n        city_map_file_lanes = os.path.join(dir_path, city + \'Lanes.png\')\n        city_map_file_center = os.path.join(dir_path, city + \'Central.png\')\n\n        # The built graph. This is the exact same graph that unreal builds. This\n        # is a generic structure used for many cases\n        self._graph = Graph(city_file, node_density)\n\n        self._pixel_density = pixel_density\n        self._grid = Grid(self._graph)\n        # The number of game units per pixel. For now this is fixed.\n\n        self._converter = Converter(city_file, pixel_density, node_density)\n\n        # Load the lanes image\n        self.map_image_lanes = Image.open(city_map_file_lanes)\n        self.map_image_lanes.load()\n        self.map_image_lanes = np.asarray(self.map_image_lanes, dtype=""int32"")\n        # Load the image\n        self.map_image = Image.open(city_map_file)\n        self.map_image.load()\n        self.map_image = np.asarray(self.map_image, dtype=""int32"")\n\n        # Load the lanes image\n        self.map_image_center = Image.open(city_map_file_center)\n        self.map_image_center.load()\n        self.map_image_center = np.asarray(self.map_image_center, dtype=""int32"")\n\n    def get_graph_resolution(self):\n\n        return self._graph.get_resolution()\n\n    def get_map(self, height=None):\n        if height is not None:\n            img = Image.fromarray(self.map_image.astype(np.uint8))\n\n            aspect_ratio = height / float(self.map_image.shape[0])\n\n            img = img.resize((int(aspect_ratio * self.map_image.shape[1]), height), Image.ANTIALIAS)\n            img.load()\n            return np.asarray(img, dtype=""int32"")\n        return np.fliplr(self.map_image)\n\n    def get_map_lanes(self, size=None):\n        if size is not None:\n            img = Image.fromarray(self.map_image_lanes.astype(np.uint8))\n            img = img.resize((size[1], size[0]), Image.ANTIALIAS)\n            img.load()\n            return np.fliplr(np.asarray(img, dtype=""int32""))\n        return np.fliplr(self.map_image_lanes)\n\n    def get_lane_orientation(self, world):\n        """"""Get the lane orientation of a certain world position.""""""\n        pixel = self.convert_to_pixel(world)\n\n        ori = self.map_image_lanes[int(pixel[1]), int(pixel[0]), 2]\n        ori = color_to_angle(ori)\n\n        return (-math.cos(ori), -math.sin(ori))\n\n    def convert_to_node(self, input_data):\n        """"""\n        Receives a data type (Can Be Pixel or World )\n        :param input_data: position in some coordinate\n        :return: A node object\n        """"""\n        return self._converter.convert_to_node(input_data)\n\n    def convert_to_pixel(self, input_data):\n        """"""\n        Receives a data type (Can Be Node or World )\n        :param input_data: position in some coordinate\n        :return: A node object\n        """"""\n        return self._converter.convert_to_pixel(input_data)\n\n    def convert_to_world(self, input_data):\n        """"""\n        Receives a data type (Can Be Pixel or Node )\n        :param input_data: position in some coordinate\n        :return: A node object\n        """"""\n        return self._converter.convert_to_world(input_data)\n\n    def get_walls_directed(self, node_source, source_ori, node_target, target_ori):\n        """"""\n        This is the most hacky function. Instead of planning on two ways,\n        we basically use a one way road and interrupt the other road by adding\n        an artificial wall.\n\n        """"""\n\n        final_walls = self._grid.get_wall_source(node_source, source_ori, node_target)\n\n        final_walls = final_walls.union(self._grid.get_wall_target(\n            node_target, target_ori, node_source))\n        return final_walls\n\n    def get_walls(self):\n\n        return self._grid.get_walls()\n\n    def get_distance_closest_node(self, pos):\n\n        distance = []\n        for node_iter in self._graph.intersection_nodes():\n            distance.append(sldist(node_iter, pos))\n\n        return sorted(distance)[0]\n\n    def get_intersection_nodes(self):\n        return self._graph.intersection_nodes()\n\n    def search_on_grid(self,node):\n        return self._grid.search_on_grid(node[0], node[1])\n'"
ch8/environment/carla_gym/envs/carla/planner/planner.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\nimport collections\nimport math\n\nimport numpy as np\n\nfrom . import city_track\n\n\ndef compare(x, y):\n    return collections.Counter(x) == collections.Counter(y)\n\n\n\n# Constants Used for the high level commands\n\n\nREACH_GOAL = 0.0\nGO_STRAIGHT = 5.0\nTURN_RIGHT = 4.0\nTURN_LEFT = 3.0\nLANE_FOLLOW = 2.0\n\n\n# Auxiliary algebra function\ndef angle_between(v1, v2):\n    return np.arccos(np.dot(v1, v2) / np.linalg.norm(v1) / np.linalg.norm(v2))\n\n\ndef sldist(c1, c2): return math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2)\n\n\ndef signal(v1, v2):\n    return np.cross(v1, v2) / np.linalg.norm(v1) / np.linalg.norm(v2)\n\n\nclass Planner(object):\n\n    def __init__(self, city_name):\n\n        self._city_track = city_track.CityTrack(city_name)\n\n        self._commands = []\n\n    def get_next_command(self, source, source_ori, target, target_ori):\n        """"""\n        Computes the full plan and returns the next command,\n        Args\n            source: source position\n            source_ori: source orientation\n            target: target position\n            target_ori: target orientation\n        Returns\n            a command ( Straight,Lane Follow, Left or Right)\n        """"""\n\n        track_source = self._city_track.project_node(source)\n        track_target = self._city_track.project_node(target)\n\n        # reach the goal\n\n        if self._city_track.is_at_goal(track_source, track_target):\n            return REACH_GOAL\n\n        if (self._city_track.is_at_new_node(track_source)\n                and self._city_track.is_away_from_intersection(track_source)):\n\n            route = self._city_track.compute_route(track_source, source_ori,\n                                                   track_target, target_ori)\n            if route is None:\n                raise RuntimeError(\'Impossible to find route\')\n\n            self._commands = self._route_to_commands(route)\n\n            if self._city_track.is_far_away_from_route_intersection(\n                    track_source):\n                return LANE_FOLLOW\n            else:\n                if self._commands:\n                    return self._commands[0]\n                else:\n                    return LANE_FOLLOW\n        else:\n\n            if self._city_track.is_far_away_from_route_intersection(\n                    track_source):\n                return LANE_FOLLOW\n\n            # If there is computed commands\n            if self._commands:\n                return self._commands[0]\n            else:\n                return LANE_FOLLOW\n\n    def get_shortest_path_distance(\n            self,\n            source,\n            source_ori,\n            target,\n            target_ori):\n\n        distance = 0\n        track_source = self._city_track.project_node(source)\n        track_target = self._city_track.project_node(target)\n\n        current_pos = track_source\n\n        route = self._city_track.compute_route(track_source, source_ori,\n                                               track_target, target_ori)\n        # No Route, distance is zero\n        if route is None:\n            return 0.0\n\n        for node_iter in route:\n            distance += sldist(node_iter, current_pos)\n            current_pos = node_iter\n\n        # We multiply by these values to convert distance to world coordinates\n        return distance * self._city_track.get_pixel_density() \\\n               * self._city_track.get_node_density()\n\n    def is_there_posible_route(self, source, source_ori, target, target_ori):\n\n        track_source = self._city_track.project_node(source)\n        track_target = self._city_track.project_node(target)\n\n        return not self._city_track.compute_route(\n            track_source, source_ori, track_target, target_ori) is None\n\n    def test_position(self, source):\n\n        node_source = self._city_track.project_node(source)\n\n        return self._city_track.is_away_from_intersection(node_source)\n\n    def _route_to_commands(self, route):\n\n        """"""\n        from the shortest path graph, transform it into a list of commands\n\n        :param route: the sub graph containing the shortest path\n        :return: list of commands encoded from 0-5\n        """"""\n\n        commands_list = []\n\n        for i in range(0, len(route)):\n            if route[i] not in self._city_track.get_intersection_nodes():\n                continue\n\n            current = route[i]\n            past = route[i - 1]\n            future = route[i + 1]\n\n            past_to_current = np.array(\n                [current[0] - past[0], current[1] - past[1]])\n            current_to_future = np.array(\n                [future[0] - current[0], future[1] - current[1]])\n            angle = signal(current_to_future, past_to_current)\n\n            if angle < -0.1:\n                command = TURN_RIGHT\n            elif angle > 0.1:\n                command = TURN_LEFT\n            else:\n                command = GO_STRAIGHT\n\n            commands_list.append(command)\n\n        return commands_list\n'"
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/experiment_suites/__init__.py,0,b'from .basic_experiment_suite import BasicExperimentSuite\nfrom .corl_2017 import CoRL2017\n'
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/experiment_suites/basic_experiment_suite.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n\nfrom __future__ import print_function\n\nfrom ..experiment import Experiment\nfrom ...sensor import Camera\nfrom ...settings import CarlaSettings\n\nfrom .experiment_suite import ExperimentSuite\n\n\nclass BasicExperimentSuite(ExperimentSuite):\n\n    @property\n    def train_weathers(self):\n        return [1]\n\n    @property\n    def test_weathers(self):\n        return [1]\n\n    def build_experiments(self):\n        """"""\n            Creates the whole set of experiment objects,\n            The experiments created depends on the selected Town.\n\n        """"""\n\n        # We check the town, based on that we define the town related parameters\n        # The size of the vector is related to the number of tasks, inside each\n        # task there is also multiple poses ( start end, positions )\n        if self._city_name == \'Town01\':\n            poses_tasks = [[[7, 3]], [[138, 17]], [[140, 134]], [[140, 134]]]\n            vehicles_tasks = [0, 0, 0, 20]\n            pedestrians_tasks = [0, 0, 0, 50]\n        else:\n            poses_tasks = [[[4, 2]], [[37, 76]], [[19, 66]], [[19, 66]]]\n            vehicles_tasks = [0, 0, 0, 15]\n            pedestrians_tasks = [0, 0, 0, 50]\n\n        # We set the camera\n        # This single RGB camera is used on every experiment\n\n        camera = Camera(\'CameraRGB\')\n        camera.set(FOV=100)\n        camera.set_image_size(800, 600)\n        camera.set_position(2.0, 0.0, 1.4)\n        camera.set_rotation(-15.0, 0, 0)\n\n        # Based on the parameters, creates a vector with experiment objects.\n        experiments_vector = []\n        for weather in self.weathers:\n\n            for iteration in range(len(poses_tasks)):\n                poses = poses_tasks[iteration]\n                vehicles = vehicles_tasks[iteration]\n                pedestrians = pedestrians_tasks[iteration]\n\n                conditions = CarlaSettings()\n                conditions.set(\n                    SendNonPlayerAgentsInfo=True,\n                    NumberOfVehicles=vehicles,\n                    NumberOfPedestrians=pedestrians,\n                    WeatherId=weather\n\n                )\n                # Add all the cameras that were set for this experiments\n                conditions.add_sensor(camera)\n                experiment = Experiment()\n                experiment.set(\n                    Conditions=conditions,\n                    Poses=poses,\n                    Task=iteration,\n                    Repetitions=1\n                )\n                experiments_vector.append(experiment)\n\n        return experiments_vector\n'"
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/experiment_suites/corl_2017.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n# CORL experiment set.\n\nfrom __future__ import print_function\n\nfrom ..experiment import Experiment\nfrom ...sensor import Camera\nfrom ...settings import CarlaSettings\nfrom .experiment_suite import ExperimentSuite\n\n\nclass CoRL2017(ExperimentSuite):\n\n    @property\n    def train_weathers(self):\n        return [1, 3, 6, 8]\n\n    @property\n    def test_weathers(self):\n        return [4, 14]\n\n    def _poses_town01(self):\n        """"""\n        Each matrix is a new task. We have all the four tasks\n\n        """"""\n\n        def _poses_straight():\n            return [[36, 40], [39, 35], [110, 114], [7, 3], [0, 4],\n                    [68, 50], [61, 59], [47, 64], [147, 90], [33, 87],\n                    [26, 19], [80, 76], [45, 49], [55, 44], [29, 107],\n                    [95, 104], [84, 34], [53, 67], [22, 17], [91, 148],\n                    [20, 107], [78, 70], [95, 102], [68, 44], [45, 69]]\n\n        def _poses_one_curve():\n            return [[138, 17], [47, 16], [26, 9], [42, 49], [140, 124],\n                    [85, 98], [65, 133], [137, 51], [76, 66], [46, 39],\n                    [40, 60], [0, 29], [4, 129], [121, 140], [2, 129],\n                    [78, 44], [68, 85], [41, 102], [95, 70], [68, 129],\n                    [84, 69], [47, 79], [110, 15], [130, 17], [0, 17]]\n\n        def _poses_navigation():\n            return [[105, 29], [27, 130], [102, 87], [132, 27], [24, 44],\n                    [96, 26], [34, 67], [28, 1], [140, 134], [105, 9],\n                    [148, 129], [65, 18], [21, 16], [147, 97], [42, 51],\n                    [30, 41], [18, 107], [69, 45], [102, 95], [18, 145],\n                    [111, 64], [79, 45], [84, 69], [73, 31], [37, 81]]\n\n        return [_poses_straight(),\n                _poses_one_curve(),\n                _poses_navigation(),\n                _poses_navigation()]\n\n    def _poses_town02(self):\n\n        def _poses_straight():\n            return [[38, 34], [4, 2], [12, 10], [62, 55], [43, 47],\n                    [64, 66], [78, 76], [59, 57], [61, 18], [35, 39],\n                    [12, 8], [0, 18], [75, 68], [54, 60], [45, 49],\n                    [46, 42], [53, 46], [80, 29], [65, 63], [0, 81],\n                    [54, 63], [51, 42], [16, 19], [17, 26], [77, 68]]\n\n        def _poses_one_curve():\n            return [[37, 76], [8, 24], [60, 69], [38, 10], [21, 1],\n                    [58, 71], [74, 32], [44, 0], [71, 16], [14, 24],\n                    [34, 11], [43, 14], [75, 16], [80, 21], [3, 23],\n                    [75, 59], [50, 47], [11, 19], [77, 34], [79, 25],\n                    [40, 63], [58, 76], [79, 55], [16, 61], [27, 11]]\n\n        def _poses_navigation():\n            return [[19, 66], [79, 14], [19, 57], [23, 1],\n                    [53, 76], [42, 13], [31, 71], [33, 5],\n                    [54, 30], [10, 61], [66, 3], [27, 12],\n                    [79, 19], [2, 29], [16, 14], [5, 57],\n                    [70, 73], [46, 67], [57, 50], [61, 49], [21, 12],\n                    [51, 81], [77, 68], [56, 65], [43, 54]]\n\n        return [_poses_straight(),\n                _poses_one_curve(),\n                _poses_navigation(),\n                _poses_navigation()\n                ]\n\n    def build_experiments(self):\n        """"""\n        Creates the whole set of experiment objects,\n        The experiments created depend on the selected Town.\n\n\n        """"""\n\n        # We set the camera\n        # This single RGB camera is used on every experiment\n\n        camera = Camera(\'CameraRGB\')\n        camera.set(FOV=100)\n        camera.set_image_size(800, 600)\n        camera.set_position(2.0, 0.0, 1.4)\n        camera.set_rotation(-15.0, 0, 0)\n\n        if self._city_name == \'Town01\':\n            poses_tasks = self._poses_town01()\n            vehicles_tasks = [0, 0, 0, 20]\n            pedestrians_tasks = [0, 0, 0, 50]\n        else:\n            poses_tasks = self._poses_town02()\n            vehicles_tasks = [0, 0, 0, 15]\n            pedestrians_tasks = [0, 0, 0, 50]\n\n        experiments_vector = []\n\n        for weather in self.weathers:\n\n            for iteration in range(len(poses_tasks)):\n                poses = poses_tasks[iteration]\n                vehicles = vehicles_tasks[iteration]\n                pedestrians = pedestrians_tasks[iteration]\n\n                conditions = CarlaSettings()\n                conditions.set(\n                    SendNonPlayerAgentsInfo=True,\n                    NumberOfVehicles=vehicles,\n                    NumberOfPedestrians=pedestrians,\n                    WeatherId=weather\n                )\n                # Add all the cameras that were set for this experiments\n\n                conditions.add_sensor(camera)\n\n                experiment = Experiment()\n                experiment.set(\n                    Conditions=conditions,\n                    Poses=poses,\n                    Task=iteration,\n                    Repetitions=1\n                )\n                experiments_vector.append(experiment)\n\n        return experiments_vector\n'"
ch7/carla-gym/carla_gym/envs/carla/driving_benchmark/experiment_suites/experiment_suite.py,0,"b'# To be redefined on subclasses on how to calculate timeout for an episode\nimport abc\n\n\nclass ExperimentSuite(object):\n\n    def __init__(self, city_name):\n\n        self._city_name = city_name\n        self._experiments = self.build_experiments()\n\n    def calculate_time_out(self, path_distance):\n        """"""\n        Function to return the timeout ,in milliseconds,\n        that is calculated based on distance to goal.\n        This is the same timeout as used on the CoRL paper.\n        """"""\n        return ((path_distance / 1000.0) / 10.0) * 3600.0 + 10.0\n\n    def get_number_of_poses_task(self):\n        """"""\n            Get the number of poses a task have for this benchmark\n        """"""\n\n        # Warning: assumes that all tasks have the same size\n\n        return len(self._experiments[0].poses)\n\n    def get_experiments(self):\n        """"""\n        Getter for the experiment set.\n        """"""\n        return self._experiments\n\n    @property\n    def dynamic_tasks(self):\n        """"""\n        Returns the episodes that contain dynamic obstacles\n        """"""\n        dynamic_tasks = set()\n        for exp in self._experiments:\n            if exp.conditions.NumberOfVehicles > 0 or exp.conditions.NumberOfPedestrians > 0:\n                dynamic_tasks.add(exp.task)\n\n        return list(dynamic_tasks)\n\n    @property\n    def metrics_parameters(self):\n        """"""\n        Property to return the parameters for the metric module\n        Could be redefined depending on the needs of the user.\n        """"""\n        return {\n\n            \'intersection_offroad\': {\'frames_skip\': 10,\n                                     \'frames_recount\': 20,\n                                     \'threshold\': 0.3\n                                     },\n            \'intersection_otherlane\': {\'frames_skip\': 10,\n                                       \'frames_recount\': 20,\n                                       \'threshold\': 0.4\n                                       },\n            \'collision_other\': {\'frames_skip\': 10,\n                                \'frames_recount\': 20,\n                                \'threshold\': 400\n                                },\n            \'collision_vehicles\': {\'frames_skip\': 10,\n                                   \'frames_recount\': 30,\n                                   \'threshold\': 400\n                                   },\n            \'collision_pedestrians\': {\'frames_skip\': 5,\n                                      \'frames_recount\': 100,\n                                      \'threshold\': 300\n                                      },\n\n        }\n\n    @property\n    def weathers(self):\n        weathers = set(self.train_weathers)\n        weathers.update(self.test_weathers)\n        return weathers\n\n    @abc.abstractmethod\n    def build_experiments(self):\n        """"""\n        Returns a set of experiments to be evaluated\n        Must be redefined in an inherited class.\n\n        """"""\n\n    @abc.abstractproperty\n    def train_weathers(self):\n        """"""\n        Return the weathers that are considered as training conditions\n        """"""\n\n    @abc.abstractproperty\n    def test_weathers(self):\n        """"""\n        Return the weathers that are considered as testing conditions\n        """"""\n'"
ch8/environment/carla_gym/envs/carla/driving_benchmark/experiment_suites/__init__.py,0,b'from .basic_experiment_suite import BasicExperimentSuite\nfrom .corl_2017 import CoRL2017\n'
ch8/environment/carla_gym/envs/carla/driving_benchmark/experiment_suites/basic_experiment_suite.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n\nfrom __future__ import print_function\n\nfrom ..experiment import Experiment\nfrom ...sensor import Camera\nfrom ...settings import CarlaSettings\n\nfrom .experiment_suite import ExperimentSuite\n\n\nclass BasicExperimentSuite(ExperimentSuite):\n\n    @property\n    def train_weathers(self):\n        return [1]\n\n    @property\n    def test_weathers(self):\n        return [1]\n\n    def build_experiments(self):\n        """"""\n            Creates the whole set of experiment objects,\n            The experiments created depends on the selected Town.\n\n        """"""\n\n        # We check the town, based on that we define the town related parameters\n        # The size of the vector is related to the number of tasks, inside each\n        # task there is also multiple poses ( start end, positions )\n        if self._city_name == \'Town01\':\n            poses_tasks = [[[7, 3]], [[138, 17]], [[140, 134]], [[140, 134]]]\n            vehicles_tasks = [0, 0, 0, 20]\n            pedestrians_tasks = [0, 0, 0, 50]\n        else:\n            poses_tasks = [[[4, 2]], [[37, 76]], [[19, 66]], [[19, 66]]]\n            vehicles_tasks = [0, 0, 0, 15]\n            pedestrians_tasks = [0, 0, 0, 50]\n\n        # We set the camera\n        # This single RGB camera is used on every experiment\n\n        camera = Camera(\'CameraRGB\')\n        camera.set(FOV=100)\n        camera.set_image_size(800, 600)\n        camera.set_position(2.0, 0.0, 1.4)\n        camera.set_rotation(-15.0, 0, 0)\n\n        # Based on the parameters, creates a vector with experiment objects.\n        experiments_vector = []\n        for weather in self.weathers:\n\n            for iteration in range(len(poses_tasks)):\n                poses = poses_tasks[iteration]\n                vehicles = vehicles_tasks[iteration]\n                pedestrians = pedestrians_tasks[iteration]\n\n                conditions = CarlaSettings()\n                conditions.set(\n                    SendNonPlayerAgentsInfo=True,\n                    NumberOfVehicles=vehicles,\n                    NumberOfPedestrians=pedestrians,\n                    WeatherId=weather\n\n                )\n                # Add all the cameras that were set for this experiments\n                conditions.add_sensor(camera)\n                experiment = Experiment()\n                experiment.set(\n                    Conditions=conditions,\n                    Poses=poses,\n                    Task=iteration,\n                    Repetitions=1\n                )\n                experiments_vector.append(experiment)\n\n        return experiments_vector\n'"
ch8/environment/carla_gym/envs/carla/driving_benchmark/experiment_suites/corl_2017.py,0,"b'# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de\n# Barcelona (UAB).\n#\n# This work is licensed under the terms of the MIT license.\n# For a copy, see <https://opensource.org/licenses/MIT>.\n\n# CORL experiment set.\n\nfrom __future__ import print_function\n\nfrom ..experiment import Experiment\nfrom ...sensor import Camera\nfrom ...settings import CarlaSettings\nfrom .experiment_suite import ExperimentSuite\n\n\nclass CoRL2017(ExperimentSuite):\n\n    @property\n    def train_weathers(self):\n        return [1, 3, 6, 8]\n\n    @property\n    def test_weathers(self):\n        return [4, 14]\n\n    def _poses_town01(self):\n        """"""\n        Each matrix is a new task. We have all the four tasks\n\n        """"""\n\n        def _poses_straight():\n            return [[36, 40], [39, 35], [110, 114], [7, 3], [0, 4],\n                    [68, 50], [61, 59], [47, 64], [147, 90], [33, 87],\n                    [26, 19], [80, 76], [45, 49], [55, 44], [29, 107],\n                    [95, 104], [84, 34], [53, 67], [22, 17], [91, 148],\n                    [20, 107], [78, 70], [95, 102], [68, 44], [45, 69]]\n\n        def _poses_one_curve():\n            return [[138, 17], [47, 16], [26, 9], [42, 49], [140, 124],\n                    [85, 98], [65, 133], [137, 51], [76, 66], [46, 39],\n                    [40, 60], [0, 29], [4, 129], [121, 140], [2, 129],\n                    [78, 44], [68, 85], [41, 102], [95, 70], [68, 129],\n                    [84, 69], [47, 79], [110, 15], [130, 17], [0, 17]]\n\n        def _poses_navigation():\n            return [[105, 29], [27, 130], [102, 87], [132, 27], [24, 44],\n                    [96, 26], [34, 67], [28, 1], [140, 134], [105, 9],\n                    [148, 129], [65, 18], [21, 16], [147, 97], [42, 51],\n                    [30, 41], [18, 107], [69, 45], [102, 95], [18, 145],\n                    [111, 64], [79, 45], [84, 69], [73, 31], [37, 81]]\n\n        return [_poses_straight(),\n                _poses_one_curve(),\n                _poses_navigation(),\n                _poses_navigation()]\n\n    def _poses_town02(self):\n\n        def _poses_straight():\n            return [[38, 34], [4, 2], [12, 10], [62, 55], [43, 47],\n                    [64, 66], [78, 76], [59, 57], [61, 18], [35, 39],\n                    [12, 8], [0, 18], [75, 68], [54, 60], [45, 49],\n                    [46, 42], [53, 46], [80, 29], [65, 63], [0, 81],\n                    [54, 63], [51, 42], [16, 19], [17, 26], [77, 68]]\n\n        def _poses_one_curve():\n            return [[37, 76], [8, 24], [60, 69], [38, 10], [21, 1],\n                    [58, 71], [74, 32], [44, 0], [71, 16], [14, 24],\n                    [34, 11], [43, 14], [75, 16], [80, 21], [3, 23],\n                    [75, 59], [50, 47], [11, 19], [77, 34], [79, 25],\n                    [40, 63], [58, 76], [79, 55], [16, 61], [27, 11]]\n\n        def _poses_navigation():\n            return [[19, 66], [79, 14], [19, 57], [23, 1],\n                    [53, 76], [42, 13], [31, 71], [33, 5],\n                    [54, 30], [10, 61], [66, 3], [27, 12],\n                    [79, 19], [2, 29], [16, 14], [5, 57],\n                    [70, 73], [46, 67], [57, 50], [61, 49], [21, 12],\n                    [51, 81], [77, 68], [56, 65], [43, 54]]\n\n        return [_poses_straight(),\n                _poses_one_curve(),\n                _poses_navigation(),\n                _poses_navigation()\n                ]\n\n    def build_experiments(self):\n        """"""\n        Creates the whole set of experiment objects,\n        The experiments created depend on the selected Town.\n\n\n        """"""\n\n        # We set the camera\n        # This single RGB camera is used on every experiment\n\n        camera = Camera(\'CameraRGB\')\n        camera.set(FOV=100)\n        camera.set_image_size(800, 600)\n        camera.set_position(2.0, 0.0, 1.4)\n        camera.set_rotation(-15.0, 0, 0)\n\n        if self._city_name == \'Town01\':\n            poses_tasks = self._poses_town01()\n            vehicles_tasks = [0, 0, 0, 20]\n            pedestrians_tasks = [0, 0, 0, 50]\n        else:\n            poses_tasks = self._poses_town02()\n            vehicles_tasks = [0, 0, 0, 15]\n            pedestrians_tasks = [0, 0, 0, 50]\n\n        experiments_vector = []\n\n        for weather in self.weathers:\n\n            for iteration in range(len(poses_tasks)):\n                poses = poses_tasks[iteration]\n                vehicles = vehicles_tasks[iteration]\n                pedestrians = pedestrians_tasks[iteration]\n\n                conditions = CarlaSettings()\n                conditions.set(\n                    SendNonPlayerAgentsInfo=True,\n                    NumberOfVehicles=vehicles,\n                    NumberOfPedestrians=pedestrians,\n                    WeatherId=weather\n                )\n                # Add all the cameras that were set for this experiments\n\n                conditions.add_sensor(camera)\n\n                experiment = Experiment()\n                experiment.set(\n                    Conditions=conditions,\n                    Poses=poses,\n                    Task=iteration,\n                    Repetitions=1\n                )\n                experiments_vector.append(experiment)\n\n        return experiments_vector\n'"
ch8/environment/carla_gym/envs/carla/driving_benchmark/experiment_suites/experiment_suite.py,0,"b'# To be redefined on subclasses on how to calculate timeout for an episode\nimport abc\n\n\nclass ExperimentSuite(object):\n\n    def __init__(self, city_name):\n\n        self._city_name = city_name\n        self._experiments = self.build_experiments()\n\n    def calculate_time_out(self, path_distance):\n        """"""\n        Function to return the timeout ,in milliseconds,\n        that is calculated based on distance to goal.\n        This is the same timeout as used on the CoRL paper.\n        """"""\n        return ((path_distance / 1000.0) / 10.0) * 3600.0 + 10.0\n\n    def get_number_of_poses_task(self):\n        """"""\n            Get the number of poses a task have for this benchmark\n        """"""\n\n        # Warning: assumes that all tasks have the same size\n\n        return len(self._experiments[0].poses)\n\n    def get_experiments(self):\n        """"""\n        Getter for the experiment set.\n        """"""\n        return self._experiments\n\n    @property\n    def dynamic_tasks(self):\n        """"""\n        Returns the episodes that contain dynamic obstacles\n        """"""\n        dynamic_tasks = set()\n        for exp in self._experiments:\n            if exp.conditions.NumberOfVehicles > 0 or exp.conditions.NumberOfPedestrians > 0:\n                dynamic_tasks.add(exp.task)\n\n        return list(dynamic_tasks)\n\n    @property\n    def metrics_parameters(self):\n        """"""\n        Property to return the parameters for the metric module\n        Could be redefined depending on the needs of the user.\n        """"""\n        return {\n\n            \'intersection_offroad\': {\'frames_skip\': 10,\n                                     \'frames_recount\': 20,\n                                     \'threshold\': 0.3\n                                     },\n            \'intersection_otherlane\': {\'frames_skip\': 10,\n                                       \'frames_recount\': 20,\n                                       \'threshold\': 0.4\n                                       },\n            \'collision_other\': {\'frames_skip\': 10,\n                                \'frames_recount\': 20,\n                                \'threshold\': 400\n                                },\n            \'collision_vehicles\': {\'frames_skip\': 10,\n                                   \'frames_recount\': 30,\n                                   \'threshold\': 400\n                                   },\n            \'collision_pedestrians\': {\'frames_skip\': 5,\n                                      \'frames_recount\': 100,\n                                      \'threshold\': 300\n                                      },\n\n        }\n\n    @property\n    def weathers(self):\n        weathers = set(self.train_weathers)\n        weathers.update(self.test_weathers)\n        return weathers\n\n    @abc.abstractmethod\n    def build_experiments(self):\n        """"""\n        Returns a set of experiments to be evaluated\n        Must be redefined in an inherited class.\n\n        """"""\n\n    @abc.abstractproperty\n    def train_weathers(self):\n        """"""\n        Return the weathers that are considered as training conditions\n        """"""\n\n    @abc.abstractproperty\n    def test_weathers(self):\n        """"""\n        Return the weathers that are considered as testing conditions\n        """"""\n'"
