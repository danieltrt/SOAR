file_path,api_count,code
constants.py,1,"b'import torch\n\ndevice = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")\n'"
custom_types.py,0,"b'import collections\nimport typing\n\nimport numpy as np\n\n\nclass TrainConfig(typing.NamedTuple):\n    T: int\n    train_size: int\n    batch_size: int\n    loss_func: typing.Callable\n\n\nclass TrainData(typing.NamedTuple):\n    feats: np.ndarray\n    targs: np.ndarray\n\n\nDaRnnNet = collections.namedtuple(""DaRnnNet"", [""encoder"", ""decoder"", ""enc_opt"", ""dec_opt""])\n'"
main.py,2,"b'import typing\nfrom typing import Tuple\nimport json\nimport os\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.externals import joblib\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nimport utils\nfrom modules import Encoder, Decoder\nfrom custom_types import DaRnnNet, TrainData, TrainConfig\nfrom utils import numpy_to_tvar\nfrom constants import device\n\nlogger = utils.setup_log()\nlogger.info(f""Using computation device: {device}"")\n\n\ndef preprocess_data(dat, col_names) -> Tuple[TrainData, StandardScaler]:\n    scale = StandardScaler().fit(dat)\n    proc_dat = scale.transform(dat)\n\n    mask = np.ones(proc_dat.shape[1], dtype=bool)\n    dat_cols = list(dat.columns)\n    for col_name in col_names:\n        mask[dat_cols.index(col_name)] = False\n\n    feats = proc_dat[:, mask]\n    targs = proc_dat[:, ~mask]\n\n    return TrainData(feats, targs), scale\n\n\ndef da_rnn(train_data: TrainData, n_targs: int, encoder_hidden_size=64, decoder_hidden_size=64,\n           T=10, learning_rate=0.01, batch_size=128):\n\n    train_cfg = TrainConfig(T, int(train_data.feats.shape[0] * 0.7), batch_size, nn.MSELoss())\n    logger.info(f""Training size: {train_cfg.train_size:d}."")\n\n    enc_kwargs = {""input_size"": train_data.feats.shape[1], ""hidden_size"": encoder_hidden_size, ""T"": T}\n    encoder = Encoder(**enc_kwargs).to(device)\n    with open(os.path.join(""data"", ""enc_kwargs.json""), ""w"") as fi:\n        json.dump(enc_kwargs, fi, indent=4)\n\n    dec_kwargs = {""encoder_hidden_size"": encoder_hidden_size,\n                  ""decoder_hidden_size"": decoder_hidden_size, ""T"": T, ""out_feats"": n_targs}\n    decoder = Decoder(**dec_kwargs).to(device)\n    with open(os.path.join(""data"", ""dec_kwargs.json""), ""w"") as fi:\n        json.dump(dec_kwargs, fi, indent=4)\n\n    encoder_optimizer = optim.Adam(\n        params=[p for p in encoder.parameters() if p.requires_grad],\n        lr=learning_rate)\n    decoder_optimizer = optim.Adam(\n        params=[p for p in decoder.parameters() if p.requires_grad],\n        lr=learning_rate)\n    da_rnn_net = DaRnnNet(encoder, decoder, encoder_optimizer, decoder_optimizer)\n\n    return train_cfg, da_rnn_net\n\n\ndef train(net: DaRnnNet, train_data: TrainData, t_cfg: TrainConfig, n_epochs=10, save_plots=False):\n    iter_per_epoch = int(np.ceil(t_cfg.train_size * 1. / t_cfg.batch_size))\n    iter_losses = np.zeros(n_epochs * iter_per_epoch)\n    epoch_losses = np.zeros(n_epochs)\n    logger.info(f""Iterations per epoch: {t_cfg.train_size * 1. / t_cfg.batch_size:3.3f} ~ {iter_per_epoch:d}."")\n\n    n_iter = 0\n\n    for e_i in range(n_epochs):\n        perm_idx = np.random.permutation(t_cfg.train_size - t_cfg.T)\n\n        for t_i in range(0, t_cfg.train_size, t_cfg.batch_size):\n            batch_idx = perm_idx[t_i:(t_i + t_cfg.batch_size)]\n            feats, y_history, y_target = prep_train_data(batch_idx, t_cfg, train_data)\n\n            loss = train_iteration(net, t_cfg.loss_func, feats, y_history, y_target)\n            iter_losses[e_i * iter_per_epoch + t_i // t_cfg.batch_size] = loss\n            # if (j / t_cfg.batch_size) % 50 == 0:\n            #    self.logger.info(""Epoch %d, Batch %d: loss = %3.3f."", i, j / t_cfg.batch_size, loss)\n            n_iter += 1\n\n            adjust_learning_rate(net, n_iter)\n\n        epoch_losses[e_i] = np.mean(iter_losses[range(e_i * iter_per_epoch, (e_i + 1) * iter_per_epoch)])\n\n        if e_i % 10 == 0:\n            y_test_pred = predict(net, train_data,\n                                  t_cfg.train_size, t_cfg.batch_size, t_cfg.T,\n                                  on_train=False)\n            # TODO: make this MSE and make it work for multiple inputs\n            val_loss = y_test_pred - train_data.targs[t_cfg.train_size:]\n            logger.info(f""Epoch {e_i:d}, train loss: {epoch_losses[e_i]:3.3f}, val loss: {np.mean(np.abs(val_loss))}."")\n            y_train_pred = predict(net, train_data,\n                                   t_cfg.train_size, t_cfg.batch_size, t_cfg.T,\n                                   on_train=True)\n            plt.figure()\n            plt.plot(range(1, 1 + len(train_data.targs)), train_data.targs,\n                     label=""True"")\n            plt.plot(range(t_cfg.T, len(y_train_pred) + t_cfg.T), y_train_pred,\n                     label=\'Predicted - Train\')\n            plt.plot(range(t_cfg.T + len(y_train_pred), len(train_data.targs) + 1), y_test_pred,\n                     label=\'Predicted - Test\')\n            plt.legend(loc=\'upper left\')\n            utils.save_or_show_plot(f""pred_{e_i}.png"", save_plots)\n\n    return iter_losses, epoch_losses\n\n\ndef prep_train_data(batch_idx: np.ndarray, t_cfg: TrainConfig, train_data: TrainData):\n    feats = np.zeros((len(batch_idx), t_cfg.T - 1, train_data.feats.shape[1]))\n    y_history = np.zeros((len(batch_idx), t_cfg.T - 1, train_data.targs.shape[1]))\n    y_target = train_data.targs[batch_idx + t_cfg.T]\n\n    for b_i, b_idx in enumerate(batch_idx):\n        b_slc = slice(b_idx, b_idx + t_cfg.T - 1)\n        feats[b_i, :, :] = train_data.feats[b_slc, :]\n        y_history[b_i, :] = train_data.targs[b_slc]\n\n    return feats, y_history, y_target\n\n\ndef adjust_learning_rate(net: DaRnnNet, n_iter: int):\n    # TODO: Where did this Learning Rate adjustment schedule come from?\n    # Should be modified to use Cosine Annealing with warm restarts https://www.jeremyjordan.me/nn-learning-rate/\n    if n_iter % 10000 == 0 and n_iter > 0:\n        for enc_params, dec_params in zip(net.enc_opt.param_groups, net.dec_opt.param_groups):\n            enc_params[\'lr\'] = enc_params[\'lr\'] * 0.9\n            dec_params[\'lr\'] = dec_params[\'lr\'] * 0.9\n\n\ndef train_iteration(t_net: DaRnnNet, loss_func: typing.Callable, X, y_history, y_target):\n    t_net.enc_opt.zero_grad()\n    t_net.dec_opt.zero_grad()\n\n    input_weighted, input_encoded = t_net.encoder(numpy_to_tvar(X))\n    y_pred = t_net.decoder(input_encoded, numpy_to_tvar(y_history))\n\n    y_true = numpy_to_tvar(y_target)\n    loss = loss_func(y_pred, y_true)\n    loss.backward()\n\n    t_net.enc_opt.step()\n    t_net.dec_opt.step()\n\n    return loss.item()\n\n\ndef predict(t_net: DaRnnNet, t_dat: TrainData, train_size: int, batch_size: int, T: int, on_train=False):\n    out_size = t_dat.targs.shape[1]\n    if on_train:\n        y_pred = np.zeros((train_size - T + 1, out_size))\n    else:\n        y_pred = np.zeros((t_dat.feats.shape[0] - train_size, out_size))\n\n    for y_i in range(0, len(y_pred), batch_size):\n        y_slc = slice(y_i, y_i + batch_size)\n        batch_idx = range(len(y_pred))[y_slc]\n        b_len = len(batch_idx)\n        X = np.zeros((b_len, T - 1, t_dat.feats.shape[1]))\n        y_history = np.zeros((b_len, T - 1, t_dat.targs.shape[1]))\n\n        for b_i, b_idx in enumerate(batch_idx):\n            if on_train:\n                idx = range(b_idx, b_idx + T - 1)\n            else:\n                idx = range(b_idx + train_size - T, b_idx + train_size - 1)\n\n            X[b_i, :, :] = t_dat.feats[idx, :]\n            y_history[b_i, :] = t_dat.targs[idx]\n\n        y_history = numpy_to_tvar(y_history)\n        _, input_encoded = t_net.encoder(numpy_to_tvar(X))\n        y_pred[y_slc] = t_net.decoder(input_encoded, y_history).cpu().data.numpy()\n\n    return y_pred\n\n\nsave_plots = True\ndebug = False\n\nraw_data = pd.read_csv(os.path.join(""data"", ""nasdaq100_padding.csv""), nrows=100 if debug else None)\nlogger.info(f""Shape of data: {raw_data.shape}.\\nMissing in data: {raw_data.isnull().sum().sum()}."")\ntarg_cols = (""NDX"",)\ndata, scaler = preprocess_data(raw_data, targ_cols)\n\nda_rnn_kwargs = {""batch_size"": 128, ""T"": 10}\nconfig, model = da_rnn(data, n_targs=len(targ_cols), learning_rate=.001, **da_rnn_kwargs)\niter_loss, epoch_loss = train(model, data, config, n_epochs=10, save_plots=save_plots)\nfinal_y_pred = predict(model, data, config.train_size, config.batch_size, config.T)\n\nplt.figure()\nplt.semilogy(range(len(iter_loss)), iter_loss)\nutils.save_or_show_plot(""iter_loss.png"", save_plots)\n\nplt.figure()\nplt.semilogy(range(len(epoch_loss)), epoch_loss)\nutils.save_or_show_plot(""epoch_loss.png"", save_plots)\n\nplt.figure()\nplt.plot(final_y_pred, label=\'Predicted\')\nplt.plot(data.targs[config.train_size:], label=""True"")\nplt.legend(loc=\'upper left\')\nutils.save_or_show_plot(""final_predicted.png"", save_plots)\n\nwith open(os.path.join(""data"", ""da_rnn_kwargs.json""), ""w"") as fi:\n    json.dump(da_rnn_kwargs, fi, indent=4)\n\njoblib.dump(scaler, os.path.join(""data"", ""scaler.pkl""))\ntorch.save(model.encoder.state_dict(), os.path.join(""data"", ""encoder.torch""))\ntorch.save(model.decoder.state_dict(), os.path.join(""data"", ""decoder.torch""))\n'"
main_predict.py,2,"b'import json\nimport os\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.externals import joblib\n\nfrom modules import Encoder, Decoder\nfrom utils import numpy_to_tvar\nimport utils\nfrom custom_types import TrainData\nfrom constants import device\n\n\ndef preprocess_data(dat, col_names, scale) -> TrainData:\n    proc_dat = scale.transform(dat)\n\n    mask = np.ones(proc_dat.shape[1], dtype=bool)\n    dat_cols = list(dat.columns)\n    for col_name in col_names:\n        mask[dat_cols.index(col_name)] = False\n\n    feats = proc_dat[:, mask]\n    targs = proc_dat[:, ~mask]\n\n    return TrainData(feats, targs)\n\n\ndef predict(encoder, decoder, t_dat, batch_size: int, T: int) -> np.ndarray:\n    y_pred = np.zeros((t_dat.feats.shape[0] - T + 1, t_dat.targs.shape[0]))\n\n    for y_i in range(0, len(y_pred), batch_size):\n        y_slc = slice(y_i, y_i + batch_size)\n        batch_idx = range(len(y_pred))[y_slc]\n        b_len = len(batch_idx)\n        X = np.zeros((b_len, T - 1, t_dat.feats.shape[1]))\n        y_history = np.zeros((b_len, T - 1, t_dat.targs.shape[0]))\n\n        for b_i, b_idx in enumerate(batch_idx):\n            idx = range(b_idx, b_idx + T - 1)\n\n            X[b_i, :, :] = t_dat.feats[idx, :]\n            y_history[b_i, :] = t_dat.targs[idx]\n\n        y_history = numpy_to_tvar(y_history)\n        _, input_encoded = encoder(numpy_to_tvar(X))\n        y_pred[y_slc] = decoder(input_encoded, y_history).cpu().data.numpy()\n\n    return y_pred\n\n\ndebug = False\nsave_plots = False\n\nwith open(os.path.join(""data"", ""enc_kwargs.json""), ""r"") as fi:\n    enc_kwargs = json.load(fi)\nenc = Encoder(**enc_kwargs)\nenc.load_state_dict(torch.load(os.path.join(""data"", ""encoder.torch""), map_location=device))\n\nwith open(os.path.join(""data"", ""dec_kwargs.json""), ""r"") as fi:\n    dec_kwargs = json.load(fi)\ndec = Decoder(**dec_kwargs)\ndec.load_state_dict(torch.load(os.path.join(""data"", ""decoder.torch""), map_location=device))\n\nscaler = joblib.load(os.path.join(""data"", ""scaler.pkl""))\nraw_data = pd.read_csv(os.path.join(""data"", ""nasdaq100_padding.csv""), nrows=100 if debug else None)\ntarg_cols = (""NDX"",)\ndata = preprocess_data(raw_data, targ_cols, scaler)\n\nwith open(os.path.join(""data"", ""da_rnn_kwargs.json""), ""r"") as fi:\n    da_rnn_kwargs = json.load(fi)\nfinal_y_pred = predict(enc, dec, data, **da_rnn_kwargs)\n\nplt.figure()\nplt.plot(final_y_pred, label=\'Predicted\')\nplt.plot(data.targs[(da_rnn_kwargs[""T""]-1):], label=""True"")\nplt.legend(loc=\'upper left\')\nutils.save_or_show_plot(""final_predicted_reloaded.png"", save_plots)\n'"
modules.py,13,"b'import torch\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.nn import functional as tf\n\n\ndef init_hidden(x, hidden_size: int):\n    """"""\n    Train the initial value of the hidden state:\n    https://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html\n    """"""\n    return Variable(torch.zeros(1, x.size(0), hidden_size))\n\n\nclass Encoder(nn.Module):\n\n    def __init__(self, input_size: int, hidden_size: int, T: int):\n        """"""\n        input size: number of underlying factors (81)\n        T: number of time steps (10)\n        hidden_size: dimension of the hidden state\n        """"""\n        super(Encoder, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.T = T\n\n        self.lstm_layer = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1)\n        self.attn_linear = nn.Linear(in_features=2 * hidden_size + T - 1, out_features=1)\n\n    def forward(self, input_data):\n        # input_data: (batch_size, T - 1, input_size)\n        input_weighted = Variable(torch.zeros(input_data.size(0), self.T - 1, self.input_size))\n        input_encoded = Variable(torch.zeros(input_data.size(0), self.T - 1, self.hidden_size))\n        # hidden, cell: initial states with dimension hidden_size\n        hidden = init_hidden(input_data, self.hidden_size)  # 1 * batch_size * hidden_size\n        cell = init_hidden(input_data, self.hidden_size)\n\n        for t in range(self.T - 1):\n            # Eqn. 8: concatenate the hidden states with each predictor\n            x = torch.cat((hidden.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n                           cell.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n                           input_data.permute(0, 2, 1)), dim=2)  # batch_size * input_size * (2*hidden_size + T - 1)\n            # Eqn. 8: Get attention weights\n            x = self.attn_linear(x.view(-1, self.hidden_size * 2 + self.T - 1))  # (batch_size * input_size) * 1\n            # Eqn. 9: Softmax the attention weights\n            attn_weights = tf.softmax(x.view(-1, self.input_size), dim=1)  # (batch_size, input_size)\n            # Eqn. 10: LSTM\n            weighted_input = torch.mul(attn_weights, input_data[:, t, :])  # (batch_size, input_size)\n            # Fix the warning about non-contiguous memory\n            # see https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282\n            self.lstm_layer.flatten_parameters()\n            _, lstm_states = self.lstm_layer(weighted_input.unsqueeze(0), (hidden, cell))\n            hidden = lstm_states[0]\n            cell = lstm_states[1]\n            # Save output\n            input_weighted[:, t, :] = weighted_input\n            input_encoded[:, t, :] = hidden\n\n        return input_weighted, input_encoded\n\n\nclass Decoder(nn.Module):\n\n    def __init__(self, encoder_hidden_size: int, decoder_hidden_size: int, T: int, out_feats=1):\n        super(Decoder, self).__init__()\n\n        self.T = T\n        self.encoder_hidden_size = encoder_hidden_size\n        self.decoder_hidden_size = decoder_hidden_size\n\n        self.attn_layer = nn.Sequential(nn.Linear(2 * decoder_hidden_size + encoder_hidden_size,\n                                                  encoder_hidden_size),\n                                        nn.Tanh(),\n                                        nn.Linear(encoder_hidden_size, 1))\n        self.lstm_layer = nn.LSTM(input_size=out_feats, hidden_size=decoder_hidden_size)\n        self.fc = nn.Linear(encoder_hidden_size + out_feats, out_feats)\n        self.fc_final = nn.Linear(decoder_hidden_size + encoder_hidden_size, out_feats)\n\n        self.fc.weight.data.normal_()\n\n    def forward(self, input_encoded, y_history):\n        # input_encoded: (batch_size, T - 1, encoder_hidden_size)\n        # y_history: (batch_size, (T-1))\n        # Initialize hidden and cell, (1, batch_size, decoder_hidden_size)\n        hidden = init_hidden(input_encoded, self.decoder_hidden_size)\n        cell = init_hidden(input_encoded, self.decoder_hidden_size)\n        context = Variable(torch.zeros(input_encoded.size(0), self.encoder_hidden_size))\n\n        for t in range(self.T - 1):\n            # (batch_size, T, (2 * decoder_hidden_size + encoder_hidden_size))\n            x = torch.cat((hidden.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n                           cell.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n                           input_encoded), dim=2)\n            # Eqn. 12 & 13: softmax on the computed attention weights\n            x = tf.softmax(\n                    self.attn_layer(\n                        x.view(-1, 2 * self.decoder_hidden_size + self.encoder_hidden_size)\n                    ).view(-1, self.T - 1),\n                    dim=1)  # (batch_size, T - 1)\n\n            # Eqn. 14: compute context vector\n            context = torch.bmm(x.unsqueeze(1), input_encoded)[:, 0, :]  # (batch_size, encoder_hidden_size)\n\n            # Eqn. 15\n            y_tilde = self.fc(torch.cat((context, y_history[:, t]), dim=1))  # (batch_size, out_size)\n            # Eqn. 16: LSTM\n            self.lstm_layer.flatten_parameters()\n            _, lstm_output = self.lstm_layer(y_tilde.unsqueeze(0), (hidden, cell))\n            hidden = lstm_output[0]  # 1 * batch_size * decoder_hidden_size\n            cell = lstm_output[1]  # 1 * batch_size * decoder_hidden_size\n\n        # Eqn. 22: final output\n        return self.fc_final(torch.cat((hidden[0], context), dim=1))\n'"
utils.py,2,"b'import logging\nimport os\n\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.autograd import Variable\n\nfrom constants import device\n\n\ndef setup_log(tag=\'VOC_TOPICS\'):\n    # create logger\n    logger = logging.getLogger(tag)\n    # logger.handlers = []\n    logger.propagate = False\n    logger.setLevel(logging.DEBUG)\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n    # create formatter\n    formatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\n    # add formatter to ch\n    ch.setFormatter(formatter)\n    # add ch to logger\n    # logger.handlers = []\n    logger.addHandler(ch)\n    return logger\n\n\ndef save_or_show_plot(file_nm: str, save: bool):\n    if save:\n        plt.savefig(os.path.join(os.path.dirname(__file__), ""plots"", file_nm))\n    else:\n        plt.show()\n\n\ndef numpy_to_tvar(x):\n    return Variable(torch.from_numpy(x).type(torch.FloatTensor).to(device))\n'"
