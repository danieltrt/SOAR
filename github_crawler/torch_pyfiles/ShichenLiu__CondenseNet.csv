file_path,api_count,code
__init__.py,0,b''
layers.py,15,"b'from __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\n\nclass LearnedGroupConv(nn.Module):\n    global_progress = 0.0\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n                 padding=0, dilation=1, groups=1, \n                 condense_factor=None, dropout_rate=0.):\n        super(LearnedGroupConv, self).__init__()\n        self.norm = nn.BatchNorm2d(in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropout_rate = dropout_rate\n        if self.dropout_rate > 0:\n            self.drop = nn.Dropout(dropout_rate, inplace=False)\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride,\n                              padding, dilation, groups=1, bias=False)\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.groups = groups\n        self.condense_factor = condense_factor\n        if self.condense_factor is None:\n            self.condense_factor = self.groups\n        ### Parameters that should be carefully used\n        self.register_buffer(\'_count\', torch.zeros(1))\n        self.register_buffer(\'_stage\', torch.zeros(1))\n        self.register_buffer(\'_mask\', torch.ones(self.conv.weight.size()))\n        ### Check if arguments are valid\n        assert self.in_channels % self.groups == 0, ""group number can not be divided by input channels""\n        assert self.in_channels % self.condense_factor == 0, ""condensation factor can not be divided by input channels""\n        assert self.out_channels % self.groups == 0, ""group number can not be divided by output channels""\n\n    def forward(self, x):\n        self._check_drop()\n        x = self.norm(x)\n        x = self.relu(x)\n        if self.dropout_rate > 0:\n            x = self.drop(x)\n        ### Masked output\n        weight = self.conv.weight * self.mask\n        return F.conv2d(x, weight, None, self.conv.stride,\n                        self.conv.padding, self.conv.dilation, 1)\n\n    def _check_drop(self):\n        progress = LearnedGroupConv.global_progress\n        delta = 0\n        ### Get current stage\n        for i in range(self.condense_factor - 1):\n            if progress * 2 < (i + 1) / (self.condense_factor - 1):\n                stage = i\n                break\n        else:\n            stage = self.condense_factor - 1\n        ### Check for dropping\n        if not self._reach_stage(stage):\n            self.stage = stage\n            delta = self.in_channels // self.condense_factor\n        if delta > 0:\n            self._dropping(delta)\n        return\n\n    def _dropping(self, delta):\n        weight = self.conv.weight * self.mask\n        ### Sum up all kernels\n        ### Assume only apply to 1x1 conv to speed up\n        assert weight.size()[-1] == 1\n        weight = weight.abs().squeeze()\n        assert weight.size()[0] == self.out_channels\n        assert weight.size()[1] == self.in_channels\n        d_out = self.out_channels // self.groups\n        ### Shuffle weight\n        weight = weight.view(d_out, self.groups, self.in_channels)\n        weight = weight.transpose(0, 1).contiguous()\n        weight = weight.view(self.out_channels, self.in_channels)\n        ### Sort and drop\n        for i in range(self.groups):\n            wi = weight[i * d_out:(i + 1) * d_out, :]\n            ### Take corresponding delta index\n            di = wi.sum(0).sort()[1][self.count:self.count + delta]\n            for d in di.data:\n                self._mask[i::self.groups, d, :, :].fill_(0)\n        self.count = self.count + delta\n\n    @property\n    def count(self):\n        return int(self._count[0])\n\n    @count.setter\n    def count(self, val):\n        self._count.fill_(val)\n\n    @property\n    def stage(self):\n        return int(self._stage[0])\n        \n    @stage.setter\n    def stage(self, val):\n        self._stage.fill_(val)\n\n    @property\n    def mask(self):\n        return Variable(self._mask)\n\n    def _reach_stage(self, stage):\n        return (self._stage >= stage).all()\n\n    @property\n    def lasso_loss(self):\n        if self._reach_stage(self.groups - 1):\n            return 0\n        weight = self.conv.weight * self.mask\n        ### Assume only apply to 1x1 conv to speed up\n        assert weight.size()[-1] == 1\n        weight = weight.squeeze().pow(2)\n        d_out = self.out_channels // self.groups\n        ### Shuffle weight\n        weight = weight.view(d_out, self.groups, self.in_channels)\n        weight = weight.sum(0).clamp(min=1e-6).sqrt()\n        return weight.sum()\n\n\ndef ShuffleLayer(x, groups):\n    batchsize, num_channels, height, width = x.data.size()\n    channels_per_group = num_channels // groups\n    ### reshape\n    x = x.view(batchsize, groups,\n               channels_per_group, height, width)\n    ### transpose\n    x = torch.transpose(x, 1, 2).contiguous()\n    ### flatten\n    x = x.view(batchsize, -1, height, width)\n    return x\n\n\nclass CondensingLinear(nn.Module):\n    def __init__(self, model, drop_rate=0.5):\n        super(CondensingLinear, self).__init__()\n        self.in_features = int(model.in_features*drop_rate)\n        self.out_features = model.out_features\n        self.linear = nn.Linear(self.in_features, self.out_features)\n        self.register_buffer(\'index\', torch.LongTensor(self.in_features))\n        _, index = model.weight.data.abs().sum(0).sort()\n        index = index[model.in_features-self.in_features:]\n        self.linear.bias.data = model.bias.data.clone()\n        for i in range(self.in_features):\n            self.index[i] = index[i]\n            self.linear.weight.data[:, i] = model.weight.data[:, index[i]]\n\n    def forward(self, x):\n        x = torch.index_select(x, 1, Variable(self.index))\n        x = self.linear(x)\n        return x\n\n\nclass CondensingConv(nn.Module):\n    def __init__(self, model):\n        super(CondensingConv, self).__init__()\n        self.in_channels = model.conv.in_channels \\\n                         * model.groups // model.condense_factor\n        self.out_channels = model.conv.out_channels\n        self.groups = model.groups\n        self.condense_factor = model.condense_factor\n        self.norm = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv = nn.Conv2d(self.in_channels, self.out_channels,\n                              kernel_size=model.conv.kernel_size,\n                              padding=model.conv.padding,\n                              groups=self.groups,\n                              bias=False,\n                              stride=model.conv.stride)\n        self.register_buffer(\'index\', torch.LongTensor(self.in_channels))\n        index = 0\n        mask = model._mask.mean(-1).mean(-1)\n        for i in range(self.groups):\n            for j in range(model.conv.in_channels):\n                if index < (self.in_channels // self.groups) * (i + 1) \\\n                         and mask[i, j] == 1:\n                    for k in range(self.out_channels // self.groups):\n                        idx_i = int(k + i * (self.out_channels // self.groups))\n                        idx_j = index % (self.in_channels // self.groups)\n                        self.conv.weight.data[idx_i, idx_j, :, :] = \\\n                            model.conv.weight.data[int(i + k * self.groups), j, :, :]\n                        self.norm.weight.data[index] = model.norm.weight.data[j]\n                        self.norm.bias.data[index] = model.norm.bias.data[j]\n                        self.norm.running_mean[index] = model.norm.running_mean[j]\n                        self.norm.running_var[index] = model.norm.running_var[j]\n                    self.index[index] = j\n                    index += 1\n\n    def forward(self, x):\n        x = torch.index_select(x, 1, Variable(self.index))\n        x = self.norm(x)\n        x = self.relu(x)\n        x = self.conv(x)\n        x = ShuffleLayer(x, self.groups)\n        return x\n\n\nclass CondenseLinear(nn.Module):\n    def __init__(self, in_features, out_features, drop_rate=0.5):\n        super(CondenseLinear, self).__init__()\n        self.in_features = int(in_features*drop_rate)\n        self.out_features = out_features\n        self.linear = nn.Linear(self.in_features, self.out_features)\n        self.register_buffer(\'index\', torch.LongTensor(self.in_features))\n\n    def forward(self, x):\n        x = torch.index_select(x, 1, Variable(self.index))\n        x = self.linear(x)\n        return x\n\n\nclass CondenseConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, \n                 stride=1, padding=0, groups=1):\n        super(CondenseConv, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.groups = groups\n        self.norm = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv = nn.Conv2d(self.in_channels, self.out_channels,\n                              kernel_size=kernel_size,\n                              stride=stride,\n                              padding=padding,\n                              groups=self.groups,\n                              bias=False)\n        self.register_buffer(\'index\', torch.LongTensor(self.in_channels))\n        self.index.fill_(0)\n\n    def forward(self, x):\n        x = torch.index_select(x, 1, Variable(self.index))\n        x = self.norm(x)\n        x = self.relu(x)\n        x = self.conv(x)\n        x = ShuffleLayer(x, self.groups)\n        return x\n\n\nclass Conv(nn.Sequential):\n    def __init__(self, in_channels, out_channels, kernel_size, \n                 stride=1, padding=0, groups=1):\n        super(Conv, self).__init__()\n        self.add_module(\'norm\', nn.BatchNorm2d(in_channels))\n        self.add_module(\'relu\', nn.ReLU(inplace=True))\n        self.add_module(\'conv\', nn.Conv2d(in_channels, out_channels,\n                                          kernel_size=kernel_size,\n                                          stride=stride,\n                                          padding=padding, bias=False,\n                                          groups=groups))\n'"
main.py,21,"b'from __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport argparse\nimport os\nimport shutil\nimport time\nimport math\nimport warnings\nimport models\nfrom utils import convert_model, measure_model\n\nparser = argparse.ArgumentParser(description=\'PyTorch Condensed Convolutional Networks\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--model\', default=\'condensenet\', type=str, metavar=\'M\',\n                    help=\'model to train the dataset\')\nparser.add_argument(\'-j\', \'--workers\', default=8, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=120, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate (default: 0.1)\')\nparser.add_argument(\'--lr-type\', default=\'cosine\', type=str, metavar=\'T\',\n                    help=\'learning rate strategy (default: cosine)\',\n                    choices=[\'cosine\', \'multistep\'])\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model (default: false)\')\nparser.add_argument(\'--no-save-model\', dest=\'no_save_model\', action=\'store_true\',\n                    help=\'only save best model (default: false)\')\nparser.add_argument(\'--manual-seed\', default=0, type=int, metavar=\'N\',\n                    help=\'manual seed (default: 0)\')\nparser.add_argument(\'--gpu\',\n                    help=\'gpu available\')\n\nparser.add_argument(\'--savedir\', type=str, metavar=\'PATH\', default=\'results/savedir\',\n                    help=\'path to save result and checkpoint (default: results/savedir)\')\nparser.add_argument(\'--resume\', action=\'store_true\',\n                    help=\'use latest checkpoint if have any (default: none)\')\n\nparser.add_argument(\'--stages\', type=str, metavar=\'STAGE DEPTH\',\n                    help=\'per layer depth\')\nparser.add_argument(\'--bottleneck\', default=4, type=int, metavar=\'B\',\n                    help=\'bottleneck (default: 4)\')\nparser.add_argument(\'--group-1x1\', type=int, metavar=\'G\', default=4,\n                    help=\'1x1 group convolution (default: 4)\')\nparser.add_argument(\'--group-3x3\', type=int, metavar=\'G\', default=4,\n                    help=\'3x3 group convolution (default: 4)\')\nparser.add_argument(\'--condense-factor\', type=int, metavar=\'C\', default=4,\n                    help=\'condense factor (default: 4)\')\nparser.add_argument(\'--growth\', type=str, metavar=\'GROWTH RATE\',\n                    help=\'per layer growth\')\nparser.add_argument(\'--reduction\', default=0.5, type=float, metavar=\'R\',\n                    help=\'transition reduction (default: 0.5)\')\nparser.add_argument(\'--dropout-rate\', default=0, type=float,\n                    help=\'drop out (default: 0)\')\nparser.add_argument(\'--group-lasso-lambda\', default=0., type=float, metavar=\'LASSO\',\n                    help=\'group lasso loss weight (default: 0)\')\n\nparser.add_argument(\'--evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set (default: false)\')\nparser.add_argument(\'--convert-from\', default=None, type=str, metavar=\'PATH\',\n                    help=\'path to saved checkpoint (default: none)\')\nparser.add_argument(\'--evaluate-from\', default=None, type=str, metavar=\'PATH\',\n                    help=\'path to saved checkpoint (default: none)\')\n\nargs = parser.parse_args()\nos.environ[""CUDA_VISIBLE_DEVICES""] = args.gpu\nargs.stages = list(map(int, args.stages.split(\'-\')))\nargs.growth = list(map(int, args.growth.split(\'-\')))\nif args.condense_factor is None:\n    args.condense_factor = args.group_1x1\n\nif args.data == \'cifar10\':\n    args.num_classes = 10\nelif args.data == \'cifar100\':\n    args.num_classes = 100\nelse:\n    args.num_classes = 1000\n\nwarnings.filterwarnings(""ignore"")\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\ntorch.manual_seed(args.manual_seed)\ntorch.cuda.manual_seed_all(args.manual_seed)\n\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n\n    ### Calculate FLOPs & Param\n    model = getattr(models, args.model)(args)\n    print(model)\n    if args.data in [\'cifar10\', \'cifar100\']:\n        IMAGE_SIZE = 32\n    else:\n        IMAGE_SIZE = 224\n    n_flops, n_params = measure_model(model, IMAGE_SIZE, IMAGE_SIZE)\n    print(\'FLOPs: %.2fM, Params: %.2fM\' % (n_flops / 1e6, n_params / 1e6))\n    args.filename = ""%s_%s_%s.txt"" % \\\n        (args.model, int(n_params), int(n_flops))\n    del(model)\n    print(args)\n\n    ### Create model\n    model = getattr(models, args.model)(args)\n\n    if args.model.startswith(\'alexnet\') or args.model.startswith(\'vgg\'):\n        model.features = torch.nn.DataParallel(model.features)\n        model.cuda()\n    else:\n        model = torch.nn.DataParallel(model).cuda()\n\n    ### Define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay,\n                                nesterov=True)\n\n    ### Optionally resume from a checkpoint\n    if args.resume:\n        checkpoint = load_checkpoint(args)\n        if checkpoint is not None:\n            args.start_epoch = checkpoint[\'epoch\'] + 1\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n\n    ### Optionally convert from a model\n    if args.convert_from is not None:\n        args.evaluate = True\n        state_dict = torch.load(args.convert_from)[\'state_dict\']\n        model.load_state_dict(state_dict)\n        model = model.cpu().module\n        convert_model(model, args)\n        model = nn.DataParallel(model).cuda()\n        head, tail = os.path.split(args.convert_from)\n        tail = ""converted_"" + tail\n        torch.save({\'state_dict\': model.state_dict()}, os.path.join(head, tail))\n\n    ### Optionally evaluate from a model\n    if args.evaluate_from is not None:\n        args.evaluate = True\n        state_dict = torch.load(args.evaluate_from)[\'state_dict\']\n        model.load_state_dict(state_dict)\n\n    cudnn.benchmark = True\n\n    ### Data loading \n    if args.data == ""cifar10"":\n        normalize = transforms.Normalize(mean=[0.4914, 0.4824, 0.4467],\n                                         std=[0.2471, 0.2435, 0.2616])\n        train_set = datasets.CIFAR10(\'../data\', train=True, download=True,\n                                     transform=transforms.Compose([\n                                         transforms.RandomCrop(32, padding=4),\n                                         transforms.RandomHorizontalFlip(),\n                                         transforms.ToTensor(),\n                                         normalize,\n                                     ]))\n        val_set = datasets.CIFAR10(\'../data\', train=False,\n                                   transform=transforms.Compose([\n                                       transforms.ToTensor(),\n                                       normalize,\n                                   ]))\n    elif args.data == ""cifar100"":\n        normalize = transforms.Normalize(mean=[0.5071, 0.4867, 0.4408],\n                                         std=[0.2675, 0.2565, 0.2761])\n        train_set = datasets.CIFAR100(\'../data\', train=True, download=True,\n                                     transform=transforms.Compose([\n                                         transforms.RandomCrop(32, padding=4),\n                                         transforms.RandomHorizontalFlip(),\n                                         transforms.ToTensor(),\n                                         normalize,\n                                     ]))\n        val_set = datasets.CIFAR100(\'../data\', train=False,\n                                   transform=transforms.Compose([\n                                       transforms.ToTensor(),\n                                       normalize,\n                                   ]))\n    else:\n        traindir = os.path.join(args.data, \'train\')\n        valdir = os.path.join(args.data, \'val\')\n        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                         std=[0.229, 0.224, 0.225])\n        train_set = datasets.ImageFolder(traindir, transforms.Compose([\n            transforms.RandomSizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n        val_set = datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Scale(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    train_loader = torch.utils.data.DataLoader(\n        train_set,\n        batch_size=args.batch_size, shuffle=True,\n        num_workers=args.workers, pin_memory=True)\n\n    val_loader = torch.utils.data.DataLoader(\n        val_set,\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        ### Train for one epoch\n        tr_prec1, tr_prec5, loss, lr = \\\n            train(train_loader, model, criterion, optimizer, epoch)\n\n        ### Evaluate on validation set\n        val_prec1, val_prec5 = validate(val_loader, model, criterion)\n\n        ### Remember best prec@1 and save checkpoint\n        is_best = val_prec1 < best_prec1\n        best_prec1 = max(val_prec1, best_prec1)\n        model_filename = \'checkpoint_%03d.pth.tar\' % epoch\n        save_checkpoint({\n            \'epoch\': epoch,\n            \'model\': args.model,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\': optimizer.state_dict(),\n        }, args, is_best, model_filename, ""%.4f %.4f %.4f %.4f %.4f %.4f\\n"" %\n            (val_prec1, val_prec5, tr_prec1, tr_prec5, loss, lr))\n\n    ### Convert model and test\n    model = model.cpu().module\n    convert_model(model, args)\n    model = nn.DataParallel(model).cuda()\n    print(model)\n    validate(val_loader, model, criterion)\n    n_flops, n_params = measure_model(model, IMAGE_SIZE, IMAGE_SIZE)\n    print(\'FLOPs: %.2fM, Params: %.2fM\' % (n_flops / 1e6, n_params / 1e6))\n    return\n\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    learned_module_list = []\n\n    ### Switch to train mode\n    model.train()\n    ### Find all learned convs to prepare for group lasso loss\n    for m in model.modules():\n        if m.__str__().startswith(\'LearnedGroupConv\'):\n            learned_module_list.append(m)\n    running_lr = None\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        progress = float(epoch * len(train_loader) + i) / \\\n            (args.epochs * len(train_loader))\n        args.progress = progress\n        ### Adjust learning rate\n        lr = adjust_learning_rate(optimizer, epoch, args, batch=i,\n                                  nBatch=len(train_loader), method=args.lr_type)\n        if running_lr is None:\n            running_lr = lr\n\n        ### Measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(non_blocking=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        ### Compute output\n        output = model(input_var, progress)\n        loss = criterion(output, target_var)\n\n        ### Add group lasso loss\n        if args.group_lasso_lambda > 0:\n            lasso_loss = 0\n            for m in learned_module_list:\n                lasso_loss = lasso_loss + m.lasso_loss\n            loss = loss + args.group_lasso_lambda * lasso_loss\n\n        ### Measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.item(), input.size(0))\n        top1.update(prec1.item(), input.size(0))\n        top5.update(prec5.item(), input.size(0))\n\n        ### Compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        ### Measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f}\\t\'  # ({batch_time.avg:.3f}) \'\n                  \'Data {data_time.val:.3f}\\t\'  # ({data_time.avg:.3f}) \'\n                  \'Loss {loss.val:.4f}\\t\'  # ({loss.avg:.4f}) \'\n                  \'Prec@1 {top1.val:.3f}\\t\'  # ({top1.avg:.3f}) \'\n                  \'Prec@5 {top5.val:.3f}\\t\'  # ({top5.avg:.3f})\'\n                  \'lr {lr: .4f}\'.format(\n                      epoch, i, len(train_loader), batch_time=batch_time,\n                      data_time=data_time, loss=losses, top1=top1, top5=top5, lr=lr))\n    return 100. - top1.avg, 100. - top5.avg, losses.avg, running_lr\n\n\ndef validate(val_loader, model, criterion):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    ### Switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(non_blocking=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        ### Compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        ### Measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data.item(), input.size(0))\n        top1.update(prec1.item(), input.size(0))\n        top5.update(prec5.item(), input.size(0))\n\n        ### Measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                      i, len(val_loader), batch_time=batch_time, loss=losses,\n                      top1=top1, top5=top5))\n\n    print(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}\'\n          .format(top1=top1, top5=top5))\n\n    return 100. - top1.avg, 100. - top5.avg\n\n\ndef load_checkpoint(args):\n    model_dir = os.path.join(args.savedir, \'save_models\')\n    latest_filename = os.path.join(model_dir, \'latest.txt\')\n    if os.path.exists(latest_filename):\n        with open(latest_filename, \'r\') as fin:\n            model_filename = fin.readlines()[0]\n    else:\n        return None\n    print(""=> loading checkpoint \'{}\'"".format(model_filename))\n    state = torch.load(model_filename)\n    print(""=> loaded checkpoint \'{}\'"".format(model_filename))\n    return state\n\n\ndef save_checkpoint(state, args, is_best, filename, result):\n    print(args)\n    result_filename = os.path.join(args.savedir, args.filename)\n    model_dir = os.path.join(args.savedir, \'save_models\')\n    model_filename = os.path.join(model_dir, filename)\n    latest_filename = os.path.join(model_dir, \'latest.txt\')\n    best_filename = os.path.join(model_dir, \'model_best.pth.tar\')\n    os.makedirs(args.savedir, exist_ok=True)\n    os.makedirs(model_dir, exist_ok=True)\n    print(""=> saving checkpoint \'{}\'"".format(model_filename))\n    with open(result_filename, \'a\') as fout:\n        fout.write(result)\n    torch.save(state, model_filename)\n    with open(latest_filename, \'w\') as fout:\n        fout.write(model_filename)\n    if args.no_save_model:\n        shutil.move(model_filename, best_filename)\n    elif is_best:\n        shutil.copyfile(model_filename, best_filename)\n\n    print(""=> saved checkpoint \'{}\'"".format(model_filename))\n    return\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef adjust_learning_rate(optimizer, epoch, args, batch=None,\n                         nBatch=None, method=\'cosine\'):\n    if method == \'cosine\':\n        T_total = args.epochs * nBatch\n        T_cur = (epoch % args.epochs) * nBatch + batch\n        lr = 0.5 * args.lr * (1 + math.cos(math.pi * T_cur / T_total))\n    elif method == \'multistep\':\n        if args.data in [\'cifar10\', \'cifar100\']:\n            lr, decay_rate = args.lr, 0.1\n            if epoch >= args.epochs * 0.75:\n                lr *= decay_rate**2\n            elif epoch >= args.epochs * 0.5:\n                lr *= decay_rate\n        else:\n            """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n            lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nif __name__ == \'__main__\':\n    main()\n'"
utils.py,3,"b""from __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\nimport operator\nfrom layers import LearnedGroupConv, CondensingLinear, CondensingConv, Conv\n\n\ncount_ops = 0\ncount_params = 0\n\n\ndef get_num_gen(gen):\n    return sum(1 for x in gen)\n\n\ndef is_pruned(layer):\n    try:\n        layer.mask\n        return True\n    except AttributeError:\n        return False\n\n\ndef is_leaf(model):\n    return get_num_gen(model.children()) == 0\n\n\ndef convert_model(model, args):\n    for m in model._modules:\n        child = model._modules[m]\n        if is_leaf(child):\n            if isinstance(child, nn.Linear):\n                model._modules[m] = CondensingLinear(child, 0.5)\n                del(child)\n        elif is_pruned(child):\n            model._modules[m] = CondensingConv(child)\n            del(child)\n        else:\n            convert_model(child, args)\n\n\ndef get_layer_info(layer):\n    layer_str = str(layer)\n    type_name = layer_str[:layer_str.find('(')].strip()\n    return type_name\n\n\ndef get_layer_param(model):\n    return sum([reduce(operator.mul, i.size(), 1) for i in model.parameters()])\n\n\n### The input batch size should be 1 to call this function\ndef measure_layer(layer, x):\n    global count_ops, count_params\n    delta_ops = 0\n    delta_params = 0\n    multi_add = 1\n    type_name = get_layer_info(layer)\n\n    ### ops_conv\n    if type_name in ['Conv2d']:\n        out_h = int((x.size()[2] + 2 * layer.padding[0] - layer.kernel_size[0]) /\n                    layer.stride[0] + 1)\n        out_w = int((x.size()[3] + 2 * layer.padding[1] - layer.kernel_size[1]) /\n                    layer.stride[1] + 1)\n        delta_ops = layer.in_channels * layer.out_channels * layer.kernel_size[0] *  \\\n                layer.kernel_size[1] * out_h * out_w / layer.groups * multi_add\n        delta_params = get_layer_param(layer)\n\n    ### ops_learned_conv\n    elif type_name in ['LearnedGroupConv']:\n        measure_layer(layer.relu, x)\n        measure_layer(layer.norm, x)\n        conv = layer.conv\n        out_h = int((x.size()[2] + 2 * conv.padding[0] - conv.kernel_size[0]) /\n                    conv.stride[0] + 1)\n        out_w = int((x.size()[3] + 2 * conv.padding[1] - conv.kernel_size[1]) /\n                    conv.stride[1] + 1)\n        delta_ops = conv.in_channels * conv.out_channels * conv.kernel_size[0] * \\\n                conv.kernel_size[1] * out_h * out_w / layer.condense_factor * multi_add\n        delta_params = get_layer_param(conv) / layer.condense_factor\n\n    ### ops_nonlinearity\n    elif type_name in ['ReLU']:\n        delta_ops = x.numel()\n        delta_params = get_layer_param(layer)\n\n    ### ops_pooling\n    elif type_name in ['AvgPool2d']:\n        in_w = x.size()[2]\n        kernel_ops = layer.kernel_size * layer.kernel_size\n        out_w = int((in_w + 2 * layer.padding - layer.kernel_size) / layer.stride + 1)\n        out_h = int((in_w + 2 * layer.padding - layer.kernel_size) / layer.stride + 1)\n        delta_ops = x.size()[0] * x.size()[1] * out_w * out_h * kernel_ops\n        delta_params = get_layer_param(layer)\n\n    elif type_name in ['AdaptiveAvgPool2d']:\n        delta_ops = x.size()[0] * x.size()[1] * x.size()[2] * x.size()[3]\n        delta_params = get_layer_param(layer)\n\n    ### ops_linear\n    elif type_name in ['Linear']:\n        weight_ops = layer.weight.numel() * multi_add\n        bias_ops = layer.bias.numel()\n        delta_ops = x.size()[0] * (weight_ops + bias_ops)\n        delta_params = get_layer_param(layer)\n\n    ### ops_nothing\n    elif type_name in ['BatchNorm2d', 'Dropout2d', 'DropChannel', 'Dropout']:\n        delta_params = get_layer_param(layer)\n\n    ### unknown layer type\n    else:\n        raise TypeError('unknown layer type: %s' % type_name)\n\n    count_ops += delta_ops\n    count_params += delta_params\n    return\n\n\ndef measure_model(model, H, W):\n    global count_ops, count_params\n    count_ops = 0\n    count_params = 0\n    data = Variable(torch.zeros(1, 3, H, W))\n\n    def should_measure(x):\n        return is_leaf(x) or is_pruned(x)\n\n    def modify_forward(model):\n        for child in model.children():\n            if should_measure(child):\n                def new_forward(m):\n                    def lambda_forward(x):\n                        measure_layer(m, x)\n                        return m.old_forward(x)\n                    return lambda_forward\n                child.old_forward = child.forward\n                child.forward = new_forward(child)\n            else:\n                modify_forward(child)\n\n    def restore_forward(model):\n        for child in model.children():\n            # leaf node\n            if is_leaf(child) and hasattr(child, 'old_forward'):\n                child.forward = child.old_forward\n                child.old_forward = None\n            else:\n                restore_forward(child)\n\n    modify_forward(model)\n    model.forward(data)\n    restore_forward(model)\n\n    return count_ops, count_params\n"""
models/__init__.py,0,b'from .densenet import DenseNet as densenet\nfrom .condensenet import CondenseNet as condensenet\nfrom .condensenet_converted import CondenseNet as condensenet_converted\nfrom .densenet_LGC import DenseNet_LGC as densenet_LGC\n'
models/condensenet.py,4,"b""from __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport math\nfrom layers import Conv, LearnedGroupConv\n\n__all__ = ['CondenseNet']\n\n\nclass _DenseLayer(nn.Module):\n    def __init__(self, in_channels, growth_rate, args):\n        super(_DenseLayer, self).__init__()\n        self.group_1x1 = args.group_1x1\n        self.group_3x3 = args.group_3x3\n        ### 1x1 conv i --> b*k\n        self.conv_1 = LearnedGroupConv(in_channels, args.bottleneck * growth_rate,\n                                       kernel_size=1, groups=self.group_1x1,\n                                       condense_factor=args.condense_factor,\n                                       dropout_rate=args.dropout_rate)\n        ### 3x3 conv b*k --> k\n        self.conv_2 = Conv(args.bottleneck * growth_rate, growth_rate,\n                           kernel_size=3, padding=1, groups=self.group_3x3)\n\n    def forward(self, x):\n        x_ = x\n        x = self.conv_1(x)\n        x = self.conv_2(x)\n        return torch.cat([x_, x], 1)\n\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, in_channels, growth_rate, args):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(in_channels + i * growth_rate, growth_rate, args)\n            self.add_module('denselayer_%d' % (i + 1), layer)\n\n\nclass _Transition(nn.Module):\n    def __init__(self, in_channels, args):\n        super(_Transition, self).__init__()\n        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = self.pool(x)\n        return x\n\n\nclass CondenseNet(nn.Module):\n    def __init__(self, args):\n\n        super(CondenseNet, self).__init__()\n\n        self.stages = args.stages\n        self.growth = args.growth\n        assert len(self.stages) == len(self.growth)\n        self.args = args\n        self.progress = 0.0\n        if args.data in ['cifar10', 'cifar100']:\n            self.init_stride = 1\n            self.pool_size = 8\n        else:\n            self.init_stride = 2\n            self.pool_size = 7\n\n        self.features = nn.Sequential()\n        ### Initial nChannels should be 3\n        self.num_features = 2 * self.growth[0]\n        ### Dense-block 1 (224x224)\n        self.features.add_module('init_conv', nn.Conv2d(3, self.num_features,\n                                                        kernel_size=3,\n                                                        stride=self.init_stride,\n                                                        padding=1,\n                                                        bias=False))\n        for i in range(len(self.stages)):\n            ### Dense-block i\n            self.add_block(i)\n        ### Linear layer\n        self.classifier = nn.Linear(self.num_features, args.num_classes)\n\n        ### initialize\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n        return\n\n    def add_block(self, i):\n        ### Check if ith is the last one\n        last = (i == len(self.stages) - 1)\n        block = _DenseBlock(\n            num_layers=self.stages[i],\n            in_channels=self.num_features,\n            growth_rate=self.growth[i],\n            args=self.args,\n        )\n        self.features.add_module('denseblock_%d' % (i + 1), block)\n        self.num_features += self.stages[i] * self.growth[i]\n        if not last:\n            trans = _Transition(in_channels=self.num_features,\n                                args=self.args)\n            self.features.add_module('transition_%d' % (i + 1), trans)\n        else:\n            self.features.add_module('norm_last',\n                                     nn.BatchNorm2d(self.num_features))\n            self.features.add_module('relu_last',\n                                     nn.ReLU(inplace=True))\n            self.features.add_module('pool_last',\n                                     nn.AvgPool2d(self.pool_size))\n\n    def forward(self, x, progress=None):\n        if progress:\n            LearnedGroupConv.global_progress = progress\n        features = self.features(x)\n        out = features.view(features.size(0), -1)\n        out = self.classifier(out)\n        return out\n"""
models/condensenet_converted.py,3,"b""from __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport math\nfrom layers import ShuffleLayer, Conv, CondenseConv, CondenseLinear\n\n__all__ = ['CondenseNet']\n\nclass _DenseLayer(nn.Module):\n    def __init__(self, in_channels, growth_rate, args):\n        super(_DenseLayer, self).__init__()\n        self.group_1x1 = args.group_1x1\n        self.group_3x3 = args.group_3x3\n        ### 1x1 conv i --> b*k\n        self.conv_1 = CondenseConv(in_channels, args.bottleneck * growth_rate,\n                                   kernel_size=1, groups=self.group_1x1)\n        ### 3x3 conv b*k-->k\n        self.conv_2 = Conv(args.bottleneck * growth_rate, growth_rate,\n                           kernel_size=3, padding=1, groups=self.group_3x3)\n\n    def forward(self, x):\n        x_ = x\n        x = self.conv_1(x)\n        x = self.conv_2(x)\n        return torch.cat([x_, x], 1)\n\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, in_channels, growth_rate, args):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(in_channels + i * growth_rate, growth_rate, args)\n            self.add_module('denselayer_%d' % (i + 1), layer)\n\n\nclass _Transition(nn.Module):\n    def __init__(self, in_channels, args):\n        super(_Transition, self).__init__()\n        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = self.pool(x)\n        return x\n\n\nclass CondenseNet(nn.Module):\n    def __init__(self, args):\n\n        super(CondenseNet, self).__init__()\n\n        self.stages = args.stages\n        self.growth = args.growth\n        assert len(self.stages) == len(self.growth)\n        self.args = args\n        self.progress = 0.0\n        if args.data in ['cifar10', 'cifar100']:\n            self.init_stride = 1\n            self.pool_size = 8\n        else:\n            self.init_stride = 2\n            self.pool_size = 7\n\n        self.features = nn.Sequential()\n        ### Initial nChannels should be 3\n        self.num_features = 2 * self.growth[0]\n        ### Dense-block 1 (224x224)\n        self.features.add_module('init_conv', nn.Conv2d(3, self.num_features,\n                                                        kernel_size=3,\n                                                        stride=self.init_stride,\n                                                        padding=1,\n                                                        bias=False))\n        for i in range(len(self.stages)):\n            ### Dense-block i\n            self.add_block(i)\n        ### Linear layer\n        self.classifier = CondenseLinear(self.num_features, args.num_classes,\n                                         0.5)\n        ### initialize\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def add_block(self, i):\n        ### Check if ith is the last one\n        last = (i == len(self.stages) - 1)\n        block = _DenseBlock(\n            num_layers=self.stages[i],\n            in_channels=self.num_features,\n            growth_rate=self.growth[i],\n            args=self.args,\n        )\n        self.features.add_module('denseblock_%d' % (i + 1), block)\n        self.num_features += self.stages[i] * self.growth[i]\n        if not last:\n            trans = _Transition(in_channels=self.num_features,\n                                args=self.args)\n            self.features.add_module('transition_%d' % (i + 1), trans)\n        else:\n            self.features.add_module('norm_last',\n                                     nn.BatchNorm2d(self.num_features))\n            self.features.add_module('relu_last',\n                                     nn.ReLU(inplace=True))\n            self.features.add_module('pool_last',\n                                     nn.AvgPool2d(self.pool_size))\n\n    def forward(self, x, progress=None):\n        features = self.features(x)\n        out = features.view(features.size(0), -1)\n        out = self.classifier(out)\n        return out\n"""
models/densenet.py,4,"b""from __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport math\nfrom layers import Conv\n\n__all__ = ['DenseNet']\n\n\ndef make_divisible(x, y):\n    return int((x // y + 1) * y) if x % y else int(x)\n\n\nclass _DenseLayer(nn.Module):\n    def __init__(self, in_channels, growth_rate, args):\n        super(_DenseLayer, self).__init__()\n        self.group_1x1 = args.group_1x1\n        self.group_3x3 = args.group_3x3\n        ### 1x1 conv i --> b*k\n        self.conv_1 = Conv(in_channels, args.bottleneck * growth_rate,\n                           kernel_size=1, groups=self.group_1x1)\n        ### 3x3 conv b*k --> k\n        self.conv_2 = Conv(args.bottleneck * growth_rate, growth_rate,\n                           kernel_size=3, padding=1, groups=self.group_3x3)\n\n    def forward(self, x):\n        x_ = x\n        x = self.conv_1(x)\n        x = self.conv_2(x)\n        return torch.cat([x_, x], 1)\n\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, in_channels, growth_rate, args):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(in_channels + i * growth_rate, growth_rate, args)\n            self.add_module('denselayer_%d' % (i + 1), layer)\n\n\nclass _Transition(nn.Module):\n    def __init__(self, in_channels, out_channels, args):\n        super(_Transition, self).__init__()\n        self.conv = Conv(in_channels, out_channels,\n                         kernel_size=1, groups=args.group_1x1)\n        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.pool(x)\n        return x\n\n\nclass DenseNet(nn.Module):\n    def __init__(self, args):\n\n        super(DenseNet, self).__init__()\n\n        self.stages = args.stages\n        self.growth = args.growth\n        self.reduction = args.reduction\n        assert len(self.stages) == len(self.growth)\n        self.args = args\n        self.progress = 0.0\n        if args.data in ['cifar10', 'cifar100']:\n            self.init_stride = 1\n            self.pool_size = 8\n        else:\n            self.init_stride = 2\n            self.pool_size = 7\n\n        self.features = nn.Sequential()\n        ### Set initial width to 2 x growth_rate[0]\n        self.num_features = 2 * self.growth[0]\n        ### Dense-block 1 (224x224)\n        self.features.add_module('init_conv', nn.Conv2d(3, self.num_features,\n                                                        kernel_size=3,\n                                                        stride=self.init_stride,\n                                                        padding=1,\n                                                        bias=False))\n        for i in range(len(self.stages)):\n            ### Dense-block i\n            self.add_block(i)\n        ### Linear layer\n        self.classifier = nn.Linear(self.num_features, args.num_classes)\n\n        ### initialize\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def add_block(self, i):\n        ### Check if ith is the last one\n        last = (i == len(self.stages) - 1)\n        block = _DenseBlock(\n            num_layers=self.stages[i],\n            in_channels=self.num_features,\n            growth_rate=self.growth[i],\n            args=self.args\n        )\n        self.features.add_module('denseblock_%d' % (i + 1), block)\n        self.num_features += self.stages[i] * self.growth[i]\n        if not last:\n            out_features = make_divisible(math.ceil(self.num_features * self.reduction),\n                                          self.args.group_1x1)\n            trans = _Transition(in_channels=self.num_features,\n                                out_channels=out_features,\n                                args=self.args)\n            self.features.add_module('transition_%d' % (i + 1), trans)\n            self.num_features = out_features\n        else:\n            self.features.add_module('norm_last',\n                                     nn.BatchNorm2d(self.num_features))\n            self.features.add_module('relu_last',\n                                     nn.ReLU(inplace=True))\n            ### Use adaptive ave pool as global pool\n            self.features.add_module('pool_last',\n                                     nn.AvgPool2d(self.pool_size))\n\n    def forward(self, x, progress=None):\n        features = self.features(x)\n        out = features.view(features.size(0), -1)\n        out = self.classifier(out)\n        return out\n"""
models/densenet_LGC.py,4,"b""from __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport math\nfrom layers import Conv, LearnedGroupConv\n\n\n__all__ = ['DenseNet_LGC']\n\n\ndef make_divisible(x, y):\n    return int((x // y + 1) * y if x % y else x)\n\n\nclass _DenseLayer(nn.Module):\n    def __init__(self, in_channels, growth_rate, args):\n        super(_DenseLayer, self).__init__()\n        self.group_1x1 = args.group_1x1\n        self.group_3x3 = args.group_3x3\n        ### 1x1 conv i --> b*k\n        self.conv_1 = LearnedGroupConv(in_channels, args.bottleneck * growth_rate,\n                                       kernel_size=1, groups=self.group_1x1,\n                                       condense_factor=args.condense_factor,\n                                       dropout_rate=args.dropout_rate)\n        ### 3x3 conv b*k-->k\n        self.conv_2 = Conv(args.bottleneck * growth_rate, growth_rate,\n                           kernel_size=3, padding=1, groups=self.group_3x3)\n\n    def forward(self, x):\n        x_ = x\n        x = self.conv_1(x)\n        x = self.conv_2(x)\n        return torch.cat([x_, x], 1)\n\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, in_channels, growth_rate, args):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(in_channels + i * growth_rate, growth_rate, args)\n            self.add_module('denselayer_%d' % (i + 1), layer)\n\n\nclass _Transition(nn.Module):\n    def __init__(self, in_channels, out_channels, args):\n        super(_Transition, self).__init__()\n        self.conv = LearnedGroupConv(in_channels, out_channels,\n                                     kernel_size=1, groups=args.group_1x1,\n                                     condense_factor=args.condense_factor)\n        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.pool(x)\n        return x\n\n\nclass DenseNet_LGC(nn.Module):\n    def __init__(self, args):\n\n        super(DenseNet_LGC, self).__init__()\n\n        self.stages = args.stages\n        self.growth = args.growth\n        self.reduction = args.reduction\n        assert len(self.stages) == len(self.growth)\n        self.args = args\n        self.progress = 0.0\n        if args.data in ['cifar10', 'cifar100']:\n            self.init_stride = 1\n            self.pool_size = 8\n        else:\n            self.init_stride = 2\n            self.pool_size = 7\n\n        self.features = nn.Sequential()\n        ### Set initial width to 2 x growth_rate[0]\n        self.num_features = 2 * self.growth[0]\n        ### Dense-block 1 (224x224)\n        self.features.add_module('init_conv', nn.Conv2d(3, self.num_features,\n                                                        kernel_size=3,\n                                                        stride=self.init_stride,\n                                                        padding=1,\n                                                        bias=False))\n        for i in range(len(self.stages)):\n            ### Dense-block i\n            self.add_block(i)\n        ### Linear layer\n        self.classifier = nn.Linear(self.num_features, args.num_classes)\n\n        ### initialize\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def add_block(self, i):\n        ### Check if ith is the last one\n        last = (i == len(self.stages) - 1)\n        block = _DenseBlock(\n            num_layers=self.stages[i],\n            in_channels=self.num_features,\n            growth_rate=self.growth[i],\n            args=self.args\n        )\n        self.features.add_module('denseblock_%d' % (i + 1), block)\n        self.num_features += self.stages[i] * self.growth[i]\n        if not last:\n            out_features = make_divisible(math.ceil(self.num_features * self.reduction),\n                                          self.args.group_1x1)\n            trans = _Transition(in_channels=self.num_features,\n                                out_channels=out_features,\n                                args=self.args)\n            self.features.add_module('transition_%d' % (i + 1), trans)\n            self.num_features = out_features\n        else:\n            self.features.add_module('norm_last',\n                                     nn.BatchNorm2d(self.num_features))\n            self.features.add_module('relu_last',\n                                     nn.ReLU(inplace=True))\n            ### Use adaptive ave pool as global pool\n            self.features.add_module('pool_last',\n                                     nn.AvgPool2d(self.pool_size))\n\n    def forward(self, x, progress=None):\n        if progress:\n            LearnedGroupConv.global_progress = progress\n        features = self.features(x)\n        out = features.view(features.size(0), -1)\n        out = self.classifier(out)\n        return out\n"""
