file_path,api_count,code
cfg.py,0,"b'# -*- coding: utf-8 -*-\n# @Date    : 2019-07-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nimport argparse\n\n\ndef str2bool(v):\n    if v.lower() in (\'yes\', \'true\', \'t\', \'y\', \'1\'):\n        return True\n    elif v.lower() in (\'no\', \'false\', \'f\', \'n\', \'0\'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError(\'Boolean value expected.\')\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--max_epoch\',\n        type=int,\n        default=200,\n        help=\'number of epochs of training\')\n    parser.add_argument(\n        \'--max_iter\',\n        type=int,\n        default=None,\n        help=\'set the max iteration number\')\n    parser.add_argument(\n        \'-gen_bs\',\n        \'--gen_batch_size\',\n        type=int,\n        default=64,\n        help=\'size of the batches\')\n    parser.add_argument(\n        \'-dis_bs\',\n        \'--dis_batch_size\',\n        type=int,\n        default=64,\n        help=\'size of the batches\')\n    parser.add_argument(\n        \'--g_lr\',\n        type=float,\n        default=0.0002,\n        help=\'adam: gen learning rate\')\n    parser.add_argument(\n        \'--d_lr\',\n        type=float,\n        default=0.0002,\n        help=\'adam: disc learning rate\')\n    parser.add_argument(\n        \'--ctrl_lr\',\n        type=float,\n        default=3.5e-4,\n        help=\'adam: ctrl learning rate\')\n    parser.add_argument(\n        \'--lr_decay\',\n        action=\'store_true\',\n        help=\'learning rate decay or not\')\n    parser.add_argument(\n        \'--beta1\',\n        type=float,\n        default=0.0,\n        help=\'adam: decay of first order momentum of gradient\')\n    parser.add_argument(\n        \'--beta2\',\n        type=float,\n        default=0.9,\n        help=\'adam: decay of first order momentum of gradient\')\n    parser.add_argument(\n        \'--num_workers\',\n        type=int,\n        default=8,\n        help=\'number of cpu threads to use during batch generation\')\n    parser.add_argument(\n        \'--latent_dim\',\n        type=int,\n        default=128,\n        help=\'dimensionality of the latent space\')\n    parser.add_argument(\n        \'--img_size\',\n        type=int,\n        default=32,\n        help=\'size of each image dimension\')\n    parser.add_argument(\n        \'--channels\',\n        type=int,\n        default=3,\n        help=\'number of image channels\')\n    parser.add_argument(\n        \'--n_critic\',\n        type=int,\n        default=1,\n        help=\'number of training steps for discriminator per iter\')\n    parser.add_argument(\n        \'--val_freq\',\n        type=int,\n        default=20,\n        help=\'interval between each validation\')\n    parser.add_argument(\n        \'--print_freq\',\n        type=int,\n        default=100,\n        help=\'interval between each verbose\')\n    parser.add_argument(\n        \'--load_path\',\n        type=str,\n        help=\'The reload model path\')\n    parser.add_argument(\n        \'--exp_name\',\n        type=str,\n        help=\'The name of exp\')\n    parser.add_argument(\n        \'--d_spectral_norm\',\n        type=str2bool,\n        default=False,\n        help=\'add spectral_norm on discriminator?\')\n    parser.add_argument(\n        \'--g_spectral_norm\',\n        type=str2bool,\n        default=False,\n        help=\'add spectral_norm on generator?\')\n    parser.add_argument(\n        \'--dataset\',\n        type=str,\n        default=\'cifar10\',\n        help=\'dataset type\')\n    parser.add_argument(\n        \'--data_path\',\n        type=str,\n        default=\'./data\',\n        help=\'The path of data set\')\n    parser.add_argument(\'--init_type\', type=str, default=\'normal\',\n                        choices=[\'normal\', \'orth\', \'xavier_uniform\', \'false\'],\n                        help=\'The init type\')\n    parser.add_argument(\'--gf_dim\', type=int, default=64,\n                        help=\'The base channel num of gen\')\n    parser.add_argument(\'--df_dim\', type=int, default=64,\n                        help=\'The base channel num of disc\')\n    parser.add_argument(\n        \'--gen_model\',\n        type=str,\n        default=\'shared_gan\',\n        help=\'path of gen model\')\n    parser.add_argument(\n        \'--dis_model\',\n        type=str,\n        default=\'shared_gan\',\n        help=\'path of dis model\')\n    parser.add_argument(\n        \'--controller\',\n        type=str,\n        default=\'controller\',\n        help=\'path of controller\')\n    parser.add_argument(\'--eval_batch_size\', type=int, default=100)\n    parser.add_argument(\'--num_eval_imgs\', type=int, default=50000)\n    parser.add_argument(\n        \'--bottom_width\',\n        type=int,\n        default=4,\n        help=""the base resolution of the GAN"")\n    parser.add_argument(\'--random_seed\', type=int, default=12345)\n\n    # search\n    parser.add_argument(\'--shared_epoch\', type=int, default=15,\n                        help=\'the number of epoch to train the shared gan at each search iteration\')\n    parser.add_argument(\'--grow_step1\', type=int, default=25,\n                        help=\'which iteration to grow the image size from 8 to 16\')\n    parser.add_argument(\'--grow_step2\', type=int, default=55,\n                        help=\'which iteration to grow the image size from 16 to 32\')\n    parser.add_argument(\'--max_search_iter\', type=int, default=90,\n                        help=\'max search iterations of this algorithm\')\n    parser.add_argument(\'--ctrl_step\', type=int, default=30,\n                        help=\'number of steps to train the controller at each search iteration\')\n    parser.add_argument(\'--ctrl_sample_batch\', type=int, default=1,\n                        help=\'sample size of controller of each step\')\n    parser.add_argument(\'--hid_size\', type=int, default=100,\n                        help=\'the size of hidden vector\')\n    parser.add_argument(\'--baseline_decay\', type=float, default=0.9,\n                        help=\'baseline decay rate in RL\')\n    parser.add_argument(\'--rl_num_eval_img\', type=int, default=5000,\n                        help=\'number of images to be sampled in order to get the reward\')\n    parser.add_argument(\'--num_candidate\', type=int, default=10,\n                        help=\'number of candidate architectures to be sampled\')\n    parser.add_argument(\'--topk\', type=int, default=5,\n                        help=\'preserve topk models architectures after each stage\' )\n    parser.add_argument(\'--entropy_coeff\', type=float, default=1e-3,\n                        help=\'to encourage the exploration\')\n    parser.add_argument(\'--dynamic_reset_threshold\', type=float, default=1e-3,\n                        help=\'var threshold\')\n    parser.add_argument(\'--dynamic_reset_window\', type=int, default=500,\n                        help=\'the window size\')\n    parser.add_argument(\'--arch\', nargs=\'+\', type=int,\n                        help=\'the vector of a discovered architecture\')\n\n    opt = parser.parse_args()\n\n    return opt\n'"
datasets.py,5,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-07-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nimport torch\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset\n\n\nclass ImageDataset(object):\n    def __init__(self, args, cur_img_size=None):\n        img_size = cur_img_size if cur_img_size else args.img_size\n        if args.dataset.lower() == 'cifar10':\n            Dt = datasets.CIFAR10\n            transform = transforms.Compose([\n                transforms.Resize(img_size),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n            ])\n            args.n_classes = 10\n        elif args.dataset.lower() == 'stl10':\n            Dt = datasets.STL10\n            transform = transforms.Compose([\n                transforms.Resize(img_size),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n            ])\n        else:\n            raise NotImplementedError('Unknown dataset: {}'.format(args.dataset))\n\n        if args.dataset.lower() == 'stl10':\n            self.train = torch.utils.data.DataLoader(\n                Dt(root=args.data_path, split='train+unlabeled', transform=transform, download=True),\n                batch_size=args.dis_batch_size, shuffle=True,\n                num_workers=args.num_workers, pin_memory=True)\n\n            self.valid = torch.utils.data.DataLoader(\n                Dt(root=args.data_path, split='test', transform=transform),\n                batch_size=args.dis_batch_size, shuffle=False,\n                num_workers=args.num_workers, pin_memory=True)\n\n            self.test = self.valid\n        else:\n            self.train = torch.utils.data.DataLoader(\n                Dt(root=args.data_path, train=True, transform=transform, download=True),\n                batch_size=args.dis_batch_size, shuffle=True,\n                num_workers=args.num_workers, pin_memory=True)\n\n            self.valid = torch.utils.data.DataLoader(\n                Dt(root=args.data_path, train=False, transform=transform),\n                batch_size=args.dis_batch_size, shuffle=False,\n                num_workers=args.num_workers, pin_memory=True)\n\n            self.test = self.valid\n"""
functions.py,18,"b'# -*- coding: utf-8 -*-\n# @Date    : 2019-07-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nimport logging\nimport operator\nimport os\nfrom copy import deepcopy\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom imageio import imsave\nfrom torchvision.utils import make_grid\nfrom tqdm import tqdm\n\nfrom utils.fid_score import calculate_fid_given_paths\nfrom utils.inception_score import get_inception_score\n\nlogger = logging.getLogger(__name__)\n\n\ndef train_shared(args, gen_net: nn.Module, dis_net: nn.Module, g_loss_history, d_loss_history, controller, gen_optimizer\n                 , dis_optimizer, train_loader, prev_hiddens=None, prev_archs=None):\n    dynamic_reset = False\n    logger.info(\'=> train shared GAN...\')\n    step = 0\n    gen_step = 0\n\n    # train mode\n    gen_net.train()\n    dis_net.train()\n\n    # eval mode\n    controller.eval()\n    for epoch in range(args.shared_epoch):\n        for iter_idx, (imgs, _) in enumerate(train_loader):\n\n            # sample an arch\n            arch = controller.sample(1, prev_hiddens=prev_hiddens, prev_archs=prev_archs)[0][0]\n            gen_net.set_arch(arch, controller.cur_stage)\n            dis_net.cur_stage = controller.cur_stage\n            # Adversarial ground truths\n            real_imgs = imgs.type(torch.cuda.FloatTensor)\n\n            # Sample noise as generator input\n            z = torch.cuda.FloatTensor(np.random.normal(0, 1, (imgs.shape[0], args.latent_dim)))\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n            dis_optimizer.zero_grad()\n\n            real_validity = dis_net(real_imgs)\n            fake_imgs = gen_net(z).detach()\n            assert fake_imgs.size() == real_imgs.size(), print(f\'fake image size is {fake_imgs.size()}, \'\n                                                               f\'while real image size is {real_imgs.size()}\')\n\n            fake_validity = dis_net(fake_imgs)\n\n            # cal loss\n            d_loss = torch.mean(nn.ReLU(inplace=True)(1.0 - real_validity)) + \\\n                     torch.mean(nn.ReLU(inplace=True)(1 + fake_validity))\n            d_loss.backward()\n            dis_optimizer.step()\n\n            # add to window\n            d_loss_history.push(d_loss.item())\n\n            # -----------------\n            #  Train Generator\n            # -----------------\n            if step % args.n_critic == 0:\n                gen_optimizer.zero_grad()\n\n                gen_z = torch.cuda.FloatTensor(np.random.normal(0, 1, (args.gen_batch_size, args.latent_dim)))\n                gen_imgs = gen_net(gen_z)\n                fake_validity = dis_net(gen_imgs)\n\n                # cal loss\n                g_loss = -torch.mean(fake_validity)\n                g_loss.backward()\n                gen_optimizer.step()\n\n                # add to window\n                g_loss_history.push(g_loss.item())\n                gen_step += 1\n\n            # verbose\n            if gen_step and iter_idx % args.print_freq == 0:\n                logger.info(\n                    ""[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"" %\n                    (epoch, args.shared_epoch, iter_idx % len(train_loader), len(train_loader), d_loss.item(),\n                     g_loss.item()))\n\n            # check window\n            if g_loss_history.is_full():\n                if g_loss_history.get_var() < args.dynamic_reset_threshold \\\n                        or d_loss_history.get_var() < args.dynamic_reset_threshold:\n                    dynamic_reset = True\n                    logger.info(""=> dynamic resetting triggered"")\n                    g_loss_history.clear()\n                    d_loss_history.clear()\n                    return dynamic_reset\n\n            step += 1\n\n    return dynamic_reset\n\n\ndef train(args, gen_net: nn.Module, dis_net: nn.Module, gen_optimizer, dis_optimizer, gen_avg_param, train_loader,\n          epoch, writer_dict, schedulers=None):\n    writer = writer_dict[\'writer\']\n    gen_step = 0\n\n    # train mode\n    gen_net = gen_net.train()\n    dis_net = dis_net.train()\n\n    for iter_idx, (imgs, _) in enumerate(tqdm(train_loader)):\n        global_steps = writer_dict[\'train_global_steps\']\n\n        # Adversarial ground truths\n        real_imgs = imgs.type(torch.cuda.FloatTensor)\n\n        # Sample noise as generator input\n        z = torch.cuda.FloatTensor(np.random.normal(0, 1, (imgs.shape[0], args.latent_dim)))\n\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n        dis_optimizer.zero_grad()\n\n        real_validity = dis_net(real_imgs)\n        fake_imgs = gen_net(z).detach()\n        assert fake_imgs.size() == real_imgs.size()\n\n        fake_validity = dis_net(fake_imgs)\n\n        # cal loss\n        d_loss = torch.mean(nn.ReLU(inplace=True)(1.0 - real_validity)) + \\\n                 torch.mean(nn.ReLU(inplace=True)(1 + fake_validity))\n        d_loss.backward()\n        dis_optimizer.step()\n\n        writer.add_scalar(\'d_loss\', d_loss.item(), global_steps)\n\n        # -----------------\n        #  Train Generator\n        # -----------------\n        if global_steps % args.n_critic == 0:\n            gen_optimizer.zero_grad()\n\n            gen_z = torch.cuda.FloatTensor(np.random.normal(0, 1, (args.gen_batch_size, args.latent_dim)))\n            gen_imgs = gen_net(gen_z)\n            fake_validity = dis_net(gen_imgs)\n\n            # cal loss\n            g_loss = -torch.mean(fake_validity)\n            g_loss.backward()\n            gen_optimizer.step()\n\n            # adjust learning rate\n            if schedulers:\n                gen_scheduler, dis_scheduler = schedulers\n                g_lr = gen_scheduler.step(global_steps)\n                d_lr = dis_scheduler.step(global_steps)\n                writer.add_scalar(\'LR/g_lr\', g_lr, global_steps)\n                writer.add_scalar(\'LR/d_lr\', d_lr, global_steps)\n\n            # moving average weight\n            for p, avg_p in zip(gen_net.parameters(), gen_avg_param):\n                avg_p.mul_(0.999).add_(0.001, p.data)\n\n            writer.add_scalar(\'g_loss\', g_loss.item(), global_steps)\n            gen_step += 1\n\n        # verbose\n        if gen_step and iter_idx % args.print_freq == 0:\n            tqdm.write(\n                ""[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"" %\n                (epoch, args.max_epoch, iter_idx % len(train_loader), len(train_loader), d_loss.item(), g_loss.item()))\n\n        writer_dict[\'train_global_steps\'] = global_steps + 1\n\n\ndef train_controller(args, controller, ctrl_optimizer, gen_net, prev_hiddens, prev_archs, writer_dict):\n    logger.info(""=> train controller..."")\n    writer = writer_dict[\'writer\']\n    baseline = None\n\n    # train mode\n    controller.train()\n\n    # eval mode\n    gen_net.eval()\n\n    cur_stage = controller.cur_stage\n    for step in range(args.ctrl_step):\n        controller_step = writer_dict[\'controller_steps\']\n        archs, selected_log_probs, entropies = controller.sample(args.ctrl_sample_batch, prev_hiddens=prev_hiddens,\n                                                                 prev_archs=prev_archs)\n        cur_batch_rewards = []\n        for arch in archs:\n            logger.info(f\'arch: {arch}\')\n            gen_net.set_arch(arch, cur_stage)\n            is_score = get_is(args, gen_net, args.rl_num_eval_img)\n            logger.info(f\'get Inception score of {is_score}\')\n            cur_batch_rewards.append(is_score)\n        cur_batch_rewards = torch.tensor(cur_batch_rewards, requires_grad=False).cuda()\n        cur_batch_rewards = cur_batch_rewards.unsqueeze(-1) + args.entropy_coeff * entropies  # bs * 1\n        if baseline is None:\n            baseline = cur_batch_rewards\n        else:\n            baseline = args.baseline_decay * baseline.detach() + (1 - args.baseline_decay) * cur_batch_rewards\n        adv = cur_batch_rewards - baseline\n\n        # policy loss\n        loss = -selected_log_probs * adv\n        loss = loss.sum()\n\n        # update controller\n        ctrl_optimizer.zero_grad()\n        loss.backward()\n        ctrl_optimizer.step()\n\n        # write\n        mean_reward = cur_batch_rewards.mean().item()\n        mean_adv = adv.mean().item()\n        mean_entropy = entropies.mean().item()\n        writer.add_scalar(\'controller/loss\', loss.item(), controller_step)\n        writer.add_scalar(\'controller/reward\', mean_reward, controller_step)\n        writer.add_scalar(\'controller/entropy\', mean_entropy, controller_step)\n        writer.add_scalar(\'controller/adv\', mean_adv, controller_step)\n\n        writer_dict[\'controller_steps\'] = controller_step + 1\n\n\ndef get_is(args, gen_net: nn.Module, num_img):\n    """"""\n    Get inception score.\n    :param args:\n    :param gen_net:\n    :param num_img:\n    :return: Inception score\n    """"""\n\n    # eval mode\n    gen_net = gen_net.eval()\n\n    eval_iter = num_img // args.eval_batch_size\n    img_list = list()\n    for _ in range(eval_iter):\n        z = torch.cuda.FloatTensor(np.random.normal(0, 1, (args.eval_batch_size, args.latent_dim)))\n\n        # Generate a batch of images\n        gen_imgs = gen_net(z).mul_(127.5).add_(127.5).clamp_(0.0, 255.0).permute(0, 2, 3, 1).to(\'cpu\',\n                                                                                                torch.uint8).numpy()\n        img_list.extend(list(gen_imgs))\n\n    # get inception score\n    logger.info(\'calculate Inception score...\')\n    mean, std = get_inception_score(img_list)\n\n    return mean\n\n\ndef validate(args, fixed_z, fid_stat, gen_net: nn.Module, writer_dict, clean_dir=True):\n    writer = writer_dict[\'writer\']\n    global_steps = writer_dict[\'valid_global_steps\']\n\n    # eval mode\n    gen_net = gen_net.eval()\n\n    # generate images\n    sample_imgs = gen_net(fixed_z)\n    img_grid = make_grid(sample_imgs, nrow=5, normalize=True, scale_each=True)\n\n    # get fid and inception score\n    fid_buffer_dir = os.path.join(args.path_helper[\'sample_path\'], \'fid_buffer\')\n    os.makedirs(fid_buffer_dir, exist_ok=True)\n\n    eval_iter = args.num_eval_imgs // args.eval_batch_size\n    img_list = list()\n    for iter_idx in tqdm(range(eval_iter), desc=\'sample images\'):\n        z = torch.cuda.FloatTensor(np.random.normal(0, 1, (args.eval_batch_size, args.latent_dim)))\n\n        # Generate a batch of images\n        gen_imgs = gen_net(z).mul_(127.5).add_(127.5).clamp_(0.0, 255.0).permute(0, 2, 3, 1).to(\'cpu\',\n                                                                                                torch.uint8).numpy()\n        for img_idx, img in enumerate(gen_imgs):\n            file_name = os.path.join(fid_buffer_dir, f\'iter{iter_idx}_b{img_idx}.png\')\n            imsave(file_name, img)\n        img_list.extend(list(gen_imgs))\n\n    # get inception score\n    logger.info(\'=> calculate inception score\')\n    mean, std = get_inception_score(img_list)\n    print(f""Inception score: {mean}"")\n\n    # get fid score\n    logger.info(\'=> calculate fid score\')\n    fid_score = calculate_fid_given_paths([fid_buffer_dir, fid_stat], inception_path=None)\n    print(f""FID score: {fid_score}"")\n\n    if clean_dir:\n        os.system(\'rm -r {}\'.format(fid_buffer_dir))\n    else:\n        logger.info(f\'=> sampled images are saved to {fid_buffer_dir}\')\n\n    writer.add_image(\'sampled_images\', img_grid, global_steps)\n    writer.add_scalar(\'Inception_score/mean\', mean, global_steps)\n    writer.add_scalar(\'Inception_score/std\', std, global_steps)\n    writer.add_scalar(\'FID_score\', fid_score, global_steps)\n\n    writer_dict[\'valid_global_steps\'] = global_steps + 1\n\n    return mean, fid_score\n\n\ndef get_topk_arch_hidden(args, controller, gen_net, prev_archs, prev_hiddens):\n    """"""\n    ~\n    :param args:\n    :param controller:\n    :param gen_net:\n    :param prev_archs: previous architecture\n    :param prev_hiddens: previous hidden vector\n    :return: a list of topk archs and hiddens.\n    """"""\n    logger.info(f\'=> get top{args.topk} archs out of {args.num_candidate} candidate archs...\')\n    assert args.num_candidate >= args.topk\n    controller.eval()\n    cur_stage = controller.cur_stage\n    archs, _, _, hiddens = controller.sample(args.num_candidate, with_hidden=True, prev_archs=prev_archs,\n                                             prev_hiddens=prev_hiddens)\n    hxs, cxs = hiddens\n    arch_idx_perf_table = {}\n    for arch_idx in range(len(archs)):\n        logger.info(f\'arch: {archs[arch_idx]}\')\n        gen_net.set_arch(archs[arch_idx], cur_stage)\n        is_score = get_is(args, gen_net, args.rl_num_eval_img)\n        logger.info(f\'get Inception score of {is_score}\')\n        arch_idx_perf_table[arch_idx] = is_score\n    topk_arch_idx_perf = sorted(arch_idx_perf_table.items(), key=operator.itemgetter(1))[::-1][:args.topk]\n    topk_archs = []\n    topk_hxs = []\n    topk_cxs = []\n    logger.info(f\'top{args.topk} archs:\')\n    for arch_idx_perf in topk_arch_idx_perf:\n        logger.info(arch_idx_perf)\n        arch_idx = arch_idx_perf[0]\n        topk_archs.append(archs[arch_idx])\n        topk_hxs.append(hxs[arch_idx].detach().requires_grad_(False))\n        topk_cxs.append(cxs[arch_idx].detach().requires_grad_(False))\n\n    return topk_archs, (topk_hxs, topk_cxs)\n\n\nclass LinearLrDecay(object):\n    def __init__(self, optimizer, start_lr, end_lr, decay_start_step, decay_end_step):\n\n        assert start_lr > end_lr\n        self.optimizer = optimizer\n        self.delta = (start_lr - end_lr) / (decay_end_step - decay_start_step)\n        self.decay_start_step = decay_start_step\n        self.decay_end_step = decay_end_step\n        self.start_lr = start_lr\n        self.end_lr = end_lr\n\n    def step(self, current_step):\n        if current_step <= self.decay_start_step:\n            lr = self.start_lr\n        elif current_step >= self.decay_end_step:\n            lr = self.end_lr\n        else:\n            lr = self.start_lr - self.delta * (current_step - self.decay_start_step)\n            for param_group in self.optimizer.param_groups:\n                param_group[\'lr\'] = lr\n        return lr\n\n\ndef load_params(model, new_param):\n    for p, new_p in zip(model.parameters(), new_param):\n        p.data.copy_(new_p)\n\n\ndef copy_params(model):\n    flatten = deepcopy(list(p.data for p in model.parameters()))\n    return flatten\n'"
search.py,8,"b'# -*- coding: utf-8 -*-\n# @Date    : 2019-09-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport cfg\nimport models_search\nimport datasets\nfrom functions import train_shared, train_controller, get_topk_arch_hidden\nfrom utils.utils import set_log_dir, save_checkpoint, create_logger, RunningStats\nfrom utils.inception_score import _init_inception\nfrom utils.fid_score import create_inception_graph, check_or_download_inception\n\nimport torch\nimport os\nimport torch.nn as nn\nfrom tensorboardX import SummaryWriter\nfrom tqdm import tqdm\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\n\nclass GrowCtrler(object):\n    def __init__(self, grow_step1, grow_step2):\n        self.grow_step1 = grow_step1\n        self.grow_step2 = grow_step2\n\n    def cur_stage(self, search_iter):\n        """"""\n        Return current stage.\n        :param epoch: current epoch.\n        :return: current stage\n        """"""\n        if search_iter < self.grow_step1:\n            return 0\n        elif self.grow_step1 <= search_iter < self.grow_step2:\n            return 1\n        else:\n            return 2\n\n\ndef create_ctrler(args, cur_stage, weights_init):\n    controller = eval(\'models_search.\'+args.controller+\'.Controller\')(args=args, cur_stage=cur_stage).cuda()\n    controller.apply(weights_init)\n    ctrl_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, controller.parameters()),\n                                     args.ctrl_lr, (args.beta1, args.beta2))\n    return controller, ctrl_optimizer\n\n\ndef create_shared_gan(args, weights_init):\n    gen_net = eval(\'models_search.\'+args.gen_model+\'.Generator\')(args=args).cuda()\n    dis_net = eval(\'models_search.\'+args.dis_model+\'.Discriminator\')(args=args).cuda()\n    gen_net.apply(weights_init)\n    dis_net.apply(weights_init)\n    gen_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, gen_net.parameters()),\n                                     args.g_lr, (args.beta1, args.beta2))\n    dis_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, dis_net.parameters()),\n                                     args.d_lr, (args.beta1, args.beta2))\n    return gen_net, dis_net, gen_optimizer, dis_optimizer\n\n\ndef main():\n    args = cfg.parse_args()\n    torch.cuda.manual_seed(args.random_seed)\n\n    # set tf env\n    _init_inception()\n    inception_path = check_or_download_inception(None)\n    create_inception_graph(inception_path)\n\n    # weight init\n    def weights_init(m):\n        classname = m.__class__.__name__\n        if classname.find(\'Conv2d\') != -1:\n            if args.init_type == \'normal\':\n                nn.init.normal_(m.weight.data, 0.0, 0.02)\n            elif args.init_type == \'orth\':\n                nn.init.orthogonal_(m.weight.data)\n            elif args.init_type == \'xavier_uniform\':\n                nn.init.xavier_uniform(m.weight.data, 1.)\n            else:\n                raise NotImplementedError(\'{} unknown inital type\'.format(args.init_type))\n        elif classname.find(\'BatchNorm2d\') != -1:\n            nn.init.normal_(m.weight.data, 1.0, 0.02)\n            nn.init.constant_(m.bias.data, 0.0)\n\n    gen_net, dis_net, gen_optimizer, dis_optimizer = create_shared_gan(args, weights_init)\n\n    # set grow controller\n    grow_ctrler = GrowCtrler(args.grow_step1, args.grow_step2)\n\n    # initial\n    start_search_iter = 0\n\n    # set writer\n    if args.load_path:\n        print(f\'=> resuming from {args.load_path}\')\n        assert os.path.exists(args.load_path)\n        checkpoint_file = os.path.join(args.load_path, \'Model\', \'checkpoint.pth\')\n        assert os.path.exists(checkpoint_file)\n        checkpoint = torch.load(checkpoint_file)\n        # set controller && its optimizer\n        cur_stage = checkpoint[\'cur_stage\']\n        controller, ctrl_optimizer = create_ctrler(args, cur_stage, weights_init)\n\n        start_search_iter = checkpoint[\'search_iter\']\n        gen_net.load_state_dict(checkpoint[\'gen_state_dict\'])\n        dis_net.load_state_dict(checkpoint[\'dis_state_dict\'])\n        controller.load_state_dict(checkpoint[\'ctrl_state_dict\'])\n        gen_optimizer.load_state_dict(checkpoint[\'gen_optimizer\'])\n        dis_optimizer.load_state_dict(checkpoint[\'dis_optimizer\'])\n        ctrl_optimizer.load_state_dict(checkpoint[\'ctrl_optimizer\'])\n        prev_archs = checkpoint[\'prev_archs\']\n        prev_hiddens = checkpoint[\'prev_hiddens\']\n\n        args.path_helper = checkpoint[\'path_helper\']\n        logger = create_logger(args.path_helper[\'log_path\'])\n        logger.info(f\'=> loaded checkpoint {checkpoint_file} (search iteration {start_search_iter})\')\n    else:\n        # create new log dir\n        assert args.exp_name\n        args.path_helper = set_log_dir(\'logs\', args.exp_name)\n        logger = create_logger(args.path_helper[\'log_path\'])\n        prev_archs = None\n        prev_hiddens = None\n\n        # set controller && its optimizer\n        cur_stage = 0\n        controller, ctrl_optimizer = create_ctrler(args, cur_stage, weights_init)\n\n    # set up data_loader\n    dataset = datasets.ImageDataset(args, 2**(cur_stage+3))\n    train_loader = dataset.train\n\n    logger.info(args)\n    writer_dict = {\n        \'writer\': SummaryWriter(args.path_helper[\'log_path\']),\n        \'controller_steps\': start_search_iter * args.ctrl_step\n    }\n\n    g_loss_history = RunningStats(args.dynamic_reset_window)\n    d_loss_history = RunningStats(args.dynamic_reset_window)\n\n    # train loop\n    for search_iter in tqdm(range(int(start_search_iter), int(args.max_search_iter)), desc=\'search progress\'):\n        logger.info(f""<start search iteration {search_iter}>"")\n        if search_iter == args.grow_step1 or search_iter == args.grow_step2:\n\n            # save\n            cur_stage = grow_ctrler.cur_stage(search_iter)\n            logger.info(f\'=> grow to stage {cur_stage}\')\n            prev_archs, prev_hiddens = get_topk_arch_hidden(args, controller, gen_net, prev_archs, prev_hiddens)\n\n            # grow section\n            del controller\n            del ctrl_optimizer\n            controller, ctrl_optimizer = create_ctrler(args, cur_stage, weights_init)\n\n            dataset = datasets.ImageDataset(args, 2 ** (cur_stage + 3))\n            train_loader = dataset.train\n\n        dynamic_reset = train_shared(args, gen_net, dis_net, g_loss_history, d_loss_history, controller, gen_optimizer,\n                                     dis_optimizer, train_loader, prev_hiddens=prev_hiddens, prev_archs=prev_archs)\n        train_controller(args, controller, ctrl_optimizer, gen_net, prev_hiddens, prev_archs, writer_dict)\n\n        if dynamic_reset:\n            logger.info(\'re-initialize share GAN\')\n            del gen_net, dis_net, gen_optimizer, dis_optimizer\n            gen_net, dis_net, gen_optimizer, dis_optimizer = create_shared_gan(args, weights_init)\n\n        save_checkpoint({\n            \'cur_stage\': cur_stage,\n            \'search_iter\': search_iter + 1,\n            \'gen_model\': args.gen_model,\n            \'dis_model\': args.dis_model,\n            \'controller\': args.controller,\n            \'gen_state_dict\': gen_net.state_dict(),\n            \'dis_state_dict\': dis_net.state_dict(),\n            \'ctrl_state_dict\': controller.state_dict(),\n            \'gen_optimizer\': gen_optimizer.state_dict(),\n            \'dis_optimizer\': dis_optimizer.state_dict(),\n            \'ctrl_optimizer\': ctrl_optimizer.state_dict(),\n            \'prev_archs\': prev_archs,\n            \'prev_hiddens\': prev_hiddens,\n            \'path_helper\': args.path_helper\n        }, False, args.path_helper[\'ckpt_path\'])\n\n    final_archs, _ = get_topk_arch_hidden(args, controller, gen_net, prev_archs, prev_hiddens)\n    logger.info(f""discovered archs: {final_archs}"")\n\n\nif __name__ == \'__main__\':\n    main()\n'"
test.py,5,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-07-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport cfg\nimport models\nfrom functions import validate\nfrom utils.utils import set_log_dir, create_logger\nfrom utils.inception_score import _init_inception\nfrom utils.fid_score import create_inception_graph, check_or_download_inception\n\nimport torch\nimport os\nimport numpy as np\nfrom tensorboardX import SummaryWriter\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\n\ndef main():\n    args = cfg.parse_args()\n    torch.cuda.manual_seed(args.random_seed)\n    assert args.exp_name\n    assert args.load_path.endswith('.pth')\n    assert os.path.exists(args.load_path)\n    args.path_helper = set_log_dir('logs_eval', args.exp_name)\n    logger = create_logger(args.path_helper['log_path'], phase='test')\n\n    # set tf env\n    _init_inception()\n    inception_path = check_or_download_inception(None)\n    create_inception_graph(inception_path)\n\n    # import network\n    gen_net = eval('models.'+args.gen_model+'.Generator')(args=args).cuda()\n\n    # fid stat\n    if args.dataset.lower() == 'cifar10':\n        fid_stat = 'fid_stat/fid_stats_cifar10_train.npz'\n    elif args.dataset.lower() == 'stl10':\n        fid_stat = 'fid_stat/stl10_train_unlabeled_fid_stats_48.npz'\n    else:\n        raise NotImplementedError(f'no fid stat for {args.dataset.lower()}')\n    assert os.path.exists(fid_stat)\n\n    # initial\n    fixed_z = torch.cuda.FloatTensor(np.random.normal(0, 1, (25, args.latent_dim)))\n\n    # set writer\n    logger.info(f'=> resuming from {args.load_path}')\n    checkpoint_file = args.load_path\n    assert os.path.exists(checkpoint_file)\n    checkpoint = torch.load(checkpoint_file)\n\n    if 'avg_gen_state_dict' in checkpoint:\n        gen_net.load_state_dict(checkpoint['avg_gen_state_dict'])\n        epoch = checkpoint['epoch']\n        logger.info(f'=> loaded checkpoint {checkpoint_file} (epoch {epoch})')\n    else:\n        gen_net.load_state_dict(checkpoint)\n        logger.info(f'=> loaded checkpoint {checkpoint_file}')\n\n    logger.info(args)\n    writer_dict = {\n        'writer': SummaryWriter(args.path_helper['log_path']),\n        'valid_global_steps': 0,\n    }\n    inception_score, fid_score = validate(args, fixed_z, fid_stat, gen_net, writer_dict, clean_dir=False)\n    logger.info(f'Inception score: {inception_score}, FID score: {fid_score}.')\n\n\nif __name__ == '__main__':\n    main()\n"""
train.py,8,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-07-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport cfg\nimport models\nimport datasets\nfrom functions import train, validate, LinearLrDecay, load_params, copy_params\nfrom utils.utils import set_log_dir, save_checkpoint, create_logger\nfrom utils.inception_score import _init_inception\nfrom utils.fid_score import create_inception_graph, check_or_download_inception\n\nimport torch\nimport os\nimport numpy as np\nimport torch.nn as nn\nfrom tensorboardX import SummaryWriter\nfrom tqdm import tqdm\nfrom copy import deepcopy\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\n\ndef main():\n    args = cfg.parse_args()\n    torch.cuda.manual_seed(args.random_seed)\n\n    # set tf env\n    _init_inception()\n    inception_path = check_or_download_inception(None)\n    create_inception_graph(inception_path)\n\n    # import network\n    gen_net = eval('models.'+args.gen_model+'.Generator')(args=args).cuda()\n    dis_net = eval('models.'+args.dis_model+'.Discriminator')(args=args).cuda()\n\n    # weight init\n    def weights_init(m):\n        classname = m.__class__.__name__\n        if classname.find('Conv2d') != -1:\n            if args.init_type == 'normal':\n                nn.init.normal_(m.weight.data, 0.0, 0.02)\n            elif args.init_type == 'orth':\n                nn.init.orthogonal_(m.weight.data)\n            elif args.init_type == 'xavier_uniform':\n                nn.init.xavier_uniform(m.weight.data, 1.)\n            else:\n                raise NotImplementedError('{} unknown inital type'.format(args.init_type))\n        elif classname.find('BatchNorm2d') != -1:\n            nn.init.normal_(m.weight.data, 1.0, 0.02)\n            nn.init.constant_(m.bias.data, 0.0)\n\n    gen_net.apply(weights_init)\n    dis_net.apply(weights_init)\n\n    # set optimizer\n    gen_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, gen_net.parameters()),\n                                     args.g_lr, (args.beta1, args.beta2))\n    dis_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, dis_net.parameters()),\n                                     args.d_lr, (args.beta1, args.beta2))\n    gen_scheduler = LinearLrDecay(gen_optimizer, args.g_lr, 0.0, 0, args.max_iter * args.n_critic)\n    dis_scheduler = LinearLrDecay(dis_optimizer, args.d_lr, 0.0, 0, args.max_iter * args.n_critic)\n\n    # set up data_loader\n    dataset = datasets.ImageDataset(args)\n    train_loader = dataset.train\n\n    # fid stat\n    if args.dataset.lower() == 'cifar10':\n        fid_stat = 'fid_stat/fid_stats_cifar10_train.npz'\n    elif args.dataset.lower() == 'stl10':\n        fid_stat = 'fid_stat/stl10_train_unlabeled_fid_stats_48.npz'\n    else:\n        raise NotImplementedError(f'no fid stat for {args.dataset.lower()}')\n    assert os.path.exists(fid_stat)\n\n    # epoch number for dis_net\n    args.max_epoch = args.max_epoch * args.n_critic\n    if args.max_iter:\n        args.max_epoch = np.ceil(args.max_iter * args.n_critic / len(train_loader))\n\n    # initial\n    fixed_z = torch.cuda.FloatTensor(np.random.normal(0, 1, (25, args.latent_dim)))\n    gen_avg_param = copy_params(gen_net)\n    start_epoch = 0\n    best_fid = 1e4\n\n    # set writer\n    if args.load_path:\n        print(f'=> resuming from {args.load_path}')\n        assert os.path.exists(args.load_path)\n        checkpoint_file = os.path.join(args.load_path, 'Model', 'checkpoint.pth')\n        assert os.path.exists(checkpoint_file)\n        checkpoint = torch.load(checkpoint_file)\n        start_epoch = checkpoint['epoch']\n        best_fid = checkpoint['best_fid']\n        gen_net.load_state_dict(checkpoint['gen_state_dict'])\n        dis_net.load_state_dict(checkpoint['dis_state_dict'])\n        gen_optimizer.load_state_dict(checkpoint['gen_optimizer'])\n        dis_optimizer.load_state_dict(checkpoint['dis_optimizer'])\n        avg_gen_net = deepcopy(gen_net)\n        avg_gen_net.load_state_dict(checkpoint['avg_gen_state_dict'])\n        gen_avg_param = copy_params(avg_gen_net)\n        del avg_gen_net\n\n        args.path_helper = checkpoint['path_helper']\n        logger = create_logger(args.path_helper['log_path'])\n        logger.info(f'=> loaded checkpoint {checkpoint_file} (epoch {start_epoch})')\n    else:\n        # create new log dir\n        assert args.exp_name\n        args.path_helper = set_log_dir('logs', args.exp_name)\n        logger = create_logger(args.path_helper['log_path'])\n\n    logger.info(args)\n    writer_dict = {\n        'writer': SummaryWriter(args.path_helper['log_path']),\n        'train_global_steps': start_epoch * len(train_loader),\n        'valid_global_steps': start_epoch // args.val_freq,\n    }\n\n    # train loop\n    for epoch in tqdm(range(int(start_epoch), int(args.max_epoch)), desc='total progress'):\n        lr_schedulers = (gen_scheduler, dis_scheduler) if args.lr_decay else None\n        train(args, gen_net, dis_net, gen_optimizer, dis_optimizer, gen_avg_param, train_loader, epoch, writer_dict,\n              lr_schedulers)\n\n        if epoch and epoch % args.val_freq == 0 or epoch == int(args.max_epoch)-1:\n            backup_param = copy_params(gen_net)\n            load_params(gen_net, gen_avg_param)\n            inception_score, fid_score = validate(args, fixed_z, fid_stat, gen_net, writer_dict)\n            logger.info(f'Inception score: {inception_score}, FID score: {fid_score} || @ epoch {epoch}.')\n            load_params(gen_net, backup_param)\n            if fid_score < best_fid:\n                best_fid = fid_score\n                is_best = True\n            else:\n                is_best = False\n        else:\n            is_best = False\n\n        avg_gen_net = deepcopy(gen_net)\n        load_params(avg_gen_net, gen_avg_param)\n        save_checkpoint({\n            'epoch': epoch + 1,\n            'gen_model': args.gen_model,\n            'dis_model': args.dis_model,\n            'gen_state_dict': gen_net.state_dict(),\n            'dis_state_dict': dis_net.state_dict(),\n            'avg_gen_state_dict': avg_gen_net.state_dict(),\n            'gen_optimizer': gen_optimizer.state_dict(),\n            'dis_optimizer': dis_optimizer.state_dict(),\n            'best_fid': best_fid,\n            'path_helper': args.path_helper\n        }, is_best, args.path_helper['ckpt_path'])\n        del avg_gen_net\n\n\nif __name__ == '__main__':\n    main()\n"""
train_derived.py,8,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-10-01\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport cfg\nimport models_search\nimport datasets\nfrom functions import train, validate, LinearLrDecay, load_params, copy_params\nfrom utils.utils import set_log_dir, save_checkpoint, create_logger\nfrom utils.inception_score import _init_inception\nfrom utils.fid_score import create_inception_graph, check_or_download_inception\n\nimport torch\nimport os\nimport numpy as np\nimport torch.nn as nn\nfrom tensorboardX import SummaryWriter\nfrom tqdm import tqdm\nfrom copy import deepcopy\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\n\ndef main():\n    args = cfg.parse_args()\n    torch.cuda.manual_seed(args.random_seed)\n\n    # set tf env\n    _init_inception()\n    inception_path = check_or_download_inception(None)\n    create_inception_graph(inception_path)\n\n    # import network\n    gen_net = eval('models_search.'+args.gen_model+'.Generator')(args=args).cuda()\n    dis_net = eval('models_search.'+args.dis_model+'.Discriminator')(args=args).cuda()\n\n    gen_net.set_arch(args.arch, cur_stage=2)\n    dis_net.cur_stage = 2\n\n    # weight init\n    def weights_init(m):\n        classname = m.__class__.__name__\n        if classname.find('Conv2d') != -1:\n            if args.init_type == 'normal':\n                nn.init.normal_(m.weight.data, 0.0, 0.02)\n            elif args.init_type == 'orth':\n                nn.init.orthogonal_(m.weight.data)\n            elif args.init_type == 'xavier_uniform':\n                nn.init.xavier_uniform(m.weight.data, 1.)\n            else:\n                raise NotImplementedError('{} unknown inital type'.format(args.init_type))\n        elif classname.find('BatchNorm2d') != -1:\n            nn.init.normal_(m.weight.data, 1.0, 0.02)\n            nn.init.constant_(m.bias.data, 0.0)\n\n    gen_net.apply(weights_init)\n    dis_net.apply(weights_init)\n\n    # set optimizer\n    gen_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, gen_net.parameters()),\n                                     args.g_lr, (args.beta1, args.beta2))\n    dis_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, dis_net.parameters()),\n                                     args.d_lr, (args.beta1, args.beta2))\n    gen_scheduler = LinearLrDecay(gen_optimizer, args.g_lr, 0.0, 0, args.max_iter * args.n_critic)\n    dis_scheduler = LinearLrDecay(dis_optimizer, args.d_lr, 0.0, 0, args.max_iter * args.n_critic)\n\n    # set up data_loader\n    dataset = datasets.ImageDataset(args)\n    train_loader = dataset.train\n\n    # fid stat\n    if args.dataset.lower() == 'cifar10':\n        fid_stat = 'fid_stat/fid_stats_cifar10_train.npz'\n    elif args.dataset.lower() == 'stl10':\n        fid_stat = 'fid_stat/stl10_train_unlabeled_fid_stats_48.npz'\n    else:\n        raise NotImplementedError(f'no fid stat for {args.dataset.lower()}')\n    assert os.path.exists(fid_stat)\n\n    # epoch number for dis_net\n    args.max_epoch = args.max_epoch * args.n_critic\n    if args.max_iter:\n        args.max_epoch = np.ceil(args.max_iter * args.n_critic / len(train_loader))\n\n    # initial\n    fixed_z = torch.cuda.FloatTensor(np.random.normal(0, 1, (25, args.latent_dim)))\n    gen_avg_param = copy_params(gen_net)\n    start_epoch = 0\n    best_fid = 1e4\n\n    # set writer\n    if args.load_path:\n        print(f'=> resuming from {args.load_path}')\n        assert os.path.exists(args.load_path)\n        checkpoint_file = os.path.join(args.load_path, 'Model', 'checkpoint.pth')\n        assert os.path.exists(checkpoint_file)\n        checkpoint = torch.load(checkpoint_file)\n        start_epoch = checkpoint['epoch']\n        best_fid = checkpoint['best_fid']\n        gen_net.load_state_dict(checkpoint['gen_state_dict'])\n        dis_net.load_state_dict(checkpoint['dis_state_dict'])\n        gen_optimizer.load_state_dict(checkpoint['gen_optimizer'])\n        dis_optimizer.load_state_dict(checkpoint['dis_optimizer'])\n        avg_gen_net = deepcopy(gen_net)\n        avg_gen_net.load_state_dict(checkpoint['avg_gen_state_dict'])\n        gen_avg_param = copy_params(avg_gen_net)\n        del avg_gen_net\n\n        args.path_helper = checkpoint['path_helper']\n        logger = create_logger(args.path_helper['log_path'])\n        logger.info(f'=> loaded checkpoint {checkpoint_file} (epoch {start_epoch})')\n    else:\n        # create new log dir\n        assert args.exp_name\n        args.path_helper = set_log_dir('logs', args.exp_name)\n        logger = create_logger(args.path_helper['log_path'])\n\n    logger.info(args)\n    writer_dict = {\n        'writer': SummaryWriter(args.path_helper['log_path']),\n        'train_global_steps': start_epoch * len(train_loader),\n        'valid_global_steps': start_epoch // args.val_freq,\n    }\n\n    # train loop\n    for epoch in tqdm(range(int(start_epoch), int(args.max_epoch)), desc='total progress'):\n        lr_schedulers = (gen_scheduler, dis_scheduler) if args.lr_decay else None\n        train(args, gen_net, dis_net, gen_optimizer, dis_optimizer, gen_avg_param, train_loader, epoch, writer_dict,\n              lr_schedulers)\n\n        if epoch and epoch % args.val_freq == 0 or epoch == int(args.max_epoch)-1:\n            backup_param = copy_params(gen_net)\n            load_params(gen_net, gen_avg_param)\n            inception_score, fid_score = validate(args, fixed_z, fid_stat, gen_net, writer_dict)\n            logger.info(f'Inception score: {inception_score}, FID score: {fid_score} || @ epoch {epoch}.')\n            load_params(gen_net, backup_param)\n            if fid_score < best_fid:\n                best_fid = fid_score\n                is_best = True\n            else:\n                is_best = False\n        else:\n            is_best = False\n\n        avg_gen_net = deepcopy(gen_net)\n        load_params(avg_gen_net, gen_avg_param)\n        save_checkpoint({\n            'epoch': epoch + 1,\n            'gen_model': args.gen_model,\n            'dis_model': args.dis_model,\n            'gen_state_dict': gen_net.state_dict(),\n            'dis_state_dict': dis_net.state_dict(),\n            'avg_gen_state_dict': avg_gen_net.state_dict(),\n            'gen_optimizer': gen_optimizer.state_dict(),\n            'dis_optimizer': dis_optimizer.state_dict(),\n            'best_fid': best_fid,\n            'path_helper': args.path_helper\n        }, is_best, args.path_helper['ckpt_path'])\n        del avg_gen_net\n\n\nif __name__ == '__main__':\n    main()\n"""
models/__init__.py,0,b'# -*- coding: utf-8 -*-\n# @Date    : 2019-07-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport models.autogan_cifar10_a\nimport models.autogan_cifar10_b\nimport models.autogan_cifar10_c\n'
models/autogan_cifar10_a.py,0,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-07-31\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom torch import nn\nfrom models.building_blocks import Cell, DisBlock, OptimizedDisBlock\n\n\nclass Generator(nn.Module):\n    def __init__(self, args):\n        super(Generator, self).__init__()\n        self.args = args\n        self.ch = args.gf_dim\n        self.bottom_width = args.bottom_width\n        self.l1 = nn.Linear(args.latent_dim, (self.bottom_width ** 2) * args.gf_dim)\n        self.cell1 = Cell(args.gf_dim, args.gf_dim, 'nearest', num_skip_in=0, short_cut=True)\n        self.cell2 = Cell(args.gf_dim, args.gf_dim, 'bilinear', num_skip_in=1, short_cut=True)\n        self.cell3 = Cell(args.gf_dim, args.gf_dim, 'nearest', num_skip_in=2, short_cut=False)\n        self.to_rgb = nn.Sequential(\n            nn.BatchNorm2d(args.gf_dim),\n            nn.ReLU(),\n            nn.Conv2d(args.gf_dim, 3, 3, 1, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        h = self.l1(z).view(-1, self.ch, self.bottom_width, self.bottom_width)\n        h1_skip_out, h1 = self.cell1(h)\n        h2_skip_out, h2 = self.cell2(h1, (h1_skip_out, ))\n        _, h3 = self.cell3(h2, (h1_skip_out, h2_skip_out))\n        output = self.to_rgb(h3)\n\n        return output\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, args, activation=nn.ReLU()):\n        super(Discriminator, self).__init__()\n        self.ch = args.df_dim\n        self.activation = activation\n        self.block1 = OptimizedDisBlock(args, 3, self.ch)\n        self.block2 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=True)\n        self.block3 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=False)\n        self.block4 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=False)\n        self.l5 = nn.Linear(self.ch, 1, bias=False)\n        if args.d_spectral_norm:\n            self.l5 = nn.utils.spectral_norm(self.l5)\n\n    def forward(self, x):\n        h = x\n        layers = [self.block1, self.block2, self.block3]\n        model = nn.Sequential(*layers)\n        h = model(h)\n        h = self.block4(h)\n        h = self.activation(h)\n        # Global average pooling\n        h = h.sum(2).sum(2)\n        output = self.l5(h)\n\n        return output\n"""
models/autogan_cifar10_b.py,0,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-07-31\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom torch import nn\nfrom models.building_blocks import Cell, DisBlock, OptimizedDisBlock\n\n\nclass Generator(nn.Module):\n    def __init__(self, args):\n        super(Generator, self).__init__()\n        self.args = args\n        self.ch = args.gf_dim\n        self.bottom_width = args.bottom_width\n        self.l1 = nn.Linear(args.latent_dim, (self.bottom_width ** 2) * args.gf_dim)\n        self.cell1 = Cell(args.gf_dim, args.gf_dim, 'nearest', num_skip_in=0, short_cut=True)\n        self.cell2 = Cell(args.gf_dim, args.gf_dim, 'nearest', num_skip_in=1, short_cut=True)\n        self.cell3 = Cell(args.gf_dim, args.gf_dim, 'nearest', num_skip_in=2, short_cut=True)\n        self.to_rgb = nn.Sequential(\n            nn.BatchNorm2d(args.gf_dim),\n            nn.ReLU(),\n            nn.Conv2d(args.gf_dim, 3, 3, 1, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        h = self.l1(z).view(-1, self.ch, self.bottom_width, self.bottom_width)\n        h1_skip_out, h1 = self.cell1(h)\n        h2_skip_out, h2 = self.cell2(h1, (h1_skip_out, ))\n        _, h3 = self.cell3(h2, (h1_skip_out, h2_skip_out))\n        output = self.to_rgb(h3)\n\n        return output\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, args, activation=nn.ReLU()):\n        super(Discriminator, self).__init__()\n        self.ch = args.df_dim\n        self.activation = activation\n        self.block1 = OptimizedDisBlock(args, 3, self.ch)\n        self.block2 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=True)\n        self.block3 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=False)\n        self.block4 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=False)\n        self.l5 = nn.Linear(self.ch, 1, bias=False)\n        if args.d_spectral_norm:\n            self.l5 = nn.utils.spectral_norm(self.l5)\n\n    def forward(self, x):\n        h = x\n        layers = [self.block1, self.block2, self.block3]\n        model = nn.Sequential(*layers)\n        h = model(h)\n        h = self.block4(h)\n        h = self.activation(h)\n        # Global average pooling\n        h = h.sum(2).sum(2)\n        output = self.l5(h)\n\n        return output\n"""
models/autogan_cifar10_c.py,0,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-07-31\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom torch import nn\nfrom models.building_blocks import Cell, DisBlock, OptimizedDisBlock\n\n\nclass Generator(nn.Module):\n    def __init__(self, args):\n        super(Generator, self).__init__()\n        self.args = args\n        self.ch = args.gf_dim\n        self.bottom_width = args.bottom_width\n        self.l1 = nn.Linear(args.latent_dim, (self.bottom_width ** 2) * args.gf_dim)\n        self.cell1 = Cell(args.gf_dim, args.gf_dim, 'nearest', num_skip_in=0, short_cut=True, norm='bn')\n        self.cell2 = Cell(args.gf_dim, args.gf_dim, 'bilinear', num_skip_in=1, short_cut=True)\n        self.cell3 = Cell(args.gf_dim, args.gf_dim, 'nearest', num_skip_in=2, short_cut=False)\n        self.to_rgb = nn.Sequential(\n            nn.BatchNorm2d(args.gf_dim),\n            nn.ReLU(),\n            nn.Conv2d(args.gf_dim, 3, 3, 1, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        h = self.l1(z).view(-1, self.ch, self.bottom_width, self.bottom_width)\n        h1_skip_out, h1 = self.cell1(h)\n        h2_skip_out, h2 = self.cell2(h1, (h1_skip_out, ))\n        _, h3 = self.cell3(h2, (h1_skip_out, h2_skip_out))\n        output = self.to_rgb(h3)\n\n        return output\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, args, activation=nn.ReLU()):\n        super(Discriminator, self).__init__()\n        self.ch = args.df_dim\n        self.activation = activation\n        self.block1 = OptimizedDisBlock(args, 3, self.ch)\n        self.block2 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=True)\n        self.block3 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=False)\n        self.block4 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=False)\n        self.l5 = nn.Linear(self.ch, 1, bias=False)\n        if args.d_spectral_norm:\n            self.l5 = nn.utils.spectral_norm(self.l5)\n\n    def forward(self, x):\n        h = x\n        layers = [self.block1, self.block2, self.block3]\n        model = nn.Sequential(*layers)\n        h = model(h)\n        h = self.block4(h)\n        h = self.activation(h)\n        # Global average pooling\n        h = h.sum(2).sum(2)\n        output = self.l5(h)\n\n        return output\n"""
models/building_blocks.py,1,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-08-02\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom torch import nn\nimport torch.nn.functional as F\n\nUP_MODES = ['nearest', 'bilinear']\nNORMS = ['in', 'bn']\n\n\nclass Cell(nn.Module):\n    def __init__(self, in_channels, out_channels, up_mode, ksize=3, num_skip_in=0, short_cut=False, norm=None):\n        super(Cell, self).__init__()\n        self.c1 = nn.Conv2d(in_channels, out_channels, ksize, padding=ksize//2)\n        self.c2 = nn.Conv2d(out_channels, out_channels, ksize, padding=ksize//2)\n        assert up_mode in UP_MODES\n        self.up_mode = up_mode\n        self.norm = norm\n        if norm:\n            assert norm in NORMS\n            if norm == 'bn':\n                self.n1 = nn.BatchNorm2d(in_channels)\n                self.n2 = nn.BatchNorm2d(out_channels)\n            elif norm == 'in':\n                self.n1 = nn.InstanceNorm2d(in_channels)\n                self.n2 = nn.InstanceNorm2d(out_channels)\n            else:\n                raise NotImplementedError(norm)\n\n        # inner shortcut\n        self.c_sc = None\n        if short_cut:\n            self.c_sc = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n        # cross scale skip\n        self.skip_in_ops = None\n        if num_skip_in:\n            self.skip_in_ops = nn.ModuleList([nn.Conv2d(out_channels, out_channels, kernel_size=1) for _ in range(num_skip_in)])\n\n    def forward(self, x, skip_ft=None):\n        residual = x\n\n        # first conv\n        if self.norm:\n            residual = self.n1(residual)\n        h = nn.ReLU()(residual)\n        h = F.interpolate(h, scale_factor=2, mode=self.up_mode)\n        _, _, ht, wt = h.size()\n        h = self.c1(h)\n        h_skip_out = h\n\n        # second conv\n        if self.skip_in_ops:\n            assert len(self.skip_in_ops) == len(skip_ft)\n            for ft, skip_in_op in zip(skip_ft, self.skip_in_ops):\n                h += skip_in_op(F.interpolate(ft, size=(ht, wt), mode=self.up_mode))\n        if self.norm:\n            h = self.n2(h)\n        h = nn.ReLU()(h)\n        final_out = self.c2(h)\n\n        # shortcut\n        if self.c_sc:\n            final_out += self.c_sc(F.interpolate(x, scale_factor=2, mode=self.up_mode))\n\n        return h_skip_out, final_out\n\n\ndef _downsample(x):\n    # Downsample (Mean Avg Pooling with 2x2 kernel)\n    return nn.AvgPool2d(kernel_size=2)(x)\n\n\nclass OptimizedDisBlock(nn.Module):\n    def __init__(\n            self,\n            args,\n            in_channels,\n            out_channels,\n            ksize=3,\n            pad=1,\n            activation=nn.ReLU()):\n        super(OptimizedDisBlock, self).__init__()\n        self.activation = activation\n\n        self.c1 = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c2 = nn.Conv2d(\n            out_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c_sc = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=1,\n            padding=0)\n        if args.d_spectral_norm:\n            self.c1 = nn.utils.spectral_norm(self.c1)\n            self.c2 = nn.utils.spectral_norm(self.c2)\n            self.c_sc = nn.utils.spectral_norm(self.c_sc)\n\n    def residual(self, x):\n        h = x\n        h = self.c1(h)\n        h = self.activation(h)\n        h = self.c2(h)\n        h = _downsample(h)\n        return h\n\n    def shortcut(self, x):\n        return self.c_sc(_downsample(x))\n\n    def forward(self, x):\n        return self.residual(x) + self.shortcut(x)\n\n\nclass DisBlock(nn.Module):\n    def __init__(\n            self,\n            args,\n            in_channels,\n            out_channels,\n            hidden_channels=None,\n            ksize=3,\n            pad=1,\n            activation=nn.ReLU(),\n            downsample=False):\n        super(DisBlock, self).__init__()\n        self.activation = activation\n        self.downsample = downsample\n        self.learnable_sc = (in_channels != out_channels) or downsample\n        hidden_channels = in_channels if hidden_channels is None else hidden_channels\n\n        self.c1 = nn.Conv2d(\n            in_channels,\n            hidden_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c2 = nn.Conv2d(\n            hidden_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        if args.d_spectral_norm:\n            self.c1 = nn.utils.spectral_norm(self.c1)\n            self.c2 = nn.utils.spectral_norm(self.c2)\n\n        if self.learnable_sc:\n            self.c_sc = nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=1,\n                padding=0)\n            if args.d_spectral_norm:\n                self.c_sc = nn.utils.spectral_norm(self.c_sc)\n\n    def residual(self, x):\n        h = x\n        h = self.activation(h)\n        h = self.c1(h)\n        h = self.activation(h)\n        h = self.c2(h)\n        if self.downsample:\n            h = _downsample(h)\n        return h\n\n    def shortcut(self, x):\n        if self.learnable_sc:\n            x = self.c_sc(x)\n            if self.downsample:\n                return _downsample(x)\n            else:\n                return x\n        else:\n            return x\n\n    def forward(self, x):\n        return self.residual(x) + self.shortcut(x)"""
models_search/__init__.py,0,"b'# -*- coding: utf-8 -*-\n# @Date    : 2019-08-15\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom models_search import shared_gan, controller\n'"
models_search/building_blocks_search.py,1,"b'# -*- coding: utf-8 -*-\n# @Date    : 2019-08-02\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nCONV_TYPE = {0: \'post\', 1: \'pre\'}\nNORM_TYPE = {0: None, 1: \'bn\', 2: \'in\'}\nUP_TYPE = {0: \'bilinear\', 1: \'nearest\', 2: \'deconv\'}\nSHORT_CUT_TYPE = {0: False, 1: True}\nSKIP_TYPE = {0: False, 1: True}\n\n\ndef decimal2binary(n):\n    return bin(n).replace(""0b"", """")\n\n\nclass PreGenBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, up_block, ksize=3):\n        super(PreGenBlock, self).__init__()\n        self.bn = nn.BatchNorm2d(in_channels)\n        self.inn = nn.InstanceNorm2d(in_channels)\n        self.up_block = up_block\n        self.deconv = nn.ConvTranspose2d(\n            in_channels, in_channels, kernel_size=2, stride=2)\n        self.conv = nn.Conv2d(in_channels, out_channels, ksize, padding=ksize//2)\n\n    def set_arch(self, up_id, norm_id):\n        self.up_type = UP_TYPE[up_id]\n        self.norm_type = NORM_TYPE[norm_id]\n\n    def forward(self, x):\n        # norm\n        if self.norm_type:\n            if self.norm_type == \'bn\':\n                h = self.bn(x)\n            elif self.norm_type == \'in\':\n                h = self.inn(x)\n            else:\n                raise NotImplementedError(self.norm_type)\n        else:\n            h = x\n\n        # activation\n        h = nn.ReLU()(h)\n\n        # whether this is a upsample block\n        if self.up_block:\n            if self.up_type == \'deconv\':\n                h = self.deconv(h)\n            else:\n                h = F.interpolate(h, scale_factor=2, mode=self.up_type)\n\n        # conv\n        out = self.conv(h)\n        return out\n\n\nclass PostGenBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, up_block, ksize=3):\n        super(PostGenBlock, self).__init__()\n        self.deconv = nn.ConvTranspose2d(\n            in_channels, in_channels, kernel_size=2, stride=2)\n        self.conv = nn.Conv2d(in_channels, out_channels, ksize, padding=ksize//2)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.inn = nn.InstanceNorm2d(out_channels)\n        self.up_block = up_block\n\n    def set_arch(self, up_id, norm_id):\n        self.up_type = UP_TYPE[up_id]\n        self.norm_type = NORM_TYPE[norm_id]\n\n    def forward(self, x):\n        # whether this is a upsample block\n        if self.up_block:\n            if self.up_type == \'deconv\':\n                h = self.deconv(x)\n            else:\n                h = F.interpolate(x, scale_factor=2, mode=self.up_type)\n        else:\n            h = x\n\n        # conv\n        h = self.conv(h)\n\n        # norm\n        if self.norm_type:\n            if self.norm_type == \'bn\':\n                h = self.bn(h)\n            elif self.norm_type == \'in\':\n                h = self.inn(h)\n            else:\n                raise NotImplementedError(self.norm_type)\n\n        # activation\n        out = nn.ReLU()(h)\n\n        return out\n\n\nclass Cell(nn.Module):\n    def __init__(self, in_channels, out_channels, num_skip_in, ksize=3):\n        super(Cell, self).__init__()\n\n        self.post_conv1 = PostGenBlock(in_channels, out_channels, ksize=ksize, up_block=True)\n        self.pre_conv1 = PreGenBlock(in_channels, out_channels, ksize=ksize, up_block=True)\n\n        self.post_conv2 = PostGenBlock(out_channels, out_channels, ksize=ksize, up_block=False)\n        self.pre_conv2 = PreGenBlock(out_channels, out_channels, ksize=ksize, up_block=False)\n\n        self.deconv_sc = nn.ConvTranspose2d(\n            in_channels, in_channels, kernel_size=2, stride=2)\n        self.c_sc = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n        # skip_in\n        self.skip_deconvx2 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n        self.skip_deconvx4 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n            nn.ConvTranspose2d(out_channels, out_channels, kernel_size=2, stride=2)\n        )\n\n        self.num_skip_in = num_skip_in\n        if num_skip_in:\n            self.skip_in_ops = nn.ModuleList([nn.Conv2d(in_channels, out_channels, kernel_size=1) for _ in range(num_skip_in)])\n\n    def set_arch(self, conv_id, norm_id, up_id, short_cut_id, skip_ins):\n        self.post_conv1.set_arch(up_id, norm_id)\n        self.pre_conv1.set_arch(up_id, norm_id)\n        self.post_conv2.set_arch(up_id, norm_id)\n        self.pre_conv2.set_arch(up_id, norm_id)\n\n        if self.num_skip_in:\n            self.skip_ins = [0 for _ in range(self.num_skip_in)]\n            for skip_idx, skip_in in enumerate(decimal2binary(skip_ins)[::-1]):\n                self.skip_ins[-(skip_idx + 1)] = int(skip_in)\n\n        self.conv_type = CONV_TYPE[conv_id]\n        self.up_type = UP_TYPE[up_id]\n        self.short_cut = SHORT_CUT_TYPE[short_cut_id]\n\n    def forward(self, x, skip_ft=None):\n        residual = x\n\n        # first conv\n        if self.conv_type == \'post\':\n            h = self.post_conv1(residual)\n        elif self.conv_type == \'pre\':\n            h = self.pre_conv1(residual)\n        else:\n            raise NotImplementedError(self.norm_type)\n        _, _, ht, wt = h.size()\n        h_skip_out = h\n        # second conv\n        if self.num_skip_in:\n            assert len(self.skip_in_ops) == len(self.skip_ins)\n            for skip_flag, ft, skip_in_op in zip(self.skip_ins, skip_ft, self.skip_in_ops):\n                if skip_flag:\n                    if self.up_type != \'deconv\':\n                        h += skip_in_op(F.interpolate(ft, size=(ht, wt), mode=self.up_type))\n                    else:\n                        scale = wt // ft.size()[-1]\n                        h += skip_in_op(getattr(self, f\'skip_deconvx{scale}\')(ft))\n\n        if self.conv_type == \'post\':\n            final_out = self.post_conv2(h)\n        elif self.conv_type == \'pre\':\n            final_out = self.pre_conv2(h)\n        else:\n            raise NotImplementedError(self.norm_type)\n\n        # shortcut\n        if self.short_cut:\n            if self.up_type != \'deconv\':\n                final_out += self.c_sc(F.interpolate(x, scale_factor=2, mode=self.up_type))\n            else:\n                final_out += self.c_sc(self.deconv_sc(x))\n\n        return h_skip_out, final_out\n\n\ndef _downsample(x):\n    # Downsample (Mean Avg Pooling with 2x2 kernel)\n    return nn.AvgPool2d(kernel_size=2)(x)\n\n\nclass OptimizedDisBlock(nn.Module):\n    def __init__(\n            self,\n            args,\n            in_channels,\n            out_channels,\n            ksize=3,\n            pad=1,\n            activation=nn.ReLU()):\n        super(OptimizedDisBlock, self).__init__()\n        self.activation = activation\n\n        self.c1 = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c2 = nn.Conv2d(\n            out_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c_sc = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=1,\n            padding=0)\n        if args.d_spectral_norm:\n            self.c1 = nn.utils.spectral_norm(self.c1)\n            self.c2 = nn.utils.spectral_norm(self.c2)\n            self.c_sc = nn.utils.spectral_norm(self.c_sc)\n\n    def residual(self, x):\n        h = x\n        h = self.c1(h)\n        h = self.activation(h)\n        h = self.c2(h)\n        h = _downsample(h)\n        return h\n\n    def shortcut(self, x):\n        return self.c_sc(_downsample(x))\n\n    def forward(self, x):\n        return self.residual(x) + self.shortcut(x)\n\n\nclass DisBlock(nn.Module):\n    def __init__(\n            self,\n            args,\n            in_channels,\n            out_channels,\n            hidden_channels=None,\n            ksize=3,\n            pad=1,\n            activation=nn.ReLU(),\n            downsample=False):\n        super(DisBlock, self).__init__()\n        self.activation = activation\n        self.downsample = downsample\n        self.learnable_sc = (in_channels != out_channels) or downsample\n        hidden_channels = in_channels if hidden_channels is None else hidden_channels\n\n        self.c1 = nn.Conv2d(\n            in_channels,\n            hidden_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c2 = nn.Conv2d(\n            hidden_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        if args.d_spectral_norm:\n            self.c1 = nn.utils.spectral_norm(self.c1)\n            self.c2 = nn.utils.spectral_norm(self.c2)\n\n        if self.learnable_sc:\n            self.c_sc = nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=1,\n                padding=0)\n            if args.d_spectral_norm:\n                self.c_sc = nn.utils.spectral_norm(self.c_sc)\n\n    def residual(self, x):\n        h = x\n        h = self.activation(h)\n        h = self.c1(h)\n        h = self.activation(h)\n        h = self.c2(h)\n        if self.downsample:\n            h = _downsample(h)\n        return h\n\n    def shortcut(self, x):\n        if self.learnable_sc:\n            x = self.c_sc(x)\n            if self.downsample:\n                return _downsample(x)\n            else:\n                return x\n        else:\n            return x\n\n    def forward(self, x):\n        return self.residual(x) + self.shortcut(x)'"
models_search/controller.py,10,"b'# -*- coding: utf-8 -*-\n# @Date    : 2019-09-29\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom models_search.building_blocks_search import CONV_TYPE, NORM_TYPE, UP_TYPE, SHORT_CUT_TYPE, SKIP_TYPE\n\n\nclass Controller(nn.Module):\n    def __init__(self, args, cur_stage):\n        """"""\n        init\n        :param args:\n        :param cur_stage: varies from 0 to ...\n        """"""\n        super(Controller, self).__init__()\n        self.hid_size = args.hid_size\n        self.cur_stage = cur_stage\n        self.lstm = torch.nn.LSTMCell(self.hid_size, self.hid_size)\n        if cur_stage:\n            self.tokens = [len(CONV_TYPE), len(NORM_TYPE), len(UP_TYPE), len(SHORT_CUT_TYPE), len(SKIP_TYPE)**cur_stage]\n        else:\n            self.tokens = [len(CONV_TYPE), len(NORM_TYPE), len(UP_TYPE), len(SHORT_CUT_TYPE)]\n        self.encoder = nn.Embedding(sum(self.tokens), self.hid_size)\n        self.decoders = nn.ModuleList([nn.Linear(self.hid_size, token) for token in self.tokens])\n\n    def initHidden(self, batch_size):\n        return torch.zeros(batch_size, self.hid_size, requires_grad=False).cuda()\n\n    def forward(self, x, hidden, index):\n        if index == 0:\n            embed = x\n        else:\n            embed = self.encoder(x)\n        hx, cx = self.lstm(embed, hidden)\n\n        # decode\n        logit = self.decoders[index](hx)\n\n        return logit, (hx, cx)\n\n    def sample(self, batch_size, with_hidden=False, prev_hiddens=None, prev_archs=None):\n        x = self.initHidden(batch_size)\n\n        if prev_hiddens:\n            assert prev_archs\n            prev_hxs, prev_cxs = prev_hiddens\n            selected_idx = np.random.choice(len(prev_archs), batch_size)  # TODO: replace=False\n            selected_idx = [int(x) for x in selected_idx]\n\n            selected_archs = []\n            selected_hxs = []\n            selected_cxs = []\n\n            for s_idx in selected_idx:\n                selected_archs.append(prev_archs[s_idx].unsqueeze(0))\n                selected_hxs.append(prev_hxs[s_idx].unsqueeze(0))\n                selected_cxs.append(prev_cxs[s_idx].unsqueeze(0))\n            selected_archs = torch.cat(selected_archs, 0)\n            hidden = (torch.cat(selected_hxs, 0), torch.cat(selected_cxs, 0))\n        else:\n            hidden = (self.initHidden(batch_size), self.initHidden(batch_size))\n        entropies = []\n        actions = []\n        selected_log_probs = []\n        for decode_idx in range(len(self.decoders)):\n            logit, hidden = self.forward(x, hidden, decode_idx)\n            prob = F.softmax(logit, dim=-1)     # bs * logit_dim\n            log_prob = F.log_softmax(logit, dim=-1)\n            entropies.append(-(log_prob * prob).sum(1, keepdim=True))  # bs * 1\n            action = prob.multinomial(1)  # batch_size * 1\n            actions.append(action)\n            selected_log_prob = log_prob.gather(1, action.data)  # batch_size * 1\n            selected_log_probs.append(selected_log_prob)\n\n            x = action.view(batch_size)+sum(self.tokens[:decode_idx])\n            x = x.requires_grad_(False)\n\n        archs = torch.cat(actions, -1)  # batch_size * len(self.decoders)\n        selected_log_probs = torch.cat(selected_log_probs, -1)  # batch_size * len(self.decoders)\n        entropies = torch.cat(entropies, 0)  # bs * 1\n\n        if prev_hiddens:\n            archs = torch.cat([selected_archs, archs], -1)\n\n        if with_hidden:\n            return archs, selected_log_probs, entropies, hidden\n\n        return archs, selected_log_probs, entropies\n'"
models_search/shared_gan.py,1,"b""# -*- coding: utf-8 -*-\n# @Date    : 2019-08-15\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\nimport torch.nn as nn\n\nfrom models_search.building_blocks_search import Cell\n\n\nclass Generator(nn.Module):\n    def __init__(self, args):\n        super(Generator, self).__init__()\n        self.args = args\n        self.ch = args.gf_dim\n        self.bottom_width = args.bottom_width\n        self.l1 = nn.Linear(args.latent_dim, (self.bottom_width ** 2) * args.gf_dim)\n        self.cell1 = Cell(args.gf_dim, args.gf_dim, num_skip_in=0)\n        self.cell2 = Cell(args.gf_dim, args.gf_dim, num_skip_in=1)\n        self.cell3 = Cell(args.gf_dim, args.gf_dim, num_skip_in=2)\n        self.to_rgb = nn.Sequential(\n            nn.BatchNorm2d(args.gf_dim),\n            nn.ReLU(),\n            nn.Conv2d(args.gf_dim, 3, 3, 1, 1),\n            nn.Tanh()\n        )\n\n    def set_arch(self, arch_id, cur_stage):\n        if not isinstance(arch_id, list):\n            arch_id = arch_id.to('cpu').numpy().tolist()\n        arch_id = [int(x) for x in arch_id]\n        self.cur_stage = cur_stage\n        arch_stage1 = arch_id[:4]\n        self.cell1.set_arch(conv_id=arch_stage1[0], norm_id=arch_stage1[1], up_id=arch_stage1[2],\n                            short_cut_id=arch_stage1[3], skip_ins=[])\n        if cur_stage >= 1:\n            arch_stage2 = arch_id[4:9]\n            self.cell2.set_arch(conv_id=arch_stage2[0], norm_id=arch_stage2[1], up_id=arch_stage2[2],\n                                short_cut_id=arch_stage2[3], skip_ins=arch_stage2[4])\n\n        if cur_stage == 2:\n            arch_stage3 = arch_id[9:]\n            self.cell3.set_arch(conv_id=arch_stage3[0], norm_id=arch_stage3[1], up_id=arch_stage3[2],\n                                short_cut_id=arch_stage3[3], skip_ins=arch_stage3[4])\n\n    def forward(self, z):\n        h = self.l1(z).view(-1, self.ch, self.bottom_width, self.bottom_width)\n        h1_skip_out, h1 = self.cell1(h)\n        if self.cur_stage == 0:\n            return self.to_rgb(h1)\n        h2_skip_out, h2 = self.cell2(h1, (h1_skip_out,))\n        if self.cur_stage == 1:\n            return self.to_rgb(h2)\n        _, h3 = self.cell3(h2, (h1_skip_out, h2_skip_out))\n        if self.cur_stage == 2:\n            return self.to_rgb(h3)\n\n\ndef _downsample(x):\n    # Downsample (Mean Avg Pooling with 2x2 kernel)\n    return nn.AvgPool2d(kernel_size=2)(x)\n\n\nclass OptimizedDisBlock(nn.Module):\n    def __init__(\n            self,\n            args,\n            in_channels,\n            out_channels,\n            ksize=3,\n            pad=1,\n            activation=nn.ReLU()):\n        super(OptimizedDisBlock, self).__init__()\n        self.activation = activation\n\n        self.c1 = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c2 = nn.Conv2d(\n            out_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c_sc = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=1,\n            padding=0)\n        if args.d_spectral_norm:\n            self.c1 = nn.utils.spectral_norm(self.c1)\n            self.c2 = nn.utils.spectral_norm(self.c2)\n            self.c_sc = nn.utils.spectral_norm(self.c_sc)\n\n    def residual(self, x):\n        h = x\n        h = self.c1(h)\n        h = self.activation(h)\n        h = self.c2(h)\n        h = _downsample(h)\n        return h\n\n    def shortcut(self, x):\n        return self.c_sc(_downsample(x))\n\n    def forward(self, x):\n        return self.residual(x) + self.shortcut(x)\n\n\nclass DisBlock(nn.Module):\n    def __init__(\n            self,\n            args,\n            in_channels,\n            out_channels,\n            hidden_channels=None,\n            ksize=3,\n            pad=1,\n            activation=nn.ReLU(),\n            downsample=False):\n        super(DisBlock, self).__init__()\n        self.activation = activation\n        self.downsample = downsample\n        self.learnable_sc = (in_channels != out_channels) or downsample\n        hidden_channels = in_channels if hidden_channels is None else hidden_channels\n\n        self.c1 = nn.Conv2d(\n            in_channels,\n            hidden_channels,\n            kernel_size=ksize,\n            padding=pad)\n        self.c2 = nn.Conv2d(\n            hidden_channels,\n            out_channels,\n            kernel_size=ksize,\n            padding=pad)\n        if args.d_spectral_norm:\n            self.c1 = nn.utils.spectral_norm(self.c1)\n            self.c2 = nn.utils.spectral_norm(self.c2)\n\n        if self.learnable_sc:\n            self.c_sc = nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=1,\n                padding=0)\n            if args.d_spectral_norm:\n                self.c_sc = nn.utils.spectral_norm(self.c_sc)\n\n    def residual(self, x):\n        h = x\n        h = self.activation(h)\n        h = self.c1(h)\n        h = self.activation(h)\n        h = self.c2(h)\n        if self.downsample:\n            h = _downsample(h)\n        return h\n\n    def shortcut(self, x):\n        if self.learnable_sc:\n            x = self.c_sc(x)\n            if self.downsample:\n                return _downsample(x)\n            else:\n                return x\n        else:\n            return x\n\n    def forward(self, x):\n        return self.residual(x) + self.shortcut(x)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, args, activation=nn.ReLU()):\n        super(Discriminator, self).__init__()\n        self.ch = args.df_dim\n        self.activation = activation\n        self.block1 = OptimizedDisBlock(args, 3, self.ch)\n        self.block2 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=True)\n        self.block3 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=False)\n        self.block4 = DisBlock(\n            args,\n            self.ch,\n            self.ch,\n            activation=activation,\n            downsample=False)\n        self.l5 = nn.Linear(self.ch, 1, bias=False)\n        if args.d_spectral_norm:\n            self.l5 = nn.utils.spectral_norm(self.l5)\n        self.cur_stage = 0\n\n    def forward(self, x):\n        h = x\n        layers = [self.block1, self.block2, self.block3]\n        variable_model = nn.Sequential(*layers[:(self.cur_stage + 1)])\n        h = variable_model(h)\n        h = self.block4(h)\n        h = self.activation(h)\n        # Global average pooling\n        h = h.sum(2).sum(2)\n        output = self.l5(h)\n\n        return output\n"""
utils/__init__.py,0,b'# -*- coding: utf-8 -*-\n# @Date    : 2019-07-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom utils import utils\n'
utils/cal_fid_stat.py,0,"b'# -*- coding: utf-8 -*-\n# @Date    : 2019-07-26\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\n\nimport os\nimport glob\nimport argparse\nimport numpy as np\nfrom imageio import imread\nimport tensorflow as tf\n\nimport utils.fid_score as fid\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--data_path\',\n        type=str,\n        required=True,\n        help=\'set path to training set jpg images dir\')\n    parser.add_argument(\n        \'--output_file\',\n        type=str,\n        default=\'fid_stat/fid_stats_cifar10_train.npz\',\n        help=\'path for where to store the statistics\')\n\n    opt = parser.parse_args()\n    print(opt)\n    return opt\n\n\ndef main():\n    args = parse_args()\n\n    ########\n    # PATHS\n    ########\n    data_path = args.data_path\n    output_path = args.output_file\n    # if you have downloaded and extracted\n    #   http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\n    # set this path to the directory where the extracted files are, otherwise\n    # just set it to None and the script will later download the files for you\n    inception_path = None\n    print(""check for inception model.."", end="" "", flush=True)\n    inception_path = fid.check_or_download_inception(inception_path)  # download inception if necessary\n    print(""ok"")\n\n    # loads all images into memory (this might require a lot of RAM!)\n    print(""load images.."", end="" "", flush=True)\n    image_list = glob.glob(os.path.join(data_path, \'*.jpg\'))\n    images = np.array([imread(str(fn)).astype(np.float32) for fn in image_list])\n    print(""%d images found and loaded"" % len(images))\n\n    print(""create inception graph.."", end="" "", flush=True)\n    fid.create_inception_graph(inception_path)  # load the graph into the current TF graph\n    print(""ok"")\n\n    print(""calculte FID stats.."", end="" "", flush=True)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        mu, sigma = fid.calculate_activation_statistics(images, sess, batch_size=100)\n        np.savez_compressed(output_path, mu=mu, sigma=sigma)\n    print(""finished"")\n\n\nif __name__ == \'__main__\':\n    main()\n'"
utils/fid_score.py,0,"b'#!/usr/bin/env python3\n"""""" Calculates the Frechet Inception Distance (FID) to evaluate GANs.\n\nThe FID metric calculates the distance between two distributions of images.\nTypically, we have summary statistics (mean & covariance matrix) of one\nof these distributions, while the 2nd distribution is given by a GAN.\n\nWhen run as a stand-alone program, it compares the distribution of\nimages that are stored as PNG/JPEG at a specified location with a\ndistribution given by summary statistics (in pickle format).\n\nThe FID is calculated by assuming that X_1 and X_2 are the activations of\nthe pool_3 layer of the inception net for generated samples and real world\nsamples respectively.\n\nSee --help to see further details.\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport os\nimport pathlib\nimport warnings\n\nimport numpy as np\nimport tensorflow as tf\nfrom scipy import linalg\nfrom imageio import imread\n\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\'] = \'3\'\n\n\nclass InvalidFIDException(Exception):\n    pass\n\n\ndef create_inception_graph(pth):\n    """"""Creates a graph from saved GraphDef file.""""""\n    # Creates graph from saved graph_def.pb.\n    with tf.gfile.FastGFile(pth, \'rb\') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        _ = tf.import_graph_def(graph_def, name=\'FID_Inception_Net\')\n\n\n# -------------------------------------------------------------------------------\n\n\n# code for handling inception net derived from\n#   https://github.com/openai/improved-gan/blob/master/inception_score/model.py\ndef _get_inception_layer(sess):\n    """"""Prepares inception net for batched usage and returns pool_3 layer. """"""\n    layername = \'FID_Inception_Net/pool_3:0\'\n    pool3 = sess.graph.get_tensor_by_name(layername)\n    ops = pool3.graph.get_operations()\n    for op_idx, op in enumerate(ops):\n        for o in op.outputs:\n            shape = o.get_shape()\n            if shape._dims != []:\n                shape = [s.value for s in shape]\n                new_shape = []\n                for j, s in enumerate(shape):\n                    if s == 1 and j == 0:\n                        new_shape.append(None)\n                    else:\n                        new_shape.append(s)\n                o.__dict__[\'_shape_val\'] = tf.TensorShape(new_shape)\n    return pool3\n\n\n# -------------------------------------------------------------------------------\n\n\ndef get_activations(images, sess, batch_size=50, verbose=False):\n    """"""Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n                     must lie between 0 and 256.\n    -- sess        : current session\n    -- batch_size  : the images numpy array is split into batches with batch size\n                     batch_size. A reasonable batch size depends on the disposable hardware.\n    -- verbose    : If set to True and parameter out_step is given, the number of calculated\n                     batches is reported.\n    Returns:\n    -- A numpy array of dimension (num images, 2048) that contains the\n       activations of the given tensor when feeding inception with the query tensor.\n    """"""\n    inception_layer = _get_inception_layer(sess)\n    d0 = images.shape[0]\n    if batch_size > d0:\n        print(""warning: batch size is bigger than the data size. setting batch size to data size"")\n        batch_size = d0\n    n_batches = d0 // batch_size\n    n_used_imgs = n_batches * batch_size\n    pred_arr = np.empty((n_used_imgs, 2048))\n    for i in range(n_batches):\n        if verbose:\n            print(""\\rPropagating batch %d/%d"" % (i + 1, n_batches), end="""", flush=True)\n        start = i * batch_size\n        end = start + batch_size\n        batch = images[start:end]\n        pred = sess.run(inception_layer, {\'FID_Inception_Net/ExpandDims:0\': batch})\n        pred_arr[start:end] = pred.reshape(batch_size, -1)\n    if verbose:\n        print("" done"")\n    return pred_arr\n\n\n# -------------------------------------------------------------------------------\n\n\ndef calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n    """"""Numpy implementation of the Frechet Distance.\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n\n    Stable version by Dougal J. Sutherland.\n\n    Params:\n    -- mu1 : Numpy array containing the activations of the pool_3 layer of the\n             inception net ( like returned by the function \'get_predictions\')\n             for generated samples.\n    -- mu2   : The sample mean over activations of the pool_3 layer, precalcualted\n               on an representive data set.\n    -- sigma1: The covariance matrix over activations of the pool_3 layer for\n               generated samples.\n    -- sigma2: The covariance matrix over activations of the pool_3 layer,\n               precalcualted on an representive data set.\n\n    Returns:\n    --   : The Frechet Distance.\n    """"""\n\n    mu1 = np.atleast_1d(mu1)\n    mu2 = np.atleast_1d(mu2)\n\n    sigma1 = np.atleast_2d(sigma1)\n    sigma2 = np.atleast_2d(sigma2)\n\n    assert mu1.shape == mu2.shape, ""Training and test mean vectors have different lengths""\n    assert sigma1.shape == sigma2.shape, ""Training and test covariances have different dimensions""\n\n    diff = mu1 - mu2\n\n    # product might be almost singular\n    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n    if not np.isfinite(covmean).all():\n        msg = ""fid calculation produces singular product; adding %s to diagonal of cov estimates"" % eps\n        warnings.warn(msg)\n        offset = np.eye(sigma1.shape[0]) * eps\n        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n\n    # numerical error might give slight imaginary component\n    if np.iscomplexobj(covmean):\n        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n            m = np.max(np.abs(covmean.imag))\n            raise ValueError(""Imaginary component {}"".format(m))\n        covmean = covmean.real\n\n    tr_covmean = np.trace(covmean)\n\n    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n\n\n# -------------------------------------------------------------------------------\n\n\ndef calculate_activation_statistics(images, sess, batch_size=50, verbose=False):\n    """"""Calculation of the statistics used by the FID.\n    Params:\n    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n                     must lie between 0 and 255.\n    -- sess        : current session\n    -- batch_size  : the images numpy array is split into batches with batch size\n                     batch_size. A reasonable batch size depends on the available hardware.\n    -- verbose     : If set to True and parameter out_step is given, the number of calculated\n                     batches is reported.\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the incption model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the incption model.\n    """"""\n    act = get_activations(images, sess, batch_size, verbose)\n    mu = np.mean(act, axis=0)\n    sigma = np.cov(act, rowvar=False)\n    return mu, sigma\n\n\n# ------------------\n# The following methods are implemented to obtain a batched version of the activations.\n# This has the advantage to reduce memory requirements, at the cost of slightly reduced efficiency.\n# - Pyrestone\n# ------------------\n\n\ndef load_image_batch(files):\n    """"""Convenience method for batch-loading images\n    Params:\n    -- files    : list of paths to image files. Images need to have same dimensions for all files.\n    Returns:\n    -- A numpy array of dimensions (num_images,hi, wi, 3) representing the image pixel values.\n    """"""\n    return np.array([imread(str(fn)).astype(np.float32) for fn in files])\n\n\ndef get_activations_from_files(files, sess, batch_size=50, verbose=False):\n    """"""Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- files      : list of paths to image files. Images need to have same dimensions for all files.\n    -- sess        : current session\n    -- batch_size  : the images numpy array is split into batches with batch size\n                     batch_size. A reasonable batch size depends on the disposable hardware.\n    -- verbose    : If set to True and parameter out_step is given, the number of calculated\n                     batches is reported.\n    Returns:\n    -- A numpy array of dimension (num images, 2048) that contains the\n       activations of the given tensor when feeding inception with the query tensor.\n    """"""\n    inception_layer = _get_inception_layer(sess)\n    d0 = len(files)\n    if batch_size > d0:\n        print(""warning: batch size is bigger than the data size. setting batch size to data size"")\n        batch_size = d0\n    n_batches = d0 // batch_size\n    n_used_imgs = n_batches * batch_size\n    pred_arr = np.empty((n_used_imgs, 2048))\n    for i in range(n_batches):\n        if verbose:\n            print(""\\rPropagating batch %d/%d"" % (i + 1, n_batches), end="""", flush=True)\n        start = i * batch_size\n        end = start + batch_size\n        batch = load_image_batch(files[start:end])\n        pred = sess.run(inception_layer, {\'FID_Inception_Net/ExpandDims:0\': batch})\n        pred_arr[start:end] = pred.reshape(batch_size, -1)\n        del batch  # clean up memory\n    if verbose:\n        print("" done"")\n    return pred_arr\n\n\ndef calculate_activation_statistics_from_files(files, sess, batch_size=50, verbose=False):\n    """"""Calculation of the statistics used by the FID.\n    Params:\n    -- files      : list of paths to image files. Images need to have same dimensions for all files.\n    -- sess        : current session\n    -- batch_size  : the images numpy array is split into batches with batch size\n                     batch_size. A reasonable batch size depends on the available hardware.\n    -- verbose     : If set to True and parameter out_step is given, the number of calculated\n                     batches is reported.\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the incption model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the incption model.\n    """"""\n    act = get_activations_from_files(files, sess, batch_size, verbose)\n    mu = np.mean(act, axis=0)\n    sigma = np.cov(act, rowvar=False)\n    return mu, sigma\n\n\n# -------------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------------\n# The following functions aren\'t needed for calculating the FID\n# they\'re just here to make this module work as a stand-alone script\n# for calculating FID scores\n# -------------------------------------------------------------------------------\ndef check_or_download_inception(inception_path):\n    """""" Checks if the path to the inception file is valid, or downloads\n        the file if it is not present. """"""\n    INCEPTION_URL = \'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\'\n    if inception_path is None:\n        inception_path = \'/tmp\'\n    inception_path = pathlib.Path(inception_path)\n    model_file = inception_path / \'classify_image_graph_def.pb\'\n    if not model_file.exists():\n        print(""Downloading Inception model"")\n        from urllib import request\n        import tarfile\n        fn, _ = request.urlretrieve(INCEPTION_URL)\n        with tarfile.open(fn, mode=\'r\') as f:\n            f.extract(\'classify_image_graph_def.pb\', str(model_file.parent))\n    return str(model_file)\n\n\ndef _handle_path(path, sess, low_profile=False):\n    if path.endswith(\'.npz\'):\n        f = np.load(path)\n        m, s = f[\'mu\'][:], f[\'sigma\'][:]\n        f.close()\n    else:\n        path = pathlib.Path(path)\n        files = list(path.glob(\'*.jpg\')) + list(path.glob(\'*.png\'))\n        if low_profile:\n            m, s = calculate_activation_statistics_from_files(files, sess)\n        else:\n            x = np.array([imread(str(fn)).astype(np.float32) for fn in files])\n            m, s = calculate_activation_statistics(x, sess)\n            del x  # clean up memory\n    return m, s\n\n\ndef calculate_fid_given_paths(paths, inception_path, low_profile=False):\n    """""" Calculates the FID of two paths. """"""\n    # inception_path = check_or_download_inception(inception_path)\n\n    for p in paths:\n        if not os.path.exists(p):\n            raise RuntimeError(""Invalid path: %s"" % p)\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        m1, s1 = _handle_path(paths[0], sess, low_profile=low_profile)\n        m2, s2 = _handle_path(paths[1], sess, low_profile=low_profile)\n        fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n    sess.close()\n\n    return fid_value\n'"
utils/inception_score.py,0,"b'# Code derived from tensorflow/tensorflow/models/image/imagenet/classify_image.py\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport os\nimport os.path\nimport sys\nimport tarfile\n\nimport numpy as np\nimport tensorflow as tf\nfrom six.moves import urllib\nfrom tqdm import tqdm\n\n\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\'] = \'3\'\nMODEL_DIR = \'/tmp/imagenet\'\nDATA_URL = \'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\'\nsoftmax = None\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\n\n\n# Call this function with list of images. Each of elements should be a\n# numpy array with values ranging from 0 to 255.\ndef get_inception_score(images, splits=10):\n    assert (type(images) == list)\n    assert (type(images[0]) == np.ndarray)\n    assert (len(images[0].shape) == 3)\n    assert (np.max(images[0]) > 10)\n    assert (np.min(images[0]) >= 0.0)\n    inps = []\n    for img in images:\n        img = img.astype(np.float32)\n        inps.append(np.expand_dims(img, 0))\n    bs = 100\n    with tf.Session(config=config) as sess:\n        preds = []\n        n_batches = int(math.ceil(float(len(inps)) / float(bs)))\n        for i in tqdm(range(n_batches), desc=""Calculate inception score""):\n            sys.stdout.flush()\n            inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\n            inp = np.concatenate(inp, 0)\n            pred = sess.run(softmax, {\'ExpandDims:0\': inp})\n            preds.append(pred)\n        preds = np.concatenate(preds, 0)\n        scores = []\n        for i in range(splits):\n            part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n            kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n            kl = np.mean(np.sum(kl, 1))\n            scores.append(np.exp(kl))\n\n        sess.close()\n    return np.mean(scores), np.std(scores)\n\n\n# This function is called automatically.\ndef _init_inception():\n    global softmax\n    if not os.path.exists(MODEL_DIR):\n        os.makedirs(MODEL_DIR)\n    filename = DATA_URL.split(\'/\')[-1]\n    filepath = os.path.join(MODEL_DIR, filename)\n    if not os.path.exists(filepath):\n        def _progress(count, block_size, total_size):\n            sys.stdout.write(\'\\r>> Downloading %s %.1f%%\' % (\n                filename, float(count * block_size) / float(total_size) * 100.0))\n            sys.stdout.flush()\n\n        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n        print()\n        statinfo = os.stat(filepath)\n        print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n    tarfile.open(filepath, \'r:gz\').extractall(MODEL_DIR)\n    with tf.gfile.FastGFile(os.path.join(\n            MODEL_DIR, \'classify_image_graph_def.pb\'), \'rb\') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        _ = tf.import_graph_def(graph_def, name=\'\')\n    # Works with an arbitrary minibatch size.\n    with tf.Session(config=config) as sess:\n        pool3 = sess.graph.get_tensor_by_name(\'pool_3:0\')\n        ops = pool3.graph.get_operations()\n        for op_idx, op in enumerate(ops):\n            for o in op.outputs:\n                shape = o.get_shape()\n                if shape._dims != []:\n                    shape = [s.value for s in shape]\n                    new_shape = []\n                    for j, s in enumerate(shape):\n                        if s == 1 and j == 0:\n                            new_shape.append(None)\n                        else:\n                            new_shape.append(s)\n                    o.__dict__[\'_shape_val\'] = tf.TensorShape(new_shape)\n        w = sess.graph.get_operation_by_name(""softmax/logits/MatMul"").inputs[1]\n        logits = tf.matmul(tf.squeeze(pool3, [1, 2]), w)\n        softmax = tf.nn.softmax(logits)\n        sess.close()\n'"
utils/utils.py,2,"b'# -*- coding: utf-8 -*-\n# @Date    : 2019-07-25\n# @Author  : Xinyu Gong (xy_gong@tamu.edu)\n# @Link    : None\n# @Version : 0.0\n\nimport collections\nimport logging\nimport math\nimport os\nimport time\nfrom datetime import datetime\n\nimport dateutil.tz\nimport torch\n\n\ndef create_logger(log_dir, phase=\'train\'):\n    time_str = time.strftime(\'%Y-%m-%d-%H-%M\')\n    log_file = \'{}_{}.log\'.format(time_str, phase)\n    final_log_file = os.path.join(log_dir, log_file)\n    head = \'%(asctime)-15s %(message)s\'\n    logging.basicConfig(filename=str(final_log_file),\n                        format=head)\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n    console = logging.StreamHandler()\n    logging.getLogger(\'\').addHandler(console)\n\n    return logger\n\n\ndef set_log_dir(root_dir, exp_name):\n    path_dict = {}\n    os.makedirs(root_dir, exist_ok=True)\n\n    # set log path\n    exp_path = os.path.join(root_dir, exp_name)\n    now = datetime.now(dateutil.tz.tzlocal())\n    timestamp = now.strftime(\'%Y_%m_%d_%H_%M_%S\')\n    prefix = exp_path + \'_\' + timestamp\n    os.makedirs(prefix)\n    path_dict[\'prefix\'] = prefix\n\n    # set checkpoint path\n    ckpt_path = os.path.join(prefix, \'Model\')\n    os.makedirs(ckpt_path)\n    path_dict[\'ckpt_path\'] = ckpt_path\n\n    log_path = os.path.join(prefix, \'Log\')\n    os.makedirs(log_path)\n    path_dict[\'log_path\'] = log_path\n\n    # set sample image path for fid calculation\n    sample_path = os.path.join(prefix, \'Samples\')\n    os.makedirs(sample_path)\n    path_dict[\'sample_path\'] = sample_path\n\n    return path_dict\n\n\ndef save_checkpoint(states, is_best, output_dir,\n                    filename=\'checkpoint.pth\'):\n    torch.save(states, os.path.join(output_dir, filename))\n    if is_best:\n        torch.save(states, os.path.join(output_dir, \'checkpoint_best.pth\'))\n\n\nclass RunningStats:\n    def __init__(self, WIN_SIZE):\n        self.mean = 0\n        self.run_var = 0\n        self.WIN_SIZE = WIN_SIZE\n\n        self.window = collections.deque(maxlen=WIN_SIZE)\n\n    def clear(self):\n        self.window.clear()\n        self.mean = 0\n        self.run_var = 0\n\n    def is_full(self):\n        return len(self.window) == self.WIN_SIZE\n\n    def push(self, x):\n\n        if len(self.window) == self.WIN_SIZE:\n            # Adjusting variance\n            x_removed = self.window.popleft()\n            self.window.append(x)\n            old_m = self.mean\n            self.mean += (x - x_removed) / self.WIN_SIZE\n            self.run_var += (x + x_removed - old_m - self.mean) * (x - x_removed)\n        else:\n            # Calculating first variance\n            self.window.append(x)\n            delta = x - self.mean\n            self.mean += delta / len(self.window)\n            self.run_var += delta * (x - self.mean)\n\n    def get_mean(self):\n        return self.mean if len(self.window) else 0.0\n\n    def get_var(self):\n        return self.run_var / len(self.window) if len(self.window) > 1 else 0.0\n\n    def get_std(self):\n        return math.sqrt(self.get_var())\n\n    def get_all(self):\n        return list(self.window)\n\n    def __str__(self):\n        return ""Current window values: {}"".format(list(self.window))\n'"
