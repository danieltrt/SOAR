file_path,api_count,code
train.py,4,"b'import sys\nimport auxiliary.argument_parser as argument_parser\nimport auxiliary.my_utils as my_utils\nimport time\nimport torch\nfrom auxiliary.my_utils import yellow_print\n\n""""""\nMain training script.\nauthor : Thibault Groueix 01.11.2019\n""""""\n\nopt = argument_parser.parser()\ntorch.cuda.set_device(opt.multi_gpu[0])\nmy_utils.plant_seeds(random_seed=opt.random_seed)\nimport training.trainer as trainer\n\ntrainer = trainer.Trainer(opt)\ntrainer.build_dataset()\ntrainer.build_network()\ntrainer.build_optimizer()\ntrainer.build_losses()\ntrainer.start_train_time = time.time()\n\nif opt.demo:\n    with torch.no_grad():\n        trainer.demo(opt.demo_input_path)\n    sys.exit(0)\n\nif opt.run_single_eval:\n    with torch.no_grad():\n        trainer.test_epoch()\n    sys.exit(0)\n\nfor epoch in range(trainer.epoch, opt.nepoch):\n    trainer.train_epoch()\n    with torch.no_grad():\n        trainer.test_epoch()\n    trainer.dump_stats()\n    trainer.increment_epoch()\n    trainer.save_network()\n\nyellow_print(f""Visdom url http://localhost:{trainer.opt.visdom_port}/"")\nyellow_print(f""Netvision report url http://localhost:{trainer.opt.http_port}/{trainer.opt.dir_name}/index.html"")\nyellow_print(f""Training time {(time.time() - trainer.start_time)//60} minutes."")\n'"
auxiliary/__init__.py,0,b''
auxiliary/argument_parser.py,0,"b'import argparse\nimport auxiliary.my_utils as my_utils\nimport os\nimport datetime\nimport json\nfrom termcolor import colored\nfrom easydict import EasyDict\nfrom os.path import exists, join\n\n""""""\n    Author : Thibault Groueix 01.11.2019\n""""""\n\n\ndef parser():\n    parser = argparse.ArgumentParser()\n\n    # Training parameters\n    parser.add_argument(""--no_learning"", action=""store_true"", help=""Learning mode (batchnorms...)"")\n    parser.add_argument(""--train_only_encoder"", action=""store_true"", help=""only train the encoder"")\n    parser.add_argument(\'--batch_size\', type=int, default=32, help=\'input batch size\')\n    parser.add_argument(\'--batch_size_test\', type=int, default=32, help=\'input batch size\')\n    parser.add_argument(\'--workers\', type=int, help=\'number of data loading workers\', default=0)\n    parser.add_argument(\'--nepoch\', type=int, default=150, help=\'number of epochs to train for\')\n    parser.add_argument(\'--start_epoch\', type=int, default=0, help=\'number of epochs to train for\')\n    parser.add_argument(""--random_seed"", action=""store_true"", help=""Fix random seed or not"")\n    parser.add_argument(\'--lrate\', type=float, default=0.001, help=\'learning rate\')\n    parser.add_argument(\'--lr_decay_1\', type=int, default=120, help=\'learning rate decay 1\')\n    parser.add_argument(\'--lr_decay_2\', type=int, default=140, help=\'learning rate decay 2\')\n    parser.add_argument(\'--lr_decay_3\', type=int, default=145, help=\'learning rate decay 2\')\n    parser.add_argument(""--run_single_eval"", action=""store_true"", help=""evaluate a trained network"")\n    parser.add_argument(""--demo"", action=""store_true"", help=""run demo autoencoder or single-view"")\n\n    # Data\n    parser.add_argument(\'--normalization\', type=str, default=""UnitBall"",\n                        choices=[\'UnitBall\', \'BoundingBox\', \'Identity\'])\n    parser.add_argument(""--shapenet13"", action=""store_true"", help=""Load 13 usual shapenet categories"")\n    parser.add_argument(""--SVR"", action=""store_true"", help=""Single_view Reconstruction"")\n    parser.add_argument(""--sample"", action=""store_false"", help=""Sample the input pointclouds"")\n    parser.add_argument(\'--class_choice\', nargs=\'+\', default=[""airplane""], type=str)\n    parser.add_argument(\'--number_points\', type=int, default=2500, help=\'Number of point sampled on the object during training, and generated by atlasnet\')\n    parser.add_argument(\'--number_points_eval\', type=int, default=2500,\n                        help=\'Number of points generated by atlasnet (rounded to the nearest squared number) \')\n    parser.add_argument(""--random_rotation"", action=""store_true"", help=""apply data augmentation : random rotation"")\n    parser.add_argument(""--data_augmentation_axis_rotation"", action=""store_true"",\n                        help=""apply data augmentation : axial rotation "")\n    parser.add_argument(""--data_augmentation_random_flips"", action=""store_true"",\n                        help=""apply data augmentation : random flips"")\n    parser.add_argument(""--random_translation"", action=""store_true"",\n                        help=""apply data augmentation :  random translation "")\n    parser.add_argument(""--anisotropic_scaling"", action=""store_true"",\n                        help=""apply data augmentation : anisotropic scaling"")\n\n    # Save dirs and reload\n    parser.add_argument(\'--id\', type=str, default=""0"", help=\'training name\')\n    parser.add_argument(\'--env\', type=str, default=""Atlasnet"", help=\'visdom environment\')\n    parser.add_argument(\'--visdom_port\', type=int, default=8890, help=""visdom port"")\n    parser.add_argument(\'--http_port\', type=int, default=8891, help=""http port"")\n    parser.add_argument(\'--dir_name\', type=str, default="""", help=\'name of the log folder.\')\n    parser.add_argument(\'--demo_input_path\', type=str, default=""./doc/pictures/plane_input_demo.png"", help=\'dirname\')\n    parser.add_argument(\'--reload_decoder_path\', type=str, default="""", help=\'dirname\')\n    parser.add_argument(\'--reload_model_path\', type=str, default=\'\', help=\'optional reload model path\')\n\n    # Network\n    parser.add_argument(\'--num_layers\', type=int, default=2, help=\'number of hidden MLP Layer\')\n    parser.add_argument(\'--hidden_neurons\', type=int, default=512, help=\'number of neurons in each hidden layer\')\n    parser.add_argument(\'--loop_per_epoch\', type=int, default=1, help=\'number of data loop per epoch\')\n    parser.add_argument(\'--nb_primitives\', type=int, default=1, help=\'number of primitives\')\n    parser.add_argument(\'--template_type\', type=str, default=""SPHERE"", choices=[""SPHERE"", ""SQUARE""],\n                        help=\'dim_out_patch\')\n    parser.add_argument(\'--multi_gpu\', nargs=\'+\', type=int, default=[0], help=\'Use multiple gpus\')\n    parser.add_argument(""--remove_all_batchNorms"", action=""store_true"", help=""Replace all batchnorms by identity"")\n    parser.add_argument(\'--bottleneck_size\', type=int, default=1024, help=\'dim_out_patch\')\n    parser.add_argument(\'--activation\', type=str, default=\'relu\',\n                        choices=[""relu"", ""sigmoid"", ""softplus"", ""logsigmoid"", ""softsign"", ""tanh""], help=\'dim_out_patch\')\n\n    # Loss\n    parser.add_argument(""--no_metro"", action=""store_true"", help=""Compute metro distance"")\n\n    opt = parser.parse_args()\n\n    opt.date = str(datetime.datetime.now())\n    now = datetime.datetime.now()\n    opt = EasyDict(opt.__dict__)\n\n    if opt.dir_name == """":\n        # Create default dirname\n        opt.dir_name = join(\'log\', opt.id + now.isoformat())\n\n\n    # If running a demo, check if input is an image or a pointcloud\n    if opt.demo:\n        ext = opt.demo_input_path.split(\'.\')[-1]\n        if ext == ""ply"" or ext == ""npy"" or ext == ""obj"":\n            opt.SVR = False\n        elif ext == ""png"":\n            opt.SVR = True\n\n    if opt.demo or opt.run_single_eval:\n        if not exists(""./training/trained_models/atlasnet_singleview_25_squares/network.pth""):\n            print(""Dowload Trained Models."")\n            os.system(""chmod +x training/download_trained_models.sh"")\n            os.system(""./training/download_trained_models.sh"")\n\n        if opt.reload_model_path == """" and opt.SVR:\n            opt.dir_name = ""./training/trained_models/atlasnet_singleview_1_sphere""\n        elif opt.reload_model_path == """" and not opt.SVR:\n            opt.dir_name = ""./training/trained_models/atlasnet_autoencoder_1_sphere""\n\n\n    if exists(join(opt.dir_name, ""options.json"")):\n        # Reload parameters from options.txt if it exists\n        with open(join(opt.dir_name, ""options.json""), \'r\') as f:\n            my_opt_dict = json.load(f)\n        my_opt_dict.pop(""run_single_eval"")\n        my_opt_dict.pop(""no_metro"")\n        my_opt_dict.pop(""train_only_encoder"")\n        my_opt_dict.pop(""no_learning"")\n        my_opt_dict.pop(""demo"")\n        my_opt_dict.pop(""demo_input_path"")\n        my_opt_dict.pop(""dir_name"")\n        for key in my_opt_dict.keys():\n            opt[key] = my_opt_dict[key]\n        if not opt.demo:\n            print(""Modifying input arguments to match network in dirname"")\n            my_utils.cyan_print(""PARAMETER: "")\n            for a in my_opt_dict:\n                print(\n                    ""         ""\n                    + colored(a, ""yellow"")\n                    + "" : ""\n                    + colored(str(my_opt_dict[a]), ""cyan"")\n                )\n\n    # Hard code dimension of the template.\n    dim_template_dict = {\n        ""SQUARE"": 2,\n        ""SPHERE"": 3,\n    }\n    opt.dim_template = dim_template_dict[opt.template_type]\n\n    # Visdom env\n    opt.env = opt.env + opt.dir_name.split(\'/\')[-1]\n\n    return opt\n'"
auxiliary/html_report.py,0,"b'import sys\nsys.path.append(\'./auxiliary/netvision/\')\nimport HtmlGenerator\nimport os\nfrom copy import deepcopy\nimport auxiliary.init_html_report as init_html_report\n\n\ndef main(trainer, outHtml=None):\n    """"""\n    Create a report for the completed experiment.\n    Author : Thibault Groueix 01.11.2019\n    """"""\n\n    if outHtml is None:\n        outHtml = os.path.join(trainer.opt.dir_name, f""{trainer.epoch}"") + \'.html\'\n    else:\n        outHtml = os.path.join(trainer.opt.dir_name, outHtml)\n\n    webpage = HtmlGenerator.HtmlGenerator(path=outHtml, title=trainer.opt.dir_name, local_copy=True)\n\n    # Display loss at the top in a title\n    loss_val = trainer.log.meters[""loss_val""].avg\n    final_fscore = trainer.html_report_data.fscore_curve[""fscore""][-1]\n    webpage.add_title(f""Reconstruction (Val):{loss_val} Metro:{trainer.metro_results} Fscore:{final_fscore}"")\n\n    table = webpage.add_table()\n\n    # Add all parameters for the experiments and training curves\n    table2 = deepcopy(table)\n    table2.add_titleless_columns(1)\n    table.add_titleless_columns(2)\n    curve_recons = webpage.chart(trainer.html_report_data.data_curve, title=""Reconstruction quality - chamfer log"")\n    table2.add_row([curve_recons])\n    curve_recons = webpage.chart(trainer.html_report_data.fscore_curve, title=""Reconstruction quality - fscore"")\n    table2.add_row([curve_recons])\n\n    table.add_row([webpage.dict(trainer.opt), table2], """")\n\n    # Add random test samples the experiments and training curves\n    for i in range(3):\n        output_mesh = trainer.html_report_data.output_meshes[i]\n        table.add_row([webpage.image(output_mesh[""image_path""]),\n                       webpage.mesh(output_mesh[""output_path""], normalize=True)], """")\n\n    webpage.return_html()\n\n    # Add main results in master webpage\n    if not os.path.exists(""master.pkl""):\n        init_html_report.main()\n    webpage_after = HtmlGenerator.HtmlGenerator(path=""master.html"", reload_path=""master.pkl"")\n    webpage_after.tables[""Shapenet""].add_row([\n        f""{trainer.opt.nb_primitives}"",\n        f""{trainer.opt.template_type}"",\n        f""{loss_val}"",\n        f""{final_fscore}"",\n        f""{trainer.metro_results}"",\n        trainer.opt.dir_name\n    ])\n    webpage_after.return_html(save_editable_version=True)\n'"
auxiliary/init_html_report.py,0,"b'import sys\n\nsys.path.append(\'./auxiliary/netvision/\')\nfrom HtmlGenerator import HtmlGenerator\n\n\ndef main():\n    """"""\n    Create a master webpage to summurize results of all experiments.\n    Author : Thibault Groueix 01.11.2019\n    """"""\n    webpage = HtmlGenerator(path=""master.html"")\n\n    for dataset in [""Shapenet""]:\n        table = webpage.add_table(dataset)\n        table.add_column(""Num Primitives"")\n        table.add_column(""Decoder"")\n        table.add_column(""Chamfer"")\n        table.add_column(""F-Score"")\n        table.add_column(""Metro"")\n        table.add_column(""Dirname"")\n\n    webpage.return_html(save_editable_version=True)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
auxiliary/meter.py,0,"b'import numpy as np\nfrom termcolor import colored\nimport matplotlib.pyplot as plt\nimport os\n\n\nclass AverageValueMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0.0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\nclass Logs(object):\n    """"""\n    Author : Thibault Groueix 01.11.2019\n    """"""\n\n    def __init__(self, curves=[]):\n        self.curves_names = curves\n        self.curves = {}\n        self.meters = {}\n        self.current_epoch = {}\n        for name in self.curves_names:\n            self.curves[name] = []\n            self.meters[name] = AverageValueMeter()\n\n    def end_epoch(self):\n        """"""\n        Add meters average in average list and keep in current_epoch the current statistics\n        :return:\n        """"""\n        for name in self.curves_names:\n            self.curves[name].append(self.meters[name].avg)\n            if len(name) < 20:\n                print(colored(name, \'yellow\') + "" "" + colored(f""{self.meters[name].avg}"", \'cyan\'))\n\n            self.current_epoch[name] = self.meters[name].avg\n\n    def reset(self):\n        """"""\n        Reset all meters\n        :return:\n        """"""\n        for name in self.curves_names:\n            self.meters[name].reset()\n\n    def update(self, name, val):\n        """"""\n        :param name: meter name\n        :param val: new value to add\n        :return: void\n        """"""\n        if not name in self.curves_names:\n            print(f""adding {name} to the log curves to display"")\n            self.meters[name] = AverageValueMeter()\n            self.curves[name] = []\n            self.curves_names.append(name)\n        try:\n            self.meters[name].update(val.item())\n        except:\n            self.meters[name].update(val)\n\n    @staticmethod\n    def stack_numpy_array(A, B):\n        if A is None:\n            return B\n        else:\n            return np.column_stack((A, B))\n\n    def plot_bar(self, vis, name):\n        vis.bar(self.meters[name].avg, win=\'barplot\')  # Here\n\n    def update_curves(self, vis, path):\n        X_Loss = None\n        Y_Loss = None\n        Names_Loss = []\n\n        for name in self.curves_names:\n            if name[:4] == ""loss"":\n                Names_Loss.append(name)\n                X_Loss = self.stack_numpy_array(X_Loss, np.arange(len(self.curves[name])))\n                Y_Loss = self.stack_numpy_array(Y_Loss, np.array(self.curves[name]))\n\n            else:\n                pass\n\n        vis.line(X=X_Loss,\n                 Y=Y_Loss,\n                 win=\'loss\',\n                 opts=dict(title=""loss"", legend=Names_Loss))\n\n        vis.line(X=X_Loss,\n                 Y=np.log(Y_Loss),\n                 win=\'log\',\n                 opts=dict(title=""log"", legend=Names_Loss))\n        try:\n            vis.line(X=np.arange(len(self.curves[""fscore""])),\n                     Y=self.curves[""fscore""],\n                     win=\'fscore\',\n                     opts=dict(title=""fscore""))\n        except:\n            pass\n        # Save figures in PNGs\n        plt.figure()\n        for i in range(X_Loss.shape[1]):\n            plt.plot(X_Loss[:, i], Y_Loss[:, i], label=Names_Loss[i])\n        plt.title(\'Curves\')\n        plt.legend()\n        plt.savefig(os.path.join(path, ""curve.png""))\n\n        plt.figure()\n        for i in range(X_Loss.shape[1]):\n            plt.plot(X_Loss[:, i], np.log(Y_Loss[:, i]), label=Names_Loss[i])\n        plt.title(\'Curves in Log\')\n        plt.legend()\n        plt.savefig(os.path.join(path, ""curve_log.png""))\n'"
auxiliary/my_utils.py,1,"b'import random\nimport numpy as np\nimport torch\nfrom termcolor import colored\n\n\n""""""\n    Author : Thibault Groueix 01.11.2019\n""""""\n\ndef grey_print(x):\n    print(colored(x, ""grey""))\n\n\ndef red_print(x):\n    print(colored(x, ""red""))\n\n\ndef green_print(x):\n    print(colored(x, ""green""))\n\n\ndef yellow_print(x):\n    print(colored(x, ""yellow""))\n\n\ndef blue_print(x):\n    print(colored(x, ""blue""))\n\n\ndef magenta_print(x):\n    print(colored(x, ""magenta""))\n\n\ndef cyan_print(x):\n    print(colored(x, ""cyan""))\n\n\ndef white_print(x):\n    print(colored(x, ""white""))\n\n\ndef print_arg(opt):\n    cyan_print(""PARAMETER: "")\n    for a in opt.__dict__:\n        print(\n            ""         ""\n            + colored(a, ""yellow"")\n            + "" : ""\n            + colored(str(opt.__dict__[a]), ""cyan"")\n        )\n\ndef plant_seeds(random_seed=False):\n    if random_seed:\n        print(""Randomized seed"")\n        manualSeed = random.randint(1, 10000)\n        print(""Random Seed: "", manualSeed)\n\n    else:\n        manualSeed = 1\n    random.seed(manualSeed)\n    torch.manual_seed(manualSeed)\n    np.random.seed(manualSeed)\n'"
auxiliary/visualization.py,0,"b'import visdom\nimport os\nimport sys\nimport time\n\n""""""\n    Author : Thibault Groueix 01.11.2019\n""""""\n\n\ndef is_port_in_use(port):\n    """"""\n    test if a port is being used or is free to use.\n    :param port:\n    :return:\n    """"""\n    import socket\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        return s.connect_ex((\'localhost\', port)) == 0\n\n\nclass Visualizer(object):\n    def __init__(self, visdom_port, env, http_port):\n        super(Visualizer, self).__init__()\n        # Create Visdom Server\n        try:\n            if not is_port_in_use(visdom_port):\n                print(f""Launching new visdom instance in port {visdom_port}"")\n                cmd = f""{sys.executable} -m visdom.server -p {visdom_port} > /dev/null 2>&1""\n                CMD = f\'TMUX=0 tmux new-session -d -s visdom_server \\; send-keys ""{cmd}"" Enter\'\n                print(CMD)\n                os.system(CMD)\n                time.sleep(2)\n        except:\n            print(""coudn\'t set up visdom server."")\n\n        try:\n            # Create Http Server\n            if not is_port_in_use(http_port):\n                print(f""Launching new HTTP instance in port {http_port}"")\n                cmd = f""{sys.executable} -m http.server -p {http_port} > /dev/null 2>&1""\n                CMD = f\'TMUX=0 tmux new-session -d -s http_server \\; send-keys ""{cmd}"" Enter\'\n                print(CMD)\n                os.system(CMD)\n        except:\n            print(""couldn\'t set up http server."")\n\n        self.visdom_port = visdom_port\n        self.http_port = http_port\n\n        vis = visdom.Visdom(port=visdom_port, env=env)\n        self.vis = vis\n\n    def show_pointcloud(self, points, title=None, Y=None):\n        """"""\n        :param points: pytorch tensor pointcloud\n        :param title:\n        :param Y:\n        :return:\n        """"""\n        points = points.squeeze()\n        if points.size(-1) == 3:\n            points = points.contiguous().data.cpu()\n        else:\n            points = points.transpose(0, 1).contiguous().data.cpu()\n\n        opts = dict(\n            title=title,\n            markersize=2,\n            xtickmin=-0.7,\n            xtickmax=0.7,\n            xtickstep=0.3,\n            ytickmin=-0.7,\n            ytickmax=0.7,\n            ytickstep=0.3,\n            ztickmin=-0.7,\n            ztickmax=0.7,\n            ztickstep=0.3)\n\n        if Y is None:\n            self.vis.scatter(X=points, win=title, opts=opts)\n        else:\n            if Y.min() < 1:\n                Y = Y - Y.min() + 1\n            self.vis.scatter(\n                X=points, Y=Y, win=title, opts=opts\n            )\n\n    def show_pointclouds(self, points, title=None, Y=None):\n        points = points.squeeze()\n        assert points.dim() == 3\n        for i in range(points.size(0)):\n            self.show_pointcloud(points[i], title=title)\n\n    def show_image(self, img, title=None):\n        img = img.squeeze()\n        self.vis.image(img, win=title, opts=dict(title=title))\n'"
dataset/augmenter.py,0,"b'import dataset.pointcloud_processor as pointcloud_processor\n\n\nclass Augmenter(object):\n    """"""\n    Class defining data augmentation for a batch of points.\n    Author : Thibault Groueix 01.11.2019\n    """"""\n    def __init__(self, translation=False, rotation_axis=[], rotation_3D=False, anisotropic_scaling=False, flips=[]):\n        self.translation = translation\n        self.rotation_axis = rotation_axis\n        self.rotation_3D = rotation_3D\n        self.anisotropic_scaling = anisotropic_scaling\n        self.flips = flips\n\n    def __call__(self, points):\n        operation = pointcloud_processor.DataAugmentation(points)\n        for axis in self.rotation_axis:\n            operation.random_axial_rotation(axis=axis)\n        if self.rotation_3D:\n            operation.random_rotation()\n        if self.anisotropic_scaling:\n            operation.random_anisotropic_scaling()\n        if len(self.flips) > 0:\n            operation.random_flips(self.flips)\n        if self.translation:\n            operation.random_translation()\n'"
dataset/dataset_shapenet.py,6,"b'import torch.utils.data as data\nimport os.path\nimport torch\nimport torchvision.transforms as transforms\nimport numpy as np\nimport os\nfrom PIL import Image\nimport auxiliary.my_utils as my_utils\nimport pickle\nfrom os.path import join, dirname, exists\nfrom easydict import EasyDict\nimport json\nfrom termcolor import colored\nimport dataset.pointcloud_processor as pointcloud_processor\nfrom copy import deepcopy\n\nclass ShapeNet(data.Dataset):\n    """"""\n    Shapenet Dataloader\n    Uses Shapenet V1\n    Make sure to respect shapenet Licence.\n    Author : Thibault Groueix 01.11.2019\n    """"""\n\n    def __init__(self, opt, train=True):\n        self.opt = opt\n        self.num_sample = opt.number_points if train else 2500\n        self.train = train\n        self.init_normalization()\n        self.init_singleview()\n\n        if not opt.demo:\n            my_utils.red_print(\'Create Shapenet Dataset...\')\n            # Define core path array\n            self.datapath = []\n            self.category_datapath = {}\n\n\n            # Load classes\n            self.pointcloud_path = join(dirname(__file__), \'data/ShapeNetV1PointCloud\')\n            self.image_path = join(dirname(__file__), \'data/ShapeNetV1Renderings\')\n\n            # Load taxonomy file\n            self.taxonomy_path = join(dirname(__file__), \'data/taxonomy.json\')\n            if not exists(self.taxonomy_path):\n                os.system(""chmod +x dataset/download_shapenet_pointclouds.sh"")\n                os.system(""./dataset/download_shapenet_pointclouds.sh"")\n\n            self.classes = [x for x in next(os.walk(self.pointcloud_path))[1]]\n            with open(self.taxonomy_path, \'r\') as f:\n                self.taxonomy = json.load(f)\n\n            self.id2names = {}\n            self.names2id = {}\n            for dict_class in self.taxonomy:\n                if dict_class[\'synsetId\'] in self.classes:\n                    name = dict_class[\'name\'].split(sep=\',\')[0]\n                    self.id2names[dict_class[\'synsetId\']] = name\n                    self.names2id[name] = dict_class[\'synsetId\']\n\n            # Select classes\n            if opt.shapenet13:\n                opt.class_choice = [""airplane"", ""bench"", ""cabinet"", ""car"", ""chair"", ""display"", ""lamp"", ""loudspeaker"",\n                                    ""rifle"", ""sofa"", ""table"", ""telephone"", ""vessel""]\n\n            if len(opt.class_choice) > 0:\n                new_classes = []\n                for category in opt.class_choice:\n                    new_classes.append(self.names2id[category])\n                self.classes = new_classes\n\n            # Create Cache path\n            self.path_dataset = join(dirname(__file__), \'data\', \'cache\')\n            if not exists(self.path_dataset):\n                os.mkdir(self.path_dataset)\n            self.path_dataset = join(self.path_dataset,\n                                     self.opt.normalization + str(train) + ""_"".join(self.opt.class_choice))\n\n            if not exists(self.image_path):\n                os.system(""chmod +x dataset/download_shapenet_renderings.sh"")\n                os.system(""./dataset/download_shapenet_renderings.sh"")\n\n            self.num_image_per_object = 24\n            self.idx_image_val = 0\n\n            # Compile list of pointcloud path by selected category\n            for category in self.classes:\n                dir_pointcloud = join(self.pointcloud_path, category)\n                dir_image = join(self.image_path, category)\n                list_pointcloud = sorted(os.listdir(dir_pointcloud))\n                if self.train:\n                    list_pointcloud = list_pointcloud[:int(len(list_pointcloud) * 0.8)]\n                else:\n                    list_pointcloud = list_pointcloud[int(len(list_pointcloud) * 0.8):]\n                print(\n                    \'    category \'\n                    + colored(category, ""yellow"")\n                    + ""  ""\n                    + colored(self.id2names[category], ""cyan"")\n                    + \' Number Files :\'\n                    + colored(str(len(list_pointcloud)), ""yellow"")\n                )\n\n                if len(list_pointcloud) != 0:\n                    self.category_datapath[category] = []\n                    for pointcloud in list_pointcloud:\n                        pointcloud_path = join(dir_pointcloud, pointcloud)\n                        image_path = join(dir_image, pointcloud.split(""."")[0], ""rendering"")\n                        if not self.opt.SVR or exists(image_path):\n                            self.category_datapath[category].append((pointcloud_path, image_path, pointcloud, category))\n                        else:\n                            my_utils.red_print(f""Rendering not found : {image_path}"")\n\n            # Add all retained path to a global vector\n            for item in self.classes:\n                for pointcloud in self.category_datapath[item]:\n                    self.datapath.append(pointcloud)\n\n            # Preprocess and cache files\n            self.preprocess()\n\n\n    def preprocess(self):\n        if exists(self.path_dataset + ""info.pkl""):\n            # Reload dataset\n            my_utils.red_print(f""Reload dataset : {self.path_dataset}"")\n            with open(self.path_dataset + ""info.pkl"", ""rb"") as fp:\n                self.data_metadata = pickle.load(fp)\n\n            self.data_points = torch.load(self.path_dataset + ""points.pth"")\n        else:\n            # Preprocess dataset and put in cache for future fast reload\n            my_utils.red_print(""preprocess dataset..."")\n            self.datas = [self._getitem(i) for i in range(self.__len__())]\n\n            # Concatenate all proccessed files\n            self.data_points = [a[0] for a in self.datas]\n            self.data_points = torch.cat(self.data_points, 0)\n\n            self.data_metadata = [{\'pointcloud_path\': a[1], \'image_path\': a[2], \'name\': a[3], \'category\': a[4]} for a in\n                                  self.datas]\n\n            # Save in cache\n            with open(self.path_dataset + ""info.pkl"", ""wb"") as fp:  # Pickling\n                pickle.dump(self.data_metadata, fp)\n            torch.save(self.data_points, self.path_dataset + ""points.pth"")\n\n        my_utils.red_print(""Dataset Size: "" + str(len(self.data_metadata)))\n\n    def init_normalization(self):\n        if not self.opt.demo:\n            my_utils.red_print(""Dataset normalization : "" + self.opt.normalization)\n\n        if self.opt.normalization == ""UnitBall"":\n            self.normalization_function = pointcloud_processor.Normalization.normalize_unitL2ball_functional\n        elif self.opt.normalization == ""BoundingBox"":\n            self.normalization_function = pointcloud_processor.Normalization.normalize_bounding_box_functional\n        else:\n            self.normalization_function = pointcloud_processor.Normalization.identity_functional\n\n    def init_singleview(self):\n        ## Define Image Transforms\n        self.transforms = transforms.Compose([\n            transforms.Resize(size=224, interpolation=2),\n            transforms.ToTensor(),\n        ])\n\n        # RandomResizedCrop or RandomCrop\n        self.dataAugmentation = transforms.Compose([\n            transforms.RandomCrop(127),\n            transforms.RandomHorizontalFlip(),\n        ])\n\n        self.validating = transforms.Compose([\n            transforms.CenterCrop(127),\n        ])\n\n    def _getitem(self, index):\n        pointcloud_path, image_path, pointcloud, category = self.datapath[index]\n        points = np.load(pointcloud_path)\n        points = torch.from_numpy(points).float()\n        points[:, :3] = self.normalization_function(points[:, :3])\n        return points.unsqueeze(0), pointcloud_path, image_path, pointcloud, category\n\n    def __getitem__(self, index):\n        return_dict = deepcopy(self.data_metadata[index])\n        # Point processing\n        points = self.data_points[index]\n        points = points.clone()\n        if self.opt.sample:\n            choice = np.random.choice(points.size(0), self.num_sample, replace=True)\n            points = points[choice, :]\n        return_dict[\'points\'] = points[:, :3].contiguous()\n\n        # Image processing\n        if self.opt.SVR:\n            if self.train:\n                N = np.random.randint(1, self.num_image_per_object)\n                im = Image.open(join(return_dict[\'image_path\'], ShapeNet.int2str(N) + "".png""))\n                im = self.dataAugmentation(im)  # random crop\n            else:\n                im = Image.open(join(return_dict[\'image_path\'], ShapeNet.int2str(self.idx_image_val) + "".png""))\n                im = self.validating(im)  # center crop\n            im = self.transforms(im)  # scale\n            im = im[:3, :, :]\n            return_dict[\'image\'] = im\n        return return_dict\n\n    def __len__(self):\n        return len(self.datapath)\n\n    @staticmethod\n    def int2str(N):\n        if N < 10:\n            return ""0"" + str(N)\n        else:\n            return str(N)\n\n    def load(self, path):\n        ext = path.split(\'.\')[-1]\n        if ext == ""npy"" or ext == ""ply"" or ext == ""obj"":\n            return self.load_point_input(path)\n        else:\n            return self.load_image(path)\n\n    def load_point_input(self, path):\n        ext = path.split(\'.\')[-1]\n        if ext == ""npy"":\n            points = np.load(path)\n        elif ext == ""ply"" or ext == ""obj"":\n            import pymesh\n            points = pymesh.load_mesh(path).vertices\n        else:\n            print(""invalid file extension"")\n\n        points = torch.from_numpy(points).float()\n        operation = pointcloud_processor.Normalization(points, keep_track=True)\n        if self.opt.normalization == ""UnitBall"":\n            operation.normalize_unitL2ball()\n        elif self.opt.normalization == ""BoundingBox"":\n            operation.normalize_bounding_box()\n        else:\n            pass\n        return_dict = {\n            \'points\': points,\n            \'operation\': operation,\n            \'path\': path,\n        }\n        return return_dict\n\n\n    def load_image(self, path):\n        im = Image.open(path)\n        im = self.validating(im)\n        im = self.transforms(im)\n        im = im[:3, :, :]\n        return_dict = {\n            \'image\': im.unsqueeze_(0),\n            \'operation\': None,\n            \'path\': path,\n        }\n        return return_dict\n\n\nif __name__ == \'__main__\':\n    print(\'Testing Shapenet dataset\')\n    opt = {""normalization"": ""UnitBall"", ""class_choice"": [""plane""], ""SVR"": True, ""sample"": True, ""npoints"": 2500,\n           ""shapenet13"": True}\n    d = ShapeNet(EasyDict(opt), train=False, keep_track=True)\n    print(d[1])\n    a = len(d)\n'"
dataset/mesh_processor.py,0,"b'import pymesh\nimport numpy as np\nfrom os.path import join, dirname\n\n""""""\nAuthor : Thibault Groueix 01.09.2019\n""""""\n\n\nclass ColorMap:\n    def __init__(self):\n        self.colormap_path = ""auxiliary/colormap.npy""\n        self.colormap = (np.load(self.colormap_path) * 255).astype(\'int\')\n\n    def __call__(self, index):\n        """"""\n        :param value: a float\n        :return:\n        """"""\n        colors = self.colormap[index]\n        return colors\n\n\ndef save(mesh, path, colormap):\n    try:\n        vertex_sources = mesh.get_attribute(""vertex_sources"")  # batch, nb_prim, num_point, 3\n        if vertex_sources.max() > 0:\n            vertex_sources = (255 * (vertex_sources / vertex_sources.max())).astype(\'int\')\n            mesh.add_attribute(""vertex_red"")\n            mesh.add_attribute(""vertex_green"")\n            mesh.add_attribute(""vertex_blue"")\n            mesh.set_attribute(""vertex_red"", colormap.colormap[vertex_sources][:, 0])\n            mesh.set_attribute(""vertex_green"", colormap.colormap[vertex_sources][:, 1])\n            mesh.set_attribute(""vertex_blue"", colormap.colormap[vertex_sources][:, 2])\n    except:\n        pass\n    pymesh.save_mesh(path[:-3] + ""ply"", mesh, *mesh.get_attribute_names(), ascii=True)\n'"
dataset/pointcloud_processor.py,27,"b'import numpy as np\nimport torch\n\n\n""""""\nAuthor : Thibault Groueix 01.09.2019\n\nStandards :\n-- For batch processing. If you have a 2D tensor, it will unsqueeze it first\n-- Support in place and out of place\n-- Support inversion of applied transformation\n""""""\n\n\nclass FunctionGenerator(object):\n    def invert(self):\n        print(""This function has to be reimplemented in every inherited class"")\n\n\nclass ScaleFunctions(FunctionGenerator):\n    def __init__(self, operator, inplace):\n        self.operator = operator.clone()\n        self.inplace = inplace\n\n    def __call__(self, points):\n        if self.inplace:\n            points *= self.operator\n            return points\n        else:\n            return points * self.operator\n\n    def invert(self):\n        self.operator = 1.0 / self.operator\n\n\nclass RotationFunctions(FunctionGenerator):\n    def __init__(self, operator, inplace):\n        self.operator = operator.clone()\n        self.inplace = inplace\n        assert (self.operator.bmm(self.operator.transpose(1, 2).contiguous()).sum().item() - (\n                operator.size(0) * operator.size(2))) ** 2 < 0.001, ""Input matrix is not a rotation matrix""\n\n    def __call__(self, points):\n        rotated_points = torch.bmm(points, self.operator)\n        if self.inplace:\n            points.copy_(rotated_points)\n            return points\n        return rotated_points\n\n    def invert(self):\n        self.operator = self.operator.transpose(1, 2).contiguous()\n\n\nclass TranslationFunctions(FunctionGenerator):\n    def __init__(self, operator, inplace):\n        self.operator = operator.clone()\n        self.inplace = inplace\n\n    def __call__(self, points):\n        if self.inplace:\n            points += self.operator\n            return points\n        else:\n            return points + self.operator\n\n    def invert(self):\n        self.operator = -self.operator\n\n\nclass Operation(object):\n    def __init__(self, points, inplace=True, keep_track=False):\n        """"""\n        The keep track boolean is used in case one wants to unroll all the operation that have been performed\n        :param keep_track: boolean\n        """"""\n        self.keep_track = keep_track\n        self.transforms = []\n        self.points = points\n        self.device = points.device\n        self.inplace = inplace\n        self.dim = points.dim()\n        self.type = self.points.type()\n\n        if not self.inplace:\n            self.points = self.points.clone()\n        if self.dim == 2:\n            self.points = self.points.unsqueeze_(0)\n        elif self.dim == 3:\n            pass\n        else:\n            print(""Input should have dimension 2 or 3"")\n\n    def apply(self, points):\n        for func in self.transforms:\n            points = func(points)\n        return points\n\n    def invert(self):\n        self.transforms.reverse()\n        for func in self.transforms:\n            func.invert()\n\n    def scale(self, scale_vector):\n        scaling_op = ScaleFunctions(scale_vector.to(self.device).type(self.type), inplace=self.inplace)\n        self.points = scaling_op(self.points)\n        if self.keep_track:\n            self.transforms.append(scaling_op)\n        return\n\n    def translate(self, translation_vector):\n        translation_op = TranslationFunctions(translation_vector.to(self.device).type(self.type), inplace=self.inplace)\n        self.points = translation_op(self.points)\n        if self.keep_track:\n            self.transforms.append(translation_op)\n        return\n\n    def rotate(self, rotation_vector):\n        rotation_op = RotationFunctions(rotation_vector.to(self.device).type(self.type), inplace=self.inplace)\n        self.points = rotation_op(self.points)\n        if self.keep_track:\n            self.transforms.append(rotation_op)\n        return\n\n    @staticmethod\n    def get_3D_rot_matrix(axis, rad_angle):\n        """"""\n        Get a 3D rotation matrix around axis with angle in radian\n        :param axis: int\n        :param angle: torch.tensor of size Batch.\n        :return: Rotation Matrix as a tensor\n        """"""\n        cos_angle = torch.cos(rad_angle)\n        sin_angle = torch.sin(rad_angle)\n        rotation_matrix = torch.zeros(rad_angle.size(0), 3, 3)\n        rotation_matrix[:, 1, 1].fill_(1)\n        rotation_matrix[:, 0, 0].copy_(cos_angle)\n        rotation_matrix[:, 0, 2].copy_(sin_angle)\n        rotation_matrix[:, 2, 0].copy_(-sin_angle)\n        rotation_matrix[:, 2, 2].copy_(cos_angle)\n        if axis == 0:\n            rotation_matrix = rotation_matrix[:, [1, 0, 2], :][:, :, [1, 0, 2]]\n        if axis == 2:\n            rotation_matrix = rotation_matrix[:, [0, 2, 1], :][:, :, [0, 2, 1]]\n        return rotation_matrix\n\n    def rotate_axis_angle(self, axis, rad_angle, normals=False):\n        """"""\n\n        :param points: Batched points\n        :param axis: int\n        :param angle: batched angles\n        :return:\n        """"""\n        rot_matrix = Operation.get_3D_rot_matrix(axis=axis, rad_angle=rad_angle)\n        if normals:\n            rot_matrix = torch.cat([rot_matrix, rot_matrix], dim=2)\n        self.rotate(rot_matrix)\n        return\n\n\nclass Normalization(Operation):\n    def __init__(self, *args, **kwargs):\n        super(Normalization, self).__init__(*args, **kwargs)\n\n    def center_pointcloud(self):\n        """"""\n        In-place centering\n        :param points:  Tensor Batch, N_pts, D_dim\n        :return: None\n        """"""\n        # input :\n        # ouput : torch Tensor N_pts, D_dim\n        centroid = torch.mean(self.points, dim=1, keepdim=True)\n        self.translate(-centroid)\n        return self.points\n\n    @staticmethod\n    def center_pointcloud_functional(points):\n        operator = Normalization(points, inplace=False)\n        return operator.center_pointcloud()\n\n    def normalize_unitL2ball(self):\n        """"""\n        In-place normalization of input to unit ball\n        :param points: torch Tensor Batch, N_pts, D_dim\n        :return: None\n        """"""\n        # input : torch Tensor N_pts, D_dim\n        # ouput : torch Tensor N_pts, D_dim\n        #\n        self.center_pointcloud()\n        scaling_factor_square, _ = torch.max(torch.sum(self.points ** 2, dim=2, keepdim=True), dim=1, keepdim=True)\n        scaling_factor = torch.sqrt(scaling_factor_square)\n        self.scale(1.0 / scaling_factor)\n        return self.points\n\n    @staticmethod\n    def normalize_unitL2ball_functional(points):\n        operator = Normalization(points, inplace=False)\n        return operator.normalize_unitL2ball()\n\n    def center_bounding_box(self):\n        """"""\n        in place Centering : return center the bounding box\n        :param points: torch Tensor Batch, N_pts, D_dim\n        :return: diameter\n        """"""\n        min_vals, _ = torch.min(self.points, 1, keepdim=True)\n        max_vals, _ = torch.max(self.points, 1, keepdim=True)\n        self.translate(-(min_vals + max_vals) / 2)\n        return self.points, (max_vals - min_vals) / 2\n\n    @staticmethod\n    def center_bounding_box_functional(points):\n        operator = Normalization(points, inplace=False)\n        points, _ = operator.center_bounding_box()\n        return points\n\n    def normalize_bounding_box(self, isotropic=True):\n        """"""\n        In place : center the bounding box and uniformly scale the bounding box to edge lenght 1 or max edge length 1 if isotropic is True  (default).\n        :param points: torch Tensor Batch, N_pts, D_dim\n        :return:\n        """"""\n        _, diameter = self.center_bounding_box()\n        if isotropic:\n            diameter, _ = torch.max(diameter, 2, keepdim=True)\n        self.scale(1.0 / diameter)\n        return self.points\n\n    @staticmethod\n    def normalize_bounding_box_functional(points):\n        operator = Normalization(points, inplace=False)\n        return operator.normalize_bounding_box()\n\n    @staticmethod\n    def identity_functional(points):\n        return points\n\n\nclass DataAugmentation(Operation):\n    def __init__(self, *args, **kwargs):\n        super(DataAugmentation, self).__init__(*args, **kwargs)\n\n    def random_anisotropic_scaling(self, min_val=0.75, max_val=1.25):\n        """"""\n        In place : Random Anisotropic scaling by a factor between min_val and max_val\n        :param points: torch Tensor Batch, N_pts, D_dim\n        :return:\n        """"""\n        scale = torch.rand(self.points.size(0), 1, self.points.size(2)) * (max_val - min_val) + min_val\n        self.scale(scale)\n        return\n\n    def random_axial_rotation(self, axis=0, normals=False, range_rot=360):\n        """"""\n        Compute a random rotation of the batch around an axis. There is is no in-place version of this function because bmm_ is not possible in pytorch.\n        :param points: torch Tensor Batch, N_pts, D_dim\n        :return: torch Tensor Batch, N_pts, D_dim\n        """"""\n        scale_factor = 360.0 / range_rot\n        scale_factor = np.pi / scale_factor\n        rad_angle = torch.rand(self.points.size(0)) * 2 * scale_factor - scale_factor\n        self.rotate_axis_angle(axis=axis, rad_angle=rad_angle, normals=normals)\n        return\n\n    @staticmethod\n    def get_random_rotation_matrix(batch_size=1):\n        """"""\n        Get a random 3D rotation matrix\n        :return: Rotation Matrix as a tensor\n        from : https://en.wikipedia.org/wiki/Rotation_matrix#Basic_rotations\n        An easy way to do this : sample a point on the sphere (with normalize(normal(), normal(), normal())\n         then sample an angle, then just compute the associated rotation matrix\n        """"""\n        # Select a random point on the sphere\n        x = torch.randn(batch_size, 1, 3).double()\n        scaling_factor_square, _ = torch.max(torch.sum(x ** 2, dim=2, keepdim=True), dim=1, keepdim=True)\n        scaling_factor = torch.sqrt(scaling_factor_square)\n        x /= scaling_factor\n        x = x.squeeze()\n        XX = torch.bmm(x.unsqueeze(2), x.unsqueeze(1))\n\n        # get random angle\n        rad_angle = torch.rand(batch_size).double() * 2 * np.pi + np.pi\n        cos_angle = torch.cos(rad_angle)\n        sin_angle = torch.sin(rad_angle)\n\n        # Compute fat matrix\n        rotation_matrix = torch.zeros(rad_angle.size(0), 3, 3).double()\n\n        rotation_matrix[:, 0, 0].copy_(cos_angle + XX[:, 0, 0] * (1 - cos_angle))\n        rotation_matrix[:, 1, 1].copy_(cos_angle + XX[:, 1, 1] * (1 - cos_angle))\n        rotation_matrix[:, 2, 2].copy_(cos_angle + XX[:, 2, 2] * (1 - cos_angle))\n\n        rotation_matrix[:, 0, 1].copy_(XX[:, 0, 1] * (1 - cos_angle) - x[:, 2] * sin_angle)\n        rotation_matrix[:, 1, 0].copy_(XX[:, 0, 1] * (1 - cos_angle) + x[:, 2] * sin_angle)\n\n        rotation_matrix[:, 0, 2].copy_(XX[:, 0, 2] * (1 - cos_angle) + x[:, 1] * sin_angle)\n        rotation_matrix[:, 2, 0].copy_(XX[:, 0, 2] * (1 - cos_angle) - x[:, 1] * sin_angle)\n\n        rotation_matrix[:, 1, 2].copy_(XX[:, 1, 2] * (1 - cos_angle) - x[:, 0] * sin_angle)\n        rotation_matrix[:, 2, 1].copy_(XX[:, 1, 2] * (1 - cos_angle) + x[:, 0] * sin_angle)\n\n        return rotation_matrix\n\n    def random_rotation(self, normals=False):\n        """"""\n        Compute a random rotation of the batch. There is is no in-place version of this function because bmm_ is not possible in pytorch.\n        :param points: torch Tensor Batch, N_pts, D_dim\n        :return: torch Tensor Batch, N_pts, D_dim\n        """"""\n        rot_matrix = DataAugmentation.get_random_rotation_matrix(batch_size=self.points.size(0))\n        if normals:\n            rot_matrix = torch.cat([rot_matrix, rot_matrix], dim=2)\n        self.rotate(rot_matrix)\n        return\n\n    def random_translation(self, scale=0.03):\n        """"""\n        In place Compute a random tranlation of the batch.\n        :param points: torch Tensor Batch, N_pts, D_dim\n        :return:\n        """"""\n        translation_vector = torch.rand(self.points.size(0), 1, self.points.size(2)) * 2 * scale - scale\n        self.translate(translation_vector)\n        return\n\n    @staticmethod\n    def diff(first, second):\n        second = set(second)\n        return [item for item in first if item not in second]\n\n    def random_flips(self, dims=[]):\n        """"""\n               In place Random flip\n               :param points: torch Tensor Batch, N_pts, D_dim\n               :return:\n        """"""\n        exclude_dims = DataAugmentation.diff(range(self.points.size(2)), dims)\n        scale_factor = torch.randint(2, (self.points.size(0), 1, self.points.size(2))) * 2 - 1\n        for axis in exclude_dims:\n            scale_factor[:, :, axis].fill_(1)\n        self.scale(scale_factor)\n        return\n\n\n# Done for eurographics 19\ndef barycentric(p, a, b, c):\n    """"""\n    :param p: numpy arrays of size N_points x 3\n    :param a: numpy arrays of size N_points x 3\n    :param b: numpy arrays of size N_points x 3\n    :param c: numpy arrays of size N_points x 3\n    :return: barycentric coordinates point p in triangle (a,b,c)\n    """"""\n\n    v0 = b - a\n    v1 = c - a\n    v2 = p - a\n\n    d00 = np.sum(np.multiply(v0, v0), 1)\n    d01 = np.sum(np.multiply(v0, v1), 1)\n    d11 = np.sum(np.multiply(v1, v1), 1)\n    d20 = np.sum(np.multiply(v2, v0), 1)\n    d21 = np.sum(np.multiply(v2, v1), 1)\n\n    denom = np.multiply(d00, d11) - np.multiply(d01, d01)\n\n    v = (np.multiply(d11, d20) - np.multiply(d01, d21)) / denom\n    w = (np.multiply(d00, d21) - np.multiply(d01, d20)) / denom\n    u = - v - w + 1.0\n\n    return (u, v, w)\n\n\nif __name__ == \'__main__\':\n    print(""Start unit test"")\n'"
dataset/trainer_dataset.py,2,"b'import torch\nimport dataset.dataset_shapenet as dataset_shapenet\nimport dataset.augmenter as augmenter\nfrom easydict import EasyDict\n\n\nclass TrainerDataset(object):\n    def __init__(self):\n        super(TrainerDataset, self).__init__()\n\n    def build_dataset(self):\n        """"""\n        Create dataset\n        Author : Thibault Groueix 01.11.2019\n        """"""\n\n        self.datasets = EasyDict()\n        # Create Datasets\n        self.datasets.dataset_train = dataset_shapenet.ShapeNet(self.opt, train=True)\n        self.datasets.dataset_test = dataset_shapenet.ShapeNet(self.opt, train=False)\n\n        if not self.opt.demo:\n            # Create dataloaders\n            self.datasets.dataloader_train = torch.utils.data.DataLoader(self.datasets.dataset_train,\n                                                                         batch_size=self.opt.batch_size,\n                                                                         shuffle=True,\n                                                                         num_workers=int(self.opt.workers))\n            self.datasets.dataloader_test = torch.utils.data.DataLoader(self.datasets.dataset_test,\n                                                                        batch_size=self.opt.batch_size_test,\n                                                                        shuffle=True, num_workers=int(self.opt.workers))\n            axis = []\n            if self.opt.data_augmentation_axis_rotation:\n                axis = [1]\n\n            flips = []\n            if self.opt.data_augmentation_random_flips:\n                flips = [0, 2]\n\n            # Create Data Augmentation\n            self.datasets.data_augmenter = augmenter.Augmenter(translation=self.opt.random_translation,\n                                                               rotation_axis=axis,\n                                                               anisotropic_scaling=self.opt.anisotropic_scaling,\n                                                               rotation_3D=self.opt.random_rotation,\n                                                               flips=flips)\n\n            self.datasets.len_dataset = len(self.datasets.dataset_train)\n            self.datasets.len_dataset_test = len(self.datasets.dataset_test)\n'"
model/atlasnet.py,6,"b'import torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.utils.data\nfrom model.model_blocks import Mapping2Dto3D, Identity\nfrom model.template import get_template\n\n\nclass Atlasnet(nn.Module):\n\n    def __init__(self, opt):\n        """"""\n        Core Atlasnet module : decoder to meshes and pointclouds.\n        This network takes an embedding in the form of a latent vector and returns a pointcloud or a mesh\n        Author : Thibault Groueix 01.11.2019\n        :param opt: \n        """"""\n        super(Atlasnet, self).__init__()\n        self.opt = opt\n        self.device = opt.device\n\n        # Define number of points per primitives\n        self.nb_pts_in_primitive = opt.number_points // opt.nb_primitives\n        self.nb_pts_in_primitive_eval = opt.number_points_eval // opt.nb_primitives\n\n        if opt.remove_all_batchNorms:\n            torch.nn.BatchNorm1d = Identity\n            print(""Replacing all batchnorms by identities."")\n\n        # Initialize templates\n        self.template = [get_template(opt.template_type, device=opt.device) for i in range(0, opt.nb_primitives)]\n\n        # Intialize deformation networks\n        self.decoder = nn.ModuleList([Mapping2Dto3D(opt) for i in range(0, opt.nb_primitives)])\n\n    def forward(self, latent_vector, train=True):\n        """"""\n        Deform points from self.template using the embedding latent_vector\n        :param latent_vector: an opt.bottleneck size vector encoding a 3D shape or an image. size : batch, bottleneck\n        :return: A deformed pointcloud os size : batch, nb_prim, num_point, 3\n        """"""\n        # Sample points in the patches\n        # input_points = [self.template[i].get_regular_points(self.nb_pts_in_primitive,\n        #                                                     device=latent_vector.device)\n        #                 for i in range(self.opt.nb_primitives)]\n        if train:\n            input_points = [self.template[i].get_random_points(\n                torch.Size((1, self.template[i].dim, self.nb_pts_in_primitive)),\n                latent_vector.device) for i in range(self.opt.nb_primitives)]\n        else:\n            input_points = [self.template[i].get_regular_points(self.nb_pts_in_primitive_eval,\n                                                                device=latent_vector.device)\n                            for i in range(self.opt.nb_primitives)]\n\n        # Deform each patch\n        output_points = torch.cat([self.decoder[i](input_points[i], latent_vector.unsqueeze(2)).unsqueeze(1) for i in\n                                   range(0, self.opt.nb_primitives)], dim=1)\n\n        # Return the deformed pointcloud\n        return output_points.contiguous()  # batch, nb_prim, num_point, 3\n\n    def generate_mesh(self, latent_vector):\n        assert latent_vector.size(0)==1, ""input should have batch size 1!""\n        import pymesh\n        input_points = [self.template[i].get_regular_points(self.nb_pts_in_primitive, latent_vector.device)\n                        for i in range(self.opt.nb_primitives)]\n        input_points = [input_points[i] for i in range(self.opt.nb_primitives)]\n\n        # Deform each patch\n        output_points = [self.decoder[i](input_points[i], latent_vector.unsqueeze(2)).squeeze() for i in\n                         range(0, self.opt.nb_primitives)]\n\n        output_meshes = [pymesh.form_mesh(vertices=output_points[i].transpose(1, 0).contiguous().cpu().numpy(),\n                                          faces=self.template[i].mesh.faces)\n                         for i in range(self.opt.nb_primitives)]\n\n        # Deform return the deformed pointcloud\n        mesh = pymesh.merge_meshes(output_meshes)\n\n        return mesh\n'"
model/model.py,1,"b'from model.atlasnet import Atlasnet\nfrom model.model_blocks import PointNet\nimport torch.nn as nn\nimport model.resnet as resnet\n\n\nclass EncoderDecoder(nn.Module):\n    """"""\n    Wrapper for a encoder and a decoder.\n    Author : Thibault Groueix 01.11.2019\n    """"""\n\n    def __init__(self, opt):\n        super(EncoderDecoder, self).__init__()\n        if opt.SVR:\n            self.encoder = resnet.resnet18(pretrained=False, num_classes=opt.bottleneck_size)\n        else:\n            self.encoder = PointNet(nlatent=opt.bottleneck_size)\n\n        self.decoder = Atlasnet(opt)\n        self.to(opt.device)\n\n        if not opt.SVR:\n            self.apply(weights_init)  # initialization of the weights\n        self.eval()\n\n    def forward(self, x, train=True):\n        return self.decoder(self.encoder(x), train=train)\n\n    def generate_mesh(self, x):\n        return self.decoder.generate_mesh(self.encoder(x))\n\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find(\'BatchNorm\') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n'"
model/model_blocks.py,21,"b'import torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.utils.data\nimport torch.nn.functional as F\n\n\nclass Identity(nn.Module):\n    def __init__(self, *args, **kwargs):\n        super(Identity, self).__init__()\n\n    def forward(self, input):\n        return input\n\n\ndef get_activation(argument):\n    getter = {\n        ""relu"": F.relu,\n        ""sigmoid"": F.sigmoid,\n        ""softplus"": F.softplus,\n        ""logsigmoid"": F.logsigmoid,\n        ""softsign"": F.softsign,\n        ""tanh"": F.tanh,\n    }\n    return getter.get(argument, ""Invalid activation"")\n\n\nclass PointNet(nn.Module):\n    def __init__(self, nlatent=1024, dim_input=3):\n        """"""\n        PointNet Encoder\n        See : PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\n                Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas\n        """"""\n\n        super(PointNet, self).__init__()\n        self.dim_input = dim_input\n        self.conv1 = torch.nn.Conv1d(dim_input, 64, 1)\n        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n        self.conv3 = torch.nn.Conv1d(128, nlatent, 1)\n        self.lin1 = nn.Linear(nlatent, nlatent)\n        self.lin2 = nn.Linear(nlatent, nlatent)\n\n        self.bn1 = torch.nn.BatchNorm1d(64)\n        self.bn2 = torch.nn.BatchNorm1d(128)\n        self.bn3 = torch.nn.BatchNorm1d(nlatent)\n        self.bn4 = torch.nn.BatchNorm1d(nlatent)\n        self.bn5 = torch.nn.BatchNorm1d(nlatent)\n\n        self.nlatent = nlatent\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.bn3(self.conv3(x))\n        x, _ = torch.max(x, 2)\n        x = x.view(-1, self.nlatent)\n        x = F.relu(self.bn4(self.lin1(x).unsqueeze(-1)))\n        x = F.relu(self.bn5(self.lin2(x.squeeze(2)).unsqueeze(-1)))\n        return x.squeeze(2)\n\n\nclass Mapping2Dto3D(nn.Module):\n    """"""\n    Core Atlasnet Function.\n    Takes batched points as input and run them through an MLP.\n    Note : the MLP is implemented as a torch.nn.Conv1d with kernels of size 1 for speed.\n    Note : The latent vector is added as a bias after the first layer. Note that this is strictly identical\n    as concatenating each input point with the latent vector but saves memory and speeed.\n    Author : Thibault Groueix 01.11.2019\n    """"""\n\n    def __init__(self, opt):\n        self.opt = opt\n        self.bottleneck_size = opt.bottleneck_size\n        self.input_size = opt.dim_template\n        self.dim_output = 3\n        self.hidden_neurons = opt.hidden_neurons\n        self.num_layers = opt.num_layers\n        super(Mapping2Dto3D, self).__init__()\n        print(\n            f""New MLP decoder : hidden size {opt.hidden_neurons}, num_layers {opt.num_layers}, activation {opt.activation}"")\n\n        self.conv1 = torch.nn.Conv1d(self.input_size, self.bottleneck_size, 1)\n        self.conv2 = torch.nn.Conv1d(self.bottleneck_size, self.hidden_neurons, 1)\n\n        self.conv_list = nn.ModuleList(\n            [torch.nn.Conv1d(self.hidden_neurons, self.hidden_neurons, 1) for i in range(self.num_layers)])\n\n        self.last_conv = torch.nn.Conv1d(self.hidden_neurons, self.dim_output, 1)\n\n        self.bn1 = torch.nn.BatchNorm1d(self.bottleneck_size)\n        self.bn2 = torch.nn.BatchNorm1d(self.hidden_neurons)\n\n        self.bn_list = nn.ModuleList([torch.nn.BatchNorm1d(self.hidden_neurons) for i in range(self.num_layers)])\n\n        self.activation = get_activation(opt.activation)\n\n    def forward(self, x, latent):\n        x = self.conv1(x) + latent\n        x = self.activation(self.bn1(x))\n        x = self.activation(self.bn2(self.conv2(x)))\n        for i in range(self.opt.num_layers):\n            x = self.activation(self.bn_list[i](self.conv_list[i](x)))\n        return self.last_conv(x)\n'"
model/resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n\n# From : https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\']\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n    return model\n\n\ndef resnet34(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model\n\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef resnet101(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n    return model\n\n\ndef resnet152(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n    return model\n'"
model/template.py,6,"b'import pymesh\nimport numpy as np\nimport torch\nfrom torch.autograd import Variable\n\n""""""\n        Author : Thibault Groueix 01.11.2019\n""""""\n\n\ndef get_template(template_type, device=0):\n    getter = {\n        ""SQUARE"": SquareTemplate,\n        ""SPHERE"": SphereTemplate,\n    }\n    template = getter.get(template_type, ""Invalid template"")\n    return template(device=device)\n\n\nclass Template(object):\n    def get_random_points(self):\n        print(""Please implement get_random_points "")\n\n    def get_regular_points(self):\n        print(""Please implement get_regular_points "")\n\n\nclass SphereTemplate(Template):\n    def __init__(self, device=0, grain=6):\n        self.device = device\n        self.dim = 3\n        self.npoints = 0\n\n    def get_random_points(self, shape, device=""gpu0""):\n        """"""\n        Get random points on a Sphere\n        Return Tensor of Size [x, 3, x ... x]\n        """"""\n        assert shape[1] == 3, ""shape should have 3 in dim 1""\n        rand_grid = torch.cuda.FloatTensor(shape).to(device).float()\n        rand_grid.data.normal_(0, 1)\n        rand_grid = rand_grid / torch.sqrt(torch.sum(rand_grid ** 2, dim=1, keepdim=True))\n        return Variable(rand_grid)\n\n    def get_regular_points(self, npoints=None, device=""gpu0""):\n        """"""\n        Get regular points on a Sphere\n        Return Tensor of Size [x, 3]\n        """"""\n        if not self.npoints == npoints:\n            self.mesh = pymesh.generate_icosphere(1, [0, 0, 0], 4)  # 2562 vertices\n            self.vertex = torch.from_numpy(self.mesh.vertices).to(device).float()\n            self.num_vertex = self.vertex.size(0)\n            self.vertex = self.vertex.transpose(0,1).contiguous().unsqueeze(0)\n            self.npoints = npoints\n\n        return Variable(self.vertex.to(device))\n\n\nclass SquareTemplate(Template):\n    def __init__(self, device=0):\n        self.device = device\n        self.dim = 2\n        self.npoints = 0\n\n    def get_random_points(self, shape, device=""gpu0""):\n        """"""\n        Get random points on a Sphere\n        Return Tensor of Size [x, 2, x ... x]\n        """"""\n        rand_grid = torch.cuda.FloatTensor(shape).to(device).float()\n        rand_grid.data.uniform_(0, 1)\n        return Variable(rand_grid)\n\n    def get_regular_points(self, npoints=2500, device=""gpu0""):\n        """"""\n        Get regular points on a Square\n        Return Tensor of Size [x, 3]\n        """"""\n        if not self.npoints == npoints:\n            self.npoints = npoints\n            vertices, faces = self.generate_square(np.sqrt(npoints))\n            self.mesh = pymesh.form_mesh(vertices=vertices, faces=faces)  # 10k vertices\n            self.vertex = torch.from_numpy(self.mesh.vertices).to(device).float()\n            self.num_vertex = self.vertex.size(0)\n            self.vertex = self.vertex.transpose(0,1).contiguous().unsqueeze(0)\n\n        return Variable(self.vertex[:, :2].contiguous().to(device))\n\n    @staticmethod\n    def generate_square(grain):\n        """"""\n        Generate a square mesh from a regular grid.\n        :param grain:\n        :return:\n        """"""\n        grain = int(grain)\n        grain = grain - 1  # to return grain*grain points\n        # generate regular grid\n        faces = []\n        vertices = []\n        for i in range(0, int(grain + 1)):\n            for j in range(0, int(grain + 1)):\n                vertices.append([i / grain, j / grain, 0])\n\n        for i in range(1, int(grain + 1)):\n            for j in range(0, (int(grain + 1) - 1)):\n                faces.append([j + (grain + 1) * i,\n                              j + (grain + 1) * i + 1,\n                              j + (grain + 1) * (i - 1)])\n        for i in range(0, (int((grain + 1)) - 1)):\n            for j in range(1, int((grain + 1))):\n                faces.append([j + (grain + 1) * i,\n                              j + (grain + 1) * i - 1,\n                              j + (grain + 1) * (i + 1)])\n\n        return np.array(vertices), np.array(faces)\n'"
model/trainer_model.py,9,"b'import torch\nfrom auxiliary.my_utils import yellow_print\nfrom model.model import EncoderDecoder\nimport torch.optim as optim\nimport numpy as np\nimport torch.nn as nn\nfrom copy import deepcopy\n\nclass TrainerModel(object):\n    def __init__(self):\n        """"""\n        This class creates the architectures and implements all trainer functions related to architecture.\n        Author : Thibault Groueix 01.11.2019\n        """"""\n        super(TrainerModel, self).__init__()\n\n    def build_network(self):\n        """"""\n        Create network architecture. Refer to auxiliary.model\n        :return:\n        """"""\n        if torch.cuda.is_available():\n            self.opt.device = torch.device(f""cuda:{self.opt.multi_gpu[0]}"")\n        else:\n            # Run on CPU\n            self.opt.device = torch.device(f""cpu"")\n\n        self.network = EncoderDecoder(self.opt)\n        self.network = nn.DataParallel(self.network, device_ids=self.opt.multi_gpu)\n\n        self.reload_network()\n\n    def reload_network(self):\n        """"""\n        Reload entire model or only decoder (atlasnet) depending on the options\n        :return:\n        """"""\n        if self.opt.reload_model_path != """":\n            yellow_print(f""Network weights loaded from  {self.opt.reload_model_path}!"")\n            # print(self.network.state_dict().keys())\n            # print(torch.load(self.opt.reload_model_path).keys())\n            self.network.module.load_state_dict(torch.load(self.opt.reload_model_path, map_location=\'cuda:0\'))\n\n        elif self.opt.reload_decoder_path != """":\n            opt = deepcopy(self.opt)\n            opt.SVR = False\n            network = EncoderDecoder(opt)\n            network = nn.DataParallel(network, device_ids=opt.multi_gpu)\n            network.module.load_state_dict(torch.load(opt.reload_decoder_path, map_location=\'cuda:0\'))\n            self.network.module.decoder = network.module.decoder\n            yellow_print(f""Network Decoder weights loaded from  {self.opt.reload_decoder_path}!"")\n\n        else:\n            yellow_print(""No network weights to reload!"")\n\n    def build_optimizer(self):\n        """"""\n        Create optimizer\n        """"""\n        if self.opt.train_only_encoder:\n            # To train a resnet image encoder with a pre-trained atlasnet decoder.\n            yellow_print(""only train the Encoder"")\n            self.optimizer = optim.Adam(self.network.module.encoder.parameters(), lr=self.opt.lrate)\n        else:\n            self.optimizer = optim.Adam(self.network.module.parameters(), lr=self.opt.lrate)\n\n        if self.opt.reload_optimizer_path != """":\n            try:\n                self.optimizer.load_state_dict(torch.load(self.opt.reload_optimizer_path, map_location=\'cuda:0\'))\n                # yellow_print(f""Reloaded optimizer {self.opt.reload_optimizer_path}"")\n            except:\n                yellow_print(f""Failed to reload optimizer {self.opt.reload_optimizer_path}"")\n\n        # Set policy for warm-up if you use multiple GPUs\n        self.next_learning_rates = []\n        if len(self.opt.multi_gpu) > 1:\n            self.next_learning_rates = np.linspace(self.opt.lrate, self.opt.lrate * len(self.opt.multi_gpu),\n                                                   5).tolist()\n            self.next_learning_rates.reverse()\n'"
training/launcher.py,0,"b'import os\nimport gpustat\nimport time\n\n""""""\n    Author : Thibault Groueix 01.11.2019\n""""""\n\nclass Experiments(object):\n    def __init__(self):\n        self.atlasnet = {\n            1: ""python train.py --shapenet13 --dir_name log/atlasnet_autoencoder_1_sphere  --nb_primitives 1 --template_type SPHERE"",\n            2: ""python train.py --shapenet13 --dir_name log/atlasnet_autoencoder_25_squares  --nb_primitives 25 --template_type SQUARE"",\n            3: ""python train.py --shapenet13 --dir_name log/atlasnet_singleview_1_sphere_tmp_True --nb_primitives 1 --template_type SPHERE --SVR --reload_decoder_path log/atlasnet_autoencoder_1_sphere/network.pth --train_only_encoder"",\n            4: ""python train.py --shapenet13 --dir_name log/atlasnet_singleview_25_squares_tmp_True  --nb_primitives 25 --template_type SQUARE  --SVR  --reload_decoder_path log/atlasnet_autoencoder_25_squares/network.pth --train_only_encoder"",\n            5: ""python train.py --shapenet13 --dir_name log/atlasnet_singleview_1_sphere --nb_primitives 1 --template_type SPHERE --SVR --reload_model_path log/atlasnet_singleview_1_sphere_tmp_True/network.pth --lrate 0.0001 --nepoch 50 --lr_decay_1 40"",\n            6: ""python train.py --shapenet13 --dir_name log/atlasnet_singleview_25_squares  --nb_primitives 25 --template_type SQUARE  --SVR  --reload_model_path log/atlasnet_singleview_25_squares_tmp_True/network.pth  --lrate 0.0001 --nepoch 50 --lr_decay_1 40"",\n        }\n\n        self.atlasnet_test = {\n            1: ""python train.py --shapenet13 --dir_name training/trained_models/atlasnet_autoencoder_1_sphere  --nb_primitives 1 --template_type SPHERE --run_single_eval --no_metro"",\n            2: ""python train.py --shapenet13 --dir_name training/trained_models/atlasnet_autoencoder_25_squares  --nb_primitives 25 --template_type SQUARE  --run_single_eval --no_metro"",\n            3: ""python train.py --shapenet13 --dir_name training/trained_models/atlasnet_singleview_1_sphere  --nb_primitives 1 --template_type SPHERE --run_single_eval --no_metro  --SVR"",\n            4: ""python train.py --shapenet13 --dir_name training/trained_models/atlasnet_singleview_25_squares  --nb_primitives 25 --template_type SQUARE  --run_single_eval --no_metro  --SVR"",\n        }\n        self.template = {\n            1: ""python train.py --shapenet13 --dir_name log/template_sphere --template_type SPHERE"",\n            2: ""python train.py --shapenet13 --dir_name log/template_square --template_type SQUARE --nb_primitives 1"",\n        }\n        self.num_prim = {\n            1: ""python train.py --shapenet13 --dir_name log/num_prim_10 --nb_primitives 10  --template_type SQUARE"",\n            2: ""python train.py --shapenet13 --dir_name log/num_prim_25 --nb_primitives 25  --template_type SQUARE"",\n        }\n        self.data_augmentation = {\n            1: ""python train.py --shapenet13 --dir_name log/data_augmentation_1 --nb_primitives 10 --random_translation 1"",\n            2: ""python train.py --shapenet13 --dir_name log/data_augmentation_2 --nb_primitives 10 --random_translation 1 --anisotropic_scaling 1"",\n            3: ""python train.py --shapenet13 --dir_name log/data_augmentation_3 --nb_primitives 10 --data_augmentation_axis_rotation 1 --data_augmentation_random_flips 1 --random_translation 1 --anisotropic_scaling 1"",\n            4: ""python train.py --shapenet13 --dir_name log/data_augmentation_4 --nb_primitives 10 --random_rotation 1 --data_augmentation_random_flips 1 --random_translation 1 --anisotropic_scaling 1"",\n        }\n\n        self.number_points = {\n            1: ""python train.py --shapenet13 --dir_name log/number_points_8000 --nb_primitives 10 --number_points 8000"",\n            2: ""python train.py --shapenet13 --dir_name log/number_points_1000 --nb_primitives 10 --number_points 1000"",\n        }\n\n        self.normalization = {\n            1: ""python train.py --shapenet13 --dir_name log/normalization_boundingBox --nb_primitives 10 --normalization BoundingBox"",\n            2: ""python train.py --shapenet13 --dir_name log/normalization_identity --nb_primitives 10 --normalization Identity"",\n            3: ""python train.py --shapenet13 --dir_name log/normalization_unitBall --nb_primitives 10 --normalization UnitBall"",\n        }\n\n        self.bottleneck_size = {\n            1: ""python train.py --shapenet13 --dir_name log/bottleneck_size_128 --nb_primitives 10 --bottleneck_size 128"",\n            2: ""python train.py --shapenet13 --dir_name log/bottleneck_size_2048 --nb_primitives 10 --bottleneck_size 2048"",\n            3: ""python train.py --shapenet13 --dir_name log/bottleneck_size_4096 --nb_primitives 10 --bottleneck_size 4096"",\n        }\n\n        self.multi_gpu = {\n            1: ""python train.py --shapenet13 --dir_name log/multi_gpu_1 --multi_gpu 0 1 2 3 --batch_size 128"",\n            2: ""python train.py --shapenet13 --dir_name log/multi_gpu_10 --multi_gpu 0 1 2 3 --nb_primitives 10 --batch_size 128"",\n        }\n\n        self.activation = {\n            1: ""python train.py --shapenet13 --dir_name log/activation_sigmoid --nb_primitives 10  --activation sigmoid"",\n            2: ""python train.py --shapenet13 --dir_name log/activation_softplus --nb_primitives 10  --activation softplus"",\n            3: ""python train.py --shapenet13 --dir_name log/activation_logsigmoid --nb_primitives 10  --activation logsigmoid"",\n            4: ""python train.py --shapenet13 --dir_name log/activation_softsign --nb_primitives 10  --activation softsign"",\n            5: ""python train.py --shapenet13 --dir_name log/activation_tanh --nb_primitives 10  --activation tanh"",\n        }\n\n        self.num_layers = {\n            1: ""python train.py --shapenet13 --dir_name log/num_layers_2 --nb_primitives 10  --num_layers 2"",\n            2: ""python train.py --shapenet13 --dir_name log/num_layers_3 --nb_primitives 10  --num_layers 3"",\n            3: ""python train.py --shapenet13 --dir_name log/num_layers_4 --nb_primitives 10  --num_layers 4"",\n            4: ""python train.py --shapenet13 --dir_name log/num_layers_5 --nb_primitives 10  --num_layers 5"",\n        }\n\n        self.hidden_neurons = {\n            1: ""python train.py --shapenet13 --dir_name log/hidden_neurons_256 --nb_primitives 10  --hidden_neurons 256"",\n            2: ""python train.py --shapenet13 --dir_name log/hidden_neurons_128 --nb_primitives 10  --hidden_neurons 128"",\n            3: ""python train.py --shapenet13 --dir_name log/hidden_neurons_64 --nb_primitives 10  --hidden_neurons 64"",\n            4: ""python train.py --shapenet13 --dir_name log/hidden_neurons_512 --nb_primitives 10  --hidden_neurons 512"",\n            5: ""python train.py --shapenet13 --dir_name log/hidden_neurons_1024 --nb_primitives 10  --hidden_neurons 1024"",\n        }\n\n        self.single_view = {\n            1: ""python train.py --dir_name log/single_view --shapenet13 --nb_primitives 10  --SVR"",\n        }\n\n\nexp = Experiments()\n\n\ndef get_first_available_gpu():\n    """"""\n    Check if a gpu is free and returns it\n    :return: gpu_id\n    """"""\n    query = gpustat.new_query()\n    for gpu_id in range(len(query)):\n        gpu = query[gpu_id]\n        print(gpu_id, gpu.memory_used)\n        if gpu.memory_used < 2000:\n            if gpu.utilization == 0 and gpu.memory_used < 12 and gpu_id == 0 and gpu.processes.__len__() == 0:\n                os.system(f""tmux kill-session -t GPU{gpu_id}"")\n            has = os.system(f""tmux has-session -t GPU{gpu_id} 2>/dev/null"")\n            if not int(has) == 0:\n                return gpu_id\n    return -1\n\n\ndef job_scheduler_parralel(dict_of_jobs):\n    """"""\n    Launch Tmux session each time it finds a free gpu\n    :param dict_of_jobs:\n    """"""\n    keys = list(dict_of_jobs.keys())\n    while len(keys) > 0:\n        job_key = keys.pop()\n        job = dict_of_jobs[job_key]\n        while get_first_available_gpu() < 0:\n            print(""Waiting to find a GPU for "", job)\n            time.sleep(15)  # Sleeps for 30 sec\n\n        gpu_id = get_first_available_gpu()\n        name_tmux = f""GPU{gpu_id}""\n        cmd = f""conda activate python3;  {job} --multi_gpu {gpu_id} 2>&1 | tee  log_terminals/{gpu_id}_{job_key}.txt; tmux kill-session -t {name_tmux}""\n        CMD = f\'tmux new-session -d -s {name_tmux} \\; send-keys ""{cmd}"" Enter\'\n        print(CMD)\n        os.system(CMD)\n        time.sleep(15)  # Sleeps for 30 sec\n\n\ndef job_scheduler_sequential(dict_of_jobs):\n    """"""\n    Choose a gpum then launches jobs sequentially on that GPU in tmux sessions.\n    :param dict_of_jobs:\n    """"""\n    keys = list(dict_of_jobs.keys())\n    while get_first_available_gpu() < 0:\n        time.sleep(15)  # Sleeps for 30 sec\n\n    gpu_id = get_first_available_gpu()\n\n    while len(keys) > 0:\n        has = os.system(f""tmux has-session -t GPU{gpu_id} 2>/dev/null"")\n        if not int(has) == 0:\n            job_key = keys.pop()\n            job = dict_of_jobs[job_key]\n            name_tmux = f""GPU{gpu_id}""\n            cmd = f""conda activate python3;  {job}  2>&1 | tee  log_terminals/{gpu_id}_{job_key}.txt; tmux kill-session -t {name_tmux}""\n            CMD = f\'tmux new-session -d -s {name_tmux} \\; send-keys ""{cmd}"" Enter\'\n            print(CMD)\n            os.system(CMD)\n        time.sleep(60)  # Sleeps for 30 sec\n\n\nfor path in [""log_terminals"", ""log""]:\n    if not os.path.exists(path):\n        print(f""Creating {path} folder"")\n        os.mkdir(path)\n\njob_scheduler_parralel(exp.activation)\njob_scheduler_parralel(exp.number_points)\njob_scheduler_parralel(exp.hidden_neurons)\njob_scheduler_parralel(exp.num_layers)\njob_scheduler_parralel(exp.normalization)\njob_scheduler_parralel(exp.template)\njob_scheduler_parralel(exp.num_prim)\n\n'"
training/metro.py,0,"b'import argparse\nimport numpy as np\nimport pymesh\nfrom os.path import exists\nimport os\nimport subprocess\nfrom shutil import copy\n\n""""""\n        Author : Thibault Groueix 01.11.2019\n""""""\n\n\ndef metro(path1, path2, metro=\'./auxiliary/metro_sources/build/metro\'):\n    """"""\n    Run the metro compiled program on two meshes and get the output.\n    :param path1: mesh 1\n    :param path2: mesh 2\n    :param metro: path to metro\n    :return: metro(mesh 1, mesh 2) [float]\n    """"""\n\n    print(f""calculing {path1}"")\n    cmd = f""{metro} {path1} {path2}""\n    returned_output = subprocess.check_output(cmd, shell=True)\n    returned_output = returned_output.decode(""utf-8"")\n    location = returned_output.find(""Hausdorff"")\n    returned_output = returned_output[location:location + 40]\n    distance = float(returned_output.split("" "")[2])\n    print(f""calculing {path1} Done {distance}!"")\n\n    return distance\n\n\ndef isolate_files():\n    """"""\n    Utility fonction to generate the metro_file archive. Useless to all users but the author.\n    """"""\n    with open(\'./dataset/data/metro_files/files-metro.txt\', \'r\') as file:\n        files = file.read().split(\'\\n\')\n    for file in files:\n        if file[-3:] == ""ply"":\n            cat = file.split(\'/\')[0]\n            name = file.split(\'/\')[1][:-4]\n            path_points = \'/\'.join([\'.\', \'dataset\', \'data\', \'ShapeNetV1PointCloud\', cat, name + \'.points.ply.npy\'])\n            path_png = \'/\'.join([\'.\', \'dataset\', \'data\', \'ShapeNetV1Renderings\', cat, name, ""rendering"", \'00.png\'])\n\n            path_obj = \'/\'.join([\'\', \'home\', \'thibault\', \'hdd\', \'data\', \'ShapeNetCore.v1\', cat, name, \'model.obj\'])\n            mesh = pymesh.load_mesh(path_obj)\n            points = np.load((path_points))\n            if not exists(\'/\'.join([\'.\', \'dataset\', \'data\', \'metro_files\', cat])):\n                os.mkdir(\'/\'.join([\'.\', \'dataset\', \'data\', \'metro_files\', cat]))\n\n            pymesh.save_mesh(\'/\'.join([\'.\', \'dataset\', \'data\', \'metro_files\', cat, name + \'.ply\']), mesh, ascii=True)\n            np.save(\'/\'.join([\'.\', \'dataset\', \'data\', \'metro_files\', cat, name + \'.npy\']), points)\n            copy(path_png, \'/\'.join([\'.\', \'dataset\', \'data\', \'metro_files\', cat, name + \'.png\']))\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--path1\', help=""Input file"", required=True)\n    parser.add_argument(\'--path2\', help=""Input file"", required=True)\n    parser.add_argument(\'--metro\', type=str, help=\'Path to the metro executable\',\n                        default=\'./metro_sources/build/metro\')\n\n    args = parser.parse_args()\n    return metro(args.path1, args.path2, args.metro)\n\n\nif __name__ == \'__main__\':\n    a = isolate_files()\n    print(a)\n'"
training/trainer.py,1,"b'import torch\nimport os\nimport auxiliary.html_report as html_report\nimport numpy as np\nfrom easydict import EasyDict\nimport pymesh\n\nfrom training.trainer_abstract import TrainerAbstract\nimport dataset.mesh_processor as mesh_processor\nfrom training.trainer_iteration import TrainerIteration\nfrom model.trainer_model import TrainerModel\nfrom dataset.trainer_dataset import TrainerDataset\nfrom training.trainer_loss import TrainerLoss\n\n\nclass Trainer(TrainerAbstract, TrainerLoss, TrainerIteration, TrainerDataset, TrainerModel):\n    def __init__(self, opt):\n        """"""\n        Main Atlasnet class inheriting from the other main modules.\n        It implements all functions related to train and evaluate for an epoch.\n        Author : Thibault Groueix 01.11.2019\n        :param opt:\n        """"""\n\n        super(Trainer, self).__init__(opt)\n        self.dataset_train = None\n        self.opt.training_media_path = os.path.join(self.opt.dir_name, ""training_media"")\n        if not os.path.exists(self.opt.training_media_path):\n            os.mkdir(self.opt.training_media_path)\n\n        # Define Flags\n        self.flags = EasyDict()\n        self.flags.media_count = 0\n        self.flags.add_log = True\n        self.flags.build_website = False\n        self.flags.get_closer_neighbourg = False\n        self.flags.compute_clustering_errors = False\n        self.display = EasyDict({""recons"": []})\n        self.colormap = mesh_processor.ColorMap()\n\n    def train_loop(self):\n        """"""\n        Take a single pass on all train data\n        :return:\n        """"""\n        iterator = self.datasets.dataloader_train.__iter__()\n        for data in iterator:\n            self.increment_iteration()\n            self.data = EasyDict(data)\n            self.data.points = self.data.points.to(self.opt.device)\n            if self.datasets.data_augmenter is not None and not self.opt.SVR:\n                # Apply data augmentation on points\n                self.datasets.data_augmenter(self.data.points)\n\n            self.train_iteration()\n\n    def train_epoch(self):\n        """""" Launch an train epoch """"""\n        self.flags.train = True\n        if self.epoch == (self.opt.nepoch - 1):\n            # Flag last epoch\n            self.flags.build_website = True\n\n        self.log.reset()\n        if not self.opt.no_learning:\n            self.network.train()\n        else:\n            self.network.eval()\n        self.learning_rate_scheduler()\n        self.reset_iteration()\n        for i in range(self.opt.loop_per_epoch):\n            self.train_loop()\n\n    def test_loop(self):\n        """"""\n        Take a single pass on all test data\n        :return:\n        """"""\n        iterator = self.datasets.dataloader_test.__iter__()\n        self.reset_iteration()\n        for data in iterator:\n            self.increment_iteration()\n            self.data = EasyDict(data)\n            self.data.points = self.data.points.to(self.opt.device)\n            self.test_iteration()\n\n    def test_epoch(self):\n        """""" Launch an test epoch """"""\n        self.flags.train = False\n        self.network.eval()\n        self.test_loop()\n        self.log.end_epoch()\n\n        try:\n            self.log.update_curves(self.visualizer.vis, self.opt.dir_name)\n        except:\n            print(""could not update curves"")\n        print(f""Sampled {self.num_val_points} regular points for evaluation"")\n\n        self.metro_results = 0\n        if (self.flags.build_website or self.opt.run_single_eval) and not self.opt.no_metro:\n            self.metro()\n\n        if self.flags.build_website:\n            # Build report using Netvision.\n            self.html_report_data = EasyDict()\n            self.html_report_data.output_meshes = [self.generate_random_mesh() for i in range(3)]\n            log_curves = [""loss_val"", ""loss_train_total""]\n            self.html_report_data.data_curve = {key: [np.log(val) for val in self.log.curves[key]] for key in\n                                                log_curves}\n            self.html_report_data.fscore_curve = {""fscore"": self.log.curves[""fscore""]}\n            html_report.main(self, outHtml=""index.html"")\n\n    def generate_random_mesh(self):\n        """""" Generate a mesh from a random test sample """"""\n        index = np.random.randint(self.datasets.len_dataset_test)\n        self.data = EasyDict(self.datasets.dataset_test[index])\n        self.data.points.unsqueeze_(0)\n        if self.opt.SVR:\n            self.data.image.unsqueeze_(0)\n        return self.generate_mesh()\n\n    def generate_mesh(self):\n        """"""\n        Generate a mesh from self.data and saves it.\n        :return:\n        """"""\n        self.make_network_input()\n        mesh = self.network.module.generate_mesh(self.data.network_input)\n        path = \'/\'.join([self.opt.training_media_path, str(self.flags.media_count)]) + "".obj""\n        image_path = \'/\'.join([self.data.image_path, \'00.png\'])\n        mesh_processor.save(mesh, path, self.colormap)\n        self.flags.media_count += 1\n        return {""output_path"": path,\n                ""image_path"": image_path}\n\n    def demo(self, demo_path, input_path_points=None):\n        """"""\n        This function takes an image or pointcloud path as input and save the mesh infered by Atlasnet\n        Extension supported are ply npy obg and png\n        :return: path to the generated mesh\n        """"""\n        ext = demo_path.split(\'.\')[-1]\n        self.data = self.datasets.dataset_train.load(demo_path)\n        self.data = EasyDict(self.data)\n\n        if input_path_points is None:\n            input_path_points = demo_path\n\n        #prepare normalization\n        get_normalization = self.datasets.dataset_train.load(input_path_points)\n        get_normalization = EasyDict(get_normalization)\n\n        self.make_network_input()\n        mesh = self.network.module.generate_mesh(self.data.network_input)\n        if get_normalization.operation is not None:\n            # Undo any normalization that was used to preprocess the input.\n            vertices = torch.from_numpy(mesh.vertices).clone().unsqueeze(0)\n            get_normalization.operation.invert()\n            unnormalized_vertices = get_normalization.operation.apply(vertices)\n            mesh = pymesh.form_mesh(vertices=unnormalized_vertices.squeeze().numpy(), faces=mesh.faces)\n\n        if self.opt.demo:\n            path = demo_path.split(\'.\')\n            path[-2] += ""AtlasnetReconstruction""\n            path[-1] = ""ply""\n            path = ""."".join(path)\n        else:\n            path = \'/\'.join([self.opt.training_media_path, str(self.flags.media_count)]) + "".ply""\n            self.flags.media_count += 1\n\n        print(f""Atlasnet generated mesh at {path}!"")\n        mesh_processor.save(mesh, path, self.colormap)\n        return path\n'"
training/trainer_abstract.py,3,"b'import torch\nimport torch.optim as optim\nimport auxiliary.my_utils as my_utils\nimport json\nimport auxiliary.visualization as visualization\nfrom os.path import join, exists\nfrom os import mkdir\nimport auxiliary.meter as meter\nfrom termcolor import colored\nimport time\n\n\nclass TrainerAbstract(object):\n    """"""\n    This class implements an abtsract deep learning trainer. It is supposed to be generic for any data, task, architecture, loss...\n    It defines the usual generic fonctions.\n    Author : Thibault Groueix 01.11.2019\n    """"""\n\n    def __init__(self, opt):\n        super(TrainerAbstract, self).__init__()\n        self.start_time = time.time()\n        self.opt = opt\n        self.start_visdom()\n        self.get_log_paths()\n        self.init_meters()\n        self.reset_epoch()\n        if not opt.demo:\n            my_utils.print_arg(self.opt)\n\n    def start_visdom(self):\n        self.visualizer = visualization.Visualizer(self.opt.visdom_port, self.opt.env, self.opt.http_port)\n        self.opt.visdom_port = self.visualizer.visdom_port\n        self.opt.http_port = self.visualizer.http_port\n\n    def get_log_paths(self):\n        """"""\n        Define paths to save and reload networks from parsed options\n        :return:\n        """"""\n\n        if not self.opt.demo:\n            if not exists(""log""):\n                print(""Creating log folder"")\n                mkdir(""log"")\n            if not exists(self.opt.dir_name):\n                print(""creating folder  "", self.opt.dir_name)\n                mkdir(self.opt.dir_name)\n\n        self.opt.log_path = join(self.opt.dir_name, ""log.txt"")\n        self.opt.optimizer_path = join(self.opt.dir_name, \'optimizer.pth\')\n        self.opt.model_path = join(self.opt.dir_name, ""network.pth"")\n        self.opt.reload_optimizer_path = """"\n\n        # # If a network is already created in the directory\n        if exists(self.opt.model_path):\n            self.opt.reload_model_path = self.opt.model_path\n            self.opt.reload_optimizer_path = self.opt.optimizer_path\n\n    def init_meters(self):\n        self.log = meter.Logs()\n\n    def print_loss_info(self):\n        pass\n\n    def save_network(self):\n        print(""saving net..."")\n        torch.save(self.network.state_dict(), self.opt.model_path)\n        torch.save(self.optimizer.state_dict(), self.opt.optimizer_path)\n        print(""network saved"")\n\n    def dump_stats(self):\n        """"""\n        Save stats at each epoch\n        """"""\n\n        log_table = {\n            ""epoch"": self.epoch + 1,\n            ""lr"": self.opt.lrate,\n            ""env"": self.opt.env,\n        }\n        log_table.update(self.log.current_epoch)\n        print(log_table)\n        with open(self.opt.log_path, ""a"") as f:  # open and append\n            f.write(""json_stats: "" + json.dumps(log_table) + ""\\n"")\n\n        self.opt.start_epoch = self.epoch\n        with open(join(self.opt.dir_name, ""options.json""), ""w"") as f:  # open and append\n            save_dict = dict(self.opt.__dict__)\n            save_dict.pop(""device"")\n            f.write(json.dumps(save_dict))\n\n    def print_iteration_stats(self, loss):\n        """"""\n        print stats at each iteration\n        """"""\n        current_time = time.time()\n        ellpased_time = current_time - self.start_train_time\n        total_time_estimated = self.opt.nepoch * (self.datasets.len_dataset / self.opt.batch_size) * ellpased_time / (\n                0.00001 + self.iteration + 1.0 * self.epoch * self.datasets.len_dataset / self.opt.batch_size)  # regle de 3\n        ETL = total_time_estimated - ellpased_time\n        print(\n            f""\\r[""\n            + colored(f""{self.epoch}"", ""cyan"")\n            + f"": ""\n            + colored(f""{self.iteration}"", ""red"")\n            + ""/""\n            + colored(f""{int(self.datasets.len_dataset / self.opt.batch_size)}"", ""red"")\n            + ""] chamfer train loss:  ""\n            + colored(f""{loss.item()} "", ""yellow"")\n            + colored(f""Ellapsed Time: {ellpased_time / 60 / 60}h "", ""cyan"")\n            + colored(f""ETL: {ETL / 60 / 60}h"", ""red""),\n            end="""",\n        )\n\n    def learning_rate_scheduler(self):\n        """"""\n        Defines the learning rate schedule\n        """"""\n        # Warm-up following https://arxiv.org/pdf/1706.02677.pdf\n        if len(self.next_learning_rates) > 0:\n            next_learning_rate = self.next_learning_rates.pop()\n            print(f""warm-up learning rate {next_learning_rate}"")\n            for g in self.optimizer.param_groups:\n                g[\'lr\'] = next_learning_rate\n\n        # Learning rate decay\n        if self.epoch == self.opt.lr_decay_1:\n            self.opt.lrate = self.opt.lrate / 10.0\n            print(f""First learning rate decay {self.opt.lrate}"")\n            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n        if self.epoch == self.opt.lr_decay_2:\n            self.opt.lrate = self.opt.lrate / 10.0\n            print(f""Second learning rate decay {self.opt.lrate}"")\n            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n        if self.epoch == self.opt.lr_decay_3:\n            self.opt.lrate = self.opt.lrate / 10.0\n            print(f""Third learning rate decay {self.opt.lrate}"")\n            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n\n    def increment_epoch(self):\n        self.epoch = self.epoch + 1\n\n    def increment_iteration(self):\n        self.iteration = self.iteration + 1\n\n    def reset_iteration(self):\n        self.iteration = 0\n\n    def reset_epoch(self):\n        self.epoch = self.opt.start_epoch\n'"
training/trainer_iteration.py,0,"b'from termcolor import colored\n\n\nclass TrainerIteration(object):\n    """"""\n        This class implements all functions related to a single forward pass of Atlasnet.\n        Author : Thibault Groueix 01.11.2019\n    """"""\n\n    def __init__(self):\n        super(TrainerIteration, self).__init__()\n\n    def make_network_input(self):\n        """"""\n        Arrange to data to be fed to the network.\n        :return:\n        """"""\n        if self.opt.SVR:\n            self.data.network_input = self.data.image.to(self.opt.device)\n        else:\n            self.data.network_input = self.data.points.transpose(2, 1).contiguous().to(self.opt.device)\n\n    def common_ops(self):\n        """"""\n        Commom operations between train and eval forward passes\n        :return:\n        """"""\n        self.make_network_input()\n        self.batch_size = self.data.points.size(0)\n\n        self.data.pointsReconstructed_prims = self.network(self.data.network_input,\n                                                           train=self.flags.train)\n        self.fuse_primitives()\n\n        self.loss_model()  # batch\n        self.visualize()\n\n    def train_iteration(self):\n        """"""\n        Forward backward pass\n        :return:\n        """"""\n        self.optimizer.zero_grad()\n        self.common_ops()\n        self.log.update(""loss_train_total"", self.data.loss.item())\n        if not self.opt.no_learning:\n            self.data.loss.backward()\n            self.optimizer.step()  # gradient update\n        self.print_iteration_stats(self.data.loss)\n\n    def visualize(self):\n        if self.iteration % 50 == 1:\n            tmp_string = ""train"" if self.flags.train else ""test""\n            self.visualizer.show_pointcloud(self.data.points[0], title=f""GT {tmp_string}"")\n            self.visualizer.show_pointcloud(self.data.pointsReconstructed[0], title=f""Reconstruction {tmp_string}"")\n            if self.opt.SVR:\n                self.visualizer.show_image(self.data.image[0], title=f""Input Image {tmp_string}"")\n\n    def test_iteration(self):\n        """"""\n        Forward evaluation pass\n        :return:\n        """"""\n        self.common_ops()\n        self.num_val_points = self.data.pointsReconstructed.size(1)\n        self.log.update(""loss_val"", self.data.loss.item())\n        self.log.update(""fscore"", self.data.loss_fscore.item())\n        print(\n            \'\\r\' + colored(\n                \'[%d: %d/%d]\' % (self.epoch, self.iteration, self.datasets.len_dataset_test / self.opt.batch_size_test),\n                \'red\') +\n            colored(\'loss_val:  %f\' % self.data.loss.item(), \'yellow\'),\n            end=\'\')\n'"
training/trainer_loss.py,3,"b'import torch\nimport auxiliary.ChamferDistancePytorch.chamfer3D.dist_chamfer_3D as dist_chamfer_3D\n\n\nfrom auxiliary.ChamferDistancePytorch.fscore import fscore\nimport os\nimport training.metro as metro\nfrom joblib import Parallel, delayed\nimport numpy as np\n\n\nclass TrainerLoss(object):\n    """"""\n    This class implements all functions related to the loss of Atlasnet, mainly applies chamfer and metro.\n    Author : Thibault Groueix 01.11.2019\n    """"""\n\n    def __init__(self):\n        super(TrainerLoss, self).__init__()\n\n    def build_losses(self):\n        """"""\n        Create loss functions.\n        """"""\n        self.distChamfer = dist_chamfer_3D.chamfer_3DDist()\n        self.loss_model = self.chamfer_loss\n\n    def fuse_primitives(self):\n        """"""\n        Merge generated surface elements in a single one and prepare data for Chamfer\n        Input size : batch, prim, 3, npoints\n        Output size : prim, prim*npoints, 3\n        :return:\n        """"""\n        #\n        self.data.pointsReconstructed = self.data.pointsReconstructed_prims.transpose(2, 3).contiguous()\n        self.data.pointsReconstructed = self.data.pointsReconstructed.view(self.batch_size, -1, 3)\n\n    def chamfer_loss(self):\n        """"""\n        Training loss of Atlasnet. The Chamfer Distance. Compute the f-score in eval mode.\n        :return:\n        """"""\n        inCham1 = self.data.points.view(self.data.points.size(0), -1, 3).contiguous()\n        inCham2 = self.data.pointsReconstructed.contiguous().view(self.data.points.size(0), -1, 3).contiguous()\n\n        dist1, dist2, idx1, idx2 = self.distChamfer(inCham1, inCham2)  # mean over points\n        self.data.loss = torch.mean(dist1) + torch.mean(dist2)  # mean over points\n        if not self.flags.train:\n            self.data.loss_fscore, _, _ = fscore(dist1, dist2)\n            self.data.loss_fscore = self.data.loss_fscore.mean()\n\n    def metro(self):\n        """"""\n        Compute the metro distance on a randomly selected test files.\n        Uses joblib to leverage as much cpu as possible\n        :return:\n        """"""\n        metro_path = \'./dataset/data/metro_files\'\n        metro_files_path = \'/\'.join([metro_path, \'files-metro.txt\'])\n        self.metro_args_input = []\n        if not os.path.exists(metro_files_path):\n            os.system(""chmod +x dataset/download_metro_files.sh"")\n            os.system(""./dataset/download_metro_files.sh"")\n        ext = \'.png\' if self.opt.SVR else \'.npy\'\n        with open(metro_files_path, \'r\') as file:\n            files = file.read().split(\'\\n\')\n\n        for file in files:\n            if file[-3:] == ""ply"":\n                cat = file.split(\'/\')[0]\n                name = file.split(\'/\')[1][:-4]\n                input_path = \'/\'.join([metro_path, cat, name + ext])\n                input_path_points = \'/\'.join([metro_path, cat, name + \'.npy\'])\n                gt_path = \'/\'.join([metro_path, cat, name + \'.ply\'])\n                path = self.demo(input_path, input_path_points)\n                self.metro_args_input.append((path, gt_path))\n\n        print(""start metro calculus. This is going to take some time (30 minutes)"")\n        self.metro_results = Parallel(n_jobs=-1, backend=""multiprocessing"")(\n            delayed(metro.metro)(*i) for i in self.metro_args_input)\n        self.metro_results = np.array(self.metro_results).mean()\n        print(f""Metro distance : {self.metro_results}"")\n'"
auxiliary/sampling_and_meshing/__init__.py,0,b''
auxiliary/sampling_and_meshing/Shuffle/__init__.py,0,b''
auxiliary/sampling_and_meshing/Shuffle/parallel_shuffle.py,0,"b'# Written by the mighty Pierre-Alain Langlois\n\n\nimport argparse\nfrom os import listdir\nfrom os.path import isfile, join\nimport pymesh\nimport numpy as np\nimport copy\nimport joblib\nfrom joblib import Parallel, delayed\nfrom collections import defaultdict\n\n\ndef shuffle_pc(file, output_path):\n    mesh = pymesh.load_mesh(file)\n    vertices = copy.deepcopy(mesh.vertices)\n    permutation = np.random.permutation(len(vertices))\n    vertices = vertices[permutation]\n    new_mesh = pymesh.meshio.form_mesh(vertices, mesh.faces)\n    new_mesh.add_attribute(""vertex_nx"")\n    new_mesh.set_attribute(""vertex_nx"", mesh.get_vertex_attribute(""vertex_nx"")[permutation])\n    new_mesh.add_attribute(""vertex_ny"")\n    new_mesh.set_attribute(""vertex_ny"", mesh.get_vertex_attribute(""vertex_ny"")[permutation])\n    new_mesh.add_attribute(""vertex_nz"")\n    new_mesh.set_attribute(""vertex_nz"", mesh.get_vertex_attribute(""vertex_nz"")[permutation])\n    pymesh.save_mesh(output_path, new_mesh, ascii=True, anonymous=True, use_float=True, *new_mesh.get_attribute_names())\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--input"", help=""Input Folder"", required=True)\n    parser.add_argument(""--output"", help=""Output Folder"", required=True)\n    args = parser.parse_args()\n\n    onlyfiles = [(join(args.input, f), join(args.output, f)) for f in listdir(args.input) if\n                 isfile(join(args.input, f))]\n\n    class BatchCompletionCallBack(object):\n        completed = defaultdict(int)\n\n        def __init__(self, time, index, parallel):\n            self.index = index\n            self.parallel = parallel\n\n        def __call__(self, index):\n            BatchCompletionCallBack.completed[self.parallel] += 1\n            print(""Progress : %s %% "" %\n                  str(BatchCompletionCallBack.completed[self.parallel] * 100 / len(onlyfiles)))\n            if self.parallel._original_iterator is not None:\n                self.parallel.dispatch_next()\n\n    joblib.parallel.BatchCompletionCallBack = BatchCompletionCallBack\n\n    _ = Parallel(n_jobs=-1, backend=""multiprocessing"") \\\n        (delayed(shuffle_pc)(*i) for i in onlyfiles)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
auxiliary/sampling_and_meshing/Shuffle/shuffle.py,0,"b'# Written by the mighty Pierre-Alain Langlois\n\n\nimport argparse\nfrom os import listdir\nfrom os.path import isfile, join\nimport pymesh\nimport numpy as np\nimport copy\n\n\ndef shuffle_pc(file, output_path):\n    """"""\n    Function to shuffle a point cloud produced by virtual scanner.\n    """"""\n    mesh = pymesh.load_mesh(file)\n    vertices = copy.deepcopy(mesh.vertices)\n    permutation = np.random.permutation(len(vertices))\n    vertices = vertices[permutation]\n    new_mesh = pymesh.meshio.form_mesh(vertices, mesh.faces)\n    new_mesh.add_attribute(""vertex_nx"")\n    new_mesh.set_attribute(""vertex_nx"", mesh.get_vertex_attribute(""vertex_nx"")[permutation])\n    new_mesh.add_attribute(""vertex_ny"")\n    new_mesh.set_attribute(""vertex_ny"", mesh.get_vertex_attribute(""vertex_ny"")[permutation])\n    new_mesh.add_attribute(""vertex_nz"")\n    new_mesh.set_attribute(""vertex_nz"", mesh.get_vertex_attribute(""vertex_nz"")[permutation])\n    pymesh.save_mesh(output_path, new_mesh, ascii=True, anonymous=True, use_float=True, *new_mesh.get_attribute_names())\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--input"", help=""Input file"", required=True)\n    parser.add_argument(""--output"", help=""Output file"", required=True)\n    args = parser.parse_args()\n    shuffle_pc(args.input, args.output)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
