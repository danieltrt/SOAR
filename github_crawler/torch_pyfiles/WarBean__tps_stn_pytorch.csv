file_path,api_count,code
data_loader.py,2,"b""# encoding: utf-8\n\nimport torch\nimport random\nfrom torchvision import datasets, transforms\n\ndef get_train_loader(args):\n    return torch.utils.data.DataLoader(\n        datasets.MNIST(\n            'mnist_data',\n            train = True,\n            download = True,\n            transform = transforms.Compose([\n                transforms.Lambda(lambda image: image.rotate(random.random() * args.angle * 2 - args.angle)),\n                transforms.ToTensor(),\n            ]),\n        ),\n        batch_size = args.batch_size,\n        shuffle = True,\n        num_workers = 4,\n        pin_memory = True if args.cuda else False,\n    )\n\ndef get_test_loader(args):\n    return torch.utils.data.DataLoader(\n        datasets.MNIST(\n            'mnist_data',\n            train = False,\n            download = True,\n            transform = transforms.Compose([\n                transforms.Lambda(lambda image: image.rotate(random.random() * args.angle * 2 - args.angle)),\n                transforms.ToTensor(),\n            ]),\n        ),\n        batch_size = args.batch_size,\n        shuffle = True,\n        num_workers = 4,\n        pin_memory = True if args.cuda else False,\n    )\n"""
grid_sample.py,2,"b'# encoding: utf-8\n\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\ndef grid_sample(input, grid, canvas = None):\n    output = F.grid_sample(input, grid)\n    if canvas is None:\n        return output\n    else:\n        input_mask = Variable(input.data.new(input.size()).fill_(1))\n        output_mask = F.grid_sample(input_mask, grid)\n        padded_output = output * output_mask + canvas * (1 - output_mask)\n        return padded_output\n'"
mnist_make_gif.py,0,"b""# encoding: utf-8\n\nimport os\nimport glob\nimport imageio\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--model', required = True)\nparser.add_argument('--angle', type = int, default = 60)\nparser.add_argument('--grid_size', type = int, default = 4)\nargs = parser.parse_args()\n\ngif_dir = 'gif/%s_angle%d_grid%d/' % (args.model, args.angle, args.grid_size)\nif not os.path.isdir(gif_dir):\n    os.makedirs(gif_dir)\n\nmax_iter = 100\nfor i in range(max_iter):\n    print('sample %d' % i)\n    paths = sorted(glob.glob('image/%s_angle%d_grid%d/sample%03d_*.png' % (\n        args.model, args.angle, args.grid_size, i,\n    )))\n    images = [imageio.imread(path) for path in paths]\n    for _ in range(20): images.append(images[-1]) # delay at the end\n    imageio.mimsave(gif_dir + 'sample%03d.gif' % i, images)\n"""
mnist_model.py,6,"b""# encoding: utf-8\n\nimport math\nimport torch\nimport itertools\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom grid_sample import grid_sample\nfrom torch.autograd import Variable\nfrom tps_grid_gen import TPSGridGen\n\nclass CNN(nn.Module):\n    def __init__(self, num_output):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, num_output)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return x\n\nclass ClsNet(nn.Module):\n\n    def __init__(self):\n        super(ClsNet, self).__init__()\n        self.cnn = CNN(10)\n\n    def forward(self, x):\n        return F.log_softmax(self.cnn(x))\n\nclass BoundedGridLocNet(nn.Module):\n\n    def __init__(self, grid_height, grid_width, target_control_points):\n        super(BoundedGridLocNet, self).__init__()\n        self.cnn = CNN(grid_height * grid_width * 2)\n\n        bias = torch.from_numpy(np.arctanh(target_control_points.numpy()))\n        bias = bias.view(-1)\n        self.cnn.fc2.bias.data.copy_(bias)\n        self.cnn.fc2.weight.data.zero_()\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        points = F.tanh(self.cnn(x))\n        return points.view(batch_size, -1, 2)\n\nclass UnBoundedGridLocNet(nn.Module):\n\n    def __init__(self, grid_height, grid_width, target_control_points):\n        super(UnBoundedGridLocNet, self).__init__()\n        self.cnn = CNN(grid_height * grid_width * 2)\n\n        bias = target_control_points.view(-1)\n        self.cnn.fc2.bias.data.copy_(bias)\n        self.cnn.fc2.weight.data.zero_()\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        points = self.cnn(x)\n        return points.view(batch_size, -1, 2)\n\nclass STNClsNet(nn.Module):\n\n    def __init__(self, args):\n        super(STNClsNet, self).__init__()\n        self.args = args\n\n        r1 = args.span_range_height\n        r2 = args.span_range_width\n        assert r1 < 1 and r2 < 1 # if >= 1, arctanh will cause error in BoundedGridLocNet\n        target_control_points = torch.Tensor(list(itertools.product(\n            np.arange(-r1, r1 + 0.00001, 2.0  * r1 / (args.grid_height - 1)),\n            np.arange(-r2, r2 + 0.00001, 2.0  * r2 / (args.grid_width - 1)),\n        )))\n        Y, X = target_control_points.split(1, dim = 1)\n        target_control_points = torch.cat([X, Y], dim = 1)\n\n        GridLocNet = {\n            'unbounded_stn': UnBoundedGridLocNet,\n            'bounded_stn': BoundedGridLocNet,\n        }[args.model]\n        self.loc_net = GridLocNet(args.grid_height, args.grid_width, target_control_points)\n\n        self.tps = TPSGridGen(args.image_height, args.image_width, target_control_points)\n\n        self.cls_net = ClsNet()\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        source_control_points = self.loc_net(x)\n        source_coordinate = self.tps(source_control_points)\n        grid = source_coordinate.view(batch_size, self.args.image_height, self.args.image_width, 2)\n        transformed_x = grid_sample(x, grid)\n        logit = self.cls_net(transformed_x)\n        return logit\n\ndef get_model(args):\n    if args.model == 'no_stn':\n        print('create model without STN')\n        model = ClsNet()\n    else:\n        print('create model with STN')\n        model = STNClsNet(args)\n    return model\n"""
mnist_plot_curve.py,0,"b""# encoding: utf-8\n\nimport os\nimport glob\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (10, 10))\nfor path in sorted(glob.glob('accuracy_log/*.txt')):\n    accu_list = [float(line.strip()) for line in open(path)]\n    label = os.path.basename(path)[:-4]\n    model1, model2, angle, grid = label.split('_')\n    linestyle = {\n        'angle60': '-',\n        'angle90': ':',\n    }[angle]\n    color = {\n        'no_stn_grid2': '#F08080',\n        'no_stn_grid3': '#FF6347',\n        'no_stn_grid4': '#FF4500',\n        'no_stn_grid5': '#FF0000',\n        'bounded_stn_grid2': '#98FB98',\n        'bounded_stn_grid3': '#00FF7F',\n        'bounded_stn_grid4': '#3CB371',\n        'bounded_stn_grid5': '#2E8B57',\n        'unbounded_stn_grid2': '#00BFFF',\n        'unbounded_stn_grid3': '#0000FF',\n        'unbounded_stn_grid4': '#0000CD',\n        'unbounded_stn_grid5': '#000080',\n    }[model1 + '_' + model2 + '_' + grid]\n    plt.plot(\n        list(range(len(accu_list))), accu_list,\n        color = color, linestyle = linestyle, linewidth = 0.5,\n        label = label,\n    )\nplt.legend(loc = 'lower right')\nif not os.path.isdir('demo'):\n    os.makedirs('demo')\nplt.savefig('demo/curve.png')\n"""
mnist_train.py,8,"b""# encoding: utf-8\n\nimport os\nimport torch\nimport random\nimport argparse\nimport mnist_model\nimport data_loader\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n# Training settings\nparser = argparse.ArgumentParser()\nparser.add_argument('--batch-size', type = int, default = 64)\nparser.add_argument('--test-batch-size', type = int, default = 1000)\nparser.add_argument('--epochs', type = int, default = 10)\nparser.add_argument('--lr', type = float, default = 0.01)\nparser.add_argument('--momentum', type=float, default = 0.5)\nparser.add_argument('--no-cuda', action = 'store_true', default = False)\nparser.add_argument('--seed', type = int, default = 1)\nparser.add_argument('--log-interval', type = int, default = 10)\nparser.add_argument('--save-interval', type = int, default = 100)\nparser.add_argument('--model', required = True)\nparser.add_argument('--angle', type = int, default=60)\nparser.add_argument('--span_range', type = int, default = 0.9)\nparser.add_argument('--grid_size', type = int, default = 4)\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nargs.span_range_height = args.span_range_width = args.span_range\nargs.grid_height = args.grid_width = args.grid_size\nargs.image_height = args.image_width = 28\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nmodel = mnist_model.get_model(args)\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr = args.lr, momentum = args.momentum)\ntrain_loader = data_loader.get_train_loader(args)\ntest_loader = data_loader.get_test_loader(args)\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n        if batch_idx % args.save_interval == 0:\n            checkpoint_path = checkpoint_dir + 'epoch%03d_iter%03d.pth' % (epoch, batch_idx)\n            torch.save(model.cpu().state_dict(), checkpoint_path)\n            if args.cuda:\n                model.cuda()\n\ndef test(epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile = True), Variable(target)\n        output = model(data)\n        test_loss += F.nll_loss(output, target).data[0]\n        pred = output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data).cpu().sum()\n\n    test_loss = test_loss\n    test_loss /= len(test_loader) # loss function already averages over batch size\n    accuracy = 100. * correct / len(test_loader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.02f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset), accuracy,\n    ))\n    log_file.write('{:.02f}\\n'.format(accuracy))\n    log_file.flush()\n    os.fsync(log_file)\n\n\ncheckpoint_dir = 'checkpoint/%s_angle%d_grid%d/' % (\n    args.model, args.angle, args.grid_size,\n)\nif not os.path.isdir(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\nif not os.path.isdir('accuracy_log'):\n    os.makedirs('accuracy_log')\nlog_file_path = 'accuracy_log/%s_angle%d_grid%d.txt' % (\n    args.model, args.angle, args.grid_size,\n)\n\nwith open(log_file_path, 'w') as log_file:\n    for epoch in range(1, args.epochs + 1):\n        train(epoch)\n        test(epoch)\n"""
mnist_visualize.py,4,"b""# encoding: utf-8\n\nimport os\nimport glob\nimport torch\nimport random\nimport argparse\nimport mnist_model\nimport data_loader\nimport numpy as np\nfrom mnist_model import STNClsNet\nfrom grid_sample import grid_sample\nfrom torch.autograd import Variable\nfrom PIL import Image, ImageDraw, ImageFont\nfrom torchvision import datasets, transforms\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--batch-size', type = int, default = 64)\nparser.add_argument('--angle', type = int, default = 60)\nparser.add_argument('--no-cuda', action = 'store_true', default = False)\nparser.add_argument('--model', required = True)\nparser.add_argument('--span_range', type = int, default = 0.9)\nparser.add_argument('--grid_size', type = int, default = 4)\nargs = parser.parse_args()\n\nargs.span_range_height = args.span_range_width = args.span_range\nargs.grid_height = args.grid_width = args.grid_size\nargs.image_height = args.image_width = 28\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\nrandom.seed(1024)\n\nassert args.model in ['bounded_stn', 'unbounded_stn']\nmodel = mnist_model.get_model(args)\nif args.cuda:\n    model.cuda()\nimage_dir = 'image/%s_angle%d_grid%d/' % (args.model, args.angle, args.grid_size)\nif not os.path.isdir(image_dir):\n    os.makedirs(image_dir)\n\ntest_loader = data_loader.get_test_loader(args)\ntarget2data_list = { i: [] for i in range(10) }\ntotal = 0\nN = 10\nfor data_batch, target_batch in test_loader:\n    for data, target in zip(data_batch, target_batch):\n        data_list = target2data_list[target]\n        if len(data_list) < N:\n            data_list.append(data)\n            total += 1\n    if total == N * 10:\n        break\ndata_list = [target2data_list[i][j] for i in range(10) for j in range(N)]\nsource_data = torch.stack(data_list)\nif args.cuda:\n    source_data = source_data.cuda()\nbatch_size = N * 10\nframes_list = [[] for _ in range(batch_size)]\n\npaths = sorted(glob.glob('checkpoint/%s_angle%d_grid%d/*.pth' % (\n    args.model, args.angle, args.grid_size,\n)))[::-1]\nfont = ImageFont.truetype('Comic Sans MS.ttf', 20)\nfor pi, path in enumerate(paths): # path index\n    print('path %d/%d: %s' % (pi, len(paths), path))\n    model.load_state_dict(torch.load(path))\n    source_control_points = model.loc_net(Variable(source_data, volatile = True))\n    source_coordinate = model.tps(source_control_points)\n    grid = source_coordinate.view(batch_size, 28, 28, 2)\n    target_data = grid_sample(source_data, grid).data\n\n    source_array = (source_data[:, 0] * 255).cpu().numpy().astype('uint8')\n    target_array = (target_data[:, 0] * 255).cpu().numpy().astype('uint8')\n    for si in range(batch_size): # sample index\n        # resize for better visualization\n        source_image = Image.fromarray(source_array[si]).convert('RGB').resize((128, 128))\n        target_image = Image.fromarray(target_array[si]).convert('RGB').resize((128, 128))\n        # create grey canvas for external control points\n        canvas = Image.new(mode = 'RGB', size = (64 * 7, 64 * 4), color = (128, 128, 128))\n        canvas.paste(source_image, (64, 64))\n        canvas.paste(target_image, (64 * 4, 64))\n        source_points = source_control_points.data[si]\n        source_points = (source_points + 1) / 2 * 128 + 64\n        draw = ImageDraw.Draw(canvas)\n        for x, y in source_points:\n            draw.rectangle([x - 2, y - 2, x + 2, y + 2], fill = (255, 0, 0))\n        source_points = source_points.view(args.grid_size, args.grid_size, 2)\n        for j in range(args.grid_size):\n            for k in range(args.grid_size):\n                x1, y1 = source_points[j, k]\n                if j > 0: # connect to left\n                    x2, y2 = source_points[j - 1, k]\n                    draw.line((x1, y1, x2, y2), fill = (255, 0, 0))\n                if k > 0: # connect to up\n                    x2, y2 = source_points[j, k - 1]\n                    draw.line((x1, y1, x2, y2), fill = (255, 0, 0))\n        draw.text((10, 0), 'sample %03d, iter %03d' % (si, len(paths) - 1 - pi), fill = (255, 0, 0), font = font)\n        canvas.save(image_dir + 'sample%03d_iter%03d.png' % (si, len(paths) - 1 - pi))\n"""
single_visualize.py,8,"b""# encoding: utf-8\n\nimport time\nimport torch\nimport itertools\nimport numpy as np\nfrom PIL import Image\nfrom grid_sample import grid_sample\nfrom torch.autograd import Variable\nfrom tps_grid_gen import TPSGridGen\n\nsource_image = Image.open('demo/source_avatar.jpg').convert(mode = 'RGB')\nsource_image = np.array(source_image).astype('float32')\nsource_image = np.expand_dims(source_image.swapaxes(2, 1).swapaxes(1, 0), 0)\nsource_image = Variable(torch.from_numpy(source_image))\n_, _, source_height, source_width = source_image.size()\ntarget_height = 400\ntarget_width = 400\n\n# creat control points\ntarget_control_points = torch.Tensor(list(itertools.product(\n    torch.arange(-1.0, 1.00001, 2.0 / 4),\n    torch.arange(-1.0, 1.00001, 2.0 / 4),\n)))\nsource_control_points = target_control_points + torch.Tensor(target_control_points.size()).uniform_(-0.1, 0.1)\n\nprint('initialize module')\nbeg_time = time.time()\ntps = TPSGridGen(target_height, target_width, target_control_points)\npast_time = time.time() - beg_time\nprint('initialization takes %.02fs' % past_time)\n\nsource_coordinate = tps(Variable(torch.unsqueeze(source_control_points, 0)))\ngrid = source_coordinate.view(1, target_height, target_width, 2)\ncanvas = Variable(torch.Tensor(1, 3, target_height, target_width).fill_(255))\ntarget_image = grid_sample(source_image, grid, canvas)\ntarget_image = target_image.data.numpy().squeeze().swapaxes(0, 1).swapaxes(1, 2)\ntarget_image = Image.fromarray(target_image.astype('uint8'))\ntarget_image.save('demo/target_avatar.jpg')\n"""
tps_grid_gen.py,14,"b""# encoding: utf-8\n\nimport torch\nimport itertools\nimport torch.nn as nn\nfrom torch.autograd import Function, Variable\n\n# phi(x1, x2) = r^2 * log(r), where r = ||x1 - x2||_2\ndef compute_partial_repr(input_points, control_points):\n    N = input_points.size(0)\n    M = control_points.size(0)\n    pairwise_diff = input_points.view(N, 1, 2) - control_points.view(1, M, 2)\n    # original implementation, very slow\n    # pairwise_dist = torch.sum(pairwise_diff ** 2, dim = 2) # square of distance\n    pairwise_diff_square = pairwise_diff * pairwise_diff\n    pairwise_dist = pairwise_diff_square[:, :, 0] + pairwise_diff_square[:, :, 1]\n    repr_matrix = 0.5 * pairwise_dist * torch.log(pairwise_dist)\n    # fix numerical error for 0 * log(0), substitute all nan with 0\n    mask = repr_matrix != repr_matrix\n    repr_matrix.masked_fill_(mask, 0)\n    return repr_matrix\n\nclass TPSGridGen(nn.Module):\n\n    def __init__(self, target_height, target_width, target_control_points):\n        super(TPSGridGen, self).__init__()\n        assert target_control_points.ndimension() == 2\n        assert target_control_points.size(1) == 2\n        N = target_control_points.size(0)\n        self.num_points = N\n        target_control_points = target_control_points.float()\n\n        # create padded kernel matrix\n        forward_kernel = torch.zeros(N + 3, N + 3)\n        target_control_partial_repr = compute_partial_repr(target_control_points, target_control_points)\n        forward_kernel[:N, :N].copy_(target_control_partial_repr)\n        forward_kernel[:N, -3].fill_(1)\n        forward_kernel[-3, :N].fill_(1)\n        forward_kernel[:N, -2:].copy_(target_control_points)\n        forward_kernel[-2:, :N].copy_(target_control_points.transpose(0, 1))\n        # compute inverse matrix\n        inverse_kernel = torch.inverse(forward_kernel)\n\n        # create target cordinate matrix\n        HW = target_height * target_width\n        target_coordinate = list(itertools.product(range(target_height), range(target_width)))\n        target_coordinate = torch.Tensor(target_coordinate) # HW x 2\n        Y, X = target_coordinate.split(1, dim = 1)\n        Y = Y * 2 / (target_height - 1) - 1\n        X = X * 2 / (target_width - 1) - 1\n        target_coordinate = torch.cat([X, Y], dim = 1) # convert from (y, x) to (x, y)\n        target_coordinate_partial_repr = compute_partial_repr(target_coordinate, target_control_points)\n        target_coordinate_repr = torch.cat([\n            target_coordinate_partial_repr, torch.ones(HW, 1), target_coordinate\n        ], dim = 1)\n\n        # register precomputed matrices\n        self.register_buffer('inverse_kernel', inverse_kernel)\n        self.register_buffer('padding_matrix', torch.zeros(3, 2))\n        self.register_buffer('target_coordinate_repr', target_coordinate_repr)\n\n    def forward(self, source_control_points):\n        assert source_control_points.ndimension() == 3\n        assert source_control_points.size(1) == self.num_points\n        assert source_control_points.size(2) == 2\n        batch_size = source_control_points.size(0)\n\n        Y = torch.cat([source_control_points, Variable(self.padding_matrix.expand(batch_size, 3, 2))], 1)\n        mapping_matrix = torch.matmul(Variable(self.inverse_kernel), Y)\n        source_coordinate = torch.matmul(Variable(self.target_coordinate_repr), mapping_matrix)\n        return source_coordinate\n"""
