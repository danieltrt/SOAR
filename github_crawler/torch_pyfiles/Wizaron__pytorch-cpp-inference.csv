file_path,api_count,code
models/resnet/resnet.py,6,"b'import torch\nimport torchvision\n\n# An instance of your model.\nmodel = torchvision.models.resnet18(pretrained=True)\n\n# Evaluation mode\nmodel.eval()\n\n# An example input you would normally provide to your model\'s forward() method.\nexample = torch.rand(1, 3, 224, 224)\n\ndef export_cpu(model, example):\n    model = model.to(""cpu"")\n    example = example.to(""cpu"")\n\n    # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n    traced_script_module = torch.jit.trace(model, example)\n\n    # Save traced model\n    traced_script_module.save(""resnet_model_cpu.pth"")\n\ndef export_gpu(model, example):\n    model = model.to(""cuda"")\n    example = example.to(""cuda"")\n\n    # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n    traced_script_module = torch.jit.trace(model, example)\n\n    # Save traced model\n    traced_script_module.save(""resnet_model_gpu.pth"")\n\nexport_cpu(model, example)\n\nif torch.cuda.is_available():\n    export_gpu(model, example)\n'"
inference-cpp/cnn-classification/server/test_api.py,0,"b'import requests, json, base64\n\nurl = ""http://localhost:8181/predict""\n\nimage_path = ""../image.jpeg""\n\nresult = requests.post(url, json={""image"": base64.b64encode(open(image_path, ""rb"").read())}).text\n\nprint(json.loads(result))\n'"
