file_path,api_count,code
noxfile.py,0,"b'import os\n\nimport nox\nfrom packaging import version\nfrom platform import system\nimport sys\n\nsys.path.append(os.path.join(os.path.dirname(__file__), os.path.join(\'.\', \'.github\', \'workflows\')))\nfrom gen_github_actions import *\n\nPYTORCH_CPU_VIRTUAL_PKG = \'1.2.0\'\nPYTORCH_PILLOW_FIXED = \'1.4.0\'\nNOX_WIN_NUMPY_VERSION = \'1.17.4\'  # avoid errors from more recent Numpy called through Nox on Windows\nCONDA_PYTHON_IDS = tuple([f\'conda_python_{i}\' for i in CONDA_PYTHON_VERSIONS])\nPYTORCH_IDS = tuple([f\'pytorch_{i}\' for i in PYTORCH_VERSIONS])\nJIT_IDS = tuple([f\'{i}\'.lower() for i in JIT_STATUSES])\n\ndef install_pytorch(pytorch, session):\n    is_win = system() == \'Windows\'\n    is_cpu_virtual = version.parse(pytorch) >= version.parse(PYTORCH_CPU_VIRTUAL_PKG)\n    if is_cpu_virtual:\n        cmd = [\'-c\', \'pytorch\', f\'pytorch=={pytorch}\', \'cpuonly\']\n    else:\n        cmd = [\'-c\', \'pytorch\', f\'pytorch-cpu=={pytorch}\']\n    if is_win:\n        cmd += [f\'numpy=={NOX_WIN_NUMPY_VERSION}\']\n    session.conda_install(*cmd)\n\n\ndef install_torchvision(pytorch, session):\n    is_cpu_virtual = version.parse(pytorch) >= version.parse(PYTORCH_CPU_VIRTUAL_PKG)\n    fixed_pillow = version.parse(pytorch) >= version.parse(PYTORCH_PILLOW_FIXED)\n    if is_cpu_virtual:\n        cmd = [\'-c\', \'pytorch\', \'torchvision\', \'cpuonly\']\n    else:\n        cmd = [\'-c\', \'pytorch\', \'torchvision-cpu\']\n    if not fixed_pillow:\n        cmd += [\'Pillow==6.2.0\']\n    session.conda_install(*cmd)\n\n\ndef dry_run_install_pytorch_deps(python, pytorch, session, deps_only):\n    deps = \'--only-deps\' if deps_only else \'--no-deps\'\n    is_win = system() == \'Windows\'\n    is_cpu_virtual = version.parse(pytorch) >= version.parse(PYTORCH_CPU_VIRTUAL_PKG)\n    if is_cpu_virtual:\n        cmd = [\'conda\', \'create\', \'-n\', \'dry_run\', deps, \'-d\', \'-c\', \'pytorch\', f\'pytorch=={pytorch}\',\n               f\'numpy=={NOX_WIN_NUMPY_VERSION}\', \'cpuonly\', f\'python={python}\']\n    else:\n        cmd = [\'conda\', \'create\', \'-n\', \'dry_run\', deps, \'-d\', \'-c\', \'pytorch\', f\'pytorch-cpu=={pytorch}\',\n               \'cpuonly\', f\'python={python}\']\n    if is_win:\n        cmd += [f\'numpy=={NOX_WIN_NUMPY_VERSION}\']\n    session.run(*cmd)\n\n\n@nox.session(venv_backend=""conda"", python=CONDA_PYTHON_VERSIONS)\n@nox.parametrize(""pytorch"", PYTORCH_VERSIONS, ids=PYTORCH_IDS)\n@nox.parametrize(""jit_status"", JIT_STATUSES, ids=JIT_IDS)\ndef tests_brevitas_cpu(session, pytorch, jit_status):\n    session.env[\'PYTORCH_JIT\'] = \'{}\'.format(int(jit_status == \'jit_enabled\'))\n    install_pytorch(pytorch, session)\n    session.install(\'.[test]\')\n    session.run(\'pytest\', \'test/brevitas\', \'-v\')\n\n\n@nox.session(venv_backend=""conda"", python=CONDA_PYTHON_VERSIONS)\n@nox.parametrize(""pytorch"", PYTORCH_VERSIONS, ids=PYTORCH_IDS)\n@nox.parametrize(""jit_status"", JIT_STATUSES, ids=JIT_IDS)\ndef tests_brevitas_examples_cpu(session, pytorch, jit_status):\n    session.env[\'PYTORCH_JIT\'] = \'{}\'.format(int(jit_status == \'jit_enabled\'))\n    install_pytorch(pytorch, session)\n    install_torchvision(pytorch, session)  # For CV eval scripts\n    session.conda_install(\'scipy\')  # For Hadamard example\n    session.install(\'.[test, tts, stt, vision]\')\n    session.run(\'pytest\', \'test/brevitas_examples\', \'-v\')\n\n\n@nox.session(venv_backend=""conda"", python=CONDA_PYTHON_VERSIONS)\n@nox.parametrize(""pytorch"", PYTORCH_VERSIONS, ids=PYTORCH_IDS)\ndef tests_brevitas_install_dev(session, pytorch):\n    install_pytorch(pytorch, session)\n    session.install(\'-e\', \'.[test]\')\n    session.run(\'pytest\', \'-v\', \'test/brevitas/test_import.py\')\n\n\n@nox.session(venv_backend=""conda"", python=CONDA_PYTHON_VERSIONS)\n@nox.parametrize(""pytorch"", PYTORCH_VERSIONS, ids=PYTORCH_IDS)\ndef tests_brevitas_examples_install_dev(session, pytorch):\n    install_pytorch(pytorch, session)\n    session.conda_install(\'scipy\')  # For Hadamard example\n    session.install(\'-e\', \'.[test, tts, stt]\')\n    session.run(\'pytest\', \'-v\', \'test/brevitas_examples/test_import.py\')\n\n\n@nox.session(python=False)\n@nox.parametrize(""pytorch"", PYTORCH_VERSIONS, ids=PYTORCH_IDS)\n@nox.parametrize(""python"", CONDA_PYTHON_VERSIONS, ids=CONDA_PYTHON_IDS)\ndef dry_run_pytorch_only_deps(session, pytorch, python):\n    dry_run_install_pytorch_deps(python, pytorch, session, deps_only=True)\n\n\n@nox.session(python=False)\n@nox.parametrize(""pytorch"", PYTORCH_VERSIONS, ids=PYTORCH_IDS)\n@nox.parametrize(""python"", CONDA_PYTHON_VERSIONS, ids=CONDA_PYTHON_IDS)\ndef dry_run_pytorch_no_deps(session, pytorch, python):\n    dry_run_install_pytorch_deps(python, pytorch, session, deps_only=False)\n'"
setup.py,6,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\n\nfrom setuptools import setup, find_packages\nimport os\nfrom string import Template\nimport torch\nfrom torch.utils.cpp_extension import BuildExtension, include_paths, library_paths\nfrom pkg_resources import normalize_path\nfrom distutils.command.build_py import build_py\nfrom setuptools.command.develop import develop\nfrom setuptools.command.install import install\nfrom setuptools import Extension\nimport glob\nimport sys\nfrom distutils.util import convert_path\n\n\nconfig= {}\nexec(open(convert_path(\'brevitas/config.py\')).read(), config)\nMIN_TORCH_JITTABLE_VERSION = config[\'MIN_TORCH_JITTABLE_VERSION\']\nMAX_TORCH_JITTABLE_VERSION = config[\'MAX_TORCH_JITTABLE_VERSION\']\n\n\nPROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))\nREQUIREMENTS_DIR = os.path.join(PROJECT_ROOT, \'requirements\')\n\n\ndef apply_template(dest_build, version):\n    template_path = os.path.join(\'brevitas\', \'function\', \'ops_ste.py.template\')\n    generated_path = os.path.join(dest_build, \'ops_ste.py\')\n    torch_version = version.parse(torch.__version__)\n    if version.parse(MIN_TORCH_JITTABLE_VERSION) <= torch_version <= version.parse(MAX_TORCH_JITTABLE_VERSION):\n        d = dict(\n            function_suffix=\'\',\n            function_prefix=\'torch.ops.brevitas.\',\n            torch_jit_template=\'@torch.jit.script\')\n    else:\n        d = dict(\n            function_suffix=\'_fn.apply\',\n            function_prefix=\'\',\n            torch_jit_template=\'@torch.jit.ignore\')\n\n    template_file = Template(read(template_path))\n    generated_file = template_file.substitute(d)\n    with open(generated_path, \'w\') as f:\n        f.write(generated_file)\n\n\ndef read(*path):\n    return open(os.path.join(*path)).read()\n\n\ndef read_requirements(filename):\n    return read(REQUIREMENTS_DIR, filename).splitlines()\n\n\nclass JittableExtension(Extension):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n\nclass BuildJittableExtension(BuildExtension):\n\n    def run(self):\n        from packaging import version\n        torch_version = version.parse(torch.__version__)\n        if not (version.parse(MIN_TORCH_JITTABLE_VERSION) <= torch_version <= version.parse(MAX_TORCH_JITTABLE_VERSION)):\n            self.extensions = [e for e in self.extensions if not isinstance(e, JittableExtension)]\n        super().run()\n\n\ndef get_jittable_extension():\n    ext_modules = []\n    extensions_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'brevitas\', \'csrc\')\n\n    sources = glob.glob(os.path.join(extensions_dir, \'*.cpp\'))\n    sources = [os.path.join(extensions_dir, s) for s in sources]\n    include_dirs = [extensions_dir] + include_paths()\n    define_macros = []\n    libraries = []\n    library_dirs = []\n    extra_compile_args = {}\n\n    if sys.platform == \'win32\':\n        define_macros += [(\'brevitas_EXPORTS\', None)]\n        extra_compile_args.setdefault(\'cxx\', [])\n        extra_compile_args[\'cxx\'].append(\'/MP\')\n        library_dirs += library_paths()\n        libraries.append(\'c10\')\n        libraries.append(\'torch\')\n        libraries.append(\'torch_python\')\n        libraries.append(\'_C\')\n\n\n    jittable_ext = JittableExtension(\n        \'brevitas._C\',\n        language=\'c++\',\n        sources=sources,\n        libraries=libraries,\n        library_dirs=library_dirs,\n        include_dirs=include_dirs,\n        define_macros=define_macros,\n        extra_compile_args=extra_compile_args)\n    ext_modules.append(jittable_ext)\n    return ext_modules\n\n\nclass BuildPy(build_py):\n\n    def run(self):\n        if not self.dry_run:\n            from packaging import version\n            target_dir = os.path.join(self.build_lib, \'brevitas\', \'function\')\n            self.mkpath(target_dir)\n            apply_template(target_dir, version)\n        build_py.run(self)\n\nclass DevelopInstall(develop):\n    def run(self):\n        from packaging import version\n        super().run()\n        bext_cmd = self.get_finalized_command(\'build_ext\')\n        build_path = normalize_path(bext_cmd.build_lib)\n        build_lib = os.path.dirname(os.path.dirname(build_path))\n        target_dir = os.path.join(build_lib, \'brevitas\', \'function\')\n        apply_template(target_dir, version)\n\n\nsetup(name=""Brevitas"",\n      version=""0.2.0-alpha"",\n      description=""Quantization-aware training in PyTorch"",\n      long_description=read(PROJECT_ROOT, \'README.md\'),\n      long_description_content_type=""text/markdown"",\n      author=""Alessandro Pappalardo"",\n      python_requires="">=3.6"",\n      setup_requires=read_requirements(\'requirements-setup.txt\'),\n      install_requires=read_requirements(\'requirements.txt\'),\n      extras_require={\n          ""Hadamard"": read_requirements(\'requirements-hadamard.txt\'),\n          ""test"": read_requirements(\'requirements-test.txt\'),\n          ""tts"": read_requirements(\'requirements-tts.txt\'),\n          ""stt"": read_requirements(\'requirements-stt.txt\'),\n          ""vision"": read_requirements(\'requirements-vision.txt\')\n      },\n      packages=find_packages(),\n      zip_safe=False,\n      ext_modules=get_jittable_extension(),\n      cmdclass={\n          \'build_py\': BuildPy,\n          \'build_ext\': BuildJittableExtension.with_options(no_python_abi_suffix=True),\n          \'develop\': DevelopInstall,\n      },\n      package_data={\n          \'\': [\'*.ini\', \'*.yaml\'],\n      },\n      entry_points={\n          \'console_scripts\': [\n              \'brevitas_bnn_pynq_train = brevitas_examples.bnn_pynq.bnn_pynq_train:main\',\n              \'brevitas_imagenet_val = brevitas_examples.imagenet_classification.imagenet_val:main\',\n              \'brevitas_quartznet_val = brevitas_examples.speech_to_text.quartznet_val:main\',\n              \'brevitas_melgan_val = brevitas_examples.text_to_speech.melgan_val:main\',\n              \'brevitas_quartznet_preprocess = brevitas_examples.speech_to_text.get_librispeech_data:main\',\n              \'brevitas_melgan_preprocess = brevitas_examples.text_to_speech.preprocess_dataset:main\'\n          ],\n      })\n\n\n'"
brevitas/__init__.py,3,"b'import imp\nimport os\nimport torch\nimport docrep\nfrom brevitas.config import MIN_TORCH_JITTABLE_VERSION, MAX_TORCH_JITTABLE_VERSION\nimport torch\nfrom packaging import version\ntorch_version = version.parse(torch.__version__)\n\nis_ste_jittable = version.parse(MIN_TORCH_JITTABLE_VERSION) <= torch_version <= version.parse(MAX_TORCH_JITTABLE_VERSION)\n\ndocstrings = docrep.DocstringProcessor()\n\n# If pytorch version >= 1.3.0, it means that we have the compiled version of the functions that use the\n# Straight-Trough-Estimator. If that is the case, we need to load those operations in torch.ops.\nif is_ste_jittable:\n    lib_dir = os.path.dirname(__file__)\n    _, path, _ = imp.find_module(""_C"", [lib_dir])\n    torch.ops.load_library(path)\n'"
brevitas/config.py,0,"b'import os\nfrom distutils.util import strtobool\n\n\ndef env_to_bool(name, default):\n    return bool(strtobool(os.environ.get(name, ""{}"".format(default))))\n\n\nMIN_TORCH_JITTABLE_VERSION = ""1.3.0""\nMAX_TORCH_JITTABLE_VERSION = ""1.4.0""\n\nIGNORE_MISSING_KEYS = env_to_bool(\'BREVITAS_IGNORE_MISSING_KEYS\', False)\nREINIT_WEIGHT_QUANT_ON_LOAD = env_to_bool(\'BREVITAS_REINIT_WEIGHT_QUANT_ON_LOAD\', True)\n'"
brevitas/quant_tensor.py,2,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom collections import namedtuple\n\nimport torch\n\nfrom brevitas.function.ops_ste import round_ste, ceil_ste\nfrom brevitas.function.ops import max_uint\n\n\ndef pack_quant_tensor(tensor, scale, bit_width):\n    return QuantTensor._make([tensor, scale, bit_width])\n\n\nclass QuantTensor(namedtuple(""QuantTensor"", [""tensor"", ""scale"", ""bit_width""])):\n\n    @staticmethod\n    def check_input_type(other):\n        if not isinstance(other, QuantTensor):\n            raise Exception(""Other tensor is not a QuantTensor"")\n\n    def check_scaling_factors_same(self, other):\n        if not torch.allclose(self.scale, other.scale):\n            raise Exception(""Scalign factors are different"")\n\n    # Reference: https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types\n\n    def __neg__(self):\n        return QuantTensor._make([- self.tensor, self.scale, self.bit_width])\n\n    def __add__(self, other):\n        QuantTensor.check_input_type(other)\n        self.check_scaling_factors_same(other)\n        output_tensor = self.tensor + other.tensor\n        output_scale = (self.scale + other.scale) / 2\n        max_uint_val = max_uint(narrow_range=False, bit_width=self.bit_width)\n        max_uint_val += max_uint(narrow_range=False, bit_width=other.bit_width)\n        output_bit_width = ceil_ste(torch.log2(max_uint_val))\n        output = pack_quant_tensor(output_tensor, output_scale, output_bit_width)\n        return output\n\n    def __mul__(self, other):\n        QuantTensor.check_input_type(other)\n        output_tensor = self.tensor * other.tensor\n        output_scale = self.scale * other.scale\n        output_bit_width = self.bit_width + other.bit_width\n        output = pack_quant_tensor(output_tensor, output_scale, output_bit_width)\n        return output\n\n    def __sub__(self, other):\n        return self.__add__(- other)\n\n    def __truediv__(self, other):\n        QuantTensor.check_input_type(other)\n        output_tensor = self.tensor / other.tensor\n        output_scale = self.scale / other.scale\n        output_bit_width = self.bit_width - other.bit_width\n        output = pack_quant_tensor(output_tensor, output_scale, output_bit_width)\n        return output\n\n    def __abs__(self):\n        return QuantTensor._make([abs(self.tensor), self.scale, self.bit_width])\n\n    def __pos__(self):\n        return self\n\n    def __int__(self):\n        return round_ste(self.tensor / self.scale)\n\n    def __float__(self):\n        return self.tensor\n\n    def __index__(self):\n        raise NotImplementedError\n\n    def __round__(self):\n        raise NotImplementedError\n\n    def __trunc__(self):\n        raise NotImplementedError\n\n    def __floor__(self):\n        raise NotImplementedError\n\n    def __ceil__(self):\n        raise NotImplementedError\n\n    def __complex__(self):\n        raise NotImplementedError\n\n    def __invert__(self):\n        raise NotImplementedError\n\n    def __matmul__(self, other):\n        raise NotImplementedError\n\n    def __floordiv__(self, other):\n        raise NotImplementedError\n\n    def __mod__(self, other):\n        raise NotImplementedError\n\n    def __divmod__(self, other):\n        raise NotImplementedError\n\n    def __pow__(self, other):\n        raise NotImplementedError\n\n    def __lshift__(self, other):\n        raise NotImplementedError\n\n    def __rshift__(self, other):\n        raise NotImplementedError\n\n    def __and__(self, other):\n        raise NotImplementedError\n\n    def __xor__(self, other):\n        raise NotImplementedError\n\n    def __or__(self, other):\n        raise NotImplementedError\n'"
brevitas_examples/__init__.py,0,b''
test/conftest.py,1,"b'# Copyright (c) 2019-     Xilinx, Inc              (Giuseppe Franco)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nimport torch\nfrom hypothesis import settings, HealthCheck\nfrom hypothesis import seed as set_seed\n\n# Remove Hypothesis check for too slow tests. Some tests requires particular input conditions, and it may take a\n# while to generate the appropriate inputs.\nsettings.register_profile(""standard"", deadline=None, suppress_health_check=[HealthCheck.too_slow])\nsettings.load_profile(""standard"")\n\nSEED = 123456\ntorch.random.manual_seed(SEED)\nset_seed(SEED)\n'"
.github/workflows/gen_github_actions.py,0,"b'from functools import reduce\nfrom string import Template\nfrom textwrap import indent\nfrom collections import OrderedDict as od\n\nimport yaml\n\nBASE_YML_TEMPLATE = \'base.yml.template\'\nPYTEST_YML = \'pytest.yml\'\nEXAMPLES_PYTEST_YML = \'examples_pytest.yml\'\nDEVELOP_INSTALL_YML = \'develop_install.yml\'\n\nNIX_NEWLINE = \'\\n\'\n\n# Data shared betwen Nox sessions and Github Actions, formatted as tuples\nCONDA_PYTHON_VERSIONS = (\'3.6\', \'3.7\', \'3.8\')\nPYTORCH_VERSIONS = (\'1.1.0\', \'1.2.0\', \'1.3.0\', \'1.3.1\', \'1.4.0\', \'1.5.0\')\nJIT_STATUSES = (\'jit_enabled\', \'jit_disabled\')\n\n# Data used only by Github Actions, formatted as lists or lists of oredered dicts\nPLATFORM_LIST = [\'windows-latest\', \'ubuntu-latest\', \'macos-latest\']\n\nEXCLUDE_LIST = [od([(\'platform\', \'macos-latest\'),\n                    (\'pytorch_version\', \'1.1.0\')]),\n                od([(\'pytorch_version\', \'1.1.0\'),\n                    (\'conda_python_version\', \'3.8\')]),\n                od([(\'pytorch_version\', \'1.2.0\'),\n                    (\'conda_python_version\', \'3.8\')]),\n                od([(\'pytorch_version\', \'1.3.0\'),\n                    (\'conda_python_version\', \'3.8\')]),\n                od([(\'pytorch_version\', \'1.3.1\'),\n                    (\'conda_python_version\', \'3.8\')])]\n\nPYTEST_EXCLUDE_LIST_EXTRA = [od([(\'pytorch_version\', \'1.1.0\'),\n                                 (\'jit_status\', \'jit_disabled\')]),\n                             od([(\'pytorch_version\', \'1.2.0\'),\n                                 (\'jit_status\', \'jit_disabled\')])]\n\nPYTEST_EXAMPLE_EXCLUDE_LIST_EXTRA = [od([(\'platform\', \'macos-latest\'),\n                                         (\'pytorch_version\', \'1.5.0\'),\n                                         (\'conda_python_version\', \'3.6\')])]\n\nMATRIX = od([(\'conda_python_version\', list(CONDA_PYTHON_VERSIONS)),\n             (\'pytorch_version\', list(PYTORCH_VERSIONS)),\n             (\'platform\', PLATFORM_LIST)])\n\nPYTEST_MATRIX_EXTRA = od([(\'jit_status\', list(JIT_STATUSES))])\n\nPYTEST_STEP_LIST = [\n    od([\n        (\'name\', \'Run Nox session for brevitas pytest\'),\n        (\'shell\', \'bash\'),\n        (\'run\',\n         \'nox -v -s tests_brevitas_cpu-${{ matrix.conda_python_version }}\\(${{ matrix.jit_status }}\\,\\ pytorch_${{ matrix.pytorch_version }}\\)\')]),\n]\n\nEXAMPLES_PYTEST_STEP_LIST = [\n    od([\n        (\'name\', \'Run Nox session for brevitas_examples pytest\'),\n        (\'shell\', \'bash\'),\n        (\'run\',\n         \'nox -v -s tests_brevitas_examples_cpu-${{ matrix.conda_python_version }}\\(${{ matrix.jit_status }}\\,\\ pytorch_${{ matrix.pytorch_version }}\\)\')]),\n]\n\nTEST_INSTALL_DEV_STEP_LIST = [\n    od([\n        (\'name\', \'Run Nox session for testing brevitas develop install and imports\'),\n        (\'shell\', \'bash\'),\n        (\'run\',\n         \'nox -v -s tests_brevitas_install_dev-${{ matrix.conda_python_version }}\\(\\pytorch_${{ matrix.pytorch_version }}\\)\')]),\n    od([\n        (\'name\', \'Run Nox session for testing brevitas_examples develop install and imports\'),\n        (\'shell\', \'bash\'),\n        (\'run\',\n         \'nox -v -s tests_brevitas_examples_install_dev-${{ matrix.conda_python_version }}\\(\\pytorch_${{ matrix.pytorch_version }}\\)\')\n    ])]\n\n# whitespaces to indent generated portions of output yaml\nSTEP_INDENT = 4\nMATRIX_INDENT = 8\nEXCLUDE_INDENT = 10\nRELATIVE_INDENT = 2\n\n\nclass CustomTemplate(Template):\n    delimiter = \'&\'\n\n\nclass Action:\n\n    def __init__(self, name, exclude_list, matrix, step_list):\n        self.name = name\n        self.exclude_list = exclude_list\n        self.matrix = matrix\n        self.step_list = step_list\n\n    @staticmethod\n    def list_of_dicts_str(list_of_dicts, quote_val, indent_first):\n        repr = \'\'\n        for e in list_of_dicts:\n            repr += Action.dict_str(e, quote_val, indent_first)\n        return repr\n\n    @staticmethod\n    def dict_str(d, quote_val, indent_first):\n        first_line_prefix = \'- \' if indent_first else \'\'\n        repr = first_line_prefix\n        for name, val in d.items():\n            if quote_val:\n                repr += f""{name}: \'{val}\'"" + NIX_NEWLINE\n            else:\n                repr += f""{name}: {val}"" + NIX_NEWLINE\n        if indent_first:\n            repr = indent(repr, RELATIVE_INDENT * \' \', predicate=lambda line: not first_line_prefix in line)\n        repr += NIX_NEWLINE\n        return repr\n\n    def gen_yaml(self, output_path):\n        d = {\'name\': self.name,\n             \'exclude\': indent(Action.list_of_dicts_str(self.exclude_list, True, True), EXCLUDE_INDENT * \' \'),\n             \'matrix\': indent(Action.dict_str(self.matrix, False, False), MATRIX_INDENT * \' \'),\n             \'steps\': indent(Action.list_of_dicts_str(self.step_list, False, True), STEP_INDENT * \' \')}\n        template = CustomTemplate(open(BASE_YML_TEMPLATE).read())\n        generated_file = template.substitute(d)\n        yaml.safe_load(generated_file)  # validate the generated yaml\n        with open(output_path, \'w\', newline=NIX_NEWLINE) as f:\n            f.write(generated_file)\n\n\ndef combine_od_list(od_list):\n    return od(reduce(lambda l1, l2: l1 + l2, list(map(lambda d: list(d.items()), od_list))))\n\n\ndef gen_pytest_yml():\n    pytest = Action(\n        \'Pytest\',\n        EXCLUDE_LIST + PYTEST_EXCLUDE_LIST_EXTRA,\n        combine_od_list([MATRIX, PYTEST_MATRIX_EXTRA]),\n        PYTEST_STEP_LIST)\n    pytest.gen_yaml(PYTEST_YML)\n\n\ndef gen_examples_pytest_yml():\n    pytest = Action(\n        \'Examples Pytest\',\n        EXCLUDE_LIST + PYTEST_EXCLUDE_LIST_EXTRA + PYTEST_EXAMPLE_EXCLUDE_LIST_EXTRA,\n        combine_od_list([MATRIX, PYTEST_MATRIX_EXTRA]),\n        EXAMPLES_PYTEST_STEP_LIST)\n    pytest.gen_yaml(EXAMPLES_PYTEST_YML)\n\n\ndef gen_test_develop_install_yml():\n    test_develop_install = Action(\n        \'Test develop install\',\n        EXCLUDE_LIST,\n        MATRIX,\n        TEST_INSTALL_DEV_STEP_LIST)\n    test_develop_install.gen_yaml(DEVELOP_INSTALL_YML)\n\n\nif __name__ == \'__main__\':\n    gen_pytest_yml()\n    gen_examples_pytest_yml()\n    gen_test_develop_install_yml()\n'"
brevitas/core/__init__.py,0,"b""ZERO_HW_SENTINEL_NAME = 'zero_hw_sentinel'\nZERO_HW_SENTINEL_VALUE = 0.0"""
brevitas/core/bit_width.py,19,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom typing import Optional\nfrom enum import auto\n\nimport torch\nfrom torch import Tensor\nfrom torch.nn import Parameter\n\nimport brevitas.config as config\nfrom brevitas.utils.python_utils import AutoName\nfrom brevitas.function.ops import tensor_clamp\nfrom brevitas.function.ops_ste import tensor_clamp_ste\nfrom .restrict_val import RestrictValueOpImplType, RestrictValueType, RestrictValue, FloatToIntImplType\n\n\nMIN_INT_BIT_WIDTH = 2\nNON_ZERO_EPSILON = 1e-6\nREMOVE_ZERO_BIT_WIDTH = 0.1\n\n\nclass BitWidthImplType(AutoName):\n    CONST = auto()\n    PARAMETER = auto()\n\nclass IdentityBitWidth(torch.jit.ScriptModule):\n\n    @torch.jit.script_method\n    def forward(self, x: Tensor, zero_hw_sentinel: Tensor) -> Tensor:\n        return x\n\nclass ZeroLsbTruncBitWidth(torch.jit.ScriptModule):\n\n    def forward(self, input_bit_width: Tensor, zero_hw_sentinel: Tensor):\n        return zero_hw_sentinel\n\n\nclass BitWidthConst(torch.jit.ScriptModule):\n    __constants__ = [\'bit_width\']\n\n    def __init__(self, bit_width_init: int, restrict_bit_width_type: RestrictValueType) -> None:\n        super(BitWidthConst, self).__init__()\n\n        if restrict_bit_width_type != RestrictValueType.INT:\n            raise Exception(""When bit width is predefined, it has to be an INT value."")\n\n        self.bit_width = int(bit_width_init)\n\n    @torch.jit.script_method\n    def forward(self, zero_hw_sentinel: Tensor) -> Tensor:\n        return self.bit_width + zero_hw_sentinel\n\n\nclass BitWidthParameter(torch.jit.ScriptModule):\n    __constants__ = [\'bit_width_base\', \'max_bit_width\', \'override_pretrained\']\n\n    def __init__(self,\n                 bit_width_init: int,\n                 min_overall_bit_width: Optional[int],\n                 max_overall_bit_width: Optional[int],\n                 restrict_bit_width_type: RestrictValueType,\n                 override_pretrained: bool) -> None:\n        super(BitWidthParameter, self).__init__()\n\n        if min_overall_bit_width is None:\n            min_overall_bit_width = MIN_INT_BIT_WIDTH\n        if not (restrict_bit_width_type == RestrictValueType.FP\n                or restrict_bit_width_type == RestrictValueType.INT\n                or restrict_bit_width_type == RestrictValueType.POWER_OF_TWO):\n            raise Exception(""Restriction on bit width {} not supported"".format(restrict_bit_width_type))\n        if bit_width_init < MIN_INT_BIT_WIDTH or min_overall_bit_width < MIN_INT_BIT_WIDTH:\n            raise Exception(""Int bit width has to be at least {}, instead is {}.""\n                            .format(MIN_INT_BIT_WIDTH, bit_width_init))\n\n        self.override_pretrained = override_pretrained\n        bit_width_init_op = RestrictValue.restrict_value_op(restrict_bit_width_type,\n                                                            restrict_value_op_impl_type=RestrictValueOpImplType.MATH)\n        self.restrict_bit_width = RestrictValue(restrict_bit_width_type,\n                                                float_to_int_impl_type=FloatToIntImplType.ROUND,\n                                                min_val=None)\n        self.bit_width_base = bit_width_init_op(min_overall_bit_width)\n        self.max_bit_width = bit_width_init_op(min_overall_bit_width) if max_overall_bit_width is not None else None\n        bit_width_offset_init = max(bit_width_init_op(bit_width_init) - self.bit_width_base, 0.0)\n        self.bit_width_offset = Parameter(torch.tensor(float(bit_width_offset_init)))\n\n    @torch.jit.script_method\n    def forward(self, zero_hw_sentinel: Tensor) -> Tensor:\n        if self.max_bit_width is not None:\n            raise Exception(""Not implemented yet."")\n        bit_width = torch.abs(self.bit_width_offset) + self.bit_width_base\n        bit_width = self.restrict_bit_width(bit_width)\n        return bit_width\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        bit_width_offset_key = prefix + \'bit_width_offset\'\n        if self.override_pretrained and bit_width_offset_key in state_dict:\n            del state_dict[bit_width_offset_key]\n        super(BitWidthParameter, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        if config.IGNORE_MISSING_KEYS and bit_width_offset_key in missing_keys:\n            missing_keys.remove(bit_width_offset_key)\n\n\n\nclass RemoveBitwidthParameter(torch.jit.ScriptModule):\n    __constants__ = [\'min_overall_bit_width\', \'non_zero_epsilon\', \'override_pretrained\', \'remove_at_least_init_val\']\n\n    def __init__(self, bit_width_to_remove, remove_at_least_init_val, restrict_bit_width_impl, override_pretrained):\n        super(RemoveBitwidthParameter, self).__init__()\n\n        if bit_width_to_remove < 0:\n            raise Exception(""Bit width to clamp has to be at least 0, instead is {}.""\n                            .format(bit_width_to_remove))\n        elif bit_width_to_remove == 0:\n            bit_width_coeff_init = 1 / REMOVE_ZERO_BIT_WIDTH\n        else:\n            bit_width_coeff_init = 1 / bit_width_to_remove\n        self.bit_width_coeff = Parameter(torch.tensor(bit_width_coeff_init))\n        self.restrict_bit_width_impl = restrict_bit_width_impl\n        self.non_zero_epsilon = NON_ZERO_EPSILON\n        self.override_pretrained = override_pretrained\n        self.remove_at_least_init_val = remove_at_least_init_val\n\n    @torch.jit.script_method\n    def forward(self, zero_hw_sentinel) -> Tensor:\n        bit_width_to_remove = 1.0 / (self.non_zero_epsilon + torch.abs(self.bit_width_coeff))\n        bit_width_to_remove = self.restrict_bit_width_impl(bit_width_to_remove)\n        return bit_width_to_remove\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        bit_width_coeff_key = prefix + \'bit_width_coeff\'\n        if self.override_pretrained and bit_width_coeff_key in state_dict:\n            del state_dict[bit_width_coeff_key]\n        super(RemoveBitwidthParameter, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n                                                                   missing_keys, unexpected_keys, error_msgs)\n        if config.IGNORE_MISSING_KEYS and bit_width_coeff_key in missing_keys:\n            missing_keys.remove(bit_width_coeff_key)\n\n\n\nclass MsbClampParameterBitWidth(torch.jit.ScriptModule):\n    __constants__ = [\'min_overall_bit_width\', \'max_overall_bit_width\']\n\n    def __init__(self,\n                 ms_bit_width_to_clamp: int,\n                 clamp_at_least_init_val: bool,\n                 min_overall_bit_width: int,\n                 max_overall_bit_width: int,\n                 bit_width_impl_type: BitWidthImplType,\n                 override_pretrained: bool) -> None:\n        super(MsbClampParameterBitWidth, self).__init__()\n\n        self.min_overall_bit_width = min_overall_bit_width\n        self.max_overall_bit_width = max_overall_bit_width\n\n        if bit_width_impl_type == BitWidthImplType.CONST:\n            self.bit_width_to_remove_impl = BitWidthConst(ms_bit_width_to_clamp, RestrictValueType.INT)\n        elif bit_width_impl_type == BitWidthImplType.PARAMETER:\n            restrict_bit_width_impl = RestrictValue(RestrictValueType.INT,\n                                                    float_to_int_impl_type=FloatToIntImplType.ROUND,\n                                                    min_val=None)\n            self.bit_width_to_remove_impl = RemoveBitwidthParameter(bit_width_to_remove=ms_bit_width_to_clamp,\n                                                                    remove_at_least_init_val=clamp_at_least_init_val,\n                                                                    restrict_bit_width_impl=restrict_bit_width_impl,\n                                                                    override_pretrained=override_pretrained)\n        else:\n            raise Exception(""Bit width implementation type {} not recognized for clamping accumulator.""\n                            .format(bit_width_impl_type))\n\n    @torch.jit.script_method\n    def forward(self, input_bit_width: Tensor, zero_hw_sentinel: Tensor) -> Tensor:\n        bit_width_to_remove = self.bit_width_to_remove_impl(zero_hw_sentinel)\n        output_bit_width = torch.abs(input_bit_width - bit_width_to_remove)\n        output_bit_width = tensor_clamp_ste(output_bit_width,\n                                            self.min_overall_bit_width + zero_hw_sentinel,\n                                            self.max_overall_bit_width + zero_hw_sentinel) #todo STE on max only\n        return output_bit_width\n\n\nclass LsbTruncParameterBitWidth(torch.jit.ScriptModule):\n    __constants__ = [\'is_const\', \'min_overall_bit_width\', \'max_overall_bit_width\']\n\n    def __init__(self,\n                 ls_bit_width_to_trunc: int,\n                 trunc_at_least_init_val: bool,\n                 min_overall_bit_width: int,\n                 max_overall_bit_width: int,\n                 bit_width_impl_type: BitWidthImplType,\n                 override_pretrained: bool):\n        super(LsbTruncParameterBitWidth, self).__init__()\n\n        self.min_overall_bit_width = min_overall_bit_width\n        self.max_overall_bit_width = max_overall_bit_width\n\n        if bit_width_impl_type == BitWidthImplType.CONST:\n            self.bit_width_to_remove_impl = BitWidthConst(ls_bit_width_to_trunc, RestrictValueType.INT)\n        elif bit_width_impl_type == BitWidthImplType.PARAMETER:\n            restrict_bit_width_impl = RestrictValue(RestrictValueType.INT,\n                                                    float_to_int_impl_type=FloatToIntImplType.ROUND,\n                                                    min_val=None)\n            self.bit_width_to_remove_impl = RemoveBitwidthParameter(bit_width_to_remove=ls_bit_width_to_trunc,\n                                                                    remove_at_least_init_val=trunc_at_least_init_val,\n                                                                    restrict_bit_width_impl=restrict_bit_width_impl,\n                                                                    override_pretrained=override_pretrained)\n        else:\n            raise Exception(""Bit width implementation type {} not recognized for truncating accumulator.""\n                            .format(bit_width_impl_type))\n\n    @torch.jit.script_method\n    def forward(self, input_bit_width: Tensor, zero_hw_sentinel: Tensor) -> Tensor:\n        bit_width_to_remove = self.bit_width_to_remove_impl(zero_hw_sentinel)\n        min_bit_width_to_remove = input_bit_width - self.max_overall_bit_width\n        max_bit_width_to_remove = input_bit_width - self.min_overall_bit_width\n        bit_width_to_remove = tensor_clamp(bit_width_to_remove,      # pass gradient to boundaries\n                                           min_bit_width_to_remove,  # since input_bit_width is possibly learned\n                                           max_bit_width_to_remove)\n        return bit_width_to_remove'"
brevitas/core/function_wrapper.py,52,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom brevitas.function.ops_ste import round_ste, tensor_clamp_ste, ceil_ste, floor_ste\nfrom brevitas.function.shape import *\nfrom brevitas.function import tensor_clamp, identity\n\n\nclass Identity(torch.jit.ScriptModule):\n    def __init__(self) -> None:\n        super(Identity, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return identity(x)\n\n\nclass RoundSte(torch.jit.ScriptModule):\n    def __init__(self) -> None:\n        super(RoundSte, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return round_ste(x)\n\n\nclass FloorSte(torch.jit.ScriptModule):\n    def __init__(self) -> None:\n        super(FloorSte, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return floor_ste(x)\n\n\nclass CeilSte(torch.jit.ScriptModule):\n    def __init__(self) -> None:\n        super(CeilSte, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return ceil_ste(x)\n\n\nclass PowerOfTwo(torch.jit.ScriptModule):\n    def __init__(self) -> None:\n        super(PowerOfTwo, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return 2.0 ** x\n\n\nclass LogTwo(torch.jit.ScriptModule):\n    def __init__(self) -> None:\n        super(LogTwo, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return torch.log2(x)\n\n\nclass TensorClampSte(torch.jit.ScriptModule):\n    def __init__(self) -> None:\n        super(TensorClampSte, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor, min_val: torch.Tensor, max_val: torch.Tensor):\n        return tensor_clamp_ste(x, min_val, max_val)\n\n\nclass TensorClamp(torch.jit.ScriptModule):\n    def __init__(self) -> None:\n        super(TensorClamp, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor, min_val: torch.Tensor, max_val: torch.Tensor):\n        return tensor_clamp(x, min_val=min_val, max_val=max_val)\n\n\nclass ConstScalarClamp(torch.jit.ScriptModule):\n    __constants__ = [\'min_val\', \'max_val\']\n\n    def __init__(self, min_val, max_val) -> None:\n        super(ConstScalarClamp, self).__init__()\n        self.min_val = min_val\n        self.max_val = max_val\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return torch.clamp(x, min=self.min_val, max=self.max_val)\n\n\nclass ClampMin(torch.jit.ScriptModule):\n    __constants__ = [\'min_val\']\n\n    def __init__(self, min_val: float) -> None:\n        super(ClampMin, self).__init__()\n        self.min_val = min_val\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return x.clamp_min(self.min_val)\n\n\nclass OverTensorView(torch.jit.ScriptModule):\n\n    def __init__(self) -> None:\n        super(OverTensorView, self).__init__()\n\n    @torch.jit.script_method\n    def shape(self, x: torch.Tensor):\n        return over_tensor(x)\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        shape = self.shape(x)\n        return x.view(shape)\n\n\nclass OverOutputChannelView(torch.jit.ScriptModule):\n\n    def __init__(self) -> None:\n        super(OverOutputChannelView, self).__init__()\n\n    @torch.jit.script_method\n    def shape(self, x: torch.Tensor):\n        return over_output_channels(x)\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        shape = self.shape(x)\n        return x.view(shape)\n\n\nclass OverBatchOverTensorView(torch.jit.ScriptModule):\n\n    def __init__(self) -> None:\n        super(OverBatchOverTensorView, self).__init__()\n\n    @torch.jit.script_method\n    def shape(self, x: torch.Tensor):\n        return over_batch_over_tensor(x)\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        shape = self.shape(x)\n        return x.view(shape)\n\n\nclass OverBatchOverOutputChannelView(torch.jit.ScriptModule):\n\n    def __init__(self) -> None:\n        super(OverBatchOverOutputChannelView, self).__init__()\n\n    @torch.jit.script_method\n    def shape(self, x: torch.Tensor):\n        return over_batch_over_output_channels(x)\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        shape = self.shape(x)\n        return x.view(shape)\n'"
brevitas/core/quant.py,24,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom enum import auto\nfrom typing import Optional, Tuple, Union\n\nimport torch\nfrom torch import Tensor\nfrom torch.nn import Module\n\nfrom brevitas.utils.python_utils import AutoName\nfrom brevitas.function.ops import tensor_clamp, min_int, max_int, max_uint\nfrom brevitas.function.ops_ste import tensor_clamp_ste, binary_sign_ste, ternary_sign_ste\n\n\n__all__ = [\'QuantType\', \'BinaryQuant\', \'TernaryQuant\', \'RescalingIntQuant\',\n           \'PrescaledRestrictIntQuant\']\n\n\nclass QuantType(AutoName):\n    BINARY = auto()\n    TERNARY = auto()\n    INT = auto()\n    FP = auto()\n\n\nclass IdentityQuant(torch.jit.ScriptModule):\n    """""" Placeholder Class that returns the input without performing any operation. The scale and bit_width output\n    arguments are set to zero_hw_sentinel (0).\n    """"""\n    @torch.jit.script_method\n    def forward(self, x: Tensor, zero_hw_sentinel: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n        return x, zero_hw_sentinel, zero_hw_sentinel\n\n\nclass BinaryQuant(torch.jit.ScriptModule):\n    """""" Class that implement the binary quantization of the input tensor, which is then converted to its floating point\n    representation according to the scale factor.\n\n    The scale factor is determined internally through the scaling_impl module.\n\n    Parameters\n    ----------\n    scaling_impl : Module\n        Module that determines the value of the scale factor\n\n    Attributes\n    ----------\n    scaling_impl: Module\n       Module that determines the value of the scale factor\n    bit_width: Int\n        For binary quantization, the bit_width is constant and fixed to 1\n\n    Methods\n    -------\n    forward(x, zero_hw_sentinel)\n        Perform the binary quantization using :func:`~brevitas.function.ops_ste.binary_sign_ste`. After that, the\n        result is converted to floating point through the scale factor.\n        The scale factor is determined by the attribute `scaling_impl`.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input tensor that will be quantized\n        zero_hw_sentinel: Tensor\n            Constant buffer required to move stateless (as in, not part of the model\'s state_dict) constant values\n            to the appropriate device and converting them to Tensor\n\n        Returns\n        -------\n        Tuple(Tensor, Tensor, Tensor)\n            Tuple with three values where:\n            y is the quantized Tensor;\n            scale is the scale factor;\n            bit_width is the bit_width of the quantization.\n\n    """"""\n    __constants__ = [\'bit_width\']\n\n    def __init__(self, scaling_impl: Module):\n        super(BinaryQuant, self).__init__()\n        self.scaling_impl = scaling_impl\n        self.bit_width = 1\n\n    @torch.jit.script_method\n    def forward(self, x: Tensor, zero_hw_sentinel: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n        scale = self.scaling_impl(zero_hw_sentinel)\n        y = binary_sign_ste(x) * scale\n        return y, scale, zero_hw_sentinel + self.bit_width\n\n\nclass ClampedBinaryQuant(torch.jit.ScriptModule):\n    """""" Class that implement the binary quantization of the input tensor, which is then converted to its floating point\n    representation according to the scale factor.\n\n    Before performing the binarization, the input tensor is clamped in the range of admissible values, determined by the\n    scale factor.\n    The scale factor is determined internally through the scaling_impl module.\n\n    Parameters\n    ----------\n    scaling_impl : Module\n        Module that determines the value of the scale factor\n\n    Attributes\n    ----------\n    scaling_impl : Module\n       Module that determines the value of the scale factor\n    bit_width : Int\n        For binary quantization, the bit_width is constant and fixed to 1\n\n    Methods\n    -------\n    forward(x, zero_hw_sentinel)\n        Perform the binary quantization using :func:`~brevitas.function.ops_ste.binary_sign_ste`. After that, the\n        result is converted to floating point through the scale factor.\n        The scale factor is determined by the attribute `scaling_impl`.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input tensor that will be quantized\n        zero_hw_sentinel: Tensor\n            Constant buffer required to move stateless (as in, not part of the model\'s state_dict) constant values\n            to the appropriate device and converting them to Tensor\n\n        Returns\n        -------\n        Tuple(Tensor, Tensor, Tensor)\n            Tuple with three values where:\n            y is the quantized Tensor;\n            scale is the scale factor;\n            bit_width is the bit_width of the quantization.\n\n    """"""\n    __constants__ = [\'bit_width\']\n\n    def __init__(self, scaling_impl: Module):\n        super(ClampedBinaryQuant, self).__init__()\n        self.scaling_impl = scaling_impl\n        self.bit_width = 1\n\n    @torch.jit.script_method\n    def forward(self, x: Tensor, zero_hw_sentinel: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n        scale = self.scaling_impl(zero_hw_sentinel)\n        y = tensor_clamp(x, - scale, scale)\n        y = binary_sign_ste(y) * scale\n        return y, scale, zero_hw_sentinel + self.bit_width\n\n\nclass TernaryQuant(torch.jit.ScriptModule):\n    """""" Class that implement the ternary quantization of the input tensor, which is then converted to its floating point\n    representation according to the scale factor.\n\n    The scale factor is determined internally through the scaling_impl module. The threshold is a user-defined value in\n    the range (0,1).\n\n    The quantization is performed in such a way that all input values in the range\n    (-scale*threshold, scale*threshold) are quantized to 0. Values greater than the upper bound are quantized to \'scale\'\n    . Values lower than the lower bound are quantized to \'-scale\'.\n\n    Parameters\n    ----------\n    scaling_impl : Module\n        Module that determines the value of the scale factor\n    threshold: Float\n        User-defined value that determines, together with the scale factor, the range of values that are quantized to 0.\n\n    Attributes\n    ----------\n    scaling_impl : Module\n       Module that determines the value of the scale factor\n    bit_width : Int\n        For binary quantization, the bit_width is constant and fixed to 2\n    threshold: Float\n        User-defined value that determines, together with the scale factor, the range of values that are quantized to 0.\n\n    Methods\n    -------\n    forward(x, zero_hw_sentinel)\n        Perform the ternary quantization using :func:`~brevitas.function.ops_ste.ternary_sign_ste`. After that, the\n        result is converted to floating point through the scale factor.\n        The scale factor is determined by the attribute `scaling_impl`.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input tensor that will be quantized\n        zero_hw_sentinel: Tensor\n            Constant buffer required to move stateless (as in, not part of the model\'s state_dict) constant values\n            to the appropriate device and converting them to Tensor\n\n        Returns\n        -------\n        Tuple(Tensor, Tensor, Tensor)\n            Tuple with three values where:\n            y is the quantized Tensor;\n            scale is the scale factor;\n            bit_width is the bit_width of the quantization.\n    """"""\n    __constants__ = [\'threshold\', \'bit_width\']\n\n    def __init__(self, scaling_impl: Module, threshold: float):\n        super(TernaryQuant, self).__init__()\n        self.scaling_impl = scaling_impl\n        self.threshold = threshold\n        self.bit_width = 2\n\n    @torch.jit.script_method\n    def forward(self, x: Tensor, zero_hw_sentinel: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n        scale = self.scaling_impl(zero_hw_sentinel)\n        mask = x.abs().ge(self.threshold * scale)\n        y = mask.float() * ternary_sign_ste(x)\n        y = y * scale\n        return y, scale, zero_hw_sentinel + self.bit_width\n\n\nclass PrescaledRestrictIntQuantWithInputBitWidth(torch.jit.ScriptModule):\n    """""" Wrapper around :class:`~brevitas.core.quant.IntQuant`, that is responsible for the actual quantization of the\n    input.\n\n    The modules tensor_clamp_impl and float_to_int_impl, and the booleans `signed` and `narrow_range` are required by\n    `IntQuant` to perform the quantization.\n\n    In order to perform the actual quantization, it is required to determine the following values: scale, int_scale,\n    bit_width.\n    Scale is determined externally, int_scale is set to 1, while bit_width is determined internally through\n    msb_clamp_bit_width_impl.\n    Must be noted that there is a name overload and that the actual scale factor is obtained computing scale/int_scale.\n\n    Parameters\n    ----------\n    narrow_range: Bool\n        Bool that determines whether to enable or not the narrow range representation.\n    signed: Bool\n        Bool that determines whether to use signed or unsigned integers.\n    tensor_clamp_impl: Module\n        Module that performs the clamping of the input values for a proper integer representation\n    msb_clamp_bit_width_impl: Module\n        Module that determines the bit_width for the integer conversion\n    float_to_int_impl: Module\n        Module that performs the conversion from floating point to integer representation\n\n    Attributes\n    ----------\n    int_quant : Module\n       Module that performs the actual quantization\n    msb_clamp_bit_width_impl : Int\n        Module that determines the bit_width for the integer conversion\n\n    Methods\n    -------\n    forward(x, scale, input_bit_width, zero_hw_sentinel)\n        After determining internally the bit_width value, it calls IntQuant to perform the quantization of the input\n\n        Parameters\n        ----------\n        x: Tensor\n            Input tensor that will be quantized\n        scale: Tensor\n            Scale factor that regulates the conversion between integer and floating point version of the input tensor\n        input_bit_width\n            Bit_width that, going in `msb_clamp_bit_with`, is used to determine the bit_width for the quantization\n        zero_hw_sentinel: Tensor\n            Constant buffer required to move stateless (as in, not part of the model\'s state_dict) constant values\n            to the appropriate device and converting them to Tensor\n\n        Returns\n        -------\n        Tuple(Tensor, Tensor, Tensor)\n            Tuple with three values where:\n            y is the quantized Tensor;\n            scale is the scale factor;\n            bit_width is the bit_width of the quantization.\n    """"""\n    def __init__(self,\n                 narrow_range: bool,\n                 signed: bool,\n                 tensor_clamp_impl: Module,\n                 msb_clamp_bit_width_impl: Module,\n                 float_to_int_impl: Module):\n        super(PrescaledRestrictIntQuantWithInputBitWidth, self).__init__()\n        self.int_quant = IntQuant(signed=signed,\n                                  narrow_range=narrow_range,\n                                  tensor_clamp_impl=tensor_clamp_impl,\n                                  float_to_int_impl=float_to_int_impl)\n        self.msb_clamp_bit_width_impl = msb_clamp_bit_width_impl\n\n    @torch.jit.script_method\n    def forward(self,\n                x: Tensor,\n                scale: Tensor,\n                input_bit_width: Tensor,\n                zero_hw_sentinel: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n\n        msb_clamp_bit_width = self.msb_clamp_bit_width_impl(input_bit_width, zero_hw_sentinel)\n        y = self.int_quant(scale, zero_hw_sentinel + 1, msb_clamp_bit_width, x)\n        return y, scale, msb_clamp_bit_width\n\n\nclass PrescaledRestrictIntQuant(torch.jit.ScriptModule):\n    """""" Wrapper around :class:`~brevitas.core.quant.IntQuant`, that is responsible for the actual quantization of the\n    input.\n\n    The modules tensor_clamp_impl and float_to_int_impl, and the booleans `signed` and `narrow_range` are required by\n    `IntQuant` to perform the quantization.\n\n    In order to perform the actual quantization, it is required to determine the following values: scale, int_scale,\n    bit_width.\n    Scale is determined externally, int_scale is set to 1, while bit_width is determined internally through\n    msb_clamp_bit_width_impl.\n    Must be noted that there is a name overload and that the actual scale factor is obtained computing scale/int_scale.\n\n    Parameters\n    ----------\n    narrow_range: Bool\n        Bool that determines whether to enable or not the narrow range representation.\n    signed: Bool\n        Bool that determines whether to use signed or unsigned integers.\n    tensor_clamp_impl: Module\n        Module that performs the clamping of the input values for a proper integer representation\n    msb_clamp_bit_width_impl: Module\n        Module that determines the bit_width for the integer conversion\n    float_to_int_impl: Module\n        Module that performs the conversion from floating point to integer representation\n\n    Attributes\n    ----------\n    int_quant: Module\n       Module that performs the actual quantization\n    msb_clamp_bit_width_impl: Int\n        Module that determines the bit_width for the integer conversion\n\n    Methods\n    -------\n    forward(x, scale, zero_hw_sentinel)\n        After determining internally the bit_width value, it calls IntQuant to perform the quantization of the input\n\n        Parameters\n        ----------\n        x: Tensor\n            Input tensor that will be quantized\n        scale: Tensor\n            Scale factor that regulates the conversion between integer and floating point version of the input tensor\n        zero_hw_sentinel: Tensor\n            Constant buffer required to move stateless (as in, not part of the model\'s state_dict) constant values\n            to the appropriate device and converting them to Tensor\n\n        Returns\n        -------\n        Tuple(Tensor, Tensor, Tensor)\n            Tuple with three values where:\n            y is the quantized Tensor;\n            scale is the scale factor;\n            bit_width is the bit_width of the quantization.\n    """"""\n    def __init__(self,\n                 narrow_range: bool,\n                 signed: bool,\n                 tensor_clamp_impl: Module,\n                 msb_clamp_bit_width_impl: Module,\n                 float_to_int_impl: Module):\n        super(PrescaledRestrictIntQuant, self).__init__()\n        self.int_quant = IntQuant(signed=signed,\n                                  narrow_range=narrow_range,\n                                  tensor_clamp_impl=tensor_clamp_impl,\n                                  float_to_int_impl=float_to_int_impl)\n        self.msb_clamp_bit_width_impl = msb_clamp_bit_width_impl\n\n    @torch.jit.script_method\n    def forward(self,\n                x: Tensor,\n                scale: Tensor,\n                zero_hw_sentinel: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n        msb_clamp_bit_width = self.msb_clamp_bit_width_impl(zero_hw_sentinel)\n        y = self.int_quant(scale, zero_hw_sentinel + 1, msb_clamp_bit_width, x)\n        return y, scale, msb_clamp_bit_width\n\n\nclass IdentityPrescaledIntQuant(torch.jit.ScriptModule):\n    """""" Placeholder Class that returns the input without performing any operation.\n    """"""\n    @torch.jit.script_method\n    def forward(self, x, input_scale, input_bit_width, zero_hw_sentinel) -> Tuple[Tensor, Tensor, Tensor]:\n        return x, input_scale, input_bit_width\n\n\nclass RescalingIntQuant(torch.jit.ScriptModule):\n    """""" Wrapper around :class:`~brevitas.core.quant.IntQuant`, that is responsible for the actual quantization of the\n    input.\n\n    The modules tensor_clamp_impl and float_to_int_impl, and the booleans `signed` and `narrow_range` are required by\n    `IntQuant` to perform the quantization.\n\n    The `runtime` boolean is required to determine how to compute the scale factor.\n    The `int_scaling_impl` module is required to  determine int_scale.\n\n    In order to perform the actual quantization, it is required to determine the following values: scale, int_scale,\n    bit_width. All values are determined internally.\n    Must be noted that there is a name overload and that the actual scale factor is obtained computing scale/int_scale.\n\n    Parameters\n    ----------\n    narrow_range: Bool\n        Bool that determines whether to enable or not the narrow range representation.\n    signed: Bool\n        Bool that determines whether to use signed or unsigned integers.\n    tensor_clamp_impl: Module\n        Module that performs the clamping of the input values for a proper integer representation\n    msb_clamp_bit_width_impl: Module\n        Module that determines the bit_width for the integer conversion\n    float_to_int_impl: Module\n        Module that performs the conversion from floating point to integer representation\n\n    Attributes\n    ----------\n    int_quant: Module\n       Module that performs the actual quantization\n    runtime: Bool\n        Value that determines how the scaling factor is computed in `scaling_impl`\n    scaling_impl: Module\n        Module that is responsible for the computation of the scale factor\n    int_scaling_impl: Module\n        Module that is responsible for the computation of the int_scale factor\n    msb_clamp_bit_width_impl: Int\n        Module that determines the bit_width for the integer conversion\n\n    Methods\n    -------\n    forward(x, zero_hw_sentinel)\n        After determining internally the bit_width value, the scale factor, and the int_scale factor\n        the method calls IntQuant to perform the quantization of the input.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input tensor that will be quantized\n        zero_hw_sentinel: Tensor\n            Constant buffer required to move stateless (as in, not part of the model\'s state_dict) constant values\n            to the appropriate device and converting them to Tensor\n\n        Returns\n        -------\n        Tuple(Tensor, Tensor, Tensor)\n            Tuple with three values where:\n            y is the quantized Tensor;\n            scale is the scale factor;\n            bit_width is the bit_width of the quantization.\n    """"""\n    __constants__ = [\'runtime\']\n\n    def __init__(self,\n                 narrow_range: bool,\n                 runtime: bool,\n                 signed: bool,\n                 scaling_impl: Module,\n                 int_scaling_impl: Module,\n                 tensor_clamp_impl: Module,\n                 msb_clamp_bit_width_impl: Module,\n                 float_to_int_impl: Module):\n        super(RescalingIntQuant, self).__init__()\n        self.int_quant = IntQuant(signed=signed,\n                                  narrow_range=narrow_range,\n                                  tensor_clamp_impl=tensor_clamp_impl,\n                                  float_to_int_impl=float_to_int_impl)\n        self.runtime = runtime\n        self.scaling_impl = scaling_impl\n        self.int_scaling_impl = int_scaling_impl\n        self.msb_clamp_bit_width_impl = msb_clamp_bit_width_impl\n\n    @staticmethod\n    def scaling_init_from_min_max(min_val_init: Union[int, float], max_val_init: Union[int, float]) -> torch.Tensor:\n        """""" Static Method that is used in the step of initializing the scale factor\n\n        Parameters\n        ----------\n        min_val_init: Tensor\n            Minimum value used for initialization\n        max_val_init: Tensor\n            Maximum value used for initialization\n\n        Returns\n        -------\n        Tensor\n            The largest number, in absolute value, between `max_val_init` and `min_val_init`\n        """"""\n        scaling_init = max(abs(float(min_val_init)), abs(float(max_val_init)))\n        return torch.tensor(scaling_init)\n\n    @torch.jit.script_method\n    def forward(self,\n                x: Tensor,\n                zero_hw_sentinel: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n        msb_clamp_bit_width = self.msb_clamp_bit_width_impl(zero_hw_sentinel)\n        if self.runtime:\n            scale = self.scaling_impl(x)\n        else:\n            scale = self.scaling_impl(zero_hw_sentinel)\n        int_scale = self.int_scaling_impl(msb_clamp_bit_width)\n        y = self.int_quant(scale, int_scale, msb_clamp_bit_width, x)\n        output_bit_width = msb_clamp_bit_width\n        output_scale = scale / int_scale\n        return y, output_scale, output_bit_width\n\n\nclass IntQuant(torch.jit.ScriptModule):\n    """""" Class that implement the quantization of the input tensor, which is then converted to its floating point\n    representation according to the scale factor (i.e. scale/int_scale).\n\n    All values required for the quantization are determined externally.\n\n\n    Parameters\n    ----------\n    float_to_int_impl: Module\n        Module that performs the conversion from floating point to integer representation\n    tensor_clamp_impl: Module\n        Module that performs the clamping of the input values for a proper integer representation\n    signed: Bool\n        Bool that determines whether to use signed or unsigned integers.\n    narrow_range: Bool\n        Bool that determines whether to enable or not the narrow range representation.\n\n    Methods\n    -------\n    to_int(scale, int_scale_msb_clamp_bit_width, x)\n        Perform the conversion to integer of the input tensor.\n        After diving by the scale factor (i.e. scale/int_scale), the input tensor is clamped in the range of admissible\n        integer values, and then converted to integer according to the strategy defined by `float_to_int_impl`.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input tensor that will be quantized\n        scale: Tensor\n            Floating point component of the scale factor\n        int_scale: Tensor\n            Integer component of the scale factor\n        msb_clamp_bit_width: Tensor\n            Bit_width to be used for the conversion to integer\n\n    forward(scale, int_scale, msb_clamp_bit_width, x)\n        Perform the quantization of the input tensor. The value is first converted to its integer representation and\n        quantized, then converted to its floating representation multiplying it by the scale factor\n        (i.e. scale/scale_int)\n\n        Parameters\n        ----------\n        x: Tensor\n            Input tensor that will be quantized\n        scale: Tensor\n            Floating point component of the scale factor\n        int_scale: Tensor\n            Integer component of the scale factor\n        msb_clamp_bit_width: Tensor\n            Bit_width to be used for the conversion to integer\n\n        Returns\n        -------\n        Tensor\n            The quantized tensor after its conversion to floating point\n\n    min_int(bit_width)\n        Determines the minimum integer representable according to the values of `signed`, `narrow_range`, and\n        `bit_width`.\n\n        Parameters\n        ----------\n        bit_width: Tensor\n            Number of bits for determining the minimum integer representable\n\n        Returns\n        -------\n        Tensor\n            The minimum integer representable\n\n    max_int(bit_width)\n        Determines the maximum signed integer representable according to the values of `signed`, `narrow_range`, and\n        `bit_width`.\n\n        Parameters\n        ----------\n        bit_width: Tensor\n            Number of bits for determining the maximum integer representable\n\n        Returns\n        -------\n        Tensor\n            The maximum integer representable\n\n    max_uint(bit_width)\n        Determines the maximum unsigned integer representable according to the values of `narrow_range` and\n        `bit_width`.\n\n        Parameters\n        ----------\n        bit_width: Tensor\n            Number of bits for determining the maximum integer representable\n\n        Returns\n        -------\n        Tensor\n            The maximum integer representable\n    """"""\n    __constants__ = [\'signed\', \'narrow_range\']\n\n    def __init__(self,\n                 narrow_range: bool,\n                 signed: bool,\n                 float_to_int_impl: Module,\n                 tensor_clamp_impl: Module):\n        super(IntQuant, self).__init__()\n        self.float_to_int_impl = float_to_int_impl\n        self.tensor_clamp_impl = tensor_clamp_impl\n        self.signed = signed\n        self.narrow_range = narrow_range\n\n    def to_int(self,\n               scale: Tensor,\n               int_scale: Tensor,\n               msb_clamp_bit_width: Tensor,\n               x: Tensor) -> Tensor:\n        y = x / scale\n        y = y * int_scale\n        min_int_val = self.min_int(msb_clamp_bit_width)\n        max_int_val = self.max_int(msb_clamp_bit_width)\n        y = self.tensor_clamp_impl(y, min_val=min_int_val, max_val=max_int_val)\n        y = self.float_to_int_impl(y)\n        return y\n\n    @torch.jit.script_method\n    def min_int(self, bit_width):\n        return min_int(self.signed, self.narrow_range, bit_width)\n\n    @torch.jit.script_method\n    def max_int(self, bit_width):\n        return max_int(self.signed, bit_width)\n\n    @torch.jit.script_method\n    def max_uint(self, bit_width):\n        return max_uint(self.narrow_range, bit_width)\n\n    @torch.jit.script_method\n    def forward(self,\n                scale: Tensor,\n                int_scale: Tensor,\n                msb_clamp_bit_width: Tensor,\n                x: Tensor) -> Tensor:\n        y_int = self.to_int(scale, int_scale, msb_clamp_bit_width, x)\n        y = y_int / int_scale\n        y = y * scale\n        return y\n'"
brevitas/core/restrict_val.py,5,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom enum import auto\nfrom typing import Callable, Union, Optional\nimport math\n\nimport torch\nfrom torch.nn import Sequential\n\nfrom brevitas.utils.python_utils import AutoName\nfrom .function_wrapper import RoundSte, CeilSte, Identity, PowerOfTwo, LogTwo, FloorSte, ClampMin\nfrom brevitas.function.ops import identity\n\nclass RestrictValueType(AutoName):\n    FP = auto()\n    LOG_FP = auto()\n    INT = auto()\n    POWER_OF_TWO = auto()\n\n\nclass FloatToIntImplType(AutoName):\n    ROUND = auto()\n    CEIL = auto()\n    FLOOR = auto()\n\n\nclass RestrictValueOpImplType(AutoName):\n    MATH = auto()\n    TORCH_FN = auto()\n    TORCH_MODULE = auto()\n\n\nclass RestrictValue(torch.jit.ScriptModule):\n\n    def __init__(self,\n                 restrict_value_type: RestrictValueType,\n                 float_to_int_impl_type: FloatToIntImplType,\n                 min_val: Optional[float]) -> None:\n        super(RestrictValue, self).__init__()\n\n        if float_to_int_impl_type == FloatToIntImplType.ROUND:\n            float_to_int_impl = RoundSte()\n        elif float_to_int_impl_type == FloatToIntImplType.CEIL:\n            float_to_int_impl = CeilSte()\n        elif float_to_int_impl_type == FloatToIntImplType.FLOOR:\n            float_to_int_impl = FloorSte()\n        else:\n            raise Exception(""Float to int impl type {} not supported for restrict value""\n                            .format(str(float_to_int_impl_type)))\n\n        if min_val is not None:\n            clamp_to_min_val = ClampMin(min_val=min_val)\n        else:\n            clamp_to_min_val = Identity()\n\n        if restrict_value_type == RestrictValueType.FP:\n            self.forward_impl = Sequential(Identity(), clamp_to_min_val)\n        elif restrict_value_type == RestrictValueType.LOG_FP:\n            self.forward_impl = Sequential(PowerOfTwo(), clamp_to_min_val)\n        elif restrict_value_type == RestrictValueType.INT:\n            self.forward_impl = Sequential(float_to_int_impl, clamp_to_min_val)\n        elif restrict_value_type == RestrictValueType.POWER_OF_TWO:\n            self.forward_impl = Sequential(float_to_int_impl, PowerOfTwo(), clamp_to_min_val)\n        else:\n            raise Exception(""Restrict value type {} not recognized"".format(str(restrict_value_type)))\n\n        self.restrict_value_type = restrict_value_type\n\n    @staticmethod\n    def restrict_value_op(restrict_value_type: RestrictValueType, restrict_value_op_impl_type: RestrictValueOpImplType):\n        if restrict_value_type == RestrictValueType.FP or restrict_value_type == RestrictValueType.INT:\n            return identity\n        elif restrict_value_type == RestrictValueType.LOG_FP or restrict_value_type == RestrictValueType.POWER_OF_TWO:\n            if restrict_value_op_impl_type == RestrictValueOpImplType.TORCH_FN:\n                return torch.log2\n            elif restrict_value_op_impl_type == RestrictValueOpImplType.MATH:\n                return math.log2\n            elif restrict_value_op_impl_type == RestrictValueOpImplType.TORCH_MODULE:\n                return LogTwo()\n            else:\n                raise Exception(""Type of implementation {} not recognized"".format(str(restrict_value_op_impl_type)))\n        else:\n            raise Exception(""Restriction of type {} not recognized"".format(str(restrict_value_type)))\n\n    @torch.jit.script_method\n    def forward(self, value: torch.Tensor) -> torch.Tensor:\n        value = self.forward_impl(value)\n        return value\n'"
brevitas/core/scaling.py,28,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom enum import auto\nfrom typing import Tuple, Optional, List\n\nimport torch\nfrom torch.nn import Module, Parameter\n\nimport brevitas.config as config\nfrom brevitas.core.function_wrapper import Identity\nfrom brevitas.function.ops import min_int, max_int\nfrom brevitas.utils.python_utils import AutoName\nfrom .restrict_val import RestrictValue, RestrictValueType, FloatToIntImplType, RestrictValueOpImplType\nfrom .stats import StatsOp, StatsInputViewShapeImpl, ParameterListStats, RuntimeStats\n\nSCALING_SCALAR_SHAPE = ()\n\n\nclass ScalingImplType(AutoName):\n    HE = auto()\n    CONST = auto()\n    STATS = auto()\n    AFFINE_STATS = auto()\n    PARAMETER = auto()\n    PARAMETER_FROM_STATS = auto()\n    OVERRIDE = auto()\n\n\nclass StandaloneScaling(torch.jit.ScriptModule):\n    __constants__ = [\'const_value\']\n\n    def __init__(self,\n                 scaling_init: torch.Tensor,\n                 is_parameter: bool,\n                 parameter_shape: Optional[Tuple[int, ...]],\n                 scaling_min_val: Optional[float],\n                 restrict_scaling_type: RestrictValueType) -> None:\n        super(StandaloneScaling, self).__init__()\n\n        if len(parameter_shape) > 1 and not is_parameter:\n            raise Exception(""Standalone scaling shape has to be a scalar when scaling is not learned."")\n        if not (restrict_scaling_type == RestrictValueType.FP\n                or restrict_scaling_type == RestrictValueType.LOG_FP\n                or restrict_scaling_type == RestrictValueType.POWER_OF_TWO):\n            raise Exception(""Restriction of type {} is not supported for standalone scaling.""\n                            .format(str(restrict_scaling_type)))\n\n        self.restrict_value = RestrictValue(restrict_scaling_type, FloatToIntImplType.CEIL, scaling_min_val)\n        scaling_init_op = RestrictValue.restrict_value_op(restrict_scaling_type,\n                                                          restrict_value_op_impl_type=RestrictValueOpImplType.TORCH_FN)\n        scaling_init = scaling_init_op(scaling_init)\n        if is_parameter and scaling_init.dim() == 0:  # for activations with per channel scaling\n            self.learned_value = Parameter(torch.full(parameter_shape, scaling_init))\n            self.const_value = None\n        elif is_parameter and scaling_init.shape == parameter_shape:\n            self.learned_value = Parameter(scaling_init)  # for weight with per output channel scaling from stats\n            self.const_value = None\n        elif not is_parameter and scaling_init.dim() == 0:  # for fixed scalar scaling\n            self.learned_value = None\n            self.const_value = scaling_init.item()\n        else:\n            raise Exception(""Problem with init of standalone scaling from value {}"".format(str(scaling_init)))\n\n    @torch.jit.script_method\n    def forward(self, zero_hw_sentinel: torch.Tensor) -> torch.Tensor:\n        if self.const_value is not None:\n            value = self.const_value + zero_hw_sentinel\n        else:\n            value = self.learned_value\n        value = self.restrict_value(value)\n        return value\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        value_key = prefix + \'learned_value\'\n        retrocomp_value_key = prefix + \'value\'\n        if retrocomp_value_key in state_dict: #  Retrocompatibility\n            state_dict[value_key] = state_dict.pop(retrocomp_value_key)\n        super(StandaloneScaling, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        if config.IGNORE_MISSING_KEYS and value_key in missing_keys:\n            missing_keys.remove(value_key)\n\n\nclass AffineRescaling(torch.jit.ScriptModule):\n\n    def __init__(self, affine_shape):\n        super(AffineRescaling, self).__init__()\n        self.affine_weight = Parameter(torch.ones(affine_shape))\n        self.affine_bias = Parameter(torch.zeros(affine_shape))\n\n    def forward(self, x):\n        out = x * self.affine_weight + self.affine_bias\n        out = torch.abs(out)\n        return out\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        super(AffineRescaling, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        affine_weight_key = prefix + \'affine_weight\'\n        affine_bias_key = prefix + \'affine_bias\'\n        if config.IGNORE_MISSING_KEYS and affine_weight_key in missing_keys:\n            missing_keys.remove(affine_weight_key)\n        if config.IGNORE_MISSING_KEYS and affine_bias_key in missing_keys:\n            missing_keys.remove(affine_bias_key)\n\n\nclass StatsScaling(torch.jit.ScriptModule):\n    __constants__ = [\'const_affine_weight\', \'const_affine_bias\']\n\n    def __init__(self,\n                 stats_op: StatsOp,\n                 restrict_scaling_type: RestrictValueType,\n                 stats_output_shape: Tuple[int, ...],\n                 scaling_min_val: Optional[float],\n                 affine: bool) -> None:\n        super(StatsScaling, self).__init__()\n\n        if not (restrict_scaling_type == RestrictValueType.FP\n                or restrict_scaling_type == RestrictValueType.LOG_FP\n                or restrict_scaling_type == RestrictValueType.POWER_OF_TWO):\n            raise Exception(""Restriction of type {} is not supported for stats scaling.""\n                            .format(str(restrict_scaling_type)))\n        if stats_op == StatsOp.MAX_AVE and stats_output_shape != SCALING_SCALAR_SHAPE:\n            raise Exception(""Scaling with MAX_AVE stats can\'t be over output channels."")\n\n        if affine:\n            self.affine_rescaling = AffineRescaling(stats_output_shape)\n        else:\n            self.affine_rescaling = Identity()\n\n        self.restrict_scaling = RestrictValue(restrict_scaling_type, FloatToIntImplType.CEIL, scaling_min_val)\n        self.restrict_scaling_preprocess = RestrictValue.restrict_value_op(restrict_scaling_type,\n                                                                           restrict_value_op_impl_type=\n                                                                           RestrictValueOpImplType.TORCH_MODULE)\n\n    @torch.jit.script_method\n    def forward(self, stats: torch.Tensor) -> torch.Tensor:\n        stats = self.affine_rescaling(stats)\n        stats = self.restrict_scaling_preprocess(stats)\n        stats = self.restrict_scaling(stats)\n        return stats\n\n\nclass RuntimeStatsScaling(torch.jit.ScriptModule):\n\n    def __init__(self,\n                 stats_op: StatsOp,\n                 restrict_scaling_type: RestrictValueType,\n                 stats_input_view_shape_impl: StatsInputViewShapeImpl,\n                 stats_output_shape: Tuple[int, ...],\n                 sigma: Optional[float],\n                 scaling_min_val: Optional[float],\n                 stats_reduce_dim: Optional[int],\n                 stats_permute_dims: Tuple,\n                 stats_buffer_momentum: Optional[float],\n                 stats_buffer_init: float,\n                 affine: bool) -> None:\n        super(RuntimeStatsScaling, self).__init__()\n\n        self.runtime_stats = RuntimeStats(stats_op=stats_op,\n                                          stats_output_shape=stats_output_shape,\n                                          stats_reduce_dim=stats_reduce_dim,\n                                          stats_input_view_shape_impl=stats_input_view_shape_impl,\n                                          stats_buffer_momentum=stats_buffer_momentum,\n                                          stats_buffer_init=stats_buffer_init,\n                                          stats_permute_dims=stats_permute_dims,\n                                          sigma=sigma)\n        self.stats_scaling_impl = StatsScaling(restrict_scaling_type=restrict_scaling_type,\n                                               scaling_min_val=scaling_min_val,\n                                               affine=affine,\n                                               stats_op=stats_op,\n                                               stats_output_shape=stats_output_shape)\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        stats = self.runtime_stats(x)\n        return self.stats_scaling_impl(stats)\n\n\nclass ParameterStatsScaling(torch.jit.ScriptModule):\n\n    def __init__(self,\n                 stats_op: StatsOp,\n                 restrict_scaling_type: RestrictValueType,\n                 stats_input_view_shape_impl: StatsInputViewShapeImpl,\n                 stats_output_shape: Tuple[int, ...],\n                 stats_input_concat_dim: Optional[int],\n                 sigma: Optional[float],\n                 scaling_min_val: Optional[float],\n                 stats_reduce_dim: Optional[int],\n                 tracked_parameter_list: List[torch.nn.Parameter],\n                 affine: bool) -> None:\n        super(ParameterStatsScaling, self).__init__()\n\n        self.parameter_list_stats = ParameterListStats(stats_op=stats_op,\n                                                       stats_output_shape=stats_output_shape,\n                                                       stats_reduce_dim=stats_reduce_dim,\n                                                       stats_input_view_shape_impl=stats_input_view_shape_impl,\n                                                       stats_input_concat_dim=stats_input_concat_dim,\n                                                       tracked_parameter_list=tracked_parameter_list,\n                                                       sigma=sigma)\n        self.stats_scaling_impl = StatsScaling(restrict_scaling_type=restrict_scaling_type,\n                                               scaling_min_val=scaling_min_val,\n                                               affine=affine,\n                                               stats_op=stats_op,\n                                               stats_output_shape=stats_output_shape)\n\n    @torch.jit.script_method\n    def forward(self, zero_hw_sentinel: torch.Tensor):\n        stats = self.parameter_list_stats()\n        return self.stats_scaling_impl(stats)\n\n\nclass SignedFpIntScale(torch.jit.ScriptModule):\n    __constants__ = [\'signed\', \'narrow_range\']\n\n    def __init__(self, narrow_range):\n        super(SignedFpIntScale, self).__init__()\n        self.signed = True\n        self.narrow_range = narrow_range\n\n    @torch.jit.script_method\n    def forward(self, bit_width):\n        return - min_int(self.signed, self.narrow_range, bit_width)\n\n\nclass UnsignedFpIntScale(torch.jit.ScriptModule):\n    __constants__ = [\'signed\']\n\n    def __init__(self):\n        super(UnsignedFpIntScale, self).__init__()\n        self.signed = False\n\n    @torch.jit.script_method\n    def forward(self, bit_width):\n        return max_int(self.signed, bit_width)\n\n\nclass PowerOfTwoIntScale(torch.jit.ScriptModule):\n    __constants__ = [\'signed\']\n\n    def __init__(self, signed):\n        super(PowerOfTwoIntScale, self).__init__()\n        self.signed = signed\n\n    @torch.jit.script_method\n    def forward(self, bit_width):\n        return max_int(self.signed, bit_width) + 1\n\n\nclass IntScaling(torch.jit.ScriptModule):\n\n    def __init__(self,\n                 narrow_range: bool,\n                 signed: bool,\n                 restrict_scaling_type: RestrictValueType) -> None:\n        super(IntScaling, self).__init__()\n\n        if not (restrict_scaling_type == RestrictValueType.FP\n                or restrict_scaling_type == RestrictValueType.LOG_FP\n                or restrict_scaling_type == RestrictValueType.POWER_OF_TWO):\n            raise Exception(""Restriction of type {} is not supported for int scaling.""\n                            .format(str(restrict_scaling_type)))\n\n        if signed and not restrict_scaling_type == RestrictValueType.POWER_OF_TWO:  # FP or LOG_FP\n            self.forward_impl = SignedFpIntScale(narrow_range)\n        elif not signed and not restrict_scaling_type == RestrictValueType.POWER_OF_TWO:  # FP or LOG_FP\n            self.forward_impl = UnsignedFpIntScale()\n        elif restrict_scaling_type == RestrictValueType.POWER_OF_TWO:\n            self.forward_impl = PowerOfTwoIntScale(signed)\n        else:\n            raise Exception(""Restrict value type {} not recognized"".format(restrict_scaling_type))\n\n    @torch.jit.script_method\n    def forward(self, bit_width):\n        int_scale = self.forward_impl(bit_width)\n        return int_scale\n\n\n\n'"
brevitas/core/stats.py,42,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom typing import Tuple, Optional, List, Union\nfrom enum import auto\n\nimport torch\nfrom torch import nn\nfrom torch.nn import Parameter\n\nimport brevitas.config as config\nfrom brevitas.function.shape import *\nfrom brevitas.core.function_wrapper import OverOutputChannelView, OverBatchOverTensorView\nfrom brevitas.core.function_wrapper import OverBatchOverOutputChannelView, OverTensorView\nfrom brevitas.utils.python_utils import AutoName\n\n__all__ = [\'StatsInputViewShapeImpl\', \'StatsOp\', \'ParameterListStats\']\n\n\nSTD_DEV_EPSILON = 1e-8\n\n\nclass StatsInputViewShapeImpl(object):\n    OVER_TENSOR = OverTensorView\n    OVER_OUTPUT_CHANNELS = OverOutputChannelView\n    OVER_BATCH_OVER_TENSOR = OverBatchOverTensorView\n    OVER_BATCH_OVER_OUTPUT_CHANNELS = OverBatchOverOutputChannelView\n\n\nclass StatsOp(AutoName):\n    MAX = auto()\n    AVE = auto()\n    MAX_AVE = auto()\n    MEAN_SIGMA_STD = auto()\n    MEAN_LEARN_SIGMA_STD = auto()\n\n\nclass _ViewParameterWrapper(torch.jit.ScriptModule):\n    __constants__ = [\'shape\']\n\n    def __init__(self, parameter, view_shape_impl):\n        super(_ViewParameterWrapper, self).__init__()\n        self.parameter = parameter\n        self.shape = view_shape_impl().shape(parameter)\n\n    @torch.jit.script_method\n    def forward(self):\n        return self.parameter.view(self.shape)\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        super(_ViewParameterWrapper, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        parameter_key = prefix + \'parameter\'\n        if parameter_key in missing_keys:\n            missing_keys.remove(parameter_key)\n\n    def state_dict(self, destination=None, prefix=\'\', keep_vars=False):\n        output_dict = super(_ViewParameterWrapper, self).state_dict(destination, prefix, keep_vars)\n        del output_dict[prefix + \'parameter\']\n        return output_dict\n\n\nclass _ViewCatParameterWrapper(torch.jit.ScriptModule):\n    __constants__ = [\'shape\', \'cat_dim\']\n\n    def __init__(self, parameter, view_shape_impl, cat_dim):\n        super(_ViewCatParameterWrapper, self).__init__()\n        self.parameter = parameter\n        self.shape = view_shape_impl().shape(parameter)\n        self.cat_dim = cat_dim\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return torch.cat([self.parameter.view(self.shape), x], dim=self.cat_dim)\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        super(_ViewCatParameterWrapper, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        parameter_key = prefix + \'parameter\'\n        if parameter_key in missing_keys:\n            missing_keys.remove(parameter_key)\n\n    def state_dict(self, destination=None, prefix=\'\', keep_vars=False):\n        output_dict = super(_ViewCatParameterWrapper, self).state_dict(destination, prefix, keep_vars)\n        del output_dict[prefix + \'parameter\']\n        return output_dict\n\n\nclass AbsMax(torch.jit.ScriptModule):\n    __constants__ = [\'reduce_dim\']\n\n    def __init__(self, reduce_dim) -> None:\n        super(AbsMax, self).__init__()\n        self.reduce_dim = reduce_dim\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        if self.reduce_dim is None:\n            return torch.max(torch.abs(x))\n        else:\n            return torch.max(torch.abs(x), dim=self.reduce_dim)[0]\n\n\nclass AbsMaxAve(torch.jit.ScriptModule):\n    __constants__ = [\'reduce_dim\']\n\n    def __init__(self, reduce_dim) -> None:\n        super(AbsMaxAve, self).__init__()\n        self.reduce_dim = reduce_dim\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        return torch.mean(torch.max(torch.abs(x), dim=self.reduce_dim)[0])\n\n\nclass AbsAve(torch.jit.ScriptModule):\n    __constants__ = [\'reduce_dim\']\n\n    def __init__(self, reduce_dim) -> None:\n        super(AbsAve, self).__init__()\n        self.reduce_dim = reduce_dim\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        if self.reduce_dim is None:\n            return torch.mean(torch.abs(x))\n        else:\n            return torch.mean(torch.abs(x), dim=self.reduce_dim)\n\n\nclass MeanSigmaStd(torch.jit.ScriptModule):\n    __constants__ = [\'reduce_dim\', \'output_shape\', \'std_dev_epsilon\', \'const_sigma\']\n\n    def __init__(self, reduce_dim, const_sigma, learned_sigma, output_shape) -> None:\n        super(MeanSigmaStd, self).__init__()\n        self.reduce_dim = reduce_dim\n        self.const_sigma = const_sigma\n        self.learned_sigma = learned_sigma\n        self.output_shape = output_shape\n        self.std_dev_epsilon = STD_DEV_EPSILON\n\n    @torch.jit.script_method\n    def forward(self, x: torch.Tensor):\n        abs_val = torch.abs(x)\n        if self.reduce_dim is None:\n            mean_val = torch.mean(abs_val)\n            std_val = torch.sqrt(torch.var(abs_val) + self.std_dev_epsilon)\n        else:\n            mean_val = torch.mean(torch.abs(x), dim=self.reduce_dim)\n            mean_val = mean_val.view(self.output_shape)\n            std_val = torch.sqrt(torch.var(abs_val, dim=self.reduce_dim) + self.std_dev_epsilon)\n            std_val = std_val.view(self.output_shape)\n        if self.const_sigma is not None:\n            return mean_val + self.const_sigma * std_val\n        else:\n            return mean_val + self.learned_sigma * std_val\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        super(MeanSigmaStd, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        sigma_key = prefix + \'learned_sigma\'\n        if config.IGNORE_MISSING_KEYS and sigma_key in missing_keys:\n            missing_keys.remove(sigma_key)\n\n\nclass Stats(torch.jit.ScriptModule):\n    __constants__ = [\'stats_output_shape\',\n                     \'stats_reduce_dim\']\n\n    def __init__(self,\n                 stats_op: StatsOp,\n                 stats_reduce_dim: Optional[int],\n                 stats_output_shape: Tuple[int, ...],\n                 sigma: Optional[float]) -> None:\n        super(Stats, self).__init__()\n\n        if stats_reduce_dim is not None and len(stats_output_shape) < 2 and stats_op != StatsOp.MAX_AVE:\n            raise Exception(""Defining a reduce dimension requires the output view shape to have at least 2 dims."")\n        if  len(stats_output_shape) > 1 and stats_reduce_dim is None:\n            raise Exception(""Defining an output view shape with more than 1 dims assumes a not None reduce dim."")\n        if (stats_op == StatsOp.MEAN_SIGMA_STD or stats_op == StatsOp.MEAN_LEARN_SIGMA_STD) and sigma is None:\n            raise Exception(""Stats of type {} requires to define a value for sigma."".format(str(stats_op)))\n\n        self.stats_output_shape = stats_output_shape\n\n        if stats_op == StatsOp.MAX:\n            self.stats_impl = AbsMax(reduce_dim=stats_reduce_dim)\n        elif stats_op == StatsOp.AVE:\n            self.stats_impl = AbsAve(reduce_dim=stats_reduce_dim)\n        elif stats_op == StatsOp.MAX_AVE:\n            self.stats_impl = AbsMaxAve(reduce_dim=stats_reduce_dim)\n        elif stats_op == StatsOp.MEAN_SIGMA_STD or stats_op == StatsOp.MEAN_LEARN_SIGMA_STD:\n            const_sigma = None\n            learned_sigma = None\n            if stats_op == StatsOp.MEAN_LEARN_SIGMA_STD:\n                learned_sigma = Parameter(torch.full(stats_output_shape, sigma))\n            else:\n                const_sigma = sigma\n            self.stats_impl = MeanSigmaStd(stats_reduce_dim, const_sigma, learned_sigma, stats_output_shape)\n        else:\n            raise Exception(""Stats op {} not recognized"".format(str(stats_op)))\n\n    @torch.jit.script_method\n    def forward(self, input) -> torch.Tensor:\n        stats = self.stats_impl(input)\n        stats = stats.view(self.stats_output_shape)\n        return stats\n\n\nclass RuntimeStats(torch.jit.ScriptModule):\n    __constants__ = [\'stats_input_concat_dim\',\n                     \'stats_permute_dims\',\n                     \'momentum\']\n\n    def __init__(self,\n                 stats_op: StatsOp,\n                 stats_input_view_shape_impl: StatsInputViewShapeImpl,\n                 stats_permute_dims: Tuple[int, ...],\n                 stats_reduce_dim: Optional[int],\n                 stats_output_shape: Tuple[int, ...],\n                 stats_buffer_momentum: float,\n                 stats_buffer_init: float,\n                 sigma: Optional[float]) -> None:\n        super(RuntimeStats, self).__init__()\n\n        self.stats_permute_dims = stats_permute_dims\n        self.stats_input_view_shape_impl = stats_input_view_shape_impl()\n        self.stats = Stats(stats_op=stats_op,\n                           stats_output_shape=stats_output_shape,\n                           stats_reduce_dim=stats_reduce_dim,\n                           sigma=sigma)\n        self.momentum = stats_buffer_momentum\n        self.register_buffer(\'running_stats\', torch.full(stats_output_shape, stats_buffer_init))\n\n    @torch.jit.script_method\n    def forward(self, stats_input) -> torch.Tensor:\n        if self.training:\n            if self.stats_permute_dims is not None:\n                stats_input = stats_input.permute(*self.stats_permute_dims).contiguous()\n            stats_input = self.stats_input_view_shape_impl(stats_input)\n            out = self.stats(stats_input)\n            self.running_stats *= (1 - self.momentum)\n            self.running_stats += self.momentum * out.detach()\n        else:\n            out = self.running_stats\n        return out\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        super(RuntimeStats, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        running_stats_key = prefix + \'running_stats\'\n        if config.IGNORE_MISSING_KEYS and running_stats_key in missing_keys:\n            missing_keys.remove(running_stats_key)\n        training_key = prefix + \'training\' # Pytorch stores training flag as a buffer with JIT enabled\n        if training_key in missing_keys:\n            missing_keys.remove(training_key)\n\n\nclass ParameterListStats(torch.jit.ScriptModule):\n    __constants__ = [\'stats_input_concat_dim\',\n                     \'extra_tracked_params_list\']\n\n    def __init__(self,\n                 stats_op: StatsOp,\n                 stats_input_view_shape_impl: StatsInputViewShapeImpl,\n                 stats_reduce_dim: Optional[int],\n                 stats_input_concat_dim: int,\n                 stats_output_shape: Tuple[int, ...],\n                 tracked_parameter_list: List[torch.nn.Parameter],\n                 sigma: Optional[float]) -> None:\n        super(ParameterListStats, self).__init__()\n\n        self.stats_input_concat_dim = stats_input_concat_dim\n        self.first_tracked_param = _ViewParameterWrapper(tracked_parameter_list[0], stats_input_view_shape_impl)\n        if len(tracked_parameter_list) > 1:\n            extra_list = [_ViewCatParameterWrapper(param, stats_input_view_shape_impl, stats_input_concat_dim)\n                          for param in tracked_parameter_list[1:]]\n            self.extra_tracked_params_list = torch.nn.ModuleList(extra_list)\n        else:\n            self.extra_tracked_params_list = None\n        self.stats = Stats(stats_op=stats_op,\n                           stats_output_shape=stats_output_shape,\n                           stats_reduce_dim=stats_reduce_dim,\n                           sigma=sigma)\n\n    @torch.jit.script_method\n    def forward(self) -> torch.Tensor:\n        stats_input = self.first_tracked_param()\n        if self.extra_tracked_params_list is not None:\n            for extra_tracked_param in self.extra_tracked_params_list:\n                stats_input = extra_tracked_param(stats_input)\n        out = self.stats(stats_input)\n        return out\n\n\n\n'"
brevitas/function/__init__.py,0,b'from .ops import *\nfrom .ops_ste import *\n'
brevitas/function/autograd_ops.py,23,"b'# Copyright (c) 2019-     Xilinx, Inc              (Giuseppe Franco)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nimport torch\n\n\nclass scalar_clamp_ste_fn(torch.autograd.Function):\n    """""" Autograd function that implements scalar_clamp with a straight through estimator\n\n    Look at the documentation of :func:`~brevitas.function.ops_ste.scalar_clamp_ste` for further details.\n\n    """"""\n    @staticmethod\n    def forward(ctx, x: torch.Tensor, min_val: float, max_val: float):\n        """"""\n        """"""\n        y = torch.clamp(x, min_val, max_val)\n        return y\n\n    @staticmethod\n    def backward(ctx, grad_y):\n        """"""\n        """"""\n        return grad_y, None, None\n\n\nclass tensor_clamp_ste_fn(torch.autograd.Function):\n    """""" Autograd function that implements tensor_clamp with a straight through estimator\n\n    Look at the documentation of :func:`~brevitas.function.ops_ste.tensor_clamp_ste` for further details.\n\n    """"""\n    @staticmethod\n    def forward(ctx, x: torch.Tensor, min_val: torch.Tensor, max_val: torch.Tensor):\n        """"""\n        """"""\n        y = torch.where(x > max_val, max_val, x)\n        y = torch.where(y < min_val, min_val, y)\n        return y\n    @staticmethod\n    def backward(ctx, grad_y):\n        """"""\n        """"""\n        return grad_y, None, None\n\n\nclass ceil_ste_fn(torch.autograd.Function):\n    """""" Autograd function that implements ceil_ste with a straight through estimator\n\n    Look at the documentation of :func:`~brevitas.function.ops_ste.ceil_ste` for further details.\n\n    """"""\n    @staticmethod\n    def forward(ctx, x: torch.Tensor):\n        """"""\n        """"""\n        y = torch.ceil(x)\n        return y\n    @staticmethod\n    def backward(ctx, grad_y):\n        """"""\n        """"""\n        return grad_y\n\n\nclass floor_ste_fn(torch.autograd.Function):\n    """""" Autograd function that implements floor_ste with a straight through estimator\n\n    Look at the documentation of :func:`~brevitas.function.ops_ste.floor_ste` for further details.\n\n    """"""\n    @staticmethod\n    def forward(ctx, x: torch.Tensor):\n        """"""\n        """"""\n        y = torch.floor(x)\n        return y\n    @staticmethod\n    def backward(ctx, grad_y):\n        """"""\n        """"""\n        return grad_y\n\n\nclass binary_sign_ste_fn(torch.autograd.Function):\n    """""" Autograd function that implements binary_sign_ste with a straight through estimator\n\n    Look at the documentation of :func:`~brevitas.function.ops_ste.binary_sign_ste` for further details.\n\n    """"""\n    @staticmethod\n    def forward(ctx, x: torch.Tensor):\n        """"""\n        """"""\n        positive_mask = torch.ge(x, 0.0)\n        negative_mask = torch.lt(x, 0.0)\n        y = positive_mask.float() - negative_mask.float()\n        return y\n    @staticmethod\n    def backward(ctx, grad_y):\n        """"""\n        """"""\n        return grad_y\n\n\nclass ternary_sign_ste_fn(torch.autograd.Function):\n    """""" Autograd function that implements ternary_sign_ste with a straight through estimator\n\n    Look at the documentation of :func:`~brevitas.function.ops_ste.ternary_sign_ste` for further details.\n\n    """"""\n    @staticmethod\n    def forward(ctx, x: torch.Tensor):\n        """"""\n        """"""\n        y = torch.sign(x)\n        return y\n    @staticmethod\n    def backward(ctx, grad_y):\n        """"""\n        """"""\n        return grad_y\n\n\nclass round_ste_fn(torch.autograd.Function):\n    """""" Autograd function that implements round_ste with a straight through estimator\n\n    Look at the documentation of :func:`~brevitas.function.ops_ste.round_ste` for further details.\n\n    """"""\n    @staticmethod\n    def forward(ctx, x: torch.Tensor):\n        """"""\n        """"""\n        y = torch.round(x)\n        return y\n    @staticmethod\n    def backward(ctx, grad_y):\n        """"""\n        """"""\n        return grad_y\n'"
brevitas/function/ops.py,16,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nimport torch\n\n\n@torch.jit.script\ndef tensor_clamp(x: torch.Tensor, min_val: torch.Tensor, max_val: torch.Tensor) -> torch.Tensor:\n    """"""\n\n    Parameters\n    ----------\n    x : Tensor\n        Tensor on which to apply the clamp operation\n    min_val : Tensor\n        Tensor containing the minimum values for the clamp operation. Must have the same shape of `x`\n    max_val : Tensor\n        Tensor containing the maximum values for the clamp operation. Must have the same shape of `x`\n\n    Returns\n    -------\n    Tensor\n        Tensor for which every element of `x` is clamped between the corresponding minimum and maximum values.\n    """"""\n    out = torch.where(x > max_val, max_val, x)\n    out = torch.where(out < min_val, min_val, out)\n    return out\n\n\n@torch.jit.script\ndef tensor_clamp_(x: torch.Tensor, min_val: torch.Tensor, max_val: torch.Tensor) -> torch.Tensor:\n    torch.min(x, max_val, out=x)\n    torch.max(x, min_val, out=x)\n    return x\n\n\n@torch.jit.script\ndef identity(x: torch.Tensor) -> torch.Tensor:\n    """""" Identity function\n\n    Parameters\n    ----------\n    x : Tensor\n        Input Tensor\n\n    Returns\n    -------\n    Tensor\n        Unaltered input tensor\n\n    """"""\n    return x\n\n\n@torch.jit.script\ndef max_uint(narrow_range: bool, bit_width: torch.Tensor) -> torch.Tensor:\n    """""" Compute the maximum unsigned integer representable\n\n    The maximum unsigned integer representable depends on the number of bits, and whether the narrow range setting\n    is used. If so, the maximum value represented is decreased by one unit.\n\n    Parameters\n    ----------\n    narrow_range : Bool\n        Flag that indicates whether to decrease the possible maximum value represented\n    bit_width : Tensor\n        Number of bits available for the representation\n\n    Returns\n    -------\n    Tensor\n        Maximum unsigned integer that can be represented according to the input parameters\n\n    """"""\n    if narrow_range:\n        value = (2 ** bit_width) - 2\n    else:\n        value = (2 ** bit_width) - 1\n    return value\n\n\n@torch.jit.script\ndef max_int(signed: bool, bit_width: torch.Tensor) -> torch.Tensor:\n    """""" Compute the maximum integer representable\n\n    The maximum integer representable depends on the number of bits, and whether the negative numbers are included\n    in the representation. If so, one bit is lost in the computation of the maximum value.\n\n    Parameters\n    ----------\n    signed : Bool\n        Flag that indicates whether negative numbers must be included or not\n    bit_width : Tensor\n        Number of bits available for the representation\n\n    Returns\n    -------\n    Tensor\n        Maximum integer that can be represented according to the input parameters\n\n    """"""\n    if signed:\n        value = (2 ** (bit_width - 1)) - 1\n    else:\n        value = (2 ** bit_width) - 1\n    return value\n\n\n@torch.jit.script\ndef min_int(signed: bool, narrow_range: bool, bit_width: torch.Tensor) -> torch.Tensor:\n    """""" Compute the minimum integer representable\n\n    The minimum integer representable depends on the number of bits, whether the negative numbers are included\n    in the representation, and whether the narrow range setting is used.\n    For positive-only number, the minimum value will always be zero.\n    If the sign and narrow range flags are both set, then the representation will be such that there is symmetry\n    between positive and negative values.\n    For example, for 3 bit representation, with sign and narrow range, the\n    values representable are in the range [-3, 3].\n    If the narrow range is not enabled, then the possible values will be in the range [-4, 3].\n\n    Parameters\n    ----------\n    signed : Bool\n        Flag that indicates whether negative numbers must be included or not\n    narrow_range : Bool\n        Flag that indicates whether the narrow range setting is enabled or not\n    bit_width : Tensor\n        Number of bits available for the representation\n\n    Returns\n    -------\n    Tensor\n        Minimum integer that can be represented according to the input parameters\n\n    """"""\n    if signed and narrow_range:\n        value = - (2 ** (bit_width - 1)) + 1\n    elif signed and not narrow_range:\n        value = - (2 ** (bit_width - 1))\n    else:\n        value = 0 * bit_width\n    return value\n'"
brevitas/function/shape.py,4,"b'import torch\n\n\n@torch.jit.script\ndef over_tensor(x):\n    return (-1)\n\n\n@torch.jit.script\ndef over_output_channels(x):\n    return (x.shape[0], -1)\n\n\n@torch.jit.script\ndef over_batch_over_tensor(x):\n    return (x.shape[0], -1)\n\n\n@torch.jit.script\ndef over_batch_over_output_channels(x):\n    return (x.shape[0], x.shape[1], -1)'"
brevitas/loss/__init__.py,0,b'\n'
brevitas/loss/base_loss.py,0,"b'from abc import ABCMeta, abstractmethod\n\nfrom torch import nn\n\n\nclass SimpleBaseLoss(object):\n    __metaclass__ = ABCMeta\n\n    def __init__(self, model, reg_coeff):\n        self.model: nn.Module = model\n        self.reg_coeff = reg_coeff\n        self.tot_loss: float = 0.0\n        self.register_hooks()\n\n    @abstractmethod\n    def register_hooks(self):\n        pass\n\n    def zero_accumulated_values(self):\n        del self.tot_loss\n        self.tot_loss = 0.0\n\n    def retrieve(self):\n        return self.tot_loss * self.reg_coeff\n\n    def log(self):\n        return self.tot_loss.detach().clone() * self.reg_coeff'"
brevitas/loss/weighted_bit_width.py,1,"b'from typing import List\nfrom abc import ABCMeta, abstractmethod\n\nfrom functools import reduce\nfrom operator import mul\n\nimport torch\nfrom torch import nn\n\nfrom brevitas.utils.quant_utils import *\nfrom brevitas.nn.quant_linear import QuantLinear\nfrom brevitas.nn.quant_conv import QuantConv2d\nfrom brevitas.nn.quant_avg_pool import QuantAvgPool2d\n\nMEGA = 10e6\n\nclass BitWidthWeighted(object):\n    __metaclass__ = ABCMeta\n\n    def __init__(self, model):\n        self.model: nn.Module = model\n        self.weighted_bit_width_list: List[torch.Tensor] = []\n        self.tot_num_elements: int = 0\n        self.register_hooks()\n\n    @abstractmethod\n    def register_hooks(self):\n        pass\n\n    def zero_accumulated_values(self):\n        del self.weighted_bit_width_list\n        del self.tot_num_elements\n        self.weighted_bit_width_list = []\n        self.tot_num_elements = 0\n\n    def retrieve(self, as_average=True):\n        if self.tot_num_elements != 0 and self.weighted_bit_width_list:\n            if as_average:\n                value = sum(self.weighted_bit_width_list) / self.tot_num_elements\n            else:\n                value = [bit_width / self.tot_num_elements for bit_width in self.weighted_bit_width_list]\n        else:\n            raise Exception(""Number of elements to penalize can\'t be zero"")\n        return value\n\n    def log(self):\n        return self.retrieve(as_average=True).detach().clone()\n\n\n\nclass WeightBitWidthWeightedBySize(BitWidthWeighted):\n\n    def __init__(self, model):\n        super(WeightBitWidthWeightedBySize, self).__init__(model=model)\n        pass\n\n    def register_hooks(self):\n\n        def hook_fn(module, input, output):\n            (quant_weight, output_scale, output_bit_width) = output\n            num_elements = reduce(mul, quant_weight.size(), 1)\n            self.weighted_bit_width_list.append(num_elements * output_bit_width)\n            self.tot_num_elements += num_elements\n\n        for name, module in self.model.named_modules():\n            if has_learned_weight_bit_width(module):\n                module.register_forward_hook(hook_fn)\n\n\nclass ActivationBitWidthWeightedBySize(BitWidthWeighted):\n\n    def __init__(self, model):\n        super(ActivationBitWidthWeightedBySize, self).__init__(model=model)\n        pass\n\n    def register_hooks(self):\n\n        def hook_fn(module, input, output):\n            (quant_act, output_scale, output_bit_width) = output\n            num_elements = reduce(mul, quant_act.size()[1:], 1)  # exclude batch size\n            self.weighted_bit_width_list.append(num_elements * output_bit_width)\n            self.tot_num_elements += num_elements\n\n        for name, module in self.model.named_modules():\n            if has_learned_activation_bit_width(module):\n                module.register_forward_hook(hook_fn)\n\n\nclass QuantLayerOutputBitWidthWeightedByOps(BitWidthWeighted):\n\n    def __init__(self, model, layer_types=(QuantConv2d, QuantLinear)):\n        self.layer_types = layer_types\n        super(QuantLayerOutputBitWidthWeightedByOps, self).__init__(model=model)\n        pass\n\n    def register_hooks(self):\n\n        def hook_fn(module, input, output):\n            if module.return_quant_tensor:\n                output, output_scale, output_bit_width = output\n            output_size = reduce(mul, output.size()[1:], 1)  # exclude batch size\n            num_mops = output_size * module.per_elem_ops / MEGA\n            self.weighted_bit_width_list.append(output_bit_width * num_mops)\n            self.tot_num_elements += num_mops\n\n        for name, module in self.model.named_modules():\n            if isinstance(module, self.layer_types) \\\n                    and module.return_quant_tensor \\\n                    and module.compute_output_bit_width\\\n                    and module.per_elem_ops is not None:\n                module.register_forward_hook(hook_fn)\n\n\n\n'"
brevitas/nn/__init__.py,0,"b'from .quant_accumulator import ClampQuantAccumulator, TruncQuantAccumulator\nfrom .quant_activation import QuantReLU, QuantSigmoid, QuantTanh, QuantHardTanh, QuantIdentity\nfrom .quant_avg_pool import QuantAvgPool2d\nfrom .quant_linear import QuantLinear\nfrom .quant_conv import QuantConv2d, PaddingType\nfrom .quant_bn import BatchNorm2dToQuantScaleBias\nfrom .quant_scale_bias import ScaleBias, QuantScaleBias\nfrom .hadamard_classifier import HadamardClassifier\nfrom .quant_convtranspose1d import QuantConvTranspose1d\nfrom .quant_conv1d import QuantConv1d'"
brevitas/nn/hadamard_classifier.py,5,"b'#\n# Based on: https://arxiv.org/abs/1801.04540\n#\n\nimport torch.nn as nn\nimport math\nimport torch\n\ntry:\n    from scipy.linalg import hadamard\nexcept ImportError:\n    hadamard = None\n\nfrom brevitas.function.ops_ste import ceil_ste\nfrom brevitas.function.ops import max_uint\nfrom .quant_layer import QuantLayer\n\n\nclass HadamardClassifier(QuantLayer, nn.Module):\n\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 fixed_scale=False,\n                 compute_output_scale: bool = False,\n                 compute_output_bit_width: bool = False,\n                 return_quant_tensor: bool = False):\n        QuantLayer.__init__(self,\n                            compute_output_scale=compute_output_scale,\n                            compute_output_bit_width=compute_output_bit_width,\n                            return_quant_tensor=return_quant_tensor)\n        nn.Module.__init__(self)\n        if hadamard is None:\n            raise Exception(""Hadamard layer requires scipy to be installed."")\n\n        self.out_channels = out_channels\n        self.in_channels = in_channels\n        sz = 2 ** int(math.ceil(math.log(max(in_channels, out_channels), 2)))\n        mat = torch.from_numpy(hadamard(sz)).float()\n        self.register_buffer(\'proj\', mat)\n        init_scale = 1. / math.sqrt(self.out_channels)\n        if fixed_scale:\n            self.register_buffer(\'scale\', torch.tensor(init_scale))\n        else:\n            self.scale = nn.Parameter(torch.tensor(init_scale))\n        self.eps = 1e-8\n\n    def forward(self, x):\n        output_scale = None\n        output_bit_width = None\n        x, input_scale, input_bit_width = self.unpack_input(x)\n        norm = x.norm(p=\'fro\', keepdim=True) + self.eps\n        x = x / norm\n        out = - self.scale * nn.functional.linear(x, self.proj[:self.out_channels, :self.in_channels])\n        if self.compute_output_scale:\n            output_scale = input_scale * self.scale / norm\n        if self.compute_output_bit_width:\n            output_bit_width = self.max_output_bit_width(input_bit_width)\n        return self.pack_output(out, output_scale, output_bit_width)\n\n    def max_output_bit_width(self, input_bit_width):\n        max_input_val = max_uint(bit_width=input_bit_width, narrow_range=False)\n        max_output_val = max_input_val * self.in_channels\n        output_bit_width = ceil_ste(torch.log2(max_output_val))\n        return output_bit_width\n\n    def state_dict(self, destination=None, prefix=\'\', keep_vars=False):\n        state_dict = super(HadamardClassifier, self).state_dict(destination, prefix, keep_vars)\n        del state_dict[prefix + \'proj\']\n        return state_dict\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        super(HadamardClassifier, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        proj_key = prefix + \'proj\'\n        if proj_key in missing_keys:\n            missing_keys.remove(proj_key)'"
brevitas/nn/quant_accumulator.py,1,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom abc import ABCMeta\n\nfrom torch.nn import Module\n\nfrom brevitas.core.bit_width import BitWidthImplType\nfrom brevitas.core.quant import QuantType\nfrom brevitas.proxy.runtime_quant import ClampQuantProxy, TruncQuantProxy\nfrom .quant_layer import QuantLayer\n\n\nclass QuantAccumulator(QuantLayer, Module):\n    __metaclass__ = ABCMeta\n\n    def __init__(self):\n        QuantLayer.__init__(self,\n                            compute_output_scale=True,\n                            compute_output_bit_width=True,\n                            return_quant_tensor=True)\n        Module.__init__(self)\n\n    @property\n    def acc_quant_proxy(self):\n        return self._act_quant_proxy\n\n    @acc_quant_proxy.setter\n    def acc_quant_proxy(self, act_quant_proxy):\n        self._acc_quant_proxy = act_quant_proxy\n\n    def forward(self, input):\n        tensor, input_scale, input_bit_width = self.unpack_input(input)\n        output, output_scale, output_bit_width = self.acc_quant_proxy(tensor, input_scale, input_bit_width)\n        return self.pack_output(output, output_scale, output_bit_width)\n\n\nclass ClampQuantAccumulator(QuantAccumulator):\n\n    def __init__(self,\n                 ms_bit_width_to_clamp: int = 0,\n                 signed: bool = True,\n                 narrow_range: bool = True,\n                 min_overall_bit_width: int = 2,\n                 max_overall_bit_width: int = 32,\n                 quant_type: QuantType = QuantType.INT,\n                 msb_clamp_bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 per_elem_ops: int = None,\n                 clamp_at_least_init_val=False,\n                 override_pretrained_bit_width: bool = False):\n        super(ClampQuantAccumulator, self).__init__()\n        self.per_elem_ops = per_elem_ops\n        self.acc_quant_proxy = ClampQuantProxy(signed=signed,\n                                               narrow_range=narrow_range,\n                                               quant_type=quant_type,\n                                               ms_bit_width_to_clamp=ms_bit_width_to_clamp,\n                                               min_overall_bit_width=min_overall_bit_width,\n                                               max_overall_bit_width=max_overall_bit_width,\n                                               msb_clamp_bit_width_impl_type=msb_clamp_bit_width_impl_type,\n                                               clamp_at_least_init_val=clamp_at_least_init_val,\n                                               override_pretrained_bit_width=override_pretrained_bit_width)\n\n\nclass TruncQuantAccumulator(QuantAccumulator):\n\n    def __init__(self,\n                 ls_bit_width_to_trunc: int = 0,\n                 signed: bool = True,\n                 min_overall_bit_width: int = 2,\n                 max_overall_bit_width: int = 32,\n                 quant_type: QuantType = QuantType.INT,\n                 lsb_trunc_bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 trunc_at_least_init_val=False,\n                 explicit_rescaling=False,\n                 override_pretrained_bit_width: bool = False):\n        super(TruncQuantAccumulator, self).__init__()\n        self.acc_quant_proxy = TruncQuantProxy(signed=signed,\n                                               quant_type=quant_type,\n                                               ls_bit_width_to_trunc=ls_bit_width_to_trunc,\n                                               min_overall_bit_width=min_overall_bit_width,\n                                               max_overall_bit_width=max_overall_bit_width,\n                                               trunc_at_least_init_val=trunc_at_least_init_val,\n                                               lsb_trunc_bit_width_impl_type=lsb_trunc_bit_width_impl_type,\n                                               override_pretrained_bit_width=override_pretrained_bit_width,\n                                               explicit_rescaling=explicit_rescaling)'"
brevitas/nn/quant_activation.py,1,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom abc import ABCMeta\nfrom typing import Optional, Union, Tuple\n\nfrom torch import nn\nfrom torch.nn import Module\n\nfrom brevitas.core.bit_width import BitWidthParameter, BitWidthImplType\nfrom brevitas.core.function_wrapper import Identity, ConstScalarClamp\nfrom brevitas.core.quant import QuantType, IdentityQuant\nfrom brevitas.core.stats import StatsOp\nfrom brevitas.core.restrict_val import RestrictValueType, FloatToIntImplType\nfrom brevitas.core.scaling import ScalingImplType, StatsInputViewShapeImpl\nfrom brevitas.proxy.runtime_quant import ActivationQuantProxy\nfrom .quant_layer import QuantLayer, SCALING_MIN_VAL\n\n\nclass QuantActivation(QuantLayer, Module):\n    __metaclass__ = ABCMeta\n\n    def __init__(self, return_quant_tensor):\n        QuantLayer.__init__(self,\n                            compute_output_scale=True,\n                            compute_output_bit_width=True,\n                            return_quant_tensor=return_quant_tensor)\n        Module.__init__(self)\n\n    @property\n    def act_quant_proxy(self):\n        return self._act_quant_proxy\n\n    @act_quant_proxy.setter\n    def act_quant_proxy(self, act_quant_proxy):\n        self._act_quant_proxy = act_quant_proxy\n\n    def quant_act_scale(self):\n        if isinstance(self.act_quant_proxy.fused_activation_quant_proxy.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t generate scaling factor without quantization enabled"")\n        zero_hw_sentinel = self.act_quant_proxy.zero_hw_sentinel\n        scaling_impl = self.act_quant_proxy.fused_activation_quant_proxy.tensor_quant.scaling_impl\n        current_status = scaling_impl.training\n        scaling_impl.eval()\n        _, out, _ = self.act_quant_proxy(zero_hw_sentinel)\n        scaling_impl.train(current_status)\n        return out\n\n    def forward(self, input):\n        tensor, _, _ = self.unpack_input(input)\n        output, output_scale, output_bit_width = self.act_quant_proxy(tensor)\n        return self.pack_output(output, output_scale, output_bit_width)\n\n\nclass QuantReLU(QuantActivation):\n\n    def __init__(self,\n                 bit_width: int,\n                 max_val: float,\n                 quant_type: QuantType = QuantType.FP,\n                 float_to_int_impl_type: FloatToIntImplType = FloatToIntImplType.ROUND,\n                 scaling_impl_type: ScalingImplType = ScalingImplType.PARAMETER,\n                 scaling_override: Optional[Module] = None,\n                 scaling_per_channel: bool = False,\n                 scaling_min_val: Optional[float] = SCALING_MIN_VAL,\n                 scaling_stats_sigma = 2.0,\n                 scaling_stats_op = StatsOp.MEAN_LEARN_SIGMA_STD,\n                 scaling_stats_buffer_momentum = 0.1,\n                 scaling_stats_permute_dims = (1, 0, 2, 3),\n                 per_channel_broadcastable_shape: Optional[Tuple[int, ...]] = None,\n                 min_overall_bit_width: Optional[int] = 2,\n                 max_overall_bit_width: Optional[int] = None,\n                 bit_width_impl_override: Union[BitWidthParameter] = None,\n                 bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 override_pretrained_bit_width: bool = False,\n                 return_quant_tensor: bool = False):\n        super(QuantReLU, self).__init__(return_quant_tensor=return_quant_tensor)\n        activation_impl = nn.ReLU()\n        self.act_quant_proxy = ActivationQuantProxy(activation_impl=activation_impl,\n                                                    bit_width=bit_width,\n                                                    signed=False,\n                                                    narrow_range=False,\n                                                    scaling_override=scaling_override,\n                                                    min_val=0.0,\n                                                    max_val=max_val,\n                                                    quant_type=quant_type,\n                                                    float_to_int_impl_type=float_to_int_impl_type,\n                                                    scaling_impl_type=scaling_impl_type,\n                                                    scaling_per_channel=scaling_per_channel,\n                                                    scaling_min_val=scaling_min_val,\n                                                    per_channel_broadcastable_shape=per_channel_broadcastable_shape,\n                                                    min_overall_bit_width=min_overall_bit_width,\n                                                    max_overall_bit_width=max_overall_bit_width,\n                                                    bit_width_impl_override=bit_width_impl_override,\n                                                    bit_width_impl_type=bit_width_impl_type,\n                                                    restrict_bit_width_type=restrict_bit_width_type,\n                                                    restrict_scaling_type=restrict_scaling_type,\n                                                    override_pretrained_bit_width=override_pretrained_bit_width,\n                                                    scaling_stats_sigma=scaling_stats_sigma,\n                                                    scaling_stats_permute_dims=scaling_stats_permute_dims,\n                                                    scaling_stats_op=scaling_stats_op,\n                                                    scaling_stats_buffer_momentum=scaling_stats_buffer_momentum)\n\n\nclass QuantSigmoid(QuantActivation):\n\n    def __init__(self,\n                 bit_width: int,\n                 narrow_range: bool = False,\n                 quant_type: QuantType = QuantType.FP,\n                 float_to_int_impl_type: FloatToIntImplType = FloatToIntImplType.ROUND,\n                 min_overall_bit_width: Optional[int] = 2,\n                 max_overall_bit_width: Optional[int] = None,\n                 bit_width_impl_override: Union[BitWidthParameter] = None,\n                 bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 scaling_min_val: Optional[float] = SCALING_MIN_VAL,\n                 override_pretrained_bit_width: bool = False,\n                 return_quant_tensor = False):\n        super(QuantSigmoid, self).__init__(return_quant_tensor=return_quant_tensor)\n        activation_impl = nn.Sigmoid()\n        self.act_quant_proxy = ActivationQuantProxy(activation_impl=activation_impl,\n                                                    bit_width=bit_width,\n                                                    signed=False,\n                                                    narrow_range=narrow_range,\n                                                    scaling_override=None,\n                                                    min_val=0.0,\n                                                    max_val=1.0,\n                                                    quant_type=quant_type,\n                                                    float_to_int_impl_type=float_to_int_impl_type,\n                                                    scaling_impl_type=ScalingImplType.CONST,\n                                                    scaling_per_channel=False,\n                                                    scaling_min_val=scaling_min_val,\n                                                    per_channel_broadcastable_shape=None,\n                                                    min_overall_bit_width=min_overall_bit_width,\n                                                    max_overall_bit_width=max_overall_bit_width,\n                                                    bit_width_impl_override=bit_width_impl_override,\n                                                    bit_width_impl_type=bit_width_impl_type,\n                                                    restrict_bit_width_type=restrict_bit_width_type,\n                                                    restrict_scaling_type=restrict_scaling_type,\n                                                    override_pretrained_bit_width=override_pretrained_bit_width,\n                                                    scaling_stats_sigma=None,\n                                                    scaling_stats_op=None,\n                                                    scaling_stats_buffer_momentum=None,\n                                                    scaling_stats_permute_dims=None)\n\n\nclass QuantTanh(QuantActivation):\n\n    def __init__(self,\n                 bit_width: int,\n                 narrow_range: bool = False,\n                 quant_type: QuantType = QuantType.FP,\n                 float_to_int_impl_type: FloatToIntImplType = FloatToIntImplType.ROUND,\n                 min_overall_bit_width: Optional[int] = 2,\n                 max_overall_bit_width: Optional[int] = None,\n                 bit_width_impl_override: Union[BitWidthParameter] = None,\n                 bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 scaling_min_val: Optional[float] = SCALING_MIN_VAL,\n                 override_pretrained_bit_width: bool = False,\n                 return_quant_tensor: bool = False):\n        super(QuantTanh, self).__init__(return_quant_tensor=return_quant_tensor)\n        activation_impl = nn.Tanh()\n        self.act_quant_proxy = ActivationQuantProxy(activation_impl=activation_impl,\n                                                    bit_width=bit_width,\n                                                    signed=True,\n                                                    narrow_range=narrow_range,\n                                                    scaling_override=None,\n                                                    min_val=-1.0,\n                                                    max_val=1.0,\n                                                    quant_type=quant_type,\n                                                    float_to_int_impl_type=float_to_int_impl_type,\n                                                    scaling_impl_type=ScalingImplType.CONST,\n                                                    scaling_per_channel=False,\n                                                    scaling_min_val=scaling_min_val,\n                                                    per_channel_broadcastable_shape=None,\n                                                    min_overall_bit_width=min_overall_bit_width,\n                                                    max_overall_bit_width=max_overall_bit_width,\n                                                    bit_width_impl_override=bit_width_impl_override,\n                                                    bit_width_impl_type=bit_width_impl_type,\n                                                    restrict_bit_width_type=restrict_bit_width_type,\n                                                    restrict_scaling_type=restrict_scaling_type,\n                                                    override_pretrained_bit_width=override_pretrained_bit_width,\n                                                    scaling_stats_sigma=None,\n                                                    scaling_stats_op=None,\n                                                    scaling_stats_buffer_momentum=None,\n                                                    scaling_stats_permute_dims=None)\n\n\nclass QuantHardTanh(QuantActivation):\n\n    def __init__(self,\n                 bit_width: int,\n                 min_val: float = -1.0,\n                 max_val: float = 1.0,\n                 narrow_range: bool = False,\n                 quant_type: QuantType = QuantType.FP,\n                 float_to_int_impl_type: FloatToIntImplType = FloatToIntImplType.ROUND,\n                 scaling_impl_type: ScalingImplType = ScalingImplType.PARAMETER,\n                 scaling_override: Optional[Module] = None,\n                 scaling_per_channel: bool = False,\n                 scaling_stats_sigma: float = 3.0,\n                 scaling_stats_op: StatsOp = StatsOp.MEAN_LEARN_SIGMA_STD,\n                 scaling_stats_buffer_momentum: float = 0.1,\n                 scaling_stats_permute_dims: Tuple = (1, 0, 2, 3),\n                 per_channel_broadcastable_shape: Optional[Tuple[int, ...]] = None,\n                 min_overall_bit_width: Optional[int] = 2,\n                 max_overall_bit_width: Optional[int] = None,\n                 bit_width_impl_override: Union[BitWidthParameter] = None,\n                 bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 scaling_min_val: Optional[float] = SCALING_MIN_VAL,\n                 override_pretrained_bit_width: bool = False,\n                 return_quant_tensor: bool = False):\n        super(QuantHardTanh, self).__init__(return_quant_tensor=return_quant_tensor)\n        if quant_type == QuantType.FP:\n            activation_impl = ConstScalarClamp(min_val=min_val, max_val=max_val)\n        else:\n            activation_impl = Identity()\n        self.act_quant_proxy = ActivationQuantProxy(activation_impl=activation_impl,\n                                                    bit_width=bit_width,\n                                                    signed=True,\n                                                    narrow_range=narrow_range,\n                                                    scaling_override=scaling_override,\n                                                    min_val=min_val,\n                                                    max_val=max_val,\n                                                    quant_type=quant_type,\n                                                    float_to_int_impl_type=float_to_int_impl_type,\n                                                    scaling_impl_type=scaling_impl_type,\n                                                    scaling_per_channel=scaling_per_channel,\n                                                    scaling_min_val=scaling_min_val,\n                                                    per_channel_broadcastable_shape=per_channel_broadcastable_shape,\n                                                    min_overall_bit_width=min_overall_bit_width,\n                                                    max_overall_bit_width=max_overall_bit_width,\n                                                    bit_width_impl_override=bit_width_impl_override,\n                                                    bit_width_impl_type=bit_width_impl_type,\n                                                    restrict_bit_width_type=restrict_bit_width_type,\n                                                    restrict_scaling_type=restrict_scaling_type,\n                                                    override_pretrained_bit_width=override_pretrained_bit_width,\n                                                    scaling_stats_sigma=scaling_stats_sigma,\n                                                    scaling_stats_op=scaling_stats_op,\n                                                    scaling_stats_buffer_momentum=scaling_stats_buffer_momentum,\n                                                    scaling_stats_permute_dims=scaling_stats_permute_dims)\n\n\nclass QuantIdentity(QuantActivation):\n\n    def __init__(self,\n                 bit_width: int,\n                 min_val: float = -1.0,\n                 max_val: float = 1.0,\n                 narrow_range: bool = False,\n                 quant_type: QuantType = QuantType.FP,\n                 float_to_int_impl_type: FloatToIntImplType = FloatToIntImplType.ROUND,\n                 scaling_impl_type: ScalingImplType = ScalingImplType.PARAMETER,\n                 scaling_override: Optional[Module] = None,\n                 scaling_per_channel: bool = False,\n                 scaling_stats_sigma: float = 3.0,\n                 scaling_stats_op: StatsOp = StatsOp.MEAN_LEARN_SIGMA_STD,\n                 scaling_stats_buffer_momentum: float = 0.1,\n                 scaling_stats_permute_dims: Tuple = (1, 0, 2, 3),\n                 per_channel_broadcastable_shape: Optional[Tuple[int, ...]] = None,\n                 min_overall_bit_width: Optional[int] = 2,\n                 max_overall_bit_width: Optional[int] = None,\n                 bit_width_impl_override: Union[BitWidthParameter] = None,\n                 bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 scaling_min_val: Optional[float] = SCALING_MIN_VAL,\n                 override_pretrained_bit_width: bool = False,\n                 return_quant_tensor: bool = False):\n        super(QuantIdentity, self).__init__(return_quant_tensor=return_quant_tensor)\n        activation_impl = Identity()\n        self.act_quant_proxy = ActivationQuantProxy(activation_impl=activation_impl,\n                                                    bit_width=bit_width,\n                                                    signed=True,\n                                                    narrow_range=narrow_range,\n                                                    scaling_override=scaling_override,\n                                                    min_val=min_val,\n                                                    max_val=max_val,\n                                                    quant_type=quant_type,\n                                                    float_to_int_impl_type=float_to_int_impl_type,\n                                                    scaling_impl_type=scaling_impl_type,\n                                                    scaling_per_channel=scaling_per_channel,\n                                                    scaling_min_val=scaling_min_val,\n                                                    per_channel_broadcastable_shape=per_channel_broadcastable_shape,\n                                                    min_overall_bit_width=min_overall_bit_width,\n                                                    max_overall_bit_width=max_overall_bit_width,\n                                                    bit_width_impl_override=bit_width_impl_override,\n                                                    bit_width_impl_type=bit_width_impl_type,\n                                                    restrict_bit_width_type=restrict_bit_width_type,\n                                                    restrict_scaling_type=restrict_scaling_type,\n                                                    override_pretrained_bit_width=override_pretrained_bit_width,\n                                                    scaling_stats_sigma=scaling_stats_sigma,\n                                                    scaling_stats_op=scaling_stats_op,\n                                                    scaling_stats_buffer_momentum=scaling_stats_buffer_momentum,\n                                                    scaling_stats_permute_dims=scaling_stats_permute_dims)\n'"
brevitas/nn/quant_avg_pool.py,2,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom typing import Optional\n\nimport math\nimport torch\nfrom torch.nn import AvgPool2d\n\nfrom brevitas.core.bit_width import BitWidthImplType\nfrom brevitas.core.quant import QuantType\nfrom brevitas.function.ops_ste import ceil_ste\nfrom brevitas.function.ops import max_uint\nfrom brevitas.nn.quant_layer import QuantLayer\nfrom brevitas.proxy.runtime_quant import TruncQuantProxy\nfrom brevitas.quant_tensor import pack_quant_tensor\n\n\nclass QuantAvgPool2d(QuantLayer, AvgPool2d):\n\n    def __init__(self,\n                 kernel_size: int,\n                 stride: int = None,\n                 signed: bool = True,\n                 min_overall_bit_width: Optional[int] = 2,\n                 max_overall_bit_width: Optional[int] = 32,\n                 quant_type: QuantType = QuantType.FP,\n                 lsb_trunc_bit_width_impl_type = BitWidthImplType.CONST):\n        QuantLayer.__init__(self,\n                            compute_output_scale=True,\n                            compute_output_bit_width=True,\n                            return_quant_tensor=True)\n        AvgPool2d.__init__(self,\n                           kernel_size=kernel_size,\n                           stride=stride)\n        ls_bit_width_to_trunc = math.ceil(math.log2(kernel_size * kernel_size))\n        self.signed = signed\n        self.quant_type = quant_type\n        explicit_rescaling = True  # we are explicitly rescaling as we are replacing the div in avg with trunc\n        self.accumulator_quant = TruncQuantProxy(signed=signed,\n                                                 quant_type=quant_type,\n                                                 trunc_at_least_init_val=True,\n                                                 ls_bit_width_to_trunc=ls_bit_width_to_trunc,\n                                                 min_overall_bit_width=min_overall_bit_width,\n                                                 max_overall_bit_width=max_overall_bit_width,\n                                                 lsb_trunc_bit_width_impl_type=lsb_trunc_bit_width_impl_type,\n                                                 explicit_rescaling=explicit_rescaling,\n                                                 override_pretrained_bit_width=False)\n\n    def forward(self, input):\n        input_tensor, input_scale, input_bit_width = self.unpack_input(input)\n        x = super(QuantAvgPool2d, self).forward(input_tensor)\n        if self.quant_type != QuantType.FP:\n            x = x * (self.kernel_size * self.kernel_size)  # remove scaling introduced by average\n            output_bit_width = self.max_output_bit_width(input_bit_width)\n            x, output_scale, output_bit_width = self.accumulator_quant(x, input_scale, output_bit_width)\n            return pack_quant_tensor(x, output_scale, output_bit_width)\n        else:\n            return pack_quant_tensor(x, input_scale, input_bit_width)\n\n    def max_output_bit_width(self, input_bit_width):\n        max_uint_input = max_uint(bit_width=input_bit_width, narrow_range=False)\n        max_uint_output = max_uint_input * self.kernel_size * self.kernel_size\n        max_output_bit_width = ceil_ste(torch.log2(max_uint_output))\n        return max_output_bit_width\n'"
brevitas/nn/quant_bn.py,3,"b""from typing import Optional\n\nimport torch\nfrom torch import nn\n\nimport brevitas.config as config\nfrom brevitas.core.quant import QuantType\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType\nfrom brevitas.core.stats import StatsOp\nfrom brevitas.nn.quant_layer import SCALING_MIN_VAL\nfrom .quant_scale_bias import QuantScaleBias\n\n\ndef mul_add_from_bn(bn_mean, bn_var, bn_eps, bn_weight, bn_bias, affine_only):\n    mul_factor = bn_weight\n    add_factor = bn_bias * torch.sqrt(bn_var + bn_eps)\n    add_factor = add_factor - bn_mean * (bn_weight - 1.0)\n    if not affine_only:\n        mul_factor = mul_factor / torch.sqrt(bn_var + bn_eps)\n        add_factor = add_factor - bn_mean\n        add_factor = add_factor / torch.sqrt(bn_var + bn_eps)\n    return mul_factor, add_factor\n\n\nclass BatchNorm2dToQuantScaleBias(QuantScaleBias):\n\n    def __init__(self,\n                 num_features,\n                 eps: float = 1e-5,\n                 bias_quant_type: QuantType = QuantType.FP,\n                 bias_narrow_range: bool = False,\n                 bias_bit_width: int = None,\n                 weight_quant_type: QuantType = QuantType.FP,\n                 weight_quant_override: nn.Module = None,\n                 weight_narrow_range: bool = False,\n                 weight_scaling_override: Optional[nn.Module] = None,\n                 weight_bit_width: int = 32,\n                 weight_scaling_impl_type: ScalingImplType = ScalingImplType.STATS,\n                 weight_scaling_const: Optional[float] = None,\n                 weight_scaling_stats_op: StatsOp = StatsOp.MAX,\n                 weight_scaling_per_output_channel: bool = False,\n                 weight_restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 weight_scaling_stats_sigma: float = 3.0,\n                 weight_scaling_min_val: float = SCALING_MIN_VAL,\n                 compute_output_scale: bool = False,\n                 compute_output_bit_width: bool = False,\n                 return_quant_tensor: bool = False):\n        super(BatchNorm2dToQuantScaleBias, self).__init__(num_features,\n                                                          bias_quant_type,\n                                                          bias_narrow_range,\n                                                          bias_bit_width,\n                                                          weight_quant_type,\n                                                          weight_quant_override,\n                                                          weight_narrow_range,\n                                                          weight_scaling_override,\n                                                          weight_bit_width,\n                                                          weight_scaling_impl_type,\n                                                          weight_scaling_const,\n                                                          weight_scaling_stats_op,\n                                                          weight_scaling_per_output_channel,\n                                                          weight_restrict_scaling_type,\n                                                          weight_scaling_stats_sigma,\n                                                          weight_scaling_min_val,\n                                                          compute_output_scale,\n                                                          compute_output_bit_width,\n                                                          return_quant_tensor)\n        self.eps = eps\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        weight_key = prefix + 'weight'\n        bias_key = prefix + 'bias'\n        running_mean_key = prefix + 'running_mean'\n        running_var_key = prefix + 'running_var'\n        num_batches_tracked_key = prefix + 'num_batches_tracked'\n\n        if running_mean_key in state_dict and running_var_key in state_dict:\n            weight_init, bias_init = mul_add_from_bn(bn_bias=state_dict[bias_key],\n                                                     bn_weight=state_dict[weight_key],\n                                                     bn_mean=state_dict[running_mean_key],\n                                                     bn_var=state_dict[running_var_key],\n                                                     bn_eps=self.eps,\n                                                     affine_only=False)\n            self.weight.data = weight_init\n            self.bias.data = bias_init\n            del state_dict[bias_key]\n            del state_dict[weight_key]\n            del state_dict[running_mean_key]\n            del state_dict[running_var_key]\n            del state_dict[num_batches_tracked_key]\n        super(BatchNorm2dToQuantScaleBias, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n                                                                       missing_keys, unexpected_keys, error_msgs)\n        if config.IGNORE_MISSING_KEYS and bias_key in missing_keys:\n            missing_keys.remove(bias_key)\n        if config.IGNORE_MISSING_KEYS and weight_key in missing_keys:\n            missing_keys.remove(weight_key)\n        if num_batches_tracked_key in unexpected_keys:\n            unexpected_keys.remove(num_batches_tracked_key)\n"""
brevitas/nn/quant_conv.py,6,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom enum import auto\nfrom typing import Union, Optional, Tuple\nimport re\n\nimport math\nimport torch\nimport docrep\nfrom torch.nn import Conv2d, Module\nfrom torch.nn import functional as F\nfrom torch.nn.functional import conv2d\nfrom torch.nn.parameter import Parameter\n\nfrom brevitas.core.bit_width import BitWidthParameter, BitWidthConst, BitWidthImplType\nfrom brevitas.core.quant import QuantType, IdentityQuant\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType, SCALING_SCALAR_SHAPE\nfrom brevitas.core.stats import StatsInputViewShapeImpl, StatsOp\nfrom brevitas.function.ops import max_uint\nfrom brevitas.function.ops_ste import ceil_ste\nfrom brevitas.proxy.parameter_quant import WeightQuantProxy, BiasQuantProxy, WeightReg\nfrom brevitas.utils.python_utils import AutoName\nfrom brevitas.nn.quant_bn import mul_add_from_bn\nfrom brevitas.nn.quant_layer import QuantLayer, SCALING_MIN_VAL\nfrom brevitas import docstrings\n\n__all__ = [\'QuantConv2d\']\n\n\nclass PaddingType(AutoName):\n    STANDARD = auto()\n    SAME = auto()\n\n\n@docstrings.dedent\nclass QuantConv2d(QuantLayer, Conv2d):\n    """"""\n\n        Parameters\n        ----------\n\n        %(weight_quant_proxy.parameters_with_prefix)s\n    """"""\n    def __init__(self,\n                 in_channels: int,\n                 out_channels: int,\n                 kernel_size: Union[int, Tuple[int, int]],\n                 stride: Union[int, Tuple[int, int]] = 1,\n                 padding: Union[int, Tuple[int, int]] = 0,\n                 padding_type: PaddingType = PaddingType.STANDARD,\n                 dilation: Union[int, Tuple[int, int]] = 1,\n                 groups: int = 1,\n                 bias: bool = True,\n                 bias_quant_type: QuantType = QuantType.FP,\n                 bias_narrow_range: bool = False,\n                 bias_bit_width: int = None,\n                 weight_quant_override: WeightQuantProxy = None,\n                 weight_quant_type: QuantType = QuantType.FP,\n                 weight_narrow_range: bool = False,\n                 weight_scaling_override: Optional[Module] = None,\n                 weight_bit_width_impl_override: Union[BitWidthParameter, BitWidthConst] = None,\n                 weight_bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 weight_restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 weight_bit_width: int = 32,\n                 weight_min_overall_bit_width: Optional[int] = 2,\n                 weight_max_overall_bit_width: Optional[int] = None,\n                 weight_scaling_impl_type: ScalingImplType = ScalingImplType.STATS,\n                 weight_scaling_const: Optional[float] = None,\n                 weight_scaling_stats_op: StatsOp = StatsOp.MAX,\n                 weight_scaling_per_output_channel: bool = False,\n                 weight_ternary_threshold: float = 0.5,\n                 weight_restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 weight_scaling_stats_sigma: float = 3.0,\n                 weight_scaling_min_val: float = SCALING_MIN_VAL,\n                 weight_override_pretrained_bit_width: bool = False,\n                 compute_output_scale: bool = False,\n                 compute_output_bit_width: bool = False,\n                 return_quant_tensor: bool = False) -> None:\n        QuantLayer.__init__(self,\n                            compute_output_scale=compute_output_scale,\n                            compute_output_bit_width=compute_output_bit_width,\n                            return_quant_tensor=return_quant_tensor)\n        Conv2d.__init__(self,\n                        in_channels=in_channels,\n                        out_channels=out_channels,\n                        kernel_size=kernel_size,\n                        stride=stride,\n                        padding=padding,\n                        dilation=dilation,\n                        groups=groups,\n                        bias=bias)\n        if weight_quant_type == QuantType.FP and compute_output_bit_width:\n            raise Exception(""Computing output bit width requires enabling quantization"")\n        if bias_quant_type != QuantType.FP and not (compute_output_scale and compute_output_bit_width):\n            raise Exception(""Quantizing bias requires to compute output scale and output bit width"")\n\n        self.per_elem_ops = 2 * self.kernel_size[0] * self.kernel_size[1] * (in_channels // groups)\n        self.padding_type = padding_type\n        self.weight_reg = WeightReg()\n\n        if weight_quant_override is not None:\n            self.weight_quant = weight_quant_override\n            self.weight_quant.add_tracked_parameter(self.weight)\n        else:\n            weight_scaling_stats_input_concat_dim = 1\n            if weight_scaling_per_output_channel:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_shape = self.per_output_channel_broadcastable_shape\n                weight_scaling_stats_reduce_dim = 1\n            else:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_TENSOR\n                weight_scaling_shape = SCALING_SCALAR_SHAPE\n                weight_scaling_stats_reduce_dim = None\n\n            if weight_scaling_stats_op == StatsOp.MAX_AVE:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_stats_reduce_dim = 1\n\n            self.weight_quant = WeightQuantProxy(bit_width=weight_bit_width,\n                                                 quant_type=weight_quant_type,\n                                                 narrow_range=weight_narrow_range,\n                                                 scaling_override=weight_scaling_override,\n                                                 restrict_scaling_type=weight_restrict_scaling_type,\n                                                 scaling_const=weight_scaling_const,\n                                                 scaling_stats_op=weight_scaling_stats_op,\n                                                 scaling_impl_type=weight_scaling_impl_type,\n                                                 scaling_stats_reduce_dim=weight_scaling_stats_reduce_dim,\n                                                 scaling_shape=weight_scaling_shape,\n                                                 bit_width_impl_type=weight_bit_width_impl_type,\n                                                 bit_width_impl_override=weight_bit_width_impl_override,\n                                                 restrict_bit_width_type=weight_restrict_bit_width_type,\n                                                 min_overall_bit_width=weight_min_overall_bit_width,\n                                                 max_overall_bit_width=weight_max_overall_bit_width,\n                                                 tracked_parameter_list_init=self.weight,\n                                                 ternary_threshold=weight_ternary_threshold,\n                                                 scaling_stats_input_view_shape_impl=weight_stats_input_view_shape_impl,\n                                                 scaling_stats_input_concat_dim=weight_scaling_stats_input_concat_dim,\n                                                 scaling_stats_sigma=weight_scaling_stats_sigma,\n                                                 scaling_min_val=weight_scaling_min_val,\n                                                 override_pretrained_bit_width=weight_override_pretrained_bit_width)\n        self.bias_quant = BiasQuantProxy(quant_type=bias_quant_type,\n                                         bit_width=bias_bit_width,\n                                         narrow_range=bias_narrow_range)\n\n    @property\n    def per_output_channel_broadcastable_shape(self):\n        if self.transposed:\n            raise Exception(""Transposed filters are not supported."")\n        else:\n            output_dim = 0\n        per_channel_size = [1] * len(self.weight.size())\n        per_channel_size[output_dim] = self.out_channels\n        per_channel_size = tuple(per_channel_size)\n        return per_channel_size\n\n    @property\n    def int_weight(self):\n        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t export int weight without quantization enabled"")\n        return self.weight_quant.int_weight(self.weight)\n\n    @property\n    def quant_weight_scale(self):\n        """"""\n\n        Returns scale factor of the quantized weights with scalar () shape or (self.out_channels, 1, 1, 1)\n        shape depending on whether scaling is per layer or per-channel.\n        -------\n\n        """"""\n        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t generate scaling factor without quantization enabled"")\n        zero_hw_sentinel = self.weight_quant.zero_hw_sentinel\n        _, scale, _ = self.weight_quant.tensor_quant(self.weight, zero_hw_sentinel)\n        return scale\n\n    def forward(self, input):\n        output_scale = None\n        output_bit_width = None\n        quant_bias_bit_width = None\n\n        input, input_scale, input_bit_width = self.unpack_input(input)\n        quant_weight, quant_weight_scale, quant_weight_bit_width = self.weight_quant(self.weight)\n        quant_weight = self.weight_reg(quant_weight)\n\n        if self.compute_output_bit_width:\n            assert input_bit_width is not None\n            output_bit_width = self.max_output_bit_width(input_bit_width, quant_weight_bit_width)\n        if self.compute_output_scale:\n            assert input_scale is not None\n            output_scale = input_scale * quant_weight_scale\n\n        if self.bias is not None:\n            quant_bias, _, quant_bias_bit_width = self.bias_quant(self.bias, output_scale, output_bit_width)\n            output = self.conv2d(input, quant_weight, quant_bias)\n        else:\n            output = self.conv2d(input, quant_weight, None)\n\n        if self.compute_output_bit_width and quant_bias_bit_width is not None:\n            output_bit_width = torch.where(quant_bias_bit_width > output_bit_width,\n                                           quant_bias_bit_width,\n                                           output_bit_width)\n            output_bit_width = output_bit_width + 1\n\n        return self.pack_output(output, output_scale, output_bit_width)\n\n    def conv2d(self, x, weight, bias):\n        if self.padding_type == PaddingType.SAME:\n            out = self.conv2d_same_padding(x, weight, bias)\n        else:\n            out = conv2d(x, weight, bias, self.stride, self.padding, self.dilation, self.groups)\n        return out\n\n    def conv2d_same_padding(self, x, weight, bias):\n        ih, iw = x.size()[-2:]\n        kh, kw = weight.size()[-2:]\n        sh, sw = self.stride\n        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n        if pad_h > 0 or pad_w > 0:\n            x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])\n        out = F.conv2d(x, weight, bias, self.stride, 0, self.dilation, self.groups)\n        return out\n\n    def merge_bn_in(self, bn, affine_only):\n        if affine_only and not bn.affine:\n            raise Exception(""Affine-only merging requires BN to have affine scaling enabled."")\n        else:\n            mul_factor, add_factor = mul_add_from_bn(bn_mean=bn.running_mean,\n                                                     bn_var=bn.running_var,\n                                                     bn_eps=bn.eps,\n                                                     bn_weight=bn.weight.data.clone(),\n                                                     bn_bias=bn.bias.data.clone(),\n                                                     affine_only=affine_only)\n            self.weight.data *= mul_factor.view(self.per_output_channel_broadcastable_shape)\n            if self.bias is not None:\n                self.bias.data += add_factor\n            else:\n                self.bias = Parameter(add_factor)\n\n    def max_output_bit_width(self, input_bit_width, weight_bit_width):\n        max_uint_input = max_uint(bit_width=input_bit_width, narrow_range=False)\n        max_kernel_val = self.weight_quant.tensor_quant.int_quant.max_uint(weight_bit_width)\n        group_size = self.out_channels // self.groups\n        max_uint_output = max_uint_input * max_kernel_val * self.kernel_size[0] * self.kernel_size[1] * group_size\n        max_output_bit_width = ceil_ste(torch.log2(max_uint_output))\n        return max_output_bit_width\n'"
brevitas/nn/quant_conv1d.py,6,"b'# Copyright (c) 2019-     Xilinx, Inc              (Giuseppe Franco)\n# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom enum import auto\nfrom typing import Union, Optional, Tuple\nimport re\n\nimport math\nimport torch\nimport docrep\nfrom torch.nn import Conv1d, Module\nfrom torch.nn import functional as F\nfrom torch.nn.functional import conv1d\nfrom torch.nn.parameter import Parameter\n\nfrom brevitas.core.bit_width import BitWidthParameter, BitWidthConst, BitWidthImplType\nfrom brevitas.core.quant import QuantType, IdentityQuant\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType, SCALING_SCALAR_SHAPE\nfrom brevitas.core.stats import StatsInputViewShapeImpl, StatsOp\nfrom brevitas.function.ops import max_uint\nfrom brevitas.function.ops_ste import ceil_ste\nfrom brevitas.proxy.parameter_quant import WeightQuantProxy, BiasQuantProxy, WeightReg\nfrom brevitas.utils.python_utils import AutoName\nfrom brevitas.nn.quant_layer import QuantLayer, SCALING_MIN_VAL\nfrom brevitas import docstrings\n__all__ = [\'QuantConv1d\']\n\n\nclass PaddingType(AutoName):\n    STANDARD = auto()\n    SAME = auto()\n\n\n@docstrings.dedent\nclass QuantConv1d(QuantLayer, Conv1d):\n    """"""\n\n        Parameters\n        ----------\n\n        %(weight_quant_proxy.parameters_with_prefix)s\n    """"""\n    def __init__(self,\n                 in_channels: int,\n                 out_channels: int,\n                 kernel_size: Union[int, Tuple[int]],\n                 stride: Union[int, Tuple[int]] = 1,\n                 padding: Union[int, Tuple[int]] = 0,\n                 padding_type: PaddingType = PaddingType.STANDARD,\n                 dilation: Union[int, Tuple[int]] = 1,\n                 groups: int = 1,\n                 bias: bool = True,\n                 bias_quant_type: QuantType = QuantType.FP,\n                 bias_narrow_range: bool = False,\n                 bias_bit_width: int = None,\n                 weight_quant_override: WeightQuantProxy = None,\n                 weight_quant_type: QuantType = QuantType.FP,\n                 weight_narrow_range: bool = False,\n                 weight_scaling_override: Optional[Module] = None,\n                 weight_bit_width_impl_override: Union[BitWidthParameter, BitWidthConst] = None,\n                 weight_bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 weight_restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 weight_bit_width: int = 32,\n                 weight_min_overall_bit_width: Optional[int] = 2,\n                 weight_max_overall_bit_width: Optional[int] = None,\n                 weight_scaling_impl_type: ScalingImplType = ScalingImplType.STATS,\n                 weight_scaling_const: Optional[float] = None,\n                 weight_scaling_stats_op: StatsOp = StatsOp.MAX,\n                 weight_scaling_per_output_channel: bool = False,\n                 weight_ternary_threshold: float = 0.5,\n                 weight_restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 weight_scaling_stats_sigma: float = 3.0,\n                 weight_scaling_min_val: float = SCALING_MIN_VAL,\n                 weight_override_pretrained_bit_width: bool = False,\n                 compute_output_scale: bool = False,\n                 compute_output_bit_width: bool = False,\n                 return_quant_tensor: bool = False) -> None:\n        QuantLayer.__init__(self,\n                            compute_output_scale=compute_output_scale,\n                            compute_output_bit_width=compute_output_bit_width,\n                            return_quant_tensor=return_quant_tensor)\n        Conv1d.__init__(self,\n                        in_channels=in_channels,\n                        out_channels=out_channels,\n                        kernel_size=kernel_size,\n                        stride=stride,\n                        padding=padding,\n                        dilation=dilation,\n                        groups=groups,\n                        bias=bias)\n        if weight_quant_type == QuantType.FP and compute_output_bit_width:\n            raise Exception(""Computing output bit width requires enabling quantization"")\n        if bias_quant_type != QuantType.FP and not (compute_output_scale and compute_output_bit_width):\n            raise Exception(""Quantizing bias requires to compute output scale and output bit width"")\n\n        self.per_elem_ops = 2 * self.kernel_size[0] * (in_channels // groups)\n        self.padding_type = padding_type\n        self.weight_reg = WeightReg()\n\n        if weight_quant_override is not None:\n            self.weight_quant = weight_quant_override\n            self.weight_quant.add_tracked_parameter(self.weight)\n        else:\n            weight_scaling_stats_input_concat_dim = 1\n            if weight_scaling_per_output_channel:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_shape = self.per_output_channel_broadcastable_shape\n                weight_scaling_stats_reduce_dim = 1\n            else:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_TENSOR\n                weight_scaling_shape = SCALING_SCALAR_SHAPE\n                weight_scaling_stats_reduce_dim = None\n\n            if weight_scaling_stats_op == StatsOp.MAX_AVE:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_stats_reduce_dim = 1\n\n            self.weight_quant = WeightQuantProxy(bit_width=weight_bit_width,\n                                                 quant_type=weight_quant_type,\n                                                 narrow_range=weight_narrow_range,\n                                                 scaling_override=weight_scaling_override,\n                                                 restrict_scaling_type=weight_restrict_scaling_type,\n                                                 scaling_const=weight_scaling_const,\n                                                 scaling_stats_op=weight_scaling_stats_op,\n                                                 scaling_impl_type=weight_scaling_impl_type,\n                                                 scaling_stats_reduce_dim=weight_scaling_stats_reduce_dim,\n                                                 scaling_shape=weight_scaling_shape,\n                                                 bit_width_impl_type=weight_bit_width_impl_type,\n                                                 bit_width_impl_override=weight_bit_width_impl_override,\n                                                 restrict_bit_width_type=weight_restrict_bit_width_type,\n                                                 min_overall_bit_width=weight_min_overall_bit_width,\n                                                 max_overall_bit_width=weight_max_overall_bit_width,\n                                                 tracked_parameter_list_init=self.weight,\n                                                 ternary_threshold=weight_ternary_threshold,\n                                                 scaling_stats_input_view_shape_impl=weight_stats_input_view_shape_impl,\n                                                 scaling_stats_input_concat_dim=weight_scaling_stats_input_concat_dim,\n                                                 scaling_stats_sigma=weight_scaling_stats_sigma,\n                                                 scaling_min_val=weight_scaling_min_val,\n                                                 override_pretrained_bit_width=weight_override_pretrained_bit_width)\n        self.bias_quant = BiasQuantProxy(quant_type=bias_quant_type,\n                                         bit_width=bias_bit_width,\n                                         narrow_range=bias_narrow_range)\n\n    @property\n    def per_output_channel_broadcastable_shape(self):\n        if self.transposed:\n            raise Exception(""Transposed filters are not supported."")\n        else:\n            output_dim = 0\n        per_channel_size = [1] * len(self.weight.size())\n        per_channel_size[output_dim] = self.out_channels\n        per_channel_size = tuple(per_channel_size)\n        return per_channel_size\n\n    @property\n    def int_weight(self):\n        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t export int weight without quantization enabled"")\n        return self.weight_quant.int_weight(self.weight)\n\n    @property\n    def quant_weight_scale(self):\n        """"""\n\n        Returns scale factor of the quantized weights with scalar () shape or (self.out_channels, 1, 1)\n        shape depending on whether scaling is per layer or per-channel.\n        -------\n\n        """"""\n        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t generate scaling factor without quantization enabled"")\n        zero_hw_sentinel = self.weight_quant.zero_hw_sentinel\n        _, scale, _ = self.weight_quant.tensor_quant(self.weight, zero_hw_sentinel)\n        return scale\n\n    def forward(self, input):\n        output_scale = None\n        output_bit_width = None\n        quant_bias_bit_width = None\n\n        input, input_scale, input_bit_width = self.unpack_input(input)\n        quant_weight, quant_weight_scale, quant_weight_bit_width = self.weight_quant(self.weight)\n        quant_weight = self.weight_reg(quant_weight)\n\n        if self.compute_output_bit_width:\n            assert input_bit_width is not None\n            output_bit_width = self.max_output_bit_width(input_bit_width, quant_weight_bit_width)\n        if self.compute_output_scale:\n            assert input_scale is not None\n            output_scale = input_scale * quant_weight_scale\n\n        if self.bias is not None:\n            quant_bias, _, quant_bias_bit_width = self.bias_quant(self.bias, output_scale, output_bit_width)\n            output = self.conv1d(input, quant_weight, quant_bias)\n        else:\n            output = self.conv1d(input, quant_weight, None)\n\n        if self.compute_output_bit_width and quant_bias_bit_width is not None:\n            output_bit_width = torch.where(quant_bias_bit_width > output_bit_width,\n                                           quant_bias_bit_width,\n                                           output_bit_width)\n            output_bit_width = output_bit_width + 1\n\n        return self.pack_output(output, output_scale, output_bit_width)\n\n    def conv1d(self, x, weight, bias):\n        if self.padding_type == PaddingType.SAME:\n            out = self.conv1d_same_padding(x, weight, bias)\n        else:\n            out = conv1d(x, weight, bias, self.stride, self.padding, self.dilation, self.groups)\n        return out\n\n    def conv1d_same_padding(self, x, weight, bias):\n        ih = x.size()[-1]\n        kh = weight.size()[-1]\n        sh = self.stride[0]\n        oh = math.ceil(ih / sh)\n        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n        if pad_h > 0:\n            x = F.pad(x, [pad_h // 2, pad_h - pad_h // 2])\n        out = F.conv1d(x, weight, bias, self.stride, 0, self.dilation, self.groups)\n        return out\n\n    def merge_bn_in(self, bn, affine_only, sign_only):\n        raise Exception(""Merged Batch-Normalization is not yet supported"")\n\n    def max_output_bit_width(self, input_bit_width, weight_bit_width):\n        max_uint_input = max_uint(bit_width=input_bit_width, narrow_range=False)\n        max_kernel_val = self.weight_quant.tensor_quant.int_quant.max_uint(weight_bit_width)\n        group_size = self.out_channels // self.groups\n        max_uint_output = max_uint_input * max_kernel_val * self.kernel_size[0] * group_size\n        max_output_bit_width = ceil_ste(torch.log2(max_uint_output))\n        return max_output_bit_width\n\n'"
brevitas/nn/quant_convtranspose1d.py,8,"b'# Copyright (c) 2019-     Xilinx, Inc              (Giuseppe Franco)\n# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom enum import auto\nfrom typing import Union, Optional, Tuple\nimport re\n\nimport math\nimport torch\nimport docrep\nfrom torch.nn import ConvTranspose1d, Module\nfrom torch.nn import functional as F\nfrom torch.nn.functional import conv_transpose1d\nfrom torch.nn.parameter import Parameter\n\nfrom brevitas.core.bit_width import BitWidthParameter, BitWidthConst, BitWidthImplType\nfrom brevitas.core.quant import QuantType, IdentityQuant\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType, SCALING_SCALAR_SHAPE\nfrom brevitas.core.stats import StatsInputViewShapeImpl, StatsOp\nfrom brevitas.function.ops import max_uint\nfrom brevitas.function.ops_ste import ceil_ste\nfrom brevitas.proxy.parameter_quant import WeightQuantProxy, BiasQuantProxy, WeightReg\nfrom brevitas.utils.python_utils import AutoName\nfrom brevitas.nn.quant_layer import QuantLayer, SCALING_MIN_VAL\nfrom brevitas import docstrings\n\n__all__ = [\'QuantConvTranspose1d\']\n\n\nclass PaddingType(AutoName):\n    STANDARD = auto()\n    SAME = auto()\n\n\n@docstrings.dedent\nclass QuantConvTranspose1d(QuantLayer, ConvTranspose1d):\n    """"""\n\n        Parameters\n        ----------\n\n        %(weight_quant_proxy.parameters_with_prefix)s\n    """"""\n\n    def __init__(self,\n                 in_channels: int,\n                 out_channels: int,\n                 kernel_size: Union[int, Tuple[int]],\n                 stride: Union[int, Tuple[int]] = 1,\n                 padding: Union[int, Tuple[int]] = 0,\n                 output_padding: Union[int, Tuple[int]] = 0,\n                 padding_type: PaddingType = PaddingType.STANDARD,\n                 dilation: Union[int, Tuple[int]] = 1,\n                 groups: int = 1,\n                 bias: bool = True,\n                 bias_quant_type: QuantType = QuantType.FP,\n                 bias_narrow_range: bool = False,\n                 bias_bit_width: int = None,\n                 weight_quant_override: WeightQuantProxy = None,\n                 weight_quant_type: QuantType = QuantType.FP,\n                 weight_narrow_range: bool = False,\n                 weight_scaling_override: Optional[Module] = None,\n                 weight_bit_width_impl_override: Union[BitWidthParameter, BitWidthConst] = None,\n                 weight_bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 weight_restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 weight_bit_width: int = 32,\n                 weight_min_overall_bit_width: Optional[int] = 2,\n                 weight_max_overall_bit_width: Optional[int] = None,\n                 weight_scaling_impl_type: ScalingImplType = ScalingImplType.STATS,\n                 weight_scaling_const: Optional[float] = None,\n                 weight_scaling_stats_op: StatsOp = StatsOp.MAX,\n                 weight_scaling_per_output_channel: bool = False,\n                 weight_ternary_threshold: float = 0.5,\n                 weight_restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 weight_scaling_stats_sigma: float = 3.0,\n                 weight_scaling_min_val: float = SCALING_MIN_VAL,\n                 weight_override_pretrained_bit_width: bool = False,\n                 compute_output_scale: bool = False,\n                 compute_output_bit_width: bool = False,\n                 return_quant_tensor: bool = False,\n                 deterministic: bool = False) -> None:\n        QuantLayer.__init__(self,\n                            compute_output_scale=compute_output_scale,\n                            compute_output_bit_width=compute_output_bit_width,\n                            return_quant_tensor=return_quant_tensor)\n        ConvTranspose1d.__init__(self,\n                                 in_channels=in_channels,\n                                 out_channels=out_channels,\n                                 kernel_size=kernel_size,\n                                 stride=stride,\n                                 padding=padding,\n                                 output_padding=output_padding,\n                                 dilation=dilation,\n                                 groups=groups,\n                                 bias=bias)\n        if weight_quant_type == QuantType.FP and compute_output_bit_width:\n            raise Exception(""Computing output bit width requires enabling quantization"")\n        if bias_quant_type != QuantType.FP and not (compute_output_scale and compute_output_bit_width):\n            raise Exception(""Quantizing bias requires to compute output scale and output bit width"")\n\n        if torch.backends.cudnn.benchmark:\n            torch.backends.cudnn.deterministic = deterministic\n\n        # self.per_elem_ops = 2 * self.kernel_size[0] * (in_channels // groups) # TO DO: Implement op_count\n        self.padding_type = padding_type\n        self.weight_reg = WeightReg()\n\n        if weight_quant_override is not None:\n            self.weight_quant = weight_quant_override\n            self.weight_quant.add_tracked_parameter(self.weight)\n        else:\n            weight_scaling_stats_input_concat_dim = 1\n            if weight_scaling_per_output_channel:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_shape = self.per_output_channel_broadcastable_shape\n                weight_scaling_stats_reduce_dim = 1\n            else:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_TENSOR\n                weight_scaling_shape = SCALING_SCALAR_SHAPE\n                weight_scaling_stats_reduce_dim = None\n\n            if weight_scaling_stats_op == StatsOp.MAX_AVE:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_stats_reduce_dim = 1\n\n            self.weight_quant = WeightQuantProxy(bit_width=weight_bit_width,\n                                                 quant_type=weight_quant_type,\n                                                 narrow_range=weight_narrow_range,\n                                                 scaling_override=weight_scaling_override,\n                                                 restrict_scaling_type=weight_restrict_scaling_type,\n                                                 scaling_const=weight_scaling_const,\n                                                 scaling_stats_op=weight_scaling_stats_op,\n                                                 scaling_impl_type=weight_scaling_impl_type,\n                                                 scaling_stats_reduce_dim=weight_scaling_stats_reduce_dim,\n                                                 scaling_shape=weight_scaling_shape,\n                                                 bit_width_impl_type=weight_bit_width_impl_type,\n                                                 bit_width_impl_override=weight_bit_width_impl_override,\n                                                 restrict_bit_width_type=weight_restrict_bit_width_type,\n                                                 min_overall_bit_width=weight_min_overall_bit_width,\n                                                 max_overall_bit_width=weight_max_overall_bit_width,\n                                                 tracked_parameter_list_init=self.weight,\n                                                 ternary_threshold=weight_ternary_threshold,\n                                                 scaling_stats_input_view_shape_impl=weight_stats_input_view_shape_impl,\n                                                 scaling_stats_input_concat_dim=weight_scaling_stats_input_concat_dim,\n                                                 scaling_stats_sigma=weight_scaling_stats_sigma,\n                                                 scaling_min_val=weight_scaling_min_val,\n                                                 override_pretrained_bit_width=weight_override_pretrained_bit_width)\n        self.bias_quant = BiasQuantProxy(quant_type=bias_quant_type,\n                                         bit_width=bias_bit_width,\n                                         narrow_range=bias_narrow_range)\n\n    @property\n    def per_output_channel_broadcastable_shape(self):\n        if self.transposed:\n            raise Exception(""Transposed filters are not supported."")\n        else:\n            output_dim = 0\n        per_channel_size = [1] * len(self.weight.size())\n        per_channel_size[output_dim] = self.out_channels\n        per_channel_size = tuple(per_channel_size)\n        return per_channel_size\n\n    @property\n    def int_weight(self):\n        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t export int weight without quantization enabled"")\n        return self.weight_quant.int_weight(self.weight)\n\n    @property\n    def quant_weight_scale(self):\n        """"""\n\n        Returns scale factor of the quantized weights with scalar () shape or (self.out_channels, 1, 1)\n        shape depending on whether scaling is per layer or per-channel.\n        -------\n\n        """"""\n        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t generate scaling factor without quantization enabled"")\n        zero_hw_sentinel = self.weight_quant.zero_hw_sentinel\n        _, scale, _ = self.weight_quant.tensor_quant(self.weight, zero_hw_sentinel)\n        return scale\n\n    def forward(self, input, output_size=None):\n        output_scale = None\n        output_bit_width = None\n        quant_bias_bit_width = None\n\n        input, input_scale, input_bit_width = self.unpack_input(input)\n        quant_weight, quant_weight_scale, quant_weight_bit_width = self.weight_quant(self.weight)\n        quant_weight = self.weight_reg(quant_weight)\n\n        if self.compute_output_bit_width:\n            assert input_bit_width is not None\n            output_bit_width = self.max_output_bit_width(input_bit_width, quant_weight_bit_width)\n        if self.compute_output_scale:\n            assert input_scale is not None\n            output_scale = input_scale * quant_weight_scale\n\n        output_padding = self.compute_output_padding(input, output_size)\n\n        if self.bias is not None:\n            quant_bias, _, quant_bias_bit_width = self.bias_quant(self.bias, output_scale, output_bit_width)\n            output = self.conv_transpose1d(input, quant_weight, quant_bias, output_padding)\n        else:\n            output = self.conv_transpose1d(input, quant_weight, None, output_padding)\n\n        if self.compute_output_bit_width and quant_bias_bit_width is not None:\n            output_bit_width = torch.where(quant_bias_bit_width > output_bit_width,\n                                           quant_bias_bit_width,\n                                           output_bit_width)\n            output_bit_width = output_bit_width + 1\n            \n        return self.pack_output(output, output_scale, output_bit_width)\n\n    def compute_output_padding(self, input, output_size):\n        return self._output_padding(input, output_size, self.stride, self.padding, self.kernel_size)\n\n    def conv_transpose1d(self, x, weight, bias, output_padding):\n        if self.padding_type == PaddingType.SAME:\n            out = self.transposeconv1d_same_padding(x, weight, bias, output_padding)\n        else:\n            out = conv_transpose1d(x, weight, bias, self.stride, self.padding, output_padding, self.groups,\n                                   self.dilation)\n        return out\n\n    def transposeconv1d_same_padding(self, x, weight, bias, output_padding):\n        raise Exception(""SAME PADDING not supported for ConvTranspose1d"")\n\n    def merge_bn_in(self, bn, affine_only, sign_only):\n        raise Exception(""Merged Batch-Normalization is not yet supported"")\n\n    def max_output_bit_width(self, input_bit_width, weight_bit_width):\n        max_uint_input = max_uint(bit_width=input_bit_width, narrow_range=False)\n        max_kernel_val = self.weight_quant.tensor_quant.int_quant.max_uint(weight_bit_width)\n        group_size = self.out_channels // self.groups\n        overlapping_sums = max(round(self.kernel_size[0] / self.stride[0]), 1)\n        max_uint_output = max_uint_input * max_kernel_val * overlapping_sums * group_size\n        max_output_bit_width = ceil_ste(torch.log2(max_uint_output))\n        return max_output_bit_width\n'"
brevitas/nn/quant_layer.py,0,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom abc import ABCMeta, abstractmethod\nfrom brevitas.quant_tensor import QuantTensor\n\n\nSCALING_MIN_VAL = 2.0 ** (-16)\n\n\nclass QuantLayer(object):\n    __metaclass__ = ABCMeta\n\n    def __init__(self, compute_output_scale, compute_output_bit_width, return_quant_tensor):\n        self.compute_output_scale = compute_output_scale\n        self.compute_output_bit_width = compute_output_bit_width\n        self.return_quant_tensor = return_quant_tensor\n\n    def unpack_input(self, input):\n        if isinstance(input, QuantTensor):\n            return input\n        else:\n            return input, None, None\n\n    def pack_output(self,\n                    output,\n                    output_scale,\n                    output_bit_width):\n        if self.return_quant_tensor:\n            return QuantTensor(tensor=output, scale=output_scale, bit_width=output_bit_width)\n        else:\n            return output\n'"
brevitas/nn/quant_linear.py,4,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom typing import Optional, Union\n\nimport math\nimport torch\nfrom torch.nn import Linear, Module\nfrom torch.nn.functional import linear\n\nfrom brevitas.core.bit_width import BitWidthParameter, BitWidthConst, BitWidthImplType\nfrom brevitas.core.quant import QuantType, IdentityQuant\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType, SCALING_SCALAR_SHAPE\nfrom brevitas.core.stats import StatsInputViewShapeImpl\nfrom brevitas.core.stats import StatsOp\nfrom brevitas.function.ops_ste import ceil_ste\nfrom brevitas.function.ops import max_uint\nfrom brevitas.proxy.parameter_quant import WeightQuantProxy, BiasQuantProxy, WeightReg\nfrom brevitas import docstrings\nfrom .quant_layer import QuantLayer, SCALING_MIN_VAL\n\n__all__ = [\'QuantLinear\']\n\n\n@docstrings.dedent\nclass QuantLinear(QuantLayer, Linear):\n    """"""\n\n        Parameters\n        ----------\n\n        %(weight_quant_proxy.parameters_with_prefix)s\n    """"""\n    def __init__(self,\n                 in_features: int,\n                 out_features: int,\n                 bias: bool,\n                 bias_quant_type: QuantType = QuantType.FP,\n                 bias_narrow_range: bool = False,\n                 bias_bit_width: int = None,\n                 weight_quant_override: WeightQuantProxy = None,\n                 weight_quant_type: QuantType = QuantType.FP,\n                 weight_narrow_range: bool = False,\n                 weight_bit_width_impl_override: Union[BitWidthParameter, BitWidthConst] = None,\n                 weight_bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n                 weight_restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n                 weight_bit_width: int = 32,\n                 weight_min_overall_bit_width: Optional[int] = 2,\n                 weight_max_overall_bit_width: Optional[int] = None,\n                 weight_scaling_override: Optional[Module] = None,\n                 weight_scaling_impl_type: ScalingImplType = ScalingImplType.STATS,\n                 weight_scaling_const: Optional[float] = None,\n                 weight_scaling_stats_op: StatsOp = StatsOp.MAX,\n                 weight_scaling_per_output_channel: bool = False,\n                 weight_scaling_min_val: float = SCALING_MIN_VAL,\n                 weight_ternary_threshold: float = 0.5,\n                 weight_restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 weight_scaling_stats_sigma: float = 3.0,\n                 weight_override_pretrained_bit_width: bool = False,\n                 compute_output_scale: bool = False,\n                 compute_output_bit_width: bool = False,\n                 return_quant_tensor: bool = False) -> None:\n        QuantLayer.__init__(self,\n                            compute_output_scale=compute_output_scale,\n                            compute_output_bit_width=compute_output_bit_width,\n                            return_quant_tensor=return_quant_tensor)\n        Linear.__init__(self,\n                        in_features=in_features,\n                        out_features=out_features,\n                        bias=bias)\n        if weight_quant_type == QuantType.FP and compute_output_bit_width:\n            raise Exception(""Computing output bit width requires enabling quantization"")\n        if bias_quant_type != QuantType.FP and not (compute_output_scale and compute_output_bit_width):\n            raise Exception(""Quantizing bias requires to compute output scale and output bit width"")\n\n        self.per_elem_ops = 2 * in_features\n        self.weight_reg = WeightReg()\n\n        if weight_quant_override is not None:\n            self.weight_quant = weight_quant_override\n            self.weight_quant.add_tracked_tensor(self.weight)\n        else:\n            weight_scaling_stats_input_concat_dim = 1\n            if weight_scaling_per_output_channel:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_shape = (self.out_features, 1)\n                weight_scaling_stats_reduce_dim = 1\n            else:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_TENSOR\n                weight_scaling_shape = SCALING_SCALAR_SHAPE\n                weight_scaling_stats_reduce_dim = None\n\n            if weight_scaling_stats_op == StatsOp.MAX_AVE:\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_stats_reduce_dim = 1\n\n            self.weight_quant = WeightQuantProxy(bit_width=weight_bit_width,\n                                                 quant_type=weight_quant_type,\n                                                 narrow_range=weight_narrow_range,\n                                                 scaling_override=weight_scaling_override,\n                                                 restrict_scaling_type=weight_restrict_scaling_type,\n                                                 scaling_const=weight_scaling_const,\n                                                 scaling_stats_op=weight_scaling_stats_op,\n                                                 scaling_impl_type=weight_scaling_impl_type,\n                                                 scaling_stats_reduce_dim=weight_scaling_stats_reduce_dim,\n                                                 scaling_shape=weight_scaling_shape,\n                                                 bit_width_impl_type=weight_bit_width_impl_type,\n                                                 bit_width_impl_override=weight_bit_width_impl_override,\n                                                 restrict_bit_width_type=weight_restrict_bit_width_type,\n                                                 min_overall_bit_width=weight_min_overall_bit_width,\n                                                 max_overall_bit_width=weight_max_overall_bit_width,\n                                                 tracked_parameter_list_init=self.weight,\n                                                 ternary_threshold=weight_ternary_threshold,\n                                                 scaling_stats_input_view_shape_impl=weight_stats_input_view_shape_impl,\n                                                 scaling_stats_input_concat_dim=weight_scaling_stats_input_concat_dim,\n                                                 scaling_stats_sigma=weight_scaling_stats_sigma,\n                                                 scaling_min_val=weight_scaling_min_val,\n                                                 override_pretrained_bit_width=weight_override_pretrained_bit_width)\n        self.bias_quant = BiasQuantProxy(quant_type=bias_quant_type,\n                                         narrow_range=bias_narrow_range,\n                                         bit_width=bias_bit_width)\n\n    @property\n    def int_weight(self):\n        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t generate int weight without quantization enabled"")\n        return self.weight_quant.int_weight(self.weight)\n\n    @property\n    def quant_weight_scale(self):\n        """"""\n\n        Returns scale factor of the quantized weights with scalar () shape or (self.out_channels, 1)\n        shape depending on whether scaling is per layer or per-channel.\n        -------\n\n        """"""\n        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n            raise Exception(""Can\'t generate scaling factor without quantization enabled"")\n        zero_hw_sentinel = self.weight_quant.zero_hw_sentinel\n        _, scale, _ = self.weight_quant.tensor_quant(self.weight, zero_hw_sentinel)\n        return scale\n\n    def forward(self, input):\n        output_scale = None\n        output_bit_width = None\n        bias_bit_width = None\n\n        input, input_scale, input_bit_width = self.unpack_input(input)\n\n        quant_weight, quant_weight_scale, quant_weight_bit_width = self.weight_quant(self.weight)\n        quant_weight = self.weight_reg(quant_weight)\n\n        if self.compute_output_bit_width:\n            assert input_bit_width is not None\n            output_bit_width = self.max_output_bit_width(input_bit_width, quant_weight_bit_width)\n        if self.compute_output_scale:\n            assert input_scale is not None\n            output_scale = input_scale * quant_weight_scale\n\n        if self.bias is not None:\n            quant_bias, _, bias_bit_width = self.bias_quant(self.bias, output_scale, output_bit_width)\n            output = linear(input, quant_weight, quant_bias)\n        else:\n            output = linear(input, quant_weight, None)\n\n        if self.compute_output_bit_width and bias_bit_width is not None:\n            output_bit_width = torch.where(bias_bit_width > output_bit_width, bias_bit_width, output_bit_width)\n            output_bit_width = output_bit_width + 1\n        return self.pack_output(output, output_scale, output_bit_width)\n\n    def max_output_bit_width(self, input_bit_width, weight_bit_width):\n        max_input_val = max_uint(bit_width=input_bit_width, narrow_range=False)\n        max_fc_val = self.weight_quant.tensor_quant.int_quant.max_uint(weight_bit_width)\n        max_output_val = max_input_val * max_fc_val * self.in_features\n        output_bit_width = ceil_ste(torch.log2(max_output_val))\n        return output_bit_width\n\n\n\n'"
brevitas/nn/quant_scale_bias.py,4,"b'from typing import Optional\n\nimport torch\nimport torch.nn as nn\n\nfrom brevitas.core.bit_width import BitWidthImplType\nfrom brevitas.core.quant import QuantType\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType, SCALING_SCALAR_SHAPE\nfrom brevitas.core.stats import StatsInputViewShapeImpl, StatsOp\nfrom brevitas.nn.quant_layer import SCALING_MIN_VAL\nfrom brevitas.proxy.parameter_quant import WeightQuantProxy, BiasQuantProxy\nfrom brevitas.proxy.runtime_quant import OVER_BATCH_OVER_CHANNELS_4D_SHAPE\nfrom .quant_layer import QuantLayer\n\n__all__ = [\'ScaleBias\', \'QuantScaleBias\']\n\n\nclass ScaleBias(nn.Module):\n\n    def __init__(self, num_features):\n        super(ScaleBias, self).__init__()\n        self.weight = nn.Parameter(torch.ones(num_features))\n        self.bias = nn.Parameter(torch.zeros(num_features))\n\n    def forward(self, x):\n        return x * self.weight + self.bias\n\n\nclass QuantScaleBias(QuantLayer, ScaleBias):\n\n    def __init__(self,\n                 num_features,\n                 bias_quant_type: QuantType = QuantType.FP,\n                 bias_narrow_range: bool = False,\n                 bias_bit_width: int = None,\n                 weight_quant_type: QuantType = QuantType.FP,\n                 weight_quant_override: nn.Module = None,\n                 weight_narrow_range: bool = False,\n                 weight_scaling_override: Optional[nn.Module] = None,\n                 weight_bit_width: int = 32,\n                 weight_scaling_impl_type: ScalingImplType = ScalingImplType.STATS,\n                 weight_scaling_const: Optional[float] = None,\n                 weight_scaling_stats_op: StatsOp = StatsOp.MAX,\n                 weight_scaling_per_output_channel: bool = False,\n                 weight_restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n                 weight_scaling_stats_sigma: float = 3.0,\n                 weight_scaling_min_val: float = SCALING_MIN_VAL,\n                 compute_output_scale: bool = False,\n                 compute_output_bit_width: bool = False,\n                 return_quant_tensor: bool = False):\n        QuantLayer.__init__(self,\n                            compute_output_scale=compute_output_scale,\n                            compute_output_bit_width=compute_output_bit_width,\n                            return_quant_tensor=return_quant_tensor)\n        ScaleBias.__init__(self, num_features)\n\n        if bias_quant_type != QuantType.FP and not self.compute_output_scale:\n            raise Exception(""Quantizing bias requires to compute output scale"")\n        if bias_quant_type != QuantType.FP and bias_bit_width is None and not self.compute_output_bit_width:\n            raise Exception(""Quantizing bias requires a bit-width, either computed or defined"")\n\n        if weight_quant_override is not None:\n            self.weight_quant = weight_quant_override\n            self.weight_quant.add_tracked_parameter(self.weight)\n        else:\n            weight_scaling_stats_input_concat_dim = 1\n            if weight_scaling_stats_op == StatsOp.MAX_AVE:\n                assert not weight_scaling_per_output_channel\n                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                weight_scaling_shape = SCALING_SCALAR_SHAPE\n                weight_scaling_stats_reduce_dim = None\n            else:\n                if weight_scaling_per_output_channel:\n                    weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                    weight_scaling_shape = (num_features, 1)\n                    weight_scaling_stats_reduce_dim = 1\n                else:\n                    weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_TENSOR\n                    weight_scaling_shape = SCALING_SCALAR_SHAPE\n                    weight_scaling_stats_reduce_dim = None\n\n            self.weight_quant = WeightQuantProxy(bit_width=weight_bit_width,\n                                                 quant_type=weight_quant_type,\n                                                 narrow_range=weight_narrow_range,\n                                                 scaling_override=weight_scaling_override,\n                                                 restrict_scaling_type=weight_restrict_scaling_type,\n                                                 scaling_const=weight_scaling_const,\n                                                 scaling_stats_op=weight_scaling_stats_op,\n                                                 scaling_impl_type=weight_scaling_impl_type,\n                                                 scaling_stats_reduce_dim=weight_scaling_stats_reduce_dim,\n                                                 scaling_shape=weight_scaling_shape,\n                                                 bit_width_impl_type=BitWidthImplType.CONST,\n                                                 bit_width_impl_override=None,\n                                                 restrict_bit_width_type=RestrictValueType.INT,\n                                                 min_overall_bit_width=None,\n                                                 max_overall_bit_width=None,\n                                                 tracked_parameter_list_init=self.weight,\n                                                 ternary_threshold=None,\n                                                 scaling_stats_input_view_shape_impl=weight_stats_input_view_shape_impl,\n                                                 scaling_stats_input_concat_dim=weight_scaling_stats_input_concat_dim,\n                                                 scaling_stats_sigma=weight_scaling_stats_sigma,\n                                                 scaling_min_val=weight_scaling_min_val,\n                                                 override_pretrained_bit_width=None)\n        self.bias_quant = BiasQuantProxy(quant_type=bias_quant_type,\n                                         narrow_range=bias_narrow_range,\n                                         bit_width=bias_bit_width)\n\n    def forward(self, quant_tensor):\n        output_scale = None\n        output_bit_width = None\n\n        input_tensor, input_scale, input_bit_width = self.unpack_input(quant_tensor)\n        quant_weight, quant_weight_scale, quant_weight_bit_width = self.weight_quant(self.weight.view(-1, 1))\n\n        if self.compute_output_bit_width:\n            assert input_bit_width is not None\n            output_bit_width = input_bit_width + quant_weight_bit_width\n        if self.compute_output_scale:\n            assert input_scale is not None\n            output_scale = input_scale * quant_weight_scale\n\n        # if bias_bit_width is not None, input_bit_width is ignored\n        quant_bias, _, quant_bias_bit_width = self.bias_quant(self.bias, output_scale, input_bit_width)\n\n        quant_weight = quant_weight.view(OVER_BATCH_OVER_CHANNELS_4D_SHAPE)\n        quant_bias = quant_bias.view(OVER_BATCH_OVER_CHANNELS_4D_SHAPE)\n        output = input_tensor * quant_weight + quant_bias\n\n        if self.compute_output_bit_width and quant_bias_bit_width is not None:\n            output_bit_width = torch.where(quant_bias_bit_width > output_bit_width,\n                                           quant_bias_bit_width,\n                                           output_bit_width)\n\n        return self.pack_output(output, output_scale, output_bit_width)\n\n\n\n\n'"
brevitas/proxy/__init__.py,0,"b'import re\n\nfrom .parameter_quant import *\nfrom .runtime_quant import *\n\nfrom brevitas import docstrings\n\n#\n# Docs post processing\n#\n\nwo_prefix = \'weight_quant_proxy.parameters\'\nw_prefix = \'weight_quant_proxy.parameters_with_prefix\'\ndocstrings.params[w_prefix] =  docstrings.params[wo_prefix]\ndocstrings.params[w_prefix] = re.compile(r\'\\nscaling_stats_reduce_dim\\n(.*\\n.*\\n.*\\n)\').sub(r""\\n"", docstrings.params[w_prefix])\ndocstrings.params[w_prefix] = re.compile(r\'\\nscaling_shape\\n(.*\\n)\').sub(r""\\n"", docstrings.params[w_prefix])\ndocstrings.params[w_prefix] = re.compile(r\'\\nscaling_stats_input_view_shape_impl\\n(.*\\n.*\\n)\').sub(r""\\n"", docstrings.params[w_prefix])\ndocstrings.params[w_prefix] = re.compile(r\'\\nscaling_stats_input_concat_dim\\n(.*\\n.*\\n.*\\n)\').sub(r""\\n"", docstrings.params[w_prefix])\ndocstrings.params[w_prefix] = re.compile(r\'\\ntracked_parameter_list_init\\n(.*\\n.*\\n.*\\n)\').sub(r""\\n"", docstrings.params[w_prefix])\ndocstrings.params[w_prefix] = re.compile(r\'(\\n)([a-z_]+)(\\n)\').sub(r""\\1weight_\\2\\3"", docstrings.params[w_prefix])\ndocstrings.params[w_prefix] = re.compile(r\'(`)([a-z_]+)(`)\').sub(r""\\1weight_\\2\\3"", docstrings.params[w_prefix])\n\n'"
brevitas/proxy/parameter_quant.py,8,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom abc import ABCMeta\nfrom functools import partial\nfrom typing import Tuple, Optional, Union, List\nimport re\n\nimport math\nimport torch\nfrom torch import nn, Tensor\n\n\nfrom brevitas.core import ZERO_HW_SENTINEL_NAME\nfrom brevitas.core.bit_width import BitWidthConst, BitWidthParameter, BitWidthImplType, IdentityBitWidth\nfrom brevitas.core.function_wrapper import TensorClampSte, TensorClamp\nfrom brevitas.core.quant import IdentityQuant\nfrom brevitas.core.quant import QuantType, BinaryQuant, TernaryQuant, RescalingIntQuant\nfrom brevitas.core.quant import PrescaledRestrictIntQuant, PrescaledRestrictIntQuantWithInputBitWidth\nfrom brevitas.core.restrict_val import RestrictValueType, FloatToIntImplType, RestrictValue\nfrom brevitas.core.scaling import ScalingImplType, ParameterStatsScaling, StatsInputViewShapeImpl, IntScaling\nfrom brevitas.core.scaling import StandaloneScaling, SCALING_SCALAR_SHAPE\nfrom brevitas.function.ops_ste import round_ste\nfrom brevitas.core.stats import StatsOp\nfrom brevitas import config\nfrom brevitas import docstrings\nfrom brevitas.proxy.runtime_quant import OVER_BATCH_OVER_CHANNELS_4D_SHAPE\n\nfrom .quant_proxy import QuantProxy\n\n__all__ = [\'WeightQuantProxy\', \'BiasQuantProxy\']\n\n\n\n\nclass WeightReg(nn.Module):\n\n    def __init__(self):\n        super(WeightReg, self).__init__()\n        pass\n\n    def forward(self, weight):\n        return weight + 0\n\n\nclass ParameterQuantProxy(QuantProxy):\n    __metaclass__ = ABCMeta\n\n    @property\n    def tensor_quant(self):\n        return self._tensor_quant\n\n    @tensor_quant.setter\n    def tensor_quant(self, tensor_quant):\n        self._tensor_quant = tensor_quant\n\n    @tensor_quant.deleter\n    def tensor_quant(self):\n        del self._tensor_quant\n\n\ndef _weight_quant_init_impl(bit_width: Optional[int],\n                            quant_type: QuantType,\n                            narrow_range: bool,\n                            scaling_override: Optional[nn.Module],\n                            restrict_scaling_type: RestrictValueType,\n                            scaling_const: float,\n                            scaling_stats_op: StatsOp,\n                            scaling_impl_type: ScalingImplType,\n                            scaling_stats_reduce_dim: Optional[int],\n                            scaling_shape: Tuple[int, ...],\n                            scaling_min_val: Optional[float],\n                            bit_width_impl_type: Optional[BitWidthImplType],\n                            restrict_bit_width_type: Optional[RestrictValueType],\n                            min_overall_bit_width: Optional[int],\n                            max_overall_bit_width: Optional[int],\n                            bit_width_impl_override: Optional[Union[BitWidthConst, BitWidthParameter]],\n                            scaling_stats_input_view_shape_impl: StatsInputViewShapeImpl,\n                            scaling_stats_input_concat_dim: int,\n                            ternary_threshold: Optional[float],\n                            scaling_stats_sigma: Optional[float],\n                            tracked_parameter_list: List[torch.nn.Parameter],\n                            zero_hw_sentinel: torch.Tensor,\n                            override_pretrained_bit_width: bool):\n\n    if quant_type == QuantType.FP:\n        tensor_quant = IdentityQuant()\n    else:\n        if scaling_impl_type != ScalingImplType.OVERRIDE and scaling_override is not None:\n            raise Exception(""Overriding scaling requires to set ScalingImplType to OVERRIDE explicitly."")\n        if scaling_impl_type == ScalingImplType.OVERRIDE and scaling_override is None:\n            raise Exception(""Overriding scaling requires to pass a scaling impl module."")\n\n        if scaling_impl_type == ScalingImplType.OVERRIDE and scaling_override is not None:\n            scaling_impl = scaling_override\n\n        elif scaling_impl_type == ScalingImplType.STATS \\\n                or scaling_impl_type == ScalingImplType.AFFINE_STATS \\\n                or scaling_impl_type == ScalingImplType.PARAMETER_FROM_STATS:\n            stats_scaling = ParameterStatsScaling(stats_op=scaling_stats_op,\n                                                  restrict_scaling_type=restrict_scaling_type,\n                                                  tracked_parameter_list=tracked_parameter_list,\n                                                  stats_input_view_shape_impl=scaling_stats_input_view_shape_impl,\n                                                  stats_input_concat_dim=scaling_stats_input_concat_dim,\n                                                  sigma=scaling_stats_sigma,\n                                                  scaling_min_val=scaling_min_val,\n                                                  stats_reduce_dim=scaling_stats_reduce_dim,\n                                                  stats_output_shape=scaling_shape,\n                                                  affine=scaling_impl_type == ScalingImplType.AFFINE_STATS)\n            if scaling_impl_type == ScalingImplType.PARAMETER_FROM_STATS:\n                if quant_type == QuantType.BINARY or quant_type == QuantType.TERNARY:\n                    raise Exception(""Parameter from stats scaling is currently not supported for binary/ternary"")\n                scaling_init = stats_scaling(zero_hw_sentinel).detach()\n                scaling_impl = StandaloneScaling(scaling_init=scaling_init,\n                                                 parameter_shape=scaling_shape,\n                                                 restrict_scaling_type=restrict_scaling_type,\n                                                 is_parameter=True,\n                                                 scaling_min_val=scaling_min_val)\n            else:\n                scaling_impl = stats_scaling\n\n        elif scaling_impl_type == ScalingImplType.CONST or scaling_impl_type == ScalingImplType.HE:\n            if scaling_impl_type == ScalingImplType.HE:\n                scaling_const = 0.0\n                for param in tracked_parameter_list:  # takes average of He scaling over parameter list\n                    two_dim_param = param.view(param.shape[0], -1)\n                    scaling_const += math.sqrt(2.0 / two_dim_param.shape[1])\n                scaling_const /= len(tracked_parameter_list)\n            scaling_init = torch.tensor(scaling_const)\n            scaling_impl = StandaloneScaling(scaling_init=scaling_init,\n                                             parameter_shape=SCALING_SCALAR_SHAPE,\n                                             restrict_scaling_type=restrict_scaling_type,\n                                             is_parameter=False,\n                                             scaling_min_val=None)\n        else:\n            raise Exception(""Scaling type {} not supported for weight quantization""\n                            .format(str(scaling_impl_type)))\n\n        if bit_width == 1 and quant_type == QuantType.BINARY:\n            tensor_quant = BinaryQuant(scaling_impl=scaling_impl)\n\n        elif bit_width == 2 and quant_type == QuantType.TERNARY:\n            tensor_quant = TernaryQuant(scaling_impl=scaling_impl, threshold=ternary_threshold)\n\n        elif bit_width >= 2 and quant_type == QuantType.INT:\n            if bit_width_impl_override is None:\n                if (bit_width_impl_type is None\n                        or bit_width is None\n                        or restrict_bit_width_type is None):\n                    raise Exception(""Bit width is not defined properly"")\n\n                if bit_width_impl_type == BitWidthImplType.CONST:\n                    bit_width_impl = BitWidthConst(bit_width, restrict_bit_width_type)\n                elif bit_width_impl_type == BitWidthImplType.PARAMETER:\n                    bit_width_impl = BitWidthParameter(bit_width_init=bit_width,\n                                                       restrict_bit_width_type=restrict_bit_width_type,\n                                                       min_overall_bit_width=min_overall_bit_width,\n                                                       max_overall_bit_width=max_overall_bit_width,\n                                                       override_pretrained=override_pretrained_bit_width)\n                else:\n                    raise Exception(""Bit width type {} not supported for weight quantization.""\n                                    .format(str(bit_width_impl_type)))\n            else:\n                bit_width_impl = bit_width_impl_override\n\n            if bit_width_impl_type == BitWidthImplType.PARAMETER or \\\n                    bit_width_impl_type == BitWidthImplType.CONST and \\\n                    scaling_impl_type == ScalingImplType.PARAMETER_FROM_STATS:\n                tensor_clamp_impl = TensorClamp()\n            else:\n                tensor_clamp_impl = TensorClampSte()\n\n            float_to_int_impl = RestrictValue(restrict_value_type=RestrictValueType.INT,\n                                              float_to_int_impl_type=FloatToIntImplType.ROUND,\n                                              min_val=None)\n            int_scaling_impl = IntScaling(narrow_range,\n                                          signed=True,\n                                          restrict_scaling_type=restrict_scaling_type)\n            tensor_quant = RescalingIntQuant(narrow_range=narrow_range,\n                                             signed=True,\n                                             scaling_impl=scaling_impl,\n                                             int_scaling_impl=int_scaling_impl,\n                                             tensor_clamp_impl=tensor_clamp_impl,\n                                             msb_clamp_bit_width_impl=bit_width_impl,\n                                             float_to_int_impl=float_to_int_impl,\n                                             runtime=False)\n        else:\n            raise Exception(\'Unsupported weight quantization: {} bit width, {} quantization.\'\n                            .format(bit_width, str(quant_type)))\n    return tensor_quant\n\n\n@docstrings.get_sectionsf(\'weight_quant_proxy\')\nclass WeightQuantProxy(ParameterQuantProxy):\n    """"""\n\n    Parameters\n    ----------\n\n    bit_width\n        The bit-width at which weights are quantized to. If `bit_width_impl_type` is set to ``PARAMETER``, this value is\n        used for initialization. If `quant_type` is set to ``FP``, this value is ignored.\n    quant_type\n        Type of quantization. If set to ``FP``, no quantization is performed.\n    narrow_range\n        Restrict range of quantized values to a symmetrical interval around 0. For example, given `bit_width` set to\n        8 and quant_type set to ``INT``, if `narrow_range` is set to ``True``, the range of quantized values is in\n        ``[-127, 127]``; If set to ``False``, it\'s in ``[-128,127]``.\n    restrict_scaling_type\n        Type of restriction imposed on the values of the scaling factor of the quantized weights.\n    scaling_const\n        If `scaling_impl_type` is set to ``CONST``, this value is used as the scaling factor across all relevant\n        dimensions. Ignored otherwise.\n    scaling_stats_op\n        Type of statistical operation performed for scaling, if required. If `scaling_impl_type` is set to ``STATS`` or\n        ``AFFINE_STATS``, the operation is part of the compute graph and back-propagated through. If `scaling_impl_type`\n        is set to ``PARAMETER_FROM_STATS``, the operation is used only for computing the initialization of the\n        parameter, possibly across some dimensions. Ignored otherwise.\n    scaling_impl_type\n        Type of strategy adopted for scaling the quantized weights.\n    scaling_stats_reduce_dim\n        Dimension within the shape determined by `scaling_stats_input_view_shape_impl` along which `scaling_stats_op` is\n        applied. If set to ``None``, scaling is assumed to be over the whole tensor. Ignored whenever `scaling_stats_op`\n        is ignored.\n    scaling_shape\n        Shape of the scaling factor tensor. This is required to be broadcastable w.r.t. the weight tensor to scale.\n    scaling_min_val\n        Minimum value that the scaling factors can reach. This has precedence over anything else, including\n        `scaling_const` when `scaling_impl_type` is set to ``CONST``. Useful in case of numerical instabilities.\n        If set to None, no minimum is imposed.\n    bit_width_impl_type\n        Type of strategy adopted for precision at which the weights are quantized to when `quant_type` is set to\n        ``INT``. Ignored otherwise.\n    restrict_bit_width_type\n        If `bit_width_impl_type` is set to ``PARAMETER`` and `quant_type` is set to ``INT``, this value constraints or\n        relax the bit-width value that can be learned. Ignored otherwise.\n    min_overall_bit_width\n        If `bit_width_impl_type` is set to ``PARAMETER`` and `quant_type` is set to ``INT``, this value imposes a lower\n        bound on the learned value. Ignored otherwise.\n    max_overall_bit_width\n        If `bit_width_impl_type` is set to ``PARAMETER`` and `quant_type` is set to ``INT``, this value imposes an upper\n        bound on the learned value. Ignored otherwise.\n    tracked_parameter_list_init\n        Pytorch Parameter of which statistics are computed when `scaling_impl_type` is set to ``STATS``,\n        ``AFFINE_STATS`` or ``PARAMETER_FROM_STATS``. This value initializes the list of parameters that are\n        concatenated together when computing statistics.\n    bit_width_impl_override\n        Override the bit-width implementation with an implementation defined elsewhere. Accepts BitWidthConst or\n        BitWidthParameter type of Modules. Useful for sharing the same learned bit-width between different layers.\n    scaling_stats_input_view_shape_impl\n        When `scaling_impl_type` is set to ``STATS``, ``AFFINE_STATS`` or ``PARAMETER_FROM_STATS``,\n        this Module reshapes each tracked parameter before concatenating them together and computing their statistics.\n    scaling_stats_input_concat_dim\n        When `scaling_impl_type` is set to ``STATS``, ``AFFINE_STATS`` or ``PARAMETER_FROM_STATS``,\n        this value defines the dimension along which the tracked parameters are concated after\n        `scaling_stats_input_view_shape_impl` is called, but before statistics are taken.\n    ternary_threshold\n        Value to be used as a threshold when `quant_type` is set to ``TERNARY``. Ignored otherwise.\n    scaling_stats_sigma\n        Value to be used as sigma if `scaling_impl_type` is set to ``STATS``, ``AFFINE_STATS`` or\n        ``PARAMETER_FROM_STATS`` and `scaling_stats_op` is set to ``AVE_SIGMA_STD`` or ``AVE_LEARN_SIGMA_STD``.\n        Ignored otherwise. When `scaling_impl_type` is set to ``STATS`` or ``AFFINE_STATS``, and\n        `scaling_stats_op` is set to ``AVE_LEARN_SIGMA_STD``, the value is used for initialization.\n    override_pretrained_bit_width\n        If set to ``True``, when loading a pre-trained model that includes a learned bit-width, the pre-trained value\n        is ignored and replaced by the value specified by ``bit-width``.\n    """"""\n\n    def __init__(self,\n                 bit_width: Optional[int],\n                 quant_type: QuantType,\n                 narrow_range: bool,\n                 scaling_override: Optional[nn.Module],\n                 restrict_scaling_type: RestrictValueType,\n                 scaling_const: Optional[float],\n                 scaling_stats_op: StatsOp,\n                 scaling_impl_type: ScalingImplType,\n                 scaling_stats_reduce_dim: Optional[int],\n                 scaling_shape: Tuple[int, ...],\n                 scaling_min_val: Optional[float],\n                 bit_width_impl_type: Optional[BitWidthImplType],\n                 restrict_bit_width_type: Optional[RestrictValueType],\n                 min_overall_bit_width: Optional[int],\n                 max_overall_bit_width: Optional[int],\n                 tracked_parameter_list_init: torch.nn.Parameter,\n                 bit_width_impl_override: Optional[Union[BitWidthConst, BitWidthParameter]],\n                 scaling_stats_input_view_shape_impl: nn.Module,\n                 scaling_stats_input_concat_dim: int,\n                 ternary_threshold: Optional[float],\n                 scaling_stats_sigma: Optional[float],\n                 override_pretrained_bit_width: bool) -> None:\n\n        super(WeightQuantProxy, self).__init__()\n        zero_hw_sentinel = getattr(self, ZERO_HW_SENTINEL_NAME)\n        self.lazy_tensor_quant_init = partial(_weight_quant_init_impl,\n                                              bit_width=bit_width,\n                                              quant_type=quant_type,\n                                              narrow_range=narrow_range,\n                                              scaling_override=scaling_override,\n                                              restrict_scaling_type=restrict_scaling_type,\n                                              scaling_const=scaling_const,\n                                              scaling_stats_op=scaling_stats_op,\n                                              scaling_impl_type=scaling_impl_type,\n                                              scaling_stats_reduce_dim=scaling_stats_reduce_dim,\n                                              scaling_shape=scaling_shape,\n                                              scaling_min_val=scaling_min_val,\n                                              bit_width_impl_type=bit_width_impl_type,\n                                              restrict_bit_width_type=restrict_bit_width_type,\n                                              min_overall_bit_width=min_overall_bit_width,\n                                              max_overall_bit_width=max_overall_bit_width,\n                                              bit_width_impl_override=bit_width_impl_override,\n                                              scaling_stats_input_view_shape_impl=scaling_stats_input_view_shape_impl,\n                                              scaling_stats_input_concat_dim=scaling_stats_input_concat_dim,\n                                              ternary_threshold=ternary_threshold,\n                                              scaling_stats_sigma=scaling_stats_sigma,\n                                              zero_hw_sentinel=zero_hw_sentinel,\n                                              override_pretrained_bit_width=override_pretrained_bit_width)\n        self._tracked_parameter_list = [tracked_parameter_list_init]\n        self.scale_output_shape = OVER_BATCH_OVER_CHANNELS_4D_SHAPE\n        self.re_init_tensor_quant()\n\n    def re_init_tensor_quant(self):\n        self.tensor_quant = self.lazy_tensor_quant_init(tracked_parameter_list=self._tracked_parameter_list)\n\n    def add_tracked_parameter(self, x: torch.nn.Parameter) -> None:\n        self._tracked_parameter_list.append(x)\n        if not isinstance(self.tensor_quant, IdentityQuant):\n            del self.tensor_quant\n            self.re_init_tensor_quant()\n\n    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n        zero_hw_sentinel = getattr(self, ZERO_HW_SENTINEL_NAME)\n        out, scale, bit_width = self.tensor_quant(x, zero_hw_sentinel)\n        reshaped_scale = scale.view(self.scale_output_shape)\n        return out, reshaped_scale, bit_width\n\n    def int_weight(self, x: torch.Tensor):\n        zero_hw_sentinel = getattr(self, ZERO_HW_SENTINEL_NAME)\n        quant_weight, scale, _ = self.tensor_quant(x, zero_hw_sentinel)\n        quant_weight = quant_weight / scale\n        quant_weight = round_ste(quant_weight)\n        quant_weight = quant_weight.int()\n        return quant_weight\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        super(WeightQuantProxy, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        if config.REINIT_WEIGHT_QUANT_ON_LOAD:\n            self.re_init_tensor_quant()\n\n\nclass BiasQuantProxy(ParameterQuantProxy):\n\n    def __init__(self,\n                 quant_type: QuantType,\n                 bit_width: Optional[int],\n                 narrow_range: bool) -> None:\n        super(BiasQuantProxy, self).__init__()\n        self.scale_output_shape = OVER_BATCH_OVER_CHANNELS_4D_SHAPE\n\n        if quant_type == QuantType.FP:\n            self.tensor_quant = None\n        elif quant_type == QuantType.INT:\n            tensor_clamp_impl = TensorClamp()\n            float_to_int_impl = RestrictValue(restrict_value_type=RestrictValueType.INT,\n                                              float_to_int_impl_type=FloatToIntImplType.ROUND,\n                                              min_val=None)\n            if bit_width is not None:\n                bit_width_impl = BitWidthConst(bit_width, restrict_bit_width_type=RestrictValueType.INT)\n                self.tensor_quant = PrescaledRestrictIntQuant(narrow_range=narrow_range,\n                                                              signed=True,\n                                                              tensor_clamp_impl=tensor_clamp_impl,\n                                                              msb_clamp_bit_width_impl=bit_width_impl,\n                                                              float_to_int_impl=float_to_int_impl)\n                self.requires_input_bit_width = False\n            else:\n                msb_clamp_bit_width_impl = IdentityBitWidth()\n                self.tensor_quant = PrescaledRestrictIntQuantWithInputBitWidth(narrow_range=narrow_range,\n                                                                               signed=True,\n                                                                               tensor_clamp_impl=tensor_clamp_impl,\n                                                                               msb_clamp_bit_width_impl=msb_clamp_bit_width_impl,\n                                                                               float_to_int_impl=float_to_int_impl)\n                self.requires_input_bit_width = True\n        else:\n            raise Exception(\'Quantization type {} not supported for bias quant.\'\n                            .format(str(quant_type)))\n\n    def forward(self,\n                x: Tensor,\n                input_scale: Tensor,\n                input_bit_width: Optional[Tensor]) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor]]:\n        zero_hw_sentinel = getattr(self, ZERO_HW_SENTINEL_NAME)\n        if self.tensor_quant is not None:\n\n            if input_scale is None:\n                raise Exception(""Input scale can\'t be None when quantizing bias"")\n            input_scale = input_scale.view(-1)\n\n            if self.requires_input_bit_width:  # bit width is defined outside\n                if input_bit_width is None:\n                    raise Exception(""Input bit width can\'t be None when quantizing bias without a predefined bit width"")\n                out, output_scale, bias_bit_width = self.tensor_quant(x, input_scale, input_bit_width, zero_hw_sentinel)\n            else:\n                out, output_scale, bias_bit_width = self.tensor_quant(x, input_scale, zero_hw_sentinel)\n            output_scale = output_scale.view(self.scale_output_shape)\n            return out, output_scale, bias_bit_width\n        else:\n            return x, input_scale, input_bit_width\n\n\n'"
brevitas/proxy/quant_proxy.py,1,"b""from abc import ABCMeta\n\nimport torch\nfrom torch import nn\n\nfrom brevitas.core import ZERO_HW_SENTINEL_NAME, ZERO_HW_SENTINEL_VALUE\n\n\nclass QuantProxy(nn.Module):\n    __metaclass__ = ABCMeta\n\n    def __init__(self):\n        super(QuantProxy, self).__init__()\n        self.register_buffer(ZERO_HW_SENTINEL_NAME, torch.tensor(ZERO_HW_SENTINEL_VALUE))\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        super(QuantProxy, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n        zero_hw_sentinel_key = prefix + ZERO_HW_SENTINEL_NAME\n        if zero_hw_sentinel_key in missing_keys:\n            missing_keys.remove(zero_hw_sentinel_key)\n        if zero_hw_sentinel_key in unexpected_keys:  # for retrocompatibility with when it wasn't removed\n            unexpected_keys.remove(zero_hw_sentinel_key)\n\n    def state_dict(self, destination=None, prefix='', keep_vars=False):\n        output_dict = super(QuantProxy, self).state_dict(destination, prefix, keep_vars)\n        del output_dict[prefix + ZERO_HW_SENTINEL_NAME]\n        return output_dict\n"""
brevitas/proxy/runtime_quant.py,3,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom typing import Optional, Tuple\n\nimport torch\nfrom torch.nn import Module\n\nfrom brevitas.core import ZERO_HW_SENTINEL_NAME, ZERO_HW_SENTINEL_VALUE\nfrom brevitas.core.bit_width import BitWidthImplType, MsbClampParameterBitWidth, BitWidthConst, IdentityBitWidth\nfrom brevitas.core.bit_width import BitWidthParameter, LsbTruncParameterBitWidth, ZeroLsbTruncBitWidth\nfrom brevitas.core.function_wrapper import TensorClamp\nfrom brevitas.core.quant import PrescaledRestrictIntQuantWithInputBitWidth, ClampedBinaryQuant\nfrom brevitas.core.quant import QuantType, IdentityPrescaledIntQuant\nfrom brevitas.core.quant import RescalingIntQuant, IdentityQuant\nfrom brevitas.function.ops_ste import round_ste\nfrom brevitas.core.restrict_val import RestrictValueType, RestrictValue, FloatToIntImplType, RestrictValueOpImplType\nfrom brevitas.core.scaling import RuntimeStatsScaling, SCALING_SCALAR_SHAPE, StatsInputViewShapeImpl\nfrom brevitas.core.scaling import ScalingImplType, StandaloneScaling, IntScaling\nfrom brevitas.core.stats import StatsOp\n\nfrom .quant_proxy import QuantProxy\n\n\nOVER_BATCH_OVER_CHANNELS_4D_SHAPE = (1, -1, 1, 1)\n\n\nclass FusedActivationQuantProxy(torch.jit.ScriptModule):\n\n    def __init__(self,\n                 activation_impl,\n                 tensor_quant):\n        super(FusedActivationQuantProxy, self).__init__()\n        self.activation_impl = activation_impl\n        self.tensor_quant = tensor_quant\n\n    @torch.jit.script_method\n    def forward(self, x, zero_hw_sentinel):\n        x = self.activation_impl(x)\n        x, output_scale, output_bit_width = self.tensor_quant(x, zero_hw_sentinel)\n        return x, output_scale, output_bit_width\n\n\nclass ActivationQuantProxy(QuantProxy):\n\n    def __init__(self,\n                 activation_impl: Module,\n                 bit_width: int,\n                 signed: bool,\n                 narrow_range: bool,\n                 min_val: float,\n                 max_val: float,\n                 quant_type: QuantType,\n                 float_to_int_impl_type: FloatToIntImplType,\n                 scaling_override: Optional[Module],\n                 scaling_impl_type: ScalingImplType,\n                 scaling_per_channel: bool,\n                 scaling_min_val: Optional[float],\n                 scaling_stats_sigma: Optional[float],\n                 scaling_stats_op: Optional[StatsOp],\n                 scaling_stats_buffer_momentum: Optional[float],\n                 scaling_stats_permute_dims: Optional[Tuple],\n                 per_channel_broadcastable_shape: Optional[Tuple[int, ...]],\n                 min_overall_bit_width: Optional[int],\n                 max_overall_bit_width: Optional[int],\n                 bit_width_impl_override: Module,\n                 bit_width_impl_type: BitWidthImplType,\n                 restrict_bit_width_type: RestrictValueType,\n                 restrict_scaling_type: RestrictValueType,\n                 override_pretrained_bit_width: bool):\n        super(ActivationQuantProxy, self).__init__()\n\n        if not signed and min_val != 0.0:\n            raise Exception(""Min val has to be 0.0 when quantization is unsigned."")\n        if scaling_per_channel and per_channel_broadcastable_shape is None:\n            raise Exception(""Per channel scaling requires to specify number of channels."")\n\n        if quant_type == QuantType.FP:\n            tensor_quant = IdentityQuant()\n        else:\n            if scaling_impl_type != ScalingImplType.OVERRIDE and scaling_override is not None:\n                raise Exception(""Overriding scaling requires to set ScalingImplType to OVERRIDE explicitly."")\n            if scaling_impl_type == ScalingImplType.OVERRIDE and scaling_override is None:\n                raise Exception(""Overriding scaling requires to pass a scaling impl module."")\n\n            if scaling_per_channel:\n                scaling_shape = per_channel_broadcastable_shape\n            else:\n                scaling_shape = SCALING_SCALAR_SHAPE\n\n            if scaling_impl_type == ScalingImplType.OVERRIDE and scaling_override is not None:\n                scaling_impl = scaling_override\n                runtime = False\n\n            elif scaling_impl_type == ScalingImplType.CONST or scaling_impl_type == ScalingImplType.PARAMETER:\n                scaling_init = RescalingIntQuant.scaling_init_from_min_max(min_val, max_val)\n                scaling_impl = StandaloneScaling(is_parameter=scaling_impl_type == ScalingImplType.PARAMETER,\n                                                 parameter_shape=scaling_shape,\n                                                 restrict_scaling_type=restrict_scaling_type,\n                                                 scaling_init=scaling_init,\n                                                 scaling_min_val=scaling_min_val)\n                runtime = False\n            elif scaling_impl_type == ScalingImplType.STATS or scaling_impl_type == ScalingImplType.AFFINE_STATS:\n\n                if scaling_per_channel and not scaling_stats_op == StatsOp.MAX_AVE:\n                    scaling_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                    scaling_stats_reduce_dim = 1\n                elif scaling_per_channel and scaling_stats_op == StatsOp.MAX_AVE:\n                    raise Exception(""Can\'t do per channel scaling with MAX AVE statistics."")\n                elif not scaling_per_channel and scaling_stats_op == StatsOp.MAX_AVE:\n                    scaling_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n                    scaling_stats_reduce_dim = 1\n                else:  # not scaling_per_channel\n                    scaling_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_TENSOR\n                    scaling_stats_reduce_dim = None\n                    scaling_stats_permute_dims = None\n\n                stats_buffer_init = RescalingIntQuant.scaling_init_from_min_max(min_val, max_val).item()\n                scaling_impl = RuntimeStatsScaling(stats_op=scaling_stats_op,\n                                                   restrict_scaling_type=restrict_scaling_type,\n                                                   stats_input_view_shape_impl=scaling_stats_input_view_shape_impl,\n                                                   stats_output_shape=scaling_shape,\n                                                   sigma=scaling_stats_sigma,\n                                                   scaling_min_val=scaling_min_val,\n                                                   stats_reduce_dim=scaling_stats_reduce_dim,\n                                                   stats_buffer_momentum=scaling_stats_buffer_momentum,\n                                                   stats_buffer_init=stats_buffer_init,\n                                                   stats_permute_dims=scaling_stats_permute_dims,\n                                                   affine=scaling_impl_type == ScalingImplType.AFFINE_STATS)\n                runtime = True\n            else:\n                raise Exception(""Scaling type {} not supported for int runtime quantization""\n                                .format(str(scaling_impl_type)))\n\n            if quant_type == QuantType.BINARY:\n                if not signed:\n                    raise Exception(""Binary activation supports only signed activations"")\n                tensor_quant = ClampedBinaryQuant(scaling_impl=scaling_impl)\n\n            elif quant_type == QuantType.INT:\n\n                if bit_width_impl_override is None:\n                    if bit_width_impl_type is None or bit_width is None or restrict_bit_width_type is None:\n                        raise Exception(""Bit width is not defined properly"")\n\n                    if bit_width_impl_type == BitWidthImplType.CONST:\n                        tensor_clamp_impl = TensorClamp()  # If it\'s const, don\'t pass gradients to clipped values\n                        msb_clamp_bit_width_impl = BitWidthConst(bit_width, restrict_bit_width_type)\n                    elif bit_width_impl_type == BitWidthImplType.PARAMETER:\n                        tensor_clamp_impl = TensorClamp()  # if it\'s learned, I pass gradients to the bit width\n                        msb_clamp_bit_width_impl = BitWidthParameter(bit_width,\n                                                                     min_overall_bit_width,\n                                                                     max_overall_bit_width,\n                                                                     restrict_bit_width_type,\n                                                                     override_pretrained_bit_width)\n                    else:\n                        raise Exception(""Bit width type {} not supported for weight quantization""\n                                        .format(str(bit_width_impl_type)))\n                else:\n                    msb_clamp_bit_width_impl = bit_width_impl_override\n                    tensor_clamp_impl = TensorClamp()  # if there is an override, it\'s learned\n\n                float_to_int_impl = RestrictValue(restrict_value_type=RestrictValueType.INT,\n                                                  float_to_int_impl_type=float_to_int_impl_type,\n                                                  min_val=None)\n                int_scaling_impl = IntScaling(narrow_range,\n                                              signed=signed,\n                                              restrict_scaling_type=restrict_scaling_type)\n                tensor_quant = RescalingIntQuant(signed=signed,\n                                                 narrow_range=narrow_range,\n                                                 scaling_impl=scaling_impl,\n                                                 int_scaling_impl=int_scaling_impl,\n                                                 tensor_clamp_impl=tensor_clamp_impl,\n                                                 msb_clamp_bit_width_impl=msb_clamp_bit_width_impl,\n                                                 float_to_int_impl=float_to_int_impl,\n                                                 runtime=runtime)\n            else:\n                raise Exception(""Quantization type {} not supported for activations."".format(quant_type))\n\n        self.fused_activation_quant_proxy = FusedActivationQuantProxy(activation_impl, tensor_quant)\n        self.scaling_impl_type = scaling_impl_type  # needed to switch between different scaling modes\n\n    def forward(self, x):\n        output, output_scale, output_bit_width = self.fused_activation_quant_proxy(x, self.zero_hw_sentinel)\n        return output, output_scale, output_bit_width\n\n    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n\n        scaling_impl_key = prefix + \'fused_activation_quant_proxy.tensor_quant.scaling_impl\'\n        runtime_stats_key = scaling_impl_key + \'.runtime_stats\'\n        running_stats_key = scaling_impl_key + \'.runtime_stats.running_stats\'\n        scaling_parameter_key = scaling_impl_key + \'.learned_value\'\n        scaling_affine_weight_key = prefix + \'.stats_scaling_impl.affine_rescaling.affine_weight\'\n        scaling_affine_bias_key = prefix + \'.stats_scaling_impl.affine_rescaling.affine_bias\'\n\n        if not isinstance(self.fused_activation_quant_proxy.tensor_quant, IdentityQuant) and \\\n                self.scaling_impl_type == ScalingImplType.PARAMETER:\n            scaling_impl = self.fused_activation_quant_proxy.tensor_quant.scaling_impl\n\n            # If it\'s retrained directly from statistics, i.e. there isn\'t a preexisting parameter\n            if running_stats_key in state_dict and not scaling_parameter_key in state_dict:\n                scaling_init = state_dict[running_stats_key]\n                if scaling_affine_weight_key in state_dict:\n                    scaling_init *= state_dict[scaling_affine_weight_key]\n                if scaling_affine_bias_key in state_dict:\n                    scaling_init += state_dict[scaling_affine_bias_key]\n\n                scaling_init = scaling_init.abs()\n\n                # Preprocess scaling init, which is always in FP range, based on current value restrictions\n                restrict_value_type = scaling_impl.restrict_value.restrict_value_type\n                restrict_value_init_op = scaling_impl.restrict_value.restrict_value_op(restrict_value_type,\n                                                                                       RestrictValueOpImplType.TORCH_FN)\n                scaling_init = restrict_value_init_op(scaling_init)\n\n                # Put scaling init in place in the dict for parameter\n                if self.scaling_impl_type == ScalingImplType.PARAMETER:\n                    state_dict[scaling_parameter_key] = scaling_init\n\n            # Get rid of statistics after using them or in case there is already a parameter\n            for k in list(state_dict.keys()):\n                if k.startswith(runtime_stats_key):\n                    del state_dict[k]\n\n        # Go on with dict restoring\n        super(ActivationQuantProxy, self)._load_from_state_dict(state_dict, prefix, local_metadata, strict,\n                                                                missing_keys, unexpected_keys, error_msgs)\n\n\nclass ClampQuantProxy(QuantProxy):\n\n    def __init__(self,\n                 signed: bool,\n                 narrow_range: bool,\n                 quant_type: QuantType,\n                 ms_bit_width_to_clamp: int,\n                 clamp_at_least_init_val: bool,\n                 min_overall_bit_width: Optional[int],\n                 max_overall_bit_width: Optional[int],\n                 msb_clamp_bit_width_impl_type: BitWidthImplType,\n                 override_pretrained_bit_width: bool):\n        super(ClampQuantProxy, self).__init__()\n\n        if quant_type == QuantType.FP:\n            self.tensor_quant = IdentityPrescaledIntQuant()\n\n        elif quant_type == QuantType.INT:\n            msb_clamp_bit_width_impl = MsbClampParameterBitWidth(ms_bit_width_to_clamp=ms_bit_width_to_clamp,\n                                                                 clamp_at_least_init_val=clamp_at_least_init_val,\n                                                                 min_overall_bit_width=min_overall_bit_width,\n                                                                 max_overall_bit_width=max_overall_bit_width,\n                                                                 bit_width_impl_type=msb_clamp_bit_width_impl_type,\n                                                                 override_pretrained=override_pretrained_bit_width)\n            tensor_clamp_impl = TensorClamp()\n            float_to_int_impl = RestrictValue(restrict_value_type=RestrictValueType.INT,\n                                              float_to_int_impl_type=FloatToIntImplType.ROUND,\n                                              min_val=None)\n            tensor_quant_impl = PrescaledRestrictIntQuantWithInputBitWidth\n            self.tensor_quant = tensor_quant_impl(signed=signed,\n                                                  narrow_range=narrow_range,\n                                                  tensor_clamp_impl=tensor_clamp_impl,\n                                                  float_to_int_impl=float_to_int_impl,\n                                                  msb_clamp_bit_width_impl=msb_clamp_bit_width_impl)\n        else:\n            raise Exception(""Quantization type {} not supported for accumulators."".format(quant_type))\n\n    def forward(self, x, input_scale, input_bit_width):\n        x, output_scale, output_bit_width = self.tensor_quant(x, input_scale, input_bit_width, self.zero_hw_sentinel)\n        return x, output_scale, output_bit_width\n\n\nclass TruncQuantProxy(QuantProxy):\n\n    def __init__(self,\n                 signed: bool,\n                 quant_type: QuantType,\n                 ls_bit_width_to_trunc: int,\n                 trunc_at_least_init_val: bool,\n                 min_overall_bit_width: Optional[int],\n                 max_overall_bit_width: Optional[int],\n                 lsb_trunc_bit_width_impl_type: BitWidthImplType,\n                 explicit_rescaling: bool,\n                 override_pretrained_bit_width: bool):\n        super(TruncQuantProxy, self).__init__()\n        self.explicit_rescaling = explicit_rescaling\n\n        if quant_type == QuantType.FP:\n            self.lsb_trunc_bit_width_impl = ZeroLsbTruncBitWidth()\n            self.tensor_quant = IdentityPrescaledIntQuant()\n\n        elif quant_type == QuantType.INT:\n            self.lsb_trunc_bit_width_impl = LsbTruncParameterBitWidth(ls_bit_width_to_trunc=ls_bit_width_to_trunc,\n                                                                      trunc_at_least_init_val=trunc_at_least_init_val,\n                                                                      min_overall_bit_width=min_overall_bit_width,\n                                                                      max_overall_bit_width=max_overall_bit_width,\n                                                                      bit_width_impl_type=lsb_trunc_bit_width_impl_type,\n                                                                      override_pretrained=override_pretrained_bit_width)\n            tensor_clamp_impl = TensorClamp()\n            float_to_int_impl = RestrictValue(restrict_value_type=RestrictValueType.INT,\n                                              float_to_int_impl_type=FloatToIntImplType.FLOOR,\n                                              min_val=None)\n            msb_clamp_bit_width_impl = IdentityBitWidth()\n            self.tensor_quant = PrescaledRestrictIntQuantWithInputBitWidth(narrow_range=False,\n                                                                           signed=signed,\n                                                                           tensor_clamp_impl=tensor_clamp_impl,\n                                                                           msb_clamp_bit_width_impl=msb_clamp_bit_width_impl,\n                                                                           float_to_int_impl=float_to_int_impl)\n\n        else:\n            raise Exception(""Quantization type {} not supported for accumulators."".format(quant_type))\n\n    def forward(self, x, input_scale, input_bit_width):\n        x = round_ste(x / input_scale) * input_scale  # clean up fp errors before floor\n        trunc_bit_width = self.lsb_trunc_bit_width_impl(input_bit_width, self.zero_hw_sentinel)\n        trunc_scale = 2.0 ** trunc_bit_width\n        output_scale = trunc_scale * input_scale\n        x, output_scale, input_bit_width = self.tensor_quant(x, output_scale, input_bit_width, self.zero_hw_sentinel)\n        if self.explicit_rescaling:\n            x = x / trunc_scale  # rescaling is explicit, so the truncation scale stays with x rather with output_scale\n            output_scale = output_scale / trunc_scale\n        output_bit_width = input_bit_width - trunc_bit_width\n        return x, output_scale, output_bit_width\n'"
brevitas/utils/__init__.py,0,b''
brevitas/utils/logging.py,0,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom typing import Dict\nfrom abc import ABCMeta, abstractmethod\nfrom functools import partial\n\nimport torch\nfrom torch import nn\n\nfrom brevitas.utils.quant_utils import *\n\n\nclass LogBitWidth(object):\n    __metaclass__ = ABCMeta\n\n    def __init__(self, model):\n        self.model: nn.Module = model\n        self.bit_width_dict: Dict[str, int] = {}\n        self.register_hooks()\n\n    @abstractmethod\n    def register_hooks(self):\n        pass\n\n\nclass LogWeightBitWidth(LogBitWidth):\n\n    def __init__(self, model):\n        super(LogWeightBitWidth, self).__init__(model=model)\n        pass\n\n    def register_hooks(self):\n        for name, module in self.model.named_modules():\n            def hook_fn(module, input, output, name):\n                (quant_weight, scale, bit_width) = output\n                self.bit_width_dict[name] = bit_width.detach().clone()\n            if has_learned_weight_bit_width(module):\n                module.register_forward_hook(partial(hook_fn, name=name))\n\n\nclass LogActivationBitWidth(LogBitWidth):\n\n    def __init__(self, model):\n        super(LogActivationBitWidth, self).__init__(model=model)\n        pass\n\n    def register_hooks(self):\n        for name, module in self.model.named_modules():\n            def hook_fn(module, input, output, name):\n                (quant_act, scale, bit_width) = output\n                self.bit_width_dict[name] = bit_width.detach().clone()\n            if has_learned_activation_bit_width(module):\n                module.register_forward_hook(partial(hook_fn, name=name))'"
brevitas/utils/python_utils.py,0,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom enum import Enum\n\n\nclass AutoName(str, Enum):\n    def _generate_next_value_(name, start, count, last_values):\n         return name\n\n    def __str__(self):\n        return self.value'"
brevitas/utils/quant_utils.py,0,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom brevitas.proxy.parameter_quant import WeightQuantProxy\nfrom brevitas.core.quant import RescalingIntQuant\nfrom brevitas.proxy.runtime_quant import ActivationQuantProxy, FusedActivationQuantProxy\nfrom brevitas.core.bit_width import BitWidthParameter\nfrom brevitas.nn.quant_layer import QuantTensor\n\n\ndef has_learned_weight_bit_width(module):\n    if isinstance(module, WeightQuantProxy) \\\n            and isinstance(module.tensor_quant, RescalingIntQuant) \\\n            and isinstance(module.tensor_quant.msb_clamp_bit_width_impl,\n                           BitWidthParameter):\n        return True\n    else:\n        return False\n\n\ndef has_learned_activation_bit_width(module):\n    if isinstance(module, ActivationQuantProxy) \\\n            and isinstance(module.fused_activation_quant_proxy, FusedActivationQuantProxy) \\\n            and isinstance(module.fused_activation_quant_proxy.tensor_quant, RescalingIntQuant) \\\n            and isinstance(module.fused_activation_quant_proxy.tensor_quant.msb_clamp_bit_width_impl,\n                           BitWidthParameter):\n        return True\n    else:\n        return False'"
brevitas/utils/torch_utils.py,1,"b'# Copyright (c) 2018-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom torch.nn import Sequential\n\n\nclass TupleSequential(Sequential):\n\n    def output(self, mod, input):\n        if isinstance(input, tuple):\n            return mod(*input)\n        else:\n            return mod(input)\n\n    def forward(self, *input):\n        modules = list(self._modules.values())\n        out = self.output(modules[0], input)\n        for mod in modules[1:]:\n            out = self.output(mod, out)\n        return out'"
brevitas_examples/bnn_pynq/__init__.py,0,b'from .models import *'
brevitas_examples/bnn_pynq/bnn_pynq_train.py,2,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport argparse\nimport os\nimport sys\n\nimport torch\nfrom brevitas_examples.bnn_pynq.trainer import Trainer\n\n# Pytorch precision\ntorch.set_printoptions(precision=10)\n\n\n# Util method to add mutually exclusive boolean\ndef add_bool_arg(parser, name, default):\n    group = parser.add_mutually_exclusive_group(required=False)\n    group.add_argument(""--"" + name, dest=name, action=""store_true"")\n    group.add_argument(""--no_"" + name, dest=name, action=""store_false"")\n    parser.set_defaults(**{name: default})\n\n\n# Util method to pass None as a string and be recognized as None value\ndef none_or_str(value):\n    if value == ""None"":\n        return None\n    return value\n\n\ndef none_or_int(value):\n    if value == ""None"":\n        return None\n    return int(value)\n\n\ndef parse_args(args):\n    parser = argparse.ArgumentParser(description=""PyTorch MNIST/CIFAR10 Training"")\n    # I/O\n    parser.add_argument(""--datadir"", default=""./data/"", help=""Dataset location"")\n    parser.add_argument(""--experiments"", default=""./experiments"", help=""Path to experiments folder"")\n    parser.add_argument(""--dry_run"", action=""store_true"", help=""Disable output files generation"")\n    parser.add_argument(""--log_freq"", type=int, default=10)\n    # Execution modes\n    parser.add_argument(""--evaluate"", dest=""evaluate"", action=""store_true"", help=""evaluate model on validation set"")\n    parser.add_argument(""--resume"", dest=""resume"", type=none_or_str,\n                        help=""Resume from checkpoint. Overrides --pretrained flag."")\n    add_bool_arg(parser, ""detect_nan"", default=False)\n    # Compute resources\n    parser.add_argument(""--num_workers"", default=4, type=int, help=""Number of workers"")\n    parser.add_argument(""--gpus"", type=none_or_str, default=""0"", help=""Comma separated GPUs"")\n    # Optimizer hyperparams\n    parser.add_argument(""--batch_size"", default=100, type=int, help=""batch size"")\n    parser.add_argument(""--lr"", default=0.02, type=float, help=""Learning rate"")\n    parser.add_argument(""--optim"", type=none_or_str, default=""ADAM"", help=""Optimizer to use"")\n    parser.add_argument(""--loss"", type=none_or_str, default=""SqrHinge"", help=""Loss function to use"")\n    parser.add_argument(""--scheduler"", default=""FIXED"", type=none_or_str, help=""LR Scheduler"")\n    parser.add_argument(""--milestones"", type=none_or_str, default=\'100,150,200,250\', help=""Scheduler milestones"")\n    parser.add_argument(""--momentum"", default=0.9, type=float, help=""Momentum"")\n    parser.add_argument(""--weight_decay"", default=0, type=float, help=""Weight decay"")\n    parser.add_argument(""--epochs"", default=1000, type=int, help=""Number of epochs"")\n    parser.add_argument(""--random_seed"", default=1, type=int, help=""Random seed"")\n    # Neural network Architecture\n    parser.add_argument(""--network"", default=""LFC_1W1A"", type=str, help=""neural network"")\n    parser.add_argument(""--pretrained"", action=\'store_true\', help=""Load pretrained model"")\n    return parser.parse_args(args)\n\n\nclass objdict(dict):\n    def __getattr__(self, name):\n        if name in self:\n            return self[name]\n        else:\n            raise AttributeError(""No such attribute: "" + name)\n\n    def __setattr__(self, name, value):\n        self[name] = value\n\n    def __delattr__(self, name):\n        if name in self:\n            del self[name]\n        else:\n            raise AttributeError(""No such attribute: "" + name)\n\n\ndef main(cmd_args):\n    args = parse_args(cmd_args)\n\n    # Set relative paths relative to current workdir\n    path_args = [""datadir"", ""experiments"", ""resume""]\n    for path_arg in path_args:\n        path = getattr(args, path_arg)\n        if path is not None and not os.path.isabs(path):\n            abs_path = os.path.abspath(os.path.join(os.getcwd(), path))\n            setattr(args, path_arg, abs_path)\n\n    # Access config as an object\n    args = objdict(args.__dict__)\n\n    # Avoid creating new folders etc.\n    if args.evaluate:\n        args.dry_run = True\n\n    # Init trainer\n    trainer = Trainer(args)\n\n    # Execute\n    if args.evaluate:\n        with torch.no_grad():\n            trainer.eval_model()\n    else:\n        trainer.train_model()\n\n\nif __name__ == ""__main__"":\n    main(sys.argv[1:])\n'"
brevitas_examples/bnn_pynq/logger.py,0,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport logging\nimport sys\nimport os\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\nclass TrainingEpochMeters(object):\n    def __init__(self):\n        self.batch_time = AverageMeter()\n        self.data_time = AverageMeter()\n        self.losses = AverageMeter()\n        self.top1 = AverageMeter()\n        self.top5 = AverageMeter()\n\n\nclass EvalEpochMeters(object):\n    def __init__(self):\n        self.model_time = AverageMeter()\n        self.loss_time = AverageMeter()\n        self.losses = AverageMeter()\n        self.top1 = AverageMeter()\n        self.top5 = AverageMeter()\n\n\nclass Logger(object):\n\n    def __init__(self, output_dir_path, dry_run):\n        self.output_dir_path = output_dir_path\n        self.log = logging.getLogger(\'log\')\n        self.log.setLevel(logging.INFO)\n\n        # Stout logging\n        out_hdlr = logging.StreamHandler(sys.stdout)\n        out_hdlr.setFormatter(logging.Formatter(\'%(asctime)s %(message)s\'))\n        out_hdlr.setLevel(logging.INFO)\n        self.log.addHandler(out_hdlr)\n\n        # Txt logging\n        if not dry_run:\n            file_hdlr = logging.FileHandler(os.path.join(self.output_dir_path, \'log.txt\'))\n            file_hdlr.setFormatter(logging.Formatter(\'%(asctime)s %(message)s\'))\n            file_hdlr.setLevel(logging.INFO)\n            self.log.addHandler(file_hdlr)\n            self.log.propagate = False\n\n    def info(self, arg):\n        self.log.info(arg)\n\n    def eval_batch_cli_log(self, epoch_meters, batch, tot_batches):\n        self.info(\'Test: [{0}/{1}]\\t\'\n                  \'Model Time {model_time.val:.3f} ({model_time.avg:.3f})\\t\'\n                  \'Loss Time {loss_time.val:.3f} ({loss_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\\t\'\n                  .format(batch, tot_batches,\n                          model_time=epoch_meters.model_time,\n                          loss_time=epoch_meters.loss_time,\n                          loss=epoch_meters.losses,\n                          top1=epoch_meters.top1,\n                          top5=epoch_meters.top5))\n\n    def training_batch_cli_log(self, epoch_meters, epoch, batch, tot_batches):\n        self.info(\'Epoch: [{0}][{1}/{2}]\\t\'\n                         \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                         \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                         \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                         \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                         \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\\t\'\n                         .format(epoch, batch, tot_batches,\n                                 batch_time=epoch_meters.batch_time,\n                                 data_time=epoch_meters.data_time,\n                                 loss=epoch_meters.losses,\n                                 top1=epoch_meters.top1,\n                                 top5=epoch_meters.top5))\n'"
brevitas_examples/bnn_pynq/trainer.py,13,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport random\nimport os\nimport time\nfrom datetime import datetime\n\nimport torch\nimport torch.optim as optim\nfrom torch import nn\nfrom torch.optim.lr_scheduler import MultiStepLR\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST, CIFAR10\n\nfrom .logger import Logger, TrainingEpochMeters, EvalEpochMeters\nfrom .models import model_with_cfg\nfrom .models.losses import SqrHingeLoss\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass Trainer(object):\n    def __init__(self, args):\n\n        model, cfg = model_with_cfg(args.network, args.pretrained)\n\n        # Init arguments\n        self.args = args\n        prec_name = ""_{}W{}A"".format(cfg.getint(\'QUANT\', \'WEIGHT_BIT_WIDTH\'), cfg.getint(\'QUANT\', \'ACT_BIT_WIDTH\'))\n        experiment_name = \'{}{}_{}\'.format(args.network, prec_name, datetime.now().strftime(\'%Y%m%d_%H%M%S\'))\n        self.output_dir_path = os.path.join(args.experiments, experiment_name)\n\n        if self.args.resume:\n            self.output_dir_path, _ = os.path.split(args.resume)\n            self.output_dir_path, _ = os.path.split(self.output_dir_path)\n\n        if not args.dry_run:\n            self.checkpoints_dir_path = os.path.join(self.output_dir_path, \'checkpoints\')\n            if not args.resume:\n                os.mkdir(self.output_dir_path)\n                os.mkdir(self.checkpoints_dir_path)\n        self.logger = Logger(self.output_dir_path, args.dry_run)\n\n        # Randomness\n        random.seed(args.random_seed)\n        torch.manual_seed(args.random_seed)\n        torch.cuda.manual_seed_all(args.random_seed)\n\n        # Datasets\n        transform_to_tensor = transforms.Compose([transforms.ToTensor()])\n\n        dataset = cfg.get(\'MODEL\', \'DATASET\')\n        self.num_classes = cfg.getint(\'MODEL\', \'NUM_CLASSES\')\n        if dataset == \'CIFAR10\':\n            train_transforms_list = [transforms.RandomCrop(32, padding=4),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.ToTensor()]\n            transform_train = transforms.Compose(train_transforms_list)\n            builder = CIFAR10\n\n        elif dataset == \'MNIST\':\n            transform_train = transform_to_tensor\n            builder = MNIST\n        else:\n            raise Exception(""Dataset not supported: {}"".format(args.dataset))\n\n        train_set = builder(root=args.datadir,\n                            train=True,\n                            download=True,\n                            transform=transform_train)\n        test_set = builder(root=args.datadir,\n                           train=False,\n                           download=True,\n                           transform=transform_to_tensor)\n        self.train_loader = DataLoader(train_set,\n                                       batch_size=args.batch_size,\n                                       shuffle=True,\n                                       num_workers=args.num_workers)\n        self.test_loader = DataLoader(test_set,\n                                      batch_size=args.batch_size,\n                                      shuffle=False,\n                                      num_workers=args.num_workers)\n\n        # Init starting values\n        self.starting_epoch = 1\n        self.best_val_acc = 0\n\n        # Setup device\n        if args.gpus is not None:\n            args.gpus = [int(i) for i in args.gpus.split(\',\')]\n            self.device = \'cuda:\' + str(args.gpus[0])\n            torch.backends.cudnn.benchmark = True\n        else:\n            self.device = \'cpu\'\n        self.device = torch.device(self.device)\n\n        # Resume checkpoint, if any\n        if args.resume:\n            print(\'Loading model checkpoint at: {}\'.format(args.resume))\n            package = torch.load(args.resume, map_location=\'cpu\')\n            model_state_dict = package[\'state_dict\']\n            model.load_state_dict(model_state_dict, strict=args.strict)\n\n        if args.gpus is not None and len(args.gpus) == 1:\n            model = model.to(device=self.device)\n        if args.gpus is not None and len(args.gpus) > 1:\n            model = nn.DataParallel(model, args.gpus)\n        self.model = model\n\n        # Loss function\n        if args.loss == \'SqrHinge\':\n            self.criterion = SqrHingeLoss()\n        else:\n            self.criterion = nn.CrossEntropyLoss()\n        self.criterion = self.criterion.to(device=self.device)\n\n        # Init optimizer\n        if args.optim == \'ADAM\':\n            self.optimizer = optim.Adam(self.model.parameters(),\n                                        lr=args.lr,\n                                        weight_decay=args.weight_decay)\n        elif args.optim == \'SGD\':\n            self.optimizer = optim.SGD(self.model.parameters(),\n                                       lr=self.args.lr,\n                                       momentum=self.args.momentum,\n                                       weight_decay=self.args.weight_decay)\n\n        # Resume optimizer, if any\n        if args.resume and not args.evaluate:\n            self.logger.log.info(""Loading optimizer checkpoint"")\n            if \'optim_dict\' in package.keys():\n                self.optimizer.load_state_dict(package[\'optim_dict\'])\n            if \'epoch\' in package.keys():\n                self.starting_epoch = package[\'epoch\']\n            if \'best_val_acc\' in package.keys():\n                self.best_val_acc = package[\'best_val_acc\']\n\n        # LR scheduler\n        if args.scheduler == \'STEP\':\n            milestones = [int(i) for i in args.milestones.split(\',\')]\n            self.scheduler = MultiStepLR(optimizer=self.optimizer,\n                                         milestones=milestones,\n                                         gamma=0.1)\n        elif args.scheduler == \'FIXED\':\n            self.scheduler = None\n        else:\n            raise Exception(""Unrecognized scheduler {}"".format(self.args.scheduler))\n\n        # Resume scheduler, if any\n        if args.resume and not args.evaluate and self.scheduler is not None:\n            self.scheduler.last_epoch = package[\'epoch\'] - 1\n\n    def checkpoint_best(self, epoch, name):\n        best_path = os.path.join(self.checkpoints_dir_path, name)\n        self.logger.info(""Saving checkpoint model to {}"".format(best_path))\n        torch.save({\n            \'state_dict\': self.model.state_dict(),\n            \'optim_dict\': self.optimizer.state_dict(),\n            \'epoch\': epoch + 1,\n            \'best_val_acc\': self.best_val_acc,\n        }, best_path)\n\n    def train_model(self):\n\n        # training starts\n        if self.args.detect_nan:\n            torch.autograd.set_detect_anomaly(True)\n\n        for epoch in range(self.starting_epoch, self.args.epochs):\n\n            # Set to training mode\n            self.model.train()\n            self.criterion.train()\n\n            # Init metrics\n            epoch_meters = TrainingEpochMeters()\n            start_data_loading = time.time()\n\n\n            for i, data in enumerate(self.train_loader):\n                (input, target) = data\n                input = input.to(self.device, non_blocking=True)\n                target = target.to(self.device, non_blocking=True)\n\n                # for hingeloss only\n                if isinstance(self.criterion, SqrHingeLoss):\n                    target=target.unsqueeze(1)\n                    target_onehot = torch.Tensor(target.size(0), self.num_classes).to(self.device, non_blocking=True)\n                    target_onehot.fill_(-1)\n                    target_onehot.scatter_(1, target, 1)\n                    target=target.squeeze()\n                    target_var = target_onehot\n                else:\n                    target_var = target\n\n                # measure data loading time\n                epoch_meters.data_time.update(time.time() - start_data_loading)\n\n                # Training batch starts\n                start_batch = time.time()\n                output = self.model(input)\n                loss = self.criterion(output, target_var)\n\n                # compute gradient and do SGD step\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                self.model.clip_weights(-1,1)\n\n                # measure elapsed time\n                epoch_meters.batch_time.update(time.time() - start_batch)\n\n                if i % int(self.args.log_freq) == 0 or i == len(self.train_loader) - 1:\n                    prec1, prec5 = accuracy(output.detach(), target, topk=(1, 5))\n                    epoch_meters.losses.update(loss.item(), input.size(0))\n                    epoch_meters.top1.update(prec1.item(), input.size(0))\n                    epoch_meters.top5.update(prec5.item(), input.size(0))\n                    self.logger.training_batch_cli_log(epoch_meters, epoch, i, len(self.train_loader))\n\n                # training batch ends\n                start_data_loading = time.time()\n\n            # Set the learning rate\n            if self.scheduler is not None:\n                self.scheduler.step(epoch)\n            else:\n                # Set the learning rate\n                if epoch%40==0:\n                    self.optimizer.param_groups[0][\'lr\'] *= 0.5\n\n            # Perform eval\n            with torch.no_grad():\n                top1avg = self.eval_model(epoch)\n\n            # checkpoint\n            if top1avg >= self.best_val_acc and not self.args.dry_run:\n                self.best_val_acc = top1avg\n                self.checkpoint_best(epoch, ""best.tar"")\n            elif not self.args.dry_run:\n                self.checkpoint_best(epoch, ""checkpoint.tar"")\n\n        # training ends\n        if not self.args.dry_run:\n            return os.path.join(self.checkpoints_dir_path, ""best.tar"")\n\n    def eval_model(self, epoch=None):\n        eval_meters = EvalEpochMeters()\n\n        # switch to evaluate mode\n        self.model.eval()\n        self.criterion.eval()\n\n        for i, data in enumerate(self.test_loader):\n\n            end = time.time()\n            (input, target) = data\n\n            input = input.to(self.device, non_blocking=True)\n            target = target.to(self.device, non_blocking=True)\n            \n            # for hingeloss only\n            if isinstance(self.criterion, SqrHingeLoss):        \n                target=target.unsqueeze(1)\n                target_onehot = torch.Tensor(target.size(0), self.num_classes).to(self.device, non_blocking=True)\n                target_onehot.fill_(-1)\n                target_onehot.scatter_(1, target, 1)\n                target=target.squeeze()\n                target_var = target_onehot\n            else:\n                target_var = target\n            \n            # compute output\n            output = self.model(input)\n\n            # measure model elapsed time\n            eval_meters.model_time.update(time.time() - end)\n            end = time.time()\n\n            #compute loss\n            loss = self.criterion(output, target_var)\n            eval_meters.loss_time.update(time.time() - end)\n\n            pred = output.data.argmax(1, keepdim=True)\n            correct = pred.eq(target.data.view_as(pred)).sum()\n            prec1 = 100. * correct.float() / input.size(0)\n\n            _, prec5 = accuracy(output, target, topk=(1, 5))\n            eval_meters.losses.update(loss.item(), input.size(0))\n            eval_meters.top1.update(prec1.item(), input.size(0))\n            eval_meters.top5.update(prec5.item(), input.size(0))\n\n            #Eval batch ends\n            self.logger.eval_batch_cli_log(eval_meters, i, len(self.test_loader))\n\n        return eval_meters.top1.avg\n'"
brevitas_examples/imagenet_classification/__init__.py,0,b'from .models import *'
brevitas_examples/imagenet_classification/imagenet_val.py,10,"b'import argparse\nimport os\nimport random\nimport configparser\n\nimport torch\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nfrom .models import model_with_cfg\n\nSEED = 123456\n\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Validation\')\nparser.add_argument(\'--imagenet-dir\', help=\'path to folder containing Imagenet val folder\')\nparser.add_argument(\'--model\', type=str, default=\'quant_mobilenet_v1_4b\', help=\'Name of the model\')\nparser.add_argument(\'--pretrained\', action=\'store_true\', help=\'Load pretrained checkpoint\')\nparser.add_argument(\'--workers\', default=4, type=int, help=\'number of data loading workers\')\nparser.add_argument(\'--batch-size\', default=256, type=int, help=\'Minibatch size\')\nparser.add_argument(\'--gpu\', default=None, type=int, help=\'GPU id to use.\')\n\n\ndef main():\n    args = parser.parse_args()\n    random.seed(SEED)\n    torch.manual_seed(SEED)\n\n    model, cfg = model_with_cfg(args.model, args.pretrained)\n\n    if args.gpu is not None:\n        torch.cuda.set_device(args.gpu)\n        model = model.cuda(args.gpu)\n        cudnn.benchmark = True\n\n    valdir = os.path.join(args.imagenet_dir, \'val\')\n    mean = [float(cfg.get(\'PREPROCESS\', \'MEAN_0\')), float(cfg.get(\'PREPROCESS\', \'MEAN_1\')),\n            float(cfg.get(\'PREPROCESS\', \'MEAN_2\'))]\n    std = [float(cfg.get(\'PREPROCESS\', \'STD_0\')), float(cfg.get(\'PREPROCESS\', \'STD_1\')),\n           float(cfg.get(\'PREPROCESS\', \'STD_2\'))]\n    normalize = transforms.Normalize(mean=mean, std=std)\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n\n    validate(val_loader, model, args)\n    return\n\n\ndef validate(val_loader, model, args):\n    top1 = AverageMeter(\'Acc@1\', \':6.2f\')\n    top5 = AverageMeter(\'Acc@5\', \':6.2f\')\n\n    def print_accuracy(top1, top5, prefix=\'\'):\n        print(\'{}Avg acc@1 {top1.avg:.3f} Avg acc@5 {top5.avg:.3f}\'\n              .format(prefix, top1=top1, top5=top5))\n\n    model.eval()\n    with torch.no_grad():\n        num_batches = len(val_loader)\n        for i, (images, target) in enumerate(val_loader):\n            if args.gpu is not None:\n                images = images.cuda(args.gpu, non_blocking=True)\n                target = target.cuda(args.gpu, non_blocking=True)\n            output = model(images)\n            # measure accuracy\n            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n            top1.update(acc1[0], images.size(0))\n            top5.update(acc5[0], images.size(0))\n            print_accuracy(top1, top5, \'{}/{}: \'.format(i, num_batches))\n        print_accuracy(top1, top5, \'Total:\')\n    return\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self, name, fmt=\':f\'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = \'{name} {val\' + self.fmt + \'} ({avg\' + self.fmt + \'})\'\n        return fmtstr.format(**self.__dict__)\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the accuracy over the k top predictions for the specified values of k""""""\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul(100.0 / batch_size))\n        return res\n\n\nif __name__ == \'__main__\':\n    main()\n'"
brevitas_examples/speech_to_text/__init__.py,0,b'from .quartznet import *'
brevitas_examples/speech_to_text/get_librispeech_data.py,0,"b'# Adapted from https://github.com/NVIDIA/NeMo/tree/r0.9\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport argparse\nimport fnmatch\nimport json\nimport os\nimport subprocess\nimport tarfile\nimport urllib.request\n\nfrom sox import Transformer\nfrom tqdm import tqdm\n\nparser = argparse.ArgumentParser(description=\'LibriSpeech Data download\')\nparser.add_argument(""--data_root"", required=True, default=None, type=str)\nparser.add_argument(""--data_sets"", default=""dev_clean"", type=str)\nargs = parser.parse_args()\n\nURLS = {\n    \'TRAIN_CLEAN_100\': (""http://www.openslr.org/resources/12/train-clean-100.tar.gz""),\n    \'TRAIN_CLEAN_360\': (""http://www.openslr.org/resources/12/train-clean-360.tar.gz""),\n    \'TRAIN_OTHER_500\': (""http://www.openslr.org/resources/12/train-other-500.tar.gz""),\n    \'DEV_CLEAN\': ""http://www.openslr.org/resources/12/dev-clean.tar.gz"",\n    \'DEV_OTHER\': ""http://www.openslr.org/resources/12/dev-other.tar.gz"",\n    \'TEST_CLEAN\': ""http://www.openslr.org/resources/12/test-clean.tar.gz"",\n    \'TEST_OTHER\': ""http://www.openslr.org/resources/12/test-other.tar.gz"",\n}\n\n\ndef __maybe_download_file(destination: str, source: str):\n    """"""\n    Downloads source to destination if it doesn\'t exist.\n    If exists, skips download\n    Args:\n        destination: local filepath\n        source: url of resource\n\n    Returns:\n\n    """"""\n    source = URLS[source]\n    if not os.path.exists(destination):\n        print(""{0} does not exist. Downloading ..."".format(destination))\n        urllib.request.urlretrieve(source, filename=destination + \'.tmp\')\n        os.rename(destination + \'.tmp\', destination)\n        print(""Downloaded {0}."".format(destination))\n    else:\n        print(""Destination {0} exists. Skipping."".format(destination))\n    return destination\n\n\ndef __extract_file(filepath: str, data_dir: str):\n    try:\n        tar = tarfile.open(filepath)\n        tar.extractall(data_dir)\n        tar.close()\n    except Exception:\n        print(\'Not extracting. Maybe already there?\')\n\n\ndef __process_data(data_folder: str, dst_folder: str, manifest_file: str):\n    """"""\n    Converts flac to wav and build manifests\'s json\n    Args:\n        data_folder: source with flac files\n        dst_folder: where wav files will be stored\n        manifest_file: where to store manifest\n\n    Returns:\n\n    """"""\n\n    if not os.path.exists(dst_folder):\n        os.makedirs(dst_folder)\n\n    files = []\n    entries = []\n\n    for root, dirnames, filenames in os.walk(data_folder):\n        for filename in fnmatch.filter(filenames, \'*.trans.txt\'):\n            files.append((os.path.join(root, filename), root))\n\n    for transcripts_file, root in tqdm(files):\n        with open(transcripts_file, encoding=""utf-8"") as fin:\n            for line in fin:\n                id, text = line[: line.index("" "")], line[line.index("" "") + 1 :]\n                transcript_text = text.lower().strip()\n\n                # Convert FLAC file to WAV\n                flac_file = os.path.join(root, id + "".flac"")\n                wav_file = os.path.join(dst_folder, id + "".wav"")\n                if not os.path.exists(wav_file):\n                    Transformer().build(flac_file, wav_file)\n                # check duration\n                duration = subprocess.check_output(""soxi -D {0}"".format(wav_file), shell=True)\n\n                entry = dict()\n                entry[\'audio_filepath\'] = os.path.abspath(wav_file)\n                entry[\'duration\'] = float(duration)\n                entry[\'text\'] = transcript_text\n                entries.append(entry)\n\n    with open(manifest_file, \'w\') as fout:\n        for m in entries:\n            fout.write(json.dumps(m) + \'\\n\')\n\n\ndef main():\n    data_root = args.data_root\n    data_sets = args.data_sets\n\n    if data_sets == ""ALL"":\n        data_sets = ""dev_clean,dev_other,train_clean_100,train_clean_360,train_other_500,test_clean,test_other""\n\n    for data_set in data_sets.split(\',\'):\n        print(""\\n\\nWorking on: {0}"".format(data_set))\n        filepath = os.path.join(data_root, data_set + "".tar.gz"")\n        print(""Getting {0}"".format(data_set))\n        __maybe_download_file(filepath, data_set.upper())\n        print(""Extracting {0}"".format(data_set))\n        __extract_file(filepath, data_root)\n        print(""Processing {0}"".format(data_set))\n        __process_data(\n            os.path.join(os.path.join(data_root, ""LibriSpeech""), data_set.replace(""_"", ""-""),),\n            os.path.join(os.path.join(data_root, ""LibriSpeech""), data_set.replace(""_"", ""-""),) + ""-processed"",\n            os.path.join(data_root, data_set + "".json""),\n        )\n    print(\'Done!\')\n\n\nif __name__ == ""__main__"":\n    main()'"
brevitas_examples/speech_to_text/quartznet_val.py,4,"b'import argparse\nimport copy\nimport os\nimport configparser\n\nfrom ruamel.yaml import YAML\nimport random\nimport torch\n\nfrom .quartznet import AudioToTextDataLayer\nfrom .quartznet.helpers import word_error_rate, post_process_predictions, \\\n    post_process_transcripts\nimport torch.backends.cudnn as cudnn\nimport brevitas.config\nfrom .quartznet import model_with_cfg\n\nbrevitas.config.IGNORE_MISSING_KEYS = False\nSEED = 123456\nBATCH_SIZE = 64\n\n\n\nparser = argparse.ArgumentParser(description=\'Quartznet\')\nparser.add_argument(""--input-folder"", type=str, required=False)\nparser.add_argument(""--gpu"", type=int)\nparser.add_argument(\'--pretrained\', action=\'store_true\', default=True, help=\'Load pretrained checkpoint\')\nparser.add_argument(\'--model\', type=str, default=\'quant_quartznet_perchannelscaling_4b\', help=\'Name of the model\')\n\n\ndef main():\n    random.seed(SEED)\n    torch.manual_seed(SEED)\n\n    args = parser.parse_args()\n\n    model, cfg = model_with_cfg(args.model, args.pretrained)\n\n    topology_file = cfg.get(\'MODEL\', \'TOPOLOGY_FILE\')\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    topology_path = os.path.join(current_dir, \'cfg\', \'topology\', topology_file)\n    yaml = YAML(typ=""safe"")\n    with open(topology_path) as f:\n        quartnzet_params = yaml.load(f)\n\n    vocab = quartnzet_params[\'labels\']\n    sample_rate = quartnzet_params[\'sample_rate\']\n\n    eval_datasets = args.input_folder\n    eval_dl_params = copy.deepcopy(quartnzet_params[""AudioToTextDataLayer""])\n    eval_dl_params.update(quartnzet_params[""AudioToTextDataLayer""][""eval""])\n    del eval_dl_params[""train""]\n    del eval_dl_params[""eval""]\n    data_layer = AudioToTextDataLayer(\n        manifest_filepath=eval_datasets,\n        sample_rate=sample_rate,\n        labels=vocab,\n        batch_size=BATCH_SIZE,\n        **eval_dl_params)\n\n    N = len(data_layer)\n    print(\'Evaluating {0} examples\'.format(N))\n\n    # Set Eval mode\n    model.eval()\n\n    encoder_weights = sum(p.numel() for p in model.encoder.parameters() if p.requires_grad)\n    decoder_weights = sum(p.numel() for p in model.decoder.parameters() if p.requires_grad)\n\n    print(\'================================\')\n    print(\n        f""Number of parameters in encoder: {encoder_weights}"")\n    print(\n        f""Number of parameters in decoder: {decoder_weights}"")\n    print(\n        f""Total number of parameters in decoder: ""\n        f""{encoder_weights + decoder_weights}"")\n    print(\'================================\')\n\n\n    if args.gpu is not None:\n        torch.cuda.set_device(args.gpu)\n        cudnn.benchmark = True\n        loc = \'cuda:{}\'.format(args.gpu)\n    else:\n        loc = \'cpu\'\n    model.to(loc)\n    \n    predictions = []\n    transcripts = []\n    transcripts_len = []\n    with torch.no_grad():\n        for data in data_layer.data_iterator:\n            tensors = []\n            for d in data:\n                tensors.append(d.to(loc))\n\n            audio_signal_e1, a_sig_length_e1, transcript_e1, transcript_len_e1 = tensors\n            predictions_e1 = model(tensors)\n            predictions.append(predictions_e1)\n            transcripts.append(transcript_e1)\n            transcripts_len.append(transcript_len_e1)\n\n        greedy_hypotheses = post_process_predictions(predictions, vocab)\n        references = post_process_transcripts(transcripts, transcripts_len, vocab)\n        wer = word_error_rate(hypotheses=greedy_hypotheses, references=references)\n        print(""Greedy WER {:.2f}%"".format(wer*100))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
brevitas_examples/text_to_speech/__init__.py,0,b'from .melgan import *'
brevitas_examples/text_to_speech/melgan_val.py,5,"b""import glob\nimport tqdm\nimport torch\nimport argparse\nfrom scipy.io.wavfile import write\n\nimport torch.backends.cudnn as cudnn\nimport brevitas.config\nfrom .melgan import model_with_cfg\n\nbrevitas.config.IGNORE_MISSING_KEYS = False\nMAX_WAV_VALUE = 32768.0\nimport random\nimport os\n\nSEED = 123456\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--input-folder', help='path to folder containing the val folder')\nparser.add_argument('--workers', default=32, type=int, help='number of data loading workers')\nparser.add_argument('--batch-size', default=16, type=int, help='Minibatch size')\nparser.add_argument('--gpu', default=None, type=int, help='GPU id to use.')\nparser.add_argument('--pretrained', action='store_true', default=True, help='Load pretrained checkpoint')\nparser.add_argument('--model', type=str, default='quant_melgan_8b', help='Name of the model')\n\n\ndef main():\n    args = parser.parse_args()\n    random.seed(SEED)\n    torch.manual_seed(SEED)\n\n    model, cfg = model_with_cfg(args.model, args.pretrained)\n\n    sampling_rate = cfg.getint('AUDIO', 'sampling_rate')\n\n    if args.gpu is not None:\n        loc = 'cuda:{}'.format(args.gpu)\n        torch.cuda.set_device(args.gpu)\n        model = model.cuda(args.gpu)\n        cudnn.benchmark = True\n    else:\n        loc = 'cpu'\n\n    model.to(loc)\n    model.eval(inference=True)\n\n    with torch.no_grad():\n        for melpath in tqdm.tqdm(glob.glob(os.path.join(args.input_folder, '*.mel'))):\n            mel = torch.load(melpath)\n            if len(mel.shape) == 2:\n                mel = mel.unsqueeze(0)\n\n            mel = mel.to(loc)\n\n            audio = model.inference(mel)\n            audio = audio.cpu().detach().numpy()\n\n            out_path = melpath.replace('.mel', '_reconstructed.wav')\n            write(out_path, sampling_rate, audio)\n\n\nif __name__ == '__main__':\n    main()\n"""
brevitas_examples/text_to_speech/preprocess_dataset.py,2,"b'import os\nimport glob\nimport tqdm\nimport torch\nimport argparse\nimport numpy as np\nfrom configparser import ConfigParser\n\nfrom .utilities.stft import TacotronSTFT\nfrom .utilities.audio_processing import read_wav_np\n\n\ndef preprocess(cfg, args):\n    filter_length = cfg.getint(\'AUDIO\', \'filter_length\')\n    hop_length = cfg.getint(\'AUDIO\', \'hop_length\')\n    win_length = cfg.getint(\'AUDIO\', \'win_length\')\n    n_mel_channels = cfg.getint(\'AUDIO\', \'n_mel_channels\')\n    sampling_rate = cfg.getint(\'AUDIO\', \'sampling_rate\')\n    mel_fmin = cfg.getfloat(\'AUDIO\', \'mel_fmin\')\n    mel_fmax = cfg.getfloat(\'AUDIO\', \'mel_fmax\')\n\n    segment_length = cfg.getint(\'AUDIO\', \'segment_length\')\n    pad_short = cfg.getint(\'AUDIO\', \'pad_short\')\n\n    stft = TacotronSTFT(filter_length=filter_length,\n                        hop_length=hop_length,\n                        win_length=win_length,\n                        n_mel_channels=n_mel_channels,\n                        sampling_rate=sampling_rate,\n                        mel_fmin=mel_fmin,\n                        mel_fmax=mel_fmax)\n\n    wav_files = glob.glob(os.path.join(args.data_path, \'**\', \'*.wav\'), recursive=True)\n\n    for wavpath in tqdm.tqdm(wav_files, desc=\'preprocess wav to mel\'):\n        sr, wav = read_wav_np(wavpath)\n        assert sr == sampling_rate, \\\n            ""sample rate mismatch. expected %d, got %d at %s"" % \\\n            (sampling_rate, sr, wavpath)\n\n        if len(wav) < segment_length + pad_short:\n            wav = np.pad(wav, (0, segment_length + pad_short - len(wav)), mode=\'constant\', constant_values=0.0)\n\n        wav = torch.from_numpy(wav).unsqueeze(0)\n        mel = stft.mel_spectrogram(wav)\n\n        melpath = wavpath.replace(\'.wav\', \'.mel\')\n        torch.save(mel, melpath)\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-n\', \'--name\', type=str, required=True,\n                        help=""name of the model"")\n    parser.add_argument(\'-d\', \'--data-path\', type=str, required=True,\n                        help=""root directory of wav files"")\n    args = parser.parse_args()\n    cfg = ConfigParser()\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    config_path = os.path.join(current_dir, \'cfg\', args.name + \'.ini\')\n    assert os.path.exists(config_path)\n    cfg.read(config_path)\n\n    preprocess(cfg, args)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
docsrc/source/conf.py,0,"b'# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n# import os\n# import sys\n# sys.path.insert(0, os.path.abspath(\'.\'))\n\nimport os\nimport sys\nimport brevitas\nimport sphinx_rtd_theme\n# sys.path.insert(0, os.path.abspath(\'../..\'))\nsys.path.insert(0, os.path.abspath(brevitas.__file__))\n# -- Project information -----------------------------------------------------\n\nproject = \'Brevitas\'\ncopyright = \'2019, Alessandro Pappalardo\'\nauthor = \'Alessandro Pappalardo\'\n\n# The full version, including alpha/beta/rc tags\nrelease = \'0.2.0-alpha\'\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'m2r\',\n    \'sphinx_rtd_theme\',\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx_autodoc_typehints\'\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# Napoleon config\nnapoleon_use_param = True\n\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\nautodoc_mock_imports = [\'_C\']\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = ""sphinx_rtd_theme""\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n'"
test/brevitas/common.py,3,"b""import hypothesis.strategies as st\nimport os\nimport pytest\nfrom packaging import version\nimport torch\n\n# Setup expected fail for Pytorch 1.2.0 and JIT Disabled\nPYT_120_JIT_CONDITION = version.parse(torch.__version__) == version.parse('1.2') and os.environ.get('PYTORCH_JIT', '1') == '0'\nPYT_120_JIT_REASON = 'Known bug to Pytorch 1.2.0 with JIT disabled'\ncheck_expected_pyt_120_fail = pytest.mark.xfail(PYT_120_JIT_CONDITION, reason=PYT_120_JIT_REASON, raises=RuntimeError)\n\n# Setup expected fail for mock and JIT Enabled for Pytorch < 1.4.0\nMOCK_JIT_CONDITION = version.parse(torch.__version__) < version.parse('1.4') and os.environ.get('PYTORCH_JIT', '1') == '1'\nMOCK_JIT_REASON = 'Cannot use Mock class with pytorch JIT enabled'\ncheck_mock_jit_pyt_l140_fail = pytest.mark.xfail(MOCK_JIT_CONDITION, reason=MOCK_JIT_REASON, raises=AttributeError)\n\n# Setup expected fail for mock and JIT Enabled for Pytorch >= 1.4.0\nMOCK_JIT_CONDITION = version.parse(torch.__version__) >= version.parse('1.4') and os.environ.get('PYTORCH_JIT', '1') == '1'\nMOCK_JIT_REASON = 'Cannot use Mock class with pytorch JIT enabled'\ncheck_mock_jit_pyt_ge140_fail = pytest.mark.xfail(MOCK_JIT_CONDITION, reason=MOCK_JIT_REASON, raises=RuntimeError)\n\ndef combine_conditions(*decs):\n    def deco(f):\n        for dec in reversed(decs):\n            f = dec(f)\n        return f\n    return deco\n\n# Set Constants\nRTOL = 0\nATOL = 1e-23\n\nFP_BIT_WIDTH = 32\n\n# Define custom type of floating point generator.\n# We are never interested in NaN and Infinity. In some case, such as when generating gradients, we may also want to\n# exclude zero. For scale factor, we want only positive numbers\nfloat_st = st.floats(allow_nan=False, allow_infinity=False, width=FP_BIT_WIDTH)\nfloat_st_nz = st.floats(allow_nan=False, allow_infinity=False, width=FP_BIT_WIDTH).filter(lambda x: x != 0.0)\nfloat_st_p = st.floats(min_value=0.0, exclude_min=True, allow_nan=False, allow_infinity=False, width=FP_BIT_WIDTH)\nlist_float_st = st.lists(float_st, min_size=1)\n\n\n# Create custom strategy for generating two lists of floats with equal size\n# This is used every time we need to test the STE property of an operation. We need an input as list of floats, and\n# a gradient as list of floats with zero filtered out\n@st.composite\ndef two_lists_equal_size(draw):\n    list_one = draw(st.lists(float_st, min_size=1))\n    size = len(list_one)\n    list_two = draw(st.lists(float_st_nz, min_size=size, max_size=size))\n    return list_one, list_two\n\n\n# Create custom strategy for generating three floating point numbers such that minimum < value < maximum\n# Used for Clamps function\n@st.composite\ndef two_ordered_numbers(draw):\n    minimum = draw(float_st)\n    maximum = draw(\n        st.floats(allow_infinity=False, allow_nan=False, width=FP_BIT_WIDTH, min_value=minimum))\n    return minimum, maximum\n\n\n# Ad-Hoc strategy for tensor clamp input\n# We need to generate three lists of the same size. Max and Min lists are created such that\n# Min[i] <= Max[i] for i =1...10, where 10 is the length of the lists (fixed for timing reasons)\n@st.composite\ndef tensor_clamp_input(draw):\n    size = 10\n    minimum_list = [0] * size\n    maximum_list = [0] * size\n    for i in range(size):\n        minimum = draw(float_st)\n        maximum = draw(\n            st.floats(allow_infinity=False, allow_nan=False, width=FP_BIT_WIDTH, min_value=minimum))\n        minimum_list[i] = minimum\n        maximum_list[i] = maximum\n    values = draw(st.lists(float_st, min_size=size, max_size=size))\n    return minimum_list, values, maximum_list\n\n\n# Same as tensor_clamp_input. In this case there is a fourth list, the Gradient List, which has the same size of the\n# other threes and that doesn't include zeroes\n@st.composite\ndef tensor_clamp_ste_input(draw):\n    size = 10\n    minimum_list = [0] * size\n    maximum_list = [0] * size\n    for i in range(size):\n        minimum = draw(float_st)\n        maximum = draw(\n            st.floats(allow_infinity=False, allow_nan=False, width=FP_BIT_WIDTH, min_value=minimum))\n        minimum_list[i] = minimum\n        maximum_list[i] = maximum\n    values = draw(st.lists(float_st, min_size=size, max_size=size))\n    grad = draw(st.lists(float_st_nz, min_size=size, max_size=size))\n    return minimum_list, values, grad, maximum_list\n"""
test/brevitas/generate_quant_input.py,1,"b'import torch\n\n\ndef generate_quant_input(shape, bit, scale_factor = 0.2, narrow_band = True, signed = True):\n    n_elements = 2**bit\n    min_value = 0\n    if narrow_band and signed:\n        min_value = 1\n    quant_input = torch.randint(min_value, 2**bit, shape)\n    if signed:\n        quant_input = quant_input - n_elements/2\n\n    return quant_input.float(), quant_input.float() * scale_factor\n'"
test/brevitas/test_act_scaling.py,2,"b'import torch\n\nfrom brevitas.core.quant import QuantType\nfrom brevitas.core.scaling import ScalingImplType\nfrom brevitas.nn import QuantReLU\nfrom common import check_expected_pyt_120_fail\n\nBIT_WIDTH = 8\nMAX_VAL = 6.0\nRANDOM_ITERS = 32\n\n\nclass TestQuantReLU:\n\n    @check_expected_pyt_120_fail\n    def test_scaling_stats_to_parameter(self):\n\n        stats_act = QuantReLU(bit_width=BIT_WIDTH,\n                              max_val=MAX_VAL,\n                              quant_type=QuantType.INT,\n                              scaling_impl_type=ScalingImplType.STATS)\n        stats_act.train()\n        for i in range(RANDOM_ITERS):\n            inp = torch.randn([8, 3, 64, 64])\n            stats_act(inp)\n\n        stats_state_dict = stats_act.state_dict()\n\n        param_act = QuantReLU(bit_width=BIT_WIDTH,\n                              max_val=MAX_VAL,\n                              quant_type=QuantType.INT,\n                              scaling_impl_type=ScalingImplType.PARAMETER)\n        param_act.load_state_dict(stats_state_dict)\n\n        stats_act.eval()\n        param_act.eval()\n\n        assert(torch.allclose(stats_act.quant_act_scale(), param_act.quant_act_scale()))\n'"
test/brevitas/test_conv1d.py,4,"b'import torch\nimport brevitas.nn.quant_conv1d as quant_conv1d\nfrom generate_quant_input import generate_quant_input\nfrom brevitas.core.quant import QuantType\nfrom common import check_expected_pyt_120_fail\n\n# Quantization parameters\nBIT = 8\nSCALE = 0.2\n\n# Absolute and Relative Tolerances\nATOL = 1E-3\nRTOL = 1E-5\n\n#Input Shape\nBATCH = 10\nIN_CHANNEL= 100\nHEIGHT = 21\n\n#Kernel/Output parameters\nOUT_CHANNEL = 200\nKERNEL = 2\nSTRIDE = 2\n\n\nclass Test1DConv:\n    @check_expected_pyt_120_fail\n    def test_float_quant(self):\n        shape = (BATCH, IN_CHANNEL, HEIGHT)\n        input_quant_int, input_quant = generate_quant_input(shape, BIT, SCALE, True, True)\n        Conv1D = quant_conv1d.QuantConv1d(in_channels=IN_CHANNEL,\n                                          out_channels=OUT_CHANNEL,\n                                          kernel_size=KERNEL,\n                                          stride=STRIDE,\n                                          weight_quant_type=QuantType.INT,\n                                          weight_bit_width=BIT,\n                                          bias=False)\n\n        results_float_quantized = Conv1D(input_quant)\n        weight_int = Conv1D.int_weight\n        bias = Conv1D.bias\n        results_int_quantized = Conv1D.conv1d(input_quant_int, weight_int.float(), bias)\n        totalScale = SCALE * Conv1D.quant_weight_scale\n        result_rescaled = results_int_quantized * totalScale\n        assert (torch.allclose(results_float_quantized, result_rescaled, atol= ATOL, rtol= RTOL))\n\n    @check_expected_pyt_120_fail\n    def test_int(self):\n        shape = (BATCH, IN_CHANNEL, HEIGHT)\n        input_quant_int, input_quant = generate_quant_input(shape, BIT, SCALE, True, True)\n        Conv1D = quant_conv1d.QuantConv1d(in_channels=IN_CHANNEL,\n                                          out_channels=OUT_CHANNEL,\n                                          kernel_size=KERNEL,\n                                          stride=STRIDE,\n                                          weight_quant_type=QuantType.INT,\n                                          weight_bit_width=BIT,\n                                          bias=False)\n\n        results_float_quantized = Conv1D(input_quant)\n        weight_int = Conv1D.int_weight\n        bias = Conv1D.bias\n        results_int_quantized = Conv1D.conv1d(input_quant_int, weight_int.float(), bias)\n        totalScale = SCALE * Conv1D.quant_weight_scale\n        result_rescaled = torch.round(results_float_quantized / totalScale)\n        assert (torch.allclose(results_int_quantized, result_rescaled, atol=ATOL, rtol=RTOL))\n\n    @check_expected_pyt_120_fail\n    def test_basic_padding(self):\n        shape = (BATCH, IN_CHANNEL, HEIGHT)\n        input_quant_int, input_quant = generate_quant_input(shape, BIT, SCALE, True, True)\n        Conv1D = quant_conv1d.QuantConv1d(in_channels=IN_CHANNEL,\n                                          out_channels=OUT_CHANNEL,\n                                          kernel_size=KERNEL,\n                                          stride=STRIDE,\n                                          weight_quant_type=QuantType.INT,\n                                          weight_bit_width=BIT,\n                                          bias=False,\n                                          padding_type=quant_conv1d.PaddingType.SAME)\n\n        results_float_quantized = Conv1D(input_quant)\n        weight_int = Conv1D.int_weight\n        bias = Conv1D.bias\n        results_int_quantized = Conv1D.conv1d(input_quant_int, weight_int.float(), bias)\n        totalScale = SCALE * Conv1D.quant_weight_scale\n        result_rescaled = results_int_quantized * totalScale\n        assert (torch.allclose(results_float_quantized, result_rescaled, atol= ATOL, rtol= RTOL))\n\n\n'"
test/brevitas/test_import.py,0,"b'# Copyright (c) 2019-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\n\ndef test_import_brevitas():\n    import brevitas\n    from brevitas.function import ops_ste\n'"
test/brevitas/test_ops.py,57,"b'# Copyright (c) 2019-     Xilinx, Inc              (Giuseppe Franco)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nfrom brevitas.function.ops import *\nfrom brevitas.function.ops_ste import *\nfrom hypothesis import given\nfrom common import *\n\nMIN_BIT_WIDTH = 1\nMAX_BIT_WIDTH = 8\n\n# When testing STE attribute, we pass an external gradient to backward and we check that it is correctly backpropagated\n# over the function\n@given(x=two_lists_equal_size())\ndef test_ste_of_round_ste(x):\n    value = x[0]\n    grad = x[1]\n    value = torch.tensor(value, requires_grad=True)\n    grad = torch.tensor(grad)\n\n    output = round_ste(value)\n    output.backward(grad, retain_graph=True)\n\n    assert torch.allclose(grad, value.grad, RTOL, ATOL)\n\n\n# Generate a list of custom floats with at least one element\n@given(x=list_float_st)\ndef test_result_of_round_ste(x):\n    x = torch.tensor(x)\n\n    output = round_ste(x)\n    expected_output = torch.round(x)\n\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n@given(x=tensor_clamp_input())\ndef test_result_of_tensor_clamp(x):\n    minimum = torch.tensor(x[0])\n    value = torch.tensor(x[1])\n    maximum = torch.tensor(x[2])\n\n    output = tensor_clamp(value, minimum, maximum)\n    expected_output = []\n    for i in range(minimum.size()[0]):\n        expected_output.append(torch.clamp(value[i], x[0][i], x[2][i]))\n    expected_output = torch.tensor(expected_output)\n\n    assert (output >= minimum).all() and (output <= maximum).all()\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n@given(x=tensor_clamp_ste_input())\ndef test_ste_of_tensor_clamp_ste(x):\n    minimum = torch.tensor(x[0])\n    value = torch.tensor(x[1], requires_grad=True)\n    grad = x[2]\n    grad = torch.tensor(grad)\n    maximum = torch.tensor(x[3])\n\n    output = tensor_clamp_ste(value, minimum, maximum)\n\n    output.backward(grad, retain_graph=True)\n    assert torch.allclose(grad, value.grad, RTOL, ATOL)\n\n\n# Test different combinations of Narrow Range (True/False) and BitWidth (1...8)\n@given(narrow_range=st.booleans(), bit_width=st.integers(min_value=MIN_BIT_WIDTH, max_value=MAX_BIT_WIDTH))\ndef test_result_of_max_uint(narrow_range, bit_width):\n    bit_width = torch.tensor(bit_width, dtype=torch.float)\n    output = max_uint(narrow_range, bit_width)\n\n    if narrow_range:\n        expected_output = (2 ** bit_width) - 2\n    else:\n        expected_output = (2 ** bit_width) - 1\n    expected_output = expected_output\n\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n# Test different combinations of Narrow Range (True/False) and BitWidth (1...8)\n@given(signed=st.booleans(), bit_width=st.integers(min_value=MIN_BIT_WIDTH, max_value=MAX_BIT_WIDTH))\ndef test_result_of_max_int(signed, bit_width):\n    bit_width = torch.tensor(bit_width, dtype=torch.float)\n    output = max_int(signed, bit_width)\n\n    if signed:\n        expected_output = (2 ** (bit_width - 1)) - 1\n    else:\n        expected_output = (2 ** bit_width) - 1\n    expected_output = expected_output\n\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n# Test different combinations of Narrow Range (True/False), Signed (True/False), and BitWidth (1...8)\n@given(narrow_range=st.booleans(), signed=st.booleans(),\n       bit_width=st.integers(min_value=MIN_BIT_WIDTH, max_value=MAX_BIT_WIDTH))\ndef test_result_of_min_int(narrow_range, signed, bit_width):\n    bit_width = torch.tensor(bit_width, dtype=torch.float)\n    output = min_int(signed, narrow_range, bit_width)\n\n    if signed and narrow_range:\n        expected_output = -(2 ** (bit_width - 1)) + 1\n    elif signed and not narrow_range:\n        expected_output = -(2 ** (bit_width - 1))\n    else:\n        expected_output = torch.tensor(0.0)\n\n    expected_output = expected_output\n\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n# Requires two floats as maximum and minimum and a tensor of float\n@given(minmax=two_ordered_numbers(), x=list_float_st)\ndef test_result_of_scalar_clamp_ste(minmax, x):\n    minimum = torch.tensor(minmax[0])\n    value = torch.tensor(x)\n    maximum = torch.tensor(minmax[1])\n\n    output = scalar_clamp_ste(value, minimum, maximum)\n    expected_output = torch.clamp(value, minmax[0], minmax[1])\n\n    assert (output >= minimum).all() and (output <= maximum).all()\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n# Same as test_result_of_scalar_clamp_ste, but with two Tensors of Float: one for the input and the other one for the\n# gradient\n@given(minmax=two_ordered_numbers(), x=two_lists_equal_size())\ndef test_ste_of_scalar_clamp_ste(minmax, x):\n    minimum = minmax[0]\n    value = torch.tensor(x[0], requires_grad=True)\n    grad = torch.tensor(x[1])\n    maximum = minmax[1]\n\n    output = scalar_clamp_ste(value, minimum, maximum)\n\n    output.backward(grad, retain_graph=True)\n    assert torch.allclose(grad, value.grad, RTOL, ATOL)\n\n\n@given(x=list_float_st)\ndef test_result_of_ceil_ste(x):\n    value = torch.tensor(x)\n    output = ceil_ste(value)\n    expected_output = torch.ceil(value)\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n@given(x=two_lists_equal_size())\ndef test_ste_of_ceil_ste(x):\n    value = torch.tensor(x[0], requires_grad=True)\n    grad = torch.tensor(x[1])\n\n    output = ceil_ste(value)\n    output.backward(grad)\n    assert torch.allclose(grad, value.grad, RTOL, ATOL)\n\n\n@given(x=list_float_st)\ndef test_result_of_floor_ste(x):\n    value = torch.tensor(x)\n    output = floor_ste(value)\n    expected_output = torch.floor(value)\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n@given(x=two_lists_equal_size())\ndef test_ste_of_floor_ste(x):\n    value = torch.tensor(x[0], requires_grad=True)\n    grad = torch.tensor(x[1])\n\n    output = floor_ste(value)\n    output.backward(grad)\n    assert torch.allclose(grad, value.grad, RTOL, ATOL)\n\n\n@given(x=list_float_st)\ndef test_result_of_binary_sign_ste(x):\n    value = torch.tensor(x)\n    output = binary_sign_ste(value)\n    positive_mask = torch.ge(value, 0.0)\n    negative_mask = torch.lt(value, 0.0)\n    expected_output = positive_mask.float() - negative_mask.float()\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n@given(x=two_lists_equal_size())\ndef test_ste_of_binary_sign_ste(x):\n    value = torch.tensor(x[0], requires_grad=True)\n    grad = torch.tensor(x[1])\n    output = binary_sign_ste(value)\n    output.backward(grad)\n    assert torch.allclose(grad, value.grad, RTOL, ATOL)\n\n\n@given(x=list_float_st)\ndef test_result_of_ternary_sign_ste(x):\n    value = torch.tensor(x)\n    output = ternary_sign_ste(value)\n    expected_output = torch.sign(value)\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n@given(x=two_lists_equal_size())\ndef test_ste_of_ternary_sign_ste(x):\n    value = torch.tensor(x[0], requires_grad=True)\n    grad = torch.tensor(x[1])\n    output = ternary_sign_ste(value)\n    output.backward(grad)\n    assert torch.allclose(grad, value.grad, RTOL, ATOL)\n'"
test/brevitas/test_quant.py,35,"b'# Copyright (c) 2019-     Xilinx, Inc              (Giuseppe Franco)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\nimport torch\nfrom brevitas.core.quant import BinaryQuant, ClampedBinaryQuant, TernaryQuant\nfrom brevitas.core.quant import PrescaledRestrictIntQuantWithInputBitWidth, PrescaledRestrictIntQuant\nfrom brevitas.core.quant import RescalingIntQuant\nfrom brevitas.core.quant import IntQuant\nfrom brevitas.function.ops import min_int, max_int\nfrom brevitas.function.ops import tensor_clamp\nfrom brevitas.core.function_wrapper import TensorClamp, RoundSte, FloorSte, CeilSte\nimport hypothesis.strategies as st\nfrom hypothesis import given\nfrom common import float_st, float_st_nz, two_lists_equal_size, list_float_st, float_st_p\nfrom common import ATOL, RTOL\nfrom common import check_expected_pyt_120_fail, check_mock_jit_pyt_l140_fail, check_mock_jit_pyt_ge140_fail\nfrom common import combine_conditions\nfrom unittest.mock import Mock\nfrom brevitas.core import ZERO_HW_SENTINEL_VALUE\nimport pytest\n\n# Constants\nMIN_BITWIDTH=2\nMAX_BITWIDTH=8\n\n# Pytest Parametrize options\nfloat_to_int_impl_scale_options = [(FloorSte, 1), (CeilSte, 1), (RoundSte, 0.5)]\n\n\n# Used for BinaryQuant and ClampedBinaryQuant. The two tests are basically identical.\ndef perform_test_binary(binary_type, inp, scaling):\n    scaling_impl_mock = Mock()\n    scaling_impl_mock.return_value = torch.tensor(scaling)\n\n    obj = binary_type(scaling_impl_mock)\n    output, _, _ = obj(inp, torch.tensor(ZERO_HW_SENTINEL_VALUE))\n    expected_output = torch.tensor([-1 * scaling, 1 * scaling])\n\n    # Check that output values match one of the possible values in expected_output\n    check_admissible_values(output, expected_output)\n    check_binary_sign(inp, output)\n\n\n# Check that the output values are one of the admissible values. If not, return False and fail the test\ndef check_admissible_values(predicted, admissible):\n    result = True\n    for value in predicted:\n        if value not in admissible:\n            result = False\n\n    assert result\n\n\n# Check that after binarization the sign match the one expected given the input value\ndef check_binary_sign(inp, predicted):\n    result = True\n    for value_input, value_predicted in zip(inp, predicted):\n        if not ((value_input >= 0 and value_predicted > 0) or (value_input < 0 and value_predicted < 0)):\n            result = False\n    assert result\n\n\n# Check that the sign is correct in ternarization. Take in account the margin introduced by the threshold\n# Threshold here is overloaded. It corresponds to threshold * scale\ndef check_ternary_sign(inp, predicted, threshold):\n    result = True\n    for value_input, value_predicted in zip(inp, predicted):\n        if (value_input.abs() < threshold and value_predicted != 0) or \\\n           (value_input > threshold and value_predicted < 0) or (value_input < threshold and value_predicted > 0):\n            result = False\n\n    assert result\n\n# Check that all values generated are either -scale or +scale. Check that the sign is coherent\n@given(x=list_float_st, scale=float_st_p)\n@combine_conditions(check_expected_pyt_120_fail, check_mock_jit_pyt_l140_fail, check_mock_jit_pyt_ge140_fail)\ndef test_of_BinaryQuant(x, scale):\n    value = torch.tensor(x)\n    scale = torch.tensor(scale)\n    perform_test_binary(BinaryQuant, value, scale)\n\n\n# Check that all values generated are either -scale or +scale. Check that the sign is coherent\n@given(x=list_float_st, scale=float_st_p)\n@combine_conditions(check_expected_pyt_120_fail, check_mock_jit_pyt_l140_fail, check_mock_jit_pyt_ge140_fail)\ndef test_of_ClampedBinaryQuant(x, scale):\n    value = torch.tensor(x)\n    scale = torch.tensor(scale)\n    perform_test_binary(ClampedBinaryQuant, value, scale)\n\n\n# Check that all values generated are either -scale, +scale or 0. Check that the sign is coherent\n@given(x=list_float_st, threshold=st.floats(min_value=0.0, max_value=1.0), scale=float_st_p)\n@combine_conditions(check_expected_pyt_120_fail, check_mock_jit_pyt_l140_fail, check_mock_jit_pyt_ge140_fail)\ndef test_of_TernaryQuant(x, threshold, scale):\n    value = torch.tensor(x)\n\n    scale_impl_mock = Mock()\n    scale_impl_mock.return_value = torch.tensor(scale)\n\n    obj = TernaryQuant(scale_impl_mock, threshold)\n    output, _, _ = obj(value, torch.tensor(ZERO_HW_SENTINEL_VALUE))\n    expected_output = torch.tensor([-1 * scale, 1 * scale, 0])\n\n    check_admissible_values(output, expected_output)\n    check_ternary_sign(value, output, scale * threshold)\n\n\n# Propriety tested:\n#  - All input values, once converted to int, are in the admissible range of integers given by the combination of\n#    sign, narrow range and bit_width\n#  - After apply IntQuant, the result is in a certain range with respected to the clamped floating point version.\n#    The range is determined by scale, and varies according to the type of float_to_int function used\n# Assumption:\n#  - TensorClamp() is used as tensor_clamp_impl. The alternative would be TensorClampSte() whose only difference lies in\n#    backpropagation of the gradient, which is something we are not interested in here.\n#  - float_to_int implementation is a stripped down version of RestrictValue object for clarity and easiness of testing.\n@given(x=list_float_st, narrow_range=st.booleans(), signed=st.booleans(),\n       bit_width=st.integers(min_value=MIN_BITWIDTH, max_value=MAX_BITWIDTH),\n       scale=float_st_p, int_scale=st.integers(min_value=1, max_value=256))\n@pytest.mark.parametrize(\'float_to_int_impl, scale_multiplier\', float_to_int_impl_scale_options)\n@combine_conditions(check_expected_pyt_120_fail, check_mock_jit_pyt_l140_fail, check_mock_jit_pyt_ge140_fail)\ndef test_IntQuant(x, narrow_range, signed, bit_width, scale, int_scale, float_to_int_impl, scale_multiplier):\n    float_to_int_impl_mock = Mock()\n    tensor_clamp_impl = TensorClamp()\n\n    value = torch.tensor(x)\n    bit_width = torch.tensor(bit_width, dtype=torch.float)\n    scale = torch.tensor(scale)\n    int_scale = torch.tensor(int_scale)\n\n    tol = scale * scale_multiplier\n    float_to_int_impl_mock.side_effect = float_to_int_impl()\n\n    obj = IntQuant(narrow_range=narrow_range, signed=signed, float_to_int_impl=float_to_int_impl_mock,\n                   tensor_clamp_impl=tensor_clamp_impl)\n    output = obj(scale, int_scale, bit_width, value)\n\n    min_value = int(min_int(signed, narrow_range, bit_width))\n    max_value = int(max_int(signed, bit_width))\n    admissible_values = [x for x in range(min_value, max_value+1)]\n\n    value = (value / scale) * int_scale\n    expected_output = tensor_clamp(value, min_val=min_int(signed, narrow_range, bit_width),\n                                   max_val=max_int(signed, bit_width))\n    expected_output = (expected_output / int_scale) * scale\n\n    int_output = obj.to_int(scale, int_scale, bit_width, value)\n\n    # The assert is performed internally check_admissible_values\n    check_admissible_values(int_output, admissible_values)\n    assert torch.allclose(expected_output, output, RTOL, tol)\n\n\n# Propriety tested:\n#  - This function is just a wrapper around IntQuant. For this reason, we are testing only the interface\n# Assumption:\n#  - IntQuant doesn\'t perform any real operation and behaves as an identity.\n#  - Since IntQuant is created inside the object, we assume that IntQuant is correct, and create an ""expected""\n#  - (i.e. correct by definition) version for generating the expected_output. IntQuant is tested in an apposite function\n#  - msb_clamp_bit_width returns a random integer between 2 and 8\n@given(x=list_float_st, narrow_range=st.booleans(), signed=st.booleans(),\n       bit_width=st.integers(min_value=MIN_BITWIDTH, max_value=MAX_BITWIDTH), scale=float_st_p)\n@combine_conditions(check_expected_pyt_120_fail, check_mock_jit_pyt_l140_fail, check_mock_jit_pyt_ge140_fail)\ndef test_PrescaledRestrictIntQuantWithInputBitWidth(x, narrow_range, signed, scale, bit_width):\n    value = torch.tensor(x)\n    scale = torch.tensor(scale)\n    tensor_clamp_impl = TensorClamp()\n\n    msb_clamp_bitwidth_mock = Mock()\n    msb_clamp_bitwidth_mock.return_value = torch.tensor(bit_width, dtype=torch.float)\n    float_to_int_impl_mock = Mock()\n    float_to_int_impl_mock.side_effect = (lambda y: y)\n\n    obj = PrescaledRestrictIntQuantWithInputBitWidth(narrow_range=narrow_range, signed=signed,\n                                                     tensor_clamp_impl=tensor_clamp_impl,\n                                                     msb_clamp_bit_width_impl=msb_clamp_bitwidth_mock,\n                                                     float_to_int_impl=float_to_int_impl_mock)\n\n    output, scale, bit_width = obj(value, scale, bit_width, torch.tensor(ZERO_HW_SENTINEL_VALUE))\n\n    expected_IntQuant = IntQuant(signed=signed, narrow_range=narrow_range, tensor_clamp_impl=tensor_clamp_impl,\n                                 float_to_int_impl=float_to_int_impl_mock)\n    expected_output = expected_IntQuant(scale, torch.tensor(ZERO_HW_SENTINEL_VALUE) + 1, bit_width, value)\n\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n# Propriety tested:\n#  - This function is just a wrapper around IntQuant. For this reason, we are testing only the interface\n# Assumption:\n#  - IntQuant doesn\'t perform any real operation and behaves as an identity.\n#  - Since IntQuant is created inside the object, we assume that IntQuant is correct, and create an ""expected""\n#    (i.e. correct by definition) version for genereting the expected_output. IntQuant is tested in an apposite function\n#  - msb_clamp_bit_width returns a random integer between 2 and 8\n@given(x=list_float_st, narrow_range=st.booleans(), signed=st.booleans(),\n       bit_width=st.integers(min_value=MIN_BITWIDTH, max_value=MAX_BITWIDTH), scale=float_st_p)\n@combine_conditions(check_expected_pyt_120_fail, check_mock_jit_pyt_l140_fail, check_mock_jit_pyt_ge140_fail)\ndef test_PrescaledRestrictIntQuanth(x, narrow_range, signed, scale, bit_width):\n    value = torch.tensor(x)\n    scale = torch.tensor(scale)\n    bit_width =torch.tensor(bit_width, dtype=torch.float)\n    tensor_clamp_impl = TensorClamp()\n\n    msb_clamp_bitwidth_mock = Mock()\n    msb_clamp_bitwidth_mock.return_value =bit_width\n    float_to_int_impl_mock = Mock()\n    float_to_int_impl_mock.side_effect = (lambda y: y)\n\n    obj = PrescaledRestrictIntQuant(narrow_range=narrow_range, signed=signed,\n                                    tensor_clamp_impl=tensor_clamp_impl,\n                                    msb_clamp_bit_width_impl=msb_clamp_bitwidth_mock,\n                                    float_to_int_impl=float_to_int_impl_mock)\n\n    output, scale, bit_width = obj(value, scale, torch.tensor(ZERO_HW_SENTINEL_VALUE))\n\n    expected_IntQuant = IntQuant(signed=signed, narrow_range=narrow_range, tensor_clamp_impl=tensor_clamp_impl,\n                                 float_to_int_impl=float_to_int_impl_mock)\n    expected_output = expected_IntQuant(scale, torch.tensor(ZERO_HW_SENTINEL_VALUE) + 1, bit_width, value)\n\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n\n\n# Propriety tested:\n#  - This function is just a wrapper around IntQuant. For this reason, we are testing the interface\n#  - In addition, we test that the scale factor generated is correct with what we expect.\n# Assumption:\n#  - IntQuant doesn\'t perform any real operation and behaves as an identity.\n#  - Since IntQuant is created inside the object, we assume that IntQuant is correct, and create an ""expected""\n#  - (i.e. correct by definition) version for genereting the expected_output. IntQuant is tested in an apposite function\n#  - Runtime is default to true, since it has no effect in the generation of the scale factor (which is random)\n#  - msb_clamp_bit_width returns a random integer between 2 and 8\n@given(x=list_float_st, narrow_range=st.booleans(), signed=st.booleans(),\n       bit_width=st.integers(min_value=MIN_BITWIDTH, max_value=MAX_BITWIDTH), scale=float_st_p,\n       int_scale=st.integers(min_value=1, max_value=256))\n@combine_conditions(check_expected_pyt_120_fail, check_mock_jit_pyt_l140_fail, check_mock_jit_pyt_ge140_fail)\ndef test_RescalingIntQuant(x, narrow_range, signed, scale, int_scale, bit_width):\n    value = torch.tensor(x)\n    scale = torch.tensor(scale)\n    bit_width = torch.tensor(bit_width, dtype=torch.float)\n    int_scale = torch.tensor(int_scale, dtype=torch.float)\n    tensor_clamp_impl = TensorClamp()\n\n    msb_clamp_bitwidth_mock = Mock()\n    msb_clamp_bitwidth_mock.return_value = bit_width\n    float_to_int_impl_mock = Mock()\n    float_to_int_impl_mock.side_effect = (lambda y: y)\n    int_scaling_impl_mock = Mock()\n    int_scaling_impl_mock.return_value = int_scale\n    scaling_impl = Mock()\n    scaling_impl.return_value = scale\n\n    obj = RescalingIntQuant(narrow_range=narrow_range, signed=signed,\n                            runtime=True,\n                            tensor_clamp_impl=tensor_clamp_impl,\n                            float_to_int_impl=float_to_int_impl_mock,\n                            int_scaling_impl=int_scaling_impl_mock,\n                            msb_clamp_bit_width_impl=msb_clamp_bitwidth_mock,\n                            scaling_impl=scaling_impl)\n\n    output, scale_out, bit_width = obj(value, torch.tensor(ZERO_HW_SENTINEL_VALUE))\n\n    expected_IntQuant = IntQuant(signed=signed, narrow_range=narrow_range, tensor_clamp_impl=tensor_clamp_impl,\n                                 float_to_int_impl=float_to_int_impl_mock)\n    expected_output = expected_IntQuant(scale, int_scale, bit_width, value)\n    expected_scale = scale/int_scale\n    assert torch.allclose(expected_output, output, RTOL, ATOL)\n    assert torch.allclose(expected_scale, scale_out, RTOL, ATOL)\n'"
test/brevitas/test_transposed_conv1d.py,5,"b'import torch\nimport brevitas.nn.quant_convtranspose1d as quant_convtranspose1d\nfrom generate_quant_input import generate_quant_input\nfrom brevitas.core.quant import QuantType\nimport random\nimport numpy as np\nfrom common import check_expected_pyt_120_fail\n\n# Quantization parameters\nBIT = 8\nSCALE = 0.2\n\n# Absolute and Relative Tolerances\nATOL = 1E-3\nRTOL = 1E-5\n\n#Input Shape\nBATCH = 10\nIN_CHANNEL= 100\nHEIGHT = 500\n\n#Kernel/Output parameters\nOUT_CHANNEL = 200\nKERNEL = 2\nSTRIDE = 2\n\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\n\nclass Test1DTranspConv:\n\n    @check_expected_pyt_120_fail\n    def test_float_quant(self):\n        shape = (BATCH, IN_CHANNEL, HEIGHT)\n        input_quant_int, input_quant = generate_quant_input(shape, BIT, SCALE, True, True)\n        ConvTranspose1d = quant_convtranspose1d.QuantConvTranspose1d(in_channels=IN_CHANNEL,\n                                          out_channels=OUT_CHANNEL,\n                                          kernel_size=KERNEL,\n                                          stride=STRIDE,\n                                          weight_quant_type=QuantType.INT,\n                                          weight_bit_width=BIT,\n                                          bias=False)\n\n        results_float_quantized = ConvTranspose1d(input_quant)\n        weight_int = ConvTranspose1d.int_weight\n        bias = ConvTranspose1d.bias\n        output_padding = ConvTranspose1d.compute_output_padding(input_quant_int, None)\n        results_int_quantized = ConvTranspose1d.conv_transpose1d(input_quant_int, weight_int.float(), bias, output_padding)\n        totalScale = SCALE * ConvTranspose1d.quant_weight_scale\n        result_rescaled = results_int_quantized * totalScale\n        # print(torch.norm(results_float_quantized- result_rescaled))\n        assert (torch.allclose(results_float_quantized, result_rescaled, atol= ATOL, rtol= RTOL))\n\n    @check_expected_pyt_120_fail\n    def test_int(self):\n        shape = (BATCH, IN_CHANNEL, HEIGHT)\n        input_quant_int, input_quant = generate_quant_input(shape, BIT, SCALE, True, True)\n        ConvTranspose1d = quant_convtranspose1d.QuantConvTranspose1d(in_channels=IN_CHANNEL,\n\n                                          out_channels=OUT_CHANNEL,\n                                          kernel_size=KERNEL,\n                                          stride=STRIDE,\n                                          weight_quant_type=QuantType.INT,\n                                          weight_bit_width=BIT,\n                                          bias=False)\n\n        results_float_quantized = ConvTranspose1d(input_quant)\n        weight_int = ConvTranspose1d.int_weight\n        bias = ConvTranspose1d.bias\n        output_padding = ConvTranspose1d.compute_output_padding(input_quant_int, None)\n        results_int_quantized = ConvTranspose1d.conv_transpose1d(input_quant_int, weight_int.float(), bias, output_padding)\n        totalScale = SCALE * ConvTranspose1d.quant_weight_scale\n        result_rescaled = torch.round(results_float_quantized / totalScale)\n        assert (torch.allclose(results_int_quantized, result_rescaled, atol=ATOL, rtol=RTOL))\n\n'"
test/brevitas_examples/test_import.py,0,"b'# Copyright (c) 2019-     Xilinx, Inc              (Alessandro Pappalardo)\n# Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n# Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n# Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n# Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n# Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n# Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n# Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n# Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n# Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n\n# 3. Neither the names of Xilinx, Facebook, Deepmind Technologies, NYU,\n#    NEC Laboratories America and IDIAP Research Institute nor the names\n#    of its contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\n\ndef test_import_bnn_pynq():\n    from brevitas_examples.bnn_pynq import (\n        cnv_1w1a, cnv_1w2a, cnv_2w2a,\n        sfc_1w1a, sfc_1w2a, sfc_2w2a,\n        tfc_1w1a, tfc_1w2a, tfc_2w2a,\n        lfc_1w1a, lfc_1w2a)\n\n\ndef test_import_image_classification():\n    from brevitas_examples.imagenet_classification import (\n        quant_mobilenet_v1_4b,\n        quant_proxylessnas_mobile14_hadamard_4b,\n        quant_proxylessnas_mobile14_4b5b,\n        quant_proxylessnas_mobile14_4b)\n\n\ndef test_import_tts():\n    from brevitas_examples.text_to_speech import quant_melgan_8b\n\n\ndef test_import_stt():\n    from brevitas_examples.speech_to_text import (\n        quant_quartznet_pertensorscaling_8b,\n        quant_quartznet_perchannelscaling_8b,\n        quant_quartznet_perchannelscaling_4b\n    )'"
test/brevitas_examples/test_pretrained_accuracy.py,0,"b'import logging\nfrom urllib import request\n\nimport pytest\nfrom brevitas_examples.bnn_pynq.bnn_pynq_train import main\nfrom brevitas_examples.bnn_pynq.models import get_model_cfg\n\n\n@pytest.mark.parametrize(""model"", [""TFC"", ""SFC"", ""LFC""])\n@pytest.mark.parametrize(""weight_bit_width"", [1, 2])\n@pytest.mark.parametrize(""act_bit_width"", [1, 2])\ndef test_bnn_pynq_fc_pretrained_accuracy(caplog, model, weight_bit_width, act_bit_width):\n    if model == ""LFC"" and weight_bit_width == 2 and act_bit_width == 2:\n        pytest.skip(""No pretrained LFC_W2A2 present."")\n    if weight_bit_width > act_bit_width:\n        pytest.skip(""No weight_bit_width > act_bit_width cases."")\n\n    caplog.set_level(logging.INFO)\n    network = f""{model}_{weight_bit_width}W{act_bit_width}A""\n    cfg = get_model_cfg(network)\n    eval_log_url = cfg.get(\'MODEL\', \'EVAL_LOG\')\n    main([\'--pretrained\', \'--network\', network, \'--evaluate\', \'--gpus\', \'None\'])\n    with request.urlopen(eval_log_url) as r:\n        log_list = [l[l.index(\'Prec@1\'):] for l in caplog.text.splitlines()]\n        reference_prec_list = [l[l.index(\'Prec@1\'):] for l in r.read().decode(\'utf-8\').splitlines()]\n        assert log_list == reference_prec_list'"
brevitas_examples/bnn_pynq/cfg/__init__.py,0,b''
brevitas_examples/bnn_pynq/models/CNV.py,3,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport torch\nfrom torch.nn import Module, ModuleList, BatchNorm2d, MaxPool2d, BatchNorm1d\nfrom .tensor_norm import TensorNorm\nfrom .common import get_quant_conv2d, get_quant_linear, get_act_quant, get_quant_type\nfrom brevitas.nn import QuantConv2d, QuantHardTanh, QuantLinear\n\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType\n\n\n# QuantConv2d configuration\nCNV_OUT_CH_POOL = [(64, False), (64, True), (128, False), (128, True), (256, False), (256, False)]\n\n# Intermediate QuantLinear configuration\nINTERMEDIATE_FC_PER_OUT_CH_SCALING = False\nINTERMEDIATE_FC_FEATURES = [(256, 512), (512, 512)]\n\n# Last QuantLinear configuration\nLAST_FC_IN_FEATURES = 512\nLAST_FC_PER_OUT_CH_SCALING = False\n\n# MaxPool2d configuration\nPOOL_SIZE = 2\n\n\nclass CNV(Module):\n\n    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None, in_bit_width=None, in_ch=3):\n        super(CNV, self).__init__()\n\n        weight_quant_type = get_quant_type(weight_bit_width)\n        act_quant_type = get_quant_type(act_bit_width)\n        in_quant_type = get_quant_type(in_bit_width)\n        max_in_val = 1-2**(-7) # for Q1.7 input format\n        self.conv_features = ModuleList()\n        self.linear_features = ModuleList()\n\n        self.conv_features.append(QuantHardTanh(bit_width=in_bit_width,\n                                                quant_type=in_quant_type,\n                                                max_val=max_in_val,\n                                                restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n                                                scaling_impl_type=ScalingImplType.CONST))\n\n        for out_ch, is_pool_enabled in CNV_OUT_CH_POOL:\n            self.conv_features.append(get_quant_conv2d(in_ch=in_ch,\n                                                       out_ch=out_ch,\n                                                       bit_width=weight_bit_width,\n                                                       quant_type=weight_quant_type))\n            in_ch = out_ch\n            self.conv_features.append(BatchNorm2d(in_ch, eps=1e-4))\n            self.conv_features.append(get_act_quant(act_bit_width, act_quant_type))\n            if is_pool_enabled:\n                self.conv_features.append(MaxPool2d(kernel_size=2))\n\n        for in_features, out_features in INTERMEDIATE_FC_FEATURES:\n            self.linear_features.append(get_quant_linear(in_features=in_features,\n                                                         out_features=out_features,\n                                                         per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,\n                                                         bit_width=weight_bit_width,\n                                                         quant_type=weight_quant_type))\n            self.linear_features.append(BatchNorm1d(out_features, eps=1e-4))\n            self.linear_features.append(get_act_quant(act_bit_width, act_quant_type))\n        \n        self.linear_features.append(get_quant_linear(in_features=LAST_FC_IN_FEATURES,\n                                   out_features=num_classes,\n                                   per_out_ch_scaling=LAST_FC_PER_OUT_CH_SCALING,\n                                   bit_width=weight_bit_width,\n                                   quant_type=weight_quant_type))\n        self.linear_features.append(TensorNorm())\n        \n        for m in self.modules():\n          if isinstance(m, QuantConv2d) or isinstance(m, QuantLinear):\n            torch.nn.init.uniform_(m.weight.data, -1, 1)\n\n\n    def clip_weights(self, min_val, max_val):\n        for mod in self.conv_features:\n            if isinstance(mod, QuantConv2d):\n                mod.weight.data.clamp_(min_val, max_val)\n        for mod in self.linear_features:\n            if isinstance(mod, QuantLinear):\n                mod.weight.data.clamp_(min_val, max_val)\n\n    def forward(self, x):\n        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n        for mod in self.conv_features:\n            x = mod(x)\n        x = x.view(x.shape[0], -1)\n        for mod in self.linear_features:\n            x = mod(x)\n        return x\n\n\ndef cnv(cfg):\n    weight_bit_width = cfg.getint(\'QUANT\', \'WEIGHT_BIT_WIDTH\')\n    act_bit_width = cfg.getint(\'QUANT\', \'ACT_BIT_WIDTH\')\n    in_bit_width = cfg.getint(\'QUANT\', \'IN_BIT_WIDTH\')\n    num_classes = cfg.getint(\'MODEL\', \'NUM_CLASSES\')\n    in_channels = cfg.getint(\'MODEL\', \'IN_CHANNELS\')\n    net = CNV(weight_bit_width=weight_bit_width,\n              act_bit_width=act_bit_width,\n              in_bit_width=in_bit_width,\n              num_classes=num_classes,\n              in_ch=in_channels)\n    return net\n\n'"
brevitas_examples/bnn_pynq/models/LFC.py,3,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom functools import reduce\nfrom operator import mul\n\nfrom torch.nn import Module, ModuleList, BatchNorm1d, Dropout\nimport torch\n\nfrom .common import get_quant_linear, get_act_quant, get_quant_type, QuantLinear\n\nFC_OUT_FEATURES = [1024, 1024, 1024]\nINTERMEDIATE_FC_PER_OUT_CH_SCALING = True\nLAST_FC_PER_OUT_CH_SCALING = False\nIN_DROPOUT = 0.2\nHIDDEN_DROPOUT = 0.2\n\n\nclass LFC(Module):\n\n    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,\n                 in_bit_width=None, in_ch=1, in_features=(28, 28)):\n        super(LFC, self).__init__()\n\n        weight_quant_type = get_quant_type(weight_bit_width)\n        act_quant_type = get_quant_type(act_bit_width)\n        in_quant_type = get_quant_type(in_bit_width)\n\n        self.features = ModuleList()\n        self.features.append(get_act_quant(in_bit_width, in_quant_type))\n        self.features.append(Dropout(p=IN_DROPOUT))\n        in_features = reduce(mul, in_features)\n        for out_features in FC_OUT_FEATURES:\n            self.features.append(get_quant_linear(in_features=in_features,\n                                                  out_features=out_features,\n                                                  per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,\n                                                  bit_width=weight_bit_width,\n                                                  quant_type=weight_quant_type))\n            in_features = out_features\n            self.features.append(BatchNorm1d(num_features=in_features))\n            self.features.append(get_act_quant(act_bit_width, act_quant_type))\n            self.features.append(Dropout(p=HIDDEN_DROPOUT))\n        self.features.append(get_quant_linear(in_features=in_features,\n                                   out_features=num_classes,\n                                   per_out_ch_scaling=LAST_FC_PER_OUT_CH_SCALING,\n                                   bit_width=weight_bit_width,\n                                   quant_type=weight_quant_type))\n        self.features.append(BatchNorm1d(num_features=num_classes))\n\n        for m in self.modules():\n          if isinstance(m, QuantLinear):\n            torch.nn.init.uniform_(m.weight.data, -1, 1)\n\n    def clip_weights(self, min_val, max_val):\n        for mod in self.features:\n            if isinstance(mod, QuantLinear):\n                mod.weight.data.clamp_(min_val, max_val)\n    \n    def forward(self, x):\n        x = x.view(x.shape[0], -1)\n        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n        for mod in self.features:\n            x = mod(x)\n        return x\n\n\ndef lfc(cfg):\n    weight_bit_width = cfg.getint(\'QUANT\', \'WEIGHT_BIT_WIDTH\')\n    act_bit_width = cfg.getint(\'QUANT\', \'ACT_BIT_WIDTH\')\n    in_bit_width = cfg.getint(\'QUANT\', \'IN_BIT_WIDTH\')\n    num_classes = cfg.getint(\'MODEL\', \'NUM_CLASSES\')\n    in_channels = cfg.getint(\'MODEL\', \'IN_CHANNELS\')\n    net = LFC(weight_bit_width=weight_bit_width,\n              act_bit_width=act_bit_width,\n              in_bit_width=in_bit_width,\n              num_classes=num_classes,\n              in_ch=in_channels)\n    return net'"
brevitas_examples/bnn_pynq/models/SFC.py,3,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom functools import reduce\nfrom operator import mul\n\nfrom torch.nn import Module, ModuleList, BatchNorm1d, Dropout\nimport torch\n\nfrom .common import get_quant_linear, get_act_quant, get_quant_type, QuantLinear\n\nFC_OUT_FEATURES = [256, 256, 256]\nINTERMEDIATE_FC_PER_OUT_CH_SCALING = True\nLAST_FC_PER_OUT_CH_SCALING = False\nIN_DROPOUT = 0.2\nHIDDEN_DROPOUT = 0.2\n\n\nclass SFC(Module):\n\n    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,\n                 in_bit_width=None, in_ch=1, in_features=(28, 28)):\n        super(SFC, self).__init__()\n\n        weight_quant_type = get_quant_type(weight_bit_width)\n        act_quant_type = get_quant_type(act_bit_width)\n        in_quant_type = get_quant_type(in_bit_width)\n\n        self.features = ModuleList()\n        self.features.append(get_act_quant(in_bit_width, in_quant_type))\n        self.features.append(Dropout(p=IN_DROPOUT))\n        in_features = reduce(mul, in_features)\n        for out_features in FC_OUT_FEATURES:\n            self.features.append(get_quant_linear(in_features=in_features,\n                                                  out_features=out_features,\n                                                  per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,\n                                                  bit_width=weight_bit_width,\n                                                  quant_type=weight_quant_type))\n            in_features = out_features\n            self.features.append(BatchNorm1d(num_features=in_features))\n            self.features.append(get_act_quant(act_bit_width, act_quant_type))\n            self.features.append(Dropout(p=HIDDEN_DROPOUT))\n        self.features.append(get_quant_linear(in_features=in_features,\n                                   out_features=num_classes,\n                                   per_out_ch_scaling=LAST_FC_PER_OUT_CH_SCALING,\n                                   bit_width=weight_bit_width,\n                                   quant_type=weight_quant_type))\n        self.features.append(BatchNorm1d(num_features=num_classes))\n\n        for m in self.modules():\n          if isinstance(m, QuantLinear):\n            torch.nn.init.uniform_(m.weight.data, -1, 1)\n\n    def clip_weights(self, min_val, max_val):\n        for mod in self.features:\n            if isinstance(mod, QuantLinear):\n                mod.weight.data.clamp_(min_val, max_val)\n    \n    def forward(self, x):\n        x = x.view(x.shape[0], -1)\n        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n        for mod in self.features:\n            x = mod(x)\n        return x\n\n\ndef sfc(cfg):\n    weight_bit_width = cfg.getint(\'QUANT\', \'WEIGHT_BIT_WIDTH\')\n    act_bit_width = cfg.getint(\'QUANT\', \'ACT_BIT_WIDTH\')\n    in_bit_width = cfg.getint(\'QUANT\', \'IN_BIT_WIDTH\')\n    num_classes = cfg.getint(\'MODEL\', \'NUM_CLASSES\')\n    in_channels = cfg.getint(\'MODEL\', \'IN_CHANNELS\')\n    net = SFC(weight_bit_width=weight_bit_width,\n              act_bit_width=act_bit_width,\n              in_bit_width=in_bit_width,\n              num_classes=num_classes,\n              in_ch=in_channels)\n    return net'"
brevitas_examples/bnn_pynq/models/TFC.py,3,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom functools import reduce\nfrom operator import mul\n\nfrom torch.nn import Module, ModuleList, BatchNorm1d, Dropout\nimport torch\n\nfrom .common import get_quant_linear, get_act_quant, get_quant_type, QuantLinear\n\nFC_OUT_FEATURES = [64, 64, 64]\nINTERMEDIATE_FC_PER_OUT_CH_SCALING = True\nLAST_FC_PER_OUT_CH_SCALING = False\nIN_DROPOUT = 0.2\nHIDDEN_DROPOUT = 0.2\n\n\nclass TFC(Module):\n\n    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,\n                 in_bit_width=None, in_ch=1, in_features=(28, 28)):\n        super(TFC, self).__init__()\n\n        weight_quant_type = get_quant_type(weight_bit_width)\n        act_quant_type = get_quant_type(act_bit_width)\n        in_quant_type = get_quant_type(in_bit_width)\n\n        self.features = ModuleList()\n        self.features.append(get_act_quant(in_bit_width, in_quant_type))\n        self.features.append(Dropout(p=IN_DROPOUT))\n        in_features = reduce(mul, in_features)\n        for out_features in FC_OUT_FEATURES:\n            self.features.append(get_quant_linear(in_features=in_features,\n                                                  out_features=out_features,\n                                                  per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,\n                                                  bit_width=weight_bit_width,\n                                                  quant_type=weight_quant_type))\n            in_features = out_features\n            self.features.append(BatchNorm1d(num_features=in_features))\n            self.features.append(get_act_quant(act_bit_width, act_quant_type))\n            self.features.append(Dropout(p=HIDDEN_DROPOUT))\n        self.features.append(get_quant_linear(in_features=in_features,\n                                   out_features=num_classes,\n                                   per_out_ch_scaling=LAST_FC_PER_OUT_CH_SCALING,\n                                   bit_width=weight_bit_width,\n                                   quant_type=weight_quant_type))\n        self.features.append(BatchNorm1d(num_features=num_classes))\n\n        for m in self.modules():\n          if isinstance(m, QuantLinear):\n            torch.nn.init.uniform_(m.weight.data, -1, 1)\n\n    def clip_weights(self, min_val, max_val):\n        for mod in self.features:\n            if isinstance(mod, QuantLinear):\n                mod.weight.data.clamp_(min_val, max_val)\n    \n    def forward(self, x):\n        x = x.view(x.shape[0], -1)\n        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n        for mod in self.features:\n            x = mod(x)\n        return x\n\n\ndef tfc(cfg):\n    weight_bit_width = cfg.getint(\'QUANT\', \'WEIGHT_BIT_WIDTH\')\n    act_bit_width = cfg.getint(\'QUANT\', \'ACT_BIT_WIDTH\')\n    in_bit_width = cfg.getint(\'QUANT\', \'IN_BIT_WIDTH\')\n    num_classes = cfg.getint(\'MODEL\', \'NUM_CLASSES\')\n    in_channels = cfg.getint(\'MODEL\', \'IN_CHANNELS\')\n    net = TFC(weight_bit_width=weight_bit_width,\n              act_bit_width=act_bit_width,\n              in_bit_width=in_bit_width,\n              num_classes=num_classes,\n              in_ch=in_channels)\n    return net\n'"
brevitas_examples/bnn_pynq/models/__init__.py,0,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport os\nfrom configparser import ConfigParser\n\nimport torch\nfrom torch import hub\n\n__all__ = [\'cnv_1w1a\', \'cnv_1w2a\', \'cnv_2w2a\',\n           \'sfc_1w1a\', \'sfc_1w2a\', \'sfc_2w2a\',\n           \'tfc_1w1a\', \'tfc_1w2a\', \'tfc_2w2a\',\n           \'lfc_1w1a\', \'lfc_1w2a\']\n\nfrom .CNV import cnv\nfrom .LFC import lfc\nfrom .TFC import tfc\nfrom .SFC import sfc\n\nmodel_impl = {\n    \'CNV\': cnv,\n    \'LFC\': lfc,\n    \'TFC\': tfc,\n    \'SFC\': sfc\n}\n\ndef get_model_cfg(name):\n    cfg = ConfigParser()\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    config_path = os.path.join(current_dir, \'..\', \'cfg\', name.lower() + \'.ini\')\n    assert os.path.exists(config_path)\n    cfg.read(config_path)\n    return cfg\n\ndef model_with_cfg(name, pretrained):\n    cfg = get_model_cfg(name)\n    arch = cfg.get(\'MODEL\', \'ARCH\')\n    model = model_impl[arch](cfg)\n    if pretrained:\n        checkpoint = cfg.get(\'MODEL\', \'PRETRAINED_URL\')\n        state_dict = hub.load_state_dict_from_url(checkpoint, progress=True, map_location=\'cpu\')\n        model.load_state_dict(state_dict, strict=True)\n    return model, cfg\n\n\ndef cnv_1w1a(pretrained=True):\n    model, _ = model_with_cfg(\'cnv_1w1a\', pretrained)\n    return model\n\n\ndef cnv_1w2a(pretrained=True):\n    model, _ = model_with_cfg(\'cnv_1w2a\', pretrained)\n    return model\n\n\ndef cnv_2w2a(pretrained=True):\n    model, _ = model_with_cfg(\'cnv_2w2a\', pretrained)\n    return model\n\n\ndef sfc_1w1a(pretrained=True):\n    model, _ = model_with_cfg(\'sfc_1w1a\', pretrained)\n    return model\n\n\ndef sfc_1w2a(pretrained=True):\n    model, _ = model_with_cfg(\'sfc_1w2a\', pretrained)\n    return model\n\n\ndef sfc_2w2a(pretrained=True):\n    model, _ = model_with_cfg(\'sfc_2w2a\', pretrained)\n    return model\n\n\ndef tfc_1w1a(pretrained=True):\n    model, _ = model_with_cfg(\'tfc_1w1a\', pretrained)\n    return model\n\n\ndef tfc_1w2a(pretrained=True):\n    model, _ = model_with_cfg(\'tfc_1w2a\', pretrained)\n    return model\n\n\ndef tfc_2w2a(pretrained=True):\n    model, _ = model_with_cfg(\'tfc_2w2a\', pretrained)\n    return model\n\n\ndef lfc_1w1a(pretrained=True):\n    model, _ = model_with_cfg(\'lfc_1w1a\', pretrained)\n    return model\n\n\ndef lfc_1w2a(pretrained=True):\n    model, _ = model_with_cfg(\'lfc_1w2a\', pretrained)\n    return model\n\n\n'"
brevitas_examples/bnn_pynq/models/common.py,0,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom brevitas.core.bit_width import BitWidthImplType\nfrom brevitas.core.quant import QuantType\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType\nfrom brevitas.nn import QuantConv2d, QuantHardTanh, QuantLinear\n\n# Quant common\nBIT_WIDTH_IMPL_TYPE = BitWidthImplType.CONST\nSCALING_VALUE_TYPE = RestrictValueType.LOG_FP\nNARROW_RANGE_ENABLED = True\n\n# Weight quant common\nBIAS_ENABLED = False\nWEIGHT_SCALING_IMPL_TYPE = ScalingImplType.CONST\nWEIGHT_SCALING_CONST = 1.0\n\n# QuantHardTanh configuration\nHARD_TANH_MIN = -1.0\nHARD_TANH_MAX = 1.0\nACT_PER_OUT_CH_SCALING = False\nACT_SCALING_IMPL_TYPE = ScalingImplType.CONST\n\n# QuantConv2d configuration\nKERNEL_SIZE = 3\nCONV_PER_OUT_CH_SCALING = False\n\n\ndef get_quant_type(bit_width):\n    if bit_width is None:\n        return QuantType.FP\n    elif bit_width == 1:\n        return QuantType.BINARY\n    else:\n        return QuantType.INT\n\n\ndef get_act_quant(act_bit_width, act_quant_type):  \n    return QuantHardTanh(quant_type=act_quant_type,\n                         bit_width=act_bit_width,\n                         bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n                         min_val=HARD_TANH_MIN,\n                         max_val=HARD_TANH_MAX,\n                         scaling_impl_type=ACT_SCALING_IMPL_TYPE,\n                         restrict_scaling_type=SCALING_VALUE_TYPE,\n                         scaling_per_channel=ACT_PER_OUT_CH_SCALING,\n                         narrow_range=NARROW_RANGE_ENABLED)\n\n\ndef get_quant_linear(in_features, out_features, per_out_ch_scaling, bit_width, quant_type):\n    return QuantLinear(bias=BIAS_ENABLED,\n                       in_features=in_features,\n                       out_features=out_features,\n                       weight_quant_type=quant_type,\n                       weight_bit_width=bit_width,\n                       weight_scaling_const=WEIGHT_SCALING_CONST,\n                       weight_bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n                       weight_scaling_per_output_channel=per_out_ch_scaling,\n                       weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n                       weight_narrow_range=NARROW_RANGE_ENABLED)\n\n\ndef get_quant_conv2d(in_ch, out_ch, bit_width, quant_type):\n    return QuantConv2d(in_channels=in_ch,\n                       kernel_size=KERNEL_SIZE,\n                       out_channels=out_ch,\n                       weight_quant_type=quant_type,\n                       weight_bit_width=bit_width,\n                       weight_narrow_range=NARROW_RANGE_ENABLED,\n                       weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n                       weight_scaling_const=WEIGHT_SCALING_CONST,\n                       weight_scaling_per_output_channel=CONV_PER_OUT_CH_SCALING,\n                       weight_restrict_scaling_type=SCALING_VALUE_TYPE,\n                       weight_bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n                       bias=BIAS_ENABLED)\n'"
brevitas_examples/bnn_pynq/models/losses.py,3,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Function\n\nclass squared_hinge_loss(Function):\n    @staticmethod\n    def forward(ctx, predictions, targets):\n        ctx.save_for_backward(predictions, targets) \n        output = 1.-predictions.mul(targets)\n        output[output.le(0.)] = 0.\n        loss = torch.mean(output.mul(output))\n        return loss \n\n    @staticmethod\n    def backward(ctx, grad_output):\n       predictions, targets = ctx.saved_tensors\n       output=1.-predictions.mul(targets)\n       output[output.le(0.)]=0.\n       grad_output.resize_as_(predictions).copy_(targets).mul_(-2.).mul_(output)\n       grad_output.mul_(output.ne(0).float())\n       grad_output.div_(predictions.numel())\n       return grad_output, None    \n\nclass SqrHingeLoss(nn.Module):\n    # Squared Hinge Loss\n    def __init__(self):\n        super(SqrHingeLoss, self).__init__()\n    \n    def forward(self, input, target):\n        return squared_hinge_loss.apply(input, target)'"
brevitas_examples/bnn_pynq/models/tensor_norm.py,6,"b'# MIT License\n#\n# Copyright (c) 2019 Xilinx\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\nclass TensorNorm(nn.Module):\n    def __init__(self, eps=1e-4, momentum=0.1):\n        super().__init__()\n\n        self.eps = eps\n        self.momentum = momentum\n        self.weight = nn.Parameter(torch.rand(1))\n        self.bias = nn.Parameter(torch.rand(1))\n        self.register_buffer(\'running_mean\', torch.zeros(1))\n        self.register_buffer(\'running_var\', torch.ones(1))\n        self.reset_running_stats()\n\n    def reset_running_stats(self):\n        self.running_mean.zero_()\n        self.running_var.fill_(1)\n        init.ones_(self.weight)\n        init.zeros_(self.bias)\n\n    def forward(self, x):\n        if self.training:\n            mean = x.mean()\n            unbias_var = x.var(unbiased=True)\n            biased_var = x.var(unbiased=False)\n            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.detach()\n            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * unbias_var.detach()\n            inv_std = 1 / (biased_var + self.eps).pow(0.5)\n            return (x - mean) * inv_std * self.weight + self.bias\n        else:\n            return ((x - self.running_mean) / (self.running_var + self.eps).pow(0.5)) * self.weight + self.bias'"
brevitas_examples/imagenet_classification/cfg/__init__.py,0,b''
brevitas_examples/imagenet_classification/models/__init__.py,0,"b""import os\nfrom configparser import ConfigParser\n\nfrom torch import hub\n\nfrom .mobilenetv1 import *\nfrom .vgg import *\nfrom .proxylessnas import *\n\nmodel_impl = {\n    'quant_mobilenet_v1': quant_mobilenet_v1,\n    'quant_proxylessnas_mobile14': quant_proxylessnas_mobile14\n}\n\n\ndef model_with_cfg(name, pretrained):\n    cfg = ConfigParser()\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    config_path = os.path.join(current_dir, '..', 'cfg', name + '.ini')\n    assert os.path.exists(config_path)\n    cfg.read(config_path)\n    arch = cfg.get('MODEL', 'ARCH')\n    model = model_impl[arch](cfg)\n    if pretrained:\n        checkpoint = cfg.get('MODEL', 'PRETRAINED_URL')\n        state_dict = hub.load_state_dict_from_url(checkpoint, progress=True, map_location='cpu')\n        model.load_state_dict(state_dict, strict=True)\n    return model, cfg\n\n\ndef quant_mobilenet_v1_4b(pretrained=True):\n    model, _ = model_with_cfg('quant_mobilenet_v1_4b', pretrained)\n    return model\n\n\ndef quant_proxylessnas_mobile14_4b(pretrained=True):\n    model, _ = model_with_cfg('quant_proxylessnas_mobile14_4b', pretrained)\n    return model\n\n\ndef quant_proxylessnas_mobile14_4b5b(pretrained=True):\n    model, _ = model_with_cfg('quant_proxylessnas_mobile14_4b5b', pretrained)\n    return model\n\n\ndef quant_proxylessnas_mobile14_hadamard_4b(pretrained=True):\n    model, _ = model_with_cfg('quant_proxylessnas_mobile14_hadamard_4b', pretrained)\n    return model"""
brevitas_examples/imagenet_classification/models/common.py,0,"b'import brevitas.nn as qnn\nfrom brevitas.core.quant import QuantType\nfrom brevitas.core.restrict_val import RestrictValueType\nfrom brevitas.core.scaling import ScalingImplType\nfrom brevitas.core.stats import StatsOp\n\n\nQUANT_TYPE = QuantType.INT\nSCALING_MIN_VAL = 2e-16\n\nACT_SCALING_IMPL_TYPE = ScalingImplType.PARAMETER\nACT_SCALING_PER_CHANNEL = False\nACT_SCALING_RESTRICT_SCALING_TYPE = RestrictValueType.LOG_FP\nACT_MAX_VAL = 6.0\nACT_RETURN_QUANT_TENSOR = False\nACT_PER_CHANNEL_BROADCASTABLE_SHAPE = None\nHARD_TANH_THRESHOLD = 10.0\n\nWEIGHT_SCALING_IMPL_TYPE = ScalingImplType.STATS\nWEIGHT_SCALING_PER_OUTPUT_CHANNEL = True\nWEIGHT_SCALING_STATS_OP = StatsOp.MAX\nWEIGHT_RESTRICT_SCALING_TYPE = RestrictValueType.LOG_FP\nWEIGHT_NARROW_RANGE = True\n\nENABLE_BIAS_QUANT = False\n\nHADAMARD_FIXED_SCALE = False\n\n\ndef make_quant_conv2d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride,\n                      padding,\n                      groups,\n                      bias,\n                      bit_width,\n                      enable_bias_quant=ENABLE_BIAS_QUANT,\n                      weight_quant_type=QUANT_TYPE,\n                      weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n                      weight_scaling_stats_op=WEIGHT_SCALING_STATS_OP,\n                      weight_scaling_per_output_channel=WEIGHT_SCALING_PER_OUTPUT_CHANNEL,\n                      weight_restrict_scaling_type=WEIGHT_RESTRICT_SCALING_TYPE,\n                      weight_narrow_range=WEIGHT_NARROW_RANGE,\n                      weight_scaling_min_val=SCALING_MIN_VAL):\n    bias_quant_type = QUANT_TYPE if enable_bias_quant else QuantType.FP\n    return qnn.QuantConv2d(in_channels,\n                           out_channels,\n                           groups=groups,\n                           kernel_size=kernel_size,\n                           padding=padding,\n                           stride=stride,\n                           bias=bias,\n                           bias_quant_type=bias_quant_type,\n                           compute_output_bit_width=bias and enable_bias_quant,\n                           compute_output_scale=bias and enable_bias_quant,\n                           weight_bit_width=bit_width,\n                           weight_quant_type=weight_quant_type,\n                           weight_scaling_impl_type=weight_scaling_impl_type,\n                           weight_scaling_stats_op=weight_scaling_stats_op,\n                           weight_scaling_per_output_channel=weight_scaling_per_output_channel,\n                           weight_restrict_scaling_type=weight_restrict_scaling_type,\n                           weight_narrow_range=weight_narrow_range,\n                           weight_scaling_min_val=weight_scaling_min_val)\n\n\ndef make_quant_linear(in_channels,\n                      out_channels,\n                      bias,\n                      bit_width,\n                      enable_bias_quant=ENABLE_BIAS_QUANT,\n                      weight_quant_type=QUANT_TYPE,\n                      weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n                      weight_scaling_stats_op=WEIGHT_SCALING_STATS_OP,\n                      weight_scaling_per_output_channel=WEIGHT_SCALING_PER_OUTPUT_CHANNEL,\n                      weight_restrict_scaling_type=WEIGHT_RESTRICT_SCALING_TYPE,\n                      weight_narrow_range=WEIGHT_NARROW_RANGE,\n                      weight_scaling_min_val=SCALING_MIN_VAL):\n    bias_quant_type = QUANT_TYPE if enable_bias_quant else QuantType.FP\n    return qnn.QuantLinear(in_channels, out_channels,\n                           bias=bias,\n                           bias_quant_type=bias_quant_type,\n                           compute_output_bit_width=bias and enable_bias_quant,\n                           compute_output_scale=bias and enable_bias_quant,\n                           weight_bit_width=bit_width,\n                           weight_quant_type=weight_quant_type,\n                           weight_scaling_impl_type=weight_scaling_impl_type,\n                           weight_scaling_stats_op=weight_scaling_stats_op,\n                           weight_scaling_per_output_channel=weight_scaling_per_output_channel,\n                           weight_restrict_scaling_type=weight_restrict_scaling_type,\n                           weight_narrow_range=weight_narrow_range,\n                           weight_scaling_min_val=weight_scaling_min_val)\n\n\ndef make_quant_relu(bit_width,\n                    quant_type=QUANT_TYPE,\n                    scaling_impl_type=ACT_SCALING_IMPL_TYPE,\n                    scaling_per_channel=ACT_SCALING_PER_CHANNEL,\n                    restrict_scaling_type=ACT_SCALING_RESTRICT_SCALING_TYPE,\n                    scaling_min_val=SCALING_MIN_VAL,\n                    max_val=ACT_MAX_VAL,\n                    return_quant_tensor=ACT_RETURN_QUANT_TENSOR,\n                    per_channel_broadcastable_shape=ACT_PER_CHANNEL_BROADCASTABLE_SHAPE):\n    return qnn.QuantReLU(bit_width=bit_width,\n                         quant_type=quant_type,\n                         scaling_impl_type=scaling_impl_type,\n                         scaling_per_channel=scaling_per_channel,\n                         restrict_scaling_type=restrict_scaling_type,\n                         scaling_min_val=scaling_min_val,\n                         max_val=max_val,\n                         return_quant_tensor=return_quant_tensor,\n                         per_channel_broadcastable_shape=per_channel_broadcastable_shape)\n\n\ndef make_quant_hard_tanh(bit_width,\n                         quant_type=QUANT_TYPE,\n                         scaling_impl_type=ACT_SCALING_IMPL_TYPE,\n                         scaling_per_channel=ACT_SCALING_PER_CHANNEL,\n                         restrict_scaling_type=ACT_SCALING_RESTRICT_SCALING_TYPE,\n                         scaling_min_val=SCALING_MIN_VAL,\n                         threshold=HARD_TANH_THRESHOLD,\n                         return_quant_tensor=ACT_RETURN_QUANT_TENSOR,\n                         per_channel_broadcastable_shape=ACT_PER_CHANNEL_BROADCASTABLE_SHAPE):\n    return qnn.QuantHardTanh(bit_width=bit_width,\n                             quant_type=quant_type,\n                             scaling_per_channel=scaling_per_channel,\n                             scaling_impl_type=scaling_impl_type,\n                             restrict_scaling_type=restrict_scaling_type,\n                             scaling_min_val=scaling_min_val,\n                             max_val=threshold,\n                             min_val=-threshold,\n                             per_channel_broadcastable_shape=per_channel_broadcastable_shape,\n                             return_quant_tensor=return_quant_tensor)\n\n\ndef make_quant_avg_pool(bit_width,\n                        kernel_size,\n                        stride,\n                        signed,\n                        quant_type=QUANT_TYPE):\n    return qnn.QuantAvgPool2d(kernel_size=kernel_size,\n                              quant_type=quant_type,\n                              signed=signed,\n                              stride=stride,\n                              min_overall_bit_width=bit_width,\n                              max_overall_bit_width=bit_width)\n\n\ndef make_hadamard_classifier(in_channels,\n                             out_channels,\n                             fixed_scale=HADAMARD_FIXED_SCALE):\n    return qnn.HadamardClassifier(in_channels=in_channels,\n                                  out_channels=out_channels,\n                                  fixed_scale=fixed_scale)\n\n\n\n'"
brevitas_examples/imagenet_classification/models/mobilenetv1.py,1,"b'""""""\nModified from: https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/models\n\nMIT License\n\nCopyright (c) 2019 Xilinx, Inc (Alessandro Pappalardo)\nCopyright (c) 2018 Oleg S\xc3\xa9mery\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\n\n__all__ = [\'quant_mobilenet_v1\']\n\nfrom torch import nn\nfrom torch.nn import Sequential\n\nfrom brevitas.quant_tensor import pack_quant_tensor\n\nfrom .common import *\n\n\nFIRST_LAYER_BIT_WIDTH = 8\n\n\nclass DwsConvBlock(nn.Module):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 stride,\n                 bit_width,\n                 pw_activation_scaling_per_channel=False):\n        super(DwsConvBlock, self).__init__()\n        self.dw_conv = ConvBlock(in_channels=in_channels,\n                                 out_channels=in_channels,\n                                 groups=in_channels,\n                                 kernel_size=3,\n                                 padding=1,\n                                 stride=stride,\n                                 weight_bit_width=bit_width,\n                                 act_bit_width=bit_width)\n        self.pw_conv = ConvBlock(in_channels=in_channels,\n                                 out_channels=out_channels,\n                                 kernel_size=1,\n                                 padding=0,\n                                 weight_bit_width=bit_width,\n                                 act_bit_width=bit_width,\n                                 activation_scaling_per_channel=pw_activation_scaling_per_channel)\n\n    def forward(self, x):\n        x = self.dw_conv(x)\n        x = self.pw_conv(x)\n        return x\n\n\nclass ConvBlock(nn.Module):\n\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 kernel_size,\n                 weight_bit_width,\n                 act_bit_width,\n                 stride=1,\n                 padding=0,\n                 groups=1,\n                 bn_eps=1e-5,\n                 activation_scaling_per_channel=False):\n        super(ConvBlock, self).__init__()\n        self.conv = make_quant_conv2d(in_channels=in_channels,\n                                      out_channels=out_channels,\n                                      kernel_size=kernel_size,\n                                      stride=stride,\n                                      padding=padding,\n                                      groups=groups,\n                                      bias=False,\n                                      bit_width=weight_bit_width)\n        self.bn = nn.BatchNorm2d(num_features=out_channels, eps=bn_eps)\n        self.activation = make_quant_relu(bit_width=act_bit_width,\n                                          per_channel_broadcastable_shape=(1, out_channels, 1, 1),\n                                          scaling_per_channel=activation_scaling_per_channel,\n                                          return_quant_tensor=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.activation(x)\n        return x\n\n\nclass MobileNet(nn.Module):\n\n    def __init__(self,\n                 channels,\n                 first_stage_stride,\n                 bit_width,\n                 in_channels=3,\n                 num_classes=1000):\n        super(MobileNet, self).__init__()\n        init_block_channels = channels[0][0]\n\n        self.features = Sequential()\n        init_block = ConvBlock(in_channels=in_channels,\n                               out_channels=init_block_channels,\n                               kernel_size=3,\n                               stride=2,\n                               weight_bit_width=FIRST_LAYER_BIT_WIDTH,\n                               activation_scaling_per_channel=True,\n                               act_bit_width=bit_width)\n        self.features.add_module(\'init_block\', init_block)\n        in_channels = init_block_channels\n        for i, channels_per_stage in enumerate(channels[1:]):\n            stage = Sequential()\n            pw_activation_scaling_per_channel = i < len(channels[1:]) - 1\n            for j, out_channels in enumerate(channels_per_stage):\n                stride = 2 if (j == 0) and ((i != 0) or first_stage_stride) else 1\n                mod = DwsConvBlock(in_channels=in_channels,\n                                   out_channels=out_channels,\n                                   stride=stride,\n                                   bit_width=bit_width,\n                                   pw_activation_scaling_per_channel=pw_activation_scaling_per_channel)\n                stage.add_module(\'unit{}\'.format(j + 1), mod)\n                in_channels = out_channels\n            self.features.add_module(\'stage{}\'.format(i + 1), stage)\n        self.final_pool = make_quant_avg_pool(kernel_size=7,\n                                              stride=1,\n                                              signed=False,\n                                              bit_width=bit_width)\n        self.output = make_quant_linear(in_channels, num_classes,\n                                        bias=True,\n                                        enable_bias_quant=True,\n                                        bit_width=bit_width,\n                                        weight_scaling_per_output_channel=False)\n\n    def forward(self, x):\n        quant_tensor = self.features(x)\n        x, scale, bit_width = self.final_pool(quant_tensor)\n        x = x.view(x.size(0), -1)\n        out = self.output(pack_quant_tensor(x, scale, bit_width))\n        return out\n\n\ndef quant_mobilenet_v1(cfg):\n\n    channels = [[32], [64], [128, 128], [256, 256], [512, 512, 512, 512, 512, 512], [1024, 1024]]\n    first_stage_stride = False\n    width_scale = float(cfg.get(\'MODEL\', \'WIDTH_SCALE\'))\n    bit_width = cfg.getint(\'QUANT\', \'BIT_WIDTH\')\n\n    if width_scale != 1.0:\n        channels = [[int(cij * width_scale) for cij in ci] for ci in channels]\n\n    net = MobileNet(channels=channels,\n                    first_stage_stride=first_stage_stride,\n                    bit_width=bit_width)\n    return net\n\n\n\n'"
brevitas_examples/imagenet_classification/models/proxylessnas.py,1,"b'""""""\nSource: https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv\nMIT License\nCopyright (c) 2019 Xilinx, Inc (Alessandro Pappalardo)\nCopyright (c) 2018 Oleg S\xc3\xa9mery\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\n__all__ = [\'quant_proxylessnas_mobile14\']\n\nimport torch.nn as nn\nfrom brevitas.quant_tensor import pack_quant_tensor\n\nfrom .common import *\n\n\nclass ConvBlock(nn.Module):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 kernel_size,\n                 stride,\n                 padding,\n                 weight_bit_width,\n                 act_bit_width,\n                 act_scaling_per_channel,\n                 bias,\n                 groups=1,\n                 bn_eps=1e-5,\n                 shared_act=None,\n                 return_quant_tensor=False):\n        super(ConvBlock, self).__init__()\n\n        self.conv = make_quant_conv2d(in_channels=in_channels,\n                                      out_channels=out_channels,\n                                      kernel_size=kernel_size,\n                                      stride=stride,\n                                      padding=padding,\n                                      groups=groups,\n                                      bias=bias,\n                                      bit_width=weight_bit_width,\n                                      weight_scaling_per_output_channel=True)\n        self.bn = nn.BatchNorm2d(num_features=out_channels,\n                                 eps=bn_eps)\n        if shared_act is None:\n            self.activ = make_quant_relu(bit_width=act_bit_width,\n                                         scaling_per_channel=act_scaling_per_channel,\n                                         per_channel_broadcastable_shape=(1, out_channels, 1, 1),\n                                         return_quant_tensor=return_quant_tensor)\n        else:\n            self.activ = shared_act\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.activ(x)\n        return x\n\n\nclass ProxylessBlock(nn.Module):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 kernel_size,\n                 stride,\n                 bn_eps,\n                 expansion,\n                 bit_width,\n                 depthwise_bit_width,\n                 shared_act):\n        super(ProxylessBlock, self).__init__()\n        self.use_bc = (expansion > 1)\n        mid_channels = in_channels * expansion\n\n        if self.use_bc:\n            self.bc_conv = ConvBlock(in_channels=in_channels,\n                                     out_channels=mid_channels,\n                                     kernel_size=1,\n                                     stride=1,\n                                     padding=0,\n                                     groups=1,\n                                     bn_eps=bn_eps,\n                                     act_scaling_per_channel=True,\n                                     weight_bit_width=bit_width,\n                                     bias=False,\n                                     act_bit_width=depthwise_bit_width)\n\n        padding = (kernel_size - 1) // 2\n        self.dw_conv = ConvBlock(in_channels=mid_channels,\n                                 out_channels=mid_channels,\n                                 kernel_size=kernel_size,\n                                 stride=stride,\n                                 padding=padding,\n                                 groups=mid_channels,\n                                 bn_eps=bn_eps,\n                                 act_scaling_per_channel=False,\n                                 weight_bit_width=depthwise_bit_width,\n                                 act_bit_width=bit_width,\n                                 bias=False)\n        self.pw_conv = ConvBlock(in_channels=mid_channels,\n                                 out_channels=out_channels,\n                                 kernel_size=1,\n                                 stride=1,\n                                 padding=0,\n                                 groups=1,\n                                 bn_eps=bn_eps,\n                                 weight_bit_width=bit_width,\n                                 shared_act=shared_act,\n                                 bias=False,\n                                 act_bit_width=None,\n                                 act_scaling_per_channel=None)\n\n    def forward(self, x):\n        if self.use_bc:\n            x = self.bc_conv(x)\n        x = self.dw_conv(x)\n        x = self.pw_conv(x)\n        return x\n\n\nclass ProxylessUnit(nn.Module):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 kernel_size,\n                 stride,\n                 bn_eps,\n                 expansion,\n                 residual,\n                 shortcut,\n                 bit_width,\n                 depthwise_bit_width,\n                 shared_act):\n        super(ProxylessUnit, self).__init__()\n        assert residual or shortcut\n        assert shared_act is not None\n        self.residual = residual\n        self.shortcut = shortcut\n\n        if self.residual:\n            self.body = ProxylessBlock(in_channels=in_channels,\n                                       out_channels=out_channels,\n                                       kernel_size=kernel_size,\n                                       stride=stride,\n                                       bn_eps=bn_eps,\n                                       expansion=expansion,\n                                       bit_width=bit_width,\n                                       depthwise_bit_width=depthwise_bit_width,\n                                       shared_act=shared_act)\n            self.shared_act = shared_act\n\n    def forward(self, x):\n        if not self.residual:\n            return x\n        if not self.shortcut:\n            x = self.body(x)\n            return x\n        identity = x\n        x = self.body(x)\n        x = identity + x\n        x = self.shared_act(x)\n        return x\n\n\nclass ProxylessNAS(nn.Module):\n    def __init__(self,\n                 channels,\n                 init_block_channels,\n                 final_block_channels,\n                 residuals,\n                 shortcuts,\n                 kernel_sizes,\n                 expansions,\n                 bit_width,\n                 depthwise_bit_width,\n                 first_layer_weight_bit_width,\n                 hadamard_classifier,\n                 bn_eps=1e-3,\n                 in_channels=3,\n                 num_classes=1000):\n        super(ProxylessNAS, self).__init__()\n        self.features = nn.Sequential()\n\n        init_block = ConvBlock(in_channels=in_channels,\n                               out_channels=init_block_channels,\n                               kernel_size=3,\n                               stride=2,\n                               padding=1,\n                               groups=1,\n                               bn_eps=bn_eps,\n                               act_scaling_per_channel=False,\n                               bias=False,\n                               act_bit_width=bit_width,\n                               weight_bit_width=first_layer_weight_bit_width)\n        self.features.add_module(""init_block"", init_block)\n\n        in_channels = init_block_channels\n        shared_act = None\n\n        for i, channels_per_stage in enumerate(channels):\n            stage = nn.Sequential()\n            residuals_per_stage = residuals[i]\n            shortcuts_per_stage = shortcuts[i]\n            kernel_sizes_per_stage = kernel_sizes[i]\n            expansions_per_stage = expansions[i]\n\n            for j, out_channels in enumerate(channels_per_stage):\n                residual = (residuals_per_stage[j] == 1)\n                shortcut = (shortcuts_per_stage[j] == 1)\n                kernel_size = kernel_sizes_per_stage[j]\n                expansion = expansions_per_stage[j]\n                stride = 2 if (j == 0) and (i != 0) else 1\n\n                if not shortcut:\n                    shared_act = make_quant_hard_tanh(bit_width=bit_width,\n                                                      return_quant_tensor=True)\n\n                unit = ProxylessUnit(in_channels=in_channels,\n                                     out_channels=out_channels,\n                                     kernel_size=kernel_size,\n                                     stride=stride,\n                                     bn_eps=bn_eps,\n                                     expansion=expansion,\n                                     residual=residual,\n                                     shortcut=shortcut,\n                                     bit_width=bit_width,\n                                     depthwise_bit_width=depthwise_bit_width,\n                                     shared_act=shared_act)\n                stage.add_module(""unit{}"".format(j + 1), unit)\n                in_channels = out_channels\n\n            self.features.add_module(""stage{}"".format(i + 1), stage)\n\n        final_block = ConvBlock(in_channels=in_channels,\n                                out_channels=final_block_channels,\n                                kernel_size=1,\n                                stride=1,\n                                padding=0,\n                                groups=1,\n                                bn_eps=bn_eps,\n                                act_scaling_per_channel=False,\n                                act_bit_width=bit_width,\n                                weight_bit_width=bit_width,\n                                bias=False,\n                                return_quant_tensor=True)\n        self.features.add_module(""final_block"", final_block)\n        in_channels = final_block_channels\n        self.final_pool = make_quant_avg_pool(kernel_size=7,\n                                              stride=1,\n                                              signed=False,\n                                              bit_width=bit_width)\n        if hadamard_classifier:\n            self.output = make_hadamard_classifier(in_channels=in_channels,\n                                                   out_channels=num_classes)\n        else:\n            self.output = make_quant_linear(in_channels=in_channels,\n                                            out_channels=num_classes,\n                                            bias=True,\n                                            enable_bias_quant=True,\n                                            bit_width=bit_width,\n                                            weight_scaling_per_output_channel=False)\n\n    def forward(self, x):\n        x = self.features(x)\n        x, scale, bit_width = self.final_pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.output(pack_quant_tensor(x, scale, bit_width))\n        return x\n\n\ndef quant_proxylessnas_mobile14(cfg):\n\n    residuals = [[1], [1, 1, 0, 0], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]\n    channels = [[24], [40, 40, 40, 40], [56, 56, 56, 56], [112, 112, 112, 112, 136, 136, 136, 136],\n                [256, 256, 256, 256, 448]]\n    kernel_sizes = [[3], [5, 3, 3, 3], [7, 3, 5, 5], [7, 5, 5, 5, 5, 5, 5, 5], [7, 7, 7, 7, 7]]\n    expansions = [[1], [3, 3, 3, 3], [3, 3, 3, 3], [6, 3, 3, 3, 6, 3, 3, 3], [6, 6, 3, 3, 6]]\n    init_block_channels = 48\n    final_block_channels = 1792\n    shortcuts = [[0], [0, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1, 0, 1, 1, 1], [0, 1, 1, 1, 0]]\n\n    bit_width = int(cfg.get(\'QUANT\', \'BIT_WIDTH\'))\n    first_layer_weight_bit_width = int(cfg.get(\'QUANT\', \'FIRST_LAYER_WEIGHT_BIT_WIDTH\'))\n    depthwise_bit_width = int(cfg.get(\'QUANT\', \'DEPTHWISE_BIT_WIDTH\'))\n    hadamard_classifier = cfg.getboolean(\'MODEL\', \'HADAMARD_CLASSIFIER\')\n\n    net = ProxylessNAS(channels=channels,\n                       init_block_channels=init_block_channels,\n                       final_block_channels=final_block_channels,\n                       residuals=residuals,\n                       shortcuts=shortcuts,\n                       kernel_sizes=kernel_sizes,\n                       expansions=expansions,\n                       bit_width=bit_width,\n                       first_layer_weight_bit_width=first_layer_weight_bit_width,\n                       depthwise_bit_width=depthwise_bit_width,\n                       hadamard_classifier=hadamard_classifier)\n    return net\n'"
brevitas_examples/imagenet_classification/models/vgg.py,2,"b'# BSD 3-Clause License\n# Copyright (c) Alessandro Pappalardo 2019,\n# Copyright (c) Soumith Chintala 2016,\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# * Redistributions of source code must retain the above copyright notice, this\n#   list of conditions and the following disclaimer.\n#\n# * Redistributions in binary form must reproduce the above copyright notice,\n#   this list of conditions and the following disclaimer in the documentation\n#   and/or other materials provided with the distribution.\n#\n# * Neither the name of the copyright holder nor the names of its\n#   contributors may be used to endorse or promote products derived from\n#   this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n# Based on the torchvision implementation\n# https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n\n\nimport torch\nimport torch.nn as nn\nfrom .common import make_quant_conv2d, make_quant_linear, make_quant_relu\n\n__all__ = [\n    \'QuantVGG\', \'quant_vgg11\', \'quant_vgg11_bn\', \'quant_vgg13\', \'quant_vgg13_bn\', \'quant_vgg16\', \'quant_vgg16_bn\',\n    \'quant_vgg19_bn\', \'quant_vgg19\',\n]\n\n\nclass QuantVGG(nn.Module):\n\n    def __init__(self, cfg, batch_norm, bit_width=8, num_classes=1000):\n        super(QuantVGG, self).__init__()\n        self.features = make_layers(cfg, batch_norm, bit_width)\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n        self.classifier = nn.Sequential(\n            make_quant_linear(512 * 7 * 7, 4096, bias=True, bit_width=bit_width),\n            make_quant_relu(bit_width),\n            nn.Dropout(),\n            make_quant_linear(4096, 4096, bias=True, bit_width=bit_width),\n            make_quant_relu(bit_width),\n            nn.Dropout(),\n            make_quant_linear(4096, num_classes, bias=False, bit_width=bit_width,\n                              weight_scaling_per_output_channel=False),\n        )\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\'fan_out\', nonlinearity=\'relu\')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n\n\ndef make_layers(cfg, batch_norm, bit_width):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = make_quant_conv2d(in_channels, v, kernel_size=3, stride=1, padding=1, groups=1,\n                                       bias=not batch_norm, bit_width=bit_width)\n            act = make_quant_relu(bit_width)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), act]\n            else:\n                layers += [conv2d, act]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfgs = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'B\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'D\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512, \'M\'],\n    \'E\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512, \'M\'],\n}\n\n\ndef _quant_vgg(cfg, batch_norm,  **kwargs):\n    model = QuantVGG(cfgs[cfg], batch_norm=batch_norm, **kwargs)\n    return model\n\n\ndef quant_vgg11(**kwargs):\n    return _quant_vgg(\'A\', False, **kwargs)\n\n\ndef quant_vgg11_bn(**kwargs):\n    return _quant_vgg(\'A\', True, **kwargs)\n\n\ndef quant_vgg13(**kwargs):\n    return _quant_vgg(\'B\', False, **kwargs)\n\n\ndef quant_vgg13_bn(**kwargs):\n    return _quant_vgg(\'B\', True, **kwargs)\n\n\ndef quant_vgg16(**kwargs):\n    return _quant_vgg(\'D\', False, **kwargs)\n\n\ndef quant_vgg16_bn(**kwargs):\n    return _quant_vgg(\'D\', True, **kwargs)\n\n\ndef quant_vgg19(**kwargs):\n    return _quant_vgg(\'E\', False, **kwargs)\n\n\ndef quant_vgg19_bn(**kwargs):\n    return _quant_vgg(\'E\', True, **kwargs)\n'"
brevitas_examples/speech_to_text/cfg/__init__.py,0,b''
brevitas_examples/speech_to_text/quartznet/__init__.py,2,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nfrom .data_layer import (\n        AudioToTextDataLayer)\nfrom .greedy_ctc_decoder import GreedyCTCDecoder\nfrom .quartznet import quartznet\nfrom .losses import CTCLossNM\nfrom .helpers import *\n\nimport os\nfrom configparser import ConfigParser\nfrom ruamel.yaml import YAML\nfrom torch import hub\n\n__all__ = [\'AudioToTextDataLayer\',\n           \'quartznet\',\n           \'quant_quartznet_perchannelscaling_4b\',\n           \'quant_quartznet_perchannelscaling_8b\',\n           \'quant_quartznet_pertensorscaling_8b\']\n\nname = ""quarznet_release""\nmodel_impl = {\n    \'quartznet\': quartznet,\n}\n\n\ndef model_with_cfg(name, pretrained):\n    cfg = ConfigParser()\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    config_path = os.path.join(current_dir, \'..\', \'cfg\', name + \'.ini\')\n    assert os.path.exists(config_path)\n    cfg.read(config_path)\n    arch = cfg.get(\'MODEL\', \'ARCH\')\n    topology_file = cfg.get(\'MODEL\', \'TOPOLOGY_FILE\')\n    topology_path = os.path.join(current_dir, \'..\', \'cfg\', \'topology\', topology_file)\n    yaml = YAML(typ=""safe"")\n    with open(topology_path) as f:\n        quartnzet_params = yaml.load(f)\n    model = model_impl[arch](cfg, quartnzet_params)\n    if pretrained:\n        pretrained_encoder_url = cfg.get(\'MODEL\', \'PRETRAINED_ENCODER_URL\')\n        pretrained_decoder_url = cfg.get(\'MODEL\', \'PRETRAINED_DECODER_URL\')\n        print(""=> Loading encoder checkpoint from:\'{}\'"".format(pretrained_encoder_url))\n        print(""=> Loading decoder checkpoint from:\'{}\'"".format(pretrained_decoder_url))\n        checkpoint_enc = torch.hub.load_state_dict_from_url(pretrained_encoder_url, progress=True, map_location=\'cpu\')\n        checkpoint_dec = torch.hub.load_state_dict_from_url(pretrained_decoder_url, progress=True, map_location=\'cpu\')\n        model.restore_checkpoints(checkpoint_enc, checkpoint_dec)\n    return model, cfg\n\n\ndef quant_quartznet_perchannelscaling_4b(pretrained=True):\n    model, _ = model_with_cfg(\'quant_quartznet_perchannelscaling_4b\', pretrained)\n    return model\n\n\ndef quant_quartznet_perchannelscaling_8b(pretrained=True):\n    model, _ = model_with_cfg(\'quant_quartznet_perchannelscaling_8b\', pretrained)\n    return model\n\n\ndef quant_quartznet_pertensorscaling_8b(pretrained=True):\n    model, _ = model_with_cfg(\'quant_quartznet_pertensorscaling_8b\', pretrained)\n    return model\n'"
brevitas_examples/speech_to_text/quartznet/audio_preprocessing.py,16,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nThis file contains neural modules responsible for preprocessing audio data.\n""""""\n__all__ = [\'AudioPreprocessing\',\n           \'AudioPreprocessor\',\n           \'AudioToMFCCPreprocessor\',\n           \'AudioToMelSpectrogramPreprocessor\',\n           \'AudioToSpectrogramPreprocessor\',\n           \'MultiplyBatch\',\n           \'SpectrogramAugmentation\']\n\nfrom abc import abstractmethod\nimport math\nimport torch\nimport torch.nn as nn\ntry:\n    import torchaudio\n    have_torchaudio = True\nexcept ModuleNotFoundError:\n    have_torchaudio = False\n    print(\'Could not import torchaudio. Some features might not work.\')\n\nfrom .parts.features import FilterbankFeatures\nfrom .parts.spectr_augment import SpecAugment, SpecCutout\n\n\nclass AudioPreprocessor(nn.Module):\n    """"""\n    A base class for Neural Modules that performs audio preprocessing,\n    transforming the wav files to features.\n    """"""\n    def __init__(self, win_length, hop_length, **kwargs):\n        super().__init__()\n\n        self.win_length = win_length\n        self.hop_length = hop_length\n\n        # self.disable_casts = (self._opt_level == Optimization.mxprO1)\n\n        self.torch_windows = {\n            \'hann\': torch.hann_window,\n            \'hamming\': torch.hamming_window,\n            \'blackman\': torch.blackman_window,\n            \'bartlett\': torch.bartlett_window,\n            \'ones\': torch.ones,\n            None: torch.ones\n        }\n\n    @torch.no_grad()\n    def forward(self, input_signal, length):\n        # if self.disable_casts:\n        #     with amp.disable_casts():\n        #         processed_signal = self.get_features(\n        #                 input_signal.to(torch.float), length)\n        # else:\n        processed_signal = self.get_features(input_signal, length)\n\n        processed_length = self.get_seq_len(length.float())\n        return processed_signal, processed_length\n\n    @abstractmethod\n    def get_features(self, input_signal, length):\n        # Called by forward(). Subclasses should implement this.\n        pass\n\n    def get_seq_len(self, length):\n        # Called by forward()\n        return torch.ceil(length / self.hop_length).to(dtype=torch.long)\n\n\nclass AudioToSpectrogramPreprocessor(AudioPreprocessor):\n    """"""Preprocessor that converts wavs to spectrograms.\n    Uses torchaudio\'s Spectrogram class as a featurizer.\n\n    Args:\n        sample_rate (int): Sample rate of the input audio data.\n            Defaults to 16000\n        window_size (float): Size of window for fft in seconds\n            Defaults to 0.02\n        window_stride (float): Stride of window for fft in seconds\n            Defaults to 0.01\n        n_window_size (int): Size of window for fft in samples\n            Defaults to None. Use one of window_size or n_window_size.\n        n_window_stride (int): Stride of window for fft in samples\n            Defaults to None. Use one of window_stride or n_window_stride.\n        n_fft (int): Length of FT window. If None, it uses the smallest power\n            of 2 that is larger than n_window_size.\n            Defaults to None\n        window (str): Windowing function for fft. can be one of [\'hann\',\n            \'hamming\', \'blackman\', \'bartlett\', \'none\', \'null\']\n            Defaults to ""hann""\n        normalized (bool): Whether to normalize by magnitude after stft\n    """"""\n\n    def __init__(\n            self, *,\n            sample_rate=16000,\n            window_size=0.02,\n            window_stride=0.01,\n            n_window_size=None,\n            n_window_stride=None,\n            n_fft=None,\n            window=""hann"",\n            normalized=True,\n            **kwargs\n    ):\n        if not have_torchaudio:\n            raise ModuleNotFoundError(\n                ""torchaudio is not installed but is necessary for ""\n                ""AudioToSpectrogramPreprocessor. We recommend you try ""\n                ""building it from source for the PyTorch version you have."")\n        if window_size and n_window_size:\n            raise ValueError(f""{self} received both window_size and ""\n                             f""n_window_size. Only one should be specified."")\n        if window_stride and n_window_stride:\n            raise ValueError(f""{self} received both window_stride and ""\n                             f""n_window_stride. Only one should be specified."")\n        if window_size:\n            n_window_size = int(window_size * sample_rate)\n        if window_stride:\n            n_window_stride = int(window_stride * sample_rate)\n\n        super().__init__(n_window_size, n_window_stride, **kwargs)\n\n        self.win_length = n_window_size\n        self.hop_length = n_window_stride\n\n        self.n_fft = n_fft or 2 ** math.ceil(math.log2(self.win_length))\n\n        # Set window_fn. None defaults to torch.ones.\n        window_fn = self.torch_windows.get(window, None)\n        if window_fn is None:\n            raise ValueError(\n                f""Window argument for AudioProcessor is invalid: {window}.""\n                f""For no window function, use \'ones\' or None."")\n\n        # Create featurizer.\n        # Calls torch.stft under the hood, and is hard-coded to use center=True\n        self.featurizer = torchaudio.transforms.Spectrogram(\n            n_fft=self.n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window_fn=window_fn,\n            normalized=normalized\n        )\n        self.featurizer.to(self._device)\n\n    def get_features(self, input_signal, length):\n        return self.featurizer(input_signal)\n\n\nclass AudioToMelSpectrogramPreprocessor(AudioPreprocessor):\n    """"""Featurizer that converts wavs to mel spectrograms.\n    We don\'t use torchaudio\'s implementation here because the original\n    implementation is not the same, so for the sake of backwards-compatibility\n    this will use the old FilterbankFeatures for now.\n\n    Args:\n        sample_rate (int): Sample rate of the input audio data.\n            Defaults to 16000\n        window_size (float): Size of window for fft in seconds\n            Defaults to 0.02\n        window_stride (float): Stride of window for fft in seconds\n            Defaults to 0.01\n        n_window_size (int): Size of window for fft in samples\n            Defaults to None. Use one of window_size or n_window_size.\n        n_window_stride (int): Stride of window for fft in samples\n            Defaults to None. Use one of window_stride or n_window_stride.\n        window (str): Windowing function for fft. can be one of [\'hann\',\n            \'hamming\', \'blackman\', \'bartlett\']\n            Defaults to ""hann""\n        normalize (str): Can be one of [\'per_feature\', \'all_features\']; all\n            other options disable feature normalization. \'all_features\'\n            normalizes the entire spectrogram to be mean 0 with std 1.\n            \'pre_features\' normalizes per channel / freq instead.\n            Defaults to ""per_feature""\n        n_fft (int): Length of FT window. If None, it uses the smallest power\n            of 2 that is larger than n_window_size.\n            Defaults to None\n        preemph (float): Amount of pre emphasis to add to audio. Can be\n            disabled by passing None.\n            Defaults to 0.97\n        features (int): Number of mel spectrogram freq bins to output.\n            Defaults to 64\n        lowfreq (int): Lower bound on mel basis in Hz.\n            Defaults to 0\n        highfreq  (int): Lower bound on mel basis in Hz.\n            Defaults to None\n        log (bool): Log features.\n            Defaults to True\n        log_zero_guard_type(str): Need to avoid taking the log of zero. There\n            are two options: ""add"" or ""clamp"".\n            Defaults to ""add"".\n        log_zero_guard_value(float, or str): Add or clamp requires the number\n            to add with or clamp to. log_zero_guard_value can either be a float\n            or ""tiny"" or ""eps"". torch.finfo is used if ""tiny"" or ""eps"" is\n            passed.\n            Defaults to 2**-24.\n        dither (float): Amount of white-noise dithering.\n            Defaults to 1e-5\n        pad_to (int): Ensures that the output size of the time dimension is\n            a multiple of pad_to.\n            Defaults to 16\n        frame_splicing (int): Defaults to 1\n        stft_conv (bool): If True, uses pytorch_stft and convolutions. If\n            False, uses torch.stft.\n            Defaults to False\n        pad_value (float): The value that shorter mels are padded with.\n            Defaults to 0\n        mag_power (float): The power that the linear spectrogram is raised to\n            prior to multiplication with mel basis.\n            Defaults to 2 for a power spec\n    """"""\n\n    def __init__(\n            self, *,\n            sample_rate=16000,\n            window_size=0.02,\n            window_stride=0.01,\n            n_window_size=None,\n            n_window_stride=None,\n            window=""hann"",\n            normalize=""per_feature"",\n            n_fft=None,\n            preemph=0.97,\n            features=64,\n            lowfreq=0,\n            highfreq=None,\n            log=True,\n            log_zero_guard_type=""add"",\n            log_zero_guard_value=2**-24,\n            dither=1e-5,\n            pad_to=16,\n            frame_splicing=1,\n            stft_conv=False,\n            pad_value=0,\n            mag_power=2.,\n            **kwargs\n    ):\n        if window_size and n_window_size:\n            raise ValueError(f""{self} received both window_size and ""\n                             f""n_window_size. Only one should be specified."")\n        if window_stride and n_window_stride:\n            raise ValueError(f""{self} received both window_stride and ""\n                             f""n_window_stride. Only one should be specified."")\n        if window_size:\n            n_window_size = int(window_size * sample_rate)\n        if window_stride:\n            n_window_stride = int(window_stride * sample_rate)\n\n        super().__init__(n_window_size, n_window_stride, **kwargs)\n\n        self.featurizer = FilterbankFeatures(\n            sample_rate=sample_rate,\n            n_window_size=n_window_size,\n            n_window_stride=n_window_stride,\n            window=window,\n            normalize=normalize,\n            n_fft=n_fft,\n            preemph=preemph,\n            nfilt=features,\n            lowfreq=lowfreq,\n            highfreq=highfreq,\n            log=log,\n            log_zero_guard_type=log_zero_guard_type,\n            log_zero_guard_value=log_zero_guard_value,\n            dither=dither,\n            pad_to=pad_to,\n            frame_splicing=frame_splicing,\n            stft_conv=stft_conv,\n            pad_value=pad_value,\n            mag_power=mag_power,\n            logger=None\n        )\n        # self.featurizer.to(self._device)\n\n    def get_features(self, input_signal, length):\n        return self.featurizer(input_signal, length)\n\n    def get_seq_len(self, seq_len):\n        return self.featurizer.get_seq_len(seq_len)\n\n    @property\n    def filter_banks(self):\n        return self.featurizer.filter_banks\n\n\nclass AudioToMFCCPreprocessor(AudioPreprocessor):\n    """"""Preprocessor that converts wavs to MFCCs.\n    Uses torchaudio.transforms.MFCC.\n\n    Args:\n        sample_rate: The sample rate of the audio.\n            Defaults to 16000.\n        window_size: Size of window for fft in seconds. Used to calculate the\n            win_length arg for mel spectrogram.\n            Defaults to 0.02\n        window_stride: Stride of window for fft in seconds. Used to caculate\n            the hop_length arg for mel spect.\n            Defaults to 0.01\n        n_window_size: Size of window for fft in samples\n            Defaults to None. Use one of window_size or n_window_size.\n        n_window_stride: Stride of window for fft in samples\n            Defaults to None. Use one of window_stride or n_window_stride.\n        window: Windowing function for fft. can be one of [\'hann\',\n            \'hamming\', \'blackman\', \'bartlett\', \'none\', \'null\'].\n            Defaults to \'hann\'\n        n_fft: Length of FT window. If None, it uses the smallest power of 2\n            that is larger than n_window_size.\n            Defaults to None\n        lowfreq (int): Lower bound on mel basis in Hz.\n            Defaults to 0\n        highfreq  (int): Lower bound on mel basis in Hz.\n            Defaults to None\n        n_mels: Number of mel filterbanks.\n            Defaults to 64\n        n_mfcc: Number of coefficients to retain\n            Defaults to 64\n        dct_type: Type of discrete cosine transform to use\n        norm: Type of norm to use\n        log: Whether to use log-mel spectrograms instead of db-scaled.\n            Defaults to True.\n    """"""\n\n    def __init__(\n            self, *,\n            sample_rate=16000,\n            window_size=0.02,\n            window_stride=0.01,\n            n_window_size=None,\n            n_window_stride=None,\n            window=\'hann\',\n            n_fft=None,\n            lowfreq=0.,\n            highfreq=None,\n            n_mels=64,\n            n_mfcc=64,\n            dct_type=2,\n            norm=\'ortho\',\n            log=True,\n            **kwargs):\n        if not have_torchaudio:\n            raise ModuleNotFoundError(\n                ""torchaudio is not installed but is necessary for ""\n                ""AudioToMFCCPreprocessor. We recommend you try ""\n                ""building it from source for the PyTorch version you have."")\n        if window_size and n_window_size:\n            raise ValueError(f""{self} received both window_size and ""\n                             f""n_window_size. Only one should be specified."")\n        if window_stride and n_window_stride:\n            raise ValueError(f""{self} received both window_stride and ""\n                             f""n_window_stride. Only one should be specified."")\n        # Get win_length (n_window_size) and hop_length (n_window_stride)\n        if window_size:\n            n_window_size = int(window_size * sample_rate)\n        if window_stride:\n            n_window_stride = int(window_stride * sample_rate)\n\n        super().__init__(n_window_size, n_window_stride, **kwargs)\n\n        mel_kwargs = {}\n\n        mel_kwargs[\'f_min\'] = lowfreq\n        mel_kwargs[\'f_max\'] = highfreq\n        mel_kwargs[\'n_mels\'] = n_mels\n\n        mel_kwargs[\'n_fft\'] = n_fft or 2 ** math.ceil(math.log2(n_window_size))\n\n        mel_kwargs[\'win_length\'] = n_window_size\n        mel_kwargs[\'hop_length\'] = n_window_stride\n\n        # Set window_fn. None defaults to torch.ones.\n        window_fn = self.torch_windows.get(window, None)\n        if window_fn is None:\n            raise ValueError(\n                f""Window argument for AudioProcessor is invalid: {window}.""\n                f""For no window function, use \'ones\' or None."")\n        mel_kwargs[\'window_fn\'] = window_fn\n\n        # Use torchaudio\'s implementation of MFCCs as featurizer\n        self.featurizer = torchaudio.transforms.MFCC(\n            sample_rate=sample_rate,\n            n_mfcc=n_mfcc,\n            dct_type=dct_type,\n            norm=norm,\n            log_mels=log,\n            melkwargs=mel_kwargs\n        )\n        self.featurizer.to(self._device)\n\n    def get_features(self, input_signal, length):\n        return self.featurizer(input_signal)\n\n\nclass SpectrogramAugmentation(nn.Module):\n    """"""\n    Performs time and freq cuts in one of two ways.\n\n    SpecAugment zeroes out vertical and horizontal sections as described in\n    SpecAugment (https://arxiv.org/abs/1904.08779). Arguments for use with\n    SpecAugment are `freq_masks`, `time_masks`, `freq_width`, and `time_width`.\n\n    SpecCutout zeroes out rectangulars as described in Cutout\n    (https://arxiv.org/abs/1708.04552). Arguments for use with Cutout are\n    `rect_masks`, `rect_freq`, and `rect_time`.\n\n    Args:\n        freq_masks (int): how many frequency segments should be cut.\n            Defaults to 0.\n        time_masks (int): how many time segments should be cut\n            Defaults to 0.\n        freq_width (int): maximum number of frequencies to be cut in one\n            segment.\n            Defaults to 10.\n        time_width (int): maximum number of time steps to be cut in one\n            segment\n            Defaults to 10.\n        rect_masks (int): how many rectangular masks should be cut\n            Defaults to 0.\n        rect_freq (int): maximum size of cut rectangles along the frequency\n            dimension\n            Defaults to 5.\n        rect_time (int): maximum size of cut rectangles along the time\n            dimension\n            Defaults to 25.\n    """"""\n\n    def __init__(\n            self, *,\n            freq_masks=0,\n            time_masks=0,\n            freq_width=10,\n            time_width=10,\n            rect_masks=0,\n            rect_time=5,\n            rect_freq=20,\n            rng=None,\n            **kwargs\n    ):\n        nn.Module.__init__(self)\n\n        if rect_masks > 0:\n            self.spec_cutout = SpecCutout(\n                rect_masks=rect_masks,\n                rect_time=rect_time,\n                rect_freq=rect_freq,\n                rng=rng\n            )\n            # self.spec_cutout.to(self._device)\n        else:\n            self.spec_cutout = lambda x: x\n\n        if freq_masks + time_masks > 0:\n            self.spec_augment = SpecAugment(\n                freq_masks=freq_masks,\n                time_masks=time_masks,\n                freq_width=freq_width,\n                time_width=time_width,\n                rng=rng\n            )\n            # self.spec_augment.to(self._device)\n        else:\n            self.spec_augment = lambda x: x\n\n    def forward(self, input_spec):\n        augmented_spec = self.spec_cutout(input_spec)\n        augmented_spec = self.spec_augment(augmented_spec)\n        return augmented_spec\n\n\nclass MultiplyBatch(nn.Module):\n    """"""\n    Augmentation that repeats each element in a batch.\n    Other augmentations can be applied afterwards.\n\n    Args:\n        mult_batch (int): number of repeats\n    """"""\n\n    def __init__(self, *, mult_batch=1):\n        nn.Module.__init__(self)\n        self.mult = mult_batch\n\n    @torch.no_grad()\n    def forward(self, in_x, in_x_len, in_y, in_y_len):\n        out_x = in_x.repeat(self.mult, 1, 1)\n        out_y = in_y.repeat(self.mult, 1)\n        out_x_len = in_x_len.repeat(self.mult)\n        out_y_len = in_y_len.repeat(self.mult)\n\n        return out_x, out_x_len, out_y, out_y_len\n\n\ndef AudioPreprocessing(*args, **kwargs):\n    raise NotImplementedError(\n        ""AudioPreprocessing has been deprecated and replaced by: ""\n        ""AudioToMFCCPreprocessor, AudioToMelSpectrogramPreprocessor, and ""\n        ""AudioToSpectrogramPreprocessor. For most ASR purposes ""\n        ""AudioToMelSpectrogramPreprocessor does the same as the old ""\n        ""AudioPreprocessing."")\n'"
brevitas_examples/speech_to_text/quartznet/data_layer.py,3,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nThis package contains Neural Modules responsible for ASR-related\ndata layers.\n""""""\n__all__ = [\'AudioToTextDataLayer\']\nfrom functools import partial\nimport torch\nimport torch.nn as nn\n\nfrom .parts.dataset import (AudioDataset, seq_collate_fn)\nfrom .parts.features import WaveformFeaturizer\n\ndef pad_to(x, k=8):\n    """"""Pad int value up to divisor of k.\n\n    Examples:\n        >>> pad_to(31, 8)\n        32\n\n    """"""\n\n    return x + (x % k > 0) * (k - x % k)\n\nclass AudioToTextDataLayer(nn.Module):\n    """"""Data Layer for general ASR tasks.\n\n    Module which reads ASR labeled data. It accepts comma-separated\n    JSON manifest files describing the correspondence between wav audio files\n    and their transcripts. JSON files should be of the following format::\n\n        {""audio_filepath"": path_to_wav_0, ""duration"": time_in_sec_0, ""text"": \\\ntranscript_0}\n        ...\n        {""audio_filepath"": path_to_wav_n, ""duration"": time_in_sec_n, ""text"": \\\ntranscript_n}\n\n    Args:\n        manifest_filepath (str): Dataset parameter.\n            Path to JSON containing data.\n        labels (list): Dataset parameter.\n            List of characters that can be output by the ASR model.\n            For Jasper, this is the 28 character set {a-z \'}. The CTC blank\n            symbol is automatically added later for models using ctc.\n        batch_size (int): batch size\n        sample_rate (int): Target sampling rate for data. Audio files will be\n            resampled to sample_rate if it is not already.\n            Defaults to 16000.\n        int_values (bool): Bool indicating whether the audio file is saved as\n            int data or float data.\n            Defaults to False.\n        eos_id (str): Dataset parameter.\n            End of string symbol used for seq2seq models.\n            Defaults to None.\n        min_duration (float): Dataset parameter.\n            All training files which have a duration less than min_duration\n            are dropped. Note: Duration is read from the manifest JSON.\n            Defaults to 0.1.\n        max_duration (float): Dataset parameter.\n            All training files which have a duration more than max_duration\n            are dropped. Note: Duration is read from the manifest JSON.\n            Defaults to None.\n        normalize_transcripts (bool): Dataset parameter.\n            Whether to use automatic text cleaning.\n            It is highly recommended to manually clean text for best results.\n            Defaults to True.\n        trim_silence (bool): Whether to use trim silence from beginning and end\n            of audio signal using librosa.effects.trim().\n            Defaults to False.\n        load_audio (bool): Dataset parameter.\n            Controls whether the dataloader loads the audio signal and\n            transcript or just the transcript.\n            Defaults to True.\n        drop_last (bool): See PyTorch DataLoader.\n            Defaults to False.\n        shuffle (bool): See PyTorch DataLoader.\n            Defaults to True.\n        num_workers (int): See PyTorch DataLoader.\n            Defaults to 0.\n        perturb_config (dict): Currently disabled.\n    """"""\n\n    def __init__(\n            self, *,\n            manifest_filepath,\n            labels,\n            batch_size,\n            sample_rate=16000,\n            int_values=False,\n            bos_id=None,\n            eos_id=None,\n            pad_id=None,\n            min_duration=0.1,\n            max_duration=None,\n            normalize_transcripts=True,\n            trim_silence=False,\n            load_audio=True,\n            drop_last=False,\n            shuffle=True,\n            num_workers=4,\n            placement=\'cpu\',\n            # perturb_config=None,\n            **kwargs\n    ):\n        super().__init__()\n\n        self._featurizer = WaveformFeaturizer(\n            sample_rate=sample_rate, int_values=int_values, augmentor=None)\n\n        # Set up dataset\n        dataset_params = {\'manifest_filepath\': manifest_filepath,\n                          \'labels\': labels,\n                          \'featurizer\': self._featurizer,\n                          \'max_duration\': max_duration,\n                          \'min_duration\': min_duration,\n                          \'normalize\': normalize_transcripts,\n                          \'trim\': trim_silence,\n                          \'bos_id\': bos_id,\n                          \'eos_id\': eos_id,\n                          \'logger\': None,\n                          \'load_audio\': load_audio}\n\n        self._dataset = AudioDataset(**dataset_params)\n\n        # Set up data loader\n        if placement == \'cuda\':\n            print(\'Parallelizing DATALAYER\')\n            sampler = torch.utils.data.distributed.DistributedSampler(\n                self._dataset)\n        else:\n            sampler = None\n\n        pad_id = 0 if pad_id is None else pad_id\n        self._dataloader = torch.utils.data.DataLoader(\n            dataset=self._dataset,\n            batch_size=batch_size,\n            collate_fn=partial(seq_collate_fn, token_pad_value=pad_id),\n            drop_last=drop_last,\n            shuffle=shuffle if sampler is None else False,\n            sampler=sampler,\n            num_workers=num_workers\n        )\n\n    def __len__(self):\n        return len(self._dataset)\n\n    @property\n    def dataset(self):\n        return None\n\n    @property\n    def data_iterator(self):\n        return self._dataloader\n\n'"
brevitas_examples/speech_to_text/quartznet/greedy_ctc_decoder.py,2,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport torch\nimport torch.nn as nn\n\nclass GreedyCTCDecoder(nn.Module):\n    """"""\n    Greedy decoder that computes the argmax over a softmax distribution\n    """"""\n    def __init__(self):\n        nn.Module.__init__(self)\n\n    def forward(self, log_probs):\n        with torch.no_grad():\n            argmx = log_probs.argmax(dim=-1, keepdim=False)\n            return argmx\n'"
brevitas_examples/speech_to_text/quartznet/helpers.py,3,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch\n\nfrom .metrics import word_error_rate\n\n\ndef __ctc_decoder_predictions_tensor(tensor, labels):\n    """"""\n    Decodes a sequence of labels to words\n    """"""\n    blank_id = len(labels)\n    hypotheses = []\n    labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n    prediction_cpu_tensor = tensor.long().cpu()\n    # iterate over batch\n    for ind in range(prediction_cpu_tensor.shape[0]):\n        # print(prediction)\n        prediction = prediction_cpu_tensor[ind].numpy().tolist()\n        # CTC decoding procedure\n        decoded_prediction = []\n        previous = len(labels)  # id of a blank symbol\n        for p in prediction:\n            if (p != previous or previous == blank_id) and p != blank_id:\n                decoded_prediction.append(p)\n            previous = p\n        hypothesis = \'\'.join([labels_map[c] for c in decoded_prediction])\n        hypotheses.append(hypothesis)\n    return hypotheses\n\n\ndef monitor_asr_train_progress(tensors: list,\n                               labels: list,\n                               eval_metric=\'WER\',\n                               tb_logger=None,\n                               logger=None):\n    """"""\n    Takes output of greedy ctc decoder and performs ctc decoding algorithm to\n    remove duplicates and special symbol. Prints sample to screen, computes\n    and logs AVG WER to console and (optionally) Tensorboard\n    Args:\n      tensors: A list of 3 tensors (predictions, targets, target_lengths)\n      labels: A list of labels\n      eval_metric: An optional string from \'WER\', \'CER\'. Defaults to \'WER\'.\n      tb_logger: Tensorboard logging object\n      logger:\n    Returns:\n      None\n    """"""\n    references = []\n\n    labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n    with torch.no_grad():\n        # prediction_cpu_tensor = tensors[0].long().cpu()\n        targets_cpu_tensor = tensors[2].long().cpu()\n        tgt_lenths_cpu_tensor = tensors[3].long().cpu()\n\n        # iterate over batch\n        for ind in range(targets_cpu_tensor.shape[0]):\n            tgt_len = tgt_lenths_cpu_tensor[ind].item()\n            target = targets_cpu_tensor[ind][:tgt_len].numpy().tolist()\n            reference = \'\'.join([labels_map[c] for c in target])\n            references.append(reference)\n        hypotheses = __ctc_decoder_predictions_tensor(\n            tensors[1], labels=labels)\n\n    eval_metric = eval_metric.upper()\n    if eval_metric not in {\'WER\', \'CER\'}:\n        raise ValueError(\'eval_metric must be \\\'WER\\\' or \\\'CER\\\'\')\n    use_cer = True if eval_metric == \'CER\' else False\n\n    tag = f\'training_batch_{eval_metric}\'\n    wer = word_error_rate(hypotheses, references, use_cer=use_cer)\n    if tb_logger is not None:\n        tb_logger.add_scalar(tag, wer)\n    if logger:\n        logger.info(f\'Loss: {tensors[0]}\')\n        logger.info(f\'{tag}: {wer*100 : 5.2f}%\')\n        logger.info(f\'Prediction: {hypotheses[0]}\')\n        logger.info(f\'Reference: {references[0]}\')\n    else:\n        print(f\'Loss: {tensors[0]}\')\n        print(f\'{tag}: {wer*100 : 5.2f}%\')\n        print(f\'Prediction: {hypotheses[0]}\')\n        print(f\'Reference: {references[0]}\')\n\n\ndef __gather_losses(losses_list: list) -> list:\n    return [torch.mean(torch.stack(losses_list))]\n\n\ndef __gather_predictions(predictions_list: list, labels: list) -> list:\n    results = []\n    for prediction in predictions_list:\n        results += __ctc_decoder_predictions_tensor(prediction, labels=labels)\n    return results\n\n\ndef __gather_transcripts(transcript_list: list, transcript_len_list: list,\n                         labels: list) -> list:\n    results = []\n    labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n    # iterate over workers\n    for t, ln in zip(transcript_list, transcript_len_list):\n        # iterate over batch\n        t_lc = t.long().cpu()\n        ln_lc = ln.long().cpu()\n        for ind in range(t.shape[0]):\n            tgt_len = ln_lc[ind].item()\n            target = t_lc[ind][:tgt_len].numpy().tolist()\n            reference = \'\'.join([labels_map[c] for c in target])\n            results.append(reference)\n    return results\n\n\ndef process_evaluation_batch(tensors: dict, global_vars: dict, labels: list):\n    """"""\n    Creates a dictionary holding the results from a batch of audio\n    """"""\n    if \'EvalLoss\' not in global_vars.keys():\n        global_vars[\'EvalLoss\'] = []\n    if \'predictions\' not in global_vars.keys():\n        global_vars[\'predictions\'] = []\n    if \'transcripts\' not in global_vars.keys():\n        global_vars[\'transcripts\'] = []\n    if \'logits\' not in global_vars.keys():\n        global_vars[\'logits\'] = []\n    # if not \'transcript_lengths\' in global_vars.keys():\n    #  global_vars[\'transcript_lengths\'] = []\n    for kv, v in tensors.items():\n        if kv.startswith(\'loss\'):\n            global_vars[\'EvalLoss\'] += __gather_losses(v)\n        elif kv.startswith(\'predictions\'):\n            global_vars[\'predictions\'] += __gather_predictions(\n                v, labels=labels)\n        elif kv.startswith(\'transcript_length\'):\n            transcript_len_list = v\n        elif kv.startswith(\'transcript\'):\n            transcript_list = v\n        elif kv.startswith(\'output\'):\n            global_vars[\'logits\'] += v\n\n    global_vars[\'transcripts\'] += __gather_transcripts(transcript_list,\n                                                       transcript_len_list,\n                                                       labels=labels)\n\n\ndef process_evaluation_epoch(global_vars: dict,\n                             eval_metric=\'WER\',\n                             tag=None,\n                             logger=None):\n    """"""\n    Calculates the aggregated loss and WER across the entire evaluation dataset\n    """"""\n    eloss = torch.mean(torch.stack(global_vars[\'EvalLoss\'])).item()\n    hypotheses = global_vars[\'predictions\']\n    references = global_vars[\'transcripts\']\n\n    eval_metric = eval_metric.upper()\n    if eval_metric not in {\'WER\', \'CER\'}:\n        raise ValueError(\'eval_metric must be \\\'WER\\\' or \\\'CER\\\'\')\n    use_cer = True if eval_metric == \'CER\' else False\n\n    wer = word_error_rate(hypotheses=hypotheses,\n                          references=references,\n                          use_cer=use_cer)\n\n    if tag is None:\n        if logger:\n            logger.info(f""==========>>>>>>Evaluation Loss: {eloss}"")\n            logger.info(f""==========>>>>>>Evaluation {eval_metric}: ""\n                        f""{wer*100 : 5.2f}%"")\n        else:\n            print(f""==========>>>>>>Evaluation Loss: {eloss}"")\n            print(f""==========>>>>>>Evaluation {eval_metric}: ""\n                  f""{wer*100 : 5.2f}%"")\n        return {""Evaluation_Loss"": eloss, f""Evaluation_{eval_metric}"": wer}\n    else:\n        if logger:\n            logger.info(f""==========>>>>>>Evaluation Loss {tag}: {eloss}"")\n            logger.info(f""==========>>>>>>Evaluation {eval_metric} {tag}: ""\n                        f""{wer*100 : 5.2f}%"")\n        else:\n            print(f""==========>>>>>>Evaluation Loss {tag}: {eloss}"")\n            print(f""==========>>>>>>Evaluation {eval_metric} {tag}:""\n                  f"" {wer*100 : 5.2f}%"")\n        return {f""Evaluation_Loss_{tag}"": eloss,\n                f""Evaluation_{eval_metric}_{tag}"": wer}\n\n\ndef post_process_predictions(predictions, labels):\n    return __gather_predictions(predictions, labels=labels)\n\n\ndef post_process_transcripts(\n        transcript_list, transcript_len_list, labels):\n    return __gather_transcripts(transcript_list,\n                                transcript_len_list,\n                                labels=labels)\n'"
brevitas_examples/speech_to_text/quartznet/losses.py,2,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport torch\nimport torch.nn as nn\n\n\nclass CTCLossNM(nn.Module):\n    """"""\n    Neural Module wrapper for pytorch\'s ctcloss\n\n    Args:\n        num_classes (int): Number of characters in ASR model\'s vocab/labels.\n            This count should not include the CTC blank symbol.\n    """"""\n\n    def __init__(self, *, num_classes, **kwargs):\n        nn.Module.__init__(self)\n\n        # self._blank = self.local_parameters.get(\'blank\', 0)\n        self._blank = num_classes\n        self._criterion = nn.CTCLoss(blank=self._blank,\n                                     reduction=\'none\')\n\n    def _loss(self, log_probs, targets, input_length, target_length):\n        input_length = input_length.long()\n        target_length = target_length.long()\n        targets = targets.long()\n        loss = self._criterion(log_probs.transpose(1, 0), targets,\n                               input_length,\n                               target_length)\n        # note that this is different from reduction = \'mean\'\n        # because we are not dividing by target lengths\n        loss = torch.mean(loss)\n        return loss\n\n    def _loss_function(self, **kwargs):\n        return self._loss(*(kwargs.values()))\n'"
brevitas_examples/speech_to_text/quartznet/metrics.py,0,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom typing import List\n\n\ndef __levenshtein(a: List, b: List) -> int:\n    """"""Calculates the Levenshtein distance between a and b.\n    The code was copied from: http://hetland.org/coding/python/levenshtein.py\n    """"""\n    n, m = len(a), len(b)\n    if n > m:\n        # Make sure n <= m, to use O(min(n,m)) space\n        a, b = b, a\n        n, m = m, n\n\n    current = list(range(n + 1))\n    for i in range(1, m + 1):\n        previous, current = current, [i] + [0] * n\n        for j in range(1, n + 1):\n            add, delete = previous[j] + 1, current[j - 1] + 1\n            change = previous[j - 1]\n            if a[j - 1] != b[i - 1]:\n                change = change + 1\n            current[j] = min(add, delete, change)\n\n    return current[n]\n\n\ndef word_error_rate(hypotheses: List[str],\n                    references: List[str],\n                    use_cer=False) -> float:\n    """"""\n    Computes Average Word Error rate between two texts represented as\n    corresponding lists of string. Hypotheses and references must have same\n    length.\n\n    Args:\n      hypotheses: list of hypotheses\n      references: list of references\n      use_cer: bool, set True to enable cer\n    Returns:\n      (float) average word error rate\n    """"""\n    scores = 0\n    words = 0\n    if len(hypotheses) != len(references):\n        raise ValueError(\n            ""In word error rate calculation, hypotheses and reference""\n            "" lists must have the same number of elements. But I got:""\n            ""{0} and {1} correspondingly"".format(len(hypotheses),\n                                                 len(references)))\n    for h, r in zip(hypotheses, references):\n        if use_cer:\n            h_list = list(h)\n            r_list = list(r)\n        else:\n            h_list = h.split()\n            r_list = r.split()\n        words += len(r_list)\n        scores += __levenshtein(h_list, r_list)\n    if words != 0:\n        wer = 1.0 * scores / words\n    else:\n        wer = float(\'inf\')\n    return wer\n'"
brevitas_examples/speech_to_text/quartznet/quartznet.py,2,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/nemo_asr/jasper.py\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom typing import Optional\n\nfrom .audio_preprocessing import AudioToMelSpectrogramPreprocessor\nfrom .parts.quartznet import JasperBlock, init_weights\nfrom .parts.common import *\nfrom .greedy_ctc_decoder import GreedyCTCDecoder\n\n\nclass JasperEncoder(nn.Module):\n    """"""\n    Jasper Encoder creates the pre-processing (prologue), Jasper convolution\n    block, and the first 3 post-processing (epilogue) layers as described in\n    Jasper (https://arxiv.org/abs/1904.03288)\n\n    Args:\n        jasper (list): A list of dictionaries. Each element in the list\n            represents the configuration of one Jasper Block. Each element\n            should contain::\n\n                {\n                    # Required parameters\n                    \'filters\' (int) # Number of output channels,\n                    \'repeat\' (int) # Number of sub-blocks,\n                    \'kernel\' (int) # Size of conv kernel,\n                    \'stride\' (int) # Conv stride\n                    \'dilation\' (int) # Conv dilation\n                    \'dropout\' (float) # Dropout probability\n                    \'residual\' (bool) # Whether to use residual or not.\n                    # Optional parameters\n                    \'residual_dense\' (bool) # Whether to use Dense Residuals\n                        # or not. \'residual\' must be True for \'residual_dense\'\n                        # to be enabled.\n                        # Defaults to False.\n                    \'separable\' (bool) # Whether to use separable convolutions.\n                        # Defaults to False\n                    \'groups\' (int) # Number of groups in each conv layer.\n                        # Defaults to 1\n                    \'heads\' (int) # Sharing of separable filters\n                        # Defaults to -1\n                    \'tied\' (bool)  # Whether to use the same weights for all\n                        # sub-blocks.\n                        # Defaults to False\n                }\n\n        activation (str): Activation function used for each sub-blocks. Can be\n            one of [""hardtanh"", ""relu"", ""selu""].\n        feat_in (int): Number of channels being input to this module\n        normalization_mode (str): Normalization to be used in each sub-block.\n            Can be one of [""batch"", ""layer"", ""instance"", ""group""]\n            Defaults to ""batch"".\n        residual_mode (str): Type of residual connection.\n            Can be ""add"" or ""max"".\n            Defaults to ""add"".\n        norm_groups (int): Number of groups for ""group"" normalization type.\n            If set to -1, number of channels is used.\n            Defaults to -1.\n        conv_mask (bool): Controls the use of sequence length masking prior\n            to convolutions.\n            Defaults to True.\n        frame_splicing (int): Defaults to 1.\n        init_mode (str): Describes how neural network parameters are\n            initialized. Options are [\'xavier_uniform\', \'xavier_normal\',\n            \'kaiming_uniform\',\'kaiming_normal\'].\n            Defaults to ""xavier_uniform"".\n    """"""\n\n    def __init__(\n            self, *,\n            jasper,\n            outer_bit_width,\n            inner_bit_width,\n            weight_scaling_per_output_channel,\n            absolute_act_val,\n            activation_inner_scaling_per_output_channel,\n            activation_other_scaling_per_output_channel,\n            activation,\n            feat_in,\n            fused_bn=False,\n            normalization_mode=""batch"",\n            residual_mode=""add"",\n            norm_groups=-1,\n            conv_mask=True,\n            frame_splicing=1,\n            init_mode=\'xavier_uniform\',\n            **kwargs\n    ):\n        nn.Module.__init__(self)\n\n        feat_in = feat_in * frame_splicing\n\n        residual_panes = []\n        encoder_layers = []\n        self.dense_residual = False\n\n        for it, lcfg in enumerate(jasper):\n            if it == 0:\n                bit_width = outer_bit_width\n            else:\n                bit_width = inner_bit_width\n\n            dense_res = []\n            if lcfg.get(\'residual_dense\', False):\n                residual_panes.append(feat_in)\n                dense_res = residual_panes\n                self.dense_residual = True\n            groups = lcfg.get(\'groups\', 1)\n            separable = lcfg.get(\'separable\', False)\n            heads = lcfg.get(\'heads\', -1)\n            encoder_layers.append(\n                JasperBlock(feat_in,\n                            lcfg[\'filters\'],\n                            repeat=lcfg[\'repeat\'],\n                            kernel_size=lcfg[\'kernel\'],\n                            stride=lcfg[\'stride\'],\n                            dilation=lcfg[\'dilation\'],\n                            dropout=lcfg[\'dropout\'],\n                            residual=lcfg[\'residual\'],\n                            groups=groups,\n                            fused_bn=fused_bn,\n                            separable=separable,\n                            heads=heads,\n                            residual_mode=residual_mode,\n                            normalization=normalization_mode,\n                            norm_groups=norm_groups,\n                            activation=activation,\n                            residual_panes=dense_res,\n                            conv_mask=conv_mask,\n                            bit_width=bit_width,\n                            absolute_act_val=absolute_act_val,\n                            activation_inner_scaling_per_output_channel=activation_inner_scaling_per_output_channel,\n                            activation_other_scaling_per_output_channel=activation_other_scaling_per_output_channel,\n                            weight_scaling_per_output_channel=weight_scaling_per_output_channel),\n                            )\n            feat_in = lcfg[\'filters\']\n\n        self.encoder = nn.Sequential(*encoder_layers)\n        self.apply(lambda x: init_weights(x, mode=init_mode))\n        # self.to(self._device)\n\n    def forward(self, audio_signal, length=None):\n        # type: (Tensor, Optional[Tensor]) -> Tensor, Optional[Tensor]\n\n        s_input, length = self.encoder(([audio_signal], length))\n        if length is None:\n            return s_input[-1]\n        return s_input[-1], length\n\n\nclass JasperDecoderForCTC(nn.Module):\n    """"""\n    Jasper Decoder creates the final layer in Jasper that maps from the outputs\n    of Jasper Encoder to the vocabulary of interest.\n\n    Args:\n        feat_in (int): Number of channels being input to this module\n        num_classes (int): Number of characters in ASR model\'s vocab/labels.\n            This count should not include the CTC blank symbol.\n        init_mode (str): Describes how neural network parameters are\n            initialized. Options are [\'xavier_uniform\', \'xavier_normal\',\n            \'kaiming_uniform\',\'kaiming_normal\'].\n            Defaults to ""xavier_uniform"".\n    """"""\n\n    def __init__(\n            self, *,\n            feat_in,\n            num_classes,\n            bit_width,\n            weight_scaling_per_channel,\n            init_mode=""xavier_uniform"",\n            **kwargs\n    ):\n        nn.Module.__init__(self)\n\n        self._feat_in = feat_in\n        # Add 1 for blank char\n        self._num_classes = num_classes + 1\n\n        self.decoder_layers = nn.Sequential(\n            make_quantconv1d(self._feat_in, self._num_classes, kernel_size=1,bias=True, bit_width=bit_width,\n                             scaling_per_channel=weight_scaling_per_channel))\n        self.apply(lambda x: init_weights(x, mode=init_mode))\n\n    def forward(self, encoder_output):\n        return F.log_softmax(self.decoder_layers(encoder_output).\n                             transpose(1, 2), dim=-1)\n\nclass Quartznet(nn.Module):\n    def __init__(self, preprocessing, encoder, decoder, greedyctcdecoder):\n        super(Quartznet, self).__init__()\n        self.preprocessing = preprocessing\n        self.encoder = encoder\n        self.decoder = decoder\n        self.greedy_ctc_decoder = greedyctcdecoder\n\n    def forward(self, input_tensors):\n        audio_signal_e1, a_sig_length_e1, _, _ = input_tensors\n        processed_signal_e1, p_length_e1 = self.preprocessing(\n            input_signal=audio_signal_e1,\n            length=a_sig_length_e1)\n        encoded_e1, encoded_len_e1 = self.encoder(\n            audio_signal=processed_signal_e1,\n            length=p_length_e1)\n        log_probs_e1 = self.decoder(encoder_output=encoded_e1)\n        predictions_e1 = self.greedy_ctc_decoder(log_probs=log_probs_e1)\n        return predictions_e1\n\n    def restore_checkpoints(self, encoder_state_dict, decoder_state_dict):\n        self.encoder.load_state_dict(encoder_state_dict)\n        self.decoder.load_state_dict(decoder_state_dict)\n        print(""Checkpoint restored"")\n\n\ndef quartznet(cfg, quartzet_params):\n\n    outer_bit_width = cfg.getint(\'QUANT\', \'OUTER_LAYERS_BIT_WIDTH\')\n    inner_bit_width = cfg.getint(\'QUANT\', \'INNER_LAYERS_BIT_WIDTH\')\n    activation_inner_scaling_per_output_channel = cfg.getboolean(\'ACTIVATIONS\', \'INNER_SCALING_PER_CHANNEL\')\n    activation_other_scaling_per_output_channel = cfg.getboolean(\'ACTIVATIONS\', \'OTHER_SCALING_PER_CHANNEL\')\n    absolute_act_val = cfg.getint(\'ACTIVATIONS\', \'ABS_ACT_VAL\')\n    encoder_weight_scaling_per_output_channel = cfg.get(\'WEIGHT\', \'ENCODER_SCALING_PER_OUTPUT_CHANNEL\')\n    decoder_weight_scaling_per_output_channel = cfg.get(\'WEIGHT\', \'DECODER_SCALING_PER_OUTPUT_CHANNEL\')\n    fused_bn = cfg.getboolean(\'QUANT\', \'FUSED_BN\')\n\n    vocab = quartzet_params[\'labels\']\n    sample_rate = quartzet_params[\'sample_rate\']\n    feat_in_encoder = quartzet_params[""AudioToMelSpectrogramPreprocessor""][""features""]\n    feat_in_decoder = quartzet_params[""JasperEncoder""][""jasper""][-1][""filters""]\n\n    data_preprocessor = AudioToMelSpectrogramPreprocessor(\n        sample_rate=sample_rate,\n        **quartzet_params[""AudioToMelSpectrogramPreprocessor""])\n\n    encoder = JasperEncoder(\n        feat_in=feat_in_encoder,\n        weight_scaling_per_output_channel=encoder_weight_scaling_per_output_channel,\n        inner_bit_width=inner_bit_width,\n        outer_bit_width=outer_bit_width,\n        absolute_act_val=absolute_act_val,\n        activation_inner_scaling_per_output_channel=activation_inner_scaling_per_output_channel,\n        activation_other_scaling_per_output_channel=activation_other_scaling_per_output_channel,\n        fused_bn=fused_bn,\n        **quartzet_params[""JasperEncoder""])\n    #\n    decoder = JasperDecoderForCTC(\n        feat_in=feat_in_decoder,\n        bit_width=outer_bit_width,\n        weight_scaling_per_channel=decoder_weight_scaling_per_output_channel,\n        num_classes=len(vocab))\n\n    greedy_decoder = GreedyCTCDecoder()\n\n    model = Quartznet(data_preprocessor, encoder, decoder, greedy_decoder)\n    return model\n\n'"
brevitas_examples/text_to_speech/cfg/__init__.py,0,b''
brevitas_examples/text_to_speech/melgan/__init__.py,0,"b""import os\nfrom configparser import ConfigParser\n\nfrom torch import hub\n\nfrom .melgan import *\n\nmodel_impl = {\n    'melgan': melgan,\n}\n\n\ndef model_with_cfg(name, pretrained):\n    cfg = ConfigParser()\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    config_path = os.path.join(current_dir, '..', 'cfg', name + '.ini')\n    assert os.path.exists(config_path)\n    cfg.read(config_path)\n    arch = cfg.get('MODEL', 'ARCH')\n    model = model_impl[arch](cfg)\n    if pretrained:\n        checkpoint = cfg.get('MODEL', 'PRETRAINED_URL')\n        state_dict = hub.load_state_dict_from_url(checkpoint, progress=True, map_location='cpu')\n        model.load_state_dict(state_dict, strict=True)\n    return model, cfg\n\n\ndef quant_melgan_8b(pretrained=True):\n    model, _ = model_with_cfg('quant_melgan_8b', pretrained)\n    return model\n"""
brevitas_examples/text_to_speech/melgan/common.py,1,"b'""""""BSD 3-Clause License\n\nCopyright (c) 2020 Xilinx, Inc (Giuseppe Franco)\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.""""""\n\nimport brevitas.nn as quant_nn\nfrom brevitas.core.quant import QuantType\nfrom brevitas.core.scaling import ScalingImplType\nfrom brevitas.core.stats import StatsOp\nimport torch.nn as nn\n\nQUANT_TYPE = QuantType.INT\nQUANT_TYPE_BIAS = QuantType.FP\n\nSCALING_MIN_VAL = 2e-9\nACT_SCALING_IMPL_TYPE = ScalingImplType.CONST\nACT_SCALING_PER_CHANNEL = False\nACT_MAX_VAL = 1\nACT_MIN_VAL = -1\n\nWEIGHT_SCALING_IMPL_TYPE = ScalingImplType.PARAMETER_FROM_STATS\nWEIGHT_SCALING_STATS_OP = StatsOp.MAX\nWEIGHT_NARROW_RANGE = True\nBIAS_CONFIGS = False\n\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n\n    def forward(self, x):\n        return x\n\n\ndef make_quantconv1d(feat_in, feat_out, kernel_size, stride, padding, bit_width, dilation=1, group=1):\n    return quant_nn.QuantConv1d(in_channels=feat_in, out_channels=feat_out, kernel_size=kernel_size,\n                                stride=stride,\n                                padding=padding,\n                                dilation=dilation,\n                                groups=group,\n                                weight_bit_width=bit_width,\n                                weight_quant_type=QUANT_TYPE,\n                                weight_narrow_range=WEIGHT_NARROW_RANGE,\n                                weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n                                weight_scaling_stats_op=WEIGHT_SCALING_STATS_OP,\n                                weight_scaling_min_val=SCALING_MIN_VAL,\n                                bias_bit_width=bit_width,\n                                bias_quant_type=QUANT_TYPE_BIAS,\n                                bias_narrow_range=BIAS_CONFIGS,\n                                compute_output_scale=BIAS_CONFIGS,\n                                compute_output_bit_width=BIAS_CONFIGS,\n                                return_quant_tensor=False)\n\n\ndef make_transpconv1d(feat_in, feat_out, kernel_size, stride, padding, bit_width, dilation=1):\n    return quant_nn.QuantConvTranspose1d(in_channels=feat_in, out_channels=feat_out, kernel_size=kernel_size,\n                                         stride=stride,\n                                         padding=padding,\n                                         dilation=dilation,\n                                         weight_bit_width=bit_width,\n                                         weight_quant_type=QUANT_TYPE,\n                                         weight_narrow_range=WEIGHT_NARROW_RANGE,\n                                         weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n                                         weight_scaling_stats_op=WEIGHT_SCALING_STATS_OP,\n                                         weight_scaling_min_val=SCALING_MIN_VAL,\n                                         bias_bit_width=bit_width,\n                                         bias_quant_type=QUANT_TYPE_BIAS,\n                                         bias_narrow_range=BIAS_CONFIGS,\n                                         compute_output_scale=BIAS_CONFIGS,\n                                         compute_output_bit_width=BIAS_CONFIGS,\n                                         return_quant_tensor=False)\n\n\ndef make_relu_activation(bit_width):\n    return quant_nn.QuantReLU(bit_width=bit_width,\n                              max_val=ACT_MAX_VAL,\n                              quant_type=QUANT_TYPE,\n                              scaling_impl_type=ACT_SCALING_IMPL_TYPE,\n                              scaling_min_val=SCALING_MIN_VAL,\n                              return_quant_tensor=False\n                              )\n\n\ndef make_hardtanh_activation(bit_width, return_quant_tensor=False):\n    return quant_nn.QuantHardTanh(bit_width=bit_width,\n                                  max_val=ACT_MAX_VAL,\n                                  min_val=ACT_MIN_VAL,\n                                  quant_type=QUANT_TYPE,\n                                  scaling_impl_type=ACT_SCALING_IMPL_TYPE,\n                                  scaling_min_val=SCALING_MIN_VAL,\n                                  return_quant_tensor=return_quant_tensor\n                                  )\n\n\ndef make_tanh_activation(bit_width):\n    return quant_nn.QuantTanh(bit_width=bit_width,\n                              quant_type=QUANT_TYPE,\n                              scaling_min_val=SCALING_MIN_VAL,\n                              return_quant_tensor=False\n                              )\n\n\ndef make_leakyRelu_activation(bit_width):\n    el1 = nn.LeakyReLU()\n    el2 = make_hardtanh_activation(bit_width=bit_width)\n    layer = nn.Sequential(el1, el2)\n\n    return layer\n'"
brevitas_examples/text_to_speech/melgan/generator_brevitas.py,4,"b'""""""BSD 3-Clause License\nSource: https://github.com/seungwonpark/melgan\n\nCopyright (c) 2020 Xilinx, Inc (Giuseppe Franco)\nCopyright (c) 2019, Seungwon Park \xeb\xb0\x95\xec\x8a\xb9\xec\x9b\x90\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.""""""\n\nimport torch\nfrom .res_stack_brevitas import ResStack\nfrom .common import *\n\nMAX_WAV_VALUE = 32768.0\n\n\nclass Generator(nn.Module):\n    def __init__(self, mel_channel, bit_width, last_layer_bit_width):\n        super(Generator, self).__init__()\n        self.mel_channel = mel_channel\n\n        self.generator = nn.Sequential(\n            nn.utils.weight_norm(make_quantconv1d(mel_channel, 512, kernel_size=7, stride=1, padding=3,\n                                                  bit_width=bit_width)),\n\n            make_leakyRelu_activation(bit_width=bit_width),\n\n            nn.utils.weight_norm(make_transpconv1d(512, 256, kernel_size=16, stride=8, padding=4,\n                                                   bit_width=bit_width)),\n\n            ResStack(256, bit_width=bit_width),\n\n            make_leakyRelu_activation(bit_width),\n            nn.utils.weight_norm(make_transpconv1d(256, 128, kernel_size=16, stride=8, padding=4,\n                                                   bit_width=bit_width)),\n\n            ResStack(128, bit_width=bit_width),\n\n            make_leakyRelu_activation(bit_width),\n            nn.utils.weight_norm(make_transpconv1d(128, 64, kernel_size=4, stride=2, padding=1,\n                                                   bit_width=bit_width)),\n\n            ResStack(64, bit_width=bit_width),\n\n            make_leakyRelu_activation(bit_width),\n            nn.utils.weight_norm(\n                make_transpconv1d(64, 32, kernel_size=4, stride=2, padding=1, bit_width=bit_width)),\n\n            ResStack(32, bit_width=bit_width),\n\n            make_leakyRelu_activation(bit_width),\n            nn.utils.weight_norm(\n                make_quantconv1d(32, 1, kernel_size=7, stride=1, padding=3, bit_width=bit_width)),\n            make_tanh_activation(bit_width=last_layer_bit_width),\n        )\n\n    def forward(self, mel):\n        mel = (mel + 5.0) / 5.0  # roughly normalize spectrogram\n        return self.generator(mel)\n\n    def eval(self, inference=False):\n        super(Generator, self).eval()\n\n        # don\'t remove weight norm while validation in training loop\n        if inference:\n            self.remove_weight_norm()\n\n    def remove_weight_norm(self):\n        for idx, layer in enumerate(self.generator):\n            if len(layer.state_dict()) != 0:\n                try:\n                    nn.utils.remove_weight_norm(layer)\n                except:\n                    layer.remove_weight_norm()\n\n    def inference(self, mel):\n        hop_length = 256\n        # pad input mel with zeros to cut artifact\n        # see https://github.com/seungwonpark/melgan/issues/8\n        zero = torch.full((1, self.mel_channel, 10), -11.5129).to(mel.device)\n        mel = torch.cat((mel, zero), dim=2)\n\n        audio = self.forward(mel)\n        audio = audio.squeeze()  # collapse all dimension except time axis\n        audio = audio[:-(hop_length * 10)]\n        audio = MAX_WAV_VALUE * audio\n        audio = audio.clamp(min=-MAX_WAV_VALUE, max=MAX_WAV_VALUE - 1)\n        audio = audio.short()\n\n        return audio\n\n\n\'\'\'\n    to run this, fix \n    from . import ResStack\n    into\n    from res_stack import ResStack\n\'\'\'\nif __name__ == \'__main__\':\n    model = Generator(7)\n\n    x = torch.randn(3, 7, 10)\n    print(x.shape)\n\n    y = model(x)\n    print(y.shape)\n    assert y.shape == torch.Size([3, 1, 2560])\n'"
brevitas_examples/text_to_speech/melgan/melgan.py,0,"b'""""""BSD 3-Clause License\nSource: https://github.com/seungwonpark/melgan\n\nCopyright (c) 2020 Xilinx, Inc (Giuseppe Franco)\nCopyright (c) 2019, Seungwon Park \xeb\xb0\x95\xec\x8a\xb9\xec\x9b\x90\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.""""""\n\nfrom .generator_brevitas import Generator\n\n\ndef melgan(cfg):\n    bit_width = cfg.getint(\'QUANT\', \'BIT_WIDTH\')\n    last_layer_bit_width = cfg.getint(\'QUANT\', \'LAST_LAYER_BIT_WIDTH\')\n    mel_channels = cfg.getint(\'AUDIO\', \'n_mel_channels\')\n    model = Generator(mel_channels, bit_width, last_layer_bit_width)\n\n    return model\n'"
brevitas_examples/text_to_speech/melgan/res_stack_brevitas.py,0,"b'""""""BSD 3-Clause License\nSource: https://github.com/seungwonpark/melgan\n\nCopyright (c) 2020 Xilinx, Inc (Giuseppe Franco)\nCopyright (c) 2019, Seungwon Park \xeb\xb0\x95\xec\x8a\xb9\xec\x9b\x90\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.""""""\n\nfrom .common import *\nfrom brevitas.quant_tensor import QuantTensor\n\n\nclass ResStack(nn.Module):\n    def __init__(self, channel, bit_width):\n        super(ResStack, self).__init__()\n        self.scale_norm = make_hardtanh_activation(bit_width=bit_width, return_quant_tensor=True)\n        self.layers = nn.ModuleList([\n            nn.Sequential(\n                make_leakyRelu_activation(bit_width),\n\n                nn.utils.weight_norm(make_quantconv1d(channel, channel, kernel_size=3, stride=1, padding=3 ** i,\n                                                      dilation=3 ** i, bit_width=bit_width)),\n\n                make_leakyRelu_activation(bit_width),\n                nn.utils.weight_norm(make_quantconv1d(channel, channel, kernel_size=3, stride=1, padding=1,\n                                                      dilation=1, bit_width=bit_width)),\n            )\n            for i in range(3)\n        ])\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = self.scale_norm(x)\n            if isinstance(x, QuantTensor):\n                x_unp, _, _ = x\n            else:\n                x_unp = x\n            x_layer = self.scale_norm(layer(x_unp))\n\n            if isinstance(x_layer, QuantTensor):\n                x_layer_unp, _, _ = x_layer\n            else:\n                x_layer_unp = x_layer\n\n            if self.training:\n                x = x_unp + x_layer_unp\n            else:\n                x = x + x_layer\n\n        if isinstance(x, QuantTensor):\n            x, _, _ = x\n\n        return x\n\n    def remove_weight_norm(self):\n        for layer in self.layers:\n            nn.utils.remove_weight_norm(layer[1])\n            nn.utils.remove_weight_norm(layer[3])\n'"
brevitas_examples/text_to_speech/utilities/__init__.py,0,b'from .stft import TacotronSTFT\nfrom .audio_processing import read_wav_np'
brevitas_examples/text_to_speech/utilities/audio_processing.py,3,"b'""""""BSD 3-Clause License\nSource: https://github.com/seungwonpark/melgan\n\nCopyright (c) 2020 Xilinx, Inc (Giuseppe Franco)\nCopyright (c) 2019, Seungwon Park \xeb\xb0\x95\xec\x8a\xb9\xec\x9b\x90\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.""""""\nimport torch\nimport numpy as np\nfrom scipy.signal import get_window\nimport librosa.util as librosa_util\nfrom scipy.io.wavfile import read\n\n\ndef window_sumsquare(window, n_frames, hop_length=200, win_length=800,\n                     n_fft=800, dtype=np.float32, norm=None):\n    """"""\n    # from librosa 0.6\n    Compute the sum-square envelope of a window function at a given hop length.\n\n    This is used to estimate modulation effects induced by windowing\n    observations in short-time fourier transforms.\n\n    Parameters\n    ----------\n    window : string, tuple, number, callable, or list-like\n        Window specification, as in `get_window`\n\n    n_frames : int > 0\n        The number of analysis frames\n\n    hop_length : int > 0\n        The number of samples to advance between frames\n\n    win_length : [optional]\n        The length of the window function.  By default, this matches `n_fft`.\n\n    n_fft : int > 0\n        The length of each analysis frame.\n\n    dtype : np.dtype\n        The data type of the output\n\n    Returns\n    -------\n    wss : np.ndarray, shape=`(n_fft + hop_length * (n_frames - 1))`\n        The sum-squared envelope of the window function\n    """"""\n    if win_length is None:\n        win_length = n_fft\n\n    n = n_fft + hop_length * (n_frames - 1)\n    x = np.zeros(n, dtype=dtype)\n\n    # Compute the squared window at the desired length\n    win_sq = get_window(window, win_length, fftbins=True)\n    win_sq = librosa_util.normalize(win_sq, norm=norm)**2\n    win_sq = librosa_util.pad_center(win_sq, n_fft)\n\n    # Fill the envelope\n    for i in range(n_frames):\n        sample = i * hop_length\n        x[sample:min(n, sample + n_fft)] += win_sq[:max(0, min(n_fft, n - sample))]\n    return x\n\n\ndef griffin_lim(magnitudes, stft_fn, n_iters=30):\n    """"""\n    PARAMS\n    ------\n    magnitudes: spectrogram magnitudes\n    stft_fn: STFT class with transform (STFT) and inverse (ISTFT) methods\n    """"""\n\n    angles = np.angle(np.exp(2j * np.pi * np.random.rand(*magnitudes.size())))\n    angles = angles.astype(np.float32)\n    angles = torch.autograd.Variable(torch.from_numpy(angles))\n    signal = stft_fn.inverse(magnitudes, angles).squeeze(1)\n\n    for i in range(n_iters):\n        _, angles = stft_fn.transform(signal)\n        signal = stft_fn.inverse(magnitudes, angles).squeeze(1)\n    return signal\n\n\ndef dynamic_range_compression(x, C=1, clip_val=1e-5):\n    """"""\n    PARAMS\n    ------\n    C: compression factor\n    """"""\n    return torch.log(torch.clamp(x, min=clip_val) * C)\n\n\ndef dynamic_range_decompression(x, C=1):\n    """"""\n    PARAMS\n    ------\n    C: compression factor used to compress\n    """"""\n    return torch.exp(x) / C\n\n\ndef read_wav_np(path):\n    sr, wav = read(path)\n\n    if len(wav.shape) == 2:\n        wav = wav[:, 0]\n\n    if wav.dtype == np.int16:\n        wav = wav / 32768.0\n    elif wav.dtype == np.int32:\n        wav = wav / 2147483648.0\n    elif wav.dtype == np.uint8:\n        wav = (wav - 128) / 128.0\n\n    wav = wav.astype(np.float32)\n\n    return sr, wav\n'"
brevitas_examples/text_to_speech/utilities/stft.py,22,"b'""""""\nBSD 3-Clause License\nSource: https://github.com/seungwonpark/melgan\n\nCopyright (c) 2020 Xilinx, Inc (Giuseppe Franco)\nCopyright (c) 2017, Prem Seetharaman\nAll rights reserved.\n\n* Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice, this\n  list of conditions and the following disclaimer in the\n  documentation and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from this\n  software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom scipy.signal import get_window\nfrom librosa.util import pad_center, tiny\nfrom .audio_processing import window_sumsquare, dynamic_range_compression, dynamic_range_decompression\nfrom librosa.filters import mel as librosa_mel_fn\n\n\nclass STFT(torch.nn.Module):\n    """"""adapted from Prem Seetharaman\'s https://github.com/pseeth/pytorch-stft""""""\n    def __init__(self, filter_length=800, hop_length=200, win_length=800,\n                 window=\'hann\'):\n        super(STFT, self).__init__()\n        self.filter_length = filter_length\n        self.hop_length = hop_length\n        self.win_length = win_length\n        self.window = window\n        self.forward_transform = None\n        scale = self.filter_length / self.hop_length\n        fourier_basis = np.fft.fft(np.eye(self.filter_length))\n\n        cutoff = int((self.filter_length / 2 + 1))\n        fourier_basis = np.vstack([np.real(fourier_basis[:cutoff, :]),\n                                   np.imag(fourier_basis[:cutoff, :])])\n\n        forward_basis = torch.FloatTensor(fourier_basis[:, None, :])\n        inverse_basis = torch.FloatTensor(\n            np.linalg.pinv(scale * fourier_basis).T[:, None, :])\n\n        if window is not None:\n            assert(filter_length >= win_length)\n            # get window and zero center pad it to filter_length\n            fft_window = get_window(window, win_length, fftbins=True)\n            fft_window = pad_center(fft_window, filter_length)\n            fft_window = torch.from_numpy(fft_window).float()\n\n            # window the bases\n            forward_basis *= fft_window\n            inverse_basis *= fft_window\n\n        self.register_buffer(\'forward_basis\', forward_basis.float())\n        self.register_buffer(\'inverse_basis\', inverse_basis.float())\n\n    def transform(self, input_data):\n        num_batches = input_data.size(0)\n        num_samples = input_data.size(1)\n\n        self.num_samples = num_samples\n\n        # similar to librosa, reflect-pad the input\n        input_data = input_data.view(num_batches, 1, num_samples)\n        input_data = F.pad(\n            input_data.unsqueeze(1),\n            (int(self.filter_length / 2), int(self.filter_length / 2), 0, 0),\n            mode=\'reflect\')\n        input_data = input_data.squeeze(1)\n\n        # https://github.com/NVIDIA/tacotron2/issues/125\n        if torch.cuda.is_available():\n            forward_transform = F.conv1d(\n                input_data.cuda(),\n                Variable(self.forward_basis, requires_grad=False).cuda(),\n                stride=self.hop_length,\n                padding=0).cpu()\n        else:\n            forward_transform = F.conv1d(\n                input_data,\n                Variable(self.forward_basis, requires_grad=False),\n                stride=self.hop_length,\n                padding=0).cpu()\n\n        cutoff = int((self.filter_length / 2) + 1)\n        real_part = forward_transform[:, :cutoff, :]\n        imag_part = forward_transform[:, cutoff:, :]\n\n        magnitude = torch.sqrt(real_part**2 + imag_part**2)\n        phase = torch.autograd.Variable(\n            torch.atan2(imag_part.data, real_part.data))\n\n        return magnitude, phase\n\n    def inverse(self, magnitude, phase):\n        recombine_magnitude_phase = torch.cat(\n            [magnitude*torch.cos(phase), magnitude*torch.sin(phase)], dim=1)\n\n        inverse_transform = F.conv_transpose1d(\n            recombine_magnitude_phase,\n            Variable(self.inverse_basis, requires_grad=False),\n            stride=self.hop_length,\n            padding=0)\n\n        if self.window is not None:\n            window_sum = window_sumsquare(\n                self.window, magnitude.size(-1), hop_length=self.hop_length,\n                win_length=self.win_length, n_fft=self.filter_length,\n                dtype=np.float32)\n            # remove modulation effects\n            approx_nonzero_indices = torch.from_numpy(\n                np.where(window_sum > tiny(window_sum))[0])\n            window_sum = torch.autograd.Variable(\n                torch.from_numpy(window_sum), requires_grad=False)\n            window_sum = window_sum.cuda() if magnitude.is_cuda else window_sum\n            inverse_transform[:, :, approx_nonzero_indices] /= window_sum[approx_nonzero_indices]\n\n            # scale by hop ratio\n            inverse_transform *= float(self.filter_length) / self.hop_length\n\n        inverse_transform = inverse_transform[:, :, int(self.filter_length/2):]\n        inverse_transform = inverse_transform[:, :, :-int(self.filter_length/2):]\n\n        return inverse_transform\n\n    def forward(self, input_data):\n        self.magnitude, self.phase = self.transform(input_data)\n        reconstruction = self.inverse(self.magnitude, self.phase)\n        return reconstruction\n\n\nclass TacotronSTFT(torch.nn.Module):\n    def __init__(self, filter_length=1024, hop_length=256, win_length=1024,\n                 n_mel_channels=80, sampling_rate=22050, mel_fmin=0.0,\n                 mel_fmax=None):\n        super(TacotronSTFT, self).__init__()\n        self.n_mel_channels = n_mel_channels\n        self.sampling_rate = sampling_rate\n        self.stft_fn = STFT(filter_length, hop_length, win_length)\n        mel_basis = librosa_mel_fn(\n            sampling_rate, filter_length, n_mel_channels, mel_fmin, mel_fmax)\n        mel_basis = torch.from_numpy(mel_basis).float()\n        self.register_buffer(\'mel_basis\', mel_basis)\n\n    def spectral_normalize(self, magnitudes):\n        output = dynamic_range_compression(magnitudes)\n        return output\n\n    def spectral_de_normalize(self, magnitudes):\n        output = dynamic_range_decompression(magnitudes)\n        return output\n\n    def mel_spectrogram(self, y):\n        """"""Computes mel-spectrograms from a batch of waves\n        PARAMS\n        ------\n        y: Variable(torch.FloatTensor) with shape (B, T) in range [-1, 1]\n\n        RETURNS\n        -------\n        mel_output: torch.FloatTensor of shape (B, n_mel_channels, T)\n        """"""\n        assert(torch.min(y.data) >= -1)\n        assert(torch.max(y.data) <= 1)\n\n        magnitudes, phases = self.stft_fn.transform(y)\n        magnitudes = magnitudes.data\n        mel_output = torch.matmul(self.mel_basis, magnitudes)\n        mel_output = self.spectral_normalize(mel_output)\n        return mel_output\n'"
brevitas_examples/speech_to_text/cfg/topology/__init__.py,0,b''
brevitas_examples/speech_to_text/quartznet/parts/__init__.py,0,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom .manifest import ManifestEN, ManifestBase\nfrom .dataset import AudioDataset\nfrom .features import WaveformFeaturizer\n\n__all__ = [\'ManifestEN\', \'ManifestBase\', \'AudioDataset\', \'WaveformFeaturizer\']\n'"
brevitas_examples/speech_to_text/quartznet/parts/cleaners.py,0,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport inflect\nimport re\n\nfrom unidecode import unidecode\n\nNUM_CHECK = re.compile(r\'([$]?)(^|\\s)(\\S*[0-9]\\S*)(?=(\\s|$)((\\S*)(\\s|$))?)\')\n\nTIME_CHECK = re.compile(r\'([0-9]{1,2}):([0-9]{2})(am|pm)?\')\nCURRENCY_CHECK = re.compile(r\'\\$\')\nORD_CHECK = re.compile(r\'([0-9]+)(st|nd|rd|th)\')\nTHREE_CHECK = re.compile(r\'([0-9]{3})([.,][0-9]{1,2})?([!.?])?$\')\nDECIMAL_CHECK = re.compile(r\'([.,][0-9]{1,2})$\')\n\nABBREVIATIONS_COMMON = [(re.compile(\'\\\\b%s\\\\.\' % x[0]), x[1]) for x in\n                        [\n                            (""ms"", ""miss""),\n                            (""mrs"", ""misess""),\n                            (""mr"", ""mister""),\n                            (""messrs"", ""messeurs""),\n                            (""dr"", ""doctor""),\n                            (""drs"", ""doctors""),\n                            (""st"", ""saint""),\n                            (""co"", ""company""),\n                            (""jr"", ""junior""),\n                            (""sr"", ""senior""),\n                            (""rev"", ""reverend""),\n                            (""hon"", ""honorable""),\n                            (""sgt"", ""sergeant""),\n                            (""capt"", ""captain""),\n                            (""maj"", ""major""),\n                            (""col"", ""colonel""),\n                            (""lt"", ""lieutenant""),\n                            (""gen"", ""general""),\n                            (""prof"", ""professor""),\n                            (""lb"", ""pounds""),\n                            (""rep"", ""representative""),\n                            (""st"", ""street""),\n                            (""ave"", ""avenue""),\n                            (""etc"", ""et cetera""),\n                            (""jan"", ""january""),\n                            (""feb"", ""february""),\n                            (""mar"", ""march""),\n                            (""apr"", ""april""),\n                            (""jun"", ""june""),\n                            (""jul"", ""july""),\n                            (""aug"", ""august""),\n                            (""sep"", ""september""),\n                            (""oct"", ""october""),\n                            (""nov"", ""november""),\n                            (""dec"", ""december""),\n                        ]]\n\nABBREVIATIONS_EXPANDED = [(re.compile(\'\\\\b%s\\\\.\' % x[0]), x[1]) for x in\n                          [\n                            (""ltd"", ""limited""),\n                            (""fig"", ""figure""),\n                            (""figs"", ""figures""),\n                            (""gent"", ""gentlemen""),\n                            (""ft"", ""fort""),\n                            (""esq"", ""esquire""),\n                            (""prep"", ""preperation""),\n                            (""bros"", ""brothers""),\n                            (""ind"", ""independent""),\n                            (""mme"", ""madame""),\n                            (""pro"", ""professional""),\n                            (""vs"", ""versus""),\n                            (""inc"", ""include""),\n                          ]]\n\ninflect = inflect.engine()\n\n\ndef clean_text(string, table, punctuation_to_replace):\n    warn_common_chars(string)\n    string = unidecode(string)\n    string = string.lower()\n    string = re.sub(r\'\\s+\', "" "", string)\n    string = clean_numbers(string)\n    string = clean_abbreviations(string)\n    string = clean_punctuations(string, table, punctuation_to_replace)\n    string = re.sub(r\'\\s+\', "" "", string).strip()\n    return string\n\n\ndef warn_common_chars(string):\n    if re.search(r\'[\xc2\xa3\xe2\x82\xac]\', string):\n        print(""WARNING: Your transcript contains one of \'\xc2\xa3\' or \'\xe2\x82\xac\' which we do""\n              ""not currently handle"")\n\n\ndef clean_numbers(string):\n    cleaner = NumberCleaner()\n    string = NUM_CHECK.sub(cleaner.clean, string)\n    return string\n\n\ndef clean_abbreviations(string, expanded=False):\n    for regex, replacement in ABBREVIATIONS_COMMON:\n        string = re.sub(regex, replacement, string)\n    if expanded:\n        for regex, replacement in ABBREVIATIONS_EXPANDED:\n            string = re.sub(regex, replacement, string)\n    return string\n\n\ndef clean_punctuations(string, table, punctuation_to_replace):\n    for punc, replacement in punctuation_to_replace.items():\n        string = re.sub(\'\\\\{}\'.format(punc),\n                        "" {} "".format(replacement),\n                        string)\n    string = string.translate(table)\n    return string\n\n\nclass NumberCleaner():\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    def reset(self):\n        self.curr_num = []\n        self.currency = None\n\n    def format_final_number(self, whole_num, decimal):\n        if self.currency:\n            return_string = inflect.number_to_words(whole_num)\n            return_string += "" dollar"" if whole_num == 1 else "" dollars""\n            if decimal:\n                return_string += "" and "" + inflect.number_to_words(decimal)\n                return_string += "" cent"" if whole_num == decimal else "" cents""\n            self.reset()\n            return return_string\n\n        self.reset()\n        if decimal:\n            whole_num += ""."" + decimal\n            return inflect.number_to_words(whole_num)\n        else:\n            # Check if there are non-numbers\n            def convert_to_word(match):\n                return "" "" + inflect.number_to_words(match.group(0)) + "" ""\n            return re.sub(r\'[0-9,]+\', convert_to_word, whole_num)\n\n    def clean(self, match):\n        ws = match.group(2)\n        number = match.group(3)\n        _proceeding_symbol = match.group(7)\n\n        time_match = TIME_CHECK.match(number)\n        if time_match:\n            string = ws + inflect.number_to_words(time_match.group(1)) + ""{}{}""\n            mins = int(time_match.group(2))\n            min_string = """"\n            if mins != 0:\n                min_string = "" "" + inflect.number_to_words(time_match.group(2))\n            ampm_string = """"\n            if time_match.group(3):\n                ampm_string = "" "" + time_match.group(3)\n            return string.format(min_string, ampm_string)\n\n        ord_match = ORD_CHECK.match(number)\n        if ORD_CHECK.match(number):\n            return ws + inflect.number_to_words(ord_match.group(0))\n\n        if self.currency is None:\n            # Check if it is a currency\n            self.currency = match.group(1) or CURRENCY_CHECK.match(number)\n\n        # Check to see if next symbol is a number\n        # If it is a number and it has 3 digits, then it is probably a\n        # continuation\n        three_match = THREE_CHECK.match(match.group(6))\n        if three_match:\n            self.curr_num.append(number)\n            return "" ""\n        # Else we can output\n        else:\n            # Check for decimals\n            whole_num = """".join(self.curr_num) + number\n            decimal = None\n            decimal_match = DECIMAL_CHECK.search(whole_num)\n            if decimal_match:\n                decimal = decimal_match.group(1)[1:]\n                whole_num = whole_num[:-len(decimal) - 1]\n            whole_num = re.sub(r\'\\.\', \'\', whole_num)\n            return ws + self.format_final_number(whole_num, decimal)\n'"
brevitas_examples/speech_to_text/quartznet/parts/common.py,0,"b'# BSD 3-Clause License\n#\n# Copyright (c) 2020 Xilinx, Inc (Giuseppe Franco)\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# 1. Redistributions of source code must retain the above copyright notice, this\n#    list of conditions and the following disclaimer.\n#\n# 2. Redistributions in binary form must reproduce the above copyright notice,\n#    this list of conditions and the following disclaimer in the documentation\n#    and/or other materials provided with the distribution.\n#\n# 3. Neither the name of the copyright holder nor the names of its\n#    contributors may be used to endorse or promote products derived from\n#    this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nimport brevitas.nn as quant_nn\nfrom brevitas.core.quant import QuantType\nfrom brevitas.core.scaling import ScalingImplType\nfrom brevitas.core.stats import StatsOp\nglobal ACT_MIN_VAL, ACT_MAX_VAL\nbrevitas_activations = {\n    ""hardtanh"": quant_nn.QuantHardTanh,\n    ""relu"": quant_nn.QuantReLU,\n}\n\nQUANT_TYPE = QuantType.INT\nQUANT_TYPE_BIAS = QuantType.FP\n\nSCALING_MIN_VAL = 2e-16\nACT_SCALING_IMPL_TYPE = ScalingImplType.PARAMETER\nACT_SCALING_PER_CHANNEL = False\n\nWEIGHT_SCALING_IMPL_TYPE = ScalingImplType.STATS\nWEIGHT_SCALING_STATS_OP = StatsOp.MAX\nWEIGHT_NARROW_RANGE = True\nBIAS_CONFIGS = False\n\n\ndef make_quantization_input(bit_width, absolute_act_val, scaling_per_channel):\n    return quant_nn.QuantHardTanh(bit_width=bit_width, scaling_per_channel=scaling_per_channel, quant_type=QUANT_TYPE,\n                                  scaling_impl_type=ACT_SCALING_IMPL_TYPE, scaling_min_val=SCALING_MIN_VAL,\n                                  max_val=absolute_act_val, min_val=-absolute_act_val, return_quant_tensor=False)\n\n\ndef make_norm_scale(bit_width, absolute_act_val, scaling_per_channel):\n    return quant_nn.QuantHardTanh(bit_width=bit_width, scaling_per_channel=scaling_per_channel, quant_type=QUANT_TYPE,\n                                  scaling_impl_type=ACT_SCALING_IMPL_TYPE, scaling_min_val=SCALING_MIN_VAL,\n                                  max_val=absolute_act_val, min_val=-absolute_act_val, scaling_stats_permute_dims=(1, 0, 2),\n                                  return_quant_tensor=True)\n\n\ndef make_jasper_activation(activation, channels, bit_width, absolute_act_val, scaling_per_channel):\n    brevitas_activation = brevitas_activations[activation]\n    return brevitas_activation(bit_width=bit_width, scaling_per_channel=scaling_per_channel, quant_type=QUANT_TYPE,\n                               scaling_impl_type=ACT_SCALING_IMPL_TYPE, scaling_min_val=SCALING_MIN_VAL,\n                               max_val=absolute_act_val, per_channel_broadcastable_shape=(1, channels, 1),\n                               scaling_stats_permute_dims=(1, 0, 2), return_quant_tensor=False)\n\n\ndef make_quantconv1d(feat_in, classes, kernel_size, bit_width, scaling_per_channel, bias,\n                     stride=1, padding=0, dilation=1, groups=1):\n\n    return quant_nn.QuantConv1d(in_channels=feat_in, out_channels=classes, kernel_size=kernel_size,\n                                stride=stride, padding=padding, dilation=dilation, groups=groups,\n                                bias=bias,\n                                weight_bit_width=bit_width,\n                                weight_scaling_stats_op=WEIGHT_SCALING_STATS_OP,\n                                weight_scaling_per_output_channel=scaling_per_channel,\n                                weight_quant_type=QUANT_TYPE,\n                                weight_narrow_range=WEIGHT_NARROW_RANGE,\n                                weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n                                weight_scaling_min_val=SCALING_MIN_VAL,\n                                bias_bit_width=bit_width,\n                                bias_quant_type=QUANT_TYPE_BIAS,\n                                bias_narrow_range=BIAS_CONFIGS,\n                                compute_output_scale=BIAS_CONFIGS,\n                                compute_output_bit_width=BIAS_CONFIGS,\n                                return_quant_tensor=False)\n'"
brevitas_examples/speech_to_text/quartznet/parts/dataset.py,14,"b'# Audio dataset and corresponding functions taken from Patter  https://github.com/ryanleary/patter\n# Adapted from https://github.com/NVIDIA/NeMo/tree/r0.9/collections/nemo_asr\n# MIT License\n# Copyright (c) 2020 Xilinx (Giuseppe Franco)\n# Copyright (c) 2019 NVIDIA Corporation\n# Copyright (c) 2018 Ryan Leary\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport torch\nfrom torch.utils.data import Dataset\n\nfrom .manifest import ManifestBase, ManifestEN\n\n\ndef seq_collate_fn(batch, token_pad_value=0):\n    """"""collate batch of audio sig, audio len, tokens, tokens len\n\n    Args:\n        batch (Optional[FloatTensor], Optional[LongTensor], LongTensor,\n               LongTensor):  A tuple of tuples of signal, signal lengths,\n               encoded tokens, and encoded tokens length.  This collate func\n               assumes the signals are 1d torch tensors (i.e. mono audio).\n\n    """"""\n    _, audio_lengths, _, tokens_lengths = zip(*batch)\n    max_audio_len = 0\n    has_audio = audio_lengths[0] is not None\n    if has_audio:\n        max_audio_len = max(audio_lengths).item()\n    max_tokens_len = max(tokens_lengths).item()\n\n    audio_signal, tokens = [], []\n    for sig, sig_len, tokens_i, tokens_i_len in batch:\n        if has_audio:\n            sig_len = sig_len.item()\n            if sig_len < max_audio_len:\n                pad = (0, max_audio_len - sig_len)\n                sig = torch.nn.functional.pad(sig, pad)\n            audio_signal.append(sig)\n        tokens_i_len = tokens_i_len.item()\n        if tokens_i_len < max_tokens_len:\n            pad = (0, max_tokens_len - tokens_i_len)\n            tokens_i = torch.nn.functional.pad(\n                tokens_i, pad, value=token_pad_value)\n        tokens.append(tokens_i)\n\n    if has_audio:\n        audio_signal = torch.stack(audio_signal)\n        audio_lengths = torch.stack(audio_lengths)\n    else:\n        audio_signal, audio_lengths = None, None\n    tokens = torch.stack(tokens)\n    tokens_lengths = torch.stack(tokens_lengths)\n\n    return audio_signal, audio_lengths, tokens, tokens_lengths\n\n\ndef audio_seq_collate_fn(batch):\n    """"""\n    Collate a batch (iterable of (sample tensor, label tensor) tuples) into\n    properly shaped data tensors\n    :param batch:\n    :return: inputs (batch_size, num_features, seq_length), targets,\n    input_lengths, target_sizes\n    """"""\n    # sort batch by descending sequence length (for packed sequences later)\n    batch.sort(key=lambda x: x[0].size(0), reverse=True)\n\n    # init tensors we need to return\n    inputs = []\n    input_lengths = []\n    target_sizes = []\n    targets = []\n    metadata = []\n\n    # iterate over minibatch to fill in tensors appropriately\n    for i, sample in enumerate(batch):\n        input_lengths.append(sample[0].size(0))\n        inputs.append(sample[0])\n        target_sizes.append(len(sample[1]))\n        targets.extend(sample[1])\n        metadata.append(sample[2])\n    targets = torch.tensor(targets, dtype=torch.long)\n    inputs = torch.stack(inputs)\n    input_lengths = torch.stack(input_lengths)\n    target_sizes = torch.stack(target_sizes)\n\n    return inputs, targets, input_lengths, target_sizes, metadata\n\n\nclass AudioDataset(Dataset):\n    """"""\n    Dataset that loads tensors via a json file containing paths to audio\n    files, transcripts, and durations (in seconds). Each new line is a\n    different sample. Example below:\n\n    {""audio_filepath"": ""/path/to/audio.wav"", ""text_filepath"":\n    ""/path/to/audio.txt"", ""duration"": 23.147}\n    ...\n    {""audio_filepath"": ""/path/to/audio.wav"", ""text"": ""the\n    transcription"", offset"": 301.75, ""duration"": 0.82, ""utt"":\n    ""utterance_id"", ""ctm_utt"": ""en_4156"", ""side"": ""A""}\n\n    Args:\n        manifest_filepath: Path to manifest json as described above. Can\n            be comma-separated paths.\n        labels: String containing all the possible characters to map to\n        featurizer: Initialized featurizer class that converts paths of\n            audio to feature tensors\n        max_duration: If audio exceeds this length, do not include in dataset\n        min_duration: If audio is less than this length, do not include\n            in dataset\n        max_utts: Limit number of utterances\n        blank_index: blank character index, default = -1\n        unk_index: unk_character index, default = -1\n        normalize: whether to normalize transcript text (default): True\n        bos_id: Id of beginning of sequence symbol to append if not None\n        eos_id: Id of end of sequence symbol to append if not None\n        load_audio: Boolean flag indicate whether do or not load audio\n    """"""\n    def __init__(\n            self,\n            manifest_filepath,\n            labels,\n            featurizer,\n            max_duration=None,\n            min_duration=None,\n            max_utts=0,\n            blank_index=-1,\n            unk_index=-1,\n            normalize=True,\n            trim=False,\n            bos_id=None,\n            eos_id=None,\n            logger=False,\n            load_audio=True,\n            manifest_class=ManifestEN):\n        m_paths = manifest_filepath.split(\',\')\n        self.manifest = manifest_class(m_paths, labels,\n                                       max_duration=max_duration,\n                                       min_duration=min_duration,\n                                       max_utts=max_utts,\n                                       blank_index=blank_index,\n                                       unk_index=unk_index,\n                                       normalize=normalize,\n                                       logger=logger)\n        self.featurizer = featurizer\n        self.trim = trim\n        self.eos_id = eos_id\n        self.bos_id = bos_id\n        self.load_audio = load_audio\n        if logger:\n            logger.info(\n                ""Dataset loaded with {0:.2f} hours. Filtered {1:.2f} ""\n                ""hours."".format(\n                    self.manifest.duration / 3600,\n                    self.manifest.filtered_duration / 3600))\n\n    def __getitem__(self, index):\n        sample = self.manifest[index]\n        if self.load_audio:\n            duration = sample[\'duration\'] if \'duration\' in sample else 0\n            offset = sample[\'offset\'] if \'offset\' in sample else 0\n            features = self.featurizer.process(sample[\'audio_filepath\'],\n                                               offset=offset,\n                                               duration=duration,\n                                               trim=self.trim)\n            f, fl = features, torch.tensor(features.shape[0]).long()\n            # f = f / (torch.max(torch.abs(f)) + 1e-5)\n        else:\n            f, fl = None, None\n\n        t, tl = sample[""tokens""], len(sample[""tokens""])\n        if self.bos_id is not None:\n            t = [self.bos_id] + t\n            tl += 1\n        if self.eos_id is not None:\n            t = t + [self.eos_id]\n            tl += 1\n\n        return \\\n            f, fl, \\\n            torch.tensor(t).long(), torch.tensor(tl).long()\n\n    def __len__(self):\n        return len(self.manifest)\n'"
brevitas_examples/speech_to_text/quartznet/parts/features.py,28,"b'# Audio dataset and corresponding functions taken from Patter  https://github.com/ryanleary/patter\n# Adapted from https://github.com/NVIDIA/NeMo/tree/r0.9/collections/nemo_asr\n# MIT License\n# Copyright (c) 2020 Xilinx (Giuseppe Franco)\n# Copyright (c) 2019 NVIDIA Corporation\n# Copyright (c) 2018 Ryan Leary\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport math\nimport librosa\nimport torch\nimport torch.nn as nn\nfrom .perturb import AudioAugmentor\nfrom .segment import AudioSegment\nfrom torch_stft import STFT\n\nCONSTANT = 1e-5\n\n\ndef normalize_batch(x, seq_len, normalize_type):\n    if normalize_type == ""per_feature"":\n        x_mean = torch.zeros((seq_len.shape[0], x.shape[1]), dtype=x.dtype,\n                             device=x.device)\n        x_std = torch.zeros((seq_len.shape[0], x.shape[1]), dtype=x.dtype,\n                            device=x.device)\n        for i in range(x.shape[0]):\n            x_mean[i, :] = x[i, :, :seq_len[i]].mean(dim=1)\n            x_std[i, :] = x[i, :, :seq_len[i]].std(dim=1)\n        # make sure x_std is not zero\n        x_std += CONSTANT\n        return (x - x_mean.unsqueeze(2)) / x_std.unsqueeze(2)\n    elif normalize_type == ""all_features"":\n        x_mean = torch.zeros(seq_len.shape, dtype=x.dtype, device=x.device)\n        x_std = torch.zeros(seq_len.shape, dtype=x.dtype, device=x.device)\n        for i in range(x.shape[0]):\n            x_mean[i] = x[i, :, :seq_len[i].item()].mean()\n            x_std[i] = x[i, :, :seq_len[i].item()].std()\n        # make sure x_std is not zero\n        x_std += CONSTANT\n        return (x - x_mean.view(-1, 1, 1)) / x_std.view(-1, 1, 1)\n    else:\n        return x\n\n\ndef splice_frames(x, frame_splicing):\n    """""" Stacks frames together across feature dim\n\n    input is batch_size, feature_dim, num_frames\n    output is batch_size, feature_dim*frame_splicing, num_frames\n\n    """"""\n    seq = [x]\n    for n in range(1, frame_splicing):\n        seq.append(torch.cat([x[:, :, :n], x[:, :, n:]], dim=2))\n    return torch.cat(seq, dim=1)\n\n\nclass WaveformFeaturizer(object):\n    def __init__(self, sample_rate=16000, int_values=False, augmentor=None):\n        self.augmentor = augmentor if augmentor is not None else \\\n            AudioAugmentor()\n        self.sample_rate = sample_rate\n        self.int_values = int_values\n\n    def max_augmentation_length(self, length):\n        return self.augmentor.max_augmentation_length(length)\n\n    def process(self, file_path, offset=0, duration=0, trim=False):\n        audio = AudioSegment.from_file(\n            file_path,\n            target_sr=self.sample_rate,\n            int_values=self.int_values,\n            offset=offset, duration=duration, trim=trim)\n        return self.process_segment(audio)\n\n    def process_segment(self, audio_segment):\n        self.augmentor.perturb(audio_segment)\n        return torch.tensor(audio_segment.samples, dtype=torch.float)\n\n    @classmethod\n    def from_config(cls, input_config, perturbation_configs=None):\n        if perturbation_configs is not None:\n            aa = AudioAugmentor.from_config(perturbation_configs)\n        else:\n            aa = None\n\n        sample_rate = input_config.get(""sample_rate"", 16000)\n        int_values = input_config.get(""int_values"", False)\n\n        return cls(sample_rate=sample_rate, int_values=int_values,\n                   augmentor=aa)\n\n\nclass FeaturizerFactory(object):\n    def __init__(self):\n        pass\n\n    @classmethod\n    def from_config(cls, input_cfg, perturbation_configs=None):\n        return WaveformFeaturizer.from_config(\n            input_cfg,\n            perturbation_configs=perturbation_configs)\n\n\nclass FilterbankFeatures(nn.Module):\n    """"""Featurizer that converts wavs to Mel Spectrograms.\n    See AudioToMelSpectrogramPreprocessor for args.\n    """"""\n    def __init__(\n            self, *,\n            sample_rate=16000,\n            n_window_size=320,\n            n_window_stride=160,\n            window=""hann"",\n            normalize=""per_feature"",\n            n_fft=None,\n            preemph=0.97,\n            nfilt=64,\n            lowfreq=0,\n            highfreq=None,\n            log=True,\n            log_zero_guard_type=""add"",\n            log_zero_guard_value=2**-24,\n            dither=CONSTANT,\n            pad_to=16,\n            max_duration=16.7,\n            frame_splicing=1,\n            stft_conv=False,\n            pad_value=0,\n            mag_power=2.,\n            logger=None\n    ):\n        super(FilterbankFeatures, self).__init__()\n        if (n_window_size is None or n_window_stride is None\n                or not isinstance(n_window_size, int)\n                or not isinstance(n_window_stride, int)\n                or n_window_size <= 0 or n_window_stride <= 0):\n            raise ValueError(\n                f""{self} got an invalid value for either n_window_size or ""\n                f""n_window_stride. Both must be positive ints."")\n        if logger:\n            logger.info(f""PADDING: {pad_to}"")\n        else:\n            print(f""PADDING: {pad_to}"")\n\n        self.win_length = n_window_size\n        self.hop_length = n_window_stride\n        self.n_fft = n_fft or 2 ** math.ceil(math.log2(self.win_length))\n        self.stft_conv = stft_conv\n\n        if stft_conv:\n            if logger:\n                logger.info(""STFT using conv"")\n            else:\n                print(""STFT using conv"")\n\n            # Create helper class to patch forward func for use with AMP\n            class STFTPatch(STFT):\n                def __init__(self, *params, **kw_params):\n                    super(STFTPatch, self).__init__(*params, **kw_params)\n\n                def forward(self, input_data):\n                    return super(STFTPatch, self).transform(input_data)[0]\n\n            self.stft = STFTPatch(self.n_fft, self.hop_length,\n                                  self.win_length, window)\n\n        else:\n            print(""STFT using torch"")\n            torch_windows = {\n                \'hann\': torch.hann_window,\n                \'hamming\': torch.hamming_window,\n                \'blackman\': torch.blackman_window,\n                \'bartlett\': torch.bartlett_window,\n                \'none\': None,\n            }\n            window_fn = torch_windows.get(window, None)\n            window_tensor = window_fn(self.win_length,\n                                      periodic=False) if window_fn else None\n            self.register_buffer(""window"", window_tensor)\n            self.stft = lambda x: torch.stft(\n                            x, n_fft=self.n_fft,\n                            hop_length=self.hop_length,\n                            win_length=self.win_length,\n                            center=True,\n                            window=self.window.to(dtype=torch.float))\n\n        self.normalize = normalize\n        self.log = log\n        self.dither = dither\n        self.frame_splicing = frame_splicing\n        self.nfilt = nfilt\n        self.preemph = preemph\n        self.pad_to = pad_to\n        highfreq = highfreq or sample_rate / 2\n\n        filterbanks = torch.tensor(\n            librosa.filters.mel(sample_rate, self.n_fft, n_mels=nfilt,\n                                fmin=lowfreq, fmax=highfreq),\n            dtype=torch.float).unsqueeze(0)\n        # self.fb = filterbanks\n        # self.window = window_tensor\n        self.register_buffer(""fb"", filterbanks)\n\n        # Calculate maximum sequence length\n        max_length = self.get_seq_len(\n            torch.tensor(max_duration * sample_rate, dtype=torch.float))\n        max_pad = pad_to - (max_length % pad_to)\n        self.max_length = max_length + max_pad\n        self.pad_value = pad_value\n        self.mag_power = mag_power\n\n        # We want to avoid taking the log of zero\n        # There are two options: either adding or clamping to a small value\n        if log_zero_guard_type not in [""add"", ""clamp""]:\n            raise ValueError(\n                f""{self} received {log_zero_guard_type} for the ""\n                f""log_zero_guard_type parameter. It must be either \'add\' or ""\n                f""\'clamp\'."")\n        # log_zero_guard_value is the the small we want to use, we support\n        # an actual number, or ""tiny"", or ""eps""\n        self.log_zero_guard_value = lambda _: log_zero_guard_value\n        if isinstance(log_zero_guard_value, str):\n            if log_zero_guard_value == ""tiny"":\n                self.log_zero_guard_value = lambda x: torch.finfo(x.dtype).tiny\n            elif log_zero_guard_value == ""eps"":\n                self.log_zero_guard_value = lambda x: torch.finfo(x.dtype).eps\n            else:\n                raise ValueError(\n                    f""{self} received {log_zero_guard_value} for the ""\n                    f""log_zero_guard_type parameter. It must be either a ""\n                    f""number, \'tiny\', or \'eps\'"")\n        self.log_zero_guard_type = log_zero_guard_type\n\n    def get_seq_len(self, seq_len):\n        return torch.ceil(seq_len / self.hop_length).to(dtype=torch.long)\n\n    @property\n    def filter_banks(self):\n        return self.fb\n\n    @torch.no_grad()\n    def forward(self, x, seq_len):\n        seq_len = self.get_seq_len(seq_len.float())\n\n        # dither\n        if self.dither > 0:\n            x += self.dither * torch.randn_like(x)\n\n        # do preemphasis\n        if self.preemph is not None:\n            x = torch.cat(\n                (x[:, 0].unsqueeze(1), x[:, 1:] - self.preemph * x[:, :-1]),\n                dim=1)\n\n        x = self.stft(x)\n\n        # get power spectrum\n        if self.mag_power != 1.:\n            x = x.pow(self.mag_power)\n        if not self.stft_conv:\n            x = x.sum(-1)\n\n        # dot with filterbank energies\n        x = torch.matmul(self.fb.to(x.dtype), x)\n\n        # log features if required\n        if self.log:\n            if self.log_zero_guard_type == ""add"":\n                x = torch.log(x + self.log_zero_guard_value(x))\n            elif self.log_zero_guard_type == ""clamp"":\n                x = torch.log(torch.clamp(x, min=self.log_zero_guard_value(x)))\n            else:\n                raise ValueError(""log_zero_guard_type was not understood"")\n\n        # frame splicing if required\n        if self.frame_splicing > 1:\n            x = splice_frames(x, self.frame_splicing)\n\n        # normalize if required\n        if self.normalize:\n            x = normalize_batch(x, seq_len, normalize_type=self.normalize)\n\n        # mask to zero any values beyond seq_len in batch, pad to multiple of\n        # `pad_to` (for efficiency)\n        max_len = x.size(-1)\n        mask = torch.arange(max_len).to(x.device)\n        mask = mask.expand(x.size(0), max_len) >= seq_len.unsqueeze(1)\n        x = x.masked_fill(\n            mask.unsqueeze(1).type(torch.bool).to(device=x.device),\n            self.pad_value)\n        del mask\n        pad_to = self.pad_to\n        if not self.training:\n            pad_to = 16\n        if pad_to == ""max"":\n            x = nn.functional.pad(x, (0, self.max_length - x.size(-1)),\n                                  value=self.pad_value)\n        elif pad_to > 0:\n            pad_amt = x.size(-1) % pad_to\n            if pad_amt != 0:\n                x = nn.functional.pad(x, (0, pad_to - pad_amt),\n                                      value=self.pad_value)\n        return x\n'"
brevitas_examples/speech_to_text/quartznet/parts/manifest.py,0,"b'# Audio dataset and corresponding functions taken from Patter  https://github.com/ryanleary/patter\n# Adapted from https://github.com/NVIDIA/NeMo/tree/r0.9/collections/nemo_asr\n# MIT License\n# Copyright (c) 2020 Xilinx (Giuseppe Franco)\n# Copyright (c) 2019 NVIDIA Corporation\n# Copyright (c) 2018 Ryan Leary\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport json\nimport string\n\nfrom .cleaners import clean_text\n\n\nclass ManifestBase:\n    def __init__(self,\n                 manifest_paths,\n                 labels,\n                 max_duration=None,\n                 min_duration=None,\n                 sort_by_duration=False,\n                 max_utts=0,\n                 blank_index=-1,\n                 unk_index=-1,\n                 normalize=True,\n                 logger=None):\n        self.min_duration = min_duration\n        self.max_duration = max_duration\n        self.sort_by_duration = sort_by_duration\n        self.max_utts = max_utts\n        self.blank_index = blank_index\n        self.unk_index = unk_index\n        self.normalize = normalize\n        self.labels_map = {label: i for i, label in enumerate(labels)}\n        self.logger = None\n        # if logger is None:\n        #     self.logger = get_logger(\'\')\n\n        data = []\n        duration = 0.0\n        filtered_duration = 0.0\n\n        for item in self.json_item_gen(manifest_paths):\n            if min_duration and item[\'duration\'] < min_duration:\n                filtered_duration += item[\'duration\']\n                continue\n            if max_duration and item[\'duration\'] > max_duration:\n                filtered_duration += item[\'duration\']\n                continue\n\n            # load and normalize transcript text, i.e. `text`\n            text = """"\n            if \'text\' in item:\n                text = item[\'text\']\n            elif \'text_filepath\' in item:\n                text = self.load_transcript(item[\'text_filepath\'])\n            else:\n                filtered_duration += item[\'duration\']\n                continue\n            if normalize:\n                text = self.normalize_text(text, labels, logger=self.logger)\n            if not isinstance(text, str):\n                self.logger.warning(\n                    ""WARNING: Got transcript: {}. It is not a ""\n                    ""string. Dropping data point"".format(text)\n                )\n                filtered_duration += item[\'duration\']\n                continue\n            # item[\'text\'] = text\n\n            # tokenize transcript text\n            item[""tokens""] = self.tokenize_transcript(\n                    text, self.labels_map, self.unk_index, self.blank_index)\n\n            # support files using audio_filename\n            if \'audio_filename\' in item and \'audio_filepath\' not in item:\n                self.logger.warning(\n                    ""Malformed manifest: The key audio_filepath was not ""\n                    ""found in the manifest. Using audio_filename instead.""\n                )\n                item[\'audio_filepath\'] = item[\'audio_filename\']\n\n            data.append(item)\n            duration += item[\'duration\']\n\n            if max_utts > 0 and len(data) >= max_utts:\n                self.logger.info(\n                    \'Stop parsing due to max_utts ({})\'.format(max_utts))\n                break\n\n        if sort_by_duration:\n            data = sorted(data, key=lambda x: x[\'duration\'])\n        self._data = data\n        self._size = len(data)\n        self._duration = duration\n        self._filtered_duration = filtered_duration\n\n    @staticmethod\n    def normalize_text(text, labels):\n        """"""for the base class remove surrounding whitespace only""""""\n        return text.strip()\n\n    @staticmethod\n    def tokenize_transcript(transcript, labels_map, unk_index, blank_index):\n        """"""tokenize transcript to convert words/characters to indices""""""\n        # allow for special labels such as ""<NOISE>""\n        special_labels = set([l for l in labels_map.keys() if len(l) > 1])\n        tokens = []\n        # split by word to find special tokens\n        for i, word in enumerate(transcript.split("" "")):\n            if i > 0:\n                tokens.append(labels_map.get("" "", unk_index))\n            if word in special_labels:\n                tokens.append(labels_map.get(word))\n                continue\n            # split by character to get the rest of the tokens\n            for char in word:\n                tokens.append(labels_map.get(char, unk_index))\n        # if unk_index == blank_index, OOV tokens are removed from transcript\n        tokens = [x for x in tokens if x != blank_index]\n        return tokens\n\n    def __getitem__(self, item):\n        return self._data[item]\n\n    def __len__(self):\n        return self._size\n\n    def __iter__(self):\n        return iter(self._data)\n\n    @staticmethod\n    def json_item_gen(manifest_paths):\n        for manifest_path in manifest_paths:\n            with open(manifest_path, ""r"", encoding=""utf-8"") as fh:\n                for line in fh:\n                    yield json.loads(line)\n\n    @staticmethod\n    def load_transcript(transcript_path):\n        with open(transcript_path, \'r\', encoding=""utf-8"") as transcript_file:\n            transcript = transcript_file.read().replace(\'\\n\', \'\')\n        return transcript\n\n    @property\n    def duration(self):\n        return self._duration\n\n    @property\n    def filtered_duration(self):\n        return self._filtered_duration\n\n    @property\n    def data(self):\n        return list(self._data)\n\n\nclass ManifestEN(ManifestBase):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    @staticmethod\n    def normalize_text(text, labels, logger=None):\n        # Punctuation to remove\n        punctuation = string.punctuation\n        # Define punctuation that will be handled by text cleaner\n        punctuation_to_replace = {\n            ""+"": ""plus"",\n            ""&"": ""and"",\n            ""%"": ""percent""\n        }\n        for char in punctuation_to_replace:\n            punctuation = punctuation.replace(char, """")\n        # We might also want to consider:\n        # @ -> at\n        # -> number, pound, hashtag\n        # ~ -> tilde\n        # _ -> underscore\n\n        # If a punctuation symbol is inside our vocab, we do not remove\n        # from text\n        for l in labels:\n            punctuation = punctuation.replace(l, """")\n\n        # Turn all other punctuation to whitespace\n        table = str.maketrans(punctuation, "" "" * len(punctuation))\n\n        try:\n            text = clean_text(text, table, punctuation_to_replace)\n        except BaseException:\n            if logger:\n                logger.warning(""WARNING: Normalizing {} failed"".format(text))\n            else:\n                print(""WARNING: Normalizing {} failed"".format(text))\n            return None\n\n        return text\n'"
brevitas_examples/speech_to_text/quartznet/parts/perturb.py,0,"b'# Audio dataset and corresponding functions taken from Patter  https://github.com/ryanleary/patter\n# Adapted from https://github.com/NVIDIA/NeMo/tree/r0.9/collections/nemo_asr\n# MIT License\n# Copyright (c) 2020 Xilinx (Giuseppe Franco)\n# Copyright (c) 2019 NVIDIA Corporation\n# Copyright (c) 2018 Ryan Leary\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport random\n\nimport librosa\nfrom scipy import signal\n\nfrom .manifest import ManifestEN\nfrom .segment import AudioSegment\n\n\nclass Perturbation(object):\n    def max_augmentation_length(self, length):\n        return length\n\n    def perturb(self, data):\n        raise NotImplementedError\n\n\nclass SpeedPerturbation(Perturbation):\n    def __init__(self, min_speed_rate=0.85, max_speed_rate=1.15, rng=None):\n        self._min_rate = min_speed_rate\n        self._max_rate = max_speed_rate\n        self._rng = random.Random() if rng is None else rng\n\n    def max_augmentation_length(self, length):\n        return length * self._max_rate\n\n    def perturb(self, data):\n        speed_rate = self._rng.uniform(self._min_rate, self._max_rate)\n        if speed_rate <= 0:\n            raise ValueError(""speed_rate should be greater than zero."")\n        # print(""DEBUG: speed:"", speed_rate)\n        data._samples = librosa.effects.time_stretch(data._samples, speed_rate)\n\n\nclass GainPerturbation(Perturbation):\n    def __init__(self, min_gain_dbfs=-10, max_gain_dbfs=10, rng=None):\n        self._min_gain_dbfs = min_gain_dbfs\n        self._max_gain_dbfs = max_gain_dbfs\n        self._rng = random.Random() if rng is None else rng\n\n    def perturb(self, data):\n        gain = self._rng.uniform(self._min_gain_dbfs, self._max_gain_dbfs)\n        # print(""DEBUG: gain:"", gain)\n        data._samples = data._samples * (10. ** (gain / 20.))\n\n\nclass ImpulsePerturbation(Perturbation):\n    def __init__(self, manifest_path=None, rng=None):\n        self._manifest = ManifestEN(manifest_path)\n        self._rng = random.Random() if rng is None else rng\n\n    def perturb(self, data):\n        impulse_record = self._rng.sample(self._manifest.data, 1)[0]\n        impulse = AudioSegment.from_file(impulse_record[\'audio_filepath\'],\n                                         target_sr=data.sample_rate)\n        # print(""DEBUG: impulse:"", impulse_record[\'audio_filepath\'])\n        data._samples = signal.fftconvolve(\n            data.samples, impulse.samples, ""full"")\n\n\nclass ShiftPerturbation(Perturbation):\n    def __init__(self, min_shift_ms=-5.0, max_shift_ms=5.0, rng=None):\n        self._min_shift_ms = min_shift_ms\n        self._max_shift_ms = max_shift_ms\n        self._rng = random.Random() if rng is None else rng\n\n    def perturb(self, data):\n        shift_ms = self._rng.uniform(self._min_shift_ms, self._max_shift_ms)\n        if abs(shift_ms) / 1000 > data.duration:\n            # TODO: do something smarter than just ignore this condition\n            return\n        shift_samples = int(shift_ms * data.sample_rate // 1000)\n        # print(""DEBUG: shift:"", shift_samples)\n        if shift_samples < 0:\n            data._samples[-shift_samples:] = data._samples[:shift_samples]\n            data._samples[:-shift_samples] = 0\n        elif shift_samples > 0:\n            data._samples[:-shift_samples] = data._samples[shift_samples:]\n            data._samples[-shift_samples:] = 0\n\n\nclass NoisePerturbation(Perturbation):\n    def __init__(self, manifest_path=None, min_snr_db=40, max_snr_db=50,\n                 max_gain_db=300.0, rng=None):\n        self._manifest = ManifestEN(manifest_path)\n        self._rng = random.Random() if rng is None else rng\n        self._min_snr_db = min_snr_db\n        self._max_snr_db = max_snr_db\n        self._max_gain_db = max_gain_db\n\n    def perturb(self, data):\n        snr_db = self._rng.uniform(self._min_snr_db, self._max_snr_db)\n        noise_record = self._rng.sample(self._manifest.data, 1)[0]\n        noise = AudioSegment.from_file(noise_record[\'audio_filepath\'],\n                                       target_sr=data.sample_rate)\n        noise_gain_db = min(data.rms_db - noise.rms_db - snr_db,\n                            self._max_gain_db)\n        # print(""DEBUG: noise:"", snr_db, noise_gain_db, noise_record[\n        # \'audio_filepath\'])\n\n        # calculate noise segment to use\n        start_time = self._rng.uniform(0.0, noise.duration - data.duration)\n        noise.subsegment(start_time=start_time,\n                         end_time=start_time + data.duration)\n\n        # adjust gain for snr purposes and superimpose\n        noise.gain_db(noise_gain_db)\n        data._samples = data._samples + noise.samples\n\n\nperturbation_types = {\n    ""speed"": SpeedPerturbation,\n    ""gain"": GainPerturbation,\n    ""impulse"": ImpulsePerturbation,\n    ""shift"": ShiftPerturbation,\n    ""noise"": NoisePerturbation\n}\n\n\nclass AudioAugmentor(object):\n    def __init__(self, perturbations=None, rng=None):\n        self._rng = random.Random() if rng is None else rng\n        self._pipeline = perturbations if perturbations is not None else []\n\n    def perturb(self, segment):\n        for (prob, p) in self._pipeline:\n            if self._rng.random() < prob:\n                p.perturb(segment)\n        return\n\n    def max_augmentation_length(self, length):\n        newlen = length\n        for (prob, p) in self._pipeline:\n            newlen = p.max_augmentation_length(newlen)\n        return newlen\n\n    @classmethod\n    def from_config(cls, config):\n        ptbs = []\n        for p in config:\n            if p[\'aug_type\'] not in perturbation_types:\n                print(p[\'aug_type\'], ""perturbation not known. Skipping."")\n                continue\n            perturbation = perturbation_types[p[\'aug_type\']]\n            ptbs.append((p[\'prob\'], perturbation(**p[\'cfg\'])))\n        return cls(perturbations=ptbs)\n'"
brevitas_examples/speech_to_text/quartznet/parts/quartznet.py,6,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/nemo_asr/parts/jasper.py\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import Tuple, Optional, List\n\nimport torch\nimport torch.nn as nn\nfrom torch import Tensor\nfrom .common import *\nfrom brevitas.quant_tensor import QuantTensor\nfrom brevitas.nn.quant_bn import mul_add_from_bn\n\njasper_activations = {\n    ""hardtanh"": nn.Hardtanh,\n    ""relu"": nn.ReLU,\n    ""selu"": nn.SELU,\n}\n\n\ndef init_weights(m, mode=\'xavier_uniform\'):\n    if isinstance(m, MaskedConv1d):\n        init_weights(m.conv, mode)\n    if isinstance(m, nn.Conv1d):\n        if mode == \'xavier_uniform\':\n            nn.init.xavier_uniform_(m.weight, gain=1.0)\n        elif mode == \'xavier_normal\':\n            nn.init.xavier_normal_(m.weight, gain=1.0)\n        elif mode == \'kaiming_uniform\':\n            nn.init.kaiming_uniform_(m.weight, nonlinearity=""relu"")\n        elif mode == \'kaiming_normal\':\n            nn.init.kaiming_normal_(m.weight, nonlinearity=""relu"")\n        else:\n            raise ValueError(""Unknown Initialization mode: {0}"".format(mode))\n    elif isinstance(m, nn.BatchNorm1d):\n        if m.track_running_stats:\n            m.running_mean.zero_()\n            m.running_var.fill_(1)\n            m.num_batches_tracked.zero_()\n        if m.affine:\n            nn.init.ones_(m.weight)\n            nn.init.zeros_(m.bias)\n\n\ndef get_same_padding(kernel_size, stride, dilation):\n    if stride > 1 and dilation > 1:\n        raise ValueError(""Only stride OR dilation may be greater than 1"")\n    if dilation > 1:\n        return (dilation * kernel_size) // 2 - 1\n    return kernel_size // 2\n\n\nclass MaskedConv1d(nn.Module):\n    __constants__ = [""use_conv_mask"", ""real_out_channels"", ""heads""]\n\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_per_channel, bit_width,\n                 stride=1, padding=0, dilation=1, groups=1, heads=-1, bias=False, use_mask=True):\n        super(MaskedConv1d, self).__init__()\n\n        if not (heads == -1 or groups == in_channels):\n            raise ValueError(""Only use heads for depthwise convolutions"")\n\n        self.real_out_channels = out_channels\n        if heads != -1:\n            in_channels = heads\n            out_channels = heads\n            groups = heads\n        self.conv = make_quantconv1d(in_channels, out_channels, kernel_size, bias=bias,\n                                     stride=stride, padding=padding, dilation=dilation,\n                                     groups=groups, scaling_per_channel=scaling_per_channel, bit_width=bit_width)\n        self.is_depthwise = (in_channels == out_channels) and (in_channels == groups)\n        self.use_mask = use_mask\n        self.heads = heads\n\n    def get_seq_len(self, lens):\n        return ((lens + 2 * self.conv.padding[0] - self.conv.dilation[0] * (\n                self.conv.kernel_size[0] - 1) - 1) / self.conv.stride[0] + 1)\n\n    def forward(self, x, lens):\n        if self.use_mask:\n            lens = lens.to(dtype=torch.long)\n            max_len = x.size(2)\n            mask = torch.arange(max_len).to(lens.device) \\\n                       .expand(len(lens), max_len) >= lens.unsqueeze(1)\n            x = x.masked_fill(\n                mask.unsqueeze(1).to(device=x.device), 0\n            )\n            # del mask\n            lens = self.get_seq_len(lens)\n\n        sh = x.shape\n        if self.heads != -1:\n            x = x.view(-1, self.heads, sh[-1])\n\n        out = self.conv(x)\n\n        if self.heads != -1:\n            out = out.view(sh[0], self.real_out_channels, -1)\n\n        return out, lens\n\n\nclass GroupShuffle(nn.Module):\n\n    def __init__(self, groups, channels):\n        super(GroupShuffle, self).__init__()\n\n        self.groups = groups\n        self.channels_per_group = channels // groups\n\n    def forward(self, x):\n        sh = x.shape\n\n        x = x.view(-1, self.groups, self.channels_per_group, sh[-1])\n\n        x = torch.transpose(x, 1, 2).contiguous()\n\n        x = x.view(-1, self.groups * self.channels_per_group, sh[-1])\n\n        return x\n\n\nclass JasperBlock(nn.Module):\n    __constants__ = [""conv_mask"", ""separable"", ""residual_mode"", ""res"", ""mconv""]\n\n    def __init__(self, inplanes, planes, bit_width,\n                 absolute_act_val,\n                 activation_inner_scaling_per_output_channel, activation_other_scaling_per_output_channel,\n                 weight_scaling_per_output_channel,\n                 repeat=3, kernel_size=11, stride=1,\n                 dilation=1, padding=\'same\', dropout=0.2, activation=None,\n                 residual=True, groups=1, separable=False,\n                 heads=-1, normalization=""batch"",\n                 norm_groups=1, residual_mode=\'add\',\n                 residual_panes=[], conv_mask=False, fused_bn=False):\n        super(JasperBlock, self).__init__()\n\n        if padding != ""same"":\n            raise ValueError(""currently only \'same\' padding is supported"")\n        self.fused_bn = fused_bn\n        padding_val = get_same_padding(kernel_size[0], stride[0], dilation[0])\n        self.conv_mask = conv_mask\n        self.separable = separable\n        self.residual_mode = residual_mode\n        self.quant_normalization = make_norm_scale(\n            bit_width=bit_width, absolute_act_val=absolute_act_val,\n            scaling_per_channel=activation_other_scaling_per_output_channel)\n        self.conv_module_to_merge = []\n        inplanes_loop = inplanes\n        conv = nn.ModuleList()\n        self.norm_depthwise = nn.ModuleList()\n        for _ in range(repeat - 1):\n            if separable:\n                self.norm_depthwise.extend(\n                    [make_norm_scale(bit_width=bit_width,\n                                     absolute_act_val=absolute_act_val,\n                                     scaling_per_channel=activation_other_scaling_per_output_channel)]\n                )\n            conv.extend(self._get_conv_bn_layer(\n                inplanes_loop,\n                planes,\n                kernel_size=kernel_size,\n                stride=stride,\n                dilation=dilation,\n                padding=padding_val,\n                groups=groups,\n                heads=heads,\n                separable=separable,\n                normalization=normalization,\n                norm_groups=norm_groups,\n                bit_width=bit_width,\n                scaling_per_channel=weight_scaling_per_output_channel))\n\n            conv.extend(self._get_act_dropout_layer(\n                drop_prob=dropout,\n                activation=activation,\n                channels=planes,\n                bit_width=bit_width,\n                absolute_act_val=absolute_act_val,\n                scaling_per_channel=activation_inner_scaling_per_output_channel))\n\n            inplanes_loop = planes\n\n        if separable:\n            self.norm_depthwise.extend(\n                [make_norm_scale(bit_width=bit_width,\n                                 absolute_act_val=absolute_act_val,\n                                 scaling_per_channel=activation_other_scaling_per_output_channel)]\n            )\n        conv.extend(self._get_conv_bn_layer(\n            inplanes_loop,\n            planes,\n            kernel_size=kernel_size,\n            stride=stride,\n            dilation=dilation,\n            padding=padding_val,\n            groups=groups,\n            heads=heads,\n            separable=separable,\n            normalization=normalization,\n            norm_groups=norm_groups,\n            bit_width=bit_width,\n            scaling_per_channel=weight_scaling_per_output_channel))\n\n        self.mconv = conv\n\n        res_panes = residual_panes.copy()\n        self.dense_residual = residual\n\n        if residual:\n            res_list = nn.ModuleList()\n            if len(residual_panes) == 0:\n                res_panes = [inplanes]\n                self.dense_residual = False\n            for ip in res_panes:\n                res_list.append(nn.ModuleList(self._get_conv_bn_layer(\n                    ip,\n                    planes,\n                    kernel_size=1,\n                    normalization=normalization,\n                    norm_groups=norm_groups,\n                    bit_width=bit_width,\n                    scaling_per_channel=weight_scaling_per_output_channel)))\n            self.res = res_list\n        else:\n            self.res = None\n\n        self.mout = nn.Sequential(\n            *self._get_act_dropout_layer(\n                drop_prob=dropout,\n                activation=activation,\n                channels=inplanes_loop,\n                absolute_act_val=absolute_act_val,\n                scaling_per_channel=activation_other_scaling_per_output_channel,\n                bit_width=bit_width)\n        )\n\n    def _get_conv(self, in_channels, out_channels, bit_width, scaling_per_channel, kernel_size=11,\n                  stride=1, dilation=1, padding=0, bias=False,\n                  groups=1, heads=-1, separable=False):\n        use_mask = self.conv_mask\n        if use_mask:\n            return MaskedConv1d(in_channels, out_channels, kernel_size,\n                                stride=stride,\n                                dilation=dilation, padding=padding, bias=bias,\n                                groups=groups, heads=heads,\n                                use_mask=use_mask, scaling_per_channel=scaling_per_channel, bit_width=bit_width)\n        else:\n            return make_quantconv1d(in_channels, out_channels, kernel_size, stride=stride,\n                                    dilation=dilation, padding=padding, groups=groups, bias=bias,\n                                    scaling_per_channel=scaling_per_channel, bit_width=bit_width)\n\n    def _get_conv_bn_layer(self, in_channels, out_channels, bit_width, scaling_per_channel, kernel_size=11,\n                           stride=1, dilation=1, padding=0, bias=False,\n                           groups=1, heads=-1, separable=False,\n                           normalization=""batch"", norm_groups=1):\n        if norm_groups == -1:\n            norm_groups = out_channels\n\n        if separable:\n            layers = [\n                self._get_conv(in_channels,\n                               in_channels,\n                               kernel_size=kernel_size,\n                               stride=stride,\n                               dilation=dilation, padding=padding,\n                               groups=in_channels, heads=heads, bias=bias,\n                               scaling_per_channel=scaling_per_channel, bit_width=bit_width),\n                self._get_conv(in_channels, out_channels, kernel_size=1,\n                               stride=1,\n                               dilation=1, padding=0, groups=groups, bias=bias,\n                               scaling_per_channel=scaling_per_channel, bit_width=bit_width)\n            ]\n        else:\n            layers = [\n                self._get_conv(in_channels, out_channels, kernel_size=kernel_size,\n                               scaling_per_channel=scaling_per_channel, bit_width=bit_width,\n                               stride=stride, bias=bias,\n                               dilation=dilation, padding=padding,\n                               groups=groups)\n            ]\n\n        if normalization == ""group"":\n            layers.append(nn.GroupNorm(\n                num_groups=norm_groups, num_channels=out_channels))\n        elif normalization == ""instance"":\n            layers.append(nn.GroupNorm(\n                num_groups=out_channels, num_channels=out_channels))\n        elif normalization == ""layer"":\n            layers.append(nn.GroupNorm(\n                num_groups=1, num_channels=out_channels))\n        elif normalization == ""batch"":\n            if self.fused_bn:\n                self.conv_module_to_merge.append(layers[-1])\n                layers.append(nn.Identity())\n            else:\n                layers.append(nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.1))\n        else:\n            raise ValueError(\n                f""Normalization method ({normalization}) does not match""\n                f"" one of [batch, layer, group, instance]."")\n\n        if groups > 1:\n            layers.append(GroupShuffle(groups, out_channels))\n        return layers\n\n    def _get_act_dropout_layer(self, channels, bit_width, absolute_act_val, scaling_per_channel, drop_prob=0.2, activation=None):\n        if activation is None:\n            raise Exception(""Activation required"")\n        layers = [\n            make_jasper_activation(activation, channels, bit_width=bit_width, absolute_act_val=absolute_act_val,\n                                   scaling_per_channel=scaling_per_channel),\n            nn.Dropout(p=drop_prob)\n        ]\n        return layers\n\n    def forward(self, input_: Tuple[List[Tensor], Optional[Tensor]]):\n        # type: (Tuple[List[Tensor], Optional[Tensor]]) -> Tuple[List[Tensor], Optional[Tensor]] # nopep8\n        lens_orig = None\n        xs = input_[0]\n        if len(input_) == 2:\n            xs, lens_orig = input_\n\n        # compute forward convolutions\n        out = xs[-1]\n        count_norm = 0\n        lens = lens_orig\n        check_flag = False\n        for i, l in enumerate(self.mconv):\n            if isinstance(l, MaskedConv1d):\n                out, lens = l(out, lens)\n                check_flag = check_flag or l.is_depthwise\n                if l.is_depthwise:\n                    out, scale, bit = self.norm_depthwise[count_norm](out)\n                    count_norm += 1\n            else:\n                out = l(out)\n        if check_flag:\n            assert (len(self.norm_depthwise) == count_norm)\n\n        # compute the residuals\n        if self.res is not None:\n            out = self.quant_normalization(out)\n            if self.training:\n                out, scale, bit = out\n            for i, layer in enumerate(self.res):\n                res_out = xs[i]\n                for j, res_layer in enumerate(layer):\n                    if isinstance(res_layer, MaskedConv1d):\n                        res_out, _ = res_layer(res_out, lens_orig)\n                    else:\n                        res_out = res_layer(res_out)\n                res_out = self.quant_normalization(res_out)\n                if self.training:\n                    res_out, scale, bit = res_out\n                if self.residual_mode == \'add\':\n                    out = out + res_out\n                else:\n                    out = torch.max(out, res_out)\n\n        if isinstance(out, QuantTensor):\n            out, scale, bit = out\n\n        # compute the output\n        out = self.mout(out)\n        if self.res is not None and self.dense_residual:\n            return xs + [out], lens\n\n        return [out], lens\n\n    def _load_from_state_dict(\n            self,\n            state_dict,\n            prefix,\n            local_metadata,\n            strict,\n            missing_keys,\n            unexpected_keys,\n            error_msgs):\n        if self.fused_bn:\n            self.fuse_bn(state_dict, prefix)\n        super(JasperBlock, self)._load_from_state_dict(\n            state_dict,\n            prefix,\n            local_metadata,\n            strict,\n            missing_keys,\n            unexpected_keys,\n            error_msgs)\n\n    def fuse_bn(self, state_dict,\n            prefix):\n        index = 0\n        flag = False\n        keys_to_check = []\n        keys_to_delete = []\n        for k in state_dict.keys():\n            if k.startswith(prefix):\n                keys_to_check.append(k)\n                if k.split(\'.\')[-1] == \'running_mean\':\n                    flag = True\n\n\n        if flag:\n            for name in keys_to_check:\n                prefix_long = name.split(\'.\')[:-1]\n\n                if name.split(\'.\')[-1] == ""running_mean"":\n                    # print(""Found"")\n                    bn_prefix = \'.\'.join(prefix_long)\n                    module_number = int(prefix_long[-1])\n                    # print(bn_prefix)\n                    conv_name = prefix_long[:-1] + [str(module_number-1)] + [\'conv\']\n                    conv_name = \'.\'.join(conv_name)\n                    # print(conv_name)\n                    conv_mod = self.conv_module_to_merge[index]\n                    index = index + 1\n                    bn_weight_key = \'.\'.join([bn_prefix, \'weight\'])\n                    bn_bias_key = \'.\'.join([bn_prefix, \'bias\'])\n                    bn_running_mean_key = \'.\'.join([bn_prefix, \'running_mean\'])\n                    bn_running_var_key = \'.\'.join([bn_prefix, \'running_var\'])\n                    bn_num_batches_traked_key = \'.\'.join([bn_prefix, \'num_batches_tracked\'])\n                    keys_to_delete = keys_to_delete + [bn_bias_key]\n                    keys_to_delete = keys_to_delete + [bn_weight_key]\n                    keys_to_delete = keys_to_delete + [bn_running_mean_key]\n                    keys_to_delete = keys_to_delete + [bn_running_var_key]\n                    keys_to_delete = keys_to_delete + [bn_num_batches_traked_key]\n                    mul_factor, add_factor = mul_add_from_bn(\n                        bn_mean=state_dict[bn_running_mean_key],\n                        bn_var=state_dict[bn_running_var_key],\n                        bn_eps=1e-03,\n                        bn_weight=state_dict[bn_weight_key],\n                        bn_bias=state_dict[bn_bias_key],\n                        affine_only=False)\n                    if isinstance(conv_mod, MaskedConv1d):\n                        conv_mod = conv_mod.conv\n                    mul_shape = conv_mod.per_output_channel_broadcastable_shape\n                    conv_weight_key = conv_name + \'.weight\'\n                    conv_bias_key = conv_name + \'.bias\'\n                    result = state_dict[conv_weight_key] * mul_factor.view(mul_shape)\n\n                    state_dict[conv_weight_key] = result\n\n                    if conv_mod.bias is not None and conv_bias_key in state_dict:\n                        state_dict[conv_bias_key] += add_factor\n                    elif conv_mod.bias is not None and not conv_bias_key in state_dict:\n                        state_dict[conv_bias_key] = add_factor\n                    else:\n                        if torch.cuda.is_available():\n                            add_factor = add_factor.cuda()\n                        conv_mod.bias = nn.Parameter(add_factor)\n                        # add it to the dict any to avoid missing key error\n                        state_dict[conv_bias_key] = add_factor\n\n                    # Get rid of statistics after using them\n                else:\n                    state_dict[name] = state_dict[name]\n        for k in list(state_dict.keys()):\n            if k in keys_to_delete:\n                del state_dict[k]\n        assert len(self.conv_module_to_merge) == index\n\n\n'"
brevitas_examples/speech_to_text/quartznet/parts/segment.py,0,"b'# Audio dataset and corresponding functions taken from Patter  https://github.com/ryanleary/patter\n# Adapted from https://github.com/NVIDIA/NeMo/tree/r0.9/collections/nemo_asr\n# MIT License\n# Copyright (c) 2020 Xilinx (Giuseppe Franco)\n# Copyright (c) 2019 NVIDIA Corporation\n# Copyright (c) 2018 Ryan Leary\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport random\n\nimport librosa\nimport numpy as np\nimport soundfile as sf\n\n\nclass AudioSegment(object):\n    """"""Monaural audio segment abstraction.\n    :param samples: Audio samples [num_samples x num_channels].\n    :type samples: ndarray.float32\n    :param sample_rate: Audio sample rate.\n    :type sample_rate: int\n    :raises TypeError: If the sample data type is not float or int.\n    """"""\n\n    def __init__(self, samples, sample_rate, target_sr=None, trim=False,\n                 trim_db=60):\n        """"""Create audio segment from samples.\n        Samples are convert float32 internally, with int scaled to [-1, 1].\n        """"""\n        samples = self._convert_samples_to_float32(samples)\n        if target_sr is not None and target_sr != sample_rate:\n            samples = librosa.core.resample(samples, sample_rate, target_sr)\n            sample_rate = target_sr\n        if trim:\n            samples, _ = librosa.effects.trim(samples, trim_db)\n        self._samples = samples\n        self._sample_rate = sample_rate\n        if self._samples.ndim >= 2:\n            self._samples = np.mean(self._samples, 1)\n\n    def __eq__(self, other):\n        """"""Return whether two objects are equal.""""""\n        if type(other) is not type(self):\n            return False\n        if self._sample_rate != other._sample_rate:\n            return False\n        if self._samples.shape != other._samples.shape:\n            return False\n        if np.any(self.samples != other._samples):\n            return False\n        return True\n\n    def __ne__(self, other):\n        """"""Return whether two objects are unequal.""""""\n        return not self.__eq__(other)\n\n    def __str__(self):\n        """"""Return human-readable representation of segment.""""""\n        return (""%s: num_samples=%d, sample_rate=%d, duration=%.2fsec, ""\n                ""rms=%.2fdB"" % (type(self), self.num_samples, self.sample_rate,\n                                self.duration, self.rms_db))\n\n    @staticmethod\n    def _convert_samples_to_float32(samples):\n        """"""Convert sample type to float32.\n        Audio sample type is usually integer or float-point.\n        Integers will be scaled to [-1, 1] in float32.\n        """"""\n        float32_samples = samples.astype(\'float32\')\n        if samples.dtype in np.sctypes[\'int\']:\n            bits = np.iinfo(samples.dtype).bits\n            float32_samples *= (1. / 2 ** (bits - 1))\n        elif samples.dtype in np.sctypes[\'float\']:\n            pass\n        else:\n            raise TypeError(""Unsupported sample type: %s."" % samples.dtype)\n        return float32_samples\n\n    @classmethod\n    def from_file(cls, filename, target_sr=None, int_values=False, offset=0,\n                  duration=0, trim=False):\n        """"""\n        Load a file supported by librosa and return as an AudioSegment.\n        :param filename: path of file to load\n        :param target_sr: the desired sample rate\n        :param int_values: if true, load samples as 32-bit integers\n        :param offset: offset in seconds when loading audio\n        :param duration: duration in seconds when loading audio\n        :return: numpy array of samples\n        """"""\n        with sf.SoundFile(filename, \'r\') as f:\n            dtype = \'int32\' if int_values else \'float32\'\n            sample_rate = f.samplerate\n            if offset > 0:\n                f.seek(int(offset * sample_rate))\n            if duration > 0:\n                samples = f.read(int(duration * sample_rate), dtype=dtype)\n            else:\n                samples = f.read(dtype=dtype)\n\n        samples = samples.transpose()\n        return cls(samples, sample_rate, target_sr=target_sr, trim=trim)\n\n    @classmethod\n    def segment_from_file(cls,\n                          filename,\n                          target_sr=None,\n                          n_segments=0,\n                          trim=False):\n        """"""Grabs n_segments number of samples from filename randomly from the\n        file as opposed to at a specified offset.\n        """"""\n        with sf.SoundFile(filename, \'r\') as f:\n            sample_rate = f.samplerate\n            if n_segments > 0 and len(f) > n_segments:\n                max_audio_start = len(f) - n_segments\n                audio_start = random.randint(0, max_audio_start)\n                f.seek(audio_start)\n                samples = f.read(n_segments, dtype=\'float32\')\n            else:\n                samples = f.read(dtype=\'float32\')\n\n        samples = samples.transpose()\n        return cls(samples, sample_rate, target_sr=target_sr, trim=trim)\n\n    @property\n    def samples(self):\n        return self._samples.copy()\n\n    @property\n    def sample_rate(self):\n        return self._sample_rate\n\n    @property\n    def num_samples(self):\n        return self._samples.shape[0]\n\n    @property\n    def duration(self):\n        return self._samples.shape[0] / float(self._sample_rate)\n\n    @property\n    def rms_db(self):\n        mean_square = np.mean(self._samples ** 2)\n        return 10 * np.log10(mean_square)\n\n    def gain_db(self, gain):\n        self._samples *= 10. ** (gain / 20.)\n\n    def pad(self, pad_size, symmetric=False):\n        """"""Add zero padding to the sample. The pad size is given in number\n        of samples.\n        If symmetric=True, `pad_size` will be added to both sides. If false,\n        `pad_size`\n        zeros will be added only to the end.\n        """"""\n        self._samples = np.pad(self._samples,\n                               (pad_size if symmetric else 0, pad_size),\n                               mode=\'constant\')\n\n    def subsegment(self, start_time=None, end_time=None):\n        """"""Cut the AudioSegment between given boundaries.\n        Note that this is an in-place transformation.\n        :param start_time: Beginning of subsegment in seconds.\n        :type start_time: float\n        :param end_time: End of subsegment in seconds.\n        :type end_time: float\n        :raise ValueError: If start_time or end_time is incorrectly set,\n        e.g. out\n                           of bounds in time.\n        """"""\n        start_time = 0.0 if start_time is None else start_time\n        end_time = self.duration if end_time is None else end_time\n        if start_time < 0.0:\n            start_time = self.duration + start_time\n        if end_time < 0.0:\n            end_time = self.duration + end_time\n        if start_time < 0.0:\n            raise ValueError(""The slice start position (%f s) is out of ""\n                             ""bounds."" % start_time)\n        if end_time < 0.0:\n            raise ValueError(\n                ""The slice end position (%f s) is out of bounds."" %\n                end_time)\n        if start_time > end_time:\n            raise ValueError(""The slice start position (%f s) is later than ""\n                             ""the end position (%f s)."" % (\n                                 start_time, end_time))\n        if end_time > self.duration:\n            raise ValueError(""The slice end position (%f s) is out of bounds ""\n                             ""(> %f s)"" % (end_time, self.duration))\n        start_sample = int(round(start_time * self._sample_rate))\n        end_sample = int(round(end_time * self._sample_rate))\n        self._samples = self._samples[start_sample:end_sample]\n'"
brevitas_examples/speech_to_text/quartznet/parts/spectr_augment.py,7,"b'# Adapted from https://github.com/NVIDIA/NeMo/blob/r0.9/collections/nemo_asr/\n# Copyright (C) 2020 Xilinx (Giuseppe Franco)\n# Copyright (C) 2019 NVIDIA CORPORATION.\n#\n# All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport random\n\nimport torch\nimport torch.nn as nn\n\n\nclass SpecAugment(nn.Module):\n    """"""\n    Zeroes out(cuts) random continuous horisontal or\n    vertical segments of the spectrogram as described in\n    SpecAugment (https://arxiv.org/abs/1904.08779).\n\n    params:\n    freq_masks - how many frequency segments should be cut\n    time_masks - how many time segments should be cut\n    freq_width - maximum number of frequencies to be cut in one segment\n    time_width - maximum number of time steps to be cut in one segment\n    """"""\n    def __init__(\n        self,\n        freq_masks=0,\n        time_masks=0,\n        freq_width=10,\n        time_width=10,\n        rng=None\n    ):\n        super(SpecAugment, self).__init__()\n\n        self._rng = random.Random() if rng is None else rng\n\n        self.freq_masks = freq_masks\n        self.time_masks = time_masks\n\n        self.freq_width = freq_width\n        self.time_width = time_width\n\n    @torch.no_grad()\n    def forward(self, x):\n        sh = x.shape\n\n        mask = torch.zeros(x.shape).byte()\n\n        for idx in range(sh[0]):\n            for i in range(self.freq_masks):\n                x_left = int(self._rng.uniform(\n                    0, sh[1] - self.freq_width))\n\n                w = int(self._rng.uniform(0, self.freq_width))\n\n                mask[idx, x_left:x_left + w, :] = 1\n\n            for i in range(self.time_masks):\n                y_left = int(self._rng.uniform(\n                    0, sh[2] - self.time_width))\n\n                w = int(self._rng.uniform(0, self.time_width))\n\n                mask[idx, :,\n                     y_left:y_left + w] = 1\n\n        x = x.masked_fill(mask.type(torch.bool).to(device=x.device), 0)\n\n        return x\n\n\nclass SpecCutout(nn.Module):\n    """"""\n    Zeroes out(cuts) random rectangles in the spectrogram\n    as described in (https://arxiv.org/abs/1708.04552).\n\n    params:\n    rect_masks - how many rectangular masks should be cut\n    rect_freq - maximum size of cut rectangles along the frequency dimension\n    rect_time - maximum size of cut rectangles along the time dimension\n    """"""\n    def __init__(\n        self,\n        rect_masks=0,\n        rect_time=5,\n        rect_freq=20,\n        rng=None\n    ):\n        super(SpecCutout, self).__init__()\n\n        self._rng = random.Random() if rng is None else rng\n\n        self.rect_masks = rect_masks\n        self.rect_time = rect_time\n        self.rect_freq = rect_freq\n\n    @torch.no_grad()\n    def forward(self, x):\n        sh = x.shape\n\n        mask = torch.zeros(x.shape).byte()\n\n        for idx in range(sh[0]):\n            for i in range(self.rect_masks):\n                rect_x = int(self._rng.uniform(\n                    0, sh[1] - self.rect_freq))\n                rect_y = int(self._rng.uniform(\n                    0, sh[2] - self.rect_time))\n\n                w_x = int(self._rng.uniform(0, self.rect_time))\n                w_y = int(self._rng.uniform(0, self.rect_freq))\n\n                mask[idx, rect_x:rect_x + w_x,\n                     rect_y:rect_y + w_y] = 1\n\n        x = x.masked_fill(mask.type(torch.bool).to(device=x.device), 0)\n\n        return x\n'"
