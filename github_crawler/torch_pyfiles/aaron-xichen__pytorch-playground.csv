file_path,api_count,code
quantize.py,4,"b'import argparse\nfrom utee import misc, quant, selector\nimport torch\nimport torch.backends.cudnn as cudnn\ncudnn.benchmark =True\nfrom collections import OrderedDict\n\ndef main():\n    parser = argparse.ArgumentParser(description=\'PyTorch SVHN Example\')\n    parser.add_argument(\'--type\', default=\'cifar10\', help=\'|\'.join(selector.known_models))\n    parser.add_argument(\'--quant_method\', default=\'linear\', help=\'linear|minmax|log|tanh\')\n    parser.add_argument(\'--batch_size\', type=int, default=100, help=\'input batch size for training (default: 64)\')\n    parser.add_argument(\'--gpu\', default=None, help=\'index of gpus to use\')\n    parser.add_argument(\'--ngpu\', type=int, default=8, help=\'number of gpus to use\')\n    parser.add_argument(\'--seed\', type=int, default=117, help=\'random seed (default: 1)\')\n    parser.add_argument(\'--model_root\', default=\'~/.torch/models/\', help=\'folder to save the model\')\n    parser.add_argument(\'--data_root\', default=\'/data/public_dataset/pytorch/\', help=\'folder to save the model\')\n    parser.add_argument(\'--logdir\', default=\'log/default\', help=\'folder to save to the log\')\n\n    parser.add_argument(\'--input_size\', type=int, default=224, help=\'input size of image\')\n    parser.add_argument(\'--n_sample\', type=int, default=20, help=\'number of samples to infer the scaling factor\')\n    parser.add_argument(\'--param_bits\', type=int, default=8, help=\'bit-width for parameters\')\n    parser.add_argument(\'--bn_bits\', type=int, default=32, help=\'bit-width for running mean and std\')\n    parser.add_argument(\'--fwd_bits\', type=int, default=8, help=\'bit-width for layer output\')\n    parser.add_argument(\'--overflow_rate\', type=float, default=0.0, help=\'overflow rate\')\n    args = parser.parse_args()\n\n    args.gpu = misc.auto_select_gpu(utility_bound=0, num_gpu=args.ngpu, selected_gpus=args.gpu)\n    args.ngpu = len(args.gpu)\n    misc.ensure_dir(args.logdir)\n    args.model_root = misc.expand_user(args.model_root)\n    args.data_root = misc.expand_user(args.data_root)\n    args.input_size = 299 if \'inception\' in args.type else args.input_size\n    assert args.quant_method in [\'linear\', \'minmax\', \'log\', \'tanh\']\n    print(""=================FLAGS=================="")\n    for k, v in args.__dict__.items():\n        print(\'{}: {}\'.format(k, v))\n    print(""========================================"")\n\n    assert torch.cuda.is_available(), \'no cuda\'\n    torch.manual_seed(args.seed)\n    torch.cuda.manual_seed(args.seed)\n\n    # load model and dataset fetcher\n    model_raw, ds_fetcher, is_imagenet = selector.select(args.type, model_root=args.model_root)\n    args.ngpu = args.ngpu if is_imagenet else 1\n\n    # quantize parameters\n    if args.param_bits < 32:\n        state_dict = model_raw.state_dict()\n        state_dict_quant = OrderedDict()\n        sf_dict = OrderedDict()\n        for k, v in state_dict.items():\n            if \'running\' in k:\n                if args.bn_bits >=32:\n                    print(""Ignoring {}"".format(k))\n                    state_dict_quant[k] = v\n                    continue\n                else:\n                    bits = args.bn_bits\n            else:\n                bits = args.param_bits\n\n            if args.quant_method == \'linear\':\n                sf = bits - 1. - quant.compute_integral_part(v, overflow_rate=args.overflow_rate)\n                v_quant  = quant.linear_quantize(v, sf, bits=bits)\n            elif args.quant_method == \'log\':\n                v_quant = quant.log_minmax_quantize(v, bits=bits)\n            elif args.quant_method == \'minmax\':\n                v_quant = quant.min_max_quantize(v, bits=bits)\n            else:\n                v_quant = quant.tanh_quantize(v, bits=bits)\n            state_dict_quant[k] = v_quant\n            print(k, bits)\n        model_raw.load_state_dict(state_dict_quant)\n\n    # quantize forward activation\n    if args.fwd_bits < 32:\n        model_raw = quant.duplicate_model_with_quant(model_raw, bits=args.fwd_bits, overflow_rate=args.overflow_rate,\n                                                     counter=args.n_sample, type=args.quant_method)\n        print(model_raw)\n        val_ds_tmp = ds_fetcher(10, data_root=args.data_root, train=False, input_size=args.input_size)\n        misc.eval_model(model_raw, val_ds_tmp, ngpu=1, n_sample=args.n_sample, is_imagenet=is_imagenet)\n\n    # eval model\n    val_ds = ds_fetcher(args.batch_size, data_root=args.data_root, train=False, input_size=args.input_size)\n    acc1, acc5 = misc.eval_model(model_raw, val_ds, ngpu=args.ngpu, is_imagenet=is_imagenet)\n\n    # print sf\n    print(model_raw)\n    res_str = ""type={}, quant_method={}, param_bits={}, bn_bits={}, fwd_bits={}, overflow_rate={}, acc1={:.4f}, acc5={:.4f}"".format(\n        args.type, args.quant_method, args.param_bits, args.bn_bits, args.fwd_bits, args.overflow_rate, acc1, acc5)\n    print(res_str)\n    with open(\'acc1_acc5.txt\', \'a\') as f:\n        f.write(res_str + \'\\n\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
setup.py,0,"b'from setuptools import setup, find_packages\n\nwith open(""requirements.txt"") as requirements_file:\n    REQUIREMENTS = requirements_file.readlines()\n\nsetup(\n    name=""pytorch-playground"",\n    version=""1.0.0"",\n    author=\'Aaron Chen\',\n    author_email=\'aaron.xichen@gmail.com\',\n    packages=find_packages(),\n    entry_points = {\n        \'console_scripts\': [\n            \'quantize=quantize:main\',\n        ]\n    },\n    install_requires=REQUIREMENTS,\n\n)\n'"
cifar/__init__.py,0,b''
cifar/dataset.py,5,"b'import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport os\n\ndef get10(batch_size, data_root=\'/tmp/public_dataset/pytorch\', train=True, val=True, **kwargs):\n    data_root = os.path.expanduser(os.path.join(data_root, \'cifar10-data\'))\n    num_workers = kwargs.setdefault(\'num_workers\', 1)\n    kwargs.pop(\'input_size\', None)\n    print(""Building CIFAR-10 data loader with {} workers"".format(num_workers))\n    ds = []\n    if train:\n        train_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\n                root=data_root, train=True, download=True,\n                transform=transforms.Compose([\n                    transforms.Pad(4),\n                    transforms.RandomCrop(32),\n                    transforms.RandomHorizontalFlip(),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                ])),\n            batch_size=batch_size, shuffle=True, **kwargs)\n        ds.append(train_loader)\n    if val:\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\n                root=data_root, train=False, download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                ])),\n            batch_size=batch_size, shuffle=False, **kwargs)\n        ds.append(test_loader)\n    ds = ds[0] if len(ds) == 1 else ds\n    return ds\n\ndef get100(batch_size, data_root=\'/tmp/public_dataset/pytorch\', train=True, val=True, **kwargs):\n    data_root = os.path.expanduser(os.path.join(data_root, \'cifar100-data\'))\n    num_workers = kwargs.setdefault(\'num_workers\', 1)\n    kwargs.pop(\'input_size\', None)\n    print(""Building CIFAR-100 data loader with {} workers"".format(num_workers))\n    ds = []\n    if train:\n        train_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\n                root=data_root, train=True, download=True,\n                transform=transforms.Compose([\n                    transforms.Pad(4),\n                    transforms.RandomCrop(32),\n                    transforms.RandomHorizontalFlip(),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                ])),\n            batch_size=batch_size, shuffle=True, **kwargs)\n        ds.append(train_loader)\n\n    if val:\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\n                root=data_root, train=False, download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                ])),\n            batch_size=batch_size, shuffle=False, **kwargs)\n        ds.append(test_loader)\n    ds = ds[0] if len(ds) == 1 else ds\n    return ds\n\n'"
cifar/model.py,2,"b""import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nfrom IPython import embed\nfrom collections import OrderedDict\n\nfrom utee import misc\nprint = misc.logger.info\n\nmodel_urls = {\n    'cifar10': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/cifar10-d875770b.pth',\n    'cifar100': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/cifar100-3a55a987.pth',\n}\n\nclass CIFAR(nn.Module):\n    def __init__(self, features, n_channel, num_classes):\n        super(CIFAR, self).__init__()\n        assert isinstance(features, nn.Sequential), type(features)\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(n_channel, num_classes)\n        )\n        print(self.features)\n        print(self.classifier)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for i, v in enumerate(cfg):\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            padding = v[1] if isinstance(v, tuple) else 1\n            out_channels = v[0] if isinstance(v, tuple) else v\n            conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(out_channels, affine=False), nn.ReLU()]\n            else:\n                layers += [conv2d, nn.ReLU()]\n            in_channels = out_channels\n    return nn.Sequential(*layers)\n\ndef cifar10(n_channel, pretrained=None):\n    cfg = [n_channel, n_channel, 'M', 2*n_channel, 2*n_channel, 'M', 4*n_channel, 4*n_channel, 'M', (8*n_channel, 0), 'M']\n    layers = make_layers(cfg, batch_norm=True)\n    model = CIFAR(layers, n_channel=8*n_channel, num_classes=10)\n    if pretrained is not None:\n        m = model_zoo.load_url(model_urls['cifar10'])\n        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n        assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n        model.load_state_dict(state_dict)\n    return model\n\ndef cifar100(n_channel, pretrained=None):\n    cfg = [n_channel, n_channel, 'M', 2*n_channel, 2*n_channel, 'M', 4*n_channel, 4*n_channel, 'M', (8*n_channel, 0), 'M']\n    layers = make_layers(cfg, batch_norm=True)\n    model = CIFAR(layers, n_channel=8*n_channel, num_classes=100)\n    if pretrained is not None:\n        m = model_zoo.load_url(model_urls['cifar100'])\n        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n        assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n        model.load_state_dict(state_dict)\n    return model\n\nif __name__ == '__main__':\n    model = cifar10(128, pretrained='log/cifar10/best-135.pth')\n    embed()\n\n"""
cifar/train.py,7,"b'import argparse\nimport os\nimport time\n\nfrom utee import misc\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nimport dataset\nimport model\n\nfrom IPython import embed\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR-X Example\')\nparser.add_argument(\'--type\', default=\'cifar10\', help=\'cifar10|cifar100\')\nparser.add_argument(\'--channel\', type=int, default=128, help=\'first conv channel (default: 32)\')\nparser.add_argument(\'--wd\', type=float, default=0.00, help=\'weight decay\')\nparser.add_argument(\'--batch_size\', type=int, default=200, help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--epochs\', type=int, default=150, help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.001, help=\'learning rate (default: 1e-3)\')\nparser.add_argument(\'--gpu\', default=None, help=\'index of gpus to use\')\nparser.add_argument(\'--ngpu\', type=int, default=2, help=\'number of gpus to use\')\nparser.add_argument(\'--seed\', type=int, default=117, help=\'random seed (default: 1)\')\nparser.add_argument(\'--log_interval\', type=int, default=100,  help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--test_interval\', type=int, default=5,  help=\'how many epochs to wait before another test\')\nparser.add_argument(\'--logdir\', default=\'log/default\', help=\'folder to save to the log\')\nparser.add_argument(\'--decreasing_lr\', default=\'80,120\', help=\'decreasing strategy\')\nargs = parser.parse_args()\nargs.logdir = os.path.join(os.path.dirname(__file__), args.logdir)\nmisc.logger.init(args.logdir, \'train_log\')\nprint = misc.logger.info\n\n# select gpu\nargs.gpu = misc.auto_select_gpu(utility_bound=0, num_gpu=args.ngpu, selected_gpus=args.gpu)\nargs.ngpu = len(args.gpu)\n\n# logger\nmisc.ensure_dir(args.logdir)\nprint(""=================FLAGS=================="")\nfor k, v in args.__dict__.items():\n    print(\'{}: {}\'.format(k, v))\nprint(""========================================"")\n\n# seed\nargs.cuda = torch.cuda.is_available()\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# data loader and model\nassert args.type in [\'cifar10\', \'cifar100\'], args.type\nif args.type == \'cifar10\':\n    train_loader, test_loader = dataset.get10(batch_size=args.batch_size, num_workers=1)\n    model = model.cifar10(n_channel=args.channel)\nelse:\n    train_loader, test_loader = dataset.get100(batch_size=args.batch_size, num_workers=1)\n    model = model.cifar100(n_channel=args.channel)\nmodel = torch.nn.DataParallel(model, device_ids= range(args.ngpu))\nif args.cuda:\n    model.cuda()\n\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\ndecreasing_lr = list(map(int, args.decreasing_lr.split(\',\')))\nprint(\'decreasing_lr: \' + str(decreasing_lr))\nbest_acc, old_file = 0, None\nt_begin = time.time()\ntry:\n    # ready to go\n    for epoch in range(args.epochs):\n        model.train()\n        if epoch in decreasing_lr:\n            optimizer.param_groups[0][\'lr\'] *= 0.1\n        for batch_idx, (data, target) in enumerate(train_loader):\n            indx_target = target.clone()\n            if args.cuda:\n                data, target = data.cuda(), target.cuda()\n            data, target = Variable(data), Variable(target)\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.cross_entropy(output, target)\n            loss.backward()\n            optimizer.step()\n\n            if batch_idx % args.log_interval == 0 and batch_idx > 0:\n                pred = output.data.max(1)[1]  # get the index of the max log-probability\n                correct = pred.cpu().eq(indx_target).sum()\n                acc = correct * 1.0 / len(data)\n                print(\'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f} lr: {:.2e}\'.format(\n                    epoch, batch_idx * len(data), len(train_loader.dataset),\n                    loss.data[0], acc, optimizer.param_groups[0][\'lr\']))\n\n        elapse_time = time.time() - t_begin\n        speed_epoch = elapse_time / (epoch + 1)\n        speed_batch = speed_epoch / len(train_loader)\n        eta = speed_epoch * args.epochs - elapse_time\n        print(""Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s"".format(\n            elapse_time, speed_epoch, speed_batch, eta))\n        misc.model_snapshot(model, os.path.join(args.logdir, \'latest.pth\'))\n\n        if epoch % args.test_interval == 0:\n            model.eval()\n            test_loss = 0\n            correct = 0\n            for data, target in test_loader:\n                indx_target = target.clone()\n                if args.cuda:\n                    data, target = data.cuda(), target.cuda()\n                data, target = Variable(data, volatile=True), Variable(target)\n                output = model(data)\n                test_loss += F.cross_entropy(output, target).data[0]\n                pred = output.data.max(1)[1]  # get the index of the max log-probability\n                correct += pred.cpu().eq(indx_target).sum()\n\n            test_loss = test_loss / len(test_loader) # average over number of mini-batch\n            acc = 100. * correct / len(test_loader.dataset)\n            print(\'\\tTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\'.format(\n                test_loss, correct, len(test_loader.dataset), acc))\n            if acc > best_acc:\n                new_file = os.path.join(args.logdir, \'best-{}.pth\'.format(epoch))\n                misc.model_snapshot(model, new_file, old_file=old_file, verbose=True)\n                best_acc = acc\n                old_file = new_file\nexcept Exception as e:\n    import traceback\n    traceback.print_exc()\nfinally:\n    print(""Total Elapse: {:.2f}, Best Result: {:.3f}%"".format(time.time()-t_begin, best_acc))\n\n\n'"
imagenet/__init__.py,0,b''
imagenet/alexnet.py,3,"b""import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\n\n\n__all__ = ['AlexNet', 'alexnet']\n\n\nmodel_urls = {\n    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n}\n\n\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=1000):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), 256 * 6 * 6)\n        x = self.classifier(x)\n        return x\n\n\ndef alexnet(pretrained=False, model_root=None, **kwargs):\n    model = AlexNet(**kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['alexnet'], model_root))\n    return model\n"""
imagenet/dataset.py,0,"b'from utee import misc\nimport os\nimport os.path\nimport numpy as np\nimport joblib\n\n\ndef get(batch_size, data_root=\'/tmp/public_dataset/pytorch\', train=False, val=True, **kwargs):\n    data_root = os.path.expanduser(os.path.join(data_root, \'imagenet-data\'))\n    print(""Building IMAGENET data loader, 50000 for train, 50000 for test"")\n    ds = []\n    assert train is not True, \'train not supported yet\'\n    if train:\n        ds.append(IMAGENET(data_root, batch_size, True, **kwargs))\n    if val:\n        ds.append(IMAGENET(data_root, batch_size, False, **kwargs))\n    ds = ds[0] if len(ds) == 1 else ds\n    return ds\n\nclass IMAGENET(object):\n    def __init__(self, root, batch_size, train=False, input_size=224, **kwargs):\n        self.mean = np.array([0.485, 0.456, 0.406]).reshape(1, 1, 1, 3)\n        self.std = np.array([0.229, 0.224, 0.225]).reshape(1, 1, 1, 3)\n        self.train = train\n\n        if train:\n            pkl_file = os.path.join(root, \'train{}.pkl\'.format(input_size))\n        else:\n            pkl_file = os.path.join(root, \'val{}.pkl\'.format(input_size))\n        self.data_dict = joblib.load(pkl_file)\n\n        self.batch_size = batch_size\n        self.idx = 0\n\n    @property\n    def n_batch(self):\n        return int(np.ceil(self.n_sample* 1.0 / self.batch_size))\n\n    @property\n    def n_sample(self):\n        return len(self.data_dict[\'data\'])\n\n    def __len__(self):\n        return self.n_batch\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.idx >= self.n_batch:\n            self.idx = 0\n            raise StopIteration\n        else:\n            img = self.data_dict[\'data\'][self.idx*self.batch_size:(self.idx+1)*self.batch_size].astype(\'float32\')\n            target = self.data_dict[\'target\'][self.idx*self.batch_size:(self.idx+1)*self.batch_size]\n            self.idx += 1\n            return img, target\n\nif __name__ == \'__main__\':\n    train_ds, val_ds = get(200)\n\n\n'"
imagenet/inception.py,11,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom utee import misc\nfrom collections import OrderedDict\n\n\n__all__ = ['Inception3', 'inception_v3']\n\n\nmodel_urls = {\n    'inception_v3_google': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',\n}\n\n\ndef inception_v3(pretrained=False, model_root=None, **kwargs):\n    if pretrained:\n        if 'transform_input' not in kwargs:\n            kwargs['transform_input'] = True\n        model = Inception3(**kwargs)\n        misc.load_state_dict(model, model_urls['inception_v3_google'], model_root)\n        return model\n\n    return Inception3(**kwargs)\n\n\nclass Inception3(nn.Module):\n\n    def __init__(self, num_classes=1000, aux_logits=True, transform_input=False):\n        super(Inception3, self).__init__()\n        self.aux_logits = aux_logits\n        self.transform_input = transform_input\n        self.Conv2d_1a_3x3 = BasicConv2d(3, 32, kernel_size=3, stride=2)\n        self.Conv2d_2a_3x3 = BasicConv2d(32, 32, kernel_size=3)\n        self.Conv2d_2b_3x3 = BasicConv2d(32, 64, kernel_size=3, padding=1)\n        self.Conv2d_3b_1x1 = BasicConv2d(64, 80, kernel_size=1)\n        self.Conv2d_4a_3x3 = BasicConv2d(80, 192, kernel_size=3)\n        self.Mixed_5b = InceptionA(192, pool_features=32)\n        self.Mixed_5c = InceptionA(256, pool_features=64)\n        self.Mixed_5d = InceptionA(288, pool_features=64)\n        self.Mixed_6a = InceptionB(288)\n        self.Mixed_6b = InceptionC(768, channels_7x7=128)\n        self.Mixed_6c = InceptionC(768, channels_7x7=160)\n        self.Mixed_6d = InceptionC(768, channels_7x7=160)\n        self.Mixed_6e = InceptionC(768, channels_7x7=192)\n        if aux_logits:\n            self.AuxLogits = InceptionAux(768, num_classes)\n        self.Mixed_7a = InceptionD(768)\n        self.Mixed_7b = InceptionE(1280)\n        self.Mixed_7c = InceptionE(2048)\n        self.group1 = nn.Sequential(\n            OrderedDict([\n                ('fc', nn.Linear(2048, num_classes))\n            ])\n        )\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n                import scipy.stats as stats\n                stddev = m.stddev if hasattr(m, 'stddev') else 0.1\n                X = stats.truncnorm(-2, 2, scale=stddev)\n                values = torch.Tensor(X.rvs(m.weight.data.numel()))\n                m.weight.data.copy_(values.reshape(m.weight.shape))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        if self.transform_input:\n            x = x.clone()\n            x[0] = x[0] * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n            x[1] = x[1] * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n            x[2] = x[2] * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n        # 299 x 299 x 3\n        x = self.Conv2d_1a_3x3(x)\n        # 149 x 149 x 32\n        x = self.Conv2d_2a_3x3(x)\n        # 147 x 147 x 32\n        x = self.Conv2d_2b_3x3(x)\n        # 147 x 147 x 64\n        x = F.max_pool2d(x, kernel_size=3, stride=2)\n        # 73 x 73 x 64\n        x = self.Conv2d_3b_1x1(x)\n        # 73 x 73 x 80\n        x = self.Conv2d_4a_3x3(x)\n        # 71 x 71 x 192\n        x = F.max_pool2d(x, kernel_size=3, stride=2)\n        # 35 x 35 x 192\n        x = self.Mixed_5b(x)\n        # 35 x 35 x 256\n        x = self.Mixed_5c(x)\n        # 35 x 35 x 288\n        x = self.Mixed_5d(x)\n        # 35 x 35 x 288\n        x = self.Mixed_6a(x)\n        # 17 x 17 x 768\n        x = self.Mixed_6b(x)\n        # 17 x 17 x 768\n        x = self.Mixed_6c(x)\n        # 17 x 17 x 768\n        x = self.Mixed_6d(x)\n        # 17 x 17 x 768\n        x = self.Mixed_6e(x)\n        # 17 x 17 x 768\n        if self.training and self.aux_logits:\n            aux = self.AuxLogits(x)\n        # 17 x 17 x 768\n        x = self.Mixed_7a(x)\n        # 8 x 8 x 1280\n        x = self.Mixed_7b(x)\n        # 8 x 8 x 2048\n        x = self.Mixed_7c(x)\n        # 8 x 8 x 2048\n        x = F.avg_pool2d(x, kernel_size=8)\n        # 1 x 1 x 2048\n        x = F.dropout(x, training=self.training)\n        # 1 x 1 x 2048\n        x = x.view(x.size(0), -1)\n        # 2048\n        x = self.group1(x)\n        # 1000 (num_classes)\n        if self.training and self.aux_logits:\n            return x, aux\n        return x\n\n\nclass InceptionA(nn.Module):\n\n    def __init__(self, in_channels, pool_features):\n        super(InceptionA, self).__init__()\n        self.branch1x1 = BasicConv2d(in_channels, 64, kernel_size=1)\n\n        self.branch5x5_1 = BasicConv2d(in_channels, 48, kernel_size=1)\n        self.branch5x5_2 = BasicConv2d(48, 64, kernel_size=5, padding=2)\n\n        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, padding=1)\n\n        self.branch_pool = BasicConv2d(in_channels, pool_features, kernel_size=1)\n\n    def forward(self, x):\n        branch1x1 = self.branch1x1(x)\n\n        branch5x5 = self.branch5x5_1(x)\n        branch5x5 = self.branch5x5_2(branch5x5)\n\n        branch3x3dbl = self.branch3x3dbl_1(x)\n        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n\n        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n        branch_pool = self.branch_pool(branch_pool)\n\n        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n        return torch.cat(outputs, 1)\n\n\nclass InceptionB(nn.Module):\n\n    def __init__(self, in_channels):\n        super(InceptionB, self).__init__()\n        self.branch3x3 = BasicConv2d(in_channels, 384, kernel_size=3, stride=2)\n\n        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, stride=2)\n\n    def forward(self, x):\n        branch3x3 = self.branch3x3(x)\n\n        branch3x3dbl = self.branch3x3dbl_1(x)\n        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n\n        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n\n        outputs = [branch3x3, branch3x3dbl, branch_pool]\n        return torch.cat(outputs, 1)\n\n\nclass InceptionC(nn.Module):\n\n    def __init__(self, in_channels, channels_7x7):\n        super(InceptionC, self).__init__()\n        self.branch1x1 = BasicConv2d(in_channels, 192, kernel_size=1)\n\n        c7 = channels_7x7\n        self.branch7x7_1 = BasicConv2d(in_channels, c7, kernel_size=1)\n        self.branch7x7_2 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n        self.branch7x7_3 = BasicConv2d(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n\n        self.branch7x7dbl_1 = BasicConv2d(in_channels, c7, kernel_size=1)\n        self.branch7x7dbl_2 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n        self.branch7x7dbl_3 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n        self.branch7x7dbl_4 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n        self.branch7x7dbl_5 = BasicConv2d(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n\n        self.branch_pool = BasicConv2d(in_channels, 192, kernel_size=1)\n\n    def forward(self, x):\n        branch1x1 = self.branch1x1(x)\n\n        branch7x7 = self.branch7x7_1(x)\n        branch7x7 = self.branch7x7_2(branch7x7)\n        branch7x7 = self.branch7x7_3(branch7x7)\n\n        branch7x7dbl = self.branch7x7dbl_1(x)\n        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n\n        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n        branch_pool = self.branch_pool(branch_pool)\n\n        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n        return torch.cat(outputs, 1)\n\n\nclass InceptionD(nn.Module):\n\n    def __init__(self, in_channels):\n        super(InceptionD, self).__init__()\n        self.branch3x3_1 = BasicConv2d(in_channels, 192, kernel_size=1)\n        self.branch3x3_2 = BasicConv2d(192, 320, kernel_size=3, stride=2)\n\n        self.branch7x7x3_1 = BasicConv2d(in_channels, 192, kernel_size=1)\n        self.branch7x7x3_2 = BasicConv2d(192, 192, kernel_size=(1, 7), padding=(0, 3))\n        self.branch7x7x3_3 = BasicConv2d(192, 192, kernel_size=(7, 1), padding=(3, 0))\n        self.branch7x7x3_4 = BasicConv2d(192, 192, kernel_size=3, stride=2)\n\n    def forward(self, x):\n        branch3x3 = self.branch3x3_1(x)\n        branch3x3 = self.branch3x3_2(branch3x3)\n\n        branch7x7x3 = self.branch7x7x3_1(x)\n        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n\n        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n        outputs = [branch3x3, branch7x7x3, branch_pool]\n        return torch.cat(outputs, 1)\n\n\nclass InceptionE(nn.Module):\n\n    def __init__(self, in_channels):\n        super(InceptionE, self).__init__()\n        self.branch1x1 = BasicConv2d(in_channels, 320, kernel_size=1)\n\n        self.branch3x3_1 = BasicConv2d(in_channels, 384, kernel_size=1)\n        self.branch3x3_2a = BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1))\n        self.branch3x3_2b = BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0))\n\n        self.branch3x3dbl_1 = BasicConv2d(in_channels, 448, kernel_size=1)\n        self.branch3x3dbl_2 = BasicConv2d(448, 384, kernel_size=3, padding=1)\n        self.branch3x3dbl_3a = BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1))\n        self.branch3x3dbl_3b = BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0))\n\n        self.branch_pool = BasicConv2d(in_channels, 192, kernel_size=1)\n\n    def forward(self, x):\n        branch1x1 = self.branch1x1(x)\n\n        branch3x3 = self.branch3x3_1(x)\n        branch3x3 = [\n            self.branch3x3_2a(branch3x3),\n            self.branch3x3_2b(branch3x3),\n        ]\n        branch3x3 = torch.cat(branch3x3, 1)\n\n        branch3x3dbl = self.branch3x3dbl_1(x)\n        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n        branch3x3dbl = [\n            self.branch3x3dbl_3a(branch3x3dbl),\n            self.branch3x3dbl_3b(branch3x3dbl),\n        ]\n        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n\n        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n        branch_pool = self.branch_pool(branch_pool)\n\n        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n        return torch.cat(outputs, 1)\n\n\nclass InceptionAux(nn.Module):\n\n    def __init__(self, in_channels, num_classes):\n        super(InceptionAux, self).__init__()\n        self.conv0 = BasicConv2d(in_channels, 128, kernel_size=1)\n        self.conv1 = BasicConv2d(128, 768, kernel_size=5)\n        self.conv1.stddev = 0.01\n\n        fc = nn.Linear(768, num_classes)\n        fc.stddev = 0.001\n\n        self.group1 = nn.Sequential(\n            OrderedDict([\n                ('fc', fc)\n            ])\n        )\n\n    def forward(self, x):\n        # 17 x 17 x 768\n        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n        # 5 x 5 x 768\n        x = self.conv0(x)\n        # 5 x 5 x 128\n        x = self.conv1(x)\n        # 1 x 1 x 768\n        x = x.view(x.size(0), -1)\n        # 768\n        x = self.group1(x)\n        # 1000\n        return x\n\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, **kwargs):\n        super(BasicConv2d, self).__init__()\n        self.group1 = nn.Sequential(\n            OrderedDict([\n                ('conv', nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)),\n                ('bn', nn.BatchNorm2d(out_channels, eps=0.001))\n            ])\n        )\n\n    def forward(self, x):\n        x = self.group1(x)\n        return F.relu(x, inplace=True)\n"""
imagenet/resnet.py,6,"b'import torch.nn as nn\nimport math\nfrom utee import misc\nfrom collections import OrderedDict\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\']\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    # ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        m = OrderedDict()\n        m[\'conv1\'] = conv3x3(inplanes, planes, stride)\n        m[\'bn1\'] = nn.BatchNorm2d(planes)\n        m[\'relu1\'] = nn.ReLU(inplace=True)\n        m[\'conv2\'] = conv3x3(planes, planes)\n        m[\'bn2\'] = nn.BatchNorm2d(planes)\n        self.group1 = nn.Sequential(m)\n\n        self.relu= nn.Sequential(nn.ReLU(inplace=True))\n        self.downsample = downsample\n\n    def forward(self, x):\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        else:\n            residual = x\n\n        out = self.group1(x) + residual\n\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        m  = OrderedDict()\n        m[\'conv1\'] = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        m[\'bn1\'] = nn.BatchNorm2d(planes)\n        m[\'relu1\'] = nn.ReLU(inplace=True)\n        m[\'conv2\'] = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        m[\'bn2\'] = nn.BatchNorm2d(planes)\n        m[\'relu2\'] = nn.ReLU(inplace=True)\n        m[\'conv3\'] = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        m[\'bn3\'] = nn.BatchNorm2d(planes * 4)\n        self.group1 = nn.Sequential(m)\n\n        self.relu= nn.Sequential(nn.ReLU(inplace=True))\n        self.downsample = downsample\n\n    def forward(self, x):\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        else:\n            residual = x\n\n        out = self.group1(x) + residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n\n        m = OrderedDict()\n        m[\'conv1\'] = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        m[\'bn1\'] = nn.BatchNorm2d(64)\n        m[\'relu1\'] = nn.ReLU(inplace=True)\n        m[\'maxpool\'] = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.group1= nn.Sequential(m)\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        self.avgpool = nn.Sequential(nn.AvgPool2d(7))\n\n        self.group2 = nn.Sequential(\n            OrderedDict([\n                (\'fc\', nn.Linear(512 * block.expansion, num_classes))\n            ])\n        )\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.group1(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.group2(x)\n\n        return x\n\n\ndef resnet18(pretrained=False, model_root=None, **kwargs):\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        misc.load_state_dict(model, model_urls[\'resnet18\'], model_root)\n    return model\n\n\ndef resnet34(pretrained=False, model_root=None, **kwargs):\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        misc.load_state_dict(model, model_urls[\'resnet34\'], model_root)\n    return model\n\n\ndef resnet50(pretrained=False, model_root=None, **kwargs):\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        misc.load_state_dict(model, model_urls[\'resnet50\'], model_root)\n    return model\n\n\ndef resnet101(pretrained=False, model_root=None, **kwargs):\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        misc.load_state_dict(model, model_urls[\'resnet101\'], model_root)\n    return model\n\n\ndef resnet152(pretrained=False, model_root=None, **kwargs):\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        misc.load_state_dict(model, model_urls[\'resnet152\'], model_root)\n    return model\n'"
imagenet/squeezenet.py,4,"b'import math\nimport torch\nimport torch.nn as nn\nfrom utee import misc\nfrom collections import OrderedDict\n\n\n__all__ = [\'SqueezeNet\', \'squeezenet1_0\', \'squeezenet1_1\']\n\n\nmodel_urls = {\n    \'squeezenet1_0\': \'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\',\n    \'squeezenet1_1\': \'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\',\n}\n\n\nclass Fire(nn.Module):\n\n    def __init__(self, inplanes, squeeze_planes,\n                 expand1x1_planes, expand3x3_planes):\n        super(Fire, self).__init__()\n        self.inplanes = inplanes\n\n        self.group1 = nn.Sequential(\n            OrderedDict([\n                (\'squeeze\', nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)),\n                (\'squeeze_activation\', nn.ReLU(inplace=True))\n            ])\n        )\n\n        self.group2 = nn.Sequential(\n            OrderedDict([\n                (\'expand1x1\', nn.Conv2d(squeeze_planes, expand1x1_planes, kernel_size=1)),\n                (\'expand1x1_activation\', nn.ReLU(inplace=True))\n            ])\n        )\n\n        self.group3 = nn.Sequential(\n            OrderedDict([\n                (\'expand3x3\', nn.Conv2d(squeeze_planes, expand3x3_planes, kernel_size=3, padding=1)),\n                (\'expand3x3_activation\', nn.ReLU(inplace=True))\n            ])\n        )\n\n    def forward(self, x):\n        x = self.group1(x)\n        return torch.cat([self.group2(x),self.group3(x)], 1)\n\n\nclass SqueezeNet(nn.Module):\n\n    def __init__(self, version=1.0, num_classes=1000):\n        super(SqueezeNet, self).__init__()\n        if version not in [1.0, 1.1]:\n            raise ValueError(""Unsupported SqueezeNet version {version}:""\n                             ""1.0 or 1.1 expected"".format(version=version))\n        self.num_classes = num_classes\n        if version == 1.0:\n            self.features = nn.Sequential(\n                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(96, 16, 64, 64),\n                Fire(128, 16, 64, 64),\n                Fire(128, 32, 128, 128),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(256, 32, 128, 128),\n                Fire(256, 48, 192, 192),\n                Fire(384, 48, 192, 192),\n                Fire(384, 64, 256, 256),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(512, 64, 256, 256),\n            )\n        else:\n            self.features = nn.Sequential(\n                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(64, 16, 64, 64),\n                Fire(128, 16, 64, 64),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(128, 32, 128, 128),\n                Fire(256, 32, 128, 128),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(256, 48, 192, 192),\n                Fire(384, 48, 192, 192),\n                Fire(384, 64, 256, 256),\n                Fire(512, 64, 256, 256),\n            )\n        # Final convolution is initialized differently form the rest\n        final_conv = nn.Conv2d(512, num_classes, kernel_size=1)\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=0.5),\n            final_conv,\n            nn.ReLU(inplace=True),\n            nn.AvgPool2d(13)\n        )\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                gain = 2.0\n                if m is final_conv:\n                    m.weight.data.normal_(0, 0.01)\n                else:\n                    fan_in = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n                    u = math.sqrt(3.0 * gain / fan_in)\n                    m.weight.data.uniform_(-u, u)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x.view(x.size(0), self.num_classes)\n\ndef squeezenet1_0(pretrained=False, model_root=None, **kwargs):\n    r""""""SqueezeNet model architecture from the `""SqueezeNet: AlexNet-level\n    accuracy with 50x fewer parameters and <0.5MB model size""\n    <https://arxiv.org/abs/1602.07360>`_ paper.\n    """"""\n    model = SqueezeNet(version=1.0, **kwargs)\n    if pretrained:\n        misc.load_state_dict(model, model_urls[\'squeezenet1_0\'], model_root)\n    return model\n\n\ndef squeezenet1_1(pretrained=False, model_root=None, **kwargs):\n    r""""""SqueezeNet 1.1 model from the `official SqueezeNet repo\n    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n    than SqueezeNet 1.0, without sacrificing accuracy.\n    """"""\n    model = SqueezeNet(version=1.1, **kwargs)\n    if pretrained:\n        misc.load_state_dict(model, model_urls[\'squeezenet1_1\'], model_root)\n    return model\n\n'"
imagenet/vgg.py,6,"b'import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport math\n\n\n__all__ = [\n    \'VGG\', \'vgg11\', \'vgg11_bn\', \'vgg13\', \'vgg13_bn\', \'vgg16\', \'vgg16_bn\',\n    \'vgg19_bn\', \'vgg19\',\n]\n\n\nmodel_urls = {\n    \'vgg11\': \'https://download.pytorch.org/models/vgg11-bbd30ac9.pth\',\n    \'vgg13\': \'https://download.pytorch.org/models/vgg13-c768596a.pth\',\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n    \'vgg19\': \'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\',\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes),\n        )\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfg = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'B\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'D\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512, \'M\'],\n    \'E\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512, \'M\'],\n}\n\n\ndef vgg11(pretrained=False, model_root=None, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"")""""""\n    model = VGG(make_layers(cfg[\'A\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg11\'], model_root))\n    return model\n\n\ndef vgg11_bn(**kwargs):\n    """"""VGG 11-layer model (configuration ""A"") with batch normalization""""""\n    kwargs.pop(\'model_root\', None)\n    return VGG(make_layers(cfg[\'A\'], batch_norm=True), **kwargs)\n\n\ndef vgg13(pretrained=False, model_root=None, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"")""""""\n    model = VGG(make_layers(cfg[\'B\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg13\'], model_root))\n    return model\n\n\ndef vgg13_bn(**kwargs):\n    """"""VGG 13-layer model (configuration ""B"") with batch normalization""""""\n    kwargs.pop(\'model_root\', None)\n    return VGG(make_layers(cfg[\'B\'], batch_norm=True), **kwargs)\n\n\ndef vgg16(pretrained=False, model_root=None, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")""""""\n    model = VGG(make_layers(cfg[\'D\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\'], model_root))\n    return model\n\n\ndef vgg16_bn(**kwargs):\n    """"""VGG 16-layer model (configuration ""D"") with batch normalization""""""\n    kwargs.pop(\'model_root\', None)\n    return VGG(make_layers(cfg[\'D\'], batch_norm=True), **kwargs)\n\n\ndef vgg19(pretrained=False, model_root=None, **kwargs):\n    """"""VGG 19-layer model (configuration ""E"")""""""\n    model = VGG(make_layers(cfg[\'E\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg19\'], model_root))\n    return model\n\n\ndef vgg19_bn(**kwargs):\n    """"""VGG 19-layer model (configuration \'E\') with batch normalization""""""\n    kwargs.pop(\'model_root\', None)\n    return VGG(make_layers(cfg[\'E\'], batch_norm=True), **kwargs)\n'"
mnist/__init__.py,0,b''
mnist/dataset.py,3,"b'from torch.utils.data import DataLoader\nimport torch\nfrom torchvision import datasets, transforms\nimport os\n\ndef get(batch_size, data_root=\'/tmp/public_dataset/pytorch\', train=True, val=True, **kwargs):\n    data_root = os.path.expanduser(os.path.join(data_root, \'mnist-data\'))\n    kwargs.pop(\'input_size\', None)\n    num_workers = kwargs.setdefault(\'num_workers\', 1)\n    print(""Building MNIST data loader with {} workers"".format(num_workers))\n    ds = []\n    if train:\n        train_loader = torch.utils.data.DataLoader(\n            datasets.MNIST(root=data_root, train=True, download=True,\n                           transform=transforms.Compose([\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.1307,), (0.3081,))\n                           ])),\n            batch_size=batch_size, shuffle=True, **kwargs)\n        ds.append(train_loader)\n    if val:\n        test_loader = torch.utils.data.DataLoader(\n            datasets.MNIST(root=data_root, train=False, download=True,\n                           transform=transforms.Compose([\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.1307,), (0.3081,))\n                            ])),\n            batch_size=batch_size, shuffle=True, **kwargs)\n        ds.append(test_loader)\n    ds = ds[0] if len(ds) == 1 else ds\n    return ds\n\n'"
mnist/model.py,2,"b""import torch.nn as nn\nfrom collections import OrderedDict\nimport torch.utils.model_zoo as model_zoo\nfrom utee import misc\nprint = misc.logger.info\n\nmodel_urls = {\n    'mnist': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/mnist-b07bb66b.pth'\n}\n\nclass MLP(nn.Module):\n    def __init__(self, input_dims, n_hiddens, n_class):\n        super(MLP, self).__init__()\n        assert isinstance(input_dims, int), 'Please provide int for input_dims'\n        self.input_dims = input_dims\n        current_dims = input_dims\n        layers = OrderedDict()\n\n        if isinstance(n_hiddens, int):\n            n_hiddens = [n_hiddens]\n        else:\n            n_hiddens = list(n_hiddens)\n        for i, n_hidden in enumerate(n_hiddens):\n            layers['fc{}'.format(i+1)] = nn.Linear(current_dims, n_hidden)\n            layers['relu{}'.format(i+1)] = nn.ReLU()\n            layers['drop{}'.format(i+1)] = nn.Dropout(0.2)\n            current_dims = n_hidden\n        layers['out'] = nn.Linear(current_dims, n_class)\n\n        self.model= nn.Sequential(layers)\n        print(self.model)\n\n    def forward(self, input):\n        input = input.view(input.size(0), -1)\n        assert input.size(1) == self.input_dims\n        return self.model.forward(input)\n\ndef mnist(input_dims=784, n_hiddens=[256, 256], n_class=10, pretrained=None):\n    model = MLP(input_dims, n_hiddens, n_class)\n    if pretrained is not None:\n        m = model_zoo.load_url(model_urls['mnist'])\n        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n        assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n        model.load_state_dict(state_dict)\n    return model\n\n"""
mnist/train.py,7,"b'import argparse\nimport os\nimport time\n\nfrom utee import misc\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nimport dataset\nimport model\n\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--wd\', type=float, default=0.0001, help=\'weight decay\')\nparser.add_argument(\'--batch_size\', type=int, default=200, help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--epochs\', type=int, default=40, help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, help=\'learning rate (default: 1e-3)\')\nparser.add_argument(\'--gpu\', default=None, help=\'index of gpus to use\')\nparser.add_argument(\'--ngpu\', type=int, default=1, help=\'number of gpus to use\')\nparser.add_argument(\'--seed\', type=int, default=117, help=\'random seed (default: 1)\')\nparser.add_argument(\'--log_interval\', type=int, default=100,  help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--test_interval\', type=int, default=5,  help=\'how many epochs to wait before another test\')\nparser.add_argument(\'--logdir\', default=\'log/default\', help=\'folder to save to the log\')\nparser.add_argument(\'--data_root\', default=\'/tmp/public_dataset/pytorch/\', help=\'folder to save the model\')\nparser.add_argument(\'--decreasing_lr\', default=\'80,120\', help=\'decreasing strategy\')\nargs = parser.parse_args()\nargs.logdir = os.path.join(os.path.dirname(__file__), args.logdir)\nmisc.logger.init(args.logdir, \'train_log\')\nprint = misc.logger.info\n\n# select gpu\nargs.gpu = misc.auto_select_gpu(utility_bound=0, num_gpu=args.ngpu, selected_gpus=args.gpu)\nargs.ngpu = len(args.gpu)\n\n# logger\nmisc.ensure_dir(args.logdir)\nprint(""=================FLAGS=================="")\nfor k, v in args.__dict__.items():\n    print(\'{}: {}\'.format(k, v))\nprint(""========================================"")\n\n# seed\nargs.cuda = torch.cuda.is_available()\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# data loader\ntrain_loader, test_loader = dataset.get(batch_size=args.batch_size, data_root=args.data_root, num_workers=1)\n\n# model\nmodel = model.mnist(input_dims=784, n_hiddens=[256, 256], n_class=10)\nmodel = torch.nn.DataParallel(model, device_ids= range(args.ngpu))\nif args.cuda:\n    model.cuda()\n\n# optimizer\noptimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wd, momentum=0.9)\ndecreasing_lr = list(map(int, args.decreasing_lr.split(\',\')))\nprint(\'decreasing_lr: \' + str(decreasing_lr))\nbest_acc, old_file = 0, None\nt_begin = time.time()\ntry:\n    # ready to go\n    for epoch in range(args.epochs):\n        model.train()\n        if epoch in decreasing_lr:\n            optimizer.param_groups[0][\'lr\'] *= 0.1\n        for batch_idx, (data, target) in enumerate(train_loader):\n            indx_target = target.clone()\n            if args.cuda:\n                data, target = data.cuda(), target.cuda()\n            data, target = Variable(data), Variable(target)\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.cross_entropy(output, target)\n            loss.backward()\n            optimizer.step()\n\n            if batch_idx % args.log_interval == 0 and batch_idx > 0:\n                pred = output.data.max(1)[1]  # get the index of the max log-probability\n                correct = pred.cpu().eq(indx_target).sum()\n                acc = correct * 1.0 / len(data)\n                print(\'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f} lr: {:.2e}\'.format(\n                    epoch, batch_idx * len(data), len(train_loader.dataset),\n                    loss.data, acc, optimizer.param_groups[0][\'lr\']))\n\n        elapse_time = time.time() - t_begin\n        speed_epoch = elapse_time / (epoch + 1)\n        speed_batch = speed_epoch / len(train_loader)\n        eta = speed_epoch * args.epochs - elapse_time\n        print(""Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s"".format(\n            elapse_time, speed_epoch, speed_batch, eta))\n        misc.model_snapshot(model, os.path.join(args.logdir, \'latest.pth\'))\n\n        if epoch % args.test_interval == 0:\n            model.eval()\n            test_loss = 0\n            correct = 0\n            for data, target in test_loader:\n                indx_target = target.clone()\n                if args.cuda:\n                    data, target = data.cuda(), target.cuda()\n                data, target = Variable(data, volatile=True), Variable(target)\n                output = model(data)\n                test_loss += F.cross_entropy(output, target).data\n                pred = output.data.max(1)[1]  # get the index of the max log-probability\n                correct += pred.cpu().eq(indx_target).sum()\n\n            test_loss = test_loss / len(test_loader) # average over number of mini-batch\n            acc = 100. * correct / len(test_loader.dataset)\n            print(\'\\tTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\'.format(\n                test_loss, correct, len(test_loader.dataset), acc))\n            if acc > best_acc:\n                new_file = os.path.join(args.logdir, \'best-{}.pth\'.format(epoch))\n                misc.model_snapshot(model, new_file, old_file=old_file, verbose=True)\n                best_acc = acc\n                old_file = new_file\nexcept Exception as e:\n    import traceback\n    traceback.print_exc()\nfinally:\n    print(""Total Elapse: {:.2f}, Best Result: {:.3f}%"".format(time.time()-t_begin, best_acc))\n\n\n'"
script/convert.py,0,"b""import os\nimport numpy as np\nimport tqdm\nfrom utee import misc\nimport argparse\nimport cv2\nimport joblib\n\nparser = argparse.ArgumentParser(description='Extract the ILSVRC2012 val dataset')\nparser.add_argument('--in_file', default='val224_compressed.pkl', help='input file path')\nparser.add_argument('--out_root', default='/data/public_dataset/pytorch/imagenet-data/', help='output file path')\nargs = parser.parse_args()\n\nd = misc.load_pickle(args.in_file)\nassert len(d['data']) == 50000, len(d['data'])\nassert len(d['target']) == 50000, len(d['target'])\n\n\ndata299 = []\nfor img, target in tqdm.tqdm(zip(d['data'], d['target']), total=50000):\n    img224 = misc.str2img(img)\n    img299 = cv2.resize(img224, (299, 299))\n    data299.append(img299)\n\ndata_dict299 = dict(\n    data = np.array(data299).transpose(0, 3, 1, 2),\n    target = d['target']\n)\nif not os.path.exists(args.out_root):\n    os.makedirs(args.out_root)\njoblib.dump(data_dict299, os.path.join(args.out_root, 'val299.pkl'))\n\ndata299.clear()\ndata_dict299.clear()\n\ndata224 = []\nfor img, target in tqdm.tqdm(zip(d['data'], d['target']), total=50000):\n    img224 = misc.str2img(img)\n    data224.append(img224)\n\ndata_dict224 = dict(\n    data = np.array(data224).transpose(0, 3, 1, 2),\n    target = d['target']\n)\njoblib.dump(data_dict224, os.path.join(args.out_root, 'val224.pkl'))\n\n\n\n\n"""
stl10/__init__.py,0,b''
stl10/dataset.py,3,"b'import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom IPython import embed\nimport os\n\ndef get(batch_size, data_root=\'/mnt/local0/public_dataset/pytorch/\', train=True, val=True, **kwargs):\n    data_root = os.path.expanduser(os.path.join(data_root, \'stl10-data\'))\n    num_workers = kwargs.setdefault(\'num_workers\', 1)\n    kwargs.pop(\'input_size\', None)\n    print(""Building STL10 data loader with {} workers"".format(num_workers))\n    ds = []\n    if train:\n        train_loader = torch.utils.data.DataLoader(\n            datasets.STL10(\n                root=data_root, split=\'train\', download=True,\n                transform=transforms.Compose([\n                    transforms.Pad(4),\n                    transforms.RandomCrop(96),\n                    transforms.RandomHorizontalFlip(),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                ])),\n            batch_size=batch_size, shuffle=True, **kwargs)\n        ds.append(train_loader)\n\n    if val:\n        test_loader = torch.utils.data.DataLoader(\n            datasets.STL10(\n                root=data_root, split=\'test\', download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                ])),\n            batch_size=batch_size, shuffle=False, **kwargs)\n        ds.append(test_loader)\n\n    ds = ds[0] if len(ds) == 1 else ds\n    return ds\n\nif __name__ == \'__main__\':\n    train_ds, test_ds = get(200, num_workers=1)\n    for data, target in train_ds:\n        print(""~~"")\n'"
stl10/model.py,2,"b""import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nfrom utee import misc\nfrom collections import OrderedDict\nprint = misc.logger.info\n\nmodel_urls = {\n    'stl10': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/stl10-866321e9.pth',\n}\n\nclass SVHN(nn.Module):\n    def __init__(self, features, n_channel, num_classes):\n        super(SVHN, self).__init__()\n        assert isinstance(features, nn.Sequential), type(features)\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(n_channel, num_classes)\n        )\n        print(self.features)\n        print(self.classifier)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for i, v in enumerate(cfg):\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            padding = v[1] if isinstance(v, tuple) else 1\n            out_channels = v[0] if isinstance(v, tuple) else v\n            conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(out_channels, affine=False), nn.ReLU()]\n            else:\n                layers += [conv2d, nn.ReLU()]\n            in_channels = out_channels\n    return nn.Sequential(*layers)\n\ndef stl10(n_channel, pretrained=None):\n    cfg = [\n        n_channel, 'M',\n        2*n_channel, 'M',\n        4*n_channel, 'M',\n        4*n_channel, 'M',\n        (8*n_channel, 0), (8*n_channel, 0), 'M'\n    ]\n    layers = make_layers(cfg, batch_norm=True)\n    model = SVHN(layers, n_channel=8*n_channel, num_classes=10)\n    if pretrained is not None:\n        m = model_zoo.load_url(model_urls['stl10'])\n        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n        assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n        model.load_state_dict(state_dict)\n    return model\n\n\n"""
stl10/train.py,7,"b'import argparse\nimport os\nimport time\nfrom utee import misc\n\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nimport dataset\nimport model\nfrom IPython import embed\n\nparser = argparse.ArgumentParser(description=\'PyTorch SVHN Example\')\nparser.add_argument(\'--channel\', type=int, default=32, help=\'first conv channel (default: 32)\')\nparser.add_argument(\'--wd\', type=float, default=0.00, help=\'weight decay\')\nparser.add_argument(\'--batch_size\', type=int, default=200, help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--epochs\', type=int, default=150, help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.001, help=\'learning rate (default: 1e-3)\')\nparser.add_argument(\'--gpu\', default=None, help=\'index of gpus to use\')\nparser.add_argument(\'--ngpu\', type=int, default=2, help=\'number of gpus to use\')\nparser.add_argument(\'--seed\', type=int, default=117, help=\'random seed (default: 1)\')\nparser.add_argument(\'--log_interval\', type=int, default=20,  help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--test_interval\', type=int, default=5,  help=\'how many epochs to wait before another test\')\nparser.add_argument(\'--logdir\', default=\'log/default\', help=\'folder to save to the log\')\nparser.add_argument(\'--decreasing_lr\', default=\'80,120\', help=\'decreasing strategy\')\nargs = parser.parse_args()\nargs.logdir = os.path.join(os.path.dirname(__file__), args.logdir)\nmisc.logger.init(args.logdir, \'train_log\')\nprint = misc.logger.info\n\n# select gpu\nargs.gpu = misc.auto_select_gpu(utility_bound=0, num_gpu=args.ngpu, selected_gpus=args.gpu)\nargs.ngpu = len(args.gpu)\n\n# logger\nmisc.ensure_dir(args.logdir)\nprint(""=================FLAGS=================="")\nfor k, v in args.__dict__.items():\n    print(\'{}: {}\'.format(k, v))\nprint(""========================================"")\n\n# seed\nargs.cuda = torch.cuda.is_available()\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# data loader and model\ntrain_loader, test_loader = dataset.get(batch_size=args.batch_size, num_workers=1)\nmodel = model.stl10(n_channel=args.channel)\nmodel = torch.nn.DataParallel(model, device_ids= range(args.ngpu))\nif args.cuda:\n    model.cuda()\n\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\ndecreasing_lr = list(map(int, args.decreasing_lr.split(\',\')))\nprint(\'decreasing_lr: \' + str(decreasing_lr))\nbest_acc, old_file = 0, None\nt_begin = time.time()\ntry:\n    # ready to go\n    for epoch in range(args.epochs):\n        model.train()\n        if epoch in decreasing_lr:\n            optimizer.param_groups[0][\'lr\'] *= 0.1\n        for batch_idx, (data, target) in enumerate(train_loader):\n            indx_target = target.clone()\n            if args.cuda:\n                data, target = data.cuda(), target.cuda()\n            data, target = Variable(data), Variable(target)\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.cross_entropy(output, target)\n            loss.backward()\n            optimizer.step()\n\n            if batch_idx % args.log_interval == 0 and batch_idx > 0:\n                pred = output.data.max(1)[1]  # get the index of the max log-probability\n                correct = pred.cpu().eq(indx_target).sum()\n                acc = correct * 1.0 / len(data)\n                print(\'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f} lr: {:.2e}\'.format(\n                    epoch, batch_idx * len(data), len(train_loader.dataset),\n                    loss.data[0], acc, optimizer.param_groups[0][\'lr\']))\n\n        elapse_time = time.time() - t_begin\n        speed_epoch = elapse_time / (epoch + 1)\n        speed_batch = speed_epoch / len(train_loader)\n        eta = speed_epoch * args.epochs - elapse_time\n        print(""Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s"".format(\n            elapse_time, speed_epoch, speed_batch, eta))\n        misc.model_snapshot(model, os.path.join(args.logdir, \'latest.pth\'))\n\n        if epoch % args.test_interval == 0:\n            model.eval()\n            test_loss = 0\n            correct = 0\n            for data, target in test_loader:\n                indx_target = target.clone()\n                if args.cuda:\n                    data, target = data.cuda(), target.cuda().long().squeeze()\n                data, target = Variable(data, volatile=True), Variable(target)\n                output = model(data)\n                test_loss += F.cross_entropy(output, target).data[0]\n                pred = output.data.max(1)[1]  # get the index of the max log-probability\n                correct += pred.cpu().eq(indx_target).sum()\n\n            test_loss = test_loss / len(test_loader) # average over number of mini-batch\n            acc = 100. * correct / len(test_loader.dataset)\n            print(\'\\tTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\'.format(\n                test_loss, correct, len(test_loader.dataset), acc))\n            if acc > best_acc:\n                new_file = os.path.join(args.logdir, \'best-{}.pth\'.format(epoch))\n                misc.model_snapshot(model, new_file, old_file=old_file, verbose=True)\n                best_acc = acc\n                old_file = new_file\nexcept Exception as e:\n    import traceback\n    traceback.print_exc()\nfinally:\n    print(""Total Elapse: {:.2f}, Best Result: {:.3f}%"".format(time.time()-t_begin, best_acc))\n\n\n'"
svhn/__init__.py,0,b''
svhn/dataset.py,3,"b'import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport os\n\ndef get(batch_size, data_root=\'/tmp/public_dataset/pytorch\', train=True, val=True, **kwargs):\n    data_root = os.path.expanduser(os.path.join(data_root, \'svhn-data\'))\n    num_workers = kwargs.setdefault(\'num_workers\', 1)\n    kwargs.pop(\'input_size\', None)\n    print(""Building SVHN data loader with {} workers"".format(num_workers))\n\n    def target_transform(target):\n        return int(target) - 1\n\n    ds = []\n    if train:\n        train_loader = torch.utils.data.DataLoader(\n            datasets.SVHN(\n                root=data_root, split=\'train\', download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                ]),\n                target_transform=target_transform,\n            ),\n            batch_size=batch_size, shuffle=True, **kwargs)\n        ds.append(train_loader)\n\n    if val:\n        test_loader = torch.utils.data.DataLoader(\n            datasets.SVHN(\n                root=data_root, split=\'test\', download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                ]),\n                target_transform=target_transform\n            ),\n            batch_size=batch_size, shuffle=False, **kwargs)\n        ds.append(test_loader)\n    ds = ds[0] if len(ds) == 1 else ds\n    return ds\n\n'"
svhn/model.py,2,"b""import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nfrom collections import OrderedDict\nfrom utee import misc\nprint = misc.logger.info\n\nmodel_urls = {\n    'svhn': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/svhn-f564f3d8.pth',\n}\n\nclass SVHN(nn.Module):\n    def __init__(self, features, n_channel, num_classes):\n        super(SVHN, self).__init__()\n        assert isinstance(features, nn.Sequential), type(features)\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(n_channel, num_classes)\n        )\n        print(self.features)\n        print(self.classifier)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for i, v in enumerate(cfg):\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            padding = v[1] if isinstance(v, tuple) else 1\n            out_channels = v[0] if isinstance(v, tuple) else v\n            conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(out_channels, affine=False), nn.ReLU(), nn.Dropout(0.3)]\n            else:\n                layers += [conv2d, nn.ReLU(), nn.Dropout(0.3)]\n            in_channels = out_channels\n    return nn.Sequential(*layers)\n\ndef svhn(n_channel, pretrained=None):\n    cfg = [n_channel, n_channel, 'M', 2*n_channel, 2*n_channel, 'M', 4*n_channel, 4*n_channel, 'M', (8*n_channel, 0), 'M']\n    layers = make_layers(cfg, batch_norm=True)\n    model = SVHN(layers, n_channel=8*n_channel, num_classes=10)\n    if pretrained is not None:\n        m = model_zoo.load_url(model_urls['svhn'])\n        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n        assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n        model.load_state_dict(state_dict)\n    return model\n\n\n"""
svhn/train.py,7,"b'import argparse\nimport os\nimport time\n\nfrom utee import misc\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nimport dataset\nimport model\nfrom IPython import embed\n\nparser = argparse.ArgumentParser(description=\'PyTorch SVHN Example\')\nparser.add_argument(\'--channel\', type=int, default=32, help=\'first conv channel (default: 32)\')\nparser.add_argument(\'--wd\', type=float, default=0.001, help=\'weight decay\')\nparser.add_argument(\'--batch_size\', type=int, default=200, help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--epochs\', type=int, default=150, help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.001, help=\'learning rate (default: 1e-3)\')\nparser.add_argument(\'--gpu\', default=None, help=\'index of gpus to use\')\nparser.add_argument(\'--ngpu\', type=int, default=2, help=\'number of gpus to use\')\nparser.add_argument(\'--seed\', type=int, default=117, help=\'random seed (default: 1)\')\nparser.add_argument(\'--log_interval\', type=int, default=100,  help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--test_interval\', type=int, default=5,  help=\'how many epochs to wait before another test\')\nparser.add_argument(\'--logdir\', default=\'log/default\', help=\'folder to save to the log\')\nparser.add_argument(\'--data_root\', default=\'/tmp/public_dataset/pytorch/\', help=\'folder to save the model\')\nparser.add_argument(\'--decreasing_lr\', default=\'80,120\', help=\'decreasing strategy\')\nargs = parser.parse_args()\nargs.logdir = os.path.join(os.path.dirname(__file__), args.logdir)\nmisc.logger.init(args.logdir, \'train_log\')\nprint = misc.logger.info\n\n# select gpu\nargs.gpu = misc.auto_select_gpu(utility_bound=0, num_gpu=args.ngpu, selected_gpus=args.gpu)\nargs.ngpu = len(args.gpu)\n\n# logger\nmisc.ensure_dir(args.logdir)\nprint(""=================FLAGS=================="")\nfor k, v in args.__dict__.items():\n    print(\'{}: {}\'.format(k, v))\nprint(""========================================"")\n\n# seed\nargs.cuda = torch.cuda.is_available()\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# data loader and model\ntrain_loader, test_loader = dataset.get(batch_size=args.batch_size, data_root=args.data_root, num_workers=1)\nmodel = model.svhn(n_channel=args.channel)\nmodel = torch.nn.DataParallel(model, device_ids= range(args.ngpu))\nif args.cuda:\n    model.cuda()\n\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\ndecreasing_lr = list(map(int, args.decreasing_lr.split(\',\')))\nprint(\'decreasing_lr: \' + str(decreasing_lr))\nbest_acc, old_file = 0, None\nt_begin = time.time()\ntry:\n    for epoch in range(args.epochs):\n        model.train()\n        if epoch in decreasing_lr:\n            optimizer.param_groups[0][\'lr\'] *= 0.1\n        for batch_idx, (data, target) in enumerate(train_loader):\n            indx_target = target.clone()\n            if args.cuda:\n                data, target = data.cuda(), target.cuda()\n            data, target = Variable(data), Variable(target)\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.cross_entropy(output, target)\n            loss.backward()\n            optimizer.step()\n\n            if batch_idx % args.log_interval == 0 and batch_idx > 0:\n                pred = output.data.max(1)[1]  # get the index of the max log-probability\n                correct = pred.cpu().eq(indx_target).sum()\n                acc = correct * 1.0 / len(data)\n                print(\'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f} lr: {:.2e}\'.format(\n                    epoch, batch_idx * len(data), len(train_loader.dataset),\n                    loss.data[0], acc, optimizer.param_groups[0][\'lr\']))\n\n        elapse_time = time.time() - t_begin\n        speed_epoch = elapse_time / (epoch + 1)\n        speed_batch = speed_epoch / len(train_loader)\n        eta = speed_epoch * args.epochs - elapse_time\n        print(""Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s"".format(\n            elapse_time, speed_epoch, speed_batch, eta))\n        misc.model_snapshot(model, os.path.join(args.logdir, \'latest.pth\'))\n\n        if epoch % args.test_interval == 0:\n            model.eval()\n            test_loss = 0\n            correct = 0\n            for data, target in test_loader:\n                indx_target = target.clone()\n                if args.cuda:\n                    data, target = data.cuda(), target.cuda().long().squeeze()\n                data, target = Variable(data, volatile=True), Variable(target)\n                output = model(data)\n                test_loss += F.cross_entropy(output, target).data[0]\n                pred = output.data.max(1)[1]  # get the index of the max log-probability\n                correct += pred.cpu().eq(indx_target).sum()\n\n            test_loss = test_loss / len(test_loader) # average over number of mini-batch\n            acc = 100. * correct / len(test_loader.dataset)\n            print(\'\\tTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\'.format(\n                test_loss, correct, len(test_loader.dataset), acc))\n            if acc > best_acc:\n                new_file = os.path.join(args.logdir, \'best-{}.pth\'.format(epoch))\n                misc.model_snapshot(model, new_file, old_file=old_file, verbose=True)\n                best_acc = acc\n                old_file = new_file\nexcept Exception as e:\n    import traceback\n    traceback.print_exc()\nfinally:\n    print(""Total Elapse: {:.2f}, Best Result: {:.3f}%"".format(time.time()-t_begin, best_acc))\n\n\n'"
utee/__init__.py,0,b''
utee/misc.py,7,"b'import cv2\nimport os\nimport shutil\nimport pickle as pkl\nimport time\nimport numpy as np\nimport hashlib\n\nfrom IPython import embed\n\nclass Logger(object):\n    def __init__(self):\n        self._logger = None\n\n    def init(self, logdir, name=\'log\'):\n        if self._logger is None:\n            import logging\n            if not os.path.exists(logdir):\n                os.makedirs(logdir)\n            log_file = os.path.join(logdir, name)\n            if os.path.exists(log_file):\n                os.remove(log_file)\n            self._logger = logging.getLogger()\n            self._logger.setLevel(\'INFO\')\n            fh = logging.FileHandler(log_file)\n            ch = logging.StreamHandler()\n            self._logger.addHandler(fh)\n            self._logger.addHandler(ch)\n\n    def info(self, str_info):\n        self.init(\'/tmp\', \'tmp.log\')\n        self._logger.info(str_info)\nlogger = Logger()\n\nprint = logger.info\ndef ensure_dir(path, erase=False):\n    if os.path.exists(path) and erase:\n        print(""Removing old folder {}"".format(path))\n        shutil.rmtree(path)\n    if not os.path.exists(path):\n        print(""Creating folder {}"".format(path))\n        os.makedirs(path)\n\ndef load_pickle(path):\n    begin_st = time.time()\n    with open(path, \'rb\') as f:\n        print(""Loading pickle object from {}"".format(path))\n        v = pkl.load(f)\n    print(""=> Done ({:.4f} s)"".format(time.time() - begin_st))\n    return v\n\ndef dump_pickle(obj, path):\n    with open(path, \'wb\') as f:\n        print(""Dumping pickle object to {}"".format(path))\n        pkl.dump(obj, f, protocol=pkl.HIGHEST_PROTOCOL)\n\ndef auto_select_gpu(mem_bound=500, utility_bound=0, gpus=(0, 1, 2, 3, 4, 5, 6, 7), num_gpu=1, selected_gpus=None):\n    import sys\n    import os\n    import subprocess\n    import re\n    import time\n    import numpy as np\n    if \'CUDA_VISIBLE_DEVCIES\' in os.environ:\n        sys.exit(0)\n    if selected_gpus is None:\n        mem_trace = []\n        utility_trace = []\n        for i in range(5): # sample 5 times\n            info = subprocess.check_output(\'nvidia-smi\', shell=True).decode(\'utf-8\')\n            mem = [int(s[:-5]) for s in re.compile(\'\\d+MiB\\s/\').findall(info)]\n            utility = [int(re.compile(\'\\d+\').findall(s)[0]) for s in re.compile(\'\\d+%\\s+Default\').findall(info)]\n            mem_trace.append(mem)\n            utility_trace.append(utility)\n            time.sleep(0.1)\n        mem = np.mean(mem_trace, axis=0)\n        utility = np.mean(utility_trace, axis=0)\n        assert(len(mem) == len(utility))\n        nGPU = len(utility)\n        ideal_gpus = [i for i in range(nGPU) if mem[i] <= mem_bound and utility[i] <= utility_bound and i in gpus]\n\n        if len(ideal_gpus) < num_gpu:\n            print(""No sufficient resource, available: {}, require {} gpu"".format(ideal_gpus, num_gpu))\n            sys.exit(0)\n        else:\n            selected_gpus = list(map(str, ideal_gpus[:num_gpu]))\n    else:\n        selected_gpus = selected_gpus.split(\',\')\n\n    print(""Setting GPU: {}"".format(selected_gpus))\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = \',\'.join(selected_gpus)\n    return selected_gpus\n\ndef expand_user(path):\n    return os.path.abspath(os.path.expanduser(path))\n\ndef model_snapshot(model, new_file, old_file=None, verbose=False):\n    from collections import OrderedDict\n    import torch\n    if isinstance(model, torch.nn.DataParallel):\n        model = model.module\n    if old_file and os.path.exists(expand_user(old_file)):\n        if verbose:\n            print(""Removing old model {}"".format(expand_user(old_file)))\n        os.remove(expand_user(old_file))\n    if verbose:\n        print(""Saving model to {}"".format(expand_user(new_file)))\n\n    state_dict = OrderedDict()\n    for k, v in model.state_dict().items():\n        if v.is_cuda:\n            v = v.cpu()\n        state_dict[k] = v\n    torch.save(state_dict, expand_user(new_file))\n\n\ndef load_lmdb(lmdb_file, n_records=None):\n    import lmdb\n    import numpy as np\n    lmdb_file = expand_user(lmdb_file)\n    if os.path.exists(lmdb_file):\n        data = []\n        env = lmdb.open(lmdb_file, readonly=True, max_readers=512)\n        with env.begin() as txn:\n            cursor = txn.cursor()\n            begin_st = time.time()\n            print(""Loading lmdb file {} into memory"".format(lmdb_file))\n            for key, value in cursor:\n                _, target, _ = key.decode(\'ascii\').split(\':\')\n                target = int(target)\n                img = cv2.imdecode(np.fromstring(value, np.uint8), cv2.IMREAD_COLOR)\n                data.append((img, target))\n                if n_records is not None and len(data) >= n_records:\n                    break\n        env.close()\n        print(""=> Done ({:.4f} s)"".format(time.time() - begin_st))\n        return data\n    else:\n        print(""Not found lmdb file"".format(lmdb_file))\n\ndef str2img(str_b):\n    return cv2.imdecode(np.fromstring(str_b, np.uint8), cv2.IMREAD_COLOR)\n\ndef img2str(img):\n    return cv2.imencode(\'.jpg\', img)[1].tostring()\n\ndef md5(s):\n    m = hashlib.md5()\n    m.update(s)\n    return m.hexdigest()\n\ndef eval_model(model, ds, n_sample=None, ngpu=1, is_imagenet=False):\n    import tqdm\n    import torch\n    from torch import nn\n    from torch.autograd import Variable\n\n    class ModelWrapper(nn.Module):\n        def __init__(self, model):\n            super(ModelWrapper, self).__init__()\n            self.model = model\n            self.mean = [0.485, 0.456, 0.406]\n            self.std = [0.229, 0.224, 0.225]\n\n        def forward(self, input):\n            input.data.div_(255.)\n            input.data[:, 0, :, :].sub_(self.mean[0]).div_(self.std[0])\n            input.data[:, 1, :, :].sub_(self.mean[1]).div_(self.std[1])\n            input.data[:, 2, :, :].sub_(self.mean[2]).div_(self.std[2])\n            return self.model(input)\n\n    correct1, correct5 = 0, 0\n    n_passed = 0\n    if is_imagenet:\n        model = ModelWrapper(model)\n    model = model.eval()\n    model = torch.nn.DataParallel(model, device_ids=range(ngpu)).cuda()\n\n    n_sample = len(ds) if n_sample is None else n_sample\n    for idx, (data, target) in enumerate(tqdm.tqdm(ds, total=n_sample)):\n        n_passed += len(data)\n        data =  Variable(torch.FloatTensor(data)).cuda()\n        indx_target = torch.LongTensor(target)\n        output = model(data)\n        bs = output.size(0)\n        idx_pred = output.data.sort(1, descending=True)[1]\n\n        idx_gt1 = indx_target.expand(1, bs).transpose_(0, 1)\n        idx_gt5 = idx_gt1.expand(bs, 5)\n\n        correct1 += idx_pred[:, :1].cpu().eq(idx_gt1).sum()\n        correct5 += idx_pred[:, :5].cpu().eq(idx_gt5).sum()\n\n        if idx >= n_sample - 1:\n            break\n\n    acc1 = correct1 * 1.0 / n_passed\n    acc5 = correct5 * 1.0 / n_passed\n    return acc1, acc5\n\ndef load_state_dict(model, model_urls, model_root):\n    from torch.utils import model_zoo\n    from torch import nn\n    import re\n    from collections import OrderedDict\n    own_state_old = model.state_dict()\n    own_state = OrderedDict() # remove all \'group\' string\n    for k, v in own_state_old.items():\n        k = re.sub(\'group\\d+\\.\', \'\', k)\n        own_state[k] = v\n\n    state_dict = model_zoo.load_url(model_urls, model_root)\n\n    for name, param in state_dict.items():\n        if name not in own_state:\n            print(own_state.keys())\n            raise KeyError(\'unexpected key ""{}"" in state_dict\'\n                           .format(name))\n        if isinstance(param, nn.Parameter):\n            # backwards compatibility for serialized parameters\n            param = param.data\n        own_state[name].copy_(param)\n\n    missing = set(own_state.keys()) - set(state_dict.keys())\n    no_use = set(state_dict.keys()) - set(own_state.keys())\n    if len(no_use) > 0:\n        raise KeyError(\'some keys are not used: ""{}""\'.format(no_use))\n\n'"
utee/quant.py,19,"b'from torch.autograd import Variable\nimport torch\nfrom torch import nn\nfrom collections import OrderedDict\nimport math\nfrom IPython import embed\n\ndef compute_integral_part(input, overflow_rate):\n    abs_value = input.abs().view(-1)\n    sorted_value = abs_value.sort(dim=0, descending=True)[0]\n    split_idx = int(overflow_rate * len(sorted_value))\n    v = sorted_value[split_idx]\n    if isinstance(v, Variable):\n        v = float(v.data.cpu())\n    sf = math.ceil(math.log2(v+1e-12))\n    return sf\n\ndef linear_quantize(input, sf, bits):\n    assert bits >= 1, bits\n    if bits == 1:\n        return torch.sign(input) - 1\n    delta = math.pow(2.0, -sf)\n    bound = math.pow(2.0, bits-1)\n    min_val = - bound\n    max_val = bound - 1\n    rounded = torch.floor(input / delta + 0.5)\n\n    clipped_value = torch.clamp(rounded, min_val, max_val) * delta\n    return clipped_value\n\ndef log_minmax_quantize(input, bits):\n    assert bits >= 1, bits\n    if bits == 1:\n        return torch.sign(input), 0.0, 0.0\n\n    s = torch.sign(input)\n    input0 = torch.log(torch.abs(input) + 1e-20)\n    v = min_max_quantize(input0, bits-1)\n    v = torch.exp(v) * s\n    return v\n\ndef log_linear_quantize(input, sf, bits):\n    assert bits >= 1, bits\n    if bits == 1:\n        return torch.sign(input), 0.0, 0.0\n\n    s = torch.sign(input)\n    input0 = torch.log(torch.abs(input) + 1e-20)\n    v = linear_quantize(input0, sf, bits-1)\n    v = torch.exp(v) * s\n    return v\n\ndef min_max_quantize(input, bits):\n    assert bits >= 1, bits\n    if bits == 1:\n        return torch.sign(input) - 1\n    min_val, max_val = input.min(), input.max()\n\n    if isinstance(min_val, Variable):\n        max_val = float(max_val.data.cpu().numpy()[0])\n        min_val = float(min_val.data.cpu().numpy()[0])\n\n    input_rescale = (input - min_val) / (max_val - min_val)\n\n    n = math.pow(2.0, bits) - 1\n    v = torch.floor(input_rescale * n + 0.5) / n\n\n    v =  v * (max_val - min_val) + min_val\n    return v\n\ndef tanh_quantize(input, bits):\n    assert bits >= 1, bits\n    if bits == 1:\n        return torch.sign(input)\n    input = torch.tanh(input) # [-1, 1]\n    input_rescale = (input + 1.0) / 2 #[0, 1]\n    n = math.pow(2.0, bits) - 1\n    v = torch.floor(input_rescale * n + 0.5) / n\n    v = 2 * v - 1 # [-1, 1]\n\n    v = 0.5 * torch.log((1 + v) / (1 - v)) # arctanh\n    return v\n\n\nclass LinearQuant(nn.Module):\n    def __init__(self, name, bits, sf=None, overflow_rate=0.0, counter=10):\n        super(LinearQuant, self).__init__()\n        self.name = name\n        self._counter = counter\n\n        self.bits = bits\n        self.sf = sf\n        self.overflow_rate = overflow_rate\n\n    @property\n    def counter(self):\n        return self._counter\n\n    def forward(self, input):\n        if self._counter > 0:\n            self._counter -= 1\n            sf_new = self.bits - 1 - compute_integral_part(input, self.overflow_rate)\n            self.sf = min(self.sf, sf_new) if self.sf is not None else sf_new\n            return input\n        else:\n            output = linear_quantize(input, self.sf, self.bits)\n            return output\n\n    def __repr__(self):\n        return \'{}(sf={}, bits={}, overflow_rate={:.3f}, counter={})\'.format(\n            self.__class__.__name__, self.sf, self.bits, self.overflow_rate, self.counter)\n\nclass LogQuant(nn.Module):\n    def __init__(self, name, bits, sf=None, overflow_rate=0.0, counter=10):\n        super(LogQuant, self).__init__()\n        self.name = name\n        self._counter = counter\n\n        self.bits = bits\n        self.sf = sf\n        self.overflow_rate = overflow_rate\n\n    @property\n    def counter(self):\n        return self._counter\n\n    def forward(self, input):\n        if self._counter > 0:\n            self._counter -= 1\n            log_abs_input = torch.log(torch.abs(input))\n            sf_new = self.bits - 1 - compute_integral_part(log_abs_input, self.overflow_rate)\n            self.sf = min(self.sf, sf_new) if self.sf is not None else sf_new\n            return input\n        else:\n            output = log_linear_quantize(input, self.sf, self.bits)\n            return output\n\n    def __repr__(self):\n        return \'{}(sf={}, bits={}, overflow_rate={:.3f}, counter={})\'.format(\n            self.__class__.__name__, self.sf, self.bits, self.overflow_rate, self.counter)\n\nclass NormalQuant(nn.Module):\n    def __init__(self, name, bits, quant_func):\n        super(NormalQuant, self).__init__()\n        self.name = name\n        self.bits = bits\n        self.quant_func = quant_func\n\n    @property\n    def counter(self):\n        return self._counter\n\n    def forward(self, input):\n        output = self.quant_func(input, self.bits)\n        return output\n\n    def __repr__(self):\n        return \'{}(bits={})\'.format(self.__class__.__name__, self.bits)\n\ndef duplicate_model_with_quant(model, bits, overflow_rate=0.0, counter=10, type=\'linear\'):\n    """"""assume that original model has at least a nn.Sequential""""""\n    assert type in [\'linear\', \'minmax\', \'log\', \'tanh\']\n    if isinstance(model, nn.Sequential):\n        l = OrderedDict()\n        for k, v in model._modules.items():\n            if isinstance(v, (nn.Conv2d, nn.Linear, nn.BatchNorm1d, nn.BatchNorm2d, nn.AvgPool2d)):\n                l[k] = v\n                if type == \'linear\':\n                    quant_layer = LinearQuant(\'{}_quant\'.format(k), bits=bits, overflow_rate=overflow_rate, counter=counter)\n                elif type == \'log\':\n                    # quant_layer = LogQuant(\'{}_quant\'.format(k), bits=bits, overflow_rate=overflow_rate, counter=counter)\n                    quant_layer = NormalQuant(\'{}_quant\'.format(k), bits=bits, quant_func=log_minmax_quantize)\n                elif type == \'minmax\':\n                    quant_layer = NormalQuant(\'{}_quant\'.format(k), bits=bits, quant_func=min_max_quantize)\n                else:\n                    quant_layer = NormalQuant(\'{}_quant\'.format(k), bits=bits, quant_func=tanh_quantize)\n                l[\'{}_{}_quant\'.format(k, type)] = quant_layer\n            else:\n                l[k] = duplicate_model_with_quant(v, bits, overflow_rate, counter, type)\n        m = nn.Sequential(l)\n        return m\n    else:\n        for k, v in model._modules.items():\n            model._modules[k] = duplicate_model_with_quant(v, bits, overflow_rate, counter, type)\n        return model\n\n'"
utee/selector.py,0,"b'from utee import misc\nimport os\nfrom imagenet import dataset\nprint = misc.logger.info\nfrom IPython import embed\n\nknown_models = [\n    \'mnist\', \'svhn\', # 28x28\n    \'cifar10\', \'cifar100\', # 32x32\n    \'stl10\', # 96x96\n    \'alexnet\', # 224x224\n    \'vgg16\', \'vgg16_bn\', \'vgg19\', \'vgg19_bn\', # 224x224\n    \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\'resnet152\', # 224x224\n    \'squeezenet_v0\', \'squeezenet_v1\', #224x224\n    \'inception_v3\', # 299x299\n]\n\ndef mnist(cuda=True, model_root=None):\n    print(""Building and initializing mnist parameters"")\n    from mnist import model, dataset\n    m = model.mnist(pretrained=os.path.join(model_root, \'mnist.pth\'))\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, False\n\ndef svhn(cuda=True, model_root=None):\n    print(""Building and initializing svhn parameters"")\n    from svhn import model, dataset\n    m = model.svhn(32, pretrained=os.path.join(model_root, \'svhn.pth\'))\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, False\n\ndef cifar10(cuda=True, model_root=None):\n    print(""Building and initializing cifar10 parameters"")\n    from cifar import model, dataset\n    m = model.cifar10(128, pretrained=os.path.join(model_root, \'cifar10.pth\'))\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get10, False\n\ndef cifar100(cuda=True, model_root=None):\n    print(""Building and initializing cifar100 parameters"")\n    from cifar import model, dataset\n    m = model.cifar100(128, pretrained=os.path.join(model_root, \'cifar100.pth\'))\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get100, False\n\ndef stl10(cuda=True, model_root=None):\n    print(""Building and initializing stl10 parameters"")\n    from stl10 import model, dataset\n    m = model.stl10(32, pretrained=os.path.join(model_root, \'stl10.pth\'))\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, False\n\ndef alexnet(cuda=True, model_root=None):\n    print(""Building and initializing alexnet parameters"")\n    from imagenet import alexnet as alx\n    m = alx.alexnet(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef vgg16(cuda=True, model_root=None):\n    print(""Building and initializing vgg16 parameters"")\n    from imagenet import vgg\n    m = vgg.vgg16(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef vgg16_bn(cuda=True, model_root=None):\n    print(""Building vgg16_bn parameters"")\n    from imagenet import vgg\n    m = vgg.vgg16_bn(model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef vgg19(cuda=True, model_root=None):\n    print(""Building and initializing vgg19 parameters"")\n    from imagenet import vgg\n    m = vgg.vgg19(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef vgg19_bn(cuda=True, model_root=None):\n    print(""Building vgg19_bn parameters"")\n    from imagenet import vgg\n    m = vgg.vgg19_bn(model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef inception_v3(cuda=True, model_root=None):\n    print(""Building and initializing inception_v3 parameters"")\n    from imagenet import inception\n    m = inception.inception_v3(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef resnet18(cuda=True, model_root=None):\n    print(""Building and initializing resnet-18 parameters"")\n    from imagenet import resnet\n    m = resnet.resnet18(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef resnet34(cuda=True, model_root=None):\n    print(""Building and initializing resnet-34 parameters"")\n    from imagenet import resnet\n    m = resnet.resnet34(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef resnet50(cuda=True, model_root=None):\n    print(""Building and initializing resnet-50 parameters"")\n    from imagenet import resnet\n    m = resnet.resnet50(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef resnet101(cuda=True, model_root=None):\n    print(""Building and initializing resnet-101 parameters"")\n    from imagenet import resnet\n    m = resnet.resnet101(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef resnet152(cuda=True, model_root=None):\n    print(""Building and initializing resnet-152 parameters"")\n    from imagenet import resnet\n    m = resnet.resnet152(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef squeezenet_v0(cuda=True, model_root=None):\n    print(""Building and initializing squeezenet_v0 parameters"")\n    from imagenet import squeezenet\n    m = squeezenet.squeezenet1_0(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef squeezenet_v1(cuda=True, model_root=None):\n    print(""Building and initializing squeezenet_v1 parameters"")\n    from imagenet import squeezenet\n    m = squeezenet.squeezenet1_1(True, model_root)\n    if cuda:\n        m = m.cuda()\n    return m, dataset.get, True\n\ndef select(model_name, **kwargs):\n    assert model_name in known_models, model_name\n    kwargs.setdefault(\'model_root\', os.path.expanduser(\'~/.torch/models\'))\n    return eval(\'{}\'.format(model_name))(**kwargs)\n\nif __name__ == \'__main__\':\n    m1 = alexnet()\n    embed()\n\n\n'"
