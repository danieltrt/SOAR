file_path,api_count,code
clr_parameters_finder.py,8,"b'\'\'\'\nThis script allows to find the optimal parameters for a learning rate scheduling:\n\n- min_lr \n- max_lr \n\nWe vary the learning rate inside one or several epochs between start_lr and end_lr \n(given as arguments) and for each mini-batch, we note the value of the learning \nrate and the loss.\n\nThen we plot the loss versus the learning rate and save it to plots/\n\nThere\'s in general a downward trend first, a minimum and upward trend.\n\nOne heuristic to find the optimal parameters:\n\n- max_lr = argmin_lr(loss) / 10\n- mix_lr = max_lr / 10\n\n\nreference: https://towardsdatascience.com/adaptive-and-cyclical-learning-rates-using-pytorch-2bf904d18dee\n\n\'\'\'\n\nimport math\nimport os\nimport shutil\nimport json\nimport argparse\nimport time\nfrom datetime import datetime\nfrom collections import Counter\n\nfrom tqdm import tqdm\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nfrom sklearn.model_selection import train_test_split\n\nfrom src.data_loader import MyDataset, load_data\nfrom src import utils\nfrom src.model import CharacterLevelCNN\n\nfrom matplotlib import pyplot as plt\n\n\ndef run(args):\n\n    batch_size = args.batch_size\n\n    training_params = {""batch_size"": batch_size,\n                       ""shuffle"": True,\n                       ""num_workers"": args.workers}\n\n    texts, labels, number_of_classes, sample_weights = load_data(args)\n    train_texts, _, train_labels, _, _, _ = train_test_split(texts,\n                                                             labels,\n                                                             sample_weights,\n                                                             test_size=args.validation_split,\n                                                             random_state=42,\n                                                             stratify=labels)\n\n    training_set = MyDataset(train_texts, train_labels, args)\n    training_generator = DataLoader(training_set, **training_params)\n    model = CharacterLevelCNN(args, number_of_classes)\n\n    if torch.cuda.is_available():\n        model.cuda()\n\n    model.train()\n\n    criterion = nn.CrossEntropyLoss()\n\n    if args.optimizer == \'sgd\':\n        optimizer = torch.optim.SGD(\n            model.parameters(), lr=args.start_lr, momentum=0.9\n        )\n    elif args.optimizer == \'adam\':\n        optimizer = torch.optim.Adam(\n            model.parameters(), lr=args.start_lr\n        )\n\n    start_lr = args.start_lr\n    end_lr = args.end_lr\n    lr_find_epochs = args.epochs\n    smoothing = args.smoothing\n\n    def lr_lambda(x): return math.exp(\n        x * math.log(end_lr / start_lr) / (lr_find_epochs * len(training_generator)))\n    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n\n    losses = []\n    learning_rates = []\n\n    for epoch in range(lr_find_epochs):\n        print(f\'[epoch {epoch + 1} / {lr_find_epochs}]\')\n        progress_bar = tqdm(enumerate(training_generator),\n                            total=len(training_generator))\n        for iter, batch in progress_bar:\n            features, labels = batch\n            if torch.cuda.is_available():\n                features = features.cuda()\n                labels = labels.cuda()\n\n            optimizer.zero_grad()\n\n            predictions = model(features)\n            loss = criterion(predictions, labels)\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            lr = optimizer.state_dict()[""param_groups""][0][""lr""]\n            learning_rates.append(lr)\n\n            if iter == 0:\n                losses.append(loss.item())\n            else:\n                loss = smoothing * loss.item() + (1 - smoothing) * losses[-1]\n                losses.append(loss)\n\n    plt.semilogx(learning_rates, losses)\n    plt.savefig(\'./plots/losses_vs_lr.png\')\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(\n        \'Character Based CNN for text classification\')\n    parser.add_argument(\'--data_path\', type=str,\n                        default=\'./data/train.csv\')\n    parser.add_argument(\'--validation_split\', type=float, default=0.2)\n    parser.add_argument(\'--label_column\', type=str, default=\'Sentiment\')\n    parser.add_argument(\'--text_column\', type=str, default=\'SentimentText\')\n    parser.add_argument(\'--max_rows\', type=int, default=None)\n    parser.add_argument(\'--chunksize\', type=int, default=50000)\n    parser.add_argument(\'--encoding\', type=str, default=\'utf-8\')\n    parser.add_argument(\'--sep\', type=str, default=\',\')\n    parser.add_argument(\'--steps\', nargs=\'+\', default=[\'lower\'])\n    parser.add_argument(\'--group_labels\', type=str,\n                        default=None, choices=[None, \'binarize\'])\n    parser.add_argument(\'--ratio\', type=float, default=1)\n\n    parser.add_argument(\'--alphabet\', type=str,\n                        default=\'abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:\\\'""\\\\/|_@#$%^&*~`+-=<>()[]{}\')\n    parser.add_argument(\'--number_of_characters\', type=int, default=69)\n    parser.add_argument(\'--extra_characters\', type=str, default=\'\')\n    parser.add_argument(\'--max_length\', type=int, default=150)\n    parser.add_argument(\'--batch_size\', type=int, default=128)\n    parser.add_argument(\'--optimizer\', type=str,\n                        choices=[\'adam\', \'sgd\'], default=\'sgd\')\n    parser.add_argument(\'--learning_rate\', type=float, default=0.01)\n    parser.add_argument(\'--workers\', type=int, default=1)\n\n    parser.add_argument(\'--start_lr\', type=float, default=1e-5)\n    parser.add_argument(\'--end_lr\', type=float, default=1e-2)\n    parser.add_argument(\'--smoothing\', type=float, default=0.05)\n    parser.add_argument(\'--epochs\', type=int, default=1)\n\n    args = parser.parse_args()\n    run(args)\n'"
predict.py,4,"b'import argparse\nimport torch\nimport torch.nn.functional as F\nfrom src.model import CharacterLevelCNN\nfrom src import utils\n\nuse_cuda = torch.cuda.is_available()\n\ndef predict(args):\n    model = CharacterLevelCNN(args, args.number_of_classes)\n    state = torch.load(args.model)\n    model.load_state_dict(state)\n    model.eval()\n    \n    processed_input = utils.preprocess_input(args)\n    processed_input = torch.tensor(processed_input)\n    processed_input = processed_input.unsqueeze(0)\n    if use_cuda:\n        processed_input = processed_input.to(\'cuda\')\n        model = model.to(\'cuda\')\n    prediction = model(processed_input)\n    probabilities = F.softmax(prediction, dim=1)\n    probabilities = probabilities.detach().cpu().numpy()\n    return probabilities\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(\n        \'Testing a pretrained Character Based CNN for text classification\')\n    parser.add_argument(\'--model\', type=str, help=\'path for pre-trained model\')\n    parser.add_argument(\'--text\', type=str,\n                        default=\'I love pizza!\', help=\'text string\')\n    parser.add_argument(\'--steps\', nargs=""+"", default=[\'lower\'])\n\n    # arguments needed for the predicition\n    parser.add_argument(\'--alphabet\', type=str,\n                        default=""abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:\'\\""/\\\\|_@#$%^&*~`+ =<>()[]{}"")\n    parser.add_argument(\'--number_of_characters\', type=int, default=69)\n    parser.add_argument(\'--extra_characters\', type=str, default=""\xc3\xa9\xc3\xa0\xc3\xa8\xc3\xb9\xc3\xa2\xc3\xaa\xc3\xae\xc3\xb4\xc3\xbb\xc3\xa7\xc3\xab\xc3\xaf\xc3\xbc"")\n    parser.add_argument(\'--max_length\', type=int, default=300)\n    parser.add_argument(\'--number_of_classes\', type=int, default=2)\n\n    args = parser.parse_args()\n    prediction = predict(args)\n    \n    print(\'input : {}\'.format(args.text))\n    print(\'prediction : {}\'.format(prediction))\n'"
train.py,18,"b'import os\nimport shutil\nimport json\nimport argparse\nimport time\nfrom datetime import datetime\nfrom collections import Counter\n\nfrom tqdm import tqdm\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom tensorboardX import SummaryWriter\n\nfrom sklearn.metrics import classification_report, f1_score\nfrom sklearn.model_selection import train_test_split\n\nfrom src.data_loader import MyDataset, load_data\nfrom src import utils\nfrom src.model import CharacterLevelCNN\nfrom src.focal_loss import FocalLoss\n\n\ndef train(model, training_generator, optimizer, criterion, epoch, writer, log_file, scheduler, class_names, args, print_every=25):\n    model.train()\n    losses = utils.AverageMeter()\n    accuracies = utils.AverageMeter()\n    num_iter_per_epoch = len(training_generator)\n\n    progress_bar = tqdm(enumerate(training_generator),\n                        total=num_iter_per_epoch)\n\n    y_true = []\n    y_pred = []\n\n    for iter, batch in progress_bar:\n        features, labels = batch\n        if torch.cuda.is_available():\n            features = features.cuda()\n            labels = labels.cuda()\n\n        optimizer.zero_grad()\n        predictions = model(features)\n\n        y_true += labels.cpu().numpy().tolist()\n        y_pred += torch.max(predictions, 1)[1].cpu().numpy().tolist()\n\n        loss = criterion(predictions, labels)\n\n        loss.backward()\n        if args.scheduler == \'clr\':\n            scheduler.step()\n\n        optimizer.step()\n        training_metrics = utils.get_evaluation(labels.cpu().numpy(),\n                                                predictions.cpu().detach().numpy(),\n                                                list_metrics=[""accuracy"", ""f1""])\n\n        losses.update(loss.data, features.size(0))\n        accuracies.update(training_metrics[""accuracy""], features.size(0))\n\n        f1 = training_metrics[\'f1\']\n\n        writer.add_scalar(\'Train/Loss\',\n                          loss.item(),\n                          epoch * num_iter_per_epoch + iter)\n\n        writer.add_scalar(\'Train/Accuracy\',\n                          training_metrics[\'accuracy\'],\n                          epoch * num_iter_per_epoch + iter)\n\n        writer.add_scalar(\'Train/f1\',\n                          f1,\n                          epoch * num_iter_per_epoch + iter)\n\n        lr = optimizer.state_dict()[""param_groups""][0][""lr""]\n\n        if (iter % print_every == 0) and (iter > 0):\n            print(""[Training - Epoch: {}], LR: {} , Iteration: {}/{} , Loss: {}, Accuracy: {}"".format(\n                epoch + 1,\n                lr,\n                iter,\n                num_iter_per_epoch,\n                losses.avg,\n                accuracies.avg\n            ))\n\n            if bool(args.log_f1):\n                intermediate_report = classification_report(\n                    y_true, y_pred, output_dict=True)\n\n                f1_by_class = \'F1 Scores by class: \'\n                for class_name in class_names:\n                    f1_by_class += f""{class_name} : {np.round(intermediate_report[class_name][\'f1-score\'], 4)} |""\n\n                print(f1_by_class)\n\n    f1_train = f1_score(y_true, y_pred, average=\'weighted\')\n\n    writer.add_scalar(\'Train/loss/epoch\', losses.avg, epoch + iter)\n    writer.add_scalar(\'Train/acc/epoch\', accuracies.avg, epoch + iter)\n    writer.add_scalar(\'Train/f1/epoch\', f1_train, epoch + iter)\n\n    report = classification_report(y_true, y_pred)\n    print(report)\n\n    with open(log_file, \'a\') as f:\n        f.write(f\'Training on Epoch {epoch} \\n\')\n        f.write(f\'Average loss: {losses.avg.item()} \\n\')\n        f.write(f\'Average accuracy: {accuracies.avg.item()} \\n\')\n        f.write(f\'F1 score: {f1_train} \\n\\n\')\n        f.write(report)\n        f.write(\'*\' * 25)\n        f.write(\'\\n\')\n\n    return losses.avg.item(), accuracies.avg.item(), f1_train\n\n\ndef evaluate(model, validation_generator, criterion, epoch, writer, log_file, print_every=25):\n    model.eval()\n    losses = utils.AverageMeter()\n    accuracies = utils.AverageMeter()\n    num_iter_per_epoch = len(validation_generator)\n\n    y_true = []\n    y_pred = []\n\n    for iter, batch in tqdm(enumerate(validation_generator), total=num_iter_per_epoch):\n        features, labels = batch\n        if torch.cuda.is_available():\n            features = features.cuda()\n            labels = labels.cuda()\n        with torch.no_grad():\n            predictions = model(features)\n        loss = criterion(predictions, labels)\n\n        y_true += labels.cpu().numpy().tolist()\n        y_pred += torch.max(predictions, 1)[1].cpu().numpy().tolist()\n\n        validation_metrics = utils.get_evaluation(labels.cpu().numpy(),\n                                                  predictions.cpu().detach().numpy(),\n                                                  list_metrics=[""accuracy"", ""f1""])\n        accuracy = validation_metrics[\'accuracy\']\n        f1 = validation_metrics[\'f1\']\n\n        losses.update(loss.data, features.size(0))\n        accuracies.update(validation_metrics[""accuracy""], features.size(0))\n\n        writer.add_scalar(\'Test/Loss\',\n                          loss.item(),\n                          epoch * num_iter_per_epoch + iter)\n\n        writer.add_scalar(\'Test/Accuracy\',\n                          accuracy,\n                          epoch * num_iter_per_epoch + iter)\n\n        writer.add_scalar(\'Test/f1\',\n                          f1,\n                          epoch * num_iter_per_epoch + iter)\n\n        if (iter % print_every == 0) and (iter > 0):\n            print(""[Validation - Epoch: {}] , Iteration: {}/{} , Loss: {}, Accuracy: {}"".format(\n                epoch + 1,\n                iter,\n                num_iter_per_epoch,\n                losses.avg,\n                accuracies.avg\n            ))\n\n    f1_test = f1_score(y_true, y_pred, average=\'weighted\')\n\n    writer.add_scalar(\'Test/loss/epoch\', losses.avg, epoch + iter)\n    writer.add_scalar(\'Test/acc/epoch\', accuracies.avg, epoch + iter)\n    writer.add_scalar(\'Test/f1/epoch\', f1_test, epoch + iter)\n\n    report = classification_report(y_true, y_pred)\n    print(report)\n\n    with open(log_file, \'a\') as f:\n        f.write(f\'Validation on Epoch {epoch} \\n\')\n        f.write(f\'Average loss: {losses.avg.item()} \\n\')\n        f.write(f\'Average accuracy: {accuracies.avg.item()} \\n\')\n        f.write(f\'F1 score {f1_test} \\n\\n\')\n        f.write(report)\n        f.write(\'=\' * 50)\n        f.write(\'\\n\')\n\n    return losses.avg.item(), accuracies.avg.item(), f1_test\n\n\ndef run(args, both_cases=False):\n\n    if args.flush_history == 1:\n        objects = os.listdir(args.log_path)\n        for f in objects:\n            if os.path.isdir(args.log_path + f):\n                shutil.rmtree(args.log_path + f)\n\n    now = datetime.now()\n    logdir = args.log_path + now.strftime(""%Y%m%d-%H%M%S"") + ""/""\n    os.makedirs(logdir)\n    log_file = logdir + \'log.txt\'\n    writer = SummaryWriter(logdir)\n\n    batch_size = args.batch_size\n\n    training_params = {""batch_size"": batch_size,\n                       ""shuffle"": True,\n                       ""num_workers"": args.workers,\n                       ""drop_last"": True}\n\n    validation_params = {""batch_size"": batch_size,\n                         ""shuffle"": False,\n                         ""num_workers"": args.workers,\n                         ""drop_last"": True}\n\n    texts, labels, number_of_classes, sample_weights = load_data(args)\n\n    class_names = sorted(list(set(labels)))\n    class_names = [str(class_name) for class_name in class_names]\n\n    train_texts, val_texts, train_labels, val_labels, train_sample_weights, _ = train_test_split(texts,\n                                                                                                 labels,\n                                                                                                 sample_weights,\n                                                                                                 test_size=args.validation_split,\n                                                                                                 random_state=42,\n                                                                                                 stratify=labels)\n    training_set = MyDataset(train_texts, train_labels, args)\n    validation_set = MyDataset(val_texts, val_labels, args)\n\n    if bool(args.use_sampler):\n        train_sample_weights = torch.from_numpy(train_sample_weights)\n        sampler = WeightedRandomSampler(train_sample_weights.type(\n            \'torch.DoubleTensor\'), len(train_sample_weights))\n        training_params[\'sampler\'] = sampler\n        training_params[\'shuffle\'] = False\n\n    training_generator = DataLoader(training_set, **training_params)\n    validation_generator = DataLoader(validation_set, **validation_params)\n\n    model = CharacterLevelCNN(args, number_of_classes)\n    if torch.cuda.is_available():\n        model.cuda()\n\n    if not bool(args.focal_loss):\n        if bool(args.class_weights):\n            class_counts = dict(Counter(train_labels))\n            m = max(class_counts.values())\n            for c in class_counts:\n                class_counts[c] = m / class_counts[c]\n            weights = []\n            for k in sorted(class_counts.keys()):\n                weights.append(class_counts[k])\n\n            weights = torch.Tensor(weights)\n            if torch.cuda.is_available():\n                weights = weights.cuda()\n                print(f\'passing weights to CrossEntropyLoss : {weights}\')\n                criterion = nn.CrossEntropyLoss(weight=weights)\n        else:\n            criterion = nn.CrossEntropyLoss()\n\n    else:\n        if args.alpha is None:\n            criterion = FocalLoss(gamma=args.gamma, alpha=None)\n        else:\n            criterion = FocalLoss(gamma=args.gamma,\n                                  alpha=[args.alpha] * number_of_classes)\n\n    if args.optimizer == \'sgd\':\n        if args.scheduler == \'clr\':\n            optimizer = torch.optim.SGD(\n                model.parameters(), lr=1, momentum=0.9, weight_decay=0.00001\n            )\n        else:\n            optimizer = torch.optim.SGD(\n                model.parameters(), lr=args.learning_rate, momentum=0.9\n            )\n    elif args.optimizer == \'adam\':\n        optimizer = torch.optim.Adam(\n            model.parameters(), lr=args.learning_rate\n        )\n\n    best_f1 = 0\n    best_epoch = 0\n\n    if args.scheduler == \'clr\':\n        stepsize = int(args.stepsize * len(training_generator))\n        clr = utils.cyclical_lr(stepsize, args.min_lr, args.max_lr)\n        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])\n    else:\n        scheduler = None\n\n    for epoch in range(args.epochs):\n        training_loss, training_accuracy, train_f1 = train(model,\n                                                           training_generator,\n                                                           optimizer,\n                                                           criterion,\n                                                           epoch,\n                                                           writer,\n                                                           log_file,\n                                                           scheduler,\n                                                           class_names,\n                                                           args,\n                                                           args.log_every)\n\n        validation_loss, validation_accuracy, validation_f1 = evaluate(model,\n                                                                       validation_generator,\n                                                                       criterion,\n                                                                       epoch,\n                                                                       writer,\n                                                                       log_file,\n                                                                       args.log_every)\n\n        print(\'[Epoch: {} / {}]\\ttrain_loss: {:.4f} \\ttrain_acc: {:.4f} \\tval_loss: {:.4f} \\tval_acc: {:.4f}\'.\n              format(epoch + 1, args.epochs, training_loss, training_accuracy, validation_loss, validation_accuracy))\n        print(""="" * 50)\n\n        # learning rate scheduling\n\n        if args.scheduler == \'step\':\n            if args.optimizer == \'sgd\' and ((epoch + 1) % 3 == 0) and epoch > 0:\n                current_lr = optimizer.state_dict()[\'param_groups\'][0][\'lr\']\n                current_lr /= 2\n                print(\'Decreasing learning rate to {0}\'.format(current_lr))\n                for param_group in optimizer.param_groups:\n                    param_group[\'lr\'] = current_lr\n\n        # model checkpoint\n\n        if validation_f1 > best_f1:\n            best_f1 = validation_f1\n            best_epoch = epoch\n            if args.checkpoint == 1:\n                torch.save(model.state_dict(), args.output + \'model_{}_epoch_{}_maxlen_{}_lr_{}_loss_{}_acc_{}_f1_{}.pth\'.format(args.model_name,\n                                                                                                                                 epoch,\n                                                                                                                                 args.max_length,\n                                                                                                                                 optimizer.state_dict()[\n                                                                                                                                     \'param_groups\'][0][\'lr\'],\n                                                                                                                                 round(\n                                                                                                                                     validation_loss, 4),\n                                                                                                                                 round(\n                                                                                                                                     validation_accuracy, 4),\n                                                                                                                                 round(\n                                                                                                                                     validation_f1, 4)\n                                                                                                                                 ))\n\n        if bool(args.early_stopping):\n            if epoch - best_epoch > args.patience > 0:\n                print(""Stop training at epoch {}. The lowest loss achieved is {} at epoch {}"".format(\n                    epoch, validation_loss, best_epoch))\n                break\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(\n        \'Character Based CNN for text classification\')\n    parser.add_argument(\'--data_path\', type=str,\n                        default=\'./data/train.csv\')\n    parser.add_argument(\'--validation_split\', type=float, default=0.2)\n    parser.add_argument(\'--label_column\', type=str, default=\'Sentiment\')\n    parser.add_argument(\'--text_column\', type=str, default=\'SentimentText\')\n    parser.add_argument(\'--max_rows\', type=int, default=None)\n    parser.add_argument(\'--chunksize\', type=int, default=50000)\n    parser.add_argument(\'--encoding\', type=str, default=\'utf-8\')\n    parser.add_argument(\'--sep\', type=str, default=\',\')\n    parser.add_argument(\'--steps\', nargs=\'+\', default=[\'lower\'])\n    parser.add_argument(\'--group_labels\', type=int, default=1, choices=[0, 1])\n    parser.add_argument(\'--ignore_center\', type=int, default=1, choices=[0, 1])\n    parser.add_argument(\'--label_ignored\', type=int, default=None)\n    parser.add_argument(\'--ratio\', type=float, default=1)\n    parser.add_argument(\'--balance\', type=int, default=0, choices=[0, 1])\n    parser.add_argument(\'--use_sampler\', type=int,\n                        default=0, choices=[0, 1])\n\n    parser.add_argument(\'--alphabet\', type=str,\n                        default=""abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:\'\\""/\\\\|_@#$%^&*~`+ =<>()[]{}"")\n    parser.add_argument(\'--number_of_characters\', type=int, default=69)\n    parser.add_argument(\'--extra_characters\', type=str, default=\'\')\n    parser.add_argument(\'--max_length\', type=int, default=150)\n    parser.add_argument(\'--dropout_input\', type=float, default=0.1)\n    parser.add_argument(\'--epochs\', type=int, default=10)\n    parser.add_argument(\'--batch_size\', type=int, default=128)\n    parser.add_argument(\'--optimizer\', type=str,\n                        choices=[\'adam\', \'sgd\'], default=\'sgd\')\n    parser.add_argument(\'--learning_rate\', type=float, default=0.01)\n    parser.add_argument(\'--class_weights\', type=int,\n                        default=0, choices=[0, 1])\n    parser.add_argument(\'--focal_loss\', type=int, default=0, choices=[0, 1])\n    parser.add_argument(\'--gamma\', type=float, default=2)\n    parser.add_argument(\'--alpha\', type=float, default=None)\n\n    parser.add_argument(\'--scheduler\', type=str,\n                        default=\'step\', choices=[\'clr\', \'step\'])\n    parser.add_argument(\'--min_lr\', type=float, default=1.7e-3)\n    parser.add_argument(\'--max_lr\', type=float, default=1e-2)\n    parser.add_argument(\'--stepsize\', type=float, default=4)\n    parser.add_argument(\'--patience\', type=int, default=3)\n    parser.add_argument(\'--early_stopping\', type=int,\n                        default=0, choices=[0, 1])\n    parser.add_argument(\'--checkpoint\', type=int,\n                        choices=[0, 1], default=1)\n    parser.add_argument(\'--workers\', type=int, default=1)\n    parser.add_argument(\'--log_path\', type=str, default=\'./logs/\')\n    parser.add_argument(\'--log_every\', type=int, default=100)\n    parser.add_argument(\'--log_f1\', type=int, default=1, choices=[0, 1])\n    parser.add_argument(\'--flush_history\', type=int,\n                        default=1, choices=[0, 1])\n    parser.add_argument(\'--output\', type=str, default=\'./models/\')\n    parser.add_argument(\'--model_name\', type=str, default=\'\')\n\n    args = parser.parse_args()\n    run(args)\n'"
src/__init__.py,0,b''
src/data_loader.py,2,"b""import json\r\nimport numpy as np\r\nfrom collections import Counter\r\n\r\nfrom torch.utils.data import Dataset\r\nimport pandas as pd\r\nfrom tqdm import tqdm\r\nfrom . import utils\r\n\r\nimport torch\r\n\r\n\r\ndef get_sample_weights(labels):\r\n    counter = Counter(labels)\r\n    counter = dict(counter)\r\n    for k in counter:\r\n        counter[k] = 1 / counter[k]\r\n    sample_weights = np.array([counter[l] for l in labels])\r\n    return sample_weights\r\n\r\n\r\ndef load_data(args):\r\n    # chunk your dataframes in small portions\r\n    chunks = pd.read_csv(args.data_path,\r\n                         usecols=[args.text_column, args.label_column],\r\n                         chunksize=args.chunksize,\r\n                         encoding=args.encoding,\r\n                         nrows=args.max_rows,\r\n                         sep=args.sep)\r\n    texts = []\r\n    labels = []\r\n    for df_chunk in tqdm(chunks):\r\n        aux_df = df_chunk.copy()\r\n        aux_df = aux_df.sample(frac=1)\r\n        aux_df = aux_df[~aux_df[args.text_column].isnull()]\r\n        aux_df = aux_df[(aux_df[args.text_column].map(len) > 1)]\r\n        aux_df['processed_text'] = (aux_df[args.text_column]\r\n                                    .map(lambda text: utils.process_text(args.steps, text)))\r\n        texts += aux_df['processed_text'].tolist()\r\n        labels += aux_df[args.label_column].tolist()\r\n\r\n    if bool(args.group_labels):\r\n\r\n        if bool(args.ignore_center):\r\n\r\n            label_ignored = args.label_ignored\r\n\r\n            clean_data = [(text, label) for (text, label) in zip(\r\n                texts, labels) if label not in [label_ignored]]\r\n\r\n            texts = [text for (text, label) in clean_data]\r\n            labels = [label for (text, label) in clean_data]\r\n\r\n            labels = list(\r\n                map(lambda l: {1: 0, 2: 0, 4: 1, 5: 1}[l], labels))\r\n\r\n        else:\r\n            labels = list(\r\n                map(lambda l: {1: 0, 2: 0, 3: 1, 4: 2, 5: 2}[l], labels))\r\n        \r\n    if bool(args.balance):\r\n\r\n        counter = Counter(labels)\r\n        keys = list(counter.keys())\r\n        values = list(counter.values())\r\n        count_minority = np.min(values)\r\n\r\n        balanced_labels = []\r\n        balanced_texts = []\r\n\r\n        for key in keys: \r\n            balanced_texts += [text for text, label in zip(texts, labels) if label == key][:int(args.ratio * count_minority)]\r\n            balanced_labels += [label for text, label in zip(texts, labels) if label == key][:int(args.ratio * count_minority)] \r\n\r\n        texts = balanced_texts\r\n        labels = balanced_labels\r\n\r\n    number_of_classes = len(set(labels))\r\n\r\n    print(\r\n        f'data loaded successfully with {len(texts)} rows and {number_of_classes} labels')\r\n    print('Distribution of the classes', Counter(labels))\r\n\r\n    sample_weights = get_sample_weights(labels)\r\n\r\n    return texts, labels, number_of_classes, sample_weights\r\n\r\n\r\nclass MyDataset(Dataset):\r\n    def __init__(self, texts, labels, args):\r\n        self.texts = texts\r\n        self.labels = labels\r\n        self.length = len(self.texts)\r\n\r\n        self.vocabulary = args.alphabet + args.extra_characters\r\n        self.number_of_characters = args.number_of_characters + \\\r\n            len(args.extra_characters)\r\n        self.max_length = args.max_length\r\n        self.preprocessing_steps = args.steps\r\n        self.identity_mat = np.identity(self.number_of_characters)\r\n\r\n    def __len__(self):\r\n        return self.length\r\n\r\n    def __getitem__(self, index):\r\n        raw_text = self.texts[index]\r\n\r\n        data = np.array([self.identity_mat[self.vocabulary.index(i)] for i in list(raw_text)[::-1] if i in self.vocabulary],\r\n                        dtype=np.float32)\r\n        if len(data) > self.max_length:\r\n            data = data[:self.max_length]\r\n        elif 0 < len(data) < self.max_length:\r\n            data = np.concatenate(\r\n                (data, np.zeros((self.max_length - len(data), self.number_of_characters), dtype=np.float32)))\r\n        elif len(data) == 0:\r\n            data = np.zeros(\r\n                (self.max_length, self.number_of_characters), dtype=np.float32)\r\n\r\n        label = self.labels[index]\r\n        data = torch.Tensor(data)\r\n\r\n        return data, label\r\n"""
src/focal_loss.py,5,"b'import torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport torch.nn as nn\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=0, alpha=None, size_average=True):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha, (float, int)):\n            self.alpha = torch.Tensor([alpha, 1-alpha])\n        if isinstance(alpha, list):\n            self.alpha = torch.Tensor(alpha)\n        self.size_average = size_average\n\n    def forward(self, input, target):\n        if input.dim() > 2:\n            # N,C,H,W => N,C,H*W\n            input = input.view(input.size(0), input.size(1), -1)\n            input = input.transpose(1, 2)    # N,C,H*W => N,H*W,C\n            input = input.contiguous().view(-1, input.size(2))   # N,H*W,C => N*H*W,C\n        target = target.view(-1, 1)\n\n        logpt = F.log_softmax(input, dim=1)\n        logpt = logpt.gather(1, target)\n        logpt = logpt.view(-1)\n        pt = Variable(logpt.data.exp())\n\n        if self.alpha is not None:\n            if self.alpha.type() != input.data.type():\n                self.alpha = self.alpha.type_as(input.data)\n            at = self.alpha.gather(0, target.data.view(-1))\n            logpt = logpt * Variable(at)\n\n        loss = -1 * (1-pt)**self.gamma * logpt\n        if self.size_average:\n            return loss.mean()\n        else:\n            return loss.sum()\n'"
src/model.py,2,"b'import json\nimport torch\nimport torch.nn as nn\n\n\nclass CharacterLevelCNN(nn.Module):\n    def __init__(self, args, number_of_classes):\n        super(CharacterLevelCNN, self).__init__()\n\n        # define conv layers\n\n        self.dropout_input = nn.Dropout2d(args.dropout_input)\n\n        self.conv1 = nn.Sequential(nn.Conv1d(args.number_of_characters + len(args.extra_characters),\n                                             256,\n                                             kernel_size=7,\n                                             padding=0),\n                                   nn.ReLU(),\n                                   nn.MaxPool1d(3)\n                                   )\n\n        self.conv2 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=7, padding=0),\n                                   nn.ReLU(),\n                                   nn.MaxPool1d(3)\n                                   )\n\n        self.conv3 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=3, padding=0),\n                                   nn.ReLU()\n                                   )\n\n        self.conv4 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=3, padding=0),\n                                   nn.ReLU()\n                                   )\n\n        self.conv5 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=3, padding=0),\n                                   nn.ReLU()\n                                   )\n\n        self.conv6 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=3, padding=0),\n                                   nn.ReLU(),\n                                   nn.MaxPool1d(3)\n                                   )\n\n        # compute the  output shape after forwarding an input to the conv layers\n\n        input_shape = (128,\n                       args.max_length,\n                       args.number_of_characters + len(args.extra_characters))\n        self.output_dimension = self._get_conv_output(input_shape)\n\n        # define linear layers\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(self.output_dimension, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.5)\n        )\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(1024, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.5)\n        )\n\n        self.fc3 = nn.Linear(1024, number_of_classes)\n\n        # initialize weights\n\n        self._create_weights()\n\n    # utility private functions\n\n    def _create_weights(self, mean=0.0, std=0.05):\n        for module in self.modules():\n            if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n                module.weight.data.normal_(mean, std)\n\n\n    def _get_conv_output(self, shape):\n        x = torch.rand(shape)\n        x = x.transpose(1, 2)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        x = x.view(x.size(0), -1)\n        output_dimension = x.size(1)\n        return output_dimension\n\n    # forward\n\n    def forward(self, x):\n        x = self.dropout_input(x)\n        x = x.transpose(1, 2)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n        return x\n\n'"
src/utils.py,0,"b'import math\r\nimport json\r\nimport re\r\nimport numpy as np\r\nfrom sklearn import metrics\r\n\r\n# text-preprocessing\r\n\r\n\r\ndef lower(text):\r\n    return text.lower()\r\n\r\n\r\ndef remove_hashtags(text):\r\n    clean_text = re.sub(r\'#[A-Za-z0-9_]+\', """", text)\r\n    return clean_text\r\n\r\n\r\ndef remove_user_mentions(text):\r\n    clean_text = re.sub(r\'@[A-Za-z0-9_]+\', """", text)\r\n    return clean_text\r\n\r\n\r\ndef remove_urls(text):\r\n    clean_text = re.sub(r\'^https?:\\/\\/.*[\\r\\n]*\', \'\', text, flags=re.MULTILINE)\r\n    return clean_text\r\n\r\n\r\npreprocessing_setps = {\r\n    \'remove_hashtags\': remove_hashtags,\r\n    \'remove_urls\': remove_urls,\r\n    \'remove_user_mentions\': remove_user_mentions,\r\n    \'lower\': lower\r\n}\r\n\r\n\r\ndef process_text(steps, text):\r\n    if steps is not None:\r\n        for step in steps:\r\n            text = preprocessing_setps[step](text)\r\n    return text\r\n\r\n# metrics // model evaluations\r\n\r\n\r\ndef get_evaluation(y_true, y_prob, list_metrics):\r\n    y_pred = np.argmax(y_prob, -1)\r\n    output = {}\r\n    if \'accuracy\' in list_metrics:\r\n        output[\'accuracy\'] = metrics.accuracy_score(y_true, y_pred)\r\n    if \'f1\' in list_metrics:\r\n        output[\'f1\'] = metrics.f1_score(y_true, y_pred, average=\'weighted\')\r\n\r\n    return output\r\n\r\n\r\nclass AverageMeter(object):\r\n    """"""Computes and stores the average and current value""""""\r\n\r\n    def __init__(self):\r\n        self.reset()\r\n\r\n    def reset(self):\r\n        self.val = 0\r\n        self.avg = 0\r\n        self.sum = 0\r\n        self.count = 0\r\n\r\n    def update(self, val, n=1):\r\n        self.val = val\r\n        self.sum += val * n\r\n        self.count += n\r\n        self.avg = self.sum / self.count\r\n\r\n\r\ndef accuracy(output, target, topk=(1,)):\r\n    """"""Computes the precision@k for the specified values of k""""""\r\n    maxk = max(topk)\r\n    batch_size = target.size(0)\r\n\r\n    _, pred = output.topk(maxk, 1, True, True)\r\n    pred = pred.t()\r\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\r\n\r\n    res = []\r\n    for k in topk:\r\n        correct_k = correct[:k].view(-1).float().sum(0)\r\n        res.append(correct_k.mul_(100.0 / batch_size))\r\n    return res\r\n\r\n# preprocess input for prediction\r\n\r\n\r\ndef preprocess_input(args):\r\n    raw_text = args.text\r\n    steps = args.steps\r\n    for step in steps:\r\n        raw_text = preprocessing_setps[step](raw_text)\r\n\r\n    number_of_characters = args.number_of_characters + \\\r\n        len(args.extra_characters)\r\n    identity_mat = np.identity(number_of_characters)\r\n    vocabulary = list(args.alphabet) + list(args.extra_characters)\r\n    max_length = args.max_length\r\n\r\n    processed_output = np.array([identity_mat[vocabulary.index(i)] for i in list(\r\n        raw_text[::-1]) if i in vocabulary], dtype=np.float32)\r\n    if len(processed_output) > max_length:\r\n        processed_output = processed_output[:max_length]\r\n    elif 0 < len(processed_output) < max_length:\r\n        processed_output = np.concatenate((processed_output, np.zeros(\r\n            (max_length - len(processed_output), number_of_characters), dtype=np.float32)))\r\n    elif len(processed_output) == 0:\r\n        processed_output = np.zeros(\r\n            (max_length, number_of_characters), dtype=np.float32)\r\n    return processed_output\r\n\r\n\r\n# cyclic learning rate scheduling\r\n\r\ndef cyclical_lr(stepsize, min_lr=1.7e-3, max_lr=1e-2):\r\n\r\n    # Scaler: we can adapt this if we do not want the triangular CLR\r\n    def scaler(x): return 1.\r\n\r\n    # Lambda function to calculate the LR\r\n    def lr_lambda(it): return min_lr + (max_lr -\r\n                                        min_lr) * relative(it, stepsize)\r\n\r\n    # Additional function to see where on the cycle we are\r\n    def relative(it, stepsize):\r\n        cycle = math.floor(1 + it / (2 * stepsize))\r\n        x = abs(it / stepsize - 2 * cycle + 1)\r\n        return max(0, (1 - x)) * scaler(cycle)\r\n\r\n    return lr_lambda\r\n'"
