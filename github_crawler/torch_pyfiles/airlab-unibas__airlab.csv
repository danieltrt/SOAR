file_path,api_count,code
setup.py,0,"b""from setuptools import setup, find_packages\n\n__version__ = '0.2.1'\nurl = 'https://github.com/airlab-unibas/airlab'\n\ninstall_requires = ['SimpleITK', 'torch', 'numpy', 'matplotlib']\n\n\nsetup(\n    name='airlab',\n    description='Autograd Image Registraion Laboratory',\n    version=__version__,\n    author='Robin Sandkuehler, Christoph Jud',\n    author_email='robin.sandkuehler@unibas.ch',\n    url=url,\n    keywords=['image registration'],\n    install_requires=install_requires,\n    packages=find_packages(exclude=['example']),\n    ext_package='')\n"""
airlab/__init__.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom .utils import *\nimport airlab.transformation\nimport airlab.loss\nfrom .registration import *\nimport airlab.regulariser\n'"
docs/conf.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Airlab documentation build configuration file, created by\n# sphinx-quickstart on Wed Jun 20 22:07:56 2018.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n# import os\nimport sys\n# sys.path.insert(0, os.path.abspath(\'.\'))\nsys.path.append(\'..\')\n\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\'sphinx.ext.autodoc\',\n              \'sphinx.ext.mathjax\',\n              \'sphinx.ext.viewcode\', \n              \'sphinx.ext.napoleon\']\n\n\nnapoleon_use_ivar = True\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = \'Airlab\'\ncopyright = \'2018, University of Basel, Center for medical Image Analysis and Navigation\'\nauthor = \'Robin Sandkuehler Christoph Jud\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = \'0.1\'\n# The full version, including alpha/beta/rc tags.\nrelease = \'0.1\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\nhtml_logo = \'airlab_logo.png\'\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# This is required for the alabaster theme\n# refs: http://alabaster.readthedocs.io/en/latest/installation.html#sidebars\nhtml_sidebars = {\n    \'**\': [\n        \'relations.html\',  # needs \'show_related\': True theme option to display\n        \'searchbox.html\',\n    ]\n}\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'Airlabdoc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'Airlab.tex\', \'Airlab Documentation\',\n     \'Robin Sandkuehler Christoph Jud\', \'manual\'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'airlab\', \'Airlab Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'Airlab\', \'Airlab Documentation\',\n     author, \'Airlab\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n\n'"
examples/affine_registration_2d.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport sys\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nimport torch as th\n\n\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport airlab as al\n\n\ndef main():\n    start = time.time()\n\n    # set the used data type\n    dtype = th.float32\n    # set the device for the computaion to CPU\n    device = th.device(""cpu"")\n\n    # In order to use a GPU uncomment the following line. The number is the device index of the used GPU\n    # Here, the GPU with the index 0 is used.\n    # device = th.device(""cuda:0"")\n\n    # load the image data and normalize to [0, 1]\n    fixed_image = al.read_image_as_tensor(""./data/affine_test_image_2d_fixed.png"", dtype=dtype, device=device)\n    moving_image = al.read_image_as_tensor(""./data/affine_test_image_2d_moving.png"", dtype=dtype, device=device)\n\n    fixed_image, moving_image = al.utils.normalize_images(fixed_image, moving_image)\n\n    # convert intensities so that the object intensities are 1 and the background 0. This is important in order to\n    # calculate the center of mass of the object\n    fixed_image.image = 1 - fixed_image.image\n    moving_image.image = 1 - moving_image.image\n\n    # create pairwise registration object\n    registration = al.PairwiseRegistration()\n\n    # choose the affine transformation model\n    transformation = al.transformation.pairwise.SimilarityTransformation(moving_image, opt_cm=True)\n    # initialize the translation with the center of mass of the fixed image\n    transformation.init_translation(fixed_image)\n\n    registration.set_transformation(transformation)\n\n    # choose the Mean Squared Error as image loss\n    image_loss = al.loss.pairwise.MSE(fixed_image, moving_image)\n\n    registration.set_image_loss([image_loss])\n\n    # choose the Adam optimizer to minimize the objective\n    optimizer = th.optim.Adam(transformation.parameters(), lr=0.01, amsgrad=True)\n\n    registration.set_optimizer(optimizer)\n    registration.set_number_of_iterations(1000)\n\n    # start the registration\n    registration.start()\n\n    # set the intensities back to the original for the visualisation\n    fixed_image.image = 1 - fixed_image.image\n    moving_image.image = 1 - moving_image.image\n\n    # warp the moving image with the final transformation result\n    displacement = transformation.get_displacement()\n    warped_image = al.transformation.utils.warp_image(moving_image, displacement)\n\n    end = time.time()\n\n    print(""================================================================="")\n\n    print(""Registration done in:"", end - start, ""s"")\n    print(""Result parameters:"")\n    transformation.print()\n\n    # plot the results\n    plt.subplot(131)\n    plt.imshow(fixed_image.numpy(), cmap=\'gray\')\n    plt.title(\'Fixed Image\')\n\n    plt.subplot(132)\n    plt.imshow(moving_image.numpy(), cmap=\'gray\')\n    plt.title(\'Moving Image\')\n\n    plt.subplot(133)\n    plt.imshow(warped_image.numpy(), cmap=\'gray\')\n    plt.title(\'Warped Moving Image\')\n\n    plt.show()\n\n\nif __name__ == \'__main__\':\n    main()'"
examples/affine_registration_3d.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport sys\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nimport torch as th\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport airlab as al\n\ndef main():\n    start = time.time()\n\n    # set the used data type\n    dtype = th.float32\n    # set the device for the computaion to CPU\n    device = th.device(""cpu"")\n\n    # In order to use a GPU uncomment the following line. The number is the device index of the used GPU\n    # Here, the GPU with the index 0 is used.\n    # device = th.device(""cuda:0"")\n\n    # create 3D image volume with two objects\n    object_shift = 10\n\n    fixed_image = th.zeros(64, 64, 64).to(device=device)\n    fixed_image[16:32, 16:32, 16:32] = 1.0\n    fixed_image = al.Image(fixed_image, [64, 64, 64], [1, 1, 1], [0, 0, 0])\n\n    moving_image = th.zeros(64, 64, 64).to(device=device)\n    moving_image[16 - object_shift:32 - object_shift, 16 - object_shift:32 - object_shift,\n    16 - object_shift:32 - object_shift] = 1.0\n    moving_image = al.Image(moving_image, [64, 64, 64], [1, 1, 1], [0, 0, 0])\n\n    # create pairwise registration object\n    registration = al.PairwiseRegistration()\n\n    # choose the affine transformation model\n    transformation = al.transformation.pairwise.RigidTransformation(moving_image, opt_cm=True)\n    transformation.init_translation(fixed_image)\n\n    registration.set_transformation(transformation)\n\n    # choose the Mean Squared Error as image loss\n    image_loss = al.loss.pairwise.MSE(fixed_image, moving_image)\n\n    registration.set_image_loss([image_loss])\n\n    # choose the Adam optimizer to minimize the objective\n    optimizer = th.optim.Adam(transformation.parameters(), lr=0.1)\n\n    registration.set_optimizer(optimizer)\n    registration.set_number_of_iterations(500)\n\n    # start the registration\n    registration.start()\n\n    # set the intensities for the visualisation\n    fixed_image.image = 1 - fixed_image.image\n    moving_image.image = 1 - moving_image.image\n\n    # warp the moving image with the final transformation result\n    displacement = transformation.get_displacement()\n    warped_image = al.transformation.utils.warp_image(moving_image, displacement)\n\n    end = time.time()\n\n    print(""================================================================="")\n\n    print(""Registration done in: "", end - start, "" s"")\n    print(""Result parameters:"")\n    transformation.print()\n\n    # sitk.WriteImage(warped_image.itk(), \'/tmp/rigid_warped_image.vtk\')\n    # sitk.WriteImage(moving_image.itk(), \'/tmp/rigid_moving_image.vtk\')\n    # sitk.WriteImage(fixed_image.itk(), \'/tmp/rigid_fixed_image.vtk\')\n\n    # plot the results\n    plt.subplot(131)\n    plt.imshow(fixed_image.numpy()[16, :, :], cmap=\'gray\')\n    plt.title(\'Fixed Image Slice\')\n\n    plt.subplot(132)\n    plt.imshow(moving_image.numpy()[16, :, :], cmap=\'gray\')\n    plt.title(\'Moving Image Slice\')\n\n    plt.subplot(133)\n    plt.imshow(warped_image.numpy()[16, :, :], cmap=\'gray\')\n    plt.title(\'Warped Moving Image Slice\')\n\n    plt.show()\n\nif __name__ == \'__main__\':\n    main()'"
examples/create_test_image_data.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport torch as th\n\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport airlab as al\n\n\ndef create_C_2_O_test_images(image_size, dtype=th.float32, device=\'cpu\'):\n    """"""\n    Create test images for the transformation from circle to c according to\n    Modersitzki, J.(2003-12-04). Numerical Methods for Image Registration. : Oxford University Press\n\n    """"""\n    x = np.linspace(-1, 1, image_size)\n\n    xv, yv = np.meshgrid(x, x)\n\n    value = xv**2 + yv**2\n\n    index = (value > 0.33**2) & (value < 0.64**2)\n\n    fixed_image = np.ones((image_size, image_size))\n    fixed_image[index] = 0\n\n    index = (xv > 0) & (np.abs(yv) < 0.16)\n    fixed_image[index] = 1\n\n    moving_image = 0.5**2 - xv**2 - yv**2\n\n    shaded_image = moving_image.copy()*10\n    index = moving_image < 0\n    shaded_image[index] = 1\n\n    shaded_image[np.logical_not(index)] = shaded_image[np.logical_not(index)]/np.max(shaded_image[np.logical_not(index)])\n\n    index_2 = moving_image > 0\n    moving_image[index_2] = 0\n\n    moving_image[index] = 1\n\n    return [al.image_from_numpy(fixed_image, [1, 1], [0, 0], dtype=dtype, device=device),\n            al.image_from_numpy(moving_image, [1, 1], [0, 0], dtype=dtype, device=device),\n            al.image_from_numpy(shaded_image, [1, 1], [0, 0], dtype=dtype, device=device)]\n\n\n'"
examples/demons_registration_2d.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport sys\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\n\nimport torch as th\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport airlab as al\n\nfrom create_test_image_data import create_C_2_O_test_images\n\ndef main():\n    start = time.time()\n\n    # set the used data type\n    dtype = th.float32\n    # set the device for the computaion to CPU\n    device = th.device(""cpu"")\n\n    # In order to use a GPU uncomment the following line. The number is the device index of the used GPU\n    # Here, the GPU with the index 0 is used.\n    # device = th.device(""cuda:0"")\n\n    # create test image data\n    fixed_image, moving_image, shaded_image = create_C_2_O_test_images(256, dtype=dtype, device=device)\n\n    # create pairwise registration object\n    registration = al.DemonsRegistraion(verbose=True)\n\n    # choose the affine transformation model\n    transformation = al.transformation.pairwise.NonParametricTransformation(moving_image.size,\n                                                                            dtype=dtype,\n                                                                            device=device,\n                                                                            diffeomorphic=True)\n\n    registration.set_transformation(transformation)\n\n    # choose the Mean Squared Error as image loss\n    image_loss = al.loss.pairwise.MSE(fixed_image, moving_image)\n\n    registration.set_image_loss([image_loss])\n\n    # choose a regulariser for the demons\n    regulariser = al.regulariser.demons.GaussianRegulariser(moving_image.spacing, sigma=[2, 2], dtype=dtype,\n                                                            device=device)\n\n    registration.set_regulariser([regulariser])\n\n    # choose the Adam optimizer to minimize the objective\n    optimizer = th.optim.Adam(transformation.parameters(), lr=0.01)\n\n    registration.set_optimizer(optimizer)\n    registration.set_number_of_iterations(1000)\n\n    # start the registration\n    registration.start()\n\n    # warp the moving image with the final transformation result\n    displacement = transformation.get_displacement()\n\n    # use the shaded version of the fixed image for visualization\n    warped_image = al.transformation.utils.warp_image(shaded_image, displacement)\n\n    end = time.time()\n\n    displacement = al.create_displacement_image_from_image(displacement, moving_image)\n\n    print(""================================================================="")\n\n    print(""Registration done in: "", end - start)\n\n    # plot the results\n    plt.subplot(221)\n    plt.imshow(fixed_image.numpy(), cmap=\'gray\')\n    plt.title(\'Fixed Image\')\n\n    plt.subplot(222)\n    plt.imshow(moving_image.numpy(), cmap=\'gray\')\n    plt.title(\'Moving Image\')\n\n    plt.subplot(223)\n    plt.imshow(warped_image.numpy(), cmap=\'gray\')\n    plt.title(\'Warped Moving Image\')\n\n    plt.subplot(224)\n    plt.imshow(displacement.magnitude().numpy(), cmap=\'jet\')\n    plt.title(\'Magnitude Displacement\')\n\n    plt.show()\n\n    # write result images\n    # sitk.WriteImage(warped_image.itk(), \'/tmp/demons_warped_image.vtk\')\n    # sitk.WriteImage(moving_image.itk(), \'/tmp/demons_moving_image.vtk\')\n    # sitk.WriteImage(fixed_image.itk(), \'/tmp/demons_fixed_image.vtk\')\n    # sitk.WriteImage(shaded_image.itk(), \'/tmp/demons_shaded_image.vtk\')\n    # sitk.WriteImage(displacement.itk(), \'/tmp/demons_displacement_image.vtk\')\n\n\nif __name__ == \'__main__\':\n    main()'"
examples/diffeomorphic_bspline_2d.py,0,"b'\n# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport sys\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nimport torch as th\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport airlab as al\n\nfrom create_test_image_data import create_C_2_O_test_images\n\ndef main():\n\tstart = time.time()\n\n\t# set the used data type\n\tdtype = th.float32\n\t# set the device for the computaion to CPU\n\tdevice = th.device(""cpu"")\n\n\t# In order to use a GPU uncomment the following line. The number is the device index of the used GPU\n\t# Here, the GPU with the index 0 is used.\n\t# device = th.device(""cuda:0"")\n\n\t# create test image data\n\tfixed_image, moving_image, shaded_image = create_C_2_O_test_images(256, dtype=dtype, device=device)\n\n\t# create image pyramide size/4, size/2, size/1\n\tfixed_image_pyramid = al.create_image_pyramid(fixed_image, [[4, 4], [2, 2]])\n\tmoving_image_pyramid = al.create_image_pyramid(moving_image, [[4, 4], [2, 2]])\n\n\tconstant_displacement = None\n\tregularisation_weight = [1, 5, 50]\n\tnumber_of_iterations = [500, 500, 500]\n\tsigma = [[11, 11], [11, 11], [3, 3]]\n\n\tfor level, (mov_im_level, fix_im_level) in enumerate(zip(moving_image_pyramid, fixed_image_pyramid)):\n\n\t\tregistration = al.PairwiseRegistration(verbose=True)\n\n\t\t# define the transformation\n\t\ttransformation = al.transformation.pairwise.BsplineTransformation(mov_im_level.size,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  sigma=sigma[level],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  order=3,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  dtype=dtype,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  device=device,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  diffeomorphic=True)\n\n\t\tif level > 0:\n\t\t\tconstant_flow = al.transformation.utils.upsample_displacement(constant_flow,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  mov_im_level.size,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  interpolation=""linear"")\n\t\t\ttransformation.set_constant_flow(constant_flow)\n\n\t\tregistration.set_transformation(transformation)\n\n\t\t# choose the Mean Squared Error as image loss\n\t\timage_loss = al.loss.pairwise.MSE(fix_im_level, mov_im_level)\n\n\t\tregistration.set_image_loss([image_loss])\n\n\t\t# define the regulariser for the displacement\n\t\tregulariser = al.regulariser.displacement.DiffusionRegulariser(mov_im_level.spacing)\n\t\tregulariser.SetWeight(regularisation_weight[level])\n\n\t\tregistration.set_regulariser_displacement([regulariser])\n\n\t\t#define the optimizer\n\t\toptimizer = th.optim.Adam(transformation.parameters())\n\n\t\tregistration.set_optimizer(optimizer)\n\t\tregistration.set_number_of_iterations(number_of_iterations[level])\n\n\t\tregistration.start()\n\n\t\tconstant_flow = transformation.get_flow()\n\n\t# create final result\n\tdisplacement = transformation.get_displacement()\n\twarped_image = al.transformation.utils.warp_image(shaded_image, displacement)\n\tdisplacement = al.create_displacement_image_from_image(displacement, moving_image)\n\n\n\t# create inverse displacement field\n\tinverse_displacement = transformation.get_inverse_displacement()\n\tinverse_warped_image = al.transformation.utils.warp_image(warped_image, inverse_displacement)\n\tinverse_displacement = al.create_displacement_image_from_image(inverse_displacement, moving_image)\n\n\tend = time.time()\n\n\tprint(""================================================================="")\n\n\tprint(""Registration done in: "", end - start)\n\tprint(""Result parameters:"")\n\n\t# plot the results\n\tplt.subplot(241)\n\tplt.imshow(fixed_image.numpy(), cmap=\'gray\')\n\tplt.title(\'Fixed Image\')\n\n\tplt.subplot(242)\n\tplt.imshow(moving_image.numpy(), cmap=\'gray\')\n\tplt.title(\'Moving Image\')\n\n\tplt.subplot(243)\n\tplt.imshow(warped_image.numpy(), cmap=\'gray\')\n\tplt.title(\'Warped Shaded Moving Image\')\n\n\tplt.subplot(244)\n\tplt.imshow(displacement.magnitude().numpy(), cmap=\'jet\')\n\tplt.title(\'Magnitude Displacement\')\n\n\t# plot the results\n\tplt.subplot(245)\n\tplt.imshow(warped_image.numpy(), cmap=\'gray\')\n\tplt.title(\'Warped Shaded Moving Image\')\n\n\tplt.subplot(246)\n\tplt.imshow(shaded_image.numpy(), cmap=\'gray\')\n\tplt.title(\'Shaded Moving Image\')\n\n\tplt.subplot(247)\n\tplt.imshow(inverse_warped_image.numpy(), cmap=\'gray\')\n\tplt.title(\'Inverse Warped Shaded Moving Image\')\n\n\tplt.subplot(248)\n\tplt.imshow(inverse_displacement.magnitude().numpy(), cmap=\'jet\')\n\tplt.title(\'Magnitude Inverse Displacement\')\n\n\tplt.show()\n\nif __name__ == \'__main__\':\n\tmain()\n'"
examples/kernel_registration_2d.py,0,"b'\n# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport sys\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nimport torch as th\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport airlab as al\n\nfrom create_test_image_data import create_C_2_O_test_images\n\ndef main():\n    start = time.time()\n\n    # set the used data type\n    dtype = th.float32\n    # set the device for the computaion to CPU\n    device = th.device(""cpu"")\n\n    # In order to use a GPU uncomment the following line. The number is the device index of the used GPU\n    # Here, the GPU with the index 0 is used.\n    # device = th.device(""cuda:0"")\n\n    # create test image data\n    fixed_image, moving_image, shaded_image = create_C_2_O_test_images(256, dtype=dtype, device=device)\n\n    # create image pyramide size/4, size/2, size/1\n    fixed_image_pyramid = al.create_image_pyramid(fixed_image, [[4, 4], [2, 2]])\n    moving_image_pyramid = al.create_image_pyramid(moving_image, [[4, 4], [2, 2]])\n\n    constant_flow = None\n    regularisation_weight = [1, 5, 50]\n    number_of_iterations = [500, 500, 500]\n    sigma = [[11, 11], [11, 11], [3, 3]]\n\n    for level, (mov_im_level, fix_im_level) in enumerate(zip(moving_image_pyramid, fixed_image_pyramid)):\n\n        registration = al.PairwiseRegistration(verbose=True)\n\n        # define the transformation\n        transformation = al.transformation.pairwise.BsplineTransformation(mov_im_level.size,\n                                                                          sigma=sigma[level],\n                                                                          order=3,\n                                                                          dtype=dtype,\n                                                                          device=device)\n\n        if level > 0:\n            constant_flow = al.transformation.utils.upsample_displacement(constant_flow,\n                                                                          mov_im_level.size,\n                                                                          interpolation=""linear"")\n            transformation.set_constant_flow(constant_flow)\n\n        registration.set_transformation(transformation)\n\n        # choose the Mean Squared Error as image loss\n        image_loss = al.loss.pairwise.MSE(fix_im_level, mov_im_level)\n\n        registration.set_image_loss([image_loss])\n\n        # define the regulariser for the displacement\n        regulariser = al.regulariser.displacement.DiffusionRegulariser(mov_im_level.spacing)\n        regulariser.SetWeight(regularisation_weight[level])\n\n        registration.set_regulariser_displacement([regulariser])\n\n        # define the optimizer\n        optimizer = th.optim.Adam(transformation.parameters())\n\n        registration.set_optimizer(optimizer)\n        registration.set_number_of_iterations(number_of_iterations[level])\n\n        registration.start()\n\n        constant_flow = transformation.get_flow()\n\n    # create final result\n    displacement = transformation.get_displacement()\n    warped_image = al.transformation.utils.warp_image(shaded_image, displacement)\n    displacement = al.create_displacement_image_from_image(displacement, moving_image)\n\n    end = time.time()\n\n    print(""================================================================="")\n\n    print(""Registration done in: "", end - start)\n    print(""Result parameters:"")\n\n    # plot the results\n    plt.subplot(221)\n    plt.imshow(fixed_image.numpy(), cmap=\'gray\')\n    plt.title(\'Fixed Image\')\n\n    plt.subplot(222)\n    plt.imshow(moving_image.numpy(), cmap=\'gray\')\n    plt.title(\'Moving Image\')\n\n    plt.subplot(223)\n    plt.imshow(warped_image.numpy(), cmap=\'gray\')\n    plt.title(\'Warped Moving Image\')\n\n    plt.subplot(224)\n    plt.imshow(displacement.magnitude().numpy(), cmap=\'jet\')\n    plt.title(\'Magnitude Displacement\')\n\n    plt.show()\n\nif __name__ == \'__main__\':\n    main()\n'"
examples/kernel_registration_3d.py,0,"b'\n# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os, sys, time\nimport torch as th\nimport numpy as np\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport airlab as al\n\n\ndef main():\n    start = time.time()\n\n    # set the used data type\n    dtype = th.float32\n    # set the device for the computaion to CPU\n    device = th.device(""cpu"")\n\n    # In order to use a GPU uncomment the following line. The number is the device index of the used GPU\n    # Here, the GPU with the index 0 is used.\n    # device = th.device(""cuda:0"")\n\n    # directory to store results\n    tmp_directory = ""/tmp/""\n\n    # load the image data and normalize intensities to [0, 1]\n    loader = al.ImageLoader(tmp_directory)\n\n    # Images:\n    p1_name = ""4DCT_POPI_1""\n    p1_img_nr = ""image_00""\n    p2_name = ""4DCT_POPI_1""\n    p2_img_nr = ""image_50""\n\n    using_landmarks = True\n\n    print(""loading images"")\n    (fixed_image, fixed_points) = loader.load(p1_name, p1_img_nr)\n    (moving_image, moving_points) = loader.load(p2_name, p2_img_nr)\n    fixed_image.to(dtype, device)\n    moving_image.to(dtype, device)\n\n    if fixed_points is None or moving_points is None:\n        using_landmarks = False\n\n    if using_landmarks:\n        initial_tre = al.Points.TRE(fixed_points, moving_points)\n        print(""initial TRE: ""+str(initial_tre))\n\n    print(""preprocessing images"")\n    (fixed_image, fixed_body_mask) = al.remove_bed_filter(fixed_image)\n    (moving_image, moving_body_mask) = al.remove_bed_filter(moving_image)\n\n    # normalize image intensities using common minimum and common maximum\n    fixed_image, moving_image = al.utils.normalize_images(fixed_image, moving_image)\n\n    # only perform center of mass alignment if inter subject registration is performed\n    if p1_name == p2_name:\n        cm_alignment = False\n    else:\n        cm_alignment = True\n\n    # Remove bed and auto-crop images\n    f_image, f_mask, m_image, m_mask, cm_displacement = al.get_joint_domain_images(fixed_image, moving_image,\n                                                                                   cm_alignment=cm_alignment,\n                                                                                   compute_masks=True)\n\n    # align also moving points\n    if not cm_displacement is None and using_landmarks:\n        moving_points_aligned = np.zeros_like(moving_points)\n        for i in range(moving_points_aligned.shape[0]):\n            moving_points_aligned[i, :] = moving_points[i, :] + cm_displacement\n        print(""aligned TRE: "" + str(al.Points.TRE(fixed_points, moving_points_aligned)))\n    else:\n        moving_points_aligned = moving_points\n\n    # create image pyramid size/8 size/4, size/2, size/1\n    fixed_image_pyramid = al.create_image_pyramid(f_image, [[8, 8, 8], [4, 4, 4], [2, 2, 2]])\n    fixed_mask_pyramid = al.create_image_pyramid(f_mask, [[8, 8, 8], [4, 4, 4], [2, 2, 2]])\n    moving_image_pyramid = al.create_image_pyramid(m_image, [[8, 8, 8], [4, 4, 4], [2, 2, 2]])\n    moving_mask_pyramid = al.create_image_pyramid(m_mask, [[8, 8, 8], [4, 4, 4], [2, 2, 2]])\n\n    constant_flow = None\n    regularisation_weight = [1e-2, 1e-1, 1e-0, 1e+2]\n    number_of_iterations = [300, 200, 100, 50]\n    sigma = [[9, 9, 9], [9, 9, 9], [9, 9, 9], [9, 9, 9]]\n    step_size = [1e-2, 4e-3, 2e-3, 2e-3]\n\n    print(""perform registration"")\n    for level, (mov_im_level, mov_msk_level, fix_im_level, fix_msk_level) in enumerate(zip(moving_image_pyramid,\n                                                                                           moving_mask_pyramid,\n                                                                                           fixed_image_pyramid,\n                                                                                           fixed_mask_pyramid)):\n\n        print(""---- Level ""+str(level)+"" ----"")\n        registration = al.PairwiseRegistration()\n\n        # define the transformation\n        transformation = al.transformation.pairwise.BsplineTransformation(mov_im_level.size,\n                                                                          sigma=sigma[level],\n                                                                          order=3,\n                                                                          dtype=dtype,\n                                                                          device=device)\n\n        if level > 0:\n            constant_flow = al.transformation.utils.upsample_displacement(constant_flow,\n                                                                          mov_im_level.size,\n                                                                          interpolation=""linear"")\n\n            transformation.set_constant_flow(constant_flow)\n\n        registration.set_transformation(transformation)\n\n        # choose the Mean Squared Error as image loss\n        image_loss = al.loss.pairwise.MSE(fix_im_level, mov_im_level, mov_msk_level, fix_msk_level)\n\n        registration.set_image_loss([image_loss])\n\n        # define the regulariser for the displacement\n        regulariser = al.regulariser.displacement.DiffusionRegulariser(mov_im_level.spacing)\n        regulariser.SetWeight(regularisation_weight[level])\n\n        registration.set_regulariser_displacement([regulariser])\n\n        # define the optimizer\n        optimizer = th.optim.Adam(transformation.parameters(), lr=step_size[level], amsgrad=True)\n\n        registration.set_optimizer(optimizer)\n        registration.set_number_of_iterations(number_of_iterations[level])\n\n        registration.start()\n\n        # store current flow field\n        constant_flow = transformation.get_flow()\n\n        current_displacement = transformation.get_displacement()\n        # generate SimpleITK displacement field and calculate TRE\n        tmp_displacement = al.transformation.utils.upsample_displacement(current_displacement.clone().to(device=\'cpu\'),\n                                                                         m_image.size, interpolation=""linear"")\n        tmp_displacement = al.transformation.utils.unit_displacement_to_dispalcement(tmp_displacement)  # unit measures to image domain measures\n        tmp_displacement = al.create_displacement_image_from_image(tmp_displacement, m_image)\n        tmp_displacement.write(\'/tmp/bspline_displacement_image_level_\'+str(level)+\'.vtk\')\n\n        # in order to not invert the displacement field, the fixed points are transformed to match the moving points\n        if using_landmarks:\n            print(""TRE on that level: ""+str(al.Points.TRE(moving_points_aligned, al.Points.transform(fixed_points, tmp_displacement))))\n\n    # create final result\n    displacement = transformation.get_displacement()\n    warped_image = al.transformation.utils.warp_image(m_image, displacement)\n    displacement = al.transformation.utils.unit_displacement_to_dispalcement(displacement) # unit measures to image domain measures\n    displacement = al.create_displacement_image_from_image(displacement, m_image)\n\n    end = time.time()\n\n    # in order to not invert the displacement field, the fixed points are transformed to match the moving points\n    if using_landmarks:\n        print(""Initial TRE: ""+str(initial_tre))\n        fixed_points_transformed = al.Points.transform(fixed_points, displacement)\n        print(""Final TRE: "" + str(al.Points.TRE(moving_points_aligned, fixed_points_transformed)))\n\n    # write result images\n    print(""writing results"")\n    warped_image.write(\'/tmp/bspline_warped_image.vtk\')\n    m_image.write(\'/tmp/bspline_moving_image.vtk\')\n    m_mask.write(\'/tmp/bspline_moving_mask.vtk\')\n    f_image.write(\'/tmp/bspline_fixed_image.vtk\')\n    f_mask.write(\'/tmp/bspline_fixed_mask.vtk\')\n    displacement.write(\'/tmp/bspline_displacement_image.vtk\')\n\n    if using_landmarks:\n        al.Points.write(\'/tmp/bspline_fixed_points_transformed.vtk\', fixed_points_transformed)\n        al.Points.write(\'/tmp/bspline_moving_points_aligned.vtk\', moving_points_aligned)\n\n    print(""================================================================="")\n    print(""Registration done in: "", end - start, "" seconds"")\n\n\nif __name__ == \'__main__\':\n    main()\n'"
airlab/loss/__init__.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom airlab.loss import pairwise\n\n'"
airlab/loss/pairwise.py,1,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nimport torch.nn.functional as F\n\nimport numpy as np\n\nfrom .. import transformation as T\nfrom ..transformation import utils as tu\nfrom ..utils import kernelFunction as utils\n\n\n\n# Loss base class (standard from PyTorch)\nclass _PairwiseImageLoss(th.nn.modules.Module):\n    def __init__(self, fixed_image, moving_image, fixed_mask=None, moving_mask=None, size_average=True, reduce=True):\n        super(_PairwiseImageLoss, self).__init__()\n        self._size_average = size_average\n        self._reduce = reduce\n        self._name = ""parent""\n\n        self._warped_moving_image = None\n        self._warped_moving_mask = None\n        self._weight = 1\n\n        self._moving_image = moving_image\n        self._moving_mask = moving_mask\n        self._fixed_image = fixed_image\n        self._fixed_mask = fixed_mask\n        self._grid = None\n\n        assert self._moving_image != None and self._fixed_image != None\n        # TODO allow different image size for each image in the future\n        assert self._moving_image.size == self._fixed_image.size\n        assert self._moving_image.device == self._fixed_image.device\n        assert len(self._moving_image.size) == 2 or len(self._moving_image.size) == 3\n\n        self._grid = T.utils.compute_grid(self._moving_image.size, dtype=self._moving_image.dtype,\n                                     device=self._moving_image.device)\n\n        self._dtype = self._moving_image.dtype\n        self._device = self._moving_image.device\n\n    @property\n    def name(self):\n        return self._name\n\n    def GetWarpedImage(self):\n        return self._warped_moving_image[0, 0, ...].detach().cpu()\n\n    def GetCurrentMask(self, displacement):\n        """"""\n        Computes a mask defining if pixels are warped outside the image domain, or if they fall into\n        a fixed image mask or a warped moving image mask.\n        return (Tensor): maks array\n        """"""\n        # exclude points which are transformed outside the image domain\n        mask = th.zeros_like(self._fixed_image.image, dtype=th.uint8, device=self._device)\n        for dim in range(displacement.size()[-1]):\n            mask += displacement[..., dim].gt(1) + displacement[..., dim].lt(-1)\n\n        mask = mask == 0\n\n        # and exclude points which are masked by the warped moving and the fixed mask\n        if not self._moving_mask is None:\n            self._warped_moving_mask = F.grid_sample(self._moving_mask.image, displacement)\n            self._warped_moving_mask = self._warped_moving_mask >= 0.5\n\n            # if either the warped moving mask or the fixed mask is zero take zero,\n            # otherwise take the value of mask\n            if not self._fixed_mask is None:\n                mask = th.where(((self._warped_moving_mask == 0) | (self._fixed_mask == 0)), th.zeros_like(mask), mask)\n            else:\n                mask = th.where((self._warped_moving_mask == 0), th.zeros_like(mask), mask)\n\n        return mask\n\n    def set_loss_weight(self, weight):\n        self._weight = weight\n\n    # conditional return\n    def return_loss(self, tensor):\n        if self._size_average and self._reduce:\n            return tensor.mean()*self._weight\n        if not self._size_average and self._reduce:\n            return tensor.sum()*self._weight\n        if not self.reduce:\n            return tensor*self._weight\n\n\nclass MSE(_PairwiseImageLoss):\n    r"""""" The mean square error loss is a simple and fast to compute point-wise measure\n    which is well suited for monomodal image registration.\n\n    .. math::\n         \\mathcal{S}_{\\text{MSE}} := \\frac{1}{\\vert \\mathcal{X} \\vert}\\sum_{x\\in\\mathcal{X}}\n          \\Big(I_M\\big(x+f(x)\\big) - I_F\\big(x\\big)\\Big)^2\n\n    Args:\n        fixed_image (Image): Fixed image for the registration\n        moving_image (Image): Moving image for the registration\n        size_average (bool): Average loss function\n        reduce (bool): Reduce loss function to a single value\n\n    """"""\n    def __init__(self, fixed_image, moving_image, fixed_mask=None, moving_mask=None, size_average=True, reduce=True):\n        super(MSE, self).__init__(fixed_image, moving_image, fixed_mask, moving_mask, size_average, reduce)\n\n        self._name = ""mse""\n\n        self.warped_moving_image = None\n\n    def forward(self, displacement):\n\n        # compute displacement field\n        displacement = self._grid + displacement\n\n        # compute current mask\n        mask = super(MSE, self).GetCurrentMask(displacement)\n\n        # warp moving image with dispalcement field\n        self.warped_moving_image = F.grid_sample(self._moving_image.image, displacement)\n\n        # compute squared differences\n        value = (self.warped_moving_image - self._fixed_image.image).pow(2)\n\n        # mask values\n        value = th.masked_select(value, mask)\n\n        return self.return_loss(value)\n\n\nclass NCC(_PairwiseImageLoss):\n    r"""""" The normalized cross correlation loss is a measure for image pairs with a linear\n         intensity relation.\n\n        .. math::\n            \\mathcal{S}_{\\text{NCC}} := \\frac{\\sum I_F\\cdot (I_M\\circ f)\n                   - \\sum\\text{E}(I_F)\\text{E}(I_M\\circ f)}\n                   {\\vert\\mathcal{X}\\vert\\cdot\\sum\\text{Var}(I_F)\\text{Var}(I_M\\circ f)}\n\n\n        Args:\n            fixed_image (Image): Fixed image for the registration\n            moving_image (Image): Moving image for the registration\n\n    """"""\n    def __init__(self, fixed_image, moving_image, fixed_mask=None, moving_mask=None):\n        super(NCC, self).__init__(fixed_image, moving_image, fixed_mask, moving_mask, False, False)\n\n        self._name = ""ncc""\n\n        self.warped_moving_image = th.empty_like(self._moving_image.image, dtype=self._dtype, device=self._device)\n\n    def forward(self, displacement):\n\n        # compute displacement field\n        displacement = self._grid + displacement\n\n        # compute current mask\n        mask = super(NCC, self).GetCurrentMask(displacement)\n\n        self._warped_moving_image = F.grid_sample(self._moving_image.image, displacement)\n\n        moving_image_valid = th.masked_select(self._warped_moving_image, mask)\n        fixed_image_valid = th.masked_select(self._fixed_image.image, mask)\n\n\n        value = -1.*th.sum((fixed_image_valid - th.mean(fixed_image_valid))*(moving_image_valid - th.mean(moving_image_valid)))\\\n                /th.sqrt(th.sum((fixed_image_valid - th.mean(fixed_image_valid))**2)*th.sum((moving_image_valid - th.mean(moving_image_valid))**2) + 1e-10)\n\n        return value\n\n\n""""""\n    Local Normaliced Cross Corelation Image Loss\n""""""\nclass LCC(_PairwiseImageLoss):\n    def __init__(self, fixed_image, moving_image,fixed_mask=None, moving_mask=None, sigma=[3], kernel_type=""box"", size_average=True, reduce=True):\n        super(LCC, self).__init__(fixed_image, moving_image, fixed_mask, moving_mask,  size_average, reduce)\n\n        self._name = ""lcc""\n        self.warped_moving_image = th.empty_like(self._moving_image.image, dtype=self._dtype, device=self._device)\n        self._kernel = None\n\n        dim = len(self._moving_image.size)\n        sigma = np.array(sigma)\n\n        if sigma.size != dim:\n            sigma_app = sigma[-1]\n            while sigma.size != dim:\n                sigma = np.append(sigma, sigma_app)\n\n        if kernel_type == ""box"":\n            kernel_size = sigma*2 + 1\n            self._kernel = th.ones(*kernel_size.tolist(), dtype=self._dtype, device=self._device) \\\n                           / float(np.product(kernel_size)**2)\n        elif kernel_type == ""gaussian"":\n            self._kernel = utils.gaussian_kernel(sigma, dim, asTensor=True, dtype=self._dtype, device=self._device)\n\n        self._kernel.unsqueeze_(0).unsqueeze_(0)\n\n        if dim == 2:\n            self._lcc_loss = self._lcc_loss_2d  # 2d lcc\n\n            self._mean_fixed_image = F.conv2d(self._fixed_image.image, self._kernel)\n            self._variance_fixed_image = F.conv2d(self._fixed_image.image.pow(2), self._kernel) \\\n                                         - (self._mean_fixed_image.pow(2))\n        elif dim == 3:\n            self._lcc_loss = self._lcc_loss_3d  # 3d lcc\n\n            self._mean_fixed_image = F.conv3d(self._fixed_image.image, self._kernel)\n            self._variance_fixed_image = F.conv3d(self._fixed_image.image.pow(2), self._kernel) \\\n                                         - (self._mean_fixed_image.pow(2))\n\n\n    def _lcc_loss_2d(self, warped_image, mask):\n\n\n        mean_moving_image = F.conv2d(warped_image, self._kernel)\n        variance_moving_image = F.conv2d(warped_image.pow(2), self._kernel) - (mean_moving_image.pow(2))\n\n        mean_fixed_moving_image = F.conv2d(self._fixed_image.image * warped_image, self._kernel)\n\n        cc = (mean_fixed_moving_image - mean_moving_image*self._mean_fixed_image)**2 \\\n             / (variance_moving_image*self._variance_fixed_image + 1e-10)\n\n        mask = F.conv2d(mask, self._kernel)\n        mask = mask == 0\n\n        return -1.0*th.masked_select(cc, mask)\n\n    def _lcc_loss_3d(self, warped_image, mask):\n\n        mean_moving_image = F.conv3d(warped_image, self._kernel)\n        variance_moving_image = F.conv3d(warped_image.pow(2), self._kernel) - (mean_moving_image.pow(2))\n\n        mean_fixed_moving_image = F.conv3d(self._fixed_image.image * warped_image, self._kernel)\n\n        cc = (mean_fixed_moving_image - mean_moving_image*self._mean_fixed_image)**2\\\n             /(variance_moving_image*self._variance_fixed_image + 1e-10)\n\n        mask = F.conv3d(mask, self._kernel)\n        mask = mask == 0\n\n        return -1.0 * th.masked_select(cc, mask)\n\n    def forward(self, displacement):\n\n        # compute displacement field\n        displacement = self._grid + displacement\n\n        # compute current mask\n        mask = super(LCC, self).GetCurrentMask(displacement)\n        mask = 1-mask\n        mask = mask.to(dtype=self._dtype, device=self._device)\n\n        self._warped_moving_image = F.grid_sample(self._moving_image.image, displacement)\n\n        return self.return_loss(self._lcc_loss(self._warped_moving_image, mask))\n\n\nclass MI(_PairwiseImageLoss):\n    r"""""" Implementation of the Mutual Information image loss.\n\n         .. math::\n            \\mathcal{S}_{\\text{MI}} := H(F, M) - H(F|M) - H(M|F)\n\n        Args:\n            fixed_image (Image): Fixed image for the registration\n            moving_image (Image): Moving image for the registration\n            bins (int): Number of bins for the intensity distribution\n            sigma (float): Kernel sigma for the intensity distribution approximation\n            spatial_samples (float): Percentage of pixels used for the intensity distribution approximation\n            background: Method to handle background pixels. None: Set background to the min value of image\n                                                            ""mean"": Set the background to the mean value of the image\n                                                            float: Set the background value to the input value\n            size_average (bool): Average loss function\n            reduce (bool): Reduce loss function to a single value\n\n    """"""\n    def __init__(self, fixed_image, moving_image, fixed_mask=None, moving_mask=None, bins=64, sigma=3,\n                 spatial_samples=0.1, background=None, size_average=True, reduce=True):\n        super(MI, self).__init__(fixed_image, moving_image, fixed_mask, moving_mask, size_average, reduce)\n\n        self._name = ""mi""\n\n        self._dim = fixed_image.ndim\n        self._bins = bins\n        self._sigma = 2*sigma**2\n        self._normalizer_1d = np.sqrt(2.0 * np.pi) * sigma\n        self._normalizer_2d = 2.0 * np.pi*sigma**2\n\n        if background is None:\n            self._background_fixed = th.min(fixed_image.image)\n            self._background_moving = th.min(moving_image.image)\n        elif background == ""mean"":\n            self._background_fixed = th.mean(fixed_image.image)\n            self._background_moving = th.mean(moving_image.image)\n        else:\n            self._background_fixed = background\n            self._background_moving = background\n\n        self._max_f = th.max(fixed_image.image)\n        self._max_m = th.max(moving_image.image)\n\n        self._spatial_samples = spatial_samples\n\n        self._bins_fixed_image = th.linspace(self._background_fixed, self._max_f, self.bins,\n                                             device=fixed_image.device, dtype=fixed_image.dtype).unsqueeze(1)\n\n        self._bins_moving_image = th.linspace(self._background_moving, self._max_m, self.bins,\n                                              device=fixed_image.device, dtype=fixed_image.dtype).unsqueeze(1)\n\n    @property\n    def sigma(self):\n        return self._sigma\n\n    @property\n    def bins(self):\n        return self._bins\n\n    @property\n    def bins_fixed_image(self):\n        return self._bins_fixed_image\n\n    def _compute_marginal_entropy(self, values, bins):\n\n        p = th.exp(-((values - bins).pow(2).div(self._sigma))).div(self._normalizer_1d)\n        p_n = p.mean(dim=1)\n        p_n = p_n/(th.sum(p_n) + 1e-10)\n\n        return -(p_n * th.log2(p_n + 1e-10)).sum(), p\n\n    def forward(self, displacement):\n\n        # compute displacement field\n        displacement = self._grid + displacement\n\n        # compute current mask\n        mask = super(MI, self).GetCurrentMask(displacement)\n\n        self._warped_moving_image = F.grid_sample(self._moving_image.image, displacement)\n\n        moving_image_valid = th.masked_select(self._warped_moving_image, mask)\n        fixed_image_valid = th.masked_select(self._fixed_image.image, mask)\n\n        mask = (fixed_image_valid > self._background_fixed) & (moving_image_valid > self._background_moving)\n\n        fixed_image_valid = th.masked_select(fixed_image_valid, mask)\n        moving_image_valid = th.masked_select(moving_image_valid, mask)\n\n        number_of_pixel = moving_image_valid.shape[0]\n\n        sample = th.zeros(number_of_pixel, device=self._fixed_image.device,\n                          dtype=self._fixed_image.dtype).uniform_() < self._spatial_samples\n\n        # compute marginal entropy fixed image\n        image_samples_fixed = th.masked_select(fixed_image_valid.view(-1), sample)\n\n        ent_fixed_image, p_f = self._compute_marginal_entropy(image_samples_fixed, self._bins_fixed_image)\n\n        # compute marginal entropy moving image\n        image_samples_moving = th.masked_select(moving_image_valid.view(-1), sample)\n\n        ent_moving_image, p_m = self._compute_marginal_entropy(image_samples_moving, self._bins_moving_image)\n\n        # compute joint entropy\n        p_joint = th.mm(p_f, p_m.transpose(0, 1)).div(self._normalizer_2d)\n        p_joint = p_joint / (th.sum(p_joint) + 1e-10)\n\n        ent_joint = -(p_joint * th.log2(p_joint + 1e-10)).sum()\n\n        return -(ent_fixed_image + ent_moving_image - ent_joint)\n\nclass NGF(_PairwiseImageLoss):\n    r"""""" Implementation of the Normalized Gradient Fields image loss.\n\n            Args:\n                fixed_image (Image): Fixed image for the registration\n                moving_image (Image): Moving image for the registration\n                fixed_mask (Tensor): Mask for the fixed image\n                moving_mask (Tensor): Mask for the moving image\n                epsilon (float): Regulariser for the gradient amplitude\n                size_average (bool): Average loss function\n                reduce (bool): Reduce loss function to a single value\n\n    """"""\n    def __init__(self, fixed_image, moving_image, fixed_mask=None, moving_mask=None, epsilon=1e-5,\n                 size_average=True,\n                 reduce=True):\n        super(NGF, self).__init__(fixed_image, moving_image, fixed_mask, moving_mask, size_average, reduce)\n\n        self._name = ""ngf""\n\n        self._dim = fixed_image.ndim\n        self._epsilon = epsilon\n\n        if self._dim == 2:\n            dx = (fixed_image.image[..., 1:, 1:] - fixed_image.image[..., :-1, 1:]) * fixed_image.spacing[0]\n            dy = (fixed_image.image[..., 1:, 1:] - fixed_image.image[..., 1:, :-1]) * fixed_image.spacing[1]\n\n            if self._epsilon is None:\n                with th.no_grad():\n                    self._epsilon = th.mean(th.abs(dx) + th.abs(dy))\n\n            norm = th.sqrt(dx.pow(2) + dy.pow(2) + self._epsilon ** 2)\n\n            self._ng_fixed_image = F.pad(th.cat((dx, dy), dim=1) / norm, (0, 1, 0, 1))\n\n            self._ngf_loss = self._ngf_loss_2d\n        else:\n            dx = (fixed_image.image[..., 1:, 1:, 1:] - fixed_image.image[..., :-1, 1:, 1:]) * fixed_image.spacing[0]\n            dy = (fixed_image.image[..., 1:, 1:, 1:] - fixed_image.image[..., 1:, :-1, 1:]) * fixed_image.spacing[1]\n            dz = (fixed_image.image[..., 1:, 1:, 1:] - fixed_image.image[..., 1:, 1:, :-1]) * fixed_image.spacing[2]\n\n            if self._epsilon is None:\n                with th.no_grad():\n                    self._epsilon = th.mean(th.abs(dx) + th.abs(dy) + th.abs(dz))\n\n            norm = th.sqrt(dx.pow(2) + dy.pow(2) + dz.pow(2) + self._epsilon ** 2)\n\n            self._ng_fixed_image = F.pad(th.cat((dx, dy, dz), dim=1) / norm, (0, 1, 0, 1, 0, 1))\n\n            self._ngf_loss = self._ngf_loss_3d\n\n    def _ngf_loss_2d(self, warped_image):\n\n        dx = (warped_image[..., 1:, 1:] - warped_image[..., :-1, 1:]) * self._moving_image.spacing[0]\n        dy = (warped_image[..., 1:, 1:] - warped_image[..., 1:, :-1]) * self._moving_image.spacing[1]\n\n        norm = th.sqrt(dx.pow(2) + dy.pow(2) + self._epsilon ** 2)\n\n        return F.pad(th.cat((dx, dy), dim=1) / norm, (0, 1, 0, 1))\n\n    def _ngf_loss_3d(self, warped_image):\n\n        dx = (warped_image[..., 1:, 1:, 1:] - warped_image[..., :-1, 1:, 1:]) * self._moving_image.spacing[0]\n        dy = (warped_image[..., 1:, 1:, 1:] - warped_image[..., 1:, :-1, 1:]) * self._moving_image.spacing[1]\n        dz = (warped_image[..., 1:, 1:, 1:] - warped_image[..., 1:, 1:, :-1]) * self._moving_image.spacing[2]\n\n        norm = th.sqrt(dx.pow(2) + dy.pow(2) + dz.pow(2) + self._epsilon ** 2)\n\n        return F.pad(th.cat((dx, dy, dz), dim=1) / norm, (0, 1, 0, 1, 0, 1))\n\n    def forward(self, displacement):\n\n        # compute displacement field\n        displacement = self._grid + displacement\n\n        # compute current mask\n        mask = super(NGF, self).GetCurrentMask(displacement)\n\n        self._warped_moving_image = F.grid_sample(self._moving_image.image, displacement)\n\n        # compute the gradient of the warped image\n        ng_warped_image = self._ngf_loss(self._warped_moving_image)\n\n        value = 0\n        for dim in range(self._dim):\n            value = value + ng_warped_image[:, dim, ...] * self._ng_fixed_image[:, dim, ...]\n\n        value = 0.5 * th.masked_select(-value.pow(2), mask)\n\n        return self.return_loss(value)\n\n\nclass SSIM(_PairwiseImageLoss):\n    r"""""" Implementation of the Structual Similarity Image Measure loss.\n\n        Args:\n                fixed_image (Image): Fixed image for the registration\n                moving_image (Image): Moving image for the registration\n                fixed_mask (Tensor): Mask for the fixed image\n                moving_mask (Tensor): Mask for the moving image\n                sigma (float): Sigma for the kernel\n                kernel_type (string): Type of kernel i.e. gaussian, box\n                alpha (float): Controls the influence of the luminance value\n                beta (float): Controls the influence of the contrast value\n                gamma (float): Controls the influence of the structure value\n                c1 (float): Numerical constant for the luminance value\n                c2 (float): Numerical constant for the contrast value\n                c3 (float): Numerical constant for the structure value\n                size_average (bool): Average loss function\n                reduce (bool): Reduce loss function to a single value\n    """"""\n    def __init__(self, fixed_image, moving_image, fixed_mask=None, moving_mask=None,\n                 sigma=[3], dim=2, kernel_type=""box"", alpha=1, beta=1, gamma=1, c1=0.00001, c2=0.00001,\n                 c3=0.00001, size_average=True, reduce=True, ):\n        super(SSIM, self).__init__(fixed_image, moving_image, fixed_mask, moving_mask, size_average, reduce)\n\n        self._alpha = alpha\n        self._beta = beta\n        self._gamma = gamma\n\n        self._c1 = c1\n        self._c2 = c2\n        self._c3 = c3\n\n        self._name = ""sim""\n        self._kernel = None\n\n        dim = dim\n        sigma = np.array(sigma)\n\n        if sigma.size != dim:\n            sigma_app = sigma[-1]\n            while sigma.size != dim:\n                sigma = np.append(sigma, sigma_app)\n\n        if kernel_type == ""box"":\n            kernel_size = sigma * 2 + 1\n            self._kernel = th.ones(*kernel_size.tolist()) \\\n                           / float(np.product(kernel_size) ** 2)\n        elif kernel_type == ""gaussian"":\n            self._kernel = utils.gaussian_kernel(sigma, dim, asTensor=True)\n\n        self._kernel.unsqueeze_(0).unsqueeze_(0)\n\n        self._kernel = self._kernel.to(dtype=self._dtype, device=self._device)\n\n        # calculate mean and variance of the fixed image\n        self._mean_fixed_image = F.conv2d(self._fixed_image.image, self._kernel)\n        self._variance_fixed_image = F.conv2d(self._fixed_image.image.pow(2), self._kernel) \\\n                                     - (self._mean_fixed_image.pow(2))\n\n    def forward(self, displacement):\n        # compute displacement field\n        displacement = self._grid + displacement\n\n        # compute current mask\n        mask = super(SSIM, self).GetCurrentMask(displacement)\n        mask = 1 - mask\n        mask = mask.to(dtype=self._dtype, device=self._device)\n\n        self._warped_moving_image = F.grid_sample(self._moving_image.image, displacement)\n\n        mask = F.conv2d(mask, self._kernel)\n        mask = mask == 0\n\n        mean_moving_image = F.conv2d(self._warped_moving_image, self._kernel)\n\n        variance_moving_image = F.conv2d(self._warped_moving_image.pow(2), self._kernel) - (\n            mean_moving_image.pow(2))\n\n        mean_fixed_moving_image = F.conv2d(self._fixed_image.image * self._warped_moving_image, self._kernel)\n\n        covariance_fixed_moving = (mean_fixed_moving_image - mean_moving_image * self._mean_fixed_image)\n\n        luminance = (2 * self._mean_fixed_image * mean_moving_image + self._c1) / \\\n                    (self._mean_fixed_image.pow(2) + mean_moving_image.pow(2) + self._c1)\n\n        contrast = (2 * th.sqrt(self._variance_fixed_image + 1e-10) * th.sqrt(\n            variance_moving_image + 1e-10) + self._c2) / \\\n                   (self._variance_fixed_image + variance_moving_image + self._c2)\n\n        structure = (covariance_fixed_moving + self._c3) / \\\n                    (th.sqrt(self._variance_fixed_image + 1e-10) * th.sqrt(\n                        variance_moving_image + 1e-10) + self._c3)\n\n        sim = luminance.pow(self._alpha) * contrast.pow(self._beta) * structure.pow(self._gamma)\n\n        value = -1.0 * th.masked_select(sim, mask)\n\n        return self.return_loss(value)\n\n'"
airlab/registration/__init__.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom .registration import PairwiseRegistration, DemonsRegistraion\n\n__all__ = [\'PairwiseRegistration\', \'DemonsRegistraion\']'"
airlab/registration/registration.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nfrom numpy import inf,max\n\nclass _Registration():\n    def __init__(self, verbose=True):\n        # transformation of the image\n        self._transformation = None\n\n        # image similarity measure\n        self._image_loss = None\n\n        # optimizer\n        self._optimizer = None\n        self._number_of_iterations = 100\n\n        self._displacement = None\n\n        self._verbose=verbose\n        self.loss=inf\n\n    def set_optimizer(self, optimizer):\n        self._optimizer = optimizer\n\n    def set_number_of_iterations(self, number_of_iterations):\n        self._number_of_iterations = number_of_iterations\n\n    def set_transformation(self, transformation):\n        self._transformation = transformation\n\n    def set_image_loss(self, loss):\n        self._image_loss = loss\n\n\nclass _PairwiseRegistration(_Registration):\n    def __init__(self, verbose=True):\n        super(_PairwiseRegistration, self).__init__(verbose=verbose)\n\n        # regulariser on the displacement\n        self._regulariser_displacement = []\n\n        # regulariser on the parameters\n        self._regulariser_parameter = []\n\n    def set_regulariser_displacement(self, regulariser_displacement):\n        self._regulariser_displacement = regulariser_displacement\n\n    def set_regulariser_parameter(self, regulariser_parameter):\n        self._regulariser_parameter = regulariser_parameter\n\n\nclass _GroupwiseRegistration(_Registration):\n    def __init__(self, verbose=True):\n        super(_GroupwiseRegistration, self).__init__(verbose=verbose)\n\n        self._images = None\n\n    def SetImages(self, images):\n        self._images = images\n\n\nclass _ImageSeriesRegistration(_Registration):\n    def __init__(self, verbose=True):\n        super(_GroupwiseRegistration, self).__init__(verbose=verbose)\n\n        self._image_series = None\n        self._fixed_image = None\n\n    def SetImageSeries(self, images):\n        self._images = images\n\n    def SetFixedImage(self, image):\n        self._fixed_image = image\n\n\nclass PairwiseRegistration(_PairwiseRegistration):\n    def __init__(self, verbose=True):\n        super(PairwiseRegistration, self).__init__(verbose=verbose)\n\n    def _closure(self):\n        self._optimizer.zero_grad()\n\n        displacement = self._transformation()\n\n        # compute the image loss\n        lossList = []\n        loss_names = []\n        for image_loss in self._image_loss:\n             lossList.append(image_loss(displacement))\n             loss_names.append(image_loss.name)\n\n        # compute the regularisation loss on the displacement\n        for reg_disp in self._regulariser_displacement:\n            lossList.append(reg_disp(displacement))\n            loss_names.append(reg_disp.name)\n\n        # compute the regularisation loss on the parameter\n        for reg_param in self._regulariser_parameter:\n            lossList.append(reg_param(self._transformation.named_parameters()))\n            loss_names.append(reg_param.name)\n\n        if self._verbose:\n            for loss_value, loss_name in zip(lossList, loss_names):\n                print(str(loss_name) + "": "" + str(loss_value.data.item()) + "" "", end=\'\', flush=True)\n            print("""")\n\n        # sum up all loss terms\n        loss = sum(lossList)\n\n        loss.backward()\n\n        return loss\n\n    def start(self, EarlyStopping=False, StopPatience=10):\n\n        if EarlyStopping:\n            from copy import deepcopy\n            n = 0\n            try:\n                self.loss\n            except:\n                self.loss=inf\n\n        for iter_index in range(self._number_of_iterations):\n            if self._verbose:\n                print(str(iter_index) + "" "", end=\'\', flush=True)\n            loss = self._optimizer.step(self._closure)\n            if EarlyStopping:\n                if loss < self.loss:\n                    n = 0\n                    self.loss=loss\n                    best=deepcopy(self._transformation)\n                else:\n                    n += 1\n                if n > StopPatience:\n                    self._transformation = best\n                    return\n        self.loss = loss\n\n\nclass DemonsRegistraion(_Registration):\n    def __init__(self, verbose=True):\n        super(DemonsRegistraion, self).__init__(verbose=verbose)\n\n        # regulariser on the displacement\n        self._regulariser = []\n\n    def set_regulariser(self, regulariser):\n            self._regulariser = regulariser\n\n    def _closure(self):\n        self._optimizer.zero_grad()\n\n        displacement = self._transformation()\n\n        # compute the image loss\n        lossList = []\n        loss_names = []\n        for image_loss in self._image_loss:\n            lossList.append(image_loss(displacement))\n            loss_names.append(image_loss.name)\n\n        if self._verbose:\n            for loss_value, loss_name in zip(lossList, loss_names):\n                print(str(loss_name) + "": "" + str(loss_value.data.item()) + "" "", end=\'\', flush=True)\n\n            print("""")\n\n        # sum up all loss terms\n        loss = sum(lossList)\n\n        loss.backward()\n\n        return loss\n\n    def start(self):\n\n        for iter_index in range(self._number_of_iterations):\n            if self._verbose:\n                print(str(iter_index) + "" "", end=\'\', flush=True)\n\n            loss = self._optimizer.step(self._closure)\n\n            for regulariser in self._regulariser:\n                regulariser.regularise(self._transformation.parameters())\n\n\n'"
airlab/regulariser/__init__.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom . import parameter\nfrom . import demons\nfrom . import displacement\n\n'"
airlab/regulariser/demons.py,1,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nimport torch.nn.functional as F\nimport numpy as np\nfrom ..utils import graph as G\nfrom ..utils import matrix as mat\nfrom ..utils import kernelFunction as utils\nfrom ..utils import image as iu\n\nclass _DemonsRegulariser():\n    def __init__(self, pixel_spacing, dtype=th.float32, device=\'cpu\'):\n        super(_DemonsRegulariser, self).__init__()\n\n        self._dtype = dtype\n        self._device = device\n        self._weight = 1\n        self._dim = len(pixel_spacing)\n        self._pixel_spacing = pixel_spacing\n        self.name = ""parent""\n\n\n\nclass GaussianRegulariser(_DemonsRegulariser):\n    def __init__(self, pixel_spacing, sigma, dtype=th.float32, device=\'cpu\'):\n        super(GaussianRegulariser, self).__init__(pixel_spacing, dtype=dtype, device=device)\n\n        sigma = np.array(sigma)\n\n        if sigma.size != self._dim:\n            sigma_app = sigma[-1]\n            while sigma.size != self._dim:\n                sigma = np.append(sigma, sigma_app)\n\n\n        self._kernel = utils.gaussian_kernel(sigma, self._dim, asTensor=True, dtype=dtype, device=device)\n\n        self._padding = (np.array(self._kernel.size()) - 1) / 2\n        self._padding = self._padding.astype(dtype=int).tolist()\n\n        self._kernel.unsqueeze_(0).unsqueeze_(0)\n        self._kernel = self._kernel.expand(self._dim, *((np.ones(self._dim + 1, dtype=int) * -1).tolist()))\n        self._kernel = self._kernel.to(dtype=dtype, device=self._device)\n\n        if self._dim == 2:\n            self._regulariser = self._regularise_2d\n        elif self._dim == 3:\n            self._regulariser = self._regularise_3d\n\n\n    def _regularise_2d(self, data):\n\n        data.data = data.data.unsqueeze(0)\n        data.data = F.conv2d(data.data, self._kernel.contiguous(), padding=self._padding, groups=2)\n        data.data = data.data.squeeze()\n\n\n    def _regularise_3d(self, data):\n\n        data.data = data.data.unsqueeze(0)\n        data.data = F.conv3d(data.data, self._kernel, padding=self._padding, groups=3)\n        data.data = data.data.squeeze()\n\n    def regularise(self, data):\n        for parameter in data:\n            # no gradient calculation for the demons regularisation\n            with th.no_grad():\n                self._regulariser(parameter)\n\n\n\nclass _GraphEdgeWeightUpdater():\n    def __init__(self, pixel_spacing, edge_window=0.9, edge_mean=False):\n\n        self._edge_window = edge_window\n        self._edge_mean = edge_mean\n        self._laplace_matrix = None\n        self._dim = len(pixel_spacing)\n        self._pixel_spacing = pixel_spacing\n        self._collapse_threshold = 0\n        self._detect_node_collapse = True\n\n    def detect_node_collapse(self, detect):\n        self._detect_node_collapse = detect\n\n\n    def set_laplace_matrix(self, laplace_matrix):\n        self._laplace_matrix = laplace_matrix\n\n    def remove_node_collapse(self):\n            for i, diag in enumerate(self._laplace_matrix.diag_elements):\n                node_value = self._laplace_matrix.main_diag[diag.edge_index[-1]]\n                index = th.abs(node_value) < self._collapse_threshold\n                diag.edge_values[index] = 1\n\n\n\n\nclass EdgeUpdaterIntensities(_GraphEdgeWeightUpdater):\n    def __init__(self, pixel_spacing, image, scale=1, edge_window=0.9, edge_mean=False):\n        super(EdgeUpdaterIntensities, self).__init__(pixel_spacing, edge_window, edge_mean)\n\n        self._image = image\n        self._scale = scale\n\n    def set_scale(self, sale):\n        self._scale = scale\n\n    def update(self, data):\n\n        if self._dim == 2:\n            for i, diag in enumerate(self._laplace_matrix.diag_elements):\n                one = th.zeros(self._dim, dtype=th.int64, device=self._image.device)\n                one[i] = 1\n\n                intensyties_A = self._image[0, 0, diag.edge_index[0], diag.edge_index[1]]\n                intensyties_B = self._image[0, 0, diag.edge_index[0] - one[0], diag.edge_index[1] - one[1]]\n\n                diag.edge_values = (th.exp(-self._scale*th.abs(intensyties_A - intensyties_B)))\n\n        elif self._dim == 3:\n            for i, diag in enumerate(self._laplace_matrix.diag_elements):\n                one = th.zeros(self._dim, dtype=th.int64, device=self._image.device)\n                one[i] = 1\n\n                intensyties_A = self._image[0, 0, diag.edge_index[0], diag.edge_index[1], diag.edge_index[2]]\n                intensyties_B = self._image[0, 0, diag.edge_index[0] - one[0], diag.edge_index[1] - one[1],\n                                            diag.edge_index[2] - one[2]]\n\n                diag.edge_values = (th.exp(-self._scale*th.abs(intensyties_A - intensyties_B)))\n\n        # update the laplace matrix\n        self._laplace_matrix.update()\n\n\n\nclass EdgeUpdaterDisplacementIntensities(_GraphEdgeWeightUpdater):\n    def __init__(self, pixel_spacing, image, edge_window=0.9, edge_mean=False):\n        super(EdgeUpdaterDisplacementIntensities, self).__init__(pixel_spacing, edge_window, edge_mean)\n\n        self._image = image[0, 0, ...]\n\n        self._image_gradient = None\n        self._scale_int_diff = 1\n        self._scale_disp_diff = 1\n        self._scale_disp = 1\n\n        if self._dim == 2:\n            data_pad = th.nn.functional.pad(self._image, pad=(1, 0, 1, 0))  # , mode=\'replicate\'\n            dx = data_pad[1:, 1:] - data_pad[:-1, 1:]\n            dy = data_pad[1:, 1:] - data_pad[:1, -1:]\n\n            self._image_gradient = th.stack((dx, dy), 2)\n\n    def update(self, data):\n\n        if self._dim == 2:\n\n            for i, diag in enumerate(self._laplace_matrix.diag_elements):\n                one = th.zeros(self._dim, dtype=th.int64, device=self._image.device)\n                one[i] = 1\n\n                intensyties_A = self._image[diag.edge_index[0], diag.edge_index[1]]\n                intensyties_B = self._image[diag.edge_index[0] - one[0], diag.edge_index[1] - one[1]]\n\n                intensity_diff = th.exp(-th.abs(intensyties_A - intensyties_B)*self._scale_int_diff)\n\n                del intensyties_A, intensyties_B\n\n                displacement_A = data[:, diag.edge_index[0], diag.edge_index[1]]\n                displacement_B = data[:, diag.edge_index[0] - one[0], diag.edge_index[1] - one[1]]\n\n                displacement_diff = displacement_A - displacement_B\n                displacement_diff = th.sqrt(displacement_diff[0, :]**2 + displacement_diff[1, :]**2)\n                displacement_diff = th.exp(-self._scale_disp_diff*displacement_diff)\n\n                norm_disp_A = th.sqrt(displacement_A[0, ...]**2 + displacement_A[1, ...]**2)\n                norm_disp_B = th.sqrt(displacement_B[0, ...]**2 + displacement_B[1, ...]**2)\n\n                image_gradient_A = self._image_gradient[diag.edge_index[0], diag.edge_index[1], :]\n                image_gradient_B = self._image_gradient[diag.edge_index[0] - one[0], diag.edge_index[1] - one[1], :]\n\n                norm_A = th.sqrt(image_gradient_A[..., 0]**2 + image_gradient_A[..., 1]**2)\n                norm_B = th.sqrt(image_gradient_B[..., 0]**2 + image_gradient_B[..., 1]**2)\n\n                max_norm = th.max(norm_A, norm_B)\n\n                max_grad = th.zeros_like(image_gradient_A)\n                index = (norm_A - max_norm) == 0\n                max_grad[index] = image_gradient_A[index]\n                max_grad[1 - index] = image_gradient_B[1 - index]\n\n                del index, image_gradient_A, image_gradient_B\n\n                phi_A = th.div(th.sum(th.mul(max_grad, displacement_A.t()), dim=1), th.mul(norm_disp_A, max_norm) + 1e-10)\n                phi_B = th.div(th.sum(th.mul(max_grad, displacement_B.t()), dim=1), th.mul(norm_disp_B, max_norm) + 1e-10)\n\n                weight = th.mul(intensity_diff,displacement_diff) + (1-intensity_diff)*((phi_A + phi_B)*0.5)\n                weight = weight*(1 - self._scale_disp) + displacement_diff*self._scale_disp\n\n                if self._edge_mean:\n                    diag.edge_values = diag.edge_values*self._edge_window + th.round(weight)*(1. - self._edge_window)\n                else:\n                    diag.edge_values = weight\n\n        elif self._dim == 3:\n            for i, diag in enumerate(self._laplace_matrix.diag_elements):\n                one = th.zeros(self._dim, dtype=th.int64, device=self._image.device)\n                one[i] = 1\n\n                intensyties_A = self._image[diag.edge_index[0], diag.edge_index[1]]\n                intensyties_B = self._image[diag.edge_index[0] - one[0], diag.edge_index[1] - one[1],\n                                            diag.edge_index[2] - one[2]]\n\n                intensity_diff = th.exp(-th.abs(intensyties_A - intensyties_B)*self._scale_int_diff)\n\n                del intensyties_A, intensyties_B\n\n                displacement_A = data[:, diag.edge_index[0], diag.edge_index[1]]\n                displacement_B = data[:, diag.edge_index[0] - one[0], diag.edge_index[1] - one[1],\n                                      diag.edge_index[2] - one[2]]\n\n                displacement_diff = displacement_A - displacement_B\n                displacement_diff = th.sqrt(displacement_diff[0, :]**2 + displacement_diff[1, :]**2 + displacement_diff[2, :]**2)\n                displacement_diff = th.exp(-self._scale_disp_diff*displacement_diff)\n\n                norm_disp_A = th.sqrt(displacement_A[0, ...]**2 + displacement_A[1, ...]**2 + displacement_A[2, ...]**2)\n                norm_disp_B = th.sqrt(displacement_B[0, ...]**2 + displacement_B[1, ...]**2 + displacement_B[2, ...]**2)\n\n                image_gradient_A = self._image_gradient[diag.edge_index[0], diag.edge_index[1], :]\n                image_gradient_B = self._image_gradient[diag.edge_index[0] - one[0], diag.edge_index[1] - one[1],\n                                                        diag.edge_index[2] - one[2], :]\n\n                norm_A = th.sqrt(image_gradient_A[..., 0]**2 + image_gradient_A[..., 1]**2 + image_gradient_A[..., 2]**2)\n                norm_B = th.sqrt(image_gradient_B[..., 0]**2 + image_gradient_B[..., 1]**2 + image_gradient_A[..., 2]**2)\n\n                max_norm = th.max(norm_A, norm_B)\n\n                del norm_A, norm_B\n\n                max_grad = th.zeros_like(image_gradient_A)\n                index = (norm_A - max_norm) == 0\n                max_grad[index] = image_gradient_A[index]\n                max_grad[1 - index] = image_gradient_B[1 - index]\n\n                del index, image_gradient_A, image_gradient_B\n\n                phi_A = th.div(th.sum(th.mul(max_grad, displacement_A.t()), dim=1), th.mul(norm_disp_A, max_norm) + 1e-10)\n                phi_B = th.div(th.sum(th.mul(max_grad, displacement_B.t()), dim=1), th.mul(norm_disp_B, max_norm) + 1e-10)\n\n                weight = th.mul(intensity_diff,displacement_diff) + (1-intensity_diff)*((phi_A + phi_B)*0.5)\n                weight = weight*(1 - self._scale_disp) + displacement_diff*self._scale_disp\n\n                if self._edge_mean:\n                    diag.edge_values = diag.edge_values*self._edge_window + th.round(weight)*(1. - self._edge_window)\n                else:\n                    diag.edge_values = weight\n\n        # remove collapsed nodes\n        if self._detect_node_collapse:\n            self.remove_node_collapse()\n\n\n\n\n\nclass GraphDiffusionRegulariser(_DemonsRegulariser):\n    def __init__(self, image_size, pixel_spacing, edge_updater, phi=1, dtype=th.float32, device=\'cpu\'):\n        super(GraphDiffusionRegulariser, self).__init__(pixel_spacing, dtype=dtype, device=device)\n\n        self._graph = G.Graph(image_size, dtype=dtype, device=device)\n\n        self._edge_updater = edge_updater\n        self._edge_updater.set_laplace_matrix(self._graph.laplace_matrix)\n\n        self._phi = phi\n\n        self._krylov_dim = 30\n\n        self._image_size = image_size\n\n    def set_krylov_dim(self, krylov_dim):\n        self._krylov_dim = krylov_dim\n\n    def get_edge_image(self):\n        main_diag_laplace = th.reshape(self._graph.laplace_matrix.main_diag, self._image_size)\n\n        return iu.Image(main_diag_laplace.unsqueeze_(0).unsqueeze(0), self._image_size, self._pixel_spacing, th.zeros(len(self._image_size))) # only zero origin supported yet\n\n\n\n    def regularise(self, data):\n        for parameter in data:\n            # no gradient calculation for the demons regularisation\n            with th.no_grad():\n                dim = parameter.size()[0]\n\n                # compute the graph diffusion regularisation for each dimension\n                for i in range(dim):\n                    mat.expm_krylov(self._graph.laplace_matrix, parameter.data[i, ...].view(-1),\n                                    phi=self._phi, krylov_dim=self._krylov_dim)\n\n                # update the edge weights on the curren data\n                self._edge_updater.update(parameter.data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
airlab/regulariser/displacement.py,1,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nimport torch.nn.functional as F\n\nimport numpy as np\n\n# Regulariser base class (standard from PyTorch)\nclass _Regulariser(th.nn.modules.Module):\n    def __init__(self, pixel_spacing, size_average=True, reduce=True):\n        super(_Regulariser, self).__init__()\n        self._size_average = size_average\n        self._reduce = reduce\n        self._weight = 1\n        self._dim = len(pixel_spacing)\n        self._pixel_spacing = pixel_spacing\n        self.name = ""parent""\n        self._mask = None\n\n    def SetWeight(self, weight):\n        print(""SetWeight is deprecated. Use set_weight instead."")\n        self.set_weight(weight)\n\n    def set_weight(self, weight):\n        self._weight = weight\n\n    def set_mask(self, mask):\n        self._mask = mask\n\n    def _mask_2d(self, df):\n        if not self._mask is None:\n            nx, ny, d = df.shape\n            return df * self._mask.image.squeeze()[:nx,:ny].unsqueeze(-1).repeat(1,1,d)\n        else:\n            return df\n\n    def _mask_3d(self, df):\n        if not self._mask is None:\n            nx, ny, nz, d = df.shape\n            return df * self._mask.image.squeeze()[:nx,:ny,:nz].unsqueeze(-1).repeat(1,1,1,d)\n        else:\n            return df\n\n    # conditional return\n    def return_loss(self, tensor):\n        if self._size_average and self._reduce:\n            return self._weight*tensor.mean()\n        if not self._size_average and self._reduce:\n            return self._weight*tensor.sum()\n        if not self._reduce:\n            return self._weight*tensor\n\n""""""\n    Isotropic TV regularisation\n""""""\nclass IsotropicTVRegulariser(_Regulariser):\n    def __init__(self, pixel_spacing, size_average=True, reduce=True):\n        super(IsotropicTVRegulariser, self).__init__(pixel_spacing, size_average, reduce)\n\n        self.name = ""isoTV""\n\n        if self._dim == 2:\n            self._regulariser = self._isotropic_TV_regulariser_2d # 2d regularisation\n        elif self._dim == 3:\n            self._regulariser = self._isotropic_TV_regulariser_3d # 3d regularisation\n\n    def _isotropic_TV_regulariser_2d(self, displacement):\n        dx = (displacement[1:, 1:, :] - displacement[:-1, 1:, :]).pow(2)*self._pixel_spacing[0]\n        dy = (displacement[1:, 1:, :] - displacement[1:, :-1, :]).pow(2)*self._pixel_spacing[1]\n\n        return self._mask_2d(F.pad(dx + dy, (0,1,0,1)))\n\n    def _isotropic_TV_regulariser_3d(self, displacement):\n        dx = (displacement[1:, 1:, 1:, :] - displacement[:-1, 1:, 1:, :]).pow(2)*self._pixel_spacing[0]\n        dy = (displacement[1:, 1:, 1:, :] - displacement[1:, :-1, 1:, :]).pow(2)*self._pixel_spacing[1]\n        dz = (displacement[1:, 1:, 1:, :] - displacement[1:, 1:, :-1, :]).pow(2)*self._pixel_spacing[2]\n\n        return self._mask_3d(F.pad(dx + dy + dz, (0,1,0,1,0,1)))\n\n    def forward(self, displacement):\n\n        # set the supgradient to zeros\n        value = self._regulariser(displacement)\n        mask = value > 0\n        value[mask] = th.sqrt(value[mask])\n\n        return self.return_loss(value)\n\n""""""\n    TV regularisation \n""""""\nclass TVRegulariser(_Regulariser):\n    def __init__(self, pixel_spacing, size_average=True, reduce=True):\n        super(TVRegulariser, self).__init__(pixel_spacing, size_average, reduce)\n\n        self.name = ""TV""\n\n        if self._dim == 2:\n            self._regulariser = self._TV_regulariser_2d  # 2d regularisation\n        elif self._dim == 3:\n            self._regulariser = self._TV_regulariser_3d  # 3d regularisation\n\n    def _TV_regulariser_2d(self, displacement):\n        dx = th.abs(displacement[1:, 1:, :] - displacement[:-1, 1:, :])*self._pixel_spacing[0]\n        dy = th.abs(displacement[1:, 1:, :] - displacement[1:, :-1, :])*self._pixel_spacing[1]\n\n        return self._mask_2d(F.pad(dx + dy, (0, 1, 0, 1)))\n\n    def _TV_regulariser_3d(self, displacement):\n        dx = th.abs(displacement[1:, 1:, 1:, :] - displacement[:-1, 1:, 1:, :])*self._pixel_spacing[0]\n        dy = th.abs(displacement[1:, 1:, 1:, :] - displacement[1:, :-1, 1:, :])*self._pixel_spacing[1]\n        dz = th.abs(displacement[1:, 1:, 1:, :] - displacement[1:, 1:, :-1, :])*self._pixel_spacing[2]\n\n        return self._mask_3d(F.pad(dx + dy + dz, (0, 1, 0, 1, 0, 1)))\n\n    def forward(self, displacement):\n        return self.return_loss(self._regulariser(displacement))\n\n\n""""""\n    Diffusion regularisation \n""""""\nclass DiffusionRegulariser(_Regulariser):\n    def __init__(self, pixel_spacing, size_average=True, reduce=True):\n        super(DiffusionRegulariser, self).__init__(pixel_spacing, size_average, reduce)\n\n        self.name = ""L2""\n\n        if self._dim == 2:\n            self._regulariser = self._l2_regulariser_2d  # 2d regularisation\n        elif self._dim == 3:\n            self._regulariser = self._l2_regulariser_3d  # 3d regularisation\n\n    def _l2_regulariser_2d(self, displacement):\n        dx = (displacement[1:, 1:, :] - displacement[:-1, 1:, :]).pow(2) * self._pixel_spacing[0]\n        dy = (displacement[1:, 1:, :] - displacement[1:, :-1, :]).pow(2) * self._pixel_spacing[1]\n\n        return self._mask_2d(F.pad(dx + dy, (0, 1, 0, 1)))\n\n    def _l2_regulariser_3d(self, displacement):\n        dx = (displacement[1:, 1:, 1:, :] - displacement[:-1, 1:, 1:, :]).pow(2) * self._pixel_spacing[0]\n        dy = (displacement[1:, 1:, 1:, :] - displacement[1:, :-1, 1:, :]).pow(2) * self._pixel_spacing[1]\n        dz = (displacement[1:, 1:, 1:, :] - displacement[1:, 1:, :-1, :]).pow(2) * self._pixel_spacing[2]\n\n        return self._mask_3d(F.pad(dx + dy + dz, (0, 1, 0, 1, 0, 1)))\n\n    def forward(self, displacement):\n        return self.return_loss(self._regulariser(displacement))\n\n\n""""""\n    Sparsity regularisation \n""""""\nclass SparsityRegulariser(_Regulariser):\n    def __init__(self, size_average=True, reduce=True):\n        super(SparsityRegulariser, self).__init__([0], size_average, reduce)\n\n    def forward(self, displacement):\n        return self.return_loss(th.abs(displacement))\n\n\n\n\n'"
airlab/regulariser/parameter.py,1,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nimport torch.nn.functional as F\n\nimport numpy as np\n\n# Regulariser base class (standard from PyTorch)\nclass _ParameterRegulariser(th.nn.modules.Module):\n    def __init__(self, parameter_name, size_average=True, reduce=True):\n        super(_ParameterRegulariser, self).__init__()\n        self._size_average = size_average\n        self._reduce = reduce\n        self._weight = 1\n        self.name = ""parent""\n        self._parameter_name = parameter_name\n\n    def SetWeight(self, weight):\n        print(""SetWeight is deprecated. Use set_weight instead."")\n        self.set_weight(weight)\n\n    def set_weight(self, weight):\n        self._weight = weight\n\n    # conditional return\n    def return_loss(self, tensor):\n        if self._size_average and self._reduce:\n            return self._weight*tensor.mean()\n        if not self._size_average and self._reduce:\n            return self._weight*tensor.sum()\n        if not self._reduce:\n            return self._weight*tensor\n\n\n""""""\n    Base class for spatial parameter regulariser\n""""""\nclass _SpatialParameterRegulariser(_ParameterRegulariser):\n    def __init__(self, parameter_name, scaling=[1], size_average=True, reduce=True):\n        super(_SpatialParameterRegulariser, self).__init__(parameter_name, size_average, reduce)\n\n        self._dim = len(scaling)\n        self._scaling = scaling\n        if len(scaling) == 1:\n            self._scaling = np.ones(self._dim)*self._scaling[0]\n\n        self.name = ""parent""\n\n    # conditional return\n    def return_loss(self, tensor):\n        if self._size_average and self._reduce:\n            return self._weight*tensor.mean()\n        if not self._size_average and self._reduce:\n            return self._weight*tensor.sum()\n        if not self._reduce:\n            return self._weight*tensor\n\n""""""\n    Isotropic TV regularisation\n""""""\nclass IsotropicTVRegulariser(_SpatialParameterRegulariser):\n    def __init__(self, parameter_name, scaling=[1], size_average=True, reduce=True):\n        super(IsotropicTVRegulariser, self).__init__(parameter_name, scaling, size_average, reduce)\n\n        self.name = ""param_isoTV""\n\n        if self._dim == 2:\n            self._regulariser = self._regulariser_2d # 2d regularisation\n        elif self._dim == 3:\n            self._regulariser = self._regulariser_3d # 3d regularisation\n\n    def _regulariser_2d(self, parameters):\n        for name, parameter in parameters:\n            if self._parameter_name in name:\n                dx = (parameter[:, 1:, 1:] - parameter[:, :-1, 1:]).pow(2)*self._scaling[0]\n                dy = (parameter[:, 1:, 1:] - parameter[:,  1:, :-1]).pow(2)*self._scaling[1]\n\n                return dx + dy\n\n    def _regulariser_3d(self, parameters):\n        for name, parameter in parameters:\n            if self._parameter_name in name:\n                dx = (parameter[:, 1:, 1:, 1:] - parameter[:, -1, 1:, 1:]).pow(2)*self._scaling[0]\n                dy = (parameter[:, 1:, 1:, 1:] - parameter[:, 1:, :-1, 1:]).pow(2)*self._scaling[1]\n                dz = (parameter[:, 1:, 1:, 1:] - parameter[:, 1:, 1:, :-1]).pow(2)*self._scaling[2]\n\n                return dx + dy + dz\n\n    def forward(self, parameters):\n\n        # set the supgradient to zeros\n        value = self._regulariser(parameters)\n        mask = value > 0\n        value[mask] = th.sqrt(value[mask])\n\n        return self.return_loss(value)\n\n\n""""""\n    TV regularisation \n""""""\nclass TVRegulariser(_SpatialParameterRegulariser):\n    def __init__(self, parameter_name, scaling=[1], size_average=True, reduce=True):\n        super(TVRegulariser, self).__init__(parameter_name, scaling, size_average, reduce)\n\n        self.name = ""param_TV""\n\n        if self._dim == 2:\n            self._regulariser = self._regulariser_2d  # 2d regularisation\n        elif self._dim == 3:\n            self._regulariser = self._regulariser_3d  # 3d regularisation\n\n    def _regulariser_2d(self, parameters):\n        for name, parameter in parameters:\n            if self._parameter_name in name:\n                dx = th.abs(parameter[:, 1:, 1:] - parameter[:, :-1, 1:])*self._pixel_spacing[0]\n                dy = th.abs(parameter[:, 1:, 1:] - parameter[:,  1:, :-1])*self._pixel_spacing[1]\n\n                return dx + dy\n\n    def _regulariser_3d(self, parameters):\n        for name, parameter in parameters:\n            if self._parameter_name in name:\n                dx = th.abs(parameter[:, 1:, 1:, 1:] - parameter[:, -1, 1:, 1:])*self._pixel_spacing[0]\n                dy = th.abs(parameter[:, 1:, 1:, 1:] - parameter[:, 1:, :-1, 1:])*self._pixel_spacing[1]\n                dz = th.abs(parameter[:, 1:, 1:, 1:] - parameter[:, 1:, 1:, :-1])*self._pixel_spacing[2]\n\n                return dx + dy + dz\n\n    def forward(self, parameters):\n        return self.return_loss(self._regulariser(parameters))\n\n""""""\n    Diffusion regularisation \n""""""\nclass DiffusionRegulariser(_SpatialParameterRegulariser):\n    def __init__(self, pixel_spacing, size_average=True, reduce=True):\n        super(DiffusionRegulariser, self).__init__(pixel_spacing, size_average, reduce)\n\n        self.name = ""param diff""\n\n        if self._dim == 2:\n            self._regulariser = self._regulariser_2d  # 2d regularisation\n        elif self._dim == 3:\n            self._regulariser = self._regulariser_3d  # 3d regularisation\n\n    def _regulariser_2d(self, parameters):\n        for name, parameter in parameters:\n            if self._parameter_name in name:\n                dx = (parameter[:, 1:, 1:] - parameter[:, :-1, 1:]).pow(2) * self._pixel_spacing[0]\n                dy = (parameter[:, 1:, 1:] - parameter[:,  1:, :-1]).pow(2) * self._pixel_spacing[1]\n\n                return dx + dy\n\n    def _regulariser_3d(self, parameters):\n        for name, parameter in parameters:\n            if self._parameter_name in name:\n                dx = (parameter[:, 1:, 1:, 1:] - parameter[:, -1, 1:, 1:]).pow(2) * self._pixel_spacing[0]\n                dy = (parameter[:, 1:, 1:, 1:] - parameter[:, 1:, :-1, 1:]).pow(2) * self._pixel_spacing[1]\n                dz = (parameter[:, 1:, 1:, 1:] - parameter[:, 1:, 1:, :-1]).pow(2) * self._pixel_spacing[2]\n\n                return dx + dy + dz\n\n    def forward(self, displacement):\n        return self.return_loss(self._regulariser(displacement))\n\n""""""\n    Sparsity regularisation \n""""""\nclass SparsityRegulariser(_ParameterRegulariser):\n    def __init__(self, parameter_name, size_average=True, reduce=True):\n        super(SparsityRegulariser, self).__init__(parameter_name, size_average, reduce)\n\n        self.name = ""param_L1""\n\n    def forward(self, parameters):\n        for name, parameter in parameters:\n            if self._parameter_name in name:\n                return self.return_loss(th.abs(parameter))\n\n'"
airlab/transformation/__init__.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom . import pairwise\nfrom . import utils\n'"
airlab/transformation/pairwise.py,2,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nfrom torch.nn.parameter import Parameter\nimport torch.nn.functional as F\nimport numpy as np\n\nfrom ..utils import kernelFunction as utils\n\nfrom . import utils as tu\n\n""""""\n    Base class for a transformation\n""""""\nclass _Transformation(th.nn.Module):\n    def __init__(self, image_size, diffeomorphic=False, dtype=th.float32, device=\'cpu\'):\n        super(_Transformation, self).__init__()\n\n        self._dtype = dtype\n        self._device = device\n        self._dim = len(image_size)\n        self._image_size = np.array(image_size)\n        self._constant_displacement = None\n        self._diffeomorphic = diffeomorphic\n        self._constant_flow = None\n\n        self._compute_flow = None\n\n        if self._diffeomorphic:\n            self._diffeomorphic_calculater = tu.Diffeomorphic(image_size, dtype=dtype, device=device)\n        else:\n            self._diffeomorphic_calculater = None\n\n    def get_flow(self):\n\n        if self._constant_flow is None:\n            return self._compute_flow().detach()\n        else:\n            return self._compute_flow().detach() + self._constant_flow\n\n    def set_constant_flow(self, flow):\n        self._constant_flow = flow\n\n    def get_displacement_numpy(self):\n\n        if self._dim == 2:\n            return th.unsqueeze(self().detach(), 0).cpu().numpy()\n        elif self._dim == 3:\n            return self().detach().cpu().numpy()\n\n    def get_displacement(self):\n            return self().detach()\n\n    # def get_current_displacement(self):\n    #\n    #     if self._dim == 2:\n    #         return th.unsqueeze(self().detach(), 0).cpu().numpy()\n    #     elif self._dim == 3:\n    #         return self().detach().cpu().numpy()\n\n    # def set_constant_displacement(self, displacement):\n    #\n    #     self._constant_displacement = displacement\n\n    # def get_inverse_transformation(self, displacement):\n    #     if self._diffeomorphic:\n    #         if self._dim == 2:\n    #             inv_displacement = self._diffeomorphic_calculater.calculate(displacement * -1)\n    #         else:\n    #             inv_displacement = self._diffeomorphic_calculater.calculate(displacement * -1)\n    #     else:\n    #         print(""error displacement "")\n    #         inv_displacement = None\n    #\n    #     return inv_displacement\n\n    def get_inverse_displacement(self):\n\n        flow = self._concatenate_flows(self._compute_flow()).detach()\n\n        if self._diffeomorphic:\n                inv_displacement = self._diffeomorphic_calculater.calculate(flow * -1)\n        else:\n            print(""error displacement "")\n            inv_displacement = None\n\n        return inv_displacement\n\n    def _compute_diffeomorphic_displacement(self, flow):\n\n        return self._diffeomorphic_calculater.calculate(flow)\n\n    def _concatenate_flows(self, flow):\n\n        if self._constant_flow is None:\n            return flow\n        else:\n            return flow + self._constant_flow\n\n\nclass RigidTransformation(_Transformation):\n    r""""""\n    Rigid centred transformation for 2D and 3D.\n\n    Args:\n        moving_image (Image): moving image for the registration\n        opt_cm (bool): using center of as parameter for the optimisation\n    """"""\n    def __init__(self, moving_image, opt_cm=False):\n        super(RigidTransformation, self).__init__(image_size=moving_image.size,\n                                                  dtype=moving_image.dtype,\n                                                  device=moving_image.device)\n\n        self._opt_cm = opt_cm\n\n        grid = th.squeeze(tu.compute_grid(moving_image.size, dtype=self._dtype))\n\n        grid = th.cat((grid, th.ones(*[list(moving_image.size) + [1]], dtype=self._dtype)), self._dim)\\\n               .to(device=self._device)\n\n        self.register_buffer(""_grid"", grid)\n\n        # compute the initial center of mass of the moving image\n        intensity_sum = th.sum(moving_image.image)\n\n        self._center_mass_x = th.sum(moving_image.image.squeeze() * self._grid[..., 0]) / intensity_sum\n        self._center_mass_y = th.sum(moving_image.image.squeeze() * self._grid[..., 1]) / intensity_sum\n\n\n        self._phi_z = Parameter(th.tensor(0.0))\n        self._t_x = Parameter(th.tensor(0.0))\n        self._t_y = Parameter(th.tensor(0.0))\n\n        self._trans_matrix_pos = None\n        self._trans_matrix_cm = None\n        self._trans_matrix_cm_rw = None\n        self._rotation_matrix = None\n\n        if self._opt_cm:\n            self._center_mass_x = Parameter(self._center_mass_x)\n            self._center_mass_y = Parameter(self._center_mass_y)\n\n        if self._dim == 2:\n            self._compute_transformation = self._compute_transformation_2d\n\n        else:\n            self._compute_transformation = self._compute_transformation_3d\n\n            self._center_mass_z = th.sum(moving_image.image.squeeze() * self._grid[..., 2]) / intensity_sum\n\n            self._t_z = Parameter(th.tensor(0.0))\n            self._phi_x = Parameter(th.tensor(0.0))\n            self._phi_y = Parameter(th.tensor(0.0))\n\n            if self._opt_cm:\n                self._center_mass_z = Parameter(self._center_mass_z)\n\n    def init_translation(self, fixed_image):\n        r""""""\n        Initialize the translation parameters with the difference between the center of mass of the\n        fixed and the moving image\n\n        Args:\n            fixed_image (Image): Fixed image for the registration\n        """"""\n        intensity_sum = th.sum(fixed_image.image)\n\n        fixed_image_center_mass_x = th.sum(fixed_image.image.squeeze() * self._grid[..., 0]) / intensity_sum\n        fixed_image_center_mass_y = th.sum(fixed_image.image.squeeze() * self._grid[..., 1]) / intensity_sum\n\n        self._t_x = Parameter(self._center_mass_x - fixed_image_center_mass_x)\n        self._t_y = Parameter(self._center_mass_y - fixed_image_center_mass_y)\n\n        if self._dim == 3:\n            fixed_image_center_mass_z = th.sum(fixed_image.image.squeeze() * self._grid[..., 2]) / intensity_sum\n            self._t_z = Parameter(self._center_mass_z - fixed_image_center_mass_z)\n            \n    @property\n    def transformation_matrix(self):\n        return self._compute_transformation_matrix()\n\n    def set_parameters(self, t, phi, rotation_center=None):\n        """"""\n        Set parameters manually\n\n        t (array): 2 or 3 dimensional array specifying the spatial translation\n        phi (array): 1 or 3 dimensional array specifying the rotation angles\n        rotation_center (array): 2 or 3 dimensional array specifying the rotation center (default is zeros)\n        """"""\n        self._t_x = Parameter(th.tensor(t[0]).to(dtype=self._dtype, device=self._device))\n        self._t_y = Parameter(th.tensor(t[1]).to(dtype=self._dtype, device=self._device))\n        self._phi_z = Parameter(th.tensor(phi[0]).to(dtype=self._dtype, device=self._device))\n\n        if rotation_center is not None:\n            self._center_mass_x = rotation_center[0]\n            self._center_mass_y = rotation_center[1]\n\n        if len(t) == 2:\n            self._compute_transformation_2d()\n        else:\n            self._t_z = Parameter(th.tensor(t[2]).to(dtype=self._dtype, device=self._device))\n            self._phi_x = Parameter(th.tensor(phi[1]).to(dtype=self._dtype, device=self._device))\n            self._phi_y = Parameter(th.tensor(phi[2]).to(dtype=self._dtype, device=self._device))\n            if rotation_center is not None:\n                self._center_mass_z = rotation_center[1]\n                \n            self._compute_transformation_3d()\n\n\n    def _compute_transformation_2d(self):\n\n        self._trans_matrix_pos = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n        self._trans_matrix_cm = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n        self._trans_matrix_cm_rw = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n        self._rotation_matrix = th.zeros(self._dim + 1, self._dim + 1, dtype=self._dtype, device=self._device)\n        self._rotation_matrix[-1, -1] = 1\n\n        self._trans_matrix_pos[0, 2] = self._t_x\n        self._trans_matrix_pos[1, 2] = self._t_y\n\n        self._trans_matrix_cm[0, 2] = -self._center_mass_x\n        self._trans_matrix_cm[1, 2] = -self._center_mass_y\n\n        self._trans_matrix_cm_rw[0, 2] = self._center_mass_x\n        self._trans_matrix_cm_rw[1, 2] = self._center_mass_y\n\n        self._rotation_matrix[0, 0] = th.cos(self._phi_z)\n        self._rotation_matrix[0, 1] = -th.sin(self._phi_z)\n        self._rotation_matrix[1, 0] = th.sin(self._phi_z)\n        self._rotation_matrix[1, 1] = th.cos(self._phi_z)\n\n    def _compute_transformation_3d(self):\n\n        self._trans_matrix_pos = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n        self._trans_matrix_cm = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n        self._trans_matrix_cm_rw = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n\n        self._trans_matrix_pos[0, 3] = self._t_x\n        self._trans_matrix_pos[1, 3] = self._t_y\n        self._trans_matrix_pos[2, 3] = self._t_z\n\n        self._trans_matrix_cm[0, 3] = -self._center_mass_x\n        self._trans_matrix_cm[1, 3] = -self._center_mass_y\n        self._trans_matrix_cm[2, 3] = -self._center_mass_z\n\n        self._trans_matrix_cm_rw[0, 3] = self._center_mass_x\n        self._trans_matrix_cm_rw[1, 3] = self._center_mass_y\n        self._trans_matrix_cm_rw[2, 3] = self._center_mass_z\n\n        R_x = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n        R_x[1, 1] = th.cos(self._phi_x)\n        R_x[1, 2] = -th.sin(self._phi_x)\n        R_x[2, 1] = th.sin(self._phi_x)\n        R_x[2, 2] = th.cos(self._phi_x)\n\n        R_y = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n        R_y[0, 0] = th.cos(self._phi_y)\n        R_y[0, 2] = th.sin(self._phi_y)\n        R_y[2, 0] = -th.sin(self._phi_y)\n        R_y[2, 2] = th.cos(self._phi_y)\n\n        R_z = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n        R_z[0, 0] = th.cos(self._phi_z)\n        R_z[0, 1] = -th.sin(self._phi_z)\n        R_z[1, 0] = th.sin(self._phi_z)\n        R_z[1, 1] = th.cos(self._phi_z)\n        \n        self._rotation_matrix = th.mm(th.mm(R_z, R_y), R_x)\n\n    def _compute_transformation_matrix(self):\n        transformation_matrix = th.mm(th.mm(th.mm(self._trans_matrix_pos, self._trans_matrix_cm),\n                                                  self._rotation_matrix), self._trans_matrix_cm_rw)[0:self._dim, :]\n        return transformation_matrix\n\n    def _compute_dense_flow(self, transformation_matrix):\n\n        displacement = th.mm(self._grid.view(np.prod(self._image_size).tolist(), self._dim + 1),\n                             transformation_matrix.t()).view(*(self._image_size.tolist()), self._dim) \\\n                       - self._grid[..., :self._dim]\n        return displacement\n\n    def print(self):\n        for name, param in self.named_parameters():\n            print(name, param.item())\n            \n    def compute_displacement(self, transformation_matrix):\n        return self._compute_dense_flow(transformation_matrix)\n\n    def forward(self):\n\n        self._compute_transformation()\n        transformation_matrix = self._compute_transformation_matrix()\n        flow = self._compute_dense_flow(transformation_matrix)\n\n        return self._concatenate_flows(flow)\n    \n    \n\n\nclass SimilarityTransformation(RigidTransformation):\n    r""""""\n    Similarity centred transformation for 2D and 3D.\n    Args:\n        moving_image (Image): moving image for the registration\n        opt_cm (bool): using center of as parameter for the optimisation\n    """"""\n    def __init__(self, moving_image, opt_cm=False):\n        super(SimilarityTransformation, self).__init__(moving_image, opt_cm)\n\n        self._scale_x = Parameter(th.tensor(1.0))\n        self._scale_y = Parameter(th.tensor(1.0))\n\n        self._scale_matrix = None\n\n        if self._dim == 2:\n            self._compute_transformation = self._compute_transformation_2d\n        else:\n            self._compute_transformation = self._compute_transformation_3d\n\n            self._scale_z = Parameter(th.tensor(1.0))\n\n    def set_parameters(self, t, phi, scale, rotation_center=None):\n        """"""\n        Set parameters manually\n\n        t (array): 2 or 3 dimensional array specifying the spatial translation\n        phi (array): 1 or 3 dimensional array specifying the rotation angles\n        scale (array): 2 or 3 dimensional array specifying the scale in each dimension\n        rotation_center (array): 2 or 3 dimensional array specifying the rotation center (default is zeros)\n        """"""\n        super(SimilarityTransformation, self).set_parameters(t, phi, rotation_center)\n\n        self._scale_x = Parameter(th.tensor(scale[0]).to(dtype=self._dtype, device=self._device))\n        self._scale_y = Parameter(th.tensor(scale[1]).to(dtype=self._dtype, device=self._device))\n\n        if len(t) == 2:\n            self._compute_transformation_2d()\n        else:\n            self._scale_z = Parameter(th.tensor(scale[2]).to(dtype=self._dtype, device=self._device))\n            self._compute_transformation_3d()\n\n    def _compute_transformation_2d(self):\n\n        super(SimilarityTransformation, self)._compute_transformation_2d()\n\n        self._scale_matrix = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n\n        self._scale_matrix[0, 0] = self._scale_x\n        self._scale_matrix[1, 1] = self._scale_y\n\n    def _compute_transformation_3d(self):\n\n        super(SimilarityTransformation, self)._compute_transformation_3d()\n\n        self._scale_matrix = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n\n        self._scale_matrix[0, 0] = self._scale_x\n        self._scale_matrix[1, 1] = self._scale_y\n        self._scale_matrix[2, 2] = self._scale_z\n\n    def _compute_transformation_matrix(self):\n        transformation_matrix = th.mm(th.mm(th.mm(th.mm(self._trans_matrix_pos, self._trans_matrix_cm),\n                                                  self._rotation_matrix), self._scale_matrix),\n                                      self._trans_matrix_cm_rw)[0:self._dim, :]\n\n        return transformation_matrix\n\n    def forward(self):\n\n        self._compute_transformation()\n        transformation_matrix = self._compute_transformation_matrix()\n        flow = self._compute_dense_flow(transformation_matrix)\n\n        return self._concatenate_flows(flow)\n\n\nclass AffineTransformation(SimilarityTransformation):\n    """"""\n    Affine centred transformation for 2D and 3D.\n\n    Args:\n        moving_image (Image): moving image for the registration\n        opt_cm (bool): using center of as parameter for the optimisation\n    """"""\n    def __init__(self, moving_image, opt_cm=False):\n        super(AffineTransformation, self).__init__(moving_image, opt_cm)\n\n        self._shear_y_x = Parameter(th.tensor(0.0))\n        self._shear_x_y = Parameter(th.tensor(0.0))\n\n        self._shear_matrix = None\n\n        if self._dim == 2:\n            self._compute_displacement = self._compute_transformation_2d\n        else:\n            self._compute_displacement = self._compute_transformation_3d\n\n            self._shear_z_x = Parameter(th.tensor(0.0))\n            self._shear_z_y = Parameter(th.tensor(0.0))\n            self._shear_x_z = Parameter(th.tensor(0.0))\n            self._shear_y_z = Parameter(th.tensor(0.0))\n\n    def set_parameters(self, t, phi, scale, shear, rotation_center=None):\n        """"""\n        Set parameters manually\n\n        t (array): 2 or 3 dimensional array specifying the spatial translation\n        phi (array): 1 or 3 dimensional array specifying the rotation angles\n        scale (array): 2 or 3 dimensional array specifying the scale in each dimension\n        shear (array): 2 or 6 dimensional array specifying the shear in each dimension: yx, xy, zx, zy, xz, yz\n        rotation_center (array): 2 or 3 dimensional array specifying the rotation center (default is zeros)\n        """"""\n        super(AffineTransformation, self).set_parameters(t, phi, scale, rotation_center)\n\n        self._shear_y_x = Parameter(th.tensor(shear[0]).to(dtype=self._dtype, device=self._device))\n        self._shear_x_y = Parameter(th.tensor(shear[1]).to(dtype=self._dtype, device=self._device))\n\n        if len(t) == 2:\n            self._compute_transformation_2d()\n        else:\n            self._shear_z_x = Parameter(th.tensor(shear[2]).to(dtype=self._dtype, device=self._device))\n            self._shear_z_y = Parameter(th.tensor(shear[3]).to(dtype=self._dtype, device=self._device))\n            self._shear_x_z = Parameter(th.tensor(shear[4]).to(dtype=self._dtype, device=self._device))\n            self._shear_y_z = Parameter(th.tensor(shear[5]).to(dtype=self._dtype, device=self._device))\n            self._compute_transformation_3d()\n\n    def _compute_transformation_2d(self):\n\n        super(AffineTransformation, self)._compute_transformation_2d()\n\n        self._shear_matrix = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n\n        self._shear_matrix[0, 1] = self._shear_y_x\n        self._shear_matrix[1, 0] = self._shear_x_y\n\n    def _compute_transformation_3d(self):\n\n        super(AffineTransformation, self)._compute_transformation_3d()\n\n        self._shear_matrix = th.diag(th.ones(self._dim + 1, dtype=self._dtype, device=self._device))\n\n        self._shear_matrix[0, 1] = self._shear_y_x\n        self._shear_matrix[0, 2] = self._shear_z_x\n        self._shear_matrix[1, 0] = self._shear_x_y\n        self._shear_matrix[1, 2] = self._shear_z_y\n        self._shear_matrix[2, 0] = self._shear_x_z\n        self._shear_matrix[2, 1] = self._shear_y_z\n\n    def _compute_transformation_matrix(self):\n        transformation_matrix = th.mm(th.mm(th.mm(th.mm(th.mm(self._trans_matrix_pos, self._trans_matrix_cm),\n                                                        self._rotation_matrix),self._scale_matrix), self._shear_matrix),\n                                      self._trans_matrix_cm_rw)[0:self._dim, :]\n\n        return transformation_matrix\n\n    def forward(self):\n\n        self._compute_transformation()\n        transformation_matrix = self._compute_transformation_matrix()\n        flow = self._compute_dense_flow(transformation_matrix)\n\n        return self._concatenate_flows(flow)\n\n\nclass NonParametricTransformation(_Transformation):\n    r""""""\n        None parametric transformation\n    """"""\n    def __init__(self, image_size,  diffeomorphic=False, dtype=th.float32, device=\'cpu\'):\n        super(NonParametricTransformation, self).__init__(image_size, diffeomorphic, dtype, device)\n\n        self._tensor_size = [self._dim] + self._image_size.tolist()\n\n        self.trans_parameters = Parameter(th.Tensor(*self._tensor_size))\n        self.trans_parameters.data.fill_(0)\n\n        self.to(dtype=self._dtype, device=self._device)\n\n        if self._dim == 2:\n            self._compute_flow = self._compute_flow_2d\n        else:\n            self._compute_flow = self._compute_flow_3d\n\n    def set_start_parameter(self, parameters):\n        if self._dim == 2:\n            self.trans_parameters = Parameter(th.tensor(parameters.transpose(0, 2)))\n        elif self._dim == 3:\n            self.trans_parameters = Parameter(th.tensor(parameters.transpose(0, 1)\n                                                        .transpose(0, 2).transpose(0, 3)))\n\n    def _compute_flow_2d(self):\n        return self.trans_parameters.transpose(0, 2).transpose(0, 1)\n\n    def _compute_flow_3d(self):\n        return self.trans_parameters.transpose(0, 3).transpose(0, 2).transpose(0, 1)\n\n    def forward(self):\n        flow = self._concatenate_flows(self._compute_flow())\n\n        if self._diffeomorphic:\n            displacement = self._compute_diffeomorphic_displacement(flow)\n        else:\n            displacement = flow\n\n        return displacement\n\n""""""\n    Base class for kernel transformations\n""""""\nclass _KernelTransformation(_Transformation):\n    def __init__(self, image_size, diffeomorphic=False, dtype=th.float32, device=\'cpu\'):\n        super(_KernelTransformation, self).__init__(image_size, diffeomorphic, dtype, device)\n\n        self._kernel = None\n        self._stride = 1\n        self._padding = 0\n        self._displacement_tmp = None\n        self._displacement = None\n\n        assert self._dim == 2 or self._dim == 3\n\n        if self._dim == 2:\n            self._compute_flow = self._compute_flow_2d\n        else:\n            self._compute_flow = self._compute_flow_3d\n\n\n    def get_current_displacement(self):\n\n        if self._dim == 2:\n            return th.unsqueeze(self._compute_displacement().detach(), 0).cpu().numpy()\n        elif self._dim == 3:\n            return self._compute_displacement().detach().cpu().numpy()\n\n    def _initialize(self):\n\n        cp_grid = np.ceil(np.divide(self._image_size, self._stride)).astype(dtype=int)\n\n        # new image size after convolution\n        inner_image_size = np.multiply(self._stride, cp_grid) - (self._stride - 1)\n\n        # add one control point at each side\n        cp_grid = cp_grid + 2\n\n        # image size with additional control points\n        new_image_size = np.multiply(self._stride, cp_grid) - (self._stride - 1)\n\n        # center image between control points\n        image_size_diff = inner_image_size - self._image_size\n        image_size_diff_floor = np.floor((np.abs(image_size_diff)/2))*np.sign(image_size_diff)\n\n        self._crop_start = image_size_diff_floor + np.remainder(image_size_diff, 2)*np.sign(image_size_diff)\n        self._crop_end = image_size_diff_floor\n\n        cp_grid = [1, self._dim] + cp_grid.tolist()\n\n        # create transformation parameters\n        self.trans_parameters = Parameter(th.Tensor(*cp_grid))\n        self.trans_parameters.data.fill_(0)\n\n        # copy to gpu if needed\n        self.to(dtype=self._dtype, device=self._device)\n\n        # convert to integer\n        self._padding = self._padding.astype(dtype=int).tolist()\n        self._stride = self._stride.astype(dtype=int).tolist()\n\n        self._crop_start = self._crop_start.astype(dtype=int)\n        self._crop_end = self._crop_end.astype(dtype=int)\n\n        size = [1, 1] + new_image_size.astype(dtype=int).tolist()\n        self._displacement_tmp = th.empty(*size, dtype=self._dtype, device=self._device)\n\n        size = [1, 1] + self._image_size.astype(dtype=int).tolist()\n        self._displacement = th.empty(*size, dtype=self._dtype, device=self._device)\n\n    def _compute_flow_2d(self):\n        displacement_tmp = F.conv_transpose2d(self.trans_parameters, self._kernel,\n                                          padding=self._padding, stride=self._stride, groups=2)\n\n        # crop displacement\n        return th.squeeze(displacement_tmp[:, :,\n                       self._stride[0] + self._crop_start[0]:-self._stride[0] - self._crop_end[0],\n                       self._stride[1] + self._crop_start[1]:-self._stride[1] - self._crop_end[1]].transpose_(1, 3).transpose(1, 2))\n\n    def _compute_flow_3d(self):\n\n        # compute dense displacement\n        displacement = F.conv_transpose3d(self.trans_parameters, self._kernel,\n                                          padding=self._padding, stride=self._stride, groups=3)\n\n        # crop displacement\n        return th.squeeze(displacement[:, :, self._stride[0] + self._crop_start[0]:-self._stride[0] - self._crop_end[0],\n                                  self._stride[1] + self._crop_start[1]:-self._stride[1] - self._crop_end[1],\n                                  self._stride[2] + self._crop_start[2]:-self._stride[2] - self._crop_end[2]\n                                  ].transpose_(1,4).transpose_(1,3).transpose_(1,2))\n\n    def forward(self):\n\n        flow = self._concatenate_flows(self._compute_flow())\n\n        if self._diffeomorphic:\n            displacement = self._compute_diffeomorphic_displacement(flow)\n        else:\n            displacement = flow\n\n        return displacement\n\n""""""\n    bspline kernel transformation\n""""""\nclass BsplineTransformation(_KernelTransformation):\n    def __init__(self, image_size, sigma, diffeomorphic=False, order=2, dtype=th.float32, device=\'cpu\'):\n        super(BsplineTransformation, self).__init__(image_size, diffeomorphic, dtype, device)\n\n        self._stride = np.array(sigma)\n\n        # compute bspline kernel\n        self._kernel = utils.bspline_kernel(sigma, dim=self._dim, order=order, asTensor=True, dtype=dtype)\n\n        self._padding = (np.array(self._kernel.size()) - 1) / 2\n\n        self._kernel.unsqueeze_(0).unsqueeze_(0)\n        self._kernel = self._kernel.expand(self._dim, *((np.ones(self._dim + 1, dtype=int)*-1).tolist()))\n        self._kernel = self._kernel.to(dtype=dtype, device=self._device)\n\n        self._initialize()\n\n\n""""""\n    Wendland kernel transformation\n""""""\nclass WendlandKernelTransformation(_KernelTransformation):\n    """"""\n    Wendland Kernel Transform:\n\n    Implements the kernel transform with the Wendland basis\n\n    Parameters:\n        sigma: specifies how many control points are used (each sigma pixels)\n        cp_scale: specifies the extent of the kernel. how many control points are in the support of the kernel\n    """"""\n    def __init__(self, image_size, sigma, cp_scale=2, diffeomorphic=False, ktype=""C4"", dtype=th.float32, device=\'cpu\'):\n        super(WendlandKernelTransformation, self).__init__(image_size, diffeomorphic, dtype, device)\n\n        self._stride = np.array(sigma)\n\n        # compute bspline kernel\n        self._kernel = utils.wendland_kernel(np.array(sigma)*cp_scale, dim=self._dim, type=ktype, asTensor=True, dtype=dtype)\n\n        self._padding = (np.array(self._kernel.size()) - 1) / 2\n\n        self._kernel.unsqueeze_(0).unsqueeze_(0)\n        self._kernel = self._kernel.expand(self._dim, *((np.ones(self._dim + 1,dtype=int) * -1).tolist()))\n        self._kernel = self._kernel.to(dtype=dtype, device=self._device)\n\n        self._initialize()\n'"
airlab/transformation/utils.py,1,"b'## Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nimport torch.nn.functional as F\n\nfrom ..utils import image as iutils\n\nimport SimpleITK as sitk\n\ndef compute_grid(image_size, dtype=th.float32, device=\'cpu\'):\n\n    dim = len(image_size)\n\n    if dim == 2:\n        nx = image_size[0]\n        ny = image_size[1]\n\n        x = th.linspace(-1, 1, steps=ny).to(dtype=dtype)\n        y = th.linspace(-1, 1, steps=nx).to(dtype=dtype)\n\n        x = x.expand(nx, -1)\n        y = y.expand(ny, -1).transpose(0, 1)\n\n        x.unsqueeze_(0).unsqueeze_(3)\n        y.unsqueeze_(0).unsqueeze_(3)\n\n        return th.cat((x, y), 3).to(dtype=dtype, device=device)\n\n    elif dim == 3:\n        nz = image_size[0]\n        ny = image_size[1]\n        nx = image_size[2]\n\n        x = th.linspace(-1, 1, steps=nx).to(dtype=dtype)\n        y = th.linspace(-1, 1, steps=ny).to(dtype=dtype)\n        z = th.linspace(-1, 1, steps=nz).to(dtype=dtype)\n\n        x = x.expand(ny, -1).expand(nz, -1, -1)\n        y = y.expand(nx, -1).expand(nz, -1, -1).transpose(1, 2)\n        z = z.expand(nx, -1).transpose(0, 1).expand(ny, -1, -1).transpose(0, 1)\n\n        x.unsqueeze_(0).unsqueeze_(4)\n        y.unsqueeze_(0).unsqueeze_(4)\n        z.unsqueeze_(0).unsqueeze_(4)\n\n        return th.cat((x, y, z), 4).to(dtype=dtype, device=device)\n    else:\n        print(""Error "" + dim + ""is not a valid grid type"")\n\n\ndef upsample_displacement(displacement, new_size, interpolation=""linear""):\n    """"""\n        Upsample displacement field\n    """"""\n    dim = displacement.size()[-1]\n    if dim == 2:\n        displacement = th.transpose(displacement.unsqueeze(0), 0, 3).unsqueeze(0)\n        if interpolation == \'linear\':\n            interpolation = \'bilinear\'\n        else:\n            interpolation = \'nearest\'\n    elif dim == 3:\n        displacement = th.transpose(displacement.unsqueeze(0), 0, 4).unsqueeze(0)\n        if interpolation == \'linear\':\n            interpolation = \'trilinear\'\n        else:\n            interpolation = \'nearest\'\n\n    upsampled_displacement = F.interpolate(displacement[..., 0], size=new_size, mode=interpolation, align_corners=False)\n\n    if dim == 2:\n        upsampled_displacement = th.transpose(upsampled_displacement.unsqueeze(-1), 1, -1)\n    elif dim == 3:\n        upsampled_displacement = th.transpose(upsampled_displacement.unsqueeze(-1), 1, -1)\n\n    return upsampled_displacement[0, 0, ...]\n\n\n""""""\n    Warp image with displacement\n""""""\ndef warp_image(image, displacement):\n\n    image_size = image.size\n\n    grid = compute_grid(image_size, dtype=image.dtype, device=image.device)\n\n    # warp image\n    warped_image = F.grid_sample(image.image, displacement + grid)\n\n    return iutils.Image(warped_image, image_size, image.spacing, image.origin)\n\n\n""""""\n    Convert displacement to a unit displacement\n""""""\ndef displacement_to_unit_displacement(displacement):\n    # scale displacements from image\n    # domain to 2square\n    # - last dimension are displacements\n    if type(displacement) == iutils.Displacement:\n        df = displacement.image\n    else:\n        df = displacement\n\n    for dim in range(df.shape[-1]):\n        df[..., dim] = 2.0 * df[..., dim] / float(df.shape[-dim - 2] - 1)\n\n    return displacement\n\n\n""""""\n    Convert a unit displacement to a displacement field with the right spacing/scale\n""""""\ndef unit_displacement_to_displacement(displacement):\n    # scale displacements from 2square\n    # domain to image domain\n    # - last dimension are displacements\n    if type(displacement) == iutils.Displacement:\n        df = displacement.image\n    else:\n        df = displacement\n\n    # manipulate displacement field\n    for dim in range(df.shape[-1]):\n        df[..., dim] = float(df.shape[-dim - 2] - 1) * df[..., dim] / 2.0\n\n    return displacement\n\ndef get_displacement_itk(displacement, refIm):\n    displacement = displacement.detach().clone()\n    dim = len(displacement.shape) - 1\n    unit_displacement_to_displacement(displacement)\n    dispIm = sitk.GetImageFromArray(\n        displacement.cpu().numpy().astype(\'float64\')\\\n        .transpose(list(range(dim-1, -1, -1)) + [dim])[..., ::-1],  # simpleitk image in numpy: D, H, W\n        isVector=True\n    )\n    dispIm.CopyInformation(refIm)\n    trans = sitk.DisplacementFieldTransform(dispIm)\n    return trans\n\n""""""\n    Create a 3d rotation matrix\n""""""\ndef rotation_matrix(phi_x, phi_y, phi_z, dtype=th.float32, device=\'cpu\', homogene=False):\n    R_x = th.Tensor([[1, 0, 0], [0, th.cos(phi_x), -th.sin(phi_x)], [0, th.sin(phi_x), th.cos(phi_x)]])\n    R_y = th.Tensor([[th.cos(phi_y), 0, th.sin(phi_y)], [0, 1, 0], [-th.sin(phi_y), 0, th.cos(phi_y)]])\n    R_z = th.Tensor([[th.cos(phi_z), -th.sin(phi_z), 0], [th.sin(phi_z), th.cos(phi_z), 0], [0, 0, 1]])\n\n    matrix = th.mm(th.mm(R_z, R_y), R_x).to(dtype=dtype, device=device)\n\n    if homogene:\n        matrix_homogene = th.zeros(4, 4, dtype=dtype, device=device)\n        matrix_homogene[3, 3] = 1\n        matrix_homogene[0:3, 0:3] = matrix\n\n        matrix = matrix_homogene\n\n    return matrix\n\n\nclass Diffeomorphic():\n    r""""""\n    Diffeomorphic transformation. This class computes the matrix exponential of a given flow field using the scaling\n    and squaring algorithm according to:\n              Unsupervised Learning for Fast Probabilistic Diffeomorphic Registration\n              Adrian V. Dalca, Guha Balakrishnan, John Guttag, Mert R. Sabuncu\n              MICCAI 2018\n              and\n              Diffeomorphic Demons: Efficient Non-parametric Image Registration\n              Tom Vercauterena et al., 2008\n\n    """"""\n    def __init__(self, image_size=None, scaling=10, dtype=th.float32, device=\'cpu\'):\n\n        self._dtype = dtype\n        self._device = device\n        self._dim = len(image_size)\n        self._image_size = image_size\n        self._scaling = scaling\n        self._init_scaling = 8\n\n        if image_size is not None:\n            self._image_grid = compute_grid(image_size, dtype=dtype, device=device)\n        else:\n            self._image_grid = None\n\n    def set_image_size(self, image_szie):\n        self._image_size = image_szie\n        self._image_grid = compute_grid(self._image_size, dtype=self._dtype, device=self._device)\n\n    def calculate(self, displacement):\n        if self._dim == 2:\n            return Diffeomorphic.diffeomorphic_2D(displacement, self._image_grid, self._scaling)\n        else:\n            return Diffeomorphic.diffeomorphic_3D(displacement, self._image_grid, self._scaling)\n\n    @staticmethod\n    def _compute_scaling_value(displacement):\n\n        with th.no_grad():\n            scaling = 8\n            norm = th.norm(displacement / (2 ** scaling))\n\n            while norm > 0.5:\n                scaling += 1\n                norm = th.norm(displacement / (2 ** scaling))\n\n        return scaling\n\n    @staticmethod\n    def diffeomorphic_2D(displacement, grid, scaling=-1):\n\n        if scaling < 0:\n            scaling = Diffeomorphic._compute_scaling_value(displacement)\n\n        displacement = displacement / (2 ** scaling)\n\n        displacement = displacement.transpose(2, 1).transpose(1, 0).unsqueeze(0)\n\n        for i in range(scaling):\n            displacement_trans = displacement.transpose(1, 2).transpose(2, 3)\n            displacement = displacement + F.grid_sample(displacement, displacement_trans + grid)\n\n        return displacement.transpose(1, 2).transpose(2, 3).squeeze()\n\n    @staticmethod\n    def diffeomorphic_3D(displacement, grid, scaling=-1):\n        displacement = displacement / (2 ** scaling)\n\n        displacement = displacement.transpose(3, 2).transpose(2, 1).transpose(0, 1).unsqueeze(0)\n\n        for i in range(scaling):\n            displacement_trans = displacement.transpose(1, 2).transpose(2, 3).transpose(3, 4)\n            displacement = displacement + F.grid_sample(displacement, displacement_trans + grid)\n\n        return displacement.transpose(1, 2).transpose(2, 3).transpose(3, 4).squeeze()\n\n\n\n'"
airlab/utils/__init__.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom .image import Image, Displacement, read_image_as_tensor, create_image_from_image, image_from_numpy, \\\n                   create_displacement_image_from_image, create_tensor_image_from_itk_image, create_image_pyramid\n\nfrom .points import Points\n\nfrom .graph import Graph\n\nfrom .matrix import MatrixDiagonalElement, LaplaceMatrix, band_mv, expm_eig, expm_krylov\nfrom .kernelFunction import gaussian_kernel_1d, gaussian_kernel_2d, gaussian_kernel_3d, gaussian_kernel,\\\n                            wendland_kernel_1d, wendland_kernel_2d, wendland_kernel_3d, wendland_kernel, \\\n                            bspline_kernel_1d, bspline_kernel_2d, bspline_kernel_3d, bspline_kernel\n\nfrom .domain import compute_coordinate_grid_2d, compute_coordinate_grid_3d, get_center_of_mass,\\\n                    get_joint_domain_images\n\nfrom .imageLoader import ImageLoader\n\nfrom .imageFilters import auto_crop_image_filter, normalize_images, remove_bed_filter\n\n\n__all__ = [\'Image\', \'Displacement\', \'read_image_as_tensor\', \'create_image_from_image\', \'image_from_numpy\',\\\n           \'create_displacement_image_from_image\', \'create_tensor_image_from_itk_image\', \'create_image_pyramid\',\\\n           \'Points\', \'Graph\', \'MatrixDiagonalElement\', \'LaplaceMatrix\', \'band_mv\', \'expm_eig\', \'expm_krylov\',\\\n           \'gaussian_kernel_1d\', \'gaussian_kernel_2d\', \'gaussian_kernel_3d\', \'gaussian_kernel\',\\\n           \'wendland_kernel_1d\', \'wendland_kernel_2d\', \'wendland_kernel_3d\', \'wendland_kernel\',\\\n           \'bspline_kernel_1d\', \'bspline_kernel_2d\', \'bspline_kernel_3d\', \'bspline_kernel\',\\\n           \'compute_coordinate_grid_2d\', \'compute_coordinate_grid_3d\', \'get_center_of_mass\', \'get_joint_domain_images\',\\\n           \'ImageLoader\', \'auto_crop_image_filter\', \'remove_bed_filter\']\n'"
airlab/utils/domain.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport torch as th\nimport multiprocessing as mp\nimport SimpleITK as sitk\nfrom .image import Image\nfrom .image import create_image_from_image\n\n""""""\nCreate a two dimensional coordinate grid\n""""""\ndef compute_coordinate_grid_2d(image):\n\n    x = np.linspace(0, image.size[0] - 1, num=image.size[0])\n    y = np.linspace(0, image.size[1] - 1, num=image.size[1])\n\n    y_m, x_m = np.meshgrid(y, x)\n\n    return [x_m, y_m]\n\n""""""\nCreate a three dimensional coordinate grid\n""""""\ndef compute_coordinate_grid_3d(image):\n\n    x = np.linspace(0, image.size[0] - 1, num=image.size[0])\n    y = np.linspace(0, image.size[1] - 1, num=image.size[1])\n    z = np.linspace(0, image.size[2] - 1, num=image.size[2])\n\n    y_m, x_m, z_m = np.meshgrid(y, x, z)\n\n    return [x_m, y_m, z_m]\n\n\ndef get_center_of_mass(image):\n    """"""\n    Returns the center of mass of the image (weighted average of coordinates where the intensity values serve as weights)\n\n    image (Image): input is an airlab image\n    return (array): coordinates of the center of mass\n    """"""\n\n    num_points = np.prod(image.size)\n    coordinate_value_array = np.zeros([num_points, len(image.size)+1])  # allocate coordinate value array\n\n    values = image.image.squeeze().cpu().numpy().reshape(num_points)  # vectorize image\n    coordinate_value_array[:, 0] = values\n\n    if len(image.size)==2:\n        X, Y = compute_coordinate_grid_2d(image)\n        coordinate_value_array[:, 1] = X.reshape(num_points)\n        coordinate_value_array[:, 2] = Y.reshape(num_points)\n\n    elif len(image.size)==3:\n        X, Y, Z = compute_coordinate_grid_3d(image)\n        coordinate_value_array[:, 1] = X.reshape(num_points)\n        coordinate_value_array[:, 2] = Y.reshape(num_points)\n        coordinate_value_array[:, 3] = Z.reshape(num_points)\n\n    else:\n        raise Exception(""Only 2 and 3 space dimensions supported"")\n\n    # compared to the itk implementation the\n    #   center of gravity for the 2d lenna should be [115.626, 91.9961]\n    #   center of gravity for 3d image it should be [2.17962, 5.27883, -1.81531]\n\n    cm = np.average(coordinate_value_array[:, 1:], axis=0, weights=coordinate_value_array[:, 0])\n    cm = cm * image.spacing + image.origin\n\n    return cm\n\n\ndef get_joint_domain_images(fixed_image, moving_image, default_value=0, interpolator=2, cm_alignment=False, compute_masks=False):\n    """"""\n    The method brings the fixed and moving image in a common image domain in order to be compatible with the\n    registration framework of airlab. Different from the ITK convention, the registration in airlab is performed\n    on pixels and not on points. This allows an efficient evaluation of the image metrics, the synthesis of\n    displacement fields and warp of the moving image.\n\n    If the images already have the same image domain (after a possible center of mass alignment) no resampling is\n    performed and only masks are generated for return.\n\n    Step 1: The moving image is aligned to the fixed image by matching the center of mass of the two images.\n    Step 2: The new image domain is the smallest possible domain where both images are contained completely.\n            The minimum spacing is taken as new spacing. This second step can increase the amount of pixels.\n    Step 3: Fixed and moving image are resampled on this new domain.\n    Step 4: Masks are built which defines in which region the respective image is not defined on this new domain.\n\n    Note: The minimum possible value of the fixed image type is used as placeholder when resampling.\n          Hence, this value should not be present in the images\n\n    fixed_image (Image): fixed image provided as airlab image\n    moving_image (Image): moving image provided as airlab image\n    default_value (float|int): default value which defines the value which is set where the images are not defined in the new domain\n    interpolator (int):  nn=1, linear=2, bspline=3\n    cm_alignment (bool): defines whether the center of mass refinement should be performed prior to the resampling\n    compute_masks (bool): defines whether the masks should be created. otherwise, None is returned as masks.\n    return (tuple): resampled fixed image, fixed mask, resampled moving image, moving mask\n    """"""\n    f_mask = None\n    m_mask = None\n\n    cm_displacement = None\n\n    # align images using center of mass\n    if cm_alignment:\n        cm_displacement = get_center_of_mass(fixed_image) - get_center_of_mass(moving_image)\n        moving_image.origin = moving_image.origin + cm_displacement\n\n    # check if domains are equal, as then nothing has to be resampled\n    if np.all(fixed_image.origin == moving_image.origin) and\\\n            np.all(fixed_image.spacing == moving_image.spacing) and\\\n            np.all(fixed_image.size == moving_image.size):\n        if compute_masks:\n            f_mask = th.ones_like(fixed_image.image)\n            m_mask = th.ones_like(moving_image.image)\n\n            f_mask = Image(f_mask, fixed_image.size, fixed_image.spacing, fixed_image.origin)\n            m_mask = Image(m_mask, moving_image.size, moving_image.spacing, moving_image.origin)\n        return fixed_image, f_mask, moving_image, m_mask, None\n\n    # common origin\n    origin = np.minimum(fixed_image.origin, moving_image.origin)\n\n    # common extent\n    f_extent = np.array(fixed_image.origin) + (np.array(fixed_image.size)-1)*np.array(fixed_image.spacing)\n    m_extent = np.array(moving_image.origin) + (np.array(moving_image.size)-1)*np.array(moving_image.spacing)\n    extent = np.maximum(f_extent, m_extent)\n\n    # common spacing\n    spacing = np.minimum(fixed_image.spacing, moving_image.spacing)\n\n    # common size\n    size = np.ceil(((extent-origin)/spacing)+1).astype(int)\n\n    # Resample images\n    # fixed and moving image are resampled in new domain\n    # the default value for resampling is set to a predefined value\n    # (minimum possible value of the fixed image type) to use it\n    # to create masks. At the end, default values are replaced with\n    # the provided default value\n    minimum_value = default_value\n    if compute_masks:\n        minimum_value = float(np.finfo(fixed_image.image.cpu().numpy().dtype).tiny)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetSize(size.tolist())\n    resampler.SetOutputSpacing(spacing)\n    resampler.SetOutputOrigin(origin)\n    resampler.SetDefaultPixelValue(minimum_value)\n    resampler.SetInterpolator(interpolator)\n    resampler.SetNumberOfThreads(mp.cpu_count())\n\n    # resample fixed and moving image\n    f_image = Image(resampler.Execute(fixed_image.itk()))\n    m_image = Image(resampler.Execute(moving_image.itk()))\n\n    f_image.to(dtype=fixed_image.dtype, device=fixed_image.device)\n    m_image.to(dtype=moving_image.dtype, device=moving_image.device)\n\n    # create masks\n    if compute_masks:\n        f_mask = th.ones_like(f_image.image)\n        m_mask = th.ones_like(m_image.image)\n\n        f_mask[f_image.image == minimum_value] = 0\n        m_mask[m_image.image == minimum_value] = 0\n\n        f_mask = Image(f_mask, size, spacing, origin)\n        m_mask = Image(m_mask, size, spacing, origin)\n\n        # reset default value in images\n        f_image.image[f_image.image == minimum_value] = default_value\n        m_image.image[m_image.image == minimum_value] = default_value\n\n    return f_image, f_mask, m_image, m_mask, cm_displacement\n\n\n'"
airlab/utils/graph.py,0,"b'# Copyright 2018 University of Basel, Center for medical image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nimport numpy as np\nfrom .matrix import MatrixDiagonalElement, LaplaceMatrix\n\n\nclass Graph():\n    def __init__(self, graph_size, dtype=th.float32, device=\'cpu\'):\n\n        self.dtype=dtype\n        self.device=device\n        self._dim = len(graph_size)\n        self._graph_size = np.array(graph_size)\n        # compute the number of nodes\n        self._number_of_nodes = np.prod(self._graph_size)\n\n        self.laplace_matrix = None\n\n        if self._dim == 2:\n            self._create_graph_2d()\n        elif self._dim == 3:\n            self._create_graph_3d()\n\n\n    def _create_graph_2d(self):\n\n        # compute the number of edges\n        self._number_of_edges = self._number_of_nodes*2.0\n\n        for length in self._graph_size:\n            self._number_of_edges -= length\n\n        self._edge_index_D1 = [[], [], []]\n        self._edge_index_D2 = [[], [], []]\n\n\n        for y in range(self._graph_size[1]):\n            for x in range(self._graph_size[0]):\n\n                if x + 1 < self._graph_size[0]:\n                    self._edge_index_D1[0].append(x + 1)\n                    self._edge_index_D1[1].append(y)\n                    self._edge_index_D1[2].append(x + y*self._graph_size[0])\n\n\n                if y + 1 < self._graph_size[1]:\n                    self._edge_index_D2[0].append(x)\n                    self._edge_index_D2[1].append(y + 1)\n                    self._edge_index_D2[2].append(x + y*self._graph_size[0])\n\n\n        element_1 = MatrixDiagonalElement(np.asarray(self._edge_index_D1), np.ones(len(self._edge_index_D1[0])),\n                                                 th.tensor(1, dtype=th.int64), dtype=self.dtype, device=self.device)\n        element_2 = MatrixDiagonalElement(np.asarray(self._edge_index_D2), np.ones(len(self._edge_index_D2[0])),\n                                                 th.tensor(self._graph_size[0], dtype=th.int64), dtype=self.dtype, device=self.device)\n\n        self.laplace_matrix = LaplaceMatrix(self._number_of_nodes, [element_1, element_2], dtype=self.dtype,\n                                                device=self.device)\n\n\n    def _create_graph_3d(self):\n\n        # compute the number of edges\n        self._number_of_edges = self._number_of_nodes * 2.0\n\n        # for length in self._graph_size:\n        #     self._number_of_edges -= length\n        #\n        # self._number_of_edges *= self._graph_size[2];\n        # self._number_of_edges += self._graph_size[0]*self._graph_size[1]*(self._graph_size[2] - 1);\n        #\n        # self._edge_index_D1 = [[], [], [], []]\n        # self._edge_index_D2 = [[], [], [], []]\n        # self._edge_index_D3 = [[], [], [], []]\n        #\n        # for z in range(self._graph_size[2]):\n        #     for y in range(self._graph_size[1]):\n        #         for x in range(self._graph_size[0]):\n        #\n        #             if x + 1 < self._graph_size[0]:\n        #                 self._edge_index_D1[0].append(x-1)\n        #                 self._edge_index_D1[1].append(y)\n        #                 self._edge_index_D1[2].append(z)\n        #                 self._edge_index_D1[3].append(x + y * self._graph_size[0] + z*self._graph_size[0]* self._graph_size[1])\n        #\n        #             if y + 1 < self._graph_size[1]:\n        #                 self._edge_index_D2[0].append(x)\n        #                 self._edge_index_D2[1].append(y + 1)\n        #                 self._edge_index_D1[2].append(z)\n        #                 self._edge_index_D2[3].append(x + y * self._graph_size[0] + z*self._graph_size[0]* self._graph_size[1])\n        #\n        #             if z + 1 < self._graph_size[2]:\n        #                 self._edge_index_D3[0].append(x)\n        #                 self._edge_index_D3[1].append(y)\n        #                 self._edge_index_D3[2].append(z + 1)\n        #                 self._edge_index_D3[3].append(x + y * self._graph_size[0] + z * self._graph_size[0] * self._graph_size[1])\n        #\n        # element_1 = MatrixDiagonalElement(np.asarray(self._edge_index_D1), np.ones(len(self._edge_index_D1[0])),\n        #                                       th.tensor(1, dtype=th.int64), dtype=self.dtype, device=self.device)\n        #\n        # element_2 = MatrixDiagonalElement(np.asarray(self._edge_index_D2), np.ones(len(self._edge_index_D2[0])),\n        #                                       th.tensor(self._graph_size[0], dtype=th.int64), dtype=self.dtype,\n        #                                       device=self.device)\n        #\n        # element_3 = MatrixDiagonalElement(np.asarray(self._edge_index_D3), np.ones(len(self._edge_index_D3[0])),\n        #                                       th.tensor(self._graph_size[0]*self._graph_size[1], dtype=th.int64), dtype=self.dtype,\n        #                                       device=self.device)\n        #\n        # self.laplace_matrix = LaplaceMatrix(self._number_of_nodes, [element_1, element_2, element_3])\n'"
airlab/utils/image.py,1,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport SimpleITK as sitk\nimport torch as th\nimport torch.nn.functional as F\nimport numpy as np\nimport sys\n\nfrom . import kernelFunction\n\n\nclass Image:\n    """"""\n        Class representing an image in airlab\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        """"""\n        Constructor for an image object where two cases are distinguished:\n\n        - Construct airlab image from an array or tensor (4 arguments)\n        - Construct airlab image from an SimpleITK image (less than 4 arguments\n        """"""\n        if len(args) == 4:\n            self.initializeForTensors(*args)\n        elif len(args) < 4:\n            self.initializeForImages(*args)\n\n\n    def initializeForTensors(self, tensor_image, image_size, image_spacing, image_origin):\n        """"""\n        Constructor for torch tensors and numpy ndarrays\n\n        Args:\n        tensor_image (np.ndarray | th.Tensor): n-dimensional tensor, where the last dimensions are the image dimensions while the preceeding dimensions need to empty\n        image_size (array | list | tuple): number of pixels in each space dimension\n        image_spacing (array | list | tuple): pixel size for each space dimension\n        image_origin (array | list | tuple): physical coordinate of the first pixel\n        :return (Image): an airlab image object\n        """"""\n\n        # distinguish between numpy array and torch tensors\n        if type(tensor_image) == np.ndarray:\n            self.image = th.from_numpy(tensor_image).squeeze().unsqueeze(0).unsqueeze(0)\n        elif type(tensor_image) == th.Tensor:\n            self.image = tensor_image.squeeze().unsqueeze(0).unsqueeze(0)\n        else:\n            raise Exception(""A numpy ndarray or a torch tensor was expected as argument. Got "" + str(type(tensor_image)))\n\n        self.size = image_size\n        self.spacing = image_spacing\n        self.origin = image_origin\n        self.dtype = self.image.dtype\n        self.device = self.image.device\n        self.ndim = len(self.image.squeeze().shape) # take only non-empty dimensions to count space dimensions\n\n\n    def initializeForImages(self, sitk_image, dtype=None, device=\'cpu\'):\n        """"""\n        Constructor for SimpleITK image\n\n        Note: the order of axis are flipped in order to follow the convention of numpy and torch\n\n        sitk_image (sitk.SimpleITK.Image):  SimpleITK image\n        dtype: pixel type\n        device (\'cpu\'|\'cuda\'): on which device the image should be allocated\n        return (Image): an airlab image object\n        """"""\n        if type(sitk_image)==sitk.SimpleITK.Image:\n            self.image = th.from_numpy(sitk.GetArrayFromImage(sitk_image)).unsqueeze(0).unsqueeze(0)\n            self.size = sitk_image.GetSize()\n            self.spacing = sitk_image.GetSpacing()\n            self.origin = sitk_image.GetOrigin()\n\n            if not dtype is None:\n                self.to(dtype, device)\n            else:\n                self.to(self.image.dtype, device)\n\n            self.ndim = len(self.image.squeeze().shape)\n\n            self._reverse_axis()\n        else:\n            raise Exception(""A SimpleITK image was expected as argument. Got "" + str(type(sitk_image)))\n\n\n    def to(self, dtype=None, device=\'cpu\'):\n        """"""\n        Converts the image tensor to a specified dtype and moves it to the specified device\n        """"""\n        if not dtype is None:\n            self.image = self.image.to(dtype=dtype, device=device)\n        else:\n            self.image = self.image.to(device=device)\n        self.dtype = self.image.dtype\n        self.device = self.image.device\n\n        return self\n\n\n    def itk(self):\n        """"""\n        Returns a SimpleITK image\n\n        Note: the order of axis is flipped back to the convention of SimpleITK\n        """"""\n        image = Image(self.image.cpu().clone(), self.size, self.spacing, self.origin)\n        image._reverse_axis()\n        image.image.squeeze_()\n\n        itk_image = sitk.GetImageFromArray(image.image.numpy())\n        itk_image.SetSpacing(spacing=self.spacing)\n        itk_image.SetOrigin(origin=self.origin)\n        return itk_image\n\n\n    def numpy(self):\n        """"""\n        Returns a numpy array\n        """"""\n        return self.image.cpu().squeeze().numpy()\n\n\n    @staticmethod\n    def read(filename, dtype=th.float32, device=\'cpu\'):\n        """"""\n        Static method to directly read an image through the Image class\n\n        filename (str): filename of the image\n        dtype: specific dtype for representing the tensor\n        device: on which device the image has to be allocated\n        return (Image): an airlab image\n        """"""\n        return Image(sitk.ReadImage(filename, sitk.sitkFloat32), dtype, device)\n\n\n    def write(self, filename):\n        """"""\n        Write an image to hard drive\n\n        Note: order of axis are flipped to have the representation of SimpleITK again\n\n        filename (str): filename where the image is written\n        """"""\n        sitk.WriteImage(self.itk(), filename)\n\n\n    def _reverse_axis(self):\n        """"""\n        Flips the order of the axis representing the space dimensions (preceeding dimensions are ignored)\n\n        Note: the method is inplace\n        """"""\n        # reverse order of axis to follow the convention of SimpleITK\n        self.image = self.image.squeeze().permute(tuple(reversed(range(self.ndim))))\n        self.image = self.image.unsqueeze(0).unsqueeze(0)\n\n\n""""""\n    Object representing a displacement image\n""""""\nclass Displacement(Image):\n    def __init__(self, *args, **kwargs):\n        """"""\n        Constructor for a displacement field object where two cases are distinguished:\n\n        - Construct airlab displacement field from an array or tensor (4 arguments)\n        - Construct airlab displacement field from an SimpleITK image (less than 4 arguments)\n        """"""\n        if len(args) == 4:\n            self.initializeForTensors(*args)\n        elif len(args) < 4:\n            self.initializeForImages(*args)\n\n\n    def itk(self):\n\n        # flip axis to\n        df = Displacement(self.image.clone(), self.size, self.spacing, self.origin)\n        df._reverse_axis()\n        df.image = df.image.squeeze()\n        df.image = df.image.cpu()\n\n        if len(self.size) == 2:\n            itk_displacement = sitk.GetImageFromArray(df.image.numpy(), isVector=True)\n        elif len(self.size) == 3:\n            itk_displacement = sitk.GetImageFromArray(df.image.numpy())\n\n        itk_displacement.SetSpacing(spacing=self.spacing)\n        itk_displacement.SetOrigin(origin=self.origin)\n        return itk_displacement\n\n    def magnitude(self):\n       return Image(th.sqrt(th.sum(self.image.pow(2),  -1)).squeeze(), self.size, self.spacing, self.origin)\n\n    def numpy(self):\n        return self.image.cpu().numpy()\n\n    def _reverse_axis(self):\n        """"""\n        Flips the order of the axis representing the space dimensions (preceeding dimensions are ignored).\n        Respectively, the axis holding the vectors is flipped as well\n\n        Note: the method is inplace\n        """"""\n        # reverse order of axis to follow the convention of SimpleITK\n        order = list(reversed(range(self.ndim-1)))\n        order.append(len(order))\n        self.image = self.image.squeeze_().permute(tuple(order))\n        self.image = flip(self.image, self.ndim-1)\n        self.image = self.image.unsqueeze(0).unsqueeze(0)\n\n\n    @staticmethod\n    def read(filename, dtype=th.float32, device=\'cpu\'):\n        """"""\n        Static method to directly read a displacement field through the Image class\n\n        filename (str): filename of the displacement field\n        dtype: specific dtype for representing the tensor\n        device: on which device the displacement field has to be allocated\n        return (Displacement): an airlab displacement field\n        """"""\n        return Displacement(sitk.ReadImage(filename, sitk.sitkVectorFloat32), dtype, device)\n\n\ndef flip(x, dim):\n    """"""\n    Flip order of a specific dimension dim\n\n    x (Tensor): input tensor\n    dim (int): axis which should be flipped\n    return (Tensor): returns the tensor with the specified axis flipped\n    """"""\n    indices = [slice(None)] * x.dim()\n    indices[dim] = th.arange(x.size(dim) - 1, -1, -1, dtype=th.long, device=x.device)\n    return x[tuple(indices)]\n\n""""""\n    Convert an image to tensor representation\n""""""\ndef read_image_as_tensor(filename, dtype=th.float32, device=\'cpu\'):\n\n    itk_image = sitk.ReadImage(filename, sitk.sitkFloat32)\n\n    return create_tensor_image_from_itk_image(itk_image, dtype=dtype, device=device)\n\n\n""""""\n    Convert an image to tensor representation\n""""""\ndef create_image_from_image(tensor_image, image):\n    return Image(tensor_image, image.size, image.spacing, image.origin)\n\n\n\n""""""\n    Convert numpy image to AirlLab image format\n""""""\ndef image_from_numpy(image, pixel_spacing, image_origin, dtype=th.float32, device=\'cpu\'):\n    tensor_image = th.from_numpy(image).unsqueeze(0).unsqueeze(0)\n    tensor_image = tensor_image.to(dtype=dtype, device=device)\n    return Image(tensor_image, image.shape, pixel_spacing, image_origin)\n\n\n""""""\n    Convert an image to tensor representation\n""""""\ndef create_displacement_image_from_image(tensor_displacement, image):\n    return Displacement(tensor_displacement, image.size, image.spacing, image.origin)\n\n\n""""""\n    Create tensor image representation\n""""""\ndef create_tensor_image_from_itk_image(itk_image, dtype=th.float32, device=\'cpu\'):\n\n    # transform image in a unit direction\n    image_dim = itk_image.GetDimension()\n    if image_dim == 2:\n        itk_image.SetDirection(sitk.VectorDouble([1, 0, 0, 1]))\n    else:\n        itk_image.SetDirection(sitk.VectorDouble([1, 0, 0, 0, 1, 0, 0, 0, 1]))\n\n    image_spacing = itk_image.GetSpacing()\n    image_origin = itk_image.GetOrigin()\n\n    np_image = np.squeeze(sitk.GetArrayFromImage(itk_image))\n    image_size = np_image.shape\n\n    # adjust image spacing vector size if image contains empty dimension\n    if len(image_size) != image_dim:\n        image_spacing = image_spacing[0:len(image_size)]\n\n    tensor_image = th.tensor(np_image, dtype=dtype, device=device).unsqueeze(0).unsqueeze(0)\n\n\n    return Image(tensor_image, image_size, image_spacing, image_origin)\n\n\n""""""\n    Create an image pyramide  \n""""""\ndef create_image_pyramid(image, down_sample_factor):\n\n    image_dim = len(image.size)\n    image_pyramide = []\n    if image_dim == 2:\n        for level in down_sample_factor:\n            sigma = (th.tensor(level)/2).to(dtype=th.float32)\n\n            kernel = kernelFunction.gaussian_kernel_2d(sigma.numpy(), asTensor=True)\n            padding = np.array([(x - 1)/2 for x in kernel.size()], dtype=int).tolist()\n            kernel = kernel.unsqueeze(0).unsqueeze(0)\n            kernel = kernel.to(dtype=image.dtype, device=image.device)\n\n            image_sample = F.conv2d(image.image, kernel, stride=level, padding=padding)\n            image_size = image_sample.size()[-image_dim:]\n            image_spacing = [x*y for x, y in zip(image.spacing, level)]\n            image_origin = image.origin\n            image_pyramide.append(Image(image_sample, image_size, image_spacing, image_origin))\n\n        image_pyramide.append(image)\n    elif image_dim == 3:\n        for level in down_sample_factor:\n            sigma = (th.tensor(level)/2).to(dtype=th.float32)\n\n            kernel = kernelFunction.gaussian_kernel_3d(sigma.numpy(), asTensor=True)\n            padding = np.array([(x - 1) / 2 for x in kernel.size()], dtype=int).tolist()\n            kernel = kernel.unsqueeze(0).unsqueeze(0)\n            kernel = kernel.to(dtype=image.dtype, device=image.device)\n\n            image_sample = F.conv3d(image.image, kernel, stride=level, padding=padding)\n            image_size = image_sample.size()[-image_dim:]\n            image_spacing = [x*y for x, y in zip(image.spacing, level)]\n            image_origin = image.origin\n            image_pyramide.append(Image(image_sample, image_size, image_spacing, image_origin))\n\n        image_pyramide.append(image)\n\n    else:\n        print(""Error: "", image_dim, "" is not supported with create_image_pyramide()"")\n        sys.exit(-1)\n\n    return image_pyramide\n'"
airlab/utils/imageFilters.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport multiprocessing as mp\nos.environ[""ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS""] = str(mp.cpu_count())\n\nimport SimpleITK as sitk\nimport numpy as np\nimport torch as th\n\nfrom .image import Image\n\n\ndef auto_crop_image_filter(image, boundary_value=0):\n    """"""\n    Performs an auto cropping of values on boundary\n    image (Image): image which has to be cropped\n    boundary_value (float|int): specifies the boundary value which will be cropped\n    return (Image): a new image with cropped boundary\n    """"""\n    msk = 1 - (image.image.squeeze() == boundary_value)\n\n    rminmax = []\n\n    for d in range(len(msk.shape)):\n        region = msk.argmax(dim=d).nonzero()\n        rminmax.append((region.min(dim=0)[0], region.max(dim=0)[0]))\n        #print(rminmax[-1])\n\n    if image.ndim == 2:\n        cropped = image.image.squeeze()[rminmax[1][0]:rminmax[1][1], rminmax[0][0]:rminmax[0][1]]\n        origin = image.origin + th.Tensor(image.spacing) * th.Tensor([rminmax[1][0], rminmax[0][0]])\n    elif image.ndim == 3:\n        cropped = image.image.squeeze()[rminmax[1][0][0]:rminmax[1][1][0], \\\n                                        rminmax[0][0][0]:rminmax[0][1][0], \\\n                                        rminmax[0][0][1]:rminmax[0][1][1]]\n        #print(cropped.shape)\n        origin = th.Tensor(image.origin) + th.Tensor(image.spacing) * th.Tensor([rminmax[1][0][0], rminmax[0][0][0],rminmax[0][0][1]])\n    else:\n        raise Exception(""Only 2 and 3 space dimensions supported"")\n\n    size = tuple(cropped.shape)\n    cropped.unsqueeze_(0).unsqueeze_(0)\n\n    return Image(cropped, size, image.spacing, origin.tolist())\n\n\ndef normalize_images(fixed_image, moving_image):\n    """"""\n    Noramlize image intensities by extracting joint minimum and dividing by joint maximum\n\n    Note: the function is inplace\n\n    fixed_image (Image): fixed image\n    moving_image (Image): moving image\n    return (Image, Image): normalized images\n    """"""\n    fixed_min = fixed_image.image.min()\n    moving_min = moving_image.image.min()\n\n    min_val = min(fixed_min, moving_min)\n\n    fixed_image.image -= min_val\n    moving_image.image -= min_val\n\n    moving_max = moving_image.image.max()\n    fixed_max = fixed_image.image.max()\n    max_val = max(fixed_max, moving_max)\n\n    fixed_image.image /= max_val\n    moving_image.image /= max_val\n\n    return (fixed_image, moving_image)\n\n\n\ndef remove_bed_filter(image, cropping=True):\n    """"""\n    Removes fine structures from the image using morphological operators. It can be used to remove the bed structure\n    usually present in CT images. The resulting image and the respective body mask can be cropped with the cropping\n    option.\n\n    Note: the morphological operations are performed on a downsampled version of the image\n\n    image (Image): image of interest\n    cropping (bool): specifies if the image should be cropped after bed removal\n    return (Image, Image): bed-free image and a body mask\n    """"""\n\n    # define parameters\n    houndsfield_min = -300\n    houndsfield_max = 3071\n    houndsfield_default = -1024\n\n    radius_opening = 3\n    radius_closing = 40\n\n\n    image_itk = image.itk()\n\n    # resample image\n    workingSize = np.array(image.size)\n    workingSize[0] /= 3\n    workingSize[1] /= 3\n    workingSpacing = np.array(image.spacing, dtype=float) * np.array(image.size, dtype=float) / np.array(workingSize, dtype=float)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetOutputOrigin(image.origin)\n    resampler.SetSize(workingSize.tolist())\n    resampler.SetOutputSpacing(workingSpacing.tolist())\n    resampler.SetInterpolator(2) # linear interpolation\n    resampler.SetNumberOfThreads(mp.cpu_count())\n\n    image_tmp = resampler.Execute(image_itk)\n\n\n    # threshold image\n    thresholder = sitk.BinaryThresholdImageFilter()\n    thresholder.SetOutsideValue(0)\n    thresholder.SetInsideValue(1)\n    thresholder.SetLowerThreshold(houndsfield_min)\n    thresholder.SetUpperThreshold(houndsfield_max)\n    thresholder.SetNumberOfThreads(mp.cpu_count())\n\n    image_tmp = thresholder.Execute(image_tmp)\n\n\n    # morphological opening with ball as structuring element\n    # removes thin structures as the bed\n    opening = sitk.BinaryMorphologicalOpeningImageFilter()\n    opening.SetKernelType(sitk.sitkBall)\n    opening.SetKernelRadius(radius_opening)\n    opening.SetForegroundValue(1)\n    opening.SetNumberOfThreads(mp.cpu_count())\n\n    image_tmp = opening.Execute(image_tmp)\n\n\n    # crop zero values from mask boundary\n    if cropping:\n        image_tmp = auto_crop_image_filter(Image(image_tmp).to(device=image.device)).itk()\n\n\n    # morphological closing with ball as structuring element\n    # fills up the lungs\n    closing = sitk.BinaryMorphologicalClosingImageFilter()\n    closing.SetKernelRadius(sitk.sitkBall)\n    closing.SetKernelRadius(radius_closing)\n    closing.SetForegroundValue(1)\n    closing.SetNumberOfThreads(mp.cpu_count())\n\n    image_tmp = closing.Execute(image_tmp)\n\n\n    # resample mask to original spacing\n    mask_size = np.array(np.array(image_tmp.GetSpacing(), dtype=float)*np.array(image_tmp.GetSize(),dtype=float)/np.array(image.spacing, dtype=float), dtype=int).tolist()\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetOutputOrigin(image_tmp.GetOrigin())\n    resampler.SetSize(mask_size)\n    resampler.SetOutputSpacing(image.spacing)\n    resampler.SetInterpolator(1) # nearest neighbor interpolation\n    resampler.SetNumberOfThreads(mp.cpu_count())\n\n    bodyMask = resampler.Execute(image_tmp)\n\n    # resample also original image\n    resampler.SetInterpolator(2)\n    image_itk = resampler.Execute(image_itk)\n\n\n    # mask image with found label map\n    masking = sitk.MaskImageFilter()\n    masking.SetMaskingValue(0)\n    masking.SetOutsideValue(houndsfield_default)\n    masking.SetNumberOfThreads(mp.cpu_count())\n\n    outImage = masking.Execute(image_itk, bodyMask)\n\n    return (Image(outImage).to(device=image.device), Image(bodyMask).to(device=image.device))\n'"
airlab/utils/imageLoader.py,0,"b'# -*- coding: latin-1 -*-\n\n# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport tempfile\nimport shutil\nimport os\nimport urllib.request\n\nimport torch as th\n\nfrom .image import Image\nfrom .points import Points\n\nclass ImageLoader(object):\n    """"""\n    Image loader is a class to download and cache images. Currently, the 6 4DCT datasets of the POPI model are supported.\n    The downloaded images are cached in a temporary folder, such that, if the image is loaded twice, it will be taken\n    from that folder. If landmark points are available too, they are downloaded and cached as well. The class is\n    implemented as singleton in order to hold a database of cached images only once and consistent.\n\n    Using the show() method, one can print the different images which can be loaded. They are grouped into subjects\n    and images. For example: 4DCT_POPI_2 image_30 means, the subject 4DCT_POPI_2 and the third image of the respiratory\n    cycle.\n\n    Usage:\n    loader = ImageLoader(""/tmp/"")\n    (image, points) = loader.load(""4DCT_POPI_2"", ""image_30"")\n\n    If no landmark points are defined, points is set to None.\n\n    In the generate_database() other images can be registered to the database.\n\n    Note: the provided publicly available images have been published for research purposes. If you are using them for\n          your research, please cite the authors appropriately.\n\n    """"""\n\n    # singleton helper\n    # (there is only one instance for class variables)\n    __instance = None\n\n    def __new__(cls, tmpdir=None):\n        if ImageLoader.__instance is None:\n            ImageLoader.__instance = object.__new__(cls)\n            ImageLoader.__instance._database = {}\n            ImageLoader.__instance._links = ImageLoader.generate_database()\n            if tmpdir is None:\n                ImageLoader.__instance._tmpdir = tempfile.mkdtemp()\n            else:\n                ImageLoader.__instance._tmpdir = tmpdir\n        return ImageLoader.__instance\n\n    def __str__(self):\n        return ""(ImageLoader) directory: "" + ImageLoader.__instance._tmpdir + "", database: "" + str(ImageLoader.__instance._database)\n\n\n    class DataItem:\n        def __init__(self, name, filename, copyright=""N/A""):\n            self.name = name\n            self.filename = filename\n            self.copyright = copyright\n            self.data = None\n\n\n    def show(self):\n        """"""\n        Prints all available images which can be loaded\n        """"""\n        for i in self._links:\n            print(i)\n            for j in self._links[i]:\n                if not str(j)==""copyright"":\n                    print(""\\t""+str(j))\n\n    def load(self, name, image, dtype=th.float32, device=\'cpu\'):\n        """"""\n        Providing the subject name and the image of interest, the image is loaded either from the memory cache, the\n        temporary folder or it is downloaded from the internet. Images which are registered in the _database can be loaded.\n\n        Note: if no points are available to the image, None is returned as points\n\n        name (str): subject name\n        image (str): image name\n        dtype: which pixel type the image should be converted to\n        device: on which device the image should be allocated\n        return (Image, array): tuple of the loaded image and the corresponding points\n        """"""\n        identifier = name +""_""+ image\n\n        # check if image has already been loaded before to possibly return just the reference\n        if not identifier in self._database:\n\n            # check if the subjects is registered\n            if not name in self._links:\n                raise Exception(""Image not found in link database: "" + name)\n\n            # check if the image is registered under the subject name\n            if not image in self._links[name]:\n                raise Exception(""Image not found in image links: "" + name + ""/"" + image)\n\n            # generate temporary filenames\n            image_filename = os.path.join(self._tmpdir, identifier+"".mha"")\n            points_filename = os.path.join(self._tmpdir, identifier + "".pts"")\n            data = None\n            copyright = self._links[name][""copyright""]\n\n            # check if file is already available in the temp directory and possibly read it from there\n            if os.path.isfile(image_filename):\n                data = Image.read(image_filename, dtype, device)\n            else:\n                # get the links from the database\n                link_mhd = self._links[name][image][0][""link_mhd""]\n                link_raw = self._links[name][image][0][""link_raw""]\n\n                # print copyright notice\n                print(""-------------------------------------------------------"")\n                print(""Downloading: ""+link_mhd)\n                print(""\\nCopyright notice for "" + identifier)\n                print(copyright)\n\n                try:\n                    # download the image\n                    urllib.request.urlretrieve(link_mhd, os.path.join(self._tmpdir, ""download.mhd""))\n                    urllib.request.urlretrieve(link_raw, os.path.join(self._tmpdir, ""download.raw""))\n                except:\n                    print(""Could not download the image"")\n                    raise\n\n                # adjust meta file to match the temporary download name\n                with open(os.path.join(self._tmpdir, ""download.mhd""), \'r\') as file:\n                    lines = file.readlines()\n\n                lines[-1] = lines[-1].split(""="")[0] + ""= download.raw""\n\n                with open(os.path.join(self._tmpdir, ""download.mhd""), \'w\') as file:\n                    file.write("""".join(lines))\n\n                # save image as mha file\n                data = Image.read(os.path.join(self._tmpdir, ""download.mhd""))\n                data.write(image_filename)\n\n\n            # load the corresponding points\n            points = None # by default, points is None\n\n            # check if the points have already been downloaded and available in the temp directory\n            if os.path.isfile(points_filename):\n                points = Points.read(points_filename)\n            else:\n                # get link from the database\n                link_pts = self._links[name][image][0][""link_pts""]\n                try:\n                    # download the points\n                    urllib.request.urlretrieve(link_pts, os.path.join(self._tmpdir, ""download.pts""))\n                    points = Points.read(os.path.join(self._tmpdir, ""download.pts""))\n                    Points.write(points_filename, points)\n                except:\n                    print(""Warning: for subject ""+name+"" and image ""+image+"" no points are defined."")\n\n\n            # make data item for the database and save the tuple consisting out of the image and the corresponding points\n            item = ImageLoader.DataItem(identifier, image_filename, copyright)\n            item.data = (data, points)\n\n            self._database[identifier] = item\n\n        return self._database[identifier].data\n\n\n    @staticmethod\n    def clear():\n        """"""\n        Delete database of images and the temp directory\n\n        Finally, a new temp directory is created\n        """"""\n        # clear dict\n        ImageLoader.__instance._database = {}\n\n        # delete temp files\n        shutil.rmtree(ImageLoader.__instance._tmpdir)\n\n        # generate new directory\n        ImageLoader.__instance._tmpdir = tempfile.mkdtemp()\n\n    @staticmethod\n    def get_temp_directory():\n        """"""\n        Returns the current temp directory\n        """"""\n        return ImageLoader.__instance._tmpdir\n\n\n    @staticmethod\n    def generate_database():\n        """"""\n        Generate database of links to the images which can be loaded. Currently, the 6 4DCT images of the POPI model\n        are supported.\n        return (dictionary): returns the database containing the names of the images and the respective links\n        """"""\n\n        # Adding DIR Validation Data to the database\n        tags = [""bl"", ""ng"", ""dx"", ""gt"", ""mm2"", ""bh""]\n        prefix = ""4DCT_POPI_""\n\n        data = {}\n        for i in range(len(tags)):\n            data[prefix+str(i)] = {}\n            for j in range(10):\n                data[prefix + str(i)][""image_"" + str(j) + ""0""] = []\n                data[prefix + str(i)][""image_"" + str(j) + ""0""].append(\n                {\n                  ""link_mhd"": ""https://www.creatis.insa-lyon.fr/~srit/POPI/MedPhys11/""+tags[i]+""/mhd/""+str(j)+""0.mhd"",\n                  ""link_raw"": ""https://www.creatis.insa-lyon.fr/~srit/POPI/MedPhys11/""+tags[i]+""/mhd/""+str(j)+""0.raw"",\n                  ""link_pts"": ""https://www.creatis.insa-lyon.fr/~srit/POPI/MedPhys11/""+tags[i]+""/pts/""+str(j)+""0.pts""\n                }\n                )\n            data[prefix + str(i)][""copyright""] = """"""\n    Data has been provided by the L\xc3\xa9on B\xc3\xa9rard Cancer Center & CREATIS lab, Lyon, France.\n    The data is described in:\n    \n    J. Vandemeulebroucke, S. Rit, J. Kybic, P. Clarysse, and D. Sarrut. \n    ""Spatiotemporal motion estimation for respiratory-correlated imaging of the lungs.""\n    In Med Phys, 2011, 38(1), 166-178.\n    \n    This data can be used for research only. If you use this data for your research, \n    please acknowledge the originators appropriately!\n    """"""\n\n        return data\n\n'"
airlab/utils/kernelFunction.py,1,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\nimport torch.nn.functional as F\nimport numpy as np\n\n""""""\nCreate a two dimensional mesh grid\n""""""\ndef _compute_mesh_grid_2d(kernel_size):\n\n    nx = int(kernel_size[0])\n    ny = int(kernel_size[1])\n\n    x = np.linspace(-(nx - 1)/2, (nx - 1)/2, num=nx)\n    y = np.linspace(-(ny - 1)/2, (ny - 1)/2, num=ny)\n\n    x_m, y_m = np.meshgrid(x, y)\n\n    return [x_m, y_m]\n\n""""""\nCreate a three dimensional mesh grid\n""""""\ndef _compute_mesh_grid_3d(kernel_size):\n\n    nx = int(kernel_size[0])\n    ny = int(kernel_size[1])\n    nz = int(kernel_size[2])\n\n    x = np.linspace(-(nx - 1)/2, (nx - 1)/2, num=nx)\n    y = np.linspace(-(ny - 1)/2, (ny - 1)/2, num=ny)\n    z = np.linspace(-(nz - 1)/2, (nz - 1)/2, num=nz)\n\n    x_m, y_m, z_m = np.meshgrid(x, y, z)\n\n    return [x_m, y_m, z_m]\n\n""""""\nCreate a one dimensional gaussian kernel matrix\n""""""\ndef gaussian_kernel_1d(sigma, asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n    kernel_size = int(2*np.ceil(sigma*2) + 1)\n\n    x = np.linspace(-(kernel_size - 1) // 2, (kernel_size - 1) // 2, num=kernel_size)\n\n    kernel = 1.0/(sigma*np.sqrt(2*np.pi))*np.exp(-(x**2)/(2*sigma**2))\n    kernel = kernel/np.sum(kernel)\n\n    if asTensor:\n        return th.tensor(kernel, dtype=dtype, device=device)\n    else:\n        return kernel\n\n\n""""""\nCreate a two dimensional gaussian kernel matrix\n""""""\ndef gaussian_kernel_2d(sigma, asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n    y_1 = gaussian_kernel_1d(sigma[0])\n    y_2 = gaussian_kernel_1d(sigma[1])\n\n    kernel = np.tensordot(y_1, y_2, 0)\n    kernel = kernel / np.sum(kernel)\n\n    if asTensor:\n        return th.tensor(kernel, dtype=dtype, device=device)\n    else:\n        return kernel\n\n""""""\nCreate a three dimensional gaussian kernel matrix\n""""""\ndef gaussian_kernel_3d(sigma, asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n    kernel_2d = gaussian_kernel_2d(sigma[:2])\n    kernel_1d = gaussian_kernel_1d(sigma[-1])\n\n    kernel = np.tensordot(kernel_2d, kernel_1d, 0)\n    kernel = kernel / np.sum(kernel)\n\n    if asTensor:\n        return th.tensor(kernel, dtype=dtype, device=device)\n    else:\n        return kernel\n\n\n""""""\n    Create a Gaussian kernel matrix\n""""""\ndef gaussian_kernel(sigma, dim=1, asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n    assert dim > 0 and dim <=3\n\n    if dim == 1:\n        return gaussian_kernel_1d(sigma, asTensor=asTensor, dtype=dtype, device=device)\n    elif dim == 2:\n        return gaussian_kernel_2d(sigma, asTensor=asTensor, dtype=dtype, device=device)\n    else:\n        return gaussian_kernel_3d(sigma, asTensor=asTensor, dtype=dtype, device=device)\n\n""""""\nCreate a 1d Wendland kernel matrix\n""""""\ndef wendland_kernel_1d(sigma, type=""C4"", asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n\tkernel_size = sigma*2 + 1\n\n\tx = np.linspace(-(kernel_size - 1) / 2, (kernel_size - 1) / 2, num=kernel_size)\n\n\tr = np.sqrt((x/float(sigma))**2)\n\tf = np.maximum(1 - r, 0)\n\n\t#kernel = ((f**6.0)*(3.0 + 18.0*r + 35.0*(r**2)))*(560.0/1680.0)\n\tif type==\'C2\':\n\t\tkernel = ((f**3.0)*(1.0 + 3.0*r))*5./4.\n\telif type==\'C4\':\n\t\tkernel = ((f**5.0)*(1.0 + 5.0*r + 8.0*(r**2)/3.))*3./2.\n\telif type==\'C6\':\n\t\tkernel = ((f**7.0)*(1.0 + 7.0*r + 19.0*(r**2) + 21*(r**3)))*55./32.\n\telse:\n\t\traise ValueError(type)\n\n\n\tif asTensor:\n\t\treturn th.tensor(kernel, dtype=dtype, device=device)\n\telse:\n\t\treturn kernel\n\n""""""\nCreate a 2d Wendland kernel matrix\n""""""\ndef wendland_kernel_2d(sigma, type=""C4"", asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n\tkernel_size = np.array(sigma)*2 + 1\n\n\txv, yv = _compute_mesh_grid_2d(kernel_size)\n\n\tr = np.sqrt((xv/sigma[0])**2 + (yv/sigma[1])**2)\n\tf = np.maximum(1 - r, 0)\n\n\tif type==\'C2\':\n\t\tkernel = ((f**4.0)*(1.0 + 4.0*r))*7./np.pi\n\telif type==\'C4\':\n\t\tkernel = ((f**6.0)*(1.0 + 6.0*r + 35.0*(r**2)/3.))*9./np.pi\n\telif type==\'C6\':\n\t\tkernel = ((f**8.0)*(1.0 + 8.0*r + 25.0*(r**2) + 32*(r**3)))*78./(7.*np.pi)\n\telse:\n\t\traise ValueError(type)\n\t\t\n\n\tif asTensor:\n\t\treturn th.tensor(kernel, dtype=dtype, device=device)\n\telse:\n\t\treturn kernel\n\n\n""""""\nCreate a 3d Wendland kernel matrix\n""""""\ndef wendland_kernel_3d(sigma, type=""C4"", asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n\tkernel_size = np.array(sigma)*2 + 1\n\n\tx_grid, y_grid, z_grid = _compute_mesh_grid_3d(kernel_size)\n\n\tr = np.sqrt((x_grid/sigma[0])**2 + (y_grid/sigma[1])**2 + (z_grid/sigma[2])**2)\n\tf = np.maximum(1 - r, 0)\n\n\t#kernel = ((f**6.0)*(3.0 + 18.0*r + 35.0*(r**2)))*(560.0/1680.0)\n\tif type==\'C2\':\n\t\tkernel = ((f**4.0)*(1.0 + 4.0*r))*21./(2.*np.pi)\n\telif type==\'C4\':\n\t\tkernel = ((f**6.0)*(1.0 + 6.0*r + 35.0*(r**2)/3.))*495./(32.*np.pi)\n\telif type==\'C6\':\n\t\tkernel = ((f**8.0)*(1.0 + 8.0*r + 25.0*(r**2) + 32*(r**3)))*1365./(64.*np.pi)\n\telse:\n\t\traise ValueError(type)\n\n\tif asTensor:\n\t\treturn th.tensor(kernel, dtype=dtype, device=device)\n\telse:\n\t\treturn kernel\n\n\n""""""\n    Create a Wendland kernel matrix\n""""""\ndef wendland_kernel(sigma, dim=1, type=""C4"", asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n    assert dim > 0 and dim <=3\n\n    if dim == 1:\n        return wendland_kernel_1d(sigma, type=type, asTensor=asTensor, dtype=dtype, device=device)\n    elif dim == 2:\n        return wendland_kernel_2d(sigma, type=type, asTensor=asTensor, dtype=dtype, device=device)\n    else:\n        return wendland_kernel_3d(sigma, type=type, asTensor=asTensor, dtype=dtype, device=device)\n\n\n""""""\n    Create a 1d bspline kernel matrix\n""""""\ndef bspline_kernel_1d(sigma, order=2, asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n    kernel_ones = th.ones(1, 1, sigma)\n    kernel = kernel_ones\n\t\n    padding = sigma - 1\n\n    for i in range(1, order + 1):\n        kernel = F.conv1d(kernel, kernel_ones, padding=padding)/sigma\n\t\n\n\n    if asTensor:\n        return kernel[0, 0, ...].to(dtype=dtype, device=device)\n    else:\n        return kernel[0, 0, ...].numpy()\n\n\n""""""\n    Create a 2d bspline kernel matrix\n""""""\ndef bspline_kernel_2d(sigma=[1, 1], order=2, asTensor=False, dtype=th.float32, device=\'cpu\'):\n    kernel_ones = th.ones(1, 1, *sigma)\n    kernel = kernel_ones\n    padding = np.array(sigma) - 1\n\n    for i in range(1, order + 1):\n        kernel = F.conv2d(kernel, kernel_ones, padding=(padding).tolist())/(sigma[0]*sigma[1])\n    \n\n\n    if asTensor:\n        return kernel[0, 0, ...].to(dtype=dtype, device=device)\n    else:\n        return kernel[0, 0, ...].numpy()\n\n\n""""""\n    Create a 3d bspline kernel matrix\n""""""\ndef bspline_kernel_3d(sigma=[1, 1, 1], order=2, asTensor=False, dtype=th.float32, device=\'cpu\'):\n    kernel_ones = th.ones(1, 1, *sigma)\n    kernel = kernel_ones\n    padding = np.array(sigma) - 1\n\n    for i in range(1, order + 1):\n        kernel = F.conv3d(kernel, kernel_ones, padding=(padding).tolist())/(sigma[0]*sigma[1]*sigma[2])\n\t\n\n\n    if asTensor:\n        return kernel[0, 0, ...].to(dtype=dtype, device=device)\n    else:\n        return kernel[0, 0, ...].numpy()\n\n\n""""""\n    Create a bspline kernel matrix for a given dim\n""""""\ndef bspline_kernel(sigma, order=2, dim=1, asTensor=False, dtype=th.float32, device=\'cpu\'):\n\n    assert dim > 0 and dim <=3\n\n    if dim == 1:\n        return bspline_kernel_1d(sigma, order=order, asTensor=asTensor, dtype=dtype, device=device)\n    elif dim == 2:\n        return bspline_kernel_2d(sigma, order=order, asTensor=asTensor, dtype=dtype, device=device)\n    else:\n        return bspline_kernel_3d(sigma, order=order, asTensor=asTensor, dtype=dtype, device=device)\n\n\n\n\n'"
airlab/utils/matrix.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch as th\n\nclass MatrixDiagonalElement():\n    def __init__(self, edge_index, edge_values, offset, dtype=th.float32, device=\'cpu\'):\n        self.edge_index = th.from_numpy(edge_index).to(dtype=th.int64, device=device)\n        self.edge_values = th.from_numpy(edge_values).to(dtype=dtype, device=device)\n        self.offset = offset.to(dtype=th.int64, device=device)\n\nclass LaplaceMatrix():\n    def __init__(self, number_of_nodes, diag_elements, dtype=th.float32, device=\'cpu\'):\n        self.main_diag = th.zeros(int(number_of_nodes), dtype=dtype, device=device)\n        self.diag_elements = diag_elements\n        self.size = int(number_of_nodes)\n\n\n        self.update()\n\n    def update(self):\n        self.main_diag.data.fill_(0)\n\n        for diag in self.diag_elements:\n            self.main_diag[diag.edge_index[-1, :]] -= diag.edge_values\n            self.main_diag[diag.edge_index[-1, :] + diag.offset] -= diag.edge_values\n\n    def full(self):\n        mat = th.zeros(self.size, self.size, dtype=self.main_diag.dtype, device=self.main_diag.device)\n        mat = mat + th.diag(self.main_diag)\n\n        for diag in self.diag_elements:\n            mat[diag.edge_index[-1, :], diag.edge_index[-1, :] + diag.offset] = diag.edge_values\n            mat[diag.edge_index[-1, :] + diag.offset, diag.edge_index[-1, :]] = diag.edge_values\n\n        return mat\n\n\n\ndef band_mv(A, x):\n\n    y = th.zeros(x.size()[0], dtype=x.dtype, device=x.device)\n\n    # add the main diagonal to the vector\n    th.mul(A.main_diag, x, out=y)\n\n    for diag in A.diag_elements:\n        y[diag.edge_index[-1, :]] += th.mul(x[diag.edge_index[-1, :] + diag.offset], diag.edge_values)\n        y[diag.edge_index[-1, :] + diag.offset] += th.mul(x[diag.edge_index[-1, :]], diag.edge_values)\n\n    return y\n\n\ndef expm_eig(A):\n    eigen_values, eigen_vector = th.eig(A, eigenvectors=True)\n\n    eigen_values.exp_()\n\n    return th.mm(th.mm(eigen_vector, th.diag(eigen_values[:, 0])), eigen_vector.t_())\n\n\ndef expm_krylov(A, x, phi=1, krylov_dim=30, inplace=True):\n\n    if krylov_dim > x.size()[0]:\n        krylov_dim = x.size()[0]\n\n    Q = th.zeros(x.size()[0], krylov_dim, dtype=x.dtype, device=x.device)\n    T = th.zeros(krylov_dim + 1, krylov_dim + 1, dtype=x.dtype, device=x.device)\n\n    #compute the norm of the vector\n    norm_x = th.norm(x, p=2)\n\n    # normalize vector\n    q = x/norm_x\n    Q[:, 0] = q.clone()\n\n    r = band_mv(A, q)\n\n    T[0, 0] = th.dot(q, r)\n    r = r - q.mul(T[0, 0])\n\n\n    T[0, 1] = th.norm(r, p=2) + 1e-10\n    T[1, 0] = T[0, 1]\n\n    for k in range(1, krylov_dim):\n        b = q\n        q = r\n\n        q.div_(T[k -1, k])\n\n        Q[:,k] = q.clone()\n\n        r = band_mv(A, q) - b.mul_(T[k -1, k])\n\n        T[k, k] = th.dot(q, r)\n\n        r =  r - q.mul(T[k, k])\n\n        T[k + 1, k] = th.norm(r, p=2) + 1e-10\n        T[k, k + 1] = T[k + 1, k]\n\n    T.mul_(phi)\n    exp_mat = expm_eig(T[:-1, :-1])\n\n    if inplace:\n        th.mv(Q, exp_mat[:,0], out=x)\n        x.mul_(norm_x)\n    else:\n        return  th.mv(Q, exp_mat[:,0]).mul_(x)\n\n\n\n\n\n\n\n'"
airlab/utils/points.py,0,"b'# Copyright 2018 University of Basel, Center for medical Image Analysis and Navigation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport torch as th\nimport SimpleITK as sitk\n\nfrom .image import Displacement\n\nclass Points:\n    """"""\n        Class implementing functionality for dealing with points:\n\n        - read/write: supported formats are pts and vtk (polydata)\n        - transform: transform the points given a displacement field\n        - TRE: calculates the target registration error between two point sets\n    """"""\n    @staticmethod\n    def read(filename):\n        """"""\n        Read points from file. Following formats are supported:\n\n        - pts: each point is represended in one line where the coordinates are separated with a tab\n\n        - vtk: the vtk polydata is supported as well\n\n        filename (str): filename\n        return (array): two dimensional array\n        """"""\n        if filename.endswith(""pts""):\n            points = []\n            with open(filename) as f:\n                lines = f.readlines()\n                for l in lines:\n                    points.append([float(p) for p in l.split()])\n            return np.array(points)\n\n        elif filename.endswith(""vtk""):\n            with open(filename) as f:\n                lines = f.readlines()\n                if not lines[1] == ""vtk output\\n"" and \\\n                    not lines[2] == ""ASCII\\n"" and \\\n                    not lines[3] == ""DATASET POLYDATA\\n"":\n                    raise Exception(""Tried to read corrupted vtk polydata file"")\n                n = int(lines[4].split()[1])\n\n                one_line = \'\'.join(\'\'.join(lines[5:]).split(\'\\n\'))\n                one_line = [float(p) for p in one_line.split()]\n                return np.array(one_line).reshape((n, 3))\n\n        else:\n            raise Exception(""Format not supported: ""+str(filename))\n\n    @staticmethod\n    def write(filename, points):\n        """"""\n        Write point list to hard drive\n        filename (str): destination filename\n        points (array): two dimensional array\n        """"""\n        if filename.endswith(""pts""):\n            with open(filename, \'w\') as f:\n                for p in points:\n                    f.write(\'\\t\'.join([str(v) for v in p])+\'\\n\')\n\n        elif filename.endswith(""vtk""):\n            n = points.shape[0]\n            with open(filename, \'w\') as f:\n                f.write(""# vtk DataFile Version 3.0\\n"")\n                f.write(""vtk output\\n"")\n                f.write(""ASCII\\n"")\n                f.write(""DATASET POLYDATA\\n"")\n                f.write(""POINTS ""+str(n)+"" float\\n"")\n                for p in points:\n                    f.write(\'\\t\'.join([str(v) for v in p])+\'\\n\')\n\n        else:\n            raise Exception(""Format not supported: ""+str(filename))\n\n    @staticmethod\n    def transform(points, displacement):\n        """"""\n        Transforms a set of points with a displacement field\n\n        points (array): array of points\n        displacement (SimpleITK.Image | Displacement ): displacement field to transform points\n        return (array): transformed points\n        """"""\n        if type(displacement) == sitk.SimpleITK.Image:\n            df_transform = sitk.DisplacementFieldTransform(displacement)\n        elif type(displacement) == Displacement:\n            df_transform = sitk.DisplacementFieldTransform(displacement.to(dtype=th.float64).itk())\n        else:\n            raise Exception(""Datatype of displacement field not supported."")\n\n        df_transform.SetSmoothingOff()\n\n        transformed_points = np.zeros_like(points)\n        for i in range(points.shape[0]):\n            transformed_points[i, :] = df_transform.TransformPoint(points[i, :])\n\n        return transformed_points\n\n    @staticmethod\n    def TRE(points1, points2):\n        """"""\n        Computes the average distance between points in points1 and points2\n\n        Note: if there is a different amount of points in the two sets, only the first points are compared\n\n        points1 (array): point set 1\n        points2 (array): point set 2\n        return (float): mean difference\n        """"""\n        n = min(points1.shape[0], points2.shape[0])\n        return np.mean(np.linalg.norm(points1[:n,:]-points2[:n,:], axis=1))\n'"
