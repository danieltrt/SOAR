file_path,api_count,code
datasets.py,1,"b""import glob\nimport random\nimport os\n\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\nclass ImageDataset(Dataset):\n    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n        self.transform = transforms.Compose(transforms_)\n        self.unaligned = unaligned\n\n        self.files_A = sorted(glob.glob(os.path.join(root, '%s/A' % mode) + '/*.*'))\n        self.files_B = sorted(glob.glob(os.path.join(root, '%s/B' % mode) + '/*.*'))\n\n    def __getitem__(self, index):\n        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n\n        if self.unaligned:\n            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\n        else:\n            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n\n        return {'A': item_A, 'B': item_B}\n\n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))"""
models.py,2,"b'import torch.nn as nn\nimport torch.nn.functional as F\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_features):\n        super(ResidualBlock, self).__init__()\n\n        conv_block = [  nn.ReflectionPad2d(1),\n                        nn.Conv2d(in_features, in_features, 3),\n                        nn.InstanceNorm2d(in_features),\n                        nn.ReLU(inplace=True),\n                        nn.ReflectionPad2d(1),\n                        nn.Conv2d(in_features, in_features, 3),\n                        nn.InstanceNorm2d(in_features)  ]\n\n        self.conv_block = nn.Sequential(*conv_block)\n\n    def forward(self, x):\n        return x + self.conv_block(x)\n\nclass Generator(nn.Module):\n    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n        super(Generator, self).__init__()\n\n        # Initial convolution block       \n        model = [   nn.ReflectionPad2d(3),\n                    nn.Conv2d(input_nc, 64, 7),\n                    nn.InstanceNorm2d(64),\n                    nn.ReLU(inplace=True) ]\n\n        # Downsampling\n        in_features = 64\n        out_features = in_features*2\n        for _ in range(2):\n            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n                        nn.InstanceNorm2d(out_features),\n                        nn.ReLU(inplace=True) ]\n            in_features = out_features\n            out_features = in_features*2\n\n        # Residual blocks\n        for _ in range(n_residual_blocks):\n            model += [ResidualBlock(in_features)]\n\n        # Upsampling\n        out_features = in_features//2\n        for _ in range(2):\n            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n                        nn.InstanceNorm2d(out_features),\n                        nn.ReLU(inplace=True) ]\n            in_features = out_features\n            out_features = in_features//2\n\n        # Output layer\n        model += [  nn.ReflectionPad2d(3),\n                    nn.Conv2d(64, output_nc, 7),\n                    nn.Tanh() ]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)\n\nclass Discriminator(nn.Module):\n    def __init__(self, input_nc):\n        super(Discriminator, self).__init__()\n\n        # A bunch of convolutions one after another\n        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n                    nn.LeakyReLU(0.2, inplace=True) ]\n\n        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\n                    nn.InstanceNorm2d(128), \n                    nn.LeakyReLU(0.2, inplace=True) ]\n\n        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n                    nn.InstanceNorm2d(256), \n                    nn.LeakyReLU(0.2, inplace=True) ]\n\n        model += [  nn.Conv2d(256, 512, 4, padding=1),\n                    nn.InstanceNorm2d(512), \n                    nn.LeakyReLU(0.2, inplace=True) ]\n\n        # FCN classification layer\n        model += [nn.Conv2d(512, 1, 4, padding=1)]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        x =  self.model(x)\n        # Average pooling and flatten\n        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)'"
utils.py,6,"b'import random\nimport time\nimport datetime\nimport sys\n\nfrom torch.autograd import Variable\nimport torch\nfrom visdom import Visdom\nimport numpy as np\n\ndef tensor2image(tensor):\n    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n    if image.shape[0] == 1:\n        image = np.tile(image, (3,1,1))\n    return image.astype(np.uint8)\n\nclass Logger():\n    def __init__(self, n_epochs, batches_epoch):\n        self.viz = Visdom()\n        self.n_epochs = n_epochs\n        self.batches_epoch = batches_epoch\n        self.epoch = 1\n        self.batch = 1\n        self.prev_time = time.time()\n        self.mean_period = 0\n        self.losses = {}\n        self.loss_windows = {}\n        self.image_windows = {}\n\n\n    def log(self, losses=None, images=None):\n        self.mean_period += (time.time() - self.prev_time)\n        self.prev_time = time.time()\n\n        sys.stdout.write(\'\\rEpoch %03d/%03d [%04d/%04d] -- \' % (self.epoch, self.n_epochs, self.batch, self.batches_epoch))\n\n        for i, loss_name in enumerate(losses.keys()):\n            if loss_name not in self.losses:\n                self.losses[loss_name] = losses[loss_name].data[0]\n            else:\n                self.losses[loss_name] += losses[loss_name].data[0]\n\n            if (i+1) == len(losses.keys()):\n                sys.stdout.write(\'%s: %.4f -- \' % (loss_name, self.losses[loss_name]/self.batch))\n            else:\n                sys.stdout.write(\'%s: %.4f | \' % (loss_name, self.losses[loss_name]/self.batch))\n\n        batches_done = self.batches_epoch*(self.epoch - 1) + self.batch\n        batches_left = self.batches_epoch*(self.n_epochs - self.epoch) + self.batches_epoch - self.batch \n        sys.stdout.write(\'ETA: %s\' % (datetime.timedelta(seconds=batches_left*self.mean_period/batches_done)))\n\n        # Draw images\n        for image_name, tensor in images.items():\n            if image_name not in self.image_windows:\n                self.image_windows[image_name] = self.viz.image(tensor2image(tensor.data), opts={\'title\':image_name})\n            else:\n                self.viz.image(tensor2image(tensor.data), win=self.image_windows[image_name], opts={\'title\':image_name})\n\n        # End of epoch\n        if (self.batch % self.batches_epoch) == 0:\n            # Plot losses\n            for loss_name, loss in self.losses.items():\n                if loss_name not in self.loss_windows:\n                    self.loss_windows[loss_name] = self.viz.line(X=np.array([self.epoch]), Y=np.array([loss/self.batch]), \n                                                                    opts={\'xlabel\': \'epochs\', \'ylabel\': loss_name, \'title\': loss_name})\n                else:\n                    self.viz.line(X=np.array([self.epoch]), Y=np.array([loss/self.batch]), win=self.loss_windows[loss_name], update=\'append\')\n                # Reset losses for next epoch\n                self.losses[loss_name] = 0.0\n\n            self.epoch += 1\n            self.batch = 1\n            sys.stdout.write(\'\\n\')\n        else:\n            self.batch += 1\n\n        \n\nclass ReplayBuffer():\n    def __init__(self, max_size=50):\n        assert (max_size > 0), \'Empty buffer or trying to create a black hole. Be careful.\'\n        self.max_size = max_size\n        self.data = []\n\n    def push_and_pop(self, data):\n        to_return = []\n        for element in data.data:\n            element = torch.unsqueeze(element, 0)\n            if len(self.data) < self.max_size:\n                self.data.append(element)\n                to_return.append(element)\n            else:\n                if random.uniform(0,1) > 0.5:\n                    i = random.randint(0, self.max_size-1)\n                    to_return.append(self.data[i].clone())\n                    self.data[i] = element\n                else:\n                    to_return.append(element)\n        return Variable(torch.cat(to_return))\n\nclass LambdaLR():\n    def __init__(self, n_epochs, offset, decay_start_epoch):\n        assert ((n_epochs - decay_start_epoch) > 0), ""Decay must start before the training session ends!""\n        self.n_epochs = n_epochs\n        self.offset = offset\n        self.decay_start_epoch = decay_start_epoch\n\n    def step(self, epoch):\n        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Conv\') != -1:\n        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find(\'BatchNorm2d\') != -1:\n        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant(m.bias.data, 0.0)\n\n'"
