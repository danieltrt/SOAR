file_path,api_count,code
resnet.py,4,"b'\'\'\'\nProperly implemented ResNet-s for CIFAR10 as described in paper [1].\n\nThe implementation and structure of this file is hugely influenced by [2]\nwhich is implemented for ImageNet and doesn\'t have option A for identity.\nMoreover, most of the implementations on the web is copy-paste from\ntorchvision\'s resnet and has wrong number of params.\n\nProper ResNet-s for CIFAR10 (for fair comparision and etc.) has following\nnumber of layers and parameters:\n\nname      | layers | params\nResNet20  |    20  | 0.27M\nResNet32  |    32  | 0.46M\nResNet44  |    44  | 0.66M\nResNet56  |    56  | 0.85M\nResNet110 |   110  |  1.7M\nResNet1202|  1202  | 19.4m\n\nwhich this implementation indeed has.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n[2] https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n\nIf you use this implementation in you work, please don\'t forget to mention the\nauthor, Yerlan Idelbayev.\n\'\'\'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\n\nfrom torch.autograd import Variable\n\n__all__ = [\'ResNet\', \'resnet20\', \'resnet32\', \'resnet44\', \'resnet56\', \'resnet110\', \'resnet1202\']\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    #print(classname)\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass LambdaLayer(nn.Module):\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option=\'A\'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == \'A\':\n                """"""\n                For CIFAR10 ResNet paper uses option A.\n                """"""\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), ""constant"", 0))\n            elif option == \'B\':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n        self.linear = nn.Linear(64, num_classes)\n\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef resnet20():\n    return ResNet(BasicBlock, [3, 3, 3])\n\n\ndef resnet32():\n    return ResNet(BasicBlock, [5, 5, 5])\n\n\ndef resnet44():\n    return ResNet(BasicBlock, [7, 7, 7])\n\n\ndef resnet56():\n    return ResNet(BasicBlock, [9, 9, 9])\n\n\ndef resnet110():\n    return ResNet(BasicBlock, [18, 18, 18])\n\n\ndef resnet1202():\n    return ResNet(BasicBlock, [200, 200, 200])\n\n\ndef test(net):\n    import numpy as np\n    total_params = 0\n\n    for x in filter(lambda p: p.requires_grad, net.parameters()):\n        total_params += np.prod(x.data.numpy().shape)\n    print(""Total number of params"", total_params)\n    print(""Total layers"", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n\n\nif __name__ == ""__main__"":\n    for net_name in __all__:\n        if net_name.startswith(\'resnet\'):\n            print(net_name)\n            test(globals()[net_name]())\n            print()'"
trainer.py,13,"b'import argparse\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport resnet\n\nmodel_names = sorted(name for name in resnet.__dict__\n    if name.islower() and not name.startswith(""__"")\n                     and name.startswith(""resnet"")\n                     and callable(resnet.__dict__[name]))\n\nprint(model_names)\n\nparser = argparse.ArgumentParser(description=\'Propert ResNets for CIFAR10 in pytorch\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet32\',\n                    choices=model_names,\n                    help=\'model architecture: \' + \' | \'.join(model_names) +\n                    \' (default: resnet32)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=200, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=128, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 128)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=50, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 50)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--half\', dest=\'half\', action=\'store_true\',\n                    help=\'use half-precision(16-bit) \')\nparser.add_argument(\'--save-dir\', dest=\'save_dir\',\n                    help=\'The directory used to save the trained models\',\n                    default=\'save_temp\', type=str)\nparser.add_argument(\'--save-every\', dest=\'save_every\',\n                    help=\'Saves checkpoints at every specified number of epochs\',\n                    type=int, default=10)\nbest_prec1 = 0\n\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n\n    # Check the save_dir exists or not\n    if not os.path.exists(args.save_dir):\n        os.makedirs(args.save_dir)\n\n    model = torch.nn.DataParallel(resnet.__dict__[args.arch]())\n    model.cuda()\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.evaluate, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root=\'./data\', train=True, transform=transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomCrop(32, 4),\n            transforms.ToTensor(),\n            normalize,\n        ]), download=True),\n        batch_size=args.batch_size, shuffle=True,\n        num_workers=args.workers, pin_memory=True)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root=\'./data\', train=False, transform=transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=128, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    if args.half:\n        model.half()\n        criterion.half()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n                                                        milestones=[100, 150], last_epoch=args.start_epoch - 1)\n\n    if args.arch in [\'resnet1202\', \'resnet110\']:\n        # for resnet1202 original paper uses lr=0.01 for first 400 minibatches for warm-up\n        # then switch back. In this setup it will correspond for first epoch.\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = args.lr*0.1\n\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n\n        # train for one epoch\n        print(\'current lr {:.5e}\'.format(optimizer.param_groups[0][\'lr\']))\n        train(train_loader, model, criterion, optimizer, epoch)\n        lr_scheduler.step()\n\n        # evaluate on validation set\n        prec1 = validate(val_loader, model, criterion)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n\n        if epoch > 0 and epoch % args.save_every == 0:\n            save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'best_prec1\': best_prec1,\n            }, is_best, filename=os.path.join(args.save_dir, \'checkpoint.th\'))\n\n        save_checkpoint({\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n        }, is_best, filename=os.path.join(args.save_dir, \'model.th\'))\n\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    """"""\n        Run one train epoch\n    """"""\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda()\n        input_var = input.cuda()\n        target_var = target\n        if args.half:\n            input_var = input_var.half()\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        output = output.float()\n        loss = loss.float()\n        # measure accuracy and record loss\n        prec1 = accuracy(output.data, target)[0]\n        losses.update(loss.item(), input.size(0))\n        top1.update(prec1.item(), input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\'.format(\n                      epoch, i, len(train_loader), batch_time=batch_time,\n                      data_time=data_time, loss=losses, top1=top1))\n\n\ndef validate(val_loader, model, criterion):\n    """"""\n    Run evaluation\n    """"""\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    with torch.no_grad():\n        for i, (input, target) in enumerate(val_loader):\n            target = target.cuda()\n            input_var = input.cuda()\n            target_var = target.cuda()\n\n            if args.half:\n                input_var = input_var.half()\n\n            # compute output\n            output = model(input_var)\n            loss = criterion(output, target_var)\n\n            output = output.float()\n            loss = loss.float()\n\n            # measure accuracy and record loss\n            prec1 = accuracy(output.data, target)[0]\n            losses.update(loss.item(), input.size(0))\n            top1.update(prec1.item(), input.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % args.print_freq == 0:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\'.format(\n                          i, len(val_loader), batch_time=batch_time, loss=losses,\n                          top1=top1))\n\n    print(\' * Prec@1 {top1.avg:.3f}\'\n          .format(top1=top1))\n\n    return top1.avg\n\ndef save_checkpoint(state, is_best, filename=\'checkpoint.pth.tar\'):\n    """"""\n    Save the training model\n    """"""\n    torch.save(state, filename)\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nif __name__ == \'__main__\':\n    main()\n'"
