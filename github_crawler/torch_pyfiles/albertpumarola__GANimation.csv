file_path,api_count,code
test.py,3,"b""import os\nimport argparse\nimport glob\nimport cv2\nfrom utils import face_utils\nfrom utils import cv_utils\nimport face_recognition\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport torch\nimport pickle\nimport numpy as np\nfrom models.models import ModelsFactory\nfrom options.test_options import TestOptions\n\nclass MorphFacesInTheWild:\n    def __init__(self, opt):\n        self._opt = opt\n        self._model = ModelsFactory.get_by_name(self._opt.model, self._opt)\n        self._model.set_eval()\n        self._transform = transforms.Compose([transforms.ToTensor(),\n                                              transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                                                   std=[0.5, 0.5, 0.5])\n                                              ])\n\n    def morph_file(self, img_path, expresion):\n        img = cv_utils.read_cv2_img(img_path)\n        morphed_img = self._img_morph(img, expresion)\n        output_name = '%s_out.png' % os.path.basename(img_path)\n        self._save_img(morphed_img, output_name)\n\n    def _img_morph(self, img, expresion):\n        bbs = face_recognition.face_locations(img)\n        if len(bbs) > 0:\n            y, right, bottom, x = bbs[0]\n            bb = x, y, (right - x), (bottom - y)\n            face = face_utils.crop_face_with_bb(img, bb)\n            face = face_utils.resize_face(face)\n        else:\n            face = face_utils.resize_face(img)\n\n        morphed_face = self._morph_face(face, expresion)\n\n        return morphed_face\n\n    def _morph_face(self, face, expresion):\n        face = torch.unsqueeze(self._transform(Image.fromarray(face)), 0)\n        expresion = torch.unsqueeze(torch.from_numpy(expresion/5.0), 0)\n        test_batch = {'real_img': face, 'real_cond': expresion, 'desired_cond': expresion, 'sample_id': torch.FloatTensor(), 'real_img_path': []}\n        self._model.set_input(test_batch)\n        imgs, _ = self._model.forward(keep_data_for_visuals=False, return_estimates=True)\n        return imgs['concat']\n\n    def _save_img(self, img, filename):\n        filepath = os.path.join(self._opt.output_dir, filename)\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(filepath, img)\n\n\ndef main():\n    opt = TestOptions().parse()\n    if not os.path.isdir(opt.output_dir):\n        os.makedirs(opt.output_dir)\n\n    morph = MorphFacesInTheWild(opt)\n\n    image_path = opt.input_path\n    expression = np.random.uniform(0, 1, opt.cond_nc)\n    morph.morph_file(image_path, expression)\n\n\n\nif __name__ == '__main__':\n    main()\n"""
train.py,0,"b'import time\nfrom options.train_options import TrainOptions\nfrom data.custom_dataset_data_loader import CustomDatasetDataLoader\nfrom models.models import ModelsFactory\nfrom utils.tb_visualizer import TBVisualizer\nfrom collections import OrderedDict\nimport os\n\n\nclass Train:\n    def __init__(self):\n        self._opt = TrainOptions().parse()\n        data_loader_train = CustomDatasetDataLoader(self._opt, is_for_train=True)\n        data_loader_test = CustomDatasetDataLoader(self._opt, is_for_train=False)\n\n        self._dataset_train = data_loader_train.load_data()\n        self._dataset_test = data_loader_test.load_data()\n\n        self._dataset_train_size = len(data_loader_train)\n        self._dataset_test_size = len(data_loader_test)\n        print(\'#train images = %d\' % self._dataset_train_size)\n        print(\'#test images = %d\' % self._dataset_test_size)\n\n        self._model = ModelsFactory.get_by_name(self._opt.model, self._opt)\n        self._tb_visualizer = TBVisualizer(self._opt)\n\n        self._train()\n\n    def _train(self):\n        self._total_steps = self._opt.load_epoch * self._dataset_train_size\n        self._iters_per_epoch = self._dataset_train_size / self._opt.batch_size\n        self._last_display_time = None\n        self._last_save_latest_time = None\n        self._last_print_time = time.time()\n\n        for i_epoch in range(self._opt.load_epoch + 1, self._opt.nepochs_no_decay + self._opt.nepochs_decay + 1):\n            epoch_start_time = time.time()\n\n            # train epoch\n            self._train_epoch(i_epoch)\n\n            # save model\n            print(\'saving the model at the end of epoch %d, iters %d\' % (i_epoch, self._total_steps))\n            self._model.save(i_epoch)\n\n            # print epoch info\n            time_epoch = time.time() - epoch_start_time\n            print(\'End of epoch %d / %d \\t Time Taken: %d sec (%d min or %d h)\' %\n                  (i_epoch, self._opt.nepochs_no_decay + self._opt.nepochs_decay, time_epoch,\n                   time_epoch / 60, time_epoch / 3600))\n\n            # update learning rate\n            if i_epoch > self._opt.nepochs_no_decay:\n                self._model.update_learning_rate()\n\n    def _train_epoch(self, i_epoch):\n        epoch_iter = 0\n        self._model.set_train()\n        for i_train_batch, train_batch in enumerate(self._dataset_train):\n            iter_start_time = time.time()\n\n            # display flags\n            do_visuals = self._last_display_time is None or time.time() - self._last_display_time > self._opt.display_freq_s\n            do_print_terminal = time.time() - self._last_print_time > self._opt.print_freq_s or do_visuals\n\n            # train model\n            self._model.set_input(train_batch)\n            train_generator = ((i_train_batch+1) % self._opt.train_G_every_n_iterations == 0) or do_visuals\n            self._model.optimize_parameters(keep_data_for_visuals=do_visuals, train_generator=train_generator)\n\n            # update epoch info\n            self._total_steps += self._opt.batch_size\n            epoch_iter += self._opt.batch_size\n\n            # display terminal\n            if do_print_terminal:\n                self._display_terminal(iter_start_time, i_epoch, i_train_batch, do_visuals)\n                self._last_print_time = time.time()\n\n            # display visualizer\n            if do_visuals:\n                self._display_visualizer_train(self._total_steps)\n                self._display_visualizer_val(i_epoch, self._total_steps)\n                self._last_display_time = time.time()\n\n            # save model\n            if self._last_save_latest_time is None or time.time() - self._last_save_latest_time > self._opt.save_latest_freq_s:\n                print(\'saving the latest model (epoch %d, total_steps %d)\' % (i_epoch, self._total_steps))\n                self._model.save(i_epoch)\n                self._last_save_latest_time = time.time()\n\n    def _display_terminal(self, iter_start_time, i_epoch, i_train_batch, visuals_flag):\n        errors = self._model.get_current_errors()\n        t = (time.time() - iter_start_time) / self._opt.batch_size\n        self._tb_visualizer.print_current_train_errors(i_epoch, i_train_batch, self._iters_per_epoch, errors, t, visuals_flag)\n\n    def _display_visualizer_train(self, total_steps):\n        self._tb_visualizer.display_current_results(self._model.get_current_visuals(), total_steps, is_train=True)\n        self._tb_visualizer.plot_scalars(self._model.get_current_errors(), total_steps, is_train=True)\n        self._tb_visualizer.plot_scalars(self._model.get_current_scalars(), total_steps, is_train=True)\n\n    def _display_visualizer_val(self, i_epoch, total_steps):\n        val_start_time = time.time()\n\n        # set model to eval\n        self._model.set_eval()\n\n        # evaluate self._opt.num_iters_validate epochs\n        val_errors = OrderedDict()\n        for i_val_batch, val_batch in enumerate(self._dataset_test):\n            if i_val_batch == self._opt.num_iters_validate:\n                break\n\n            # evaluate model\n            self._model.set_input(val_batch)\n            self._model.forward(keep_data_for_visuals=(i_val_batch == 0))\n            errors = self._model.get_current_errors()\n\n            # store current batch errors\n            for k, v in errors.iteritems():\n                if k in val_errors:\n                    val_errors[k] += v\n                else:\n                    val_errors[k] = v\n\n        # normalize errors\n        for k in val_errors.iterkeys():\n            val_errors[k] /= self._opt.num_iters_validate\n\n        # visualize\n        t = (time.time() - val_start_time)\n        self._tb_visualizer.print_current_validate_errors(i_epoch, val_errors, t)\n        self._tb_visualizer.plot_scalars(val_errors, total_steps, is_train=False)\n        self._tb_visualizer.display_current_results(self._model.get_current_visuals(), total_steps, is_train=False)\n\n        # set model back to train\n        self._model.set_train()\n\n\nif __name__ == ""__main__"":\n    Train()\n'"
data/__init__.py,0,b''
data/custom_dataset_data_loader.py,2,"b'import torch.utils.data\nfrom data.dataset import DatasetFactory\n\n\nclass CustomDatasetDataLoader:\n    def __init__(self, opt, is_for_train=True):\n        self._opt = opt\n        self._is_for_train = is_for_train\n        self._num_threds = opt.n_threads_train if is_for_train else opt.n_threads_test\n        self._create_dataset()\n\n    def _create_dataset(self):\n        self._dataset = DatasetFactory.get_by_name(self._opt.dataset_mode, self._opt, self._is_for_train)\n        self._dataloader = torch.utils.data.DataLoader(\n            self._dataset,\n            batch_size=self._opt.batch_size,\n            shuffle=not self._opt.serial_batches,\n            num_workers=int(self._num_threds),\n            drop_last=True)\n\n    def load_data(self):\n        return self._dataloader\n\n    def __len__(self):\n        return len(self._dataset)\n'"
data/dataset.py,1,"b'import torch.utils.data as data\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport os\nimport os.path\n\n\nclass DatasetFactory:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def get_by_name(dataset_name, opt, is_for_train):\n        if dataset_name == \'aus\':\n            from data.dataset_aus import AusDataset\n            dataset = AusDataset(opt, is_for_train)\n        else:\n            raise ValueError(""Dataset [%s] not recognized."" % dataset_name)\n\n        print(\'Dataset {} was created\'.format(dataset.name))\n        return dataset\n\n\nclass DatasetBase(data.Dataset):\n    def __init__(self, opt, is_for_train):\n        super(DatasetBase, self).__init__()\n        self._name = \'BaseDataset\'\n        self._root = None\n        self._opt = opt\n        self._is_for_train = is_for_train\n        self._create_transform()\n\n        self._IMG_EXTENSIONS = [\n            \'.jpg\', \'.JPG\', \'.jpeg\', \'.JPEG\',\n            \'.png\', \'.PNG\', \'.ppm\', \'.PPM\', \'.bmp\', \'.BMP\',\n        ]\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def path(self):\n        return self._root\n\n    def _create_transform(self):\n        self._transform = transforms.Compose([])\n\n    def get_transform(self):\n        return self._transform\n\n    def _is_image_file(self, filename):\n        return any(filename.endswith(extension) for extension in self._IMG_EXTENSIONS)\n\n    def _is_csv_file(self, filename):\n        return filename.endswith(\'.csv\')\n\n    def _get_all_files_in_subfolders(self, dir, is_file):\n        images = []\n        assert os.path.isdir(dir), \'%s is not a valid directory\' % dir\n\n        for root, _, fnames in sorted(os.walk(dir)):\n            for fname in fnames:\n                if is_file(fname):\n                    path = os.path.join(root, fname)\n                    images.append(path)\n\n        return images\n'"
data/dataset_aus.py,0,"b""import os.path\nimport torchvision.transforms as transforms\nfrom data.dataset import DatasetBase\nfrom PIL import Image\nimport random\nimport numpy as np\nimport pickle\nfrom utils import cv_utils\n\n\nclass AusDataset(DatasetBase):\n    def __init__(self, opt, is_for_train):\n        super(AusDataset, self).__init__(opt, is_for_train)\n        self._name = 'AusDataset'\n\n        # read dataset\n        self._read_dataset_paths()\n\n    def __getitem__(self, index):\n        assert (index < self._dataset_size)\n\n        # start_time = time.time()\n        real_img = None\n        real_cond = None\n        while real_img is None or real_cond is None:\n            # if sample randomly: overwrite index\n            if not self._opt.serial_batches:\n                index = random.randint(0, self._dataset_size - 1)\n\n            # get sample data\n            sample_id = self._ids[index]\n\n            real_img, real_img_path = self._get_img_by_id(sample_id)\n            real_cond = self._get_cond_by_id(sample_id)\n\n            if real_img is None:\n                print 'error reading image %s, skipping sample' % sample_id\n            if real_cond is None:\n                print 'error reading aus %s, skipping sample' % sample_id\n\n        desired_cond = self._generate_random_cond()\n\n        # transform data\n        img = self._transform(Image.fromarray(real_img))\n\n        # pack data\n        sample = {'real_img': img,\n                  'real_cond': real_cond,\n                  'desired_cond': desired_cond,\n                  'sample_id': sample_id,\n                  'real_img_path': real_img_path\n                  }\n\n        # print (time.time() - start_time)\n\n        return sample\n\n    def __len__(self):\n        return self._dataset_size\n\n    def _read_dataset_paths(self):\n        self._root = self._opt.data_dir\n        self._imgs_dir = os.path.join(self._root, self._opt.images_folder)\n\n        # read ids\n        use_ids_filename = self._opt.train_ids_file if self._is_for_train else self._opt.test_ids_file\n        use_ids_filepath = os.path.join(self._root, use_ids_filename)\n        self._ids = self._read_ids(use_ids_filepath)\n\n        # read aus\n        conds_filepath = os.path.join(self._root, self._opt.aus_file)\n        self._conds = self._read_conds(conds_filepath)\n\n        self._ids = list(set(self._ids).intersection(set(self._conds.keys())))\n\n        # dataset size\n        self._dataset_size = len(self._ids)\n\n    def _create_transform(self):\n        if self._is_for_train:\n            transform_list = [transforms.RandomHorizontalFlip(),\n                              transforms.ToTensor(),\n                              transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                                   std=[0.5, 0.5, 0.5]),\n                              ]\n        else:\n            transform_list = [transforms.ToTensor(),\n                              transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                                   std=[0.5, 0.5, 0.5]),\n                              ]\n        self._transform = transforms.Compose(transform_list)\n\n    def _read_ids(self, file_path):\n        ids = np.loadtxt(file_path, delimiter='\\t', dtype=np.str)\n        return [id[:-4] for id in ids]\n\n    def _read_conds(self, file_path):\n        with open(file_path, 'rb') as f:\n            return pickle.load(f)\n\n    def _get_cond_by_id(self, id):\n        if id in self._conds:\n            return self._conds[id]/5.0\n        else:\n            return None\n\n    def _get_img_by_id(self, id):\n        filepath = os.path.join(self._imgs_dir, id+'.jpg')\n        return cv_utils.read_cv2_img(filepath), filepath\n\n    def _generate_random_cond(self):\n        cond = None\n        while cond is None:\n            rand_sample_id = self._ids[random.randint(0, self._dataset_size - 1)]\n            cond = self._get_cond_by_id(rand_sample_id)\n            cond += np.random.uniform(-0.1, 0.1, cond.shape)\n        return cond\n"""
data/prepare_au_annotations.py,0,"b'import numpy as np\nimport os\nfrom tqdm import tqdm\nimport argparse\nimport glob\nimport re\nimport pickle\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'-ia\', \'--input_aus_filesdir\', type=str, help=\'Dir with imgs aus files\')\nparser.add_argument(\'-op\', \'--output_path\', type=str, help=\'Output path\')\nargs = parser.parse_args()\n\ndef get_data(filepaths):\n    data = dict()\n    for filepath in tqdm(filepaths):\n        content = np.loadtxt(filepath, delimiter=\', \', skiprows=1)\n        data[os.path.basename(filepath[:-4])] = content[2:19]\n\n    return data\n\ndef save_dict(data, name):\n    with open(name + \'.pkl\', \'wb\') as f:\n        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n\ndef main():\n    filepaths = glob.glob(os.path.join(args.input_aus_filesdir, \'*.csv\'))\n    filepaths.sort()\n\n    # create aus file\n    data = get_data(filepaths)\n\n    if not os.path.isdir(args.output_path):\n        os.makedirs(args.output_path)\n    save_dict(data, os.path.join(args.output_path, ""aus""))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
models/__init__.py,0,b''
models/ganimation.py,20,"b""import torch\nfrom collections import OrderedDict\nfrom torch.autograd import Variable\nimport utils.util as util\nimport utils.plots as plot_utils\nfrom .models import BaseModel\nfrom networks.networks import NetworksFactory\nimport os\nimport numpy as np\n\n\nclass GANimation(BaseModel):\n    def __init__(self, opt):\n        super(GANimation, self).__init__(opt)\n        self._name = 'GANimation'\n\n        # create networks\n        self._init_create_networks()\n\n        # init train variables\n        if self._is_train:\n            self._init_train_vars()\n\n        # load networks and optimizers\n        if not self._is_train or self._opt.load_epoch > 0:\n            self.load()\n\n        # prefetch variables\n        self._init_prefetch_inputs()\n\n        # init\n        self._init_losses()\n\n    def _init_create_networks(self):\n        # generator network\n        self._G = self._create_generator()\n        self._G.init_weights()\n        if len(self._gpu_ids) > 1:\n            self._G = torch.nn.DataParallel(self._G, device_ids=self._gpu_ids)\n        self._G.cuda()\n\n        # discriminator network\n        self._D = self._create_discriminator()\n        self._D.init_weights()\n        if len(self._gpu_ids) > 1:\n            self._D = torch.nn.DataParallel(self._D, device_ids=self._gpu_ids)\n        self._D.cuda()\n\n    def _create_generator(self):\n        return NetworksFactory.get_by_name('generator_wasserstein_gan', c_dim=self._opt.cond_nc)\n\n    def _create_discriminator(self):\n        return NetworksFactory.get_by_name('discriminator_wasserstein_gan', c_dim=self._opt.cond_nc)\n\n    def _init_train_vars(self):\n        self._current_lr_G = self._opt.lr_G\n        self._current_lr_D = self._opt.lr_D\n\n        # initialize optimizers\n        self._optimizer_G = torch.optim.Adam(self._G.parameters(), lr=self._current_lr_G,\n                                             betas=[self._opt.G_adam_b1, self._opt.G_adam_b2])\n        self._optimizer_D = torch.optim.Adam(self._D.parameters(), lr=self._current_lr_D,\n                                             betas=[self._opt.D_adam_b1, self._opt.D_adam_b2])\n\n    def _init_prefetch_inputs(self):\n        self._input_real_img = self._Tensor(self._opt.batch_size, 3, self._opt.image_size, self._opt.image_size)\n        self._input_real_cond = self._Tensor(self._opt.batch_size, self._opt.cond_nc)\n        self._input_desired_cond = self._Tensor(self._opt.batch_size, self._opt.cond_nc)\n        self._input_real_img_path = None\n        self._input_real_cond_path = None\n\n    def _init_losses(self):\n        # define loss functions\n        self._criterion_cycle = torch.nn.L1Loss().cuda()\n        self._criterion_D_cond = torch.nn.MSELoss().cuda()\n\n        # init losses G\n        self._loss_g_fake = Variable(self._Tensor([0]))\n        self._loss_g_cond = Variable(self._Tensor([0]))\n        self._loss_g_cyc = Variable(self._Tensor([0]))\n        self._loss_g_mask_1 = Variable(self._Tensor([0]))\n        self._loss_g_mask_2 = Variable(self._Tensor([0]))\n        self._loss_g_idt = Variable(self._Tensor([0]))\n        self._loss_g_masked_fake = Variable(self._Tensor([0]))\n        self._loss_g_masked_cond = Variable(self._Tensor([0]))\n        self._loss_g_mask_1_smooth = Variable(self._Tensor([0]))\n        self._loss_g_mask_2_smooth = Variable(self._Tensor([0]))\n        self._loss_rec_real_img_rgb = Variable(self._Tensor([0]))\n        self._loss_g_fake_imgs_smooth = Variable(self._Tensor([0]))\n        self._loss_g_unmasked_rgb = Variable(self._Tensor([0]))\n\n        # init losses D\n        self._loss_d_real = Variable(self._Tensor([0]))\n        self._loss_d_cond = Variable(self._Tensor([0]))\n        self._loss_d_fake = Variable(self._Tensor([0]))\n        self._loss_d_gp = Variable(self._Tensor([0]))\n\n    def set_input(self, input):\n        self._input_real_img.resize_(input['real_img'].size()).copy_(input['real_img'])\n        self._input_real_cond.resize_(input['real_cond'].size()).copy_(input['real_cond'])\n        self._input_desired_cond.resize_(input['desired_cond'].size()).copy_(input['desired_cond'])\n        self._input_real_id = input['sample_id']\n        self._input_real_img_path = input['real_img_path']\n\n        if len(self._gpu_ids) > 0:\n            self._input_real_img = self._input_real_img.cuda(self._gpu_ids[0], async=True)\n            self._input_real_cond = self._input_real_cond.cuda(self._gpu_ids[0], async=True)\n            self._input_desired_cond = self._input_desired_cond.cuda(self._gpu_ids[0], async=True)\n\n    def set_train(self):\n        self._G.train()\n        self._D.train()\n        self._is_train = True\n\n    def set_eval(self):\n        self._G.eval()\n        self._is_train = False\n\n    # get image paths\n    def get_image_paths(self):\n        return OrderedDict([('real_img', self._input_real_img_path)])\n\n    def forward(self, keep_data_for_visuals=False, return_estimates=False):\n        if not self._is_train:\n            # convert tensor to variables\n            real_img = Variable(self._input_real_img, volatile=True)\n            real_cond = Variable(self._input_real_cond, volatile=True)\n            desired_cond = Variable(self._input_desired_cond, volatile=True)\n\n            # generate fake images\n            fake_imgs, fake_img_mask = self._G.forward(real_img, desired_cond)\n            fake_img_mask = self._do_if_necessary_saturate_mask(fake_img_mask, saturate=self._opt.do_saturate_mask)\n            fake_imgs_masked = fake_img_mask * real_img + (1 - fake_img_mask) * fake_imgs\n\n            rec_real_img_rgb, rec_real_img_mask = self._G.forward(fake_imgs_masked, real_cond)\n            rec_real_img_mask = self._do_if_necessary_saturate_mask(rec_real_img_mask, saturate=self._opt.do_saturate_mask)\n            rec_real_imgs = rec_real_img_mask * fake_imgs_masked + (1 - rec_real_img_mask) * rec_real_img_rgb\n\n            imgs = None\n            data = None\n            if return_estimates:\n                # normalize mask for better visualization\n                fake_img_mask_max = fake_imgs_masked.view(fake_img_mask.size(0), -1).max(-1)[0]\n                fake_img_mask_max = torch.unsqueeze(torch.unsqueeze(torch.unsqueeze(fake_img_mask_max, -1), -1), -1)\n                # fake_img_mask_norm = fake_img_mask / fake_img_mask_max\n                fake_img_mask_norm = fake_img_mask\n\n                # generate images\n                im_real_img = util.tensor2im(real_img.data)\n                im_fake_imgs = util.tensor2im(fake_imgs.data)\n                im_fake_img_mask_norm = util.tensor2maskim(fake_img_mask_norm.data)\n                im_fake_imgs_masked = util.tensor2im(fake_imgs_masked.data)\n                im_rec_imgs = util.tensor2im(rec_real_img_rgb.data)\n                im_rec_img_mask_norm = util.tensor2maskim(rec_real_img_mask.data)\n                im_rec_imgs_masked = util.tensor2im(rec_real_imgs.data)\n                im_concat_img = np.concatenate([im_real_img, im_fake_imgs_masked, im_fake_img_mask_norm, im_fake_imgs,\n                                                im_rec_imgs, im_rec_img_mask_norm, im_rec_imgs_masked],\n                                               1)\n\n                im_real_img_batch = util.tensor2im(real_img.data, idx=-1, nrows=1)\n                im_fake_imgs_batch = util.tensor2im(fake_imgs.data, idx=-1, nrows=1)\n                im_fake_img_mask_norm_batch = util.tensor2maskim(fake_img_mask_norm.data, idx=-1, nrows=1)\n                im_fake_imgs_masked_batch = util.tensor2im(fake_imgs_masked.data, idx=-1, nrows=1)\n                im_concat_img_batch = np.concatenate([im_real_img_batch, im_fake_imgs_masked_batch,\n                                                      im_fake_img_mask_norm_batch, im_fake_imgs_batch],\n                                                     1)\n\n                imgs = OrderedDict([('real_img', im_real_img),\n                                    ('fake_imgs', im_fake_imgs),\n                                    ('fake_img_mask', im_fake_img_mask_norm),\n                                    ('fake_imgs_masked', im_fake_imgs_masked),\n                                    ('concat', im_concat_img),\n                                    ('real_img_batch', im_real_img_batch),\n                                    ('fake_imgs_batch', im_fake_imgs_batch),\n                                    ('fake_img_mask_batch', im_fake_img_mask_norm_batch),\n                                    ('fake_imgs_masked_batch', im_fake_imgs_masked_batch),\n                                    ('concat_batch', im_concat_img_batch),\n                                    ])\n\n                data = OrderedDict([('real_path', self._input_real_img_path),\n                                    ('desired_cond', desired_cond.data[0, ...].cpu().numpy().astype('str'))\n                                    ])\n\n            # keep data for visualization\n            if keep_data_for_visuals:\n                self._vis_real_img = util.tensor2im(self._input_real_img)\n                self._vis_fake_img_unmasked = util.tensor2im(fake_imgs.data)\n                self._vis_fake_img = util.tensor2im(fake_imgs_masked.data)\n                self._vis_fake_img_mask = util.tensor2maskim(fake_img_mask.data)\n                self._vis_real_cond = self._input_real_cond.cpu()[0, ...].numpy()\n                self._vis_desired_cond = self._input_desired_cond.cpu()[0, ...].numpy()\n                self._vis_batch_real_img = util.tensor2im(self._input_real_img, idx=-1)\n                self._vis_batch_fake_img_mask = util.tensor2maskim(fake_img_mask.data, idx=-1)\n                self._vis_batch_fake_img = util.tensor2im(fake_imgs_masked.data, idx=-1)\n\n            return imgs, data\n\n    def optimize_parameters(self, train_generator=True, keep_data_for_visuals=False):\n        if self._is_train:\n            # convert tensor to variables\n            self._B = self._input_real_img.size(0)\n            self._real_img = Variable(self._input_real_img)\n            self._real_cond = Variable(self._input_real_cond)\n            self._desired_cond = Variable(self._input_desired_cond)\n\n            # train D\n            loss_D, fake_imgs_masked = self._forward_D()\n            self._optimizer_D.zero_grad()\n            loss_D.backward()\n            self._optimizer_D.step()\n\n            loss_D_gp= self._gradinet_penalty_D(fake_imgs_masked)\n            self._optimizer_D.zero_grad()\n            loss_D_gp.backward()\n            self._optimizer_D.step()\n\n            # train G\n            if train_generator:\n                loss_G = self._forward_G(keep_data_for_visuals)\n                self._optimizer_G.zero_grad()\n                loss_G.backward()\n                self._optimizer_G.step()\n\n    def _forward_G(self, keep_data_for_visuals):\n        # generate fake images\n        fake_imgs, fake_img_mask = self._G.forward(self._real_img, self._desired_cond)\n        fake_img_mask = self._do_if_necessary_saturate_mask(fake_img_mask, saturate=self._opt.do_saturate_mask)\n        fake_imgs_masked = fake_img_mask * self._real_img + (1 - fake_img_mask) * fake_imgs\n\n        # D(G(Ic1, c2)*M) masked\n        d_fake_desired_img_masked_prob, d_fake_desired_img_masked_cond = self._D.forward(fake_imgs_masked)\n        self._loss_g_masked_fake = self._compute_loss_D(d_fake_desired_img_masked_prob, True) * self._opt.lambda_D_prob\n        self._loss_g_masked_cond = self._criterion_D_cond(d_fake_desired_img_masked_cond, self._desired_cond) / self._B * self._opt.lambda_D_cond\n\n        # G(G(Ic1,c2), c1)\n        rec_real_img_rgb, rec_real_img_mask = self._G.forward(fake_imgs_masked, self._real_cond)\n        rec_real_img_mask = self._do_if_necessary_saturate_mask(rec_real_img_mask, saturate=self._opt.do_saturate_mask)\n        rec_real_imgs = rec_real_img_mask * fake_imgs_masked + (1 - rec_real_img_mask) * rec_real_img_rgb\n\n        # l_cyc(G(G(Ic1,c2), c1)*M)\n        self._loss_g_cyc = self._criterion_cycle(rec_real_imgs, self._real_img) * self._opt.lambda_cyc\n\n        # loss mask\n        self._loss_g_mask_1 = torch.mean(fake_img_mask) * self._opt.lambda_mask\n        self._loss_g_mask_2 = torch.mean(rec_real_img_mask) * self._opt.lambda_mask\n        self._loss_g_mask_1_smooth = self._compute_loss_smooth(fake_img_mask) * self._opt.lambda_mask_smooth\n        self._loss_g_mask_2_smooth = self._compute_loss_smooth(rec_real_img_mask) * self._opt.lambda_mask_smooth\n\n        # keep data for visualization\n        if keep_data_for_visuals:\n            self._vis_real_img = util.tensor2im(self._input_real_img)\n            self._vis_fake_img_unmasked = util.tensor2im(fake_imgs.data)\n            self._vis_fake_img = util.tensor2im(fake_imgs_masked.data)\n            self._vis_fake_img_mask = util.tensor2maskim(fake_img_mask.data)\n            self._vis_real_cond = self._input_real_cond.cpu()[0, ...].numpy()\n            self._vis_desired_cond = self._input_desired_cond.cpu()[0, ...].numpy()\n            self._vis_batch_real_img = util.tensor2im(self._input_real_img, idx=-1)\n            self._vis_batch_fake_img_mask = util.tensor2maskim(fake_img_mask.data, idx=-1)\n            self._vis_batch_fake_img = util.tensor2im(fake_imgs_masked.data, idx=-1)\n            self._vis_rec_img_unmasked = util.tensor2im(rec_real_img_rgb.data)\n            self._vis_rec_real_img = util.tensor2im(rec_real_imgs.data)\n            self._vis_rec_real_img_mask = util.tensor2maskim(rec_real_img_mask.data)\n            self._vis_batch_rec_real_img = util.tensor2im(rec_real_imgs.data, idx=-1)\n\n        # combine losses\n        return self._loss_g_masked_fake + self._loss_g_masked_cond + \\\n               self._loss_g_cyc + \\\n               self._loss_g_mask_1 + self._loss_g_mask_2 + \\\n               self._loss_g_mask_1_smooth + self._loss_g_mask_2_smooth\n\n    def _forward_D(self):\n        # generate fake images\n        fake_imgs, fake_img_mask = self._G.forward(self._real_img, self._desired_cond)\n        fake_img_mask = self._do_if_necessary_saturate_mask(fake_img_mask, saturate=self._opt.do_saturate_mask)\n        fake_imgs_masked = fake_img_mask * self._real_img + (1 - fake_img_mask) * fake_imgs\n\n        # D(real_I)\n        d_real_img_prob, d_real_img_cond = self._D.forward(self._real_img)\n        self._loss_d_real = self._compute_loss_D(d_real_img_prob, True) * self._opt.lambda_D_prob\n        self._loss_d_cond = self._criterion_D_cond(d_real_img_cond, self._real_cond) / self._B * self._opt.lambda_D_cond\n\n        # D(fake_I)\n        d_fake_desired_img_prob, _ = self._D.forward(fake_imgs_masked.detach())\n        self._loss_d_fake = self._compute_loss_D(d_fake_desired_img_prob, False) * self._opt.lambda_D_prob\n\n        # combine losses\n        return self._loss_d_real + self._loss_d_cond + self._loss_d_fake, fake_imgs_masked\n\n    def _gradinet_penalty_D(self, fake_imgs_masked):\n        # interpolate sample\n        alpha = torch.rand(self._B, 1, 1, 1).cuda().expand_as(self._real_img)\n        interpolated = Variable(alpha * self._real_img.data + (1 - alpha) * fake_imgs_masked.data, requires_grad=True)\n        interpolated_prob, _ = self._D(interpolated)\n\n        # compute gradients\n        grad = torch.autograd.grad(outputs=interpolated_prob,\n                                   inputs=interpolated,\n                                   grad_outputs=torch.ones(interpolated_prob.size()).cuda(),\n                                   retain_graph=True,\n                                   create_graph=True,\n                                   only_inputs=True)[0]\n\n        # penalize gradients\n        grad = grad.view(grad.size(0), -1)\n        grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n        self._loss_d_gp = torch.mean((grad_l2norm - 1) ** 2) * self._opt.lambda_D_gp\n\n        return self._loss_d_gp\n\n    def _compute_loss_D(self, estim, is_real):\n        return -torch.mean(estim) if is_real else torch.mean(estim)\n\n    def _compute_loss_smooth(self, mat):\n        return torch.sum(torch.abs(mat[:, :, :, :-1] - mat[:, :, :, 1:])) + \\\n               torch.sum(torch.abs(mat[:, :, :-1, :] - mat[:, :, 1:, :]))\n\n    def get_current_errors(self):\n        loss_dict = OrderedDict([('g_fake', self._loss_g_fake.data[0]),\n                                 ('g_cond', self._loss_g_cond.data[0]),\n                                 ('g_mskd_fake', self._loss_g_masked_fake.data[0]),\n                                 ('g_mskd_cond', self._loss_g_masked_cond.data[0]),\n                                 ('g_cyc', self._loss_g_cyc.data[0]),\n                                 ('g_rgb', self._loss_rec_real_img_rgb.data[0]),\n                                 ('g_rgb_un', self._loss_g_unmasked_rgb.data[0]),\n                                 ('g_rgb_s', self._loss_g_fake_imgs_smooth.data[0]),\n                                 ('g_m1', self._loss_g_mask_1.data[0]),\n                                 ('g_m2', self._loss_g_mask_2.data[0]),\n                                 ('g_m1_s', self._loss_g_mask_1_smooth.data[0]),\n                                 ('g_m2_s', self._loss_g_mask_2_smooth.data[0]),\n                                 ('g_idt', self._loss_g_idt.data[0]),\n                                 ('d_real', self._loss_d_real.data[0]),\n                                 ('d_cond', self._loss_d_cond.data[0]),\n                                 ('d_fake', self._loss_d_fake.data[0]),\n                                 ('d_gp', self._loss_d_gp.data[0])])\n\n        return loss_dict\n\n    def get_current_scalars(self):\n        return OrderedDict([('lr_G', self._current_lr_G), ('lr_D', self._current_lr_D)])\n\n    def get_current_visuals(self):\n        # visuals return dictionary\n        visuals = OrderedDict()\n\n        # input visuals\n        title_input_img = os.path.basename(self._input_real_img_path[0])\n        visuals['1_input_img'] = plot_utils.plot_au(self._vis_real_img, self._vis_real_cond, title=title_input_img)\n        visuals['2_fake_img'] = plot_utils.plot_au(self._vis_fake_img, self._vis_desired_cond)\n        visuals['3_rec_real_img'] = plot_utils.plot_au(self._vis_rec_real_img, self._vis_real_cond)\n        visuals['4_fake_img_unmasked'] = self._vis_fake_img_unmasked\n        visuals['5_fake_img_mask'] = self._vis_fake_img_mask\n        visuals['6_rec_real_img_mask'] = self._vis_rec_real_img_mask\n        visuals['7_cyc_img_unmasked'] = self._vis_fake_img_unmasked\n        # visuals['8_fake_img_mask_sat'] = self._vis_fake_img_mask_saturated\n        # visuals['9_rec_real_img_mask_sat'] = self._vis_rec_real_img_mask_saturated\n        visuals['10_batch_real_img'] = self._vis_batch_real_img\n        visuals['11_batch_fake_img'] = self._vis_batch_fake_img\n        visuals['12_batch_fake_img_mask'] = self._vis_batch_fake_img_mask\n        # visuals['11_idt_img'] = self._vis_idt_img\n\n        return visuals\n\n    def save(self, label):\n        # save networks\n        self._save_network(self._G, 'G', label)\n        self._save_network(self._D, 'D', label)\n\n        # save optimizers\n        self._save_optimizer(self._optimizer_G, 'G', label)\n        self._save_optimizer(self._optimizer_D, 'D', label)\n\n    def load(self):\n        load_epoch = self._opt.load_epoch\n\n        # load G\n        self._load_network(self._G, 'G', load_epoch)\n\n        if self._is_train:\n            # load D\n            self._load_network(self._D, 'D', load_epoch)\n\n            # load optimizers\n            self._load_optimizer(self._optimizer_G, 'G', load_epoch)\n            self._load_optimizer(self._optimizer_D, 'D', load_epoch)\n\n    def update_learning_rate(self):\n        # updated learning rate G\n        lr_decay_G = self._opt.lr_G / self._opt.nepochs_decay\n        self._current_lr_G -= lr_decay_G\n        for param_group in self._optimizer_G.param_groups:\n            param_group['lr'] = self._current_lr_G\n        print('update G learning rate: %f -> %f' %  (self._current_lr_G + lr_decay_G, self._current_lr_G))\n\n        # update learning rate D\n        lr_decay_D = self._opt.lr_D / self._opt.nepochs_decay\n        self._current_lr_D -= lr_decay_D\n        for param_group in self._optimizer_D.param_groups:\n            param_group['lr'] = self._current_lr_D\n        print('update D learning rate: %f -> %f' %  (self._current_lr_D + lr_decay_D, self._current_lr_D))\n\n    def _l1_loss_with_target_gradients(self, input, target):\n        return torch.sum(torch.abs(input - target)) / input.data.nelement()\n\n    def _do_if_necessary_saturate_mask(self, m, saturate=False):\n        return torch.clamp(0.55*torch.tanh(3*(m-0.5))+0.5, 0, 1) if saturate else m\n"""
models/models.py,6,"b'import os\nimport torch\nfrom torch.optim import lr_scheduler\n\nclass ModelsFactory:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def get_by_name(model_name, *args, **kwargs):\n        model = None\n\n        if model_name == \'ganimation\':\n            from .ganimation import GANimation\n            model = GANimation(*args, **kwargs)\n        else:\n            raise ValueError(""Model %s not recognized."" % model_name)\n\n        print(""Model %s was created"" % model.name)\n        return model\n\n\nclass BaseModel(object):\n\n    def __init__(self, opt):\n        self._name = \'BaseModel\'\n\n        self._opt = opt\n        self._gpu_ids = opt.gpu_ids\n        self._is_train = opt.is_train\n\n        self._Tensor = torch.cuda.FloatTensor if self._gpu_ids else torch.Tensor\n        self._save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def is_train(self):\n        return self._is_train\n\n    def set_input(self, input):\n        assert False, ""set_input not implemented""\n\n    def set_train(self):\n        assert False, ""set_train not implemented""\n\n    def set_eval(self):\n        assert False, ""set_eval not implemented""\n\n    def forward(self, keep_data_for_visuals=False):\n        assert False, ""forward not implemented""\n\n    # used in test time, no backprop\n    def test(self):\n        assert False, ""test not implemented""\n\n    def get_image_paths(self):\n        return {}\n\n    def optimize_parameters(self):\n        assert False, ""optimize_parameters not implemented""\n\n    def get_current_visuals(self):\n        return {}\n\n    def get_current_errors(self):\n        return {}\n\n    def get_current_scalars(self):\n        return {}\n\n    def save(self, label):\n        assert False, ""save not implemented""\n\n    def load(self):\n        assert False, ""load not implemented""\n\n    def _save_optimizer(self, optimizer, optimizer_label, epoch_label):\n        save_filename = \'opt_epoch_%s_id_%s.pth\' % (epoch_label, optimizer_label)\n        save_path = os.path.join(self._save_dir, save_filename)\n        torch.save(optimizer.state_dict(), save_path)\n\n    def _load_optimizer(self, optimizer, optimizer_label, epoch_label):\n        load_filename = \'opt_epoch_%s_id_%s.pth\' % (epoch_label, optimizer_label)\n        load_path = os.path.join(self._save_dir, load_filename)\n        assert os.path.exists(\n            load_path), \'Weights file not found. Have you trained a model!? We are not providing one\' % load_path\n\n        optimizer.load_state_dict(torch.load(load_path))\n        print \'loaded optimizer: %s\' % load_path\n\n    def _save_network(self, network, network_label, epoch_label):\n        save_filename = \'net_epoch_%s_id_%s.pth\' % (epoch_label, network_label)\n        save_path = os.path.join(self._save_dir, save_filename)\n        torch.save(network.state_dict(), save_path)\n        print \'saved net: %s\' % save_path\n\n    def _load_network(self, network, network_label, epoch_label):\n        load_filename = \'net_epoch_%s_id_%s.pth\' % (epoch_label, network_label)\n        load_path = os.path.join(self._save_dir, load_filename)\n        assert os.path.exists(\n            load_path), \'Weights file not found. Have you trained a model!? We are not providing one\' % load_path\n\n        network.load_state_dict(torch.load(load_path))\n        print \'loaded net: %s\' % load_path\n\n    def update_learning_rate(self):\n        pass\n\n    def print_network(self, network):\n        num_params = 0\n        for param in network.parameters():\n            num_params += param.numel()\n        print(network)\n        print(\'Total number of parameters: %d\' % num_params)\n\n    def _get_scheduler(self, optimizer, opt):\n        if opt.lr_policy == \'lambda\':\n            def lambda_rule(epoch):\n                lr_l = 1.0 - max(0, epoch + 1 + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)\n                return lr_l\n            scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n        elif opt.lr_policy == \'step\':\n            scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n        elif opt.lr_policy == \'plateau\':\n            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\'min\', factor=0.2, threshold=0.01, patience=5)\n        else:\n            return NotImplementedError(\'learning rate policy [%s] is not implemented\', opt.lr_policy)\n        return scheduler\n'"
networks/__init__.py,0,b''
networks/discriminator_wasserstein_gan.py,1,"b'import torch.nn as nn\nimport numpy as np\nfrom .networks import NetworkBase\n\nclass Discriminator(NetworkBase):\n    """"""Discriminator. PatchGAN.""""""\n    def __init__(self, image_size=128, conv_dim=64, c_dim=5, repeat_num=6):\n        super(Discriminator, self).__init__()\n        self._name = \'discriminator_wgan\'\n\n        layers = []\n        layers.append(nn.Conv2d(3, conv_dim, kernel_size=4, stride=2, padding=1))\n        layers.append(nn.LeakyReLU(0.01, inplace=True))\n\n        curr_dim = conv_dim\n        for i in range(1, repeat_num):\n            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1))\n            layers.append(nn.LeakyReLU(0.01, inplace=True))\n            curr_dim = curr_dim * 2\n\n        k_size = int(image_size / np.power(2, repeat_num))\n        self.main = nn.Sequential(*layers)\n        self.conv1 = nn.Conv2d(curr_dim, 1, kernel_size=3, stride=1, padding=1, bias=False)\n        self.conv2 = nn.Conv2d(curr_dim, c_dim, kernel_size=k_size, bias=False)\n\n    def forward(self, x):\n        h = self.main(x)\n        out_real = self.conv1(h)\n        out_aux = self.conv2(h)\n        return out_real.squeeze(), out_aux.squeeze()'"
networks/generator_wasserstein_gan.py,2,"b'import torch.nn as nn\nimport numpy as np\nfrom .networks import NetworkBase\nimport torch\n\nclass Generator(NetworkBase):\n    """"""Generator. Encoder-Decoder Architecture.""""""\n    def __init__(self, conv_dim=64, c_dim=5, repeat_num=6):\n        super(Generator, self).__init__()\n        self._name = \'generator_wgan\'\n\n        layers = []\n        layers.append(nn.Conv2d(3+c_dim, conv_dim, kernel_size=7, stride=1, padding=3, bias=False))\n        layers.append(nn.InstanceNorm2d(conv_dim, affine=True))\n        layers.append(nn.ReLU(inplace=True))\n\n        # Down-Sampling\n        curr_dim = conv_dim\n        for i in range(2):\n            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1, bias=False))\n            layers.append(nn.InstanceNorm2d(curr_dim*2, affine=True))\n            layers.append(nn.ReLU(inplace=True))\n            curr_dim = curr_dim * 2\n\n        # Bottleneck\n        for i in range(repeat_num):\n            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))\n\n        # Up-Sampling\n        for i in range(2):\n            layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=4, stride=2, padding=1, bias=False))\n            layers.append(nn.InstanceNorm2d(curr_dim//2, affine=True))\n            layers.append(nn.ReLU(inplace=True))\n            curr_dim = curr_dim // 2\n\n        self.main = nn.Sequential(*layers)\n\n        layers = []\n        layers.append(nn.Conv2d(curr_dim, 3, kernel_size=7, stride=1, padding=3, bias=False))\n        layers.append(nn.Tanh())\n        self.img_reg = nn.Sequential(*layers)\n\n        layers = []\n        layers.append(nn.Conv2d(curr_dim, 1, kernel_size=7, stride=1, padding=3, bias=False))\n        layers.append(nn.Sigmoid())\n        self.attetion_reg = nn.Sequential(*layers)\n\n    def forward(self, x, c):\n        # replicate spatially and concatenate domain information\n        c = c.unsqueeze(2).unsqueeze(3)\n        c = c.expand(c.size(0), c.size(1), x.size(2), x.size(3))\n        x = torch.cat([x, c], dim=1)\n        features = self.main(x)\n        return self.img_reg(features), self.attetion_reg(features)\n\nclass ResidualBlock(nn.Module):\n    """"""Residual Block.""""""\n    def __init__(self, dim_in, dim_out):\n        super(ResidualBlock, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.InstanceNorm2d(dim_out, affine=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.InstanceNorm2d(dim_out, affine=True))\n\n    def forward(self, x):\n        return x + self.main(x)'"
networks/networks.py,1,"b'import torch.nn as nn\nimport functools\n\nclass NetworksFactory:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def get_by_name(network_name, *args, **kwargs):\n\n        if network_name == \'generator_wasserstein_gan\':\n            from .generator_wasserstein_gan import Generator\n            network = Generator(*args, **kwargs)\n        elif network_name == \'discriminator_wasserstein_gan\':\n            from .discriminator_wasserstein_gan import Discriminator\n            network = Discriminator(*args, **kwargs)\n        else:\n            raise ValueError(""Network %s not recognized."" % network_name)\n\n        print ""Network %s was created"" % network_name\n\n        return network\n\n\nclass NetworkBase(nn.Module):\n    def __init__(self):\n        super(NetworkBase, self).__init__()\n        self._name = \'BaseNetwork\'\n\n    @property\n    def name(self):\n        return self._name\n\n    def init_weights(self):\n        self.apply(self._weights_init_fn)\n\n    def _weights_init_fn(self, m):\n        classname = m.__class__.__name__\n        if classname.find(\'Conv\') != -1:\n            m.weight.data.normal_(0.0, 0.02)\n            if hasattr(m.bias, \'data\'):\n                m.bias.data.fill_(0)\n        elif classname.find(\'BatchNorm2d\') != -1:\n            m.weight.data.normal_(1.0, 0.02)\n            m.bias.data.fill_(0)\n\n    def _get_norm_layer(self, norm_type=\'batch\'):\n        if norm_type == \'batch\':\n            norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n        elif norm_type == \'instance\':\n            norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n        elif norm_type ==\'batchnorm2d\':\n            norm_layer = nn.BatchNorm2d\n        else:\n            raise NotImplementedError(\'normalization layer [%s] is not found\' % norm_type)\n\n        return norm_layer\n'"
options/__init__.py,0,b''
options/base_options.py,1,"b'import argparse\nimport os\nfrom utils import util\nimport torch\n\nclass BaseOptions():\n    def __init__(self):\n        self._parser = argparse.ArgumentParser()\n        self._initialized = False\n\n    def initialize(self):\n        self._parser.add_argument(\'--data_dir\', type=str, help=\'path to dataset\')\n        self._parser.add_argument(\'--train_ids_file\', type=str, default=\'train_ids.csv\', help=\'file containing train ids\')\n        self._parser.add_argument(\'--test_ids_file\', type=str, default=\'test_ids.csv\', help=\'file containing test ids\')\n        self._parser.add_argument(\'--images_folder\', type=str, default=\'imgs\', help=\'images folder\')\n        self._parser.add_argument(\'--aus_file\', type=str, default=\'aus_openface.pkl\', help=\'file containing samples aus\')\n\n        self._parser.add_argument(\'--load_epoch\', type=int, default=-1, help=\'which epoch to load? set to -1 to use latest cached model\')\n        self._parser.add_argument(\'--batch_size\', type=int, default=4, help=\'input batch size\')\n        self._parser.add_argument(\'--image_size\', type=int, default=128, help=\'input image size\')\n        self._parser.add_argument(\'--cond_nc\', type=int, default=17, help=\'# of conditions\')\n        self._parser.add_argument(\'--gpu_ids\', type=str, default=\'0\', help=\'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU\')\n        self._parser.add_argument(\'--name\', type=str, default=\'experiment_1\', help=\'name of the experiment. It decides where to store samples and models\')\n        self._parser.add_argument(\'--dataset_mode\', type=str, default=\'aus\', help=\'chooses dataset to be used\')\n        self._parser.add_argument(\'--model\', type=str, default=\'ganimation\', help=\'model to run[au_net_model]\')\n        self._parser.add_argument(\'--n_threads_test\', default=1, type=int, help=\'# threads for loading data\')\n        self._parser.add_argument(\'--checkpoints_dir\', type=str, default=\'./checkpoints\', help=\'models are saved here\')\n        self._parser.add_argument(\'--serial_batches\', action=\'store_true\', help=\'if true, takes images in order to make batches, otherwise takes them randomly\')\n        self._parser.add_argument(\'--do_saturate_mask\', action=""store_true"", default=False, help=\'do use mask_fake for mask_cyc\')\n\n\n\n\n        self._initialized = True\n\n    def parse(self):\n        if not self._initialized:\n            self.initialize()\n        self._opt = self._parser.parse_args()\n\n        # set is train or set\n        self._opt.is_train = self.is_train\n\n        # set and check load_epoch\n        self._set_and_check_load_epoch()\n\n        # get and set gpus\n        self._get_set_gpus()\n\n        args = vars(self._opt)\n\n        # print in terminal args\n        self._print(args)\n\n        # save args to file\n        self._save(args)\n\n        return self._opt\n\n    def _set_and_check_load_epoch(self):\n        models_dir = os.path.join(self._opt.checkpoints_dir, self._opt.name)\n        if os.path.exists(models_dir):\n            if self._opt.load_epoch == -1:\n                load_epoch = 0\n                for file in os.listdir(models_dir):\n                    if file.startswith(""net_epoch_""):\n                        load_epoch = max(load_epoch, int(file.split(\'_\')[2]))\n                self._opt.load_epoch = load_epoch\n            else:\n                found = False\n                for file in os.listdir(models_dir):\n                    if file.startswith(""net_epoch_""):\n                        found = int(file.split(\'_\')[2]) == self._opt.load_epoch\n                        if found: break\n                assert found, \'Model for epoch %i not found\' % self._opt.load_epoch\n        else:\n            assert self._opt.load_epoch < 1, \'Model for epoch %i not found\' % self._opt.load_epoch\n            self._opt.load_epoch = 0\n\n    def _get_set_gpus(self):\n        # get gpu ids\n        str_ids = self._opt.gpu_ids.split(\',\')\n        self._opt.gpu_ids = []\n        for str_id in str_ids:\n            id = int(str_id)\n            if id >= 0:\n                self._opt.gpu_ids.append(id)\n\n        # set gpu ids\n        if len(self._opt.gpu_ids) > 0:\n            torch.cuda.set_device(self._opt.gpu_ids[0])\n\n    def _print(self, args):\n        print(\'------------ Options -------------\')\n        for k, v in sorted(args.items()):\n            print(\'%s: %s\' % (str(k), str(v)))\n        print(\'-------------- End ----------------\')\n\n    def _save(self, args):\n        expr_dir = os.path.join(self._opt.checkpoints_dir, self._opt.name)\n        print(expr_dir)\n        util.mkdirs(expr_dir)\n        file_name = os.path.join(expr_dir, \'opt_%s.txt\' % (\'train\' if self.is_train else \'test\'))\n        with open(file_name, \'wt\') as opt_file:\n            opt_file.write(\'------------ Options -------------\\n\')\n            for k, v in sorted(args.items()):\n                opt_file.write(\'%s: %s\\n\' % (str(k), str(v)))\n            opt_file.write(\'-------------- End ----------------\\n\')\n'"
options/test_options.py,0,"b""from .base_options import BaseOptions\n\n\nclass TestOptions(BaseOptions):\n    def initialize(self):\n        BaseOptions.initialize(self)\n        self._parser.add_argument('--input_path', type=str, help='path to image')\n        self._parser.add_argument('--output_dir', type=str, default='./output', help='output path')\n        self.is_train = False\n"""
options/train_options.py,0,"b""from .base_options import BaseOptions\n\n\nclass TrainOptions(BaseOptions):\n    def initialize(self):\n        BaseOptions.initialize(self)\n        self._parser.add_argument('--n_threads_train', default=4, type=int, help='# threads for loading data')\n        self._parser.add_argument('--num_iters_validate', default=1, type=int, help='# batches to use when validating')\n        self._parser.add_argument('--print_freq_s', type=int, default=60, help='frequency of showing training results on console')\n        self._parser.add_argument('--display_freq_s', type=int, default=300, help='frequency [s] of showing training results on screen')\n        self._parser.add_argument('--save_latest_freq_s', type=int, default=3600, help='frequency of saving the latest results')\n\n        self._parser.add_argument('--nepochs_no_decay', type=int, default=20, help='# of epochs at starting learning rate')\n        self._parser.add_argument('--nepochs_decay', type=int, default=10, help='# of epochs to linearly decay learning rate to zero')\n\n        self._parser.add_argument('--train_G_every_n_iterations', type=int, default=5, help='train G every n interations')\n        self._parser.add_argument('--poses_g_sigma', type=float, default=0.06, help='initial learning rate for adam')\n        self._parser.add_argument('--lr_G', type=float, default=0.0001, help='initial learning rate for G adam')\n        self._parser.add_argument('--G_adam_b1', type=float, default=0.5, help='beta1 for G adam')\n        self._parser.add_argument('--G_adam_b2', type=float, default=0.999, help='beta2 for G adam')\n        self._parser.add_argument('--lr_D', type=float, default=0.0001, help='initial learning rate for D adam')\n        self._parser.add_argument('--D_adam_b1', type=float, default=0.5, help='beta1 for D adam')\n        self._parser.add_argument('--D_adam_b2', type=float, default=0.999, help='beta2 for D adam')\n        self._parser.add_argument('--lambda_D_prob', type=float, default=1, help='lambda for real/fake discriminator loss')\n        self._parser.add_argument('--lambda_D_cond', type=float, default=4000, help='lambda for condition discriminator loss')\n        self._parser.add_argument('--lambda_cyc', type=float, default=10, help='lambda cycle loss')\n        self._parser.add_argument('--lambda_mask', type=float, default=0.1, help='lambda mask loss')\n        self._parser.add_argument('--lambda_D_gp', type=float, default=10, help='lambda gradient penalty loss')\n        self._parser.add_argument('--lambda_mask_smooth', type=float, default=1e-5, help='lambda mask smooth loss')\n\n        self.is_train = True\n"""
utils/__init__.py,0,b''
utils/cv_utils.py,0,"b""import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\ndef read_cv2_img(path):\n    '''\n    Read color images\n    :param path: Path to image\n    :return: Only returns color images\n    '''\n    img = cv2.imread(path, -1)\n\n    if img is not None:\n        if len(img.shape) != 3:\n            return None\n\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    return img\n\ndef show_cv2_img(img, title='img'):\n    '''\n    Display cv2 image\n    :param img: cv::mat\n    :param title: title\n    :return: None\n    '''\n    plt.imshow(img)\n    plt.title(title)\n    plt.axis('off')\n    plt.show()\n\ndef show_images_row(imgs, titles, rows=1):\n    '''\n       Display grid of cv2 images image\n       :param img: list [cv::mat]\n       :param title: titles\n       :return: None\n    '''\n    assert ((titles is None) or (len(imgs) == len(titles)))\n    num_images = len(imgs)\n\n    if titles is None:\n        titles = ['Image (%d)' % i for i in range(1, num_images + 1)]\n\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(imgs, titles)):\n        ax = fig.add_subplot(rows, np.ceil(num_images / float(rows)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image)\n        ax.set_title(title)\n        plt.axis('off')\n    plt.show()"""
utils/face_utils.py,0,"b""import face_recognition\nimport cv2\nimport numpy as np\nimport skimage\nimport skimage.transform\nimport warnings\n\ndef detect_faces(img):\n    '''\n    Detect faces in image\n    :param img: cv::mat HxWx3 RGB\n    :return: yield 4 <x,y,w,h>\n    '''\n    # detect faces\n    bbs = face_recognition.face_locations(img)\n\n    for y, right, bottom, x in bbs:\n        # Scale back up face bb\n        yield x, y, (right - x), (bottom - y)\n\ndef detect_biggest_face(img):\n    '''\n    Detect biggest face in image\n    :param img: cv::mat HxWx3 RGB\n    :return: 4 <x,y,w,h>\n    '''\n    # detect faces\n    bbs = face_recognition.face_locations(img)\n\n    max_area = float('-inf')\n    max_area_i = 0\n    for i, (y, right, bottom, x) in enumerate(bbs):\n        area = (right - x) * (bottom - y)\n        if max_area < area:\n            max_area = area\n            max_area_i = i\n\n    if max_area != float('-inf'):\n        y, right, bottom, x = bbs[max_area_i]\n        return x, y, (right - x), (bottom - y)\n\n    return None\n\ndef crop_face_with_bb(img, bb):\n    '''\n    Crop face in image given bb\n    :param img: cv::mat HxWx3\n    :param bb: 4 (<x,y,w,h>)\n    :return: HxWx3\n    '''\n    x, y, w, h = bb\n    return img[y:y+h, x:x+w, :]\n\ndef place_face(img, face, bb):\n    x, y, w, h = bb\n    face = resize_face(face, size=(w, h))\n    img[y:y+h, x:x+w] = face\n    return img\n\ndef resize_face(face_img, size=(128, 128)):\n    '''\n    Resize face to a given size\n    :param face_img: cv::mat HxWx3\n    :param size: new H and W (size x size). 128 by default.\n    :return: cv::mat size x size x 3\n    '''\n    return cv2.resize(face_img, size)\n\ndef detect_landmarks(face_img):\n    landmakrs = face_recognition.face_landmarks(face_img)\n    return landmakrs[0] if len(landmakrs) > 0 else None\n"""
utils/plots.py,0,"b""from __future__ import print_function\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_au(img, aus, title=None):\n    '''\n    Plot action units\n    :param img: HxWx3\n    :param aus: N\n    :return:\n    '''\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax.axis('off')\n    fig.subplots_adjust(0, 0, 0.8, 1)  # get rid of margins\n\n    # display img\n    ax.imshow(img)\n\n    if len(aus) == 11:\n        au_ids = ['1','2','4','5','6','9','12','17','20','25','26']\n        x = 0.1\n        y = 0.39\n        i = 0\n        for au, id in zip(aus, au_ids):\n            if id == '9':\n                x = 0.5\n                y -= .15\n                i = 0\n            elif id == '12':\n                x = 0.1\n                y -= .15\n                i = 0\n\n            ax.text(x + i * 0.2, y, id, horizontalalignment='center', verticalalignment='center',\n                    transform=ax.transAxes, color='r', fontsize=20)\n            ax.text((x-0.001)+i*0.2, y-0.07, au, horizontalalignment='center', verticalalignment='center',\n                    transform=ax.transAxes, color='b', fontsize=20)\n            i+=1\n\n    else:\n        au_ids = ['1', '2', '4', '5', '6', '7', '9', '10', '12', '14', '15', '17', '20', '23', '25', '26', '45']\n        x = 0.1\n        y = 0.39\n        i = 0\n        for au, id in zip(aus, au_ids):\n            if id == '9' or id == '20':\n                x = 0.1\n                y -= .15\n                i = 0\n\n            ax.text(x + i * 0.2, y, id, horizontalalignment='center', verticalalignment='center',\n                    transform=ax.transAxes, color='r', fontsize=20)\n            ax.text((x-0.001)+i*0.2, y-0.07, au, horizontalalignment='center', verticalalignment='center',\n                    transform=ax.transAxes, color='b', fontsize=20)\n            i+=1\n\n    if title is not None:\n        ax.text(0.5, 0.95, title, horizontalalignment='center', verticalalignment='center',\n                transform=ax.transAxes, color='r', fontsize=20)\n\n    fig.canvas.draw()\n    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n    plt.close(fig)\n\n    return data"""
utils/tb_visualizer.py,0,"b'import numpy as np\nimport os\nimport time\nfrom . import util\nfrom tensorboardX import SummaryWriter\n\n\nclass TBVisualizer:\n    def __init__(self, opt):\n        self._opt = opt\n        self._save_path = os.path.join(opt.checkpoints_dir, opt.name)\n\n        self._log_path = os.path.join(self._save_path, \'loss_log2.txt\')\n        self._tb_path = os.path.join(self._save_path, \'summary.json\')\n        self._writer = SummaryWriter(self._save_path)\n\n        with open(self._log_path, ""a"") as log_file:\n            now = time.strftime(""%c"")\n            log_file.write(\'================ Training Loss (%s) ================\\n\' % now)\n\n    def __del__(self):\n        self._writer.close()\n\n    def display_current_results(self, visuals, it, is_train, save_visuals=False):\n        for label, image_numpy in visuals.items():\n            sum_name = \'{}/{}\'.format(\'Train\' if is_train else \'Test\', label)\n            self._writer.add_image(sum_name, image_numpy, it)\n\n            if save_visuals:\n                util.save_image(image_numpy,\n                                os.path.join(self._opt.checkpoints_dir, self._opt.name,\n                                             \'event_imgs\', sum_name, \'%08d.png\' % it))\n\n        self._writer.export_scalars_to_json(self._tb_path)\n\n    def plot_scalars(self, scalars, it, is_train):\n        for label, scalar in scalars.items():\n            sum_name = \'{}/{}\'.format(\'Train\' if is_train else \'Test\', label)\n            self._writer.add_scalar(sum_name, scalar, it)\n\n    def print_current_train_errors(self, epoch, i, iters_per_epoch, errors, t, visuals_were_stored):\n        log_time = time.strftime(""[%d/%m/%Y %H:%M:%S]"")\n        visuals_info = ""v"" if visuals_were_stored else """"\n        message = \'%s (T%s, epoch: %d, it: %d/%d, t/smpl: %.3fs) \' % (log_time, visuals_info, epoch, i, iters_per_epoch, t)\n        for k, v in errors.items():\n            message += \'%s:%.3f \' % (k, v)\n\n        print(message)\n        with open(self._log_path, ""a"") as log_file:\n            log_file.write(\'%s\\n\' % message)\n\n    def print_current_validate_errors(self, epoch, errors, t):\n        log_time = time.strftime(""[%d/%m/%Y %H:%M:%S]"")\n        message = \'%s (V, epoch: %d, time_to_val: %ds) \' % (log_time, epoch, t)\n        for k, v in errors.items():\n            message += \'%s:%.3f \' % (k, v)\n\n        print(message)\n        with open(self._log_path, ""a"") as log_file:\n            log_file.write(\'%s\\n\' % message)\n\n    def save_images(self, visuals):\n        for label, image_numpy in visuals.items():\n            image_name = \'%s.png\' % label\n            save_path = os.path.join(self._save_path, ""samples"", image_name)\n            util.save_image(image_numpy, save_path)'"
utils/util.py,0,"b'from __future__ import print_function\nfrom PIL import Image\nimport numpy as np\nimport os\nimport torchvision\nimport math\n\n\ndef tensor2im(img, imtype=np.uint8, unnormalize=True, idx=0, nrows=None):\n    # select a sample or create grid if img is a batch\n    if len(img.shape) == 4:\n        nrows = nrows if nrows is not None else int(math.sqrt(img.size(0)))\n        img = img[idx] if idx >= 0 else torchvision.utils.make_grid(img, nrows)\n\n    img = img.cpu().float()\n    if unnormalize:\n        mean = [0.5, 0.5, 0.5]\n        std = [0.5, 0.5, 0.5]\n\n        for i, m, s in zip(img, mean, std):\n            i.mul_(s).add_(m)\n\n    image_numpy = img.numpy()\n    image_numpy_t = np.transpose(image_numpy, (1, 2, 0))\n    image_numpy_t = image_numpy_t*254.0\n\n    return image_numpy_t.astype(imtype)\n\ndef tensor2maskim(mask, imtype=np.uint8, idx=0, nrows=1):\n    im = tensor2im(mask, imtype=imtype, idx=idx, unnormalize=False, nrows=nrows)\n    if im.shape[2] == 1:\n        im = np.repeat(im, 3, axis=-1)\n    return im\n\ndef mkdirs(paths):\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)\n\ndef mkdir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef save_image(image_numpy, image_path):\n    mkdir(os.path.dirname(image_path))\n    image_pil = Image.fromarray(image_numpy)\n    image_pil.save(image_path)\n\ndef save_str_data(data, path):\n    mkdir(os.path.dirname(path))\n    np.savetxt(path, data, delimiter="","", fmt=""%s"")'"
