file_path,api_count,code
src/pytorch-rnn-demo.py,19,"b'# coding: utf-8\n\n###\n# Thanks to http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n# Thanks to Ngarneau https://github.com/ngarneau/understanding-pytorch-batching-lstm\n# Integrator :\xe9\x9b\xaa\xe4\xb8\x8a-kia\n###\n\nfrom __future__ import division, print_function, unicode_literals\n\nimport glob\nimport random\nimport string\nimport unicodedata\nfrom io import open\n\nfrom sklearn.metrics import (accuracy_score, classification_report, confusion_matrix)\n\nimport torch\nimport torch.optim as optim\nfrom torch import nn as nn\nfrom torch import autograd\nfrom torch.nn import functional as F\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom torch.utils.data import DataLoader, Dataset\n\nrandom.seed(1)\n\n\ndef findFiles(path):\n    return glob.glob(path)\n\n\n\n# \xe6\x8a\x8a Unicode \xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90 ASCII\xef\xbc\x9bthanks to http://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return \'\'.join(\n        c for c in unicodedata.normalize(\'NFD\', s)\n        if unicodedata.category(c) != \'Mn\' and c in all_letters)\n\n\ndef readLines(filename):\n    lines = open(filename, encoding=\'utf-8\').read().strip().split(\'\\n\')\n    return [unicodeToAscii(line) for line in lines]\n\n\n""""""\nDataset class\xe6\x98\xaf pytorch \xe7\x9a\x84\xe7\x89\xb9\xe8\x89\xb2\xe4\xb9\x8b\xe4\xb8\x80\xef\xbc\x8c\xe8\x83\xbd\xe5\xa4\x9f\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\xb0\x81\xe8\xa3\x85\xe8\xb5\xb7\xe6\x9d\xa5\xef\xbc\x8c\xe6\x96\xb9\xe4\xbe\xbf\xe4\xbb\xa5 batch \xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\n\xe5\xae\x98\xe7\xbd\x91\xe7\x9a\x84\xe6\x95\x99\xe7\xa8\x8b\xe4\xb8\xad\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe4\xb8\x80\xe4\xb8\xaa(name, country)\xe4\xbc\xa0\xe8\xbf\x9b\xe5\x8e\xbb\xe7\x9a\x84\xef\xbc\x8c\xe8\x80\x8c\xe5\x8a\xa0\xe5\x85\xa5 Dataset class \xe6\x98\xaf\xe4\xb8\xba\xe4\xba\x86\xe5\xb0\x81\xe8\xa3\x85\xe5\x90\x8e\xe4\xb8\x80\xe6\xac\xa1\xe6\x80\xa7\xe4\xbc\xa0\xe8\xbf\x9b\xe5\x8e\xbb batch \xe4\xb8\xaa(name, country)\n""""""\nclass PaddedTensorDataset(Dataset):\n    """"""Dataset wrapping data, target and length tensors.\n\n    Each sample will be retrieved by indexing both tensors along the first\n    dimension.\n\n    Arguments:\n        data_tensor (Tensor): contains sample data.\n        target_tensor (Tensor): contains sample targets (labels).\n        length (Tensor): contains sample lengths.\n        raw_data (Any): The data that has been transformed into tensor, useful for debugging\n    """"""\n\n    def __init__(self, data_tensor, target_tensor, length_tensor, raw_data):\n        assert data_tensor.size(0) == target_tensor.size(\n            0) == length_tensor.size(0)\n        self.data_tensor = data_tensor\n        self.target_tensor = target_tensor\n        self.length_tensor = length_tensor\n        self.raw_data = raw_data\n\n    def __getitem__(self, index):\n        return self.data_tensor[index], self.target_tensor[\n            index], self.length_tensor[index], self.raw_data[index]\n\n    def __len__(self):\n        return self.data_tensor.size(0)\n\n\n""""""\nA couple useful method\n""""""\n\n\n# \xe6\x8a\x8a\xe5\x90\x8d\xe5\xad\x97\xe5\x90\x91\xe9\x87\x8f\xe5\x8c\x96\xef\xbc\x8c\xe5\x85\xb6\xe5\xae\x9e\xe5\xb0\xb1\xe6\x98\xaf\xe8\xbf\x94\xe5\x9b\x9e\xe6\xaf\x8f\xe4\xb8\xaa\xe5\xad\x97\xe6\xaf\x8d\xe5\x9c\xa8vocabulary\xe4\xb8\xad\xe7\x9a\x84idex\xef\xbc\x8c\xe6\xaf\x94\xe5\xa6\x82San =\xef\xbc\x884,5,9\xef\xbc\x89\xef\xbc\x8cSnai = \xef\xbc\x884,9,5,10\xef\xbc\x89   --figure 1 \ndef vectorize_data(data, to_ix):\n    return [[to_ix[tok] if tok in to_ix else to_ix[\'UNK\'] for tok in seq]\n            for seq, y in data]\n\n\n# \xe7\x94\xb1\xe4\xba\x8e\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x90\x8d\xe5\xad\x97\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\x8d\xe5\x90\x8c\xef\xbc\x8c\xe9\x82\xa3\xe5\xae\x83\xe4\xbb\xac\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90\xe5\x90\x91\xe9\x87\x8f\xe5\xb0\xb1\xe6\x9c\x89\xe9\x95\xbf\xe6\x9c\x89\xe7\x9f\xad\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x8c\x89\xe7\x85\xa7\xe5\xae\x98\xe7\xbd\x91\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xe6\xaf\x8f\xe6\xac\xa1\xe5\x8f\xaa\xe4\xbc\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe5\x90\x8d\xe5\xad\x97\xe6\x98\xaf\xe6\xb2\xa1\xe6\x9c\x89\xe5\xbd\xb1\xe5\x93\x8d\xe7\x9a\x84\n# \xe4\xbd\x86\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x99\xe9\x87\x8c\xe9\x87\x87\xe7\x94\xa8\xe4\xba\x86\xe4\xb8\x80\xe6\xac\xa1\xe4\xbc\xa0batch\xe4\xb8\xaa\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe8\x83\xbd\xe4\xb8\x80\xe6\xac\xa1\xe6\x80\xa7\xe4\xbc\xa0\xe7\xbb\x99\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe5\xb0\xb1\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe9\x83\xbd\xe5\xaf\xb9\xe9\xbd\x90batch\xe4\xb8\xad\xe5\x90\x8d\xe5\xad\x97\xe6\x9c\x80\xe9\x95\xbf\xe7\x9a\x84\xe9\x82\xa3\xe4\xb8\xaa\n# \xe6\x96\xb9\xe6\xb3\x95\xe5\xb0\xb1\xe6\x98\xaf\xe7\x94\xa80\xe5\xa1\xab\xe5\x85\x85  \xe6\xaf\x94\xe5\xa6\x82Snai = \xef\xbc\x884,9,5,10\xef\xbc\x89\xe6\x98\xaf\xe6\x9c\x80\xe9\x95\xbf\xe7\x9a\x84\xef\xbc\x8c\xe9\x82\xa3San\xe5\xb0\xb1\xe8\xa6\x81\xe5\x8f\x98\xe6\x88\x90 \xef\xbc\x884,5,9,0\xef\xbc\x89                       --figure 2\ndef pad_sequences(vectorized_seqs, seq_lengths):\n    seq_tensor = torch.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n    for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n    return seq_tensor\n\n\n# target\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe5\xbf\x85\xe9\xa1\xbb\xe8\xa6\x81\xe6\x98\xaflong.variable\xe8\x80\x8c\xe4\xb8\x8d\xe6\x98\xaffloat\ndef create_dataset(data, x_to_ix, y_to_ix, bs=4):\n    vectorized_seqs = vectorize_data(data, x_to_ix)\n    seq_lengths = torch.LongTensor([len(s) for s in vectorized_seqs])\n    seq_tensor = pad_sequences(vectorized_seqs, seq_lengths)\n    target_tensor = torch.LongTensor([y_to_ix[y] for _, y in data])\n    raw_data = [x for x, _ in data]\n    return DataLoader(\n        PaddedTensorDataset(seq_tensor, target_tensor, seq_lengths, raw_data),\n        batch_size=bs)\n\n\n# input\xe6\xad\xa4\xe6\x97\xb6\xe8\xbf\x98\xe6\x98\xafB x S  (batch_size * seq_lenth)               --\xe8\xbf\x99\xe4\xb8\xaa\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x88\xb0\xe5\x90\x8e\xe9\x9d\xa2\xe7\x9a\x84\xe7\xbd\x91\xe7\xbb\x9c\xe7\xbb\x93\xe6\x9e\x84\xe5\x90\x8e\xe5\x86\x8d\xe5\x9b\x9e\xe6\x9d\xa5\xe7\x90\x86\xe8\xa7\xa3\n#\xe8\x80\x8cembedding\xe5\xb1\x82\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe8\xa6\x81\xe6\xb1\x82\xe6\x98\xafS x B  \xe8\xbe\x93\xe5\x87\xba\xe6\x97\xb6S x B x I (embedding size)\xef\xbc\x8c\xe6\x95\x85\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86input \xe8\xbf\x9b\xe8\xa1\x8c transpose\ndef sort_batch(batch, ys, lengths):\n    seq_lengths, perm_idx = lengths.sort(0, descending=True)\n    seq_tensor = batch[perm_idx]\n    targ_tensor = ys[perm_idx]\n    return seq_tensor.transpose(0, 1), targ_tensor, seq_lengths\n\n\n#\xe5\x88\x86\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe6\xb5\x8b\xe8\xaf\x95\xef\xbc\x8c\xe5\x86\x85\xe9\x83\xa8\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x88dev\xef\xbc\x89\ndef train_dev_test_split(data):\n    train_ratio = int(len(data) * 0.8)  # 80% of dataset\n    train = data[:train_ratio]\n    test = data[train_ratio:]\n    valid_ratio = int(len(train) * 0.8)  # 20% of train set\n    dev = train[valid_ratio:]\n    return train, dev, test\n\n\n# tag == target == label == category == country \ndef build_vocab_tag_sets(data):\n    vocab = set()\n    tags = set()\n    for name in data:\n        chars = set(name[0])\n        # \xe5\x8f\x96\xe5\xb9\xb6\xe9\x9b\x86\n        vocab = vocab.union(chars)\n        tags.add(name[1])\n    return vocab, tags\n\n\ndef make_to_ix(data, to_ix=None):\n    if to_ix is None:\n        to_ix = dict()\n    for c in data:\n        to_ix[c] = len(to_ix)\n    return to_ix\n\n\n# \xe6\x89\x93\xe5\x8c\x85\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x92\x8c\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xef\xbc\x8c\xe6\x9c\x80\xe7\xbb\x88\xe8\xbf\x94\xe5\x9b\x9e\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8closs,\xe8\xa6\x81\xe6\xb3\xa8\xe6\x84\x8f\xe6\x89\x80\xe6\x9c\x89\xe8\xbe\x93\xe5\x85\xa5\xe9\x83\xbd\xe8\xa6\x81\xe4\xbb\x8etensor\xe5\x8f\x98\xe6\x88\x90variable\xef\xbc\x8c\ndef apply(model, criterion, batch, targets, lengths):\n    pred = model(torch.autograd.Variable(batch), lengths.cpu().numpy())\n    loss = criterion(pred, torch.autograd.Variable(targets))\n    return pred, loss\n\n\n""""""\nTraining and evaluation methods\n""""""\n\n\ndef train_model(model, optimizer, train, dev, x_to_ix, y_to_ix):\n    criterion = nn.NLLLoss(size_average=False)\n    for epoch in range(20):\n        print(""Epoch {}"".format(epoch))\n        y_true = list()\n        y_pred = list()\n        total_loss = 0\n        for batch, targets, lengths, raw_data in create_dataset(train, x_to_ix, y_to_ix, bs=TRAIN_BATCH_SIZE):\n            batch, targets, lengths = sort_batch(batch, targets, lengths)\n\n            model.zero_grad()\n            pred, loss = apply(model, criterion, batch, targets, lengths)\n            loss.backward()\n            optimizer.step()\n\n            pred_idx = torch.max(pred, 1)[1]\n            y_true += list(targets.int())\n            y_pred += list(pred_idx.data.int())\n            total_loss += loss\n        acc = accuracy_score(y_true, y_pred)\n        val_loss, val_acc = evaluate_validation_set(model, dev, x_to_ix,\n                                                    y_to_ix, criterion)\n        print(\n            ""Train loss: {} - acc: {} \\nValidation loss: {} - acc: {}"".format(\n                list(total_loss.data.float())[0] / len(train), acc, val_loss,\n                val_acc))\n    return model\n\n\ndef evaluate_validation_set(model, devset, x_to_ix, y_to_ix, criterion):\n    y_true = list()\n    y_pred = list()\n    total_loss = 0\n    for batch, targets, lengths, raw_data in create_dataset(devset, x_to_ix, y_to_ix, bs=VALIDATION_BATCH_SIZE):\n        batch, targets, lengths = sort_batch(batch, targets, lengths)\n        pred, loss = apply(model, criterion, batch, targets, lengths)\n        pred_idx = torch.max(pred, 1)[1]\n        y_true += list(targets.int())\n        y_pred += list(pred_idx.data.int())\n        total_loss += loss\n    acc = accuracy_score(y_true, y_pred)\n    return list(total_loss.data.float())[0] / len(devset), acc\n\n\ndef evaluate_test_set(model, test, x_to_ix, y_to_ix):\n    y_true = list()\n    y_pred = list()\n\n    for batch, targets, lengths, raw_data in create_dataset(\n            test, x_to_ix, y_to_ix, bs=TEST_BATCH_SIZE):\n        batch, targets, lengths = sort_batch(batch, targets, lengths)\n\n        pred = model(torch.autograd.Variable(batch), lengths.cpu().numpy())\n        pred_idx = torch.max(pred, 1)[1]\n        y_true += list(targets.int())\n        y_pred += list(pred_idx.data.int())\n\n    print(len(y_true), len(y_pred))\n    print(classification_report(y_true, y_pred))\n    print(confusion_matrix(y_true, y_pred))\n\n\n""""""\n\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x98\xaf\xe4\xb8\x80\xe5\xb1\x82embedding\xef\xbc\x8c\xe4\xb8\x80\xe5\xb1\x82LSTM\xef\xbc\x8c\xe4\xb8\x80\xe5\xb1\x82\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5,\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaasoftmax\xe3\x80\x82\n\xe8\xbe\x93\xe5\x85\xa5\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaabatch\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe7\xbb\x84\xe6\x88\x90\xe7\x9a\x84\xe5\x90\x91\xe9\x87\x8f\xe5\x92\x8c\xe8\xbf\x99\xe4\xb8\xaabatch\xe4\xb8\xad\xe6\x9c\x80\xe9\x95\xbf\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe5\x8d\xb3seq_lenth,\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xafLSTM\xe4\xb8\xad\xe6\x89\x80\xe8\xb0\x93\xe7\x9a\x84time_step\xef\xbc\x9b\n\xe8\xbe\x93\xe5\x87\xba\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaa\xe5\x90\x8d\xe5\xad\x97\xe5\xaf\xb9\xe5\xba\x94\xe5\x90\x84\xe4\xb8\xaa\xe5\x9b\xbd\xe5\xae\xb6\xe7\x9a\x84\xe5\x8f\xaf\xe8\x83\xbd\xe6\x80\xa7\xe3\x80\x82\n\n\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xef\xbc\x8cembedding\xe5\xb1\x82\xe7\x9a\x84\xe6\x84\x8f\xe4\xb9\x89\xe6\x98\xaf\xe9\x81\xbf\xe5\x85\x8d\xe5\x87\xba\xe7\x8e\xb0\xe5\xa4\xaa\xe5\xa4\x9a\xe7\x9a\x840\xe5\x80\xbc\xe8\x80\x8c\xe5\xbd\xb1\xe5\x93\x8d\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe4\xb9\x8b\xe5\x89\x8d\xe4\xb8\xba\xe4\xba\x86\xe5\xaf\xb9\xe9\xbd\x90\xe7\xbb\x99\xe5\x90\x8d\xe5\xad\x97\xe5\x90\x91\xe9\x87\x8f\xe6\x89\x8b\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85\xe4\xba\x86\xe5\xbe\x88\xe5\xa4\x9a0\xef\xbc\x8c\n\xe9\x80\x9a\xe8\xbf\x87embedding\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x86\xe5\x85\xb6\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xef\xbc\x88\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x80\xbc\xe9\x83\xbd\xe5\x9c\xa8-2~2\xe4\xb9\x8b\xe9\x97\xb4\xef\xbc\x89\xe5\xb9\xb6\xe9\x81\xbf\xe5\x85\x8d\xe5\x87\xba\xe7\x8e\xb00\xe5\x80\xbc\xe3\x80\x82\n\xe8\x80\x8c\xe5\xae\x9e\xe9\x99\x85\xe5\xba\x94\xe7\x94\xa8\xe4\xb8\xadembedding\xe5\xb1\x82\xe7\x9a\x84\xe4\xbb\xb7\xe5\x80\xbc\xe6\x9b\xb4\xe5\xa4\x9a\xe7\x9a\x84\xe8\xa1\xa8\xe7\x8e\xb0\xe5\x9c\xa8\xe5\xae\x83\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x99\x8d\xe7\xbb\xb4\xe5\xb9\xb6\xe8\x83\xbd\xe5\xb1\x95\xe7\xa4\xba\xe8\xaf\x8d\xe4\xb8\x8e\xe8\xaf\x8d\xe4\xb9\x8b\xe9\x97\xb4\xe5\x85\xb3\xe8\x81\x94\xe6\x80\xa7\xe3\x80\x82      --figure 4\n\npack \xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe4\xb9\x9f\xe5\xbe\x88\xe6\x9c\x89\xe8\xb6\xa3\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe4\xb8\x8d\xe6\x98\xaf\xe5\xbf\x85\xe9\xa1\xbb\xe7\x9a\x84\xe3\x80\x82pack\xe5\xb0\xb1\xe6\x98\xaf\xe5\xb0\x86\xe6\x88\x91\xe4\xbb\xac\xe5\xa1\xab\xe5\x85\x85\xe5\x90\x8e\xe7\x9a\x84\xe5\x90\x91\xe9\x87\x8f\xe5\x85\xa8\xe9\x83\xa8\xe6\x95\xb4\xe5\x90\x88\xe5\x9c\xa8\xe4\xb8\x80\xe8\xb5\xb7\xef\xbc\x8c\xe4\xb8\x80\xe6\xac\xa1\xe8\xbe\x93\xe5\x85\xa5\xe5\xb0\xb1\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe5\xae\x8c\xe6\x95\xb4\xe7\x9a\x84tensor\xef\xbc\x8c\xe4\xbd\xbf\xe5\xbe\x97\xe8\xbf\x90\xe7\xae\x97\xe9\x80\x9f\xe5\xba\xa6\xe6\x9b\xb4\xe5\xbf\xab\n                                                                                   --figure 5\n\xe8\xbf\x98\xe6\x9c\x89\xe4\xb8\x80\xe7\x82\xb9\xe8\xbf\x99\xe9\x87\x8c\xe5\x8a\xa0\xe5\x85\xa5\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x80\xe5\xa4\xa7\xe6\xb1\xa0\xe5\x8c\x96\xe5\xb1\x82max_pool\xe5\xa4\x84\xe7\x90\x86\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe5\x92\x8cCNN\xe4\xb8\xad\xe7\x9a\x84\xe6\xb1\xa0\xe5\x8c\x96\xe6\xb2\xa1\xe6\x9c\x89\xe5\xa4\xaa\xe5\xa4\x9a\xe5\x8c\xba\xe5\x88\xab\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe4\xb9\x9f\xe4\xb8\x8d\xe6\x98\xaf\xe5\xbf\x85\xe9\xa1\xbb\xe7\x9a\x84\xe3\x80\x82\n                                                                                   --figure 9\n""""""\nclass NamesRNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n        super(NamesRNN, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.vocab_size = vocab_size\n\n        self.char_embeds = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1)\n\n        self.fully_connected_layer = nn.Linear(hidden_dim, output_size)\n        self.softmax = nn.LogSoftmax()\n\n    def init_hidden(self, batch):\n        return (autograd.Variable(torch.randn(2, batch, self.hidden_dim)),\n                autograd.Variable(torch.randn(2, batch, self.hidden_dim)))\n\n    def _get_lstm_features(self, names, lengths):\n        self.hidden = self.init_hidden(names.size(-1))\n        embeds = self.char_embeds(names)  # Figure 4\n        packed_input = pack_padded_sequence(embeds, lengths)  # Figure 5\n        packed_output, (ht, ct) = self.lstm(packed_input, self.hidden)  # Figure 6\n        lstm_out, _ = pad_packed_sequence(packed_output)  # Figure 7\n        lstm_out = torch.transpose(lstm_out, 0, 1)\n        lstm_out = torch.transpose(lstm_out, 1, 2)\n        lstm_out = F.tanh(lstm_out)  # Figure 8\n        lstm_out, indices = F.max_pool1d(lstm_out, lstm_out.size(2), return_indices=True)  # Figure 9\n        lstm_out = lstm_out.squeeze(2)  #\xe5\xaf\xb9\xe7\xbb\xb4\xe5\xba\xa6\xe7\x9a\x84\xe4\xbf\xae\xe6\xad\xa3\xef\xbc\x8c\xe4\xbd\xbf\xe5\x85\xb6\xe7\xac\xa6\xe5\x90\x88\xe8\xbe\x93\xe5\x85\xa5\xe6\xa0\xbc\xe5\xbc\x8f\n        lstm_out = F.tanh(lstm_out)\n        lstm_feats = self.fully_connected_layer(lstm_out)\n        output = self.softmax(lstm_feats)  # Figure 10\n        return output\n\n    def forward(self, name, lengths):\n        return self._get_lstm_features(name, lengths)\n\n\n""""""\nMethod for debugging purpose\n""""""\ndef filter_for_visual_example(train):\n    new_t = list()\n    for x in train:\n        if len(x[0]) == 6:\n            new_t.append(x)\n            break\n    for x in train:\n        if len(x[0]) == 5:\n            new_t.append(x)\n            break\n    for x in train:\n        if len(x[0]) == 4:\n            new_t.append(x)\n            break\n    for x in train:\n        if len(x[0]) == 3:\n            new_t.append(x)\n            break\n    return new_t\n\n\ndef load_data(file_directory):\n    # \xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xe5\x80\xbc\n    all_categories = []\n    data = list()\n\n    for filename in findFiles(file_directory):\n        print(""\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84: "", filename)\n        category = filename.split(\'/\')[-1].split(\'.\')[0]\n        all_categories.append(category)\n\n        lines = readLines(filename)\n        for l in lines:\n            data.append((l, category))\n\n    data = random.sample(data, len(data))  # \xe6\x89\x93\xe4\xb9\xb1\xe6\x95\xb0\xe6\x8d\xae\n    return all_categories, data\n\n\nif __name__ == ""__main__"":\n\n    """"""\n    Vocabulary\xe7\x9a\x84\xe7\xbb\x84\xe6\x88\x90\xe4\xb8\x8e\xe5\xae\x98\xe7\xbd\x91\xe6\x95\x99\xe7\xa8\x8b\xe7\x9b\xb8\xe5\x90\x8c\xe3\x80\x82\n    \xe7\x94\xb1\xe4\xba\x8e\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe9\x83\xbd\xe6\x98\xaf\xe7\x94\xb1ASCII\xe7\xa0\x81\xe7\xbb\x84\xe6\x88\x90\xef\xbc\x8c\xe6\xad\xa4\xe5\xa4\x84\xe7\x9a\x84ascii_letters\xe5\x8c\x85\xe6\x8b\xac\xe6\x89\x80\xe6\x9c\x89\xe5\xa4\xa7\xe5\xb0\x8f\xe5\x86\x99\xe5\xad\x97\xe6\xaf\x8d\xe3\x80\x82\n    """"""\n    TRAIN_BATCH_SIZE = 32\n    VALIDATION_BATCH_SIZE = 1\n    TEST_BATCH_SIZE = 1\n\n    all_letters = string.ascii_letters + "" .,;\'""\n    n_letters = len(all_letters)\n\n    category_lines = {}\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe6\x96\x87\xe4\xbb\xb6\xe5\xb9\xb6\xe5\xb0\x86\xe5\xae\x83\xe4\xbb\xac\xe6\x8c\x89\xe7\x85\xa7 [(name,country)...]\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe9\x87\x8d\xe7\xbb\x84\n    all_categories, data = load_data(\'/opt/data/NLP/names/*.txt\')\n    # \xe6\x89\x93\xe5\x8d\xb0\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84\xe5\x89\x8d5\xe8\xa1\x8c\n    print(data[:5])\n\n    # \xe8\x8e\xb7\xe5\x8f\x96\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac\xe5\x88\x86\xe7\xb1\xbb + \xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe9\x87\x8f\n    n_categories = len(all_categories)\n    print(""\\n\xe6\x80\xbb\xe5\x85\xb1: %s \xe5\x88\x86\xe7\xb1\xbb \\n %s"" % (n_categories, all_categories))\n\n    """"""\n    data \xe6\x8c\x89\xe7\x85\xa7 8:2 \xe6\x8b\x86\xe5\x88\x86 train \xe5\x92\x8c test(\xe9\xa2\x84\xe6\xb5\x8b) \xe6\xa0\xb7\xe6\x9c\xac\xe9\x9b\x86\xe5\x90\x88\n    train \xe6\x8c\x89\xe7\x85\xa7 8:2 \xe6\x8b\x86\xe5\x88\x86 train \xe5\x92\x8c dev(\xe6\xa0\xa1\xe9\xaa\x8c) \xe6\xa0\xb7\xe6\x9c\xac\xe9\x9b\x86\xe5\x90\x88\n    """"""\n    train, dev, test = train_dev_test_split(data)\n    # train = filter_for_visual_example(train)\n    # print(train)\n\n    vocab, tags = build_vocab_tag_sets(train)\n\n    chars_to_idx = {\'PAD\': 0, \'UNK\': 1}\n    # \xe7\xbb\x99 vocab \xe5\x92\x8c tags \xe4\xb8\xad\xe7\x9a\x84\xe5\x85\x83\xe7\xb4\xa0\xe5\x8a\xa0 index\n    chars_to_idx = make_to_ix(sorted(list(vocab)), chars_to_idx)  # Really important to sort it if you save your model for later\n    tags_to_idx = make_to_ix(sorted(list(tags)))\n\n    model = NamesRNN(len(chars_to_idx), 128, 32, len(tags))  #voc_size, embedding_size, lstm\xe7\x9a\x84hidden_size, target_size\n    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n\n    model = train_model(model, optimizer, train, dev, chars_to_idx, tags_to_idx)\n'"
src/script.py,0,"b'# coding: utf-8\nimport os\nimport sys\n\n\ndef format_file(filename, str1, str2):\n    """"""\n    \xe6\x96\x87\xe4\xbb\xb6\xe5\x86\x85\xe5\xae\xb9\xe7\x9a\x84\xe6\x9b\xbf\xe6\x8d\xa2\xe5\x8a\x9f\xe8\x83\xbd\n    :return:\n    """"""\n    with open(filename, \'r\') as f:\n        var_object = f.read()\n        if ""gitalk"" not in var_object:\n            var_object = var_object.replace(str1, str2)\n        # print(var_object)\n\n    f = open(filename, ""w"")\n    f.write(var_object)\n\n\nif __name__ == ""__main__"":\n    u_type = sys.argv[1]\n    tag = True\n    if u_type == ""book"":\n        filename = ""book.json""\n        tag = False\n    elif u_type == ""powered"":\n        filename = ""node_modules/gitbook-plugin-tbfed-pagefooter/index.js""\n        str1 = ""powered by Gitbook""\n        str2 = ""\xe7\x94\xb1 ApacheCN \xe5\x9b\xa2\xe9\x98\x9f\xe6\x8f\x90\xe4\xbe\x9b\xe6\x94\xaf\xe6\x8c\x81""\n    elif u_type == ""gitalk"":\n        filename = ""node_modules/gitbook-plugin-tbfed-pagefooter/index.js""\n        str1 = """"""      var str = \' \\\\n\\\\n<footer class=""page-footer"">\' + _copy +\n        \'<span class=""footer-modification"">\' +\n        _label +\n        \'\\\\n{{file.mtime | date(""\' + _format +\n        \'"")}}\\\\n</span></footer>\'""""""\n\n        str2 = """"""\n      var str = \'\\\\n\\\\n\'+\n      \'\\\\n<hr/>\'+\n      \'\\\\n<div align=""center"">\'+\n      \'\\\\n    <p><a href=""http://www.apachecn.org"" target=""_blank""><font face=""KaiTi"" size=""6"" color=""red"">\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x80\xe7\x9b\xb4\xe5\x9c\xa8\xe5\x8a\xaa\xe5\x8a\x9b</font></a></p>\'+\n      \'\\\\n    <p><a href=""https://github.com/apachecn/nlp-pytorch-zh/"" target=""_blank"">apachecn/nlp-pytorch-zh</a></p>\'+\n      \'\\\\n    <p><iframe align=""middle"" src=""https://ghbtns.com/github-btn.html?user=apachecn&repo=nlp-pytorch-zh&type=watch&count=true&v=2"" frameborder=""0"" scrolling=""0"" width=""100px"" height=""25px""></iframe>\'+\n      \'\\\\n    <iframe align=""middle"" src=""https://ghbtns.com/github-btn.html?user=apachecn&repo=nlp-pytorch-zh&type=star&count=true"" frameborder=""0"" scrolling=""0"" width=""100px"" height=""25px""></iframe>\'+\n      \'\\\\n    <iframe align=""middle"" src=""https://ghbtns.com/github-btn.html?user=apachecn&repo=nlp-pytorch-zh&type=fork&count=true"" frameborder=""0"" scrolling=""0"" width=""100px"" height=""25px""></iframe>\'+\n      \'\\\\n    <a target=""_blank"" href=""//shang.qq.com/wpa/qunwpa?idkey=bcee938030cc9e1552deb3bd9617bbbf62d3ec1647e4b60d9cd6b6e8f78ddc03""><img border=""0"" src=""http://data.apachecn.org/img/logo/ApacheCN-group.png"" alt=""ML\xc2\xa0|\xc2\xa0ApacheCN"" title=""ML\xc2\xa0|\xc2\xa0ApacheCN""></a></p>\'+\n      \'\\\\n</div>\'+\n      \'\\\\n <div style=""text-align:center;margin:0 0 10.5px;"">\'+\n      \'\\\\n     <script async src=""//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js""></script>\'+\n      \'\\\\n     <ins class=""adsbygoogle""\'+\n      \'\\\\n         style=""display:inline-block;width:728px;height:90px""\'+\n      \'\\\\n         data-ad-client=""ca-pub-3565452474788507""\'+\n      \'\\\\n         data-ad-slot=""2543897000"">\'+\n      \'\\\\n     </ins>\'+\n      \'\\\\n     <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>\'+\n      \'\\\\n\'+\n      \'\\\\n    <script>\'+\n      \'\\\\n      var _hmt = _hmt || [];\'+\n      \'\\\\n      (function() {\'+\n      \'\\\\n        var hm = document.createElement(""script"");\'+\n      \'\\\\n        hm.src = ""https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91"";\'+\n      \'\\\\n        var s = document.getElementsByTagName(""script"")[0]; \'+\n      \'\\\\n        s.parentNode.insertBefore(hm, s);\'+\n      \'\\\\n      })();\'+\n      \'\\\\n    </script>\'+\n      \'\\\\n\'+\n     \'\\\\n</div>\'+\n      \'\\\\n\'+\n      \'\\\\n<meta name=""google-site-verification"" content=""pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo"" />\'+\n      \'\\\\n<iframe src=""https://www.bilibili.com/read/cv2710377"" style=""display:none""></iframe>\'+ \n      \'\\\\n<img src=""http://t.cn/AiCoDHwb"" hidden=""hidden"" />\'\n\n      str += \'\\\\n\\\\n\'+\n      \'\\\\n<div>\'+\n      \'\\\\n    <link rel=""stylesheet"" href=""https://unpkg.com/gitalk/dist/gitalk.css"">\'+\n      \'\\\\n    <script src=""https://unpkg.com/gitalk@latest/dist/gitalk.min.js""></script>\'+\n      \'\\\\n    <script src=""https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js""></script>\'+\n      \'\\\\n    <div id=""gitalk-container""></div>\'+\n      \'\\\\n    <script type=""text/javascript"">\'+\n      \'\\\\n        const gitalk = new Gitalk({\'+\n      \'\\\\n        clientID: \\\\\'1eba1fde838d39ce2ba9\\\\\',\'+\n      \'\\\\n        clientSecret: \\\\\'0bdf321e160ca29b2d54e8722700dd5accb084e0\\\\\',\'+\n      \'\\\\n        repo: \\\\\'nlp-pytorch-zh\\\\\',\'+\n      \'\\\\n        owner: \\\\\'apachecn\\\\\',\'+\n      \'\\\\n        admin: [\\\\\'jiangzhonglian\\\\\', \\\\\'wizardforcel\\\\\'],\'+\n      \'\\\\n        id: md5(location.pathname),\'+\n      \'\\\\n        distractionFreeMode: false\'+\n      \'\\\\n        })\'+\n      \'\\\\n        gitalk.render(\\\\\'gitalk-container\\\\\')\'+\n      \'\\\\n    </script>\'+\n      \'\\\\n</div>\'\n\n      str += \'\\\\n\\\\n<footer class=""page-footer"">\' + _copy + \'<span class=""footer-modification"">\' + _label + \'\\\\n{{file.mtime | date(""\' + _format + \'"")}}\\\\n</span></footer>\'\n        """"""\n\n    # \xe7\x8a\xb6\xe6\x80\x81\xe4\xb8\xba True \xe5\xb0\xb1\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x9b\xbf\xe6\x8d\xa2\n    if tag: format_file(filename, str1, str2)\n'"
src/文本摘要.py,0,"b'#!/user/bin/python\n# coding:utf-8\n\nimport nltk\nimport numpy\nimport jieba\nimport codecs\nimport os\n\n\nclass SummaryTxt:\n    def __init__(self, stopwordspath):\n        # \xe5\x8d\x95\xe8\xaf\x8d\xe6\x95\xb0\xe9\x87\x8f\n        self.N = 100\n        # \xe5\x8d\x95\xe8\xaf\x8d\xe9\x97\xb4\xe7\x9a\x84\xe8\xb7\x9d\xe7\xa6\xbb\n        self.CLUSTER_THRESHOLD = 5\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84top n\xe5\x8f\xa5\xe5\xad\x90\n        self.TOP_SENTENCES = 5\n        self.stopwrods = {}\n        # \xe5\x8a\xa0\xe8\xbd\xbd\xe5\x81\x9c\xe7\x94\xa8\xe8\xaf\x8d\n        if os.path.exists(stopwordspath):\n            stoplist = [\n                line.strip()\n                for line in codecs.open(\n                    stopwordspath, \'r\', encoding=\'utf8\').readlines()\n            ]\n            self.stopwrods = {}.fromkeys(stoplist)\n\n    def _split_sentences(self, texts):\n        \'\'\'\n        \xe6\x8a\x8atexts\xe6\x8b\x86\xe5\x88\x86\xe6\x88\x90\xe5\x8d\x95\xe4\xb8\xaa\xe5\x8f\xa5\xe5\xad\x90\xef\xbc\x8c\xe4\xbf\x9d\xe5\xad\x98\xe5\x9c\xa8\xe5\x88\x97\xe8\xa1\xa8\xe9\x87\x8c\xe9\x9d\xa2\xef\xbc\x8c\xe4\xbb\xa5\xef\xbc\x88.!?\xe3\x80\x82\xef\xbc\x81\xef\xbc\x9f\xef\xbc\x89\xe8\xbf\x99\xe4\xba\x9b\xe6\xa0\x87\xe7\x82\xb9\xe4\xbd\x9c\xe4\xb8\xba\xe6\x8b\x86\xe5\x88\x86\xe7\x9a\x84\xe6\x84\x8f\xe8\xa7\x81\xef\xbc\x8c\n        :param texts: \xe6\x96\x87\xe6\x9c\xac\xe4\xbf\xa1\xe6\x81\xaf\n        :return:\n        \'\'\'\n        splitstr = \'.!?\xe3\x80\x82\xef\xbc\x81\xef\xbc\x9f\' # .decode(\'utf8\')\n        start = 0\n        index = 0  # \xe6\xaf\x8f\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\n        sentences = []\n        for text in texts:\n            if text in splitstr:  # \xe6\xa3\x80\xe6\x9f\xa5\xe6\xa0\x87\xe7\x82\xb9\xe7\xac\xa6\xe5\x8f\xb7\xe4\xb8\x8b\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\xe6\x98\xaf\xe5\x90\xa6\xe8\xbf\x98\xe6\x98\xaf\xe6\xa0\x87\xe7\x82\xb9\n                sentences.append(texts[start:index + 1])  # \xe5\xbd\x93\xe5\x89\x8d\xe6\xa0\x87\xe7\x82\xb9\xe7\xac\xa6\xe5\x8f\xb7\xe4\xbd\x8d\xe7\xbd\xae\n                start = index + 1  # start\xe6\xa0\x87\xe8\xae\xb0\xe5\x88\xb0\xe4\xb8\x8b\xe4\xb8\x80\xe5\x8f\xa5\xe7\x9a\x84\xe5\xbc\x80\xe5\xa4\xb4\n            index += 1\n        if start < len(texts):\n            sentences.append(texts[start:])  # \xe8\xbf\x99\xe6\x98\xaf\xe4\xb8\xba\xe4\xba\x86\xe5\xa4\x84\xe7\x90\x86\xe6\x96\x87\xe6\x9c\xac\xe6\x9c\xab\xe5\xb0\xbe\xe6\xb2\xa1\xe6\x9c\x89\xe6\xa0\x87\n\n        return sentences\n\n    def _score_sentences(self, sentences, topn_words):\n        \'\'\'\n        \xe5\x88\xa9\xe7\x94\xa8\xe5\x89\x8dN\xe4\xb8\xaa\xe5\x85\xb3\xe9\x94\xae\xe5\xad\x97\xe7\xbb\x99\xe5\x8f\xa5\xe5\xad\x90\xe6\x89\x93\xe5\x88\x86\n        :param sentences: \xe5\x8f\xa5\xe5\xad\x90\xe5\x88\x97\xe8\xa1\xa8\n        :param topn_words: \xe5\x85\xb3\xe9\x94\xae\xe5\xad\x97\xe5\x88\x97\xe8\xa1\xa8\n        :return:\n        \'\'\'\n        scores = []\n        sentence_idx = -1\n        for s in [list(jieba.cut(s)) for s in sentences]:\n            sentence_idx += 1\n            word_idx = []\n            for w in topn_words:\n                try:\n                    word_idx.append(s.index(w))  # \xe5\x85\xb3\xe9\x94\xae\xe8\xaf\x8d\xe5\x87\xba\xe7\x8e\xb0\xe5\x9c\xa8\xe8\xaf\xa5\xe5\x8f\xa5\xe5\xad\x90\xe4\xb8\xad\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\xe4\xbd\x8d\xe7\xbd\xae\n                except ValueError:  # w\xe4\xb8\x8d\xe5\x9c\xa8\xe5\x8f\xa5\xe5\xad\x90\xe4\xb8\xad\n                    pass\n            word_idx.sort()\n            if len(word_idx) == 0:\n                continue\n            # \xe5\xaf\xb9\xe4\xba\x8e\xe4\xb8\xa4\xe4\xb8\xaa\xe8\xbf\x9e\xe7\xbb\xad\xe7\x9a\x84\xe5\x8d\x95\xe8\xaf\x8d\xef\xbc\x8c\xe5\x88\xa9\xe7\x94\xa8\xe5\x8d\x95\xe8\xaf\x8d\xe4\xbd\x8d\xe7\xbd\xae\xe7\xb4\xa2\xe5\xbc\x95\xef\xbc\x8c\xe9\x80\x9a\xe8\xbf\x87\xe8\xb7\x9d\xe7\xa6\xbb\xe9\x98\x80\xe5\x80\xbc\xe8\xae\xa1\xe7\xae\x97\xe6\x97\x8f\n            clusters = []\n            cluster = [word_idx[0]]\n            i = 1\n            while i < len(word_idx):\n                if word_idx[i] - word_idx[i - 1] < self.CLUSTER_THRESHOLD:\n                    cluster.append(word_idx[i])\n                else:\n                    clusters.append(cluster[:])\n                    cluster = [word_idx[i]]\n                i += 1\n            clusters.append(cluster)\n            # \xe5\xaf\xb9\xe6\xaf\x8f\xe4\xb8\xaa\xe6\x97\x8f\xe6\x89\x93\xe5\x88\x86\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\xaa\xe6\x97\x8f\xe7\xb1\xbb\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe5\x88\x86\xe6\x95\xb0\xe6\x98\xaf\xe5\xaf\xb9\xe5\x8f\xa5\xe5\xad\x90\xe7\x9a\x84\xe6\x89\x93\xe5\x88\x86\n            max_cluster_score = 0\n            for c in clusters:\n                significant_words_in_cluster = len(c)\n                total_words_in_cluster = c[-1] - c[0] + 1\n                score = 1.0 * significant_words_in_cluster * significant_words_in_cluster / total_words_in_cluster\n                if score > max_cluster_score:\n                    max_cluster_score = score\n            scores.append((sentence_idx, max_cluster_score))\n        return scores\n\n    def summaryScoredtxt(self, text):\n        # \xe5\xb0\x86\xe6\x96\x87\xe7\xab\xa0\xe5\x88\x86\xe6\x88\x90\xe5\x8f\xa5\xe5\xad\x90\n        sentences = self._split_sentences(text)\n\n        # \xe7\x94\x9f\xe6\x88\x90\xe5\x88\x86\xe8\xaf\x8d\n        words = [\n            w for sentence in sentences for w in jieba.cut(sentence)\n            if w not in self.stopwrods if len(w) > 1 and w != \'\\t\'\n        ]\n        # words = []\n        # for sentence in sentences:\n        #     for w in jieba.cut(sentence):\n        #         if w not in stopwords and len(w) > 1 and w != \'\\t\':\n        #             words.append(w)\n\n        # \xe7\xbb\x9f\xe8\xae\xa1\xe8\xaf\x8d\xe9\xa2\x91\n        wordfre = nltk.FreqDist(words)\n\n        # \xe8\x8e\xb7\xe5\x8f\x96\xe8\xaf\x8d\xe9\xa2\x91\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84\xe5\x89\x8dN\xe4\xb8\xaa\xe8\xaf\x8d\n        topn_words = [\n            w[0]\n            for w in sorted(\n                wordfre.items(), key=lambda d: d[1], reverse=True)\n        ][:self.N]\n\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84n\xe4\xb8\xaa\xe5\x85\xb3\xe9\x94\xae\xe8\xaf\x8d\xef\xbc\x8c\xe7\xbb\x99\xe5\x8f\xa5\xe5\xad\x90\xe6\x89\x93\xe5\x88\x86\n        scored_sentences = self._score_sentences(sentences, topn_words)\n\n        # \xe5\x88\xa9\xe7\x94\xa8\xe5\x9d\x87\xe5\x80\xbc\xe5\x92\x8c\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe8\xbf\x87\xe6\xbb\xa4\xe9\x9d\x9e\xe9\x87\x8d\xe8\xa6\x81\xe5\x8f\xa5\xe5\xad\x90\n        avg = numpy.mean([s[1] for s in scored_sentences])  # \xe5\x9d\x87\xe5\x80\xbc\n        std = numpy.std([s[1] for s in scored_sentences])  # \xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\n        summarySentences = []\n        for (sent_idx, score) in scored_sentences:\n            if score > (avg + 0.5 * std):\n                summarySentences.append(sentences[sent_idx])\n                print(sentences[sent_idx])\n        return summarySentences\n\n    def summaryTopNtxt(self, text):\n        # \xe5\xb0\x86\xe6\x96\x87\xe7\xab\xa0\xe5\x88\x86\xe6\x88\x90\xe5\x8f\xa5\xe5\xad\x90\n        sentences = self._split_sentences(text)\n\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe5\x8f\xa5\xe5\xad\x90\xe5\x88\x97\xe8\xa1\xa8\xe7\x94\x9f\xe6\x88\x90\xe5\x88\x86\xe8\xaf\x8d\xe5\x88\x97\xe8\xa1\xa8\n        words = [\n            w for sentence in sentences for w in jieba.cut(sentence)\n            if w not in self.stopwrods if len(w) > 1 and w != \'\\t\'\n        ]\n        # words = []\n        # for sentence in sentences:\n        #     for w in jieba.cut(sentence):\n        #         if w not in stopwords and len(w) > 1 and w != \'\\t\':\n        #             words.append(w)\n\n        # \xe7\xbb\x9f\xe8\xae\xa1\xe8\xaf\x8d\xe9\xa2\x91\n        wordfre = nltk.FreqDist(words)\n\n        # \xe8\x8e\xb7\xe5\x8f\x96\xe8\xaf\x8d\xe9\xa2\x91\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84\xe5\x89\x8dN\xe4\xb8\xaa\xe8\xaf\x8d\n        topn_words = [\n            w[0]\n            for w in sorted(\n                wordfre.items(), key=lambda d: d[1], reverse=True)\n        ][:self.N]\n\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84n\xe4\xb8\xaa\xe5\x85\xb3\xe9\x94\xae\xe8\xaf\x8d\xef\xbc\x8c\xe7\xbb\x99\xe5\x8f\xa5\xe5\xad\x90\xe6\x89\x93\xe5\x88\x86\n        scored_sentences = self._score_sentences(sentences, topn_words)\n\n        top_n_scored = sorted(\n            scored_sentences, key=lambda s: s[1])[-self.TOP_SENTENCES:]\n        top_n_scored = sorted(top_n_scored, key=lambda s: s[0])\n        summarySentences = []\n        for (idx, score) in top_n_scored:\n            print(sentences[idx])\n            summarySentences.append(sentences[idx])\n\n        return sentences\n\n\nif __name__ == \'__main__\':\n    obj = SummaryTxt(\'D:\\work\\Solr\\solr-python\\CNstopwords.txt\')\n\n    txt=u\'\xe5\x8d\x81\xe5\x85\xab\xe5\xa4\xa7\xe4\xbb\xa5\xe6\x9d\xa5\xe7\x9a\x84\xe4\xba\x94\xe5\xb9\xb4\xef\xbc\x8c\xe6\x98\xaf\xe5\x85\x9a\xe5\x92\x8c\xe5\x9b\xbd\xe5\xae\xb6\xe5\x8f\x91\xe5\xb1\x95\xe8\xbf\x9b\xe7\xa8\x8b\xe4\xb8\xad\xe6\x9e\x81\xe4\xb8\x8d\xe5\xb9\xb3\xe5\x87\xa1\xe7\x9a\x84\xe4\xba\x94\xe5\xb9\xb4\xe3\x80\x82\xe9\x9d\xa2\xe5\xaf\xb9\xe4\xb8\x96\xe7\x95\x8c\xe7\xbb\x8f\xe6\xb5\x8e\xe5\xa4\x8d\xe8\x8b\x8f\xe4\xb9\x8f\xe5\x8a\x9b\xe3\x80\x81\xe5\xb1\x80\xe9\x83\xa8\xe5\x86\xb2\xe7\xaa\x81\xe5\x92\x8c\xe5\x8a\xa8\xe8\x8d\xa1\xe9\xa2\x91\xe5\x8f\x91\xe3\x80\x81\xe5\x85\xa8\xe7\x90\x83\xe6\x80\xa7\xe9\x97\xae\xe9\xa2\x98\xe5\x8a\xa0\xe5\x89\xa7\xe7\x9a\x84\xe5\xa4\x96\xe9\x83\xa8\xe7\x8e\xaf\xe5\xa2\x83\xef\xbc\x8c\xe9\x9d\xa2\xe5\xaf\xb9\xe6\x88\x91\xe5\x9b\xbd\xe7\xbb\x8f\xe6\xb5\x8e\xe5\x8f\x91\xe5\xb1\x95\xe8\xbf\x9b\xe5\x85\xa5\xe6\x96\xb0\xe5\xb8\xb8\xe6\x80\x81\xe7\xad\x89\xe4\xb8\x80\xe7\xb3\xbb\xe5\x88\x97\xe6\xb7\xb1\xe5\x88\xbb\xe5\x8f\x98\xe5\x8c\x96\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe5\x9d\x9a\xe6\x8c\x81\xe7\xa8\xb3\xe4\xb8\xad\xe6\xb1\x82\xe8\xbf\x9b\xe5\xb7\xa5\xe4\xbd\x9c\xe6\x80\xbb\xe5\x9f\xba\xe8\xb0\x83\xef\xbc\x8c\xe8\xbf\x8e\xe9\x9a\xbe\xe8\x80\x8c\xe4\xb8\x8a\xef\xbc\x8c\xe5\xbc\x80\xe6\x8b\x93\xe8\xbf\x9b\xe5\x8f\x96\xef\xbc\x8c\xe5\x8f\x96\xe5\xbe\x97\xe4\xba\x86\xe6\x94\xb9\xe9\x9d\xa9\xe5\xbc\x80\xe6\x94\xbe\xe5\x92\x8c\xe7\xa4\xbe\xe4\xbc\x9a\xe4\xb8\xbb\xe4\xb9\x89\xe7\x8e\xb0\xe4\xbb\xa3\xe5\x8c\x96\xe5\xbb\xba\xe8\xae\xbe\xe7\x9a\x84\xe5\x8e\x86\xe5\x8f\xb2\xe6\x80\xa7\xe6\x88\x90\xe5\xb0\xb1\xe3\x80\x82\' \\\n        u\'\xe4\xb8\xba\xe8\xb4\xaf\xe5\xbd\xbb\xe5\x8d\x81\xe5\x85\xab\xe5\xa4\xa7\xe7\xb2\xbe\xe7\xa5\x9e\xef\xbc\x8c\xe5\x85\x9a\xe4\xb8\xad\xe5\xa4\xae\xe5\x8f\xac\xe5\xbc\x80\xe4\xb8\x83\xe6\xac\xa1\xe5\x85\xa8\xe4\xbc\x9a\xef\xbc\x8c\xe5\x88\x86\xe5\x88\xab\xe5\xb0\xb1\xe6\x94\xbf\xe5\xba\x9c\xe6\x9c\xba\xe6\x9e\x84\xe6\x94\xb9\xe9\x9d\xa9\xe5\x92\x8c\xe8\x81\x8c\xe8\x83\xbd\xe8\xbd\xac\xe5\x8f\x98\xe3\x80\x81\xe5\x85\xa8\xe9\x9d\xa2\xe6\xb7\xb1\xe5\x8c\x96\xe6\x94\xb9\xe9\x9d\xa9\xe3\x80\x81\xe5\x85\xa8\xe9\x9d\xa2\xe6\x8e\xa8\xe8\xbf\x9b\xe4\xbe\x9d\xe6\xb3\x95\xe6\xb2\xbb\xe5\x9b\xbd\xe3\x80\x81\xe5\x88\xb6\xe5\xae\x9a\xe2\x80\x9c\xe5\x8d\x81\xe4\xb8\x89\xe4\xba\x94\xe2\x80\x9d\xe8\xa7\x84\xe5\x88\x92\xe3\x80\x81\xe5\x85\xa8\xe9\x9d\xa2\xe4\xbb\x8e\xe4\xb8\xa5\xe6\xb2\xbb\xe5\x85\x9a\xe7\xad\x89\xe9\x87\x8d\xe5\xa4\xa7\xe9\x97\xae\xe9\xa2\x98\xe4\xbd\x9c\xe5\x87\xba\xe5\x86\xb3\xe5\xae\x9a\xe5\x92\x8c\xe9\x83\xa8\xe7\xbd\xb2\xe3\x80\x82\xe4\xba\x94\xe5\xb9\xb4\xe6\x9d\xa5\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe7\xbb\x9f\xe7\xad\xb9\xe6\x8e\xa8\xe8\xbf\x9b\xe2\x80\x9c\xe4\xba\x94\xe4\xbd\x8d\xe4\xb8\x80\xe4\xbd\x93\xe2\x80\x9d\xe6\x80\xbb\xe4\xbd\x93\xe5\xb8\x83\xe5\xb1\x80\xe3\x80\x81\xe5\x8d\x8f\xe8\xb0\x83\xe6\x8e\xa8\xe8\xbf\x9b\xe2\x80\x9c\xe5\x9b\x9b\xe4\xb8\xaa\xe5\x85\xa8\xe9\x9d\xa2\xe2\x80\x9d\xe6\x88\x98\xe7\x95\xa5\xe5\xb8\x83\xe5\xb1\x80\xef\xbc\x8c\xe2\x80\x9c\xe5\x8d\x81\xe4\xba\x8c\xe4\xba\x94\xe2\x80\x9d\xe8\xa7\x84\xe5\x88\x92\xe8\x83\x9c\xe5\x88\xa9\xe5\xae\x8c\xe6\x88\x90\xef\xbc\x8c\xe2\x80\x9c\xe5\x8d\x81\xe4\xb8\x89\xe4\xba\x94\xe2\x80\x9d\xe8\xa7\x84\xe5\x88\x92\xe9\xa1\xba\xe5\x88\xa9\xe5\xae\x9e\xe6\x96\xbd\xef\xbc\x8c\xe5\x85\x9a\xe5\x92\x8c\xe5\x9b\xbd\xe5\xae\xb6\xe4\xba\x8b\xe4\xb8\x9a\xe5\x85\xa8\xe9\x9d\xa2\xe5\xbc\x80\xe5\x88\x9b\xe6\x96\xb0\xe5\xb1\x80\xe9\x9d\xa2\xe3\x80\x82\' \\\n        u\'\xe7\xbb\x8f\xe6\xb5\x8e\xe5\xbb\xba\xe8\xae\xbe\xe5\x8f\x96\xe5\xbe\x97\xe9\x87\x8d\xe5\xa4\xa7\xe6\x88\x90\xe5\xb0\xb1\xe3\x80\x82\xe5\x9d\x9a\xe5\xae\x9a\xe4\xb8\x8d\xe7\xa7\xbb\xe8\xb4\xaf\xe5\xbd\xbb\xe6\x96\xb0\xe5\x8f\x91\xe5\xb1\x95\xe7\x90\x86\xe5\xbf\xb5\xef\xbc\x8c\xe5\x9d\x9a\xe5\x86\xb3\xe7\xab\xaf\xe6\xad\xa3\xe5\x8f\x91\xe5\xb1\x95\xe8\xa7\x82\xe5\xbf\xb5\xe3\x80\x81\xe8\xbd\xac\xe5\x8f\x98\xe5\x8f\x91\xe5\xb1\x95\xe6\x96\xb9\xe5\xbc\x8f\xef\xbc\x8c\xe5\x8f\x91\xe5\xb1\x95\xe8\xb4\xa8\xe9\x87\x8f\xe5\x92\x8c\xe6\x95\x88\xe7\x9b\x8a\xe4\xb8\x8d\xe6\x96\xad\xe6\x8f\x90\xe5\x8d\x87\xe3\x80\x82\xe7\xbb\x8f\xe6\xb5\x8e\xe4\xbf\x9d\xe6\x8c\x81\xe4\xb8\xad\xe9\xab\x98\xe9\x80\x9f\xe5\xa2\x9e\xe9\x95\xbf\xef\xbc\x8c\xe5\x9c\xa8\xe4\xb8\x96\xe7\x95\x8c\xe4\xb8\xbb\xe8\xa6\x81\xe5\x9b\xbd\xe5\xae\xb6\xe4\xb8\xad\xe5\x90\x8d\xe5\x88\x97\xe5\x89\x8d\xe8\x8c\x85\xef\xbc\x8c\xe5\x9b\xbd\xe5\x86\x85\xe7\x94\x9f\xe4\xba\xa7\xe6\x80\xbb\xe5\x80\xbc\xe4\xbb\x8e\xe4\xba\x94\xe5\x8d\x81\xe5\x9b\x9b\xe4\xb8\x87\xe4\xba\xbf\xe5\x85\x83\xe5\xa2\x9e\xe9\x95\xbf\xe5\x88\xb0\xe5\x85\xab\xe5\x8d\x81\xe4\xb8\x87\xe4\xba\xbf\xe5\x85\x83\xef\xbc\x8c\xe7\xa8\xb3\xe5\xb1\x85\xe4\xb8\x96\xe7\x95\x8c\xe7\xac\xac\xe4\xba\x8c\xef\xbc\x8c\xe5\xaf\xb9\xe4\xb8\x96\xe7\x95\x8c\xe7\xbb\x8f\xe6\xb5\x8e\xe5\xa2\x9e\xe9\x95\xbf\xe8\xb4\xa1\xe7\x8c\xae\xe7\x8e\x87\xe8\xb6\x85\xe8\xbf\x87\xe7\x99\xbe\xe5\x88\x86\xe4\xb9\x8b\xe4\xb8\x89\xe5\x8d\x81\xe3\x80\x82\xe4\xbe\x9b\xe7\xbb\x99\xe4\xbe\xa7\xe7\xbb\x93\xe6\x9e\x84\xe6\x80\xa7\xe6\x94\xb9\xe9\x9d\xa9\xe6\xb7\xb1\xe5\x85\xa5\xe6\x8e\xa8\xe8\xbf\x9b\xef\xbc\x8c\xe7\xbb\x8f\xe6\xb5\x8e\xe7\xbb\x93\xe6\x9e\x84\xe4\xb8\x8d\xe6\x96\xad\xe4\xbc\x98\xe5\x8c\x96\xef\xbc\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbb\x8f\xe6\xb5\x8e\xe7\xad\x89\xe6\x96\xb0\xe5\x85\xb4\xe4\xba\xa7\xe4\xb8\x9a\xe8\x93\xac\xe5\x8b\x83\xe5\x8f\x91\xe5\xb1\x95\xef\xbc\x8c\xe9\xab\x98\xe9\x93\x81\xe3\x80\x81\xe5\x85\xac\xe8\xb7\xaf\xe3\x80\x81\xe6\xa1\xa5\xe6\xa2\x81\xe3\x80\x81\xe6\xb8\xaf\xe5\x8f\xa3\xe3\x80\x81\xe6\x9c\xba\xe5\x9c\xba\xe7\xad\x89\xe5\x9f\xba\xe7\xa1\x80\xe8\xae\xbe\xe6\x96\xbd\xe5\xbb\xba\xe8\xae\xbe\xe5\xbf\xab\xe9\x80\x9f\xe6\x8e\xa8\xe8\xbf\x9b\xe3\x80\x82\xe5\x86\x9c\xe4\xb8\x9a\xe7\x8e\xb0\xe4\xbb\xa3\xe5\x8c\x96\xe7\xa8\xb3\xe6\xad\xa5\xe6\x8e\xa8\xe8\xbf\x9b\xef\xbc\x8c\xe7\xb2\xae\xe9\xa3\x9f\xe7\x94\x9f\xe4\xba\xa7\xe8\x83\xbd\xe5\x8a\x9b\xe8\xbe\xbe\xe5\x88\xb0\xe4\xb8\x80\xe4\xb8\x87\xe4\xba\x8c\xe5\x8d\x83\xe4\xba\xbf\xe6\x96\xa4\xe3\x80\x82\xe5\x9f\x8e\xe9\x95\x87\xe5\x8c\x96\xe7\x8e\x87\xe5\xb9\xb4\xe5\x9d\x87\xe6\x8f\x90\xe9\xab\x98\xe4\xb8\x80\xe7\x82\xb9\xe4\xba\x8c\xe4\xb8\xaa\xe7\x99\xbe\xe5\x88\x86\xe7\x82\xb9\xef\xbc\x8c\xe5\x85\xab\xe5\x8d\x83\xe5\xa4\x9a\xe4\xb8\x87\xe5\x86\x9c\xe4\xb8\x9a\xe8\xbd\xac\xe7\xa7\xbb\xe4\xba\xba\xe5\x8f\xa3\xe6\x88\x90\xe4\xb8\xba\xe5\x9f\x8e\xe9\x95\x87\xe5\xb1\x85\xe6\xb0\x91\xe3\x80\x82\xe5\x8c\xba\xe5\x9f\x9f\xe5\x8f\x91\xe5\xb1\x95\xe5\x8d\x8f\xe8\xb0\x83\xe6\x80\xa7\xe5\xa2\x9e\xe5\xbc\xba\xef\xbc\x8c\xe2\x80\x9c\xe4\xb8\x80\xe5\xb8\xa6\xe4\xb8\x80\xe8\xb7\xaf\xe2\x80\x9d\xe5\xbb\xba\xe8\xae\xbe\xe3\x80\x81\xe4\xba\xac\xe6\xb4\xa5\xe5\x86\x80\xe5\x8d\x8f\xe5\x90\x8c\xe5\x8f\x91\xe5\xb1\x95\xe3\x80\x81\xe9\x95\xbf\xe6\xb1\x9f\xe7\xbb\x8f\xe6\xb5\x8e\xe5\xb8\xa6\xe5\x8f\x91\xe5\xb1\x95\xe6\x88\x90\xe6\x95\x88\xe6\x98\xbe\xe8\x91\x97\xe3\x80\x82\xe5\x88\x9b\xe6\x96\xb0\xe9\xa9\xb1\xe5\x8a\xa8\xe5\x8f\x91\xe5\xb1\x95\xe6\x88\x98\xe7\x95\xa5\xe5\xa4\xa7\xe5\x8a\x9b\xe5\xae\x9e\xe6\x96\xbd\xef\xbc\x8c\xe5\x88\x9b\xe6\x96\xb0\xe5\x9e\x8b\xe5\x9b\xbd\xe5\xae\xb6\xe5\xbb\xba\xe8\xae\xbe\xe6\x88\x90\xe6\x9e\x9c\xe4\xb8\xb0\xe7\xa1\x95\xef\xbc\x8c\xe5\xa4\xa9\xe5\xae\xab\xe3\x80\x81\xe8\x9b\x9f\xe9\xbe\x99\xe3\x80\x81\xe5\xa4\xa9\xe7\x9c\xbc\xe3\x80\x81\xe6\x82\x9f\xe7\xa9\xba\xe3\x80\x81\xe5\xa2\xa8\xe5\xad\x90\xe3\x80\x81\xe5\xa4\xa7\xe9\xa3\x9e\xe6\x9c\xba\xe7\xad\x89\xe9\x87\x8d\xe5\xa4\xa7\xe7\xa7\x91\xe6\x8a\x80\xe6\x88\x90\xe6\x9e\x9c\xe7\x9b\xb8\xe7\xbb\xa7\xe9\x97\xae\xe4\xb8\x96\xe3\x80\x82\xe5\x8d\x97\xe6\xb5\xb7\xe5\xb2\x9b\xe7\xa4\x81\xe5\xbb\xba\xe8\xae\xbe\xe7\xa7\xaf\xe6\x9e\x81\xe6\x8e\xa8\xe8\xbf\x9b\xe3\x80\x82\xe5\xbc\x80\xe6\x94\xbe\xe5\x9e\x8b\xe7\xbb\x8f\xe6\xb5\x8e\xe6\x96\xb0\xe4\xbd\x93\xe5\x88\xb6\xe9\x80\x90\xe6\xad\xa5\xe5\x81\xa5\xe5\x85\xa8\xef\xbc\x8c\xe5\xaf\xb9\xe5\xa4\x96\xe8\xb4\xb8\xe6\x98\x93\xe3\x80\x81\xe5\xaf\xb9\xe5\xa4\x96\xe6\x8a\x95\xe8\xb5\x84\xe3\x80\x81\xe5\xa4\x96\xe6\xb1\x87\xe5\x82\xa8\xe5\xa4\x87\xe7\xa8\xb3\xe5\xb1\x85\xe4\xb8\x96\xe7\x95\x8c\xe5\x89\x8d\xe5\x88\x97\xe3\x80\x82\' \\\n        u\'\xe5\x85\xa8\xe9\x9d\xa2\xe6\xb7\xb1\xe5\x8c\x96\xe6\x94\xb9\xe9\x9d\xa9\xe5\x8f\x96\xe5\xbe\x97\xe9\x87\x8d\xe5\xa4\xa7\xe7\xaa\x81\xe7\xa0\xb4\xe3\x80\x82\xe8\xb9\x84\xe7\x96\xbe\xe6\xad\xa5\xe7\xa8\xb3\xe6\x8e\xa8\xe8\xbf\x9b\xe5\x85\xa8\xe9\x9d\xa2\xe6\xb7\xb1\xe5\x8c\x96\xe6\x94\xb9\xe9\x9d\xa9\xef\xbc\x8c\xe5\x9d\x9a\xe5\x86\xb3\xe7\xa0\xb4\xe9\x99\xa4\xe5\x90\x84\xe6\x96\xb9\xe9\x9d\xa2\xe4\xbd\x93\xe5\x88\xb6\xe6\x9c\xba\xe5\x88\xb6\xe5\xbc\x8a\xe7\xab\xaf\xe3\x80\x82\xe6\x94\xb9\xe9\x9d\xa9\xe5\x85\xa8\xe9\x9d\xa2\xe5\x8f\x91\xe5\x8a\x9b\xe3\x80\x81\xe5\xa4\x9a\xe7\x82\xb9\xe7\xaa\x81\xe7\xa0\xb4\xe3\x80\x81\xe7\xba\xb5\xe6\xb7\xb1\xe6\x8e\xa8\xe8\xbf\x9b\xef\xbc\x8c\xe7\x9d\x80\xe5\x8a\x9b\xe5\xa2\x9e\xe5\xbc\xba\xe6\x94\xb9\xe9\x9d\xa9\xe7\xb3\xbb\xe7\xbb\x9f\xe6\x80\xa7\xe3\x80\x81\xe6\x95\xb4\xe4\xbd\x93\xe6\x80\xa7\xe3\x80\x81\xe5\x8d\x8f\xe5\x90\x8c\xe6\x80\xa7\xef\xbc\x8c\xe5\x8e\x8b\xe8\x8c\xac\xe6\x8b\x93\xe5\xb1\x95\xe6\x94\xb9\xe9\x9d\xa9\xe5\xb9\xbf\xe5\xba\xa6\xe5\x92\x8c\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe6\x8e\xa8\xe5\x87\xba\xe4\xb8\x80\xe5\x8d\x83\xe4\xba\x94\xe7\x99\xbe\xe5\xa4\x9a\xe9\xa1\xb9\xe6\x94\xb9\xe9\x9d\xa9\xe4\xb8\xbe\xe6\x8e\xaa\xef\xbc\x8c\xe9\x87\x8d\xe8\xa6\x81\xe9\xa2\x86\xe5\x9f\x9f\xe5\x92\x8c\xe5\x85\xb3\xe9\x94\xae\xe7\x8e\xaf\xe8\x8a\x82\xe6\x94\xb9\xe9\x9d\xa9\xe5\x8f\x96\xe5\xbe\x97\xe7\xaa\x81\xe7\xa0\xb4\xe6\x80\xa7\xe8\xbf\x9b\xe5\xb1\x95\xef\xbc\x8c\xe4\xb8\xbb\xe8\xa6\x81\xe9\xa2\x86\xe5\x9f\x9f\xe6\x94\xb9\xe9\x9d\xa9\xe4\xb8\xbb\xe4\xbd\x93\xe6\xa1\x86\xe6\x9e\xb6\xe5\x9f\xba\xe6\x9c\xac\xe7\xa1\xae\xe7\xab\x8b\xe3\x80\x82\xe4\xb8\xad\xe5\x9b\xbd\xe7\x89\xb9\xe8\x89\xb2\xe7\xa4\xbe\xe4\xbc\x9a\xe4\xb8\xbb\xe4\xb9\x89\xe5\x88\xb6\xe5\xba\xa6\xe6\x9b\xb4\xe5\x8a\xa0\xe5\xae\x8c\xe5\x96\x84\xef\xbc\x8c\xe5\x9b\xbd\xe5\xae\xb6\xe6\xb2\xbb\xe7\x90\x86\xe4\xbd\x93\xe7\xb3\xbb\xe5\x92\x8c\xe6\xb2\xbb\xe7\x90\x86\xe8\x83\xbd\xe5\x8a\x9b\xe7\x8e\xb0\xe4\xbb\xa3\xe5\x8c\x96\xe6\xb0\xb4\xe5\xb9\xb3\xe6\x98\x8e\xe6\x98\xbe\xe6\x8f\x90\xe9\xab\x98\xef\xbc\x8c\xe5\x85\xa8\xe7\xa4\xbe\xe4\xbc\x9a\xe5\x8f\x91\xe5\xb1\x95\xe6\xb4\xbb\xe5\x8a\x9b\xe5\x92\x8c\xe5\x88\x9b\xe6\x96\xb0\xe6\xb4\xbb\xe5\x8a\x9b\xe6\x98\x8e\xe6\x98\xbe\xe5\xa2\x9e\xe5\xbc\xba\xe3\x80\x82\'\n\n    # txt =\'The information disclosed by the Film Funds Office of the State Administration of Press, Publication, Radio, Film and Television shows that, the total box office in China amounted to nearly 3 billion yuan during the first six days of the lunar year (February 8 - 13), an increase of 67% compared to the 1.797 billion yuan in the Chinese Spring Festival period in 2015, becoming the ""Best Chinese Spring Festival Period in History"".\' \\\n    #      \'During the Chinese Spring Festival period, ""The Mermaid"" contributed to a box office of 1.46 billion yuan. ""The Man From Macau III"" reached a box office of 680 million yuan. ""The Journey to the West: The Monkey King 2"" had a box office of 650 million yuan. ""Kung Fu Panda 3"" also had a box office of exceeding 130 million. These four blockbusters together contributed more than 95% of the total box office during the Chinese Spring Festival period.\' \\\n    #      \'There were many factors contributing to the popularity during the Chinese Spring Festival period. Apparently, the overall popular film market with good box office was driven by the emergence of a few blockbusters. In fact, apart from the appeal of the films, other factors like film ticket subsidy of online seat-selection companies, cinema channel sinking and the film-viewing heat in the middle and small cities driven by the home-returning wave were all main factors contributing to this blowout. A management of Shanghai Film Group told the 21st Century Business Herald.\'\n    print(txt)\n    print(""--"")\n    obj.summaryScoredtxt(txt)\n\n    print(""----"")\n    obj.summaryTopNtxt(txt)\n'"
docs/src/script.py,0,"b'# coding: utf-8\nimport os\nimport sys\n\n\ndef format_file(filename, str1, str2):\n    """"""\n    \xe6\x96\x87\xe4\xbb\xb6\xe5\x86\x85\xe5\xae\xb9\xe7\x9a\x84\xe6\x9b\xbf\xe6\x8d\xa2\xe5\x8a\x9f\xe8\x83\xbd\n    :return:\n    """"""\n    with open(filename, \'r\') as f:\n        var_object = f.read()\n        if ""gitalk"" not in var_object:\n            var_object = var_object.replace(str1, str2)\n        # print(var_object)\n\n    f = open(filename, ""w"")\n    f.write(var_object)\n\n\nif __name__ == ""__main__"":\n    u_type = sys.argv[1]\n    tag = True\n    if u_type == ""book"":\n        filename = ""book.json""\n        tag = False\n    elif u_type == ""powered"":\n        filename = ""node_modules/gitbook-plugin-tbfed-pagefooter/index.js""\n        str1 = ""powered by Gitbook""\n        str2 = ""\xe7\x94\xb1 ApacheCN \xe5\x9b\xa2\xe9\x98\x9f\xe6\x8f\x90\xe4\xbe\x9b\xe6\x94\xaf\xe6\x8c\x81""\n    elif u_type == ""gitalk"":\n        filename = ""node_modules/gitbook-plugin-tbfed-pagefooter/index.js""\n        str1 = """"""      var str = \' \\\\n\\\\n<footer class=""page-footer"">\' + _copy +\n        \'<span class=""footer-modification"">\' +\n        _label +\n        \'\\\\n{{file.mtime | date(""\' + _format +\n        \'"")}}\\\\n</span></footer>\'""""""\n\n        str2 = """"""\n      var str = \'\\\\n\\\\n\'+\n      \'\\\\n<hr/>\'+\n      \'\\\\n<div align=""center"">\'+\n      \'\\\\n    <p><a href=""http://www.apachecn.org"" target=""_blank""><font face=""KaiTi"" size=""6"" color=""red"">\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x80\xe7\x9b\xb4\xe5\x9c\xa8\xe5\x8a\xaa\xe5\x8a\x9b</font></a></p>\'+\n      \'\\\\n    <p><a href=""https://github.com/apachecn/nlp-pytorch-zh/"" target=""_blank"">apachecn/nlp-pytorch-zh</a></p>\'+\n      \'\\\\n    <p><iframe align=""middle"" src=""https://ghbtns.com/github-btn.html?user=apachecn&repo=nlp-pytorch-zh&type=watch&count=true&v=2"" frameborder=""0"" scrolling=""0"" width=""100px"" height=""25px""></iframe>\'+\n      \'\\\\n    <iframe align=""middle"" src=""https://ghbtns.com/github-btn.html?user=apachecn&repo=nlp-pytorch-zh&type=star&count=true"" frameborder=""0"" scrolling=""0"" width=""100px"" height=""25px""></iframe>\'+\n      \'\\\\n    <iframe align=""middle"" src=""https://ghbtns.com/github-btn.html?user=apachecn&repo=nlp-pytorch-zh&type=fork&count=true"" frameborder=""0"" scrolling=""0"" width=""100px"" height=""25px""></iframe>\'+\n      \'\\\\n    <a target=""_blank"" href=""//shang.qq.com/wpa/qunwpa?idkey=bcee938030cc9e1552deb3bd9617bbbf62d3ec1647e4b60d9cd6b6e8f78ddc03""><img border=""0"" src=""http://data.apachecn.org/img/logo/ApacheCN-group.png"" alt=""ML\xc2\xa0|\xc2\xa0ApacheCN"" title=""ML\xc2\xa0|\xc2\xa0ApacheCN""></a></p>\'+\n      \'\\\\n</div>\'+\n      \'\\\\n <div style=""text-align:center;margin:0 0 10.5px;"">\'+\n      \'\\\\n     <script async src=""//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js""></script>\'+\n      \'\\\\n     <ins class=""adsbygoogle""\'+\n      \'\\\\n         style=""display:inline-block;width:728px;height:90px""\'+\n      \'\\\\n         data-ad-client=""ca-pub-3565452474788507""\'+\n      \'\\\\n         data-ad-slot=""2543897000"">\'+\n      \'\\\\n     </ins>\'+\n      \'\\\\n     <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>\'+\n      \'\\\\n\'+\n      \'\\\\n    <script>\'+\n      \'\\\\n      var _hmt = _hmt || [];\'+\n      \'\\\\n      (function() {\'+\n      \'\\\\n        var hm = document.createElement(""script"");\'+\n      \'\\\\n        hm.src = ""https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91"";\'+\n      \'\\\\n        var s = document.getElementsByTagName(""script"")[0]; \'+\n      \'\\\\n        s.parentNode.insertBefore(hm, s);\'+\n      \'\\\\n      })();\'+\n      \'\\\\n    </script>\'+\n      \'\\\\n\'+\n     \'\\\\n</div>\'+\n      \'\\\\n\'+\n      \'\\\\n<meta name=""google-site-verification"" content=""pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo"" />\'+\n      \'\\\\n<iframe src=""https://www.bilibili.com/read/cv2710377"" style=""display:none""></iframe>\'+ \n      \'\\\\n<img src=""http://t.cn/AiCoDHwb"" hidden=""hidden"" />\'\n\n      str += \'\\\\n\\\\n\'+\n      \'\\\\n<div>\'+\n      \'\\\\n    <link rel=""stylesheet"" href=""https://unpkg.com/gitalk/dist/gitalk.css"">\'+\n      \'\\\\n    <script src=""https://unpkg.com/gitalk@latest/dist/gitalk.min.js""></script>\'+\n      \'\\\\n    <script src=""https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js""></script>\'+\n      \'\\\\n    <div id=""gitalk-container""></div>\'+\n      \'\\\\n    <script type=""text/javascript"">\'+\n      \'\\\\n        const gitalk = new Gitalk({\'+\n      \'\\\\n        clientID: \\\\\'1eba1fde838d39ce2ba9\\\\\',\'+\n      \'\\\\n        clientSecret: \\\\\'0bdf321e160ca29b2d54e8722700dd5accb084e0\\\\\',\'+\n      \'\\\\n        repo: \\\\\'nlp-pytorch-zh\\\\\',\'+\n      \'\\\\n        owner: \\\\\'apachecn\\\\\',\'+\n      \'\\\\n        admin: [\\\\\'jiangzhonglian\\\\\', \\\\\'wizardforcel\\\\\'],\'+\n      \'\\\\n        id: md5(location.pathname),\'+\n      \'\\\\n        distractionFreeMode: false\'+\n      \'\\\\n        })\'+\n      \'\\\\n        gitalk.render(\\\\\'gitalk-container\\\\\')\'+\n      \'\\\\n    </script>\'+\n      \'\\\\n</div>\'\n\n      str += \'\\\\n\\\\n<footer class=""page-footer"">\' + _copy + \'<span class=""footer-modification"">\' + _label + \'\\\\n{{file.mtime | date(""\' + _format + \'"")}}\\\\n</span></footer>\'\n        """"""\n\n    # \xe7\x8a\xb6\xe6\x80\x81\xe4\xb8\xba True \xe5\xb0\xb1\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x9b\xbf\xe6\x8d\xa2\n    if tag: format_file(filename, str1, str2)\n'"
src/1.set0bag-of-words/CountVectorizer.py,0,"b'# coding: utf-8\n\n""""""\n\xe8\xaf\x8d\xe9\x9b\x86\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe5\x8d\x95\xe8\xaf\x8d\xe6\x9e\x84\xe6\x88\x90\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\xef\xbc\x8c\xe9\x9b\x86\xe5\x90\x88\xe8\x87\xaa\xe7\x84\xb6\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe9\x83\xbd\xe5\x8f\xaa\xe6\x9c\x89\xe4\xb8\x80\xe4\xb8\xaa\xef\xbc\x8c\xe4\xb9\x9f\xe5\x8d\xb3\xe8\xaf\x8d\xe9\x9b\x86\xe4\xb8\xad\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x8d\x95\xe8\xaf\x8d\xe9\x83\xbd\xe5\x8f\xaa\xe6\x9c\x89\xe4\xb8\x80\xe4\xb8\xaa\n\xe8\xaf\x8d\xe8\xa2\x8b\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe5\x9c\xa8\xe8\xaf\x8d\xe9\x9b\x86\xe7\x9a\x84\xe5\x9f\xba\xe7\xa1\x80\xe4\xb8\x8a\xe5\xa6\x82\xe6\x9e\x9c\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8d\x95\xe8\xaf\x8d\xe5\x9c\xa8\xe6\x96\x87\xe6\xa1\xa3\xe4\xb8\xad\xe5\x87\xba\xe7\x8e\xb0\xe4\xb8\x8d\xe6\xad\xa2\xe4\xb8\x80\xe6\xac\xa1\xef\xbc\x8c\xe7\xbb\x9f\xe8\xae\xa1\xe5\x85\xb6\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\xef\xbc\x88\xe9\xa2\x91\xe6\x95\xb0\xef\xbc\x89\n""""""\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# \xe8\xaf\xad\xe6\x96\x99\ncorpus = [\n    \'This is the first document.\',\n    \'This is the second second document.\',\n    \'And the third one.\',\n    \'Is this the first document?\',\n]\n\n# \xe5\xb0\x86\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad\xe7\x9a\x84\xe8\xaf\x8d\xe8\xaf\xad\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe8\xaf\x8d\xe9\xa2\x91\xe7\x9f\xa9\xe9\x98\xb5\ncv = CountVectorizer(min_df=1)\n# \xe8\xae\xa1\xe7\xae\x97\xe4\xb8\xaa\xe8\xaf\x8d\xe8\xaf\xad\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\ncv_fit = cv.fit_transform(corpus)\n\n# set of words\xef\xbc\x88SOW\xef\xbc\x89 \xe8\xaf\x8d\xe9\x9b\x86\xe6\xa8\xa1\xe5\x9e\x8b - \xe8\x8e\xb7\xe5\x8f\x96\xe8\xaf\x8d\xe8\xa2\x8b\xe4\xb8\xad\xe6\x89\x80\xe6\x9c\x89\xe6\x96\x87\xe6\x9c\xac\xe5\x85\xb3\xe9\x94\xae\xe8\xaf\x8d\nprint(""\xe6\x89\x93\xe5\x8d\xb0\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe5\x90\x8d\xe7\xa7\xb0"")\nprint(cv.get_feature_names())\n\n# bag of words\xef\xbc\x88BOW\xef\xbc\x89 \xe8\xaf\x8d\xe8\xa2\x8b\xe6\xa8\xa1\xe5\x9e\x8b\nprint(""\xe6\x89\x93\xe5\x8d\xb0\xe6\x95\xb4\xe4\xb8\xaa\xe6\x96\x87\xe6\x9c\xac\xe7\x9f\xa9\xe9\x98\xb5"")\nprint(cv_fit.toarray())\nprint(""\xe6\x89\x93\xe5\x8d\xb0\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x88\x97\xe7\x9b\xb8\xe5\x8a\xa0"")\nprint(cv_fit.toarray().sum(axis=0))\nprint(""\xe6\x89\x93\xe5\x8d\xb0\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\xa1\x8c\xe7\x9b\xb8\xe5\x8a\xa0"")\nprint(cv_fit.toarray().sum(axis=1))\n'"
src/1.set0bag-of-words/Demo-ClassByLanguage-BOW-model.py,9,"b'# coding: utf-8\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ntorch.manual_seed(1)\n\n\ndata = [(""me gusta comer en la cafeteria"".split(), ""SPANISH""),\n        (""Give it to me"".split(), ""ENGLISH""),\n        (""No creo que sea una buena idea"".split(), ""SPANISH""),\n        (""No it is not a good idea to get lost at sea"".split(), ""ENGLISH"")]\n\ntest_data = [(""Yo creo que si"".split(), ""SPANISH""),\n             (""it is lost on me"".split(), ""ENGLISH"")]\n\nlabel_to_ix = {""SPANISH"": 0, ""ENGLISH"": 1}\n\n\n# word_to_ix \xe5\xb0\x86\xe8\xaf\x8d\xe6\xb1\x87\xe8\xa1\xa8\xe4\xb8\xad\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x8d\x95\xe8\xaf\x8d\xe6\x98\xa0\xe5\xb0\x84\xe5\x88\xb0\xe4\xb8\x80\xe4\xb8\xaa\xe5\x94\xaf\xe4\xb8\x80\xe7\x9a\x84\xe6\x95\xb4\xe6\x95\xb0\xef\xbc\x8c\xe8\xbf\x99\xe5\xb0\x86\xe6\x88\x90\xe4\xb8\xba\xe5\x8d\x95\xe8\xaf\x8d\xe5\x90\x91\xe9\x87\x8f\xe8\xa2\x8b\xe4\xb8\xad\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\nword_to_ix = {}\nfor sent, _ in data + test_data:\n    for word in sent:\n        if word not in word_to_ix:\n            word_to_ix[word] = len(word_to_ix)\nprint(""\xe6\x89\x93\xe5\x8d\xb0\xe8\xaf\x8d\xe6\xb1\x87\xe8\xa1\xa8: \\n"", word_to_ix)\n\n# \xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\nVOCAB_SIZE = len(word_to_ix)\n# \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\nNUM_LABELS = 2\n\n\n# \xe7\xbb\xa7\xe6\x89\xbf nn.Module\nclass BoWClassifier(nn.Module):\n\n    def __init__(self, num_labels, vocab_size):\n        # \xe8\xb0\x83\xe7\x94\xa8 nn.Module \xe7\x9a\x84 init \xe5\x87\xbd\xe6\x95\xb0\xe3\x80\x82 \xe4\xb8\x8d\xe8\xa6\x81\xe8\xa2\xab\xe8\xaf\xad\xe6\xb3\x95\xe6\xb7\xb7\xe6\xb7\x86\xef\xbc\x8c\xe5\x8f\xaa\xe6\x98\xaf\xe6\x80\xbb\xe6\x98\xaf\xe5\x9c\xa8 nn.Module \xe4\xb8\xad\xe5\x81\x9a\n        super(BoWClassifier, self).__init__()\n\n        # \xe5\xae\x9a\xe4\xb9\x89\xe6\x82\xa8\xe5\xb0\x86\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe3\x80\x82\n        # \xe5\x9c\xa8\xe8\xbf\x99\xe7\xa7\x8d\xe6\x83\x85\xe5\x86\xb5\xe4\xb8\x8b\xef\xbc\x8c\xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81A\xe5\x92\x8cb\xef\xbc\x8c\xe4\xbb\xbf\xe5\xb0\x84\xe6\x98\xa0\xe5\xb0\x84\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe3\x80\x82\n        # Torch\xe5\xae\x9a\xe4\xb9\x89\xe4\xba\x86nn.Linear()\xef\xbc\x8c\xe5\xae\x83\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86\xe4\xbb\xbf\xe5\xb0\x84\xe5\x9b\xbe\xe3\x80\x82\n        # \xe7\xa1\xae\xe4\xbf\x9d\xe4\xbd\xa0\xe6\x98\x8e\xe7\x99\xbd\xe4\xb8\xba\xe4\xbb\x80\xe4\xb9\x88\xe8\xbe\x93\xe5\x85\xa5\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf vocab_size\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x98\xaf num_labels\xef\xbc\x81\n        self.linear = nn.Linear(vocab_size, num_labels)\n\n        # NOTE! \xe9\x9d\x9e\xe7\xba\xbf\xe6\x80\xa7\xe6\x97\xa5\xe5\xbf\x97softmax\xe6\xb2\xa1\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x81 \xe6\x89\x80\xe4\xbb\xa5\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe4\xb8\xba\xe6\xad\xa4\xe6\x8b\x85\xe5\xbf\x83\n\n    def forward(self, bow_vec):\n        # \xe9\x80\x9a\xe8\xbf\x87\xe7\xba\xbf\xe6\x80\xa7\xe5\xb1\x82\xe4\xbc\xa0\xe9\x80\x92\xe8\xbe\x93\xe5\x85\xa5\xef\xbc\x8c\n        # \xe7\x84\xb6\xe5\x90\x8e\xe9\x80\x9a\xe8\xbf\x87 log_softmax \xe4\xbc\xa0\xe9\x80\x92\xe3\x80\x82\xef\xbc\x88\xe4\xbd\xbf\xe7\x94\xa8\xe5\xaf\xb9\xe6\x95\xb0\xe5\xbd\xa2\xe5\xbc\x8f\xe7\x9a\x84 softmax \xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x89\n        # \xe8\xae\xb8\xe5\xa4\x9a\xe9\x9d\x9e\xe7\xba\xbf\xe6\x80\xa7\xe5\x92\x8c\xe5\x85\xb6\xe4\xbb\x96\xe5\x8a\x9f\xe8\x83\xbd\xe5\x9c\xa8 torch.nn.functional \xe4\xb8\xad\n        # SVM\xe5\x8f\xaa\xe9\x80\x89\xe8\x87\xaa\xe5\xb7\xb1\xe5\x96\x9c\xe6\xac\xa2\xe7\x9a\x84\xe7\x94\xb7\xe7\xa5\x9e\xef\xbc\x8cSoftmax\xe6\x8a\x8a\xe6\x89\x80\xe6\x9c\x89\xe5\xa4\x87\xe8\x83\x8e\xe5\x85\xa8\xe9\x83\xa8\xe6\x8b\x89\xe5\x87\xba\xe6\x9d\xa5\xe8\xaf\x84\xe5\x88\x86\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe8\xbf\x98\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe4\xb8\x80\xe4\xb8\x8b\n        return F.log_softmax(self.linear(bow_vec), dim=1)\n\n\ndef make_bow_vector(sentence, word_to_ix):\n    vec = torch.zeros(len(word_to_ix))\n    for word in sentence:\n        vec[word_to_ix[word]] += 1\n    # \xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x89\xe7\x9b\xb8\xe5\x90\x8c\xe6\x95\xb0\xe6\x8d\xae\xe4\xbd\x86\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\x96\xb0\xe7\x9a\x84 tensor.\xef\xbc\x88 -1\xe8\xa1\xa8\xe7\xa4\xba\xe5\x85\xb6\xe4\xbb\x96\xe7\xbb\xb4\xe5\xba\xa6 \xef\xbc\x89\n    """"""\n    # -1 \xe8\xa1\xa8\xe7\xa4\xba\xe8\x87\xaa\xe5\xb7\xb1\xe4\xb8\x8d\xe7\xa1\xae\xe5\xae\x9a\xef\xbc\x8c\xe8\xae\xa9\xe7\xb3\xbb\xe7\xbb\x9f\xe6\x9d\xa5\xe8\xae\xa1\xe7\xae\x97\n    y = x.view(4, 2)\n    print y\n\n    # \xe8\xbe\x93\xe5\x87\xba\xe5\xa6\x82\xe4\xb8\x8b\n    1.5600 -1.6180\n    -2.0366  2.7115\n    0.8415 -1.0103\n    -0.4793  1.5734\n    [torch.FloatTensor of size 4x2]\n    """"""\n    return vec.view(1, -1)\n\n\ndef make_target(label, label_to_ix):\n    return torch.LongTensor([label_to_ix[label]])\n\n\nmodel = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9f\xa5\xe9\x81\x93\xe5\xae\x83\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe3\x80\x82 \xe4\xb8\x8b\xe9\x9d\xa2\xe7\x9a\x84\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbe\x93\xe5\x87\xba\xe6\x98\xafA\xef\xbc\x8c\xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe8\xbe\x93\xe5\x87\xba\xe6\x98\xafb\xe3\x80\x82\n# \xe5\x8f\xaa\xe8\xa6\x81\xe4\xbd\xa0\xe5\x9c\xa8\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9d\x97\xe7\x9a\x84 __init__ \xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe5\xb0\x86\xe4\xb8\x80\xe4\xb8\xaa\xe7\xbb\x84\xe4\xbb\xb6\xe5\x88\x86\xe9\x85\x8d\xe7\xbb\x99\xe4\xb8\x80\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x8f\x98\xe9\x87\x8f\xef\xbc\x8c\xe8\xbf\x99\xe6\x98\xaf\xe9\x80\x9a\xe8\xbf\x87\xe8\xaf\xa5\xe8\xa1\x8c\xe5\xae\x8c\xe6\x88\x90\xe7\x9a\x84\n# self.linear = nn.Linear\xef\xbc\x88...\xef\xbc\x89\n# \xe7\x84\xb6\xe5\x90\x8e\xe9\x80\x9a\xe8\xbf\x87 Pytorch \xe5\xbc\x80\xe5\x8f\x91\xe8\x80\x85\xe7\x9a\x84\xe4\xb8\x80\xe4\xba\x9b Python \xe9\xad\x94\xe6\xb3\x95\xef\xbc\x8c\xe4\xbd\xa0\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9d\x97\xef\xbc\x88\xe5\x9c\xa8\xe8\xbf\x99\xe7\xa7\x8d\xe6\x83\x85\xe5\x86\xb5\xe4\xb8\x8b\xef\xbc\x8cBoWClassifier\xef\xbc\x89\xe5\xb0\x86\xe5\xad\x98\xe5\x82\xa8\xe5\x85\xb3\xe4\xba\x8e nn.Linear \xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\x9f\xa5\xe8\xaf\x86\n# for param in model.parameters():\n#     print(""\\n parameters \xe5\x8f\x82\xe6\x95\xb0\xe6\x9c\x89: \\n"", param)\n\n# \xe8\xa6\x81\xe8\xbf\x90\xe8\xa1\x8c\xe8\xaf\xa5\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe4\xbc\xa0\xe5\x85\xa5\xe4\xb8\x80\xe4\xb8\xaaBoW variable\xef\xbc\x8c\xe4\xbd\x86\xe5\x8c\x85\xe8\xa3\xb9\xe5\x9c\xa8\xe4\xb8\x80\xe4\xb8\xaa autograd.Variable \xe4\xb8\xad\nsample = data[0]\n# \xe5\xb0\x86\xe6\x96\x87\xe6\x9c\xac\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba Variable \xe5\xaf\xb9\xe8\xb1\xa1\nbow_vector = make_bow_vector(sample[0], word_to_ix)\nprint(""bow_vector: \\n"", bow_vector)\nlog_probs = model(autograd.Variable(bow_vector))\n# \xe5\xb0\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xbb\x8e x \xe2\x87\x92 log (x)\xef\xbc\x8c\xe6\x97\xa0\xe7\x96\x91\xe4\xbc\x9a\xe5\xb0\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x80\xbc\xe5\x9f\x9f\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xb8\x80\xe5\xae\x9a\xe7\x9a\x84\xe6\x94\xb6\xe7\xbc\xa9\xe3\x80\x82\n""""""lable\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe4\xb8\x8b\xe6\x89\x80\xe6\x9c\x89\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\xef\xbc\x88\xe4\xb8\x8b\xe9\x9d\xa2\xe4\xb8\xba: SPANISH \xe5\x92\x8c ENGLISH \xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\xe5\x88\x86\xe5\xb8\x83-\xe6\x9a\x82\xe6\x97\xb6\xe8\xbf\x98\xe6\xb2\xa1\xe6\x9c\x89\xe5\xae\x9a\xe4\xb9\x89\xe5\x85\x88\xe5\x90\x8e\xe9\xa1\xba\xe5\xba\x8f\xef\xbc\x8c\xe9\xbb\x98\xe8\xae\xa4\xe6\x98\xaf\xe5\xad\x97\xe6\xaf\x8d\xef\xbc\x9f\xef\xbc\x89\nVariable containing:\n-0.8195 -0.5810\n""""""\nprint(log_probs)\n\n\n# # \xe5\x9c\xa8\xe6\x88\x91\xe4\xbb\xac\xe8\xae\xad\xe7\xbb\x83\xe4\xb9\x8b\xe5\x89\x8d\xe8\xbf\x90\xe8\xa1\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\x8f\xaa\xe6\x98\xaf\xe4\xb8\xba\xe4\xba\x86\xe7\x9c\x8b\xe5\x88\xb0\xe5\x89\x8d\xe5\x90\x8e\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\n# for instance, label in test_data:\n#     bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n#     log_probs = model(bow_vec)\n#     print(""\xe8\xae\xad\xe7\xbb\x83\xe5\x89\x8d ---: \\n"", log_probs)\n\n# # \xe6\x89\x93\xe5\x8d\xb0\xe5\xaf\xb9\xe5\xba\x94\xe4\xba\x8e ""creo"" \xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe5\x88\x97\xe7\x9a\x84\xe8\xae\xa1\xe7\xae\x97\xe5\x80\xbc\xef\xbc\x8c\xe7\x94\xa8\xe4\xba\x8e\xe5\xaf\xb9\xe6\xaf\x94\xe8\xae\xad\xe7\xbb\x83\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\x98\xe5\x8c\x96\n# print(\'model.parameters(): \\n\', next(model.parameters())[:, word_to_ix[""creo""]])\n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nloss_function = nn.NLLLoss()\n\n# \xe9\x80\x9a\xe5\xb8\xb8\xe4\xbd\xa0\xe6\x83\xb3\xe5\xa4\x9a\xe6\xac\xa1\xe4\xbc\xa0\xe9\x80\x92\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\n# 100\xe6\xaf\x94\xe5\xae\x9e\xe9\x99\x85\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xa4\xa7\xe5\xbe\x97\xe5\xa4\x9a\xef\xbc\x8c\xe4\xbd\x86\xe7\x9c\x9f\xe6\xad\xa3\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8d\xe6\xad\xa2\n# \xe4\xb8\xa4\xe4\xb8\xaa\xe5\xae\x9e\xe4\xbe\x8b\xe3\x80\x82\xe9\x80\x9a\xe5\xb8\xb8\xef\xbc\x8c5\xe8\x87\xb330\xe4\xb8\xaa\xe6\x97\xb6\xe6\x9c\x9f\xe6\x98\xaf\xe5\x90\x88\xe7\x90\x86\xe7\x9a\x84\xe3\x80\x82\nfor epoch in range(100):\n    for instance, label in data:\n        # \xe6\xad\xa5\xe9\xaa\xa41.\n        # \xe8\xaf\xb7\xe8\xae\xb0\xe4\xbd\x8f\xef\xbc\x8cPytorch\xe4\xbc\x9a\xe7\xb4\xaf\xe7\xa7\xaf\xe6\xb8\x90\xe5\x8f\x98\xe3\x80\x82\n        # \xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe5\x9c\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe5\xae\x9e\xe4\xbe\x8b\xe4\xb9\x8b\xe5\x89\x8d\xe6\xb8\x85\xe9\x99\xa4\xe5\xae\x83\xe4\xbb\xac\n        model.zero_grad()\n\n        # \xe7\xac\xac2\xe6\xad\xa5.\n        # \xe5\x88\xb6\xe4\xbd\x9c\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84BOW\xe7\x9f\xa2\xe9\x87\x8f\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x94\xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x98\xe5\xbf\x85\xe9\xa1\xbb\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8c\x85\xe8\xa3\x85\xe5\x9c\xa8\xe4\xb8\x80\xe4\xb8\xaa\n        # \xe4\xbd\x9c\xe4\xb8\xba\xe6\x95\xb4\xe6\x95\xb0\xe5\x8f\x98\xe9\x87\x8f\n        # \xe4\xbe\x8b\xe5\xa6\x82: \xe5\xa6\x82\xe6\x9e\x9c\xe7\x9b\xae\xe6\xa0\x87\xe6\x98\xaf\xe8\xa5\xbf\xe7\x8f\xad\xe7\x89\x99\xe8\xaf\xad\xef\xbc\x8c\xe9\x82\xa3\xe4\xb9\x88\xe6\x88\x91\xe4\xbb\xac\xe5\x8c\x85\xe8\xa3\x85\xe6\x95\xb4\xe6\x95\xb00.\n        # \xe7\x84\xb6\xe5\x90\x8e\xef\xbc\x8c\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\xe7\x9f\xa5\xe9\x81\x93\xe6\x97\xa5\xe5\xbf\x97\xe6\xa6\x82\xe7\x8e\x87\xe7\x9a\x84\xe7\xac\xac0\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe6\x98\xaf\xe5\xaf\xb9\xe5\xba\x94\xe4\xba\x8e\xe8\xa5\xbf\xe7\x8f\xad\xe7\x89\x99\xe8\xaf\xad\xe7\x9a\x84\xe6\x97\xa5\xe5\xbf\x97\xe6\xa6\x82\xe7\x8e\x87\n        bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n        target = autograd.Variable(make_target(label, label_to_ix))\n\n        # \xe7\xac\xac3\xe6\xad\xa5.\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\n        log_probs = model(bow_vec)\n\n        # \xe7\xac\xac4\xe6\xad\xa5.\n        # \xe9\x80\x9a\xe8\xbf\x87\xe8\xb0\x83\xe7\x94\xa8optimizer.step\xef\xbc\x88\xef\xbc\x89\xe6\x9d\xa5\xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\xef\xbc\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe5\x92\x8c\xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\n        loss = loss_function(log_probs, target)\n        loss.backward()\n        optimizer.step()\n\nfor instance, label in test_data:\n    bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n    log_probs = model(bow_vec)\n    print(""\xe8\xae\xad\xe7\xbb\x83\xe5\x90\x8e ---: \\n"", log_probs)\n\n# Index corresponding to Spanish goes up, English goes down!\nprint(next(model.parameters())[:, word_to_ix[""creo""]])\n'"
src/17.LSTM/Problem2FunctionTest.py,0,"b'#!/usr/bin/python\r\n# encoding: utf-8\r\n\r\nimport math\r\nimport numpy\r\nimport matplotlib.pyplot as plt\r\nfrom pandas import read_csv\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense\r\nfrom keras.layers import LSTM\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nfrom sklearn.metrics import mean_squared_error\r\nfrom sklearn.externals import joblib\r\nfrom keras.models import load_model\r\n\r\n# \xe5\xa6\x82\xe6\x9e\x9c\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84seed()\xe5\x80\xbc\xef\xbc\x8c\xe5\x88\x99\xe6\xaf\x8f\xe6\xac\xa1\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe9\x9a\x8f\xe5\x8d\xb3\xe6\x95\xb0\xe9\x83\xbd\xe7\x9b\xb8\xe5\x90\x8c\xef\xbc\x9b\r\nnumpy.random.seed(7)\r\n\r\n\r\ndef load_data():\r\n    # \xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\r\n    dataframe = read_csv(\'sp5001.csv\', header=0, names=[\'\xe4\xbb\xb7\xe6\xa0\xbc\'], usecols=[1], engine=\'python\', skipfooter=3)\r\n    dataset = dataframe.values\r\n    # print(\'dataset=\', dataset)\r\n    # \xe5\xb0\x86\xe6\x95\xb4\xe5\x9e\x8b\xe5\x8f\x98\xe4\xb8\xbafloat\r\n    dataset = dataset.astype(\'float32\')\r\n    return dataset\r\n\r\n\r\n# X is the number of passengers at a given time (t) and Y is the number of passengers at the next time (t + 1).\r\n# look_back \xe8\xa1\xa8\xe7\xa4\xba \xe6\x97\xb6\xe9\x97\xb4\xe7\x9a\x84\xe6\xad\xa5\xe9\x95\xbf\xe4\xb8\xba 1; \xe5\xb0\x86\xe6\x95\xb0\xe7\xbb\x84\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe7\x9f\xa9\xe9\x98\xb5\r\ndef create_dataset(dataset, look_back=1):\r\n    dataX, dataY = [], []\r\n    for i in range(len(dataset) - look_back - 1):\r\n        dataX.append(dataset[i:(i + look_back), 0])\r\n        dataY.append(dataset[i + look_back, 0])\r\n    return numpy.array(dataX), numpy.array(dataY)\r\n\r\n\r\ndef splitData(dataset, look_back):\r\n    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\r\n    # \xe4\xbc\x98\xe5\x8c\x96\xe7\x82\xb9\xef\xbc\x9a\xe7\x94\xa8\xe6\xba\x90\xe6\x95\xb0\xe6\x8d\xae/\xe8\xbf\x98\xe6\x98\xaf\xe7\x94\xa8\xe5\xa2\x9e\xe9\x95\xbf\xe7\x9a\x84\xe5\x80\xbc\r\n    scaler = MinMaxScaler(feature_range=(0, 1))\r\n    dataset = scaler.fit_transform(dataset)\r\n\r\n    # \xe6\x8b\x86\xe5\x88\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x88\xe5\x8f\xaf\xe4\xbb\xbb\xe6\x84\x8f\xe8\xb0\x83\xe6\x95\xb4\xe6\xaf\x94\xe4\xbe\x8b\xef\xbc\x89\r\n    train_size = int(len(dataset) * 0.8)\r\n    train, test = dataset[0:train_size, :], dataset[train_size:, :]\r\n\r\n    # \xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\r\n    trainX, trainY = create_dataset(train, look_back)\r\n    testX, testY = create_dataset(test, look_back)\r\n    print(""dataX=%s \\n dataY=%s"" % (trainX.T, trainY.T))\r\n\r\n    # reshape input to be [samples, time steps, features]\r\n    trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\r\n    testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\r\n    return dataset, scaler, trainX, trainY, testX, testY\r\n\r\n\r\ndef getModel(trainX, trainY, look_back):\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\xb9\xb6\xe6\x8b\x9f\xe5\x90\x88 LSTM \xe7\xbd\x91\xe7\xbb\x9c\r\n    model = Sequential()\r\n    model.add(LSTM(4, input_shape=(1, look_back)))\r\n    model.add(Dense(1))\r\n    model.compile(loss=\'mean_squared_error\', optimizer=\'adam\')\r\n    model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\r\n    return model\r\n\r\n\r\ndef trainModel(look_back=1):\r\n    # \xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\r\n    dataset = load_data()\r\n    # \xe5\x88\x86\xe6\x9e\x90\xe6\x95\xb0\xe6\x8d\xae\r\n    # plt.plot(dataset)\r\n    # plt.show()\r\n\r\n    # \xe6\x8b\x86\xe5\x88\x86\xe6\x95\xb0\xe6\x8d\xae\xe6\x9c\xba\r\n    dataset, scaler, trainX, trainY, testX, testY = splitData(dataset, look_back)\r\n    joblib.dump(dataset, ""dataset.data"")\r\n    joblib.dump(trainX, ""trainX.data"")\r\n    joblib.dump(trainY, ""trainY.data"")\r\n    joblib.dump(testX, ""testX.data"")\r\n    joblib.dump(testY, ""testY.data"")\r\n    joblib.dump(testY, ""testY.data"")\r\n    joblib.dump(scaler, ""scaler.clf"")\r\n\r\n    # \xe8\x8e\xb7\xe5\x8f\x96\xe6\xa8\xa1\xe5\x9e\x8b\r\n    model = getModel(trainX, trainY, look_back)\r\n    return model\r\n\r\n\r\nif __name__ == ""__main__"":\r\n\r\n    # look_back \xe6\x97\xb6\xe9\x97\xb4\xe7\x9a\x84\xe6\xb3\xa2\xe5\x8a\xa8\xe5\x8c\xba\xe9\x97\xb4\xef\xbc\x881\xe5\xa4\xa9/7\xe5\xa4\xa9/1\xe4\xb8\xaa\xe6\x9c\x88/1\xe5\xb9\xb4\xef\xbc\x9f\xef\xbc\x9f\xef\xbc\x89\r\n    look_back = 1\r\n\r\n    # # \xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\r\n    # model = trainModel(look_back)\r\n    # # \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\r\n    # model.save(\'my_model.h5\')\r\n    # del model\r\n\r\n\r\n    # \xe5\x8a\xa0\xe8\xbd\xbd\xe6\xa8\xa1\xe5\x9e\x8b\r\n    model = load_model(\'my_model.h5\')\r\n    # \xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\r\n    dataset = joblib.load(""dataset.data"")\r\n    trainX = joblib.load(""trainX.data"")\r\n    trainY = joblib.load(""trainY.data"")\r\n    testX = joblib.load(""testX.data"")\r\n    testY = joblib.load(""testY.data"")\r\n    scaler = joblib.load(""scaler.clf"")\r\n\r\n    # make predictions\r\n    trainPredict = model.predict(trainX)\r\n    testPredict = model.predict(testX)\r\n\r\n    # invert predictions\r\n    trainPredict = scaler.inverse_transform(trainPredict)\r\n    trainY = scaler.inverse_transform([trainY])\r\n    testPredict = scaler.inverse_transform(testPredict)\r\n    testY = scaler.inverse_transform([testY])\r\n\r\n    # # \xe6\xa8\xa1\xe5\x9e\x8b\xe8\xaf\x84\xe4\xbc\xb0\r\n    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:, 0]))\r\n    print(\'Train Score: %.2f RMSE\' % (trainScore))\r\n    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:, 0]))\r\n    print(\'Test Score: %.2f RMSE\' % (testScore))\r\n\r\n    # shift train predictions for plotting\r\n    # 1. empty_like \xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x80\xe4\xb8\xaa\xe5\x92\x8c dataset \xe7\x9b\xb8\xe4\xbc\xbc\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe7\x9f\xa9\xe9\x98\xb5\r\n    # 2. \xe7\xbd\xae\xe7\xa9\xba\r\n    # 3. \xe8\xb5\x8b\xe5\x80\xbc\r\n    trainPredictPlot = numpy.empty_like(dataset)\r\n    trainPredictPlot[:, :] = numpy.nan\r\n    trainPredictPlot[look_back: len(trainPredict)+look_back, :] = trainPredict\r\n\r\n    # shift test predictions for plotting\r\n    testPredictPlot = numpy.empty_like(dataset)\r\n    testPredictPlot[:, :] = numpy.nan\r\n    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\r\n\r\n    # plot baseline and predictions\r\n    plt.plot(scaler.inverse_transform(dataset))\r\n    plt.plot(trainPredictPlot)\r\n    plt.plot(testPredictPlot)\r\n    plt.show()\r\n'"
src/17.LSTM/test.py,0,"b'from sklearn.externals import joblib\nfrom sklearn import svm\n\nX = [[0, 0], [1, 1]]\ny = [0, 1]\nclf = svm.SVC()\nclf.fit(X, y)  \njoblib.dump(clf, ""train_model.m"")\n# clf = joblib.load(""train_model.m"")\n# clf.predit(X) # \xe6\xad\xa4\xe5\xa4\x84test_X\xe4\xb8\xba\xe7\x89\xb9\xe5\xbe\x81\xe9\x9b\x86'"
src/17.LSTM/test1.py,0,"b""#!/usr/bin/python\n# encoding: utf-8\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sqrt\nimport matplotlib\n# be able to save images on server\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\n\n\n# date-time parsing function for loading the dataset\ndef parser(x):\n    return pd.datetime.strptime('190' + x, '%Y-%m')\n\n\n# frame a sequence as a supervised learning problem\ndef timeSeries_to_supervised(data, lag=1):\n\n    # \xe5\xb0\x86 Series \xe8\xbd\xac\xe5\x9d\x8f\xe4\xb8\xba DataFrame \xe7\xb1\xbb\xe5\x9e\x8b\n    df = pd.DataFrame(data)\n    # print('1=' * 10, data.head(5))\n    # print('2=' * 10, df.head(5))\n\n    # shift \xe8\xa1\x8c\xe5\x9d\x90\xe6\xa0\x87\xef\xbc\x8c\xe5\x90\x91\xe4\xb8\x8b\xe7\xa7\xbb\xe5\x8a\xa8\xe4\xb8\x80\xe4\xbd\x8d\n    columns = [df.shift(i) for i in range(1, lag + 1)]\n    # print('0='*10, columns)\n    # print('3='*10, columns[0].head(5))\n    \n    '''\n    # copy \xe4\xb8\x80\xe5\x88\x97\xe5\x8f\x982\xe5\x88\x97\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x94\xe7\xac\xac\xe4\xb8\x80\xe5\x88\x97\xe5\x90\x91\xe4\xb8\x8b\xe7\xa7\xbb\xe5\x8a\xa8\xe4\xb8\x80\xe4\xbd\x8d\n    0\t NaN -120.1\n    1  -120.1   37.2\n    2\t37.2  -63.8\n    3   -63.8   61.0\n    4\t61.0  -11.8\n    '''\n    columns.append(df)\n    df = pd.concat(columns, axis=1)\n    # print('0='*10, columns)\n    # print('1='*10, df)\n    return df\n\n\n# create a differenced pd.Series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return pd.Series(diff)\n\n\n# invert differenced value\ndef inverse_difference(history, yhat, interval=1):\n    return yhat + history[-interval]\n\n\n# scale train and test data to [-1, 1]\n# \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\x8e\x8b\xe7\xbc\xa9\xe5\x88\xb0 [-1, 1] \xe4\xb9\x8b\xe9\x97\xb4\ndef scale(train, test):\n    # fit scaler\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    scaler = scaler.fit(train)\n    # transform train\n    train = train.reshape(train.shape[0], train.shape[1])\n    train_scaled = scaler.transform(train)\n    # transform test\n    test = test.reshape(test.shape[0], test.shape[1])\n    test_scaled = scaler.transform(test)\n    return scaler, train_scaled, test_scaled\n\n\n# inverse scaling for a forecasted value\ndef invert_scale(scaler, X, yhat):\n    new_row = [x for x in X] + [yhat]\n    array = np.array(new_row)\n    array = array.reshape(1, len(array))\n    inverted = scaler.inverse_transform(array)\n    return inverted[0, -1]\n\n\n# fit an LSTM network to training data\n# n_batch\n# nb_epoch\n# n_neurons \xe7\xa5\x9e\xe7\xbb\x8f\xe5\x85\x83\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\ndef fit_lstm(train, n_batch, nb_epoch, n_neurons):\n    X, y = train[:, 0:-1], train[:, -1]\n    X = X.reshape(X.shape[0], 1, X.shape[1])\n    print('x=', X)\n    model = Sequential()\n    # https://keras.io/layers/recurrent/#lstm\n    # \n    model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    for i in range(nb_epoch):\n        model.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n        model.reset_states()\n    return model\n\n\n# run a repeated experiment\ndef experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons):\n    # transform data to be stationary\n\n    # \xe8\x8e\xb7\xe5\x8f\x96 trainY \xe7\x9a\x84\xe5\x80\xbc \xe5\x92\x8c \xe5\x89\x8d\xe5\x90\x8e\xe7\x9a\x84\xe5\xb7\xae\xe5\x80\xbc\n    raw_values = series.values\n    diff_values = difference(raw_values, 1)\n    print('=' * 10, raw_values[:5])\n    print('=' * 10, diff_values.head(5).values)\n\n    # \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe7\x9b\x91\xe7\x9d\xa3\xe5\xad\xa6\xe4\xb9\xa0\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe6\x97\xb6\xe9\x97\xb4\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\x89\x8d\xe5\x90\x8e\xe5\x85\xb3\xe7\xb3\xbb\xef\xbc\x88\xe5\x89\x8d\xe4\xb8\x80\xe5\xa4\xa9 \xe9\xa2\x84\xe6\xb5\x8b \xe5\x90\x8e\xe4\xb8\x80\xe5\xa4\xa9\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x89\n    # \xe5\x89\x94\xe9\x99\xa4 n_lag \xe4\xb9\x8b\xe5\x89\x8d\xe7\x9a\x84 None \xe7\x9a\x84\xe5\x80\xbc\n    supervised = timeSeries_to_supervised(diff_values, n_lag)\n    supervised_values = supervised.values[n_lag:, :]\n    print('=' * 10, supervised_values[:5])\n\n    # \xe5\x88\x86\xe7\xa6\xbb \xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\n    train, test = supervised_values[0:-12], supervised_values[-12:]\n\n    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\x8e\x8b\xe7\xbc\xa9\xe5\x88\xb0 [-1, 1] \xe4\xb9\x8b\xe9\x97\xb4\n    scaler, train_scaled, test_scaled = scale(train, test)\n    # run experiment\n    error_scores = list()\n    for r in range(n_repeats):\n        # fit the model\n        train_trimmed = train_scaled[2:, :]\n        lstm_model = fit_lstm(train_trimmed, n_batch, n_epochs, n_neurons)\n        # forecast test dataset\n        test_reshaped = test_scaled[:, 0:-1]\n        test_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n        output = lstm_model.predict(test_reshaped, batch_size=n_batch)\n        predictions = list()\n        for i in range(len(output)):\n            yhat = output[i, 0]\n            X = test_scaled[i, 0:-1]\n            # invert scaling\n            yhat = invert_scale(scaler, X, yhat)\n            # invert differencing\n            yhat = inverse_difference(raw_values, yhat,\n                                      len(test_scaled) + 1 - i)\n            # store forecast\n            predictions.append(yhat)\n        # report performance\n        rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n        print('%d) Test RMSE: %.3f' % (r + 1, rmse))\n        error_scores.append(rmse)\n    return error_scores\n\n\n# configure the experiment\ndef run():\n    # load dataset\n    series = pd.read_csv(\n        'shampoo-sales.csv',\n        header=0,\n        parse_dates=[0],\n        index_col=0,\n        squeeze=True,\n        date_parser=parser)\n    print(series.head(5))\n    print(np.shape(series))\n\n    # n_lag \xe8\xa1\xa8\xe7\xa4\xba\xe6\x97\xb6\xe9\x97\xb4\xe7\xaa\x97\xe5\x8f\xa3\xef\xbc\x88\xe4\xb8\x8a\xe4\xb8\x8b/\xe5\xb7\xa6\xe5\x8f\xb3\xef\xbc\x89\xe7\xa7\xbb\xe5\x8a\xa8\xe7\x9a\x84\xe5\xb9\x85\xe5\xba\xa6\n    n_lag = 1\n    # \xe5\xbe\xaa\xe7\x8e\xaf\xe9\x81\x8d\xe5\x8e\x86\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\n    n_repeats = 2\n    n_epochs = 1000\n    n_batch = 4\n    n_neurons = 3\n    # run the experiment\n    results = pd.DataFrame()\n    results['results'] = experiment(series, n_lag, n_repeats, n_epochs,\n                                    n_batch, n_neurons)\n    # summarize results\n    print(results.describe())\n    # save boxplot\n    results.boxplot()\n    plt.savefig('experiment_baseline.png')\n\n# entry point\n\n\nrun()\n"""
src/2.tf-idf/TF-IDF.py,0,"b'# coding: utf-8\n\n""""""\nTF-IDF \xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\n\xe4\xb8\xbb\xe8\xa6\x81\xe6\x80\x9d\xe6\x83\xb3\xe6\x98\xaf\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x9f\x90\xe4\xb8\xaa\xe8\xaf\x8d\xe6\x88\x96\xe7\x9f\xad\xe8\xaf\xad\xe5\x9c\xa8\xe4\xb8\x80\xe7\xaf\x87\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\xad\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe9\xa2\x91\xe7\x8e\x87TF(Term Frequency\xef\xbc\x8c\xe8\xaf\x8d\xe9\xa2\x91)\xef\xbc\x8c\xe8\xaf\x8d\xe9\xa2\x91\xe9\xab\x98\xef\xbc\x8c\n    \xe5\xb9\xb6\xe4\xb8\x94\xe5\x9c\xa8\xe5\x85\xb6\xe4\xbb\x96\xe6\x96\x87\xe7\xab\xa0\xe4\xb8\xad\xe5\xbe\x88\xe5\xb0\x91\xe5\x87\xba\xe7\x8e\xb0\xef\xbc\x8c\xe5\x88\x99\xe8\xae\xa4\xe4\xb8\xba\xe6\xad\xa4\xe8\xaf\x8d\xe6\x88\x96\xe8\x80\x85\xe7\x9f\xad\xe8\xaf\xad\xe5\x85\xb7\xe6\x9c\x89\xe5\xbe\x88\xe5\xa5\xbd\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x8c\xba\xe5\x88\x86\xe8\x83\xbd\xe5\x8a\x9b\xef\xbc\x8c\xe9\x80\x82\xe5\x90\x88\xe7\x94\xa8\xe6\x9d\xa5\xe5\x88\x86\xe7\xb1\xbb\xe3\x80\x82\n\n\xe5\x85\xac\xe5\xbc\x8f\xef\xbc\x9a\n* TF-IDF = TF * IDF\n* TF(t) = (\xe8\xaf\x8dt\xe5\x9c\xa8\xe6\x96\x87\xe6\xa1\xa3\xe4\xb8\xad\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe6\x80\xbb\xe6\xac\xa1\xe6\x95\xb0) / (\xe6\x96\x87\xe6\xa1\xa3\xe7\x9a\x84\xe8\xaf\x8d\xe6\x80\xbb\xe6\x95\xb0)\n* IDF = log_e(\xe6\x80\xbb\xe6\x96\x87\xe6\xa1\xa3\xe6\x95\xb0/\xe8\xaf\x8dt\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe6\x96\x87\xe6\xa1\xa3\xe6\x95\xb0)\n""""""\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# \xe8\xaf\xad\xe6\x96\x99\ncorpus = [\n    \'This is the first document.\',\n    \'This is the second second document.\',\n    \'And the third one.\',\n    \'Is this the first document?\',\n]\n\n""""""\n\xe8\xae\xa1\xe7\xae\x97\xe6\x96\xb9\xe5\xbc\x8f1: \xe9\x80\x9a\xe8\xbf\x87\xe6\x89\x8b\xe5\x8a\xa8\xe7\x9a\x84\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xa1\xe7\xae\x97\xe8\xaf\x8d\xe9\xa2\x91\n""""""\n# \xe5\xb0\x86\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad\xe7\x9a\x84\xe8\xaf\x8d\xe8\xaf\xad\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe8\xaf\x8d\xe9\xa2\x91\xe7\x9f\xa9\xe9\x98\xb5\ncv = CountVectorizer(min_df=1)\n# \xe8\xae\xa1\xe7\xae\x97\xe4\xb8\xaa\xe8\xaf\x8d\xe8\xaf\xad\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\ncv_fit = cv.fit_transform(corpus)\nprint(""bag of words\xef\xbc\x88BOW\xef\xbc\x89 \xe8\xaf\x8d\xe8\xa2\x8b\xe6\xa8\xa1\xe5\x9e\x8b"")\nprint(cv_fit.toarray())\n\nprint(""\\n"", ""---"" * 10, ""\\n"")\n\n# \xe8\xae\xa1\xe7\xae\x97 IF-IDF\xe7\x9a\x84\xe5\x80\xbc\ntransformer = TfidfTransformer()\n# \xe5\xb0\x86\xe8\xaf\x8d\xe9\xa2\x91\xe7\x9f\xa9\xe9\x98\xb5 cv_fit \xe7\xbb\x9f\xe8\xae\xa1\xe6\x88\x90 TF-IDF \xe5\x80\xbc\ntfidf = transformer.fit_transform(cv_fit)\n# \xe6\x9f\xa5\xe7\x9c\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84 tfidf[i][j] \xe8\xa1\xa8\xe7\xa4\xbai\xe7\xb1\xbb\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad tf-idf \xe6\x9d\x83\xe9\x87\x8d\nprint(""TF-IDF \xe6\xa8\xa1\xe5\x9e\x8b"")\nprint(tfidf.toarray())\n\n\nprint(""\\n"", ""---"" * 10, ""\\n"")\n""""""\n\xe8\xae\xa1\xe7\xae\x97\xe6\x96\xb9\xe5\xbc\x8f2: \xe7\x9b\xb4\xe6\x8e\xa5\xe9\x80\x9a\xe8\xbf\x87 \xe6\x96\x87\xe6\x9c\xac\xe8\xaf\x8d\xe6\x96\x99 \xe6\x9d\xa5\xe8\xae\xa1\xe7\xae\x97\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad tf-idf \xe6\x9d\x83\xe9\x87\x8d\n""""""\n# \xe8\xae\xa1\xe7\xae\x97 IF-IDF\xe7\x9a\x84\xe5\x80\xbc\ntransformer = TfidfVectorizer()\n# \xe5\xb0\x86\xe8\xaf\x8d\xe9\xa2\x91\xe7\x9f\xa9\xe9\x98\xb5 cv \xe7\xbb\x9f\xe8\xae\xa1\xe6\x88\x90 TF-IDF \xe5\x80\xbc\ntfidf = transformer.fit_transform(corpus)\n# \xe6\x9f\xa5\xe7\x9c\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84 tfidf[i][j] \xe8\xa1\xa8\xe7\xa4\xbai\xe7\xb1\xbb\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad\xe7\x9a\x84 tf-idf \xe6\x9d\x83\xe9\x87\x8d\nprint(""TF-IDF \xe6\xa8\xa1\xe5\x9e\x8b"")\nprint(tfidf.toarray())\n'"
src/2.获得文本语料和词汇资源/test.py,0,b''
src/3.vocabulary-model/Vocabulary-Model.py,0,"b'# coding: utf-8\n\n""""""\n\xe8\xaf\x8d\xe6\xb1\x87\xe8\xa1\xa8\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\n* \xe8\xa2\x8b\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xbe\x88\xe5\xa5\xbd\xe7\x9a\x84\xe8\xa1\xa8\xe7\x8e\xb0\xe6\x96\x87\xe6\x9c\xac\xe7\x94\xb1\xe5\x93\xaa\xe4\xba\x9b\xe5\x8d\x95\xe8\xaf\x8d\xe7\xbb\x84\xe6\x88\x90\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe5\x8d\xb4\xe6\x97\xa0\xe6\xb3\x95\xe8\xa1\xa8\xe8\xbe\xbe\xe5\x87\xba\xe5\x8d\x95\xe8\xaf\x8d\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe5\x89\x8d\xe5\x90\x8e\xe5\x85\xb3\xe7\xb3\xbb\xef\xbc\x8c\n* \xe4\xba\x8e\xe6\x98\xaf\xe4\xba\xba\xe4\xbb\xac\xe5\x80\x9f\xe9\x89\xb4\xe4\xba\x86\xe8\xaf\x8d\xe8\xa2\x8b\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe6\x80\x9d\xe6\x83\xb3\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe8\xaf\x8d\xe6\xb1\x87\xe8\xa1\xa8\xe5\xaf\xb9\xe5\x8e\x9f\xe6\x9c\x89\xe5\x8f\xa5\xe5\xad\x90\xe6\x8c\x89\xe7\x85\xa7\xe5\x8d\x95\xe8\xaf\x8d\xe9\x80\x90\xe4\xb8\xaa\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xbc\x96\xe7\xa0\x81\xe3\x80\x82\n""""""\n\nimport numpy as np\nfrom tensorflow.contrib.learn import preprocessing as pc\n\n# \xe8\xaf\xad\xe6\x96\x99\ncorpus = [\'i love you\', \'me too\']\n\nvocab = pc.VocabularyProcessor(max_document_length=4)\n""""""\nVocabularyProcessor \xe5\x8f\x82\xe6\x95\xb0\n* max_document_length: \xe6\x96\x87\xe6\xa1\xa3\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe9\x95\xbf\xe5\xba\xa6\xe3\x80\x82\xe5\xa6\x82\xe6\x9e\x9c\xe6\x96\x87\xe6\x9c\xac\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe5\xa4\xa7\xe4\xba\x8e\xe6\x9c\x80\xe5\xa4\xa7\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe9\x82\xa3\xe4\xb9\x88\xe5\xae\x83\xe4\xbc\x9a\xe8\xa2\xab\xe5\x89\xaa\xe5\x88\x87\xef\xbc\x8c\xe5\x8f\x8d\xe4\xb9\x8b\xe5\x88\x99\xe7\x94\xa80\xe5\xa1\xab\xe5\x85\x85\xe3\x80\x82\n* min_frequency: \xe8\xaf\x8d\xe9\xa2\x91\xe7\x9a\x84\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xef\xbc\x8c\xe5\x87\xba\xe7\x8e\xb0\xe6\xac\xa1\xe6\x95\xb0\xe5\xb0\x8f\xe4\xba\x8e\xe6\x9c\x80\xe5\xb0\x8f\xe8\xaf\x8d\xe9\xa2\x91\xe5\x88\x99\xe4\xb8\x8d\xe4\xbc\x9a\xe8\xa2\xab\xe6\x94\xb6\xe5\xbd\x95\xe5\x88\xb0\xe8\xaf\x8d\xe8\xa1\xa8\xe4\xb8\xad\xe3\x80\x82\n* vocabulary: CategoricalVocabulary \xe5\xaf\xb9\xe8\xb1\xa1\xe3\x80\x82\n* tokenizer_fn: \xe5\x88\x86\xe8\xaf\x8d\xe5\x87\xbd\xe6\x95\xb0\xe3\x80\x82\n""""""\n# \xe5\x88\x9b\xe5\xbb\xba\xe8\xaf\x8d\xe6\xb1\x87\xe8\xa1\xa8\xef\xbc\x8c\xe5\x88\x9b\xe5\xbb\xba\xe5\x90\x8e\xe4\xb8\x8d\xe8\x83\xbd\xe6\x9b\xb4\xe6\x94\xb9\nvocab.fit(corpus)\n\n# \xe8\x8e\xb7\xe5\x8f\x96 Iterator \xe5\xaf\xb9\xe8\xb1\xa1, next \xe8\xbf\x9b\xe8\xa1\x8c\xe9\x81\x8d\xe5\x8e\x86\nprint(""Encoding: \\n"", next(vocab.transform([\'i me too\'])).tolist())\n\n# \xe8\x8e\xb7\xe5\x8f\x96 \xe9\xa2\x84\xe6\x96\x99 \xe7\xbc\x96\xe7\xa0\x81\xe5\x90\x8e\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x91\xe9\x87\x8f\nmat_corpus = np.array(list(vocab.fit_transform(corpus)))\nprint(""mat_corpus: \\n"", mat_corpus)\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe5\x92\x8c\xe5\x8a\xa0\xe8\xbd\xbd\xe8\xaf\x8d\xe6\xb1\x87\xe8\xa1\xa8\n# vocab.save(\'vocab.pickle\')\n# vocab = pc.VocabularyProcessor.restore(\'vocab.pickle\')\n'"
src/4.word2vec/Demo-CBoW.py,7,"b'# coding: utf-8\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# torch.manual_seed(1)\n\n# word_to_ix = {""hello"": 0, ""world"": 1}\n# # 2\xe8\xa1\xa8\xe7\xa4\xba\xe6\x9c\x892\xe4\xb8\xaa\xe8\xaf\x8d\xef\xbc\x8c5\xe8\xa1\xa8\xe7\xa4\xba5\xe7\xbb\xb4\xe5\xba\xa6\xef\xbc\x8c\xe5\x85\xb6\xe5\xae\x9e\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa2x5\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\n# embeds = nn.Embedding(2, 5)\n# lookup_tensor = torch.LongTensor([word_to_ix[""hello""]])\n# hello_embed = embeds(autograd.Variable(lookup_tensor))\n# print(hello_embed)\n\nCONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\nraw_text = """"""We are about to study the idea of a computational process.\nComputational processes are abstract beings that inhabit computers.\nAs they evolve, processes manipulate other abstract things called data.\nThe evolution of a process is directed by a pattern of rules\ncalled a program. People create programs to direct processes. In effect,\nwe conjure the spirits of the computer with our spells."""""".split()\n\n# By deriving a set from `raw_text`, we deduplicate the array\nvocab = set(raw_text)\nvocab_size = len(vocab)\n\nword_to_ix = {word: i for i, word in enumerate(vocab)}\ndata = []\nfor i in range(2, len(raw_text) - 2):\n    context = [raw_text[i - 2], raw_text[i - 1],\n               raw_text[i + 1], raw_text[i + 2]]\n    target = raw_text[i]\n    data.append((context, target))\nprint(data[:5])\n\n\nclass CBOW(nn.Module):\n\n    def __init__(self):\n        pass\n\n    def forward(self, inputs):\n        pass\n\n# create your model and train.  here are some functions to help you make\n# the data ready for use by your module\n\n\ndef make_context_vector(context, word_to_ix):\n    idxs = [word_to_ix[w] for w in context]\n    tensor = torch.LongTensor(idxs)\n    return autograd.Variable(tensor)\n\n\nmake_context_vector(data[0][0], word_to_ix)  # example\n'"
src/4.word2vec/Demo-Ngram.py,9,"b'# coding: utf-8\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ntorch.manual_seed(1)\n\n# word_to_ix = {""hello"": 0, ""world"": 1}\n# # 2\xe8\xa1\xa8\xe7\xa4\xba\xe6\x9c\x892\xe4\xb8\xaa\xe8\xaf\x8d\xef\xbc\x8c5\xe8\xa1\xa8\xe7\xa4\xba5\xe7\xbb\xb4\xe5\xba\xa6\xef\xbc\x8c\xe5\x85\xb6\xe5\xae\x9e\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa2x5\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\n# embeds = nn.Embedding(2, 5)\n# lookup_tensor = torch.LongTensor([word_to_ix[""hello""]])\n# hello_embed = embeds(autograd.Variable(lookup_tensor))\n# print(hello_embed)\n\n\nCONTEXT_SIZE = 2\nEMBEDDING_DIM = 10\n\n# \xe6\x88\x91\xe4\xbb\xac\xe5\xb0\x86\xe4\xbd\xbf\xe7\x94\xa8 Shakespeare Sonnet 2\ntest_sentence = """"""When forty winters shall besiege thy brow,\nAnd dig deep trenches in thy beauty\'s field,\nThy youth\'s proud livery so gazed on now,\nWill be a totter\'d weed of small worth held:\nThen being asked, where all thy beauty lies,\nWhere all the treasure of thy lusty days;\nTo say, within thine own deep sunken eyes,\nWere an all-eating shame, and thriftless praise.\nHow much more praise deserv\'d thy beauty\'s use,\nIf thou couldst answer \'This fair child of mine\nShall sum my count, and make my old excuse,\'\nProving his beauty by succession thine!\nThis were to be new made when thou art old,\nAnd see thy blood warm when thou feel\'st it cold."""""".split()\n\n# \xe5\xbb\xba\xe9\x80\xa0\xe4\xb8\x80\xe7\xb3\xbb\xe5\x88\x97\xe5\x85\x83\xe7\xbb\x84. \xe6\xaf\x8f\xe4\xb8\xaa\xe5\x85\x83\xe7\xbb\x84 ([word_i-2, word_i-1] => \xe7\x89\xb9\xe5\xbe\x81, word_i => \xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f)\n# \xe7\x9b\xae\xe6\xa0\x87\xe8\xaf\x8d\xe7\x9a\x84\xe6\x9d\xa1\xe4\xbb\xb6\xe6\xa6\x82\xe7\x8e\x87\xe5\x8f\xaa\xe4\xb8\x8e\xe5\x85\xb6\xe4\xb9\x8b\xe5\x89\x8d\xe7\x9a\x84 n \xe4\xb8\xaa\xe8\xaf\x8d\xe6\x9c\x89\xe5\x85\xb3\ntrigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n            for i in range(len(test_sentence) - 2)]\n# \xe6\x89\x93\xe5\x8d\xb0\xe5\x89\x8d3\xe8\xa1\x8c\nprint(""\xe6\x89\x93\xe5\x8d\xb0\xe6\x95\xb0\xe6\x8d\xae\xe5\x89\x8d3\xe8\xa1\x8c: \\n"", trigrams[:3])\n\n# \xe8\xaf\x8d\xe9\x9b\x86\xe9\x80\x89\xe6\x8b\xa9\xef\xbc\x8c enumerate\xe6\x98\xaf\xe5\xb8\xa6\xe5\xba\x8f\xe5\x88\x97\xe5\x8f\xb7\xe7\x9a\x84\xe5\xa2\x9e\xe5\xba\x8fID\xe5\x88\x97\xe8\xa1\xa8\nvocab = set(test_sentence)\nword_to_ix = {word: i for i, word in enumerate(vocab)}\n\n\nclass NGramLanguageModeler(nn.Module):\n\n    def __init__(self, vocab_size, embedding_dim, context_size):\n        super(NGramLanguageModeler, self).__init__()\n        # embedding_dim \xe8\xae\xbe\xe7\xbd\xae Embedding \xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\xe5\xa4\xa7\xe5\xb0\x8f\n        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n        self.linear2 = nn.Linear(128, vocab_size)\n\n    def forward(self, inputs):\n        embeds = self.embeddings(inputs).view((1, -1))\n        out = F.relu(self.linear1(embeds))\n        out = self.linear2(out)\n        log_probs = F.log_softmax(out, dim=1)\n        return log_probs\n\n\nmodel = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n\n\nlosses = []\nloss_function = nn.NLLLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n\nfor epoch in range(10):\n    total_loss = torch.Tensor([0])\n    for context, target in trigrams:\n\n        # 1\n        context_idxs = [word_to_ix[w] for w in context]\n        context_var = autograd.Variable(torch.LongTensor(context_idxs))\n\n        # 2\n        model.zero_grad()\n\n        # 3\n        log_probs = model(context_var)\n\n        # 4\n        loss = loss_function(log_probs, autograd.Variable(torch.LongTensor([word_to_ix[target]])))\n\n        # 5\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.data\n    losses.append(total_loss)\nprint(""\xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0: \\n"", losses)  # The loss decreased every iteration over the training data!\n'"
src/4.word2vec/word2vec.py,0,"b'# coding: utf-8\n\n""""""\nWord2Vec \xe6\xa8\xa1\xe5\x9e\x8b:\n* Word2Vec \xe9\x80\x9a\xe8\xbf\x87\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x8a\x8a\xe5\xaf\xb9\xe6\x96\x87\xe6\x9c\xac\xe5\x86\x85\xe5\xae\xb9\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xe7\xae\x80\xe5\x8c\x96\xe4\xb8\xbaK\xe7\xbb\xb4\xe5\x90\x91\xe9\x87\x8f\xe7\xa9\xba\xe9\x97\xb4\xe4\xb8\xad\xe7\x9a\x84\xe5\x90\x91\xe9\x87\x8f\xe8\xbf\x90\xe7\xae\x97.(\xe8\x80\x8c\xe5\x90\x91\xe9\x87\x8f\xe7\xa9\xba\xe9\x97\xb4\xe4\xb8\x8a\xe7\x9a\x84\xe7\x9b\xb8\xe4\xbc\xbc\xe5\xba\xa6\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\xe6\x9d\xa5\xe8\xa1\xa8\xe7\xa4\xba\xe6\x96\x87\xe6\x9c\xac\xe8\xaf\xad\xe4\xb9\x89\xe4\xb8\x8a\xe7\x9a\x84\xe7\x9b\xb8\xe4\xbc\xbc\xe5\xba\xa6)\n    * \xe9\x87\x87\xe7\x94\xa8\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9c\x89CBOW(Continuous Bag-Of-Words\xef\xbc\x8c\xe5\x8d\xb3\xe8\xbf\x9e\xe7\xbb\xad\xe7\x9a\x84\xe8\xaf\x8d\xe8\xa2\x8b\xe6\xa8\xa1\xe5\x9e\x8b)\xe5\x92\x8c Skip-Gram \xe4\xb8\xa4\xe7\xa7\x8d.\n    * \xe5\x9b\xa0\xe6\xad\xa4\xef\xbc\x8cWord2Vec \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe8\xaf\x8d\xe5\x90\x91\xe9\x87\x8f\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xa2\xab\xe7\x94\xa8\xe6\x9d\xa5\xe5\x81\x9a\xe5\xbe\x88\xe5\xa4\x9aNLP\xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84\xe5\xb7\xa5\xe4\xbd\x9c\xef\xbc\x8c\xe6\xaf\x94\xe5\xa6\x82\xe8\x81\x9a\xe7\xb1\xbb\xe3\x80\x81\xe6\x89\xbe\xe5\x90\x8c\xe4\xb9\x89\xe8\xaf\x8d\xe3\x80\x81\xe8\xaf\x8d\xe6\x80\xa7\xe5\x88\x86\xe6\x9e\x90\xe7\xad\x89\xe7\xad\x89.\n* CBOW \xe6\xa8\xa1\xe5\x9e\x8b: \xe8\x83\xbd\xe5\xa4\x9f\xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x85\xa5\xe5\x91\xa8\xe5\x9b\xb4n-1\xe4\xb8\xaa\xe8\xaf\x8d\xe6\x9d\xa5\xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xba\xe8\xbf\x99\xe4\xb8\xaa\xe8\xaf\x8d\xe6\x9c\xac\xe8\xba\xab.\n    * \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe8\xaf\xb4\xef\xbc\x8cCBOW\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe6\x98\xaf\xe6\x9f\x90\xe4\xb8\xaa\xe8\xaf\x8dA\xe5\x91\xa8\xe5\x9b\xb4\xe7\x9a\x84n\xe4\xb8\xaa\xe5\x8d\x95\xe8\xaf\x8d\xe7\x9a\x84\xe8\xaf\x8d\xe5\x90\x91\xe9\x87\x8f\xe4\xb9\x8b\xe5\x92\x8c\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x98\xaf\xe8\xaf\x8dA\xe6\x9c\xac\xe8\xba\xab\xe7\x9a\x84\xe8\xaf\x8d\xe5\x90\x91\xe9\x87\x8f.\n* Skip-gram \xe6\xa8\xa1\xe5\x9e\x8b: \xe8\x83\xbd\xe5\xa4\x9f\xe6\xa0\xb9\xe6\x8d\xae\xe8\xaf\x8d\xe6\x9c\xac\xe8\xba\xab\xe6\x9d\xa5\xe9\xa2\x84\xe6\xb5\x8b\xe5\x91\xa8\xe5\x9b\xb4\xe6\x9c\x89\xe5\x93\xaa\xe4\xba\x9b\xe8\xaf\x8d.\n    * \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe8\xaf\xb4\xef\xbc\x8cSkip-gram\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe6\x98\xaf\xe8\xaf\x8dA\xe6\x9c\xac\xe8\xba\xab\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x98\xaf\xe8\xaf\x8dA\xe5\x91\xa8\xe5\x9b\xb4\xe7\x9a\x84n\xe4\xb8\xaa\xe5\x8d\x95\xe8\xaf\x8d\xe7\x9a\x84\xe8\xaf\x8d\xe5\x90\x91\xe9\x87\x8f.\n""""""\n\nimport pandas as pd\nfrom gensim.models import word2vec\n\n# \xe5\x8a\xa0\xe8\xbd\xbd\xe8\xaf\xad\xe6\x96\x99\nsentences = word2vec.Text8Corpus(u""/opt/data/NLP/4.word2vec/text8.txt"")\nmodel = word2vec.Word2Vec(sentences, size=200)  # \xe8\xae\xad\xe7\xbb\x83skip-gram\xe6\xa8\xa1\xe5\x9e\x8b; \xe9\xbb\x98\xe8\xae\xa4window=5\n\n# \xe8\xae\xa1\xe7\xae\x97\xe4\xb8\xa4\xe4\xb8\xaa\xe8\xaf\x8d\xe7\x9a\x84\xe7\x9b\xb8\xe4\xbc\xbc\xe5\xba\xa6/\xe7\x9b\xb8\xe5\x85\xb3\xe7\xa8\x8b\xe5\xba\xa6\ny1 = model.similarity(""woman"", ""man"")\nprint(u""woman\xe5\x92\x8cman\xe7\x9a\x84\xe7\x9b\xb8\xe4\xbc\xbc\xe5\xba\xa6\xe4\xb8\xba\xef\xbc\x9a"", y1)\nprint(""--------\\n"")\n\n# \xe8\xae\xa1\xe7\xae\x97\xe6\x9f\x90\xe4\xb8\xaa\xe8\xaf\x8d\xe7\x9a\x84\xe7\x9b\xb8\xe5\x85\xb3\xe8\xaf\x8d\xe5\x88\x97\xe8\xa1\xa8\ny2 = model.most_similar(""good"", topn=20)  # 20\xe4\xb8\xaa\xe6\x9c\x80\xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84\nprint(pd.Series(y2))\n# print(u""\xe5\x92\x8cgood\xe6\x9c\x80\xe7\x9b\xb8\xe5\x85\xb3\xe7\x9a\x84\xe8\xaf\x8d\xe6\x9c\x89\xef\xbc\x9a\\n"")\n# for item in y2:\n#     print(item[0], item[1])\nprint(""--------\\n"")\n\n# \xe5\xaf\xbb\xe6\x89\xbe\xe5\xaf\xb9\xe5\xba\x94\xe5\x85\xb3\xe7\xb3\xbb\nprint(\' ""boy"" is to ""father"" as ""girl"" is to ...? \\n\')\ny3 = model.most_similar([\'girl\', \'father\'], [\'boy\'], topn=3)\nfor item in y3:\n    print(item[0], item[1])\nprint(""--------\\n"")\n\nmore_examples = [""he his she"", ""big bigger bad"", ""going went being""]\nfor example in more_examples:\n    a, b, x = example.split()\n    predicted = model.most_similar([x, b], [a])[0][0]\n    print(""\'%s\' is to \'%s\' as \'%s\' is to \'%s\'"" % (a, b, x, predicted))\nprint(""--------\\n"")\n\n# \xe5\xaf\xbb\xe6\x89\xbe\xe4\xb8\x8d\xe5\x90\x88\xe7\xbe\xa4\xe7\x9a\x84\xe8\xaf\x8d\ny4 = model.doesnt_match(""breakfast cereal dinner lunch"".split())\nprint(u""\xe4\xb8\x8d\xe5\x90\x88\xe7\xbe\xa4\xe7\x9a\x84\xe8\xaf\x8d\xef\xbc\x9a"", y4)\nprint(""--------\\n"")\n\n# \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe4\xbb\xa5\xe4\xbe\xbf\xe9\x87\x8d\xe7\x94\xa8\n# model.save(""text8.model"")\n# \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x96\xb9\xe5\xbc\x8f\n# model_2 = word2vec.Word2Vec.load(""text8.model"")\n\n# \xe4\xbb\xa5\xe4\xb8\x80\xe7\xa7\x8dC\xe8\xaf\xad\xe8\xa8\x80\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xa7\xa3\xe6\x9e\x90\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe8\xaf\x8d\xe5\x90\x91\xe9\x87\x8f\n# model.save_word2vec_format(""text8.model.bin"", binary=True)\n# \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x96\xb9\xe5\xbc\x8f\n# model_3 = word2vec.Word2Vec.load_word2vec_format(""text8.model.bin"", binary=True)\n'"
src/5.jieba-model/jieba-model.py,0,"b'# coding: utf-8\n\n# \xe7\xac\xac\xe4\xb8\x89\xe6\x96\xb9\xe5\x88\x86\xe8\xaf\x8d\xe5\xb7\xa5\xe5\x85\xb7\nimport jieba\n\n# \xe5\x88\x86\xe8\xaf\x8d\xe6\xa8\xa1\xe5\xbc\x8f\nseg = jieba.cut(""\xe8\xbf\x99\xe6\x98\xaf\xe4\xb8\x80\xe6\x9c\xac\xe5\x85\xb3\xe4\xba\x8e\xe4\xbf\xa1\xe6\x81\xaf\xe6\xa3\x80\xe7\xb4\xa2\xe7\x9a\x84\xe4\xb9\xa6"", cut_all=True)  # cut_all=True\xef\xbc\x8c\xe5\x85\xa8\xe6\xa8\xa1\xe5\xbc\x8f\nprint(""\\n\xe5\x85\xa8\xe6\xa8\xa1\xe5\xbc\x8f\xe5\x88\x86\xe8\xaf\x8d: \\n"", ""/ "".join(seg))\n\nseg = jieba.cut(""\xe8\xbf\x99\xe6\x98\xaf\xe4\xb8\x80\xe6\x9c\xac\xe5\x85\xb3\xe4\xba\x8e\xe4\xbf\xa1\xe6\x81\xaf\xe6\xa3\x80\xe7\xb4\xa2\xe7\x9a\x84\xe4\xb9\xa6"", cut_all=False)  # cut_all=False\xef\xbc\x8c\xe7\xb2\xbe\xe7\xa1\xae\xe6\xa8\xa1\xe5\xbc\x8f\nprint(""\\n\xe7\xb2\xbe\xe7\xa1\xae\xe6\xa8\xa1\xe5\xbc\x8f\xe5\x88\x86\xe8\xaf\x8d: \\n"", ""/ "".join(seg))\n\nseg = jieba.cut(""\xe4\xbb\x96\xe6\x9d\xa5\xe5\x88\xb0\xe4\xba\x86\xe7\xbd\x91\xe6\x98\x93\xe6\x9d\xad\xe7\xa0\x94\xe5\xa4\xa7\xe5\x8e\xa6"")  # \xe9\xbb\x98\xe8\xae\xa4\xe6\x98\xaf\xe7\xb2\xbe\xe7\xa1\xae\xe6\xa8\xa1\xe5\xbc\x8f\nprint(""\\n\xe6\xb5\x8b\xe8\xaf\x95\xe7\xb2\xbe\xe7\xa1\xae\xe6\xa8\xa1\xe5\xbc\x8f: \\n"", "", "".join(seg))\n\n\n# \xe6\x90\x9c\xe7\xb4\xa2\xe5\xbc\x95\xe6\x93\x8e\xe6\xa8\xa1\xe5\xbc\x8f\nseg = jieba.cut_for_search(""\xe5\xb0\x8f\xe6\x98\x8e\xe7\xa1\x95\xe5\xa3\xab\xe6\xaf\x95\xe4\xb8\x9a\xe4\xba\x8e\xe4\xb8\xad\xe5\x9b\xbd\xe7\xa7\x91\xe5\xad\xa6\xe9\x99\xa2\xe8\xae\xa1\xe7\xae\x97\xe6\x89\x80\xef\xbc\x8c\xe5\x90\x8e\xe5\x9c\xa8\xe6\x97\xa5\xe6\x9c\xac\xe4\xba\xac\xe9\x83\xbd\xe5\xa4\xa7\xe5\xad\xa6\xe6\xb7\xb1\xe9\x80\xa0"")\nprint(""\\n\xe6\xb5\x8b\xe8\xaf\x95\xe6\x90\x9c\xe7\xb4\xa2\xe5\xbc\x95\xe6\x93\x8e\xe6\xa8\xa1\xe5\xbc\x8f: \\n"", "", "".join(seg))\n\n\n# \xe6\xb7\xbb\xe5\x8a\xa0\xe8\x87\xaa\xe5\xae\x9a\xe4\xb9\x89\xe8\xaf\x8d\xe5\x85\xb8\njieba.load_userdict(""src/py3.x/NLP/5.jieba-model/userdic.txt"")\nseg = jieba.cut(""\xe8\xbf\x99\xe6\x98\xaf\xe4\xb8\x80\xe6\x9c\xac\xe5\x85\xb3\xe4\xba\x8e\xe5\x85\xab\xe4\xb8\x80\xe5\x8f\x8c\xe9\xb9\xbf\xe4\xbf\xa1\xe6\x81\xaf\xe6\xa3\x80\xe7\xb4\xa2\xe7\x9a\x84\xe4\xb9\xa6"")\nprint(""\\n\xe6\xb5\x8b\xe8\xaf\x95\xe8\x87\xaa\xe5\xae\x9a\xe4\xb9\x89\xe5\xad\x97\xe5\x85\xb8: \\n"", ""/ "".join(seg))\n'"
src/6.LDA/EmailDemo.py,0,b''
src/6.LDA/demo.py,0,"b""import codecs\nfrom gensim.models import LdaModel\nfrom gensim.corpora import Dictionary\n\ntrain = []\nstopwords = codecs.open('stopwords.txt', 'r', encoding='utf8').readlines()\nstopwords = [w.strip() for w in stopwords]\nfp = codecs.open('wiki.zh.seg.utf.txt', 'r', encoding='utf8')\nfor line in fp:\n    line = line.split()\n    train.append([w for w in line if w not in stopwords])\n\ndictionary = Dictionary(train)\ncorpus = [dictionary.doc2bow(text) for text in train]\nlda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=100)\n"""
src/6.LDA/test.py,0,"b'#!/usr/bin/python\n# coding:utf8\n""""""\nCreated on 2018-03-13\nUpdated on 2018-03-13\nAuthor: \xe7\x89\x87\xe5\x88\xbb\nGitHub: https://github.com/apachecn/AiLearning\nCoding: http://blog.csdn.net/github_36299736/article/details/54966460\n""""""\n\nimport gensim\nfrom gensim import corpora, models\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import RegexpTokenizer\nfrom stop_words import get_stop_words\n\n# \xe5\x88\x9b\xe5\xbb\xba\xe7\xa4\xba\xe4\xbe\x8b\xe6\x96\x87\xe6\xa1\xa3\ndoc_a = ""Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.""\ndoc_b = ""My mother spends a lot of time driving my brother around to baseball practice.""\ndoc_c = ""Some health experts suggest that driving may cause increased tension and blood pressure.""\ndoc_d = ""I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.""\ndoc_e = ""Health professionals say that brocolli is good for your health.""\n# \xe5\xb0\x86\xe7\xa4\xba\xe4\xbe\x8b\xe6\x96\x87\xe6\xa1\xa3\xe7\xbc\x96\xe8\xaf\x91\xe6\x88\x90\xe5\x88\x97\xe8\xa1\xa8\ndoc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]\n\n\n# \xe5\x88\x9b\xe5\xbb\xbaPorterStemmer\xe7\xb1\xbb\xe7\x9a\x84p_stemmer\np_stemmer = PorterStemmer()\n# \xe5\x88\x86\xe8\xaf\x8d\xef\xbc\x9a\xe5\xb0\x86\xe6\x96\x87\xe6\xa1\xa3\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe5\x85\xb6\xe5\x8e\x9f\xe5\xad\x90\xe5\x85\x83\xe7\xb4\xa0\ntokenizer = RegexpTokenizer(r\'\\w+\')\n# \xe5\x88\x9b\xe5\xbb\xba\xe8\x8b\xb1\xe6\x96\x87\xe5\x81\x9c\xe7\x94\xa8\xe8\xaf\x8d\xe5\x88\x97\xe8\xa1\xa8\nen_stop = get_stop_words(\'en\')\n\n\n# \xe5\xbe\xaa\xe7\x8e\xaf\xe4\xb8\xad\xe6\xa0\x87\xe8\xae\xb0\xe7\x9a\x84\xe6\x96\x87\xe6\xa1\xa3\xe5\x88\x97\xe8\xa1\xa8\ntexts = []\n# \xe9\x81\x8d\xe5\x8e\x86\xe6\x96\x87\xe6\xa1\xa3\xe5\x88\x97\xe8\xa1\xa8\nfor i in doc_set:\n\n    # \xe6\xb8\x85\xe7\x90\x86\xe5\xb9\xb6\xe6\xa0\x87\xe8\xae\xb0\xe6\x96\x87\xe6\xa1\xa3\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\n    raw = i.lower()\n    tokens = tokenizer.tokenize(raw)\n    print(tokens)\n\n    # \xe4\xbb\x8e\xe4\xbb\xa4\xe7\x89\x8c\xe4\xb8\xad\xe5\x88\xa0\xe9\x99\xa4\xe5\x81\x9c\xe7\x94\xa8\xe8\xaf\x8d(\xe5\x81\x9c\xe7\x94\xa8\xe8\xaf\x8d\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x9a\xe7\xa7\xbb\xe9\x99\xa4\xe6\x97\xa0\xe6\x84\x8f\xe4\xb9\x89\xe7\x9a\x84\xe8\xaf\x8d)\n    stopped_tokens = [i for i in tokens if not i in en_stop]\n\n    # \xe8\xaf\x8d\xe5\xb9\xb2\xe4\xbb\xa4\xe7\x89\x8c(\xe8\xaf\x8d\xe5\xb9\xb2\xe6\x8f\x90\xe5\x8f\x96\xef\xbc\x9a\xe5\xb0\x86\xe5\x90\x8c\xe4\xb9\x89\xe8\xaf\x8d\xe5\x90\x88\xe5\xb9\xb6)\n    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n    # \xe6\xb7\xbb\xe5\x8a\xa0\xe4\xbb\xa4\xe7\x89\x8c\xe5\x88\x97\xe8\xa1\xa8\n    texts.append(stemmed_tokens)\n\n# \xe6\x8a\x8a\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe6\xa0\x87\xe8\xae\xb0\xe6\x96\x87\xe6\xa1\xa3\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaaid <-> \xe8\xaf\x8d\xe6\x9d\xa1\xe5\xad\x97\xe5\x85\xb8\ndictionary = corpora.Dictionary(texts)\nprint(dictionary.token2id)  # \xe6\x9d\xa5\xe6\x9f\xa5\xe7\x9c\x8b\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x8d\x95\xe8\xaf\x8d\xe7\x9a\x84id\n# print(dictionary.roken2id)  # \xe6\x98\xbe\xe7\xa4\xba brocolli \xe7\x9a\x84 id \xe6\x98\xaf 0\n\n# \xe5\xb0\x86\xe6\xa0\x87\xe8\xae\xb0\xe6\x96\x87\xe6\xa1\xa3\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe6\x96\x87\xe6\xa1\xa3\xe6\x9c\xaf\xe8\xaf\xad\xe7\x9f\xa9\xe9\x98\xb5\n# doc2bow() \xe6\x96\xb9\xe6\xb3\x95\xe5\xb0\x86 dictionary \xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\x8d\xe8\xa2\x8b\ncorpus = [dictionary.doc2bow(text) for text in texts]\n\n\n# \xe7\x94\x9f\xe6\x88\x90LDA\xe6\xa8\xa1\xe5\x9e\x8b\n""""""\nLdaModel \xe7\xb1\xbb\xe7\x9a\x84\xe8\xaf\xa6\xe7\xbb\x86\xe6\x8f\x8f\xe8\xbf\xb0\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x9c\xa8 gensim \xe6\x96\x87\xe6\xa1\xa3\xe4\xb8\xad\xe6\x9f\xa5\xe7\x9c\x8b\xe3\x80\x82\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe5\xae\x9e\xe4\xbe\x8b\xe4\xb8\xad\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n\n\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\nnum_topics: \xe5\xbf\x85\xe9\xa1\xbb\xe3\x80\x82LDA \xe6\xa8\xa1\xe5\x9e\x8b\xe8\xa6\x81\xe6\xb1\x82\xe7\x94\xa8\xe6\x88\xb7\xe5\x86\xb3\xe5\xae\x9a\xe5\xba\x94\xe8\xaf\xa5\xe7\x94\x9f\xe6\x88\x90\xe5\xa4\x9a\xe5\xb0\x91\xe4\xb8\xaa\xe4\xb8\xbb\xe9\xa2\x98\xe3\x80\x82\xe7\x94\xb1\xe4\xba\x8e\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe6\x96\x87\xe6\xa1\xa3\xe9\x9b\x86\xe5\xbe\x88\xe5\xb0\x8f\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaa\xe7\x94\x9f\xe6\x88\x90\xe4\xb8\x89\xe4\xb8\xaa\xe4\xb8\xbb\xe9\xa2\x98\xe3\x80\x82\nid2word: \xe5\xbf\x85\xe9\xa1\xbb\xe3\x80\x82LdaModel \xe7\xb1\xbb\xe8\xa6\x81\xe6\xb1\x82\xe6\x88\x91\xe4\xbb\xac\xe4\xb9\x8b\xe5\x89\x8d\xe7\x9a\x84 dictionary \xe6\x8a\x8a id \xe9\x83\xbd\xe6\x98\xa0\xe5\xb0\x84\xe6\x88\x90\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe3\x80\x82\npasses: \xe5\x8f\xaf\xe9\x80\x89\xe3\x80\x82\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x81\x8d\xe5\x8e\x86\xe8\xaf\xad\xe6\x96\x99\xe5\xba\x93\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\xe3\x80\x82\xe9\x81\x8d\xe5\x8e\x86\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\xe8\xb6\x8a\xe5\xa4\x9a\xef\xbc\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xb6\x8a\xe7\xb2\xbe\xe7\xa1\xae\xe3\x80\x82\xe4\xbd\x86\xe6\x98\xaf\xe5\xaf\xb9\xe4\xba\x8e\xe9\x9d\x9e\xe5\xb8\xb8\xe5\xa4\xa7\xe7\x9a\x84\xe8\xaf\xad\xe6\x96\x99\xe5\xba\x93\xef\xbc\x8c\xe9\x81\x8d\xe5\x8e\x86\xe5\xa4\xaa\xe5\xa4\x9a\xe6\xac\xa1\xe4\xbc\x9a\xe8\x8a\xb1\xe8\xb4\xb9\xe5\xbe\x88\xe9\x95\xbf\xe7\x9a\x84\xe6\x97\xb6\xe9\x97\xb4\xe3\x80\x82\n""""""\nldamodel = gensim.models.ldamodel.LdaModel(\n    corpus, num_topics=3, id2word=dictionary, passes=20)\n\nprint(dir(ldamodel))\nprint(ldamodel.print_topics(num_topics=3, num_words=3))  \n\n""""""\n\xe8\xbf\x99\xe6\x98\xaf\xe4\xbb\x80\xe4\xb9\x88\xe6\x84\x8f\xe6\x80\x9d\xe5\x91\xa2\xef\xbc\x9f\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe4\xb8\xbb\xe9\xa2\x98\xe9\x83\xbd\xe7\x94\xa8\xe9\x80\x97\xe5\x8f\xb7\xe5\x88\x86\xe9\x9a\x94\xe5\xbc\x80\xe3\x80\x82\xe6\xaf\x8f\xe4\xb8\xaa\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbd\x93\xe4\xb8\xad\xe6\x9c\x89\xe4\xb8\x89\xe4\xb8\xaa\xe8\xaf\xa5\xe4\xb8\xbb\xe9\xa2\x98\xe5\xbd\x93\xe4\xb8\xad\xe6\x9c\x80\xe5\x8f\xaf\xe8\x83\xbd\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe5\x8d\x95\xe8\xaf\x8d\xe3\x80\x82\xe5\x8d\xb3\xe4\xbd\xbf\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe6\x96\x87\xe6\xa1\xa3\xe9\x9b\x86\xe5\xbe\x88\xe5\xb0\x8f\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbe\x9d\xe6\x97\xa7\xe6\x98\xaf\xe5\xbe\x88\xe5\x8f\xaf\xe9\x9d\xa0\xe7\x9a\x84\xe3\x80\x82\xe8\xbf\x98\xe6\x9c\x89\xe4\xb8\x80\xe4\xba\x9b\xe9\x9c\x80\xe8\xa6\x81\xe6\x88\x91\xe4\xbb\xac\xe8\x80\x83\xe8\x99\x91\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x9a\n\n- health, brocolli \xe5\x92\x8c good \xe5\x9c\xa8\xe4\xb8\x80\xe8\xb5\xb7\xe6\x97\xb6\xe6\x9c\x89\xe5\xbe\x88\xe5\xa5\xbd\xe7\x9a\x84\xe5\x90\xab\xe4\xb9\x89\xe3\x80\x82\n- \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe4\xb8\xbb\xe9\xa2\x98\xe6\x9c\x89\xe7\x82\xb9\xe8\xae\xa9\xe4\xba\xba\xe7\x96\x91\xe6\x83\x91\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x88\x91\xe4\xbb\xac\xe9\x87\x8d\xe6\x96\xb0\xe6\x9f\xa5\xe7\x9c\x8b\xe6\xba\x90\xe6\x96\x87\xe6\xa1\xa3\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x88\xb0 drive \xe6\x9c\x89\xe5\xbe\x88\xe5\xa4\x9a\xe7\xa7\x8d\xe5\x90\xab\xe4\xb9\x89\xef\xbc\x9adriving a car \xe6\x84\x8f\xe6\x80\x9d\xe6\x98\xaf\xe5\xbc\x80\xe8\xbd\xa6\xef\xbc\x8cdriving oneself to improve \xe6\x98\xaf\xe6\xbf\x80\xe5\x8a\xb1\xe8\x87\xaa\xe5\xb7\xb1\xe8\xbf\x9b\xe6\xad\xa5\xe3\x80\x82\xe8\xbf\x99\xe6\x98\xaf\xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe4\xb8\xad\xe9\x9c\x80\xe8\xa6\x81\xe6\xb3\xa8\xe6\x84\x8f\xe7\x9a\x84\xe5\x9c\xb0\xe6\x96\xb9\xe3\x80\x82\n- \xe7\xac\xac\xe4\xb8\x89\xe4\xb8\xaa\xe4\xb8\xbb\xe9\xa2\x98\xe5\x8c\x85\xe5\x90\xab mother \xe5\x92\x8c brother\xef\xbc\x8c\xe8\xbf\x99\xe5\xbe\x88\xe5\x90\x88\xe7\x90\x86\xe3\x80\x82\n\n\xe8\xb0\x83\xe6\x95\xb4\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xbb\xe9\xa2\x98\xe6\x95\xb0\xe5\x92\x8c\xe9\x81\x8d\xe5\x8e\x86\xe6\xac\xa1\xe6\x95\xb0\xe5\xaf\xb9\xe4\xba\x8e\xe5\xbe\x97\xe5\x88\xb0\xe4\xb8\x80\xe4\xb8\xaa\xe5\xa5\xbd\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe6\x98\xaf\xe5\xbe\x88\xe9\x87\x8d\xe8\xa6\x81\xe7\x9a\x84\xe3\x80\x82\xe4\xb8\xa4\xe4\xb8\xaa\xe4\xb8\xbb\xe9\xa2\x98\xe7\x9c\x8b\xe8\xb5\xb7\xe6\x9d\xa5\xe6\x9b\xb4\xe9\x80\x82\xe5\x90\x88\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe6\x96\x87\xe6\xa1\xa3\xe3\x80\x82\n""""""\n\nlda = gensim.models.ldamodel.LdaModel(\n    corpus, num_topics=2, id2word=dictionary, passes=20)\n\nprint(lda.print_topics(num_topics=3, num_words=3))  \n\n\n# # LDA\xe4\xb8\xbb\xe9\xa2\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xbf\x9d\xe5\xad\x98\n# from gensim import corpora, models\n\n# # # \xe8\xaf\xad\xe6\x96\x99\xe5\xaf\xbc\xe5\x85\xa5\n# id2word = corpora.Dictionary.load_from_text(\'zhwiki_wordids.txt\')\n# mm = corpora.MmCorpus(\'zhwiki_tfidf.mm\')\n\n# # # \xe6\xa8\xa1\xe5\x9e\x8b\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe8\x80\x97\xe6\x97\xb628m\n# lda = models.ldamodel.LdaModel(corpus=mm, id2word=id2word, num_topics=100)\n\n# # \xe6\x89\x93\xe5\x8d\xb0\xe5\x89\x8d20\xe4\xb8\xaatopic\xe7\x9a\x84\xe8\xaf\x8d\xe5\x88\x86\xe5\xb8\x83\n# lda.print_topics(20)\n# # \xe6\x89\x93\xe5\x8d\xb0id\xe4\xb8\xba20\xe7\x9a\x84topic\xe7\x9a\x84\xe8\xaf\x8d\xe5\x88\x86\xe5\xb8\x83\n# lda.print_topic(20)\n\n# # \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xbf\x9d\xe5\xad\x98/ \xe5\x8a\xa0\xe8\xbd\xbd\n# lda.save(\'zhwiki_lda.model\')\n# lda = models.ldamodel.LdaModel.load(\'zhwiki_lda.model\')\n\n\n# # LDA \xe4\xb8\xbb\xe9\xa2\x98\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xbd\xbf\xe7\x94\xa8\n# # \xe5\xaf\xb9\xe6\x96\xb0\xe6\x96\x87\xe6\xa1\xa3\xef\xbc\x8c\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90bag-of-word\xe5\x90\x8e\xef\xbc\x8c\xe5\x8f\xaf\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xb8\xbb\xe9\xa2\x98\xe9\xa2\x84\xe6\xb5\x8b\xe3\x80\x82\n# test_doc = list(jieba.cut(test_doc))     # \xe6\x96\xb0\xe6\x96\x87\xe6\xa1\xa3\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x88\x86\xe8\xaf\x8d\n# doc_bow = id2word.doc2bow(test_doc)      # \xe6\x96\x87\xe6\xa1\xa3\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90bow\n# *** # doc_lda = lda[doc_bow]             # \xe5\xbe\x97\xe5\x88\xb0\xe6\x96\xb0\xe6\x96\x87\xe6\xa1\xa3\xe7\x9a\x84\xe4\xb8\xbb\xe9\xa2\x98\xe5\x88\x86\xe5\xb8\x83\n# #\xe8\xbe\x93\xe5\x87\xba\xe6\x96\xb0\xe6\x96\x87\xe6\xa1\xa3\xe7\x9a\x84\xe4\xb8\xbb\xe9\xa2\x98\xe5\x88\x86\xe5\xb8\x83\n# print doc_lda\n# for topic in doc_lda:\n#     print(""%s\\t%f\\n"" % (lda.print_topic(topic[0]), topic[1]))\n'"
src/7.crf/test.py,18,"b'# coding: utf-8\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.optim as optim\n\n\ndef to_scalar(var):  #var\xe6\x98\xafVariable,\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf\xef\xbc\x91\n    # returns a python float\n    return var.view(-1).data.tolist()[0]\n\n\ndef argmax(vec):\n    # return the argmax as a python int\n    _, idx = torch.max(vec, 1)\n    return to_scalar(idx)\n\n\ndef prepare_sequence(seq, to_ix):\n    idxs = [to_ix[w] for w in seq]\n    tensor = torch.LongTensor(idxs)\n    return autograd.Variable(tensor)\n\n\n# Compute log sum exp in a numerically stable way for the forward algorithm\ndef log_sum_exp(vec):  # vec\xe6\x98\xaf1*5, type\xe6\x98\xafVariable\n\n    max_score = vec[0, argmax(vec)]\n    # max_score\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf\xef\xbc\x91\xef\xbc\x8c\xe3\x80\x80max_score.view(1,-1)\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf\xef\xbc\x91\xef\xbc\x8a\xef\xbc\x91\xef\xbc\x8cmax_score.view(1, -1).expand(1, vec.size()[1])\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf\xef\xbc\x91\xef\xbc\x8a\xef\xbc\x95\n    max_score_broadcast = max_score.view(1, -1).expand(\n        1, vec.size()[1])  # vec.size()\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf1*5\n    return max_score + torch.log(\n        torch.sum(torch.exp(vec - max_score_broadcast)))  # \xe4\xb8\xba\xe4\xbb\x80\xe4\xb9\x88\xe6\x8c\x87\xe6\x95\xb0\xe4\xb9\x8b\xe5\x90\x8e\xe5\x86\x8d\xe6\xb1\x82\xe5\x92\x8c\xef\xbc\x8c\xe8\x80\x8c\xe5\x90\x8e\xe6\x89\x8dlog\xe5\x91\xa2\n\n\nclass BiLSTM_CRF(nn.Module):\n    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n        super(BiLSTM_CRF, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.vocab_size = vocab_size\n        self.tag_to_ix = tag_to_ix\n        self.tagset_size = len(tag_to_ix)\n\n        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n\n        self.lstm = nn.LSTM(\n            embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n\n        # Maps the output of the LSTM into tag space.\n        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n\n        # Matrix of transition parameters.  Entry i,j is the score of\n        # transitioning *to* i *from* j.\n        self.transitions = nn.Parameter(\n            torch.randn(self.tagset_size, self.tagset_size))\n\n        # These two statements enforce the constraint that we never transfer\n        # to the start tag and we never transfer from the stop tag\n        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n\n        self.hidden = self.init_hidden()\n\n    def init_hidden(self):\n        return (autograd.Variable(torch.randn(2, 1, self.hidden_dim // 2)),\n                autograd.Variable(torch.randn(2, 1, self.hidden_dim // 2)))\n\n    #\xe9\xa2\x84\xe6\xb5\x8b\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xbe\x97\xe5\x88\x86\n    def _forward_alg(self, feats):\n        # Do the forward algorithm to compute the partition function\n        init_alphas = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n\n        # START_TAG has all of the score.\n        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n\n        # Wrap in a variable so that we will get automatic backprop\n        forward_var = autograd.Variable(\n            init_alphas)  # \xe5\x88\x9d\xe5\xa7\x8b\xe7\x8a\xb6\xe6\x80\x81\xe7\x9a\x84forward_var\xef\xbc\x8c\xe9\x9a\x8f\xe7\x9d\x80step t\xe5\x8f\x98\xe5\x8c\x96\n\n        # Iterate through the sentence\n        for feat in feats:  # feat\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf\xef\xbc\x95\n            alphas_t = []  # The forward variables at this timestep\n            for next_tag in range(self.tagset_size):\n                # broadcast the emission score: it is the same regardless of\n                # the previous tag\n                emit_score = feat[next_tag].view(1, -1).expand(\n                    1, self.tagset_size)  # \xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf1*5\n\n                # the ith entry of trans_score is the score of transitioning to\n                # next_tag from i\n                trans_score = self.transitions[next_tag].view(1, -1)  #\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf\xef\xbc\x91\xef\xbc\x8a\xef\xbc\x95\n                # The ith entry of next_tag_var is the value for the\n                # edge (i -> next_tag) before we do log-sum-exp\n                # \xe7\xac\xac\xe4\xb8\x80\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xe6\x97\xb6\xe7\x90\x86\xe8\xa7\xa3\xef\xbc\x9a\n                # trans_score\xe6\x89\x80\xe6\x9c\x89\xe5\x85\xb6\xe4\xbb\x96\xe6\xa0\x87\xe7\xad\xbe\xe5\x88\xb0\xef\xbc\xa2\xe6\xa0\x87\xe7\xad\xbe\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\n                # \xe7\x94\xb1lstm\xe8\xbf\x90\xe8\xa1\x8c\xe8\xbf\x9b\xe5\x85\xa5\xe9\x9a\x90\xe5\xb1\x82\xe5\x86\x8d\xe5\x88\xb0\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe5\xbe\x97\xe5\x88\xb0\xe6\xa0\x87\xe7\xad\xbe\xef\xbc\xa2\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\xef\xbc\x8cemit_score\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf\xef\xbc\x91\xef\xbc\x8a\xef\xbc\x95\xef\xbc\x8c5\xe4\xb8\xaa\xe5\x80\xbc\xe6\x98\xaf\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\n                next_tag_var = forward_var + trans_score + emit_score\n                # The forward variable for this tag is log-sum-exp of all the\n                # scores.\n                alphas_t.append(log_sum_exp(next_tag_var))\n            forward_var = torch.cat(alphas_t).view(1, -1)  # \xe5\x88\xb0\xe7\xac\xac\xef\xbc\x88t-1\xef\xbc\x89step\xe6\x97\xb6\xef\xbc\x95\xe4\xb8\xaa\xe6\xa0\x87\xe7\xad\xbe\xe7\x9a\x84\xe5\x90\x84\xe8\x87\xaa\xe5\x88\x86\xe6\x95\xb0\n        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n        alpha = log_sum_exp(terminal_var)\n\n        return alpha\n\n    # \xe5\xbe\x97\xe5\x88\xb0feats\n    def _get_lstm_features(self, sentence):\n        self.hidden = self.init_hidden()\n        #embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n        embeds = self.word_embeds(sentence)\n\n        embeds = embeds.unsqueeze(1)\n\n        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n\n        lstm_feats = self.hidden2tag(lstm_out)\n\n        return lstm_feats\n\n    #\xe5\xbe\x97\xe5\x88\xb0gold_seq tag\xe7\x9a\x84score\n    def _score_sentence(self, feats, tags):\n        # Gives the score of a provided tag sequence\n        score = autograd.Variable(torch.Tensor([0]))\n        tags = torch.cat([torch.LongTensor([self.tag_to_ix[START_TAG]]), tags])  # \xe5\xb0\x86START_TAG\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\xef\xbc\x93\xe6\x8b\xbc\xe6\x8e\xa5\xe5\x88\xb0tag\xe5\xba\x8f\xe5\x88\x97\xe4\xb8\x8a\n\n        for i, feat in enumerate(feats):\n            #self.transitions[tags[i + 1], tags[i]] \xe5\xae\x9e\xe9\x99\x85\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe6\x98\xaf\xe4\xbb\x8e\xe6\xa0\x87\xe7\xad\xbei\xe5\x88\xb0\xe6\xa0\x87\xe7\xad\xbei+1\xe7\x9a\x84\xe8\xbd\xac\xe7\xa7\xbb\xe6\xa6\x82\xe7\x8e\x87\n            #feat[tags[i+1]], feat\xe6\x98\xafstep i \xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x8c\xe6\x9c\x89\xef\xbc\x95\xe4\xb8\xaa\xe5\x80\xbc\xef\xbc\x8c\xe5\xaf\xb9\xe5\xba\x94B, I, E, START_TAG, END_TAG, \xe5\x8f\x96\xe5\xaf\xb9\xe5\xba\x94\xe6\xa0\x87\xe7\xad\xbe\xe7\x9a\x84\xe5\x80\xbc\n\n            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[\n                i + 1]]\n        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n        return score\n\n    #\xe8\xa7\xa3\xe7\xa0\x81\xef\xbc\x8c\xe5\xbe\x97\xe5\x88\xb0\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\xba\x8f\xe5\x88\x97\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe9\xa2\x84\xe6\xb5\x8b\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xbe\x97\xe5\x88\x86\n    def _viterbi_decode(self, feats):\n        backpointers = []\n\n        # Initialize the viterbi variables in log space\n        init_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n\n        # forward_var at step i holds the viterbi variables for step i-1\n        forward_var = autograd.Variable(init_vvars)\n        for feat in feats:\n            bptrs_t = []  # holds the backpointers for this step\n            viterbivars_t = []  # holds the viterbi variables for this step\n\n            for next_tag in range(self.tagset_size):\n                # next_tag_var[i] holds the viterbi variable for tag i at the\n                # previous step, plus the score of transitioning\n                # from tag i to next_tag.\n                # We don\'t include the emission scores here because the max\n                # does not depend on them (we add them in below)\n                next_tag_var = forward_var + self.transitions[\n                    next_tag]  #\xe5\x85\xb6\xe4\xbb\x96\xe6\xa0\x87\xe7\xad\xbe\xef\xbc\x88B,I,E,Start,End\xef\xbc\x89\xe5\x88\xb0\xe6\xa0\x87\xe7\xad\xbenext_tag\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\n                best_tag_id = argmax(next_tag_var)\n                bptrs_t.append(best_tag_id)\n                viterbivars_t.append(next_tag_var[0][best_tag_id])\n            # Now add in the emission scores, and assign forward_var to the set\n            # of viterbi variables we just computed\n            forward_var = (torch.cat(viterbivars_t) + feat).view(\n                1, -1)  #\xe4\xbb\x8estep0\xe5\x88\xb0step(i-1)\xe6\x97\xb65\xe4\xb8\xaa\xe5\xba\x8f\xe5\x88\x97\xe4\xb8\xad\xe6\xaf\x8f\xe4\xb8\xaa\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7score\n            backpointers.append(bptrs_t)  #bptrs_t\xe6\x9c\x89\xef\xbc\x95\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\n\n        # Transition to STOP_TAG\n        terminal_var = forward_var + self.transitions[\n            self.tag_to_ix[STOP_TAG]]  #\xe5\x85\xb6\xe4\xbb\x96\xe6\xa0\x87\xe7\xad\xbe\xe5\x88\xb0STOP_TAG\xe7\x9a\x84\xe8\xbd\xac\xe7\xa7\xbb\xe6\xa6\x82\xe7\x8e\x87\n        best_tag_id = argmax(terminal_var)\n        path_score = terminal_var[0][best_tag_id]\n\n        # Follow the back pointers to decode the best path.\n        best_path = [best_tag_id]\n        for bptrs_t in reversed(backpointers):  #\xe4\xbb\x8e\xe5\x90\x8e\xe5\x90\x91\xe5\x89\x8d\xe8\xb5\xb0\xef\xbc\x8c\xe6\x89\xbe\xe5\x88\xb0\xe4\xb8\x80\xe4\xb8\xaabest\xe8\xb7\xaf\xe5\xbe\x84\n            best_tag_id = bptrs_t[best_tag_id]\n            best_path.append(best_tag_id)\n        # Pop off the start tag (we dont want to return that to the caller)\n        start = best_path.pop()\n        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n        best_path.reverse()  # \xe6\x8a\x8a\xe4\xbb\x8e\xe5\x90\x8e\xe5\x90\x91\xe5\x89\x8d\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\xe6\xad\xa3\xe8\xbf\x87\xe6\x9d\xa5\n        return path_score, best_path\n\n    def neg_log_likelihood(self, sentence, tags):\n        feats = self._get_lstm_features(sentence)\n        forward_score = self._forward_alg(feats)\n        gold_score = self._score_sentence(feats, tags)\n\n        return forward_score - gold_score\n\n    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n        # Get the emission scores from the BiLSTM\n        lstm_feats = self._get_lstm_features(sentence)\n\n        # Find the best path, given the features.\n        score, tag_seq = self._viterbi_decode(lstm_feats)\n        return score, tag_seq\n\n\nSTART_TAG = ""<START>""\nSTOP_TAG = ""<STOP>""\nEMBEDDING_DIM = 5\nHIDDEN_DIM = 4\n\n# Make up some training data\ntraining_data = [(""the wall street journal reported today that apple corporation made money"".split(), ""B I I I O O O B I O O"".split()),\n                 (""georgia tech is a university in georgia"".split(), ""B I O O O O B"".split())]\n\nword_to_ix = {}\nfor sentence, tags in training_data:\n    for word in sentence:\n        if word not in word_to_ix:\n            word_to_ix[word] = len(word_to_ix)\n\ntag_to_ix = {""B"": 0, ""I"": 1, ""O"": 2, START_TAG: 3, STOP_TAG: 4}\n\nmodel = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\noptimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n\n# Check predictions before training\n# precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n# precheck_tags = torch.LongTensor([tag_to_ix[t] for t in training_data[0][1]])\n# print(model(precheck_sent))\n\n# Make sure prepare_sequence from earlier in the LSTM section is loaded\nfor epoch in range(1):  # again, normally you would NOT do 300 epochs, it is toy data\n    for sentence, tags in training_data:\n        # Step 1. Remember that Pytorch accumulates gradients.\n        # We need to clear them out before each instance\n        model.zero_grad()\n\n        # Step 2. Get our inputs ready for the network, that is,\n        # turn them into Variables of word indices.\n        sentence_in = prepare_sequence(sentence, word_to_ix)\n        targets = torch.LongTensor([tag_to_ix[t] for t in tags])\n\n        # Step 3. Run our forward pass.\n        neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets)\n\n        # Step 4. Compute the loss, gradients, and update the parameters by\n        # calling optimizer.step()\n        neg_log_likelihood.backward()\n        optimizer.step()\n\n\n# Check predictions after training\nprecheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\nprint(model(precheck_sent)[0])  # \xe5\xbe\x97\xe5\x88\x86\nprint(\'^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\')\nprint(model(precheck_sent)[1])  # tag sequence\n'"
src/Chinese_ChatBot/QQ_ETL.py,0,"b'#!/usr/bin/python\n# coding: utf-8\nimport re\nimport codecs\nimport pandas as pd\n \n \nscript_name = ""QQ\xe8\x81\x8a\xe5\xa4\xa9\xe8\xae\xb0\xe5\xbd\x95\xe6\x95\xb4\xe7\x90\x86""\n \n# 1\xe3\x80\x81\xe9\x80\x9a\xe8\xbf\x87\xe6\xad\xa3\xe5\x88\x99\xe8\xaf\xad\xe5\x8f\xa5\xef\xbc\x8c\xe6\x8f\x90\xe5\x8f\x96\xe5\x87\xba\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe5\x92\x8c\xe8\xae\xb0\xe5\xbd\x95\xe5\x86\x85\xe5\xae\xb9\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x95\xb0\xe7\xbb\x84\xe3\x80\x82\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe5\xaf\xb9\xe5\xba\x94\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x95\xb0\xe7\xbb\x84\xe9\x95\xbf\xe5\xba\xa6\xe5\xba\x94\xe8\xaf\xa5\xe7\x9b\xb8\xe7\xad\x89\xe3\x80\x82\n# 2\xe3\x80\x81\xe5\xa4\x84\xe7\x90\x86\xe8\xae\xb0\xe5\xbd\x95\xe5\x86\x85\xe5\xae\xb9\n#     2.1\xe3\x80\x81windows\xe7\x9a\x84\xe6\x8d\xa2\xe8\xa1\x8c\xe4\xb8\xba\'\\r\\n\'\xef\xbc\x8c\xe5\x8d\x95\'\\n\'\xe4\xbd\x93\xe7\x8e\xb0\xe4\xb8\x8d\xe5\x87\xba\xe6\x8d\xa2\xe8\xa1\x8c\xe6\x95\x88\xe6\x9e\x9c\xe3\x80\x82\xe6\x89\x8b\xe6\x9c\xba\xe7\xab\xaf\xe5\xaf\xbc\xe5\x87\xba\xe7\x9a\x84\xe8\xae\xb0\xe5\xbd\x95\xe6\x9c\x89\xe7\x9a\x84\xe6\x8d\xa2\xe8\xa1\x8c\xe6\x98\xaf\\n\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe6\x9b\xbf\xe6\x8d\xa2\xe4\xb8\x80\xe4\xb8\x8b\xe3\x80\x82\n#     2.2\xe3\x80\x81\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe6\x94\xbe\xe5\x9c\xa8\xe4\xba\x86\xe6\xaf\x8f\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\xe6\x9c\xab\xe8\xa1\x8c\xe5\x90\x8e\xe9\x9d\xa2\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe6\x95\xb4\xe9\xbd\x90\xe7\xbe\x8e\xe8\xa7\x82\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe4\xb8\x8b\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe5\x89\x8d\xe8\xa1\xa5\xe5\xa4\x9a\xe5\xb0\x91\xe7\xa9\xba\xe6\xa0\xbc\xe3\x80\x82windows\xe8\xae\xb0\xe4\xba\x8b\xe6\x9c\xac\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe7\xac\xa6\xe5\x8d\xa0\xe4\xb8\xa4\xe6\xa0\xbc\xef\xbc\x8c\xe8\x8b\xb1\xe6\x96\x87\xe5\x8d\xa01\xe6\xa0\xbc\xef\xbc\x8c\xe8\x80\x8cpython\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe7\xac\xa6\xe9\x95\xbf\xe5\xba\xa6\xe6\x98\xaf\xe5\x8d\xb4\xe6\x98\xaf1\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x83\xb3\xe8\xa6\x81\xe6\x98\xbe\xe7\xa4\xba\xe6\x95\xb4\xe9\xbd\x90\xef\xbc\x8c\xe8\xbf\x98\xe9\x9c\x80\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe4\xb8\x8b\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe8\xa1\xa5\xe9\xbd\x90\xe7\xa9\xba\xe6\xa0\xbc\xe6\x95\xb0\xe3\x80\x82\xe8\xa1\xa5\xe9\xbd\x90\xe5\x90\x8e\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe8\xb7\x9d\xe7\xa6\xbb\xe8\xa1\x8c\xe9\xa6\x96\xe4\xbd\x8d\xe7\xbd\xae\xe4\xb8\xba100\xe7\x9a\x84\xe6\x95\xb4\xe6\x95\xb0\xe5\x80\x8d\xe3\x80\x82\n# 3\xe3\x80\x81\xe8\xaf\xbb\xe5\x92\x8c\xe5\x86\x99\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xe6\xb3\xa8\xe6\x84\x8f\xe7\xbc\x96\xe7\xa0\x81\xe8\xbd\xac\xe6\x8d\xa2\n \n \n \ndef length_w(text):\n    \'\'\'\xe8\xae\xa1\xe7\xae\x97\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\x9c\xa8windows\xe8\xae\xb0\xe4\xba\x8b\xe6\x9c\xac\xe4\xb8\xad\xe7\x9a\x84\xe5\xae\x9e\xe9\x99\x85\xe6\x98\xbe\xe7\xa4\xba\xe9\x95\xbf\xe5\xba\xa6\'\'\'\n    # \xe5\x8f\x96\xe6\x96\x87\xe6\x9c\xac\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe4\xb8\xad\xe6\x96\x87\xe6\x8c\x892\xe6\xa0\xbc\xe8\xae\xa1\xe7\xae\x97\xe3\x80\x82\n    length      = len(text)                          # \xe5\x8f\x96\xe5\x85\xb6\xe9\x95\xbf\xe5\xba\xa6(\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe7\xac\xa6\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba1\xef\xbc\x8c\xe8\x8b\xb1\xe6\x96\x871)\n    utf8_length = len(text.encode(\'utf-8\'))          # \xe5\x8f\x96\xe5\x85\xb6\xe9\x95\xbf\xe5\xba\xa6(\xe4\xb8\xad\xe6\x96\x87\xe9\x95\xbf3\xef\xbc\x8c\xe8\x8b\xb1\xe6\x96\x871)\n    length      = int((utf8_length-length)/2)+length # \xe6\x8c\x89(\xe4\xb8\xad\xe6\x96\x872\xe8\x8b\xb1\xe6\x96\x871)\xe8\xae\xa1\xe7\xae\x97\xe9\x95\xbf\xe5\xba\xa6\n    \n    # \xe8\xbf\x99\xe4\xb8\xaa\xe5\x86\x99\xe6\xb3\x95\xe5\xae\x9e\xe9\x99\x85\xe4\xb8\x8a\xe8\xbf\x98\xe6\x98\xaf\xe6\x9c\x89\xe9\x97\xae\xe9\xa2\x98\xe7\x9a\x84\xef\xbc\x8c\xe6\x9c\x89\xe4\xba\x9b\xe7\x89\xb9\xe6\xae\x8a\xe5\xad\x97\xe7\xac\xa6\xe4\xbc\x9a\xe5\xaf\xbc\xe8\x87\xb4\xe8\xae\xa1\xe7\xae\x97\xe9\x95\xbf\xe5\xba\xa6\xe5\x92\x8c\xe5\xae\x9e\xe9\x99\x85\xe6\x98\xbe\xe7\xa4\xba\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\x8d\xe4\xb8\x80\xe8\x87\xb4\xe3\x80\x82\xe6\x89\x80\xe4\xbb\xa5\xe4\xb8\x8b\xe9\x9d\xa2\xe8\xae\xa1\xe7\xae\x97\xe6\x8d\xa2\xe8\xa1\x8c\xe9\x97\xae\xe9\xa2\x98\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81\xe4\xb8\xad\xe6\x8d\xa2\xe4\xba\x86\xe5\x8f\xa6\xe4\xb8\x80\xe7\xa7\x8d\xe5\x86\x99\xe6\xb3\x95\xef\xbc\x8c\xe9\x81\xbf\xe5\x85\x8d\xe5\x9b\xa0\xe7\x89\xb9\xe6\xae\x8a\xe5\xad\x97\xe7\xac\xa6\xe5\xaf\xbc\xe8\x87\xb4\xe6\xaf\x8f\xe8\xa1\x8c\xe5\xae\x9e\xe9\x99\x85\xe6\x98\xbe\xe7\xa4\xba\xe9\x95\xbf\xe5\xba\xa6\xe8\xb6\x85\xe5\x87\xba\xe9\x99\x90\xe5\xae\x9a\xe5\x80\xbc\xef\xbc\x8c\xe8\x99\xbd\xe7\x84\xb6\xe8\xbf\x98\xe6\x98\xaf\xe4\xb8\x8d\xe7\xb2\xbe\xe7\xa1\xae\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe4\xb8\x8d\xe4\xbc\x9a\xe8\xb6\x85\xe5\x87\xba\xe9\x99\x90\xe5\xae\x9a\xe5\x80\xbc\xe3\x80\x82\n    # \xe6\xaf\x94\xe5\xa6\x82\xef\xbc\x9a\n    # \'\xc2\xb0\'\xe5\x9c\xa8\xe8\xae\xb0\xe4\xba\x8b\xe6\x9c\xac\xe4\xb8\xad\xe6\x98\xbe\xe7\xa4\xba\xe5\x8d\xa02\xe6\xa0\xbc\xef\xbc\x8cb\'\\xc2\\xb0\'utf-8\xe7\xbc\x96\xe7\xa0\x81\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba2\xe3\x80\x82\n    # \'\xef\xbf\xbd\'\xe5\x9c\xa8\xe8\xae\xb0\xe4\xba\x8b\xe6\x9c\xac\xe4\xb8\xad\xe6\x98\xbe\xe7\xa4\xba\xe5\x8d\xa01\xe6\xa0\xbc\xef\xbc\x8cb\'\\xef\\xbf\\xbd\'utf-8\xe7\xbc\x96\xe7\xa0\x81\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba3\xe3\x80\x82\n    # \'\'\xe5\x9c\xa8\xe8\xae\xb0\xe4\xba\x8b\xe6\x9c\xac\xe4\xb8\xad\xe6\x98\xbe\xe7\xa4\xba\xe5\x8d\xa02\xe6\xa0\xbc\xef\xbc\x8cb\'\\x01\'utf-8\xe7\xbc\x96\xe7\xa0\x81\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba1\xe3\x80\x82\xef\xbc\x88\xe7\x89\xb9\xe6\xae\x8a\xe5\xad\x97\xe7\xac\xa6\xe6\x97\xa0\xe6\xb3\x95\xe6\x98\xbe\xe7\xa4\xba\xef\xbc\x89\n    # \xe8\x87\xb3\xe4\xba\x8e\xe7\x89\xb9\xe6\xae\x8a\'\\t\'\xe5\x88\xb6\xe8\xa1\xa8\xe7\xac\xa6\xe6\x9c\x80\xe5\xa5\xbd\xe6\x9c\x80\xe5\xbc\x80\xe5\xa7\x8b\xe5\xb0\xb1\xe7\x94\xa8\xe5\x9b\x9b\xe4\xb8\xaa\xe7\xa9\xba\xe6\xa0\xbc\xe6\x9b\xbf\xe6\x8d\xa2\xe6\x8e\x89\xef\xbc\x8c\xe9\x81\xbf\xe5\x85\x8d\xe5\x85\xb6\xe8\x87\xaa\xe5\x8a\xa8\xe7\xbc\xa9\xe8\xbf\x9b\xe5\xb8\xa6\xe6\x9d\xa5\xe7\x9a\x84\xe5\xbd\xb1\xe5\x93\x8d\n    \n    return length\n \ndef chinese_linefeed(text,limit):\n    \'\'\'\xe4\xb8\xad\xe8\x8b\xb1\xe6\x96\x87\xe6\xb7\xb7\xe5\x90\x88\xe6\x8e\x92\xe7\x89\x88\xef\xbc\x8c\xe9\x99\x90\xe5\x88\xb6\xe5\x8d\x95\xe8\xa1\x8c\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe8\xb6\x85\xe5\x87\xba\xe9\x95\xbf\xe5\xba\xa6\xe6\x8d\xa2\xe8\xa1\x8c\'\'\'\n    text_format= \'\' # \xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\x98\xe9\x87\x8f\xef\xbc\x8c\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\n    text = text.replace(\'\\t\',\'    \')\n    text = text.replace(\'\\r\\n\',\'\\n\')\n    text_arr = text.split(\'\\n\') # \xe6\x8c\x89\xe8\xa1\x8c\xe5\x88\x86\xe5\x89\xb2\xe6\x96\x87\xe6\x9c\xac\n    for line in text_arr:\n        # \xe9\x80\x90\xe8\xa1\x8c\xe5\xa4\x84\xe7\x90\x86\n        text_format+=\'\\r\\n\'\n        num = 0 # \xe9\x95\xbf\xe5\xba\xa6\xe8\xae\xa1\xe6\x95\xb0\xe5\x8f\x98\xe9\x87\x8f\xef\xbc\x8c\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\n        for i in line:\n            # \xe4\xbb\x8e\xe8\xaf\xa5\xe8\xa1\x8c\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\xe8\xb5\xb7\xe8\xae\xa1\xe7\xae\x97\xe9\x95\xbf\xe5\xba\xa6\n            # \xe4\xb8\xad\xe6\x96\x87\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba2\n            # asc2\xe7\xa0\x81(\xe8\x8b\xb1\xe6\x96\x87\xe5\x8f\x8a\xe5\x85\xb6\xe5\xad\x97\xe7\xac\xa6\xe7\xad\x89)\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba1\n            # \xe5\x85\xb6\xe4\xbb\x96\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba2\xef\xbc\x88\xe4\xb8\x80\xe4\xba\x9b\xe7\x89\xb9\xe6\xae\x8a\xef\xbc\x89\n            if i >= u\'\\u4e00\' and i <= u\'\\u9fa5\':\n                char_len=2\n            elif i >= u\'\\u001c\' and i <= u\'\\u00ff\':\n                char_len=1\n            else:\n                char_len=2\n            # \xe7\xb4\xaf\xe8\xae\xa1\xe9\x95\xbf\xe5\xba\xa6\xe5\xb0\x8f\xe4\xba\x8elimit\xef\xbc\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe4\xbf\x9d\xe5\xad\x98\xe8\x87\xb3\xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\x98\xe9\x87\x8f\xef\xbc\x8c\xe8\xae\xa1\xe6\x95\xb0\xe5\x8f\x98\xe9\x87\x8f\xe7\xb4\xaf\xe5\x8a\xa0\n            # \xe7\xb4\xaf\xe8\xae\xa1\xe9\x95\xbf\xe5\xba\xa6\xe5\xa4\xa7\xe4\xba\x8elimit\xef\xbc\x8c\xe6\x8d\xa2\xe8\xa1\x8c\xe5\x90\x8e\xe5\x86\x8d\xe4\xbf\x9d\xe5\xad\x98\xef\xbc\x8c\xe8\xae\xa1\xe6\x95\xb0\xe5\x8f\x98\xe9\x87\x8f\xe9\x87\x8d\xe7\xbd\xae\n            if num+char_len<=limit:\n                text_format+=i\n                num+=char_len\n            else:\n                text_format+=\'\\r\\n\'+i\n                num=char_len\n    return text_format.strip()\n \n\ndef format_chat_data(infile, outfile):\n    """"""\n    # QQ\xe8\x81\x8a\xe5\xa4\xa9\xe8\xae\xb0\xe5\xbd\x95\xe6\x89\x8b\xe6\x9c\xba\xe7\xab\xaf\xe5\xaf\xbc\xe5\x87\xba\xe6\x96\x87\xe6\x9c\xac\n    """"""\n\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe6\x96\x87\xe4\xbb\xb6\n    fp = codecs.open(infile,\'r\',\'utf-8\')\n    txt = fp.read()\n    fp.close()\n    \n    re_pat = r\'20[\\d-]{8}\\s[\\d:]{7,8}\\s+[^\\n]+(?:\\d{5,11}|@\\w+\\.[comnet]{2,3})\\)\'  # \xe6\xad\xa3\xe5\x88\x99\xe8\xaf\xad\xe5\x8f\xa5\xef\xbc\x8c\xe5\x8c\xb9\xe9\x85\x8d\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\n    log_title_arr = re.findall(re_pat, txt) # \xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe6\x95\xb0\xe7\xbb\x84[\'2016-06-24 15:42:52  \xe5\xbc\xa0\xe6\x9f\x90(40**21)\',\xe2\x80\xa6]\n    log_content_arr = re.split(re_pat, txt) # \xe8\xae\xb0\xe5\xbd\x95\xe5\x86\x85\xe5\xae\xb9\xe6\x95\xb0\xe7\xbb\x84[\'\\n\', \'\\n\xe9\x80\x89\xe4\xbf\xae\xe7\x9a\x84\\n\\n\', \'\\n\xe5\xb0\xb1\xe6\x80\x95\xe8\xbf\x99\xe6\xac\xa1\xe2\x80\xa6]\n    log_content_arr.pop(0)                  # \xe5\x89\x94\xe9\x99\xa4\xe6\x8e\x89\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xef\xbc\x88\xe5\x88\x86\xe5\x89\xb2\xe9\x80\xa0\xe6\x88\x90\xe7\x9a\x84\xe5\x86\x97\xe4\xbd\x99\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x89\n    \n    # \xe6\x95\xb0\xe7\xbb\x84\xe9\x95\xbf\xe5\xba\xa6\n    l1 = len(log_title_arr)\n    l2 = len(log_content_arr)\n    print(\'\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe6\x95\xb0: %d\\n\xe8\xae\xb0\xe5\xbd\x95\xe5\x86\x85\xe5\xae\xb9: %d\'%(l1,l2))\n    \n    if l1==l2:\n        # \xe6\x95\xb4\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84\xe8\xae\xb0\xe5\xbd\x95\n        log_format = \'\'\n        \n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x95\xb4\xe7\x90\x86\n        for i in range(0,l1):\n            title       = log_title_arr[i]                   # \xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\n            content     = log_content_arr[i].strip()         # \xe5\x88\xa0\xe8\xae\xb0\xe5\xbd\x95\xe5\x86\x85\xe5\xae\xb9\xe9\xa6\x96\xe5\xb0\xbe\xe7\xa9\xba\xe7\x99\xbd\xe5\xad\x97\xe7\xac\xa6\n            content     = content.replace(\'\\r\\n\',\'\\n\')       # \xe8\xae\xb0\xe5\xbd\x95\xe4\xb8\xad\xe7\x9a\x84\'\\n\'\xef\xbc\x8c\xe6\x9b\xbf\xe6\x8d\xa2\xe4\xb8\xba\'\\r\\n\'\n            content     = content.replace(\'\\n\',\'\\r\\n\')\n            content     = chinese_linefeed(content,100)      # \xe6\xaf\x8f\xe8\xa1\x8c\xe8\xbf\x87\xe9\x95\xbf\xe8\x87\xaa\xe5\x8a\xa8\xe6\x8d\xa2\xe8\xa1\x8c\n            lastline    = content.split(\'\\r\\n\')[-1]          # \xe5\x8f\x96\xe8\xae\xb0\xe5\xbd\x95\xe5\x86\x85\xe5\xae\xb9\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe8\xa1\x8c\n            length      = length_w(lastline)                 # \xe5\x8f\x96\xe5\x85\xb6\xe9\x95\xbf\xe5\xba\xa6\n            # space = (100-(length%100))*\' \' if length%100!=0 else \'\'# \xe8\xaf\xa5\xe8\xa1\x8c\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe5\x89\x8d\xe8\xa1\xa5\xe7\xa9\xba\xe6\xa0\xbc\xef\xbc\x8c\xe5\x8f\x98\xe6\x95\xb4\xe9\xbd\x90\xe4\xb8\xba100\xe6\x95\xb4\xe6\x95\xb0\xe5\x80\x8d\xef\xbc\x9b\xe4\xbd\x99\xe6\x95\xb0\xe4\xb8\xba0\xe5\x88\x99\xe4\xb8\x8d\xe7\x94\xa8\xe8\xa1\xa5\xe7\xa9\xba\xe6\xa0\xbc\n            space = \' | \' # \xe8\xaf\xa5\xe8\xa1\x8c\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe5\x89\x8d\xe8\xa1\xa5\xe7\xa9\xba\xe6\xa0\xbc\xef\xbc\x8c\xe5\x8f\x98\xe6\x95\xb4\xe9\xbd\x90\xe4\xb8\xba100\xe6\x95\xb4\xe6\x95\xb0\xe5\x80\x8d\xef\xbc\x9b\xe4\xbd\x99\xe6\x95\xb0\xe4\xb8\xba0\xe5\x88\x99\xe4\xb8\x8d\xe7\x94\xa8\xe8\xa1\xa5\xe7\xa9\xba\xe6\xa0\xbc\n            log_format += content + space + \'[\'+title+\']\\r\\n\'# \xe6\x8b\xbc\xe6\x8e\xa5\xe5\x90\x88\xe6\x88\x90\xe8\xae\xb0\xe5\xbd\x95\n    \n        # \xe5\x86\x99\xe5\x88\xb0\xe6\x96\x87\xe4\xbb\xb6\n        fp = codecs.open(outfile, \'w\', \'utf-8\')\n        fp.write(log_format)\n        fp.close()\n    \n        print(""\xe6\x95\xb4\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95~^_^~"")\n    else:\n        print(\'\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\xb4\xe5\x92\x8c\xe8\xae\xb0\xe5\xbd\x95\xe5\x86\x85\xe5\xae\xb9\xe6\x9d\xa1\xe6\x95\xb0\xe4\xb8\x8d\xe5\x8c\xb9\xe9\x85\x8d\xef\xbc\x8c\xe8\xaf\xb7\xe4\xbf\xae\xe6\xad\xa3\xe4\xbb\xa3\xe7\xa0\x81\')\n    \n\ndef split_line(line):\n    l = re.sub(r""[\\[\\]]+"", """", str(line).strip()).split("" | "")\n    if len(l) == 2:\n        content = l[0]\n        names = l[1].split("" "")\n        if names == 3:\n            c_time = names[0] + names[1]\n            c_id = names[2]\n            print([content, c_time, c_id])\n            # return ""%s | %s | %s"" % (content, c_time, c_id)\n            return content\n        return content\n    return """"\n\n\n# Extracts pairs of sentences from conversations\ndef extractSentencePairs(conversation):\n    qa_pairs = []\n    for i in range(len(conversation) - 1):  # We ignore the last line (no answer for it)\n        inputLine = conversation[i].strip()\n        targetLine = conversation[i+1].strip()\n        # Filter wrong samples (if one of the lists is empty)\n        if inputLine and targetLine:\n            qa_pairs.append(""%s | %s"" % (inputLine, targetLine))\n    return qa_pairs\n\n\ndef format_2(infile, outfile):\n    df = pd.read_csv(infile, sep=\'\\00001\', header=None, names=[""txt""])\n    # print(df[""txt""].head(5))\n    df[""content""] = df[""txt""].apply(lambda line: split_line(line))\n    # df.query(""content!=\'\'"")[""content""].to_csv(outfile, sep=""\\t"", header=False, index=False)\n\n    lines = df.query(""content!=\'\'"")[""content""].tolist()\n    # print(lines)\n    chats = extractSentencePairs(lines)\n    df_chats = pd.DataFrame(chats, columns=[\'lines\'])\n    df_chats.to_csv(outfile, sep=""\\t"", header=False, index=False)\n    print("">>> \xe6\x95\xb0\xe6\x8d\xae\xe5\x90\x88\xe5\xb9\xb6\xe6\x88\x90\xe5\x8a\x9f: %s"" % outfile)\n\n\nif __name__ == ""__main__"":\n    infile = r\'data/QQChat/ML_ApacheCN.csv\'\n    outfile_1 = r\'data/QQChat/format_1.csv\'\n    outfile_2 = r\'data/QQChat/format_2.csv\'\n    # format_chat_data(infile, outfile_1)\n    format_2(outfile_1, outfile_2)'"
src/Chinese_ChatBot/run_demo.py,6,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nfrom u_tools import normalizeString, load_model\nfrom u_class import Voc, GreedySearchDecoder\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\nMAX_LENGTH = 50  # Maximum sentence length to consider\n\n\ndef indexesFromSentence(voc, sentence):\n    return [voc.word2index[word] for word in sentence.split(\' \')] + [EOS_token]\n\n\ndef evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n    ### Format input sentence as a batch\n    # words -> indexes\n    indexes_batch = [indexesFromSentence(voc, sentence)]\n    # Create lengths tensor\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    # Transpose dimensions of batch to match models\' expectations\n    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n    # Use appropriate device\n    input_batch = input_batch.to(device)\n    lengths = lengths.to(device)\n    # Decode sentence with searcher\n    tokens, scores = searcher(input_batch, lengths, max_length)\n    # indexes -> words\n    decoded_words = [voc.index2word[token.item()] for token in tokens]\n    return decoded_words\n\n\ndef evaluateInput(encoder, decoder, searcher, voc):\n    input_sentence = \'\'\n    while(1):\n        try:\n            # Get input sentence\n            input_sentence = input(\'> \')\n            # Check if it is quit case\n            if input_sentence == \'q\' or input_sentence == \'quit\': break\n            # Normalize sentence\n            input_sentence = normalizeString(input_sentence)\n            # Evaluate sentence\n            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n            # Format and print response sentence\n            output_words[:] = [x for x in output_words if not (x == \'EOS\' or x == \'PAD\')]\n            # print(\'Bot:\', \' \'.join(output_words))\n            print(\'Bot:\', \'\'.join(output_words))\n\n        except KeyError:\n            print(""Error: Encountered unknown word."")\n\n\nif __name__ == ""__main__"":\n    global device, corpus_name\n    USE_CUDA = torch.cuda.is_available()\n    device = torch.device(""cuda"" if USE_CUDA else ""cpu"")\n    corpus_name = ""Chinese_ChatBot""\n\n\n    # Configure models\n    attn_model = \'dot\'\n    #attn_model = \'general\'\n    #attn_model = \'concat\'\n    hidden_size = 500\n    encoder_n_layers = 2\n    decoder_n_layers = 2\n    dropout = 0.1\n    cp_start_iteration = 0\n    learning_rate = 0.0001\n    decoder_learning_ratio = 5.0\n    n_iteration = 8000\n\n    voc = Voc(corpus_name)\n    loadFilename = ""data/save/cb_model/%s/2-2_500/%s_checkpoint.tar"" % (corpus_name, n_iteration)\n    if os.path.exists(loadFilename):\n        checkpoint = torch.load(loadFilename)\n        voc.__dict__ = checkpoint[\'voc_dict\']\n\n    cp_start_iteration, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding = load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, dropout, learning_rate, decoder_learning_ratio)\n\n    # Use appropriate device\n    encoder = encoder.to(device)\n    decoder = decoder.to(device)\n    # Set dropout layers to eval mode\n    encoder.eval()\n    decoder.eval()\n\n    # Initialize search module\n    searcher = GreedySearchDecoder(encoder, decoder, device)\n\n    # Begin chatting (uncomment and run the following line to begin)\n    evaluateInput(encoder, decoder, searcher, voc)\n'"
src/Chinese_ChatBot/run_train.py,16,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport fire\nimport random\nimport unicodedata\nimport itertools\nimport csv\nimport math\nimport codecs\nimport torch\nimport torch.nn as nn\nfrom u_tools import normalizeString, load_model\nfrom u_class import Voc\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\nMAX_LENGTH = 50  # Maximum sentence length to consider\nMIN_COUNT = 3    # Minimum word count threshold for trimming\n\n\ndef printLines(file, n=10):\n    with open(file, \'rb\') as datafile:\n        lines = datafile.readlines()\n    for line in lines[:n]:\n        print(line)\n\n\ndef indexesFromSentence(voc, sentence):\n    return [voc.word2index[word] for word in sentence.split(\' \')] + [EOS_token]\n\ndef zeroPadding(l, fillvalue=PAD_token):\n    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n\ndef binaryMatrix(l, value=PAD_token):\n    m = []\n    for i, seq in enumerate(l):\n        m.append([])\n        for token in seq:\n            if token == PAD_token:\n                m[i].append(0)\n            else:\n                m[i].append(1)\n    return m\n\n# Returns padded input sequence tensor and lengths\ndef inputVar(l, voc):\n    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    padList = zeroPadding(indexes_batch)\n    padVar = torch.LongTensor(padList)\n    return padVar, lengths\n\n# Returns padded target sequence tensor, padding mask, and max target length\ndef outputVar(l, voc):\n    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n    max_target_len = max([len(indexes) for indexes in indexes_batch])\n    padList = zeroPadding(indexes_batch)\n    mask = binaryMatrix(padList)\n    mask = torch.ByteTensor(mask)\n    padVar = torch.LongTensor(padList)\n    return padVar, mask, max_target_len\n\n\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96Voc\xe5\xaf\xb9\xe8\xb1\xa1 \xe5\x92\x8c \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96pairs\xe5\xaf\xb9\xe8\xaf\x9d\xe5\xad\x98\xe6\x94\xbe\xe5\x88\xb0list\xe4\xb8\xad\ndef readVocs(datafile):\n    print(""Reading lines..."")\n    # Read the file and split into lines\n    lines = open(datafile, encoding=\'utf-8\').read().strip().split(\'\\n\')\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split(\' | \')] for l in lines]\n    return pairs\n\n\n# \xe5\xa6\x82\xe6\x9e\x9c\xe5\xaf\xb9 \'p\' \xe4\xb8\xad\xe7\x9a\x84\xe4\xb8\xa4\xe4\xb8\xaa\xe5\x8f\xa5\xe5\xad\x90\xe9\x83\xbd\xe4\xbd\x8e\xe4\xba\x8e MAX_LENGTH \xe9\x98\x88\xe5\x80\xbc\xef\xbc\x8c\xe5\x88\x99\xe8\xbf\x94\xe5\x9b\x9eTrue\ndef filterPair(p):\n    # Input sequences need to preserve the last word for EOS token\n    return len(p[0].split(\' \')) < MAX_LENGTH and len(p[1].split(\' \')) < MAX_LENGTH\n\n\n# \xe8\xbf\x87\xe6\xbb\xa4\xe6\xbb\xa1\xe8\xb6\xb3\xe6\x9d\xa1\xe4\xbb\xb6\xe7\x9a\x84 pairs \xe5\xaf\xb9\xe8\xaf\x9d\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe4\xb8\x8a\xe9\x9d\xa2\xe5\xae\x9a\xe4\xb9\x89\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x80\xe4\xb8\xaa\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84voc\xe5\xaf\xb9\xe8\xb1\xa1\xe5\x92\x8c\xe5\xaf\xb9\xe5\x88\x97\xe8\xa1\xa8\ndef loadPrepareData(corpus, corpus_name, datafile, voc, save_dir):\n    print(""Start preparing training data ..."")\n    pairs = readVocs(datafile)\n    print(""Read {!s} sentence pairs"".format(len(pairs)))\n    pairs = filterPairs(pairs)\n    print(""Trimmed to {!s} sentence pairs"".format(len(pairs)))\n    print(""Counting words..."")\n    for pair in pairs:\n        voc.addSentence(pair[0])\n        voc.addSentence(pair[1])\n    print(""Counted words:"", voc.num_words)\n    return voc, pairs\n\n\n# Returns all items for a given batch of pairs\ndef batch2TrainData(voc, pair_batch):\n    pair_batch.sort(key=lambda x: len(x[0].split("" "")), reverse=True)\n    input_batch, output_batch = [], []\n    for pair in pair_batch:\n        input_batch.append(pair[0])\n        output_batch.append(pair[1])\n    inp, lengths = inputVar(input_batch, voc)\n    output, mask, max_target_len = outputVar(output_batch, voc)\n    return inp, lengths, output, mask, max_target_len\n\n\ndef trimRareWords(voc, pairs, MIN_COUNT):\n    # Trim words used under the MIN_COUNT from the voc\n    voc.trim(MIN_COUNT)\n    # Filter out pairs with trimmed words\n    keep_pairs = []\n    for pair in pairs:\n        input_sentence = pair[0]\n        output_sentence = pair[1]\n        keep_input = True\n        keep_output = True\n        # Check input sentence\n        for word in input_sentence.split(\' \'):\n            if word not in voc.word2index:\n                keep_input = False\n                break\n        # Check output sentence\n        for word in output_sentence.split(\' \'):\n            if word not in voc.word2index:\n                keep_output = False\n                break\n\n        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n        if keep_input and keep_output:\n            keep_pairs.append(pair)\n\n    print(""Trimmed from {} pairs to {}, {:.4f} of total"".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n    return keep_pairs\n\n\ndef maskNLLLoss(inp, target, mask):\n    nTotal = mask.sum()\n    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n    loss = crossEntropy.masked_select(mask).mean()\n    loss = loss.to(device)\n    return loss, nTotal.item()\n\n\ndef train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n\n    # Zero gradients\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    # Set device options\n    input_variable = input_variable.to(device)\n    lengths = lengths.to(device)\n    target_variable = target_variable.to(device)\n    mask = mask.to(device)\n\n    # Initialize variables\n    loss = 0\n    print_losses = []\n    n_totals = 0\n\n    # Forward pass through encoder\n    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n\n    # Create initial decoder input (start with SOS tokens for each sentence)\n    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n    decoder_input = decoder_input.to(device)\n\n    # Set initial decoder hidden state to the encoder\'s final hidden state\n    decoder_hidden = encoder_hidden[:decoder.n_layers]\n\n    # Determine if we are using teacher forcing this iteration\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    # Forward batch of sequences through decoder one time step at a time\n    if use_teacher_forcing:\n        for t in range(max_target_len):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            # Teacher forcing: next input is current target\n            decoder_input = target_variable[t].view(1, -1)\n            # Calculate and accumulate loss\n            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n            loss += mask_loss\n            print_losses.append(mask_loss.item() * nTotal)\n            n_totals += nTotal\n    else:\n        for t in range(max_target_len):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            # No teacher forcing: next input is decoder\'s own current output\n            _, topi = decoder_output.topk(1)\n            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n            decoder_input = decoder_input.to(device)\n            # Calculate and accumulate loss\n            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n            loss += mask_loss\n            print_losses.append(mask_loss.item() * nTotal)\n            n_totals += nTotal\n\n    # Perform backpropatation\n    loss.backward()\n\n    # Clip gradients: gradients are modified in place\n    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n\n    # Adjust model weights\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return sum(print_losses) / n_totals\n\n\ndef trainIters(model_name, cp_start_iteration, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name):\n\n    # Load batches for each iteration\n    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_iteration)]\n\n    # Initializations\n    print(\'Initializing ...\')\n    # start_iteration = 1\n    print_loss = 0\n    start_iteration = cp_start_iteration + 1\n\n    # Training loop\n    print(""Training..."")\n    for iteration in range(start_iteration, n_iteration+1):\n        training_batch = training_batches[iteration-1]\n        # Extract fields from batch\n        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n\n        # Run a training iteration with batch\n        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n        print_loss += loss\n\n        # Print progress\n        if iteration % print_every == 0:\n            print_loss_avg = print_loss / print_every\n            print(""Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}"".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n            print_loss = 0\n\n        # Save checkpoint\n        if (iteration % save_every == 0):\n            directory = os.path.join(save_dir, model_name, corpus_name, \'{}-{}_{}\'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n            if not os.path.exists(directory):\n                os.makedirs(directory)\n            torch.save({\n                \'iteration\': iteration,\n                \'state_dict_en\': encoder.state_dict(),\n                \'state_dict_de\': decoder.state_dict(),\n                \'state_dict_en_opt\': encoder_optimizer.state_dict(),\n                \'state_dict_de_opt\': decoder_optimizer.state_dict(),\n                \'loss\': loss,\n                \'voc_dict\': voc.__dict__,\n                \'embedding\': embedding.state_dict()\n            }, os.path.join(directory, \'{}_{}.tar\'.format(iteration, \'checkpoint\')))\n\n\ndef TrainModel():\n    global device, corpus_name\n    USE_CUDA = torch.cuda.is_available()\n    device = torch.device(""cuda"" if USE_CUDA else ""cpu"")\n\n    corpus_name = ""Chinese_ChatBot""\n    corpus = os.path.join(""data"", corpus_name)\n    datafile = os.path.join(corpus, ""format_data.csv"")\n    save_dir = os.path.join(""data"", ""save"")\n    \n    global teacher_forcing_ratio, hidden_size\n    # Configure models\n    model_name = \'cb_model\'\n    attn_model = \'dot\'\n    #attn_model = \'general\'\n    #attn_model = \'concat\'\n    hidden_size = 500\n    encoder_n_layers = 2\n    decoder_n_layers = 2\n    dropout = 0.1\n    cp_start_iteration = 0\n    learning_rate = 0.0001\n    decoder_learning_ratio = 5.0\n    teacher_forcing_ratio = 1.0\n    clip = 50.0\n    print_every = 1\n    batch_size = 64\n    save_every = 1000\n    n_iteration = 8000\n\n    voc = Voc(corpus_name)\n    loadFilename = ""data/save/cb_model/%s/2-2_500/5000_checkpoint.tar"" % (corpus_name)\n    if os.path.exists(loadFilename):\n        checkpoint = torch.load(loadFilename)\n        voc.__dict__ = checkpoint[\'voc_dict\']\n\n    # Load/Assemble voc and pairs\n    voc, pairs = loadPrepareData(corpus, corpus_name, datafile, voc, save_dir)\n    # Print some pairs to validate\n    print(""\\npairs:"")\n    for pair in pairs[:10]:\n        print(pair)\n\n    # Trim voc and pairs\n    pairs = trimRareWords(voc, pairs, MIN_COUNT)\n\n    # # Example for validation\n    # small_batch_size = 5\n    # batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n    # input_variable, lengths, target_variable, mask, max_target_len = batches\n    # print(""input_variable:"", input_variable)\n    # print(""lengths:"", lengths)\n    # print(""target_variable:"", target_variable)\n    # print(""mask:"", mask)\n    # print(""max_target_len:"", max_target_len)\n\n    cp_start_iteration, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding = load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, dropout, learning_rate, decoder_learning_ratio)\n    \n    # Use appropriate device\n    encoder = encoder.to(device)\n    decoder = decoder.to(device)\n    for state in encoder_optimizer.state.values():\n        for k, v in state.items():\n            if isinstance(v, torch.Tensor):\n                state[k] = v.cuda()\n\n    for state in decoder_optimizer.state.values():\n        for k, v in state.items():\n            if isinstance(v, torch.Tensor):\n                state[k] = v.cuda()\n\n    # Ensure dropout layers are in train mode\n    encoder.train()\n    decoder.train()\n\n    print(""Starting Training!"")\n    trainIters(model_name, cp_start_iteration, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name)\n\n\nif __name__ == ""__main__"":\n    fire.Fire()\n'"
src/Chinese_ChatBot/u_class.py,20,"b'#!/usr/bin/python\n# coding: utf-8\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\n\n\nclass Voc:\n    def __init__(self, name):\n        self.name = name\n        self.trimmed = False\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: ""PAD"", SOS_token: ""SOS"", EOS_token: ""EOS""}\n        self.num_words = 3  # Count SOS, EOS, PAD\n\n    def addSentence(self, sentence):\n        for word in sentence.split(\' \'):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.num_words\n            self.word2count[word] = 1\n            self.index2word[self.num_words] = word\n            self.num_words += 1\n        else:\n            self.word2count[word] += 1\n\n    # Remove words below a certain count threshold\n    def trim(self, min_count):\n        if self.trimmed:\n            return\n        self.trimmed = True\n\n        keep_words = []\n\n        for k, v in self.word2count.items():\n            if v >= min_count:\n                keep_words.append(k)\n\n        print(\'keep_words {} / {} = {:.4f}\'.format(\n            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n        ))\n\n        # Reinitialize dictionaries\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: ""PAD"", SOS_token: ""SOS"", EOS_token: ""EOS""}\n        self.num_words = 3 # Count default tokens\n\n        for word in keep_words:\n            self.addWord(word)\n\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n        super(EncoderRNN, self).__init__()\n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        self.embedding = embedding\n\n        # Initialize GRU; the input_size and hidden_size params are both set to \'hidden_size\'\n        #   because our input size is a word embedding with number of features == hidden_size\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n\n    def forward(self, input_seq, input_lengths, hidden=None):\n        # Convert word indexes to embeddings\n        embedded = self.embedding(input_seq)\n        # Pack padded batch of sequences for RNN module\n        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n        # Forward pass through GRU\n        outputs, hidden = self.gru(packed, hidden)\n        # Unpack padding\n        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n        # Sum bidirectional GRU outputs\n        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n        # Return output and final hidden state\n        return outputs, hidden\n\n\n# Luong attention layer\nclass Attn(nn.Module):\n    def __init__(self, method, hidden_size):\n        super(Attn, self).__init__()\n        self.method = method\n        if self.method not in [\'dot\', \'general\', \'concat\']:\n            raise ValueError(self.method, ""is not an appropriate attention method."")\n        self.hidden_size = hidden_size\n        if self.method == \'general\':\n            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n        elif self.method == \'concat\':\n            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n\n    def dot_score(self, hidden, encoder_output):\n        return torch.sum(hidden * encoder_output, dim=2)\n\n    def general_score(self, hidden, encoder_output):\n        energy = self.attn(encoder_output)\n        return torch.sum(hidden * energy, dim=2)\n\n    def concat_score(self, hidden, encoder_output):\n        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n        return torch.sum(self.v * energy, dim=2)\n\n    def forward(self, hidden, encoder_outputs):\n        # Calculate the attention weights (energies) based on the given method\n        if self.method == \'general\':\n            attn_energies = self.general_score(hidden, encoder_outputs)\n        elif self.method == \'concat\':\n            attn_energies = self.concat_score(hidden, encoder_outputs)\n        elif self.method == \'dot\':\n            attn_energies = self.dot_score(hidden, encoder_outputs)\n\n        # Transpose max_length and batch_size dimensions\n        attn_energies = attn_energies.t()\n\n        # Return the softmax normalized probability scores (with added dimension)\n        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n\n\nclass LuongAttnDecoderRNN(nn.Module):\n    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n        super(LuongAttnDecoderRNN, self).__init__()\n\n        # Keep for reference\n        self.attn_model = attn_model\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.dropout = dropout\n\n        # Define layers\n        self.embedding = embedding\n        self.embedding_dropout = nn.Dropout(dropout)\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n\n        self.attn = Attn(attn_model, hidden_size)\n\n    def forward(self, input_step, last_hidden, encoder_outputs):\n        # Note: we run this one step (word) at a time\n        # Get embedding of current input word\n        embedded = self.embedding(input_step)\n        embedded = self.embedding_dropout(embedded)\n        # Forward through unidirectional GRU\n        rnn_output, hidden = self.gru(embedded, last_hidden)\n        # Calculate attention weights from the current GRU output\n        attn_weights = self.attn(rnn_output, encoder_outputs)\n        # Multiply attention weights to encoder outputs to get new ""weighted sum"" context vector\n        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n        # Concatenate weighted context vector and GRU output using Luong eq. 5\n        rnn_output = rnn_output.squeeze(0)\n        context = context.squeeze(1)\n        concat_input = torch.cat((rnn_output, context), 1)\n        concat_output = torch.tanh(self.concat(concat_input))\n        # Predict next word using Luong eq. 6\n        output = self.out(concat_output)\n        output = F.softmax(output, dim=1)\n        # Return output and final hidden state\n        return output, hidden\n\n\nclass GreedySearchDecoder(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super(GreedySearchDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, input_seq, input_length, max_length):\n        # Forward input through encoder model\n        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n        # Prepare encoder\'s final hidden layer to be first hidden input to the decoder\n        decoder_hidden = encoder_hidden[:self.decoder.n_layers]\n        # Initialize decoder input with SOS_token\n        decoder_input = torch.ones(1, 1, device=self.device, dtype=torch.long) * SOS_token\n        # Initialize tensors to append decoded words to\n        all_tokens = torch.zeros([0], device=self.device, dtype=torch.long)\n        all_scores = torch.zeros([0], device=self.device)\n        # Iteratively decode one word token at a time\n        for _ in range(max_length):\n            # Forward pass through decoder\n            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n            # Obtain most likely word token and its softmax score\n            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n            # Record token and score\n            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n            # Prepare current token to be next decoder input (add a dimension)\n            decoder_input = torch.unsqueeze(decoder_input, 0)\n        # Return collections of word tokens and scores\n        return all_tokens, all_scores\n'"
src/Chinese_ChatBot/u_tools.py,2,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom u_class import Voc, EncoderRNN, LuongAttnDecoderRNN\n\n\n# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return \'\'.join(\n        c for c in unicodedata.normalize(\'NFD\', s)\n        if unicodedata.category(c) != \'Mn\'\n    )\n\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r""([.!? ])"", r"" \\1"", s)\n    # s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    s = re.sub(r""[^a-zA-Z.!? \\u4E00-\\u9FA5]+"", r"" "", s)\n    s = re.sub(r""\\s+"", r"" "", s).strip()\n    # \'\xe5\x92\x8b\xe6\xad\xbb ? ? ?\xe7\xba\xa2\xe7\x83\xa7\xe8\xbf\x98\xe6\x98\xaf\xe7\x88\x86\xe7\x82\x92dddd\' > \'\xe5\x92\x8b \xe6\xad\xbb   ?   ?   ? \xe7\xba\xa2 \xe7\x83\xa7 \xe8\xbf\x98 \xe6\x98\xaf \xe7\x88\x86 \xe7\x82\x92 d d d d\'\n    s = "" "".join(list(s))\n    return s\n\n\ndef load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, \n        dropout, learning_rate, decoder_learning_ratio):\n\n    # Load model if a loadFilename is provided\n    if os.path.exists(loadFilename):\n        # If loading on same machine the model was trained on\n        checkpoint = torch.load(loadFilename)\n        cp_start_iteration = checkpoint[\'iteration\']\n        encoder_sd = checkpoint[\'state_dict_en\']\n        decoder_sd = checkpoint[\'state_dict_de\']\n        encoder_optimizer_sd = checkpoint[\'state_dict_en_opt\']\n        decoder_optimizer_sd = checkpoint[\'state_dict_de_opt\']\n        # loss = checkpoint[\'loss\']\n        # voc.__dict__ = checkpoint[\'voc_dict\']\n        embedding_sd = checkpoint[\'embedding\']\n\n    print(\'Building encoder and decoder ...\')\n    # Initialize word embeddings\n    embedding = nn.Embedding(voc.num_words, hidden_size)\n    if os.path.exists(loadFilename):\n        embedding.load_state_dict(embedding_sd)\n\n    print(\'Initialize encoder & decoder models\')\n    encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n    decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n    print(\'Building optimizers ...\')\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n    if os.path.exists(loadFilename):\n        encoder.load_state_dict(encoder_sd)\n        decoder.load_state_dict(decoder_sd)\n        encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n        decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n\n    print(\'Models built and ready to go!\')\n    return cp_start_iteration, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding\n'"
src/PyTorch/CNN-DigitRecognizer.py,11,"b'#!/usr/bin/python\n# coding: utf-8\n\n\'\'\'\nCreated on 2017-05-18\nUpdate  on 2017-11-17\nAuthor: Peter Harrington/1988/\xe7\x89\x87\xe5\x88\xbb\nGitHub: https://github.com/apachecn/AiLearning\nScore : 98.46%\n\'\'\'\n\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\n\ntorch.manual_seed(1)  # reproducible\n\n\nclass CustomedDataSet(Dataset):\n\n    def __init__(self, pd_data, data_type=True):\n        self.data_type = data_type\n        if self.data_type:\n            trainX = pd_data\n            trainY = trainX.label.as_matrix().tolist()\n            trainX = trainX.drop(\'label\', axis=1).as_matrix().reshape(trainX.shape[0], 1, 28, 28)\n            self.datalist = trainX\n            self.labellist = trainY\n        else:\n            testX = pd_data\n            testX = testX.as_matrix().reshape(testX.shape[0], 1, 28, 28)\n            self.datalist = testX\n\n    def __getitem__(self, index):\n        if self.data_type:\n            return torch.Tensor(self.datalist[index].astype(float)), self.labellist[index]\n        else:\n            return torch.Tensor(self.datalist[index].astype(float))\n\n    def __len__(self):\n        return self.datalist.shape[0]\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Sequential(  # input shape (1, 28, 28)\n            # output shape (16, 28, 28)  28=(width+2*padding-kernel_size)/stride+1\n            nn.Conv2d(\n                in_channels=1,    # \xe8\xbe\x93\xe5\x85\xa5\xe4\xbf\xa1\xe5\x8f\xb7\xe7\x9a\x84\xe9\x80\x9a\xe9\x81\x93\xe6\x95\xb0\n                out_channels=16,  # \xe5\x8d\xb7\xe7\xa7\xaf\xe5\x90\x8e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe9\x80\x9a\xe9\x81\x93\xe6\x95\xb0\n                kernel_size=5,    # \xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\xe7\x9a\x84\xe5\xbd\xa2\xe7\x8a\xb6\n                stride=1,         # \xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\xe5\xbe\x97\xe6\xad\xa5\xe9\x95\xbf\n                padding=2,        # \xe5\xa4\x84\xe7\x90\x86\xe8\xbe\xb9\xe7\x95\x8c\xe6\x97\xb6\xe5\x9c\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xbb\xb4\xe5\xba\xa6\xe9\xa6\x96\xe5\xb0\xbe\xe8\xa1\xa50\xe6\x95\xb0\xe9\x87\x8f padding=(kernel_size-1)/2 if stride=1\n            ),\n            nn.ReLU(),  # activation\n            # output shape (16, 14, 14)  14=(width+0*padding-dilation*(kernel_size-1)-1)/stride+1\n            # dilation=1 \xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc\xe4\xb8\xba0\n            nn.MaxPool2d(kernel_size=2, stride=2),  # \xe6\x9c\x80\xe5\xa4\xa7\xe6\xb1\xa0\xe5\x8c\x96\xe6\x93\x8d\xe4\xbd\x9c\xe6\x97\xb6\xe7\x9a\x84\xe7\xaa\x97\xe5\x8f\xa3\xe5\xa4\xa7\xe5\xb0\x8f\n        )\n        # output shape (32, 7, 7)\n        self.conv2 = nn.Sequential(      # input shape (1, 14, 14)\n            nn.Conv2d(16, 32, 5, 1, 2),  # output shape (32, 14, 14)\n            nn.ReLU(),  # activation\n            nn.MaxPool2d(2, 2),\n        )\n        self.out = nn.Linear(32 * 7 * 7, 10)  # fully connected layer, output 10 classes\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        # \xe6\x89\x81\xe5\xb9\xb3\xe5\x8c\x96\xe6\x93\x8d\xe4\xbd\x9c\n        x = x.view(x.size(0), -1)  # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n        output = self.out(x)\n        return output, x  # return x for visualization\n\n\ndef load_data_train():\n    # \xe5\x85\x88\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90 torch \xe8\x83\xbd\xe8\xaf\x86\xe5\x88\xab\xe7\x9a\x84 Dataset\n    pd_train = pd.read_csv(\'/opt/data/kaggle/getting-started/digit-recognizer/train.csv\', header=0)\n\n    # \xe6\x89\xbe\xe5\x88\xb0\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe5\x89\xb2\xe7\x82\xb9\n    row = pd_train.shape[0]\n    split_num = int(TRAIN_TATIO*row)\n\n    pd_data_train = pd_train[:split_num]\n    pd_data_test = pd_train[split_num:]\n    data_train = CustomedDataSet(pd_data_train, data_type=True)\n    data_test = CustomedDataSet(pd_data_test, data_type=True)\n\n    # \xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xbb\xe5\x8f\x96\xe5\x99\xa8 (Data Loader)\n    # Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n    loader_train = DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n    loader_test = DataLoader(dataset=data_test, batch_size=pd_data_test.shape[0], shuffle=True)\n    return loader_train, loader_test\n\n\ndef load_data_pre():\n    pd_pre = pd.read_csv(\'/opt/data/kaggle/getting-started/digit-recognizer/test.csv\', header=0)\n    data_pre = CustomedDataSet(pd_pre, data_type=False)\n    loader_pre = DataLoader(dataset=data_pre, batch_size=BATCH_SIZE, shuffle=True)\n    return loader_pre\n\n\ndef optimizer_lossfunction(cnn):\n    \'\'\'\n    3. \xe8\xae\xbe\xe7\xbd\xae\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\xe5\x92\x8c\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n    \'\'\'\n    # optimizer \xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8 \xe6\x98\xaf\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xb7\xa5\xe5\x85\xb7\xef\xbc\x8clr\xe8\xa1\xa8\xe7\xa4\xba\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\n    \'\'\'\n    lr\n    >>> # lr = 0.05     if epoch < 30\n    >>> # lr = 0.005    if 30 <= epoch < 80\n    >>> # lr = 0.0005   if epoch >= 80\n    Adam \xe5\xa5\xbd\xe5\x83\x8f\xe6\xb2\xa1\xe8\xbf\x99\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0 -> momentum \xe5\x8a\xa8\xe9\x87\x8f\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a \xe8\xae\xa1\xe7\xae\x97\xe9\x80\x9f\xe5\xba\xa6\xe6\x9b\xb4\xe6\x96\xb0\xef\xbc\x8c\xe4\xbc\x98\xe5\x8c\x96\xe6\x94\xb6\xe6\x95\x9b\xe9\x80\x9f\xe5\xba\xa6\n    \'\'\'\n    optimizer = torch.optim.Adam(cnn.parameters(), lr=LR, betas=(0.9, 0.99))  # optimize all cnn parameters\n    loss_func = nn.CrossEntropyLoss()  # the target label is not one-hotted\n    return optimizer, loss_func\n\n\ndef show(last_layer, y_test):\n    try:\n        from sklearn.manifold import TSNE\n        HAS_SK = True\n    except:\n        HAS_SK = False\n        print(\'Please install sklearn for layer visualization\')\n\n    if HAS_SK:\n        # Visualization of trained flatten layer (T-SNE)\n        tsne = TSNE(perplexity=30, n_components=2, init=\'pca\', n_iter=5000)\n        plot_only = 500\n        low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])\n        labels = y_test.numpy()[:plot_only]\n        plot_with_labels(low_dim_embs, labels)\n\n\ndef plot_with_labels(lowDWeights, labels):\n    plt.cla()\n    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n    for x, y, s in zip(X, Y, labels):\n        from matplotlib import cm\n        c = cm.rainbow(int(255 * s / 9))\n        plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n    plt.xlim(X.min(), X.max())\n    plt.ylim(Y.min(), Y.max())\n    plt.title(\'Visualize last layer\')\n    plt.show()\n    plt.pause(0.01)\n\n\ndef train_model(cnn, optimizer, loss_func, loader_train, loader_test):\n    plt.ion()\n    # Hyper Parameters\n    EPOCH = 10  # train the training data n times, to save time, we just train 1 epoch\n    # training and testing\n    for epoch in range(EPOCH):\n        num = 0\n        # gives batch data, normalize x when iterate train_loader\n        for step, (x, y) in enumerate(loader_train):\n            b_x = Variable(x)  # batch x\n            b_y = Variable(y)  # batch y\n\n            output = cnn(b_x)[0]  # cnn output\n            loss = loss_func(output, b_y)  # cross entropy loss\n            optimizer.zero_grad()  # clear gradients for this training step\n            loss.backward()  # backpropagation, compute gradients\n            optimizer.step()  # apply gradients\n\n            # print(\'-\'*30, step)\n            if step % 50 == 0:\n                num += 1\n                for _, (x_t, y_test) in enumerate(loader_test):\n                    x_test = Variable(x_t)  # batch x\n                    test_output, last_layer = cnn(x_test)\n                    pred_y = torch.max(test_output, 1)[1].data.squeeze()\n                    accuracy = sum(pred_y == y_test) / float(y_test.size(0))\n                    print(\'Epoch: \', epoch, \'| Num: \',  num, \'| Step: \',  step, \'| train loss: %.4f\' % loss.data[0], \'| test accuracy: %.4f\' % accuracy)\n                    # \xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\xe5\xb1\x95\xe7\x8e\xb0\n                    show(last_layer, y_test)\n    plt.ioff()\n    return cnn\n\n\ndef model_train():\n    # 1.\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x95\xb0\xe6\x8d\xae\n    loader_train, loader_test = load_data_train()\n\n    # 2.\xe5\x88\x9b\xe5\xbb\xbaCNN\xe6\xa8\xa1\xe5\x9e\x8b\n    cnn = CNN()\n    print(cnn)  # net architecture\n\n    # 3. \xe8\xae\xbe\xe7\xbd\xae\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\xe5\x92\x8c\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n    optimizer, loss_func = optimizer_lossfunction(cnn)\n\n    # 4. \xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\n    cnn = train_model(cnn, optimizer, loss_func, loader_train, loader_test)\n    return cnn\n\n\ndef prediction(cnn, loader_pre):\n    # print 10 predictions from test data\n    for step, (x, y) in enumerate(loader_pre):\n        b_x = Variable(x)  # batch x\n        test_output, _ = cnn(b_x)\n\n        pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n        print(pred_y, \'prediction number\')\n\n    return pred_y\n\n\nif __name__ == ""__main__"":\n    global BATCH_SIZE, TRAIN_TATIO, LR, momentum\n    BATCH_SIZE = 50\n    TRAIN_TATIO = 0.8\n    LR = 0.0001  # learning rate\n\n    # \xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\n    file_path = \'/opt/data/kaggle/getting-started/digit-recognizer/net.pkl\'\n    cnn = model_train()\n    torch.save(cnn, file_path)\n\n    # # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\n    # loader_pre = load_data_pre()\n    # cnn = torch.load(file_path)\n    # pre_data = prediction(cnn)\n'"
src/PyTorch/LinearRegression.py,11,"b""# coding: utf-8\n\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\n\n# torch.linspace \xe8\xa1\xa8\xe7\xa4\xba\xe5\x9c\xa8 -1\xe5\x92\x8c1\xe4\xb9\x8b\xe9\x97\xb4\xe7\xad\x89\xe8\xb7\x9d\xe9\x87\x87\xe5\x8f\x96100\xe5\x90\x84\xe7\x82\xb9 \n# torch.unsqueeze \xe8\xa1\xa8\xe7\xa4\xba\xe5\xaf\xb9\xe8\x80\x81\xe7\x9a\x84tensor\xe5\xae\x9a\xe4\xbd\x8d\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe6\x96\xb9\xe5\x90\x91\xef\xbc\x8cdim\xe8\xa1\xa8\xe7\xa4\xba\xe4\xbb\xa5\xe8\xa1\x8c/\xe5\x88\x97\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe8\xbe\x93\xe5\x87\xba\nx = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1)  # x data (tensor), shape=(100, 1)\ny = x.pow(2) + 0.2*torch.rand(x.size())                 # noisy y data (tensor), shape=(100, 1)\n\n# # \xe7\x94\xa8 Variable \xe6\x9d\xa5\xe4\xbf\xae\xe9\xa5\xb0\xe8\xbf\x99\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae tensor\nx, y = Variable(x), Variable(y)\n\n# # \xe7\x94\xbb\xe5\x9b\xbe\n# # scatter \xe6\x89\x93\xe5\x8d\xb0\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\n# plt.scatter(x.data.numpy(), y.data.numpy())\n# plt.show()\n\n\n# \xe7\xbb\xa7\xe6\x89\xbf torch \xe7\x9a\x84 Model\nclass Net(torch.nn.Module):\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96-\xe6\x90\xad\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\xb1\x82\xe6\x89\x80\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe4\xbf\xa1\xe6\x81\xaf\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        # \xe5\xae\x9a\xe4\xb9\x89\xe6\xaf\x8f\xe5\xb1\x82\xe7\x94\xa8\xe4\xbb\x80\xe4\xb9\x88\xe6\xa0\xb7\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n        self.predict = torch.nn.Linear(n_hidden, n_output)\n\n    # \xe6\x90\xad\xe5\xbb\xba-\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x89\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\n    def forward(self, x):\n        # \xe9\x9a\x90\xe8\x97\x8f\xe5\xb1\x82-\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x88\xe8\xbe\x93\xe5\x85\xa5\xe5\x8a\xa0\xe6\x9d\x83\xe3\x80\x81\xe6\xbf\x80\xe6\xb4\xbb\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x89\n        x_h_o = F.relu(self.hidden(x))\n        # \xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82-\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x88\xe8\xbe\x93\xe5\x85\xa5\xe5\x8a\xa0\xe6\x9d\x83\xef\xbc\x89\n        y = self.predict(x_h_o)\n        return y\n\n\nnet = Net(n_feature=1, n_hidden=10, n_output=1)\nprint(net)\n\n\n# optimizer \xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8 \xe6\x98\xaf\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xb7\xa5\xe5\x85\xb7\xef\xbc\x8clr\xe8\xa1\xa8\xe7\xa4\xba\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\n'''\n>>> # lr = 0.05     if epoch < 30\n>>> # lr = 0.005    if 30 <= epoch < 80\n>>> # lr = 0.0005   if epoch >= 80\n'''\n# \xe4\xbc\xa0\xe5\x85\xa5 net \xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0, \xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\xef\xbc\x88\xe4\xbe\x8b\xe5\xa6\x82\xef\xbc\x9a\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87<=1, \xe5\xa6\x82\xe6\x9e\x9c\xe5\x80\xbc\xe8\xbf\x87\xe9\xab\x98\xef\xbc\x8c\xe9\x80\x9f\xe5\xba\xa6\xe4\xbc\x9a\xe5\xbe\x88\xe5\xbf\xab\xef\xbc\x8c\xe4\xbd\x86\xe5\xae\xb9\xe6\x98\x93\xe5\xbf\xbd\xe8\xa7\x86\xe7\x9f\xa5\xe8\xaf\x86\xe7\x82\xb9\xef\xbc\x89\noptimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n# \xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\nloss_func = torch.nn.MSELoss()      # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe8\xae\xa1\xe7\xae\x97\xe5\x85\xac\xe5\xbc\x8f (\xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae)\n\nplt.ion()   # \xe7\x94\xbb\xe5\x9b\xbe\n\nfor t in range(100):\n    prediction = net(x)     # \xe5\x96\x82\xe7\xbb\x99 net \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae x, \xe8\xbe\x93\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\n    # \xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae\n    loss = loss_func(prediction, y)     # \xe8\xae\xa1\xe7\xae\x97\xe4\xb8\xa4\xe8\x80\x85\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\n\n    optimizer.zero_grad()   # \xe6\xb8\x85\xe7\xa9\xba\xe4\xb8\x8a\xe4\xb8\x80\xe6\xad\xa5\xe7\x9a\x84\xe6\xae\x8b\xe4\xbd\x99\xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\xe5\x80\xbc\n    loss.backward()         # \xe8\xaf\xaf\xe5\xb7\xae\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad, \xe8\xae\xa1\xe7\xae\x97\xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\xe5\x80\xbc\n    optimizer.step()        # \xe5\xb0\x86\xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\xe5\x80\xbc\xe6\x96\xbd\xe5\x8a\xa0\xe5\x88\xb0 net \xe7\x9a\x84 parameters \xe4\xb8\x8a\n\n    # \xe6\x8e\xa5\xe7\x9d\x80\xe4\xb8\x8a\xe9\x9d\xa2\xe6\x9d\xa5\n    if t % 5 == 0:\n        # plot and show learning process\n        plt.cla()\n        plt.scatter(x.data.numpy(), y.data.numpy())\n        plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)\n        plt.text(0.5, 0, 'Loss=%.4f' % loss.data[0], fontdict={'size': 20, 'color':  'red'})\n        # \xe5\x88\xb7\xe6\x96\xb0\xe9\xa2\x91\xe7\x8e\x87\n        plt.pause(0.1)\n\nplt.ioff()\nplt.show()\n"""
src/PyTorch/LogisticRegression.py,21,"b'# coding: utf-8\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn.functional as F  # \xe6\xbf\x80\xe5\x8a\xb1\xe5\x87\xbd\xe6\x95\xb0\xe9\x83\xbd\xe5\x9c\xa8\xe8\xbf\x99\nfrom torch.autograd import Variable\n\n# \xe5\x81\x87\xe6\x95\xb0\xe6\x8d\xae\nn_data = torch.ones(100, 2)  # \xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x9f\xba\xe6\x9c\xac\xe5\xbd\xa2\xe6\x80\x81 shape=(100, 2) \xe6\x95\xb0\xe5\x80\xbc\xe9\x83\xbd\xe4\xb8\xba1\nx0 = torch.normal(2 * n_data, 1)  # \xe7\xb1\xbb\xe5\x9e\x8b0 x data (tensor), shape=(100, 2)\ny0 = torch.zeros(100)  # \xe7\xb1\xbb\xe5\x9e\x8b0 y data (tensor), shape=(100, 1)\nx1 = torch.normal(-2 * n_data, 1)  # \xe7\xb1\xbb\xe5\x9e\x8b1 x data (tensor), shape=(100, 2)\ny1 = torch.ones(100)  # \xe7\xb1\xbb\xe5\x9e\x8b1 y data (tensor), shape=(100, 1)\n\n# \xe6\xb3\xa8\xe6\x84\x8f x, y \xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\xa2\xe5\xbc\x8f\xe6\x98\xaf\xe4\xb8\x80\xe5\xae\x9a\xe8\xa6\x81\xe5\x83\x8f\xe4\xb8\x8b\xe9\x9d\xa2\xe4\xb8\x80\xe6\xa0\xb7 (torch.cat \xe6\x98\xaf\xe5\x9c\xa8\xe5\x90\x88\xe5\xb9\xb6\xe6\x95\xb0\xe6\x8d\xae, \xe9\xbb\x98\xe8\xae\xa4\xe6\x98\xaf0\xef\xbc\x8c0\xe8\xa1\xa8\xe7\xa4\xba\xe8\xbf\xbd\xe5\x8a\xa0\xe8\xa1\x8c)\nx = torch.cat(\n    (x0, x1), 0).type(torch.FloatTensor)  # FloatTensor = 32-bit floating\ny = torch.cat((y0, y1), ).type(torch.LongTensor)  # LongTensor = 64-bit integer\n\n# torch \xe5\x8f\xaa\xe8\x83\xbd\xe5\x9c\xa8 Variable \xe4\xb8\x8a\xe8\xae\xad\xe7\xbb\x83, \xe6\x89\x80\xe4\xbb\xa5\xe6\x8a\x8a\xe5\xae\x83\xe4\xbb\xac\xe5\x8f\x98\xe6\x88\x90 Variable\nx, y = Variable(x), Variable(y)\n\nprint(zip(x0, y0))\nprint(\'00\', 20)\nprint(zip(x1, y1))\n\n# # \xe7\x94\xbb\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\n# # s\xe8\xa1\xa8\xe7\xa4\xbasize\xe5\xa4\xa7\xe5\xb0\x8f\n# # c\xe8\xa1\xa8\xe7\xa4\xba\xe9\xa2\x9c\xe8\x89\xb2\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\xe4\xba\x8e\xe4\xb8\x8d\xe5\x90\x8c\xe7\xbb\x84\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\n# # lw\xe8\xa1\xa8\xe7\xa4\xba\xe6\xa0\x87\xe8\xae\xb0\xe8\xbe\xb9\xe7\xbc\x98\xe7\x9a\x84\xe7\xba\xbf\xe5\xae\xbd\xe3\x80\x82\xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x9a\xe9\xbb\x98\xe8\xae\xa4\xe7\x9a\x84\xe8\xbe\xb9\xe6\xa1\x86\xe9\xa2\x9c\xe8\x89\xb2 \xe6\x98\xaf\'face\'\n# plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=y.data.numpy(), s=100, lw=0, cmap=\'RdYlGn\')\n# plt.show()\n\n\n# \xe5\x88\x9b\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f1\xef\xbc\x9a\xe5\x8f\xaf\xe4\xbb\xa5\xe6\x89\x8b\xe5\x8a\xa8\xe7\x9a\x84\xe6\x9d\xa5\xe5\xae\x9a\xe4\xb9\x89\xe6\xbf\x80\xe5\x8a\xb1\xe5\x87\xbd\xe6\x95\xb0\nclass Net(torch.nn.Module):  # \xe7\xbb\xa7\xe6\x89\xbf torch \xe7\x9a\x84 Module\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()  # \xe7\xbb\xa7\xe6\x89\xbf __init__ \xe5\x8a\x9f\xe8\x83\xbd\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)  # \xe9\x9a\x90\xe8\x97\x8f\xe5\xb1\x82\xe7\xba\xbf\xe6\x80\xa7\xe8\xbe\x93\xe5\x87\xba\n        self.out = torch.nn.Linear(n_hidden, n_output)  # \xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe7\xba\xbf\xe6\x80\xa7\xe8\xbe\x93\xe5\x87\xba\n\n    def forward(self, x):\n        # \xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe8\xbe\x93\xe5\x85\xa5\xe5\x80\xbc, \xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x88\x86\xe6\x9e\x90\xe5\x87\xba\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\n        x_h_o = F.relu(self.hidden(x))  # \xe6\xbf\x80\xe5\x8a\xb1\xe5\x87\xbd\xe6\x95\xb0(\xe9\x9a\x90\xe8\x97\x8f\xe5\xb1\x82\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe5\x80\xbc)\n        y = self.out(x_h_o)  # \xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc, \xe4\xbd\x86\xe6\x98\xaf\xe8\xbf\x99\xe4\xb8\xaa\xe4\xb8\x8d\xe6\x98\xaf\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc, \xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe8\xbf\x98\xe9\x9c\x80\xe8\xa6\x81\xe5\x86\x8d\xe5\x8f\xa6\xe5\xa4\x96\xe8\xae\xa1\xe7\xae\x97\n        return y\n\n\nnet1 = Net(n_feature=2, n_hidden=10, n_output=2)  # \xe5\x87\xa0\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe5\xb0\xb1\xe5\x87\xa0\xe4\xb8\xaa output\n\n# # \xe5\x88\x9b\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f2\xef\xbc\x9a\xe5\xae\x83\xe5\xae\x9a\xe4\xb9\x89\xe5\xa5\xbd\xe4\xba\x86\xe6\xbf\x80\xe5\x8a\xb1\xe5\x87\xbd\xe6\x95\xb0\n# net2 = torch.nn.Sequential(\n#     torch.nn.Linear(1, 10),\n#     torch.nn.ReLU(),\n#     torch.nn.Linear(10, 1)\n# )\n\n# # net1 \xe5\x92\x8c net2 \xe6\x95\x88\xe6\x9e\x9c\xe6\x98\xaf\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\nprint(\'net1:\\n\', net1)  # net1 \xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\n# print(\'net2:\\n\', net2)  # net2 \xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\n# """"""\n# net1:\n#  Net (\n#   (hidden): Linear (2 -> 10)\n#   (out): Linear (10 -> 2)\n# )\n# net2:\n#  Sequential (\n#   (0): Linear (1 -> 10)\n#   (1): ReLU ()\n#   (2): Linear (10 -> 1)\n# )\n# """"""\n\n# optimizer \xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8 \xe6\x98\xaf\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xb7\xa5\xe5\x85\xb7\xef\xbc\x8clr\xe8\xa1\xa8\xe7\xa4\xba\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\n\'\'\'\n>>> # lr = 0.05     if epoch < 30\n>>> # lr = 0.005    if 30 <= epoch < 80\n>>> # lr = 0.0005   if epoch >= 80\n\'\'\'\noptimizer = torch.optim.SGD(net1.parameters(), lr=0.02)  # \xe4\xbc\xa0\xe5\x85\xa5 net \xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0, \xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\n# \xe7\xae\x97\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99, \xe6\xb3\xa8\xe6\x84\x8f\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc!\xe4\xb8\x8d\xe6\x98\xaf! one-hot \xe5\xbd\xa2\xe5\xbc\x8f\xe7\x9a\x84, \xe8\x80\x8c\xe6\x98\xaf1D Tensor, (batch,)\n# \xe4\xbd\x86\xe6\x98\xaf\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe6\x98\xaf2D tensor (batch, n_classes)\nloss_func = torch.nn.CrossEntropyLoss()\n\nplt.ion()   # \xe7\x94\xbb\xe5\x9b\xbe\n\nfor t in range(100):\n    out = net1(x)     # \xe5\x96\x82\xe7\xbb\x99 net \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae x, \xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe6\x9e\x90\xe5\x80\xbc\n    # \xe4\xba\xa4\xe5\x8f\x89\xe7\x86\xb5\n    loss = loss_func(out, y)     # \xe8\xae\xa1\xe7\xae\x97\xe4\xb8\xa4\xe8\x80\x85\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\n\n    optimizer.zero_grad()   # \xe6\xb8\x85\xe7\xa9\xba\xe4\xb8\x8a\xe4\xb8\x80\xe6\xad\xa5\xe7\x9a\x84\xe6\xae\x8b\xe4\xbd\x99\xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\xe5\x80\xbc\xef\xbc\x88\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe8\xaf\xb4\xef\xbc\x9a\xe6\xb8\x85\xe9\x99\xa4\xe6\x89\x80\xe6\x9c\x89\xe4\xbc\x98\xe5\x8c\x96\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xe6\xa2\xaf\xe5\xba\xa6\xe3\x80\x82\xef\xbc\x89\n    loss.backward()         # \xe8\xaf\xaf\xe5\xb7\xae\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad, \xe8\xae\xa1\xe7\xae\x97\xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\xe5\x80\xbc\n    optimizer.step()        # \xe5\xb0\x86\xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\xe5\x80\xbc\xe6\x96\xbd\xe5\x8a\xa0\xe5\x88\xb0 net \xe7\x9a\x84 parameters \xe4\xb8\x8a\n\n    # \xe6\x8e\xa5\xe7\x9d\x80\xe4\xb8\x8a\xe9\x9d\xa2\xe6\x9d\xa5\n    if t % 2 == 0:\n        plt.cla()\n        # \xe8\xbf\x87\xe4\xba\x86\xe4\xb8\x80\xe9\x81\x93 softmax \xe7\x9a\x84\xe6\xbf\x80\xe5\x8a\xb1\xe5\x87\xbd\xe6\x95\xb0\xe5\x90\x8e\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa6\x82\xe7\x8e\x87\xe6\x89\x8d\xe6\x98\xaf\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\n        prediction = torch.max(F.softmax(out), 1)[1]\n        pred_y = prediction.data.numpy().squeeze()\n        target_y = y.data.numpy()\n        plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap=\'RdYlGn\')\n        accuracy = sum(pred_y == target_y)/200  # \xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xad\xe6\x9c\x89\xe5\xa4\x9a\xe5\xb0\x91\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe4\xb8\x80\xe6\xa0\xb7\n        plt.text(1.5, -4, \'Accuracy=%.2f\' % accuracy, fontdict={\'size\': 20, \'color\':  \'red\'})\n        plt.pause(0.1)\n\nplt.ioff()  # \xe5\x81\x9c\xe6\xad\xa2\xe7\x94\xbb\xe5\x9b\xbe\nplt.show()\n'"
src/PyTorch/PyTorch-DQN_Reinforcement_learning.py,10,"b""import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\nimport gym\n\n\n# \xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nBATCH_SIZE = 32\nLR = 0.01                   # learning rate\nEPSILON = 0.9               # \xe6\x9c\x80\xe4\xbc\x98\xe9\x80\x89\xe6\x8b\xa9\xe5\x8a\xa8\xe4\xbd\x9c\xe7\x99\xbe\xe5\x88\x86\xe6\xaf\x94\nGAMMA = 0.9                 # \xe5\xa5\x96\xe5\x8a\xb1\xe9\x80\x92\xe5\x87\x8f\xe5\x8f\x82\xe6\x95\xb0\nTARGET_REPLACE_ITER = 100   # Q \xe7\x8e\xb0\xe5\xae\x9e\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe6\x9b\xb4\xe6\x96\xb0\xe9\xa2\x91\xe7\x8e\x87\nMEMORY_CAPACITY = 2000      # \xe8\xae\xb0\xe5\xbf\x86\xe5\xba\x93\xe5\xa4\xa7\xe5\xb0\x8f\nenv = gym.make('CartPole-v0')   # \xe7\xab\x8b\xe6\x9d\x86\xe5\xad\x90\xe6\xb8\xb8\xe6\x88\x8f\nenv = env.unwrapped\nN_ACTIONS = env.action_space.n  # \xe6\x9d\x86\xe5\xad\x90\xe8\x83\xbd\xe5\x81\x9a\xe7\x9a\x84\xe5\x8a\xa8\xe4\xbd\x9c\nN_STATES = env.observation_space.shape[0]   # \xe6\x9d\x86\xe5\xad\x90\xe8\x83\xbd\xe8\x8e\xb7\xe5\x8f\x96\xe7\x9a\x84\xe7\x8e\xaf\xe5\xa2\x83\xe4\xbf\xa1\xe6\x81\xaf\xe6\x95\xb0\nENV_A_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape     # to confirm the shape\n\n\nclass Net(nn.Module):\n    def __init__(self, ):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(N_STATES, 50)\n        self.fc1.weight.data.normal_(0, 0.1)   # initialization\n        self.out = nn.Linear(50, N_ACTIONS)\n        self.out.weight.data.normal_(0, 0.1)   # initialization\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = F.relu(x)\n        actions_value = self.out(x)\n        return actions_value\n\n\nclass DQN(object):\n    def __init__(self):\n        self.eval_net, self.target_net = Net(), Net()\n\n        self.learn_step_counter = 0                                     # for target updating\n        self.memory_counter = 0                                         # for storing memory\n        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))     # initialize memory\n        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n        self.loss_func = nn.MSELoss()\n\n    def choose_action(self, x):\n        x = Variable(torch.unsqueeze(torch.FloatTensor(x), 0))\n        # input only one sample\n        if np.random.uniform() < EPSILON:   # greedy\n            actions_value = self.eval_net.forward(x)\n            action = torch.max(actions_value, 1)[1].data.numpy()\n            action = action[0, 0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n        else:   # random\n            action = np.random.randint(0, N_ACTIONS)\n            action = action if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n        return action\n\n    def store_transition(self, s, a, r, s_):\n        transition = np.hstack((s, [a, r], s_))\n        # replace the old memory with new memory\n        index = self.memory_counter % MEMORY_CAPACITY\n        self.memory[index, :] = transition\n        self.memory_counter += 1\n\n    def learn(self):\n        # target parameter update\n        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n            self.target_net.load_state_dict(self.eval_net.state_dict())\n        self.learn_step_counter += 1\n\n        # sample batch transitions\n        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n        b_memory = self.memory[sample_index, :]\n        b_s = Variable(torch.FloatTensor(b_memory[:, :N_STATES]))\n        b_a = Variable(torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int)))\n        b_r = Variable(torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2]))\n        b_s_ = Variable(torch.FloatTensor(b_memory[:, -N_STATES:]))\n\n        # q_eval w.r.t the action in experience\n        q_eval = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n        q_next = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)   # shape (batch, 1)\n        loss = self.loss_func(q_eval, q_target)\n\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n\ndqn = DQN()\n\nprint('\\nCollecting experience...')\nfor i_episode in range(400):\n    s = env.reset()\n    ep_r = 0\n    while True:\n        env.render()\n        a = dqn.choose_action(s)\n\n        # take action\n        s_, r, done, info = env.step(a)\n\n        # modify the reward\n        x, x_dot, theta, theta_dot = s_\n        r1 = (env.x_threshold - abs(x)) / env.x_threshold - 0.8\n        r2 = (env.theta_threshold_radians - abs(theta)) / env.theta_threshold_radians - 0.5\n        r = r1 + r2\n\n        dqn.store_transition(s, a, r, s_)\n\n        ep_r += r\n        if dqn.memory_counter > MEMORY_CAPACITY:\n            dqn.learn()\n            if done:\n                print('Ep: ', i_episode,\n                      '| Ep_r: ', round(ep_r, 2))\n\n        if done:\n            break\n        s = s_\n"""
src/PyTorch/PyTorch-RNN_classifier.py,8,"b""import torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n\n\ntorch.manual_seed(1)    # reproducible\n\n# Hyper Parameters\nEPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\nBATCH_SIZE = 64\nTIME_STEP = 28          # rnn time step / image height\nINPUT_SIZE = 28         # rnn input size / image width\nLR = 0.01               # learning rate\nDOWNLOAD_MNIST = False   # set to True if haven't download the data\n\n\n# Mnist digital dataset\ntrain_data = dsets.MNIST(\n    root='./mnist/',\n    train=True,                         # this is training data\n    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n    download=DOWNLOAD_MNIST,            # download it if you don't have it\n)\n\n# plot one example\nprint(train_data.train_data.size())     # (60000, 28, 28)\nprint(train_data.train_labels.size())   # (60000)\nplt.imshow(train_data.train_data[0].numpy(), cmap='gray')\nplt.title('%i' % train_data.train_labels[0])\nplt.show()\n\n# Data Loader for easy mini-batch return in training\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n\n# convert test data into Variable, pick 2000 samples to speed up testing\ntest_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\ntest_x = Variable(test_data.test_data, volatile=True).type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)\ntest_y = test_data.test_labels.numpy().squeeze()[:2000]    # covert to numpy array\n\n\nclass RNN(nn.Module):\n    def __init__(self):\n        super(RNN, self).__init__()\n\n        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n            input_size=INPUT_SIZE,\n            hidden_size=64,         # rnn hidden unit\n            num_layers=1,           # number of rnn layer\n            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n        )\n\n        self.out = nn.Linear(64, 10)\n\n    def forward(self, x):\n        # x shape (batch, time_step, input_size)\n        # r_out shape (batch, time_step, output_size)\n        # h_n shape (n_layers, batch, hidden_size)\n        # h_c shape (n_layers, batch, hidden_size)\n        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n\n        # choose r_out at the last time step\n        out = self.out(r_out[:, -1, :])\n        return out\n\n\nrnn = RNN()\nprint(rnn)\n\noptimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\nloss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n\n# training and testing\nfor epoch in range(EPOCH):\n    for step, (x, y) in enumerate(train_loader):        # gives batch data\n        b_x = Variable(x.view(-1, 28, 28))              # reshape x to (batch, time_step, input_size)\n        b_y = Variable(y)                               # batch y\n\n        output = rnn(b_x)                               # rnn output\n        loss = loss_func(output, b_y)                   # cross entropy loss\n        optimizer.zero_grad()                           # clear gradients for this training step\n        loss.backward()                                 # backpropagation, compute gradients\n        optimizer.step()                                # apply gradients\n\n        if step % 50 == 0:\n            test_output = rnn(test_x)                   # (samples, time_step, input_size)\n            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n            accuracy = sum(pred_y == test_y) / float(test_y.size)\n            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0], '| test accuracy: %.4f' % accuracy)\n\n# print 10 predictions from test data\ntest_output = rnn(test_x[:100].view(-1, 28, 28))\npred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\nprint(pred_y, 'prediction number')\nprint(test_y[:100], 'real number')\n"""
src/PyTorch/PyTorch-RNN_regressor.py,6,"b""import torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntorch.manual_seed(1)    # reproducible\n\n# Hyper Parameters\nTIME_STEP = 10      # rnn time step\nINPUT_SIZE = 1      # rnn input size\nLR = 0.02           # learning rate\n\n# show data\nsteps = np.linspace(0, np.pi*2, 100, dtype=np.float32)\nx_np = np.sin(steps)    # float32 for converting torch FloatTensor\ny_np = np.cos(steps)\nplt.plot(steps, y_np, 'r-', label='target (cos)')\nplt.plot(steps, x_np, 'b-', label='input (sin)')\nplt.legend(loc='best')\nplt.show()\n\n\nclass RNN(nn.Module):\n    def __init__(self):\n        super(RNN, self).__init__()\n\n        self.rnn = nn.RNN(\n            input_size=INPUT_SIZE,\n            hidden_size=32,     # rnn hidden unit\n            num_layers=1,       # number of rnn layer\n            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n        )\n        self.out = nn.Linear(32, 1)\n\n    def forward(self, x, h_state):\n        # x (batch, time_step, input_size)\n        # h_state (n_layers, batch, hidden_size)\n        # r_out (batch, time_step, hidden_size)\n        r_out, h_state = self.rnn(x, h_state)\n\n        outs = []    # save all predictions\n        for time_step in range(r_out.size(1)):    # calculate output for each time step\n            outs.append(self.out(r_out[:, time_step, :]))\n        return torch.stack(outs, dim=1), h_state\n\n        # instead, for simplicity, you can replace above codes by follows\n        # r_out = r_out.view(-1, 32)\n        # outs = self.out(r_out)\n        # return outs, h_state\n\nrnn = RNN()\nprint(rnn)\n\noptimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\nloss_func = nn.MSELoss()\n\nh_state = None      # for initial hidden state\n\nplt.figure(1, figsize=(12, 5))\nplt.ion()           # continuously plot\n\nfor step in range(60):\n    start, end = step * np.pi, (step+1)*np.pi   # time range\n    # use sin predicts cos\n    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32)\n    x_np = np.sin(steps)    # float32 for converting torch FloatTensor\n    y_np = np.cos(steps)\n\n    x = Variable(torch.from_numpy(x_np[np.newaxis, :, np.newaxis]))    # shape (batch, time_step, input_size)\n    y = Variable(torch.from_numpy(y_np[np.newaxis, :, np.newaxis]))\n\n    prediction, h_state = rnn(x, h_state)   # rnn output\n    # !! next step is important !!\n    h_state = Variable(h_state.data)        # repack the hidden state, break the connection from last iteration\n\n    loss = loss_func(prediction, y)         # cross entropy loss\n    optimizer.zero_grad()                   # clear gradients for this training step\n    loss.backward()                         # backpropagation, compute gradients\n    optimizer.step()                        # apply gradients\n\n    # plotting\n    plt.plot(steps, y_np.flatten(), 'r-')\n    plt.plot(steps, prediction.data.numpy().flatten(), 'b-')\n    plt.draw()\n    plt.pause(0.05)\n\n\nplt.ioff()\nplt.show()\n"""
src/PyTorch/PyTorch-autoencoder.py,8,"b""import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.utils.data as Data\nimport torchvision\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport numpy as np\n\n\ntorch.manual_seed(1)    # reproducible\n\n# Hyper Parameters\nEPOCH = 10\nBATCH_SIZE = 64\nLR = 0.005         # learning rate\nDOWNLOAD_MNIST = False\nN_TEST_IMG = 5\n\n# Mnist digits dataset\ntrain_data = torchvision.datasets.MNIST(\n    root='./mnist/',\n    train=True,                                     # this is training data\n    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n    download=DOWNLOAD_MNIST,                        # download it if you don't have it\n)\n\n# plot one example\nprint(train_data.train_data.size())     # (60000, 28, 28)\nprint(train_data.train_labels.size())   # (60000)\nplt.imshow(train_data.train_data[2].numpy(), cmap='gray')\nplt.title('%i' % train_data.train_labels[2])\nplt.show()\n\n# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\ntrain_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n\n\nclass AutoEncoder(nn.Module):\n    def __init__(self):\n        super(AutoEncoder, self).__init__()\n\n        self.encoder = nn.Sequential(\n            nn.Linear(28*28, 128),\n            nn.Tanh(),\n            nn.Linear(128, 64),\n            nn.Tanh(),\n            nn.Linear(64, 12),\n            nn.Tanh(),\n            nn.Linear(12, 3),   # compress to 3 features which can be visualized in plt\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(3, 12),\n            nn.Tanh(),\n            nn.Linear(12, 64),\n            nn.Tanh(),\n            nn.Linear(64, 128),\n            nn.Tanh(),\n            nn.Linear(128, 28*28),\n            nn.Sigmoid(),       # compress to a range (0, 1)\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return encoded, decoded\n\n\nautoencoder = AutoEncoder()\n\noptimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\nloss_func = nn.MSELoss()\n\n# initialize figure\nf, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\nplt.ion()   # continuously plot\n\n# original data (first row) for viewing\nview_data = Variable(train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.)\nfor i in range(N_TEST_IMG):\n    a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n\nfor epoch in range(EPOCH):\n    for step, (x, y) in enumerate(train_loader):\n        b_x = Variable(x.view(-1, 28*28))   # batch x, shape (batch, 28*28)\n        b_y = Variable(x.view(-1, 28*28))   # batch y, shape (batch, 28*28)\n        b_label = Variable(y)               # batch label\n\n        encoded, decoded = autoencoder(b_x)\n\n        loss = loss_func(decoded, b_y)      # mean square error\n        optimizer.zero_grad()               # clear gradients for this training step\n        loss.backward()                     # backpropagation, compute gradients\n        optimizer.step()                    # apply gradients\n\n        if step % 100 == 0:\n            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0])\n\n            # plotting decoded image (second row)\n            _, decoded_data = autoencoder(view_data)\n            for i in range(N_TEST_IMG):\n                a[1][i].clear()\n                a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n            plt.draw(); plt.pause(0.05)\n\nplt.ioff()\nplt.show()\n\n# visualize in 3D plot\nview_data = Variable(train_data.train_data[:200].view(-1, 28*28).type(torch.FloatTensor)/255.)\nencoded_data, _ = autoencoder(view_data)\nfig = plt.figure(2); ax = Axes3D(fig)\nX, Y, Z = encoded_data.data[:, 0].numpy(), encoded_data.data[:, 1].numpy(), encoded_data.data[:, 2].numpy()\nvalues = train_data.train_labels[:200].numpy()\nfor x, y, z, s in zip(X, Y, Z, values):\n    c = cm.rainbow(int(255*s/9)); ax.text(x, y, z, s, backgroundcolor=c)\nax.set_xlim(X.min(), X.max()); ax.set_ylim(Y.min(), Y.max()); ax.set_zlim(Z.min(), Z.max())\nplt.show()\n"""
src/PyTorch/PyTorch-save-reload.py,18,"b'#!/usr/bin/python3\n# coding: utf-8\n""""""\nView more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\nMy Youtube Channel: https://www.youtube.com/user/MorvanZhou\n\nDependencies:\ntorch: 0.1.11\nmatplotlib\n""""""\nimport torch\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\n\ntorch.manual_seed(1)    # reproducible\n\n# fake data\nx = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1)  # x data (tensor), shape=(100, 1)\ny = x.pow(2) + 0.2*torch.rand(x.size())  # noisy y data (tensor), shape=(100, 1)\nx, y = Variable(x, requires_grad=False), Variable(y, requires_grad=False)\n\n\ndef save():\n    # save net1\n    net1 = torch.nn.Sequential(\n        torch.nn.Linear(1, 10),\n        torch.nn.ReLU(),\n        torch.nn.Linear(10, 1)\n    )\n    optimizer = torch.optim.SGD(net1.parameters(), lr=0.5)\n    loss_func = torch.nn.MSELoss()\n\n    for t in range(100):\n        prediction = net1(x)\n        loss = loss_func(prediction, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    # plot result\n    plt.figure(1, figsize=(10, 3))\n    plt.subplot(131)\n    plt.title(\'Net1\')\n    plt.scatter(x.data.numpy(), y.data.numpy())\n    plt.plot(x.data.numpy(), prediction.data.numpy(), \'r-\', lw=5)\n\n    # 2 ways to save the net\n    torch.save(net1, \'net.pkl\')  # save entire net\n    torch.save(net1.state_dict(), \'net_params.pkl\')   # save only the parameters\n\n\ndef restore_net():\n    # restore entire net1 to net2\n    net2 = torch.load(\'net.pkl\')\n    prediction = net2(x)\n\n    # plot result\n    plt.subplot(132)\n    plt.title(\'Net2\')\n    plt.scatter(x.data.numpy(), y.data.numpy())\n    plt.plot(x.data.numpy(), prediction.data.numpy(), \'r-\', lw=5)\n\n\ndef restore_params():\n    # restore only the parameters in net1 to net3\n    net3 = torch.nn.Sequential(\n        torch.nn.Linear(1, 10),\n        torch.nn.ReLU(),\n        torch.nn.Linear(10, 1)\n    )\n\n    # copy net1\'s parameters into net3\n    net3.load_state_dict(torch.load(\'net_params.pkl\'))\n    prediction = net3(x)\n\n    # plot result\n    plt.subplot(133)\n    plt.title(\'Net3\')\n    plt.scatter(x.data.numpy(), y.data.numpy())\n    plt.plot(x.data.numpy(), prediction.data.numpy(), \'r-\', lw=5)\n    plt.show()\n\n\n# save net1\nsave()\n\n# restore entire net (may slow)\nrestore_net()\n\n# restore only the net parameters\nrestore_params()\n'"
src/PyTorch/Pytorch-GAN.py,9,"b""import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntorch.manual_seed(1)    # reproducible\nnp.random.seed(1)\n\n# Hyper Parameters\nBATCH_SIZE = 64\nLR_G = 0.0001           # learning rate for generator\nLR_D = 0.0001           # learning rate for discriminator\nN_IDEAS = 5             # think of this as number of ideas for generating an art work (Generator)\nART_COMPONENTS = 15     # it could be total point G can draw in the canvas\nPAINT_POINTS = np.vstack([np.linspace(-1, 1, ART_COMPONENTS) for _ in range(BATCH_SIZE)])\n\n# show our beautiful painting range\n# plt.plot(PAINT_POINTS[0], 2 * np.power(PAINT_POINTS[0], 2) + 1, c='#74BCFF', lw=3, label='upper bound')\n# plt.plot(PAINT_POINTS[0], 1 * np.power(PAINT_POINTS[0], 2) + 0, c='#FF9359', lw=3, label='lower bound')\n# plt.legend(loc='upper right')\n# plt.show()\n\n\ndef artist_works():     # painting from the famous artist (real target)\n    a = np.random.uniform(1, 2, size=BATCH_SIZE)[:, np.newaxis]\n    paintings = a * np.power(PAINT_POINTS, 2) + (a-1)\n    paintings = torch.from_numpy(paintings).float()\n    return Variable(paintings)\n\nG = nn.Sequential(                      # Generator\n    nn.Linear(N_IDEAS, 128),            # random ideas (could from normal distribution)\n    nn.ReLU(),\n    nn.Linear(128, ART_COMPONENTS),     # making a painting from these random ideas\n)\n\nD = nn.Sequential(                      # Discriminator\n    nn.Linear(ART_COMPONENTS, 128),     # receive art work either from the famous artist or a newbie like G\n    nn.ReLU(),\n    nn.Linear(128, 1),\n    nn.Sigmoid(),                       # tell the probability that the art work is made by artist\n)\n\nopt_D = torch.optim.Adam(D.parameters(), lr=LR_D)\nopt_G = torch.optim.Adam(G.parameters(), lr=LR_G)\n\nplt.ion()   # something about continuous plotting\n\nfor step in range(10000):\n    artist_paintings = artist_works()           # real painting from artist\n    G_ideas = Variable(torch.randn(BATCH_SIZE, N_IDEAS))    # random ideas\n    G_paintings = G(G_ideas)                    # fake painting from G (random ideas)\n\n    prob_artist0 = D(artist_paintings)          # D try to increase this prob\n    prob_artist1 = D(G_paintings)               # D try to reduce this prob\n\n    D_loss = - torch.mean(torch.log(prob_artist0) + torch.log(1. - prob_artist1))\n    G_loss = torch.mean(torch.log(1. - prob_artist1))\n\n    opt_D.zero_grad()\n    D_loss.backward(retain_variables=True)      # retain_variables for reusing computational graph\n    opt_D.step()\n\n    opt_G.zero_grad()\n    G_loss.backward()\n    opt_G.step()\n\n    if step % 50 == 0:  # plotting\n        plt.cla()\n        plt.plot(PAINT_POINTS[0], G_paintings.data.numpy()[0], c='#4AD631', lw=3, label='Generated painting',)\n        plt.plot(PAINT_POINTS[0], 2 * np.power(PAINT_POINTS[0], 2) + 1, c='#74BCFF', lw=3, label='upper bound')\n        plt.plot(PAINT_POINTS[0], 1 * np.power(PAINT_POINTS[0], 2) + 0, c='#FF9359', lw=3, label='lower bound')\n        plt.text(-.5, 2.3, 'D accuracy=%.2f (0.5 for D to converge)' % prob_artist0.data.numpy().mean(), fontdict={'size': 15})\n        plt.text(-.5, 2, 'D score= %.2f (-1.38 for G to converge)' % -D_loss.data.numpy(), fontdict={'size': 15})\n        plt.ylim((0, 3));plt.legend(loc='upper right', fontsize=12);plt.draw();plt.pause(0.01)\n\nplt.ioff()\nplt.show()\n"""
src/Python自然语言处理/test.py,0,"b'#!/usr/bin/env python\n# coding: utf-8\n\n""""""\nCreated on 2018-05-09\nUpdated on 2017-05-09\nAuthor: /\xe7\x89\x87\xe5\x88\xbb\nGitHub: https://github.com/apachecn/AiLearning\n""""""\n\n\n""""""\nthe first example for nltk book\n""""""\nfrom __future__ import print_function\n\nfrom nltk.book import *\n\n\n# \xe6\x9f\xa5\xe6\x89\xbe\xe7\x89\xb9\xe5\xae\x9a\xe8\xaf\x8d\xe8\xaf\xad\xe4\xb8\x8a\xe4\xb8\x8b\xe6\x96\x87\ntext1.concordance(""monstrous"")\n\n# \xe7\x9b\xb8\xe5\x85\xb3\xe8\xaf\x8d\xe6\x9f\xa5\xe6\x89\xbe\ntext1.similar(""monstrous"")\n\n# \xe6\x9f\xa5\xe6\x89\xbe\xe5\xa4\x9a\xe4\xb8\xaa\xe8\xaf\x8d\xe8\xaf\xad\xe7\x9a\x84\xe5\x85\xb1\xe5\x90\x8c\xe4\xb8\x8a\xe4\xb8\x8b\xe6\x96\x87\ntext2.common_contexts([""monstrous"", ""very""])\n\n# \xe7\x94\xbb\xe5\x87\xba\xe8\xaf\x8d\xe8\xaf\xad\xe7\x9a\x84\xe7\xa6\xbb\xe6\x95\xa3\xe5\x9b\xbe\ntext4.dispersion_plot([""citizens"", ""democracy"", ""freedom"", ""duties"", ""America""])\n\n# \xe4\xba\xa7\xe7\x94\x9f\xe9\x9a\x8f\xe6\x9c\xba\xe6\x96\x87\xe6\x9c\xac\ntext3.generate()\n# TOTO: Clean up the following\n# Traceback (most recent call last):\n#   File ""E:/nlp/eg1.py"", line 25, in <module>\n#     text3.generate()\n# TypeError: generate() missing 1 required positional argument: \'words\'\n\n# \xe5\x8d\x95\xe8\xaf\x8d\xe6\x95\xb0\xe9\x87\x8f \xe6\xa0\x87\xe8\xaf\x86\xe7\xac\xa6\xe6\x80\xbb\xe6\x95\xb0\nprint(len(text3))\n\n# \xe8\xaf\x8d\xe6\xb1\x87\xe7\x9a\x84\xe7\xa7\x8d\xe7\xb1\xbb\xe5\x8f\x8a\xe6\x95\xb0\xe9\x87\x8f \xe7\x94\xa8\xe9\x9b\x86\xe5\x90\x88set\xe6\x98\xbe\xe7\xa4\xba\nprint(sorted(set(text3)))\nprint(len(set(text3)))\n\n# \xe6\xb5\x8b\xe9\x87\x8f\xe5\xb9\xb3\xe5\x9d\x87\xe6\xaf\x8f\xe7\xb1\xbb\xe8\xaf\x8d\xe8\xaf\xad\xe8\xa2\xab\xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\nfrom __future__ import division #\xe6\x9c\xac\xe5\x91\xbd\xe4\xbb\xa4\xe5\xbf\x85\xe9\xa1\xbb\xe6\x94\xbe\xe5\x9c\xa8\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84\xe5\xbc\x80\xe5\xa7\x8b\xe4\xb9\x8b\xe5\x88\x9d\nprint(len(text3)/len(set(text3)))\n\n# \xe7\xbb\x9f\xe8\xae\xa1\xe7\x89\xb9\xe5\xae\x9a\xe5\x8d\x95\xe8\xaf\x8d\xe5\x9c\xa8\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\xef\xbc\x8c\xe5\xb9\xb6\xe8\xae\xa1\xe7\xae\x97\xe5\x85\xb6\xe5\x8d\xa0\xe6\xaf\x94\nprint(text3.count(""smote""))\nprint(100*text4.count(\'a\')/len(text4))\n\n\n# \xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe4\xb8\xaa\xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad\xef\xbc\x8c\xe5\xb9\xb3\xe5\x9d\x87\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe5\x87\xba\xe7\x8e\xb0\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\xef\xbc\x88\xe8\xaf\x8d\xe6\xb1\x87\xe5\xa4\x9a\xe6\xa0\xb7\xe6\x80\xa7\xef\xbc\x89\ndef lexical_diversity(text):\n  return len(text) / len(set(text))\n\n\ndef percentage(count, total):\n  return 100 * count / total\n\n\n""""""\n\xe6\xb5\x8b\xe8\xaf\x95\xe6\xa1\x88\xe4\xbe\x8b\n\nIn [32]: ex1 = [\'Monty\', \'Python\', \'and\', \'the\', \'Holy\', \'Grail\']\nIn [34]: sorted(ex1)\nOut[34]: [\'Grail\', \'Holy\', \'Monty\', \'Python\', \'and\', \'the\']\n\nIn [35]: len(set(ex1))\nOut[35]: 6\n\nIn [36]: ex1.count(""the"")\nOut[36]: 1\n\nIn [37]: [\'Monty\', \'Python\'] + [\'and\', \'the\', \'Holy\', \'Grail\']\nOut[37]: [\'Monty\', \'Python\', \'and\', \'the\', \'Holy\', \'Grail\']\n""""""\n\n# # \xe8\xaf\x8d\xe7\x9a\x84\xe9\xa2\x91\xe7\x8e\x87\xe5\x88\x86\xe5\xb8\x83\nfdist1 = FreqDist(text1)\n# # \xe8\xbe\x93\xe5\x87\xba\xe6\x80\xbb\xe7\x9a\x84\xe8\xaf\x8d\xe6\x95\xb0\nprint(fdist1)\n# In Python 3 dict.keys() returns an iteratable but not indexable object.\nvac1 = list(fdist1.keys())\n# # \xe8\xbe\x93\xe5\x87\xba\xe8\xaf\x8d\xe6\x95\xb0\xe6\x9c\x80\xe5\xa4\x9a\xe7\x9a\x84\xe5\x89\x8d\xe4\xba\x94\xe5\x8d\x81\xe4\xb8\xaa\xe8\xaf\x8d\nprint(vac1[:50])\n# # \xe8\xbe\x93\xe5\x87\xbawhale\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\nprint(fdist1[""whale""])\n# # \xe8\xbe\x93\xe5\x87\xba\xe5\x89\x8d\xe4\xba\x94\xe5\x8d\x81\xe4\xb8\xaa\xe8\xaf\x8d\xe7\x9a\x84\xe7\xb4\xaf\xe7\xa7\xaf\xe9\xa2\x91\xe7\x8e\x87\xe5\x9b\xbe\n\nfdist1.plot(50)\n\n# \xe6\x9f\xa5\xe6\x89\xbe\xe9\x95\xbf\xe5\xba\xa6\xe8\xb6\x85\xe8\xbf\x8715\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\xe7\x9a\x84\xe8\xaf\x8d\nV = set(text1)\nlong_words = [w for w in V if len(w)>15]\nprint(sorted(long_words))\n\n# \xe6\x9f\xa5\xe6\x89\xbe\xe9\x95\xbf\xe5\xba\xa6\xe8\xb6\x85\xe8\xbf\x877\xe7\x9a\x84\xe8\xaf\x8d\xe4\xb8\x94\xe9\xa2\x91\xe7\x8e\x87\xe8\xb6\x85\xe8\xbf\x877\nfdist5 = FreqDist(text5)\nprint(sorted([ w for w in set(text5) if len(w)>7 and fdist5[w]>7]))\n\n# \xe5\x8f\x8c\xe8\xbf\x9e\xe8\xaf\x8d\xe7\x9a\x84\xe4\xbd\xbf\xe7\x94\xa8\nfrom nltk import bigrams\n# # \xe6\x9f\xa5\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\x8bnltk\xe5\xae\x98\xe7\xbd\x91\xe4\xb8\x8a\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xe8\xaf\xb4\xe6\x98\x8e\xef\xbc\x8c\xe8\xa6\x81\xe5\x8a\xa0list()\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe7\xbb\x93\xe6\x9e\x9c\xe6\x89\x8d\xe6\x98\xaf\xe4\xb9\xa6\xe4\xb8\x8a\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\nprint(list(bigrams([\'more\', \'is\', \'said\', \'than\', \'done\'])))\n\n# \xe6\x96\x87\xe6\x9c\xac\xe4\xb8\xad\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe8\xbf\x9e\xe6\x8e\xa5\xe8\xaf\x8d\nprint(text4.collocations())\n\nprint([len(w) for w in text1])\nfdist = FreqDist([len(w) for w in text1])\nprint(fdist)\nprint(fdist.keys())\nprint(fdist.items())\nprint(fdist.max())\nprint(fdist[3])\nprint(fdist.freq(3))\n\nprint(sorted([w for w in set(text1) if w.endswith(\'ableness\')]))\n\nprint(babelize_shell())\n'"
src/chatbot/run_demo.py,5,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nfrom u_tools import normalizeString, load_model\nfrom u_class import Voc, GreedySearchDecoder\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\nMAX_LENGTH = 10  # Maximum sentence length to consider\n\n\ndef indexesFromSentence(voc, sentence):\n    return [voc.word2index[word] for word in sentence.split(\' \')] + [EOS_token]\n\n\ndef evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n    ### Format input sentence as a batch\n    # words -> indexes\n    indexes_batch = [indexesFromSentence(voc, sentence)]\n    # Create lengths tensor\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    # Transpose dimensions of batch to match models\' expectations\n    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n    # Use appropriate device\n    input_batch = input_batch.to(device)\n    lengths = lengths.to(device)\n    # Decode sentence with searcher\n    tokens, scores = searcher(input_batch, lengths, max_length)\n    # indexes -> words\n    decoded_words = [voc.index2word[token.item()] for token in tokens]\n    return decoded_words\n\n\ndef evaluateInput(encoder, decoder, searcher, voc):\n    input_sentence = \'\'\n    while(1):\n        try:\n            # Get input sentence\n            input_sentence = input(\'> \')\n            # Check if it is quit case\n            if input_sentence == \'q\' or input_sentence == \'quit\': break\n            # Normalize sentence\n            input_sentence = normalizeString(input_sentence)\n            # Evaluate sentence\n            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n            # Format and print response sentence\n            output_words[:] = [x for x in output_words if not (x == \'EOS\' or x == \'PAD\')]\n            print(\'Bot:\', \' \'.join(output_words))\n\n        except KeyError:\n            print(""Error: Encountered unknown word."")\n\n\nif __name__ == ""__main__"":\n    global device, corpus_name\n    USE_CUDA = torch.cuda.is_available()\n    device = torch.device(""cuda"" if USE_CUDA else ""cpu"")\n    corpus_name = ""cornell_movie-dialogs_corpus""\n\n\n    # Configure models\n    attn_model = \'dot\'\n    #attn_model = \'general\'\n    #attn_model = \'concat\'\n    hidden_size = 500\n    encoder_n_layers = 2\n    decoder_n_layers = 2\n    dropout = 0.1\n    cp_start_iteration = 0\n    learning_rate = 0.0001\n    decoder_learning_ratio = 5.0\n\n    loadFilename = ""data/save_copy/cb_model/%s/2-2_500/6000_checkpoint.tar"" % corpus_name\n    if os.path.exists(loadFilename):\n        voc = Voc(corpus_name)\n    cp_start_iteration, voc, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding = load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, dropout, learning_rate, decoder_learning_ratio)\n\n    # Use appropriate device\n    encoder = encoder.to(device)\n    decoder = decoder.to(device)\n    # Set dropout layers to eval mode\n    encoder.eval()\n    decoder.eval()\n\n    # Initialize search module\n    searcher = GreedySearchDecoder(encoder, decoder, device)\n\n    # Begin chatting (uncomment and run the following line to begin)\n    evaluateInput(encoder, decoder, searcher, voc)\n\n\n'"
src/chatbot/run_train.py,15,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport random\nimport unicodedata\nimport itertools\nimport csv\nimport math\nimport codecs\nimport torch\nimport torch.nn as nn\nfrom u_tools import normalizeString, load_model\nfrom u_class import Voc\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\nMAX_LENGTH = 10  # Maximum sentence length to consider\nMIN_COUNT = 3    # Minimum word count threshold for trimming\n\n\ndef printLines(file, n=10):\n    with open(file, \'rb\') as datafile:\n        lines = datafile.readlines()\n    for line in lines[:n]:\n        print(line)\n\n# Splits each line of the file into a dictionary of fields\ndef loadLines(fileName, fields):\n    lines = {}\n    with open(fileName, \'r\', encoding=\'iso-8859-1\') as f:\n        for line in f:\n            values = line.split("" +++$+++ "")\n            # Extract fields\n            lineObj = {}\n            for i, field in enumerate(fields):\n                lineObj[field] = values[i]\n            lines[lineObj[\'lineID\']] = lineObj\n    return lines\n\n# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\ndef loadConversations(fileName, lines, fields):\n    conversations = []\n    with open(fileName, \'r\', encoding=\'iso-8859-1\') as f:\n        for line in f:\n            values = line.split("" +++$+++ "")\n            # Extract fields\n            convObj = {}\n            for i, field in enumerate(fields):\n                convObj[field] = values[i]\n            # Convert string to list (convObj[""utteranceIDs""] == ""[\'L598485\', \'L598486\', ...]"")\n            lineIds = eval(convObj[""utteranceIDs""])\n            # Reassemble lines\n            convObj[""lines""] = []\n            for lineId in lineIds:\n                convObj[""lines""].append(lines[lineId])\n            conversations.append(convObj)\n    return conversations\n\n# Extracts pairs of sentences from conversations\ndef extractSentencePairs(conversations):\n    qa_pairs = []\n    for conversation in conversations:\n        # Iterate over all the lines of the conversation\n        for i in range(len(conversation[""lines""]) - 1):  # We ignore the last line (no answer for it)\n            inputLine = conversation[""lines""][i][""text""].strip()\n            targetLine = conversation[""lines""][i+1][""text""].strip()\n            # Filter wrong samples (if one of the lists is empty)\n            if inputLine and targetLine:\n                qa_pairs.append([inputLine, targetLine])\n    return qa_pairs\n\n\n\ndef get_datafile(datafile):\n    # Define path to new file\n    delimiter = \'\\t\'\n    # Unescape the delimiter\n    delimiter = str(codecs.decode(delimiter, ""unicode_escape""))\n\n    # Initialize lines dict, conversations list, and field ids\n    lines = {}\n    conversations = []\n    MOVIE_LINES_FIELDS = [""lineID"", ""characterID"", ""movieID"", ""character"", ""text""]\n    MOVIE_CONVERSATIONS_FIELDS = [""character1ID"", ""character2ID"", ""movieID"", ""utteranceIDs""]\n\n    # Load lines and process conversations\n    print(""\\nProcessing corpus..."")\n    lines = loadLines(os.path.join(corpus, ""movie_lines.txt""), MOVIE_LINES_FIELDS)\n    # print("">>> "", lines)\n    print(""\\nLoading conversations..."")\n    conversations = loadConversations(os.path.join(corpus, ""movie_conversations.txt""), lines, MOVIE_CONVERSATIONS_FIELDS)\n    # print("">>> "", conversations)\n\n    # Write new csv file\n    print(""\\nWriting newly formatted file..."")\n    with open(datafile, \'w\', encoding=\'utf-8\') as outputfile:\n        writer = csv.writer(outputfile, delimiter=delimiter, lineterminator=\'\\n\')\n        for pair in extractSentencePairs(conversations):\n            writer.writerow(pair)\n\n    # Print a sample of lines\n    print(""\\nSample lines from file:"")\n    printLines(datafile)\n\n\ndef indexesFromSentence(voc, sentence):\n    return [voc.word2index[word] for word in sentence.split(\' \')] + [EOS_token]\n\ndef zeroPadding(l, fillvalue=PAD_token):\n    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n\ndef binaryMatrix(l, value=PAD_token):\n    m = []\n    for i, seq in enumerate(l):\n        m.append([])\n        for token in seq:\n            if token == PAD_token:\n                m[i].append(0)\n            else:\n                m[i].append(1)\n    return m\n\n# Returns padded input sequence tensor and lengths\ndef inputVar(l, voc):\n    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    padList = zeroPadding(indexes_batch)\n    padVar = torch.LongTensor(padList)\n    return padVar, lengths\n\n# Returns padded target sequence tensor, padding mask, and max target length\ndef outputVar(l, voc):\n    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n    max_target_len = max([len(indexes) for indexes in indexes_batch])\n    padList = zeroPadding(indexes_batch)\n    mask = binaryMatrix(padList)\n    mask = torch.ByteTensor(mask)\n    padVar = torch.LongTensor(padList)\n    return padVar, mask, max_target_len\n\n\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96Voc\xe5\xaf\xb9\xe8\xb1\xa1 \xe5\x92\x8c \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96pairs\xe5\xaf\xb9\xe8\xaf\x9d\xe5\xad\x98\xe6\x94\xbe\xe5\x88\xb0list\xe4\xb8\xad\ndef readVocs(datafile, corpus_name):\n    print(""Reading lines..."")\n    # Read the file and split into lines\n    lines = open(datafile, encoding=\'utf-8\').\\\n        read().strip().split(\'\\n\')\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split(\'\\t\')] for l in lines]\n    voc = Voc(corpus_name)\n    return voc, pairs\n\n# \xe5\xa6\x82\xe6\x9e\x9c\xe5\xaf\xb9 \'p\' \xe4\xb8\xad\xe7\x9a\x84\xe4\xb8\xa4\xe4\xb8\xaa\xe5\x8f\xa5\xe5\xad\x90\xe9\x83\xbd\xe4\xbd\x8e\xe4\xba\x8e MAX_LENGTH \xe9\x98\x88\xe5\x80\xbc\xef\xbc\x8c\xe5\x88\x99\xe8\xbf\x94\xe5\x9b\x9eTrue\ndef filterPair(p):\n    # Input sequences need to preserve the last word for EOS token\n    return len(p[0].split(\' \')) < MAX_LENGTH and len(p[1].split(\' \')) < MAX_LENGTH\n\n# \xe8\xbf\x87\xe6\xbb\xa4\xe6\xbb\xa1\xe8\xb6\xb3\xe6\x9d\xa1\xe4\xbb\xb6\xe7\x9a\x84 pairs \xe5\xaf\xb9\xe8\xaf\x9d\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe4\xb8\x8a\xe9\x9d\xa2\xe5\xae\x9a\xe4\xb9\x89\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x80\xe4\xb8\xaa\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84voc\xe5\xaf\xb9\xe8\xb1\xa1\xe5\x92\x8c\xe5\xaf\xb9\xe5\x88\x97\xe8\xa1\xa8\ndef loadPrepareData(corpus, corpus_name, datafile, save_dir):\n    print(""Start preparing training data ..."")\n    voc, pairs = readVocs(datafile, corpus_name)\n    print(""Read {!s} sentence pairs"".format(len(pairs)))\n    pairs = filterPairs(pairs)\n    print(""Trimmed to {!s} sentence pairs"".format(len(pairs)))\n    print(""Counting words..."")\n    for pair in pairs:\n        voc.addSentence(pair[0])\n        voc.addSentence(pair[1])\n    print(""Counted words:"", voc.num_words)\n    return voc, pairs\n\n\n# Returns all items for a given batch of pairs\ndef batch2TrainData(voc, pair_batch):\n    pair_batch.sort(key=lambda x: len(x[0].split("" "")), reverse=True)\n    input_batch, output_batch = [], []\n    for pair in pair_batch:\n        input_batch.append(pair[0])\n        output_batch.append(pair[1])\n    inp, lengths = inputVar(input_batch, voc)\n    output, mask, max_target_len = outputVar(output_batch, voc)\n    return inp, lengths, output, mask, max_target_len\n\n\ndef trimRareWords(voc, pairs, MIN_COUNT):\n    # Trim words used under the MIN_COUNT from the voc\n    voc.trim(MIN_COUNT)\n    # Filter out pairs with trimmed words\n    keep_pairs = []\n    for pair in pairs:\n        input_sentence = pair[0]\n        output_sentence = pair[1]\n        keep_input = True\n        keep_output = True\n        # Check input sentence\n        for word in input_sentence.split(\' \'):\n            if word not in voc.word2index:\n                keep_input = False\n                break\n        # Check output sentence\n        for word in output_sentence.split(\' \'):\n            if word not in voc.word2index:\n                keep_output = False\n                break\n\n        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n        if keep_input and keep_output:\n            keep_pairs.append(pair)\n\n    print(""Trimmed from {} pairs to {}, {:.4f} of total"".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n    return keep_pairs\n\n\ndef maskNLLLoss(inp, target, mask):\n    nTotal = mask.sum()\n    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n    loss = crossEntropy.masked_select(mask).mean()\n    loss = loss.to(device)\n    return loss, nTotal.item()\n\n\ndef train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n\n    # Zero gradients\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    # Set device options\n    input_variable = input_variable.to(device)\n    lengths = lengths.to(device)\n    target_variable = target_variable.to(device)\n    mask = mask.to(device)\n\n    # Initialize variables\n    loss = 0\n    print_losses = []\n    n_totals = 0\n\n    # Forward pass through encoder\n    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n\n    # Create initial decoder input (start with SOS tokens for each sentence)\n    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n    decoder_input = decoder_input.to(device)\n\n    # Set initial decoder hidden state to the encoder\'s final hidden state\n    decoder_hidden = encoder_hidden[:decoder.n_layers]\n\n    # Determine if we are using teacher forcing this iteration\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    # Forward batch of sequences through decoder one time step at a time\n    if use_teacher_forcing:\n        for t in range(max_target_len):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            # Teacher forcing: next input is current target\n            decoder_input = target_variable[t].view(1, -1)\n            # Calculate and accumulate loss\n            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n            loss += mask_loss\n            print_losses.append(mask_loss.item() * nTotal)\n            n_totals += nTotal\n    else:\n        for t in range(max_target_len):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            # No teacher forcing: next input is decoder\'s own current output\n            _, topi = decoder_output.topk(1)\n            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n            decoder_input = decoder_input.to(device)\n            # Calculate and accumulate loss\n            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n            loss += mask_loss\n            print_losses.append(mask_loss.item() * nTotal)\n            n_totals += nTotal\n\n    # Perform backpropatation\n    loss.backward()\n\n    # Clip gradients: gradients are modified in place\n    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n\n    # Adjust model weights\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return sum(print_losses) / n_totals\n\n\ndef trainIters(model_name, cp_start_iteration, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name):\n\n    # Load batches for each iteration\n    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_iteration)]\n\n    # Initializations\n    print(\'Initializing ...\')\n    # start_iteration = 1\n    print_loss = 0\n    start_iteration = cp_start_iteration + 1\n\n    # Training loop\n    print(""Training..."")\n    for iteration in range(start_iteration, n_iteration+1):\n        training_batch = training_batches[iteration-1]\n        # Extract fields from batch\n        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n\n        # Run a training iteration with batch\n        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n        print_loss += loss\n\n        # Print progress\n        if iteration % print_every == 0:\n            print_loss_avg = print_loss / print_every\n            print(""Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}"".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n            print_loss = 0\n\n        # Save checkpoint\n        if (iteration % save_every == 0):\n            directory = os.path.join(save_dir, model_name, corpus_name, \'{}-{}_{}\'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n            if not os.path.exists(directory):\n                os.makedirs(directory)\n            torch.save({\n                \'iteration\': iteration,\n                \'state_dict_en\': encoder.state_dict(),\n                \'state_dict_de\': decoder.state_dict(),\n                \'state_dict_en_opt\': encoder_optimizer.state_dict(),\n                \'state_dict_de_opt\': decoder_optimizer.state_dict(),\n                \'loss\': loss,\n                \'voc_dict\': voc.__dict__,\n                \'embedding\': embedding.state_dict()\n            }, os.path.join(directory, \'{}_{}.tar\'.format(iteration, \'checkpoint\')))\n\n\nif __name__ == ""__main__"":\n    global device, corpus_name\n    USE_CUDA = torch.cuda.is_available()\n    device = torch.device(""cuda"" if USE_CUDA else ""cpu"")\n\n    corpus_name = ""cornell_movie-dialogs_corpus""\n    corpus = os.path.join(""data"", corpus_name)\n    # printLines(os.path.join(corpus, ""movie_lines.txt""))\n\n    datafile = os.path.join(corpus, ""formatted_movie_lines.txt"")\n    get_datafile(datafile)\n\n    # Load/Assemble voc and pairs\n    save_dir = os.path.join(""data"", ""save"")\n    voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n    # Print some pairs to validate\n    print(""\\npairs:"")\n    for pair in pairs[:10]:\n        print(pair)\n\n    # Trim voc and pairs\n    pairs = trimRareWords(voc, pairs, MIN_COUNT)\n\n    # # Example for validation\n    # small_batch_size = 5\n    # batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n    # input_variable, lengths, target_variable, mask, max_target_len = batches\n    # print(""input_variable:"", input_variable)\n    # print(""lengths:"", lengths)\n    # print(""target_variable:"", target_variable)\n    # print(""mask:"", mask)\n    # print(""max_target_len:"", max_target_len)\n\n    global teacher_forcing_ratio, hidden_size\n    # Configure models\n    model_name = \'cb_model\'\n    attn_model = \'dot\'\n    #attn_model = \'general\'\n    #attn_model = \'concat\'\n    hidden_size = 500\n    encoder_n_layers = 2\n    decoder_n_layers = 2\n    dropout = 0.1\n    cp_start_iteration = 0\n    learning_rate = 0.0001\n    decoder_learning_ratio = 5.0\n    teacher_forcing_ratio = 1.0\n    clip = 50.0\n    print_every = 1\n    batch_size = 64\n    save_every = 1000\n    n_iteration = 7000\n\n    loadFilename = ""data/save/cb_model/%s/2-2_500/6000_checkpoint.tar"" % corpus_name\n    if os.path.exists(loadFilename):\n        voc = Voc(corpus_name)\n    cp_start_iteration, voc, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding = load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, dropout, learning_rate, decoder_learning_ratio)\n    \n    # Use appropriate device\n    encoder = encoder.to(device)\n    decoder = decoder.to(device)\n    for state in encoder_optimizer.state.values():\n        for k, v in state.items():\n            if isinstance(v, torch.Tensor):\n                state[k] = v.cuda()\n\n    for state in decoder_optimizer.state.values():\n        for k, v in state.items():\n            if isinstance(v, torch.Tensor):\n                state[k] = v.cuda()\n\n    # Ensure dropout layers are in train mode\n    encoder.train()\n    decoder.train()\n\n    print(""Starting Training!"")\n    trainIters(model_name, cp_start_iteration, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name)\n'"
src/chatbot/u_class.py,20,"b'#!/usr/bin/python\n# coding: utf-8\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\n\n\nclass Voc:\n    def __init__(self, name):\n        self.name = name\n        self.trimmed = False\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: ""PAD"", SOS_token: ""SOS"", EOS_token: ""EOS""}\n        self.num_words = 3  # Count SOS, EOS, PAD\n\n    def addSentence(self, sentence):\n        for word in sentence.split(\' \'):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.num_words\n            self.word2count[word] = 1\n            self.index2word[self.num_words] = word\n            self.num_words += 1\n        else:\n            self.word2count[word] += 1\n\n    # Remove words below a certain count threshold\n    def trim(self, min_count):\n        if self.trimmed:\n            return\n        self.trimmed = True\n\n        keep_words = []\n\n        for k, v in self.word2count.items():\n            if v >= min_count:\n                keep_words.append(k)\n\n        print(\'keep_words {} / {} = {:.4f}\'.format(\n            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n        ))\n\n        # Reinitialize dictionaries\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: ""PAD"", SOS_token: ""SOS"", EOS_token: ""EOS""}\n        self.num_words = 3 # Count default tokens\n\n        for word in keep_words:\n            self.addWord(word)\n\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n        super(EncoderRNN, self).__init__()\n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        self.embedding = embedding\n\n        # Initialize GRU; the input_size and hidden_size params are both set to \'hidden_size\'\n        #   because our input size is a word embedding with number of features == hidden_size\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n\n    def forward(self, input_seq, input_lengths, hidden=None):\n        # Convert word indexes to embeddings\n        embedded = self.embedding(input_seq)\n        # Pack padded batch of sequences for RNN module\n        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n        # Forward pass through GRU\n        outputs, hidden = self.gru(packed, hidden)\n        # Unpack padding\n        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n        # Sum bidirectional GRU outputs\n        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n        # Return output and final hidden state\n        return outputs, hidden\n\n\n# Luong attention layer\nclass Attn(nn.Module):\n    def __init__(self, method, hidden_size):\n        super(Attn, self).__init__()\n        self.method = method\n        if self.method not in [\'dot\', \'general\', \'concat\']:\n            raise ValueError(self.method, ""is not an appropriate attention method."")\n        self.hidden_size = hidden_size\n        if self.method == \'general\':\n            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n        elif self.method == \'concat\':\n            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n\n    def dot_score(self, hidden, encoder_output):\n        return torch.sum(hidden * encoder_output, dim=2)\n\n    def general_score(self, hidden, encoder_output):\n        energy = self.attn(encoder_output)\n        return torch.sum(hidden * energy, dim=2)\n\n    def concat_score(self, hidden, encoder_output):\n        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n        return torch.sum(self.v * energy, dim=2)\n\n    def forward(self, hidden, encoder_outputs):\n        # Calculate the attention weights (energies) based on the given method\n        if self.method == \'general\':\n            attn_energies = self.general_score(hidden, encoder_outputs)\n        elif self.method == \'concat\':\n            attn_energies = self.concat_score(hidden, encoder_outputs)\n        elif self.method == \'dot\':\n            attn_energies = self.dot_score(hidden, encoder_outputs)\n\n        # Transpose max_length and batch_size dimensions\n        attn_energies = attn_energies.t()\n\n        # Return the softmax normalized probability scores (with added dimension)\n        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n\n\nclass LuongAttnDecoderRNN(nn.Module):\n    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n        super(LuongAttnDecoderRNN, self).__init__()\n\n        # Keep for reference\n        self.attn_model = attn_model\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.dropout = dropout\n\n        # Define layers\n        self.embedding = embedding\n        self.embedding_dropout = nn.Dropout(dropout)\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n\n        self.attn = Attn(attn_model, hidden_size)\n\n    def forward(self, input_step, last_hidden, encoder_outputs):\n        # Note: we run this one step (word) at a time\n        # Get embedding of current input word\n        embedded = self.embedding(input_step)\n        embedded = self.embedding_dropout(embedded)\n        # Forward through unidirectional GRU\n        rnn_output, hidden = self.gru(embedded, last_hidden)\n        # Calculate attention weights from the current GRU output\n        attn_weights = self.attn(rnn_output, encoder_outputs)\n        # Multiply attention weights to encoder outputs to get new ""weighted sum"" context vector\n        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n        # Concatenate weighted context vector and GRU output using Luong eq. 5\n        rnn_output = rnn_output.squeeze(0)\n        context = context.squeeze(1)\n        concat_input = torch.cat((rnn_output, context), 1)\n        concat_output = torch.tanh(self.concat(concat_input))\n        # Predict next word using Luong eq. 6\n        output = self.out(concat_output)\n        output = F.softmax(output, dim=1)\n        # Return output and final hidden state\n        return output, hidden\n\n\nclass GreedySearchDecoder(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super(GreedySearchDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, input_seq, input_length, max_length):\n        # Forward input through encoder model\n        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n        # Prepare encoder\'s final hidden layer to be first hidden input to the decoder\n        decoder_hidden = encoder_hidden[:self.decoder.n_layers]\n        # Initialize decoder input with SOS_token\n        decoder_input = torch.ones(1, 1, device=self.device, dtype=torch.long) * SOS_token\n        # Initialize tensors to append decoded words to\n        all_tokens = torch.zeros([0], device=self.device, dtype=torch.long)\n        all_scores = torch.zeros([0], device=self.device)\n        # Iteratively decode one word token at a time\n        for _ in range(max_length):\n            # Forward pass through decoder\n            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n            # Obtain most likely word token and its softmax score\n            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n            # Record token and score\n            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n            # Prepare current token to be next decoder input (add a dimension)\n            decoder_input = torch.unsqueeze(decoder_input, 0)\n        # Return collections of word tokens and scores\n        return all_tokens, all_scores\n'"
src/chatbot/u_tools.py,2,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom u_class import Voc, EncoderRNN, LuongAttnDecoderRNN\n\n\n# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return \'\'.join(\n        c for c in unicodedata.normalize(\'NFD\', s)\n        if unicodedata.category(c) != \'Mn\'\n    )\n\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    s = re.sub(r""\\s+"", r"" "", s).strip()\n    return s\n\n\ndef load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, \n        dropout, learning_rate, decoder_learning_ratio):\n\n    # Load model if a loadFilename is provided\n    if os.path.exists(loadFilename):\n        # If loading on same machine the model was trained on\n        checkpoint = torch.load(loadFilename)\n        cp_start_iteration = checkpoint[\'iteration\']\n        encoder_sd = checkpoint[\'state_dict_en\']\n        decoder_sd = checkpoint[\'state_dict_de\']\n        encoder_optimizer_sd = checkpoint[\'state_dict_en_opt\']\n        decoder_optimizer_sd = checkpoint[\'state_dict_de_opt\']\n        # loss = checkpoint[\'loss\']\n        voc.__dict__ = checkpoint[\'voc_dict\']\n        embedding_sd = checkpoint[\'embedding\']\n\n    print(\'Building encoder and decoder ...\')\n    # Initialize word embeddings\n    embedding = nn.Embedding(voc.num_words, hidden_size)\n    if os.path.exists(loadFilename):\n        embedding.load_state_dict(embedding_sd)\n\n    print(\'Initialize encoder & decoder models\')\n    encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n    decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n    print(\'Building optimizers ...\')\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n    if os.path.exists(loadFilename):\n        encoder.load_state_dict(encoder_sd)\n        decoder.load_state_dict(decoder_sd)\n        encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n        decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n\n    print(\'Models built and ready to go!\')\n    return cp_start_iteration, voc, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding\n'"
src/lstm/Demo-BiLSTM_CRF.py,18,"b'# coding: utf-8\n# \xe4\xbd\x9c\xe8\x80\x85: Robert Guthrie\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.optim as optim\n\ntorch.manual_seed(1)\n\n\ndef to_scalar(var):\n    # \xe8\xbf\x94\xe5\x9b\x9e python \xe6\xb5\xae\xe7\x82\xb9\xe6\x95\xb0 (float)\n    return var.view(-1).data.tolist()[0]\n\n\ndef argmax(vec):\n    # \xe4\xbb\xa5 python \xe6\x95\xb4\xe6\x95\xb0\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe8\xbf\x94\xe5\x9b\x9e argmax\n    _, idx = torch.max(vec, 1)\n    return to_scalar(idx)\n\n\ndef prepare_sequence(seq, to_ix):\n    idxs = [to_ix[w] for w in seq]\n    tensor = torch.LongTensor(idxs)\n    return autograd.Variable(tensor)\n\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe6\x95\xb0\xe5\x80\xbc\xe4\xb8\x8a\xe7\xa8\xb3\xe5\xae\x9a\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xba\xe5\x89\x8d\xe5\x90\x91\xe7\xae\x97\xe6\xb3\x95\xe8\xae\xa1\xe7\xae\x97\xe6\x8c\x87\xe6\x95\xb0\xe5\x92\x8c\xe7\x9a\x84\xe5\xaf\xb9\xe6\x95\xb0\ndef log_sum_exp(vec):\n    max_score = vec[0, argmax(vec)]\n    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n    return max_score + \\\n        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n\n\nclass BiLSTM_CRF(nn.Module):\n    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n        super(BiLSTM_CRF, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.vocab_size = vocab_size\n        self.tag_to_ix = tag_to_ix\n        self.tagset_size = len(tag_to_ix)\n\n        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(\n            embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n\n        # \xe5\xb0\x86LSTM\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe6\x98\xa0\xe5\xb0\x84\xe5\x88\xb0\xe6\xa0\x87\xe8\xae\xb0\xe7\xa9\xba\xe9\x97\xb4\n        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n\n        # \xe8\xbf\x87\xe6\xb8\xa1\xe5\x8f\x82\xe6\x95\xb0\xe7\x9f\xa9\xe9\x98\xb5. \xe6\x9d\xa1\xe7\x9b\xae i,j \xe6\x98\xaf\n        # *\xe4\xbb\x8e * j *\xe5\x88\xb0* i \xe7\x9a\x84\xe8\xbf\x87\xe6\xb8\xa1\xe7\x9a\x84\xe5\x88\x86\xe6\x95\xb0\n        self.transitions = nn.Parameter(\n            torch.randn(self.tagset_size, self.tagset_size))\n\n        # \xe8\xbf\x99\xe4\xb8\xa4\xe5\x8f\xa5\xe5\xa3\xb0\xe6\x98\x8e\xe5\xbc\xba\xe5\x88\xb6\xe7\xba\xa6\xe6\x9d\x9f\xe4\xba\x86\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\x8d\xe8\x83\xbd\n        # \xe5\x90\x91\xe5\xbc\x80\xe5\xa7\x8b\xe6\xa0\x87\xe8\xae\xb0\xe6\xa0\x87\xe6\xb3\xa8\xe4\xbc\xa0\xe9\x80\x92\xe5\x92\x8c\xe4\xbb\x8e\xe7\xbb\x93\xe6\x9d\x9f\xe6\xa0\x87\xe6\xb3\xa8\xe4\xbc\xa0\xe9\x80\x92\n        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n\n        self.hidden = self.init_hidden()\n\n    def init_hidden(self):\n        return (autograd.Variable(torch.randn(2, 1, self.hidden_dim // 2)),\n                autograd.Variable(torch.randn(2, 1, self.hidden_dim // 2)))\n\n    def _forward_alg(self, feats):\n        # \xe6\x89\xa7\xe8\xa1\x8c\xe5\x89\x8d\xe5\x90\x91\xe7\xae\x97\xe6\xb3\x95\xe6\x9d\xa5\xe8\xae\xa1\xe7\xae\x97\xe5\x88\x86\xe5\x89\xb2\xe5\x87\xbd\xe6\x95\xb0\n        init_alphas = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n        # START_TAG \xe5\x8c\x85\xe5\x90\xab\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x88\x86\xe6\x95\xb0\n        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n\n        # \xe5\xb0\x86\xe5\x85\xb6\xe5\x8c\x85\xe5\x9c\xa8\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x98\xe9\x87\x8f\xe7\xb1\xbb\xe5\x9e\x8b\xe4\xb8\xad\xe7\xbb\xa7\xe8\x80\x8c\xe5\xbe\x97\xe5\x88\xb0\xe8\x87\xaa\xe5\x8a\xa8\xe7\x9a\x84\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\n        forward_var = autograd.Variable(init_alphas)\n\n        # \xe5\x9c\xa8\xe5\x8f\xa5\xe5\xad\x90\xe4\xb8\xad\xe8\xbf\xad\xe4\xbb\xa3\n        for feat in feats:\n            alphas_t = []  # \xe5\x9c\xa8\xe8\xbf\x99\xe4\xb8\xaa\xe6\x97\xb6\xe9\x97\xb4\xe6\xad\xa5\xe7\x9a\x84\xe5\x89\x8d\xe5\x90\x91\xe5\x8f\x98\xe9\x87\x8f\n            for next_tag in range(self.tagset_size):\n                # \xe5\xaf\xb9 emission \xe5\xbe\x97\xe5\x88\x86\xe6\x89\xa7\xe8\xa1\x8c\xe5\xb9\xbf\xe6\x92\xad\xe6\x9c\xba\xe5\x88\xb6: \xe5\xae\x83\xe6\x80\xbb\xe6\x98\xaf\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84,\n                # \xe4\xb8\x8d\xe8\xae\xba\xe5\x89\x8d\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\x87\xe6\xb3\xa8\xe5\xa6\x82\xe4\xbd\x95\n                emit_score = feat[next_tag].view(\n                    1, -1).expand(1, self.tagset_size)\n                # trans_score \xe7\xac\xac i \xe4\xb8\xaa\xe6\x9d\xa1\xe7\x9b\xae\xe6\x98\xaf\n                # \xe4\xbb\x8ei\xe8\xbf\x87\xe6\xb8\xa1\xe5\x88\xb0 next_tag \xe7\x9a\x84\xe5\x88\x86\xe6\x95\xb0\n                trans_score = self.transitions[next_tag].view(1, -1)\n                # next_tag_var \xe7\xac\xac i \xe4\xb8\xaa\xe6\x9d\xa1\xe7\x9b\xae\xe6\x98\xaf\xe5\x9c\xa8\xe6\x88\x91\xe4\xbb\xac\xe6\x89\xa7\xe8\xa1\x8c \xe5\xaf\xb9\xe6\x95\xb0-\xe6\xb1\x82\xe5\x92\x8c-\xe6\x8c\x87\xe6\x95\xb0 \xe5\x89\x8d\n                # \xe8\xbe\xb9\xe7\xbc\x98\xe7\x9a\x84\xe5\x80\xbc (i -> next_tag)\n                next_tag_var = forward_var + trans_score + emit_score\n                # \xe8\xbf\x99\xe4\xb8\xaa\xe6\xa0\x87\xe6\xb3\xa8\xe7\x9a\x84\xe5\x89\x8d\xe5\x90\x91\xe5\x8f\x98\xe9\x87\x8f\xe6\x98\xaf\n                # \xe5\xaf\xb9\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x88\x86\xe6\x95\xb0\xe6\x89\xa7\xe8\xa1\x8c \xe5\xaf\xb9\xe6\x95\xb0-\xe6\xb1\x82\xe5\x92\x8c-\xe6\x8c\x87\xe6\x95\xb0\n                alphas_t.append(log_sum_exp(next_tag_var))\n            forward_var = torch.cat(alphas_t).view(1, -1)\n        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n        alpha = log_sum_exp(terminal_var)\n        return alpha\n\n    def _get_lstm_features(self, sentence):\n        self.hidden = self.init_hidden()\n        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n        lstm_feats = self.hidden2tag(lstm_out)\n        return lstm_feats\n\n    def _score_sentence(self, feats, tags):\n        # \xe7\xbb\x99\xe5\x87\xba\xe6\xa0\x87\xe8\xae\xb0\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\x88\x86\xe6\x95\xb0\n        score = autograd.Variable(torch.Tensor([0]))\n        tags = torch.cat([torch.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n        for i, feat in enumerate(feats):\n            score = score + \\\n                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n        return score\n\n    def _viterbi_decode(self, feats):\n        backpointers = []\n\n        # \xe5\x9c\xa8\xe5\xaf\xb9\xe6\x95\xb0\xe7\xa9\xba\xe9\x97\xb4\xe4\xb8\xad\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\xbb\xb4\xe7\x89\xb9\xe6\xaf\x94\xe5\x8f\x98\xe9\x87\x8f\n        init_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n\n        # \xe5\x9c\xa8\xe7\xac\xac i \xe6\xad\xa5\xe7\x9a\x84 forward_var \xe5\xad\x98\xe6\x94\xbe\xe7\xac\xac i-1 \xe6\xad\xa5\xe7\x9a\x84\xe7\xbb\xb4\xe7\x89\xb9\xe6\xaf\x94\xe5\x8f\x98\xe9\x87\x8f\n        forward_var = autograd.Variable(init_vvars)\n        for feat in feats:\n            bptrs_t = []  # \xe5\xad\x98\xe6\x94\xbe\xe8\xbf\x99\xe4\xb8\x80\xe6\xad\xa5\xe7\x9a\x84\xe5\x90\x8e\xe6\x8c\x87\xe9\x92\x88\n            viterbivars_t = []  # \xe5\xad\x98\xe6\x94\xbe\xe8\xbf\x99\xe4\xb8\x80\xe6\xad\xa5\xe7\x9a\x84\xe7\xbb\xb4\xe7\x89\xb9\xe6\xaf\x94\xe5\x8f\x98\xe9\x87\x8f\n\n            for next_tag in range(self.tagset_size):\n                # next_tag_var[i] \xe5\xad\x98\xe6\x94\xbe\xe5\x85\x88\xe5\x89\x8d\xe4\xb8\x80\xe6\xad\xa5\xe6\xa0\x87\xe6\xb3\xa8i\xe7\x9a\x84\n                # \xe7\xbb\xb4\xe7\x89\xb9\xe6\xaf\x94\xe5\x8f\x98\xe9\x87\x8f, \xe5\x8a\xa0\xe4\xb8\x8a\xe4\xba\x86\xe4\xbb\x8e\xe6\xa0\x87\xe6\xb3\xa8 i \xe5\x88\xb0 next_tag \xe7\x9a\x84\xe8\xbf\x87\xe6\xb8\xa1\n                # \xe7\x9a\x84\xe5\x88\x86\xe6\x95\xb0\n                # \xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\xb9\xb6\xe6\xb2\xa1\xe6\x9c\x89\xe5\xb0\x86 emission \xe5\x88\x86\xe6\x95\xb0\xe5\x8c\x85\xe5\x90\xab\xe8\xbf\x9b\xe6\x9d\xa5, \xe5\x9b\xa0\xe4\xb8\xba\n                # \xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe5\xb9\xb6\xe4\xb8\x8d\xe4\xbe\x9d\xe8\xb5\x96\xe4\xba\x8e\xe5\xae\x83\xe4\xbb\xac(\xe6\x88\x91\xe4\xbb\xac\xe5\x9c\xa8\xe4\xb8\x8b\xe9\x9d\xa2\xe5\xaf\xb9\xe5\xae\x83\xe4\xbb\xac\xe8\xbf\x9b\xe8\xa1\x8c\xe7\x9a\x84\xe6\x98\xaf\xe7\x9b\xb8\xe5\x8a\xa0)\n                next_tag_var = forward_var + self.transitions[next_tag]\n                best_tag_id = argmax(next_tag_var)\n                bptrs_t.append(best_tag_id)\n                viterbivars_t.append(next_tag_var[0][best_tag_id])\n            # \xe7\x8e\xb0\xe5\x9c\xa8\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89 emission \xe5\xbe\x97\xe5\x88\x86\xe7\x9b\xb8\xe5\x8a\xa0, \xe5\xb0\x86 forward_var\n            # \xe8\xb5\x8b\xe5\x80\xbc\xe5\x88\xb0\xe6\x88\x91\xe4\xbb\xac\xe5\x88\x9a\xe5\x88\x9a\xe8\xae\xa1\xe7\xae\x97\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe7\xbb\xb4\xe7\x89\xb9\xe6\xaf\x94\xe5\x8f\x98\xe9\x87\x8f\xe9\x9b\x86\xe5\x90\x88\n            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n            backpointers.append(bptrs_t)\n\n        # \xe8\xbf\x87\xe6\xb8\xa1\xe5\x88\xb0 STOP_TAG\n        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n        best_tag_id = argmax(terminal_var)\n        path_score = terminal_var[0][best_tag_id]\n\n        # \xe8\xb7\x9f\xe7\x9d\x80\xe5\x90\x8e\xe6\x8c\x87\xe9\x92\x88\xe5\x8e\xbb\xe8\xa7\xa3\xe7\xa0\x81\xe6\x9c\x80\xe4\xbd\xb3\xe8\xb7\xaf\xe5\xbe\x84\n        best_path = [best_tag_id]\n        for bptrs_t in reversed(backpointers):\n            best_tag_id = bptrs_t[best_tag_id]\n            best_path.append(best_tag_id)\n        # \xe5\xbc\xb9\xe5\x87\xba\xe5\xbc\x80\xe5\xa7\x8b\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe (\xe6\x88\x91\xe4\xbb\xac\xe5\xb9\xb6\xe4\xb8\x8d\xe5\xb8\x8c\xe6\x9c\x9b\xe6\x8a\x8a\xe8\xbf\x99\xe4\xb8\xaa\xe8\xbf\x94\xe5\x9b\x9e\xe5\x88\xb0\xe8\xb0\x83\xe7\x94\xa8\xe5\x87\xbd\xe6\x95\xb0)\n        start = best_path.pop()\n        assert start == self.tag_to_ix[START_TAG]  # \xe5\x81\xa5\xe5\x85\xa8\xe6\x80\xa7\xe6\xa3\x80\xe6\x9f\xa5\n        best_path.reverse()\n        return path_score, best_path\n\n    def neg_log_likelihood(self, sentence, tags):\n        feats = self._get_lstm_features(sentence)\n        forward_score = self._forward_alg(feats)\n        gold_score = self._score_sentence(feats, tags)\n        return forward_score - gold_score\n\n    def forward(self, sentence):  # \xe4\xb8\x8d\xe8\xa6\x81\xe6\x8a\x8a\xe8\xbf\x99\xe5\x92\x8c\xe4\xb8\x8a\xe9\x9d\xa2\xe7\x9a\x84 _forward_alg \xe6\xb7\xb7\xe6\xb7\x86\n        # \xe5\xbe\x97\xe5\x88\xb0 BiLSTM \xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe6\x95\xb0\n        lstm_feats = self._get_lstm_features(sentence)\n\n        # \xe7\xbb\x99\xe5\xae\x9a\xe7\x89\xb9\xe5\xbe\x81, \xe6\x89\xbe\xe5\x88\xb0\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\n        score, tag_seq = self._viterbi_decode(lstm_feats)\n        return score, tag_seq\n\n\nSTART_TAG = ""<START>""\nSTOP_TAG = ""<STOP>""\nEMBEDDING_DIM = 5\nHIDDEN_DIM = 4\n\n# \xe7\xbc\x96\xe9\x80\xa0\xe4\xb8\x80\xe4\xba\x9b\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\ntraining_data = [(\n    ""the wall street journal reported today that apple corporation made money"".\n    split(), ""B I I I O O O B I O O"".split()),\n                 (""georgia tech is a university in georgia"".split(),\n                  ""B I O O O O B"".split())]\n\nword_to_ix = {}\nfor sentence, tags in training_data:\n    for word in sentence:\n        if word not in word_to_ix:\n            word_to_ix[word] = len(word_to_ix)\n\ntag_to_ix = {""B"": 0, ""I"": 1, ""O"": 2, START_TAG: 3, STOP_TAG: 4}\n\nmodel = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\noptimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n\n# \xe5\x9c\xa8\xe8\xae\xad\xe7\xbb\x83\xe4\xb9\x8b\xe5\x89\x8d\xe6\xa3\x80\xe6\x9f\xa5\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\nprecheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\nprecheck_tags = torch.LongTensor([tag_to_ix[t] for t in training_data[0][1]])\nprint(model(precheck_sent))\n\n# \xe7\xa1\xae\xe8\xae\xa4\xe4\xbb\x8e\xe4\xb9\x8b\xe5\x89\x8d\xe7\x9a\x84 LSTM \xe9\x83\xa8\xe5\x88\x86\xe7\x9a\x84 prepare_sequence \xe8\xa2\xab\xe5\x8a\xa0\xe8\xbd\xbd\xe4\xba\x86\nfor epoch in range(300):  # \xe5\x8f\x88\xe4\xb8\x80\xe6\xac\xa1, \xe6\xad\xa3\xe5\xb8\xb8\xe6\x83\x85\xe5\x86\xb5\xe4\xb8\x8b\xe4\xbd\xa0\xe4\xb8\x8d\xe4\xbc\x9a\xe8\xae\xad\xe7\xbb\x83300\xe4\xb8\xaa epoch, \xe8\xbf\x99\xe5\x8f\xaa\xe6\x98\xaf\xe7\xa4\xba\xe4\xbe\x8b\xe6\x95\xb0\xe6\x8d\xae\n    for sentence, tags in training_data:\n        # \xe7\xac\xac\xe4\xb8\x80\xe6\xad\xa5: \xe9\x9c\x80\xe8\xa6\x81\xe8\xae\xb0\xe4\xbd\x8f\xe7\x9a\x84\xe6\x98\xafPytorch\xe4\xbc\x9a\xe7\xb4\xaf\xe7\xa7\xaf\xe6\xa2\xaf\xe5\xba\xa6\n        # \xe6\x88\x91\xe4\xbb\xac\xe9\x9c\x80\xe8\xa6\x81\xe5\x9c\xa8\xe6\xaf\x8f\xe6\xac\xa1\xe5\xae\x9e\xe4\xbe\x8b\xe4\xb9\x8b\xe5\x89\x8d\xe6\x8a\x8a\xe5\xae\x83\xe4\xbb\xac\xe6\xb8\x85\xe9\x99\xa4\n        model.zero_grad()\n\n        # \xe7\xac\xac\xe4\xba\x8c\xe6\xad\xa5: \xe4\xb8\xba\xe6\x88\x91\xe4\xbb\xac\xe7\x9a\x84\xe7\xbd\x91\xe7\xbb\x9c\xe5\x87\x86\xe5\xa4\x87\xe5\xa5\xbd\xe8\xbe\x93\xe5\x85\xa5, \xe5\x8d\xb3\n        # \xe6\x8a\x8a\xe5\xae\x83\xe4\xbb\xac\xe8\xbd\xac\xe5\x8f\x98\xe6\x88\x90\xe5\x8d\x95\xe8\xaf\x8d\xe7\xb4\xa2\xe5\xbc\x95\xe5\x8f\x98\xe9\x87\x8f (Variables)\n        sentence_in = prepare_sequence(sentence, word_to_ix)\n        targets = torch.LongTensor([tag_to_ix[t] for t in tags])\n\n        # \xe7\xac\xac\xe4\xb8\x89\xe6\xad\xa5: \xe8\xbf\x90\xe8\xa1\x8c\xe5\x89\x8d\xe5\x90\x91\xe4\xbc\xa0\xe9\x80\x92.\n        neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets)\n\n        # \xe7\xac\xac\xe5\x9b\x9b\xe6\xad\xa5: \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1, \xe6\xa2\xaf\xe5\xba\xa6\xe4\xbb\xa5\xe5\x8f\x8a\n        # \xe4\xbd\xbf\xe7\x94\xa8 optimizer.step() \xe6\x9d\xa5\xe6\x9b\xb4\xe6\x96\xb0\xe5\x8f\x82\xe6\x95\xb0\n        neg_log_likelihood.backward()\n        optimizer.step()\n\n# \xe5\x9c\xa8\xe8\xae\xad\xe7\xbb\x83\xe4\xb9\x8b\xe5\x90\x8e\xe6\xa3\x80\xe6\x9f\xa5\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\nprecheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\nprint(model(precheck_sent))\n# \xe6\x88\x91\xe4\xbb\xac\xe5\xae\x8c\xe6\x88\x90\xe4\xba\x86!\n'"
src/lstm/Demo-LSTMTagger.py,7,"b'# coding: utf-8\n# \xe4\xbd\x9c\xe8\x80\x85: Robert Guthrie\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n\ndef prepare_sequence(seq, to_ix):\n    idxs = [to_ix[w] for w in seq]\n    tensor = torch.LongTensor(idxs)\n    return autograd.Variable(tensor)\n\n\ntraining_data = [\n    (""The dog ate the apple"".split(), [""DET"", ""NN"", ""V"", ""DET"", ""NN""]),\n    (""Everybody read that book"".split(), [""NN"", ""V"", ""DET"", ""NN""])\n]\nword_to_ix = {}\nfor sent, tags in training_data:\n    for word in sent:\n        if word not in word_to_ix:\n            word_to_ix[word] = len(word_to_ix)\nprint(word_to_ix)\ntag_to_ix = {""DET"": 0, ""NN"": 1, ""V"": 2}\n\n# \xe5\xae\x9e\xe9\x99\x85\xe4\xb8\xad\xe9\x80\x9a\xe5\xb8\xb8\xe4\xbd\xbf\xe7\x94\xa8\xe6\x9b\xb4\xe5\xa4\xa7\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\xe5\xa6\x8232\xe7\xbb\xb4, 64\xe7\xbb\xb4.\n# \xe8\xbf\x99\xe9\x87\x8c\xe6\x88\x91\xe4\xbb\xac\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6, \xe4\xb8\xba\xe4\xba\x86\xe6\x96\xb9\xe4\xbe\xbf\xe6\x9f\xa5\xe7\x9c\x8b\xe8\xae\xad\xe7\xbb\x83\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe6\x9d\x83\xe9\x87\x8d\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96.\nEMBEDDING_DIM = 6\nHIDDEN_DIM = 6\n\n\nclass LSTMTagger(nn.Module):\n    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n        super(LSTMTagger, self).__init__()\n        self.hidden_dim = hidden_dim\n\n        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n\n        #  LSTM \xe4\xbb\xa5 word_embeddings \xe4\xbd\x9c\xe4\xb8\xba\xe8\xbe\x93\xe5\x85\xa5, \xe8\xbe\x93\xe5\x87\xba\xe7\xbb\xb4\xe5\xba\xa6\xe4\xb8\xba hidden_dim \xe7\x9a\x84\xe9\x9a\x90\xe7\x8a\xb6\xe6\x80\x81\xe5\x80\xbc\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n\n        # \xe7\xba\xbf\xe6\x80\xa7\xe5\xb1\x82\xe5\xb0\x86\xe9\x9a\x90\xe7\x8a\xb6\xe6\x80\x81\xe7\xa9\xba\xe9\x97\xb4\xe6\x98\xa0\xe5\xb0\x84\xe5\x88\xb0\xe6\xa0\x87\xe6\xb3\xa8\xe7\xa9\xba\xe9\x97\xb4\n        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n        self.hidden = self.init_hidden()\n\n    def init_hidden(self):\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x97\xb6\xe5\x88\xbb, \xe6\xb2\xa1\xe6\x9c\x89\xe9\x9a\x90\xe7\x8a\xb6\xe6\x80\x81\n        # \xe5\x85\xb3\xe4\xba\x8e\xe7\xbb\xb4\xe5\xba\xa6\xe8\xae\xbe\xe7\xbd\xae\xe7\x9a\x84\xe8\xaf\xa6\xe6\x83\x85,\xe8\xaf\xb7\xe5\x8f\x82\xe8\x80\x83 Pytorch \xe6\x96\x87\xe6\xa1\xa3\n        # \xe5\x90\x84\xe4\xb8\xaa\xe7\xbb\xb4\xe5\xba\xa6\xe7\x9a\x84\xe5\x90\xab\xe4\xb9\x89\xe6\x98\xaf (num_layers, minibatch_size, hidden_dim)\n        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)),\n                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n\n    def forward(self, sentence):\n        embeds = self.word_embeddings(sentence)\n        lstm_out, self.hidden = self.lstm(\n            embeds.view(len(sentence), 1, -1), self.hidden)\n        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n        tag_scores = F.log_softmax(tag_space, dim=1)\n        return tag_scores\n\n\nmodel = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\nloss_function = nn.NLLLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\n# \xe6\x9f\xa5\xe7\x9c\x8b\xe4\xb8\x8b\xe8\xae\xad\xe7\xbb\x83\xe5\x89\x8d\xe5\xbe\x97\xe5\x88\x86\xe7\x9a\x84\xe5\x80\xbc\n# \xe6\xb3\xa8\xe6\x84\x8f: \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84 i,j \xe5\x85\x83\xe7\xb4\xa0\xe7\x9a\x84\xe5\x80\xbc\xe8\xa1\xa8\xe7\xa4\xba\xe5\x8d\x95\xe8\xaf\x8d i \xe7\x9a\x84 j \xe6\xa0\x87\xe7\xad\xbe\xe7\x9a\x84\xe5\xbe\x97\xe5\x88\x86\ninputs = prepare_sequence(training_data[0][0], word_to_ix)\ntag_scores = model(inputs)\nprint(tag_scores)\n\nfor epoch in range(300):  # \xe5\x86\x8d\xe6\xac\xa1\xe8\xaf\xb4\xe6\x98\x8e\xe4\xb8\x8b, \xe5\xae\x9e\xe9\x99\x85\xe6\x83\x85\xe5\x86\xb5\xe4\xb8\x8b\xe4\xbd\xa0\xe4\xb8\x8d\xe4\xbc\x9a\xe8\xae\xad\xe7\xbb\x83300\xe4\xb8\xaa\xe5\x91\xa8\xe6\x9c\x9f, \xe6\xad\xa4\xe4\xbe\x8b\xe4\xb8\xad\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaa\xe6\x98\xaf\xe6\x9e\x84\xe9\x80\xa0\xe4\xba\x86\xe4\xb8\x80\xe4\xba\x9b\xe5\x81\x87\xe6\x95\xb0\xe6\x8d\xae\n    for sentence, tags in training_data:\n        # Step 1. \xe8\xaf\xb7\xe8\xae\xb0\xe4\xbd\x8f Pytorch \xe4\xbc\x9a\xe7\xb4\xaf\xe5\x8a\xa0\xe6\xa2\xaf\xe5\xba\xa6\n        # \xe6\xaf\x8f\xe6\xac\xa1\xe8\xae\xad\xe7\xbb\x83\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\xb8\x85\xe7\xa9\xba\xe6\xa2\xaf\xe5\xba\xa6\xe5\x80\xbc\n        model.zero_grad()\n\n        # \xe6\xad\xa4\xe5\xa4\x96\xe8\xbf\x98\xe9\x9c\x80\xe8\xa6\x81\xe6\xb8\x85\xe7\xa9\xba LSTM \xe7\x9a\x84\xe9\x9a\x90\xe7\x8a\xb6\xe6\x80\x81\n        # \xe5\xb0\x86\xe5\x85\xb6\xe4\xbb\x8e\xe4\xb8\x8a\xe4\xb8\xaa\xe5\xae\x9e\xe4\xbe\x8b\xe7\x9a\x84\xe5\x8e\x86\xe5\x8f\xb2\xe4\xb8\xad\xe5\x88\x86\xe7\xa6\xbb\xe5\x87\xba\xe6\x9d\xa5\n        model.hidden = model.init_hidden()\n\n        # Step 2. \xe5\x87\x86\xe5\xa4\x87\xe7\xbd\x91\xe7\xbb\x9c\xe8\xbe\x93\xe5\x85\xa5, \xe5\xb0\x86\xe5\x85\xb6\xe5\x8f\x98\xe4\xb8\xba\xe8\xaf\x8d\xe7\xb4\xa2\xe5\xbc\x95\xe7\x9a\x84 Variables \xe7\xb1\xbb\xe5\x9e\x8b\xe6\x95\xb0\xe6\x8d\xae\n        sentence_in = prepare_sequence(sentence, word_to_ix)\n        targets = prepare_sequence(tags, tag_to_ix)\n\n        # Step 3. \xe5\x89\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\n        tag_scores = model(sentence_in)\n\n        # Step 4. \xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x92\x8c\xe6\xa2\xaf\xe5\xba\xa6\xe5\x80\xbc, \xe9\x80\x9a\xe8\xbf\x87\xe8\xb0\x83\xe7\x94\xa8 optimizer.step() \xe6\x9d\xa5\xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\n        loss = loss_function(tag_scores, targets)\n        loss.backward()\n        optimizer.step()\n\n\n# \xe6\x9f\xa5\xe7\x9c\x8b\xe8\xae\xad\xe7\xbb\x83\xe5\x90\x8e\xe5\xbe\x97\xe5\x88\x86\xe7\x9a\x84\xe5\x80\xbc\ninputs = prepare_sequence(training_data[0][0], word_to_ix)\nprint(\'inputs: \\n\', inputs)\ntag_scores = model(inputs)\n# \xe5\x8f\xa5\xe5\xad\x90\xe6\x98\xaf ""the dog ate the apple"", i,j \xe8\xa1\xa8\xe7\xa4\xba\xe5\xaf\xb9\xe4\xba\x8e\xe5\x8d\x95\xe8\xaf\x8d i, \xe6\xa0\x87\xe7\xad\xbe j \xe7\x9a\x84\xe5\xbe\x97\xe5\x88\x86.\n# \xe6\x88\x91\xe4\xbb\xac\xe9\x87\x87\xe7\x94\xa8\xe5\xbe\x97\xe5\x88\x86\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\xe4\xbd\x9c\xe4\xb8\xba\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe. \xe4\xbb\x8e\xe4\xb8\x8b\xe9\x9d\xa2\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe6\x88\x91\xe4\xbb\xac\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x9c\x8b\xe5\x88\xb0, \xe9\xa2\x84\xe6\xb5\x8b\xe5\xbe\x97\n# \xe5\x88\xb0\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe6\x98\xaf0 1 2 0 1. \xe5\x9b\xa0\xe4\xb8\xba \xe7\xb4\xa2\xe5\xbc\x95\xe6\x98\xaf\xe4\xbb\x8e0\xe5\xbc\x80\xe5\xa7\x8b\xe7\x9a\x84, \xe5\x9b\xa0\xe6\xad\xa4\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc0\xe8\xa1\xa8\xe7\xa4\xba\xe7\xac\xac\xe4\xb8\x80\xe8\xa1\x8c\xe7\x9a\x84\n# \xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc, \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x80\xbc1\xe8\xa1\xa8\xe7\xa4\xba\xe7\xac\xac\xe4\xba\x8c\xe8\xa1\x8c\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc, \xe4\xbb\xa5\xe6\xad\xa4\xe7\xb1\xbb\xe6\x8e\xa8. \xe6\x89\x80\xe4\xbb\xa5\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe6\x98\xaf DET\n# NOUN VERB DET NOUN, \xe6\x95\xb4\xe4\xb8\xaa\xe5\xba\x8f\xe5\x88\x97\xe9\x83\xbd\xe6\x98\xaf\xe6\xad\xa3\xe7\xa1\xae\xe7\x9a\x84!\nprint(\'tag_scores: \\n\', tag_scores)\n'"
src/lstm/test.py,11,"b'# coding: utf-8\n# \xe4\xbd\x9c\xe8\x80\x85: Robert Guthrie\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ntorch.manual_seed(1)\n\nlstm = nn.LSTM(3, 3)  # \xe8\xbe\x93\xe5\x85\xa5\xe7\xbb\xb4\xe5\xba\xa6\xe6\x98\xaf3, \xe8\xbe\x93\xe5\x87\xba\xe7\xbb\xb4\xe5\xba\xa6\xe4\xb9\x9f\xe6\x98\xaf3\ninputs = [autograd.Variable(torch.randn((1, 3)))\n          for _ in range(5)]  # \xe6\x9e\x84\xe9\x80\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\xba5\xe7\x9a\x84\xe5\xba\x8f\xe5\x88\x97\n\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe9\x9a\x90\xe8\x97\x8f\xe7\x8a\xb6\xe6\x80\x81\nhidden = (autograd.Variable(torch.randn(1, 1, 3)),\n          autograd.Variable(torch.randn((1, 1, 3))))\nfor i in inputs:\n    # \xe5\xb0\x86\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\x85\x83\xe7\xb4\xa0\xe9\x80\x90\xe4\xb8\xaa\xe8\xbe\x93\xe5\x85\xa5\xe5\x88\xb0LSTM\n    # \xe7\xbb\x8f\xe8\xbf\x87\xe6\xaf\x8f\xe6\xad\xa5\xe6\x93\x8d\xe4\xbd\x9c,hidden \xe7\x9a\x84\xe5\x80\xbc\xe5\x8c\x85\xe5\x90\xab\xe4\xba\x86\xe9\x9a\x90\xe8\x97\x8f\xe7\x8a\xb6\xe6\x80\x81\xe7\x9a\x84\xe4\xbf\xa1\xe6\x81\xaf\n    out, hidden = lstm(i.view(1, 1, -1), hidden)\n\n# \xe5\x8f\xa6\xe5\xa4\x96, \xe6\x88\x91\xe4\xbb\xac\xe8\xbf\x98\xe5\x8f\xaf\xe4\xbb\xa5\xe4\xb8\x80\xe6\xac\xa1\xe5\xaf\xb9\xe6\x95\xb4\xe4\xb8\xaa\xe5\xba\x8f\xe5\x88\x97\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83. LSTM \xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc\xe8\xa1\xa8\xe7\xa4\xba\xe6\x89\x80\xe6\x9c\x89\xe6\x97\xb6\xe5\x88\xbb\xe7\x9a\x84\xe9\x9a\x90\xe7\x8a\xb6\xe6\x80\x81\xe5\x80\xbc,\n# \xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x80\xbc\xe8\xa1\xa8\xe7\xa4\xba\xe6\x9c\x80\xe8\xbf\x91\xe7\x9a\x84\xe9\x9a\x90\xe7\x8a\xb6\xe6\x80\x81\xe5\x80\xbc (\xe5\x9b\xa0\xe6\xad\xa4\xe4\xb8\x8b\xe9\x9d\xa2\xe7\x9a\x84 ""out""\xe7\x9a\x84\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc\xe5\x92\x8c ""hidden"" \xe7\x9a\x84\xe5\x80\xbc\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84).\n# \xe4\xb9\x8b\xe6\x89\x80\xe4\xbb\xa5\xe8\xbf\x99\xe6\xa0\xb7\xe8\xae\xbe\xe8\xae\xa1, \xe6\x98\xaf\xe4\xb8\xba\xe4\xba\x86\xe9\x80\x9a\xe8\xbf\x87 ""out"" \xe7\x9a\x84\xe5\x80\xbc\xe6\x9d\xa5\xe8\x8e\xb7\xe5\x8f\x96\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe9\x9a\x90\xe7\x8a\xb6\xe6\x80\x81\xe5\x80\xbc, \xe8\x80\x8c\xe7\x94\xa8 ""hidden"" \xe7\x9a\x84\xe5\x80\xbc\xe6\x9d\xa5\n# \xe8\xbf\x9b\xe8\xa1\x8c\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\xe8\xbf\x90\xe7\xae\x97, \xe5\x85\xb7\xe4\xbd\x93\xe6\x96\xb9\xe5\xbc\x8f\xe5\xb0\xb1\xe6\x98\xaf\xe5\xb0\x86\xe5\xae\x83\xe4\xbd\x9c\xe4\xb8\xba\xe5\x8f\x82\xe6\x95\xb0\xe4\xbc\xa0\xe5\x85\xa5\xe5\x90\x8e\xe9\x9d\xa2\xe7\x9a\x84 LSTM \xe7\xbd\x91\xe7\xbb\x9c.\n\n# \xe5\xa2\x9e\xe5\x8a\xa0\xe9\xa2\x9d\xe5\xa4\x96\xe7\x9a\x84\xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe7\xbb\xb4\xe5\xba\xa6\ninputs = torch.cat(inputs).view(len(inputs), 1, -1)\nhidden = (autograd.Variable(torch.randn(1, 1, 3)), autograd.Variable(\n    torch.randn((1, 1, 3))))  # \xe6\xb8\x85\xe7\xa9\xba\xe8\xbe\x93\xe5\x87\xba\xe9\x9a\x90\xe7\x8a\xb6\xe6\x80\x81\nout, hidden = lstm(inputs, hidden)\nprint(""out: \\n"", out)\nprint(""hidden: \\n"", hidden)\n'"
src/play/test.py,0,"b'# -*- coding: utf-8 -*-  \n"""""" \nCreated on Mon Jun  5 09:04:16 2017 \n \nAuthor: Owner \n""""""  \n  \nfrom os import path  \nfrom PIL import Image  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \n  \nfrom wordcloud import WordCloud, STOPWORDS  \n  \nd = path.dirname(__file__)  \n  \n# Read the whole text.  \n#\xe6\x88\x91\xe8\xbf\x99\xe9\x87\x8c\xe5\x8a\xa0\xe8\xbd\xbd\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe6\x98\xaf\xe5\xb7\xb2\xe7\xbb\x8f\xe5\x88\x86\xe8\xaf\x8d\xe5\xa5\xbd\xe7\x9a\x84\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe5\x8a\xa0\xe8\xbd\xbd\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe6\x98\xaf\xe6\xb2\xa1\xe6\x9c\x89\xe5\x88\x86\xe8\xaf\x8d\xe7\x9a\x84\xef\xbc\x8c\xe8\xbf\x98\xe9\x9c\x80\xe8\xa6\x81\xe4\xbd\xbf\xe7\x94\xa8\xe5\x88\x86\xe8\xaf\x8d\xe5\xb7\xa5\xe5\x85\xb7\xe5\x85\x88\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x88\x86\xe8\xaf\x8d    \ntext = open(path.join(d, \'ctest2.txt\'),encoding=\'utf-8\').read()  \n  \n# read the mask image  \n# taken from  \n# http://www.stencilry.org/stencils/movies/alice%20in%20wonderland/255fk.jpg  \nalice_mask = np.array(Image.open(path.join(d, ""alice_mask.png"")))  \n  \nstopwords = set(STOPWORDS)  \nstopwords.add(""said"")  \n  \nwc = WordCloud(  \n    #\xe8\xae\xbe\xe7\xbd\xae\xe5\xad\x97\xe4\xbd\x93\xef\xbc\x8c\xe4\xb8\x8d\xe6\x8c\x87\xe5\xae\x9a\xe5\xb0\xb1\xe4\xbc\x9a\xe5\x87\xba\xe7\x8e\xb0\xe4\xb9\xb1\xe7\xa0\x81,\xe8\xbf\x99\xe4\xb8\xaa\xe5\xad\x97\xe4\xbd\x93\xe6\x96\x87\xe4\xbb\xb6\xe9\x9c\x80\xe8\xa6\x81\xe4\xb8\x8b\xe8\xbd\xbd   \n    font_path=""HYQiHei-25JF.ttf"",  \n    background_color=""white"",   \n    max_words=2000,   \n    mask=alice_mask,  \n    stopwords=stopwords)  \n      \n# generate word cloud  \nwc.generate(text)  \n  \n# store to file  \nwc.to_file(path.join(d, ""alice_cloud.png""))  \n  \n# show  \nplt.imshow(wc, interpolation=\'bilinear\')  \nplt.axis(""off"")  \nplt.figure()  \nplt.imshow(alice_mask, cmap=plt.cm.gray, interpolation=\'bilinear\')  \nplt.axis(""off"")  \nplt.show()  '"
docs/src/chatbot/run_demo.py,5,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nfrom u_tools import normalizeString, load_model\nfrom u_class import Voc, GreedySearchDecoder\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\nMAX_LENGTH = 10  # Maximum sentence length to consider\n\n\ndef indexesFromSentence(voc, sentence):\n    return [voc.word2index[word] for word in sentence.split(\' \')] + [EOS_token]\n\n\ndef evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n    ### Format input sentence as a batch\n    # words -> indexes\n    indexes_batch = [indexesFromSentence(voc, sentence)]\n    # Create lengths tensor\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    # Transpose dimensions of batch to match models\' expectations\n    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n    # Use appropriate device\n    input_batch = input_batch.to(device)\n    lengths = lengths.to(device)\n    # Decode sentence with searcher\n    tokens, scores = searcher(input_batch, lengths, max_length)\n    # indexes -> words\n    decoded_words = [voc.index2word[token.item()] for token in tokens]\n    return decoded_words\n\n\ndef evaluateInput(encoder, decoder, searcher, voc):\n    input_sentence = \'\'\n    while(1):\n        try:\n            # Get input sentence\n            input_sentence = input(\'> \')\n            # Check if it is quit case\n            if input_sentence == \'q\' or input_sentence == \'quit\': break\n            # Normalize sentence\n            input_sentence = normalizeString(input_sentence)\n            # Evaluate sentence\n            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n            # Format and print response sentence\n            output_words[:] = [x for x in output_words if not (x == \'EOS\' or x == \'PAD\')]\n            print(\'Bot:\', \' \'.join(output_words))\n\n        except KeyError:\n            print(""Error: Encountered unknown word."")\n\n\nif __name__ == ""__main__"":\n    global device, corpus_name\n    USE_CUDA = torch.cuda.is_available()\n    device = torch.device(""cuda"" if USE_CUDA else ""cpu"")\n    corpus_name = ""cornell_movie-dialogs_corpus""\n\n\n    # Configure models\n    attn_model = \'dot\'\n    #attn_model = \'general\'\n    #attn_model = \'concat\'\n    hidden_size = 500\n    encoder_n_layers = 2\n    decoder_n_layers = 2\n    dropout = 0.1\n    cp_start_iteration = 0\n    learning_rate = 0.0001\n    decoder_learning_ratio = 5.0\n\n    loadFilename = ""data/save_copy/cb_model/%s/2-2_500/6000_checkpoint.tar"" % corpus_name\n    if os.path.exists(loadFilename):\n        voc = Voc(corpus_name)\n    cp_start_iteration, voc, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding = load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, dropout, learning_rate, decoder_learning_ratio)\n\n    # Use appropriate device\n    encoder = encoder.to(device)\n    decoder = decoder.to(device)\n    # Set dropout layers to eval mode\n    encoder.eval()\n    decoder.eval()\n\n    # Initialize search module\n    searcher = GreedySearchDecoder(encoder, decoder, device)\n\n    # Begin chatting (uncomment and run the following line to begin)\n    evaluateInput(encoder, decoder, searcher, voc)\n\n\n'"
docs/src/chatbot/run_train.py,15,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport random\nimport unicodedata\nimport itertools\nimport csv\nimport math\nimport codecs\nimport torch\nimport torch.nn as nn\nfrom u_tools import normalizeString, load_model\nfrom u_class import Voc\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\nMAX_LENGTH = 10  # Maximum sentence length to consider\nMIN_COUNT = 3    # Minimum word count threshold for trimming\n\n\ndef printLines(file, n=10):\n    with open(file, \'rb\') as datafile:\n        lines = datafile.readlines()\n    for line in lines[:n]:\n        print(line)\n\n# Splits each line of the file into a dictionary of fields\ndef loadLines(fileName, fields):\n    lines = {}\n    with open(fileName, \'r\', encoding=\'iso-8859-1\') as f:\n        for line in f:\n            values = line.split("" +++$+++ "")\n            # Extract fields\n            lineObj = {}\n            for i, field in enumerate(fields):\n                lineObj[field] = values[i]\n            lines[lineObj[\'lineID\']] = lineObj\n    return lines\n\n# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\ndef loadConversations(fileName, lines, fields):\n    conversations = []\n    with open(fileName, \'r\', encoding=\'iso-8859-1\') as f:\n        for line in f:\n            values = line.split("" +++$+++ "")\n            # Extract fields\n            convObj = {}\n            for i, field in enumerate(fields):\n                convObj[field] = values[i]\n            # Convert string to list (convObj[""utteranceIDs""] == ""[\'L598485\', \'L598486\', ...]"")\n            lineIds = eval(convObj[""utteranceIDs""])\n            # Reassemble lines\n            convObj[""lines""] = []\n            for lineId in lineIds:\n                convObj[""lines""].append(lines[lineId])\n            conversations.append(convObj)\n    return conversations\n\n# Extracts pairs of sentences from conversations\ndef extractSentencePairs(conversations):\n    qa_pairs = []\n    for conversation in conversations:\n        # Iterate over all the lines of the conversation\n        for i in range(len(conversation[""lines""]) - 1):  # We ignore the last line (no answer for it)\n            inputLine = conversation[""lines""][i][""text""].strip()\n            targetLine = conversation[""lines""][i+1][""text""].strip()\n            # Filter wrong samples (if one of the lists is empty)\n            if inputLine and targetLine:\n                qa_pairs.append([inputLine, targetLine])\n    return qa_pairs\n\n\n\ndef get_datafile(datafile):\n    # Define path to new file\n    delimiter = \'\\t\'\n    # Unescape the delimiter\n    delimiter = str(codecs.decode(delimiter, ""unicode_escape""))\n\n    # Initialize lines dict, conversations list, and field ids\n    lines = {}\n    conversations = []\n    MOVIE_LINES_FIELDS = [""lineID"", ""characterID"", ""movieID"", ""character"", ""text""]\n    MOVIE_CONVERSATIONS_FIELDS = [""character1ID"", ""character2ID"", ""movieID"", ""utteranceIDs""]\n\n    # Load lines and process conversations\n    print(""\\nProcessing corpus..."")\n    lines = loadLines(os.path.join(corpus, ""movie_lines.txt""), MOVIE_LINES_FIELDS)\n    # print("">>> "", lines)\n    print(""\\nLoading conversations..."")\n    conversations = loadConversations(os.path.join(corpus, ""movie_conversations.txt""), lines, MOVIE_CONVERSATIONS_FIELDS)\n    # print("">>> "", conversations)\n\n    # Write new csv file\n    print(""\\nWriting newly formatted file..."")\n    with open(datafile, \'w\', encoding=\'utf-8\') as outputfile:\n        writer = csv.writer(outputfile, delimiter=delimiter, lineterminator=\'\\n\')\n        for pair in extractSentencePairs(conversations):\n            writer.writerow(pair)\n\n    # Print a sample of lines\n    print(""\\nSample lines from file:"")\n    printLines(datafile)\n\n\ndef indexesFromSentence(voc, sentence):\n    return [voc.word2index[word] for word in sentence.split(\' \')] + [EOS_token]\n\ndef zeroPadding(l, fillvalue=PAD_token):\n    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n\ndef binaryMatrix(l, value=PAD_token):\n    m = []\n    for i, seq in enumerate(l):\n        m.append([])\n        for token in seq:\n            if token == PAD_token:\n                m[i].append(0)\n            else:\n                m[i].append(1)\n    return m\n\n# Returns padded input sequence tensor and lengths\ndef inputVar(l, voc):\n    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    padList = zeroPadding(indexes_batch)\n    padVar = torch.LongTensor(padList)\n    return padVar, lengths\n\n# Returns padded target sequence tensor, padding mask, and max target length\ndef outputVar(l, voc):\n    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n    max_target_len = max([len(indexes) for indexes in indexes_batch])\n    padList = zeroPadding(indexes_batch)\n    mask = binaryMatrix(padList)\n    mask = torch.ByteTensor(mask)\n    padVar = torch.LongTensor(padList)\n    return padVar, mask, max_target_len\n\n\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96Voc\xe5\xaf\xb9\xe8\xb1\xa1 \xe5\x92\x8c \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96pairs\xe5\xaf\xb9\xe8\xaf\x9d\xe5\xad\x98\xe6\x94\xbe\xe5\x88\xb0list\xe4\xb8\xad\ndef readVocs(datafile, corpus_name):\n    print(""Reading lines..."")\n    # Read the file and split into lines\n    lines = open(datafile, encoding=\'utf-8\').\\\n        read().strip().split(\'\\n\')\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split(\'\\t\')] for l in lines]\n    voc = Voc(corpus_name)\n    return voc, pairs\n\n# \xe5\xa6\x82\xe6\x9e\x9c\xe5\xaf\xb9 \'p\' \xe4\xb8\xad\xe7\x9a\x84\xe4\xb8\xa4\xe4\xb8\xaa\xe5\x8f\xa5\xe5\xad\x90\xe9\x83\xbd\xe4\xbd\x8e\xe4\xba\x8e MAX_LENGTH \xe9\x98\x88\xe5\x80\xbc\xef\xbc\x8c\xe5\x88\x99\xe8\xbf\x94\xe5\x9b\x9eTrue\ndef filterPair(p):\n    # Input sequences need to preserve the last word for EOS token\n    return len(p[0].split(\' \')) < MAX_LENGTH and len(p[1].split(\' \')) < MAX_LENGTH\n\n# \xe8\xbf\x87\xe6\xbb\xa4\xe6\xbb\xa1\xe8\xb6\xb3\xe6\x9d\xa1\xe4\xbb\xb6\xe7\x9a\x84 pairs \xe5\xaf\xb9\xe8\xaf\x9d\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe4\xb8\x8a\xe9\x9d\xa2\xe5\xae\x9a\xe4\xb9\x89\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x80\xe4\xb8\xaa\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84voc\xe5\xaf\xb9\xe8\xb1\xa1\xe5\x92\x8c\xe5\xaf\xb9\xe5\x88\x97\xe8\xa1\xa8\ndef loadPrepareData(corpus, corpus_name, datafile, save_dir):\n    print(""Start preparing training data ..."")\n    voc, pairs = readVocs(datafile, corpus_name)\n    print(""Read {!s} sentence pairs"".format(len(pairs)))\n    pairs = filterPairs(pairs)\n    print(""Trimmed to {!s} sentence pairs"".format(len(pairs)))\n    print(""Counting words..."")\n    for pair in pairs:\n        voc.addSentence(pair[0])\n        voc.addSentence(pair[1])\n    print(""Counted words:"", voc.num_words)\n    return voc, pairs\n\n\n# Returns all items for a given batch of pairs\ndef batch2TrainData(voc, pair_batch):\n    pair_batch.sort(key=lambda x: len(x[0].split("" "")), reverse=True)\n    input_batch, output_batch = [], []\n    for pair in pair_batch:\n        input_batch.append(pair[0])\n        output_batch.append(pair[1])\n    inp, lengths = inputVar(input_batch, voc)\n    output, mask, max_target_len = outputVar(output_batch, voc)\n    return inp, lengths, output, mask, max_target_len\n\n\ndef trimRareWords(voc, pairs, MIN_COUNT):\n    # Trim words used under the MIN_COUNT from the voc\n    voc.trim(MIN_COUNT)\n    # Filter out pairs with trimmed words\n    keep_pairs = []\n    for pair in pairs:\n        input_sentence = pair[0]\n        output_sentence = pair[1]\n        keep_input = True\n        keep_output = True\n        # Check input sentence\n        for word in input_sentence.split(\' \'):\n            if word not in voc.word2index:\n                keep_input = False\n                break\n        # Check output sentence\n        for word in output_sentence.split(\' \'):\n            if word not in voc.word2index:\n                keep_output = False\n                break\n\n        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n        if keep_input and keep_output:\n            keep_pairs.append(pair)\n\n    print(""Trimmed from {} pairs to {}, {:.4f} of total"".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n    return keep_pairs\n\n\ndef maskNLLLoss(inp, target, mask):\n    nTotal = mask.sum()\n    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n    loss = crossEntropy.masked_select(mask).mean()\n    loss = loss.to(device)\n    return loss, nTotal.item()\n\n\ndef train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n\n    # Zero gradients\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    # Set device options\n    input_variable = input_variable.to(device)\n    lengths = lengths.to(device)\n    target_variable = target_variable.to(device)\n    mask = mask.to(device)\n\n    # Initialize variables\n    loss = 0\n    print_losses = []\n    n_totals = 0\n\n    # Forward pass through encoder\n    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n\n    # Create initial decoder input (start with SOS tokens for each sentence)\n    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n    decoder_input = decoder_input.to(device)\n\n    # Set initial decoder hidden state to the encoder\'s final hidden state\n    decoder_hidden = encoder_hidden[:decoder.n_layers]\n\n    # Determine if we are using teacher forcing this iteration\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    # Forward batch of sequences through decoder one time step at a time\n    if use_teacher_forcing:\n        for t in range(max_target_len):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            # Teacher forcing: next input is current target\n            decoder_input = target_variable[t].view(1, -1)\n            # Calculate and accumulate loss\n            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n            loss += mask_loss\n            print_losses.append(mask_loss.item() * nTotal)\n            n_totals += nTotal\n    else:\n        for t in range(max_target_len):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            # No teacher forcing: next input is decoder\'s own current output\n            _, topi = decoder_output.topk(1)\n            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n            decoder_input = decoder_input.to(device)\n            # Calculate and accumulate loss\n            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n            loss += mask_loss\n            print_losses.append(mask_loss.item() * nTotal)\n            n_totals += nTotal\n\n    # Perform backpropatation\n    loss.backward()\n\n    # Clip gradients: gradients are modified in place\n    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n\n    # Adjust model weights\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return sum(print_losses) / n_totals\n\n\ndef trainIters(model_name, cp_start_iteration, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name):\n\n    # Load batches for each iteration\n    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_iteration)]\n\n    # Initializations\n    print(\'Initializing ...\')\n    # start_iteration = 1\n    print_loss = 0\n    start_iteration = cp_start_iteration + 1\n\n    # Training loop\n    print(""Training..."")\n    for iteration in range(start_iteration, n_iteration+1):\n        training_batch = training_batches[iteration-1]\n        # Extract fields from batch\n        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n\n        # Run a training iteration with batch\n        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n        print_loss += loss\n\n        # Print progress\n        if iteration % print_every == 0:\n            print_loss_avg = print_loss / print_every\n            print(""Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}"".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n            print_loss = 0\n\n        # Save checkpoint\n        if (iteration % save_every == 0):\n            directory = os.path.join(save_dir, model_name, corpus_name, \'{}-{}_{}\'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n            if not os.path.exists(directory):\n                os.makedirs(directory)\n            torch.save({\n                \'iteration\': iteration,\n                \'state_dict_en\': encoder.state_dict(),\n                \'state_dict_de\': decoder.state_dict(),\n                \'state_dict_en_opt\': encoder_optimizer.state_dict(),\n                \'state_dict_de_opt\': decoder_optimizer.state_dict(),\n                \'loss\': loss,\n                \'voc_dict\': voc.__dict__,\n                \'embedding\': embedding.state_dict()\n            }, os.path.join(directory, \'{}_{}.tar\'.format(iteration, \'checkpoint\')))\n\n\nif __name__ == ""__main__"":\n    global device, corpus_name\n    USE_CUDA = torch.cuda.is_available()\n    device = torch.device(""cuda"" if USE_CUDA else ""cpu"")\n\n    corpus_name = ""cornell_movie-dialogs_corpus""\n    corpus = os.path.join(""data"", corpus_name)\n    # printLines(os.path.join(corpus, ""movie_lines.txt""))\n\n    datafile = os.path.join(corpus, ""formatted_movie_lines.txt"")\n    get_datafile(datafile)\n\n    # Load/Assemble voc and pairs\n    save_dir = os.path.join(""data"", ""save"")\n    voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n    # Print some pairs to validate\n    print(""\\npairs:"")\n    for pair in pairs[:10]:\n        print(pair)\n\n    # Trim voc and pairs\n    pairs = trimRareWords(voc, pairs, MIN_COUNT)\n\n    # # Example for validation\n    # small_batch_size = 5\n    # batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n    # input_variable, lengths, target_variable, mask, max_target_len = batches\n    # print(""input_variable:"", input_variable)\n    # print(""lengths:"", lengths)\n    # print(""target_variable:"", target_variable)\n    # print(""mask:"", mask)\n    # print(""max_target_len:"", max_target_len)\n\n    global teacher_forcing_ratio, hidden_size\n    # Configure models\n    model_name = \'cb_model\'\n    attn_model = \'dot\'\n    #attn_model = \'general\'\n    #attn_model = \'concat\'\n    hidden_size = 500\n    encoder_n_layers = 2\n    decoder_n_layers = 2\n    dropout = 0.1\n    cp_start_iteration = 0\n    learning_rate = 0.0001\n    decoder_learning_ratio = 5.0\n    teacher_forcing_ratio = 1.0\n    clip = 50.0\n    print_every = 1\n    batch_size = 64\n    save_every = 1000\n    n_iteration = 7000\n\n    loadFilename = ""data/save/cb_model/%s/2-2_500/6000_checkpoint.tar"" % corpus_name\n    if os.path.exists(loadFilename):\n        voc = Voc(corpus_name)\n    cp_start_iteration, voc, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding = load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, dropout, learning_rate, decoder_learning_ratio)\n    \n    # Use appropriate device\n    encoder = encoder.to(device)\n    decoder = decoder.to(device)\n    for state in encoder_optimizer.state.values():\n        for k, v in state.items():\n            if isinstance(v, torch.Tensor):\n                state[k] = v.cuda()\n\n    for state in decoder_optimizer.state.values():\n        for k, v in state.items():\n            if isinstance(v, torch.Tensor):\n                state[k] = v.cuda()\n\n    # Ensure dropout layers are in train mode\n    encoder.train()\n    decoder.train()\n\n    print(""Starting Training!"")\n    trainIters(model_name, cp_start_iteration, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name)\n'"
docs/src/chatbot/u_class.py,20,"b'#!/usr/bin/python\n# coding: utf-8\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\n\n\nclass Voc:\n    def __init__(self, name):\n        self.name = name\n        self.trimmed = False\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: ""PAD"", SOS_token: ""SOS"", EOS_token: ""EOS""}\n        self.num_words = 3  # Count SOS, EOS, PAD\n\n    def addSentence(self, sentence):\n        for word in sentence.split(\' \'):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.num_words\n            self.word2count[word] = 1\n            self.index2word[self.num_words] = word\n            self.num_words += 1\n        else:\n            self.word2count[word] += 1\n\n    # Remove words below a certain count threshold\n    def trim(self, min_count):\n        if self.trimmed:\n            return\n        self.trimmed = True\n\n        keep_words = []\n\n        for k, v in self.word2count.items():\n            if v >= min_count:\n                keep_words.append(k)\n\n        print(\'keep_words {} / {} = {:.4f}\'.format(\n            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n        ))\n\n        # Reinitialize dictionaries\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: ""PAD"", SOS_token: ""SOS"", EOS_token: ""EOS""}\n        self.num_words = 3 # Count default tokens\n\n        for word in keep_words:\n            self.addWord(word)\n\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n        super(EncoderRNN, self).__init__()\n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        self.embedding = embedding\n\n        # Initialize GRU; the input_size and hidden_size params are both set to \'hidden_size\'\n        #   because our input size is a word embedding with number of features == hidden_size\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n\n    def forward(self, input_seq, input_lengths, hidden=None):\n        # Convert word indexes to embeddings\n        embedded = self.embedding(input_seq)\n        # Pack padded batch of sequences for RNN module\n        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n        # Forward pass through GRU\n        outputs, hidden = self.gru(packed, hidden)\n        # Unpack padding\n        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n        # Sum bidirectional GRU outputs\n        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n        # Return output and final hidden state\n        return outputs, hidden\n\n\n# Luong attention layer\nclass Attn(nn.Module):\n    def __init__(self, method, hidden_size):\n        super(Attn, self).__init__()\n        self.method = method\n        if self.method not in [\'dot\', \'general\', \'concat\']:\n            raise ValueError(self.method, ""is not an appropriate attention method."")\n        self.hidden_size = hidden_size\n        if self.method == \'general\':\n            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n        elif self.method == \'concat\':\n            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n\n    def dot_score(self, hidden, encoder_output):\n        return torch.sum(hidden * encoder_output, dim=2)\n\n    def general_score(self, hidden, encoder_output):\n        energy = self.attn(encoder_output)\n        return torch.sum(hidden * energy, dim=2)\n\n    def concat_score(self, hidden, encoder_output):\n        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n        return torch.sum(self.v * energy, dim=2)\n\n    def forward(self, hidden, encoder_outputs):\n        # Calculate the attention weights (energies) based on the given method\n        if self.method == \'general\':\n            attn_energies = self.general_score(hidden, encoder_outputs)\n        elif self.method == \'concat\':\n            attn_energies = self.concat_score(hidden, encoder_outputs)\n        elif self.method == \'dot\':\n            attn_energies = self.dot_score(hidden, encoder_outputs)\n\n        # Transpose max_length and batch_size dimensions\n        attn_energies = attn_energies.t()\n\n        # Return the softmax normalized probability scores (with added dimension)\n        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n\n\nclass LuongAttnDecoderRNN(nn.Module):\n    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n        super(LuongAttnDecoderRNN, self).__init__()\n\n        # Keep for reference\n        self.attn_model = attn_model\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.dropout = dropout\n\n        # Define layers\n        self.embedding = embedding\n        self.embedding_dropout = nn.Dropout(dropout)\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n\n        self.attn = Attn(attn_model, hidden_size)\n\n    def forward(self, input_step, last_hidden, encoder_outputs):\n        # Note: we run this one step (word) at a time\n        # Get embedding of current input word\n        embedded = self.embedding(input_step)\n        embedded = self.embedding_dropout(embedded)\n        # Forward through unidirectional GRU\n        rnn_output, hidden = self.gru(embedded, last_hidden)\n        # Calculate attention weights from the current GRU output\n        attn_weights = self.attn(rnn_output, encoder_outputs)\n        # Multiply attention weights to encoder outputs to get new ""weighted sum"" context vector\n        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n        # Concatenate weighted context vector and GRU output using Luong eq. 5\n        rnn_output = rnn_output.squeeze(0)\n        context = context.squeeze(1)\n        concat_input = torch.cat((rnn_output, context), 1)\n        concat_output = torch.tanh(self.concat(concat_input))\n        # Predict next word using Luong eq. 6\n        output = self.out(concat_output)\n        output = F.softmax(output, dim=1)\n        # Return output and final hidden state\n        return output, hidden\n\n\nclass GreedySearchDecoder(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super(GreedySearchDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, input_seq, input_length, max_length):\n        # Forward input through encoder model\n        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n        # Prepare encoder\'s final hidden layer to be first hidden input to the decoder\n        decoder_hidden = encoder_hidden[:self.decoder.n_layers]\n        # Initialize decoder input with SOS_token\n        decoder_input = torch.ones(1, 1, device=self.device, dtype=torch.long) * SOS_token\n        # Initialize tensors to append decoded words to\n        all_tokens = torch.zeros([0], device=self.device, dtype=torch.long)\n        all_scores = torch.zeros([0], device=self.device)\n        # Iteratively decode one word token at a time\n        for _ in range(max_length):\n            # Forward pass through decoder\n            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n            # Obtain most likely word token and its softmax score\n            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n            # Record token and score\n            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n            # Prepare current token to be next decoder input (add a dimension)\n            decoder_input = torch.unsqueeze(decoder_input, 0)\n        # Return collections of word tokens and scores\n        return all_tokens, all_scores\n'"
docs/src/chatbot/u_tools.py,2,"b'#!/usr/bin/python\n# coding: utf-8\nimport os\nimport re\nimport unicodedata\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom u_class import Voc, EncoderRNN, LuongAttnDecoderRNN\n\n\n# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return \'\'.join(\n        c for c in unicodedata.normalize(\'NFD\', s)\n        if unicodedata.category(c) != \'Mn\'\n    )\n\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    s = re.sub(r""\\s+"", r"" "", s).strip()\n    return s\n\n\ndef load_model(loadFilename, voc, cp_start_iteration, attn_model, hidden_size, encoder_n_layers, decoder_n_layers, \n        dropout, learning_rate, decoder_learning_ratio):\n\n    # Load model if a loadFilename is provided\n    if os.path.exists(loadFilename):\n        # If loading on same machine the model was trained on\n        checkpoint = torch.load(loadFilename)\n        cp_start_iteration = checkpoint[\'iteration\']\n        encoder_sd = checkpoint[\'state_dict_en\']\n        decoder_sd = checkpoint[\'state_dict_de\']\n        encoder_optimizer_sd = checkpoint[\'state_dict_en_opt\']\n        decoder_optimizer_sd = checkpoint[\'state_dict_de_opt\']\n        # loss = checkpoint[\'loss\']\n        voc.__dict__ = checkpoint[\'voc_dict\']\n        embedding_sd = checkpoint[\'embedding\']\n\n    print(\'Building encoder and decoder ...\')\n    # Initialize word embeddings\n    embedding = nn.Embedding(voc.num_words, hidden_size)\n    if os.path.exists(loadFilename):\n        embedding.load_state_dict(embedding_sd)\n\n    print(\'Initialize encoder & decoder models\')\n    encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n    decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n    print(\'Building optimizers ...\')\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n    if os.path.exists(loadFilename):\n        encoder.load_state_dict(encoder_sd)\n        decoder.load_state_dict(decoder_sd)\n        encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n        decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n\n    print(\'Models built and ready to go!\')\n    return cp_start_iteration, voc, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding\n'"
