file_path,api_count,code
cifar.py,13,"b'\'\'\'\nTraining script for CIFAR-10/100\nCopyright (c) Wei YANG, 2017\n\'\'\'\nfrom __future__ import print_function\n\nimport argparse\nimport os\nimport shutil\nimport time\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport models.cifar as models\n\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10/100 Training\')\n# Datasets\nparser.add_argument(\'-d\', \'--dataset\', default=\'cifar10\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=300, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=128, type=int, metavar=\'N\',\n                    help=\'train batchsize\')\nparser.add_argument(\'--test-batch\', default=100, type=int, metavar=\'N\',\n                    help=\'test batchsize\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=5e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\n# Checkpoints\nparser.add_argument(\'-c\', \'--checkpoint\', default=\'checkpoint\', type=str, metavar=\'PATH\',\n                    help=\'path to save checkpoint (default: checkpoint)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet20\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--block-name\', type=str, default=\'BasicBlock\',\n                    help=\'the building block for Resnet and Preresnet: BasicBlock, Bottleneck (default: Basicblock for cifar10/cifar100)\')\nparser.add_argument(\'--cardinality\', type=int, default=8, help=\'Model cardinality (group).\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\nparser.add_argument(\'--growthRate\', type=int, default=12, help=\'Growth rate for DenseNet.\')\nparser.add_argument(\'--compressionRate\', type=int, default=2, help=\'Compression Rate (theta) for DenseNet.\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\n#Device options\nparser.add_argument(\'--gpu-id\', default=\'0\', type=str,\n                    help=\'id(s) for CUDA_VISIBLE_DEVICES\')\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Validate dataset\nassert args.dataset == \'cifar10\' or args.dataset == \'cifar100\', \'Dataset can only be cifar10 or cifar100.\'\n\n# Use CUDA\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = args.gpu_id\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n\n    if not os.path.isdir(args.checkpoint):\n        mkdir_p(args.checkpoint)\n\n\n\n    # Data\n    print(\'==> Preparing dataset %s\' % args.dataset)\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    if args.dataset == \'cifar10\':\n        dataloader = datasets.CIFAR10\n        num_classes = 10\n    else:\n        dataloader = datasets.CIFAR100\n        num_classes = 100\n\n\n    trainset = dataloader(root=\'./data\', train=True, download=True, transform=transform_train)\n    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n\n    testset = dataloader(root=\'./data\', train=False, download=False, transform=transform_test)\n    testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n\n    # Model\n    print(""==> creating model \'{}\'"".format(args.arch))\n    if args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    cardinality=args.cardinality,\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'densenet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    growthRate=args.growthRate,\n                    compressionRate=args.compressionRate,\n                    dropRate=args.drop,\n                )\n    elif args.arch.startswith(\'wrn\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    widen_factor=args.widen_factor,\n                    dropRate=args.drop,\n                )\n    elif args.arch.endswith(\'resnet\'):\n        model = models.__dict__[args.arch](\n                    num_classes=num_classes,\n                    depth=args.depth,\n                    block_name=args.block_name,\n                )\n    else:\n        model = models.__dict__[args.arch](num_classes=num_classes)\n\n    model = torch.nn.DataParallel(model).cuda()\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n    # Resume\n    title = \'cifar-10-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Resuming from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        args.checkpoint = os.path.dirname(args.resume)\n        checkpoint = torch.load(args.resume)\n        best_acc = checkpoint[\'best_acc\']\n        start_epoch = checkpoint[\'epoch\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        logger = Logger(os.path.join(args.checkpoint, \'log.txt\'), title=title, resume=True)\n    else:\n        logger = Logger(os.path.join(args.checkpoint, \'log.txt\'), title=title)\n        logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n\n    if args.evaluate:\n        print(\'\\nEvaluation only\')\n        test_loss, test_acc = test(testloader, model, criterion, start_epoch, use_cuda)\n        print(\' Test Loss:  %.8f, Test Acc:  %.2f\' % (test_loss, test_acc))\n        return\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n\n        train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.checkpoint)\n\n    logger.close()\n    logger.plot()\n    savefig(os.path.join(args.checkpoint, \'log.eps\'))\n\n    print(\'Best acc:\')\n    print(best_acc)\n\ndef train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(trainloader))\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(testloader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(testloader))\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(testloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint=\'checkpoint\', filename=\'checkpoint.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n    if is_best:\n        shutil.copyfile(filepath, os.path.join(checkpoint, \'model_best.pth.tar\'))\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
imagenet.py,16,"b'\'\'\'\nTraining script for ImageNet\nCopyright (c) Wei YANG, 2017\n\'\'\'\nfrom __future__ import print_function\n\nimport argparse\nimport os\nimport shutil\nimport time\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nimport models.imagenet as customized_models\n\nfrom utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n\n# Models\ndefault_model_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\ncustomized_models_names = sorted(name for name in customized_models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(customized_models.__dict__[name]))\n\nfor name in customized_models.__dict__:\n    if name.islower() and not name.startswith(""__"") and callable(customized_models.__dict__[name]):\n        models.__dict__[name] = customized_models.__dict__[name]\n\nmodel_names = default_model_names + customized_models_names\n\n# Parse arguments\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\n\n# Datasets\nparser.add_argument(\'-d\', \'--data\', default=\'path to dataset\', type=str)\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\n# Optimization options\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--train-batch\', default=256, type=int, metavar=\'N\',\n                    help=\'train batchsize (default: 256)\')\nparser.add_argument(\'--test-batch\', default=200, type=int, metavar=\'N\',\n                    help=\'test batchsize (default: 200)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--drop\', \'--dropout\', default=0, type=float,\n                    metavar=\'Dropout\', help=\'Dropout ratio\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225],\n                        help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma on schedule.\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\n# Checkpoints\nparser.add_argument(\'-c\', \'--checkpoint\', default=\'checkpoint\', type=str, metavar=\'PATH\',\n                    help=\'path to save checkpoint (default: checkpoint)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\n# Architecture\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'--depth\', type=int, default=29, help=\'Model depth.\')\nparser.add_argument(\'--cardinality\', type=int, default=32, help=\'ResNet cardinality (group).\')\nparser.add_argument(\'--base-width\', type=int, default=4, help=\'ResNet base width.\')\nparser.add_argument(\'--widen-factor\', type=int, default=4, help=\'Widen factor. 4 -> 64, 8 -> 128, ...\')\n# Miscs\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\n#Device options\nparser.add_argument(\'--gpu-id\', default=\'0\', type=str,\n                    help=\'id(s) for CUDA_VISIBLE_DEVICES\')\n\nargs = parser.parse_args()\nstate = {k: v for k, v in args._get_kwargs()}\n\n# Use CUDA\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = args.gpu_id\nuse_cuda = torch.cuda.is_available()\n\n# Random seed\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\n\nbest_acc = 0  # best test accuracy\n\ndef main():\n    global best_acc\n    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n\n    if not os.path.isdir(args.checkpoint):\n        mkdir_p(args.checkpoint)\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(traindir, transforms.Compose([\n            transforms.RandomSizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.train_batch, shuffle=True,\n        num_workers=args.workers, pin_memory=True)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Scale(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.test_batch, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    # create model\n    if args.pretrained:\n        print(""=> using pre-trained model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch](pretrained=True)\n    elif args.arch.startswith(\'resnext\'):\n        model = models.__dict__[args.arch](\n                    baseWidth=args.base_width,\n                    cardinality=args.cardinality,\n                )\n    else:\n        print(""=> creating model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch]()\n\n    if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n        model.features = torch.nn.DataParallel(model.features)\n        model.cuda()\n    else:\n        model = torch.nn.DataParallel(model).cuda()\n\n    cudnn.benchmark = True\n    print(\'    Total params: %.2fM\' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n    # Resume\n    title = \'ImageNet-\' + args.arch\n    if args.resume:\n        # Load checkpoint.\n        print(\'==> Resuming from checkpoint..\')\n        assert os.path.isfile(args.resume), \'Error: no checkpoint directory found!\'\n        args.checkpoint = os.path.dirname(args.resume)\n        checkpoint = torch.load(args.resume)\n        best_acc = checkpoint[\'best_acc\']\n        start_epoch = checkpoint[\'epoch\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        logger = Logger(os.path.join(args.checkpoint, \'log.txt\'), title=title, resume=True)\n    else:\n        logger = Logger(os.path.join(args.checkpoint, \'log.txt\'), title=title)\n        logger.set_names([\'Learning Rate\', \'Train Loss\', \'Valid Loss\', \'Train Acc.\', \'Valid Acc.\'])\n\n\n    if args.evaluate:\n        print(\'\\nEvaluation only\')\n        test_loss, test_acc = test(val_loader, model, criterion, start_epoch, use_cuda)\n        print(\' Test Loss:  %.8f, Test Acc:  %.2f\' % (test_loss, test_acc))\n        return\n\n    # Train and val\n    for epoch in range(start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        print(\'\\nEpoch: [%d | %d] LR: %f\' % (epoch + 1, args.epochs, state[\'lr\']))\n\n        train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n        test_loss, test_acc = test(val_loader, model, criterion, epoch, use_cuda)\n\n        # append logger file\n        logger.append([state[\'lr\'], train_loss, test_loss, train_acc, test_acc])\n\n        # save model\n        is_best = test_acc > best_acc\n        best_acc = max(test_acc, best_acc)\n        save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'state_dict\': model.state_dict(),\n                \'acc\': test_acc,\n                \'best_acc\': best_acc,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best, checkpoint=args.checkpoint)\n\n    logger.close()\n    logger.plot()\n    savefig(os.path.join(args.checkpoint, \'log.eps\'))\n\n    print(\'Best acc:\')\n    print(best_acc)\n\ndef train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n    # switch to train mode\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    end = time.time()\n\n    bar = Bar(\'Processing\', max=len(train_loader))\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(train_loader),\n                    data=data_time.val,\n                    bt=batch_time.val,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef test(val_loader, model, criterion, epoch, use_cuda):\n    global best_acc\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(\'Processing\', max=len(val_loader))\n    for batch_idx, (inputs, targets) in enumerate(val_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n\n        # compute output\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n        losses.update(loss.data[0], inputs.size(0))\n        top1.update(prec1[0], inputs.size(0))\n        top5.update(prec5[0], inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # plot progress\n        bar.suffix  = \'({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}\'.format(\n                    batch=batch_idx + 1,\n                    size=len(val_loader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    top1=top1.avg,\n                    top5=top5.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return (losses.avg, top1.avg)\n\ndef save_checkpoint(state, is_best, checkpoint=\'checkpoint\', filename=\'checkpoint.pth.tar\'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n    if is_best:\n        shutil.copyfile(filepath, os.path.join(checkpoint, \'model_best.pth.tar\'))\n\ndef adjust_learning_rate(optimizer, epoch):\n    global state\n    if epoch in args.schedule:\n        state[\'lr\'] *= args.gamma\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] = state[\'lr\']\n\nif __name__ == \'__main__\':\n    main()\n'"
models/__init__.py,0,b''
utils/__init__.py,0,"b'""""""Useful utils\n""""""\nfrom .misc import *\nfrom .logger import *\nfrom .visualize import *\nfrom .eval import *\n\n# progress bar\nimport os, sys\nsys.path.append(os.path.join(os.path.dirname(__file__), ""progress""))\nfrom progress.bar import Bar as Bar'"
utils/eval.py,0,"b'from __future__ import print_function, absolute_import\n\n__all__ = [\'accuracy\']\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res'"
utils/logger.py,0,"b'# A simple torch style logger\n# (C) Wei YANG 2017\nfrom __future__ import absolute_import\nimport matplotlib.pyplot as plt\nimport os\nimport sys\nimport numpy as np\n\n__all__ = [\'Logger\', \'LoggerMonitor\', \'savefig\']\n\ndef savefig(fname, dpi=None):\n    dpi = 150 if dpi == None else dpi\n    plt.savefig(fname, dpi=dpi)\n    \ndef plot_overlap(logger, names=None):\n    names = logger.names if names == None else names\n    numbers = logger.numbers\n    for _, name in enumerate(names):\n        x = np.arange(len(numbers[name]))\n        plt.plot(x, np.asarray(numbers[name]))\n    return [logger.title + \'(\' + name + \')\' for name in names]\n\nclass Logger(object):\n    \'\'\'Save training process to log file with simple plot function.\'\'\'\n    def __init__(self, fpath, title=None, resume=False): \n        self.file = None\n        self.resume = resume\n        self.title = \'\' if title == None else title\n        if fpath is not None:\n            if resume: \n                self.file = open(fpath, \'r\') \n                name = self.file.readline()\n                self.names = name.rstrip().split(\'\\t\')\n                self.numbers = {}\n                for _, name in enumerate(self.names):\n                    self.numbers[name] = []\n\n                for numbers in self.file:\n                    numbers = numbers.rstrip().split(\'\\t\')\n                    for i in range(0, len(numbers)):\n                        self.numbers[self.names[i]].append(numbers[i])\n                self.file.close()\n                self.file = open(fpath, \'a\')  \n            else:\n                self.file = open(fpath, \'w\')\n\n    def set_names(self, names):\n        if self.resume: \n            pass\n        # initialize numbers as empty list\n        self.numbers = {}\n        self.names = names\n        for _, name in enumerate(self.names):\n            self.file.write(name)\n            self.file.write(\'\\t\')\n            self.numbers[name] = []\n        self.file.write(\'\\n\')\n        self.file.flush()\n\n\n    def append(self, numbers):\n        assert len(self.names) == len(numbers), \'Numbers do not match names\'\n        for index, num in enumerate(numbers):\n            self.file.write(""{0:.6f}"".format(num))\n            self.file.write(\'\\t\')\n            self.numbers[self.names[index]].append(num)\n        self.file.write(\'\\n\')\n        self.file.flush()\n\n    def plot(self, names=None):   \n        names = self.names if names == None else names\n        numbers = self.numbers\n        for _, name in enumerate(names):\n            x = np.arange(len(numbers[name]))\n            plt.plot(x, np.asarray(numbers[name]))\n        plt.legend([self.title + \'(\' + name + \')\' for name in names])\n        plt.grid(True)\n\n    def close(self):\n        if self.file is not None:\n            self.file.close()\n\nclass LoggerMonitor(object):\n    \'\'\'Load and visualize multiple logs.\'\'\'\n    def __init__ (self, paths):\n        \'\'\'paths is a distionary with {name:filepath} pair\'\'\'\n        self.loggers = []\n        for title, path in paths.items():\n            logger = Logger(path, title=title, resume=True)\n            self.loggers.append(logger)\n\n    def plot(self, names=None):\n        plt.figure()\n        plt.subplot(121)\n        legend_text = []\n        for logger in self.loggers:\n            legend_text += plot_overlap(logger, names)\n        plt.legend(legend_text, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n        plt.grid(True)\n                    \nif __name__ == \'__main__\':\n    # # Example\n    # logger = Logger(\'test.txt\')\n    # logger.set_names([\'Train loss\', \'Valid loss\',\'Test loss\'])\n\n    # length = 100\n    # t = np.arange(length)\n    # train_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n    # valid_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n    # test_loss = np.exp(-t / 10.0) + np.random.rand(length) * 0.1\n\n    # for i in range(0, length):\n    #     logger.append([train_loss[i], valid_loss[i], test_loss[i]])\n    # logger.plot()\n\n    # Example: logger monitor\n    paths = {\n    \'resadvnet20\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet20/log.txt\', \n    \'resadvnet32\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet32/log.txt\',\n    \'resadvnet44\':\'/home/wyang/code/pytorch-classification/checkpoint/cifar10/resadvnet44/log.txt\',\n    }\n\n    field = [\'Valid Acc.\']\n\n    monitor = LoggerMonitor(paths)\n    monitor.plot(names=field)\n    savefig(\'test.eps\')'"
utils/misc.py,6,"b'\'\'\'Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n\'\'\'\nimport errno\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\nfrom torch.autograd import Variable\n\n__all__ = [\'get_mean_and_std\', \'init_params\', \'mkdir_p\', \'AverageMeter\']\n\n\ndef get_mean_and_std(dataset):\n    \'\'\'Compute the mean and std value of dataset.\'\'\'\n    dataloader = trainloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print(\'==> Computing mean and std..\')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    \'\'\'Init layer parameters.\'\'\'\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode=\'fan_out\')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\ndef mkdir_p(path):\n    \'\'\'make dir if not exist\'\'\'\n    try:\n        os.makedirs(path)\n    except OSError as exc:  # Python >2.5\n        if exc.errno == errno.EEXIST and os.path.isdir(path):\n            pass\n        else:\n            raise\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value\n       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n    """"""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count'"
utils/visualize.py,6,"b""import matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nfrom .misc import *   \n\n__all__ = ['make_image', 'show_batch', 'show_mask', 'show_mask_single']\n\n# functions to show an image\ndef make_image(img, mean=(0,0,0), std=(1,1,1)):\n    for i in range(0, 3):\n        img[i] = img[i] * std[i] + mean[i]    # unnormalize\n    npimg = img.numpy()\n    return np.transpose(npimg, (1, 2, 0))\n\ndef gauss(x,a,b,c):\n    return torch.exp(-torch.pow(torch.add(x,-b),2).div(2*c*c)).mul(a)\n\ndef colorize(x):\n    ''' Converts a one-channel grayscale image to a color heatmap image '''\n    if x.dim() == 2:\n        torch.unsqueeze(x, 0, out=x)\n    if x.dim() == 3:\n        cl = torch.zeros([3, x.size(1), x.size(2)])\n        cl[0] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n        cl[1] = gauss(x,1,.5,.3)\n        cl[2] = gauss(x,1,.2,.3)\n        cl[cl.gt(1)] = 1\n    elif x.dim() == 4:\n        cl = torch.zeros([x.size(0), 3, x.size(2), x.size(3)])\n        cl[:,0,:,:] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n        cl[:,1,:,:] = gauss(x,1,.5,.3)\n        cl[:,2,:,:] = gauss(x,1,.2,.3)\n    return cl\n\ndef show_batch(images, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.imshow(images)\n    plt.show()\n\n\ndef show_mask_single(images, mask, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    im_size = images.size(2)\n\n    # save for adding mask\n    im_data = images.clone()\n    for i in range(0, 3):\n        im_data[:,i,:,:] = im_data[:,i,:,:] * Std[i] + Mean[i]    # unnormalize\n\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.subplot(2, 1, 1)\n    plt.imshow(images)\n    plt.axis('off')\n\n    # for b in range(mask.size(0)):\n    #     mask[b] = (mask[b] - mask[b].min())/(mask[b].max() - mask[b].min())\n    mask_size = mask.size(2)\n    # print('Max %f Min %f' % (mask.max(), mask.min()))\n    mask = (upsampling(mask, scale_factor=im_size/mask_size))\n    # mask = colorize(upsampling(mask, scale_factor=im_size/mask_size))\n    # for c in range(3):\n    #     mask[:,c,:,:] = (mask[:,c,:,:] - Mean[c])/Std[c]\n\n    # print(mask.size())\n    mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask.expand_as(im_data)))\n    # mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask), Mean, Std)\n    plt.subplot(2, 1, 2)\n    plt.imshow(mask)\n    plt.axis('off')\n\ndef show_mask(images, masklist, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n    im_size = images.size(2)\n\n    # save for adding mask\n    im_data = images.clone()\n    for i in range(0, 3):\n        im_data[:,i,:,:] = im_data[:,i,:,:] * Std[i] + Mean[i]    # unnormalize\n\n    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n    plt.subplot(1+len(masklist), 1, 1)\n    plt.imshow(images)\n    plt.axis('off')\n\n    for i in range(len(masklist)):\n        mask = masklist[i].data.cpu()\n        # for b in range(mask.size(0)):\n        #     mask[b] = (mask[b] - mask[b].min())/(mask[b].max() - mask[b].min())\n        mask_size = mask.size(2)\n        # print('Max %f Min %f' % (mask.max(), mask.min()))\n        mask = (upsampling(mask, scale_factor=im_size/mask_size))\n        # mask = colorize(upsampling(mask, scale_factor=im_size/mask_size))\n        # for c in range(3):\n        #     mask[:,c,:,:] = (mask[:,c,:,:] - Mean[c])/Std[c]\n\n        # print(mask.size())\n        mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask.expand_as(im_data)))\n        # mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask), Mean, Std)\n        plt.subplot(1+len(masklist), 1, i+2)\n        plt.imshow(mask)\n        plt.axis('off')\n\n\n\n# x = torch.zeros(1, 3, 3)\n# out = colorize(x)\n# out_im = make_image(out)\n# plt.imshow(out_im)\n# plt.show()"""
models/cifar/__init__.py,1,"b'from __future__ import absolute_import\n\n""""""The models subpackage contains definitions for the following model for CIFAR10/CIFAR100\narchitectures:\n\n-  `AlexNet`_\n-  `VGG`_\n-  `ResNet`_\n-  `SqueezeNet`_\n-  `DenseNet`_\n\nYou can construct a model with random weights by calling its constructor:\n\n.. code:: python\n\n    import torchvision.models as models\n    resnet18 = models.resnet18()\n    alexnet = models.alexnet()\n    squeezenet = models.squeezenet1_0()\n    densenet = models.densenet_161()\n\nWe provide pre-trained models for the ResNet variants and AlexNet, using the\nPyTorch :mod:`torch.utils.model_zoo`. These can  constructed by passing\n``pretrained=True``:\n\n.. code:: python\n\n    import torchvision.models as models\n    resnet18 = models.resnet18(pretrained=True)\n    alexnet = models.alexnet(pretrained=True)\n\nImageNet 1-crop error rates (224x224)\n\n======================== =============   =============\nNetwork                  Top-1 error     Top-5 error\n======================== =============   =============\nResNet-18                30.24           10.92\nResNet-34                26.70           8.58\nResNet-50                23.85           7.13\nResNet-101               22.63           6.44\nResNet-152               21.69           5.94\nInception v3             22.55           6.44\nAlexNet                  43.45           20.91\nVGG-11                   30.98           11.37\nVGG-13                   30.07           10.75\nVGG-16                   28.41           9.62\nVGG-19                   27.62           9.12\nSqueezeNet 1.0           41.90           19.58\nSqueezeNet 1.1           41.81           19.38\nDensenet-121             25.35           7.83\nDensenet-169             24.00           7.00\nDensenet-201             22.80           6.43\nDensenet-161             22.35           6.20\n======================== =============   =============\n\n\n.. _AlexNet: https://arxiv.org/abs/1404.5997\n.. _VGG: https://arxiv.org/abs/1409.1556\n.. _ResNet: https://arxiv.org/abs/1512.03385\n.. _SqueezeNet: https://arxiv.org/abs/1602.07360\n.. _DenseNet: https://arxiv.org/abs/1608.06993\n""""""\n\nfrom .alexnet import *\nfrom .vgg import *\nfrom .resnet import *\nfrom .resnext import *\nfrom .wrn import *\nfrom .preresnet import *\nfrom .densenet import *\n'"
models/cifar/alexnet.py,1,"b'\'\'\'AlexNet for CIFAR10. FC layers are removed. Paddings are adjusted.\nWithout BN, the start learning rate should be 0.01\n(c) YANG, Wei \n\'\'\'\nimport torch.nn as nn\n\n\n__all__ = [\'alexnet\']\n\n\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=10):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.classifier = nn.Linear(256, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\ndef alexnet(**kwargs):\n    r""""""AlexNet model architecture from the\n    `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.\n    """"""\n    model = AlexNet(**kwargs)\n    return model\n'"
models/cifar/densenet.py,5,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n\n__all__ = [\'densenet\']\n\n\nfrom torch.autograd import Variable\n\nclass Bottleneck(nn.Module):\n    def __init__(self, inplanes, expansion=4, growthRate=12, dropRate=0):\n        super(Bottleneck, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, inplanes, expansion=1, growthRate=12, dropRate=0):\n        super(BasicBlock, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\n\nclass Transition(nn.Module):\n    def __init__(self, inplanes, outplanes):\n        super(Transition, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1,\n                               bias=False)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = F.avg_pool2d(out, 2)\n        return out\n\n\nclass DenseNet(nn.Module):\n\n    def __init__(self, depth=22, block=Bottleneck, \n        dropRate=0, num_classes=10, growthRate=12, compressionRate=2):\n        super(DenseNet, self).__init__()\n\n        assert (depth - 4) % 3 == 0, \'depth should be 3n+4\'\n        n = (depth - 4) / 3 if block == BasicBlock else (depth - 4) // 6\n\n        self.growthRate = growthRate\n        self.dropRate = dropRate\n\n        # self.inplanes is a global variable used across multiple\n        # helper functions\n        self.inplanes = growthRate * 2 \n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n                               bias=False)\n        self.dense1 = self._make_denseblock(block, n)\n        self.trans1 = self._make_transition(compressionRate)\n        self.dense2 = self._make_denseblock(block, n)\n        self.trans2 = self._make_transition(compressionRate)\n        self.dense3 = self._make_denseblock(block, n)\n        self.bn = nn.BatchNorm2d(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(self.inplanes, num_classes)\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_denseblock(self, block, blocks):\n        layers = []\n        for i in range(blocks):\n            # Currently we fix the expansion ratio as the default value\n            layers.append(block(self.inplanes, growthRate=self.growthRate, dropRate=self.dropRate))\n            self.inplanes += self.growthRate\n\n        return nn.Sequential(*layers)\n\n    def _make_transition(self, compressionRate):\n        inplanes = self.inplanes\n        outplanes = int(math.floor(self.inplanes // compressionRate))\n        self.inplanes = outplanes\n        return Transition(inplanes, outplanes)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.trans1(self.dense1(x)) \n        x = self.trans2(self.dense2(x)) \n        x = self.dense3(x)\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef densenet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return DenseNet(**kwargs)'"
models/cifar/preresnet.py,1,"b'from __future__ import absolute_import\n\n\'\'\'Resnet for cifar dataset.\nPorted form\nhttps://github.com/facebook/fb.resnet.torch\nand\nhttps://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n(c) YANG, Wei\n\'\'\'\nimport torch.nn as nn\nimport math\n\n\n__all__ = [\'preresnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass PreResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=1000, block_name=\'BasicBlock\'):\n        super(PreResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        if block_name.lower() == \'basicblock\':\n            assert (depth - 2) % 6 == 0, \'When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\'\n            n = (depth - 2) // 6\n            block = BasicBlock\n        elif block_name.lower() == \'bottleneck\':\n            assert (depth - 2) % 9 == 0, \'When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\'\n            n = (depth - 2) // 9\n            block = Bottleneck\n        else:\n            raise ValueError(\'block_name shoule be Basicblock or Bottleneck\')\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.bn = nn.BatchNorm2d(64 * block.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef preresnet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return PreResNet(**kwargs)\n'"
models/cifar/resnet.py,1,"b'from __future__ import absolute_import\n\n\'\'\'Resnet for cifar dataset.\nPorted form\nhttps://github.com/facebook/fb.resnet.torch\nand\nhttps://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n(c) YANG, Wei\n\'\'\'\nimport torch.nn as nn\nimport math\n\n\n__all__ = [\'resnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=1000, block_name=\'BasicBlock\'):\n        super(ResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        if block_name.lower() == \'basicblock\':\n            assert (depth - 2) % 6 == 0, \'When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\'\n            n = (depth - 2) // 6\n            block = BasicBlock\n        elif block_name.lower() == \'bottleneck\':\n            assert (depth - 2) % 9 == 0, \'When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\'\n            n = (depth - 2) // 9\n            block = Bottleneck\n        else:\n            raise ValueError(\'block_name shoule be Basicblock or Bottleneck\')\n\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)    # 32x32\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet(**kwargs):\n    """"""\n    Constructs a ResNet model.\n    """"""\n    return ResNet(**kwargs)\n'"
models/cifar/resnext.py,3,"b'from __future__ import division\n"""""" \nCreates a ResNeXt Model as defined in:\nXie, S., Girshick, R., Dollar, P., Tu, Z., & He, K. (2016). \nAggregated residual transformations for deep neural networks. \narXiv preprint arXiv:1611.05431.\nimport from https://github.com/prlz77/ResNeXt.pytorch/blob/master/models/model.py\n""""""\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\n\n__all__ = [\'resnext\']\n\nclass ResNeXtBottleneck(nn.Module):\n    """"""\n    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n    """"""\n    def __init__(self, in_channels, out_channels, stride, cardinality, widen_factor):\n        """""" Constructor\n        Args:\n            in_channels: input channel dimensionality\n            out_channels: output channel dimensionality\n            stride: conv stride. Replaces pooling layer.\n            cardinality: num of convolution groups.\n            widen_factor: factor to reduce the input dimensionality before convolution.\n        """"""\n        super(ResNeXtBottleneck, self).__init__()\n        D = cardinality * out_channels // widen_factor\n        self.conv_reduce = nn.Conv2d(in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_reduce = nn.BatchNorm2d(D)\n        self.conv_conv = nn.Conv2d(D, D, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n        self.bn = nn.BatchNorm2d(D)\n        self.conv_expand = nn.Conv2d(D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_expand = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut.add_module(\'shortcut_conv\', nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False))\n            self.shortcut.add_module(\'shortcut_bn\', nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        bottleneck = self.conv_reduce.forward(x)\n        bottleneck = F.relu(self.bn_reduce.forward(bottleneck), inplace=True)\n        bottleneck = self.conv_conv.forward(bottleneck)\n        bottleneck = F.relu(self.bn.forward(bottleneck), inplace=True)\n        bottleneck = self.conv_expand.forward(bottleneck)\n        bottleneck = self.bn_expand.forward(bottleneck)\n        residual = self.shortcut.forward(x)\n        return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n    """"""\n    ResNext optimized for the Cifar dataset, as specified in\n    https://arxiv.org/pdf/1611.05431.pdf\n    """"""\n    def __init__(self, cardinality, depth, num_classes, widen_factor=4, dropRate=0):\n        """""" Constructor\n        Args:\n            cardinality: number of convolution groups.\n            depth: number of layers.\n            num_classes: number of classes\n            widen_factor: factor to adjust the channel dimensionality\n        """"""\n        super(CifarResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.depth = depth\n        self.block_depth = (self.depth - 2) // 9\n        self.widen_factor = widen_factor\n        self.num_classes = num_classes\n        self.output_size = 64\n        self.stages = [64, 64 * self.widen_factor, 128 * self.widen_factor, 256 * self.widen_factor]\n\n        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(64)\n        self.stage_1 = self.block(\'stage_1\', self.stages[0], self.stages[1], 1)\n        self.stage_2 = self.block(\'stage_2\', self.stages[1], self.stages[2], 2)\n        self.stage_3 = self.block(\'stage_3\', self.stages[2], self.stages[3], 2)\n        self.classifier = nn.Linear(1024, num_classes)\n        init.kaiming_normal(self.classifier.weight)\n\n        for key in self.state_dict():\n            if key.split(\'.\')[-1] == \'weight\':\n                if \'conv\' in key:\n                    init.kaiming_normal(self.state_dict()[key], mode=\'fan_out\')\n                if \'bn\' in key:\n                    self.state_dict()[key][...] = 1\n            elif key.split(\'.\')[-1] == \'bias\':\n                self.state_dict()[key][...] = 0\n\n    def block(self, name, in_channels, out_channels, pool_stride=2):\n        """""" Stack n bottleneck modules where n is inferred from the depth of the network.\n        Args:\n            name: string name of the current block.\n            in_channels: number of input channels\n            out_channels: number of output channels\n            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n        Returns: a Module consisting of n sequential bottlenecks.\n        """"""\n        block = nn.Sequential()\n        for bottleneck in range(self.block_depth):\n            name_ = \'%s_bottleneck_%d\' % (name, bottleneck)\n            if bottleneck == 0:\n                block.add_module(name_, ResNeXtBottleneck(in_channels, out_channels, pool_stride, self.cardinality,\n                                                          self.widen_factor))\n            else:\n                block.add_module(name_,\n                                 ResNeXtBottleneck(out_channels, out_channels, 1, self.cardinality, self.widen_factor))\n        return block\n\n    def forward(self, x):\n        x = self.conv_1_3x3.forward(x)\n        x = F.relu(self.bn_1.forward(x), inplace=True)\n        x = self.stage_1.forward(x)\n        x = self.stage_2.forward(x)\n        x = self.stage_3.forward(x)\n        x = F.avg_pool2d(x, 8, 1)\n        x = x.view(-1, 1024)\n        return self.classifier(x)\n\ndef resnext(**kwargs):\n    """"""Constructs a ResNeXt.\n    """"""\n    model = CifarResNeXt(**kwargs)\n    return model'"
models/cifar/vgg.py,6,"b'\'\'\'VGG for CIFAR10. FC layers are removed.\n(c) YANG, Wei \n\'\'\'\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport math\n\n\n__all__ = [\n    \'VGG\', \'vgg11\', \'vgg11_bn\', \'vgg13\', \'vgg13_bn\', \'vgg16\', \'vgg16_bn\',\n    \'vgg19_bn\', \'vgg19\',\n]\n\n\nmodel_urls = {\n    \'vgg11\': \'https://download.pytorch.org/models/vgg11-bbd30ac9.pth\',\n    \'vgg13\': \'https://download.pytorch.org/models/vgg13-c768596a.pth\',\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n    \'vgg19\': \'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\',\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Linear(512, num_classes)\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfg = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'B\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'D\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512, \'M\'],\n    \'E\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512, \'M\'],\n}\n\n\ndef vgg11(**kwargs):\n    """"""VGG 11-layer model (configuration ""A"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\']), **kwargs)\n    return model\n\n\ndef vgg11_bn(**kwargs):\n    """"""VGG 11-layer model (configuration ""A"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'A\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg13(**kwargs):\n    """"""VGG 13-layer model (configuration ""B"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\']), **kwargs)\n    return model\n\n\ndef vgg13_bn(**kwargs):\n    """"""VGG 13-layer model (configuration ""B"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'B\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg16(**kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\']), **kwargs)\n    return model\n\n\ndef vgg16_bn(**kwargs):\n    """"""VGG 16-layer model (configuration ""D"") with batch normalization""""""\n    model = VGG(make_layers(cfg[\'D\'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg19(**kwargs):\n    """"""VGG 19-layer model (configuration ""E"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\']), **kwargs)\n    return model\n\n\ndef vgg19_bn(**kwargs):\n    """"""VGG 19-layer model (configuration \'E\') with batch normalization""""""\n    model = VGG(make_layers(cfg[\'E\'], batch_norm=True), **kwargs)\n    return model\n'"
models/cifar/wrn.py,3,"b'import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n__all__ = [\'wrn\']\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut:\n            x = self.relu1(self.bn1(x))\n        else:\n            out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super(NetworkBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x):\n        return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(WideResNet, self).__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert (depth - 4) % 6 == 0, \'depth should be 6n+4\'\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        # 1st block\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        # 2nd block\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        # 3rd block\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n\ndef wrn(**kwargs):\n    """"""\n    Constructs a Wide Residual Networks.\n    """"""\n    model = WideResNet(**kwargs)\n    return model\n'"
models/imagenet/__init__.py,0,b'from __future__ import absolute_import\n\nfrom .resnext import *\n'
models/imagenet/resnext.py,3,"b'from __future__ import division\n"""""" \nCreates a ResNeXt Model as defined in:\nXie, S., Girshick, R., Dollar, P., Tu, Z., & He, K. (2016). \nAggregated residual transformations for deep neural networks. \narXiv preprint arXiv:1611.05431.\nimport from https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua\n""""""\nimport math\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport torch\n\n__all__ = [\'resnext50\', \'resnext101\', \'resnext152\']\n\nclass Bottleneck(nn.Module):\n    """"""\n    RexNeXt bottleneck type C\n    """"""\n    expansion = 4\n\n    def __init__(self, inplanes, planes, baseWidth, cardinality, stride=1, downsample=None):\n        """""" Constructor\n        Args:\n            inplanes: input channel dimensionality\n            planes: output channel dimensionality\n            baseWidth: base width.\n            cardinality: num of convolution groups.\n            stride: conv stride. Replaces pooling layer.\n        """"""\n        super(Bottleneck, self).__init__()\n\n        D = int(math.floor(planes * (baseWidth / 64)))\n        C = cardinality\n\n        self.conv1 = nn.Conv2d(inplanes, D*C, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn1 = nn.BatchNorm2d(D*C)\n        self.conv2 = nn.Conv2d(D*C, D*C, kernel_size=3, stride=stride, padding=1, groups=C, bias=False)\n        self.bn2 = nn.BatchNorm2d(D*C)\n        self.conv3 = nn.Conv2d(D*C, planes * 4, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.downsample = downsample\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNeXt(nn.Module):\n    """"""\n    ResNext optimized for the ImageNet dataset, as specified in\n    https://arxiv.org/pdf/1611.05431.pdf\n    """"""\n    def __init__(self, baseWidth, cardinality, layers, num_classes):\n        """""" Constructor\n        Args:\n            baseWidth: baseWidth for ResNeXt.\n            cardinality: number of convolution groups.\n            layers: config of layers, e.g., [3, 4, 6, 3]\n            num_classes: number of classes\n        """"""\n        super(ResNeXt, self).__init__()\n        block = Bottleneck\n\n        self.cardinality = cardinality\n        self.baseWidth = baseWidth\n        self.num_classes = num_classes\n        self.inplanes = 64\n        self.output_size = 64\n\n        self.conv1 = nn.Conv2d(3, 64, 7, 2, 3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], 2)\n        self.layer3 = self._make_layer(block, 256, layers[2], 2)\n        self.layer4 = self._make_layer(block, 512, layers[3], 2)\n        self.avgpool = nn.AvgPool2d(7)      \n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        """""" Stack n bottleneck modules where n is inferred from the depth of the network.\n        Args:\n            block: block type used to construct ResNext\n            planes: number of output channels (need to multiply by block.expansion)\n            blocks: number of blocks to be built\n            stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n        Returns: a Module consisting of n sequential bottlenecks.\n        """"""\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, self.baseWidth, self.cardinality, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, self.baseWidth, self.cardinality))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool1(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnext50(baseWidth, cardinality):\n    """"""\n    Construct ResNeXt-50.\n    """"""\n    model = ResNeXt(baseWidth, cardinality, [3, 4, 6, 3], 1000)\n    return model\n\n\ndef resnext101(baseWidth, cardinality):\n    """"""\n    Construct ResNeXt-101.\n    """"""\n    model = ResNeXt(baseWidth, cardinality, [3, 4, 23, 3], 1000)\n    return model\n\n\ndef resnext152(baseWidth, cardinality):\n    """"""\n    Construct ResNeXt-152.\n    """"""\n    model = ResNeXt(baseWidth, cardinality, [3, 8, 36, 3], 1000)\n    return model\n'"
