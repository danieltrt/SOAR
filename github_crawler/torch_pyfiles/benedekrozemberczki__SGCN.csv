file_path,api_count,code
src/main.py,0,"b'""""""SGCN runner.""""""\n\nfrom sgcn import SignedGCNTrainer\nfrom param_parser import parameter_parser\nfrom utils import tab_printer, read_graph, score_printer, save_logs\n\ndef main():\n    """"""\n    Parsing command line parameters.\n    Creating target matrix.\n    Fitting an SGCN.\n    Predicting edge signs and saving the embedding.\n    """"""\n    args = parameter_parser()\n    tab_printer(args)\n    edges = read_graph(args)\n    trainer = SignedGCNTrainer(args, edges)\n    trainer.setup_dataset()\n    trainer.create_and_train_model()\n    if args.test_size > 0:\n        trainer.save_model()\n        score_printer(trainer.logs)\n        save_logs(args, trainer.logs)\n\nif __name__ == ""__main__"":\n    main()\n'"
src/param_parser.py,0,"b'import argparse\n\ndef parameter_parser():\n    """"""\n    A method to parse up command line parameters.\n    By default it gives an embedding of the Bitcoin OTC dataset.\n    The default hyperparameters give a good quality representation without grid search.\n    Representations are sorted by node ID.\n    """"""\n    parser = argparse.ArgumentParser(description=""Run SGCN."")\n\n    parser.add_argument(""--edge-path"",\n                        nargs=""?"",\n                        default=""./input/bitcoin_otc.csv"",\n\t                help=""Edge list csv."")\n\n    parser.add_argument(""--features-path"",\n                        nargs=""?"",\n                        default=""./input/bitcoin_otc.csv"",\n\t                help=""Edge list csv."")\n\n    parser.add_argument(""--embedding-path"",\n                        nargs=""?"",\n                        default=""./output/embedding/bitcoin_otc_sgcn.csv"",\n\t                help=""Target embedding csv."")\n\n    parser.add_argument(""--regression-weights-path"",\n                        nargs=""?"",\n                        default=""./output/weights/bitcoin_otc_sgcn.csv"",\n\t                help=""Regression weights csv."")\n\n    parser.add_argument(""--log-path"",\n                        nargs=""?"",\n                        default=""./logs/bitcoin_otc_logs.json"",\n\t                help=""Log json."")\n\n    parser.add_argument(""--epochs"",\n                        type=int,\n                        default=100,\n\t                help=""Number of training epochs. Default is 100."")\n\n    parser.add_argument(""--reduction-iterations"",\n                        type=int,\n                        default=30,\n\t                help=""Number of SVD iterations. Default is 30."")\n\n    parser.add_argument(""--reduction-dimensions"",\n                        type=int,\n                        default=64,\n\t                help=""Number of SVD feature extraction dimensions. Default is 64."")\n\n    parser.add_argument(""--seed"",\n                        type=int,\n                        default=42,\n\t                help=""Random seed for sklearn pre-training. Default is 42."")\n\n    parser.add_argument(""--lamb"",\n                        type=float,\n                        default=1.0,\n\t                help=""Embedding regularization parameter. Default is 1.0."")\n\n    parser.add_argument(""--test-size"",\n                        type=float,\n                        default=0.2,\n\t                help=""Test dataset size. Default is 0.2."")\n\n    parser.add_argument(""--learning-rate"",\n                        type=float,\n                        default=0.01,\n\t                help=""Learning rate. Default is 0.01."")\n\n    parser.add_argument(""--weight-decay"",\n                        type=float,\n                        default=10**-5,\n\t                help=""Learning rate. Default is 10^-5."")\n\n    parser.add_argument(""--layers"",\n                        nargs=""+"",\n                        type=int,\n                        help=""Layer dimensions separated by space. E.g. 32 32."")\n\n    parser.add_argument(""--spectral-features"",\n                        dest=""spectral_features"",\n                        action=""store_true"")\n\n    parser.add_argument(""--general-features"",\n                        dest=""spectral_features"",\n                        action=""store_false"")\n\n    parser.set_defaults(spectral_features=True)\n\n    parser.set_defaults(layers=[32, 32])\n\n    return parser.parse_args()\n'"
src/sgcn.py,43,"b'""""""SGCN runner.""""""\n\nimport time\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import trange\nimport torch.nn.init as init\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom utils import calculate_auc, setup_features\nfrom sklearn.model_selection import train_test_split\nfrom signedsageconvolution import SignedSAGEConvolutionBase, SignedSAGEConvolutionDeep\nfrom signedsageconvolution import ListModule\n\nclass SignedGraphConvolutionalNetwork(torch.nn.Module):\n    """"""\n    Signed Graph Convolutional Network Class.\n    For details see: Signed Graph Convolutional Network.\n    Tyler Derr, Yao Ma, and Jiliang Tang ICDM, 2018.\n    https://arxiv.org/abs/1808.06354\n    """"""\n    def __init__(self, device, args, X):\n        super(SignedGraphConvolutionalNetwork, self).__init__()\n        """"""\n        SGCN Initialization.\n        :param device: Device for calculations.\n        :param args: Arguments object.\n        :param X: Node features.\n        """"""\n        self.args = args\n        torch.manual_seed(self.args.seed)\n        self.device = device\n        self.X = X\n        self.setup_layers()\n\n    def setup_layers(self):\n        """"""\n        Adding Base Layers, Deep Signed GraphSAGE layers.\n        Assing Regression Parameters if the model is not a single layer model.\n        """"""\n        self.nodes = range(self.X.shape[0])\n        self.neurons = self.args.layers\n        self.layers = len(self.neurons)\n        self.positive_base_aggregator = SignedSAGEConvolutionBase(self.X.shape[1]*2,\n                                                                  self.neurons[0]).to(self.device)\n\n        self.negative_base_aggregator = SignedSAGEConvolutionBase(self.X.shape[1]*2,\n                                                                  self.neurons[0]).to(self.device)\n        self.positive_aggregators = []\n        self.negative_aggregators = []\n        for i in range(1, self.layers):\n            self.positive_aggregators.append(SignedSAGEConvolutionDeep(3*self.neurons[i-1],\n                                                                       self.neurons[i]).to(self.device))\n\n            self.negative_aggregators.append(SignedSAGEConvolutionDeep(3*self.neurons[i-1],\n                                                                       self.neurons[i]).to(self.device))\n\n        self.positive_aggregators = ListModule(*self.positive_aggregators)\n        self.negative_aggregators = ListModule(*self.negative_aggregators)\n        self.regression_weights = Parameter(torch.Tensor(4*self.neurons[-1], 3))\n        init.xavier_normal_(self.regression_weights)\n\n    def calculate_regression_loss(self, z, target):\n        """"""\n        Calculating the regression loss for all pairs of nodes.\n        :param z: Hidden vertex representations.\n        :param target: Target vector.\n        :return loss_term: Regression loss.\n        :return predictions_soft: Predictions for each vertex pair.\n        """"""\n        pos = torch.cat((self.positive_z_i, self.positive_z_j), 1)\n        neg = torch.cat((self.negative_z_i, self.negative_z_j), 1)\n\n        surr_neg_i = torch.cat((self.negative_z_i, self.negative_z_k), 1)\n        surr_neg_j = torch.cat((self.negative_z_j, self.negative_z_k), 1)\n        surr_pos_i = torch.cat((self.positive_z_i, self.positive_z_k), 1)\n        surr_pos_j = torch.cat((self.positive_z_j, self.positive_z_k), 1)\n\n        features = torch.cat((pos, neg, surr_neg_i, surr_neg_j, surr_pos_i, surr_pos_j))\n        predictions = torch.mm(features, self.regression_weights)\n        predictions_soft = F.log_softmax(predictions, dim=1)\n        loss_term = F.nll_loss(predictions_soft, target)\n        return loss_term, predictions_soft\n\n    def calculate_positive_embedding_loss(self, z, positive_edges):\n        """"""\n        Calculating the loss on the positive edge embedding distances\n        :param z: Hidden vertex representation.\n        :param positive_edges: Positive training edges.\n        :return loss_term: Loss value on positive edge embedding.\n        """"""\n        self.positive_surrogates = [random.choice(self.nodes) for node in range(positive_edges.shape[1])]\n        self.positive_surrogates = torch.from_numpy(np.array(self.positive_surrogates, dtype=np.int64).T)\n        self.positive_surrogates = self.positive_surrogates.type(torch.long).to(self.device)\n        positive_edges = torch.t(positive_edges)\n        self.positive_z_i = z[positive_edges[:, 0], :]\n        self.positive_z_j = z[positive_edges[:, 1], :]\n        self.positive_z_k = z[self.positive_surrogates, :]\n        norm_i_j = torch.norm(self.positive_z_i-self.positive_z_j, 2, 1, True).pow(2)\n        norm_i_k = torch.norm(self.positive_z_i-self.positive_z_k, 2, 1, True).pow(2)\n        term = norm_i_j-norm_i_k\n        term[term < 0] = 0\n        loss_term = term.mean()\n        return loss_term\n\n    def calculate_negative_embedding_loss(self, z, negative_edges):\n        """"""\n        Calculating the loss on the negative edge embedding distances\n        :param z: Hidden vertex representation.\n        :param negative_edges: Negative training edges.\n        :return loss_term: Loss value on negative edge embedding.\n        """"""\n        self.negative_surrogates = [random.choice(self.nodes) for node in range(negative_edges.shape[1])]\n        self.negative_surrogates = torch.from_numpy(np.array(self.negative_surrogates, dtype=np.int64).T)\n        self.negative_surrogates = self.negative_surrogates.type(torch.long).to(self.device)\n        negative_edges = torch.t(negative_edges)\n        self.negative_z_i = z[negative_edges[:, 0], :]\n        self.negative_z_j = z[negative_edges[:, 1], :]\n        self.negative_z_k = z[self.negative_surrogates, :]\n        norm_i_j = torch.norm(self.negative_z_i-self.negative_z_j, 2, 1, True).pow(2)\n        norm_i_k = torch.norm(self.negative_z_i-self.negative_z_k, 2, 1, True).pow(2)\n        term = norm_i_k-norm_i_j\n        term[term < 0] = 0\n        loss_term = term.mean()\n        return loss_term\n\n    def calculate_loss_function(self, z, positive_edges, negative_edges, target):\n        """"""\n        Calculating the embedding losses, regression loss and weight regularization loss.\n        :param z: Node embedding.\n        :param positive_edges: Positive edge pairs.\n        :param negative_edges: Negative edge pairs.\n        :param target: Target vector.\n        :return loss: Value of loss.\n        """"""\n        loss_term_1 = self.calculate_positive_embedding_loss(z, positive_edges)\n        loss_term_2 = self.calculate_negative_embedding_loss(z, negative_edges)\n        regression_loss, self.predictions = self.calculate_regression_loss(z, target)\n        loss_term = regression_loss+self.args.lamb*(loss_term_1+loss_term_2)\n        return loss_term\n\n    def forward(self, positive_edges, negative_edges, target):\n        """"""\n        Model forward propagation pass. Can fit deep and single layer SGCN models.\n        :param positive_edges: Positive edges.\n        :param negative_edges: Negative edges.\n        :param target: Target vectors.\n        :return loss: Loss value.\n        :return self.z: Hidden vertex representations.\n        """"""\n        self.h_pos, self.h_neg = [], []\n        self.h_pos.append(torch.tanh(self.positive_base_aggregator(self.X, positive_edges)))\n        self.h_neg.append(torch.tanh(self.negative_base_aggregator(self.X, negative_edges)))\n        for i in range(1, self.layers):\n            self.h_pos.append(torch.tanh(self.positive_aggregators[i-1](self.h_pos[i-1], self.h_neg[i-1], positive_edges, negative_edges)))\n            self.h_neg.append(torch.tanh(self.negative_aggregators[i-1](self.h_neg[i-1], self.h_pos[i-1], positive_edges, negative_edges)))\n        self.z = torch.cat((self.h_pos[-1], self.h_neg[-1]), 1)\n        loss = self.calculate_loss_function(self.z, positive_edges, negative_edges, target)\n        return loss, self.z\n\nclass SignedGCNTrainer(object):\n    """"""\n    Object to train and score the SGCN, log the model behaviour and save the output.\n    """"""\n    def __init__(self, args, edges):\n        """"""\n        Constructing the trainer instance and setting up logs.\n        :param args: Arguments object.\n        :param edges: Edge data structure with positive and negative edges separated.\n        """"""\n        self.args = args\n        self.edges = edges\n        self.device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n        self.setup_logs()\n\n    def setup_logs(self):\n        """"""\n        Creating a log dictionary.\n        """"""\n        self.logs = {}\n        self.logs[""parameters""] = vars(self.args)\n        self.logs[""performance""] = [[""Epoch"", ""AUC"", ""F1""]]\n        self.logs[""training_time""] = [[""Epoch"", ""Seconds""]]\n\n    def setup_dataset(self):\n        """"""\n        Creating train and test split.\n        """"""\n        self.positive_edges, self.test_positive_edges = train_test_split(self.edges[""positive_edges""],\n                                                                         test_size=self.args.test_size)\n\n        self.negative_edges, self.test_negative_edges = train_test_split(self.edges[""negative_edges""],\n                                                                         test_size=self.args.test_size)\n        self.ecount = len(self.positive_edges + self.negative_edges)\n\n        self.X = setup_features(self.args,\n                                self.positive_edges,\n                                self.negative_edges,\n                                self.edges[""ncount""])\n\n        self.positive_edges = torch.from_numpy(np.array(self.positive_edges,\n                                                        dtype=np.int64).T).type(torch.long).to(self.device)\n\n        self.negative_edges = torch.from_numpy(np.array(self.negative_edges,\n                                                        dtype=np.int64).T).type(torch.long).to(self.device)\n\n        self.y = np.array([0 if i < int(self.ecount/2) else 1 for i in range(self.ecount)]+[2]*(self.ecount*2))\n        self.y = torch.from_numpy(self.y).type(torch.LongTensor).to(self.device)\n        self.X = torch.from_numpy(self.X).float().to(self.device)\n\n    def score_model(self, epoch):\n        """"""\n        Score the model on the test set edges in each epoch.\n        :param epoch: Epoch number.\n        """"""\n        loss, self.train_z = self.model(self.positive_edges, self.negative_edges, self.y)\n        score_positive_edges = torch.from_numpy(np.array(self.test_positive_edges, dtype=np.int64).T).type(torch.long).to(self.device)\n        score_negative_edges = torch.from_numpy(np.array(self.test_negative_edges, dtype=np.int64).T).type(torch.long).to(self.device)\n        test_positive_z = torch.cat((self.train_z[score_positive_edges[0, :], :], self.train_z[score_positive_edges[1, :], :]), 1)\n        test_negative_z = torch.cat((self.train_z[score_negative_edges[0, :], :], self.train_z[score_negative_edges[1, :], :]), 1)\n        scores = torch.mm(torch.cat((test_positive_z, test_negative_z), 0), self.model.regression_weights.to(self.device))\n        probability_scores = torch.exp(F.softmax(scores, dim=1))\n        predictions = probability_scores[:, 0]/probability_scores[:, 0:2].sum(1)\n        predictions = predictions.cpu().detach().numpy()\n        targets = [0]*len(self.test_positive_edges) + [1]*len(self.test_negative_edges)\n        auc, f1 = calculate_auc(targets, predictions, self.edges)\n        self.logs[""performance""].append([epoch+1, auc, f1])\n\n    def create_and_train_model(self):\n        """"""\n        Model training and scoring.\n        """"""\n        print(""\\nTraining started.\\n"")\n        self.model = SignedGraphConvolutionalNetwork(self.device, self.args, self.X).to(self.device)\n        self.optimizer = torch.optim.Adam(self.model.parameters(),\n                                          lr=self.args.learning_rate,\n                                          weight_decay=self.args.weight_decay)\n        self.model.train()\n        self.epochs = trange(self.args.epochs, desc=""Loss"")\n        for epoch in self.epochs:\n            start_time = time.time()\n            self.optimizer.zero_grad()\n            loss, _ = self.model(self.positive_edges, self.negative_edges, self.y)\n            loss.backward()\n            self.epochs.set_description(""SGCN (Loss=%g)"" % round(loss.item(), 4))\n            self.optimizer.step()\n            self.logs[""training_time""].append([epoch+1, time.time()-start_time])\n            if self.args.test_size > 0:\n                self.score_model(epoch)\n\n    def save_model(self):\n        """"""\n        Saving the embedding and model weights.\n        """"""\n        print(""\\nEmbedding is saved.\\n"")\n        self.train_z = self.train_z.cpu().detach().numpy()\n        embedding_header = [""id""] + [""x_""+str(x) for x in range(self.train_z.shape[1])]\n        self.train_z = np.concatenate([np.array(range(self.train_z.shape[0])).reshape(-1, 1), self.train_z], axis=1)\n        self.train_z = pd.DataFrame(self.train_z, columns=embedding_header)\n        self.train_z.to_csv(self.args.embedding_path, index=None)\n        print(""\\nRegression weights are saved.\\n"")\n        self.regression_weights = self.model.regression_weights.cpu().detach().numpy().T\n        regression_header = [""x_"" + str(x) for x in range(self.regression_weights.shape[1])]\n        self.regression_weights = pd.DataFrame(self.regression_weights, columns=regression_header)\n        self.regression_weights.to_csv(self.args.regression_weights_path, index=None)\n'"
src/signedsageconvolution.py,10,"b'""""""Layer classes.""""""\n\nimport math\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nfrom torch_scatter import scatter_add, scatter_mean\nfrom torch_geometric.utils import remove_self_loops, add_self_loops\n\ndef uniform(size, tensor):\n    """"""\n    Uniform weight initialization.\n    :param size: Size of the tensor.\n    :param tensor: Tensor initialized.\n    """"""\n    stdv = 1.0 / math.sqrt(size)\n    if tensor is not None:\n        tensor.data.uniform_(-stdv, stdv)\n\nclass ListModule(torch.nn.Module):\n    """"""\n    Abstract list layer class.\n    """"""\n    def __init__(self, *args):\n        """"""\n        Model initializing.\n        """"""\n        super(ListModule, self).__init__()\n        idx = 0\n        for module in args:\n            self.add_module(str(idx), module)\n            idx += 1\n\n    def __getitem__(self, idx):\n        """"""\n        Getting the indexed layer.\n        """"""\n        if idx < 0 or idx >= len(self._modules):\n            raise IndexError(\'index {} is out of range\'.format(idx))\n        it = iter(self._modules.values())\n        for i in range(idx):\n            next(it)\n        return next(it)\n\n    def __iter__(self):\n        """"""\n        Iterating on the layers.\n        """"""\n        return iter(self._modules.values())\n\n    def __len__(self):\n        """"""\n        Number of layers.\n        """"""\n        return len(self._modules)\n\nclass SignedSAGEConvolution(torch.nn.Module):\n    """"""\n    Abstract Signed SAGE convolution class.\n    :param in_channels: Number of features.\n    :param out_channels: Number of filters.\n    :param norm_embed: Normalize embedding -- boolean.\n    :param bias: Add bias or no.\n    """"""\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 norm=True,\n                 norm_embed=True,\n                 bias=True):\n        super(SignedSAGEConvolution, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.norm = norm\n        self.norm_embed = norm_embed\n        self.weight = Parameter(torch.Tensor(self.in_channels, out_channels))\n\n        if bias:\n            self.bias = Parameter(torch.Tensor(out_channels))\n        else:\n            self.register_parameter(""bias"", None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        """"""\n        Initialize parameters.\n        """"""\n        size = self.weight.size(0)\n        uniform(size, self.weight)\n        uniform(size, self.bias)\n\n    def __repr__(self):\n        """"""\n        Create formal string representation.\n        """"""\n        return ""{}({}, {})"".format(self.__class__.__name__, self.in_channels, self.out_channels)\n\nclass SignedSAGEConvolutionBase(SignedSAGEConvolution):\n    """"""\n    Base Signed SAGE class for the first layer of the model.\n    """"""\n    def forward(self, x, edge_index):\n        """"""\n        Forward propagation pass with features an indices.\n        :param x: Feature matrix.\n        :param edge_index: Indices.\n        """"""\n        edge_index, _ = remove_self_loops(edge_index, None)\n        row, col = edge_index\n\n        if self.norm:\n            out = scatter_mean(x[col], row, dim=0, dim_size=x.size(0))\n        else:\n            out = scatter_add(x[col], row, dim=0, dim_size=x.size(0))\n\n        out = torch.cat((out, x), 1)\n        out = torch.matmul(out, self.weight)\n\n        if self.bias is not None:\n            out = out + self.bias\n        if self.norm_embed:\n            out = F.normalize(out, p=2, dim=-1)\n        return out\n\nclass SignedSAGEConvolutionDeep(SignedSAGEConvolution):\n    """"""\n    Deep Signed SAGE class for multi-layer models.\n    """"""\n    def forward(self, x_1, x_2, edge_index_pos, edge_index_neg):\n        """"""\n        Forward propagation pass with features an indices.\n        :param x_1: Features for left hand side vertices.\n        :param x_2: Features for right hand side vertices.\n        :param edge_index_pos: Positive indices.\n        :param edge_index_neg: Negative indices.\n        :return out: Abstract convolved features.\n        """"""\n        edge_index_pos, _ = remove_self_loops(edge_index_pos, None)\n        edge_index_pos, _ = add_self_loops(edge_index_pos, num_nodes=x_1.size(0))\n        edge_index_neg, _ = remove_self_loops(edge_index_neg, None)\n        edge_index_neg, _ = add_self_loops(edge_index_neg, num_nodes=x_2.size(0))\n\n        row_pos, col_pos = edge_index_pos\n        row_neg, col_neg = edge_index_neg\n\n        if self.norm:\n            out_1 = scatter_mean(x_1[col_pos], row_pos, dim=0, dim_size=x_1.size(0))\n            out_2 = scatter_mean(x_2[col_neg], row_neg, dim=0, dim_size=x_2.size(0))\n        else:\n            out_1 = scatter_add(x_1[col_pos], row_pos, dim=0, dim_size=x_1.size(0))\n            out_2 = scatter_add(x_2[col_neg], row_neg, dim=0, dim_size=x_2.size(0))\n\n        out = torch.cat((out_1, out_2, x_1), 1)\n        out = torch.matmul(out, self.weight)\n        if self.bias is not None:\n            out = out + self.bias\n\n        if self.norm_embed:\n            out = F.normalize(out, p=2, dim=-1)\n        return out\n'"
src/utils.py,0,"b'""""""Data reading utils.""""""\n\nimport json\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom texttable import Texttable\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import roc_auc_score, f1_score\n\ndef read_graph(args):\n    """"""\n    Method to read graph and create a target matrix with pooled adjacency matrix powers.\n    :param args: Arguments object.\n    :return edges: Edges dictionary.\n    """"""\n    dataset = pd.read_csv(args.edge_path).values.tolist()\n    edges = {}\n    edges[""positive_edges""] = [edge[0:2] for edge in dataset if edge[2] == 1]\n    edges[""negative_edges""] = [edge[0:2] for edge in dataset if edge[2] == -1]\n    edges[""ecount""] = len(dataset)\n    edges[""ncount""] = len(set([edge[0] for edge in dataset]+[edge[1] for edge in dataset]))\n    return edges\n\ndef tab_printer(args):\n    """"""\n    Function to print the logs in a nice tabular format.\n    :param args: Parameters used for the model.\n    """"""\n    args = vars(args)\n    keys = sorted(args.keys())\n    t = Texttable()\n    t.add_rows([[""Parameter"", ""Value""]])\n    t.add_rows([[k.replace(""_"", "" "").capitalize(), args[k]] for k in keys])\n    print(t.draw())\n\ndef calculate_auc(targets, predictions, edges):\n    """"""\n    Calculate performance measures on test dataset.\n    :param targets: Target vector to predict.\n    :param predictions: Predictions vector.\n    :param edges: Edges dictionary with number of edges etc.\n    :return auc: AUC value.\n    :return f1: F1-score.\n    """"""\n    neg_ratio = len(edges[""negative_edges""])/edges[""ecount""]\n    targets = [0 if target == 1 else 1 for target in targets]\n    auc = roc_auc_score(targets, predictions)\n    f1 = f1_score(targets, [1 if p > neg_ratio else 0 for p in  predictions])\n    return auc, f1\n\ndef score_printer(logs):\n    """"""\n    Print the performance for every 10th epoch on the test dataset.\n    :param logs: Log dictionary.\n    """"""\n    t = Texttable()\n    t.add_rows([per for i, per in enumerate(logs[""performance""]) if i % 10 == 0])\n    print(t.draw())\n\ndef save_logs(args, logs):\n    """"""\n    Save the logs at the path.\n    :param args: Arguments objects.\n    :param logs: Log dictionary.\n    """"""\n    with open(args.log_path, ""w"") as f:\n        json.dump(logs, f)\n\ndef setup_features(args, positive_edges, negative_edges, node_count):\n    """"""\n    Setting up the node features as a numpy array.\n    :param args: Arguments object.\n    :param positive_edges: Positive edges list.\n    :param negative_edges: Negative edges list.\n    :param node_count: Number of nodes.\n    :return X: Node features.\n    """"""\n    if args.spectral_features:\n        X = create_spectral_features(args, positive_edges, negative_edges, node_count)\n    else:\n        X = create_general_features(args)\n    return X\n\ndef create_general_features(args):\n    """"""\n    Reading features using the path.\n    :param args: Arguments object.\n    :return X: Node features.\n    """"""\n    X = np.array(pd.read_csv(args.features_path))\n    return X\n\ndef create_spectral_features(args, positive_edges, negative_edges, node_count):\n    """"""\n    Creating spectral node features using the train dataset edges.\n    :param args: Arguments object.\n    :param positive_edges: Positive edges list.\n    :param negative_edges: Negative edges list.\n    :param node_count: Number of nodes.\n    :return X: Node features.\n    """"""\n    p_edges = positive_edges + [[edge[1], edge[0]] for edge in positive_edges]\n    n_edges = negative_edges + [[edge[1], edge[0]] for edge in negative_edges]\n    train_edges = p_edges + n_edges\n    index_1 = [edge[0] for edge in train_edges]\n    index_2 = [edge[1] for edge in train_edges]\n    values = [1]*len(p_edges) + [-1]*len(n_edges)\n    shaping = (node_count, node_count)\n    signed_A = sparse.csr_matrix(sparse.coo_matrix((values, (index_1, index_2)),\n                                                   shape=shaping,\n                                                   dtype=np.float32))\n\n    svd = TruncatedSVD(n_components=args.reduction_dimensions,\n                       n_iter=args.reduction_iterations,\n                       random_state=args.seed)\n    svd.fit(signed_A)\n    X = svd.components_.T\n    return X\n'"
