file_path,api_count,code
__init__.py,0,b'#'
common.py,3,"b'import os\nimport numpy as np\nimport pandas as pd\nimport time\nimport importlib\nimport torch\nimport random\nimport pickle\nimport math\nimport matplotlib.pyplot as plt\nimport socket\nimport datetime\nfrom PIL import Image\nfrom collections import Counter\nfrom glob import glob\nfrom IPython.display import FileLink\n\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.backends import cudnn\nfrom torch.autograd import Variable\nfrom torch import optim\nfrom torch import nn\nimport torchvision\nimport torchsample\n\nimport config as cfg\nimport constants as c\n\nimport competitions\n\nimport ensembles\nfrom ensembles import ens_utils\n\nimport datasets\nfrom datasets import data_aug\nfrom datasets import data_folds\nfrom datasets import data_loaders\nfrom datasets import metadata\n\nfrom experiments.experiment import Experiment\nfrom experiments import exp_utils, exp_builder\n\nimport models.builder\nimport models.resnet\nimport models.unet\nimport models.utils\n\nfrom metrics import evaluate\nfrom metrics import metric_utils\nfrom metrics import metric\nfrom metrics import loss_functions\n\nimport predictions\nfrom predictions import pred_utils\n\nimport submissions\n\nimport training\nfrom training import learning_rates\nfrom training import trainers\n\nimport visualizers\nfrom visualizers.viz import Viz\nfrom visualizers.kibana import Kibana\nfrom visualizers import vis_utils\n\nimport utils\n'"
config.py,0,"b""import os\nimport socket\nimport init_project\nimport constants as c\n\n# Main config\nHOSTNAME = socket.gethostname()\nPROJECT_NAME = 'dogscats'\nPROJECT_PATH = '/bigguy/data/' + PROJECT_NAME\nPROJECT_TYPE = c.SEGMENTATION\nIMG_INPUT_FORMATS = [c.JPG]\nIMG_TARGET_FORMATS = [c.BCOLZ] #segmentation or generative\nIMG_DATASET_TYPES = [c.TRAIN, c.TEST]\nMETADATA_PATH = os.path.join(PROJECT_PATH, 'metadata.csv')\nPATHS = init_project.init_paths(PROJECT_PATH, IMG_DATASET_TYPES,\n    IMG_INPUT_FORMATS, IMG_TARGET_FORMATS)\n\n# AWS Config\nAWS_ACCESS_KEY = os.getenv('KAGGLE_AWS_ACCESS_KEY', 'dummy')\nAWS_SECRET_KEY = os.getenv('KAGGLE_AWS_SECRET_ACCESS_KEY', 'dummy')\nAWS_REGION = 'us-west-1'\nAWS_SES_REGION = 'us-west-2'\nES_ENDPOINT = 'search-kagglecarvana-s7dnklyyz6sm2zald6umybeuau.us-west-1.es.amazonaws.com'\nES_PORT = 80\nKIBANA_URL = 'https://search-kagglecarvana-s7dnklyyz6sm2zald6umybeuau.us-west-1.es.amazonaws.com/_plugin/kibana'\nTIMEZONE = 'US/Pacific'\n\n# External Resources\n# If True, you must setup an S3 bucket, ES Instance, and SES address\nS3_ENABLED = bool(os.getenv('KAGGLE_S3_ENABLED', False))\nES_ENABLED = bool(os.getenv('KAGGLE_ES_ENABLED', False))\nEMAIL_ENABLED = bool(os.getenv('KAGGLE_SES_ENABLED', False))\n\n\n# Email Notifications\nADMIN_EMAIL = 'bfortuner@gmail.com'\nUSER_EMAIL = 'bfortuner@gmail.com'\n"""
constants.py,0,"b""# Project Types\nCLASSIFICATION = 'classification'\nSEGMENTATION = 'segmentation'\nPROJECT_TYPES = [CLASSIFICATION, SEGMENTATION]\n\n# Datasets\nTRAIN = 'trn'\nVAL = 'val'\nTEST = 'tst'\nFULL = 'full'\nDSETS = [TRAIN, VAL, TEST, FULL]\n\n# Transforms\nJOINT = 'joint'\nUPSAMPLE = 'upsample'\nTARGET = 'target'\nTENSOR = 'tensor'\nMASK = 'mask'\n\n# File\nJPG = 'jpg'\nTIF = 'tif'\nPNG = 'png'\nGIF = 'gif'\nBCOLZ = 'bc'\nJPG_EXT = '.'+JPG\nTIF_EXT = '.'+TIF\nPNG_EXT = '.'+PNG\nGIF_EXT = '.'+GIF\nBCOLZ_EXT = '.'+BCOLZ\nIMG_EXTS = [JPG_EXT, TIF_EXT, PNG_EXT, GIF_EXT, BCOLZ_EXT]\nCHECKPOINT_EXT = '.th'\nEXPERIMENT_CONFIG_FILE_EXT = '.json'\nEXPERIMENT_CONFIG_FNAME = 'config.json'\nEXPERIMENT_HISTORY_FILE_EXT = '.csv'\nEXP_FILE_EXT = '.zip'\nPRED_FILE_EXT = '.bc'\nSUBMISSION_FILE_EXT = '.csv'\nENSEMBLE_FILE_EXT = '.bc'\nDSET_FOLD_FILE_EXT = '.json'\nMODEL_EXT = '.mdl'\nWEIGHTS_EXT = '.th'\nOPTIM_EXT = '.th'\n\n# Postfix\nINPUT_POSTFIX = JPG_EXT\nTARGET_POSTFIX = '_mask'+GIF_EXT\n\n# Metrics\nLOSS = 'Loss'\nSCORE = 'Score'\nACCURACY = 'Accuracy'\nF2_SCORE = 'F2'\nENSEMBLE_F2 = 'EnsembleF2'\nDICE_SCORE = 'Dice'\nMEAN = 'mean'\nGMEAN = 'gmean'\nVOTE = 'vote'\nSTD_DEV = 'std'\nENSEMBLE_METHODS = [MEAN, GMEAN]\n\n# File Regex\nWEIGHTS_FNAME_REGEX = r'weights-(\\d+)\\.pth$'\nOPTIM_FNAME_REGEX = r'optim-(\\d+)\\.pth$'\nWEIGHTS_OPTIM_FNAME_REGEX = r'(weights|optim)-(\\d+)\\.th$'\nLATEST_WEIGHTS_FNAME = 'latest_weights.th'\nLATEST_OPTIM_FNAME = 'latest_optim.th'\nLATEST = 'latest'\n\n\n# Predictions\nSINGLE_MODEL_PRED = 'single-basic'\nSINGLE_MODEL_TTA_PRED = 'single-tta'\nPREDICTION_TYPES = [SINGLE_MODEL_PRED, SINGLE_MODEL_TTA_PRED]\nSINGLE_MODEL_ENSEMBLE = 'single-ens'\nSINGLE_MODEL_TTA_ENSEMBLE = 'single-ens-tta'\nENSEMBLE_TYPES = [SINGLE_MODEL_ENSEMBLE, SINGLE_MODEL_TTA_ENSEMBLE]\nDEFAULT_BLOCK_NAME = 'preds'\n\n# Ensembles\nMEGA_ENSEMBLE = 'mega-ens'\nMEGA_ENSEMBLE_TYPES = [MEGA_ENSEMBLE]\n\n\n# Experiments\nINITIALIZED = 'INITIALIZED'\nRESUMED = 'RESUMED'\nCOMPLETED = 'COMPLETED'\nIN_PROGRESS = 'IN_PROGRESS'\nFAILED = 'FAILED'\nMAX_PATIENCE_EXCEEDED = 'MAX_PATIENCE_EXCEEDED'\nEXPERIMENT_STATUSES = [INITIALIZED, RESUMED, COMPLETED,\n    IN_PROGRESS, FAILED, MAX_PATIENCE_EXCEEDED]\nEXP_ID_FIELD = 'exp_id'\nES_EXP_KEY_FIELD = 'key'\nLATEST_WEIGHTS_FNAME = 'latest_weights{:s}'.format(WEIGHTS_EXT)\nLATEST_OPTIM_FNAME = 'latest_optim{:s}'.format(OPTIM_EXT)\nMODEL_FNAME = 'model{:s}'.format(MODEL_EXT)\nOPTIM_FNAME = 'optim{:s}'.format(OPTIM_EXT)\n\n\n# Data Aug\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD = [0.229, 0.224, 0.225]\n"""
init_project.py,0,"b""import os\nimport config as cfg\n\n\ndef init_paths(root, dset_types, input_img_exts, target_img_exts):\n    paths = {\n        'project': root,\n        'experiments': os.path.join(root, 'experiments'),\n        'predictions': os.path.join(root, 'predictions'),\n        'submissions': os.path.join(root, 'submissions'),\n        'folds': os.path.join(root, 'folds')\n    }\n    for key in paths:\n        os.makedirs(paths[key], exist_ok=True)\n    \n    paths['datasets'] = {}\n    datasets_root = os.path.join(root, 'datasets')\n    os.makedirs(datasets_root, exist_ok=True)\n    make_dataset(paths, datasets_root, 'inputs', dset_types, input_img_exts)\n    make_dataset(paths, datasets_root, 'targets', dset_types, target_img_exts)\n\n    return paths\n\n\ndef make_dataset(paths, datasets_root, name, dset_types, img_exts):\n    root = os.path.join(datasets_root, name)\n    os.makedirs(root, exist_ok=True)\n    paths['datasets'][name] = {}\n\n    for dset in dset_types:\n        for img in img_exts:\n            dir_name = dset+'_'+img\n            dir_path = os.path.join(root, dir_name)\n            os.makedirs(dir_path, exist_ok=True)\n            paths['datasets'][name][dir_name] = dir_path\n\n\nif __name__ == '__main__':\n    init_paths(cfg.PROJECT_PATH, cfg.IMG_DATASET_TYPES, \n        cfg.IMG_INPUT_FORMATS, cfg.IMG_TARGET_FORMATS)"""
clients/__init__.py,0,b''
clients/client_constants.py,0,"b""import config as cfg\n\n# AWS Config\nAWS_REGION = cfg.AWS_REGION\nAWS_ACCESS_KEY = cfg.AWS_ACCESS_KEY\nAWS_SECRET_KEY = cfg.AWS_SECRET_KEY\nTIMEZONE = cfg.TIMEZONE\n\n# S3 Config\nS3_BUCKET = 'kaggle{:s}'.format(cfg.PROJECT_NAME)\nEXPERIMENT_CONFIG_PREFIX = 'experiment_configs/'\nEXPERIMENT_HISTORY_PREFIX = 'experiment_histories/'\nEXPERIMENT_PREFIX = 'experiments/'\nPREDICTION_PREFIX = 'predictions/'\nENSEMBLE_PREFIX = 'ensembles/'\n\n# Elasticsearch Config\nES_EXPERIMENT_HISTORY_INDEX = 'kaggle-{:s}-history'.format(cfg.PROJECT_NAME)\nES_EXPERIMENT_CONFIG_INDEX = 'kaggle-{:s}-config'.format(cfg.PROJECT_NAME)\nES_PREDICTIONS_INDEX = 'kaggle-{:s}-predictions'.format(cfg.PROJECT_NAME)\nES_EXPERIMENT_HISTORY_DOC_TYPE = 'history'\nES_EXPERIMENT_CONFIG_DOC_TYPE = 'config'\nES_PREDICTIONS_DOC_TYPE = 'prediction'\nES_ENDPOINT = cfg.ES_ENDPOINT\nES_PORT = cfg.ES_PORT\n\n# SES Config\nAWS_SES_REGION = cfg.AWS_SES_REGION\nADMIN_EMAIL = cfg.ADMIN_EMAIL\nUSER_EMAIL = cfg.USER_EMAIL\nEMAIL_CHARSET = 'UTF-8'\n"""
clients/es_client.py,0,"b'from elasticsearch import Elasticsearch\nfrom datetime import datetime\nimport pytz\n\nfrom .client_constants import *\n\n\ndef upload_experiment_history(config, history):\n    index_docs(history.to_doc(config), ES_EXPERIMENT_HISTORY_INDEX,\n                  ES_EXPERIMENT_HISTORY_DOC_TYPE)\n\n\ndef upload_experiment_config(config):\n    index_doc(config.to_doc(), ES_EXPERIMENT_CONFIG_INDEX,\n                 ES_EXPERIMENT_CONFIG_DOC_TYPE)\n\n\ndef upload_prediction(pred):\n    index_doc(pred.to_doc(), ES_PREDICTIONS_INDEX,\n                 ES_PREDICTIONS_DOC_TYPE)\n\n\ndef delete_experiment(config):\n    delete_experiment_by_id(config.get_id())\n\n\ndef delete_experiment_by_id(exp_id):\n    r1 = delete_by_field(ES_EXPERIMENT_HISTORY_INDEX,\n                       ES_EXPERIMENT_HISTORY_DOC_TYPE,\n                       ES_EXP_KEY_FIELD, exp_id)\n    r2 = delete_by_field(ES_EXPERIMENT_CONFIG_INDEX,\n                       ES_EXPERIMENT_CONFIG_DOC_TYPE,\n                       ES_EXP_KEY_FIELD, exp_id)\n    return r1,r2\n\n\ndef delete_experiment_by_field(field, value):\n    r1 = delete_by_field(ES_EXPERIMENT_HISTORY_INDEX,\n                   ES_EXPERIMENT_HISTORY_DOC_TYPE,\n                   field, value)\n    r2 = delete_by_field(ES_EXPERIMENT_CONFIG_INDEX,\n                   ES_EXPERIMENT_CONFIG_DOC_TYPE,\n                   field, value)\n    return r1,r2\n\n\n# API\n# http://elasticsearch-py.readthedocs.io/en/master/api.html\n\ndef get_client():\n    return Elasticsearch([\n        {\'host\': ES_ENDPOINT, \'port\': ES_PORT},\n    ])\n\ndef create_index(name, shards=2, replicas=1):\n    es = get_client()\n    ok = es.indices.create(name, body={\n        ""settings"" : {\n            ""index"" : {\n                ""number_of_shards"" : shards,\n                ""number_of_replicas"" : replicas\n            }\n        }\n    })[\'acknowledged\']\n    assert ok is True\n    return ok\n\ndef delete_index(name):\n    ok = get_client().indices.delete(name)[\'acknowledged\']\n    assert ok is True\n    return ok\n\ndef delete_docs_by_ids(index_name, doc_ids):\n    pass\n\ndef delete_by_field(index_name, doc_type, field, value):\n    query = {\n        ""query"": {\n            ""match"" : {\n                field : value\n            }\n        }\n    }\n    es = get_client()\n    r = es.delete_by_query(index=index_name, doc_type=doc_type, body=query)\n    return r\n\ndef search_by_field(index_name, doc_type, field, value):\n    query = {\n            ""term"" : {\n                field : value\n            }\n    }\n    print(query)\n    es = get_client()\n    resp = es.search(index=index_name, doc_type=doc_type, body=query)\n    return resp\n\ndef get_doc(index_name, doc_key):\n    return get_client().get(index_name, id=doc_key)\n\ndef search(index_name, query, metadata_only=False, n_docs=10):\n    es = get_client()\n    filters = []\n    if metadata_only:\n        filters = [\'hits.hits._id\', \'hits.hits._type\']\n    return es.search(index=index_name, filter_path=filters,\n                     body=query, size=n_docs)\n\ndef index_doc(doc, index_name, doc_type):\n    assert \'key\' in doc\n    es = get_client()\n    doc[\'uploaded\'] = datetime.now(pytz.timezone(TIMEZONE))\n    es.index(index=index_name, doc_type=doc_type, body=doc, id=doc[\'key\'])\n\ndef index_docs(docs, index_name, doc_type):\n    # There exists a bulk API, but this is fine for now\n    for doc in docs:\n        index_doc(doc, index_name, doc_type)\n\ndef get_mappings(index_name):\n    # Shows the keys and data types in an index\n    return get_client().indices.get_mapping(index_name)\n\ndef doc_exists(index_name, doc_type, doc_id):\n    return get_client().exists(index_name, doc_type, doc_id)\n\ndef health():\n    return get_client().cluster.health(wait_for_status=\'yellow\',\n                                       request_timeout=1)\n\ndef ping():\n    return get_client().ping()\n\n'"
clients/s3_client.py,0,"b""import boto3\nimport constants as c\nfrom .client_constants import *\n\n\n# List Files\n\ndef list_experiment_configs():\n    return list_fnames(EXPERIMENT_CONFIG_PREFIX,\n                       c.EXPERIMENT_CONFIG_FILE_EXT)\n\ndef list_experiments():\n    return list_fnames(EXPERIMENT_PREFIX, c.EXP_FILE_EXT)\n\ndef list_predictions():\n    return list_fnames(PREDICTION_PREFIX, c.PRED_FILE_EXT)\n\ndef list_fnames(prefix, postfix):\n    keys = get_keys(prefix=prefix)\n    names = []\n    for k in keys:\n        names.append(k.replace(prefix,'').replace(postfix,''))\n    return names\n\n\n# Download\n\ndef download_experiment(dest_fpath, exp_name, bucket=S3_BUCKET):\n    key = EXPERIMENT_PREFIX+exp_name + c.EXP_FILE_EXT\n    download_file(dest_fpath, key, bucket=bucket)\n\ndef download_experiment_config(dest_fpath, exp_name, bucket=S3_BUCKET):\n    key = EXPERIMENT_CONFIG_PREFIX+exp_name+c.EXPERIMENT_CONFIG_FILE_EXT\n    download_file(dest_fpath, key, bucket=bucket)\n\ndef download_prediction(dest_fpath, pred_name, bucket=S3_BUCKET):\n    key = PREDICTION_PREFIX+pred_name+c.PRED_FILE_EXT\n    download_file(dest_fpath, key, bucket=bucket)\n\n\n# Read Object directly from S3\n\ndef fetch_experiment_history(exp_name, bucket=S3_BUCKET):\n    key = EXPERIMENT_HISTORY_PREFIX+exp_name+c.EXPERIMENT_HISTORY_FILE_EXT\n    return get_object_str(key, bucket)\n\ndef fetch_experiment_config(exp_name, bucket=S3_BUCKET):\n    key = EXPERIMENT_CONFIG_PREFIX+exp_name+c.EXPERIMENT_CONFIG_FILE_EXT\n    return get_object_str(key, bucket)\n\n\n# Upload\n\ndef upload_experiment(src_fpath, exp_name, bucket=S3_BUCKET):\n    key = EXPERIMENT_PREFIX+exp_name+c.EXP_FILE_EXT\n    upload_file(src_fpath, key, bucket=bucket)\n\ndef upload_experiment_config(src_fpath, exp_name, bucket=S3_BUCKET):\n    key = EXPERIMENT_CONFIG_PREFIX+exp_name+c.EXPERIMENT_CONFIG_FILE_EXT\n    upload_file(src_fpath, key, bucket=bucket)\n\ndef upload_experiment_history(src_fpath, exp_name, bucket=S3_BUCKET):\n    key = EXPERIMENT_HISTORY_PREFIX+exp_name+c.EXPERIMENT_HISTORY_FILE_EXT\n    upload_file(src_fpath, key, bucket=bucket)\n\ndef upload_prediction(src_fpath, pred_name, bucket=S3_BUCKET):\n    key = PREDICTION_PREFIX+pred_name+c.PRED_FILE_EXT\n    upload_file(src_fpath, key, bucket=bucket)\n\n\n# Cleanup\n\ndef delete_experiment(exp_name):\n    exp_config_key = (EXPERIMENT_CONFIG_PREFIX + exp_name\n                      + c.EXPERIMENT_CONFIG_FILE_EXT)\n    exp_history_key = (EXPERIMENT_HISTORY_PREFIX + exp_name\n                      + c.EXPERIMENT_HISTORY_FILE_EXT)\n    delete_object(S3_BUCKET, key=exp_config_key)\n    delete_object(S3_BUCKET, key=exp_history_key)\n\n\n# Base Helpers\n\ndef get_client():\n    return boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY,\n                        aws_secret_access_key=AWS_SECRET_KEY)\n\ndef get_resource():\n    return boto3.resource('s3', aws_access_key_id=AWS_ACCESS_KEY,\n                          aws_secret_access_key=AWS_SECRET_KEY)\n\ndef get_buckets():\n    return get_client().list_buckets()\n\ndef get_object_str(key, bucket=S3_BUCKET):\n    s3 = get_resource()\n    obj = s3.Object(bucket, key)\n    return obj.get()['Body'].read().decode('utf-8')\n\ndef get_keys(prefix, bucket=S3_BUCKET):\n    objs = get_objects(prefix, bucket)\n    keys = []\n    if 'Contents' not in objs:\n        return keys\n    for obj in objs['Contents']:\n        keys.append(obj['Key'])\n    return keys\n\ndef download_file(dest_fpath, s3_fpath, bucket=S3_BUCKET):\n    get_client().download_file(Filename=dest_fpath,\n                               Bucket=bucket,\n                               Key=s3_fpath)\n\ndef upload_file(src_fpath, s3_fpath, bucket=S3_BUCKET):\n    get_client().upload_file(Filename=src_fpath,\n                             Bucket=bucket,\n                             Key=s3_fpath)\n\ndef get_download_url(s3_path, bucket=S3_BUCKET, expiry=86400):\n    return get_client().generate_presigned_url(\n        ClientMethod='get_object',\n        Params={'Bucket': bucket,\n                'Key': s3_path},\n        ExpiresIn=expiry\n    )\n\n#key = 'experiment_configs/JeremyCNN-SGD-lr1-wd0001-bs32-id6E878.json'\ndef delete_object(bucket, key):\n    return get_client().delete_object(\n        Bucket=bucket,\n        Key=key\n    )\n"""
clients/ses_client.py,0,"b""import boto3\nfrom .client_constants import *\n\n\ndef get_client():\n    return boto3.client('ses', aws_access_key_id=AWS_ACCESS_KEY,\n                        aws_secret_access_key=AWS_SECRET_KEY,\n                        region_name=AWS_SES_REGION)\n\n\ndef send_email(subject, body, to_email, from_email=ADMIN_EMAIL):\n    response = get_client().send_email(\n        Source=from_email,\n        Destination={\n            'ToAddresses': [\n                to_email,\n            ],\n            'CcAddresses': [],\n            'BccAddresses': []\n        },\n        Message={\n            'Subject': {\n                'Data': subject,\n                'Charset': EMAIL_CHARSET\n            },\n            'Body': {\n                'Text': {\n                    'Data': body,\n                    'Charset': EMAIL_CHARSET\n                },\n                'Html': {\n                    'Data': body,\n                    'Charset': EMAIL_CHARSET\n                }\n            }\n        }\n    )\n    return response\n\n"""
competitions/__init__.py,0,b''
competitions/carvana.py,0,"b'import os\nimport time\nimport shutil\nimport gzip\n\nimport utils.files\nimport config as cfg\nimport constants as c\nfrom datasets import datasets\nfrom datasets import data_loaders\nimport predictions\nimport training\nimport submissions\n\n\n\ndef get_submission_lines(pred_arr, fnames):\n    lines = []\n    for i in range(len(pred_arr)):\n        rle = submissions.run_length_encode(pred_arr[i])\n        lines.append(fnames[i]+\',\'+rle)\n    return lines\n\n\ndef make_submission(pred, block_size=10000, header=None, compress=True):\n    meta = pred.attrs[\'meta\']\n    print(""Preds"", pred.shape, meta[\'name\'], meta[\'dset\'])\n    input_fnames = meta[\'input_fnames\']\n    sub_fpath = os.path.join(cfg.PATHS[\'submissions\'], meta[\'name\']+c.SUBMISSION_FILE_EXT)\n    lines = [] if header is None else [header]\n\n    i = 0\n    while i < len(pred):\n        start = time.time()\n        pred_block = pred[i:i+block_size].squeeze().astype(\'uint8\')\n        newlines = get_submission_lines(pred_block, input_fnames[i:i+block_size])\n        lines.extend(newlines)\n        i += block_size\n        print(training.get_time_msg(start))\n\n    sub_fpath = utils.files.write_lines(sub_fpath, lines, compress)\n    return sub_fpath\n\n\ndef get_block_predict_dataloaders(dataset, block_size, batch_size):\n    loaders = []\n    i = 0\n    while i < len(dataset):\n        inp_fpaths = dataset.input_fpaths[i:i+block_size]\n        tar_fpaths = (None if dataset.target_fpaths is None \n                      else dataset.target_fpaths[i:i+block_size])\n        block_dset = datasets.ImageTargetDataset(inp_fpaths, tar_fpaths, \n                          \'pil\', \'pil\', input_transform=dataset.input_transform, \n                            target_transform=dataset.target_transform, \n                            joint_transform=dataset.joint_transform)\n        block_loader = data_loaders.get_data_loader(block_dset, batch_size,\n                              shuffle=False, n_workers=2, pin_memory=False)\n        loaders.append(block_loader)\n        i += block_size\n    return loaders\n\n\ndef predict_binary_mask_blocks(name, dset, model, dataset, block_size,\n                                batch_size, threshold, W=None, H=None):\n    pred_fpath = os.path.join(cfg.PATHS[\'predictions\'], name + \'_\' \n                              + dset + c.PRED_FILE_EXT)\n    if os.path.exists(pred_fpath):\n        print(\'Pred file exists. Overwriting\')\n        time.sleep(2)\n        shutil.rmtree(pred_fpath)\n    \n    loaders = get_block_predict_dataloaders(dataset, block_size, batch_size)\n    input_fnames = utils.files.get_fnames_from_fpaths(dataset.input_fpaths)\n    target_fnames = (None if dataset.target_fpaths is None else \n        utils.files.get_fnames_from_fpaths(dataset.target_fpaths))\n    meta = {\n            \'name\': name,\n            \'dset\': dset,\n            \'input_fnames\': input_fnames,\n            \'target_fnames\': target_fnames\n    }\n    \n    i = 0\n    for loader in loaders:\n        print(\'Predicting block_{:d}, inputs: {:d}\'.format(i, len(loader.dataset)))\n        start = time.time()\n        pred_block = predictions.get_mask_predictions(\n            model, loader, threshold, W, H).astype(\'uint8\')\n        if i == 0:\n            preds = predictions.save_pred(pred_fpath, pred_block, meta)\n        else:\n            preds = predictions.append_to_pred(preds, pred_block)\n        i += 1\n        print(training.get_time_msg(start))\n    return pred_fpath\n\n\ndef upsample_preds(preds, block_size, W, H):\n    meta = preds[0].attrs[\'meta\'].copy()\n    n_inputs = preds[0].shape[0]\n    up_fpath = os.path.join(cfg.PATHS[\'predictions\'], \n        meta[\'name\']+\'_up\'+c.PRED_FILE_EXT)\n    print(""inputs"", n_inputs, ""preds"",len(preds), up_fpath)\n\n    if os.path.exists(up_fpath):\n        print(\'Ens file exists. Overwriting\')\n        time.sleep(2)\n        shutil.rmtree(up_fpath)\n    \n    i = 0\n    start = time.time()\n    while i < n_inputs:\n        up_block = predictions.resize_batch(\n            preds[i:i+block_size], W, H).astype(\'uint8\')\n        if i == 0:\n            up_pred = predictions.save_pred(up_fpath, up_block, meta)\n        else:\n            up_pred = predictions.append_to_pred(up_pred, up_block)\n        i += block_size\n    \n    print(utils.logger.get_time_msg(start))\n    return up_pred\n\n\n\ndef get_and_write_probabilities_to_bcolz():\n    """"""If I need extra speed""""""\n    pass'"
competitions/dogscats.py,0,"b""import os\nimport numpy as np\nimport pandas as pd\n\nimport config as cfg\nimport constants as c\n\nimport datasets.metadata as meta\nimport utils\n\n\nLABEL_NAMES = ['cat', 'dog']\nLABEL_TO_IDX = meta.get_labels_to_idxs(LABEL_NAMES)\nIDX_TO_LABEL = meta.get_idxs_to_labels(LABEL_NAMES)\nSUB_HEADER = 'id,label'\n\n\ndef make_metadata_file():\n    '''\n    First move the cats/dogs data in train.zip \n    to `catsdogs/datasets/inputs/trn_jpg` \n    '''\n    train_path = cfg.PATHS['datasets']['inputs']['trn_jpg']\n    _, fnames = utils.files.get_paths_to_files(\n        train_path, strip_ext=True)\n    lines = []\n    for name in fnames:\n        label = name.split('.')[0]\n        lines.append('{:s},{:s}\\n'.format(name, label))\n    with open(cfg.METADATA_PATH, 'w') as f:\n        f.writelines(lines)"""
competitions/planet.py,0,"b""import os\nimport numpy as np\nimport pandas as pd\n\nimport config as cfg\nimport constants as c\n\nimport datasets.metadata as meta\nimport utils\n\n\nLABEL_NAMES = [\n    'clear','partly_cloudy','haze','cloudy','primary','agriculture','road','water',\n    'cultivation','habitation','bare_ground','selective_logging','artisinal_mine','blooming',\n    'slash_burn','blow_down','conventional_mine']\nLABEL_TO_IDX = meta.get_labels_to_idxs(LABEL_NAMES)\nIDX_TO_LABEL = meta.get_idxs_to_labels(LABEL_NAMES)\nSUB_HEADER = 'image_name,tags'\n"""
datasets/__init__.py,0,b''
datasets/data_aug.py,5,"b'import math\nimport random\nfrom PIL import Image, ImageFilter\nimport cv2\nimport numpy as np\n\nimport torch\nimport torchsample\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\n\n#http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html\n\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD = [0.229, 0.224, 0.225]\n\nIMAGENET_NORMALIZE = torchvision.transforms.Normalize(\n            mean=IMAGENET_MEAN,\n            std=IMAGENET_STD\n)\n\ndef get_data_aug_summary(transforms):\n    data_aug = []\n    for r in transforms.transforms:\n        data_aug.append((str(r.__class__.__name__), r.__dict__))\n    return data_aug\n\n\ndef get_basic_transform(scale, normalize=None):\n    data_aug = [\n        torchvision.transforms.Scale(scale),\n        torchvision.transforms.ToTensor()\n    ]\n    if normalize is not None:\n        data_aug.append(normalize)\n    return torchvision.transforms.Compose(data_aug)\n\n\ndef get_single_pil_transform(scale, augmentation, normalize=None):\n    data_aug = [\n        torchvision.transforms.Scale(scale),\n        augmentation,\n        torchvision.transforms.ToTensor()\n    ]\n    if normalize is not None:\n        data_aug.append(normalize)\n    return torchvision.transforms.Compose(data_aug)\n\n\ndef get_single_tensor_transform(scale, augmentation, normalize=None):\n    data_aug = [\n        torchvision.transforms.Scale(scale),\n        torchvision.transforms.ToTensor(),\n        augmentation\n    ]\n    if normalize is not None:\n        data_aug.append(normalize)\n    return torchvision.transforms.Compose(data_aug)\n\n\nclass RandomRotate90(object):\n    def __init__(self, p=0.75):\n        self.p = p\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, input_ in enumerate(inputs):\n            input_ = random_rotate_90(input_, self.p)\n            outputs.append(input_)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass BinaryMask(object):\n    def __init__(self, thresholds):\n        self.thresholds = thresholds\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, input_ in enumerate(inputs):\n            input_[input_ >= self.thresholds] = 1.0\n            input_[input_ < self.thresholds] = 0.0\n            outputs.append(input_)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass Slice1D(object):\n    def __init__(self, dim=0, slice_idx=0):\n        self.dim = dim\n        self.slice_idx = slice_idx\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, input_ in enumerate(inputs):\n            input_ = torch.unsqueeze(input_[self.slice_idx,:,:], dim=self.dim)\n            outputs.append(input_)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass RandomHueSaturation(object):\n    def __init__(self, hue_shift=(-180, 180), sat_shift=(-255, 255),\n                    val_shift=(-255, 255), u=0.5):\n        self.hue_shift = hue_shift\n        self.sat_shift = sat_shift\n        self.val_shift = val_shift\n        self.u = u\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, input_ in enumerate(inputs):\n            input_ = random_hue_saturation(input_, self.hue_shift,\n                self.sat_shift, self.val_shift, self.u)\n            outputs.append(input_)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass RandomShiftScaleRotate(object):\n    def __init__(self, shift=(-0.0625,0.0625), scale=(-0.1,0.1),\n                    rotate=(-45,45), aspect=(0,0), u=0.5):\n        self.shift = shift\n        self.scale = scale\n        self.rotate = rotate\n        self.aspect = aspect\n        self.border_mode = cv2.BORDER_CONSTANT\n        self.u = u\n\n    def __call__(self, input_, target):\n        input_, target = random_shift_scale_rot(input_, target, self.shift, \n        self.scale, self.rotate, self.aspect, self.border_mode, self.u)\n        return [input_, target]\n\n\ndef random_rotate_90(pil_img, p=1.0):\n    if random.random() < p:\n        angle=random.randint(1,3)*90\n        if angle == 90:\n            pil_img = pil_img.rotate(90)\n        elif angle == 180:\n            pil_img = pil_img.rotate(180)\n        elif angle == 270:\n            pil_img = pil_img.rotate(270)\n    return pil_img\n\n\ndef random_hue_saturation(image, hue_shift=(-180, 180), sat_shift=(-255, 255),\n                            val_shift=(-255, 255), u=0.5):\n    image = np.array(image)\n    if np.random.random() < u:\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        h, s, v = cv2.split(image)\n        hue_shift = np.random.uniform(hue_shift[0], hue_shift[1])\n        h = cv2.add(h, hue_shift)\n        sat_shift = np.random.uniform(sat_shift[0], sat_shift[1])\n        s = cv2.add(s, sat_shift)\n        val_shift = np.random.uniform(val_shift[0], val_shift[1])\n        v = cv2.add(v, val_shift)\n        image = cv2.merge((h, s, v))\n        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n    \n    return Image.fromarray(image)\n\n\ndef random_shift_scale_rot(image, label, shift_limit=(-0.0625,0.0625), \n        scale_limit=(-0.1,0.1), rotate_limit=(-45,45), aspect_limit = (0,0),  \n        borderMode=cv2.BORDER_CONSTANT, u=0.5):\n    image = image.numpy().transpose(1,2,0)\n    label = label.numpy().squeeze()\n    if random.random() < u:\n        height,width,channel = image.shape\n\n        angle  = random.uniform(rotate_limit[0],rotate_limit[1])  #degree\n        scale  = random.uniform(1+scale_limit[0],1+scale_limit[1])\n        aspect = random.uniform(1+aspect_limit[0],1+aspect_limit[1])\n        sx    = scale*aspect/(aspect**0.5)\n        sy    = scale       /(aspect**0.5)\n        dx    = round(random.uniform(shift_limit[0],shift_limit[1])*width )\n        dy    = round(random.uniform(shift_limit[0],shift_limit[1])*height)\n\n        cc = math.cos(angle/180*math.pi)*(sx)\n        ss = math.sin(angle/180*math.pi)*(sy)\n        rotate_matrix = np.array([ [cc,-ss], [ss,cc] ])\n\n        box0 = np.array([ [0,0], [width,0],  [width,height], [0,height], ])\n        box1 = box0 - np.array([width/2,height/2])\n        box1 = np.dot(box1,rotate_matrix.T) + np.array([width/2+dx,height/2+dy])\n        box0 = box0.astype(np.float32)\n        box1 = box1.astype(np.float32)\n        mat = cv2.getPerspectiveTransform(box0,box1)\n        image = cv2.warpPerspective(image, mat, (width,height),\n        flags=cv2.INTER_LINEAR,borderMode=borderMode,borderValue=(0,0,0,))  \n        #cv2.BORDER_CONSTANT, borderValue = (0, 0, 0))  #cv2.BORDER_REFLECT_101\n\n        box0 = np.array([ [0,0], [width,0],  [width,height], [0,height], ])\n        box1 = box0 - np.array([width/2,height/2])\n        box1 = np.dot(box1,rotate_matrix.T) + np.array([width/2+dx,height/2+dy])\n        box0 = box0.astype(np.float32)\n        box1 = box1.astype(np.float32)\n        mat = cv2.getPerspectiveTransform(box0,box1)\n        label = cv2.warpPerspective(label, mat, (width,height),\n        flags=cv2.INTER_LINEAR,borderMode=borderMode,borderValue=(0,0,0,)) \n        #cv2.BORDER_CONSTANT, borderValue = (0, 0, 0))  #cv2.BORDER_REFLECT_101\n    image = torch.from_numpy(image.transpose(2,0,1))\n    label = np.expand_dims(label, 0)\n    label = torch.from_numpy(label)#.transpose(2,0,1)) \n    return image,label\n\n\nblurTransform = torchvision.transforms.Lambda(\n    lambda img: img.filter(ImageFilter.GaussianBlur(1.5)))'"
datasets/data_folds.py,0,"b""import os\nimport random\nimport numpy as np\n\nimport utils.files\nimport constants as c\n\n\ndef make_bag(fpaths, targets):\n    bag_fpaths = []\n    bag_targets = []\n    for i in range(len(fpaths)):\n        idx = random.randint(1,len(fpaths)-1)\n        bag_fpaths.append(fpaths[idx])\n        bag_targets.append(targets[idx])\n    return bag_fpaths, np.array(bag_targets)\n\n\ndef verify_bag(trn_fpaths_bag):\n    trn_dict = {}\n    for f in trn_fpaths_bag:\n        if f in trn_dict:\n            trn_dict[f] += 1\n        else:\n            trn_dict[f] = 1\n    return max(trn_dict.values())\n\n\ndef make_fold(name, trn_path, tst_path, folds_dir, \n                val_size, shuffle=True):\n    _, trn_fnames = utils.files.get_paths_to_files(\n        trn_path, file_ext=c.JPG, sort=True, strip_ext=True)\n    _, tst_fnames = utils.files.get_paths_to_files(\n        tst_path, file_ext=c.JPG, sort=True, strip_ext=True)\n\n    if shuffle:\n        random.shuffle(trn_fnames)\n\n    fold = {\n        c.TRAIN: trn_fnames[:-val_size],\n        c.VAL: trn_fnames[-val_size:],\n        c.TEST: tst_fnames\n    }\n\n    fpath = os.path.join(folds_dir, name + c.DSET_FOLD_FILE_EXT)\n    utils.files.save_json(fpath, fold)\n    return fold\n\n\ndef load_data_fold(folds_dir, name):\n    fpath = os.path.join(folds_dir, name + c.DSET_FOLD_FILE_EXT)\n    return utils.files.load_json(fpath)\n\n\ndef get_fpaths_from_fold(fold, dset, dset_path, postfix=''):\n    fnames = fold[dset]\n    fpaths = [os.path.join(dset_path, f+postfix) for f in fnames]\n    return fpaths\n\n\ndef get_targets_from_fold(fold, dset, lookup):\n    img_names = [f.split('.')[0] for f in fold[dset]]\n    targets = []\n    for img in img_names:\n        targets.append(lookup[img])\n    return np.array(targets)\n\n\ndef get_fpaths_targets_from_fold(fold, dset, dset_path, lookup):\n    fpaths = get_fpaths_from_fold(fold, dset, dset_path)\n    targets = get_fpaths_from_fold(fold, dset, lookup)\n    return fpaths, targets\n"""
datasets/data_loaders.py,3,"b'import os\nimport torch.utils.data\nfrom torch.utils.data import DataLoader\nfrom config import *\nimport utils.imgs as img_utils\n\n\n\nclass MixDataLoader():\n    """"""\n    Combines batches from two data loaders.\n    Useful for pseudolabeling.\n    """"""\n    def __init__(self, dl1, dl2):\n        self.dl1 = dl1\n        self.dl2 = dl2\n        self.dl1_iter = iter(dl1)\n        self.dl2_iter = iter(dl2)\n        self.n = len(dl1)\n        self.cur = 0\n\n    def _reset(self):\n        self.cur = 0\n\n    def _cat_lst(self, fn1, fn2):\n        return fn1 + fn2\n\n    def _cat_tns(self, t1, t2):\n        return torch.cat([t1, t2])\n\n    def __next__(self):\n        x1,y1,f1 = next(self.dl1_iter)\n        x2,y2,f2 = next(self.dl2_iter)\n        while self.cur < self.n:\n            self.cur += 1\n            return (self._cat_tns(x1,x2), self._cat_tns(y1,y2),\n                    self._cat_lst(f1,f2))\n\n    def __iter__(self):\n        self.cur = 0\n        self.dl1_iter = iter(self.dl1)\n        self.dl2_iter = iter(self.dl2)\n        return self\n\n    def __len__(self):\n        return self.n\n\n\ndef get_batch(dataset, batch_size, shuffle=False):\n    dataloader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=shuffle)\n    inputs, targets, img_paths = next(iter(dataloader))\n    return inputs, targets, img_paths\n\n\ndef get_data_loader(dset, batch_size, shuffle=False,\n                    n_workers=1, pin_memory=False):\n    return DataLoader(dset, batch_size, shuffle=shuffle,\n                      pin_memory=pin_memory, num_workers=n_workers)\n'"
datasets/data_utils.py,1,"b""import os\nimport shutil\nimport numpy as np \nimport utils\nfrom glob import glob\nfrom PIL import Image\nfrom skimage import io\nimport torch\n\nimport config as cfg\nimport constants as c\nfrom datasets import metadata\n\n\n\ndef pil_loader(path):\n    return Image.open(path).convert('RGB')\n\n\ndef tensor_loader(path):\n    return torch.load(path)\n\n\ndef numpy_loader(path):\n    return np.load(path)\n\n\ndef io_loader(path):\n    return io.imread(path)\n\n\ndef tif_loader(path):\n    return calibrate_image(io.imread(path)[:,:,(2,1,0,3)])\n\n\ndef calibrate_image(rgb_image, ref_stds, ref_means):\n    res = rgb_image.astype('float32')\n    return np.clip((res - np.mean(res,axis=(0,1))) / np.std(res,axis=(0,1))\n           * ref_stds + ref_means,0,255).astype('uint8')\n\n\ndef get_inputs_targets(fpaths, dframe):\n    ## REFACTOR\n    inputs = []\n    targets = []\n    for fpath in fpaths:\n        # Refactor\n        name, tags = metadata.get_img_name_and_tags(METADATA_DF, fpath)\n        inputs.append(img_utils.load_img_as_arr(fpath))\n        targets.append(meta.get_one_hots_by_name(name, dframe))\n    return np.array(inputs), np.array(targets)"""
datasets/datasets.py,7,"b'import torch\nfrom . import data_utils\n\n\nloaders = {\n    \'pil\': data_utils.pil_loader,\n    \'tns\': data_utils.tensor_loader,\n    \'npy\': data_utils.numpy_loader,\n    \'tif\': data_utils.tif_loader,\n    \'io\': data_utils.io_loader\n}\n\n\nclass FileDataset(torch.utils.data.Dataset):\n    def __init__(self, fpaths,\n                 img_loader=\'pil\',\n                 targets=None,\n                 transform=None,\n                 target_transform=None):\n        self.fpaths = fpaths\n        self.loader = self._get_loader(img_loader)\n        self.targets = targets\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def _get_loader(self, loader_type):\n        return loaders[loader_type]\n\n    def _get_target(self, index):\n        if self.targets is None:\n            return torch.FloatTensor(1)\n        target = self.targets[index]\n        if self.target_transform is not None:\n            return self.target_transform(target)\n        return torch.FloatTensor(target)\n\n    def _get_input(self, index):\n        img_path = self.fpaths[index]\n        img = self.loader(img_path)\n        if self.transform is not None:\n            img = self.transform(img)\n        return img\n\n    def __getitem__(self, index):\n        input_ = self._get_input(index)\n        target = self._get_target(index)\n        img_path = self.fpaths[index]\n        return input_, target, img_path\n\n    def __len__(self):\n        return len(self.fpaths)\n\n\nclass MultiInputDataset(FileDataset):\n    def __init__(self, fpaths,\n                 img_loader=\'pil\', #\'tns\', \'npy\'\n                 targets=None,\n                 other_inputs=None,\n                 transform=None,\n                 target_transform=None):\n        super().__init__(fpaths, img_loader, targets,\n                         transform, target_transform)\n        self.other_inputs = other_inputs\n\n    def _get_other_input(self, index):\n        other_input = self.other_inputs[index]\n        return other_input\n\n    def __getitem__(self, index):\n        input_ = self._get_input(index)\n        target = self._get_target(index)\n        other_input = self._get_other_input(index)\n        img_path = self.fpaths[index]\n        return input_, target, other_input, img_path\n\n\nclass MultiTargetDataset(FileDataset):\n    def __init__(self, fpaths,\n                 img_loader=\'pil\',\n                 targets=None,\n                 other_targets=None,\n                 transform=None,\n                 target_transform=None):\n        super().__init__(fpaths, img_loader, targets,\n                         transform, target_transform)\n        self.other_targets = other_targets\n\n    def _get_other_target(self, index):\n        if self.other_targets is None:\n            return torch.FloatTensor(1)\n        other_target = self.other_targets[index]\n        return torch.FloatTensor(other_target)\n\n    def __getitem__(self, index):\n        input_ = self._get_input(index)\n        target = self._get_target(index)\n        other_target = self._get_other_target(index)\n        img_path = self.fpaths[index]\n        return input_, target, other_target, img_path\n\n\nclass ImageTargetDataset(torch.utils.data.Dataset):\n    def __init__(self, input_fpaths,\n                target_fpaths,\n                input_loader=\'pil\',\n                target_loader=\'pil\',\n                input_transform=None,\n                target_transform=None,\n                joint_transform=None):\n        self.input_fpaths = input_fpaths\n        self.target_fpaths = target_fpaths\n        self.input_loader = loaders[input_loader]\n        self.target_loader = loaders[target_loader]\n        self.input_transform = input_transform\n        self.target_transform = target_transform\n        self.joint_transform = joint_transform\n\n    def _get_target(self, index):\n        if self.target_fpaths is None:\n            return torch.FloatTensor(1), """"\n        img_path = self.target_fpaths[index]\n        img = self.target_loader(img_path)\n        if self.target_transform is not None:\n            img = self.target_transform(img)\n        return img, img_path\n\n    def _get_input(self, index):\n        img_path = self.input_fpaths[index]\n        img = self.input_loader(img_path)\n        if self.input_transform is not None:\n            img = self.input_transform(img)\n        return img, img_path\n\n    def __getitem__(self, index):\n        input_, inp_path = self._get_input(index)\n        target, tar_path = self._get_target(index)\n        if self.joint_transform is not None:\n            input_, target = self.joint_transform(input_, target)\n        return input_, target, inp_path, tar_path\n\n    def __len__(self):\n        return len(self.input_fpaths)\n'"
datasets/metadata.py,0,"b""import numpy as np\nimport pandas as pd\n\nimport constants as c\n\n\ndef get_metadata_df(fpath):\n    return pd.read_csv(fpath, header=0, names=['id','labels'])\n\n\ndef get_labels_to_idxs(label_names):\n    return {v:k for k,v in enumerate(label_names)}\n\n\ndef get_idxs_to_labels(label_names):\n    return {k:v for k,v in enumerate(label_names)}\n\n\ndef convert_tags_to_one_hots(tags, label_names, delim=' '):\n    label_to_idx = get_labels_to_idxs(label_names)\n    idxs = [label_to_idx[o] for o in tags.split(delim)]\n    onehot = np.zeros((len(label_names),), dtype=np.float32)\n    onehot[idxs] = 1\n    return onehot\n\n\ndef get_one_hots_array(meta_fpath, label_names):\n    meta_df = get_metadata_df(meta_fpath)\n    onehots = np.zeros( (0, len(label_names)) )\n    for _, row in meta_df.iterrows():\n        onehot = convert_tags_to_one_hots(row[1], label_names)\n        onehots = np.append(onehots, np.array([onehot]), axis=0)\n    return onehots\n\n\ndef get_one_hots_from_fold(meta_fpath, fold, dset, label_names):\n    meta_df = get_metadata_df(meta_fpath)\n    onehots = np.zeros( (0, len(label_names)) )\n    for _, name in enumerate(fold[dset]):\n        tags = meta_df[meta_df['id'] == name]['labels'].values[0]\n        onehot = convert_tags_to_one_hots(tags, label_names)\n        onehots = np.append(onehots, np.array([onehot]), axis=0)\n    return onehots\n\n\ndef get_label_idx_by_name(label, label_names):\n    return label_names.index(label)\n\n\ndef get_tags_from_preds(preds, label_names):\n    tags = []\n    for _, pred in enumerate(preds):\n        tag_str = ' '.join(convert_one_hot_to_tags(pred, label_names))\n        tags.append(tag_str)\n    return tags\n\n\ndef convert_one_hot_to_tags(onehot, label_names):\n    tags = []\n    for idx, val in enumerate(onehot):\n        if val == 1:\n            tags.append(label_names[idx])\n    return tags"""
ensembles/__init__.py,0,b'from .ens_utils import *\nimport os'
ensembles/ens_utils.py,0,"b'import os\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nimport shutil\n\nimport config as cfg\nimport constants as c\nimport utils\nimport predictions\n\n\n\ndef get_ensemble_fpath(basename, dset):\n    fname = \'{:s}_{:s}_{:s}\'.format(basename, \'ens\', dset + c.PRED_FILE_EXT)\n    return os.path.join(cfg.PATHS[\'predictions\'], fname)\n\n\ndef get_ensemble_meta(name, fpaths):\n    preds = [predictions.load_pred(f) for f in fpaths]\n    meta = preds[0].attrs[\'meta\'].copy()\n    meta[\'name\'] = name\n    meta[\'members\'] = {p.attrs[\'meta\'][\'name\']:p.attrs[\'meta\'] for p in preds}\n    print(""members"", list(meta[\'members\'].keys()))\n    return meta\n\n\ndef ens_prediction_files(ens_fpath, pred_fpaths, block_size=1, \n                         method=c.MEAN, meta=None):\n    preds = [predictions.load_pred(f) for f in pred_fpaths]\n    n_inputs = preds[0].shape[0]\n    if os.path.exists(ens_fpath):\n        print(\'Ens file exists. Overwriting\')\n        time.sleep(2)\n        shutil.rmtree(ens_fpath)\n    \n    i = 0\n    start = time.time()\n    while i < n_inputs:\n        pred_block = np.array([p[i:i+block_size] for p in preds])\n        ens_block = predictions.ensemble_with_method(pred_block, method)\n        if i == 0:\n            ens_pred = predictions.save_pred(ens_fpath, ens_block, meta)\n        else:\n            ens_pred = predictions.append_to_pred(ens_pred, ens_block)\n        i += block_size\n    print(utils.logger.get_time_msg(start))\n    return ens_fpath\n\n\ndef build_scores(loss, score):\n    return {\n        c.LOSS: loss,\n        c.SCORE: score\n    }\n\n\ndef build_metadata(labels, scores, thresholds, pred_type, dset):\n    return {\n        \'label_names\': labels,\n        \'scores\': scores,\n        \'thresholds\': thresholds,\n        \'pred_type\': pred_type,\n        \'dset\': dset,\n        \'created\': time.strftime(""%m/%d/%Y %H:%M:%S"", time.localtime())\n    }'"
ensembles/ensemble.py,0,"b'import os\nimport pprint\nimport utils.files\nimport copy\nimport constants as c\nfrom predictions.prediction import Prediction\n\n\n\nclass MegaEnsemblePrediction(Prediction):\n    """"""\n    Prediction combining multiple experiments, models and epochs\n    """"""\n    def __init__(self, name, pred_type, fpath, thresholds,\n                 label_names, val_score, val_probs, val_preds,\n                 test_probs, test_preds, created, sub_preds,\n                 ens_method, all_val_probs, all_test_probs):\n        super().__init__(name, pred_type, fpath, thresholds,\n                         label_names, val_score, val_probs, val_preds,\n                         test_probs, test_preds, tta=None, created=created,\n                         other=None)\n\n        self.sub_preds = self.get_sub_pred_docs(sub_preds)\n        self.ens_method = ens_method\n        self.all_val_probs = all_val_probs\n        self.all_test_probs = all_test_probs\n\n    def get_sub_pred_docs(self, sub_preds):\n        docs = []\n        for pred in sub_preds:\n            docs.append(pred.to_doc(include_exp=False))\n        return docs\n\n    def to_doc(self):\n        d = copy.deepcopy(self.__dict__)\n        d[\'key\'] = self.get_id()\n        d[\'pred_id\'] = self.get_id()\n        d[\'display_name\'] = self.get_display_name()\n        d[\'preds\'] = self.sub_preds\n        del d[\'val_probs\']\n        del d[\'val_preds\']\n        del d[\'test_probs\']\n        del d[\'test_preds\']\n        del d[\'all_val_probs\']\n        del d[\'all_test_probs\']\n        return d\n\n\n'"
experiments/__init__.py,0,b''
experiments/exp_builder.py,0,"b""from glob import glob\nimport pandas as pd\nfrom .experiment import Experiment\n\n\n\ndef prune_experiments(exp_dir, exp_names):\n    # Delete weights except for best weight in `n_bins`\n    for name in exp_names:\n        exp = Experiment(name, exp_dir)\n        exp.review(verbose=False)\n        exp.auto_prune(n_bins=5, metric_name='Loss', func=max)\n\n\ndef build_exp_summary_dict(exp):\n    config = exp.config\n    history = exp.history\n    dict_ = {\n        'name': config.name,\n        'exp_id': config.get_id(),\n        'created': config.created,\n        'fold': config.data['dset_fold'],\n        'model_name' : config.model_name,\n        'threshold' : config.training['threshold'],\n        'model_name' : config.model['name'],\n        'optim' : config.optimizer['name'],\n        'optim_params' : str(config.optimizer['params']),\n        'lr_adjuster' : config.lr_adjuster['name'],\n        'lr_adjuster_params' : str(config.lr_adjuster['params']),\n        'criterion': config.criterion['name'],\n        'transforms' : ', '.join([t[0] for t in config.transforms]),\n        ### initial lr, img_scale, rescale, total_epochs\n        'transforms' : ', '.join([t[0] for t in config.transforms]),\n        'init_lr':config.training['initial_lr'],\n        'wdecay':config.training['weight_decay'],\n        'batch': config.training['batch_size'],\n        'img_scl':config.data['img_scale'],\n        'img_rescl': config.data['img_rescale'],\n        'nepochs':config.training['n_epochs'],\n    }\n    for name in config.metrics:\n        dict_[name+'Epoch'] = history.best_metrics[name]['epoch']\n        dict_[name+'Val'] = history.best_metrics[name]['value']\n    return dict_\n\n\ndef build_exps_df_from_dir(exps_dir):\n    exp_names = glob(exps_dir+'/*/')\n    summaries = []\n    for name in exp_names:\n        exp = Experiment(name, exps_dir)\n        exp.review(verbose=False)\n        exp_summary = build_exp_summary_dict(exp)\n        summaries.append(exp_summary)\n    return pd.DataFrame(summaries)\n\n\ndef upload_experiments(exp_dir):\n    exp_paths = glob(exp_dir+'/*/')\n    for path in exp_paths:\n        name = path.strip('/').split('/')[-1]\n        exp = Experiment(name, exp_dir)\n        exp.review(verbose=False)\n        exp.save()\n\n\ndef upload_experiments(exp_dir):\n    exp_paths = glob(exp_dir+'/*/')\n    for path in exp_paths:\n        name = path.strip('/').split('/')[-1]\n        exp = Experiment(name, exp_dir)\n        exp.review(verbose=False)\n        exp.save()\n"""
experiments/exp_config.py,0,"b'import os\nimport json\nimport pprint\nimport logging\nimport time\nimport copy\nfrom datetime import datetime\n\nimport pandas as pd\n\nimport config\nimport constants as c\nimport utils.files\nimport utils.general\nfrom clients import s3_client, es_client\n\n\n\n\nclass ExperimentConfig():\n    def __init__(self, name, parent_dir, created, metrics, aux_metrics,\n                model, optimizer, lr_adjuster, criterion, transforms,\n                visualizers, training, data, hardware, other, progress=None):\n        self.name = name\n        self.parent_dir = parent_dir\n        self.fpath = os.path.join(parent_dir, name,\n                                  c.EXPERIMENT_CONFIG_FNAME)\n        self.created = created\n        self.metrics = metrics\n        self.aux_metrics = aux_metrics\n        self.visualizers = visualizers\n        self.model = model\n        self.optimizer = optimizer\n        self.lr_adjuster = lr_adjuster\n        self.criterion = criterion\n        self.transforms = transforms\n        self.data = data\n        self.training = training\n        self.hardware = hardware\n        self.other = other\n        self.progress = {} if progress is None else progress\n        self.model_name = self.model[\'name\']\n\n    def get_id(self):\n        return self.name.split(\'-id\')[-1]\n\n    def get_display_name(self):\n        return self.name.split(\'-id\')[0]\n\n    def summary(self, include_model=True):\n        d = dict(self.__dict__)\n        del d[\'model\']\n        print(json.dumps(d, indent=4, ensure_ascii=False))\n        if include_model:\n            print(self.model[\'layers\'])\n\n    def save(self, s3=config.S3_ENABLED, es=config.ES_ENABLED):\n        dict_ = self.__dict__\n        utils.files.save_json(self.fpath, dict_)\n        if s3:\n            s3_client.upload_experiment_config(self.fpath, self.name)\n        if es:\n            es_client.upload_experiment_config(self)\n\n    def to_dict(self):\n        return self.__dict__\n\n    def to_json(self):\n        return json.dumps(self.to_dict(), indent=4, ensure_ascii=False)\n\n    def to_html(self):\n        dict_ = self.to_dict()\n        html = utils.general.dict_to_html_ul(dict_)\n        return html\n\n    def to_doc(self):\n        # Changes to self.__dict__ also change instance variables??\n        doc = copy.deepcopy(self.to_dict())\n        doc[c.EXP_ID_FIELD] = self.get_id()\n        doc[c.ES_EXP_KEY_FIELD] = self.get_id()\n        doc[\'display_name\'] = self.get_display_name()\n        doc[\'transforms\'] = str(doc[\'transforms\'])\n        del doc[\'model\']\n        return doc\n\n\n## Helpers\n\ndef fetch_external_config(exp_name):\n    str_ = s3_client.fetch_experiment_config(exp_name)\n    dict_ = json.loads(str_)\n    return load_config_from_json(dict_)\n\n\ndef load_config_from_file(fpath):\n    dict_ = utils.files.load_json(fpath)\n    return load_config_from_json(dict_)\n\n\ndef load_config_from_json(dict_):\n    return ExperimentConfig(\n            name=dict_[\'name\'],\n            parent_dir=dict_[\'parent_dir\'],\n            created=dict_[\'created\'],\n            metrics=dict_[\'metrics\'],\n            aux_metrics=dict_[\'aux_metrics\'],\n            visualizers=dict_[\'visualizers\'],\n            model=dict_[\'model\'],\n            optimizer=dict_[\'optimizer\'],\n            lr_adjuster=dict_[\'lr_adjuster\'],\n            criterion=dict_[\'criterion\'],\n            transforms=dict_[\'transforms\'],\n            data=dict_[\'data\'],\n            training=dict_[\'training\'],\n            hardware=dict_[\'hardware\'],\n            other=dict_[\'other\'],\n            progress=dict_[\'progress\'])\n\n\ndef create_config_from_dict(config):\n    metrics_config = get_metrics_config(config[\'metrics\'])\n    aux_metrics_config = get_aux_metrics_config(config[\'aux_metrics\'])\n    visualizers_config = get_visualizers_config(config[\'visualizers\'])\n    transforms_config = get_transforms_config(config[\'transforms\'])\n    model_config = get_model_config(config[\'model\'])\n    optim_config = get_optim_config(config[\'optimizer\'])\n    lr_adjuster_config = get_lr_config(config[\'lr_adjuster\'])\n    criterion_config = get_criterion_config(config[\'criterion\'])\n    return ExperimentConfig(\n            name=config[\'name\'],\n            parent_dir=config[\'parent_dir\'],\n            created=time.strftime(""%m/%d/%Y %H:%M:%S"", time.localtime()),\n            metrics=metrics_config,\n            aux_metrics=aux_metrics_config,\n            visualizers=visualizers_config,\n            model=model_config,\n            optimizer=optim_config,\n            lr_adjuster=lr_adjuster_config,\n            criterion=criterion_config,\n            transforms=transforms_config,\n            data=config[\'data\'],\n            training=get_training_config(config[\'training\']),\n            hardware=config[\'hardware\'],\n            other=config[\'other\'])\n\n\ndef remove_large_items(dict_):\n    max_len = 100\n    new_dict = {}\n    for k,v in dict_.items():\n        if isinstance(v, list) and len(v) > max_len:\n            pass\n        elif isinstance(v, dict):\n            if len(v.items()) < max_len:\n                new_dict[k] = str(v.items())\n        else:\n            assert not isinstance(v, dict)\n            new_dict[k] = v\n    return new_dict\n\n\ndef get_training_config(train_config):\n    return remove_large_items(train_config)\n\n\ndef get_model_config(model):\n    name = utils.general.get_class_name(model)\n    layers = str(model)\n    return {\n        \'name\': name,\n        \'layers\': layers\n    }\n\n\ndef get_optim_config(optim):\n    name = utils.general.get_class_name(optim)\n    params = optim.param_groups[0]\n    params = remove_large_items(dict(params))\n    if \'params\' in params:\n        del params[\'params\']\n    return {\n        \'name\': name,\n        \'params\': params\n    }\n\n\ndef get_lr_config(lr_adjuster):\n    name = utils.general.get_class_name(lr_adjuster)\n    params = dict(vars(lr_adjuster))\n    params = remove_large_items(params)\n    return {\n        \'name\': name,\n        \'params\': params\n    }\n\n\ndef get_criterion_config(criterion):\n    name = utils.general.get_class_name(criterion)\n    return {\n        \'name\': name\n    }\n\n\ndef get_transforms_config(transforms):\n    data_aug = []\n    for r in transforms.transforms:\n        data_aug.append((str(r.__class__.__name__),\n                         str(r.__dict__)))\n    return data_aug\n\n\ndef get_visualizers_config(visualizers):\n    return [v.classname for v in visualizers]\n\n\ndef get_metrics_config(metrics):\n    return [m.name for m in metrics]\n\n\ndef get_aux_metrics_config(aux_metrics):\n    return [m.__dict__ for m in aux_metrics]\n\n\n'"
experiments/exp_history.py,0,"b'import os\nimport json\nfrom os.path import join\nfrom pathlib import Path\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport utils.files\nimport pandas as pd\nfrom io import StringIO\nmpl.use(\'Agg\')\nplt.style.use(\'bmh\')\n\nimport config as cfg\nimport constants as c\nfrom clients import s3_client, es_client\n\n\n\nclass ExperimentHistory():\n\n    def __init__(self, exp_name, history_dir, metrics=None, aux_metrics=None):\n        self.exp_name = exp_name\n        self.history_dir = history_dir\n        self.train_history_fpath = join(self.history_dir, c.TRAIN+\'.csv\')\n        self.val_history_fpath = join(self.history_dir, c.VAL+\'.csv\')\n        self.aux_metrics_fpath = join(self.history_dir, \'aux_metrics.csv\')\n        self.summary_fpath = join(self.history_dir, exp_name+\'.csv\')\n        self.metrics = metrics\n        self.aux_metrics = aux_metrics\n        self.metrics_history = None\n        self.best_metrics = {}\n\n    def init(self):\n        self.init_metrics()\n        self.init_history_files()\n\n    def resume(self, fetch=False):\n        self.init_metrics()\n        if fetch:\n            self.load_from_external()\n        else:\n            self.load_from_files()\n        self.update_best_metrics()\n\n    def init_history_files(self):\n        Path(self.train_history_fpath).touch()\n        Path(self.val_history_fpath).touch()\n        Path(self.aux_metrics_fpath).touch()\n\n    def init_metrics(self):\n        histories = {}\n        for metric in self.metrics:\n            histories[metric.name] = {\n                c.TRAIN: [],\n                c.VAL: []\n            }\n        for aux_metric in self.aux_metrics:\n            histories[aux_metric.name] = []\n        self.metrics_history = histories\n\n    def save(self, config, s3=cfg.S3_ENABLED, es=cfg.S3_ENABLED):\n        df = pd.DataFrame()\n        for metric in self.metrics:\n            trn_data = self.metrics_history[metric.name][c.TRAIN]\n            val_data = self.metrics_history[metric.name][c.VAL]\n            df[c.TRAIN+\'_\'+metric.name] = trn_data\n            df[c.VAL+\'_\'+metric.name] = val_data\n\n        for aux_metric in self.aux_metrics:\n            df[aux_metric.name] = self.metrics_history[aux_metric.name]\n\n        epochs = pd.Series([i for i in range(1,len(trn_data)+1)])\n        df.insert(0, \'Epoch\', epochs)\n        df.to_csv(self.summary_fpath, index=False)\n\n        if s3:\n            s3_client.upload_experiment_history(self.summary_fpath,\n                                                self.exp_name)\n        if es:\n            es_client.upload_experiment_history(config, self)\n\n    def load_from_files(self):\n        self.load_history_from_file(c.TRAIN)\n        self.load_history_from_file(c.VAL)\n        self.load_aux_metrics_from_file()\n\n    def load_from_external(self):\n        df = self.fetch_dataframe()\n        for metric in self.metrics:\n            for dset in [c.TRAIN, c.VAL]:\n                data = df[dset+\'_\'+metric.name].tolist()\n                self.metrics_history[metric.name][dset] = data\n        for aux_metric in self.aux_metrics:\n            data = df[aux_metric.name].tolist()\n            self.metrics_history[aux_metric.name] = data\n\n    def get_dataframe(self):\n        if os.path.isfile(self.summary_fpath):\n            return self.load_dataframe_from_file()\n        return self.fetch_dataframe()\n\n    def fetch_dataframe(self):\n        csv_str = s3_client.fetch_experiment_history(self.exp_name)\n        df = pd.DataFrame\n        data = StringIO(csv_str)\n        return pd.read_csv(data, sep="","")\n\n    def load_dataframe_from_file(self):\n        df = pd.read_csv(self.summary_fpath, sep=\',\')\n        return df\n\n    def save_metric(self, dset_type, values_dict, epoch):\n        values_arr = []\n        for metric in self.metrics:\n            value = values_dict[metric.name]\n            self.metrics_history[metric.name][dset_type].append(value)\n            values_arr.append(value)\n        fpath = join(self.history_dir, dset_type+\'.csv\')\n        self.append_history_to_file(fpath, values_arr, epoch)\n\n    def load_history_from_file(self, dset_type):\n        fpath = join(self.history_dir, dset_type+\'.csv\')\n        data = np.loadtxt(fpath, delimiter=\',\').reshape(\n                            -1, len(self.metrics)+1)\n        for i in range(len(self.metrics)):\n            self.metrics_history[self.metrics[i].name][dset_type] = data[:,i+1].tolist()\n\n    def append_history_to_file(self, fpath, values, epoch):\n        # Restricts decimals to 6 places!!!\n        formatted_vals = [""{:.6f}"".format(v) for v in values]\n        line = \',\'.join(formatted_vals)\n        with open(fpath, \'a\') as f:\n            f.write(\'{},{}\\n\'.format(epoch, line))\n\n    def update_best_metrics(self):\n        best_metrics = {}\n        for metric in self.metrics:\n            metric_history = self.metrics_history[metric.name][c.VAL]\n            best_epoch, best_value = metric.get_best_epoch(\n                metric_history)\n            best_metrics[metric.name] = {\n                \'epoch\':best_epoch,\n                \'value\':best_value\n            }\n        self.best_metrics = best_metrics\n\n    def load_aux_metrics_from_file(self):\n        data = np.loadtxt(self.aux_metrics_fpath, delimiter=\',\').reshape(\n               -1, len(self.aux_metrics)+1)\n        for i in range(len(self.aux_metrics)):\n            self.metrics_history[self.aux_metrics[i].name] = data[:,i+1].tolist()\n\n    def save_aux_metrics(self, values, epoch):\n        for i in range(len(self.aux_metrics)):\n            self.metrics_history[self.aux_metrics[i].name].append(values[i])\n        self.append_history_to_file(self.aux_metrics_fpath, values, epoch)\n\n    def get_dset_arr(self, dset):\n        data = []\n        for metric in self.metrics:\n            data.append(self.metrics_history[metric.name][dset])\n        epochs = [i+1 for i in range(len(data[0]))]\n        data.insert(0,epochs)\n        arr = np.array(data)\n        return arr.T\n\n    def plot(self, save=False):\n        trn_data = self.get_dset_arr(c.TRAIN)\n        val_data = self.get_dset_arr(c.VAL)\n        metrics_idx = [i+1 for i in range(len(self.metrics))]\n        trn_args = np.split(trn_data, metrics_idx, axis=1)\n        val_args = np.split(val_data, metrics_idx, axis=1)\n\n        metric_fpaths = []\n        for i in range(len(self.metrics)):\n            metric_trn_data = trn_data[:,i+1] #skip epoch\n            metric_val_data = val_data[:,i+1]\n\n            fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n            plt.plot(trn_args[0], metric_trn_data, label=\'Train\')\n            plt.plot(val_args[0], metric_val_data, label=\'Validation\')\n            plt.title(self.metrics[i].name)\n            plt.xlabel(\'Epoch\')\n            plt.ylabel(self.metrics[i].name)\n            plt.legend()\n            ax.set_yscale(\'log\')\n\n            if save:\n                metric_fpath = join(self.history_dir,\n                                    self.metrics[i].name+\'.png\')\n                metric_fpaths.append(metric_fpath)\n                plt.savefig(metric_fpath)\n\n        # Combined View\n        if save:\n            all_metrics_fpath = join(self.history_dir, \'all_metrics.png\')\n            metric_fpaths.append(all_metrics_fpath)\n            os.system(\'convert +append \' + \' \'.join(metric_fpaths))\n\n        plt.show()\n\n    def to_doc(self, config):\n        df = self.get_dataframe()\n        df[c.EXP_ID_FIELD] = config.get_id()\n        df[c.ES_EXP_KEY_FIELD] = df[\'Epoch\'].map(str) + \'_\' + config.get_id()\n        df[\'name\'] = config.get_display_name()\n        df[\'user\'] = config.hardware[\'hostname\']\n        df[\'criterion\'] = config.criterion[\'name\']\n        df[\'optim\'] = config.optimizer[\'name\']\n        df[\'init_lr\'] = config.training[\'initial_lr\']\n        df[\'wd\'] = config.training[\'weight_decay\']\n        df[\'bs\'] = config.training[\'batch_size\']\n        df[\'imsz\'] = config.data[\'img_rescale\']\n        df[\'model_name\'] = config.model_name\n        df[\'lr_adjuster\'] = config.lr_adjuster[\'name\']\n        df[\'threshold\'] = config.training[\'threshold\']\n        return json.loads(df.to_json(orient=\'records\'))\n\n\n    ### TODO\n    def get_history_summary(self, epoch, early_stop_metric):\n        msg = [\'Epoch: %d\' % epoch]\n        for dset in [c.TRAIN, c.VAL]:\n            dset_msg = dset.capitalize() + \' - \'\n            for metric in self.metrics:\n                value = self.metrics_history[metric.name][dset][-1]\n                dset_msg += \'{:s}: {:.3f} \'.format(metric.name, value)\n            msg.append(dset_msg)\n\n        best_epoch = self.best_metrics[early_stop_metric][\'epoch\']\n        best_epoch_value = self.best_metrics[early_stop_metric][\'value\']\n        best_metric_msg = \'Best val {:s}: Epoch {:d} - {:.3f}\'.format(\n            early_stop_metric, best_epoch, best_epoch_value)\n        msg.append(best_metric_msg)\n\n        return \'\\n\'.join(msg)\n\n'"
experiments/exp_utils.py,0,"b'import os\nimport math\nimport shutil\nfrom glob import glob\n\nimport config as cfg\nimport constants as c\nimport numpy as np\nimport utils.general as gen_utils\nimport utils.files\nimport models.utils\nfrom clients import s3_client, es_client\n\n\n\ndef cleanup_experiments(exp_dir):\n    exp_paths = glob(exp_dir+\'/*/\')\n    for path in exp_paths:\n        config_path = os.path.join(path, c.EXPERIMENT_CONFIG_FNAME)\n        if not os.path.isfile(config_path):\n            shutil.rmtree(path)\n\n\ndef delete_experiment(exp_name, exp_dir, local=True, s3=False, es=False):\n    if local:\n        pattern = os.path.join(exp_dir, exp_name)\n        exp_path_list = glob(pattern)\n        if len(exp_path_list) > 0:\n            for p in exp_path_list:\n                print(""Deleting local exp"")\n                shutil.rmtree(p)\n        else:\n            print(""Local copy of exp not found!"")\n    if s3:\n        print(""Deleting S3 document"")\n        s3_client.delete_experiment(exp_name)\n    if es:\n        print(""ES delete not implemented"")\n        es_client.delete_experiment_by_field(field=\'exp_name\', value=exp_name)\n\n\ndef prune(weights_dir, keep_epochs):\n    prune_weights_and_optims(weights_dir, keep_epochs)\n\n\ndef auto_prune(exp, n_bins=5, metric_name=c.LOSS, func=min):\n    best_epochs = get_best_epochs(exp, metric_name, n_bins, func)\n    print(best_epochs)\n    prune(exp.weights_dir, best_epochs)\n\n\ndef get_best_epochs(exp, metric_name, n_bins=5, func=max, end_epoch=10000):\n    metric_arr = exp.history.metrics_history[metric_name][c.VAL][:end_epoch+1]\n    idx, _ = get_best_values_in_bins(metric_arr, n_bins, func)\n    return [i+1 for i in idx] #epoch starts at 1\n\n\ndef get_best_values_in_bins(arr, n_bins, func):\n    bucket_size = math.ceil(len(arr)/n_bins)\n    if isinstance(arr, list):\n        arr = np.array(arr)\n    best_idxfunc = np.argmax if func is max else np.argmin\n    best_valfunc = np.amax if func is max else np.amin\n    best_idx, best_vals = [], []\n    for i in range(0, len(arr), bucket_size):\n        best_idx.append(i+best_idxfunc(arr[i:i+bucket_size]))\n        best_vals.append(best_valfunc(arr[i:i+bucket_size]))\n    return best_idx, best_vals\n\n\ndef prune_weights_and_optims(weights_dir, keep_epochs):\n    matches, fpaths = utils.files.get_matching_files_in_dir(\n        weights_dir, c.WEIGHTS_OPTIM_FNAME_REGEX)\n    print(matches)\n    for i in range(len(matches)):\n        epoch = int(matches[i].group(2))\n        if epoch not in keep_epochs:\n            os.remove(fpaths[i])\n\n\ndef get_weights_fpaths(weights_dir):\n    return utils.files.get_matching_files_in_dir(\n        weights_dir, c.WEIGHTS_FNAME_REGEX)[1]\n\n\ndef get_weight_epochs_from_fpaths(fpaths):\n    epochs = []\n    found_latest = False\n    for path_ in fpaths:\n        ## FIX THIS override\n        if \'latest\' not in path_:\n            epochs.append(int(path_.strip(c.WEIGHTS_EXT).split(\'-\')[-1]))\n        else:\n            found_latest = True\n    epochs.sort()\n    if found_latest:\n        epochs.insert(0,\'latest\')\n    return epochs\n\n\ndef get_weight_fpaths_by_epoch(weights_dir, epochs):\n    matches, fpaths = utils.files.get_matching_files_in_dir(\n        weights_dir, c.WEIGHTS_FNAME_REGEX)\n    weight_fpaths = []\n    for i in range(len(matches)):\n        epoch = int(matches[i].group(1))\n        if epoch in epochs:\n            weight_fpaths.append(fpaths[i])\n    return weight_fpaths\n\n\ndef get_optim_fpaths_by_epoch(optims_dir, keep_epochs):\n    matches, fpaths = utils.files.get_matching_files_in_dir(\n        optims_dir, c.OPTIM_FNAME_REGEX)\n    weight_fpaths = []\n    for i in range(len(matches)):\n        epoch = int(matches[i].group(1))\n        if epoch in keep_epochs:\n            weight_fpaths.append(fpaths[i])\n    return weight_fpaths\n\n\ndef get_weights_fname(epoch):\n    if epoch is None:\n        return c.LATEST_WEIGHTS_FNAME\n    return \'weights-%d%s\' % (epoch, c.WEIGHTS_EXT)\n\n\ndef get_optim_fname(epoch):\n    if epoch is None:\n        return c.LATEST_OPTIM_FNAME\n    return \'optim-%d%s\' % (epoch, c.OPTIM_EXT)\n\n\ndef load_weights_by_exp_and_epoch(model, exp_name, epoch=\'latest\'):\n    if epoch is None or epoch == \'latest\':\n        weights_fname = c.LATEST_WEIGHTS_FNAME\n    else:\n        weights_fname = \'weights-{:d}.th\'.format(epoch)\n    fpath = os.path.join(cfg.PATHS[\'experiments\'], exp_name, \'weights\', weights_fname)\n    models.utils.load_weights(model, fpath)\n\n\ndef download_experiment(dest_dir, exp_name):\n    fpath = os.path.join(dest_dir, exp_name + c.EXP_FILE_EXT)\n    s3_client.download_experiment(fpath, exp_name)\n    utils.files.unzipdir(fpath, dest_dir)\n\n\ndef upload_experiment(parent_dir, exp_name):\n    print((\'Uploading experiment {:s}. \'\n           \'This may take a while..\').format(exp_name))\n    exp_path = os.path.join(parent_dir, exp_name)\n    exp_copy_path = exp_path+\'_copy\'\n    exp_copy_archive_path = os.path.join(exp_copy_path, exp_name)\n    archive_path = exp_path + c.EXP_FILE_EXT\n    shutil.copytree(exp_path, exp_copy_archive_path)\n    print(\'Archiving..\')\n    utils.files.zipdir(exp_copy_path, archive_path)\n    shutil.rmtree(exp_copy_path)\n    print(\'Uploading..\')\n    s3_client.upload_experiment(archive_path, exp_name)\n    os.remove(archive_path)\n    print(\'Upload complete!\')\n\n\ndef generate_display_name(base_name, *args):\n    unique_id = gen_utils.gen_unique_id()\n    return base_name+\'-\'.join(args[0])+\'-id\'+unique_id\n\n\ndef get_id_from_name(exp_name):\n    return exp_name.split(\'-id\')[-1]\n\n\ndef get_transforms_config(transforms):\n    data_aug = []\n    for r in transforms.transforms:\n        data_aug.append((str(r.__class__.__name__),\n                         r.__dict__))\n    return data_aug'"
experiments/experiment.py,0,"b'import os\nimport shutil\nimport time\nimport logging\nfrom os.path import join\n\nimport config as cfg\nimport constants as c\nfrom metrics import metric_builder\nfrom visualizers import vis_utils\nfrom notifications import emailer\nimport utils.logger\nimport training\nimport models.utils\n\nfrom .exp_history import ExperimentHistory\nfrom . import exp_utils\nfrom . import exp_config\n\n\n\n\nclass Experiment():\n    def __init__(self, name, parent_dir):\n        self.name = name\n        self.parent_dir = parent_dir\n        self.root = join(parent_dir, name)\n        self.weights_dir = join(self.root, \'weights\')\n        self.results_dir = join(self.root, \'results\')\n        self.history_dir = join(self.root, \'history\')\n        self.config_fpath = join(self.root, c.EXPERIMENT_CONFIG_FNAME)\n        self.model_fpath = join(self.root, c.MODEL_FNAME)\n        self.optim_fpath = join(self.root, c.OPTIM_FNAME)\n\n        # Initialized/loaded later\n        self.config = None\n        self.logger = None\n        self.history = None\n        self.model = None\n        self.optim = None\n        self.max_patience = None\n        self.early_stop_metric = None\n        self.epoch = 0\n        self.best_epoch = 1\n        self.best_epoch_value = None\n        self.visualizers = []\n        self.metrics = []\n        self.aux_metrics = []\n        self.best_metrics = None\n\n    def init(self, config_dict):\n        self.config = exp_config.create_config_from_dict(config_dict)\n        self.config.progress[\'status\'] = c.INITIALIZED\n        self.metrics = config_dict[\'metrics\']\n        self.aux_metrics = config_dict[\'aux_metrics\']\n        self.model = config_dict[\'model\']\n        self.optim = config_dict[\'optimizer\']\n        self.visualizers = config_dict[\'visualizers\']\n        self.max_patience = self.config.training[\'max_patience\']\n        self.early_stop_metric = self.config.training[\'early_stop_metric\']\n        self.history = ExperimentHistory(self.name, self.history_dir,\n            self.metrics, self.aux_metrics)\n        self.init_dirs()\n        self.history.init()\n        self.init_logger()\n        self.init_visualizers()\n        self.save_components()\n        self.model.logger = self.logger\n\n    def resume(self, epoch=None, verbose=False):\n        self.init_logger()\n        self.log(""Resuming existing experiment"")\n        self.config = exp_config.load_config_from_file(self.config_fpath)\n        self.config.progress[\'status\'] = c.RESUMED\n        self.load(verbose)\n        self.init_visualizers()\n        self.load_components(epoch)\n        self.model.logger = self.logger\n\n    def review(self, download=False, verbose=True):\n        self.init_logger()\n        if download:\n            self.config = exp_config.fetch_external_config(self.name)\n        else:\n            self.config = exp_config.load_config_from_file(self.config_fpath)\n        self.load(verbose=verbose)\n\n    def init_visualizers(self):\n        for v in self.visualizers:\n            v.init(self.config)\n\n    def init_dirs(self):\n        os.makedirs(self.weights_dir)\n        os.makedirs(self.history_dir)\n        os.makedirs(self.results_dir)\n\n    def init_logger(self, log_level=logging.INFO):\n        self.logger = utils.logger.get_logger(\n              self.root, \'logger\', ch_log_level=log_level,\n              fh_log_level=log_level)\n\n    def load(self, verbose=False):\n        self.metrics = metric_builder.get_metrics_from_config(self.config)\n        self.aux_metrics = metric_builder.get_aux_metrics_from_config(self.config)\n        self.visualizers = vis_utils.get_visualizers_from_config(self.config)\n        self.history = ExperimentHistory(self.name, self.history_dir,\n                            self.metrics, self.aux_metrics)\n        self.history.resume()\n        self.max_patience = self.config.training[\'max_patience\']\n        self.early_stop_metric = self.config.training[\'early_stop_metric\']\n        self.epoch = self.config.progress[\'epoch\']\n        self.best_metrics = self.config.progress[\'best_metrics\']\n        self.best_epoch = self.best_metrics[self.early_stop_metric][\'epoch\']\n        self.best_epoch_value = self.best_metrics[self.early_stop_metric][\'value\']\n        if verbose: self.config.summary(self.logger)\n\n    def save(self, s3=cfg.S3_ENABLED, es=cfg.ES_ENABLED):\n        self.config.save(s3, es)\n        self.history.save(self.config, s3, es)\n\n    def upload(self):\n        exp_utils.upload_experiment(self.parent_dir, self.name)\n\n    def load_components(self, epoch):\n        self.model = models.utils.load_model(self.model_fpath)\n        self.optim = training.load_optim(self.optim_fpath)\n        self.load_model_state(epoch)\n        self.load_optim_state(epoch)\n\n    def save_components(self):\n        models.utils.save_model(self.model.cpu(), self.model_fpath)\n        training.save_optim(self.optim, self.optim_fpath)\n        self.model = self.model.cuda()\n\n    def log(self, msg):\n        self.logger.info(msg)\n\n    def update_visualizers(self, msg=None):\n        for v in self.visualizers:\n            v.update(self.config, self.history, msg)\n\n    def update_progress(self):\n        best = self.history.best_metrics\n        self.best_epoch = best[self.early_stop_metric][\'epoch\']\n        self.best_epoch_value = best[self.early_stop_metric][\'value\']\n        self.config.progress[\'epoch\'] = self.epoch\n        self.config.progress[\'best_metrics\'] = best\n\n    def get_weights_fpath(self, epoch=None):\n        fname = exp_utils.get_weights_fname(epoch)\n        return join(self.weights_dir, fname)    \n\n    def get_optim_fpath(self, epoch=None):\n        fname = exp_utils.get_optim_fname(epoch)\n        return join(self.weights_dir, fname)    \n\n    def save_model_state(self, save_now=False):\n        models.utils.save_weights(self.model, self.get_weights_fpath(), \n            epoch=self.epoch, name=self.name)\n        if (save_now or self.epoch\n            % self.config.training[\'save_weights_cadence\'] == 0):\n            fpath = self.get_weights_fpath(self.epoch)\n            shutil.copyfile(self.get_weights_fpath(), fpath)\n\n    def load_model_state(self, epoch=None):\n        fpath = self.get_weights_fpath(epoch)\n        models.utils.load_weights(self.model, fpath)\n\n    def save_optim_state(self, save_now=False):\n        training.save_optim_params(self.optim, self.get_optim_fpath(), \n            epoch=self.epoch, name=self.name)\n        if (save_now or self.epoch\n            % self.config.training[\'save_weights_cadence\'] == 0):\n            fpath = self.get_optim_fpath(self.epoch)\n            shutil.copyfile(self.get_optim_fpath(), fpath)\n\n    def load_optim_state(self, epoch=None):\n        fpath = self.get_optim_fpath(epoch)\n        training.load_optim_params(self.optim, fpath)\n\n    def train(self, trainer, trn_loader, val_loader, n_epochs=None):\n        start_epoch = self.epoch + 1 # Epochs start at 1\n        self.config.progress[\'status\'] = c.IN_PROGRESS\n        self.config.progress[\'status_msg\'] = \'Experiment in progress\'\n\n        if n_epochs is None:\n            end_epoch = self.config.training[\'n_epochs\'] + 1\n        else:\n            end_epoch = start_epoch + n_epochs\n        try:\n            for epoch in range(start_epoch, end_epoch):\n\n                ### Adjust Lr ###\n                lr_params = {\'best_iter\' : self.best_epoch}\n                if trainer.lr_adjuster.iteration_type == \'epoch\':\n                    trainer.lr_adjuster.adjust(self.optim, epoch, lr_params)\n                current_lr = trainer.lr_adjuster.get_learning_rate(self.optim)\n\n                ### Train ###\n                trn_start_time = time.time()\n                trn_metrics = trainer.train(self.model, trn_loader, \n                    self.config.training[\'threshold\'], epoch, self.metrics)\n                trn_msg = training.log_trn_msg(self.logger, trn_start_time,\n                                                trn_metrics, current_lr, epoch)\n\n                ### Test ###\n                val_start_time = time.time()\n                val_metrics = trainer.test(self.model, val_loader, \n                    self.config.training[\'threshold\'], self.metrics)\n                val_msg = training.log_val_msg(self.logger, val_start_time,\n                                                val_metrics, current_lr)\n\n                sys_mem = training.log_memory(\'\')\n\n                ### Save Metrics ###\n                aux_metrics = [current_lr, sys_mem]\n                self.history.save_metric(c.TRAIN, trn_metrics, epoch)\n                self.history.save_metric(c.VAL, val_metrics, epoch)\n                self.history.save_aux_metrics(aux_metrics, epoch)\n                self.history.update_best_metrics()\n\n                ### Checkpoint ###\n                self.epoch = epoch\n                self.update_progress()\n                self.save()\n                self.save_model_state()\n                self.save_optim_state()\n                self.update_visualizers(\'\\n\'.join([trn_msg, val_msg]))\n\n                ### Early Stopping ###\n                if training.early_stop(epoch, self.best_epoch, self.max_patience):\n                    msg = ""Early stopping at epoch %d since no better %s found since epoch %d at %.3f"" % (\n                        epoch, self.early_stop_metric, self.best_epoch, self.best_epoch_value)\n                    self.config.progress[\'status\'] = c.MAX_PATIENCE_EXCEEDED\n                    self.config.progress[\'status_msg\'] = msg\n                    break\n\n        except Exception as e:\n            self.config.progress[\'status\'] = c.FAILED\n            self.config.progress[\'status_msg\'] = e\n            raise Exception(e)\n        finally:\n            if self.config.progress[\'status\'] == c.IN_PROGRESS:\n                self.config.progress[\'status\'] = c.COMPLETED\n                self.config.progress[\'status_msg\'] = \'Experiment Complete!\'\n            if cfg.EMAIL_ENABLED:\n                emailer.send_experiment_status_email(self, cfg.USER_EMAIL)\n            self.log(self.config.progress[\'status_msg\'])\n\n\n'"
metrics/__init__.py,0,b'from .metric_utils import *'
metrics/evaluate.py,0,"b'import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics as scipy_metrics\nimport sklearn\nimport itertools\n\nimport utils\nimport predictions\nimport datasets.metadata as meta\nimport metrics\nimport constants as c\n\n\n\ndef get_evaluate_df(preds, probs, targets, fpaths, label_names):\n    fnames = utils.files.get_fnames_from_fpaths(fpaths)\n    preds_df = pd.DataFrame(preds, columns=label_names, dtype=int)\n    probs_df = pd.DataFrame(np.round(probs, 2),\n                        columns=[\'p_\'+l for l in label_names], dtype=float)\n    targets_df = pd.DataFrame(targets,\n                        columns=[\'t_\'+l for l in label_names], dtype=int)\n    evaluate_df = pd.concat([preds_df, probs_df, targets_df], axis=1)\n    evaluate_df.insert(len(evaluate_df.columns),\'fpath\',\n                    pd.Series(fpaths, index=evaluate_df.index))\n    evaluate_df.insert(0,\'fname\', pd.Series(fnames, index=evaluate_df.index))\n    return evaluate_df\n\n\ndef get_preds_by_target_label(df, label, outcome=\'all\', condensed=False, \n                              shuffle=True):\n    t = \'t_\'+label.lower()\n    p = \'p_\'+label.lower()\n    if outcome == \'all\':\n        label_preds = df[df[t] == 1]\n    elif outcome == \'correct\':\n        label_preds = df[df[t] == df[label]]\n    elif outcome == \'incorrect\':\n        label_preds = df[df[t] != df[label]]\n    elif outcome == \'TP\':\n        label_preds = df[(df[t] == 1) & (df[label] == 1)]\n    elif outcome == \'TN\':\n        label_preds = df[(df[t] == 0) & (df[label] == 0)]\n    elif outcome == \'FP\':\n        label_preds = df[(df[t] == 0) & (df[label] == 1)]\n    elif outcome == \'FN\':\n        label_preds = df[(df[t] == 1) & (df[label] == 0)]\n    if condensed:\n        label_preds = label_preds[[label, p, t, \'fpath\']]\n    if shuffle:\n        return label_preds.sample(frac=1)\n    return label_preds\n\n\ndef get_preds_by_predicted_label(df, label, condensed=False, shuffle=True):\n    t = \'t_\'+label.lower()\n    p = \'p_\'+label.lower()\n    label_preds = df[df[label] == 1][[label, p, t, \'fname\']]\n    if condensed:\n        label_preds = label_preds[[label, p, t, \'fpath\']]\n    if shuffle:\n        return label_preds.sample(frac=1)\n    return label_preds\n\n\ndef get_preds_by_target_and_prob(df, label, targ, p_min=0.0, p_max=1.0,\n                                 shuffle=True):\n    t = \'t_\'+label.lower()\n    p = \'p_\'+label.lower()\n    label_preds = df[(df[t] == targ) & (df[p] >= p_min) & (df[p] <= p_max)]\n    if shuffle:\n        return label_preds.sample(frac=1)\n    return label_preds\n\n\ndef plot_pred_from_df_idx(df, idx, label_names, fs=(5,5)):\n    img_row = df.loc[idx]\n    title = get_img_title_for_plot(df, idx, label_names)\n    img_utils.plot_img_from_fpath(img_row[\'img_path\'], fs=fs, title=title)\n\n\ndef get_img_title_for_plot(df, idx, label_names):\n    img_row = df.loc[idx]\n    pred_headers = label_names\n    prob_headers = [\'p_\'+l for l in label_names]\n    target_headers = [\'t_\'+l for l in label_names]\n    pred_tag = meta.convert_one_hot_to_tags(\n                    np.array(img_row[pred_headers]), label_names)\n    target_tag = meta.convert_one_hot_to_tags(\n                    np.array(img_row[target_headers]), label_names)\n    prob_targ_pct = meta.convert_one_hot_to_tags(\n                    np.array(img_row[target_headers]),\n                    np.array(img_row[prob_headers]).astype(float))\n    prob_pred_pct = meta.convert_one_hot_to_tags(\n                    np.array(img_row[pred_headers]),\n                    np.array(img_row[prob_headers]).astype(float))\n    prob_targ_pct = np.round(prob_targ_pct, 3)\n    prob_pred_pct = np.round(prob_pred_pct, 3)\n    title = (""Trg: "" + str(target_tag) + ""\\nPrb: "" + str(prob_targ_pct) +\n             ""\\nPrd: "" + str(pred_tag) + ""\\nPrb: "" + str(prob_pred_pct) +\n             \'\\n\' + img_row[\'fname\'].split(\'/\')[-1])\n    return title\n\n\ndef plot_predictions(df, label_names, n=6, rows=3, cols=3, fs=(20,16)):\n    plt.figure(figsize=fs)\n    j = 1\n    for idx, row in df.iterrows():\n        plt.subplot(rows, cols, j)\n        plt.imshow(plt.imread(row[\'fpath\']))\n        title = get_img_title_for_plot(df, idx, label_names)\n        plt.title(title)\n        plt.axis(\'off\')\n        j+=1\n        if j > n:\n            break\n\n\ndef plot_confusion_matrix(cm, classes, normalize=False,\n                          title=\'Confusion matrix\', cmap=plt.cm.Blues):\n    plt.figure()\n    plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=""center"", color=""white"" if cm[i, j] > thresh else ""black"")\n\n    plt.tight_layout()\n    plt.ylabel(\'Target\')\n    plt.xlabel(\'Prediction\')\n\n\ndef plot_label_confusion_matrix(df, label):\n    cm = sklearn.metrics.confusion_matrix(df[\'t_\'+label], df[label])\n    title = label.upper()\n    plot_confusion_matrix(cm, {\'not present\':0, \'present\':1}, title=title)\n\n\ndef plot_label_level_cms(df, label_names):\n    for label in label_names:\n        plot_label_confusion_matrix(df, label)\n\n\ndef plot_roc_curve(probs, targets):\n    fpr, tpr, thresholds = scipy_metrics.roc_curve(\n                targets.flatten(), probs.flatten())\n    plt.plot(fpr, tpr)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.title(\'ROC curve\')\n    plt.xlabel(\'False Positive Rate (1 - Specificity)\')\n    plt.ylabel(\'True Positive Rate (Sensitivity)\')\n    plt.grid(True)\n\n\n\n# Multi-label methods\n\ndef get_samples_containing_labels(df, labels, target, sample_by=\'target\',\n                                  shuffle=True):\n    if sample_by == \'target\':\n        prefix = \'t_\'\n    else:\n        prefix = \'\'\n    query = \'\'\n    for label in labels[:-1]:\n        query +=  prefix + label + \' == \'+str(target)+\' & \'\n    query += prefix + labels[-1] + \' == \'+str(target)\n    preds = df.query(query)\n    if shuffle:\n        return preds.sample(frac=1)\n    return preds\n\n\ndef get_summary_metrics_by_labels(df, labels):\n    query = \'\'\n    for label in labels[:-1]:\n        query +=  ""lb == \'""+label+""\' | ""\n    query += ""lb == \'""+labels[-1]+""\'""\n    metrics = df.query(query)\n    return metrics\n\n\ndef get_label_freq_bins(labels, label_names):\n    indices = np.arange(len(label_names))\n    binned_labels = np.bincount(labels, minlength=len(label_names))\n    return np.column_stack([indices, binned_labels])\n\n\ndef graph_summary_metric(summary_df, metric_name, sort_desc=True):\n    plt_df = summary_df.loc[:,[\'lb\',metric_name]][:-2].sort_values(\n                           [metric_name], ascending=sort_desc)\n    plt_df[[\'lb\']]\n    myplot = plt_df.plot(kind=\'barh\',title=metric_name, figsize=(10,6))\n    myplot.set_yticklabels(plt_df.lb.values)\n    myplot.set_xlabel(metric_name)\n    myplot.set_ylabel(\'label\')\n    plt.show()\n\n\ndef get_label_probs(df, label, targ, p_range, bins=15):\n    t = \'t_\'+label.lower()\n    p = \'p_\'+label.lower()\n    label_preds = df[(df[t] == targ) & (df[p] >= p_range[0]) & (df[p] <= p_range[1])]\n    return label_preds[\'p_\'+label]\n\n\ndef plot_label_level_prob_hists(df, label_name, targ=1, pred=None, prob=1.0):\n    for label in label_names:\n        get_label_prob_hist(df, label, targ, pred, prob)\n\n\ndef get_multi_label_summary_metrics(preds, probs, targets, label_names, verbose=True):\n    """"""\n    Currently designed for multi-label classification\n    """"""\n    label_level_accuracy = np.round(metrics.get_accuracy(\n                                        preds, targets),3)\n    img_level_accuracy = np.round(scipy_metrics.accuracy_score(\n                                        targets, preds),3)\n    correct_img_idx, correct_label_idx = np.where(preds==targets)\n    incorrect_img_idx, incorrect_label_idx = np.where(preds!=targets)\n\n    accuracy = metrics.get_accuracy(preds, targets)\n    error = np.sum(preds!=targets) / len(preds.flatten())\n    f2_score = metrics.get_f2_score(preds, targets, \'samples\')\n\n    # TP/FP/TN/FN\n    TP_img_idx, TP_label_idx = np.where((preds==targets) & (preds==1))\n    FP_img_idx, FP_label_idx = np.where((preds!=targets) & (preds==1))\n    TN_img_idx, TN_label_idx = np.where((preds==targets) & (preds==0))\n    FN_img_idx, FN_label_idx = np.where((preds!=targets) & (preds==0))\n    TP,FP,TN,FN = TP_label_idx,FP_label_idx,TN_label_idx,FN_label_idx\n    n_TP = len(TP_label_idx)\n    n_FP = len(FP_label_idx)\n    n_TN = len(TN_label_idx)\n    n_FN = len(FN_label_idx)\n\n    #Labels\n    n_labels = len(preds.flatten())\n    correct_labels_cnt = np.count_nonzero(preds==targets)\n    incorrect_labels_cnt = np.count_nonzero(preds!=targets)\n    assert (correct_labels_cnt+incorrect_labels_cnt == n_labels)\n\n    # Total Positive/True/One Labels\n    total_positive_labels = np.sum(targets)\n    total_positive_labels_by_class = np.sum(targets, axis=0)\n\n    #Images\n    n_imgs = len(preds)\n    image_idx = np.unique(np.where(preds==targets))\n    incorrect_images_idx = np.unique(incorrect_img_idx)\n    mask = np.in1d(image_idx, incorrect_images_idx)\n    correct_images_idx = np.where(~mask)[0]\n    n_imgs_correct = len(correct_images_idx)\n    n_imgs_incorrect = len(incorrect_images_idx)\n    assert (n_imgs_correct+n_imgs_incorrect == n_imgs)\n\n    correct_freq = get_label_freq_bins(correct_label_idx, label_names)\n    incorrect_freq = get_label_freq_bins(incorrect_label_idx, label_names)\n    total_freq = correct_freq[:,1] + incorrect_freq[:,1]\n    total_ones = np.sum(targets, axis=0)\n    percent_ones = np.round(total_ones/total_freq*100,1)\n    assert np.sum(incorrect_freq[:,1]) + np.sum(\n                correct_freq[:,1]) == n_labels\n\n    # Truth\n    tp_freq = get_label_freq_bins(TP_label_idx, label_names)\n    fp_freq = get_label_freq_bins(FP_label_idx, label_names)\n    tn_freq = get_label_freq_bins(TN_label_idx, label_names)\n    fn_freq = get_label_freq_bins(FN_label_idx, label_names)\n    assert np.sum(tp_freq[:,1]) == n_TP\n    assert np.sum(fp_freq[:,1]) == n_FP\n    assert np.sum(tn_freq[:,1]) == n_TN\n    assert np.sum(fn_freq[:,1]) == n_FN\n\n    # Metrics\n    error_pct = np.round(incorrect_freq[:,1] / total_freq * 100,1)\n    weighted_error_pct = np.round(incorrect_freq[:,1]/np.sum(\n        incorrect_freq[:,1]),2)\n    #http://ml-cheatsheet.readthedocs.io/en/latest/glossary.html?highlight=precision\n    total_precision = n_TP/(n_TP+n_FP)\n    total_recall = n_TP/(n_TP+n_FN)\n    precision_by_label = np.round(\n        tp_freq[:,1]/(tp_freq[:,1]+fp_freq[:,1])*100,1)\n    recall_by_label = np.round(\n        tp_freq[:,1]/(tp_freq[:,1]+fn_freq[:,1])*100,1)\n    weighted_fp_pct = np.round(fp_freq/n_FP*100,1)[:,1]\n    weighted_fn_pct = np.round(fn_freq/n_FN*100,1)[:,1]\n    mean_prob_by_label = np.round(np.mean(probs, axis=0),2)\n    median_prob_by_label = np.round(np.median(probs, axis=0),2)\n\n    combined_pivot = np.column_stack([error_pct,\n                                    weighted_error_pct,\n                                    precision_by_label,\n                                    recall_by_label,\n                                    correct_freq[:,1],\n                                    incorrect_freq[:,1],\n                                    tp_freq[:,1],\n                                    tn_freq[:,1],\n                                    fp_freq[:,1],\n                                    fn_freq[:,1],\n                                    weighted_fp_pct,\n                                    weighted_fn_pct,\n                                    total_ones,\n                                    percent_ones,\n                                    mean_prob_by_label,\n                                    median_prob_by_label])\n\n    columns = [\n    \'err_pct\',\'wt_err_pct\', \'precision\',\'recall\',\n    \'correct_labels\',\'incorrect_labels\',\'tp\',\'tn\', \'fp\',\'fn\',\n    \'wt_fp_pct\',\'wt_fn_pct\',\'total_ones\',\'pct_ones\',\'mean_prb\',\'med_prb\'\n    ]\n    int_columns = [\'total_ones\',\'correct_labels\',\'incorrect_labels\',\n        \'tp\',\'tn\',\'fp\',\'fn\'\n    ]\n    float_columns = [\'pct_ones\',\'err_pct\',\'precision\',\'recall\']\n    combined_pivot[np.isnan(combined_pivot)] = 0\n    summary_df = pd.DataFrame(combined_pivot, columns=columns)\n    summary_df.insert(0, \'lb\', pd.Series(\n        label_names, index=summary_df.index))\n    # sum_row = summary_df.sum(numeric_only=True)\n    # sum_row[\'lb\'] = \'sum\'\n    # mean_row = np.round(summary_df.mean(numeric_only=True), 1)\n    # mean_row[\'lb\'] = \'mean\'\n    # summary_df = summary_df.append(sum_row, ignore_index=True)\n    # summary_df = summary_df.append(mean_row, ignore_index=True)\n    summary_df[int_columns] = summary_df[int_columns].astype(int)\n\n    if verbose:\n        print(""Error"", round(error, 4),""\\nAcc"",round(accuracy, 4),\n              ""\\nn_labels"",n_labels,""\\nn_labels_correct"",correct_labels_cnt,\n              ""\\nn_labels_incorrect"",incorrect_labels_cnt,\n              ""\\nn_imgs"",n_imgs, ""\\nn_imgs_correct"", n_imgs_correct,\n              ""\\nn_imgs_incorrect"", n_imgs_incorrect, \'\\ntotal_one_labels\',\n               total_positive_labels, \'\\nlabel_level_accuracy\',\n               label_level_accuracy,\'\\nimg_level_accuracy\',img_level_accuracy)\n\n    return summary_df\n'"
metrics/loss_functions.py,10,"b""import torch\nimport torch.nn.functional as F\nfrom . import metric_utils\n\n\nclass DiceLoss():\n    '''\n    http://campar.in.tum.de/pub/milletari2016Vnet/milletari2016Vnet.pdf\n    https://github.com/faustomilletari/VNet/blob/master/pyLayer.py\n    https://github.com/pytorch/pytorch/issues/1249\n    '''\n    def __init__(self):\n        self.__class__.__name__ = 'Dice'\n\n    def __call__(self, output, target):\n        return 1.0 - get_torch_dice_score(output, target)\n\n\nclass DiceBCELoss():\n    def __init__(self, dice_weight=1.0):\n        self.__class__.__name__ = 'DiceBCE'\n        self.dice_weight = dice_weight\n        self.bce_weight = 1.0 - dice_weight\n\n    def __call__(self, output, target):\n        bce = F.binary_cross_entropy(output, target)\n        dice = 1 - get_torch_dice_score(output, target)\n        return (dice * self.dice_weight) + (bce * self.bce_weight)\n\n\nclass WeightedBCELoss():\n    def __init__(self, weights):\n        self.weights = weights\n        self.__class__.__name__ = 'WeightedBCE'\n\n    def __call__(self, output, target):\n        return F.binary_cross_entropy(output, target, self.weights)\n\n\nclass KnowledgeDistillLoss():\n    def __init__(self, target_weight=0.25):\n        self.__class__.__name__ = 'KnowledgeDistill'\n        self.target_weight = target_weight\n\n    def __call__(self, output, target, soft_target):\n        target_loss = F.binary_cross_entropy(output, target) * self.target_weight\n        soft_target_loss = F.binary_cross_entropy(output, soft_target)\n        return target_loss + soft_target_loss\n\n\nclass HuberLoss():\n    def __init__(self, c=0.5):\n        self.c = c\n        self.__class__.__name__ = 'Huber'\n\n    def __call__(self, output, target):\n        bce = F.binary_cross_entropy(output, target)\n        return self.c**2 * (torch.sqrt(1 + (bce/self.c)**2) - 1)\n\n\nclass SmoothF2Loss():\n    def __init__(self, c=10.0, f2_weight=0.2, bce_weight=1.0):\n        self.__class__.__name__ = 'SmoothF2'\n        self.c = c\n        self.f2_weight = f2_weight\n        self.bce_weight = bce_weight\n\n    def __call__(self, output, target, thresholds):\n        f2 = get_smooth_f2_score(output, target, thresholds, self.c) * self.f2_weight\n        bce = F.binary_cross_entropy(output, target) * self.bce_weight\n        return f2 + bce\n\n\n\n# Helpers / Shared Methods\n\ndef get_torch_dice_score(outputs, targets):\n    eps = 1e-7\n    batch_size = outputs.size()[0]\n    outputs = outputs.view(batch_size, -1)\n    targets = targets.view(batch_size, -1)\n\n    total = torch.sum(outputs, dim=1) + torch.sum(targets, dim=1)\n    intersection = torch.sum(outputs * targets, dim=1).float()\n\n    dice_score = (2.0 * intersection) / (total + eps)\n    return torch.mean(dice_score)\n\n\ndef sigmoid(z, c=1.0):\n    return 1.0 / (1.0 + torch.exp(-c*z))\n\n\ndef get_smooth_f2_score(outputs, targets, thresholds, c=10.0):\n    eps = 1e-9\n    outputs = sigmoid(thresholds - outputs, c).float()\n    tot_out_pos = torch.sum(outputs, dim=1)\n    tot_tar_pos = torch.sum(targets, dim=1)\n    TP = torch.sum(outputs * targets, dim=1)\n\n    P = TP / (tot_out_pos + eps)\n    R = TP / tot_tar_pos + eps\n    F2 = 5.0 * (P*R / (4*P + R))\n    return torch.mean(F2)"""
metrics/metric.py,0,"b""import numpy as np\nimport operator\nimport constants as c\nfrom . import metric_utils\n\n\nclass Metric():\n    def __init__(self, name, minimize=True):\n        self.name = name\n        self.minimize = minimize\n\n    def get_best_epoch(self, values):\n        if self.minimize:\n            idx, value = min(enumerate(values),\n                key=operator.itemgetter(1))\n        else:\n            idx, value = max(enumerate(values),\n                key=operator.itemgetter(1))\n        epoch = idx + 1 # epochs start at 1\n        return epoch, value\n\n    def evaluate(self, loss, preds, probs, targets):\n        pass\n\n    def format(self, value):\n        pass\n\n\nclass AuxiliaryMetric():\n    def __init__(self, name, units):\n        self.name = name\n        self.units = units\n\n\nclass Accuracy(Metric):\n    def __init__(self):\n        super().__init__(c.ACCURACY, minimize=False)\n\n    def evaluate(self, loss, preds, probs, targets):\n        return metric_utils.get_accuracy(preds, targets)\n\n    def format(self, value):\n        return value\n\n\nclass Loss(Metric):\n    def __init__(self):\n        super().__init__(c.LOSS, minimize=True)\n\n    def evaluate(self, loss, preds, probs, targets):\n        return loss\n\n    def format(self, value):\n        return value\n\n\nclass F2Score(Metric):\n    def __init__(self, target_threshold=None):\n        super().__init__(c.F2_SCORE, minimize=False)\n        self.target_threshold = target_threshold  # pseudo soft targets\n\n    def evaluate(self, loss, preds, probs, targets):\n        average = 'samples' if targets.shape[1] > 1 else 'binary'\n        if self.target_threshold is not None:\n            targets = targets > self.target_threshold\n\n        return metric_utils.get_f2_score(preds, targets, average)\n\n    def format(self, value):\n        return value\n\n\nclass DiceScore(Metric):\n    def __init__(self):\n        super().__init__(c.DICE_SCORE, minimize=False)\n\n    def evaluate(self, loss, preds, probs, targets):\n        return metric_utils.get_dice_score(preds, targets)\n\n    def format(self, value):\n        return value\n\n\nclass EnsembleF2(Metric):\n    def __init__(self, ens_probs, threshold):\n        super().__init__('EnsembleF2', minimize=False)\n        self.ens_probs = ens_probs\n        self.threshold = threshold\n\n    def evaluate(self, loss, preds, probs, targets):\n        if probs.shape[0] != self.ens_probs.shape[1]:\n            return .950\n        average = 'samples' if targets.shape[1] > 1 else 'binary'\n        probs = np.expand_dims(probs, 0)\n        joined_probs = np.concatenate([self.ens_probs, probs])\n        joined_probs = np.mean(joined_probs, axis=0)\n        preds = joined_probs > self.threshold\n        return metric_utils.get_f2_score(preds, targets, average)\n\n    def format(self, value):\n        return value"""
metrics/metric_builder.py,0,"b""import constants as c\nfrom . import metric\n\n\nSUPPORTED_METRICS = {\n    c.ACCURACY: metric.Accuracy(),\n    c.LOSS: metric.Loss(),\n    c.F2_SCORE: metric.F2Score(),\n    c.ENSEMBLE_F2: metric.EnsembleF2(None,None),\n    c.DICE_SCORE: metric.DiceScore(),\n}\nSUPPORTED_AUX_METRICS = {}\n\n\ndef get_metric_by_name(name):\n    return SUPPORTED_METRICS[name]\n\n\ndef get_metrics_from_config(config):\n    primary_metrics = []\n    for m in config.metrics:\n        new_metric = get_metric_by_name(m)\n        primary_metrics.append(new_metric)\n    return primary_metrics\n\n\ndef get_aux_metrics_from_config(config):\n    aux_metrics = []\n    for m in config.aux_metrics:\n        new_metric = metric.AuxiliaryMetric(m['name'], m['units'])\n        aux_metrics.append(new_metric)\n    return aux_metrics\n"""
metrics/metric_utils.py,4,"b""import numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import fbeta_score\nfrom sklearn import metrics as scipy_metrics\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport warnings\nimport constants as c\nimport predictions\n\n\ndef get_default_loss(probs, targets, **kwargs):\n    return get_cross_entropy_loss(probs, targets)\n\n\ndef get_default_score(preds, targets, avg='samples', **kwargs):\n    return get_f2_score(preds, targets, avg)\n\n\ndef get_metric_in_blocks(outputs, targets, block_size, metric):\n    sum_ = 0\n    n = 0\n    i = 0\n    while i < len(outputs):\n        out_block = outputs[i:i+block_size]\n        tar_block = targets[i:i+block_size]\n        score = metric(out_block, tar_block)\n        sum_ += len(out_block) * score\n        n += len(out_block)\n        i += block_size\n    return sum_ / n\n\n\ndef get_metrics_in_batches(model, loader, thresholds, metrics):\n    model.eval()\n    n_batches = len(loader)\n    metric_totals = [0 for m in metrics]\n\n    for data in loader:\n        if len(data[1].size()) == 1:\n            targets = data[1].float().view(-1, 1)\n        inputs = Variable(data[0].cuda(async=True))\n        targets = Variable(data[1].cuda(async=True))\n\n        output = model(inputs)\n\n        labels = targets.data.cpu().numpy()\n        probs = output.data.cpu().numpy()\n        preds = predictions.get_predictions(probs, thresholds)\n\n        for i,m in enumerate(metrics):\n            score = m(preds, labels)\n            metric_totals[i] += score\n\n    metric_totals = [m / n_batches for m in metric_totals]\n    return metric_totals\n\n\ndef get_accuracy(preds, targets):\n    preds = preds.flatten() \n    targets = targets.flatten()\n    correct = np.sum(preds==targets)\n    return correct / len(targets)\n\n\ndef get_cross_entropy_loss(probs, targets):\n    return F.binary_cross_entropy(\n              Variable(torch.from_numpy(probs)),\n              Variable(torch.from_numpy(targets).float())).data[0]\n\n\ndef get_recall(preds, targets):\n    return scipy_metrics.recall_score(targets.flatten(), preds.flatten())\n\n\ndef get_precision(preds, targets):\n    return scipy_metrics.precision_score(targets.flatten(), preds.flatten())\n\n\ndef get_roc_score(probs, targets):\n    return scipy_metrics.roc_auc_score(targets.flatten(), probs.flatten())\n\n\ndef get_dice_score(preds, targets):\n    eps = 1e-7\n    batch_size = preds.shape[0]\n    preds = preds.reshape(batch_size, -1)\n    targets = targets.reshape(batch_size, -1)\n\n    total = preds.sum(1) + targets.sum(1) + eps\n    intersection = (preds * targets).astype(float)\n    score = 2. * intersection.sum(1) / total\n    return np.mean(score)\n\n\ndef get_f2_score(y_pred, y_true, average='samples'):\n    y_pred, y_true, = np.array(y_pred), np.array(y_true)\n    return fbeta_score(y_true, y_pred, beta=2, average=average) \n\n\ndef find_f2score_threshold(probs, targets, average='samples',\n                           try_all=True, verbose=False, step=.01):\n    best = 0\n    best_score = -1\n    totry = np.arange(0.1, 0.9, step)\n    for t in totry:\n        score = get_f2_score(probs, targets, t)\n        if score > best_score:\n            best_score = score\n            best = t\n    if verbose is True:\n        print('Best score: ', round(best_score, 5),\n              ' @ threshold =', round(best,4))\n    return round(best,6)\n\n"""
models/__init__.py,0,b''
models/builder.py,1,"b'import torch\nimport torch.nn as nn\nimport torchvision.models\nimport models.utils\n\n\ndef get_fc(in_feat, n_classes, activation=None):\n    layers = [\n        nn.Linear(in_features=in_feat, out_features=n_classes)\n    ]\n    if activation is not None:\n        layers.append(activation)\n    return nn.Sequential(*layers)\n\n\ndef get_classifier(in_feat, n_classes, activation, p=0.5):\n    layers = [\n        nn.BatchNorm1d(num_features=in_feat),\n        nn.Dropout(p),\n        nn.Linear(in_features=in_feat, out_features=n_classes),\n        activation\n    ]\n    return nn.Sequential(*layers)\n\n\ndef get_mlp_classifier(in_feat, out_feat, n_classes, activation, p=0.01, p2=0.5):\n    layers = [\n        nn.BatchNorm1d(num_features=in_feat),\n        nn.Dropout(p),\n        nn.Linear(in_features=in_feat, out_features=out_feat),\n        nn.ReLU(),\n        nn.BatchNorm1d(num_features=out_feat),\n        nn.Dropout(p2),\n        nn.Linear(in_features=out_feat, out_features=n_classes),\n        activation\n    ]\n    return nn.Sequential(*layers)\n\n\ndef cut_model(model, cut):\n    return nn.Sequential(*list(model.children())[:cut])'"
models/layers.py,1,"b'import torch.nn as nn\n\n\ndef conv_relu(in_channels, out_channels, kernel_size=3, stride=1,\n              padding=1, bias=True):\n    return [\n        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n            stride=stride, padding=padding, bias=bias),\n        nn.ReLU(inplace=True),\n    ]\n\ndef conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, \n                 padding=1, bias=False):\n    return [\n        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n        stride=stride, padding=padding, bias=bias),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(inplace=True),\n    ]\n\ndef linear_bn_relu_drop(in_channels, out_channels, dropout=0.5, bias=False):\n    layers = [\n        nn.Linear(in_channels, out_channels, bias=bias),\n        nn.BatchNorm1d(out_channels),\n        nn.ReLU(inplace=True)\n    ]\n    if dropout > 0:\n        layers.append(nn.Dropout(dropout))\n    return layers\n\n\n'"
models/resnet.py,2,"b'import torch\nimport torch.nn as nn\nimport torchvision.models\nimport models.utils\n\n\nclass SimpleResnet(nn.Module):\n    def __init__(self, resnet, classifier):\n        super().__init__()\n        self.__class__.__name__ = ""SimpleResnet""\n        self.resnet = resnet\n        self.classifier = classifier\n\n    def forward(self, x):\n        x = self.resnet(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\nclass ConcatResnet(nn.Module):\n    def __init__(self, resnet, classifier):\n        super().__init__()\n        self.__class__.__name__ = \'ConcatResnet\'\n        self.resnet = resnet\n        self.ap = nn.AdaptiveAvgPool2d((1,1))\n        self.mp = nn.AdaptiveMaxPool2d((1,1))\n        self.classifier = classifier\n\n    def forward(self, x):\n        x = self.resnet(x)\n        x = torch.cat([self.mp(x), self.ap(x)], 1)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    \ndef get_resnet18(pretrained, n_freeze):\n    resnet = torchvision.models.resnet18(pretrained)\n    if n_freeze > 0:\n        models.utils.freeze_layers(resnet, n_freeze)\n    return resnet\n\n\ndef get_resnet34(pretrained, n_freeze):\n    resnet = torchvision.models.resnet34(pretrained)\n    if n_freeze > 0:\n        models.utils.freeze_layers(resnet, n_freeze)\n    return resnet\n\n\ndef get_resnet50(pretrained, n_freeze):\n    resnet = torchvision.models.resnet50(pretrained)\n    if n_freeze > 0:\n        models.utils.freeze_layers(resnet, n_freeze)\n    return resnet\n'"
models/simplenet.py,1,"b'import torch.nn as nn\nimport models.layers as layers\n\n\nclass SimpleNet(nn.Module):\n    def __init__(self, in_feat, n_classes):\n        super().__init__()\n        self.features = nn.Sequential(\n            *layers.conv_bn_relu(in_feat, 8, kernel_size=1, stride=1, padding=0, bias=False),\n            *layers.conv_bn_relu(8, 32, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.MaxPool2d(kernel_size=2, stride=2), #size/2\n            *layers.conv_bn_relu(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.MaxPool2d(kernel_size=2, stride=2), #size/2     \n            *layers.conv_bn_relu(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.MaxPool2d(kernel_size=2, stride=2), #size/2     \n        )\n        self.classifier = nn.Sequential(\n            *layers.linear_bn_relu_drop(64, 512, dropout=0.0, bias=False),\n            nn.Linear(512, n_classes, bias=False),\n            nn.Sigmoid()   \n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x'"
models/unet.py,31,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n\n\ndef make_conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n    return [\n        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n                  stride=stride, padding=padding, bias=False),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(inplace=True),\n    ]\n\n\nclass UNet128(nn.Module):\n    \n    def __init__(self, in_shape, num_classes):\n        super().__init__()\n        in_channels, height, width = in_shape\n\n        #128\n\n        self.down1 = nn.Sequential(\n            *make_conv_bn_relu(in_channels, 16, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(16, 32, kernel_size=1, stride=1, padding=0 ),\n        )\n        #64\n\n        self.down2 = nn.Sequential(\n            *make_conv_bn_relu(32, 64,  kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(64, 128, kernel_size=1, stride=1, padding=0 ),\n        )\n        #32\n\n        self.down3 = nn.Sequential(\n            *make_conv_bn_relu(128, 256, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(256, 512, kernel_size=1, stride=1, padding=0 ),\n        )\n        #16\n\n        self.down4 = nn.Sequential(\n            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(512,512, kernel_size=1, stride=1, padding=0 ),\n        )\n        #8\n\n        self.same = nn.Sequential(\n            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n        )\n\n        #16\n        self.up4 = nn.Sequential(\n            *make_conv_bn_relu(1024,512, kernel_size=1, stride=1, padding=0 ),\n            *make_conv_bn_relu( 512,512, kernel_size=3, stride=1, padding=1 ),\n            #nn.Dropout(p=0.10),\n        )\n        #16\n\n        self.up3 = nn.Sequential(\n            *make_conv_bn_relu(1024,512, kernel_size=1, stride=1, padding=0 ),\n            *make_conv_bn_relu( 512,128, kernel_size=3, stride=1, padding=1 ),\n        )\n        #32\n\n        self.up2 = nn.Sequential(\n            *make_conv_bn_relu(256,128, kernel_size=1, stride=1, padding=0 ),\n            *make_conv_bn_relu(128, 32, kernel_size=3, stride=1, padding=1 ),\n        )\n        #64\n\n        self.up1 = nn.Sequential(\n            *make_conv_bn_relu(64, 64, kernel_size=1, stride=1, padding=0 ),\n            *make_conv_bn_relu(64, 32, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.classify = nn.Conv2d(32, num_classes, kernel_size=1, stride=1, padding=0 )\n\n\n\n    def forward(self, x):\n\n        #128\n\n        down1 = self.down1(x)\n        out   = F.max_pool2d(down1, kernel_size=2, stride=2) #64\n\n        down2 = self.down2(out)\n        out   = F.max_pool2d(down2, kernel_size=2, stride=2) #32\n\n        down3 = self.down3(out)\n        out   = F.max_pool2d(down3, kernel_size=2, stride=2) #16\n\n        down4 = self.down4(out)\n        out   = F.max_pool2d(down4, kernel_size=2, stride=2) # 8\n\n        out   = self.same(out)\n\n        out   = F.upsample(out, scale_factor=2) #16\n        #print(out.size(), down4.size())\n        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n        #print(out.size(), down4.size())\n        out   = torch.cat([down4, out],1)\n        out   = self.up4(out)\n\n        out   = F.upsample(out, scale_factor=2) #32\n        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n        #print(out.size(), down3.size())\n        out   = torch.cat([down3, out],1)\n        out   = self.up3(out)\n\n        out   = F.upsample(out, scale_factor=2) #64\n        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n        out   = torch.cat([down2, out],1)\n        out   = self.up2(out)\n\n        out   = F.upsample(out, scale_factor=2) #128\n        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n        out   = torch.cat([down1, out],1)\n        out   = self.up1(out)\n        out   = self.classify(out)\n        out   = F.sigmoid(out)\n\n        return out\n\n\nclass UNet128Pad(nn.Module):\n    \n    def __init__(self, in_shape, num_classes):\n        super().__init__()\n        in_channels, height, width = in_shape\n\n        #128\n\n        self.down1 = nn.Sequential(\n            *make_conv_bn_relu(in_channels, 16, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(16, 32, kernel_size=1, stride=1, padding=0 ),\n        )\n        #64\n\n        self.down2 = nn.Sequential(\n            *make_conv_bn_relu(32, 64,  kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(64, 128, kernel_size=1, stride=1, padding=0 ),\n        )\n        #32\n\n        self.down3 = nn.Sequential(\n            *make_conv_bn_relu(128, 256, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(256, 512, kernel_size=1, stride=1, padding=0 ),\n        )\n        #16\n\n        self.down4 = nn.Sequential(\n            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(512,512, kernel_size=1, stride=1, padding=0 ),\n        )\n        #8\n\n        self.same = nn.Sequential(\n            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n        )\n\n        #16\n        self.up4 = nn.Sequential(\n            *make_conv_bn_relu(1024,512, kernel_size=1, stride=1, padding=0 ),\n            *make_conv_bn_relu( 512,512, kernel_size=3, stride=1, padding=1 ),\n            #nn.Dropout(p=0.10),\n        )\n        #16\n\n        self.up3 = nn.Sequential(\n            *make_conv_bn_relu(1024,512, kernel_size=1, stride=1, padding=0 ),\n            *make_conv_bn_relu( 512,128, kernel_size=3, stride=1, padding=1 ),\n        )\n        #32\n\n        self.up2 = nn.Sequential(\n            *make_conv_bn_relu(256,128, kernel_size=1, stride=1, padding=0 ),\n            *make_conv_bn_relu(128, 32, kernel_size=3, stride=1, padding=1 ),\n        )\n        #64\n\n        self.up1 = nn.Sequential(\n            *make_conv_bn_relu(64, 64, kernel_size=1, stride=1, padding=0 ),\n            *make_conv_bn_relu(64, 32, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.classify = nn.Conv2d(32, num_classes, kernel_size=1, stride=1, padding=0 )\n\n\n\n    def forward(self, x):\n\n        #128\n\n        down1 = self.down1(x)\n        out   = F.max_pool2d(down1, kernel_size=2, stride=2) #64\n\n        down2 = self.down2(out)\n        out   = F.max_pool2d(down2, kernel_size=2, stride=2) #32\n\n        down3 = self.down3(out)\n        out   = F.max_pool2d(down3, kernel_size=2, stride=2) #16\n\n        down4 = self.down4(out)\n        out   = F.max_pool2d(down4, kernel_size=2, stride=2) # 8\n\n        out   = self.same(out)\n\n        out   = F.upsample(out, scale_factor=2) #16\n        #print(out.size(), down4.size())\n        out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n        #print(out.size(), down4.size())\n        out   = torch.cat([down4, out],1)\n        out   = self.up4(out)\n\n        out   = F.upsample(out, scale_factor=2) #32\n        out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n        #print(out.size(), down3.size())\n        out   = torch.cat([down3, out],1)\n        out   = self.up3(out)\n\n        out   = F.upsample(out, scale_factor=2) #64\n        out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n        out   = torch.cat([down2, out],1)\n        out   = self.up2(out)\n\n        out   = F.upsample(out, scale_factor=2) #128\n        #print(out.size())\n        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n        #print(out.size(), down1.size())\n        out   = torch.cat([down1, out],1)\n        out   = self.up1(out)\n        out   = self.classify(out)\n        out   = F.sigmoid(out)\n\n        return out\n\n\nclass UNet512(nn.Module):\n    \n    def __init__(self, in_shape, num_classes):\n        super().__init__()\n        in_channels, height, width = in_shape\n\n\n        #512\n        self.down0a = nn.Sequential(\n            *make_conv_bn_relu(in_channels, 16, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(16, 16, kernel_size=3, stride=1, padding=1 ),\n        )\n        #256\n\n\n        #UNet512_2 ------------------------------------------------------------------------\n        #256\n        self.down0 = nn.Sequential(\n            *make_conv_bn_relu(16, 32, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(32, 32, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.down1 = nn.Sequential(\n            *make_conv_bn_relu(32, 64, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(64, 64, kernel_size=3, stride=1, padding=1 ),\n        )\n        #64\n\n        self.down2 = nn.Sequential(\n            *make_conv_bn_relu(64,  128, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(128, 128, kernel_size=3, stride=1, padding=1 ),\n        )\n        #32\n\n        self.down3 = nn.Sequential(\n            *make_conv_bn_relu(128, 256, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(256, 256, kernel_size=3, stride=1, padding=1 ),\n        )\n        #16\n\n        self.down4 = nn.Sequential(\n            *make_conv_bn_relu(256,512, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n        )\n        #8\n\n        self.center = nn.Sequential(\n            *make_conv_bn_relu(512, 1024, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(1024,1024, kernel_size=3, stride=1, padding=1 ),\n        )\n\n        #16\n        self.up4 = nn.Sequential(\n            *make_conv_bn_relu(512+1024,512, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     512,512, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     512,512, kernel_size=3, stride=1, padding=1 ),\n            #nn.Dropout(p=0.10),\n        )\n        #16\n\n        self.up3 = nn.Sequential(\n            *make_conv_bn_relu(256+512,256, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    256,256, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    256,256, kernel_size=3, stride=1, padding=1 ),\n        )\n        #32\n\n        self.up2 = nn.Sequential(\n            *make_conv_bn_relu(128+256,128, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    128,128, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    128,128, kernel_size=3, stride=1, padding=1 ),\n        )\n        #64\n\n        self.up1 = nn.Sequential(\n            *make_conv_bn_relu( 64+128,64, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     64,64, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     64,64, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.up0 = nn.Sequential(\n            *make_conv_bn_relu( 32+64,32, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    32,32, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    32,32, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n        #-------------------------------------------------------------------------\n\n        self.up0a = nn.Sequential(\n            *make_conv_bn_relu( 16+32,16, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    16,16, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    16,16, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.classify = nn.Conv2d(16, num_classes, kernel_size=1, stride=1, padding=0 )\n\n\n    def forward(self, x):\n\n        #512\n        down0a = self.down0a(x)\n        out    = F.max_pool2d(down0a, kernel_size=2, stride=2) #64\n\n        down0 = self.down0(out)\n        out   = F.max_pool2d(down0, kernel_size=2, stride=2) #64\n\n        down1 = self.down1(out)\n        out   = F.max_pool2d(down1, kernel_size=2, stride=2) #64\n\n        down2 = self.down2(out)\n        out   = F.max_pool2d(down2, kernel_size=2, stride=2) #32\n\n        down3 = self.down3(out)\n        out   = F.max_pool2d(down3, kernel_size=2, stride=2) #16\n\n        down4 = self.down4(out)\n        out   = F.max_pool2d(down4, kernel_size=2, stride=2) # 8\n\n        out   = self.center(out)\n\n        out   = F.upsample_bilinear(out, scale_factor=2) #16\n        out   = torch.cat([down4, out],1)\n        out   = self.up4(out)\n\n        out   = F.upsample_bilinear(out, scale_factor=2) #32\n        out   = torch.cat([down3, out],1)\n        out   = self.up3(out)\n\n        out   = F.upsample_bilinear(out, scale_factor=2) #64\n        out   = torch.cat([down2, out],1)\n        out   = self.up2(out)\n\n        out   = F.upsample_bilinear(out, scale_factor=2) #128\n        out   = torch.cat([down1, out],1)\n        out   = self.up1(out)\n\n        out   = F.upsample_bilinear(out, scale_factor=2) #128\n        out   = torch.cat([down0, out],1)\n        out   = self.up0(out)\n\n        out   = F.upsample_bilinear(out, scale_factor=2) #256\n        out   = torch.cat([down0a, out],1)\n        out   = self.up0a(out)\n\n        out   = self.classify(out)\n\n        return out\n\n\nclass UNet512_1024(nn.Module):\n    def __init__(self, in_shape, num_classes):\n        super().__init__()\n        in_channels, height, width = in_shape\n\n\n        #512\n        self.down1 = nn.Sequential(\n            *make_conv_bn_relu(in_channels, 16, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(16, 16, kernel_size=3, stride=1, padding=1 ),\n        )\n        #256\n\n\n        #UNet512_2 ------------------------------------------------------------------------\n        #256\n        self.down2 = nn.Sequential(\n            *make_conv_bn_relu(16, 32, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(32, 32, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.down3 = nn.Sequential(\n            *make_conv_bn_relu(32, 64, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(64, 64, kernel_size=3, stride=1, padding=1 ),\n        )\n        #64\n\n        self.down4 = nn.Sequential(\n            *make_conv_bn_relu(64,  128, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(128, 128, kernel_size=3, stride=1, padding=1 ),\n        )\n        #32\n\n        self.down5 = nn.Sequential(\n            *make_conv_bn_relu(128, 256, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(256, 256, kernel_size=3, stride=1, padding=1 ),\n        )\n        #16\n\n        self.down6 = nn.Sequential(\n            *make_conv_bn_relu(256,512, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n        )\n        #8\n\n        self.center = nn.Sequential(\n            *make_conv_bn_relu(512, 1024, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(1024,1024, kernel_size=3, stride=1, padding=1 ),\n        )\n\n        #16\n        self.up6 = nn.Sequential(\n            *make_conv_bn_relu(512+1024,512, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     512,512, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     512,512, kernel_size=3, stride=1, padding=1 ),\n            #nn.Dropout(p=0.10),\n        )\n        #16\n\n        self.up5 = nn.Sequential(\n            *make_conv_bn_relu(256+512,256, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    256,256, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    256,256, kernel_size=3, stride=1, padding=1 ),\n        )\n        #32\n\n        self.up4 = nn.Sequential(\n            *make_conv_bn_relu(128+256,128, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    128,128, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    128,128, kernel_size=3, stride=1, padding=1 ),\n        )\n        #64\n\n        self.up3 = nn.Sequential(\n            *make_conv_bn_relu( 64+128,64, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     64,64, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     64,64, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.up2 = nn.Sequential(\n            *make_conv_bn_relu( 32+64,32, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    32,32, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    32,32, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n        #-------------------------------------------------------------------------\n\n        self.up1 = nn.Sequential(\n            *make_conv_bn_relu( 16+32,16, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    16,16, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(    16,16, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.up0 = nn.Sequential(\n            *make_conv_bn_relu(  3+16,8, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     8,8, kernel_size=3, stride=1, padding=1 ),\n            *make_conv_bn_relu(     8,8, kernel_size=3, stride=1, padding=1 ),\n        )\n        #128\n\n        self.classify = nn.Conv2d(8, num_classes, kernel_size=1, stride=1, padding=0 )\n\n\n    def forward(self, x):\n\n        #512\n        down1 = self.down1(x)\n        out   = F.max_pool2d(down1, kernel_size=2, stride=2) #64\n\n        down2 = self.down2(out)\n        out   = F.max_pool2d(down2, kernel_size=2, stride=2) #64\n\n        down3 = self.down3(out)\n        out   = F.max_pool2d(down3, kernel_size=2, stride=2) #64\n\n        down4 = self.down4(out)\n        out   = F.max_pool2d(down4, kernel_size=2, stride=2) #32\n\n        down5 = self.down5(out)\n        out   = F.max_pool2d(down5, kernel_size=2, stride=2) #16\n\n        down6 = self.down6(out)\n        out   = F.max_pool2d(down6, kernel_size=2, stride=2) # 8\n\n        out   = self.center(out)\n\n        out   = F.upsample(out, scale_factor=2) #16\n        out   = torch.cat([down6, out],1)\n        out   = self.up6(out)\n\n        out   = F.upsample(out, scale_factor=2) #32\n        out   = torch.cat([down5, out],1)\n        out   = self.up5(out)\n\n        out   = F.upsample(out, scale_factor=2) #64\n        out   = torch.cat([down4, out],1)\n        out   = self.up4(out)\n\n        out   = F.upsample(out, scale_factor=2) #128\n        out   = torch.cat([down3, out],1)\n        out   = self.up3(out)\n\n        out   = F.upsample(out, scale_factor=2) #128\n        out   = torch.cat([down2, out],1)\n        out   = self.up2(out)\n\n        out   = F.upsample(out, scale_factor=2) #256\n        out   = torch.cat([down1, out],1)\n        out   = self.up1(out)\n\n        out   = F.upsample(out, scale_factor=2) #1024\n        x     = F.upsample(x,   scale_factor=2)\n        out   = torch.cat([x, out],1)\n        out   = self.up0(out)\n\n\n        out   = self.classify(out)\n\n        return out'"
models/utils.py,8,"b'import torch\n\n\ndef load_model(fpath, cuda=True):\n    if cuda:\n        return torch.load(fpath).cuda()\n    return torch.load(fpath)\n\n\ndef save_model(model, fpath):\n    torch.save(model.cpu(), fpath)\n\n\ndef load_weights(model, fpath):\n    state = torch.load(fpath)\n    model.load_state_dict(state[\'state_dict\'])\n\n\ndef save_weights(model, fpath, epoch=None, name=None):\n    torch.save({\n        \'name\': name,\n        \'epoch\': epoch,\n        \'state_dict\': model.state_dict()\n    }, fpath)\n\n\ndef freeze_layers(model, n_layers):\n    i = 0\n    for child in model.children():\n        if i >= n_layers:\n            break\n        print(i, ""freezing"", child)\n        for param in child.parameters():\n            param.requires_grad = False\n        i += 1\n\n\ndef freeze_nested_layers(model, n_layers):\n    i = 0\n    for child in model.children():\n        for grandchild in child.children():\n            if isinstance(grandchild, torch.nn.modules.container.Sequential):\n                for greatgrand in grandchild.children():\n                    if i >= n_layers:\n                        break\n                    for param in greatgrand.parameters():\n                        param.requires_grad = False\n                    print(i, ""freezing"", greatgrand)\n                    i += 1\n            else:\n                if i >= n_layers:\n                    break\n                for param in grandchild.parameters():\n                    param.requires_grad = False\n                print(i, ""freezing"", grandchild)\n                i += 1\n\n\ndef init_nested_layers(module, conv_init, fc_init):\n    for child in module.children():\n        if len(list(child.children())) > 0:\n            init_nested_layers(child, conv_init, fc_init)\n        else:\n            init_weights(child, conv_init, fc_init)\n\n\ndef init_weights(layer, conv_init, fc_init):\n    if isinstance(layer, torch.nn.Conv2d):\n        print(""init"", layer, ""with"", conv_init)\n        conv_init(layer.weight)\n    elif isinstance(layer, torch.nn.Linear):\n        print(""init"", layer, ""with"", fc_init)\n        fc_init(layer.weight)\n'"
notifications/__init__.py,0,b''
notifications/email_constants.py,0,"b'import config\nimport constants as c\n\n\nWEBSITE_URL = config.KIBANA_URL\nADMIN_EMAIL = config.ADMIN_EMAIL\nUSER_EMAIL = config.USER_EMAIL\nEMAIL_CHARSET = \'UTF-8\'\n\nHEADER=""<html>""\nFOOTER=""</html>""\n\nEXPERIMENT_STATUS_EMAIL_TEMPLATE=""""""\n<p>Hello,</p>\n<p>Your experiment has ended.</p>\n<p><b>Name:</b> %s</p>\n<p><b>Status:</b> %s</p>\n<p><b>Status Msg:</b> %s</p>\n<p><a href=""%s"">View Dashboard</a></p>\n<p><b>Experiment Results:</b></p>\n<p>%s</p>\n<p><b>Experiment Config:</b></p>\n<p>%s</p>\n<p><b>Thanks,<br>\nTeam</p>\n""""""\n\nEXPERIMENT_STATUS_EMAIL_BODY = (\n   HEADER + EXPERIMENT_STATUS_EMAIL_TEMPLATE + FOOTER\n)\n\nEXPERIMENT_STATUS_EMAIL ={\n    \'subject\' : \'New Experiment Results\',\n    \'body\' : EXPERIMENT_STATUS_EMAIL_BODY\n}\n'"
notifications/emailer.py,0,"b""import config\nfrom .email_constants import *\nimport clients.ses_client as ses\nimport utils.general\n\n\ndef send_experiment_status_email(exp, to_email):\n    body = get_experiment_status_template(exp)\n    ses.send_email(EXPERIMENT_STATUS_EMAIL['subject'], body, to_email)\n\n\ndef get_experiment_status_template(exp):\n    status = exp.config.progress['status']\n    msg = exp.config.progress['status_msg']\n    progress = utils.general.dict_to_html_ul(exp.config.progress)\n    config = exp.config.to_html()\n    return EXPERIMENT_STATUS_EMAIL['body'] % (exp.name, status, msg,\n                                              WEBSITE_URL, progress, config)\n"""
predictions/__init__.py,0,b'from .pred_utils import *\nfrom .pred_builder import *\nfrom .pred_constants import *\nfrom .prediction import *'
predictions/pred_builder.py,0,"b'import time\n\nimport utils.files\nimport constants as c\nfrom .pred_constants import *\nfrom .prediction import Prediction\n\n\ndef build_scores(loss, score):\n    return {\n        c.LOSS: loss,\n        c.SCORE: score\n    }\n\n\ndef build_metadata(labels, scores, thresholds, pred_type, dset):\n    return {\n        \'label_names\': labels,\n        \'scores\': scores,\n        \'thresholds\': thresholds,\n        \'pred_type\': pred_type,\n        \'dset\': dset,\n        \'created\': time.strftime(""%m/%d/%Y %H:%M:%S"", time.localtime())\n    }\n\n\ndef build_pred(name, preds, probs, val_preds, val_probs, labels, loss,\n               score, thresholds, w_fpath, exp_name, tta, dset):\n    name = PRED_TYPE + \'-\' + name\n    scores = build_scores(loss, score)\n    metadata = build_metadata(labels, scores, thresholds, PRED_TYPE, dset)\n    metadata[\'w_fpath\'] = w_fpath\n    metadata[\'exp_name\'] = exp_name\n    metadata[\'tta\'] = get_tta_doc(tta)\n    return Prediction(name, metadata, preds=preds, probs=probs,\n                     val_preds=val_preds, val_probs=val_probs)\n\n\ndef get_tta_doc(transforms):\n    data_aug = []\n    for r in transforms.transforms:\n        data_aug.append((str(r.__class__.__name__),\n                         r.__dict__))\n    return str(data_aug)\n'"
predictions/pred_constants.py,0,"b""PRED_TYPE = 'Basic'\nTTA_PRED_TYPE = 'TTA'\nENS_TYPE = 'Ens'\nMEGA_ENS_TYPE = 'MegaEns'\n"""
predictions/pred_utils.py,1,"b'import os\nimport json\nimport time\nimport scipy\nimport numpy as np\nimport pandas as pd\nimport bcolz\nimport random\nfrom io import StringIO\nfrom torch.autograd import Variable\nimport cv2\nimport h5py\n\nimport config as cfg\nimport constants as c\nfrom .pred_constants import *\nfrom . import pred_builder\nimport utils.general\nimport utils.files\nimport models.utils\nimport clients.s3_client as s3\nfrom datasets import data_loaders\nfrom datasets import metadata\nfrom metrics import metric_utils\nfrom experiments import exp_utils\nfrom datasets.datasets import FileDataset\n\n\n\ndef predict_batch(net, inputs):\n    v = Variable(inputs.cuda(), volatile=True)\n    return net(v).data.cpu().numpy()\n\n\ndef get_probabilities(model, loader):\n    model.eval()\n    return np.vstack(predict_batch(model, data[0]) for data in loader)\n\n\ndef get_predictions(probs, thresholds):\n    preds = np.copy(probs)\n    preds[preds >= thresholds] = 1\n    preds[preds < thresholds] = 0\n    return preds.astype(\'uint8\')\n\n\ndef get_mask_predictions(model, loader, thresholds, W=None, H=None):\n    probs = get_probabilities(model, loader)\n    preds = get_predictions(probs, thresholds)\n\n    if W is not None and H is not None:\n        preds = resize_batch(preds, W, H)\n    return preds\n\n\ndef get_mask_probabilities(model, loader, W=None, H=None):\n    model.eval()\n    probs = get_probabilities(model, loader)  \n    if W is not None and H is not None:\n        probs = resize_batch(probs, W, H)\n    return probs\n\n\ndef resize_batch(pred_batch, W=None, H=None):\n    preds = []\n    for i in range(len(pred_batch)):\n        arr = resize_arr(pred_batch[i], W, H)\n        preds.append(arr)\n    return np.stack(preds)\n\n\ndef resize_arr(arr, W, H, mode=cv2.INTER_LINEAR):\n    """"""\n    We assume shape is (C, H, W) like tensor\n    # arr = scipy.misc.imresize(arr.squeeze(), shape, interp=\'bilinear\', mode=None)\n    To shrink: \n        - INTER_AREA\n    To enlarge:\n        - INTER_CUBIC (slow, best quality)\n        - INTER_LINEAR (faster, good quality).\n    """"""\n    arr = arr.transpose(1,2,0)\n    arr = cv2.resize(arr, (W, H), mode)\n    if len(arr.shape) < 3:\n        arr = np.expand_dims(arr, 2)\n    arr = arr.transpose(2,0,1)\n    return arr\n\n\ndef get_targets(loader):\n    targets = None\n    for data in loader:\n        if targets is None:\n            shape = list(data[1].size())\n            shape[0] = 0\n            targets = np.empty(shape)\n        target = data[1]\n        if len(target.size()) == 1:\n            target = target.view(-1,1)\n        target = target.numpy()\n        targets = np.vstack([targets, target])\n    return targets\n\n\ndef save_pred(fpath, pred_arr, meta_dict=None):\n    bc = bcolz.carray(pred_arr, mode=\'w\', rootdir=fpath, \n            cparams=bcolz.cparams(clevel=9, cname=\'lz4\'))\n    if meta_dict is not None:\n        bc.attrs[\'meta\'] = meta_dict\n    bc.flush()\n    return bc\n\n\ndef append_to_pred(bc_arr, pred_arr, meta_dict=None):\n    bc_arr.append(pred_arr)\n    if meta_dict is not None:\n        bc_arr.attrs[\'meta\'] = meta_dict\n    bc_arr.flush()\n    return bc_arr\n\n\ndef append_pred_to_file(fpath, pred_arr, meta_dict=None):\n    bc_arr = bcolz.open(rootdir=fpath)\n    bc_arr.append(pred_arr)\n    if meta_dict is not None:\n        bc_arr.attrs[\'meta\'] = meta_dict\n    bc_arr.flush()\n    return bc_arr\n\n\ndef save_or_append_pred_to_file(fpath, pred_arr, meta_dict=None):\n    if os.path.exists(fpath):\n        return append_pred_to_file(fpath, pred_arr, meta_dict)\n    else:\n        return save_pred(fpath, pred_arr, meta_dict)\n\n\ndef load_pred(fpath, numpy=False):\n    bc = bcolz.open(rootdir=fpath)\n    if numpy:\n        return np.array(bc)\n    return bc\n\n\ndef get_local_pred_fpath(name):\n    return os.path.join(cfg.PATHS[\'predictions\'], name+c.PRED_FILE_EXT)\n\n\ndef list_local_preds(dset=c.TEST, fnames_only=False):\n    pattern = \'_\' + dset + c.PRED_FILE_EXT\n    _, fpaths = utils.files.get_matching_files_in_dir(\n        cfg.PATHS[\'predictions\'], pattern)\n    if fnames_only:\n        return [utils.files.get_fname_from_fpath(f) for f in fpaths]\n    return fpaths\n\n\ndef ensemble_with_method(arr, method):\n    if method == c.MEAN:\n        return np.mean(arr, axis=0)\n    elif method == c.GMEAN:\n        return scipy.stats.mstats.gmean(arr, axis=0)\n    elif method == c.VOTE:\n        return scipy.stats.mode(arr, axis=0)[0][0]\n    raise Exception(""Operation not found"")\n\n\ndef get_prediction_fpath(basename, dset):\n    fname = \'{:s}_{:s}\'.format(basename, dset + c.PRED_FILE_EXT)\n    return os.path.join(cfg.PATHS[\'predictions\'], fname)\n\n\n\n# refactor notebook helpers\n\ndef build_pred_df_from_dir(dir_path):\n    fpaths, _ = utils.files.get_paths_to_files(dir_path)\n    summary = []\n    for f in fpaths:\n        if c.PRED_FILE_EXT in f:\n            pred = load_pred(f)\n            summary_dict = build_pred_summary_dict(pred)\n            summary.append(summary_dict)\n    return pd.DataFrame(summary)\n\n\ndef get_pred_summary_from_dicts(dicts):\n    summary = []\n    for d in dicts:\n        summary.append(build_pred_summary_dict(d))\n    return pd.DataFrame(summary)\n\n\ndef build_pred_summary_dict(pred):\n    meta = pred[\'meta\']\n    return {\n        \'id\': pred.get_id(),\n        \'name\': pred.name,\n        \'pred_type\': pred.pred_type,\n        \'dset\': meta[\'dset\'],\n        c.LOSS : meta[\'scores\'][c.LOSS],\n        c.SCORE : meta[\'scores\'][c.SCORE],\n        \'threshold\' : meta[\'thresholds\'],\n        \'created\': meta[\'created\'],\n        \'fpath\': get_local_pred_fpath(pred.name)\n    }\n\n\ndef get_clean_tta_str(tta):\n    STRIP = [\n    \'torchvision.transforms.\',\n    \'torchsample.tensor_transforms.\',\n    \'torchsample.affine_transforms.\',\n    \'torchsample.transforms.tensor_transforms.\',\n    \'torchsample.transforms.affine_transforms.\',\n    \'object at \',\n    \'<\', \'>\',\n    ]\n    str_ = str(tta.transforms)\n    for s in STRIP:\n        str_ = str_.replace(s,\'\')\n    return str_'"
predictions/prediction.py,0,"b""import os\nimport copy\n\nimport config as cfg\nimport constants as c\nfrom clients import s3_client\nfrom clients import es_client\nfrom .pred_constants import *\n\n\n\nclass Prediction:\n    def __init__(self, fpath, metadata):\n        self.fpath = fpath\n        self.meta = metadata\n\n    @property\n    def name(self):\n        return os.path.basename(self.fpath).rstrip(\n            c.PRED_FILE_EXT)\n\n    @property\n    def id(self):\n        return self.name.split('-id')[-1]\n\n    @property\n    def display_name(self):\n        return self.name.split('-id')[0]\n\n    def to_dict(self):\n        return copy.deepcopy(self.__dict__)\n\n    def to_doc(self):\n        dict_ = self.to_dict()\n        dict_['key'] = self.id\n        dict_['display_name'] = self.display_name()\n        return dict_\n\n    def save(self, s3=cfg.S3_ENABLED, es=cfg.ES_ENABLED):\n        if s3: \n            s3_client.upload_prediction(self.fpath, self.name())\n        if es: \n            es_client.upload_prediction(self)\n"""
submissions/__init__.py,0,b'from .utils import *\n'
submissions/utils.py,0,"b""import os\nimport numpy as np\nimport time\nimport predictions\nimport datasets.metadata as meta\nimport training\nimport constants as c\nimport config as cfg\nimport utils.files\n\n\n\ndef write_preds_to_file(fpath, ids, preds, header):\n    ids = np.array(ids).T\n    preds = np.array(preds).T\n    submission = np.stack([ids, preds], axis=1)\n    np.savetxt(fpath, submission, fmt='%s', delimiter=',',\n               header=header, comments='')\n\n\ndef make_tags_submission(sub_fpath, ids, preds, label_names, header):\n    tags = meta.get_tags_from_preds(preds, label_names)\n    write_preds_to_file(sub_fpath, ids, tags, header)\n\n\ndef make_preds_submission(sub_fpath, ids, preds, header):\n    preds = [' '.join(map(str, p.tolist())) for p in preds]\n    write_preds_to_file(sub_fpath, ids, preds, header)\n\n\ndef get_sub_path_from_pred_path(pred_fpath):\n    sub_fname = os.path.basename(pred_fpath).rstrip(\n        c.PRED_FILE_EXT) + c.SUBMISSION_FILE_EXT\n    sub_fpath = os.path.join(cfg.PATHS['submissions'], sub_fname)\n    return sub_fpath\n\n\ndef run_length_encode(mask_image):\n    pixels = mask_image.flatten()\n    # We avoid issues with '1' at the start or end (at the corners of \n    # the original image) by setting those pixels to '0' explicitly.\n    # We do not expect these to be non-zero for an accurate mask, \n    # so this should not harm the score.\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] = runs[1::2] - runs[:-1:2]\n    return rle_to_string(runs)\n\n\ndef rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\n\ndef run_length_decode(rel, H, W, fill_value=1):\n    mask = np.zeros((H*W),np.uint8)\n    rel  = np.array([int(s) for s in rel.split(' ')]).reshape(-1,2)\n    for r in rel:\n        start = r[0]\n        end   = start +r[1]\n        mask[start:end]=fill_value\n    mask = mask.reshape(H,W)\n    return mask\n\n\n\n\n\ndef submit_to_kaggle(fpath, competition, username, password):\n    pass\n    \n\n\n# Refactor classification stuff from amazon..\n\ndef make_multi_label_submission(preds, img_paths, label_names, out_path,\n                    name, file_ext='.csv.gz'):\n    pred_tags = convert_preds_to_tags(preds, label_names)\n    fnames = utils.files.get_fnames_from_fpaths(img_paths)\n    fnames = np.array(fnames)\n    fnames = np.expand_dims(fnames, 1)\n    submission_fpath = os.path.join(out_path, name+'-submission'+file_ext)\n    write_preds_to_file(fnames, pred_tags, submission_fpath)\n\n\ndef convert_preds_to_tags(preds, tags_list):\n    tag_list = []\n    for pred in preds:\n        tags = ' '.join(meta.convert_one_hot_to_tags(pred, tags_list))\n        tag_list.append(tags)\n    tag_arr = np.array(tag_list)\n    return np.expand_dims(tag_arr,1)"""
torchsample/__init__.py,0,b'\nfrom __future__ import absolute_import\n\nfrom .version import __version__\n\nfrom .datasets import *\nfrom .samplers import *\n\n#from .callbacks import *\n#from .constraints import *\n#from .regularizers import *\n\n#from . import functions\n#from . import transforms\nfrom . import modules\n'
torchsample/callbacks.py,0,"b'""""""\nSuperModule Callbacks\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nfrom collections import OrderedDict\nfrom collections import Iterable\nimport warnings\n\nimport os\nimport csv\nimport time\nfrom tempfile import NamedTemporaryFile\nimport shutil\nimport math\nimport datetime\n\nfrom tqdm import tqdm\n\nimport torch as th\n\n\ndef _get_current_time():\n    return datetime.datetime.now().strftime(""%B %d, %Y - %I:%M%p"")\n\nclass CallbackContainer(object):\n    """"""\n    Container holding a list of callbacks.\n    """"""\n    def __init__(self, callbacks=None, queue_length=10):\n        callbacks = callbacks or []\n        self.callbacks = [c for c in callbacks]\n        self.queue_length = queue_length\n\n    def append(self, callback):\n        self.callbacks.append(callback)\n\n    def set_params(self, params):\n        for callback in self.callbacks:\n            callback.set_params(params)\n\n    def set_trainer(self, trainer):\n        self.trainer = trainer\n        for callback in self.callbacks:\n            callback.set_trainer(trainer)\n\n    def on_epoch_begin(self, epoch, logs=None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_begin(epoch, logs)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_end(epoch, logs)\n\n    def on_batch_begin(self, batch, logs=None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_batch_begin(batch, logs)\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_batch_end(batch, logs)\n\n    def on_train_begin(self, logs=None):\n        logs = logs or {}\n        logs[\'start_time\'] = _get_current_time()\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)\n\n    def on_train_end(self, logs=None):\n        logs = logs or {}\n        logs[\'final_loss\'] = self.trainer.history.epoch_losses[-1],\n        logs[\'best_loss\'] = min(self.trainer.history.epoch_losses),\n        logs[\'stop_time\'] = _get_current_time()\n        for callback in self.callbacks:\n            callback.on_train_end(logs)\n\n\nclass Callback(object):\n    """"""\n    Abstract base class used to build new callbacks.\n    """"""\n\n    def __init__(self):\n        pass\n\n    def set_params(self, params):\n        self.params = params\n\n    def set_trainer(self, model):\n        self.trainer = model\n\n    def on_epoch_begin(self, epoch, logs=None):\n        pass\n\n    def on_epoch_end(self, epoch, logs=None):\n        pass\n\n    def on_batch_begin(self, batch, logs=None):\n        pass\n\n    def on_batch_end(self, batch, logs=None):\n        pass\n\n    def on_train_begin(self, logs=None):\n        pass\n\n    def on_train_end(self, logs=None):\n        pass\n\n\nclass TQDM(Callback):\n\n    def __init__(self):\n        """"""\n        TQDM Progress Bar callback\n\n        This callback is automatically applied to \n        every SuperModule if verbose > 0\n        """"""\n        self.progbar = None\n        super(TQDM, self).__init__()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        # make sure the dbconnection gets closed\n        if self.progbar is not None:\n            self.progbar.close()\n\n    def on_train_begin(self, logs):\n        self.train_logs = logs\n\n    def on_epoch_begin(self, epoch, logs=None):\n        try:\n            self.progbar = tqdm(total=self.train_logs[\'num_batches\'],\n                                unit=\' batches\')\n            self.progbar.set_description(\'Epoch %i/%i\' % \n                            (epoch+1, self.train_logs[\'num_epoch\']))\n        except:\n            pass\n\n    def on_epoch_end(self, epoch, logs=None):\n        log_data = {key: \'%.04f\' % value for key, value in self.trainer.history.batch_metrics.items()}\n        for k, v in logs.items():\n            if k.endswith(\'metric\'):\n                log_data[k.split(\'_metric\')[0]] = \'%.02f\' % v\n        self.progbar.set_postfix(log_data)\n        self.progbar.update()\n        self.progbar.close()\n\n    def on_batch_begin(self, batch, logs=None):\n        self.progbar.update(1)\n\n    def on_batch_end(self, batch, logs=None):\n        log_data = {key: \'%.04f\' % value for key, value in self.trainer.history.batch_metrics.items()}\n        for k, v in logs.items():\n            if k.endswith(\'metric\'):\n                log_data[k.split(\'_metric\')[0]] = \'%.02f\' % v\n        self.progbar.set_postfix(log_data)\n\n\nclass History(Callback):\n    """"""\n    Callback that records events into a `History` object.\n\n    This callback is automatically applied to\n    every SuperModule.\n    """"""\n    def __init__(self, model):\n        super(History, self).__init__()\n        self.samples_seen = 0.\n        self.trainer = model\n\n    def on_train_begin(self, logs=None):\n        self.epoch_metrics = {\n            \'loss\': []\n        }\n        self.batch_size = logs[\'batch_size\']\n        self.has_val_data = logs[\'has_val_data\']\n        self.has_regularizers = logs[\'has_regularizers\']\n        if self.has_val_data:\n            self.epoch_metrics[\'val_loss\'] = []\n        if self.has_regularizers:\n            self.epoch_metrics[\'reg_loss\'] = []\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.batch_metrics = {\n            \'loss\': 0.\n        }\n        if self.has_regularizers:\n            self.batch_metrics[\'reg_loss\'] = 0.\n        self.samples_seen = 0.\n\n    def on_epoch_end(self, epoch, logs=None):\n        for k in self.batch_metrics:\n            self.epoch_metrics[k].append(self.batch_metrics[k])\n\n    def on_batch_end(self, batch, logs=None):\n        for k in self.batch_metrics:\n            self.batch_metrics[k] = (self.samples_seen*self.batch_metrics[k] + logs[k]*self.batch_size) / (self.samples_seen+self.batch_size)\n        self.samples_seen += self.batch_size\n\n    def __getitem__(self, name):\n        return self.epoch_metrics[name]\n\n    def __repr__(self):\n        return str(self.epoch_metrics)\n\n    def __str__(self):\n        return str(self.epoch_metrics)\n\n\nclass ModelCheckpoint(Callback):\n    """"""\n    Model Checkpoint to save model weights during training\n\n    save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'arch\': args.arch,\n                \'state_dict\': model.state_dict(),\n                \'best_prec1\': best_prec1,\n                \'optimizer\' : optimizer.state_dict(),\n            }\n    def save_checkpoint(state, is_best, filename=\'checkpoint.pth.tar\'):\n        th.save(state, filename)\n        if is_best:\n            shutil.copyfile(filename, \'model_best.pth.tar\')\n\n    """"""\n\n    def __init__(self,\n                 directory, \n                 filename=\'ckpt.pth.tar\', \n                 monitor=\'val_loss\', \n                 save_best_only=False, \n                 save_weights_only=True,\n                 max_save=-1,\n                 verbose=0):\n        """"""\n        Model Checkpoint to save model weights during training\n\n        Arguments\n        ---------\n        file : string\n            file to which model will be saved.\n            It can be written \'filename_{epoch}_{loss}\' and those\n            values will be filled in before saving.\n        monitor : string in {\'val_loss\', \'loss\'}\n            whether to monitor train or val loss\n        save_best_only : boolean\n            whether to only save if monitored value has improved\n        save_weight_only : boolean \n            whether to save entire model or just weights\n            NOTE: only `True` is supported at the moment\n        max_save : integer > 0 or -1\n            the max number of models to save. Older model checkpoints\n            will be overwritten if necessary. Set equal to -1 to have\n            no limit\n        verbose : integer in {0, 1}\n            verbosity\n        """"""\n        if directory.startswith(\'~\'):\n            directory = os.path.expanduser(directory)\n        self.directory = directory\n        self.filename = filename\n        self.file = os.path.join(self.directory, self.filename)\n        self.monitor = monitor\n        self.save_best_only = save_best_only\n        self.save_weights_only = save_weights_only\n        self.max_save = max_save\n        self.verbose = verbose\n\n        if self.max_save > 0:\n            self.old_files = []\n\n        # mode = \'min\' only supported\n        self.best_loss = math.inf\n        super(ModelCheckpoint, self).__init__()\n\n    def save_checkpoint(self, state, is_best=False):\n        th.save(state, self.file)\n        if is_best:\n            shutil.copyfile(self.file, \'model_best.pth.tar\')\n\n    def on_epoch_end(self, epoch, logs=None):\n        file = self.file.format(epoch=\'%03i\'%(epoch+1), \n                                loss=\'%0.4f\'%logs[self.monitor])\n        if self.save_best_only:\n            current_loss = logs.get(self.monitor)\n            if current_loss is None:\n                pass\n            else:\n                if current_loss < self.best_loss:\n                    if self.verbose > 0:\n                        print(\'\\nEpoch %i: improved from %0.4f to %0.4f saving model to %s\' % \n                              (epoch+1, self.best_loss, current_loss, file))\n                    self.best_loss = current_loss\n                    #if self.save_weights_only:\n                    self.trainer.save_state_dict(file)\n                    #else:\n                    #    self.save_checkpoint({\n                    #            \'epoch\': epoch + 1,\n                    #            #\'arch\': args.arch,\n                    #            \'state_dict\': self.trainer.state_dict(),\n                    #            #\'best_prec1\': best_prec1,\n                    #            \'optimizer\' : self.trainer.optimizer.state_dict(),\n                    #            #\'loss\':{},\n                    #            #\'regularizers\':{},\n                    #            #\'constraints\':{},\n                    #            #\'initializers\':{},\n                    #            #\'metrics\':{},\n                    #            #\'val_loss\':{}\n                    #        })\n                    if self.max_save > 0:\n                        if len(self.old_files) == self.max_save:\n                            try:\n                                os.remove(self.old_files[0])\n                            except:\n                                pass\n                            self.old_files = self.old_files[1:]\n                        self.old_files.append(file)\n        else:\n            if self.verbose > 0:\n                print(\'\\nEpoch %i: saving model to %s\' % (epoch+1, file))\n            self.trainer.save_state_dict(file)\n            if self.max_save > 0:\n                if len(self.old_files) == self.max_save:\n                    try:\n                        os.remove(self.old_files[0])\n                    except:\n                        pass\n                    self.old_files = self.old_files[1:]\n                self.old_files.append(file)\n\n\nclass EarlyStopping(Callback):\n    """"""\n    Early Stopping to terminate training early under certain conditions\n    """"""\n\n    def __init__(self, \n                 monitor=\'val_loss\',\n                 min_delta=0,\n                 patience=5):\n        """"""\n        EarlyStopping callback to exit the training loop if training or\n        validation loss does not improve by a certain amount for a certain\n        number of epochs\n\n        Arguments\n        ---------\n        monitor : string in {\'val_loss\', \'loss\'}\n            whether to monitor train or val loss\n        min_delta : float\n            minimum change in monitored value to qualify as improvement.\n            This number should be positive.\n        patience : integer\n            number of epochs to wait for improvment before terminating.\n            the counter be reset after each improvment\n        """"""\n        self.monitor = monitor\n        self.min_delta = min_delta\n        self.patience = patience\n        self.wait = 0\n        self.best_loss = 1e-15\n        self.stopped_epoch = 0\n        super(EarlyStopping, self).__init__()\n\n    def on_train_begin(self, logs=None):\n        self.wait = 0\n        self.best_loss = 1e15\n\n    def on_epoch_end(self, epoch, logs=None):\n        current_loss = logs.get(self.monitor)\n        if current_loss is None:\n            pass\n        else:\n            if (current_loss - self.best_loss) < -self.min_delta:\n                self.best_loss = current_loss\n                self.wait = 1\n            else:\n                if self.wait >= self.patience:\n                    self.stopped_epoch = epoch + 1\n                    self.trainer._stop_training = True\n                self.wait += 1\n\n    def on_train_end(self, logs):\n        if self.stopped_epoch > 0:\n            print(\'\\nTerminated Training for Early Stopping at Epoch %04i\' % \n                (self.stopped_epoch))\n\n\nclass LRScheduler(Callback):\n    """"""\n    Schedule the learning rate according to some function of the \n    current epoch index, current learning rate, and current train/val loss.\n    """"""\n\n    def __init__(self, schedule):\n        """"""\n        LearningRateScheduler callback to adapt the learning rate\n        according to some function\n\n        Arguments\n        ---------\n        schedule : callable\n            should return a number of learning rates equal to the number\n            of optimizer.param_groups. It should take the epoch index and\n            **kwargs (or logs) as argument. **kwargs (or logs) will return\n            the epoch logs such as mean training and validation loss from\n            the epoch\n        """"""\n        if isinstance(schedule, dict):\n            schedule = self.schedule_from_dict\n            self.schedule_dict = schedule\n            if any([k < 1.0 for k in schedule.keys()]):\n                self.fractional_bounds = False\n            else:\n                self.fractional_bounds = True\n        self.schedule = schedule\n        super(LRScheduler, self).__init__()\n\n    def schedule_from_dict(self, epoch, logs=None):\n        for epoch_bound, learn_rate in self.schedule_dict.items():\n            # epoch_bound is in units of ""epochs""\n            if not self.fractional_bounds:\n                if epoch_bound < epoch:\n                    return learn_rate\n            # epoch_bound is in units of ""cumulative percent of epochs""\n            else:\n                if epoch <= epoch_bound*logs[\'num_epoch\']:\n                    return learn_rate\n        warnings.warn(\'Check the keys in the schedule dict.. Returning last value\')\n        return learn_rate\n\n    def on_epoch_begin(self, epoch, logs=None):\n        current_lrs = [p[\'lr\'] for p in self.trainer._optimizer.param_groups]\n        lr_list = self.schedule(epoch, current_lrs, **logs)\n        if not isinstance(lr_list, list):\n            lr_list = [lr_list]\n\n        for param_group, lr_change in zip(self.trainer._optimizer.param_groups, lr_list):\n            param_group[\'lr\'] = lr_change\n\n\nclass ReduceLROnPlateau(Callback):\n    """"""\n    Reduce the learning rate if the train or validation loss plateaus\n    """"""\n\n    def __init__(self,\n                 monitor=\'val_loss\', \n                 factor=0.1, \n                 patience=10,\n                 epsilon=0, \n                 cooldown=0, \n                 min_lr=0,\n                 verbose=0):\n        """"""\n        Reduce the learning rate if the train or validation loss plateaus\n\n        Arguments\n        ---------\n        monitor : string in {\'loss\', \'val_loss\'}\n            which metric to monitor\n        factor : floar\n            factor to decrease learning rate by\n        patience : integer\n            number of epochs to wait for loss improvement before reducing lr\n        epsilon : float\n            how much improvement must be made to reset patience\n        cooldown : integer \n            number of epochs to cooldown after a lr reduction\n        min_lr : float\n            minimum value to ever let the learning rate decrease to\n        verbose : integer\n            whether to print reduction to console\n        """"""\n        self.monitor = monitor\n        if factor >= 1.0:\n            raise ValueError(\'ReduceLROnPlateau does not support a factor >= 1.0.\')\n        self.factor = factor\n        self.min_lr = min_lr\n        self.epsilon = epsilon\n        self.patience = patience\n        self.verbose = verbose\n        self.cooldown = cooldown\n        self.cooldown_counter = 0\n        self.wait = 0\n        self.best_loss = 1e15\n        self._reset()\n        super(ReduceLROnPlateau, self).__init__()\n\n    def _reset(self):\n        """"""\n        Reset the wait and cooldown counters\n        """"""\n        self.monitor_op = lambda a, b: (a - b) < -self.epsilon\n        self.best_loss = 1e15\n        self.cooldown_counter = 0\n        self.wait = 0\n\n    def on_train_begin(self, logs=None):\n        self._reset()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs[\'lr\'] = [p[\'lr\'] for p in self.trainer._optimizer.param_groups]\n        current_loss = logs.get(self.monitor)\n        if current_loss is None:\n            pass\n        else:\n            # if in cooldown phase\n            if self.cooldown_counter > 0: \n                self.cooldown_counter -= 1\n                self.wait = 0\n            # if loss improved, grab new loss and reset wait counter\n            if self.monitor_op(current_loss, self.best_loss):\n                self.best_loss = current_loss\n                self.wait = 0\n            # loss didnt improve, and not in cooldown phase\n            elif not (self.cooldown_counter > 0):\n                if self.wait >= self.patience:\n                    for p in self.trainer._optimizer.param_groups:\n                        old_lr = p[\'lr\']\n                        if old_lr > self.min_lr + 1e-4:\n                            new_lr = old_lr * self.factor\n                            new_lr = max(new_lr, self.min_lr)\n                            if self.verbose > 0:\n                                print(\'\\nEpoch %05d: reducing lr from %0.3f to %0.3f\' % \n                                    (epoch, old_lr, new_lr))\n                            p[\'lr\'] = new_lr\n                            self.cooldown_counter = self.cooldown\n                            self.wait = 0\n                self.wait += 1\n\n\nclass CSVLogger(Callback):\n    """"""\n    Logs epoch-level metrics to a CSV file\n    """"""\n\n    def __init__(self, \n                 file, \n                 separator=\',\', \n                 append=False):\n        """"""\n        Logs epoch-level metrics to a CSV file\n\n        Arguments\n        ---------\n        file : string\n            path to csv file\n        separator : string\n            delimiter for file\n        apped : boolean\n            whether to append result to existing file or make new file\n        """"""\n        self.file = file\n        self.sep = separator\n        self.append = append\n        self.writer = None\n        self.keys = None\n        self.append_header = True\n        super(CSVLogger, self).__init__()\n\n    def on_train_begin(self, logs=None):\n        if self.append:\n            if os.path.exists(self.file):\n                with open(self.file) as f:\n                    self.append_header = not bool(len(f.readline()))\n            self.csv_file = open(self.file, \'a\')\n        else:\n            self.csv_file = open(self.file, \'w\')\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        RK = {\'num_batches\', \'num_epoch\'}\n\n        def handle_value(k):\n            is_zero_dim_tensor = isinstance(k, th.Tensor) and k.dim() == 0\n            if isinstance(k, Iterable) and not is_zero_dim_tensor:\n                return \'""[%s]""\' % (\', \'.join(map(str, k)))\n            else:\n                return k\n\n        if not self.writer:\n            self.keys = sorted(logs.keys())\n\n            class CustomDialect(csv.excel):\n                delimiter = self.sep\n\n            self.writer = csv.DictWriter(self.csv_file,\n                    fieldnames=[\'epoch\'] + [k for k in self.keys if k not in RK], \n                    dialect=CustomDialect)\n            if self.append_header:\n                self.writer.writeheader()\n\n        row_dict = OrderedDict({\'epoch\': epoch})\n        row_dict.update((key, handle_value(logs[key])) for key in self.keys if key not in RK)\n        self.writer.writerow(row_dict)\n        self.csv_file.flush()\n\n    def on_train_end(self, logs=None):\n        self.csv_file.close()\n        self.writer = None\n\n\nclass ExperimentLogger(Callback):\n\n    def __init__(self,\n                 directory,\n                 filename=\'Experiment_Logger.csv\',\n                 save_prefix=\'Model_\', \n                 separator=\',\', \n                 append=True):\n\n        self.directory = directory\n        self.filename = filename\n        self.file = os.path.join(self.directory, self.filename)\n        self.save_prefix = save_prefix\n        self.sep = separator\n        self.append = append\n        self.writer = None\n        self.keys = None\n        self.append_header = True\n        super(ExperimentLogger, self).__init__()\n\n    def on_train_begin(self, logs=None):\n        if self.append:\n            open_type = \'a\'\n        else:\n            open_type = \'w\'\n\n        # if append is True, find whether the file already has header\n        num_lines = 0\n        if self.append:\n            if os.path.exists(self.file):\n                with open(self.file) as f:\n                    for num_lines, l in enumerate(f):\n                        pass\n                    # if header exists, DONT append header again\n                with open(self.file) as f:\n                    self.append_header = not bool(len(f.readline()))\n                \n        model_idx = num_lines\n        REJECT_KEYS={\'has_validation_data\'}\n        MODEL_NAME = self.save_prefix + str(model_idx) # figure out how to get model name\n        self.row_dict = OrderedDict({\'model\': MODEL_NAME})\n        self.keys = sorted(logs.keys())\n        for k in self.keys:\n            if k not in REJECT_KEYS:\n                self.row_dict[k] = logs[k]\n\n        class CustomDialect(csv.excel):\n            delimiter = self.sep\n\n        with open(self.file, open_type) as csv_file:\n            writer = csv.DictWriter(csv_file,\n                fieldnames=[\'model\'] + [k for k in self.keys if k not in REJECT_KEYS], \n                dialect=CustomDialect)\n            if self.append_header:\n                writer.writeheader()\n\n            writer.writerow(self.row_dict)\n            csv_file.flush()\n\n    def on_train_end(self, logs=None):\n        REJECT_KEYS={\'has_validation_data\'}\n        row_dict = self.row_dict\n\n        class CustomDialect(csv.excel):\n            delimiter = self.sep\n        self.keys = self.keys\n        temp_file = NamedTemporaryFile(delete=False, mode=\'w\')\n        with open(self.file, \'r\') as csv_file, temp_file:\n            reader = csv.DictReader(csv_file,\n                fieldnames=[\'model\'] + [k for k in self.keys if k not in REJECT_KEYS], \n                dialect=CustomDialect)\n            writer = csv.DictWriter(temp_file,\n                fieldnames=[\'model\'] + [k for k in self.keys if k not in REJECT_KEYS], \n                dialect=CustomDialect)\n            for row_idx, row in enumerate(reader):\n                if row_idx == 0:\n                    # re-write header with on_train_end\'s metrics\n                    pass\n                if row[\'model\'] == self.row_dict[\'model\']:\n                    writer.writerow(row_dict)\n                else:\n                    writer.writerow(row)\n        shutil.move(temp_file.name, self.file)   \n\n\nclass LambdaCallback(Callback):\n    """"""\n    Callback for creating simple, custom callbacks on-the-fly.\n    """"""\n    def __init__(self,\n                 on_epoch_begin=None,\n                 on_epoch_end=None,\n                 on_batch_begin=None,\n                 on_batch_end=None,\n                 on_train_begin=None,\n                 on_train_end=None,\n                 **kwargs):\n        super(LambdaCallback, self).__init__()\n        self.__dict__.update(kwargs)\n        if on_epoch_begin is not None:\n            self.on_epoch_begin = on_epoch_begin\n        else:\n            self.on_epoch_begin = lambda epoch, logs: None\n        if on_epoch_end is not None:\n            self.on_epoch_end = on_epoch_end\n        else:\n            self.on_epoch_end = lambda epoch, logs: None\n        if on_batch_begin is not None:\n            self.on_batch_begin = on_batch_begin\n        else:\n            self.on_batch_begin = lambda batch, logs: None\n        if on_batch_end is not None:\n            self.on_batch_end = on_batch_end\n        else:\n            self.on_batch_end = lambda batch, logs: None\n        if on_train_begin is not None:\n            self.on_train_begin = on_train_begin\n        else:\n            self.on_train_begin = lambda logs: None\n        if on_train_end is not None:\n            self.on_train_end = on_train_end\n        else:\n            self.on_train_end = lambda logs: None\n\n'"
torchsample/constraints.py,0,"b'\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nfrom fnmatch import fnmatch\n\nimport torch as th\nfrom .callbacks import Callback\n\n\nclass ConstraintContainer(object):\n\n    def __init__(self, constraints):\n        self.constraints = constraints\n        self.batch_constraints = [c for c in self.constraints if c.unit.upper() == \'BATCH\']\n        self.epoch_constraints = [c for c in self.constraints if c.unit.upper() == \'EPOCH\']\n\n    def register_constraints(self, model):\n        """"""\n        Grab pointers to the weights which will be modified by constraints so\n        that we dont have to search through the entire network using `apply`\n        each time\n        """"""\n        # get batch constraint pointers\n        self._batch_c_ptrs = {}\n        for c_idx, constraint in enumerate(self.batch_constraints):\n            self._batch_c_ptrs[c_idx] = []\n            for name, module in model.named_modules():\n                if fnmatch(name, constraint.module_filter) and hasattr(module, \'weight\'):\n                    self._batch_c_ptrs[c_idx].append(module)\n\n        # get epoch constraint pointers\n        self._epoch_c_ptrs = {}\n        for c_idx, constraint in enumerate(self.epoch_constraints):\n            self._epoch_c_ptrs[c_idx] = []\n            for name, module in model.named_modules():\n                if fnmatch(name, constraint.module_filter) and hasattr(module, \'weight\'):\n                    self._epoch_c_ptrs[c_idx].append(module)\n\n    def apply_batch_constraints(self, batch_idx):\n        for c_idx, modules in self._batch_c_ptrs.items():\n            if (batch_idx+1) % self.constraints[c_idx].frequency == 0:\n                for module in modules:\n                    self.constraints[c_idx](module)\n\n    def apply_epoch_constraints(self, epoch_idx):\n        for c_idx, modules in self._epoch_c_ptrs.items():\n            if (epoch_idx+1) % self.constraints[c_idx].frequency == 0:\n                for module in modules:\n                    self.constraints[c_idx](module)\n\n\nclass ConstraintCallback(Callback):\n\n    def __init__(self, container):\n        self.container = container\n\n    def on_batch_end(self, batch_idx, logs):\n        self.container.apply_batch_constraints(batch_idx)\n\n    def on_epoch_end(self, epoch_idx, logs):\n        self.container.apply_epoch_constraints(epoch_idx)\n\n\nclass Constraint(object):\n\n    def __call__(self):\n        raise NotImplementedError(\'Subclass much implement this method\')\n\n\nclass UnitNorm(Constraint):\n    """"""\n    UnitNorm constraint.\n\n    Constraints the weights to have column-wise unit norm\n    """"""\n    def __init__(self, \n                 frequency=1, \n                 unit=\'batch\',\n                 module_filter=\'*\'):\n\n        self.frequency = frequency\n        self.unit = unit\n        self.module_filter = module_filter\n\n    def __call__(self, module):\n        w = module.weight.data\n        module.weight.data = w.div(th.norm(w,2,0))\n\n\nclass MaxNorm(Constraint):\n    """"""\n    MaxNorm weight constraint.\n\n    Constrains the weights incident to each hidden unit\n    to have a norm less than or equal to a desired value.\n\n    Any hidden unit vector with a norm less than the max norm\n    constaint will not be altered.\n    """"""\n\n    def __init__(self, \n                 value, \n                 axis=0, \n                 frequency=1, \n                 unit=\'batch\',\n                 module_filter=\'*\'):\n        self.value = float(value)\n        self.axis = axis\n\n        self.frequency = frequency\n        self.unit = unit\n        self.module_filter = module_filter\n\n    def __call__(self, module):\n        w = module.weight.data\n        module.weight.data = th.renorm(w, 2, self.axis, self.value)\n\n\nclass NonNeg(Constraint):\n    """"""\n    Constrains the weights to be non-negative.\n    """"""\n    def __init__(self, \n                 frequency=1, \n                 unit=\'batch\',\n                 module_filter=\'*\'):\n        self.frequency = frequency\n        self.unit = unit\n        self.module_filter = module_filter\n\n    def __call__(self, module):\n        w = module.weight.data\n        module.weight.data = w.gt(0).float().mul(w)\n\n\n\n\n\n\n'"
torchsample/datasets.py,0,"b'\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport os\nimport fnmatch\n\nimport numpy as np\nimport pandas as pd\nimport PIL.Image as Image\nimport nibabel\n\nimport torch as th\n\nfrom . import transforms\n\n\nclass BaseDataset(object):\n    """"""An abstract class representing a Dataset.\n\n    All other datasets should subclass it. All subclasses should override\n    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n    supporting integer indexing in range from 0 to len(self) exclusive.\n    """"""\n\n    def __len__(self):\n        return len(self.inputs) if not isinstance(self.inputs, (tuple,list)) else len(self.inputs[0])\n\n    def add_input_transform(self, transform, add_to_front=True, idx=None):\n        if idx is None:\n            idx = np.arange(len(self.num_inputs))\n        elif not is_tuple_or_list(idx):\n            idx = [idx]\n\n        if add_to_front:\n            for i in idx:\n                self.input_transform[i] = transforms.Compose([transform, self.input_transform[i]])\n        else:\n            for i in idx:\n                self.input_transform[i] = transforms.Compose([self.input_transform[i], transform])\n\n    def add_target_transform(self, transform, add_to_front=True, idx=None):\n        if idx is None:\n            idx = np.arange(len(self.num_targets))\n        elif not is_tuple_or_list(idx):\n            idx = [idx]\n\n        if add_to_front:\n            for i in idx:\n                self.target_transform[i] = transforms.Compose([transform, self.target_transform[i]])\n        else:\n            for i in idx:\n                self.target_transform[i] = transforms.Compose([self.target_transform[i], transform])\n\n    def add_co_transform(self, transform, add_to_front=True, idx=None):\n        if idx is None:\n            idx = np.arange(len(self.min_inputs_or_targets))\n        elif not is_tuple_or_list(idx):\n            idx = [idx]\n\n        if add_to_front:\n            for i in idx:\n                self.co_transform[i] = transforms.Compose([transform, self.co_transform[i]])\n        else:\n            for i in idx:\n                self.co_transform[i] = transforms.Compose([self.co_transform[i], transform])\n\n    def load(self, num_samples=None, load_range=None):\n        """"""\n        Load all data or a subset of the data into actual memory.\n        For instance, if the inputs are paths to image files, then this\n        function will actually load those images.\n    \n        Arguments\n        ---------\n        num_samples : integer (optional)\n            number of samples to load. if None, will load all\n        load_range : numpy array of integers (optional)\n            the index range of images to load\n            e.g. np.arange(4) loads the first 4 inputs+targets\n        """"""\n        def _parse_shape(x):\n            if isinstance(x, (list,tuple)):\n                return (len(x),)\n            elif isinstance(x, th.Tensor):\n                return x.size()\n            else:\n                return (1,)\n\n        if num_samples is None and load_range is None:\n            num_samples = len(self)\n            load_range = np.arange(num_samples)\n        elif num_samples is None and load_range is not None:\n            num_samples = len(load_range)\n        elif num_samples is not None and load_range is None:\n            load_range = np.arange(num_samples)\n\n\n        if self.has_target:\n            for enum_idx, sample_idx in enumerate(load_range):\n                input_sample, target_sample = self.__getitem__(sample_idx)\n\n                if enum_idx == 0:\n                    if self.num_inputs == 1:\n                        _shape = [len(load_range)] + list(_parse_shape(input_sample))\n                        inputs = np.empty(_shape)\n                    else:\n                        inputs = []\n                        for i in range(self.num_inputs):\n                            _shape = [len(load_range)] + list(_parse_shape(input_sample[i]))\n                            inputs.append(np.empty(_shape))\n                        #inputs = [np.empty((len(load_range), *_parse_shape(input_sample[i]))) for i in range(self.num_inputs)]\n\n                    if self.num_targets == 1:\n                        _shape = [len(load_range)] + list(_parse_shape(target_sample))\n                        targets = np.empty(_shape)\n                        #targets = np.empty((len(load_range), *_parse_shape(target_sample)))\n                    else:\n                        targets = []\n                        for i in range(self.num_targets):\n                            _shape = [len(load_range)] + list(_parse_shape(target_sample[i]))\n                            targets.append(np.empty(_shape))\n                        #targets = [np.empty((len(load_range), *_parse_shape(target_sample[i]))) for i in range(self.num_targets)]\n\n                if self.num_inputs == 1:\n                    inputs[enum_idx] = input_sample\n                else:\n                    for i in range(self.num_inputs):\n                        inputs[i][enum_idx] = input_sample[i]\n\n                if self.num_targets == 1:\n                    targets[enum_idx] = target_sample\n                else:\n                    for i in range(self.num_targets):\n                        targets[i][enum_idx] = target_sample[i]\n\n            return inputs, targets\n        else:\n            for enum_idx, sample_idx in enumerate(load_range):\n                input_sample = self.__getitem__(sample_idx)\n\n                if enum_idx == 0:\n                    if self.num_inputs == 1:\n                        _shape = [len(load_range)] + list(_parse_shape(input_sample))\n                        inputs = np.empty(_shape)\n                        #inputs = np.empty((len(load_range), *_parse_shape(input_sample)))\n                    else:\n                        inputs = []\n                        for i in range(self.num_inputs):\n                            _shape = [len(load_range)] + list(_parse_shape(input_sample[i]))\n                            inputs.append(np.empty(_shape))\n                        #inputs = [np.empty((len(load_range), *_parse_shape(input_sample[i]))) for i in range(self.num_inputs)]\n\n                if self.num_inputs == 1:\n                    inputs[enum_idx] = input_sample\n                else:\n                    for i in range(self.num_inputs):\n                        inputs[i][enum_idx] = input_sample[i]\n\n            return inputs\n\n    def fit_transforms(self):\n        """"""\n        Make a single pass through the entire dataset in order to fit \n        any parameters of the transforms which require the entire dataset.\n        e.g. StandardScaler() requires mean and std for the entire dataset.\n\n        If you dont call this fit function, then transforms which require properties\n        of the entire dataset will just work at the batch level.\n        e.g. StandardScaler() will normalize each batch by the specific batch mean/std\n        """"""\n        it_fit = hasattr(self.input_transform, \'update_fit\')\n        tt_fit = hasattr(self.target_transform, \'update_fit\')\n        ct_fit = hasattr(self.co_transform, \'update_fit\')\n        if it_fit or tt_fit or ct_fit:\n            for sample_idx in range(len(self)):\n                if hasattr(self, \'input_loader\'):\n                    x = self.input_loader(self.inputs[sample_idx])\n                else:\n                    x = self.inputs[sample_idx]\n                if it_fit:\n                    self.input_transform.update_fit(x)\n                if self.has_target:\n                    if hasattr(self, \'target_loader\'):\n                        y = self.target_loader(self.targets[sample_idx])\n                    else:\n                        y = self.targets[sample_idx]\n                if tt_fit:\n                    self.target_transform.update_fit(y)\n                if ct_fit:\n                    self.co_transform.update_fit(x,y)\n\n\ndef _process_array_argument(x):\n    if not is_tuple_or_list(x):\n        x = [x]\n    return x\n\n\nclass TensorDataset(BaseDataset):\n\n    def __init__(self,\n                 inputs,\n                 targets=None,\n                 input_transform=None, \n                 target_transform=None,\n                 co_transform=None):\n        """"""\n        Dataset class for loading in-memory data.\n\n        Arguments\n        ---------\n        inputs: numpy array\n\n        targets : numpy array\n\n        input_transform : class with __call__ function implemented\n            transform to apply to input sample individually\n\n        target_transform : class with __call__ function implemented\n            transform to apply to target sample individually\n\n        co_transform : class with __call__ function implemented\n            transform to apply to both input and target sample simultaneously\n\n        """"""\n        self.inputs = _process_array_argument(inputs)\n        self.num_inputs = len(self.inputs)\n        self.input_return_processor = _return_first_element_of_list if self.num_inputs==1 else _pass_through\n\n        if targets is None:\n            self.has_target = False\n        else:\n            self.targets = _process_array_argument(targets)\n            self.num_targets = len(self.targets)\n            self.target_return_processor = _return_first_element_of_list if self.num_targets==1 else _pass_through\n            self.min_inputs_or_targets = min(self.num_inputs, self.num_targets)\n            self.has_target = True            \n        \n        self.input_transform = _process_transform_argument(input_transform, self.num_inputs)\n        if self.has_target:\n            self.target_transform = _process_transform_argument(target_transform, self.num_targets)\n            self.co_transform = _process_co_transform_argument(co_transform, self.num_inputs, self.num_targets)\n\n    def __getitem__(self, index):\n        """"""\n        Index the dataset and return the input + target\n        """"""\n        input_sample = [self.input_transform[i](self.inputs[i][index]) for i in range(self.num_inputs)]\n\n        if self.has_target:\n            target_sample = [self.target_transform[i](self.targets[i][index]) for i in range(self.num_targets)]\n            #for i in range(self.min_inputs_or_targets):\n            #    input_sample[i], target_sample[i] = self.co_transform[i](input_sample[i], target_sample[i])\n\n            return self.input_return_processor(input_sample), self.target_return_processor(target_sample)\n        else:\n            return self.input_return_processor(input_sample)\n\n\ndef default_file_reader(x):\n    def pil_loader(path):\n        return Image.open(path).convert(\'RGB\')\n    def npy_loader(path):\n        return np.load(path)\n    def nifti_loader(path):\n        return nibabel.load(path).get_data()\n    if isinstance(x, str):\n        if x.endswith(\'.npy\'):\n            x = npy_loader(x)\n        elif x.endsiwth(\'.nii.gz\'):\n            x = nifti_loader(x)\n        else:\n            try:\n                x = pil_loader(x)\n            except:\n                raise ValueError(\'File Format is not supported\')\n    #else:\n        #raise ValueError(\'x should be string, but got %s\' % type(x))\n    return x\n\ndef is_tuple_or_list(x):\n    return isinstance(x, (tuple,list))\n\ndef _process_transform_argument(tform, num_inputs):\n    tform = tform if tform is not None else _pass_through\n    if is_tuple_or_list(tform):\n        if len(tform) != num_inputs:\n            raise Exception(\'If transform is list, must provide one transform for each input\')\n        tform = [t if t is not None else _pass_through for t in tform]\n    else:\n        tform = [tform] * num_inputs\n    return tform\n\ndef _process_co_transform_argument(tform, num_inputs, num_targets):\n    tform = tform if tform is not None else _multi_arg_pass_through\n    if is_tuple_or_list(tform):\n        if len(tform) != num_inputs:\n            raise Exception(\'If transform is list, must provide one transform for each input\')\n        tform = [t if t is not None else _multi_arg_pass_through for t in tform]\n    else:\n        tform = [tform] * min(num_inputs, num_targets)\n    return tform\n\ndef _process_csv_argument(csv):\n    if isinstance(csv, str):\n        df = pd.read_csv(csv)\n    elif isinstance(csv, pd.DataFrame):\n        df = csv\n    else:\n        raise ValueError(\'csv argument must be string or dataframe\')\n    return df\n\ndef _select_dataframe_columns(df, cols):\n    if isinstance(cols[0], str):\n        inputs = df.loc[:,cols].values\n    elif isinstance(cols[0], int):\n        inputs = df.iloc[:,cols].values\n    else:\n        raise ValueError(\'Provided columns should be string column names or integer column indices\')\n    return inputs\n\ndef _process_cols_argument(cols):\n    if isinstance(cols, tuple):\n        cols = list(cols)\n    return cols\n\ndef _return_first_element_of_list(x):\n    return x[0]\n\ndef _pass_through(x):\n    return x\n\ndef _multi_arg_pass_through(*x):\n    return x\n\n\nclass CSVDataset(BaseDataset):\n\n    def __init__(self,\n                 csv,\n                 input_cols=[0],\n                 target_cols=[1],\n                 input_transform=None,\n                 target_transform=None,\n                 co_transform=None):\n        """"""\n        Initialize a Dataset from a CSV file/dataframe. This does NOT\n        actually load the data into memory if the CSV contains filepaths.\n\n        Arguments\n        ---------\n        csv : string or pandas.DataFrame\n            if string, should be a path to a .csv file which\n            can be loaded as a pandas dataframe\n        \n        input_cols : int/list of ints, or string/list of strings\n            which columns to use as input arrays.\n            If int(s), should be column indicies\n            If str(s), should be column names \n        \n        target_cols : int/list of ints, or string/list of strings\n            which columns to use as input arrays.\n            If int(s), should be column indicies\n            If str(s), should be column names \n\n        input_transform : class which implements a __call__ method\n            tranform(s) to apply to inputs during runtime loading\n\n        target_tranform : class which implements a __call__ method\n            transform(s) to apply to targets during runtime loading\n\n        co_transform : class which implements a __call__ method\n            transform(s) to apply to both inputs and targets simultaneously\n            during runtime loading\n        """"""\n        self.input_cols = _process_cols_argument(input_cols)\n        self.target_cols = _process_cols_argument(target_cols)\n        \n        self.df = _process_csv_argument(csv)\n\n        self.inputs = _select_dataframe_columns(self.df, input_cols)\n        self.num_inputs = self.inputs.shape[1]\n        self.input_return_processor = _return_first_element_of_list if self.num_inputs==1 else _pass_through\n\n        if target_cols is None:\n            self.num_targets = 0\n            self.has_target = False\n        else:\n            self.targets = _select_dataframe_columns(self.df, target_cols)\n            self.num_targets = self.targets.shape[1]\n            self.target_return_processor = _return_first_element_of_list if self.num_targets==1 else _pass_through\n            self.has_target = True\n            self.min_inputs_or_targets = min(self.num_inputs, self.num_targets)\n\n        self.input_loader = default_file_reader\n        self.target_loader = default_file_reader\n        \n        self.input_transform = _process_transform_argument(input_transform, self.num_inputs)\n        if self.has_target:\n            self.target_transform = _process_transform_argument(target_transform, self.num_targets)\n            self.co_transform = _process_co_transform_argument(co_transform, self.num_inputs, self.num_targets)\n\n    def __getitem__(self, index):\n        """"""\n        Index the dataset and return the input + target\n        """"""\n        input_sample = [self.input_transform[i](self.input_loader(self.inputs[index, i])) for i in range(self.num_inputs)]\n\n        if self.has_target:\n            target_sample = [self.target_transform[i](self.target_loader(self.targets[index, i])) for i in range(self.num_targets)]\n            for i in range(self.min_inputs_or_targets):\n                input_sample[i], input_sample[i] = self.co_transform[i](input_sample[i], target_sample[i])\n\n            return self.input_return_processor(input_sample), self.target_return_processor(target_sample)\n        else:\n            return self.input_return_processor(input_sample)\n\n    def split_by_column(self, col):\n        """"""\n        Split this dataset object into multiple dataset objects based on \n        the unique factors of the given column. The number of returned\n        datasets will be equal to the number of unique values in the given\n        column. The transforms and original dataframe will all be transferred\n        to the new datasets \n\n        Useful for splitting a dataset into train/val/test datasets.\n\n        Arguments\n        ---------\n        col : integer or string\n            which column to split the data on. \n            if int, should be column index\n            if str, should be column name\n\n        Returns\n        -------\n        - list of new datasets with transforms copied\n        """"""\n        if isinstance(col, int):\n            split_vals = self.df.iloc[:,col].values.flatten()\n\n            new_df_list = []\n            for unique_split_val in np.unique(split_vals):\n                new_df = self.df[:][self.df.iloc[:,col]==unique_split_val]\n                new_df_list.append(new_df)\n        elif isinstance(col, str):\n            split_vals = self.df.loc[:,col].values.flatten()\n\n            new_df_list = []\n            for unique_split_val in np.unique(split_vals):\n                new_df = self.df[:][self.df.loc[:,col]==unique_split_val]\n                new_df_list.append(new_df)\n        else:\n            raise ValueError(\'col argument not valid - must be column name or index\')\n\n        new_datasets = []\n        for new_df in new_df_list:\n            new_dataset = self.copy(new_df)\n            new_datasets.append(new_dataset)\n\n        return new_datasets\n\n    def train_test_split(self, train_size):\n        if train_size < 1:\n            train_size = int(train_size * len(self))\n\n        train_indices = np.random.choice(len(self), train_size, replace=False)\n        test_indices = np.array([i for i in range(len(self)) if i not in train_indices])\n        \n        train_df = self.df.iloc[train_indices,:]\n        test_df = self.df.iloc[test_indices,:]\n\n        train_dataset = self.copy(train_df)\n        test_dataset = self.copy(test_df)\n\n        return train_dataset, test_dataset\n\n    def copy(self, df=None):\n        if df is None:\n            df = self.df\n\n        return CSVDataset(df,\n                          input_cols=self.input_cols, \n                          target_cols=self.target_cols,\n                          input_transform=self.input_transform,\n                          target_transform=self.target_transform,\n                          co_transform=self.co_transform)\n\n\nclass FolderDataset(BaseDataset):\n\n    def __init__(self, \n                 root,\n                 class_mode=\'label\',\n                 input_regex=\'*\',\n                 target_regex=None,\n                 input_transform=None, \n                 target_transform=None,\n                 co_transform=None, \n                 input_loader=\'npy\'):\n        """"""\n        Dataset class for loading out-of-memory data.\n\n        Arguments\n        ---------\n        root : string\n            path to main directory\n\n        class_mode : string in `{\'label\', \'image\'}`\n            type of target sample to look for and return\n            `label` = return class folder as target\n            `image` = return another image as target as found by \'target_regex\'\n                NOTE: if class_mode == \'image\', you must give an\n                input and target regex and the input/target images should\n                be in a folder together with no other images in that folder\n\n        input_regex : string (default is any valid image file)\n            regular expression to find input images\n            e.g. if all your inputs have the word \'input\', \n            you\'d enter something like input_regex=\'*input*\'\n        \n        target_regex : string (default is Nothing)\n            regular expression to find target images if class_mode == \'image\'\n            e.g. if all your targets have the word \'segment\', \n            you\'d enter somthing like target_regex=\'*segment*\'\n\n        transform : transform class\n            transform to apply to input sample individually\n\n        target_transform : transform class\n            transform to apply to target sample individually\n\n        input_loader : string in `{\'npy\', \'pil\', \'nifti\'} or callable\n            defines how to load samples from file\n            if a function is provided, it should take in a file path\n            as input and return the loaded sample.\n\n        """"""\n        self.input_loader = default_file_reader\n        self.target_loader = default_file_reader if class_mode == \'image\' else lambda x: x\n\n        root = os.path.expanduser(root)\n\n        classes, class_to_idx = _find_classes(root)\n        inputs, targets = _finds_inputs_and_targets(root, class_mode,\n            class_to_idx, input_regex, target_regex)\n\n        if len(inputs) == 0:\n            raise(RuntimeError(\'Found 0 images in subfolders of: %s\' % root))\n        else:\n            print(\'Found %i images\' % len(inputs))\n\n        self.root = os.path.expanduser(root)\n        self.inputs = inputs\n        self.targets = targets\n        self.classes = classes\n        self.class_to_idx = class_to_idx\n\n        self.input_transform = input_transform if input_transform is not None else lambda x: x\n        if isinstance(input_transform, (tuple,list)):\n            self.input_transform = transforms.Compose(self.input_transform)\n        self.target_transform = target_transform if target_transform is not None else lambda x: x\n        if isinstance(target_transform, (tuple,list)):\n            self.target_transform = transforms.Compose(self.target_transform)\n        self.co_transform = co_transform if co_transform is not None else lambda x,y: (x,y)\n        if isinstance(co_transform, (tuple,list)):\n            self.co_transform = transforms.Compose(self.co_transform)\n        \n        self.class_mode = class_mode\n\n    def get_full_paths(self):\n        return [os.path.join(self.root, i) for i in self.inputs]\n\n    def __getitem__(self, index):\n        input_sample = self.inputs[index]\n        input_sample = self.input_loader(input_sample)\n        input_sample = self.input_transform(input_sample)\n\n        target_sample = self.targets[index]\n        target_sample = self.target_loader(target_sample)\n        target_sample = self.target_transform(target_sample)\n        \n        input_sample, target_sample = self.co_transform(input_sample, target_sample)\n\n        return input_sample, target_sample\n    \n    def __len__(self):\n        return len(self.inputs)\n\n\n\ndef _find_classes(dir):\n    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    return classes, class_to_idx\n\ndef _is_image_file(filename):\n    IMG_EXTENSIONS = [\n        \'.jpg\', \'.JPG\', \'.jpeg\', \'.JPEG\',\n        \'.png\', \'.PNG\', \'.ppm\', \'.PPM\', \'.bmp\', \'.BMP\',\n        \'.nii.gz\', \'.npy\'\n    ]\n    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n\ndef _finds_inputs_and_targets(directory, class_mode, class_to_idx=None, \n            input_regex=None, target_regex=None, ):\n    """"""\n    Map a dataset from a root folder\n    """"""\n    if class_mode == \'image\':\n        if not input_regex and not target_regex:\n            raise ValueError(\'must give input_regex and target_regex if\'+\n                \' class_mode==image\')\n    inputs = []\n    targets = []\n    for subdir in sorted(os.listdir(directory)):\n        d = os.path.join(directory, subdir)\n        if not os.path.isdir(d):\n            continue\n\n        for root, _, fnames in sorted(os.walk(d)):\n            for fname in fnames:\n                if _is_image_file(fname):\n                    if fnmatch.fnmatch(fname, input_regex):\n                        path = os.path.join(root, fname)\n                        inputs.append(path)\n                        if class_mode == \'label\':\n                            targets.append(class_to_idx[subdir])\n                    if class_mode == \'image\' and \\\n                            fnmatch.fnmatch(fname, target_regex):\n                        path = os.path.join(root, fname)\n                        targets.append(path)\n    if class_mode is None:\n        return inputs\n    else:\n        return inputs, targets\n'"
torchsample/initializers.py,30,"b'""""""\nClasses to initialize module weights\n""""""\n\nfrom fnmatch import fnmatch\n\nimport torch.nn.init\n\n\ndef _validate_initializer_string(init):\n    dir_f = dir(torch.nn.init)\n    loss_fns = [d.lower() for d in dir_f]\n    if isinstance(init, str):\n        try:\n            str_idx = loss_fns.index(init.lower())\n        except:\n            raise ValueError(\'Invalid loss string input - must match pytorch function.\')\n        return getattr(torch.nn.init, dir(torch.nn.init)[str_idx])\n    elif callable(init):\n        return init\n    else:\n        raise ValueError(\'Invalid loss input\')\n\n\nclass InitializerContainer(object):\n\n    def __init__(self, initializers):\n        self._initializers = initializers\n\n    def apply(self, model):\n        for initializer in self._initializers:\n            model.apply(initializer)\n\n\nclass Initializer(object):\n\n    def __call__(self, module):\n        raise NotImplementedError(\'Initializer must implement this method\')\n\n\nclass GeneralInitializer(Initializer):\n\n    def __init__(self, initializer, bias=False, bias_only=False, **kwargs):\n        self._initializer = _validate_initializer_string(initializer)\n        self.kwargs = kwargs\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                self._initializer(module.bias.data, **self.kwargs)\n            else:\n                self._initializer(module.weight.data, **self.kwargs)\n                if self.bias:\n                    self._initializer(module.bias.data, **self.kwargs)\n\n\nclass Normal(Initializer):\n\n    def __init__(self, mean=0.0, std=0.02, bias=False, \n                 bias_only=False, module_filter=\'*\'):\n        self.mean = mean\n        self.std = std\n\n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(Normal, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.normal(module.bias.data, mean=self.mean, std=self.std)\n            else:\n                torch.nn.init.normal(module.weight.data, mean=self.mean, std=self.std)\n                if self.bias:\n                    torch.nn.init.normal(module.bias.data, mean=self.mean, std=self.std)\n\n\nclass Uniform(Initializer):\n\n    def __init__(self, a=0, b=1, bias=False, bias_only=False, module_filter=\'*\'):\n        self.a = a\n        self.b = b\n\n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(Uniform, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.uniform(module.bias.data, a=self.a, b=self.b)\n            else:\n                torch.nn.init.uniform(module.weight.data, a=self.a, b=self.b)\n                if self.bias:\n                    torch.nn.init.uniform(module.bias.data, a=self.a, b=self.b)\n\n\nclass ConstantInitializer(Initializer):\n\n    def __init__(self, value, bias=False, bias_only=False, module_filter=\'*\'):\n        self.value = value\n\n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(ConstantInitializer, self).__init__()\n\n    def __call__(self, module, bias=False, bias_only=False, module_filter=\'*\'):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.constant(module.bias.data, val=self.value)\n            else:\n                torch.nn.init.constant(module.weight.data, val=self.value)\n                if self.bias:\n                    torch.nn.init.constant(module.bias.data, val=self.value)\n\n\nclass XavierUniform(Initializer):\n\n    def __init__(self, gain=1, bias=False, bias_only=False, module_filter=\'*\'):\n        self.gain = gain\n\n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(XavierUniform, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.xavier_uniform(module.bias.data, gain=self.gain)\n            else:\n                torch.nn.init.xavier_uniform(module.weight.data, gain=self.gain)\n                if self.bias:\n                    torch.nn.init.xavier_uniform(module.bias.data, gain=self.gain)\n\n\nclass XavierNormal(Initializer):\n\n    def __init__(self, gain=1, bias=False, bias_only=False, module_filter=\'*\'):\n        self.gain = gain\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(XavierNormal, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.xavier_normal(module.bias.data, gain=self.gain)\n            else:\n                torch.nn.init.xavier_normal(module.weight.data, gain=self.gain)\n                if self.bias:\n                    torch.nn.init.xavier_normal(module.bias.data, gain=self.gain)\n\n\nclass KaimingUniform(Initializer):\n\n    def __init__(self, a=0, mode=\'fan_in\', bias=False, bias_only=False, module_filter=\'*\'):\n        self.a = a\n        self.mode = mode\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(KaimingUniform, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.kaiming_uniform(module.bias.data, a=self.a, mode=self.mode)\n            else:\n                torch.nn.init.kaiming_uniform(module.weight.data, a=self.a, mode=self.mode)\n                if self.bias:\n                    torch.nn.init.kaiming_uniform(module.bias.data, a=self.a, mode=self.mode)\n\n\nclass KaimingNormal(Initializer):\n\n    def __init__(self, a=0, mode=\'fan_in\', bias=False, bias_only=False, module_filter=\'*\'):\n        self.a = a\n        self.mode = mode\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(KaimingNormal, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.kaiming_normal(module.bias.data, a=self.a, mode=self.mode)\n            else:\n                torch.nn.init.kaiming_normal(module.weight.data, a=self.a, mode=self.mode)\n                if self.bias:\n                    torch.nn.init.kaiming_normal(module.bias.data, a=self.a, mode=self.mode)\n\n\nclass Orthogonal(Initializer):\n\n    def __init__(self, gain=1, bias=False, bias_only=False, module_filter=\'*\'):\n        self.gain = gain\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(Orthogonal, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.orthogonal(module.bias.data, gain=self.gain)\n            else:\n                torch.nn.init.orthogonal(module.weight.data, gain=self.gain)\n                if self.bias:\n                    torch.nn.init.orthogonal(module.bias.data, gain=self.gain)\n\n\nclass Sparse(Initializer):\n\n    def __init__(self, sparsity, std=0.01, bias=False, bias_only=False, module_filter=\'*\'):\n        self.sparsity = sparsity\n        self.std = std\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(Sparse, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.sparse(module.bias.data, sparsity=self.sparsity, std=self.std)\n            else:\n                torch.nn.init.sparse(module.weight.data, sparsity=self.sparsity, std=self.std)\n                if self.bias:\n                    torch.nn.init.sparse(module.bias.data, sparsity=self.sparsity, std=self.std)\n\n\n\n'"
torchsample/metrics.py,0,"b'\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport torch as th\n\nfrom .utils import th_matrixcorr\n\nfrom .callbacks import Callback\n\nclass MetricContainer(object):\n\n\n    def __init__(self, metrics, prefix=\'\'):\n        self.metrics = metrics\n        self.helper = None\n        self.prefix = prefix\n\n    def set_helper(self, helper):\n        self.helper = helper\n\n    def reset(self):\n        for metric in self.metrics:\n            metric.reset()\n\n    def __call__(self, output_batch, target_batch):\n        logs = {}\n        for metric in self.metrics:\n            logs[self.prefix+metric._name] = self.helper.calculate_loss(output_batch,\n                                                                        target_batch,\n                                                                        metric) \n        return logs\n\nclass Metric(object):\n\n    def __call__(self, y_pred, y_true):\n        raise NotImplementedError(\'Custom Metrics must implement this function\')\n\n    def reset(self):\n        raise NotImplementedError(\'Custom Metrics must implement this function\')\n\n\nclass MetricCallback(Callback):\n\n    def __init__(self, container):\n        self.container = container\n    def on_epoch_begin(self, epoch_idx, logs):\n        self.container.reset()\n\nclass CategoricalAccuracy(Metric):\n\n    def __init__(self, top_k=1):\n        self.top_k = top_k\n        self.correct_count = 0\n        self.total_count = 0\n        self.accuracy = 0\n\n        self._name = \'acc_metric\'\n\n    def reset(self):\n        self.correct_count = 0\n        self.total_count = 0\n        self.accuracy = 0\n\n    def __call__(self, y_pred, y_true):\n        top_k = y_pred.topk(self.top_k,1)[1]\n        true_k = y_true.view(len(y_true),1).expand_as(top_k)\n        self.correct_count += top_k.eq(true_k).float().sum().data[0]\n        self.total_count += len(y_pred)\n        accuracy = 100. * float(self.correct_count) / float(self.total_count)\n        return accuracy\n\n\nclass BinaryAccuracy(Metric):\n\n    def __init__(self):\n        self.correct_count = 0\n        self.total_count = 0\n        self.accuracy = 0\n\n        self._name = \'acc_metric\'\n\n    def reset(self):\n        self.correct_count = 0\n        self.total_count = 0\n        self.accuracy = 0\n\n    def __call__(self, y_pred, y_true):\n        y_pred_round = y_pred.round().long()\n        self.correct_count += y_pred_round.eq(y_true).float().sum().data[0]\n        self.total_count += len(y_pred)\n        accuracy = 100. * float(self.correct_count) / float(self.total_count)\n        return accuracy\n\n\nclass ProjectionCorrelation(Metric):\n\n    def __init__(self):\n        self.corr_sum = 0.\n        self.total_count = 0.\n\n        self._name = \'corr_metric\'\n\n    def reset(self):\n        self.corr_sum = 0.\n        self.total_count = 0.\n        self.average = 0.\n\n    def __call__(self, y_pred, y_true=None):\n        """"""\n        y_pred should be two projections\n        """"""\n        covar_mat = th.abs(th_matrixcorr(y_pred[0].data, y_pred[1].data))\n        self.corr_sum += th.trace(covar_mat)\n        self.total_count += covar_mat.size(0)\n        return self.corr_sum / self.total_count\n\n\nclass ProjectionAntiCorrelation(Metric):\n\n    def __init__(self):\n        self.anticorr_sum = 0.\n        self.total_count = 0.\n        self.average = 0.\n\n        self._name = \'anticorr_metric\'\n\n    def reset(self):\n        self.anticorr_sum = 0.\n        self.total_count = 0.\n        self.average = 0.\n\n    def __call__(self, y_pred, y_true=None):\n        """"""\n        y_pred should be two projections\n        """"""\n        covar_mat = th.abs(th_matrixcorr(y_pred[0].data, y_pred[1].data))\n        upper_sum = th.sum(th.triu(covar_mat,1))\n        lower_sum = th.sum(th.tril(covar_mat,-1))\n        self.anticorr_sum += upper_sum\n        self.anticorr_sum += lower_sum\n        self.total_count += covar_mat.size(0)*(covar_mat.size(1) - 1)\n        return self.anticorr_sum / self.total_count\n\n\n\n'"
torchsample/regularizers.py,0,"b'\nimport torch as th\nfrom fnmatch import fnmatch\n\nfrom .callbacks import Callback\n\nclass RegularizerContainer(object):\n\n    def __init__(self, regularizers):\n        self.regularizers = regularizers\n        self._forward_hooks = []\n\n    def register_forward_hooks(self, model):\n        for regularizer in self.regularizers:\n            for module_name, module in model.named_modules():\n                if fnmatch(module_name, regularizer.module_filter) and hasattr(module, \'weight\'):\n                    hook = module.register_forward_hook(regularizer)\n                    self._forward_hooks.append(hook)\n        \n        if len(self._forward_hooks) == 0:\n            raise Exception(\'Tried to register regularizers but no modules \'\n                \'were found that matched any module_filter argument.\')\n\n    def unregister_forward_hooks(self):\n        for hook in self._forward_hooks:\n            hook.remove()\n\n    def reset(self):\n        for r in self.regularizers:\n            r.reset()\n\n    def get_value(self):\n        value = sum([r.value for r in self.regularizers])\n        self.current_value = value.data[0]\n        return value\n\n    def __len__(self):\n        return len(self.regularizers)\n\n\nclass RegularizerCallback(Callback):\n\n    def __init__(self, container):\n        self.container = container\n\n    def on_batch_end(self, batch, logs=None):\n        self.container.reset()\n\n\nclass Regularizer(object):\n\n    def reset(self):\n        raise NotImplementedError(\'subclass must implement this method\')\n\n    def __call__(self, module, input=None, output=None):\n        raise NotImplementedError(\'subclass must implement this method\')\n\n\nclass L1Regularizer(Regularizer):\n\n    def __init__(self, scale=1e-3, module_filter=\'*\'):\n        self.scale = float(scale)\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        value = th.sum(th.abs(module.weight)) * self.scale\n        self.value += value\n\n\nclass L2Regularizer(Regularizer):\n\n    def __init__(self, scale=1e-3, module_filter=\'*\'):\n        self.scale = float(scale)\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        value = th.sum(th.pow(module.weight,2)) * self.scale\n        self.value += value\n\n\nclass L1L2Regularizer(Regularizer):\n\n    def __init__(self, l1_scale=1e-3, l2_scale=1e-3, module_filter=\'*\'):\n        self.l1 = L1Regularizer(l1_scale)\n        self.l2 = L2Regularizer(l2_scale)\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        self.l1(module, input, output)\n        self.l2(module, input, output)\n        self.value += (self.l1.value + self.l2.value)\n\n\n# ------------------------------------------------------------------\n# ------------------------------------------------------------------\n# ------------------------------------------------------------------\n\nclass UnitNormRegularizer(Regularizer):\n    """"""\n    UnitNorm constraint on Weights\n\n    Constraints the weights to have column-wise unit norm\n    """"""\n    def __init__(self,\n                 scale=1e-3,\n                 module_filter=\'*\'):\n\n        self.scale = scale\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        w = module.weight\n        norm_diff = th.norm(w, 2, 1).sub(1.)\n        value = self.scale * th.sum(norm_diff.gt(0).float().mul(norm_diff))\n        self.value += value\n\n\nclass MaxNormRegularizer(Regularizer):\n    """"""\n    MaxNorm regularizer on Weights\n\n    Constraints the weights to have column-wise unit norm\n    """"""\n    def __init__(self,\n                 scale=1e-3,\n                 module_filter=\'*\'):\n\n        self.scale = scale\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        w = module.weight\n        norm_diff = th.norm(w,2,self.axis).sub(self.value)\n        value = self.scale * th.sum(norm_diff.gt(0).float().mul(norm_diff))\n        self.value += value\n\n\nclass NonNegRegularizer(Regularizer):\n    """"""\n    Non-Negativity regularizer on Weights\n\n    Constraints the weights to have column-wise unit norm\n    """"""\n    def __init__(self,\n                 scale=1e-3,\n                 module_filter=\'*\'):\n\n        self.scale = scale\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        w = module.weight\n        value = -1 * self.scale * th.sum(w.gt(0).float().mul(w))\n        self.value += value\n\n'"
torchsample/samplers.py,0,"b'\nimport torch as th\nimport math\n\nclass Sampler(object):\n    """"""Base class for all Samplers.\n\n    Every Sampler subclass has to provide an __iter__ method, providing a way\n    to iterate over indices of dataset elements, and a __len__ method that\n    returns the length of the returned iterators.\n    """"""\n\n    def __init__(self, data_source):\n        pass\n\n    def __iter__(self):\n        raise NotImplementedError\n\n    def __len__(self):\n        raise NotImplementedError\n\nclass StratifiedSampler(Sampler):\n    """"""Stratified Sampling\n\n    Provides equal representation of target classes in each batch\n    """"""\n    def __init__(self, class_vector, batch_size):\n        """"""\n        Arguments\n        ---------\n        class_vector : torch tensor\n            a vector of class labels\n        batch_size : integer\n            batch_size\n        """"""\n        self.n_splits = int(class_vector.size(0) / batch_size)\n        self.class_vector = class_vector\n\n    def gen_sample_array(self):\n        try:\n            from sklearn.model_selection import StratifiedShuffleSplit\n        except:\n            print(\'Need scikit-learn for this functionality\')\n        import numpy as np\n        \n        s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.5)\n        X = th.randn(self.class_vector.size(0),2).numpy()\n        y = self.class_vector.numpy()\n        s.get_n_splits(X, y)\n\n        train_index, test_index = next(s.split(X, y))\n        return np.hstack([train_index, test_index])\n\n    def __iter__(self):\n        return iter(self.gen_sample_array())\n\n    def __len__(self):\n        return len(self.class_vector)\n\nclass MultiSampler(Sampler):\n    """"""Samples elements more than once in a single pass through the data.\n\n    This allows the number of samples per epoch to be larger than the number\n    of samples itself, which can be useful when training on 2D slices taken\n    from 3D images, for instance.\n    """"""\n    def __init__(self, nb_samples, desired_samples, shuffle=False):\n        """"""Initialize MultiSampler\n\n        Arguments\n        ---------\n        data_source : the dataset to sample from\n        \n        desired_samples : number of samples per batch you want\n            whatever the difference is between an even division will\n            be randomly selected from the samples.\n            e.g. if len(data_source) = 3 and desired_samples = 4, then\n            all 3 samples will be included and the last sample will be\n            randomly chosen from the 3 original samples.\n\n        shuffle : boolean\n            whether to shuffle the indices or not\n        \n        Example:\n            >>> m = MultiSampler(2, 6)\n            >>> x = m.gen_sample_array()\n            >>> print(x) # [0,1,0,1,0,1]\n        """"""\n        self.data_samples = nb_samples\n        self.desired_samples = desired_samples\n        self.shuffle = shuffle\n\n    def gen_sample_array(self):\n        from torchsample.utils import th_random_choice\n        n_repeats = self.desired_samples / self.data_samples\n        cat_list = []\n        for i in range(math.floor(n_repeats)):\n            cat_list.append(th.arange(0,self.data_samples))\n        # add the left over samples\n        left_over = self.desired_samples % self.data_samples\n        if left_over > 0:\n            cat_list.append(th_random_choice(self.data_samples, left_over))\n        self.sample_idx_array = th.cat(cat_list).long()\n        return self.sample_idx_array\n\n    def __iter__(self):\n        return iter(self.gen_sample_array())\n\n    def __len__(self):\n        return self.desired_samples\n\n\nclass SequentialSampler(Sampler):\n    """"""Samples elements sequentially, always in the same order.\n\n    Arguments:\n        data_source (Dataset): dataset to sample from\n    """"""\n\n    def __init__(self, nb_samples):\n        self.num_samples = nb_samples\n\n    def __iter__(self):\n        return iter(range(self.num_samples))\n\n    def __len__(self):\n        return self.num_samples\n\n\nclass RandomSampler(Sampler):\n    """"""Samples elements randomly, without replacement.\n\n    Arguments:\n        data_source (Dataset): dataset to sample from\n    """"""\n\n    def __init__(self, nb_samples):\n        self.num_samples = nb_samples\n\n    def __iter__(self):\n        return iter(th.randperm(self.num_samples).long())\n\n    def __len__(self):\n        return self.num_samples\n\n\n'"
torchsample/utils.py,0,"b'""""""\nUtility functions for th.Tensors\n""""""\n\nimport pickle\nimport random\nimport numpy as np\n\nimport torch as th\n\n\ndef th_allclose(x, y):\n    """"""\n    Determine whether two torch tensors have same values\n    Mimics np.allclose\n    """"""\n    return th.sum(th.abs(x-y)) < 1e-5\n\n\ndef th_flatten(x):\n    """"""Flatten tensor""""""\n    return x.contiguous().view(-1)\n\ndef th_c_flatten(x):\n    """"""\n    Flatten tensor, leaving channel intact.\n    Assumes CHW format.\n    """"""\n    return x.contiguous().view(x.size(0), -1)\n\ndef th_bc_flatten(x):\n    """"""\n    Flatten tensor, leaving batch and channel dims intact.\n    Assumes BCHW format\n    """"""\n    return x.contiguous().view(x.size(0), x.size(1), -1)\n\n\ndef th_zeros_like(x):\n    return x.new().resize_as_(x).zero_()\n\ndef th_ones_like(x):\n    return x.new().resize_as_(x).fill_(1)\n\ndef th_constant_like(x, val):\n    return x.new().resize_as_(x).fill_(val)\n\n\ndef th_iterproduct(*args):\n    return th.from_numpy(np.indices(args).reshape((len(args),-1)).T)\n\ndef th_iterproduct_like(x):\n    return th_iterproduct(*x.size())\n\n\ndef th_uniform(lower, upper):\n    return random.uniform(lower, upper)\n\n\ndef th_gather_nd(x, coords):\n    x = x.contiguous()\n    inds = coords.mv(th.LongTensor(x.stride()))\n    x_gather = th.index_select(th_flatten(x), 0, inds)\n    return x_gather\n\n\ndef th_affine2d(x, matrix, mode=\'bilinear\', center=True):\n    """"""\n    2D Affine image transform on th.Tensor\n    \n    Arguments\n    ---------\n    x : th.Tensor of size (C, H, W)\n        image tensor to be transformed\n\n    matrix : th.Tensor of size (3, 3) or (2, 3)\n        transformation matrix\n\n    mode : string in {\'nearest\', \'bilinear\'}\n        interpolation scheme to use\n\n    center : boolean\n        whether to alter the bias of the transform \n        so the transform is applied about the center\n        of the image rather than the origin\n\n    Example\n    ------- \n    >>> import torch\n    >>> from torchsample.utils import *\n    >>> x = th.zeros(2,1000,1000)\n    >>> x[:,100:1500,100:500] = 10\n    >>> matrix = th.FloatTensor([[1.,0,-50],\n    ...                             [0,1.,-50]])\n    >>> xn = th_affine2d(x, matrix, mode=\'nearest\')\n    >>> xb = th_affine2d(x, matrix, mode=\'bilinear\')\n    """"""\n\n    if matrix.dim() == 2:\n        matrix = matrix[:2,:]\n        matrix = matrix.unsqueeze(0)\n    elif matrix.dim() == 3:\n        if matrix.size()[1:] == (3,3):\n            matrix = matrix[:,:2,:]\n\n    A_batch = matrix[:,:,:2]\n    if A_batch.size(0) != x.size(0):\n        A_batch = A_batch.repeat(x.size(0),1,1)\n    b_batch = matrix[:,:,2].unsqueeze(1)\n\n    # make a meshgrid of normal coordinates\n    _coords = th_iterproduct(x.size(1),x.size(2))\n    coords = _coords.unsqueeze(0).repeat(x.size(0),1,1).float()\n\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,:,0] = coords[:,:,0] - (x.size(1) / 2. - 0.5)\n        coords[:,:,1] = coords[:,:,1] - (x.size(2) / 2. - 0.5)\n    # apply the coordinate transformation\n    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(1) / 2. - 0.5)\n        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(2) / 2. - 0.5)\n\n    # map new coordinates using bilinear interpolation\n    if mode == \'nearest\':\n        x_transformed = th_nearest_interp2d(x.contiguous(), new_coords)\n    elif mode == \'bilinear\':\n        x_transformed = th_bilinear_interp2d(x.contiguous(), new_coords)\n\n    return x_transformed\n\n\ndef th_nearest_interp2d(input, coords):\n    """"""\n    2d nearest neighbor interpolation th.Tensor\n    """"""\n    # take clamp of coords so they\'re in the image bounds\n    x = th.clamp(coords[:,:,0], 0, input.size(1)-1).round()\n    y = th.clamp(coords[:,:,1], 0, input.size(2)-1).round()\n\n    stride = th.LongTensor(input.stride())\n    x_ix = x.mul(stride[1]).long()\n    y_ix = y.mul(stride[2]).long()\n\n    input_flat = input.view(input.size(0),-1)\n\n    mapped_vals = input_flat.gather(1, x_ix.add(y_ix))\n\n    return mapped_vals.view_as(input)\n\n\ndef th_bilinear_interp2d(input, coords):\n    """"""\n    bilinear interpolation in 2d\n    """"""\n    x = th.clamp(coords[:,:,0], 0, input.size(1)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    y = th.clamp(coords[:,:,1], 0, input.size(2)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n\n    stride = th.LongTensor(input.stride())\n    x0_ix = x0.mul(stride[1]).long()\n    x1_ix = x1.mul(stride[1]).long()\n    y0_ix = y0.mul(stride[2]).long()\n    y1_ix = y1.mul(stride[2]).long()\n\n    input_flat = input.view(input.size(0),-1)\n\n    vals_00 = input_flat.gather(1, x0_ix.add(y0_ix))\n    vals_10 = input_flat.gather(1, x1_ix.add(y0_ix))\n    vals_01 = input_flat.gather(1, x0_ix.add(y1_ix))\n    vals_11 = input_flat.gather(1, x1_ix.add(y1_ix))\n    \n    xd = x - x0\n    yd = y - y0\n    xm = 1 - xd\n    ym = 1 - yd\n\n    x_mapped = (vals_00.mul(xm).mul(ym) +\n                vals_10.mul(xd).mul(ym) +\n                vals_01.mul(xm).mul(yd) +\n                vals_11.mul(xd).mul(yd))\n\n    return x_mapped.view_as(input)\n\n\ndef th_affine3d(x, matrix, mode=\'trilinear\', center=True):\n    """"""\n    3D Affine image transform on th.Tensor\n    """"""\n    A = matrix[:3,:3]\n    b = matrix[:3,3]\n\n    # make a meshgrid of normal coordinates\n    coords = th_iterproduct(x.size(1),x.size(2),x.size(3)).float()\n\n\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,0] = coords[:,0] - (x.size(1) / 2. - 0.5)\n        coords[:,1] = coords[:,1] - (x.size(2) / 2. - 0.5)\n        coords[:,2] = coords[:,2] - (x.size(3) / 2. - 0.5)\n\n    \n    # apply the coordinate transformation\n    new_coords = coords.mm(A.t().contiguous()) + b.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,0] = new_coords[:,0] + (x.size(1) / 2. - 0.5)\n        new_coords[:,1] = new_coords[:,1] + (x.size(2) / 2. - 0.5)\n        new_coords[:,2] = new_coords[:,2] + (x.size(3) / 2. - 0.5)\n\n    # map new coordinates using bilinear interpolation\n    if mode == \'nearest\':\n        x_transformed = th_nearest_interp3d(x, new_coords)\n    elif mode == \'trilinear\':\n        x_transformed = th_trilinear_interp3d(x, new_coords)\n    else:\n        x_transformed = th_trilinear_interp3d(x, new_coords)\n\n    return x_transformed\n\n\ndef th_nearest_interp3d(input, coords):\n    """"""\n    2d nearest neighbor interpolation th.Tensor\n    """"""\n    # take clamp of coords so they\'re in the image bounds\n    coords[:,0] = th.clamp(coords[:,0], 0, input.size(1)-1).round()\n    coords[:,1] = th.clamp(coords[:,1], 0, input.size(2)-1).round()\n    coords[:,2] = th.clamp(coords[:,2], 0, input.size(3)-1).round()\n\n    stride = th.LongTensor(input.stride())[1:].float()\n    idx = coords.mv(stride).long()\n\n    input_flat = th_flatten(input)\n\n    mapped_vals = input_flat[idx]\n\n    return mapped_vals.view_as(input)\n\n\ndef th_trilinear_interp3d(input, coords):\n    """"""\n    trilinear interpolation of 3D th.Tensor image\n    """"""\n    # take clamp then floor/ceil of x coords\n    x = th.clamp(coords[:,0], 0, input.size(1)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    # take clamp then floor/ceil of y coords\n    y = th.clamp(coords[:,1], 0, input.size(2)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n    # take clamp then floor/ceil of z coords\n    z = th.clamp(coords[:,2], 0, input.size(3)-2)\n    z0 = z.floor()\n    z1 = z0 + 1\n\n    stride = th.LongTensor(input.stride())[1:]\n    x0_ix = x0.mul(stride[0]).long()\n    x1_ix = x1.mul(stride[0]).long()\n    y0_ix = y0.mul(stride[1]).long()\n    y1_ix = y1.mul(stride[1]).long()\n    z0_ix = z0.mul(stride[2]).long()\n    z1_ix = z1.mul(stride[2]).long()\n\n    input_flat = th_flatten(input)\n\n    vals_000 = input_flat[x0_ix+y0_ix+z0_ix]\n    vals_100 = input_flat[x1_ix+y0_ix+z0_ix]\n    vals_010 = input_flat[x0_ix+y1_ix+z0_ix]\n    vals_001 = input_flat[x0_ix+y0_ix+z1_ix]\n    vals_101 = input_flat[x1_ix+y0_ix+z1_ix]\n    vals_011 = input_flat[x0_ix+y1_ix+z1_ix]\n    vals_110 = input_flat[x1_ix+y1_ix+z0_ix]\n    vals_111 = input_flat[x1_ix+y1_ix+z1_ix]\n\n    xd = x - x0\n    yd = y - y0\n    zd = z - z0\n    xm1 = 1 - xd\n    ym1 = 1 - yd\n    zm1 = 1 - zd\n\n    x_mapped = (vals_000.mul(xm1).mul(ym1).mul(zm1) +\n                vals_100.mul(xd).mul(ym1).mul(zm1) +\n                vals_010.mul(xm1).mul(yd).mul(zm1) +\n                vals_001.mul(xm1).mul(ym1).mul(zd) +\n                vals_101.mul(xd).mul(ym1).mul(zd) +\n                vals_011.mul(xm1).mul(yd).mul(zd) +\n                vals_110.mul(xd).mul(yd).mul(zm1) +\n                vals_111.mul(xd).mul(yd).mul(zd))\n\n    return x_mapped.view_as(input)\n\n\ndef th_pearsonr(x, y):\n    """"""\n    mimics scipy.stats.pearsonr\n    """"""\n    mean_x = th.mean(x)\n    mean_y = th.mean(y)\n    xm = x.sub(mean_x)\n    ym = y.sub(mean_y)\n    r_num = xm.dot(ym)\n    r_den = th.norm(xm, 2) * th.norm(ym, 2)\n    r_val = r_num / r_den\n    return r_val\n\n\ndef th_corrcoef(x):\n    """"""\n    mimics np.corrcoef\n    """"""\n    # calculate covariance matrix of rows\n    mean_x = th.mean(x, 1)\n    xm = x.sub(mean_x.expand_as(x))\n    c = xm.mm(xm.t())\n    c = c / (x.size(1) - 1)\n\n    # normalize covariance matrix\n    d = th.diag(c)\n    stddev = th.pow(d, 0.5)\n    c = c.div(stddev.expand_as(c))\n    c = c.div(stddev.expand_as(c).t())\n\n    # clamp between -1 and 1\n    c = th.clamp(c, -1.0, 1.0)\n\n    return c\n\n\ndef th_matrixcorr(x, y):\n    """"""\n    return a correlation matrix between\n    columns of x and columns of y.\n\n    So, if X.size() == (1000,4) and Y.size() == (1000,5),\n    then the result will be of size (4,5) with the\n    (i,j) value equal to the pearsonr correlation coeff\n    between column i in X and column j in Y\n    """"""\n    mean_x = th.mean(x, 0)\n    mean_y = th.mean(y, 0)\n    xm = x.sub(mean_x.expand_as(x))\n    ym = y.sub(mean_y.expand_as(y))\n    r_num = xm.t().mm(ym)\n    r_den1 = th.norm(xm,2,0)\n    r_den2 = th.norm(ym,2,0)\n    r_den = r_den1.t().mm(r_den2)\n    r_mat = r_num.div(r_den)\n    return r_mat\n\n\ndef th_random_choice(a, n_samples=1, replace=True, p=None):\n    """"""\n    Parameters\n    -----------\n    a : 1-D array-like\n        If a th.Tensor, a random sample is generated from its elements.\n        If an int, the random sample is generated as if a was th.range(n)\n    n_samples : int, optional\n        Number of samples to draw. Default is None, in which case a\n        single value is returned.\n    replace : boolean, optional\n        Whether the sample is with or without replacement\n    p : 1-D array-like, optional\n        The probabilities associated with each entry in a.\n        If not given the sample assumes a uniform distribution over all\n        entries in a.\n\n    Returns\n    --------\n    samples : 1-D ndarray, shape (size,)\n        The generated random samples\n    """"""\n    if isinstance(a, int):\n        a = th.arange(0, a)\n\n    if p is None:\n        if replace:\n            idx = th.floor(th.rand(n_samples)*a.size(0)).long()\n        else:\n            idx = th.randperm(len(a))[:n_samples]\n    else:\n        if abs(1.0-sum(p)) > 1e-3:\n            raise ValueError(\'p must sum to 1.0\')\n        if not replace:\n            raise ValueError(\'replace must equal true if probabilities given\')\n        idx_vec = th.cat([th.zeros(round(p[i]*1000))+i for i in range(len(p))])\n        idx = (th.floor(th.rand(n_samples)*999)).long()\n        idx = idx_vec[idx].long()\n    selection = a[idx]\n    if n_samples == 1:\n        selection = selection[0]\n    return selection\n\n\ndef save_transform(file, transform):\n    """"""\n    Save a transform object\n    """"""\n    with open(file, \'wb\') as output_file:\n        pickler = pickle.Pickler(output_file, -1)\n        pickler.dump(transform)\n\n\ndef load_transform(file):\n    """"""\n    Load a transform object\n    """"""\n    with open(file, \'rb\') as input_file:\n        transform = pickle.load(input_file)\n    return transform\n    \n\n\n    \n'"
torchsample/version.py,0,"b""__version__ = '0.1.3'\n"""
training/__init__.py,0,b'from .utils import *\nfrom .trainers import *\nfrom .pseudolabels import *\n'
training/learning_rates.py,0,"b""import math\nimport operator\nimport copy\n\n\ndef set_learning_rate(optimizer, lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n\ndef get_learning_rate(optimizer):\n    return optimizer.param_groups[0]['lr']\n\n\n\nclass LearningRate():\n    def __init__(self, initial_lr, iteration_type):\n        self.initial_lr = initial_lr\n        self.iteration_type = iteration_type #epoch or mini_batch\n\n    def get_learning_rate(self, optimizer):\n        return optimizer.param_groups[0]['lr']\n\n    def set_learning_rate(self, optimizer, new_lr):\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = new_lr\n\n    def adjust(self, optimizer, lr, iteration, params=None):\n        self.set_learning_rate(optimizer, lr)\n        return lr\n\n\nclass FixedLR(LearningRate):\n    def __init__(self, initial_lr, iteration_type):\n        super().__init__(initial_lr, iteration_type)\n\n    def adjust(self, optimizer, iteration, params=None):\n        new_lr = super().get_learning_rate(optimizer)\n        return new_lr\n\n\nclass LinearLR(LearningRate):\n    def __init__(self, initial_lr, iteration_type, fixed_delta):\n        super().__init__(initial_lr, iteration_type)\n        self.fixed_delta = fixed_delta\n\n    def adjust(self, optimizer, iteration, params=None):\n        lr = super().get_learning_rate(optimizer)\n        new_lr = lr + self.fixed_delta\n        super().set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\nclass SnapshotLR(LearningRate):\n    '''https://arxiv.org/abs/1704.00109'''\n    def __init__(self, initial_lr, iteration_type,\n                 max_lr, total_iters, n_cycles):\n        '''\n        n_iters = total number of mini-batch iterations during training\n        n_cycles = total num snapshots during training\n        max_lr = starting learning rate each cycle'''\n        super().__init__(initial_lr, iteration_type)\n        self.max_lr = max_lr\n        self.total_iters = total_iters\n        self.cycles = n_cycles\n\n    def cosine_annealing(self, t):\n        '''t = current mini-batch iteration'''\n        return self.max_lr/2 * (math.cos(\n         (math.pi * (t % (self.total_iters//self.cycles))) /\n         (self.total_iters//self.cycles)) + 1)\n\n    def adjust(self, optimizer, iteration, params=None):\n        new_lr = self.cosine_annealing(iteration)\n        self.set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\nclass SnapshotParamsLR(LearningRate):\n    '''Snapshot Learning with per-parameter LRs'''\n    def __init__(self, initial_lr, iteration_type,\n                 total_iters, n_cycles):\n        '''\n        n_iters = total number of mini-batch iterations during training\n        n_cycles = total num snapshots during training\n        max_lr = starting learning rate each cycle'''\n        super().__init__(initial_lr, iteration_type)\n        self.total_iters = total_iters\n        self.cycles = n_cycles\n\n    def cosine_annealing(self, t, max_lr):\n        return max_lr/2 * (math.cos(\n         (math.pi * (t % (self.total_iters//self.cycles)))/(\n            self.total_iters//self.cycles)) + 1)\n\n    def adjust(self, optimizer, iteration, params=None):\n        lrs = []\n        for param_group in optimizer.param_groups:\n            new_lr = self.cosine_annealing(iteration, param_group['max_lr'])\n            param_group['lr'] = new_lr\n            lrs.append(new_lr)\n        return new_lr\n\n\nclass DevDecayLR(LearningRate):\n    '''https://arxiv.org/abs/1705.08292'''\n    def __init__(self, initial_lr, iteration_type,\n                 decay_factor=0.9, decay_patience=1):\n        super().__init__(initial_lr, iteration_type)\n        self.decay_factor = decay_factor\n        self.decay_patience = decay_patience\n\n    def adjust(self, optimizer, iteration, params):\n        lr = super().get_learning_rate(optimizer)\n        best_iter = params['best_iter']\n\n        if (iteration - best_iter) > self.decay_patience:\n            print('Decaying learning rate by factor: {:.5f}'.format(\n                self.decay_factor).rstrip('0'))\n            lr *= self.decay_factor\n            super().set_learning_rate(optimizer, lr)\n        return lr\n\n\nclass ScheduledLR(LearningRate):\n    def __init__(self, initial_lr, iteration_type, lr_schedule):\n        super().__init__(initial_lr, iteration_type)\n        self.lr_schedule = lr_schedule\n\n    def adjust(self, optimizer, iteration, params=None):\n        if iteration in self.lr_schedule:\n            new_lr = self.lr_schedule[iteration]\n        else:\n            new_lr = self.get_learning_rate(optimizer)\n        super().set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\nclass DecayingLR(LearningRate):\n    def __init__(self, initial_lr, iteration_type, decay, n_epochs):\n         super().__init__(initial_lr, iteration_type)\n         self.decay = decay\n         self.n_epochs = n_epochs\n\n    def exponential_decay(self, iteration, params=None):\n        '''Update learning rate to `initial_lr` decayed\n        by `decay` every `n_epochs`'''\n        return self.initial_lr * (self.decay ** (iteration // self.n_epochs))\n\n    def adjust(self, optimizer, iteration):\n        new_lr = self.exponential_decay(iteration)\n        super().set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\nclass CyclicalLR(LearningRate):\n    '''https://arxiv.org/abs/1506.01186'''\n    def __init__(self, initial_lr, iteration_type, n_iters, cycle_length,\n                 min_lr, max_lr):\n         assert initial_lr == min_lr\n         super(CyclicalLR, self).__init__(initial_lr, iteration_type)\n         self.n_iters = n_iters\n         self.cycle_length = cycle_length\n         self.min_lr = min_lr\n         self.max_lr = max_lr\n\n    def triangular(self, iteration):\n        iteration -= 1 # if iteration count starts at 1\n        cycle = math.floor(1 + iteration/self.cycle_length)\n        x = abs(iteration/(self.cycle_length/2) - 2*cycle + 1)\n        new_lr = self.min_lr + (self.max_lr - self.min_lr) * max(0, (1-x))\n        return new_lr\n\n    def adjust(self, optimizer, iteration, best_iter=1):\n        new_lr = self.triangular(iteration)\n        super().set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\n\n\n## Helpers\n\ndef cosine_annealing(lr_max, T, M, t):\n    '''\n    t = current mini-batch iteration\n    # lr(t) = f(t-1 % T//M)\n    # lr(t) = lr_max/2 * (math.cos( (math.pi * (t % T/M))/(T/M) ) + 1)\n    '''\n    return lr_max/2 * (math.cos( (math.pi * (t % (T//M)))/(T//M)) + 1)\n"""
training/pseudolabels.py,1,"b""import numpy as np\nimport torch\nimport random\nfrom predictions import pred_utils\nimport utils.files as file_utils\nimport datasets.data_aug as data_aug\nimport pickle\nfrom datasets.datasets import FileDataset\n\n\ndef get_pseudo_label_targets(fpaths, model, img_scale, n_labels, thresholds):\n    dataset = FileDataset(fpaths, targets=None,\n                          transform=data_aug.get_basic_transform(img_scale))\n    dataloader = torch.utils.data.DataLoader(dataset, 64, shuffle=False,\n                            pin_memory=False, num_workers=1)\n    probs = pred_utils.get_probabilities(model, dataloader)\n    preds = pred_utils.get_predictions(probs, thresholds)\n    return preds, probs\n\n\ndef get_pseudo_labeled_fpaths_targets(dir_path, model, n_samples,\n                                      img_scale, n_labels, thresholds):\n    fpaths, _ = file_utils.get_paths_to_files(dir_path)\n    random.shuffle(fpaths)\n    fpaths = fpaths[:n_samples]\n    targets, _ = get_pseudo_label_targets(fpaths, model, img_scale,\n                                          n_labels, thresholds)\n    return fpaths, targets\n\n\ndef combined_train_and_pseudo_fpaths_targets(trn_fpaths, trn_targets,\n                                             pseudo_fpaths, pseudo_targets):\n    combined_fpaths = trn_fpaths + pseudo_fpaths\n    combined_targets = np.vstack([trn_targets, pseudo_targets])\n    return combined_fpaths, combined_targets\n\n\ndef save_pseudo_labels(pseudo_preds, img_paths, out_fpath):\n    obj = {'preds':pseudo_preds, 'img_paths':img_paths}\n    with open(out_fpath, 'wb') as f:\n        pickle.dump(obj, f)\n\n\ndef load_pseudo_labels(fpath):\n    obj = pickle.load(open(fpath, 'rb'))\n    return obj['img_paths'], obj['preds']\n"""
training/trainers.py,1,"b""import time\nimport torch\nimport numpy as np\nimport logging\nfrom torch.autograd import Variable\n\nimport constants as c\nfrom predictions import pred_utils\nfrom metrics import metric\nfrom metrics import metric_utils\nfrom . import utils as trn_utils\n\n\n\nclass QuickTrainer():\n    def __init__(self, metrics):\n        self.metrics = metrics\n        self.logger = None\n\n    def train(self, model, optim, lr_adjuster, criterion, trn_loader,\n              val_loader, n_classes, threshold, n_epochs):\n        start_epoch = 1\n        end_epoch = start_epoch + n_epochs\n\n        for epoch in range(start_epoch, end_epoch):\n            current_lr = lr_adjuster.get_learning_rate(optim)\n\n            ### Train ###\n            trn_start_time = time.time()\n            trn_metrics = trn_utils.train_model(model, trn_loader, threshold,\n                    optim, criterion, lr_adjuster, epoch, n_epochs,\n                    self.metrics)\n            trn_msg = trn_utils.log_trn_msg(self.logger, trn_start_time,\n                                            trn_metrics, current_lr, epoch)\n            print(trn_msg)\n\n            ### Test ###\n            val_start_time = time.time()\n            val_metrics = trn_utils.test_model(model, val_loader, threshold,\n                    n_classes, criterion, self.metrics)\n            val_msg = trn_utils.log_val_msg(self.logger, val_start_time,\n                                            val_metrics, current_lr)\n            print(val_msg)\n\n            ### Adjust Lr ###\n            if lr_adjuster.iteration_type == 'epoch':\n                lr_adjuster.adjust(optim, epoch+1)\n\n\nclass Trainer():\n    def __init__(self, trn_criterion, tst_criterion, optimizer, lr_adjuster):\n        self.trn_criterion = trn_criterion\n        self.tst_criterion = tst_criterion\n        self.optimizer = optimizer\n        self.lr_adjuster = lr_adjuster\n\n    def train(self, model, loader, thresholds, epoch, metrics):\n        model.train()\n\n        loss_data = 0\n        n_classes = loader.dataset.targets.shape[1]\n        probs = np.empty((0, n_classes))\n        labels = np.empty((0, n_classes))\n        metric_totals = {m.name:0 for m in metrics}\n        cur_iter = int((epoch-1) * len(loader))+1\n\n        for inputs, targets, _ in loader:\n            if len(targets.size()) == 1:\n                targets = targets.float().view(-1, 1)\n            inputs = Variable(inputs.cuda(async=True))\n            targets = Variable(targets.cuda(async=True))\n\n            ## Forward Pass\n            output = model(inputs)\n\n            ## Clear Gradients\n            model.zero_grad()\n\n            # Loss\n            loss = self.trn_criterion(output, targets)\n\n            ## Backprop\n            loss.backward()\n            self.optimizer.step()\n\n            ### Adjust Lr ###\n            if self.lr_adjuster.iteration_type == 'mini_batch':\n                self.lr_adjuster.adjust(self.optimizer, cur_iter)\n            cur_iter += 1\n\n            loss_data += loss.data[0]\n            probs = np.vstack([probs, output.data.cpu().numpy()])\n            labels = np.vstack([labels, targets.data.cpu().numpy()])\n\n\n        loss_data /= len(loader)\n        preds = pred_utils.get_predictions(probs, thresholds)\n\n        for m in metrics:\n            score = m.evaluate(loss_data, preds, probs, labels)\n            metric_totals[m.name] = score\n\n        return metric_totals\n\n    def test(self, model, loader, thresholds, metrics):\n        model.eval()\n\n        loss = 0\n        n_classes = loader.dataset.targets.shape[1]\n        probs = np.empty((0, n_classes))\n        labels = np.empty((0, n_classes))\n        metric_totals = {m.name:0 for m in metrics}\n\n        for inputs, targets, _ in loader:\n            if len(targets.size()) == 1:\n                targets = targets.float().view(-1,1)\n            inputs = Variable(inputs.cuda(async=True), volatile=True)\n            targets = Variable(targets.cuda(async=True), volatile=True)\n\n            output = model(inputs)\n\n            loss += self.tst_criterion(output, targets).data[0]\n            probs = np.vstack([probs, output.data.cpu().numpy()])\n            labels = np.vstack([labels, targets.data.cpu().numpy()])\n\n        loss /= len(loader)\n        preds = pred_utils.get_predictions(probs, thresholds)\n\n        for m in metrics:\n            score = m.evaluate(loss, preds, probs, labels)\n            metric_totals[m.name] = score\n\n        return metric_totals\n\n\nclass MultiTargetTrainer(Trainer):\n    def __init__(self, trn_criterion, tst_criterion, optimizer, lr_adjuster):\n        super().__init__(trn_criterion, tst_criterion, optimizer, lr_adjuster)\n\n    def train(self, model, loader, thresholds, epoch, metrics):\n        model.train()\n        n_batches = len(loader)\n        cur_iter = int((epoch-1) * n_batches)+1\n        metric_totals = {m.name:0 for m in metrics}\n\n        for inputs, targets, aux_targets, _ in loader:\n            if len(targets.size()) == 1:\n                targets = targets.float().view(-1, 1)\n            inputs = Variable(inputs.cuda(async=True))\n            targets = Variable(targets.cuda(async=True))\n            aux_targets = Variable(aux_targets.cuda(async=True))\n\n            output = model(inputs)\n\n            model.zero_grad()\n\n            loss = self.trn_criterion(output, targets, aux_targets)\n            loss_data = loss.data[0]\n            labels = targets.data.cpu().numpy()\n            probs = output.data.cpu().numpy()\n            preds = pred_utils.get_predictions(probs, thresholds)\n\n            for m in metrics:\n                score = m.evaluate(loss_data, preds, probs, labels)\n                metric_totals[m.name] += score\n\n            loss.backward()\n            self.optimizer.step()\n\n            if self.lr_adjuster.iteration_type == 'mini_batch':\n                self.lr_adjuster.adjust(self.optimizer, cur_iter)\n            cur_iter += 1\n\n        for m in metrics:\n            metric_totals[m.name] /= n_batches\n\n        return metric_totals\n\n\nclass MultiInputTrainer(Trainer):\n    def __init__(self, trn_criterion, tst_criterion, optimizer, lr_adjuster):\n        super().__init__(trn_criterion, tst_criterion, optimizer, lr_adjuster)\n\n    def train(self, model, loader, thresholds, epoch, metrics):\n        model.train()\n        n_batches = len(loader)\n        cur_iter = int((epoch-1) * n_batches)+1\n        metric_totals = {m.name:0 for m in metrics}\n\n        for inputs, targets, aux_inputs, _ in loader:\n            if len(targets.size()) == 1:\n                targets = targets.float().view(-1, 1)\n            inputs = Variable(inputs.cuda(async=True))\n            aux_inputs = Variable(aux_inputs.cuda(async=True))\n            targets = Variable(targets.cuda(async=True))\n\n            output = model(inputs, aux_inputs)\n\n            model.zero_grad()\n\n            loss = self.trn_criterion(output, targets)\n            loss_data = loss.data[0]\n            labels = targets.data.cpu().numpy()\n            probs = output.data.cpu().numpy()\n            preds = pred_utils.get_predictions(probs, thresholds)\n\n            for m in metrics:\n                score = m.evaluate(loss_data, preds, probs, labels)\n                metric_totals[m.name] += score\n\n            loss.backward()\n            self.optimizer.step()\n\n            if self.lr_adjuster.iteration_type == 'mini_batch':\n                self.lr_adjuster.adjust(self.optimizer, cur_iter)\n            cur_iter += 1\n\n        for m in metrics:\n            metric_totals[m.name] /= n_batches\n\n        return metric_totals\n\n    def test(self, model, loader, thresholds, metrics):\n        model.eval()\n\n        loss = 0\n        probs = []\n        labels = []\n        metric_totals = {m.name:0 for m in metrics}\n\n        for inputs, targets, aux_inputs, _ in loader:\n            if len(targets.size()) == 1:\n                targets = targets.float().view(-1,1)\n            inputs = Variable(inputs.cuda(async=True), volatile=True)\n            aux_inputs = Variable(aux_inputs.cuda(async=True), volatile=True)\n            targets = Variable(targets.cuda(async=True), volatile=True)\n\n            output = model(inputs, aux_inputs)\n\n            loss += self.tst_criterion(output, targets).data[0]\n            probs = np.vstack([probs, output.data.cpu().numpy()])\n            labels = np.vstack([labels, targets.data.cpu().numpy()])\n\n        loss /= len(loader)\n        preds = pred_utils.get_predictions(probs, thresholds)\n        for m in metrics:\n            score = m.evaluate(loss, preds, probs, labels)\n            metric_totals[m.name] = score\n\n        return metric_totals\n\n\nclass ImageTargetTrainer(Trainer):\n    def __init__(self, trn_criterion, tst_criterion, optimizer, \n                    lr_adjuster, n_classes, n_batches_per_step=1):\n        super().__init__(trn_criterion, tst_criterion, optimizer, lr_adjuster)\n        self.n_batches_per_step = n_batches_per_step\n\n    def train(self, model, loader, thresholds, epoch, n_epochs,\n              metrics):\n        model.train()\n        n_batches = len(loader)\n        cur_iter = int((epoch-1) * n_batches)+1\n        metric_totals = {m.name:0 for m in metrics}\n\n        for inputs, targets, _, _ in loader:\n            inputs = Variable(inputs.cuda(async=True))\n            targets = Variable(targets.cuda(async=True))\n\n            output = model(inputs)\n\n            loss = self.trn_criterion(output, targets)\n            loss_data = loss.data[0]\n            labels = targets.data.cpu().numpy()\n            probs = output.data.cpu().numpy()\n            preds = pred_utils.get_predictions(probs, thresholds)\n\n            for m in metrics:\n                score = m.evaluate(loss_data, preds, probs, labels)\n                metric_totals[m.name] += score\n\n            ## Backprop (Calculate gradient)\n            loss.backward()\n\n            ## Update gradient\n            if cur_iter % self.n_batches_per_step == 0:\n                self.optimizer.step()\n                model.zero_grad()\n\n            if self.lr_adjuster.iteration_type == 'mini_batch':\n                self.lr_adjuster.adjust(self.optimizer, cur_iter)\n            cur_iter += 1\n\n        for m in metrics:\n            metric_totals[m.name] /= n_batches\n\n        return metric_totals\n\n    def test(self, model, loader, thresholds, metrics):\n        model.eval()\n        n_batches = len(loader)\n        metric_totals = {m.name:0 for m in metrics}\n\n        for inputs, targets, _, _ in loader:\n            inputs = Variable(inputs.cuda(async=True), volatile=True)\n            targets = Variable(targets.cuda(async=True), volatile=True)\n\n            output = model(inputs)\n\n            loss = self.tst_criterion(output, targets)\n            loss_data = loss.data[0]\n            labels = targets.data.cpu().numpy()\n            probs = output.data.cpu().numpy()\n            preds = pred_utils.get_predictions(probs, thresholds)\n\n            for m in metrics:\n                score = m.evaluate(loss_data, preds, probs, labels)\n                metric_totals[m.name] += score\n\n        for m in metrics:\n            metric_totals[m.name] /= n_batches\n\n        return metric_totals"""
training/utils.py,7,"b'import gc\nimport objgraph\nimport resource\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport time\nimport math\n\nfrom predictions import pred_utils\nimport constants as c\n\n\n\ndef train_model(model, dataloader, thresholds, optimizer, criterion,\n                lr_adjuster, epoch, n_epochs, metrics=[]):\n    model.train()\n    n_batches = len(dataloader)\n    cur_iter = int((epoch-1) * n_batches)+1\n    total_iter = int(n_batches * n_epochs)\n    metric_totals = {m.name:0 for m in metrics}\n\n    for inputs, targets, img_paths in dataloader:\n        if len(targets.size()) == 1:\n            targets = targets.float().view(-1, 1)\n        inputs = Variable(inputs.cuda(async=True))\n        targets = Variable(targets.cuda(async=True))\n\n        ## Forward Pass\n        output = model(inputs)\n\n        ## Clear Gradients\n        model.zero_grad()\n\n        # Metrics\n        loss = criterion(output, targets)\n        loss_data = loss.data[0]\n        labels = targets.data.cpu().numpy()\n        probs = output.data.cpu().numpy()\n        preds = pred_utils.get_predictions(probs, thresholds)\n\n        for metric in metrics:\n            score = metric.evaluate(loss_data, preds, probs, labels)\n            metric_totals[metric.name] += score\n\n        ## Backprop\n        loss.backward()\n        optimizer.step()\n\n        ### Adjust Lr ###\n        if lr_adjuster.iteration_type == \'mini_batch\':\n            lr_adjuster.adjust(optimizer, cur_iter)\n        cur_iter += 1\n\n    for metric in metrics:\n        metric_totals[metric.name] /= n_batches\n\n    return metric_totals\n\n\ndef test_model(model, loader, thresholds, n_classes, criterion, metrics):\n    model.eval()\n\n    loss = 0\n    probs = np.empty((0, n_classes))\n    labels = np.empty((0, n_classes))\n    metric_totals = {m.name:0 for m in metrics}\n\n    for inputs, targets, img_paths in loader:\n        if len(targets.size()) == 1:\n            targets = targets.float().view(-1,1)\n        inputs = Variable(inputs.cuda(async=True), volatile=True)\n        targets = Variable(targets.cuda(async=True), volatile=True)\n\n        output = model(inputs)\n\n        loss += criterion(output, targets).data[0]\n        probs = np.vstack([probs, output.data.cpu().numpy()])\n        labels = np.vstack([labels, targets.data.cpu().numpy()])\n\n    loss /= len(loader)\n    preds = pred_utils.get_predictions(probs, thresholds)\n    for metric in metrics:\n        score = metric.evaluate(loss, preds, probs, labels)\n        metric_totals[metric.name] = score\n\n    return metric_totals\n\n\ndef early_stop(epoch, best_epoch, patience):\n    return (epoch - best_epoch) > patience\n\n\ndef log_memory(step):\n    gc.collect()\n    max_mem_used = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss // 1024\n    print(""Memory usage ({:s}): {:.2f} MB\\n"".format(step, max_mem_used))\n    return max_mem_used\n\n\ndef log_trn_msg(logger, start_time, trn_metrics, lr, epoch):\n    epoch_msg = \'Epoch {:d}\'.format(epoch)\n    metric_msg = get_metric_msg(logger, c.TRAIN, trn_metrics, lr)\n    time_msg = get_time_msg(start_time)\n    combined = epoch_msg + \'\\n\' + metric_msg + time_msg\n    logger.info(combined)\n    return combined\n\n\ndef log_val_msg(logger, start_time, trn_metrics, lr):\n    metric_msg = get_metric_msg(logger, c.VAL, trn_metrics, lr)\n    time_msg = get_time_msg(start_time)\n    combined = metric_msg + time_msg\n    logger.info(combined)\n    return combined\n\n\ndef get_metric_msg(logger, dset, metrics_dict, lr=0):\n    msg = dset.capitalize() + \' - \'\n    for name in metrics_dict.keys():\n        metric_str = (\'{:.4f}\').format(metrics_dict[name]).lstrip(\'0\')\n        msg += (\'{:s} {:s} | \').format(name, metric_str)\n    msg += \'LR \' + \'{:.6f}\'.format(lr).rstrip(\'0\').lstrip(\'0\') + \' | \'\n    return msg\n\n\ndef get_time_msg(start_time):\n    time_elapsed = time.time() - start_time\n    msg = \'Time {:.1f}m {:.2f}s\'.format(\n        time_elapsed // 60, time_elapsed % 60)\n    return msg\n\n\ndef load_optim_params(optim, fpath):\n    state = torch.load(fpath)\n    optim.load_state_dict(state[\'state_dict\'])\n\n\ndef save_optim_params(optim, fpath, epoch=None, name=None):\n    torch.save({\n        \'name\': name,\n        \'epoch\': epoch,\n        \'state_dict\': optim.state_dict()\n    }, fpath)\n\n\ndef load_optim(fpath):\n    return torch.load(fpath)\n\n\ndef save_optim(optim, fpath):\n    torch.save(optim, fpath)\n'"
utils/__init__.py,0,b''
utils/files.py,0,"b'import os\nimport random\nfrom glob import glob\nimport shutil\nimport gzip\nimport pickle\nimport json\nfrom contextlib import closing\nfrom zipfile import ZipFile, ZIP_DEFLATED\nimport re\nimport bcolz\n\n\n\ndef get_fnames_from_fpaths(fpaths):\n    fnames = []\n    for f in fpaths:\n        if isinstance(f, tuple):\n            f = f[0]\n        fnames.append(os.path.basename(f))\n    return fnames\n\n\ndef get_matching_files_in_dir(dirpath, regex):\n    fpaths = glob(os.path.join(dirpath,\'*.*\'))\n    match_objs, match_fpaths = [], []\n    for i in range(len(fpaths)):\n        match = re.search(regex, fpaths[i])\n        if match is not None:\n            match_objs.append(match)\n            match_fpaths.append(fpaths[i])\n    return match_objs, match_fpaths\n\n\ndef zipdir(basedir, archivename):\n    assert os.path.isdir(basedir)\n    with closing(ZipFile(archivename, ""w"", ZIP_DEFLATED)) as z:\n        for root, dirs, files in os.walk(basedir):\n            #NOTE: ignore empty directories\n            for fn in files:\n                absfn = os.path.join(root, fn)\n                zfn = absfn[len(basedir)+len(os.sep):] #XXX: relative path\n                z.write(absfn, zfn)\n\n\ndef unzipdir(archive_path, dest_path, remove=True):\n    ZipFile(archive_path).extractall(dest_path)\n    if remove:\n        os.remove(archive_path)\n\n\ndef save_json(fpath, dict_):\n    with open(fpath, \'w\') as f:\n        json.dump(dict_, f, indent=4, ensure_ascii=False)\n\n\ndef load_json(fpath):\n    with open(fpath, \'r\') as f:\n        json_ = json.load(f)\n    return json_\n\n\ndef pickle_obj(obj, fpath):\n    with open(fpath, \'wb\') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n\n\ndef unpickle_obj(fpath):\n    with open(fpath, \'rb\') as f:\n        return pickle.load(f)\n\n\ndef get_fname_from_fpath(fpath):\n    return os.path.basename(fpath)\n\n\ndef get_paths_to_files(root, file_ext=None, sort=True, strip_ext=False):\n    filepaths = []\n    fnames = []\n    for (dirpath, dirnames, filenames) in os.walk(root):\n        filepaths.extend(os.path.join(dirpath, f) \n            for f in filenames if file_ext is None or f.endswith(file_ext))\n        fnames.extend([f for f in filenames if file_ext is None or f.endswith(file_ext)])\n    if strip_ext:\n        fnames = [os.path.splitext(f)[0] for f in fnames]\n    if sort:\n        return sorted(filepaths), sorted(fnames)\n    return filepaths, fnames\n\n\ndef get_random_image_path(dir_path):\n    filepaths = get_paths_to_files(dir_path)[0]\n    return filepaths[random.randrange(len(filepaths))]\n\n\ndef save_obj(obj, out_fpath):\n    with open(out_fpath, \'wb\') as f:\n        pickle.dump(obj, f)\n\n\ndef load_obj(fpath):\n    return pickle.load(open(fpath, \'rb\'))\n\n\ndef save_bcolz_array(fpath, arr):\n    c=bcolz.carray(arr, rootdir=fpath, mode=\'w\')\n    c.flush()\n\n\ndef load_bcolz_array(fpath):\n    return bcolz.open(fpath)[:]\n\n\ndef compress_file(fpath):\n    gzip_fpath = fpath+\'.gz\'\n    with open(fpath, \'rb\') as f_in:\n        with gzip.open(gzip_fpath, \'wb\') as f_out:\n            shutil.copyfileobj(f_in, f_out)\n    return gzip_fpath\n\n\ndef write_lines(fpath, lines, compress=False):\n    lines_str = \'\\n\'.join(lines)\n    if compress:\n        fpath += \'.gz\'\n        lines_str = str.encode(lines_str)\n        f = gzip.open(fpath, \'wb\')\n    else:\n        f = open(fpath, \'w\')\n    f.write(lines_str)\n    f.close()\n    return fpath'"
utils/general.py,0,"b'import uuid\n\n\ndef gen_unique_id(prefix=\'\', length=5):\n    return prefix + str(uuid.uuid4()).upper().replace(\'-\',\'\')[:length]\n\ndef get_class_name(obj):\n    invalid_class_names = [\'function\']\n    classname = obj.__class__.__name__\n    if classname is None or classname in invalid_class_names:\n        classname = obj.__name__\n    return classname\n\ndef dict_to_html(dd, level=0):\n    """"""\n    Convert dict to html using basic html tags\n    """"""\n    import simplejson\n    text = \'\'\n    for k, v in dd.items():\n        text += \'<br>\' + \'&nbsp;\'*(4*level) + \'<b>%s</b>: %s\' % (k, dict_to_html(v, level+1) if isinstance(v, dict) else (simplejson.dumps(v) if isinstance(v, list) else v))\n    return text\n\ndef dict_to_html_ul(dd, level=0):\n    """"""\n    Convert dict to html using ul/li tags\n    """"""\n    import simplejson\n    text = \'<ul>\'\n    for k, v in dd.items():\n        text += \'<li><b>%s</b>: %s</li>\' % (k, dict_to_html_ul(v, level+1) if isinstance(v, dict) else (simplejson.dumps(v) if isinstance(v, list) else v))\n    text += \'</ul>\'\n    return text\n\n\n'"
utils/imgs.py,1,"b'import os\nimport random\nimport numpy as np\nfrom skimage import io\nfrom PIL import Image, ImageFilter\nfrom  scipy import ndimage\nimport cv2\nimport scipy.misc\nimport matplotlib.image as mpimg\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torchsample\nfrom torch.utils.data import DataLoader, TensorDataset\n\nimport config as cfg\nimport constants as c\nfrom datasets import metadata\nfrom . import files\n\n\nCLASS_COLORS = {\n    \'green\': (0, 128, 0),\n    \'red\': (128, 0, 0),\n    \'blue\': (0, 0, 128),\n    \'black\': (0, 0, 0),\n    \'white\': (255, 255, 255),\n    \'grey\':(128, 128, 128),\n}\n\n\ndef is_image_file(filename):\n    return any(filename.endswith(extension) for extension in c.IMG_EXTS)\n\n\ndef load_rgb_pil(img_path):\n    return Image.open(img_path).convert(\'RGB\')\n\n\ndef load_tif_as_arr(img_path):\n    return io.imread(img_path)\n\n\ndef load_img_as_arr(img_path):\n    return plt.imread(img_path)\n\n\ndef load_img_as_tensor(img_path):\n    img_arr = load_img_as_arr(img_path)\n    return transforms.ToTensor()(img_arr)\n\n\ndef load_img_as_pil(img_path):\n    return Image.open(img_path).convert(\'RGB\')\n\n\ndef save_pil_img(pil_img, fpath):\n    pil_img.save(fpath)\n\n\ndef save_arr(arr, fpath):\n    scipy.misc.imsave(fpath, arr)\n\n\ndef norm_meanstd(arr, mean, std):\n    return (arr - mean) / std\n\n\ndef denorm_meanstd(arr, mean, std):\n    return (arr * std) + mean\n\n\ndef norm255_tensor(arr):\n    """"""Given a color image/where max pixel value in each channel is 255\n    returns normalized tensor or array with all values between 0 and 1""""""\n    return arr / 255.\n\n\ndef denorm255_tensor(arr):\n    return arr * 255.\n\n\ndef plot_img_arr(arr, fs=(6,6), title=None):\n    plt.figure(figsize=fs)\n    plt.imshow(arr.astype(\'uint8\'))\n    plt.title(title)\n    plt.show()\n\n\ndef plot_img_tensor(tns, fs=(6,6), title=None):\n    tns = denorm255_tensor(tns)\n    arr = tns.numpy().transpose((1,2,0))\n    plot_img_arr(arr, fs, title)\n\n\ndef tensor_to_arr(tns):\n    tns = denorm255_tensor(tns)\n    return tns.numpy().transpose((1,2,0))\n\n\ndef plot_img_from_fpath(img_path, fs=(8,8), title=None):\n    plt.figure(figsize=fs)\n    plt.imshow(plt.imread(img_path))\n    plt.title(title)\n    plt.show()\n\n\ndef plot_meanstd_normed_tensor(tns, mean, std, fs=(6,6), title=None):\n    """"""If normalized with mean/std""""""\n    tns = denorm255_tensor(tns)\n    arr = tns.numpy().transpose((1, 2, 0))\n    arr = denorm_meanstd(arr, mean, std)\n    plt.figure(figsize=fs)\n    plt.imshow(arr)\n    if title:\n        plt.title(title)\n    plt.show()\n\n\ndef get_mean_std_of_dataset(dir_path, sample_size=5):\n    fpaths, fnames = files.get_paths_to_files(dir_path)\n    random.shuffle(fpaths)\n    total_mean = np.array([0.,0.,0.])\n    total_std = np.array([0.,0.,0.])\n    for f in fpaths[:sample_size]:\n        if \'tif\' in f:\n            img_arr = io.imread(f)\n        else:\n            img_arr = load_img_as_arr(f)\n        mean = np.mean(img_arr, axis=(0,1))\n        std = np.std(img_arr, axis=(0,1))\n        total_mean += mean\n        total_std += std\n    avg_mean = total_mean / sample_size\n    avg_std = total_std / sample_size\n    print(""mean: {}"".format(avg_mean), ""stdev: {}"".format(avg_std))\n    return avg_mean, avg_std\n\n\ndef plot_binary_mask(arr, threshold=0.5, title=None, color=(255,255,255)):\n    arr = format_1D_binary_mask(arr.copy())\n    print(arr.shape)\n    for i in range(3):\n        arr[:,:,i][arr[:,:,i] >= threshold] = color[i]\n    arr[arr < threshold] = 0\n    plot_img_arr(arr, title=title)\n\n\ndef format_1D_binary_mask(mask):\n    if len(mask.shape) == 2:\n        mask = np.expand_dims(mask, 0)\n    mask = np.stack([mask,mask,mask],axis=1).squeeze().transpose(1,2,0)\n    return mask.astype(\'float32\')\n\n\ndef plot_binary_mask_overlay(mask, img_arr, fs=(18,18), title=None):\n    mask = format_1D_binary_mask(mask.copy())\n    fig = plt.figure(figsize=fs)\n    a = fig.add_subplot(1,2,1)\n    a.set_title(title)\n    plt.imshow(img_arr.astype(\'uint8\'))\n    plt.imshow(mask, cmap=\'jet\', alpha=0.5) # interpolation=\'none\'\n    plt.show()\n\n\ndef plot_binary_mask_overlay(mask, img_arr, fs=(18,18), title=None):\n    mask = format_1D_binary_mask(mask.copy())\n    fig = plt.figure(figsize=fs)\n    a = fig.add_subplot(1,2,1)\n    a.set_title(title)\n    plt.imshow(img_arr.astype(\'uint8\'))\n    plt.imshow(mask, cmap=\'jet\', alpha=0.5) # interpolation=\'none\'\n    plt.show()\n\n\ndef plot_samples_from_dir(dir_path, shuffle=False):\n    fpaths, fnames = files.get_paths_to_files(dir_path)\n    plt.figure(figsize=(16,12))\n    start = random.randint(0,len(fpaths)-1) if shuffle else 0\n    j = 1\n    for idx in range(start, start+6):\n        plt.subplot(2,3,j)\n        plt.imshow(plt.imread(fpaths[idx]))\n        plt.title(fnames[idx])\n        plt.axis(\'off\')\n        j += 1\n\n\ndef plot_sample_preds(fpaths, preds, targs, label_names, shuffle=False):\n    fnames = files.get_fnames_from_fpaths(fpaths)\n    plt.figure(figsize=(16,12))\n    start = random.randint(0,len(preds)-1) if shuffle else 0\n    j = 1\n    for idx in range(start, start+6):\n        plt.subplot(2,3,j)\n        pred_tags = \'P: \' + \',\'.join(metadata.convert_one_hot_to_tags(preds[idx], label_names))\n        if targs is not None:\n            targ_tags = \'T: \' + \',\'.join(metadata.convert_one_hot_to_tags(\n                targs[idx], label_names))\n        else:\n            targ_tags = \'\'\n        title = \'\\n\'.join([fnames[idx], pred_tags, targ_tags])\n        plt.imshow(plt.imread(fpaths[idx]))\n        plt.title(title)\n        j += 1\n\n\ndef plot_sample_preds_masks(fnames, inputs, preds, fs=(9,9), \n        n_samples=8, shuffle=False):\n    start = random.randint(0,len(inputs)-1) if shuffle else 0\n    for idx in range(start, start+n_samples):\n        print(fnames[idx])\n        img = tensor_to_arr(inputs[idx])\n        plot_binary_mask_overlay(preds[idx], img, fs, fnames[idx])\n'"
utils/logger.py,0,"b""import os\nimport logging\nimport imp\nimport time\n\n\ndef get_logger(log_path='',\n               logger_name='logger',\n               ch_log_level=logging.ERROR,\n               fh_log_level=logging.INFO):\n    logging.shutdown()\n    imp.reload(logging)\n    logger = logging.getLogger(logger_name)\n    logger.setLevel(logging.DEBUG)\n\n    # Console Handler\n    if ch_log_level:\n        ch = logging.StreamHandler()\n        ch.setLevel(ch_log_level)\n        ch.setFormatter(logging.Formatter('%(message)s'))\n        logger.addHandler(ch)\n\n    # File Handler\n    if fh_log_level:\n        fh = logging.FileHandler(os.path.join(log_path,logger_name+'.log'))\n        fh.setLevel(fh_log_level)\n        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n        fh.setFormatter(formatter)\n        logger.addHandler(fh)\n\n    return logger\n\n\ndef get_time_msg(start_time):\n    time_elapsed = time.time() - start_time\n    msg = 'Time {:.1f}m {:.2f}s'.format(\n        time_elapsed // 60, time_elapsed % 60)\n    return msg"""
utils/multitasking.py,0,"b'from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\nfrom itertools import repeat\n\ndef multithreading(func, args, workers):\n    begin_time = time.time()\n    with ThreadPoolExecutor(max_workers=workers) as executor:\n        res = executor.map(func, args, [begin_time for i in range(len(args))])\n    return list(res)\n        \ndef multiprocessing(func, args, workers):\n    begin_time = time.time()\n    with ProcessPoolExecutor(max_workers=workers) as executor:\n        res = executor.map(func, args, [begin_time for i in range(len(args))])\n    return list(res)'"
utils/widgets.py,0,"b""import os\nimport re\nfrom glob import glob\nfrom config import PATHS\nfrom experiments import experiment\nfrom experiments import exp_utils\nimport training.utils as train_utils\nimport constants as c\n\n\nLATEST = 'latest'\n\ndef load_single_weights(exp_name, epoch):\n    return epoch\n\n\ndef load_multiple_weights(exp_name, epoch):\n    return list(epoch)\n\n\ndef get_weights_path(exp_name):\n    return os.path.join(PATHS['experiments']['root'], exp_name, 'weights')\n\n\ndef load_experiment(name):\n    exp = experiment.Experiment(name, PATHS['experiments']['root'])\n    exp.review()\n    exp.history.load_history_from_file(c.VAL)\n    return exp\n\n\ndef get_f2_scores_by_epoch(exp_name, sort_by_score):\n    exp = load_experiment(exp_name)\n    weight_fpaths = exp_utils.get_weights_fpaths(exp.weights_dir)\n    epochs = exp_utils.get_weight_epochs_from_fpaths(weight_fpaths)\n    epochs.insert(0,'latest')\n    f2_scores = exp.history.metrics_history[c.F2_SCORE][c.VAL]\n    score_by_epoch = {}\n    for epoch in epochs[1:]:\n        score_by_epoch[epoch] = float('{:4g}'.format(f2_scores[epoch-1]))\n    score_by_epoch[LATEST] = float('{:4g}'.format(f2_scores[-1]))\n    if sort_by_score:\n        sorted_epochs_by_score = {}\n        sorted_epochs = sorted(score_by_epoch, key=score_by_epoch.get,\n                                reverse=sort_by_score)\n        for epoch in sorted_epochs:\n            if epoch == LATEST:\n                sorted_epochs_by_score[epoch] = '{:4g}'.format(f2_scores[-1])\n            else:\n                score = '{:4g}'.format(f2_scores[epoch-1])\n                sorted_epochs_by_score[epoch] = score\n        return append_score_wpaths(exp_name, sorted_epochs_by_score)\n    return append_score_wpaths(exp_name, score_by_epoch)\n\ndef append_score_wpaths(exp_name, epoch_dict):\n    new_dict = {}\n    for epoch in epoch_dict.keys():\n        new_key = '{:} ({:4g})'.format(\n            epoch, float(epoch_dict[epoch]))\n        wpath = get_weights_fpath(epoch, exp_name)\n        new_dict[new_key] = wpath\n    return new_dict\n\n\ndef get_weights_fpath(epoch, exp_name):\n    weights_path = get_weights_path(exp_name)\n    if epoch == LATEST:\n        return os.path.join(weights_path, c.LATEST_WEIGHTS_FNAME)\n    return weights_path+'/weights-'+str(epoch)+'.pth'\n\n\ndef get_weights_epoch_path_dict(exp_name):\n    wtdict = {}\n    epochs = get_weights_epochs(exp_name)\n    for epoch in epochs:\n        wtdict[epoch] = get_weights_fpath(epoch, exp_name)\n    return wtdict\n"""
visualizers/__init__.py,0,b'\n'
visualizers/kibana.py,0,"b""import json\nimport pandas as pd\nimport config\nimport constants as c\nimport clients.client_constants as cc\nimport clients.es_client as es\nimport copy\n\n\nclass Kibana():\n    \n    def __init__(self, exp_name):\n        self.name = exp_name\n        self.classname = 'Kibana'\n\n    def init(self, exp_config):\n        assert config.ES_ENABLED is True\n        assert es.ping() is True\n\n    def update(self, exp_config, exp_history, msg=None):\n        es.upload_experiment_history(exp_config, exp_history)\n        es.upload_experiment_config(exp_config)\n\n\ndef load(config):\n    return Kibana(config.name)\n\n\n"""
visualizers/vis_utils.py,0,"b""from . import kibana\nfrom . import viz\n\n\nVISUALIZERS = {\n    'visdom': viz.load,\n    'kibana': kibana.load\n}\n\ndef get_visualizer(config, name):\n    return VISUALIZERS[name.lower()](config)\n\n\ndef get_visualizers_from_config(config):\n    visualizers = []\n    for v in config.visualizers:\n        visualizer = get_visualizer(config, v)\n        visualizers.append(visualizer)\n    return visualizers\n"""
visualizers/viz.py,0,"b'import numpy as np\nfrom visdom import Visdom\nimport constants as c\n\nclass Viz():\n\n    def __init__(self, exp_name):\n        self.name = exp_name\n        self.classname = \'Visdom\'\n        self.viz = None\n        self.plots = None\n\n    def init(self, exp_config):\n        self.viz = Visdom()\n        self.plots = self.init_visdom_plots(exp_config)\n\n    def update(self, exp_config, exp_history, msg=None):\n        epoch = exp_config.progress[\'epoch\']\n        metrics_history = exp_history.metrics_history\n\n        for name in exp_config.metrics:\n            trn_arr = np.array(metrics_history[name][c.TRAIN])\n            val_arr = np.array(metrics_history[name][c.VAL])\n            self.update_metric_plot(name, trn_arr, val_arr, epoch,\n                                    ylabel=name)\n\n        for metric in exp_config.aux_metrics:\n            name = metric[\'name\']\n            data_arr = np.array(metrics_history[name])\n            self.update_aux_metric_plot(name, data_arr, epoch,\n                                        ylabel=metric[\'units\'])\n        self.update_summary_plot(msg)\n\n    def init_visdom_plots(self, exp_config):\n        plots = {}\n        for name in exp_config.metrics:\n            plot = self.init_train_val_metric_plot(name, name)\n            plots[name] = plot\n        for aux_metric in exp_config.aux_metrics:\n            name = aux_metric[\'name\']\n            plot = self.init_auxiliary_metric_plot(name, aux_metric[\'units\'])\n            plots[name] = plot\n        plots[\'summary\'] = self.init_txt_plot(\'summary\')\n        return plots\n\n    def init_train_val_metric_plot(self, title, ylabel, xlabel=\'epoch\'):\n        return self.viz.line(\n            X=np.array([1]),\n            Y=np.array([[1, 1]]),\n            opts=dict(\n                xlabel=xlabel,\n                ylabel=ylabel,\n                title=title,\n                legend=[\'Train\', \'Valid\']\n            ),\n            env=self.name\n        )\n\n    def init_auxiliary_metric_plot(self, title, ylabel, xlabel=\'epoch\'):\n        return self.viz.line(\n            X=np.array([1]),\n            Y=np.array([1]),\n            opts=dict(\n                xlabel=xlabel,\n                ylabel=ylabel,\n                title=title,\n                legend=[]\n            ),\n            env=self.name\n        )\n\n    def init_txt_plot(self, title):\n        return self.viz.text(\n            ""Initializing.. "" + title,\n            env=self.name\n        )\n\n    def viz_epochs(self, cur_epoch):\n        # Epochs start at 1\n        epochs = np.arange(1, cur_epoch+1)\n        return np.stack([epochs, epochs],1)\n\n    def update_metric_plot(self, metric, train_arr, val_arr,\n                           epoch, ylabel, xlabel=\'epoch\'):\n        data = np.stack([train_arr, val_arr], 1)\n        window = self.plots[metric]\n        return self.viz.line(\n            X=self.viz_epochs(epoch),\n            Y=data,\n            win=window,\n            env=self.name,\n            opts=dict(\n                xlabel=xlabel,\n                ylabel=ylabel,\n                title=metric,\n                legend=[\'Train\', \'Valid\']\n            ),\n        )\n\n    def update_aux_metric_plot(self, metric, data_arr, epoch, ylabel,\n                                   xlabel=\'epoch\', legend=[]):\n        window = self.plots[metric]\n        return self.viz.line(\n            X=self.viz_epochs(epoch)[:,0],\n            Y=data_arr,\n            win=window,\n            env=self.name,\n            opts=dict(\n                xlabel=xlabel,\n                ylabel=ylabel, #metric.units,\n                title=metric,\n                legend=legend\n            ),\n        )\n\n    def update_summary_plot(self, msg):\n        window = self.plots[\'summary\']\n        return self.viz.text(\n            msg,\n            win=window,\n            env=self.name\n        )\n\n\ndef load(config):\n    return Viz(config.name)\n'"
competitions/team/__init__.py,0,b''
competitions/team/brendan.py,0,b''
torchsample/functions/__init__.py,0,b'\nfrom .affine import *'
torchsample/functions/affine.py,36,"b'\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nfrom ..utils import th_iterproduct, th_flatten\n\n\ndef F_affine2d(x, matrix, center=True):\n    """"""\n    2D Affine image transform on torch.autograd.Variable\n    """"""\n    if matrix.dim() == 2:\n        matrix = matrix.view(-1,2,3)\n\n    A_batch = matrix[:,:,:2]\n    if A_batch.size(0) != x.size(0):\n        A_batch = A_batch.repeat(x.size(0),1,1)\n    b_batch = matrix[:,:,2].unsqueeze(1)\n\n    # make a meshgrid of normal coordinates\n    _coords = th_iterproduct(x.size(1),x.size(2))\n    coords = Variable(_coords.unsqueeze(0).repeat(x.size(0),1,1).float(),\n                    requires_grad=False)\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,:,0] = coords[:,:,0] - (x.size(1) / 2. + 0.5)\n        coords[:,:,1] = coords[:,:,1] - (x.size(2) / 2. + 0.5)\n\n    # apply the coordinate transformation\n    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(1) / 2. + 0.5)\n        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(2) / 2. + 0.5)\n\n    # map new coordinates using bilinear interpolation\n    x_transformed = F_bilinear_interp2d(x, new_coords)\n\n    return x_transformed\n\n\ndef F_bilinear_interp2d(input, coords):\n    """"""\n    bilinear interpolation of 2d torch.autograd.Variable\n    """"""\n    x = torch.clamp(coords[:,:,0], 0, input.size(1)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    y = torch.clamp(coords[:,:,1], 0, input.size(2)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n\n    stride = torch.LongTensor(input.stride())\n    x0_ix = x0.mul(stride[1]).long()\n    x1_ix = x1.mul(stride[1]).long()\n    y0_ix = y0.mul(stride[2]).long()\n    y1_ix = y1.mul(stride[2]).long()\n\n    input_flat = input.view(input.size(0),-1).contiguous()\n\n    vals_00 = input_flat.gather(1, x0_ix.add(y0_ix).detach())\n    vals_10 = input_flat.gather(1, x1_ix.add(y0_ix).detach())\n    vals_01 = input_flat.gather(1, x0_ix.add(y1_ix).detach())\n    vals_11 = input_flat.gather(1, x1_ix.add(y1_ix).detach())\n    \n    xd = x - x0\n    yd = y - y0\n    xm = 1 - xd\n    ym = 1 - yd\n\n    x_mapped = (vals_00.mul(xm).mul(ym) +\n                vals_10.mul(xd).mul(ym) +\n                vals_01.mul(xm).mul(yd) +\n                vals_11.mul(xd).mul(yd))\n\n    return x_mapped.view_as(input)\n\n\ndef F_batch_affine2d(x, matrix, center=True):\n    """"""\n\n    x : torch.Tensor\n        shape = (Samples, C, H, W)\n        NOTE: Assume C is always equal to 1!\n    matrix : torch.Tensor\n        shape = (Samples, 6) or (Samples, 2, 3)\n\n    Example\n    -------\n    >>> x = Variable(torch.zeros(3,1,10,10))\n    >>> x[:,:,3:7,3:7] = 1\n    >>> m1 = torch.FloatTensor([[1.2,0,0],[0,1.2,0]])\n    >>> m2 = torch.FloatTensor([[0.8,0,0],[0,0.8,0]])\n    >>> m3 = torch.FloatTensor([[1.0,0,3],[0,1.0,3]])\n    >>> matrix = Variable(torch.stack([m1,m2,m3]))\n    >>> xx = F_batch_affine2d(x,matrix)\n    """"""\n    if matrix.dim() == 2:\n        matrix = matrix.view(-1,2,3)\n\n    A_batch = matrix[:,:,:2]\n    b_batch = matrix[:,:,2].unsqueeze(1)\n\n    # make a meshgrid of normal coordinates\n    _coords = th_iterproduct(x.size(2),x.size(3))\n    coords = Variable(_coords.unsqueeze(0).repeat(x.size(0),1,1).float(),\n                requires_grad=False)\n\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,:,0] = coords[:,:,0] - (x.size(2) / 2. + 0.5)\n        coords[:,:,1] = coords[:,:,1] - (x.size(3) / 2. + 0.5)\n    \n    # apply the coordinate transformation\n    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(2) / 2. + 0.5)\n        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(3) / 2. + 0.5)\n\n    # map new coordinates using bilinear interpolation\n    x_transformed = F_batch_bilinear_interp2d(x, new_coords)\n\n    return x_transformed\n\n\ndef F_batch_bilinear_interp2d(input, coords):\n    """"""\n    input : torch.Tensor\n        size = (N,H,W,C)\n    coords : torch.Tensor\n        size = (N,H*W*C,2)\n    """"""\n    x = torch.clamp(coords[:,:,0], 0, input.size(2)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    y = torch.clamp(coords[:,:,1], 0, input.size(3)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n\n    stride = torch.LongTensor(input.stride())\n    x0_ix = x0.mul(stride[2]).long()\n    x1_ix = x1.mul(stride[2]).long()\n    y0_ix = y0.mul(stride[3]).long()\n    y1_ix = y1.mul(stride[3]).long()\n\n    input_flat = input.view(input.size(0),-1).contiguous()\n\n    vals_00 = input_flat.gather(1, x0_ix.add(y0_ix).detach())\n    vals_10 = input_flat.gather(1, x1_ix.add(y0_ix).detach())\n    vals_01 = input_flat.gather(1, x0_ix.add(y1_ix).detach())\n    vals_11 = input_flat.gather(1, x1_ix.add(y1_ix).detach())\n    \n    xd = x - x0\n    yd = y - y0\n    xm = 1 - xd\n    ym = 1 - yd\n\n    x_mapped = (vals_00.mul(xm).mul(ym) +\n                vals_10.mul(xd).mul(ym) +\n                vals_01.mul(xm).mul(yd) +\n                vals_11.mul(xd).mul(yd))\n\n    return x_mapped.view_as(input)\n\n\ndef F_affine3d(x, matrix, center=True):\n    A = matrix[:3,:3]\n    b = matrix[:3,3]\n\n    # make a meshgrid of normal coordinates\n    coords = Variable(th_iterproduct(x.size(1),x.size(2),x.size(3)).float(),\n                requires_grad=False)\n\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,0] = coords[:,0] - (x.size(1) / 2. + 0.5)\n        coords[:,1] = coords[:,1] - (x.size(2) / 2. + 0.5)\n        coords[:,2] = coords[:,2] - (x.size(3) / 2. + 0.5)\n\n    \n    # apply the coordinate transformation\n    new_coords = F.linear(coords, A, b)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,0] = new_coords[:,0] + (x.size(1) / 2. + 0.5)\n        new_coords[:,1] = new_coords[:,1] + (x.size(2) / 2. + 0.5)\n        new_coords[:,2] = new_coords[:,2] + (x.size(3) / 2. + 0.5)\n\n    # map new coordinates using bilinear interpolation\n    x_transformed = F_trilinear_interp3d(x, new_coords)\n\n    return x_transformed\n\n\ndef F_trilinear_interp3d(input, coords):\n    """"""\n    trilinear interpolation of 3D image\n    """"""\n    # take clamp then floor/ceil of x coords\n    x = torch.clamp(coords[:,0], 0, input.size(1)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    # take clamp then floor/ceil of y coords\n    y = torch.clamp(coords[:,1], 0, input.size(2)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n    # take clamp then floor/ceil of z coords\n    z = torch.clamp(coords[:,2], 0, input.size(3)-2)\n    z0 = z.floor()\n    z1 = z0 + 1\n\n    stride = torch.LongTensor(input.stride())[1:]\n    x0_ix = x0.mul(stride[0]).long()\n    x1_ix = x1.mul(stride[0]).long()\n    y0_ix = y0.mul(stride[1]).long()\n    y1_ix = y1.mul(stride[1]).long()\n    z0_ix = z0.mul(stride[2]).long()\n    z1_ix = z1.mul(stride[2]).long()\n\n    input_flat = th_flatten(input)\n\n    vals_000 = input_flat[x0_ix.add(y0_ix).add(z0_ix).detach()]\n    vals_100 = input_flat[x1_ix.add(y0_ix).add(z0_ix).detach()]\n    vals_010 = input_flat[x0_ix.add(y1_ix).add(z0_ix).detach()]\n    vals_001 = input_flat[x0_ix.add(y0_ix).add(z1_ix).detach()]\n    vals_101 = input_flat[x1_ix.add(y0_ix).add(z1_ix).detach()]\n    vals_011 = input_flat[x0_ix.add(y1_ix).add(z1_ix).detach()]\n    vals_110 = input_flat[x1_ix.add(y1_ix).add(z0_ix).detach()]\n    vals_111 = input_flat[x1_ix.add(y1_ix).add(z1_ix).detach()]\n\n    xd = x - x0\n    yd = y - y0\n    zd = z - z0\n    xm = 1 - xd\n    ym = 1 - yd\n    zm = 1 - zd\n\n    x_mapped = (vals_000.mul(xm).mul(ym).mul(zm) +\n                vals_100.mul(xd).mul(ym).mul(zm) +\n                vals_010.mul(xm).mul(yd).mul(zm) +\n                vals_001.mul(xm).mul(ym).mul(zd) +\n                vals_101.mul(xd).mul(ym).mul(zd) +\n                vals_011.mul(xm).mul(yd).mul(zd) +\n                vals_110.mul(xd).mul(yd).mul(zm) +\n                vals_111.mul(xd).mul(yd).mul(zd))\n\n    return x_mapped.view_as(input)\n\n\ndef F_batch_affine3d(x, matrix, center=True):\n    """"""\n\n    x : torch.Tensor\n        shape = (Samples, C, H, W)\n        NOTE: Assume C is always equal to 1!\n    matrix : torch.Tensor\n        shape = (Samples, 6) or (Samples, 2, 3)\n\n    Example\n    -------\n    >>> x = Variable(torch.zeros(3,1,10,10,10))\n    >>> x[:,:,3:7,3:7,3:7] = 1\n    >>> m1 = torch.FloatTensor([[1.2,0,0,0],[0,1.2,0,0],[0,0,1.2,0]])\n    >>> m2 = torch.FloatTensor([[0.8,0,0,0],[0,0.8,0,0],[0,0,0.8,0]])\n    >>> m3 = torch.FloatTensor([[1.0,0,0,3],[0,1.0,0,3],[0,0,1.0,3]])\n    >>> matrix = Variable(torch.stack([m1,m2,m3]))\n    >>> xx = F_batch_affine3d(x,matrix)\n    """"""\n    if matrix.dim() == 2:\n        matrix = matrix.view(-1,3,4)\n\n    A_batch = matrix[:,:3,:3]\n    b_batch = matrix[:,:3,3].unsqueeze(1)\n\n    # make a meshgrid of normal coordinates\n    _coords = th_iterproduct(x.size(2),x.size(3),x.size(4))\n    coords = Variable(_coords.unsqueeze(0).repeat(x.size(0),1,1).float(),\n                requires_grad=False)\n    \n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,:,0] = coords[:,:,0] - (x.size(2) / 2. + 0.5)\n        coords[:,:,1] = coords[:,:,1] - (x.size(3) / 2. + 0.5)\n        coords[:,:,2] = coords[:,:,2] - (x.size(4) / 2. + 0.5)\n    \n    # apply the coordinate transformation\n    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(2) / 2. + 0.5)\n        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(3) / 2. + 0.5)\n        new_coords[:,:,2] = new_coords[:,:,2] + (x.size(4) / 2. + 0.5)\n\n    # map new coordinates using bilinear interpolation\n    x_transformed = F_batch_trilinear_interp3d(x, new_coords)\n\n    return x_transformed\n\n\ndef F_batch_trilinear_interp3d(input, coords):\n    """"""\n    input : torch.Tensor\n        size = (N,H,W,C)\n    coords : torch.Tensor\n        size = (N,H*W*C,2)\n    """"""\n    x = torch.clamp(coords[:,:,0], 0, input.size(2)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    y = torch.clamp(coords[:,:,1], 0, input.size(3)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n    z = torch.clamp(coords[:,:,2], 0, input.size(4)-2)\n    z0 = z.floor()\n    z1 = z0 + 1\n\n    stride = torch.LongTensor(input.stride())\n    x0_ix = x0.mul(stride[2]).long()\n    x1_ix = x1.mul(stride[2]).long()\n    y0_ix = y0.mul(stride[3]).long()\n    y1_ix = y1.mul(stride[3]).long()\n    z0_ix = z0.mul(stride[4]).long()\n    z1_ix = z1.mul(stride[4]).long()\n\n    input_flat = input.contiguous().view(input.size(0),-1)\n\n    vals_000 = input_flat.gather(1,x0_ix.add(y0_ix).add(z0_ix).detach())\n    vals_100 = input_flat.gather(1,x1_ix.add(y0_ix).add(z0_ix).detach())\n    vals_010 = input_flat.gather(1,x0_ix.add(y1_ix).add(z0_ix).detach())\n    vals_001 = input_flat.gather(1,x0_ix.add(y0_ix).add(z1_ix).detach())\n    vals_101 = input_flat.gather(1,x1_ix.add(y0_ix).add(z1_ix).detach())\n    vals_011 = input_flat.gather(1,x0_ix.add(y1_ix).add(z1_ix).detach())\n    vals_110 = input_flat.gather(1,x1_ix.add(y1_ix).add(z0_ix).detach())\n    vals_111 = input_flat.gather(1,x1_ix.add(y1_ix).add(z1_ix).detach())\n\n    xd = x - x0\n    yd = y - y0\n    zd = z - z0\n    xm = 1 - xd\n    ym = 1 - yd\n    zm = 1 - zd\n\n    x_mapped = (vals_000.mul(xm).mul(ym).mul(zm) +\n                vals_100.mul(xd).mul(ym).mul(zm) +\n                vals_010.mul(xm).mul(yd).mul(zm) +\n                vals_001.mul(xm).mul(ym).mul(zd) +\n                vals_101.mul(xd).mul(ym).mul(zd) +\n                vals_011.mul(xm).mul(yd).mul(zd) +\n                vals_110.mul(xd).mul(yd).mul(zm) +\n                vals_111.mul(xd).mul(yd).mul(zd))\n\n    return x_mapped.view_as(input)\n\n\n'"
torchsample/modules/__init__.py,0,b'from __future__ import absolute_import\n\nfrom .module_trainer import ModuleTrainer\n'
torchsample/modules/_utils.py,2,"b'\nimport datetime\nimport warnings\n\ntry:\n    from inspect import signature\nexcept:\n    warnings.warn(\'inspect.signature not available... \'\n        \'you should upgrade to Python 3.x\')\n\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom ..metrics import Metric, CategoricalAccuracy, BinaryAccuracy\nfrom ..initializers import GeneralInitializer\n\ndef _add_regularizer_to_loss_fn(loss_fn, \n                                regularizer_container):\n    def new_loss_fn(output_batch, target_batch):\n        return loss_fn(output_batch, target_batch) + regularizer_container.get_value()\n    return new_loss_fn\n\ndef _is_iterable(x):\n    return isinstance(x, (tuple, list))\ndef _is_tuple_or_list(x):\n    return isinstance(x, (tuple, list))\n\ndef _parse_num_inputs_and_targets_from_loader(loader):\n    """""" NOT IMPLEMENTED """"""\n    #batch = next(iter(loader))\n    num_inputs = loader.dataset.num_inputs\n    num_targets = loader.dataset.num_targets\n    return num_inputs, num_targets\n\ndef _parse_num_inputs_and_targets(inputs, targets=None):\n    if isinstance(inputs, (list, tuple)):\n        num_inputs = len(inputs)\n    else:\n        num_inputs = 1\n    if targets is not None:\n        if isinstance(targets, (list, tuple)):\n            num_targets = len(targets)\n        else:\n            num_targets = 1\n    else:\n        num_targets = 0\n    return num_inputs, num_targets\n\ndef _standardize_user_data(inputs, targets=None):\n    if not isinstance(inputs, (list,tuple)):\n        inputs = [inputs]\n    if targets is not None:\n        if not isinstance(targets, (list,tuple)):\n            targets = [targets]\n        return inputs, targets\n    else:\n        return inputs\n\ndef _validate_metric_input(metric):\n    if isinstance(metric, str):\n        if metric.upper() == \'CATEGORICAL_ACCURACY\' or metric.upper() == \'ACCURACY\':\n            return CategoricalAccuracy()\n        elif metric.upper() == \'BINARY_ACCURACY\':\n            return BinaryAccuracy()\n        else:\n            raise ValueError(\'Invalid metric string input - must match pytorch function.\')\n    elif isinstance(metric, Metric):\n        return metric\n    else:\n        raise ValueError(\'Invalid metric input\')\n\ndef _validate_loss_input(loss):\n    dir_f = dir(F)\n    loss_fns = [d.lower() for d in dir_f]\n    if isinstance(loss, str):\n        if loss.lower() == \'unconstrained\':\n            return lambda x: x\n        elif loss.lower() == \'unconstrained_sum\':\n            return lambda x: x.sum()\n        elif loss.lower() == \'unconstrained_mean\':\n            return lambda x: x.mean()\n        else:\n            try:\n                str_idx = loss_fns.index(loss.lower())\n            except:\n                raise ValueError(\'Invalid loss string input - must match pytorch function.\')\n            return getattr(F, dir(F)[str_idx])\n    elif callable(loss):\n        return loss\n    else:\n        raise ValueError(\'Invalid loss input\')\n\ndef _validate_optimizer_input(optimizer):\n    dir_optim = dir(optim)\n    opts = [o.lower() for o in dir_optim]\n    if isinstance(optimizer, str):\n        try:\n            str_idx = opts.index(optimizer.lower())    \n        except:\n            raise ValueError(\'Invalid optimizer string input - must match pytorch function.\')\n        return getattr(optim, dir_optim[str_idx])\n    elif hasattr(optimizer, \'step\') and hasattr(optimizer, \'zero_grad\'):\n        return optimizer\n    else:\n        raise ValueError(\'Invalid optimizer input\')\n\ndef _validate_initializer_input(initializer):\n    if isinstance(initializer, str):\n        try:\n            initializer = GeneralInitializer(initializer)\n        except:\n            raise ValueError(\'Invalid initializer string input - must match pytorch function.\')\n        return initializer\n    elif callable(initializer):\n        return initializer\n    else:\n        raise ValueError(\'Invalid optimizer input\')\n\ndef _get_current_time():\n    return datetime.datetime.now().strftime(""%B %d, %Y - %I:%M%p"")\n\ndef _nb_function_args(fn):\n    return len(signature(fn).parameters)'"
torchsample/modules/module_trainer.py,3,"b'""""""\nModuleTrainer for high level training on Pytorch models\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport warnings\nimport functools\nimport math\nfrom collections import OrderedDict\n\nimport torch as th\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n# local imports\nfrom ._utils import (_validate_loss_input, _validate_metric_input,\n                     _validate_optimizer_input, _validate_initializer_input,\n                     _standardize_user_data, _parse_num_inputs_and_targets,\n                     _is_tuple_or_list, _parse_num_inputs_and_targets_from_loader,\n                     _add_regularizer_to_loss_fn)\n\nfrom ..callbacks import CallbackContainer, History, TQDM\nfrom ..regularizers import RegularizerContainer, RegularizerCallback\nfrom ..initializers import InitializerContainer\nfrom ..constraints import ConstraintContainer, ConstraintCallback\nfrom ..metrics import MetricContainer, MetricCallback\n\n\nclass ModuleTrainer(object):\n\n    def __init__(self, model):\n        """"""\n        ModelTrainer for high-level training of Pytorch models\n\n        Major Parts\n        -----------\n        - optimizer(s)\n        - loss(es)\n        - regularizers\n        - initializers\n        - constraints\n        - metrics\n        - callbacks\n        """"""\n        if not isinstance(model, nn.Module):\n            raise ValueError(\'model argument must inherit from torch.nn.Module\')\n        self.model = model\n\n        # callbacks\n        self._callbacks = []\n\n        # regularizers\n        self._regularizers = []\n        self._has_regularizers = False\n\n        # initializers\n        self._initializers = []\n\n        # constraints\n        self._constraints = []\n        self._has_constraints = False\n\n        # metrics\n        self._metrics = []\n        self._has_metrics = False\n\n        # transforms\n        self._transforms = []\n        self._has_transforms = False\n\n        # losses\n        self._loss = None\n        self._loss_fn = None\n\n        # other properties\n        self._in_train_loop = False\n        self._stop_training = False\n\n    def set_loss(self, loss):\n        self._loss = loss\n        if _is_tuple_or_list(loss):\n            self._loss_fn = [_validate_loss_input(l) for l in loss]\n        else:\n            self._loss_fn = _validate_loss_input(loss)\n\n    def set_optimizer(self, optimizer, **kwargs):\n        if type(optimizer) is type or isinstance(optimizer, str):\n            if \'parameters\' in kwargs:\n                parameters = kwargs[\'parameters\']\n            else:\n                parameters = self.model.parameters()\n\n            optimizer = _validate_optimizer_input(optimizer)\n            self._optimizer = optimizer(parameters, **kwargs)\n        else:\n            self._optimizer = optimizer\n\n    def set_callbacks(self, callbacks):\n        if not _is_tuple_or_list(callbacks):\n            callbacks = [callbacks]\n        self._callbacks = [self.history] + callbacks\n\n    def set_regularizers(self, regularizers):\n        regularizers = [regularizers] if not _is_tuple_or_list(regularizers) else regularizers\n        self._regularizers = regularizers\n        self._has_regularizers = True\n\n    def set_initializers(self, initializers):\n        initializers = [initializers] if not _is_tuple_or_list(initializers) else initializers\n        initializers = [_validate_initializer_input(it) for it in initializers]\n        self._initializers = initializers\n\n    def set_constraints(self, constraints):\n        constraints = [constraints] if not _is_tuple_or_list(constraints) else constraints\n        self._has_constraints = True\n        self._constraints = constraints\n\n    def set_metrics(self, metrics):\n        metrics = [metrics] if not _is_tuple_or_list(metrics) else metrics\n        metrics = [_validate_metric_input(m) for m in metrics]\n        self._has_metrics = True\n        self._metrics = metrics\n\n    def set_transforms(self, transforms):\n        if not _is_tuple_or_list(transforms):\n            transforms = (transforms, lambda x: x, lambda x,y: (x,y))\n        if len(transforms) == 1:\n            transforms = (transforms, lambda x: x, lambda x,y: (x,y))\n        elif len(transforms) == 2:\n            transforms = (transforms, transforms, lambda x,y: (x,y))\n\n        self._has_input_transform = transforms[0] is not None\n        self._has_target_transform = transforms[1] is not None\n        self._has_co_transform = transforms[2] is not None\n\n        self._has_transforms = True\n        self._transforms = transforms\n\n    def compile(self,\n                optimizer,\n                loss,\n                callbacks=None,\n                regularizers=None,\n                initializers=None,\n                constraints=None,\n                metrics=None,\n                transforms=None):\n        self.set_optimizer(optimizer)\n        self.set_loss(loss)\n\n        if regularizers is not None:\n            self.set_regularizers(regularizers)\n            self.regularizer_container = RegularizerContainer(self._regularizers)\n            self.regularizer_container.register_forward_hooks(self.model)\n        else:\n            self._has_regularizers = False\n\n        self.history = History(self)\n        self._callbacks = [self.history]\n        if callbacks is not None:\n            self.set_callbacks(callbacks)\n\n\n        if initializers is not None:\n            self.set_initializers(initializers)\n            self.initializer_container = InitializerContainer(self._initializers)\n            # actually initialize the model\n            self.initializer_container.apply(self.model)\n\n        if constraints is not None:\n            self.set_constraints(constraints)\n            self.constraint_container = ConstraintContainer(self._constraints)\n            self.constraint_container.register_constraints(self.model)\n        else:\n            self._has_constraints = False\n\n        if metrics is not None:\n            self.set_metrics(metrics)\n            self.metric_container = MetricContainer(self._metrics)\n        else:\n            self._has_metrics = False\n        \n        if transforms is not None:\n            self.set_transforms(transforms)\n        else:\n            self._has_transforms = False\n\n    def fit(self,\n            inputs,\n            targets=None,\n            val_data=None,\n            num_epoch=100,\n            batch_size=32,\n            shuffle=False,\n            cuda_device=-1,\n            verbose=1):\n        """"""\n        Fit a model on in-memory tensors using ModuleTrainer\n        """"""\n        self.model.train(True)\n        # ----------------------------------------------------------------------\n        num_inputs, num_targets = _parse_num_inputs_and_targets(inputs, targets)\n        len_inputs = len(inputs) if not _is_tuple_or_list(inputs) else len(inputs[0])\n        \n        if val_data is not None:\n            if num_targets == 0:\n                val_data = (val_data, None)\n            if len(val_data) != 2:\n                raise Exception(\'val_data must be a 2-tuple\')\n            num_val_inputs, num_val_targets = _parse_num_inputs_and_targets(val_data[0], val_data[1])\n            if (num_inputs != num_val_inputs) or (num_targets != num_val_targets):\n                raise Exception(\'The number of input/target tensors must be the same for training and validation data\\n\'\n                                 \'Num Input tensors: (%i train, %i val), Num Target tensors: (%i train, %i val)\' % (num_inputs, num_val_inputs, num_targets, num_val_targets) )\n            val_inputs, val_targets = val_data\n        has_val_data = val_data is not None\n        num_batches = int(math.ceil(len_inputs / batch_size))\n        # ----------------------------------------------------------------------\n\n        fit_helper = _get_helper(self, num_inputs, num_targets)\n        fit_loss_fn = fit_helper.get_partial_loss_fn(self._loss_fn)\n        fit_forward_fn = fit_helper.get_partial_forward_fn(self.model)\n\n        with TQDM() as pbar:\n            tmp_callbacks = []\n            if verbose > 0:\n                tmp_callbacks.append(pbar)\n            if self._has_regularizers:\n                tmp_callbacks.append(RegularizerCallback(self.regularizer_container))\n                fit_loss_fn = _add_regularizer_to_loss_fn(fit_loss_fn,\n                                                          self.regularizer_container)\n            if self._has_constraints:\n                tmp_callbacks.append(ConstraintCallback(self.constraint_container))\n            if self._has_metrics:\n                self.metric_container.set_helper(fit_helper)\n                tmp_callbacks.append(MetricCallback(self.metric_container))\n\n            callback_container = CallbackContainer(self._callbacks+tmp_callbacks)\n            callback_container.set_trainer(self)\n            callback_container.on_train_begin({\'batch_size\': batch_size,\n                                               \'num_batches\': num_batches,\n                                               \'num_epoch\': num_epoch,\n                                               \'has_val_data\': has_val_data,\n                                               \'has_regularizers\': self._has_regularizers,\n                                               \'has_metrics\': self._has_metrics})\n\n            for epoch_idx in range(num_epoch):\n                epoch_logs = {}\n                callback_container.on_epoch_begin(epoch_idx, epoch_logs)\n\n                if shuffle:\n                    inputs, targets = fit_helper.shuffle_arrays(inputs, targets)\n\n                for batch_idx in range(num_batches):\n                    batch_logs = {}\n                    callback_container.on_batch_begin(batch_idx, batch_logs)\n\n                    input_batch, target_batch = fit_helper.grab_batch(batch_idx, batch_size, inputs, targets)\n                    if cuda_device >= 0:\n                        input_batch, target_batch = fit_helper.move_to_cuda(cuda_device, input_batch, target_batch)\n                    if self._has_transforms:\n                        input_batch, target_batch = fit_helper.apply_transforms(self._transforms, input_batch, target_batch)\n\n                    # ---------------------------------------------\n                    self._optimizer.zero_grad()\n                    output_batch = fit_forward_fn(input_batch)\n                    loss = fit_loss_fn(output_batch, target_batch)\n                    loss.backward()\n                    self._optimizer.step()\n                    # ---------------------------------------------\n\n                    if self._has_regularizers:\n                        batch_logs[\'reg_loss\'] = self.regularizer_container.current_value\n                    if self._has_metrics:\n                        metrics_logs = self.metric_container(output_batch, target_batch)\n                        batch_logs.update(metrics_logs)\n\n                    batch_logs[\'loss\'] = loss.data[0]\n                    callback_container.on_batch_end(batch_idx, batch_logs)\n\n                if has_val_data:\n                    self._in_train_loop = True\n                    val_epoch_logs = self.evaluate(val_inputs,\n                                                   val_targets,\n                                                   batch_size=batch_size,\n                                                   cuda_device=cuda_device,\n                                                   verbose=verbose)\n                    self._in_train_loop = False\n                    self.history.batch_metrics.update(val_epoch_logs)\n\n                callback_container.on_epoch_end(epoch_idx, epoch_logs)\n\n                if self._stop_training:\n                    break\n        self.model.train(mode=False)\n\n    def fit_loader(self,\n                   loader,\n                   val_loader=None,\n                   num_epoch=100,\n                   cuda_device=-1,\n                   verbose=1):\n        """"""\n        Fit a model on in-memory tensors using ModuleTrainer\n        """"""\n        self.model.train(mode=True)\n        # ----------------------------------------------------------------------\n        num_inputs = loader.dataset.num_inputs\n        num_targets = loader.dataset.num_targets\n        len_inputs = len(loader.dataset)\n        batch_size = loader.batch_size\n\n        if val_loader is not None:\n            num_val_inputs = val_loader.dataset.num_inputs\n            num_val_targets = val_loader.dataset.num_targets\n            if (num_inputs != num_val_inputs) or (num_targets != num_val_targets):\n                raise ValueError(\'num_inputs != num_val_inputs or num_targets != num_val_targets\')\n        has_val_data = val_loader is not None\n        num_batches = int(math.ceil(len_inputs / batch_size))\n        # ----------------------------------------------------------------------\n\n        fit_helper = _get_helper(self, num_inputs, num_targets)\n        fit_loss_fn = fit_helper.get_partial_loss_fn(self._loss_fn)\n        fit_forward_fn = fit_helper.get_partial_forward_fn(self.model)\n\n        with TQDM() as pbar:\n            tmp_callbacks = []\n            if verbose > 0:\n                tmp_callbacks.append(pbar)\n            if self._has_regularizers:\n                tmp_callbacks.append(RegularizerCallback(self.regularizer_container))\n                fit_loss_fn = _add_regularizer_to_loss_fn(fit_loss_fn,\n                                                            self.regularizer_container)\n            if self._has_constraints:\n                tmp_callbacks.append(ConstraintCallback(self.constraint_container))\n            if self._has_metrics:\n                self.metric_container.set_helper(fit_helper)\n                tmp_callbacks.append(MetricCallback(self.metric_container))\n\n            callback_container = CallbackContainer(self._callbacks+tmp_callbacks)\n            callback_container.set_trainer(self)\n            callback_container.on_train_begin({\'batch_size\': loader.batch_size,\n                                               \'num_batches\': num_batches,\n                                               \'num_epoch\': num_epoch,\n                                               \'has_val_data\': has_val_data,\n                                               \'has_regularizers\': self._has_regularizers,\n                                               \'has_metrics\': self._has_metrics})\n\n            for epoch_idx in range(num_epoch):\n                epoch_logs = {}\n                callback_container.on_epoch_begin(epoch_idx, epoch_logs)\n\n                loader_iter = iter(loader)\n                for batch_idx in range(num_batches):\n\n                    batch_logs = {}\n                    callback_container.on_batch_begin(batch_idx, batch_logs)\n\n                    input_batch, target_batch = fit_helper.grab_batch_from_loader(loader_iter)\n                    if cuda_device >= 0:\n                        input_batch, target_batch = fit_helper.move_to_cuda(cuda_device, input_batch, target_batch)\n                    \n                    # ---------------------------------------------\n                    self._optimizer.zero_grad()\n                    output_batch = fit_forward_fn(input_batch)\n                    loss = fit_loss_fn(output_batch, target_batch)\n                    loss.backward()\n                    self._optimizer.step()\n                    # ---------------------------------------------\n\n                    if self._has_regularizers:\n                        batch_logs[\'reg_loss\'] = self.regularizer_container.current_value\n                    if self._has_metrics:\n                        metrics_logs = self.metric_container(output_batch, target_batch)\n                        batch_logs.update(metrics_logs)\n\n                    batch_logs[\'loss\'] = loss.data[0]\n                    callback_container.on_batch_end(batch_idx, batch_logs)\n\n                if has_val_data:\n                    self._in_train_loop = True\n                    val_epoch_logs = self.evaluate_loader(val_loader,\n                                                          cuda_device=cuda_device,\n                                                          verbose=verbose)\n                    self._in_train_loop = False\n                    self.history.batch_metrics.update(val_epoch_logs)\n\n                callback_container.on_epoch_end(epoch_idx, epoch_logs)\n\n                if self._stop_training:\n                    break\n        self.model.train(mode=False)\n\n    def predict(self,\n                inputs,\n                batch_size=32,\n                cuda_device=-1,\n                verbose=1):\n        self.model.train(mode=True)\n        # --------------------------------------------------------\n        num_inputs, _ = _parse_num_inputs_and_targets(inputs, None)\n        len_inputs = len(inputs) if not _is_tuple_or_list(inputs) else len(inputs[0])\n        num_batches = int(math.ceil(len_inputs / batch_size))\n        # --------------------------------------------------------\n\n        predict_helper = _get_helper(self, num_inputs, num_targets=0)\n        pred_forward_fn = predict_helper.get_partial_forward_fn(self.model)\n        \n        for batch_idx in range(num_batches):\n            input_batch, _ = predict_helper.grab_batch(batch_idx, batch_size, inputs, None, volatile=True)\n            if cuda_device >= 0:\n                inputs = predict_helper.move_to_cuda(cuda_device, inputs)\n            output_batch = pred_forward_fn(input_batch)\n\n            if batch_idx == 0:\n                len_outputs = 1 if not _is_tuple_or_list(output_batch) else len(output_batch)\n                prediction_lists = [[] for _ in range(len_outputs)]\n\n            if len_outputs == 1:\n                prediction_lists[0].append(output_batch)\n            else:\n                for out_idx in range(len_outputs):\n                    prediction_lists[out_idx].append(output_batch[out_idx])\n            \n        final_pred_list = [th.cat(pred_list,0) for pred_list in prediction_lists]\n        self.model.train(mode=True)\n        return final_pred_list if len_outputs > 1 else final_pred_list[0]\n\n    def predict_loader(self,\n                       loader,\n                       cuda_device=-1,\n                       verbose=1):\n        self.model.train(mode=False)\n        # --------------------------------------------------------\n        num_inputs, num_targets = _parse_num_inputs_and_targets_from_loader(loader)\n        batch_size = loader.batch_size\n        len_inputs = len(loader.dataset)\n        num_batches = int(math.ceil(len_inputs / batch_size))\n        # --------------------------------------------------------\n\n        predict_helper = _get_helper(self, num_inputs, num_targets=0)\n        pred_forward_fn = predict_helper.get_partial_forward_fn(self.model)\n        \n        for batch_idx in range(num_batches):\n            input_batch, _ = predict_helper.grab_batch_from_loader(loader, volatile=True)\n            output_batch = pred_forward_fn(input_batch)\n\n            if batch_idx == 0:\n                len_outputs = 1 if not _is_tuple_or_list(output_batch) else len(output_batch)\n                prediction_lists = [[] for _ in range(len_outputs)]\n\n            if len_outputs == 1:\n                prediction_lists[0].append(output_batch)\n            else:\n                for out_idx in range(len_outputs):\n                    prediction_lists[out_idx].append(output_batch[out_idx])\n            \n        final_pred_list = [th.cat(pred_list,0) for pred_list in prediction_lists]\n        self.model.train(mode=True)\n        return final_pred_list if len_outputs > 1 else final_pred_list[0]\n\n    def evaluate(self,\n                 inputs,\n                 targets=None,\n                 batch_size=32,\n                 cuda_device=-1,\n                 verbose=1):\n        self.model.train(mode=False)\n        num_inputs, num_targets = _parse_num_inputs_and_targets(inputs, targets)\n        len_inputs = len(inputs) if not _is_tuple_or_list(inputs) else len(inputs[0])\n        num_batches = int(math.ceil(len_inputs / batch_size))\n\n        evaluate_helper = _get_helper(self, num_inputs, num_targets)\n        eval_loss_fn = evaluate_helper.get_partial_loss_fn(self._loss_fn)\n        eval_forward_fn = evaluate_helper.get_partial_forward_fn(self.model)\n        eval_logs= {\'val_loss\': 0.}\n\n        samples_seen = 0\n        for batch_idx in range(num_batches):\n            input_batch, target_batch = evaluate_helper.grab_batch(batch_idx, batch_size, inputs, targets, volatile=True)\n            if cuda_device >= 0:\n                input_batch, target_batch = evaluate_helper.move_to_cuda(cuda_device, input_batch, target_batch)\n\n            self._optimizer.zero_grad()\n            output_batch = eval_forward_fn(input_batch)\n            loss = eval_loss_fn(output_batch, target_batch)\n            \n            samples_seen += batch_size\n            eval_logs[\'val_loss\'] = (samples_seen*eval_logs[\'val_loss\'] + loss.data[0]*batch_size) / (samples_seen+batch_size)\n\n        if self._in_train_loop:\n            return eval_logs\n        else:\n            return eval_logs[\'val_loss\']\n        self.model.train(mode=True)\n\n    def evaluate_loader(self,\n                        loader,\n                        cuda_device=-1,\n                        verbose=1):\n        self.model.train(mode=False)\n        num_inputs, num_targets = _parse_num_inputs_and_targets_from_loader(loader)\n        batch_size = loader.batch_size\n        len_inputs = len(loader.dataset)\n        num_batches = int(math.ceil(len_inputs / batch_size))\n\n        evaluate_helper = _get_helper(self, num_inputs, num_targets)\n        eval_loss_fn = evaluate_helper.get_partial_loss_fn(self._loss_fn)\n        eval_forward_fn = evaluate_helper.get_partial_forward_fn(self.model)\n        eval_logs= {\'val_loss\': 0.}\n        loader_iter = iter(loader)\n\n        samples_seen = 0\n        for batch_idx in range(num_batches):\n            input_batch, target_batch = evaluate_helper.grab_batch_from_loader(loader_iter, volatile=True)\n            if cuda_device >= 0:\n                input_batch, target_batch = evaluate_helper.move_to_cuda(cuda_device, input_batch, target_batch)\n\n            self._optimizer.zero_grad()\n            output_batch = eval_forward_fn(input_batch)\n            loss = eval_loss_fn(output_batch, target_batch)\n            \n            samples_seen += batch_size\n            eval_logs[\'val_loss\'] = (samples_seen*eval_logs[\'val_loss\'] + loss.data[0]*batch_size) / (samples_seen+batch_size)\n\n        if self._in_train_loop:\n            return eval_logs\n        else:\n            return eval_logs[\'val_loss\']\n        self.model.train(mode=True)\n\n    def summary(self, input_size):\n        def register_hook(module):\n            def hook(module, input, output):\n                class_name = str(module.__class__).split(\'.\')[-1].split(""\'"")[0]\n                module_idx = len(summary)\n\n                m_key = \'%s-%i\' % (class_name, module_idx+1)\n                summary[m_key] = OrderedDict()\n                summary[m_key][\'input_shape\'] = list(input[0].size())\n                summary[m_key][\'input_shape\'][0] = -1\n                summary[m_key][\'output_shape\'] = list(output.size())\n                summary[m_key][\'output_shape\'][0] = -1\n\n                params = 0\n                if hasattr(module, \'weight\'):\n                    params += th.prod(th.LongTensor(list(module.weight.size())))\n                    if module.weight.requires_grad:\n                        summary[m_key][\'trainable\'] = True\n                    else:\n                        summary[m_key][\'trainable\'] = False\n                if hasattr(module, \'bias\'):\n                    params +=  th.prod(th.LongTensor(list(module.bias.size())))\n                summary[m_key][\'nb_params\'] = params\n\n            if not isinstance(module, nn.Sequential) and \\\n               not isinstance(module, nn.ModuleList) and \\\n               not (module == self.model):\n                hooks.append(module.register_forward_hook(hook))\n\n        # create properties\n        summary = OrderedDict()\n        hooks = []\n        # register forward hooks\n        self.model.apply(register_hook)\n\n        if isinstance(input_size[0], (list, tuple)):\n            x = [Variable(th.rand(1,*in_size)) for in_size in input_size]\n            self.model(*x)\n        else:\n            x = Variable(th.rand(1,*input_size))\n            self.model(x)\n\n        # remove these hooks\n        for h in hooks:\n            h.remove()\n\n        return summary\n\n\ndef _get_helper(trainer, num_inputs, num_targets):\n    if (num_inputs == 1) and (num_targets == 1):\n        helper = SingleInput_SingleTarget_Helper()\n\n    elif (num_inputs == 1) and (num_targets > 1):\n        # use same loss function for all targets if multiple loss fns not explicitly given\n        if not _is_tuple_or_list(trainer._loss_fn):\n            trainer._loss_fn = [trainer._loss_fn] * num_targets\n        else:\n            if len(trainer._loss_fn) != num_targets:\n                raise ValueError(\'must give one loss function for every input if you give multiple\')\n        helper = SingleInput_MultiTarget_Helper()\n\n    elif (num_inputs == 1) and (num_targets == 0):\n        helper = SingleInput_NoTarget_Helper()\n\n    elif (num_inputs > 1) and (num_targets == 1):\n        helper = MultiInput_SingleTarget_Helper()\n\n    elif (num_inputs > 1) and (num_targets > 1):\n        # use same loss function for all targets if multiple loss fns not explicitly given\n        if not _is_tuple_or_list(trainer._loss_fn):\n            trainer._loss_fn = [trainer._loss_fn] * num_targets\n        else:\n            if len(trainer._loss_fn) != num_targets:\n                raise ValueError(\'must give one loss function for every input if you give multiple\')\n        helper = MultiInput_MultiTarget_Helper()\n\n    elif (num_inputs > 1) and (num_targets == 0):\n        helper = MultiInput_NoTarget_Helper()\n\n    return helper\n\n\nclass SingleInput_SingleTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets):\n        inputs = inputs.cuda(cuda_device)\n        targets = targets.cuda(cuda_device)\n        return inputs, targets\n    def shuffle_arrays(self, inputs, targets):\n        rand_indices = th.randperm(len(inputs))\n        inputs = inputs[rand_indices]\n        targets = targets[rand_indices]\n        return inputs, targets\n    def grab_batch(self, batch_idx, batch_size, inputs, targets, volatile=False):\n        input_batch = Variable(inputs[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n        target_batch = Variable(targets[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n        return input_batch, target_batch\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch, target_batch = next(loader_iter)\n        return Variable(input_batch, volatile=volatile), Variable(target_batch, volatile=volatile)\n    def apply_transforms(self, tforms, input_batch, target_batch):\n        input_batch = tforms[0](input_batch)\n        target_batch = tforms[1](target_batch)\n        input_batch, target_batch = tforms[2](input_batch, target_batch)\n        return input_batch, target_batch\n    def forward_pass(self, input_batch, model):\n        return model(input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return loss_fn(output_batch, target_batch)\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n        #def new_loss_fn(output_batch, target_batch):\n        #    return self.calculate_loss(output_batch, target_batch, loss_fn)\n        #return new_loss_fn\n\n\nclass SingleInput_MultiTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets):\n        inputs = inputs.cuda(cuda_device)\n        targets = [target_.cuda(cuda_device) for target_ in targets]\n        return inputs, targets\n    def shuffle_arrays(self, inputs, targets):\n        rand_indices = th.randperm(len(inputs))\n        inputs = inputs[rand_indices]\n        targets = [target_[rand_indices] for target_ in targets]\n        return inputs, targets\n    def grab_batch(self, batch_idx, batch_size, inputs, targets, volatile=False):\n        input_batch = Variable(inputs[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n        target_batch = [Variable(target_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n                        for target_ in targets]\n        return input_batch, target_batch\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch, target_batch = next(loader_iter)\n        return Variable(input_batch, volatile=volatile), [Variable(target_, volatile=volatile) for target_ in target_batch]\n    def apply_transforms(self, tforms, input_batch, target_batch):\n        input_batch = tforms[0](input_batch)\n        target_batch = [tforms[1](target_) for target_ in target_batch]\n        return input_batch, target_batch\n    def forward_pass(self, input_batch, model):\n        return model(input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return sum([loss_fn[idx](output_batch[idx], target_batch[idx]) \n                    for idx in range(len(output_batch))])\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n\nclass MultiInput_SingleTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets):\n        inputs = [input_.cuda(cuda_device) for input_ in inputs] \n        targets = targets.cuda(cuda_device)\n        return inputs, targets\n    def shuffle_arrays(self, inputs, targets):\n        rand_indices = th.randperm(len(inputs))\n        inputs = [input_[rand_indices] for input_ in inputs]\n        targets = targets[rand_indices]\n        return inputs, targets\n    def grab_batch(self, batch_idx, batch_size, inputs, targets, volatile=False):\n        input_batch = [Variable(input_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n                       for input_ in inputs]\n        target_batch = Variable(targets[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n        return input_batch, target_batch\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch, target_batch = next(loader_iter)\n        return [Variable(input_, volatile=volatile) for input_ in input_batch], Variable(target_batch, volatile=volatile)\n    def apply_transforms(self, tforms, input_batch, target_batch):\n        input_batch = [tforms[0](input_) for input_ in input_batch]\n        target_batch = tforms[1](target_batch)\n        return input_batch, target_batch\n    def forward_pass(self, input_batch, model):\n        return model(*input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return loss_fn(output_batch, target_batch)\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n\nclass MultiInput_MultiTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets):\n        inputs = [input_.cuda(cuda_device) for input_ in inputs] \n        targets = [target_.cuda(cuda_device) for target_ in targets]\n        return inputs, targets\n    def shuffle_arrays(self, inputs, targets):\n        rand_indices = th.randperm(len(inputs))\n        inputs = [input_[rand_indices] for input_ in inputs]\n        targets = [input_[rand_indices] for input_ in inputs]\n        return inputs, targets\n    def grab_batch(self, batch_idx, batch_size, inputs, targets, volatile=False):\n        input_batch = [Variable(input_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n                       for input_ in inputs]\n        target_batch = [Variable(target_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n                       for target_ in targets]\n        return input_batch, target_batch\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch, target_batch = next(loader_iter)\n        return [Variable(input_, volatile=volatile) for input_ in input_batch], [Variable(target_, volatile=volatile) for target_ in target_batch]\n    def apply_transforms(self, tforms, input_batch, target_batch):\n        input_batch = [tforms[0](input_) for input_ in input_batch]\n        target_batch = [tforms[1](target_) for target_ in target_batch]\n        return input_batch, target_batch\n    def forward_pass(self, input_batch, model):\n        return model(*input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return sum([loss_fn[idx](output_batch[idx], target_batch[idx]) \n                    for idx in range(len(output_batch))])\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n\nclass SingleInput_NoTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets=None):\n        inputs = inputs.cuda(cuda_device)\n        return inputs, None\n    def shuffle_arrays(self, inputs, targets=None):\n        rand_indices = th.randperm(len(inputs))\n        inputs = inputs[rand_indices]\n        return inputs, None\n    def grab_batch(self, batch_idx, batch_size, inputs, targets=None, volatile=False):\n        input_batch = Variable(inputs[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n        return input_batch, None\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch = next(loader_iter)\n        return Variable(input_batch, volatile=volatile), None\n    def apply_transforms(self, tforms, input_batch, target_batch=None):\n        input_batch = tforms[0](input_batch)\n        return input_batch, None\n    def forward_pass(self, input_batch, model):\n        return model(input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return loss_fn(output_batch)\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n\nclass MultiInput_NoTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets=None):\n        inputs = [input_.cuda(cuda_device) for input_ in inputs]\n        return inputs, None\n    def shuffle_arrays(self, inputs, targets=None):\n        rand_indices = th.randperm(len(inputs))\n        inputs = [input_[rand_indices] for input_ in inputs]\n        return inputs, None\n    def grab_batch(self, batch_idx, batch_size, inputs, targets=None, volatile=False):\n        input_batch = [Variable(input_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n                       for input_ in inputs]\n        return input_batch, None\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch = next(loader_iter)\n        return [Variable(input_, volatile=volatile) for input_ in input_batch], None\n    def apply_transforms(self, tforms, input_batch, target_batch=None):\n        input_batch = [tforms[0](input_) for input_ in input_batch]\n        return input_batch, None\n    def forward_pass(self, input_batch, model):\n        return model(*input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return loss_fn(output_batch)\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n'"
torchsample/transforms/__init__.py,0,b'\nfrom __future__ import absolute_import\n\nfrom .affine_transforms import *\nfrom .image_transforms import *\nfrom .tensor_transforms import *'
torchsample/transforms/affine_transforms.py,0,"b'""""""\nAffine transforms implemented on torch tensors, and\nrequiring only one interpolation\n""""""\n\nimport math\nimport random\nimport torch as th\n\nfrom ..utils import th_affine2d, th_random_choice\n\n\nclass RandomAffine(object):\n\n    def __init__(self, \n                 rotation_range=None, \n                 translation_range=None,\n                 shear_range=None, \n                 zoom_range=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Perform an affine transforms with various sub-transforms, using\n        only one interpolation and without having to instantiate each\n        sub-transform individually.\n\n        Arguments\n        ---------\n        rotation_range : one integer or float\n            image will be rotated randomly between (-degrees, degrees) \n\n        translation_range : a float or a tuple/list with 2 floats between [0, 1)\n            first value:\n                image will be horizontally shifted between \n                (-height_range * height_dimension, height_range * height_dimension)\n            second value:\n                Image will be vertically shifted between \n                (-width_range * width_dimension, width_range * width_dimension)\n\n        shear_range : float\n            image will be sheared randomly between (-degrees, degrees)\n\n        zoom_range : list/tuple with two floats between [0, infinity).\n            first float should be less than the second\n            lower and upper bounds on percent zoom. \n            Anything less than 1.0 will zoom in on the image, \n            anything greater than 1.0 will zoom out on the image.\n            e.g. (0.7, 1.0) will only zoom in, \n                 (1.0, 1.4) will only zoom out,\n                 (0.7, 1.4) will randomly zoom in or out\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        """"""\n        self.transforms = []\n        if rotation_range is not None:\n            rotation_tform = RandomRotate(rotation_range, lazy=True)\n            self.transforms.append(rotation_tform)\n\n        if translation_range is not None:\n            translation_tform = RandomTranslate(translation_range, lazy=True)\n            self.transforms.append(translation_tform)\n\n        if shear_range is not None:\n            shear_tform = RandomShear(shear_range, lazy=True)\n            self.transforms.append(shear_tform) \n\n        if zoom_range is not None:\n            zoom_tform = RandomZoom(zoom_range, lazy=True)\n            self.transforms.append(zoom_tform)\n\n        self.interp = interp\n        self.lazy = lazy\n\n        if len(self.transforms) == 0:\n            raise Exception(\'Must give at least one transform parameter\')\n\n    def __call__(self, *inputs):\n        # collect all of the lazily returned tform matrices\n        tform_matrix = self.transforms[0](inputs[0])\n        for tform in self.transforms[1:]:\n            tform_matrix = tform_matrix.mm(tform(inputs[0])) \n        self.tform_matrix = tform_matrix\n\n        if self.lazy:\n            return tform_matrix\n        else:\n            outputs = Affine(tform_matrix,\n                             interp=self.interp)(*inputs)\n            return outputs\n\n\nclass Affine(object):\n\n    def __init__(self, \n                 tform_matrix,\n                 interp=\'bilinear\'):\n        """"""\n        Perform an affine transforms with various sub-transforms, using\n        only one interpolation and without having to instantiate each\n        sub-transform individually.\n\n        Arguments\n        ---------\n        tform_matrix : a 2x3 or 3x3 matrix\n            affine transformation matrix to apply\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        """"""\n        self.tform_matrix = tform_matrix\n        self.interp = interp\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            input_tf = th_affine2d(_input,\n                                   self.tform_matrix,\n                                   mode=interp[idx])\n            outputs.append(input_tf)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass AffineCompose(object):\n\n    def __init__(self, \n                 transforms,\n                 interp=\'bilinear\'):\n        """"""\n        Apply a collection of explicit affine transforms to an input image,\n        and to a target image if necessary\n\n        Arguments\n        ---------\n        transforms : list or tuple\n            each element in the list/tuple should be an affine transform.\n            currently supported transforms:\n                - Rotate()\n                - Translate()\n                - Shear()\n                - Zoom()\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        """"""\n        self.transforms = transforms\n        self.interp = interp\n        # set transforms to lazy so they only return the tform matrix\n        for t in self.transforms:\n            t.lazy = True\n\n    def __call__(self, *inputs):\n        # collect all of the lazily returned tform matrices\n        tform_matrix = self.transforms[0](inputs[0])\n        for tform in self.transforms[1:]:\n            tform_matrix = tform_matrix.mm(tform(inputs[0])) \n\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            input_tf = th_affine2d(_input,\n                                   tform_matrix,\n                                   mode=interp[idx])\n            outputs.append(input_tf)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass RandomRotate(object):\n\n    def __init__(self, \n                 rotation_range,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly rotate an image between (-degrees, degrees). If the image\n        has multiple channels, the same rotation will be applied to each channel.\n\n        Arguments\n        ---------\n        rotation_range : integer or float\n            image will be rotated between (-degrees, degrees) degrees\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        self.rotation_range = rotation_range\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        degree = random.uniform(-self.rotation_range, self.rotation_range)\n        print(len(inputs))\n\n        if self.lazy:\n            return Rotate(degree, lazy=True)(inputs[0])\n        else:\n            outputs = Rotate(degree, interp=self.interp)(*inputs)\n            print(len(outputs))\n            return outputs\n\n\nclass RandomChoiceRotate(object):\n\n    def __init__(self, \n                 values,\n                 p=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly rotate an image from a list of values. If the image\n        has multiple channels, the same rotation will be applied to each channel.\n\n        Arguments\n        ---------\n        values : a list or tuple\n            the values from which the rotation value will be sampled\n\n        p : a list or tuple the same length as `values`\n            the probabilities of sampling any given value. Must sum to 1.\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        if isinstance(values, (list, tuple)):\n            values = th.FloatTensor(values)\n        self.values = values\n        if p is None:\n            p = th.ones(len(values)) / len(values)\n        else:\n            if abs(1.0-sum(p)) > 1e-3:\n                raise ValueError(\'Probs must sum to 1\')\n        self.p = p\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        degree = th_random_choice(self.values, p=self.p)\n\n        if self.lazy:\n            return Rotate(degree, lazy=True)(inputs[0])\n        else:\n            outputs = Rotate(degree,\n                             interp=self.interp)(*inputs)\n            print(len(outputs))\n            return outputs\n\n\nclass Rotate(object):\n\n    def __init__(self, \n                 value,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly rotate an image between (-degrees, degrees). If the image\n        has multiple channels, the same rotation will be applied to each channel.\n\n        Arguments\n        ---------\n        rotation_range : integer or float\n            image will be rotated between (-degrees, degrees) degrees\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        self.value = value\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        theta = math.pi / 180 * self.value\n        rotation_matrix = th.FloatTensor([[math.cos(theta), -math.sin(theta), 0],\n                                          [math.sin(theta), math.cos(theta), 0],\n                                          [0, 0, 1]])\n        if self.lazy:\n            return rotation_matrix\n        else:\n            outputs = []\n            for idx, _input in enumerate(inputs):\n                input_tf = th_affine2d(_input,\n                                       rotation_matrix,\n                                       mode=interp[idx],\n                                       center=True)\n                outputs.append(input_tf)\n            return outputs if idx > 1 else outputs[0]\n\n\nclass RandomTranslate(object):\n\n    def __init__(self, \n                 translation_range,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly translate an image some fraction of total height and/or\n        some fraction of total width. If the image has multiple channels,\n        the same translation will be applied to each channel.\n\n        Arguments\n        ---------\n        translation_range : two floats between [0, 1) \n            first value:\n                fractional bounds of total height to shift image\n                image will be horizontally shifted between \n                (-height_range * height_dimension, height_range * height_dimension)\n            second value:\n                fractional bounds of total width to shift image \n                Image will be vertically shifted between \n                (-width_range * width_dimension, width_range * width_dimension)\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        if isinstance(translation_range, float):\n            translation_range = (translation_range, translation_range)\n        self.height_range = translation_range[0]\n        self.width_range = translation_range[1]\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        # height shift\n        random_height = random.uniform(-self.height_range, self.height_range)\n        # width shift\n        random_width = random.uniform(-self.width_range, self.width_range)\n\n        if self.lazy:\n            return Translate([random_height, random_width], \n                             lazy=True)(inputs[0])\n        else:\n            outputs = Translate([random_height, random_width],\n                                 interp=self.interp)(*inputs)\n            return outputs\n\n\nclass RandomChoiceTranslate(object):\n\n    def __init__(self,\n                 values,\n                 p=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly translate an image some fraction of total height and/or\n        some fraction of total width from a list of potential values. \n        If the image has multiple channels,\n        the same translation will be applied to each channel.\n\n        Arguments\n        ---------\n        values : a list or tuple\n            the values from which the translation value will be sampled\n\n        p : a list or tuple the same length as `values`\n            the probabilities of sampling any given value. Must sum to 1.\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        if isinstance(values, (list, tuple)):\n            values = th.FloatTensor(values)\n        self.values = values\n        if p is None:\n            p = th.ones(len(values)) / len(values)\n        else:\n            if abs(1.0-sum(p)) > 1e-3:\n                raise ValueError(\'Probs must sum to 1\')\n        self.p = p\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        random_height = th_random_choice(self.values, p=self.p)\n        random_width = th_random_choice(self.values, p=self.p)\n\n        if self.lazy:\n            return Translate([random_height, random_width],\n                             lazy=True)(inputs[0])\n        else:\n            outputs = Translate([random_height, random_width],\n                                interp=self.interp)(*inputs)\n            return outputs\n\n\nclass Translate(object):\n\n    def __init__(self, \n                 value, \n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Arguments\n        ---------\n        value : float or 2-tuple of float\n            if single value, both horizontal and vertical translation\n            will be this value * total height/width. Thus, value should\n            be a fraction of total height/width with range (-1, 1)\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        """"""\n        if not isinstance(value, (tuple,list)):\n            value = (value, value)\n\n        if value[0] > 1 or value[0] < -1:\n            raise ValueError(\'Translation must be between -1 and 1\')\n        if value[1] > 1 or value[1] < -1:\n            raise ValueError(\'Translation must be between -1 and 1\')\n\n        self.height_range = value[0]\n        self.width_range = value[1]\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        tx = self.height_range * inputs[0].size(1)\n        ty = self.width_range * inputs[0].size(2)\n\n        translation_matrix = th.FloatTensor([[1, 0, tx],\n                                             [0, 1, ty],\n                                             [0, 0, 1]])\n        if self.lazy:\n            return translation_matrix\n        else:\n            outputs = []\n            for idx, _input in enumerate(inputs):\n                input_tf = th_affine2d(_input,\n                                       translation_matrix,\n                                       mode=interp[idx],\n                                       center=True)\n                outputs.append(input_tf)\n            return outputs if idx > 1 else outputs[0]\n\n\nclass RandomShear(object):\n\n    def __init__(self, \n                 shear_range,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly shear an image with radians (-shear_range, shear_range)\n\n        Arguments\n        ---------\n        shear_range : float\n            radian bounds on the shear transform\n        \n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if false, perform the transform on the tensor and return the tensor\n            if true, only create the affine transform matrix and return that\n        """"""\n        self.shear_range = shear_range\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        shear = random.uniform(-self.shear_range, self.shear_range)\n        if self.lazy:\n            return Shear(shear, \n                         lazy=True)(inputs[0])\n        else:\n            outputs = Shear(shear,\n                            interp=self.interp)(*inputs)\n            return outputs\n\n\nclass RandomChoiceShear(object):\n\n    def __init__(self,\n                 values,\n                 p=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly shear an image with a value sampled from a list of values.\n\n        Arguments\n        ---------\n        values : a list or tuple\n            the values from which the rotation value will be sampled\n\n        p : a list or tuple the same length as `values`\n            the probabilities of sampling any given value. Must sum to 1.\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if false, perform the transform on the tensor and return the tensor\n            if true, only create the affine transform matrix and return that\n        """"""\n        if isinstance(values, (list, tuple)):\n            values = th.FloatTensor(values)\n        self.values = values\n        if p is None:\n            p = th.ones(len(values)) / len(values)\n        else:\n            if abs(1.0-sum(p)) > 1e-3:\n                raise ValueError(\'Probs must sum to 1\')\n        self.p = p\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        shear = th_random_choice(self.values, p=self.p)\n\n        if self.lazy:\n            return Shear(shear, \n                         lazy=True)(inputs[0])\n        else:\n            outputs = Shear(shear,\n                            interp=self.interp)(*inputs)\n            return outputs \n\n\nclass Shear(object):\n\n    def __init__(self,\n                 value,\n                 interp=\'bilinear\',\n                 lazy=False):\n        self.value = value\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        theta = (math.pi * self.value) / 180\n        shear_matrix = th.FloatTensor([[1, -math.sin(theta), 0],\n                                        [0, math.cos(theta), 0],\n                                        [0, 0, 1]])\n        if self.lazy:\n            return shear_matrix\n        else:\n            outputs = []\n            for idx, _input in enumerate(inputs):\n                input_tf = th_affine2d(_input,\n                                       shear_matrix,\n                                       mode=interp[idx],\n                                       center=True)\n                outputs.append(input_tf)\n            return outputs if idx > 1 else outputs[0]\n\n\nclass RandomZoom(object):\n\n    def __init__(self, \n                 zoom_range,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly zoom in and/or out on an image \n\n        Arguments\n        ---------\n        zoom_range : tuple or list with 2 values, both between (0, infinity)\n            lower and upper bounds on percent zoom. \n            Anything less than 1.0 will zoom in on the image, \n            anything greater than 1.0 will zoom out on the image.\n            e.g. (0.7, 1.0) will only zoom in, \n                 (1.0, 1.4) will only zoom out,\n                 (0.7, 1.4) will randomly zoom in or out\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if false, perform the transform on the tensor and return the tensor\n            if true, only create the affine transform matrix and return that\n        """"""\n        if not isinstance(zoom_range, list) and not isinstance(zoom_range, tuple):\n            raise ValueError(\'zoom_range must be tuple or list with 2 values\')\n        self.zoom_range = zoom_range\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        zx = random.uniform(self.zoom_range[0], self.zoom_range[1])\n        zy = random.uniform(self.zoom_range[0], self.zoom_range[1])\n\n        if self.lazy:\n            return Zoom([zx, zy], lazy=True)(inputs[0])\n        else:\n            outputs = Zoom([zx, zy], \n                           interp=self.interp)(*inputs)\n            return outputs\n\n\nclass RandomChoiceZoom(object):\n\n    def __init__(self, \n                 values,\n                 p=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly zoom in and/or out on an image with a value sampled from\n        a list of values\n\n        Arguments\n        ---------\n        values : a list or tuple\n            the values from which the applied zoom value will be sampled\n\n        p : a list or tuple the same length as `values`\n            the probabilities of sampling any given value. Must sum to 1.\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if false, perform the transform on the tensor and return the tensor\n            if true, only create the affine transform matrix and return that\n        """"""\n        if isinstance(values, (list, tuple)):\n            values = th.FloatTensor(values)\n        self.values = values\n        if p is None:\n            p = th.ones(len(values)) / len(values)\n        else:\n            if abs(1.0-sum(p)) > 1e-3:\n                raise ValueError(\'Probs must sum to 1\')\n        self.p = p\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        zx = th_random_choice(self.values, p=self.p)\n        zy = th_random_choice(self.values, p=self.p)\n\n        if self.lazy:\n            return Zoom([zx, zy], lazy=True)(inputs[0])\n        else:\n            outputs = Zoom([zx, zy], \n                           interp=self.interp)(*inputs)\n            return outputs\n\n\nclass Zoom(object):\n\n    def __init__(self,\n                 value,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Arguments\n        ---------\n        value : float\n            Fractional zoom.\n            =1 : no zoom\n            >1 : zoom-in (value-1)%\n            <1 : zoom-out (1-value)%\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy: boolean\n            If true, just return transformed\n        """"""\n\n        if not isinstance(value, (tuple,list)):\n            value = (value, value)\n        self.value = value\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        zx, zy = self.value\n        zoom_matrix = th.FloatTensor([[zx, 0, 0],\n                                      [0, zy, 0],\n                                      [0, 0,  1]])        \n\n        if self.lazy:\n            return zoom_matrix\n        else:\n            outputs = []\n            for idx, _input in enumerate(inputs):\n                input_tf = th_affine2d(_input,\n                                       zoom_matrix,\n                                       mode=interp[idx],\n                                       center=True)\n                outputs.append(input_tf)\n            return outputs if idx > 1 else outputs[0]\n\n\n'"
torchsample/transforms/distortion_transforms.py,0,"b'""""""\nTransforms to distort local or global information of an image\n""""""\n\n\nimport torch as th\nimport numpy as np\nimport random\n\n\nclass Scramble(object):\n    """"""\n    Create blocks of an image and scramble them\n    """"""\n    def __init__(self, blocksize):\n        self.blocksize = blocksize\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            size = _input.size()\n            img_height = size[1]\n            img_width = size[2]\n\n            x_blocks = int(img_height/self.blocksize) # number of x blocks\n            y_blocks = int(img_width/self.blocksize)\n            ind = th.randperm(x_blocks*y_blocks)\n\n            new = th.zeros(_input.size())\n            count = 0\n            for i in range(x_blocks):\n                for j in range (y_blocks):\n                    row = int(ind[count] / x_blocks)\n                    column = ind[count] % x_blocks\n                    new[:, i*self.blocksize:(i+1)*self.blocksize, j*self.blocksize:(j+1)*self.blocksize] = \\\n                    _input[:, row*self.blocksize:(row+1)*self.blocksize, column*self.blocksize:(column+1)*self.blocksize]\n                    count += 1\n            outputs.append(new)\n        return outputs if idx > 1 else outputs[0]\n \n\nclass RandomChoiceScramble(object):\n\n    def __init__(self, blocksizes):\n        self.blocksizes = blocksizes\n\n    def __call__(self, *inputs):\n        blocksize = random.choice(self.blocksizes)\n        outputs = Scramble(blocksize=blocksize)(*inputs)\n        return outputs\n\n\ndef _blur_image(image, H):\n    # break image up into its color components\n    size = image.shape\n    imr = image[0,:,:]\n    img = image[1,:,:]\n    imb = image[2,:,:]\n\n    # compute Fourier transform and frequqnecy spectrum\n    Fim1r = np.fft.fftshift(np.fft.fft2(imr))\n    Fim1g  = np.fft.fftshift(np.fft.fft2(img))\n    Fim1b  = np.fft.fftshift(np.fft.fft2(imb))\n    \n    # Apply the lowpass filter to the Fourier spectrum of the image\n    filtered_imager = np.multiply(H, Fim1r)\n    filtered_imageg = np.multiply(H, Fim1g)\n    filtered_imageb = np.multiply(H, Fim1b)\n    \n    newim = np.zeros(size)\n\n    # convert the result to the spatial domain.\n    newim[0,:,:] = np.absolute(np.real(np.fft.ifft2(filtered_imager)))\n    newim[1,:,:] = np.absolute(np.real(np.fft.ifft2(filtered_imageg)))\n    newim[2,:,:] = np.absolute(np.real(np.fft.ifft2(filtered_imageb)))\n\n    return newim.astype(\'uint8\')\n\ndef _butterworth_filter(rows, cols, thresh, order):\n    # X and Y matrices with ranges normalised to +/- 0.5\n    array1 = np.ones(rows)\n    array2 = np.ones(cols)\n    array3 = np.arange(1,rows+1)\n    array4 = np.arange(1,cols+1)\n\n    x = np.outer(array1, array4)\n    y = np.outer(array3, array2)\n\n    x = x - float(cols/2) - 1\n    y = y - float(rows/2) - 1\n\n    x = x / cols\n    y = y / rows\n\n    radius = np.sqrt(np.square(x) + np.square(y))\n\n    matrix1 = radius/thresh\n    matrix2 = np.power(matrix1, 2*order)\n    f = np.reciprocal(1 + matrix2)\n\n    return f\n\n\nclass Blur(object):\n    """"""\n    Blur an image with a Butterworth filter with a frequency\n    cutoff matching local block size\n    """"""\n    def __init__(self, threshold, order=5):\n        """"""\n        scramble blocksize of 128 => filter threshold of 64\n        scramble blocksize of 64 => filter threshold of 32\n        scramble blocksize of 32 => filter threshold of 16\n        scramble blocksize of 16 => filter threshold of 8\n        scramble blocksize of 8 => filter threshold of 4\n        """"""\n        self.threshold = threshold\n        self.order = order\n\n    def __call__(self, *inputs):\n        """"""\n        inputs should have values between 0 and 255\n        """"""\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            rows = _input.size(1)\n            cols = _input.size(2)\n            fc = self.threshold # threshold\n            fs = 128.0 # max frequency\n            n  = self.order # filter order\n            fc_rad = (fc/fs)*0.5\n            H = _butterworth_filter(rows, cols, fc_rad, n)\n            _input_blurred = _blur_image(_input.numpy().astype(\'uint8\'), H)\n            _input_blurred = th.from_numpy(_input_blurred).float()\n            outputs.append(_input_blurred)\n\n        return outputs if idx > 1 else outputs[0]\n\n\nclass RandomChoiceBlur(object):\n\n    def __init__(self, thresholds, order=5):\n        """"""\n        thresholds = [64.0, 32.0, 16.0, 8.0, 4.0]\n        """"""\n        self.thresholds = thresholds\n        self.order = order\n\n    def __call__(self, *inputs):\n        threshold = random.choice(self.thresholds)\n        outputs = Blur(threshold=threshold, order=self.order)(*inputs)\n        return outputs\n\n\n\n\n\n\n'"
torchsample/transforms/image_transforms.py,0,"b'""""""\nTransforms very specific to images such as \ncolor, lighting, contrast, brightness, etc transforms\n\nNOTE: Most of these transforms assume your image intensity\nis between 0 and 1, and are torch tensors (NOT numpy or PIL)\n""""""\n\nimport random\n\nimport torch as th\n\nfrom ..utils import th_random_choice\n\n\ndef _blend(img1, img2, alpha):\n    """"""\n    Weighted sum of two images\n\n    Arguments\n    ---------\n    img1 : torch tensor\n    img2 : torch tensor\n    alpha : float between 0 and 1\n        how much weight to put on img1 and 1-alpha weight\n        to put on img2\n    """"""\n    return img1.mul(alpha).add(1 - alpha, img2)\n\n\nclass Grayscale(object):\n\n    def __init__(self, keep_channels=False):\n        """"""\n        Convert RGB image to grayscale\n\n        Arguments\n        ---------\n        keep_channels : boolean\n            If true, will keep all 3 channels and they will be the same\n            If false, will just return 1 grayscale channel\n        """"""\n        self.keep_channels = keep_channels\n        if keep_channels:\n            self.channels = 3\n        else:\n            self.channels = 1\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input_dst = _input[0]*0.299 + _input[1]*0.587 + _input[2]*0.114\n            _input_gs = _input_dst.repeat(self.channels,1,1)\n            outputs.append(_input_gs)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomGrayscale(object):\n\n    def __init__(self, p=0.5):\n        """"""\n        Randomly convert RGB image(s) to Grayscale w/ some probability,\n        NOTE: Always retains the 3 channels if image is grayscaled\n\n        p : a float\n            probability that image will be grayscaled\n        """"""\n        self.p = p\n\n    def __call__(self, *inputs):\n        pval = random.random()\n        if pval < self.p:\n            outputs = Grayscale(keep_channels=True)(*inputs)\n        else:\n            outputs = inputs\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\nclass Gamma(object):\n\n    def __init__(self, value):\n        """"""\n        Performs Gamma Correction on the input image. Also known as \n        Power Law Transform. This function transforms the input image \n        pixelwise according \n        to the equation Out = In**gamma after scaling each \n        pixel to the range 0 to 1.\n\n        Arguments\n        ---------\n        value : float\n            <1 : image will tend to be lighter\n            =1 : image will stay the same\n            >1 : image will tend to be darker\n        """"""\n        self.value = value\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = th.pow(_input, self.value)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomGamma(object):\n\n    def __init__(self, min_val, max_val):\n        """"""\n        Performs Gamma Correction on the input image with some\n        randomly selected gamma value between min_val and max_val. \n        Also known as Power Law Transform. This function transforms \n        the input image pixelwise according to the equation \n        Out = In**gamma after scaling each pixel to the range 0 to 1.\n\n        Arguments\n        ---------\n        min_val : float\n            min range\n        max_val : float\n            max range\n\n        NOTE:\n        for values:\n            <1 : image will tend to be lighter\n            =1 : image will stay the same\n            >1 : image will tend to be darker\n        """"""\n        self.values = (min_val, max_val)\n\n    def __call__(self, *inputs):\n        value = random.uniform(self.values[0], self.values[1])\n        outputs = Gamma(value)(*inputs)\n        return outputs\n\nclass RandomChoiceGamma(object):\n\n    def __init__(self, values, p=None):\n        """"""\n        Performs Gamma Correction on the input image with some\n        gamma value selected in the list of given values.\n        Also known as Power Law Transform. This function transforms \n        the input image pixelwise according to the equation \n        Out = In**gamma after scaling each pixel to the range 0 to 1.\n\n        Arguments\n        ---------\n        values : list of floats\n            gamma values to sampled from\n        p : list of floats - same length as `values`\n            if None, values will be sampled uniformly.\n            Must sum to 1.\n\n        NOTE:\n        for values:\n            <1 : image will tend to be lighter\n            =1 : image will stay the same\n            >1 : image will tend to be darker\n        """"""\n        self.values = values\n        self.p = p\n\n    def __call__(self, *inputs):\n        value = th_random_choice(self.values, p=self.p)\n        outputs = Gamma(value)(*inputs)\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\nclass Brightness(object):\n    def __init__(self, value):\n        """"""\n        Alter the Brightness of an image\n\n        Arguments\n        ---------\n        value : brightness factor\n            =-1 = completely black\n            <0 = darker\n            0 = no change\n            >0 = brighter\n            =1 = completely white\n        """"""\n        self.value = max(min(value,1.0),-1.0)\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = th.clamp(_input.float().add(self.value).type(_input.type()), 0, 1)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomBrightness(object):\n\n    def __init__(self, min_val, max_val):\n        """"""\n        Alter the Brightness of an image with a value randomly selected\n        between `min_val` and `max_val`\n\n        Arguments\n        ---------\n        min_val : float\n            min range\n        max_val : float\n            max range\n        """"""\n        self.values = (min_val, max_val)\n\n    def __call__(self, *inputs):\n        value = random.uniform(self.values[0], self.values[1])\n        outputs = Brightness(value)(*inputs)\n        return outputs\n\nclass RandomChoiceBrightness(object):\n\n    def __init__(self, values, p=None):\n        """"""\n        Alter the Brightness of an image with a value randomly selected\n        from the list of given values with given probabilities\n\n        Arguments\n        ---------\n        values : list of floats\n            brightness values to sampled from\n        p : list of floats - same length as `values`\n            if None, values will be sampled uniformly.\n            Must sum to 1.\n        """"""\n        self.values = values\n        self.p = p\n\n    def __call__(self, *inputs):\n        value = th_random_choice(self.values, p=self.p)\n        outputs = Brightness(value)(*inputs)\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\nclass Saturation(object):\n\n    def __init__(self, value):\n        """"""\n        Alter the Saturation of image\n\n        Arguments\n        ---------\n        value : float\n            =-1 : gray\n            <0 : colors are more muted\n            =0 : image stays the same\n            >0 : colors are more pure\n            =1 : most saturated\n        """"""\n        self.value = max(min(value,1.0),-1.0)\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _in_gs = Grayscale(keep_channels=True)(_input)\n            alpha = 1.0 + self.value\n            _in = th.clamp(_blend(_input, _in_gs, alpha), 0, 1)\n            outputs.append(_in)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomSaturation(object):\n\n    def __init__(self, min_val, max_val):\n        """"""\n        Alter the Saturation of an image with a value randomly selected\n        between `min_val` and `max_val`\n\n        Arguments\n        ---------\n        min_val : float\n            min range\n        max_val : float\n            max range\n        """"""\n        self.values = (min_val, max_val)\n\n    def __call__(self, *inputs):\n        value = random.uniform(self.values[0], self.values[1])\n        outputs = Saturation(value)(*inputs)\n        return outputs\n\nclass RandomChoiceSaturation(object):\n\n    def __init__(self, values, p=None):\n        """"""\n        Alter the Saturation of an image with a value randomly selected\n        from the list of given values with given probabilities\n\n        Arguments\n        ---------\n        values : list of floats\n            saturation values to sampled from\n        p : list of floats - same length as `values`\n            if None, values will be sampled uniformly.\n            Must sum to 1.\n\n        """"""\n        self.values = values\n        self.p = p\n\n    def __call__(self, *inputs):\n        value = th_random_choice(self.values, p=self.p)\n        outputs = Saturation(value)(*inputs)\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\nclass Contrast(object):\n    """"""\n\n    """"""\n    def __init__(self, value):\n        """"""\n        Adjust Contrast of image.\n\n        Contrast is adjusted independently for each channel of each image.\n\n        For each channel, this Op computes the mean of the image pixels \n        in the channel and then adjusts each component x of each pixel to \n        (x - mean) * contrast_factor + mean.\n\n        Arguments\n        ---------\n        value : float\n            smaller value: less contrast\n            ZERO: channel means\n            larger positive value: greater contrast\n            larger negative value: greater inverse contrast\n        """"""\n        self.value = value\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            channel_means = _input.mean(1).mean(2)\n            channel_means = channel_means.expand_as(_input)\n            _input = th.clamp((_input - channel_means) * self.value + channel_means,0,1)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomContrast(object):\n\n    def __init__(self, min_val, max_val):\n        """"""\n        Alter the Contrast of an image with a value randomly selected\n        between `min_val` and `max_val`\n\n        Arguments\n        ---------\n        min_val : float\n            min range\n        max_val : float\n            max range\n        """"""\n        self.values = (min_val, max_val)\n\n    def __call__(self, *inputs):\n        value = random.uniform(self.values[0], self.values[1])\n        outputs = Contrast(value)(*inputs)\n        return outputs\n\nclass RandomChoiceContrast(object):\n\n    def __init__(self, values, p=None):\n        """"""\n        Alter the Contrast of an image with a value randomly selected\n        from the list of given values with given probabilities\n\n        Arguments\n        ---------\n        values : list of floats\n            contrast values to sampled from\n        p : list of floats - same length as `values`\n            if None, values will be sampled uniformly.\n            Must sum to 1.\n\n        """"""\n        self.values = values\n        self.p = p\n\n    def __call__(self, *inputs):\n        value = th_random_choice(self.values, p=None)\n        outputs = Contrast(value)(*inputs)\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\ndef rgb_to_hsv(x):\n    """"""\n    Convert from RGB to HSV\n    """"""\n    hsv = th.zeros(*x.size())\n    c_min = x.min(0)\n    c_max = x.max(0)\n\n    delta = c_max[0] - c_min[0]\n\n    # set H\n    r_idx = c_max[1].eq(0)\n    hsv[0][r_idx] = ((x[1][r_idx] - x[2][r_idx]) / delta[r_idx]) % 6\n    g_idx = c_max[1].eq(1)\n    hsv[0][g_idx] = 2 + ((x[2][g_idx] - x[0][g_idx]) / delta[g_idx])\n    b_idx = c_max[1].eq(2)\n    hsv[0][b_idx] = 4 + ((x[0][b_idx] - x[1][b_idx]) / delta[b_idx])\n    hsv[0] = hsv[0].mul(60)\n\n    # set S\n    hsv[1] = delta / c_max[0]\n\n    # set V - good\n    hsv[2] = c_max[0]\n\n    return hsv\n'"
torchsample/transforms/tensor_transforms.py,7,"b'\nimport os\nimport random\nimport math\nimport numpy as np\nimport torch\n\nimport torch as th\nfrom torch.autograd import Variable\n\nfrom ..utils import th_random_choice\n\n\nclass BinaryMask(object):\n    def __init__(self, thresholds):\n        self.thresholds = thresholds\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input[_input >= self.thresholds] = 1.0\n            _input[_input < self.thresholds] = 0.0\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass Slice1D(object):\n    def __init__(self, dim=0, slice_idx=0):\n        self.dim = dim\n        self.slice_idx = slice_idx\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = torch.unsqueeze(_input[self.slice_idx,:,:], dim=self.dim)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass Compose(object):\n    """"""\n    Composes several transforms together.\n    """"""\n    def __init__(self, transforms):\n        """"""\n        Composes (chains) several transforms together into\n        a single transform\n\n        Arguments\n        ---------\n        transforms : a list of transforms\n            transforms will be applied sequentially\n        """"""\n        self.transforms = transforms\n\n    def __call__(self, *inputs):\n        for transform in self.transforms:\n            if not isinstance(inputs, (list,tuple)):\n                inputs = [inputs]\n            inputs = transform(*inputs)\n        return inputs\n\n\nclass RandomChoiceCompose(object):\n    """"""\n    Randomly choose to apply one transform from a collection of transforms\n\n    e.g. to randomly apply EITHER 0-1 or -1-1 normalization to an input:\n        >>> transform = RandomChoiceCompose([RangeNormalize(0,1),\n                                             RangeNormalize(-1,1)])\n        >>> x_norm = transform(x) # only one of the two normalizations is applied\n    """"""\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, *inputs):\n        tform = random.choice(self.transforms)\n        outputs = tform(*inputs)\n        return outputs\n\n\nclass ToTensor(object):\n    """"""\n    Converts a numpy array to torch.Tensor\n    """"""\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = th.from_numpy(_input)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass ToVariable(object):\n    """"""\n    Converts a torch.Tensor to autograd.Variable\n    """"""\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = Variable(_input)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass ToCuda(object):\n    """"""\n    Moves an autograd.Variable to the GPU\n    """"""\n    def __init__(self, device=0):\n        """"""\n        Moves an autograd.Variable to the GPU\n\n        Arguments\n        ---------\n        device : integer\n            which GPU device to put the input(s) on\n        """"""\n        self.device = device\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.cuda(self.device)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass ToFile(object):\n    """"""\n    Saves an image to file. Useful as a pass-through ransform\n    when wanting to observe how augmentation affects the data\n\n    NOTE: Only supports saving to Numpy currently\n    """"""\n    def __init__(self, root):\n        """"""\n        Saves an image to file. Useful as a pass-through ransform\n        when wanting to observe how augmentation affects the data\n\n        NOTE: Only supports saving to Numpy currently\n\n        Arguments\n        ---------\n        root : string\n            path to main directory in which images will be saved\n        """"""\n        if root.startswith(\'~\'):\n            root = os.path.expanduser(root)\n        self.root = root\n        self.counter = 0\n\n    def __call__(self, *inputs):\n        for idx, _input in inputs:\n            fpath = os.path.join(self.root, \'img_%i_%i.npy\'%(self.counter, idx))\n            np.save(fpath, _input.numpy())\n        self.counter += 1\n        return inputs\n\n\nclass ChannelsLast(object):\n    """"""\n    Transposes a tensor so that the channel dim is last\n    `HWC` and `DHWC` are aliases for this transform.    \n    """"""\n    def __init__(self, safe_check=False):\n        """"""\n        Transposes a tensor so that the channel dim is last\n        `HWC` and `DHWC` are aliases for this transform.\n\n        Arguments\n        ---------\n        safe_check : boolean\n            if true, will check if channels are already last and, if so,\n            will just return the inputs\n        """"""\n        self.safe_check = safe_check\n\n    def __call__(self, *inputs):\n        ndim = inputs[0].dim()\n        if self.safe_check:\n            # check if channels are already last\n            if inputs[0].size(-1) < inputs[0].size(0):\n                return inputs\n        plist = list(range(1,ndim))+[0]\n\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.permute(*plist)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nHWC = ChannelsLast\nDHWC = ChannelsLast\n\nclass ChannelsFirst(object):\n    """"""\n    Transposes a tensor so that the channel dim is first.\n    `CHW` and `CDHW` are aliases for this transform.\n    """"""\n    def __init__(self, safe_check=False):\n        """"""\n        Transposes a tensor so that the channel dim is first.\n        `CHW` and `CDHW` are aliases for this transform.\n\n        Arguments\n        ---------\n        safe_check : boolean\n            if true, will check if channels are already last and, if so,\n            will just return the inputs\n        """"""\n        self.safe_check = safe_check\n\n    def __call__(self, *inputs):\n        ndim = inputs[0].dim()\n        if self.safe_check:\n            # check if channels are already first\n            if inputs[0].size(0) < inputs[0].size(-1):\n                return inputs\n        plist = [ndim-1] + list(range(0,ndim-1))\n\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.permute(*plist)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nCHW = ChannelsFirst\nCDHW = ChannelsFirst\n\nclass TypeCast(object):\n    """"""\n    Cast a torch.Tensor to a different type\n    """"""\n    def __init__(self, dtype=\'float\'):\n        """"""\n        Cast a torch.Tensor to a different type\n\n        Arguments\n        ---------\n        dtype : string or torch.*Tensor literal or list of such\n            data type to which input(s) will be cast.\n            If list, it should be the same length as inputs.\n        """"""\n        if isinstance(dtype, (list,tuple)):\n            dtypes = []\n            for dt in dtype:\n                if isinstance(dt, str):\n                    if dt == \'byte\':\n                        dt = th.ByteTensor\n                    elif dt == \'double\':\n                        dt = th.DoubleTensor\n                    elif dt == \'float\':\n                        dt = th.FloatTensor\n                    elif dt == \'int\':\n                        dt = th.IntTensor\n                    elif dt == \'long\':\n                        dt = th.LongTensor\n                    elif dt == \'short\':\n                        dt = th.ShortTensor\n                dtypes.append(dt)\n            self.dtype = dtypes\n        else:\n            if isinstance(dtype, str):\n                if dtype == \'byte\':\n                    dtype = th.ByteTensor\n                elif dtype == \'double\':\n                    dtype = th.DoubleTensor\n                elif dtype == \'float\':\n                    dtype = th.FloatTensor\n                elif dtype == \'int\':\n                    dtype = th.IntTensor\n                elif dtype == \'long\':\n                    dtype = th.LongTensor\n                elif dtype == \'short\':\n                    dtype = th.ShortTensor\n            self.dtype = dtype\n\n    def __call__(self, *inputs):\n        if not isinstance(self.dtype, (tuple,list)):\n            dtypes = [self.dtype]*len(inputs)\n        else:\n            dtypes = self.dtype\n        \n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.type(dtypes[idx])\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass AddChannel(object):\n    """"""\n    Adds a dummy channel to an image. \n    This will make an image of size (28, 28) to now be\n    of size (1, 28, 28), for example.\n    """"""\n    def __init__(self, axis=0):\n        """"""\n        Adds a dummy channel to an image, also known as\n        expanding an axis or unsqueezing a dim\n\n        Arguments\n        ---------\n        axis : integer\n            dimension to be expanded to singleton\n        """"""\n        self.axis = axis\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.unsqueeze(self.axis)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nExpandAxis = AddChannel\nUnsqueeze = AddChannel\n\nclass Transpose(object):\n\n    def __init__(self, dim1, dim2):\n        """"""\n        Swaps two dimensions of a tensor\n\n        Arguments\n        ---------\n        dim1 : integer\n            first dim to switch\n        dim2 : integer\n            second dim to switch\n        """"""\n        self.dim1 = dim1\n        self.dim2 = dim2\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = th.transpose(_input, self.dim1, self.dim2)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass RangeNormalize(object):\n    """"""\n    Given min_val: (R, G, B) and max_val: (R,G,B),\n    will normalize each channel of the th.*Tensor to\n    the provided min and max values.\n\n    Works by calculating :\n        a = (max\'-min\')/(max-min)\n        b = max\' - a * max\n        new_value = a * value + b\n    where min\' & max\' are given values, \n    and min & max are observed min/max for each channel\n    \n    Arguments\n    ---------\n    min_range : float or integer\n        Min value to which tensors will be normalized\n    max_range : float or integer\n        Max value to which tensors will be normalized\n    fixed_min : float or integer\n        Give this value if every sample has the same min (max) and \n        you know for sure what it is. For instance, if you\n        have an image then you know the min value will be 0 and the\n        max value will be 255. Otherwise, the min/max value will be\n        calculated for each individual sample and this will decrease\n        speed. Dont use this if each sample has a different min/max.\n    fixed_max :float or integer\n        See above\n\n    Example:\n        >>> x = th.rand(3,5,5)\n        >>> rn = RangeNormalize((0,0,10),(1,1,11))\n        >>> x_norm = rn(x)\n\n    Also works with just one value for min/max:\n        >>> x = th.rand(3,5,5)\n        >>> rn = RangeNormalize(0,1)\n        >>> x_norm = rn(x)\n    """"""\n    def __init__(self, \n                 min_val, \n                 max_val):\n        """"""\n        Normalize a tensor between a min and max value\n\n        Arguments\n        ---------\n        min_val : float\n            lower bound of normalized tensor\n        max_val : float\n            upper bound of normalized tensor\n        """"""\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _min_val = _input.min()\n            _max_val = _input.max()\n            a = (self.max_val - self.min_val) / (_max_val - _min_val)\n            b = self.max_val- a * _max_val\n            _input = _input.mul(a).add(b)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass StdNormalize(object):\n    """"""\n    Normalize torch tensor to have zero mean and unit std deviation\n    """"""\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.sub(_input.mean()).div(_input.std())\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass Slice2D(object):\n\n    def __init__(self, axis=0, reject_zeros=False):\n        """"""\n        Take a random 2D slice from a 3D image along \n        a given axis. This image should not have a 4th channel dim.\n\n        Arguments\n        ---------\n        axis : integer in {0, 1, 2}\n            the axis on which to take slices\n\n        reject_zeros : boolean\n            whether to reject slices that are all zeros\n        """"""\n        self.axis = axis\n        self.reject_zeros = reject_zeros\n\n    def __call__(self, x, y=None):\n        while True:\n            keep_slice  = random.randint(0,x.size(self.axis)-1)\n            if self.axis == 0:\n                slice_x = x[keep_slice,:,:]\n                if y is not None:\n                    slice_y = y[keep_slice,:,:]\n            elif self.axis == 1:\n                slice_x = x[:,keep_slice,:]\n                if y is not None:\n                    slice_y = y[:,keep_slice,:]\n            elif self.axis == 2:\n                slice_x = x[:,:,keep_slice]\n                if y is not None:\n                    slice_y = y[:,:,keep_slice]\n\n            if not self.reject_zeros:\n                break\n            else:\n                if y is not None and th.sum(slice_y) > 0:\n                        break\n                elif th.sum(slice_x) > 0:\n                        break\n        if y is not None:\n            return slice_x, slice_y\n        else:\n            return slice_x\n\n\nclass RandomCrop(object):\n\n    def __init__(self, size):\n        """"""\n        Randomly crop a torch tensor\n\n        Arguments\n        --------\n        size : tuple or list\n            dimensions of the crop\n        """"""\n        self.size = size\n\n    def __call__(self, *inputs):\n        h_idx = random.randint(0,inputs[0].size(1)-self.size[0])\n        w_idx = random.randint(0,inputs[1].size(2)-self.size[1])\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input[:, h_idx:(h_idx+self.size[0]),w_idx:(w_idx+self.size[1])]\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass SpecialCrop(object):\n\n    def __init__(self, size, crop_type=0):\n        """"""\n        Perform a special crop - one of the four corners or center crop\n\n        Arguments\n        ---------\n        size : tuple or list\n            dimensions of the crop\n\n        crop_type : integer in {0,1,2,3,4}\n            0 = center crop\n            1 = top left crop\n            2 = top right crop\n            3 = bottom right crop\n            4 = bottom left crop\n        """"""\n        if crop_type not in {0, 1, 2, 3, 4}:\n            raise ValueError(\'crop_type must be in {0, 1, 2, 3, 4}\')\n        self.size = size\n        self.crop_type = crop_type\n    \n    def __call__(self, x, y=None):\n        if self.crop_type == 0:\n            # center crop\n            x_diff  = (x.size(1)-self.size[0])/2.\n            y_diff  = (x.size(2)-self.size[1])/2.\n            ct_x    = [int(math.ceil(x_diff)),x.size(1)-int(math.floor(x_diff))]\n            ct_y    = [int(math.ceil(y_diff)),x.size(2)-int(math.floor(y_diff))]\n            indices = [ct_x,ct_y]        \n        elif self.crop_type == 1:\n            # top left crop\n            tl_x = [0, self.size[0]]\n            tl_y = [0, self.size[1]]\n            indices = [tl_x,tl_y]\n        elif self.crop_type == 2:\n            # top right crop\n            tr_x = [0, self.size[0]]\n            tr_y = [x.size(2)-self.size[1], x.size(2)]\n            indices = [tr_x,tr_y]\n        elif self.crop_type == 3:\n            # bottom right crop\n            br_x = [x.size(1)-self.size[0],x.size(1)]\n            br_y = [x.size(2)-self.size[1],x.size(2)]\n            indices = [br_x,br_y]\n        elif self.crop_type == 4:\n            # bottom left crop\n            bl_x = [x.size(1)-self.size[0], x.size(1)]\n            bl_y = [0, self.size[1]]\n            indices = [bl_x,bl_y]\n        \n        x = x[:,indices[0][0]:indices[0][1],indices[1][0]:indices[1][1]]\n\n        if y is not None:\n            y = y[:,indices[0][0]:indices[0][1],indices[1][0]:indices[1][1]]\n            return x, y\n        else:\n            return x\n\n\nclass Pad(object):\n\n    def __init__(self, size):\n        """"""\n        Pads an image to the given size\n\n        Arguments\n        ---------\n        size : tuple or list\n            size of crop\n        """"""\n        self.size = size\n\n    def __call__(self, x, y=None):\n        x = x.numpy()\n        shape_diffs = [int(np.ceil((i_s - d_s))) for d_s,i_s in zip(x.shape,self.size)]\n        shape_diffs = np.maximum(shape_diffs,0)\n        pad_sizes = [(int(np.ceil(s/2.)),int(np.floor(s/2.))) for s in shape_diffs]\n        x = np.pad(x, pad_sizes, mode=\'constant\')\n        if y is not None:\n            y = y.numpy()\n            y = np.pad(y, pad_sizes, mode=\'constant\')\n            return th.from_numpy(x), th.from_numpy(y)\n        else:\n            return th.from_numpy(x)\n\n\nclass RandomFlip(object):\n\n    def __init__(self, h=True, v=False, p=0.5):\n        """"""\n        Randomly flip an image horizontally and/or vertically with\n        some probability.\n\n        Arguments\n        ---------\n        h : boolean\n            whether to horizontally flip w/ probability p\n\n        v : boolean\n            whether to vertically flip w/ probability p\n\n        p : float between [0,1]\n            probability with which to apply allowed flipping operations\n        """"""\n        self.horizontal = h\n        self.vertical = v\n        self.p = p\n\n    def __call__(self, x, y=None):\n        x = x.numpy()\n        if y is not None:\n            y = y.numpy()\n        # horizontal flip with p = self.p\n        if self.horizontal:\n            if random.random() < self.p:\n                x = x.swapaxes(2, 0)\n                x = x[::-1, ...]\n                x = x.swapaxes(0, 2)\n                if y is not None:\n                    y = y.swapaxes(2, 0)\n                    y = y[::-1, ...]\n                    y = y.swapaxes(0, 2)\n        # vertical flip with p = self.p\n        if self.vertical:\n            if random.random() < self.p:\n                x = x.swapaxes(1, 0)\n                x = x[::-1, ...]\n                x = x.swapaxes(0, 1)\n                if y is not None:\n                    y = y.swapaxes(1, 0)\n                    y = y[::-1, ...]\n                    y = y.swapaxes(0, 1)\n        if y is None:\n            # must copy because torch doesnt current support neg strides\n            return th.from_numpy(x.copy())\n        else:\n            return th.from_numpy(x.copy()),th.from_numpy(y.copy())\n\n\nclass RandomOrder(object):\n    """"""\n    Randomly permute the channels of an image\n    """"""\n    def __call__(self, *inputs):\n        order = th.randperm(inputs[0].dim())\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.index_select(0, order)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n'"
tests/unit_tests/training/test_learning_rates.py,2,"b'import math\nimport mock\nimport pytest\nfrom pytest_mock import mocker\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom training import learning_rates\n\n# Instructions\n# https://medium.com/@bfortuner/python-unit-testing-with-pytest-and-mock-197499c4623c\n\n\n## Shared Objects\n\nINITIAL_LR = 1e-3\n\n@pytest.fixture(scope=""module"")\ndef example_fixture():\n    return 1e-3\n\n@pytest.fixture(scope=""module"")\ndef lr_schedule():\n    return {\n        1: 1e-3,\n        5: 1e-4,\n        10: 1e-5\n    }\n\ndef sgd():\n    model = nn.Sequential(nn.Linear(3, 3))\n    return optim.SGD(model.parameters(), lr=INITIAL_LR)\n\ndef adam():\n    model = nn.Sequential(nn.Linear(3, 3))\n    return optim.Adam(model.parameters(), lr=INITIAL_LR)\n\n\n## Tests\n\ndef test_get_learning_rate():\n    LR = learning_rates.LearningRate(INITIAL_LR, \'epoch\')\n    optim = sgd()\n    assert LR.initial_lr == INITIAL_LR\n    assert LR.get_learning_rate(optim) == INITIAL_LR\n\ndef test_set_learning_rate():\n    LR = learning_rates.LearningRate(INITIAL_LR, \'epoch\')\n    optim = sgd()\n    new_lr = INITIAL_LR + 1e-1\n    LR.set_learning_rate(optim, new_lr)\n    assert LR.get_learning_rate(optim) == new_lr\n\ndef test_LearningRate_adjust():\n    LR = learning_rates.LearningRate(INITIAL_LR, \'epoch\')\n    optim = sgd()\n    iteration = 5\n    new_lr_expected = INITIAL_LR + 1e-1\n    new_lr_output = LR.adjust(optim, new_lr_expected, iteration)\n    assert new_lr_output == new_lr_expected\n    assert LR.get_learning_rate(optim) == new_lr_expected\n    assert LR.lr_history[0] == [iteration, new_lr_expected]\n\ndef test_FixedLR_adjust():\n    LR = learning_rates.FixedLR(INITIAL_LR, \'epoch\')\n    optim = sgd()\n    iteration = 5\n    new_lr_output = LR.adjust(optim, iteration)\n    assert new_lr_output == INITIAL_LR\n    assert LR.get_learning_rate(optim) == INITIAL_LR\n    assert LR.lr_history[0] == [iteration, INITIAL_LR]\n\ndef test_LinearLR_adjust():\n    fixed_delta = 1e-1\n    LR = learning_rates.LinearLR(INITIAL_LR, \'epoch\', fixed_delta)\n    optim = sgd()\n    iteration = 5\n    new_lr_expected = INITIAL_LR + fixed_delta\n    new_lr_output = LR.adjust(optim, iteration)\n    assert new_lr_output == new_lr_expected\n    assert LR.get_learning_rate(optim) == new_lr_expected\n    assert LR.lr_history[0] == [iteration, new_lr_expected]\n\ndef test_ScheduledLR_adjust(lr_schedule):\n    LR = learning_rates.ScheduledLR(INITIAL_LR, \'epoch\', lr_schedule)\n    optim = sgd()\n\n    assert LR.adjust(optim, 1) == lr_schedule[1]\n    assert LR.get_learning_rate(optim) == lr_schedule[1]\n    assert LR.lr_history[0] == [1, lr_schedule[1]]\n\n    assert LR.adjust(optim, 2) == lr_schedule[1]\n    assert LR.get_learning_rate(optim) == lr_schedule[1]\n    assert LR.lr_history[1] == [2, lr_schedule[1]]\n\n    assert LR.adjust(optim, 5) == lr_schedule[5]\n    assert LR.get_learning_rate(optim) == lr_schedule[5]\n    assert LR.lr_history[2] == [5, lr_schedule[5]]\n\ndef test_SnapshotLR_adjust():\n    max_lr = 0.1\n    n_iters = 100\n    n_cycles = 5\n    LR = learning_rates.SnapshotLR(INITIAL_LR, \'mini_batch\',\n                                    max_lr, n_iters, n_cycles)\n    optim = sgd()\n\n    assert LR.adjust(optim, 0) == 0.1\n    assert LR.get_learning_rate(optim) == 0.1\n    assert LR.lr_history[0] == [0, max_lr]\n\n    assert math.isclose(LR.adjust(optim, 19), 0.0006, abs_tol=0.000016)\n    assert math.isclose(LR.get_learning_rate(optim), 0.0006, abs_tol=0.000016)\n\n    assert LR.adjust(optim, 20) == 0.1\n    assert LR.get_learning_rate(optim) == 0.1\n\n'"
