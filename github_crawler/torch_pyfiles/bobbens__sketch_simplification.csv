file_path,api_count,code
simplify.py,3,"b""import torch\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torch.utils.serialization import load_lua\n\nfrom PIL import Image\nimport argparse\n\nparser = argparse.ArgumentParser(description='Sketch simplification demo.')\nparser.add_argument('--model', type=str, default='model_gan.t7', help='Model to use.')\nparser.add_argument('--img',   type=str, default='test.png',     help='Input image file.')\nparser.add_argument('--out',   type=str, default='out.png',      help='File to output.')\nopt = parser.parse_args()\n\nuse_cuda = torch.cuda.device_count() > 0\n\ncache  = load_lua( opt.model )\nmodel  = cache.model\nimmean = cache.mean\nimstd  = cache.std\nmodel.evaluate()\n\ndata  = Image.open( opt.img ).convert('L')\nw, h  = data.size[0], data.size[1]\npw    = 8-(w%8) if w%8!=0 else 0\nph    = 8-(h%8) if h%8!=0 else 0\ndata  = ((transforms.ToTensor()(data)-immean)/imstd).unsqueeze(0)\nif pw!=0 or ph!=0:\n   data = torch.nn.ReplicationPad2d( (0,pw,0,ph) )( data ).data\n\nif use_cuda:\n   pred = model.cuda().forward( data.cuda() ).float()\nelse:\n   pred = model.forward( data )\nsave_image( pred[0], opt.out )\n\n\n"""
