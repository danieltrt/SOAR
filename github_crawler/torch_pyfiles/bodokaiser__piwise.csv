file_path,api_count,code
main.py,7,"b""import numpy as np\nimport torch\n\nfrom PIL import Image\nfrom argparse import ArgumentParser\n\nfrom torch.optim import SGD, Adam\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import Compose, CenterCrop, Normalize\nfrom torchvision.transforms import ToTensor, ToPILImage\n\nfrom piwise.dataset import VOC12\nfrom piwise.network import FCN8, FCN16, FCN32, UNet, PSPNet, SegNet\nfrom piwise.criterion import CrossEntropyLoss2d\nfrom piwise.transform import Relabel, ToLabel, Colorize\nfrom piwise.visualize import Dashboard\n\nNUM_CHANNELS = 3\nNUM_CLASSES = 22\n\ncolor_transform = Colorize()\nimage_transform = ToPILImage()\ninput_transform = Compose([\n    CenterCrop(256),\n    ToTensor(),\n    Normalize([.485, .456, .406], [.229, .224, .225]),\n])\ntarget_transform = Compose([\n    CenterCrop(256),\n    ToLabel(),\n    Relabel(255, 21),\n])\n\ndef train(args, model):\n    model.train()\n\n    weight = torch.ones(22)\n    weight[0] = 0\n\n    loader = DataLoader(VOC12(args.datadir, input_transform, target_transform),\n        num_workers=args.num_workers, batch_size=args.batch_size, shuffle=True)\n\n    if args.cuda:\n        criterion = CrossEntropyLoss2d(weight.cuda())\n    else:\n        criterion = CrossEntropyLoss2d(weight)\n\n    optimizer = Adam(model.parameters())\n    if args.model.startswith('FCN'):\n        optimizer = SGD(model.parameters(), 1e-4, .9, 2e-5)\n    if args.model.startswith('PSP'):\n        optimizer = SGD(model.parameters(), 1e-2, .9, 1e-4)\n    if args.model.startswith('Seg'):\n        optimizer = SGD(model.parameters(), 1e-3, .9)\n\n    if args.steps_plot > 0:\n        board = Dashboard(args.port)\n\n    for epoch in range(1, args.num_epochs+1):\n        epoch_loss = []\n\n        for step, (images, labels) in enumerate(loader):\n            if args.cuda:\n                images = images.cuda()\n                labels = labels.cuda()\n\n            inputs = Variable(images)\n            targets = Variable(labels)\n            outputs = model(inputs)\n\n            optimizer.zero_grad()\n            loss = criterion(outputs, targets[:, 0])\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss.append(loss.data[0])\n            if args.steps_plot > 0 and step % args.steps_plot == 0:\n                image = inputs[0].cpu().data\n                image[0] = image[0] * .229 + .485\n                image[1] = image[1] * .224 + .456\n                image[2] = image[2] * .225 + .406\n                board.image(image,\n                    f'input (epoch: {epoch}, step: {step})')\n                board.image(color_transform(outputs[0].cpu().max(0)[1].data),\n                    f'output (epoch: {epoch}, step: {step})')\n                board.image(color_transform(targets[0].cpu().data),\n                    f'target (epoch: {epoch}, step: {step})')\n            if args.steps_loss > 0 and step % args.steps_loss == 0:\n                average = sum(epoch_loss) / len(epoch_loss)\n                print(f'loss: {average} (epoch: {epoch}, step: {step})')\n            if args.steps_save > 0 and step % args.steps_save == 0:\n                filename = f'{args.model}-{epoch:03}-{step:04}.pth'\n                torch.save(model.state_dict(), filename)\n                print(f'save: {filename} (epoch: {epoch}, step: {step})')\n\ndef evaluate(args, model):\n    model.eval()\n\n    image = input_transform(Image.open(args.image))\n    label = model(Variable(image, volatile=True).unsqueeze(0))\n    label = color_transform(label[0].data.max(0)[1])\n\n    image_transform(label).save(args.label)\n\ndef main(args):\n    Net = None\n    if args.model == 'fcn8':\n        Net = FCN8\n    if args.model == 'fcn16':\n        Net = FCN16\n    if args.model == 'fcn32':\n        Net = FCN32\n    if args.model == 'fcn32':\n        Net = FCN32\n    if args.model == 'unet':\n        Net = UNet\n    if args.model == 'pspnet':\n        Net = PSPNet\n    if args.model == 'segnet':\n        Net = SegNet\n    assert Net is not None, f'model {args.model} not available'\n\n    model = Net(NUM_CLASSES)\n\n    if args.cuda:\n        model = model.cuda()\n    if args.state:\n        try:\n            model.load_state_dict(torch.load(args.state))\n        except AssertionError:\n            model.load_state_dict(torch.load(args.state,\n                map_location=lambda storage, loc: storage))\n\n    if args.mode == 'eval':\n        evaluate(args, model)\n    if args.mode == 'train':\n        train(args, model)\n\nif __name__ == '__main__':\n    parser = ArgumentParser()\n    parser.add_argument('--cuda', action='store_true')\n    parser.add_argument('--model', required=True)\n    parser.add_argument('--state')\n\n    subparsers = parser.add_subparsers(dest='mode')\n    subparsers.required = True\n\n    parser_eval = subparsers.add_parser('eval')\n    parser_eval.add_argument('image')\n    parser_eval.add_argument('label')\n\n    parser_train = subparsers.add_parser('train')\n    parser_train.add_argument('--port', type=int, default=80)\n    parser_train.add_argument('--datadir', required=True)\n    parser_train.add_argument('--num-epochs', type=int, default=32)\n    parser_train.add_argument('--num-workers', type=int, default=4)\n    parser_train.add_argument('--batch-size', type=int, default=1)\n    parser_train.add_argument('--steps-loss', type=int, default=50)\n    parser_train.add_argument('--steps-plot', type=int, default=0)\n    parser_train.add_argument('--steps-save', type=int, default=500)\n\n    main(parser.parse_args())"""
piwise/criterion.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CrossEntropyLoss2d(nn.Module):\n\n    def __init__(self, weight=None):\n        super().__init__()\n\n        self.loss = nn.NLLLoss2d(weight)\n\n    def forward(self, outputs, targets):\n        return self.loss(F.log_softmax(outputs), targets)'"
piwise/dataset.py,1,"b""import numpy as np\nimport os\n\nfrom PIL import Image\n\nfrom torch.utils.data import Dataset\n\nEXTENSIONS = ['.jpg', '.png']\n\ndef load_image(file):\n    return Image.open(file)\n\ndef is_image(filename):\n    return any(filename.endswith(ext) for ext in EXTENSIONS)\n\ndef image_path(root, basename, extension):\n    return os.path.join(root, f'{basename}{extension}')\n\ndef image_basename(filename):\n    return os.path.basename(os.path.splitext(filename)[0])\n\nclass VOC12(Dataset):\n\n    def __init__(self, root, input_transform=None, target_transform=None):\n        self.images_root = os.path.join(root, 'images')\n        self.labels_root = os.path.join(root, 'labels')\n\n        self.filenames = [image_basename(f)\n            for f in os.listdir(self.labels_root) if is_image(f)]\n        self.filenames.sort()\n\n        self.input_transform = input_transform\n        self.target_transform = target_transform\n\n    def __getitem__(self, index):\n        filename = self.filenames[index]\n\n        with open(image_path(self.images_root, filename, '.jpg'), 'rb') as f:\n            image = load_image(f).convert('RGB')\n        with open(image_path(self.labels_root, filename, '.png'), 'rb') as f:\n            label = load_image(f).convert('P')\n\n        if self.input_transform is not None:\n            image = self.input_transform(image)\n        if self.target_transform is not None:\n            label = self.target_transform(label)\n\n        return image, label\n\n    def __len__(self):\n        return len(self.filenames)"""
piwise/network.py,9,"b""import torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\nfrom torch.utils import model_zoo\nfrom torchvision import models\n\nclass FCN8(nn.Module):\n\n    def __init__(self, num_classes):\n        super().__init__()\n\n        feats = list(models.vgg16(pretrained=True).features.children())\n\n        self.feats = nn.Sequential(*feats[0:9])\n        self.feat3 = nn.Sequential(*feats[10:16])\n        self.feat4 = nn.Sequential(*feats[17:23])\n        self.feat5 = nn.Sequential(*feats[24:30])\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                m.requires_grad = False\n\n        self.fconn = nn.Sequential(\n            nn.Conv2d(512, 4096, 7),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Conv2d(4096, 4096, 1),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n        )\n        self.score_feat3 = nn.Conv2d(256, num_classes, 1)\n        self.score_feat4 = nn.Conv2d(512, num_classes, 1)\n        self.score_fconn = nn.Conv2d(4096, num_classes, 1)\n\n    def forward(self, x):\n        feats = self.feats(x)\n        feat3 = self.feat3(feats)\n        feat4 = self.feat4(feat3)\n        feat5 = self.feat5(feat4)\n        fconn = self.fconn(feat5)\n\n        score_feat3 = self.score_feat3(feat3)\n        score_feat4 = self.score_feat4(feat4)\n        score_fconn = self.score_fconn(fconn)\n\n        score = F.upsample_bilinear(score_fconn, score_feat4.size()[2:])\n        score += score_feat4\n        score = F.upsample_bilinear(score, score_feat3.size()[2:])\n        score += score_feat3\n\n        return F.upsample_bilinear(score, x.size()[2:])\n\n\nclass FCN16(nn.Module):\n\n    def __init__(self, num_classes):\n        super().__init__()\n\n        feats = list(models.vgg16(pretrained=True).features.children())\n        self.feats = nn.Sequential(*feats[0:16])\n        self.feat4 = nn.Sequential(*feats[17:23])\n        self.feat5 = nn.Sequential(*feats[24:30])\n        self.fconn = nn.Sequential(\n            nn.Conv2d(512, 4096, 7),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Conv2d(4096, 4096, 1),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n        )\n        self.score_fconn = nn.Conv2d(4096, num_classes, 1)\n        self.score_feat4 = nn.Conv2d(512, num_classes, 1)\n\n    def forward(self, x):\n        feats = self.feats(x)\n        feat4 = self.feat4(feats)\n        feat5 = self.feat5(feat4)\n        fconn = self.fconn(feat5)\n\n        score_feat4 = self.score_feat4(feat4)\n        score_fconn = self.score_fconn(fconn)\n\n        score = F.upsample_bilinear(score_fconn, score_feat4.size()[2:])\n        score += score_feat4\n\n        return F.upsample_bilinear(score, x.size()[2:])\n\n\nclass FCN32(nn.Module):\n\n    def __init__(self, num_classes):\n        super().__init__()\n\n        self.feats = models.vgg16(pretrained=True).features\n        self.fconn = nn.Sequential(\n            nn.Conv2d(512, 4096, 7),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Conv2d(4096, 4096, 1),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n        )\n        self.score = nn.Conv2d(4096, num_classes, 1)\n\n    def forward(self, x):\n        feats = self.feats(x)\n        fconn = self.fconn(feats)\n        score = self.score(fconn)\n\n        return F.upsample_bilinear(score, x.size()[2:])\n\n\nclass UNetEnc(nn.Module):\n\n    def __init__(self, in_channels, features, out_channels):\n        super().__init__()\n\n        self.up = nn.Sequential(\n            nn.Conv2d(in_channels, features, 3),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(features, features, 3),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(features, out_channels, 2, stride=2),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.up(x)\n\n\nclass UNetDec(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dropout=False):\n        super().__init__()\n\n        layers = [\n            nn.Conv2d(in_channels, out_channels, 3),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3),\n            nn.ReLU(inplace=True),\n        ]\n        if dropout:\n            layers += [nn.Dropout(.5)]\n        layers += [nn.MaxPool2d(2, stride=2, ceil_mode=True)]\n\n        self.down = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.down(x)\n\n\nclass UNet(nn.Module):\n\n    def __init__(self, num_classes):\n        super().__init__()\n\n        self.dec1 = UNetDec(3, 64)\n        self.dec2 = UNetDec(64, 128)\n        self.dec3 = UNetDec(128, 256)\n        self.dec4 = UNetDec(256, 512, dropout=True)\n        self.center = nn.Sequential(\n            nn.Conv2d(512, 1024, 3),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(1024, 1024, 3),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.ConvTranspose2d(1024, 512, 2, stride=2),\n            nn.ReLU(inplace=True),\n        )\n        self.enc4 = UNetEnc(1024, 512, 256)\n        self.enc3 = UNetEnc(512, 256, 128)\n        self.enc2 = UNetEnc(256, 128, 64)\n        self.enc1 = nn.Sequential(\n            nn.Conv2d(128, 64, 3),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, 3),\n            nn.ReLU(inplace=True),\n        )\n        self.final = nn.Conv2d(64, num_classes, 1)\n\n    def forward(self, x):\n        dec1 = self.dec1(x)\n        dec2 = self.dec2(dec1)\n        dec3 = self.dec3(dec2)\n        dec4 = self.dec4(dec3)\n        center = self.center(dec4)\n        enc4 = self.enc4(torch.cat([\n            center, F.upsample_bilinear(dec4, center.size()[2:])], 1))\n        enc3 = self.enc3(torch.cat([\n            enc4, F.upsample_bilinear(dec3, enc4.size()[2:])], 1))\n        enc2 = self.enc2(torch.cat([\n            enc3, F.upsample_bilinear(dec2, enc3.size()[2:])], 1))\n        enc1 = self.enc1(torch.cat([\n            enc2, F.upsample_bilinear(dec1, enc2.size()[2:])], 1))\n\n        return F.upsample_bilinear(self.final(enc1), x.size()[2:])\n\n\nclass SegNetEnc(nn.Module):\n\n    def __init__(self, in_channels, out_channels, num_layers):\n        super().__init__()\n        layers = [\n            nn.Conv2d(in_channels, in_channels // 2, 3, padding=1),\n            nn.BatchNorm2d(in_channels // 2),\n            nn.ReLU(inplace=True),\n        ]\n        layers += [\n            nn.Conv2d(in_channels // 2, in_channels // 2, 3, padding=1),\n            nn.BatchNorm2d(in_channels // 2),\n            nn.ReLU(inplace=True),\n        ] * num_layers\n        layers += [\n            nn.Conv2d(in_channels // 2, out_channels, 3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        ]\n        self.encode = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.encode(x)\n\n\nclass SegNet(nn.Module):\n\n    def __init__(self, classes):\n        super().__init__()\n        vgg16 = models.vgg16(pretrained=True)\n        features = vgg16.features\n        self.dec1 = features[0: 4]\n        self.dec2 = features[5: 9]\n        self.dec3 = features[10: 16]\n        self.dec4 = features[17: 23]\n        self.dec5 = features[24: -1]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                m.requires_grad = False\n\n        self.enc5 = SegNetEnc(512, 512, 1)\n        self.enc4 = SegNetEnc(512, 256, 1)\n        self.enc3 = SegNetEnc(256, 128, 1)\n        self.enc2 = SegNetEnc(128, 64, 0)\n\n        self.final = nn.Sequential(*[\n            nn.Conv2d(64, classes, 3, padding=1),\n            nn.BatchNorm2d(classes),\n            nn.ReLU(inplace=True)\n        ])\n\n    def forward(self, x):\n        x1 = self.dec1(x)\n        d1, m1 = F.max_pool2d(x1, kernel_size=2, stride=2, return_indices=True)\n        x2 = self.dec2(d1)\n        d2, m2 = F.max_pool2d(x2, kernel_size=2, stride=2, return_indices=True)\n        x3 = self.dec3(d2)\n        d3, m3 = F.max_pool2d(x3, kernel_size=2, stride=2, return_indices=True)\n        x4 = self.dec4(d3)\n        d4, m4 = F.max_pool2d(x4, kernel_size=2, stride=2, return_indices=True)\n        x5 = self.dec5(d4)\n        d5, m5 = F.max_pool2d(x5, kernel_size=2, stride=2, return_indices=True)\n\n        def upsample(d):\n            e5 = self.enc5(F.max_unpool2d(d, m5, kernel_size=2, stride=2, output_size=x5.size()))\n            e4 = self.enc4(F.max_unpool2d(e5, m4, kernel_size=2, stride=2, output_size=x4.size()))\n            e3 = self.enc3(F.max_unpool2d(e4, m3, kernel_size=2, stride=2, output_size=x3.size()))\n            e2 = self.enc2(F.max_unpool2d(e3, m2, kernel_size=2, stride=2, output_size=x2.size()))\n            e1 = F.max_unpool2d(e2, m1, kernel_size=2, stride=2, output_size=x1.size())\n            return e1\n\n        e = upsample(d5)\n\n        return self.final(e)\n\n\n\nclass PSPDec(nn.Module):\n\n    def __init__(self, in_features, out_features, downsize, upsize=60):\n        super().__init__()\n\n        self.features = nn.Sequential(\n            nn.AvgPool2d(downsize, stride=downsize),\n            nn.Conv2d(in_features, out_features, 1, bias=False),\n            nn.BatchNorm2d(out_features, momentum=.95),\n            nn.ReLU(inplace=True),\n            nn.UpsamplingBilinear2d(upsize)\n        )\n\n    def forward(self, x):\n        return self.features(x)\n\n\nclass PSPNet(nn.Module):\n\n    def __init__(self, num_classes):\n        super().__init__()\n\n        '''\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 64, 3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(64, momentum=.95),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(64, momentum=.95),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 128, 3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(128, momentum=.95),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(3, stride=2, padding=1),\n        )\n        '''\n\n        resnet = models.resnet101(pretrained=True)\n\n        self.conv1 = resnet.conv1\n        self.layer1 = resnet.layer1\n        self.layer2 = resnet.layer2\n        self.layer3 = resnet.layer3\n        self.layer4 = resnet.layer4\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                m.stride = 1\n                m.requires_grad = False\n            if isinstance(m, nn.BatchNorm2d):\n                m.requires_grad = False\n\n        self.layer5a = PSPDec(2048, 512, 60)\n        self.layer5b = PSPDec(2048, 512, 30)\n        self.layer5c = PSPDec(2048, 512, 20)\n        self.layer5d = PSPDec(2048, 512, 10)\n\n        self.final = nn.Sequential(\n            nn.Conv2d(2048, 512, 3, padding=1, bias=False),\n            nn.BatchNorm2d(512, momentum=.95),\n            nn.ReLU(inplace=True),\n            nn.Dropout(.1),\n            nn.Conv2d(512, num_classes, 1),\n        )\n\n    def forward(self, x):\n        print('x', x.size())\n        x = self.conv1(x)\n        print('conv1', x.size())\n        x = self.layer1(x)\n        print('layer1', x.size())\n        x = self.layer2(x)\n        print('layer2', x.size())\n        x = self.layer3(x)\n        print('layer3', x.size())\n        x = self.layer4(x)\n        print('layer4', x.size())\n        x = self.final(torch.cat([\n            x,\n            self.layer5a(x),\n            self.layer5b(x),\n            self.layer5c(x),\n            self.layer5d(x),\n        ], 1))\n        print('final', x.size())\n\n        return F.upsample_bilinear(final, x.size()[2:])\n"""
piwise/transform.py,4,"b""import numpy as np\nimport torch\n\nfrom PIL import Image\n\ndef colormap(n):\n    cmap=np.zeros([n, 3]).astype(np.uint8)\n\n    for i in np.arange(n):\n        r, g, b = np.zeros(3)\n\n        for j in np.arange(8):\n            r = r + (1<<(7-j))*((i&(1<<(3*j))) >> (3*j))\n            g = g + (1<<(7-j))*((i&(1<<(3*j+1))) >> (3*j+1))\n            b = b + (1<<(7-j))*((i&(1<<(3*j+2))) >> (3*j+2))\n\n        cmap[i,:] = np.array([r, g, b])\n\n    return cmap\n\nclass Relabel:\n\n    def __init__(self, olabel, nlabel):\n        self.olabel = olabel\n        self.nlabel = nlabel\n\n    def __call__(self, tensor):\n        assert isinstance(tensor, torch.LongTensor), 'tensor needs to be LongTensor'\n        tensor[tensor == self.olabel] = self.nlabel\n        return tensor\n\n\nclass ToLabel:\n\n    def __call__(self, image):\n        return torch.from_numpy(np.array(image)).long().unsqueeze(0)\n\n\nclass Colorize:\n\n    def __init__(self, n=22):\n        self.cmap = colormap(256)\n        self.cmap[n] = self.cmap[-1]\n        self.cmap = torch.from_numpy(self.cmap[:n])\n\n    def __call__(self, gray_image):\n        size = gray_image.size()\n        color_image = torch.ByteTensor(3, size[1], size[2]).fill_(0)\n\n        for label in range(1, len(self.cmap)):\n            mask = gray_image[0] == label\n\n            color_image[0][mask] = self.cmap[label][0]\n            color_image[1][mask] = self.cmap[label][1]\n            color_image[2][mask] = self.cmap[label][2]\n\n        return color_image"""
piwise/visualize.py,1,"b""import numpy as np\n\nfrom torch.autograd import Variable\n\nfrom visdom import Visdom\n\nclass Dashboard:\n\n    def __init__(self, port):\n        self.vis = Visdom(port=port)\n\n    def loss(self, losses, title):\n        x = np.arange(1, len(losses)+1, 1)\n\n        self.vis.line(losses, x, env='loss', opts=dict(title=title))\n\n    def image(self, image, title):\n        if image.is_cuda:\n            image = image.cpu()\n        if isinstance(image, Variable):\n            image = image.data\n        image = image.numpy()\n\n        self.vis.image(image, env='images', opts=dict(title=title))"""
tests/dataset.py,0,"b""import os\nimport unittest\n\nfrom piwise import dataset\n\nclass TestVOC2012(unittest.TestCase):\n\n    def setUp(self):\n        self.dataset = dataset.VOC2012('data')\n        self.dataset_len = sum([\n            1 for f in os.listdir('data/labels') if f.endswith('.png')])\n\n    def test_length(self):\n        self.assertEqual(len(self.dataset), self.dataset_len)\n\n    def test_getitem(self):\n        image, label = self.dataset[0]\n\n        self.assertEqual(image.mode, label.mode)\n        self.assertEqual(image.width, label.width)\n        self.assertEqual(image.height, label.height)\n"""
