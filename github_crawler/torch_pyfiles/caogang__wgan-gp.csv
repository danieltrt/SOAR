file_path,api_count,code
gan_cifar10.py,10,"b'import os, sys\nsys.path.append(os.getcwd())\n\nimport time\nimport tflib as lib\nimport tflib.save_images\nimport tflib.mnist\nimport tflib.cifar10\nimport tflib.plot\nimport tflib.inception_score\n\nimport numpy as np\n\n\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torch import autograd\nfrom torch import optim\n\n# Download CIFAR-10 (Python version) at\n# https://www.cs.toronto.edu/~kriz/cifar.html and fill in the path to the\n# extracted files here!\nDATA_DIR = \'cifar-10-batches-py/\'\nif len(DATA_DIR) == 0:\n    raise Exception(\'Please specify path to data directory in gan_cifar.py!\')\n\nMODE = \'wgan-gp\' # Valid options are dcgan, wgan, or wgan-gp\nDIM = 128 # This overfits substantially; you\'re probably better off with 64\nLAMBDA = 10 # Gradient penalty lambda hyperparameter\nCRITIC_ITERS = 5 # How many critic iterations per generator iteration\nBATCH_SIZE = 64 # Batch size\nITERS = 200000 # How many generator iterations to train for\nOUTPUT_DIM = 3072 # Number of pixels in CIFAR10 (3*32*32)\n\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        preprocess = nn.Sequential(\n            nn.Linear(128, 4 * 4 * 4 * DIM),\n            nn.BatchNorm2d(4 * 4 * 4 * DIM),\n            nn.ReLU(True),\n        )\n\n        block1 = nn.Sequential(\n            nn.ConvTranspose2d(4 * DIM, 2 * DIM, 2, stride=2),\n            nn.BatchNorm2d(2 * DIM),\n            nn.ReLU(True),\n        )\n        block2 = nn.Sequential(\n            nn.ConvTranspose2d(2 * DIM, DIM, 2, stride=2),\n            nn.BatchNorm2d(DIM),\n            nn.ReLU(True),\n        )\n        deconv_out = nn.ConvTranspose2d(DIM, 3, 2, stride=2)\n\n        self.preprocess = preprocess\n        self.block1 = block1\n        self.block2 = block2\n        self.deconv_out = deconv_out\n        self.tanh = nn.Tanh()\n\n    def forward(self, input):\n        output = self.preprocess(input)\n        output = output.view(-1, 4 * DIM, 4, 4)\n        output = self.block1(output)\n        output = self.block2(output)\n        output = self.deconv_out(output)\n        output = self.tanh(output)\n        return output.view(-1, 3, 32, 32)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        main = nn.Sequential(\n            nn.Conv2d(3, DIM, 3, 2, padding=1),\n            nn.LeakyReLU(),\n            nn.Conv2d(DIM, 2 * DIM, 3, 2, padding=1),\n            nn.LeakyReLU(),\n            nn.Conv2d(2 * DIM, 4 * DIM, 3, 2, padding=1),\n            nn.LeakyReLU(),\n        )\n\n        self.main = main\n        self.linear = nn.Linear(4*4*4*DIM, 1)\n\n    def forward(self, input):\n        output = self.main(input)\n        output = output.view(-1, 4*4*4*DIM)\n        output = self.linear(output)\n        return output\n\nnetG = Generator()\nnetD = Discriminator()\nprint netG\nprint netD\n\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    gpu = 0\nif use_cuda:\n    netD = netD.cuda(gpu)\n    netG = netG.cuda(gpu)\n\none = torch.FloatTensor([1])\nmone = one * -1\nif use_cuda:\n    one = one.cuda(gpu)\n    mone = mone.cuda(gpu)\n\noptimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\noptimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n\ndef calc_gradient_penalty(netD, real_data, fake_data):\n    # print ""real_data: "", real_data.size(), fake_data.size()\n    alpha = torch.rand(BATCH_SIZE, 1)\n    alpha = alpha.expand(BATCH_SIZE, real_data.nelement()/BATCH_SIZE).contiguous().view(BATCH_SIZE, 3, 32, 32)\n    alpha = alpha.cuda(gpu) if use_cuda else alpha\n\n    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n\n    if use_cuda:\n        interpolates = interpolates.cuda(gpu)\n    interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n    disc_interpolates = netD(interpolates)\n\n    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(gpu) if use_cuda else torch.ones(\n                                  disc_interpolates.size()),\n                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n    gradients = gradients.view(gradients.size(0), -1)\n\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n    return gradient_penalty\n\n# For generating samples\ndef generate_image(frame, netG):\n    fixed_noise_128 = torch.randn(128, 128)\n    if use_cuda:\n        fixed_noise_128 = fixed_noise_128.cuda(gpu)\n    noisev = autograd.Variable(fixed_noise_128, volatile=True)\n    samples = netG(noisev)\n    samples = samples.view(-1, 3, 32, 32)\n    samples = samples.mul(0.5).add(0.5)\n    samples = samples.cpu().data.numpy()\n\n    lib.save_images.save_images(samples, \'./tmp/cifar10/samples_{}.jpg\'.format(frame))\n\n# For calculating inception score\ndef get_inception_score(G, ):\n    all_samples = []\n    for i in xrange(10):\n        samples_100 = torch.randn(100, 128)\n        if use_cuda:\n            samples_100 = samples_100.cuda(gpu)\n        samples_100 = autograd.Variable(samples_100, volatile=True)\n        all_samples.append(G(samples_100).cpu().data.numpy())\n\n    all_samples = np.concatenate(all_samples, axis=0)\n    all_samples = np.multiply(np.add(np.multiply(all_samples, 0.5), 0.5), 255).astype(\'int32\')\n    all_samples = all_samples.reshape((-1, 3, 32, 32)).transpose(0, 2, 3, 1)\n    return lib.inception_score.get_inception_score(list(all_samples))\n\n# Dataset iterator\ntrain_gen, dev_gen = lib.cifar10.load(BATCH_SIZE, data_dir=DATA_DIR)\ndef inf_train_gen():\n    while True:\n        for images, target in train_gen():\n            # yield images.astype(\'float32\').reshape(BATCH_SIZE, 3, 32, 32).transpose(0, 2, 3, 1)\n            yield images\ngen = inf_train_gen()\npreprocess = torchvision.transforms.Compose([\n                               torchvision.transforms.ToTensor(),\n                               torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ])\n\nfor iteration in xrange(ITERS):\n    start_time = time.time()\n    ############################\n    # (1) Update D network\n    ###########################\n    for p in netD.parameters():  # reset requires_grad\n        p.requires_grad = True  # they are set to False below in netG update\n    for i in xrange(CRITIC_ITERS):\n        _data = gen.next()\n        netD.zero_grad()\n\n        # train with real\n        _data = _data.reshape(BATCH_SIZE, 3, 32, 32).transpose(0, 2, 3, 1)\n        real_data = torch.stack([preprocess(item) for item in _data])\n\n        if use_cuda:\n            real_data = real_data.cuda(gpu)\n        real_data_v = autograd.Variable(real_data)\n\n        # import torchvision\n        # filename = os.path.join(""test_train_data"", str(iteration) + str(i) + "".jpg"")\n        # torchvision.utils.save_image(real_data, filename)\n\n        D_real = netD(real_data_v)\n        D_real = D_real.mean()\n        D_real.backward(mone)\n\n        # train with fake\n        noise = torch.randn(BATCH_SIZE, 128)\n        if use_cuda:\n            noise = noise.cuda(gpu)\n        noisev = autograd.Variable(noise, volatile=True)  # totally freeze netG\n        fake = autograd.Variable(netG(noisev).data)\n        inputv = fake\n        D_fake = netD(inputv)\n        D_fake = D_fake.mean()\n        D_fake.backward(one)\n\n        # train with gradient penalty\n        gradient_penalty = calc_gradient_penalty(netD, real_data_v.data, fake.data)\n        gradient_penalty.backward()\n\n        # print ""gradien_penalty: "", gradient_penalty\n\n        D_cost = D_fake - D_real + gradient_penalty\n        Wasserstein_D = D_real - D_fake\n        optimizerD.step()\n    ############################\n    # (2) Update G network\n    ###########################\n    for p in netD.parameters():\n        p.requires_grad = False  # to avoid computation\n    netG.zero_grad()\n\n    noise = torch.randn(BATCH_SIZE, 128)\n    if use_cuda:\n        noise = noise.cuda(gpu)\n    noisev = autograd.Variable(noise)\n    fake = netG(noisev)\n    G = netD(fake)\n    G = G.mean()\n    G.backward(mone)\n    G_cost = -G\n    optimizerG.step()\n\n    # Write logs and save samples\n    lib.plot.plot(\'./tmp/cifar10/train disc cost\', D_cost.cpu().data.numpy())\n    lib.plot.plot(\'./tmp/cifar10/time\', time.time() - start_time)\n    lib.plot.plot(\'./tmp/cifar10/train gen cost\', G_cost.cpu().data.numpy())\n    lib.plot.plot(\'./tmp/cifar10/wasserstein distance\', Wasserstein_D.cpu().data.numpy())\n\n    # Calculate inception score every 1K iters\n    if False and iteration % 1000 == 999:\n        inception_score = get_inception_score(netG)\n        lib.plot.plot(\'./tmp/cifar10/inception score\', inception_score[0])\n\n    # Calculate dev loss and generate samples every 100 iters\n    if iteration % 100 == 99:\n        dev_disc_costs = []\n        for images, _ in dev_gen():\n            images = images.reshape(BATCH_SIZE, 3, 32, 32).transpose(0, 2, 3, 1)\n            imgs = torch.stack([preprocess(item) for item in images])\n\n            # imgs = preprocess(images)\n            if use_cuda:\n                imgs = imgs.cuda(gpu)\n            imgs_v = autograd.Variable(imgs, volatile=True)\n\n            D = netD(imgs_v)\n            _dev_disc_cost = -D.mean().cpu().data.numpy()\n            dev_disc_costs.append(_dev_disc_cost)\n        lib.plot.plot(\'./tmp/cifar10/dev disc cost\', np.mean(dev_disc_costs))\n\n        generate_image(iteration, netG)\n\n    # Save logs every 100 iters\n    if (iteration < 5) or (iteration % 100 == 99):\n        lib.plot.flush()\n    lib.plot.tick()\n'"
gan_language.py,14,"b'import os, sys\nsys.path.append(os.getcwd())\n\nimport time\n\nimport numpy as np\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport language_helpers\nimport tflib as lib\nimport tflib.plot\n\nfrom sklearn.preprocessing import OneHotEncoder\n\ntorch.manual_seed(1)\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    gpu = 0\n\n# Download Google Billion Word at http://www.statmt.org/lm-benchmark/ and\n# fill in the path to the extracted files here!\nDATA_DIR = \'./data_language\'\nif len(DATA_DIR) == 0:\n    raise Exception(\'Please specify path to data directory in gan_language.py!\')\n\nBATCH_SIZE = 64 # Batch size\nITERS = 200000 # How many iterations to train for\nSEQ_LEN = 32 # Sequence length in characters\nDIM = 512 # Model dimensionality. This is fairly slow and overfits, even on\n          # Billion Word. Consider decreasing for smaller datasets.\nCRITIC_ITERS = 10 # How many critic iterations per generator iteration. We\n                  # use 10 for the results in the paper, but 5 should work fine\n                  # as well.\nLAMBDA = 10 # Gradient penalty lambda hyperparameter.\nMAX_N_EXAMPLES = 10000000#10000000 # Max number of data examples to load. If data loading\n                          # is too slow or takes too much RAM, you can decrease\n                          # this (at the expense of having less training data).\n\n\nlib.print_model_settings(locals().copy())\n\nlines, charmap, inv_charmap = language_helpers.load_dataset(\n    max_length=SEQ_LEN,\n    max_n_examples=MAX_N_EXAMPLES,\n    data_dir=DATA_DIR\n)\n\ntable = np.arange(len(charmap)).reshape(-1, 1)\none_hot = OneHotEncoder()\none_hot.fit(table)\n\n# ==================Definition Start======================\n\ndef make_noise(shape, volatile=False):\n    tensor = torch.randn(shape).cuda(gpu) if use_cuda else torch.randn(shape)\n    return autograd.Variable(tensor, volatile)\n\nclass ResBlock(nn.Module):\n\n    def __init__(self):\n        super(ResBlock, self).__init__()\n\n        self.res_block = nn.Sequential(\n            nn.ReLU(True),\n            nn.Conv1d(DIM, DIM, 5, padding=2),#nn.Linear(DIM, DIM),\n            nn.ReLU(True),\n            nn.Conv1d(DIM, DIM, 5, padding=2),#nn.Linear(DIM, DIM),\n        )\n\n    def forward(self, input):\n        output = self.res_block(input)\n        return input + (0.3*output)\n\nclass Generator(nn.Module):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.fc1 = nn.Linear(128, DIM*SEQ_LEN)\n        self.block = nn.Sequential(\n            ResBlock(),\n            ResBlock(),\n            ResBlock(),\n            ResBlock(),\n            ResBlock(),\n        )\n        self.conv1 = nn.Conv1d(DIM, len(charmap), 1)\n        self.softmax = nn.Softmax()\n\n    def forward(self, noise):\n        output = self.fc1(noise)\n        output = output.view(-1, DIM, SEQ_LEN) # (BATCH_SIZE, DIM, SEQ_LEN)\n        output = self.block(output)\n        output = self.conv1(output)\n        output = output.transpose(1, 2)\n        shape = output.size()\n        output = output.contiguous()\n        output = output.view(BATCH_SIZE*SEQ_LEN, -1)\n        output = self.softmax(output)\n        return output.view(shape) # (BATCH_SIZE, SEQ_LEN, len(charmap))\n\nclass Discriminator(nn.Module):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.block = nn.Sequential(\n            ResBlock(),\n            ResBlock(),\n            ResBlock(),\n            ResBlock(),\n            ResBlock(),\n        )\n        self.conv1d = nn.Conv1d(len(charmap), DIM, 1)\n        self.linear = nn.Linear(SEQ_LEN*DIM, 1)\n\n    def forward(self, input):\n        output = input.transpose(1, 2) # (BATCH_SIZE, len(charmap), SEQ_LEN)\n        output = self.conv1d(output)\n        output = self.block(output)\n        output = output.view(-1, SEQ_LEN*DIM)\n        output = self.linear(output)\n        return output\n\n# Dataset iterator\ndef inf_train_gen():\n    while True:\n        np.random.shuffle(lines)\n        for i in xrange(0, len(lines)-BATCH_SIZE+1, BATCH_SIZE):\n            yield np.array(\n                [[charmap[c] for c in l] for l in lines[i:i+BATCH_SIZE]],\n                dtype=\'int32\'\n            )\n\ndef calc_gradient_penalty(netD, real_data, fake_data):\n    alpha = torch.rand(BATCH_SIZE, 1, 1)\n    alpha = alpha.expand(real_data.size())\n    alpha = alpha.cuda(gpu) if use_cuda else alpha\n\n    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n\n    if use_cuda:\n        interpolates = interpolates.cuda(gpu)\n    interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n    disc_interpolates = netD(interpolates)\n\n    # TODO: Make ConvBackward diffentiable\n    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(gpu) if use_cuda else torch.ones(\n                                  disc_interpolates.size()),\n                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n    return gradient_penalty\n\ndef generate_samples(netG):\n    noise = torch.randn(BATCH_SIZE, 128)\n    if use_cuda:\n        noise = noise.cuda(gpu)\n    noisev = autograd.Variable(noise, volatile=True)\n    samples = netG(noisev)\n    samples = samples.view(-1, SEQ_LEN, len(charmap))\n    # print samples.size()\n\n    samples = samples.cpu().data.numpy()\n\n    samples = np.argmax(samples, axis=2)\n    decoded_samples = []\n    for i in xrange(len(samples)):\n        decoded = []\n        for j in xrange(len(samples[i])):\n            decoded.append(inv_charmap[samples[i][j]])\n        decoded_samples.append(tuple(decoded))\n    return decoded_samples\n\n# ==================Definition End======================\n\nnetG = Generator()\nnetD = Discriminator()\nprint netG\nprint netD\n\nif use_cuda:\n    netD = netD.cuda(gpu)\n    netG = netG.cuda(gpu)\n\noptimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\noptimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n\none = torch.FloatTensor([1])\nmone = one * -1\nif use_cuda:\n    one = one.cuda(gpu)\n    mone = mone.cuda(gpu)\n\ndata = inf_train_gen()\n\n# During training we monitor JS divergence between the true & generated ngram\n# distributions for n=1,2,3,4. To get an idea of the optimal values, we\n# evaluate these statistics on a held-out set first.\ntrue_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines[10*BATCH_SIZE:], tokenize=False) for i in xrange(4)]\nvalidation_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines[:10*BATCH_SIZE], tokenize=False) for i in xrange(4)]\nfor i in xrange(4):\n    print ""validation set JSD for n={}: {}"".format(i+1, true_char_ngram_lms[i].js_with(validation_char_ngram_lms[i]))\ntrue_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines, tokenize=False) for i in xrange(4)]\n\nfor iteration in xrange(ITERS):\n    start_time = time.time()\n    ############################\n    # (1) Update D network\n    ###########################\n    for p in netD.parameters():  # reset requires_grad\n        p.requires_grad = True  # they are set to False below in netG update\n\n    for iter_d in xrange(CRITIC_ITERS):\n        _data = data.next()\n        data_one_hot = one_hot.transform(_data.reshape(-1, 1)).toarray().reshape(BATCH_SIZE, -1, len(charmap))\n        #print data_one_hot.shape\n        real_data = torch.Tensor(data_one_hot)\n        if use_cuda:\n            real_data = real_data.cuda(gpu)\n        real_data_v = autograd.Variable(real_data)\n\n        netD.zero_grad()\n\n        # train with real\n        D_real = netD(real_data_v)\n        D_real = D_real.mean()\n        # print D_real\n        # TODO: Waiting for the bug fix from pytorch\n        D_real.backward(mone)\n\n        # train with fake\n        noise = torch.randn(BATCH_SIZE, 128)\n        if use_cuda:\n            noise = noise.cuda(gpu)\n        noisev = autograd.Variable(noise, volatile=True)  # totally freeze netG\n        fake = autograd.Variable(netG(noisev).data)\n        inputv = fake\n        D_fake = netD(inputv)\n        D_fake = D_fake.mean()\n        # TODO: Waiting for the bug fix from pytorch\n        D_fake.backward(one)\n\n        # train with gradient penalty\n        gradient_penalty = calc_gradient_penalty(netD, real_data_v.data, fake.data)\n        gradient_penalty.backward()\n\n        D_cost = D_fake - D_real + gradient_penalty\n        Wasserstein_D = D_real - D_fake\n        optimizerD.step()\n\n    ############################\n    # (2) Update G network\n    ###########################\n    for p in netD.parameters():\n        p.requires_grad = False  # to avoid computation\n    netG.zero_grad()\n\n    noise = torch.randn(BATCH_SIZE, 128)\n    if use_cuda:\n        noise = noise.cuda(gpu)\n    noisev = autograd.Variable(noise)\n    fake = netG(noisev)\n    G = netD(fake)\n    G = G.mean()\n    G.backward(mone)\n    G_cost = -G\n    optimizerG.step()\n\n    # Write logs and save samples\n    lib.plot.plot(\'tmp/lang/time\', time.time() - start_time)\n    lib.plot.plot(\'tmp/lang/train disc cost\', D_cost.cpu().data.numpy())\n    lib.plot.plot(\'tmp/lang/train gen cost\', G_cost.cpu().data.numpy())\n    lib.plot.plot(\'tmp/lang/wasserstein distance\', Wasserstein_D.cpu().data.numpy())\n\n    if iteration % 100 == 99:\n        samples = []\n        for i in xrange(10):\n            samples.extend(generate_samples(netG))\n\n        for i in xrange(4):\n            lm = language_helpers.NgramLanguageModel(i+1, samples, tokenize=False)\n            lib.plot.plot(\'tmp/lang/js{}\'.format(i+1), lm.js_with(true_char_ngram_lms[i]))\n\n        with open(\'tmp/lang/samples_{}.txt\'.format(iteration), \'w\') as f:\n            for s in samples:\n                s = """".join(s)\n                f.write(s + ""\\n"")\n\n    if iteration % 100 == 99:\n        lib.plot.flush()\n\n    lib.plot.tick()\n'"
gan_mnist.py,14,"b""import os, sys\nsys.path.append(os.getcwd())\n\nimport time\n\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sklearn.datasets\n\nimport tflib as lib\nimport tflib.save_images\nimport tflib.mnist\nimport tflib.plot\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ntorch.manual_seed(1)\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    gpu = 0\n\nDIM = 64 # Model dimensionality\nBATCH_SIZE = 50 # Batch size\nCRITIC_ITERS = 5 # For WGAN and WGAN-GP, number of critic iters per gen iter\nLAMBDA = 10 # Gradient penalty lambda hyperparameter\nITERS = 200000 # How many generator iterations to train for\nOUTPUT_DIM = 784 # Number of pixels in MNIST (28*28)\n\nlib.print_model_settings(locals().copy())\n\n# ==================Definition Start======================\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        preprocess = nn.Sequential(\n            nn.Linear(128, 4*4*4*DIM),\n            nn.ReLU(True),\n        )\n        block1 = nn.Sequential(\n            nn.ConvTranspose2d(4*DIM, 2*DIM, 5),\n            nn.ReLU(True),\n        )\n        block2 = nn.Sequential(\n            nn.ConvTranspose2d(2*DIM, DIM, 5),\n            nn.ReLU(True),\n        )\n        deconv_out = nn.ConvTranspose2d(DIM, 1, 8, stride=2)\n\n        self.block1 = block1\n        self.block2 = block2\n        self.deconv_out = deconv_out\n        self.preprocess = preprocess\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input):\n        output = self.preprocess(input)\n        output = output.view(-1, 4*DIM, 4, 4)\n        #print output.size()\n        output = self.block1(output)\n        #print output.size()\n        output = output[:, :, :7, :7]\n        #print output.size()\n        output = self.block2(output)\n        #print output.size()\n        output = self.deconv_out(output)\n        output = self.sigmoid(output)\n        #print output.size()\n        return output.view(-1, OUTPUT_DIM)\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        main = nn.Sequential(\n            nn.Conv2d(1, DIM, 5, stride=2, padding=2),\n            # nn.Linear(OUTPUT_DIM, 4*4*4*DIM),\n            nn.ReLU(True),\n            nn.Conv2d(DIM, 2*DIM, 5, stride=2, padding=2),\n            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n            nn.ReLU(True),\n            nn.Conv2d(2*DIM, 4*DIM, 5, stride=2, padding=2),\n            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n            nn.ReLU(True),\n            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n            # nn.LeakyReLU(True),\n            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n            # nn.LeakyReLU(True),\n        )\n        self.main = main\n        self.output = nn.Linear(4*4*4*DIM, 1)\n\n    def forward(self, input):\n        input = input.view(-1, 1, 28, 28)\n        out = self.main(input)\n        out = out.view(-1, 4*4*4*DIM)\n        out = self.output(out)\n        return out.view(-1)\n\ndef generate_image(frame, netG):\n    noise = torch.randn(BATCH_SIZE, 128)\n    if use_cuda:\n        noise = noise.cuda(gpu)\n    noisev = autograd.Variable(noise, volatile=True)\n    samples = netG(noisev)\n    samples = samples.view(BATCH_SIZE, 28, 28)\n    # print samples.size()\n\n    samples = samples.cpu().data.numpy()\n\n    lib.save_images.save_images(\n        samples,\n        'tmp/mnist/samples_{}.png'.format(frame)\n    )\n\n# Dataset iterator\ntrain_gen, dev_gen, test_gen = lib.mnist.load(BATCH_SIZE, BATCH_SIZE)\ndef inf_train_gen():\n    while True:\n        for images,targets in train_gen():\n            yield images\n\ndef calc_gradient_penalty(netD, real_data, fake_data):\n    #print real_data.size()\n    alpha = torch.rand(BATCH_SIZE, 1)\n    alpha = alpha.expand(real_data.size())\n    alpha = alpha.cuda(gpu) if use_cuda else alpha\n\n    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n\n    if use_cuda:\n        interpolates = interpolates.cuda(gpu)\n    interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n    disc_interpolates = netD(interpolates)\n\n    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(gpu) if use_cuda else torch.ones(\n                                  disc_interpolates.size()),\n                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n    return gradient_penalty\n\n# ==================Definition End======================\n\nnetG = Generator()\nnetD = Discriminator()\nprint netG\nprint netD\n\nif use_cuda:\n    netD = netD.cuda(gpu)\n    netG = netG.cuda(gpu)\n\noptimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\noptimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n\none = torch.FloatTensor([1])\nmone = one * -1\nif use_cuda:\n    one = one.cuda(gpu)\n    mone = mone.cuda(gpu)\n\ndata = inf_train_gen()\n\nfor iteration in xrange(ITERS):\n    start_time = time.time()\n    ############################\n    # (1) Update D network\n    ###########################\n    for p in netD.parameters():  # reset requires_grad\n        p.requires_grad = True  # they are set to False below in netG update\n\n    for iter_d in xrange(CRITIC_ITERS):\n        _data = data.next()\n        real_data = torch.Tensor(_data)\n        if use_cuda:\n            real_data = real_data.cuda(gpu)\n        real_data_v = autograd.Variable(real_data)\n\n        netD.zero_grad()\n\n        # train with real\n        D_real = netD(real_data_v)\n        D_real = D_real.mean()\n        # print D_real\n        D_real.backward(mone)\n\n        # train with fake\n        noise = torch.randn(BATCH_SIZE, 128)\n        if use_cuda:\n            noise = noise.cuda(gpu)\n        noisev = autograd.Variable(noise, volatile=True)  # totally freeze netG\n        fake = autograd.Variable(netG(noisev).data)\n        inputv = fake\n        D_fake = netD(inputv)\n        D_fake = D_fake.mean()\n        D_fake.backward(one)\n\n        # train with gradient penalty\n        gradient_penalty = calc_gradient_penalty(netD, real_data_v.data, fake.data)\n        gradient_penalty.backward()\n\n        D_cost = D_fake - D_real + gradient_penalty\n        Wasserstein_D = D_real - D_fake\n        optimizerD.step()\n\n    ############################\n    # (2) Update G network\n    ###########################\n    for p in netD.parameters():\n        p.requires_grad = False  # to avoid computation\n    netG.zero_grad()\n\n    noise = torch.randn(BATCH_SIZE, 128)\n    if use_cuda:\n        noise = noise.cuda(gpu)\n    noisev = autograd.Variable(noise)\n    fake = netG(noisev)\n    G = netD(fake)\n    G = G.mean()\n    G.backward(mone)\n    G_cost = -G\n    optimizerG.step()\n\n    # Write logs and save samples\n    lib.plot.plot('tmp/mnist/time', time.time() - start_time)\n    lib.plot.plot('tmp/mnist/train disc cost', D_cost.cpu().data.numpy())\n    lib.plot.plot('tmp/mnist/train gen cost', G_cost.cpu().data.numpy())\n    lib.plot.plot('tmp/mnist/wasserstein distance', Wasserstein_D.cpu().data.numpy())\n\n    # Calculate dev loss and generate samples every 100 iters\n    if iteration % 100 == 99:\n        dev_disc_costs = []\n        for images,_ in dev_gen():\n            imgs = torch.Tensor(images)\n            if use_cuda:\n                imgs = imgs.cuda(gpu)\n            imgs_v = autograd.Variable(imgs, volatile=True)\n\n            D = netD(imgs_v)\n            _dev_disc_cost = -D.mean().cpu().data.numpy()\n            dev_disc_costs.append(_dev_disc_cost)\n        lib.plot.plot('tmp/mnist/dev disc cost', np.mean(dev_disc_costs))\n\n        generate_image(iteration, netG)\n\n    # Write logs every 100 iters\n    if (iteration < 5) or (iteration % 100 == 99):\n        lib.plot.flush()\n\n    lib.plot.tick()\n"""
gan_toy.py,15,"b'import os, sys\n\nsys.path.append(os.getcwd())\n\nimport random\n\nimport matplotlib\n\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sklearn.datasets\n\nimport tflib as lib\nimport tflib.plot\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ntorch.manual_seed(1)\n\n\nMODE = \'wgan-gp\'  # wgan or wgan-gp\nDATASET = \'8gaussians\'  # 8gaussians, 25gaussians, swissroll\nDIM = 512  # Model dimensionality\nFIXED_GENERATOR = False  # whether to hold the generator fixed at real data plus\n# Gaussian noise, as in the plots in the paper\nLAMBDA = .1  # Smaller lambda seems to help for toy tasks specifically\nCRITIC_ITERS = 5  # How many critic iterations per generator iteration\nBATCH_SIZE = 256  # Batch size\nITERS = 100000  # how many generator iterations to train for\nuse_cuda = True\n\n# ==================Definition Start======================\n\nclass Generator(nn.Module):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        main = nn.Sequential(\n            nn.Linear(2, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, 2),\n        )\n        self.main = main\n\n    def forward(self, noise, real_data):\n        if FIXED_GENERATOR:\n            return noise + real_data\n        else:\n            output = self.main(noise)\n            return output\n\n\nclass Discriminator(nn.Module):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        main = nn.Sequential(\n            nn.Linear(2, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, 1),\n        )\n        self.main = main\n\n    def forward(self, inputs):\n        output = self.main(inputs)\n        return output.view(-1)\n\n\n# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Linear\') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n        m.bias.data.fill_(0)\n    elif classname.find(\'BatchNorm\') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\nframe_index = [0]\ndef generate_image(true_dist):\n    """"""\n    Generates and saves a plot of the true distribution, the generator, and the\n    critic.\n    """"""\n    N_POINTS = 128\n    RANGE = 3\n\n    points = np.zeros((N_POINTS, N_POINTS, 2), dtype=\'float32\')\n    points[:, :, 0] = np.linspace(-RANGE, RANGE, N_POINTS)[:, None]\n    points[:, :, 1] = np.linspace(-RANGE, RANGE, N_POINTS)[None, :]\n    points = points.reshape((-1, 2))\n\n    points_v = autograd.Variable(torch.Tensor(points), volatile=True)\n    if use_cuda:\n        points_v = points_v.cuda()\n    disc_map = netD(points_v).cpu().data.numpy()\n\n    noise = torch.randn(BATCH_SIZE, 2)\n    if use_cuda:\n        noise = noise.cuda()\n    noisev = autograd.Variable(noise, volatile=True)\n    true_dist_v = autograd.Variable(torch.Tensor(true_dist).cuda() if use_cuda else torch.Tensor(true_dist))\n    samples = netG(noisev, true_dist_v).cpu().data.numpy()\n\n    plt.clf()\n\n    x = y = np.linspace(-RANGE, RANGE, N_POINTS)\n    plt.contour(x, y, disc_map.reshape((len(x), len(y))).transpose())\n\n    plt.scatter(true_dist[:, 0], true_dist[:, 1], c=\'orange\', marker=\'+\')\n    if not FIXED_GENERATOR:\n        plt.scatter(samples[:, 0], samples[:, 1], c=\'green\', marker=\'+\')\n\n    plt.savefig(\'tmp/\' + DATASET + \'/\' + \'frame\' + str(frame_index[0]) + \'.jpg\')\n\n    frame_index[0] += 1\n\n\n# Dataset iterator\ndef inf_train_gen():\n    if DATASET == \'25gaussians\':\n\n        dataset = []\n        for i in xrange(100000 / 25):\n            for x in xrange(-2, 3):\n                for y in xrange(-2, 3):\n                    point = np.random.randn(2) * 0.05\n                    point[0] += 2 * x\n                    point[1] += 2 * y\n                    dataset.append(point)\n        dataset = np.array(dataset, dtype=\'float32\')\n        np.random.shuffle(dataset)\n        dataset /= 2.828  # stdev\n        while True:\n            for i in xrange(len(dataset) / BATCH_SIZE):\n                yield dataset[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n\n    elif DATASET == \'swissroll\':\n\n        while True:\n            data = sklearn.datasets.make_swiss_roll(\n                n_samples=BATCH_SIZE,\n                noise=0.25\n            )[0]\n            data = data.astype(\'float32\')[:, [0, 2]]\n            data /= 7.5  # stdev plus a little\n            yield data\n\n    elif DATASET == \'8gaussians\':\n\n        scale = 2.\n        centers = [\n            (1, 0),\n            (-1, 0),\n            (0, 1),\n            (0, -1),\n            (1. / np.sqrt(2), 1. / np.sqrt(2)),\n            (1. / np.sqrt(2), -1. / np.sqrt(2)),\n            (-1. / np.sqrt(2), 1. / np.sqrt(2)),\n            (-1. / np.sqrt(2), -1. / np.sqrt(2))\n        ]\n        centers = [(scale * x, scale * y) for x, y in centers]\n        while True:\n            dataset = []\n            for i in xrange(BATCH_SIZE):\n                point = np.random.randn(2) * .02\n                center = random.choice(centers)\n                point[0] += center[0]\n                point[1] += center[1]\n                dataset.append(point)\n            dataset = np.array(dataset, dtype=\'float32\')\n            dataset /= 1.414  # stdev\n            yield dataset\n\n\ndef calc_gradient_penalty(netD, real_data, fake_data):\n    alpha = torch.rand(BATCH_SIZE, 1)\n    alpha = alpha.expand(real_data.size())\n    alpha = alpha.cuda() if use_cuda else alpha\n\n    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n\n    if use_cuda:\n        interpolates = interpolates.cuda()\n    interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n    disc_interpolates = netD(interpolates)\n\n    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else torch.ones(\n                                  disc_interpolates.size()),\n                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n    return gradient_penalty\n\n# ==================Definition End======================\n\nnetG = Generator()\nnetD = Discriminator()\nnetD.apply(weights_init)\nnetG.apply(weights_init)\nprint netG\nprint netD\n\nif use_cuda:\n    netD = netD.cuda()\n    netG = netG.cuda()\n\noptimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\noptimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n\none = torch.FloatTensor([1])\nmone = one * -1\nif use_cuda:\n    one = one.cuda()\n    mone = mone.cuda()\n\ndata = inf_train_gen()\n\nfor iteration in xrange(ITERS):\n    ############################\n    # (1) Update D network\n    ###########################\n    for p in netD.parameters():  # reset requires_grad\n        p.requires_grad = True  # they are set to False below in netG update\n\n    for iter_d in xrange(CRITIC_ITERS):\n        _data = data.next()\n        real_data = torch.Tensor(_data)\n        if use_cuda:\n            real_data = real_data.cuda()\n        real_data_v = autograd.Variable(real_data)\n\n        netD.zero_grad()\n\n        # train with real\n        D_real = netD(real_data_v)\n        D_real = D_real.mean()\n        D_real.backward(mone)\n\n        # train with fake\n        noise = torch.randn(BATCH_SIZE, 2)\n        if use_cuda:\n            noise = noise.cuda()\n        noisev = autograd.Variable(noise, volatile=True)  # totally freeze netG\n        fake = autograd.Variable(netG(noisev, real_data_v).data)\n        inputv = fake\n        D_fake = netD(inputv)\n        D_fake = D_fake.mean()\n        D_fake.backward(one)\n\n        # train with gradient penalty\n        gradient_penalty = calc_gradient_penalty(netD, real_data_v.data, fake.data)\n        gradient_penalty.backward()\n\n        D_cost = D_fake - D_real + gradient_penalty\n        Wasserstein_D = D_real - D_fake\n        optimizerD.step()\n\n    if not FIXED_GENERATOR:\n        ############################\n        # (2) Update G network\n        ###########################\n        for p in netD.parameters():\n            p.requires_grad = False  # to avoid computation\n        netG.zero_grad()\n\n        _data = data.next()\n        real_data = torch.Tensor(_data)\n        if use_cuda:\n            real_data = real_data.cuda()\n        real_data_v = autograd.Variable(real_data)\n\n        noise = torch.randn(BATCH_SIZE, 2)\n        if use_cuda:\n            noise = noise.cuda()\n        noisev = autograd.Variable(noise)\n        fake = netG(noisev, real_data_v)\n        G = netD(fake)\n        G = G.mean()\n        G.backward(mone)\n        G_cost = -G\n        optimizerG.step()\n\n    # Write logs and save samples\n    lib.plot.plot(\'tmp/\' + DATASET + \'/\' + \'disc cost\', D_cost.cpu().data.numpy())\n    lib.plot.plot(\'tmp/\' + DATASET + \'/\' + \'wasserstein distance\', Wasserstein_D.cpu().data.numpy())\n    if not FIXED_GENERATOR:\n        lib.plot.plot(\'tmp/\' + DATASET + \'/\' + \'gen cost\', G_cost.cpu().data.numpy())\n    if iteration % 100 == 99:\n        lib.plot.flush()\n        generate_image(_data)\n    lib.plot.tick()\n'"
language_helpers.py,0,"b'import collections\nimport numpy as np\nimport re\n\ndef tokenize_string(sample):\n    return tuple(sample.lower().split(\' \'))\n\nclass NgramLanguageModel(object):\n    def __init__(self, n, samples, tokenize=False):\n        if tokenize:\n            tokenized_samples = []\n            for sample in samples:\n                tokenized_samples.append(tokenize_string(sample))\n            samples = tokenized_samples\n\n        self._n = n\n        self._samples = samples\n        self._ngram_counts = collections.defaultdict(int)\n        self._total_ngrams = 0\n        for ngram in self.ngrams():\n            self._ngram_counts[ngram] += 1\n            self._total_ngrams += 1\n\n    def ngrams(self):\n        n = self._n\n        for sample in self._samples:\n            for i in xrange(len(sample)-n+1):\n                yield sample[i:i+n]\n\n    def unique_ngrams(self):\n        return set(self._ngram_counts.keys())\n\n    def log_likelihood(self, ngram):\n        if ngram not in self._ngram_counts:\n            return -np.inf\n        else:\n            return np.log(self._ngram_counts[ngram]) - np.log(self._total_ngrams)\n\n    def kl_to(self, p):\n        # p is another NgramLanguageModel\n        log_likelihood_ratios = []\n        for ngram in p.ngrams():\n            log_likelihood_ratios.append(p.log_likelihood(ngram) - self.log_likelihood(ngram))\n        return np.mean(log_likelihood_ratios)\n\n    def cosine_sim_with(self, p):\n        # p is another NgramLanguageModel\n        p_dot_q = 0.\n        p_norm = 0.\n        q_norm = 0.\n        for ngram in p.unique_ngrams():\n            p_i = np.exp(p.log_likelihood(ngram))\n            q_i = np.exp(self.log_likelihood(ngram))\n            p_dot_q += p_i * q_i\n            p_norm += p_i**2\n        for ngram in self.unique_ngrams():\n            q_i = np.exp(self.log_likelihood(ngram))\n            q_norm += q_i**2\n        return p_dot_q / (np.sqrt(p_norm) * np.sqrt(q_norm))\n\n    def precision_wrt(self, p):\n        # p is another NgramLanguageModel\n        num = 0.\n        denom = 0\n        p_ngrams = p.unique_ngrams()\n        for ngram in self.unique_ngrams():\n            if ngram in p_ngrams:\n                num += self._ngram_counts[ngram]\n            denom += self._ngram_counts[ngram]\n        return float(num) / denom\n\n    def recall_wrt(self, p):\n        return p.precision_wrt(self)\n\n    def js_with(self, p):\n        log_p = np.array([p.log_likelihood(ngram) for ngram in p.unique_ngrams()])\n        log_q = np.array([self.log_likelihood(ngram) for ngram in p.unique_ngrams()])\n        log_m = np.logaddexp(log_p - np.log(2), log_q - np.log(2))\n        kl_p_m = np.sum(np.exp(log_p) * (log_p - log_m))\n\n        log_p = np.array([p.log_likelihood(ngram) for ngram in self.unique_ngrams()])\n        log_q = np.array([self.log_likelihood(ngram) for ngram in self.unique_ngrams()])\n        log_m = np.logaddexp(log_p - np.log(2), log_q - np.log(2))\n        kl_q_m = np.sum(np.exp(log_q) * (log_q - log_m))\n\n        return 0.5*(kl_p_m + kl_q_m) / np.log(2)\n\ndef load_dataset(max_length, max_n_examples, tokenize=False, max_vocab_size=2048, data_dir=\'/home/ishaan/data/1-billion-word-language-modeling-benchmark-r13output\'):\n    print ""loading dataset...""\n\n    lines = []\n\n    finished = False\n\n    for i in xrange(99):\n        path = data_dir+(""/training-monolingual.tokenized.shuffled/news.en-{}-of-00100"".format(str(i+1).zfill(5)))\n        with open(path, \'r\') as f:\n            for line in f:\n                line = line[:-1]\n                if tokenize:\n                    line = tokenize_string(line)\n                else:\n                    line = tuple(line)\n\n                if len(line) > max_length:\n                    line = line[:max_length]\n\n                lines.append(line + ( (""`"",)*(max_length-len(line)) ) )\n\n                if len(lines) == max_n_examples:\n                    finished = True\n                    break\n        if finished:\n            break\n\n    np.random.shuffle(lines)\n\n    import collections\n    counts = collections.Counter(char for line in lines for char in line)\n\n    charmap = {\'unk\':0}\n    inv_charmap = [\'unk\']\n\n    for char,count in counts.most_common(max_vocab_size-1):\n        if char not in charmap:\n            charmap[char] = len(inv_charmap)\n            inv_charmap.append(char)\n\n    filtered_lines = []\n    for line in lines:\n        filtered_line = []\n        for char in line:\n            if char in charmap:\n                filtered_line.append(char)\n            else:\n                filtered_line.append(\'unk\')\n        filtered_lines.append(tuple(filtered_line))\n\n    for i in xrange(100):\n        print filtered_lines[i]\n\n    print ""loaded {} lines in dataset"".format(len(lines))\n    return filtered_lines, charmap, inv_charmap\n'"
tflib/__init__.py,0,"b'import numpy as np\n#import tensorflow as tf\n\nimport locale\n\nlocale.setlocale(locale.LC_ALL, \'\')\n\n_params = {}\n_param_aliases = {}\ndef param(name, *args, **kwargs):\n    """"""\n    A wrapper for `tf.Variable` which enables parameter sharing in models.\n    \n    Creates and returns theano shared variables similarly to `tf.Variable`, \n    except if you try to create a param with the same name as a \n    previously-created one, `param(...)` will just return the old one instead of \n    making a new one.\n\n    This constructor also adds a `param` attribute to the shared variables it \n    creates, so that you can easily search a graph for all params.\n    """"""\n\n    if name not in _params:\n        kwargs[\'name\'] = name\n        param = tf.Variable(*args, **kwargs)\n        param.param = True\n        _params[name] = param\n    result = _params[name]\n    i = 0\n    while result in _param_aliases:\n        # print \'following alias {}: {} to {}\'.format(i, result, _param_aliases[result])\n        i += 1\n        result = _param_aliases[result]\n    return result\n\ndef params_with_name(name):\n    return [p for n,p in _params.items() if name in n]\n\ndef delete_all_params():\n    _params.clear()\n\ndef alias_params(replace_dict):\n    for old,new in replace_dict.items():\n        # print ""aliasing {} to {}"".format(old,new)\n        _param_aliases[old] = new\n\ndef delete_param_aliases():\n    _param_aliases.clear()\n\n# def search(node, critereon):\n#     """"""\n#     Traverse the Theano graph starting at `node` and return a list of all nodes\n#     which match the `critereon` function. When optimizing a cost function, you \n#     can use this to get a list of all of the trainable params in the graph, like\n#     so:\n\n#     `lib.search(cost, lambda x: hasattr(x, ""param""))`\n#     """"""\n\n#     def _search(node, critereon, visited):\n#         if node in visited:\n#             return []\n#         visited.add(node)\n\n#         results = []\n#         if isinstance(node, T.Apply):\n#             for inp in node.inputs:\n#                 results += _search(inp, critereon, visited)\n#         else: # Variable node\n#             if critereon(node):\n#                 results.append(node)\n#             if node.owner is not None:\n#                 results += _search(node.owner, critereon, visited)\n#         return results\n\n#     return _search(node, critereon, set())\n\n# def print_params_info(params):\n#     """"""Print information about the parameters in the given param set.""""""\n\n#     params = sorted(params, key=lambda p: p.name)\n#     values = [p.get_value(borrow=True) for p in params]\n#     shapes = [p.shape for p in values]\n#     print ""Params for cost:""\n#     for param, value, shape in zip(params, values, shapes):\n#         print ""\\t{0} ({1})"".format(\n#             param.name,\n#             "","".join([str(x) for x in shape])\n#         )\n\n#     total_param_count = 0\n#     for shape in shapes:\n#         param_count = 1\n#         for dim in shape:\n#             param_count *= dim\n#         total_param_count += param_count\n#     print ""Total parameter count: {0}"".format(\n#         locale.format(""%d"", total_param_count, grouping=True)\n#     )\n\ndef print_model_settings(locals_):\n    print ""Uppercase local vars:""\n    all_vars = [(k,v) for (k,v) in locals_.items() if (k.isupper() and k!=\'T\' and k!=\'SETTINGS\' and k!=\'ALL_SETTINGS\')]\n    all_vars = sorted(all_vars, key=lambda x: x[0])\n    for var_name, var_value in all_vars:\n        print ""\\t{}: {}"".format(var_name, var_value)\n\n\ndef print_model_settings_dict(settings):\n    print ""Settings dict:""\n    all_vars = [(k,v) for (k,v) in settings.items()]\n    all_vars = sorted(all_vars, key=lambda x: x[0])\n    for var_name, var_value in all_vars:\n        print ""\\t{}: {}"".format(var_name, var_value)\n'"
tflib/cifar10.py,0,"b""import numpy as np\n\nimport os\nimport urllib\nimport gzip\nimport cPickle as pickle\n\ndef unpickle(file):\n    fo = open(file, 'rb')\n    dict = pickle.load(fo)\n    fo.close()\n    return dict['data']\n\ndef cifar_generator(filenames, batch_size, data_dir):\n    all_data = []\n    for filename in filenames:\n        all_data.append(unpickle(data_dir + '/' + filename))\n\n    images = np.concatenate(all_data, axis=0)\n\n    def get_epoch():\n        np.random.shuffle(images)\n\n        for i in xrange(len(images) / batch_size):\n            yield np.copy(images[i*batch_size:(i+1)*batch_size])\n\n    return get_epoch\n\n\ndef load(batch_size, data_dir):\n    return (\n        cifar_generator(['data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5'], batch_size, data_dir), \n        cifar_generator(['test_batch'], batch_size, data_dir)\n    )\n"""
tflib/inception_score.py,0,"b'# From https://github.com/openai/improved-gan/blob/master/inception_score/model.py\n# Code derived from tensorflow/tensorflow/models/image/imagenet/classify_image.py\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os.path\nimport sys\nimport tarfile\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow as tf\nimport glob\nimport scipy.misc\nimport math\nimport sys\n\nMODEL_DIR = \'/tmp/imagenet\'\nDATA_URL = \'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\'\nsoftmax = None\n\n# Call this function with list of images. Each of elements should be a \n# numpy array with values ranging from 0 to 255.\ndef get_inception_score(images, splits=10):\n  assert(type(images) == list)\n  assert(type(images[0]) == np.ndarray)\n  assert(len(images[0].shape) == 3)\n  assert(np.max(images[0]) > 10)\n  assert(np.min(images[0]) >= 0.0)\n  inps = []\n  for img in images:\n    img = img.astype(np.float32)\n    inps.append(np.expand_dims(img, 0))\n  bs = 100\n  with tf.Session() as sess:\n    preds = []\n    n_batches = int(math.ceil(float(len(inps)) / float(bs)))\n    for i in range(n_batches):\n        # sys.stdout.write(""."")\n        # sys.stdout.flush()\n        inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\n        inp = np.concatenate(inp, 0)\n        pred = sess.run(softmax, {\'ExpandDims:0\': inp})\n        preds.append(pred)\n    preds = np.concatenate(preds, 0)\n    scores = []\n    for i in range(splits):\n      part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n      kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n      kl = np.mean(np.sum(kl, 1))\n      scores.append(np.exp(kl))\n    return np.mean(scores), np.std(scores)\n\n# This function is called automatically.\ndef _init_inception():\n  global softmax\n  if not os.path.exists(MODEL_DIR):\n    os.makedirs(MODEL_DIR)\n  filename = DATA_URL.split(\'/\')[-1]\n  filepath = os.path.join(MODEL_DIR, filename)\n  if not os.path.exists(filepath):\n    def _progress(count, block_size, total_size):\n      sys.stdout.write(\'\\r>> Downloading %s %.1f%%\' % (\n          filename, float(count * block_size) / float(total_size) * 100.0))\n      sys.stdout.flush()\n    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n    print()\n    statinfo = os.stat(filepath)\n    print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n  tarfile.open(filepath, \'r:gz\').extractall(MODEL_DIR)\n  with tf.gfile.FastGFile(os.path.join(\n      MODEL_DIR, \'classify_image_graph_def.pb\'), \'rb\') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    _ = tf.import_graph_def(graph_def, name=\'\')\n  # Works with an arbitrary minibatch size.\n  with tf.Session() as sess:\n    pool3 = sess.graph.get_tensor_by_name(\'pool_3:0\')\n    ops = pool3.graph.get_operations()\n    for op_idx, op in enumerate(ops):\n        for o in op.outputs:\n            shape = o.get_shape()\n            shape = [s.value for s in shape]\n            new_shape = []\n            for j, s in enumerate(shape):\n                if s == 1 and j == 0:\n                    new_shape.append(None)\n                else:\n                    new_shape.append(s)\n            o._shape = tf.TensorShape(new_shape)\n    w = sess.graph.get_operation_by_name(""softmax/logits/MatMul"").inputs[1]\n    logits = tf.matmul(tf.squeeze(pool3), w)\n    softmax = tf.nn.softmax(logits)\n\nif softmax is None:\n  _init_inception()\n'"
tflib/mnist.py,0,"b'import numpy\n\nimport os\nimport urllib\nimport gzip\nimport cPickle as pickle\n\ndef mnist_generator(data, batch_size, n_labelled, limit=None):\n    images, targets = data\n\n    rng_state = numpy.random.get_state()\n    numpy.random.shuffle(images)\n    numpy.random.set_state(rng_state)\n    numpy.random.shuffle(targets)\n    if limit is not None:\n        print ""WARNING ONLY FIRST {} MNIST DIGITS"".format(limit)\n        images = images.astype(\'float32\')[:limit]\n        targets = targets.astype(\'int32\')[:limit]\n    if n_labelled is not None:\n        labelled = numpy.zeros(len(images), dtype=\'int32\')\n        labelled[:n_labelled] = 1\n\n    def get_epoch():\n        rng_state = numpy.random.get_state()\n        numpy.random.shuffle(images)\n        numpy.random.set_state(rng_state)\n        numpy.random.shuffle(targets)\n\n        if n_labelled is not None:\n            numpy.random.set_state(rng_state)\n            numpy.random.shuffle(labelled)\n\n        image_batches = images.reshape(-1, batch_size, 784)\n        target_batches = targets.reshape(-1, batch_size)\n\n        if n_labelled is not None:\n            labelled_batches = labelled.reshape(-1, batch_size)\n\n            for i in xrange(len(image_batches)):\n                yield (numpy.copy(image_batches[i]), numpy.copy(target_batches[i]), numpy.copy(labelled))\n\n        else:\n\n            for i in xrange(len(image_batches)):\n                yield (numpy.copy(image_batches[i]), numpy.copy(target_batches[i]))\n\n    return get_epoch\n\ndef load(batch_size, test_batch_size, n_labelled=None):\n    filepath = \'/tmp/mnist.pkl.gz\'\n    url = \'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz\'\n\n    if not os.path.isfile(filepath):\n        print ""Couldn\'t find MNIST dataset in /tmp, downloading...""\n        urllib.urlretrieve(url, filepath)\n\n    with gzip.open(\'/tmp/mnist.pkl.gz\', \'rb\') as f:\n        train_data, dev_data, test_data = pickle.load(f)\n\n    return (\n        mnist_generator(train_data, batch_size, n_labelled), \n        mnist_generator(dev_data, test_batch_size, n_labelled), \n        mnist_generator(test_data, test_batch_size, n_labelled)\n    )'"
tflib/plot.py,0,"b'import numpy as np\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\n\nimport collections\nimport time\nimport cPickle as pickle\n\n_since_beginning = collections.defaultdict(lambda: {})\n_since_last_flush = collections.defaultdict(lambda: {})\n\n_iter = [0]\ndef tick():\n\t_iter[0] += 1\n\ndef plot(name, value):\n\t_since_last_flush[name][_iter[0]] = value\n\ndef flush():\n\tprints = []\n\n\tfor name, vals in _since_last_flush.items():\n\t\tprints.append(""{}\\t{}"".format(name, np.mean(vals.values())))\n\t\t_since_beginning[name].update(vals)\n\n\t\tx_vals = np.sort(_since_beginning[name].keys())\n\t\ty_vals = [_since_beginning[name][x] for x in x_vals]\n\n\t\tplt.clf()\n\t\tplt.plot(x_vals, y_vals)\n\t\tplt.xlabel(\'iteration\')\n\t\tplt.ylabel(name)\n\t\tplt.savefig(name.replace(\' \', \'_\')+\'.jpg\')\n\n\tprint ""iter {}\\t{}"".format(_iter[0], ""\\t"".join(prints))\n\t_since_last_flush.clear()\n\n\twith open(\'log.pkl\', \'wb\') as f:\n\t\tpickle.dump(dict(_since_beginning), f, pickle.HIGHEST_PROTOCOL)'"
tflib/save_images.py,0,"b'""""""\nImage grid saver, based on color_grid_vis from github.com/Newmu\n""""""\n\nimport numpy as np\nimport scipy.misc\nfrom scipy.misc import imsave\n\ndef save_images(X, save_path):\n    # [0, 1] -> [0,255]\n    if isinstance(X.flatten()[0], np.floating):\n        X = (255.99*X).astype(\'uint8\')\n\n    n_samples = X.shape[0]\n    rows = int(np.sqrt(n_samples))\n    while n_samples % rows != 0:\n        rows -= 1\n\n    nh, nw = rows, n_samples/rows\n\n    if X.ndim == 2:\n        X = np.reshape(X, (X.shape[0], int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1]))))\n\n    if X.ndim == 4:\n        # BCHW -> BHWC\n        X = X.transpose(0,2,3,1)\n        h, w = X[0].shape[:2]\n        img = np.zeros((h*nh, w*nw, 3))\n    elif X.ndim == 3:\n        h, w = X[0].shape[:2]\n        img = np.zeros((h*nh, w*nw))\n\n    for n, x in enumerate(X):\n        j = n/nw\n        i = n%nw\n        img[j*h:j*h+h, i*w:i*w+w] = x\n\n    imsave(save_path, img)'"
tflib/small_imagenet.py,0,"b'import numpy as np\nimport scipy.misc\nimport time\n\ndef make_generator(path, n_files, batch_size):\n    epoch_count = [1]\n    def get_epoch():\n        images = np.zeros((batch_size, 3, 64, 64), dtype=\'int32\')\n        files = range(n_files)\n        random_state = np.random.RandomState(epoch_count[0])\n        random_state.shuffle(files)\n        epoch_count[0] += 1\n        for n, i in enumerate(files):\n            image = scipy.misc.imread(""{}/{}.png"".format(path, str(i+1).zfill(len(str(n_files)))))\n            images[n % batch_size] = image.transpose(2,0,1)\n            if n > 0 and n % batch_size == 0:\n                yield (images,)\n    return get_epoch\n\ndef load(batch_size, data_dir=\'/home/ishaan/data/imagenet64\'):\n    return (\n        make_generator(data_dir+\'/train_64x64\', 1281149, batch_size),\n        make_generator(data_dir+\'/valid_64x64\', 49999, batch_size)\n    )\n\nif __name__ == \'__main__\':\n    train_gen, valid_gen = load(64)\n    t0 = time.time()\n    for i, batch in enumerate(train_gen(), start=1):\n        print ""{}\\t{}"".format(str(time.time() - t0), batch[0][0,0,0,0])\n        if i == 1000:\n            break\n        t0 = time.time()'"
tflib/ops/__init__.py,0,b''
tflib/ops/batchnorm.py,0,"b'import tflib as lib\n\nimport numpy as np\nimport tensorflow as tf\n\ndef Batchnorm(name, axes, inputs, is_training=None, stats_iter=None, update_moving_stats=True, fused=True):\n    if ((axes == [0,2,3]) or (axes == [0,2])) and fused==True:\n        if axes==[0,2]:\n            inputs = tf.expand_dims(inputs, 3)\n        # Old (working but pretty slow) implementation:\n        ##########\n\n        # inputs = tf.transpose(inputs, [0,2,3,1])\n\n        # mean, var = tf.nn.moments(inputs, [0,1,2], keep_dims=False)\n        # offset = lib.param(name+\'.offset\', np.zeros(mean.get_shape()[-1], dtype=\'float32\'))\n        # scale = lib.param(name+\'.scale\', np.ones(var.get_shape()[-1], dtype=\'float32\'))\n        # result = tf.nn.batch_normalization(inputs, mean, var, offset, scale, 1e-4)\n\n        # return tf.transpose(result, [0,3,1,2])\n\n        # New (super fast but untested) implementation:\n        offset = lib.param(name+\'.offset\', np.zeros(inputs.get_shape()[1], dtype=\'float32\'))\n        scale = lib.param(name+\'.scale\', np.ones(inputs.get_shape()[1], dtype=\'float32\'))\n\n        moving_mean = lib.param(name+\'.moving_mean\', np.zeros(inputs.get_shape()[1], dtype=\'float32\'), trainable=False)\n        moving_variance = lib.param(name+\'.moving_variance\', np.ones(inputs.get_shape()[1], dtype=\'float32\'), trainable=False)\n\n        def _fused_batch_norm_training():\n            return tf.nn.fused_batch_norm(inputs, scale, offset, epsilon=1e-5, data_format=\'NCHW\')\n        def _fused_batch_norm_inference():\n            # Version which blends in the current item\'s statistics\n            batch_size = tf.cast(tf.shape(inputs)[0], \'float32\')\n            mean, var = tf.nn.moments(inputs, [2,3], keep_dims=True)\n            mean = ((1./batch_size)*mean) + (((batch_size-1.)/batch_size)*moving_mean)[None,:,None,None]\n            var = ((1./batch_size)*var) + (((batch_size-1.)/batch_size)*moving_variance)[None,:,None,None]\n            return tf.nn.batch_normalization(inputs, mean, var, offset[None,:,None,None], scale[None,:,None,None], 1e-5), mean, var\n\n            # Standard version\n            # return tf.nn.fused_batch_norm(\n            #     inputs,\n            #     scale,\n            #     offset,\n            #     epsilon=1e-2, \n            #     mean=moving_mean,\n            #     variance=moving_variance,\n            #     is_training=False,\n            #     data_format=\'NCHW\'\n            # )\n\n        if is_training is None:\n            outputs, batch_mean, batch_var = _fused_batch_norm_training()\n        else:\n            outputs, batch_mean, batch_var = tf.cond(is_training,\n                                                       _fused_batch_norm_training,\n                                                       _fused_batch_norm_inference)\n            if update_moving_stats:\n                no_updates = lambda: outputs\n                def _force_updates():\n                    """"""Internal function forces updates moving_vars if is_training.""""""\n                    float_stats_iter = tf.cast(stats_iter, tf.float32)\n\n                    update_moving_mean = tf.assign(moving_mean, ((float_stats_iter/(float_stats_iter+1))*moving_mean) + ((1/(float_stats_iter+1))*batch_mean))\n                    update_moving_variance = tf.assign(moving_variance, ((float_stats_iter/(float_stats_iter+1))*moving_variance) + ((1/(float_stats_iter+1))*batch_var))\n\n                    with tf.control_dependencies([update_moving_mean, update_moving_variance]):\n                        return tf.identity(outputs)\n                outputs = tf.cond(is_training, _force_updates, no_updates)\n\n        if axes == [0,2]:\n            return outputs[:,:,:,0] # collapse last dim\n        else:\n            return outputs\n    else:\n        # raise Exception(\'old BN\')\n        # TODO we can probably use nn.fused_batch_norm here too for speedup\n        mean, var = tf.nn.moments(inputs, axes, keep_dims=True)\n        shape = mean.get_shape().as_list()\n        if 0 not in axes:\n            print ""WARNING ({}): didn\'t find 0 in axes, but not using separate BN params for each item in batch"".format(name)\n            shape[0] = 1\n        offset = lib.param(name+\'.offset\', np.zeros(shape, dtype=\'float32\'))\n        scale = lib.param(name+\'.scale\', np.ones(shape, dtype=\'float32\'))\n        result = tf.nn.batch_normalization(inputs, mean, var, offset, scale, 1e-5)\n\n\n        return result\n'"
tflib/ops/conv1d.py,0,"b'import tflib as lib\n\nimport numpy as np\nimport tensorflow as tf\n\n_default_weightnorm = False\ndef enable_default_weightnorm():\n    global _default_weightnorm\n    _default_weightnorm = True\n\ndef Conv1D(name, input_dim, output_dim, filter_size, inputs, he_init=True, mask_type=None, stride=1, weightnorm=None, biases=True, gain=1.):\n    """"""\n    inputs: tensor of shape (batch size, num channels, width)\n    mask_type: one of None, \'a\', \'b\'\n\n    returns: tensor of shape (batch size, num channels, width)\n    """"""\n    with tf.name_scope(name) as scope:\n\n        if mask_type is not None:\n            mask_type, mask_n_channels = mask_type\n\n            mask = np.ones(\n                (filter_size, input_dim, output_dim), \n                dtype=\'float32\'\n            )\n            center = filter_size // 2\n\n            # Mask out future locations\n            # filter shape is (width, input channels, output channels)\n            mask[center+1:, :, :] = 0.\n\n            # Mask out future channels\n            for i in xrange(mask_n_channels):\n                for j in xrange(mask_n_channels):\n                    if (mask_type==\'a\' and i >= j) or (mask_type==\'b\' and i > j):\n                        mask[\n                            center,\n                            i::mask_n_channels,\n                            j::mask_n_channels\n                        ] = 0.\n\n\n        def uniform(stdev, size):\n            return np.random.uniform(\n                low=-stdev * np.sqrt(3),\n                high=stdev * np.sqrt(3),\n                size=size\n            ).astype(\'float32\')\n\n        fan_in = input_dim * filter_size\n        fan_out = output_dim * filter_size / stride\n\n        if mask_type is not None: # only approximately correct\n            fan_in /= 2.\n            fan_out /= 2.\n\n        if he_init:\n            filters_stdev = np.sqrt(4./(fan_in+fan_out))\n        else: # Normalized init (Glorot & Bengio)\n            filters_stdev = np.sqrt(2./(fan_in+fan_out))\n\n        filter_values = uniform(\n            filters_stdev,\n            (filter_size, input_dim, output_dim)\n        )\n        # print ""WARNING IGNORING GAIN""\n        filter_values *= gain\n\n        filters = lib.param(name+\'.Filters\', filter_values)\n\n        if weightnorm==None:\n            weightnorm = _default_weightnorm\n        if weightnorm:\n            norm_values = np.sqrt(np.sum(np.square(filter_values), axis=(0,1)))\n            target_norms = lib.param(\n                name + \'.g\',\n                norm_values\n            )\n            with tf.name_scope(\'weightnorm\') as scope:\n                norms = tf.sqrt(tf.reduce_sum(tf.square(filters), reduction_indices=[0,1]))\n                filters = filters * (target_norms / norms)\n\n        if mask_type is not None:\n            with tf.name_scope(\'filter_mask\'):\n                filters = filters * mask\n\n        result = tf.nn.conv1d(\n            value=inputs, \n            filters=filters, \n            stride=stride,\n            padding=\'SAME\',\n            data_format=\'NCHW\'\n        )\n\n        if biases:\n            _biases = lib.param(\n                name+\'.Biases\',\n                np.zeros([output_dim], dtype=\'float32\')\n            )\n\n            # result = result + _biases\n\n            result = tf.expand_dims(result, 3)\n            result = tf.nn.bias_add(result, _biases, data_format=\'NCHW\')\n            result = tf.squeeze(result)\n\n        return result\n'"
tflib/ops/conv2d.py,0,"b'import tflib as lib\n\nimport numpy as np\nimport tensorflow as tf\n\n_default_weightnorm = False\ndef enable_default_weightnorm():\n    global _default_weightnorm\n    _default_weightnorm = True\n\n_weights_stdev = None\ndef set_weights_stdev(weights_stdev):\n    global _weights_stdev\n    _weights_stdev = weights_stdev\n\ndef unset_weights_stdev():\n    global _weights_stdev\n    _weights_stdev = None\n\ndef Conv2D(name, input_dim, output_dim, filter_size, inputs, he_init=True, mask_type=None, stride=1, weightnorm=None, biases=True, gain=1.):\n    """"""\n    inputs: tensor of shape (batch size, num channels, height, width)\n    mask_type: one of None, \'a\', \'b\'\n\n    returns: tensor of shape (batch size, num channels, height, width)\n    """"""\n    with tf.name_scope(name) as scope:\n\n        if mask_type is not None:\n            mask_type, mask_n_channels = mask_type\n\n            mask = np.ones(\n                (filter_size, filter_size, input_dim, output_dim), \n                dtype=\'float32\'\n            )\n            center = filter_size // 2\n\n            # Mask out future locations\n            # filter shape is (height, width, input channels, output channels)\n            mask[center+1:, :, :, :] = 0.\n            mask[center, center+1:, :, :] = 0.\n\n            # Mask out future channels\n            for i in xrange(mask_n_channels):\n                for j in xrange(mask_n_channels):\n                    if (mask_type==\'a\' and i >= j) or (mask_type==\'b\' and i > j):\n                        mask[\n                            center,\n                            center,\n                            i::mask_n_channels,\n                            j::mask_n_channels\n                        ] = 0.\n\n\n        def uniform(stdev, size):\n            return np.random.uniform(\n                low=-stdev * np.sqrt(3),\n                high=stdev * np.sqrt(3),\n                size=size\n            ).astype(\'float32\')\n\n        fan_in = input_dim * filter_size**2\n        fan_out = output_dim * filter_size**2 / (stride**2)\n\n        if mask_type is not None: # only approximately correct\n            fan_in /= 2.\n            fan_out /= 2.\n\n        if he_init:\n            filters_stdev = np.sqrt(4./(fan_in+fan_out))\n        else: # Normalized init (Glorot & Bengio)\n            filters_stdev = np.sqrt(2./(fan_in+fan_out))\n\n        if _weights_stdev is not None:\n            filter_values = uniform(\n                _weights_stdev,\n                (filter_size, filter_size, input_dim, output_dim)\n            )\n        else:\n            filter_values = uniform(\n                filters_stdev,\n                (filter_size, filter_size, input_dim, output_dim)\n            )\n\n        # print ""WARNING IGNORING GAIN""\n        filter_values *= gain\n\n        filters = lib.param(name+\'.Filters\', filter_values)\n\n        if weightnorm==None:\n            weightnorm = _default_weightnorm\n        if weightnorm:\n            norm_values = np.sqrt(np.sum(np.square(filter_values), axis=(0,1,2)))\n            target_norms = lib.param(\n                name + \'.g\',\n                norm_values\n            )\n            with tf.name_scope(\'weightnorm\') as scope:\n                norms = tf.sqrt(tf.reduce_sum(tf.square(filters), reduction_indices=[0,1,2]))\n                filters = filters * (target_norms / norms)\n\n        if mask_type is not None:\n            with tf.name_scope(\'filter_mask\'):\n                filters = filters * mask\n\n        result = tf.nn.conv2d(\n            input=inputs, \n            filter=filters, \n            strides=[1, 1, stride, stride],\n            padding=\'SAME\',\n            data_format=\'NCHW\'\n        )\n\n        if biases:\n            _biases = lib.param(\n                name+\'.Biases\',\n                np.zeros(output_dim, dtype=\'float32\')\n            )\n\n            result = tf.nn.bias_add(result, _biases, data_format=\'NCHW\')\n\n\n        return result\n'"
tflib/ops/deconv2d.py,0,"b'import tflib as lib\n\nimport numpy as np\nimport tensorflow as tf\n\n_default_weightnorm = False\ndef enable_default_weightnorm():\n    global _default_weightnorm\n    _default_weightnorm = True\n\n_weights_stdev = None\ndef set_weights_stdev(weights_stdev):\n    global _weights_stdev\n    _weights_stdev = weights_stdev\n\ndef unset_weights_stdev():\n    global _weights_stdev\n    _weights_stdev = None\n\ndef Deconv2D(\n    name, \n    input_dim, \n    output_dim, \n    filter_size, \n    inputs, \n    he_init=True,\n    weightnorm=None,\n    biases=True,\n    gain=1.,\n    mask_type=None,\n    ):\n    """"""\n    inputs: tensor of shape (batch size, height, width, input_dim)\n    returns: tensor of shape (batch size, 2*height, 2*width, output_dim)\n    """"""\n    with tf.name_scope(name) as scope:\n\n        if mask_type != None:\n            raise Exception(\'Unsupported configuration\')\n\n        def uniform(stdev, size):\n            return np.random.uniform(\n                low=-stdev * np.sqrt(3),\n                high=stdev * np.sqrt(3),\n                size=size\n            ).astype(\'float32\')\n\n        stride = 2\n        fan_in = input_dim * filter_size**2 / (stride**2)\n        fan_out = output_dim * filter_size**2\n\n        if he_init:\n            filters_stdev = np.sqrt(4./(fan_in+fan_out))\n        else: # Normalized init (Glorot & Bengio)\n            filters_stdev = np.sqrt(2./(fan_in+fan_out))\n\n\n        if _weights_stdev is not None:\n            filter_values = uniform(\n                _weights_stdev,\n                (filter_size, filter_size, output_dim, input_dim)\n            )\n        else:\n            filter_values = uniform(\n                filters_stdev,\n                (filter_size, filter_size, output_dim, input_dim)\n            )\n\n        filter_values *= gain\n\n        filters = lib.param(\n            name+\'.Filters\',\n            filter_values\n        )\n\n        if weightnorm==None:\n            weightnorm = _default_weightnorm\n        if weightnorm:\n            norm_values = np.sqrt(np.sum(np.square(filter_values), axis=(0,1,3)))\n            target_norms = lib.param(\n                name + \'.g\',\n                norm_values\n            )\n            with tf.name_scope(\'weightnorm\') as scope:\n                norms = tf.sqrt(tf.reduce_sum(tf.square(filters), reduction_indices=[0,1,3]))\n                filters = filters * tf.expand_dims(target_norms / norms, 1)\n\n\n        inputs = tf.transpose(inputs, [0,2,3,1], name=\'NCHW_to_NHWC\')\n\n        input_shape = tf.shape(inputs)\n        try: # tf pre-1.0 (top) vs 1.0 (bottom)\n            output_shape = tf.pack([input_shape[0], 2*input_shape[1], 2*input_shape[2], output_dim])\n        except Exception as e:\n            output_shape = tf.stack([input_shape[0], 2*input_shape[1], 2*input_shape[2], output_dim])\n\n        result = tf.nn.conv2d_transpose(\n            value=inputs, \n            filter=filters,\n            output_shape=output_shape, \n            strides=[1, 2, 2, 1],\n            padding=\'SAME\'\n        )\n\n        if biases:\n            _biases = lib.param(\n                name+\'.Biases\',\n                np.zeros(output_dim, dtype=\'float32\')\n            )\n            result = tf.nn.bias_add(result, _biases)\n\n        result = tf.transpose(result, [0,3,1,2], name=\'NHWC_to_NCHW\')\n\n\n        return result\n'"
tflib/ops/layernorm.py,0,"b""import tflib as lib\n\nimport numpy as np\nimport tensorflow as tf\n\ndef Layernorm(name, norm_axes, inputs):\n    mean, var = tf.nn.moments(inputs, norm_axes, keep_dims=True)\n\n    # Assume the 'neurons' axis is the first of norm_axes. This is the case for fully-connected and BCHW conv layers.\n    n_neurons = inputs.get_shape().as_list()[norm_axes[0]]\n\n    offset = lib.param(name+'.offset', np.zeros(n_neurons, dtype='float32'))\n    scale = lib.param(name+'.scale', np.ones(n_neurons, dtype='float32'))\n\n    # Add broadcasting dims to offset and scale (e.g. BCHW conv data)\n    offset = tf.reshape(offset, [-1] + [1 for i in xrange(len(norm_axes)-1)])\n    scale = tf.reshape(scale, [-1] + [1 for i in xrange(len(norm_axes)-1)])\n\n    result = tf.nn.batch_normalization(inputs, mean, var, offset, scale, 1e-5)\n\n    return result"""
tflib/ops/linear.py,0,"b'import tflib as lib\n\nimport numpy as np\nimport tensorflow as tf\n\n_default_weightnorm = False\ndef enable_default_weightnorm():\n    global _default_weightnorm\n    _default_weightnorm = True\n\ndef disable_default_weightnorm():\n    global _default_weightnorm\n    _default_weightnorm = False\n\n_weights_stdev = None\ndef set_weights_stdev(weights_stdev):\n    global _weights_stdev\n    _weights_stdev = weights_stdev\n\ndef unset_weights_stdev():\n    global _weights_stdev\n    _weights_stdev = None\n\ndef Linear(\n        name, \n        input_dim, \n        output_dim, \n        inputs,\n        biases=True,\n        initialization=None,\n        weightnorm=None,\n        gain=1.\n        ):\n    """"""\n    initialization: None, `lecun`, \'glorot\', `he`, \'glorot_he\', `orthogonal`, `(""uniform"", range)`\n    """"""\n    with tf.name_scope(name) as scope:\n\n        def uniform(stdev, size):\n            if _weights_stdev is not None:\n                stdev = _weights_stdev\n            return np.random.uniform(\n                low=-stdev * np.sqrt(3),\n                high=stdev * np.sqrt(3),\n                size=size\n            ).astype(\'float32\')\n\n        if initialization == \'lecun\':# and input_dim != output_dim):\n            # disabling orth. init for now because it\'s too slow\n            weight_values = uniform(\n                np.sqrt(1./input_dim),\n                (input_dim, output_dim)\n            )\n\n        elif initialization == \'glorot\' or (initialization == None):\n\n            weight_values = uniform(\n                np.sqrt(2./(input_dim+output_dim)),\n                (input_dim, output_dim)\n            )\n\n        elif initialization == \'he\':\n\n            weight_values = uniform(\n                np.sqrt(2./input_dim),\n                (input_dim, output_dim)\n            )\n\n        elif initialization == \'glorot_he\':\n\n            weight_values = uniform(\n                np.sqrt(4./(input_dim+output_dim)),\n                (input_dim, output_dim)\n            )\n\n        elif initialization == \'orthogonal\' or \\\n            (initialization == None and input_dim == output_dim):\n            \n            # From lasagne\n            def sample(shape):\n                if len(shape) < 2:\n                    raise RuntimeError(""Only shapes of length 2 or more are ""\n                                       ""supported."")\n                flat_shape = (shape[0], np.prod(shape[1:]))\n                 # TODO: why normal and not uniform?\n                a = np.random.normal(0.0, 1.0, flat_shape)\n                u, _, v = np.linalg.svd(a, full_matrices=False)\n                # pick the one with the correct shape\n                q = u if u.shape == flat_shape else v\n                q = q.reshape(shape)\n                return q.astype(\'float32\')\n            weight_values = sample((input_dim, output_dim))\n        \n        elif initialization[0] == \'uniform\':\n        \n            weight_values = np.random.uniform(\n                low=-initialization[1],\n                high=initialization[1],\n                size=(input_dim, output_dim)\n            ).astype(\'float32\')\n\n        else:\n\n            raise Exception(\'Invalid initialization!\')\n\n        weight_values *= gain\n\n        weight = lib.param(\n            name + \'.W\',\n            weight_values\n        )\n\n        if weightnorm==None:\n            weightnorm = _default_weightnorm\n        if weightnorm:\n            norm_values = np.sqrt(np.sum(np.square(weight_values), axis=0))\n            # norm_values = np.linalg.norm(weight_values, axis=0)\n\n            target_norms = lib.param(\n                name + \'.g\',\n                norm_values\n            )\n\n            with tf.name_scope(\'weightnorm\') as scope:\n                norms = tf.sqrt(tf.reduce_sum(tf.square(weight), reduction_indices=[0]))\n                weight = weight * (target_norms / norms)\n\n        # if \'Discriminator\' in name:\n        #     print ""WARNING weight constraint on {}"".format(name)\n        #     weight = tf.nn.softsign(10.*weight)*.1\n\n        if inputs.get_shape().ndims == 2:\n            result = tf.matmul(inputs, weight)\n        else:\n            reshaped_inputs = tf.reshape(inputs, [-1, input_dim])\n            result = tf.matmul(reshaped_inputs, weight)\n            result = tf.reshape(result, tf.pack(tf.unpack(tf.shape(inputs))[:-1] + [output_dim]))\n\n        if biases:\n            result = tf.nn.bias_add(\n                result,\n                lib.param(\n                    name + \'.b\',\n                    np.zeros((output_dim,), dtype=\'float32\')\n                )\n            )\n\n        return result'"
