file_path,api_count,code
config.py,0,"b'#-*- coding: utf-8 -*-\nimport argparse\n\ndef str2bool(v):\n    return v.lower() in (\'true\', \'1\')\n\narg_lists = []\nparser = argparse.ArgumentParser()\n\ndef add_argument_group(name):\n    arg = parser.add_argument_group(name)\n    arg_lists.append(arg)\n    return arg\n\n# Network\nnet_arg = add_argument_group(\'Network\')\nnet_arg.add_argument(\'--input_scale_size\', type=int, default=64,\n                     help=\'input image will be resized with the given value as width and height\')\nnet_arg.add_argument(\'--g_num_layer\', type=int, default=3)\nnet_arg.add_argument(\'--d_num_layer\', type=int, default=5)\nnet_arg.add_argument(\'--cnn_type\', type=int, default=0)\nnet_arg.add_argument(\'--fc_hidden_dim\', type=int, default=128, help=\'only for toy dataset\')\n\n# Data\ndata_arg = add_argument_group(\'Data\')\ndata_arg.add_argument(\'--dataset\', type=str, default=\'edges2shoes\')\ndata_arg.add_argument(\'--batch_size\', type=int, default=200)\ndata_arg.add_argument(\'--a_grayscale\', type=str2bool, default=False)\ndata_arg.add_argument(\'--b_grayscale\', type=str2bool, default=False)\ndata_arg.add_argument(\'--num_worker\', type=int, default=12)\n\n# Training / test parameters\ntrain_arg = add_argument_group(\'Training\')\ntrain_arg.add_argument(\'--is_train\', type=str2bool, default=True)\ntrain_arg.add_argument(\'--optimizer\', type=str, default=\'adam\')\ntrain_arg.add_argument(\'--max_step\', type=int, default=500000)\ntrain_arg.add_argument(\'--lr\', type=float, default=0.0002)\ntrain_arg.add_argument(\'--beta1\', type=float, default=0.5)\ntrain_arg.add_argument(\'--beta2\', type=float, default=0.999)\ntrain_arg.add_argument(\'--loss\', type=str, default=""log_prob"",\n                       choices=[""log_prob""], help=""least square loss doesn\'t work well"")\ntrain_arg.add_argument(\'--weight_decay\', type=float, default=0.0001)\n\n# Misc\nmisc_arg = add_argument_group(\'Misc\')\nmisc_arg.add_argument(\'--load_path\', type=str, default=\'\')\nmisc_arg.add_argument(\'--log_step\', type=int, default=50)\nmisc_arg.add_argument(\'--save_step\', type=int, default=500)\nmisc_arg.add_argument(\'--num_log_samples\', type=int, default=3)\nmisc_arg.add_argument(\'--log_level\', type=str, default=\'INFO\', choices=[\'INFO\', \'DEBUG\', \'WARN\'])\nmisc_arg.add_argument(\'--log_dir\', type=str, default=\'logs\')\nmisc_arg.add_argument(\'--data_dir\', type=str, default=\'data\')\nmisc_arg.add_argument(\'--num_gpu\', type=int, default=1)\nmisc_arg.add_argument(\'--test_data_path\', type=str, default=None,\n                      help=\'directory with images which will be used in test sample generation\')\nmisc_arg.add_argument(\'--sample_per_image\', type=int, default=64,\n                      help=\'# of sample per image during test sample generation\')\nmisc_arg.add_argument(\'--random_seed\', type=int, default=123)\nmisc_arg.add_argument(\'--skip_pix2pix_processing\', type=str2bool, default=False,\n                      help=\'just for fast debugging in poor cpu machine\')\n\ndef get_config():\n    config, unparsed = parser.parse_known_args()\n    return config, unparsed\n'"
data_loader.py,3,"b'import os\nimport numpy as np\nfrom glob import glob\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nfrom torchvision import transforms\n\nPIX2PIX_DATASETS = [\n    \'facades\', \'cityscapes\', \'maps\', \'edges2shoes\', \'edges2handbags\']\n\ndef makedirs(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef pix2pix_split_images(root):\n    paths = glob(os.path.join(root, ""train/*""))\n\n    a_path = os.path.join(root, ""A"")\n    b_path = os.path.join(root, ""B"")\n\n    makedirs(a_path)\n    makedirs(b_path)\n\n    for path in tqdm(paths, desc=""pix2pix processing""):\n        filename = os.path.basename(path)\n\n        a_image_path = os.path.join(a_path, filename)\n        b_image_path = os.path.join(b_path, filename)\n\n        if os.path.exists(a_image_path) and os.path.exists(b_image_path):\n            continue\n\n        image = Image.open(os.path.join(path)).convert(\'RGB\')\n        data = np.array(image)\n\n        height, width, channel = data.shape\n\n        a_image = Image.fromarray(data[:,:width/2].astype(np.uint8))\n        b_image = Image.fromarray(data[:,width/2:].astype(np.uint8))\n\n        a_image.save(a_image_path)\n        b_image.save(b_image_path)\n\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, root, scale_size, data_type, skip_pix2pix_processing=False):\n        self.root = root\n        if not os.path.exists(self.root):\n            raise Exception(""[!] {} not exists."".format(root))\n\n        self.name = os.path.basename(root)\n        if self.name in PIX2PIX_DATASETS and not skip_pix2pix_processing:\n            pix2pix_split_images(self.root)\n\n        self.paths = glob(os.path.join(self.root, \'{}/*\'.format(data_type)))\n        if len(self.paths) == 0:\n            raise Exception(""No images are found in {}"".format(self.root))\n        self.shape = list(Image.open(self.paths[0]).size) + [3]\n\n        self.transform = transforms.Compose([\n            transforms.Scale(scale_size), \n            transforms.ToTensor(), \n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        ])\n\n    def __getitem__(self, index):\n        image = Image.open(self.paths[index]).convert(\'RGB\')\n        return self.transform(image)\n\n    def __len__(self):\n        return len(self.paths)\n\ndef get_loader(root, batch_size, scale_size, num_workers=2,\n               skip_pix2pix_processing=False, shuffle=True):\n    a_data_set, b_data_set = \\\n        Dataset(root, scale_size, ""A"", skip_pix2pix_processing), \\\n        Dataset(root, scale_size, ""B"", skip_pix2pix_processing)\n    a_data_loader = torch.utils.data.DataLoader(dataset=a_data_set,\n                                                batch_size=batch_size,\n                                                shuffle=True,\n                                                num_workers=num_workers)\n    b_data_loader = torch.utils.data.DataLoader(dataset=b_data_set,\n                                                batch_size=batch_size,\n                                                shuffle=True,\n                                                num_workers=num_workers)\n    a_data_loader.shape = a_data_set.shape\n    b_data_loader.shape = b_data_set.shape\n\n    return a_data_loader, b_data_loader\n'"
main.py,2,"b'import torch\n\nfrom trainer import Trainer\nfrom config import get_config\nfrom data_loader import get_loader\nfrom utils import prepare_dirs_and_logger, save_config\n\ndef main(config):\n    prepare_dirs_and_logger(config)\n\n    torch.manual_seed(config.random_seed)\n    if config.num_gpu > 0:\n        torch.cuda.manual_seed(config.random_seed)\n\n    if config.is_train:\n        data_path = config.data_path\n        batch_size = config.batch_size\n    else:\n        if config.test_data_path is None:\n            data_path = config.data_path\n        else:\n            data_path = config.test_data_path\n        batch_size = config.sample_per_image\n\n    a_data_loader, b_data_loader = get_loader(\n            data_path, batch_size, config.input_scale_size,\n            config.num_worker, config.skip_pix2pix_processing)\n\n    trainer = Trainer(config, a_data_loader, b_data_loader)\n\n    if config.is_train:\n        save_config(config)\n        trainer.train()\n    else:\n        if not config.load_path:\n            raise Exception(""[!] You should specify `load_path` to load a pretrained model"")\n        trainer.test()\n\nif __name__ == ""__main__"":\n    config, unparsed = get_config()\n    main(config)\n'"
models.py,3,"b'import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import TensorDataset, DataLoader\n\nclass GeneratorCNN(nn.Module):\n    def __init__(self, input_channel, output_channel, conv_dims, deconv_dims, num_gpu):\n        super(GeneratorCNN, self).__init__()\n        self.num_gpu = num_gpu\n        self.layers = []\n\n        prev_dim = conv_dims[0]\n        self.layers.append(nn.Conv2d(input_channel, prev_dim, 4, 2, 1, bias=False))\n        self.layers.append(nn.LeakyReLU(0.2, inplace=True))\n\n        for out_dim in conv_dims[1:]:\n            self.layers.append(nn.Conv2d(prev_dim, out_dim, 4, 2, 1, bias=False))\n            self.layers.append(nn.BatchNorm2d(out_dim))\n            self.layers.append(nn.LeakyReLU(0.2, inplace=True))\n            prev_dim = out_dim\n\n        for out_dim in deconv_dims:\n            self.layers.append(nn.ConvTranspose2d(prev_dim, out_dim, 4, 2, 1, bias=False))\n            self.layers.append(nn.BatchNorm2d(out_dim))\n            self.layers.append(nn.ReLU(True))\n            prev_dim = out_dim\n\n        self.layers.append(nn.ConvTranspose2d(prev_dim, output_channel, 4, 2, 1, bias=False))\n        self.layers.append(nn.Tanh())\n\n        self.layer_module = nn.ModuleList(self.layers)\n\n    def main(self, x):\n        out = x\n        for layer in self.layer_module:\n            out = layer(out)\n        return out\n\n    def forward(self, x):\n        return self.main(x)\n\nclass DiscriminatorCNN(nn.Module):\n    def __init__(self, input_channel, output_channel, hidden_dims, num_gpu):\n        super(DiscriminatorCNN, self).__init__()\n        self.num_gpu = num_gpu\n        self.layers = []\n\n        prev_dim = hidden_dims[0]\n        self.layers.append(nn.Conv2d(input_channel, prev_dim, 4, 2, 1, bias=False))\n        self.layers.append(nn.LeakyReLU(0.2, inplace=True))\n\n        for out_dim in hidden_dims[1:]:\n            self.layers.append(nn.Conv2d(prev_dim, out_dim, 4, 2, 1, bias=False))\n            self.layers.append(nn.BatchNorm2d(out_dim))\n            self.layers.append(nn.LeakyReLU(0.2, inplace=True))\n            prev_dim = out_dim\n\n        self.layers.append(nn.Conv2d(prev_dim, output_channel, 4, 1, 0, bias=False))\n        self.layers.append(nn.Sigmoid())\n\n        self.layer_module = nn.ModuleList(self.layers)\n\n    def main(self, x):\n        out = x\n        for layer in self.layer_module:\n            out = layer(out)\n        return out.view(out.size(0), -1)\n\n    def forward(self, x):\n        return self.main(x)\n\nclass GeneratorFC(nn.Module):\n    def __init__(self, input_size, output_size, hidden_dims):\n        super(GeneratorFC, self).__init__()\n        self.layers = []\n\n        prev_dim = input_size\n        for hidden_dim in hidden_dims:\n            self.layers.append(nn.Linear(prev_dim, hidden_dim))\n            self.layers.append(nn.ReLU(True))\n            prev_dim = hidden_dim\n        self.layers.append(nn.Linear(prev_dim, output_size))\n\n        self.layer_module = nn.ModuleList(self.layers)\n\n    def forward(self, x):\n        out = x\n        for layer in self.layer_module:\n            out = layer(out)\n        return out\n\nclass DiscriminatorFC(nn.Module):\n    def __init__(self, input_size, output_size, hidden_dims):\n        super(DiscriminatorFC, self).__init__()\n        self.layers = []\n\n        prev_dim = input_size\n        for idx, hidden_dim in enumerate(hidden_dims):\n            self.layers.append(nn.Linear(prev_dim, hidden_dim))\n            self.layers.append(nn.ReLU(True))\n            prev_dim = hidden_dim\n\n        self.layers.append(nn.Linear(prev_dim, output_size))\n        self.layers.append(nn.Sigmoid())\n\n        self.layer_module = nn.ModuleList(self.layers)\n\n    def forward(self, x):\n        out = x\n        for layer in self.layer_module:\n            out = layer(out)\n        return out.view(-1, 1)\n'"
trainer.py,17,"b'from __future__ import print_function\n\nimport os\nfrom glob import glob\nfrom tqdm import trange\nfrom itertools import chain\n\nimport torch\nfrom torch import nn\nimport torch.nn.parallel\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\n\nfrom models import *\nfrom data_loader import get_loader\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Conv\') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find(\'BatchNorm\') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\nclass Trainer(object):\n    def __init__(self, config, a_data_loader, b_data_loader):\n        self.config = config\n\n        self.a_data_loader = a_data_loader\n        self.b_data_loader = b_data_loader\n\n        self.num_gpu = config.num_gpu\n        self.dataset = config.dataset\n\n        self.loss = config.loss\n        self.lr = config.lr\n        self.beta1 = config.beta1\n        self.beta2 = config.beta2\n        self.optimizer = config.optimizer\n        self.batch_size = config.batch_size\n        self.weight_decay = config.weight_decay\n        self.cnn_type = config.cnn_type\n\n        self.model_dir = config.model_dir\n        self.load_path = config.load_path\n\n        self.start_step = 0\n        self.log_step = config.log_step\n        self.max_step = config.max_step\n        self.save_step = config.save_step\n\n        self.build_model()\n\n        if self.num_gpu == 1:\n            self.G_AB.cuda()\n            self.G_BA.cuda()\n            self.D_A.cuda()\n            self.D_B.cuda()\n\n        elif self.num_gpu > 1:\n            self.G_AB = nn.DataParallel(self.G_AB.cuda(),device_ids=range(self.num_gpu))\n            self.G_BA = nn.DataParallel(self.G_BA.cuda(),device_ids=range(self.num_gpu))\n            self.D_A = nn.DataParallel(self.D_A.cuda(),device_ids=range(self.num_gpu))\n            self.D_B = nn.DataParallel(self.D_B.cuda(),device_ids=range(self.num_gpu))\n\n        if self.load_path:\n            self.load_model()\n\n    def build_model(self):\n        if self.dataset == \'toy\':\n            self.G_AB = GeneratorFC(2, 2, [config.fc_hidden_dim] * config.g_num_layer)\n            self.G_BA = GeneratorFC(2, 2, [config.fc_hidden_dim] * config.g_num_layer)\n\n            self.D_A = DiscriminatorFC(2, 1, [config.fc_hidden_dim] * config.d_num_layer)\n            self.D_B = DiscriminatorFC(2, 1, [config.fc_hidden_dim] * config.d_num_layer)\n        else:\n            a_height, a_width, a_channel = self.a_data_loader.shape\n            b_height, b_width, b_channel = self.b_data_loader.shape\n\n            if self.cnn_type == 0:\n                #conv_dims, deconv_dims = [64, 128, 256, 512], [512, 256, 128, 64]\n                conv_dims, deconv_dims = [64, 128, 256, 512], [256, 128, 64]\n            elif self.cnn_type == 1:\n                #conv_dims, deconv_dims = [32, 64, 128, 256], [256, 128, 64, 32]\n                conv_dims, deconv_dims = [32, 64, 128, 256], [128, 64, 32]\n            else:\n                raise Exception(""[!] cnn_type {} is not defined"".format(self.cnn_type))\n\n            self.G_AB = GeneratorCNN(\n                    a_channel, b_channel, conv_dims, deconv_dims, self.num_gpu)\n            self.G_BA = GeneratorCNN(\n                    b_channel, a_channel, conv_dims, deconv_dims, self.num_gpu)\n\n            self.D_A = DiscriminatorCNN(\n                    a_channel, 1, conv_dims, self.num_gpu)\n            self.D_B = DiscriminatorCNN(\n                    b_channel, 1, conv_dims, self.num_gpu)\n\n            self.G_AB.apply(weights_init)\n            self.G_BA.apply(weights_init)\n\n            self.D_A.apply(weights_init)\n            self.D_B.apply(weights_init)\n\n    def load_model(self):\n        print(""[*] Load models from {}..."".format(self.load_path))\n\n        paths = glob(os.path.join(self.load_path, \'G_AB_*.pth\'))\n        paths.sort()\n\n        if len(paths) == 0:\n            print(""[!] No checkpoint found in {}..."".format(self.load_path))\n            return\n\n        idxes = [int(os.path.basename(path.split(\'.\')[0].split(\'_\')[-1])) for path in paths]\n        self.start_step = max(idxes)\n\n        if self.num_gpu == 0:\n            map_location = lambda storage, loc: storage\n        else:\n            map_location = None\n\n        G_AB_filename = \'{}/G_AB_{}.pth\'.format(self.load_path, self.start_step)\n        self.G_AB.load_state_dict(torch.load(G_AB_filename, map_location=map_location))\n        self.G_BA.load_state_dict(\n            torch.load(\'{}/G_BA_{}.pth\'.format(self.load_path, self.start_step), map_location=map_location))\n\n        self.D_A.load_state_dict(\n            torch.load(\'{}/D_A_{}.pth\'.format(self.load_path, self.start_step), map_location=map_location))\n        self.D_B.load_state_dict(\n            torch.load(\'{}/D_B_{}.pth\'.format(self.load_path, self.start_step), map_location=map_location))\n\n        print(""[*] Model loaded: {}"".format(G_AB_filename))\n\n    def train(self):\n        d = nn.MSELoss()\n        bce = nn.BCELoss()\n\n        real_label = 1\n        fake_label = 0\n\n        real_tensor = Variable(torch.FloatTensor(self.batch_size))\n        _ = real_tensor.data.fill_(real_label)\n\n        fake_tensor = Variable(torch.FloatTensor(self.batch_size))\n        _ = fake_tensor.data.fill_(fake_label)\n\n        if self.num_gpu > 0:\n            d.cuda()\n            bce.cuda()\n\n            real_tensor = real_tensor.cuda()\n            fake_tensor = fake_tensor.cuda()\n\n        if self.optimizer == \'adam\':\n            optimizer = torch.optim.Adam\n        else:\n            raise Exception(""[!] Caution! Paper didn\'t use {} opimizer other than Adam"".format(config.optimizer))\n\n        optimizer_d = optimizer(\n            chain(self.D_A.parameters(), self.D_B.parameters()),\n            lr=self.lr, betas=(self.beta1, self.beta2), weight_decay=self.weight_decay)\n        optimizer_g = optimizer(\n            chain(self.G_AB.parameters(), self.G_BA.parameters()),\n            lr=self.lr, betas=(self.beta1, self.beta2))\n\n        A_loader, B_loader = iter(self.a_data_loader), iter(self.b_data_loader)\n        valid_x_A, valid_x_B = self._get_variable(A_loader.next()), self._get_variable(B_loader.next())\n\n        vutils.save_image(valid_x_A.data, \'{}/valid_x_A.png\'.format(self.model_dir))\n        vutils.save_image(valid_x_B.data, \'{}/valid_x_B.png\'.format(self.model_dir))\n\n        for step in trange(self.start_step, self.max_step):\n            try:\n                x_A, x_B = A_loader.next(), B_loader.next()\n            except StopIteration:\n                A_loader, B_loader = iter(self.a_data_loader), iter(self.b_data_loader)\n                x_A, x_B = A_loader.next(), B_loader.next()\n            if x_A.size(0) != x_B.size(0):\n                print(""[!] Sampled dataset from A and B have different # of data. Try resampling..."")\n                continue\n\n            x_A, x_B = self._get_variable(x_A), self._get_variable(x_B)\n\n            batch_size = x_A.size(0)\n            real_tensor.data.resize_(batch_size).fill_(real_label)\n            fake_tensor.data.resize_(batch_size).fill_(fake_label)\n\n            # update D network\n            self.D_A.zero_grad()\n            self.D_B.zero_grad()\n\n            x_AB = self.G_AB(x_A).detach()\n            x_BA = self.G_BA(x_B).detach()\n\n            x_ABA = self.G_BA(x_AB).detach()\n            x_BAB = self.G_AB(x_BA).detach()\n\n            if self.loss == ""log_prob"":\n                l_d_A_real, l_d_A_fake = bce(self.D_A(x_A), real_tensor), bce(self.D_A(x_BA), fake_tensor)\n                l_d_B_real, l_d_B_fake = bce(self.D_B(x_B), real_tensor), bce(self.D_B(x_AB), fake_tensor)\n            elif self.loss == ""least_square"":\n                l_d_A_real, l_d_A_fake = \\\n                    0.5 * torch.mean((self.D_A(x_A) - 1)**2), 0.5 * torch.mean((self.D_A(x_BA))**2)\n                l_d_B_real, l_d_B_fake = \\\n                    0.5 * torch.mean((self.D_B(x_B) - 1)**2), 0.5 * torch.mean((self.D_B(x_AB))**2)\n            else:\n                raise Exception(""[!] Unkown loss type: {}"".format(self.loss))\n\n            l_d_A = l_d_A_real + l_d_A_fake\n            l_d_B = l_d_B_real + l_d_B_fake\n\n            l_d = l_d_A + l_d_B\n\n            l_d.backward()\n            optimizer_d.step()\n\n            # update G network\n            self.G_AB.zero_grad()\n            self.G_BA.zero_grad()\n\n            x_AB = self.G_AB(x_A)\n            x_BA = self.G_BA(x_B)\n\n            x_ABA = self.G_BA(x_AB)\n            x_BAB = self.G_AB(x_BA)\n\n            l_const_A = d(x_ABA, x_A)\n            l_const_B = d(x_BAB, x_B)\n\n            if self.loss == ""log_prob"":\n                l_gan_A = bce(self.D_A(x_BA), real_tensor)\n                l_gan_B = bce(self.D_B(x_AB), real_tensor)\n            elif self.loss == ""least_square"":\n                l_gan_A = 0.5 * torch.mean((self.D_A(x_BA) - 1)**2)\n                l_gan_B = 0.5 * torch.mean((self.D_B(x_AB) - 1)**2)\n            else:\n                raise Exception(""[!] Unkown loss type: {}"".format(self.loss))\n\n            l_g = l_gan_A + l_gan_B + l_const_A + l_const_B\n\n            l_g.backward()\n            optimizer_g.step()\n\n            if step % self.log_step == 0:\n                print(""[{}/{}] Loss_D: {:.4f} Loss_G: {:.4f}"". \\\n                      format(step, self.max_step, l_d.data[0], l_g.data[0]))\n\n                print(""[{}/{}] l_d_A_real: {:.4f} l_d_A_fake: {:.4f}, l_d_B_real: {:.4f}, l_d_B_fake: {:.4f}"". \\\n                      format(step, self.max_step, l_d_A_real.data[0], l_d_A_fake.data[0],\n                             l_d_B_real.data[0], l_d_B_fake.data[0]))\n\n                print(""[{}/{}] l_const_A: {:.4f} l_const_B: {:.4f}, l_gan_A: {:.4f}, l_gan_B: {:.4f}"". \\\n                      format(step, self.max_step, l_const_A.data[0], l_const_B.data[0],\n                             l_gan_A.data[0], l_gan_B.data[0]))\n\n                self.generate_with_A(valid_x_A, self.model_dir, idx=step)\n                self.generate_with_B(valid_x_B, self.model_dir, idx=step)\n\n            if step % self.save_step == self.save_step - 1:\n                print(""[*] Save models to {}..."".format(self.model_dir))\n\n                torch.save(self.G_AB.state_dict(), \'{}/G_AB_{}.pth\'.format(self.model_dir, step))\n                torch.save(self.G_BA.state_dict(), \'{}/G_BA_{}.pth\'.format(self.model_dir, step))\n\n                torch.save(self.D_A.state_dict(), \'{}/D_A_{}.pth\'.format(self.model_dir, step))\n                torch.save(self.D_B.state_dict(), \'{}/D_B_{}.pth\'.format(self.model_dir, step))\n\n    def generate_with_A(self, inputs, path, idx=None):\n        x_AB = self.G_AB(inputs)\n        x_ABA = self.G_BA(x_AB)\n\n        x_AB_path = \'{}/{}_x_AB.png\'.format(path, idx)\n        x_ABA_path = \'{}/{}_x_ABA.png\'.format(path, idx)\n\n        vutils.save_image(x_AB.data, x_AB_path)\n        print(""[*] Samples saved: {}"".format(x_AB_path))\n\n        vutils.save_image(x_ABA.data, x_ABA_path)\n        print(""[*] Samples saved: {}"".format(x_ABA_path))\n\n    def generate_with_B(self, inputs, path, idx=None):\n        x_BA = self.G_BA(inputs)\n        x_BAB = self.G_AB(x_BA)\n\n        x_BA_path = \'{}/{}_x_BA.png\'.format(path, idx)\n        x_BAB_path = \'{}/{}_x_BAB.png\'.format(path, idx)\n\n        vutils.save_image(x_BA.data, x_BA_path)\n        print(""[*] Samples saved: {}"".format(x_BA_path))\n\n        vutils.save_image(x_BAB.data, x_BAB_path)\n        print(""[*] Samples saved: {}"".format(x_BAB_path))\n\n    def generate_infinitely(self, inputs, path, input_type, count=10, nrow=2, idx=None):\n        if input_type.lower() == ""a"":\n            iterator = [self.G_AB, self.G_BA] * count\n        elif input_type.lower() == ""b"":\n            iterator = [self.G_BA, self.G_AB] * count\n\n        out = inputs\n        for step, model in enumerate(iterator):\n            out = model(out)\n\n            out_path = \'{}/{}_x_{}_#{}.png\'.format(path, idx, input_type, step)\n            vutils.save_image(out.data, out_path, nrow=nrow)\n            print(""[*] Samples saved: {}"".format(out_path))\n\n    def test(self):\n        batch_size = self.config.sample_per_image\n        A_loader, B_loader = iter(self.a_data_loader), iter(self.b_data_loader)\n\n        test_dir = os.path.join(self.model_dir, \'test\')\n        if not os.path.exists(test_dir):\n            os.makedirs(test_dir)\n\n        step = 0\n        while True:\n            try:\n                x_A, x_B = self._get_variable(A_loader.next()), self._get_variable(B_loader.next())\n            except StopIteration:\n                print(""[!] Test sample generation finished. Samples are in {}"".format(test_dir))\n                break\n\n            vutils.save_image(x_A.data, \'{}/{}_x_A.png\'.format(test_dir, step))\n            vutils.save_image(x_B.data, \'{}/{}_x_B.png\'.format(test_dir, step))\n\n            self.generate_with_A(x_A, test_dir, idx=step)\n            self.generate_with_B(x_B, test_dir, idx=step)\n\n            self.generate_infinitely(x_A, test_dir, input_type=""A"", count=10, nrow=4, idx=step)\n            self.generate_infinitely(x_B, test_dir, input_type=""B"", count=10, nrow=4, idx=step)\n\n            step += 1\n\n    def _get_variable(self, inputs):\n        if self.num_gpu > 0:\n            out = Variable(inputs.cuda())\n        else:\n            out = Variable(inputs)\n        return out\n'"
utils.py,0,"b'from __future__ import print_function\n\nimport os\nimport json\nimport logging\nimport numpy as np\nfrom datetime import datetime\n\ndef prepare_dirs_and_logger(config):\n    formatter = logging.Formatter(""%(asctime)s:%(levelname)s::%(message)s"")\n    logger = logging.getLogger()\n\n    for hdlr in logger.handlers:\n        logger.removeHandler(hdlr)\n\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n\n    logger.addHandler(handler)\n\n    if config.load_path:\n        if config.load_path.startswith(config.log_dir):\n            config.model_dir = config.load_path\n        else:\n            if config.load_path.startswith(config.dataset):\n                config.model_name = config.load_path\n            else:\n                config.model_name = ""{}_{}"".format(config.dataset, config.load_path)\n    else:\n        config.model_name = ""{}_{}"".format(config.dataset, get_time())\n\n    if not hasattr(config, \'model_dir\'):\n        config.model_dir = os.path.join(config.log_dir, config.model_name)\n    config.data_path = os.path.join(config.data_dir, config.dataset)\n\n    for path in [config.log_dir, config.data_dir, config.model_dir]:\n        if not os.path.exists(path):\n            os.makedirs(path)\n\ndef get_time():\n    return datetime.now().strftime(""%Y-%m-%d_%H-%M-%S"")\n\ndef save_config(config):\n    param_path = os.path.join(config.model_dir, ""params.json"")\n\n    print(""[*] MODEL dir: %s"" % config.model_dir)\n    print(""[*] PARAM path: %s"" % param_path)\n\n    with open(param_path, \'w\') as fp:\n        json.dump(config.__dict__, fp, indent=4, sort_keys=True)\n'"
