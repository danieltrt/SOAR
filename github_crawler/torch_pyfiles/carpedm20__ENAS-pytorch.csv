file_path,api_count,code
config.py,0,"b'import argparse\nfrom utils import get_logger\n\nlogger = get_logger()\n\n\narg_lists = []\nparser = argparse.ArgumentParser()\n\ndef str2bool(v):\n    return v.lower() in (\'true\')\n\ndef add_argument_group(name):\n    arg = parser.add_argument_group(name)\n    arg_lists.append(arg)\n    return arg\n\n# Network\nnet_arg = add_argument_group(\'Network\')\nnet_arg.add_argument(\'--network_type\', type=str, choices=[\'rnn\', \'cnn\'], default=\'rnn\')\n\n# Controller\nnet_arg.add_argument(\'--num_blocks\', type=int, default=12)\nnet_arg.add_argument(\'--tie_weights\', type=str2bool, default=True)\nnet_arg.add_argument(\'--controller_hid\', type=int, default=100)\n\n# Shared parameters for PTB\n# NOTE(brendan): See Merity config for wdrop\n# https://github.com/salesforce/awd-lstm-lm.\nnet_arg.add_argument(\'--shared_wdrop\', type=float, default=0.5)\nnet_arg.add_argument(\'--shared_dropout\', type=float, default=0.4) # TODO\nnet_arg.add_argument(\'--shared_dropoute\', type=float, default=0.1) # TODO\nnet_arg.add_argument(\'--shared_dropouti\', type=float, default=0.65) # TODO\nnet_arg.add_argument(\'--shared_embed\', type=int, default=1000) # TODO: 200, 500, 1000\nnet_arg.add_argument(\'--shared_hid\', type=int, default=1000)\nnet_arg.add_argument(\'--shared_rnn_max_length\', type=int, default=35)\nnet_arg.add_argument(\'--shared_rnn_activations\', type=eval,\n                     default=""[\'tanh\', \'ReLU\', \'identity\', \'sigmoid\']"")\nnet_arg.add_argument(\'--shared_cnn_types\', type=eval,\n                     default=""[\'3x3\', \'5x5\', \'sep 3x3\', \'sep 5x5\', \'max 3x3\', \'max 5x5\']"")\n\n# PTB regularizations\nnet_arg.add_argument(\'--activation_regularization\',\n                     type=str2bool,\n                     default=False)\nnet_arg.add_argument(\'--activation_regularization_amount\',\n                     type=float,\n                     default=2.0)\nnet_arg.add_argument(\'--temporal_activation_regularization\',\n                     type=str2bool,\n                     default=False)\nnet_arg.add_argument(\'--temporal_activation_regularization_amount\',\n                     type=float,\n                     default=1.0)\nnet_arg.add_argument(\'--norm_stabilizer_regularization\',\n                     type=str2bool,\n                     default=False)\nnet_arg.add_argument(\'--norm_stabilizer_regularization_amount\',\n                     type=float,\n                     default=1.0)\nnet_arg.add_argument(\'--norm_stabilizer_fixed_point\', type=float, default=5.0)\n\n# Shared parameters for CIFAR\nnet_arg.add_argument(\'--cnn_hid\', type=int, default=64)\n\n\n# Data\ndata_arg = add_argument_group(\'Data\')\ndata_arg.add_argument(\'--dataset\', type=str, default=\'ptb\')\n\n\n# Training / test parameters\nlearn_arg = add_argument_group(\'Learning\')\nlearn_arg.add_argument(\'--mode\', type=str, default=\'train\',\n                       choices=[\'train\', \'derive\', \'test\', \'single\'],\n                       help=\'train: Training ENAS, derive: Deriving Architectures,\\\n                       single: training one dag\')\nlearn_arg.add_argument(\'--batch_size\', type=int, default=64)\nlearn_arg.add_argument(\'--test_batch_size\', type=int, default=1)\nlearn_arg.add_argument(\'--max_epoch\', type=int, default=150)\nlearn_arg.add_argument(\'--entropy_mode\', type=str, default=\'reward\', choices=[\'reward\', \'regularizer\'])\n\n\n# Controller\nlearn_arg.add_argument(\'--ppl_square\', type=str2bool, default=False)\n# NOTE(brendan): (Zoph and Le, 2017) page 8 states that c is a constant,\n# usually set at 80.\nlearn_arg.add_argument(\'--reward_c\', type=int, default=80,\n                       help=""WE DON\'T KNOW WHAT THIS VALUE SHOULD BE"") # TODO\n# NOTE(brendan): irrelevant for actor critic.\nlearn_arg.add_argument(\'--ema_baseline_decay\', type=float, default=0.95) # TODO: very important\nlearn_arg.add_argument(\'--discount\', type=float, default=1.0) # TODO\nlearn_arg.add_argument(\'--controller_max_step\', type=int, default=2000,\n                       help=\'step for controller parameters\')\nlearn_arg.add_argument(\'--controller_optim\', type=str, default=\'adam\')\nlearn_arg.add_argument(\'--controller_lr\', type=float, default=3.5e-4,\n                       help=""will be ignored if --controller_lr_cosine=True"")\nlearn_arg.add_argument(\'--controller_lr_cosine\', type=str2bool, default=False)\nlearn_arg.add_argument(\'--controller_lr_max\', type=float, default=0.05,\n                       help=""lr max for cosine schedule"")\nlearn_arg.add_argument(\'--controller_lr_min\', type=float, default=0.001,\n                       help=""lr min for cosine schedule"")\nlearn_arg.add_argument(\'--controller_grad_clip\', type=float, default=0)\nlearn_arg.add_argument(\'--tanh_c\', type=float, default=2.5)\nlearn_arg.add_argument(\'--softmax_temperature\', type=float, default=5.0)\nlearn_arg.add_argument(\'--entropy_coeff\', type=float, default=1e-4)\n\n# Shared parameters\nlearn_arg.add_argument(\'--shared_initial_step\', type=int, default=0)\nlearn_arg.add_argument(\'--shared_max_step\', type=int, default=400,\n                       help=\'step for shared parameters\')\n# NOTE(brendan): Should be 10 for CNN architectures.\nlearn_arg.add_argument(\'--shared_num_sample\', type=int, default=1,\n                       help=\'# of Monte Carlo samples\')\nlearn_arg.add_argument(\'--shared_optim\', type=str, default=\'sgd\')\nlearn_arg.add_argument(\'--shared_lr\', type=float, default=20.0)\nlearn_arg.add_argument(\'--shared_decay\', type=float, default=0.96)\nlearn_arg.add_argument(\'--shared_decay_after\', type=float, default=15)\nlearn_arg.add_argument(\'--shared_l2_reg\', type=float, default=1e-7)\nlearn_arg.add_argument(\'--shared_grad_clip\', type=float, default=0.25)\n\n# Deriving Architectures\nlearn_arg.add_argument(\'--derive_num_sample\', type=int, default=100)\n\n\n# Misc\nmisc_arg = add_argument_group(\'Misc\')\nmisc_arg.add_argument(\'--load_path\', type=str, default=\'\')\nmisc_arg.add_argument(\'--log_step\', type=int, default=50)\nmisc_arg.add_argument(\'--save_epoch\', type=int, default=4)\nmisc_arg.add_argument(\'--max_save_num\', type=int, default=4)\nmisc_arg.add_argument(\'--log_level\', type=str, default=\'INFO\', choices=[\'INFO\', \'DEBUG\', \'WARN\'])\nmisc_arg.add_argument(\'--log_dir\', type=str, default=\'logs\')\nmisc_arg.add_argument(\'--data_dir\', type=str, default=\'data\')\nmisc_arg.add_argument(\'--num_gpu\', type=int, default=1)\nmisc_arg.add_argument(\'--random_seed\', type=int, default=12345)\nmisc_arg.add_argument(\'--use_tensorboard\', type=str2bool, default=True)\nmisc_arg.add_argument(\'--dag_path\', type=str, default=\'\')\n\ndef get_args():\n    """"""Parses all of the arguments above, which mostly correspond to the\n    hyperparameters mentioned in the paper.\n    """"""\n    args, unparsed = parser.parse_known_args()\n    if args.num_gpu > 0:\n        setattr(args, \'cuda\', True)\n    else:\n        setattr(args, \'cuda\', False)\n    if len(unparsed) > 1:\n        logger.info(f""Unparsed args: {unparsed}"")\n    return args, unparsed\n'"
generate_gif.py,0,"b'#!/usr/bin/env python\n\nimport argparse\nfrom glob import glob\n\nfrom utils import make_gif\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--model_name"", type=str)\nparser.add_argument(""--max_frame"", type=int, default=50)\nparser.add_argument(""--output"", type=str, default=""sampe.gif"")\nparser.add_argument(""--title"", type=str, default="""")\n\nif __name__ == ""__main__"":\n    args = parser.parse_args()\n\n    paths = glob(f""./logs/{args.model_name}/networks/*.png"")\n    make_gif(paths, args.output,\n            max_frame=args.max_frame,\n            prefix=f""{args.title}\\n"" if args.title else """")\n'"
main.py,2,"b'""""""Entry point.""""""\nimport os\n\nimport torch\n\nimport data\nimport config\nimport utils\nimport trainer\n\nlogger = utils.get_logger()\n\n\ndef main(args):  # pylint:disable=redefined-outer-name\n    """"""main: Entry point.""""""\n    utils.prepare_dirs(args)\n\n    torch.manual_seed(args.random_seed)\n\n    if args.num_gpu > 0:\n        torch.cuda.manual_seed(args.random_seed)\n\n    if args.network_type == \'rnn\':\n        dataset = data.text.Corpus(args.data_path)\n    elif args.dataset == \'cifar\':\n        dataset = data.image.Image(args.data_path)\n    else:\n        raise NotImplementedError(f""{args.dataset} is not supported"")\n\n    trnr = trainer.Trainer(args, dataset)\n\n    if args.mode == \'train\':\n        utils.save_args(args)\n        trnr.train()\n    elif args.mode == \'derive\':\n        assert args.load_path != """", (""`--load_path` should be given in ""\n                                      ""`derive` mode"")\n        trnr.derive()\n    elif args.mode == \'test\':\n        if not args.load_path:\n            raise Exception(""[!] You should specify `load_path` to load a ""\n                            ""pretrained model"")\n        trnr.test()\n    elif args.mode == \'single\':\n        if not args.dag_path:\n            raise Exception(""[!] You should specify `dag_path` to load a dag"")\n        utils.save_args(args)\n        trnr.train(single=True)\n    else:\n        raise Exception(f""[!] Mode not found: {args.mode}"")\n\nif __name__ == ""__main__"":\n    args, unparsed = config.get_args()\n    main(args)\n'"
tensorboard.py,0,"b'import PIL\nimport scipy.misc\nfrom io import BytesIO\nimport tensorboardX as tb\nfrom tensorboardX.summary import Summary\n\n\nclass TensorBoard(object):\n    def __init__(self, model_dir):\n        self.summary_writer = tb.FileWriter(model_dir)\n\n    def image_summary(self, tag, value, step):\n        for idx, img in enumerate(value):\n            summary = Summary()\n            bio = BytesIO()\n\n            if type(img) == str:\n                img = PIL.Image.open(img)\n            elif type(img) == PIL.Image.Image:\n                pass\n            else:\n                img = scipy.misc.toimage(img)\n\n            img.save(bio, format=""png"")\n            image_summary = Summary.Image(encoded_image_string=bio.getvalue())\n            summary.value.add(tag=f""{tag}/{idx}"", image=image_summary)\n            self.summary_writer.add_summary(summary, global_step=step)\n\n    def scalar_summary(self, tag, value, step):\n        summary= Summary(value=[Summary.Value(tag=tag, simple_value=value)])\n        self.summary_writer.add_summary(summary, global_step=step)\n'"
trainer.py,13,"b'""""""The module for training ENAS.""""""\nimport contextlib\nimport glob\nimport math\nimport os\n\nimport numpy as np\nimport scipy.signal\nfrom tensorboard import TensorBoard\nimport torch\nfrom torch import nn\nimport torch.nn.parallel\nfrom torch.autograd import Variable\n\nimport models\nimport utils\n\n\nlogger = utils.get_logger()\n\n\ndef _apply_penalties(extra_out, args):\n    """"""Based on `args`, optionally adds regularization penalty terms for\n    activation regularization, temporal activation regularization and/or hidden\n    state norm stabilization.\n\n    Args:\n        extra_out[*]:\n            dropped: Post-dropout activations.\n            hiddens: All hidden states for a batch of sequences.\n            raw: Pre-dropout activations.\n\n    Returns:\n        The penalty term associated with all of the enabled regularizations.\n\n    See:\n        Regularizing and Optimizing LSTM Language Models (Merity et al., 2017)\n        Regularizing RNNs by Stabilizing Activations (Krueger & Memsevic, 2016)\n    """"""\n    penalty = 0\n\n    # Activation regularization.\n    if args.activation_regularization:\n        penalty += (args.activation_regularization_amount *\n                    extra_out[\'dropped\'].pow(2).mean())\n\n    # Temporal activation regularization (slowness)\n    if args.temporal_activation_regularization:\n        raw = extra_out[\'raw\']\n        penalty += (args.temporal_activation_regularization_amount *\n                    (raw[1:] - raw[:-1]).pow(2).mean())\n\n    # Norm stabilizer regularization\n    if args.norm_stabilizer_regularization:\n        penalty += (args.norm_stabilizer_regularization_amount *\n                    (extra_out[\'hiddens\'].norm(dim=-1) -\n                     args.norm_stabilizer_fixed_point).pow(2).mean())\n\n    return penalty\n\n\ndef discount(x, amount):\n    return scipy.signal.lfilter([1], [1, -amount], x[::-1], axis=0)[::-1]\n\n\ndef _get_optimizer(name):\n    if name.lower() == \'sgd\':\n        optim = torch.optim.SGD\n    elif name.lower() == \'adam\':\n        optim = torch.optim.Adam\n\n    return optim\n\n\ndef _get_no_grad_ctx_mgr():\n    """"""Returns a the `torch.no_grad` context manager for PyTorch version >=\n    0.4, or a no-op context manager otherwise.\n    """"""\n    if float(torch.__version__[0:3]) >= 0.4:\n        return torch.no_grad()\n\n    return contextlib.suppress()\n\n\ndef _check_abs_max_grad(abs_max_grad, model):\n    """"""Checks `model` for a new largest gradient for this epoch, in order to\n    track gradient explosions.\n    """"""\n    finite_grads = [p.grad.data\n                    for p in model.parameters()\n                    if p.grad is not None]\n\n    new_max_grad = max([grad.max() for grad in finite_grads])\n    new_min_grad = min([grad.min() for grad in finite_grads])\n\n    new_abs_max_grad = max(new_max_grad, abs(new_min_grad))\n    if new_abs_max_grad > abs_max_grad:\n        logger.info(f\'abs max grad {abs_max_grad}\')\n        return new_abs_max_grad\n\n    return abs_max_grad\n\n\nclass Trainer(object):\n    """"""A class to wrap training code.""""""\n    def __init__(self, args, dataset):\n        """"""Constructor for training algorithm.\n\n        Args:\n            args: From command line, picked up by `argparse`.\n            dataset: Currently only `data.text.Corpus` is supported.\n\n        Initializes:\n            - Data: train, val and test.\n            - Model: shared and controller.\n            - Inference: optimizers for shared and controller parameters.\n            - Criticism: cross-entropy loss for training the shared model.\n        """"""\n        self.args = args\n        self.controller_step = 0\n        self.cuda = args.cuda\n        self.dataset = dataset\n        self.epoch = 0\n        self.shared_step = 0\n        self.start_epoch = 0\n\n        logger.info(\'regularizing:\')\n        for regularizer in [(\'activation regularization\',\n                             self.args.activation_regularization),\n                            (\'temporal activation regularization\',\n                             self.args.temporal_activation_regularization),\n                            (\'norm stabilizer regularization\',\n                             self.args.norm_stabilizer_regularization)]:\n            if regularizer[1]:\n                logger.info(f\'{regularizer[0]}\')\n\n        self.train_data = utils.batchify(dataset.train,\n                                         args.batch_size,\n                                         self.cuda)\n        # NOTE(brendan): The validation set data is batchified twice\n        # separately: once for computing rewards during the Train Controller\n        # phase (valid_data, batch size == 64), and once for evaluating ppl\n        # over the entire validation set (eval_data, batch size == 1)\n        self.valid_data = utils.batchify(dataset.valid,\n                                         args.batch_size,\n                                         self.cuda)\n        self.eval_data = utils.batchify(dataset.valid,\n                                        args.test_batch_size,\n                                        self.cuda)\n        self.test_data = utils.batchify(dataset.test,\n                                        args.test_batch_size,\n                                        self.cuda)\n\n        self.max_length = self.args.shared_rnn_max_length\n\n        if args.use_tensorboard:\n            self.tb = TensorBoard(args.model_dir)\n        else:\n            self.tb = None\n        self.build_model()\n\n        if self.args.load_path:\n            self.load_model()\n\n        shared_optimizer = _get_optimizer(self.args.shared_optim)\n        controller_optimizer = _get_optimizer(self.args.controller_optim)\n\n        self.shared_optim = shared_optimizer(\n            self.shared.parameters(),\n            lr=self.shared_lr,\n            weight_decay=self.args.shared_l2_reg)\n\n        self.controller_optim = controller_optimizer(\n            self.controller.parameters(),\n            lr=self.args.controller_lr)\n\n        self.ce = nn.CrossEntropyLoss()\n\n    def build_model(self):\n        """"""Creates and initializes the shared and controller models.""""""\n        if self.args.network_type == \'rnn\':\n            self.shared = models.RNN(self.args, self.dataset)\n        elif self.args.network_type == \'cnn\':\n            self.shared = models.CNN(self.args, self.dataset)\n        else:\n            raise NotImplementedError(f\'Network type \'\n                                      f\'`{self.args.network_type}` is not \'\n                                      f\'defined\')\n        self.controller = models.Controller(self.args)\n\n        if self.args.num_gpu == 1:\n            self.shared.cuda()\n            self.controller.cuda()\n        elif self.args.num_gpu > 1:\n            raise NotImplementedError(\'`num_gpu > 1` is in progress\')\n\n    def train(self, single=False):\n        """"""Cycles through alternately training the shared parameters and the\n        controller, as described in Section 2.2, Training ENAS and Deriving\n        Architectures, of the paper.\n\n        From the paper (for Penn Treebank):\n\n        - In the first phase, shared parameters omega are trained for 400\n          steps, each on a minibatch of 64 examples.\n\n        - In the second phase, the controller\'s parameters are trained for 2000\n          steps.\n          \n        Args:\n            single (bool): If True it won\'t train the controller and use the\n                           same dag instead of derive().\n        """"""\n        dag = utils.load_dag(self.args) if single else None\n        \n        if self.args.shared_initial_step > 0:\n            self.train_shared(self.args.shared_initial_step)\n            self.train_controller()\n\n        for self.epoch in range(self.start_epoch, self.args.max_epoch):\n            # 1. Training the shared parameters omega of the child models\n            self.train_shared(dag=dag)\n\n            # 2. Training the controller parameters theta\n            if not single:\n                self.train_controller()\n\n            if self.epoch % self.args.save_epoch == 0:\n                with _get_no_grad_ctx_mgr():\n                    best_dag = dag if dag else self.derive()\n                    self.evaluate(self.eval_data,\n                                  best_dag,\n                                  \'val_best\',\n                                  max_num=self.args.batch_size*100)\n                self.save_model()\n\n            if self.epoch >= self.args.shared_decay_after:\n                utils.update_lr(self.shared_optim, self.shared_lr)\n\n    def get_loss(self, inputs, targets, hidden, dags):\n        """"""Computes the loss for the same batch for M models.\n\n        This amounts to an estimate of the loss, which is turned into an\n        estimate for the gradients of the shared model.\n        """"""\n        if not isinstance(dags, list):\n            dags = [dags]\n\n        loss = 0\n        for dag in dags:\n            output, hidden, extra_out = self.shared(inputs, dag, hidden=hidden)\n            output_flat = output.view(-1, self.dataset.num_tokens)\n            sample_loss = (self.ce(output_flat, targets) /\n                           self.args.shared_num_sample)\n            loss += sample_loss\n\n        assert len(dags) == 1, \'there are multiple `hidden` for multple `dags`\'\n        return loss, hidden, extra_out\n\n    def train_shared(self, max_step=None, dag=None):\n        """"""Train the language model for 400 steps of minibatches of 64\n        examples.\n\n        Args:\n            max_step: Used to run extra training steps as a warm-up.\n            dag: If not None, is used instead of calling sample().\n\n        BPTT is truncated at 35 timesteps.\n\n        For each weight update, gradients are estimated by sampling M models\n        from the fixed controller policy, and averaging their gradients\n        computed on a batch of training data.\n        """"""\n        model = self.shared\n        model.train()\n        self.controller.eval()\n\n        hidden = self.shared.init_hidden(self.args.batch_size)\n\n        if max_step is None:\n            max_step = self.args.shared_max_step\n        else:\n            max_step = min(self.args.shared_max_step, max_step)\n\n        abs_max_grad = 0\n        abs_max_hidden_norm = 0\n        step = 0\n        raw_total_loss = 0\n        total_loss = 0\n        train_idx = 0\n        # TODO(brendan): Why - 1 - 1?\n        while train_idx < self.train_data.size(0) - 1 - 1:\n            if step > max_step:\n                break\n\n            dags = dag if dag else self.controller.sample(\n                self.args.shared_num_sample)\n            inputs, targets = self.get_batch(self.train_data,\n                                             train_idx,\n                                             self.max_length)\n\n            loss, hidden, extra_out = self.get_loss(inputs,\n                                                    targets,\n                                                    hidden,\n                                                    dags)\n            hidden.detach_()\n            raw_total_loss += loss.data\n\n            loss += _apply_penalties(extra_out, self.args)\n\n            # update\n            self.shared_optim.zero_grad()\n            loss.backward()\n\n            h1tohT = extra_out[\'hiddens\']\n            new_abs_max_hidden_norm = utils.to_item(\n                h1tohT.norm(dim=-1).data.max())\n            if new_abs_max_hidden_norm > abs_max_hidden_norm:\n                abs_max_hidden_norm = new_abs_max_hidden_norm\n                logger.info(f\'max hidden {abs_max_hidden_norm}\')\n            abs_max_grad = _check_abs_max_grad(abs_max_grad, model)\n            torch.nn.utils.clip_grad_norm(model.parameters(),\n                                          self.args.shared_grad_clip)\n            self.shared_optim.step()\n\n            total_loss += loss.data\n\n            if ((step % self.args.log_step) == 0) and (step > 0):\n                self._summarize_shared_train(total_loss, raw_total_loss)\n                raw_total_loss = 0\n                total_loss = 0\n\n            step += 1\n            self.shared_step += 1\n            train_idx += self.max_length\n\n    def get_reward(self, dag, entropies, hidden, valid_idx=0):\n        """"""Computes the perplexity of a single sampled model on a minibatch of\n        validation data.\n        """"""\n        if not isinstance(entropies, np.ndarray):\n            entropies = entropies.data.cpu().numpy()\n\n        inputs, targets = self.get_batch(self.valid_data,\n                                         valid_idx,\n                                         self.max_length,\n                                         volatile=True)\n        valid_loss, hidden, _ = self.get_loss(inputs, targets, hidden, dag)\n        valid_loss = utils.to_item(valid_loss.data)\n\n        valid_ppl = math.exp(valid_loss)\n\n        # TODO: we don\'t know reward_c\n        if self.args.ppl_square:\n            # TODO: but we do know reward_c=80 in the previous paper\n            R = self.args.reward_c / valid_ppl ** 2\n        else:\n            R = self.args.reward_c / valid_ppl\n\n        if self.args.entropy_mode == \'reward\':\n            rewards = R + self.args.entropy_coeff * entropies\n        elif self.args.entropy_mode == \'regularizer\':\n            rewards = R * np.ones_like(entropies)\n        else:\n            raise NotImplementedError(f\'Unkown entropy mode: {self.args.entropy_mode}\')\n\n        return rewards, hidden\n\n    def train_controller(self):\n        """"""Fixes the shared parameters and updates the controller parameters.\n\n        The controller is updated with a score function gradient estimator\n        (i.e., REINFORCE), with the reward being c/valid_ppl, where valid_ppl\n        is computed on a minibatch of validation data.\n\n        A moving average baseline is used.\n\n        The controller is trained for 2000 steps per epoch (i.e.,\n        first (Train Shared) phase -> second (Train Controller) phase).\n        """"""\n        model = self.controller\n        model.train()\n        # TODO(brendan): Why can\'t we call shared.eval() here? Leads to loss\n        # being uniformly zero for the controller.\n        # self.shared.eval()\n\n        avg_reward_base = None\n        baseline = None\n        adv_history = []\n        entropy_history = []\n        reward_history = []\n\n        hidden = self.shared.init_hidden(self.args.batch_size)\n        total_loss = 0\n        valid_idx = 0\n        for step in range(self.args.controller_max_step):\n            # sample models\n            dags, log_probs, entropies = self.controller.sample(\n                with_details=True)\n\n            # calculate reward\n            np_entropies = entropies.data.cpu().numpy()\n            # NOTE(brendan): No gradients should be backpropagated to the\n            # shared model during controller training, obviously.\n            with _get_no_grad_ctx_mgr():\n                rewards, hidden = self.get_reward(dags,\n                                                  np_entropies,\n                                                  hidden,\n                                                  valid_idx)\n\n            # discount\n            if 1 > self.args.discount > 0:\n                rewards = discount(rewards, self.args.discount)\n\n            reward_history.extend(rewards)\n            entropy_history.extend(np_entropies)\n\n            # moving average baseline\n            if baseline is None:\n                baseline = rewards\n            else:\n                decay = self.args.ema_baseline_decay\n                baseline = decay * baseline + (1 - decay) * rewards\n\n            adv = rewards - baseline\n            adv_history.extend(adv)\n\n            # policy loss\n            loss = -log_probs*utils.get_variable(adv,\n                                                 self.cuda,\n                                                 requires_grad=False)\n            if self.args.entropy_mode == \'regularizer\':\n                loss -= self.args.entropy_coeff * entropies\n\n            loss = loss.sum()  # or loss.mean()\n\n            # update\n            self.controller_optim.zero_grad()\n            loss.backward()\n\n            if self.args.controller_grad_clip > 0:\n                torch.nn.utils.clip_grad_norm(model.parameters(),\n                                              self.args.controller_grad_clip)\n            self.controller_optim.step()\n\n            total_loss += utils.to_item(loss.data)\n\n            if ((step % self.args.log_step) == 0) and (step > 0):\n                self._summarize_controller_train(total_loss,\n                                                 adv_history,\n                                                 entropy_history,\n                                                 reward_history,\n                                                 avg_reward_base,\n                                                 dags)\n\n                reward_history, adv_history, entropy_history = [], [], []\n                total_loss = 0\n\n            self.controller_step += 1\n\n            prev_valid_idx = valid_idx\n            valid_idx = ((valid_idx + self.max_length) %\n                         (self.valid_data.size(0) - 1))\n            # NOTE(brendan): Whenever we wrap around to the beginning of the\n            # validation data, we reset the hidden states.\n            if prev_valid_idx > valid_idx:\n                hidden = self.shared.init_hidden(self.args.batch_size)\n\n    def evaluate(self, source, dag, name, batch_size=1, max_num=None):\n        """"""Evaluate on the validation set.\n\n        NOTE(brendan): We should not be using the test set to develop the\n        algorithm (basic machine learning good practices).\n        """"""\n        self.shared.eval()\n        self.controller.eval()\n\n        data = source[:max_num*self.max_length]\n\n        total_loss = 0\n        hidden = self.shared.init_hidden(batch_size)\n\n        pbar = range(0, data.size(0) - 1, self.max_length)\n        for count, idx in enumerate(pbar):\n            inputs, targets = self.get_batch(data, idx, volatile=True)\n            output, hidden, _ = self.shared(inputs,\n                                            dag,\n                                            hidden=hidden,\n                                            is_train=False)\n            output_flat = output.view(-1, self.dataset.num_tokens)\n            total_loss += len(inputs) * self.ce(output_flat, targets).data\n            hidden.detach_()\n            ppl = math.exp(utils.to_item(total_loss) / (count + 1) / self.max_length)\n\n        val_loss = utils.to_item(total_loss) / len(data)\n        ppl = math.exp(val_loss)\n\n        self.tb.scalar_summary(f\'eval/{name}_loss\', val_loss, self.epoch)\n        self.tb.scalar_summary(f\'eval/{name}_ppl\', ppl, self.epoch)\n        logger.info(f\'eval | loss: {val_loss:8.2f} | ppl: {ppl:8.2f}\')\n\n    def derive(self, sample_num=None, valid_idx=0):\n        """"""TODO(brendan): We are always deriving based on the very first batch\n        of validation data? This seems wrong...\n        """"""\n        hidden = self.shared.init_hidden(self.args.batch_size)\n\n        if sample_num is None:\n            sample_num = self.args.derive_num_sample\n\n        dags, _, entropies = self.controller.sample(sample_num,\n                                                    with_details=True)\n\n        max_R = 0\n        best_dag = None\n        for dag in dags:\n            R, _ = self.get_reward(dag, entropies, hidden, valid_idx)\n            if R.max() > max_R:\n                max_R = R.max()\n                best_dag = dag\n\n        logger.info(f\'derive | max_R: {max_R:8.6f}\')\n        fname = (f\'{self.epoch:03d}-{self.controller_step:06d}-\'\n                 f\'{max_R:6.4f}-best.png\')\n        path = os.path.join(self.args.model_dir, \'networks\', fname)\n        utils.draw_network(best_dag, path)\n        self.tb.image_summary(\'derive/best\', [path], self.epoch)\n\n        return best_dag\n\n    @property\n    def shared_lr(self):\n        degree = max(self.epoch - self.args.shared_decay_after + 1, 0)\n        return self.args.shared_lr * (self.args.shared_decay ** degree)\n\n    @property\n    def controller_lr(self):\n        return self.args.controller_lr\n\n    def get_batch(self, source, idx, length=None, volatile=False):\n        # code from\n        # https://github.com/pytorch/examples/blob/master/word_language_model/main.py\n        length = min(length if length else self.max_length,\n                     len(source) - 1 - idx)\n        data = Variable(source[idx:idx + length], volatile=volatile)\n        target = Variable(source[idx + 1:idx + 1 + length].view(-1),\n                          volatile=volatile)\n        return data, target\n\n    @property\n    def shared_path(self):\n        return f\'{self.args.model_dir}/shared_epoch{self.epoch}_step{self.shared_step}.pth\'\n\n    @property\n    def controller_path(self):\n        return f\'{self.args.model_dir}/controller_epoch{self.epoch}_step{self.controller_step}.pth\'\n\n    def get_saved_models_info(self):\n        paths = glob.glob(os.path.join(self.args.model_dir, \'*.pth\'))\n        paths.sort()\n\n        def get_numbers(items, delimiter, idx, replace_word, must_contain=\'\'):\n            return list(set([int(\n                    name.split(delimiter)[idx].replace(replace_word, \'\'))\n                    for name in basenames if must_contain in name]))\n\n        basenames = [os.path.basename(path.rsplit(\'.\', 1)[0]) for path in paths]\n        epochs = get_numbers(basenames, \'_\', 1, \'epoch\')\n        shared_steps = get_numbers(basenames, \'_\', 2, \'step\', \'shared\')\n        controller_steps = get_numbers(basenames, \'_\', 2, \'step\', \'controller\')\n\n        epochs.sort()\n        shared_steps.sort()\n        controller_steps.sort()\n\n        return epochs, shared_steps, controller_steps\n\n    def save_model(self):\n        torch.save(self.shared.state_dict(), self.shared_path)\n        logger.info(f\'[*] SAVED: {self.shared_path}\')\n\n        torch.save(self.controller.state_dict(), self.controller_path)\n        logger.info(f\'[*] SAVED: {self.controller_path}\')\n\n        epochs, shared_steps, controller_steps = self.get_saved_models_info()\n\n        for epoch in epochs[:-self.args.max_save_num]:\n            paths = glob.glob(\n                os.path.join(self.args.model_dir, f\'*_epoch{epoch}_*.pth\'))\n\n            for path in paths:\n                utils.remove_file(path)\n\n    def load_model(self):\n        epochs, shared_steps, controller_steps = self.get_saved_models_info()\n\n        if len(epochs) == 0:\n            logger.info(f\'[!] No checkpoint found in {self.args.model_dir}...\')\n            return\n\n        self.epoch = self.start_epoch = max(epochs)\n        self.shared_step = max(shared_steps)\n        self.controller_step = max(controller_steps)\n\n        if self.args.num_gpu == 0:\n            map_location = lambda storage, loc: storage\n        else:\n            map_location = None\n\n        self.shared.load_state_dict(\n            torch.load(self.shared_path, map_location=map_location))\n        logger.info(f\'[*] LOADED: {self.shared_path}\')\n\n        self.controller.load_state_dict(\n            torch.load(self.controller_path, map_location=map_location))\n        logger.info(f\'[*] LOADED: {self.controller_path}\')\n\n    def _summarize_controller_train(self,\n                                    total_loss,\n                                    adv_history,\n                                    entropy_history,\n                                    reward_history,\n                                    avg_reward_base,\n                                    dags):\n        """"""Logs the controller\'s progress for this training epoch.""""""\n        cur_loss = total_loss / self.args.log_step\n\n        avg_adv = np.mean(adv_history)\n        avg_entropy = np.mean(entropy_history)\n        avg_reward = np.mean(reward_history)\n\n        if avg_reward_base is None:\n            avg_reward_base = avg_reward\n\n        logger.info(\n            f\'| epoch {self.epoch:3d} | lr {self.controller_lr:.5f} \'\n            f\'| R {avg_reward:.5f} | entropy {avg_entropy:.4f} \'\n            f\'| loss {cur_loss:.5f}\')\n\n        # Tensorboard\n        if self.tb is not None:\n            self.tb.scalar_summary(\'controller/loss\',\n                                   cur_loss,\n                                   self.controller_step)\n            self.tb.scalar_summary(\'controller/reward\',\n                                   avg_reward,\n                                   self.controller_step)\n            self.tb.scalar_summary(\'controller/reward-B_per_epoch\',\n                                   avg_reward - avg_reward_base,\n                                   self.controller_step)\n            self.tb.scalar_summary(\'controller/entropy\',\n                                   avg_entropy,\n                                   self.controller_step)\n            self.tb.scalar_summary(\'controller/adv\',\n                                   avg_adv,\n                                   self.controller_step)\n\n            paths = []\n            for dag in dags:\n                fname = (f\'{self.epoch:03d}-{self.controller_step:06d}-\'\n                         f\'{avg_reward:6.4f}.png\')\n                path = os.path.join(self.args.model_dir, \'networks\', fname)\n                utils.draw_network(dag, path)\n                paths.append(path)\n\n            self.tb.image_summary(\'controller/sample\',\n                                  paths,\n                                  self.controller_step)\n\n    def _summarize_shared_train(self, total_loss, raw_total_loss):\n        """"""Logs a set of training steps.""""""\n        cur_loss = utils.to_item(total_loss) / self.args.log_step\n        # NOTE(brendan): The raw loss, without adding in the activation\n        # regularization terms, should be used to compute ppl.\n        cur_raw_loss = utils.to_item(raw_total_loss) / self.args.log_step\n        ppl = math.exp(cur_raw_loss)\n\n        logger.info(f\'| epoch {self.epoch:3d} \'\n                    f\'| lr {self.shared_lr:4.2f} \'\n                    f\'| raw loss {cur_raw_loss:.2f} \'\n                    f\'| loss {cur_loss:.2f} \'\n                    f\'| ppl {ppl:8.2f}\')\n\n        # Tensorboard\n        if self.tb is not None:\n            self.tb.scalar_summary(\'shared/loss\',\n                                   cur_loss,\n                                   self.shared_step)\n            self.tb.scalar_summary(\'shared/perplexity\',\n                                   ppl,\n                                   self.shared_step)\n'"
utils.py,3,"b'from __future__ import print_function\n\nfrom collections import defaultdict\nimport collections\nfrom datetime import datetime\nimport os\nimport json\nimport logging\n\nimport numpy as np\nimport pygraphviz as pgv\n\nimport torch\nfrom torch.autograd import Variable\n\nfrom PIL import Image\nfrom PIL import ImageFont\nfrom PIL import ImageDraw \n\n\ntry:\n    import scipy.misc\n    imread = scipy.misc.imread\n    imresize = scipy.misc.imresize\n    imsave = imwrite = scipy.misc.imsave\nexcept:\n    import cv2\n    imread = cv2.imread\n    imresize = cv2.imresize\n    imsave = imwrite = cv2.imwrite\n\n\n##########################\n# Network visualization\n##########################\n\ndef add_node(graph, node_id, label, shape=\'box\', style=\'filled\'):\n    if label.startswith(\'x\'):\n        color = \'white\'\n    elif label.startswith(\'h\'):\n        color = \'skyblue\'\n    elif label == \'tanh\':\n        color = \'yellow\'\n    elif label == \'ReLU\':\n        color = \'pink\'\n    elif label == \'identity\':\n        color = \'orange\'\n    elif label == \'sigmoid\':\n        color = \'greenyellow\'\n    elif label == \'avg\':\n        color = \'seagreen3\'\n    else:\n        color = \'white\'\n\n    if not any(label.startswith(word) for word in  [\'x\', \'avg\', \'h\']):\n        label = f""{label}\\n({node_id})""\n\n    graph.add_node(\n            node_id, label=label, color=\'black\', fillcolor=color,\n            shape=shape, style=style,\n    )\n\ndef draw_network(dag, path):\n    makedirs(os.path.dirname(path))\n    graph = pgv.AGraph(directed=True, strict=True,\n                       fontname=\'Helvetica\', arrowtype=\'open\') # not work?\n\n    checked_ids = [-2, -1, 0]\n\n    if -1 in dag:\n        add_node(graph, -1, \'x[t]\')\n    if -2 in dag:\n        add_node(graph, -2, \'h[t-1]\')\n\n    add_node(graph, 0, dag[-1][0].name)\n\n    for idx in dag:\n        for node in dag[idx]:\n            if node.id not in checked_ids:\n                add_node(graph, node.id, node.name)\n                checked_ids.append(node.id)\n            graph.add_edge(idx, node.id)\n\n    graph.layout(prog=\'dot\')\n    graph.draw(path)\n\ndef make_gif(paths, gif_path, max_frame=50, prefix=""""):\n    import imageio\n\n    paths.sort()\n\n    skip_frame = len(paths) // max_frame\n    paths = paths[::skip_frame]\n\n    images = [imageio.imread(path) for path in paths]\n    max_h, max_w, max_c = np.max(\n            np.array([image.shape for image in images]), 0)\n\n    for idx, image in enumerate(images):\n        h, w, c = image.shape\n        blank = np.ones([max_h, max_w, max_c], dtype=np.uint8) * 255\n\n        pivot_h, pivot_w = (max_h-h)//2, (max_w-w)//2\n        blank[pivot_h:pivot_h+h,pivot_w:pivot_w+w,:c] = image\n\n        images[idx] = blank\n\n    try:\n        images = [Image.fromarray(image) for image in images]\n        draws = [ImageDraw.Draw(image) for image in images]\n        font = ImageFont.truetype(""assets/arial.ttf"", 30)\n\n        steps = [int(os.path.basename(path).rsplit(\'.\', 1)[0].split(\'-\')[1]) for path in paths]\n        for step, draw in zip(steps, draws):\n            draw.text((max_h//20, max_h//20),\n                      f""{prefix}step: {format(step, \',d\')}"", (0, 0, 0), font=font)\n    except IndexError:\n        pass\n\n    imageio.mimsave(gif_path, [np.array(img) for img in images], duration=0.5)\n\n\n##########################\n# Torch\n##########################\n\ndef detach(h):\n    if type(h) == Variable:\n        return Variable(h.data)\n    else:\n        return tuple(detach(v) for v in h)\n\ndef get_variable(inputs, cuda=False, **kwargs):\n    if type(inputs) in [list, np.ndarray]:\n        inputs = torch.Tensor(inputs)\n    if cuda:\n        out = Variable(inputs.cuda(), **kwargs)\n    else:\n        out = Variable(inputs, **kwargs)\n    return out\n\ndef update_lr(optimizer, lr):\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef batchify(data, bsz, use_cuda):\n    # code from https://github.com/pytorch/examples/blob/master/word_language_model/main.py \n    nbatch = data.size(0) // bsz\n    data = data.narrow(0, 0, nbatch * bsz)\n    data = data.view(bsz, -1).t().contiguous()\n    if use_cuda:\n        data = data.cuda()\n    return data\n\n\n##########################\n# ETC\n##########################\n\nNode = collections.namedtuple(\'Node\', [\'id\', \'name\'])\n\n\nclass keydefaultdict(defaultdict):\n    def __missing__(self, key):\n        if self.default_factory is None:\n            raise KeyError(key)\n        else:\n            ret = self[key] = self.default_factory(key)\n            return ret\n\n\ndef to_item(x):\n    """"""Converts x, possibly scalar and possibly tensor, to a Python scalar.""""""\n    if isinstance(x, (float, int)):\n        return x\n\n    if float(torch.__version__[0:3]) < 0.4:\n        assert (x.dim() == 1) and (len(x) == 1)\n        return x[0]\n\n    return x.item()\n\n\ndef get_logger(name=__file__, level=logging.INFO):\n    logger = logging.getLogger(name)\n\n    if getattr(logger, \'_init_done__\', None):\n        logger.setLevel(level)\n        return logger\n\n    logger._init_done__ = True\n    logger.propagate = False\n    logger.setLevel(level)\n\n    formatter = logging.Formatter(""%(asctime)s:%(levelname)s::%(message)s"")\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    handler.setLevel(0)\n\n    del logger.handlers[:]\n    logger.addHandler(handler)\n\n    return logger\n\n\nlogger = get_logger()\n\n\ndef prepare_dirs(args):\n    """"""Sets the directories for the model, and creates those directories.\n\n    Args:\n        args: Parsed from `argparse` in the `config` module.\n    """"""\n    if args.load_path:\n        if args.load_path.startswith(args.log_dir):\n            args.model_dir = args.load_path\n        else:\n            if args.load_path.startswith(args.dataset):\n                args.model_name = args.load_path\n            else:\n                args.model_name = ""{}_{}"".format(args.dataset, args.load_path)\n    else:\n        args.model_name = ""{}_{}"".format(args.dataset, get_time())\n\n    if not hasattr(args, \'model_dir\'):\n        args.model_dir = os.path.join(args.log_dir, args.model_name)\n    args.data_path = os.path.join(args.data_dir, args.dataset)\n\n    for path in [args.log_dir, args.data_dir, args.model_dir]:\n        if not os.path.exists(path):\n            makedirs(path)\n\ndef get_time():\n    return datetime.now().strftime(""%Y-%m-%d_%H-%M-%S"")\n\ndef save_args(args):\n    param_path = os.path.join(args.model_dir, ""params.json"")\n\n    logger.info(""[*] MODEL dir: %s"" % args.model_dir)\n    logger.info(""[*] PARAM path: %s"" % param_path)\n\n    with open(param_path, \'w\') as fp:\n        json.dump(args.__dict__, fp, indent=4, sort_keys=True)\n\ndef save_dag(args, dag, name):\n    save_path = os.path.join(args.model_dir, name)\n    logger.info(""[*] Save dag : {}"".format(save_path))\n    json.dump(dag, open(save_path, \'w\'))\n\ndef load_dag(args):\n    load_path = os.path.join(args.dag_path)\n    logger.info(""[*] Load dag : {}"".format(load_path))\n    with open(load_path) as f:\n        dag = json.load(f)\n    dag = {int(k): [Node(el[0], el[1]) for el in v] for k, v in dag.items()}\n    save_dag(args, dag, ""dag.json"")\n    draw_network(dag, os.path.join(args.model_dir, ""dag.png""))\n    return dag          \n  \ndef makedirs(path):\n    if not os.path.exists(path):\n        logger.info(""[*] Make directories : {}"".format(path))\n        os.makedirs(path)\n\ndef remove_file(path):\n    if os.path.exists(path):\n        logger.info(""[*] Removed: {}"".format(path))\n        os.remove(path)\n\ndef backup_file(path):\n    root, ext = os.path.splitext(path)\n    new_path = ""{}.backup_{}{}"".format(root, get_time(), ext)\n\n    os.rename(path, new_path)\n    logger.info(""[*] {} has backup: {}"".format(path, new_path))\n'"
data/__init__.py,0,b'import data.text\nimport data.image\n'
data/image.py,0,"b""import torch as t\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\n\nclass Image(object):\n    def __init__(self, args):\n        if args.dataset == 'cifar10':\n            Dataset = datasets.CIFAR10\n\n            mean = [0.49139968, 0.48215827, 0.44653124]\n            std = [0.24703233, 0.24348505, 0.26158768]\n\n            normalize = transforms.Normalize(mean, std)\n\n            transform = transforms.Compose([\n                transforms.RandomCrop(32, padding=4),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        elif args.dataset == 'MNIST':\n            Dataset = datasets.MNIST\n        else:\n            raise NotImplementedError(f'Unknown dataset: {args.dataset}')\n\n        self.train = t.utils.data.DataLoader(\n            Dataset(root='./data', train=True, transform=transform, download=True),\n            batch_size=args.batch_size, shuffle=True,\n            num_workers=args.num_workers, pin_memory=True)\n\n        self.valid = t.utils.data.DataLoader(\n            Dataset(root='./data', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                normalize,\n            ])),\n            batch_size=args.batch_size, shuffle=False,\n            num_workers=args.num_workers, pin_memory=True)\n\n        self.test = self.valid\n"""
data/text.py,0,"b'# Code from https://github.com/salesforce/awd-lstm-lm\nimport os\nimport torch as t\n\nimport collections\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {}\n        self.idx2word = []\n        self.counter = collections.Counter()\n        self.total = 0\n\n    def add_word(self, word):\n        if word not in self.word2idx:\n            self.idx2word.append(word)\n            self.word2idx[word] = len(self.idx2word) - 1\n\n        token_id = self.word2idx[word]\n        self.counter[token_id] += 1\n        self.total += 1\n\n        return token_id\n\n    def __len__(self):\n        return len(self.idx2word)\n\n\nclass Corpus(object):\n    def __init__(self, path):\n        self.dictionary = Dictionary()\n        self.train = self.tokenize(os.path.join(path, \'train.txt\'))\n        self.valid = self.tokenize(os.path.join(path, \'valid.txt\'))\n        self.test = self.tokenize(os.path.join(path, \'test.txt\'))\n        self.num_tokens = len(self.dictionary)\n\n    def tokenize(self, path):\n        """"""Tokenizes a text file.""""""\n        assert os.path.exists(path)\n        # Add words to the dictionary\n        with open(path, \'r\') as f:\n            tokens = 0\n            for line in f:\n                words = line.split() + [\'<eos>\']\n                tokens += len(words)\n                for word in words:\n                    self.dictionary.add_word(word)\n\n        # Tokenize file content\n        with open(path, \'r\') as f:\n            ids = t.LongTensor(tokens)\n            token = 0\n            for line in f:\n                words = line.split() + [\'<eos>\']\n                for word in words:\n                    ids[token] = self.dictionary.word2idx[word]\n                    token += 1\n\n        return ids\n'"
models/__init__.py,0,b'from models.shared_rnn import RNN\nfrom models.shared_cnn import CNN\nfrom models.controller import Controller\n'
models/controller.py,12,"b'""""""A module with NAS controller-related code.""""""\nimport collections\nimport os\n\nimport torch\nimport torch.nn.functional as F\n\nimport utils\nfrom utils import Node\n\n\ndef _construct_dags(prev_nodes, activations, func_names, num_blocks):\n    """"""Constructs a set of DAGs based on the actions, i.e., previous nodes and\n    activation functions, sampled from the controller/policy pi.\n\n    Args:\n        prev_nodes: Previous node actions from the policy.\n        activations: Activations sampled from the policy.\n        func_names: Mapping from activation function names to functions.\n        num_blocks: Number of blocks in the target RNN cell.\n\n    Returns:\n        A list of DAGs defined by the inputs.\n\n    RNN cell DAGs are represented in the following way:\n\n    1. Each element (node) in a DAG is a list of `Node`s.\n\n    2. The `Node`s in the list dag[i] correspond to the subsequent nodes\n       that take the output from node i as their own input.\n\n    3. dag[-1] is the node that takes input from x^{(t)} and h^{(t - 1)}.\n       dag[-1] always feeds dag[0].\n       dag[-1] acts as if `w_xc`, `w_hc`, `w_xh` and `w_hh` are its\n       weights.\n\n    4. dag[N - 1] is the node that produces the hidden state passed to\n       the next timestep. dag[N - 1] is also always a leaf node, and therefore\n       is always averaged with the other leaf nodes and fed to the output\n       decoder.\n    """"""\n    dags = []\n    for nodes, func_ids in zip(prev_nodes, activations):\n        dag = collections.defaultdict(list)\n\n        # add first node\n        dag[-1] = [Node(0, func_names[func_ids[0]])]\n        dag[-2] = [Node(0, func_names[func_ids[0]])]\n\n        # add following nodes\n        for jdx, (idx, func_id) in enumerate(zip(nodes, func_ids[1:])):\n            dag[utils.to_item(idx)].append(Node(jdx + 1, func_names[func_id]))\n\n        leaf_nodes = set(range(num_blocks)) - dag.keys()\n\n        # merge with avg\n        for idx in leaf_nodes:\n            dag[idx] = [Node(num_blocks, \'avg\')]\n\n        # TODO(brendan): This is actually y^{(t)}. h^{(t)} is node N - 1 in\n        # the graph, where N Is the number of nodes. I.e., h^{(t)} takes\n        # only one other node as its input.\n        # last h[t] node\n        last_node = Node(num_blocks + 1, \'h[t]\')\n        dag[num_blocks] = [last_node]\n        dags.append(dag)\n\n    return dags\n\n\nclass Controller(torch.nn.Module):\n    """"""Based on\n    https://github.com/pytorch/examples/blob/master/word_language_model/model.py\n\n    TODO(brendan): RL controllers do not necessarily have much to do with\n    language models.\n\n    Base the controller RNN on the GRU from:\n    https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/blob/master/model.py\n    """"""\n    def __init__(self, args):\n        torch.nn.Module.__init__(self)\n        self.args = args\n\n        if self.args.network_type == \'rnn\':\n            # NOTE(brendan): `num_tokens` here is just the activation function\n            # for every even step,\n            self.num_tokens = [len(args.shared_rnn_activations)]\n            for idx in range(self.args.num_blocks):\n                self.num_tokens += [idx + 1,\n                                    len(args.shared_rnn_activations)]\n            self.func_names = args.shared_rnn_activations\n        elif self.args.network_type == \'cnn\':\n            self.num_tokens = [len(args.shared_cnn_types),\n                               self.args.num_blocks]\n            self.func_names = args.shared_cnn_types\n\n        num_total_tokens = sum(self.num_tokens)\n\n        self.encoder = torch.nn.Embedding(num_total_tokens,\n                                          args.controller_hid)\n        self.lstm = torch.nn.LSTMCell(args.controller_hid, args.controller_hid)\n\n        # TODO(brendan): Perhaps these weights in the decoder should be\n        # shared? At least for the activation functions, which all have the\n        # same size.\n        self.decoders = []\n        for idx, size in enumerate(self.num_tokens):\n            decoder = torch.nn.Linear(args.controller_hid, size)\n            self.decoders.append(decoder)\n\n        self._decoders = torch.nn.ModuleList(self.decoders)\n\n        self.reset_parameters()\n        self.static_init_hidden = utils.keydefaultdict(self.init_hidden)\n\n        def _get_default_hidden(key):\n            return utils.get_variable(\n                torch.zeros(key, self.args.controller_hid),\n                self.args.cuda,\n                requires_grad=False)\n\n        self.static_inputs = utils.keydefaultdict(_get_default_hidden)\n\n    def reset_parameters(self):\n        init_range = 0.1\n        for param in self.parameters():\n            param.data.uniform_(-init_range, init_range)\n        for decoder in self.decoders:\n            decoder.bias.data.fill_(0)\n\n    def forward(self,  # pylint:disable=arguments-differ\n                inputs,\n                hidden,\n                block_idx,\n                is_embed):\n        if not is_embed:\n            embed = self.encoder(inputs)\n        else:\n            embed = inputs\n\n        hx, cx = self.lstm(embed, hidden)\n        logits = self.decoders[block_idx](hx)\n\n        logits /= self.args.softmax_temperature\n\n        # exploration\n        if self.args.mode == \'train\':\n            logits = (self.args.tanh_c*F.tanh(logits))\n\n        return logits, (hx, cx)\n\n    def sample(self, batch_size=1, with_details=False, save_dir=None):\n        """"""Samples a set of `args.num_blocks` many computational nodes from the\n        controller, where each node is made up of an activation function, and\n        each node except the last also includes a previous node.\n        """"""\n        if batch_size < 1:\n            raise Exception(f\'Wrong batch_size: {batch_size} < 1\')\n\n        # [B, L, H]\n        inputs = self.static_inputs[batch_size]\n        hidden = self.static_init_hidden[batch_size]\n\n        activations = []\n        entropies = []\n        log_probs = []\n        prev_nodes = []\n        # NOTE(brendan): The RNN controller alternately outputs an activation,\n        # followed by a previous node, for each block except the last one,\n        # which only gets an activation function. The last node is the output\n        # node, and its previous node is the average of all leaf nodes.\n        for block_idx in range(2*(self.args.num_blocks - 1) + 1):\n            logits, hidden = self.forward(inputs,\n                                          hidden,\n                                          block_idx,\n                                          is_embed=(block_idx == 0))\n\n            probs = F.softmax(logits, dim=-1)\n            log_prob = F.log_softmax(logits, dim=-1)\n            # TODO(brendan): .mean() for entropy?\n            entropy = -(log_prob * probs).sum(1, keepdim=False)\n\n            action = probs.multinomial(num_samples=1).data\n            selected_log_prob = log_prob.gather(\n                1, utils.get_variable(action, requires_grad=False))\n\n            # TODO(brendan): why the [:, 0] here? Should it be .squeeze(), or\n            # .view()? Same below with `action`.\n            entropies.append(entropy)\n            log_probs.append(selected_log_prob[:, 0])\n\n            # 0: function, 1: previous node\n            mode = block_idx % 2\n            inputs = utils.get_variable(\n                action[:, 0] + sum(self.num_tokens[:mode]),\n                requires_grad=False)\n\n            if mode == 0:\n                activations.append(action[:, 0])\n            elif mode == 1:\n                prev_nodes.append(action[:, 0])\n\n        prev_nodes = torch.stack(prev_nodes).transpose(0, 1)\n        activations = torch.stack(activations).transpose(0, 1)\n\n        dags = _construct_dags(prev_nodes,\n                               activations,\n                               self.func_names,\n                               self.args.num_blocks)\n\n        if save_dir is not None:\n            for idx, dag in enumerate(dags):\n                utils.draw_network(dag,\n                                   os.path.join(save_dir, f\'graph{idx}.png\'))\n\n        if with_details:\n            return dags, torch.cat(log_probs), torch.cat(entropies)\n\n        return dags\n\n    def init_hidden(self, batch_size):\n        zeros = torch.zeros(batch_size, self.args.controller_hid)\n        return (utils.get_variable(zeros, self.args.cuda, requires_grad=False),\n                utils.get_variable(zeros.clone(), self.args.cuda, requires_grad=False))\n'"
models/shared_base.py,2,"b'import numpy as np\nimport torch\n\n\ndef size(p):\n    return np.prod(p.size())\n\nclass SharedModel(torch.nn.Module):\n    def __init__(self):\n        torch.nn.Module.__init__(self)\n\n    @property\n    def num_parameters(self):\n        return sum([size(param) for param in self.parameters()])\n\n    def get_f(self, name):\n        raise NotImplementedError()\n\n    def get_num_cell_parameters(self, dag):\n        raise NotImplementedError()\n\n    def reset_parameters(self):\n        raise NotImplementedError()\n'"
models/shared_cnn.py,2,"b'import numpy as np\nfrom collections import defaultdict, deque\n\nimport torch as t\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nfrom models.shared_base import *\nfrom utils import get_logger, get_variable, keydefaultdict\n\nlogger = get_logger()\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef conv5x5(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=5, stride=stride,\n                     padding=1, bias=False)\n\ndef conv(kernel, planes):\n    if kernel == 3:\n        _conv = conv3x3\n    elif kernel == 5:\n        _conv = conv5x5\n    else:\n        raise NotImplemented(f""Unkown kernel size: {kernel}"")\n\n    return nn.Sequential(\n            nn.ReLU(inplace=True),\n            _conv(planes, planes),\n            nn.BatchNorm2d(planes),\n    )\n\n\nclass CNN(SharedModel):\n    def __init__(self, args, images):\n        super(CNN, self).__init__()\n\n        self.args = args\n        self.images = images\n\n        self.w_c, self.w_h = defaultdict(dict), defaultdict(dict)\n        self.reset_parameters()\n\n        self.conv = defaultdict(dict)\n        for idx in range(args.num_blocks):\n            for jdx in range(idx+1, args.num_blocks):\n                self.conv[idx][jdx] = conv()\n\n        raise NotImplemented(""In progress..."")\n\n    def forward(self, inputs, dag):\n        pass\n\n    def get_f(self, name):\n        name = name.lower()\n        return f\n\n    def get_num_cell_parameters(self, dag):\n        pass\n\n    def reset_parameters(self):\n        pass\n'"
models/shared_rnn.py,21,"b'""""""Module containing the shared RNN model.""""""\nimport numpy as np\nimport collections\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nimport models.shared_base\nimport utils\n\n\nlogger = utils.get_logger()\n\n\ndef _get_dropped_weights(w_raw, dropout_p, is_training):\n    """"""Drops out weights to implement DropConnect.\n\n    Args:\n        w_raw: Full, pre-dropout, weights to be dropped out.\n        dropout_p: Proportion of weights to drop out.\n        is_training: True iff _shared_ model is training.\n\n    Returns:\n        The dropped weights.\n\n    TODO(brendan): Why does torch.nn.functional.dropout() return:\n    1. `torch.autograd.Variable()` on the training loop\n    2. `torch.nn.Parameter()` on the controller or eval loop, when\n    training = False...\n\n    Even though the call to `_setweights` in the Smerity repo\'s\n    `weight_drop.py` does not have this behaviour, and `F.dropout` always\n    returns `torch.autograd.Variable` there, even when `training=False`?\n\n    The above TODO is the reason for the hacky check for `torch.nn.Parameter`.\n    """"""\n    dropped_w = F.dropout(w_raw, p=dropout_p, training=is_training)\n\n    if isinstance(dropped_w, torch.nn.Parameter):\n        dropped_w = dropped_w.clone()\n\n    return dropped_w\n\n\ndef isnan(tensor):\n    return np.isnan(tensor.cpu().data.numpy()).sum() > 0\n\n\nclass EmbeddingDropout(torch.nn.Embedding):\n    """"""Class for dropping out embeddings by zero\'ing out parameters in the\n    embedding matrix.\n\n    This is equivalent to dropping out particular words, e.g., in the sentence\n    \'the quick brown fox jumps over the lazy dog\', dropping out \'the\' would\n    lead to the sentence \'### quick brown fox jumps over ### lazy dog\' (in the\n    embedding vector space).\n\n    See \'A Theoretically Grounded Application of Dropout in Recurrent Neural\n    Networks\', (Gal and Ghahramani, 2016).\n    """"""\n    def __init__(self,\n                 num_embeddings,\n                 embedding_dim,\n                 max_norm=None,\n                 norm_type=2,\n                 scale_grad_by_freq=False,\n                 sparse=False,\n                 dropout=0.1,\n                 scale=None):\n        """"""Embedding constructor.\n\n        Args:\n            dropout: Dropout probability.\n            scale: Used to scale parameters of embedding weight matrix that are\n                not dropped out. Note that this is _in addition_ to the\n                `1/(1 - dropout)` scaling.\n\n        See `torch.nn.Embedding` for remaining arguments.\n        """"""\n        torch.nn.Embedding.__init__(self,\n                                    num_embeddings=num_embeddings,\n                                    embedding_dim=embedding_dim,\n                                    max_norm=max_norm,\n                                    norm_type=norm_type,\n                                    scale_grad_by_freq=scale_grad_by_freq,\n                                    sparse=sparse)\n        self.dropout = dropout\n        assert (dropout >= 0.0) and (dropout < 1.0), (\'Dropout must be >= 0.0 \'\n                                                      \'and < 1.0\')\n        self.scale = scale\n\n    def forward(self, inputs):  # pylint:disable=arguments-differ\n        """"""Embeds `inputs` with the dropped out embedding weight matrix.""""""\n        if self.training:\n            dropout = self.dropout\n        else:\n            dropout = 0\n\n        if dropout:\n            mask = self.weight.data.new(self.weight.size(0), 1)\n            mask.bernoulli_(1 - dropout)\n            mask = mask.expand_as(self.weight)\n            mask = mask / (1 - dropout)\n            masked_weight = self.weight * Variable(mask)\n        else:\n            masked_weight = self.weight\n        if self.scale and self.scale != 1:\n            masked_weight = masked_weight * self.scale\n\n        return F.embedding(inputs,\n                           masked_weight,\n                           max_norm=self.max_norm,\n                           norm_type=self.norm_type,\n                           scale_grad_by_freq=self.scale_grad_by_freq,\n                           sparse=self.sparse)\n\n\nclass LockedDropout(nn.Module):\n    # code from https://github.com/salesforce/awd-lstm-lm/blob/master/locked_dropout.py\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x, dropout=0.5):\n        if not self.training or not dropout:\n            return x\n        m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - dropout)\n        mask = Variable(m, requires_grad=False) / (1 - dropout)\n        mask = mask.expand_as(x)\n        return mask * x\n\n\nclass RNN(models.shared_base.SharedModel):\n    """"""Shared RNN model.""""""\n    def __init__(self, args, corpus):\n        models.shared_base.SharedModel.__init__(self)\n\n        self.args = args\n        self.corpus = corpus\n\n        self.decoder = nn.Linear(args.shared_hid, corpus.num_tokens)\n        self.encoder = EmbeddingDropout(corpus.num_tokens,\n                                        args.shared_embed,\n                                        dropout=args.shared_dropoute)\n        self.lockdrop = LockedDropout()\n\n        if self.args.tie_weights:\n            self.decoder.weight = self.encoder.weight\n\n        # NOTE(brendan): Since W^{x, c} and W^{h, c} are always summed, there\n        # is no point duplicating their bias offset parameter. Likewise for\n        # W^{x, h} and W^{h, h}.\n        self.w_xc = nn.Linear(args.shared_embed, args.shared_hid)\n        self.w_xh = nn.Linear(args.shared_embed, args.shared_hid)\n\n        # The raw weights are stored here because the hidden-to-hidden weights\n        # are weight dropped on the forward pass.\n        self.w_hc_raw = torch.nn.Parameter(\n            torch.Tensor(args.shared_hid, args.shared_hid))\n        self.w_hh_raw = torch.nn.Parameter(\n            torch.Tensor(args.shared_hid, args.shared_hid))\n        self.w_hc = None\n        self.w_hh = None\n\n        self.w_h = collections.defaultdict(dict)\n        self.w_c = collections.defaultdict(dict)\n\n        for idx in range(args.num_blocks):\n            for jdx in range(idx + 1, args.num_blocks):\n                self.w_h[idx][jdx] = nn.Linear(args.shared_hid,\n                                               args.shared_hid,\n                                               bias=False)\n                self.w_c[idx][jdx] = nn.Linear(args.shared_hid,\n                                               args.shared_hid,\n                                               bias=False)\n\n        self._w_h = nn.ModuleList([self.w_h[idx][jdx]\n                                   for idx in self.w_h\n                                   for jdx in self.w_h[idx]])\n        self._w_c = nn.ModuleList([self.w_c[idx][jdx]\n                                   for idx in self.w_c\n                                   for jdx in self.w_c[idx]])\n\n        if args.mode == \'train\':\n            self.batch_norm = nn.BatchNorm1d(args.shared_hid)\n        else:\n            self.batch_norm = None\n\n        self.reset_parameters()\n        self.static_init_hidden = utils.keydefaultdict(self.init_hidden)\n\n        logger.info(f\'# of parameters: {format(self.num_parameters, "",d"")}\')\n\n    def forward(self,  # pylint:disable=arguments-differ\n                inputs,\n                dag,\n                hidden=None,\n                is_train=True):\n        time_steps = inputs.size(0)\n        batch_size = inputs.size(1)\n\n        is_train = is_train and self.args.mode in [\'train\']\n\n        self.w_hh = _get_dropped_weights(self.w_hh_raw,\n                                         self.args.shared_wdrop,\n                                         self.training)\n        self.w_hc = _get_dropped_weights(self.w_hc_raw,\n                                         self.args.shared_wdrop,\n                                         self.training)\n\n        if hidden is None:\n            hidden = self.static_init_hidden[batch_size]\n\n        embed = self.encoder(inputs)\n\n        if self.args.shared_dropouti > 0:\n            embed = self.lockdrop(embed,\n                                  self.args.shared_dropouti if is_train else 0)\n\n        # TODO(brendan): The norm of hidden states are clipped here because\n        # otherwise ENAS is especially prone to exploding activations on the\n        # forward pass. This could probably be fixed in a more elegant way, but\n        # it might be exposing a weakness in the ENAS algorithm as currently\n        # proposed.\n        #\n        # For more details, see\n        # https://github.com/carpedm20/ENAS-pytorch/issues/6\n        clipped_num = 0\n        max_clipped_norm = 0\n        h1tohT = []\n        logits = []\n        for step in range(time_steps):\n            x_t = embed[step]\n            logit, hidden = self.cell(x_t, hidden, dag)\n\n            hidden_norms = hidden.norm(dim=-1)\n            max_norm = 25.0\n            if hidden_norms.data.max() > max_norm:\n                # TODO(brendan): Just directly use the torch slice operations\n                # in PyTorch v0.4.\n                #\n                # This workaround for PyTorch v0.3.1 does everything in numpy,\n                # because the PyTorch slicing and slice assignment is too\n                # flaky.\n                hidden_norms = hidden_norms.data.cpu().numpy()\n\n                clipped_num += 1\n                if hidden_norms.max() > max_clipped_norm:\n                    max_clipped_norm = hidden_norms.max()\n\n                clip_select = hidden_norms > max_norm\n                clip_norms = hidden_norms[clip_select]\n\n                mask = np.ones(hidden.size())\n                normalizer = max_norm/clip_norms\n                normalizer = normalizer[:, np.newaxis]\n\n                mask[clip_select] = normalizer\n                hidden *= torch.autograd.Variable(\n                    torch.FloatTensor(mask).cuda(), requires_grad=False)\n\n            logits.append(logit)\n            h1tohT.append(hidden)\n\n        if clipped_num > 0:\n            logger.info(f\'clipped {clipped_num} hidden states in one forward \'\n                        f\'pass. \'\n                        f\'max clipped hidden state norm: {max_clipped_norm}\')\n\n        h1tohT = torch.stack(h1tohT)\n        output = torch.stack(logits)\n        raw_output = output\n        if self.args.shared_dropout > 0:\n            output = self.lockdrop(output,\n                                   self.args.shared_dropout if is_train else 0)\n\n        dropped_output = output\n\n        decoded = self.decoder(\n            output.view(output.size(0)*output.size(1), output.size(2)))\n        decoded = decoded.view(output.size(0), output.size(1), decoded.size(1))\n\n        extra_out = {\'dropped\': dropped_output,\n                     \'hiddens\': h1tohT,\n                     \'raw\': raw_output}\n        return decoded, hidden, extra_out\n\n    def cell(self, x, h_prev, dag):\n        """"""Computes a single pass through the discovered RNN cell.""""""\n        c = {}\n        h = {}\n        f = {}\n\n        f[0] = self.get_f(dag[-1][0].name)\n        c[0] = F.sigmoid(self.w_xc(x) + F.linear(h_prev, self.w_hc, None))\n        h[0] = (c[0]*f[0](self.w_xh(x) + F.linear(h_prev, self.w_hh, None)) +\n                (1 - c[0])*h_prev)\n\n        leaf_node_ids = []\n        q = collections.deque()\n        q.append(0)\n\n        # NOTE(brendan): Computes connections from the parent nodes `node_id`\n        # to their child nodes `next_id` recursively, skipping leaf nodes. A\n        # leaf node is a node whose id == `self.args.num_blocks`.\n        #\n        # Connections between parent i and child j should be computed as\n        # h_j = c_j*f_{ij}{(W^h_{ij}*h_i)} + (1 - c_j)*h_i,\n        # where c_j = \\sigmoid{(W^c_{ij}*h_i)}\n        #\n        # See Training details from Section 3.1 of the paper.\n        #\n        # The following algorithm does a breadth-first (since `q.popleft()` is\n        # used) search over the nodes and computes all the hidden states.\n        while True:\n            if len(q) == 0:\n                break\n\n            node_id = q.popleft()\n            nodes = dag[node_id]\n\n            for next_node in nodes:\n                next_id = next_node.id\n                if next_id == self.args.num_blocks:\n                    leaf_node_ids.append(node_id)\n                    assert len(nodes) == 1, (\'parent of leaf node should have \'\n                                             \'only one child\')\n                    continue\n\n                w_h = self.w_h[node_id][next_id]\n                w_c = self.w_c[node_id][next_id]\n\n                f[next_id] = self.get_f(next_node.name)\n                c[next_id] = F.sigmoid(w_c(h[node_id]))\n                h[next_id] = (c[next_id]*f[next_id](w_h(h[node_id])) +\n                              (1 - c[next_id])*h[node_id])\n\n                q.append(next_id)\n\n        # TODO(brendan): Instead of averaging loose ends, perhaps there should\n        # be a set of separate unshared weights for each ""loose"" connection\n        # between each node in a cell and the output.\n        #\n        # As it stands, all weights W^h_{ij} are doing double duty by\n        # connecting both from i to j, as well as from i to the output.\n\n        # average all the loose ends\n        leaf_nodes = [h[node_id] for node_id in leaf_node_ids]\n        output = torch.mean(torch.stack(leaf_nodes, 2), -1)\n\n        # stabilizing the Updates of omega\n        if self.batch_norm is not None:\n            output = self.batch_norm(output)\n\n        return output, h[self.args.num_blocks - 1]\n\n    def init_hidden(self, batch_size):\n        zeros = torch.zeros(batch_size, self.args.shared_hid)\n        return utils.get_variable(zeros, self.args.cuda, requires_grad=False)\n\n    def get_f(self, name):\n        name = name.lower()\n        if name == \'relu\':\n            f = F.relu\n        elif name == \'tanh\':\n            f = F.tanh\n        elif name == \'identity\':\n            f = lambda x: x\n        elif name == \'sigmoid\':\n            f = F.sigmoid\n        return f\n\n    def get_num_cell_parameters(self, dag):\n        num = 0\n\n        num += models.shared_base.size(self.w_xc)\n        num += models.shared_base.size(self.w_xh)\n\n        q = collections.deque()\n        q.append(0)\n\n        while True:\n            if len(q) == 0:\n                break\n\n            node_id = q.popleft()\n            nodes = dag[node_id]\n\n            for next_node in nodes:\n                next_id = next_node.id\n                if next_id == self.args.num_blocks:\n                    assert len(nodes) == 1, \'parent of leaf node should have only one child\'\n                    continue\n\n                w_h = self.w_h[node_id][next_id]\n                w_c = self.w_c[node_id][next_id]\n\n                num += models.shared_base.size(w_h)\n                num += models.shared_base.size(w_c)\n\n                q.append(next_id)\n\n        logger.debug(f\'# of cell parameters: \'\n                     f\'{format(self.num_parameters, "",d"")}\')\n        return num\n\n    def reset_parameters(self):\n        init_range = 0.025 if self.args.mode == \'train\' else 0.04\n        for param in self.parameters():\n            param.data.uniform_(-init_range, init_range)\n        self.decoder.bias.data.fill_(0)\n'"
