file_path,api_count,code
config.py,0,"b'#coding:utf8\nimport warnings\nclass DefaultConfig(object):\n    env = \'default\' # visdom \xe7\x8e\xaf\xe5\xa2\x83\n    model = \'ResNet34\' # \xe4\xbd\xbf\xe7\x94\xa8\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe5\x90\x8d\xe5\xad\x97\xe5\xbf\x85\xe9\xa1\xbb\xe4\xb8\x8emodels/__init__.py\xe4\xb8\xad\xe7\x9a\x84\xe5\x90\x8d\xe5\xad\x97\xe4\xb8\x80\xe8\x87\xb4\n    \n    train_data_root = \'./data/train/\' # \xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe5\xad\x98\xe6\x94\xbe\xe8\xb7\xaf\xe5\xbe\x84\n    test_data_root = \'./data/test1\' # \xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe5\xad\x98\xe6\x94\xbe\xe8\xb7\xaf\xe5\xbe\x84\n    load_model_path = \'checkpoints/model.pth\' # \xe5\x8a\xa0\xe8\xbd\xbd\xe9\xa2\x84\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\xef\xbc\x8c\xe4\xb8\xbaNone\xe4\xbb\xa3\xe8\xa1\xa8\xe4\xb8\x8d\xe5\x8a\xa0\xe8\xbd\xbd\n\n    batch_size = 128 # batch size\n    use_gpu = True # user GPU or not\n    num_workers = 4 # how many workers for loading data\n    print_freq = 20 # print info every N batch\n\n    debug_file = \'/tmp/debug\' # if os.path.exists(debug_file): enter ipdb\n    result_file = \'result.csv\'\n      \n    max_epoch = 10\n    lr = 0.1 # initial learning rate\n    lr_decay = 0.95 # when val_loss increase, lr = lr*lr_decay\n    weight_decay = 1e-4 # \xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\n\n\n\ndef parse(self,kwargs):\n        \'\'\'\n        \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8kwargs \xe6\x9b\xb4\xe6\x96\xb0 config\xe5\x8f\x82\xe6\x95\xb0\n        \'\'\'\n        for k,v in kwargs.iteritems():\n            if not hasattr(self,k):\n                warnings.warn(""Warning: opt has not attribut %s"" %k)\n            setattr(self,k,v)\n\n        print(\'user config:\')\n        for k,v in self.__class__.__dict__.iteritems():\n            if not k.startswith(\'__\'):\n                print(k,getattr(self,k))\n\n\nDefaultConfig.parse = parse\nopt =DefaultConfig()\n# opt.parse = parse\n'"
main.py,2,"b'#coding:utf8\nfrom config import opt\nimport os\nimport torch as t\nimport models\nfrom data.dataset import DogCat\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nfrom torchnet import meter\nfrom utils.visualize import Visualizer\nfrom tqdm import tqdm\n\ndef test(**kwargs):\n    opt.parse(kwargs)\n    import ipdb;\n    ipdb.set_trace()\n    # configure model\n    model = getattr(models, opt.model)().eval()\n    if opt.load_model_path:\n        model.load(opt.load_model_path)\n    if opt.use_gpu: model.cuda()\n\n    # data\n    train_data = DogCat(opt.test_data_root,test=True)\n    test_dataloader = DataLoader(train_data,batch_size=opt.batch_size,shuffle=False,num_workers=opt.num_workers)\n    results = []\n    for ii,(data,path) in enumerate(test_dataloader):\n        input = t.autograd.Variable(data,volatile = True)\n        if opt.use_gpu: input = input.cuda()\n        score = model(input)\n        probability = t.nn.functional.softmax(score)[:,0].data.tolist()\n        # label = score.max(dim = 1)[1].data.tolist()\n        \n        batch_results = [(path_,probability_) for path_,probability_ in zip(path,probability) ]\n\n        results += batch_results\n    write_csv(results,opt.result_file)\n\n    return results\n\ndef write_csv(results,file_name):\n    import csv\n    with open(file_name,\'w\') as f:\n        writer = csv.writer(f)\n        writer.writerow([\'id\',\'label\'])\n        writer.writerows(results)\n    \ndef train(**kwargs):\n    opt.parse(kwargs)\n    vis = Visualizer(opt.env)\n\n    # step1: configure model\n    model = getattr(models, opt.model)()\n    if opt.load_model_path:\n        model.load(opt.load_model_path)\n    if opt.use_gpu: model.cuda()\n\n    # step2: data\n    train_data = DogCat(opt.train_data_root,train=True)\n    val_data = DogCat(opt.train_data_root,train=False)\n    train_dataloader = DataLoader(train_data,opt.batch_size,\n                        shuffle=True,num_workers=opt.num_workers)\n    val_dataloader = DataLoader(val_data,opt.batch_size,\n                        shuffle=False,num_workers=opt.num_workers)\n    \n    # step3: criterion and optimizer\n    criterion = t.nn.CrossEntropyLoss()\n    lr = opt.lr\n    optimizer = t.optim.Adam(model.parameters(),lr = lr,weight_decay = opt.weight_decay)\n        \n    # step4: meters\n    loss_meter = meter.AverageValueMeter()\n    confusion_matrix = meter.ConfusionMeter(2)\n    previous_loss = 1e100\n\n    # train\n    for epoch in range(opt.max_epoch):\n        \n        loss_meter.reset()\n        confusion_matrix.reset()\n\n        for ii,(data,label) in tqdm(enumerate(train_dataloader),total=len(train_data)):\n\n            # train model \n            input = Variable(data)\n            target = Variable(label)\n            if opt.use_gpu:\n                input = input.cuda()\n                target = target.cuda()\n\n            optimizer.zero_grad()\n            score = model(input)\n            loss = criterion(score,target)\n            loss.backward()\n            optimizer.step()\n            \n            \n            # meters update and visualize\n            loss_meter.add(loss.data[0])\n            confusion_matrix.add(score.data, target.data)\n\n            if ii%opt.print_freq==opt.print_freq-1:\n                vis.plot(\'loss\', loss_meter.value()[0])\n                \n                # \xe8\xbf\x9b\xe5\x85\xa5debug\xe6\xa8\xa1\xe5\xbc\x8f\n                if os.path.exists(opt.debug_file):\n                    import ipdb;\n                    ipdb.set_trace()\n\n\n        model.save()\n\n        # validate and visualize\n        val_cm,val_accuracy = val(model,val_dataloader)\n\n        vis.plot(\'val_accuracy\',val_accuracy)\n        vis.log(""epoch:{epoch},lr:{lr},loss:{loss},train_cm:{train_cm},val_cm:{val_cm}"".format(\n                    epoch = epoch,loss = loss_meter.value()[0],val_cm = str(val_cm.value()),train_cm=str(confusion_matrix.value()),lr=lr))\n        \n        # update learning rate\n        if loss_meter.value()[0] > previous_loss:          \n            lr = lr * opt.lr_decay\n            # \xe7\xac\xac\xe4\xba\x8c\xe7\xa7\x8d\xe9\x99\x8d\xe4\xbd\x8e\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95:\xe4\xb8\x8d\xe4\xbc\x9a\xe6\x9c\x89moment\xe7\xad\x89\xe4\xbf\xa1\xe6\x81\xaf\xe7\x9a\x84\xe4\xb8\xa2\xe5\xa4\xb1\n            for param_group in optimizer.param_groups:\n                param_group[\'lr\'] = lr\n        \n\n        previous_loss = loss_meter.value()[0]\n\ndef val(model,dataloader):\n    \'\'\'\n    \xe8\xae\xa1\xe7\xae\x97\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x9c\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe9\x9b\x86\xe4\xb8\x8a\xe7\x9a\x84\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87\xe7\xad\x89\xe4\xbf\xa1\xe6\x81\xaf\n    \'\'\'\n    model.eval()\n    confusion_matrix = meter.ConfusionMeter(2)\n    for ii, data in enumerate(dataloader):\n        input, label = data\n        val_input = Variable(input, volatile=True)\n        val_label = Variable(label.type(t.LongTensor), volatile=True)\n        if opt.use_gpu:\n            val_input = val_input.cuda()\n            val_label = val_label.cuda()\n        score = model(val_input)\n        confusion_matrix.add(score.data.squeeze(), label.type(t.LongTensor))\n\n    model.train()\n    cm_value = confusion_matrix.value()\n    accuracy = 100. * (cm_value[0][0] + cm_value[1][1]) / (cm_value.sum())\n    return confusion_matrix, accuracy\n\ndef help():\n    \'\'\'\n    \xe6\x89\x93\xe5\x8d\xb0\xe5\xb8\xae\xe5\x8a\xa9\xe7\x9a\x84\xe4\xbf\xa1\xe6\x81\xaf\xef\xbc\x9a python file.py help\n    \'\'\'\n    \n    print(\'\'\'\n    usage : python file.py <function> [--args=value]\n    <function> := train | test | help\n    example: \n            python {0} train --env=\'env0701\' --lr=0.01\n            python {0} test --dataset=\'path/to/dataset/root/\'\n            python {0} help\n    avaiable args:\'\'\'.format(__file__))\n\n    from inspect import getsource\n    source = (getsource(opt.__class__))\n    print(source)\n\nif __name__==\'__main__\':\n    import fire\n    fire.Fire()\n'"
data/__init__.py,0,b''
data/dataset.py,1,"b""#coding:utf8\nimport os\nfrom PIL import  Image\nfrom torch.utils import data\nimport numpy as np\nfrom torchvision import  transforms as T\n\n\nclass DogCat(data.Dataset):\n    \n    def __init__(self,root,transforms=None,train=True,test=False):\n        '''\n        \xe4\xb8\xbb\xe8\xa6\x81\xe7\x9b\xae\xe6\xa0\x87\xef\xbc\x9a \xe8\x8e\xb7\xe5\x8f\x96\xe6\x89\x80\xe6\x9c\x89\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe5\x9c\xb0\xe5\x9d\x80\xef\xbc\x8c\xe5\xb9\xb6\xe6\xa0\xb9\xe6\x8d\xae\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe5\x88\x92\xe5\x88\x86\xe6\x95\xb0\xe6\x8d\xae\n        '''\n        self.test = test\n        imgs = [os.path.join(root,img) for img in os.listdir(root)] \n\n        # test1: data/test1/8973.jpg\n        # train: data/train/cat.10004.jpg \n        if self.test:\n            imgs = sorted(imgs,key=lambda x:int(x.split('.')[-2].split('/')[-1]))\n        else:\n            imgs = sorted(imgs,key=lambda x:int(x.split('.')[-2]))\n            \n        imgs_num = len(imgs)\n        \n        # shuffle imgs\n        np.random.seed(100)\n        imgs = np.random.permutation(imgs)\n        \n        if self.test:\n            self.imgs = imgs\n        elif train:\n            self.imgs = imgs[:int(0.7*imgs_num)]\n        else :\n            self.imgs = imgs[int(0.7*imgs_num):]\n            \n    \n        if transforms is None:\n            normalize = T.Normalize(mean = [0.485, 0.456, 0.406], \n                                     std = [0.229, 0.224, 0.225])\n\n            if self.test or not train: \n                self.transforms = T.Compose([\n                    T.Scale(224),\n                    T.CenterCrop(224),\n                    T.ToTensor(),\n                    normalize\n                    ]) \n            else :\n                self.transforms = T.Compose([\n                    T.Scale(256),\n                    T.RandomSizedCrop(224),\n                    T.RandomHorizontalFlip(),\n                    T.ToTensor(),\n                    normalize\n                    ]) \n                \n        \n    def __getitem__(self,index):\n        '''\n        \xe4\xb8\x80\xe6\xac\xa1\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x80\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\n        '''\n        img_path = self.imgs[index]\n        if self.test: label = int(self.imgs[index].split('.')[-2].split('/')[-1])\n        else: label = 1 if 'dog' in img_path.split('/')[-1] else 0\n        data = Image.open(img_path)\n        data = self.transforms(data)\n        return data, label\n    \n    def __len__(self):\n        return len(self.imgs)\n"""
models/AlexNet.py,0,"b""#coding:utf8\nfrom torch import nn\nfrom .BasicModule import BasicModule\n\nclass AlexNet(BasicModule):\n    '''\n    code from torchvision/models/alexnet.py\n    \xe7\xbb\x93\xe6\x9e\x84\xe5\x8f\x82\xe8\x80\x83 <https://arxiv.org/abs/1404.5997>\n    '''\n    def __init__(self, num_classes=2):\n        \n        super(AlexNet, self).__init__()\n        \n        self.model_name = 'alexnet'\n\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), 256 * 6 * 6)\n        x = self.classifier(x)\n        return x\n"""
models/BasicModule.py,0,"b""#coding:utf8\nimport torch as t\nimport time\n\n\nclass BasicModule(t.nn.Module):\n    '''\n    \xe5\xb0\x81\xe8\xa3\x85\xe4\xba\x86nn.Module,\xe4\xb8\xbb\xe8\xa6\x81\xe6\x98\xaf\xe6\x8f\x90\xe4\xbe\x9b\xe4\xba\x86save\xe5\x92\x8cload\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x96\xb9\xe6\xb3\x95\n    '''\n\n    def __init__(self):\n        super(BasicModule,self).__init__()\n        self.model_name=str(type(self))# \xe9\xbb\x98\xe8\xae\xa4\xe5\x90\x8d\xe5\xad\x97\n\n    def load(self, path):\n        '''\n        \xe5\x8f\xaf\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x8c\x87\xe5\xae\x9a\xe8\xb7\xaf\xe5\xbe\x84\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\n        '''\n        self.load_state_dict(t.load(path))\n\n    def save(self, name=None):\n        '''\n        \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe9\xbb\x98\xe8\xae\xa4\xe4\xbd\xbf\xe7\x94\xa8\xe2\x80\x9c\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x90\x8d\xe5\xad\x97+\xe6\x97\xb6\xe9\x97\xb4\xe2\x80\x9d\xe4\xbd\x9c\xe4\xb8\xba\xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\n        '''\n        if name is None:\n            prefix = 'checkpoints/' + self.model_name + '_'\n            name = time.strftime(prefix + '%m%d_%H:%M:%S.pth')\n        t.save(self.state_dict(), name)\n        return name\n\n\nclass Flat(t.nn.Module):\n    '''\n    \xe6\x8a\x8a\xe8\xbe\x93\xe5\x85\xa5reshape\xe6\x88\x90\xef\xbc\x88batch_size,dim_length\xef\xbc\x89\n    '''\n\n    def __init__(self):\n        super(Flat, self).__init__()\n        #self.size = size\n\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n"""
models/ResNet34.py,1,"b""#coding:utf8\nfrom .BasicModule import BasicModule\nfrom torch import nn\nfrom torch.nn import functional as F\n\nclass ResidualBlock(nn.Module):\n    '''\n    \xe5\xae\x9e\xe7\x8e\xb0\xe5\xad\x90module: Residual Block\n    '''\n    def __init__(self, inchannel, outchannel, stride=1, shortcut=None):\n        super(ResidualBlock, self).__init__()\n        self.left = nn.Sequential(\n                nn.Conv2d(inchannel, outchannel, 3, stride, 1, bias=False),\n                nn.BatchNorm2d(outchannel),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(outchannel, outchannel, 3, 1, 1, bias=False),\n                nn.BatchNorm2d(outchannel) )\n        self.right = shortcut\n\n    def forward(self, x):\n        out = self.left(x)\n        residual = x if self.right is None else self.right(x)\n        out += residual\n        return F.relu(out)\n\nclass ResNet34(BasicModule):\n    '''\n    \xe5\xae\x9e\xe7\x8e\xb0\xe4\xb8\xbbmodule\xef\xbc\x9aResNet34\n    ResNet34\xe5\x8c\x85\xe5\x90\xab\xe5\xa4\x9a\xe4\xb8\xaalayer\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\xaalayer\xe5\x8f\x88\xe5\x8c\x85\xe5\x90\xab\xe5\xa4\x9a\xe4\xb8\xaaResidual block\n    \xe7\x94\xa8\xe5\xad\x90module\xe6\x9d\xa5\xe5\xae\x9e\xe7\x8e\xb0Residual block\xef\xbc\x8c\xe7\x94\xa8_make_layer\xe5\x87\xbd\xe6\x95\xb0\xe6\x9d\xa5\xe5\xae\x9e\xe7\x8e\xb0layer\n    '''\n    def __init__(self, num_classes=2):\n        super(ResNet34, self).__init__()\n        self.model_name = 'resnet34'\n\n        # \xe5\x89\x8d\xe5\x87\xa0\xe5\xb1\x82: \xe5\x9b\xbe\xe5\x83\x8f\xe8\xbd\xac\xe6\x8d\xa2\n        self.pre = nn.Sequential(\n                nn.Conv2d(3, 64, 7, 2, 3, bias=False),\n                nn.BatchNorm2d(64),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(3, 2, 1))\n        \n        # \xe9\x87\x8d\xe5\xa4\x8d\xe7\x9a\x84layer\xef\xbc\x8c\xe5\x88\x86\xe5\x88\xab\xe6\x9c\x893\xef\xbc\x8c4\xef\xbc\x8c6\xef\xbc\x8c3\xe4\xb8\xaaresidual block\n        self.layer1 = self._make_layer( 64, 128, 3)\n        self.layer2 = self._make_layer( 128, 256, 4, stride=2)\n        self.layer3 = self._make_layer( 256, 512, 6, stride=2)\n        self.layer4 = self._make_layer( 512, 512, 3, stride=2)\n\n        #\xe5\x88\x86\xe7\xb1\xbb\xe7\x94\xa8\xe7\x9a\x84\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\n        self.fc = nn.Linear(512, num_classes)\n    \n    def _make_layer(self,  inchannel, outchannel, block_num, stride=1):\n        '''\n        \xe6\x9e\x84\xe5\xbb\xbalayer,\xe5\x8c\x85\xe5\x90\xab\xe5\xa4\x9a\xe4\xb8\xaaresidual block\n        '''\n        shortcut = nn.Sequential(\n                nn.Conv2d(inchannel,outchannel,1,stride, bias=False),\n                nn.BatchNorm2d(outchannel))\n        \n        layers = []\n        layers.append(ResidualBlock(inchannel, outchannel, stride, shortcut))\n        \n        for i in range(1, block_num):\n            layers.append(ResidualBlock(outchannel, outchannel))\n        return nn.Sequential(*layers)\n        \n    def forward(self, x):\n        x = self.pre(x)\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = F.avg_pool2d(x, 7)\n        x = x.view(x.size(0), -1)\n        return self.fc(x)"""
models/__init__.py,0,b'from .AlexNet import AlexNet\nfrom .ResNet34 import ResNet34\n# from torchvision.models import InceptinV3\n# from torchvision.models import alexnet as AlexNet'
utils/__init__.py,0,b'from .visualize import Visualizer'
utils/visualize.py,0,"b""#coding:utf8\nimport visdom\nimport time\nimport numpy as np\n\nclass Visualizer(object):\n    '''\n    \xe5\xb0\x81\xe8\xa3\x85\xe4\xba\x86visdom\xe7\x9a\x84\xe5\x9f\xba\xe6\x9c\xac\xe6\x93\x8d\xe4\xbd\x9c\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe4\xbd\xa0\xe4\xbb\x8d\xe7\x84\xb6\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x80\x9a\xe8\xbf\x87`self.vis.function`\n    \xe8\xb0\x83\xe7\x94\xa8\xe5\x8e\x9f\xe7\x94\x9f\xe7\x9a\x84visdom\xe6\x8e\xa5\xe5\x8f\xa3\n    '''\n\n    def __init__(self, env='default', **kwargs):\n        self.vis = visdom.Visdom(env=env, **kwargs)\n        \n        # \xe7\x94\xbb\xe7\x9a\x84\xe7\xac\xac\xe5\x87\xa0\xe4\xb8\xaa\xe6\x95\xb0\xef\xbc\x8c\xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8e\xe6\xa8\xaa\xe5\xba\xa7\xe6\xa0\x87\n        # \xe4\xbf\x9d\xe5\xad\x98\xef\xbc\x88\xe2\x80\x99loss',23\xef\xbc\x89 \xe5\x8d\xb3loss\xe7\x9a\x84\xe7\xac\xac23\xe4\xb8\xaa\xe7\x82\xb9\n        self.index = {} \n        self.log_text = ''\n    def reinit(self,env='default',**kwargs):\n        '''\n        \xe4\xbf\xae\xe6\x94\xb9visdom\xe7\x9a\x84\xe9\x85\x8d\xe7\xbd\xae\n        '''\n        self.vis = visdom.Visdom(env=env,**kwargs)\n        return self\n\n    def plot_many(self, d):\n        '''\n        \xe4\xb8\x80\xe6\xac\xa1plot\xe5\xa4\x9a\xe4\xb8\xaa\n        @params d: dict (name,value) i.e. ('loss',0.11)\n        '''\n        for k, v in d.iteritems():\n            self.plot(k, v)\n\n    def img_many(self, d):\n        for k, v in d.iteritems():\n            self.img(k, v)\n\n    def plot(self, name, y,**kwargs):\n        '''\n        self.plot('loss',1.00)\n        '''\n        x = self.index.get(name, 0)\n        self.vis.line(Y=np.array([y]), X=np.array([x]),\n                      win=unicode(name),\n                      opts=dict(title=name),\n                      update=None if x == 0 else 'append',\n                      **kwargs\n                      )\n        self.index[name] = x + 1\n\n    def img(self, name, img_,**kwargs):\n        '''\n        self.img('input_img',t.Tensor(64,64))\n        self.img('input_imgs',t.Tensor(3,64,64))\n        self.img('input_imgs',t.Tensor(100,1,64,64))\n        self.img('input_imgs',t.Tensor(100,3,64,64),nrows=10)\n\n        \xef\xbc\x81\xef\xbc\x81\xef\xbc\x81don\xe2\x80\x98t ~~self.img('input_imgs',t.Tensor(100,64,64),nrows=10)~~\xef\xbc\x81\xef\xbc\x81\xef\xbc\x81\n        '''\n        self.vis.images(img_.cpu().numpy(),\n                       win=unicode(name),\n                       opts=dict(title=name),\n                       **kwargs\n                       )\n\n\n    def log(self,info,win='log_text'):\n        '''\n        self.log({'loss':1,'lr':0.0001})\n        '''\n\n        self.log_text += ('[{time}] {info} <br>'.format(\n                            time=time.strftime('%m%d_%H%M%S'),\\\n                            info=info)) \n        self.vis.text(self.log_text,win)   \n\n    def __getattr__(self, name):\n        return getattr(self.vis, name)\n\n"""
