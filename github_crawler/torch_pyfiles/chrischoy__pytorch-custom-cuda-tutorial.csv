file_path,api_count,code
__init__.py,3,"b'import numpy as np\nimport unittest\n\nimport torch\nfrom torch.autograd import Function, Variable\nimport mathutils\n\n\nclass BroadcastAccum(Function):\n  """"""Accumulate x += y using broadcasting sum.\n  """"""\n  def forward(self, x, y):\n    mathutils.broadcast_sum(x, y, *map(int, x.size()))\n    return x\n\n\nclass TestBroadcastAccum(unittest.TestCase):\n\n  def test_broadcast_accum(self):\n    N, M = 3, 5\n    x = torch.rand(N, M).cuda()\n    y = torch.rand(N, 1).cuda()\n\n    x_np = x.cpu().numpy()\n    y_np = y.cpu().numpy()\n\n    x_np += y_np\n\n    x = BroadcastAccum()(Variable(x), Variable(y))\n    self.assertTrue(np.allclose(x_np, x.data.cpu().numpy()))\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
build_ffi.py,2,"b""# https://gist.github.com/tonyseek/7821993\nimport glob\nimport torch\nfrom os import path as osp\nfrom torch.utils.ffi import create_extension\n\nabs_path = osp.dirname(osp.realpath(__file__))\nextra_objects = [osp.join(abs_path, 'build/mathutil_cuda_kernel.so')]\nextra_objects += glob.glob('/usr/local/cuda/lib64/*.a')\n\nffi = create_extension(\n    'mathutils',\n    headers=['include/mathutil_cuda.h'],\n    sources=['src/mathutil_cuda.c'],\n    define_macros=[('WITH_CUDA', None)],\n    relative_to=__file__,\n    with_cuda=True,\n    extra_objects=extra_objects,\n    include_dirs=[osp.join(abs_path, 'include')]\n)\n\n\nif __name__ == '__main__':\n    assert torch.cuda.is_available(), 'Please install CUDA for GPU support.'\n    ffi.build()\n"""
