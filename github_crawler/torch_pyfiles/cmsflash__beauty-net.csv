file_path,api_count,code
setup.py,0,"b""from setuptools import setup, find_packages\n\n\nsetup(\n    name='beauty-net',\n    version='0.1.0',\n    author='Shen Zhuoran',\n    author_email='cmsflash99@gmail.com',\n    install_requires=['torch', 'torchvision'],\n    packages=find_packages()\n)\n"""
train.py,0,"b""from os import path as osp\nfrom argparse import Namespace\nimport sys\n\nfrom torch import nn, optim\nfrom torchvision import transforms\n\nfrom beauty import Task, networks, metrics, lr_schedulers, datasets\n\n\nif __name__ == '__main__':\n    gpus = int(sys.argv[1])\n    task_name = sys.argv[2]\n\n    config = Namespace(\n        data=Namespace(\n            train=Namespace(\n                dataset=datasets.ImageNet,\n                config=Namespace(\n                    data_dir=(\n                        '/mnt/lustre/share/images/train/'\n                    ),\n                    data_list_path=(\n                        '/mnt/lustre/share/images/meta/train.txt'\n                    ),\n                    transforms=[\n                        Namespace(\n                            transform=datasets.transforms.ToColor,\n                            config=Namespace()\n                        ),\n                        Namespace(\n                            transform=transforms.Resize,\n                            config=Namespace(size=(320, 320))\n                        ),\n                        Namespace(\n                            transform=transforms.ToTensor,\n                            config=Namespace()\n                        )\n                    ]\n                ),\n                batch_size=gpus * 32\n            ),\n            val=Namespace(\n                dataset=datasets.ImageNet,\n                config=Namespace(\n                    data_dir=(\n                        '/mnt/lustre/share/images/val/'\n                    ),\n                    data_list_path=(\n                        '/mnt/lustre/share/images/meta/val.txt'\n                    ),\n                    transforms=[\n                        Namespace(\n                            transform=datasets.transforms.ToColor,\n                            config=Namespace()\n                        ),\n                        Namespace(\n                            transform=transforms.Resize,\n                            config=Namespace(size=(320, 320))\n                        ),\n                        Namespace(\n                            transform=transforms.ToTensor,\n                            config=Namespace()\n                        )\n                    ]\n                ),\n                batch_size=gpus * 32\n            )\n        ),\n        model=Namespace(\n            network=networks.BeautyNet,\n            feature_extractor=networks.feature_extractors.ResNet50,\n            classifier=networks.classifiers.SoftmaxClassifier,\n            class_count=1000,\n            weight_decay=5e-4,\n            loss=nn.CrossEntropyLoss\n        ),\n        training=Namespace(\n            epochs=1000\n        ),\n        optimizer=Namespace(\n            optimizer=optim.Adam,\n            config=Namespace(\n                betas=(0.9, 0.99)\n            )\n        ),\n        lr=Namespace(\n            lr=1e-3,\n            lr_scheduler=lr_schedulers.ConstantLr,\n            config=Namespace()\n        ),\n        log=Namespace(\n            dir=osp.join('logs', task_name),\n            interval=1,\n            metrics=[metrics.Accuracy]\n        )\n\n    )\n\n    task = Task(task_name, config)\n    task.train()\n"""
beauty/__init__.py,0,b'from .task import Task\n'
beauty/data_loaders.py,1,"b""from argparse import Namespace\n\nfrom torch.utils.data import DataLoader\n\n\nTRAIN_CONFIG = Namespace(split_name='Training', shuffle=True, drop_last=True)\nVAL_CONFIG = Namespace(split_name='Validation', shuffle=False, drop_last=False)\n\n\ndef create_data_loader(input_config, loader_config, pin_memory=True):\n    dataset = input_config.dataset(input_config.config)\n    print(f'{loader_config.split_name} set: {len(dataset)} examples')\n    data_loader = DataLoader(\n        dataset,\n        input_config.batch_size,\n        shuffle=loader_config.shuffle,\n        num_workers=8,\n        pin_memory=pin_memory,\n        drop_last=loader_config.drop_last\n    )\n    return data_loader\n"""
beauty/task.py,1,"b'import time\n\nimport torch\n\nfrom . import networks, metrics, data_loaders, utils\n\n\nclass Task:\n    tags = {True: \'training\', False: \'validation\'}\n\n    def __init__(self, name, config):\n        self.name = name\n        self.config = config\n        self.epoch = -1\n        self.iteration = -1\n        self.training = True\n        self.device = utils.tensor_utils.get_device()\n\n        self.loaders = {\n            True: data_loaders.create_data_loader(\n                config.data.train, data_loaders.TRAIN_CONFIG\n            ),\n            False: data_loaders.create_data_loader(\n                config.data.val, data_loaders.VAL_CONFIG, pin_memory=False\n            )\n        }\n        self.model = networks.create_model(config.model, self.device)\n        self.loss = config.model.loss()\n        self.metrics = metrics.create_metric_bundle(config.log.metrics)\n        self.meters = utils.meters.ModelMeters(self.metrics)\n        self.optimizer = config.optimizer.optimizer(\n            self.model.parameters(), config.lr.lr,\n            **vars(config.optimizer.config)\n        )\n        self.scheduler = config.lr.lr_scheduler(\n            self.optimizer, **vars(config.lr.config)\n        )\n        self.best_meters = self.metrics.create_max_meters()\n\n    def train(self):\n        start_epoch = self.epoch + 1\n        for epoch in range(start_epoch, self.config.training.epochs):\n            self.epoch = epoch\n            self._run_epoch(training=True)\n            metric_meters = self._run_epoch(training=False)\n            self._log_training(metric_meters)\n\n    def resume(self, checkpoint_path, refresh=True, partial=False):\n        checkpoint = torch.load(checkpoint_path)\n        if partial:\n            model_state_dict = self.model.state_dict()\n            model_state_dict.update(checkpoint[\'model\'])\n        else:\n            model_state_dict = checkpoint[\'model\']\n        self.model.load_state_dict(model_state_dict)\n        if not refresh:\n            self.epoch = checkpoint[\'epoch\']\n            self.optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(f\'Training resumed at epoch {self.epoch}\')\n        print(f\'Best metrics: {checkpoint[""best_meters""]}\')\n\n    def set_training(self, training):\n        self.training = training\n        self.model.train(self.training)\n\n    def _run_epoch(self, training=None):\n        if training is not None:\n            self.set_training(training)\n        self._epoch_step()\n        self.meters.reset()\n        loader = self.loaders[self.training]\n        start_time = time.time()\n        for data in loader:\n            self._iterate(data, start_time)\n            start_time = time.time()\n        return self.meters.metric_meters\n\n    def _epoch_step(self):\n        self.iteration = -1\n        self.scheduler.step()\n\n    def _iterate(self, data, start_time):\n        self.iteration += 1\n        _, input_, target = self._parse_data(data)\n        loss, metric_bundle = self._forward(input_, target)\n        self._step(loss)\n        iteration_time = time.time() - start_time\n        self.meters.update(\n            iteration_time, loss, metric_bundle, batch_size=input_.size(0)\n        )\n        self._print_stats()\n\n    def _parse_data(self, data):\n        index, input_, target = data\n        input_ = input_.to(self.device)\n        target = target.to(self.device)\n        return index, input_, target\n\n    def _forward(self, input_, target):\n        output = self.model(input_)\n        loss = self.loss(output, target)\n        metric_bundle = self.metrics(output, target)\n        return loss, metric_bundle\n\n    def _step(self, loss):\n        if self.training:\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n\n    def _print_stats(self):\n        print(f\'{self._get_header()}\\t{self.meters}\')\n\n    def _get_header(self):\n        header = (\n            f\'Epoch {self.epoch} {self.tags[self.training]}\'\n            f\' {self.iteration}/{len(self.loaders[self.training])}:\'\n        )\n        return header\n\n    def _log_training(self, metric_meters):\n        self.best_meters.update(metric_meters)\n        print(f\'\\n * Finished epoch {self.epoch}:\\t{self.best_meters}\\n\\n\')\n        checkpoint = {\n            \'epoch\': self.epoch + 1,\n            \'model\': self.model.state_dict(),\n            \'optimizer\': self.optimizer.state_dict(),\n            \'best_meters\': self.best_meters\n        }\n        utils.serialization.save(checkpoint, self.config.log)\n'"
beauty/datasets/__init__.py,0,b'from .image_net import ImageNet\n\n'
beauty/datasets/image_net.py,1,"b'import os.path as osp\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data import Dataset\n\nfrom . import transforms\n\n\nclass ImageNet(Dataset):\n    def __init__(self, data_config):\n        super().__init__()\n        self.transform = transforms.create_transform(data_config.transforms)\n        self.data_list = self._read_data_list(\n            data_config.data_dir, data_config.data_list_path\n        )\n\n    @classmethod\n    def _read_data_list(cls, data_dir, data_list_path):\n        data_list = []\n        with open(data_list_path) as data_list_file:\n            for line in data_list_file:\n                image_name, class_ = line.split()\n                image_path = osp.join(data_dir, image_name)\n                class_ = int(class_)\n                data_list.append((image_path, class_))\n        return data_list\n\n    def __len__(self):\n        return len(self.data_list)\n\n    def __getitem__(self, index):\n        image, class_ = self._read_example(index)\n        image = self.transform(image)\n        return index, image, class_\n\n    def _read_example(self, index):\n        image_path, class_ = self.data_list[index]\n        image = Image.open(image_path)\n        return image, class_\n\n'"
beauty/datasets/transforms.py,0,"b""import torchvision\n\n\ndef create_transform(transforms):\n    transform = torchvision.transforms.Compose([\n        transform.transform(**vars(transform.config))\n        for transform in transforms\n    ])\n    return transform\n\n\nclass ToColor:\n\n    def __call__(self, image):\n        color_image = image.convert('RGB')\n        return color_image\n\n"""
beauty/lr_schedulers/__init__.py,0,b'from .constant_lr import ConstantLr\n'
beauty/lr_schedulers/constant_lr.py,1,"b'from torch.optim.lr_scheduler import LambdaLR\n\n\nclass ConstantLr(LambdaLR):\n    def __init__(self, optimizer, last_epoch=-1):\n        super().__init__(optimizer, lambda x: 1, last_epoch)\n'"
beauty/metrics/__init__.py,0,b'from .accuracy import Accuracy\nfrom .metric_bundle import MetricBundle\n\n\ndef create_metric_bundle(metrics):\n    metric_bundle = MetricBundle([metric() for metric in metrics])\n    return metric_bundle\n'
beauty/metrics/accuracy.py,0,"b""from torch import nn\n\n\nclass Accuracy(nn.Module):\n    label = 'Accuracy'\n\n    def forward(self, prediction, truth):\n        prediction = prediction.argmax(dim=1)\n        correct = prediction == truth\n        accuracy = correct.float().mean()\n        return accuracy\n"""
beauty/metrics/metric_bundle.py,0,"b'from torch import nn\n\nfrom ..utils import meters\n\n\nclass MetricBundle(nn.Module):\n    def __init__(self, metrics):\n        super().__init__()\n        self.metrics = {metric.label: metric for metric in metrics}\n\n    def forward(self, prediction, truth):\n        metric_values = meters.MeterBundle([\n            meters.Meter(label, metric(prediction, truth))\n            for label, metric in self.metrics.items()\n        ])\n        return metric_values\n\n    def create_max_meters(self):\n        metric_values = self._create_meters(meters.MaxMeter)\n        return metric_values\n\n    def create_average_meters(self):\n        metric_values = self._create_meters(meters.AverageMeter)\n        return metric_values\n\n    def _create_meters(self, meter_type):\n        metric_values = meters.MeterBundle([\n            meter_type(label, 0) for label, metric in self.metrics.items()\n        ])\n        return metric_values\n'"
beauty/networks/__init__.py,0,"b'from torch import nn\n\nfrom . import feature_extractors, classifiers\nfrom .networks import BeautyNet\n\n\ndef create_model(model_config, device):\n    feature_extractor = model_config.feature_extractor()\n    classifier = model_config.classifier(\n        feature_extractor.feature_channels, model_config.class_count\n    )\n    model = model_config.network(feature_extractor, classifier)\n    model = nn.DataParallel(model).to(device)\n    return model\n'"
beauty/networks/classifiers.py,1,"b'from torch import nn\nfrom torch.nn import functional as f\n\nfrom . import weight_init\n\n\nclass SoftmaxClassifier(nn.Module):\n    def __init__(self, input_channels, output_channels):\n        super().__init__()\n        self.linear = nn.Linear(input_channels, output_channels)\n        weight_init.init(self.modules())\n\n    def forward(self, input_):\n        linear = self.linear(input_)\n        softmax = f.softmax(linear, dim=1)\n        return softmax\n'"
beauty/networks/networks.py,2,"b'import torch\nfrom torch import nn\nfrom torch.nn import functional as f\n\n\nclass BeautyNet(nn.Module):\n    def __init__(self, feature_extractor, classifier):\n        super().__init__()\n\n        self.feature_extractor = feature_extractor\n        self.classifier = classifier\n\n    def forward(self, input_):\n        feature = self.feature_extractor(input_)\n        global_pool = f.adaptive_avg_pool2d(feature, 1)\n        feature_vector = torch.squeeze(torch.squeeze(global_pool, dim=3), dim=2)\n        classification = self.classifier(feature_vector)\n        return classification\n'"
beauty/networks/submodules.py,0,"b""from torch import nn\n\n\ndef get_perfect_padding(kernel_size, dilation=1):\n    padding = (kernel_size - 1) * dilation // 2\n    return padding\n\n\ndef sequential(*modules):\n    '''\n    Returns an nn.Sequential object using modules with None's filtered\n    '''\n    modules = [module for module in modules if module is not None]\n    return nn.Sequential(*modules)\n\n\ndef identity():\n    return sequential()\n\n\ndef default_activation():\n    activation = nn.ReLU6(inplace=True)\n    return activation\n\n\nclass InvertedResidual(nn.Module):\n    def __init__(self, in_channels, out_channels, expansion, stride):\n        super().__init__()\n        self.stride = stride\n        self.is_residual = self.stride == 1 and in_channels == out_channels\n        channels = in_channels * expansion\n\n        self.bottlebody = sequential(\n            conv(in_channels, channels, 1, activation=default_activation()),\n            conv(\n                channels, channels, 3, self.stride, groups=channels,\n                activation=default_activation()\n            ),\n            conv(channels, out_channels, 1, activation=None)\n        )\n\n    def forward(self, input_):\n        bottlebody = self.bottlebody(input_)\n        output = bottlebody + input_ if self.is_residual else bottlebody\n        return output\n\n\ndef inverted_residuals(\n        in_channels, out_channels, expansion=6, stride=1, blocks=1\n    ):\n    residual_list = [\n        InvertedResidual(in_channels, out_channels, expansion, stride)\n    ] + [\n        InvertedResidual(out_channels, out_channels, expansion, 1)\n        for _ in range(blocks - 1)\n    ]\n    residuals = sequential(*residual_list)\n    return residuals\n\n\ndef conv(\n        in_channels, out_channels, kernel_size=3,\n        stride=1, padding=None, dilation=1, groups=1,\n        normalization=nn.BatchNorm2d, activation=default_activation()\n    ):\n    padding = padding or get_perfect_padding(kernel_size, dilation)\n    layer = sequential(\n        nn.Conv2d(\n            in_channels, out_channels, kernel_size,\n            stride, padding, dilation, groups, bias=False\n        ),\n        normalization(out_channels),\n        activation\n    )\n    return layer\n"""
beauty/networks/weight_init.py,0,"b'from torch import nn\n\n\ndef init(modules):\n    for module in modules:\n        if isinstance(module, nn.Conv2d):\n            nn.init.xavier_normal_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.BatchNorm2d):\n            nn.init.ones_(module.weight)\n            nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.uniform_(module.bias)\n\n'"
beauty/utils/__init__.py,0,"b'from . import meters, os_utils, serialization, tensor_utils\n'"
beauty/utils/meters.py,0,"b""class Meter:\n    def __init__(self, label='Default', initial=None):\n        self.label = label\n        self.initial = initial\n        self.value = None\n        self.measure = None\n        self.count = None\n        self.reset()\n\n    def reset(self):\n        self.value = self.initial or 0.\n        self.measure = self.initial or 0.\n        self.count = 0 if self.initial is None else 1\n\n    def update(self, value, multiplicity=1):\n        self.value = value\n        self.count += multiplicity\n\n    def __str__(self):\n        string = f'{self.label}: {self.value:5.3} ({self.measure:5.3})'\n        return string\n\n\nclass AverageMeter(Meter):\n    def update(self, value, multiplicity=1):\n        super().update(value, multiplicity)\n        self.measure = (\n            (self.measure * (self.count - multiplicity) + value * multiplicity)\n            / self.count\n        )\n\n\nclass MaxMeter(Meter):\n    def __init__(self, label='Default', initial=None):\n        self.latest = None\n        super().__init__(label, initial)\n\n    def reset(self):\n        super().reset()\n        self.latest = False\n\n    def update(self, value, multiplicity=1):\n        super().update(value, multiplicity)\n        if value > self.measure:\n            self.measure = value\n            self.latest = True\n        else:\n            self.latest = False\n\n    def __str__(self):\n        marker = '*' if self.latest else ''\n        string = f'{super().__str__()}{marker}'\n        return string\n\n\nclass MeterBundle:\n    def __init__(self, meters):\n        self.meters = {meter.label: meter for meter in meters}\n\n    def reset(self):\n        for meter in self.meters.values():\n            meter.reset()\n\n    def update(self, other_bundle):\n        assert self.meters.keys() == other_bundle.meters.keys()\n        for label in self.meters.keys():\n            other_meter = other_bundle.meters[label]\n            self.meters[label].update(other_meter.measure, other_meter.count)\n\n    def __add__(self, other_bundle):\n        assert self.meters.keys().isdisjoint(other_bundle.meters.keys())\n        bundle = MeterBundle(\n            self.meters.values() + other_bundle.meters.values()\n        )\n        return bundle\n\n    def __str__(self):\n        string = '\\t'.join([str(meter) for meter in self.meters.values()])\n        return string\n\n\nclass ModelMeters:\n    def __init__(self, metrics):\n        self.time_meter = AverageMeter('Time')\n        self.loss_meter = AverageMeter('Loss')\n        self.metric_meters = metrics.create_average_meters()\n\n    def reset(self):\n        self.time_meter.reset()\n        self.loss_meter.reset()\n        self.metric_meters.reset()\n\n    def update(self, time, loss, metric_bundle, batch_size=1):\n        self.time_meter.update(time)\n        self.loss_meter.update(loss.item(), batch_size)\n        self.metric_meters.update(metric_bundle)\n\n    def __str__(self):\n        string = f'{self.time_meter}\\t{self.loss_meter}\\t{self.metric_meters}'\n        return string\n"""
beauty/utils/os_utils.py,0,b'import os\nfrom os import path as osp\nimport shutil\n\n\ndef make_dir_if_missing(dir_):\n    if not osp.exists(dir_):\n        os.makedirs(dir_)\n\n\ndef remove_if_exists(path):\n    if osp.exists(path):\n        shutil.rmtree(path)\n'
beauty/utils/serialization.py,1,"b""from os import path as osp\nimport shutil\n\nimport torch\n\nfrom . import os_utils\n\n\ndef save(checkpoint, log_config):\n    os_utils.make_dir_if_missing(log_config.dir)\n    checkpoint_path = osp.join(log_config.dir, 'checkpoint.pth')\n    torch.save(checkpoint, checkpoint_path)\n    are_best = {\n        label: meter.latest\n        for label, meter in checkpoint['best_meters'].meters.items()\n    }\n    for metric_name, is_best in are_best.items():\n        if is_best:\n            shutil.copy(checkpoint_path, osp.join(\n                log_config.dir, f'best_{metric_name}.pth'\n            ))\n    epoch = checkpoint['epoch']\n    if epoch % log_config.interval == 0:\n        shutil.copy(\n            checkpoint_path, osp.join(log_config.dir, f'epoch{epoch - 1}.pth')\n        )\n"""
beauty/utils/tensor_utils.py,3,"b""import torch\n\n\ndef get_device():\n    if torch.cuda.is_available():\n        device = torch.device('cuda')\n    else:\n        device = torch.device('cpu')\n    return device\n"""
beauty/networks/feature_extractors/__init__.py,0,b'from .mobile_net_v2 import MobileNetV2\r\nfrom .res_net import ResNet50\r\n\r\n'
beauty/networks/feature_extractors/_feature_extractor.py,0,"b'from torch import nn\r\n\r\n\r\nclass _FeatureExtractor(nn.Module):\r\n    def __init__(self, feature_channels):\r\n        super().__init__()\r\n        self.feature_channels = feature_channels\r\n'"
beauty/networks/feature_extractors/mobile_net_v2.py,0,"b'from ._feature_extractor import _FeatureExtractor\r\nfrom .. import submodules, weight_init\r\n\r\n\r\nclass MobileNetV2(_FeatureExtractor):\r\n    def __init__(self, feature_channels=1280):\r\n        super().__init__(feature_channels)\r\n\r\n        self.initial = submodules.conv(3, 32, stride=2)\r\n        self.block1 = submodules.inverted_residuals(32, 16, expansion=1)\r\n        self.block2 = submodules.inverted_residuals(16, 24, stride=2, blocks=2)\r\n        self.block3 = submodules.inverted_residuals(24, 32, stride=2, blocks=3)\r\n        self.block4a = submodules.inverted_residuals(32, 64, stride=2, blocks=4)\r\n        self.block4b = submodules.inverted_residuals(64, 96, blocks=3)\r\n        self.block5a = submodules.inverted_residuals(\r\n            96, 160, stride=2, blocks=3\r\n        )\r\n        self.block5b = submodules.inverted_residuals(160, 320)\r\n        self.final = submodules.conv(320, self.feature_channels, 1)\r\n\r\n        weight_init.init(self.modules())\r\n\r\n    def forward(self, input_):\r\n        initial = self.initial(input_)\r\n        block1 = self.block1(initial)\r\n        block2 = self.block2(block1)\r\n        block3 = self.block3(block2)\r\n        block4a = self.block4a(block3)\r\n        block4b = self.block4b(block4a)\r\n        block5a = self.block5a(block4b)\r\n        block5b = self.block5b(block5a)\r\n        final = self.final(block5b)\r\n        return final\r\n\r\n'"
beauty/networks/feature_extractors/res_net.py,0,"b'from torchvision.models import resnet\r\n\r\nfrom ._feature_extractor import _FeatureExtractor\r\nfrom .. import submodules, weight_init\r\n\r\n\r\nclass ResNet50(_FeatureExtractor):\r\n\r\n    def __init__(self, feature_channels=2048):\r\n        super().__init__(feature_channels)\r\n\r\n        self.res_net = resnet.resnet50()\r\n        self.res_net.avgpool = submodules.identity()\r\n        self.res_net.fc = submodules.identity()\r\n\r\n        weight_init.init(self.modules())\r\n\r\n    def forward(self, input_):\r\n        \r\n        n, _, h, w = input_.size()\r\n        vectorized_output = self.res_net(input_)\r\n        output = vectorized_output.view(n, 2048, h // 32, w // 32)\r\n        return output\r\n\r\n'"
