file_path,api_count,code
main.py,0,"b'""""""Main script for ADDA.""""""\n\nimport params\nfrom core import eval_src, eval_tgt, train_src, train_tgt\nfrom models import Discriminator, LeNetClassifier, LeNetEncoder\nfrom utils import get_data_loader, init_model, init_random_seed\n\nif __name__ == \'__main__\':\n    # init random seed\n    init_random_seed(params.manual_seed)\n\n    # load dataset\n    src_data_loader = get_data_loader(params.src_dataset)\n    src_data_loader_eval = get_data_loader(params.src_dataset, train=False)\n    tgt_data_loader = get_data_loader(params.tgt_dataset)\n    tgt_data_loader_eval = get_data_loader(params.tgt_dataset, train=False)\n\n    # load models\n    src_encoder = init_model(net=LeNetEncoder(),\n                             restore=params.src_encoder_restore)\n    src_classifier = init_model(net=LeNetClassifier(),\n                                restore=params.src_classifier_restore)\n    tgt_encoder = init_model(net=LeNetEncoder(),\n                             restore=params.tgt_encoder_restore)\n    critic = init_model(Discriminator(input_dims=params.d_input_dims,\n                                      hidden_dims=params.d_hidden_dims,\n                                      output_dims=params.d_output_dims),\n                        restore=params.d_model_restore)\n\n    # train source model\n    print(""=== Training classifier for source domain ==="")\n    print("">>> Source Encoder <<<"")\n    print(src_encoder)\n    print("">>> Source Classifier <<<"")\n    print(src_classifier)\n\n    if not (src_encoder.restored and src_classifier.restored and\n            params.src_model_trained):\n        src_encoder, src_classifier = train_src(\n            src_encoder, src_classifier, src_data_loader)\n\n    # eval source model\n    print(""=== Evaluating classifier for source domain ==="")\n    eval_src(src_encoder, src_classifier, src_data_loader_eval)\n\n    # train target encoder by GAN\n    print(""=== Training encoder for target domain ==="")\n    print("">>> Target Encoder <<<"")\n    print(tgt_encoder)\n    print("">>> Critic <<<"")\n    print(critic)\n\n    # init weights of target encoder with those of source encoder\n    if not tgt_encoder.restored:\n        tgt_encoder.load_state_dict(src_encoder.state_dict())\n\n    if not (tgt_encoder.restored and critic.restored and\n            params.tgt_model_trained):\n        tgt_encoder = train_tgt(src_encoder, tgt_encoder, critic,\n                                src_data_loader, tgt_data_loader)\n\n    # eval target encoder on test set of target dataset\n    print(""=== Evaluating classifier for encoded target domain ==="")\n    print("">>> source only <<<"")\n    eval_tgt(src_encoder, src_classifier, tgt_data_loader_eval)\n    print("">>> domain adaption <<<"")\n    eval_tgt(tgt_encoder, src_classifier, tgt_data_loader_eval)\n'"
params.py,0,"b'""""""Params for ADDA.""""""\n\n# params for dataset and data loader\ndata_root = ""data""\ndataset_mean_value = 0.5\ndataset_std_value = 0.5\ndataset_mean = (dataset_mean_value, dataset_mean_value, dataset_mean_value)\ndataset_std = (dataset_std_value, dataset_std_value, dataset_std_value)\nbatch_size = 50\nimage_size = 64\n\n# params for source dataset\nsrc_dataset = ""MNIST""\nsrc_encoder_restore = ""snapshots/ADDA-source-encoder-final.pt""\nsrc_classifier_restore = ""snapshots/ADDA-source-classifier-final.pt""\nsrc_model_trained = True\n\n# params for target dataset\ntgt_dataset = ""USPS""\ntgt_encoder_restore = ""snapshots/ADDA-target-encoder-final.pt""\ntgt_model_trained = True\n\n# params for setting up models\nmodel_root = ""snapshots""\nd_input_dims = 500\nd_hidden_dims = 500\nd_output_dims = 2\nd_model_restore = ""snapshots/ADDA-critic-final.pt""\n\n# params for training network\nnum_gpu = 1\nnum_epochs_pre = 100\nlog_step_pre = 20\neval_step_pre = 20\nsave_step_pre = 100\nnum_epochs = 2000\nlog_step = 100\nsave_step = 100\nmanual_seed = None\n\n# params for optimizing models\nd_learning_rate = 1e-4\nc_learning_rate = 1e-4\nbeta1 = 0.5\nbeta2 = 0.9\n'"
utils.py,10,"b'""""""Utilities for ADDA.""""""\n\nimport os\nimport random\n\nimport torch\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\n\nimport params\nfrom datasets import get_mnist, get_usps\n\n\ndef make_variable(tensor, volatile=False):\n    """"""Convert Tensor to Variable.""""""\n    if torch.cuda.is_available():\n        tensor = tensor.cuda()\n    return Variable(tensor, volatile=volatile)\n\n\ndef make_cuda(tensor):\n    """"""Use CUDA if it\'s available.""""""\n    if torch.cuda.is_available():\n        tensor = tensor.cuda()\n    return tensor\n\n\ndef denormalize(x, std, mean):\n    """"""Invert normalization, and then convert array into image.""""""\n    out = x * std + mean\n    return out.clamp(0, 1)\n\n\ndef init_weights(layer):\n    """"""Init weights for layers w.r.t. the original paper.""""""\n    layer_name = layer.__class__.__name__\n    if layer_name.find(""Conv"") != -1:\n        layer.weight.data.normal_(0.0, 0.02)\n    elif layer_name.find(""BatchNorm"") != -1:\n        layer.weight.data.normal_(1.0, 0.02)\n        layer.bias.data.fill_(0)\n\n\ndef init_random_seed(manual_seed):\n    """"""Init random seed.""""""\n    seed = None\n    if manual_seed is None:\n        seed = random.randint(1, 10000)\n    else:\n        seed = manual_seed\n    print(""use random seed: {}"".format(seed))\n    random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n\ndef get_data_loader(name, train=True):\n    """"""Get data loader by name.""""""\n    if name == ""MNIST"":\n        return get_mnist(train)\n    elif name == ""USPS"":\n        return get_usps(train)\n\n\ndef init_model(net, restore):\n    """"""Init models with cuda and weights.""""""\n    # init weights of model\n    net.apply(init_weights)\n\n    # restore model weights\n    if restore is not None and os.path.exists(restore):\n        net.load_state_dict(torch.load(restore))\n        net.restored = True\n        print(""Restore model from: {}"".format(os.path.abspath(restore)))\n\n    # check if cuda is available\n    if torch.cuda.is_available():\n        cudnn.benchmark = True\n        net.cuda()\n\n    return net\n\n\ndef save_model(net, filename):\n    """"""Save trained model.""""""\n    if not os.path.exists(params.model_root):\n        os.makedirs(params.model_root)\n    torch.save(net.state_dict(),\n               os.path.join(params.model_root, filename))\n    print(""save pretrained model to: {}"".format(os.path.join(params.model_root,\n                                                             filename)))\n'"
core/__init__.py,0,"b'from .adapt import train_tgt\nfrom .pretrain import eval_src, train_src\nfrom .test import eval_tgt\n\n__all__ = (eval_src, train_src, train_tgt, eval_tgt)\n'"
core/adapt.py,11,"b'""""""Adversarial adaptation to train target encoder.""""""\n\nimport os\n\nimport torch\nimport torch.optim as optim\nfrom torch import nn\n\nimport params\nfrom utils import make_variable\n\n\ndef train_tgt(src_encoder, tgt_encoder, critic,\n              src_data_loader, tgt_data_loader):\n    """"""Train encoder for target domain.""""""\n    ####################\n    # 1. setup network #\n    ####################\n\n    # set train state for Dropout and BN layers\n    tgt_encoder.train()\n    critic.train()\n\n    # setup criterion and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer_tgt = optim.Adam(tgt_encoder.parameters(),\n                               lr=params.c_learning_rate,\n                               betas=(params.beta1, params.beta2))\n    optimizer_critic = optim.Adam(critic.parameters(),\n                                  lr=params.d_learning_rate,\n                                  betas=(params.beta1, params.beta2))\n    len_data_loader = min(len(src_data_loader), len(tgt_data_loader))\n\n    ####################\n    # 2. train network #\n    ####################\n\n    for epoch in range(params.num_epochs):\n        # zip source and target data pair\n        data_zip = enumerate(zip(src_data_loader, tgt_data_loader))\n        for step, ((images_src, _), (images_tgt, _)) in data_zip:\n            ###########################\n            # 2.1 train discriminator #\n            ###########################\n\n            # make images variable\n            images_src = make_variable(images_src)\n            images_tgt = make_variable(images_tgt)\n\n            # zero gradients for optimizer\n            optimizer_critic.zero_grad()\n\n            # extract and concat features\n            feat_src = src_encoder(images_src)\n            feat_tgt = tgt_encoder(images_tgt)\n            feat_concat = torch.cat((feat_src, feat_tgt), 0)\n\n            # predict on discriminator\n            pred_concat = critic(feat_concat.detach())\n\n            # prepare real and fake label\n            label_src = make_variable(torch.ones(feat_src.size(0)).long())\n            label_tgt = make_variable(torch.zeros(feat_tgt.size(0)).long())\n            label_concat = torch.cat((label_src, label_tgt), 0)\n\n            # compute loss for critic\n            loss_critic = criterion(pred_concat, label_concat)\n            loss_critic.backward()\n\n            # optimize critic\n            optimizer_critic.step()\n\n            pred_cls = torch.squeeze(pred_concat.max(1)[1])\n            acc = (pred_cls == label_concat).float().mean()\n\n            ############################\n            # 2.2 train target encoder #\n            ############################\n\n            # zero gradients for optimizer\n            optimizer_critic.zero_grad()\n            optimizer_tgt.zero_grad()\n\n            # extract and target features\n            feat_tgt = tgt_encoder(images_tgt)\n\n            # predict on discriminator\n            pred_tgt = critic(feat_tgt)\n\n            # prepare fake labels\n            label_tgt = make_variable(torch.ones(feat_tgt.size(0)).long())\n\n            # compute loss for target encoder\n            loss_tgt = criterion(pred_tgt, label_tgt)\n            loss_tgt.backward()\n\n            # optimize target encoder\n            optimizer_tgt.step()\n\n            #######################\n            # 2.3 print step info #\n            #######################\n            if ((step + 1) % params.log_step == 0):\n                print(""Epoch [{}/{}] Step [{}/{}]:""\n                      ""d_loss={:.5f} g_loss={:.5f} acc={:.5f}""\n                      .format(epoch + 1,\n                              params.num_epochs,\n                              step + 1,\n                              len_data_loader,\n                              loss_critic.data[0],\n                              loss_tgt.data[0],\n                              acc.data[0]))\n\n        #############################\n        # 2.4 save model parameters #\n        #############################\n        if ((epoch + 1) % params.save_step == 0):\n            torch.save(critic.state_dict(), os.path.join(\n                params.model_root,\n                ""ADDA-critic-{}.pt"".format(epoch + 1)))\n            torch.save(tgt_encoder.state_dict(), os.path.join(\n                params.model_root,\n                ""ADDA-target-encoder-{}.pt"".format(epoch + 1)))\n\n    torch.save(critic.state_dict(), os.path.join(\n        params.model_root,\n        ""ADDA-critic-final.pt""))\n    torch.save(tgt_encoder.state_dict(), os.path.join(\n        params.model_root,\n        ""ADDA-target-encoder-final.pt""))\n    return tgt_encoder\n'"
core/pretrain.py,2,"b'""""""Pre-train encoder and classifier for source dataset.""""""\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport params\nfrom utils import make_variable, save_model\n\n\ndef train_src(encoder, classifier, data_loader):\n    """"""Train classifier for source domain.""""""\n    ####################\n    # 1. setup network #\n    ####################\n\n    # set train state for Dropout and BN layers\n    encoder.train()\n    classifier.train()\n\n    # setup criterion and optimizer\n    optimizer = optim.Adam(\n        list(encoder.parameters()) + list(classifier.parameters()),\n        lr=params.c_learning_rate,\n        betas=(params.beta1, params.beta2))\n    criterion = nn.CrossEntropyLoss()\n\n    ####################\n    # 2. train network #\n    ####################\n\n    for epoch in range(params.num_epochs_pre):\n        for step, (images, labels) in enumerate(data_loader):\n            # make images and labels variable\n            images = make_variable(images)\n            labels = make_variable(labels.squeeze_())\n\n            # zero gradients for optimizer\n            optimizer.zero_grad()\n\n            # compute loss for critic\n            preds = classifier(encoder(images))\n            loss = criterion(preds, labels)\n\n            # optimize source classifier\n            loss.backward()\n            optimizer.step()\n\n            # print step info\n            if ((step + 1) % params.log_step_pre == 0):\n                print(""Epoch [{}/{}] Step [{}/{}]: loss={}""\n                      .format(epoch + 1,\n                              params.num_epochs_pre,\n                              step + 1,\n                              len(data_loader),\n                              loss.data[0]))\n\n        # eval model on test set\n        if ((epoch + 1) % params.eval_step_pre == 0):\n            eval_src(encoder, classifier, data_loader)\n\n        # save model parameters\n        if ((epoch + 1) % params.save_step_pre == 0):\n            save_model(encoder, ""ADDA-source-encoder-{}.pt"".format(epoch + 1))\n            save_model(\n                classifier, ""ADDA-source-classifier-{}.pt"".format(epoch + 1))\n\n    # # save final model\n    save_model(encoder, ""ADDA-source-encoder-final.pt"")\n    save_model(classifier, ""ADDA-source-classifier-final.pt"")\n\n    return encoder, classifier\n\n\ndef eval_src(encoder, classifier, data_loader):\n    """"""Evaluate classifier for source domain.""""""\n    # set eval state for Dropout and BN layers\n    encoder.eval()\n    classifier.eval()\n\n    # init loss and accuracy\n    loss = 0\n    acc = 0\n\n    # set loss function\n    criterion = nn.CrossEntropyLoss()\n\n    # evaluate network\n    for (images, labels) in data_loader:\n        images = make_variable(images, volatile=True)\n        labels = make_variable(labels)\n\n        preds = classifier(encoder(images))\n        loss += criterion(preds, labels).data[0]\n\n        pred_cls = preds.data.max(1)[1]\n        acc += pred_cls.eq(labels.data).cpu().sum()\n\n    loss /= len(data_loader)\n    acc /= len(data_loader.dataset)\n\n    print(""Avg Loss = {}, Avg Accuracy = {:2%}"".format(loss, acc))\n'"
core/test.py,1,"b'""""""Test script to classify target data.""""""\n\nimport torch\nimport torch.nn as nn\n\nfrom utils import make_variable\n\n\ndef eval_tgt(encoder, classifier, data_loader):\n    """"""Evaluation for target encoder by source classifier on target dataset.""""""\n    # set eval state for Dropout and BN layers\n    encoder.eval()\n    classifier.eval()\n\n    # init loss and accuracy\n    loss = 0\n    acc = 0\n\n    # set loss function\n    criterion = nn.CrossEntropyLoss()\n\n    # evaluate network\n    for (images, labels) in data_loader:\n        images = make_variable(images, volatile=True)\n        labels = make_variable(labels).squeeze_()\n\n        preds = classifier(encoder(images))\n        loss += criterion(preds, labels).data[0]\n\n        pred_cls = preds.data.max(1)[1]\n        acc += pred_cls.eq(labels.data).cpu().sum()\n\n    loss /= len(data_loader)\n    acc /= len(data_loader.dataset)\n\n    print(""Avg Loss = {}, Avg Accuracy = {:2%}"".format(loss, acc))\n'"
datasets/__init__.py,0,"b'from .mnist import get_mnist\nfrom .usps import get_usps\n\n__all__ = (get_usps, get_mnist)\n'"
datasets/mnist.py,1,"b'""""""Dataset setting and data loader for MNIST.""""""\n\n\nimport torch\nfrom torchvision import datasets, transforms\n\nimport params\n\n\ndef get_mnist(train):\n    """"""Get MNIST dataset loader.""""""\n    # image pre-processing\n    pre_process = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Normalize(\n                                          mean=params.dataset_mean,\n                                          std=params.dataset_std)])\n\n    # dataset and data loader\n    mnist_dataset = datasets.MNIST(root=params.data_root,\n                                   train=train,\n                                   transform=pre_process,\n                                   download=True)\n\n    mnist_data_loader = torch.utils.data.DataLoader(\n        dataset=mnist_dataset,\n        batch_size=params.batch_size,\n        shuffle=True)\n\n    return mnist_data_loader\n'"
datasets/usps.py,4,"b'""""""Dataset setting and data loader for USPS.\n\nModified from\nhttps://github.com/mingyuliutw/CoGAN/blob/master/cogan_pytorch/src/dataset_usps.py\n""""""\n\nimport gzip\nimport os\nimport pickle\nimport urllib\n\nimport numpy as np\nimport torch\nimport torch.utils.data as data\nfrom torchvision import datasets, transforms\n\nimport params\n\n\nclass USPS(data.Dataset):\n    """"""USPS Dataset.\n\n    Args:\n        root (string): Root directory of dataset where dataset file exist.\n        train (bool, optional): If True, resample from dataset randomly.\n        download (bool, optional): If true, downloads the dataset\n            from the internet and puts it in root directory.\n            If dataset is already downloaded, it is not downloaded again.\n        transform (callable, optional): A function/transform that takes in\n            an PIL image and returns a transformed version.\n            E.g, ``transforms.RandomCrop``\n    """"""\n\n    url = ""https://raw.githubusercontent.com/mingyuliutw/CoGAN/master/cogan_pytorch/data/uspssample/usps_28x28.pkl""\n\n    def __init__(self, root, train=True, transform=None, download=False):\n        """"""Init USPS dataset.""""""\n        # init params\n        self.root = os.path.expanduser(root)\n        self.filename = ""usps_28x28.pkl""\n        self.train = train\n        # Num of Train = 7438, Num ot Test 1860\n        self.transform = transform\n        self.dataset_size = None\n\n        # download dataset.\n        if download:\n            self.download()\n        if not self._check_exists():\n            raise RuntimeError(""Dataset not found."" +\n                               "" You can use download=True to download it"")\n\n        self.train_data, self.train_labels = self.load_samples()\n        if self.train:\n            total_num_samples = self.train_labels.shape[0]\n            indices = np.arange(total_num_samples)\n            np.random.shuffle(indices)\n            self.train_data = self.train_data[indices[0:self.dataset_size], ::]\n            self.train_labels = self.train_labels[indices[0:self.dataset_size]]\n        self.train_data *= 255.0\n        self.train_data = self.train_data.transpose(\n            (0, 2, 3, 1))  # convert to HWC\n\n    def __getitem__(self, index):\n        """"""Get images and target for data loader.\n\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        """"""\n        img, label = self.train_data[index, ::], self.train_labels[index]\n        if self.transform is not None:\n            img = self.transform(img)\n        label = torch.LongTensor([np.int64(label).item()])\n        # label = torch.FloatTensor([label.item()])\n        return img, label\n\n    def __len__(self):\n        """"""Return size of dataset.""""""\n        return self.dataset_size\n\n    def _check_exists(self):\n        """"""Check if dataset is download and in right place.""""""\n        return os.path.exists(os.path.join(self.root, self.filename))\n\n    def download(self):\n        """"""Download dataset.""""""\n        filename = os.path.join(self.root, self.filename)\n        dirname = os.path.dirname(filename)\n        if not os.path.isdir(dirname):\n            os.makedirs(dirname)\n        if os.path.isfile(filename):\n            return\n        print(""Download %s to %s"" % (self.url, os.path.abspath(filename)))\n        urllib.request.urlretrieve(self.url, filename)\n        print(""[DONE]"")\n        return\n\n    def load_samples(self):\n        """"""Load sample images from dataset.""""""\n        filename = os.path.join(self.root, self.filename)\n        f = gzip.open(filename, ""rb"")\n        data_set = pickle.load(f, encoding=""bytes"")\n        f.close()\n        if self.train:\n            images = data_set[0][0]\n            labels = data_set[0][1]\n            self.dataset_size = labels.shape[0]\n        else:\n            images = data_set[1][0]\n            labels = data_set[1][1]\n            self.dataset_size = labels.shape[0]\n        return images, labels\n\n\ndef get_usps(train):\n    """"""Get USPS dataset loader.""""""\n    # image pre-processing\n    pre_process = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Normalize(\n                                          mean=params.dataset_mean,\n                                          std=params.dataset_std)])\n\n    # dataset and data loader\n    usps_dataset = USPS(root=params.data_root,\n                        train=train,\n                        transform=pre_process,\n                        download=True)\n\n    usps_data_loader = torch.utils.data.DataLoader(\n        dataset=usps_dataset,\n        batch_size=params.batch_size,\n        shuffle=True)\n\n    return usps_data_loader\n'"
models/__init__.py,0,"b'from .discriminator import Discriminator\nfrom .lenet import LeNetClassifier, LeNetEncoder\n\n__all__ = (LeNetClassifier, LeNetEncoder, Discriminator)\n'"
models/discriminator.py,0,"b'""""""Discriminator model for ADDA.""""""\n\nfrom torch import nn\n\n\nclass Discriminator(nn.Module):\n    """"""Discriminator model for source domain.""""""\n\n    def __init__(self, input_dims, hidden_dims, output_dims):\n        """"""Init discriminator.""""""\n        super(Discriminator, self).__init__()\n\n        self.restored = False\n\n        self.layer = nn.Sequential(\n            nn.Linear(input_dims, hidden_dims),\n            nn.ReLU(),\n            nn.Linear(hidden_dims, hidden_dims),\n            nn.ReLU(),\n            nn.Linear(hidden_dims, output_dims),\n            nn.LogSoftmax()\n        )\n\n    def forward(self, input):\n        """"""Forward the discriminator.""""""\n        out = self.layer(input)\n        return out\n'"
models/lenet.py,1,"b'""""""LeNet model for ADDA.""""""\n\nimport torch.nn.functional as F\nfrom torch import nn\n\n\nclass LeNetEncoder(nn.Module):\n    """"""LeNet encoder model for ADDA.""""""\n\n    def __init__(self):\n        """"""Init LeNet encoder.""""""\n        super(LeNetEncoder, self).__init__()\n\n        self.restored = False\n\n        self.encoder = nn.Sequential(\n            # 1st conv layer\n            # input [1 x 28 x 28]\n            # output [20 x 12 x 12]\n            nn.Conv2d(1, 20, kernel_size=5),\n            nn.MaxPool2d(kernel_size=2),\n            nn.ReLU(),\n            # 2nd conv layer\n            # input [20 x 12 x 12]\n            # output [50 x 4 x 4]\n            nn.Conv2d(20, 50, kernel_size=5),\n            nn.Dropout2d(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.ReLU()\n        )\n        self.fc1 = nn.Linear(50 * 4 * 4, 500)\n\n    def forward(self, input):\n        """"""Forward the LeNet.""""""\n        conv_out = self.encoder(input)\n        feat = self.fc1(conv_out.view(-1, 50 * 4 * 4))\n        return feat\n\n\nclass LeNetClassifier(nn.Module):\n    """"""LeNet classifier model for ADDA.""""""\n\n    def __init__(self):\n        """"""Init LeNet encoder.""""""\n        super(LeNetClassifier, self).__init__()\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, feat):\n        """"""Forward the LeNet classifier.""""""\n        out = F.dropout(F.relu(feat), training=self.training)\n        out = self.fc2(out)\n        return out\n'"
