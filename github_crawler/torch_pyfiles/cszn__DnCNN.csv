file_path,api_count,code
TrainingCodes/dncnn_keras/data_generator.py,0,"b""# -*- coding: utf-8 -*-\n\n# =============================================================================\n#  @article{zhang2017beyond,\n#    title={Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for image denoising},\n#    author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},\n#    journal={IEEE Transactions on Image Processing},\n#    year={2017},\n#    volume={26}, \n#    number={7}, \n#    pages={3142-3155}, \n#  }\n# by Kai Zhang (08/2018)\n# cskaizhang@gmail.com\n# https://github.com/cszn\n# modified on the code from https://github.com/husqin/DnCNN-keras\n# =============================================================================\n\n# no need to run this code separately\n\n\nimport glob\n#import os\nimport cv2\nimport numpy as np\n#from multiprocessing import Pool\n\n\npatch_size, stride = 40, 10\naug_times = 1\nscales = [1, 0.9, 0.8, 0.7]\nbatch_size = 128\n\n\ndef show(x,title=None,cbar=False,figsize=None):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=figsize)\n    plt.imshow(x,interpolation='nearest',cmap='gray')\n    if title:\n        plt.title(title)\n    if cbar:\n        plt.colorbar()\n    plt.show()\n\ndef data_aug(img, mode=0):\n\n    if mode == 0:\n        return img\n    elif mode == 1:\n        return np.flipud(img)\n    elif mode == 2:\n        return np.rot90(img)\n    elif mode == 3:\n        return np.flipud(np.rot90(img))\n    elif mode == 4:\n        return np.rot90(img, k=2)\n    elif mode == 5:\n        return np.flipud(np.rot90(img, k=2))\n    elif mode == 6:\n        return np.rot90(img, k=3)\n    elif mode == 7:\n        return np.flipud(np.rot90(img, k=3))\n\ndef gen_patches(file_name):\n\n    # read image\n    img = cv2.imread(file_name, 0)  # gray scale\n    h, w = img.shape\n    patches = []\n    for s in scales:\n        h_scaled, w_scaled = int(h*s),int(w*s)\n        img_scaled = cv2.resize(img, (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n        # extract patches\n        for i in range(0, h_scaled-patch_size+1, stride):\n            for j in range(0, w_scaled-patch_size+1, stride):\n                x = img_scaled[i:i+patch_size, j:j+patch_size]\n                #patches.append(x)        \n                # data aug\n                for k in range(0, aug_times):\n                    x_aug = data_aug(x, mode=np.random.randint(0,8))\n                    patches.append(x_aug)\n                \n    return patches\n\ndef datagenerator(data_dir='data/Train400',verbose=False):\n    \n    file_list = glob.glob(data_dir+'/*.png')  # get name list of all .png files\n    # initrialize\n    data = []\n    # generate patches\n    for i in range(len(file_list)):\n        patch = gen_patches(file_list[i])\n        data.append(patch)\n        if verbose:\n            print(str(i+1)+'/'+ str(len(file_list)) + ' is done ^_^')\n    data = np.array(data, dtype='uint8')\n    data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],1))\n    discard_n = len(data)-len(data)//batch_size*batch_size;\n    data = np.delete(data,range(discard_n),axis = 0)\n    print('^_^-training data finished-^_^')\n    return data\n\nif __name__ == '__main__':   \n\n    data = datagenerator(data_dir='data/Train400')\n    \n\n#    print('Shape of result = ' + str(res.shape))\n#    print('Saving data...')\n#    if not os.path.exists(save_dir):\n#            os.mkdir(save_dir)\n#    np.save(save_dir+'clean_patches.npy', res)\n#    print('Done.')       """
TrainingCodes/dncnn_keras/main_test.py,0,"b'# -*- coding: utf-8 -*-\n\n# =============================================================================\n#  @article{zhang2017beyond,\n#    title={Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for image denoising},\n#    author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},\n#    journal={IEEE Transactions on Image Processing},\n#    year={2017},\n#    volume={26}, \n#    number={7}, \n#    pages={3142-3155}, \n#  }\n# by Kai Zhang (08/2018)\n# cskaizhang@gmail.com\n# https://github.com/cszn\n# modified on the code from https://github.com/husqin/DnCNN-keras\n# =============================================================================\n\n# run this to test the model\n\nimport argparse\nimport os, time, datetime\n#import PIL.Image as Image\nimport numpy as np\nfrom keras.models import load_model, model_from_json\nfrom skimage.measure import compare_psnr, compare_ssim\nfrom skimage.io import imread, imsave\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--set_dir\', default=\'data/Test\', type=str, help=\'directory of test dataset\')\n    parser.add_argument(\'--set_names\', default=[\'Set68\',\'Set12\'], type=list, help=\'name of test dataset\')\n    parser.add_argument(\'--sigma\', default=25, type=int, help=\'noise level\')\n    parser.add_argument(\'--model_dir\', default=os.path.join(\'models\',\'DnCNN_sigma25\'), type=str, help=\'directory of the model\')\n    parser.add_argument(\'--model_name\', default=\'model_001.hdf5\', type=str, help=\'the model name\')\n    parser.add_argument(\'--result_dir\', default=\'results\', type=str, help=\'directory of results\')\n    parser.add_argument(\'--save_result\', default=0, type=int, help=\'save the denoised image, 1 or 0\')\n    return parser.parse_args()\n    \ndef to_tensor(img):\n    if img.ndim == 2:\n        return img[np.newaxis,...,np.newaxis]\n    elif img.ndim == 3:\n        return np.moveaxis(img,2,0)[...,np.newaxis]\n\ndef from_tensor(img):\n    return np.squeeze(np.moveaxis(img[...,0],0,-1))\n\ndef log(*args,**kwargs):\n     print(datetime.datetime.now().strftime(""%Y-%m-%d %H:%M:%S:""),*args,**kwargs)\n\ndef save_result(result,path):\n    path = path if path.find(\'.\') != -1 else path+\'.png\'\n    ext = os.path.splitext(path)[-1]\n    if ext in (\'.txt\',\'.dlm\'):\n        np.savetxt(path,result,fmt=\'%2.4f\')\n    else:\n        imsave(path,np.clip(result,0,1))\n\n\ndef show(x,title=None,cbar=False,figsize=None):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=figsize)\n    plt.imshow(x,interpolation=\'nearest\',cmap=\'gray\')\n    if title:\n        plt.title(title)\n    if cbar:\n        plt.colorbar()\n    plt.show()\n\n\nif __name__ == \'__main__\':    \n    \n    args = parse_args()\n    \n    \n    # =============================================================================\n    #     # serialize model to JSON\n    #     model_json = model.to_json()\n    #     with open(""model.json"", ""w"") as json_file:\n    #         json_file.write(model_json)\n    #     # serialize weights to HDF5\n    #     model.save_weights(""model.h5"")\n    #     print(""Saved model"")\n    # =============================================================================\n\n    if not os.path.exists(os.path.join(args.model_dir, args.model_name)):\n        # load json and create model\n        json_file = open(os.path.join(args.model_dir,\'model.json\'), \'r\')\n        loaded_model_json = json_file.read()\n        json_file.close()\n        model = model_from_json(loaded_model_json)\n        # load weights into new model\n        model.load_weights(os.path.join(args.model_dir,\'model.h5\'))\n        log(\'load trained model on Train400 dataset by kai\')\n    else:\n        model = load_model(os.path.join(args.model_dir, args.model_name),compile=False)\n        log(\'load trained model\')\n\n    if not os.path.exists(args.result_dir):\n        os.mkdir(args.result_dir)\n        \n    for set_cur in args.set_names:  \n        \n        if not os.path.exists(os.path.join(args.result_dir,set_cur)):\n            os.mkdir(os.path.join(args.result_dir,set_cur))\n        psnrs = []\n        ssims = [] \n        \n        for im in os.listdir(os.path.join(args.set_dir,set_cur)): \n            if im.endswith("".jpg"") or im.endswith("".bmp"") or im.endswith("".png""):\n                #x = np.array(Image.open(os.path.join(args.set_dir,set_cur,im)), dtype=\'float32\') / 255.0\n                x = np.array(imread(os.path.join(args.set_dir,set_cur,im)), dtype=np.float32) / 255.0\n                np.random.seed(seed=0) # for reproducibility\n                y = x + np.random.normal(0, args.sigma/255.0, x.shape) # Add Gaussian noise without clipping\n                y = y.astype(np.float32)\n                y_  = to_tensor(y)\n                start_time = time.time()\n                x_ = model.predict(y_) # inference\n                elapsed_time = time.time() - start_time\n                print(\'%10s : %10s : %2.4f second\'%(set_cur,im,elapsed_time))\n                x_=from_tensor(x_)\n                psnr_x_ = compare_psnr(x, x_)\n                ssim_x_ = compare_ssim(x, x_)\n                if args.save_result:\n                    name, ext = os.path.splitext(im)\n                    show(np.hstack((y,x_))) # show the image\n                    save_result(x_,path=os.path.join(args.result_dir,set_cur,name+\'_dncnn\'+ext)) # save the denoised image\n                psnrs.append(psnr_x_)\n                ssims.append(ssim_x_)\n    \n        psnr_avg = np.mean(psnrs)\n        ssim_avg = np.mean(ssims)\n        psnrs.append(psnr_avg)\n        ssims.append(ssim_avg)\n        \n        if args.save_result:\n            save_result(np.hstack((psnrs,ssims)),path=os.path.join(args.result_dir,set_cur,\'results.txt\'))\n            \n        log(\'Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}\'.format(set_cur, psnr_avg, ssim_avg))\n        \n        \n\n\n'"
TrainingCodes/dncnn_keras/main_train.py,0,"b'# -*- coding: utf-8 -*-\n\n# =============================================================================\n#  @article{zhang2017beyond,\n#    title={Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for image denoising},\n#    author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},\n#    journal={IEEE Transactions on Image Processing},\n#    year={2017},\n#    volume={26}, \n#    number={7}, \n#    pages={3142-3155}, \n#  }\n# by Kai Zhang (08/2018)\n# cskaizhang@gmail.com\n# https://github.com/cszn\n# modified on the code from https://github.com/husqin/DnCNN-keras\n# =============================================================================\n\n# run this to train the model\n\n# =============================================================================\n# For batch normalization layer, momentum should be a value from [0, 0.9] rather than the default 0.99. \n# The Gaussian noise output helps to stablize the batch normalization, thus a small momentum is preferred.\n# =============================================================================\n\nimport argparse\nimport re\nimport os, glob, datetime\nimport numpy as np\nfrom keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract\nfrom keras.models import Model, load_model\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\nfrom keras.optimizers import Adam\nimport data_generator as dg\nimport keras.backend as K\n\n## Params\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--model\', default=\'DnCNN\', type=str, help=\'choose a type of model\')\nparser.add_argument(\'--batch_size\', default=128, type=int, help=\'batch size\')\nparser.add_argument(\'--train_data\', default=\'data/Train400\', type=str, help=\'path of train data\')\nparser.add_argument(\'--sigma\', default=25, type=int, help=\'noise level\')\nparser.add_argument(\'--epoch\', default=300, type=int, help=\'number of train epoches\')\nparser.add_argument(\'--lr\', default=1e-3, type=float, help=\'initial learning rate for Adam\')\nparser.add_argument(\'--save_every\', default=1, type=int, help=\'save model at every x epoches\')\nargs = parser.parse_args()\n\n\nsave_dir = os.path.join(\'models\',args.model+\'_\'+\'sigma\'+str(args.sigma)) \n\nif not os.path.exists(save_dir):\n    os.mkdir(save_dir)\n\ndef DnCNN(depth,filters=64,image_channels=1, use_bnorm=True):\n    layer_count = 0\n    inpt = Input(shape=(None,None,image_channels),name = \'input\'+str(layer_count))\n    # 1st layer, Conv+relu\n    layer_count += 1\n    x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer=\'Orthogonal\', padding=\'same\',name = \'conv\'+str(layer_count))(inpt)\n    layer_count += 1\n    x = Activation(\'relu\',name = \'relu\'+str(layer_count))(x)\n    # depth-2 layers, Conv+BN+relu\n    for i in range(depth-2):\n        layer_count += 1\n        x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer=\'Orthogonal\', padding=\'same\',use_bias = False,name = \'conv\'+str(layer_count))(x)\n        if use_bnorm:\n            layer_count += 1\n            #x = BatchNormalization(axis=3, momentum=0.1,epsilon=0.0001, name = \'bn\'+str(layer_count))(x) \n\t    x = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = \'bn\'+str(layer_count))(x)\n        layer_count += 1\n        x = Activation(\'relu\',name = \'relu\'+str(layer_count))(x)  \n    # last layer, Conv\n    layer_count += 1\n    x = Conv2D(filters=image_channels, kernel_size=(3,3), strides=(1,1), kernel_initializer=\'Orthogonal\',padding=\'same\',use_bias = False,name = \'conv\'+str(layer_count))(x)\n    layer_count += 1\n    x = Subtract(name = \'subtract\' + str(layer_count))([inpt, x])   # input - noise\n    model = Model(inputs=inpt, outputs=x)\n    \n    return model\n\n\ndef findLastCheckpoint(save_dir):\n    file_list = glob.glob(os.path.join(save_dir,\'model_*.hdf5\'))  # get name list of all .hdf5 files\n    #file_list = os.listdir(save_dir)\n    if file_list:\n        epochs_exist = []\n        for file_ in file_list:\n            result = re.findall("".*model_(.*).hdf5.*"",file_)\n            #print(result[0])\n            epochs_exist.append(int(result[0]))\n        initial_epoch=max(epochs_exist)   \n    else:\n        initial_epoch = 0\n    return initial_epoch\n\ndef log(*args,**kwargs):\n     print(datetime.datetime.now().strftime(""%Y-%m-%d %H:%M:%S:""),*args,**kwargs)\n\ndef lr_schedule(epoch):\n    initial_lr = args.lr\n    if epoch<=30:\n        lr = initial_lr\n    elif epoch<=60:\n        lr = initial_lr/10\n    elif epoch<=80:\n        lr = initial_lr/20 \n    else:\n        lr = initial_lr/20 \n    log(\'current learning rate is %2.8f\' %lr)\n    return lr\n\ndef train_datagen(epoch_iter=2000,epoch_num=5,batch_size=128,data_dir=args.train_data):\n    while(True):\n        n_count = 0\n        if n_count == 0:\n            #print(n_count)\n            xs = dg.datagenerator(data_dir)\n            assert len(xs)%args.batch_size ==0, \\\n            log(\'make sure the last iteration has a full batchsize, this is important if you use batch normalization!\')\n            xs = xs.astype(\'float32\')/255.0\n            indices = list(range(xs.shape[0]))\n            n_count = 1\n        for _ in range(epoch_num):\n            np.random.shuffle(indices)    # shuffle\n            for i in range(0, len(indices), batch_size):\n                batch_x = xs[indices[i:i+batch_size]]\n                noise =  np.random.normal(0, args.sigma/255.0, batch_x.shape)    # noise\n                #noise =  K.random_normal(ge_batch_y.shape, mean=0, stddev=args.sigma/255.0)\n                batch_y = batch_x + noise \n                yield batch_y, batch_x\n        \n# define loss\ndef sum_squared_error(y_true, y_pred):\n    #return K.mean(K.square(y_pred - y_true), axis=-1)\n    #return K.sum(K.square(y_pred - y_true), axis=-1)/2\n    return K.sum(K.square(y_pred - y_true))/2\n    \nif __name__ == \'__main__\':\n    # model selection\n    model = DnCNN(depth=17,filters=64,image_channels=1,use_bnorm=True)\n    model.summary()\n    \n    # load the last model in matconvnet style\n    initial_epoch = findLastCheckpoint(save_dir=save_dir)\n    if initial_epoch > 0:  \n        print(\'resuming by loading epoch %03d\'%initial_epoch)\n        model = load_model(os.path.join(save_dir,\'model_%03d.hdf5\'%initial_epoch), compile=False)\n    \n    # compile the model\n    model.compile(optimizer=Adam(0.001), loss=sum_squared_error)\n    \n    # use call back functions\n    checkpointer = ModelCheckpoint(os.path.join(save_dir,\'model_{epoch:03d}.hdf5\'), \n                verbose=1, save_weights_only=False, period=args.save_every)\n    csv_logger = CSVLogger(os.path.join(save_dir,\'log.csv\'), append=True, separator=\',\')\n    lr_scheduler = LearningRateScheduler(lr_schedule)\n    \n    history = model.fit_generator(train_datagen(batch_size=args.batch_size),\n                steps_per_epoch=2000, epochs=args.epoch, verbose=1, initial_epoch=initial_epoch,\n                callbacks=[checkpointer,csv_logger,lr_scheduler])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
TrainingCodes/dncnn_pytorch/data_generator.py,2,"b'# -*- coding: utf-8 -*-\n\n# =============================================================================\n#  @article{zhang2017beyond,\n#    title={Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for image denoising},\n#    author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},\n#    journal={IEEE Transactions on Image Processing},\n#    year={2017},\n#    volume={26}, \n#    number={7}, \n#    pages={3142-3155}, \n#  }\n# by Kai Zhang (08/2018)\n# cskaizhang@gmail.com\n# https://github.com/cszn\n# modified on the code from https://github.com/SaoYan/DnCNN-PyTorch\n# =============================================================================\n\n# no need to run this code separately\n\n\nimport glob\nimport cv2\nimport numpy as np\n# from multiprocessing import Pool\nfrom torch.utils.data import Dataset\nimport torch\n\npatch_size, stride = 40, 10\naug_times = 1\nscales = [1, 0.9, 0.8, 0.7]\nbatch_size = 128\n\n\nclass DenoisingDataset(Dataset):\n    """"""Dataset wrapping tensors.\n    Arguments:\n        xs (Tensor): clean image patches\n        sigma: noise level, e.g., 25\n    """"""\n    def __init__(self, xs, sigma):\n        super(DenoisingDataset, self).__init__()\n        self.xs = xs\n        self.sigma = sigma\n\n    def __getitem__(self, index):\n        batch_x = self.xs[index]\n        noise = torch.randn(batch_x.size()).mul_(self.sigma/255.0)\n        batch_y = batch_x + noise\n        return batch_y, batch_x\n\n    def __len__(self):\n        return self.xs.size(0)\n\n\ndef show(x, title=None, cbar=False, figsize=None):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=figsize)\n    plt.imshow(x, interpolation=\'nearest\', cmap=\'gray\')\n    if title:\n        plt.title(title)\n    if cbar:\n        plt.colorbar()\n    plt.show()\n\n\ndef data_aug(img, mode=0):\n    # data augmentation\n    if mode == 0:\n        return img\n    elif mode == 1:\n        return np.flipud(img)\n    elif mode == 2:\n        return np.rot90(img)\n    elif mode == 3:\n        return np.flipud(np.rot90(img))\n    elif mode == 4:\n        return np.rot90(img, k=2)\n    elif mode == 5:\n        return np.flipud(np.rot90(img, k=2))\n    elif mode == 6:\n        return np.rot90(img, k=3)\n    elif mode == 7:\n        return np.flipud(np.rot90(img, k=3))\n\n\ndef gen_patches(file_name):\n    # get multiscale patches from a single image\n    img = cv2.imread(file_name, 0)  # gray scale\n    h, w = img.shape\n    patches = []\n    for s in scales:\n        h_scaled, w_scaled = int(h*s), int(w*s)\n        img_scaled = cv2.resize(img, (h_scaled, w_scaled), interpolation=cv2.INTER_CUBIC)\n        # extract patches\n        for i in range(0, h_scaled-patch_size+1, stride):\n            for j in range(0, w_scaled-patch_size+1, stride):\n                x = img_scaled[i:i+patch_size, j:j+patch_size]\n                for k in range(0, aug_times):\n                    x_aug = data_aug(x, mode=np.random.randint(0, 8))\n                    patches.append(x_aug)\n    return patches\n\n\ndef datagenerator(data_dir=\'data/Train400\', verbose=False):\n    # generate clean patches from a dataset\n    file_list = glob.glob(data_dir+\'/*.png\')  # get name list of all .png files\n    # initrialize\n    data = []\n    # generate patches\n    for i in range(len(file_list)):\n        patches = gen_patches(file_list[i])\n        for patch in patches:    \n            data.append(patch)\n        if verbose:\n            print(str(i+1) + \'/\' + str(len(file_list)) + \' is done ^_^\')\n    data = np.array(data, dtype=\'uint8\')\n    data = np.expand_dims(data, axis=3)\n    discard_n = len(data)-len(data)//batch_size*batch_size  # because of batch namalization\n    data = np.delete(data, range(discard_n), axis=0)\n    print(\'^_^-training data finished-^_^\')\n    return data\n\n\nif __name__ == \'__main__\': \n\n    data = datagenerator(data_dir=\'data/Train400\')\n\n\n#    print(\'Shape of result = \' + str(res.shape))\n#    print(\'Saving data...\')\n#    if not os.path.exists(save_dir):\n#            os.mkdir(save_dir)\n#    np.save(save_dir+\'clean_patches.npy\', res)\n#    print(\'Done.\')       '"
TrainingCodes/dncnn_pytorch/main_test.py,9,"b'# -*- coding: utf-8 -*-\n\n# =============================================================================\n#  @article{zhang2017beyond,\n#    title={Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for image denoising},\n#    author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},\n#    journal={IEEE Transactions on Image Processing},\n#    year={2017},\n#    volume={26}, \n#    number={7}, \n#    pages={3142-3155}, \n#  }\n# by Kai Zhang (08/2018)\n# cskaizhang@gmail.com\n# https://github.com/cszn\n# modified on the code from https://github.com/SaoYan/DnCNN-PyTorch\n# =============================================================================\n\n# run this to test the model\n\nimport argparse\nimport os, time, datetime\n# import PIL.Image as Image\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch\nfrom skimage.measure import compare_psnr, compare_ssim\nfrom skimage.io import imread, imsave\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--set_dir\', default=\'data/Test\', type=str, help=\'directory of test dataset\')\n    parser.add_argument(\'--set_names\', default=[\'Set68\', \'Set12\'], help=\'directory of test dataset\')\n    parser.add_argument(\'--sigma\', default=25, type=int, help=\'noise level\')\n    parser.add_argument(\'--model_dir\', default=os.path.join(\'models\', \'DnCNN_sigma25\'), help=\'directory of the model\')\n    parser.add_argument(\'--model_name\', default=\'model_001.pth\', type=str, help=\'the model name\')\n    parser.add_argument(\'--result_dir\', default=\'results\', type=str, help=\'directory of test dataset\')\n    parser.add_argument(\'--save_result\', default=0, type=int, help=\'save the denoised image, 1 or 0\')\n    return parser.parse_args()\n\n\ndef log(*args, **kwargs):\n     print(datetime.datetime.now().strftime(""%Y-%m-%d %H:%M:%S:""), *args, **kwargs)\n\n\ndef save_result(result, path):\n    path = path if path.find(\'.\') != -1 else path+\'.png\'\n    ext = os.path.splitext(path)[-1]\n    if ext in (\'.txt\', \'.dlm\'):\n        np.savetxt(path, result, fmt=\'%2.4f\')\n    else:\n        imsave(path, np.clip(result, 0, 1))\n\n\ndef show(x, title=None, cbar=False, figsize=None):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=figsize)\n    plt.imshow(x, interpolation=\'nearest\', cmap=\'gray\')\n    if title:\n        plt.title(title)\n    if cbar:\n        plt.colorbar()\n    plt.show()\n\n\nclass DnCNN(nn.Module):\n\n    def __init__(self, depth=17, n_channels=64, image_channels=1, use_bnorm=True, kernel_size=3):\n        super(DnCNN, self).__init__()\n        kernel_size = 3\n        padding = 1\n        layers = []\n        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n        layers.append(nn.ReLU(inplace=True))\n        for _ in range(depth-2):\n            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n            layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum=0.95))\n            layers.append(nn.ReLU(inplace=True))\n        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n        self.dncnn = nn.Sequential(*layers)\n        self._initialize_weights()\n\n    def forward(self, x):\n        y = x\n        out = self.dncnn(x)\n        return y-out\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.orthogonal_(m.weight)\n                print(\'init weight\')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n\n\nif __name__ == \'__main__\':\n\n    args = parse_args()\n\n    # model = DnCNN()\n    if not os.path.exists(os.path.join(args.model_dir, args.model_name)):\n\n        model = torch.load(os.path.join(args.model_dir, \'model.pth\'))\n        # load weights into new model\n        log(\'load trained model on Train400 dataset by kai\')\n    else:\n        # model.load_state_dict(torch.load(os.path.join(args.model_dir, args.model_name)))\n        model = torch.load(os.path.join(args.model_dir, args.model_name))\n        log(\'load trained model\')\n\n#    params = model.state_dict()\n#    print(params.values())\n#    print(params.keys())\n#\n#    for key, value in params.items():\n#        print(key)    # parameter name\n#    print(params[\'dncnn.12.running_mean\'])\n#    print(model.state_dict())\n\n    model.eval()  # evaluation mode\n#    model.train()\n\n    if torch.cuda.is_available():\n        model = model.cuda()\n\n    if not os.path.exists(args.result_dir):\n        os.mkdir(args.result_dir)\n\n    for set_cur in args.set_names:\n\n        if not os.path.exists(os.path.join(args.result_dir, set_cur)):\n            os.mkdir(os.path.join(args.result_dir, set_cur))\n        psnrs = []\n        ssims = []\n\n        for im in os.listdir(os.path.join(args.set_dir, set_cur)):\n            if im.endswith("".jpg"") or im.endswith("".bmp"") or im.endswith("".png""):\n\n                x = np.array(imread(os.path.join(args.set_dir, set_cur, im)), dtype=np.float32)/255.0\n                np.random.seed(seed=0)  # for reproducibility\n                y = x + np.random.normal(0, args.sigma/255.0, x.shape)  # Add Gaussian noise without clipping\n                y = y.astype(np.float32)\n                y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])\n\n                torch.cuda.synchronize()\n                start_time = time.time()\n                y_ = y_.cuda()\n                x_ = model(y_)  # inference\n                x_ = x_.view(y.shape[0], y.shape[1])\n                x_ = x_.cpu()\n                x_ = x_.detach().numpy().astype(np.float32)\n                torch.cuda.synchronize()\n                elapsed_time = time.time() - start_time\n                print(\'%10s : %10s : %2.4f second\' % (set_cur, im, elapsed_time))\n\n                psnr_x_ = compare_psnr(x, x_)\n                ssim_x_ = compare_ssim(x, x_)\n                if args.save_result:\n                    name, ext = os.path.splitext(im)\n                    show(np.hstack((y, x_)))  # show the image\n                    save_result(x_, path=os.path.join(args.result_dir, set_cur, name+\'_dncnn\'+ext))  # save the denoised image\n                psnrs.append(psnr_x_)\n                ssims.append(ssim_x_)\n        psnr_avg = np.mean(psnrs)\n        ssim_avg = np.mean(ssims)\n        psnrs.append(psnr_avg)\n        ssims.append(ssim_avg)\n        if args.save_result:\n            save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, \'results.txt\'))\n        log(\'Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}\'.format(set_cur, psnr_avg, ssim_avg))\n\n\n\n\n\n\n\n\n'"
TrainingCodes/dncnn_pytorch/main_train.py,15,"b'# -*- coding: utf-8 -*-\n\n# PyTorch 0.4.1, https://pytorch.org/docs/stable/index.html\n\n# =============================================================================\n#  @article{zhang2017beyond,\n#    title={Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for image denoising},\n#    author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},\n#    journal={IEEE Transactions on Image Processing},\n#    year={2017},\n#    volume={26}, \n#    number={7}, \n#    pages={3142-3155}, \n#  }\n# by Kai Zhang (08/2018)\n# cskaizhang@gmail.com\n# https://github.com/cszn\n# modified on the code from https://github.com/SaoYan/DnCNN-PyTorch\n# =============================================================================\n\n# run this to train the model\n\n# =============================================================================\n# For batch normalization layer, momentum should be a value from [0.1, 1] rather than the default 0.1. \n# The Gaussian noise output helps to stablize the batch normalization, thus a large momentum (e.g., 0.95) is preferred.\n# =============================================================================\n\nimport argparse\nimport re\nimport os, glob, datetime, time\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn.modules.loss import _Loss\nimport torch.nn.init as init\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import MultiStepLR\nimport data_generator as dg\nfrom data_generator import DenoisingDataset\n\n\n# Params\nparser = argparse.ArgumentParser(description=\'PyTorch DnCNN\')\nparser.add_argument(\'--model\', default=\'DnCNN\', type=str, help=\'choose a type of model\')\nparser.add_argument(\'--batch_size\', default=128, type=int, help=\'batch size\')\nparser.add_argument(\'--train_data\', default=\'data/Train400\', type=str, help=\'path of train data\')\nparser.add_argument(\'--sigma\', default=25, type=int, help=\'noise level\')\nparser.add_argument(\'--epoch\', default=180, type=int, help=\'number of train epoches\')\nparser.add_argument(\'--lr\', default=1e-3, type=float, help=\'initial learning rate for Adam\')\nargs = parser.parse_args()\n\nbatch_size = args.batch_size\ncuda = torch.cuda.is_available()\nn_epoch = args.epoch\nsigma = args.sigma\n\nsave_dir = os.path.join(\'models\', args.model+\'_\' + \'sigma\' + str(sigma))\n\nif not os.path.exists(save_dir):\n    os.mkdir(save_dir)\n\n\nclass DnCNN(nn.Module):\n    def __init__(self, depth=17, n_channels=64, image_channels=1, use_bnorm=True, kernel_size=3):\n        super(DnCNN, self).__init__()\n        kernel_size = 3\n        padding = 1\n        layers = []\n\n        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n        layers.append(nn.ReLU(inplace=True))\n        for _ in range(depth-2):\n            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n            layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum = 0.95))\n            layers.append(nn.ReLU(inplace=True))\n        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n        self.dncnn = nn.Sequential(*layers)\n        self._initialize_weights()\n\n    def forward(self, x):\n        y = x\n        out = self.dncnn(x)\n        return y-out\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.orthogonal_(m.weight)\n                print(\'init weight\')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n\n\nclass sum_squared_error(_Loss):  # PyTorch 0.4.1\n    """"""\n    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = \'sum\')\n    The backward is defined as: input-target\n    """"""\n    def __init__(self, size_average=None, reduce=None, reduction=\'sum\'):\n        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n\n    def forward(self, input, target):\n        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction=\'sum\').div_(2)\n\n\ndef findLastCheckpoint(save_dir):\n    file_list = glob.glob(os.path.join(save_dir, \'model_*.pth\'))\n    if file_list:\n        epochs_exist = []\n        for file_ in file_list:\n            result = re.findall("".*model_(.*).pth.*"", file_)\n            epochs_exist.append(int(result[0]))\n        initial_epoch = max(epochs_exist)\n    else:\n        initial_epoch = 0\n    return initial_epoch\n\n\ndef log(*args, **kwargs):\n     print(datetime.datetime.now().strftime(""%Y-%m-%d %H:%M:%S:""), *args, **kwargs)\n\n\nif __name__ == \'__main__\':\n    # model selection\n    print(\'===> Building model\')\n    model = DnCNN()\n    \n    initial_epoch = findLastCheckpoint(save_dir=save_dir)  # load the last model in matconvnet style\n    if initial_epoch > 0:\n        print(\'resuming by loading epoch %03d\' % initial_epoch)\n        # model.load_state_dict(torch.load(os.path.join(save_dir, \'model_%03d.pth\' % initial_epoch)))\n        model = torch.load(os.path.join(save_dir, \'model_%03d.pth\' % initial_epoch))\n    model.train()\n    # criterion = nn.MSELoss(reduction = \'sum\')  # PyTorch 0.4.1\n    criterion = sum_squared_error()\n    if cuda:\n        model = model.cuda()\n         # device_ids = [0]\n         # model = nn.DataParallel(model, device_ids=device_ids).cuda()\n         # criterion = criterion.cuda()\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)  # learning rates\n    for epoch in range(initial_epoch, n_epoch):\n\n        scheduler.step(epoch)  # step to the learning rate in this epcoh\n        xs = dg.datagenerator(data_dir=args.train_data)\n        xs = xs.astype(\'float32\')/255.0\n        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\n        DDataset = DenoisingDataset(xs, sigma)\n        DLoader = DataLoader(dataset=DDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n        epoch_loss = 0\n        start_time = time.time()\n\n        for n_count, batch_yx in enumerate(DLoader):\n                optimizer.zero_grad()\n                if cuda:\n                    batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n                loss = criterion(model(batch_y), batch_x)\n                epoch_loss += loss.item()\n                loss.backward()\n                optimizer.step()\n                if n_count % 10 == 0:\n                    print(\'%4d %4d / %4d loss = %2.4f\' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))\n        elapsed_time = time.time() - start_time\n\n        log(\'epcoh = %4d , loss = %4.4f , time = %4.2f s\' % (epoch+1, epoch_loss/n_count, elapsed_time))\n        np.savetxt(\'train_result.txt\', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt=\'%2.4f\')\n        # torch.save(model.state_dict(), os.path.join(save_dir, \'model_%03d.pth\' % (epoch+1)))\n        torch.save(model, os.path.join(save_dir, \'model_%03d.pth\' % (epoch+1)))\n\n\n\n\n\n\n'"
