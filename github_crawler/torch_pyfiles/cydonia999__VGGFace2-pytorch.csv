file_path,api_count,code
demo.py,10,"b'#!/usr/bin/env python\n\nimport argparse\nimport os\nimport sys\nimport torch\nimport torch.nn as nn\n\nimport datasets\nimport models.resnet as ResNet\nimport models.senet as SENet\nfrom trainer import Trainer, Validator\nfrom extractor import Extractor\nimport utils\n\nconfigurations = {\n    1: dict(\n        max_iteration=1000000,\n        lr=1.0e-1,\n        momentum=0.9,\n        weight_decay=0.0,\n        gamma=0.1, # ""lr_policy: step""\n        step_size=1000000, # ""lr_policy: step""\n        interval_validate=1000,\n    ),\n}\n\ndef get_parameters(model, bias=False):\n    for k, m in model._modules.items():\n        if k == ""fc"" and isinstance(m, nn.Linear):\n            if bias:\n                yield m.bias\n            else:\n                yield m.weight\n\nN_IDENTITY = 8631  # the number of identities in VGGFace2 for which ResNet and SENet are trained\n\ndef main():\n    parser = argparse.ArgumentParser(""PyTorch Face Recognizer"")\n    parser.add_argument(\'cmd\', type=str,  choices=[\'train\', \'test\', \'extract\'], help=\'train, test or extract\')\n    parser.add_argument(\'--arch_type\', type=str, default=\'resnet50_ft\', help=\'model type\',\n                        choices=[\'resnet50_ft\', \'senet50_ft\', \'resnet50_scratch\', \'senet50_scratch\'])\n    parser.add_argument(\'--dataset_dir\', type=str, default=\'/path/to/dataset_directory\', help=\'dataset directory\')\n    parser.add_argument(\'--log_file\', type=str, default=\'/path/to/log_file\', help=\'log file\')\n    parser.add_argument(\'--train_img_list_file\', type=str, default=\'/path/to/train_image_list.txt\',\n                        help=\'text file containing image files used for training\')\n    parser.add_argument(\'--test_img_list_file\', type=str, default=\'/path/to/test_image_list.txt\',\n                        help=\'text file containing image files used for validation, test or feature extraction\')\n    parser.add_argument(\'--meta_file\', type=str, default=\'/path/to/identity_meta.csv\', help=\'meta file\')\n    parser.add_argument(\'--checkpoint_dir\', type=str, default=\'/path/to/checkpoint_directory\',\n                        help=\'checkpoints directory\')\n    parser.add_argument(\'--feature_dir\', type=str, default=\'/path/to/feature_directory\',\n                        help=\'directory where extracted features are saved\')\n    parser.add_argument(\'-c\', \'--config\', type=int, default=1, choices=configurations.keys(),\n                        help=\'the number of settings and hyperparameters used in training\')\n    parser.add_argument(\'--batch_size\', type=int, default=32, help=\'batch size\')\n    parser.add_argument(\'--resume\', type=str, default=\'\', help=\'checkpoint file\')\n    parser.add_argument(\'--weight_file\', type=str, default=\'/path/to/weight_file.pkl\', help=\'weight file\')\n    parser.add_argument(\'--gpu\', type=int, default=0)\n    parser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                        help=\'number of data loading workers (default: 4)\')\n    parser.add_argument(\'--horizontal_flip\', action=\'store_true\', \n                        help=\'horizontally flip images specified in test_img_list_file\')\n    args = parser.parse_args()\n    print(args)\n\n    if args.cmd == ""extract"":\n        utils.create_dir(args.feature_dir)\n\n    if args.cmd == \'train\':\n        utils.create_dir(args.checkpoint_dir)\n        cfg = configurations[args.config]\n\n    log_file = args.log_file\n    resume = args.resume\n\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = str(args.gpu)\n    cuda = torch.cuda.is_available()\n    if cuda:\n        print(""torch.backends.cudnn.version: {}"".format(torch.backends.cudnn.version()))\n\n    torch.manual_seed(1337)\n    if cuda:\n        torch.cuda.manual_seed(1337)\n\n    # 0. id label map\n    meta_file = args.meta_file\n    id_label_dict = utils.get_id_label_map(meta_file)\n\n    # 1. data loader\n    root = args.dataset_dir\n    train_img_list_file = args.train_img_list_file\n    test_img_list_file = args.test_img_list_file\n\n    kwargs = {\'num_workers\': args.workers, \'pin_memory\': True} if cuda else {}\n\n    if args.cmd == \'train\':\n        dt = datasets.VGG_Faces2(root, train_img_list_file, id_label_dict, split=\'train\')\n        train_loader = torch.utils.data.DataLoader(dt, batch_size=args.batch_size, shuffle=True, **kwargs)\n\n    dv = datasets.VGG_Faces2(root, test_img_list_file, id_label_dict, split=\'valid\',\n                             horizontal_flip=args.horizontal_flip)\n    val_loader = torch.utils.data.DataLoader(dv, batch_size=args.batch_size, shuffle=False, **kwargs)\n\n    # 2. model\n    include_top = True if args.cmd != \'extract\' else False\n    if \'resnet\' in args.arch_type:\n        model = ResNet.resnet50(num_classes=N_IDENTITY, include_top=include_top)\n    else:\n        model = SENet.senet50(num_classes=N_IDENTITY, include_top=include_top)\n    # print(model)\n\n    start_epoch = 0\n    start_iteration = 0\n    if resume:\n        checkpoint = torch.load(resume)\n        model.load_state_dict(checkpoint[\'model_state_dict\'])\n        start_epoch = checkpoint[\'epoch\']\n        start_iteration = checkpoint[\'iteration\']\n        assert checkpoint[\'arch\'] == args.arch_type\n        print(""Resume from epoch: {}, iteration: {}"".format(start_epoch, start_iteration))\n    else:\n        utils.load_state_dict(model, args.weight_file)\n        if args.cmd == \'train\':\n            model.fc.reset_parameters()\n\n    if cuda:\n        model = model.cuda()\n\n    criterion = nn.CrossEntropyLoss()\n    if cuda:\n        criterion = criterion.cuda()\n\n    # 3. optimizer\n    if args.cmd == \'train\':\n        optim = torch.optim.SGD(\n            [\n                {\'params\': get_parameters(model, bias=False)},\n                {\'params\': get_parameters(model, bias=True), \'lr\': cfg[\'lr\'] * 2, \'weight_decay\': 0},\n            ],\n            lr=cfg[\'lr\'],\n            momentum=cfg[\'momentum\'],\n            weight_decay=cfg[\'weight_decay\'])\n        if resume:\n            optim.load_state_dict(checkpoint[\'optim_state_dict\'])\n    \n        # lr_policy: step\n        last_epoch = start_iteration if resume else -1\n        lr_scheduler = torch.optim.lr_scheduler.StepLR(optim,  cfg[\'step_size\'],\n                                                       gamma=cfg[\'gamma\'], last_epoch=last_epoch)\n\n    if args.cmd == \'train\':\n        trainer = Trainer(\n            cmd=args.cmd,\n            cuda=cuda,\n            model=model,\n            criterion=criterion,\n            optimizer=optim,\n            lr_scheduler=lr_scheduler,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            log_file=log_file,\n            max_iter=cfg[\'max_iteration\'],\n            checkpoint_dir=args.checkpoint_dir,\n            print_freq=1,\n        )\n        trainer.epoch = start_epoch\n        trainer.iteration = start_iteration\n        trainer.train()\n    elif args.cmd == \'test\':\n        validator = Validator(\n            cmd=args.cmd,\n            cuda=cuda,\n            model=model,\n            criterion=criterion,\n            val_loader=val_loader,\n            log_file=log_file,\n            print_freq=1,\n        )\n        validator.validate()\n    elif args.cmd == \'extract\':\n        extractor = Extractor(\n            cuda=cuda,\n            model=model,\n            val_loader=val_loader,\n            log_file=log_file,\n            feature_dir=args.feature_dir,\n            flatten_feature=True,\n            print_freq=1,\n        )\n        extractor.extract()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
extractor.py,2,"b'import datetime\nimport math\nimport os\nimport gc\nimport time\n\nimport numpy as np\nimport torch\nfrom torch.autograd import Variable\n\nimport utils\nimport tqdm\n\nclass Extractor(object):\n\n    def __init__(self, cuda, model, val_loader, log_file, feature_dir, flatten_feature=True, print_freq=1):\n        """"""\n        :param cuda:\n        :param model:\n        :param val_loader:\n        :param log_file: log file name. logs are appended to this file.\n        :param feature_dir:\n        :param flatten_feature:\n        :param print_freq:\n        """"""\n        self.cuda = cuda\n\n        self.model = model\n        self.val_loader = val_loader\n        self.log_file = log_file\n        self.feature_dir = feature_dir\n        self.flatten_feature = flatten_feature\n        self.print_freq = print_freq\n\n        self.timestamp_start = datetime.datetime.now()\n\n\n    def print_log(self, log_str):\n        with open(self.log_file, \'a\') as f:\n            f.write(log_str + \'\\n\')\n\n\n    def extract(self):\n        batch_time = utils.AverageMeter()\n\n        self.model.eval()\n        end = time.time()\n\n        for batch_idx, (imgs, target, img_files, class_ids) in tqdm.tqdm(\n                enumerate(self.val_loader), total=len(self.val_loader),\n                desc=\'Extract\', ncols=80, leave=False):\n\n            gc.collect()\n\n            if self.cuda:\n                imgs = imgs.cuda()\n            imgs = Variable(imgs, volatile=True)\n            output = self.model(imgs)  # N C H W torch.Size([1, 1, 401, 600])\n            if self.flatten_feature:\n                output = output.view(output.size(0), -1)\n            output = output.data.cpu().numpy()\n\n            assert output.shape[0] == len(img_files)\n            for i, img_file in enumerate(img_files):\n                base_name = os.path.splitext(img_file)[0]\n                feature_file = os.path.join(self.feature_dir, base_name + "".npy"")\n                utils.create_dir(os.path.dirname(feature_file))\n                np.save(feature_file, output[i])\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n            if batch_idx % self.print_freq == 0:\n                log_str = \'Extract: [{0}/{1}]\\tTime: {batch_time.val:.3f} ({batch_time.avg:.3f})\'.format(\n                    batch_idx, len(self.val_loader), batch_time=batch_time)\n                print(log_str)\n                self.print_log(log_str)\n\n'"
trainer.py,2,"b'import datetime\nimport math\nimport os\nimport shutil\nimport psutil\nimport gc\nimport time\n\nimport numpy as np\nimport torch\nfrom torch.autograd import Variable\n\nimport utils\nimport tqdm\n\nclass Trainer(object):\n\n    def __init__(self, cmd, cuda, model, criterion, optimizer,\n                 train_loader, val_loader, log_file, max_iter,\n                 interval_validate=None, lr_scheduler=None,\n                 checkpoint_dir=None, print_freq=1):\n        """"""\n        :param cuda:\n        :param model:\n        :param optimizer:\n        :param train_loader:\n        :param val_loader:\n        :param log_file: log file name. logs are appended to this file.\n        :param max_iter:\n        :param interval_validate:\n        :param checkpoint_dir:\n        :param lr_scheduler:\n        """"""\n\n\n        self.cmd = cmd\n        self.cuda = cuda\n\n        self.model = model\n        self.criterion = criterion\n        self.optim = optimizer\n        self.lr_scheduler = lr_scheduler\n\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        self.timestamp_start = datetime.datetime.now()\n\n        if cmd == \'train\':\n            self.interval_validate = len(self.train_loader) if interval_validate is None else interval_validate\n\n        self.epoch = 0\n        self.iteration = 0\n\n        self.max_iter = max_iter\n        self.best_top1 = 0\n        self.best_top5 = 0\n        self.print_freq = print_freq\n\n        self.checkpoint_dir = checkpoint_dir\n        self.log_file = log_file\n\n\n    def print_log(self, log_str):\n        with open(self.log_file, \'a\') as f:\n            f.write(log_str + \'\\n\')\n\n\n    def validate(self):\n        batch_time = utils.AverageMeter()\n        losses = utils.AverageMeter()\n        top1 = utils.AverageMeter()\n        top5 = utils.AverageMeter()\n\n        training = self.model.training\n        self.model.eval()\n\n        end = time.time()\n        for batch_idx, (imgs, target, img_files, class_ids) in tqdm.tqdm(\n                enumerate(self.val_loader), total=len(self.val_loader),\n                desc=\'Valid iteration={} epoch={}\'.format(self.iteration, self.epoch), ncols=80, leave=False):\n\n            gc.collect()\n            if self.cuda:\n                imgs, target = imgs.cuda(), target.cuda(async=True)\n            imgs = Variable(imgs, volatile=True)\n            target = Variable(target, volatile=True)\n\n            output = self.model(imgs)\n            loss = self.criterion(output, target)\n\n            if np.isnan(float(loss.data[0])):\n                raise ValueError(\'loss is nan while validating\')\n\n            # measure accuracy and record loss\n            prec1, prec5 = utils.accuracy(output.data, target.data, topk=(1, 5))\n            losses.update(loss.data[0], imgs.size(0))\n            top1.update(prec1[0], imgs.size(0))\n            top5.update(prec5[0], imgs.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n            if batch_idx % self.print_freq == 0:\n                log_str = \'Test: [{0}/{1}/{top1.count:}]\\tepoch: {epoch:}\\titer: {iteration:}\\t\' \\\n                      \'Time: {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\' \\\n                      \'Loss: {loss.val:.4f} ({loss.avg:.4f})\\t\' \\\n                      \'Prec@1: {top1.val:.3f} ({top1.avg:.3f})\\t\' \\\n                      \'Prec@5: {top5.val:.3f} ({top5.avg:.3f})\\t\'.format(\n                    batch_idx, len(self.val_loader), epoch=self.epoch, iteration=self.iteration,\n                    batch_time=batch_time, loss=losses, top1=top1, top5=top5)\n                print(log_str)\n                self.print_log(log_str)\n\n        if self.cmd == \'train\':\n            is_best = top1.avg > self.best_top1\n            self.best_top1 = max(top1.avg, self.best_top1)\n            self.best_top5 = max(top5.avg, self.best_top5)\n\n            log_str = \'Test_summary: [{0}/{1}/{top1.count:}] epoch: {epoch:} iter: {iteration:}\\t\' \\\n                  \'BestPrec@1: {best_top1:.3f}\\tBestPrec@5: {best_top5:.3f}\\t\' \\\n                  \'Time: {batch_time.avg:.3f}\\tLoss: {loss.avg:.4f}\\t\' \\\n                  \'Prec@1: {top1.avg:.3f}\\tPrec@5: {top5.avg:.3f}\\t\'.format(\n                batch_idx, len(self.val_loader), epoch=self.epoch, iteration=self.iteration,\n                best_top1=self.best_top1, best_top5=self.best_top5,\n                batch_time=batch_time, loss=losses, top1=top1, top5=top5)\n            print(log_str)\n            self.print_log(log_str)\n\n            checkpoint_file = os.path.join(self.checkpoint_dir, \'checkpoint.pth.tar\')\n            torch.save({\n                \'epoch\': self.epoch,\n                \'iteration\': self.iteration,\n                \'arch\': self.model.__class__.__name__,\n                \'optim_state_dict\': self.optim.state_dict(),\n                \'model_state_dict\': self.model.state_dict(),\n                \'best_top1\': self.best_top1,\n                \'batch_time\': batch_time,\n                \'losses\': losses,\n                \'top1\': top1,\n                \'top5\': top5,\n            }, checkpoint_file)\n            if is_best:\n                shutil.copy(checkpoint_file, os.path.join(self.checkpoint_dir, \'model_best.pth.tar\'))\n            if (self.epoch + 1) % 10 == 0: # save each 10 epoch\n                shutil.copy(checkpoint_file, os.path.join(self.checkpoint_dir, \'checkpoint-{}.pth.tar\'.format(self.epoch)))\n\n            if training:\n                self.model.train()\n\n    def train_epoch(self):\n        batch_time = utils.AverageMeter()\n        data_time = utils.AverageMeter()\n        losses = utils.AverageMeter()\n        top1 = utils.AverageMeter()\n        top5 = utils.AverageMeter()\n\n        self.model.train()\n        self.optim.zero_grad()\n\n        end = time.time()\n        for batch_idx, (imgs, target, img_files, class_ids) in tqdm.tqdm(\n                enumerate(self.train_loader), total=len(self.train_loader),\n                desc=\'Train epoch={}, iter={}\'.format(self.epoch, self.iteration), ncols=80, leave=False):\n            iteration = batch_idx + self.epoch * len(self.train_loader)\n            data_time.update(time.time() - end)\n\n            gc.collect()\n\n            if self.iteration != 0 and (iteration - 1) != self.iteration:\n                continue  # for resuming\n            self.iteration = iteration\n\n            if (self.iteration + 1) % self.interval_validate == 0:\n                self.validate()\n\n            if self.cuda:\n                imgs, target = imgs.cuda(), target.cuda(async=True)\n            imgs, target = Variable(imgs), Variable(target)\n\n            output = self.model(imgs)\n            loss = self.criterion(output, target)\n            if np.isnan(float(loss.data[0])):\n                raise ValueError(\'loss is nan while training\')\n\n            # measure accuracy and record loss\n            prec1, prec5 = utils.accuracy(output.data, target.data, topk=(1, 5))\n            losses.update(loss.data[0], imgs.size(0))\n            top1.update(prec1[0], imgs.size(0))\n            top5.update(prec5[0], imgs.size(0))\n\n            self.optim.zero_grad()\n            loss.backward()\n            self.optim.step()\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n            if self.iteration % self.print_freq == 0:\n                log_str = \'Train: [{0}/{1}/{top1.count:}]\\tepoch: {epoch:}\\titer: {iteration:}\\t\' \\\n                      \'Time: {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\' \\\n                      \'Data: {data_time.val:.3f} ({data_time.avg:.3f})\\t\' \\\n                      \'Loss: {loss.val:.4f} ({loss.avg:.4f})\\t\' \\\n                      \'Prec@1: {top1.val:.3f} ({top1.avg:.3f})\\t\' \\\n                      \'Prec@5: {top5.val:.3f} ({top5.avg:.3f})\\tlr {lr:.6f}\'.format(\n                    batch_idx, len(self.train_loader), epoch=self.epoch, iteration=self.iteration,\n                    lr=self.optim.param_groups[0][\'lr\'],\n                    batch_time=batch_time, data_time=data_time, loss=losses, top1=top1, top5=top5)\n                print(log_str)\n                self.print_log(log_str)\n\n            if self.lr_scheduler is not None:\n                self.lr_scheduler.step()  # update lr\n\n\n        log_str = \'Train_summary: [{0}/{1}/{top1.count:}]\\tepoch: {epoch:}\\titer: {iteration:}\\t\' \\\n                      \'Time: {batch_time.avg:.3f}\\tData: {data_time.avg:.3f}\\t\' \\\n                      \'Loss: {loss.avg:.4f}\\tPrec@1: {top1.avg:.3f}\\tPrec@5: {top5.avg:.3f}\\tlr {lr:.6f}\'.format(\n                    batch_idx, len(self.train_loader), epoch=self.epoch, iteration=self.iteration,\n                    lr=self.optim.param_groups[0][\'lr\'],\n                    batch_time=batch_time, data_time=data_time, loss=losses, top1=top1, top5=top5)\n        print(log_str)\n        self.print_log(log_str)\n\n\n    def train(self):\n        max_epoch = int(math.ceil(1. * self.max_iter / len(self.train_loader))) # 117\n        for epoch in tqdm.trange(self.epoch, max_epoch, desc=\'Train\', ncols=80):\n            self.epoch = epoch\n            self.train_epoch()\n            if self.iteration >= self.max_iter:\n                break\n\n\n\nclass Validator(Trainer):\n\n    def __init__(self, cmd, cuda, model, criterion, val_loader, log_file, print_freq=1):\n        super(Validator, self).__init__(cmd, cuda=cuda, model=model, criterion=criterion,\n                                        val_loader=val_loader, log_file=log_file, print_freq=print_freq,\n                                        optimizer=None, train_loader=None, max_iter=None,\n                                        interval_validate=None, lr_scheduler=None,\n                                        checkpoint_dir=None)\n\n    def train(self):\n        raise NotImplementedError\n\n'"
utils.py,2,"b'import pandas as pd\nimport csv\nimport os\nimport sys\nimport torch\nimport shutil\nimport pickle\n\ndef load_state_dict(model, fname):\n    """"""\n    Set parameters converted from Caffe models authors of VGGFace2 provide.\n    See https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/.\n\n    Arguments:\n        model: model\n        fname: file name of parameters converted from a Caffe model, assuming the file format is Pickle.\n    """"""\n    with open(fname, \'rb\') as f:\n        weights = pickle.load(f, encoding=\'latin1\')\n\n    own_state = model.state_dict()\n    for name, param in weights.items():\n        if name in own_state:\n            try:\n                own_state[name].copy_(torch.from_numpy(param))\n            except Exception:\n                raise RuntimeError(\'While copying the parameter named {}, whose dimensions in the model are {} and whose \'\\\n                                   \'dimensions in the checkpoint are {}.\'.format(name, own_state[name].size(), param.size()))\n        else:\n            raise KeyError(\'unexpected key ""{}"" in state_dict\'.format(name))\n\n\ndef get_id_label_map(meta_file):\n    N_IDENTITY = 9131  # total number of identities in VGG Face2\n    N_IDENTITY_PRETRAIN = 8631  # the number of identities used in training by Caffe\n    identity_list = meta_file\n    df = pd.read_csv(identity_list, sep=\',\\s+\', quoting=csv.QUOTE_ALL, encoding=""utf-8"")\n    df[""class""] = -1\n    df.loc[df[""Flag""] == 1, ""class""] = range(N_IDENTITY_PRETRAIN)\n    df.loc[df[""Flag""] == 0, ""class""] = range(N_IDENTITY_PRETRAIN, N_IDENTITY)\n    # print(df)\n    key = df[""Class_ID""].values\n    val = df[""class""].values\n    id_label_dict = dict(zip(key, val))\n    return id_label_dict\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef save_checkpoint(state, is_best, filename=\'checkpoint.pth.tar\'):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, \'model_best.pth.tar\')\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    output_sorted, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\ndef create_dir(dir_name):\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n'"
datasets/__init__.py,0,b'from .vgg_face2 import VGG_Faces2\n'
datasets/vgg_face2.py,2,"b'#!/usr/bin/env python\n\nimport collections\nimport os\n\nimport numpy as np\nimport PIL.Image\nimport scipy.io\nimport torch\nfrom torch.utils import data\nimport torchvision.transforms\n\nclass VGG_Faces2(data.Dataset):\n\n    mean_bgr = np.array([91.4953, 103.8827, 131.0912])  # from resnet50_ft.prototxt\n\n    def __init__(self, root, image_list_file, id_label_dict, split=\'train\', transform=True,\n                 horizontal_flip=False, upper=None):\n        """"""\n        :param root: dataset directory\n        :param image_list_file: contains image file names under root\n        :param id_label_dict: X[class_id] -> label\n        :param split: train or valid\n        :param transform: \n        :param horizontal_flip:\n        :param upper: max number of image used for debug\n        """"""\n        assert os.path.exists(root), ""root: {} not found."".format(root)\n        self.root = root\n        assert os.path.exists(image_list_file), ""image_list_file: {} not found."".format(image_list_file)\n        self.image_list_file = image_list_file\n        self.split = split\n        self._transform = transform\n        self.id_label_dict = id_label_dict\n        self.horizontal_flip = horizontal_flip\n\n        self.img_info = []\n        with open(self.image_list_file, \'r\') as f:\n            for i, img_file in enumerate(f):\n                img_file = img_file.strip()  # e.g. train/n004332/0317_01.jpg\n                class_id = img_file.split(""/"")[1]  # like n004332\n                label = self.id_label_dict[class_id]\n                self.img_info.append({\n                    \'cid\': class_id,\n                    \'img\': img_file,\n                    \'lbl\': label,\n                })\n                if i % 1000 == 0:\n                    print(""processing: {} images for {}"".format(i, self.split))\n                if upper and i == upper - 1:  # for debug purpose\n                    break\n\n    def __len__(self):\n        return len(self.img_info)\n\n    def __getitem__(self, index):\n        info = self.img_info[index]\n        img_file = info[\'img\']\n        img = PIL.Image.open(os.path.join(self.root, img_file))\n        img = torchvision.transforms.Resize(256)(img)\n        if self.split == \'train\':\n            img = torchvision.transforms.RandomCrop(224)(img)\n            img = torchvision.transforms.RandomGrayscale(p=0.2)(img)\n        else:\n            img = torchvision.transforms.CenterCrop(224)(img)\n        if self.horizontal_flip:\n            img = torchvision.transforms.functional.hflip(img)\n\n        img = np.array(img, dtype=np.uint8)\n        assert len(img.shape) == 3  # assumes color images and no alpha channel\n\n        label = info[\'lbl\']\n        class_id = info[\'cid\']\n        if self._transform:\n            return self.transform(img), label, img_file, class_id\n        else:\n            return img, label, img_file, class_id\n\n    def transform(self, img):\n        img = img[:, :, ::-1]  # RGB -> BGR\n        img = img.astype(np.float32)\n        img -= self.mean_bgr\n        img = img.transpose(2, 0, 1)  # C x H x W\n        img = torch.from_numpy(img).float()\n        return img\n\n    def untransform(self, img, lbl):\n        img = img.numpy()\n        img = img.transpose(1, 2, 0)\n        img += self.mean_bgr\n        img = img.astype(np.uint8)\n        img = img[:, :, ::-1]\n        return img, lbl\n\n'"
models/__init__.py,0,b''
models/resnet.py,1,"b'import torch.nn as nn\nimport math\n\n__all__ = [\'ResNet\', \'resnet50\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000, include_top=True):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.include_top = include_top\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        \n        if not self.include_top:\n            return x\n        \n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\ndef resnet50(**kwargs):\n    """"""Constructs a ResNet-50 model.\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    return model\n'"
models/senet.py,2,"b'import torch.nn as nn\nimport math\nimport torch.nn.functional as F\n\n__all__ = [\'SENet\', \'senet50\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n# This SEModule is not used.\nclass SEModule(nn.Module):\n\n    def __init__(self, planes, compress_rate):\n        super(SEModule, self).__init__()\n        self.conv1 = nn.Conv2d(planes, planes // compress_rate, kernel_size=1, stride=1, bias=True)\n        self.conv2 = nn.Conv2d(planes // compress_rate, planes, kernel_size=1, stride=1, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        module_input = x\n        x = F.avg_pool2d(module_input, kernel_size=module_input.size(2))\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.sigmoid(x)\n        return module_input * x\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n        # SENet\n        compress_rate = 16\n        # self.se_block = SEModule(planes * 4, compress_rate)  # this is not used.\n        self.conv4 = nn.Conv2d(planes * 4, planes * 4 // compress_rate, kernel_size=1, stride=1, bias=True)\n        self.conv5 = nn.Conv2d(planes * 4 // compress_rate, planes * 4, kernel_size=1, stride=1, bias=True)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n\n        ## senet\n        out2 = F.avg_pool2d(out, kernel_size=out.size(2))\n        out2 = self.conv4(out2)\n        out2 = self.relu(out2)\n        out2 = self.conv5(out2)\n        out2 = self.sigmoid(out2)\n        # out2 = self.se_block.forward(out)  # not used\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out = out2 * out + residual\n        # out = out2 + residual  # not used\n        out = self.relu(out)\n        return out\n\n\nclass SENet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000, include_top=True):\n        self.inplanes = 64\n        super(SENet, self).__init__()\n        self.include_top = include_top\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        \n        if not self.include_top:\n            return x\n        \n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\ndef senet50(**kwargs):\n    """"""Constructs a SENet-50 model.\n    """"""\n    model = SENet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    return model\n'"
