file_path,api_count,code
evaluate_awa2.py,6,"b""import argparse\nimport json\nimport os.path as osp\n\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom models.resnet import make_resnet50_base\nfrom datasets.image_folder import ImageFolder\nfrom utils import set_gpu, pick_vectors\n\n\ndef test_on_subset(dataset, cnn, n, pred_vectors, all_label,\n                   consider_trains):\n    hit = 0\n    tot = 0\n\n    loader = DataLoader(dataset=dataset, batch_size=32,\n                        shuffle=False, num_workers=2)\n\n    for batch_id, batch in enumerate(loader, 1):\n        data, label = batch \n        data = data.cuda()\n\n        feat = cnn(data) # (batch_size, d)\n        feat = torch.cat([feat, torch.ones(len(feat)).view(-1, 1).cuda()], dim=1)\n\n        fcs = pred_vectors.t()\n\n        table = torch.matmul(feat, fcs)\n        if not consider_trains:\n            table[:, :n] = -1e18\n\n        pred = torch.argmax(table, dim=1)\n        hit += (pred == all_label).sum().item()\n        tot += len(data)\n\n    return hit, tot\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--cnn')\n    parser.add_argument('--pred')\n\n    parser.add_argument('--gpu', default='0')\n    parser.add_argument('--consider-trains', action='store_true')\n\n    parser.add_argument('--output', default=None)\n    args = parser.parse_args()\n\n    set_gpu(args.gpu)\n\n    awa2_split = json.load(open('materials/awa2-split.json', 'r'))\n    train_wnids = awa2_split['train']\n    test_wnids = awa2_split['test']\n\n    print('train: {}, test: {}'.format(len(train_wnids), len(test_wnids)))\n    print('consider train classifiers: {}'.format(args.consider_trains))\n\n    pred_file = torch.load(args.pred)\n    pred_wnids = pred_file['wnids']\n    pred_vectors = pred_file['pred']\n    pred_dic = dict(zip(pred_wnids, pred_vectors))\n    pred_vectors = pick_vectors(pred_dic, train_wnids + test_wnids, is_tensor=True).cuda()\n    pred_vectors = pred_vectors.cuda()\n\n    n = len(train_wnids)\n    m = len(test_wnids)\n    \n    cnn = make_resnet50_base()\n    cnn.load_state_dict(torch.load(args.cnn))\n    cnn = cnn.cuda()\n    cnn.eval()\n\n    test_names = awa2_split['test_names']\n\n    ave_acc = 0; ave_acc_n = 0\n\n    results = {}\n\n    awa2_path = 'materials/datasets/awa2'\n\n    for i, name in enumerate(test_names, 1):\n        dataset = ImageFolder(osp.join(awa2_path, 'JPEGImages'), [name], 'test')\n        hit, tot = test_on_subset(dataset, cnn, n, pred_vectors, n + i - 1,\n                                  args.consider_trains)\n        acc = hit / tot\n        ave_acc += acc\n        ave_acc_n += 1\n\n        print('{} {}: {:.2f}%'.format(i, name.replace('+', ' '), acc * 100))\n        \n        results[name] = acc\n\n    print('summary: {:.2f}%'.format(ave_acc / ave_acc_n * 100))\n\n    if args.output is not None:\n        json.dump(results, open(args.output, 'w'))\n"""
evaluate_imagenet.py,8,"b""import argparse\nimport json\nimport os.path as osp\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nfrom models.resnet import make_resnet50_base\nfrom datasets.imagenet import ImageNet\nfrom utils import set_gpu, pick_vectors\n\n\ndef test_on_subset(dataset, cnn, n, pred_vectors, all_label,\n                   consider_trains):\n    top = [1, 2, 5, 10, 20]\n    hits = torch.zeros(len(top)).cuda()\n    tot = 0\n\n    loader = DataLoader(dataset=dataset, batch_size=32,\n                        shuffle=False, num_workers=2)\n\n    for batch_id, batch in enumerate(loader, 1):\n        data, label = batch \n        data = data.cuda()\n\n        feat = cnn(data) # (batch_size, d)\n        feat = torch.cat([feat, torch.ones(len(feat)).view(-1, 1).cuda()], dim=1)\n\n        fcs = pred_vectors.t()\n\n        table = torch.matmul(feat, fcs)\n        if not consider_trains:\n            table[:, :n] = -1e18\n\n        gth_score = table[:, all_label].repeat(table.shape[1], 1).t()\n        rks = (table >= gth_score).sum(dim=1)\n\n        assert (table[:, all_label] == gth_score[:, all_label]).min() == 1\n\n        for i, k in enumerate(top):\n            hits[i] += (rks <= k).sum().item()\n        tot += len(data)\n\n    return hits, tot\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--cnn')\n    parser.add_argument('--pred')\n\n    parser.add_argument('--test-set')\n\n    parser.add_argument('--output', default=None)\n\n    parser.add_argument('--gpu', default='0')\n\n    parser.add_argument('--keep-ratio', type=float, default=0.1)\n    parser.add_argument('--consider-trains', action='store_true')\n    parser.add_argument('--test-train', action='store_true')\n\n    args = parser.parse_args()\n\n    set_gpu(args.gpu)\n\n    test_sets = json.load(open('materials/imagenet-testsets.json', 'r'))\n    train_wnids = test_sets['train']\n    test_wnids = test_sets[args.test_set]\n\n    print('test set: {}, {} classes, ratio={}'\n          .format(args.test_set, len(test_wnids), args.keep_ratio))\n    print('consider train classifiers: {}'.format(args.consider_trains))\n\n    pred_file = torch.load(args.pred)\n    pred_wnids = pred_file['wnids']\n    pred_vectors = pred_file['pred']\n    pred_dic = dict(zip(pred_wnids, pred_vectors))\n    pred_vectors = pick_vectors(pred_dic, train_wnids + test_wnids, is_tensor=True).cuda()\n\n    pred_vectors = pred_vectors.cuda()\n\n    n = len(train_wnids)\n    m = len(test_wnids)\n    \n    cnn = make_resnet50_base()\n    cnn.load_state_dict(torch.load(args.cnn))\n    cnn = cnn.cuda()\n    cnn.eval()\n\n    TEST_TRAIN = args.test_train\n\n    imagenet_path = 'materials/datasets/imagenet'\n    dataset = ImageNet(imagenet_path)\n    dataset.set_keep_ratio(args.keep_ratio)\n\n    s_hits = torch.FloatTensor([0, 0, 0, 0, 0]).cuda() # top 1 2 5 10 20\n    s_tot = 0\n\n    results = {}\n\n    if TEST_TRAIN:\n        for i, wnid in enumerate(train_wnids, 1):\n            subset = dataset.get_subset(wnid)\n            hits, tot = test_on_subset(subset, cnn, n, pred_vectors, i - 1,\n                                       consider_trains=args.consider_trains)\n            results[wnid] = (hits / tot).tolist()\n\n            s_hits += hits\n            s_tot += tot\n\n            print('{}/{}, {}:'.format(i, len(train_wnids), wnid), end=' ')\n            for i in range(len(hits)):\n                print('{:.0f}%({:.2f}%)'\n                      .format(hits[i] / tot * 100, s_hits[i] / s_tot * 100), end=' ')\n            print('x{}({})'.format(tot, s_tot))\n    else:\n        for i, wnid in enumerate(test_wnids, 1):\n            subset = dataset.get_subset(wnid)\n            hits, tot = test_on_subset(subset, cnn, n, pred_vectors, n + i - 1,\n                                       consider_trains=args.consider_trains)\n            results[wnid] = (hits / tot).tolist()\n\n            s_hits += hits\n            s_tot += tot\n\n            print('{}/{}, {}:'.format(i, len(test_wnids), wnid), end=' ')\n            for i in range(len(hits)):\n                print('{:.0f}%({:.2f}%)'\n                      .format(hits[i] / tot * 100, s_hits[i] / s_tot * 100), end=' ')\n            print('x{}({})'.format(tot, s_tot))\n\n    print('summary:', end=' ')\n    for s_hit in s_hits:\n        print('{:.2f}%'.format(s_hit / s_tot * 100), end=' ')\n    print('total {}'.format(s_tot))\n\n    if args.output is not None:\n        json.dump(results, open(args.output, 'w'))\n\n"""
train_gcn_basic.py,7,"b""import argparse\nimport json\nimport random\nimport os.path as osp\n\nimport torch\nimport torch.nn.functional as F\n\nfrom utils import ensure_path, set_gpu, l2_loss\nfrom models.gcn import GCN\n\n\ndef save_checkpoint(name):\n    torch.save(gcn.state_dict(), osp.join(save_path, name + '.pth'))\n    torch.save(pred_obj, osp.join(save_path, name + '.pred'))\n\n\ndef mask_l2_loss(a, b, mask):\n    return l2_loss(a[mask], b[mask])\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('--max-epoch', type=int, default=3000)\n    parser.add_argument('--trainval', default='10,0')\n    parser.add_argument('--lr', type=float, default=0.001)\n    parser.add_argument('--weight-decay', type=float, default=0.0005)\n    parser.add_argument('--save-epoch', type=int, default=300)\n    parser.add_argument('--save-path', default='save/gcn-basic')\n\n    parser.add_argument('--gpu', default='0')\n\n    parser.add_argument('--no-pred', action='store_true')\n    args = parser.parse_args()\n\n    set_gpu(args.gpu)\n\n    save_path = args.save_path\n    ensure_path(save_path)\n\n    graph = json.load(open('materials/imagenet-induced-graph.json', 'r'))\n    wnids = graph['wnids']\n    n = len(wnids)\n    edges = graph['edges']\n    \n    edges = edges + [(v, u) for (u, v) in edges]\n    edges = edges + [(u, u) for u in range(n)]\n\n    word_vectors = torch.tensor(graph['vectors']).cuda()\n    word_vectors = F.normalize(word_vectors)\n\n    fcfile = json.load(open('materials/fc-weights.json', 'r'))\n    train_wnids = [x[0] for x in fcfile]\n    fc_vectors = [x[1] for x in fcfile]\n    assert train_wnids == wnids[:len(train_wnids)]\n    fc_vectors = torch.tensor(fc_vectors).cuda()\n    fc_vectors = F.normalize(fc_vectors)\n\n    hidden_layers = 'd2048,d'\n    gcn = GCN(n, edges, word_vectors.shape[1], fc_vectors.shape[1], hidden_layers).cuda()\n\n    print('{} nodes, {} edges'.format(n, len(edges)))\n    print('word vectors:', word_vectors.shape)\n    print('fc vectors:', fc_vectors.shape)\n    print('hidden layers:', hidden_layers)\n\n    optimizer = torch.optim.Adam(gcn.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n\n    v_train, v_val = map(float, args.trainval.split(','))\n    n_trainval = len(fc_vectors)\n    n_train = round(n_trainval * (v_train / (v_train + v_val)))\n    print('num train: {}, num val: {}'.format(n_train, n_trainval - n_train))\n    tlist = list(range(len(fc_vectors)))\n    random.shuffle(tlist)\n\n    min_loss = 1e18\n\n    trlog = {}\n    trlog['train_loss'] = []\n    trlog['val_loss'] = []\n    trlog['min_loss'] = 0\n\n    for epoch in range(1, args.max_epoch + 1):\n        gcn.train()\n        output_vectors = gcn(word_vectors)\n        loss = mask_l2_loss(output_vectors, fc_vectors, tlist[:n_train])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        gcn.eval()\n        output_vectors = gcn(word_vectors)\n        train_loss = mask_l2_loss(output_vectors, fc_vectors, tlist[:n_train]).item()\n        if v_val > 0:\n            val_loss = mask_l2_loss(output_vectors, fc_vectors, tlist[n_train:]).item()\n            loss = val_loss\n        else:\n            val_loss = 0\n            loss = train_loss\n        print('epoch {}, train_loss={:.4f}, val_loss={:.4f}'\n              .format(epoch, train_loss, val_loss))\n\n        trlog['train_loss'].append(train_loss)\n        trlog['val_loss'].append(val_loss)\n        trlog['min_loss'] = min_loss\n        torch.save(trlog, osp.join(save_path, 'trlog'))\n\n        if (epoch % args.save_epoch == 0):\n            if args.no_pred:\n                pred_obj = None\n            else:\n                pred_obj = {\n                    'wnids': wnids,\n                    'pred': output_vectors\n                }\n\n        if epoch % args.save_epoch == 0:\n            save_checkpoint('epoch-{}'.format(epoch))\n        \n        pred_obj = None\n\n"""
train_gcn_dense.py,7,"b""import argparse\nimport json\nimport random\nimport os.path as osp\n\nimport torch\nimport torch.nn.functional as F\n\nfrom utils import ensure_path, set_gpu, l2_loss\nfrom models.gcn_dense import GCN_Dense\n\n\ndef save_checkpoint(name):\n    torch.save(gcn.state_dict(), osp.join(save_path, name + '.pth'))\n    torch.save(pred_obj, osp.join(save_path, name + '.pred'))\n\n\ndef mask_l2_loss(a, b, mask):\n    return l2_loss(a[mask], b[mask])\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('--max-epoch', type=int, default=3000)\n    parser.add_argument('--trainval', default='10,0')\n    parser.add_argument('--lr', type=float, default=0.001)\n    parser.add_argument('--weight-decay', type=float, default=0.0005)\n    parser.add_argument('--save-epoch', type=int, default=300)\n    parser.add_argument('--save-path', default='save/gcn-dense')\n\n    parser.add_argument('--gpu', default='0')\n\n    parser.add_argument('--no-pred', action='store_true')\n    args = parser.parse_args()\n\n    set_gpu(args.gpu)\n\n    save_path = args.save_path\n    ensure_path(save_path)\n\n    graph = json.load(open('materials/imagenet-dense-graph.json', 'r'))\n    wnids = graph['wnids']\n    n = len(wnids)\n    edges = graph['edges']\n    \n    word_vectors = torch.tensor(graph['vectors']).cuda()\n    word_vectors = F.normalize(word_vectors)\n\n    fcfile = json.load(open('materials/fc-weights.json', 'r'))\n    train_wnids = [x[0] for x in fcfile]\n    fc_vectors = [x[1] for x in fcfile]\n    assert train_wnids == wnids[:len(train_wnids)]\n    fc_vectors = torch.tensor(fc_vectors).cuda()\n    fc_vectors = F.normalize(fc_vectors)\n\n    hidden_layers = 'd2048,d'\n    gcn = GCN_Dense(n, edges, word_vectors.shape[1], fc_vectors.shape[1], hidden_layers).cuda()\n\n    print('{} nodes, {} edges'.format(n, len(edges)))\n    print('word vectors:', word_vectors.shape)\n    print('fc vectors:', fc_vectors.shape)\n    print('hidden layers:', hidden_layers)\n\n    optimizer = torch.optim.Adam(gcn.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n\n    v_train, v_val = map(float, args.trainval.split(','))\n    n_trainval = len(fc_vectors)\n    n_train = round(n_trainval * (v_train / (v_train + v_val)))\n    print('num train: {}, num val: {}'.format(n_train, n_trainval - n_train))\n    tlist = list(range(len(fc_vectors)))\n    random.shuffle(tlist)\n\n    min_loss = 1e18\n\n    trlog = {}\n    trlog['train_loss'] = []\n    trlog['val_loss'] = []\n    trlog['min_loss'] = 0\n\n    for epoch in range(1, args.max_epoch + 1):\n        gcn.train()\n        output_vectors = gcn(word_vectors)\n        loss = mask_l2_loss(output_vectors, fc_vectors, tlist[:n_train])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        gcn.eval()\n        output_vectors = gcn(word_vectors)\n        train_loss = mask_l2_loss(output_vectors, fc_vectors, tlist[:n_train]).item()\n        if v_val > 0:\n            val_loss = mask_l2_loss(output_vectors, fc_vectors, tlist[n_train:]).item()\n            loss = val_loss\n        else:\n            val_loss = 0\n            loss = train_loss\n        print('epoch {}, train_loss={:.4f}, val_loss={:.4f}'\n              .format(epoch, train_loss, val_loss))\n\n        trlog['train_loss'].append(train_loss)\n        trlog['val_loss'].append(val_loss)\n        trlog['min_loss'] = min_loss\n        torch.save(trlog, osp.join(save_path, 'trlog'))\n\n        if (epoch % args.save_epoch == 0):\n            if args.no_pred:\n                pred_obj = None\n            else:\n                pred_obj = {\n                    'wnids': wnids,\n                    'pred': output_vectors\n                }\n\n        if epoch % args.save_epoch == 0:\n            save_checkpoint('epoch-{}'.format(epoch))\n\n        pred_obj = None\n\n"""
train_gcn_dense_att.py,7,"b""import argparse\nimport json\nimport random\nimport os.path as osp\n\nimport torch\nimport torch.nn.functional as F\n\nfrom utils import ensure_path, set_gpu, l2_loss\nfrom models.gcn_dense_att import GCN_Dense_Att\n\n\ndef save_checkpoint(name):\n    torch.save(gcn.state_dict(), osp.join(save_path, name + '.pth'))\n    torch.save(pred_obj, osp.join(save_path, name + '.pred'))\n\n\ndef mask_l2_loss(a, b, mask):\n    return l2_loss(a[mask], b[mask])\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('--max-epoch', type=int, default=3000)\n    parser.add_argument('--trainval', default='10,0')\n    parser.add_argument('--lr', type=float, default=0.001)\n    parser.add_argument('--weight-decay', type=float, default=0.0005)\n    parser.add_argument('--save-epoch', type=int, default=300)\n    parser.add_argument('--save-path', default='save/gcn-dense-att')\n\n    parser.add_argument('--gpu', default='0')\n\n    parser.add_argument('--no-pred', action='store_true')\n    args = parser.parse_args()\n\n    set_gpu(args.gpu)\n\n    save_path = args.save_path\n    ensure_path(save_path)\n\n    graph = json.load(open('materials/imagenet-dense-grouped-graph.json', 'r'))\n    wnids = graph['wnids']\n    n = len(wnids)\n\n    edges_set = graph['edges_set']\n    print('edges_set', [len(l) for l in edges_set])\n\n    lim = 4\n    for i in range(lim + 1, len(edges_set)):\n        edges_set[lim].extend(edges_set[i])\n    edges_set = edges_set[:lim + 1]\n    print('edges_set', [len(l) for l in edges_set])\n    \n    word_vectors = torch.tensor(graph['vectors']).cuda()\n    word_vectors = F.normalize(word_vectors)\n\n    fcfile = json.load(open('materials/fc-weights.json', 'r'))\n    train_wnids = [x[0] for x in fcfile]\n    fc_vectors = [x[1] for x in fcfile]\n    assert train_wnids == wnids[:len(train_wnids)]\n    fc_vectors = torch.tensor(fc_vectors).cuda()\n    fc_vectors = F.normalize(fc_vectors)\n\n    hidden_layers = 'd2048,d'\n    gcn = GCN_Dense_Att(n, edges_set,\n                        word_vectors.shape[1], fc_vectors.shape[1], hidden_layers).cuda()\n\n    print('word vectors:', word_vectors.shape)\n    print('fc vectors:', fc_vectors.shape)\n    print('hidden layers:', hidden_layers)\n\n    optimizer = torch.optim.Adam(gcn.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n\n    v_train, v_val = map(float, args.trainval.split(','))\n    n_trainval = len(fc_vectors)\n    n_train = round(n_trainval * (v_train / (v_train + v_val)))\n    print('num train: {}, num val: {}'.format(n_train, n_trainval - n_train))\n    tlist = list(range(len(fc_vectors)))\n    random.shuffle(tlist)\n\n    min_loss = 1e18\n\n    trlog = {}\n    trlog['train_loss'] = []\n    trlog['val_loss'] = []\n    trlog['min_loss'] = 0\n\n    for epoch in range(1, args.max_epoch + 1):\n        gcn.train()\n        output_vectors = gcn(word_vectors)\n        loss = mask_l2_loss(output_vectors, fc_vectors, tlist[:n_train])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        gcn.eval()\n        output_vectors = gcn(word_vectors)\n        train_loss = mask_l2_loss(output_vectors, fc_vectors, tlist[:n_train]).item()\n        if v_val > 0:\n            val_loss = mask_l2_loss(output_vectors, fc_vectors, tlist[n_train:]).item()\n            loss = val_loss\n        else:\n            val_loss = 0\n            loss = train_loss\n        print('epoch {}, train_loss={:.4f}, val_loss={:.4f}'\n              .format(epoch, train_loss, val_loss))\n\n        trlog['train_loss'].append(train_loss)\n        trlog['val_loss'].append(val_loss)\n        trlog['min_loss'] = min_loss\n        torch.save(trlog, osp.join(save_path, 'trlog'))\n\n        if (epoch % args.save_epoch == 0):\n            if args.no_pred:\n                pred_obj = None\n            else:\n                pred_obj = {\n                    'wnids': wnids,\n                    'pred': output_vectors\n                }\n\n        if epoch % args.save_epoch == 0:\n            save_checkpoint('epoch-{}'.format(epoch))\n\n        pred_obj = None\n\n"""
train_resnet_fit.py,9,"b""import argparse\nimport json\nimport os\nimport os.path as osp\n\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\nfrom utils import set_gpu, ensure_path\nfrom models.resnet import ResNet\nfrom datasets.image_folder import ImageFolder\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--pred')\n    parser.add_argument('--train-dir')\n    parser.add_argument('--save-path', default='save/resnet-fit')\n    parser.add_argument('--gpu', default='0')\n    args = parser.parse_args()\n\n    set_gpu(args.gpu)\n    save_path = args.save_path\n    ensure_path(save_path)\n\n    pred = torch.load(args.pred)\n    train_wnids = sorted(os.listdir(args.train_dir))\n\n    train_dir = args.train_dir\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n    train_dataset = datasets.ImageFolder(train_dir, transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize]))\n    loader = torch.utils.data.DataLoader(\n            train_dataset, batch_size=64, shuffle=True,\n            num_workers=4, pin_memory=True, sampler=None)\n\n    assert pred['wnids'][:1000] == train_wnids\n\n    model = ResNet('resnet50', 1000)\n    sd = model.resnet_base.state_dict()\n    sd.update(torch.load('materials/resnet50-base.pth'))\n    model.resnet_base.load_state_dict(sd)\n\n    fcw = pred['pred'][:1000].cpu()\n    model.fc.weight = nn.Parameter(fcw[:, :-1])\n    model.fc.bias = nn.Parameter(fcw[:, -1])\n\n    model = model.cuda()\n    model.train()\n\n    optimizer = torch.optim.SGD(model.resnet_base.parameters(), lr=0.0001, momentum=0.9)\n    loss_fn = nn.CrossEntropyLoss().cuda()\n    \n    keep_ratio = 0.9975\n    trlog = {}\n    trlog['loss'] = []\n    trlog['acc'] = []\n\n    for epoch in range(1, 9999):\n\n        ave_loss = None\n        ave_acc = None\n\n        for i, (data, label) in enumerate(loader, 1):\n            data = data.cuda()\n            label = label.cuda()\n\n            logits = model(data)\n            loss = loss_fn(logits, label)\n\n            _, pred = torch.max(logits, dim=1)\n            acc = torch.eq(pred, label).type(torch.FloatTensor).mean().item()\n\n            if i == 1:\n                ave_loss = loss.item()\n                ave_acc = acc\n            else:\n                ave_loss = ave_loss * keep_ratio + loss.item() * (1 - keep_ratio)\n                ave_acc = ave_acc * keep_ratio + acc * (1 - keep_ratio)\n\n            print('epoch {}, {}/{}, loss={:.4f} ({:.4f}), acc={:.4f} ({:.4f})'\n                  .format(epoch, i, len(loader), loss.item(), ave_loss, acc, ave_acc))\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        trlog['loss'].append(ave_loss)\n        trlog['acc'].append(ave_acc)\n\n        torch.save(trlog, osp.join(save_path, 'trlog'))\n\n        torch.save(model.resnet_base.state_dict(),\n                   osp.join(save_path, 'epoch-{}.pth'.format(epoch)))\n\n"""
utils.py,7,"b""import os\nimport os.path as osp\nimport shutil\n\nimport numpy as np\nimport scipy.sparse as sp\nimport torch\n\n\ndef ensure_path(path):\n    if osp.exists(path):\n        if input('{} exists, remove? ([y]/n)'.format(path)) != 'n':\n            shutil.rmtree(path)\n            os.mkdir(path)\n    else:\n        os.mkdir(path)\n\n\ndef set_gpu(gpu):\n    os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n    print('using gpu {}'.format(gpu))\n\n\ndef pick_vectors(dic, wnids, is_tensor=False):\n    o = next(iter(dic.values()))\n    dim = len(o)\n    ret = []\n    for wnid in wnids:\n        v = dic.get(wnid)\n        if v is None:\n            if not is_tensor:\n                v = [0] * dim\n            else:\n                v = torch.zeros(dim)\n        ret.append(v)\n    if not is_tensor:\n        return torch.FloatTensor(ret)\n    else:\n        return torch.stack(ret)\n\n\ndef l2_loss(a, b):\n    return ((a - b)**2).sum() / (len(a) * 2)\n\n\ndef normt_spm(mx, method='in'):\n    if method == 'in':\n        mx = mx.transpose()\n        rowsum = np.array(mx.sum(1))\n        r_inv = np.power(rowsum, -1).flatten()\n        r_inv[np.isinf(r_inv)] = 0.\n        r_mat_inv = sp.diags(r_inv)\n        mx = r_mat_inv.dot(mx)\n        return mx\n\n    if method == 'sym':\n        rowsum = np.array(mx.sum(1))\n        r_inv = np.power(rowsum, -0.5).flatten()\n        r_inv[np.isinf(r_inv)] = 0.\n        r_mat_inv = sp.diags(r_inv)\n        mx = mx.dot(r_mat_inv).transpose().dot(r_mat_inv)\n        return mx\n\n\ndef spm_to_tensor(sparse_mx):\n    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n    indices = torch.from_numpy(np.vstack(\n            (sparse_mx.row, sparse_mx.col))).long()\n    values = torch.from_numpy(sparse_mx.data)\n    shape = torch.Size(sparse_mx.shape)\n    return torch.sparse.FloatTensor(indices, values, shape)\n\n"""
datasets/__init__.py,0,b'\n'
datasets/image_folder.py,1,"b""import os\nimport os.path as osp\n\nfrom PIL import Image\nimport torch\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset\n\n\nclass ImageFolder(Dataset):\n\n    def __init__(self, path, classes, stage='train'):\n        self.data = []\n        for i, c in enumerate(classes):\n            cls_path = osp.join(path, c)\n            images = os.listdir(cls_path)\n            for image in images:\n                self.data.append((osp.join(cls_path, image), i))\n\n        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                         std=[0.229, 0.224, 0.225])\n        \n        if stage == 'train':\n            self.transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n                                                  transforms.RandomHorizontalFlip(),\n                                                  transforms.ToTensor(),\n                                                  normalize])\n        if stage == 'test':\n            self.transforms = transforms.Compose([transforms.Resize(256),\n                                                  transforms.CenterCrop(224),\n                                                  transforms.ToTensor(),\n                                                  normalize])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        path, label = self.data[i]\n        image = Image.open(path).convert('RGB')\n        image = self.transforms(image)\n        if image.shape[0] != 3 or image.shape[1] != 224 or image.shape[2] != 224:\n            print('you should delete this guy:', path)\n        return image, label\n\n"""
datasets/imagenet.py,2,"b""import json\nimport os\nimport os.path as osp\nimport random\n\nimport torch\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\n\nfrom PIL import Image\nfrom torchvision import get_image_backend\n\n\nclass ImageNet():\n\n    def __init__(self, path):\n        self.path = path\n        self.keep_ratio = 1.0\n    \n    def get_subset(self, wnid):\n        path = osp.join(self.path, wnid)\n        return ImageNetSubset(path, wnid, keep_ratio=self.keep_ratio)\n\n    def set_keep_ratio(self, r):\n        self.keep_ratio = r\n\n\nclass ImageNetSubset(Dataset):\n\n    def __init__(self, path, wnid, keep_ratio=1.0):\n        self.wnid = wnid\n\n        def pil_loader(path):\n            with open(path, 'rb') as f:\n                try:\n                    img = Image.open(f)\n                except OSError:\n                    return None\n                return img.convert('RGB')\n\n        def accimage_loader(path):\n            import accimage\n            try:\n                return accimage.Image(path)\n            except IOError:\n                return pil_loader(path)\n\n        def default_loader(path):\n            if get_image_backend() == 'accimage':\n                return accimage_loader(path)\n            else:\n                return pil_loader(path)\n\n        # get file list\n        all_files = os.listdir(path)\n        files = []\n        for f in all_files:\n            if f.endswith('.JPEG'):\n                files.append(f)\n        random.shuffle(files)\n        files = files[:max(1, round(len(files) * keep_ratio))]\n\n        # read images\n        data = []\n        for filename in files:\n            image = default_loader(osp.join(path, filename))\n            if image is None:\n                continue\n            # pytorch model-zoo pre-process\n            preprocess = transforms.Compose([\n                transforms.Resize(256),\n                transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n            ])\n            data.append(preprocess(image))\n        if data != []:\n            self.data = torch.stack(data) \n        else:\n            self.data = []\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.wnid\n\n"""
materials/glove.py,2,"b""import torch\n\n\nclass GloVe():\n\n    def __init__(self, file_path):\n        self.dimension = None\n        self.embedding = dict()\n        with open(file_path, 'r') as f:\n            for line in f.readlines():\n                strs = line.strip().split()\n                word = strs[0]\n                vector = torch.FloatTensor(list(map(float, strs[1:])))\n                self.embedding[word] = vector\n                if self.dimension is None:\n                    self.dimension = len(vector)\n\n    def _fix_word(self, word):\n        terms = word.replace('_', ' ').split(' ')\n        ret = self.zeros()\n        cnt = 0\n        for term in terms:\n            v = self.embedding.get(term)\n            if v is None:\n                subterms = term.split('-')\n                subterm_sum = self.zeros()\n                subterm_cnt = 0\n                for subterm in subterms:\n                    subv = self.embedding.get(subterm)\n                    if subv is not None:\n                        subterm_sum += subv\n                        subterm_cnt += 1\n                if subterm_cnt > 0:\n                    v = subterm_sum / subterm_cnt\n            if v is not None:\n                ret += v\n                cnt += 1\n        return ret / cnt if cnt > 0 else None\n\n    def __getitem__(self, words):\n        if type(words) is str:\n            words = [words]\n        ret = self.zeros()\n        cnt = 0\n        for word in words:\n            v = self.embedding.get(word)\n            if v is None:\n                v = self._fix_word(word)\n            if v is not None:\n                ret += v\n                cnt += 1\n        if cnt > 0:\n            return ret / cnt\n        else:\n            return self.zeros()\n    \n    def zeros(self):\n        return torch.zeros(self.dimension)\n \n"""
materials/make_dense_graph.py,0,"b""import argparse\nimport json\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--input', default='imagenet-induced-graph.json')\nparser.add_argument('--output', default='imagenet-dense-graph.json')\nargs = parser.parse_args()\n\njs = json.load(open(args.input, 'r'))\nwnids = js['wnids']\nvectors = js['vectors']\nedges = js['edges']\n\nn = len(wnids)\nadjs = {}\nfor i in range(n):\n    adjs[i] = []\nfor u, v in edges:\n    adjs[u].append(v)\n\nnew_edges = []\n\nfor u, wnid in enumerate(wnids):\n    q = [u]\n    l = 0\n    d = {}\n    d[u] = 0\n    while l < len(q):\n        x = q[l]\n        l += 1\n        for y in adjs[x]:\n            if d.get(y) is None:\n                d[y] = d[x] + 1\n                q.append(y)\n    for x, dis in d.items():\n        new_edges.append((u, x))\n\njson.dump({'wnids': wnids, 'vectors': vectors, 'edges': new_edges},\n          open(args.output, 'w'))\n\n"""
materials/make_dense_grouped_graph.py,0,"b""import argparse\nimport json\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--input', default='imagenet-induced-graph.json')\nparser.add_argument('--output', default='imagenet-dense-grouped-graph.json')\nargs = parser.parse_args()\n\njs = json.load(open(args.input, 'r'))\nwnids = js['wnids']\nvectors = js['vectors']\nedges = js['edges']\n\nn = len(wnids)\nadjs = {}\nfor i in range(n):\n    adjs[i] = []\nfor u, v in edges:\n    adjs[u].append(v)\n\nnew_edges = [[] for i in range(99)]\n\nfor u, wnid in enumerate(wnids):\n    q = [u]\n    l = 0\n    d = {}\n    d[u] = 0\n    while l < len(q):\n        x = q[l]\n        l += 1\n        for y in adjs[x]:\n            if d.get(y) is None:\n                d[y] = d[x] + 1\n                q.append(y)\n    for x, dis in d.items():\n        new_edges[dis].append((u, x))\n\nwhile new_edges[-1] == []:\n    new_edges.pop()\n\njson.dump({'wnids': wnids, 'vectors': vectors, 'edges_set': new_edges},\n          open(args.output, 'w'))\n\n"""
materials/make_induced_graph.py,1,"b""import argparse\nimport json\n\nfrom nltk.corpus import wordnet as wn\nimport torch\n\nfrom glove import GloVe\n\n\ndef getnode(x):\n    return wn.synset_from_pos_and_offset('n', int(x[1:]))\n\n\ndef getwnid(u):\n    s = str(u.offset())\n    return 'n' + (8 - len(s)) * '0' + s\n\n\ndef getedges(s):\n    dic = {x: i for i, x in enumerate(s)}\n    edges = []\n    for i, u in enumerate(s):\n        for v in u.hypernyms():\n            j = dic.get(v)\n            if j is not None:\n                edges.append((i, j))\n    return edges\n\n\ndef induce_parents(s, stop_set):\n    q = s\n    vis = set(s)\n    l = 0\n    while l < len(q):\n        u = q[l]\n        l += 1\n        if u in stop_set:\n            continue\n        for p in u.hypernyms():\n            if p not in vis:\n                vis.add(p)\n                q.append(p)\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input', default='imagenet-split.json')\n    parser.add_argument('--output', default='imagenet-induced-graph.json')\n    args = parser.parse_args()\n\n    print('making graph ...')\n\n    xml_wnids = json.load(open('imagenet-xml-wnids.json', 'r'))\n    xml_nodes = list(map(getnode, xml_wnids))\n    xml_set = set(xml_nodes)\n\n    js = json.load(open(args.input, 'r'))\n    train_wnids = js['train']\n    test_wnids = js['test']\n\n    key_wnids = train_wnids + test_wnids\n\n    s = list(map(getnode, key_wnids))\n    induce_parents(s, xml_set)\n\n    s_set = set(s)\n    for u in xml_nodes:\n        if u not in s_set:\n            s.append(u)\n\n    wnids = list(map(getwnid, s))\n    edges = getedges(s)\n\n    print('making glove embedding ...')\n\n    glove = GloVe('glove.6B.300d.txt')\n    vectors = []\n    for wnid in wnids:\n        vectors.append(glove[getnode(wnid).lemma_names()])\n    vectors = torch.stack(vectors)\n\n    print('dumping ...')\n\n    obj = {}\n    obj['wnids'] = wnids\n    obj['vectors'] = vectors.tolist()\n    obj['edges'] = edges\n    json.dump(obj, open(args.output, 'w'))\n\n"""
materials/process_resnet.py,4,"b""import json\nimport torch\nimport torch.nn.functional as F\n\np = torch.load('resnet50-raw.pth')\nw = p['fc.weight'].data\nb = p['fc.bias'].data\n\np.pop('fc.weight')\np.pop('fc.bias')\ntorch.save(p, 'resnet50-base.pth')\n\nv = torch.cat([w, b.unsqueeze(1)], dim=1).tolist()\nwnids = json.load(open('imagenet-split.json', 'r'))['train']\nwnids = sorted(wnids)\nobj = []\nfor i in range(len(wnids)):\n    obj.append((wnids[i], v[i]))\njson.dump(obj, open('fc-weights.json', 'w'))\n\n"""
models/__init__.py,0,b'\n'
models/gcn.py,6,"b""import numpy as np\nimport scipy.sparse as sp\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.init import xavier_uniform_\n\nfrom utils import normt_spm, spm_to_tensor\n\n\nclass GraphConv(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dropout=False, relu=True):\n        super().__init__()\n\n        if dropout:\n            self.dropout = nn.Dropout(p=0.5)\n        else:\n            self.dropout = None\n\n        self.w = nn.Parameter(torch.empty(in_channels, out_channels))\n        self.b = nn.Parameter(torch.zeros(out_channels))\n        xavier_uniform_(self.w)\n\n        if relu:\n            self.relu = nn.LeakyReLU(negative_slope=0.2)\n        else:\n            self.relu = None\n\n    def forward(self, inputs, adj):\n        if self.dropout is not None:\n            inputs = self.dropout(inputs)\n\n        outputs = torch.mm(adj, torch.mm(inputs, self.w)) + self.b\n\n        if self.relu is not None:\n            outputs = self.relu(outputs)\n        return outputs\n\n\nclass GCN(nn.Module):\n\n    def __init__(self, n, edges, in_channels, out_channels, hidden_layers):\n        super().__init__()\n\n        edges = np.array(edges)\n        adj = sp.coo_matrix((np.ones(len(edges)), (edges[:, 0], edges[:, 1])),\n                            shape=(n, n), dtype='float32')\n        adj = normt_spm(adj, method='in')\n        adj = spm_to_tensor(adj)\n        self.adj = adj.cuda()\n\n        hl = hidden_layers.split(',')\n        if hl[-1] == 'd':\n            dropout_last = True\n            hl = hl[:-1]\n        else:\n            dropout_last = False\n\n        i = 0\n        layers = []\n        last_c = in_channels\n        for c in hl:\n            if c[0] == 'd':\n                dropout = True\n                c = c[1:]\n            else:\n                dropout = False\n            c = int(c)\n\n            i += 1\n            conv = GraphConv(last_c, c, dropout=dropout)\n            self.add_module('conv{}'.format(i), conv)\n            layers.append(conv)\n\n            last_c = c\n\n        conv = GraphConv(last_c, out_channels, relu=False, dropout=dropout_last)\n        self.add_module('conv-last', conv)\n        layers.append(conv)\n\n        self.layers = layers\n\n    def forward(self, x):\n        for conv in self.layers:\n            x = conv(x, self.adj)\n        return F.normalize(x)\n\n"""
models/gcn_dense.py,6,"b""import numpy as np\nimport scipy.sparse as sp\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.init import xavier_uniform_\n\nfrom utils import normt_spm, spm_to_tensor\n\n\nclass GraphConv(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dropout=False, relu=True):\n        super().__init__()\n\n        if dropout:\n            self.dropout = nn.Dropout(p=0.5)\n        else:\n            self.dropout = None\n\n        self.w = nn.Parameter(torch.empty(in_channels, out_channels))\n        self.b = nn.Parameter(torch.zeros(out_channels))\n        xavier_uniform_(self.w)\n\n        if relu:\n            self.relu = nn.LeakyReLU(negative_slope=0.2)\n        else:\n            self.relu = None\n\n    def forward(self, inputs, adj):\n        if self.dropout is not None:\n            inputs = self.dropout(inputs)\n\n        outputs = torch.mm(adj, torch.mm(inputs, self.w)) + self.b\n\n        if self.relu is not None:\n            outputs = self.relu(outputs)\n        return outputs\n\n\nclass GCN_Dense(nn.Module):\n\n    def __init__(self, n, edges, in_channels, out_channels, hidden_layers):\n        super().__init__()\n\n        edges = np.array(edges)\n        adj = sp.coo_matrix((np.ones(len(edges)), (edges[:, 0], edges[:, 1])),\n                            shape=(n, n), dtype='float32')\n        self.adj = spm_to_tensor(normt_spm(adj, method='in')).cuda()\n        self.r_adj = spm_to_tensor(normt_spm(adj.transpose(), method='in')).cuda()\n\n        hl = hidden_layers.split(',')\n        if hl[-1] == 'd':\n            dropout_last = True\n            hl = hl[:-1]\n        else:\n            dropout_last = False\n\n        i = 0\n        layers = []\n        last_c = in_channels\n        for c in hl:\n            if c[0] == 'd':\n                dropout = True\n                c = c[1:]\n            else:\n                dropout = False\n            c = int(c)\n\n            i += 1\n            conv = GraphConv(last_c, c, dropout=dropout)\n            self.add_module('conv{}'.format(i), conv)\n            layers.append(conv)\n\n            last_c = c\n\n        conv = GraphConv(last_c, out_channels, relu=False, dropout=dropout_last)\n        self.add_module('conv-last', conv)\n        layers.append(conv)\n\n        self.layers = layers\n\n    def forward(self, x):\n        graph_side = True\n        for conv in self.layers:\n            if graph_side:\n                x = conv(x, self.adj)\n            else:\n                x = conv(x, self.r_adj)\n            graph_side = not graph_side\n        return F.normalize(x)\n\n"""
models/gcn_dense_att.py,9,"b""import numpy as np\nimport scipy.sparse as sp\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.init import xavier_uniform_\n\nfrom utils import normt_spm, spm_to_tensor\n\n\nclass GraphConv(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dropout=False, relu=True):\n        super().__init__()\n\n        if dropout:\n            self.dropout = nn.Dropout(p=0.5)\n        else:\n            self.dropout = None\n\n        self.w = nn.Parameter(torch.empty(in_channels, out_channels))\n        self.b = nn.Parameter(torch.zeros(out_channels))\n        xavier_uniform_(self.w)\n\n        if relu:\n            self.relu = nn.LeakyReLU(negative_slope=0.2)\n        else:\n            self.relu = None\n\n    def forward(self, inputs, adj_set, att):\n        if self.dropout is not None:\n            inputs = self.dropout(inputs)\n\n        support = torch.mm(inputs, self.w) + self.b\n        outputs = None\n        for i, adj in enumerate(adj_set):\n            y = torch.mm(adj, support) * att[i]\n            if outputs is None:\n                outputs = y\n            else:\n                outputs = outputs + y\n\n        if self.relu is not None:\n            outputs = self.relu(outputs)\n        return outputs\n\n\nclass GCN_Dense_Att(nn.Module):\n\n    def __init__(self, n, edges_set, in_channels, out_channels, hidden_layers):\n        super().__init__()\n\n        self.n = n\n        self.d = len(edges_set)\n\n        self.a_adj_set = []\n        self.r_adj_set = []\n\n        for edges in edges_set:\n            edges = np.array(edges)\n            adj = sp.coo_matrix((np.ones(len(edges)), (edges[:, 0], edges[:, 1])),\n                                shape=(n, n), dtype='float32')\n            a_adj = spm_to_tensor(normt_spm(adj, method='in')).cuda()\n            r_adj = spm_to_tensor(normt_spm(adj.transpose(), method='in')).cuda()\n            self.a_adj_set.append(a_adj)\n            self.r_adj_set.append(r_adj)\n\n        hl = hidden_layers.split(',')\n        if hl[-1] == 'd':\n            dropout_last = True\n            hl = hl[:-1]\n        else:\n            dropout_last = False\n\n        self.a_att = nn.Parameter(torch.ones(self.d))\n        self.r_att = nn.Parameter(torch.ones(self.d))\n\n        i = 0\n        layers = []\n        last_c = in_channels\n        for c in hl:\n            if c[0] == 'd':\n                dropout = True\n                c = c[1:]\n            else:\n                dropout = False\n            c = int(c)\n\n            i += 1\n            conv = GraphConv(last_c, c, dropout=dropout)\n            self.add_module('conv{}'.format(i), conv)\n            layers.append(conv)\n\n            last_c = c\n\n        conv = GraphConv(last_c, out_channels, relu=False, dropout=dropout_last)\n        self.add_module('conv-last', conv)\n        layers.append(conv)\n\n        self.layers = layers\n\n    def forward(self, x):\n        graph_side = True\n        for conv in self.layers:\n            if graph_side:\n                adj_set = self.a_adj_set\n                att = self.a_att\n            else:\n                adj_set = self.r_adj_set\n                att = self.r_att\n            att = F.softmax(att, dim=0)\n            x = conv(x, adj_set, att)\n            graph_side = not graph_side\n\n        return F.normalize(x)\n\n"""
models/resnet.py,7,"b'import math\n\nimport torch\nimport torch.nn as nn\n\n\n__all__ = [\'ResNetBase\', \'make_resnet_base\', \'ResNet\']\n\n\n\'\'\'\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\'\'\'\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass ResNetBase(nn.Module):\n\n    def __init__(self, block, layers):\n        self.inplanes = 64\n        super(ResNetBase, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        self.out_channels = 512 * block.expansion\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers) \n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x) \n        x = self.layer2(x) \n        x = self.layer3(x) \n        x = self.layer4(x) \n\n        x = x.view(x.shape[0], x.shape[1], -1).mean(dim=2)\n        return x\n\n\ndef make_resnet18_base(**kwargs):\n    """"""Constructs a ResNet-18 model.\n    """"""\n    model = ResNetBase(BasicBlock, [2, 2, 2, 2], **kwargs)\n    return model\n\n\ndef make_resnet34_base(**kwargs):\n    """"""Constructs a ResNet-34 model.\n    """"""\n    model = ResNetBase(BasicBlock, [3, 4, 6, 3], **kwargs)\n    return model\n\n\ndef make_resnet50_base(**kwargs):\n    """"""Constructs a ResNet-50 model.\n    """"""\n    model = ResNetBase(Bottleneck, [3, 4, 6, 3], **kwargs)\n    return model\n\n\ndef make_resnet101_base(**kwargs):\n    """"""Constructs a ResNet-101 model.\n    """"""\n    model = ResNetBase(Bottleneck, [3, 4, 23, 3], **kwargs)\n    return model\n\n\ndef make_resnet152_base(**kwargs):\n    """"""Constructs a ResNet-152 model.\n    """"""\n    model = ResNetBase(Bottleneck, [3, 8, 36, 3], **kwargs)\n    return model\n\n\ndef make_resnet_base(version, pretrained=None):\n    maker = {\n        \'resnet18\': make_resnet18_base,\n        \'resnet34\': make_resnet34_base,\n        \'resnet50\': make_resnet50_base,\n        \'resnet101\': make_resnet101_base,\n        \'resnet152\': make_resnet152_base\n    }\n    resnet = maker[version]()\n    if pretrained is not None:\n        sd = torch.load(pretrained)\n        sd.pop(\'fc.weight\')\n        sd.pop(\'fc.bias\')\n        resnet.load_state_dict(sd)\n    return resnet\n\n\nclass ResNet(nn.Module):\n    \n    def __init__(self, version, num_classes, pretrained=None):\n        super().__init__()\n        self.resnet_base = make_resnet_base(version, pretrained=pretrained)\n        self.fc = nn.Linear(self.resnet_base.out_channels, num_classes)\n\n    def forward(self, x, need_features=False):\n        x = self.resnet_base(x)\n        feat = x\n        x = self.fc(x)\n        if need_features:\n            return x, feat\n        else:\n            return x\n\n'"
