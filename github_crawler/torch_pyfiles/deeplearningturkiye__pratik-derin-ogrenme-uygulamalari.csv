file_path,api_count,code
KERAS/CNN_Fashion_Mnist.py,0,"b""#Deep Learning T\xc3\xbcrkiye toplulu\xc4\x9fu taraf\xc4\xb1ndan haz\xc4\xb1rlanm\xc4\xb1\xc5\x9ft\xc4\xb1r.\r\n#Ama\xc3\xa7: K\xc4\xb1yafetlerin tan\xc4\xb1mlanmas\xc4\xb1\r\n#Veriseti: Fashion-Mnist\r\n#Algoritma : Evri\xc5\x9fimli Sinir A\xc4\x9flar\xc4\xb1 (Convolutional Neural Networks)\r\n#Haz\xc4\xb1rlayan: Can UMAY\r\n\r\n#Gerekli k\xc3\xbct\xc3\xbcphanelerimizi i\xc3\xa7eri aktar\xc4\xb1yoruz.\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\r\nfrom keras.datasets import fashion_mnist\r\nfrom keras.utils.np_utils import to_categorical\r\n\r\n#E\xc4\x9fitim ve test verilerimizi aktar\xc4\xb1yoruz.\r\n(inp_train, out_train),(inp_test, out_test)=fashion_mnist.load_data()\r\n#Inp_ olarak tan\xc4\xb1mlanan de\xc4\x9fi\xc5\x9fkenlerimizin boyutlar\xc4\xb1n\xc4\xb1 d\xc3\xbczenliyoruz.\r\ninp_train=inp_train.reshape(-1,28,28,1)\r\ninp_test=inp_test.reshape(-1,28,28,1)\r\n#Daha sonra ondal\xc4\xb1k hale \xc3\xa7eviriyoruz.\r\ninp_train=inp_train.astype('float32')\r\ninp_test=inp_test.astype('float32')\r\n#Modelimizin daha optimize \xc3\xa7al\xc4\xb1\xc5\x9fmas\xc4\xb1 i\xc3\xa7in de\xc4\x9ferlerimizi 0 ile 1 aras\xc4\xb1na indirgiyoruz.\r\ninp_train=inp_train/255.0\r\ninp_test=inp_test/255.0\r\n#Out_ olarak tan\xc4\xb1mlanan de\xc4\x9fi\xc5\x9fkenleri ise one-hot-encoding haline getiriyoruz.\r\nout_train=to_categorical(out_train)\r\nout_test=to_categorical(out_test)\r\n\r\n#Modelimizi olu\xc5\x9fturmaya ba\xc5\x9fl\xc4\xb1yoruz.\r\nmodel=Sequential()\r\n# 3x3'l\xc3\xbck 32 filtreli ve relu aktivasyon fonksiyonlu ilk Conv2D katman\xc4\xb1m\xc4\xb1z\xc4\xb1 olu\xc5\x9fturuyoruz.\r\nmodel.add(Conv2D(32,(3,3),input_shape=(28,28,1), activation='relu'))\r\n# 3x3'l\xc3\xbck 32 filtreli ve relu aktivasyon fonksiyonlu ikinci Conv2D katman\xc4\xb1m\xc4\xb1z\xc4\xb1 olu\xc5\x9fturuyoruz.\r\nmodel.add(Conv2D(32, (3,3), activation='relu'))\r\n# 2x2 pool size'\xc4\xb1 bulunan MaxPooling2D i\xc5\x9flemi ger\xc3\xa7ekle\xc5\x9ftiriyoruz.\r\nmodel.add(MaxPooling2D(pool_size=(2,2)))\r\n# Flatten ile modelimizin Fully Connected k\xc4\xb1sm\xc4\xb1na ba\xc4\x9fl\xc4\xb1yoruz.\r\nmodel.add(Flatten())\r\n# Fully Connected b\xc3\xb6l\xc3\xbcm\xc3\xbcn\xc3\xbcn ilk katman\xc4\xb1n\xc4\xb1 olu\xc5\x9fturuyoruz.\r\nmodel.add(Dense(64, activation='relu'))\r\n# Son katman\xc4\xb1m\xc4\xb1z\xc4\xb1 10 n\xc3\xb6ron ile olu\xc5\x9fturuyoruz \xc3\xa7\xc3\xbcnk\xc3\xbc 10 s\xc4\xb1n\xc4\xb1f\xc4\xb1m\xc4\xb1z var.\r\nmodel.add(Dense(10, activation='softmax'))\r\n\r\n#Modeli compile edelim.\r\nmodel.compile(optimizer='rmsprop',\r\n              loss='categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\n#Art\xc4\xb1k modeli e\xc4\x9fitebiliriz.\r\nmodel.fit(inp_train,\r\n          out_train,\r\n          verbose=1,\r\n          epochs=15,\r\n          validation_split=0.2)\r\n\r\n#Correction olarak olu\xc5\x9fturdu\xc4\x9fumuz de\xc4\x9fi\xc5\x9fken ile modelimizin do\xc4\x9fruluk oran\xc4\xb1n\xc4\xb1 \xc3\xb6l\xc3\xa7elim.\r\ncorrection=model.evaluate(inp_test.reshape(-1,28,28,1),out_test, verbose=1)\r\nprint('Yitim de\xc4\x9feri (loss): {}'.format(correction[0]))\r\nprint('Test ba\xc5\x9far\xc4\xb1s\xc4\xb1 (accuracy): {}'.format(correction[1]))"""
KERAS/nesne_tanima_CNN_CIFAR10.py,0,"b'# -*- coding: utf-8 -*- \n\'\'\'\nDeep Learning T\xc3\xbcrkiye toplulu\xc4\x9fu taraf\xc4\xb1ndan haz\xc4\xb1rlanm\xc4\xb1\xc5\x9ft\xc4\xb1r.\n\nAma\xc3\xa7: Foto\xc4\x9fraftaki nesneyi s\xc4\xb1n\xc4\xb1fland\xc4\xb1rmak.\nVeriseti: CIFAR10 (https://www.cs.toronto.edu/~kriz/cifar.html)\nAlgoritma: Evri\xc5\x9fimli Sinir A\xc4\x9flar\xc4\xb1 (Convolutional Neural Networks)\n\nE\xc4\x9fer arkaplanda TensorFlow kullan\xc4\xb1yorsan\xc4\xb1z otomatik olarak GPU kullan\xc4\xb1lacakt\xc4\xb1r.\nTheano arkaplan\xc4\xb1nda GPU kullanarak \xc3\xa7al\xc4\xb1\xc5\x9ft\xc4\xb1rmak i\xc3\xa7in gereken komut:\nTHEANO_FLAGS=mode=FAST_RUN,device=gpu,floatx=float32 python cifar10_cnn.py\n\n25 epoch sonunda hata oran\xc4\xb1 0.65\'e, 50 epoch sonunda 0.55\'e d\xc3\xbc\xc5\x9f\xc3\xbcr\xc3\xbcld\xc3\xbc.\n(Bu durumda hala yetersiz durumda.)\n\'\'\'\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nimport numpy as np\nimport os\n\nbatch_size = 32 # Her iterasyonda 32 foto\xc4\x9fraf al\xc4\xb1n\xc4\xb1r.\nnum_classes = 10 # CIFAR10 veri setinde 10 s\xc4\xb1n\xc4\xb1f bulunmakta.\nepochs = 200 # 200 epoch ile e\xc4\x9fitim yap\xc4\xb1lacakt\xc4\xb1r.\ndata_augmentation = True # Canl\xc4\xb1 veri artt\xc4\xb1rmas\xc4\xb1 yap\xc4\xb1lacakt\xc4\xb1r.\nsave_dir = os.path.join(os.getcwd(), \'saved_models\') # Modelin kaydedilece\xc4\x9fi yer belirlenir.\nmodel_name = \'keras_cifar10_trained_model.h5\' # Kaydedilecek modelin dosya ad\xc4\xb1 belirlenir.\n\n# Veri kar\xc4\xb1\xc5\x9ft\xc4\xb1r\xc4\xb1l\xc4\xb1r ve train-test \xc5\x9feklinde b\xc3\xb6l\xc3\xbcn\xc3\xbcr.\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\') # E\xc4\x9fitim i\xc3\xa7in \xc3\xb6rnek say\xc4\xb1s\xc4\xb1.\nprint(x_test.shape[0], \'test samples\') # Test i\xc3\xa7in \xc3\xb6rnek say\xc4\xb1s\xc4\xb1.\n\n# S\xc4\xb1n\xc4\xb1flar ikili (binary) formununa d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcl\xc3\xbcr.\n# ""to_catogorical"" fonksiyonu ile one-hot-encoding yap\xc4\xb1lmakta.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\n# 32 adet 3x3 boyutunda filtereler olu\xc5\x9fturulur ve modele eklenir.\n# ""Padding"" foto\xc4\x9frafa \xc3\xa7erv\xc3\xa7eve ekler ve \xc3\xa7\xc4\xb1k\xc4\xb1\xc5\x9f boyutunun giri\xc5\x9f boyutuna e\xc5\x9fit olmas\xc4\xb1 sa\xc4\x9flan\xc4\xb1r.\nmodel.add(Conv2D(32, (3, 3), padding=\'same\',\n                 input_shape=x_train.shape[1:]))\n# ReLu aktivasyon fonksiyonumuzu ekliyoruz:\nmodel.add(Activation(\'relu\'))\n# 32 adet 3x3 boyutunda filterelerden olu\xc5\x9fan katman\xc4\xb1m\xc4\xb1z\xc4\xb1 modelimize ekliyoruz:\nmodel.add(Conv2D(32, (3, 3)))\n# ReLu aktivasyon fonksiyonumuzu ekliyoruz:\nmodel.add(Activation(\'relu\'))\n# 2x2 boyutunda \xc3\xa7er\xc3\xa7eveden olu\xc5\x9fan MaxPooling katman\xc4\xb1m\xc4\xb1z\xc4\xb1 ekliyoruz:\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Rastgele olacak \xc5\x9fekilde n\xc3\xb6ronlar\xc4\xb1n %25\'ini kapat\xc4\xb1yoruz: (E\xc4\x9fitim s\xc4\xb1ras\xc4\xb1ndaki ezberlemeyi \xc3\xb6nlemek i\xc3\xa7in.)\nmodel.add(Dropout(0.25))\n\n# 64 adet 3x3 boyutunda filterelerden olu\xc5\x9fan katman\xc4\xb1m\xc4\xb1z\xc4\xb1 modelimize ekliyoruz:\nmodel.add(Conv2D(64, (3, 3), padding=\'same\'))\n# ReLu aktivasyon fonksiyonumuzu ekliyoruz:\nmodel.add(Activation(\'relu\'))\n# 64 adet 3x3 boyutunda filterelerden olu\xc5\x9fan katman\xc4\xb1m\xc4\xb1z\xc4\xb1 modelimize ekliyoruz:\nmodel.add(Conv2D(64, (3, 3)))\n# ReLu aktivasyon fonksiyonumuzu ekliyoruz:\nmodel.add(Activation(\'relu\'))\n# 2x2 boyutunda \xc3\xa7er\xc3\xa7eveden olu\xc5\x9fan MaxPooling katman\xc4\xb1m\xc4\xb1z\xc4\xb1 ekliyoruz:\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Rastgele olacak \xc5\x9fekilde n\xc3\xb6ronlar\xc4\xb1n %25\'ini kapat\xc4\xb1yoruz:\nmodel.add(Dropout(0.25))\n\n# 2 boyutlu g\xc3\xb6rsellerimizi 1 boyutlu vekt\xc3\xb6re \xc3\xa7eviriyoruz:\nmodel.add(Flatten())\n# 512 n\xc3\xb6ronumuzu modelimize ekliyoruz:\nmodel.add(Dense(512))\n# ReLu aktivasyon fonksiyonumuzu ekliyoruz:\nmodel.add(Activation(\'relu\'))\n# Rastgele olacak \xc5\x9fekilde n\xc3\xb6ronlar\xc4\xb1n %50\'sini kapat\xc4\xb1yoruz:\nmodel.add(Dropout(0.5))\n# 10 s\xc4\xb1n\xc4\xb1f\xc4\xb1m\xc4\xb1z\xc4\xb1 temsil edecek 10 n\xc3\xb6ronumuzu modelimize ekliyoruz:\nmodel.add(Dense(num_classes)) # num_classes = 10\n# S\xc4\xb1n\xc4\xb1flar\xc4\xb1n olas\xc4\xb1l\xc4\xb1klar\xc4\xb1n\xc4\xb1 hesaplamak i\xc3\xa7in ""Softmax"" fonksiyonumuzu ekliyoruz:\nmodel.add(Activation(\'softmax\'))\n\n# ""RMSprop"" optimizasyon fonksiyonumuzu haz\xc4\xb1rl\xc4\xb1yoruz:\nopt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n\n# Modeli e\xc4\x9fitirken kullanaca\xc4\x9f\xc4\xb1m\xc4\xb1z optimizasyon ve hata hesaplama fonksiyonumuzu belirliyoruz:\n# S\xc4\xb1n\xc4\xb1fland\xc4\xb1rma yapaca\xc4\x9f\xc4\xb1m\xc4\xb1z i\xc3\xa7in ""categorical_crossentropy"" fonksiyonunu kullan\xc4\xb1yoruz.\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=opt,\n              metrics=[\'accuracy\'])\n\n# Verimizi kesirli hale \xc3\xa7eviriyoruz: (\xc3\x96rne\xc4\x9fin: 255 -> 255.0)\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\n# Verimizi forma sokuyoruz. (\xc3\x96rne\xc4\x9fin: 255.0 -> 1.0)\nx_train /= 255\nx_test /= 255\n\nif not data_augmentation:\n    # Veri artt\xc4\xb1rma i\xc5\x9flemi yap\xc4\xb1lmayacak ise:\n    print(\'Not using data augmentation.\')\n    # Modelimize verilerimizi veriyoruz ve e\xc4\x9fitimimizi ba\xc5\x9flat\xc4\xb1yoruz:\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True)\nelse:\n    # Veri artt\xc4\xb1rma i\xc5\x9flemi yap\xc4\xb1lacak ise:\n    print(\'Using real-time data augmentation.\')\n    # Canl\xc4\xb1 veri artt\xc4\xb1rmak i\xc3\xa7in ayarlar\xc4\xb1m\xc4\xb1z\xc4\xb1 yap\xc4\xb1yoruz:\n    datagen = ImageDataGenerator(\n                                 featurewise_center=False,\n                                 samplewise_center=False,\n                                 featurewise_std_normalization=False,\n                                 samplewise_std_normalization=False,\n                                 zca_whitening=False,\n                                 rotation_range=0,\n                                 width_shift_range=0.1,  # G\xc3\xb6r\xc3\xbcnt\xc3\xbcleri rasgele olarak yatay olarak kayd\xc4\xb1r\xc4\xb1n.\n                                 height_shift_range=0.1,  # G\xc3\xb6r\xc3\xbcnt\xc3\xbcleri rasgele olarak dikey olarak kayd\xc4\xb1r\xc4\xb1n.\n                                 horizontal_flip=True,  # Foto\xc4\x9fraf\xc4\xb1 yatay d\xc3\xbczlemde rastgele \xc3\xa7evirme.\n                                 vertical_flip=False)\n\n    # Veri olu\xc5\x9fturma i\xc3\xa7in hesaplama\n    datagen.fit(x_train)\n\n    # Canl\xc4\xb1 olarak artt\xc4\xb1r\xc4\xb1lan veri ile modelimizi e\xc4\x9fitelim:\n    model.fit_generator(datagen.flow(x_train, y_train,\n                                     batch_size=batch_size),\n                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n                        epochs=epochs,\n                        validation_data=(x_test, y_test),\n                        workers=4)\n\n# E\xc4\x9fitilmi\xc5\x9f modelimizi kaydedelim:\nif not os.path.isdir(save_dir):\n    # Klas\xc3\xb6r yoksa olu\xc5\x9fturulur:\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint(\'Saved trained model at %s \' % model_path)\n\n# Modelimizin ba\xc5\x9far\xc4\xb1s\xc4\xb1n\xc4\xb1 \xc3\xb6l\xc3\xa7elim:\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint(\'Test loss:\', scores[0])\nprint(\'Test accuracy:\', scores[1])\n'"
KERAS/nesne_tanima_CNN_CIFAR10_RESNET.py,0,"b'\n""""""\nAma\xc3\xa7: Verilen g\xc3\xb6rseldeki nesmeyi tan\xc4\xb1mak\nY\xc3\xb6ntem: CIFAR10 veri seti \xc3\xbczerinde ResNet e\xc4\x9fitmek\nVeriseti: CIFAR10 (https://www.cs.toronto.edu/~kriz/cifar.html)\nAlgoritma: Evri\xc5\x9fimli Sinir A\xc4\x9flar\xc4\xb1 (Convolutional Neural Networks)\n\n50 epoch sonunda 91% \xc3\xbczerinde test do\xc4\x9fruluk oran\xc4\xb1 elde ediliyor.\nGTX 1080Ti kullanarak her bir epoch 48 saniye s\xc3\xbcr\xc3\xbcyor.\n""""""\n\nfrom __future__ import print_function\nimport keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import MaxPooling2D, AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.datasets import cifar10\nimport numpy as np\nimport os\n\n# Parametrelerin e\xc4\x9fitilmesi\nbatch_size = 32\nepochs = 100\ndata_augmentation = True\n\n# A\xc4\x9f mimarisi parametreleri\nnum_classes = 10\nnum_filters = 64\nnum_blocks = 4\nnum_sub_blocks = 2\nuse_max_pool = False\n\n# Veri setinin y\xc3\xbcklenip e\xc4\x9fitim/test olarak ayr\xc4\xb1lmas\xc4\xb1\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Giri\xc5\x9f resimlerinin boyutlar\xc4\xb1\n# Varsay\xc4\xb1lan veri format\xc4\xb1 ""channels_last"".\nimg_rows = x_train.shape[1]\nimg_cols = x_train.shape[2]\nchannels = x_train.shape[3]\n\nif K.image_data_format() == \'channels_first\':\n    img_rows = x_train.shape[2]\n    img_cols = x_train.shape[3]\n    channels = x_train.shape[1]\n    x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n    input_shape = (channels, img_rows, img_cols)\nelse:\n    img_rows = x_train.shape[1]\n    img_cols = x_train.shape[2]\n    channels = x_train.shape[3]\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n    input_shape = (img_rows, img_cols, channels)\n\n# Verinin kesirli hale getirilip normalle\xc5\x9ftirilmesi\nx_train = x_train.astype(\'float32\') / 255\nx_test = x_test.astype(\'float32\') / 255\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\nprint(\'y_train shape:\', y_train.shape)\n\n# S\xc4\xb1n\xc4\xb1f vekt\xc3\xb6rlerinin ikili s\xc4\xb1n\xc4\xb1f matrislerine d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbclmesi\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n# Start model definition.\ninputs = Input(shape=input_shape)\nx = Conv2D(num_filters,\n           kernel_size=7,\n           padding=\'same\',\n           strides=2,\n           kernel_initializer=\'he_normal\',\n           kernel_regularizer=l2(1e-4))(inputs)\nx = BatchNormalization()(x)\nx = Activation(\'relu\')(x)\n\n# Orjinal makale 1. evri\xc5\x9fimden sonra max pool metodunu kullanmaktad\xc4\xb1r.\n# use_max_pool = True oldu\xc4\x9funda do\xc4\x9fruluk oran\xc4\xb1 87%\'ye kadar \xc3\xa7\xc4\xb1k\xc4\xb1yor.\n# Cifar10 veri setinin resimleri max pool metodunu kullanmak i\xc3\xa7in \xc3\xa7ok k\xc3\xbc\xc3\xa7\xc3\xbck(32x32). Bu nedenle bu y\xc3\xb6ntemi atl\xc4\xb1yoruz.\nif use_max_pool:\n    x = MaxPooling2D(pool_size=3, strides=2, padding=\'same\')(x)\n    num_blocks = 3\n\n# Modelin temelinin olu\xc5\x9fturulmas\xc4\xb1\nfor i in range(num_blocks):\n    for j in range(num_sub_blocks):\n        strides = 1\n        is_first_layer_but_not_first_block = j == 0 and i > 0\n        if is_first_layer_but_not_first_block:\n            strides = 2\n        y = Conv2D(num_filters,\n                   kernel_size=3,\n                   padding=\'same\',\n                   strides=strides,\n                   kernel_initializer=\'he_normal\',\n                   kernel_regularizer=l2(1e-4))(x)\n        y = BatchNormalization()(y)\n        y = Activation(\'relu\')(y)\n        y = Conv2D(num_filters,\n                   kernel_size=3,\n                   padding=\'same\',\n                   kernel_initializer=\'he_normal\',\n                   kernel_regularizer=l2(1e-4))(y)\n        y = BatchNormalization()(y)\n        if is_first_layer_but_not_first_block:\n            x = Conv2D(num_filters,\n                       kernel_size=1,\n                       padding=\'same\',\n                       strides=2,\n                       kernel_initializer=\'he_normal\',\n                       kernel_regularizer=l2(1e-4))(x)\n        x = keras.layers.add([x, y])\n        x = Activation(\'relu\')(x)\n\n    num_filters = 2 * num_filters\n\n# S\xc4\xb1n\xc4\xb1fland\xc4\xb1r\xc4\xb1c\xc4\xb1n\xc4\xb1n en ba\xc5\x9fa eklenmesi\nx = AveragePooling2D()(x)\ny = Flatten()(x)\noutputs = Dense(num_classes,\n                activation=\'softmax\',\n                kernel_initializer=\'he_normal\')(y)\n\n# Modelin olu\xc5\x9fturulup derlenmesi\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=Adam(),\n              metrics=[\'accuracy\'])\nmodel.summary()\n\n# Model dizinin haz\xc4\xb1rlan\xc4\xb1p, kaydedilmesi\nsave_dir = os.path.join(os.getcwd(), \'saved_models\')\nmodel_name = \'cifar10_resnet_model.h5\'\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath = os.path.join(save_dir, model_name)\n\n# Prepare callbacks for model saving and for learning rate decaying.\n# Modelin kaydedilmesi ve \xc3\xb6\xc4\x9frenme de\xc4\x9ferinin azalt\xc4\xb1lmas\xc4\xb1 i\xc3\xa7in geri\xc3\xa7a\xc4\x9f\xc4\xb1r\xc4\xb1mlar\xc4\xb1n haz\xc4\xb1rlanmas\xc4\xb1\ncheckpoint = ModelCheckpoint(filepath=filepath,\n                             verbose=1,\n                             save_best_only=True)\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\ncallbacks = [checkpoint, lr_reducer]\n\n# E\xc4\x9fitimin ba\xc5\x9flat\xc4\xb1lmas\xc4\xb1. Veri artt\xc4\xb1rma ile ya da veri artt\xc4\xb1rma olmaks\xc4\xb1z\xc4\xb1n.\nif not data_augmentation:\n    print(\'Not using data augmentation.\')\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True,\n              callbacks=callbacks)\nelse:\n    print(\'Using real-time data augmentation.\')\n    # \xc3\x96n i\xc5\x9fleme ve ger\xc3\xa7ek zamanl\xc4\xb1 veri artt\xc4\xb1r\xc4\xb1m\xc4\xb1n\xc4\xb1n uygulanmas\xc4\xb1\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # Giri\xc5\x9f verilerinin prtalamas\xc4\xb1n\xc4\xb1n 0\'lanmas\xc4\xb1\n        samplewise_center=False,  # Herbir \xc3\xb6rnek verinin ortalamas\xc4\xb1n\xc4\xb1n 0\'a e\xc5\x9fitlenmesi\n        featurewise_std_normalization=False, # Giri\xc5\x9f verilerinin, veri setinin standart varyans de\xc4\x9ferine b\xc3\xb6l\xc3\xbcnmesi\n        samplewise_std_normalization=False,  # Herbir verinin standart varyans de\xc4\x9ferine b\xc3\xb6l\xc3\xbcnmesi\n        zca_whitening=False,  # ""ZCA whitening"" metodunun uygulanmas\xc4\xb1\n        rotation_range=0,  # Resimlerin bir s\xc4\xb1n\xc4\xb1r aral\xc4\xb1\xc4\x9f\xc4\xb1nda geli\xc5\x9fi g\xc3\xbczel d\xc3\xb6nd\xc3\xbcr\xc3\xbclmesi (degrees, 0 to 180)\n        width_shift_range=0.1,  # Resimlerin geli\xc5\x9fig\xc3\xbczel bir \xc5\x9fekilde yatay olarak kayd\xc4\xb1r\xc4\xb1lmas\xc4\xb1 (toplam geni\xc5\x9fli\xc4\x9fin b\xc3\xb6l\xc3\xbcm\xc3\xbc)\n        height_shift_range=0.1,  # Resimlerin geli\xc5\x9fig\xc3\xbczel bir \xc5\x9fekilde dikey olarak kayd\xc4\xb1r\xc4\xb1lmas\xc4\xb1(toplam y\xc3\xbcksekli\xc4\x9fin b\xc3\xb6l\xc3\xbcm\xc3\xbc)\n        horizontal_flip=True,  # Resimlerin geli\xc5\x9fig\xc3\xbczel bir \xc5\x9fekilde yatay olarak \xc3\xa7evirilmesi\n        vertical_flip=False)  # Resimlerin geli\xc5\x9fig\xc3\xbczel bir \xc5\x9fekilde dikey olarak \xc3\xa7evirilmesi\n\n    # Normalizasyon gerekliliklerinin hesaplanmas\xc4\xb1\n    # (standart varyans, ortalama, ve as\xc4\xb1l bile\xc5\x9fenler e\xc4\x9fer ""ZCA whitening"" uygulan\xc4\xb1yorsa).\n    datagen.fit(x_train)\n\n    # Fit the model on the batches generated by datagen.flow().\n    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n                        validation_data=(x_test, y_test),\n                        epochs=epochs, verbose=1, workers=4,\n                        callbacks=callbacks)\n\n# E\xc4\x9fitilmi\xc5\x9f modelin ba\xc5\x9far\xc4\xb1s\xc4\xb1n\xc4\xb1n \xc3\xb6l\xc3\xa7\xc3\xbclmesi\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint(\'Test loss:\', scores[0])\nprint(\'Test accuracy:\', scores[1])'"
KERAS/rakam_tanima_CNN_MNIST.py,0,"b'# -*- coding: utf-8 -*- \n\'\'\'\nDeep Learning T\xc3\xbcrkiye toplulu\xc4\x9fu taraf\xc4\xb1ndan haz\xc4\xb1rlanm\xc4\xb1\xc5\x9ft\xc4\xb1r.\n\nAma\xc3\xa7: El yaz\xc4\xb1s\xc4\xb1 rakamlar\xc4\xb1n tan\xc4\xb1nmas\xc4\xb1.\nVeriseti: MNIST (http://yann.lecun.com/exdb/mnist/)\nAlgoritma: Evri\xc5\x9fimli Sinir A\xc4\x9flar\xc4\xb1 (Convolutional Neural Networks)\nMicrosoft Azure Notebook: https://notebooks.azure.com/deeplearningturkiye/libraries/pratik-derin-ogrenme/html/rakam_tanima_CNN_MNIST.ipynb\n\nA\xc4\x9f Mimarisi:\n\n- 32 x 3 x 3 CONV\n- 64 x 3 x 4 CONV\n- 2 x 2 MAX POOL\n- DROPOUT (%25)\n- 128 FC\n- DROPOUT (%50)\n- 10 FC\n\n\n12 epoch sonunda 99.25% test do\xc4\x9fruluk oran\xc4\xb1 elde ediliyor.\n\'\'\'\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nbatch_size = 128 # her bir iterasyonda ""128"" resim al\xc4\xb1ns\xc4\xb1n\nnum_classes = 10 # ay\xc4\xb1rt etmek istedi\xc4\x9fimiz ""10"" rakam\nepochs = 12 # e\xc4\x9fitim 12 epoch s\xc3\xbcrs\xc3\xbcn\n\n# giri\xc5\x9f resimlerinin boyutlar\xc4\xb1 28 x 28 piksel\nimg_rows, img_cols = 28, 28\n\n# veri \xc3\xb6nce kar\xc4\xb1\xc5\x9ft\xc4\xb1r\xc4\xb1l\xc4\xb1yor (shuffle) sonra da e\xc4\x9fitim/test diye ayr\xc4\xb1l\xc4\xb1yor\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == \'channels_first\':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\n\n# s\xc4\xb1n\xc4\xb1f vekt\xc3\xb6rleri ikili (binary) formununa d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcl\xc3\xbcr\n# ""to_catogorical"" fonksiyonu ile one-hot-encoding yap\xc4\xb1yoruz\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\n\n# 3x3 boyutunda 32 adet filtreden olu\xc5\x9fan ReLU aktivasyonlu CONV katman\xc4\xb1 ekleyelim. \nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation=\'relu\',\n                 input_shape=input_shape))\n\n# 3x3 boyutunda 64 adet filtreden olu\xc5\x9fan ReLU aktivasyonlu CONV katman\xc4\xb1 ekleyelim. \nmodel.add(Conv2D(64, (3, 3), activation=\'relu\'))\n\n# 2x2 boyutlu \xc3\xa7er\xc3\xa7eveden olu\xc5\x9fan MAXPOOL katman\xc4\xb1 ekleyelim. \nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# her seferinde n\xc3\xb6ronlar\xc4\xb1n %25\'i at\xc4\xb1ls\xc4\xb1n (drop)\nmodel.add(Dropout(0.25))\n\n# Tam ba\xc4\x9flant\xc4\xb1l\xc4\xb1 (fully connected) katman\xc4\xb1na ge\xc3\xa7i\xc5\x9f olaca\xc4\x9f\xc4\xb1 i\xc3\xa7in d\xc3\xbczle\xc5\x9ftirme yapal\xc4\xb1m \nmodel.add(Flatten())\n\n# 128 n\xc3\xb6rondan olu\xc5\x9fan ReLU aktivasyonu FC katman\xc4\xb1 ekleyelim \nmodel.add(Dense(128, activation=\'relu\'))\n\n# Her seferinde %50\'sini atal\xc4\xb1m (drop)\nmodel.add(Dropout(0.5))\n\n# \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f katman\xc4\xb1na s\xc4\xb1n\xc4\xb1f say\xc4\xb1s\xc4\xb1 kadar (10) Softmax aktivasyonlu n\xc3\xb6ron ekleyelim\nmodel.add(Dense(num_classes, activation=\'softmax\'))\n\n# Adadelta optimizasyon y\xc3\xb6ntemini ve cross entropy yitim (loss) fonksiyonunu kullanal\xc4\xb1m.\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=[\'accuracy\'])\n\n# e\xc4\x9fitim i\xc5\x9flemini ger\xc3\xa7ekle\xc5\x9ftirelim\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n\n# test i\xc5\x9flemini ger\xc3\xa7ekle\xc5\x9ftirelim ve sonu\xc3\xa7lar\xc4\xb1 ekrana yazd\xc4\xb1ral\xc4\xb1m\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\'Test loss:\', score[0])\nprint(\'Test accuracy:\', score[1])\n'"
KERAS/rakam_tanima_Denoising_Autoencoder.py,0,"b""# -*- coding: utf-8 -*- \n\n'''\nMNIST dataseti \xc3\xbczerinde Denoising Autoencoder (parazit ar\xc4\xb1nd\xc4\xb1ran otomatik kodlay\xc4\xb1c\xc4\xb1) uyguluyor.\nParazit ar\xc4\xb1nd\xc4\xb1rma otomatik kodlay\xc4\xb1c\xc4\xb1lar\xc4\xb1n en klasik uygulama alanlar\xc4\xb1ndan birisidir.\nParazit ar\xc4\xb1nd\xc4\xb1rma s\xc3\xbcreci as\xc4\xb1l sinyalleri bozan istenmeyen parazitlerden kurtulmay\xc4\xb1 sa\xc4\x9flar.\n\nParazit + Veri ---> Denoising Autoencoder ---> Veri\nBozuk bir veri k\xc3\xbcmesini girdi, as\xc4\xb1l veriyi \xc3\xa7\xc4\xb1kt\xc4\xb1 olarak verdi\xc4\x9fimizde Denoising Autoencoder\nas\xc4\xb1l veriyi elde etmek i\xc3\xa7in gizli yap\xc4\xb1y\xc4\xb1 kurtar\xc4\xb1r.\n\nBu \xc3\xb6rnek mod\xc3\xbcler dizayna sahip. Encoder (\xc5\x9fifreleyici), Decoder (\xc3\xa7\xc3\xb6z\xc3\xbcmleyici) ve Autoencoder\nayn\xc4\xb1 a\xc4\x9f\xc4\xb1rl\xc4\xb1k de\xc4\x9ferlerini (weight) payla\xc5\x9fan 3 ayr\xc4\xb1 modeldir. \xc3\x96rne\xc4\x9fin, autoencoder e\xc4\x9fitildikten\nsonra, encoder girdi verisetinin \xc3\xb6rt\xc3\xbcl\xc3\xbc vekt\xc3\xb6rlerini (latent vectors) olu\xc5\x9fturmak i\xc3\xa7in \nkullan\xc4\xb1labilir. B\xc3\xb6ylece PCA ve TSNE'nin yapt\xc4\xb1\xc4\x9f\xc4\xb1 gibi k\xc3\xbc\xc3\xa7\xc3\xbck boyutta indirgeyerek g\xc3\xb6rselle\xc5\x9ftirme \nyap\xc4\xb1labilir.\n'''\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport keras\nfrom keras.layers import Activation, Dense, Input\nfrom keras.layers import Conv2D, Flatten\nfrom keras.layers import Reshape, Conv2DTranspose\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.datasets import mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nnp.random.seed(1337)\n\n# Veriseti y\xc3\xbckleniyor ve e\xc4\x9fitim/test diye ayr\xc4\xb1l\xc4\xb1yor.\n(x_train, _), (x_test, _) = mnist.load_data()\n\n# Veri 4 boyutlu olarak yeniden \xc5\x9fekillendiriliyor.\nimage_size = x_train.shape[1]\nx_train = np.reshape(x_train, [-1, image_size, image_size, 1])\nx_test = np.reshape(x_test, [-1, image_size, image_size, 1])\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n# MNIST verisine parazit katarak bozuyoruz. Bunun i\xc3\xa7in\n# 0.5 merkezinde std=0.5 olan bir normal frekans da\xc4\x9f\xc4\xb1l\xc4\xb1m\xc4\xb1 ekliyoruz veriye.\nnoise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\nx_train_noisy = x_train + noise\nnoise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\nx_test_noisy = x_test + noise\n\n# Parazit kat\xc4\xb1lm\xc4\xb1\xc5\x9f veriler 0 ile 1 aras\xc4\xb1n\xc4\xb1 a\xc5\x9fmayacak \xc5\x9fekilde d\xc3\xbczenleniyor.\n# 0'dan k\xc3\xbc\xc3\xa7\xc3\xbck de\xc4\x9ferler 0'a, 1'den b\xc3\xbcy\xc3\xbck de\xc4\x9ferler 1'e e\xc5\x9fitleniyor.\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n# Model parametreleri\ninput_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3\nlatent_dim = 16\n\n# Encoder ve Decoder i\xc3\xa7in CNN katmanlar\xc4\xb1 ve her katman i\xc3\xa7in uygulanacak filtreler\n# Burada 2 katman var. \xc4\xb0lk katman\xc4\xb1n filtre say\xc4\xb1s\xc4\xb1 32, ikincisinin 64.\nlayer_filters = [32, 64]\n\n\n# Autoencoder Modelinin Kurulumu\n\n# \xc3\x96ncelikle Encoder modeli kuruluyor\ninputs = Input(shape=input_shape, name='encoder_input')\nx = inputs\n\n# Con2D bloklar\xc4\xb1\n# Not:\n# 1) Derin a\xc4\x9flarda ReLU kullanmadan \xc3\xb6nce Batch Normalization kullan\xc4\xb1n\n# 2) strides>1'a alternatif olarak MaxPooling2D kullan\xc4\xb1n\n# - daha h\xc4\xb1zl\xc4\xb1 ama strides>1 kadar iyi de\xc4\x9fil\nfor filters in layer_filters:\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               strides=2,\n               activation='relu',\n               padding='same')(x)\n\n# Decoder Modelini olu\xc5\x9ftururken laz\xc4\xb1m olan boyut bilgileri\nshape = K.int_shape(x)\n\n# \xc3\x96rt\xc3\xbcl\xc3\xbc vekt\xc3\xb6r\xc3\xbcn (Latent Vector) olu\xc5\x9fturulmas\xc4\xb1\nx = Flatten()(x)\nlatent = Dense(latent_dim, name='latent_vector')(x)\n\n# Encoder Modelinin \xc3\xb6rneklendirilmesi\nencoder = Model(inputs, latent, name='encoder')\nencoder.summary()\n\n# Decoder Modelinin olu\xc5\x9fturulmas\xc4\xb1\nlatent_inputs = Input(shape=(latent_dim,), name='decoder_input')\nx = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\nx = Reshape((shape[1], shape[2], shape[3]))(x)\n\n# Transpozu al\xc4\xb1nm\xc4\xb1\xc5\x9f Conv2D bloklar\xc4\xb1\n# Not:\n# 1) Derin a\xc4\x9flarda ReLU kullanmadan \xc3\xb6nce Batch Normalization kullan\xc4\xb1n\n# 2) strides>1'a alternatif olarak UpSampling2D kullan\xc4\xb1n\n# - daha h\xc4\xb1zl\xc4\xb1 ama strides>1 kadar iyi de\xc4\x9fil\nfor filters in layer_filters[::-1]:\n    x = Conv2DTranspose(filters=filters,\n                        kernel_size=kernel_size,\n                        strides=2,\n                        activation='relu',\n                        padding='same')(x)\n\nx = Conv2DTranspose(filters=1,\n                    kernel_size=kernel_size,\n                    padding='same')(x)\n\noutputs = Activation('sigmoid', name='decoder_output')(x)\n\n# Decoder Modelinin \xc3\xb6rneklendirilmesi\ndecoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()\n\n# Autoencoder = Encoder + Decoder\n# Autoencoder Modelinin \xc3\xb6rneklendirilmesi\nautoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\nautoencoder.summary()\n\nautoencoder.compile(loss='mse', optimizer='adam')\n\n# Autoencoder'\xc4\xb1 e\xc4\x9fitiyoruz bu ad\xc4\xb1mda\nautoencoder.fit(x_train_noisy,\n                x_train,\n                validation_data=(x_test_noisy, x_test),\n                epochs=30,\n                batch_size=batch_size)\n\n# Parazit eklenmi\xc5\x9f test g\xc3\xb6rsellerinin \xc3\xa7\xc4\xb1kt\xc4\xb1lar\xc4\xb1n\xc4\xb1 autoencoder ile tahmin ediyoruz\nx_decoded = autoencoder.predict(x_test_noisy)\n\n# \xc4\xb0lk 8 parazit eklenmi\xc5\x9f ve bozulmu\xc5\x9f imaj\xc4\xb1 g\xc3\xb6rselliyoruz\nrows, cols = 10, 30\nnum = rows * cols\nimgs = np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\nimgs = imgs.reshape((rows * 3, cols, image_size, image_size))\nimgs = np.vstack(np.split(imgs, rows, axis=1))\nimgs = imgs.reshape((rows * 3, -1, image_size, image_size))\nimgs = np.vstack([np.hstack(i) for i in imgs])\nimgs = (imgs * 255).astype(np.uint8)\nplt.figure()\nplt.axis('off')\nplt.title('Orjinal imajlar: Ust Satir, '\n          'Bozulmus Girdi: Orta Satir, '\n          'Parazitlerden arindirilmis Girdi:  Ucuncu satirlar')\nplt.imshow(imgs, interpolation='none', cmap='gray')\nImage.fromarray(imgs).save('bozulmus_ve_parazit_eklenmis.png')\nplt.show()"""
KERAS/rakam_tanima_Hierarchical_RNN_MNIST.py,0,"b'# -*- coding: utf-8 -*- \n\n""""""\nDeep Learning T\xc3\xbcrkiye toplulu\xc4\x9fu taraf\xc4\xb1ndan haz\xc4\xb1rlanm\xc4\xb1\xc5\x9ft\xc4\xb1r.\nAma\xc3\xa7: El yaz\xc4\xb1s\xc4\xb1 rakamlar\xc4\xb1n tan\xc4\xb1nmas\xc4\xb1.\nVeriseti: MNIST (http://yann.lecun.com/exdb/mnist/)\nAlgoritma: Hiyerar\xc5\x9fik Devirli Sinir A\xc4\x9flar\xc4\xb1 (Hierarchical Recurrent Neural Networks (HRNN))\n\nEl yaz\xc4\xb1s\xc4\xb1 rakamlar\xc4\xb1n tan\xc4\xb1nmas\xc4\xb1nda Hiyerar\xc5\x9fik Devirli Sinir A\xc4\x9flar\xc4\xb1 (HRNN) kullan\xc4\xb1m\xc4\xb1n\xc4\xb1n bir \xc3\xb6rne\xc4\x9fidir.\nHRNN\'ler karma\xc5\x9f\xc4\xb1k bir dizilim \xc3\xbczerinde ge\xc3\xa7ici hiyerar\xc5\x9filerin bir\xc3\xa7ok katman\xc4\xb1n\xc4\xb1 kullanarak \xc3\xb6\xc4\x9frenebilirler.\nGenelde, HRNN\'in ilk devirli katman\xc4\xb1 c\xc3\xbcmleleri (kelime vekt\xc3\xb6r\xc3\xbc gibi) c\xc3\xbcmle vekt\xc3\xb6rlerine d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcyor.\n\xc4\xb0kinci devirli katman\xc4\xb1 sonras\xc4\xb1nda bu vekt\xc3\xb6rlerin dizilimini bir d\xc3\xb6k\xc3\xbcman vekt\xc3\xb6r\xc3\xbcne d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcyor.\nBu d\xc3\xb6k\xc3\xbcman vekt\xc3\xb6r\xc3\xbc ile hem kelime seviyesindeki hem de c\xc3\xbcmle seviyesindeki i\xc3\xa7erik yap\xc4\xb1s\xc4\xb1n\xc4\xb1n korunmu\xc5\x9f oluyor.\n\n# Referanslar\n- [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://arxiv.org/abs/1506.01057)\n  Paragraf ve d\xc3\xb6k\xc3\xbcmanlar\xc4\xb1 HRNN ile d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcyor.\n  Sonu\xc3\xa7lar\xc4\xb1n g\xc3\xb6sterdi\xc4\x9fine g\xc3\xb6re HRNN standart RNN\'lerin performans\xc4\xb1n\xc4\xb1 ge\xc3\xa7mi\xc5\x9f\n  ve yaz\xc4\xb1 \xc3\xb6zetlemek yada soru-cevap \xc3\xbcretimi gibi daha ileri seviye g\xc3\xb6revlerde kullan\xc4\xb1labilir.\n- [Hierarchical recurrent neural network for skeleton based action recognition](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298714)\n  \xc4\xb0skelet baz\xc4\xb1nda hareket tahmini konusunda \xc5\x9fimdiye kadarki en iyi sonu\xc3\xa7lara ula\xc5\x9fm\xc4\xb1\xc5\x9ft\xc4\xb1r.\n  3 katmanl\xc4\xb1 \xc3\xa7ift y\xc3\xb6nl\xc3\xbc (bidirectional) HRNN ve tamamen ba\xc4\x9fl\xc4\xb1 katmanlar\xc4\xb1n (fully connected layers) kombinasyonu kullan\xc4\xb1lm\xc4\xb1\xc5\x9ft\xc4\xb1r.\n\nA\xc5\x9fa\xc4\x9f\xc4\xb1daki MNIST \xc3\xb6rne\xc4\x9finde, birinci LSTM katman\xc4\xb1 \xc3\xb6ncelikle herbir (28,1) boyutundaki piksel s\xc3\xbctununu (128,) boyutunda s\xc3\xbctun vekt\xc3\xb6r\xc3\xbcne d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcyor.\n\xc4\xb0kinci LSTM sonras\xc4\xb1nda bu (28, 128) boyutundaki 28 s\xc3\xbctun vekt\xc3\xb6r\xc3\xbcn\xc3\xbc resim vekt\xc3\xb6r\xc3\xbcne yani t\xc3\xbcm resme d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcyor.\nSon yo\xc4\x9fun (Dense) katman tahmin yapmak i\xc3\xa7in eklendi.\n\n5 epoch sonunda, e\xc4\x9fitim verisetinde 98.58%, validasyon verisetinde 98.64% do\xc4\x9fruluk oran\xc4\xb1 elde ediliyor.\n""""""\n\nfrom __future__ import print_function\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, TimeDistributed\nfrom keras.layers import LSTM\n\n# Parametrelerin de\xc4\x9ferlerinin belirlenmesi.\nbatch_size = 32 # her bir iterasyonda ""32"" resim al\xc4\xb1ns\xc4\xb1n\nnum_classes = 10  # ay\xc4\xb1rt etmek istedi\xc4\x9fimiz ""10"" rakam\nepochs = 5 # e\xc4\x9fitim 5 epoch s\xc3\xbcrs\xc3\xbcn\n\n\n# Modele yerle\xc5\x9ftirme boyutlar\xc4\xb1 (Embedding Dimensions).\nrow_hidden = 128\ncol_hidden = 128\n\n# Veriseti y\xc3\xbckleniyor ve e\xc4\x9fitim/test diye ayr\xc4\xb1l\xc4\xb1yor.\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Veri HRNN i\xc3\xa7in 4 boyutlu olarak yeniden \xc5\x9fekillendiriliyor.\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\n\n# S\xc4\xb1n\xc4\xb1f vekt\xc3\xb6rleri ikili (binary) forma d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcl\xc3\xbcyor.\n# ""to_catogorical"" fonksiyonu ile one-hot-encoding yap\xc4\xb1yoruz.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nrow, col, pixel = x_train.shape[1:]\n\n# 4 boyutlu giri\xc5\x9f verileri.\nx = Input(shape=(row, col, pixel))\n\n# Her sat\xc4\xb1r\xc4\xb1n pikselleri TimeDistributed Wrapper kullan\xc4\xb1lar d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcl\xc3\xbcyor (encoding).\nencoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n\n# D\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbclm\xc3\xbc\xc5\x9f sat\xc4\xb1rlar\xc4\xb1n s\xc3\xbctunlar\xc4\xb1 da d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcl\xc3\xbcyor.\nencoded_columns = LSTM(col_hidden)(encoded_rows)\n\n# Son olarak, tahmin yap\xc4\xb1l\xc4\xb1yor.\nprediction = Dense(num_classes, activation=\'softmax\')(encoded_columns)\n\n# Model kuruluyor.\nmodel = Model(x, prediction)\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=\'rmsprop\',\n              metrics=[\'accuracy\'])\n\n# E\xc4\x9fitim yap\xc4\xb1l\xc4\xb1yor.\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n\n# Sonu\xc3\xa7lar\xc4\xb1n de\xc4\x9ferlendirilmesi.\nscores = model.evaluate(x_test, y_test, verbose=0)\nprint(\'Test loss:\', scores[0])\nprint(\'Test accuracy:\', scores[1])'"
KERAS/rakam_tanima_MLP_MNIST.py,0,"b'# -*- coding: utf-8 -*- \n""""""\nDeep Learning T\xc3\xbcrkiye toplulu\xc4\x9fu taraf\xc4\xb1ndan haz\xc4\xb1rlanm\xc4\xb1\xc5\x9ft\xc4\xb1r.\n\nAma\xc3\xa7: El yaz\xc4\xb1s\xc4\xb1 rakamlar\xc4\xb1n tan\xc4\xb1nmas\xc4\xb1.\nVeriseti: MNIST (http://yann.lecun.com/exdb/mnist/)\nAlgoritma: \xc3\x87ok Katmanl\xc4\xb1 Alg\xc4\xb1lay\xc4\xb1c\xc4\xb1 (Multi-Layer Perceptron (MLP))\nMicrosoft Azure Notebook: \n\n20 epoch sonunda %98.40 test do\xc4\x9fruluk oran\xc4\xb1 elde ediliyor.\n""""""\nfrom __future__ import print_function\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import RMSprop\n\nbatch_size = 128 # her bir iterasyonda ""128"" resim al\xc4\xb1ns\xc4\xb1n\nnum_classes = 10 # tan\xc4\xb1nmak istenen 0-9 rakam (10 s\xc4\xb1n\xc4\xb1f)\nepochs = 20 # e\xc4\x9fitim 20 epoch(e\xc4\x9fitim devir say\xc4\xb1s\xc4\xb1) s\xc3\xbcrs\xc3\xbcn\n\n# the data, shuffled and split between train and test sets\n# mnist veriseti rastgele kar\xc4\xb1\xc5\x9ft\xc4\xb1r\xc4\xb1lm\xc4\xb1\xc5\x9f \xc5\x9fekilde train ve set setleri olarak y\xc3\xbckleniyor\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n\n# Sinir a\xc4\x9f\xc4\xb1m\xc4\xb1z her e\xc4\x9fitim \xc3\xb6rne\xc4\x9fi i\xc3\xa7in tek bir vekt\xc3\xb6r alacakt\xc4\xb1r, \n# bu nedenle girdiyi 28x28 resim tek bir 784 boyutlu vekt\xc3\xb6r olarak \xc5\x9fekilde yeniden \xc5\x9fekillendiriyoruz.\n# Ayr\xc4\xb1ca girdileri [0-255] yerine [0-1] aral\xc4\xb1\xc4\x9f\xc4\xb1nda \xc3\xb6l\xc3\xa7eklendirece\xc4\x9fiz.\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\nprint(x_train.shape[0], \'train samples(e\xc4\x9fitim \xc3\xb6rnek say\xc4\xb1s\xc4\xb1)\')\nprint(x_test.shape[0], \'test samples(test \xc3\xb6rnek say\xc4\xb1s\xc4\xb1)\')\n\n# s\xc4\xb1n\xc4\xb1f vekt\xc3\xb6rlerini ikili s\xc4\xb1n\xc4\xb1f matrislerine d\xc3\xb6n\xc3\xbc\xc5\x9ft\xc3\xbcr\xc3\xbcyoruz\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n\n# A\xc4\x9f\xc4\xb1m\xc4\xb1z\xc4\xb1 kural\xc4\xb1m\n# Burada basit bir 3 katmanl\xc4\xb1 tam ba\xc4\x9flant\xc4\xb1l\xc4\xb1 a\xc4\x9f yapaca\xc4\x9f\xc4\xb1z.(fully connected network (""Dense""))\n# Ayr\xc4\xb1ca e\xc4\x9fitim s\xc4\xb1ras\xc4\xb1nda a\xc5\x9f\xc4\xb1r\xc4\xb1 \xc3\xb6\xc4\x9frenme (overfitting) olmamas\xc4\xb1 i\xc3\xa7in b\xc4\xb1rakma/at\xc4\xb1lma (""Dropout"") uygulayaca\xc4\x9f\xc4\xb1z.\n# Dropout tekni\xc4\x9fi 2014 y\xc4\xb1l\xc4\xb1nda bir makale de \xc3\xb6nerilmi\xc5\x9ftir ve o zamandan beri benimsenerek kullan\xc4\xb1lm\xc4\xb1\xc5\x9ft\xc4\xb1r. (http://jmlr.org/papers/v15/srivastava14a.html)\n# Pratikte %20 ile %50 aras\xc4\xb1nda dropout uyguland\xc4\xb1\xc4\x9f\xc4\xb1 g\xc3\xb6r\xc3\xbcl\xc3\xbcyor.\n\nmodel = Sequential()\nmodel.add(Dense(512, activation=\'relu\', input_shape=(784,)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation=\'relu\'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation=\'softmax\')) #Softmax katman\xc4\xb1 ile \xc3\xa7\xc4\xb1kt\xc4\xb1 de\xc4\x9ferlerimizin hepsini bir olas\xc4\xb1l\xc4\xb1k da\xc4\x9f\xc4\xb1l\xc4\xb1m\xc4\xb1 olarak hesaplanmas\xc4\xb1n\xc4\xb1 sa\xc4\x9fl\xc4\xb1yoruz.\n\nmodel.summary()\n\n# A\xc4\x9f derlenirken kay\xc4\xb1p fonksiyonunuzu ve optimizat\xc3\xb6r\xc3\xbcn\xc3\xbcz\xc3\xbc belirtmemiz isteniyor.\n# Optimizasyon tiplerinden ""RMSprop"" ve yitim (loss) fonksiyonu olarak ""categorical_crossentropy"" kullan\xc4\xb1yoruz.\n# Son parametre olarak da hali haz\xc4\xb1rda tan\xc4\xb1mlanm\xc4\xb1\xc5\x9f tek metrik fonksiyonu olan ""accuracy"" yi kullan\xc4\xb1yoruz. Accuracy bize 0-1 aras\xc4\xb1nda bir do\xc4\x9fruluk de\xc4\x9feri verecektir.\nmodel.compile(loss=\'categorical_crossentropy\',\n              optimizer=RMSprop(),\n              metrics=[\'accuracy\'])\n\n# Buras\xc4\xb1 en e\xc4\x9flenceli k\xc4\xb1s\xc4\xb1m, a\xc4\x9f\xc4\xb1m\xc4\xb1z\xc4\xb1 e\xc4\x9fitme k\xc4\xb1sm\xc4\xb1 :)\n# Daha \xc3\xb6nce y\xc3\xbcklenmi\xc5\x9f e\xc4\x9fitim verileri ile s\xc4\xb1n\xc4\xb1fland\xc4\xb1rmay\xc4\xb1 \xc3\xb6\xc4\x9frenmeye \xc3\xa7al\xc4\xb1\xc5\x9f\xc4\xb1r.\n# Fit fonksiyonu e\xc4\x9fitim s\xc4\xb1ras\xc4\xb1ndaki yitim(loss)/do\xc4\x9frulama ba\xc5\x9far\xc4\xb1m\xc4\xb1 (accuracy) de\xc4\x9ferleri ile bir \xc3\xa7ok ayr\xc4\xb1nt\xc4\xb1 d\xc3\xb6nd\xc3\xbcr\xc3\xbcr.\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(x_test, y_test))\n\n# Son olarak e\xc4\x9fitilmi\xc5\x9f a\xc4\x9f\xc4\xb1m\xc4\xb1z\xc4\xb1n test setimiz \xc3\xbczerindeki performans de\xc4\x9ferlerimizi hesaplayarak ekrana yazd\xc4\xb1ral\xc4\xb1m.\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\'Test loss:\', score[0])\nprint(\'Test accuracy:\', score[1])\n\n\n'"
PyTorch/rakam_tanima_CNN_MNIST.py,9,"b'\'\'\'\nDeep Learning T\xc3\xbcrkiye toplulu\xc4\x9fu taraf\xc4\xb1ndan haz\xc4\xb1rlanm\xc4\xb1\xc5\x9ft\xc4\xb1r.\n\nAma\xc3\xa7: El yaz\xc4\xb1s\xc4\xb1 rakamlar\xc4\xb1n tan\xc4\xb1nmas\xc4\xb1.\nVeriseti: MNIST (http://yann.lecun.com/exdb/mnist/)\nAlgoritma: Evri\xc5\x9fimli Sinir A\xc4\x9flar\xc4\xb1 (Convolutional Neural Networks)\n\n10 epoch sonunda testde 98% do\xc4\x9fruluk oran\xc4\xb1 elde edilmi\xc5\x9ftir.\n\nNas\xc4\xb1l \xc3\xa7al\xc4\xb1\xc5\x9ft\xc4\xb1r\xc4\xb1l\xc4\xb1r ?\npython main.py\nCUDA_VISIBLE_DEVICES=2 python main.py  # \xc4\xb0stenilen GPU\'da \xc3\xa7al\xc4\xb1\xc5\x9ft\xc4\xb1rmak i\xc3\xa7in.\n\'\'\'\n\n# Gerekli k\xc3\xbct\xc3\xbcphanelerin dahil edilmesi:\nfrom __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\n# Terminal komutundan al\xc4\xb1nan bilginin i\xc5\x9flenmesi:\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=1000, metavar=\'N\',\n                    help=\'input batch size for testing (default: 1000)\')\nparser.add_argument(\'--epochs\', type=int, default=10, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.5, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available() # Cuda var m\xc4\xb1 diye kontrol edilir.\n\n# Rastgele say\xc4\xb1 \xc3\xbcretmek i\xc3\xa7in:\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\n# MNIST verisetini i\xc3\xa7e aktar\xc4\xb1lmas\xc4\xb1:\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'../data\', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'../data\', train=False, transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n# Evri\xc5\x9fimli Sinir A\xc4\x9flar\xc4\xb1 modelinin olu\xc5\x9fturulmas\xc4\xb1:\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # Giri\xc5\x9f kanal\xc4\xb1: 1, \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f kanal\xc4\xb1: 10, Filtre boyutu: 5x5\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # Giri\xc5\x9f kanal\xc4\xb1: 10, \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f kanal\xc4\xb1: 20, Filtre boyutu: 5x5\n\n        # Rastgele olacak \xc5\x9fekilde n\xc3\xb6ronlar\xc4\xb1n %50\'sini kapat\xc4\xb1yoruz (modelin ezberlemesini engeller):\n        self.conv2_drop = nn.Dropout2d() # Fonksiyonun varsay\xc4\xb1lan kapama oran\xc4\xb1 %50\n\n        self.fc1 = nn.Linear(320, 50) # Giri\xc5\x9f n\xc3\xb6ron say\xc4\xb1s\xc4\xb1: 320, \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f n\xc3\xb6ron say\xc4\xb1s\xc4\xb1: 50\n        # Modele yeni bir katmanda 50 n\xc3\xb6ron eklemi\xc5\x9f olduk.\n\n        self.fc2 = nn.Linear(50, 10) # Giri\xc5\x9f n\xc3\xb6ron say\xc4\xb1s\xc4\xb1: 50, \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f n\xc3\xb6ron say\xc4\xb1s\xc4\xb1: 10\n        # 10 s\xc4\xb1n\xc4\xb1f\xc4\xb1m\xc4\xb1z\xc4\xb1 temsil edecek 10 n\xc3\xb6ron.\n\n    # Modelin ak\xc4\xb1\xc5\x9f \xc5\x9femas\xc4\xb1n\xc4\xb1 olu\xc5\x9ftural\xc4\xb1m:\n    def forward(self, x):\n        # Giri\xc5\x9f(x) boyutu: [1, 28, 28] x 64(batch_size) Kanal sya\xc4\xb1s\xc4\xb1: 1, G\xc3\xb6rselin boyutu: 28x28\n\n        # Giri\xc5\x9fi, yukar\xc4\xb1da tan\xc4\xb1mlad\xc4\xb1\xc4\x9f\xc4\xb1m\xc4\xb1z ""conv1"" katman\xc4\xb1ndan ge\xc3\xa7iriyoruz,\n        # sonra 2x2 boyutunda \xc3\xa7er\xc3\xa7eveden olu\xc5\x9fan MaxPooling katman\xc4\xb1m\xc4\xb1z\xc4\xb1 ekliyoruz,\n        # daha sonra ReLu aktivasyon fonksiyonumuzdan ge\xc3\xa7iriyoruz:\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        # \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f boyutu: [10, 12, 12]\n\n        # Yukar\xc4\xb1da ald\xc4\xb1\xc4\x9f\xc4\xb1m\xc4\xb1z \xc3\xa7\xc4\xb1kt\xc4\xb1y\xc4\xb1 ""conv2"" katman\xc4\xb1ndan ge\xc3\xa7iriyoruz,\n        # sonra yukar\xc4\xb1da tan\xc4\xb1mlad\xc4\xb1\xc4\x9f\xc4\xb1m\xc4\xb1z Dropout katman\xc4\xb1m\xc4\xb1z\xc4\xb1 ekliyoruz,\n        # daha sonra 2x2 boyutunda \xc3\xa7er\xc3\xa7eveden olu\xc5\x9fan MaxPooling katman\xc4\xb1m\xc4\xb1z\xc4\xb1 uyguluyoruz,\n        # en sonda ReLu aktivasyon fonksiyonumuzdan ge\xc3\xa7iriyoruz:\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        # \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f boyutu: [20, 4, 4]\n\n        x = x.view(-1, 320) # Yeniden boyutland\xc4\xb1rma yap\xc4\xb1yoruz.\n        # 4x4 boyutlu 20 kanall\xc4\xb1 foto\xc4\x9fraf\xc4\xb1 1 boyutlu vect\xc3\xb6re \xc3\xa7eviriyoruz.\n        # -1 boyutu giri\xc5\x9f boyutuna ve belirlenen di\xc4\x9fer boyutlara bak\xc4\xb1larak bulunur.\n        # 20x4x4 = 320:\n        # \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f boyutu: [320]\n\n        # Yukar\xc4\xb1da tan\xc4\xb1mlad\xc4\xb1\xc4\x9f\xc4\xb1m\xc4\xb1z ""fc1"" katman\xc4\xb1m\xc4\xb1zdaki 50 n\xc3\xb6ronu modelimize ekliyoruz,\n        # daha sonra \xc3\xa7\xc4\xb1kt\xc4\xb1m\xc4\xb1z\xc4\xb1 ReLu aktivasyon fonksiyonumuzdan ge\xc3\xa7iriyoruz:\n        x = F.relu(self.fc1(x))\n        # \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f boyutu: [50]\n\n        # Modelin ezberlemesini \xc3\xb6nlemek i\xc3\xa7in Dropout katman\xc4\xb1m\xc4\xb1z\xc4\xb1 ekliyoruz:\n        x = F.dropout(x, training=self.training)\n\n        # Yukar\xc4\xb1da tan\xc4\xb1mlad\xc4\xb1\xc4\x9f\xc4\xb1m\xc4\xb1z ""fc2"" katman\xc4\xb1m\xc4\xb1zdaki 10 n\xc3\xb6ronu modelimize ekliyoruz,\n        # daha sonra \xc3\xa7\xc4\xb1kt\xc4\xb1m\xc4\xb1z\xc4\xb1 ReLu aktivasyon fonksiyonumuzdan ge\xc3\xa7iriyoruz:\n        x = self.fc2(x)\n        # \xc3\x87\xc4\xb1k\xc4\xb1\xc5\x9f boyutu: [10]\n        # Verisetimizdeki 10 s\xc4\xb1n\xc4\xb1f\xc4\xb1 temsil edecek 10 \xc3\xa7\xc4\xb1kt\xc4\xb1y\xc4\xb1 elde ettik.\n\n        # Son olarak s\xc4\xb1n\xc4\xb1fland\xc4\xb1rma yapmak i\xc3\xa7in Softmax fonksiyoumuzu kullan\xc4\xb1yoruz:\n        return F.log_softmax(x)\n\nmodel = Net() # Modelimizi tan\xc4\xb1ml\xc4\xb1yoruz.\nif args.cuda:\n    model.cuda() # Verileri GPU\'ya ta\xc5\x9f\xc4\xb1r.\n\n# ""SGD"" optimizasyon fonksiyonumuzu olu\xc5\x9fturuyoruz:\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n# Modeli e\xc4\x9fitecek fonksiyonumuzu olu\xc5\x9fturuyoruz:\ndef train(epoch):\n    model.train() # Modelimizi e\xc4\x9fitim moduna al\xc4\xb1yoruz.\n    for batch_idx, (data, target) in enumerate(train_loader): # Verisetini batch\'lere b\xc3\xb6l\xc3\xbcyoruz.\n        if args.cuda:\n            data, target = data.cuda(), target.cuda() # Verileri GPU\'ya ta\xc5\x9f\xc4\xb1r.\n        data, target = Variable(data), Variable(target) # Verilerimizi PyTorch de\xc4\x9fi\xc5\x9fkenlerine(Tensor) \xc3\xa7eviriyoruz.\n        optimizer.zero_grad() # T\xc3\xbcm optimize edilmi\xc5\x9f de\xc4\x9fi\xc5\x9fkenlerin verilerini temizler.\n        output = model(data) # Girdi verisini modelimizde i\xc5\x9fliyoruz ve \xc3\xa7\xc4\xb1kt\xc4\xb1m\xc4\xb1z\xc4\xb1 al\xc4\xb1yoruz.\n        # \xc3\x87\xc4\xb1kmas\xc4\xb1 gereken sonu\xc3\xa7 ile modelimizin \xc3\xbcretti\xc4\x9fi \xc3\xa7\xc4\xb1kt\xc4\xb1y\xc4\xb1 kar\xc5\x9f\xc4\xb1la\xc5\x9ft\xc4\xb1rarak hata hesaplamam\xc4\xb1z\xc4\xb1 yap\xc4\xb1yoruz:\n        loss = F.nll_loss(output, target) # Hata fonksiyonumuz: The negative log likelihood loss(NLLLoss)\n        loss.backward() # Buldu\xc4\x9fumuz hata oran\xc4\xb1yla geri-yay\xc4\xb1l\xc4\xb1m uyguluyoruz.\n        optimizer.step() # Modelimizi(a\xc4\x9f\xc4\xb1rl\xc4\xb1klar\xc4\xb1) daha optimize sonu\xc3\xa7 i\xc3\xa7in g\xc3\xbcncelliyoruz.\n\n        # Belli aral\xc4\xb1klarla(log_interval, varsay\xc4\xb1lan de\xc4\x9fer: 10) modelin ba\xc5\x9far\xc4\xb1n\xc4\xb1 ekrana yazd\xc4\xb1r\xc4\xb1yoruz:\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\n# Modeli test edecek fonksiyonumuzu olu\xc5\x9fturuyoruz:\ndef test():\n    model.eval() # Modeli test moduna al\xc4\xb1yoruz.\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader: # Test verimizi al\xc4\xb1yoruz.\n        if args.cuda:\n            data, target = data.cuda(), target.cuda() # Verileri GPU\'ya ta\xc5\x9f\xc4\xb1r.\n        data, target = Variable(data, volatile=True), Variable(target) # Verilerimizi PyTorch de\xc4\x9fi\xc5\x9fkenlerine(Tensor) \xc3\xa7eviriyoruz.\n        output = model(data) # Girdi verisini modelimizde i\xc5\x9fliyoruz ve \xc3\xa7\xc4\xb1kt\xc4\xb1m\xc4\xb1z\xc4\xb1 al\xc4\xb1yoruz.\n        test_loss += F.nll_loss(output, target, size_average=False).data[0] # Batch hata oran\xc4\xb1n\xc4\xb1n hesaplanmas\xc4\xb1 ve toplam hata oran\xc4\xb1na eklenmesi.\n        # \xc3\x87\xc4\xb1kmas\xc4\xb1 gereken sonu\xc3\xa7 ile modelimizin \xc3\xbcretti\xc4\x9fi \xc3\xa7\xc4\xb1kt\xc4\xb1y\xc4\xb1 kar\xc5\x9f\xc4\xb1la\xc5\x9ft\xc4\xb1rarak hata hesaplamam\xc4\xb1z\xc4\xb1 yap\xc4\xb1yoruz:\n        pred = output.data.max(1)[1] # Maksimim olas\xc4\xb1l\xc4\xb1k indeksi al\xc4\xb1narak sonu\xc3\xa7 elde edilir.\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum() # Modelin ba\xc5\x9far\xc4\xb1s\xc4\xb1 hesaplan\xc4\xb1r.\n\n    # Modelin ba\xc5\x9far\xc4\xb1s\xc4\xb1n\xc4\xb1 ekrana yazd\xc4\xb1r\xc4\xb1yoruz:\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n# E\xc4\x9fitimi ba\xc5\x9flat\xc4\xb1yoruz:\nfor epoch in range(1, args.epochs + 1):\n    train(epoch) # Model e\xc4\x9fitilir.\n    test() # Model test edilir.\n'"
