file_path,api_count,code
dorn/__init__.py,0,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-04 00:55\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : __init__.py.py\n""""""'"
dorn/models/__init__.py,0,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-04-02 00:23\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : __init__.py.py\n""""""\n\n\ndef _get_model(cfg):\n    mod = __import__(\'{}.{}\'.format(__name__, cfg[\'model\'][\'name\']), fromlist=[\'\'])\n    return getattr(mod, ""DepthPredModel"")(**cfg[""model""][""params""])'"
dorn/models/dorn.py,12,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-02 21:06\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : dorn.py\n""""""\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom dorn.modules.backbones.resnet import ResNetBackbone\nfrom dorn.modules.encoders.SceneUnderstandingModule import SceneUnderstandingModule\nfrom dorn.modules.decoders.OrdinalRegression import OrdinalRegressionLayer\nfrom dorn.modules.losses.ordinal_regression_loss import OrdinalRegressionLoss\n\n\nclass DepthPredModel(nn.Module):\n\n    def __init__(self, ord_num=90, gamma=1.0, beta=80.0,\n                 input_size=(385, 513), kernel_size=16, pyramid=[8, 12, 16],\n                 batch_norm=False,\n                 discretization=""SID"", pretrained=True):\n        super().__init__()\n        assert len(input_size) == 2\n        assert isinstance(kernel_size, int)\n        self.ord_num = ord_num\n        self.gamma = gamma\n        self.beta = beta\n        self.discretization = discretization\n\n        self.backbone = ResNetBackbone(pretrained=pretrained)\n        self.SceneUnderstandingModule = SceneUnderstandingModule(ord_num, size=input_size,\n                                                                 kernel_size=kernel_size,\n                                                                 pyramid=pyramid,\n                                                                 batch_norm=batch_norm)\n        self.regression_layer = OrdinalRegressionLayer()\n        self.criterion = OrdinalRegressionLoss(ord_num, beta, discretization)\n\n    def forward(self, image, target=None):\n        """"""\n        :param image: RGB image, torch.Tensor, Nx3xHxW\n        :param target: ground truth depth, torch.Tensor, NxHxW\n        :return: output: if training, return loss, torch.Float,\n                         else return {""target"": depth, ""prob"": prob, ""label"": label},\n                         depth: predicted depth, torch.Tensor, NxHxW\n                         prob: probability of each label, torch.Tensor, NxCxHxW, C is number of label\n                         label: predicted label, torch.Tensor, NxHxW\n        """"""\n        N, C, H, W = image.shape\n        feat = self.backbone(image)\n        feat = self.SceneUnderstandingModule(feat)\n        # print(""feat shape:"", feat.shape)\n        # feat = F.interpolate(feat, size=(H, W), mode=""bilinear"", align_corners=True)\n        if self.training:\n            prob = self.regression_layer(feat)\n            loss = self.criterion(prob, target)\n            return loss\n\n        prob, label = self.regression_layer(feat)\n        # print(""prob shape:"", prob.shape, "" label shape:"", label.shape)\n        if self.discretization == ""SID"":\n            t0 = torch.exp(np.log(self.beta) * label.float() / self.ord_num)\n            t1 = torch.exp(np.log(self.beta) * (label.float() + 1) / self.ord_num)\n        else:\n            t0 = 1.0 + (self.beta - 1.0) * label.float() / self.ord_num\n            t1 = 1.0 + (self.beta - 1.0) * (label.float() + 1) / self.ord_num\n        depth = (t0 + t1) / 2 - self.gamma\n        # print(""depth min:"", torch.min(depth), "" max:"", torch.max(depth),\n        #       "" label min:"", torch.min(label), "" max:"", torch.max(label))\n        return {""target"": [depth], ""prob"": [prob], ""label"": [label]}\n'"
dorn/modules/__init__.py,0,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2019-12-24 21:47\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : __init__.py.py\n""""""\n'"
dorn/modules/backbones/__init__.py,0,b'# -*- coding: utf-8 -*-\n# @Time    : 2019/12/27 \xe4\xb8\x8b\xe5\x8d\x8810:09\n# @Author  : Wang Xin\n# @Email   : wangxin_buaa@163.com\n# @File    : __init__.py.py'
dorn/modules/backbones/resnet.py,4,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-02 16:37\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : resnet.py\n""""""\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import BatchNorm2d\n\naffine_par = True\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None, fist_dilation=1, multi_grid=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=dilation * multi_grid, dilation=dilation * multi_grid, bias=False)\n        self.bn2 = BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=False)\n        self.relu_inplace = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.dilation = dilation\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out = out + residual\n        out = self.relu_inplace(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers):\n        self.inplanes = 128\n        super(ResNet, self).__init__()\n        self.conv1 = conv3x3(3, 64, stride=2)\n        self.bn1 = BatchNorm2d(64)\n        self.relu1 = nn.ReLU(inplace=False)\n        self.conv2 = conv3x3(64, 64)\n        self.bn2 = BatchNorm2d(64)\n        self.relu2 = nn.ReLU(inplace=False)\n        self.conv3 = conv3x3(64, 128)\n        self.bn3 = BatchNorm2d(128)\n        self.relu3 = nn.ReLU(inplace=False)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.relu = nn.ReLU(inplace=False)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4, multi_grid=(1, 1, 1))\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, multi_grid=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                BatchNorm2d(planes * block.expansion, affine=affine_par))\n\n        layers = []\n        generate_multi_grid = lambda index, grids: grids[index % len(grids)] if isinstance(grids, tuple) else 1\n        layers.append(block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample,\n                            multi_grid=generate_multi_grid(0, multi_grid)))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(\n                block(self.inplanes, planes, dilation=dilation, multi_grid=generate_multi_grid(i, multi_grid)))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.relu1(self.bn1(self.conv1(x)))\n        x = self.relu2(self.bn2(self.conv2(x)))\n        x = self.relu3(self.bn3(self.conv3(x)))\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\n    def freeze(self):\n        for m in self.modules():\n            if isinstance(m, nn.BatchNorm2d):\n                m.eval()\n\n\nclass ResNetBackbone(nn.Module):\n\n    def __init__(self, pretrained=True):\n        super().__init__()\n        self.backbone = ResNet(Bottleneck, [3, 4, 23, 3])\n\n        if pretrained:\n            # saved_state_dict = torch.load(\'./network/pretrained_models/resnet101-imagenet.pth\')\n            saved_state_dict = torch.load(\'./dp/modules/backbones/pretrained_models/resnet101-imagenet.pth\',\n                                          map_location=""cpu"")\n            new_params = self.backbone.state_dict().copy()\n            for i in saved_state_dict:\n                i_parts = i.split(\'.\')\n                if not i_parts[0] == \'fc\':\n                    new_params[\'.\'.join(i_parts[0:])] = saved_state_dict[i]\n\n            self.backbone.load_state_dict(new_params)\n\n    def forward(self, input):\n        return self.backbone(input)\n'"
dorn/modules/decoders/OrdinalRegression.py,5,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-02 17:55\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : oridinal_regression_layer.py\n""""""\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass OrdinalRegressionLayer(nn.Module):\n    def __init__(self):\n        super(OrdinalRegressionLayer, self).__init__()\n\n    def forward(self, x):\n        """"""\n        :param x: NxCxHxW, N is batch_size, C is channels of features\n        :return: ord_label is ordinal outputs for each spatial locations , N x 1 x H x W\n                 ord prob is the probability of each label, N x OrdNum x H x W\n        """"""\n        N, C, H, W = x.size()\n        ord_num = C // 2\n\n        # implementation according to the paper\n        # A = x[:, ::2, :, :]\n        # B = x[:, 1::2, :, :]\n        #\n        # # A = A.reshape(N, 1, ord_num * H * W)\n        # # B = B.reshape(N, 1, ord_num * H * W)\n        # A = A.unsqueeze(dim=1)\n        # B = B.unsqueeze(dim=1)\n        # concat_feats = torch.cat((A, B), dim=1)\n        #\n        # if self.training:\n        #     prob = F.log_softmax(concat_feats, dim=1)\n        #     ord_prob = x.clone()\n        #     ord_prob[:, 0::2, :, :] = prob[:, 0, :, :, :]\n        #     ord_prob[:, 1::2, :, :] = prob[:, 1, :, :, :]\n        #     return ord_prob\n        #\n        # ord_prob = F.softmax(concat_feats, dim=1)[:, 0, ::]\n        # ord_label = torch.sum((ord_prob > 0.5), dim=1).reshape((N, 1, H, W))\n        # return ord_prob, ord_label\n\n        # reimplementation for fast speed.\n\n        x = x.view(-1, 2, ord_num, H, W)\n        if self.training:\n            prob = F.log_softmax(x, dim=1).view(N, C, H, W)\n            return prob\n\n        ord_prob = F.softmax(x, dim=1)[:, 0, :, :, :]\n        ord_label = torch.sum((ord_prob > 0.5), dim=1)\n        return ord_prob, ord_label\n'"
dorn/modules/decoders/__init__.py,0,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-02 16:47\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : __init__.py.py\n""""""'"
dorn/modules/encoders/SceneUnderstandingModule.py,3,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-04 15:17\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : SceneUnderstandingModule.py\n""""""\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom dorn.modules.layers.basic_layers import conv_bn_relu\n\n\nclass FullImageEncoder(nn.Module):\n    def __init__(self, h, w, kernel_size):\n        super(FullImageEncoder, self).__init__()\n        self.global_pooling = nn.AvgPool2d(kernel_size, stride=kernel_size, padding=kernel_size // 2)  # KITTI 16 16\n        self.dropout = nn.Dropout2d(p=0.5)\n        self.h = h // kernel_size + 1\n        self.w = w // kernel_size + 1\n        # print(""h="", self.h, "" w="", self.w, h, w)\n        self.global_fc = nn.Linear(2048 * self.h * self.w, 512)  # kitti 4x5\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(512, 512, 1)  # 1x1 \xe5\x8d\xb7\xe7\xa7\xaf\n\n    def forward(self, x):\n        # print(\'x size:\', x.size())\n        x1 = self.global_pooling(x)\n        # print(\'# x1 size:\', x1.size())\n        x2 = self.dropout(x1)\n        x3 = x2.view(-1, 2048 * self.h * self.w)  # kitti 4x5\n        x4 = self.relu(self.global_fc(x3))\n        # print(\'# x4 size:\', x4.size())\n        x4 = x4.view(-1, 512, 1, 1)\n        # print(\'# x4 size:\', x4.size())\n        x5 = self.conv1(x4)\n        # out = self.upsample(x5)\n        return x5\n\n\nclass SceneUnderstandingModule(nn.Module):\n    def __init__(self, ord_num, size, kernel_size, pyramid=[6, 12, 18], batch_norm=False):\n        # pyramid kitti [6, 12, 18] nyu [4, 8, 12]\n        super(SceneUnderstandingModule, self).__init__()\n        assert len(size) == 2\n        assert len(pyramid) == 3\n        self.size = size\n        h, w = self.size\n        self.encoder = FullImageEncoder(h // 8, w // 8, kernel_size)\n        self.aspp1 = nn.Sequential(\n            conv_bn_relu(batch_norm, 2048, 512, kernel_size=1, padding=0),\n            conv_bn_relu(batch_norm, 512, 512, kernel_size=1, padding=0)\n        )\n        self.aspp2 = nn.Sequential(\n            conv_bn_relu(batch_norm, 2048, 512, kernel_size=3, padding=pyramid[0], dilation=pyramid[0]),\n            conv_bn_relu(batch_norm, 512, 512, kernel_size=1, padding=0)\n        )\n        self.aspp3 = nn.Sequential(\n            conv_bn_relu(batch_norm, 2048, 512, kernel_size=3, padding=pyramid[1], dilation=pyramid[1]),\n            conv_bn_relu(batch_norm, 512, 512, kernel_size=1, padding=0)\n        )\n        self.aspp4 = nn.Sequential(\n            conv_bn_relu(batch_norm, 2048, 512, kernel_size=3, padding=pyramid[2], dilation=pyramid[2]),\n            conv_bn_relu(batch_norm, 512, 512, kernel_size=1, padding=0)\n        )\n        self.concat_process = nn.Sequential(\n            nn.Dropout2d(p=0.5),\n            conv_bn_relu(batch_norm, 512*5, 2048, kernel_size=1, padding=0),\n            nn.Dropout2d(p=0.5),\n            nn.Conv2d(2048, ord_num * 2, 1)\n        )\n\n    def forward(self, x):\n        N, C, H, W = x.shape\n        x1 = self.encoder(x)\n        x1 = F.interpolate(x1, size=(H, W), mode=""bilinear"", align_corners=True)\n\n        x2 = self.aspp1(x)\n        x3 = self.aspp2(x)\n        x4 = self.aspp3(x)\n        x5 = self.aspp4(x)\n\n        x6 = torch.cat((x1, x2, x3, x4, x5), dim=1)\n        out = self.concat_process(x6)\n        out = F.interpolate(out, size=self.size, mode=""bilinear"", align_corners=True)\n        return out\n'"
dorn/modules/encoders/__init__.py,0,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-02 16:49\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : __init__.py.py\n""""""'"
dorn/modules/layers/__init__.py,0,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-04 17:07\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : __init__.py.py\n""""""'"
dorn/modules/layers/basic_layers.py,3,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-04 17:07\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : basic_layers.py\n""""""\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.modules.utils import _pair, _triple\n\n\ndef consistent_padding_with_dilation(padding, dilation, dim=2):\n    assert dim == 2 or dim == 3, \'Convolution layer only support 2D and 3D\'\n    if dim == 2:\n        padding = _pair(padding)\n        dilation = _pair(dilation)\n    else:  # dim == 3\n        padding = _triple(padding)\n        dilation = _triple(dilation)\n\n    padding = list(padding)\n    for d in range(dim):\n        padding[d] = dilation[d] if dilation[d] > 1 else padding[d]\n    padding = tuple(padding)\n\n    return padding, dilation\n\n\ndef conv_bn_relu(batchNorm, in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):\n    padding, dilation = consistent_padding_with_dilation(padding, dilation, dim=2)\n    if batchNorm:\n        return nn.Sequential(\n            nn.Conv2d(\n                in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n                padding=padding, dilation=dilation, bias=False),\n            nn.BatchNorm2d(out_planes),\n            nn.ReLU(inplace=True),\n        )\n    else:\n        return nn.Sequential(\n            nn.Conv2d(\n                in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n                padding=padding, dilation=dilation, bias=True),\n            nn.ReLU(inplace=True),\n        )\n'"
dorn/modules/losses/__init__.py,0,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-03 04:35\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : __init__.py\n""""""'"
dorn/modules/losses/ordinal_regression_loss.py,9,"b'#!/usr/bin/python3\n# -*- coding: utf-8 -*-\n""""""\n@Time    : 2020-05-02 18:17\n@Author  : Wang Xin\n@Email   : wangxin_buaa@163.com\n@File    : ordinal_regression_loss.py\n""""""\n\nimport numpy as np\nimport torch\n\n\nclass OrdinalRegressionLoss(object):\n\n    def __init__(self, ord_num, beta, discretization=""SID""):\n        self.ord_num = ord_num\n        self.beta = beta\n        self.discretization = discretization\n\n    def _create_ord_label(self, gt):\n        N, H, W = gt.shape\n        # print(""gt shape:"", gt.shape)\n\n        ord_c0 = torch.ones(N, self.ord_num, H, W).to(gt.device)\n        if self.discretization == ""SID"":\n            label = self.ord_num * torch.log(gt) / np.log(self.beta)\n        else:\n            label = self.ord_num * (gt - 1.0) / (self.beta - 1.0)\n        label = label.long()\n        mask = torch.linspace(0, self.ord_num - 1, self.ord_num, requires_grad=False) \\\n            .view(1, self.ord_num, 1, 1).to(gt.device)\n        mask = mask.repeat(N, 1, H, W).contiguous().long()\n        mask = (mask > label)\n        ord_c0[mask] = 0\n        ord_c1 = 1 - ord_c0\n        # implementation according to the paper.\n        # ord_label = torch.ones(N, self.ord_num * 2, H, W).to(gt.device)\n        # ord_label[:, 0::2, :, :] = ord_c0\n        # ord_label[:, 1::2, :, :] = ord_c1\n        # reimplementation for fast speed.\n        ord_label = torch.cat((ord_c0, ord_c1), dim=1)\n        return ord_label, mask\n\n    def __call__(self, prob, gt):\n        """"""\n        :param prob: ordinal regression probability, N x 2*Ord Num x H x W, torch.Tensor\n        :param gt: depth ground truth, NXHxW, torch.Tensor\n        :return: loss: loss value, torch.float\n        """"""\n        # N, C, H, W = prob.shape\n        valid_mask = gt > 0.\n        ord_label, mask = self._create_ord_label(gt)\n        # print(""prob shape: {}, ord label shape: {}"".format(prob.shape, ord_label.shape))\n        entropy = -prob * ord_label\n        loss = torch.sum(entropy, dim=1)[valid_mask]\n        return loss.mean()\n'"
