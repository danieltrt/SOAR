file_path,api_count,code
wildcat/__init__.py,0,b''
wildcat/demo_mit67.py,3,"b""import argparse\n\nimport torch\nimport torch.nn as nn\n\nfrom wildcat.engine import MulticlassEngine\nfrom wildcat.mit67 import Mit67\nfrom wildcat.models import resnet101_wildcat\n\nparser = argparse.ArgumentParser(description='WILDCAT Training')\nparser.add_argument('data', metavar='DIR',\n                    help='path to dataset (e.g. ../data/')\nparser.add_argument('--image-size', '-i', default=224, type=int,\n                    metavar='N', help='image size (default: 224)')\nparser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n                    help='number of data loading workers (default: 4)')\nparser.add_argument('--epochs', default=20, type=int, metavar='N',\n                    help='number of total epochs to run')\nparser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n                    help='manual epoch number (useful on restarts)')\nparser.add_argument('-b', '--batch-size', default=16, type=int,\n                    metavar='N', help='mini-batch size (default: 256)')\nparser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n                    metavar='LR', help='initial learning rate')\nparser.add_argument('--lrp', '--learning-rate-pretrained', default=0.1, type=float,\n                    metavar='LR', help='learning rate for pre-trained layers')\nparser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n                    help='momentum')\nparser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n                    metavar='W', help='weight decay (default: 1e-4)')\nparser.add_argument('--print-freq', '-p', default=0, type=int,\n                    metavar='N', help='print frequency (default: 10)')\nparser.add_argument('--resume', default='', type=str, metavar='PATH',\n                    help='path to latest checkpoint (default: none)')\nparser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n                    help='evaluate model on validation set')\nparser.add_argument('--k', default=1, type=float,\n                    metavar='N', help='number of regions (default: 1)')\nparser.add_argument('--alpha', default=1, type=float,\n                    metavar='N', help='weight for the min regions (default: 1)')\nparser.add_argument('--maps', default=1, type=int,\n                    metavar='N', help='number of maps per class (default: 1)')\n\n\ndef main_voc2007():\n    global args, best_prec1, use_gpu\n    args = parser.parse_args()\n\n    use_gpu = torch.cuda.is_available()\n\n    # define dataset\n    train_dataset = Mit67(args.data, 'train')\n    val_dataset = Mit67(args.data, 'test')\n    num_classes = 67\n\n    # load model\n    model = resnet101_wildcat(num_classes, pretrained=True, kmax=args.k, alpha=args.alpha, num_maps=args.maps)\n    print('classifier', model.classifier)\n    print('spatial pooling', model.spatial_pooling)\n\n    # define loss function (criterion)\n    criterion = nn.CrossEntropyLoss()\n\n    # define optimizer\n    optimizer = torch.optim.SGD(model.get_config_optim(args.lr, args.lrp),\n                                lr=args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    state = {'batch_size': args.batch_size, 'image_size': args.image_size, 'max_epochs': args.epochs,\n             'evaluate': args.evaluate, 'resume': args.resume}\n    state['difficult_examples'] = True\n    state['save_model_path'] = '../expes/models/mit67/'\n\n    engine = MulticlassEngine(state)\n    engine.learning(model, criterion, train_dataset, val_dataset, optimizer)\n\n\nif __name__ == '__main__':\n    main_voc2007()\n"""
wildcat/demo_voc2007.py,3,"b""import argparse\n\nimport torch\nimport torch.nn as nn\n\nfrom wildcat.engine import MultiLabelMAPEngine\nfrom wildcat.models import resnet101_wildcat\nfrom wildcat.voc import Voc2007Classification\n\nparser = argparse.ArgumentParser(description='WILDCAT Training')\nparser.add_argument('data', metavar='DIR',\n                    help='path to dataset (e.g. ../data/')\nparser.add_argument('--image-size', '-i', default=224, type=int,\n                    metavar='N', help='image size (default: 224)')\nparser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n                    help='number of data loading workers (default: 4)')\nparser.add_argument('--epochs', default=20, type=int, metavar='N',\n                    help='number of total epochs to run')\nparser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n                    help='manual epoch number (useful on restarts)')\nparser.add_argument('-b', '--batch-size', default=16, type=int,\n                    metavar='N', help='mini-batch size (default: 256)')\nparser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n                    metavar='LR', help='initial learning rate')\nparser.add_argument('--lrp', '--learning-rate-pretrained', default=0.1, type=float,\n                    metavar='LR', help='learning rate for pre-trained layers')\nparser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n                    help='momentum')\nparser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n                    metavar='W', help='weight decay (default: 1e-4)')\nparser.add_argument('--print-freq', '-p', default=0, type=int,\n                    metavar='N', help='print frequency (default: 10)')\nparser.add_argument('--resume', default='', type=str, metavar='PATH',\n                    help='path to latest checkpoint (default: none)')\nparser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n                    help='evaluate model on validation set')\nparser.add_argument('--k', default=1, type=float,\n                    metavar='N', help='number of regions (default: 1)')\nparser.add_argument('--alpha', default=1, type=float,\n                    metavar='N', help='weight for the min regions (default: 1)')\nparser.add_argument('--maps', default=1, type=int,\n                    metavar='N', help='number of maps per class (default: 1)')\n\n\ndef main_voc2007():\n    global args, best_prec1, use_gpu\n    args = parser.parse_args()\n\n    use_gpu = torch.cuda.is_available()\n\n    # define dataset\n    train_dataset = Voc2007Classification(args.data, 'trainval')\n    val_dataset = Voc2007Classification(args.data, 'test')\n    num_classes = 20\n\n    # load model\n    model = resnet101_wildcat(num_classes, pretrained=True, kmax=args.k, alpha=args.alpha, num_maps=args.maps)\n    print('classifier', model.classifier)\n    print('spatial pooling', model.spatial_pooling)\n\n    # define loss function (criterion)\n    criterion = nn.MultiLabelSoftMarginLoss()\n\n    # define optimizer\n    optimizer = torch.optim.SGD(model.get_config_optim(args.lr, args.lrp),\n                                lr=args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    state = {'batch_size': args.batch_size, 'image_size': args.image_size, 'max_epochs': args.epochs,\n             'evaluate': args.evaluate, 'resume': args.resume}\n    state['difficult_examples'] = True\n    state['save_model_path'] = '../expes/models/voc2007/'\n\n    engine = MultiLabelMAPEngine(state)\n    engine.learning(model, criterion, train_dataset, val_dataset, optimizer)\n\n\nif __name__ == '__main__':\n    main_voc2007()\n"""
wildcat/engine.py,13,"b'import os\nimport shutil\nimport time\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn.parallel\nimport torch.optim\nimport torch.utils.data\nimport torchnet as tnt\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\n\nfrom wildcat.util import AveragePrecisionMeter, Warp\n\n\nclass Engine(object):\n    def __init__(self, state={}):\n        self.state = state\n        if self._state(\'use_gpu\') is None:\n            self.state[\'use_gpu\'] = torch.cuda.is_available()\n\n        if self._state(\'image_size\') is None:\n            self.state[\'image_size\'] = 224\n\n        if self._state(\'batch_size\') is None:\n            self.state[\'batch_size\'] = 64\n\n        if self._state(\'workers\') is None:\n            self.state[\'workers\'] = 4\n\n        if self._state(\'multi_gpu\') is None:\n            self.state[\'multi_gpu\'] = False\n\n        if self._state(\'device_ids\') is None:\n            self.state[\'device_ids\'] = [0, 1, 2, 3]\n\n        if self._state(\'evaluate\') is None:\n            self.state[\'evaluate\'] = False\n\n        if self._state(\'start_epoch\') is None:\n            self.state[\'start_epoch\'] = 0\n\n        if self._state(\'max_epochs\') is None:\n            self.state[\'max_epochs\'] = 90\n\n        if self._state(\'epoch_step\') is None:\n            self.state[\'epoch_step\'] = []\n\n        # meters\n        self.state[\'meter_loss\'] = tnt.meter.AverageValueMeter()\n        # time measure\n        self.state[\'batch_time\'] = tnt.meter.AverageValueMeter()\n        self.state[\'data_time\'] = tnt.meter.AverageValueMeter()\n        # display parameters\n        if self._state(\'use_pb\') is None:\n            self.state[\'use_pb\'] = True\n        if self._state(\'print_freq\') is None:\n            self.state[\'print_freq\'] = 0\n\n    def _state(self, name):\n        if name in self.state:\n            return self.state[name]\n\n    def on_start_epoch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        self.state[\'meter_loss\'].reset()\n        self.state[\'batch_time\'].reset()\n        self.state[\'data_time\'].reset()\n\n    def on_end_epoch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        loss = self.state[\'meter_loss\'].value()[0]\n        if display:\n            if training:\n                print(\'Epoch: [{0}]\\t\'\n                      \'Loss {loss:.4f}\'.format(self.state[\'epoch\'], loss=loss))\n            else:\n                print(\'Test: \\t Loss {loss:.4f}\'.format(loss=loss))\n        return loss\n\n    def on_start_batch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        pass\n\n    def on_end_batch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n\n        # record loss\n        self.state[\'loss_batch\'] = self.state[\'loss\'].data[0]\n        self.state[\'meter_loss\'].add(self.state[\'loss_batch\'])\n\n        if display and self.state[\'print_freq\'] != 0 and self.state[\'iteration\'] % self.state[\'print_freq\'] == 0:\n            loss = self.state[\'meter_loss\'].value()[0]\n            batch_time = self.state[\'batch_time\'].value()[0]\n            data_time = self.state[\'data_time\'].value()[0]\n            if training:\n                print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                      \'Time {batch_time_current:.3f} ({batch_time:.3f})\\t\'\n                      \'Data {data_time_current:.3f} ({data_time:.3f})\\t\'\n                      \'Loss {loss_current:.4f} ({loss:.4f})\'.format(\n                    self.state[\'epoch\'], self.state[\'iteration\'], len(data_loader),\n                    batch_time_current=self.state[\'batch_time_current\'],\n                    batch_time=batch_time, data_time_current=self.state[\'data_time_batch\'],\n                    data_time=data_time, loss_current=self.state[\'loss_batch\'], loss=loss))\n            else:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time_current:.3f} ({batch_time:.3f})\\t\'\n                      \'Data {data_time_current:.3f} ({data_time:.3f})\\t\'\n                      \'Loss {loss_current:.4f} ({loss:.4f})\'.format(\n                    self.state[\'iteration\'], len(data_loader), batch_time_current=self.state[\'batch_time_current\'],\n                    batch_time=batch_time, data_time_current=self.state[\'data_time_batch\'],\n                    data_time=data_time, loss_current=self.state[\'loss_batch\'], loss=loss))\n\n    def on_forward(self, training, model, criterion, data_loader, optimizer=None, display=True):\n\n        input_var = torch.autograd.Variable(self.state[\'input\'])\n        target_var = torch.autograd.Variable(self.state[\'target\'])\n\n        if not training:\n            input_var.volatile = True\n            target_var.volatile = True\n\n        # compute output\n        self.state[\'output\'] = model(input_var)\n        self.state[\'loss\'] = criterion(self.state[\'output\'], target_var)\n\n        if training:\n            optimizer.zero_grad()\n            self.state[\'loss\'].backward()\n            optimizer.step()\n\n    def init_learning(self, model, criterion):\n\n        if self._state(\'train_transform\') is None:\n            normalize = transforms.Normalize(mean=model.image_normalization_mean,\n                                             std=model.image_normalization_std)\n            self.state[\'train_transform\'] = transforms.Compose([\n                Warp(self.state[\'image_size\']),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n\n        if self._state(\'val_transform\') is None:\n            normalize = transforms.Normalize(mean=model.image_normalization_mean,\n                                             std=model.image_normalization_std)\n            self.state[\'val_transform\'] = transforms.Compose([\n                Warp(self.state[\'image_size\']),\n                transforms.ToTensor(),\n                normalize,\n            ])\n\n        self.state[\'best_score\'] = 0\n\n    def learning(self, model, criterion, train_dataset, val_dataset, optimizer=None):\n\n        self.init_learning(model, criterion)\n\n        # define train and val transform\n        train_dataset.transform = self.state[\'train_transform\']\n        train_dataset.target_transform = self._state(\'train_target_transform\')\n        val_dataset.transform = self.state[\'val_transform\']\n        val_dataset.target_transform = self._state(\'val_target_transform\')\n\n        # data loading code\n        train_loader = torch.utils.data.DataLoader(train_dataset,\n                                                   batch_size=self.state[\'batch_size\'], shuffle=True,\n                                                   num_workers=self.state[\'workers\'])\n\n        val_loader = torch.utils.data.DataLoader(val_dataset,\n                                                 batch_size=self.state[\'batch_size\'], shuffle=False,\n                                                 num_workers=self.state[\'workers\'])\n\n        # optionally resume from a checkpoint\n        if self._state(\'resume\') is not None:\n            if os.path.isfile(self.state[\'resume\']):\n                print(""=> loading checkpoint \'{}\'"".format(self.state[\'resume\']))\n                checkpoint = torch.load(self.state[\'resume\'])\n                self.state[\'start_epoch\'] = checkpoint[\'epoch\']\n                self.state[\'best_score\'] = checkpoint[\'best_score\']\n                model.load_state_dict(checkpoint[\'state_dict\'])\n                print(""=> loaded checkpoint \'{}\' (epoch {})""\n                      .format(self.state[\'evaluate\'], checkpoint[\'epoch\']))\n            else:\n                print(""=> no checkpoint found at \'{}\'"".format(self.state[\'resume\']))\n\n\n        if self.state[\'use_gpu\']:\n            train_loader.pin_memory = True\n            val_loader.pin_memory = True\n            cudnn.benchmark = True\n\n            if self.state[\'multi_gpu\']:\n                model = torch.nn.DataParallel(model, device_ids=self.state[\'device_ids\']).cuda()\n            else:\n                model = torch.nn.DataParallel(model).cuda()\n\n            criterion = criterion.cuda()\n\n        if self.state[\'evaluate\']:\n            self.validate(val_loader, model, criterion)\n            return\n\n        # TODO define optimizer\n\n        for epoch in range(self.state[\'start_epoch\'], self.state[\'max_epochs\']):\n            self.state[\'epoch\'] = epoch\n            self.adjust_learning_rate(optimizer)\n\n            # train for one epoch\n            self.train(train_loader, model, criterion, optimizer, epoch)\n\n            # evaluate on validation set\n            prec1 = self.validate(val_loader, model, criterion)\n\n            # remember best prec@1 and save checkpoint\n            is_best = prec1 > self.state[\'best_score\']\n            self.state[\'best_score\'] = max(prec1, self.state[\'best_score\'])\n            self.save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'arch\': self._state(\'arch\'),\n                \'state_dict\': model.module.state_dict() if self.state[\'use_gpu\'] else model.state_dict(),\n                \'best_score\': self.state[\'best_score\'],\n            }, is_best)\n\n            print(\' *** best={best:.3f}\'.format(best=self.state[\'best_score\']))\n\n    def train(self, data_loader, model, criterion, optimizer, epoch):\n\n        # switch to train mode\n        model.train()\n\n        self.on_start_epoch(True, model, criterion, data_loader, optimizer)\n\n        if self.state[\'use_pb\']:\n            data_loader = tqdm(data_loader, desc=\'Training\')\n\n        end = time.time()\n        for i, (input, target) in enumerate(data_loader):\n            # measure data loading time\n            self.state[\'iteration\'] = i\n            self.state[\'data_time_batch\'] = time.time() - end\n            self.state[\'data_time\'].add(self.state[\'data_time_batch\'])\n\n            self.state[\'input\'] = input\n            self.state[\'target\'] = target\n\n            self.on_start_batch(True, model, criterion, data_loader, optimizer)\n\n            if self.state[\'use_gpu\']:\n                self.state[\'target\'] = self.state[\'target\'].cuda(async=True)\n\n            self.on_forward(True, model, criterion, data_loader, optimizer)\n\n            # measure elapsed time\n            self.state[\'batch_time_current\'] = time.time() - end\n            self.state[\'batch_time\'].add(self.state[\'batch_time_current\'])\n            end = time.time()\n            # measure accuracy\n            self.on_end_batch(True, model, criterion, data_loader, optimizer)\n\n        self.on_end_epoch(True, model, criterion, data_loader, optimizer)\n\n    def validate(self, data_loader, model, criterion):\n\n        # switch to evaluate mode\n        model.eval()\n\n        self.on_start_epoch(False, model, criterion, data_loader)\n\n        if self.state[\'use_pb\']:\n            data_loader = tqdm(data_loader, desc=\'Test\')\n\n        end = time.time()\n        for i, (input, target) in enumerate(data_loader):\n            # measure data loading time\n            self.state[\'iteration\'] = i\n            self.state[\'data_time_batch\'] = time.time() - end\n            self.state[\'data_time\'].add(self.state[\'data_time_batch\'])\n\n            self.state[\'input\'] = input\n            self.state[\'target\'] = target\n\n            self.on_start_batch(False, model, criterion, data_loader)\n\n            if self.state[\'use_gpu\']:\n                self.state[\'target\'] = self.state[\'target\'].cuda(async=True)\n\n            self.on_forward(False, model, criterion, data_loader)\n\n            # measure elapsed time\n            self.state[\'batch_time_current\'] = time.time() - end\n            self.state[\'batch_time\'].add(self.state[\'batch_time_current\'])\n            end = time.time()\n            # measure accuracy\n            self.on_end_batch(False, model, criterion, data_loader)\n\n        score = self.on_end_epoch(False, model, criterion, data_loader)\n\n        return score\n\n    def save_checkpoint(self, state, is_best, filename=\'checkpoint.pth.tar\'):\n        if self._state(\'save_model_path\') is not None:\n            filename_ = filename\n            filename = os.path.join(self.state[\'save_model_path\'], filename_)\n            if not os.path.exists(self.state[\'save_model_path\']):\n                os.makedirs(self.state[\'save_model_path\'])\n        print(\'save model {filename}\'.format(filename=filename))\n        torch.save(state, filename)\n        if is_best:\n            filename_best = \'model_best.pth.tar\'\n            if self._state(\'save_model_path\') is not None:\n                filename_best = os.path.join(self.state[\'save_model_path\'], filename_best)\n            shutil.copyfile(filename, filename_best)\n            if self._state(\'save_model_path\') is not None:\n                if self._state(\'filename_previous_best\') is not None:\n                    os.remove(self._state(\'filename_previous_best\'))\n                filename_best = os.path.join(self.state[\'save_model_path\'], \'model_best_{score:.4f}.pth.tar\'.format(score=state[\'best_score\']))\n                shutil.copyfile(filename, filename_best)\n                self.state[\'filename_previous_best\'] = filename_best\n\n    def adjust_learning_rate(self, optimizer):\n        """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n        # lr = args.lr * (0.1 ** (epoch // 30))\n        if self.state[\'epoch\'] is not 0 and self.state[\'epoch\'] in self.state[\'epoch_step\']:\n            print(\'update learning rate\')\n            for param_group in optimizer.state_dict()[\'param_groups\']:\n                param_group[\'lr\'] = param_group[\'lr\'] * 0.1\n                print(param_group[\'lr\'])\n\n\nclass MulticlassEngine(Engine):\n    def __init__(self, state):\n        Engine.__init__(self, state)\n        self.state[\'classacc\'] = tnt.meter.ClassErrorMeter(accuracy=True)\n\n    def on_start_epoch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        Engine.on_start_epoch(self, training, model, criterion, data_loader, optimizer)\n        self.state[\'classacc\'].reset()\n\n    def on_end_epoch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        top1 = self.state[\'classacc\'].value()[0]\n        loss = self.state[\'meter_loss\'].value()[0]\n        if display:\n            if training:\n                # print(model.module.spatial_pooling)\n                print(\'Epoch: [{0}]\\t\'\n                      \'Loss {loss:.4f}\\t\'\n                      \'Prec@1 {top1:.3f}\'.format(self.state[\'epoch\'], loss=loss, top1=top1))\n            else:\n                print(\'Test: \\t Loss {loss:.4f}\\t Prec@1 {top1:.3f}\'.format(loss=loss, top1=top1))\n\n        return top1\n\n    def on_end_batch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n\n        Engine.on_end_batch(self, training, model, criterion, data_loader, optimizer, display=False)\n\n        # measure accuracy\n        self.state[\'classacc\'].add(self.state[\'output\'].data, self.state[\'target\'])\n\n        if display and self.state[\'print_freq\'] != 0 and self.state[\'iteration\'] % self.state[\'print_freq\'] == 0:\n            top1 = self.state[\'classacc\'].value()[0]\n            loss = self.state[\'meter_loss\'].value()[0]\n            batch_time = self.state[\'batch_time\'].value()[0]\n            data_time = self.state[\'data_time\'].value()[0]\n            if training:\n                print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                      \'Time {batch_time_current:.3f} ({batch_time:.3f})\\t\'\n                      \'Data {data_time_current:.3f} ({data_time:.3f})\\t\'\n                      \'Loss {loss_current:.4f} ({loss:.4f})\\t\'\n                      \'Prec@1 {top1:.3f}\'.format(\n                    self.state[\'epoch\'], self.state[\'iteration\'], len(data_loader),\n                    batch_time_current=self.state[\'batch_time_current\'], batch_time=batch_time,\n                    data_time_current=self.state[\'data_time_batch\'], data_time=data_time,\n                    loss_current=self.state[\'loss_batch\'], loss=loss, top1=top1))\n            else:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time_current:.3f} ({batch_time:.3f})\\t\'\n                      \'Data {data_time_current:.3f} ({data_time:.3f})\\t\'\n                      \'Loss {loss_current:.4f} ({loss:.4f})\\t\'\n                      \'Prec@1 {top1:.3f}\'.format(\n                    self.state[\'iteration\'], len(data_loader), batch_time_current=self.state[\'batch_time_current\'],\n                    batch_time=batch_time, data_time_current=self.state[\'data_time_batch\'],\n                    data_time=data_time, loss_current=self.state[\'loss_batch\'], loss=loss, top1=top1))\n\n\nclass MulticlassTop5Engine(Engine):\n    def __init__(self, state):\n        Engine.__init__(self, state)\n        self.state[\'classacc\'] = tnt.meter.ClassErrorMeter(topk=[1, 5], accuracy=True)\n\n    def on_start_epoch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        Engine.on_start_epoch(self, training, model, criterion, data_loader, optimizer)\n        self.state[\'classacc\'].reset()\n\n    def on_end_epoch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        top1 = self.state[\'classacc\'].value()[0]\n        top5 = self.state[\'classacc\'].value()[1]\n        loss = self.state[\'meter_loss\'].value()[0]\n        if display:\n            if training:\n                print(\'Epoch: [{0}]\\t\'\n                      \'Loss {loss:.4f}\\t\'\n                      \'Prec@1 {top1:.3f}\\t\'\n                      \'Prec@5 {top5:.3f}\'.format(self.state[\'epoch\'], loss=loss, top1=top1, top5=top5))\n            else:\n                print(\'Test: \\t\'\n                      \'Loss {loss:.4f}\\t\'\n                      \'Prec@1 {top1:.3f}\\t\'\n                      \'Prec@5 {top5:.3f}\'.format(loss=loss, top1=top1, top5=top5))\n\n        return top1\n\n    def on_end_batch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n\n        Engine.on_end_batch(self, training, model, criterion, data_loader, optimizer, display=False)\n\n        # measure accuracy\n        self.state[\'classacc\'].add(self.state[\'output\'].data, self.state[\'target\'])\n\n        if display and self.state[\'print_freq\'] != 0 and self.state[\'iteration\'] % self.state[\'print_freq\'] == 0:\n            top1 = self.state[\'classacc\'].value()[0]\n            top5 = self.state[\'classacc\'].value()[1]\n            loss = self.state[\'meter_loss\'].value()[0]\n            batch_time = self.state[\'batch_time\'].value()[0]\n            data_time = self.state[\'data_time\'].value()[0]\n            if training:\n                print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                      \'Time {batch_time_current:.3f} ({batch_time:.3f})\\t\'\n                      \'Data {data_time_current:.3f} ({data_time:.3f})\\t\'\n                      \'Loss {loss_current:.4f} ({loss:.4f})\\t\'\n                      \'Prec@1 {top1:.3f}\\t\'\n                      \'Prec@5 {top5:.3f}\'.format(\n                    self.state[\'epoch\'], self.state[\'iteration\'], len(data_loader),\n                    batch_time_current=self.state[\'batch_time_current\'], batch_time=batch_time,\n                    data_time_current=self.state[\'data_time_batch\'], data_time=data_time,\n                    loss_current=self.state[\'loss_batch\'], loss=loss, top1=top1, top5=top5))\n            else:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time_current:.3f} ({batch_time:.3f})\\t\'\n                      \'Data {data_time_current:.3f} ({data_time:.3f})\\t\'\n                      \'Loss {loss_current:.4f} ({loss:.4f})\\t\'\n                      \'Prec@1 {top1:.3f}\\t\'\n                      \'Prec@5 {top5:.3f}\'.format(\n                    self.state[\'iteration\'], len(data_loader), batch_time_current=self.state[\'batch_time_current\'],\n                    batch_time=batch_time, data_time_current=self.state[\'data_time_batch\'],\n                    data_time=data_time, loss_current=self.state[\'loss_batch\'], loss=loss, top1=top1, top5=top5))\n\n\nclass MultiLabelMAPEngine(Engine):\n    def __init__(self, state):\n        Engine.__init__(self, state)\n        if self._state(\'difficult_examples\') is None:\n            self.state[\'difficult_examples\'] = False\n        self.state[\'ap_meter\'] = AveragePrecisionMeter(self.state[\'difficult_examples\'])\n\n    def on_start_epoch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        Engine.on_start_epoch(self, training, model, criterion, data_loader, optimizer)\n        self.state[\'ap_meter\'].reset()\n\n    def on_end_epoch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n        map = 100 * self.state[\'ap_meter\'].value().mean()\n        loss = self.state[\'meter_loss\'].value()[0]\n        if display:\n            if training:\n                # print(model.module.spatial_pooling)\n                print(\'Epoch: [{0}]\\t\'\n                      \'Loss {loss:.4f}\\t\'\n                      \'mAP {map:.3f}\'.format(self.state[\'epoch\'], loss=loss, map=map))\n            else:\n                print(\'Test: \\t Loss {loss:.4f}\\t mAP {map:.3f}\'.format(loss=loss, map=map))\n\n        return map\n\n    def on_start_batch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n\n        self.state[\'target_gt\'] = self.state[\'target\'].clone()\n        self.state[\'target\'][self.state[\'target\'] == 0] = 1\n        self.state[\'target\'][self.state[\'target\'] == -1] = 0\n\n        input = self.state[\'input\']\n        self.state[\'input\'] = input[0]\n        self.state[\'name\'] = input[1]\n\n    def on_end_batch(self, training, model, criterion, data_loader, optimizer=None, display=True):\n\n        Engine.on_end_batch(self, training, model, criterion, data_loader, optimizer, display=False)\n\n        # measure mAP\n        self.state[\'ap_meter\'].add(self.state[\'output\'].data, self.state[\'target_gt\'])\n\n        if display and self.state[\'print_freq\'] != 0 and self.state[\'iteration\'] % self.state[\'print_freq\'] == 0:\n            loss = self.state[\'meter_loss\'].value()[0]\n            batch_time = self.state[\'batch_time\'].value()[0]\n            data_time = self.state[\'data_time\'].value()[0]\n            if training:\n                print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                      \'Time {batch_time_current:.3f} ({batch_time:.3f})\\t\'\n                      \'Data {data_time_current:.3f} ({data_time:.3f})\\t\'\n                      \'Loss {loss_current:.4f} ({loss:.4f})\'.format(\n                    self.state[\'epoch\'], self.state[\'iteration\'], len(data_loader),\n                    batch_time_current=self.state[\'batch_time_current\'],\n                    batch_time=batch_time, data_time_current=self.state[\'data_time_batch\'],\n                    data_time=data_time, loss_current=self.state[\'loss_batch\'], loss=loss))\n            else:\n                print(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time_current:.3f} ({batch_time:.3f})\\t\'\n                      \'Data {data_time_current:.3f} ({data_time:.3f})\\t\'\n                      \'Loss {loss_current:.4f} ({loss:.4f})\'.format(\n                    self.state[\'iteration\'], len(data_loader), batch_time_current=self.state[\'batch_time_current\'],\n                    batch_time=batch_time, data_time_current=self.state[\'data_time_batch\'],\n                    data_time=data_time, loss_current=self.state[\'loss_batch\'], loss=loss))'"
wildcat/mit67.py,1,"b'import csv\nimport os\nimport os.path\nimport tarfile\nfrom urllib.parse import urlparse\n\nimport torch.utils.data as data\nfrom PIL import Image\n\nfrom wildcat import util\n\nurls = {\n    \'images\': \'http://groups.csail.mit.edu/vision/LabelMe/NewImages/indoorCVPR_09.tar\',\n    \'train_file\': \'http://web.mit.edu/torralba/www/TrainImages.txt\',\n    \'test_file\': \'http://web.mit.edu/torralba/www/TestImages.txt\'\n}\n\n\ndef download(root):\n    """""" Download the data """"""\n\n    tmpdir = os.path.join(root, \'tmp\')\n    path_images = os.path.join(root, \'Images\')\n\n    # create directory\n    if not os.path.exists(root):\n        os.makedirs(root)\n\n    # create directory\n    if not os.path.exists(tmpdir):\n        os.makedirs(tmpdir)\n\n    if not os.path.exists(path_images):\n\n        # download train/val images/annotations\n        parts = urlparse(urls[\'images\'])\n        filename = os.path.basename(parts.path)\n        cached_file = os.path.join(tmpdir, filename)\n\n        if not os.path.exists(cached_file):\n            print(\'Downloading: ""{}"" to {}\\n\'.format(urls[\'images\'], cached_file))\n            util.download_url(urls[\'images\'], cached_file)\n\n        # extract file\n        print(\'[dataset] Extracting tar file {file} to {path}\'.format(file=cached_file, path=root))\n        cwd = os.getcwd()\n        tar = tarfile.open(cached_file, ""r"")\n        os.chdir(root)\n        tar.extractall()\n        tar.close()\n        os.chdir(cwd)\n        print(\'[dataset] Done!\')\n\n    # download train file\n    parts = urlparse(urls[\'train_file\'])\n    filename = os.path.basename(parts.path)\n    cached_file = os.path.join(root, filename)\n\n    if not os.path.exists(cached_file):\n        print(\'Downloading: ""{}"" to {}\\n\'.format(urls[\'train_file\'], cached_file))\n        util.download_url(urls[\'train_file\'], cached_file)\n\n    # download test file\n    parts = urlparse(urls[\'test_file\'])\n    filename = os.path.basename(parts.path)\n    cached_file = os.path.join(root, filename)\n\n    if not os.path.exists(cached_file):\n        print(\'Downloading: ""{}"" to {}\\n\'.format(urls[\'test_file\'], cached_file))\n        util.download_url(urls[\'test_file\'], cached_file)\n\n\ndef find_classes(dir):\n    fname = os.path.join(dir, \'TrainImages.txt\')\n    # read the content of the file\n    with open(fname) as f:\n        content = f.readlines()\n    # remove whitespace characters like `\\n` at the end of each line\n    content = [x.strip() for x in content]\n\n    # find the list of classes\n    classes = dict()\n    for x in content:\n        classes[x.split(""/"")[0]] = 0\n\n    # assign a label for each class\n    index = 0\n    for key in sorted(classes):\n        classes[key] = index\n        index += 1\n\n    return classes\n\n\ndef make_dataset(dir, classes, set):\n    images = []\n\n    if set == \'train\':\n        fname = os.path.join(dir, \'TrainImages.txt\')\n    elif set == \'test\':\n        fname = os.path.join(dir, \'TestImages.txt\')\n\n    # read the content of the file\n    with open(fname) as f:\n        content = f.readlines()\n    # remove whitespace characters like `\\n` at the end of each line\n    content = [x.strip() for x in content]\n\n    for x in content:\n        path = x\n        label = classes[x.split(""/"")[0]]\n        item = (path, label)\n        images.append(item)\n\n    return images\n\n\ndef write_csv_file(dir, images, set):\n    csv_file = os.path.join(dir, set + \'.csv\')\n    if not os.path.exists(csv_file):\n\n        # write a csv file\n        print(\'[dataset] write file %s\' % csv_file)\n        with open(csv_file, \'w\') as csvfile:\n            fieldnames = [\'name\', \'label\']\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n            writer.writeheader()\n            for x in images:\n                writer.writerow({\'name\': x[0], \'label\': x[1]})\n\n        csvfile.close()\n\n\nclass Mit67(data.Dataset):\n    def __init__(self, root, set, transform=None, target_transform=None):\n        self.root = root\n        self.set = set\n        self.transform = transform\n        self.target_transform = target_transform\n        self.path_images = os.path.join(self.root, \'Images\')\n\n        download(self.root)\n\n        self.classes = find_classes(self.root)\n        self.images = make_dataset(self.root, self.classes, set)\n\n        print(\'[dataset] MIT67 set=%s  number of classes=%d  number of images=%d\' % (\n            set, len(self.classes), len(self.images)))\n\n        write_csv_file(self.root, self.images, set)\n\n    def __getitem__(self, index):\n        path, target = self.images[index]\n        img = Image.open(os.path.join(self.path_images, path)).convert(\'RGB\')\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.images)\n\n    def get_number_classes(self):\n        return len(self.classes)\n'"
wildcat/models.py,1,"b""import torch.nn as nn\nimport torchvision.models as models\n\nfrom wildcat.pooling import WildcatPool2d, ClassWisePool\n\n\nclass ResNetWSL(nn.Module):\n\n    def __init__(self, model, num_classes, pooling=WildcatPool2d(), dense=False):\n        super(ResNetWSL, self).__init__()\n\n        self.dense = dense\n\n        self.features = nn.Sequential(\n            model.conv1,\n            model.bn1,\n            model.relu,\n            model.maxpool,\n            model.layer1,\n            model.layer2,\n            model.layer3,\n            model.layer4)\n\n        # classification layer\n        num_features = model.layer4[1].conv1.in_channels\n        self.classifier = nn.Sequential(\n            nn.Conv2d(num_features, num_classes, kernel_size=1, stride=1, padding=0, bias=True))\n\n        self.spatial_pooling = pooling\n\n        # image normalization\n        self.image_normalization_mean = [0.485, 0.456, 0.406]\n        self.image_normalization_std = [0.229, 0.224, 0.225]\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        if not self.dense:\n            x = self.spatial_pooling(x)\n        return x\n\n    def get_config_optim(self, lr, lrp):\n        return [{'params': self.features.parameters(), 'lr': lr * lrp},\n                {'params': self.classifier.parameters()},\n                {'params': self.spatial_pooling.parameters()}]\n\n\ndef resnet50_wildcat(num_classes, pretrained=True, kmax=1, kmin=None, alpha=1, num_maps=1):\n    model = models.resnet50(pretrained)\n    pooling = nn.Sequential()\n    pooling.add_module('class_wise', ClassWisePool(num_maps))\n    pooling.add_module('spatial', WildcatPool2d(kmax, kmin, alpha))\n    return ResNetWSL(model, num_classes * num_maps, pooling=pooling)\n\n\ndef resnet101_wildcat(num_classes, pretrained=True, kmax=1, kmin=None, alpha=1, num_maps=1):\n    model = models.resnet101(pretrained)\n    pooling = nn.Sequential()\n    pooling.add_module('class_wise', ClassWisePool(num_maps))\n    pooling.add_module('spatial', WildcatPool2d(kmax, kmin, alpha))\n    return ResNetWSL(model, num_classes * num_maps, pooling=pooling)\n"""
wildcat/pooling.py,4,"b""import sys\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Function, Variable\n\n\nclass WildcatPool2dFunction(Function):\n    def __init__(self, kmax, kmin, alpha):\n        super(WildcatPool2dFunction, self).__init__()\n        self.kmax = kmax\n        self.kmin = kmin\n        self.alpha = alpha\n\n    def get_positive_k(self, k, n):\n        if k <= 0:\n            return 0\n        elif k < 1:\n            return round(k * n)\n        elif k > n:\n            return int(n)\n        else:\n            return int(k)\n\n    def forward(self, input):\n        batch_size = input.size(0)\n        num_channels = input.size(1)\n        h = input.size(2)\n        w = input.size(3)\n\n        n = h * w  # number of regions\n\n        kmax = self.get_positive_k(self.kmax, n)\n        kmin = self.get_positive_k(self.kmin, n)\n\n        sorted, indices = input.new(), input.new().long()\n        torch.sort(input.view(batch_size, num_channels, n), dim=2, descending=True, out=(sorted, indices))\n\n        self.indices_max = indices.narrow(2, 0, kmax)\n        output = sorted.narrow(2, 0, kmax).sum(2).div_(kmax)\n\n        if kmin > 0 and self.alpha is not 0:\n            self.indices_min = indices.narrow(2, n - kmin, kmin)\n            output.add_(sorted.narrow(2, n - kmin, kmin).sum(2).mul_(self.alpha / kmin)).div_(2)\n\n        self.save_for_backward(input)\n        return output.view(batch_size, num_channels)\n\n    def backward(self, grad_output):\n\n        input, = self.saved_tensors\n\n        batch_size = input.size(0)\n        num_channels = input.size(1)\n        h = input.size(2)\n        w = input.size(3)\n\n        n = h * w  # number of regions\n\n        kmax = self.get_positive_k(self.kmax, n)\n        kmin = self.get_positive_k(self.kmin, n)\n\n        grad_output_max = grad_output.view(batch_size, num_channels, 1).expand(batch_size, num_channels, kmax)\n\n        grad_input = grad_output.new().resize_(batch_size, num_channels, n).fill_(0).scatter_(2, self.indices_max,\n                                                                                              grad_output_max).div_(\n            kmax)\n\n        if kmin > 0 and self.alpha is not 0:\n            grad_output_min = grad_output.view(batch_size, num_channels, 1).expand(batch_size, num_channels, kmin)\n            grad_input_min = grad_output.new().resize_(batch_size, num_channels, n).fill_(0).scatter_(2,\n                                                                                                      self.indices_min,\n                                                                                                      grad_output_min).mul_(\n                self.alpha / kmin)\n            grad_input.add_(grad_input_min).div_(2)\n\n        return grad_input.view(batch_size, num_channels, h, w)\n\n\nclass WildcatPool2d(nn.Module):\n    def __init__(self, kmax=1, kmin=None, alpha=1):\n        super(WildcatPool2d, self).__init__()\n        self.kmax = kmax\n        self.kmin = kmin\n        if self.kmin is None:\n            self.kmin = self.kmax\n        self.alpha = alpha\n\n    def forward(self, input):\n        return WildcatPool2dFunction(self.kmax, self.kmin, self.alpha)(input)\n\n    def __repr__(self):\n        return self.__class__.__name__ + ' (kmax=' + str(self.kmax) + ', kmin=' + str(self.kmin) + ', alpha=' + str(\n            self.alpha) + ')'\n\n\nclass ClassWisePoolFunction(Function):\n    def __init__(self, num_maps):\n        super(ClassWisePoolFunction, self).__init__()\n        self.num_maps = num_maps\n\n    def forward(self, input):\n        # batch dimension\n        batch_size, num_channels, h, w = input.size()\n\n        if num_channels % self.num_maps != 0:\n            print('Error in ClassWisePoolFunction. The number of channels has to be a multiple of the number of maps per class')\n            sys.exit(-1)\n\n        num_outputs = int(num_channels / self.num_maps)\n        x = input.view(batch_size, num_outputs, self.num_maps, h, w)\n        output = torch.sum(x, 2)\n        self.save_for_backward(input)\n        return output.view(batch_size, num_outputs, h, w) / self.num_maps\n\n    def backward(self, grad_output):\n        input, = self.saved_tensors\n\n        # batch dimension\n        batch_size, num_channels, h, w = input.size()\n        num_outputs = grad_output.size(1)\n\n        grad_input = grad_output.view(batch_size, num_outputs, 1, h, w).expand(batch_size, num_outputs, self.num_maps,\n                                                                               h, w).contiguous()\n\n        return grad_input.view(batch_size, num_channels, h, w)\n\n\nclass ClassWisePool(nn.Module):\n    def __init__(self, num_maps):\n        super(ClassWisePool, self).__init__()\n        self.num_maps = num_maps\n\n    def forward(self, input):\n        return ClassWisePoolFunction(self.num_maps)(input)\n\n    def __repr__(self):\n        return self.__class__.__name__ + ' (num_maps={num_maps})'.format(num_maps=self.num_maps)\n\n"""
wildcat/util.py,9,"b'import math\nfrom urllib.request import urlretrieve\n\nimport torch\nfrom PIL import Image\nfrom tqdm import tqdm\n\n\nclass Warp(object):\n    def __init__(self, size, interpolation=Image.BILINEAR):\n        self.size = int(size)\n        self.interpolation = interpolation\n\n    def __call__(self, img):\n        return img.resize((self.size, self.size), self.interpolation)\n\n    def __str__(self):\n        return self.__class__.__name__ + \' (size={size}, interpolation={interpolation})\'.format(size=self.size,\n                                                                                                interpolation=self.interpolation)\n\n\ndef download_url(url, destination=None, progress_bar=True):\n    """"""Download a URL to a local file.\n\n    Parameters\n    ----------\n    url : str\n        The URL to download.\n    destination : str, None\n        The destination of the file. If None is given the file is saved to a temporary directory.\n    progress_bar : bool\n        Whether to show a command-line progress bar while downloading.\n\n    Returns\n    -------\n    filename : str\n        The location of the downloaded file.\n\n    Notes\n    -----\n    Progress bar use/example adapted from tqdm documentation: https://github.com/tqdm/tqdm\n    """"""\n\n    def my_hook(t):\n        last_b = [0]\n\n        def inner(b=1, bsize=1, tsize=None):\n            if tsize is not None:\n                t.total = tsize\n            if b > 0:\n                t.update((b - last_b[0]) * bsize)\n            last_b[0] = b\n\n        return inner\n\n    if progress_bar:\n        with tqdm(unit=\'B\', unit_scale=True, miniters=1, desc=url.split(\'/\')[-1]) as t:\n            filename, _ = urlretrieve(url, filename=destination, reporthook=my_hook(t))\n    else:\n        filename, _ = urlretrieve(url, filename=destination)\n\n\nclass AveragePrecisionMeter(object):\n    """"""\n    The APMeter measures the average precision per class.\n    The APMeter is designed to operate on `NxK` Tensors `output` and\n    `target`, and optionally a `Nx1` Tensor weight where (1) the `output`\n    contains model output scores for `N` examples and `K` classes that ought to\n    be higher when the model is more convinced that the example should be\n    positively labeled, and smaller when the model believes the example should\n    be negatively labeled (for instance, the output of a sigmoid function); (2)\n    the `target` contains only values 0 (for negative examples) and 1\n    (for positive examples); and (3) the `weight` ( > 0) represents weight for\n    each sample.\n    """"""\n\n    def __init__(self, difficult_examples=False):\n        super(AveragePrecisionMeter, self).__init__()\n        self.reset()\n        self.difficult_examples = difficult_examples\n\n    def reset(self):\n        """"""Resets the meter with empty member variables""""""\n        self.scores = torch.FloatTensor(torch.FloatStorage())\n        self.targets = torch.LongTensor(torch.LongStorage())\n\n    def add(self, output, target):\n        """"""\n        Args:\n            output (Tensor): NxK tensor that for each of the N examples\n                indicates the probability of the example belonging to each of\n                the K classes, according to the model. The probabilities should\n                sum to one over all classes\n            target (Tensor): binary NxK tensort that encodes which of the K\n                classes are associated with the N-th input\n                    (eg: a row [0, 1, 0, 1] indicates that the example is\n                         associated with classes 2 and 4)\n            weight (optional, Tensor): Nx1 tensor representing the weight for\n                each example (each weight > 0)\n        """"""\n        if not torch.is_tensor(output):\n            output = torch.from_numpy(output)\n        if not torch.is_tensor(target):\n            target = torch.from_numpy(target)\n\n        if output.dim() == 1:\n            output = output.view(-1, 1)\n        else:\n            assert output.dim() == 2, \\\n                \'wrong output size (should be 1D or 2D with one column \\\n                per class)\'\n        if target.dim() == 1:\n            target = target.view(-1, 1)\n        else:\n            assert target.dim() == 2, \\\n                \'wrong target size (should be 1D or 2D with one column \\\n                per class)\'\n        if self.scores.numel() > 0:\n            assert target.size(1) == self.targets.size(1), \\\n                \'dimensions for output should match previously added examples.\'\n\n        # make sure storage is of sufficient size\n        if self.scores.storage().size() < self.scores.numel() + output.numel():\n            new_size = math.ceil(self.scores.storage().size() * 1.5)\n            self.scores.storage().resize_(int(new_size + output.numel()))\n            self.targets.storage().resize_(int(new_size + output.numel()))\n\n        # store scores and targets\n        offset = self.scores.size(0) if self.scores.dim() > 0 else 0\n        self.scores.resize_(offset + output.size(0), output.size(1))\n        self.targets.resize_(offset + target.size(0), target.size(1))\n        self.scores.narrow(0, offset, output.size(0)).copy_(output)\n        self.targets.narrow(0, offset, target.size(0)).copy_(target)\n\n    def value(self):\n        """"""Returns the model\'s average precision for each class\n        Return:\n            ap (FloatTensor): 1xK tensor, with avg precision for each class k\n        """"""\n\n        if self.scores.numel() == 0:\n            return 0\n        ap = torch.zeros(self.scores.size(1))\n        rg = torch.arange(1, self.scores.size(0)).float()\n\n        # compute average precision for each class\n        for k in range(self.scores.size(1)):\n            # sort scores\n            scores = self.scores[:, k]\n            targets = self.targets[:, k]\n\n            # compute average precision\n            ap[k] = AveragePrecisionMeter.average_precision(scores, targets, self.difficult_examples)\n        return ap\n\n    @staticmethod\n    def average_precision(output, target, difficult_examples=True):\n\n        # sort examples\n        sorted, indices = torch.sort(output, dim=0, descending=True)\n\n        # Computes prec@i\n        pos_count = 0.\n        total_count = 0.\n        precision_at_i = 0.\n        for i in indices:\n            label = target[i]\n            if difficult_examples and label == 0:\n                continue\n            if label == 1:\n                pos_count += 1\n            total_count += 1\n            if label == 1:\n                precision_at_i += pos_count / total_count\n        precision_at_i /= pos_count\n        return precision_at_i\n'"
wildcat/voc.py,2,"b'import csv\nimport os\nimport os.path\nimport tarfile\nfrom urllib.parse import urlparse\n\nimport numpy as np\nimport torch\nimport torch.utils.data as data\nfrom PIL import Image\n\nfrom wildcat import util\n\nobject_categories = [\'aeroplane\', \'bicycle\', \'bird\', \'boat\',\n                     \'bottle\', \'bus\', \'car\', \'cat\', \'chair\',\n                     \'cow\', \'diningtable\', \'dog\', \'horse\',\n                     \'motorbike\', \'person\', \'pottedplant\',\n                     \'sheep\', \'sofa\', \'train\', \'tvmonitor\']\n\nurls = {\n    \'devkit\': \'http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCdevkit_18-May-2011.tar\',\n    \'trainval_2007\': \'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\',\n    \'test_images_2007\': \'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\',\n    \'test_anno_2007\': \'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtestnoimgs_06-Nov-2007.tar\',\n}\n\n\ndef read_image_label(file):\n    print(\'[dataset] read \' + file)\n    data = dict()\n    with open(file, \'r\') as f:\n        for line in f:\n            tmp = line.split(\' \')\n            name = tmp[0]\n            label = int(tmp[-1])\n            data[name] = label\n            # data.append([name, label])\n            # print(\'%s  %d\' % (name, label))\n    return data\n\n\ndef read_object_labels(root, dataset, set):\n    path_labels = os.path.join(root, \'VOCdevkit\', dataset, \'ImageSets\', \'Main\')\n    labeled_data = dict()\n    num_classes = len(object_categories)\n\n    for i in range(num_classes):\n        file = os.path.join(path_labels, object_categories[i] + \'_\' + set + \'.txt\')\n        data = read_image_label(file)\n\n        if i == 0:\n            for (name, label) in data.items():\n                labels = np.zeros(num_classes)\n                labels[i] = label\n                labeled_data[name] = labels\n        else:\n            for (name, label) in data.items():\n                labeled_data[name][i] = label\n\n    return labeled_data\n\n\ndef write_object_labels_csv(file, labeled_data):\n    # write a csv file\n    print(\'[dataset] write file %s\' % file)\n    with open(file, \'w\') as csvfile:\n        fieldnames = [\'name\']\n        fieldnames.extend(object_categories)\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        writer.writeheader()\n        for (name, labels) in labeled_data.items():\n            example = {\'name\': name}\n            for i in range(20):\n                example[fieldnames[i + 1]] = int(labels[i])\n            writer.writerow(example)\n\n    csvfile.close()\n\n\ndef read_object_labels_csv(file, header=True):\n    images = []\n    num_categories = 0\n    print(\'[dataset] read\', file)\n    with open(file, \'r\') as f:\n        reader = csv.reader(f)\n        rownum = 0\n        for row in reader:\n            if header and rownum == 0:\n                header = row\n            else:\n                if num_categories == 0:\n                    num_categories = len(row) - 1\n                name = row[0]\n                labels = (np.asarray(row[1:num_categories + 1])).astype(np.float32)\n                labels = torch.from_numpy(labels)\n                item = (name, labels)\n                images.append(item)\n            rownum += 1\n    return images\n\n\ndef find_images_classification(root, dataset, set):\n    path_labels = os.path.join(root, \'VOCdevkit\', dataset, \'ImageSets\', \'Main\')\n    images = []\n    file = os.path.join(path_labels, set + \'.txt\')\n    with open(file, \'r\') as f:\n        for line in f:\n            images.append(line)\n    return images\n\n\ndef download_voc2007(root):\n    path_devkit = os.path.join(root, \'VOCdevkit\')\n    path_images = os.path.join(root, \'VOCdevkit\', \'VOC2007\', \'JPEGImages\')\n    tmpdir = os.path.join(root, \'tmp\')\n\n    # create directory\n    if not os.path.exists(root):\n        os.makedirs(root)\n\n    if not os.path.exists(path_devkit):\n\n        if not os.path.exists(tmpdir):\n            os.makedirs(tmpdir)\n\n        parts = urlparse(urls[\'devkit\'])\n        filename = os.path.basename(parts.path)\n        cached_file = os.path.join(tmpdir, filename)\n\n        if not os.path.exists(cached_file):\n            print(\'Downloading: ""{}"" to {}\\n\'.format(urls[\'devkit\'], cached_file))\n            util.download_url(urls[\'devkit\'], cached_file)\n\n        # extract file\n        print(\'[dataset] Extracting tar file {file} to {path}\'.format(file=cached_file, path=root))\n        cwd = os.getcwd()\n        tar = tarfile.open(cached_file, ""r"")\n        os.chdir(root)\n        tar.extractall()\n        tar.close()\n        os.chdir(cwd)\n        print(\'[dataset] Done!\')\n\n    # train/val images/annotations\n    if not os.path.exists(path_images):\n\n        # download train/val images/annotations\n        parts = urlparse(urls[\'trainval_2007\'])\n        filename = os.path.basename(parts.path)\n        cached_file = os.path.join(tmpdir, filename)\n\n        if not os.path.exists(cached_file):\n            print(\'Downloading: ""{}"" to {}\\n\'.format(urls[\'trainval_2007\'], cached_file))\n            util.download_url(urls[\'trainval_2007\'], cached_file)\n\n        # extract file\n        print(\'[dataset] Extracting tar file {file} to {path}\'.format(file=cached_file, path=root))\n        cwd = os.getcwd()\n        tar = tarfile.open(cached_file, ""r"")\n        os.chdir(root)\n        tar.extractall()\n        tar.close()\n        os.chdir(cwd)\n        print(\'[dataset] Done!\')\n\n    # test annotations\n    test_anno = os.path.join(path_devkit, \'VOC2007/ImageSets/Main/aeroplane_test.txt\')\n    if not os.path.exists(test_anno):\n\n        # download test annotations\n        parts = urlparse(urls[\'test_images_2007\'])\n        filename = os.path.basename(parts.path)\n        cached_file = os.path.join(tmpdir, filename)\n\n        if not os.path.exists(cached_file):\n            print(\'Downloading: ""{}"" to {}\\n\'.format(urls[\'test_images_2007\'], cached_file))\n            util.download_url(urls[\'test_images_2007\'], cached_file)\n\n        # extract file\n        print(\'[dataset] Extracting tar file {file} to {path}\'.format(file=cached_file, path=root))\n        cwd = os.getcwd()\n        tar = tarfile.open(cached_file, ""r"")\n        os.chdir(root)\n        tar.extractall()\n        tar.close()\n        os.chdir(cwd)\n        print(\'[dataset] Done!\')\n\n    # test images\n    test_image = os.path.join(path_devkit, \'VOC2007/JPEGImages/000001.jpg\')\n    if not os.path.exists(test_image):\n\n        # download test images\n        parts = urlparse(urls[\'test_anno_2007\'])\n        filename = os.path.basename(parts.path)\n        cached_file = os.path.join(tmpdir, filename)\n\n        if not os.path.exists(cached_file):\n            print(\'Downloading: ""{}"" to {}\\n\'.format(urls[\'test_anno_2007\'], cached_file))\n            util.download_url(urls[\'test_anno_2007\'], cached_file)\n\n        # extract file\n        print(\'[dataset] Extracting tar file {file} to {path}\'.format(file=cached_file, path=root))\n        cwd = os.getcwd()\n        tar = tarfile.open(cached_file, ""r"")\n        os.chdir(root)\n        tar.extractall()\n        tar.close()\n        os.chdir(cwd)\n        print(\'[dataset] Done!\')\n\n\nclass Voc2007Classification(data.Dataset):\n    def __init__(self, root, set, transform=None, target_transform=None):\n        self.root = root\n        self.path_devkit = os.path.join(root, \'VOCdevkit\')\n        self.path_images = os.path.join(root, \'VOCdevkit\', \'VOC2007\', \'JPEGImages\')\n        self.set = set\n        self.transform = transform\n        self.target_transform = target_transform\n\n        # download dataset\n        download_voc2007(self.root)\n\n        # define path of csv file\n        path_csv = os.path.join(self.root, \'files\', \'VOC2007\')\n        # define filename of csv file\n        file_csv = os.path.join(path_csv, \'classification_\' + set + \'.csv\')\n\n        # create the csv file if necessary\n        if not os.path.exists(file_csv):\n            if not os.path.exists(path_csv):  # create dir if necessary\n                os.makedirs(path_csv)\n            # generate csv file\n            labeled_data = read_object_labels(self.root, \'VOC2007\', self.set)\n            # write csv file\n            write_object_labels_csv(file_csv, labeled_data)\n\n        self.classes = object_categories\n        self.images = read_object_labels_csv(file_csv)\n\n        print(\'[dataset] VOC 2007 classification set=%s number of classes=%d  number of images=%d\' % (\n            set, len(self.classes), len(self.images)))\n\n    def __getitem__(self, index):\n        path, target = self.images[index]\n        img = Image.open(os.path.join(self.path_images, path + \'.jpg\')).convert(\'RGB\')\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n        return (img, path), target\n\n    def __len__(self):\n        return len(self.images)\n\n    def get_number_classes(self):\n        return len(self.classes)\n'"
