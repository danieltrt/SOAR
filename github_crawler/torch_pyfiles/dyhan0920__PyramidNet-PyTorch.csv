file_path,api_count,code
PyramidNet.py,6,"b'import torch\nimport torch.nn as nn\nimport math\n#from math import round\nimport torch.utils.model_zoo as model_zoo\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    outchannel_ratio = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = conv3x3(inplanes, planes, stride)        \n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n\n        out = self.bn1(x)\n        out = self.conv1(out)        \n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn3(out)\n       \n        if self.downsample is not None:\n            shortcut = self.downsample(x)\n            featuremap_size = shortcut.size()[2:4]\n        else:\n            shortcut = x\n            featuremap_size = out.size()[2:4]\n\n        batch_size = out.size()[0]\n        residual_channel = out.size()[1]\n        shortcut_channel = shortcut.size()[1]\n\n        if residual_channel != shortcut_channel:\n            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \n            out += torch.cat((shortcut, padding), 1)\n        else:\n            out += shortcut \n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    outchannel_ratio = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, (planes*1), kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d((planes*1))\n        self.conv3 = nn.Conv2d((planes*1), planes * Bottleneck.outchannel_ratio, kernel_size=1, bias=False)\n        self.bn4 = nn.BatchNorm2d(planes * Bottleneck.outchannel_ratio)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n\n        out = self.bn1(x)\n        out = self.conv1(out)\n        \n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n \n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out = self.bn4(out)\n\n        if self.downsample is not None:\n            shortcut = self.downsample(x)\n            featuremap_size = shortcut.size()[2:4]\n        else:\n            shortcut = x\n            featuremap_size = out.size()[2:4]\n\n        batch_size = out.size()[0]\n        residual_channel = out.size()[1]\n        shortcut_channel = shortcut.size()[1]\n\n        if residual_channel != shortcut_channel:\n            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \n            out += torch.cat((shortcut, padding), 1)\n        else:\n            out += shortcut \n\n        return out\n\n\nclass PyramidNet(nn.Module):\n        \n    def __init__(self, dataset, depth, alpha, num_classes, bottleneck=False):\n        super(PyramidNet, self).__init__()   \t\n        self.dataset = dataset\n        if self.dataset.startswith(\'cifar\'):\n            self.inplanes = 16\n            if bottleneck == True:\n                n = int((depth - 2) / 9)\n                block = Bottleneck\n            else:\n                n = int((depth - 2) / 6)\n                block = BasicBlock\n\n            self.addrate = alpha / (3*n*1.0)\n\n            self.input_featuremap_dim = self.inplanes\n            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=3, stride=1, padding=1, bias=False)\n            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n\n            self.featuremap_dim = self.input_featuremap_dim \n            self.layer1 = self.pyramidal_make_layer(block, n)\n            self.layer2 = self.pyramidal_make_layer(block, n, stride=2)\n            self.layer3 = self.pyramidal_make_layer(block, n, stride=2)\n\n            self.final_featuremap_dim = self.input_featuremap_dim\n            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\n            self.relu_final = nn.ReLU(inplace=True)\n            self.avgpool = nn.AvgPool2d(8)\n            self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n\n        elif dataset == \'imagenet\':\n            blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n            layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\n\n            if layers.get(depth) is None:\n                if bottleneck == True:\n                    blocks[depth] = Bottleneck\n                    temp_cfg = int((depth-2)/12)\n                else:\n                    blocks[depth] = BasicBlock\n                    temp_cfg = int((depth-2)/8)\n\n                layers[depth]= [temp_cfg, temp_cfg, temp_cfg, temp_cfg]\n                print(\'=> the layer configuration for each stage is set to\', layers[depth])\n\n            self.inplanes = 64            \n            self.addrate = alpha / (sum(layers[depth])*1.0)\n\n            self.input_featuremap_dim = self.inplanes\n            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=7, stride=2, padding=3, bias=False)\n            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n            self.relu = nn.ReLU(inplace=True)\n            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n            self.featuremap_dim = self.input_featuremap_dim \n            self.layer1 = self.pyramidal_make_layer(blocks[depth], layers[depth][0])\n            self.layer2 = self.pyramidal_make_layer(blocks[depth], layers[depth][1], stride=2)\n            self.layer3 = self.pyramidal_make_layer(blocks[depth], layers[depth][2], stride=2)\n            self.layer4 = self.pyramidal_make_layer(blocks[depth], layers[depth][3], stride=2)\n\n            self.final_featuremap_dim = self.input_featuremap_dim\n            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\n            self.relu_final = nn.ReLU(inplace=True)\n            self.avgpool = nn.AvgPool2d(7) \n            self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def pyramidal_make_layer(self, block, block_depth, stride=1):\n        downsample = None\n        if stride != 1: # or self.inplanes != int(round(featuremap_dim_1st)) * block.outchannel_ratio:\n            downsample = nn.AvgPool2d((2,2), stride = (2, 2), ceil_mode=True)\n\n        layers = []\n        self.featuremap_dim = self.featuremap_dim + self.addrate\n        layers.append(block(self.input_featuremap_dim, int(round(self.featuremap_dim)), stride, downsample))\n        for i in range(1, block_depth):\n            temp_featuremap_dim = self.featuremap_dim + self.addrate\n            layers.append(block(int(round(self.featuremap_dim)) * block.outchannel_ratio, int(round(temp_featuremap_dim)), 1))\n            self.featuremap_dim  = temp_featuremap_dim\n        self.input_featuremap_dim = int(round(self.featuremap_dim)) * block.outchannel_ratio\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        if self.dataset == \'cifar10\' or self.dataset == \'cifar100\':\n            x = self.conv1(x)\n            x = self.bn1(x)\n            \n            x = self.layer1(x)\n            x = self.layer2(x)\n            x = self.layer3(x)\n\n            x = self.bn_final(x)\n            x = self.relu_final(x)\n            x = self.avgpool(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n\n        elif self.dataset == \'imagenet\':\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n            x = self.maxpool(x)\n\n            x = self.layer1(x)\n            x = self.layer2(x)\n            x = self.layer3(x)\n            x = self.layer4(x)\n\n            x = self.bn_final(x)\n            x = self.relu_final(x)\n            x = self.avgpool(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n    \n        return x\n'"
preresnet.py,2,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, preact=\'no_preact\'):\n        super(BasicBlock, self).__init__()\n\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.relu = nn.ReLU(inplace=True)\n        \n        self.downsample = downsample\n        self.stride = stride\n        self.preact = preact\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n\n        if self.downsample is not None:\n            if self.preact == \'preact\':\n                residual = self.downsample(out)\n            else:\n                residual = self.downsample(x)\n\n        out = self.conv1(out)   \n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)        \n\n        out += residual\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, preact=\'no_preact\'):\n        super(Bottleneck, self).__init__()\n\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * Bottleneck.expansion, kernel_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        \n        self.downsample = downsample\n        self.stride = stride\n        self.preact = preact\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n\n        if self.downsample is not None:\n            if self.preact == \'preact\':\n                residual = self.downsample(out)\n            else:\n                residual = self.downsample(x)\n\n        out = self.conv1(out) \n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out += residual\n\n        return out\n\nclass PreResNet(nn.Module):\n\n    def __init__(self, dataset, depth, num_classes, bottleneck=False):\n        super(PreResNet, self).__init__()        \n        self.dataset = dataset\n        if self.dataset.startswith(\'cifar\'):\n            self.inplanes = 16\n            if bottleneck == True:\n                n = int((depth - 2) / 9)\n                block = Bottleneck\n            else:\n                n = int((depth - 2) / 6)\n                block = BasicBlock\n\n            self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n            self.layer1 = self._make_layer(block, 16, n)\n            self.layer2 = self._make_layer(block, 32, n, stride=2)\n            self.layer3 = self._make_layer(block, 64, n, stride=2) \n            self.bn1 = nn.BatchNorm2d(64 * block.expansion)\n            self.relu = nn.ReLU(inplace=True)\n            self.avgpool = nn.AvgPool2d(8)\n            self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        elif dataset == \'imagenet\':\n            blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n            layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\n            assert layers[depth], \'invalid detph for Pre-ResNet (depth should be one of 18, 34, 50, 101, 152, and 200)\'\n\n            self.inplanes = 64\n            self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n            self.bn1 = nn.BatchNorm2d(64)\n            self.relu = nn.ReLU(inplace=True)\n            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            self.layer1 = self._make_layer(blocks[depth], 64, layers[depth][0], preact=\'no_preact\')\n            self.layer2 = self._make_layer(blocks[depth], 128, layers[depth][1], stride=2)\n            self.layer3 = self._make_layer(blocks[depth], 256, layers[depth][2], stride=2)\n            self.layer4 = self._make_layer(blocks[depth], 512, layers[depth][3], stride=2)\n            self.bn2 = nn.BatchNorm2d(512 * blocks[depth].expansion)\n            self.avgpool = nn.AvgPool2d(7, stride=1) \n            self.fc = nn.Linear(512 * blocks[depth].expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1, preact=\'preact\'):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, preact))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        if self.dataset == \'cifar10\' or self.dataset == \'cifar100\':\n            x = self.conv1(x)\n            \n            x = self.layer1(x)\n            x = self.layer2(x)\n            x = self.layer3(x)\n            \n            x = self.bn1(x)\n            x = self.relu(x)\n            x = self.avgpool(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n\n        elif self.dataset == \'imagenet\':\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n            x = self.maxpool(x)\n\n            x = self.layer1(x)\n            x = self.layer2(x)\n            x = self.layer3(x)\n            x = self.layer4(x)\n\n            x = self.bn2(x)\n            x = self.relu(x)\n            x = self.avgpool(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n    \n        return x\n'"
resnet.py,2,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * Bottleneck.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * Bottleneck.expansion)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, dataset, depth, num_classes, bottleneck=False):\n        super(ResNet, self).__init__()        \n        self.dataset = dataset\n        if self.dataset.startswith(\'cifar\'):\n            self.inplanes = 16\n            print(bottleneck)\n            if bottleneck == True:\n                n = int((depth - 2) / 9)\n                block = Bottleneck\n            else:\n                n = int((depth - 2) / 6)\n                block = BasicBlock\n\n            self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n            self.bn1 = nn.BatchNorm2d(self.inplanes)\n            self.relu = nn.ReLU(inplace=True)\n            self.layer1 = self._make_layer(block, 16, n)\n            self.layer2 = self._make_layer(block, 32, n, stride=2)\n            self.layer3 = self._make_layer(block, 64, n, stride=2) \n            self.avgpool = nn.AvgPool2d(8)\n            self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        elif dataset == \'imagenet\':\n            blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n            layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\n            assert layers[depth], \'invalid detph for ResNet (depth should be one of 18, 34, 50, 101, 152, and 200)\'\n\n            self.inplanes = 64\n            self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n            self.bn1 = nn.BatchNorm2d(64)\n            self.relu = nn.ReLU(inplace=True)\n            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            self.layer1 = self._make_layer(blocks[depth], 64, layers[depth][0])\n            self.layer2 = self._make_layer(blocks[depth], 128, layers[depth][1], stride=2)\n            self.layer3 = self._make_layer(blocks[depth], 256, layers[depth][2], stride=2)\n            self.layer4 = self._make_layer(blocks[depth], 512, layers[depth][3], stride=2)\n            self.avgpool = nn.AvgPool2d(7) \n            self.fc = nn.Linear(512 * blocks[depth].expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        if self.dataset == \'cifar10\' or self.dataset == \'cifar100\':\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n            \n            x = self.layer1(x)\n            x = self.layer2(x)\n            x = self.layer3(x)\n\n            x = self.avgpool(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n\n        elif self.dataset == \'imagenet\':\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n            x = self.maxpool(x)\n\n            x = self.layer1(x)\n            x = self.layer2(x)\n            x = self.layer3(x)\n            x = self.layer4(x)\n\n            x = self.avgpool(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n    \n        return x\n'"
train.py,28,"b'import argparse\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nimport resnet as RN\nimport preresnet as PRN\nimport PyramidNet as PYRM\n\nfrom tensorboard_logger import configure, log_value\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR-10, CIFAR-100 and ImageNet-1k Training\')\nparser.add_argument(\'--data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--net_type\', default=\'PyramidNet\', type=str,\n                    help=\'networktype: resnet, resnext, densenet, pyamidnet, and so on\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch_size\', default=128, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=1, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model on ImageNet-1k dataset\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--depth\', default=32, type=int,\n                    help=\'depth of the network (default: 32)\')\nparser.add_argument(\'--no-bottleneck\', dest=\'bottleneck\', action=\'store_false\',\n                    help=\'to use basicblock for CIFAR datasets (default: bottleneck)\')\nparser.add_argument(\'--dataset\', dest=\'dataset\', default=\'imagenet\', type=str,\n                    help=\'dataset (options: cifar10, cifar100, and imagenet)\')\nparser.add_argument(\'--no-verbose\', dest=\'verbose\', action=\'store_false\',\n                    help=\'to print the status at every iteration\')\nparser.add_argument(\'--alpha\', default=300, type=int,\n                    help=\'number of new channel increases per depth (default: 300)\')\nparser.add_argument(\'--no-augment\', dest=\'augment\', action=\'store_false\',\n                    help=\'whether to use standard augmentation for CIFAR datasets (default: True)\')\nparser.add_argument(\'--tensorboard\',\n                    help=\'Log progress to TensorBoard\', action=\'store_true\')\nparser.add_argument(\'--expname\', default=\'PyramidNet\', type=str,\n                    help=\'name of experiment\')\n\nparser.set_defaults(bottleneck=True)\nparser.set_defaults(verbose=True)\nparser.set_defaults(augment=True)\n\nbest_err1 = 100\nbest_err5 = 100\n\ndef main():\n    global args, best_err1, best_err5\n    args = parser.parse_args()\n    if args.tensorboard: configure(""runs/%s""%(args.expname))\n\n    args.distributed = args.world_size > 1\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n    \n    if args.dataset.startswith(\'cifar\'):\n        normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n                                         std=[x/255.0 for x in [63.0, 62.1, 66.7]])    \n        if args.augment:\n            transform_train = transforms.Compose([\n                transforms.RandomCrop(32, padding=4),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n                ])\n        else:\n            transform_train = transforms.Compose([\n                transforms.ToTensor(),\n                normalize,\n                ])\n        transform_test = transforms.Compose([\n            transforms.ToTensor(),\n            normalize\n            ])\n\n        if args.dataset == \'cifar100\':\n            train_loader = torch.utils.data.DataLoader(\n                datasets.CIFAR100(\'../data\', train=True, download=True, transform=transform_train),\n                batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True)\n            val_loader = torch.utils.data.DataLoader(\n                datasets.CIFAR100(\'../data\', train=False, transform=transform_test),\n                batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True) \n            numberofclass = 100         \n        elif args.dataset == \'cifar10\':\n            train_loader = torch.utils.data.DataLoader(\n                datasets.CIFAR10(\'../data\', train=True, download=True, transform=transform_train),\n                batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True)\n            val_loader = torch.utils.data.DataLoader(\n                datasets.CIFAR10(\'../data\', train=False, transform=transform_test),\n                batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True)\n            numberofclass = 10\n        else: \n            raise Exception (\'unknown dataset: {}\'.format(args.dataset)) \n\n    elif args.dataset == \'imagenet\':\n        traindir = os.path.join(args.data, \'train\')\n        valdir = os.path.join(args.data, \'val\')\n        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                         std=[0.229, 0.224, 0.225])\n\n        train_dataset = datasets.ImageFolder(\n            traindir,\n            transforms.Compose([\n                transforms.RandomResizedCrop(224),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ]))\n\n        if args.distributed:\n            train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n        else:\n            train_sampler = None\n\n        train_loader = torch.utils.data.DataLoader(\n            train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n            num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n        val_loader = torch.utils.data.DataLoader(\n            datasets.ImageFolder(valdir, transforms.Compose([\n                transforms.Resize(256),\n                transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                normalize,\n            ])),\n            batch_size=args.batch_size, shuffle=False,\n            num_workers=args.workers, pin_memory=True)\n        numberofclass = 1000\n\n    else: \n        raise Exception (\'unknown dataset: {}\'.format(args.dataset)) \n\n    if args.pretrained:\n        print(""=> using pre-trained model \'{}\'"".format(args.net_type))\n        try:\n            model = models.__dict__[str(args.net_type)](pretrained=True)\n        except (KeyError, TypeError):\n            print(\'unknown model\')\n            print(\'torchvision provides the follwoing pretrained model:\', model_names)\n            return\n    else:\n        print(""=> creating model \'{}\'"".format(args.net_type))\n        if args.net_type == \'resnet\':\n            model = RN.ResNet(args.dataset, args.depth, numberofclass, args.bottleneck) # for ResNet  \n        elif args.net_type == \'preresnet\':\n            model = PRN.PreResNet(args.dataset, args.depth, numberofclass, args.bottleneck) # for Pre-activation ResNet  \n        elif args.net_type == \'pyramidnet\':\n            model = PYRM.PyramidNet(args.dataset, args.depth, args.alpha, numberofclass, args.bottleneck) # for ResNet  \n        else:\n            raise Exception (\'unknown network architecture: {}\'.format(args.net_type)) \n\n    if not args.distributed:\n        if args.net_type.startswith(\'alexnet\') or args.net_type.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n    print(model)\n    print(\'the number of model parameters: {}\'.format(sum([p.data.nelement() for p in model.parameters()])))\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay, nesterov=True)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_err1 = checkpoint[\'best_err1\']\n            best_err5 = checkpoint[\'best_err5\']            \n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs+1):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        err1, err5 = validate(val_loader, model, criterion, epoch)\n\n        # remember best prec@1 and save checkpoint\n        is_best = err1 <= best_err1\n        best_err1 = min(err1, best_err1)\n        if is_best:\n            best_err5 = err5\n        print (\'Current best accuracy (top-1 and 5 error):\', best_err1, best_err5)\n        save_checkpoint({\n            \'epoch\': epoch,\n            \'arch\': args.net_type,\n            \'state_dict\': model.state_dict(),\n            \'best_err1\': best_err1,\n            \'best_err5\': best_err5,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best)\n    print (\'Best accuracy (top-1 and 5 error):\', best_err1, best_err5)  \n \n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    current_LR = get_learning_rate(optimizer)[0]\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        err1, err5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(err1[0], input.size(0))\n        top5.update(err5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0 and args.verbose == True:\n            print(\'Epoch: [{0}/{1}][{2}/{3}]\\t\'\n                  \'LR: {LR:.6f}\\t\' \n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Top 1-err {top1.val:.4f} ({top1.avg:.4f})\\t\'\n                  \'Top 5-err {top5.val:.4f} ({top5.avg:.4f})\'.format(\n                   epoch, args.epochs, i, len(train_loader), LR=current_LR, batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n    # log to TensorBoard\n    if args.tensorboard:\n        log_value(\'train_loss\', losses.avg, epoch)\n        log_value(\'train_error\', top1.avg, epoch)\n\ndef validate(val_loader, model, criterion, epoch):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n\n        # for PyTorch 0.3.x, use volatile=True for preventing memory leakage in evaluation phase:`\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # for PyTorch 0.4.x, volatile=True is replaced by with torch.no.grad(), so uncomment the followings:\n        # with torch.no_grad():\n        #     input_var = torch.autograd.Variable(input)\n        #     target_var = torch.autograd.Variable(target)\n        #     output = model(input_var)\n        #     loss = criterion(output, target_var)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        err1, err5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(err1[0], input.size(0))\n        top5.update(err5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0 and args.verbose == True:\n            print(\'Test (on val set): [{0}/{1}][{2}/{3}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Top 1-err {top1.val:.4f} ({top1.avg:.4f})\\t\'\n                  \'Top 5-err {top5.val:.4f} ({top5.avg:.4f})\'.format(\n                   epoch, args.epochs, i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5))\n\n    print(\'* Epoch: [{0}/{1}]\\t Top 1-err {top1.avg:.3f}  Top 5-err {top5.avg:.3f}\\t Test Loss {loss.avg:.3f}\'.format(epoch, args.epochs, top1=top1, top5=top5, loss=losses))\n    # log to TensorBoard\n    if args.tensorboard:\n        log_value(\'val_loss\', losses.avg, epoch)\n        log_value(\'val_acc\', top1.avg, epoch)\n    return top1.avg, top5.avg\n\ndef save_checkpoint(state, is_best, filename=\'checkpoint.pth.tar\'):\n    directory = ""runs/%s/""%(args.expname)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    filename = directory + filename\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, \'runs/%s/\'%(args.expname) + \'model_best.pth.tar\')\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    if args.dataset.startswith(\'cifar\'):\n        lr = args.lr * (0.1 ** (epoch // (args.epochs*0.5))) * (0.1 ** (epoch // (args.epochs*0.75)))\n    elif args.dataset == (\'imagenet\'):\n        lr = args.lr * (0.1 ** (epoch // 30))\n    \n    if args.tensorboard:\n        log_value(\'learning_rate\', lr, epoch)\n\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef get_learning_rate(optimizer):\n    lr=[]\n    for param_group in optimizer.param_groups:\n       lr +=[ param_group[\'lr\'] ]\n    return lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        wrong_k = batch_size - correct_k\n        res.append(wrong_k.mul_(100.0 / batch_size))\n\n    return res\n\n\nif __name__ == \'__main__\':\n    main()\n'"
