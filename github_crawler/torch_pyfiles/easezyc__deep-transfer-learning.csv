file_path,api_count,code
Application/cross-domain fraud detection/main.py,19,"b'import torch\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nimport os\nfrom sklearn.metrics import roc_auc_score\n\nfrom models.nfm import NeuralFactorizationMachineModel\nfrom models.hen import HENModel\nfrom models.m3r import SeqM3RModel\nfrom models.wd import WideAndDeepModel\nfrom models.lstm4fd import LSTM4FDModel\nfrom data.dataset import Mydataset\nimport time\nfrom utils.utils import mmd_rbf_noaccelerate, cmmd, coral, euclidian, c_euclidian, nometric, ced\nfrom utils.utils import Stoper, Averager\n\nimport math\n\nmax_auc = -1\nmax_auchead = -1\nmin_loss = 100000\n\n\ndef get_model(name, field_dims):\n    """"""\n    name: the name of the target model\n    field_dims: the dimensions of fields\n    """"""\n    if name == \'nfm\':\n        return NeuralFactorizationMachineModel(field_dims, embed_dim=16, mlp_dims=(64,), dropouts=(0.2, 0.2))\n    elif name == \'hen\':\n        return HENModel(field_dims, embed_dim=16, sequence_length=11, lstm_dims=20,\n                        mlp_dims=(64,),\n                        dropouts=(0.2, 0.2))\n    elif name == \'wd\':\n        return WideAndDeepModel(field_dims, embed_dim=16, mlp_dims=(64,), dropout=0.2)\n    elif name == \'lstm4fd\':\n        return LSTM4FDModel(field_dims, embed_dim=16, sequence_length=11, lstm_dims=20, mlp_dims=(64,),\n                            dropouts=(0.2, 0.2))\n    elif name == \'m3r\':\n        return SeqM3RModel(field_dims, embed_dim=16, sequence_length=11, lstm_dims=20, mlp_dims=(64,),\n                           dropouts=(0.2, 0.2))\n    else:\n        raise ValueError(\'unknown model name: \' + name)\n\n\ndef train(model, optimizer, src_loader, tgt_loader, valid_loader, criterion, log_interval=1000, val_interval=50, posp=1,\n          nagp=0.5, params_cls=0.5, params_da=0.5, da_type=\'cmmd\', max_fpr=0.01):\n    global max_auc\n    global max_auchead\n    global min_loss\n    posp = torch.FloatTensor([posp]).cuda()\n    nagp = torch.FloatTensor([nagp]).cuda()\n    one = torch.FloatTensor([1]).cuda()\n\n    iter_src = iter(src_loader)\n    iter_tgt = iter(tgt_loader)\n    num_iter = len(src_loader)\n    stoper = Stoper()\n\n    avg_all_loss = Averager()\n    avg_src_loss = Averager()\n    avg_tgt_loss = Averager()\n    avg_da_loss = Averager()\n    start_time = time.time()\n    for i in range(1, num_iter * 20):\n        model.train()\n        src_ids, src_values, src_seqlength, src_label, src_seq_mask = iter_src.next()\n        src_ids, src_values, src_label = src_ids.cuda(), src_values.cuda(), src_label.cuda().float()\n        src_seq_mask = src_seq_mask.cuda()\n        if i % len(src_loader) == 0:\n            iter_src = iter(src_loader)\n        if i % len(tgt_loader) == 0:\n            iter_tgt = iter(tgt_loader)\n\n        src_p = posp * src_label + nagp * (one - src_label)\n        src_y, src_fea_LSTM = model(src_ids, src_values, src_seqlength, src_seq_mask, \'src\')\n        src_loss = torch.mean(\n            src_p * criterion(src_y, src_label))  # + torch.mean(src_p * criterion(src_spey, src_label))\n\n        tgt_ids, tgt_values, tgt_seqlength, tgt_label, tgt_seq_mask = iter_tgt.next()\n        tgt_ids, tgt_values, tgt_label = tgt_ids.cuda(), tgt_values.cuda(), tgt_label.cuda().float()\n        tgt_seq_mask = tgt_seq_mask.cuda()\n        # print(tgt_seqlength, tgt_label)\n\n        tgt_p = posp * tgt_label + nagp * (one - tgt_label)\n        tgt_y, tgt_fea_LSTM, tgt_spey = model(tgt_ids, tgt_values, tgt_seqlength, tgt_seq_mask, \'tgt\')\n        tgt_loss = torch.mean(\n            tgt_p * criterion(tgt_y, tgt_label))  # + 0.5 * torch.mean(tgt_p * criterion(tgt_spey, tgt_label))\n        if da_type == \'cmmd\':\n            da_loss = cmmd(src_fea_LSTM, tgt_fea_LSTM, src_label.long(), tgt_label.long())\n        elif da_type == \'mmd\':\n            da_loss = mmd_rbf_noaccelerate(src_fea_LSTM, tgt_fea_LSTM)\n        elif da_type == \'coral\':\n            da_loss = coral(src_fea_LSTM, tgt_fea_LSTM)\n        elif da_type == \'euclidian\':\n            da_loss = euclidian(src_fea_LSTM, tgt_fea_LSTM)\n        elif da_type == \'c_euclidian\':\n            da_loss = c_euclidian(src_fea_LSTM, tgt_fea_LSTM, src_label.long(), tgt_label.long())\n        elif da_type == \'nometric\':\n            da_loss = nometric(src_fea_LSTM, tgt_fea_LSTM)\n        elif da_type == \'ced\':\n            da_loss = ced(src_fea_LSTM, tgt_fea_LSTM, src_label.long(), tgt_label.long())\n        lambd = 2 / (1 + math.exp((- 5 * i) / (len(src_loader)))) - 1\n        loss = params_cls * src_loss + tgt_loss + params_da * lambd * da_loss\n        model.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n        optimizer.step()\n        avg_all_loss.add(loss.item())\n        avg_src_loss.add(src_loss.item())\n        avg_tgt_loss.add(tgt_loss.item())\n        avg_da_loss.add(da_loss.item())\n        if (i + 1) % log_interval == 0:\n            print(\n                \'step: {}, loss: {:.4f}, src_loss: {:.4f}, tgt_loss: {:.4f}, {}_loss:, {:.4f}, lambda: {}\'.format(i + 1,\n                                                                                                                  avg_all_loss.item(),\n                                                                                                                  avg_src_loss.item(),\n                                                                                                                  avg_tgt_loss.item(),\n                                                                                                                  da_type,\n                                                                                                                  avg_da_loss.item(),\n                                                                                                                  lambd))\n            avg_all_loss = Averager()\n            avg_src_loss = Averager()\n            avg_tgt_loss = Averager()\n            avg_da_loss = Averager()\n\n        if (i + 1) % val_interval == 0:\n            end_time = time.time()\n            print(\'train time (s):\', end_time - start_time)\n            start_time = time.time()\n            auc_head, loss, auc = test(model, valid_loader, criterion, posp, max_fpr)\n            if loss < min_loss:\n                min_loss = loss\n            if auc > max_auc:\n                max_auc = auc\n            if auc_head > max_auchead:\n                torch.save(model, f\'{save_dir}/tmp.pt\')\n                max_auchead = auc_head\n            print(\n                \'dev ---  auchead: {:.4f}, max_auchead: {:.4f}, auc: {:.4f}, max_auc: {:.4f}, loss: {:.4f}, minloss: {:.4f}\'.format(\n                    auc_head, max_auchead, auc, max_auc, loss, min_loss))\n            end_time = time.time()\n            print(\'dev time (s):\', end_time - start_time)\n            start_time = time.time()\n            if stoper.add(auc_head):\n                print(\'training end\')\n                break\n\n\ndef test(model, data_loader, criterion, posp, max_fpr):\n    model.eval()\n    targets, predicts = list(), list()\n    loss = Averager()\n    posp = torch.FloatTensor([posp]).cuda()\n    one = torch.FloatTensor([1]).cuda()\n    with torch.no_grad():\n        for j, (ids, values, seqlength, label, seq_mask) in enumerate(data_loader):\n            ids, values = ids.cuda(), values.cuda()\n            label = label.cuda().float()\n            seq_mask = seq_mask.cuda()\n            y, _ = model(ids, values, seqlength, seq_mask, \'tgt\')\n            p = posp * label + (one - posp) * (one - label)\n            loss.add(torch.mean(p * criterion(y, label)).item())\n            targets.extend(label.tolist())\n            predicts.extend(y.tolist())\n    model.train()\n    return roc_auc_score(targets, predicts, max_fpr=max_fpr), loss.item(), roc_auc_score(targets, predicts)\n\n\ndef main(batch_size,\n         log_step,\n         val_step,\n         posp,\n         nagp,\n         sample_radio,\n         params_cls,\n         params_da,\n         src_name,\n         tgt_name,\n         da_type,\n         model,\n         optimizer,\n         max_fpr,\n         data_radio):\n    # feature = [\'item_id\', \'user_id\']\n    global max_auc\n    global max_auchead\n    global min_loss\n\n    src_train_path = \'d:/Jupyter/zhuyc/data/fourcountry/%s%s/train.txt\' % (src_name, data_radio)\n    tgt_train_path = \'d:/Jupyter/zhuyc/data/fourcountry/%s%s/train.txt\' % (tgt_name, data_radio)\n    dev_path = \'d:/Jupyter/zhuyc/data/fourcountry/%s%s/test.txt\' % (tgt_name, data_radio)\n    test_path = \'d:/Jupyter/zhuyc/data/fourcountry/%s%s/test.txt\' % (tgt_name, data_radio)\n\n    src_train_dataset = Mydataset(src_train_path, sample_radio)\n    tgt_train_dataset = Mydataset(tgt_train_path, sample_radio)\n    dev_dataset = Mydataset(dev_path, 1)\n    test_dataset = Mydataset(test_path, 1)\n    src_sampler = WeightedRandomSampler(src_train_dataset.get_weight(), len(src_train_dataset), True)\n    tgt_sampler = WeightedRandomSampler(tgt_train_dataset.get_weight(), len(tgt_train_dataset), True)\n    print(\'src_name:\', src_name, \'tgt_name:\', tgt_name, \'src training set:\', len(src_train_dataset),\n          \'tgt training set:\', len(tgt_train_dataset), \'dev set:\', len(dev_dataset), \'test set:\', len(test_dataset))\n\n    src_train_loader = DataLoader(src_train_dataset, batch_size=batch_size, num_workers=1, sampler=src_sampler,\n                                  drop_last=True)\n    tgt_train_loader = DataLoader(tgt_train_dataset, batch_size=batch_size, num_workers=1, sampler=tgt_sampler,\n                                  drop_last=True)\n\n    valid_loader = DataLoader(dev_dataset, batch_size=batch_size, num_workers=2)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)\n    if data_radio != \'0.05\' and data_radio != \'0.1\':\n        val_step = int(len(tgt_train_dataset) / 1024)\n    criterion = torch.nn.BCELoss(reduction=\'none\')\n    train(model, optimizer, src_train_loader, tgt_train_loader, valid_loader, criterion, log_step, val_step, posp, nagp,\n          params_cls, params_da, da_type, max_fpr)\n\n    model = torch.load(f\'{save_dir}/tmp.pt\').cuda()\n    start_time = time.time()\n    auc_head, loss, auc = test(model, test_loader, criterion, posp, max_fpr)\n    end_time = time.time()\n    print(\'test time (s):\', end_time - start_time)\n    print(\'dev auchead:\', max_auchead, \'dev auc:\', max_auc, \'dev loss:\', min_loss)\n    print(\'test auchead:\', auc_head, \'test auc:\', auc, \'test loss:\', loss)\n\n\nif __name__ == \'__main__\':\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--model_name\', default=\'hen\')\n    parser.add_argument(\'--epoch\', type=int, default=20)\n    parser.add_argument(\'--learning_rate\', type=float, default=0.005)\n    parser.add_argument(\'--posp\', type=float, default=1)\n    parser.add_argument(\'--nagp\', type=float, default=0.5)\n    parser.add_argument(\'--params_cls\', type=float, default=1)\n    parser.add_argument(\'--params_da\', type=float, default=1)\n    parser.add_argument(\'--sample_radio\', type=float, default=5)\n    parser.add_argument(\'--batch_size\', type=int, default=1024)\n    parser.add_argument(\'--log_step\', type=int, default=10)\n    parser.add_argument(\'--data_radio\', default=\'0.05\')\n    parser.add_argument(\'--val_step\', type=int, default=30)\n    parser.add_argument(\'--weight_decay\', type=float, default=1e-8)\n    parser.add_argument(\'--embed_dim\', type=int, default=16)\n    parser.add_argument(\'--sequence_length\', type=int, default=11)\n    parser.add_argument(\'--lstm_dims\', type=int, default=20)\n    parser.add_argument(\'--seed\', type=int, default=1)\n    parser.add_argument(\'--mlp_dims\', default=(64,))\n    parser.add_argument(\'--src_name\', default=\'TH\')\n    parser.add_argument(\'--tgt_name\', default=\'VN\')\n    parser.add_argument(\'--da_type\', default=\'nometric\')\n    parser.add_argument(\'--max_fpr\', type=float, default=0.01)\n    parser.add_argument(\'--gpu\', type=str, default=\'3\')\n    # \xe5\x88\xa4\xe6\x96\xad\xe7\xbb\x93\xe6\x9e\x9c\n    args = parser.parse_args()\n    os.environ[""CUDA_VISIBLE_DEVICES""] = args.gpu\n    save_dir = \'seqnfmchkpt_gpu%s_%s\' % (args.gpu, args.da_type)\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n    print(\n        \'positive probability: {}, nagative probability: {}, sample radio: {}, batch size: {}, params_cls: {}, params_da: {}, da_type: {}, weight_decay: {}, src_name: {}, tgt_name: {}, gpu: {}\'.format(\n            args.posp, args.nagp, args.sample_radio, args.batch_size, args.params_cls, args.params_da, args.da_type,\n            args.weight_decay, args.src_name, args.tgt_name, args.gpu))\n\n    field_dims = [int(1e5)]\n    model = get_model(args.model_name,\n                      field_dims).cuda()\n    print(model)\n    optimizer = torch.optim.Adam(params=model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n    # torch.manual_seed(args.seed)#\xe4\xb8\xbaCPU\xe8\xae\xbe\xe7\xbd\xae\xe9\x9a\x8f\xe6\x9c\xba\xe7\xa7\x8d\xe5\xad\x90\n    # torch.cuda.manual_seed(args.seed)#\xe4\xb8\xba\xe5\xbd\x93\xe5\x89\x8dGPU\xe8\xae\xbe\xe7\xbd\xae\xe9\x9a\x8f\xe6\x9c\xba\xe7\xa7\x8d\xe5\xad\x90\n    main(args.batch_size,\n         args.log_step,\n         args.val_step,\n         args.posp,\n         args.nagp,\n         args.sample_radio,\n         args.params_cls,\n         args.params_da,\n         args.src_name,\n         args.tgt_name,\n         args.da_type,\n         model,\n         optimizer,\n         args.max_fpr,\n         args.data_radio)\n'"
Application/cross-domain fraud detection/data/dataset.py,2,"b'import numpy as np\nimport torch.utils.data\n\n\nclass Mydataset(torch.utils.data.Dataset):\n\n    def __init__(self, path, ratio):\n        """"""\n            :param\n            path: the path of dataset\n            ratio: the ritio of oversample\n        """"""\n        self.path = path\n        file = open(self.path, \'r\')\n        self.lines = file.readlines()\n        file.close()\n        self.categorical_columns = 50\n        self.numerical_columns = 6\n        self.maxnum_events = 11  # 10 historical event 1 target payment event\n        self.nb_features_per_event = self.categorical_columns + self.numerical_columns\n\n        length = len(self.lines)\n        self.weight = []\n        black_num = 0\n        for i in range(length):\n            tmp = self.lines[i].split(\' \')\n            if int(tmp[2]) == 1:\n                self.weight.append(ratio)\n                black_num += 1\n            else:\n                self.weight.append(1)\n        print(path, \'black num:\', black_num, \'white num:\', length - black_num)\n\n    def __len__(self):\n        return len(self.lines)\n\n    def get_weight(self):\n        return self.weight\n\n    def __getitem__(self, index):\n        """"""\n            :param: index\n            return  (ids, values, seq_length, label, seq_mask)\n            ids: the ids of fileds\n            values: values of fields\n            seq_length: the length of historical events\n            label: the label of the target payment\n            seq_mask: the attention mask\n        """"""\n        line = self.lines[index]\n        line = line.strip()\n        line = line.split(\' \')\n        event_id = line.pop(0)\n        num_events = int(line.pop(0))\n        label = np.array(int(line.pop(0)))\n        valid_features = self.nb_features_per_event * self.maxnum_events\n\n        line = line[-valid_features:]\n        ids, values = zip(*[x.split(\':\') for x in line])\n        ids = list(ids)\n        values = list(values)\n        # the id, values of the target payment\n        driver_ids = np.array(ids[-self.nb_features_per_event:]).reshape((1, -1))\n        driver_values = np.array(values[-self.nb_features_per_event:]).reshape((1, -1))\n        # the id, values of the historical events\n        detail_ids = np.array(ids[:-self.nb_features_per_event]).reshape((-1, self.nb_features_per_event))\n        detail_values = np.array(values[:-self.nb_features_per_event]).reshape((-1, self.nb_features_per_event))\n\n        seq_length = self.maxnum_events - 1\n\n        if num_events < self.maxnum_events - 1:\n            seq_length = num_events\n            detail_ids = np.concatenate(\n                (detail_ids, np.zeros((self.maxnum_events - 1 - seq_length, self.nb_features_per_event))), axis=0)\n            detail_values = np.concatenate(\n                (detail_values, np.zeros((self.maxnum_events - 1 - seq_length, self.nb_features_per_event))), axis=0)\n\n        if seq_length <= 0:\n            seq_length = 1\n        seq_length = np.array(seq_length)\n        seq_mask = np.zeros(10, dtype=\'float32\')\n        seq_mask[seq_length:] = 1\n        ids = np.concatenate((detail_ids, driver_ids), axis=0).astype(float).astype(\'int64\')\n        values = np.concatenate((detail_values, driver_values), axis=0).astype(\'float32\')\n        return ids, values, seq_length, label, seq_mask\n'"
Application/cross-domain fraud detection/models/hen.py,60,"b'import torch\nimport numpy as np\n\nfrom .layer import FeaturesLinear, MultiLayerPerceptron, FeaturesEmbedding\n\nclass FactorizationMachine(torch.nn.Module):\n\n    def __init__(self, reduce_sum=True):\n        super().__init__()\n        self.reduce_sum = reduce_sum\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, sequence_lenth, num_fields, embed_dim)``\n        """"""\n        square_of_sum = torch.sum(x, dim=2) ** 2\n        sum_of_square = torch.sum(x ** 2, dim=2)\n        ix = square_of_sum - sum_of_square\n        if self.reduce_sum:\n            ix = torch.sum(ix, dim=2, keepdim=True)\n        return 0.5 * ix\n\n\nclass HENModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Hierarchical Exlainable Network.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, sequence_length, lstm_dims, mlp_dims, dropouts):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.src_embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.tgt_embedding = FeaturesEmbedding(field_dims, embed_dim)\n\n        self.linear = FeaturesLinear(field_dims)\n        self.mlp = MultiLayerPerceptron(embed_dim + embed_dim, mlp_dims, dropouts[1])\n\n        self.attention = torch.nn.Embedding(sum(field_dims), 1)\n        self.src_attention = torch.nn.Embedding(sum(field_dims), 1)\n        self.tgt_attention = torch.nn.Embedding(sum(field_dims), 1)\n        # torch.nn.init.constant_(self.attention.weight, 0)\n        # torch.nn.init.constant_(self.src_attention.weight, 0)\n        # torch.nn.init.constant_(self.tgt_attention.weight, 0)\n\n        self.attr_softmax = torch.nn.Softmax(dim=2)\n\n        self.fm = FactorizationMachine(reduce_sum=False)\n        self.src_bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(sequence_length),\n            torch.nn.Dropout(dropouts[0])\n        )\n        self.tgt_bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(sequence_length),\n            torch.nn.Dropout(dropouts[0])\n        )\n        self.bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(sequence_length),\n            torch.nn.Dropout(dropouts[0])\n        )\n\n        self.event_K = torch.nn.Linear(embed_dim, embed_dim)\n        self.event_Q = torch.nn.Linear(embed_dim, embed_dim)\n        self.event_V = torch.nn.Linear(embed_dim, embed_dim)\n\n        self.src_event_K = torch.nn.Linear(embed_dim, embed_dim)\n        self.src_event_Q = torch.nn.Linear(embed_dim, embed_dim)\n        self.src_event_V = torch.nn.Linear(embed_dim, embed_dim)\n\n        self.tgt_event_K = torch.nn.Linear(embed_dim, embed_dim)\n        self.tgt_event_Q = torch.nn.Linear(embed_dim, embed_dim)\n        self.tgt_event_V = torch.nn.Linear(embed_dim, embed_dim)\n        self.event_softmax = torch.nn.Softmax(dim=1)\n\n        self.src_domain_K = torch.nn.Linear(32, 32)\n        self.src_domain_Q = torch.nn.Linear(32, 32)\n        self.src_domain_V = torch.nn.Linear(32, 32)\n\n        self.tgt_domain_K = torch.nn.Linear(32, 32)\n        self.tgt_domain_Q = torch.nn.Linear(32, 32)\n        self.tgt_domain_V = torch.nn.Linear(32, 32)\n\n    def forward(self, ids, values, seq_lengths, seq_mask, dlabel):\n        """"""\n        :param\n        ids: the ids of fields (batch_size, seqlength, fields)\n        values: the values of fields (batch_size, seqlength, fields)\n        seq_length: the length of historical events (batch_size, 1)\n        seq_mask: the attention mask for historical events (batch_size, seqlength)\n        dlabel: the domain label of the batch samples (batch_size, 1)\n        :return\n        torch.sigmoid(result.squeeze(1)): the predition of the target payment\n        term: the sequence embedding, output of user behavior extractor (batch_size, 32)\n        """"""\n        if dlabel == \'src\':\n            batch_size = ids.size()[0]\n\n            shared_emb = self.embedding(ids, values)\n            src_emb = self.src_embedding(ids, values)\n\n            src_attention = self.attr_softmax(self.src_attention(ids))\n            src_event_fea = self.src_bn(torch.mean(src_attention * src_emb, 2) + self.fm(src_emb))\n\n            src_payment_fea = src_event_fea[:, -1, :]\n            src_history_fea = src_event_fea[:, :-1, :]\n\n            src_event_K = self.src_event_K(src_history_fea)\n            src_event_Q = self.src_event_Q(src_history_fea)\n            src_event_V = self.src_event_V(src_history_fea)\n            t = torch.sum(src_event_K * src_event_Q, 2, True) / 4 - torch.unsqueeze(seq_mask, 2) * 1e8\n            src_his_fea = torch.sum(self.event_softmax(t) * src_event_V, 1)\n\n            shared_attention = self.attr_softmax(self.attention(ids))\n            shared_event_fea = self.bn(torch.mean(shared_attention * shared_emb, 2) + self.fm(shared_emb))\n\n            shared_payment_fea = shared_event_fea[:, -1, :]\n            shared_history_fea = shared_event_fea[:, :-1, :]\n\n            shared_event_K = self.event_K(shared_history_fea)\n            shared_event_Q = self.event_Q(shared_history_fea)\n            shared_event_V = self.event_V(shared_history_fea)\n            t = torch.sum(shared_event_K * shared_event_Q, 2, True) / 4 - torch.unsqueeze(seq_mask, 2) * 1e8\n            shared_his_fea = torch.sum(self.event_softmax(t) * shared_event_V, 1)\n\n            src_term = torch.cat((src_his_fea, src_payment_fea), 1)\n            shared_term = torch.cat((shared_his_fea, shared_payment_fea), 1)\n\n            src_K = self.src_domain_K(src_term)\n            src_Q = self.src_domain_Q(src_term)\n            src_V = self.src_domain_V(src_term)\n            src_a = torch.exp(torch.sum(src_K * src_Q, 1, True) / 6)\n\n            shared_K = self.src_domain_K(shared_term)\n            shared_Q = self.src_domain_Q(shared_term)\n            shared_V = self.src_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 6)\n\n            term = src_a / (src_a + shared_a) * src_V + shared_a / (src_a + shared_a) * shared_V\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n\n        elif dlabel == \'tgt\':\n            batch_size = ids.size()[0]\n            shared_emb = self.embedding(ids, values)\n            tgt_emb = self.tgt_embedding(ids, values)\n\n            tgt_attention = self.attr_softmax(self.tgt_attention(ids))\n            tgt_event_fea = self.tgt_bn(torch.mean(tgt_attention * tgt_emb, 2) + self.fm(tgt_emb))\n\n            tgt_payment_fea = tgt_event_fea[:, -1, :]\n            tgt_history_fea = tgt_event_fea[:, :-1, :]\n\n            tgt_event_K = self.tgt_event_K(tgt_history_fea)\n            tgt_event_Q = self.tgt_event_Q(tgt_history_fea)\n            tgt_event_V = self.tgt_event_V(tgt_history_fea)\n            t = torch.sum(tgt_event_K * tgt_event_Q, 2, True) / 4 - torch.unsqueeze(seq_mask, 2) * 1e8\n            tgt_his_fea = torch.sum(self.event_softmax(t) * tgt_event_V, 1)\n\n            shared_attention = self.attr_softmax(self.attention(ids))\n            shared_event_fea = self.bn(torch.mean(shared_attention * shared_emb, 2) + self.fm(shared_emb))\n\n            shared_payment_fea = shared_event_fea[:, -1, :]\n            shared_history_fea = shared_event_fea[:, :-1, :]\n\n            shared_event_K = self.event_K(shared_history_fea)\n            shared_event_Q = self.event_Q(shared_history_fea)\n            shared_event_V = self.event_V(shared_history_fea)\n            t = torch.sum(shared_event_K * shared_event_Q, 2, True) / 4 - torch.unsqueeze(seq_mask, 2) * 1e8\n            shared_his_fea = torch.sum(self.event_softmax(t) * shared_event_V, 1)\n\n            tgt_term = torch.cat((tgt_his_fea, tgt_payment_fea), 1)\n            shared_term = torch.cat((shared_his_fea, shared_payment_fea), 1)\n\n            tgt_K = self.tgt_domain_K(tgt_term)\n            tgt_Q = self.tgt_domain_Q(tgt_term)\n            tgt_V = self.tgt_domain_V(tgt_term)\n            tgt_a = torch.exp(torch.sum(tgt_K * tgt_Q, 1, True) / 6)\n\n            shared_K = self.tgt_domain_K(shared_term)\n            shared_Q = self.tgt_domain_Q(shared_term)\n            shared_V = self.tgt_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 6)\n\n            term = tgt_a / (tgt_a + shared_a) * tgt_V + shared_a / (tgt_a + shared_a) * shared_V\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n'"
Application/cross-domain fraud detection/models/layer.py,19,"b'import numpy as np\nimport torch\n\n\nclass FeaturesLinear(torch.nn.Module):\n\n    def __init__(self, field_dims, output_dim=1):\n        super().__init__()\n        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n        # torch.nn.init.constant_(self.fc.weight, 0)\n        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n        return torch.sum(self.fc(x), dim=1) + self.bias\n\n\nclass FactorizationMachine(torch.nn.Module):\n\n    def __init__(self, reduce_sum=True):\n        super().__init__()\n        self.reduce_sum = reduce_sum\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        square_of_sum = torch.sum(x, dim=1) ** 2\n        sum_of_square = torch.sum(x ** 2, dim=1)\n        ix = square_of_sum - sum_of_square\n        if self.reduce_sum:\n            ix = torch.sum(ix, dim=1, keepdim=True)\n        return 0.5 * ix\n\n\nclass FeaturesEmbedding(torch.nn.Module):\n\n    def __init__(self, field_dims, embed_dim):\n        super().__init__()\n        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n\n    def forward(self, x, values):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n        values = values.unsqueeze(3)\n        return values * self.embedding(x)\n\nclass MultiLayerPerceptron(torch.nn.Module):\n\n    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n        super().__init__()\n        layers = list()\n        for embed_dim in embed_dims:\n            layers.append(torch.nn.Linear(input_dim, embed_dim))\n            layers.append(torch.nn.BatchNorm1d(embed_dim))\n            layers.append(torch.nn.ReLU())\n            layers.append(torch.nn.Dropout(p=dropout))\n            input_dim = embed_dim\n        if output_layer:\n            layers.append(torch.nn.Linear(input_dim, 1))\n        self.mlp = torch.nn.Sequential(*layers)\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        return self.mlp(x)\n'"
Application/cross-domain fraud detection/models/lstm4fd.py,33,"b'import torch\n\nfrom .layer import FeaturesLinear, MultiLayerPerceptron, FeaturesEmbedding\n\nclass LSTM4FDModel(torch.nn.Module):\n    """"""\n    A pytorch implementation LSTM4FD\n    Reference:\n        Wang S, Liu C, Gao X, et al. Session-based fraud detection in online e-commerce transactions using recurrent neural networks[C]//Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Cham, 2017: 241-252.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, sequence_length, lstm_dims, mlp_dims, dropouts):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.src_embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.tgt_embedding = FeaturesEmbedding(field_dims, embed_dim)\n\n        self.linear = FeaturesLinear(field_dims)\n        self.mlp = MultiLayerPerceptron(embed_dim + embed_dim, mlp_dims, dropouts[1])  # + hidden_size  + lstm_dims\n        self.embed_dim = embed_dim\n\n        self.src_domain_K = torch.nn.Linear(32, 32)\n        self.src_domain_Q = torch.nn.Linear(32, 32)\n        self.src_domain_V = torch.nn.Linear(32, 32)\n\n        self.tgt_domain_K = torch.nn.Linear(32, 32)\n        self.tgt_domain_Q = torch.nn.Linear(32, 32)\n        self.tgt_domain_V = torch.nn.Linear(32, 32)\n\n        self.lstm = torch.nn.LSTM(embed_dim, hidden_size=embed_dim, num_layers=1, batch_first=True, bidirectional=True)\n        self.src_lstm = torch.nn.LSTM(embed_dim, hidden_size=embed_dim, num_layers=1, batch_first=True,\n                                      bidirectional=True)\n        self.tgt_lstm = torch.nn.LSTM(embed_dim, hidden_size=embed_dim, num_layers=1, batch_first=True,\n                                      bidirectional=True)\n\n    def forward(self, ids, values, seq_lengths, seq_mask, dlabel):\n        """"""\n        :param\n        ids: the ids of fields (batch_size, seqlength, fields)\n        values: the values of fields (batch_size, seqlength, fields)\n        seq_length: the length of historical events (batch_size, 1)\n        seq_mask: the attention mask for historical events (batch_size, seqlength)\n        dlabel: the domain label of the batch samples (batch_size, 1)\n        :return\n        torch.sigmoid(result.squeeze(1)): the predition of the target payment\n        term: the sequence embedding, output of user behavior extractor (batch_size, 32)\n        """"""\n        batch_size = ids.size()[0]\n        if dlabel == \'src\':\n            shared_emb = self.embedding(ids, values)\n            shared_t = torch.mean(shared_emb, 2)\n            shared_history = shared_t[:, :-1, :]\n            shared_term = shared_t[:, -1:, :].view(batch_size, -1)\n\n            shared_pack = torch.nn.utils.rnn.pack_padded_sequence(shared_history, seq_lengths, batch_first=True,\n                                                                  enforce_sorted=False)\n            _, (shared_lstm_hn, __) = self.lstm(shared_pack)\n            shared_lstm_hn = torch.mean(shared_lstm_hn, dim=0)\n\n            shared_term = torch.cat((shared_lstm_hn, shared_term), 1)\n\n            src_emb = self.src_embedding(ids, values)\n            src_t = torch.mean(src_emb, 2)\n            src_history = src_t[:, :-1, :]\n            src_term = src_t[:, -1:, :].view(batch_size, -1)\n\n            src_pack = torch.nn.utils.rnn.pack_padded_sequence(src_history, seq_lengths, batch_first=True,\n                                                               enforce_sorted=False)\n            _, (src_lstm_hn, __) = self.src_lstm(src_pack)\n            src_lstm_hn = torch.mean(src_lstm_hn, dim=0)\n\n            src_term = torch.cat((src_lstm_hn, src_term), 1)\n\n            src_K = self.src_domain_K(src_term)\n            src_Q = self.src_domain_Q(src_term)\n            src_V = self.src_domain_V(src_term)\n            src_a = torch.exp(torch.sum(src_K * src_Q, 1, True) / 7)\n\n            shared_K = self.src_domain_K(shared_term)\n            shared_Q = self.src_domain_Q(shared_term)\n            shared_V = self.src_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 7)\n\n            term = src_a / (src_a + shared_a) * src_V + shared_a / (src_a + shared_a) * shared_V\n\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n        if dlabel == \'tgt\':\n            shared_emb = self.embedding(ids, values)\n            shared_t = torch.mean(shared_emb, 2)\n            shared_history = shared_t[:, :-1, :]\n            shared_term = shared_t[:, -1:, :].view(batch_size, -1)\n\n            shared_pack = torch.nn.utils.rnn.pack_padded_sequence(shared_history, seq_lengths, batch_first=True,\n                                                                  enforce_sorted=False)\n            _, (shared_lstm_hn, __) = self.lstm(shared_pack)\n            shared_lstm_hn = torch.mean(shared_lstm_hn, dim=0)\n\n            shared_term = torch.cat((shared_lstm_hn, shared_term), 1)\n\n            tgt_emb = self.tgt_embedding(ids, values)\n            tgt_t = torch.mean(tgt_emb, 2)\n            tgt_history = tgt_t[:, :-1, :]\n            tgt_term = tgt_t[:, -1:, :].view(batch_size, -1)\n\n            tgt_pack = torch.nn.utils.rnn.pack_padded_sequence(tgt_history, seq_lengths, batch_first=True,\n                                                               enforce_sorted=False)\n            _, (tgt_lstm_hn, __) = self.tgt_lstm(tgt_pack)\n            tgt_lstm_hn = torch.mean(tgt_lstm_hn, dim=0)\n\n            tgt_term = torch.cat((tgt_lstm_hn, tgt_term), 1)\n\n            tgt_K = self.tgt_domain_K(tgt_term)\n            tgt_Q = self.tgt_domain_Q(tgt_term)\n            tgt_V = self.tgt_domain_V(tgt_term)\n            tgt_a = torch.exp(torch.sum(tgt_K * tgt_Q, 1, True) / 7)\n\n            shared_K = self.tgt_domain_K(shared_term)\n            shared_Q = self.tgt_domain_Q(shared_term)\n            shared_V = self.tgt_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 7)\n\n            term = tgt_a / (tgt_a + shared_a) * tgt_V + shared_a / (tgt_a + shared_a) * shared_V\n\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n'"
Application/cross-domain fraud detection/models/m3r.py,44,"b'import torch\nimport numpy as np\n\nfrom .layer import FeaturesLinear, MultiLayerPerceptron, FeaturesEmbedding\n\n\nclass SeqM3RModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of M3R.\n    Reference:\n        Tang J, Belletti F, Jain S, et al. Towards neural mixture recommender for long range dependent user sequences[C]//The World Wide Web Conference. ACM, 2019: 1782-1793.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, sequence_length, lstm_dims, mlp_dims, dropouts):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.src_embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.tgt_embedding = FeaturesEmbedding(field_dims, embed_dim)\n\n        self.fc = torch.nn.Linear(in_features=56 * embed_dim, out_features=embed_dim)\n        self.src_fc = torch.nn.Linear(in_features=56 * embed_dim, out_features=embed_dim)\n        self.tgt_fc = torch.nn.Linear(in_features=56 * embed_dim, out_features=embed_dim)\n        self.bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(sequence_length),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(dropouts[0])\n        )\n        self.src_bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(sequence_length),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(dropouts[0])\n        )\n        self.tgt_bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(sequence_length),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(dropouts[0])\n        )\n\n        self.linear = FeaturesLinear(field_dims)\n        self.mlp = MultiLayerPerceptron(embed_dim + embed_dim, mlp_dims, dropouts[1])  # + hidden_size  + lstm_dims\n        self.embed_dim = embed_dim\n\n        self.src_domain_K = torch.nn.Linear(32, 32)\n        self.src_domain_Q = torch.nn.Linear(32, 32)\n        self.src_domain_V = torch.nn.Linear(32, 32)\n\n        self.tgt_domain_K = torch.nn.Linear(32, 32)\n        self.tgt_domain_Q = torch.nn.Linear(32, 32)\n        self.tgt_domain_V = torch.nn.Linear(32, 32)\n\n        self.lstm = torch.nn.LSTM(embed_dim, hidden_size=embed_dim, num_layers=1, batch_first=True, bidirectional=True)\n        self.src_lstm = torch.nn.LSTM(embed_dim, hidden_size=embed_dim, num_layers=1, batch_first=True,\n                                      bidirectional=True)\n        self.tgt_lstm = torch.nn.LSTM(embed_dim, hidden_size=embed_dim, num_layers=1, batch_first=True,\n                                      bidirectional=True)\n\n    def forward(self, ids, values, seq_lengths, seq_mask, dlabel):\n        """"""\n        :param\n        ids: the ids of fields (batch_size, seqlength, fields)\n        values: the values of fields (batch_size, seqlength, fields)\n        seq_length: the length of historical events (batch_size, 1)\n        seq_mask: the attention mask for historical events (batch_size, seqlength)\n        dlabel: the domain label of the batch samples (batch_size, 1)\n        :return\n        torch.sigmoid(result.squeeze(1)): the predition of the target payment\n        term: the sequence embedding, output of user behavior extractor (batch_size, 32)\n        """"""\n        batch_size = ids.size()[0]\n        if dlabel == \'src\':\n            shared_emb = self.embedding(ids, values).view(-1, 56 * self.embed_dim)\n            shared_t = self.bn(self.fc(shared_emb).view(batch_size, -1, self.embed_dim))\n            shared_history = shared_t[:, :-1, :]\n            shared_term = shared_t[:, -1:, :].view(batch_size, -1)\n\n            shared_pack = torch.nn.utils.rnn.pack_padded_sequence(shared_history, seq_lengths, batch_first=True,\n                                                                  enforce_sorted=False)\n            _, (shared_lstm_hn, __) = self.lstm(shared_pack)\n            shared_lstm_hn = torch.mean(shared_lstm_hn, dim=0)\n\n            shared_term = torch.cat((shared_lstm_hn, shared_term), 1)\n\n            src_emb = self.src_embedding(ids, values).view(-1, 56 * self.embed_dim)\n            src_t = self.src_bn(self.src_fc(src_emb).view(batch_size, -1, self.embed_dim))\n            src_history = src_t[:, :-1, :]\n            src_term = src_t[:, -1:, :].view(batch_size, -1)\n\n            src_pack = torch.nn.utils.rnn.pack_padded_sequence(src_history, seq_lengths, batch_first=True,\n                                                               enforce_sorted=False)\n            _, (src_lstm_hn, __) = self.src_lstm(src_pack)\n            src_lstm_hn = torch.mean(src_lstm_hn, dim=0)\n\n            src_term = torch.cat((src_lstm_hn, src_term), 1)\n\n            src_K = self.src_domain_K(src_term)\n            src_Q = self.src_domain_Q(src_term)\n            src_V = self.src_domain_V(src_term)\n            src_a = torch.exp(torch.sum(src_K * src_Q, 1, True) / 7)\n\n            shared_K = self.src_domain_K(shared_term)\n            shared_Q = self.src_domain_Q(shared_term)\n            shared_V = self.src_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 7)\n\n            term = src_a / (src_a + shared_a) * src_V + shared_a / (src_a + shared_a) * shared_V\n\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n        if dlabel == \'tgt\':\n            shared_emb = self.embedding(ids, values).view(-1, 56 * self.embed_dim)\n            shared_t = self.bn(self.fc(shared_emb).view(batch_size, -1, self.embed_dim))\n            shared_history = shared_t[:, :-1, :]\n            shared_term = shared_t[:, -1:, :].view(batch_size, -1)\n\n            shared_pack = torch.nn.utils.rnn.pack_padded_sequence(shared_history, seq_lengths, batch_first=True,\n                                                                  enforce_sorted=False)\n            _, (shared_lstm_hn, __) = self.lstm(shared_pack)\n            shared_lstm_hn = torch.mean(shared_lstm_hn, dim=0)\n\n            shared_term = torch.cat((shared_lstm_hn, shared_term), 1)\n\n            tgt_emb = self.tgt_embedding(ids, values).view(-1, 56 * self.embed_dim)\n            tgt_t = self.tgt_bn(self.tgt_fc(tgt_emb).view(batch_size, -1, self.embed_dim))\n            tgt_history = tgt_t[:, :-1, :]\n            tgt_term = tgt_t[:, -1:, :].view(batch_size, -1)\n\n            tgt_pack = torch.nn.utils.rnn.pack_padded_sequence(tgt_history, seq_lengths, batch_first=True,\n                                                               enforce_sorted=False)\n            _, (tgt_lstm_hn, __) = self.tgt_lstm(tgt_pack)\n            tgt_lstm_hn = torch.mean(tgt_lstm_hn, dim=0)\n\n            tgt_term = torch.cat((tgt_lstm_hn, tgt_term), 1)\n\n            tgt_K = self.tgt_domain_K(tgt_term)\n            tgt_Q = self.tgt_domain_Q(tgt_term)\n            tgt_V = self.tgt_domain_V(tgt_term)\n            tgt_a = torch.exp(torch.sum(tgt_K * tgt_Q, 1, True) / 7)\n\n            shared_K = self.tgt_domain_K(shared_term)\n            shared_Q = self.tgt_domain_Q(shared_term)\n            shared_V = self.tgt_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 7)\n\n            term = tgt_a / (tgt_a + shared_a) * tgt_V + shared_a / (tgt_a + shared_a) * shared_V\n\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n'"
Application/cross-domain fraud detection/models/nfm.py,23,"b'import torch\n\nfrom .layer import FeaturesLinear, MultiLayerPerceptron, FeaturesEmbedding, FactorizationMachine\n\n\nclass NeuralFactorizationMachineModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Neural Factorization Machine.\n    Reference:\n        X He and TS Chua, Neural Factorization Machines for Sparse Predictive Analytics, 2017.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropouts):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.src_embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.tgt_embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.linear = FeaturesLinear(field_dims)\n        self.fm = FactorizationMachine(reduce_sum=False)\n        # self.fm1 = FactorizationMachine1(reduce_sum=False)\n        self.bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(embed_dim),\n            torch.nn.Dropout(dropouts[0])\n        )\n        self.tgt_bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(embed_dim),\n            torch.nn.Dropout(dropouts[0])\n        )\n        self.src_bn = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(embed_dim),\n            torch.nn.Dropout(dropouts[0])\n        )\n        self.mlp = MultiLayerPerceptron(embed_dim, mlp_dims, dropouts[1])  # + hidden_size  + lstm_dims\n        self.embed_dim = embed_dim\n        self.src_domain_K = torch.nn.Linear(16, 16)\n        self.src_domain_Q = torch.nn.Linear(16, 16)\n        self.src_domain_V = torch.nn.Linear(16, 16)\n\n        self.tgt_domain_K = torch.nn.Linear(16, 16)\n        self.tgt_domain_Q = torch.nn.Linear(16, 16)\n        self.tgt_domain_V = torch.nn.Linear(16, 16)\n\n    def forward(self, ids, values, seq_lengths, seq_mask, dlabel):\n        """"""\n        :param\n        ids: the ids of fields (batch_size, seqlength, fields)\n        values: the values of fields (batch_size, seqlength, fields)\n        seq_length: the length of historical events (batch_size, 1)\n        seq_mask: the attention mask for historical events (batch_size, seqlength)\n        dlabel: the domain label of the batch samples (batch_size, 1)\n        :return\n        torch.sigmoid(result.squeeze(1)): the predition of the target payment\n        term: the sequence embedding, output of user behavior extractor (batch_size, 32)\n        """"""\n        if dlabel == \'src\':\n            batch_size = ids.size()[0]\n            shared_emb = self.embedding(ids, values)\n            shared_term = self.bn(self.fm(shared_emb[:, :, :].view(batch_size, -1, self.embed_dim)))\n\n            src_emb = self.src_embedding(ids, values)\n            src_term = self.src_bn(self.fm(src_emb[:, :, :].view(batch_size, -1, self.embed_dim)))\n\n            src_K = self.src_domain_K(src_term)\n            src_Q = self.src_domain_Q(src_term)\n            src_V = self.src_domain_V(src_term)\n            src_a = torch.exp(torch.sum(src_K * src_Q, 1, True) / 4)\n\n            shared_K = self.src_domain_K(shared_term)\n            shared_Q = self.src_domain_Q(shared_term)\n            shared_V = self.src_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 4)\n\n            term = src_a / (src_a + shared_a) * src_V + shared_a / (src_a + shared_a) * shared_V\n\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n\n        elif dlabel == \'tgt\':\n            batch_size = ids.size()[0]\n            shared_emb = self.embedding(ids, values)\n            shared_term = self.bn(self.fm(shared_emb[:, :, :].view(batch_size, -1, self.embed_dim)))\n\n            tgt_emb = self.tgt_embedding(ids, values)\n            tgt_term = self.tgt_bn(self.fm(tgt_emb[:, :, :].view(batch_size, -1, self.embed_dim)))\n\n            tgt_K = self.tgt_domain_K(tgt_term)\n            tgt_Q = self.tgt_domain_Q(tgt_term)\n            tgt_V = self.tgt_domain_V(tgt_term)\n            tgt_a = torch.exp(torch.sum(tgt_K * tgt_Q, 1, True) / 4)\n\n            shared_K = self.tgt_domain_K(shared_term)\n            shared_Q = self.tgt_domain_Q(shared_term)\n            shared_V = self.tgt_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 4)\n\n            term = tgt_a / (tgt_a + shared_a) * tgt_V + shared_a / (tgt_a + shared_a) * shared_V\n\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n'"
Application/cross-domain fraud detection/models/wd.py,17,"b'import torch\nimport numpy as np\nfrom .layer import FeaturesLinear, MultiLayerPerceptron, FeaturesEmbedding\n\n\nclass WideAndDeepModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of wide and deep learning.\n    Reference:\n        HT Cheng, et al. Wide & Deep Learning for Recommender Systems, 2016.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropout):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.src_embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.tgt_embedding = FeaturesEmbedding(field_dims, embed_dim)\n\n        self.embed_output_dim = 11 * 56 * embed_dim\n        self.layer = torch.nn.Linear(self.embed_output_dim, 32)\n        self.src_layer = torch.nn.Linear(self.embed_output_dim, 32)\n        self.tgt_layer = torch.nn.Linear(self.embed_output_dim, 32)\n\n        self.linear = FeaturesLinear(field_dims)\n        self.mlp = MultiLayerPerceptron(32, mlp_dims, dropout)\n\n        self.src_domain_K = torch.nn.Linear(32, 32)\n        self.src_domain_Q = torch.nn.Linear(32, 32)\n        self.src_domain_V = torch.nn.Linear(32, 32)\n\n        self.tgt_domain_K = torch.nn.Linear(32, 32)\n        self.tgt_domain_Q = torch.nn.Linear(32, 32)\n        self.tgt_domain_V = torch.nn.Linear(32, 32)\n\n    def forward(self, ids, values, seq_lengths, seq_mask, dlabel):\n        """"""\n        :param\n        ids: the ids of fields (batch_size, seqlength, fields)\n        values: the values of fields (batch_size, seqlength, fields)\n        seq_length: the length of historical events (batch_size, 1)\n        seq_mask: the attention mask for historical events (batch_size, seqlength)\n        dlabel: the domain label of the batch samples (batch_size, 1)\n        :return\n        torch.sigmoid(result.squeeze(1)): the predition of the target payment\n        term: the sequence embedding, output of user behavior extractor (batch_size, 32)\n        """"""\n        batch_size = ids.size()[0]\n        if dlabel == \'src\':\n            shared_emb = self.embedding(ids, values).view(batch_size, -1)\n            shared_term = self.layer(shared_emb)\n\n            src_emb = self.src_embedding(ids, values).view(batch_size, -1)\n            src_term = self.src_layer(src_emb)\n\n            src_K = self.src_domain_K(src_term)\n            src_Q = self.src_domain_Q(src_term)\n            src_V = self.src_domain_V(src_term)\n            src_a = torch.exp(torch.sum(src_K * src_Q, 1, True) / 6)\n\n            shared_K = self.src_domain_K(shared_term)\n            shared_Q = self.src_domain_Q(shared_term)\n            shared_V = self.src_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 6)\n\n            term = src_a / (src_a + shared_a) * src_V + shared_a / (src_a + shared_a) * shared_V\n\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n\n        if dlabel == \'tgt\':\n            shared_emb = self.embedding(ids, values).view(batch_size, -1)\n            shared_term = self.layer(shared_emb)\n\n            tgt_emb = self.tgt_embedding(ids, values).view(batch_size, -1)\n            tgt_term = self.tgt_layer(tgt_emb)\n\n            tgt_K = self.tgt_domain_K(tgt_term)\n            tgt_Q = self.tgt_domain_Q(tgt_term)\n            tgt_V = self.tgt_domain_V(tgt_term)\n            tgt_a = torch.exp(torch.sum(tgt_K * tgt_Q, 1, True) / 6)\n\n            shared_K = self.tgt_domain_K(shared_term)\n            shared_Q = self.tgt_domain_Q(shared_term)\n            shared_V = self.tgt_domain_V(shared_term)\n            shared_a = torch.exp(torch.sum(shared_K * shared_Q, 1, True) / 6)\n\n            term = tgt_a / (tgt_a + shared_a) * tgt_V + shared_a / (tgt_a + shared_a) * shared_V\n\n            result = self.linear(ids[:, -1, :].view(batch_size, -1)) + self.mlp(term)\n            return torch.sigmoid(result.squeeze(1)), term\n'"
Application/cross-domain fraud detection/utils/utils.py,25,"b'import torch\nfrom utils.weight import Weight\n\n\nclass Averager():\n\n    def __init__(self):\n        self.n = 0\n        self.v = 0\n\n    def add(self, x):\n        self.v = (self.v * self.n + x) / (self.n + 1)\n        self.n += 1\n\n    def item(self):\n        return self.v\n\n\nclass Stoper():\n\n    def __init__(self, early_step):\n        self.max = -1\n        self.maxindex = 0\n        self.l = []\n        self.early_step = early_step\n\n    def add(self, x):\n        self.l.append(x)\n        if x > self.max:\n            self.max = x\n            self.maxindex = len(self.l) - 1\n            return False\n        elif len(self.l) > self.early_step:\n            if len(self.l) - 1 - self.maxindex >= self.early_step:\n                return True\n            else:\n                return False\n        else:\n            return False\n\n\ndef guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    n_samples = int(source.size()[0]) + int(target.size()[0])\n    total = torch.cat([source, target], dim=0)\n    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    L2_distance = ((total0 - total1) ** 2).sum(2)\n    if fix_sigma:\n        bandwidth = fix_sigma\n    else:\n        bandwidth = torch.sum(L2_distance.data) / (n_samples ** 2 - n_samples)\n    bandwidth /= kernel_mul ** (kernel_num // 2)\n    bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n    return sum(kernel_val)  # /len(kernel_val)\n\n\ndef mmd_rbf_accelerate(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    loss = 0\n    for i in range(batch_size):\n        s1, s2 = i, (i + 1) % batch_size\n        t1, t2 = s1 + batch_size, s2 + batch_size\n        loss += kernels[s1, s2] + kernels[t1, t2]\n        loss -= kernels[s1, t2] + kernels[s2, t1]\n    return loss / float(batch_size)\n\n\ndef mmd_rbf_noaccelerate(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    XX = kernels[:batch_size, :batch_size]\n    YY = kernels[batch_size:, batch_size:]\n    XY = kernels[:batch_size, batch_size:]\n    YX = kernels[batch_size:, :batch_size]\n    loss = torch.mean(XX + YY - XY - YX)\n    return loss\n\n\ndef cmmd(source, target, s_label, t_label, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = source.size()[0]\n    weight_ss, weight_tt, weight_st = Weight.cal_weight(s_label, t_label, class_num=2)\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    SS = kernels[:batch_size, :batch_size]\n    TT = kernels[batch_size:, batch_size:]\n    ST = kernels[:batch_size, batch_size:]\n\n    loss = torch.sum(weight_ss * SS + weight_tt * TT - 2 * weight_st * ST)\n    if torch.isnan(loss):\n        return torch.Tensor([0]).cuda()\n    # print(loss)\n    return loss\n\n\ndef coral(source, target):\n    d = source.data.shape[1]\n\n    # source covariance\n    xm = torch.mean(source, 1, keepdim=True) - source\n    xc = torch.matmul(torch.transpose(xm, 0, 1), xm)\n\n    # target covariance\n    xmt = torch.mean(target, 1, keepdim=True) - target\n    xct = torch.matmul(torch.transpose(xmt, 0, 1), xmt)\n    # frobenius norm between source and target\n    loss = torch.mean(torch.mul((xc - xct), (xc - xct)))\n    loss = loss / (4 * d * 4)\n    return loss\n\n\ndef euclidian(source, target):\n    d = source.data.shape[1]\n\n    # source covariance\n    avg_s = torch.mean(source, 0)\n    avg_t = torch.mean(target, 0)\n    loss = ((avg_s - avg_t) ** 2).sum()\n    return loss\n\n\ndef c_euclidian(source, target, s_label, t_label):\n    d = source.data.shape[1]\n    src_white = source[s_label == 0]\n    src_black = source[s_label == 1]\n\n    tgt_white = target[t_label == 0]\n    tgt_black = target[t_label == 1]\n\n    loss = 0\n    avg_sw = torch.mean(src_white, 0)\n    avg_tw = torch.mean(tgt_white, 0)\n    loss += ((avg_sw - avg_tw) ** 2).sum()\n\n    avg_sb = torch.mean(src_black, 0)\n    avg_tb = torch.mean(tgt_black, 0)\n    loss += ((avg_sb - avg_tb) ** 2).sum()\n\n    return loss\n\n\ndef ced(source, target, s_label, t_label):\n    src_white = source[s_label == 0]\n    src_black = source[s_label == 1]\n\n    tgt_white = target[t_label == 0]\n    tgt_black = target[t_label == 1]\n    if (not bool(src_white.numel())) or (not bool(src_black.numel())) or (not bool(tgt_white.numel())) or (\n            not bool(tgt_black.numel())):\n        avg_s = torch.mean(source, 0)\n        avg_t = torch.mean(target, 0)\n        loss = ((avg_s - avg_t) ** 2).sum()\n        return loss\n    loss = 0\n    avg_sw = torch.mean(src_white, 0)\n    avg_tw = torch.mean(tgt_white, 0)\n    loss += ((avg_sw - avg_tw) ** 2).sum()\n\n    avg_sb = torch.mean(src_black, 0)\n    avg_tb = torch.mean(tgt_black, 0)\n    loss += ((avg_sb - avg_tb) ** 2).sum()\n\n    loss /= (((avg_sw - avg_tb) ** 2).sum() + ((avg_sb - avg_tw) ** 2).sum() + ((avg_sw - avg_sb) ** 2).sum() + (\n            (avg_tw - avg_tb) ** 2).sum())\n\n    return loss\n\n\ndef nometric(source, target):\n    loss = torch.FloatTensor([0]).cuda()\n\n    return loss\n'"
Application/cross-domain fraud detection/utils/weight.py,12,"b'import numpy as np\nimport torch\n\n\ndef convert_to_onehot(label, batch_size, class_num):\n    return torch.zeros(batch_size, class_num).cuda().scatter_(1, label, 1)\n\n\nclass Weight:\n\n    @staticmethod\n    def cal_weight(s_label, t_label, batch_size=512, class_num=2):\n        batch_size = s_label.size()[0]\n        s_sca_label = s_label\n        s_vec_label = convert_to_onehot(s_sca_label.view(-1, 1), batch_size, class_num)\n        s_sum = torch.sum(s_vec_label, dim=0).view(1, class_num)\n        s_sum[s_sum == 0] = 10000\n        s_vec_label = s_vec_label / s_sum\n\n        t_sca_label = t_label\n        t_vec_label = convert_to_onehot(t_sca_label.view(-1, 1), batch_size, class_num)\n        t_sum = torch.sum(t_vec_label, dim=0).view(1, class_num)\n        t_sum[t_sum == 0] = 100\n        t_vec_label = t_vec_label / t_sum\n\n        weight_ss = torch.zeros(batch_size, batch_size).cuda()\n        weight_tt = torch.zeros(batch_size, batch_size).cuda()\n        weight_st = torch.zeros(batch_size, batch_size).cuda()\n\n        set_s = set(s_sca_label.cpu().numpy())\n        set_t = set(t_sca_label.cpu().numpy())\n        count = 0\n        for i in range(class_num):\n            if i in set_s and i in set_t:\n                s_tvec = s_vec_label[:, i]\n                t_tvec = t_vec_label[:, i]\n                ss = torch.mm(s_tvec.view(-1, 1), s_tvec.view(1, -1))\n                weight_ss = weight_ss + ss\n                tt = torch.mm(t_tvec.view(-1, 1), t_tvec.view(1, -1))\n                weight_tt = weight_tt + tt\n                st = torch.mm(s_tvec.view(-1, 1), t_tvec.view(1, -1))\n                weight_st = weight_st + st\n                count += 1\n\n        length = count\n        if length != 0:\n            weight_ss = weight_ss / length\n            weight_tt = weight_tt / length\n            weight_st = weight_st / length\n        else:\n            weight_ss = torch.zeros(1)\n            weight_tt = torch.zeros(1)\n            weight_st = torch.zeros(1)\n        return weight_ss, weight_tt, weight_st\n'"
MUDA/MFSAN/MFSAN_2src/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
MUDA/MFSAN/MFSAN_2src/mfsan.py,8,"b'from __future__ import print_function\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport resnet as models\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n# Training settings\nbatch_size = 32\niteration = 10000\nlr = 0.01\nmomentum = 0.9\ncuda = True\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nroot_path = ""./dataset/""\nsource1_name = ""webcam""\nsource2_name = \'dslr\'\ntarget_name = ""amazon""\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsource1_loader = data_loader.load_training(root_path, source1_name, batch_size, kwargs)\nsource2_loader = data_loader.load_training(root_path, source2_name, batch_size, kwargs)\ntarget_train_loader = data_loader.load_training(root_path, target_name, batch_size, kwargs)\ntarget_test_loader = data_loader.load_testing(root_path, target_name, batch_size, kwargs)\n\ndef train(model):\n    source1_iter = iter(source1_loader)\n    source2_iter = iter(source2_loader)\n    target_iter = iter(target_train_loader)\n    correct = 0\n\n    for i in range(1, iteration + 1):\n        model.train()\n        LEARNING_RATE = lr / math.pow((1 + 10 * (i - 1) / (iteration)), 0.75)\n        if (i - 1) % 100 == 0:\n            print(""learning rate\xef\xbc\x9a"", LEARNING_RATE)\n        optimizer = torch.optim.SGD([\n            {\'params\': model.sharedNet.parameters()},\n            {\'params\': model.cls_fc_son1.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.cls_fc_son2.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.sonnet1.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.sonnet2.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n\n        try:\n            source_data, source_label = source1_iter.next()\n        except Exception as err:\n            source1_iter = iter(source1_loader)\n            source_data, source_label = source1_iter.next()\n        try:\n            target_data, __ = target_iter.next()\n        except Exception as err:\n            target_iter = iter(target_train_loader)\n            target_data, __ = target_iter.next()\n        if cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        target_data = Variable(target_data)\n        optimizer.zero_grad()\n\n        cls_loss, mmd_loss, l1_loss = model(source_data, target_data, source_label, mark=1)\n        gamma = 2 / (1 + math.exp(-10 * (i) / (iteration) )) - 1\n        loss = cls_loss + gamma * (mmd_loss + l1_loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % log_interval == 0:\n            print(\'Train source1 iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\\tl1_Loss: {:.6f}\'.format(\n                i, 100. * i / iteration, loss.item(), cls_loss.item(), mmd_loss.item(), l1_loss.item()))\n\n        try:\n            source_data, source_label = source2_iter.next()\n        except Exception as err:\n            source2_iter = iter(source2_loader)\n            source_data, source_label = source2_iter.next()\n        try:\n            target_data, __ = target_iter.next()\n        except Exception as err:\n            target_iter = iter(target_train_loader)\n            target_data, __ = target_iter.next()\n        if cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        target_data = Variable(target_data)\n        optimizer.zero_grad()\n\n        cls_loss, mmd_loss, l1_loss = model(source_data, target_data, source_label, mark=2)\n        gamma = 2 / (1 + math.exp(-10 * (i) / (iteration))) - 1\n        loss = cls_loss + gamma * (mmd_loss + l1_loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % log_interval == 0:\n            print(\n                \'Train source2 iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\\tl1_Loss: {:.6f}\'.format(\n                    i, 100. * i / iteration, loss.item(), cls_loss.item(), mmd_loss.item(), l1_loss.item()))\n\n        if i % (log_interval * 20) == 0:\n            t_correct = test(model)\n            if t_correct > correct:\n                correct = t_correct\n            print(source1_name, source2_name, ""to"", target_name, ""%s max correct:"" % target_name, correct.item(), ""\\n"")\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    correct1 = 0\n    correct2 = 0\n    with torch.no_grad():\n        for data, target in target_test_loader:\n            if cuda:\n                data, target = data.cuda(), target.cuda()\n            data, target = Variable(data), Variable(target)\n            pred1, pred2 = model(data, mark = 0)\n\n            pred1 = torch.nn.functional.softmax(pred1, dim=1)\n            pred2 = torch.nn.functional.softmax(pred2, dim=1)\n\n            pred = (pred1 + pred2) / 2\n            test_loss += F.nll_loss(F.log_softmax(pred, dim=1), target).item()\n\n            pred = pred.data.max(1)[1]\n            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n            pred = pred1.data.max(1)[1]\n            correct1 += pred.eq(target.data.view_as(pred)).cpu().sum()\n            pred = pred2.data.max(1)[1]\n            correct2 += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n        test_loss /= len(target_test_loader.dataset)\n        print(target_name, \'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n            test_loss, correct, len(target_test_loader.dataset),\n            100. * correct / len(target_test_loader.dataset)))\n        print(\'\\nsource1 accnum {}, source2 accnum {}\'.format(correct1, correct2))\n    return correct\n\nif __name__ == \'__main__\':\n    model = models.MFSAN(num_classes=31)\n    print(model)\n    if cuda:\n        model.cuda()\n    train(model)\n'"
MUDA/MFSAN/MFSAN_2src/mmd.py,5,"b'#!/usr/bin/env python\n# encoding: utf-8\n\nimport torch\nfrom torch.autograd import Variable\n\ndef guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    n_samples = int(source.size()[0])+int(target.size()[0])\n    total = torch.cat([source, target], dim=0)\n    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    L2_distance = ((total0-total1)**2).sum(2)\n    if fix_sigma:\n        bandwidth = fix_sigma\n    else:\n        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n    bandwidth /= kernel_mul ** (kernel_num // 2)\n    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n    return sum(kernel_val)#/len(kernel_val)\n\ndef mmd(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    XX = kernels[:batch_size, :batch_size]\n    YY = kernels[batch_size:, batch_size:]\n    XY = kernels[:batch_size, batch_size:]\n    YX = kernels[batch_size:, :batch_size]\n    loss = torch.mean(XX + YY - XY -YX)\n    return loss\n'"
MUDA/MFSAN/MFSAN_2src/resnet.py,10,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport mmd\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch\n\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ADDneck(nn.Module):\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(ADDneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.stride = stride\n\n    def forward(self, x):\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.baselayer = [self.conv1, self.bn1, self.layer1, self.layer2, self.layer3, self.layer4]\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        return x\n\nclass MFSAN(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(MFSAN, self).__init__()\n        self.sharedNet = resnet50(True)\n        self.sonnet1 = ADDneck(2048, 256)\n        self.sonnet2 = ADDneck(2048, 256)\n        self.cls_fc_son1 = nn.Linear(256, num_classes)\n        self.cls_fc_son2 = nn.Linear(256, num_classes)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n\n    def forward(self, data_src, data_tgt = 0, label_src = 0, mark = 1):\n        mmd_loss = 0\n        if self.training == True:\n            if mark == 1:\n                data_src = self.sharedNet(data_src)\n                data_tgt = self.sharedNet(data_tgt)\n\n                data_tgt_son1 = self.sonnet1(data_tgt)\n                data_tgt_son1 = self.avgpool(data_tgt_son1)\n                data_tgt_son1 = data_tgt_son1.view(data_tgt_son1.size(0), -1)\n\n                data_src = self.sonnet1(data_src)\n                data_src = self.avgpool(data_src)\n                data_src = data_src.view(data_src.size(0), -1)\n                mmd_loss += mmd.mmd(data_src, data_tgt_son1)\n\n                data_tgt_son1 = self.cls_fc_son1(data_tgt_son1)\n\n                data_tgt_son2 = self.sonnet2(data_tgt)\n                data_tgt_son2 = self.avgpool(data_tgt_son2)\n                data_tgt_son2 = data_tgt_son2.view(data_tgt_son2.size(0), -1)\n                data_tgt_son2 = self.cls_fc_son2(data_tgt_son2)\n                l1_loss = torch.abs(torch.nn.functional.softmax(data_tgt_son1, dim=1) - torch.nn.functional.softmax(data_tgt_son2, dim=1))\n                l1_loss = torch.mean(l1_loss)\n                pred_src = self.cls_fc_son1(data_src)\n\n                cls_loss = F.nll_loss(F.log_softmax(pred_src, dim=1), label_src)\n\n                return cls_loss, mmd_loss, l1_loss\n\n            if mark == 2:\n                data_src = self.sharedNet(data_src)\n                data_tgt = self.sharedNet(data_tgt)\n\n                data_tgt_son2 = self.sonnet2(data_tgt)\n                data_tgt_son2 = self.avgpool(data_tgt_son2)\n                data_tgt_son2 = data_tgt_son2.view(data_tgt_son2.size(0), -1)\n\n                data_src = self.sonnet2(data_src)\n                data_src = self.avgpool(data_src)\n                data_src = data_src.view(data_src.size(0), -1)\n                mmd_loss += mmd.mmd(data_src, data_tgt_son2)\n\n                data_tgt_son2 = self.cls_fc_son2(data_tgt_son2)\n\n                data_tgt_son1 = self.sonnet1(data_tgt)\n                data_tgt_son1 = self.avgpool(data_tgt_son1)\n                data_tgt_son1 = data_tgt_son1.view(data_tgt_son1.size(0), -1)\n                data_tgt_son1 = self.cls_fc_son1(data_tgt_son1)\n                l1_loss = torch.abs(torch.nn.functional.softmax(data_tgt_son1, dim=1) - torch.nn.functional.softmax(data_tgt_son2, dim=1))\n                l1_loss = torch.mean(l1_loss)\n\n                #l1_loss = F.l1_loss(torch.nn.functional.softmax(data_tgt_son1, dim=1), torch.nn.functional.softmax(data_tgt_son2, dim=1))\n\n                pred_src = self.cls_fc_son2(data_src)\n                cls_loss = F.nll_loss(F.log_softmax(pred_src, dim=1), label_src)\n\n                return cls_loss, mmd_loss, l1_loss\n\n        else:\n            data = self.sharedNet(data_src)\n\n            fea_son1 = self.sonnet1(data)\n            fea_son1 = self.avgpool(fea_son1)\n            fea_son1 = fea_son1.view(fea_son1.size(0), -1)\n            pred1 = self.cls_fc_son1(fea_son1)\n\n            fea_son2 = self.sonnet2(data)\n            fea_son2 = self.avgpool(fea_son2)\n            fea_son2 = fea_son2.view(fea_son2.size(0), -1)\n            pred2 = self.cls_fc_son2(fea_son2)\n\n            return pred1, pred2\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n'"
MUDA/MFSAN/MFSAN_3src/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
MUDA/MFSAN/MFSAN_3src/mfsan.py,9,"b'from __future__ import print_function\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport resnet as models\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n# Training settings\nbatch_size = 32\niteration = 15000\nlr = 0.01\nmomentum = 0.9\ncuda = True\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nclass_num = 65\nroot_path = ""./dataset/""\nsource1_name = ""Art""\nsource2_name = \'Clipart\'\nsource3_name = \'Product\'\ntarget_name = ""Real World""\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsource1_loader = data_loader.load_training(root_path, source1_name, batch_size, kwargs)\nsource2_loader = data_loader.load_training(root_path, source2_name, batch_size, kwargs)\nsource3_loader = data_loader.load_training(root_path, source3_name, batch_size, kwargs)\ntarget_train_loader = data_loader.load_training(root_path, target_name, batch_size, kwargs)\ntarget_test_loader = data_loader.load_testing(root_path, target_name, batch_size, kwargs)\n\ndef train(model):\n    source1_iter = iter(source1_loader)\n    source2_iter = iter(source2_loader)\n    source3_iter = iter(source3_loader)\n    target_iter = iter(target_train_loader)\n    correct = 0\n\n    for i in range(1, iteration + 1):\n        model.train()\n        LEARNING_RATE = lr / math.pow((1 + 10 * (i - 1) / (iteration)), 0.75)\n        if (i - 1) % 100 == 0:\n            print(""learning rate\xef\xbc\x9a"", LEARNING_RATE)\n        optimizer = torch.optim.SGD([\n            {\'params\': model.sharedNet.parameters()},\n            {\'params\': model.cls_fc_son1.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.cls_fc_son2.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.cls_fc_son3.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.sonnet1.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.sonnet2.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.sonnet3.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n\n        try:\n            source_data, source_label = source1_iter.next()\n        except Exception as err:\n            source1_iter = iter(source1_loader)\n            source_data, source_label = source1_iter.next()\n        try:\n            target_data, __ = target_iter.next()\n        except Exception as err:\n            target_iter = iter(target_train_loader)\n            target_data, __ = target_iter.next()\n        if cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        target_data = Variable(target_data)\n        optimizer.zero_grad()\n\n        cls_loss, mmd_loss, l1_loss = model(source_data, target_data, source_label, mark=1)\n        gamma = 2 / (1 + math.exp(-10 * (i) / (iteration) )) - 1\n        loss = cls_loss + gamma * (mmd_loss + l1_loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % log_interval == 0:\n            print(\'Train source1 iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\\tl1_Loss: {:.6f}\'.format(\n                i, 100. * i / iteration, loss.item(), cls_loss.item(), mmd_loss.item(), l1_loss.item()))\n\n        try:\n            source_data, source_label = source2_iter.next()\n        except Exception as err:\n            source2_iter = iter(source2_loader)\n            source_data, source_label = source2_iter.next()\n        try:\n            target_data, __ = target_iter.next()\n        except Exception as err:\n            target_iter = iter(target_train_loader)\n            target_data, __ = target_iter.next()\n        if cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        target_data = Variable(target_data)\n        optimizer.zero_grad()\n\n        cls_loss, mmd_loss, l1_loss = model(source_data, target_data, source_label, mark=2)\n        gamma = 2 / (1 + math.exp(-10 * (i) / (iteration))) - 1\n        loss = cls_loss + gamma * (mmd_loss + l1_loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % log_interval == 0:\n            print(\n                \'Train source2 iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\\tl1_Loss: {:.6f}\'.format(\n                    i, 100. * i / iteration, loss.item(), cls_loss.item(), mmd_loss.item(), l1_loss.item()))\n\n\n        try:\n            source_data, source_label = source3_iter.next()\n        except Exception as err:\n            source3_iter = iter(source3_loader)\n            source_data, source_label = source3_iter.next()\n        try:\n            target_data, __ = target_iter.next()\n        except Exception as err:\n            target_iter = iter(target_train_loader)\n            target_data, __ = target_iter.next()\n        if cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        target_data = Variable(target_data)\n        optimizer.zero_grad()\n\n        cls_loss, mmd_loss, l1_loss = model(source_data, target_data, source_label, mark=3)\n        gamma = 2 / (1 + math.exp(-10 * (i) / (iteration))) - 1\n        loss = cls_loss + gamma * (mmd_loss + l1_loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % log_interval == 0:\n            print(\n                \'Train source3 iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\\tl1_Loss: {:.6f}\'.format(\n                    i, 100. * i / iteration, loss.item(), cls_loss.item(), mmd_loss.item(), l1_loss.item()))\n\n        if i % (log_interval * 20) == 0:\n            t_correct = test(model)\n            if t_correct > correct:\n                correct = t_correct\n            print(source1_name, source2_name, source3_name, ""to"", target_name, ""%s max correct:"" % target_name, correct.item(), ""\\n"")\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    correct1 = 0\n    correct2 = 0\n    correct3 = 0\n    with torch.no_grad():\n        for data, target in target_test_loader:\n            if cuda:\n                data, target = data.cuda(), target.cuda()\n            data, target = Variable(data), Variable(target)\n            pred1, pred2, pred3 = model(data)\n\n            pred1 = torch.nn.functional.softmax(pred1, dim=1)\n            pred2 = torch.nn.functional.softmax(pred2, dim=1)\n            pred3 = torch.nn.functional.softmax(pred3, dim=1)\n\n            pred = (pred1 + pred2 + pred3) / 3\n            test_loss += F.nll_loss(F.log_softmax(pred, dim=1), target).item()  # sum up batch loss\n            pred = pred.data.max(1)[1]  # get the index of the max log-probability\n            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n            pred = pred1.data.max(1)[1]  # get the index of the max log-probability\n            correct1 += pred.eq(target.data.view_as(pred)).cpu().sum()\n            pred = pred2.data.max(1)[1]  # get the index of the max log-probability\n            correct2 += pred.eq(target.data.view_as(pred)).cpu().sum()\n            pred = pred3.data.max(1)[1]  # get the index of the max log-probability\n            correct3 += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n        test_loss /= len(target_test_loader.dataset)\n        print(target_name, \'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n            test_loss, correct, len(target_test_loader.dataset),\n            100. * correct / len(target_test_loader.dataset)))\n        print(\'\\nsource1 accnum {}, source2 accnum {}\xef\xbc\x8csource3 accnum {}\'.format(correct1, correct2, correct3))\n    return correct\n\nif __name__ == \'__main__\':\n    model = models.MFSAN(num_classes=class_num)\n    print(model)\n    if cuda:\n        model.cuda()\n    train(model)\n'"
MUDA/MFSAN/MFSAN_3src/mfsan1.py,12,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nimport numpy as np\nimport mmd\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""2""\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=32, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=32, metavar=\'N\',\n                    help=\'input batch size for testing (default: 1000)\')\nparser.add_argument(\'--iter\', type=int, default=15000, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=8, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--l2_decay\', type=float, default=5e-4,\n                    help=\'the L2  weight decay\')\nparser.add_argument(\'--save_path\', type=str, default=""./tmp/origin_"",\n                    help=\'the path to save the model\')\nparser.add_argument(\'--root_path\', type=str, default=""/data/zhuyc/OfficeHome/"",\n                    help=\'the path to load the data\')\nparser.add_argument(\'--source1_dir\', type=str, default=""Art"",#Art  Clipart   Product   Real World\n                    help=\'the name of the source dir\')\nparser.add_argument(\'--source2_dir\', type=str, default=""Clipart"",\n                    help=\'the name of the source dir\')\nparser.add_argument(\'--source3_dir\', type=str, default=""Real World"",\n                    help=\'the name of the source dir\')\nparser.add_argument(\'--test_dir\', type=str, default=""Product"",\n                    help=\'the name of the test dir\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\n#torch.manual_seed(args.seed)\n#if args.cuda:\n#    torch.cuda.manual_seed(args.seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n\nsource1_loader = data_loader.load_training(args.root_path, args.source1_dir, args.batch_size, kwargs)\nsource2_loader = data_loader.load_training(args.root_path, args.source2_dir, args.batch_size, kwargs)\nsource3_loader = data_loader.load_training(args.root_path, args.source3_dir, args.batch_size, kwargs)\ntarget_train_loader = data_loader.load_training(args.root_path, args.test_dir, args.batch_size, kwargs)\ntarget_test_loader = data_loader.load_testing(args.root_path, args.test_dir, args.batch_size, kwargs)\n\ndef load_pretrain(model):\n    url = \'https://download.pytorch.org/models/resnet50-19c8e357.pth\'\n    pretrained_dict = model_zoo.load_url(url)\n    model_dict = model.state_dict()\n    for k, v in model_dict.items():\n        if ""sharedNet"" in k:\n            model_dict[k] = pretrained_dict[k[k.find(""."") + 1:]]\n\n    model.load_state_dict(model_dict)\n    return model\n\ndef train(model):\n    #\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\xe4\xb8\xba\xe5\x89\x8d\xe9\x9d\xa2\xe7\x9a\x8410\xe5\x80\x8d\n    source1_iter = iter(source1_loader)\n    source2_iter = iter(source2_loader)\n    source3_iter = iter(source3_loader)\n    target_iter = iter(target_train_loader)\n    correct = 0\n\n    for i in range(1, args.iter + 1):\n        model.train()\n        LEARNING_RATE = args.lr / math.pow((1 + 10 * (i - 1) / (args.iter)), 0.75)\n        if (i - 1) % 100 == 0:\n            print(""learning rate\xef\xbc\x9a"", LEARNING_RATE)\n        optimizer = torch.optim.SGD([\n            {\'params\': model.sharedNet.parameters()},\n            {\'params\': model.cls_fc_son1.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.cls_fc_son2.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.cls_fc_son3.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.sonnet1.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.sonnet2.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.sonnet3.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=args.momentum, weight_decay=args.l2_decay)\n\n        try:\n            source_data, source_label = source1_iter.next()\n        except Exception as err:\n            source1_iter = iter(source1_loader)\n            source_data, source_label = source1_iter.next()\n        try:\n            target_data, __ = target_iter.next()\n        except Exception as err:\n            target_iter = iter(target_train_loader)\n            target_data, __ = target_iter.next()\n        if args.cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        target_data = Variable(target_data)\n        optimizer.zero_grad()\n\n        cls_loss, mmd_loss, l1_loss = model(source_data, target_data, source_label, source_label, 1)\n        gamma = 2 / (1 + math.exp(-10 * (i) / (args.iter) )) - 1\n        loss = cls_loss + gamma * (mmd_loss)# + l1_loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % args.log_interval == 0:\n            print(\'Train source1 iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\\tl1_Loss: {:.6f}\'.format(\n                i, 100. * i / args.iter, loss.data[0], cls_loss.data[0], mmd_loss.data[0], l1_loss.data[0]))\n\n        #if i % 3 == 2:\n        try:\n            source_data, source_label = source2_iter.next()\n        except Exception as err:\n            source2_iter = iter(source2_loader)\n            source_data, source_label = source2_iter.next()\n        try:\n            target_data, __ = target_iter.next()\n        except Exception as err:\n            target_iter = iter(target_train_loader)\n            target_data, __ = target_iter.next()\n        if args.cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        target_data = Variable(target_data)\n        optimizer.zero_grad()\n\n        cls_loss, mmd_loss, l1_loss = model(source_data, target_data, source_label, source_label, 2)\n        gamma = 2 / (1 + math.exp(-10 * (i) / (args.iter))) - 1\n        loss = cls_loss + gamma * (mmd_loss)# + l1_loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % args.log_interval == 0:\n            print(\n                \'Train source2 iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\\tl1_Loss: {:.6f}\'.format(\n                    i, 100. * i / args.iter, loss.data[0], cls_loss.data[0], mmd_loss.data[0], l1_loss.data[0]))\n\n        #source3\n        try:\n            source_data, source_label = source3_iter.next()\n        except Exception as err:\n            source3_iter = iter(source3_loader)\n            source_data, source_label = source3_iter.next()\n        try:\n            target_data, __ = target_iter.next()\n        except Exception as err:\n            target_iter = iter(target_train_loader)\n            target_data, __ = target_iter.next()\n        if args.cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        target_data = Variable(target_data)\n        optimizer.zero_grad()\n\n        cls_loss, mmd_loss, l1_loss = model(source_data, target_data, source_label, source_label, 3)\n        gamma = 2 / (1 + math.exp(-10 * (i) / (args.iter) )) - 1\n        loss = cls_loss + gamma * (mmd_loss)# + l1_loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % args.log_interval == 0:\n            print(\'Train source3 iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\\tl1_Loss: {:.6f}\'.format(\n                i, 100. * i / args.iter, loss.data[0], cls_loss.data[0], mmd_loss.data[0], l1_loss.data[0]))\n\n        if i == args.iter:\n            print(""aaaaaa"")\n        if i % (args.log_interval * 20) == 0:\n            t_correct = test(model)\n            if t_correct > correct:\n                correct = t_correct\n            print(args.source1_dir, args.source2_dir, ""to"", args.test_dir, ""%s max correct:"" % args.test_dir, correct, ""\\n"")\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    correct1 = 0\n    correct2 = 0\n    correct3 = 0\n\n    for data, target in target_test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        pred1, pred2, pred3 = model(data)\n\n        #print(weight)\n        test_loss += F.nll_loss(F.log_softmax(pred1, dim = 1), target, size_average=False).data[0] # sum up batch loss\n        pred1 = torch.nn.functional.softmax(pred1, dim=1)\n        pred2 = torch.nn.functional.softmax(pred2, dim=1)\n        pred3 = torch.nn.functional.softmax(pred3, dim=1)\n\n        pred = (pred1 + pred2 + pred3) / 3\n        pred = pred.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        pred = pred1.data.max(1)[1]  # get the index of the max log-probability\n        correct1 += pred.eq(target.data.view_as(pred)).cpu().sum()\n        pred = pred2.data.max(1)[1]  # get the index of the max log-probability\n        correct2 += pred.eq(target.data.view_as(pred)).cpu().sum()\n        pred = pred3.data.max(1)[1]  # get the index of the max log-probability\n        correct3 += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(target_test_loader.dataset)\n    print(args.test_dir, \'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(target_test_loader.dataset),\n        100. * correct / len(target_test_loader.dataset)))\n    print(correct1, correct2, correct3)\n    return correct\n\nif __name__ == \'__main__\':\n    model = models.DANNet(num_classes=65)\n    print(model)\n    if args.cuda:\n        model.cuda()\n    #model = load_pretrain(model)\n    train(model)\n    #test(model)\n'"
MUDA/MFSAN/MFSAN_3src/mmd.py,5,"b'#!/usr/bin/env python\n# encoding: utf-8\n\nimport torch\nfrom torch.autograd import Variable\n\ndef guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    n_samples = int(source.size()[0])+int(target.size()[0])\n    total = torch.cat([source, target], dim=0)\n    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    L2_distance = ((total0-total1)**2).sum(2)\n    if fix_sigma:\n        bandwidth = fix_sigma\n    else:\n        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n    bandwidth /= kernel_mul ** (kernel_num // 2)\n    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n    return sum(kernel_val)#/len(kernel_val)\n\ndef mmd(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    XX = kernels[:batch_size, :batch_size]\n    YY = kernels[batch_size:, batch_size:]\n    XY = kernels[:batch_size, batch_size:]\n    YX = kernels[batch_size:, :batch_size]\n    loss = torch.mean(XX + YY - XY -YX)\n    return loss'"
MUDA/MFSAN/MFSAN_3src/resnet.py,16,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport mmd\nimport torch.nn.functional as F\nimport torch\n\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ADDneck(nn.Module):\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(ADDneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.stride = stride\n\n    def forward(self, x):\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.baselayer = [self.conv1, self.bn1, self.layer1, self.layer2, self.layer3, self.layer4]\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        return x\n\nclass MFSAN(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(MFSAN, self).__init__()\n        self.sharedNet = resnet50(True)\n        self.sonnet1 = ADDneck(2048, 256)\n        self.sonnet2 = ADDneck(2048, 256)\n        self.sonnet3 = ADDneck(2048, 256)\n        self.cls_fc_son1 = nn.Linear(256, num_classes)\n        self.cls_fc_son2 = nn.Linear(256, num_classes)\n        self.cls_fc_son3 = nn.Linear(256, num_classes)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n\n    def forward(self, data_src, data_tgt = 0, label_src = 0, mark = 1):\n        mmd_loss = 0\n        if self.training == True:\n            data_src = self.sharedNet(data_src)\n            data_tgt = self.sharedNet(data_tgt)\n\n            data_tgt_son1 = self.sonnet1(data_tgt)\n            data_tgt_son1 = self.avgpool(data_tgt_son1)\n            data_tgt_son1 = data_tgt_son1.view(data_tgt_son1.size(0), -1)\n            pred_tgt_son1 = self.cls_fc_son1(data_tgt_son1)\n\n            data_tgt_son2 = self.sonnet2(data_tgt)\n            data_tgt_son2 = self.avgpool(data_tgt_son2)\n            data_tgt_son2 = data_tgt_son2.view(data_tgt_son2.size(0), -1)\n            pred_tgt_son2 = self.cls_fc_son2(data_tgt_son2)\n\n            data_tgt_son3 = self.sonnet3(data_tgt)\n            data_tgt_son3 = self.avgpool(data_tgt_son3)\n            data_tgt_son3 = data_tgt_son3.view(data_tgt_son3.size(0), -1)\n            pred_tgt_son3 = self.cls_fc_son3(data_tgt_son3)\n\n            if mark == 1:\n\n                data_src = self.sonnet1(data_src)\n                data_src = self.avgpool(data_src)\n                data_src = data_src.view(data_src.size(0), -1)\n                mmd_loss += mmd.mmd(data_src, data_tgt_son1)\n\n                l1_loss = torch.mean( torch.abs(torch.nn.functional.softmax(data_tgt_son1, dim=1)\n                                                - torch.nn.functional.softmax(data_tgt_son2, dim=1)) )\n                l1_loss += torch.mean( torch.abs(torch.nn.functional.softmax(data_tgt_son1, dim=1)\n                                                - torch.nn.functional.softmax(data_tgt_son3, dim=1)) )\n                pred_src = self.cls_fc_son1(data_src)\n\n                cls_loss = F.nll_loss(F.log_softmax(pred_src, dim=1), label_src)\n\n                return cls_loss, mmd_loss, l1_loss / 2\n\n            if mark == 2:\n\n                data_src = self.sonnet2(data_src)\n                data_src = self.avgpool(data_src)\n                data_src = data_src.view(data_src.size(0), -1)\n                mmd_loss += mmd.mmd(data_src, data_tgt_son2)\n\n                l1_loss = torch.mean( torch.abs(torch.nn.functional.softmax(data_tgt_son2, dim=1)\n                                                - torch.nn.functional.softmax(data_tgt_son1, dim=1)) )\n                l1_loss += torch.mean( torch.abs(torch.nn.functional.softmax(data_tgt_son2, dim=1)\n                                                - torch.nn.functional.softmax(data_tgt_son3, dim=1)) )\n                pred_src = self.cls_fc_son2(data_src)\n\n                cls_loss = F.nll_loss(F.log_softmax(pred_src, dim=1), label_src)\n\n                return cls_loss, mmd_loss, l1_loss / 2\n\n            if mark == 3:\n\n                data_src = self.sonnet3(data_src)\n                data_src = self.avgpool(data_src)\n                data_src = data_src.view(data_src.size(0), -1)\n                mmd_loss += mmd.mmd(data_src, data_tgt_son3)\n\n                l1_loss = torch.mean( torch.abs(torch.nn.functional.softmax(data_tgt_son3, dim=1)\n                                                - torch.nn.functional.softmax(data_tgt_son1, dim=1)) )\n                l1_loss += torch.mean( torch.abs(torch.nn.functional.softmax(data_tgt_son3, dim=1)\n                                                - torch.nn.functional.softmax(data_tgt_son2, dim=1)) )\n                pred_src = self.cls_fc_son3(data_src)\n\n                cls_loss = F.nll_loss(F.log_softmax(pred_src, dim=1), label_src)\n\n                return cls_loss, mmd_loss, l1_loss / 2\n\n        else:\n            data = self.sharedNet(data_src)\n\n            fea_son1 = self.sonnet1(data)\n            fea_son1 = self.avgpool(fea_son1)\n            fea_son1 = fea_son1.view(fea_son1.size(0), -1)\n            pred1 = self.cls_fc_son1(fea_son1)\n\n            fea_son2 = self.sonnet2(data)\n            fea_son2 = self.avgpool(fea_son2)\n            fea_son2 = fea_son2.view(fea_son2.size(0), -1)\n            pred2 = self.cls_fc_son2(fea_son2)\n\n            fea_son3 = self.sonnet3(data)\n            fea_son3 = self.avgpool(fea_son3)\n            fea_son3 = fea_son3.view(fea_son3.size(0), -1)\n            pred3 = self.cls_fc_son3(fea_son3)\n\n            return pred1, pred2, pred3\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n'"
UDA/pytorch0.3/DAN/DAN.py,9,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""1""\n\n# Training settings\nbatch_size = 32\nepochs = 200\nlr = 0.01\nmomentum = 0.9\nno_cuda =False\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nroot_path = ""./dataset/""\nsource_name = ""amazon""\ntarget_name = ""webcam""\n\ncuda = not no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsource_loader = data_loader.load_training(root_path, source_name, batch_size, kwargs)\ntarget_train_loader = data_loader.load_training(root_path, target_name, batch_size, kwargs)\ntarget_test_loader = data_loader.load_testing(root_path, target_name, batch_size, kwargs)\n\nlen_source_dataset = len(source_loader.dataset)\nlen_target_dataset = len(target_test_loader.dataset)\nlen_source_loader = len(source_loader)\nlen_target_loader = len(target_train_loader)\n\ndef load_pretrain(model):\n    url = \'https://download.pytorch.org/models/resnet50-19c8e357.pth\'\n    pretrained_dict = model_zoo.load_url(url)\n    model_dict = model.state_dict()\n    for k, v in model_dict.items():\n        if not ""cls_fc"" in k:\n            model_dict[k] = pretrained_dict[k[k.find(""."") + 1:]]\n    model.load_state_dict(model_dict)\n    return model\n\ndef train(epoch, model):\n    LEARNING_RATE = lr / math.pow((1 + 10 * (epoch - 1) / epochs), 0.75)\n    print(\'learning rate{: .4f}\'.format(LEARNING_RATE) )\n    optimizer = torch.optim.SGD([\n        {\'params\': model.sharedNet.parameters()},\n        {\'params\': model.cls_fc.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n\n    model.train()\n\n    iter_source = iter(source_loader)\n    iter_target = iter(target_train_loader)\n    num_iter = len_source_loader\n    for i in range(1, num_iter):\n        data_source, label_source = iter_source.next()\n        data_target, _ = iter_target.next()\n        if i % len_target_loader == 0:\n            iter_target = iter(target_train_loader)\n        if cuda:\n            data_source, label_source = data_source.cuda(), label_source.cuda()\n            data_target = data_target.cuda()\n        data_source, label_source = Variable(data_source), Variable(label_source)\n        data_target = Variable(data_target)\n\n        optimizer.zero_grad()\n        label_source_pred, loss_mmd = model(data_source, data_target)\n        loss_cls = F.nll_loss(F.log_softmax(label_source_pred, dim=1), label_source)\n        lambd = 2 / (1 + math.exp(-10 * (epoch) / epochs)) - 1\n        loss = loss_cls + lambd * loss_mmd\n        loss.backward()\n        optimizer.step()\n        if i % log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\'.format(\n                epoch, i * len(data_source), len_source_dataset,\n                100. * i / len_source_loader, loss.data[0], loss_cls.data[0], loss_mmd.data[0]))\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    for data, target in target_test_loader:\n        if cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        s_output, t_output = model(data, data)\n        test_loss += F.nll_loss(F.log_softmax(s_output, dim = 1), target, size_average=False).data[0] # sum up batch loss\n        pred = s_output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len_target_dataset\n    print(\'\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        target_name, test_loss, correct, len_target_dataset,\n        100. * correct / len_target_dataset))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.DANNet(num_classes=31)\n    correct = 0\n    print(model)\n    if cuda:\n        model.cuda()\n    model = load_pretrain(model)\n    for epoch in range(1, epochs + 1):\n        train(epoch, model)\n        t_correct = test(model)\n        if t_correct > correct:\n            correct = t_correct\n        print(\'source: {} to target: {} max correct: {} max accuracy{: .2f}%\\n\'.format(\n              source_name, target_name, correct, 100. * correct / len_target_dataset ))'"
UDA/pytorch0.3/DAN/ResNet.py,3,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport mmd\nimport torch\n\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.baselayer = [self.conv1, self.bn1, self.layer1, self.layer2, self.layer3, self.layer4]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n\n        return x\n\nclass DANNet(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(DANNet, self).__init__()\n        self.sharedNet = resnet50(False)\n        self.cls_fc = nn.Linear(2048, num_classes)\n\n    def forward(self, source, target):\n        loss = 0\n        source = self.sharedNet(source)\n        if self.training == True:\n            target = self.sharedNet(target)\n            #loss += mmd.mmd_rbf_accelerate(source, target)\n            loss += mmd.mmd_rbf_noaccelerate(source, target)\n\n        source = self.cls_fc(source)\n        #target = self.cls_fc(target)\n\n        return source, loss\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model'"
UDA/pytorch0.3/DAN/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
UDA/pytorch0.3/DAN/mmd.py,4,"b'#!/usr/bin/env python\n# encoding: utf-8\n\nimport torch\n\ndef guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    n_samples = int(source.size()[0])+int(target.size()[0])\n    total = torch.cat([source, target], dim=0)\n    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    L2_distance = ((total0-total1)**2).sum(2)\n    if fix_sigma:\n        bandwidth = fix_sigma\n    else:\n        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n    bandwidth /= kernel_mul ** (kernel_num // 2)\n    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n    return sum(kernel_val)#/len(kernel_val)\n\n\ndef mmd_rbf_accelerate(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n        kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    loss = 0\n    for i in range(batch_size):\n        s1, s2 = i, (i+1)%batch_size\n        t1, t2 = s1+batch_size, s2+batch_size\n        loss += kernels[s1, s2] + kernels[t1, t2]\n        loss -= kernels[s1, t2] + kernels[s2, t1]\n    return loss / float(batch_size)\n\ndef mmd_rbf_noaccelerate(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    XX = kernels[:batch_size, :batch_size]\n    YY = kernels[batch_size:, batch_size:]\n    XY = kernels[:batch_size, batch_size:]\n    YX = kernels[batch_size:, :batch_size]\n    loss = torch.mean(XX + YY - XY -YX)\n    return loss\n\n'"
UDA/pytorch0.3/DDC/DDC.py,9,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""1""\n\n# Training settings\nbatch_size = 32\nepochs = 200\nlr = 0.01\nmomentum = 0.9\nno_cuda =False\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nroot_path = ""./dataset/""\nsource_name = ""amazon""\ntarget_name = ""webcam""\n\ncuda = not no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsource_loader = data_loader.load_training(root_path, source_name, batch_size, kwargs)\ntarget_train_loader = data_loader.load_training(root_path, target_name, batch_size, kwargs)\ntarget_test_loader = data_loader.load_testing(root_path, target_name, batch_size, kwargs)\n\nlen_source_dataset = len(source_loader.dataset)\nlen_target_dataset = len(target_test_loader.dataset)\nlen_source_loader = len(source_loader)\nlen_target_loader = len(target_train_loader)\n\ndef load_pretrain(model):\n    url = \'https://download.pytorch.org/models/resnet50-19c8e357.pth\'\n    pretrained_dict = model_zoo.load_url(url)\n    model_dict = model.state_dict()\n    for k, v in model_dict.items():\n        if not ""cls_fc"" in k:\n            model_dict[k] = pretrained_dict[k[k.find(""."") + 1:]]\n    model.load_state_dict(model_dict)\n    return model\n\ndef train(epoch, model):\n    LEARNING_RATE = lr / math.pow((1 + 10 * (epoch - 1) / epochs), 0.75)\n    print(\'learning rate{: .4f}\'.format(LEARNING_RATE) )\n    optimizer = torch.optim.SGD([\n        {\'params\': model.sharedNet.parameters()},\n        {\'params\': model.cls_fc.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n\n    model.train()\n\n    iter_source = iter(source_loader)\n    iter_target = iter(target_train_loader)\n    num_iter = len_source_loader\n    for i in range(1, num_iter):\n        data_source, label_source = iter_source.next()\n        data_target, _ = iter_target.next()\n        if i % len_target_loader == 0:\n            iter_target = iter(target_train_loader)\n        if cuda:\n            data_source, label_source = data_source.cuda(), label_source.cuda()\n            data_target = data_target.cuda()\n        data_source, label_source = Variable(data_source), Variable(label_source)\n        data_target = Variable(data_target)\n\n        optimizer.zero_grad()\n        label_source_pred, loss_mmd = model(data_source, data_target)\n        loss_cls = F.nll_loss(F.log_softmax(label_source_pred, dim=1), label_source)\n        lambd = 2 / (1 + math.exp(-10 * (epoch) / epochs)) - 1\n        loss = loss_cls + lambd * loss_mmd\n        loss.backward()\n        optimizer.step()\n        if i % log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\'.format(\n                epoch, i * len(data_source), len_source_dataset,\n                100. * i / len_source_loader, loss.data[0], loss_cls.data[0], loss_mmd.data[0]))\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    for data, target in target_test_loader:\n        if cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        s_output, t_output = model(data, data)\n        test_loss += F.nll_loss(F.log_softmax(s_output, dim = 1), target, size_average=False).data[0] # sum up batch loss\n        pred = s_output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len_target_dataset\n    print(\'\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        target_name, test_loss, correct, len_target_dataset,\n        100. * correct / len_target_dataset))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.DDCNet(num_classes=31)\n    correct = 0\n    print(model)\n    if cuda:\n        model.cuda()\n    model = load_pretrain(model)\n    for epoch in range(1, epochs + 1):\n        train(epoch, model)\n        t_correct = test(model)\n        if t_correct > correct:\n            correct = t_correct\n        print(\'source: {} to target: {} max correct: {} max accuracy{: .2f}%\\n\'.format(\n              source_name, target_name, correct, 100. * correct / len_target_dataset ))'"
UDA/pytorch0.3/DDC/ResNet.py,3,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport mmd\nimport torch\n\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.baselayer = [self.conv1, self.bn1, self.layer1, self.layer2, self.layer3, self.layer4]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n\n        return x\n\nclass DDCNet(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(DDCNet, self).__init__()\n        self.sharedNet = resnet50(False)\n        self.cls_fc = nn.Linear(2048, num_classes)\n\n    def forward(self, source, target):\n        source = self.sharedNet(source)\n        loss = 0\n\n        if self.training == True:\n            target = self.sharedNet(target)\n            loss = mmd.mmd_linear(source, target)\n\n        source = self.cls_fc(source)\n        return source, loss\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model'"
UDA/pytorch0.3/DDC/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, **kwargs)\n    return test_loader'"
UDA/pytorch0.3/DDC/mmd.py,1,"b'#!/usr/bin/env python\n# encoding: utf-8\n\nimport torch\n\ndef mmd_linear(f_of_X, f_of_Y):\n    delta = f_of_X - f_of_Y\n    loss = torch.mean(torch.mm(delta, torch.transpose(delta, 0, 1)))\n    return loss\n'"
UDA/pytorch0.3/DeepCoral/Coral.py,5,"b'import torch\n\ndef CORAL(source, target):\n    d = source.data.shape[1]\n\n    # source covariance\n    xm = torch.mean(source, 1, keepdim=True) - source\n    xc = torch.matmul(torch.transpose(xm, 0, 1), xm)\n\n    # target covariance\n    xmt = torch.mean(target, 1, keepdim=True) - target\n    xct = torch.matmul(torch.transpose(xmt, 0, 1), xmt)\n    # frobenius norm between source and target\n    loss = torch.mean(torch.mul((xc - xct), (xc - xct)))\n    loss = loss/(4*d*4)\n    return loss'"
UDA/pytorch0.3/DeepCoral/DeepCoral.py,8,"b'from __future__ import print_function\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n# Training settings\nbatch_size = 32\nepochs = 200\nlr = 0.01\nmomentum = 0.9\nno_cuda =False\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nroot_path = ""./dataset/""\nsource_name = ""amazon""\ntarget_name = ""webcam""\n\ncuda = not no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsource_loader = data_loader.load_training(root_path, source_name, batch_size, kwargs)\ntarget_train_loader = data_loader.load_training(root_path, target_name, batch_size, kwargs)\ntarget_test_loader = data_loader.load_testing(root_path, target_name, batch_size, kwargs)\n\nlen_source_dataset = len(source_loader.dataset)\nlen_target_dataset = len(target_test_loader.dataset)\nlen_source_loader = len(source_loader)\nlen_target_loader = len(target_train_loader)\n\ndef load_pretrain(model):\n    url = \'https://download.pytorch.org/models/resnet50-19c8e357.pth\'\n    pretrained_dict = model_zoo.load_url(url)\n    model_dict = model.state_dict()\n    for k, v in model_dict.items():\n        if not ""cls_fc"" in k:\n            model_dict[k] = pretrained_dict[k[k.find(""."") + 1:]]\n    model.load_state_dict(model_dict)\n    return model\n\ndef train(epoch, model):\n    LEARNING_RATE = lr / math.pow((1 + 10 * (epoch - 1) / epochs), 0.75)\n    print(\'learning rate{: .4f}\'.format(LEARNING_RATE) )\n    optimizer = torch.optim.SGD([\n        {\'params\': model.sharedNet.parameters()},\n        {\'params\': model.cls_fc.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n\n    model.train()\n\n    iter_source = iter(source_loader)\n    iter_target = iter(target_train_loader)\n    num_iter = len_source_loader\n    for i in range(1, num_iter):\n        data_source, label_source = iter_source.next()\n        data_target, _ = iter_target.next()\n        if i % len_target_loader == 0:\n            iter_target = iter(target_train_loader)\n        if cuda:\n            data_source, label_source = data_source.cuda(), label_source.cuda()\n            data_target = data_target.cuda()\n        data_source, label_source = Variable(data_source), Variable(label_source)\n        data_target = Variable(data_target)\n\n        optimizer.zero_grad()\n        label_source_pred, loss_coral = model(data_source, data_target)\n        loss_cls = F.nll_loss(F.log_softmax(label_source_pred, dim=1), label_source)\n        lambd = 2 / (1 + math.exp(-10 * (epoch) / epochs)) - 1\n        loss = loss_cls + lambd * loss_coral\n        loss.backward()\n        optimizer.step()\n        if i % log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\ttotal_Loss: {:.6f}\\tcls_Loss: {:.6f}\\tcoral_Loss: {:.6f}\'.format(\n                epoch, i * len(data_source), len_source_dataset,\n                100. * i / len_source_loader, loss.data[0], loss_cls.data[0], loss_coral.data[0]))\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    for data, target in target_test_loader:\n        if cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        s_output, t_output = model(data, data)\n        test_loss += F.nll_loss(F.log_softmax(s_output, dim = 1), target, size_average=False).data[0] # sum up batch loss\n        pred = s_output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len_target_dataset\n    print(\'\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        target_name, test_loss, correct, len_target_dataset,\n        100. * correct / len_target_dataset))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.DeepCoral(num_classes=31)\n    correct = 0\n    print(model)\n    if cuda:\n        model.cuda()\n    model = load_pretrain(model)\n    for epoch in range(1, epochs + 1):\n        train(epoch, model)\n        t_correct = test(model)\n        if t_correct > correct:\n            correct = t_correct\n        print(\'source: {} to target: {} max correct: {} max accuracy{: .2f}%\\n\'.format(\n              source_name, target_name, correct, 100. * correct / len_target_dataset ))'"
UDA/pytorch0.3/DeepCoral/ResNet.py,3,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom Coral import CORAL\n\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.baselayer = [self.conv1, self.bn1, self.layer1, self.layer2, self.layer3, self.layer4]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n\n        return x\n\nclass DeepCoral(nn.Module):\n    def __init__(self, num_classes=31):\n        super(DeepCoral, self).__init__()\n        self.sharedNet = resnet50(False)\n        self.cls_fc = nn.Linear(2048, num_classes)\n\n    def forward(self, source, target):\n        loss = 0\n        source = self.sharedNet(source)\n\n        if self.training == True:\n            target = self.sharedNet(target)\n            loss += CORAL(source, target)\n        source = self.cls_fc(source)\n\n        return source, loss\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model'"
UDA/pytorch0.3/DeepCoral/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
UDA/pytorch0.3/RevGrad/ResNet.py,4,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torch\nfrom torch.autograd import Function\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.baselayer = [self.conv1, self.bn1, self.layer1, self.layer2, self.layer3, self.layer4]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n\n        return x\n\nclass RevGrad(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(RevGrad, self).__init__()\n        self.sharedNet = resnet50(False)\n        self.cls_fc = nn.Linear(2048, num_classes)\n        self.domain_fc = nn.Linear(2048, 2)\n\n    def forward(self, data):\n        data = self.sharedNet(data)\n        clabel_pred = self.cls_fc(data)\n        dlabel_pred = self.domain_fc(data)\n\n        return clabel_pred, dlabel_pred\n\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model'"
UDA/pytorch0.3/RevGrad/RevGrad.py,12,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""1""\n\n# Training settings\nbatch_size = 32\nepochs = 200\nlr = 0.01\nmomentum = 0.9\nno_cuda =False\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nroot_path = ""./dataset/""\nsource_name = ""amazon""\ntarget_name = ""webcam""\n\ncuda = not no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsource_loader = data_loader.load_training(root_path, source_name, batch_size, kwargs)\ntarget_train_loader = data_loader.load_training(root_path, target_name, batch_size, kwargs)\ntarget_test_loader = data_loader.load_testing(root_path, target_name, batch_size, kwargs)\n\nlen_source_dataset = len(source_loader.dataset)\nlen_target_dataset = len(target_test_loader.dataset)\nlen_source_loader = len(source_loader)\nlen_target_loader = len(target_train_loader)\n\ndef load_pretrain(model):\n    url = \'https://download.pytorch.org/models/resnet50-19c8e357.pth\'\n    pretrained_dict = model_zoo.load_url(url)\n    model_dict = model.state_dict()\n    for k, v in model_dict.items():\n        if not ""cls_fc"" in k and not ""domain_fc"" in k:\n            model_dict[k] = pretrained_dict[k[k.find(""."") + 1:]]\n    model.load_state_dict(model_dict)\n    return model\n\ndef train(epoch, model):\n    #\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\xe4\xb8\xba\xe5\x89\x8d\xe9\x9d\xa2\xe7\x9a\x8410\xe5\x80\x8d\n    LEARNING_RATE = lr / math.pow((1 + 10 * (epoch - 1) / epochs), 0.75)\n    print(""learning rate: "", LEARNING_RATE)\n    optimizer_fea = torch.optim.SGD([\n        {\'params\': model.sharedNet.parameters()},\n        {\'params\': model.cls_fc.parameters(), \'lr\': LEARNING_RATE},\n    ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n    optimizer_critic = torch.optim.SGD([\n        {\'params\': model.domain_fc.parameters(), \'lr\': LEARNING_RATE}\n    ], lr=LEARNING_RATE, momentum=momentum, weight_decay=l2_decay)\n\n    data_source_iter = iter(source_loader)\n    data_target_iter = iter(target_train_loader)\n    dlabel_src = Variable(torch.ones(batch_size).long().cuda())\n    dlabel_tgt = Variable(torch.zeros(batch_size).long().cuda())\n    i = 1\n    while i <= len_source_loader:\n        model.train()\n\n        source_data, source_label = data_source_iter.next()\n        if cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n        source_data, source_label = Variable(source_data), Variable(source_label)\n        clabel_src, dlabel_pred_src = model(source_data)\n        label_loss = F.nll_loss(F.log_softmax(clabel_src, dim=1), source_label)\n        critic_loss_src = F.nll_loss(F.log_softmax(dlabel_pred_src, dim=1), dlabel_src)\n        confusion_loss_src = 0.5 * ( F.nll_loss(F.log_softmax(dlabel_pred_src, dim=1), dlabel_src) + F.nll_loss(F.log_softmax(dlabel_pred_src, dim=1), dlabel_tgt) )\n\n        target_data, target_label = data_target_iter.next()\n        if i % len_target_loader == 0:\n            data_target_iter = iter(target_train_loader)\n        if cuda:\n            target_data, target_label = target_data.cuda(), target_label.cuda()\n        target_data = Variable(target_data)\n        clabel_tgt, dlabel_pred_tgt = model(target_data)\n        critic_loss_tgt = F.nll_loss(F.log_softmax(dlabel_pred_tgt, dim=1), dlabel_tgt)\n        confusion_loss_tgt = 0.5 * (F.nll_loss(F.log_softmax(dlabel_pred_tgt, dim=1), dlabel_src) + F.nll_loss(\n            F.log_softmax(dlabel_pred_tgt, dim=1), dlabel_tgt))\n\n        confusion_loss_total = (confusion_loss_src + confusion_loss_tgt) / 2\n        fea_loss_total = confusion_loss_total + label_loss\n        critic_loss_total = (critic_loss_src + critic_loss_tgt) / 2\n\n        optimizer_fea.zero_grad()\n        fea_loss_total.backward(retain_graph=True)\n        optimizer_fea.step()\n        optimizer_fea.zero_grad()\n        optimizer_critic.zero_grad()\n        critic_loss_total.backward()\n        optimizer_critic.step()\n\n        if i % log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tconfusion_Loss: {:.6f}\\tlabel_Loss: {:.6f}\\tdomain_Loss: {:.6f}\'.format(\n                epoch, i * len(source_data),len_source_dataset,\n                100. * i / len_source_loader, confusion_loss_total.data[0], label_loss.data[0], critic_loss_total.data[0]))\n        i = i + 1\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    for data, target in target_test_loader:\n        if cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        s_output, t_output = model(data)\n        test_loss += F.nll_loss(F.log_softmax(s_output, dim = 1), target, size_average=False).data[0] # sum up batch loss\n        pred = s_output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len_target_dataset\n    print(\'\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        target_name, test_loss, correct, len_target_dataset,\n        100. * correct / len_target_dataset))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.RevGrad(num_classes=31)\n    correct = 0\n    print(model)\n    if cuda:\n        model.cuda()\n    model = load_pretrain(model)\n    for epoch in range(1, epochs + 1):\n        train(epoch, model)\n        t_correct = test(model)\n        if t_correct > correct:\n            correct = t_correct\n        print(\'source: {} to target: {} max correct: {} max accuracy{: .2f}%\\n\'.format(\n              source_name, target_name, correct, 100. * correct / len_target_dataset ))'"
UDA/pytorch0.3/RevGrad/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
UDA/pytorch1.0/DAN/DAN.py,9,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n# Training settings\nbatch_size = 32\niteration=10000\nlr = 0.01\nmomentum = 0.9\nno_cuda =False\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nroot_path = ""/data/zhuyc/OFFICE31/""\nsrc_name = ""amazon""\ntgt_name = ""dslr""\n\ncuda = not no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsrc_loader = data_loader.load_training(root_path, src_name, batch_size, kwargs)\ntgt_train_loader = data_loader.load_training(root_path, tgt_name, batch_size, kwargs)\ntgt_test_loader = data_loader.load_testing(root_path, tgt_name, batch_size, kwargs)\n\nsrc_dataset_len = len(src_loader.dataset)\ntgt_dataset_len = len(tgt_test_loader.dataset)\nsrc_loader_len = len(src_loader)\ntgt_loader_len = len(tgt_train_loader)\n\n\ndef train(model):\n    src_iter = iter(src_loader)\n    tgt_iter = iter(tgt_train_loader)\n    correct = 0\n    for i in range(1, iteration+1):\n        model.train()\n        LEARNING_RATE = lr / math.pow((1 + 10 * (i - 1) / (iteration)), 0.75)\n        if (i-1)%100==0:\n            print(\'learning rate{: .4f}\'.format(LEARNING_RATE) )\n        optimizer = torch.optim.SGD([\n        {\'params\': model.sharedNet.parameters()},\n        {\'params\': model.cls_fc.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n        try:\n            src_data, src_label = src_iter.next()\n        except Exception as err:\n            src_iter=iter(src_loader)\n            src_data, src_label = src_iter.next()\n            \n        try:\n            tgt_data, _ = tgt_iter.next()\n        except Exception as err:\n            tgt_iter=iter(tgt_train_loader)\n            tgt_data, _ = tgt_iter.next()\n            \n        if cuda:\n            src_data, src_label = src_data.cuda(), src_label.cuda()\n            tgt_data = tgt_data.cuda()\n\n        optimizer.zero_grad()\n        src_pred, mmd_loss = model(src_data, tgt_data)\n        cls_loss = F.nll_loss(F.log_softmax(src_pred, dim=1), src_label)\n        lambd = 2 / (1 + math.exp(-10 * (i) / iteration)) - 1\n        loss = cls_loss + lambd * mmd_loss\n        loss.backward()\n        optimizer.step()\n        if i % log_interval == 0:\n            print(\'Train iter: {} [({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\'.format(\n                i, 100. * i / iteration, loss.item(), cls_loss.item(), mmd_loss.item()))\n\n        if i%(log_interval*20)==0:\n            t_correct = test(model)\n            if t_correct > correct:\n                correct = t_correct\n            print(\'src: {} to tgt: {} max correct: {} max accuracy{: .2f}%\\n\'.format(\n              src_name, tgt_name, correct, 100. * correct / tgt_dataset_len ))\n        \ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    with torch.no_grad():\n        for tgt_test_data, tgt_test_label in tgt_test_loader:\n            if cuda:\n                tgt_test_data, tgt_test_label = tgt_test_data.cuda(), tgt_test_label.cuda()\n            tgt_test_data, tgt_test_label = Variable(tgt_test_data), Variable(tgt_test_label)\n            tgt_pred, mmd_loss = model(tgt_test_data, tgt_test_data)\n            test_loss += F.nll_loss(F.log_softmax(tgt_pred, dim = 1), tgt_test_label, reduction=\'sum\').item() # sum up batch loss\n            pred = tgt_pred.data.max(1)[1] # get the index of the max log-probability\n            correct += pred.eq(tgt_test_label.data.view_as(pred)).cpu().sum()\n\n    test_loss /= tgt_dataset_len\n    print(\'\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        tgt_name, test_loss, correct, tgt_dataset_len,\n        100. * correct / tgt_dataset_len))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.DANNet(num_classes=31)\n    print(model)\n    if cuda:\n        model.cuda()\n    train(model)\n    \n'"
UDA/pytorch1.0/DAN/ResNet.py,3,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport mmd\nimport torch\n\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1,groups=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    """"""1x1 convolution""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, norm_layer=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000,zero_init_residual=False,\n                 groups=1, width_per_group=64, norm_layer=None):\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n\n        self.inplanes = 64\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, norm_layer=norm_layer)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, norm_layer=norm_layer)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\'fan_out\', nonlinearity=\'relu\')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1,norm_layer=None):\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n                            self.base_width, norm_layer))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups=self.groups,\n                                base_width=self.base_width, norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        #x=self.fc(x)\n\n        return x\n\nclass DANNet(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(DANNet, self).__init__()\n        self.sharedNet = resnet50(True)\n        self.cls_fc = nn.Linear(2048, num_classes)\n\n    def forward(self, source, target):\n        loss = 0\n        source = self.sharedNet(source)\n        if self.training == True:\n            target = self.sharedNet(target)\n            #loss += mmd.mmd_rbf_accelerate(source, target)\n            loss += mmd.mmd_rbf_noaccelerate(source, target)\n\n        source = self.cls_fc(source)\n        #target = self.cls_fc(target)\n\n        return source, loss\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n'"
UDA/pytorch1.0/DAN/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
UDA/pytorch1.0/DAN/mmd.py,4,"b'#!/usr/bin/env python\n# encoding: utf-8\n\nimport torch\n\ndef guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    n_samples = int(source.size()[0])+int(target.size()[0])\n    total = torch.cat([source, target], dim=0)\n    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    L2_distance = ((total0-total1)**2).sum(2)\n    if fix_sigma:\n        bandwidth = fix_sigma\n    else:\n        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n    bandwidth /= kernel_mul ** (kernel_num // 2)\n    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n    return sum(kernel_val)#/len(kernel_val)\n\n\ndef mmd_rbf_accelerate(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n        kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    loss = 0\n    for i in range(batch_size):\n        s1, s2 = i, (i+1)%batch_size\n        t1, t2 = s1+batch_size, s2+batch_size\n        loss += kernels[s1, s2] + kernels[t1, t2]\n        loss -= kernels[s1, t2] + kernels[s2, t1]\n    return loss / float(batch_size)\n\ndef mmd_rbf_noaccelerate(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    XX = kernels[:batch_size, :batch_size]\n    YY = kernels[batch_size:, batch_size:]\n    XY = kernels[:batch_size, batch_size:]\n    YX = kernels[batch_size:, :batch_size]\n    loss = torch.mean(XX + YY - XY -YX)\n    return loss\n\n'"
UDA/pytorch1.0/DSAN/Config.py,0,"b'batch_size = 32\nepochs = 200\nlr = 0.01\nmomentum = 0.9\nno_cuda =False\ncuda_id = \'0\'\nseed = 1\nlog_interval = 10\nl2_decay = 5e-4\nclass_num = 31\nparam = 0.3\nbottle_neck = True\nroot_path = ""/data/zhuyc/OFFICE31/""\nsource_name = ""dslr""\ntarget_name = ""amazon""\n'"
UDA/pytorch1.0/DSAN/DSAN.py,9,"b'from __future__ import print_function\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom Weight import Weight\nfrom Config import *\nimport time\nos.environ[""CUDA_VISIBLE_DEVICES""] = cuda_id\n\ncuda = not no_cuda and torch.cuda.is_available()\n#torch.manual_seed(seed)\n#if cuda:\n#    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsource_loader = data_loader.load_training(root_path, source_name, batch_size, kwargs)\ntarget_train_loader = data_loader.load_training(root_path, target_name, batch_size, kwargs)\ntarget_test_loader = data_loader.load_testing(root_path, target_name, batch_size, kwargs)\n\nlen_source_dataset = len(source_loader.dataset)\nlen_target_dataset = len(target_test_loader.dataset)\nlen_source_loader = len(source_loader)\nlen_target_loader = len(target_train_loader)\n\ndef train(epoch, model):\n    LEARNING_RATE = lr / math.pow((1 + 10 * (epoch - 1) / epochs), 0.75)\n    print(\'learning rate{: .4f}\'.format(LEARNING_RATE) )\n    if bottle_neck:\n        optimizer = torch.optim.SGD([\n            {\'params\': model.feature_layers.parameters()},\n            {\'params\': model.bottle.parameters(), \'lr\': LEARNING_RATE},\n            {\'params\': model.cls_fc.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n    else:\n        optimizer = torch.optim.SGD([\n            {\'params\': model.feature_layers.parameters()},\n            {\'params\': model.cls_fc.parameters(), \'lr\': LEARNING_RATE},\n            ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n\n    model.train()\n\n    iter_source = iter(source_loader)\n    iter_target = iter(target_train_loader)\n    num_iter = len_source_loader\n    for i in range(1, num_iter):\n        data_source, label_source = iter_source.next()\n        data_target, _ = iter_target.next()\n        if i % len_target_loader == 0:\n            iter_target = iter(target_train_loader)\n        if cuda:\n            data_source, label_source = data_source.cuda(), label_source.cuda()\n            data_target = data_target.cuda()\n        data_source, label_source = Variable(data_source), Variable(label_source)\n        data_target = Variable(data_target)\n\n        optimizer.zero_grad()\n        label_source_pred, loss_mmd = model(data_source, data_target, label_source)\n        loss_cls = F.nll_loss(F.log_softmax(label_source_pred, dim=1), label_source)\n        lambd = 2 / (1 + math.exp(-10 * (epoch) / epochs)) - 1\n        loss = loss_cls + param * lambd * loss_mmd\n        loss.backward()\n        optimizer.step()\n        if i % log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tsoft_Loss: {:.6f}\\tmmd_Loss: {:.6f}\'.format(\n                epoch, i * len(data_source), len_source_dataset,\n                100. * i / len_source_loader, loss.item(), loss_cls.item(), loss_mmd.item()))\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in target_test_loader:\n            if cuda:\n                data, target = data.cuda(), target.cuda()\n            data, target = Variable(data), Variable(target)\n            s_output, t_output = model(data, data, target)\n            test_loss += F.nll_loss(F.log_softmax(s_output, dim = 1), target).item() # sum up batch loss\n            pred = s_output.data.max(1)[1] # get the index of the max log-probability\n            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n        test_loss /= len_target_dataset\n        print(\'\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n            target_name, test_loss, correct, len_target_dataset,\n            100. * correct / len_target_dataset))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.DSAN(num_classes=class_num)\n    correct = 0\n    print(model)\n    if cuda:\n        model.cuda()\n    time_start=time.time()\n    for epoch in range(1, epochs + 1):\n        train(epoch, model)\n        t_correct = test(model)\n        if t_correct > correct:\n            correct = t_correct\n            #torch.save(model, \'model.pkl\')\n        end_time = time.time()\n        print(\'source: {} to target: {} max correct: {} max accuracy{: .2f}%\\n\'.format(\n              source_name, target_name, correct, 100. * correct / len_target_dataset ))\n        print(\'cost time:\', end_time - time_start)\n'"
UDA/pytorch1.0/DSAN/ResNet.py,8,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport mmd\nimport torch\nimport numpy as np\nfrom Config import bottle_neck\n\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\']\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.baselayer = [self.conv1, self.bn1, self.layer1, self.layer2, self.layer3, self.layer4]\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n\n        return x\n\nclass DSAN(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(DSAN, self).__init__()\n        self.feature_layers = resnet50(True)\n\n        if bottle_neck:\n            self.bottle = nn.Linear(2048, 256)\n            self.cls_fc = nn.Linear(256, num_classes)\n        else:\n            self.cls_fc = nn.Linear(2048, num_classes)\n\n\n    def forward(self, source, target, s_label):\n        source = self.feature_layers(source)\n        if bottle_neck:\n            source = self.bottle(source)\n        s_pred = self.cls_fc(source)\n        if self.training ==True:\n            target = self.feature_layers(target)\n            if bottle_neck:\n                target = self.bottle(target)\n            t_label = self.cls_fc(target)\n            loss = mmd.lmmd(source, target, s_label, torch.nn.functional.softmax(t_label, dim=1))\n        else:\n            loss = 0\n        return s_pred, loss\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n'"
UDA/pytorch1.0/DSAN/Weight.py,0,"b""import numpy as np\nimport torch\nfrom Config import class_num\ndef convert_to_onehot(sca_label, class_num=31):\n    return np.eye(class_num)[sca_label]\n\nclass Weight:\n\n    @staticmethod\n    def cal_weight(s_label, t_label, type='visual', batch_size=32, class_num=31):\n        batch_size = s_label.size()[0]\n        s_sca_label = s_label.cpu().data.numpy()\n        s_vec_label = convert_to_onehot(s_sca_label)\n        s_sum = np.sum(s_vec_label, axis=0).reshape(1, class_num)\n        s_sum[s_sum == 0] = 100\n        s_vec_label = s_vec_label / s_sum\n\n        t_sca_label = t_label.cpu().data.max(1)[1].numpy()\n        #t_vec_label = convert_to_onehot(t_sca_label)\n\n        t_vec_label = t_label.cpu().data.numpy()\n        t_sum = np.sum(t_vec_label, axis=0).reshape(1, class_num)\n        t_sum[t_sum == 0] = 100\n        t_vec_label = t_vec_label / t_sum\n\n        weight_ss = np.zeros((batch_size, batch_size))\n        weight_tt = np.zeros((batch_size, batch_size))\n        weight_st = np.zeros((batch_size, batch_size))\n\n        set_s = set(s_sca_label)\n        set_t = set(t_sca_label)\n        count = 0\n        for i in range(class_num):\n            if i in set_s and i in set_t:\n                s_tvec = s_vec_label[:, i].reshape(batch_size, -1)\n                t_tvec = t_vec_label[:, i].reshape(batch_size, -1)\n                ss = np.dot(s_tvec, s_tvec.T)\n                weight_ss = weight_ss + ss# / np.sum(s_tvec) / np.sum(s_tvec)\n                tt = np.dot(t_tvec, t_tvec.T)\n                weight_tt = weight_tt + tt# / np.sum(t_tvec) / np.sum(t_tvec)\n                st = np.dot(s_tvec, t_tvec.T)\n                weight_st = weight_st + st# / np.sum(s_tvec) / np.sum(t_tvec)\n                count += 1\n\n        length = count  # len( set_s ) * len( set_t )\n        if length != 0:\n            weight_ss = weight_ss / length\n            weight_tt = weight_tt / length\n            weight_st = weight_st / length\n        else:\n            weight_ss = np.array([0])\n            weight_tt = np.array([0])\n            weight_st = np.array([0])\n        return weight_ss.astype('float32'), weight_tt.astype('float32'), weight_st.astype('float32')\n"""
UDA/pytorch1.0/DSAN/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
UDA/pytorch1.0/DSAN/mmd.py,9,"b""#!/usr/bin/env python\n# encoding: utf-8\nimport torch\nfrom Weight import Weight\n\ndef guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    n_samples = int(source.size()[0])+int(target.size()[0])\n    total = torch.cat([source, target], dim=0)\n    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    L2_distance = ((total0-total1)**2).sum(2)\n    if fix_sigma:\n        bandwidth = fix_sigma\n    else:\n        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n    bandwidth /= kernel_mul ** (kernel_num // 2)\n    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n    return sum(kernel_val)#/len(kernel_val)\n\ndef lmmd(source, target, s_label, t_label, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    batch_size = source.size()[0]\n    weight_ss, weight_tt, weight_st = Weight.cal_weight(s_label, t_label, type='visual')\n    weight_ss = torch.from_numpy(weight_ss).cuda()\n    weight_tt = torch.from_numpy(weight_tt).cuda()\n    weight_st = torch.from_numpy(weight_st).cuda()\n\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    loss = torch.Tensor([0]).cuda()\n    if torch.sum(torch.isnan(sum(kernels))):\n        return loss\n    SS = kernels[:batch_size, :batch_size]\n    TT = kernels[batch_size:, batch_size:]\n    ST = kernels[:batch_size, batch_size:]\n\n    loss += torch.sum( weight_ss * SS + weight_tt * TT - 2 * weight_st * ST )\n    return loss\n"""
UDA/pytorch1.0/DeepCoral/Coral.py,5,"b'import torch\n\ndef CORAL(source, target):\n    d = source.data.shape[1]\n\n    # source covariance\n    xm = torch.mean(source, 1, keepdim=True) - source\n    xc = torch.matmul(torch.transpose(xm, 0, 1), xm)\n\n    # target covariance\n    xmt = torch.mean(target, 1, keepdim=True) - target\n    xct = torch.matmul(torch.transpose(xmt, 0, 1), xmt)\n    # frobenius norm between source and target\n    loss = torch.mean(torch.mul((xc - xct), (xc - xct)))\n    loss = loss/(4*d*4)\n    return loss'"
UDA/pytorch1.0/DeepCoral/DeepCoral.py,8,"b'from __future__ import print_function\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n# Training settings\nbatch_size = 32\niteration=10000\nlr = 0.01\nmomentum = 0.9\nno_cuda =False\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nroot_path = ""/data/zhuyc/OFFICE31/""\nsrc_name = ""amazon""\ntgt_name = ""dslr""\n\ncuda = not no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsrc_loader = data_loader.load_training(root_path, src_name, batch_size, kwargs)\ntgt_train_loader = data_loader.load_training(root_path, tgt_name, batch_size, kwargs)\ntgt_test_loader = data_loader.load_testing(root_path, tgt_name, batch_size, kwargs)\n\nsrc_dataset_len = len(src_loader.dataset)\ntgt_dataset_len = len(tgt_test_loader.dataset)\nsrc_loader_len = len(src_loader)\ntgt_loader_len = len(tgt_train_loader)\n\n\ndef train(model):\n    src_iter = iter(src_loader)\n    tgt_iter = iter(tgt_train_loader)\n    correct=0\n    for i in range(1, iteration+1):\n        model.train()\n        LEARNING_RATE = lr / math.pow((1 + 10 * (i - 1) / (iteration)), 0.75)\n        if (i-1)%100==0:\n            print(\'learning rate{: .4f}\'.format(LEARNING_RATE))\n        optimizer = torch.optim.SGD([\n        {\'params\': model.sharedNet.parameters()},\n        {\'params\': model.cls_fc.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n        try:\n            src_data, src_label = src_iter.next()\n        except Exception as err:\n            src_iter=iter(src_loader)\n            src_data, src_label = src_iter.next()\n            \n        try:\n            tgt_data, _ = tgt_iter.next()\n        except Exception as err:\n            tgt_iter=iter(tgt_train_loader)\n            tgt_data, _ = tgt_iter.next()\n            \n        if cuda:\n            src_data, src_label = src_data.cuda(), src_label.cuda()\n            tgt_data = tgt_data.cuda()\n\n        optimizer.zero_grad()\n        src_pred, coral_loss = model(src_data, tgt_data)\n        cls_loss = F.nll_loss(F.log_softmax(src_pred, dim=1), src_label)\n        lambd = 2 / (1 + math.exp(-10 * (i) / iteration)) - 1\n        loss = cls_loss + lambd * coral_loss\n        loss.backward()\n        optimizer.step()\n        if i % log_interval == 0:\n            print(\'Train iter: {} [({:.0f}%)]\\ttotal_Loss: {:.6f}\\tcls_Loss: {:.6f}\\tcoral_Loss: {:.6f}\'.format(\n                i, 100. * i / iteration, loss.item(), cls_loss.item(), coral_loss.item()))\n\n        if i%(log_interval*20)==0:\n            t_correct = test(model)\n            if t_correct > correct:\n                correct = t_correct\n            print(\'src: {} to tgt: {} max correct: {} max accuracy{: .2f}%\\n\'.format(\n              src_name, tgt_name, correct, 100. * correct / tgt_dataset_len ))\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    with torch.no_grad():\n        for tgt_test_data, tgt_test_label in tgt_test_loader:\n            if cuda:\n                tgt_test_data, tgt_test_label = tgt_test_data.cuda(), tgt_test_label.cuda()\n            tgt_test_data, tgt_test_label = Variable(tgt_test_data), Variable(tgt_test_label)\n            tgt_pred, coral_loss = model(tgt_test_data, tgt_test_data)\n            test_loss += F.nll_loss(F.log_softmax(tgt_pred, dim = 1), tgt_test_label, reduction=\'sum\').item() # sum up batch loss\n            pred = tgt_pred.data.max(1)[1] # get the index of the max log-probability\n            correct += pred.eq(tgt_test_label.data.view_as(pred)).cpu().sum()\n\n    test_loss /= tgt_dataset_len\n    print(\'\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        tgt_name, test_loss, correct, tgt_dataset_len,\n        100. * correct / tgt_dataset_len))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.DeepCoral(num_classes=31)\n    print(model)\n    if cuda:\n        model.cuda()\n    train(model)\n'"
UDA/pytorch1.0/DeepCoral/ResNet.py,3,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom Coral import CORAL\n\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1, groups=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    """"""1x1 convolution""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, norm_layer=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000,zero_init_residual=False,\n                 groups=1, width_per_group=64, norm_layer=None):\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n\n        self.inplanes = 64\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, norm_layer=norm_layer)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, norm_layer=norm_layer)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\'fan_out\', nonlinearity=\'relu\')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1,norm_layer=None):\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n                            self.base_width, norm_layer))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups=self.groups,\n                                base_width=self.base_width, norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        #x=self.fc(x)\n\n        return x\n\nclass DeepCoral(nn.Module):\n    def __init__(self, num_classes=31):\n        super(DeepCoral, self).__init__()\n        self.sharedNet = resnet50(True)\n        self.cls_fc = nn.Linear(2048, num_classes)\n\n    def forward(self, source, target):\n        loss = 0\n        source = self.sharedNet(source)\n\n        if self.training == True:\n            target = self.sharedNet(target)\n            loss += CORAL(source, target)\n        source = self.cls_fc(source)\n\n        return source, loss\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n'"
UDA/pytorch1.0/DeepCoral/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
UDA/pytorch1.0/MRAN/MRAN.py,8,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""3""\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=32, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=32, metavar=\'N\',\n                    help=\'input batch size for testing (default: 1000)\')\nparser.add_argument(\'--epochs\', type=int, default=200, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=3, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--l2_decay\', type=float, default=5e-4,\n                    help=\'the L2  weight decay\')\nparser.add_argument(\'--save_path\', type=str, default=""./tmp/origin_"",\n                    help=\'the path to save the model\')\nparser.add_argument(\'--root_path\', type=str, default=""../OFFICE31/"",\n                    help=\'the path to load the data\')\nparser.add_argument(\'--source_dir\', type=str, default=""webcam"",\n                    help=\'the name of the source dir\')\nparser.add_argument(\'--test_dir\', type=str, default=""dslr"",\n                    help=\'the name of the test dir\')\nparser.add_argument(\'--diff_lr\', type=bool, default=True,\n                    help=\'the fc layer and the sharenet have different or same learning rate\')\nparser.add_argument(\'--gamma\', type=int, default=1,\n                    help=\'the fc layer and the sharenet have different or same learning rate\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n\ndef load_data():\n    source_train_loader = data_loader.load_training(args.root_path, args.source_dir, args.batch_size, kwargs)\n    target_train_loader = data_loader.load_training(args.root_path, args.test_dir, args.batch_size, kwargs)\n    target_test_loader = data_loader.load_testing(args.root_path, args.test_dir, args.batch_size, kwargs)\n\n    return source_train_loader, target_train_loader, target_test_loader\n\ndef train(epoch, model, source_loader, target_loader):\n    #\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\xe4\xb8\xba\xe5\x89\x8d\xe9\x9d\xa2\xe7\x9a\x8410\xe5\x80\x8d\n    LEARNING_RATE = args.lr / math.pow((1 + 10 * (epoch - 1) / args.epochs), 0.75)\n    print(""learning rate\xef\xbc\x9a"", LEARNING_RATE)\n    if args.diff_lr:\n        optimizer = torch.optim.SGD([\n        {\'params\': model.sharedNet.parameters()},\n        {\'params\': model.Inception.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=args.momentum, weight_decay=args.l2_decay)\n    else:\n        optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=args.momentum,weight_decay = args.l2_decay)\n    model.train()\n    tgt_iter = iter(target_loader)\n    for batch_idx, (source_data, source_label) in enumerate(source_loader):\n        try:\n            target_data, _ = tgt_iter.next()\n        except Exception as err:\n            tgt_iter=iter(target_loader)\n            target_data, _ = tgt_iter.next()\n        \n        if args.cuda:\n            source_data, source_label = source_data.cuda(), source_label.cuda()\n            target_data = target_data.cuda()\n        optimizer.zero_grad()\n\n        s_output, mmd_loss = model(source_data, target_data, source_label)\n        soft_loss = F.nll_loss(F.log_softmax(s_output, dim=1), source_label)\n        # print((2 / (1 + math.exp(-10 * (epoch) / args.epochs)) - 1))\n        if args.gamma == 1:\n            gamma = 2 / (1 + math.exp(-10 * (epoch) / args.epochs)) - 1\n        if args.gamma == 2:\n            gamma = epoch /args.epochs\n        loss = soft_loss + gamma * mmd_loss\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tlabel_Loss: {:.6f}\\tmmd_Loss: {:.6f}\'.format(\n                epoch, batch_idx * len(source_data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item(), soft_loss.item(), mmd_loss.item()))\n\ndef test(model, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            if args.cuda:\n                data, target = data.cuda(), target.cuda()\n            s_output, t_output = model(data, data, target)\n            test_loss += F.nll_loss(F.log_softmax(s_output, dim = 1), target, reduction=\'sum\').item()# sum up batch loss\n            pred = s_output.data.max(1)[1] # get the index of the max log-probability\n            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n        test_loss /= len(test_loader.dataset)\n        print(args.test_dir, \'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n            test_loss, correct, len(test_loader.dataset),\n            100. * correct / len(test_loader.dataset)))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.MRANNet(num_classes=31)\n    print(model)\n    if args.cuda:\n        model.cuda()\n    train_loader, unsuptrain_loader, test_loader = load_data()\n    correct = 0\n    for epoch in range(1, args.epochs + 1):\n        train(epoch, model, train_loader, unsuptrain_loader)\n        t_correct = test(model, test_loader)\n        if t_correct > correct:\n            correct = t_correct\n        print(""%s max correct:"" % args.test_dir, correct.item())\n        print(args.source_dir, ""to"", args.test_dir)\n'"
UDA/pytorch1.0/MRAN/ResNet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport mmd\nimport torch\nimport torch.nn.functional as F\nimport random\n\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(8, stride=1)\n        self.baselayer = [self.conv1, self.bn1, self.layer1, self.layer2, self.layer3, self.layer4]\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        return x\n\nclass MRANNet(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(MRANNet, self).__init__()\n        self.sharedNet = resnet50(True)\n        self.Inception = InceptionA(2048, 64, num_classes)\n\n    def forward(self, source, target, s_label):\n        source = self.sharedNet(source)\n        target = self.sharedNet(target)\n        source, loss = self.Inception(source, target, s_label)\n\n        return source, loss\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, **kwargs):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return F.relu(x, inplace=True)\n\nclass InceptionA(nn.Module):\n\n    def __init__(self, in_channels, pool_features, num_classes):\n        super(InceptionA, self).__init__()\n        self.branch1x1 = BasicConv2d(in_channels, 64, kernel_size=1)\n\n        self.branch5x5_1 = BasicConv2d(in_channels, 48, kernel_size=1)\n        self.branch5x5_2 = BasicConv2d(48, 64, kernel_size=5, padding=2)\n\n        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, padding=1)\n\n        self.branch_pool = BasicConv2d(in_channels, pool_features, kernel_size=1)\n\n        self.avg_pool = nn.AvgPool2d(7, stride=1)\n\n        self.source_fc = nn.Linear(288, num_classes)\n\n    def forward(self, source, target, s_label):\n        s_branch1x1 = self.branch1x1(source)\n\n        s_branch5x5 = self.branch5x5_1(source)\n        s_branch5x5 = self.branch5x5_2(s_branch5x5)\n\n        s_branch3x3dbl = self.branch3x3dbl_1(source)\n        s_branch3x3dbl = self.branch3x3dbl_2(s_branch3x3dbl)\n        s_branch3x3dbl = self.branch3x3dbl_3(s_branch3x3dbl)\n\n        s_branch_pool = F.avg_pool2d(source, kernel_size=3, stride=1, padding=1)\n        s_branch_pool = self.branch_pool(s_branch_pool)\n\n        s_branch1x1 = self.avg_pool(s_branch1x1)\n        s_branch5x5 = self.avg_pool(s_branch5x5)\n        s_branch3x3dbl = self.avg_pool(s_branch3x3dbl)\n        s_branch_pool = self.avg_pool(s_branch_pool)\n\n        s_branch1x1 = s_branch1x1.view(s_branch1x1.size(0), -1)\n        s_branch5x5 = s_branch5x5.view(s_branch5x5.size(0), -1)\n        s_branch3x3dbl = s_branch3x3dbl.view(s_branch3x3dbl.size(0), -1)\n        s_branch_pool = s_branch_pool.view(s_branch_pool.size(0), -1)\n\n        t_branch1x1 = self.branch1x1(target)\n\n        t_branch5x5 = self.branch5x5_1(target)\n        t_branch5x5 = self.branch5x5_2(t_branch5x5)\n\n        t_branch3x3dbl = self.branch3x3dbl_1(target)\n        t_branch3x3dbl = self.branch3x3dbl_2(t_branch3x3dbl)\n        t_branch3x3dbl = self.branch3x3dbl_3(t_branch3x3dbl)\n\n        t_branch_pool = F.avg_pool2d(target, kernel_size=3, stride=1, padding=1)\n        t_branch_pool = self.branch_pool(t_branch_pool)\n\n        t_branch1x1 = self.avg_pool(t_branch1x1)\n        t_branch5x5 = self.avg_pool(t_branch5x5)\n        t_branch3x3dbl = self.avg_pool(t_branch3x3dbl)\n        t_branch_pool = self.avg_pool(t_branch_pool)\n\n        t_branch1x1 = t_branch1x1.view(t_branch1x1.size(0), -1)\n        t_branch5x5 = t_branch5x5.view(t_branch5x5.size(0), -1)\n        t_branch3x3dbl = t_branch3x3dbl.view(t_branch3x3dbl.size(0), -1)\n        t_branch_pool = t_branch_pool.view(t_branch_pool.size(0), -1)\n\n        source = torch.cat([s_branch1x1, s_branch5x5, s_branch3x3dbl, s_branch_pool], 1)\n        target = torch.cat([t_branch1x1, t_branch5x5, t_branch3x3dbl, t_branch_pool], 1)\n\n        source = self.source_fc(source)\n        t_label = self.source_fc(target)\n        t_label = t_label.data.max(1)[1]\n\n        loss = torch.Tensor([0])\n        loss = loss.cuda()\n        if self.training == True:\n            loss += mmd.cmmd(s_branch1x1, t_branch1x1, s_label, t_label)\n            loss += mmd.cmmd(s_branch5x5, t_branch5x5, s_label, t_label)\n            loss += mmd.cmmd(s_branch3x3dbl, t_branch3x3dbl, s_label, t_label)\n            loss += mmd.cmmd(s_branch_pool, t_branch_pool, s_label, t_label)\n        return source, loss\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model'"
UDA/pytorch1.0/MRAN/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
UDA/pytorch1.0/MRAN/mmd.py,9,"b'#!/usr/bin/env python\n# encoding: utf-8\n\n\nimport torch\nimport numpy as np\nfrom torch.autograd import Variable\nmin_var_est = 1e-8\n\ndef guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    n_samples = int(source.size()[0])+int(target.size()[0])\n    total = torch.cat([source, target], dim=0)\n    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n    L2_distance = ((total0-total1)**2).sum(2)\n    if fix_sigma:\n        bandwidth = fix_sigma\n    else:\n        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n    bandwidth /= kernel_mul ** (kernel_num // 2)\n    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n    return sum(kernel_val)#/len(kernel_val)\n\ndef cmmd(source, target, s_label, t_label, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n    s_label = s_label.cpu()\n    s_label = s_label.view(32,1)\n    s_label = torch.zeros(32, 31).scatter_(1, s_label.data, 1)\n    s_label = Variable(s_label).cuda()\n\n    t_label = t_label.cpu()\n    t_label = t_label.view(32, 1)\n    t_label = torch.zeros(32, 31).scatter_(1, t_label.data, 1)\n    t_label = Variable(t_label).cuda()\n\n    batch_size = int(source.size()[0])\n    kernels = guassian_kernel(source, target,\n                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n    loss = 0\n    XX = kernels[:batch_size, :batch_size]\n    YY = kernels[batch_size:, batch_size:]\n    XY = kernels[:batch_size, batch_size:]\n    loss += torch.mean(torch.mm(s_label, torch.transpose(s_label, 0, 1)) * XX +\n                      torch.mm(t_label, torch.transpose(t_label, 0, 1)) * YY -\n                      2 * torch.mm(s_label, torch.transpose(t_label, 0, 1)) * XY)\n    return loss'"
UDA/pytorch1.0/RevGrad/ResNet.py,5,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torch\nfrom torch.autograd import Function, Variable\nimport numpy as np\n\n__all__ = [\'ResNet\', \'resnet50\']\n\n\nmodel_urls = {\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc=nn.Linear(512*block.expansion,num_classes)\n        self.fc.weight.data.normal_(0, 0.01)\n        self.fc.bias.data.fill_(0.0)\n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n\n        return x\n\n    def output_num(self):\n        return resnet50(True).fc.in_features\n\nclass RevGrad(nn.Module):\n\n    def __init__(self, num_classes=31):\n        super(RevGrad, self).__init__()\n        self.sharedNet = resnet50(True)\n        self.cls_fn = nn.Linear(2048, num_classes)\n        self.domain_fn = AdversarialNetwork(in_feature=2048)\n             \n    def forward(self, data):\n        data = self.sharedNet(data)\n        clabel_pred = self.cls_fn(data)\n        dlabel_pred = self.domain_fn(AdversarialLayer(high_value=1.0)(data))\n        #print(dlabel_pred)\n        return clabel_pred, dlabel_pred\n\n\nclass AdversarialNetwork(nn.Module):\n    def __init__(self, in_feature):\n        super(AdversarialNetwork, self).__init__()\n        self.ad_layer1 = nn.Linear(in_feature,1024)\n        self.ad_layer2 = nn.Linear(1024,1024)\n        self.ad_layer3 = nn.Linear(1024, 1)\n        self.ad_layer1.weight.data.normal_(0, 0.01)\n        self.ad_layer2.weight.data.normal_(0, 0.01)\n        self.ad_layer3.weight.data.normal_(0, 0.3)\n        self.ad_layer1.bias.data.fill_(0.0)\n        self.ad_layer2.bias.data.fill_(0.0)\n        self.ad_layer3.bias.data.fill_(0.0)\n        self.relu1 = nn.ReLU()\n        self.relu2 = nn.ReLU()\n        self.dropout1 = nn.Dropout(0.5)\n        self.dropout2 = nn.Dropout(0.5)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.ad_layer1(x)\n        x = self.relu1(x)\n        x = self.dropout1(x)\n        x = self.ad_layer2(x)\n        x = self.relu2(x)\n        x = self.dropout2(x)\n        x = self.ad_layer3(x)\n        x = self.sigmoid(x)\n        return x\n\n    def output_num(self):\n        return 1\n\nclass AdversarialLayer(torch.autograd.Function):\n  def __init__(self, high_value=1.0):\n    self.iter_num = 0\n    self.alpha = 10\n    self.low = 0.0\n    self.high = high_value\n    self.max_iter = 2000.0\n    \n  def forward(self, input):\n    self.iter_num += 1\n    output = input * 1.0\n    return output\n\n  def backward(self, gradOutput):\n    self.coeff = np.float(2.0 * (self.high - self.low) / (1.0 + np.exp(-self.alpha*self.iter_num / self.max_iter)) - (self.high - self.low) + self.low)\n    return -self.coeff * gradOutput\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n'"
UDA/pytorch1.0/RevGrad/RevGrad.py,15,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport os\nimport math\nimport data_loader\nimport ResNet as models\nfrom torch.utils import model_zoo\nimport torchvision\nimport torch.nn as nn\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\n\n# Training settings\nbatch_size = 32\niteration=10000\nlr = 0.01\nmomentum = 0.9\nno_cuda =False\nseed = 8\nlog_interval = 10\nl2_decay = 5e-4\nroot_path = ""/data/zhuyc/OFFICE31/""\nsrc_name = ""dslr""\ntgt_name = ""amazon""\n\ncuda = not no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if cuda else {}\n\nsrc_loader = data_loader.load_training(root_path, src_name, batch_size, kwargs)\ntgt_train_loader = data_loader.load_training(root_path, tgt_name, batch_size, kwargs)\ntgt_test_loader = data_loader.load_testing(root_path, tgt_name, batch_size, kwargs)\n\nsrc_dataset_len = len(src_loader.dataset)\ntgt_dataset_len = len(tgt_test_loader.dataset)\nsrc_loader_len = len(src_loader)\ntgt_loader_len = len(tgt_train_loader)\n\n\ndef train(model):\n    src_data_iter = iter(src_loader)\n    tgt_data_iter = iter(tgt_train_loader)\n    src_dlabel = Variable(torch.ones(batch_size).long().cuda())\n    tgt_dlabel = Variable(torch.zeros(batch_size).long().cuda())\n    correct=0\n    #gradient_reverse_layer = network.AdversarialLayer(high_value=config[""high""])\n    for i in range(1, iteration+1):\n        model.train()\n        LEARNING_RATE = lr / math.pow((1 + 10 * (i - 1) / (iteration)), 0.75)\n        if (i-1)%100==0:\n            print(""learning rate: "", LEARNING_RATE)\n        optimizer_fea = torch.optim.SGD([\n        {\'params\': model.sharedNet.parameters()},\n        {\'params\': model.cls_fn.parameters(), \'lr\': LEARNING_RATE},\n        ], lr=LEARNING_RATE / 10, momentum=momentum, weight_decay=l2_decay)\n        optimizer_critic = torch.optim.SGD([\n        {\'params\': model.domain_fn.parameters(), \'lr\': LEARNING_RATE}\n        ], lr=LEARNING_RATE, momentum=momentum, weight_decay=l2_decay)\n\n        try:\n            src_data, src_label = src_iter.next()\n        except Exception as err:\n            src_iter=iter(src_loader)\n            src_data, src_label = src_iter.next()\n            \n        try:\n            tgt_data, _ = tgt_iter.next()\n        except Exception as err:\n            tgt_iter=iter(tgt_train_loader)\n            tgt_data, _ = tgt_iter.next()\n            \n        if cuda:\n            src_data, src_label = src_data.cuda(), src_label.cuda()\n            tgt_data = tgt_data.cuda()\n        src_clabel_pred, src_dlabel_pred = model(src_data)\n        loss=nn.CrossEntropyLoss()\n        label_loss=loss(src_clabel_pred,src_clabel)\n            \n        tgt_clabel_pred, tgt_dlabel_pred = model(tgt_data)\n        new_label_pred=torch.cat((src_dlabel_pred,tgt_dlabel_pred),0)\n        confusion_loss=nn.BCELoss()\n        confusion_loss_total=confusion_loss(new_label_pred,torch.cat((src_dlabel,tgt_dlabel),0).float().reshape(2*batch_size,1))\n\n        fea_loss_total = confusion_loss_total + label_loss\n        optimizer_fea.zero_grad()\n        fea_loss_total.backward()\n        optimizer_fea.step()\n\n        if i % log_interval == 0:\n            print(\'Train iter: {} [({:.0f}%)]\\tconfusion_Loss: {:.6f}\\tlabel_Loss: {:.6f}\'.format(\n                i, 100. * i / iteration, confusion_loss_total.item(), label_loss.item()))\n\n        if i%(log_interval*20)==0:\n            t_correct = test(model)\n            if t_correct > correct:\n                correct = t_correct\n            print(\'src: {} to tgt: {} max correct: {} max accuracy{: .2f}%\\n\'.format(\n              src_name, tgt_name, correct, 100. * correct / tgt_dataset_len ))\n\n       \ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    with torch.no_grad():\n        for tgt_test_data, tgt_test_label in tgt_test_loader:\n            if cuda:\n                tgt_test_data, tgt_test_label = tgt_test_data.cuda(), tgt_test_label.cuda()\n            tgt_test_data, tgt_test_label = Variable(tgt_test_data), Variable(tgt_test_label)\n            tgt_clabel_pred, tgt_dlabel_pred = model(tgt_test_data)\n            test_loss += F.nll_loss(F.log_softmax(tgt_clabel_pred, dim = 1), tgt_test_label, reduction=\'sum\').item() # sum up batch loss\n            pred = tgt_clabel_pred.data.max(1)[1] # get the index of the max log-probability\n            correct += pred.eq(tgt_test_label.data.view_as(pred)).cpu().sum()\n\n    test_loss /= tgt_dataset_len\n    print(\'\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        tgt_name, test_loss, correct, tgt_dataset_len,\n        100. * correct / tgt_dataset_len))\n    return correct\n\n\nif __name__ == \'__main__\':\n    model = models.RevGrad(num_classes=31)\n    print(model)\n    if cuda:\n        model.cuda()\n    train(model)\n'"
UDA/pytorch1.0/RevGrad/data_loader.py,2,"b'from torchvision import datasets, transforms\nimport torch\n\ndef load_training(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([256, 256]),\n         transforms.RandomCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n    return train_loader\n\ndef load_testing(root_path, dir, batch_size, kwargs):\n    transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         transforms.ToTensor()])\n    data = datasets.ImageFolder(root=root_path + dir, transform=transform)\n    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs)\n    return test_loader'"
UDA/pytorch1.0/RevGrad/loss.py,5,"b'import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\ndef EntropyLoss(input_):\n    mask = input_.ge(0.000001)\n    mask_out = torch.masked_select(input_, mask)\n    entropy = -(torch.sum(mask_out * torch.log(mask_out)))\n    return entropy / float(input_.size(0))\n\ndef PADA(features, ad_net, grl_layer, weight_ad, use_gpu=True):\n    ad_out = ad_net(grl_layer(features))\n    batch_size = ad_out.size(0) // 2\n    dc_target = Variable(torch.from_numpy(np.array([[1]] * batch_size + [[0]] * batch_size)).float())\n    if use_gpu:\n        dc_target = dc_target.cuda()\n        weight_ad = weight_ad.cuda()\n    return nn.BCELoss(weight=weight_ad.view(-1))(ad_out.view(-1), dc_target.view(-1))\n'"
