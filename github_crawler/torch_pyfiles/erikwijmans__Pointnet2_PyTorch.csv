file_path,api_count,code
setup.py,0,"b'import os.path as osp\n\nfrom setuptools import find_packages, setup\n\nrequirements = [""h5py"", ""pprint"", ""hydra-core==0.11.3"", ""pytorch-lightning==0.7.1""]\n\n\nexec(open(osp.join(""pointnet2"", ""_version.py"")).read())\n\nsetup(\n    name=""pointnet2"",\n    version=__version__,\n    author=""Erik Wijmans"",\n    packages=find_packages(),\n    install_requires=requirements,\n)\n'"
pointnet2/__init__.py,0,"b'from pointnet2 import data, models, utils\nfrom pointnet2._version import __version__\n'"
pointnet2/_version.py,0,"b'__version__ = ""3.0.0""\n'"
pointnet2/train.py,2,"b'import os\n\nimport hydra\nimport omegaconf\nimport pytorch_lightning as pl\nimport torch\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\n\ndef wrap_tb_logger():\n    orig_method = TensorBoardLogger.log_hyperparams\n\n    def hydra_hparams(self, hparams):\n        def _to_dot_dict(cfg):\n            res = {}\n            for k, v in cfg.items():\n                if isinstance(v, omegaconf.DictConfig):\n                    res.update(\n                        {k + ""."" + subk: subv for subk, subv in _to_dot_dict(v).items()}\n                    )\n                elif isinstance(v, (str, int, float, bool)):\n                    res[k] = v\n\n            return res\n\n        return orig_method(self, _to_dot_dict(hparams))\n\n    TensorBoardLogger.log_hyperparams = hydra_hparams\n\n\n@hydra.main(""config/config.yaml"")\ndef main(cfg):\n    wrap_tb_logger()\n    model = hydra.utils.instantiate(cfg.task_model, cfg)\n\n    early_stop_callback = pl.callbacks.EarlyStopping(patience=5)\n    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n        monitor=""val_acc"",\n        mode=""max"",\n        save_top_k=2,\n        filepath=os.path.join(\n            cfg.task_model.name, ""{epoch}-{val_loss:.2f}-{val_acc:.3f}""\n        ),\n        verbose=True,\n    )\n    trainer = pl.Trainer(\n        gpus=list(cfg.gpus),\n        max_epochs=cfg.epochs,\n        early_stop_callback=early_stop_callback,\n        checkpoint_callback=checkpoint_callback,\n        distributed_backend=cfg.distrib_backend,\n    )\n\n    trainer.fit(model)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
pointnet2_ops_lib/setup.py,1,"b'import glob\nimport os\nimport os.path as osp\n\nfrom setuptools import find_packages, setup\nfrom torch.utils.cpp_extension import BuildExtension, CUDAExtension\n\nthis_dir = osp.dirname(osp.abspath(__file__))\n_ext_src_root = osp.join(""pointnet2_ops"", ""_ext-src"")\n_ext_sources = glob.glob(osp.join(_ext_src_root, ""src"", ""*.cpp"")) + glob.glob(\n    osp.join(_ext_src_root, ""src"", ""*.cu"")\n)\n_ext_headers = glob.glob(osp.join(_ext_src_root, ""include"", ""*""))\n\nrequirements = [""torch>=1.4""]\n\nexec(open(osp.join(""pointnet2_ops"", ""_version.py"")).read())\n\nos.environ[""TORCH_CUDA_ARCH_LIST""] = ""3.7+PTX;5.0;6.0;6.1;6.2;7.0;7.5""\nsetup(\n    name=""pointnet2_ops"",\n    version=__version__,\n    author=""Erik Wijmans"",\n    packages=find_packages(),\n    install_requires=requirements,\n    ext_modules=[\n        CUDAExtension(\n            name=""pointnet2_ops._ext"",\n            sources=_ext_sources,\n            extra_compile_args={\n                ""cxx"": [""-O3""],\n                ""nvcc"": [""-O3"", ""-Xfatbin"", ""-compress-all""],\n            },\n            include_dirs=[osp.join(this_dir, _ext_src_root, ""include"")],\n        )\n    ],\n    cmdclass={""build_ext"": BuildExtension},\n    include_package_data=True,\n)\n'"
tests/conftest.py,5,"b'import os\n\nimport hydra\nimport hydra.experimental\nimport numpy as np\nimport pytest\nimport torch\n\npytest_plugins = [""helpers_namespace""]\n\nhydra.experimental.initialize(\n    os.path.join(os.path.dirname(__file__), ""../pointnet2/config"")\n)\n\n\n@pytest.helpers.register\ndef build_cfg(overrides=[]):\n    return hydra.experimental.compose(""config.yaml"", overrides)\n\n\n@pytest.helpers.register\ndef get_model(overrides=[]):\n    cfg = build_cfg(overrides)\n    return hydra.utils.instantiate(cfg.task_model, cfg)\n\n\ndef _test_loop(model, inputs, labels):\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n\n    prev_loss = 1e10\n    for _ in range(5):\n        optimizer.zero_grad()\n        res = model.training_step((inputs, labels), None)\n        loss = res[""loss""]\n        loss.backward()\n        optimizer.step()\n\n        assert loss.item() < prev_loss + 1.0, ""Loss spiked upwards""\n\n        prev_loss = loss.item()\n\n\n@pytest.helpers.register\ndef cls_test(model):\n    B, N = 4, 2048\n    inputs = torch.randn(B, N, 6).cuda()\n    labels = torch.from_numpy(np.random.randint(0, 3, size=B)).cuda()\n    model.cuda()\n\n    _test_loop(model, inputs, labels)\n\n\n@pytest.helpers.register\ndef semseg_test(model):\n    B, N = 4, 2048\n    inputs = torch.randn(B, N, 9).cuda()\n    labels = torch.from_numpy(np.random.randint(0, 3, size=B * N)).view(B, N).cuda()\n    model.cuda()\n\n    _test_loop(model, inputs, labels)\n'"
tests/test_cls.py,0,"b'import pytest\n\n\n@pytest.mark.parametrize(""use_xyz"", [""True"", ""False""])\n@pytest.mark.parametrize(""model"", [""ssg"", ""msg""])\ndef test_cls(use_xyz, model):\n    model = pytest.helpers.get_model(\n        [""task=cls"", f""model={model}"", f""model.use_xyz={use_xyz}""]\n    )\n    pytest.helpers.cls_test(model)\n'"
tests/test_semseg.py,0,"b'import pytest\n\n\n@pytest.mark.parametrize(""use_xyz"", [""True"", ""False""])\n@pytest.mark.parametrize(""model"", [""ssg"", ""msg""])\ndef test_semseg(use_xyz, model):\n    model = pytest.helpers.get_model(\n        [""task=semseg"", f""model={model}"", f""model.use_xyz={use_xyz}""]\n    )\n    pytest.helpers.semseg_test(model)\n'"
pointnet2/data/Indoor3DSemSegLoader.py,4,"b'import os\nimport shlex\nimport subprocess\n\nimport h5py\nimport numpy as np\nimport torch\nimport torch.utils.data as data\n\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\n\n\ndef _get_data_files(list_filename):\n    with open(list_filename) as f:\n        return [line.rstrip() for line in f]\n\n\ndef _load_data_file(name):\n    f = h5py.File(name)\n    data = f[""data""][:]\n    label = f[""label""][:]\n    return data, label\n\n\nclass Indoor3DSemSeg(data.Dataset):\n    def __init__(self, num_points, train=True, download=True, data_precent=1.0):\n        super().__init__()\n        self.data_precent = data_precent\n        self.folder = ""indoor3d_sem_seg_hdf5_data""\n        self.data_dir = os.path.join(BASE_DIR, self.folder)\n        self.url = (\n            ""https://shapenet.cs.stanford.edu/media/indoor3d_sem_seg_hdf5_data.zip""\n        )\n\n        if download and not os.path.exists(self.data_dir):\n            zipfile = os.path.join(BASE_DIR, os.path.basename(self.url))\n            subprocess.check_call(\n                shlex.split(""curl {} -o {}"".format(self.url, zipfile))\n            )\n\n            subprocess.check_call(\n                shlex.split(""unzip {} -d {}"".format(zipfile, BASE_DIR))\n            )\n\n            subprocess.check_call(shlex.split(""rm {}"".format(zipfile)))\n\n        self.train, self.num_points = train, num_points\n\n        all_files = _get_data_files(os.path.join(self.data_dir, ""all_files.txt""))\n        room_filelist = _get_data_files(\n            os.path.join(self.data_dir, ""room_filelist.txt"")\n        )\n\n        data_batchlist, label_batchlist = [], []\n        for f in all_files:\n            data, label = _load_data_file(os.path.join(BASE_DIR, f))\n            data_batchlist.append(data)\n            label_batchlist.append(label)\n\n        data_batches = np.concatenate(data_batchlist, 0)\n        labels_batches = np.concatenate(label_batchlist, 0)\n\n        test_area = ""Area_5""\n        train_idxs, test_idxs = [], []\n        for i, room_name in enumerate(room_filelist):\n            if test_area in room_name:\n                test_idxs.append(i)\n            else:\n                train_idxs.append(i)\n\n        if self.train:\n            self.points = data_batches[train_idxs, ...]\n            self.labels = labels_batches[train_idxs, ...]\n        else:\n            self.points = data_batches[test_idxs, ...]\n            self.labels = labels_batches[test_idxs, ...]\n\n    def __getitem__(self, idx):\n        pt_idxs = np.arange(0, self.num_points)\n        np.random.shuffle(pt_idxs)\n\n        current_points = torch.from_numpy(self.points[idx, pt_idxs].copy()).float()\n        current_labels = torch.from_numpy(self.labels[idx, pt_idxs].copy()).long()\n\n        return current_points, current_labels\n\n    def __len__(self):\n        return int(self.points.shape[0] * self.data_precent)\n\n    def set_num_points(self, pts):\n        self.num_points = pts\n\n    def randomize(self):\n        pass\n\n\nif __name__ == ""__main__"":\n    dset = Indoor3DSemSeg(16, ""./"", train=True)\n    print(dset[0])\n    print(len(dset))\n    dloader = torch.utils.data.DataLoader(dset, batch_size=32, shuffle=True)\n    for i, data in enumerate(dloader, 0):\n        inputs, labels = data\n        if i == len(dloader) - 1:\n            print(inputs.size())\n'"
pointnet2/data/ModelNet40Loader.py,2,"b'import os\nimport os.path as osp\nimport shlex\nimport shutil\nimport subprocess\n\nimport lmdb\nimport msgpack_numpy\nimport numpy as np\nimport torch\nimport torch.utils.data as data\nimport tqdm\n\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\n\n\ndef pc_normalize(pc):\n    l = pc.shape[0]\n    centroid = np.mean(pc, axis=0)\n    pc = pc - centroid\n    m = np.max(np.sqrt(np.sum(pc ** 2, axis=1)))\n    pc = pc / m\n    return pc\n\n\nclass ModelNet40Cls(data.Dataset):\n    def __init__(self, num_points, transforms=None, train=True, download=True):\n        super().__init__()\n\n        self.transforms = transforms\n\n        self.set_num_points(num_points)\n        self._cache = os.path.join(BASE_DIR, ""modelnet40_normal_resampled_cache"")\n\n        if not osp.exists(self._cache):\n            self.folder = ""modelnet40_normal_resampled""\n            self.data_dir = os.path.join(BASE_DIR, self.folder)\n            self.url = (\n                ""https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip""\n            )\n\n            if download and not os.path.exists(self.data_dir):\n                zipfile = os.path.join(BASE_DIR, os.path.basename(self.url))\n                subprocess.check_call(\n                    shlex.split(""curl {} -o {}"".format(self.url, zipfile))\n                )\n\n                subprocess.check_call(\n                    shlex.split(""unzip {} -d {}"".format(zipfile, BASE_DIR))\n                )\n\n                subprocess.check_call(shlex.split(""rm {}"".format(zipfile)))\n\n            self.train = train\n            self.set_num_points(num_points)\n\n            self.catfile = os.path.join(self.data_dir, ""modelnet40_shape_names.txt"")\n            self.cat = [line.rstrip() for line in open(self.catfile)]\n            self.classes = dict(zip(self.cat, range(len(self.cat))))\n\n            os.makedirs(self._cache)\n\n            print(""Converted to LMDB for faster dataloading while training"")\n            for split in [""train"", ""test""]:\n                if split == ""train"":\n                    shape_ids = [\n                        line.rstrip()\n                        for line in open(\n                            os.path.join(self.data_dir, ""modelnet40_train.txt"")\n                        )\n                    ]\n                else:\n                    shape_ids = [\n                        line.rstrip()\n                        for line in open(\n                            os.path.join(self.data_dir, ""modelnet40_test.txt"")\n                        )\n                    ]\n\n                shape_names = [""_"".join(x.split(""_"")[0:-1]) for x in shape_ids]\n                # list of (shape_name, shape_txt_file_path) tuple\n                self.datapath = [\n                    (\n                        shape_names[i],\n                        os.path.join(self.data_dir, shape_names[i], shape_ids[i])\n                        + "".txt"",\n                    )\n                    for i in range(len(shape_ids))\n                ]\n\n                with lmdb.open(\n                    osp.join(self._cache, split), map_size=1 << 36\n                ) as lmdb_env, lmdb_env.begin(write=True) as txn:\n                    for i in tqdm.trange(len(self.datapath)):\n                        fn = self.datapath[i]\n                        point_set = np.loadtxt(fn[1], delimiter="","").astype(np.float32)\n                        cls = self.classes[self.datapath[i][0]]\n                        cls = int(cls)\n\n                        txn.put(\n                            str(i).encode(),\n                            msgpack_numpy.packb(\n                                dict(pc=point_set, lbl=cls), use_bin_type=True\n                            ),\n                        )\n\n            shutil.rmtree(self.data_dir)\n\n        self._lmdb_file = osp.join(self._cache, ""train"" if train else ""test"")\n        with lmdb.open(self._lmdb_file, map_size=1 << 36) as lmdb_env:\n            self._len = lmdb_env.stat()[""entries""]\n\n        self._lmdb_env = None\n\n    def __getitem__(self, idx):\n        if self._lmdb_env is None:\n            self._lmdb_env = lmdb.open(\n                self._lmdb_file, map_size=1 << 36, readonly=True, lock=False\n            )\n\n        with self._lmdb_env.begin(buffers=True) as txn:\n            ele = msgpack_numpy.unpackb(txn.get(str(idx).encode()), raw=False)\n\n        point_set = ele[""pc""]\n\n        pt_idxs = np.arange(0, self.num_points)\n        np.random.shuffle(pt_idxs)\n\n        point_set = point_set[pt_idxs, :]\n        point_set[:, 0:3] = pc_normalize(point_set[:, 0:3])\n\n        if self.transforms is not None:\n            point_set = self.transforms(point_set)\n\n        return point_set, ele[""lbl""]\n\n    def __len__(self):\n        return self._len\n\n    def set_num_points(self, pts):\n        self.num_points = min(int(1e4), pts)\n\n\nif __name__ == ""__main__"":\n    from torchvision import transforms\n    import data_utils as d_utils\n\n    transforms = transforms.Compose(\n        [\n            d_utils.PointcloudToTensor(),\n            d_utils.PointcloudRotate(axis=np.array([1, 0, 0])),\n            d_utils.PointcloudScale(),\n            d_utils.PointcloudTranslate(),\n            d_utils.PointcloudJitter(),\n        ]\n    )\n    dset = ModelNet40Cls(16, train=True, transforms=transforms)\n    print(dset[0][0])\n    print(dset[0][1])\n    print(len(dset))\n    dloader = torch.utils.data.DataLoader(dset, batch_size=32, shuffle=True)\n'"
pointnet2/data/__init__.py,0,b'from .Indoor3DSemSegLoader import Indoor3DSemSeg\nfrom .ModelNet40Loader import ModelNet40Cls\n'
pointnet2/data/data_utils.py,11,"b'import numpy as np\nimport torch\n\n\ndef angle_axis(angle, axis):\n    # type: (float, np.ndarray) -> float\n    r""""""Returns a 4x4 rotation matrix that performs a rotation around axis by angle\n\n    Parameters\n    ----------\n    angle : float\n        Angle to rotate by\n    axis: np.ndarray\n        Axis to rotate about\n\n    Returns\n    -------\n    torch.Tensor\n        3x3 rotation matrix\n    """"""\n    u = axis / np.linalg.norm(axis)\n    cosval, sinval = np.cos(angle), np.sin(angle)\n\n    # yapf: disable\n    cross_prod_mat = np.array([[0.0, -u[2], u[1]],\n                                [u[2], 0.0, -u[0]],\n                                [-u[1], u[0], 0.0]])\n\n    R = torch.from_numpy(\n        cosval * np.eye(3)\n        + sinval * cross_prod_mat\n        + (1.0 - cosval) * np.outer(u, u)\n    )\n    # yapf: enable\n    return R.float()\n\n\nclass PointcloudScale(object):\n    def __init__(self, lo=0.8, hi=1.25):\n        self.lo, self.hi = lo, hi\n\n    def __call__(self, points):\n        scaler = np.random.uniform(self.lo, self.hi)\n        points[:, 0:3] *= scaler\n        return points\n\n\nclass PointcloudRotate(object):\n    def __init__(self, axis=np.array([0.0, 1.0, 0.0])):\n        self.axis = axis\n\n    def __call__(self, points):\n        rotation_angle = np.random.uniform() * 2 * np.pi\n        rotation_matrix = angle_axis(rotation_angle, self.axis)\n\n        normals = points.size(1) > 3\n        if not normals:\n            return torch.matmul(points, rotation_matrix.t())\n        else:\n            pc_xyz = points[:, 0:3]\n            pc_normals = points[:, 3:]\n            points[:, 0:3] = torch.matmul(pc_xyz, rotation_matrix.t())\n            points[:, 3:] = torch.matmul(pc_normals, rotation_matrix.t())\n\n            return points\n\n\nclass PointcloudRotatePerturbation(object):\n    def __init__(self, angle_sigma=0.06, angle_clip=0.18):\n        self.angle_sigma, self.angle_clip = angle_sigma, angle_clip\n\n    def _get_angles(self):\n        angles = np.clip(\n            self.angle_sigma * np.random.randn(3), -self.angle_clip, self.angle_clip\n        )\n\n        return angles\n\n    def __call__(self, points):\n        angles = self._get_angles()\n        Rx = angle_axis(angles[0], np.array([1.0, 0.0, 0.0]))\n        Ry = angle_axis(angles[1], np.array([0.0, 1.0, 0.0]))\n        Rz = angle_axis(angles[2], np.array([0.0, 0.0, 1.0]))\n\n        rotation_matrix = torch.matmul(torch.matmul(Rz, Ry), Rx)\n\n        normals = points.size(1) > 3\n        if not normals:\n            return torch.matmul(points, rotation_matrix.t())\n        else:\n            pc_xyz = points[:, 0:3]\n            pc_normals = points[:, 3:]\n            points[:, 0:3] = torch.matmul(pc_xyz, rotation_matrix.t())\n            points[:, 3:] = torch.matmul(pc_normals, rotation_matrix.t())\n\n            return points\n\n\nclass PointcloudJitter(object):\n    def __init__(self, std=0.01, clip=0.05):\n        self.std, self.clip = std, clip\n\n    def __call__(self, points):\n        jittered_data = (\n            points.new(points.size(0), 3)\n            .normal_(mean=0.0, std=self.std)\n            .clamp_(-self.clip, self.clip)\n        )\n        points[:, 0:3] += jittered_data\n        return points\n\n\nclass PointcloudTranslate(object):\n    def __init__(self, translate_range=0.1):\n        self.translate_range = translate_range\n\n    def __call__(self, points):\n        translation = np.random.uniform(-self.translate_range, self.translate_range)\n        points[:, 0:3] += translation\n        return points\n\n\nclass PointcloudToTensor(object):\n    def __call__(self, points):\n        return torch.from_numpy(points).float()\n\n\nclass PointcloudRandomInputDropout(object):\n    def __init__(self, max_dropout_ratio=0.875):\n        assert max_dropout_ratio >= 0 and max_dropout_ratio < 1\n        self.max_dropout_ratio = max_dropout_ratio\n\n    def __call__(self, points):\n        pc = points.numpy()\n\n        dropout_ratio = np.random.random() * self.max_dropout_ratio  # 0~0.875\n        drop_idx = np.where(np.random.random((pc.shape[0])) <= dropout_ratio)[0]\n        if len(drop_idx) > 0:\n            pc[drop_idx] = pc[0]  # set to the first point\n\n        return torch.from_numpy(pc).float()\n'"
pointnet2/models/__init__.py,0,b'from pointnet2.models.pointnet2_msg_cls import PointNet2ClassificationMSG\nfrom pointnet2.models.pointnet2_msg_sem import PointNet2SemSegMSG\nfrom pointnet2.models.pointnet2_ssg_cls import PointNet2ClassificationSSG\nfrom pointnet2.models.pointnet2_ssg_sem import PointNet2SemSegSSG\n'
pointnet2/models/pointnet2_msg_cls.py,2,"b'import pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom pointnet2_ops.pointnet2_modules import PointnetSAModule, PointnetSAModuleMSG\n\nfrom pointnet2.models.pointnet2_ssg_cls import PointNet2ClassificationSSG\n\n\nclass PointNet2ClassificationMSG(PointNet2ClassificationSSG):\n    def _build_model(self):\n        super()._build_model()\n\n        self.SA_modules = nn.ModuleList()\n        self.SA_modules.append(\n            PointnetSAModuleMSG(\n                npoint=512,\n                radii=[0.1, 0.2, 0.4],\n                nsamples=[16, 32, 128],\n                mlps=[[3, 32, 32, 64], [3, 64, 64, 128], [3, 64, 96, 128]],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n\n        input_channels = 64 + 128 + 128\n        self.SA_modules.append(\n            PointnetSAModuleMSG(\n                npoint=128,\n                radii=[0.2, 0.4, 0.8],\n                nsamples=[32, 64, 128],\n                mlps=[\n                    [input_channels, 64, 64, 128],\n                    [input_channels, 128, 128, 256],\n                    [input_channels, 128, 128, 256],\n                ],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        self.SA_modules.append(\n            PointnetSAModule(\n                mlp=[128 + 256 + 256, 256, 512, 1024],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n'"
pointnet2/models/pointnet2_msg_sem.py,1,"b'from collections import namedtuple\n\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nfrom pointnet2_ops.pointnet2_modules import PointnetFPModule, PointnetSAModuleMSG\n\nfrom pointnet2.models.pointnet2_ssg_sem import PointNet2SemSegSSG\n\n\nclass PointNet2SemSegMSG(PointNet2SemSegSSG):\n    def _build_model(self):\n        self.SA_modules = nn.ModuleList()\n        c_in = 6\n        self.SA_modules.append(\n            PointnetSAModuleMSG(\n                npoint=1024,\n                radii=[0.05, 0.1],\n                nsamples=[16, 32],\n                mlps=[[c_in, 16, 16, 32], [c_in, 32, 32, 64]],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        c_out_0 = 32 + 64\n\n        c_in = c_out_0\n        self.SA_modules.append(\n            PointnetSAModuleMSG(\n                npoint=256,\n                radii=[0.1, 0.2],\n                nsamples=[16, 32],\n                mlps=[[c_in, 64, 64, 128], [c_in, 64, 96, 128]],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        c_out_1 = 128 + 128\n\n        c_in = c_out_1\n        self.SA_modules.append(\n            PointnetSAModuleMSG(\n                npoint=64,\n                radii=[0.2, 0.4],\n                nsamples=[16, 32],\n                mlps=[[c_in, 128, 196, 256], [c_in, 128, 196, 256]],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        c_out_2 = 256 + 256\n\n        c_in = c_out_2\n        self.SA_modules.append(\n            PointnetSAModuleMSG(\n                npoint=16,\n                radii=[0.4, 0.8],\n                nsamples=[16, 32],\n                mlps=[[c_in, 256, 256, 512], [c_in, 256, 384, 512]],\n                use_xyz=self.hparams.use_xyz,\n            )\n        )\n        c_out_3 = 512 + 512\n\n        self.FP_modules = nn.ModuleList()\n        self.FP_modules.append(PointnetFPModule(mlp=[256 + 6, 128, 128]))\n        self.FP_modules.append(PointnetFPModule(mlp=[512 + c_out_0, 256, 256]))\n        self.FP_modules.append(PointnetFPModule(mlp=[512 + c_out_1, 512, 512]))\n        self.FP_modules.append(PointnetFPModule(mlp=[c_out_3 + c_out_2, 512, 512]))\n\n        self.fc_lyaer = nn.Sequential(\n            nn.Conv1d(128, 128, kernel_size=1, bias=False),\n            nn.BatchNorm1d(128),\n            nn.ReLU(True),\n            nn.Dropout(0.5),\n            nn.Conv1d(128, 13, kernel_size=1),\n        )\n'"
pointnet2/models/pointnet2_ssg_cls.py,10,"b'import pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim.lr_scheduler as lr_sched\nfrom pointnet2_ops.pointnet2_modules import PointnetFPModule, PointnetSAModule\nfrom torch.utils.data import DataLoader, DistributedSampler\nfrom torchvision import transforms\n\nimport pointnet2.data.data_utils as d_utils\nfrom pointnet2.data.ModelNet40Loader import ModelNet40Cls\n\n\ndef set_bn_momentum_default(bn_momentum):\n    def fn(m):\n        if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n            m.momentum = bn_momentum\n\n    return fn\n\n\nclass BNMomentumScheduler(lr_sched.LambdaLR):\n    def __init__(self, model, bn_lambda, last_epoch=-1, setter=set_bn_momentum_default):\n        if not isinstance(model, nn.Module):\n            raise RuntimeError(\n                ""Class \'{}\' is not a PyTorch nn Module"".format(type(model)._name_)\n            )\n\n        self.model = model\n        self.setter = setter\n        self.lmbd = bn_lambda\n\n        self.step(last_epoch + 1)\n        self.last_epoch = last_epoch\n\n    def step(self, epoch=None):\n        if epoch is None:\n            epoch = self.last_epoch + 1\n\n        self.last_epoch = epoch\n        self.model.apply(self.setter(self.lmbd(epoch)))\n\n    def state_dict(self):\n        return dict(last_epoch=self.last_epoch)\n\n    def load_state_dict(self, state):\n        self.last_epoch = state[""last_epoch""]\n        self.step(self.last_epoch)\n\n\nlr_clip = 1e-5\nbnm_clip = 1e-2\n\n\nclass PointNet2ClassificationSSG(pl.LightningModule):\n    def __init__(self, hparams):\n        super().__init__()\n\n        self.hparams = hparams\n\n        self._build_model()\n\n    def _build_model(self):\n        self.SA_modules = nn.ModuleList()\n        self.SA_modules.append(\n            PointnetSAModule(\n                npoint=512,\n                radius=0.2,\n                nsample=64,\n                mlp=[3, 64, 64, 128],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        self.SA_modules.append(\n            PointnetSAModule(\n                npoint=128,\n                radius=0.4,\n                nsample=64,\n                mlp=[128, 128, 128, 256],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        self.SA_modules.append(\n            PointnetSAModule(\n                mlp=[256, 256, 512, 1024], use_xyz=self.hparams.model.use_xyz\n            )\n        )\n\n        self.fc_layer = nn.Sequential(\n            nn.Linear(1024, 512, bias=False),\n            nn.BatchNorm1d(512),\n            nn.ReLU(True),\n            nn.Linear(512, 256, bias=False),\n            nn.BatchNorm1d(256),\n            nn.ReLU(True),\n            nn.Dropout(0.5),\n            nn.Linear(256, 40),\n        )\n\n    def _break_up_pc(self, pc):\n        xyz = pc[..., 0:3].contiguous()\n        features = pc[..., 3:].transpose(1, 2).contiguous() if pc.size(-1) > 3 else None\n\n        return xyz, features\n\n    def forward(self, pointcloud):\n        r""""""\n            Forward pass of the network\n\n            Parameters\n            ----------\n            pointcloud: Variable(torch.cuda.FloatTensor)\n                (B, N, 3 + input_channels) tensor\n                Point cloud to run predicts on\n                Each point in the point-cloud MUST\n                be formated as (x, y, z, features...)\n        """"""\n        xyz, features = self._break_up_pc(pointcloud)\n\n        for module in self.SA_modules:\n            xyz, features = module(xyz, features)\n\n        return self.fc_layer(features.squeeze(-1))\n\n    def training_step(self, batch, batch_idx):\n        pc, labels = batch\n\n        logits = self.forward(pc)\n        loss = F.cross_entropy(logits, labels)\n        with torch.no_grad():\n            acc = (torch.argmax(logits, dim=1) == labels).float().mean()\n\n        log = dict(train_loss=loss, train_acc=acc)\n\n        return dict(loss=loss, log=log, progress_bar=dict(train_acc=acc))\n\n    def validation_step(self, batch, batch_idx):\n        pc, labels = batch\n\n        logits = self.forward(pc)\n        loss = F.cross_entropy(logits, labels)\n        acc = (torch.argmax(logits, dim=1) == labels).float().mean()\n\n        return dict(val_loss=loss, val_acc=acc)\n\n    def validation_end(self, outputs):\n        reduced_outputs = {}\n        for k in outputs[0]:\n            for o in outputs:\n                reduced_outputs[k] = reduced_outputs.get(k, []) + [o[k]]\n\n        for k in reduced_outputs:\n            reduced_outputs[k] = torch.stack(reduced_outputs[k]).mean()\n\n        reduced_outputs.update(\n            dict(log=reduced_outputs.copy(), progress_bar=reduced_outputs.copy())\n        )\n\n        return reduced_outputs\n\n    def configure_optimizers(self):\n        lr_lbmd = lambda _: max(\n            self.hparams.optimizer.lr_decay\n            ** (\n                int(\n                    self.global_step\n                    * self.hparams.batch_size\n                    / self.hparams.optimizer.decay_step\n                )\n            ),\n            lr_clip / self.hparams.optimizer.lr,\n        )\n        bn_lbmd = lambda _: max(\n            self.hparams.optimizer.bn_momentum\n            * self.hparams.optimizer.bnm_decay\n            ** (\n                int(\n                    self.global_step\n                    * self.hparams.batch_size\n                    / self.hparams.optimizer.decay_step\n                )\n            ),\n            bnm_clip,\n        )\n\n        optimizer = torch.optim.Adam(\n            self.parameters(),\n            lr=self.hparams.optimizer.lr,\n            weight_decay=self.hparams.optimizer.weight_decay,\n        )\n        lr_scheduler = lr_sched.LambdaLR(optimizer, lr_lambda=lr_lbmd)\n        bnm_scheduler = BNMomentumScheduler(self, bn_lambda=bn_lbmd)\n\n        return [optimizer], [lr_scheduler, bnm_scheduler]\n\n    def prepare_data(self):\n        train_transforms = transforms.Compose(\n            [\n                d_utils.PointcloudToTensor(),\n                d_utils.PointcloudScale(),\n                d_utils.PointcloudRotate(),\n                d_utils.PointcloudRotatePerturbation(),\n                d_utils.PointcloudTranslate(),\n                d_utils.PointcloudJitter(),\n                d_utils.PointcloudRandomInputDropout(),\n            ]\n        )\n\n        self.train_dset = ModelNet40Cls(\n            self.hparams.num_points, transforms=train_transforms, train=True\n        )\n        self.val_dset = ModelNet40Cls(\n            self.hparams.num_points, transforms=None, train=False\n        )\n\n    def _build_dataloader(self, dset, mode):\n        return DataLoader(\n            dset,\n            batch_size=self.hparams.batch_size,\n            shuffle=mode == ""train"",\n            num_workers=4,\n            pin_memory=True,\n            drop_last=mode == ""train"",\n        )\n\n    def train_dataloader(self):\n        return self._build_dataloader(self.train_dset, mode=""train"")\n\n    def val_dataloader(self):\n        return self._build_dataloader(self.val_dset, mode=""val"")\n'"
pointnet2/models/pointnet2_ssg_sem.py,3,"b'import pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nfrom pointnet2_ops.pointnet2_modules import PointnetFPModule, PointnetSAModule\nfrom torch.utils.data import DataLoader\n\nfrom pointnet2.data import Indoor3DSemSeg\nfrom pointnet2.models.pointnet2_ssg_cls import PointNet2ClassificationSSG\n\n\nclass PointNet2SemSegSSG(PointNet2ClassificationSSG):\n    def _build_model(self):\n        self.SA_modules = nn.ModuleList()\n        self.SA_modules.append(\n            PointnetSAModule(\n                npoint=1024,\n                radius=0.1,\n                nsample=32,\n                mlp=[6, 32, 32, 64],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        self.SA_modules.append(\n            PointnetSAModule(\n                npoint=256,\n                radius=0.2,\n                nsample=32,\n                mlp=[64, 64, 64, 128],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        self.SA_modules.append(\n            PointnetSAModule(\n                npoint=64,\n                radius=0.4,\n                nsample=32,\n                mlp=[128, 128, 128, 256],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n        self.SA_modules.append(\n            PointnetSAModule(\n                npoint=16,\n                radius=0.8,\n                nsample=32,\n                mlp=[256, 256, 256, 512],\n                use_xyz=self.hparams.model.use_xyz,\n            )\n        )\n\n        self.FP_modules = nn.ModuleList()\n        self.FP_modules.append(PointnetFPModule(mlp=[128 + 6, 128, 128, 128]))\n        self.FP_modules.append(PointnetFPModule(mlp=[256 + 64, 256, 128]))\n        self.FP_modules.append(PointnetFPModule(mlp=[256 + 128, 256, 256]))\n        self.FP_modules.append(PointnetFPModule(mlp=[512 + 256, 256, 256]))\n\n        self.fc_lyaer = nn.Sequential(\n            nn.Conv1d(128, 128, kernel_size=1, bias=False),\n            nn.BatchNorm1d(128),\n            nn.ReLU(True),\n            nn.Dropout(0.5),\n            nn.Conv1d(128, 13, kernel_size=1),\n        )\n\n    def forward(self, pointcloud):\n        r""""""\n            Forward pass of the network\n\n            Parameters\n            ----------\n            pointcloud: Variable(torch.cuda.FloatTensor)\n                (B, N, 3 + input_channels) tensor\n                Point cloud to run predicts on\n                Each point in the point-cloud MUST\n                be formated as (x, y, z, features...)\n        """"""\n        xyz, features = self._break_up_pc(pointcloud)\n\n        l_xyz, l_features = [xyz], [features]\n        for i in range(len(self.SA_modules)):\n            li_xyz, li_features = self.SA_modules[i](l_xyz[i], l_features[i])\n            l_xyz.append(li_xyz)\n            l_features.append(li_features)\n\n        for i in range(-1, -(len(self.FP_modules) + 1), -1):\n            l_features[i - 1] = self.FP_modules[i](\n                l_xyz[i - 1], l_xyz[i], l_features[i - 1], l_features[i]\n            )\n\n        return self.fc_lyaer(l_features[0])\n\n    def prepare_data(self):\n        self.train_dset = Indoor3DSemSeg(self.hparams.num_points, train=True)\n        self.val_dset = Indoor3DSemSeg(self.hparams.num_points, train=False)\n'"
pointnet2_ops_lib/pointnet2_ops/__init__.py,0,b'import pointnet2_ops.pointnet2_modules\nimport pointnet2_ops.pointnet2_utils\nfrom pointnet2_ops._version import __version__\n'
pointnet2_ops_lib/pointnet2_ops/_version.py,0,"b'__version__ = ""3.0.0""\n'"
pointnet2_ops_lib/pointnet2_ops/pointnet2_modules.py,17,"b'from typing import List, Optional, Tuple\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom pointnet2_ops import pointnet2_utils\n\n\ndef build_shared_mlp(mlp_spec: List[int], bn: bool = True):\n    layers = []\n    for i in range(1, len(mlp_spec)):\n        layers.append(\n            nn.Conv2d(mlp_spec[i - 1], mlp_spec[i], kernel_size=1, bias=not bn)\n        )\n        if bn:\n            layers.append(nn.BatchNorm2d(mlp_spec[i]))\n        layers.append(nn.ReLU(True))\n\n    return nn.Sequential(*layers)\n\n\nclass _PointnetSAModuleBase(nn.Module):\n    def __init__(self):\n        super(_PointnetSAModuleBase, self).__init__()\n        self.npoint = None\n        self.groupers = None\n        self.mlps = None\n\n    def forward(\n        self, xyz: torch.Tensor, features: Optional[torch.Tensor]\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        r""""""\n        Parameters\n        ----------\n        xyz : torch.Tensor\n            (B, N, 3) tensor of the xyz coordinates of the features\n        features : torch.Tensor\n            (B, C, N) tensor of the descriptors of the the features\n\n        Returns\n        -------\n        new_xyz : torch.Tensor\n            (B, npoint, 3) tensor of the new features\' xyz\n        new_features : torch.Tensor\n            (B,  \\sum_k(mlps[k][-1]), npoint) tensor of the new_features descriptors\n        """"""\n\n        new_features_list = []\n\n        xyz_flipped = xyz.transpose(1, 2).contiguous()\n        new_xyz = (\n            pointnet2_utils.gather_operation(\n                xyz_flipped, pointnet2_utils.furthest_point_sample(xyz, self.npoint)\n            )\n            .transpose(1, 2)\n            .contiguous()\n            if self.npoint is not None\n            else None\n        )\n\n        for i in range(len(self.groupers)):\n            new_features = self.groupers[i](\n                xyz, new_xyz, features\n            )  # (B, C, npoint, nsample)\n\n            new_features = self.mlps[i](new_features)  # (B, mlp[-1], npoint, nsample)\n            new_features = F.max_pool2d(\n                new_features, kernel_size=[1, new_features.size(3)]\n            )  # (B, mlp[-1], npoint, 1)\n            new_features = new_features.squeeze(-1)  # (B, mlp[-1], npoint)\n\n            new_features_list.append(new_features)\n\n        return new_xyz, torch.cat(new_features_list, dim=1)\n\n\nclass PointnetSAModuleMSG(_PointnetSAModuleBase):\n    r""""""Pointnet set abstrction layer with multiscale grouping\n\n    Parameters\n    ----------\n    npoint : int\n        Number of features\n    radii : list of float32\n        list of radii to group with\n    nsamples : list of int32\n        Number of samples in each ball query\n    mlps : list of list of int32\n        Spec of the pointnet before the global max_pool for each scale\n    bn : bool\n        Use batchnorm\n    """"""\n\n    def __init__(self, npoint, radii, nsamples, mlps, bn=True, use_xyz=True):\n        # type: (PointnetSAModuleMSG, int, List[float], List[int], List[List[int]], bool, bool) -> None\n        super(PointnetSAModuleMSG, self).__init__()\n\n        assert len(radii) == len(nsamples) == len(mlps)\n\n        self.npoint = npoint\n        self.groupers = nn.ModuleList()\n        self.mlps = nn.ModuleList()\n        for i in range(len(radii)):\n            radius = radii[i]\n            nsample = nsamples[i]\n            self.groupers.append(\n                pointnet2_utils.QueryAndGroup(radius, nsample, use_xyz=use_xyz)\n                if npoint is not None\n                else pointnet2_utils.GroupAll(use_xyz)\n            )\n            mlp_spec = mlps[i]\n            if use_xyz:\n                mlp_spec[0] += 3\n\n            self.mlps.append(build_shared_mlp(mlp_spec, bn))\n\n\nclass PointnetSAModule(PointnetSAModuleMSG):\n    r""""""Pointnet set abstrction layer\n\n    Parameters\n    ----------\n    npoint : int\n        Number of features\n    radius : float\n        Radius of ball\n    nsample : int\n        Number of samples in the ball query\n    mlp : list\n        Spec of the pointnet before the global max_pool\n    bn : bool\n        Use batchnorm\n    """"""\n\n    def __init__(\n        self, mlp, npoint=None, radius=None, nsample=None, bn=True, use_xyz=True\n    ):\n        # type: (PointnetSAModule, List[int], int, float, int, bool, bool) -> None\n        super(PointnetSAModule, self).__init__(\n            mlps=[mlp],\n            npoint=npoint,\n            radii=[radius],\n            nsamples=[nsample],\n            bn=bn,\n            use_xyz=use_xyz,\n        )\n\n\nclass PointnetFPModule(nn.Module):\n    r""""""Propigates the features of one set to another\n\n    Parameters\n    ----------\n    mlp : list\n        Pointnet module parameters\n    bn : bool\n        Use batchnorm\n    """"""\n\n    def __init__(self, mlp, bn=True):\n        # type: (PointnetFPModule, List[int], bool) -> None\n        super(PointnetFPModule, self).__init__()\n        self.mlp = build_shared_mlp(mlp, bn=bn)\n\n    def forward(self, unknown, known, unknow_feats, known_feats):\n        # type: (PointnetFPModule, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor) -> torch.Tensor\n        r""""""\n        Parameters\n        ----------\n        unknown : torch.Tensor\n            (B, n, 3) tensor of the xyz positions of the unknown features\n        known : torch.Tensor\n            (B, m, 3) tensor of the xyz positions of the known features\n        unknow_feats : torch.Tensor\n            (B, C1, n) tensor of the features to be propigated to\n        known_feats : torch.Tensor\n            (B, C2, m) tensor of features to be propigated\n\n        Returns\n        -------\n        new_features : torch.Tensor\n            (B, mlp[-1], n) tensor of the features of the unknown features\n        """"""\n\n        if known is not None:\n            dist, idx = pointnet2_utils.three_nn(unknown, known)\n            dist_recip = 1.0 / (dist + 1e-8)\n            norm = torch.sum(dist_recip, dim=2, keepdim=True)\n            weight = dist_recip / norm\n\n            interpolated_feats = pointnet2_utils.three_interpolate(\n                known_feats, idx, weight\n            )\n        else:\n            interpolated_feats = known_feats.expand(\n                *(known_feats.size()[0:2] + [unknown.size(1)])\n            )\n\n        if unknow_feats is not None:\n            new_features = torch.cat(\n                [interpolated_feats, unknow_feats], dim=1\n            )  # (B, C2 + C1, n)\n        else:\n            new_features = interpolated_feats\n\n        new_features = new_features.unsqueeze(-1)\n        new_features = self.mlp(new_features)\n\n        return new_features.squeeze(-1)\n'"
pointnet2_ops_lib/pointnet2_ops/pointnet2_utils.py,49,"b'import torch\nimport torch.nn as nn\nimport warnings\nfrom torch.autograd import Function\nfrom typing import *\n\ntry:\n    import pointnet2_ops._ext as _ext\nexcept ImportError:\n    from torch.utils.cpp_extension import load\n    import glob\n    import os.path as osp\n    import os\n\n    warnings.warn(""Unable to load pointnet2_ops cpp extension. JIT Compiling."")\n\n    _ext_src_root = osp.join(osp.dirname(__file__), ""_ext-src"")\n    _ext_sources = glob.glob(osp.join(_ext_src_root, ""src"", ""*.cpp"")) + glob.glob(\n        osp.join(_ext_src_root, ""src"", ""*.cu"")\n    )\n    _ext_headers = glob.glob(osp.join(_ext_src_root, ""include"", ""*""))\n\n    os.environ[""TORCH_CUDA_ARCH_LIST""] = ""3.7+PTX;5.0;6.0;6.1;6.2;7.0;7.5""\n    _ext = load(\n        ""_ext"",\n        sources=_ext_sources,\n        extra_include_paths=[osp.join(_ext_src_root, ""include"")],\n        extra_cflags=[""-O3""],\n        extra_cuda_cflags=[""-O3"", ""-Xfatbin"", ""-compress-all""],\n        with_cuda=True,\n    )\n\n\nclass FurthestPointSampling(Function):\n    @staticmethod\n    def forward(ctx, xyz, npoint):\n        # type: (Any, torch.Tensor, int) -> torch.Tensor\n        r""""""\n        Uses iterative furthest point sampling to select a set of npoint features that have the largest\n        minimum distance\n\n        Parameters\n        ----------\n        xyz : torch.Tensor\n            (B, N, 3) tensor where N > npoint\n        npoint : int32\n            number of features in the sampled set\n\n        Returns\n        -------\n        torch.Tensor\n            (B, npoint) tensor containing the set\n        """"""\n        out = _ext.furthest_point_sampling(xyz, npoint)\n\n        ctx.mark_non_differentiable(out)\n\n        return out\n\n    @staticmethod\n    def backward(ctx, grad_out):\n        return ()\n\n\nfurthest_point_sample = FurthestPointSampling.apply\n\n\nclass GatherOperation(Function):\n    @staticmethod\n    def forward(ctx, features, idx):\n        # type: (Any, torch.Tensor, torch.Tensor) -> torch.Tensor\n        r""""""\n\n        Parameters\n        ----------\n        features : torch.Tensor\n            (B, C, N) tensor\n\n        idx : torch.Tensor\n            (B, npoint) tensor of the features to gather\n\n        Returns\n        -------\n        torch.Tensor\n            (B, C, npoint) tensor\n        """"""\n\n        ctx.save_for_backward(idx, features)\n\n        return _ext.gather_points(features, idx)\n\n    @staticmethod\n    def backward(ctx, grad_out):\n        idx, features = ctx.saved_tensors\n        N = features.size(2)\n\n        grad_features = _ext.gather_points_grad(grad_out.contiguous(), idx, N)\n        return grad_features, None\n\n\ngather_operation = GatherOperation.apply\n\n\nclass ThreeNN(Function):\n    @staticmethod\n    def forward(ctx, unknown, known):\n        # type: (Any, torch.Tensor, torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]\n        r""""""\n            Find the three nearest neighbors of unknown in known\n        Parameters\n        ----------\n        unknown : torch.Tensor\n            (B, n, 3) tensor of known features\n        known : torch.Tensor\n            (B, m, 3) tensor of unknown features\n\n        Returns\n        -------\n        dist : torch.Tensor\n            (B, n, 3) l2 distance to the three nearest neighbors\n        idx : torch.Tensor\n            (B, n, 3) index of 3 nearest neighbors\n        """"""\n        dist2, idx = _ext.three_nn(unknown, known)\n        dist = torch.sqrt(dist2)\n\n        ctx.mark_non_differentiable(dist, idx)\n\n        return dist, idx\n\n    @staticmethod\n    def backward(ctx, grad_dist, grad_idx):\n        return ()\n\n\nthree_nn = ThreeNN.apply\n\n\nclass ThreeInterpolate(Function):\n    @staticmethod\n    def forward(ctx, features, idx, weight):\n        # type(Any, torch.Tensor, torch.Tensor, torch.Tensor) -> Torch.Tensor\n        r""""""\n            Performs weight linear interpolation on 3 features\n        Parameters\n        ----------\n        features : torch.Tensor\n            (B, c, m) Features descriptors to be interpolated from\n        idx : torch.Tensor\n            (B, n, 3) three nearest neighbors of the target features in features\n        weight : torch.Tensor\n            (B, n, 3) weights\n\n        Returns\n        -------\n        torch.Tensor\n            (B, c, n) tensor of the interpolated features\n        """"""\n        ctx.save_for_backward(idx, weight, features)\n\n        return _ext.three_interpolate(features, idx, weight)\n\n    @staticmethod\n    def backward(ctx, grad_out):\n        # type: (Any, torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n        r""""""\n        Parameters\n        ----------\n        grad_out : torch.Tensor\n            (B, c, n) tensor with gradients of ouputs\n\n        Returns\n        -------\n        grad_features : torch.Tensor\n            (B, c, m) tensor with gradients of features\n\n        None\n\n        None\n        """"""\n        idx, weight, features = ctx.saved_tensors\n        m = features.size(2)\n\n        grad_features = _ext.three_interpolate_grad(\n            grad_out.contiguous(), idx, weight, m\n        )\n\n        return grad_features, torch.zeros_like(idx), torch.zeros_like(weight)\n\n\nthree_interpolate = ThreeInterpolate.apply\n\n\nclass GroupingOperation(Function):\n    @staticmethod\n    def forward(ctx, features, idx):\n        # type: (Any, torch.Tensor, torch.Tensor) -> torch.Tensor\n        r""""""\n\n        Parameters\n        ----------\n        features : torch.Tensor\n            (B, C, N) tensor of features to group\n        idx : torch.Tensor\n            (B, npoint, nsample) tensor containing the indicies of features to group with\n\n        Returns\n        -------\n        torch.Tensor\n            (B, C, npoint, nsample) tensor\n        """"""\n        ctx.save_for_backward(idx, features)\n\n        return _ext.group_points(features, idx)\n\n    @staticmethod\n    def backward(ctx, grad_out):\n        # type: (Any, torch.tensor) -> Tuple[torch.Tensor, torch.Tensor]\n        r""""""\n\n        Parameters\n        ----------\n        grad_out : torch.Tensor\n            (B, C, npoint, nsample) tensor of the gradients of the output from forward\n\n        Returns\n        -------\n        torch.Tensor\n            (B, C, N) gradient of the features\n        None\n        """"""\n        idx, features = ctx.saved_tensors\n        N = features.size(2)\n\n        grad_features = _ext.group_points_grad(grad_out.contiguous(), idx, N)\n\n        return grad_features, torch.zeros_like(idx)\n\n\ngrouping_operation = GroupingOperation.apply\n\n\nclass BallQuery(Function):\n    @staticmethod\n    def forward(ctx, radius, nsample, xyz, new_xyz):\n        # type: (Any, float, int, torch.Tensor, torch.Tensor) -> torch.Tensor\n        r""""""\n\n        Parameters\n        ----------\n        radius : float\n            radius of the balls\n        nsample : int\n            maximum number of features in the balls\n        xyz : torch.Tensor\n            (B, N, 3) xyz coordinates of the features\n        new_xyz : torch.Tensor\n            (B, npoint, 3) centers of the ball query\n\n        Returns\n        -------\n        torch.Tensor\n            (B, npoint, nsample) tensor with the indicies of the features that form the query balls\n        """"""\n        output = _ext.ball_query(new_xyz, xyz, radius, nsample)\n\n        ctx.mark_non_differentiable(output)\n\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_out):\n        return ()\n\n\nball_query = BallQuery.apply\n\n\nclass QueryAndGroup(nn.Module):\n    r""""""\n    Groups with a ball query of radius\n\n    Parameters\n    ---------\n    radius : float32\n        Radius of ball\n    nsample : int32\n        Maximum number of features to gather in the ball\n    """"""\n\n    def __init__(self, radius, nsample, use_xyz=True):\n        # type: (QueryAndGroup, float, int, bool) -> None\n        super(QueryAndGroup, self).__init__()\n        self.radius, self.nsample, self.use_xyz = radius, nsample, use_xyz\n\n    def forward(self, xyz, new_xyz, features=None):\n        # type: (QueryAndGroup, torch.Tensor. torch.Tensor, torch.Tensor) -> Tuple[Torch.Tensor]\n        r""""""\n        Parameters\n        ----------\n        xyz : torch.Tensor\n            xyz coordinates of the features (B, N, 3)\n        new_xyz : torch.Tensor\n            centriods (B, npoint, 3)\n        features : torch.Tensor\n            Descriptors of the features (B, C, N)\n\n        Returns\n        -------\n        new_features : torch.Tensor\n            (B, 3 + C, npoint, nsample) tensor\n        """"""\n\n        idx = ball_query(self.radius, self.nsample, xyz, new_xyz)\n        xyz_trans = xyz.transpose(1, 2).contiguous()\n        grouped_xyz = grouping_operation(xyz_trans, idx)  # (B, 3, npoint, nsample)\n        grouped_xyz -= new_xyz.transpose(1, 2).unsqueeze(-1)\n\n        if features is not None:\n            grouped_features = grouping_operation(features, idx)\n            if self.use_xyz:\n                new_features = torch.cat(\n                    [grouped_xyz, grouped_features], dim=1\n                )  # (B, C + 3, npoint, nsample)\n            else:\n                new_features = grouped_features\n        else:\n            assert (\n                self.use_xyz\n            ), ""Cannot have not features and not use xyz as a feature!""\n            new_features = grouped_xyz\n\n        return new_features\n\n\nclass GroupAll(nn.Module):\n    r""""""\n    Groups all features\n\n    Parameters\n    ---------\n    """"""\n\n    def __init__(self, use_xyz=True):\n        # type: (GroupAll, bool) -> None\n        super(GroupAll, self).__init__()\n        self.use_xyz = use_xyz\n\n    def forward(self, xyz, new_xyz, features=None):\n        # type: (GroupAll, torch.Tensor, torch.Tensor, torch.Tensor) -> Tuple[torch.Tensor]\n        r""""""\n        Parameters\n        ----------\n        xyz : torch.Tensor\n            xyz coordinates of the features (B, N, 3)\n        new_xyz : torch.Tensor\n            Ignored\n        features : torch.Tensor\n            Descriptors of the features (B, C, N)\n\n        Returns\n        -------\n        new_features : torch.Tensor\n            (B, C + 3, 1, N) tensor\n        """"""\n\n        grouped_xyz = xyz.transpose(1, 2).unsqueeze(2)\n        if features is not None:\n            grouped_features = features.unsqueeze(2)\n            if self.use_xyz:\n                new_features = torch.cat(\n                    [grouped_xyz, grouped_features], dim=1\n                )  # (B, 3 + C, 1, N)\n            else:\n                new_features = grouped_features\n        else:\n            new_features = grouped_xyz\n\n        return new_features\n'"
