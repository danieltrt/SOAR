file_path,api_count,code
criteria.py,2,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass MaskedMSELoss(nn.Module):\n    def __init__(self):\n        super(MaskedMSELoss, self).__init__()\n\n    def forward(self, pred, target):\n        assert pred.dim() == target.dim(), ""inconsistent dimensions""\n        valid_mask = (target>0).detach()\n        diff = target - pred\n        diff = diff[valid_mask]\n        self.loss = (diff ** 2).mean()\n        return self.loss\n\nclass MaskedL1Loss(nn.Module):\n    def __init__(self):\n        super(MaskedL1Loss, self).__init__()\n\n    def forward(self, pred, target):\n        assert pred.dim() == target.dim(), ""inconsistent dimensions""\n        valid_mask = (target>0).detach()\n        diff = target - pred\n        diff = diff[valid_mask]\n        self.loss = diff.abs().mean()\n        return self.loss'"
main.py,13,"b'import os\nimport time\nimport csv\nimport numpy as np\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.optim\ncudnn.benchmark = True\n\nfrom models import ResNet\nfrom metrics import AverageMeter, Result\nfrom dataloaders.dense_to_sparse import UniformSampling, SimulatedStereo\nimport criteria\nimport utils\n\nargs = utils.parse_command()\nprint(args)\n\nfieldnames = [\'mse\', \'rmse\', \'absrel\', \'lg10\', \'mae\',\n                \'delta1\', \'delta2\', \'delta3\',\n                \'data_time\', \'gpu_time\']\nbest_result = Result()\nbest_result.set_to_worst()\n\ndef create_data_loaders(args):\n    # Data loading code\n    print(""=> creating data loaders ..."")\n    traindir = os.path.join(\'data\', args.data, \'train\')\n    valdir = os.path.join(\'data\', args.data, \'val\')\n    train_loader = None\n    val_loader = None\n\n    # sparsifier is a class for generating random sparse depth input from the ground truth\n    sparsifier = None\n    max_depth = args.max_depth if args.max_depth >= 0.0 else np.inf\n    if args.sparsifier == UniformSampling.name:\n        sparsifier = UniformSampling(num_samples=args.num_samples, max_depth=max_depth)\n    elif args.sparsifier == SimulatedStereo.name:\n        sparsifier = SimulatedStereo(num_samples=args.num_samples, max_depth=max_depth)\n\n    if args.data == \'nyudepthv2\':\n        from dataloaders.nyu_dataloader import NYUDataset\n        if not args.evaluate:\n            train_dataset = NYUDataset(traindir, type=\'train\',\n                modality=args.modality, sparsifier=sparsifier)\n        val_dataset = NYUDataset(valdir, type=\'val\',\n            modality=args.modality, sparsifier=sparsifier)\n\n    elif args.data == \'kitti\':\n        from dataloaders.kitti_dataloader import KITTIDataset\n        if not args.evaluate:\n            train_dataset = KITTIDataset(traindir, type=\'train\',\n                modality=args.modality, sparsifier=sparsifier)\n        val_dataset = KITTIDataset(valdir, type=\'val\',\n            modality=args.modality, sparsifier=sparsifier)\n\n    else:\n        raise RuntimeError(\'Dataset not found.\' +\n                           \'The dataset must be either of nyudepthv2 or kitti.\')\n\n    # set batch size to be 1 for validation\n    val_loader = torch.utils.data.DataLoader(val_dataset,\n        batch_size=1, shuffle=False, num_workers=args.workers, pin_memory=True)\n\n    # put construction of train loader here, for those who are interested in testing only\n    if not args.evaluate:\n        train_loader = torch.utils.data.DataLoader(\n            train_dataset, batch_size=args.batch_size, shuffle=True,\n            num_workers=args.workers, pin_memory=True, sampler=None,\n            worker_init_fn=lambda work_id:np.random.seed(work_id))\n            # worker_init_fn ensures different sampling patterns for each data loading thread\n\n    print(""=> data loaders created."")\n    return train_loader, val_loader\n\ndef main():\n    global args, best_result, output_directory, train_csv, test_csv\n\n    # evaluation mode\n    start_epoch = 0\n    if args.evaluate:\n        assert os.path.isfile(args.evaluate), \\\n        ""=> no best model found at \'{}\'"".format(args.evaluate)\n        print(""=> loading best model \'{}\'"".format(args.evaluate))\n        checkpoint = torch.load(args.evaluate)\n        output_directory = os.path.dirname(args.evaluate)\n        args = checkpoint[\'args\']\n        start_epoch = checkpoint[\'epoch\'] + 1\n        best_result = checkpoint[\'best_result\']\n        model = checkpoint[\'model\']\n        print(""=> loaded best model (epoch {})"".format(checkpoint[\'epoch\']))\n        _, val_loader = create_data_loaders(args)\n        args.evaluate = True\n        validate(val_loader, model, checkpoint[\'epoch\'], write_to_file=False)\n        return\n\n    # optionally resume from a checkpoint\n    elif args.resume:\n        chkpt_path = args.resume\n        assert os.path.isfile(chkpt_path), \\\n            ""=> no checkpoint found at \'{}\'"".format(chkpt_path)\n        print(""=> loading checkpoint \'{}\'"".format(chkpt_path))\n        checkpoint = torch.load(chkpt_path)\n        args = checkpoint[\'args\']\n        start_epoch = checkpoint[\'epoch\'] + 1\n        best_result = checkpoint[\'best_result\']\n        model = checkpoint[\'model\']\n        optimizer = checkpoint[\'optimizer\']\n        output_directory = os.path.dirname(os.path.abspath(chkpt_path))\n        print(""=> loaded checkpoint (epoch {})"".format(checkpoint[\'epoch\']))\n        train_loader, val_loader = create_data_loaders(args)\n        args.resume = True\n\n    # create new model\n    else:\n        train_loader, val_loader = create_data_loaders(args)\n        print(""=> creating Model ({}-{}) ..."".format(args.arch, args.decoder))\n        in_channels = len(args.modality)\n        if args.arch == \'resnet50\':\n            model = ResNet(layers=50, decoder=args.decoder, output_size=train_loader.dataset.output_size,\n                in_channels=in_channels, pretrained=args.pretrained)\n        elif args.arch == \'resnet18\':\n            model = ResNet(layers=18, decoder=args.decoder, output_size=train_loader.dataset.output_size,\n                in_channels=in_channels, pretrained=args.pretrained)\n        print(""=> model created."")\n        optimizer = torch.optim.SGD(model.parameters(), args.lr, \\\n            momentum=args.momentum, weight_decay=args.weight_decay)\n\n        # model = torch.nn.DataParallel(model).cuda() # for multi-gpu training\n        model = model.cuda()\n\n    # define loss function (criterion) and optimizer\n    if args.criterion == \'l2\':\n        criterion = criteria.MaskedMSELoss().cuda()\n    elif args.criterion == \'l1\':\n        criterion = criteria.MaskedL1Loss().cuda()\n\n    # create results folder, if not already exists\n    output_directory = utils.get_output_directory(args)\n    if not os.path.exists(output_directory):\n        os.makedirs(output_directory)\n    train_csv = os.path.join(output_directory, \'train.csv\')\n    test_csv = os.path.join(output_directory, \'test.csv\')\n    best_txt = os.path.join(output_directory, \'best.txt\')\n\n    # create new csv files with only header\n    if not args.resume:\n        with open(train_csv, \'w\') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n            writer.writeheader()\n        with open(test_csv, \'w\') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n            writer.writeheader()\n\n    for epoch in range(start_epoch, args.epochs):\n        utils.adjust_learning_rate(optimizer, epoch, args.lr)\n        train(train_loader, model, criterion, optimizer, epoch) # train for one epoch\n        result, img_merge = validate(val_loader, model, epoch) # evaluate on validation set\n\n        # remember best rmse and save checkpoint\n        is_best = result.rmse < best_result.rmse\n        if is_best:\n            best_result = result\n            with open(best_txt, \'w\') as txtfile:\n                txtfile.write(""epoch={}\\nmse={:.3f}\\nrmse={:.3f}\\nabsrel={:.3f}\\nlg10={:.3f}\\nmae={:.3f}\\ndelta1={:.3f}\\nt_gpu={:.4f}\\n"".\n                    format(epoch, result.mse, result.rmse, result.absrel, result.lg10, result.mae, result.delta1, result.gpu_time))\n            if img_merge is not None:\n                img_filename = output_directory + \'/comparison_best.png\'\n                utils.save_image(img_merge, img_filename)\n\n        utils.save_checkpoint({\n            \'args\': args,\n            \'epoch\': epoch,\n            \'arch\': args.arch,\n            \'model\': model,\n            \'best_result\': best_result,\n            \'optimizer\' : optimizer,\n        }, is_best, epoch, output_directory)\n\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    average_meter = AverageMeter()\n    model.train() # switch to train mode\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n\n        input, target = input.cuda(), target.cuda()\n        torch.cuda.synchronize()\n        data_time = time.time() - end\n\n        # compute pred\n        end = time.time()\n        pred = model(input)\n        loss = criterion(pred, target)\n        optimizer.zero_grad()\n        loss.backward() # compute gradient and do SGD step\n        optimizer.step()\n        torch.cuda.synchronize()\n        gpu_time = time.time() - end\n\n        # measure accuracy and record loss\n        result = Result()\n        result.evaluate(pred.data, target.data)\n        average_meter.update(result, gpu_time, data_time, input.size(0))\n        end = time.time()\n\n        if (i + 1) % args.print_freq == 0:\n            print(\'=> output: {}\'.format(output_directory))\n            print(\'Train Epoch: {0} [{1}/{2}]\\t\'\n                  \'t_Data={data_time:.3f}({average.data_time:.3f}) \'\n                  \'t_GPU={gpu_time:.3f}({average.gpu_time:.3f})\\n\\t\'\n                  \'RMSE={result.rmse:.2f}({average.rmse:.2f}) \'\n                  \'MAE={result.mae:.2f}({average.mae:.2f}) \'\n                  \'Delta1={result.delta1:.3f}({average.delta1:.3f}) \'\n                  \'REL={result.absrel:.3f}({average.absrel:.3f}) \'\n                  \'Lg10={result.lg10:.3f}({average.lg10:.3f}) \'.format(\n                  epoch, i+1, len(train_loader), data_time=data_time,\n                  gpu_time=gpu_time, result=result, average=average_meter.average()))\n\n    avg = average_meter.average()\n    with open(train_csv, \'a\') as csvfile:\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        writer.writerow({\'mse\': avg.mse, \'rmse\': avg.rmse, \'absrel\': avg.absrel, \'lg10\': avg.lg10,\n            \'mae\': avg.mae, \'delta1\': avg.delta1, \'delta2\': avg.delta2, \'delta3\': avg.delta3,\n            \'gpu_time\': avg.gpu_time, \'data_time\': avg.data_time})\n\n\ndef validate(val_loader, model, epoch, write_to_file=True):\n    average_meter = AverageMeter()\n    model.eval() # switch to evaluate mode\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        input, target = input.cuda(), target.cuda()\n        torch.cuda.synchronize()\n        data_time = time.time() - end\n\n        # compute output\n        end = time.time()\n        with torch.no_grad():\n            pred = model(input)\n        torch.cuda.synchronize()\n        gpu_time = time.time() - end\n\n        # measure accuracy and record loss\n        result = Result()\n        result.evaluate(pred.data, target.data)\n        average_meter.update(result, gpu_time, data_time, input.size(0))\n        end = time.time()\n\n        # save 8 images for visualization\n        skip = 50\n        if args.modality == \'d\':\n            img_merge = None\n        else:\n            if args.modality == \'rgb\':\n                rgb = input\n            elif args.modality == \'rgbd\':\n                rgb = input[:,:3,:,:]\n                depth = input[:,3:,:,:]\n\n            if i == 0:\n                if args.modality == \'rgbd\':\n                    img_merge = utils.merge_into_row_with_gt(rgb, depth, target, pred)\n                else:\n                    img_merge = utils.merge_into_row(rgb, target, pred)\n            elif (i < 8*skip) and (i % skip == 0):\n                if args.modality == \'rgbd\':\n                    row = utils.merge_into_row_with_gt(rgb, depth, target, pred)\n                else:\n                    row = utils.merge_into_row(rgb, target, pred)\n                img_merge = utils.add_row(img_merge, row)\n            elif i == 8*skip:\n                filename = output_directory + \'/comparison_\' + str(epoch) + \'.png\'\n                utils.save_image(img_merge, filename)\n\n        if (i+1) % args.print_freq == 0:\n            print(\'Test: [{0}/{1}]\\t\'\n                  \'t_GPU={gpu_time:.3f}({average.gpu_time:.3f})\\n\\t\'\n                  \'RMSE={result.rmse:.2f}({average.rmse:.2f}) \'\n                  \'MAE={result.mae:.2f}({average.mae:.2f}) \'\n                  \'Delta1={result.delta1:.3f}({average.delta1:.3f}) \'\n                  \'REL={result.absrel:.3f}({average.absrel:.3f}) \'\n                  \'Lg10={result.lg10:.3f}({average.lg10:.3f}) \'.format(\n                   i+1, len(val_loader), gpu_time=gpu_time, result=result, average=average_meter.average()))\n\n    avg = average_meter.average()\n\n    print(\'\\n*\\n\'\n        \'RMSE={average.rmse:.3f}\\n\'\n        \'MAE={average.mae:.3f}\\n\'\n        \'Delta1={average.delta1:.3f}\\n\'\n        \'REL={average.absrel:.3f}\\n\'\n        \'Lg10={average.lg10:.3f}\\n\'\n        \'t_GPU={time:.3f}\\n\'.format(\n        average=avg, time=avg.gpu_time))\n\n    if write_to_file:\n        with open(test_csv, \'a\') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n            writer.writerow({\'mse\': avg.mse, \'rmse\': avg.rmse, \'absrel\': avg.absrel, \'lg10\': avg.lg10,\n                \'mae\': avg.mae, \'delta1\': avg.delta1, \'delta2\': avg.delta2, \'delta3\': avg.delta3,\n                \'data_time\': avg.data_time, \'gpu_time\': avg.gpu_time})\n    return avg, img_merge\n\nif __name__ == \'__main__\':\n    main()\n'"
metrics.py,4,"b'import torch\nimport math\nimport numpy as np\n\ndef log10(x):\n    """"""Convert a new tensor with the base-10 logarithm of the elements of x. """"""\n    return torch.log(x) / math.log(10)\n\nclass Result(object):\n    def __init__(self):\n        self.irmse, self.imae = 0, 0\n        self.mse, self.rmse, self.mae = 0, 0, 0\n        self.absrel, self.lg10 = 0, 0\n        self.delta1, self.delta2, self.delta3 = 0, 0, 0\n        self.data_time, self.gpu_time = 0, 0\n\n    def set_to_worst(self):\n        self.irmse, self.imae = np.inf, np.inf\n        self.mse, self.rmse, self.mae = np.inf, np.inf, np.inf\n        self.absrel, self.lg10 = np.inf, np.inf\n        self.delta1, self.delta2, self.delta3 = 0, 0, 0\n        self.data_time, self.gpu_time = 0, 0\n\n    def update(self, irmse, imae, mse, rmse, mae, absrel, lg10, delta1, delta2, delta3, gpu_time, data_time):\n        self.irmse, self.imae = irmse, imae\n        self.mse, self.rmse, self.mae = mse, rmse, mae\n        self.absrel, self.lg10 = absrel, lg10\n        self.delta1, self.delta2, self.delta3 = delta1, delta2, delta3\n        self.data_time, self.gpu_time = data_time, gpu_time\n\n    def evaluate(self, output, target):\n        valid_mask = target>0\n        output = output[valid_mask]\n        target = target[valid_mask]\n\n        abs_diff = (output - target).abs()\n\n        self.mse = float((torch.pow(abs_diff, 2)).mean())\n        self.rmse = math.sqrt(self.mse)\n        self.mae = float(abs_diff.mean())\n        self.lg10 = float((log10(output) - log10(target)).abs().mean())\n        self.absrel = float((abs_diff / target).mean())\n\n        maxRatio = torch.max(output / target, target / output)\n        self.delta1 = float((maxRatio < 1.25).float().mean())\n        self.delta2 = float((maxRatio < 1.25 ** 2).float().mean())\n        self.delta3 = float((maxRatio < 1.25 ** 3).float().mean())\n        self.data_time = 0\n        self.gpu_time = 0\n\n        inv_output = 1 / output\n        inv_target = 1 / target\n        abs_inv_diff = (inv_output - inv_target).abs()\n        self.irmse = math.sqrt((torch.pow(abs_inv_diff, 2)).mean())\n        self.imae = float(abs_inv_diff.mean())\n\n\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.count = 0.0\n\n        self.sum_irmse, self.sum_imae = 0, 0\n        self.sum_mse, self.sum_rmse, self.sum_mae = 0, 0, 0\n        self.sum_absrel, self.sum_lg10 = 0, 0\n        self.sum_delta1, self.sum_delta2, self.sum_delta3 = 0, 0, 0\n        self.sum_data_time, self.sum_gpu_time = 0, 0\n\n    def update(self, result, gpu_time, data_time, n=1):\n        self.count += n\n\n        self.sum_irmse += n*result.irmse\n        self.sum_imae += n*result.imae\n        self.sum_mse += n*result.mse\n        self.sum_rmse += n*result.rmse\n        self.sum_mae += n*result.mae\n        self.sum_absrel += n*result.absrel\n        self.sum_lg10 += n*result.lg10\n        self.sum_delta1 += n*result.delta1\n        self.sum_delta2 += n*result.delta2\n        self.sum_delta3 += n*result.delta3\n        self.sum_data_time += n*data_time\n        self.sum_gpu_time += n*gpu_time\n\n    def average(self):\n        avg = Result()\n        avg.update(\n            self.sum_irmse / self.count, self.sum_imae / self.count,\n            self.sum_mse / self.count, self.sum_rmse / self.count, self.sum_mae / self.count, \n            self.sum_absrel / self.count, self.sum_lg10 / self.count,\n            self.sum_delta1 / self.count, self.sum_delta2 / self.count, self.sum_delta3 / self.count,\n            self.sum_gpu_time / self.count, self.sum_data_time / self.count)\n        return avg'"
models.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models\nimport collections\nimport math\n\nclass Unpool(nn.Module):\n    # Unpool: 2*2 unpooling with zero padding\n    def __init__(self, num_channels, stride=2):\n        super(Unpool, self).__init__()\n\n        self.num_channels = num_channels\n        self.stride = stride\n\n        # create kernel [1, 0; 0, 0]\n        self.weights = torch.autograd.Variable(torch.zeros(num_channels, 1, stride, stride).cuda()) # currently not compatible with running on CPU\n        self.weights[:,:,0,0] = 1\n\n    def forward(self, x):\n        return F.conv_transpose2d(x, self.weights, stride=self.stride, groups=self.num_channels)\n\ndef weights_init(m):\n    # Initialize filters with Gaussian random weights\n    if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif isinstance(m, nn.ConvTranspose2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n\nclass Decoder(nn.Module):\n    # Decoder is the base class for all decoders\n\n    names = [\'deconv2\', \'deconv3\', \'upconv\', \'upproj\']\n\n    def __init__(self):\n        super(Decoder, self).__init__()\n\n        self.layer1 = None\n        self.layer2 = None\n        self.layer3 = None\n        self.layer4 = None\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\nclass DeConv(Decoder):\n    def __init__(self, in_channels, kernel_size):\n        assert kernel_size>=2, ""kernel_size out of range: {}"".format(kernel_size)\n        super(DeConv, self).__init__()\n\n        def convt(in_channels):\n            stride = 2\n            padding = (kernel_size - 1) // 2\n            output_padding = kernel_size % 2\n            assert -2 - 2*padding + kernel_size + output_padding == 0, ""deconv parameters incorrect""\n\n            module_name = ""deconv{}"".format(kernel_size)\n            return nn.Sequential(collections.OrderedDict([\n                  (module_name, nn.ConvTranspose2d(in_channels,in_channels//2,kernel_size,\n                        stride,padding,output_padding,bias=False)),\n                  (\'batchnorm\', nn.BatchNorm2d(in_channels//2)),\n                  (\'relu\',      nn.ReLU(inplace=True)),\n                ]))\n\n        self.layer1 = convt(in_channels)\n        self.layer2 = convt(in_channels // 2)\n        self.layer3 = convt(in_channels // (2 ** 2))\n        self.layer4 = convt(in_channels // (2 ** 3))\n\nclass UpConv(Decoder):\n    # UpConv decoder consists of 4 upconv modules with decreasing number of channels and increasing feature map size\n    def upconv_module(self, in_channels):\n        # UpConv module: unpool -> 5*5 conv -> batchnorm -> ReLU\n        upconv = nn.Sequential(collections.OrderedDict([\n          (\'unpool\',    Unpool(in_channels)),\n          (\'conv\',      nn.Conv2d(in_channels,in_channels//2,kernel_size=5,stride=1,padding=2,bias=False)),\n          (\'batchnorm\', nn.BatchNorm2d(in_channels//2)),\n          (\'relu\',      nn.ReLU()),\n        ]))\n        return upconv\n\n    def __init__(self, in_channels):\n        super(UpConv, self).__init__()\n        self.layer1 = self.upconv_module(in_channels)\n        self.layer2 = self.upconv_module(in_channels//2)\n        self.layer3 = self.upconv_module(in_channels//4)\n        self.layer4 = self.upconv_module(in_channels//8)\n\nclass UpProj(Decoder):\n    # UpProj decoder consists of 4 upproj modules with decreasing number of channels and increasing feature map size\n\n    class UpProjModule(nn.Module):\n        # UpProj module has two branches, with a Unpool at the start and a ReLu at the end\n        #   upper branch: 5*5 conv -> batchnorm -> ReLU -> 3*3 conv -> batchnorm\n        #   bottom branch: 5*5 conv -> batchnorm\n\n        def __init__(self, in_channels):\n            super(UpProj.UpProjModule, self).__init__()\n            out_channels = in_channels//2\n            self.unpool = Unpool(in_channels)\n            self.upper_branch = nn.Sequential(collections.OrderedDict([\n              (\'conv1\',      nn.Conv2d(in_channels,out_channels,kernel_size=5,stride=1,padding=2,bias=False)),\n              (\'batchnorm1\', nn.BatchNorm2d(out_channels)),\n              (\'relu\',      nn.ReLU()),\n              (\'conv2\',      nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1,bias=False)),\n              (\'batchnorm2\', nn.BatchNorm2d(out_channels)),\n            ]))\n            self.bottom_branch = nn.Sequential(collections.OrderedDict([\n              (\'conv\',      nn.Conv2d(in_channels,out_channels,kernel_size=5,stride=1,padding=2,bias=False)),\n              (\'batchnorm\', nn.BatchNorm2d(out_channels)),\n            ]))\n            self.relu = nn.ReLU()\n\n        def forward(self, x):\n            x = self.unpool(x)\n            x1 = self.upper_branch(x)\n            x2 = self.bottom_branch(x)\n            x = x1 + x2\n            x = self.relu(x)\n            return x\n\n    def __init__(self, in_channels):\n        super(UpProj, self).__init__()\n        self.layer1 = self.UpProjModule(in_channels)\n        self.layer2 = self.UpProjModule(in_channels//2)\n        self.layer3 = self.UpProjModule(in_channels//4)\n        self.layer4 = self.UpProjModule(in_channels//8)\n\ndef choose_decoder(decoder, in_channels):\n    # iheight, iwidth = 10, 8\n    if decoder[:6] == \'deconv\':\n        assert len(decoder)==7\n        kernel_size = int(decoder[6])\n        return DeConv(in_channels, kernel_size)\n    elif decoder == ""upproj"":\n        return UpProj(in_channels)\n    elif decoder == ""upconv"":\n        return UpConv(in_channels)\n    else:\n        assert False, ""invalid option for decoder: {}"".format(decoder)\n\n\nclass ResNet(nn.Module):\n    def __init__(self, layers, decoder, output_size, in_channels=3, pretrained=True):\n\n        if layers not in [18, 34, 50, 101, 152]:\n            raise RuntimeError(\'Only 18, 34, 50, 101, and 152 layer model are defined for ResNet. Got {}\'.format(layers))\n\n        super(ResNet, self).__init__()\n        pretrained_model = torchvision.models.__dict__[\'resnet{}\'.format(layers)](pretrained=pretrained)\n\n        if in_channels == 3:\n            self.conv1 = pretrained_model._modules[\'conv1\']\n            self.bn1 = pretrained_model._modules[\'bn1\']\n        else:\n            self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            self.bn1 = nn.BatchNorm2d(64)\n            weights_init(self.conv1)\n            weights_init(self.bn1)\n\n        self.output_size = output_size\n\n        self.relu = pretrained_model._modules[\'relu\']\n        self.maxpool = pretrained_model._modules[\'maxpool\']\n        self.layer1 = pretrained_model._modules[\'layer1\']\n        self.layer2 = pretrained_model._modules[\'layer2\']\n        self.layer3 = pretrained_model._modules[\'layer3\']\n        self.layer4 = pretrained_model._modules[\'layer4\']\n\n        # clear memory\n        del pretrained_model\n\n        # define number of intermediate channels\n        if layers <= 34:\n            num_channels = 512\n        elif layers >= 50:\n            num_channels = 2048\n\n        self.conv2 = nn.Conv2d(num_channels,num_channels//2,kernel_size=1,bias=False)\n        self.bn2 = nn.BatchNorm2d(num_channels//2)\n        self.decoder = choose_decoder(decoder, num_channels//2)\n\n        # setting bias=true doesn\'t improve accuracy\n        self.conv3 = nn.Conv2d(num_channels//32,1,kernel_size=3,stride=1,padding=1,bias=False)\n        self.bilinear = nn.Upsample(size=self.output_size, mode=\'bilinear\', align_corners=True)\n\n        # weight init\n        self.conv2.apply(weights_init)\n        self.bn2.apply(weights_init)\n        self.decoder.apply(weights_init)\n        self.conv3.apply(weights_init)\n\n    def forward(self, x):\n        # resnet\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n\n        # decoder\n        x = self.decoder(x)\n        x = self.conv3(x)\n        x = self.bilinear(x)\n\n        return x\n'"
utils.py,1,"b'import os\nimport torch\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ncmap = plt.cm.viridis\n\ndef parse_command():\n    model_names = [\'resnet18\', \'resnet50\']\n    loss_names = [\'l1\', \'l2\']\n    data_names = [\'nyudepthv2\', \'kitti\']\n    from dataloaders.dense_to_sparse import UniformSampling, SimulatedStereo\n    sparsifier_names = [x.name for x in [UniformSampling, SimulatedStereo]]\n    from models import Decoder\n    decoder_names = Decoder.names\n    from dataloaders.dataloader import MyDataloader\n    modality_names = MyDataloader.modality_names\n\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Sparse-to-Dense\')\n    parser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names,\n                        help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnet18)\')\n    parser.add_argument(\'--data\', metavar=\'DATA\', default=\'nyudepthv2\',\n                        choices=data_names,\n                        help=\'dataset: \' + \' | \'.join(data_names) + \' (default: nyudepthv2)\')\n    parser.add_argument(\'--modality\', \'-m\', metavar=\'MODALITY\', default=\'rgb\', choices=modality_names,\n                        help=\'modality: \' + \' | \'.join(modality_names) + \' (default: rgb)\')\n    parser.add_argument(\'-s\', \'--num-samples\', default=0, type=int, metavar=\'N\',\n                        help=\'number of sparse depth samples (default: 0)\')\n    parser.add_argument(\'--max-depth\', default=-1.0, type=float, metavar=\'D\',\n                        help=\'cut-off depth of sparsifier, negative values means infinity (default: inf [m])\')\n    parser.add_argument(\'--sparsifier\', metavar=\'SPARSIFIER\', default=UniformSampling.name, choices=sparsifier_names,\n                        help=\'sparsifier: \' + \' | \'.join(sparsifier_names) + \' (default: \' + UniformSampling.name + \')\')\n    parser.add_argument(\'--decoder\', \'-d\', metavar=\'DECODER\', default=\'deconv2\', choices=decoder_names,\n                        help=\'decoder: \' + \' | \'.join(decoder_names) + \' (default: deconv2)\')\n    parser.add_argument(\'-j\', \'--workers\', default=10, type=int, metavar=\'N\',\n                        help=\'number of data loading workers (default: 10)\')\n    parser.add_argument(\'--epochs\', default=15, type=int, metavar=\'N\',\n                        help=\'number of total epochs to run (default: 15)\')\n    parser.add_argument(\'-c\', \'--criterion\', metavar=\'LOSS\', default=\'l1\', choices=loss_names,\n                        help=\'loss function: \' + \' | \'.join(loss_names) + \' (default: l1)\')\n    parser.add_argument(\'-b\', \'--batch-size\', default=8, type=int, help=\'mini-batch size (default: 8)\')\n    parser.add_argument(\'--lr\', \'--learning-rate\', default=0.01, type=float,\n                        metavar=\'LR\', help=\'initial learning rate (default 0.01)\')\n    parser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                        help=\'momentum\')\n    parser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                        metavar=\'W\', help=\'weight decay (default: 1e-4)\')\n    parser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                        metavar=\'N\', help=\'print frequency (default: 10)\')\n    parser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                        help=\'path to latest checkpoint (default: none)\')\n    parser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', type=str, default=\'\',\n                        help=\'evaluate model on validation set\')\n    parser.add_argument(\'--no-pretrain\', dest=\'pretrained\', action=\'store_false\',\n                        help=\'not to use ImageNet pre-trained weights\')\n    parser.set_defaults(pretrained=True)\n    args = parser.parse_args()\n    if args.modality == \'rgb\' and args.num_samples != 0:\n        print(""number of samples is forced to be 0 when input modality is rgb"")\n        args.num_samples = 0\n    if args.modality == \'rgb\' and args.max_depth != 0.0:\n        print(""max depth is forced to be 0.0 when input modality is rgb/rgbd"")\n        args.max_depth = 0.0\n    return args\n\ndef save_checkpoint(state, is_best, epoch, output_directory):\n    checkpoint_filename = os.path.join(output_directory, \'checkpoint-\' + str(epoch) + \'.pth.tar\')\n    torch.save(state, checkpoint_filename)\n    if is_best:\n        best_filename = os.path.join(output_directory, \'model_best.pth.tar\')\n        shutil.copyfile(checkpoint_filename, best_filename)\n    if epoch > 0:\n        prev_checkpoint_filename = os.path.join(output_directory, \'checkpoint-\' + str(epoch-1) + \'.pth.tar\')\n        if os.path.exists(prev_checkpoint_filename):\n            os.remove(prev_checkpoint_filename)\n\ndef adjust_learning_rate(optimizer, epoch, lr_init):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 5 epochs""""""\n    lr = lr_init * (0.1 ** (epoch // 5))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\ndef get_output_directory(args):\n    output_directory = os.path.join(\'results\',\n        \'{}.sparsifier={}.samples={}.modality={}.arch={}.decoder={}.criterion={}.lr={}.bs={}.pretrained={}\'.\n        format(args.data, args.sparsifier, args.num_samples, args.modality, \\\n            args.arch, args.decoder, args.criterion, args.lr, args.batch_size, \\\n            args.pretrained))\n    return output_directory\n\n\ndef colored_depthmap(depth, d_min=None, d_max=None):\n    if d_min is None:\n        d_min = np.min(depth)\n    if d_max is None:\n        d_max = np.max(depth)\n    depth_relative = (depth - d_min) / (d_max - d_min)\n    return 255 * cmap(depth_relative)[:,:,:3] # H, W, C\n\n\ndef merge_into_row(input, depth_target, depth_pred):\n    rgb = 255 * np.transpose(np.squeeze(input.cpu().numpy()), (1,2,0)) # H, W, C\n    depth_target_cpu = np.squeeze(depth_target.cpu().numpy())\n    depth_pred_cpu = np.squeeze(depth_pred.data.cpu().numpy())\n\n    d_min = min(np.min(depth_target_cpu), np.min(depth_pred_cpu))\n    d_max = max(np.max(depth_target_cpu), np.max(depth_pred_cpu))\n    depth_target_col = colored_depthmap(depth_target_cpu, d_min, d_max)\n    depth_pred_col = colored_depthmap(depth_pred_cpu, d_min, d_max)\n    img_merge = np.hstack([rgb, depth_target_col, depth_pred_col])\n    \n    return img_merge\n\n\ndef merge_into_row_with_gt(input, depth_input, depth_target, depth_pred):\n    rgb = 255 * np.transpose(np.squeeze(input.cpu().numpy()), (1,2,0)) # H, W, C\n    depth_input_cpu = np.squeeze(depth_input.cpu().numpy())\n    depth_target_cpu = np.squeeze(depth_target.cpu().numpy())\n    depth_pred_cpu = np.squeeze(depth_pred.data.cpu().numpy())\n\n    d_min = min(np.min(depth_input_cpu), np.min(depth_target_cpu), np.min(depth_pred_cpu))\n    d_max = max(np.max(depth_input_cpu), np.max(depth_target_cpu), np.max(depth_pred_cpu))\n    depth_input_col = colored_depthmap(depth_input_cpu, d_min, d_max)\n    depth_target_col = colored_depthmap(depth_target_cpu, d_min, d_max)\n    depth_pred_col = colored_depthmap(depth_pred_cpu, d_min, d_max)\n\n    img_merge = np.hstack([rgb, depth_input_col, depth_target_col, depth_pred_col])\n\n    return img_merge\n\n\ndef add_row(img_merge, row):\n    return np.vstack([img_merge, row])\n\n\ndef save_image(img_merge, filename):\n    img_merge = Image.fromarray(img_merge.astype(\'uint8\'))\n    img_merge.save(filename)'"
dataloaders/dataloader.py,1,"b'import os\nimport os.path\nimport numpy as np\nimport torch.utils.data as data\nimport h5py\nimport dataloaders.transforms as transforms\n\nIMG_EXTENSIONS = [\'.h5\',]\n\ndef is_image_file(filename):\n    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n\ndef find_classes(dir):\n    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    return classes, class_to_idx\n\ndef make_dataset(dir, class_to_idx):\n    images = []\n    dir = os.path.expanduser(dir)\n    for target in sorted(os.listdir(dir)):\n        d = os.path.join(dir, target)\n        if not os.path.isdir(d):\n            continue\n        for root, _, fnames in sorted(os.walk(d)):\n            for fname in sorted(fnames):\n                if is_image_file(fname):\n                    path = os.path.join(root, fname)\n                    item = (path, class_to_idx[target])\n                    images.append(item)\n    return images\n\ndef h5_loader(path):\n    h5f = h5py.File(path, ""r"")\n    rgb = np.array(h5f[\'rgb\'])\n    rgb = np.transpose(rgb, (1, 2, 0))\n    depth = np.array(h5f[\'depth\'])\n    return rgb, depth\n\n# def rgb2grayscale(rgb):\n#     return rgb[:,:,0] * 0.2989 + rgb[:,:,1] * 0.587 + rgb[:,:,2] * 0.114\n\nto_tensor = transforms.ToTensor()\n\nclass MyDataloader(data.Dataset):\n    modality_names = [\'rgb\', \'rgbd\', \'d\'] # , \'g\', \'gd\'\n    color_jitter = transforms.ColorJitter(0.4, 0.4, 0.4)\n\n    def __init__(self, root, type, sparsifier=None, modality=\'rgb\', loader=h5_loader):\n        classes, class_to_idx = find_classes(root)\n        imgs = make_dataset(root, class_to_idx)\n        assert len(imgs)>0, ""Found 0 images in subfolders of: "" + root + ""\\n""\n        print(""Found {} images in {} folder."".format(len(imgs), type))\n        self.root = root\n        self.imgs = imgs\n        self.classes = classes\n        self.class_to_idx = class_to_idx\n        if type == \'train\':\n            self.transform = self.train_transform\n        elif type == \'val\':\n            self.transform = self.val_transform\n        else:\n            raise (RuntimeError(""Invalid dataset type: "" + type + ""\\n""\n                                ""Supported dataset types are: train, val""))\n        self.loader = loader\n        self.sparsifier = sparsifier\n\n        assert (modality in self.modality_names), ""Invalid modality type: "" + modality + ""\\n"" + \\\n                                ""Supported dataset types are: "" + \'\'.join(self.modality_names)\n        self.modality = modality\n\n    def train_transform(self, rgb, depth):\n        raise (RuntimeError(""train_transform() is not implemented. ""))\n\n    def val_transform(rgb, depth):\n        raise (RuntimeError(""val_transform() is not implemented.""))\n\n    def create_sparse_depth(self, rgb, depth):\n        if self.sparsifier is None:\n            return depth\n        else:\n            mask_keep = self.sparsifier.dense_to_sparse(rgb, depth)\n            sparse_depth = np.zeros(depth.shape)\n            sparse_depth[mask_keep] = depth[mask_keep]\n            return sparse_depth\n\n    def create_rgbd(self, rgb, depth):\n        sparse_depth = self.create_sparse_depth(rgb, depth)\n        rgbd = np.append(rgb, np.expand_dims(sparse_depth, axis=2), axis=2)\n        return rgbd\n\n    def __getraw__(self, index):\n        """"""\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (rgb, depth) the raw data.\n        """"""\n        path, target = self.imgs[index]\n        rgb, depth = self.loader(path)\n        return rgb, depth\n\n    def __getitem__(self, index):\n        rgb, depth = self.__getraw__(index)\n        if self.transform is not None:\n            rgb_np, depth_np = self.transform(rgb, depth)\n        else:\n            raise(RuntimeError(""transform not defined""))\n\n        # color normalization\n        # rgb_tensor = normalize_rgb(rgb_tensor)\n        # rgb_np = normalize_np(rgb_np)\n\n        if self.modality == \'rgb\':\n            input_np = rgb_np\n        elif self.modality == \'rgbd\':\n            input_np = self.create_rgbd(rgb_np, depth_np)\n        elif self.modality == \'d\':\n            input_np = self.create_sparse_depth(rgb_np, depth_np)\n\n        input_tensor = to_tensor(input_np)\n        while input_tensor.dim() < 3:\n            input_tensor = input_tensor.unsqueeze(0)\n        depth_tensor = to_tensor(depth_np)\n        depth_tensor = depth_tensor.unsqueeze(0)\n\n        return input_tensor, depth_tensor\n\n    def __len__(self):\n        return len(self.imgs)\n\n    # def __get_all_item__(self, index):\n    #     """"""\n    #     Args:\n    #         index (int): Index\n\n    #     Returns:\n    #         tuple: (input_tensor, depth_tensor, input_np, depth_np)\n    #     """"""\n    #     rgb, depth = self.__getraw__(index)\n    #     if self.transform is not None:\n    #         rgb_np, depth_np = self.transform(rgb, depth)\n    #     else:\n    #         raise(RuntimeError(""transform not defined""))\n\n    #     # color normalization\n    #     # rgb_tensor = normalize_rgb(rgb_tensor)\n    #     # rgb_np = normalize_np(rgb_np)\n\n    #     if self.modality == \'rgb\':\n    #         input_np = rgb_np\n    #     elif self.modality == \'rgbd\':\n    #         input_np = self.create_rgbd(rgb_np, depth_np)\n    #     elif self.modality == \'d\':\n    #         input_np = self.create_sparse_depth(rgb_np, depth_np)\n\n    #     input_tensor = to_tensor(input_np)\n    #     while input_tensor.dim() < 3:\n    #         input_tensor = input_tensor.unsqueeze(0)\n    #     depth_tensor = to_tensor(depth_np)\n    #     depth_tensor = depth_tensor.unsqueeze(0)\n\n    #     return input_tensor, depth_tensor, input_np, depth_np\n'"
dataloaders/dense_to_sparse.py,0,"b'import numpy as np\nimport cv2\n\n\ndef rgb2grayscale(rgb):\n    return rgb[:, :, 0] * 0.2989 + rgb[:, :, 1] * 0.587 + rgb[:, :, 2] * 0.114\n\n\nclass DenseToSparse:\n    def __init__(self):\n        pass\n\n    def dense_to_sparse(self, rgb, depth):\n        pass\n\n    def __repr__(self):\n        pass\n\nclass UniformSampling(DenseToSparse):\n    name = ""uar""\n    def __init__(self, num_samples, max_depth=np.inf):\n        DenseToSparse.__init__(self)\n        self.num_samples = num_samples\n        self.max_depth = max_depth\n\n    def __repr__(self):\n        return ""%s{ns=%d,md=%f}"" % (self.name, self.num_samples, self.max_depth)\n\n    def dense_to_sparse(self, rgb, depth):\n        """"""\n        Samples pixels with `num_samples`/#pixels probability in `depth`.\n        Only pixels with a maximum depth of `max_depth` are considered.\n        If no `max_depth` is given, samples in all pixels\n        """"""\n        mask_keep = depth > 0\n        if self.max_depth is not np.inf:\n            mask_keep = np.bitwise_and(mask_keep, depth <= self.max_depth)\n        n_keep = np.count_nonzero(mask_keep)\n        if n_keep == 0:\n            return mask_keep\n        else:\n            prob = float(self.num_samples) / n_keep\n            return np.bitwise_and(mask_keep, np.random.uniform(0, 1, depth.shape) < prob)\n\n\nclass SimulatedStereo(DenseToSparse):\n    name = ""sim_stereo""\n\n    def __init__(self, num_samples, max_depth=np.inf, dilate_kernel=3, dilate_iterations=1):\n        DenseToSparse.__init__(self)\n        self.num_samples = num_samples\n        self.max_depth = max_depth\n        self.dilate_kernel = dilate_kernel\n        self.dilate_iterations = dilate_iterations\n\n    def __repr__(self):\n        return ""%s{ns=%d,md=%f,dil=%d.%d}"" % \\\n               (self.name, self.num_samples, self.max_depth, self.dilate_kernel, self.dilate_iterations)\n\n    # We do not use cv2.Canny, since that applies non max suppression\n    # So we simply do\n    # RGB to intensitities\n    # Smooth with gaussian\n    # Take simple sobel gradients\n    # Threshold the edge gradient\n    # Dilatate\n    def dense_to_sparse(self, rgb, depth):\n        gray = rgb2grayscale(rgb)\n        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n        gx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=5)\n        gy = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=5)\n\n        depth_mask = np.bitwise_and(depth != 0.0, depth <= self.max_depth)\n\n        edge_fraction = float(self.num_samples) / np.size(depth)\n\n        mag = cv2.magnitude(gx, gy)\n        min_mag = np.percentile(mag[depth_mask], 100 * (1.0 - edge_fraction))\n        mag_mask = mag >= min_mag\n\n        if self.dilate_iterations >= 0:\n            kernel = np.ones((self.dilate_kernel, self.dilate_kernel), dtype=np.uint8)\n            cv2.dilate(mag_mask.astype(np.uint8), kernel, iterations=self.dilate_iterations)\n\n        mask = np.bitwise_and(mag_mask, depth_mask)\n        return mask\n'"
dataloaders/kitti_dataloader.py,0,"b""import numpy as np\nimport dataloaders.transforms as transforms\nfrom dataloaders.dataloader import MyDataloader\n\nclass KITTIDataset(MyDataloader):\n    def __init__(self, root, type, sparsifier=None, modality='rgb'):\n        super(KITTIDataset, self).__init__(root, type, sparsifier, modality)\n        self.output_size = (228, 912)\n\n    def train_transform(self, rgb, depth):\n        s = np.random.uniform(1.0, 1.5)  # random scaling\n        depth_np = depth / s\n        angle = np.random.uniform(-5.0, 5.0)  # random rotation degrees\n        do_flip = np.random.uniform(0.0, 1.0) < 0.5  # random horizontal flip\n\n        # perform 1st step of data augmentation\n        transform = transforms.Compose([\n            transforms.Crop(130, 10, 240, 1200),\n            transforms.Rotate(angle),\n            transforms.Resize(s),\n            transforms.CenterCrop(self.output_size),\n            transforms.HorizontalFlip(do_flip)\n        ])\n        rgb_np = transform(rgb)\n        rgb_np = self.color_jitter(rgb_np) # random color jittering\n        rgb_np = np.asfarray(rgb_np, dtype='float') / 255\n        # Scipy affine_transform produced RuntimeError when the depth map was\n        # given as a 'numpy.ndarray'\n        depth_np = np.asfarray(depth_np, dtype='float32')\n        depth_np = transform(depth_np)\n\n        return rgb_np, depth_np\n\n    def val_transform(self, rgb, depth):\n        depth_np = depth\n        transform = transforms.Compose([\n            transforms.Crop(130, 10, 240, 1200),\n            transforms.CenterCrop(self.output_size),\n        ])\n        rgb_np = transform(rgb)\n        rgb_np = np.asfarray(rgb_np, dtype='float') / 255\n        depth_np = np.asfarray(depth_np, dtype='float32')\n        depth_np = transform(depth_np)\n\n        return rgb_np, depth_np\n\n"""
dataloaders/nyu_dataloader.py,0,"b""import numpy as np\nimport dataloaders.transforms as transforms\nfrom dataloaders.dataloader import MyDataloader\n\niheight, iwidth = 480, 640 # raw image size\n\nclass NYUDataset(MyDataloader):\n    def __init__(self, root, type, sparsifier=None, modality='rgb'):\n        super(NYUDataset, self).__init__(root, type, sparsifier, modality)\n        self.output_size = (228, 304)\n\n    def train_transform(self, rgb, depth):\n        s = np.random.uniform(1.0, 1.5) # random scaling\n        depth_np = depth / s\n        angle = np.random.uniform(-5.0, 5.0) # random rotation degrees\n        do_flip = np.random.uniform(0.0, 1.0) < 0.5 # random horizontal flip\n\n        # perform 1st step of data augmentation\n        transform = transforms.Compose([\n            transforms.Resize(250.0 / iheight), # this is for computational efficiency, since rotation can be slow\n            transforms.Rotate(angle),\n            transforms.Resize(s),\n            transforms.CenterCrop(self.output_size),\n            transforms.HorizontalFlip(do_flip)\n        ])\n        rgb_np = transform(rgb)\n        rgb_np = self.color_jitter(rgb_np) # random color jittering\n        rgb_np = np.asfarray(rgb_np, dtype='float') / 255\n        depth_np = transform(depth_np)\n\n        return rgb_np, depth_np\n\n    def val_transform(self, rgb, depth):\n        depth_np = depth\n        transform = transforms.Compose([\n            transforms.Resize(240.0 / iheight),\n            transforms.CenterCrop(self.output_size),\n        ])\n        rgb_np = transform(rgb)\n        rgb_np = np.asfarray(rgb_np, dtype='float') / 255\n        depth_np = transform(depth_np)\n\n        return rgb_np, depth_np\n"""
dataloaders/transforms.py,5,"b'from __future__ import division\nimport torch\nimport math\nimport random\n\nfrom PIL import Image, ImageOps, ImageEnhance\ntry:\n    import accimage\nexcept ImportError:\n    accimage = None\n\nimport numpy as np\nimport numbers\nimport types\nimport collections\nimport warnings\n\nimport scipy.ndimage.interpolation as itpl\nimport scipy.misc as misc\n\n\ndef _is_numpy_image(img):\n    return isinstance(img, np.ndarray) and (img.ndim in {2, 3})\n\ndef _is_pil_image(img):\n    if accimage is not None:\n        return isinstance(img, (Image.Image, accimage.Image))\n    else:\n        return isinstance(img, Image.Image)\n\ndef _is_tensor_image(img):\n    return torch.is_tensor(img) and img.ndimension() == 3\n\ndef adjust_brightness(img, brightness_factor):\n    """"""Adjust brightness of an Image.\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        brightness_factor (float):  How much to adjust the brightness. Can be\n            any non negative number. 0 gives a black image, 1 gives the\n            original image while 2 increases the brightness by a factor of 2.\n\n    Returns:\n        PIL Image: Brightness adjusted image.\n    """"""\n    if not _is_pil_image(img):\n        raise TypeError(\'img should be PIL Image. Got {}\'.format(type(img)))\n\n    enhancer = ImageEnhance.Brightness(img)\n    img = enhancer.enhance(brightness_factor)\n    return img\n\n\ndef adjust_contrast(img, contrast_factor):\n    """"""Adjust contrast of an Image.\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        contrast_factor (float): How much to adjust the contrast. Can be any\n            non negative number. 0 gives a solid gray image, 1 gives the\n            original image while 2 increases the contrast by a factor of 2.\n\n    Returns:\n        PIL Image: Contrast adjusted image.\n    """"""\n    if not _is_pil_image(img):\n        raise TypeError(\'img should be PIL Image. Got {}\'.format(type(img)))\n\n    enhancer = ImageEnhance.Contrast(img)\n    img = enhancer.enhance(contrast_factor)\n    return img\n\n\ndef adjust_saturation(img, saturation_factor):\n    """"""Adjust color saturation of an image.\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        saturation_factor (float):  How much to adjust the saturation. 0 will\n            give a black and white image, 1 will give the original image while\n            2 will enhance the saturation by a factor of 2.\n\n    Returns:\n        PIL Image: Saturation adjusted image.\n    """"""\n    if not _is_pil_image(img):\n        raise TypeError(\'img should be PIL Image. Got {}\'.format(type(img)))\n\n    enhancer = ImageEnhance.Color(img)\n    img = enhancer.enhance(saturation_factor)\n    return img\n\n\ndef adjust_hue(img, hue_factor):\n    """"""Adjust hue of an image.\n\n    The image hue is adjusted by converting the image to HSV and\n    cyclically shifting the intensities in the hue channel (H).\n    The image is then converted back to original image mode.\n\n    `hue_factor` is the amount of shift in H channel and must be in the\n    interval `[-0.5, 0.5]`.\n\n    See https://en.wikipedia.org/wiki/Hue for more details on Hue.\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        hue_factor (float):  How much to shift the hue channel. Should be in\n            [-0.5, 0.5]. 0.5 and -0.5 give complete reversal of hue channel in\n            HSV space in positive and negative direction respectively.\n            0 means no shift. Therefore, both -0.5 and 0.5 will give an image\n            with complementary colors while 0 gives the original image.\n\n    Returns:\n        PIL Image: Hue adjusted image.\n    """"""\n    if not(-0.5 <= hue_factor <= 0.5):\n        raise ValueError(\'hue_factor is not in [-0.5, 0.5].\'.format(hue_factor))\n\n    if not _is_pil_image(img):\n        raise TypeError(\'img should be PIL Image. Got {}\'.format(type(img)))\n\n    input_mode = img.mode\n    if input_mode in {\'L\', \'1\', \'I\', \'F\'}:\n        return img\n\n    h, s, v = img.convert(\'HSV\').split()\n\n    np_h = np.array(h, dtype=np.uint8)\n    # uint8 addition take cares of rotation across boundaries\n    with np.errstate(over=\'ignore\'):\n        np_h += np.uint8(hue_factor * 255)\n    h = Image.fromarray(np_h, \'L\')\n\n    img = Image.merge(\'HSV\', (h, s, v)).convert(input_mode)\n    return img\n\n\ndef adjust_gamma(img, gamma, gain=1):\n    """"""Perform gamma correction on an image.\n\n    Also known as Power Law Transform. Intensities in RGB mode are adjusted\n    based on the following equation:\n\n        I_out = 255 * gain * ((I_in / 255) ** gamma)\n\n    See https://en.wikipedia.org/wiki/Gamma_correction for more details.\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        gamma (float): Non negative real number. gamma larger than 1 make the\n            shadows darker, while gamma smaller than 1 make dark regions\n            lighter.\n        gain (float): The constant multiplier.\n    """"""\n    if not _is_pil_image(img):\n        raise TypeError(\'img should be PIL Image. Got {}\'.format(type(img)))\n\n    if gamma < 0:\n        raise ValueError(\'Gamma should be a non-negative real number\')\n\n    input_mode = img.mode\n    img = img.convert(\'RGB\')\n\n    np_img = np.array(img, dtype=np.float32)\n    np_img = 255 * gain * ((np_img / 255) ** gamma)\n    np_img = np.uint8(np.clip(np_img, 0, 255))\n\n    img = Image.fromarray(np_img, \'RGB\').convert(input_mode)\n    return img\n\n\nclass Compose(object):\n    """"""Composes several transforms together.\n\n    Args:\n        transforms (list of ``Transform`` objects): list of transforms to compose.\n\n    Example:\n        >>> transforms.Compose([\n        >>>     transforms.CenterCrop(10),\n        >>>     transforms.ToTensor(),\n        >>> ])\n    """"""\n\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img):\n        for t in self.transforms:\n            img = t(img)\n        return img\n\n\nclass ToTensor(object):\n    """"""Convert a ``numpy.ndarray`` to tensor.\n\n    Converts a numpy.ndarray (H x W x C) to a torch.FloatTensor of shape (C x H x W).\n    """"""\n\n    def __call__(self, img):\n        """"""Convert a ``numpy.ndarray`` to tensor.\n\n        Args:\n            img (numpy.ndarray): Image to be converted to tensor.\n\n        Returns:\n            Tensor: Converted image.\n        """"""\n        if not(_is_numpy_image(img)):\n            raise TypeError(\'img should be ndarray. Got {}\'.format(type(img)))\n\n        if isinstance(img, np.ndarray):\n            # handle numpy array\n            if img.ndim == 3:\n                img = torch.from_numpy(img.transpose((2, 0, 1)).copy())\n            elif img.ndim == 2:\n                img = torch.from_numpy(img.copy())\n            else:\n                raise RuntimeError(\'img should be ndarray with 2 or 3 dimensions. Got {}\'.format(img.ndim))\n\n            # backward compatibility\n            # return img.float().div(255)\n            return img.float()\n\n\nclass NormalizeNumpyArray(object):\n    """"""Normalize a ``numpy.ndarray`` with mean and standard deviation.\n    Given mean: ``(M1,...,Mn)`` and std: ``(M1,..,Mn)`` for ``n`` channels, this transform\n    will normalize each channel of the input ``numpy.ndarray`` i.e.\n    ``input[channel] = (input[channel] - mean[channel]) / std[channel]``\n\n    Args:\n        mean (sequence): Sequence of means for each channel.\n        std (sequence): Sequence of standard deviations for each channel.\n    """"""\n\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (numpy.ndarray): Image of size (H, W, C) to be normalized.\n\n        Returns:\n            Tensor: Normalized image.\n        """"""\n        if not(_is_numpy_image(img)):\n            raise TypeError(\'img should be ndarray. Got {}\'.format(type(img)))\n        # TODO: make efficient\n        print(img.shape)\n        for i in range(3):\n            img[:,:,i] = (img[:,:,i] - self.mean[i]) / self.std[i]\n        return img\n\nclass NormalizeTensor(object):\n    """"""Normalize an tensor image with mean and standard deviation.\n    Given mean: ``(M1,...,Mn)`` and std: ``(M1,..,Mn)`` for ``n`` channels, this transform\n    will normalize each channel of the input ``torch.*Tensor`` i.e.\n    ``input[channel] = (input[channel] - mean[channel]) / std[channel]``\n\n    Args:\n        mean (sequence): Sequence of means for each channel.\n        std (sequence): Sequence of standard deviations for each channel.\n    """"""\n\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        """"""\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n\n        Returns:\n            Tensor: Normalized Tensor image.\n        """"""\n        if not _is_tensor_image(tensor):\n            raise TypeError(\'tensor is not a torch image.\')\n        # TODO: make efficient\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.sub_(m).div_(s)\n        return tensor\n\nclass Rotate(object):\n    """"""Rotates the given ``numpy.ndarray``.\n\n    Args:\n        angle (float): The rotation angle in degrees.\n    """"""\n\n    def __init__(self, angle):\n        self.angle = angle\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (numpy.ndarray (C x H x W)): Image to be rotated.\n\n        Returns:\n            img (numpy.ndarray (C x H x W)): Rotated image.\n        """"""\n\n        # order=0 means nearest-neighbor type interpolation\n        return itpl.rotate(img, self.angle, reshape=False, prefilter=False, order=0)\n\n\nclass Resize(object):\n    """"""Resize the the given ``numpy.ndarray`` to the given size.\n    Args:\n        size (sequence or int): Desired output size. If size is a sequence like\n            (h, w), output size will be matched to this. If size is an int,\n            smaller edge of the image will be matched to this number.\n            i.e, if height > width, then image will be rescaled to\n            (size * height / width, size)\n        interpolation (int, optional): Desired interpolation. Default is\n            ``PIL.Image.BILINEAR``\n    """"""\n\n    def __init__(self, size, interpolation=\'nearest\'):\n        assert isinstance(size, int) or isinstance(size, float) or \\\n               (isinstance(size, collections.Iterable) and len(size) == 2)\n        self.size = size\n        self.interpolation = interpolation\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (PIL Image): Image to be scaled.\n        Returns:\n            PIL Image: Rescaled image.\n        """"""\n        if img.ndim == 3:\n            return misc.imresize(img, self.size, self.interpolation)\n        elif img.ndim == 2:\n            return misc.imresize(img, self.size, self.interpolation, \'F\')\n        else:\n            RuntimeError(\'img should be ndarray with 2 or 3 dimensions. Got {}\'.format(img.ndim))\n\n\nclass CenterCrop(object):\n    """"""Crops the given ``numpy.ndarray`` at the center.\n\n    Args:\n        size (sequence or int): Desired output size of the crop. If size is an\n            int instead of sequence like (h, w), a square crop (size, size) is\n            made.\n    """"""\n\n    def __init__(self, size):\n        if isinstance(size, numbers.Number):\n            self.size = (int(size), int(size))\n        else:\n            self.size = size\n\n    @staticmethod\n    def get_params(img, output_size):\n        """"""Get parameters for ``crop`` for center crop.\n\n        Args:\n            img (numpy.ndarray (C x H x W)): Image to be cropped.\n            output_size (tuple): Expected output size of the crop.\n\n        Returns:\n            tuple: params (i, j, h, w) to be passed to ``crop`` for center crop.\n        """"""\n        h = img.shape[0]\n        w = img.shape[1]\n        th, tw = output_size\n        i = int(round((h - th) / 2.))\n        j = int(round((w - tw) / 2.))\n\n        # # randomized cropping\n        # i = np.random.randint(i-3, i+4)\n        # j = np.random.randint(j-3, j+4)\n\n        return i, j, th, tw\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (numpy.ndarray (C x H x W)): Image to be cropped.\n\n        Returns:\n            img (numpy.ndarray (C x H x W)): Cropped image.\n        """"""\n        i, j, h, w = self.get_params(img, self.size)\n\n        """"""\n        i: Upper pixel coordinate.\n        j: Left pixel coordinate.\n        h: Height of the cropped image.\n        w: Width of the cropped image.\n        """"""\n        if not(_is_numpy_image(img)):\n            raise TypeError(\'img should be ndarray. Got {}\'.format(type(img)))\n        if img.ndim == 3:\n            return img[i:i+h, j:j+w, :]\n        elif img.ndim == 2:\n            return img[i:i + h, j:j + w]\n        else:\n            raise RuntimeError(\'img should be ndarray with 2 or 3 dimensions. Got {}\'.format(img.ndim))\n\n\nclass Lambda(object):\n    """"""Apply a user-defined lambda as a transform.\n\n    Args:\n        lambd (function): Lambda/function to be used for transform.\n    """"""\n\n    def __init__(self, lambd):\n        assert isinstance(lambd, types.LambdaType)\n        self.lambd = lambd\n\n    def __call__(self, img):\n        return self.lambd(img)\n\n\nclass HorizontalFlip(object):\n    """"""Horizontally flip the given ``numpy.ndarray``.\n\n    Args:\n        do_flip (boolean): whether or not do horizontal flip.\n\n    """"""\n\n    def __init__(self, do_flip):\n        self.do_flip = do_flip\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (numpy.ndarray (C x H x W)): Image to be flipped.\n\n        Returns:\n            img (numpy.ndarray (C x H x W)): flipped image.\n        """"""\n        if not(_is_numpy_image(img)):\n            raise TypeError(\'img should be ndarray. Got {}\'.format(type(img)))\n\n        if self.do_flip:\n            return np.fliplr(img)\n        else:\n            return img\n\n\nclass ColorJitter(object):\n    """"""Randomly change the brightness, contrast and saturation of an image.\n\n    Args:\n        brightness (float): How much to jitter brightness. brightness_factor\n            is chosen uniformly from [max(0, 1 - brightness), 1 + brightness].\n        contrast (float): How much to jitter contrast. contrast_factor\n            is chosen uniformly from [max(0, 1 - contrast), 1 + contrast].\n        saturation (float): How much to jitter saturation. saturation_factor\n            is chosen uniformly from [max(0, 1 - saturation), 1 + saturation].\n        hue(float): How much to jitter hue. hue_factor is chosen uniformly from\n            [-hue, hue]. Should be >=0 and <= 0.5.\n    """"""\n    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0):\n        self.brightness = brightness\n        self.contrast = contrast\n        self.saturation = saturation\n        self.hue = hue\n\n    @staticmethod\n    def get_params(brightness, contrast, saturation, hue):\n        """"""Get a randomized transform to be applied on image.\n\n        Arguments are same as that of __init__.\n\n        Returns:\n            Transform which randomly adjusts brightness, contrast and\n            saturation in a random order.\n        """"""\n        transforms = []\n        if brightness > 0:\n            brightness_factor = np.random.uniform(max(0, 1 - brightness), 1 + brightness)\n            transforms.append(Lambda(lambda img: adjust_brightness(img, brightness_factor)))\n\n        if contrast > 0:\n            contrast_factor = np.random.uniform(max(0, 1 - contrast), 1 + contrast)\n            transforms.append(Lambda(lambda img: adjust_contrast(img, contrast_factor)))\n\n        if saturation > 0:\n            saturation_factor = np.random.uniform(max(0, 1 - saturation), 1 + saturation)\n            transforms.append(Lambda(lambda img: adjust_saturation(img, saturation_factor)))\n\n        if hue > 0:\n            hue_factor = np.random.uniform(-hue, hue)\n            transforms.append(Lambda(lambda img: adjust_hue(img, hue_factor)))\n\n        np.random.shuffle(transforms)\n        transform = Compose(transforms)\n\n        return transform\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (numpy.ndarray (C x H x W)): Input image.\n\n        Returns:\n            img (numpy.ndarray (C x H x W)): Color jittered image.\n        """"""\n        if not(_is_numpy_image(img)):\n            raise TypeError(\'img should be ndarray. Got {}\'.format(type(img)))\n\n        pil = Image.fromarray(img)\n        transform = self.get_params(self.brightness, self.contrast,\n                                    self.saturation, self.hue)\n        return np.array(transform(pil))\n\nclass Crop(object):\n    """"""Crops the given PIL Image to a rectangular region based on a given\n    4-tuple defining the left, upper pixel coordinated, hight and width size.\n\n    Args:\n        a tuple: (upper pixel coordinate, left pixel coordinate, hight, width)-tuple\n    """"""\n\n    def __init__(self, i, j, h, w):\n        """"""\n        i: Upper pixel coordinate.\n        j: Left pixel coordinate.\n        h: Height of the cropped image.\n        w: Width of the cropped image.\n        """"""\n        self.i = i\n        self.j = j\n        self.h = h\n        self.w = w\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (numpy.ndarray (C x H x W)): Image to be cropped.\n        Returns:\n            img (numpy.ndarray (C x H x W)): Cropped image.\n        """"""\n\n        i, j, h, w = self.i, self.j, self.h, self.w\n\n        if not(_is_numpy_image(img)):\n            raise TypeError(\'img should be ndarray. Got {}\'.format(type(img)))\n        if img.ndim == 3:\n            return img[i:i + h, j:j + w, :]\n        elif img.ndim == 2:\n            return img[i:i + h, j:j + w]\n        else:\n            raise RuntimeError(\n                \'img should be ndarray with 2 or 3 dimensions. Got {}\'.format(img.ndim))\n\n    def __repr__(self):\n        return self.__class__.__name__ + \'(i={0},j={1},h={2},w={3})\'.format(\n            self.i, self.j, self.h, self.w)\n'"
