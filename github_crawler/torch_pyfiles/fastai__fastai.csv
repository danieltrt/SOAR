file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n""""""The setup script.""""""\n\nimport re\nfrom setuptools import setup, find_packages\n\nfrom distutils.core import Command\n\nclass DepsCommand(Command):\n    """"""A custom distutils command to print selective dependency groups.\n\n    # show available dependency groups:\n    python setup.py -q deps\n\n    # print dependency list for specified groups\n    python setup.py -q deps --dep-groups=core,vision\n\n    # see all options:\n    python setup.py -q deps --help\n    """"""\n\n    description = \'show dependency groups and their packages\'\n    user_options = [\n        # format: (long option, short option, description).\n        (\'dep-groups=\', None, \'comma separated dependency groups\'),\n        (\'dep-quote\',   None, \'quote each dependency\'),\n        (\'dep-conda\',   None, \'adjust output for conda\'),\n    ]\n\n    def initialize_options(self):\n        """"""Set default values for options.""""""\n        self.dep_groups = \'\'\n        self.dep_quote = False\n        self.dep_conda = False\n\n    def finalize_options(self):\n        """"""Post-process options.""""""\n        pass\n\n    def parse(self):\n        arg = self.dep_groups.strip()\n        return re.split(r\' *, *\', arg) if len(arg) else []\n\n    def run(self):\n        """"""Run command.""""""\n        wanted_groups = self.parse()\n\n        deps = []\n        invalid_groups = []\n        for grp in wanted_groups:\n            if grp in dep_groups: deps.extend(dep_groups[grp])\n            else:                 invalid_groups.append(grp)\n\n        if invalid_groups or not wanted_groups:\n            print(""Available dependency groups:"", "", "".join(sorted(dep_groups.keys())))\n            if invalid_groups:\n                print(f""Error: Invalid group name(s): {\', \'.join(invalid_groups)}"")\n                exit(1)\n        else:\n            # prepare for shell word splitting (no whitespace in items)\n            deps = [re.sub("" "", """", x, 0) for x in sorted(set(deps))]\n            if self.dep_conda:\n                for i in range(len(deps)):\n                    # strip pip-specific syntax\n                    deps[i] = re.sub(r\';.*\',     \'\',         deps[i])\n                    # rename mismatching package names\n                    deps[i] = re.sub(r\'^torch>\', \'pytorch>\', deps[i])\n            if self.dep_quote:\n                # for manual copy-n-paste (assuming no "" in vars)\n                print("" "".join(map(lambda x: f\'""{x}""\', deps)))\n            else:\n                # if fed directly to `pip install` via backticks/$() don\'t quote\n                print("" "".join(deps))\n\n# note: version is maintained inside fastai/version.py\nexec(open(\'fastai/version.py\').read())\n\nwith open(\'README.md\') as readme_file: readme = readme_file.read()\n\n# helper functions to make it easier to list dependencies not as a python list, but vertically w/ optional built-in comments to why a certain version of the dependency is listed\ndef cleanup(x): return re.sub(r\' *#.*\', \'\', x.strip()) # comments\ndef to_list(buffer): return list(filter(None, map(cleanup, buffer.splitlines())))\n\n### normal dependencies ###\n#\n# these get resolved and installed via either of these two:\n#\n#   pip install fastai\n#   pip install -e .\n#\n# IMPORTANT: when updating these, please make sure to sync conda/meta.yaml\ndep_groups = {\n    \'core\':   to_list(""""""\n        bottleneck           # performance-improvement for numpy\n        dataclasses ; python_version<\'3.7\'\n        fastprogress>=0.2.1\n        beautifulsoup4\n        matplotlib\n        numexpr              # performance-improvement for numpy\n        numpy>=1.15\n        nvidia-ml-py3\n        pandas\n        packaging\n        Pillow\n        pyyaml\n        pynvx>=1.0.0 ; platform_system==""Darwin""  # only pypi at the moment\n        requests\n        scipy\n        torch>=1.0.0\n""""""),\n    \'text\':   to_list(""""""\n        spacy>=2.0.18; python_version<\'3.8\'\n""""""),\n    \'vision\': to_list(""""""\n        torchvision\n""""""),\n}\n\nrequirements = [y for x in dep_groups.values() for y in x]\n\n### developer dependencies ###\n#\n# anything else that\'s not required by a user to run the library, but\n# either is an enhancement or a developer-build requirement goes here.\n#\n# the [dev] feature is documented here:\n# https://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-extras-optional-features-with-their-own-dependencies\n#\n# these, including the normal dependencies, get installed with:\n#\n#   pip install ""fastai[dev]""\n#\n# or via an editable install:\n#\n#   pip install -e "".[dev]""\n#\n# some of the listed modules appear in test_requirements as well, as explained below.\n#\ndev_requirements = { \'dev\' : to_list(""""""\n    coverage                     # make coverage\n    distro\n    ipython\n    jupyter\n    jupyter_contrib_nbextensions\n    nbconvert>=5.4\n    nbdime                       # help with nb diff/merge\n    nbformat\n    notebook>=5.7.0\n    pip>=9.0.1\n    pipreqs>=0.4.9\n    pytest>=4.4.0\n    pytest-xdist                 # make test-fast (faster parallel testing)\n    responses                    # for requests testing\n    traitlets\n    wheel>=0.30.0\n"""""") }\n\n### setup dependencies ###\n# need at least setuptools>=36.2 to support syntax:\n#   dataclasses ; python_version<\'3.7\'\nsetup_requirements = to_list(""""""\n    pytest-runner\n    setuptools>=36.2\n"""""")\n\n# notes:\n#\n# * these deps will be installed locally under .eggs/ and will not be\n#   visible to pytest unless it\'s invoked via `python setup test`.\n#   Therefore it\'s the best to install them explicitly with:\n#   pip install -e .[dev]\n#\n### test dependencies ###\ntest_requirements = to_list(""""""\n    pytest\n"""""")\n\n# list of classifiers: https://pypi.org/pypi?%3Aaction=list_classifiers\nsetup(\n    cmdclass = { \'deps\': DepsCommand },\n\n    name = \'fastai\',\n    version = __version__,\n\n    packages = find_packages(),\n    include_package_data = True,\n\n    install_requires = requirements,\n    setup_requires   = setup_requirements,\n    extras_require   = dev_requirements,\n    tests_require    = test_requirements,\n    python_requires  = \'>=3.6\',\n\n    test_suite = \'tests\',\n\n    description = ""fastai makes deep learning with PyTorch faster, more accurate, and easier"",\n    long_description = readme,\n    long_description_content_type = \'text/markdown\',\n    keywords = \'fastai, deep learning, machine learning\',\n\n    license = ""Apache Software License 2.0"",\n\n    url = \'https://github.com/fastai/fastai\',\n\n    author = ""Jeremy Howard"",\n    author_email = \'info@fast.ai\',\n\n    classifiers = [\n        \'Development Status :: 5 - Production/Stable\',\n        \'Intended Audience :: Developers\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Natural Language :: English\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n    ],\n\n    zip_safe = False,\n)\n'"
docs_src/conftest.py,0,"b'pytest_plugins = ""nbval.plugin""\n\n'"
docs_src/trustnbs.py,0,"b'#!/usr/bin/env python\n\nimport os, glob, nbformat.sign\n\n# Iterate over notebooks and sign each of them as trusted\nfor fname in glob.glob(""*.ipynb""):\n    with open(fname) as f:\n        nb = nbformat.read(f, as_version=4)\n        nbformat.sign.NotebookNotary().sign(nb)\n\n'"
examples/train_cifar.py,1,"b'from fastai.script import *\nfrom fastai.vision import *\nfrom fastai.vision.models.wrn import wrn_22\nfrom fastai.distributed import *\ntorch.backends.cudnn.benchmark = True\n\n@call_parse\ndef main( gpu:Param(""GPU to run on"", str)=None ):\n    """"""Distrubuted training of CIFAR-10.\n    Fastest speed is if you run as follows:\n        python -m fastai.launch train_cifar.py""""""\n    gpu = setup_distrib(gpu)\n    n_gpus = num_distrib()\n    path = url2path(URLs.CIFAR)\n    ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n    workers = min(16, num_cpus()//n_gpus)\n    data = ImageDataBunch.from_folder(path, valid=\'test\', ds_tfms=ds_tfms, bs=512//n_gpus,\n                                      num_workers=workers).normalize(cifar_stats)\n    learn = Learner(data, wrn_22(), metrics=accuracy)\n    if gpu is None: learn.model = nn.DataParallel(learn.model)\n    else: learn.to_distributed(gpu)\n    learn.to_fp16()\n    learn.fit_one_cycle(35, 3e-3, wd=0.4)\n\n'"
examples/train_imagenet.py,2,"b'from fastai.script import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.distributed import *\nfrom fastai.callbacks.tracker import *\ntorch.backends.cudnn.benchmark = True\nimport time\n\ndef get_data(path, size, bs, workers):\n    tfms = ([\n        flip_lr(p=0.5),\n        brightness(change=(0.4,0.6)),\n        contrast(scale=(0.7,1.3))\n    ], [])\n    train = ImageList.from_csv(path, \'train.csv\')\n    valid = ImageList.from_csv(path, \'valid.csv\')\n    lls = ItemLists(path, train, valid).label_from_df().transform(\n            tfms, size=size).presize(size, scale=(0.25, 1.0))\n    return lls.databunch(bs=bs, num_workers=workers).normalize(imagenet_stats)\n\n@call_parse\ndef main( gpu:Param(""GPU to run on"", str)=None ):\n    """"""Distributed training of Imagenet. Fastest speed is if you run with: python -m fastai.launch""""""\n    path = Path(\'/mnt/fe2_disk/\')\n    tot_epochs,size,bs,lr = 60,224,256,3e-1\n    dirname = \'imagenet\'\n\n    gpu = setup_distrib(gpu)\n    if gpu is None: bs *= torch.cuda.device_count()\n    n_gpus = num_distrib() or 1\n    workers = min(12, num_cpus()//n_gpus)\n    data = get_data(path/dirname, size, bs, workers)\n    b_its = len(data.train_dl)//n_gpus\n\n    # Using bs 256 on single GPU as baseline, scale the LR linearly\n    tot_bs = bs*n_gpus\n    bs_rat = tot_bs/256\n    lr *= bs_rat\n\n    ph1 = (TrainingPhase(tot_epochs*0.10*b_its)\n            .schedule_hp(\'lr\', (lr/10,lr),  anneal=annealing_cos))\n    ph2 = (TrainingPhase(tot_epochs*0.90*b_its)\n            .schedule_hp(\'lr\', (lr,lr/1e5), anneal=annealing_cos))\n    opt_func = partial(optim.Adam, eps=0.1, betas=(0.9,0.99))\n    learn = Learner(data, models.xresnet50(), metrics=[accuracy,top_k_accuracy], wd=1e-3,\n        opt_func=opt_func, bn_wd=False, true_wd=True,\n        loss_func = LabelSmoothingCrossEntropy()).mixup(alpha=0.2)\n\n    learn.callback_fns += [\n        partial(GeneralScheduler, phases=(ph1,ph2)),\n        partial(SaveModelCallback, every=\'epoch\', name=\'model\')\n    ]\n    learn.split(lambda m: (children(m)[-2],))\n    if gpu is None: learn.model = nn.DataParallel(learn.model)\n    else:           learn.to_distributed(gpu)\n    learn.to_fp16(dynamic=True)\n\n    learn.fit(tot_epochs, 1)\n    if rank_distrib(): time.sleep(1)\n    learn.save(\'done\')\n\n'"
examples/train_imagenette.py,2,"b'from fastai.script import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.distributed import *\nfrom fastprogress import fastprogress\nfrom torchvision.models import *\nfrom fastai.vision.models.xresnet import *\nfrom fastai.vision.models.xresnet2 import *\nfrom fastai.vision.models.presnet import *\n\ntorch.backends.cudnn.benchmark = True\nfastprogress.MAX_COLS = 80\n\ndef get_data(size, woof, bs, workers=None):\n    if   size<=128: path = URLs.IMAGEWOOF_160 if woof else URLs.IMAGENETTE_160\n    elif size<=224: path = URLs.IMAGEWOOF_320 if woof else URLs.IMAGENETTE_320\n    else          : path = URLs.IMAGEWOOF     if woof else URLs.IMAGENETTE\n    path = untar_data(path)\n\n    n_gpus = num_distrib() or 1\n    if workers is None: workers = min(8, num_cpus()//n_gpus)\n\n    return (ImageList.from_folder(path).split_by_folder(valid=\'val\')\n            .label_from_folder().transform(([flip_lr(p=0.5)], []), size=size)\n            .databunch(bs=bs, num_workers=workers)\n            .presize(size, scale=(0.35,1))\n            .normalize(imagenet_stats))\n\n@call_parse\ndef main(\n        gpu:Param(""GPU to run on"", str)=None,\n        woof: Param(""Use imagewoof (otherwise imagenette)"", int)=0,\n        lr: Param(""Learning rate"", float)=1e-3,\n        size: Param(""Size (px: 128,192,224)"", int)=128,\n        alpha: Param(""Alpha"", float)=0.99,\n        mom: Param(""Momentum"", float)=0.9,\n        eps: Param(""epsilon"", float)=1e-6,\n        epochs: Param(""Number of epochs"", int)=5,\n        bs: Param(""Batch size"", int)=256,\n        mixup: Param(""Mixup"", float)=0.,\n        opt: Param(""Optimizer (adam,rms,sgd)"", str)=\'adam\',\n        arch: Param(""Architecture (xresnet34, xresnet50, presnet34, presnet50)"", str)=\'xresnet50\',\n        dump: Param(""Print model; don\'t train"", int)=0,\n        ):\n    ""Distributed training of Imagenette.""\n\n    gpu = setup_distrib(gpu)\n    if gpu is None: bs *= torch.cuda.device_count()\n    if   opt==\'adam\' : opt_func = partial(optim.Adam, betas=(mom,alpha), eps=eps)\n    elif opt==\'rms\'  : opt_func = partial(optim.RMSprop, alpha=alpha, eps=eps)\n    elif opt==\'sgd\'  : opt_func = partial(optim.SGD, momentum=mom)\n\n    data = get_data(size, woof, bs)\n    bs_rat = bs/256\n    if gpu is not None: bs_rat *= num_distrib()\n    if not gpu: print(f\'lr: {lr}; eff_lr: {lr*bs_rat}; size: {size}; alpha: {alpha}; mom: {mom}; eps: {eps}\')\n    lr *= bs_rat\n\n    m = globals()[arch]\n    learn = (Learner(data, m(c_out=10), wd=1e-2, opt_func=opt_func,\n             metrics=[accuracy,top_k_accuracy],\n             bn_wd=False, true_wd=True,\n             loss_func = LabelSmoothingCrossEntropy())\n            )\n    if dump: print(learn.model); exit()\n    if mixup: learn = learn.mixup(alpha=mixup)\n    learn = learn.to_fp16(dynamic=True)\n    if gpu is None:       learn.to_parallel()\n    elif num_distrib()>1: learn.to_distributed(gpu) # Requires `-m fastai.launch`\n\n    learn.fit_one_cycle(epochs, lr, div_factor=10, pct_start=0.3)\n\n'"
examples/train_imagenette_adv.py,2,"b'from fastai.script import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.distributed import *\nfrom fastai.callbacks.tracker import *\ntorch.backends.cudnn.benchmark = True\nimport time\nfrom fastprogress import fastprogress\nfrom fastai.general_optimizer import *\n\nfastprogress.MAX_COLS = 80\n\ndef get_data(size, woof, bs, workers=None, use_lighting=False):\n    path = Path(\'/mnt/fe2_disk\')\n    if   size<=128: path = path/(\'imagewoof-160\' if woof else \'imagenette-160\')\n    elif size<=192: path = path/(\'imagewoof-320\' if woof else \'imagenette-320\')\n    else          : path = path/(\'imagewoof\'     if woof else \'imagenette\'    )\n\n    n_gpus = num_distrib() or 1\n    if workers is None: workers = min(8, num_cpus()//n_gpus)\n\n    tfms = [flip_lr(p=0.5)]\n    if use_lighting:\n        tfms += [brightness(change=(0.4,0.6)), contrast(scale=(0.7,1.3))]\n    return (ImageList.from_folder(path).split_by_folder(valid=\'val\')\n            .label_from_folder().transform((tfms, []), size=size)\n            .databunch(bs=bs, num_workers=workers)\n            .presize(size, scale=(0.35,1))\n            .normalize(imagenet_stats))\n\ndef get_learner(lr, size, woof, bs, opt_func, gpu, epochs):\n    data = get_data(size, woof, bs)\n    bs_rat = bs/256\n    lr *= bs_rat\n    b_its = len(data.train_dl)\n\n    ph1 = (TrainingPhase(epochs*0.5*b_its)\n            .schedule_hp(\'lr\', (lr/20,lr), anneal=annealing_cos)\n            .schedule_hp(\'eps\', (1e-4,1e-7), anneal=annealing_cos)\n            )\n    ph2 = (TrainingPhase(epochs*0.5*b_its)\n            .schedule_hp(\'lr\', (lr,lr/1e5), anneal=annealing_cos)\n            .schedule_hp(\'eps\', (1e-7,1e-7), anneal=annealing_cos)\n            )\n    learn = (Learner(data, models.xresnet50(),\n             metrics=[accuracy,top_k_accuracy], wd=1e-3, opt_func=opt_func,\n             bn_wd=False, true_wd=True, loss_func = LabelSmoothingCrossEntropy())\n        .mixup(alpha=0.2)\n        .to_fp16(dynamic=True)\n    )\n    if gpu is None:       learn.to_parallel()\n    elif num_distrib()>1: learn.to_distributed(gpu)\n\n    gs = GeneralScheduler(learn, (ph1,ph2))\n    learn.fit(epochs, lr=1, callbacks=gs)\n\ndef bn_and_final(m):\n    ll = flatten_model(m)\n    last_lin = next(o for o in reversed(ll) if isinstance(o, bias_types))\n    idx = [i for i,o in enumerate(ll) if\n           (i>50 and isinstance(o, bn_types)) or o==last_lin]\n    l1 = [o for i,o in enumerate(ll) if i not in idx]\n    l2 = [ll[i] for i in idx]\n    return split_model(splits=[l1,l2])\n\ndef on_step(self, p, group, group_idx):\n    st = self.state[p]\n    alpha = ((st[\'alpha_buffer\'] + group[\'eps\']).sqrt()\n            ) if \'alpha_buffer\' in st else mom.new_tensor(1.)\n    clip = group[\'clip\'] if \'clip\' in group else 1e9\n    alr = (st[\'alpha_buffer\']).clamp_min_(clip)\n    p.data.addcdiv_(-group[\'lr\'], st[\'momentum_buffer\'], alr)\n\n@call_parse\ndef main(\n        gpu:Param(""GPU to run on"", str)=None,\n        lr: Param(""Learning rate"", float)=1e-3,\n        size: Param(""Size (px: 128,192,224)"", int)=128,\n        debias_mom: Param(""Debias statistics"", bool)=False,\n        debias_sqr: Param(""Debias statistics"", bool)=False,\n        opt: Param(""Optimizer: \'adam\',\'genopt\',\'rms\',\'sgd\'"", str)=\'genopt\',\n        alpha: Param(""Alpha"", float)=0.99,\n        mom: Param(""Momentum"", float)=0.9,\n        eps: Param(""epsilon"", float)=1e-7,\n        decay: Param(""Decay AvgStatistic (momentum)"", bool)=False,\n        epochs: Param(""Number of epochs"", int)=5,\n        bs: Param(""Batch size"", int)=128,\n        ):\n    """"""Distributed training of Imagenette.\n    Fastest multi-gpu speed is if you run with: python -m fastai.launch""""""\n\n    # Pick one of these\n    gpu = setup_distrib(gpu)\n    if gpu is None: bs *= torch.cuda.device_count()\n\n    moms = (mom,mom)\n    stats = [\n            AvgStatistic(\'momentum\', mom,   scope=StatScope.Weight, decay=decay, debias=debias_mom),\n            AvgSquare   (\'alpha\',    alpha, scope=StatScope.Weight, debias=debias_sqr),\n            ConstStatistic(\'eps\', eps), ConstStatistic(\'clip\', 0.001),\n            ]\n    if   opt==\'adam\'  : opt_func = partial(optim.Adam, betas=(mom,alpha), eps=eps)\n    elif opt==\'rms\'   : opt_func = partial(optim.RMSprop, alpha=alpha)\n    elif opt==\'genopt\': opt_func = partial(GeneralOptimizer, on_step=on_step, stats=stats)\n    else: raise Exception(f\'unknown opt: {opt}\')\n\n    #opt_func = optim.SGD\n    #learn = (cnn_learner(data, models.xresnet50, pretrained=False, concat_pool=False, lin_ftrs=[], split_on=bn_and_final,\n    print(f\'lr: {lr}; size: {size}; debias_mom: {debias_mom}; debias_sqr: {debias_sqr}; opt: {opt}; alpha: {alpha}; mom: {mom}; eps: {eps}; decay: {decay}\')\n    print(\'imagenette\')\n    get_learner(lr, size, False, bs, opt_func, gpu, epochs)\n    gc.collect()\n\n    print(\'imagewoof\')\n    get_learner(lr, size, True, bs, opt_func, gpu, epochs)\n\n    #learn.recorder.plot_lr(show_moms=True)\n    #learn.save(\'nette\')\n\n'"
examples/train_mnist.py,0,"b'from fastai.script import *\nfrom fastai.vision import *\nfrom fastai.distributed import *\n\n@call_parse\ndef main():\n    path = url2path(URLs.MNIST_SAMPLE)\n    tfms = (rand_pad(2, 28), [])\n    data = ImageDataBunch.from_folder(path, ds_tfms=tfms, bs=64).normalize(imagenet_stats)\n    learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n    learn.fit_one_cycle(1, 0.02)\n\n'"
examples/train_wt103.py,1,"b'##To train a language model on Wikitext-103\n##`python train_wt103.py fwd` for the forward pretrained model in fastai\n##`python train_wt103.py bwd --backwards True` for the backward pretrained model in fastai\n## Takes 6 hours on a Titan RTX (24Gb RAM), adjust batch size and lr if less GPU RAM\n\nfrom fastai.text import *\nfrom fastai.script import *\nfrom fastprogress import fastprogress\n\n#Functions to parse WT103 in separate articles\ndef istitle(line):\n    return len(re.findall(r\'^ = [^=]* = $\', line)) != 0\n\ndef read_file(filename):\n    articles = []\n    with open(filename, encoding=\'utf8\') as f:\n        lines = f.readlines()\n    current_article = \'\'\n    for i,line in enumerate(lines):\n        current_article += line\n        if i < len(lines)-2 and lines[i+1] == \' \\n\' and istitle(lines[i+2]):\n            current_article = current_article.replace(\'<unk>\', UNK)\n            articles.append(current_article)\n            current_article = \'\'\n    current_article = current_article.replace(\'<unk>\', UNK)\n    articles.append(current_article)\n    return np.array(articles)\n\ndef create_data(path):\n    train = read_file(path/\'train.txt\')\n    valid = read_file(path/\'valid.txt\')\n    test =  read_file(path/\'test.txt\')\n    all_texts = np.concatenate([valid, train, test])\n    df = pd.DataFrame({\'texts\':all_texts})\n    del train ; del valid ; del test #Free RQM before tokenizing\n    data = (TextList.from_df(df, path, cols=\'texts\')\n                    .split_by_idx(range(0,60))\n                    .label_for_lm()\n                    .databunch())\n    data.save()\n\n@call_parse\ndef main(\n        name:Param(""Name of the experiment"", str, opt=False),\n        gpu:Param(""GPU to run on"", int)=0,\n        lr: Param(""Learning rate"", float)=1e-2,\n        drop_mult: Param(""Dropouts multiplicator"", float)=0.1,\n        wd: Param(""Weight Decay"", float)=0.1,\n        epochs: Param(""Number of epochs"", int)=12,\n        bs: Param(""Batch size"", int)=256,\n        bptt: Param(""Bptt"", int)=80,\n        backwards: Param(""Backward model"", bool)=False\n        ):\n    ""Training on Wikitext 103""\n    path = Config().data_path()/\'wikitext-103\'\n    fastprogress.SAVE_PATH = f\'{name}.txt\' #Save the output of the progress bar in {name}.txt\n    torch.cuda.set_device(gpu)\n    if not (path/\'data_save.pkl\').is_file(): create_data(path)\n    data = load_data(path, bs=bs, bptt=bptt, backwards=backwards)\n    learn = language_model_learner(data, AWD_LSTM, drop_mult=drop_mult, pretrained=False,\n                                   metrics=[accuracy, Perplexity()])\n    learn = learn.to_fp16(clip=0.1)\n\n    learn.fit_one_cycle(epochs, lr, moms=(0.8,0.7), div_factor=10, wd=wd)\n\n    learn = learn.to_fp32()\n    learn.save(f\'{name}\', with_opt=False)\n    learn.data.vocab.save(path/f\'{name}_vocab.pkl\')\n'"
fastai/__init__.py,0,b'from .version import __version__\n\n'
fastai/basic_data.py,10,"b'""`fastai.data` loads and manages datasets with `DataBunch`""\nfrom .torch_core import *\nfrom torch.utils.data.dataloader import default_collate\n\nDatasetType = Enum(\'DatasetType\', \'Train Valid Test Single Fix\')\n__all__ = [\'DataBunch\', \'DeviceDataLoader\', \'DatasetType\', \'load_data\']\n\nold_dl_init = torch.utils.data.DataLoader.__init__\n\ndef intercept_args(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None,\n                 num_workers=0, collate_fn=default_collate, pin_memory=True, drop_last=False,\n                 timeout=0, worker_init_fn=None):\n    self.init_kwargs = {\'batch_size\':batch_size, \'shuffle\':shuffle, \'sampler\':sampler, \'batch_sampler\':batch_sampler,\n                        \'num_workers\':num_workers, \'collate_fn\':collate_fn, \'pin_memory\':pin_memory,\n                        \'drop_last\': drop_last, \'timeout\':timeout, \'worker_init_fn\':worker_init_fn}\n    old_dl_init(self, dataset, **self.init_kwargs)\n\ntorch.utils.data.DataLoader.__init__ = intercept_args\n\ndef DataLoader___getattr__(dl, k:str)->Any: return getattr(dl.dataset, k)\nDataLoader.__getattr__ = DataLoader___getattr__\n\ndef DataLoader___setstate__(dl, data:Any): dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n\n@dataclass\nclass DeviceDataLoader():\n    ""Bind a `DataLoader` to a `torch.device`.""\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable]=None\n    collate_fn: Callable=data_collate\n    def __post_init__(self):\n        self.dl.collate_fn=self.collate_fn\n        self.tfms = listify(self.tfms)\n\n    def __len__(self)->int: return len(self.dl)\n    def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n    def __setstate__(self,data:Any): self.__dict__.update(data)\n\n    @property\n    def batch_size(self):   return self.dl.batch_size\n    @batch_size.setter\n    def batch_size(self,v):\n        new_kwargs = {**self.dl.init_kwargs, \'batch_size\':v, \'collate_fn\':self.collate_fn}\n        self.dl = self.dl.__class__(self.dl.dataset, **new_kwargs)\n        if hasattr(self.dl.dataset, \'bs\'): self.dl.dataset.bs = v\n\n    @property\n    def num_workers(self):   return self.dl.num_workers\n    @num_workers.setter\n    def num_workers(self,v): self.dl.num_workers = v\n\n    def add_tfm(self,tfm:Callable)->None:\n        ""Add `tfm` to `self.tfms`.""\n        self.tfms.append(tfm)\n    def remove_tfm(self,tfm:Callable)->None:\n        ""Remove `tfm` from `self.tfms`.""\n        if tfm in self.tfms: self.tfms.remove(tfm)\n\n    def new(self, **kwargs):\n        ""Create a new copy of `self` with `kwargs` replacing current values.""\n        new_kwargs = {**self.dl.init_kwargs, **kwargs}\n        return DeviceDataLoader(self.dl.__class__(self.dl.dataset, **new_kwargs), self.device, self.tfms,\n                                self.collate_fn)\n\n    def proc_batch(self,b:Tensor)->Tensor:\n        ""Process batch `b` of `TensorImage`.""\n        b = to_device(b, self.device)\n        for f in listify(self.tfms): b = f(b)\n        return b\n\n    def __iter__(self):\n        ""Process and returns items from `DataLoader`.""\n        for b in self.dl: yield self.proc_batch(b)\n\n    @classmethod\n    def create(cls, dataset:Dataset, bs:int=64, shuffle:bool=False, device:torch.device=defaults.device,\n               tfms:Collection[Callable]=tfms, num_workers:int=defaults.cpus, collate_fn:Callable=data_collate, **kwargs:Any):\n        ""Create DeviceDataLoader from `dataset` with `bs` and `shuffle`: process using `num_workers`.""\n        return cls(DataLoader(dataset, batch_size=bs, shuffle=shuffle, num_workers=num_workers, **kwargs),\n                   device=device, tfms=tfms, collate_fn=collate_fn)\n\nclass DataBunch():\n    ""Bind `train_dl`,`valid_dl` and `test_dl` in a data object.""\n\n    def __init__(self, train_dl:DataLoader, valid_dl:DataLoader, fix_dl:DataLoader=None, test_dl:Optional[DataLoader]=None,\n                 device:torch.device=None, dl_tfms:Optional[Collection[Callable]]=None, path:PathOrStr=\'.\',\n                 collate_fn:Callable=data_collate, no_check:bool=False):\n        self.dl_tfms = listify(dl_tfms)\n        self.device = defaults.device if device is None else device\n        assert not isinstance(train_dl,DeviceDataLoader)\n        def _create_dl(dl, **kwargs):\n            if dl is None: return None\n            return DeviceDataLoader(dl, self.device, self.dl_tfms, collate_fn, **kwargs)\n        self.train_dl,self.valid_dl,self.fix_dl,self.test_dl = map(_create_dl, [train_dl,valid_dl,fix_dl,test_dl])\n        if fix_dl is None: self.fix_dl = self.train_dl.new(shuffle=False, drop_last=False)\n        self.single_dl = _create_dl(DataLoader(valid_dl.dataset, batch_size=1, num_workers=0))\n        self.path = Path(path)\n        if not no_check: self.sanity_check()\n\n    def __repr__(self)->str:\n        return f\'{self.__class__.__name__};\\n\\nTrain: {self.train_ds};\\n\\nValid: {self.valid_ds};\\n\\nTest: {self.test_ds}\'\n\n    @staticmethod\n    def _init_ds(train_ds:Dataset, valid_ds:Dataset, test_ds:Optional[Dataset]=None):\n        # train_ds, but without training tfms\n        fix_ds = valid_ds.new(train_ds.x, train_ds.y) if hasattr(valid_ds,\'new\') else train_ds\n        return [o for o in (train_ds,valid_ds,fix_ds,test_ds) if o is not None]\n\n    @classmethod\n    def create(cls, train_ds:Dataset, valid_ds:Dataset, test_ds:Optional[Dataset]=None, path:PathOrStr=\'.\', bs:int=64,\n               val_bs:int=None, num_workers:int=defaults.cpus, dl_tfms:Optional[Collection[Callable]]=None,\n               device:torch.device=None, collate_fn:Callable=data_collate, no_check:bool=False, **dl_kwargs)->\'DataBunch\':\n        ""Create a `DataBunch` from `train_ds`, `valid_ds` and maybe `test_ds` with a batch size of `bs`. Passes `**dl_kwargs` to `DataLoader()`""\n        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n        val_bs = ifnone(val_bs, bs)\n        dls = [DataLoader(d, b, shuffle=s, drop_last=s, num_workers=num_workers, **dl_kwargs) for d,b,s in\n               zip(datasets, (bs,val_bs,val_bs,val_bs), (True,False,False,False)) if d is not None]\n        return cls(*dls, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)\n\n    def __getattr__(self,k:int)->Any: return getattr(self.train_dl, k)\n    def __setstate__(self,data:Any): self.__dict__.update(data)\n\n    def dl(self, ds_type:DatasetType=DatasetType.Valid)->DeviceDataLoader:\n        ""Returns an appropriate `DataLoader` with a dataset for validation, training, or test (`ds_type`).""\n        #TODO: refactor\n        return (self.train_dl if ds_type == DatasetType.Train else\n                self.test_dl if ds_type == DatasetType.Test else\n                self.valid_dl if ds_type == DatasetType.Valid else\n                self.single_dl if ds_type == DatasetType.Single else\n                self.fix_dl)\n\n    @property\n    def dls(self)->List[DeviceDataLoader]:\n        ""Returns a list of all DeviceDataLoaders. If you need a specific DeviceDataLoader, access via the relevant property (`train_dl`, `valid_dl`, etc) as the index of DLs in this list is not guaranteed to remain constant.""\n        res = [self.train_dl, self.fix_dl, self.single_dl]\n        # Preserve the original ordering of Train, Valid, Fix, Single, Test Data Loaders\n        # (Unknown/not verified as of 1.0.47 whether there are other methods explicitly using DLs their list index)\n        if self.valid_dl: res.insert(1, self.valid_dl)\n        return res if not self.test_dl else res + [self.test_dl]\n\n    def add_tfm(self,tfm:Callable)->None:\n        for dl in self.dls: dl.add_tfm(tfm)\n\n    def remove_tfm(self,tfm:Callable)->None:\n        for dl in self.dls: dl.remove_tfm(tfm)\n\n    def save(self, file:PathLikeOrBinaryStream= \'data_save.pkl\')->None:\n        ""Save the `DataBunch` in `self.path/file`. `file` can be file-like (file or buffer)""\n        if rank_distrib(): return # don\'t save if slave proc\n        if not getattr(self, \'label_list\', False):\n            warn(""Serializing the `DataBunch` only works when you created it using the data block API."")\n            return\n        try_save(self.label_list, self.path, file)\n\n    def add_test(self, items:Iterator, label:Any=None, tfms=None, tfm_y=None)->None:\n        ""Add the `items` as a test set. Pass along `label` otherwise label them with `EmptyLabel`.""\n        self.label_list.add_test(items, label=label, tfms=tfms, tfm_y=tfm_y)\n        vdl = self.valid_dl\n        dl = DataLoader(self.label_list.test, vdl.batch_size, shuffle=False, drop_last=False, num_workers=vdl.num_workers)\n        self.test_dl = DeviceDataLoader(dl, vdl.device, vdl.tfms, vdl.collate_fn)\n\n    def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n        ""Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.""\n        dl = self.dl(ds_type)\n        w = dl.num_workers\n        dl.num_workers = 0\n        try:     x,y = next(iter(dl))\n        finally: dl.num_workers = w\n        if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)\n        norm = getattr(self,\'norm\',False)\n        if denorm and norm:\n            x = self.denorm(x)\n            if norm.keywords.get(\'do_y\',False): y = self.denorm(y, do_x=True)\n        return x,y\n\n    def one_item(self, item, detach:bool=False, denorm:bool=False, cpu:bool=False):\n        ""Get `item` into a batch. Optionally `detach` and `denorm`.""\n        ds = self.single_ds\n        with ds.set_item(item):\n            return self.one_batch(ds_type=DatasetType.Single, detach=detach, denorm=denorm, cpu=cpu)\n\n    def show_batch(self, rows:int=5, ds_type:DatasetType=DatasetType.Train, reverse:bool=False, **kwargs)->None:\n        ""Show a batch of data in `ds_type` on a few `rows`.""\n        x,y = self.one_batch(ds_type, True, True)\n        if reverse: x,y = x.flip(0),y.flip(0)\n        n_items = rows **2 if self.train_ds.x._square_show else rows\n        if self.dl(ds_type).batch_size < n_items: n_items = self.dl(ds_type).batch_size\n        xs = [self.train_ds.x.reconstruct(grab_idx(x, i)) for i in range(n_items)]\n        #TODO: get rid of has_arg if possible\n        if has_arg(self.train_ds.y.reconstruct, \'x\'):\n            ys = [self.train_ds.y.reconstruct(grab_idx(y, i), x=x) for i,x in enumerate(xs)]\n        else : ys = [self.train_ds.y.reconstruct(grab_idx(y, i)) for i in range(n_items)]\n        self.train_ds.x.show_xys(xs, ys, **kwargs)\n\n    def export(self, file:PathLikeOrBinaryStream=\'export.pkl\'):\n        ""Export the minimal state of `self` for inference in `self.path/file`. `file` can be file-like (file or buffer)""\n        xtra = dict(normalize=self.norm.keywords) if getattr(self, \'norm\', False) else {}\n        try_save(self.valid_ds.get_state(**xtra), self.path, file)\n\n    def _grab_dataset(self, dl:DataLoader):\n        ds = dl.dl.dataset\n        while hasattr(ds, \'dataset\'): ds = ds.dataset\n        return ds\n\n    @property\n    def train_ds(self)->Dataset: return self._grab_dataset(self.train_dl)\n    @property\n    def fix_ds(self)->Dataset: return self._grab_dataset(self.fix_dl)\n    @property\n    def valid_ds(self)->Dataset: return self._grab_dataset(self.valid_dl)\n    @property\n    def single_ds(self)->Dataset: return self._grab_dataset(self.single_dl)\n    @property\n    def loss_func(self)->OptLossFunc:\n        return getattr(self.train_ds.y, \'loss_func\', F.nll_loss) if hasattr(self.train_ds, \'y\') else F.nll_loss\n\n    @property\n    def test_ds(self)->Dataset:\n        return self._grab_dataset(self.test_dl) if self.test_dl is not None else None\n\n    @property\n    def empty_val(self)->bool:\n        if not hasattr(self, \'valid_dl\') or self.valid_dl is None:            return True\n        if hasattr(self.valid_ds, \'items\') and len(self.valid_ds.items) == 0: return True\n        return (len(self.valid_ds) == 0)\n\n    @property\n    def is_empty(self)->bool:\n        return not ((self.train_dl and len(self.train_ds.items) != 0) or\n                    (self.valid_dl and len(self.valid_ds.items) != 0) or\n                    (self.test_dl  and len(self.test_ds.items)  != 0))\n\n    @property\n    def batch_size(self):   return self.train_dl.batch_size\n    @batch_size.setter\n    def batch_size(self,v):\n        self.train_dl.batch_size,self.valid_dl.batch_size = v,v\n        if self.test_dl is not None: self.test_dl.batch_size = v\n\n    def sanity_check(self):\n        ""Check the underlying data in the training set can be properly loaded.""\n        final_message = ""You can deactivate this warning by passing `no_check=True`.""\n        if not hasattr(self.train_ds, \'items\') or len(self.train_ds.items) == 0 or not hasattr(self.train_dl, \'batch_sampler\'): return\n        if len(self.train_dl) == 0:\n            warn(f""""""Your training dataloader is empty, you have only {len(self.train_dl.dataset)} items in your training set.\n                 Your batch size is {self.train_dl.batch_size}, you should lower it."""""")\n            print(final_message)\n            return\n        idx = next(iter(self.train_dl.batch_sampler))\n        samples,fails = [],[]\n        for i in idx:\n            try:    samples.append(self.train_dl.dataset[i])\n            except: fails.append(i)\n        if len(fails) > 0:\n            warn_msg = ""There seems to be something wrong with your dataset, for example, in the first batch can\'t access""\n            if len(fails) == len(idx):\n                warn_msg += f"" any element of self.train_ds.\\nTried: {show_some(idx)}""\n            else:\n                warn_msg += f"" these elements in self.train_ds: {show_some(fails)}""\n            warn(warn_msg)\n            print(final_message)\n            return\n        try: batch = self.collate_fn(samples)\n        except:\n            message = ""It\'s not possible to collate samples of your dataset together in a batch.""\n            try:\n                shapes = [[o[i].data.shape for o in samples] for i in range(2)]\n                message += f\'\\nShapes of the inputs/targets:\\n{shapes}\'\n            except: pass\n            warn(message)\n            print(final_message)\n\ndef load_data(path:PathOrStr, file:PathLikeOrBinaryStream=\'data_save.pkl\', bs:int=64, val_bs:int=None, num_workers:int=defaults.cpus,\n              dl_tfms:Optional[Collection[Callable]]=None, device:torch.device=None, collate_fn:Callable=data_collate,\n              no_check:bool=False, **kwargs)->DataBunch:\n    ""Load a saved `DataBunch` from `path/file`. `file` can be file-like (file or buffer)""\n    source = Path(path)/file if is_pathlike(file) else file\n    distrib_barrier()\n    ll = torch.load(source, map_location=\'cpu\') if defaults.device == torch.device(\'cpu\') else torch.load(source)\n    return ll.databunch(path=path, bs=bs, val_bs=val_bs, num_workers=num_workers, dl_tfms=dl_tfms, device=device,\n                        collate_fn=collate_fn, no_check=no_check, **kwargs)\n'"
fastai/basic_train.py,14,"b'""Provides basic training and validation with `Learner`""\nfrom .torch_core import *\nfrom .basic_data import *\nfrom .callback import *\nfrom .data_block import *\nfrom .utils.ipython import gpu_mem_restore\nimport inspect\nfrom fastprogress.fastprogress import format_time, IN_NOTEBOOK\nfrom time import time\nfrom .sixel import plot_sixel\n\n__all__ = [\'Learner\', \'LearnerCallback\', \'Recorder\', \'RecordOnCPU\', \'fit\', \'loss_batch\', \'train_epoch\', \'validate\',\n           \'get_preds\', \'load_learner\']\n\ndefaults.lr = slice(3e-3)\ndefaults.wd = 1e-2\ndefaults.extra_callbacks    = None\ndefaults.extra_callback_fns = None\n\ndef loss_batch(model:nn.Module, xb:Tensor, yb:Tensor, loss_func:OptLossFunc=None, opt:OptOptimizer=None,\n               cb_handler:Optional[CallbackHandler]=None)->Tuple[Union[Tensor,int,float,str]]:\n    ""Calculate loss and metrics for a batch, call out to callbacks as necessary.""\n    cb_handler = ifnone(cb_handler, CallbackHandler())\n    if not is_listy(xb): xb = [xb]\n    if not is_listy(yb): yb = [yb]\n    out = model(*xb)\n    out = cb_handler.on_loss_begin(out)\n\n    if not loss_func: return to_detach(out), to_detach(yb[0])\n    loss = loss_func(out, *yb)\n\n    if opt is not None:\n        loss,skip_bwd = cb_handler.on_backward_begin(loss)\n        if not skip_bwd:                     loss.backward()\n        if not cb_handler.on_backward_end(): opt.step()\n        if not cb_handler.on_step_end():     opt.zero_grad()\n\n    return loss.detach().cpu()\n\ndef get_preds(model:nn.Module, dl:DataLoader, pbar:Optional[PBar]=None, cb_handler:Optional[CallbackHandler]=None,\n              activ:nn.Module=None, loss_func:OptLossFunc=None, n_batch:Optional[int]=None) -> List[Tensor]:\n    ""Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.""\n    res = [to_float(torch.cat(o).cpu()) for o in\n           zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\n    if loss_func is not None:\n        with NoneReduceOnCPU(loss_func) as lf: res.append(lf(res[0], res[1]))\n    if activ is not None: res[0] = activ(res[0])\n    return res\n\ndef validate(model:nn.Module, dl:DataLoader, loss_func:OptLossFunc=None, cb_handler:Optional[CallbackHandler]=None,\n             pbar:Optional[PBar]=None, average=True, n_batch:Optional[int]=None)->Iterator[Tuple[Union[Tensor,int],...]]:\n    ""Calculate `loss_func` of `model` on `dl` in evaluation mode.""\n    model.eval()\n    with torch.no_grad():\n        val_losses,nums = [],[]\n        if cb_handler: cb_handler.set_dl(dl)\n        for xb,yb in progress_bar(dl, parent=pbar, leave=(pbar is not None)):\n            if cb_handler: xb, yb = cb_handler.on_batch_begin(xb, yb, train=False)\n            val_loss = loss_batch(model, xb, yb, loss_func, cb_handler=cb_handler)\n            val_losses.append(val_loss)\n            if not is_listy(yb): yb = [yb]\n            nums.append(first_el(yb).shape[0])\n            if cb_handler and cb_handler.on_batch_end(val_losses[-1]): break\n            if n_batch and (len(nums)>=n_batch): break\n        nums = np.array(nums, dtype=np.float32)\n        if average: return (to_np(torch.stack(val_losses)) * nums).sum() / nums.sum()\n        else:       return val_losses\n\ndef train_epoch(model:nn.Module, dl:DataLoader, opt:optim.Optimizer, loss_func:LossFunction)->None:\n    ""Simple training of `model` for 1 epoch of `dl` using optim `opt` and loss function `loss_func`.""\n    model.train()\n    for xb,yb in dl:\n        loss = loss_func(model(xb), yb)\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n\n@dataclass\nclass BasicLearner():\n    model:nn.Module\n    loss_func:LossFunction\n    opt:optim.Optimizer\n    data:DataBunch\n\ndef fit(epochs:int, learn:BasicLearner, callbacks:Optional[CallbackList]=None, metrics:OptMetrics=None)->None:\n    ""Fit the `model` on `data` and learn using `loss_func` and `opt`.""\n    assert len(learn.data.train_dl) != 0, f""""""Your training dataloader is empty, can\'t train a model.\n        Use a smaller batch size (batch size={learn.data.train_dl.batch_size} for {len(learn.data.train_dl.dataset)} elements).""""""\n    cb_handler = CallbackHandler(callbacks, metrics)\n    pbar = master_bar(range(epochs))\n    cb_handler.on_train_begin(epochs, pbar=pbar, metrics=metrics)\n\n    exception=False\n    try:\n        for epoch in pbar:\n            learn.model.train()\n            cb_handler.set_dl(learn.data.train_dl)\n            cb_handler.on_epoch_begin()\n            for xb,yb in progress_bar(learn.data.train_dl, parent=pbar):\n                xb, yb = cb_handler.on_batch_begin(xb, yb)\n                loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)\n                if cb_handler.on_batch_end(loss): break\n\n            if not cb_handler.skip_validate and not learn.data.empty_val:\n                val_loss = validate(learn.model, learn.data.valid_dl, loss_func=learn.loss_func,\n                                       cb_handler=cb_handler, pbar=pbar)\n            else: val_loss=None\n            if cb_handler.on_epoch_end(val_loss): break\n    except Exception as e:\n        exception = e\n        raise\n    finally: cb_handler.on_train_end(exception)\n\nloss_func_name2activ = {\'cross_entropy_loss\': F.softmax, \'nll_loss\': torch.exp, \'poisson_nll_loss\': torch.exp,\n    \'kl_div_loss\': torch.exp, \'bce_with_logits_loss\': torch.sigmoid, \'cross_entropy\': F.softmax,\n    \'kl_div\': torch.exp, \'binary_cross_entropy_with_logits\': torch.sigmoid,\n}\n\ndef _loss_func_name2activ(name:str, axis:int=-1):\n    res = loss_func_name2activ[name]\n    if res == F.softmax: res = partial(F.softmax, dim=axis)\n    return res\n\ndef _loss_func2activ(loss_func):\n    if getattr(loss_func,\'keywords\',None):\n        if not loss_func.keywords.get(\'log_input\', True): return\n    axis = getattr(loss_func, \'axis\', -1)\n    # flattened loss\n    loss_func = getattr(loss_func, \'func\', loss_func)\n    # could have a partial inside flattened loss! Duplicate on purpose.\n    loss_func = getattr(loss_func, \'func\', loss_func)\n    cls_name = camel2snake(loss_func.__class__.__name__)\n    if cls_name == \'mix_up_loss\':\n        loss_func = loss_func.crit\n        cls_name = camel2snake(loss_func.__class__.__name__)\n    if cls_name in loss_func_name2activ:\n        if cls_name == \'poisson_nll_loss\' and (not getattr(loss_func, \'log_input\', True)): return\n        return _loss_func_name2activ(cls_name, axis)\n    if getattr(loss_func,\'__name__\',\'\') in loss_func_name2activ:\n        return _loss_func_name2activ(loss_func.__name__, axis)\n    return noop\n\n@dataclass\nclass Learner():\n    ""Trainer for `model` using `data` to minimize `loss_func` with optimizer `opt_func`.""\n    data:DataBunch\n    model:nn.Module\n    opt_func:Callable=AdamW\n    loss_func:Callable=None\n    metrics:Collection[Callable]=None\n    true_wd:bool=True\n    bn_wd:bool=True\n    wd:Floats=defaults.wd\n    train_bn:bool=True\n    path:str = None\n    model_dir:PathOrStr = \'models\'\n    callback_fns:Collection[Callable]=None\n    callbacks:Collection[Callback]=field(default_factory=list)\n    layer_groups:Collection[nn.Module]=None\n    add_time:bool=True\n    silent:bool=None\n    def __post_init__(self)->None:\n        ""Setup path,metrics, callbacks and ensure model directory exists.""\n        self.path = Path(ifnone(self.path, self.data.path))\n        self.model = self.model.to(self.data.device)\n        self.loss_func = self.loss_func or self.data.loss_func\n        self.metrics=listify(self.metrics)\n        if not self.layer_groups: self.layer_groups = [nn.Sequential(*flatten_model(self.model))]\n        self.callbacks = listify(self.callbacks)\n        if self.silent is None: self.silent = defaults.silent\n        self.callback_fns = [partial(Recorder, add_time=self.add_time, silent=self.silent)] + listify(self.callback_fns)\n        if defaults.extra_callbacks is not None: self.callbacks += defaults.extra_callbacks\n\n    def init(self, init): apply_init(self.model, init)\n\n    def _test_writeable_path(self):\n        path = self.path/self.model_dir\n        try:\n            path.mkdir(parents=True, exist_ok=True)\n            tmp_file = get_tmp_file(path)\n        except OSError as e:\n            raise Exception(f""{e}\\nCan\'t write to \'{path}\', set `learn.model_dir` attribute in Learner to a full libpath path that is writable"") from None\n        os.remove(tmp_file)\n\n    def lr_range(self, lr:Union[float,slice])->np.ndarray:\n        ""Build differential learning rates from `lr`.""\n        if not isinstance(lr,slice): return lr\n        if lr.start: res = even_mults(lr.start, lr.stop, len(self.layer_groups))\n        else: res = [lr.stop/10]*(len(self.layer_groups)-1) + [lr.stop]\n        return np.array(res)\n\n    def fit(self, epochs:int, lr:Union[Floats,slice]=defaults.lr,\n            wd:Floats=None, callbacks:Collection[Callback]=None)->None:\n        ""Fit the model on this learner with `lr` learning rate, `wd` weight decay for `epochs` with `callbacks`.""\n        lr = self.lr_range(lr)\n        if wd is None: wd = self.wd\n        if not getattr(self, \'opt\', False): self.create_opt(lr, wd)\n        else: self.opt.lr,self.opt.wd = lr,wd\n        callbacks = [cb(self) for cb in self.callback_fns + listify(defaults.extra_callback_fns)] + listify(callbacks)\n        fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)\n\n    def create_opt(self, lr:Floats, wd:Floats=0.)->None:\n        ""Create optimizer with `lr` learning rate and `wd` weight decay.""\n        self.opt = OptimWrapper.create(self.opt_func, lr, self.layer_groups, wd=wd, true_wd=self.true_wd, bn_wd=self.bn_wd)\n\n    def split(self, split_on:SplitFuncOrIdxList)->None:\n        ""Split the model at `split_on`.""\n        if isinstance(split_on,Callable): split_on = split_on(self.model)\n        self.layer_groups = split_model(self.model, split_on)\n        return self\n\n    def freeze_to(self, n:int)->None:\n        ""Freeze layers up to layer group `n`.""\n        if hasattr(self.model, \'reset\'): self.model.reset()\n        for g in self.layer_groups[:n]:\n            for l in g:\n                if not self.train_bn or not isinstance(l, bn_types): requires_grad(l, False)\n        for g in self.layer_groups[n:]: requires_grad(g, True)\n        self.create_opt(defaults.lr)\n\n    def freeze(self)->None:\n        ""Freeze up to last layer group.""\n        assert(len(self.layer_groups)>1)\n        self.freeze_to(-1)\n\n    def unfreeze(self):\n        ""Unfreeze entire model.""\n        self.freeze_to(0)\n\n    def export(self, file:PathLikeOrBinaryStream=\'export.pkl\', destroy=False):\n        ""Export the state of the `Learner` in `self.path/file`. `file` can be file-like (file or buffer)""\n        if rank_distrib(): return # don\'t save if slave proc\n        args = [\'opt_func\', \'loss_func\', \'metrics\', \'true_wd\', \'bn_wd\', \'wd\', \'train_bn\', \'model_dir\', \'callback_fns\']\n        state = {a:getattr(self,a) for a in args}\n        state[\'cb_state\'] = {cb.__class__:cb.get_state() for cb in self.callbacks}\n        #layer_groups -> need to find a way\n        #TO SEE: do we save model structure and weights separately?\n        with ModelOnCPU(self.model) as m:\n            state[\'model\'] = m\n            xtra = dict(normalize=self.data.norm.keywords) if getattr(self.data, \'norm\', False) else {}\n            state[\'data\'] = self.data.valid_ds.get_state(**xtra)\n            state[\'cls\'] = self.__class__\n            try_save(state, self.path, file)\n        if destroy: self.destroy()\n\n    def save(self, file:PathLikeOrBinaryStream=None, return_path:bool=False, with_opt:bool=True):\n        ""Save model and optimizer state (if `with_opt`) with `file` to `self.model_dir`. `file` can be file-like (file or buffer)""\n        if is_pathlike(file): self._test_writeable_path()\n        if rank_distrib(): return # don\'t save if slave proc\n        target = self.path/self.model_dir/f\'{file}.pth\' if is_pathlike(file) else file\n        if not hasattr(self, \'opt\'): with_opt=False\n        if not with_opt: state = get_model(self.model).state_dict()\n        else: state = {\'model\': get_model(self.model).state_dict(), \'opt\':self.opt.state_dict()}\n        torch.save(state, target)\n        if return_path: return target\n\n    def dl(self, ds_type:DatasetType=DatasetType.Valid):\n        ""Return DataLoader for DatasetType `ds_type`.""\n        return self.data.dl(ds_type)\n\n    def load(self, file:PathLikeOrBinaryStream=None, device:torch.device=None, strict:bool=True,\n             with_opt:bool=None, purge:bool=False, remove_module:bool=False)->\'Learner\':\n        ""Load model and optimizer state (if `with_opt`) `file` from `self.model_dir` using `device`. `file` can be file-like (file or buffer)""\n        if purge: self.purge(clear_opt=ifnone(with_opt, False))\n        if device is None: device = self.data.device\n        elif isinstance(device, int): device = torch.device(\'cuda\', device)\n        source = self.path/self.model_dir/f\'{file}.pth\' if is_pathlike(file) else file\n        distrib_barrier()\n        state = torch.load(source, map_location=device)\n        if set(state.keys()) == {\'model\', \'opt\'}:\n            model_state = state[\'model\']\n            if remove_module: model_state = remove_module_load(model_state)\n            get_model(self.model).load_state_dict(model_state, strict=strict)\n            if ifnone(with_opt,True):\n                if not hasattr(self, \'opt\'): self.create_opt(defaults.lr, self.wd)\n                try:    self.opt.load_state_dict(state[\'opt\'])\n                except: pass\n        else:\n            if with_opt: warn(""Saved filed doesn\'t contain an optimizer state."")\n            if remove_module: state = remove_module_load(state)\n            get_model(self.model).load_state_dict(state, strict=strict)\n        del state\n        gc.collect()\n        return self\n\n    def destroy(self):\n        ""Free the Learner internals, leaving just an empty shell that consumes no memory""\n\n        class ZombieLearner(Learner):\n            msg = ""this object has been destroyed""\n            def __getattr__(self, item):    print(ZombieLearner.msg); return None\n            def destroyed(*args, **kwargs): print(ZombieLearner.msg)\n\n        attrs = [k for k in self.__dict__.keys() if not k.startswith(""__"")]\n        for a in attrs: delattr(self, a)\n        # the instance methods can still be called, but will just give a message\n        methods = [k for k in dir(self) if not k.startswith(""__"") and inspect.isroutine(getattr(self, k))]\n        for m in methods: setattr(self, m, ZombieLearner.destroyed)\n        self.__class__ = ZombieLearner\n        gc.collect()\n        print(""this Learner object self-destroyed - it still exists, but no longer usable"")\n\n    def purge(self, clear_opt:bool=True):\n        ""Purge the `Learner` of all cached attributes to release some GPU memory.""\n        self._test_writeable_path()\n        attrs_all = [k for k in self.__dict__.keys() if not k.startswith(""__"")]\n        attrs_pkl = [\'bn_wd\', \'callback_fns\', \'layer_groups\', \'loss_func\', \'metrics\', \'model\',\n                     \'model_dir\', \'opt_func\', \'path\', \'train_bn\', \'true_wd\', \'wd\']\n        # +callbacks: get pickled too, but not directly\n        attrs_keep = [\'data\', \'recorder\']\n        attrs_del = list(set(attrs_all) - set(attrs_keep))\n        state = {a:getattr(self, a) for a in attrs_pkl}\n        state[\'cb_state\'] = {cb.__class__:cb.get_state() for cb in self.callbacks}\n        if hasattr(self, \'opt\'): state[\'opt\'] = self.opt.get_state()\n\n        tmp_file = get_tmp_file(self.path/self.model_dir)\n        torch.save(state, open(tmp_file, \'wb\'))\n        for a in attrs_del: delattr(self, a)\n        gc.collect()\n        state = torch.load(tmp_file)\n        os.remove(tmp_file)\n\n        for a in attrs_pkl: setattr(self, a, state[a])\n        cb_state = state.pop(\'cb_state\')\n        self.callbacks = [load_callback(c,s, self) for c,s in cb_state.items()]\n        if not clear_opt and \'opt\' in state:\n            try: self.opt = OptimWrapper.load_with_state_and_layer_group(state[\'opt\'], self.layer_groups)\n            except: warn(""Wasn\'t able to properly load the optimizer state again."")\n        del state\n        gc.collect()\n        return self\n\n    def get_preds(self, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None,\n                  with_loss:bool=False, n_batch:Optional[int]=None, pbar:Optional[PBar]=None) -> List[Tensor]:\n        ""Return predictions and targets on `ds_type` dataset.""\n        lf = self.loss_func if with_loss else None\n        activ = ifnone(activ, _loss_func2activ(self.loss_func))\n        if not getattr(self, \'opt\', False): self.create_opt(defaults.lr, self.wd)\n        callbacks = [cb(self) for cb in self.callback_fns + listify(defaults.extra_callback_fns)] + listify(self.callbacks)\n        return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(callbacks),\n                         activ=activ, loss_func=lf, n_batch=n_batch, pbar=pbar)\n\n    def pred_batch(self, ds_type:DatasetType=DatasetType.Valid, batch:Tuple=None, reconstruct:bool=False,\n                   with_dropout:bool=False, activ:nn.Module=None) -> List[Tensor]:\n        ""Return output of the model on one batch from `ds_type` dataset.""\n        if batch is not None: xb,yb = batch\n        else: xb,yb = self.data.one_batch(ds_type, detach=False, denorm=False)\n        cb_handler = CallbackHandler(self.callbacks)\n        xb,yb = cb_handler.on_batch_begin(xb,yb, train=False)\n        activ = ifnone(activ, _loss_func2activ(self.loss_func))\n        with torch.no_grad():\n            if not with_dropout: preds = loss_batch(self.model.eval(), xb, yb, cb_handler=cb_handler)\n            else: preds = loss_batch(self.model.eval().apply(self.apply_dropout), xb, yb, cb_handler=cb_handler)\n            res = activ(preds[0])\n        if not reconstruct: return res\n        res = res.detach().cpu()\n        ds = self.dl(ds_type).dataset\n        norm = getattr(self.data, \'norm\', False)\n        if norm and norm.keywords.get(\'do_y\',False):\n            res = self.data.denorm(res, do_x=True)\n        return [ds.reconstruct(o) for o in res]\n\n    def backward(self, item):\n        ""Pass `item` through the model and computes the gradient. Useful if `backward_hooks` are attached.""\n        xb,yb = self.data.one_item(item)\n        loss = loss_batch(self.model.eval(), xb, yb, self.loss_func, opt=FakeOptimizer(),\n                          cb_handler=CallbackHandler(self.callbacks))\n        return loss\n\n    def predict(self, item:ItemBase, return_x:bool=False, batch_first:bool=True, with_dropout:bool=False, **kwargs):\n        ""Return predicted class, label and probabilities for `item`.""\n        batch = self.data.one_item(item)\n        res = self.pred_batch(batch=batch, with_dropout=with_dropout)\n        raw_pred,x = grab_idx(res,0,batch_first=batch_first),batch[0]\n        norm = getattr(self.data,\'norm\',False)\n        if norm:\n            x = self.data.denorm(x)\n            if norm.keywords.get(\'do_y\',False): raw_pred = self.data.denorm(raw_pred)\n        ds = self.data.single_ds\n        pred = ds.y.analyze_pred(raw_pred, **kwargs)\n        x = ds.x.reconstruct(grab_idx(x, 0))\n        y = ds.y.reconstruct(pred, x) if has_arg(ds.y.reconstruct, \'x\') else ds.y.reconstruct(pred)\n        return (x, y, pred, raw_pred) if return_x else (y, pred, raw_pred)\n\n    def validate(self, dl=None, callbacks=None, metrics=None):\n        ""Validate on `dl` with potential `callbacks` and `metrics`.""\n        dl = ifnone(dl, self.data.valid_dl)\n        metrics = ifnone(metrics, self.metrics)\n        cb_handler = CallbackHandler(self.callbacks + ifnone(callbacks, []), metrics)\n        cb_handler.on_train_begin(1, None, metrics); cb_handler.on_epoch_begin()\n        val_metrics = validate(self.model, dl, self.loss_func, cb_handler)\n        cb_handler.on_epoch_end(val_metrics)\n        return cb_handler.state_dict[\'last_metrics\']\n\n    def show_results(self, ds_type=DatasetType.Valid, rows:int=5, **kwargs):\n        ""Show `rows` result of predictions on `ds_type` dataset.""\n        #TODO: get read of has_arg x and split_kwargs_by_func if possible\n        #TODO: simplify this and refactor with pred_batch(...reconstruct=True)\n        n_items = rows ** 2 if self.data.train_ds.x._square_show_res else rows\n        if self.dl(ds_type).batch_size < n_items: n_items = self.dl(ds_type).batch_size\n        ds = self.dl(ds_type).dataset\n        self.callbacks.append(RecordOnCPU())\n        preds = self.pred_batch(ds_type)\n        *self.callbacks,rec_cpu = self.callbacks\n        x,y = rec_cpu.input,rec_cpu.target\n        norm = getattr(self.data,\'norm\',False)\n        if norm:\n            x = self.data.denorm(x)\n            if norm.keywords.get(\'do_y\',False):\n                y     = self.data.denorm(y, do_x=True)\n                preds = self.data.denorm(preds, do_x=True)\n        analyze_kwargs,kwargs = split_kwargs_by_func(kwargs, ds.y.analyze_pred)\n        preds = [ds.y.analyze_pred(grab_idx(preds, i), **analyze_kwargs) for i in range(n_items)]\n        xs = [ds.x.reconstruct(grab_idx(x, i)) for i in range(n_items)]\n        if has_arg(ds.y.reconstruct, \'x\'):\n            ys = [ds.y.reconstruct(grab_idx(y, i), x=x) for i,x in enumerate(xs)]\n            zs = [ds.y.reconstruct(z, x=x) for z,x in zip(preds,xs)]\n        else :\n            ys = [ds.y.reconstruct(grab_idx(y, i)) for i in range(n_items)]\n            zs = [ds.y.reconstruct(z) for z in preds]\n        ds.x.show_xyzs(xs, ys, zs, **kwargs)\n\n    def apply_dropout(self, m):\n        ""If a module contains \'dropout\' in it\'s name, it will be switched to .train() mode.""\n        if \'dropout\' in m.__class__.__name__.lower(): m.train()\n\n    def predict_with_mc_dropout(self, item:ItemBase, with_dropout:bool=True, n_times=10, **kwargs):\n        ""Make predictions with dropout turned on for n_times (default 10).""\n        return [self.predict(item, with_dropout=with_dropout) for _ in range(n_times)]\n\nclass RecordOnCPU(Callback):\n    ""Store the `input` and `target` going through the model on the CPU.""\n    def on_batch_begin(self, last_input,last_target,**kwargs):\n        self.input,self.target = to_cpu(last_input),to_cpu(last_target)\n\nclass LearnerCallback(Callback):\n    ""Base class for creating callbacks for a `Learner`.""\n    def __init__(self, learn):\n        self._learn = weakref.ref(learn)\n        self.exclude,self.not_min = [\'_learn\'],[]\n        setattr(self.learn, self.cb_name, self)\n\n    def __getattr__(self,k): return getattr(self.learn, k)\n    def __setstate__(self,data:Any): self.__dict__.update(data)\n\n    @property\n    def learn(self) -> Learner: return self._learn()\n    @learn.setter\n    def learn(self, learn: Learner) -> None: self._learn = weakref.ref(learn)\n\n    @property\n    def cb_name(self): return camel2snake(self.__class__.__name__)\n\nclass Recorder(LearnerCallback):\n    ""A `LearnerCallback` that records epoch, loss, opt and metric data during training.""\n    _order=-10\n    def __init__(self, learn:Learner, add_time:bool=True, silent:bool=False):\n        super().__init__(learn)\n        if not getattr(self.learn, \'opt\', False): self.learn.create_opt(defaults.lr, self.learn.wd)\n        self.opt = self.learn.opt\n        self.train_dl = self.learn.data.train_dl\n        self.no_val,self.silent,self.add_time = False,silent,add_time\n\n    def on_train_begin(self, pbar:PBar, metrics_names:Collection[str], **kwargs:Any)->None:\n        ""Initialize recording status at beginning of training.""\n        self.pbar = pbar\n        self.names = [\'epoch\', \'train_loss\'] if self.no_val else [\'epoch\', \'train_loss\', \'valid_loss\']\n        self.metrics_names = metrics_names\n        if hasattr(self, \'_added_met_names\'): self.metrics_names += self._added_met_names\n        self.names += self.metrics_names\n        if self.add_time: self.names.append(\'time\')\n        if not self.silent: self.pbar.write(self.names, table=True)\n        self.losses,self.val_losses,self.lrs,self.moms,self.metrics,self.nb_batches = [],[],[],[],[],[]\n\n    def on_epoch_begin(self, **kwargs:Any)->None:\n        if self.add_time: self.start_epoch = time()\n\n    def on_batch_begin(self, train, **kwargs:Any)->None:\n        ""Record learning rate and momentum at beginning of batch.""\n        if train:\n            self.lrs.append(self.opt.lr)\n            self.moms.append(self.opt.mom)\n\n    def on_backward_begin(self, smooth_loss:Tensor, **kwargs:Any)->None:\n        ""Record the loss before any other callback has a chance to modify it.""\n        self.losses.append(smooth_loss)\n        if self.pbar is not None and hasattr(self.pbar,\'child\'):\n            self.pbar.child.comment = f\'{smooth_loss:.4f}\'\n\n    def on_epoch_end(self, epoch:int, num_batch:int, smooth_loss:Tensor,\n                     last_metrics:MetricsList, **kwargs:Any)->bool:\n        ""Save epoch info: num_batch, smooth_loss, metrics.""\n        self.nb_batches.append(num_batch)\n        if last_metrics is not None: self.val_losses.append(last_metrics[0])\n        else: last_metrics = [] if self.no_val else [None]\n        if len(last_metrics) > 1: self.metrics.append(last_metrics[1:])\n        self.format_stats([epoch, smooth_loss] + last_metrics)\n\n    def format_stats(self, stats:TensorOrNumList)->None:\n        ""Format stats before printing.""\n        str_stats = []\n        for name,stat in zip(self.names,stats):\n            str_stats.append(\'#na#\' if stat is None else str(stat) if isinstance(stat, int) else f\'{stat:.6f}\')\n        if self.add_time: str_stats.append(format_time(time() - self.start_epoch))\n        if not self.silent: self.pbar.write(str_stats, table=True)\n\n    def add_metric_names(self, names):\n        ""Add `names` to the inner metric names.""\n        if hasattr(self, \'_added_met_names\'): self._added_met_names += names\n        else:                                 self._added_met_names  = names\n\n    def plot_lr(self, show_moms=False, skip_start:int=0, skip_end:int=0, return_fig:bool=None)->Optional[plt.Figure]:\n        ""Plot learning rate, `show_moms` to include momentum.""\n        lrs = self._split_list(self.lrs, skip_start, skip_end)\n        iterations = self._split_list(range_of(self.lrs), skip_start, skip_end)\n        if show_moms:\n            moms = self._split_list(self.moms, skip_start, skip_end)\n            fig, axs = plt.subplots(1,2, figsize=(12,4))\n            axs[0].plot(iterations, lrs)\n            axs[0].set_xlabel(\'Iterations\')\n            axs[0].set_ylabel(\'Learning Rate\')\n            axs[1].plot(iterations, moms)\n            axs[1].set_xlabel(\'Iterations\')\n            axs[1].set_ylabel(\'Momentum\')\n        else:\n            fig, ax = plt.subplots()\n            ax.plot(iterations, lrs)\n            ax.set_xlabel(\'Iterations\')\n            ax.set_ylabel(\'Learning Rate\')\n        if ifnone(return_fig, defaults.return_fig): return fig\n        if not IN_NOTEBOOK: plot_sixel(fig)\n\n    @staticmethod\n    def smoothen_by_spline(xs, ys, **kwargs):\n        xs = np.arange(len(ys))\n        spl = scipy.interpolate.UnivariateSpline(xs, ys, **kwargs)\n        ys = spl(xs)\n        return ys\n\n    def plot(self, skip_start:int=10, skip_end:int=5, suggestion:bool=False, return_fig:bool=None, show_grid:bool=False,\n             **kwargs)->Optional[plt.Figure]:\n        ""Plot learning rate and losses, trimmed between `skip_start` and `skip_end`. Optionally plot and return min gradient""\n        lrs = self._split_list(self.lrs, skip_start, skip_end)\n        losses = self._split_list(self.losses, skip_start, skip_end)\n        losses = [x.item() for x in losses]\n        if \'k\' in kwargs: losses = self.smoothen_by_spline(lrs, losses, **kwargs)\n        fig, ax = plt.subplots(1,1)\n        ax.plot(lrs, losses)\n        ax.set_ylabel(""Loss"")\n        ax.set_xlabel(""Learning Rate"")\n        ax.set_xscale(\'log\')\n        if show_grid: plt.grid(True,which=""both"",ls=""-"")\n        ax.xaxis.set_major_formatter(plt.FormatStrFormatter(\'%.0e\'))\n        if suggestion:\n            try: mg = (np.gradient(np.array(losses))).argmin()\n            except:\n                print(""Failed to compute the gradients, there might not be enough points."")\n                return\n            print(f""Min numerical gradient: {lrs[mg]:.2E}"")\n            ax.plot(lrs[mg],losses[mg],markersize=10,marker=\'o\',color=\'red\')\n            self.min_grad_lr = lrs[mg]\n            ml = np.argmin(losses)\n            print(f""Min loss divided by 10: {lrs[ml]/10:.2E}"")\n        if ifnone(return_fig, defaults.return_fig): return fig\n        if not IN_NOTEBOOK: plot_sixel(fig)\n\n    def plot_losses(self, skip_start:int=0, skip_end:int=0, return_fig:bool=None, show_grid:bool=False)->Optional[plt.Figure]:\n        ""Plot training and validation losses.""\n        fig, ax = plt.subplots(1,1)\n        losses = self._split_list(self.losses, skip_start, skip_end)\n        iterations = self._split_list(range_of(self.losses), skip_start, skip_end)\n        ax.plot(iterations, losses, label=\'Train\')\n        val_iter = self._split_list_val(np.cumsum(self.nb_batches), skip_start, skip_end)\n        val_losses = self._split_list_val(self.val_losses, skip_start, skip_end)\n        ax.plot(val_iter, val_losses, label=\'Validation\')\n        plt.grid(show_grid)\n        ax.set_ylabel(\'Loss\')\n        ax.set_xlabel(\'Batches processed\')\n        ax.legend()\n        if ifnone(return_fig, defaults.return_fig): return fig\n        if not IN_NOTEBOOK: plot_sixel(fig)\n\n    def plot_metrics(self, skip_start:int=0, skip_end:int=0, return_fig:bool=None, show_grid:bool=False)->Optional[plt.Figure]:\n        ""Plot metrics collected during training.""\n        assert len(self.metrics) != 0, ""There are no metrics to plot.""\n        fig, axes = plt.subplots(len(self.metrics[0]),1,figsize=(6, 4*len(self.metrics[0])))\n        val_iter = self._split_list_val(np.cumsum(self.nb_batches), skip_start, skip_end)\n        axes = axes.flatten() if len(self.metrics[0]) != 1 else [axes]\n        for i, ax in enumerate(axes):\n            values = [met[i] for met in self.metrics]\n            values = self._split_list_val(values, skip_start, skip_end)\n            ax.plot(val_iter, values)\n            plt.grid(show_grid)\n            ax.set_ylabel(str(self.metrics_names[i]))\n            ax.set_xlabel(\'Batches processed\')\n        if ifnone(return_fig, defaults.return_fig): return fig\n        if not IN_NOTEBOOK: plot_sixel(fig)\n\n    def _split_list(self, vals:Collection[float], skip_start:int, skip_end:int):\n        return vals[skip_start:-skip_end] if skip_end > 0 else vals[skip_start:]\n\n    def _split_list_val(self, vals:Collection[float], skip_start:int, skip_end:int):\n        val_iter = np.cumsum(self.nb_batches)\n        start_val = (val_iter - skip_start >= 0).nonzero()[0].min()\n        end_val = (val_iter[-1] - val_iter - skip_end >= 0).nonzero()[0].max()+1\n        return vals[start_val:end_val] if skip_end > 0 else vals[start_val:]\n\nclass FakeOptimizer():\n    def step(self): pass\n    def zero_grad(self): pass\n\ndef load_callback(class_func, state, learn:Learner):\n    init_kwargs, others = split_kwargs_by_func(state, class_func.__init__)\n    res = class_func(learn, **init_kwargs) if issubclass(class_func, LearnerCallback) else class_func(**init_kwargs)\n    for k,v in others.items(): setattr(res, k, v)\n    return res\n\ndef load_learner(path:PathOrStr, file:PathLikeOrBinaryStream=\'export.pkl\', test:ItemList=None, tfm_y=None, **db_kwargs):\n    ""Load a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)""\n    source = Path(path)/file if is_pathlike(file) else file\n    state = torch.load(source, map_location=\'cpu\') if defaults.device == torch.device(\'cpu\') else torch.load(source)\n    model = state.pop(\'model\')\n    src = LabelLists.load_state(path, state.pop(\'data\'))\n    if test is not None: src.add_test(test, tfm_y=tfm_y)\n    data = src.databunch(**db_kwargs)\n    cb_state = state.pop(\'cb_state\')\n    clas_func = state.pop(\'cls\')\n    res = clas_func(data, model, **state)\n    res.callback_fns = state[\'callback_fns\'] #to avoid duplicates\n    res.callbacks = [load_callback(c,s, res) for c,s in cb_state.items()]\n    return res\n'"
fastai/basics.py,0,"b'from .basic_train import *\nfrom .callback import *\nfrom .core import *\nfrom .basic_data import *\nfrom .data_block import *\nfrom .layers import *\nfrom .metrics import *\nfrom .torch_core import *\nfrom .train import *\nfrom .datasets import *\nfrom .version import *\nfrom . import callbacks\n\n""""""\nfrom . import core,torch_core,basic_data,basic_train,callback,data_block,layers,metrics,train,datasets,callbacks\n\n__all__  = [o for o in dir(core) if not o.startswith(\'_\')]\n__all__ += [o for o in dir(torch_core) if not o.startswith(\'_\')]\n__all__ += [*basic_train.__all__, *callback.__all__, \'core\', \'torch_core\', \'callbacks\',\n           *basic_data.__all__, *data_block.__all__, *layers.__all__, *metrics.__all__,\n           *train.__all__, *datasets.__all__, \'__version__\']\n""""""\n\ntry: from .gen_doc.nbdoc import doc\nexcept: pass  # Optional if jupyter is present\n    #__all__.append(\'doc\')\n\n__all__ = [o for o in dir(sys.modules[__name__]) if not o.startswith(\'_\')] + [\'__version__\']\n\n'"
fastai/callback.py,1,"b'""Callbacks provides extensibility to the `basic_train` loop. See `train` for examples of custom callbacks.""\nfrom .basic_data import *\nfrom .torch_core import *\nimport torch.distributed as dist\n\n__all__ = [\'AverageMetric\', \'Callback\', \'CallbackHandler\', \'OptimWrapper\', \'SmoothenValue\', \'Scheduler\', \'annealing_cos\', \'CallbackList\',\n           \'annealing_exp\', \'annealing_linear\', \'annealing_no\', \'annealing_poly\']\n\nclass OptimWrapper():\n    ""Basic wrapper around `opt` to simplify hyper-parameters changes.""\n    def __init__(self, opt:optim.Optimizer, wd:Floats=0., true_wd:bool=False, bn_wd:bool=True):\n        assert not isinstance(opt, OptimWrapper)\n        self.opt,self.true_wd,self.bn_wd = opt,true_wd,bn_wd\n        self.opt_keys = list(self.opt.param_groups[0].keys())\n        self.opt_keys.remove(\'params\')\n        self.read_defaults()\n        self.wd = wd\n\n    @classmethod\n    def create(cls, opt_func:Union[type,Callable], lr:Union[float,Tuple,List], layer_groups:ModuleList, wd:Floats=0., \n               true_wd:bool=False, bn_wd:bool=True)->optim.Optimizer:\n        ""Create an `optim.Optimizer` from `opt_func` with `lr`. Set lr on `layer_groups`.""\n        split_params = split_no_wd_params(layer_groups)\n        opt = opt_func([{\'params\': p, \'lr\':0} for p in split_params])\n        opt = cls(opt, wd=wd, true_wd=true_wd, bn_wd=bn_wd)\n        opt.lr,opt.opt_func = listify(lr, layer_groups),opt_func\n        return opt\n\n    def new(self, layer_groups:Collection[nn.Module], split_no_wd:bool=True):\n        ""Create a new `OptimWrapper` from `self` with another `layer_groups` but the same hyper-parameters.""\n        opt_func = getattr(self, \'opt_func\', self.opt.__class__)\n        res = self.create(opt_func, self.lr, layer_groups, wd=self.wd, true_wd=self.true_wd, bn_wd=self.bn_wd)\n        res.mom,res.beta = self.mom,self.beta\n        return res\n\n    def new_with_params(self, param_groups:Collection[Collection[nn.Parameter]]):\n        ""Create a new `OptimWrapper` from `self` with another `layer_groups` but the same hyper-parameters.""\n        opt_func = getattr(self, \'opt_func\', self.opt.__class__)\n        opt = opt_func([{\'params\': p, \'lr\':0} for p in param_groups])\n        opt = self.__class__(opt, wd=self.wd, true_wd=self.true_wd, bn_wd=self.bn_wd)\n        opt.lr,opt.opt_func,opt.mom,opt.beta = self.lr,opt_func,self.mom,self.beta\n        return opt\n\n    def __repr__(self)->str:\n        return f\'OptimWrapper over {repr(self.opt)}.\\nTrue weight decay: {self.true_wd}\'\n\n    #Pytorch optimizer methods\n    def step(self)->None:\n        ""Set weight decay and step optimizer.""\n        # weight decay outside of optimizer step (AdamW)\n        if self.true_wd:\n            for lr,wd,pg1,pg2 in zip(self._lr,self._wd,self.opt.param_groups[::2],self.opt.param_groups[1::2]):\n                for p in pg1[\'params\']: \n                    if p.grad is not None: p.data.mul_(1 - wd*lr)\n                if self.bn_wd:\n                    for p in pg2[\'params\']: \n                        if p.grad is not None: p.data.mul_(1 - wd*lr)\n            self.set_val(\'weight_decay\', listify(0, self._wd))\n        self.opt.step()\n\n    def zero_grad(self)->None:\n        ""Clear optimizer gradients.""\n        self.opt.zero_grad()\n\n    #Passthrough to the inner opt.\n    def __getattr__(self, k:str)->Any: return getattr(self.opt, k, None)\n    def __setstate__(self,data:Any): self.__dict__.update(data)\n\n    def clear(self):\n        ""Reset the state of the inner optimizer.""\n        sd = self.state_dict()\n        sd[\'state\'] = {}\n        self.load_state_dict(sd)\n\n    @property\n    def n_params(self): return sum([len(pg[\'params\']) for pg in self.opt.param_groups])\n\n    #Hyperparameters as properties\n    @property\n    def lr(self)->float: return self._lr[-1]\n    @lr.setter\n    def lr(self, val:float)->None:\n        self._lr = self.set_val(\'lr\', listify(val, self._lr))\n\n    @property\n    def mom(self)->float:return self._mom[-1] if self._mom is not None else None\n    @mom.setter\n    def mom(self, val:float)->None:\n        if \'momentum\' in self.opt_keys: self.set_val(\'momentum\', listify(val, self._mom))\n        elif \'betas\' in self.opt_keys:  self.set_val(\'betas\', (listify(val, self._mom), self._beta))\n        self._mom = listify(val, self._mom)\n\n    @property\n    def beta(self)->float: return None if self._beta is None else self._beta[-1]\n    @beta.setter\n    def beta(self, val:float)->None:\n        ""Set beta (or alpha as makes sense for given optimizer).""\n        if val is None: return\n        if \'betas\' in self.opt_keys:    self.set_val(\'betas\', (self._mom, listify(val, self._beta)))\n        elif \'alpha\' in self.opt_keys:  self.set_val(\'alpha\', listify(val, self._beta))\n        self._beta = listify(val, self._beta)\n\n    @property\n    def wd(self)->float: return self._wd[-1]\n    @wd.setter\n    def wd(self, val:float)->None:\n        ""Set weight decay.""\n        if not self.true_wd: self.set_val(\'weight_decay\', listify(val, self._wd), bn_groups=self.bn_wd)\n        self._wd = listify(val, self._wd)\n\n    #Helper functions\n    def read_defaults(self)->None:\n        ""Read the values inside the optimizer for the hyper-parameters.""\n        self._beta = None\n        if \'lr\' in self.opt_keys: self._lr = self.read_val(\'lr\')\n        if \'momentum\' in self.opt_keys: self._mom = self.read_val(\'momentum\')\n        if \'alpha\' in self.opt_keys: self._beta = self.read_val(\'alpha\')\n        if \'betas\' in self.opt_keys: self._mom,self._beta = self.read_val(\'betas\')\n        if \'weight_decay\' in self.opt_keys: self._wd = self.read_val(\'weight_decay\')\n        reserved_names = [\'params\', \'lr\', \'momentum\', \'alpha\', \'betas\', \'weight_decay\']\n        stat_names = [n for n in self.opt_keys if n not in reserved_names]\n        self._stats = {n:self.read_val(n) for n in stat_names}\n\n    def get_stat(self, name:str)->float: \n        if name in [\'lr\', \'mom\', \'beta\', \'wd\']: return getattr(self, name)\n        else: return self._stats[name][-1]\n    def set_stat(self, name:str, value:Union[float, Collection[float]])->None:\n        if name in [\'lr\', \'mom\', \'beta\', \'wd\']: setattr(self, name, value)\n        else:\n            val = listify(value, self._stats[name])\n            self.set_val(name, val)\n            self._stats[name] = val\n\n    def set_val(self, key:str, val:Any, bn_groups:bool=True)->Any:\n        ""Set `val` inside the optimizer dictionary at `key`.""\n        if is_tuple(val): val = [(v1,v2) for v1,v2 in zip(*val)]\n        for v,pg1,pg2 in zip(val,self.opt.param_groups[::2],self.opt.param_groups[1::2]):\n            pg1[key] = v\n            if bn_groups: pg2[key] = v\n        return val\n\n    def read_val(self, key:str) -> Union[List[float],Tuple[List[float],List[float]]]:\n        ""Read a hyperparameter `key` in the optimizer dictionary.""\n        val = [pg[key] for pg in self.opt.param_groups[::2]]\n        if is_tuple(val[0]): val = [o[0] for o in val], [o[1] for o in val]\n        return val\n    \n    def get_state(self):\n        ""Return the inner state minus the layer groups.""\n        return {\'opt_state\':self.opt.state_dict(), \'lr\':self._lr, \'wd\':self._wd, \'beta\':self._beta, \'mom\':self._mom,\n                \'opt_func\':self.opt_func, \'true_wd\':self.true_wd, \'bn_wd\':self.bn_wd}\n\n    @classmethod\n    def load_with_state_and_layer_group(cls, state:dict, layer_groups:Collection[nn.Module]):\n        res = cls.create(state[\'opt_func\'], state[\'lr\'], layer_groups, wd=state[\'wd\'], true_wd=state[\'true_wd\'], \n                     bn_wd=state[\'bn_wd\'])\n        res._mom,res._beta = state[\'mom\'],state[\'beta\']\n        res.load_state_dict(state[\'opt_state\'])\n        return res\n\nclass Callback():\n    ""Base class for callbacks that want to record values, dynamically change learner params, etc.""\n    _order=0\n    def on_train_begin(self, **kwargs:Any)->None:\n        ""To initialize constants in the callback.""\n        pass\n    def on_epoch_begin(self, **kwargs:Any)->None:\n        ""At the beginning of each epoch.""\n        pass\n    def on_batch_begin(self, **kwargs:Any)->None:\n        ""Set HP before the output and loss are computed.""\n        pass\n    def on_loss_begin(self, **kwargs:Any)->None:\n        ""Called after forward pass but before loss has been computed.""\n        pass\n    def on_backward_begin(self, **kwargs:Any)->None:\n        ""Called after the forward pass and the loss has been computed, but before backprop.""\n        pass\n    def on_backward_end(self, **kwargs:Any)->None:\n        ""Called after backprop but before optimizer step. Useful for true weight decay in AdamW.""\n        pass\n    def on_step_end(self, **kwargs:Any)->None:\n        ""Called after the step of the optimizer but before the gradients are zeroed.""\n        pass\n    def on_batch_end(self, **kwargs:Any)->None:\n        ""Called at the end of the batch.""\n        pass\n    def on_epoch_end(self, **kwargs:Any)->None:\n        ""Called at the end of an epoch.""\n        pass\n    def on_train_end(self, **kwargs:Any)->None:\n        ""Useful for cleaning up things and saving files/models.""\n        pass\n    def jump_to_epoch(self, epoch)->None:\n        ""To resume training at `epoch` directly.""\n        pass\n\n    def get_state(self, minimal:bool=True):\n        ""Return the inner state of the `Callback`, `minimal` or not.""\n        to_remove = [\'exclude\', \'not_min\'] + getattr(self, \'exclude\', []).copy()\n        if minimal: to_remove += getattr(self, \'not_min\', []).copy()\n        return {k:v for k,v in self.__dict__.items() if k not in to_remove}\n\n    def  __repr__(self):\n        attrs = func_args(self.__init__)\n        to_remove = getattr(self, \'exclude\', [])\n        list_repr = [self.__class__.__name__] + [f\'{k}: {getattr(self, k)}\' for k in attrs if k != \'self\' and k not in to_remove]\n        return \'\\n\'.join(list_repr)\n\nclass SmoothenValue():\n    ""Create a smooth moving average for a value (loss, etc) using `beta`.""\n    def __init__(self, beta:float):\n        self.beta,self.n,self.mov_avg = beta,0,0\n\n    def add_value(self, val:float)->None:\n        ""Add `val` to calculate updated smoothed value.""\n        self.n += 1\n        self.mov_avg = self.beta * self.mov_avg + (1 - self.beta) * val\n        self.smooth = self.mov_avg / (1 - self.beta ** self.n)\n\nCallbackList = Collection[Callback]\n\ndef _get_init_state(): return {\'epoch\':0, \'iteration\':0, \'num_batch\':0, \'skip_validate\': False}\n\n@dataclass\nclass CallbackHandler():\n    ""Manage all of the registered `callbacks` and `metrics`, smoothing loss by momentum `beta`.""\n    callbacks:CallbackList=None\n    metrics:CallbackList=None\n    beta:float=0.98\n\n    def __post_init__(self)->None:\n        ""Initialize smoother and learning stats.""\n        self.callbacks = ifnone(self.callbacks, [])\n        self.metrics = ifnone(self.metrics, [])\n        self.metrics = [(met if isinstance(met, Callback) else AverageMetric(met)) for met in self.metrics]\n        self.callbacks = sorted(self.callbacks, key=lambda o: getattr(o, \'_order\', 0))\n        self.smoothener = SmoothenValue(self.beta)\n        self.state_dict:Dict[str,Union[int,float,Tensor]]=_get_init_state()\n\n    def _call_and_update(self, cb, cb_name, **kwargs)->None:\n        ""Call `cb_name` on `cb` and update the inner state.""\n        new = ifnone(getattr(cb, f\'on_{cb_name}\')(**self.state_dict, **kwargs), dict())\n        for k,v in new.items():\n            if k not in self.state_dict:\n                raise Exception(f""{k} isn\'t a valid key in the state of the callbacks."")\n            else: self.state_dict[k] = v\n    \n    def __call__(self, cb_name, call_mets=True, **kwargs)->None:\n        ""Call through to all of the `CallbakHandler` functions.""\n        if call_mets: \n            for met in self.metrics: self._call_and_update(met, cb_name, **kwargs)\n        for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n\n    def set_dl(self, dl:DataLoader):\n        ""Set the current `dl` used.""\n        if hasattr(self, \'cb_dl\'): self.callbacks.remove(self.cb_dl)\n        if isinstance(dl.dataset, Callback):\n            self.callbacks.append(dl.dataset)\n            self.cb_dl = dl.dataset\n\n    def on_train_begin(self, epochs:int, pbar:PBar, metrics:MetricFuncList)->None:\n        ""About to start learning.""\n        self.state_dict = _get_init_state()\n        self.state_dict.update(dict(n_epochs=epochs, pbar=pbar, metrics=metrics))\n        names = [(met.name if hasattr(met, \'name\') else camel2snake(met.__class__.__name__)) for met in self.metrics]\n        self(\'train_begin\', metrics_names=names)\n        if self.state_dict[\'epoch\'] != 0:\n            self.state_dict[\'pbar\'].main_bar.total -= self.state_dict[\'epoch\']\n            for cb in self.callbacks: cb.jump_to_epoch(self.state_dict[\'epoch\'])\n\n    def on_epoch_begin(self)->None:\n        ""Handle new epoch.""\n        self.state_dict[\'num_batch\'],self.state_dict[\'stop_training\'] = 0,False\n        self(\'epoch_begin\')\n\n    def on_batch_begin(self, xb:Tensor, yb:Tensor, train:bool=True)->Tuple[Any,Any]:\n        ""Handle new batch `xb`,`yb` in `train` or validation.""\n        self.state_dict.update(dict(last_input=xb, last_target=yb, train=train, \n            stop_epoch=False, skip_step=False, skip_zero=False, skip_bwd=False))\n        self(\'batch_begin\', call_mets = not self.state_dict[\'train\'])\n        return self.state_dict[\'last_input\'], self.state_dict[\'last_target\']\n\n    def on_loss_begin(self, out:Tensor)->Any:\n        ""Handle start of loss calculation with model output `out`.""\n        self.state_dict[\'last_output\'] = out\n        self(\'loss_begin\', call_mets=False)\n        return self.state_dict[\'last_output\']\n\n    def on_backward_begin(self, loss:Tensor)->Tuple[Any,Any]:\n        ""Handle gradient calculation on `loss`.""\n        self.smoothener.add_value(loss.float().detach().cpu())\n        self.state_dict[\'last_loss\'], self.state_dict[\'smooth_loss\'] = loss, self.smoothener.smooth\n        self(\'backward_begin\', call_mets=False)\n        return self.state_dict[\'last_loss\'], self.state_dict[\'skip_bwd\']\n\n    def on_backward_end(self)->Any:\n        ""Handle end of gradient calculation.""\n        self(\'backward_end\', call_mets=False)\n        return self.state_dict[\'skip_step\']\n\n    def on_step_end(self)->Any:\n        ""Handle end of optimization step.""\n        self(\'step_end\', call_mets=False)\n        return self.state_dict[\'skip_zero\']\n\n    def on_batch_end(self, loss:Tensor)->Any:\n        ""Handle end of processing one batch with `loss`.""\n        self.state_dict[\'last_loss\'] = loss\n        self(\'batch_end\', call_mets = not self.state_dict[\'train\'])\n        if self.state_dict[\'train\']:\n            self.state_dict[\'iteration\'] += 1\n            self.state_dict[\'num_batch\'] += 1\n        return self.state_dict[\'stop_epoch\']\n\n    def on_epoch_end(self, val_loss:Tensor)->bool:\n        ""Epoch is done, process `val_loss`.""\n        self.state_dict[\'last_metrics\'] = [val_loss] if val_loss is not None else [None]\n        self(\'epoch_end\', call_mets = val_loss is not None)\n        self.state_dict[\'epoch\'] += 1\n        return self.state_dict[\'stop_training\']\n\n    def on_train_end(self, exception:Union[bool,Exception])->None:\n        ""Handle end of training, `exception` is an `Exception` or False if no exceptions during training.""\n        self(\'train_end\', exception=exception)\n        \n    @property\n    def skip_validate(self): return self.state_dict[\'skip_validate\']\n\nclass AverageMetric(Callback):\n    ""Wrap a `func` in a callback for metrics computation.""\n    def __init__(self, func):\n        # If func has a __name__ use this one else it should be a partial\n        name = func.__name__ if hasattr(func, \'__name__\') else func.func.__name__\n        self.func, self.name = func, name\n        self.world = num_distrib()\n\n    def on_epoch_begin(self, **kwargs):\n        ""Set the inner value to 0.""\n        self.val, self.count = 0.,0\n\n    def on_batch_end(self, last_output, last_target, **kwargs):\n        ""Update metric computation with `last_output` and `last_target`.""\n        if not is_listy(last_target): last_target=[last_target]\n        self.count += first_el(last_target).size(0)\n        val = self.func(last_output, *last_target)\n        if self.world:\n            val = val.clone()\n            dist.all_reduce(val, op=dist.ReduceOp.SUM)\n            val /= self.world\n        self.val += first_el(last_target).size(0) * val.detach().cpu()\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        ""Set the final result in `last_metrics`.""\n        return add_metrics(last_metrics, self.val/self.count)\n\ndef annealing_no(start:Number, end:Number, pct:float)->Number:\n    ""No annealing, always return `start`.""\n    return start\ndef annealing_linear(start:Number, end:Number, pct:float)->Number:\n    ""Linearly anneal from `start` to `end` as pct goes from 0.0 to 1.0.""\n    return start + pct * (end-start)\ndef annealing_exp(start:Number, end:Number, pct:float)->Number:\n    ""Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.""\n    return start * (end/start) ** pct\ndef annealing_cos(start:Number, end:Number, pct:float)->Number:\n    ""Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.""\n    cos_out = np.cos(np.pi * pct) + 1\n    return end + (start-end)/2 * cos_out\n\ndef do_annealing_poly(start:Number, end:Number, pct:float, degree:Number)->Number:\n    ""Helper function for `anneal_poly`.""\n    return end + (start-end) * (1-pct)**degree\ndef annealing_poly(degree:Number)->Number:\n    ""Anneal polynomically from `start` to `end` as pct goes from 0.0 to 1.0.""\n    return functools.partial(do_annealing_poly, degree=degree)\n\nclass Scheduler():\n    ""Used to \\""step\\"" from start,end (`vals`) over `n_iter` iterations on a schedule defined by `func`""\n    def __init__(self, vals:StartOptEnd, n_iter:int, func:Optional[AnnealFunc]=None):\n        self.start,self.end = (vals[0],vals[1]) if is_tuple(vals) else (vals,0)\n        self.n_iter = max(1,n_iter)\n        if func is None: self.func = annealing_linear if is_tuple(vals) else annealing_no\n        else:          self.func = func\n        self.n = 0\n        \n    def restart(self): self.n = 0\n\n    def step(self)->Number:\n        ""Return next value along annealed schedule.""\n        self.n += 1\n        return self.func(self.start, self.end, self.n/self.n_iter)\n\n    @property\n    def is_done(self)->bool:\n        ""Return `True` if schedule completed.""\n        return self.n >= self.n_iter\n\n'"
fastai/collab.py,3,"b'""Module support for Collaborative Filtering""\nfrom .tabular import *\nfrom . import tabular\n\n__all__ = [*tabular.__all__, \'EmbeddingDotBias\', \'EmbeddingNN\', \'collab_learner\', \'CollabDataBunch\', \'CollabLine\',\n           \'CollabList\', \'CollabLearner\']\n\nclass CollabProcessor(TabularProcessor):\n    ""Subclass `TabularProcessor for `process_one`.""\n    def process_one(self, item):\n        res = super().process_one(item)\n        return CollabLine(res.cats,res.conts,res.classes,res.names)\n\nclass CollabLine(TabularLine):\n    ""Base item for collaborative filtering, subclasses `TabularLine`.""\n    def __init__(self, cats, conts, classes, names):\n        super().__init__(cats, conts, classes, names)\n        self.data = [self.data[0][0],self.data[0][1]]\n\nclass CollabList(TabularList):\n    ""Base `ItemList` for collaborative filtering, subclasses `TabularList`.""\n    _item_cls,_label_cls,_processor = CollabLine,FloatList,CollabProcessor\n\n    def reconstruct(self, t:Tensor): return CollabLine(tensor(t), tensor([]), self.classes, self.col_names)\n\nclass EmbeddingNN(TabularModel):\n    ""Subclass `TabularModel` to create a NN suitable for collaborative filtering.""\n    def __init__(self, emb_szs:ListSizes, layers:Collection[int]=None, ps:Collection[float]=None,\n                 emb_drop:float=0., y_range:OptRange=None, use_bn:bool=True, bn_final:bool=False):\n        super().__init__(emb_szs=emb_szs, n_cont=0, out_sz=1, layers=layers, ps=ps, emb_drop=emb_drop, y_range=y_range,\n                         use_bn=use_bn, bn_final=bn_final)\n\n    def forward(self, users:LongTensor, items:LongTensor) -> Tensor:\n        return super().forward(torch.stack([users,items], dim=1), None)\n\nclass EmbeddingDotBias(Module):\n    ""Base dot model for collaborative filtering.""\n    def __init__(self, n_factors:int, n_users:int, n_items:int, y_range:Tuple[float,float]=None):\n        self.y_range = y_range\n        (self.u_weight, self.i_weight, self.u_bias, self.i_bias) = [embedding(*o) for o in [\n            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n        ]]\n\n    def forward(self, users:LongTensor, items:LongTensor) -> Tensor:\n        dot = self.u_weight(users)* self.i_weight(items)\n        res = dot.sum(1) + self.u_bias(users).squeeze() + self.i_bias(items).squeeze()\n        if self.y_range is None: return res\n        return torch.sigmoid(res) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]\n\nclass CollabDataBunch(DataBunch):\n    ""Base `DataBunch` for collaborative filtering.""\n    @classmethod\n    def from_df(cls, ratings:DataFrame, valid_pct:float=0.2, user_name:Optional[str]=None, item_name:Optional[str]=None,\n                rating_name:Optional[str]=None, test:DataFrame=None, seed:int=None, path:PathOrStr=\'.\', bs:int=64, \n                val_bs:int=None, num_workers:int=defaults.cpus, dl_tfms:Optional[Collection[Callable]]=None, \n                device:torch.device=None, collate_fn:Callable=data_collate, no_check:bool=False) -> \'CollabDataBunch\':\n        ""Create a `DataBunch` suitable for collaborative filtering from `ratings`.""\n        user_name   = ifnone(user_name,  ratings.columns[0])\n        item_name   = ifnone(item_name,  ratings.columns[1])\n        rating_name = ifnone(rating_name,ratings.columns[2])\n        cat_names = [user_name,item_name]\n        src = (CollabList.from_df(ratings, cat_names=cat_names, procs=Categorify)\n               .split_by_rand_pct(valid_pct=valid_pct, seed=seed).label_from_df(cols=rating_name))\n        if test is not None: src.add_test(CollabList.from_df(test, cat_names=cat_names))\n        return src.databunch(path=path, bs=bs, val_bs=val_bs, num_workers=num_workers, device=device, \n                             collate_fn=collate_fn, no_check=no_check)\n\nclass CollabLearner(Learner):\n    ""`Learner` suitable for collaborative filtering.""\n    def get_idx(self, arr:Collection, is_item:bool=True):\n        ""Fetch item or user (based on `is_item`) for all in `arr`. (Set model to `cpu` and no grad.)""\n        m = self.model.eval().cpu()\n        requires_grad(m,False)\n        u_class,i_class = self.data.train_ds.x.classes.values()\n        classes = i_class if is_item else u_class\n        c2i = {v:k for k,v in enumerate(classes)}\n        try: return tensor([c2i[o] for o in arr])\n        except Exception as e: \n            print(f""""""You\'re trying to access {\'an item\' if is_item else \'a user\'} that isn\'t in the training data.\n                  If it was in your original data, it may have been split such that it\'s only in the validation set now."""""")\n\n    def bias(self, arr:Collection, is_item:bool=True):\n        ""Bias for item or user (based on `is_item`) for all in `arr`. (Set model to `cpu` and no grad.)""\n        idx = self.get_idx(arr, is_item)\n        m = self.model\n        layer = m.i_bias if is_item else m.u_bias\n        return layer(idx).squeeze()\n\n    def weight(self, arr:Collection, is_item:bool=True):\n        ""Weight for item or user (based on `is_item`) for all in `arr`. (Set model to `cpu` and no grad.)""\n        idx = self.get_idx(arr, is_item)\n        m = self.model\n        layer = m.i_weight if is_item else m.u_weight\n        return layer(idx)\n\ndef collab_learner(data, n_factors:int=None, use_nn:bool=False, emb_szs:Dict[str,int]=None, layers:Collection[int]=None, \n                   ps:Collection[float]=None, emb_drop:float=0., y_range:OptRange=None, use_bn:bool=True, \n                   bn_final:bool=False, **learn_kwargs)->Learner:\n    ""Create a Learner for collaborative filtering on `data`.""\n    emb_szs = data.get_emb_szs(ifnone(emb_szs, {}))\n    u,m = data.train_ds.x.classes.values()\n    if use_nn: model = EmbeddingNN(emb_szs=emb_szs, layers=layers, ps=ps, emb_drop=emb_drop, y_range=y_range, \n                                   use_bn=use_bn, bn_final=bn_final, **learn_kwargs)\n    else:      model = EmbeddingDotBias(n_factors, len(u), len(m), y_range=y_range)\n    return CollabLearner(data, model, **learn_kwargs)\n\n'"
fastai/core.py,0,"b'""`fastai.core` contains essential util functions to format and split data""\nfrom .imports.core import *\n\nwarnings.filterwarnings(""ignore"", message=""numpy.dtype size changed"")\nwarnings.filterwarnings(""ignore"", message=""numpy.ufunc size changed"")\n\nAnnealFunc = Callable[[Number,Number,float], Number]\nArgStar = Collection[Any]\nBatchSamples = Collection[Tuple[Collection[int], int]]\nDataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str,Any]\nListOrItem = Union[Collection[Any],int,float,str]\nListRules = Collection[Callable[[str],str]]\nListSizes = Collection[Tuple[int,int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float,float]]\nOptStrTuple = Optional[Tuple[str,str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path,str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint=Tuple[float,float]\nPoints=Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray,np.ndarray]]\nStartOptEnd=Union[float,Tuple[float,float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\n\ndef num_cpus()->int:\n    ""Get number of cpus""\n    try:                   return len(os.sched_getaffinity(0))\n    except AttributeError: return os.cpu_count()\n\n_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(cpus=_default_cpus, cmap=\'viridis\', return_fig=False, silent=False)\n\ndef is_listy(x:Any)->bool: return isinstance(x, (tuple,list))\ndef is_tuple(x:Any)->bool: return isinstance(x, tuple)\ndef is_dict(x:Any)->bool: return isinstance(x, dict)\ndef is_pathlike(x:Any)->bool: return isinstance(x, (str,Path))\ndef noop(x): return x\n\nclass PrePostInitMeta(type):\n    ""A metaclass that calls optional `__pre_init__` and `__post_init__` methods""\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)\n        old_init = x.__init__\n        def _pass(self): pass\n        @functools.wraps(old_init)\n        def _init(self,*args,**kwargs):\n            self.__pre_init__()\n            old_init(self, *args,**kwargs)\n            self.__post_init__()\n        x.__init__ = _init\n        if not hasattr(x,\'__pre_init__\'):  x.__pre_init__  = _pass\n        if not hasattr(x,\'__post_init__\'): x.__post_init__ = _pass\n        return x\n\ndef chunks(l:Collection, n:int)->Iterable:\n    ""Yield successive `n`-sized chunks from `l`.""\n    for i in range(0, len(l), n): yield l[i:i+n]\n\ndef recurse(func:Callable, x:Any, *args, **kwargs)->Any:\n    if is_listy(x): return [recurse(func, o, *args, **kwargs) for o in x]\n    if is_dict(x):  return {k: recurse(func, v, *args, **kwargs) for k,v in x.items()}\n    return func(x, *args, **kwargs)\n\ndef first_el(x: Any)->Any:\n    ""Recursively get the first element of `x`.""\n    if is_listy(x): return first_el(x[0])\n    if is_dict(x):  return first_el(x[list(x.keys())[0]])\n    return x\n\ndef to_int(b:Any)->Union[int,List[int]]:\n    ""Recursively convert `b` to an int or list/dict of ints; raises exception if not convertible.""\n    return recurse(lambda x: int(x), b)\n\ndef ifnone(a:Any,b:Any)->Any:\n    ""`a` if `a` is not None, otherwise `b`.""\n    return b if a is None else a\n\ndef is1d(a:Collection)->bool:\n    ""Return `True` if `a` is one-dimensional""\n    return len(a.shape) == 1 if hasattr(a, \'shape\') else len(np.array(a).shape) == 1\n\ndef uniqueify(x:Series, sort:bool=False)->List:\n    ""Return sorted unique values of `x`.""\n    res = list(OrderedDict.fromkeys(x).keys())\n    if sort: res.sort()\n    return res\n\ndef idx_dict(a):\n    ""Create a dictionary value to index from `a`.""\n    return {v:k for k,v in enumerate(a)}\n\ndef find_classes(folder:Path)->FilePathList:\n    ""List of label subdirectories in imagenet-style `folder`.""\n    classes = [d for d in folder.iterdir()\n               if d.is_dir() and not d.name.startswith(\'.\')]\n    assert(len(classes)>0)\n    return sorted(classes, key=lambda d: d.name)\n\ndef arrays_split(mask:NPArrayMask, *arrs:NPArrayableList)->SplitArrayList:\n    ""Given `arrs` is [a,b,...] and `mask`index - return[(a[mask],a[~mask]),(b[mask],b[~mask]),...].""\n    assert all([len(arr)==len(arrs[0]) for arr in arrs]), \'All arrays should have same length\'\n    mask = array(mask)\n    return list(zip(*[(a[mask],a[~mask]) for a in map(np.array, arrs)]))\n\ndef random_split(valid_pct:float, *arrs:NPArrayableList)->SplitArrayList:\n    ""Randomly split `arrs` with `valid_pct` ratio. good for creating validation set.""\n    assert (valid_pct>=0 and valid_pct<=1), \'Validation set percentage should be between 0 and 1\'\n    is_train = np.random.uniform(size=(len(arrs[0]),)) > valid_pct\n    return arrays_split(is_train, *arrs)\n\ndef listify(p:OptListOrItem=None, q:OptListOrItem=None):\n    ""Make `p` listy and the same length as `q`.""\n    if p is None: p=[]\n    elif isinstance(p, str):          p = [p]\n    elif not isinstance(p, Iterable): p = [p]\n    #Rank 0 tensors in PyTorch are Iterable but don\'t have a length.\n    else:\n        try: a = len(p)\n        except: p = [p]\n    n = q if type(q)==int else len(p) if q is None else len(q)\n    if len(p)==1: p = p * n\n    assert len(p)==n, f\'List len mismatch ({len(p)} vs {n})\'\n    return list(p)\n\n_camel_re1 = re.compile(\'(.)([A-Z][a-z]+)\')\n_camel_re2 = re.compile(\'([a-z0-9])([A-Z])\')\ndef camel2snake(name:str)->str:\n    ""Change `name` from camel to snake style.""\n    s1 = re.sub(_camel_re1, r\'\\1_\\2\', name)\n    return re.sub(_camel_re2, r\'\\1_\\2\', s1).lower()\n\ndef even_mults(start:float, stop:float, n:int)->np.ndarray:\n    ""Build log-stepped array from `start` to `stop` in `n` steps.""\n    mult = stop/start\n    step = mult**(1/(n-1))\n    return np.array([start*(step**i) for i in range(n)])\n\ndef extract_kwargs(names:Collection[str], kwargs:KWArgs):\n    ""Extract the keys in `names` from the `kwargs`.""\n    new_kwargs = {}\n    for arg_name in names:\n        if arg_name in kwargs:\n            arg_val = kwargs.pop(arg_name)\n            new_kwargs[arg_name] = arg_val\n    return new_kwargs, kwargs\n\ndef partition(a:Collection, sz:int)->List[Collection]:\n    ""Split iterables `a` in equal parts of size `sz`""\n    return [a[i:i+sz] for i in range(0, len(a), sz)]\n\ndef partition_by_cores(a:Collection, n_cpus:int)->List[Collection]:\n    ""Split data in `a` equally among `n_cpus` cores""\n    return partition(a, len(a)//n_cpus + 1)\n\ndef series2cat(df:DataFrame, *col_names):\n    ""Categorifies the columns `col_names` in `df`.""\n    for c in listify(col_names): df[c] = df[c].astype(\'category\').cat.as_ordered()\n\nTfmList = Union[Callable, Collection[Callable]]\n\nclass ItemBase():\n    ""Base item type in the fastai library.""\n    def __init__(self, data:Any): self.data=self.obj=data\n    def __repr__(self)->str: return f\'{self.__class__.__name__} {str(self.data)}\'\n    def show(self, ax:plt.Axes, **kwargs):\n        ""Subclass this method if you want to customize the way this `ItemBase` is shown on `ax`.""\n        ax.set_title(str(self))\n    def apply_tfms(self, tfms:Collection, **kwargs):\n        ""Subclass this method if you want to apply data augmentation with `tfms` to this `ItemBase`.""\n        if tfms: raise Exception(f""Not implemented: you can\'t apply transforms to this type of item ({self.__class__.__name__})"")\n        return self\n    def __eq__(self, other): return recurse_eq(self.data, other.data)\n\ndef recurse_eq(arr1, arr2):\n    if is_listy(arr1): return is_listy(arr2) and len(arr1) == len(arr2) and np.all([recurse_eq(x,y) for x,y in zip(arr1,arr2)])\n    else:              return np.all(np.atleast_1d(arr1 == arr2))\n\ndef download_url(url:str, dest:str, overwrite:bool=False, pbar:ProgressBar=None,\n                 show_progress=True, chunk_size=1024*1024, timeout=4, retries=5)->None:\n    ""Download `url` to `dest` unless it exists and not `overwrite`.""\n    if os.path.exists(dest) and not overwrite: return\n\n    s = requests.Session()\n    s.mount(\'http://\',requests.adapters.HTTPAdapter(max_retries=retries))\n    # additional line to identify as a firefox browser, see #2438\n    s.headers.update({\'User-Agent\': \'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:71.0) Gecko/20100101 Firefox/71.0\'}) \n    u = s.get(url, stream=True, timeout=timeout)\n    try: file_size = int(u.headers[""Content-Length""])\n    except: show_progress = False\n\n    with open(dest, \'wb\') as f:\n        nbytes = 0\n        if show_progress: pbar = progress_bar(range(file_size), leave=False, parent=pbar)\n        try:\n            if show_progress: pbar.update(0)\n            for chunk in u.iter_content(chunk_size=chunk_size):\n                nbytes += len(chunk)\n                if show_progress: pbar.update(nbytes)\n                f.write(chunk)\n        except requests.exceptions.ConnectionError as e:\n            fname = url.split(\'/\')[-1]\n            from fastai.datasets import Config\n            data_dir = Config().data_path()\n            timeout_txt =(f\'\\n Download of {url} has failed after {retries} retries\\n\'\n                          f\' Fix the download manually:\\n\'\n                          f\'$ mkdir -p {data_dir}\\n\'\n                          f\'$ cd {data_dir}\\n\'\n                          f\'$ wget -c {url}\\n\'\n                          f\'$ tar -zxvf {fname}\\n\\n\'\n                          f\'And re-run your code once the download is successful\\n\')\n            print(timeout_txt)\n            import sys;sys.exit(1)\n\ndef range_of(x):\n    ""Create a range from 0 to `len(x)`.""\n    return list(range(len(x)))\ndef arange_of(x):\n    ""Same as `range_of` but returns an array.""\n    return np.arange(len(x))\n\nPath.ls = lambda x: list(x.iterdir())\n\ndef join_path(fname:PathOrStr, path:PathOrStr=\'.\')->Path:\n    ""Return `Path(path)/Path(fname)`, `path` defaults to current dir.""\n    return Path(path)/Path(fname)\n\ndef join_paths(fnames:FilePathList, path:PathOrStr=\'.\')->Collection[Path]:\n    ""Join `path` to every file name in `fnames`.""\n    path = Path(path)\n    return [join_path(o,path) for o in fnames]\n\ndef loadtxt_str(path:PathOrStr)->np.ndarray:\n    ""Return `ndarray` of `str` of lines of text from `path`.""\n    with open(path, \'r\') as f: lines = f.readlines()\n    return np.array([l.strip() for l in lines])\n\ndef save_texts(fname:PathOrStr, texts:Collection[str]):\n    ""Save in `fname` the content of `texts`.""\n    with open(fname, \'w\') as f:\n        for t in texts: f.write(f\'{t}\\n\')\n\ndef df_names_to_idx(names:IntsOrStrs, df:DataFrame):\n    ""Return the column indexes of `names` in `df`.""\n    if not is_listy(names): names = [names]\n    if isinstance(names[0], int): return names\n    return [df.columns.get_loc(c) for c in names]\n\ndef one_hot(x:Collection[int], c:int):\n    ""One-hot encode `x` with `c` classes.""\n    res = np.zeros((c,), np.float32)\n    res[listify(x)] = 1.\n    return res\n\ndef index_row(a:Union[Collection,pd.DataFrame,pd.Series], idxs:Collection[int])->Any:\n    ""Return the slice of `a` corresponding to `idxs`.""\n    if a is None: return a\n    if isinstance(a,(pd.DataFrame,pd.Series)):\n        res = a.iloc[idxs]\n        if isinstance(res,(pd.DataFrame,pd.Series)): return res.copy()\n        return res\n    return a[idxs]\n\ndef func_args(func)->bool:\n    ""Return the arguments of `func`.""\n    code = func.__code__\n    return code.co_varnames[:code.co_argcount]\n\ndef has_arg(func, arg)->bool:\n    ""Check if `func` accepts `arg`.""\n    return arg in func_args(func)\n\ndef split_kwargs_by_func(kwargs, func):\n    ""Split `kwargs` between those expected by `func` and the others.""\n    args = func_args(func)\n    func_kwargs = {a:kwargs.pop(a) for a in args if a in kwargs}\n    return func_kwargs, kwargs\n\ndef array(a, dtype:type=None, **kwargs)->np.ndarray:\n    ""Same as `np.array` but also handles generators. `kwargs` are passed to `np.array` with `dtype`.""\n    if not isinstance(a, Sized) and not getattr(a,\'__array_interface__\',False):\n        a = list(a)\n    if np.int_==np.int32 and dtype is None and is_listy(a) and len(a) and isinstance(a[0],int):\n        dtype=np.int64\n    return np.array(a, dtype=dtype, **kwargs)\n\nclass EmptyLabel(ItemBase):\n    ""Should be used for a dummy label.""\n    def __init__(self): self.obj,self.data = 0,0\n    def __str__(self):  return \'\'\n    def __hash__(self): return hash(str(self))\n    def apply_tfms(self, *args, **kwargs):\n        raise Exception(""""""Attempting to apply transforms to an empty label. This usually means you are\n        trying to apply transforms on your xs and ys on an inference problem, which will give you wrong\n        predictions. Pass `tfms=None, tfm_y=False` when creating your test set.\n        """""")\n\nclass Category(ItemBase):\n    ""Basic class for single classification labels.""\n    def __init__(self,data,obj): self.data,self.obj = data,obj\n    def __int__(self):  return int(self.data)\n    def __str__(self):  return str(self.obj)\n    def __hash__(self): return hash(str(self))\n\nclass MultiCategory(ItemBase):\n    ""Basic class for multi-classification labels.""\n    def __init__(self,data,obj,raw): self.data,self.obj,self.raw = data,obj,raw\n    def __str__(self):  return \';\'.join([str(o) for o in self.obj])\n    def __hash__(self): return hash(str(self))\n\nclass FloatItem(ItemBase):\n    ""Basic class for float items.""\n    def __init__(self,obj): self.data,self.obj = np.array(obj).astype(np.float32),obj\n    def __str__(self):  return str(self.obj)\n    def __hash__(self): return hash(str(self))\n\ndef _treat_html(o:str)->str:\n    o = str(o)\n    to_replace = {\'\\n\':\'\\\\n\', \'<\':\'&lt;\', \'>\':\'&gt;\', \'&\':\'&amp;\'}\n    for k,v in to_replace.items(): o = o.replace(k, v)\n    return o\n\ndef text2html_table(items:Collection[Collection[str]])->str:\n    ""Put the texts in `items` in an HTML table, `widths` are the widths of the columns in %.""\n    html_code = f""""""<table border=""1"" class=""dataframe"">""""""\n    html_code += f""""""  <thead>\\n    <tr style=""text-align: right;"">\\n""""""\n    for i in items[0]: html_code += f""      <th>{_treat_html(i)}</th>""\n    html_code += f""    </tr>\\n  </thead>\\n  <tbody>""\n    html_code += ""  <tbody>""\n    for line in items[1:]:\n        html_code += ""    <tr>""\n        for i in line: html_code += f""      <td>{_treat_html(i)}</td>""\n        html_code += ""    </tr>""\n    html_code += ""  </tbody>\\n</table>""\n    return html_code\n\ndef parallel(func, arr:Collection, max_workers:int=None, leave=False):\n    ""Call `func` on every element of `arr` in parallel using `max_workers`.""\n    max_workers = ifnone(max_workers, defaults.cpus)\n    if max_workers<2: results = [func(o,i) for i,o in progress_bar(enumerate(arr), total=len(arr), leave=leave)]\n    else:\n        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n            futures = [ex.submit(func,o,i) for i,o in enumerate(arr)]\n            results = []\n            for f in progress_bar(concurrent.futures.as_completed(futures), total=len(arr), leave=leave): \n                results.append(f.result())\n    if any([o is not None for o in results]): return results\n\ndef subplots(rows:int, cols:int, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, title=None, **kwargs):\n    ""Like `plt.subplots` but with consistent axs shape, `kwargs` passed to `fig.suptitle` with `title`""\n    figsize = ifnone(figsize, (imgsize*cols, imgsize*rows))\n    fig, axs = plt.subplots(rows,cols,figsize=figsize)\n    if rows==cols==1: axs = [[axs]] # subplots(1,1) returns Axes, not [Axes]\n    elif (rows==1 and cols!=1) or (cols==1 and rows!=1): axs = [axs]\n    if title is not None: fig.suptitle(title, **kwargs)\n    return array(axs)\n\ndef show_some(items:Collection, n_max:int=5, sep:str=\',\'):\n    ""Return the representation of the first  `n_max` elements in `items`.""\n    if items is None or len(items) == 0: return \'\'\n    res = sep.join([f\'{o}\' for o in items[:n_max]])\n    if len(items) > n_max: res += \'...\'\n    return res\n\ndef get_tmp_file(dir=None):\n    ""Create and return a tmp filename, optionally at a specific path. `os.remove` when done with it.""\n    with tempfile.NamedTemporaryFile(delete=False, dir=dir) as f: return f.name\n\ndef compose(funcs:List[Callable])->Callable:\n    ""Compose `funcs`""\n    def compose_(funcs, x, *args, **kwargs):\n        for f in listify(funcs): x = f(x, *args, **kwargs)\n        return x\n    return partial(compose_, funcs)\n\nclass PrettyString(str):\n    ""Little hack to get strings to show properly in Jupyter.""\n    def __repr__(self): return self\n\ndef float_or_x(x):\n    ""Tries to convert to float, returns x if it can\'t""\n    try:   return float(x)\n    except:return x\n\ndef bunzip(fn:PathOrStr):\n    ""bunzip `fn`, raising exception if output already exists""\n    fn = Path(fn)\n    assert fn.exists(), f""{fn} doesn\'t exist""\n    out_fn = fn.with_suffix(\'\')\n    assert not out_fn.exists(), f""{out_fn} already exists""\n    with bz2.BZ2File(fn, \'rb\') as src, out_fn.open(\'wb\') as dst:\n        for d in iter(lambda: src.read(1024*1024), b\'\'): dst.write(d)\n\n@contextmanager\ndef working_directory(path:PathOrStr):\n    ""Change working directory to `path` and return to previous on exit.""\n    prev_cwd = Path.cwd()\n    os.chdir(path)\n    try: yield\n    finally: os.chdir(prev_cwd)\n\n'"
fastai/data_block.py,2,"b'from .torch_core import *\nfrom .basic_data import *\nfrom .layers import *\nfrom numbers import Integral\n\n__all__ = [\'ItemList\', \'CategoryList\', \'MultiCategoryList\', \'MultiCategoryProcessor\', \'LabelList\', \'ItemLists\', \'get_files\',\n           \'PreProcessor\', \'LabelLists\', \'FloatList\', \'CategoryProcessor\', \'EmptyLabelList\', \'MixedItem\', \'MixedProcessor\',\n           \'MixedItemList\']\n\ndef _decode(df):\n    return np.array([[df.columns[i] for i,t in enumerate(x) if t==1] for x in df.values], dtype=np.object)\n\ndef _maybe_squeeze(arr): return arr if is1d(arr) else (np.array(arr).ravel() if np.array(arr).shape == () else np.squeeze(arr))\n\ndef _path_to_same_str(p_fn):\n    ""path -> str, but same on nt+posix, for alpha-sort only""\n    s_fn = str(p_fn)\n    s_fn = s_fn.replace(\'\\\\\',\'.\')\n    s_fn = s_fn.replace(\'/\',\'.\')\n    return s_fn\n\ndef _get_files(parent, p, f, extensions):\n    p = Path(p)#.relative_to(parent)\n    if isinstance(extensions,str): extensions = [extensions]\n    low_extensions = [e.lower() for e in extensions] if extensions is not None else None\n    res = [p/o for o in f if not o.startswith(\'.\')\n           and (extensions is None or f\'.{o.split(""."")[-1].lower()}\' in low_extensions)]\n    return res\n\ndef get_files(path:PathOrStr, extensions:Collection[str]=None, recurse:bool=False, exclude:Optional[Collection[str]]=None,\n              include:Optional[Collection[str]]=None, presort:bool=False, followlinks:bool=False)->FilePathList:\n    ""Return list of files in `path` that have a suffix in `extensions`; optionally `recurse`.""\n    if recurse:\n        res = []\n        for i,(p,d,f) in enumerate(os.walk(path, followlinks=followlinks)):\n            # skip hidden dirs\n            if include is not None and i==0:   d[:] = [o for o in d if o in include]\n            elif exclude is not None and i==0: d[:] = [o for o in d if o not in exclude]\n            else:                              d[:] = [o for o in d if not o.startswith(\'.\')]\n            res += _get_files(path, p, f, extensions)\n        if presort: res = sorted(res, key=lambda p: _path_to_same_str(p), reverse=False)\n        return res\n    else:\n        f = [o.name for o in os.scandir(path) if o.is_file()]\n        res = _get_files(path, path, f, extensions)\n        if presort: res = sorted(res, key=lambda p: _path_to_same_str(p), reverse=False)\n        return res\n\nclass PreProcessor():\n    ""Basic class for a processor that will be applied to items at the end of the data block API.""\n    def __init__(self, ds:Collection=None):  self.ref_ds = ds\n    def process_one(self, item:Any):         return item\n    def process(self, ds:Collection):        ds.items = array([self.process_one(item) for item in ds.items])\n\nPreProcessors = Union[PreProcessor, Collection[PreProcessor]]\nfastai_types[PreProcessors] = \'PreProcessors\'\n\nclass ItemList():\n    ""A collection of items with `__len__` and `__getitem__` with `ndarray` indexing semantics.""\n    _bunch,_processor,_label_cls,_square_show,_square_show_res = DataBunch,None,None,False,False\n\n    def __init__(self, items:Iterator, path:PathOrStr=\'.\', label_cls:Callable=None, inner_df:Any=None,\n                 processor:PreProcessors=None, x:\'ItemList\'=None, ignore_empty:bool=False):\n        self.path = Path(path)\n        self.num_parts = len(self.path.parts)\n        self.items,self.x,self.ignore_empty = items,x,ignore_empty\n        if not isinstance(self.items,np.ndarray): self.items = array(self.items, dtype=object)\n        self.label_cls,self.inner_df,self.processor = ifnone(label_cls,self._label_cls),inner_df,processor\n        self._label_list,self._split = LabelList,ItemLists\n        self.copy_new = [\'x\', \'label_cls\', \'path\']\n\n    def __len__(self)->int: return len(self.items) or 1\n    def get(self, i)->Any:\n        ""Subclass if you want to customize how to create item `i` from `self.items`.""\n        return self.items[i]\n    def __repr__(self)->str:\n        items = [self[i] for i in range(min(5,len(self.items)))]\n        return f\'{self.__class__.__name__} ({len(self.items)} items)\\n{show_some(items)}\\nPath: {self.path}\'\n\n    def process(self, processor:PreProcessors=None):\n        ""Apply `processor` or `self.processor` to `self`.""\n        if processor is not None: self.processor = processor\n        self.processor = listify(self.processor)\n        for p in self.processor: p.process(self)\n        return self\n\n    def process_one(self, item:ItemBase, processor:PreProcessors=None):\n        ""Apply `processor` or `self.processor` to `item`.""\n        if processor is not None: self.processor = processor\n        self.processor = listify(self.processor)\n        for p in self.processor: item = p.process_one(item)\n        return item\n\n    def analyze_pred(self, pred:Tensor):\n        ""Called on `pred` before `reconstruct` for additional preprocessing.""\n        return pred\n\n    def reconstruct(self, t:Tensor, x:Tensor=None):\n        ""Reconstruct one of the underlying item for its data `t`.""\n        if not hasattr(self[0], \'reconstruct\'): return t\n        return self[0].reconstruct(t,x) if has_arg(self[0].reconstruct, \'x\') else self[0].reconstruct(t)\n\n    def new(self, items:Iterator, processor:PreProcessors=None, **kwargs)->\'ItemList\':\n        ""Create a new `ItemList` from `items`, keeping the same attributes.""\n        processor = ifnone(processor, self.processor)\n        copy_d = {o:getattr(self,o) for o in self.copy_new}\n        kwargs = {**copy_d, **kwargs}\n        return self.__class__(items=items, processor=processor, **kwargs)\n\n    def add(self, items:\'ItemList\'):\n        self.items = np.concatenate([self.items, items.items], 0)\n        if self.inner_df is not None and items.inner_df is not None:\n            self.inner_df = pd.concat([self.inner_df, items.inner_df])\n        else: self.inner_df = self.inner_df or items.inner_df\n        return self\n\n    def __getitem__(self,idxs:int)->Any:\n        ""returns a single item based if `idxs` is an integer or a new `ItemList` object if `idxs` is a range.""\n        idxs = try_int(idxs)\n        if isinstance(idxs, Integral): return self.get(idxs)\n        else: return self.new(self.items[idxs], inner_df=index_row(self.inner_df, idxs))\n\n    @classmethod\n    def from_folder(cls, path:PathOrStr, extensions:Collection[str]=None, recurse:bool=True, exclude:Optional[Collection[str]]=None,\n                    include:Optional[Collection[str]]=None, processor:PreProcessors=None, presort:Optional[bool]=False, **kwargs)->\'ItemList\':\n        """"""Create an `ItemList` in `path` from the filenames that have a suffix in `extensions`.\n        `recurse` determines if we search subfolders.""""""\n        path = Path(path)\n        assert path.is_dir() and path.exists(), f""{path} is not a valid directory.""\n        return cls(get_files(path, extensions, recurse=recurse, exclude=exclude, include=include, presort=presort), \n                   path=path, processor=processor, **kwargs)\n\n    @classmethod\n    def from_df(cls, df:DataFrame, path:PathOrStr=\'.\', cols:IntsOrStrs=0, processor:PreProcessors=None, **kwargs)->\'ItemList\':\n        ""Create an `ItemList` in `path` from the inputs in the `cols` of `df`.""\n        inputs = df.iloc[:,df_names_to_idx(cols, df)]\n        assert not inputs.isna().any().any(), f""You have NaN values in column(s) {cols} of your dataframe, please fix it.""\n        items = _maybe_squeeze(inputs.values) if len(df) > 1 else (inputs.values[0] if not isinstance(cols, Collection) or len(cols) == 1 else inputs.values)\n        res = cls(items=items, path=path, inner_df=df, processor=processor, **kwargs)\n        return res\n\n    @classmethod\n    def from_csv(cls, path:PathOrStr, csv_name:str, cols:IntsOrStrs=0, delimiter:str=None, header:str=\'infer\',\n                 processor:PreProcessors=None, **kwargs)->\'ItemList\':\n        """"""Create an `ItemList` in `path` from the inputs in the `cols` of `path/csv_name`""""""\n        df = pd.read_csv(Path(path)/csv_name, delimiter=delimiter, header=header)\n        return cls.from_df(df, path=path, cols=cols, processor=processor, **kwargs)\n\n    def _relative_item_path(self, i): return self.items[i].relative_to(self.path)\n    def _relative_item_paths(self):   return [self._relative_item_path(i) for i in range_of(self.items)]\n\n    def use_partial_data(self, sample_pct:float=0.01, seed:int=None)->\'ItemList\':\n        ""Use only a sample of `sample_pct`of the full dataset and an optional `seed`.""\n        if seed is not None: np.random.seed(seed)\n        rand_idx = np.random.permutation(range_of(self))\n        cut = int(sample_pct * len(self))\n        return self[rand_idx[:cut]]\n\n    def to_text(self, fn:str):\n        ""Save `self.items` to `fn` in `self.path`.""\n        with open(self.path/fn, \'w\') as f: f.writelines([f\'{o}\\n\' for o in self._relative_item_paths()])\n\n    def filter_by_func(self, func:Callable)->\'ItemList\':\n        ""Only keep elements for which `func` returns `True`.""\n        self.items = array([o for o in self.items if func(o)])\n        return self\n\n    def filter_by_folder(self, include=None, exclude=None):\n        ""Only keep filenames in `include` folder or reject the ones in `exclude`.""\n        include,exclude = listify(include),listify(exclude)\n        def _inner(o):\n            if isinstance(o, Path): n = o.relative_to(self.path).parts[0]\n            else: n = o.split(os.path.sep)[len(str(self.path).split(os.path.sep))]\n            if include and not n in include: return False\n            if exclude and     n in exclude: return False\n            return True\n        return self.filter_by_func(_inner)\n\n    def filter_by_rand(self, p:float, seed:int=None):\n        ""Keep random sample of `items` with probability `p` and an optional `seed`.""\n        if seed is not None: set_all_seed(seed)\n        return self.filter_by_func(lambda o: rand_bool(p))\n\n    def no_split(self):\n        warn(""`no_split` is deprecated, please use `split_none`."")\n        return self.split_none()\n\n    def split_none(self):\n        ""Don\'t split the data and create an empty validation set.""\n        val = self[[]]\n        val.ignore_empty = True\n        return self._split(self.path, self, val)\n\n    def split_by_list(self, train, valid):\n        ""Split the data between `train` and `valid`.""\n        return self._split(self.path, train, valid)\n\n    def split_by_idxs(self, train_idx, valid_idx):\n        ""Split the data between `train_idx` and `valid_idx`.""\n        return self.split_by_list(self[train_idx], self[valid_idx])\n\n    def split_by_idx(self, valid_idx:Collection[int])->\'ItemLists\':\n        ""Split the data according to the indexes in `valid_idx`.""\n        #train_idx = [i for i in range_of(self.items) if i not in valid_idx]\n        train_idx = np.setdiff1d(arange_of(self.items), valid_idx)\n        return self.split_by_idxs(train_idx, valid_idx)\n\n    def _get_by_folder(self, name):\n        return [i for i in range_of(self) if (self.items[i].parts[self.num_parts] if isinstance(self.items[i], Path)\n                else self.items[i].split(os.path.sep)[0]) == name ]\n\n    def split_by_folder(self, train:str=\'train\', valid:str=\'valid\')->\'ItemLists\':\n        ""Split the data depending on the folder (`train` or `valid`) in which the filenames are.""\n        return self.split_by_idxs(self._get_by_folder(train), self._get_by_folder(valid))\n\n    def random_split_by_pct(self, valid_pct:float=0.2, seed:int=None):\n        warn(""`random_split_by_pct` is deprecated, please use `split_by_rand_pct`."")\n        return self.split_by_rand_pct(valid_pct=valid_pct, seed=seed)\n\n    def split_by_rand_pct(self, valid_pct:float=0.2, seed:int=None)->\'ItemLists\':\n        ""Split the items randomly by putting `valid_pct` in the validation set, optional `seed` can be passed.""\n        if valid_pct==0.: return self.split_none()\n        if seed is not None: np.random.seed(seed)\n        rand_idx = np.random.permutation(range_of(self))\n        cut = int(valid_pct * len(self))\n        return self.split_by_idx(rand_idx[:cut])\n\n    def split_subsets(self, train_size:float, valid_size:float, seed=None) -> \'ItemLists\':\n        ""Split the items into train set with size `train_size * n` and valid set with size `valid_size * n`.""\n        assert 0 < train_size < 1\n        assert 0 < valid_size < 1\n        assert train_size + valid_size <= 1.\n        if seed is not None: np.random.seed(seed)\n        n = len(self.items)\n        rand_idx = np.random.permutation(range(n))\n        train_cut, valid_cut = int(train_size * n), int(valid_size * n)\n        return self.split_by_idxs(rand_idx[:train_cut], rand_idx[-valid_cut:])\n\n    def split_by_valid_func(self, func:Callable)->\'ItemLists\':\n        ""Split the data by result of `func` (which returns `True` for validation set).""\n        valid_idx = [i for i,o in enumerate(self.items) if func(o)]\n        return self.split_by_idx(valid_idx)\n\n    def split_by_files(self, valid_names:\'ItemList\')->\'ItemLists\':\n        ""Split the data by using the names in `valid_names` for validation.""\n        if isinstance(self.items[0], Path): return self.split_by_valid_func(lambda o: o.name in valid_names)\n        else: return self.split_by_valid_func(lambda o: os.path.basename(o) in valid_names)\n\n    def split_by_fname_file(self, fname:PathOrStr, path:PathOrStr=None)->\'ItemLists\':\n        ""Split the data by using the names in `fname` for the validation set. `path` will override `self.path`.""\n        path = Path(ifnone(path, self.path))\n        valid_names = loadtxt_str(path/fname)\n        return self.split_by_files(valid_names)\n\n    def split_from_df(self, col:IntsOrStrs=2):\n        ""Split the data from the `col` in the dataframe in `self.inner_df`.""\n        valid_idx = np.where(self.inner_df.iloc[:,df_names_to_idx(col, self.inner_df)])[0]\n        return self.split_by_idx(valid_idx)\n\n    def get_label_cls(self, labels, label_cls:Callable=None, label_delim:str=None, **kwargs):\n        ""Return `label_cls` or guess one from the first element of `labels`.""\n        if label_cls is not None:               return label_cls\n        if self.label_cls is not None:          return self.label_cls\n        if label_delim is not None:             return MultiCategoryList\n        try: it = index_row(labels,0)\n        except: raise Exception(""""""Can\'t infer the type of your targets. \nIt\'s either because your data source is empty or because your labelling function raised an error."""""")\n        if isinstance(it, (float, np.float32)): return FloatList\n        if isinstance(try_int(it), (str, Integral)):  return CategoryList\n        if isinstance(it, Collection):          return MultiCategoryList\n        return ItemList #self.__class__\n\n    def _label_from_list(self, labels:Iterator, label_cls:Callable=None, from_item_lists:bool=False, **kwargs)->\'LabelList\':\n        ""Label `self.items` with `labels`.""\n        if not from_item_lists:\n            raise Exception(""Your data isn\'t split, if you don\'t want a validation set, please use `split_none`."")\n        labels = array(labels, dtype=object)\n        label_cls = self.get_label_cls(labels, label_cls=label_cls, **kwargs)\n        y = label_cls(labels, path=self.path, **kwargs)\n        res = self._label_list(x=self, y=y)\n        return res\n\n    def label_from_df(self, cols:IntsOrStrs=1, label_cls:Callable=None, **kwargs):\n        ""Label `self.items` from the values in `cols` in `self.inner_df`.""\n        labels = self.inner_df.iloc[:,df_names_to_idx(cols, self.inner_df)]\n        assert labels.isna().sum().sum() == 0, f""You have NaN values in column(s) {cols} of your dataframe, please fix it.""\n        if is_listy(cols) and len(cols) > 1 and (label_cls is None or label_cls == MultiCategoryList):\n            new_kwargs,label_cls = dict(one_hot=True, classes= cols),MultiCategoryList\n            kwargs = {**new_kwargs, **kwargs}\n        return self._label_from_list(_maybe_squeeze(labels), label_cls=label_cls, **kwargs)\n\n    def label_const(self, const:Any=0, label_cls:Callable=None, **kwargs)->\'LabelList\':\n        ""Label every item with `const`.""\n        return self.label_from_func(func=lambda o: const, label_cls=label_cls, **kwargs)\n\n    def label_empty(self, **kwargs):\n        ""Label every item with an `EmptyLabel`.""\n        kwargs[\'label_cls\'] = EmptyLabelList\n        return self.label_from_func(func=lambda o: 0., **kwargs)\n\n    def label_from_func(self, func:Callable, label_cls:Callable=None, **kwargs)->\'LabelList\':\n        ""Apply `func` to every input to get its label.""\n        return self._label_from_list([func(o) for o in self.items], label_cls=label_cls, **kwargs)\n\n    def label_from_folder(self, label_cls:Callable=None, **kwargs)->\'LabelList\':\n        ""Give a label to each filename depending on its folder.""\n        return self.label_from_func(func=lambda o: (o.parts if isinstance(o, Path) else o.split(os.path.sep))[-2],\n                                    label_cls=label_cls, **kwargs)\n\n    def label_from_re(self, pat:str, full_path:bool=False, label_cls:Callable=None, **kwargs)->\'LabelList\':\n        ""Apply the re in `pat` to determine the label of every filename.  If `full_path`, search in the full name.""\n        pat = re.compile(pat)\n        def _inner(o):\n            s = str((os.path.join(self.path,o) if full_path else o).as_posix())\n            res = pat.search(s)\n            assert res,f\'Failed to find ""{pat}"" in ""{s}""\'\n            return res.group(1)\n        return self.label_from_func(_inner, label_cls=label_cls, **kwargs)\n\n    def databunch(self, **kwargs):\n        ""To throw a clear error message when the data wasn\'t split and labeled.""\n        raise Exception(""Your data is neither split nor labeled, can\'t turn it into a `DataBunch` yet."")\n\nclass EmptyLabelList(ItemList):\n    ""Basic `ItemList` for dummy labels.""\n    def get(self, i): return EmptyLabel()\n    def reconstruct(self, t:Tensor, x:Tensor=None):\n        if len(t.size()) == 0: return EmptyLabel()\n        return self.x.reconstruct(t,x) if has_arg(self.x.reconstruct, \'x\') else self.x.reconstruct(t)\n\nclass CategoryProcessor(PreProcessor):\n    ""`PreProcessor` that create `classes` from `ds.items` and handle the mapping.""\n    def __init__(self, ds:ItemList):\n        self.create_classes(ds.classes)\n        self.state_attrs,self.warns = [\'classes\'],[]\n\n    def create_classes(self, classes):\n        self.classes = classes\n        if classes is not None: self.c2i = {v:k for k,v in enumerate(classes)}\n\n    def generate_classes(self, items):\n        ""Generate classes from `items` by taking the sorted unique values.""\n        return uniqueify(items, sort=True)\n\n    def process_one(self,item):\n        if isinstance(item, EmptyLabel): return item\n        res = self.c2i.get(item,None)\n        if res is None: self.warns.append(str(item))\n        return res\n\n    def process(self, ds):\n        if self.classes is None: self.create_classes(self.generate_classes(ds.items))\n        ds.classes = self.classes\n        ds.c2i = self.c2i\n        super().process(ds)\n\n    def __getstate__(self): return {n:getattr(self,n) for n in self.state_attrs}\n    def __setstate__(self, state:dict):\n        self.create_classes(state[\'classes\'])\n        self.state_attrs = state.keys()\n        for n in state.keys():\n            if n!=\'classes\': setattr(self, n, state[n])\n\nclass CategoryListBase(ItemList):\n    ""Basic `ItemList` for classification.""\n    def __init__(self, items:Iterator, classes:Collection=None, **kwargs):\n        self.classes=classes\n        self.filter_missing_y = True\n        super().__init__(items, **kwargs)\n        self.copy_new.append(\'classes\')\n\n    @property\n    def c(self): return len(self.classes)\n\nclass CategoryList(CategoryListBase):\n    ""Basic `ItemList` for single classification labels.""\n    _processor=CategoryProcessor\n    def __init__(self, items:Iterator, classes:Collection=None, label_delim:str=None, **kwargs):\n        super().__init__(items, classes=classes, **kwargs)\n        self.loss_func = CrossEntropyFlat()\n\n    def get(self, i):\n        o = self.items[i]\n        if o is None: return None\n        return Category(o, self.classes[o])\n\n    def analyze_pred(self, pred, thresh:float=0.5): return pred.argmax()\n\n    def reconstruct(self, t):\n        return Category(t, self.classes[t])\n\nclass MultiCategoryProcessor(CategoryProcessor):\n    ""`PreProcessor` that create `classes` from `ds.items` and handle the mapping.""\n    def __init__(self, ds:ItemList, one_hot:bool=False):\n        super().__init__(ds)\n        self.one_hot = one_hot\n        self.state_attrs.append(\'one_hot\')\n\n    def process_one(self,item):\n        if self.one_hot or isinstance(item, EmptyLabel): return item\n        res = [super(MultiCategoryProcessor, self).process_one(o) for o in item]\n        return [r for r in res if r is not None]\n\n    def generate_classes(self, items):\n        ""Generate classes from `items` by taking the sorted unique values.""\n        classes = set()\n        for c in items: classes = classes.union(set(c))\n        classes = list(classes)\n        classes.sort()\n        return classes\n\nclass MultiCategoryList(CategoryListBase):\n    ""Basic `ItemList` for multi-classification labels.""\n    _processor=MultiCategoryProcessor\n    def __init__(self, items:Iterator, classes:Collection=None, label_delim:str=None, one_hot:bool=False, **kwargs):\n        if label_delim is not None: items = array(csv.reader(items.astype(str), delimiter=label_delim))\n        super().__init__(items, classes=classes, **kwargs)\n        if one_hot:\n            assert classes is not None, ""Please provide class names with `classes=...`""\n            self.processor = [MultiCategoryProcessor(self, one_hot=True)]\n        self.loss_func = BCEWithLogitsFlat()\n        self.one_hot = one_hot\n        self.copy_new += [\'one_hot\']\n\n    def get(self, i):\n        o = self.items[i]\n        if o is None: return None\n        if self.one_hot: return self.reconstruct(o.astype(np.float32))\n        return MultiCategory(one_hot(o, self.c), [self.classes[p] for p in o], o)\n\n    def analyze_pred(self, pred, thresh:float=0.5):\n        return (pred >= thresh).float()\n\n    def reconstruct(self, t):\n        o = [i for i in range(self.c) if t[i] == 1.]\n        return MultiCategory(t, [self.classes[p] for p in o], o)\n\nclass FloatList(ItemList):\n    ""`ItemList` suitable for storing the floats in items for regression. Will add a `log` if this flag is `True`.""\n    def __init__(self, items:Iterator, log:bool=False, classes:Collection=None, **kwargs):\n        super().__init__(np.array(items, dtype=np.float32), **kwargs)\n        self.log = log\n        self.copy_new.append(\'log\')\n        self.c = self.items.shape[1] if len(self.items.shape) > 1 else 1\n        self.loss_func = MSELossFlat()\n\n    def get(self, i):\n        o = super().get(i)\n        return FloatItem(np.log(o) if self.log else o)\n\n    def reconstruct(self,t): return FloatItem(t.numpy())\n\nclass ItemLists():\n    ""An `ItemList` for each of `train` and `valid` (optional `test`).""\n    def __init__(self, path:PathOrStr, train:ItemList, valid:ItemList):\n        self.path,self.train,self.valid,self.test = Path(path),train,valid,None\n        if not self.train.ignore_empty and len(self.train.items) == 0:\n            warn(""Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning."")\n        if not self.valid.ignore_empty and len(self.valid.items) == 0:\n            warn(""""""Your validation set is empty. If this is by design, use `split_none()`\n                 or pass `ignore_empty=True` when labelling to remove this warning."""""")\n        if isinstance(self.train, LabelList): self.__class__ = LabelLists\n\n    def __dir__(self)->List[str]:\n        default_dir = dir(type(self)) + list(self.__dict__.keys())\n        add_ons = [\'label_const\', \'label_empty\', \'label_from_df\', \'label_from_folder\', \'label_from_func\',\n                   \'label_from_list\', \'label_from_re\']\n        return default_dir + add_ons\n\n    def __repr__(self)->str:\n        return f\'{self.__class__.__name__};\\n\\nTrain: {self.train};\\n\\nValid: {self.valid};\\n\\nTest: {self.test}\'\n\n    def __getattr__(self, k):\n        ft = getattr(self.train, k)\n        if not isinstance(ft, Callable): return ft\n        fv = getattr(self.valid, k)\n        assert isinstance(fv, Callable)\n        def _inner(*args, **kwargs):\n            self.train = ft(*args, from_item_lists=True, **kwargs)\n            assert isinstance(self.train, LabelList)\n            kwargs[\'label_cls\'] = self.train.y.__class__\n            self.valid = fv(*args, from_item_lists=True, **kwargs)\n            self.__class__ = LabelLists\n            self.process()\n            return self\n        return _inner\n\n    def __setstate__(self,data:Any): self.__dict__.update(data)\n\n    @property\n    def lists(self):\n        res = [self.train,self.valid]\n        if self.test is not None: res.append(self.test)\n        return res\n\n    def label_from_lists(self, train_labels:Iterator, valid_labels:Iterator, label_cls:Callable=None, **kwargs)->\'LabelList\':\n        ""Use the labels in `train_labels` and `valid_labels` to label the data. `label_cls` will overwrite the default.""\n        label_cls = self.train.get_label_cls(train_labels, label_cls)\n        self.train = self.train._label_list(x=self.train, y=label_cls(train_labels, **kwargs))\n        self.valid = self.valid._label_list(x=self.valid, y=self.train.y.new(valid_labels, **kwargs))\n        self.__class__ = LabelLists\n        self.process()\n        return self\n\n    def transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n        ""Set `tfms` to be applied to the xs of the train and validation set.""\n        if not tfms: tfms=(None,None)\n        assert is_listy(tfms) and len(tfms) == 2, ""Please pass a list of two lists of transforms (train and valid).""\n        self.train.transform(tfms[0], **kwargs)\n        self.valid.transform(tfms[1], **kwargs)\n        if self.test: self.test.transform(tfms[1], **kwargs)\n        return self\n\n    def transform_y(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n        ""Set `tfms` to be applied to the ys of the train and validation set.""\n        if not tfms: tfms=(None,None)\n        self.train.transform_y(tfms[0], **kwargs)\n        self.valid.transform_y(tfms[1], **kwargs)\n        if self.test: self.test.transform_y(tfms[1], **kwargs)\n        return self\n\n    def databunch(self, **kwargs):\n        ""To throw a clear error message when the data wasn\'t labeled.""\n        raise Exception(""Your data isn\'t labeled, can\'t turn it into a `DataBunch` yet!"")\n\nclass LabelLists(ItemLists):\n    ""A `LabelList` for each of `train` and `valid` (optional `test`).""\n    def get_processors(self):\n        ""Read the default class processors if none have been set.""\n        procs_x,procs_y = listify(self.train.x._processor),listify(self.train.y._processor)\n        xp = ifnone(self.train.x.processor, [p(ds=self.train.x) for p in procs_x])\n        yp = ifnone(self.train.y.processor, [p(ds=self.train.y) for p in procs_y])\n        return xp,yp\n\n    def process(self):\n        ""Process the inner datasets.""\n        xp,yp = self.get_processors()\n        for ds,n in zip(self.lists, [\'train\',\'valid\',\'test\']): ds.process(xp, yp, name=n)\n        #progress_bar clear the outputs so in some case warnings issued during processing disappear.\n        for ds in self.lists:\n            if getattr(ds, \'warn\', False): warn(ds.warn)\n        return self\n\n    def filter_by_func(self, func:Callable):\n        for ds in self.lists: ds.filter_by_func(func)\n        return self\n\n    def databunch(self, path:PathOrStr=None, bs:int=64, val_bs:int=None, num_workers:int=defaults.cpus,\n                  dl_tfms:Optional[Collection[Callable]]=None, device:torch.device=None, collate_fn:Callable=data_collate,\n                  no_check:bool=False, **kwargs)->\'DataBunch\':\n        ""Create an `DataBunch` from self, `path` will override `self.path`, `kwargs` are passed to `DataBunch.create`.""\n        path = Path(ifnone(path, self.path))\n        data = self.x._bunch.create(self.train, self.valid, test_ds=self.test, path=path, bs=bs, val_bs=val_bs,\n                                    num_workers=num_workers, dl_tfms=dl_tfms, device=device, collate_fn=collate_fn, no_check=no_check, **kwargs)\n        if getattr(self, \'normalize\', False):#In case a normalization was serialized\n            norm = self.normalize\n            data.normalize((norm[\'mean\'], norm[\'std\']), do_x=norm[\'do_x\'], do_y=norm[\'do_y\'])\n        data.label_list = self\n        return data\n\n    def add_test(self, items:Iterator, label:Any=None, tfms=None, tfm_y=None):\n        ""Add test set containing `items` with an arbitrary `label`.""\n        # if no label passed, use label of first training item\n        if label is None: labels = EmptyLabelList([0] * len(items))\n        else: labels = self.valid.y.new([label] * len(items)).process()\n        if isinstance(items, MixedItemList): items = self.valid.x.new(items.item_lists, inner_df=items.inner_df).process()\n        elif isinstance(items, ItemList): items = self.valid.x.new(items.items, inner_df=items.inner_df).process()\n        else: items = self.valid.x.new(items).process()\n        self.test = self.valid.new(items, labels, tfms=tfms, tfm_y=tfm_y)\n        return self\n\n    def add_test_folder(self, test_folder:str=\'test\', label:Any=None, tfms=None, tfm_y=None):\n        ""Add test set containing items from `test_folder` and an arbitrary `label`.""\n        # note: labels will be ignored if available in the test dataset\n        items = self.x.__class__.from_folder(self.path/test_folder)\n        return self.add_test(items.items, label=label, tfms=tfms, tfm_y=tfm_y)\n\n    @classmethod\n    def load_state(cls, path:PathOrStr, state:dict):\n        ""Create a `LabelLists` with empty sets from the serialized `state`.""\n        path = Path(path)\n        train_ds = LabelList.load_state(path, state)\n        valid_ds = LabelList.load_state(path, state)\n        return LabelLists(path, train=train_ds, valid=valid_ds)\n\n    @classmethod\n    def load_empty(cls, path:PathOrStr, fn:PathOrStr=\'export.pkl\'):\n        ""Create a `LabelLists` with empty sets from the serialized file in `path/fn`.""\n        path = Path(path)\n        state = torch.load(open(path/fn, \'rb\'))\n        return LabelLists.load_state(path, state)\n\ndef _check_kwargs(ds:ItemList, tfms:TfmList, **kwargs):\n    tfms = listify(tfms)\n    if (tfms is None or len(tfms) == 0) and len(kwargs) == 0: return\n    if len(ds.items) >= 1:\n        x = ds[0]\n        try: x.apply_tfms(tfms, **kwargs)\n        except Exception as e:\n            raise Exception(f""It\'s not possible to apply those transforms to your dataset:\\n {e}"")\n\nclass LabelList(Dataset):\n    ""A list of inputs `x` and labels `y` with optional `tfms`.""\n    def __init__(self, x:ItemList, y:ItemList, tfms:TfmList=None, tfm_y:bool=False, **kwargs):\n        self.x,self.y,self.tfm_y = x,y,tfm_y\n        self.y.x = x\n        self.item=None\n        self.transform(tfms, **kwargs)\n\n    def __len__(self)->int: return len(self.x) if self.item is None else 1\n\n    @contextmanager\n    def set_item(self,item):\n        ""For inference, will briefly replace the dataset with one that only contains `item`.""\n        self.item = self.x.process_one(item)\n        yield None\n        self.item = None\n\n    def __repr__(self)->str:\n        items = [self[i] for i in range(min(5,len(self.items)))]\n        res = f\'{self.__class__.__name__} ({len(self.items)} items)\\n\'\n        res += f\'x: {self.x.__class__.__name__}\\n{show_some([i[0] for i in items])}\\n\'\n        res += f\'y: {self.y.__class__.__name__}\\n{show_some([i[1] for i in items])}\\n\'\n        return res + f\'Path: {self.path}\'\n\n    def predict(self, res):\n        ""Delegates predict call on `res` to `self.y`.""\n        return self.y.predict(res)\n\n    @property\n    def c(self): return self.y.c\n\n    def new(self, x, y, tfms=None, tfm_y=None, **kwargs)->\'LabelList\':\n        tfms,tfm_y = ifnone(tfms, self.tfms),ifnone(tfm_y, self.tfm_y)\n        if isinstance(x, ItemList):\n            return self.__class__(x, y, tfms=tfms, tfm_y=tfm_y, **self.tfmargs)\n        else:\n            return self.new(self.x.new(x, **kwargs), self.y.new(y, **kwargs), tfms=tfms, tfm_y=tfm_y).process()\n\n    def __getattr__(self,k:str)->Any:\n        x = super().__getattribute__(\'x\')\n        res = getattr(x, k, None)\n        if res is not None and k not in [\'classes\', \'c\']: return res\n        y = super().__getattribute__(\'y\')\n        res = getattr(y, k, None)\n        if res is not None: return res\n        raise AttributeError(k)\n\n    def __setstate__(self,data:Any): self.__dict__.update(data)\n\n    def __getitem__(self,idxs:Union[int,np.ndarray])->\'LabelList\':\n        ""return a single (x, y) if `idxs` is an integer or a new `LabelList` object if `idxs` is a range.""\n        idxs = try_int(idxs)\n        if isinstance(idxs, Integral):\n            if self.item is None: x,y = self.x[idxs],self.y[idxs]\n            else:                 x,y = self.item   ,0\n            if self.tfms or self.tfmargs:\n                x = x.apply_tfms(self.tfms, **self.tfmargs)\n            if hasattr(self, \'tfms_y\') and self.tfm_y and self.item is None:\n                y = y.apply_tfms(self.tfms_y, **{**self.tfmargs_y, \'do_resolve\':False})\n            if y is None: y=0\n            return x,y\n        else: return self.new(self.x[idxs], self.y[idxs])\n\n    def to_df(self)->None:\n        ""Create `pd.DataFrame` containing `items` from `self.x` and `self.y`.""\n        return pd.DataFrame(dict(x=self.x._relative_item_paths(), y=[str(o) for o in self.y]))\n\n    def to_csv(self, dest:str)->None:\n        ""Save `self.to_df()` to a CSV file in `self.path`/`dest`.""\n        self.to_df().to_csv(self.path/dest, index=False)\n\n    def get_state(self, **kwargs):\n        ""Return the minimal state for export.""\n        state = {\'x_cls\':self.x.__class__, \'x_proc\':self.x.processor,\n                 \'y_cls\':self.y.__class__, \'y_proc\':self.y.processor,\n                 \'tfms\':self.tfms, \'tfm_y\':self.tfm_y, \'tfmargs\':self.tfmargs}\n        if hasattr(self, \'tfms_y\'):    state[\'tfms_y\']    = self.tfms_y\n        if hasattr(self, \'tfmargs_y\'): state[\'tfmargs_y\'] = self.tfmargs_y\n        return {**state, **kwargs}\n\n    def export(self, fn:PathOrStr, **kwargs):\n        ""Export the minimal state and save it in `fn` to load an empty version for inference.""\n        pickle.dump(self.get_state(**kwargs), open(fn, \'wb\'))\n\n    @classmethod\n    def load_empty(cls, path:PathOrStr, fn:PathOrStr):\n        ""Load the state in `fn` to create an empty `LabelList` for inference.""\n        return cls.load_state(path, pickle.load(open(Path(path)/fn, \'rb\')))\n\n    @classmethod\n    def load_state(cls, path:PathOrStr, state:dict) -> \'LabelList\':\n        ""Create a `LabelList` from `state`.""\n        x = state[\'x_cls\']([], path=path, processor=state[\'x_proc\'], ignore_empty=True)\n        y = state[\'y_cls\']([], path=path, processor=state[\'y_proc\'], ignore_empty=True)\n        res = cls(x, y, tfms=state[\'tfms\'], tfm_y=state[\'tfm_y\'], **state[\'tfmargs\']).process()\n        if state.get(\'tfms_y\', False):    res.tfms_y    = state[\'tfms_y\']\n        if state.get(\'tfmargs_y\', False): res.tfmargs_y = state[\'tfmargs_y\']\n        if state.get(\'normalize\', False): res.normalize = state[\'normalize\']\n        return res\n\n    def process(self, xp:PreProcessor=None, yp:PreProcessor=None, name:str=None, max_warn_items:int=5):\n        ""Launch the processing on `self.x` and `self.y` with `xp` and `yp`.""\n        self.y.process(yp)\n        if getattr(self.y, \'filter_missing_y\', False):\n            filt = array([o is None for o in self.y.items])\n            if filt.sum()>0:\n                #Warnings are given later since progress_bar might make them disappear.\n                self.warn = f""You are labelling your items with {self.y.__class__.__name__}.\\n""\n                self.warn += f""Your {name} set contained the following unknown labels, the corresponding items have been discarded.\\n""\n                for p in self.y.processor:\n                    if len(getattr(p, \'warns\', [])) > 0:\n                        warnings = list(set(p.warns))\n                        self.warn += \', \'.join(warnings[:max_warn_items])\n                        if len(warnings) > max_warn_items: self.warn += ""...""\n                    p.warns = []\n                self.x,self.y = self.x[~filt],self.y[~filt]\n        self.x.process(xp)\n        return self\n\n    def filter_by_func(self, func:Callable):\n        filt = array([func(x,y) for x,y in zip(self.x.items, self.y.items)])\n        self.x,self.y = self.x[~filt],self.y[~filt]\n        return self\n\n    def transform(self, tfms:TfmList, tfm_y:bool=None, **kwargs):\n        ""Set the `tfms` and `tfm_y` value to be applied to the inputs and targets.""\n        _check_kwargs(self.x, tfms, **kwargs)\n        if tfm_y is None: tfm_y = self.tfm_y\n        tfms_y = None if tfms is None else list(filter(lambda t: getattr(t, \'use_on_y\', True), listify(tfms)))\n        if tfm_y: _check_kwargs(self.y, tfms_y, **kwargs)\n        self.tfms,self.tfmargs  = tfms,kwargs\n        self.tfm_y,self.tfms_y,self.tfmargs_y = tfm_y,tfms_y,kwargs\n        return self\n\n    def transform_y(self, tfms:TfmList=None, **kwargs):\n        ""Set `tfms` to be applied to the targets only.""\n        tfms_y = list(filter(lambda t: getattr(t, \'use_on_y\', True), listify(self.tfms if tfms is None else tfms)))\n        tfmargs_y = {**self.tfmargs, **kwargs} if tfms is None else kwargs\n        _check_kwargs(self.y, tfms_y, **tfmargs_y)\n        self.tfm_y,self.tfms_y,self.tfmargs_y=True,tfms_y,tfmargs_y\n        return self\n\n    def databunch(self, **kwargs):\n        ""To throw a clear error message when the data wasn\'t split.""\n        raise Exception(""Your data isn\'t split, if you don\'t want a validation set, please use `split_none`"")\n\n@classmethod\ndef _databunch_load_empty(cls, path, fname:str=\'export.pkl\'):\n    ""Load an empty `DataBunch` from the exported file in `path/fname` with optional `tfms`.""\n    sd = LabelLists.load_empty(path, fn=fname)\n    return sd.databunch()\n\nDataBunch.load_empty = _databunch_load_empty\n\nclass MixedProcessor(PreProcessor):\n    def __init__(self, procs:Collection[Union[PreProcessor, Collection[PreProcessor]]]):\n        self.procs = procs\n\n    def process_one(self, item:Any):\n        res = []\n        for procs, i in zip(self.procs, item):\n            for p in procs: i = p.process_one(i)\n            res.append(i)\n        return res\n\n    def process(self, ds:Collection):\n        for procs, il in zip(self.procs, ds.item_lists):\n            for p in procs: p.process(il)\n\nclass MixedItem(ItemBase):\n    def __init__(self, items):\n        self.obj = items\n        self.data = [item.data for item in items]\n\n    def __repr__(self): return \'\\n\'.join([f\'{self.__class__.__name__}\'] + [repr(item) for item in self.obj])\n\n    def apply_tfms(self, tfms:Collection, **kwargs):\n        self.obj = [item.apply_tfms(t, **kwargs) for item,t in zip(self.obj, tfms)]\n        self.data = [item.data for item in self.obj]\n        return self\n\nclass MixedItemList(ItemList):\n\n    def __init__(self, item_lists, path:PathOrStr=None, label_cls:Callable=None, inner_df:Any=None,\n                 x:\'ItemList\'=None, ignore_empty:bool=False, processor=None):\n        self.item_lists = item_lists\n        if processor is None:\n            default_procs = [[p(ds=il) for p in listify(il._processor)] for il in item_lists]\n            processor = MixedProcessor([ifnone(il.processor, dp) for il,dp in zip(item_lists, default_procs)])\n        items = range_of(item_lists[0]) if len(item_lists) >= 1 else []\n        if path is None and len(item_lists) >= 1: path = item_lists[0].path\n        super().__init__(items, processor=processor, path=path,\n                         label_cls=label_cls, inner_df=inner_df, x=x, ignore_empty=ignore_empty)\n\n    def new(self, item_lists, processor:PreProcessor=None, **kwargs)->\'ItemList\':\n        ""Create a new `ItemList` from `items`, keeping the same attributes.""\n        processor = ifnone(processor, self.processor)\n        copy_d = {o:getattr(self,o) for o in self.copy_new}\n        kwargs = {**copy_d, **kwargs}\n        return self.__class__(item_lists, processor=processor, **kwargs)\n\n    def get(self, i):\n        return MixedItem([il.get(i) for il in self.item_lists])\n\n    def __getitem__(self,idxs:int)->Any:\n        idxs = try_int(idxs)\n        if isinstance(idxs, Integral): return self.get(idxs)\n        else:\n            item_lists = [il.new(il.items[idxs], inner_df=index_row(il.inner_df, idxs)) for il in self.item_lists]\n            return self.new(item_lists, inner_df=index_row(self.inner_df, idxs))\n'"
fastai/datasets.py,0,"b'from .core import *\nimport hashlib\n\n__all__ = [\'URLs\', \'Config\', \'untar_data\', \'download_data\', \'datapath4file\', \'url2name\', \'url2path\']\n\nMODEL_URL = \'http://files.fast.ai/models/\'\nURL = \'http://files.fast.ai/data/examples/\'\nclass URLs():\n    ""Global constants for dataset and model URLs.""\n    LOCAL_PATH = Path.cwd()\n    S3 = \'https://s3.amazonaws.com/fast-ai-\'\n\n    S3_IMAGE    = f\'{S3}imageclas/\'\n    S3_IMAGELOC = f\'{S3}imagelocal/\'\n    S3_NLP      = f\'{S3}nlp/\'\n    S3_COCO     = f\'{S3}coco/\'\n    S3_MODEL    = f\'{S3}modelzoo/\'\n\n    # main datasets\n    ADULT_SAMPLE        = f\'{URL}adult_sample\'\n    BIWI_SAMPLE         = f\'{URL}biwi_sample\'\n    CIFAR               = f\'{URL}cifar10\'\n    COCO_SAMPLE         = f\'{S3_COCO}coco_sample\'\n    COCO_TINY           = f\'{URL}coco_tiny\'\n    HUMAN_NUMBERS       = f\'{URL}human_numbers\'\n    IMDB                = f\'{S3_NLP}imdb\'\n    IMDB_SAMPLE         = f\'{URL}imdb_sample\'\n    ML_SAMPLE           = f\'{URL}movie_lens_sample\'\n    MNIST_SAMPLE        = f\'{URL}mnist_sample\'\n    MNIST_TINY          = f\'{URL}mnist_tiny\'\n    MNIST_VAR_SIZE_TINY = f\'{S3_IMAGE}mnist_var_size_tiny\'\n    PLANET_SAMPLE       = f\'{URL}planet_sample\'\n    PLANET_TINY         = f\'{URL}planet_tiny\'\n    IMAGENETTE          = f\'{S3_IMAGE}imagenette2\'\n    IMAGENETTE_160      = f\'{S3_IMAGE}imagenette2-160\'\n    IMAGENETTE_320      = f\'{S3_IMAGE}imagenette2-320\'\n    IMAGEWOOF           = f\'{S3_IMAGE}imagewoof2\'\n    IMAGEWOOF_160       = f\'{S3_IMAGE}imagewoof2-160\'\n    IMAGEWOOF_320       = f\'{S3_IMAGE}imagewoof2-320\'\n\n    # kaggle competitions download dogs-vs-cats -p {DOGS.absolute()}\n    DOGS = f\'{URL}dogscats\'\n\n    # image classification datasets\n    CALTECH_101  = f\'{S3_IMAGE}caltech_101\'\n    CARS         = f\'{S3_IMAGE}stanford-cars\'\n    CIFAR_100    = f\'{S3_IMAGE}cifar100\'\n    CUB_200_2011 = f\'{S3_IMAGE}CUB_200_2011\'\n    FLOWERS      = f\'{S3_IMAGE}oxford-102-flowers\'\n    FOOD         = f\'{S3_IMAGE}food-101\'\n    MNIST        = f\'{S3_IMAGE}mnist_png\'\n    PETS         = f\'{S3_IMAGE}oxford-iiit-pet\'\n\n    # NLP datasets\n    AG_NEWS                 = f\'{S3_NLP}ag_news_csv\'\n    AMAZON_REVIEWS          = f\'{S3_NLP}amazon_review_full_csv\'\n    AMAZON_REVIEWS_POLARITY = f\'{S3_NLP}amazon_review_polarity_csv\'\n    DBPEDIA                 = f\'{S3_NLP}dbpedia_csv\'\n    MT_ENG_FRA              = f\'{S3_NLP}giga-fren\'\n    SOGOU_NEWS              = f\'{S3_NLP}sogou_news_csv\'\n    WIKITEXT                = f\'{S3_NLP}wikitext-103\'\n    WIKITEXT_TINY           = f\'{S3_NLP}wikitext-2\'\n    YAHOO_ANSWERS           = f\'{S3_NLP}yahoo_answers_csv\'\n    YELP_REVIEWS            = f\'{S3_NLP}yelp_review_full_csv\'\n    YELP_REVIEWS_POLARITY   = f\'{S3_NLP}yelp_review_polarity_csv\'\n\n    # Image localization datasets\n    BIWI_HEAD_POSE     = f""{S3_IMAGELOC}biwi_head_pose""\n    CAMVID             = f\'{S3_IMAGELOC}camvid\'\n    CAMVID_TINY        = f\'{URL}camvid_tiny\'\n    LSUN_BEDROOMS      = f\'{S3_IMAGE}bedroom\'\n    PASCAL_2007        = f\'{S3_IMAGELOC}pascal_2007\'\n    PASCAL_2012        = f\'{S3_IMAGELOC}pascal_2012\'\n    SKIN_LESION        = f\'{S3_IMAGELOC}skin-lesion\'\n\n    #Pretrained models\n    OPENAI_TRANSFORMER = f\'{S3_MODEL}transformer\'\n    WT103_FWD          = f\'{S3_MODEL}wt103-fwd\'\n    WT103_BWD          = f\'{S3_MODEL}wt103-bwd\'\n\n# to create/update a checksum for ./mnist_var_size_tiny.tgz, run:\n# python -c \'import fastai.datasets; print(fastai.datasets._check_file(""mnist_var_size_tiny.tgz""))\'\n_checks = {\n    URLs.ADULT_SAMPLE:(968212, \'64eb9d7e23732de0b138f7372d15492f\'),\n    URLs.AG_NEWS:(11784419, \'b86f328f4dbd072486591cb7a5644dcd\'),\n    URLs.AMAZON_REVIEWS_POLARITY:(688339454, \'676f7e5208ec343c8274b4bb085bc938\'),\n    URLs.AMAZON_REVIEWS:(643695014, \'4a1196cf0adaea22f4bc3f592cddde90\'),\n    URLs.BIWI_HEAD_POSE:(452316199, \'00f4ccf66e8cba184bc292fdc08fb237\'),\n    URLs.BIWI_SAMPLE:(593774, \'9179f4c1435f4b291f0d5b072d60c2c9\'),\n    URLs.CALTECH_101:(131740031, \'d673425306e98ee4619fcdeef8a0e876\'),\n    URLs.CAMVID:(598913237, \'648371e4f3a833682afb39b08a3ce2aa\'),\n    URLs.CAMVID_TINY:(2314212, \'2cf6daf91b7a2083ecfa3e9968e9d915\'),\n    URLs.CARS:(1957803273, \'9045d6673c9ced0889f41816f6bf2f9f\'),\n    URLs.CIFAR:(168168549, \'a5f8c31371b63a406b23368042812d3c\'),\n    URLs.CIFAR_100:(169168619, \'e5e65dcb54b9d3913f7b8a9ad6607e62\'),\n    URLs.COCO_SAMPLE:(3245877008, \'006cd55d633d94b36ecaf661467830ec\'),\n    URLs.COCO_TINY:(801038, \'367467451ac4fba79a647753c2c66d3a\'),\n    URLs.CUB_200_2011:(1150585339, \'d2acaa99439dff0483c7bbac1bfe2a92\'),\n    URLs.DBPEDIA:(68341743, \'239c7837b9e79db34486f3de6a00e38e\'),\n    URLs.DOGS:(839285364, \'3e483c8d6ef2175e9d395a6027eb92b7\'),\n    URLs.FLOWERS:(345236087, \'5666e01c1311b4c67fcf20d2b3850a88\'),\n    URLs.FOOD:(5686607260, \'1a540ebf1fb40b2bf3f2294234ba7907\'),\n    URLs.HUMAN_NUMBERS:(30252, \'8a19c3bfa2bcb08cd787e741261f3ea2\'),\n    URLs.IMDB:(144440600, \'90f9b1c4ff43a90d67553c9240dc0249\'),\n    URLs.IMDB_SAMPLE:(571827, \'0842e61a9867caa2e6fbdb14fa703d61\'),\n    URLs.LSUN_BEDROOMS:(4579163978, \'35d84f38f8a15fe47e66e460c8800d68\'),\n    URLs.ML_SAMPLE:(51790, \'10961384dfe7c5181460390a460c1f77\'),\n    URLs.MNIST:(15683414, \'03639f83c4e3d19e0a3a53a8a997c487\'),\n    URLs.MNIST_SAMPLE:(3214948, \'2dbc7ec6f9259b583af0072c55816a88\'),\n    URLs.MNIST_TINY:(342207, \'56143e8f24db90d925d82a5a74141875\'),\n    URLs.MNIST_VAR_SIZE_TINY:(565372, \'b71a930f4eb744a4a143a6c7ff7ed67f\'),\n    URLs.MT_ENG_FRA:(2598183296, \'69573f58e2c850b90f2f954077041d8c\'),\n    URLs.OPENAI_TRANSFORMER:(432848315, \'024b0d2203ebb0cd1fc64b27cf8af18e\'),\n    URLs.PASCAL_2007:(1637796771, \'433b4706eb7c42bd74e7f784e3fdf244\'),\n    URLs.PASCAL_2012:(2618908000, \'d90e29e54a4c76c0c6fba8355dcbaca5\'),\n    URLs.PETS:(811706944, \'e4db5c768afd933bb91f5f594d7417a4\'),\n    URLs.PLANET_SAMPLE:(15523994, \'8bfb174b3162f07fbde09b54555bdb00\'),\n    URLs.PLANET_TINY:(997569, \'490873c5683454d4b2611fb1f00a68a9\'),\n    URLs.SKIN_LESION:(6601110169, \'3324b8993d541bea49df798a64fe41a3\'),\n    URLs.SOGOU_NEWS:(384269937, \'950f1366d33be52f5b944f8a8b680902\'),\n    URLs.WIKITEXT:(190200704, \'2dd8cf8693b3d27e9c8f0a7df054b2c7\'),\n    URLs.WIKITEXT_TINY:(4070055, \'2a82d47a7b85c8b6a8e068dc4c1d37e7\'),\n    URLs.WT103_FWD:(105067061, \'7d1114cd9684bf9d1ca3c9f6a54da6f9\'),\n    URLs.WT103_BWD:(105205312, \'20b06f5830fd5a891d21044c28d3097f\'),\n    URLs.YAHOO_ANSWERS:(319476345, \'0632a0d236ef3a529c0fa4429b339f68\'),\n    URLs.YELP_REVIEWS_POLARITY:(166373201, \'48c8451c1ad30472334d856b5d294807\'),\n    URLs.YELP_REVIEWS:(196146755, \'1efd84215ea3e30d90e4c33764b889db\'),\n}\n\n#TODO: This can probably be coded more shortly and nicely.\nclass Config():\n    ""Creates a default config file \'config.yml\' in $FASTAI_HOME (default `~/.fastai/`)""\n    DEFAULT_CONFIG_LOCATION = os.path.expanduser(os.getenv(\'FASTAI_HOME\', \'~/.fastai\'))\n    DEFAULT_CONFIG_PATH = DEFAULT_CONFIG_LOCATION + \'/config.yml\'\n    DEFAULT_CONFIG = {\n        \'data_path\': DEFAULT_CONFIG_LOCATION + \'/data\',\n        \'data_archive_path\': DEFAULT_CONFIG_LOCATION + \'/data\',\n        \'model_path\': DEFAULT_CONFIG_LOCATION + \'/models\'\n    }\n\n    @classmethod\n    def get_key(cls, key):\n        ""Get the path to `key` in the config file.""\n        return cls.get().get(key, cls.DEFAULT_CONFIG.get(key,None))\n\n    @classmethod\n    def get_path(cls, path):\n        ""Get the `path` in the config file.""\n        return _expand_path(cls.get_key(path))\n\n    @classmethod\n    def data_path(cls):\n        ""Get the path to data in the config file.""\n        return cls.get_path(\'data_path\')\n\n    @classmethod\n    def data_archive_path(cls):\n        ""Get the path to data archives in the config file.""\n        return cls.get_path(\'data_archive_path\')\n\n    @classmethod\n    def model_path(cls):\n        ""Get the path to fastai pretrained models in the config file.""\n        return cls.get_path(\'model_path\')\n\n    @classmethod\n    def get(cls, fpath=None, create_missing=True):\n        ""Retrieve the `Config` in `fpath`.""\n        fpath = _expand_path(fpath or cls.DEFAULT_CONFIG_PATH)\n        if not fpath.exists() and create_missing: cls.create(fpath)\n        assert fpath.exists(), f\'Could not find config at: {fpath}. Please create\'\n        with open(fpath, \'r\') as yaml_file: return yaml.safe_load(yaml_file)\n\n    @classmethod\n    def create(cls, fpath):\n        ""Creates a `Config` from `fpath`.""\n        fpath = _expand_path(fpath)\n        assert(fpath.suffix == \'.yml\')\n        if fpath.exists(): return\n        fpath.parent.mkdir(parents=True, exist_ok=True)\n        with open(fpath, \'w\') as yaml_file:\n            yaml.dump(cls.DEFAULT_CONFIG, yaml_file, default_flow_style=False)\n\ndef _expand_path(fpath): return Path(fpath).expanduser()\ndef url2name(url): return url.split(\'/\')[-1]\n\n#TODO: simplify this mess\ndef url2path(url, data=True, ext:str=\'.tgz\'):\n    ""Change `url` to a path.""\n    name = url2name(url)\n    return datapath4file(name, ext=ext, archive=False) if data else modelpath4file(name, ext=ext)\n\ndef _url2tgz(url, data=True, ext:str=\'.tgz\'):\n    return datapath4file(f\'{url2name(url)}{ext}\', ext=ext) if data else modelpath4file(f\'{url2name(url)}{ext}\', ext=ext)\n\ndef modelpath4file(filename:str, ext:str=\'.tgz\'):\n    ""Return model path to `filename`, checking locally first then in the config file.""\n    local_path = URLs.LOCAL_PATH/\'models\'/filename\n    if local_path.exists() or local_path.with_suffix(ext).exists(): return local_path\n    else: return Config.model_path()/filename\n\ndef datapath4file(filename:str, ext:str=\'.tgz\', archive=True):\n    ""Return data path to `filename`, checking locally first then in the config file.""\n    local_path = URLs.LOCAL_PATH/\'data\'/filename\n    if local_path.exists() or local_path.with_suffix(ext).exists(): return local_path\n    elif archive: return Config.data_archive_path() / filename\n    else: return Config.data_path() / filename\n\ndef download_data(url:str, fname:PathOrStr=None, data:bool=True, ext:str=\'.tgz\') -> Path:\n    ""Download `url` to destination `fname`.""\n    fname = Path(ifnone(fname, _url2tgz(url, data, ext=ext)))\n    os.makedirs(fname.parent, exist_ok=True)\n    if not fname.exists():\n        print(f\'Downloading {url}{ext}\')\n        download_url(f\'{url}{ext}\', fname)\n    return fname\n\ndef _check_file(fname):\n    size = os.path.getsize(fname)\n    with open(fname, ""rb"") as f:\n        hash_nb = hashlib.md5(f.read(2**20)).hexdigest()\n    return size,hash_nb\n\ndef untar_data(url:str, fname:PathOrStr=None, dest:PathOrStr=None, data=True, force_download=False, verbose=False) -> Path:\n    ""Download `url` to `fname` if `dest` doesn\'t exist, and un-tgz to folder `dest`.""\n    dest = url2path(url, data) if dest is None else Path(dest)/url2name(url)\n    fname = Path(ifnone(fname, _url2tgz(url, data)))\n    if force_download or (fname.exists() and url in _checks and _check_file(fname) != _checks[url]):\n        print(f""A new version of the {\'dataset\' if data else \'model\'} is available."")\n        if fname.exists(): os.remove(fname)\n        if dest.exists(): shutil.rmtree(dest)\n    if not dest.exists():\n        fname = download_data(url, fname=fname, data=data)\n        if url in _checks:\n            assert _check_file(fname) == _checks[url], f""Downloaded file {fname} does not match checksum expected! Remove that file from {Config().data_archive_path()} and try your code again.""\n        if verbose: print(\'.tgz file downloaded. Extracting the contents...\')\n        tarfile.open(fname, \'r:gz\').extractall(dest.parent)\n        if verbose: print(\'File extracted successfully.\')\n    return dest\n'"
fastai/distributed.py,8,"b'from .torch_core import *\nfrom .basic_train import Learner,LearnerCallback\nfrom torch.nn.parallel import DistributedDataParallel, DataParallel\nfrom torch.utils.data.distributed import DistributedSampler\n\nfrom fastai.text import TextLMDataBunch, TextClasDataBunch\n\n__all__ = [\'DistributedRecorder\', \'DistributedTrainer\', \'read_metrics\', \'setup_distrib\']\n\ndef rnn_reset(self):\n    if hasattr(self.module, \'reset\'): self.module.reset()\nDistributedDataParallel.reset = rnn_reset\n\nclass ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs): self.learn.model = DataParallel(self.learn.model)\n    def on_train_end  (self, **kwargs): self.learn.model = self.learn.model.module\n\nclass DistributedTrainer(LearnerCallback):\n    _order = -20 # Needs to run before the recorder\n    def __init__(self, learn:Learner, cuda_id:int=0):\n        super().__init__(learn)\n        self.cuda_id,self.train_sampler = cuda_id,None\n\n    def _change_dl(self, dl, shuffle):\n        old_dl = dl\n        sampler = OurDistributedSampler(dl.dataset, shuffle=shuffle)\n        new_dl = dl.new(shuffle=False, sampler=sampler)\n        return old_dl,new_dl,sampler\n\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DistributedDataParallel(self.model, device_ids=[self.cuda_id], output_device=self.cuda_id)\n        shuffle = self.data.train_dl.init_kwargs[\'shuffle\'] if hasattr(self.data.train_dl, \'init_kwargs\') else True\n        shuffle_train = True if isinstance(self.data, TextClasDataBunch) else shuffle\n        self.old_train_dl,self.data.train_dl,self.train_sampler = self._change_dl(self.data.train_dl, shuffle_train)\n        if hasattr(self.data, \'valid_dl\') and self.data.valid_dl is not None:\n            self.old_valid_dl,self.data.valid_dl,self.valid_sampler = self._change_dl(self.data.valid_dl, shuffle)\n        self.rank = rank_distrib()\n        self.recorder.silent = (self.rank != 0)\n\n    def on_epoch_begin(self, epoch, **kwargs): self.train_sampler.set_epoch(epoch)\n\n    def on_train_end(self, **kwargs):\n        self.learn.model = self.learn.model.module\n        self.learn.data.train_dl = self.old_train_dl\n        if hasattr(self.learn.data, \'valid_dl\') and self.learn.data.valid_dl is not None:\n            self.learn.data.valid_dl = self.old_valid_dl\n\nclass DistributedRecorder(LearnerCallback):\n    def __init__(self, learn:Learner, cuda_id:int=0, cache_dir:PathOrStr=\'tmp\'):\n        super().__init__(learn)\n        self.cuda_id,self.cache_dir = cuda_id,cache_dir\n\n    def on_train_begin(self, **kwargs):\n        os.makedirs(self.learn.path/self.cache_dir, exist_ok=True)\n\n    def on_epoch_end(self, **kwargs): self.save_stats()\n    def on_train_end(self, **kwargs): self.save_stats()\n\n    def save_stats(self):\n        cache_path,recorder = self.learn.path/self.cache_dir,self.learn.recorder\n        np.save(cache_path/f\'losses_{self.cuda_id}\', np.array(recorder.losses))\n        stats = np.array([[v] + m for v,m in zip(recorder.val_losses,recorder.metrics)])\n        np.save(cache_path/f\'metrics_{self.cuda_id}\', stats)\n\ndef _learner_parallel(learn:Learner):\n    ""Use nn.DataParallel when training and remove when done""\n    if not torch.cuda.is_available(): warnings.warn(\'CUDA is not available, check your drivers - training will continue on CPU\', ResourceWarning) \n    learn.callbacks.append(ParallelTrainer(learn))\n    return learn\n\ndef _learner_distributed(learn:Learner, cuda_id:int, cache_dir:PathOrStr=\'tmp\'):\n    ""Put `learn` on distributed training with `cuda_id`.""\n    learn.callbacks.append(DistributedTrainer(learn, cuda_id))\n    learn.callbacks.append(DistributedRecorder(learn, cuda_id, cache_dir))\n    return learn\n\nLearner.to_distributed = _learner_distributed\nLearner.to_parallel = _learner_parallel\n\ndef read_metrics(cache_path:PathOrStr, n_gpus:int, reduce:bool=True):\n    losses,metrics = [],[]\n    for i in range(n_gpus):\n        losses.append(np.load(cache_path/f\'losses_{i}.npy\')[None])\n        metrics.append(np.load(cache_path/f\'metrics_{i}.npy\')[None])\n    if reduce:\n        losses,metrics = np.concatenate(losses,0),np.concatenate(metrics,0)\n        return losses.mean(0),metrics.mean(0)\n    return losses,metrics\n\ndef setup_distrib(gpu:Any=None):\n    if gpu is None: return gpu\n    gpu = int(gpu)\n    torch.cuda.set_device(int(gpu))\n    if num_distrib() > 1:\n        torch.distributed.init_process_group(backend=\'nccl\', init_method=\'env://\')\n    return gpu\n\nclass OurDistributedSampler(DistributedSampler):\n    ""A sampler for language models with the option to not shuffle.""\n    def __init__(self, dataset, num_replicas=None, rank=None, shuffle=True):\n            super().__init__(dataset, num_replicas=num_replicas, rank=rank)\n            self.shuffle = shuffle\n    \n    def __iter__(self):\n        if self.shuffle:\n            g = torch.Generator()\n            g.manual_seed(self.epoch)\n            indices = torch.randperm(len(self.dataset), generator=g).tolist()\n        else: indices = torch.arange(len(self.dataset)).tolist()\n\n        # add extra samples to make it evenly divisible\n        indices += indices[:(self.total_size - len(indices))]\n        assert len(indices) == self.total_size\n\n        # subsample\n        indices = indices[self.rank:self.total_size:self.num_replicas]\n        assert len(indices) == self.num_samples\n\n        return iter(indices)\n'"
fastai/general_optimizer.py,3,"b'from .torch_core import *\nfrom torch.optim import Optimizer\nimport types\n\n__all__ = [\'StatScope\', \'Statistic\', \'ConstStatistic\', \'AvgStatistic\', \'AvgSquare\', \'GeneralOptimizer\']\n\nStatScope = Enum(\'StatScope\', \'Global Group Layer Channel Weight\')\n\n@dataclass\nclass Statistic():\n    name:str\n    param:float=0.9  # e.g. for exp moving average\n    scope:StatScope=StatScope.Weight\n    init:float=0.  # starting value\n\n    @property\n    def buf(self): return f\'{self.name}_buffer\'\n\n    def new_step(self):\n        ""Set state when computing statistics for Global or Group""\n        raise NotImplementedError\n\n    def accumulate(self, val):\n        ""Add `val` to statistic""\n        raise NotImplementedError\n\n    def update(self, state, param, val=None, step=None):\n        ""Update state with accumlated, or `val` (if `Weight` or `Layer` scope)""\n        raise NotImplementedError\n\nclass ConstStatistic(Statistic):\n    @property\n    def buf(self): return None\n    def new_step(self):   pass\n    def accumulate(self): pass\n    def update(self, state, param, val=None, step=None): return param\n\n@dataclass\nclass CounterStat(Statistic):\n    def __post_init__(self): self.init,self._buf,self.name = 0,self.name,None\n    @property\n    def buf(self): return self._buf\n    def new_step(self): pass\n    def accumulate(self, val): pass\n    def update(self, state, param, val=None, step=None): return state + 1\n\n@dataclass\nclass AvgStatistic(Statistic):\n    decay:bool=False\n    debias:bool=False\n    def new_step(self): self.val,self.count = 0.,0\n\n    def accumulate(self, val):\n        self.count += 1\n        self.val += self._get_val1(val)\n\n    def _get_val1(self, val): return val.mean()\n    def _get_val2(self, state, val, param): return state.add_(1-param, val) if self.decay else state.add_(val)\n    def _get_val3(self, state, val, param): \n        v = val.view(val.size(0), -1).mean(1)\n        return state.add_(1-param, v) if self.decay else state.add_(v)\n\n    def update(self, state, param, val=None, step=None):\n        if self.scope == StatScope.Weight:\n            # `state` is a tensor\n            res = self._get_val2(state.mul_(param), val, param)\n        elif self.scope == StatScope.Channel:\n            # `state` is a tensor of size n_channels\n            res = self._get_val3(state.mul_(param), val, param)\n        # For everything else, `state` is a scalar\n        elif self.scope == StatScope.Layer:  res = state*param + self._get_val1(val) * (1-param if self.decay else 1.)\n        elif self.count != 0:                res = state*param + self.val/self.count * (1-param if self.decay else 1.)\n        else: return state\n        if self.debias and step is not None: res /= (1 - param ** step)\n        return res\n\nclass AvgSquare(AvgStatistic):\n\n    def __init__(self, name:str, param:float=0.9, scope=StatScope.Weight, init:float=0., decay:bool=True, debias:bool=False):\n        super().__init__(name, param=param, scope=scope, init=init, decay=decay, debias=debias)\n\n    def _get_val1(self, val): return torch.norm(val).pow(2)/val.numel()\n    def _get_val2(self, state, val, param): \n        return state.addcmul_(1-param, val, val) if self.decay else state.addcmul_(val, val)\n    def _get_val3(self, state, val, param):\n        v = val.view(val.size(0), -1).mean(1)\n        return state.addcmul_(1-param, v, v) if self.decay else state.addcmul_(v, v)\n\nclass GeneralOptimizer(Optimizer):\n    def __init__(self, params, stats=None, on_step:Callable=None):\n        defaults = {s.name:s.param for s in listify(stats) if s.name is not None}\n        super().__init__(params, defaults)\n        self.global_stats,self.group_stats,self.layer_stats,self.channel_stats,self.weight_stats = self._split_stats(stats)\n        self.init_stats()\n        if on_step is not None: self.on_step = types.MethodType(on_step, self)\n\n    def step(self, closure=None):\n        self.update_stats()\n        for i,pg in enumerate(self.param_groups):\n            for p in pg[\'params\']:\n                if p.grad is not None: self.on_step(p, pg, i)\n\n    def on_step(self, p, group, group_idx): p.data.add_(-group[\'lr\'], p.grad.data)\n\n    def _split_stats(self, stats):\n        splits = [[stat for stat in listify(stats) if stat.scope==scope] for scope in StatScope]\n        for split,s in zip([splits[0], splits[1], splits[2]+splits[3]+splits[4]], StatScope):\n            if np.any([getattr(s, \'debias\', False) for s in split]): split.insert(0, CounterStat(\'step\', scope=s))\n        return splits\n\n    def _init_stats(self, stats, data=None):\n        return {stat.buf: stat.init if data is None\n                else torch.zeros_like(data) + stat.init for stat in stats if stat.buf is not None}\n\n    def init_stats(self):\n        self.state[\'global\'] = self._init_stats(self.global_stats)\n        for i,pg in enumerate(self.param_groups):\n            self.state[f\'group{i}\'] = self._init_stats(self.group_stats)\n            for p in pg[\'params\']:\n                self.state[p] = self._init_stats(self.layer_stats)\n                self.state[p].update(self._init_stats(self.channel_stats, p.data.view(p.data.size(0), -1).mean(1)))\n                self.state[p].update(self._init_stats(self.weight_stats, p.data))\n\n    def _set_bufs(self, p, stats, pg, val=None):\n        d = self.state[p]\n        for stat in stats:\n            if stat.buf is not None: d[stat.buf] = stat.update(d[stat.buf], pg[stat.name], val=val, step=d.get(\'step\', None))\n\n    def update_stats(self):\n        for stat in self.global_stats: stat.new_step()\n        for i,pg in enumerate(self.param_groups):\n            for stat in self.group_stats: stat.new_step()\n            for p in pg[\'params\']:\n                if p.grad is not None:\n                    for stat in self.global_stats + self.group_stats: stat.accumulate(p.grad.data)\n                    self._set_bufs(p, self.layer_stats+self.channel_stats+self.weight_stats, pg, p.grad.data)\n            self._set_bufs(f\'group{i}\', self.group_stats, pg)\n        self._set_bufs(\'global\', self.global_stats, self.param_groups[0])\n\n'"
fastai/launch.py,2,"b'import subprocess, torch\nfrom fastai.script import *\n\n@call_parse\ndef main(\n    gpus:Param(""The GPUs to use for distributed training"", str)=\'all\',\n    script:Param(""Script to run"", str, opt=False)=\'\',\n    args:Param(""Args to pass to script"", nargs=\'...\', opt=False)=\'\'\n):\n    ""PyTorch distributed training launch helper that spawns multiple distributed processes""\n    # Loosely based on torch.distributed.launch\n    current_env = os.environ.copy()\n    gpus = list(range(torch.cuda.device_count())) if gpus==\'all\' else list(gpus)\n    current_env[""WORLD_SIZE""] = str(len(gpus))\n    current_env[""MASTER_ADDR""] = \'127.0.0.1\'\n    current_env[""MASTER_PORT""] = \'29500\'\n\n    processes = []\n    for i,gpu in enumerate(gpus):\n        current_env[""RANK""] = str(i)\n        cmd = [sys.executable, ""-u"", script, f""--gpu={gpu}""] + args\n        process = subprocess.Popen(cmd, env=current_env)\n        processes.append(process)\n\n    for process in processes: process.wait()\n\n'"
fastai/layers.py,11,"b'""`fastai.layers` provides essential functions to building and modifying `model` architectures""\nfrom .torch_core import *\n\n__all__ = [\'AdaptiveConcatPool2d\', \'BCEWithLogitsFlat\', \'BCEFlat\', \'MSELossFlat\', \'CrossEntropyFlat\', \'Debugger\',\n           \'Flatten\', \'Lambda\', \'PoolFlatten\', \'View\', \'ResizeBatch\', \'bn_drop_lin\', \'conv2d\', \'conv2d_trans\', \'conv_layer\',\n           \'embedding\', \'simple_cnn\', \'NormType\', \'relu\', \'batchnorm_2d\', \'trunc_normal_\', \'PixelShuffle_ICNR\', \'icnr\',\n           \'NoopLoss\', \'WassersteinLoss\', \'SelfAttention\', \'SequentialEx\', \'MergeLayer\', \'res_block\', \'sigmoid_range\',\n           \'SigmoidRange\', \'PartialLayer\', \'FlattenedLoss\', \'BatchNorm1dFlat\', \'LabelSmoothingCrossEntropy\', \'PooledSelfAttention2d\']\n\nclass Lambda(Module):\n    ""Create a layer that simply calls `func` with `x`""\n    def __init__(self, func:LambdaFunc): self.func=func\n    def forward(self, x): return self.func(x)\n\nclass View(Module):\n    ""Reshape `x` to `size`""\n    def __init__(self, *size:int): self.size = size\n    def forward(self, x): return x.view(self.size)\n\nclass ResizeBatch(Module):\n    ""Reshape `x` to `size`, keeping batch dim the same size""\n    def __init__(self, *size:int): self.size = size\n    def forward(self, x): return x.view((x.size(0),) + self.size)\n\nclass Flatten(Module):\n    ""Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor""\n    def __init__(self, full:bool=False): self.full = full\n    def forward(self, x): return x.view(-1) if self.full else x.view(x.size(0), -1)\n\ndef PoolFlatten()->nn.Sequential:\n    ""Apply `nn.AdaptiveAvgPool2d` to `x` and then flatten the result.""\n    return nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten())\n\nNormType = Enum(\'NormType\', \'Batch BatchZero Weight Spectral\')\n\ndef batchnorm_2d(nf:int, norm_type:NormType=NormType.Batch):\n    ""A batchnorm2d layer with `nf` features initialized depending on `norm_type`.""\n    bn = nn.BatchNorm2d(nf)\n    with torch.no_grad():\n        bn.bias.fill_(1e-3)\n        bn.weight.fill_(0. if norm_type==NormType.BatchZero else 1.)\n    return bn\n\ndef bn_drop_lin(n_in:int, n_out:int, bn:bool=True, p:float=0., actn:Optional[nn.Module]=None):\n    ""Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn`.""\n    layers = [nn.BatchNorm1d(n_in)] if bn else []\n    if p != 0: layers.append(nn.Dropout(p))\n    layers.append(nn.Linear(n_in, n_out))\n    if actn is not None: layers.append(actn)\n    return layers\n\ndef conv1d(ni:int, no:int, ks:int=1, stride:int=1, padding:int=0, bias:bool=False):\n    ""Create and initialize a `nn.Conv1d` layer with spectral normalization.""\n    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n    nn.init.kaiming_normal_(conv.weight)\n    if bias: conv.bias.data.zero_()\n    return spectral_norm(conv)\n\nclass PooledSelfAttention2d(Module):\n    ""Pooled self attention layer for 2d.""\n    def __init__(self, n_channels:int):\n        self.n_channels = n_channels\n        self.theta = spectral_norm(conv2d(n_channels, n_channels//8, 1)) # query\n        self.phi   = spectral_norm(conv2d(n_channels, n_channels//8, 1)) # key\n        self.g     = spectral_norm(conv2d(n_channels, n_channels//2, 1)) # value\n        self.o     = spectral_norm(conv2d(n_channels//2, n_channels, 1))\n        self.gamma = nn.Parameter(tensor([0.]))\n\n    def forward(self, x):\n        # code borrowed from https://github.com/ajbrock/BigGAN-PyTorch/blob/7b65e82d058bfe035fc4e299f322a1f83993e04c/layers.py#L156\n        theta = self.theta(x)\n        phi = F.max_pool2d(self.phi(x), [2,2])\n        g = F.max_pool2d(self.g(x), [2,2])    \n        theta = theta.view(-1, self.n_channels // 8, x.shape[2] * x.shape[3])\n        phi = phi.view(-1, self.n_channels // 8, x.shape[2] * x.shape[3] // 4)\n        g = g.view(-1, self.n_channels // 2, x.shape[2] * x.shape[3] // 4)\n        beta = F.softmax(torch.bmm(theta.transpose(1, 2), phi), -1)\n        o = self.o(torch.bmm(g, beta.transpose(1,2)).view(-1, self.n_channels // 2, x.shape[2], x.shape[3]))\n        return self.gamma * o + x\n\nclass SelfAttention(Module):\n    ""Self attention layer for nd.""\n    def __init__(self, n_channels:int):\n        self.query = conv1d(n_channels, n_channels//8)\n        self.key   = conv1d(n_channels, n_channels//8)\n        self.value = conv1d(n_channels, n_channels)\n        self.gamma = nn.Parameter(tensor([0.]))\n\n    def forward(self, x):\n        #Notation from https://arxiv.org/pdf/1805.08318.pdf\n        size = x.size()\n        x = x.view(*size[:2],-1)\n        f,g,h = self.query(x),self.key(x),self.value(x)\n        beta = F.softmax(torch.bmm(f.permute(0,2,1).contiguous(), g), dim=1)\n        o = self.gamma * torch.bmm(h, beta) + x\n        return o.view(*size).contiguous()\n\ndef conv2d(ni:int, nf:int, ks:int=3, stride:int=1, padding:int=None, bias=False, init:LayerFunc=nn.init.kaiming_normal_) -> nn.Conv2d:\n    ""Create and initialize `nn.Conv2d` layer. `padding` defaults to `ks//2`.""\n    if padding is None: padding = ks//2\n    return init_default(nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=padding, bias=bias), init)\n\ndef conv2d_trans(ni:int, nf:int, ks:int=2, stride:int=2, padding:int=0, bias=False) -> nn.ConvTranspose2d:\n    ""Create `nn.ConvTranspose2d` layer.""\n    return nn.ConvTranspose2d(ni, nf, kernel_size=ks, stride=stride, padding=padding, bias=bias)\n\ndef relu(inplace:bool=False, leaky:float=None):\n    ""Return a relu activation, maybe `leaky` and `inplace`.""\n    return nn.LeakyReLU(inplace=inplace, negative_slope=leaky) if leaky is not None else nn.ReLU(inplace=inplace)\n\ndef conv_layer(ni:int, nf:int, ks:int=3, stride:int=1, padding:int=None, bias:bool=None, is_1d:bool=False,\n               norm_type:Optional[NormType]=NormType.Batch,  use_activ:bool=True, leaky:float=None,\n               transpose:bool=False, init:Callable=nn.init.kaiming_normal_, self_attention:bool=False):\n    ""Create a sequence of convolutional (`ni` to `nf`), ReLU (if `use_activ`) and batchnorm (if `bn`) layers.""\n    if padding is None: padding = (ks-1)//2 if not transpose else 0\n    bn = norm_type in (NormType.Batch, NormType.BatchZero)\n    if bias is None: bias = not bn\n    conv_func = nn.ConvTranspose2d if transpose else nn.Conv1d if is_1d else nn.Conv2d\n    conv = init_default(conv_func(ni, nf, kernel_size=ks, bias=bias, stride=stride, padding=padding), init)\n    if   norm_type==NormType.Weight:   conv = weight_norm(conv)\n    elif norm_type==NormType.Spectral: conv = spectral_norm(conv)\n    layers = [conv]\n    if use_activ: layers.append(relu(True, leaky=leaky))\n    if bn: layers.append((nn.BatchNorm1d if is_1d else nn.BatchNorm2d)(nf))\n    if self_attention: layers.append(SelfAttention(nf))\n    return nn.Sequential(*layers)\n\nclass SequentialEx(Module):\n    ""Like `nn.Sequential`, but with ModuleList semantics, and can access module input""\n    def __init__(self, *layers): self.layers = nn.ModuleList(layers)\n\n    def forward(self, x):\n        res = x\n        for l in self.layers:\n            res.orig = x\n            nres = l(res)\n            # We have to remove res.orig to avoid hanging refs and therefore memory leaks\n            res.orig = None\n            res = nres\n        return res\n\n    def __getitem__(self,i): return self.layers[i]\n    def append(self,l): return self.layers.append(l)\n    def extend(self,l): return self.layers.extend(l)\n    def insert(self,i,l): return self.layers.insert(i,l)\n\nclass MergeLayer(Module):\n    ""Merge a shortcut with the result of the module by adding them or concatenating them if `dense=True`.""\n    def __init__(self, dense:bool=False): self.dense=dense\n    def forward(self, x): return torch.cat([x,x.orig], dim=1) if self.dense else (x+x.orig)\n\ndef res_block(nf, dense:bool=False, norm_type:Optional[NormType]=NormType.Batch, bottle:bool=False, **conv_kwargs):\n    ""Resnet block of `nf` features. `conv_kwargs` are passed to `conv_layer`.""\n    norm2 = norm_type\n    if not dense and (norm_type==NormType.Batch): norm2 = NormType.BatchZero\n    nf_inner = nf//2 if bottle else nf\n    return SequentialEx(conv_layer(nf, nf_inner, norm_type=norm_type, **conv_kwargs),\n                      conv_layer(nf_inner, nf, norm_type=norm2, **conv_kwargs),\n                      MergeLayer(dense))\n\ndef sigmoid_range(x, low, high):\n    ""Sigmoid function with range `(low, high)`""\n    return torch.sigmoid(x) * (high - low) + low\n\nclass SigmoidRange(Module):\n    ""Sigmoid module with range `(low,x_max)`""\n    def __init__(self, low, high): self.low,self.high = low,high\n    def forward(self, x): return sigmoid_range(x, self.low, self.high)\n\nclass PartialLayer(Module):\n    ""Layer that applies `partial(func, **kwargs)`.""\n    def __init__(self, func, **kwargs): self.repr,self.func = f\'{func}({kwargs})\', partial(func, **kwargs)\n    def forward(self, x): return self.func(x)\n    def __repr__(self): return self.repr\n\nclass AdaptiveConcatPool2d(Module):\n    ""Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.""\n    def __init__(self, sz:Optional[int]=None):\n        ""Output will be 2*sz or 2 if sz is None""\n        self.output_size = sz or 1\n        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n\n    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n\nclass Debugger(Module):\n    ""A module to debug inside a model.""\n    def forward(self,x:Tensor) -> Tensor:\n        set_trace()\n        return x\n\ndef icnr(x, scale=2, init=nn.init.kaiming_normal_):\n    ""ICNR init of `x`, with `scale` and `init` function.""\n    ni,nf,h,w = x.shape\n    ni2 = int(ni/(scale**2))\n    k = init(torch.zeros([ni2,nf,h,w])).transpose(0, 1)\n    k = k.contiguous().view(ni2, nf, -1)\n    k = k.repeat(1, 1, scale**2)\n    k = k.contiguous().view([nf,ni,h,w]).transpose(0, 1)\n    x.data.copy_(k)\n\nclass PixelShuffle_ICNR(Module):\n    ""Upsample by `scale` from `ni` filters to `nf` (default `ni`), using `nn.PixelShuffle`, `icnr` init, and `weight_norm`.""\n    def __init__(self, ni:int, nf:int=None, scale:int=2, blur:bool=False, norm_type=NormType.Weight, leaky:float=None):\n        nf = ifnone(nf, ni)\n        self.conv = conv_layer(ni, nf*(scale**2), ks=1, norm_type=norm_type, use_activ=False)\n        icnr(self.conv[0].weight)\n        self.shuf = nn.PixelShuffle(scale)\n        # Blurring over (h*w) kernel\n        # ""Super-Resolution using Convolutional Neural Networks without Any Checkerboard Artifacts""\n        # - https://arxiv.org/abs/1806.02658\n        self.pad = nn.ReplicationPad2d((1,0,1,0))\n        self.blur = nn.AvgPool2d(2, stride=1)\n        self.do_blur = blur\n        self.relu = relu(True, leaky=leaky)\n\n    def forward(self,x):\n        x = self.shuf(self.relu(self.conv(x)))\n        return self.blur(self.pad(x)) if self.do_blur else x\n\nclass FlattenedLoss():\n    ""Same as `func`, but flattens input and target.""\n    def __init__(self, func, *args, axis:int=-1, floatify:bool=False, is_2d:bool=True, **kwargs):\n        self.func,self.axis,self.floatify,self.is_2d = func(*args,**kwargs),axis,floatify,is_2d\n        functools.update_wrapper(self, self.func)\n\n    def __repr__(self): return f""FlattenedLoss of {self.func}""\n    @property\n    def reduction(self): return self.func.reduction\n    @reduction.setter\n    def reduction(self, v): self.func.reduction = v\n\n    @property\n    def weight(self): return self.func.weight\n    @weight.setter\n    def weight(self, v): self.func.weight = v\n\n    def __call__(self, input:Tensor, target:Tensor, **kwargs)->Rank0Tensor:\n        input = input.transpose(self.axis,-1).contiguous()\n        target = target.transpose(self.axis,-1).contiguous()\n        if self.floatify: target = target.float()\n        input = input.view(-1,input.shape[-1]) if self.is_2d else input.view(-1)\n        return self.func.__call__(input, target.view(-1), **kwargs)\n\ndef CrossEntropyFlat(*args, axis:int=-1, **kwargs):\n    ""Same as `nn.CrossEntropyLoss`, but flattens input and target.""\n    return FlattenedLoss(nn.CrossEntropyLoss, *args, axis=axis, **kwargs)\n\ndef BCEWithLogitsFlat(*args, axis:int=-1, floatify:bool=True, **kwargs):\n    ""Same as `nn.BCEWithLogitsLoss`, but flattens input and target.""\n    return FlattenedLoss(nn.BCEWithLogitsLoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs)\n\ndef BCEFlat(*args, axis:int=-1, floatify:bool=True, **kwargs):\n    ""Same as `nn.BCELoss`, but flattens input and target.""\n    return FlattenedLoss(nn.BCELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs)\n\ndef MSELossFlat(*args, axis:int=-1, floatify:bool=True, **kwargs):\n    ""Same as `nn.MSELoss`, but flattens input and target.""\n    return FlattenedLoss(nn.MSELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs)\n\nclass NoopLoss(Module):\n    ""Just returns the mean of the `output`.""\n    def forward(self, output, *args): return output.mean()\n\nclass WassersteinLoss(Module):\n    ""For WGAN.""\n    def forward(self, real, fake): return real.mean() - fake.mean()\n\ndef simple_cnn(actns:Collection[int], kernel_szs:Collection[int]=None,\n               strides:Collection[int]=None, bn=False) -> nn.Sequential:\n    ""CNN with `conv_layer` defined by `actns`, `kernel_szs` and `strides`, plus batchnorm if `bn`.""\n    nl = len(actns)-1\n    kernel_szs = ifnone(kernel_szs, [3]*nl)\n    strides    = ifnone(strides   , [2]*nl)\n    layers = [conv_layer(actns[i], actns[i+1], kernel_szs[i], stride=strides[i],\n              norm_type=(NormType.Batch if bn and i<(len(strides)-1) else None)) for i in range_of(strides)]\n    layers.append(PoolFlatten())\n    return nn.Sequential(*layers)\n\ndef trunc_normal_(x:Tensor, mean:float=0., std:float=1.) -> Tensor:\n    ""Truncated normal initialization.""\n    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n    return x.normal_().fmod_(2).mul_(std).add_(mean)\n\ndef embedding(ni:int,nf:int) -> nn.Module:\n    ""Create an embedding layer.""\n    emb = nn.Embedding(ni, nf)\n    # See https://arxiv.org/abs/1711.09160\n    with torch.no_grad(): trunc_normal_(emb.weight, std=0.01)\n    return emb\n\nclass BatchNorm1dFlat(nn.BatchNorm1d):\n    ""`nn.BatchNorm1d`, but first flattens leading dimensions""\n    def forward(self, x):\n        if x.dim()==2: return super().forward(x)\n        *f,l = x.shape\n        x = x.contiguous().view(-1,l)\n        return super().forward(x).view(*f,l)\n\nclass LabelSmoothingCrossEntropy(Module):\n    def __init__(self, eps:float=0.1, reduction=\'mean\'): self.eps,self.reduction = eps,reduction\n\n    def forward(self, output, target):\n        c = output.size()[-1]\n        log_preds = F.log_softmax(output, dim=-1)\n        if self.reduction==\'sum\': loss = -log_preds.sum()\n        else:\n            loss = -log_preds.sum(dim=-1)\n            if self.reduction==\'mean\':  loss = loss.mean()\n        return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)\n'"
fastai/metrics.py,35,"b'""Implements various metrics to measure training accuracy""\nfrom .torch_core import *\nfrom .callback import *\nfrom .layers import *\nfrom .basic_train import LearnerCallback\n\n__all__ = [\'error_rate\', \'accuracy\', \'accuracy_thresh\', \'dice\', \'exp_rmspe\', \'fbeta\',\'FBeta\', \'mse\', \'mean_squared_error\',\n            \'mae\', \'mean_absolute_error\', \'rmse\', \'root_mean_squared_error\', \'msle\', \'mean_squared_logarithmic_error\',\n            \'explained_variance\', \'r2_score\', \'top_k_accuracy\', \'KappaScore\', \'ConfusionMatrix\', \'MatthewsCorreff\',\n            \'Precision\', \'Recall\', \'R2Score\', \'ExplainedVariance\', \'ExpRMSPE\', \'RMSE\', \'Perplexity\', \'AUROC\', \'auc_roc_score\', \n            \'roc_curve\', \'MultiLabelFbeta\', \'foreground_acc\']\n\ndef fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True)->Rank0Tensor:\n    ""Computes the f_beta between `preds` and `targets`""\n    beta2 = beta ** 2\n    if sigmoid: y_pred = y_pred.sigmoid()\n    y_pred = (y_pred>thresh).float()\n    y_true = y_true.float()\n    TP = (y_pred*y_true).sum(dim=1)\n    prec = TP/(y_pred.sum(dim=1)+eps)\n    rec = TP/(y_true.sum(dim=1)+eps)\n    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n    return res.mean()\n\ndef accuracy(input:Tensor, targs:Tensor)->Rank0Tensor:\n    ""Computes accuracy with `targs` when `input` is bs * n_classes.""\n    n = targs.shape[0]\n    input = input.argmax(dim=-1).view(n,-1)\n    targs = targs.view(n,-1)\n    return (input==targs).float().mean()\n\ndef accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True)->Rank0Tensor:\n    ""Computes accuracy when `y_pred` and `y_true` are the same size.""\n    if sigmoid: y_pred = y_pred.sigmoid()\n    return ((y_pred>thresh).byte()==y_true.byte()).float().mean()\n\ndef top_k_accuracy(input:Tensor, targs:Tensor, k:int=5)->Rank0Tensor:\n    ""Computes the Top-k accuracy (target is in the top k predictions).""\n    input = input.topk(k=k, dim=-1)[1]\n    targs = targs.unsqueeze(dim=-1).expand_as(input)\n    return (input == targs).max(dim=-1)[0].float().mean()\n\ndef foreground_acc(input, target, void_code):\n    ""Computes non-background accuracy, e.g. camvid for multiclass segmentation""\n    target = target.squeeze(1)\n    mask = target != void_code\n    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()\n\ndef error_rate(input:Tensor, targs:Tensor)->Rank0Tensor:\n    ""1 - `accuracy`""\n    return 1 - accuracy(input, targs)\n\ndef dice(input:Tensor, targs:Tensor, iou:bool=False, eps:float=1e-8)->Rank0Tensor:\n    ""Dice coefficient metric for binary target. If iou=True, returns iou metric, classic for segmentation problems.""\n    n = targs.shape[0]\n    input = input.argmax(dim=1).view(n,-1)\n    targs = targs.view(n,-1)\n    intersect = (input * targs).sum(dim=1).float()\n    union = (input+targs).sum(dim=1).float()\n    if not iou: l = 2. * intersect / union\n    else: l = intersect / (union-intersect+eps)\n    l[union == 0.] = 1.\n    return l.mean()\n\ndef psnr(input:Tensor, targs:Tensor)->Rank0Tensor:\n    return 10 * (1. / mean_squared_error(input, targs)).log10()\n\ndef exp_rmspe(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    ""Exp RMSE between `pred` and `targ`.""\n    pred,targ = flatten_check(pred,targ)\n    pred, targ = torch.exp(pred), torch.exp(targ)\n    pct_var = (targ - pred)/targ\n    return torch.sqrt((pct_var**2).mean())\n\ndef mean_absolute_error(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    ""Mean absolute error between `pred` and `targ`.""\n    pred,targ = flatten_check(pred,targ)\n    return torch.abs(targ - pred).mean()\n\ndef mean_squared_error(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    ""Mean squared error between `pred` and `targ`.""\n    pred,targ = flatten_check(pred,targ)\n    return F.mse_loss(pred, targ)\n\ndef root_mean_squared_error(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    ""Root mean squared error between `pred` and `targ`.""\n    pred,targ = flatten_check(pred,targ)\n    return torch.sqrt(F.mse_loss(pred, targ))\n\ndef mean_squared_logarithmic_error(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    ""Mean squared logarithmic error between `pred` and `targ`.""\n    pred,targ = flatten_check(pred,targ)\n    return F.mse_loss(torch.log(1 + pred), torch.log(1 + targ))\n\ndef explained_variance(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    ""Explained variance between `pred` and `targ`.""\n    pred,targ = flatten_check(pred,targ)\n    var_pct = torch.var(targ - pred) / torch.var(targ)\n    return 1 - var_pct\n\ndef r2_score(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    ""R2 score (coefficient of determination) between `pred` and `targ`.""\n    pred,targ = flatten_check(pred,targ)\n    u = torch.sum((targ - pred) ** 2)\n    d = torch.sum((targ - targ.mean()) ** 2)\n    return 1 - u / d\n\nclass RegMetrics(Callback):\n    ""Stores predictions and targets to perform calculations on epoch end.""\n    def on_epoch_begin(self, **kwargs):\n        self.targs, self.preds = Tensor([]), Tensor([])\n\n    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n        assert last_output.numel() == last_target.numel(), ""Expected same numbers of elements in pred & targ""\n        self.preds = torch.cat((self.preds, last_output.cpu()))\n        self.targs = torch.cat((self.targs, last_target.cpu()))\n\nclass R2Score(RegMetrics):\n    ""Computes the R2 score (coefficient of determination).""\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, r2_score(self.preds, self.targs))\n\nclass ExplainedVariance(RegMetrics):\n    ""Computes the explained variance.""\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, explained_variance(self.preds, self.targs))\n\nclass RMSE(RegMetrics):\n    ""Computes the root mean squared error.""\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, root_mean_squared_error(self.preds, self.targs))\n\nclass ExpRMSPE(RegMetrics):\n    ""Computes the exponential of the root mean square error.""\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, exp_rmspe(self.preds, self.targs))\n\n# Aliases\nmse = mean_squared_error\nmae = mean_absolute_error\nmsle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\n\nclass ConfusionMatrix(Callback):\n    ""Computes the confusion matrix.""\n\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n\n    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n        preds = last_output.argmax(-1).view(-1).cpu()\n        targs = last_target.cpu()\n        if self.n_classes == 0:\n            self.n_classes = last_output.shape[-1]\n        if self.cm is None: self.cm = torch.zeros((self.n_classes, self.n_classes), device=torch.device(\'cpu\'))\n        cm_temp_numpy = self.cm.numpy()\n        np.add.at(cm_temp_numpy, (targs ,preds), 1)\n        self.cm = torch.from_numpy(cm_temp_numpy)\n\n    def on_epoch_end(self, **kwargs):\n        self.metric = self.cm\n\n@dataclass\nclass CMScores(ConfusionMatrix):\n    ""Base class for metrics which rely on the calculation of the precision and/or recall score.""\n    average:Optional[str]=""binary""      # `binary`, `micro`, `macro`, `weighted` or None\n    pos_label:int=1                     # 0 or 1\n    eps:float=1e-9\n\n    def _recall(self):\n        rec = torch.diag(self.cm) / self.cm.sum(dim=1)\n        if self.average is None: return rec\n        else:\n            if self.average == ""micro"": weights = self._weights(avg=""weighted"")\n            else: weights = self._weights(avg=self.average)\n            return (rec * weights).sum()\n\n    def _precision(self):\n        prec = torch.diag(self.cm) / self.cm.sum(dim=0)\n        if self.average is None: return prec\n        else:\n            weights = self._weights(avg=self.average)\n            return (prec * weights).sum()\n\n    def _weights(self, avg:str):\n        if self.n_classes != 2 and avg == ""binary"":\n            avg = self.average = ""macro""\n            warn(""average=`binary` was selected for a non binary case. Value for average has now been set to `macro` instead."")\n        if avg == ""binary"":\n            if self.pos_label not in (0, 1):\n                self.pos_label = 1\n                warn(""Invalid value for pos_label. It has now been set to 1."")\n            if self.pos_label == 1: return Tensor([0,1])\n            else: return Tensor([1,0])\n        elif avg == ""micro"": return self.cm.sum(dim=0) / self.cm.sum()\n        elif avg == ""macro"": return torch.ones((self.n_classes,)) / self.n_classes\n        elif avg == ""weighted"": return self.cm.sum(dim=1) / self.cm.sum()\n\n\nclass Recall(CMScores):\n    ""Computes the Recall.""\n    def on_epoch_end(self, last_metrics, **kwargs): \n        return add_metrics(last_metrics, self._recall())\n\nclass Precision(CMScores):\n    ""Computes the Precision.""\n    def on_epoch_end(self, last_metrics, **kwargs): \n        return add_metrics(last_metrics, self._precision())\n\n@dataclass\nclass FBeta(CMScores):\n    ""Computes the F`beta` score.""\n    beta:float=2\n\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n        self.beta2 = self.beta ** 2\n        self.avg = self.average\n        if self.average != ""micro"": self.average = None\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        prec = self._precision()\n        rec = self._recall()\n        metric = (1 + self.beta2) * prec * rec / (prec * self.beta2 + rec + self.eps)\n        metric[metric != metric] = 0  # removing potential ""nan""s\n        if self.avg: metric = (self._weights(avg=self.avg) * metric).sum()\n        return add_metrics(last_metrics, metric)\n\n    def on_train_end(self, **kwargs): self.average = self.avg\n\n@dataclass\nclass KappaScore(ConfusionMatrix):\n    ""Computes the rate of agreement (Cohens Kappa).""\n    weights:Optional[str]=None      # None, `linear`, or `quadratic`\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        sum0 = self.cm.sum(dim=0)\n        sum1 = self.cm.sum(dim=1)\n        expected = torch.einsum(\'i,j->ij\', (sum0, sum1)) / sum0.sum()\n        if self.weights is None:\n            w = torch.ones((self.n_classes, self.n_classes))\n            w[self.x, self.x] = 0\n        elif self.weights == ""linear"" or self.weights == ""quadratic"":\n            w = torch.zeros((self.n_classes, self.n_classes))\n            w += torch.arange(self.n_classes, dtype=torch.float)\n            w = torch.abs(w - torch.t(w)) if self.weights == ""linear"" else (w - torch.t(w)) ** 2\n        else: raise ValueError(\'Unknown weights. Expected None, ""linear"", or ""quadratic"".\')\n        k = torch.sum(w * self.cm) / torch.sum(w * expected)\n        return add_metrics(last_metrics, 1-k)\n\n@dataclass\nclass MatthewsCorreff(ConfusionMatrix):\n    ""Computes the Matthews correlation coefficient.""\n    def on_epoch_end(self, last_metrics, **kwargs):\n        t_sum = self.cm.sum(dim=1)\n        p_sum = self.cm.sum(dim=0)\n        n_correct = torch.trace(self.cm)\n        n_samples = p_sum.sum()\n        cov_ytyp = n_correct * n_samples - torch.dot(t_sum, p_sum)\n        cov_ypyp = n_samples ** 2 - torch.dot(p_sum, p_sum)\n        cov_ytyt = n_samples ** 2 - torch.dot(t_sum, t_sum)\n        return add_metrics(last_metrics, cov_ytyp / torch.sqrt(cov_ytyt * cov_ypyp))\n\nclass Perplexity(Callback):\n    ""Perplexity metric for language models.""\n    def on_epoch_begin(self, **kwargs): self.loss,self.len = 0.,0\n\n    def on_batch_end(self, last_output, last_target, **kwargs):\n        self.loss += last_target.size(1) * CrossEntropyFlat()(last_output, last_target)\n        self.len += last_target.size(1)\n\n    def on_epoch_end(self, last_metrics, **kwargs): \n        return add_metrics(last_metrics, torch.exp(self.loss / self.len))\n\ndef auc_roc_score(input:Tensor, targ:Tensor):\n    ""Computes the area under the receiver operator characteristic (ROC) curve using the trapezoid method. Restricted binary classification tasks.""\n    fpr, tpr = roc_curve(input, targ)\n    d = fpr[1:] - fpr[:-1]\n    sl1, sl2 = [slice(None)], [slice(None)]\n    sl1[-1], sl2[-1] = slice(1, None), slice(None, -1)\n    return (d * (tpr[tuple(sl1)] + tpr[tuple(sl2)]) / 2.).sum(-1)\n\ndef roc_curve(input:Tensor, targ:Tensor):\n    ""Computes the receiver operator characteristic (ROC) curve by determining the true positive ratio (TPR) and false positive ratio (FPR) for various classification thresholds. Restricted binary classification tasks.""\n    targ = (targ == 1)\n    desc_score_indices = torch.flip(input.argsort(-1), [-1])\n    input = input[desc_score_indices]\n    targ = targ[desc_score_indices]\n    d = input[1:] - input[:-1]\n    distinct_value_indices = torch.nonzero(d).transpose(0,1)[0]\n    threshold_idxs = torch.cat((distinct_value_indices, LongTensor([len(targ) - 1]).to(targ.device)))\n    tps = torch.cumsum(targ * 1, dim=-1)[threshold_idxs]\n    fps = (1 + threshold_idxs - tps)\n    if tps[0] != 0 or fps[0] != 0:\n        zer = fps.new_zeros(1)\n        fps = torch.cat((zer, fps))\n        tps = torch.cat((zer, tps))\n    fpr, tpr = fps.float() / fps[-1], tps.float() / tps[-1]\n    return fpr, tpr\n\n@dataclass\nclass AUROC(Callback):\n    ""Computes the area under the curve (AUC) score based on the receiver operator characteristic (ROC) curve. Restricted to binary classification tasks.""\n    def on_epoch_begin(self, **kwargs):\n        self.targs, self.preds = LongTensor([]), Tensor([])\n        \n    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n        last_output = F.softmax(last_output, dim=1)[:,-1]\n        self.preds = torch.cat((self.preds, last_output.cpu()))\n        self.targs = torch.cat((self.targs, last_target.cpu().long()))\n    \n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, auc_roc_score(self.preds, self.targs))\n\nclass MultiLabelFbeta(Callback):\n    ""Computes the fbeta score for multilabel classification""\n    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n    _order = -20 \n    def __init__(self, beta=2, eps=1e-15, thresh=0.3, sigmoid=True, average=""micro""):\n        self.eps,self.thresh,self.sigmoid,self.average,self.beta = eps,thresh,sigmoid,average,beta\n\n    def on_epoch_begin(self, **kwargs):\n        self.tp,self.total_pred,self.total_targ = 0,0,0\n    \n    def on_batch_end(self, last_output, last_target, **kwargs):\n        pred, targ = ((last_output.sigmoid() if self.sigmoid else last_output) > self.thresh).byte(), last_target.byte()\n        m = pred*targ\n        self.tp += m.sum(0).float()\n        self.total_pred += pred.sum(0).float()\n        self.total_targ += targ.sum(0).float()\n    \n    def fbeta_score(self, precision, recall):\n        beta2 = self.beta**2\n        return (1 + beta2)*(precision*recall)/((beta2*precision + recall) + self.eps)\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        self.total_pred += self.eps\n        self.total_targ += self.eps\n        if self.average == ""micro"":\n            precision, recall = self.tp.sum() / self.total_pred.sum(), self.tp.sum() / self.total_targ.sum()\n            res = self.fbeta_score(precision, recall)\n        elif self.average == ""macro"":\n            res = self.fbeta_score((self.tp / self.total_pred), (self.tp / self.total_targ)).mean()\n        elif self.average == ""weighted"":\n            scores = self.fbeta_score((self.tp / self.total_pred), (self.tp / self.total_targ))\n            res = (scores*self.total_targ).sum() / self.total_targ.sum()\n        elif self.average == ""none"":\n            res = listify(self.fbeta_score((self.tp / self.total_pred), (self.tp / self.total_targ)))\n        else:\n            raise Exception(""Choose one of the average types: [micro, macro, weighted, none]"")\n        \n        return add_metrics(last_metrics, res)\n'"
fastai/script.py,0,"b'import os, sys, subprocess, inspect\nfrom dataclasses import dataclass\nfrom typing import Any\nfrom argparse import ArgumentParser\n\n\n@dataclass\nclass Param():\n    ""A parameter in a function used in `anno_parser` or `call_parse`""\n    help:str=None\n    type:type=None\n    opt:bool=True\n    action:str=None\n    nargs:str=None\n    const:str=None\n    choices:str=None\n    required:bool=None\n\n    @property\n    def pre(self): return \'--\' if self.opt else \'\'\n    @property\n    def kwargs(self): return {k:v for k,v in self.__dict__.items()\n                              if v is not None and k!=\'opt\'}\n\ndef anno_parser(func):\n    ""Look at params (annotated with `Param`) in func and return an `ArgumentParser`""\n    p = ArgumentParser(description=func.__doc__)\n    for k,v in inspect.signature(func).parameters.items():\n        param = func.__annotations__.get(k, Param())\n        kwargs = param.kwargs\n        if v.default != inspect.Parameter.empty: kwargs[\'default\'] = v.default\n        p.add_argument(f""{param.pre}{k}"", **kwargs)\n    return p\n\ndef call_parse(func):\n    ""Decorator to create a simple CLI from `func` using `anno_parser`""\n    name = inspect.currentframe().f_back.f_globals[\'__name__\']\n    if name == ""__main__"":\n        args = anno_parser(func).parse_args()\n        func(**args.__dict__)\n    else: return func\n\ndef call_plac(f):\n    ""Decorator to create a simple CLI from `func` using `plac`""\n    name = inspect.currentframe().f_back.f_globals[\'__name__\']\n    if name == \'__main__\':\n        import plac\n        res = plac.call(f)\n        if callable(res): res()\n    else: return f\n\n'"
fastai/sixel.py,0,"b'from .core import *\n\nlibsixel = try_import(\'libsixel\')\n\ndef _sixel_encode(data, width, height):\n    s = io.BytesIO()\n    output = libsixel.sixel_output_new(lambda data, s: s.write(data), s)\n    dither = libsixel.sixel_dither_new(256)\n    w,h = int(width),int(height)\n    libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)\n    libsixel.sixel_encode(data, w, h, 1, dither, output)\n    return s.getvalue().decode(\'ascii\')\n\ndef plot_sixel(fig=None):\n    if not libsixel:\n        warn(""You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel"")\n        return\n    if fig is None: fig = plt.gcf()\n    fig.canvas.draw()\n    dpi = fig.get_dpi()\n    res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)\n    print(res)\n\n'"
fastai/torch_core.py,27,"b'""Utility functions to help deal with tensors""\nfrom .imports.torch import *\nfrom .core import *\nfrom collections import OrderedDict\nfrom torch.nn.parallel import DistributedDataParallel\n\nAffineMatrix = Tensor\nBoolOrTensor = Union[bool,Tensor]\nFloatOrTensor = Union[float,Tensor]\nIntOrTensor = Union[int,Tensor]\nItemsList = Collection[Union[Tensor,ItemBase,\'ItemsList\',float,int]]\nLambdaFunc = Callable[[Tensor],Tensor]\nLayerFunc = Callable[[nn.Module],None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\'OneEltTensor\', Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor,Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int,int,int]\nTensors = Union[Tensor, Collection[\'Tensors\']]\nWeights = Dict[str,Tensor]\n\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor,Tensor],TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\n\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\n\nfastai_types = {\n    AnnealFunc:\'AnnealFunc\', ArgStar:\'ArgStar\', BatchSamples:\'BatchSamples\',\n    FilePathList:\'FilePathList\', Floats:\'Floats\', ImgLabel:\'ImgLabel\', ImgLabels:\'ImgLabels\', KeyFunc:\'KeyFunc\',\n    KWArgs:\'KWArgs\', ListOrItem:\'ListOrItem\', ListRules:\'ListRules\', ListSizes:\'ListSizes\',\n    NPArrayableList:\'NPArrayableList\', NPArrayList:\'NPArrayList\', NPArrayMask:\'NPArrayMask\', NPImage:\'NPImage\',\n    OptDataFrame:\'OptDataFrame\', OptListOrItem:\'OptListOrItem\', OptRange:\'OptRange\', OptStrTuple:\'OptStrTuple\',\n    OptStats:\'OptStats\', PathOrStr:\'PathOrStr\', PBar:\'PBar\', Point:\'Point\', Points:\'Points\', Sizes:\'Sizes\',\n    SplitArrayList:\'SplitArrayList\', StartOptEnd:\'StartOptEnd\', StrList:\'StrList\', Tokens:\'Tokens\',\n    OptStrList:\'OptStrList\', AffineMatrix:\'AffineMatrix\', BoolOrTensor:\'BoolOrTensor\', FloatOrTensor:\'FloatOrTensor\',\n    IntOrTensor:\'IntOrTensor\', ItemsList:\'ItemsList\', LambdaFunc:\'LambdaFunc\',\n    LayerFunc:\'LayerFunc\', ModuleList:\'ModuleList\', OptOptimizer:\'OptOptimizer\', ParamList:\'ParamList\',\n    Rank0Tensor:\'Rank0Tensor\', SplitFunc:\'SplitFunc\', SplitFuncOrIdxList:\'SplitFuncOrIdxList\',\n    TensorOrNumber:\'TensorOrNumber\', TensorOrNumList:\'TensorOrNumList\', TensorImage:\'TensorImage\',\n    TensorImageSize:\'TensorImageSize\', Tensors:\'Tensors\', Weights:\'Weights\', AffineFunc:\'AffineFunc\',\n    HookFunc:\'HookFunc\', LogitTensorImage:\'LogitTensorImage\', LossFunction:\'LossFunction\', MetricFunc:\'MetricFunc\',\n    MetricFuncList:\'MetricFuncList\', MetricsList:\'MetricsList\', OptLossFunc:\'OptLossFunc\', OptMetrics:\'OptMetrics\',\n    OptSplitFunc:\'OptSplitFunc\', PixelFunc:\'PixelFunc\', LightingFunc:\'LightingFunc\', IntsOrStrs:\'IntsOrStrs\',\n    PathLikeOrBinaryStream:\'PathLikeOrBinaryStream\'\n}\n\nbn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\nbias_types = (nn.Linear, nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.ConvTranspose1d, nn.ConvTranspose2d, nn.ConvTranspose3d)\ndef is_pool_type(l:Callable): return re.search(r\'Pool[123]d$\', l.__class__.__name__)\nno_wd_types = bn_types + (nn.LayerNorm,)\ndefaults.device = torch.device(\'cuda\') if torch.cuda.is_available() else torch.device(\'cpu\')\nAdamW = partial(optim.Adam, betas=(0.9,0.99))\n\n#Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = torch.device(\'cuda\', device) if isinstance(device, int) else device\ntorch.cuda.set_device = _new_torch_cuda_set_device\n\ndef tensor(x:Any, *rest)->Tensor:\n    ""Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.""\n    if len(rest): x = (x,)+rest\n    # XXX: Pytorch bug in dataloader using num_workers>0; TODO: create repro and report\n    if is_listy(x) and len(x)==0: return tensor(0)\n    res = torch.tensor(x) if is_listy(x) else as_tensor(x)\n    if res.dtype is torch.int32:\n        warn(\'Tensor is int32: upgrading to int64; for better performance use int64 input\')\n        return res.long()\n    return res\n\nclass Module(nn.Module, metaclass=PrePostInitMeta):\n    ""Same as `nn.Module`, but no need for subclasses to call `super().__init__`""\n    def __pre_init__(self): super().__init__()\n    def __init__(self): pass\n\ndef np_address(x:np.ndarray)->int:\n    ""Address of `x` in memory.""\n    return x.__array_interface__[\'data\'][0]\n\ndef to_detach(b:Tensors, cpu:bool=True):\n    ""Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.""\n    def _inner(x, cpu=True):\n        if not isinstance(x,Tensor): return x\n        x = x.detach()\n        return x.cpu() if cpu else x\n    return recurse(_inner, b, cpu=cpu)\n\ndef to_data(b:ItemsList):\n    ""Recursively map lists of items in `b ` to their wrapped data.""\n    return recurse(lambda x: x.data if isinstance(x,ItemBase) else x, b)\n\ndef to_cpu(b:ItemsList):\n    ""Recursively map lists of tensors in `b ` to the cpu.""\n    return recurse(lambda x: x.cpu() if isinstance(x,Tensor) else x, b)\n\ndef to_half(b:Collection[Tensor])->Collection[Tensor]:\n    ""Recursively map lists of tensors in `b ` to FP16.""\n    return recurse(lambda x: x.half() if x.dtype not in [torch.int64, torch.int32, torch.int16] else x, b)\n\ndef to_float(b:Collection[Tensor])->Collection[Tensor]:\n    ""Recursively map lists of tensors in `b ` to FP16.""\n    return recurse(lambda x: x.float() if x.dtype not in [torch.int64, torch.int32, torch.int16] else x, b)\n\ndef to_device(b:Tensors, device:torch.device):\n    ""Recursively put `b` on `device`.""\n    device = ifnone(device, defaults.device)\n    return recurse(lambda x: x.to(device, non_blocking=True), b)\n\ndef data_collate(batch:ItemsList)->Tensor:\n    ""Convert `batch` items to tensor data.""\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\n\ndef requires_grad(m:nn.Module, b:Optional[bool]=None)->Optional[bool]:\n    ""If `b` is not set return `requires_grad` of first param, else set `requires_grad` on all params as `b`""\n    ps = list(m.parameters())\n    if not ps: return None\n    if b is None: return ps[0].requires_grad\n    for p in ps: p.requires_grad=b\n\ndef has_params(m:nn.Module)->bool:\n    ""Check if `m` has at least one parameter""\n    return len(list(m.parameters())) > 0\n        \ndef trainable_params(m:nn.Module)->ParamList:\n    ""Return list of trainable params in `m`.""\n    res = filter(lambda p: p.requires_grad, m.parameters())\n    return res\n\ndef children(m:nn.Module)->ModuleList:\n    ""Get children of `m`.""\n    return list(m.children())\n\ndef num_children(m:nn.Module)->int:\n    ""Get number of children modules in `m`.""\n    return len(children(m))\n\ndef range_children(m:nn.Module)->Iterator[int]:\n    ""Return iterator of len of children of `m`.""\n    return range(num_children(m))\n\nclass ParameterModule(Module):\n    ""Register a lone parameter `p` in a module.""\n    def __init__(self, p:nn.Parameter): self.val = p\n    def forward(self, x): return x\n\ndef children_and_parameters(m:nn.Module):\n    ""Return the children of `m` and its direct parameters not registered in modules.""\n    children = list(m.children())\n    children_p = sum([[id(p) for p in c.parameters()] for c in m.children()],[])\n    for p in m.parameters():\n        if id(p) not in children_p: children.append(ParameterModule(p))\n    return children\n\nflatten_model = lambda m: sum(map(flatten_model,children_and_parameters(m)),[]) if num_children(m) else [m]\n\ndef first_layer(m:nn.Module)->nn.Module:\n    ""Retrieve first layer in a module `m`.""\n    return flatten_model(m)[0]\n\ndef last_layer(m:nn.Module)->nn.Module:\n    ""Retrieve last layer in a module `m`.""\n    return flatten_model(m)[-1]\n\ndef split_model_idx(model:nn.Module, idxs:Collection[int])->ModuleList:\n    ""Split `model` according to the indexes in `idxs`.""\n    layers = flatten_model(model)\n    if idxs[0] != 0: idxs = [0] + idxs\n    if idxs[-1] != len(layers): idxs.append(len(layers))\n    return [nn.Sequential(*layers[i:j]) for i,j in zip(idxs[:-1],idxs[1:])]\n\ndef split_model(model:nn.Module=None, splits:Collection[Union[nn.Module,ModuleList]]=None):\n    ""Split `model` according to the layers in `splits`.""\n    splits = listify(splits)\n    if isinstance(splits[0], nn.Module):\n        layers = flatten_model(model)\n        idxs = [layers.index(first_layer(s)) for s in splits]\n        return split_model_idx(model, idxs)\n    return [nn.Sequential(*s) for s in splits]\n\ndef get_param_groups(layer_groups:Collection[nn.Module])->List[List[nn.Parameter]]:\n    return [sum([list(trainable_params(c)) for c in l.children()], []) for l in layer_groups]\n\ndef split_no_wd_params(layer_groups:Collection[nn.Module])->List[List[nn.Parameter]]:\n    ""Separate the parameters in `layer_groups` between `no_wd_types` and  bias (`bias_types`) from the rest.""\n    split_params = []\n    for l in layer_groups:\n        l1,l2 = [],[]\n        for c in l.children():\n            if isinstance(c, no_wd_types): l2 += list(trainable_params(c))\n            elif isinstance(c, bias_types):\n                bias = c.bias if hasattr(c, \'bias\') else None\n                l1 += [p for p in trainable_params(c) if not (p is bias)]\n                if bias is not None: l2.append(bias)\n            else: l1 += list(trainable_params(c))\n        #Since we scan the children separately, we might get duplicates (tied weights). We need to preserve the order\n        #for the optimizer load of state_dict\n        l1,l2 = uniqueify(l1),uniqueify(l2)\n        split_params += [l1, l2]\n    return split_params\n\ndef set_bn_eval(m:nn.Module)->None:\n    ""Set bn layers in eval mode for all recursive children of `m`.""\n    for l in m.children():\n        if isinstance(l, bn_types) and not next(l.parameters()).requires_grad:\n            l.eval()\n        set_bn_eval(l)\n\ndef batch_to_half(b:Collection[Tensor])->Collection[Tensor]:\n    ""Set the input of batch `b` to half precision.""\n    return [to_half(b[0]), b[1]]\n\ndef bn2float(module:nn.Module)->nn.Module:\n    ""If `module` is batchnorm don\'t use half precision.""\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm): module.float()\n    for child in module.children(): bn2float(child)\n    return module\n\ndef model2half(model:nn.Module)->nn.Module:\n    ""Convert `model` to half precision except the batchnorm layers.""\n    return bn2float(model.half())\n\ndef init_default(m:nn.Module, func:LayerFunc=nn.init.kaiming_normal_)->nn.Module:\n    ""Initialize `m` weights with `func` and set `bias` to 0.""\n    if func:\n        if hasattr(m, \'weight\'): func(m.weight)\n        if hasattr(m, \'bias\') and hasattr(m.bias, \'data\'): m.bias.data.fill_(0.)\n    return m\n\ndef cond_init(m:nn.Module, init_func:LayerFunc):\n    ""Initialize the non-batchnorm layers of `m` with `init_func`.""\n    if (not isinstance(m, bn_types)) and requires_grad(m): init_default(m, init_func)\n\ndef apply_leaf(m:nn.Module, f:LayerFunc):\n    ""Apply `f` to children of `m`.""\n    c = children(m)\n    if isinstance(m, nn.Module): f(m)\n    for l in c: apply_leaf(l,f)\n\ndef apply_init(m, init_func:LayerFunc):\n    ""Initialize all non-batchnorm layers of `m` with `init_func`.""\n    apply_leaf(m, partial(cond_init, init_func=init_func))\n\ndef in_channels(m:nn.Module) -> List[int]:\n    ""Return the shape of the first weight layer in `m`.""\n    for l in flatten_model(m):\n        if hasattr(l, \'weight\'): return l.weight.shape[1]\n    raise Exception(\'No weight layer\')\n\nclass ModelOnCPU():\n    ""A context manager to evaluate `model` on the CPU inside.""\n    def __init__(self, model:nn.Module): self.model = model       \n    def __enter__(self):\n        self.device = one_param(self.model).device\n        return self.model.cpu()\n    def __exit__(self, type, value, traceback):\n        self.model = self.model.to(self.device)\n    \nclass NoneReduceOnCPU():\n    ""A context manager to evaluate `loss_func` with none reduce and weights on the CPU inside.""\n    def __init__(self, loss_func:LossFunction): \n        self.loss_func,self.device,self.old_red = loss_func,None,None\n        \n    def __enter__(self):\n        if hasattr(self.loss_func, \'weight\') and self.loss_func.weight is not None:\n            self.device = self.loss_func.weight.device\n            self.loss_func.weight = self.loss_func.weight.cpu()\n        if hasattr(self.loss_func, \'reduction\'):\n            self.old_red = getattr(self.loss_func, \'reduction\')\n            setattr(self.loss_func, \'reduction\', \'none\')\n            return self.loss_func\n        else: return partial(self.loss_func, reduction=\'none\')\n        \n    def __exit__(self, type, value, traceback):\n        if self.device is not None:  self.loss_func.weight = self.loss_func.weight.to(self.device)\n        if self.old_red is not None: setattr(self.loss_func, \'reduction\', self.old_red)    \n    \ndef model_type(dtype):\n    ""Return the torch type corresponding to `dtype`.""\n    return (torch.float32 if np.issubdtype(dtype, np.floating) else\n            torch.int64 if np.issubdtype(dtype, np.integer)\n            else None)\n\ndef np2model_tensor(a):\n    ""Tranform numpy array `a` to a tensor of the same type.""\n    dtype = model_type(a.dtype)\n    res = as_tensor(a)\n    if not dtype: return res\n    return res.type(dtype)\n\ndef _pca(x, k=2, center=True):\n    ""Compute PCA of `x` with `k` dimensions.""\n    if center: x = x-torch.mean(x,0)\n    U,S,V = torch.svd(x.t())\n    return torch.mm(x,U[:,:k])\ntorch.Tensor.pca = _pca\n\ndef trange_of(x): \n    ""Create a tensor from `range_of(x)`.""\n    return torch.arange(len(x))\n\ndef to_np(x): \n    ""Convert a tensor to a numpy array.""\n    return x.data.cpu().numpy()\n\ndef grab_idx(x,i,batch_first:bool=True):\n    ""Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.""\n    if batch_first: return ([o[i].cpu() for o in x]   if is_listy(x) else x[i].cpu())\n    else:           return ([o[:,i].cpu() for o in x] if is_listy(x) else x[:,i].cpu())\n\ndef logit(x:Tensor)->Tensor:\n    ""Logit of `x`, clamped to avoid inf.""\n    x = x.clamp(1e-7, 1-1e-7)\n    return -(1/x-1).log()\n\ndef logit_(x:Tensor)->Tensor:\n    ""Inplace logit of `x`, clamped to avoid inf""\n    x.clamp_(1e-7, 1-1e-7)\n    return (x.reciprocal_().sub_(1)).log_().neg_()\n\ndef set_all_seed(seed:int)->None:\n    ""Sets the seeds for all pseudo random generators in fastai lib""\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\n\ndef uniform(low:Number, high:Number=None, size:Optional[List[int]]=None)->FloatOrTensor:\n    ""Draw 1 or shape=`size` random floats from uniform dist: min=`low`, max=`high`.""\n    if high is None: high=low\n    return random.uniform(low,high) if size is None else torch.FloatTensor(*listify(size)).uniform_(low,high)\n\ndef log_uniform(low, high, size:Optional[List[int]]=None)->FloatOrTensor:\n    ""Draw 1 or shape=`size` random floats from uniform dist: min=log(`low`), max=log(`high`).""\n    res = uniform(log(low), log(high), size)\n    return exp(res) if size is None else res.exp_()\n\ndef rand_bool(p:float, size:Optional[List[int]]=None)->BoolOrTensor:\n    ""Draw 1 or shape=`size` random booleans (`True` occuring with probability `p`).""\n    return uniform(0,1,size)<p\n\ndef uniform_int(low:int, high:int, size:Optional[List[int]]=None)->IntOrTensor:\n    ""Generate int or tensor `size` of ints between `low` and `high` (included).""\n    return random.randint(low,high) if size is None else torch.randint(low,high+1,size)\n\ndef one_param(m: nn.Module)->Tensor: \n    ""Return the first parameter of `m`.""\n    return next(m.parameters())\n\ndef try_int(o:Any)->Any:\n    ""Try to convert `o` to int, default to `o` if not possible.""\n    # NB: single-item rank-1 array/tensor can be converted to int, but we don\'t want to do this\n    if isinstance(o, (np.ndarray,Tensor)): return o if o.ndim else int(o)\n    if isinstance(o, Sized) or getattr(o,\'__array_interface__\',False): return o\n    try: return int(o)\n    except: return o\n\ndef get_model(model:nn.Module):\n    ""Return the model maybe wrapped inside `model`.""\n    return model.module if isinstance(model, (DistributedDataParallel, nn.DataParallel)) else model\n\ndef flatten_check(out:Tensor, targ:Tensor) -> Tensor:\n    ""Check that `out` and `targ` have the same number of elements and flatten them.""\n    out,targ = out.contiguous().view(-1),targ.contiguous().view(-1)\n    assert len(out) == len(targ), f""Expected output and target to have the same number of elements but got {len(out)} and {len(targ)}.""\n    return out,targ\n\n#Monkey-patch nn.DataParallel.reset\ndef _data_parallel_reset(self): \n    if hasattr(self.module, \'reset\'): self.module.reset()\nnn.DataParallel.reset = _data_parallel_reset\n\ndef remove_module_load(state_dict):\n    """"""create new OrderedDict that does not contain `module.`""""""\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items(): new_state_dict[k[7:]] = v\n    return new_state_dict\n\ndef num_distrib():\n    ""Return the number of processes in distributed training (if applicable).""\n    return int(os.environ.get(\'WORLD_SIZE\', 0))\n\ndef rank_distrib():\n    ""Return the distributed rank of this process (if applicable).""\n    return int(os.environ.get(\'RANK\', 0))\n\ndef distrib_barrier():\n    ""Barrier synchronization in distributed training (if applicable).  Processes in the same process group must all arrive here before proceeding further. Example use case: avoid processes stepping on each other when saving and loading models in distributed training.  See https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#save-and-load-checkpoints.""\n    if num_distrib() > 1: torch.distributed.barrier()\n    \ndef add_metrics(last_metrics:Collection[Rank0Tensor], mets:Union[Rank0Tensor, Collection[Rank0Tensor]]):\n    ""Return a dictionary for updating `last_metrics` with `mets`.""\n    last_metrics,mets = listify(last_metrics),listify(mets)\n    return {\'last_metrics\': last_metrics + mets}\n\ndef try_save(state:Dict, path:Path=None, file:PathLikeOrBinaryStream=None):\n    target = open(path/file, \'wb\') if is_pathlike(file) else file\n    try: \n        with warnings.catch_warnings():\n            #To avoid the warning that come from PyTorch about model not being checked\n            warnings.simplefilter(""ignore"")\n            torch.save(state, target)\n    except OSError as e:\n        raise Exception(f""{e}\\n Can\'t write {path/file}. Pass an absolute writable pathlib obj `fname`."")\n\ndef np_func(f):\n    ""Convert a function taking and returning numpy arrays to one taking and returning tensors""\n    def _inner(*args, **kwargs):\n        nargs = [to_np(arg) if isinstance(arg,Tensor) else arg for arg in args]\n        return tensor(f(*nargs, **kwargs))\n    functools.update_wrapper(_inner, f)\n    return _inner\n\n'"
fastai/train.py,3,"b'""Provides advanced training extensions to `fastai.basic_train`. Includes half-precision, learning rate finder, mixup, and one-cycle""\nfrom .torch_core import *\nfrom .callback import *\nfrom .callbacks import *\nfrom .basic_data import *\nfrom .basic_train import *\n\n__all__ = [\'BnFreeze\', \'GradientClipping\', \'ShowGraph\', \'Interpretation\', \'ClassificationInterpretation\', \'MultiLabelClassificationInterpretation\',\n \'fit_one_cycle\', \'lr_find\', \'one_cycle_scheduler\', \'to_fp16\', \'to_fp32\', \'mixup\', \'AccumulateScheduler\', \'fit_fc\']\n\ndef one_cycle_scheduler(lr_max:float, **kwargs:Any)->OneCycleScheduler:\n    ""Instantiate a `OneCycleScheduler` with `lr_max`.""\n    return partial(OneCycleScheduler, lr_max=lr_max, **kwargs)\n\ndef fit_one_cycle(learn:Learner, cyc_len:int, max_lr:Union[Floats,slice]=defaults.lr,\n                  moms:Tuple[float,float]=(0.95,0.85), div_factor:float=25., pct_start:float=0.3, final_div:float=None,\n                  wd:float=None, callbacks:Optional[CallbackList]=None, tot_epochs:int=None, start_epoch:int=None)->None:\n    ""Fit a model following the 1cycle policy.""\n    max_lr = learn.lr_range(max_lr)\n    callbacks = listify(callbacks)\n    callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n                                       final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n    learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)\n\ndef fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n                  wd:float=None, callbacks:Optional[CallbackList]=None)->None:\n    ""Fit a model with Flat Cosine Annealing""\n    max_lr = learn.lr_range(lr)\n    callbacks = listify(callbacks)\n    callbacks.append(FlatCosAnnealScheduler(learn, lr, moms=moms, start_pct=start_pct, tot_epochs=tot_epochs))\n    learn.fit(tot_epochs, max_lr, wd=wd, callbacks=callbacks)\n\ndef lr_find(learn:Learner, start_lr:Floats=1e-7, end_lr:Floats=10, num_it:int=100, stop_div:bool=True, wd:float=None):\n    ""Explore lr from `start_lr` to `end_lr` over `num_it` iterations in `learn`. If `stop_div`, stops when loss diverges.""\n    start_lr = learn.lr_range(start_lr)\n    start_lr = np.array(start_lr) if is_listy(start_lr) else start_lr\n    end_lr = learn.lr_range(end_lr)\n    end_lr = np.array(end_lr) if is_listy(end_lr) else end_lr\n    cb = LRFinder(learn, start_lr, end_lr, num_it, stop_div)\n    epochs = int(np.ceil(num_it/len(learn.data.train_dl))) * (num_distrib() or 1)\n    learn.fit(epochs, start_lr, callbacks=[cb], wd=wd)\n\ndef to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n            flat_master:bool=False, max_scale:float=2**24, loss_fp32:bool=True)->Learner:\n    ""Put `learn` in FP16 precision mode.""\n    learn.to_fp32()\n    learn.model = model2half(learn.model)\n    learn.data.add_tfm(batch_to_half)\n    learn.mp_cb = MixedPrecision(learn, loss_scale=loss_scale, max_noskip=max_noskip, dynamic=dynamic, clip=clip,\n                                 flat_master=flat_master, max_scale=max_scale, loss_fp32=loss_fp32)\n    learn.callbacks.append(learn.mp_cb)\n    return learn\n\ndef to_fp32(learn:Learner):\n    ""Put `learn` back to FP32 precision mode.""\n    learn.data.remove_tfm(batch_to_half)\n    for cb in learn.callbacks:\n        if isinstance(cb, MixedPrecision): learn.callbacks.remove(cb)\n    learn.model = learn.model.float()\n    return learn\n\ndef mixup(learn:Learner, alpha:float=0.4, stack_x:bool=False, stack_y:bool=True) -> Learner:\n    ""Add mixup https://arxiv.org/abs/1710.09412 to `learn`.""\n    learn.callback_fns.append(partial(MixUpCallback, alpha=alpha, stack_x=stack_x, stack_y=stack_y))\n    return learn\n\nLearner.fit_one_cycle = fit_one_cycle\nLearner.lr_find = lr_find\nLearner.to_fp16 = to_fp16\nLearner.to_fp32 = to_fp32\nLearner.mixup = mixup\nLearner.fit_fc = fit_fc\n\nclass ShowGraph(LearnerCallback):\n    ""Update a graph of learner stats and metrics after each epoch.""\n    def on_epoch_end(self, n_epochs:int, last_metrics:MetricsList, **kwargs)->bool:\n        ""If we have `last_metrics` plot them in our pbar graph""\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)\n            val_iter = np.array(rec.nb_batches).cumsum()\n            x_bounds = (0, (n_epochs - len(rec.nb_batches)) * rec.nb_batches[-1] + len(rec.losses))\n            y_bounds = (0, max((max(Tensor(rec.losses)), max(Tensor(rec.val_losses)))))\n            rec.pbar.update_graph([(iters, rec.losses), (val_iter, rec.val_losses)], x_bounds, y_bounds)\n        return {}\n\nclass BnFreeze(LearnerCallback):\n    ""Freeze moving average statistics in all non-trainable batchnorm layers.""\n    def on_epoch_begin(self, **kwargs:Any)->None:\n        ""Put bn layers in eval mode just after `model.train()`.""\n        set_bn_eval(self.learn.model)\n\nclass GradientClipping(LearnerCallback):\n    ""Gradient clipping during training.""\n    def __init__(self, learn:Learner, clip:float = 0.):\n        super().__init__(learn)\n        self.clip = clip\n\n    def on_backward_end(self, **kwargs):\n        ""Clip the gradient before the optimizer step.""\n        if self.clip: nn.utils.clip_grad_norm_(self.learn.model.parameters(), self.clip)\n\ndef clip_grad(learn:Learner, clip:float=0.1)->Learner:\n    ""Add gradient clipping of `clip` during training.""\n    learn.callback_fns.append(partial(GradientClipping, clip=clip))\n    return learn\nLearner.clip_grad = clip_grad\n\nclass AccumulateScheduler(LearnerCallback):\n    ""Does accumlated step every nth step by accumulating gradients""\n\n    def __init__(self, learn:Learner, n_step:int = 1, drop_last:bool = False):\n        super().__init__(learn)\n        self.n_step,self.drop_last = n_step,drop_last\n\n    def on_train_begin(self, **kwargs):\n        ""check if loss is reduction""\n        if hasattr(self.loss_func, ""reduction"") and (self.loss_func.reduction != ""sum""):\n             warn(""For better gradients consider \'reduction=sum\'"")\n\n    def on_epoch_begin(self, **kwargs):\n        ""init samples and batches, change optimizer""\n        self.acc_samples, self.acc_batches = 0., 0.\n\n    def on_batch_begin(self, last_input, last_target, **kwargs):\n        ""accumulate samples and batches""\n        self.acc_samples += last_input.shape[0]\n        self.acc_batches += 1\n\n    def on_backward_end(self, **kwargs):\n        ""accumulated step and reset samples, True will result in no stepping""\n        if (self.acc_batches % self.n_step) == 0:\n            for p in (self.learn.model.parameters()):\n                if p.requires_grad: p.grad.div_(self.acc_samples)\n            self.acc_samples = 0\n        else: return {\'skip_step\':True, \'skip_zero\':True}\n\n    def on_epoch_end(self, **kwargs):\n        ""step the rest of the accumulated grads if not perfectly divisible""\n        for p in (self.learn.model.parameters()):\n                if p.requires_grad: p.grad.div_(self.acc_samples)\n        if not self.drop_last: self.learn.opt.step()\n        self.learn.opt.zero_grad()\n\n\nclass Interpretation():\n    ""Interpretation base class, can be inherited for task specific Interpretation classes""\n    def __init__(self, learn:Learner, preds:Tensor, y_true:Tensor, losses:Tensor, ds_type:DatasetType=DatasetType.Valid):\n        self.data,self.preds,self.y_true,self.losses,self.ds_type, self.learn = \\\n                                 learn.data,preds,y_true,losses,ds_type,learn\n        self.ds = (self.data.train_ds if ds_type == DatasetType.Train else\n                   self.data.test_ds if ds_type == DatasetType.Test else\n                   self.data.valid_ds if ds_type == DatasetType.Valid else\n                   self.data.single_ds if ds_type == DatasetType.Single else\n                   self.data.fix_ds)\n\n    @classmethod\n    def from_learner(cls, learn: Learner,  ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None):\n        ""Gets preds, y_true, losses to construct base class from a learner""\n        preds_res = learn.get_preds(ds_type=ds_type, activ=activ, with_loss=True)\n        return cls(learn, *preds_res)\n\n    def top_losses(self, k:int=None, largest=True):\n        ""`k` largest(/smallest) losses and indexes, defaulting to all losses (sorted by `largest`).""\n        return self.losses.topk(ifnone(k, len(self.losses)), largest=largest)\n\n    # def top_scores(self, metric:Callable=None, k:int=None, largest=True):\n    #     ""`k` largest(/smallest) metric scores and indexes, defaulting to all scores (sorted by `largest`).""\n    #     self.scores = metric(self.preds, self.y_true)\n    #     return self.scores.topk(ifnone(k, len(self.scores)), largest=largest)\n\n\nclass ClassificationInterpretation(Interpretation):\n    ""Interpretation methods for classification models.""\n    def __init__(self, learn:Learner, preds:Tensor, y_true:Tensor, losses:Tensor, ds_type:DatasetType=DatasetType.Valid):\n        super().__init__(learn,preds,y_true,losses,ds_type)\n        self.pred_class = self.preds.argmax(dim=1)\n\n    def confusion_matrix(self, slice_size:int=1):\n        ""Confusion matrix as an `np.ndarray`.""\n        x=torch.arange(0,self.data.c)\n        if slice_size is None: cm = ((self.pred_class==x[:,None]) & (self.y_true==x[:,None,None])).sum(2)\n        else:\n            cm = torch.zeros(self.data.c, self.data.c, dtype=x.dtype)\n            for i in range(0, self.y_true.shape[0], slice_size):\n                cm_slice = ((self.pred_class[i:i+slice_size]==x[:,None])\n                            & (self.y_true[i:i+slice_size]==x[:,None,None])).sum(2)\n                torch.add(cm, cm_slice, out=cm)\n        return to_np(cm)\n\n    def plot_confusion_matrix(self, normalize:bool=False, title:str=\'Confusion matrix\', cmap:Any=""Blues"", slice_size:int=1,\n                              norm_dec:int=2, plot_txt:bool=True, return_fig:bool=None, **kwargs)->Optional[plt.Figure]:\n        ""Plot the confusion matrix, with `title` and using `cmap`.""\n        # This function is mainly copied from the sklearn docs\n        cm = self.confusion_matrix(slice_size=slice_size)\n        if normalize: cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n        fig = plt.figure(**kwargs)\n        plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n        plt.title(title)\n        tick_marks = np.arange(self.data.c)\n        plt.xticks(tick_marks, self.data.y.classes, rotation=90)\n        plt.yticks(tick_marks, self.data.y.classes, rotation=0)\n\n        if plot_txt:\n            thresh = cm.max() / 2.\n            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n                coeff = f\'{cm[i, j]:.{norm_dec}f}\' if normalize else f\'{cm[i, j]}\'\n                plt.text(j, i, coeff, horizontalalignment=""center"", verticalalignment=""center"", color=""white"" if cm[i, j] > thresh else ""black"")\n\n        ax = fig.gca()\n        ax.set_ylim(len(self.data.y.classes)-.5,-.5)\n                           \n        plt.tight_layout()\n        plt.ylabel(\'Actual\')\n        plt.xlabel(\'Predicted\')\n        plt.grid(False)\n        if ifnone(return_fig, defaults.return_fig): return fig\n\n    def most_confused(self, min_val:int=1, slice_size:int=1)->Collection[Tuple[str,str,int]]:\n        ""Sorted descending list of largest non-diagonal entries of confusion matrix, presented as actual, predicted, number of occurrences.""\n        cm = self.confusion_matrix(slice_size=slice_size)\n        np.fill_diagonal(cm, 0)\n        res = [(self.data.classes[i],self.data.classes[j],cm[i,j])\n                for i,j in zip(*np.where(cm>=min_val))]\n        return sorted(res, key=itemgetter(2), reverse=True)\n\n\ndef _learner_interpret(learn:Learner, ds_type:DatasetType=DatasetType.Valid):\n    ""Create a `ClassificationInterpretation` object from `learner` on `ds_type` with `tta`.""\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type)\nLearner.interpret = _learner_interpret\n\nclass MultiLabelClassificationInterpretation(Interpretation):\n    ""Interpretation methods for classification models.""\n    def __init__(self, learn:Learner, preds:Tensor, y_true:Tensor, losses:Tensor, ds_type:DatasetType=DatasetType.Valid,\n                     sigmoid:bool=True, thresh:float=0.3):\n        raise NotImplementedError\n        super(MultiLabelClassificationInterpretation, self).__init__(learn,preds,y_true,losses,ds_type)\n        self.pred_class = self.preds.sigmoid(dim=1)>thresh if sigmoid else self.preds>thresh\n       \n'"
fastai/version.py,0,"b""__all__ = ['__version__']\n__version__ = '1.0.62.dev0'\n"""
old/setup.py,0,"b'\n# coding: utf-8\n\n"""""" Setup script for installing fastai """"""\n\n#from distutils.core import setup\nfrom setuptools import setup\n\nsetup(\n    name = ""fastai"",\n    packages = [\'fastai\', \'fastai/models\', \'fastai/models/cifar10\'],\n    version = \'0.7.0\',\n    description = ""The fastai deep learning and machine learning library."",\n    author = ""Jeremy Howard and contributors"",\n    author_email = ""info@fast.ai"",\n    license = ""Apache License 2.0"",\n    url = ""https://github.com/fastai/fastai"",\n    download_url =  \'https://github.com/fastai/fastai/archive/0.7.0.tar.gz\',\n    install_requires =\n     [\'bcolz\', \'bleach\', \'certifi\', \'cycler\', \'decorator\', \'entrypoints\', \'feather-format\', \'graphviz\', \'html5lib\',\n      \'ipykernel\', \'ipython\', \'ipython-genutils\', \'ipywidgets\', \'isoweek\', \'jedi\', \'Jinja2\', \'jsonschema\', \'jupyter\',\n      \'MarkupSafe\', \'matplotlib\', \'numpy\', \'opencv-python\', \'pandas\',\n      \'pandas_summary\', \'pickleshare\', \'Pillow\', \'plotnine\',\n      \'ptyprocess\', \'Pygments\', \'pyparsing\', \'python-dateutil\', \'pytz\', \'PyYAML\', \'pyzmq\', \'scipy\',\n      \'seaborn\', \'simplegeneric\', \'sklearn_pandas\', \'spacy\', \'testpath\', \'torch<0.4\', \'torchtext\',\n      \'torchvision\', \'tornado\', \'tqdm\', \'traitlets\', \'wcwidth\', \'webencodings\', \'widgetsnbextension\'],\n    keywords = [\'deeplearning\', \'pytorch\', \'machinelearning\'],\n    classifiers = [\'Development Status :: 3 - Alpha\',\n                   \'Programming Language :: Python\',\n                   \'Programming Language :: Python :: 3.6\',\n                   \'Topic :: Scientific/Engineering :: Artificial Intelligence\']\n)\n'"
tests/conftest.py,0,"b'# tests directory-specific settings - this file is run automatically\n# by pytest before any tests are run\n\nimport pytest, sys, re\nfrom os.path import abspath, dirname, join\n\n# make sure we test against the checked out git version of fastai and\n# not the pre-installed version. With \'pip install -e .[dev]\' it\'s not\n# needed, but it\'s better to be safe and ensure the git path comes\n# second in sys.path (the first path is the test dir path)\ngit_repo_path = abspath(dirname(dirname(__file__)))\nsys.path.insert(1, git_repo_path)\n\n# fastai modules should be imported **only after sys.path was tweaked to include the local checkout**\nfrom utils.mem import use_gpu\nfrom fastai.gen_doc.doctest import TestRegistry\n\ndef pytest_addoption(parser):\n    parser.addoption(""--runslow"", action=""store_true"", default=False, help=""run slow tests"")\n    parser.addoption(""--runcpp"", action=""store_true"",  default=False, help=""run tests cpp extension tests"")\n    parser.addoption(""--skipint"", action=""store_true"", default=False, help=""skip integration tests"")\n    #parser.addoption(""--testreg"", action=""store_true"", default=False, help=""test api registry"")\n\ndef mark_items_with_keyword(items, marker, keyword):\n    for item in items:\n        if keyword in item.keywords: item.add_marker(marker)\n\ndef pytest_collection_modifyitems(config, items):\n    if not config.getoption(""--runslow""):\n        skip_slow = pytest.mark.skip(reason=""need --runslow option to run"")\n        mark_items_with_keyword(items, skip_slow, ""slow"")\n\n    if not config.getoption(""--runcpp""):\n        skip_cpp = pytest.mark.skip(reason=""need --runcpp option to run"")\n        mark_items_with_keyword(items, skip_cpp, ""cpp"")\n\n    if config.getoption(""--skipint""):\n        skip_int = pytest.mark.skip(reason=""--skipint used to skip integration test"")\n        mark_items_with_keyword(items, skip_int, ""integration"")\n\n    if not use_gpu:\n        skip_cuda = pytest.mark.skip(reason=""CUDA is not available"")\n        mark_items_with_keyword(items, skip_cuda, ""cuda"")\n\n\n### TestRegistry hooks and fixtures ###\n@pytest.hookimpl(hookwrapper=True)\ndef pytest_terminal_summary(terminalreporter):\n    yield\n    TestRegistry.missing_this_tests_alert()\n\n@pytest.fixture(scope=""session"", autouse=True)\ndef test_registry_machinery(request):\n    # pytest setup\n    yield\n    # pytest teardown\n    # XXX: let\'s try to do it unconditionally\n    #if (pytest.config.getoption(""--testreg"") and # don\'t interfere with duties\n    #    not request.session.testsfailed):        # failures could miss this_tests\n    TestRegistry.registry_save()\n\n@pytest.hookimpl(tryfirst=True, hookwrapper=True)\ndef pytest_runtest_makereport(item, call):\n    outcome = yield\n    res = outcome.get_result()\n    if res.when == ""setup"" and res.passed:\n        TestRegistry.this_tests_check_on()\n    elif res.when == ""call"" and not res.passed:\n        TestRegistry.this_tests_check_off()\n    elif res.when == ""teardown"":\n        file_name, _, test_name = res.location\n        TestRegistry.this_tests_check_run(file_name, test_name)\n'"
tests/test_basic_data.py,0,"b'import pytest\nfrom utils.fakes import *\nimport sys\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.basic_data import intercept_args\n\n## run: pytest tests/test_basic_data.py -s\n\n\n# filename: test_basic_data.py\n\n## Test Cases\n\n    ## TO DO: Class DeviceDataLoader\n\n## Function intercept_args\n\ndef test_intercept_args():\n    dataset = TensorDataset(fake_basedata(n_in=4, batch_size=6))\n    dataloader = DataLoader(dataset, batch_size=5, shuffle=True, drop_last=True, timeout=3)\n    this_tests(intercept_args)\n\n    assert dataloader.init_kwargs[\'batch_size\'] == 5\n    assert dataloader.init_kwargs[\'shuffle\'] == True\n    assert dataloader.init_kwargs[\'drop_last\'] == True\n    assert dataloader.init_kwargs[\'timeout\'] == 3\n\n## Class DataBunch\n\ndef test_DataBunch_Create():\n    x_train,y_train = fake_basedata(n_in=3, batch_size=6),fake_basedata(n_in=3, batch_size=6)\n    x_valid,y_valid = fake_basedata(n_in=3, batch_size=3),fake_basedata(n_in=3, batch_size=3)\n    bs=5\n    train_ds,valid_ds = TensorDataset(x_train, y_train),TensorDataset(x_valid, y_valid)\n    data = DataBunch.create(train_ds, valid_ds, bs=bs)\n    this_tests(data.create)\n\n    assert 4 == len(data.dls)\n    assert 3 == len(data.train_dl)\n    assert 18 == len(data.train_ds)\n    assert 18 == len(data.fix_ds)\n    assert 2 == len(data.valid_dl)\n    assert 9 == len(data.valid_ds)\n\ndef test_DataBunch_no_valid_dl():\n    x_train,y_train = fake_basedata(n_in=3, batch_size=6),fake_basedata(n_in=3, batch_size=6)\n    bs=5\n    train_ds = TensorDataset(x_train, y_train)\n    data = DataBunch.create(train_ds, None, bs=bs)\n    this_tests(data.create)\n    data.valid_dl = None\n\n    assert 3 == len(data.dls)\n    assert 3 == len(data.train_dl)\n    assert 18 == len(data.train_ds)\n    assert 18 == len(data.fix_ds)\n    assert None == data.valid_dl\n\n## TO DO (?)ideally, call one_batch with type dataloader\ndef test_DataBunch_onebatch():\n    data = fake_data(n_in=4, n_out=5, batch_size=6)\n    this_tests(data.one_batch)\n    x,y = data.one_batch()\n    assert 4 == x[0].shape[0]\n    assert 6 == x.shape[0]\n    assert 6 == y.shape[0]\n\n\ndef test_DataBunch_oneitem():\n    data = fake_data()\n    this_tests(data.one_item)\n    x,y = data.one_item(item=1)\n    assert 1 == x.shape[0]\n    assert 1 == y.shape[0]\n\n\ndef test_DataBunch_show_batch(capsys):\n    data = fake_data()\n    this_tests(data.show_batch)\n    data.show_batch()\n    captured = capsys.readouterr()\n    match = re.findall(r\'tensor\', captured.out)\n    assert match\n\ndef test_DataBunch_save_load():\n    save_name = \'data_save.pkl\'\n    this_tests(DataBunch.save, load_data)\n\n    data = fake_data(n_in=4, n_out=5, batch_size=6)\n    data.save(save_name)\n    loaded_data = load_data(data.path, save_name, bs=6)\n    this_tests(loaded_data.one_batch)\n    x,y = loaded_data.one_batch()\n    assert 4 == x[0].shape[0]\n    assert 6 == x.shape[0]\n    assert 6 == y.shape[0]\n\n    # save/load using buffer\n    output_buffer = io.BytesIO()\n    data.save(output_buffer)\n    input_buffer = io.BytesIO(output_buffer.getvalue())\n    loaded_data = load_data(data.path, input_buffer, bs=6)\n    this_tests(loaded_data.one_batch)\n    x,y = loaded_data.one_batch()\n    assert 4 == x[0].shape[0]\n    assert 6 == x.shape[0]\n    assert 6 == y.shape[0]\n    os.remove(save_name)\n\ndef test_DeviceDataLoader_getitem():\n    this_tests(\'na\')\n    class DictDataset(Dataset):\n        def __getitem__(self, idx):\n            return {""a"":np.ones((3,)),""b"":np.zeros((2,))}\n        def __len__(self):\n            return 10\n\n    ds = DictDataset()\n    next(iter(DeviceDataLoader.create(ds)))\n'"
tests/test_basic_train.py,1,"b'""""""\nmodule: basic_train.py - Model fitting methods\ndocs  : https://docs.fast.ai/train.html\n""""""\n\nimport pytest\nfrom fastai.vision import *\nfrom fastai.utils.mem import *\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.fakes import *\nfrom utils.text import *\nfrom utils.mem import *\nfrom math import isclose\n\ntorch_preload_mem()\n\n@pytest.fixture(scope=""module"")\ndef data():\n    path = untar_data(URLs.MNIST_TINY)\n    data = ImageDataBunch.from_folder(path, ds_tfms=([], []), bs=2)\n    return data\n\n# this is not a fixture on purpose - the memory measurement tests are very sensitive, so\n# they need to be able to get a fresh learn object and not one modified by other tests.\ndef learn_large_unfit(data):\n    learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n    return learn\n\n@pytest.fixture(scope=""module"")\ndef learn(data): return learn_large_unfit(data)\n\ndef test_get_preds():\n    learn = fake_learner()\n    this_tests(learn.get_preds)\n    with CaptureStdout() as cs:\n        a = learn.get_preds()\n    assert learn.data.batch_size == len(a[1])\n\ndef test_freeze_to():\n    learn = fake_learner(layer_group_count=3)\n    this_tests(learn.freeze_to)\n    learn.freeze_to(1)\n    for i, param in enumerate(learn.model.parameters()):\n        # param 0 is weights in layer_group 0 and param 1 is bias in layer_group 0\n        # all params other than those should be frozen\n        if i >= 2: assert param.requires_grad == True\n        else:      assert param.requires_grad == False\n\ndef test_freeze():\n    learn = fake_learner(layer_group_count=3)\n    this_tests(learn.freeze)\n    learn.freeze()\n    for i, param in enumerate(learn.model.parameters()):\n        # 2 layer groups with 1 param in each should be frozen\n        if i >= 4: assert param.requires_grad == True\n        else:      assert param.requires_grad == False\n\ndef test_unfreeze():\n    learn = fake_learner(layer_group_count=4)\n    this_tests(learn.unfreeze)\n    for param in learn.model.parameters(): param.requires_grad=False\n    learn.unfreeze()\n    for param in learn.model.parameters(): assert param.requires_grad == True\n\ndef check_learner(learn, model_summary_before, train_items_before):\n    # basic checks\n    #assert learn.recorder\n    assert learn.model\n    assert train_items_before == len(learn.data.train_ds.items)\n\n    if model_summary_before is not None:\n        assert model_summary_before == learn.summary(), f""model summary before and after""\n\n    # XXX: could use more sanity checks\n\ndef test_purge():\n    learn = fake_learner() # don\'t use fixture - we mess with the object\n    this_tests(learn.purge)\n\n    # just testing we can run each of these\n    learn.purge()\n    learn.purge(clear_opt=False)\n\n    # writable dir\n    model_dir_orig = learn.model_dir\n    learn.model_dir = ""."" # should succeed\n    learn.purge()\n    learn.model_dir = model_dir_orig\n\ndef test_save_load(learn):\n    this_tests(learn.save, learn.load, learn.purge)\n    name = \'mnist-tiny-test-save-load\'\n    train_items_before = len(learn.data.train_ds.items)\n    model_summary_before = learn.summary()\n\n    # testing that all these various sequences don\'t break each other\n    model_path = learn.save(name, return_path=True)\n    _ = learn.load(name, purge=True)\n    learn.data.sanity_check()\n    check_learner(learn, model_summary_before, train_items_before)\n\n    learn.purge()\n    _ = learn.load(name)\n    _ = learn.load(name)\n    model_path = learn.save(name, return_path=True)\n    _ = learn.load(name, purge=True)\n    check_learner(learn, model_summary_before, train_items_before)\n\n    # Test save/load using bytes streams\n    output_buffer = io.BytesIO()\n    learn.save(output_buffer)\n    learn.purge()\n    input_buffer = io.BytesIO(output_buffer.getvalue())\n    _ = learn.load(input_buffer)\n    check_learner(learn, model_summary_before, train_items_before)\n\n    # cleanup\n    if os.path.exists(model_path): os.remove(model_path)\n\ndef subtest_save_load_mem(data):\n    learn = learn_large_unfit(data)\n    name = \'mnist-tiny-test-save-load\'\n    #learn.fit_one_cycle(1)\n\n    # save should consume no extra used or peaked memory\n    with GPUMemTrace(on_exit_report=False) as mtrace:\n        model_path = learn.save(name, return_path=True)\n    check_mtrace(used_exp=0, peaked_exp=0, mtrace=mtrace, abs_tol=10, ctx=""save"")\n\n    # load w/ purge still leaks some the first time it\'s run\n    with GPUMemTrace(on_exit_report=False) as mtrace:\n        learn.load(name, purge=True)\n    # XXX: very different numbers if done w/o fit first 42 8, w/ fit 24 16\n    check_mtrace(used_exp=18, peaked_exp=8, mtrace=mtrace, abs_tol=10, ctx=""load"")\n\n    # subsequent multiple load w/o purge should consume no extra used memory\n    with GPUMemTrace(on_exit_report=False) as mtrace:\n        learn.load(name, purge=False)\n        learn.load(name, purge=False)\n    check_mtrace(used_exp=0, peaked_exp=20, mtrace=mtrace, abs_tol=10, ctx=""load x 2"")\n\n    # subsequent multiple load w/ purge should consume no extra used memory\n    with GPUMemTrace(on_exit_report=False) as mtrace:\n        learn.load(name, purge=True)\n        learn.load(name, purge=True)\n    check_mtrace(used_exp=0, peaked_exp=20, mtrace=mtrace, abs_tol=10, ctx=""load x 2 2nd time"")\n\n    # purge + load w/ default purge should consume no extra used memory\n    with GPUMemTrace(on_exit_report=False) as mtrace:\n        learn.purge()\n        learn.load(name)\n    check_mtrace(used_exp=0, peaked_exp=0, mtrace=mtrace, abs_tol=10, ctx=""purge+load"")\n\n    if os.path.exists(model_path): os.remove(model_path)\n\ndef test_destroy():\n    msg = ""this object has been destroyed""\n    learn = fake_learner()\n    this_tests(learn.destroy)\n    with CaptureStdout() as cs: learn.destroy()\n    assert ""this Learner object self-destroyed"" in cs.out\n\n    # should be able to re-run learn.destroy multiple times for nb convenience\n    with CaptureStdout() as cs: learn.destroy()\n    assert msg in cs.out\n\n    # should be able to run normal methods, except they are no-ops and say that they are\n    with CaptureStdout() as cs: learn.fit(1)\n    assert msg in cs.out\n\n    # should be able to call attributes, except they are gone and say so\n    # unless they are __getattr__\' loaded from Learner, in which case they are still normal\n    for attr in [\'data\', \'model\', \'callbacks\']:\n        with CaptureStdout() as cs: val = getattr(learn, attr, None)\n        assert msg in cs.out, attr\n        assert val is None, attr\n\n    # check that `destroy` didn\'t break the Learner class\n    learn = fake_learner()\n    with CaptureStdout() as cs: learn.fit(1)\n    assert ""epoch"" in cs.out\n    assert ""train_loss"" in cs.out\n\ndef subtest_destroy_mem(data):\n    with GPUMemTrace(on_exit_report=False) as mtrace:\n        learn = learn_large_unfit(data)\n    load_used, load_peaked = mtrace.data()\n\n    # destroy should free most of the memory that was allocated during load (training, etc.)\n    with GPUMemTrace(on_exit_report=False) as mtrace:\n        with CaptureStdout() as cs: learn.destroy()\n    check_mtrace(used_exp=-load_used, peaked_exp=-load_peaked, mtrace=mtrace, abs_tol=10, ctx=""destroy"")\n\n# memory tests behave differently when run individually and in a row, since\n# memory utilization patterns are very inconsistent - would require a full gpu\n# card reset before each test to be able to test consistently, so will run them\n# all in a precise sequence\n@pytest.mark.cuda\ndef test_memory(data):\n    this_tests(Learner.save, Learner.load, Learner.purge, Learner.destroy)\n\n    # A big difficulty with measuring memory consumption is that it varies quite\n    # wildly from one GPU model to another.\n    #\n    # Perhaps we need sets of different expected numbers per developer\'s GPUs?\n    # override check_mem above in tests.utils.mem with report_mem to acquire a new set\n    #\n    # So for now just testing the specific card I have until a better way is found.\n    dev_name = torch.cuda.get_device_name(None)\n    if dev_name != \'GeForce GTX 1070 Ti\':\n        pytest.skip(f""currently only matched for mem usage on specific GPU models, {dev_name} is not one of them"")\n\n    subtest_save_load_mem(data)\n    subtest_destroy_mem(data)\n\ndef test_export_load_learner():\n    export_file = \'export.pkl\'\n    for should_destroy in [False, True]:\n        learn = fake_learner()\n        this_tests(learn.export, load_learner, learn.summary)\n        path = learn.path\n        model_summary_before = learn.summary()\n\n        print(f""\\n*** Testing w/ learn.export(destroy={should_destroy})"")\n        with CaptureStdout() as cs: learn.export(destroy=should_destroy)\n        learn = load_learner(path)\n        check_empty_learner(learn)\n        if os.path.exists(export_file): os.remove(export_file)\n\n    print(f""\\n*** Testing learn.export to buffer"")\n    learn = fake_learner()\n    path = learn.path\n\n    output_buffer = io.BytesIO()\n    with CaptureStdout() as cs:\n        learn.export(output_buffer, destroy=should_destroy)\n    input_buffer = io.BytesIO(output_buffer.getvalue())\n    learn = load_learner(path, input_buffer)\n    check_empty_learner(learn)\n\n\ndef check_empty_learner(learn):\n    # export removes data, so train_items_before=0\n    # also testing learn.summary here on learn created from `load_learner`\n    check_learner(learn, model_summary_before=None, train_items_before=0)\n\n    try:\n        learn.summary()\n    except:\n        assert ""This is an empty `Learner`"" in str(sys.exc_info()[1])\n    else:\n        assert False, ""should have failed""\n\n\n# XXX: dupe with test_memory - integrate (moved from test_vision_train.py)\ndef test_model_load_mem_leak():\n    ""testing memory leak on load""\n    pytest.xfail(""memory leak in learn.load()"")\n\n    path = untar_data(URLs.MNIST_TINY)\n    data = ImageDataBunch.from_folder(path, ds_tfms=([], []), bs=2)\n    learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n    this_tests(learn.load)\n    gpu_mem_reclaim() # baseline\n    used_before = gpu_mem_get_used()\n\n    name = \'mnist-tiny-test-load-mem-leak\'\n    model_path = learn.save(name, return_path=True)\n    _ = learn.load(name)\n    if os.path.exists(model_path): os.remove(model_path)\n    used_after = gpu_mem_get_used()\n\n    # models.resnet18 loaded in GPU RAM is about 50MB\n    # calling learn.load() of a saved and then instantly re-loaded model shouldn\'t require more GPU RAM\n    # XXX: currently w/o running gc.collect() this temporarily leaks memory and causes fragmentation - the fragmentation can\'t be tested from here, but it\'ll get automatically fixed once load is fixed. load() must unload first the previous model, gc.collect() and only then load the new one onto cuda.\n    assert isclose(used_before, used_after, abs_tol=6), f""load() and used GPU RAM: before load(): {used_before}, after: {used_after}""\n\n    # this shows how it should have been\n    gc.collect()\n    gpu_cache_clear()\n    used_after_reclaimed = gpu_mem_get_used()\n    # XXX: not sure where 6MB get lost still but for now it\'s a small leak - need to test with a bigger model\n    assert isclose(used_before, used_after_reclaimed, abs_tol=6),f""load() and used GPU RAM: before load(): {used_before}, after: {used_after}, after gc.collect() {used_after_reclaimed} used""\n'"
tests/test_batchnom_issue_minimal.py,4,"b""from fastai.gen_doc.doctest import this_tests\nimport torch, torch.nn as nn\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data.dataloader import DataLoader\nimport pytest\n\ndef _run_batch_size_test(bs):\n    dataset = TensorDataset(torch.randn(9, 128), torch.randint(0,3,(9,)))\n    dataloader = DataLoader(dataset, batch_size=bs)\n    simple_model = nn.Sequential(nn.BatchNorm1d(128), nn.Linear(128,4))\n    for (x,y) in iter(dataloader):\n        z = simple_model(x)\n\n# This test will fail as the last batch will have a size of 1\n@pytest.mark.skip\ndef test_batch_size_4():\n    this_tests('na')\n    _run_batch_size_test(4)\n\n# This test succeeds\ndef test_batch_size_3():\n    this_tests('na')\n    _run_batch_size_test(3)\n"""
tests/test_callback.py,0,"b'import pytest, fastai\nfrom fastai.vision import *\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.fakes import fake_data\nfrom utils.text import CaptureStdout\n\nn_in, n_out = 3, 2\n@pytest.fixture(scope=""module"")\ndef data(): return fake_data(n_in=n_in, n_out=n_out)\n\n@pytest.fixture(scope=""module"")\ndef model(): return nn.Linear(n_in, n_out)\n\ncol_a = 5678722929\ncol_b = 1237892223\nclass DummyCallback(LearnerCallback):\n    _order=-20\n    def __init__(self, learn):\n        super().__init__(learn)\n        self.dummy = 0\n\n    def on_train_begin(self, **kwargs):\n        self.learn.recorder.add_metric_names([\'col_a\', \'col_b\'])\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        # add dummy metrics\n        return {\'last_metrics\': last_metrics + [col_a, col_b]}\n\ndef check_dummy_metric(out):\n    for s in [\'col_a\', col_a, \'col_b\', col_b]:\n        assert str(s) in out, f""{s} is in the output:\\n{out}""\n\ndef test_callbacks_learner(data, model):\n    this_tests(Callback)\n\n    # single callback in learner constructor\n    learn = Learner(data, model, metrics=accuracy, callback_fns=DummyCallback)\n    with CaptureStdout() as cs: learn.fit_one_cycle(2)\n    check_dummy_metric(cs.out)\n\n    # list of callbacks in learner constructor\n    learn = Learner(data, model, metrics=accuracy, callback_fns=[DummyCallback])\n    with CaptureStdout() as cs: learn.fit_one_cycle(2)\n    check_dummy_metric(cs.out)\n\n    # single callback append\n    learn = Learner(data, model, metrics=accuracy)\n    learn.callbacks.append(DummyCallback(learn))\n    with CaptureStdout() as cs: learn.fit_one_cycle(2)\n    check_dummy_metric(cs.out)\n\n    # list of callbacks append: python\'s append, so append([x]) will not do the right\n    # thing, so it\'s expected to fail\n    learn = Learner(data, model, metrics=[accuracy])\n    learn.callbacks.append([DummyCallback(learn)])\n    error = \'\'\n    try:\n        with CaptureStdout() as cs: learn.fit_one_cycle(2)\n    except Exception as e:\n        error = str(e)\n    error_pat = ""\'list\' object has no attribute \'on_train_begin\'""\n    assert error_pat in error, f""{error_pat} is in the exception:\\n{error}""\n\ndef test_callbacks_fit(data, model):\n    learn = Learner(data, model, metrics=accuracy)\n    this_tests(Callback)\n\n    for func in [\'fit\', \'fit_one_cycle\']:\n        fit_func = getattr(learn, func)\n\n        # single callback\n        with CaptureStdout() as cs: fit_func(2, callbacks=DummyCallback(learn))\n        check_dummy_metric(cs.out)\n\n        # list of callbacks\n        with CaptureStdout() as cs: fit_func(2, callbacks=[DummyCallback(learn)])\n        check_dummy_metric(cs.out)\n'"
tests/test_callbacks_cpu_mem.py,0,"b'import pytest\nfrom fastai.callbacks.cpu_mem import *\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.fakes import *\nfrom utils.text import CaptureStdout\n\n@pytest.mark.skip(""occassional random failures"")\n@pytest.mark.cuda\ndef test_peak_mem_metric():\n    learn = fake_learner()\n    learn.callbacks.append(CpuPeakMemMetric(learn))\n    this_tests(CpuPeakMemMetric)\n    with CaptureStdout() as cs:\n        learn.fit_one_cycle(3, max_lr=1e-2)\n    for s in [\'cpu used\', \'cpu_peak\']:\n        assert s in cs.out, f""expecting \'{s}\' in \\n{cs.out}""\n    # XXX: needs a better test to assert some numbers here (at least >0)\n    # epochs 2-3 it shouldn\'t allocate more general or CPU RAM\n    for s in [\'0         0\']:\n        assert s in cs.out, f""expecting \'{s}\' in \\n{cs.out}""\n'"
tests/test_callbacks_csv_logger.py,0,"b'import pytest, re\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.fakes import *\nfrom utils.text import CaptureStdout\n\ndef create_metrics_dataframe(learn):\n    ""Converts metrics stored in `Recorder` into dataframe.""\n    records = [\n        [i, loss, val_loss, *itemize(epoch_metrics)]\n        for i, (loss, val_loss, epoch_metrics)\n        in enumerate(zip(\n            get_train_losses(learn),\n            learn.recorder.val_losses,\n            learn.recorder.metrics))]\n    return pd.DataFrame(records, columns=learn.recorder.names[:-1])\n\ndef convert_into_dataframe(buffer):\n    ""Converts data captured from `fastprogress.ConsoleProgressBar` into dataframe.""\n    lines = buffer.split(\'\\n\')\n    header, *lines = [l.strip() for l in lines if l and not l.startswith(\'Total\')]\n    header = header.split()[:]\n    floats = [[float_or_x(x) for x in line.split()[:]] for line in lines]\n    records = [dict(zip(header, metrics_list)) for metrics_list in floats]\n    df = pd.DataFrame(records, columns=header)\n    df[\'epoch\'] = df[\'epoch\'].astype(int)\n    return df\n\ndef get_train_losses(learn):\n    ""Returns list of training losses at the end of each training epoch.""\n    np_losses = [to_np(l).item() for l in learn.recorder.losses]\n    batch_size = len(learn.data.train_dl)\n    return [batch[-1] for batch in partition(np_losses, batch_size)]\n\ndef itemize(metrics):\n    return [m.item() for m in metrics]\n\ndef test_logger():\n    learn = fake_learner()\n    learn.metrics = [accuracy, error_rate]\n    learn.callback_fns.append(callbacks.CSVLogger)\n    this_tests(callbacks.CSVLogger)\n    with CaptureStdout() as cs: learn.fit_one_cycle(3)\n    csv_df = learn.csv_logger.read_logged_file()\n    stdout_df = convert_into_dataframe(cs.out)\n    pd.testing.assert_frame_equal(csv_df, stdout_df, check_exact=False, check_less_precise=2)\n    recorder_df = create_metrics_dataframe(learn)\n    # XXX: there is a bug in pandas:\n    # https://github.com/pandas-dev/pandas/issues/25068#issuecomment-460014120\n    # which quite often fails on CI.\n    # once it\'s resolved can change the setting back to check_less_precise=True (or better =3), until then using =2 as it works, but this check is less good.\n    csv_df_notime = csv_df.drop([\'time\'], axis=1)\n    pd.testing.assert_frame_equal(csv_df_notime, recorder_df, check_exact=False, check_less_precise=2)\n\n@pytest.fixture(scope=""module"", autouse=True)\ndef cleanup(request):\n    """"""Cleanup the autogenerated file once we are finished.""""""\n    def remove_history_csv():\n        file = ""history.csv""\n        if os.path.exists(file): os.remove(file)\n    request.addfinalizer(remove_history_csv)\n'"
tests/test_callbacks_hooks.py,1,"b'import pytest, torch, fastai\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.basics import *\nfrom fastai.callbacks import *\nfrom fastai.callbacks.hooks import *\nfrom fastai.vision import *\nfrom fastai.text import *\nfrom fastai.tabular import *\nfrom fastai.collab import *\n\nuse_gpu = torch.cuda.is_available()\n\n@pytest.fixture(scope=""module"")\ndef mnist_path():\n    path = untar_data(URLs.MNIST_TINY)\n    return path\n\ndef test_model_summary_vision(mnist_path):\n    this_tests(model_summary)\n    path = mnist_path\n    data = ImageDataBunch.from_folder(path, ds_tfms=([], []), bs=2)\n    learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n    _ = model_summary(learn)\n\n@pytest.mark.xfail(reason = ""Expected Fail, text models not supported yet."")\ndef test_model_summary_text():\n    this_tests(model_summary)\n    path = untar_data(URLs.IMDB_SAMPLE)\n    data_lm = TextLMDataBunch.from_csv(path, \'texts.csv\')\n    learn = language_model_learner(data_lm, pretrained_model=None)\n    _ = model_summary(learn)\n\ndef test_model_summary_tabular():\n    this_tests(model_summary)\n    path = untar_data(URLs.ADULT_SAMPLE)\n    dep_var = \'salary\'\n    cat_names = [\'workclass\', \'education\', \'marital-status\', \'occupation\', \'relationship\', \'race\']\n    cont_names = [\'age\', \'fnlwgt\', \'education-num\']\n    procs = [FillMissing, Categorify]\n    df = pd.read_csv(path/\'adult.csv\')\n    data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n                               .split_by_idx(list(range(800,1000)))\n                               .label_from_df(cols=dep_var)\n                               .databunch(bs=2))\n    learn = tabular_learner(data, layers=[200,100], metrics=accuracy)\n    _ = model_summary(learn)\n\ndef test_model_summary_collab():\n    this_tests(model_summary)\n    path = untar_data(URLs.ML_SAMPLE)\n    ratings = pd.read_csv(path/\'ratings.csv\')\n    series2cat(ratings, \'userId\', \'movieId\')\n    data = CollabDataBunch.from_df(ratings, seed=42, bs=2)\n    y_range = [0,5.5]\n    learn = collab_learner(data, n_factors=50, y_range=y_range)\n    _ = model_summary(learn)\n\n#model_summary takes a Learner now\n#def test_model_summary_nn_module():\n#    _ = model_summary(nn.Conv2d(16,16,3,padding=1))\n#\n#def test_model_summary_nn_modules():\n#    class BasicBlock(Module):\n#        def __init__(self):\n#            super().__init__()\n#            self.conv1 = conv2d(16,16,3,1)\n#            self.conv2 = conv2d(16,16,3,1)\n#        def forward(self, x):\n#            x = self.conv1(x)\n#            x = self.conv2(x)\n#            return x\n#    _ = model_summary(BasicBlock())\n\ndef test_hook_output_basics(mnist_path):\n    this_tests(hook_output)\n    data = ImageDataBunch.from_folder(mnist_path, size=128, bs=2)\n    learn = cnn_learner(data, models.resnet18)\n    # need to train to get something meaningful, but for just checking shape its fine w/o it\n    m = learn.model.eval()\n    x,y = data.train_ds[0]\n    xb,_ = data.one_item(x)\n    if use_gpu: xb = xb.cuda()\n\n    def hooked(cat=y):\n        with hook_output(m[0]) as hook_forward:\n            preds = m(xb)\n        with hook_output(m[0]) as hook_backward:\n            preds = m(xb)\n            preds[0,int(cat)].backward()\n        return hook_forward, hook_backward\n\n    for hook in hooked():\n        acts = hook.stored[0].cpu()\n        assert list(acts.shape) == [512, 4, 4], ""activations via hooks""\n'"
tests/test_callbacks_mem.py,0,"b'import pytest\nfrom fastai.callbacks.mem import *\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.fakes import *\nfrom utils.text import CaptureStdout\n\n@pytest.mark.skip(""occassional random failures"")\n@pytest.mark.cuda\ndef test_peak_mem_metric():\n    learn = fake_learner()\n    learn.callbacks.append(PeakMemMetric(learn))\n    this_tests(PeakMemMetric)\n    with CaptureStdout() as cs:\n        learn.fit_one_cycle(3, max_lr=1e-2)\n    for s in [\'cpu\', \'used\', \'peak\', \'gpu\']:\n        assert s in cs.out, f""expecting \'{s}\' in \\n{cs.out}""\n    # XXX: needs a better test to assert some numbers here (at least >0)\n    # epochs 2-3 it shouldn\'t allocate more general or GPU RAM\n    for s in [\'0         0         0         0\']:\n        assert s in cs.out, f""expecting \'{s}\' in \\n{cs.out}""\n'"
tests/test_callbacks_misc.py,0,"b'import pytest\nfrom fastai.callbacks.misc import *\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.fakes import *\nfrom utils.text import CaptureStdout\n\ndef stop_after_n_batches_run_n_check(learn, bs, run_n_batches_exp):\n    has_batches = len(learn.data.train_ds)//bs\n    with CaptureStdout() as cs:\n        learn.fit_one_cycle(3, max_lr=1e-2)\n    for s in [\'train_loss\', \'valid_loss\']:\n        assert s in cs.out, f""expecting \'{s}\' in \\n{cs.out}""\n\n    # test that epochs are stopped at epoch 0\n    assert ""\\n0"" in cs.out, ""expecting epoch0""\n    assert ""\\n1"" not in cs.out, ""epoch 1 shouldn\'t run""\n\n    # test that only run_n_batches_exp batches were run\n    run_n_batches_got = len(learn.recorder.losses)\n    assert run_n_batches_got == run_n_batches_exp, f""should have run only {run_n_batches_exp}, but got {run_n_batches_got}""\n\ndef test_stop_after_n_batches():\n    this_tests(StopAfterNBatches)\n\n    # this should normally give us 10 batches for train_ds\n    train_length = 20\n    bs = 2\n    # but we only want to run 2\n    run_n_batches = 2\n\n    print()\n    # 1. global assignment\n    defaults_extra_callbacks_bak = defaults.extra_callbacks\n    defaults.extra_callbacks = [StopAfterNBatches(n_batches=run_n_batches)]\n    learn = fake_learner(train_length=train_length, batch_size=bs)\n    stop_after_n_batches_run_n_check(learn, bs, run_n_batches)\n    # restore\n    defaults.extra_callbacks = defaults_extra_callbacks_bak\n\n    # 2. dynamic assignment\n    learn = fake_learner(train_length=train_length, batch_size=bs)\n    learn.callbacks.append(StopAfterNBatches(n_batches=run_n_batches))\n    stop_after_n_batches_run_n_check(learn, bs, run_n_batches)\n'"
tests/test_collab_train.py,0,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.basics import *\nfrom fastai.collab import *\n\n@pytest.fixture(scope=""module"")\ndef learn():\n    path = untar_data(URLs.ML_SAMPLE)\n    ratings = pd.read_csv(path/\'ratings.csv\')\n    series2cat(ratings, \'userId\',\'movieId\')\n    data = CollabDataBunch.from_df(ratings)\n    learn = collab_learner(data, n_factors=50, y_range=(0.,5.))\n    learn.fit_one_cycle(3, 5e-3)\n    return learn\n\ndef test_val_loss(learn):\n    this_tests(learn.validate, CollabDataBunch.from_df, collab_learner)\n    assert learn.validate()[0] < 0.8\n'"
tests/test_core.py,6,"b'import pytest, torch\nimport numpy as np\nfrom fastai.basics import *\nfrom fastai.gen_doc.doctest import this_tests\nfrom tempfile import TemporaryDirectory\nfrom collections import Counter\n\ndef test_cpus():\n    this_tests(num_cpus)\n    assert num_cpus() >= 1\n\n@pytest.mark.parametrize(""p, q, expected"", [\n    (None, None, []),\n    (\'hi\', None, [\'hi\']),\n    ([1,2],None, [1,2]),\n    (5  , 1    , [5]),\n    (5  , [1,1], [5, 5]),\n    ([5], 1    , [5]),\n    ([5], [1,1], [5, 5]),\n    (""ab""  , ""cd""        , [""ab"", ""ab""]),\n    (""ab""  , [""cd"", ""ef""], [""ab"", ""ab""]),\n    ([""ab""], ""cd""        , [""ab"", ""ab""]),\n    ([""ab""], [""cd"", ""ef""], [""ab"", ""ab""]),\n])\ndef test_listify(p, q, expected):\n    this_tests(listify)\n    assert listify(p, q) == expected\n\ndef test_recurse():\n    this_tests(recurse)\n    def to_plus(x, a=1): return recurse(lambda x,a: x+a, x, a)\n    assert to_plus(1) == 2\n    assert to_plus([1,2,3]) == [2,3,4]\n    assert to_plus([1,2,3], a=3) == [4,5,6]\n    assert to_plus({\'a\': 1, \'b\': 2, \'c\': 3}) == {\'a\': 2, \'b\': 3, \'c\': 4}\n    assert to_plus({\'a\': 1, \'b\': 2, \'c\': 3}, a=2) == {\'a\': 3, \'b\': 4, \'c\': 5}\n    assert to_plus({\'a\': 1, \'b\': [1,2,3], \'c\': {\'d\': 4, \'e\': 5}}) == {\'a\': 2, \'b\': [2, 3, 4], \'c\': {\'d\': 5, \'e\': 6}}\n\ndef test_ifnone():\n    this_tests(ifnone)\n    assert ifnone(None, 5) == 5\n    assert ifnone(5, None) == 5\n    assert ifnone(1, 5)    == 1\n    assert ifnone(0, 5)    == 0\n\ndef test_chunks():\n    this_tests(chunks)\n    ls = [0,1,2,3]\n    assert([a for a in chunks(ls, 2)] == [[0,1],[2,3]])\n    assert([a for a in chunks(ls, 4)] == [[0,1,2,3]])\n    assert([a for a in chunks(ls, 1)] == [[0],[1],[2],[3]])\n\ndef test_uniqueify():\n    this_tests(uniqueify)\n    assert uniqueify([1,1,3,3,5]) == [1,3,5]\n    assert uniqueify([1,3,5])     == [1,3,5]\n    assert uniqueify([1,1,1,3,5]) == [1,3,5]\n\ndef test_listy():\n    this_tests(is_listy)\n    assert is_listy([1,1,3,3,5])      == True\n    assert is_listy((1,1,3,3,5))      == True\n    assert is_listy([1,""2"",3,3,5])    == True\n    assert is_listy((1,""2"",3,3,5))    == True\n    assert is_listy(1)                == False\n    assert is_listy(""2"")              == False\n    assert is_listy({1, 2})           == False\n    assert is_listy(set([1,1,3,3,5])) == False\n\ndef test_tuple():\n    this_tests(is_tuple)\n    assert is_tuple((1,1,3,3,5)) == True\n    assert is_tuple([1])         == False\n    assert is_tuple(1)           == False\n\ndef test_dict():\n    this_tests(is_dict)\n    assert is_dict({1:2,3:4})  == True\n    assert is_dict([1,2,3])    == False\n    assert is_dict((1,2,3))    == False\n\ndef test_noop():\n    this_tests(noop)\n    assert noop(1) == 1\n\ndef test_to_int():\n    this_tests(to_int)\n    assert to_int((""1"",""1"",""3"",""3"",""5"")) == [1,1,3,3,5]\n    assert to_int([1,""2"",3.3,3,5])       == [1,2,3,3,5]\n    assert to_int(1)                     == 1\n    assert to_int(1.2)                   == 1\n    assert to_int(""1"")                   == 1\n\ndef test_partition_functionality():\n    this_tests(partition)\n\n    def test_partition(a, sz, ex):\n        result = partition(a, sz)\n        assert len(result) == len(ex)\n        assert all([a == b for a, b in zip(result, ex)])\n\n    a = [1,2,3,4,5]\n\n    sz = 2\n    ex = [[1,2],[3,4],[5]]\n    test_partition(a, sz, ex)\n\n    sz = 3\n    ex = [[1,2,3],[4,5]]\n    test_partition(a, sz, ex)\n\n    sz = 1\n    ex = [[1],[2],[3],[4],[5]]\n    test_partition(a, sz, ex)\n\n    sz = 6\n    ex = [[1,2,3,4,5]]\n    test_partition(a, sz, ex)\n\n    sz = 3\n    a = []\n    result = partition(a, sz)\n    assert len(result) == 0\n\ndef test_idx_dict():\n    this_tests(idx_dict)\n    assert idx_dict(np.array([1,2,3]))=={1: 0, 2: 1, 3: 2}\n    assert idx_dict([1, 2, 3])=={1: 0, 2: 1, 3: 2}\n    assert idx_dict((1, 2, 3))=={1: 0, 2: 1, 3: 2}\n\ndef test_find_classes():\n    this_tests(find_classes)\n    path = Path(\'./classes_test\').resolve()\n    os.mkdir(path)\n    classes = [\'class_0\', \'class_1\', \'class_2\']\n    for class_num in classes:\n        os.mkdir(path/class_num)\n    try: assert [o.name for o in find_classes(path)]==classes\n    finally: shutil.rmtree(path)\n\ndef test_arrays_split():\n    this_tests(arrays_split)\n    a = arrays_split([0,3],[1, 2, 3, 4, 5], [\'a\', \'b\', \'c\', \'d\', \'e\'])\n    b = [(array([1, 4]),array([\'a\', \'d\'])), (array([5, 2]),(array([\'e\',\'b\'])))]\n    np.testing.assert_array_equal(a,b)\n\n    c = arrays_split([0,3],[1, 2, 3, 4, 5])\n    d = [(array([1, 4]),), (array([5, 2]),)]\n    np.testing.assert_array_equal(c,d)\n\n    with pytest.raises(Exception): arrays_split([0,5],[1, 2, 3, 4, 5])\n    with pytest.raises(Exception): arrays_split([0,3],[1, 2, 3, 4, 5], [1, 2, 3, 4])\n\ndef test_random_split():\n    this_tests(random_split)\n    valid_pct = 0.4\n    a = [len(arr) for arr in random_split(valid_pct, [1,2,3,4,5], [\'a\', \'b\', \'c\', \'d\', \'e\'])]\n    b = [2, 2]\n    assert a == b\n\n    with pytest.raises(Exception): random_split(1.1, [1,2,3])\n    with pytest.raises(Exception): random_split(0.1, [1,2,3], [1,2,3,4])\n\ndef test_camel2snake():\n    this_tests(camel2snake)\n    a = camel2snake(\'someString\')\n    b = \'some_string\'\n    assert a == b\n\n    c = camel2snake(\'some2String\')\n    d = \'some2_string\'\n    assert c == d\n\n    e = camel2snake(\'longStringExmpl\')\n    f = \'long_string_exmpl\'\n    assert e == f\n\ndef test_even_mults():\n    this_tests(even_mults)\n    a = even_mults(start=1, stop=8, n=4)\n    b = array([1.,2.,4.,8.])\n    np.testing.assert_array_equal(a,b)\n\ndef test_series2cat():\n    this_tests(series2cat)\n    df = pd.DataFrame({\'col1\': [1, 2], \'col2\': [3, 4], \'col3\':[5, 6]})\n    cols = \'col1\',\'col2\'\n    series2cat(df,*cols)\n    for col in cols:\n        assert (df[col].dtypes == \'category\')\n    assert (df[\'col3\'].dtypes == \'int64\')\n\ndef test_download_url():\n    this_tests(download_url)\n    for link, ext in [(URLs.MNIST_TINY, \'tgz\')]:\n        url = f\'{link}.{ext}\'\n        path = URLs.LOCAL_PATH/\'data\'/\'tmp\'\n        try:\n            os.makedirs(path, exist_ok=True)\n            filepath = path/url2name(url)\n            download_url(url, filepath)\n            assert os.path.getsize(filepath) > 0\n        finally:\n            shutil.rmtree(path)\n\ndef test_join_paths():\n    this_tests(join_path)\n    assert join_path(\'f\') == Path(\'f\')\n    assert join_path(\'f\', Path(\'dir\')) == Path(\'dir/f\')\n    assert join_paths([\'f1\',\'f2\']) == [Path(\'f1\'), Path(\'f2\')]\n    assert set(join_paths({\'f1\',\'f2\'}, Path(\'dir\'))) == {Path(\'dir/f1\'), Path(\'dir/f2\')}\n\ndef test_df_names_to_idx():\n    this_tests(df_names_to_idx)\n    df = pd.DataFrame({\'col1\': [1,2], \'col2\': [3,4], \'col3\':[5,6]})\n    assert df_names_to_idx([\'col1\',\'col3\'], df) == [0, 2]\n\ndef test_one_hot():\n    this_tests(one_hot)\n    assert all(one_hot([0,-1], 5) == np.array([1,0,0,0,1]))\n\ndef test_subplots_multi_row_cols():\n    this_tests(subplots)\n    axs = subplots(4, 4, figsize=(10, 10))\n    assert len(axs) == 4\n    assert (len(axs[0]) == 4)\n    assert (len(axs.flatten()) == 16)\n\ndef test_subplots_single():\n    this_tests(subplots)\n    axs = subplots(1,1, figsize=(10, 10))\n    assert (len(axs) == 1)\n    assert (len(axs[0]) == 1)\n\ndef test_is1d():\n    this_tests(is1d)\n    assert is1d([1, 2, 3, 4])\n    assert is1d((1, 2, 3, 4))\n    assert not is1d([[1, 2], [3, 4]])\n    assert not is1d(np.array(((1,2), (3,4))))\n\ndef test_itembase_eq():\n    this_tests(ItemBase.__eq__, Category, FloatItem, MultiCategory)\n    c1 = Category(0, \'cat\')\n    c2 = Category(1, \'dog\')\n    c3 = Category(0, \'cat\')\n    assert c1 == c1\n    assert c1 != c2\n    assert c1 == c3\n\n    f1 = FloatItem(0.1)\n    f2 = FloatItem(1.2)\n    f3 = FloatItem(0.1)\n    assert f1 == f1\n    assert f1 != f2\n    assert f1 == f3\n\n    mc1 = MultiCategory(np.array([1, 0]), [\'cat\'], [0])\n    mc2 = MultiCategory(np.array([1, 1]), [\'cat\', \'dog\'], [0, 1])\n    mc3 = MultiCategory(np.array([1, 0]), [\'cat\'], [0])\n\n    assert mc1 == mc1\n    assert mc1 != mc2\n    assert mc1 == mc3\n\n    # tensors are used instead of arrays\n    mc4 = MultiCategory(torch.Tensor([1, 0]), [\'cat\'], [0])\n    mc5 = MultiCategory(torch.Tensor([1, 1]), [\'cat\', \'dog\'], [0, 1])\n    mc6 = MultiCategory(torch.Tensor([1, 0]), [\'cat\'], [0])\n\n    assert mc4 == mc4\n    assert mc4 != mc5\n    assert mc4 == mc6\n\n    class TestItemBase(ItemBase):\n        def __init__(self, data):\n            self.data = data\n\n    # data is a list of objects\n    t1 = TestItemBase([torch.Tensor([1, 2]), torch.Tensor([3, 4])])\n    t2 = TestItemBase([torch.Tensor([2, 3]), torch.Tensor([3, 4])])\n    t3 = TestItemBase([torch.Tensor([1, 2]), torch.Tensor([3, 4])])\n\n    assert t1 == t1\n    assert t1 != t2\n    assert t1 == t3\n\n    t4 = TestItemBase([1, 2])\n    t5 = TestItemBase([1])\n    t6 = TestItemBase([1, 2])\n\n    assert t4 == t4\n    assert t4 != t5\n    assert t4 == t6\n\n    t7 = TestItemBase([[1]])\n    t8 = TestItemBase([1])\n    t9 = TestItemBase([[1]])\n\n    assert t7 == t7\n    assert t7 != t8\n    assert t7 == t9\n\ndef test_itembase_hash():\n    this_tests(ItemBase.__eq__, Category.__hash__, FloatItem.__hash__, MultiCategory.__hash__)\n\n    c1 = Category(0, \'cat\')\n    c2 = Category(1, \'dog\')\n    c3 = Category(0, \'cat\')\n    assert hash(c1) == hash(c3)\n    assert hash(c1) != hash(c2)\n    assert Counter([c1, c2, c3]) == {c1: 2, c2: 1}\n\n    f1 = FloatItem(0.1)\n    f2 = FloatItem(1.2)\n    f3 = FloatItem(0.1)\n    assert hash(f1) == hash(f3)\n    assert hash(f1) != hash(f2)\n    assert Counter([f1, f2, f3]) == {f1: 2, f2: 1}\n\n    mc1 = MultiCategory(np.array([1, 0]), [\'cat\'], [0])\n    mc2 = MultiCategory(np.array([1, 1]), [\'cat\', \'dog\'], [0, 1])\n    mc3 = MultiCategory(np.array([1, 0]), [\'cat\'], [0])\n\n    assert hash(mc1) == hash(mc3)\n    assert hash(mc1) != hash(mc2)\n    assert Counter([mc1, mc2, mc3]) == {mc1: 2, mc2: 1}\n'"
tests/test_data_block.py,0,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.basics import *\nfrom fastai.vision import ImageList\n\n\ndef chk(a,b): assert np.array_equal(a,b)\n\ndef test_category():\n    this_tests(\'na\')\n    c1 = [1,3,2,3,1]\n    c2 = list(\'cabbc\')\n    df = pd.DataFrame(dict(c1=c1,c2=c2))\n    trn_idx = [0,1,3]\n\n    l1 = ItemList.from_df(df, cols=0)\n    assert l1[0]==c1[0]\n    chk(l1[[1,2]].items, array(c1)[[1,2]])\n\n    sd = l1.split_by_idx([2,4])\n    chk(sd.train.items, array(c1)[[0,1,3]])\n\n    ll = sd.label_from_df(1)\n    x,y = ll.train.x,ll.train.y\n    c2i = {v:k for k,v in enumerate(ll.train.classes)}\n\n    chk(x.items, array(c1)[trn_idx])\n    chk(ll.train.classes, ll.valid.classes)\n    assert set(ll.train.classes)==set(c2)\n    chk(list(map(str, y)), array(c2)[trn_idx])\n    chk([o.obj for o in y], array(c2)[trn_idx])\n    exp = [c2i[o] for o in array(c2)[trn_idx]]\n    chk (list(map(int, y)), exp)\n    chk([o.data for o in y], exp)\n\n    c = list(\'abcd\')\n    ll = sd.label_from_df(1, classes=c)\n\n    x,y = ll.train.x,ll.train.y\n    c2i = {v:k for k,v in enumerate(c)}\n\n    chk(x.items, array(c1)[trn_idx])\n    chk(ll.train.classes, ll.valid.classes)\n    assert set(ll.train.classes)==set(c)\n    chk(list(map(str, y)), array(c2)[trn_idx])\n    chk([o.obj for o in y], array(c2)[trn_idx])\n    exp = [c2i[o] for o in array(c2)[trn_idx]]\n    chk (list(map(int, y)), exp)\n    chk([o.data for o in y], exp)\n\ndef test_multi_category():\n    this_tests(\'na\')\n    c1 = [1,3,2,3,1]\n    c2     = [\'c a\', \'a b\', \'b c\', \'\', \'a\']\n    c2_exp = [\'c;a\', \'a;b\', \'b;c\', \'\', \'a\']\n    c2_obj = [[\'c\', \'a\'], [\'a\', \'b\'], [\'b\', \'c\'], [], [\'a\']]\n    df = pd.DataFrame(dict(c1=c1,c2=c2))\n    trn_idx = [0,1,3]\n\n    l1 = ItemList.from_df(df, cols=0)\n    sd = l1.split_by_idx([2,4])\n\n    ll = sd.label_from_df(1, label_delim=\' \')\n    x,y = ll.train.x,ll.train.y\n    c2i = {v:k for k,v in enumerate(ll.train.classes)}\n\n    chk(x.items, array(c1)[trn_idx])\n    chk(ll.train.classes, ll.valid.classes)\n    assert set(ll.train.classes)==set(list(\'abc\'))\n    chk(list(map(str, y)), array(c2_exp)[trn_idx])\n    chk([o.obj for o in y], array(c2_obj)[trn_idx])\n    exp = [[c2i[p] for p in o] for o in array(c2_obj)[trn_idx]]\n    chk([o.raw for o in y], exp)\n    t = c2_obj[1]\n    exp = [0.,0.,0.]\n    exp[c2i[t[0]]] = 1.\n    exp[c2i[t[1]]] = 1.\n    chk(y[1].data, exp)\n\ndef test_category_processor_existing_class():\n    c1 = [1,3,2,3,1]\n    c2 = list(\'cabbc\')\n    df = pd.DataFrame(dict(c1=c1,c2=c2))\n\n    l1 = ItemList.from_df(df, cols=0)\n    sd = l1.split_by_idx([2, 4])\n    ll = sd.label_from_df(1)\n    ll.y.processor[0].process_one(\'a\')\n    this_tests(ll.y.processor[0].process_one)\n\ndef test_category_processor_non_existing_class():\n    c1 = [1,3,2,3,1]\n    c2 = list(\'cabbc\')\n    df = pd.DataFrame(dict(c1=c1,c2=c2))\n\n    l1 = ItemList.from_df(df, cols=0)\n    sd = l1.split_by_idx([2, 4])\n    ll = sd.label_from_df(1)\n    this_tests(ll.y.processor[0].process_one)\n    assert ll.y.processor[0].process_one(\'d\') is None\n    assert ll.y.processor[0].warns == [\'d\']\n\ndef test_splitdata_datasets():\n    c1,ratio,n = list(\'abc\'),0.2,10\n\n    this_tests(ItemList.split_by_rand_pct)\n    sd = ItemList(range(n)).split_by_rand_pct(ratio).label_const(0)\n    assert len(sd.train)==(1-ratio)*n, \'Training set is right size\'\n    assert len(sd.valid)==ratio*n, \'Validation set is right size\'\n    assert set(list(sd.train.items)+list(sd.valid.items))==set(range(n)), \'All items covered\'\n\ndef test_filter_by_rand():\n    c1,p,n,seed = list(\'abc\'),0.2,100,759\n    \n    this_tests(ItemList.filter_by_rand)\n    sd1 = ItemList(range(n)).filter_by_rand(p,seed)\n    sd2 = ItemList(range(n)).filter_by_rand(p,seed)\n    assert len(sd1) == len(sd2), \'Identically seeded random data sets are of different sizes\'\n    assert (sd1.items == sd2.items).all(), \'Identically seeded random data sets contain different values\'\n\ndef test_split_subsets():\n    this_tests(ItemList.split_subsets)\n    sd = ItemList(range(10)).split_subsets(train_size=.1, valid_size=.2).label_const(0)\n    assert len(sd.train)==1\n    assert len(sd.valid)==2\n\n    with pytest.raises(AssertionError):\n        ItemList(range(10)).split_subsets(train_size=.6, valid_size=.6).label_const(0)\n    with pytest.raises(AssertionError):\n        ItemList(range(10)).split_subsets(train_size=0.0, valid_size=0.5).label_const(0)\n    with pytest.raises(AssertionError):\n        ItemList(range(10)).split_subsets(train_size=0.5, valid_size=0.0).label_const(0)\n\ndef test_regression():\n    this_tests(\'na\')\n    df = pd.DataFrame({\'x\':range(100), \'y\':np.random.rand(100)})\n    data = ItemList.from_df(df, path=\'.\', cols=0).split_by_rand_pct().label_from_df(cols=1).databunch()\n    assert data.c==1\n    assert isinstance(data.valid_ds, LabelList)\n\ndef test_wrong_order():\n    this_tests(\'na\')\n    path = untar_data(URLs.MNIST_TINY)\n    with pytest.raises(Exception, match=""Your data isn\'t split*""):\n        ImageList.from_folder(path).label_from_folder().split_by_folder()\n\nclass CustomDataset(Dataset):\n    def __init__(self, data_list): self.data = copy(data_list)\n    def __len__(self): return len(self.data)\n    def __getitem__(self, idx): return self.data[idx]\n\ndef test_custom_dataset():\n    this_tests(DataBunch)\n    tr_dataset = CustomDataset([1, 2, 3])\n    val_dataset = CustomDataset([4, 5, 6])\n    data = DataBunch.create(tr_dataset, val_dataset)\n\n    # test property fallback\n    assert data.loss_func == F.nll_loss\n\ndef test_filter_by_folder():\n    this_tests(ItemList.filter_by_folder)\n    items = [""parent/in"", ""parent/out"", ""parent/unspecified_means_out""]\n\n    res = ItemList.filter_by_folder(\n        ItemList(items=[Path(p) for p in items], path=""parent""),\n        include=[""in"", ""and_in""], exclude=[""out"", ""also_out""])\n    assert res.items == [Path(""parent/in"")]\n\n    res = ItemList.filter_by_folder(\n        ItemList(items=items),\n        include=[""in"", ""and_in""], exclude=[""out"", ""also_out""])\n    assert res.items == [""parent/in""]\n\ndef test_from_df():\n    this_tests(ItemList.from_df)\n    df = pd.DataFrame([""123.png""], columns=[""name""])\n    try:\n        ImageList.from_df(path=""dummy_path"", df=df)\n    except Exception as ex:\n        assert not isinstance(ex, TypeError)\n'"
tests/test_datasets.py,0,"b'import pytest, fastai, shutil, os, yaml, sys\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.datasets import *\nfrom fastai.datasets import Config, _expand_path\nfrom pathlib import Path\n\n\ndef clean_test_config(path):\n    path = Path(path)\n    if path.is_file(): shutil.rmtree(path.parent)\n    if path.is_dir(): print(path); shutil.rmtree(path)\n    Config.DEFAULT_CONFIG_LOCATION = os.path.expanduser(os.getenv(\'FASTAI_HOME\', \'~/.fastai\'))\n    Config.DEFAULT_CONFIG_PATH = Config.DEFAULT_CONFIG_LOCATION + \'/config.yml\'\n\ndef test_creates_config():\n    this_tests(Config)\n    DEFAULT_CONFIG_PATH = \'config_test/test.yml\'\n\n    try:\n        config_path = _expand_path(DEFAULT_CONFIG_PATH)\n        clean_test_config(config_path)\n        assert not config_path.exists(), ""config path should not exist""\n        config = Config.get(config_path)\n        assert config_path.exists(), ""Config.get should create config if it doesn\'t exist""\n    finally:\n        clean_test_config(config_path)\n        assert not config_path.exists(), ""config path should not exist""\n\ndef test_default_config():\n    this_tests(Config)\n    Config.DEFAULT_CONFIG_LOCATION = \'config_test\'\n    Config.DEFAULT_CONFIG_PATH = Config.DEFAULT_CONFIG_LOCATION + \'/config.yml\'\n    try:\n        assert Config.get() == {\n            \'data_archive_path\': str(_expand_path(\'~/.fastai/data\')),\n            \'data_path\': str(_expand_path(\'~/.fastai/data\')),\n            \'model_path\': str(_expand_path(\'~/.fastai/models\'))\n        }\n    finally:\n        clean_test_config(Config.DEFAULT_CONFIG_LOCATION)\n\n@pytest.mark.slow\ndef test_user_config():\n    this_tests(Config, download_data, untar_data, url2path, datapath4file)\n    Config.DEFAULT_CONFIG_LOCATION = \'config_test\'\n    Config.DEFAULT_CONFIG_PATH = Config.DEFAULT_CONFIG_LOCATION + \'/config.yml\'\n    clean_test_config(Config.DEFAULT_CONFIG_LOCATION)\n\n    USER_CONFIG = {\n            \'data_archive_path\': Config.DEFAULT_CONFIG_LOCATION + \'/archive\',\n            \'data_path\': Config.DEFAULT_CONFIG_LOCATION + \'/data_test\',\n            \'model_path\': Config.DEFAULT_CONFIG_LOCATION + \'/model_test\'\n    }\n    os.makedirs(Config.DEFAULT_CONFIG_LOCATION, exist_ok=True)\n    with open(Config.DEFAULT_CONFIG_PATH, \'w+\') as config_file:\n        yaml.dump(USER_CONFIG, config_file)\n    \n    try:\n        # No directory should be created before data download\n        assert not Path(Config.DEFAULT_CONFIG_LOCATION + \'/data_test\').exists()\n        assert not Path(Config.DEFAULT_CONFIG_LOCATION + \'/archive\').exists()\n        assert not Path(Config.DEFAULT_CONFIG_LOCATION + \'/model_test\').exists()\n        download_data(URLs.MNIST_TINY)\n        # Data directory should not be created in download_data\n        assert not Path(Config.DEFAULT_CONFIG_LOCATION + \'/data_test\').exists()\n        # Compressed file should be saved to corresponding directories\n        assert Path(Config.DEFAULT_CONFIG_LOCATION + \'/archive/mnist_tiny.tgz\').exists()\n        untar_data(URLs.MNIST_TINY)\n        # Data should be decompressed to corresponding directories\n        assert Path(Config.DEFAULT_CONFIG_LOCATION + \'/data_test/mnist_tiny\').exists()\n        # untar_data should not meddle with archive file if it exists and isn\'t corrupted\n        assert Path(Config.DEFAULT_CONFIG_LOCATION + \'/archive/mnist_tiny.tgz\').exists()\n\n        # No file should exist prior to download\n        assert not Path(Config.DEFAULT_CONFIG_LOCATION + \'/data_test/mnist_sample\').exists()\n        assert not Path(Config.DEFAULT_CONFIG_LOCATION + \'/archive/mnist_sample.tgz\').exists()\n        untar_data(URLs.ML_SAMPLE)\n        # untar_data on dataset without local archive downloads the data too\n        assert Path(Config.DEFAULT_CONFIG_LOCATION + \'/data_test/movie_lens_sample\').exists()\n        assert Path(Config.DEFAULT_CONFIG_LOCATION + \'/archive/movie_lens_sample.tgz\').exists()\n    finally:\n        clean_test_config(Config.DEFAULT_CONFIG_LOCATION)'"
tests/test_fp16.py,9,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.fakes import *\na3b3b3 = torch.ones([1,3,3,3])\n\ndef test_model2half():\n    this_tests(model2half)\n    m = simple_cnn([3,6,6],bn=True)\n    m = model2half(m)\n    conv1 = m[0][0]\n    bn = m[0][2]\n    assert isinstance(conv1.weight, torch.HalfTensor)\n    assert isinstance(bn.weight, torch.FloatTensor)\n\n@pytest.mark.cuda\ndef test_model2half_forward():\n    this_tests(model2half)\n    learn = fake_learner()\n    x,y = next(iter(learn.data.train_dl))\n    res1 = learn.model(x)\n    learn.model = model2half(learn.model)\n    res2 = learn.model(x.half())\n    assert (res2.float() - res1).abs().sum() < 0.01\n\ndef test_to_half():\n    this_tests(to_half)\n    t1,t2 = torch.ones([1]).long(),torch.ones([1])\n    half = to_half([t1,t2])\n    assert isinstance(half[0],torch.LongTensor)\n    assert isinstance(half[1],torch.HalfTensor)\n\ndef test_batch_to_half():\n    this_tests(batch_to_half)\n    t1,t2 = torch.ones([1]),torch.ones([1])\n    half = batch_to_half([t1,t2])\n    assert isinstance(half[0],torch.HalfTensor)\n    assert isinstance(half[1],torch.FloatTensor)\n'"
tests/test_gen_doc_nbtest.py,0,"b'import pytest\nfrom fastai.gen_doc.nbtest import *\nfrom fastai.gen_doc import nbtest\nfrom fastai.gen_doc.doctest import this_tests, merge_registries\nimport inspect\n\ndef test_submodule_name():\n    this_tests(nbtest._submodule_name)\n    result:str = nbtest._submodule_name(nbtest.doctest)\n    assert result == \'gen_doc\', \'should return submodule\'\n\n    from fastai.core import ifnone\n    result:str = nbtest._submodule_name(ifnone)\n    assert result == None, f\'fastai/module should not have a submodule: {result}\'\n\ndef test_is_file_match():\n    this_tests(nbtest._is_file_match)\n    import fastai.text.data\n    result = nbtest._is_file_match(fastai.text.data, \'test_text_data.py\')\n    assert result is not None, f""matches test files with submodule""\n\n    import fastai.core\n    result = nbtest._is_file_match(fastai.core.ifnone, \'test_core_subset_category.py\')\n    assert result is not None, f""matches module subsets""\n\ndef test_wrapped_functions():\n    this_tests(nbtest.get_file)\n    from fastai.data_block import CrossEntropyFlat\n    loss_func = CrossEntropyFlat()\n    try: nbtest.get_file(loss_func)\n    except: raise AssertionError(""show_test should handle __wrapped__ loss functions"")\n\n    # from fastai.vision.transform import dihedral_affine\n    # tfm =  = dihedral_affine()\n    # try: build_tests_markdown(tfm)\n    # except: raise AssertionError(""show_test should handle __wrapped__ transform function"")\n\ndef test_fuzzy_test_match():\n    this_tests(fuzzy_test_match)\n    lines = [\'def test_mock_function():\',\n             \'    x = mock_function(testedapi)\',\n             \'def test_related():\',\n             \'    return related().mock_function()\'\n             \'def test_substring():\',\n             \'    a.mock_func()._mock_function(1,2)\']\n    result = fuzzy_test_match(\'mock_function\', lines, None)\n    assert result[0][\'test\'] == \'test_mock_function\', \'matches simple function calls\'\n    assert result[0][\'line\'] == 1, \'line numbers should be 1 based indexed\'\n    assert result[1][\'test\'] == \'test_related\', \'matches related calls\'\n    assert len(result) == 2, \'should not include test_substring\'\n\n    lines = [\'def test_without_fcall():\',\n             \'    return None\',\n             \'def helper_func():\',\n             \'    x = func(testedapi)\',\n             \'    x = test_function(testedapi)\',\n             \'x = func()\']\n    result = fuzzy_test_match(\'func\', lines, None)\n    assert len(result) == 0, \'should only find parent test functions with `def test_` prefix\'\n\ndef test_fuzzy_line_match():\n    this_tests(nbtest._fuzzy_line_match)\n    # Testing _fuzzy_test_match private methods\n    result = nbtest._fuzzy_line_match(\'Databunch.get\', [\'d = DataBunch()\', \'item = d.get(5)\'])\n    assert len(result) == 1, \'finds class methods\'\n\n    result = nbtest._fuzzy_line_match(\'TextList\', [\'tl = (TextList.from_df()\', \'\', \'LMTextList()\'])\n    assert len(result) == 1, \'matches classes\'\n\ndef test_get_tests_dir():\n    this_tests(nbtest.get_tests_dir)\n    result:Path = nbtest.get_tests_dir(nbtest)\n    assert result.parts[-1] == \'tests\', f""Failed: get_tests_dir return unexpected result: {result}""\n\ndef test_this_tests():\n    # function by reference (and self test)\n    this_tests(this_tests)\n\n    # multiple entries: same function twice on purpose, should result in just one entry,\n    # but also testing multiple entries - and this test tests only a single function.\n    this_tests(this_tests, this_tests)\n\n    import fastai\n    # explicit fully qualified function (requires all the sub-modules to be loaded)\n    this_tests(fastai.gen_doc.doctest.this_tests)\n\n    # explicit fully qualified function as a string\n    this_tests(\'fastai.gen_doc.doctest.this_tests\')\n\n    # special case for situations where a test doesn\'t test fastai API or non-callable attribute\n    this_tests(\'na\')\n\n    # not a real function\n    func = \'foo bar\'\n    try: this_tests(func)\n    except Exception as e: assert f""\'{func}\' is not a function"" in str(e)\n    else: assert False, f\'this_tests({func}) should have failed\'\n\n    # not a function as a string that looks like fastai function, but it is not\n    func = \'fastai.gen_doc.doctest.doesntexistreally\'\n    try: this_tests(func)\n    except Exception as e: assert f""\'{func}\' is not a function"" in str(e)\n    else: assert False, f\'this_tests({func}) should have failed\'\n\n    # not a fastai function\n    import numpy as np\n    func = np.any\n    try: this_tests(func)\n    except Exception as e: assert f""\'{func}\' is not in the fastai API"" in str(e)\n    else: assert False, f\'this_tests({func}) should have failed\'\n\n@pytest.mark.parametrize(""old, new, expected"", [\n    # 1.\n    ({ # old\n        ""a"": [\n            {""file"": ""mod1"", ""line"": 19, ""test"": ""test1""},\n        ],\n        ""b"": [\n            {""file"": ""mod2"", ""line"": 11, ""test"": ""test7""},\n            {""file"": ""mod2"", ""line"": 56, ""test"": ""test8""},\n        ],\n    },\n     { # new\n     },\n     { # expected\n         ""a"": [\n             {""file"": ""mod1"", ""line"": 19, ""test"": ""test1""},\n         ],\n         ""b"": [\n             {""file"": ""mod2"", ""line"": 11, ""test"": ""test7""},\n             {""file"": ""mod2"", ""line"": 56, ""test"": ""test8""},\n         ],\n     },\n    ),\n\n    # 2.\n    ({ # old\n        ""a"": [\n            {""file"": ""mod1"", ""line"": 19, ""test"": ""test1""},\n        ],\n        ""b"": [\n            {""file"": ""mod2"", ""line"": 11, ""test"": ""test7""},\n            {""file"": ""mod2"", ""line"": 56, ""test"": ""test8""},\n        ],\n    },\n     { # new\n         ""a"": [\n             {""file"": ""mod1"", ""line"": 35, ""test"": ""test1""},\n         ],\n         ""b"": [\n             {""file"": ""mod3"", ""line"": 26, ""test"": ""test3""},\n         ],\n     },\n     { # expected\n         ""a"": [\n             {""file"": ""mod1"", ""line"": 35, ""test"": ""test1""},\n         ],\n         ""b"": [\n             {""file"": ""mod2"", ""line"": 11, ""test"": ""test7""},\n             {""file"": ""mod2"", ""line"": 56, ""test"": ""test8""},\n             {""file"": ""mod3"", ""line"": 26, ""test"": ""test3""},\n         ],\n     },\n    ),\n\n     # 3.\n    ({ # old\n        ""a"": [\n            {""file"": ""mod1"", ""line"": 19, ""test"": ""test1""},\n        ],\n        ""b"": [\n            {""file"": ""mod2"", ""line"": 11, ""test"": ""test7""},\n            {""file"": ""mod2"", ""line"": 56, ""test"": ""test8""},\n        ],\n    },\n     { # new\n         ""a"": [\n             {""file"": ""mod1"", ""line"": 35, ""test"": ""test2""},\n         ],\n         ""c"": [\n             {""file"": ""mod3"", ""line"": 16, ""test"": ""test3""},\n         ],\n     },\n     { # expected\n         ""a"": [\n             {""file"": ""mod1"", ""line"": 19, ""test"": ""test1""},\n             {""file"": ""mod1"", ""line"": 35, ""test"": ""test2""},\n         ],\n         ""b"": [\n             {""file"": ""mod2"", ""line"": 11, ""test"": ""test7""},\n             {""file"": ""mod2"", ""line"": 56, ""test"": ""test8""},\n         ],\n         ""c"": [\n             {""file"": ""mod3"", ""line"": 16, ""test"": ""test3""},\n         ],\n     },\n    ),\n])\ndef test_merge_registries(old, new, expected):\n    this_tests(merge_registries)\n    merged = merge_registries(old, new)\n    assert expected == merged\n'"
tests/test_layers.py,0,"b""import pytest, fastai\n\n#I'm all empty, please fill me with tests about the functions in layers.py"""
tests/test_metrics.py,44,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.basics import *\nfrom fastai.metrics import *\nfrom utils.fakes import fake_learner\nfrom utils.text import CaptureStdout\n\np1 = torch.Tensor([0,1,0,0,0]).expand(5,-1)\np2 = torch.Tensor([[0,0,0,0,0],[0,1,0,0,0]]).expand(5,2,-1).float()\np3 = torch.Tensor([[0,0,0,0,0],[0,0,0,0,0]]).expand(5,2,-1).float()\nt1 = torch.arange(5)\nt2 = torch.Tensor([1,1,1,1,0]).expand(5,-1)\nt3 = torch.Tensor([0,0,0,0,0]).expand(5,-1)\n\n# Test data for multi-class single-label sequential models (like language models)\n# batch size: 5, sequence length: 4, classes: 4\nseq_targs = torch.arange(4).expand(5,-1)\nseq_preds_perfect = torch.Tensor([\n    [0.6, 0.3, 0.08, 0.02],\n    [0.02, 0.6, 0.3, 0.08],\n    [0.08, 0.02, 0.6, 0.3],\n    [0.3, 0.08, 0.02, 0.6],\n]).expand(5,4,-1)\nseq_preds_wrong = torch.Tensor([\n    [0.02, 0.6, 0.3, 0.08],\n    [0.08, 0.02, 0.6, 0.3],\n    [0.3, 0.08, 0.02, 0.6],\n    [0.6, 0.3, 0.08, 0.02],\n]).expand(5,4,-1)\nseq_preds = torch.Tensor([\n    [0.6, 0.3, 0.08, 0.02],\n    [0.08, 0.3, 0.6, 0.02],\n    [0.3, 0.02, 0.08, 0.6],\n    [0.6, 0.3, 0.08, 0.02],\n]).expand(5,4,-1)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (p1, t1, 0.2),\n    (torch.eye(5), t1, 1),\n    (seq_preds_perfect, seq_targs, 1),\n    (seq_preds_wrong, seq_targs, 0),\n    (seq_preds, seq_targs, 0.25),\n])\ndef test_accuracy(p, t, expect):\n    this_tests(accuracy)\n    assert np.isclose(accuracy(p, t).item(), expect)\n\n@pytest.mark.parametrize(""p, t, k, expect"", [\n    # should behave like `accuracy` for k = 1\n    (p1, t1, 1, 0.2),\n    (torch.eye(5), t1, 1, 1),\n    (seq_preds_perfect, seq_targs, 1, 1),\n    (seq_preds_wrong, seq_targs, 1, 0),\n    (seq_preds, seq_targs, 1, 0.25),\n    # should always return 1.0 for k = num_classes = 4\n    (seq_preds_perfect, seq_targs, 4, 1),\n    (seq_preds_wrong, seq_targs, 4, 1),\n    (seq_preds, seq_targs, 4, 1),\n    # perfect predictions should result in 1 for all k\n    (seq_preds_perfect, seq_targs, 2, 1),\n    (seq_preds_perfect, seq_targs, 3, 1),\n    # totally wrong predictions should result in 0 for all k\n    (seq_preds_wrong, seq_targs, 2, 0),\n    (seq_preds_wrong, seq_targs, 3, 0),\n    # all other cases\n    (seq_preds, seq_targs, 2, 0.5),\n    (seq_preds, seq_targs, 3, 0.75),\n])\ndef test_top_k_accuracy(p, t, k, expect):\n    this_tests(top_k_accuracy)\n    assert np.isclose(top_k_accuracy(p, t, k).item(), expect)\n\n@pytest.mark.parametrize(""p, t, expect, atol"", [\n    (torch.randn((128, 2, 224, 224)),  torch.randint(0, 2, (128, 1, 224, 224)), 1/2, 1e-3),\n    (torch.randn((128, 8, 224, 224)),  torch.randint(0, 8, (128, 1, 224, 224)), 1/8, 1e-3),\n    (torch.randn((128, 16, 224, 224)),  torch.randint(0, 16, (128, 1, 224, 224)), 1/16, 1e-3),\n])\ndef test_foreground_acc(p, t, expect, atol):\n    this_tests(foreground_acc)\n    assert np.isclose(partial(foreground_acc, void_code=0)(p, t).item(), expect, atol=atol)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (p1, t1, 0.8),\n    (torch.eye(5), t1, 0),\n])\ndef test_error_rate(p, t, expect):\n    this_tests(error_rate)\n    assert np.isclose(error_rate(p, t).item(), expect)\n\ndef test_exp_rmspe():\n    this_tests(exp_rmspe)\n    assert np.isclose(exp_rmspe(torch.ones(1,5), torch.ones(5)).item(), 0)\n\ndef test_exp_rmspe_num_of_ele():\n    this_tests(exp_rmspe)\n    with pytest.raises(AssertionError):\n        exp_rmspe(p1, t1.float())\n\ndef test_accuracy_thresh():\n    this_tests(accuracy_thresh)\n    assert np.isclose(accuracy_thresh(torch.linspace(0,1,5), torch.ones(5)), 0.8)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (p2, t2, 8/9), #0.4\n    (torch.zeros(5,2,5), torch.eye(5,5), 1/3),\n    (torch.zeros(5,2,5), torch.zeros(5,5), 0),\n    (tensor([[[[1., 1.],\n               [1., 1.]],\n              [[0., 0.],\n               [0., 0.]]],\n             [[[1., 1.],\n               [1., 1.]],\n              [[1., 0.],\n               [0., 0.]]],\n             [[[1., 1.],\n               [1., 1.]],\n              [[0., 0.],\n               [1., 0.]]]]),\n     tensor([[[[0, 0],\n               [0, 0]]],\n             [[[0, 0],\n               [0, 1]]],\n             [[[0, 0],\n               [1, 0]]]]),\n     2/3)\n])\ndef test_dice(p, t, expect):\n    this_tests(dice)\n    assert np.isclose(dice(p, t.long()).item(), expect)\n\n@pytest.mark.parametrize(""p, t, expect, atol"", [\n    (p2, t2, 0.8, 0.),\n    (p3, t3, 0.0, 0.),\n    (p2, torch.eye(5,5), 0.200, 1e-3),\n    (p2, torch.zeros(5,5), 0, 0.),\n])\ndef test_dice_iou(p, t, expect, atol):\n    this_tests(dice)\n    assert np.isclose(dice(p, t.long(), iou=True).item(), expect, atol=atol)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (torch.ones(1,10), torch.ones(1,10), 1),\n    (torch.zeros(1,10), torch.zeros(1,10), 0),\n])\ndef test_fbeta(p, t, expect):\n    this_tests(fbeta)\n    assert np.isclose(fbeta(p, t).item(), expect)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (torch.arange(-10, 10).float(), torch.arange(-9, 11).float(), 1),\n    (torch.arange(-10, 10).float(), torch.arange(-11, 9).float(), 1),\n    (torch.arange(-10, 10).float(), torch.arange(-10, 10).float(), 0)\n])\ndef test_mae(p, t, expect):\n    this_tests(mean_absolute_error)\n    assert np.isclose(mean_absolute_error(p, t), expect)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (torch.arange(-10, 10).float(), torch.arange(-8, 12).float(), 4),\n    (torch.arange(-10, 10).float(), torch.arange(-12, 8).float(), 4),\n    (torch.arange(-10, 10).float(), torch.arange(-10, 10).float(), 0)\n])\ndef test_mse(p, t, expect):\n    this_tests(mean_squared_error)\n    assert np.isclose(mean_squared_error(p, t), expect)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (torch.arange(-10, 10).float(), torch.arange(-8, 12).float(), 2),\n    (torch.arange(-10, 10).float(), torch.arange(-12, 8).float(), 2),\n    (torch.arange(-10, 10).float(), torch.arange(-10, 10).float(), 0)\n])\ndef test_rmse(p, t, expect):\n    this_tests(root_mean_squared_error)\n    assert np.isclose(root_mean_squared_error(p, t), expect)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (torch.exp(torch.arange(-10, 10).float())-1,\n     torch.exp(torch.arange(-8,  12).float())-1, 4),\n    (torch.exp(torch.arange(-10, 10).float())-1,\n     torch.exp(torch.arange(-12,  8).float())-1, 4),\n])\ndef test_msle(p, t, expect):\n    this_tests(mean_squared_logarithmic_error)\n    assert np.isclose(mean_squared_logarithmic_error(p, t), expect, rtol=1.e-4)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (torch.arange(-5, 5).float(), torch.arange(-10,  0).float(), 1.),\n    (torch.zeros(10).float(), torch.arange(-5, 5).float(), 0.),\n    (torch.arange(-5, 5).float(), torch.zeros(10).float(), -float(""inf"")),\n    (p1/2., p1, 0.75),\n    (p1, t2, -0.5),\n])\ndef test_explained_variance(p, t, expect):\n    this_tests(explained_variance)\n    assert np.isclose(explained_variance(p, t), expect)\n\n@pytest.mark.parametrize(""p, t, expect"", [\n    (torch.arange(-5, 5).float(), torch.arange(-5,  5).float(), 1),\n    (torch.zeros(10).float(), torch.arange(-5, 5).float(), -0.0303),\n    (torch.arange(-5, 5).float(), torch.zeros(10).float(), -float(""inf"")),\n    (p1/2., p1, 0.6875),\n    (p1, t2, -2.75),\n])\ndef test_r2_score(p, t, expect):\n    this_tests(r2_score)\n    assert np.isclose(r2_score(p, t), expect, atol=1e-2)\n\n### metric as a custom class\ndummy_base_val = 9876\nclass DummyMetric(Callback):\n    """""" this dummy metric returns an epoch number power of a base """"""\n    def __init__(self):\n        super().__init__()\n        self.name = ""dummy""\n        self.epoch = 0\n\n    def on_epoch_begin(self, **kwargs):\n        self.epoch += 1\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return {\'last_metrics\': last_metrics + [torch.tensor(dummy_base_val**self.epoch)]}\n\ndef test_custom_metric_class():\n    this_tests(\'na\')\n    learn = fake_learner(3,2)\n    learn.metrics.append(DummyMetric())\n    with CaptureStdout() as cs: learn.fit_one_cycle(2)\n    # expecting column header \'dummy\', and the metrics per class definition\n    for s in [\'dummy\', f\'{dummy_base_val}.00\', f\'{dummy_base_val**2}.00\']:\n        assert s in cs.out, f""{s} is in the output:\\n{cs.out}""\n\ndef test_average_metric_naming():\n    this_tests(AverageMetric)\n    top2_accuracy = partial(top_k_accuracy, k=2)\n    top3_accuracy = partial(top_k_accuracy, k=3)\n    top4_accuracy = partial(top_k_accuracy, k=4)\n    # give top2_accuracy and top4_accuracy a custom name\n    top2_accuracy.__name__ = ""top2_accuracy""\n    top4_accuracy.__name__ = ""top4_accuracy""\n    # prewrap top4_accuracy\n    top4_accuracy = AverageMetric(top4_accuracy)\n    learn = fake_learner()\n    learn.metrics = [accuracy, top2_accuracy, top3_accuracy, top4_accuracy]\n    learn.fit(1)\n    assert learn.recorder.names[3:7] == [""accuracy"", ""top2_accuracy"", ""top_k_accuracy"", ""top4_accuracy""]'"
tests/test_mod_display.py,0,"b'""""""\nprogress bar tweaks\n""""""\n\nimport pytest\nfrom fastai.utils.mod_display import *\nfrom utils.fakes import *\nfrom utils.text import *\nfrom fastai.gen_doc.doctest import this_tests\n\n@pytest.fixture(scope=""module"")\ndef learn():\n    learn = fake_learner(50, 50)\n    return learn\n\ndef test_progress_disabled_ctx(learn):\n    this_tests(progress_disabled_ctx)\n\n    # progress output is expected\n    with CaptureStdout() as cs: learn.fit(1)\n    assert (\'epoch\' in cs.out) == True\n    assert (\'train_loss\' in cs.out) == True\n    assert (\'valid_loss\' in cs.out) == True\n    assert (\'\\n0\' in cs.out) == True #record of 0 epoch\n\n    # progress output shouldn\'t appear\n    with CaptureStdout() as cs:\n        with progress_disabled_ctx(learn): learn.fit(1)\n    assert (\'epoch\' not in cs.out) == True\n    assert (\'train_loss\' not in cs.out) == True\n    assert (\'valid_loss\' not in cs.out) == True\n    assert (\'\\n0\' not in cs.out) == True #record of 0 epoch\n'"
tests/test_tabular_data.py,0,"b""import pytest\nfrom fastai.tabular import *\nfrom fastai.gen_doc.doctest import this_tests\n\ndef test_from_df():\n    path = Path('data/adult_sample/')\n    datafile = path/'adult.csv'\n    assert datafile.exists(), f'We assume test data is in {datafile}'\n    df = pd.read_csv(datafile,nrows=5)\n\n    dep_var = 'salary'\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n    cont_names = ['age', 'fnlwgt', 'education-num']\n    procs = [FillMissing, Categorify, Normalize]\n\n    tablist = TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names,procs=procs)\n\n    this_tests(tablist.from_df)\n    assert tablist.cat_names == cat_names\n    assert tablist.cont_names == cont_names\n    assert tablist.procs == procs\n    assert (tablist.items == df.index).all()\n    assert tablist.path == path\n\n    # Check correct initialization and `get`; 3rd record without 'NaN'\n    assert (tablist[3] == df.iloc[3]).all()\n"""
tests/test_tabular_train.py,0,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.tabular import *\nfrom fastai.train import ClassificationInterpretation\n\npytestmark = pytest.mark.integration\npath = untar_data(URLs.ADULT_SAMPLE)\n\n@pytest.fixture(scope=""module"")\ndef learn():\n    df = pd.read_csv(path/\'adult.csv\')\n    procs = [FillMissing, Categorify, Normalize]\n    dep_var = \'salary\'\n    cat_names = [\'workclass\', \'education\', \'marital-status\', \'occupation\', \'relationship\', \'race\', \'sex\', \'native-country\']\n    cont_names = [\'age\', \'fnlwgt\', \'education-num\']\n    test = TabularList.from_df(df.iloc[800:1000].copy(), path=path, cat_names=cat_names, cont_names=cont_names)\n    data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n            .split_by_idx(list(range(800,1000)))\n            .label_from_df(cols=dep_var)\n            .add_test(test)\n            .databunch(num_workers=1))\n    learn = tabular_learner(data, layers=[200,100], emb_szs={\'native-country\': 10}, metrics=accuracy)\n    learn.fit_one_cycle(2, 1e-2)\n    return learn\n\ndef test_accuracy(learn):\n    this_tests(validate)\n    assert learn.validate()[1] > 0.7\n\ndef test_same_categories(learn):\n    this_tests(\'na\')\n    x_train,y_train = learn.data.train_ds[0]\n    x_valid,y_valid = learn.data.valid_ds[0]\n    x_test,y_test = learn.data.test_ds[0]\n    assert x_train.classes.keys() == x_valid.classes.keys()\n    assert x_train.classes.keys() == x_test.classes.keys()\n    for key in x_train.classes.keys():\n        assert np.all(x_train.classes[key] == x_valid.classes[key])\n        assert np.all(x_train.classes[key] == x_test.classes[key])\n\ndef test_same_fill_nan(learn):\n    this_tests(\'na\')\n    df = pd.read_csv(path/\'adult.csv\')\n    nan_idx = np.where(df[\'education-num\'].isnull())\n    val = None\n    for i in nan_idx[0]:\n        x,y = (learn.data.train_ds[i] if i < 800 else learn.data.valid_ds[i-800])\n        j = x.names.index(\'education-num\') - len(x.cats)\n        if val is None: val = x.conts[j]\n        else: assert val == x.conts[j]\n        if i >= 800:\n            x,y = learn.data.test_ds[i-800]\n            assert val == x.conts[j]\n\ndef test_normalize(learn):\n    df = pd.read_csv(path/\'adult.csv\')\n    train_df = df.iloc[0:800].append(df.iloc[1000:])\n    c = \'age\'\n    this_tests(\'na\')\n    mean, std = train_df[c].mean(), train_df[c].std()\n    for i in np.random.randint(0,799, (20,)):\n        x,y = learn.data.train_ds[i]\n        assert np.abs(x.conts[0] - (df.loc[i, c] - mean) / (1e-7 + std)) < 1e-6\n    for i in np.random.randint(800,1000, (20,)):\n        x,y = learn.data.valid_ds[i-800]\n        assert np.abs(x.conts[0] - (df.loc[i, c] - mean) / (1e-7 + std)) < 1e-6\n    for i in np.random.randint(800,1000, (20,)):\n        x,y = learn.data.test_ds[i-800]\n        assert np.abs(x.conts[0] - (df.loc[i, c] - mean) / (1e-7 + std)) < 1e-6\n\ndef test_empty_cont():\n    this_tests(\'na\')\n    df = pd.read_csv(path/\'adult.csv\')\n    procs = [FillMissing, Categorify, Normalize]\n    dep_var = \'salary\'\n    cat_names = [\'workclass\', \'education\', \'marital-status\', \'occupation\', \'relationship\', \'race\', \'sex\', \'native-country\']\n    data = (TabularList.from_df(df, path=path, cat_names=cat_names, procs=procs)\n            .split_by_idx(list(range(990,1000)))\n            .label_from_df(cols=dep_var).databunch(num_workers=1))\n    learn = tabular_learner(data, layers=[10], metrics=accuracy)\n    learn.fit_one_cycle(1, 1e-1)\n    assert learn.validate()[1] > 0.5\n\ndef test_confusion_tabular(learn):\n    interp = ClassificationInterpretation.from_learner(learn)\n    assert isinstance(interp.confusion_matrix(), (np.ndarray))\n    assert interp.confusion_matrix().sum() == len(learn.data.valid_ds)\n    this_tests(interp.confusion_matrix)\n'"
tests/test_tabular_transform.py,0,"b'from fastai.gen_doc.doctest import this_tests\nfrom fastai.tabular import *\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\n\n\ndef test_categorify():\n    this_tests(Categorify)\n    cat_names = [\'A\']\n    cont_names = [\'X\']\n    train_df = pd.DataFrame({\'A\': [\'a\', \'b\'],\n                             \'X\': [0., 1.]})\n    valid_df = pd.DataFrame({\'A\': [\'b\', \'a\'],\n                             \'X\': [1., 0.]})\n    original_cont_train_df = train_df[cont_names].copy()\n    original_cont_valid_df = valid_df[cont_names].copy()\n\n    categorify_transform = Categorify(cat_names, cont_names)\n    categorify_transform.apply_train(train_df)\n    categorify_transform.apply_test(valid_df)\n\n    # Make sure all categorical columns have the right type\n    assert all([isinstance(dt, CategoricalDtype) for dt\n                in train_df[cat_names].dtypes])\n    assert all([isinstance(dt, CategoricalDtype) for dt\n                in valid_df[cat_names].dtypes])\n    # Make sure continuous columns have not changed\n    assert train_df[cont_names].equals(original_cont_train_df)\n    assert valid_df[cont_names].equals(original_cont_valid_df)\n\n\ndef test_default_fill_strategy_is_median():\n    fill_missing_transform = FillMissing([], [])\n\n    assert fill_missing_transform.fill_strategy is FillStrategy.MEDIAN\n    this_tests(FillMissing)\n\n\ndef test_fill_missing_leaves_no_na_values():\n    cont_names = [\'A\']\n    train_df = pd.DataFrame({\'A\': [0., np.nan, np.nan]})\n    valid_df = pd.DataFrame({\'A\': [np.nan, 0., np.nan]})\n\n    fill_missing_transform = FillMissing([], cont_names)\n    fill_missing_transform.apply_train(train_df)\n    fill_missing_transform.apply_test(valid_df)\n    this_tests(fill_missing_transform.apply_train, fill_missing_transform.apply_test)\n\n    assert train_df.isna().values.sum() == 0\n    assert valid_df.isna().values.sum() == 0\n\n\ndef test_fill_missing_returns_correct_medians():\n    train_df = pd.DataFrame({\'A\': [0., 1., 1., np.nan, np.nan]})\n    valid_df = pd.DataFrame({\'A\': [0., 0., 1., np.nan, np.nan]})\n    expected_filled_train_df = pd.DataFrame({\'A\': [0., 1., 1., 1., 1.]})\n    expected_filled_valid_df = pd.DataFrame({\'A\': [0., 0., 1., 1., 1.]})\n\n    fill_missing_transform = FillMissing([], [\'A\'], add_col=False)\n    fill_missing_transform.apply_train(train_df)\n    fill_missing_transform.apply_test(valid_df)\n    this_tests(fill_missing_transform.apply_train, fill_missing_transform.apply_test)\n\n    # Make sure the train median is used in both cases\n    assert train_df.equals(expected_filled_train_df)\n    assert valid_df.equals(expected_filled_valid_df)\n\n\ndef test_cont_cat_split():\n    this_tests(cont_cat_split)\n    cat_names = [\'A\']\n    cont_names = [\'F\', \'I\']\n    df = pd.DataFrame({\'A\': [\'a\', \'b\'], \'F\': [0., 1.], \'I\': [0, 1]})\n\n    # Make sure the list and number of columns is correct\n    res_cont, res_cat = cont_cat_split(df, max_card=0)\n    assert res_cont == cont_names\n    assert res_cat == cat_names\n    assert len(res_cont) == len(cont_names)\n    assert len(res_cat) == len(cat_names)\n    # Make sure `max_card` is correctly used to differentiate int as categorical\n    res_cont, res_cat = cont_cat_split(df)\n    assert res_cont == [\'F\']\n    assert res_cat == [\'A\', \'I\']\n\n\ndef test_normalize():\n    this_tests(Normalize)\n\n    cont_names = [\'height\']\n    normalize_transform = Normalize([], cont_names)\n    train_df = pd.DataFrame({\'height\': [180, 140, 122], \'age\': [24, 33, 45]})\n    test_df = pd.DataFrame({\'height\': [184, 102, 113], \'age\': [44, 31, 19]})\n    normalize_transform(train_df)\n    normalize_transform(test_df, test=True)\n\n    expected_test_df = pd.DataFrame({\'height\': [1.235, -1.527, -1.157], \'age\': [44, 31, 19]})\n\n    np.testing.assert_array_almost_equal(expected_test_df[""height""], test_df[""height""],decimal=3)\n    np.testing.assert_array_equal(expected_test_df[""age""], test_df[""age""])\n\n\ndef test_add_datepart():\n    this_tests(add_datepart)\n\n    df = pd.DataFrame({\'transaction_date\': [\'02/03/2017\', \'02/04/2017\', \'02/05/2017\'], \'category\': [\'a\', \'b\', \'a\']})\n    add_datepart(df, \'transaction_date\')\n\n    expected_test_df = pd.DataFrame(\n        {\'category\': [\'a\', \'b\', \'a\'],\n         \'transaction_Year\': [2017, 2017, 2017],\n         \'transaction_Month\': [2, 2, 2],\n         \'transaction_Week\': [5, 5, 5],\n         \'transaction_Day\': [3, 4, 5],\n         \'transaction_Dayofweek\': [4, 5, 6],\n         \'transaction_Dayofyear\': [34, 35, 36],\n         \'transaction_Is_month_end\': [False, False, False],\n         \'transaction_Is_month_start\': [False, False, False],\n         \'transaction_Is_quarter_end\': [False, False, False],\n         \'transaction_Is_quarter_start\': [False, False, False],\n         \'transaction_Is_year_end\': [False, False, False],\n         \'transaction_Is_year_start\': [False, False, False],\n         \'transaction_Elapsed\': [1486080000, 1486166400, 1486252800]\n\n         })\n\n    for col in df.columns:\n        np.testing.assert_array_equal(df[col], expected_test_df[col])\n'"
tests/test_text_data.py,0,"b'import pytest, tempfile\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.text import *\n\ndef text_df(labels):\n    data = []\n    texts = [""fast ai is a cool project"", ""hello world""] * 20\n    for ind, text in enumerate(texts):\n        sample = {}\n        sample[""label""] = labels[ind%len(labels)]\n        sample[""text""] = text\n        data.append(sample)\n    return pd.DataFrame(data)\n\ndef text_csv_file(filepath, labels):\n    file = open(filepath, \'w\', encoding=\'utf-8\')\n    df = text_df(labels)\n    df.to_csv(filepath, index=False)\n    file.close()\n    return file\n\ndef text_files(path, labels):\n    os.makedirs(path/\'temp\', exist_ok=True)\n    texts = [""fast ai is a cool project"", ""hello world""] * 20\n    for lbl in labels:\n        os.makedirs(path/\'temp\'/lbl, exist_ok=True)\n        for i,t in enumerate(texts):\n            with open(path/\'temp\'/lbl/f\'{lbl}_{i}.txt\', \'w\') as f: f.write(t)\n\ndef test_from_folder():\n    this_tests(TextList.label_from_folder)\n    path = untar_data(URLs.IMDB_SAMPLE)\n    text_files(path, [\'pos\', \'neg\'])\n    data = (TextList.from_folder(path/\'temp\')\n               .split_by_rand_pct(0.1)\n               .label_from_folder()\n               .databunch())\n    assert (len(data.train_ds) + len(data.valid_ds)) == 80\n    assert set(data.classes) == {\'neg\', \'pos\'}\n    shutil.rmtree(path/\'temp\')\n\ndef test_filter_classes():\n    this_tests(TextList.label_from_folder)\n    path = untar_data(URLs.IMDB_SAMPLE)\n    text_files(path, [\'pos\', \'neg\', \'unsup\'])\n    with pytest.warns(UserWarning):\n        data = (TextList.from_folder(path/\'temp\')\n                 .split_by_rand_pct(0.1)\n                 .label_from_folder(classes=[\'pos\', \'neg\'])\n                 .databunch())\n    assert (len(data.train_ds) + len(data.valid_ds)) == 80\n    assert set(data.classes) == {\'neg\', \'pos\'}\n    shutil.rmtree(path/\'temp\')\n\ndef special_fastai_test_rule(s): return s.replace(""fast ai"", ""@fastdotai"")\n\ndef test_from_csv_and_from_df():\n    this_tests(TextClasDataBunch.from_df, TextClasDataBunch.from_csv)\n    path = untar_data(URLs.IMDB_SAMPLE)\n    df = text_df([\'neg\',\'pos\']) #""fast ai is a cool project"", ""hello world""\n    trn_df,val_df,tst_df = df.iloc[:20],df.iloc[20:],df.iloc[:10]\n    data1 = TextClasDataBunch.from_df(path, train_df=trn_df, valid_df=val_df, test_df=tst_df, label_cols=0,\n                                      text_cols=[""text""], no_check=True)\n    assert len(data1.classes) == 2\n    x,y = next(iter(data1.valid_dl)) # Will fail if the SortSampler keys get messed up between train and valid.\n    df = text_df([\'neg\',\'pos\',\'neg pos\'])\n    data2 = TextClasDataBunch.from_df(path, train_df=trn_df, valid_df=val_df,\n                                  label_cols=0, text_cols=[""text""], label_delim=\' \',\n                                  tokenizer=Tokenizer(pre_rules=[special_fastai_test_rule]), no_check=True)\n    assert len(data2.classes) == 2\n    x,y = data2.train_ds[0]\n    assert len(y.data) == 2\n    assert \'@fastdotai\' in data2.train_ds.vocab.itos,  ""custom tokenzier not used by TextClasDataBunch""\n    text_csv_file(path/\'tmp.csv\', [\'neg\',\'pos\'])\n    data3 = TextLMDataBunch.from_csv(path, \'tmp.csv\', test=\'tmp.csv\', label_cols=0, text_cols=[""text""], bs=2)\n    assert isinstance(data3.train_ds.y[0], EmptyLabel)\n    data4 = TextLMDataBunch.from_csv(path, \'tmp.csv\', label_cols=0, text_cols=[""text""], max_vocab=5, bs=2)\n    assert 5 <= len(data4.train_ds.vocab.itos) <= 5+8 # +(8 special tokens - UNK/BOS/etc)\n    data4.batch_size = 8\n\n    os.remove(path/\'tmp.csv\')\n\ndef test_should_load_backwards_lm_1():\n    ""assumes that a backwards batch starts where forward ends. Whether this holds depends on LanguageModelPreLoader""\n    path = untar_data(URLs.IMDB_SAMPLE)\n\n    df = text_df([\'neg\',\'pos\'])\n    data = TextLMDataBunch.from_df(path, train_df=df, valid_df=df, label_cols=0, text_cols=[""text""],\n                                   bs=2, backwards=False)\n    this_tests(data.one_batch)\n    batch_forward = data.one_batch(DatasetType.Valid)[0].numpy()\n\n    data = TextLMDataBunch.from_df(path, train_df=df, valid_df=df, label_cols=0, text_cols=[""text""],\n                                   bs=2, backwards=True)\n    batch_backwards = data.one_batch(DatasetType.Valid)[0].numpy()\n\n    np.testing.assert_array_equal(batch_backwards, np.flip(batch_forward))\n\ndef test_should_load_backwards_lm_2():\n    ""it is fragile to test against specific words. What if 2 batches were split between \'is\' an \'a\' in df.Text""\n    path = untar_data(URLs.IMDB_SAMPLE)\n    df = text_df([\'neg\',\'pos\'])\n    data = TextLMDataBunch.from_df(path, train_df=df, valid_df=df, label_cols=0, text_cols=[""text""],\n                                   bs=2, backwards=True)\n    this_tests(data.one_batch)\n    batch = data.one_batch(DatasetType.Valid)\n    as_text = [data.vocab.itos[x] for x in batch[0][0]]\n    np.testing.assert_array_equal(as_text[:2], [""world"", ""hello""])\n\ndef test_backwards_cls_databunch():\n    path = untar_data(URLs.IMDB_SAMPLE)\n    df = text_df([\'neg\', \'pos\'])\n    data = TextClasDataBunch.from_df(path, train_df=df, valid_df=df, label_cols=0, text_cols=[\'text\'], bs=4,\n                                         backwards=True)\n    this_tests(data.one_batch)\n    orig_texts = df.text.unique()\n    for ds in [DatasetType.Train, DatasetType.Valid]:\n        batch = data.one_batch(ds)\n        for sample in batch[0]:\n            as_text = \' \'.join([data.vocab.itos[tok] for tok in sample.flip(0)])\n            assert any([orig in as_text for orig in orig_texts])  # batch samples contain BOS and optionally PAD tokens\n\ndef df_test_collate(data):\n    this_tests(\'na\')\n    x,y = next(iter(data.train_dl))\n    assert x.size(0) == 8\n    assert x[0,-1] == 1\n\ndef test_load_and_save_test():\n    this_tests(load_data)\n    path = untar_data(URLs.IMDB_SAMPLE)\n    df = text_df([\'neg\',\'pos\'])\n    data = TextClasDataBunch.from_df(path, train_df=df, valid_df=df, test_df=df, label_cols=0, text_cols=""text"", bs=10)\n    data.save()\n    data1 = load_data(path, bs=10)\n    assert np.all(data.classes == data1.classes)\n    assert np.all(data.train_ds.y.items == data1.train_ds.y.items)\n    str1 = np.array([str(o) for o in data.train_ds.y])\n    str2 = np.array([str(o) for o in data1.train_ds.y])\n    assert np.all(str1 == str2)\n    os.remove(path/\'data_save.pkl\')\n\ndef test_sortish_sampler():\n    this_tests(SortishSampler)\n    ds = [1,2,3,4,5,6,7,8,9,10]\n    train_sampler = SortishSampler(ds, key=lambda t: ds[t], bs=2)\n    assert len(train_sampler) == 10\n    ds_srt = [ds[i] for i in train_sampler]\n    assert ds_srt[0] == 10\n\n    # test on small datasets\n    ds = [1, 10]\n    train_sampler = SortishSampler(ds, key=lambda t: ds[t], bs=2)\n    assert len(train_sampler) == 2\n    ds_srt = [ds[i] for i in train_sampler]\n    assert ds_srt[0] == 10\n    \ndef test_sort_sampler():\n    this_tests(SortSampler)\n    ds = [1,2,3,4,5,6,7,8,9,10]\n    train_sampler = SortSampler(ds, key=lambda t: ds[t])\n    assert len(train_sampler) == 10\n    ds_srt = [ds[i] for i in train_sampler]\n    assert ds_srt[0] == 10\n\n    # test on small datasets\n    ds = [1, 10]\n    train_sampler = SortSampler(ds, key=lambda t: ds[t])\n    assert len(train_sampler) == 2\n    ds_srt = [ds[i] for i in train_sampler]\n    assert ds_srt[0] == 10\n\ndef test_from_ids_works_for_equally_length_sentences():\n    this_tests(TextClasDataBunch.from_ids)\n    ids = [np.array([0])]*10\n    lbl = [0]*10\n    with tempfile.TemporaryDirectory() as tmp:\n        data = TextClasDataBunch.from_ids(tmp, vocab=Vocab({0: BOS, 1:PAD}),\n                                          train_ids=ids, train_lbls=lbl,\n                                          valid_ids=ids, valid_lbls=lbl, classes={0:0}, bs=8)\n\ndef test_from_ids_works_for_variable_length_sentences():\n    this_tests(TextClasDataBunch.from_ids)\n    ids = [np.array([0]),np.array([0,1])]*5 # notice diffrent number of elements in arrays\n    lbl = [0]*10\n    with tempfile.TemporaryDirectory() as tmp:\n        data = TextClasDataBunch.from_ids(tmp, vocab=Vocab({0: BOS, 1:PAD}),\n                                      train_ids=ids, train_lbls=lbl,\n                                      valid_ids=ids, valid_lbls=lbl, classes={0:0}, bs=8)\n\ndef test_from_ids_exports_classes():\n    this_tests(TextClasDataBunch.from_ids)\n    ids = [np.array([0])]*10\n    lbl = [0]*10\n    with tempfile.TemporaryDirectory() as tmp:\n        data = TextClasDataBunch.from_ids(tmp, vocab=Vocab({0: BOS, 1:PAD}),\n                                      train_ids=ids, train_lbls=lbl,\n                                      valid_ids=ids, valid_lbls=lbl,\n                                      classes=[\'a\', \'b\', \'c\'], bs=8)\n        data.export(Path(tmp)/\'export.pkl\')\n        empty_data = TextClasDataBunch.load_empty(tmp)\n        assert hasattr(empty_data, \'classes\')\n        assert empty_data.classes == [\'a\', \'b\', \'c\'] \n\ndef test_regression():\n    this_tests(\'na\')\n    path = untar_data(URLs.IMDB_SAMPLE)\n    df = text_df([0., 1.])\n    data = (TextList.from_df(df, path, cols=\'text\')\n             .split_by_rand_pct(0.2)\n             .label_from_df(cols=\'label\',label_cls=FloatList)\n             .databunch(bs=4))\n    assert data.c == 1\n    x,y = data.one_batch()\n'"
tests/test_text_languagemodelpreloader.py,0,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.text import *\n\ndef getAllBatches(data,epochs=1):\n    x=None\n    for i in range(epochs):\n        data.on_epoch_begin()\n        countIte=0\n        for xb,yb in data:\n            countIte += 1\n            d= xb.data.numpy()\n            if x is None:\n                x = xb.data.numpy().copy()\n            else:\n                x = np.concatenate((x, xb.data.numpy().copy()),axis=1)\n            continue\n        data.on_epoch_end()\n    return x,countIte\n\ndef jaggedWithConsecutiveNumbers(bs,sentence_len,iterations,minTokens):\n    ""create jagged array with random layout and filled with consequetive numbers""\n    jagged = []\n    count = 0\n    total = bs*sentence_len*iterations\n    while count < total:\n        nb = total-count if total-count<sentence_len else minTokens+int(np.random.random() * sentence_len)\n        jagged.append(np.arange(count+1,count+1+nb))\n        count = jagged[-1][-1]\n    jagged = np.asarray(jagged)\n    return jagged, count\n\ndef verify_datadirection( bs,seq_len,sentence_len, iterations,minTokens, backwards=False, nbTests=1000):\n    for i in range(nbTests):\n        jagged,countTokens = jaggedWithConsecutiveNumbers(bs,sentence_len,iterations,minTokens)\n\n        trainIDS = validIDS = jagged\n        db   = TextLMDataBunch.from_ids( ""."", None, trainIDS, validIDS, bptt=seq_len, bs=bs,no_check=True)\n        data = LanguageModelPreLoader(db.train_ds, bs=bs, bptt=seq_len, backwards=backwards, shuffle=False)\n        dl   = DataLoader(data, bs, shuffle=False)\n        batches, countIte = getAllBatches(dl)\n\n        assert countIte==len(dl), f""number of iteration does not match: countIte:{countIte}!= len(data):{len(dl)} ""\n\n        #The diff from one to the next column must be 1 for aligned mini-batches with forward indexing of the data\n        #(forward is default for LanguageModelLoader ie.: backwards=False)\n        b_diff = batches[:,1:] - batches[:,0:-1]\n        diff = -1 if backwards else 1\n        assert (b_diff.flatten()==diff).all(), ""the sequences of batch rows are not contiguous""\n\n        ix = np.arange(1,len(batches))\n        assert np.all(batches[ix-1,-1]+diff == batches[ix,0]), f""last token i row-1 {batches[ix-1,-1]}+{diff} must be equal to first element in row:{batches[ix,0]}""\n\ndef test_forward_minibatch():\n    this_tests(\'na\')\n    bs           = 4\n    seq_len      = 3\n    sentence_len = 20*seq_len\n    iterations   = 2\n    minTokens    = 1\n    verify_datadirection( bs, seq_len, sentence_len, iterations, minTokens, backwards=False, nbTests=1000)\n\ndef test_backwards_minibatch():\n    this_tests(\'na\')\n    bs           = 4\n    seq_len      = 3\n    sentence_len = 20*seq_len\n    iterations   = 2\n    minTokens    = 1\n    verify_datadirection( bs, seq_len, sentence_len, iterations, minTokens, backwards=True, nbTests=1000)\n'"
tests/test_text_qrnn.py,32,"b'import pytest,torch\nfrom fastai.basics import have_min_pkg_version\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.text.models.qrnn import ForgetMultGPU, BwdForgetMultGPU, forget_mult_CPU, QRNN, QRNNLayer\n\n@pytest.mark.cuda\n@pytest.mark.cpp\ndef test_forget_mult_forward_gpu():\n    this_tests(ForgetMultGPU)\n    dtype = torch.double\n    x,f,h,expected = range(3,8),[0.5]*5,1,range(1,7)\n    x,f,expected = [torch.tensor(t, dtype=dtype)[None,:,None].cuda() for t in (x,f,expected)]\n    #output = torch.zeros(1,6,1, dtype=dtype).cuda()\n    #output[0,0,0] = h\n    output = ForgetMultGPU.apply(x, f, h, True)\n    assert torch.allclose(output,expected[:,1:])\n\ndef random_inputs(shape, batch_first, **opts):\n    x = torch.randn(shape, **opts)\n    f = torch.randn(shape, **opts)\n    h = torch.randn((shape[0 if batch_first else 1], shape[2]), **opts)\n    return x, f, h\n\ndef detach_and_clone(t):\n    return t.detach().clone().requires_grad_(True)\n\n@pytest.mark.cuda\n@pytest.mark.cpp\ndef test_forget_mult_cuda():\n    this_tests(ForgetMultGPU, BwdForgetMultGPU)\n    x,f = torch.randn(5,3,20).cuda().chunk(2, dim=2)\n    x,f = x.contiguous().requires_grad_(True),f.contiguous().requires_grad_(True)\n    th_x,th_f = detach_and_clone(x),detach_and_clone(f)\n    for (bf, bw) in [(True,True), (False,True), (True,False), (False,False)]:\n        forget_mult = BwdForgetMultGPU if bw else ForgetMultGPU\n        th_out = forget_mult_CPU(th_x, th_f, hidden_init=None, batch_first=bf, backward=bw)\n        th_loss = th_out.pow(2).mean()\n        th_loss.backward()\n        out = forget_mult.apply(x, f, None, bf)\n        loss = out.pow(2).mean()\n        loss.backward()\n        assert torch.allclose(th_out,out, rtol=1e-4, atol=1e-5)\n        assert torch.allclose(th_x.grad,x.grad, rtol=1e-4, atol=1e-5)\n        assert torch.allclose(th_f.grad,f.grad, rtol=1e-4, atol=1e-5)\n        for p in [x,f, th_x, th_f]:\n            p = p.detach()\n            p.grad = None\n        h = torch.randn((5 if bf else 3), 10).cuda().requires_grad_(True)\n        th_h = detach_and_clone(h)\n        th_out = forget_mult_CPU(th_x, th_f, hidden_init=th_h, batch_first=bf, backward=bw)\n        th_loss = th_out.pow(2).mean()\n        th_loss.backward()\n        out = forget_mult.apply(x.contiguous(), f.contiguous(), h, bf)\n        loss = out.pow(2).mean()\n        loss.backward()\n        assert torch.allclose(th_out,out, rtol=1e-4, atol=1e-5)\n        assert torch.allclose(th_x.grad,x.grad, rtol=1e-4, atol=1e-5)\n        assert torch.allclose(th_f.grad,f.grad, rtol=1e-4, atol=1e-5)\n        assert torch.allclose(th_h.grad,h.grad, rtol=1e-4, atol=1e-5)\n        for p in [x,f, th_x, th_f]:\n            p = p.detach()\n            p.grad = None\n\ndef manual_forget_mult(x, f, h=None, batch_first=True, backward=False):\n    if batch_first: x,f = x.transpose(0,1),f.transpose(0,1)\n    out = torch.zeros_like(x)\n    prev = h if h is not None else torch.zeros_like(out[0])\n    idx_range = range(x.shape[0]-1,-1,-1) if backward else range(x.shape[0])\n    for i in idx_range:\n        out[i] = f[i] * x[i] + (1-f[i]) * prev\n        prev = out[i]\n    if batch_first: out = out.transpose(0,1)\n    return out\n\ndef test_forget_mult():\n    this_tests(forget_mult_CPU)\n    x,f = torch.randn(5,3,20).chunk(2, dim=2)\n    for (bf, bw) in [(True,True), (False,True), (True,False), (False,False)]:\n        th_out = manual_forget_mult(x, f, batch_first=bf, backward=bw)\n        out = forget_mult_CPU(x, f, batch_first=bf, backward=bw)\n        assert torch.allclose(th_out,out)\n        h = torch.randn((5 if bf else 3), 10)\n        th_out = manual_forget_mult(x, f, h=h, batch_first=bf, backward=bw)\n        out = forget_mult_CPU(x, f, hidden_init=h, batch_first=bf, backward=bw)\n        assert torch.allclose(th_out,out)\n\n# bug in pytorch=1.0.1, fixed in 1.0.2 https://github.com/pytorch/pytorch/issues/18189\n@pytest.mark.skipif(not have_min_pkg_version(""torch"", ""1.0.2""), reason=""requires torch>=1.0.2"")\ndef test_qrnn_layer():\n    this_tests(QRNNLayer)\n    qrnn_fwd = QRNNLayer(10, 20, save_prev_x=True, zoneout=0, window=2, output_gate=True)\n    qrnn_bwd = QRNNLayer(10, 20, save_prev_x=True, zoneout=0, window=2, output_gate=True, backward=True)\n    qrnn_bwd.load_state_dict(qrnn_fwd.state_dict())\n    x_fwd = torch.randn(7,5,10)\n    x_bwd = x_fwd.clone().flip(1)\n    y_fwd,h_fwd = qrnn_fwd(x_fwd)\n    y_bwd,h_bwd = qrnn_bwd(x_bwd)\n    assert torch.allclose(y_fwd, y_bwd.flip(1), rtol=1e-4, atol=1e-5)\n    assert torch.allclose(h_fwd, h_bwd, rtol=1e-4, atol=1e-5)\n    y_fwd,h_fwd = qrnn_fwd(x_fwd, h_fwd)\n    y_bwd,h_bwd = qrnn_bwd(x_bwd, h_bwd)\n    assert torch.allclose(y_fwd, y_bwd.flip(1), rtol=1e-4, atol=1e-5)\n    assert torch.allclose(h_fwd, h_bwd, rtol=1e-4, atol=1e-5)\n\ndef test_qrnn_bidir():\n    this_tests(QRNN)\n    qrnn = QRNN(10, 20, 2, bidirectional=True, batch_first=True, window=2, output_gate=False)\n    x = torch.randn(7,5,10)\n    y,h = qrnn(x)\n    assert y.size() == torch.Size([7, 5, 40])\n    assert h.size() == torch.Size([4, 7, 20])\n    #Without an out gate, the last timestamp in the forward output is the second to last hidden\n    #and the first timestamp of the backward output is the last hidden\n    assert torch.allclose(y[:,-1,:20], h[2])\n    assert torch.allclose(y[:,0,20:], h[3])\n'"
tests/test_text_train.py,5,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.text import *\n\npytestmark = pytest.mark.integration\n\ndef read_file(fname):\n    texts = []\n    with open(fname, \'r\') as f: texts = f.readlines()\n    labels = [0] * len(texts)\n    df = pd.DataFrame({\'labels\':labels, \'texts\':texts}, columns = [\'labels\', \'texts\'])\n    return df\n\ndef prep_human_numbers():\n    path = untar_data(URLs.HUMAN_NUMBERS)\n    df_trn = read_file(path/\'train.txt\')\n    df_val = read_file(path/\'valid.txt\')\n    return path, df_trn, df_val\n\ndef config(qrnn:bool=False):\n    config = awd_lstm_lm_config.copy()\n    config[\'emb_sz\'],config[\'n_hid\'],config[\'n_layers\'],config[\'qrnn\'] = 100,100,1,qrnn\n    return config\n\n@pytest.fixture(scope=""module"")\ndef learn():\n    path, df_trn, df_val = prep_human_numbers()\n    df = df_trn.append(df_val)\n    data = (TextList.from_df(df, path, cols=\'texts\')\n                .split_by_idx(list(range(len(df_trn),len(df))))\n                .label_for_lm()\n                .add_test(df[\'texts\'].iloc[:200].values)\n                .databunch())\n    learn = language_model_learner(data, AWD_LSTM, pretrained=False, config=config(), drop_mult=0.)\n    learn.opt_func = partial(optim.SGD, momentum=0.9)\n    learn.fit(3,1)\n    return learn\n\ndef n_params(learn): return sum([len(pg[\'params\']) for pg in learn.opt.opt.param_groups])\n\ndef test_opt_params(learn):\n    this_tests(\'na\')\n    learn.freeze()\n    assert n_params(learn) == 2\n    learn.unfreeze()\n    assert n_params(learn) == 6\n\ndef manual_seed(seed=42):\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\ndef test_val_loss(learn):\n    this_tests(learn.validate)\n    assert learn.validate()[1] > 0.3\n\n@pytest.mark.slow\ndef test_qrnn_works_with_no_split():\n    this_tests(language_model_learner)\n    gc.collect()\n    manual_seed()\n    path, df_trn, df_val = prep_human_numbers()\n    data = TextLMDataBunch.from_df(path, df_trn, df_val, tokenizer=Tokenizer(BaseTokenizer))\n    learn = language_model_learner(data, AWD_LSTM, pretrained=False, config=config(True), drop_mult=0.)\n    learn = LanguageLearner(data, learn.model) #  remove the split_fn\n    learn.fit_one_cycle(2, 0.1)\n    assert learn.validate()[1] > 0.3\n\n@pytest.mark.slow\ndef test_qrnn_works_if_split_fn_provided():\n    this_tests(language_model_learner)\n    gc.collect()\n    manual_seed()\n    path, df_trn, df_val = prep_human_numbers()\n    data = TextLMDataBunch.from_df(path, df_trn, df_val, tokenizer=Tokenizer(BaseTokenizer))\n    learn = language_model_learner(data, AWD_LSTM, pretrained=False, config=config(True), drop_mult=0.)\n    learn.fit_one_cycle(2, 0.1)\n    assert learn.validate()[1] > 0.3\n\ndef test_vocabs(learn):\n    this_tests(\'na\')\n    for ds in [learn.data.valid_ds, learn.data.test_ds]:\n        assert len(learn.data.train_ds.vocab.itos) == len(ds.vocab.itos)\n        assert np.all(learn.data.train_ds.vocab.itos == ds.vocab.itos)\n\ndef text_df(n_labels):\n    data = []\n    texts = [""fast ai is a cool project"", ""hello world""]\n    for ind, text in enumerate(texts):\n        sample = {}\n        for label in range(n_labels): sample[label] = ind%2\n        sample[""text""] = text\n        data.append(sample)\n    df = pd.DataFrame(data)\n    return df\n\ndef test_classifier():\n    this_tests(text_classifier_learner)\n    for n_labels in [1, 8]:\n        path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'data\', \'tmp\')\n        os.makedirs(path)\n        try:\n            expected_classes = n_labels if n_labels > 1 else 2\n            df = text_df(n_labels=n_labels)\n            data = TextClasDataBunch.from_df(path, train_df=df, valid_df=df, label_cols=list(range(n_labels)), text_cols=[""text""], bs=2)\n            classifier = text_classifier_learner(data, AWD_LSTM, pretrained=False, bptt=10)\n            assert last_layer(classifier.model).out_features == expected_classes\n            assert len(data.train_dl) == math.ceil(len(data.train_ds)/data.train_dl.batch_size)\n            assert next(iter(data.train_dl))[0].shape == (2, 7)\n            assert next(iter(data.valid_dl))[0].shape == (2, 7)\n        finally:\n            shutil.rmtree(path)\n\n# TODO: may be move into its own test module?\nimport gc\n# everything created by this function should be freed at its exit\ndef clean_destroy_block():\n    path, df_trn, df_val = prep_human_numbers()\n    data = TextLMDataBunch.from_df(path, df_trn, df_val, tokenizer=Tokenizer(BaseTokenizer))\n    learn = language_model_learner(data, AWD_LSTM, pretrained=False, config=config(), drop_mult=0.)\n    learn.lr_find()\n\n@pytest.mark.skip(reason=""fix me"")\ndef test_mem_leak():\n    this_tests(\'na\')\n    gc.collect()\n    garbage_before = len(gc.garbage)  # should be 0 already, or something leaked earlier\n    assert garbage_before == 0\n    clean_destroy_block()\n\n    gc_collected = gc.collect() # should be 0 too - !0 means we have circular references\n    assert gc_collected < 102 # scipy has some cyclic references that we want to ignore (this accounts for 100 objects).\n    garbage_after = len(gc.garbage)  # again, should be 0, or == garbage_before\n    assert garbage_after == 0\n\ndef test_order_preds():\n    this_tests(text_classifier_learner)\n    path, df_trn, df_val = prep_human_numbers()\n    df_val.labels = np.random.randint(0,5,(len(df_val),))\n    data_clas = (TextList.from_df(df_val, path, cols=\'texts\')\n                .split_by_idx(list(range(200)))\n                .label_from_df(cols=\'labels\')\n                .databunch())\n    learn = text_classifier_learner(data_clas, AWD_LSTM, pretrained=False)\n    preds = learn.get_preds(ordered=True)\n    true_value = np.array([learn.data.train_ds.c2i[o] for o in df_val.iloc[:200,0]])\n    np.all(true_value==preds[1].numpy())\n'"
tests/test_text_transform.py,0,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.text import *\n\ndef test_rules():\n    this_tests(fix_html, replace_rep, replace_wrep, rm_useless_spaces, spec_add_spaces, replace_all_caps, deal_caps)\n    assert fix_html(""Some HTML&nbsp;text<br />"") == ""Some HTML& text\\n""\n    assert replace_rep(""I\'m so excited!!!!!!!!"") == ""I\'m so excited xxrep 8 ! ""\n    assert replace_wrep(""I\'ve never ever ever ever ever ever ever ever done this."") == ""I\'ve never  xxwrep 7 ever  done this.""\n    assert rm_useless_spaces(""Inconsistent   use  of     spaces."") == ""Inconsistent use of spaces.""\n    assert spec_add_spaces(\'I #like to #put #hashtags #everywhere!\') == ""I  # like to  # put  # hashtags  # everywhere!""\n    assert replace_all_caps([\'Mark\',\'CAPITALIZED\',\'Only\']) == [\'Mark\', \'xxup\', \'capitalized\', \'Only\']\n    assert deal_caps([\'Mark\',\'Capitalized\',\'lower\', \'All\']) == [\'xxmaj\', \'mark\', \'xxmaj\', \'capitalized\', \'lower\', \'xxmaj\', \'all\']\n\ndef test_tokenize():\n    this_tests(Tokenizer)\n    texts = [\'one two three four\', \'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\', ""I\'m suddenly SHOUTING FOR NO REASON""]\n    tokenizer = Tokenizer(BaseTokenizer)\n    toks = tokenizer.process_all(texts)\n    assert toks[0] == [\'one\', \'two\', \'three\', \'four\']\n    assert toks[1][:6] == [\'xxmaj\', \'lorem\', \'ipsum\', \'dolor\', \'sit\', \'amet,\']\n    assert \' \'.join(toks[2]) == ""xxmaj i\'m suddenly xxup shouting xxup for xxup no xxup reason""\n\ndef test_tokenize_handles_empty_lines():\n    this_tests(Tokenizer)\n    texts = [\'= Markdown Title =\\n\\nMakrdown Title does not have spaces around\']\n    tokenizer = Tokenizer(BaseTokenizer)\n    toks = tokenizer.process_all(texts)\n    assert toks[0] == [\'=\', \'xxmaj\', \'markdown\', \'xxmaj\', \'title\', \'=\', \'\\n\', \'\\n\',\n                       \'xxmaj\', \'makrdown\', \'xxmaj\', \'title\', \'does\', \'not\', \'have\', \'spaces\', \'around\']\n\ndef test_tokenize_ignores_extraneous_space():\n    this_tests(Tokenizer)\n    texts = [\'test \']\n    tokenizer = Tokenizer(BaseTokenizer)\n    toks = tokenizer.process_all(texts)\n    assert toks[0] == [\'test\']\n\ndef test_numericalize_and_textify():\n    toks = [[\'ok\', \'!\', \'xxmaj\', \'nice\', \'!\', \'anti\', \'-\', \'virus\'], [\'!\', \'xxmaj\', \'meg\', \'xxmaj\', \'nice\', \'meg\']]\n    vocab = Vocab.create(toks, max_vocab=20, min_freq=2)\n    this_tests(vocab.numericalize, vocab.textify)\n    assert vocab.numericalize(toks[0]) == [0, 9, 5, 10, 9, 0, 0, 0]\n    assert vocab.textify([0, 3, 10, 11, 9]) == \'xxunk xxeos nice meg !\'\n    print(vocab.stoi)\n    with pytest.raises(IndexError):\n        vocab.textify([16])\n'"
tests/test_torch_core.py,47,"b'import pytest, torch, fastai\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.torch_core import *\nfrom fastai.layers import *\nfrom math import isclose\n\na=[1,2,3]\nexp=torch.tensor(a)\nb=[3,6,6]\n\ndef test_tensor_with_list():\n    this_tests(tensor)\n    r = tensor(a)\n    assert torch.all(r==exp)\n\ndef test_tensor_with_ndarray():\n    this_tests(tensor)\n    b=np.array(a, dtype=np.int64)\n    r = tensor(b)\n    assert np_address(r.numpy()) == np_address(b)\n    assert torch.all(r==exp)\n\ndef test_tensor_with_tensor():\n    this_tests(tensor)\n    c=torch.tensor(a)\n    r = tensor(c)\n    assert r.data_ptr()==c.data_ptr()\n    assert torch.all(r==exp)\n\ndef test_requires_grad():\n    this_tests(requires_grad)\n    m = simple_cnn(b)\n    assert requires_grad(m) == True\n\ndef test_requires_grad_set():\n    this_tests(requires_grad)\n    m = simple_cnn(b)\n    requires_grad(m,False)\n    allF = np.all([not p.requires_grad for p in m.parameters()])\n    assert allF, ""requires_grad(m,False) did not set all parameters to False""\n    requires_grad(m,True)\n    allT = np.all([p.requires_grad for p in m.parameters()])\n    assert allT, ""requires_grad(m,True) did not set all parameters to True""\n\ndef test_apply_init():\n    this_tests(apply_leaf, apply_init)\n    m = simple_cnn(b,bn=True)\n    all2 = lambda m: nn.init.constant_(m.weight,0.2) if hasattr(m, \'weight\') else m\n    all7 = lambda m: nn.init.constant_(m,0.7)\n    apply_leaf(m,all2)\n    apply_init(m,all7)\n    conv1_w = torch.full([6,3,3,3],0.7)\n    bn1_w = torch.full([6],0.2)\n    assert conv1_w.equal(m[0][0].weight), ""Expected first colvulition layer\'s weights to be %r"" % conv1_w\n    assert bn1_w.equal(m[0][2].weight), ""Expected first batch norm layers weights to be %r"" % bn1_w\n\ndef test_in_channels():\n    this_tests(in_channels)\n    m = simple_cnn(b)\n    assert in_channels(m) == 3\n\ndef test_in_channels_no_weights():\n    this_tests(in_channels)\n    with pytest.raises(Exception) as e_info:\n        in_channels(nn.Sequential())\n    assert e_info.value.args[0] == \'No weight layer\'\n    \ndef test_range_children():\n    this_tests(range_children)\n    m = simple_cnn(b)\n    assert len(range_children(m)) == 3\n\ndef test_split_model():\n    this_tests(split_model)\n    m = simple_cnn(b)\n    pool = split_model(m,[m[2][0]])[1][0]\n    assert pool == m[2][0], ""Did not properly split at adaptive pooling layer""\n\ndef test_split_no_wd_params():\n    this_tests(split_no_wd_params)\n    groups = split_no_wd_params(simple_cnn((1, 1, 1), bn=True))\n    assert len(groups[0]) == 1\n    assert len(groups[1]) == 2\n\ndef test_set_bn_eval():\n    this_tests(set_bn_eval)\n    m = simple_cnn(b,bn=True)\n    requires_grad(m,False)\n    set_bn_eval(m)\n    assert m[0][2].training == False, ""Batch norm layer not properly set to eval mode""\n\ndef test_np2model_tensor():\n    this_tests(np2model_tensor)\n    a = np.ones([2,2])\n    t = np2model_tensor(a)\n    assert isinstance(t,torch.FloatTensor)\n    \ndef test_np_address(): \n    this_tests(np_address)\n    a=np.ndarray(shape=(2,2))\n    add=np_address(a)\n    assert isinstance(add, int)\n\ndef test_to_data():\n    this_tests(to_data)    \n    path = untar_data(URLs.MNIST_SAMPLE)\n    data1 = ImageDataBunch.from_folder(path)\n    ys1 = list(data1.y)\n    a=([1,2,3],[3,6,6])\n    b=([4,5,6],[4,7,7])\n    data2 = torch.tensor([a,b])\n    ys2= list(data2[0])\n    assert isinstance(data1, fastai.vision.data.ImageDataBunch)\n    assert isinstance(data1.y, ItemList)\n    assert isinstance(ys1, list)\n    assert isinstance(ys1[0], Category)\n    assert isinstance(ys1[0].data, np.int64)\n    assert isinstance(to_data(ys1[0]), np.int64)\n    assert ys1[0].data == to_data(ys1[0]) \n    assert isinstance(data2, torch.Tensor)\n    assert isinstance(data2[0], torch.Tensor)\n    assert isinstance(ys2, list)\n    assert isinstance(ys2[0], torch.Tensor)\n    assert isinstance(ys2[0].data, torch.Tensor)\n    assert isinstance(to_data(ys2[0]), torch.Tensor) \n    assert torch.all(torch.eq(ys2[0].data, to_data(ys2[0]))) \n    \n@pytest.mark.cuda\ndef test_to_detach():\n    this_tests(to_detach)\n    a=([1.,2.,3.],[3.,6.,6.])\n    b=np.array([[4,5,6],[4,7,7]])\n    ta=torch.tensor(a, requires_grad=True).cuda()\n    dta=to_detach(a)\n    dtta=to_detach(ta, False)\n    dttacpu=to_detach(ta, True)\n    db=to_detach(b)\n    assert ta.is_cuda\n    assert isinstance(ta, (torch.cuda.FloatTensor or torch.cuda.DoubleTensor or torch.cuda.HalfTensor))\n    assert ta.requires_grad \n    assert dtta.is_cuda\n    assert isinstance(dtta, (torch.cuda.FloatTensor or torch.cuda.DoubleTensor or torch.cuda.HalfTensor))\n    assert not dtta.requires_grad\n    assert not dttacpu.is_cuda\n    assert isinstance(dttacpu, (torch.FloatTensor or torch.DoubleTensor or torch.HalfTensor))\n    assert not dttacpu.requires_grad\n    assert isinstance(b,np.ndarray)\n    assert isinstance(db,np.ndarray)\n    assert np.all([b,db]) \n    \n@pytest.mark.cuda    \ndef test_to_cpu():\n    this_tests(to_cpu)\n    a=([1,2,3],[3,6,6])\n    b=([4,5,6],[4,7,7])\n    ta=torch.tensor(a).cuda()\n    tb=torch.tensor(b)\n    tacpu=to_cpu(ta)\n    tbcpu=to_cpu(tb)\n    assert ta.is_cuda\n    assert isinstance(ta, (torch.cuda.LongTensor or torch.cuda.IntTensor or torch.cuda.ShortTensor))\n    assert not tacpu.is_cuda\n    assert isinstance(tacpu, (torch.LongTensor or torch.IntTensor or torch.ShortTensor))\n    assert not tb.is_cuda\n    assert isinstance(tb, (torch.LongTensor or torch.IntTensor or torch.ShortTensor))\n    assert not tbcpu.is_cuda\n    assert isinstance(tbcpu, (torch.LongTensor or torch.IntTensor or torch.ShortTensor))\n\ndef test_to_half():\n    this_tests(to_half)\n    a=([1.,2.,3.],[3.,6.,6.])\n    b=([1,2,3],[3,6,6])\n    ta=torch.tensor(a)\n    tb=torch.tensor(b)\n    tfl=to_half(ta)\n    tint=to_half(tb)\n    assert tfl[0].dtype == torch.half\n    assert tfl[1].dtype == torch.half\n    assert tint[0].dtype == torch.int64 or torch.int32 or torch.int16\n    assert tint[1].dtype == torch.int64 or torch.int32 or torch.int16\n    \ndef test_to_float():\n    this_tests(to_float)\n    a=([1.,2.,3.],[3.,6.,6.])\n    b=([1,2,3],[3,6,6])\n    ta=torch.tensor(a)\n    tb=torch.tensor(b)\n    tfl=to_float(ta)\n    tint=to_float(tb)\n    assert tfl[0].dtype == torch.float32\n    assert tfl[1].dtype == torch.float32\n    assert tint[0].dtype == torch.int64 or torch.int32 or torch.int16\n    assert tint[1].dtype == torch.int64 or torch.int32 or torch.int16\n    \ndef test_children():\n    this_tests(children)\n    m=nn.Sequential(nn.Linear(2,2), nn.ReLU())\n    ch=children(m)\n    assert len(ch) == 2\n    assert isinstance(ch, list)\n    assert isinstance(ch[0], torch.nn.modules.linear.Linear)\n    assert isinstance(ch[1], torch.nn.modules.activation.ReLU)\n\ndef test_num_children():\n    this_tests(num_children)\n    m=nn.Sequential(nn.Linear(2,2), nn.ReLU())\n    n=num_children(m)\n    assert isinstance(n, int)\n    assert n == 2\n    \ndef test_first_layer():\n    this_tests(first_layer)\n    m=nn.Sequential(nn.Linear(2,2), nn.ReLU())\n    fl=first_layer(m)\n    assert isinstance(fl, nn.Module)\n    assert isinstance(fl, torch.nn.modules.linear.Linear)\n    \ndef test_last_layer():\n    this_tests(last_layer)\n    m=nn.Sequential(nn.Linear(2,2), nn.ReLU())\n    ll=last_layer(m)\n    assert isinstance(ll, nn.Module)\n    assert isinstance(ll, torch.nn.modules.activation.ReLU)\n    \ndef test_model_type(): \n    this_tests(model_type) \n    a=np.array([1.,2.,3.]).dtype \n    b=np.array([1,2,3]).dtype \n    c=np.array([""1"",""2"",""3""]).dtype \n    assert model_type(a) == torch.float32 \n    assert model_type(b) == torch.int64 \n    assert model_type(c) == None   \n    \ndef test_trange_of():\n    this_tests(trange_of)\n    t = trange_of(a)\n    assert len(t) == len(a)\n    assert t[0] == 0\n    assert t[1] == 1\n    assert t[2] == 2\n    \ndef test_to_np():\n    this_tests(to_np)\n    a = to_np(exp)\n    assert isinstance(a,np.ndarray)\n\ndef test_none_reduce_on_cpu():\n    this_tests(NoneReduceOnCPU)\n    y_pred = torch.ones([3,8], requires_grad=True)\n    y_true = torch.zeros([3],dtype=torch.long)\n    with NoneReduceOnCPU(nn.CrossEntropyLoss()) as lf:\n        loss = lf(y_pred,y_true)\n        assert isclose(loss.sum(),6.23,abs_tol=1e-2), ""final loss does not seem to be correct""\n    with NoneReduceOnCPU(F.cross_entropy) as lf:\n        loss = lf(y_pred,y_true)\n        assert isclose(loss.sum(),6.23,abs_tol=1e-2), ""final loss without reduction does not seem to be correct""\n\ndef test_tensor_array_monkey_patch():\n    this_tests(\'na\')\n    t = torch.ones(a)\n    t = np.array(t)\n    assert np.all(t == t), ""Tensors did not properly convert to numpy arrays""\n    t = torch.ones(a)\n    t = np.array(t,dtype=float)\n    assert np.all(t == t), ""Tensors did not properly convert to numpy arrays with a dtype set""\n\ndef test_keep_parameter():\n    sa = SelfAttention(128)\n    this_tests(SelfAttention)\n    flat = nn.Sequential(*flatten_model(sa))\n    for p in sa.parameters(): assert id(p) in [id(a) for a in flat.parameters()]\n'"
tests/test_train.py,0,"b'""""""\nmodule: train.py - Model fitting methods\ndocs  : https://docs.fast.ai/train.html\n""""""\n\nimport pytest, fastai\nfrom utils.fakes import *\nfrom utils.text import *\nfrom fastai.gen_doc.doctest import this_tests\n\n@pytest.fixture(scope=""module"")\ndef learn():\n    learn = fake_learner(50,50)\n    return learn\n\ndef test_lr_find(learn):\n    this_tests(learn.lr_find)\n    wd, start_lr, num_it, end_lr = 0.002, 1e-06, 90, 10\n    lr_find(learn=learn, start_lr=start_lr, end_lr=end_lr, num_it=num_it, stop_div=True, wd=wd)\n    assert len(learn.recorder.moms) == len(learn.recorder.lrs)\n    assert learn.recorder.lrs[0] == start_lr\n    assert learn.recorder.moms[0] == 0.9\n    assert learn.recorder.lrs[-1] < learn.recorder.opt.lr\n    assert learn.recorder.opt.wd == wd\n    lr_find(learn=learn, start_lr=start_lr, end_lr=end_lr, num_it=num_it, stop_div=False, wd=wd)\n    assert len(learn.recorder.lrs) == num_it\n\ndef test_fit(learn):\n    this_tests(learn.fit)\n    # Test confirms learning rate and momentum are stable, see difference to test_fit_one_cycle\n    learning_rate, weight_decay, eps = 3e-3, 1e-2,  4\n    with CaptureStdout() as cs:  learn.fit(epochs=eps, lr=learning_rate, wd=weight_decay)\n    assert set(learn.recorder.lrs) == {learning_rate}\n    assert set(learn.recorder.moms) == {learn.recorder.moms[0]}\n\ndef test_fit_one_cycle(learn):\n    # Test confirms expected behavior change of learning rate and momentum\n    # see graphical representation here: output cell 17 of, learn.sched.plot_lr() in\n    # https://github.com/sgugger/Deep-Learning/blob/master/Cyclical%20LR%20and%20momentums.ipynb\n    lr, cycle_length = 3e-3,  4\n    with CaptureStdout() as cs: learn.fit_one_cycle(cycle_length, lr)\n    this_tests(learn.fit_one_cycle)\n    listlrs = list(learn.recorder.lrs)\n    listmoms = list(learn.recorder.moms)\n    # we confirm learning rate is at its max when momentum is at its min\n    val_lr, idx_lr = max((val, idx) for (idx, val) in enumerate(listlrs))\n    val_mom, idx_mom = min((val, idx) for (idx, val) in enumerate(listmoms))\n    assert idx_lr == idx_mom\n    maxlr_minmom = idx_lr # = idx_mom\n    # confirm 1st half (left): learning rate is at its minimum when momentum is at its maximum\n    val_lr, idx_lr = min((val, idx) for (idx, val) in enumerate(listlrs[0:maxlr_minmom+1]))\n    val_mom, idx_mom = max((val, idx) for (idx, val) in enumerate(listmoms[0:maxlr_minmom+1]))\n    assert idx_lr == idx_mom\n    # confirm 2nd half (right): learning rate is at its minimum when momentum is at its maximum\n    val_lr, idx_lr = min((val, idx) for (idx, val) in enumerate(listlrs[maxlr_minmom:]))\n    val_mom, idx_mom = max((val, idx) for (idx, val) in enumerate(listmoms[maxlr_minmom:]))\n    assert idx_lr == idx_mom\n'"
tests/test_utils.py,1,"b""import pytest, torch, re, fastai\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.torch_core import *\nfrom fastai.utils.show_install import *\nfrom fastai.utils.check_perf import *\nfrom PIL import Image\n\ndef test_show_install(capsys):\n    this_tests(show_install)\n    show_install()\n    captured = capsys.readouterr()\n    #print(captured.out)\n    match = re.findall(rf'fastai\\s+: {fastai.__version__}', captured.out)\n    assert match\n    match = re.findall(rf'torch\\s+: {re.escape(torch.__version__)}', captured.out)\n    assert match\n\ndef test_check_perf(capsys):\n    this_tests(check_perf)\n    check_perf()\n    captured = capsys.readouterr()\n    #print(captured.out)\n    #match = re.findall(rf'Running Pillow.*?{Image.PILLOW_VERSION}', captured.out)\n    #assert match\n"""
tests/test_utils_fastai.py,0,"b""import pytest, fastai\nfrom fastai.gen_doc.doctest import this_tests\n\ndef test_has_version():\n    this_tests('na')\n    assert fastai.__version__\n"""
tests/test_utils_links.py,3,"b'import pytest, torch\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.gen_doc import gen_notebooks\nfrom fastai.gen_doc import nbdoc\n\ndef assert_link(docstr, expected, nb_cells=None, modules=None, msg=\'\'):\n    if modules is None: modules = gen_notebooks.get_imported_modules(nb_cells or [])\n    linked = nbdoc.link_docstring(modules, docstr)\n    assert linked == expected, f\'{msg}\\nExpected: {expected}\\nActual  : {linked}\'\n\ndef build_nb_cells(mod_names):\n    return [{\'cell_type\': \'code\', \'source\': f\'from {m} import *\'} for m in mod_names]\n\n@pytest.mark.skip(reason=""need to update"")\ndef test_torchvision():\n    this_tests(\'na\')\n    docstr   = \'Note that `tvm` is the namespace we use for `torchvision.models`.\'\n    expected = \'Note that [`tvm`](https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models) is the namespace we use for `torchvision.models`.\'\n    assert_link(docstr, expected, msg=\'Should match imported aliases\')\n\ndef test_fastai_prefix():\n    this_tests(\'na\')\n    docstr   = ""functions for your application (`fastai.vision`)""\n    expected = ""functions for your application ([`fastai.vision`](/vision.html#vision))""\n    assert_link(docstr, expected, msg=\'Should match keywords prefixed with fastai. See `index.ipynb`\')\n\ndef test_link_typedef():\n    this_tests(\'na\')\n    docstr   = r""- `LayerFunc` = `Callable`\\[`nn.Module`],`None`]""\n    expected = r""- `LayerFunc` = `Callable`\\[[`nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)],`None`]""\n    assert_link(docstr, expected, modules=[torch], msg=\'Type definitions to torch formatted incorrectly. See fastai_typing.ipynb\')\n\ndef test_link_typedef_double_bt():\n    this_tests(\'na\')\n    docstr   = r""- `ParamList` = `Collection`\\[`nn`.`Parameter`]""\n    expected = r""- `ParamList` = `Collection`\\[[`nn`](https://pytorch.org/docs/stable/nn.html#torch-nn).`Parameter`]""\n    assert_link(docstr, expected)\n\ndef test_link_inner_class_functions():\n    this_tests(\'na\')\n    docstr   = ""To train your model in mixed precision you just have to call `Learner.to_fp16`, which converts the model and modifies the existing `Learner` to add `MixedPrecision`.""\n    expected = ""To train your model in mixed precision you just have to call [`Learner.to_fp16`](/train.html#to_fp16), which converts the model and modifies the existing [`Learner`](/basic_train.html#Learner) to add [`MixedPrecision`](/callbacks.fp16.html#MixedPrecision).""\n    imports = \'from fastai.callbacks.fp16 import *\'\n    assert_link(docstr, expected, nb_cells=[gen_notebooks.get_code_cell(imports)])\n\ndef test_class_anchor():\n    this_tests(\'na\')\n    docstr   = ""`DataBunch.create`, `DeviceDataLoader.proc_batch`""\n    expected = ""[`DataBunch.create`](/basic_data.html#DataBunch.create), [`DeviceDataLoader.proc_batch`](/basic_data.html#DeviceDataLoader.proc_batch)""\n    imports = \'from fastai.basic_train import *\'\n    assert_link(docstr, expected, nb_cells=[gen_notebooks.get_code_cell(imports)])\n\ndef test_link_class_methods():\n    this_tests(\'na\')\n    docstr   = ""`ImageDataBunch.from_csv`""\n    expected = ""[`ImageDataBunch.from_csv`](/vision.data.html#ImageDataBunch.from_csv)""\n    imports = \'from fastai.vision.data import *\'\n    assert_link(docstr, expected, nb_cells=[gen_notebooks.get_code_cell(imports)])\n\ndef test_respects_import_order():\n    this_tests(\'na\')\n    docstr   = ""`learner`""\n    expected = ""[`learner`](/vision.learner.html#vision.learner)""\n    assert_link(docstr, expected, build_nb_cells([\'fastai.text\', \'fastai.vision\']))\n\n    expected_text = ""[`learner`](/text.learner.html#text.learner)""\n    assert_link(docstr, expected_text, build_nb_cells([\'fastai.vision\', \'fastai.text\']))\n\ndef test_nb_module_name_has_highest_priority():\n    this_tests(\'na\')\n    # get_imported_modules.nb_module_name should have highest priority. This is the associated notebook module.\n    # Ex: vision.transforms.ipynb is associated with fastai.vision.transforms\n    docstr   = ""`transform`""\n    expected = ""[`transform`](/text.transform.html#text.transform)""\n    modules = gen_notebooks.get_imported_modules([], nb_module_name=\'fastai.text.transform\')\n    assert_link(docstr, expected, modules=modules)\n\n    expected = ""[`transform`](/tabular.transform.html#tabular.transform)""\n    modules = gen_notebooks.get_imported_modules([], nb_module_name=\'fastai.tabular.transform\')\n    assert_link(docstr, expected, modules=modules)\n\n@pytest.mark.skip(reason=""need to update"")\ndef test_application_links_top_level_modules():\n    this_tests(\'na\')\n    # Snippet taken from applications.ipynb\n    docstr = """"""## Module structure\nIn each case (except for `collab`), the module is organized this way:\n### `transform`\n### `data`\n### `models`\n### `learner`""""""\n    expected = """"""## Module structure\nIn each case (except for [`collab`](/collab.html#collab)), the module is organized this way:\n### [`transform`](/text.transform.html#text.transform)\n### [`data`](/text.data.html#text.data)\n### [`models`](/text.models.html#text.models)\n### [`learner`](/text.learner.html#text.learner)""""""\n    assert_link(docstr, expected, msg=\'data, models should link to highest module. transform and learner links to first match\')\n\ndef test_link_vision_learner_priority():\n    this_tests(\'na\')\n    # Edge case for vision.learner.ipynb\n    imports = """"""from fastai.gen_doc.nbdoc import *\n    from fastai.vision import *\n    from fastai.vision import data\n    """"""\n\n    docstr   = ""Pass in your `data`, calculated `preds`, actual `y`,""\n    expected = ""Pass in your [`data`](/vision.data.html#vision.data), calculated `preds`, actual `y`,""\n    err_msg = ""`data` should link to vision.data instead of text.data.""\n    modules = gen_notebooks.get_imported_modules([gen_notebooks.get_code_cell(imports)], nb_module_name=\'fastai.vision.learner\')\n    assert_link(docstr, expected, modules=modules, msg=err_msg)\n'"
tests/test_utils_mem.py,1,"b'import pytest\nfrom fastai.utils.mem import *\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.mem import *\nfrom utils.text import *\nfrom math import isclose\n\n# Important: When modifying this test module, make sure to validate that it runs w/o\n# GPU, by running: CUDA_VISIBLE_DEVICES="""" pytest\n\n# most tests are run regardless of cuda available or not, we just get zeros when gpu is not available\nuse_gpu = torch.cuda.is_available()\ntorch_preload_mem()\n\ndef check_gpu_mem_zeros(total, used, free):\n    assert total == 0, ""have total GPU RAM""\n    assert used  == 0, ""have used GPU RAM""\n    assert free  == 0, ""have free GPU RAM""\n\ndef check_gpu_mem_non_zeros(total, used, free):\n    assert total > 0, ""have total GPU RAM""\n    assert used  > 0, ""have used GPU RAM""\n    assert free  > 0, ""have free GPU RAM""\n\ndef test_gpu_mem_by_id():\n    this_tests(gpu_mem_get)\n    # test by currently selected device\n    total, used, free = gpu_mem_get()\n    if use_gpu: check_gpu_mem_non_zeros(total, used, free)\n    else: check_gpu_mem_zeros(total, used, free)\n\n    # wrong id that can\'t exist\n    check_gpu_mem_zeros(*gpu_mem_get(99))\n\ndef test_gpu_mem_all():\n    # all available gpus\n    this_tests(gpu_mem_get_all)\n    mem_per_id = gpu_mem_get_all()\n    if use_gpu:\n        for mem in mem_per_id: check_gpu_mem_non_zeros(*mem)\n    else:\n        assert len(mem_per_id) == 0\n\ndef test_gpu_with_max_free_mem():\n    this_tests(gpu_with_max_free_mem)\n    # all available gpus\n    id, free = gpu_with_max_free_mem()\n    if use_gpu:\n        assert id != None, ""have gpu id""\n        assert free > 0,   ""have gpu free ram""\n    else:\n        assert id == None, ""have no gpu id""\n        assert free == 0,  ""have no gpu free ram""\n\n@pytest.mark.cuda\ndef test_gpu_mem_measure_consumed_reclaimed():\n    this_tests(gpu_mem_get_used)\n    gpu_mem_reclaim()\n    used_before = gpu_mem_get_used()\n\n    # 1. measure memory consumption\n    x1 = gpu_mem_consume_16mb();\n    used_after = gpu_mem_get_used()\n    diff_real = used_after - used_before\n    diff_expected_min = 15 # could be slightly different\n    assert diff_real >= diff_expected_min, f""check gpu consumption, expected at least {diff_expected_min}, got {diff_real} diff""\n\n    # 2. measure memory reclamation\n    del x1 # this may or may not trigger automatic gc.collect - can\'t rely on that\n    gpu_mem_reclaim() # force gc.collect and cache clearing\n    used_after_reclaimed = gpu_mem_get_used()\n    # allow 2mb tolerance for rounding of 1 mb on each side\n    assert isclose(used_before, used_after_reclaimed, abs_tol=2), f""reclaim all consumed memory, started with {used_before}, now {used_after_reclaimed} used""\n\n@pytest.mark.cuda\ndef test_gpu_mem_trace():\n\n    gpu_prepare_clean_slate()\n\n    mtrace = GPUMemTrace()\n    this_tests(mtrace.__class__)\n\n    ### 1. more allocated, less released, then all released, w/o counter reset\n    # expecting used=~10, peaked=~15\n    x1 = gpu_mem_allocate_mbs(10)\n    x2 = gpu_mem_allocate_mbs(15)\n    del x2\n    yield_to_thread() # hack: ensure peak thread gets a chance to measure the peak\n    check_mtrace(used_exp=10, peaked_exp=15, mtrace=mtrace, abs_tol=2, ctx=""rel some"")\n\n    # check `report`\'s format including the right numbers\n    ctx = ""whoah""\n    with CaptureStdout() as cs: mtrace.report(ctx)\n    used, peaked = parse_mtrace_repr(cs.out, ctx)\n    check_mem(used_exp=10,   peaked_exp=15,\n              used_rcv=used, peaked_rcv=peaked, abs_tol=2, ctx=""trace `report`"")\n\n    # release the remaining allocation, keeping the global counter running w/o reset\n    # expecting used=~0, peaked=~25\n    del x1\n    check_mtrace(used_exp=0, peaked_exp=25, mtrace=mtrace, abs_tol=2, ctx=""rel all"")\n\n    ### 2. more allocated, less released, then all released, w/ counter reset\n    # expecting used=~10, peaked=~15\n    x1 = gpu_mem_allocate_mbs(10)\n    x2 = gpu_mem_allocate_mbs(15)\n    yield_to_thread() # hack: ensure peak thread gets a chance to measure the peak\n    del x2\n    check_mtrace(used_exp=10, peaked_exp=15, mtrace=mtrace, abs_tol=2, ctx=""rel some"")\n\n    # release the remaining allocation, resetting the global counter\n    mtrace.reset()\n    # expecting used=-10, peaked=0\n    del x1\n    check_mtrace(used_exp=-10, peaked_exp=0, mtrace=mtrace, abs_tol=2, ctx=""rel all"")\n\n    # test context + subcontext\n    ctx = \'test2\'\n    mtrace = GPUMemTrace(ctx=ctx)\n    mtrace.start() # not needed, calling for testing\n    check_mtrace(used_exp=0, peaked_exp=0, mtrace=mtrace, abs_tol=2, ctx=ctx)\n    # 1. main context\n    with CaptureStdout() as cs: mtrace.report()\n    used, peaked = parse_mtrace_repr(cs.out, ctx)\n    check_mem(used_exp=0,    peaked_exp=0,\n              used_rcv=used, peaked_rcv=peaked, abs_tol=2, ctx=""auto-report on exit"")\n    # 2. context+sub-context\n    subctx = \'sub-context test\'\n    with CaptureStdout() as cs: mtrace.report(subctx)\n    used, peaked = parse_mtrace_repr(cs.out, f\'{ctx}: {subctx}\')\n    check_mem(used_exp=0,    peaked_exp=0,\n              used_rcv=used, peaked_rcv=peaked, abs_tol=2, ctx=""auto-report on exit"")\n\n    mtrace.stop()\n\n@pytest.mark.cuda\ndef test_gpu_mem_trace_ctx():\n    # context manager\n    # expecting used=20, peaked=0, auto-printout\n    with CaptureStdout() as cs:\n        with GPUMemTrace() as mtrace:\n            x1 = gpu_mem_allocate_mbs(20)\n    _, _ = parse_mtrace_repr(cs.out, ""exit"")\n    this_tests(mtrace.__class__)\n    check_mtrace(used_exp=20, peaked_exp=0, mtrace=mtrace, abs_tol=2, ctx=""ctx manager"")\n    del x1\n\n    # auto-report on exit w/ context and w/o\n    for ctx in [None, ""test""]:\n        with CaptureStdout() as cs:\n            with GPUMemTrace(ctx=ctx):\n                # expecting used=20, peaked=0\n                x1 = gpu_mem_allocate_mbs(20)\n        if ctx is None: ctx = ""exit"" # exit is the hardcoded subctx for ctx manager\n        else:           ctx += "": exit""\n        used, peaked = parse_mtrace_repr(cs.out, ctx)\n        check_mem(used_exp=20,   peaked_exp=0,\n                  used_rcv=used, peaked_rcv=peaked, abs_tol=2, ctx=""auto-report on exit"")\n        del x1\n\n    # auto-report off\n    ctx = ""auto-report off""\n    with CaptureStdout() as cs:\n        with GPUMemTrace(ctx=ctx, on_exit_report=False): 1\n    assert len(cs.out) == 0, f""stdout: {cs.out}""\n\n\n# setup for test_gpu_mem_trace_decorator\n@gpu_mem_trace\ndef experiment1(): pass\n\nclass NewTestExp():\n    @staticmethod\n    @gpu_mem_trace\n    def experiment2(): pass\n\n@pytest.mark.cuda\ndef test_gpu_mem_trace_decorator():\n    this_tests(gpu_mem_trace)\n\n    # func\n    with CaptureStdout() as cs: experiment1()\n    used, peaked = parse_mtrace_repr(cs.out, ""experiment1: exit"")\n    check_mem(used_exp=0,    peaked_exp=0,\n              used_rcv=used, peaked_rcv=peaked, abs_tol=2, ctx="""")\n\n    # class func\n    with CaptureStdout() as cs: NewTestExp.experiment2()\n    used, peaked = parse_mtrace_repr(cs.out, ""NewTestExp.experiment2: exit"")\n    check_mem(used_exp=0,    peaked_exp=0,\n              used_rcv=used, peaked_rcv=peaked, abs_tol=2, ctx="""")\n\n\ndef reduce_mem_usage(df):\n    """""" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    """"""\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\'Memory usage of dataframe is {:.2f} MB\'.format(start_mem))\n\n    #Removed from debugging\n    columns = df.columns\n    #.drop(\'index\')\n\n    for col in columns:\n        col_type = df[col].dtype\n        if str(col_type) != \'category\' and col_type != \'datetime64[ns]\' and col_type != bool:\n            if col_type != object:\n                c_min = df[col].min()\n                c_max = df[col].max()\n                if str(col_type)[:3] == \'int\':\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)\n                else:\n                    #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                        #df[col] = df[col].astype(np.float16)\n                    #Sometimes causes and error and had to remove\n                    if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                        df[col] = df[col].astype(np.float32)\n                    else:\n                        print(\'Error \'+col+\' value would be a float64. Disregarding.\')\n            else:\n                df[col] = df[col].astype(\'category\')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(\'Memory usage after optimization is: {:.2f} MB\'.format(end_mem))\n    print(\'Decreased by {:.1f}%\'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\n'"
tests/test_utils_mod_independency.py,0,"b'# this test checks that the core fastai library doesn\'t depend on \'extras_require\'\n# package requirements from setup.py, which won\'t be installed by default\n\n# XXX: the approach taken by this test to trace \'import\' calls\n# currently has a fault in it, as it\'ll detect `try: import foo` as a\n# requirement, while it is not. Even if there is a way to detect a\n# `try` context, it would be useless since the import call may come\n# deep inside a stack frame and even this test itself is running\n# inside `try` context. So it\'s possible that we might need to ditch\n# it. It might be useful as an advisory rather than a real test.\n\nfrom fastai.gen_doc.doctest import this_tests\nimport os, sys, re\nfrom pathlib import Path\n\n# this is a simplified version of _load_setup_py_data.py from\n# https://github.com/conda/conda-build that gives us access to\n# `setup.py` data. It returns the data dict as it was parsed by\n# `setup()` in `setup.py`. It incorporates data from `setup.cfg` too.\ndef load_setup_py_data_basic(setup_file, work_dir=None):\n    _setuptools_data = {}\n\n    import setuptools\n\n    cd_to_work = False\n    path_backup = sys.path\n\n    os.chdir(work_dir)\n    setup_cfg_data = {}\n    try:\n        from setuptools.config import read_configuration\n    except ImportError:\n        pass  # setuptools <30.3.0 cannot read metadata / options from \'setup.cfg\'\n    else:\n        setup_cfg = os.path.join(os.path.dirname(setup_file), \'setup.cfg\')\n        if os.path.isfile(setup_cfg):\n            # read_configuration returns a dict of dicts. Each dict (keys: \'metadata\',\n            # \'options\'), if present, provides keyword arguments for the setup function.\n            for kwargs in read_configuration(setup_cfg).values():\n                # explicit arguments to setup.cfg take priority over values in setup.py\n                setup_cfg_data.update(kwargs)\n\n    def setup(**kw):\n        _setuptools_data.update(kw)\n        # values in setup.cfg take priority over explicit arguments to setup.py\n        _setuptools_data.update(setup_cfg_data)\n\n    # Patch setuptools, distutils\n    setuptools_setup = setuptools.setup\n\n    setuptools.setup = setup\n    ns = {\n        \'__name__\': \'__main__\',\n        \'__doc__\': None,\n        \'__file__\': setup_file,\n    }\n    if os.path.isfile(setup_file):\n        with open(setup_file) as f:\n            code = compile(f.read(), setup_file, \'exec\', dont_inherit=1)\n            exec(code, ns, ns)\n\n    setuptools.setup = setuptools_setup\n\n    if cd_to_work: os.chdir(cwd)\n    # remove our workdir from sys.path\n    sys.path = path_backup\n    return _setuptools_data\n\n\n# setup.py dir\nwork_dir = Path(__file__).parent.parent\nprint(f""setup.py is at \'{work_dir}\'"")\n\n# we get back a dict of the setup data\ndata = load_setup_py_data_basic(""setup.py"", work_dir)\n\n# just test first that the parsing worked\ndef test_setup_parser():\n    this_tests(\'na\')\n    assert data[\'name\'] == \'fastai\'\n\n    # print(data[\'extras_require\'])\n    assert \'dev\' in data[\'extras_require\']\n\n# fastai must not depend on \'extras_require\' package requirements from setup.py,\n# which won\'t be installed by default\nif \'extras_require\' not in data: data[\'extras_require\']= {\'dev\':[]}\nextras_require = [(re.split(r\'[>=<]+\',x))[0] for x in data[\'extras_require\'][\'dev\']]\nexceptions = [\'pytest\'] # see the top for the reason for exceptions\nunwanted_deps = [x for x in extras_require if x not in exceptions]\n#print(unwanted_deps)\n\nclass CheckDependencyImporter(object):\n    def find_spec(self, fullname, path, target=None):\n        #print(""spec: "", fullname, path, target)\n        # catch if import of any unwanted dependencies gets triggered\n        assert fullname not in unwanted_deps, f""detected unwanted dependency on \'{fullname}\'""\n        return None\n\n\nimport pytest\n@pytest.mark.skip(""Currently broken test"")\ndef test_unwanted_mod_dependencies():\n    this_tests(\'na\')\n    # save the original state\n    mod_saved = sys.modules[\'fastai\'] if \'fastai\' in sys.modules else None\n    meta_path_saved = sys.meta_path.copy\n\n    # unload any candidates we want to test, including fastai, so we can test their import\n    for mod in unwanted_deps + [\'fastai\']:\n        if mod in sys.modules: del sys.modules[mod]\n\n    # test\n    try:\n        sys.meta_path.insert(0, CheckDependencyImporter())\n        import fastai\n    finally:\n        # restore the original state\n        del sys.meta_path[0]\n        if mod_saved is not None: sys.modules[\'fastai\'] = mod_saved\n'"
tests/test_vision_data.py,1,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.vision import *\nfrom fastai.vision.data import verify_image\nfrom utils.text import *\nimport PIL\n\n@pytest.fixture(scope=""module"")\ndef path():\n    path = untar_data(URLs.MNIST_TINY)\n    return path\n\n@pytest.fixture(scope=""module"")\ndef path_var_size():\n    path = untar_data(URLs.MNIST_VAR_SIZE_TINY)\n    return path\n\ndef mnist_tiny_sanity_test(data):\n    assert data.c == 2\n    assert set(map(str, set(data.classes))) == {\'3\', \'7\'}\n\ndef test_path_can_be_str_type(path):\n    this_tests(ImageDataBunch.from_csv)\n    assert ImageDataBunch.from_csv(str(path))\n\ndef test_from_folder(path):\n    this_tests(ImageDataBunch.from_folder)\n    for valid_pct in [None, 0.9]:\n        data = ImageDataBunch.from_folder(path, test=\'test\', valid_pct=valid_pct)\n        mnist_tiny_sanity_test(data)\n        if valid_pct:\n            n_valid = len(data.valid_ds)\n            n_train = len(data.train_ds)\n            n_total = n_valid + n_train\n            assert n_valid == int(n_total * valid_pct)\n\ndef test_from_name_re(path):\n    this_tests(ImageDataBunch.from_name_re)\n    fnames = get_image_files(path/\'train\', recurse=True)\n    pat = r\'/([^/]+)\\/\\d+.png$\'\n    data = ImageDataBunch.from_name_re(path, fnames, pat, ds_tfms=(rand_pad(2, 28), []))\n    mnist_tiny_sanity_test(data)\n\ndef test_from_lists(path):\n    this_tests(ImageDataBunch.from_lists)\n    df = pd.read_csv(path/\'labels.csv\')\n    fnames = [path/f for f in df[\'name\'].values]\n    labels = df[\'label\'].values\n    data = ImageDataBunch.from_lists(path, fnames, labels)\n    mnist_tiny_sanity_test(data)\n    #Check labels weren\'t shuffled for the validation set\n    valid_fnames = data.valid_ds.x.items\n    pat = re.compile(r\'/([^/]+)/\\d+.png$\')\n    expected_labels = [int(pat.search(str(o)).group(1)) for o in valid_fnames]\n    current_labels = [int(str(l)) for l in data.valid_ds.y]\n    assert len(expected_labels) == len(current_labels)\n    assert np.all(np.array(expected_labels) == np.array(current_labels))\n\ndef test_from_csv_and_from_df(path):\n    this_tests(ImageDataBunch.from_csv, ImageDataBunch.from_df)\n    for func in [\'from_csv\', \'from_df\']:\n        files = []\n        if func == \'from_df\': data = ImageDataBunch.from_df(path, df=pd.read_csv(path/\'labels.csv\'), size=28)\n        else: data = ImageDataBunch.from_csv(path, size=28)\n        mnist_tiny_sanity_test(data)\n\nrms = [\'PAD\', \'CROP\', \'SQUISH\']\n\ndef check_resized(data, size, args):\n    x,_ = data.train_ds[0]\n    size_want = (size, size) if isinstance(size, int) else size\n    size_real = x.size\n    assert size_want == size_real, f""[{args}]: size mismatch after resize {size} expected {size_want}, got {size_real}""\n\ndef test_image_resize(path, path_var_size):\n    this_tests(ImageDataBunch.from_name_re)\n    # in this test the 2 datasets are:\n    # (1) 28x28,\n    # (2) var-size but larger than 28x28,\n    # and the resizes are always less than 28x28, so it always tests a real resize\n    for p in [path, path_var_size]: # identical + var sized inputs\n        fnames = get_image_files(p/\'train\', recurse=True)\n        pat = r\'/([^/]+)\\/\\d+.png$\'\n        for size in [14, (14,14), (14,20)]:\n            for rm_name in rms:\n                rm = getattr(ResizeMethod, rm_name)\n                args = f""path={p}, size={size}, resize_method={rm_name}""\n\n                # resize the factory method way\n                with CaptureStderr() as cs:\n                    data = ImageDataBunch.from_name_re(p, fnames, pat, ds_tfms=None, size=size, resize_method=rm)\n                assert len(cs.err)==0, f""[{args}]: got collate_fn warning {cs.err}""\n                check_resized(data, size, args)\n\n                # resize the data block way\n                with CaptureStderr() as cs:\n                    data = (ImageList.from_folder(p)\n                            .split_none()\n                            .label_from_folder()\n                            .transform(size=size, resize_method=rm)\n                            .databunch(bs=2)\n                            )\n                assert len(cs.err)==0, f""[{args}]: got collate_fn warning {cs.err}""\n                check_resized(data, size, args)\n\ndef test_multi_iter_broken(path):\n    this_tests(\'na\')\n    data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []))\n    for i in range(2): x,y = next(iter(data.train_dl))\n\ndef test_multi_iter(path):\n    this_tests(\'na\')\n    data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []))\n    data.normalize()\n    for i in range(2): x,y = data.one_batch()\n\ndef test_clean_tear_down(path):\n    this_tests(\'na\')\n    docstr = ""test DataLoader iter doesn\'t get stuck""\n    data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []))\n    data.normalize()\n    data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []))\n    data.normalize()\n\ndef test_normalize(path):\n    data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []))\n    x,y = data.one_batch(ds_type=DatasetType.Valid, denorm=False)\n    m,s = x.mean(),x.std()\n    this_tests(data.normalize)\n    data.normalize()\n    x,y = data.one_batch(ds_type=DatasetType.Valid, denorm=False)\n    assert abs(x.mean()) < abs(m)\n    assert abs(x.std()-1) < abs(m-1)\n\n    with pytest.raises(Exception): data.normalize()\n    data.valid_dl = None\n    with pytest.raises(Exception): data.normalize()\n\ndef test_denormalize(path):\n    this_tests(denormalize)\n    data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []))\n    original_x, y = data.one_batch(ds_type=DatasetType.Valid, denorm=False)\n    data.normalize()\n    normalized_x, y = data.one_batch(ds_type=DatasetType.Valid, denorm=False)\n    denormalized = denormalize(normalized_x, *data.stats)\n    assert round(original_x.mean().item(), 3) == round(denormalized.mean().item(), 3)\n    assert round(original_x.std().item(), 3) == round(denormalized.std().item(), 3)\n\ndef test_download_images():\n    this_tests(download_images)\n    base_url = \'http://files.fast.ai/data/tst_images/\'\n    fnames = [\'tst0.jpg\', \'tst1.png\', \'tst2.tif\']\n\n    tmp_path = URLs.LOCAL_PATH/\'data\'/\'tmp\'\n    try:\n        os.makedirs(tmp_path)\n        with open(tmp_path/\'imgs.txt\', \'w\') as f:\n            [f.write(f\'{base_url}{fname}\\n\') for fname in fnames]\n        download_images(tmp_path/\'imgs.txt\', tmp_path)\n        for fname in fnames:\n            ext = fname.split(\'.\')[-1]\n            files = list(tmp_path.glob(f\'*.{ext}\'))\n            assert len(files) == 1\n            assert os.path.getsize(files[0]) > 0\n    finally:\n        shutil.rmtree(tmp_path)\n\nresponses = try_import(\'responses\')\n@pytest.mark.skipif(not responses, reason=""requires the `responses` module"")\ndef test_trunc_download():\n    this_tests(untar_data)\n    url = URLs.COCO_TINY\n    fname = datapath4file(url2name(url)).with_suffix("".tgz"")\n    # backup user\'s current state\n    fname_bak = fname.parent/f""{fname.name}-bak""\n    if fname.exists(): os.rename(fname, fname_bak)\n\n    with responses.RequestsMock() as rsps:\n        mock_headers = {\'Content-Type\':\'text/plain\', \'Content-Length\':\'168168549\'}\n        rsps.add(responses.GET, f""{url}.tgz"",\n                 body=""some truncated text"", status=200, headers=mock_headers)\n        try: coco = untar_data(url, force_download=True)\n        except AssertionError as e:\n            expected_error = f""Downloaded file {fname} does not match checksum expected! Remove that file from {Config().data_path()} and try your code again.""\n            assert e.args[0] == expected_error\n        except:\n            assert False, f""untar_data({URLs.COCO_TINY}) had Unexpected error: {sys.exc_info()[0]}""\n        else:\n            assert False, f""untar_data({URLs.COCO_TINY})  should have gracefully failed on a truncated download""\n        finally:\n            # restore user\'s original state\n            if fname.exists():     os.remove(fname)\n            if fname_bak.exists(): os.rename(fname_bak, fname)\n\ndef test_verify_images(path):\n    this_tests(verify_images)\n    tmp_path = path/\'tmp\'\n    os.makedirs(tmp_path, exist_ok=True)\n    verify_images(path/\'train\'/\'3\', dest=tmp_path, max_size=27, max_workers=4)\n    images = list(tmp_path.iterdir())\n    assert len(images) == 346\n    img = PIL.Image.open(images[0])\n    assert img.height == 27 and img.width == 27\n    shutil.rmtree(tmp_path)\n\ndef test_verify_image(path):\n    this_tests(verify_image)\n    tmp_path = path/\'tmp\'\n    os.makedirs(tmp_path, exist_ok=True)\n    verify_image(path/\'train\'/\'3\'/\'867.png\', 0, False, dest=tmp_path, max_size=27)\n    img = PIL.Image.open(tmp_path/\'867.png\')\n    assert img.height == 27 and img.width == 27\n    shutil.rmtree(tmp_path)\n\n#Data block\ndef _print_data(data): print(len(data.train_ds),len(data.valid_ds))\ndef _check_data(data, t, v):\n    assert len(data.train_ds)==t\n    assert len(data.valid_ds)==v\n    _ = data.train_ds[0]\n\ndef test_vision_datasets():\n    this_tests(ImageList.from_folder)\n    il = ImageList.from_folder(untar_data(URLs.MNIST_TINY))\n    sds = il.split_by_idx([0]).label_from_folder().add_test_folder()\n    assert np.array_equal(sds.train.classes, sds.valid.classes), \'train/valid classes same\'\n    assert len(sds.test)==20, ""test_ds is correct size""\n    this_tests(sds.databunch)\n    data = sds.databunch()\n    _check_data(data, len(il)-1, 1)\n\ndef test_multi():\n    this_tests(ImageList.from_csv)\n    path = untar_data(URLs.PLANET_TINY)\n    data = (ImageList.from_csv(path, \'labels.csv\', folder=\'train\', suffix=\'.jpg\')\n            .split_by_rand_pct(seed=42).label_from_df(label_delim=\' \').databunch())\n    x,y = data.valid_ds[0]\n    assert x.shape[0]==3\n    assert data.c==len(y.data)==14\n    assert len(str(y))>2\n    _check_data(data, 160, 40)\n\ndef test_camvid():\n    this_tests(SegmentationItemList)\n    camvid = untar_data(URLs.CAMVID_TINY)\n    path_lbl = camvid/\'labels\'\n    path_img = camvid/\'images\'\n    codes = np.loadtxt(camvid/\'codes.txt\', dtype=str)\n    get_y_fn = lambda x: path_lbl/f\'{x.stem}_P{x.suffix}\'\n    data = (SegmentationItemList.from_folder(path_img)\n            .split_by_rand_pct()\n            .label_from_func(get_y_fn, classes=codes)\n            .transform(get_transforms(), tfm_y=True)\n            .databunch())\n    _check_data(data, 80, 20)\n\ndef get_ip(img,pts): return ImagePoints(FlowField(img.size, pts), scale=True)\n\ndef test_points():\n    this_tests(PointsItemList)\n    coco = untar_data(URLs.COCO_TINY)\n    images, lbl_bbox = get_annotations(coco/\'train.json\')\n    points = [tensor([b[0][0][0], b[0][0][1]]) for b in lbl_bbox]\n    img2pnts = dict(zip(images, points))\n    get_y_func = lambda o:img2pnts[o.name]\n    data = (PointsItemList.from_folder(coco)\n            .split_by_rand_pct()\n            .label_from_func(get_y_func)\n            .databunch())\n    _check_data(data,160,40)\n\ndef test_coco():\n    this_tests(ObjectItemList)\n    coco = untar_data(URLs.COCO_TINY)\n    images, lbl_bbox = get_annotations(coco/\'train.json\')\n    img2bbox = dict(zip(images, lbl_bbox))\n    get_y_func = lambda o:img2bbox[o.name]\n    data = (ObjectItemList.from_folder(coco)\n            .split_by_rand_pct()\n            .label_from_func(get_y_func)\n            .transform(get_transforms(), tfm_y=True)\n            .databunch(bs=16, collate_fn=bb_pad_collate))\n    _check_data(data, 160, 40)\n\ndef test_coco_same_size():\n    this_tests(ObjectItemList)\n    def get_y_func(fname):\n        cat = fname.parent.name\n        bbox = torch.cat([torch.randint(0,5,(2,)), torch.randint(23,28,(2,))])\n        bbox = list(bbox.float().numpy())\n        return [[bbox, bbox], [cat, cat]]\n\n    coco = untar_data(URLs.MNIST_TINY)\n    bs = 16\n    data = (ObjectItemList.from_folder(coco)\n            .split_by_rand_pct()\n            .label_from_func(get_y_func)\n            .transform(get_transforms(), tfm_y=True)\n            .databunch(bs=16, collate_fn=bb_pad_collate))\n    _check_data(data, 1143, 285)\n\ndef test_coco_pickle():\n    this_tests(ObjectItemList)\n    coco = untar_data(URLs.COCO_TINY)\n    images, lbl_bbox = get_annotations(coco/\'train.json\')\n    img2bbox = dict(zip(images, lbl_bbox))\n    get_y_func = lambda o:img2bbox[o.name]\n    tfms = get_transforms()\n    pickle_tfms = pickle.dumps(tfms)\n    unpickle_tfms = pickle.loads(pickle_tfms)\n    data = (ObjectItemList.from_folder(coco)\n            .split_by_rand_pct()\n            .label_from_func(get_y_func)\n            .transform(unpickle_tfms, tfm_y=True)\n            .databunch(bs=16, collate_fn=bb_pad_collate))\n    _check_data(data, 160, 40)\n\ndef test_image_to_image_different_y_size():\n    this_tests(get_transforms)\n    get_y_func = lambda o:o\n    mnist = untar_data(URLs.MNIST_TINY)\n    tfms = get_transforms()\n    data = (ImageImageList.from_folder(mnist)\n            .split_by_rand_pct()\n            .label_from_func(get_y_func)\n            .transform(tfms, size=20)\n            .transform_y(size=80)\n            .databunch(bs=16))\n\n    x,y = data.one_batch()\n    assert x.shape[2]*4 == y.shape[3]\n\ndef test_image_to_image_different_tfms():\n    this_tests(get_transforms)\n    get_y_func = lambda o:o\n    mnist = untar_data(URLs.COCO_TINY)\n    x_tfms = get_transforms()\n    y_tfms = [[t for t in x_tfms[0]], [t for t in x_tfms[1]]]\n    y_tfms[0].append(flip_lr())\n    data = (ImageImageList.from_folder(mnist)\n            .split_by_rand_pct()\n            .label_from_func(get_y_func)\n            .transform(x_tfms)\n            .transform_y(y_tfms)\n            .databunch(bs=16))\n\n    x,y = data.one_batch()\n    x1 = x[0]\n    y1 = y[0]\n    x1r = flip_lr(Image(x1)).data\n    assert (y1 == x1r).all()\n\ndef test_vision_pil2tensor():\n    this_tests(pil2tensor)\n    path  = Path(__file__).parent / ""data/test/images""\n    files = list(Path(path).glob(""**/*.*""))\n    pil_passed, pil_failed = [],[]\n    for f in files:\n        try:\n            im = PIL.Image.open(f)\n            #provoke read of the file so we can isolate PIL issue separately\n            b = np.asarray(im.convert(""RGB""))\n            pil_passed.append(f)\n        except:\n            pil_failed.append(f)\n\n    pil2tensor_passed,pil2tensor_failed = [],[]\n    for f in pil_passed:\n        try :\n            # it doesn\'t matter for the test if we convert ""RGB"" or ""I""\n            im = PIL.Image.open(f).convert(""RGB"")\n            t  = pil2tensor(im,np.float)\n            pil2tensor_passed.append(f)\n        except:\n            pil2tensor_failed.append(f)\n            print(f""converting file: {f}  had Unexpected error:"", sys.exc_info()[0])\n\n    if len(pil2tensor_failed)>0 :\n        print(""\\npil2tensor failed to convert the following images:"")\n        [print(f) for f in pil2tensor_failed]\n\n    assert(len(pil2tensor_passed) == len(pil_passed))\n\ndef test_vision_pil2tensor_16bit():\n    this_tests(pil2tensor)\n    f    = Path(__file__) .parent/ ""data/test/images/gray_16bit.png""\n    im   = PIL.Image.open(f).convert(""I"") # so that the 16bit values are preserved as integers\n    vmax = pil2tensor(im,np.int).data.numpy().max()\n    assert(vmax>255)\n\ndef test_vision_pil2tensor_numpy():\n    this_tests(pil2tensor)\n    ""assert that the two arrays contains the same values""\n    arr  = np.random.rand(16,16,3)\n    diff = np.sort( pil2tensor(arr,np.float).data.numpy().flatten() ) - np.sort(arr.flatten())\n    assert( np.sum(diff==0)==len(arr.flatten()) )\n'"
tests/test_vision_gan.py,7,"b'import pytest, torch\nfrom fastai.gen_doc.doctest import this_tests\nfrom utils.text import CaptureStdout\nfrom fastai.datasets import untar_data, URLs\nfrom fastai.core import noop\nfrom fastai.vision.gan import *\n\n\n@pytest.fixture(scope=""module"")\ndef path():\n    path = untar_data(URLs.MNIST_TINY)\n    return path\n\n@pytest.fixture(scope=""module"")\ndef data(path):\n    data = (GANItemList.from_folder(path, noise_sz=5)\n                       .split_none()\n                       .label_from_func(noop)\n                       .transform(size=32, tfm_y=True) # image size needs to be a power of 2\n                       .databunch(bs=16))\n    return data\n\n@pytest.fixture(scope=""module"")\ndef gan_learner(data):\n    generator = basic_generator(32, 3, 5)\n    critic = basic_critic(32, 3, 16)\n    return GANLearner.wgan(data, generator, critic)\n\n\ndef test_gan_datasets(path):\n    this_tests(GANItemList.from_folder)\n    lls = GANItemList.from_folder(path).split_none().label_from_func(noop)\n\n    assert len(lls.train) == 1428\n    assert isinstance(lls.train.x, GANItemList)\n\ndef test_noisy_item():\n    this_tests(NoisyItem)\n    item = NoisyItem(10)\n\n    assert item.obj == 10\n    assert item.data.size() == torch.Size([10, 1, 1])\n    assert f""{item}"" == """"\n\ndef test_basic_generator():\n    this_tests(basic_generator)\n\n    batch_size = 2; noise_size = 10; img_size = 16; n_channels = 3; n_features = 8;\n    noise = torch.randn((batch_size, noise_size, 1, 1))\n    generator = basic_generator(img_size, n_channels, noise_size, n_features)\n\n    out = generator(noise)\n    assert out.size() == torch.Size([batch_size, n_channels, img_size, img_size])\n\ndef test_basic_critic():\n    this_tests(basic_critic)\n\n    batch_size = 2; img_size = 16; n_channels = 3; n_features = 8;\n    image = torch.randn((batch_size, n_channels, img_size, img_size))\n    critic = basic_critic(img_size, n_channels, n_features)\n\n    out = critic(image)\n    assert out.size() == torch.Size([1])\n\n\ndef test_gan_module(data):\n    this_tests(GANModule)\n    generator = basic_generator(32, 3, 5, 6)\n    critic = basic_critic(32, 3)\n    gan_module = GANModule(generator, critic, gen_mode=True)\n    noise, image = data.one_batch()\n\n    assert isinstance(gan_module(noise), torch.Tensor)\n    gan_module.switch()\n    assert gan_module.gen_mode == False\n    assert isinstance(gan_module(image), torch.Tensor)\n\n@pytest.mark.slow\ndef test_gan_trainer(gan_learner):\n    this_tests(GANTrainer)\n    gan_trainer = gan_learner.gan_trainer\n    with CaptureStdout() as cs: gan_learner.fit(1, 1e-4)\n    assert gan_trainer.imgs\n    assert gan_trainer.gen_mode\n    assert gan_trainer.titles\n\n'"
tests/test_vision_image.py,1,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.vision import *\n\ndef test_rle_encode_with_array():\n    this_tests(rle_encode)\n    fake_img = np.array([[0, 0, 1], [0, 1, 0], [1, 0 ,0]])\n    answer = \'3 1 5 1 7 1\'\n    assert rle_encode(fake_img) == answer\n\ndef test_rle_encode_all_zero_array():\n    this_tests(rle_encode)\n    fake_img = np.array([[0, 0, 0], [0, 0, 0], [0, 0 ,0]])\n    answer = \'\'\n    assert rle_encode(fake_img) == answer\n\ndef test_rle_decode_with_str():\n    this_tests(rle_decode)\n    encoded_str = \'3 1 5 1 7 1\'\n    ans = np.array([[0, 0, 1], [0, 1, 0], [1, 0 ,0]])\n    assert np.alltrue(rle_decode(encoded_str,(3,3)) == ans)\n\ndef test_rle_decode_empty_str():\n    this_tests(rle_decode)\n    encoded_str = \'\'\n    ans = np.array([[0, 0, 0], [0, 0, 0], [0, 0 ,0]])\n    assert np.alltrue(rle_decode(encoded_str,(3,3)) == ans)\n\ndef test_tis2hw_int():\n    this_tests(tis2hw)\n    size = 224\n    assert(tis2hw(size) == [224,224])\n\ndef test_tis2hw_3dims():\n    this_tests(tis2hw)\n    size = (3, 224, 224)\n    assert(tis2hw(size) == [224,224])\n\ndef test_tis2hw_2dims():\n    this_tests(tis2hw)\n    size = (224, 224)\n    assert(tis2hw(size) == [224,224])\n\ndef test_tis2hw_str_raises_an_error():\n    this_tests(tis2hw)\n    with pytest.raises(RuntimeError) as e:\n        tis2hw(""224"")\n\ndef test_image_resize_same_size_shortcut():\n    this_tests(Image.resize)\n    px = torch.Tensor([[[1, 2,], [3, 4]]])\n    image = Image(px)\n    old_size = image.size\n    image = image.resize(px.size()) \n    assert(image is not None and (old_size == image.size))\n'"
tests/test_vision_learner.py,3,"b'import pytest\nimport torch\nimport torch.nn as nn\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.vision.learner import *\nfrom fastai.callbacks.hooks import *\nfrom torchvision.models import resnet18\nfrom torchvision.models.resnet import BasicBlock\nfrom fastai.vision.learner import has_pool_type\n\n@pytest.fixture\ndef image():\n    return torch.randn([4, 3, 32, 32])\n\n\ndef test_create_body(image):\n    this_tests(create_body)\n    def get_hook_fn(actns): \n        return lambda self,input,output: actns.append(output)\n    def run_with_capture(m):\n        actns = []\n        hooks = Hooks(m, get_hook_fn(actns))\n        m(image)\n        hooks.remove()\n        return actns \n    body = create_body(resnet18, pretrained=True, cut=-2)\n    resnet = nn.Sequential(*list(resnet18(pretrained=True).children())[:-2])\n    body_actns = run_with_capture(body)\n    resnet_actns = run_with_capture(resnet)\n    for i in range(len(body_actns)):\n        assert torch.allclose(body_actns[i], resnet_actns[i]) # check activation values at each block\n\n    body = create_body(resnet18, cut=lambda x:x)\n    assert isinstance(body, type(resnet18()))\n\n    with pytest.raises(NameError):\n        create_body(resnet18, cut=1.)\n\ndef test_create_head(image):\n    this_tests(create_head)\n    nc = 4 # number of output classes\n    head = create_head(nf=image.shape[1]*2,nc=nc)\n    assert list(head(image).shape) == [image.shape[0],nc]\n\ndef test_has_pool_type():\n\tthis_tests(has_pool_type)\n\tnc = 5 # dummy number of output classes\n\trn18m = create_cnn_model(resnet18, nc=nc)\n\tassert has_pool_type(rn18m) # rn34 has pool type\n'"
tests/test_vision_models_unet.py,2,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.vision.models import *\nfrom fastai.vision.learner import create_body\nimport torch.nn as nn\nimport torch\n\n@pytest.fixture\ndef model():\n    body = create_body(resnet18, pretrained=False)\n    for param in body.parameters():\n        param.requires_grad = False\n    return DynamicUnet(body, 10)\n\n@pytest.fixture\ndef image():\n    return torch.randn([4,3,32,32]) # create fake image\n\n\ndef add_hooks(m, fn):\n    hooks = []\n    def add_hook(m):\n        if isinstance(m, UnetBlock):\n            hooks.append(m.register_forward_hook(fn))\n    m.apply(add_hook)\n    return hooks\n\ndef remove_hooks(hooks): [h.remove() for h in hooks]\n\ndef run_with_capture(m, image):\n    activation_shapes = []\n    def capture_hook(self, input, output):\n        activation_shapes.append(output.shape)\n    hooks = add_hooks(m, capture_hook)\n    m(image)\n    remove_hooks(hooks)\n    return activation_shapes\n\ndef test_dynamic_unet_shape(model, image):\n    this_tests(DynamicUnet)\n    pred = model(image)\n    assert list(pred.shape[-2:]) == [32,32] # image HxW should remain the same\n    assert pred.shape[1] == 10 # number of output classes \n\ndef test_unet_block_shapes(model, image):\n    this_tests(DynamicUnet)\n    expected_shapes = [[4,512,2,2],[4,384,4,4],[4,256,8,8],[4,96,16,16]]\n    activation_shapes = run_with_capture(model, image)\n    for act, exp in zip(activation_shapes, expected_shapes):\n        assert list(act) == exp\n'"
tests/test_vision_train.py,2,"b'import pytest\nfrom fastai.vision import *\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.callbacks import *\nfrom fastai.utils.mem import *\nfrom utils.mem import *\nfrom math import isclose\nfrom fastai.train import ClassificationInterpretation\n\nuse_gpu = torch.cuda.is_available()\ntorch_preload_mem()\n\npytestmark = pytest.mark.integration\n\n@pytest.fixture\ndef no_bar():\n    fastprogress.NO_BAR = True\n    yield\n    fastprogress.NO_BAR = False\n\n@pytest.fixture(scope=""module"")\ndef mnist_tiny():\n    path = untar_data(URLs.MNIST_TINY)\n    data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []), num_workers=2)\n    data.normalize()\n    return data\n\n@pytest.fixture(scope=""module"")\ndef zero_image():\n    return Image(torch.zeros((3, 128, 128)))\n\n@pytest.fixture(scope=""module"")\ndef learn(mnist_tiny):\n    # path = untar_data(URLs.MNIST_TINY)\n    # data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []), num_workers=2)\n    # data.normalize()\n    learn = Learner(mnist_tiny, simple_cnn((3,16,16,16,2), bn=True), metrics=[accuracy, error_rate])\n    learn.fit_one_cycle(3)\n    return learn\n\ndef test_1cycle_lrs(learn):\n    lrs = learn.recorder.lrs\n    this_tests(learn.recorder.__class__)\n    assert lrs[0]<0.001\n    assert lrs[-1]<0.0001\n    assert np.max(lrs)==3e-3\n\ndef test_1cycle_moms(learn):\n    this_tests(learn.recorder.__class__)\n    moms = learn.recorder.moms\n    assert moms[0]==0.95\n    assert abs(moms[-1]-0.95)<0.01\n    assert np.min(moms)==0.85\n    \ndef test_accuracy(learn):\n    this_tests(accuracy)\n    assert accuracy(*learn.get_preds()) > 0.9\n\ndef test_error_rate(learn):\n    this_tests(error_rate)\n    assert error_rate(*learn.get_preds()) < 0.1\n\ndef test_preds(learn):\n    this_tests(learn.predict)\n    pass_tst = False\n    for i in range(3):\n        img, label = learn.data.valid_ds[i]\n        pred_class,pred_idx,outputs = learn.predict(img)\n        if outputs[int(label)] > outputs[1-int(label)]: return\n    assert False, \'Failed to predict correct class\'\n\ndef test_interp(learn):\n    this_tests(ClassificationInterpretation.from_learner)\n    interp = ClassificationInterpretation.from_learner(learn)\n    losses,idxs = interp.top_losses()\n    assert len(learn.data.valid_ds)==len(losses)==len(idxs)\n\ndef test_interp_shortcut(learn):\n    this_tests(learn.interpret)\n    interp = learn.interpret()\n    losses,idxs = interp.top_losses()\n    assert len(learn.data.valid_ds)==len(losses)==len(idxs)\n\ndef test_lrfind(learn):\n    this_tests(learn.lr_find)\n    learn.lr_find(start_lr=1e-5,end_lr=1e-3, num_it=15)\n\n@pytest.mark.parametrize(\'arch\', [models.resnet18, models.squeezenet1_1])\ndef test_models_meta(mnist_tiny, arch, zero_image):\n    learn = cnn_learner(mnist_tiny, arch, metrics=[accuracy, error_rate])\n    this_tests(learn.predict)\n    pred = learn.predict(zero_image)\n    assert pred is not None\n\ndef test_ClassificationInterpretation(learn):\n    this_tests(ClassificationInterpretation)\n    interp = ClassificationInterpretation.from_learner(learn)\n    assert isinstance(interp.confusion_matrix(), (np.ndarray))\n    assert interp.confusion_matrix().sum() == len(learn.data.valid_ds)\n    conf = interp.most_confused()\n    expect = {\'3\', \'7\'}\n    assert (len(conf) == 0 or\n            len(conf) == 1 and (set(conf[0][:2]) == expect) or\n            len(conf) == 2 and (set(conf[0][:2]) == set(conf[1][:2]) == expect)\n    ), f""conf={conf}""\n'"
tests/test_vision_transform.py,10,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.vision import *\n\ndef bbox2pic(corners, size):\n    pic = torch.zeros(1, size,size)\n    pic[0, corners[0]:corners[2], corners[1]:corners[3]] = 1.\n    return Image(pic)\n\ndef points2pic(points, size):\n    points = points.clamp(min=0,max=size-1)\n    pic = torch.zeros(1, size,size)\n    for p in points: pic[0, max(0,int(p[0])-1):min(size, int(p[0])+1),max(0,int(p[1])-1):min(size, int(p[1])+1)] = 1.\n    return Image(pic)\n\ndef create_data(img, target, size, **kwargs):\n    ll = LabelList(ItemList([img]), ItemList([target]))\n    lls = LabelLists(Path(\'.\'), ll, ll)\n    lls = lls.transform(get_transforms(), size=size, **kwargs)\n    return lls\n\ndef test_points_data_aug():\n    ""Check that ImagePoints get changed with their input Image.""\n    this_tests(ImagePoints)\n    points = torch.randint(0,64, ((5,2)))\n    img = points2pic(points, 64)\n    pnts = ImagePoints(FlowField((64,64), points.float()))\n    lls = create_data(img, pnts, 64, mode=\'nearest\')\n    tfm_x,tfm_y = lls.train[0]\n    new_pnts = scale_flow(FlowField(tfm_y.size, tfm_y.data), to_unit=False).flow.round()\n    fail = False\n    for p in new_pnts.round():\n        if tfm_x.data[0, max(0,int(p[0])-1):min(int(p[0])+2,64), max(0,int(p[1])-1):min(int(p[1])+2,64)].sum() < 0.8:\n            fail = True\n    assert not fail\n\ndef test_bbox_data_aug():\n    this_tests(ImageBBox)\n    ""Check that ImagePoints get changed with their input Image.""\n    pick_box = True\n    while pick_box:\n        points = torch.randint(5,59, ((2,2)))\n        #Will fail if box to close to the border\n        corners = torch.cat([points.min(0)[0], points.max(0)[0]])\n        pick_box = (corners[2:] - corners[:2]).min() < 2\n    img = bbox2pic(corners, 64)\n    bbox = ImageBBox.create(64, 64, [list(corners)])\n    lls = create_data(img, bbox, 64, mode=\'nearest\', padding_mode=\'zeros\')\n    tfm_x,tfm_y = lls.train[0]\n    new_bb = ((tfm_y.data + 1) * 32)\n    mask = (tfm_x.data[0] > 0.5).nonzero()\n    if len(mask) == 0:\n        assert (new_bb[0][2:] - new_bb[0][:2]).min() < 1\n    else:\n        img_bb = torch.cat([mask.min(0)[0], mask.max(0)[0]])\n        assert (new_bb - img_bb.float()).abs().max() < 2\n\ndef test_mask_data_aug():\n    this_tests(Image, ImageSegment)\n    points = torch.randint(0,2, ((1,64,64))).float()\n    img, mask = Image(points), ImageSegment(points)\n    lls = create_data(img, mask, 64, mode=\'nearest\')\n    tfm_x,tfm_y = lls.train[0]\n    new_mask = (tfm_x.data[0] > 0.5)\n    assert (new_mask.float() - tfm_y.data[0].float()).sum() < 1.\n\ndef img_test(cs):\n    points = torch.zeros(5,5)\n    if not is_listy(cs[0]): cs = [cs]\n    for c in cs: points[c[0],c[1]] = 1\n    return Image(points[None])\n\ndef check_image(x, cs):\n    if not is_listy(cs[0]): cs = [cs]\n    target = torch.zeros(*x.size)\n    for c in cs: target[c[0],c[1]] = 1\n    assert (x.data - target).abs().sum() <5e-7\n\ndef check_tfms(img, tfms, targets, **kwargs):\n    for tfm, t in zip(tfms, targets):\n        check_image(img.apply_tfms(tfm, **kwargs), t)\n\ndef test_all_warps():\n    this_tests(perspective_warp, skew, tilt)\n    signs = [1,1,1,-1,-1,1,-1,-1]\n    inputs = [[0,0], [0,0], [4,0], [4,0], [0,4], [0,4], [4,4], [4,4]]\n    targets = [[0,1], [1,0], [4,1], [3,0], [0,3], [1,4], [4,3], [3,4]]\n    for k, (i,t, s) in enumerate(zip(inputs, targets, signs)):\n        magnitudes = torch.zeros(8)\n        magnitudes[k] = s * 0.5\n        check_image(perspective_warp(img_test(i), magnitude=magnitudes), t)\n        tfm = [skew(magnitude=-0.5)]\n        tfm[0].resolved = {\'direction\':k, \'magnitude\':-0.5}\n        check_image(img_test(i).apply_tfms(tfm, do_resolve=False), t)\n    inputs = [[[0,4], [4,4]], [[0,0], [4,0]], [[4,0], [4,4]], [[0,0], [0,4]]]\n    targets = [[[1,4], [3,4]], [[1,0], [3,0]], [[4,1], [4,3]], [[0,1], [0,3]]]\n    for k, (i,t) in enumerate(zip(inputs, targets)):\n        tfm = [tilt(magnitude=-0.5)]\n        tfm[0].resolved = {\'direction\':k, \'magnitude\':-0.5}\n        check_image(img_test(i).apply_tfms(tfm, do_resolve=False), t)\n\ndef test_all_dihedral():\n    this_tests(dihedral)\n    tfm = dihedral()\n    img = img_test([0,1])\n    targets = [[0,1], [4,1], [0,3], [4,3], [1,0], [1,4], [3,0], [3,4]]\n    for k, t in enumerate(targets):\n        tfm.resolved = {\'k\':k}\n        check_image(img.apply_tfms(tfm, do_resolve=False), t)\n\ndef test_deterministic_transforms():\n    this_tests(squish, zoom, rotate, flip_lr, flip_affine, pad, crop)\n    img = img_test([3,3])\n    check_tfms(img, [rotate(degrees=90), rotate(degrees=-90), flip_lr(), flip_affine()],\n               [[1,3], [3,1], [3,1], [3,1]])\n    check_tfms(img, [zoom(scale=2), squish(scale=0.5), squish(scale=2)],\n               [[4,4], [3,4], [4,3]], mode=\'nearest\')\n    crops = [crop(size=4, row_pct=r, col_pct=c) for r,c in zip([0.,0.,0.5,0.99,0.99], [0.,0.99,0.5,0.,0.99])]\n    check_tfms(img, crops, [[3,3], [3,2],[2,2],[2,3],[2,2]])\n    pads = [pad(padding=1, mode=mode) for mode in [\'zeros\', \'border\', \'reflection\']]\n    check_tfms(img_test([3,4]), pads, [[4,5], [[4,5],[4,6]], [[4,5],[6,5]]])\n\ndef test_crop_without_size():\n    this_tests(crop)\n    path = untar_data(URLs.MNIST_TINY)/\'train\'/\'3\'\n    files = get_image_files(path)\n    img = open_image(path/files[0])\n    tfms = get_transforms()\n    img = img.apply_tfms(tfms[0])\n\ndef test_crops_with_tensor_image_sizes():\n    this_tests(crop)\n    img = img_test([3,3])\n    crops = [crop(size=(1,4,4), row_pct=r, col_pct=c) for r,c in zip([0.,0.,0.5,0.99,0.99], [0.,0.99,0.5,0.,0.99])]\n    check_tfms(img, crops, [[3,3], [3,2],[2,2],[2,3],[2,2]])\n'"
tests/test_widgets_image_cleaner.py,0,"b'import pytest\nfrom fastai.gen_doc.doctest import this_tests\nfrom fastai.basics import *\nfrom fastai.vision import *\nfrom fastai.widgets import *\n\nnp.random.seed(42)\n\n@pytest.fixture(scope=""module"")\ndef data():\n    path = untar_data(URLs.MNIST_TINY)\n    data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []), bs=16, num_workers=2)\n    return data\n\n@pytest.mark.xfail(reason = ""Expected Fail, lengths should be the same."")\ndef test_image_cleaner_index_length_mismatch(data):\n    this_tests(ImageCleaner)\n    with pytest.raises(AssertionError) as e:\n        path = untar_data(URLs.MNIST_TINY)\n        n = len(data.valid_ds)\n        assert ImageCleaner(data.valid_ds, np.arange(n+2), path)\n\ndef test_image_cleaner_length_correct(data):\n    this_tests(ImageCleaner)\n    path = untar_data(URLs.MNIST_TINY)\n    n = len(data.valid_ds)\n    ImageCleaner(data.valid_ds, np.arange(n), path)\n\n@pytest.mark.xfail(reason = ""Expected Fail, Dataset should be passed instead."")\ndef test_image_cleaner_wrong_input_type(data):\n    this_tests(ImageCleaner)\n    path = untar_data(URLs.MNIST_TINY)\n    n = len(data.valid_ds)\n    ImageCleaner(data, np.arange(n), path)\n\n@pytest.mark.parametrize(\'duplicates\', [True, False])\ndef test_image_cleaner_with_data_from_csv(duplicates: bool):\n    this_tests(ImageCleaner)\n    path = untar_data(URLs.MNIST_TINY)\n    data_from_csv = ImageList.from_csv(path, csv_name=\'labels.csv\').split_none().label_from_df().transform(get_transforms(), size=224).databunch()\n    learn_cln = cnn_learner(data_from_csv, models.resnet34, metrics=error_rate)\n    ds, idxs = DatasetFormatter().from_similars(learn_cln)\n    ImageCleaner(ds, idxs, path=path, duplicates=duplicates)\n\ndef test_image_downloader_with_path():\n    this_tests(ImageDownloader)\n    ImageDownloader(\'.tmp/data\')\n'"
tests_nb/config.py,1,"b'import os\nimport torch\n\nRUN_SLOW = os.environ.get(""RUN_SLOW"", False)\nRUN_CUDA = torch.cuda.is_available()'"
tools/make_sidebar.py,0,"b'#!/usr/bin/env python3\n\n# create docs/_data/sidebars/home_sidebar.yml\n# from   docs_src/sidebar/sidebar_data.py\n#\n# usage: tools/make_sidebar.py\n\nimport yaml, os, sys\nfrom pathlib import Path\n\n# make sure we are under the root of the project\ncur_dir = Path(""."").resolve().name\nif (cur_dir == ""tools""): os.chdir("".."")\n\nsys.path.append(str(Path(""docs_src"")/""sidebar""))\nfrom sidebar_data import sidebar_d\n\ndef _leaf(k,v):\n    url = \'external_url\' if ""http"" in v else \'url\'\n    if url==\'url\': v=v+\'.html\'\n    return {\'title\':k, url:v, \'output\':\'web,pdf\'}\n\n_k_names = [\'folders\', \'folderitems\', \'subfolders\', \'subfolderitems\']\ndef _side_dict(title, data, level=0):\n    k_name = _k_names[level]\n    level += 1\n    res = [(_side_dict(k, v, level) if isinstance(v,dict) else _leaf(k,v))\n        for k,v in data.items()]\n    return ({k_name:res} if not title\n            else res if title.startswith(\'empty\')\n            else {\'title\': title, \'output\':\'web\', k_name: res})\n\nres = _side_dict(\'Sidebar\', sidebar_d)\nres = {\'entries\': [res]}\nres_s = yaml.dump(res, default_flow_style=False)\nres_s = res_s.replace(\'- subfolders:\', \'  subfolders:\').replace(\' - - \', \'   - \')\nres_s = """"""\n#################################################\n### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n#################################################\n# Instead edit sidebar_d inside docs_src/tools/make_sidebar.ipynb,\n# Then execute that notebook from the beginning to the end\n# Finally commit the modified notebook and this autogenerated file\n#\n""""""+res_s\n\nopen(\'docs/_data/sidebars/home_sidebar.yml\', \'w\').write(res_s)\n'"
courses/dl1/planet.py,0,"b'from fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.dataset import *\nfrom sklearn.metrics import fbeta_score\nimport warnings\n\ndef f2(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return max([fbeta_score(targs, (preds>th), 2, average=\'samples\')\n                    for th in np.arange(start,end,step)])\n\ndef opt_th(preds, targs, start=0.17, end=0.24, step=0.01):\n    ths = np.arange(start,end,step)\n    idx = np.argmax([fbeta_score(targs, (preds>th), 2, average=\'samples\')\n                for th in ths])\n    return ths[idx]\n\ndef get_data(path, tfms,bs,  n, cv_idx):\n    val_idxs = get_cv_idxs(n, cv_idx)\n    return ImageClassifierData.from_csv(path, \'train-jpg\', f\'{path}train_v2.csv\', bs, tfms,\n                                 suffix=\'.jpg\', val_idxs=val_idxs, test_name=\'test-jpg\')\n\ndef get_data_zoom(f_model, path, sz, bs, n, cv_idx):\n    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n    return get_data(path, tfms, bs, n, cv_idx)\n\ndef get_data_pad(f_model, path, sz, bs, n, cv_idx):\n    transforms_pt = [RandomRotateZoom(9, 0.18, 0.1), RandomLighting(0.05, 0.1), RandomDihedral()]\n    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_pt, pad=sz//12)\n    return get_data(path, tfms, bs, n, cv_idx)\n'"
courses/dl1/rossman_exp.py,0,"b'train_ratio=0.9\nuse_dict=True\nuse_scaler=False\ninit_emb=False\nsplit_contins=True\nsamp_size = 100000\n#samp_size = 0\n\nimport math, keras, datetime, pandas as pd, numpy as np, keras.backend as K\nimport matplotlib.pyplot as plt, xgboost, operator, random, pickle, os\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom keras.models import Model\nfrom keras.layers import merge, Input\nfrom keras.layers.core import Dense, Activation, Reshape, Flatten, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.optimizers import Adam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom keras import initializations\nnp.set_printoptions(4)\n\ncfg = K.tf.ConfigProto()\ncfg.gpu_options.allow_growth = True\nK.set_session(K.tf.Session(config=cfg))\n\nos.chdir(\'data/rossman\')\ncat_var_dict = {\'Store\': 50, \'DayOfWeek\': 6, \'Year\': 2, \'Month\': 6,\n    \'Day\': 10, \'StateHoliday\': 3, \'CompetitionMonthsOpen\': 2,\n    \'Promo2Weeks\': 1, \'StoreType\': 2, \'Assortment\': 3, \'PromoInterval\': 3,\n    \'CompetitionOpenSinceYear\': 4, \'Promo2SinceYear\': 4, \'State\': 6,\n    \'Week\': 2, \'Events\': 4, \'Promo_fw\': 1,\n    \'Promo_bw\': 1, \'StateHoliday_fw\': 1,\n    \'StateHoliday_bw\': 1, \'SchoolHoliday_fw\': 1,\n    \'SchoolHoliday_bw\': 1}\n\ncats, contins= [o for n,o in np.load(\'vars.npz\').items()]\ny = np.load(\'deps.npz\').items()[0][1]\n\nif samp_size != 0:\n    np.random.seed(42)\n    idxs = sorted(np.random.choice(len(y), samp_size, replace=False))\n    cats= cats[idxs]\n    contins= contins[idxs]\n    y= y[idxs]\n\nn=len(y)\ntrain_size = int(n*train_ratio)\n\ncontins_trn_orig, contins_val_orig = contins[:train_size], contins[train_size:]\ncats_trn, cats_val = cats[:train_size], cats[train_size:]\ny_trn, y_val = y[:train_size], y[train_size:]\n\ncontin_map_fit = pickle.load(open(\'contin_maps.pickle\', \'rb\'))\ncat_map_fit = pickle.load(open(\'cat_maps.pickle\', \'rb\'))\n\ndef cat_map_info(feat): return feat[0], len(feat[1].classes_)\n\nco_enc = StandardScaler().fit(contins_trn_orig)\ntf_contins_trn = co_enc.transform(contins_trn_orig)\ntf_contins_val = co_enc.transform(contins_val_orig)\n\n\n""""""\ndef rmspe(y_pred, targ = y_valid_orig):\n    return math.sqrt(np.square((targ - y_pred)/targ).mean())\ndef log_max_inv(preds, mx = max_log_y): return np.exp(preds * mx)\ndef normalize_inv(preds): return preds * ystd + ymean\n""""""\n\n\ndef split_cols(arr): return np.hsplit(arr,arr.shape[1])\n\n\ndef emb_init(shape, name=None):\n    return initializations.uniform(shape, scale=0.6/shape[1], name=name)\n\n\ndef get_emb(feat):\n    name, c = cat_map_info(feat)\n    if use_dict:\n        c2 = cat_var_dict[name]\n    else:\n        c2 = (c+2)//3\n        if c2>50: c2=50\n    inp = Input((1,), dtype=\'int64\', name=name+\'_in\')\n    if init_emb:\n        u = Flatten(name=name+\'_flt\')(Embedding(c, c2, input_length=1)(inp))\n    else:\n        u = Flatten(name=name+\'_flt\')(Embedding(c, c2, input_length=1, init=emb_init)(inp))\n    return inp,u\n\n\ndef get_contin(feat):\n    name = feat[0][0]\n    inp = Input((1,), name=name+\'_in\')\n    return inp, Dense(1, name=name+\'_d\')(inp)\n\n\ndef split_data():\n    if split_contins:\n        map_train = split_cols(cats_trn) + split_cols(contins_trn)\n        map_valid = split_cols(cats_val) + split_cols(contins_val)\n    else:\n        map_train = split_cols(cats_trn) + [contins_trn]\n        map_valid = split_cols(cats_val) + [contins_val]\n    return (map_train, map_valid)\n\n\ndef get_contin_one():\n    n_contin = contins_trn.shape[1]\n    contin_inp = Input((n_contin,), name=\'contin\')\n    contin_out = BatchNormalization()(contin_inp)\n    return contin_inp, contin_out\n\n\ndef train(model, map_train, map_valid,  bs=128, ne=10):\n    return model.fit(map_train, y_trn, batch_size=bs, nb_epoch=ne,\n                 verbose=0, validation_data=(map_valid, y_val))\n\n\ndef get_model():\n    if split_contins:\n        conts = [get_contin(feat) for feat in contin_map_fit.features]\n        cont_out = [d for inp,d in conts]\n        cont_inp = [inp for inp,d in conts]\n    else:\n        contin_inp, contin_out = get_contin_one()\n        cont_out = [contin_out]\n        cont_inp = [contin_inp]\n\n    embs = [get_emb(feat) for feat in cat_map_fit.features]\n    x = merge([emb for inp,emb in embs] + cont_out, mode=\'concat\')\n\n    x = Dropout(0.02)(x)\n    x = Dense(1000, activation=\'relu\', init=\'uniform\')(x)\n    x = Dense(500, activation=\'relu\', init=\'uniform\')(x)\n    x = Dense(1, activation=\'sigmoid\')(x)\n\n    model = Model([inp for inp,emb in embs] + cont_inp, x)\n    model.compile(\'adam\', \'mean_absolute_error\')\n    #model.compile(Adam(), \'mse\')\n    return model\n\nfor split_contins in [True, False]:\n    for use_dict in [True, False]:\n        for use_scaler in [True, False]:\n            for init_emb in [True, False]:\n                print ({\'split_contins\':split_contins, \'use_dict\':use_dict,\n                       \'use_scaler\':use_scaler, \'init_emb\':init_emb})\n                if use_scaler:\n                    contins_trn = tf_contins_trn\n                    contins_val = tf_contins_val\n                else:\n                    contins_trn = contins_trn_orig\n                    contins_val = contins_val_orig\n\n                map_train, map_valid = split_data()\n                model = get_model()\n                hist = np.array(train(model, map_train, map_valid, 128, 10)\n                                .history[\'val_loss\'])\n                print(hist)\n                print(hist.min())\n\n'"
docs_src/nbval/__init__.py,0,"b'""""""\nA pytest plugin for testing and validating ipython notebooks\n""""""\n\nfrom ._version import __version__\n'"
docs_src/nbval/_version.py,0,"b""version_info = (0, 9, 1)\n__version__ = '.'.join(map(str, version_info[:3])) + ''.join(version_info[3:])\n"""
docs_src/nbval/cover.py,0,"b'""""""\nCode to enable coverage of any external code called by the\nnotebook.\n""""""\n\nimport os\nimport coverage\n\n\n# Coverage setup/teardown code to run in kernel\n# Inspired by pytest-cov code.\n_python_setup = """"""\\\nimport coverage\n\n__cov = coverage.Coverage(\n    data_file=%r,\n    source=%r,\n    config_file=%r,\n    auto_data=True,\n    data_suffix=%r,\n    )\n__cov.load()\n__cov.start()\n__cov._warn_no_data = False\n__cov._warn_unimported_source = False\n""""""\n_python_teardown = """"""\\\n__cov.stop()\n__cov.save()\n""""""\n\n\ndef setup_coverage(config, kernel, floc, output_loc=None):\n    """"""Start coverage reporting in kernel.\n\n    Currently supported kernel languages are:\n     - Python\n    """"""\n\n    language = kernel.language\n    if language.startswith(\'python\'):\n        # Get the pytest-cov coverage object\n        cov = get_cov(config)\n        if cov:\n            # If present, copy the data file location used by pytest-cov\n            data_file = os.path.abspath(cov.config.data_file)\n        else:\n            # Fall back on output_loc and current dir if not\n            data_file = os.path.abspath(os.path.join(output_loc or os.getcwd(), \'.coverage\'))\n\n        # Get options from pytest-cov\'s command line arguments:\n        source = config.option.cov_source\n        config_file = config.option.cov_config\n        if isinstance(config_file, str) and os.path.isfile(config_file):\n            config_file = os.path.abspath(config_file)\n\n        # Copy the suffix of plugin if available\n        suffix = _make_suffix(cov)\n        if suffix is True:\n            # Cannot merge data with autogen suffix, so turn off warning\n            # for missing data in pytest-cov collector\n            cov._warn_no_data = False\n\n        # Build setup command and execute in kernel:\n        cmd = _python_setup % (data_file, source, config_file, suffix)\n        msg_id = kernel.kc.execute(cmd, stop_on_error=False)\n        kernel.await_idle(msg_id, 60)  # A minute should be plenty to enable coverage\n    else:\n        config.warn(\n            \'C1\',\n            \'Coverage currently not supported for language ""%s"".\' % language,\n            floc)\n        return\n\n\ndef teardown_coverage(config, kernel, output_loc=None):\n    """"""Finish coverage reporting in kernel.\n\n    The coverage should previously have been started with\n    setup_coverage.\n    """"""\n    language = kernel.language\n    if language.startswith(\'python\'):\n        # Teardown code does not require any input, simply execute:\n        msg_id = kernel.kc.execute(_python_teardown)\n        kernel.await_idle(msg_id, 60)  # A minute should be plenty to write out coverage\n\n        # Ensure we merge our data into parent data of pytest-cov, if possible\n        cov = get_cov(config)\n        _merge_nbval_coverage_data(cov)\n\n    else:\n        # Warnings should be given on setup, or there might be no teardown\n        # for a specific language, so do nothing here\n        pass\n\n\ndef get_cov(config):\n    """"""Returns the coverage object of pytest-cov.""""""\n\n    # Check with hasplugin to avoid getplugin exception in older pytest.\n    if config.pluginmanager.hasplugin(\'_cov\'):\n        plugin = config.pluginmanager.getplugin(\'_cov\')\n        if plugin.cov_controller:\n            return plugin.cov_controller.cov\n    return None\n\n\ndef _make_suffix(cov):\n    """"""Create a suffix for nbval data file depending on pytest-cov config.""""""\n    # Check if coverage object has data_suffix:\n    if cov and cov.data_suffix is not None:\n        # If True, the suffix will be autogenerated by coverage.py.\n        # The suffixed data files will be automatically combined later.\n        if cov.data_suffix is True:\n            return True\n        # Has a suffix, but we add our own extension\n        return cov.data_suffix + \'.nbval\'\n    return \'nbval\'\n\n\ndef _merge_nbval_coverage_data(cov):\n    """"""Merge nbval coverage data into pytest-cov data.""""""\n    if not cov:\n        return\n\n    suffix = _make_suffix(cov)\n    if suffix is True:\n        # Note: If suffix is true, we are running in parallel, so several\n        # files will be generated. This will cause some warnings about ""no coverage""\n        # but is otherwise OK. Do nothing.\n        return\n\n    # Get the filename of the nbval coverage:\n    filename = cov.data_files.filename + \'.\' + suffix\n\n    # Read coverage generated by nbval in this run:\n    nbval_data = coverage.CoverageData(debug=cov.debug)\n    try:\n        nbval_data.read_file(os.path.abspath(filename))\n    except coverage.CoverageException:\n        return\n\n    # Set up aliases (following internal coverage.py code here)\n    aliases = None\n    if cov.config.paths:\n        aliases = coverage.files.PathAliases()\n        for paths in cov.config.paths.values():\n            result = paths[0]\n            for pattern in paths[1:]:\n                aliases.add(pattern, result)\n\n    # Merge nbval data into pytest-cov data:\n    cov.data.update(nbval_data, aliases=aliases)\n    # Delete our nbval coverage data\n    coverage.misc.file_be_gone(filename)\n\n\n""""""\nNote about coverage data/datafiles:\n\nWhen pytest is running, we get the pytest-cov coverage object.\nThis object tracks its own coverage data, which is stored in its\ndata file. For several reasons detailed below, we cannot use the\nsame file in the kernel, so we have to ensure our own, and then\nensure that they are all merged correctly at the end. The important\nfactor here is the data_suffix attribute which might be set.\n\nCases:\n1. data_suffix is set to None:\n   No suffix is used by pytest-cov. We need to create a new file,\n   so we add a suffix for kernel, and then merge this file into\n   the pytest-cov data at teardown.\n2. data_suffix is set to a string:\n   We need to create a new file, so we append a string to the\n   suffix passed to the kernel. We merge this file into the\n   pytest-cov data at teardown.\n3. data_suffix is set to True:\n   The suffix will be autogenerated by coverage.py, along the lines\n   of \'hostname.pid.random\'. This is typically used for parallel\n   tests. We pass True as suffix to kernel, ensuring a unique\n   auto-suffix later. We cannot merge this data into the pytest-cov\n   one, as we do not know the suffix, but we can just leave the data\n   for automatic collection. However, this might lead to a warning\n   about no coverage data being collected by the pytest-cov\n   collector.\n\nWhy do we need our own coverage data file?\nCoverage data can get lost if we try to sync via load/save/load cycles\nbetween the two. By having our own file, we can do an in-memory merge\nof the data afterwards using the official API. Either way, the data\nwill always be merged to one coverage file in the end, so these files\nare transient.\n""""""\n'"
docs_src/nbval/kernel.py,0,"b'""""""\npytest ipython plugin modification\n\nAuthors: D. Cortes, O. Laslett, T. Kluyver, H. Fangohr, V.T. Fauske\n\n""""""\n\nimport os\nimport logging\nfrom pprint import pformat\n\ntry:\n    from Queue import Empty\nexcept:\n    from queue import Empty\n\n# Kernel for jupyter notebooks\nfrom jupyter_client.manager import KernelManager\nfrom jupyter_client.kernelspec import KernelSpecManager\nimport ipykernel.kernelspec\n\n\nCURRENT_ENV_KERNEL_NAME = \':nbval-parent-env\'\n\nlogger = logging.getLogger(\'nbval\')\n# Uncomment to debug kernel communication:\n# logger.setLevel(\'DEBUG\')\n# logging.basicConfig(format=""[%(asctime)s - %(name)s - %(levelname)s] %(message)s"")\n\n\nclass NbvalKernelspecManager(KernelSpecManager):\n    """"""Kernel manager that also allows for python kernel in parent environment\n    """"""\n\n    def get_kernel_spec(self, kernel_name):\n        """"""Returns a :class:`KernelSpec` instance for the given kernel_name.\n\n        Raises :exc:`NoSuchKernel` if the given kernel name is not found.\n        """"""\n        if kernel_name == CURRENT_ENV_KERNEL_NAME:\n            return self.kernel_spec_class(\n                resource_dir=ipykernel.kernelspec.RESOURCES,\n                **ipykernel.kernelspec.get_kernel_dict())\n        else:\n            return super(NbvalKernelspecManager, self).get_kernel_spec(kernel_name)\n\n\ndef start_new_kernel(startup_timeout=60, kernel_name=\'python\', **kwargs):\n    """"""Start a new kernel, and return its Manager and Client""""""\n    logger.debug(\'Starting new kernel: ""%s""\' % kernel_name)\n    km = KernelManager(kernel_name=kernel_name,\n                       kernel_spec_manager=NbvalKernelspecManager())\n    km.start_kernel(**kwargs)\n    kc = km.client()\n    kc.start_channels()\n    try:\n        kc.wait_for_ready(timeout=startup_timeout)\n    except RuntimeError:\n        logger.exception(\'Failure starting kernel ""%s""\', kernel_name)\n        kc.stop_channels()\n        km.shutdown_kernel()\n        raise\n\n    return km, kc\n\n\nclass RunningKernel(object):\n    """"""\n    Running a Kernel a Jupyter, info can be found at:\n    http://jupyter-client.readthedocs.org/en/latest/messaging.html\n\n    The purpose of this class is to encapsulate interaction with the\n    jupyter kernel. Thus any changes on the jupyter side to how\n    kernels are started/managed should not require any changes outside\n    this class.\n\n    """"""\n    def __init__(self, kernel_name, cwd=None):\n        """"""\n        Initialise a new kernel\n        specify that matplotlib is inline and connect the stderr.\n        Stores the active kernel process and its manager.\n        """"""\n\n        self.km, self.kc = start_new_kernel(\n            kernel_name=kernel_name,\n            stderr=open(os.devnull, \'w\'),\n            cwd=cwd,\n        )\n\n        self._ensure_iopub_up()\n\n    def _ensure_iopub_up(self):\n        total_timeout = 30\n        individual_timeout = 1\n        shell_timeout = 10\n        for _ in range(total_timeout // individual_timeout):\n            msg_id = self.kc.kernel_info()\n\n            try:\n                self.await_reply(msg_id, timeout=shell_timeout)\n            except Empty:\n                raise RuntimeError(\'Kernel info reqest timed out after %d seconds!\' % shell_timeout)\n\n            try:\n                self.await_idle(msg_id, individual_timeout)\n            except Empty:\n                continue\n            else:\n                # got IOPub\n                break\n        else:\n            raise RuntimeError(""Wasn\'t able to establish IOPub after %d seconds."" % total_timeout)\n\n    def get_message(self, stream, timeout=None):\n        """"""\n        Function is used to get a message from the iopub channel.\n        Timeout is None by default\n        When timeout is reached\n        """"""\n        try:\n            if stream == \'iopub\':\n                msg = self.kc.get_iopub_msg(timeout=timeout)\n            elif stream == \'shell\':\n                msg = self.kc.get_shell_msg(timeout=timeout)\n            else:\n                raise ValueError(\'Invalid stream specified: ""%s""\' % stream)\n        except Empty:\n            logger.debug(\'Kernel: Timeout waiting for message on %s\', stream)\n            raise\n        logger.debug(""Kernel message (%s):\\n%s"", stream, pformat(msg))\n        return msg\n\n    def execute_cell_input(self, cell_input, allow_stdin=None):\n        """"""\n        Executes a string of python code in cell input.\n        We do not allow the kernel to make requests to the stdin\n             this is the norm for notebooks\n\n        Function returns a unique message id of the reply from\n        the kernel.\n        """"""\n        if cell_input:\n            logger.debug(\'Executing cell: ""%s""...\', cell_input.splitlines()[0][:40])\n        else:\n            logger.debug(\'Executing empty cell\')\n        return self.kc.execute(cell_input, allow_stdin=allow_stdin, stop_on_error=False)\n\n    def await_reply(self, msg_id, timeout=None):\n        """"""\n        Continuously poll the kernel \'shell\' stream for messages until:\n         - It receives an \'execute_reply\' status for the given message id\n         - The timeout is reached awaiting a message, in which case\n           a `Queue.Empty` exception will be raised.\n        """"""\n        while True:\n            msg = self.get_message(stream=\'shell\', timeout=timeout)\n\n            # Is this the message we are waiting for?\n            if msg[\'parent_header\'].get(\'msg_id\') == msg_id:\n                if msg[\'content\'][\'status\'] == \'aborted\':\n                    # This should not occur!\n                    raise RuntimeError(\'Kernel aborted execution request\')\n                return\n\n    def await_idle(self, parent_id, timeout):\n        """"""Poll the iopub stream until an idle message is received for the given parent ID""""""\n        while True:\n            # Get a message from the kernel iopub channel\n            msg = self.get_message(timeout=timeout, stream=\'iopub\') # raises Empty on timeout!\n\n            if msg[\'parent_header\'].get(\'msg_id\') != parent_id:\n                continue\n            if msg[\'msg_type\'] == \'status\':\n                if msg[\'content\'][\'execution_state\'] == \'idle\':\n                    break\n\n    def is_alive(self):\n        if hasattr(self, \'km\'):\n            return self.km.is_alive()\n        return False\n\n    # These options are in case we wanted to restart the nb every time\n    # it is executed a certain task\n    def restart(self):\n        """"""\n        Instructs the kernel manager to restart the kernel process now.\n        """"""\n        logger.debug(\'Restarting kernel\')\n        self.km.restart_kernel(now=True)\n\n    def interrupt(self):\n        """"""\n        Instructs the kernel to stop whatever it is doing, and await\n        further commands.\n        """"""\n        logger.debug(\'Interrupting kernel\')\n        self.km.interrupt_kernel()\n\n    def stop(self):\n        """"""\n        Instructs the kernel process to stop channels\n        and the kernel manager to then shutdown the process.\n        """"""\n        logger.debug(\'Stopping kernel\')\n        self.kc.stop_channels()\n        self.km.shutdown_kernel(now=True)\n        del self.km\n\n    @property\n    def language(self):\n        if self.km.kernel_spec is None:\n            return None\n        return self.km.kernel_spec.language\n'"
docs_src/nbval/nbdime_reporter.py,0,"b'""""""\npytest ipython plugin modification - Nbdime reporter\n\nAuthors: V.T. Fauske\n\n""""""\n\n# import the pytest API\nimport pytest\nfrom _pytest.main import EXIT_OK, EXIT_TESTSFAILED, EXIT_INTERRUPTED, \\\n    EXIT_USAGEERROR, EXIT_NOTESTSCOLLECTED\n\nimport re\nimport copy\nimport tempfile\nimport os\nimport shutil\nimport io\n\nimport nbformat\nimport nbdime\nfrom nbdime.webapp.nbdiffweb import run_server, browse\n\nfrom .plugin import IPyNbCell, bcolors\n\nnbdime.log.set_nbdime_log_level(\'ERROR\')\n\n_re_nbval_nodeid = re.compile(\'.*\\.ipynb::Cell \\d+\')\n\n\nclass NbdimeReporter:\n    def __init__(self, config, file=None):\n        self.config = config\n        self.verbosity = self.config.option.verbose\n        self._numcollected = 0\n\n        self.nbval_items = []\n\n        self.nb_ref = nbformat.v4.new_notebook()\n        self.nb_test = nbformat.v4.new_notebook()\n\n        self.stats = {}\n\n    # ---- These functions store captured test items and reports ----\n\n    def pytest_runtest_logreport(self, report):\n        """"""Store all test reports for evaluation on finish""""""\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep)\n        cat, letter, word = res\n        self.stats.setdefault(cat, []).append(rep)\n\n    def pytest_collectreport(self, report):\n        """"""Store all collected nbval tests for evaluation on finish\n        """"""\n        items = [x for x in report.result if isinstance(x, IPyNbCell)]\n        self.nbval_items.extend(items)\n        self._numcollected += len(items)\n\n\n    # ---- Code below writes up report ----\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, exitstatus):\n        """"""Called when test session has finished.\n        """"""\n        outcome = yield\n        outcome.get_result()\n        summary_exit_codes = (\n            EXIT_OK, EXIT_TESTSFAILED, EXIT_INTERRUPTED, EXIT_USAGEERROR,\n            EXIT_NOTESTSCOLLECTED)\n        if exitstatus in summary_exit_codes:\n            # We had some failures that might need reporting\n            self.make_report(outcome)\n\n    def make_report(self, outcome):\n        """"""Make report in form of two notebooks.\n\n        Use nbdime diff-web to present the difference between reference\n        cells and test cells.\n        """"""\n        failures = self.getreports(\'failed\')\n        if not failures:\n            return\n        for rep in failures:\n            # Check if this is a notebook node\n            msg = self._getfailureheadline(rep)\n            lines = rep.longrepr.splitlines()\n            if len(lines) > 1:\n                self.section(msg, lines[1])\n            self._outrep_summary(rep)\n        tmpdir = tempfile.mkdtemp()\n        try:\n            ref_file = os.path.join(tmpdir, \'reference.ipynb\')\n            test_file = os.path.join(tmpdir, \'test_result.ipynb\')\n            with io.open(ref_file, ""w"", encoding=""utf8"") as f:\n                nbformat.write(self.nb_ref, f)\n            with io.open(test_file, ""w"", encoding=""utf8"") as f:\n                nbformat.write(self.nb_test, f)\n            run_server(\n                port=0,     # Run on random port\n                cwd=tmpdir,\n                closable=True,\n                on_port=lambda port: browse(\n                    port, ref_file, test_file, None))\n        finally:\n            shutil.rmtree(tmpdir)\n\n    #\n    # summaries for sessionfinish\n    #\n    def getreports(self, name):\n        l = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \'_pdbshown\'):\n                l.append(x)\n        return l\n\n    def section(self, title, details):\n        # Create markdown cell with title\n        source = ""## "" + title\n        if details:\n            details = details.replace(bcolors.OKBLUE, \'\')\n            source += ""\\n\\n**"" + details + \'**\'\n        header = nbformat.v4.new_markdown_cell(source)\n        # Add markdown in both ref and test\n        self.nb_ref.cells.append(header)\n        self.nb_test.cells.append(header)\n\n    def _outrep_summary(self, rep):\n        # Find corresponding item\n        for item in self.nbval_items:\n            if item.nodeid == rep.nodeid:\n                # item found, output\n                # Sanitize reference cell\n                ref_cell = item.cell\n                ref_cell.outputs = item.sanitize_outputs(ref_cell.outputs)\n                self.nb_ref.cells.append(item.cell)\n                test_cell = copy.copy(item.cell)\n                if item.test_outputs:\n                    test_cell.outputs = item.sanitize_outputs(item.test_outputs)\n                self.nb_test.cells.append(test_cell)\n\n    def _getfailureheadline(self, rep):\n        if hasattr(rep, \'location\'):\n            domain = rep.location[2]\n            return domain\n        else:\n            return ""test session""  # XXX?\n'"
docs_src/nbval/plugin.py,0,"b'""""""\npytest ipython plugin modification\n\nAuthors: D. Cortes, O. Laslett, T. Kluyver, H. Fangohr, V.T. Fauske\n\n""""""\n\nfrom __future__ import print_function\n\n# import the pytest API\nimport pytest\nimport sys\nimport os\nimport re\nimport hashlib\nimport warnings\nfrom collections import OrderedDict, defaultdict\n\n# for python 3 compatibility\nimport six\n\ntry:\n    from Queue import Empty\nexcept:\n    from queue import Empty\n\n# for reading notebook files\nimport nbformat\nfrom nbformat import NotebookNode\n\n# Kernel for running notebooks\nfrom .kernel import RunningKernel, CURRENT_ENV_KERNEL_NAME\nfrom .cover import setup_coverage, teardown_coverage\n\n\n# define colours for pretty outputs\nclass bcolors:\n    HEADER = \'\\033[95m\'\n    OKBLUE = \'\\033[94m\'\n    OKGREEN = \'\\033[92m\'\n    WARNING = \'\\033[93m\'\n    FAIL = \'\\033[91m\'\n    ENDC = \'\\033[0m\'\n\nclass nocolors:\n    HEADER = \'\'\n    OKBLUE = \'\'\n    OKGREEN = \'\'\n    WARNING = \'\'\n    FAIL = \'\'\n    ENDC = \'\'\n\n\n\nclass NbCellError(Exception):\n    """""" custom exception for error reporting. """"""\n    def __init__(self, cell_num, msg, source, traceback=None, *args, **kwargs):\n        self.cell_num = cell_num\n        super(NbCellError, self).__init__(msg, *args, **kwargs)\n        self.source = source\n        self.inner_traceback = traceback\n\n\ndef pytest_addoption(parser):\n    """"""\n    Adds the --nbval option flag for py.test.\n\n    Adds an optional flag to pass a config file with regex\n    expressions to sanitise the outputs\n    Only will work if the --nbval flag is present\n\n    This is called by the pytest API\n    """"""\n    group = parser.getgroup(""general"")\n    group.addoption(\'--nbval\', action=\'store_true\',\n                    help=""Validate Jupyter notebooks"")\n\n    group.addoption(\'--nbval-lax\', action=\'store_true\',\n                    help=""Run Jupyter notebooks, only validating output on ""\n                         ""cells marked with # NBVAL_CHECK_OUTPUT"")\n\n    group.addoption(\'--sanitize-with\',\n                    help=\'File with regex expressions to sanitize \'\n                         \'the outputs. This option only works when \'\n                         \'the --nbval flag is passed to py.test\')\n\n    group.addoption(\'--current-env\', action=\'store_true\',\n                    help=\'Force test execution to use a python kernel in \'\n                         \'the same enviornment that py.test was \'\n                         \'launched from.\')\n\n    group.addoption(\'--nbval-cell-timeout\', action=\'store\', default=2000,\n                    type=float,\n                    help=\'Timeout for cell execution, in seconds.\')\n\n    term_group = parser.getgroup(""terminal reporting"")\n    term_group._addoption(\n        \'--nbdime\', action=\'store_true\',\n        help=""view failed nbval cells with nbdime."")\n\n\ndef pytest_configure(config):\n    if config.option.nbdime:\n        from .nbdime_reporter import NbdimeReporter\n        reporter = NbdimeReporter(config, sys.stdout)\n        config.pluginmanager.register(reporter, \'nbdimereporter\')\n\n\ndef pytest_collect_file(path, parent):\n    """"""\n    Collect IPython notebooks using the specified pytest hook\n    """"""\n    opt = parent.config.option\n    if (opt.nbval or opt.nbval_lax) and path.fnmatch(""*.ipynb""):\n        return IPyNbFile(path, parent)\n\n\n\ncomment_markers = {\n    \'PYTEST_VALIDATE_IGNORE_OUTPUT\': (\'check\', False),  # For backwards compatibility\n    \'NBVAL_IGNORE_OUTPUT\': (\'check\', False),\n    \'NBVAL_CHECK_OUTPUT\': \'check\',\n    \'NBVAL_RAISES_EXCEPTION\': \'check_exception\',\n    \'NBVAL_SKIP\': \'skip\',\n}\n\nmetadata_tags = {\n    k.lower().replace(\'_\', \'-\'): v\n    for (k, v) in comment_markers.items()\n}\n\nmetadata_tags[\'raises-exception\'] = \'check_exception\'\n\n\ndef find_comment_markers(cellsource):\n    """"""Look through the cell source for comments which affect nbval\'s behaviour\n\n    Yield an iterable of ``(MARKER_TYPE, True)``.\n    """"""\n    found = {}\n    for line in cellsource.splitlines():\n        line = line.strip()\n        if line.startswith(\'#\'):\n            # print(""Found comment in \'{}\'"".format(line))\n            comment = line.lstrip(\'#\').strip()\n            if comment in comment_markers:\n                # print(""Found marker {}"".format(comment))\n                marker = comment_markers[comment]\n                if not isinstance(marker, tuple):\n                    # If not an explicit tuple (\'option\', True/False),\n                    # imply (\'option\', True)\n                    marker = (marker, True)\n                marker_type = marker[0]\n                if marker_type in found:\n                    warnings.warn(\n                        ""Conflicting comment markers found, using the latest: ""\n                        "" %s VS %s"" %\n                        (found[marker_type], comment))\n                found[marker_type] = comment\n                yield marker\n\n\ndef find_metadata_tags(cell_metadata):\n    tags = cell_metadata.get(\'tags\', None)\n    if tags is None:\n        return\n    elif not isinstance(tags, list):\n        warnings.warn(""Cell tags is not a list, ignoring."")\n        return\n    found = {}\n    for tag in tags:\n        if tag in metadata_tags:\n            marker = metadata_tags[tag]\n            if not isinstance(marker, tuple):\n                # If not an explicit tuple (\'option\', True/False),\n                # imply (\'option\', True)\n                marker = (marker, True)\n            marker_type = marker[0]\n            if marker_type in found:\n                warnings.warn(\n                    ""Conflicting metadata tags found, using the latest: ""\n                    "" %s VS %s"" %\n                    (found[marker_type], tag))\n            found[marker_type] = tag\n            yield marker\n\n\nclass Dummy:\n    """"""Needed to use xfail for our tests""""""\n    def __init__(self):\n        self.__globals__ = {}\n\n\nclass IPyNbFile(pytest.File):\n    """"""\n    This class represents a pytest collector object.\n    A collector is associated with an ipynb file and collects the cells\n    in the notebook for testing.\n    yields pytest items that are required by pytest.\n    """"""\n    def __init__(self, *args, **kwargs):\n        super(IPyNbFile, self).__init__(*args, **kwargs)\n        config = self.parent.config\n        self.sanitize_patterns = OrderedDict()  # Filled in setup_sanitize_patterns()\n        self.compare_outputs = not config.option.nbval_lax\n        self.timed_out = False\n        self.skip_compare = (\n            \'metadata\',\n            \'traceback\',\n            #\'text/latex\',\n            \'prompt_number\',\n            \'output_type\',\n            \'name\',\n            \'execution_count\',\n        )\n        if not config.option.nbdime:\n            self.skip_compare = self.skip_compare + (\'image/png\', \'image/jpeg\')\n\n    kernel = None\n\n    def setup(self):\n        """"""\n        Called by pytest to setup the collector cells in .\n        Here we start a kernel and setup the sanitize patterns.\n        """"""\n\n        if self.parent.config.option.current_env:\n            kernel_name = CURRENT_ENV_KERNEL_NAME\n        else:\n            kernel_name = self.nb.metadata.get(\n                \'kernelspec\', {}).get(\'name\', \'python\')\n        self.kernel = RunningKernel(kernel_name, str(self.fspath.dirname))\n        self.setup_sanitize_files()\n        if getattr(self.parent.config.option, \'cov_source\', None):\n            setup_coverage(self.parent.config, self.kernel, getattr(self, ""fspath"", None))\n\n\n    def setup_sanitize_files(self):\n        """"""\n        For each of the sanitize files that were specified as command line options\n        load the contents of the file into the sanitise patterns dictionary.\n        """"""\n        for fname in self.get_sanitize_files():\n            with open(fname, \'r\') as f:\n                self.sanitize_patterns.update(get_sanitize_patterns(f.read()))\n\n\n    def get_sanitize_files(self):\n        """"""\n        Return list of all sanitize files provided by the user on the command line.\n\n        N.B.: We only support one sanitize file at the moment, but\n              this is likely to change in the future\n\n        """"""\n        if self.parent.config.option.sanitize_with is not None:\n            return [self.parent.config.option.sanitize_with]\n        else:\n            return []\n\n    def get_kernel_message(self, timeout=None, stream=\'iopub\'):\n        """"""\n        Gets a message from the iopub channel of the notebook kernel.\n        """"""\n        return self.kernel.get_message(stream, timeout=timeout)\n\n    # Read through the specified notebooks and load the data\n    # (which is in json format)\n    def collect(self):\n        """"""\n        The collect function is required by pytest and is used to yield pytest\n        Item objects. We specify an Item for each code cell in the notebook.\n        """"""\n\n        self.nb = nbformat.read(str(self.fspath), as_version=4)\n\n        # Start the cell count\n        cell_num = 0\n\n        # Iterate over the cells in the notebook\n        for cell in self.nb.cells:\n            # Skip the cells that have text, headings or related stuff\n            # Only test code cells\n            if cell.cell_type == \'code\':\n                # The cell may contain a comment indicating that its output\n                # should be checked or ignored. If it doesn\'t, use the default\n                # behaviour. The --nbval option checks unmarked cells.\n                with warnings.catch_warnings(record=True) as ws:\n                    options = defaultdict(bool, find_metadata_tags(cell.metadata))\n                    comment_opts = dict(find_comment_markers(cell.source))\n                    if set(comment_opts.keys()) & set(options.keys()):\n                        warnings.warn(\n                            ""Overlapping options from comments and metadata, ""\n                            ""using options from comments: %s"" %\n                            str(set(comment_opts.keys()) & set(options.keys())))\n                    for w in ws:\n                        self.parent.config.warn(\n                            ""C1"",\n                            str(w.message),\n                            \'%s:Cell %d\' % (\n                                getattr(self, ""fspath"", None),\n                                cell_num))\n                options.update(comment_opts)\n                options.setdefault(\'check\', self.compare_outputs)\n                yield IPyNbCell(\'Cell \' + str(cell_num), self, cell_num,\n                                cell, options)\n\n                # Update \'code\' cell count\n                cell_num += 1\n\n    def teardown(self):\n        if self.kernel is not None and self.kernel.is_alive():\n            if getattr(self.parent.config.option, \'cov_source\', None):\n                teardown_coverage(self.parent.config, self.kernel)\n            self.kernel.stop()\n\n\nclass IPyNbCell(pytest.Item):\n    def __init__(self, name, parent, cell_num, cell, options):\n        super(IPyNbCell, self).__init__(name, parent)\n\n        # Store reference to parent IPynbFile so that we have access\n        # to the running kernel.\n        self.parent = parent\n        self.cell_num = cell_num\n        self.cell = cell\n        self.test_outputs = None\n        self.options = options\n        self.config = parent.parent.config\n        self.output_timeout = 5\n        # Disable colors if we have been explicitly asked to\n        self.colors = bcolors if self.config.option.color != \'no\' else nocolors\n        # _pytest.skipping assumes all pytest.Item have this attribute:\n        self.obj = Dummy()\n\n    """""" *****************************************************\n        *****************  TESTING FUNCTIONS  ***************\n        ***************************************************** """"""\n\n    def repr_failure(self, excinfo):\n        """""" called when self.runtest() raises an exception. """"""\n        exc = excinfo.value\n        cc = self.colors\n        if isinstance(exc, NbCellError):\n            msg_items = [\n                cc.FAIL + ""Notebook cell execution failed"" + cc.ENDC]\n            formatstring = (\n                cc.OKBLUE + ""Cell %d: %s\\n\\n"" +\n                ""Input:\\n"" + cc.ENDC + ""%s\\n"")\n            msg_items.append(formatstring % (\n                exc.cell_num,\n                str(exc),\n                exc.source\n            ))\n            if exc.inner_traceback:\n                msg_items.append((\n                    cc.OKBLUE + ""Traceback:"" + cc.ENDC + ""\\n%s\\n"") %\n                    exc.inner_traceback)\n            return ""\\n"".join(msg_items)\n        else:\n            return ""pytest plugin exception: %s"" % str(exc)\n\n    def reportinfo(self):\n        description = ""%s::Cell %d"" % (self.fspath.relto(self.config.rootdir), self.cell_num)\n        return self.fspath, 0, description\n\n    def compare_outputs(self, test, ref, skip_compare=None):\n        # Use stored skips unless passed a specific value\n        skip_compare = skip_compare or self.parent.skip_compare\n\n        test = transform_streams_for_comparison(test)\n        ref = transform_streams_for_comparison(ref)\n\n        # Color codes to use for reporting\n        cc = self.colors\n\n        # We reformat outputs into a dictionaries where\n        # key:\n        #   - all keys on output except \'data\' and those in skip_compare\n        #   - all keys on \'data\' except those in skip_compare, i.e. data is flattened\n        # value:\n        #   - list of all corresponding values for that key, i.e. for all outputs\n        #\n        # This format allows to disregard the relative order of dissimilar\n        # output keys, while still caring about the order of those that share\n        # a key.\n        testing_outs = defaultdict(list)\n        reference_outs = defaultdict(list)\n\n        for reference in ref:\n            for key in reference.keys():\n                # We discard the keys from the skip_compare list:\n                if key not in skip_compare:\n                    # Flatten out MIME types from data of display_data and execute_result\n                    if key == \'data\':\n                        for data_key in reference[key].keys():\n                            # Filter the keys in the SUB-dictionary again:\n                            if data_key not in skip_compare:\n                                reference_outs[data_key].append(self.sanitize(reference[key][data_key]))\n\n                    # Otherwise, just create a normal dictionary entry from\n                    # one of the keys of the dictionary\n                    else:\n                        # Create the dictionary entries on the fly, from the\n                        # existing ones to be compared\n                        reference_outs[key].append(self.sanitize(reference[key]))\n\n        # the same for the testing outputs (the cells that are being executed)\n        for testing in test:\n            for key in testing.keys():\n                if key not in skip_compare:\n                    if key == \'data\':\n                        for data_key in testing[key].keys():\n                            if data_key not in skip_compare:\n                                testing_outs[data_key].append(self.sanitize(testing[key][data_key]))\n                    else:\n                        testing_outs[key].append(self.sanitize(testing[key]))\n\n        # The traceback from the comparison will be stored here.\n        self.comparison_traceback = []\n\n        ref_keys = set(reference_outs.keys())\n        test_keys = set(testing_outs.keys())\n\n        if ref_keys - test_keys:\n            self.comparison_traceback.append(\n                cc.FAIL\n                + ""Missing output fields from running code: %s""\n                % (ref_keys - test_keys)\n                + cc.ENDC\n            )\n            return False\n        elif test_keys - ref_keys:\n            self.comparison_traceback.append(\n                cc.FAIL\n                + ""Unexpected output fields from running code: %s""\n                % (test_keys - ref_keys)\n                + cc.ENDC\n            )\n            return False\n\n        # If we\'ve got to here, the two dicts must have the same set of keys\n\n        for key in reference_outs.keys():\n            # Get output values for dictionary entries.\n            # We use str() to be sure that the unicode key strings from the\n            # reference are also read from the testing dictionary:\n            test_values = testing_outs[str(key)]\n            ref_values = reference_outs[key]\n            if len(test_values) != len(ref_values):\n                # The number of outputs for a specific MIME type differs\n                self.comparison_traceback.append(\n                    cc.OKBLUE\n                    + \'dissimilar number of outputs for key ""%s""\' % key\n                    + cc.FAIL\n                    + ""<<<<<<<<<<<< Reference outputs from ipynb file:""\n                    + cc.ENDC\n                )\n                for val in ref_values:\n                    self.comparison_traceback.append(_trim_base64(val))\n                self.comparison_traceback.append(\n                    cc.FAIL\n                    + \'============ disagrees with newly computed (test) output:\'\n                    + cc.ENDC)\n                for val in test_values:\n                    self.comparison_traceback.append(_trim_base64(val))\n                self.comparison_traceback.append(\n                    cc.FAIL\n                    + \'>>>>>>>>>>>>\'\n                    + cc.ENDC)\n                return False\n\n            for ref_out, test_out in zip(ref_values, test_values):\n                # Compare the individual values\n                if ref_out != test_out:\n                    self.format_output_compare(key, ref_out, test_out)\n                    return False\n        return True\n\n    def format_output_compare(self, key, left, right):\n        """"""Format an output for printing""""""\n        if isinstance(left, six.string_types):\n            left = _trim_base64(left)\n        if isinstance(right, six.string_types):\n            right = _trim_base64(right)\n\n        cc = self.colors\n\n        self.comparison_traceback.append(\n            cc.OKBLUE\n            + "" mismatch \'%s\'"" % key\n            + cc.FAIL)\n\n        # Use comparison repr from pytest:\n        hook_result = self.ihook.pytest_assertrepr_compare(\n            config=self.config, op=\'==\', left=left, right=right)\n        for new_expl in hook_result:\n            if new_expl:\n                new_expl = [\'  %s\' % line.replace(""\\n"", ""\\\\n"") for line in new_expl]\n                self.comparison_traceback.append(""\\n assert reference_output == test_output failed:\\n"")\n                self.comparison_traceback.extend(new_expl)\n                break\n        else:\n            # Fallback repr:\n            self.comparison_traceback.append(\n                ""  <<<<<<<<<<<< Reference output from ipynb file:""\n                + cc.ENDC)\n            self.comparison_traceback.append(_indent(left))\n            self.comparison_traceback.append(\n                cc.FAIL\n                + \'  ============ disagrees with newly computed (test) output:\'\n                + cc.ENDC)\n            self.comparison_traceback.append(_indent(right))\n            self.comparison_traceback.append(\n                cc.FAIL\n                + \'  >>>>>>>>>>>>\')\n        self.comparison_traceback.append(cc.ENDC)\n\n\n    """""" *****************************************************\n        ***************************************************** """"""\n\n    def setup(self):\n        if self.parent.timed_out:\n            # xfail(condition, reason=None, run=True, raises=None, strict=False)\n            xfail_mark = pytest.mark.xfail(\n                True,\n                reason=\'Previous cell timed out, expected cell to fail\'\n            )\n            self.add_marker(xfail_mark)\n\n\n    def raise_cell_error(self, message, *args, **kwargs):\n        raise NbCellError(self.cell_num, message, self.cell.source, *args, **kwargs)\n\n\n    def runtest(self):\n        """"""\n        Run test is called by pytest for each of these nodes that are\n        collected i.e. a notebook cell. Runs all the cell tests in one\n        kernel without restarting.  It is very common for ipython\n        notebooks to run through assuming a single kernel.  The cells\n        are tested that they execute without errors and that the\n        output matches the output stored in the notebook.\n\n        """"""\n        # Simply skip cell if configured to\n        if self.options[\'skip\']:\n            pytest.skip()\n\n        kernel = self.parent.kernel\n        if not kernel.is_alive():\n            raise RuntimeError(""Kernel dead on test start"")\n\n        # Execute the code in the current cell in the kernel. Returns the\n        # message id of the corresponding response from iopub.\n        msg_id = kernel.execute_cell_input(\n            self.cell.source, allow_stdin=False)\n\n        # Timeout for the cell execution\n        # after code is sent for execution, the kernel sends a message on\n        # the shell channel. Timeout if no message received.\n        timeout = self.config.option.nbval_cell_timeout\n        timed_out_this_run = False\n\n        # Poll the shell channel to get a message\n        try:\n            self.parent.kernel.await_reply(msg_id, timeout=timeout)\n        except Empty:  # Timeout reached\n            # Try to interrupt kernel, as this will give us traceback:\n            kernel.interrupt()\n            self.parent.timed_out = True\n            timed_out_this_run = True\n\n        # This list stores the output information for the entire cell\n        outs = []\n        # TODO: Only store if comparing with nbdime, to save on memory usage\n        self.test_outputs = outs\n\n        # Now get the outputs from the iopub channel\n        while True:\n            # The iopub channel broadcasts a range of messages. We keep reading\n            # them until we find the message containing the side-effects of our\n            # code execution.\n            try:\n                # Get a message from the kernel iopub channel\n                msg = self.parent.get_kernel_message(timeout=self.output_timeout)\n\n            except Empty:\n                # This is not working: ! The code will not be checked\n                # if the time is out (when the cell stops to be executed?)\n                # Halt kernel here!\n                kernel.stop()\n                if timed_out_this_run:\n                    self.raise_cell_error(\n                        ""Timeout of %g seconds exceeded while executing cell.""\n                        "" Failed to interrupt kernel in %d seconds, so ""\n                        ""failing without traceback."" %\n                            (timeout, self.output_timeout),\n                    )\n                else:\n                    self.parent.timed_out = True\n                    self.raise_cell_error(\n                        ""Timeout of %d seconds exceeded waiting for output."" %\n                            self.output_timeout,\n                    )\n\n\n\n            # now we must handle the message by checking the type and reply\n            # info and we store the output of the cell in a notebook node object\n            msg_type = msg[\'msg_type\']\n            reply = msg[\'content\']\n            out = NotebookNode(output_type=msg_type)\n\n            # Is the iopub message related to this cell execution?\n            if msg[\'parent_header\'].get(\'msg_id\') != msg_id:\n                continue\n\n            # When the kernel starts to execute code, it will enter the \'busy\'\n            # state and when it finishes, it will enter the \'idle\' state.\n            # The kernel will publish state \'starting\' exactly\n            # once at process startup.\n            if msg_type == \'status\':\n                if reply[\'execution_state\'] == \'idle\':\n                    break\n                else:\n                    continue\n\n            # execute_input: To let all frontends know what code is\n            # being executed at any given time, these messages contain a\n            # re-broadcast of the code portion of an execute_request,\n            # along with the execution_count.\n            elif msg_type == \'execute_input\':\n                continue\n\n            # com? execute reply?\n            elif msg_type.startswith(\'comm\'):\n                continue\n            elif msg_type == \'execute_reply\':\n                continue\n\n            # This message type is used to clear the output that is\n            # visible on the frontend\n            # elif msg_type == \'clear_output\':\n            #     outs = []\n            #     continue\n\n\n            # elif (msg_type == \'clear_output\'\n            #       and msg_type[\'execution_state\'] == \'idle\'):\n            #     outs = []\n            #     continue\n\n            # \'execute_result\' is equivalent to a display_data message.\n            # The object being displayed is passed to the display\n            # hook, i.e. the *result* of the execution.\n            # The only difference is that \'execute_result\' has an\n            # \'execution_count\' number which does not seems useful\n            # (we will filter it in the sanitize function)\n            #\n            # When the reply is display_data or execute_result,\n            # the dictionary contains\n            # a \'data\' sub-dictionary with the \'text\' AND the \'image/png\'\n            # picture (in hexadecimal). There is also a \'metadata\' entry\n            # but currently is not of much use, sometimes there is information\n            # as height and width of the image (CHECK the documentation)\n            # Thus we iterate through the keys (mimes) \'data\' sub-dictionary\n            # to obtain the \'text\' and \'image/png\' information\n            elif msg_type in (\'display_data\', \'execute_result\'):\n                out[\'metadata\'] = reply[\'metadata\']\n                out[\'data\'] = reply[\'data\']\n                outs.append(out)\n\n                if msg_type == \'execute_result\':\n                    out.execution_count = reply[\'execution_count\']\n\n\n            # if the message is a stream then we store the output\n            elif msg_type == \'stream\':\n                out.name = reply[\'name\']\n                out.text = reply[\'text\']\n                outs.append(out)\n\n\n            # if the message type is an error then an error has occurred during\n            # cell execution. Therefore raise a cell error and pass the\n            # traceback information.\n            elif msg_type == \'error\':\n                # Store error in output first\n                out[\'ename\'] = reply[\'ename\']\n                out[\'evalue\'] = reply[\'evalue\']\n                out[\'traceback\'] = reply[\'traceback\']\n                outs.append(out)\n                if not self.options[\'check_exception\']:\n                    # Ensure we flush iopub before raising error\n                    try:\n                        self.parent.kernel.await_idle(msg_id, self.output_timeout)\n                    except Empty:\n                        self.stop()\n                        raise RuntimeError(\'Timed out waiting for idle kernel!\')\n                    traceback = \'\\n\' + \'\\n\'.join(reply[\'traceback\'])\n                    if out[\'ename\'] == \'KeyboardInterrupt\' and self.parent.timed_out:\n                        msg = ""Timeout of %g seconds exceeded executing cell"" % timeout\n                    else:\n                        msg = ""Cell execution caused an exception""\n                    self.raise_cell_error(msg, traceback)\n\n            # any other message type is not expected\n            # should this raise an error?\n            else:\n                print(""unhandled iopub msg:"", msg_type)\n\n        outs[:] = coalesce_streams(outs)\n\n        # Cells where the reference is not run, will not check outputs:\n        #unrun = self.cell.execution_count is None\n        #if unrun and self.cell.outputs:\n            #self.raise_cell_error(\'Unrun reference cell has outputs\')\n\n        # Compare if the outputs have the same number of lines\n        # and throw an error if it fails\n        # if len(outs) != len(self.cell.outputs):\n        #     self.diff_number_outputs(outs, self.cell.outputs)\n        #     failed = True\n        failed = False\n        if self.options[\'check\'] and not unrun:\n            if not self.compare_outputs(outs, coalesce_streams(self.cell.outputs)):\n                failed = True\n\n        # If the comparison failed then we raise an exception.\n        if failed:\n            # The traceback containing the difference in the outputs is\n            # stored in the variable comparison_traceback\n            self.raise_cell_error(\n                ""Cell outputs differ"",\n                # Here we must put the traceback output:\n                \'\\n\'.join(self.comparison_traceback),\n            )\n\n\n    def sanitize_outputs(self, outputs, skip_sanitize=(\'metadata\',\n                                                       \'traceback\',\n                                                       \'text/latex\',\n                                                       \'prompt_number\',\n                                                       \'output_type\',\n                                                       \'name\',\n                                                       \'execution_count\'\n                                                       )):\n        sanitized_outputs = []\n        for output in outputs:\n            sanitized = {}\n            for key in output.keys():\n                if key in skip_sanitize:\n                    sanitized[key] = output[key]\n                else:\n                    if key == \'data\':\n                        sanitized[key] = {}\n                        for data_key in output[key].keys():\n                            # Filter the keys in the SUB-dictionary again\n                            if data_key in skip_sanitize:\n                                sanitized[key][data_key] = output[key][data_key]\n                            else:\n                                sanitized[key][data_key] = self.sanitize(output[key][data_key])\n\n                    # Otherwise, just create a normal dictionary entry from\n                    # one of the keys of the dictionary\n                    else:\n                        # Create the dictionary entries on the fly, from the\n                        # existing ones to be compared\n                        sanitized[key] = self.sanitize(output[key])\n            sanitized_outputs.append(nbformat.from_dict(sanitized))\n        return sanitized_outputs\n\n    def sanitize(self, s):\n        """"""sanitize a string for comparison.\n        """"""\n        if not isinstance(s, six.string_types):\n            return s\n\n        """"""\n        re.sub matches a regex and replaces it with another.\n        The regex replacements are taken from a file if the option\n        is passed when py.test is called. Otherwise, the strings\n        are not processed\n        """"""\n        for regex, replace in six.iteritems(self.parent.sanitize_patterns):\n            s = re.sub(regex, replace, s)\n        return s\n\n\ncarriagereturn_pat = re.compile(r\'.*\\r(?=[^\\n])\')\nbackspace_pat = re.compile(r\'[^\\n]\\b\')\n\n\ndef coalesce_streams(outputs):\n    """"""\n    Merge all stream outputs with shared names into single streams\n    to ensure deterministic outputs.\n\n    Parameters\n    ----------\n    outputs : iterable of NotebookNodes\n        Outputs being processed\n    """"""\n    if not outputs:\n        return outputs\n\n    new_outputs = []\n    streams = {}\n    for output in outputs:\n        if (output.output_type == \'stream\'):\n            if output.name in streams:\n                streams[output.name].text += output.text\n            else:\n                new_outputs.append(output)\n                streams[output.name] = output\n        else:\n            new_outputs.append(output)\n\n    # process \\r and \\b characters\n    for output in streams.values():\n        old = output.text\n        while len(output.text) < len(old):\n            old = output.text\n            # Cancel out anything-but-newline followed by backspace\n            output.text = backspace_pat.sub(\'\', output.text)\n        # Replace all carriage returns not followed by newline\n        output.text = carriagereturn_pat.sub(\'\', output.text)\n\n    return new_outputs\n\n\ndef transform_streams_for_comparison(outputs):\n    """"""Makes failure output for streams better by having key be the stream name""""""\n    new_outputs = []\n    for output in outputs:\n        if (output.output_type == \'stream\'):\n            # Transform output\n            new_outputs.append({\n                \'output_type\': \'stream\',\n                output.name: output.text,\n            })\n        else:\n            new_outputs.append(output)\n    return new_outputs\n\n\ndef get_sanitize_patterns(string):\n    """"""\n    *Arguments*\n\n    string:  str\n\n        String containing a list of regex-replace pairs as would be\n        read from a sanitize config file.\n\n    *Returns*\n\n    A list of (regex, replace) pairs.\n    """"""\n    return re.findall(\'^regex: (.*)$\\n^replace: (.*)$\',\n                      string,\n                      flags=re.MULTILINE)\n\n\ndef hash_string(s):\n    return hashlib.md5(s.encode(""utf8"")).hexdigest()\n\n_base64 = re.compile(r\'^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$\', re.MULTILINE | re.UNICODE)\n\n\ndef _trim_base64(s):\n    """"""Trim and hash base64 strings""""""\n    if len(s) > 64 and _base64.match(s.replace(\'\\n\', \'\')):\n        h = hash_string(s)\n        s = \'%s...<snip base64, md5=%s...>\' % (s[:8], h[:16])\n    return s\n\n\ndef _indent(s, indent=\'  \'):\n    """"""Intent each line with indent""""""\n    if isinstance(s, six.string_types):\n        return \'\\n\'.join((\'%s%s\' % (indent, line) for line in s.splitlines()))\n    return s\n'"
docs_src/sidebar/sidebar_data.py,0,"b""# Usage: After editing this file, next run:\n#\n# tools/make_sidebar.py\n# git commit docs/_data/sidebars/home_sidebar.yml docs_src/sidebar/sidebar_data.py\n# git push\n\n# This dict defines the structure:\n\nsidebar_d = {\n    'Getting started': {\n        'Installation': 'https://github.com/fastai/fastai/blob/master/README.md#installation',\n        'Installation Extras': '/install',\n        'Troubleshooting': '/troubleshoot',\n        'Performance': '/performance',\n        'Support': '/support'\n    },\n    'Training': {\n        'Overview': '/training',\n        'basic_train': '/basic_train',\n        'train': '/train',\n        'metrics': '/metrics',\n        'callback': '/callback',\n        '': {\n            'callbacks': {\n                'Overview': '/callbacks',\n                'HookCallback': '/callbacks.hooks',\n                'MixedPrecision': '/callbacks.fp16',\n                'OneCycleScheduler': '/callbacks.one_cycle',\n                'LRFinder': '/callbacks.lr_finder',\n                'MixUpCallback': '/callbacks.mixup',\n                'RNNTrainer': '/callbacks.rnn',\n                'GeneralScheduler': '/callbacks.general_sched',\n                'CSV Logger': '/callbacks.csv_logger',\n                'Tracking': '/callbacks.tracker',\n                'Tensorboard': '/callbacks.tensorboard',\n                'Memory Profiling': '/callbacks.mem',\n                'Miscellaneous': '/callbacks.misc',\n            }\n        },\n    },\n    'Applications': {\n        'Overview': '/applications',\n        '': {\n            'vision': {\n                'Overview': '/vision',\n                'vision.learner': '/vision.learner',\n                'vision.interpret': '/vision.interpret',\n                'vision.transform': '/vision.transform',\n                'vision.image': '/vision.image',\n                'vision.data': '/vision.data',\n                'vision.gan': '/vision.gan',\n                'vision.model overview': '/vision.models',\n                'vision.models.unet': '/vision.models.unet',\n            }\n        },\n        'empty1': {\n            'text': {\n                'Overview': '/text',\n                'text.learner': '/text.learner',\n                'text.interpret': '/text.interpret',\n                'text.transform': '/text.transform',\n                'text.data': '/text.data',\n                'text.models': '/text.models'\n            },\n        },\n        'empty2': {\n            'tabular': {\n                'Overview': '/tabular',\n                'tabular.transform': '/tabular.transform',\n                'tabular.data': '/tabular.data',\n                'tabular.models': '/tabular.models',\n                'tabular.learner': '/tabular.learner'\n            },\n        },\n        'empty3': {\n            'widgets': {\n                'widgets.class_confusion': '/widgets.class_confusion',\n                'widgets.image_cleaner': '/widgets.image_cleaner'\n            },\n        },\n        'collab': '/collab',\n    },\n    'Core': {\n        'Overview': '/overview',\n        'data_block': '/data_block',\n        'basic_data': '/basic_data',\n        'layers': '/layers',\n        'datasets': '/datasets',\n        'core': '/core',\n        'torch_core': '/torch_core',\n        'imports': '/imports',\n    },\n    'Utils': {\n        'Helpers': '/utils.collect_env',\n        'Memory Management': '/utils.mem',\n        'ipython helpers': '/utils.ipython',\n        'Display utils': '/utils.mod_display',\n    },\n    'Tutorials': {\n        'Overview': '/tutorials',\n        'Look at data': '/tutorial.data',\n        'Inference Learner': '/tutorial.inference',\n        'Custom ItemList': '/tutorial.itemlist',\n        'DL on a Shoestring': '/tutorial.resources',\n        'Distributed training': '/distributed',\n    },\n    'Doc authoring': {\n        'Instructions': '/gen_doc_main',\n        'gen_doc': '/gen_doc',\n        'gen_doc.gen_notebooks': '/gen_doc.gen_notebooks',\n        'gen_doc.nbdoc': '/gen_doc.nbdoc',\n        'gen_doc.nbtest': '/gen_doc.nbtest',\n        'gen_doc.convert2html': '/gen_doc.convert2html',\n    },\n    'Library development': {\n        'Contributing': 'https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md',\n        'Dev Notes': '/dev/develop',\n        'GPU Notes': '/dev/gpu',\n        'git notes': '/dev/git',\n        'Testing': '/dev/test',\n        'Style Guide': '/dev/style',\n        'Abbreviations': '/dev/abbr',\n        'Packaging': '/dev/release',\n    }\n}\n"""
fastai/callbacks/__init__.py,0,"b'from .lr_finder import *\nfrom .one_cycle import *\nfrom .fp16 import *\nfrom .general_sched import *\nfrom .hooks import *\nfrom .mixup import *\nfrom .rnn import *\nfrom .tracker import *\nfrom .csv_logger import *\nfrom .loss_metrics import *\nfrom .oversampling import *\nfrom .flat_cos_anneal import *\n\n__all__ = [*lr_finder.__all__, *one_cycle.__all__, *fp16.__all__, *general_sched.__all__, *hooks.__all__, *mixup.__all__, *rnn.__all__,\n           *tracker.__all__, *csv_logger.__all__, *loss_metrics.__all__, *oversampling.__all__, *flat_cos_anneal.__all__]\n'"
fastai/callbacks/cpu_mem.py,0,"b'"" Memory profiling callbacks ""\n\nimport tracemalloc, threading, torch, time\nfrom ..utils.mem import *\nfrom ..basic_train import *\nfrom ..torch_core import *\n\nclass CpuPeakMemMetric(LearnerCallback):\n    ""Callback that measures used and peaked general and CPU memory.""\n\n    _order = -20  # Needs to run before the recorder\n\n    def peak_monitor_start(self):\n        self.peak_monitoring = True\n\n        # start RAM tracing\n        tracemalloc.start()\n\n        # this thread samples RAM usage as long as the current epoch of the fit loop is running\n        peak_monitor_thread = threading.Thread(target=self.peak_monitor_func)\n        peak_monitor_thread.daemon = True\n        peak_monitor_thread.start()\n\n    def peak_monitor_stop(self):\n        tracemalloc.stop()\n        self.peak_monitoring = False\n\n    def peak_monitor_func(self):\n        self.cpu_mem_used_peak = -1\n        while True:\n            if not self.peak_monitoring: break\n            time.sleep(0.001)  # 1msec\n\n    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names([\'cpu used\', \'cpu_peak\'])\n\n    def on_epoch_begin(self, **kwargs): self.peak_monitor_start()\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        cpu_used, cpu_peak = list(map(lambda x: float(x / 2 ** 20), tracemalloc.get_traced_memory()))\n        self.peak_monitor_stop()\n        # The numbers are deltas in MBs (beginning of the epoch and the end)\n        return add_metrics(last_metrics, [cpu_used, cpu_peak])\n'"
fastai/callbacks/csv_logger.py,0,"b'""A `Callback` that saves tracked metrics into a persistent file.""\n#Contribution from devforfu: https://nbviewer.jupyter.org/gist/devforfu/ea0b3fcfe194dad323c3762492b05cae\nfrom ..torch_core import *\nfrom ..basic_data import DataBunch\nfrom ..callback import *\nfrom ..basic_train import Learner, LearnerCallback\nfrom time import time\nfrom fastprogress.fastprogress import format_time\n\n__all__ = [\'CSVLogger\']\n\nclass CSVLogger(LearnerCallback):\n    ""A `LearnerCallback` that saves history of metrics while training `learn` into CSV `filename`.""\n    def __init__(self, learn:Learner, filename: str = \'history\', append: bool = False): \n        super().__init__(learn)\n        self.filename,self.path,self.append = filename,self.learn.path/f\'{filename}.csv\',append\n        self.add_time = True\n\n    def read_logged_file(self):  \n        ""Read the content of saved file""\n        return pd.read_csv(self.path)\n\n    def on_train_begin(self, **kwargs: Any) -> None:\n        ""Prepare file with metric names.""\n        self.path.parent.mkdir(parents=True, exist_ok=True)  \n        add_header = not self.path.exists() or not self.append\n        self.file = self.path.open(\'a\') if self.append else self.path.open(\'w\')\n        if add_header: self.file.write(\',\'.join(self.learn.recorder.names[:(None if self.add_time else -1)]) + \'\\n\')\n    \n    def on_epoch_begin(self, **kwargs:Any)->None:\n        if self.add_time: self.start_epoch = time()\n        \n    def on_epoch_end(self, epoch: int, smooth_loss: Tensor, last_metrics: MetricsList, **kwargs: Any) -> bool:\n        ""Add a line with `epoch` number, `smooth_loss` and `last_metrics`.""\n        last_metrics = ifnone(last_metrics, [])\n        stats = [str(stat) if isinstance(stat, int) else \'#na#\' if stat is None else f\'{stat:.6f}\'\n                 for name, stat in zip(self.learn.recorder.names, [epoch, smooth_loss] + last_metrics)]\n        if self.add_time: stats.append(format_time(time() - self.start_epoch))\n        str_stats = \',\'.join(stats)\n        self.file.write(str_stats + \'\\n\')\n        self.file.flush()\n        os.fsync(self.file.fileno())\n\n    def on_train_end(self, **kwargs: Any) -> None:  \n        ""Close the file.""\n        self.file.close()\n'"
fastai/callbacks/flat_cos_anneal.py,0,"b'""Supports flat-cosine-annealling style training""\r\n\r\nfrom ..core import *\r\nfrom ..callback import *\r\nfrom ..callbacks import *\r\nfrom ..basic_train import Learner, LearnerCallback\r\n\r\n__all__ = [\'FlatCosAnnealScheduler\']\r\n\r\n# A new scheduler by Mikhail Grankin aimed for use of the new optimizers\r\n\r\ndef FlatCosAnnealScheduler(learn, lr:float=4e-3, tot_epochs:int=1, moms:Floats=(0.95,0.999),\r\n                          start_pct:float=0.72, curve=\'cosine\'):\r\n  ""Manage FCFit trainnig as found in the ImageNette experiments""\r\n  n = len(learn.data.train_dl)\r\n  anneal_start = int(n * tot_epochs * start_pct)\r\n  batch_finish = ((n * tot_epochs) - anneal_start)\r\n  if curve==""cosine"":        curve_type=annealing_cos\r\n  elif curve==""linear"":      curve_type=annealing_linear\r\n  elif curve==""exponential"": curve_type=annealing_exp\r\n  else: raiseValueError(f""annealing type not supported {curve}"")\r\n  phase0 = TrainingPhase(anneal_start).schedule_hp(\'lr\', lr).schedule_hp(\'mom\', moms[0])\r\n  phase1 = TrainingPhase(batch_finish).schedule_hp(\'lr\', lr, anneal=curve_type).schedule_hp(\'mom\', moms[1])\r\n  phases = [phase0, phase1]\r\n  return GeneralScheduler(learn, phases)\r\n'"
fastai/callbacks/fp16.py,4,"b'""Callback support for half precision (fp16) training. Increases training speed.""\nfrom ..torch_core import *\nfrom ..callback import *\nfrom ..basic_train import *\nfrom torch._utils import _unflatten_dense_tensors\nfrom torch.nn.utils import parameters_to_vector\n\n__all__ = [\'MixedPrecision\']\n\ndef get_master(layer_groups:ModuleList, flat_master:bool=False) -> Tuple[List[List[Tensor]], List[List[Tensor]]]:\n    ""Return two lists, one for the model parameters in FP16 and one for the master parameters in FP32.""\n    split_params = split_no_wd_params(layer_groups)\n    model_params = [[param for param in pg if param.requires_grad] for pg in split_params]\n    if flat_master:\n        master_params = []\n        for lg in model_params:\n            if len(lg) !=0 :\n                mp = parameters_to_vector([param.data.float() for param in lg])\n                mp = torch.nn.Parameter(mp, requires_grad=True)\n                if mp.grad is None: mp.grad = mp.new(*mp.size())\n                master_params.append([mp])\n            else: master_params.append([])\n        return model_params, master_params\n    else:\n        master_params = [[param.clone().float().detach() for param in lg] for lg in model_params]\n        for mp in master_params:\n            for param in mp: param.requires_grad = True\n        return model_params, master_params\n\ndef model_g2master_g(model_params:Sequence[Tensor], master_params:Sequence[Tensor], flat_master:bool=False)->None:\n    ""Copy the `model_params` gradients to `master_params` for the optimizer step.""\n    if flat_master:\n        for model_group,master_group in zip(model_params,master_params):\n            if len(master_group) != 0:\n                if master_group[0].grad is None: master_group[0].grad = master_group[0].data.new(*master_group[0].data.size())\n                master_group[0].grad.data.copy_(parameters_to_vector([p.grad.data.float() for p in model_group]))\n    else:\n        for model_group,master_group in zip(model_params,master_params):\n            for model, master in zip(model_group, master_group):\n                if model.grad is not None:\n                    if master.grad is None: master.grad = master.data.new(*master.data.size())\n                    master.grad.data.copy_(model.grad.data)\n                else: master.grad = None\n\ndef master2model(model_params:Sequence[Tensor], master_params:Sequence[Tensor], flat_master:bool=False)->None:\n    ""Copy `master_params` to `model_params`.""\n    if flat_master:\n        for model_group,master_group in zip(model_params,master_params):\n            if len(model_group) != 0:\n                for model, master in zip(model_group, _unflatten_dense_tensors(master_group[0].data, model_group)):\n                    model.data.copy_(master)\n    else:\n        for model_group,master_group in zip(model_params,master_params):\n            for model, master in zip(model_group, master_group): model.data.copy_(master.data)\n\ndef grad_overflow(param_group):\n    for group in param_group:\n        for p in group:\n            if p.grad is not None:\n                s = float(p.grad.data.float().sum())\n                if s == float(\'inf\') or s == float(\'-inf\') or s != s: return True\n    return False\n\nclass MixedPrecision(LearnerCallback):\n    _order = 999 #Need to run after things that could call on_backward_begin and change the loss\n    ""Callback that handles mixed-precision training.""\n    def __init__(self, learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n                 flat_master:bool=False, max_scale:float=2**24, loss_fp32:bool=True):\n        super().__init__(learn)\n        self.flat_master,self.dynamic,self.max_noskip,self.clip,self.max_scale = flat_master,dynamic,max_noskip,clip,max_scale\n        self.loss_fp32 = loss_fp32\n        self.loss_scale = ifnone(loss_scale, 2**16 if dynamic else 512)\n        self.not_min += [\'model_params\', \'master_params\']\n        assert torch.backends.cudnn.enabled, ""Mixed precision training requires cudnn.""\n        self.opt = None\n\n    def on_train_begin(self, **kwargs:Any)->None:\n        ""Prepare the master model.""\n        #Get a copy of the model params in FP32\n        self.model_params, self.master_params = get_master(self.learn.layer_groups, self.flat_master)\n        #Changes the optimizer so that the optimization step is done in FP32.\n        new_opt = self.learn.opt.new_with_params(self.master_params)\n        if self.opt is not None:\n            self.opt.lr,self.opt.wd = self.learn.opt.lr,self.learn.opt.wd\n            new_opt.load_state_dict(self.opt)\n        self.learn.opt.opt = new_opt.opt\n        self.noskip = 0\n\n    def on_loss_begin(self, last_output:Tensor, **kwargs:Any) -> Tensor:\n        ""Convert half precision output to FP32 to avoid reduction overflow.""\n        if self.loss_fp32: return {\'last_output\': to_float(last_output)}\n\n    def on_backward_begin(self, last_loss:Rank0Tensor, **kwargs:Any) -> Rank0Tensor:\n        ""Scale gradients up by `self.loss_scale` to prevent underflow.""\n        #To avoid gradient underflow, we scale the gradients\n        ret_loss = last_loss * self.loss_scale\n        return {\'last_loss\': ret_loss}\n\n    def on_backward_end(self, **kwargs:Any)->None:\n        ""Convert the gradients back to FP32 and divide them by the scale.""\n        if self.dynamic and grad_overflow(self.model_params) and self.loss_scale > 1:\n            self.loss_scale /= 2\n            self.noskip = 0\n            #The step will be skipped since we don\'t update the master grads so they are all None or zero\n        else:\n            model_g2master_g(self.model_params, self.master_params, self.flat_master)\n            for group in self.master_params:\n                for param in group:\n                    if param.grad is not None: param.grad.div_(self.loss_scale)\n            if self.clip is not None:\n                for group in self.master_params: nn.utils.clip_grad_norm_(group, self.clip)\n            if not self.dynamic: return\n            self.noskip += 1\n            if self.noskip >= self.max_noskip and self.loss_scale < self.max_scale:\n                self.loss_scale *= 2\n                self.noskip = 0\n\n    def on_step_end(self, **kwargs:Any)->None:\n        ""Update the params from master to model and zero grad.""\n        #Zeros the gradients of the model since the optimizer is disconnected.\n        self.learn.model.zero_grad()\n        #Update the params from master to model.\n        master2model(self.model_params, self.master_params, self.flat_master)\n'"
fastai/callbacks/general_sched.py,0,"b'from ..core import *\nfrom ..callback import *\nfrom ..basic_train import Learner, LearnerCallback\n\n__all__ = [\'GeneralScheduler\', \'TrainingPhase\']\n\n@dataclass\nclass TrainingPhase():\n    ""Schedule hyper-parameters for a phase of `length` iterations.""\n    length:int\n    \n    def __post_init__(self): self.scheds = dict()\n    def schedule_hp(self, name, vals, anneal=None):\n        ""Adds a schedule for `name` between `vals` using `anneal`.""\n        self.scheds[name] = Scheduler(vals, self.length, anneal)\n        return self\n\nclass GeneralScheduler(LearnerCallback):\n    ""Schedule multiple `TrainingPhase` for a `Learner`.""\n    def __init__(self, learn:Learner, phases:Collection[TrainingPhase], start_epoch:int=None):\n        super().__init__(learn)\n        self.phases,self.start_epoch = phases,start_epoch\n\n    def on_train_begin(self, epoch:int, **kwargs:Any)->None:\n        ""Initialize the schedulers for training.""\n        res = {\'epoch\':self.start_epoch} if self.start_epoch is not None else None\n        self.start_epoch = ifnone(self.start_epoch, epoch)\n        self.scheds = [p.scheds for p in self.phases]\n        self.opt = self.learn.opt\n        for k,v in self.scheds[0].items(): \n            v.restart()\n            self.opt.set_stat(k, v.start)\n        self.idx_s = 0\n        return res\n    \n    def jump_to_epoch(self, epoch:int)->None:\n        for _ in range(len(self.learn.data.train_dl) * epoch):\n            self.on_batch_end(True)\n\n    def on_batch_end(self, train, **kwargs:Any)->None:\n        ""Take a step in lr,mom sched, start next stepper when the current one is complete.""\n        if train:\n            if self.idx_s >= len(self.scheds): return {\'stop_training\': True, \'stop_epoch\': True}\n            sched = self.scheds[self.idx_s]\n            for k,v in sched.items(): self.opt.set_stat(k, v.step())\n            if list(sched.values())[0].is_done: self.idx_s += 1'"
fastai/callbacks/hooks.py,0,"b'""Hooks provide extensibility at the model level.""\nfrom ..torch_core import *\nfrom ..callback import *\nfrom ..basic_train import *\nfrom ..basic_data import *\n\n__all__ = [\'ActivationStats\', \'Hook\', \'HookCallback\', \'Hooks\', \'hook_output\', \'hook_outputs\',\n           \'model_sizes\', \'num_features_model\', \'model_summary\', \'dummy_eval\', \'dummy_batch\']\n\nclass Hook():\n    ""Create a hook on `m` with `hook_func`.""\n    def __init__(self, m:nn.Module, hook_func:HookFunc, is_forward:bool=True, detach:bool=True):\n        self.hook_func,self.detach,self.stored = hook_func,detach,None\n        f = m.register_forward_hook if is_forward else m.register_backward_hook\n        self.hook = f(self.hook_fn)\n        self.removed = False\n\n    def hook_fn(self, module:nn.Module, input:Tensors, output:Tensors):\n        ""Applies `hook_func` to `module`, `input`, `output`.""\n        if self.detach:\n            input  = (o.detach() for o in input ) if is_listy(input ) else input.detach()\n            output = (o.detach() for o in output) if is_listy(output) else output.detach()\n        self.stored = self.hook_func(module, input, output)\n\n    def remove(self):\n        ""Remove the hook from the model.""\n        if not self.removed:\n            self.hook.remove()\n            self.removed=True\n\n    def __enter__(self, *args): return self\n    def __exit__(self, *args): self.remove()\n\nclass Hooks():\n    ""Create several hooks on the modules in `ms` with `hook_func`.""\n    def __init__(self, ms:Collection[nn.Module], hook_func:HookFunc, is_forward:bool=True, detach:bool=True):\n        self.hooks = [Hook(m, hook_func, is_forward, detach) for m in ms]\n\n    def __getitem__(self,i:int)->Hook: return self.hooks[i]\n    def __len__(self)->int: return len(self.hooks)\n    def __iter__(self): return iter(self.hooks)\n    @property\n    def stored(self): return [o.stored for o in self]\n\n    def remove(self):\n        ""Remove the hooks from the model.""\n        for h in self.hooks: h.remove()\n\n    def __enter__(self, *args): return self\n    def __exit__ (self, *args): self.remove()\n\ndef _hook_inner(m,i,o): return o if isinstance(o,Tensor) else o if is_listy(o) else list(o)\n\ndef hook_output (module:nn.Module, detach:bool=True, grad:bool=False)->Hook:\n    ""Return a `Hook` that stores activations of `module` in `self.stored`""\n    return Hook(module, _hook_inner, detach=detach, is_forward=not grad)\n\ndef hook_outputs(modules:Collection[nn.Module], detach:bool=True, grad:bool=False)->Hooks:\n    ""Return `Hooks` that store activations of all `modules` in `self.stored`""\n    return Hooks(modules, _hook_inner, detach=detach, is_forward=not grad)\n\nclass HookCallback(LearnerCallback):\n    ""Callback that can be used to register hooks on `modules`. Implement the corresponding function in `self.hook`.""\n    def __init__(self, learn:Learner, modules:Sequence[nn.Module]=None, do_remove:bool=True):\n        super().__init__(learn)\n        self.modules,self.do_remove = modules,do_remove\n\n    def on_train_begin(self, **kwargs):\n        ""Register the `Hooks` on `self.modules`.""\n        if not self.modules:\n            self.modules = [m for m in flatten_model(self.model) if has_params(m)]\n        self.hooks = Hooks(self.modules, self.hook)\n\n    def on_train_end(self, **kwargs):\n        ""Remove the `Hooks`.""\n        if self.do_remove: self.remove()\n\n    def remove(self): \n        if getattr(self, \'hooks\', None): self.hooks.remove()\n    def __del__(self): self.remove()\n\nclass ActivationStats(HookCallback):\n    ""Callback that record the mean and std of activations.""\n\n    def on_train_begin(self, **kwargs):\n        ""Initialize stats.""\n        super().on_train_begin(**kwargs)\n        self.stats = []\n\n    def hook(self, m:nn.Module, i:Tensors, o:Tensors)->Tuple[Rank0Tensor,Rank0Tensor]:\n        ""Take the mean and std of `o`.""\n        return o.mean().item(),o.std().item()\n    def on_batch_end(self, train, **kwargs):\n        ""Take the stored results and puts it in `self.stats`""\n        if train: self.stats.append(self.hooks.stored)\n    def on_train_end(self, **kwargs):\n        ""Polish the final result.""\n        super().on_train_end(**kwargs)\n        self.stats = tensor(self.stats).permute(2,1,0)\n\ndef dummy_batch(m: nn.Module, size:tuple=(64,64))->Tensor:\n    ""Create a dummy batch to go through `m` with `size`.""\n    ch_in = in_channels(m)\n    return one_param(m).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.)\n\ndef dummy_eval(m:nn.Module, size:tuple=(64,64)):\n    ""Pass a `dummy_batch` in evaluation mode in `m` with `size`.""\n    return m.eval()(dummy_batch(m, size))\n\ndef model_sizes(m:nn.Module, size:tuple=(64,64))->Tuple[Sizes,Tensor,Hooks]:\n    ""Pass a dummy input through the model `m` to get the various sizes of activations.""\n    with hook_outputs(m) as hooks:\n        x = dummy_eval(m, size)\n        return [o.stored.shape for o in hooks]\n\ndef num_features_model(m:nn.Module)->int:\n    ""Return the number of output features for `model`.""\n    sz = 64\n    while True:\n        try: return model_sizes(m, size=(sz,sz))[-1][1]\n        except Exception as e:\n            sz *= 2\n            if sz > 2048: raise\n\ndef total_params(m:nn.Module)->int:\n    params, trainable = 0, False\n    if hasattr(m, ""weight"") and hasattr(m.weight, ""size""):\n         params += m.weight.numel()\n         trainable = m.weight.requires_grad\n    if hasattr(m, ""bias"") and hasattr(m.bias, ""size""): params += m.bias.numel()\n    return params, trainable\n\ndef hook_params(modules:Collection[nn.Module])->Hooks:\n    return Hooks(modules, lambda m, i, o: total_params(m))\n\ndef params_size(m: Union[nn.Module,Learner], size: tuple = (3, 64, 64))->Tuple[Sizes, Tensor, Hooks]:\n    ""Pass a dummy input through the model to get the various sizes. Returns (res,x,hooks) if `full`""\n    if isinstance(m, Learner):\n        if m.data.is_empty:\n            raise Exception(""This is an empty `Learner` and `Learner.summary` requires some data to pass through the model."")\n        ds_type = DatasetType.Train if m.data.train_dl else (DatasetType.Valid if m.data.valid_dl else DatasetType.Test)\n        x = m.data.one_batch(ds_type=ds_type, detach=False, denorm=False)[0]\n        x = [o[:1] for o in x]  if is_listy(x) else x[:1]\n        m = m.model\n    elif isinstance(m, nn.Module): x = next(m.parameters()).new(1, *size)\n    else: raise TypeError(\'You should either pass in a Learner or nn.Module\')\n    with hook_outputs(flatten_model(m)) as hook_o:\n        with hook_params(flatten_model(m))as hook_p:\n            x = m.eval()(*x) if is_listy(x) else m.eval()(x)\n            output_size = [((o.stored.shape[1:]) if o.stored is not None else None) for o in hook_o]\n            params = [(o.stored if o.stored is not None else (None,None)) for o in hook_p]\n    params, trainables = map(list,zip(*params))\n    return output_size, params, trainables\n\ndef get_layer_name(layer:nn.Module)->str:\n    return str(layer.__class__).split(""."")[-1].split(""\'"")[0]\n\ndef layers_info(m:Collection[nn.Module]) -> Collection[namedtuple]:\n    func = lambda m:list(map(get_layer_name, flatten_model(m)))\n    layers_names = func(m.model) if isinstance(m, Learner) else func(m)\n    layers_sizes, layers_params, layers_trainable = params_size(m)\n    layer_info = namedtuple(\'Layer_Information\', [\'Layer\', \'OutputSize\', \'Params\', \'Trainable\'])\n    return list(map(layer_info, layers_names, layers_sizes, layers_params, layers_trainable))\n\ndef model_summary(m:Learner, n:int=70):\n    ""Print a summary of `m` using a output text width of `n` chars""\n    info = layers_info(m)\n    header = [""Layer (type)"", ""Output Shape"", ""Param #"", ""Trainable""]\n    res = m.model.__class__.__name__ + ""\\n""\n    res += ""="" * n + ""\\n""\n    res += f""{header[0]:<20} {header[1]:<20} {header[2]:<10} {header[3]:<10}\\n""\n    res += ""="" * n + ""\\n""\n    total_params = 0\n    total_trainable_params = 0\n    for layer, size, params, trainable in info:\n        if size is None: continue\n        total_params += int(params)\n        total_trainable_params += int(params) * trainable\n        size, trainable = str(list(size)), str(trainable)\n        res += f""{layer:<20} {size:<20} {int(params):<10,} {trainable:<10}\\n""\n        res += ""_"" * n + ""\\n""\n    res += f""\\nTotal params: {total_params:,}\\n""\n    res += f""Total trainable params: {total_trainable_params:,}\\n""\n    res += f""Total non-trainable params: {total_params - total_trainable_params:,}\\n""\n           \n    res += f""Optimized with {str(m.opt_func)[25:-1].replace(\'>\', \'\')}\\n""\n    if m.true_wd: res += f""Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \\n""\n    if ""wd"" in str(m.opt_func) or ""weight_decay"" in str(m.opt_func): res += f""\\x1b[1;31m Specifying weight decay in the optimizer has no effect, Learner will overwrite \\x1b[0m \\n""\n    if ""lr"" in str(m.opt_func) or ""learning_rate"" in str(m.opt_func): res += f""\\x1b[1;31m Specifying lr in the optimizer has no effect, pass it to fit or the defaults.lr will apply \\x1b[0m \\n"" \n    res += f""Loss function : {m.loss_func.__class__.__name__}\\n""\n    res += ""="" * n + ""\\n""\n    res += ""Callbacks functions applied \\n""\n    res += ""\\n"".join([f""    {cbs.__class__.__name__}"" for cbs in m.callbacks])\n\n    return PrettyString(res)\n\nLearner.summary = model_summary\n'"
fastai/callbacks/loss_metrics.py,0,"b'from ..torch_core import *\nfrom ..callback import *\nfrom ..basic_train import Learner, LearnerCallback\n\n__all__ = [\'LossMetrics\']\n\nclass LossMetrics(LearnerCallback):\n    ""Add `loss_func.metrics` to metrics named by `loss_func.metric_names`""\n    _order = -20 #Needs to run before the recorder\n\n    def on_train_begin(self, **kwargs):\n        ""Add the metrics names to the `Recorder`.""\n        self.names = ifnone(self.learn.loss_func.metric_names, [])\n        if not self.names: warn(\'LossMetrics requested but no loss_func.metric_names provided\')\n        self.learn.recorder.add_metric_names(self.names)\n\n    def on_epoch_begin(self, **kwargs):\n        ""Initialize the metrics for this epoch.""\n        self.metrics = {name:0. for name in self.names}\n        self.nums = 0\n\n    def on_batch_end(self, last_target, train, **kwargs):\n        ""Update the metrics if not `train`""\n        if train: return\n        bs = last_target.size(0)\n        for name in self.names:\n            self.metrics[name] += bs * self.learn.loss_func.metrics[name].detach().cpu()\n        self.nums += bs\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        ""Finish the computation and sends the result to the Recorder.""\n        if not self.nums: return\n        metrics = [self.metrics[name]/self.nums for name in self.names]\n        return {\'last_metrics\': last_metrics+metrics}\n'"
fastai/callbacks/lr_finder.py,1,"b'""Tools to help find the optimal learning rate for training""\nfrom ..torch_core import *\nfrom ..basic_data import DataBunch\nfrom ..callback import *\nfrom ..basic_train import Learner, LearnerCallback\n\n__all__ = [\'LRFinder\']\n\nclass LRFinder(LearnerCallback):\n    ""Causes `learn` to go on a mock training from `start_lr` to `end_lr` for `num_it` iterations.""\n    def __init__(self, learn:Learner, start_lr:float=1e-7, end_lr:float=10, num_it:int=100, stop_div:bool=True):\n        super().__init__(learn)\n        self.data,self.stop_div = learn.data,stop_div\n        self.sched = Scheduler((start_lr, end_lr), num_it, annealing_exp)\n\n    def on_train_begin(self, pbar, **kwargs:Any)->None:\n        ""Initialize optimizer and learner hyperparameters.""\n        setattr(pbar, \'clean_on_interrupt\', True)\n        self.learn.save(\'tmp\')\n        self.opt = self.learn.opt\n        self.opt.lr = self.sched.start\n        self.stop,self.best_loss = False,0.\n        return {\'skip_validate\': True}\n\n    def on_batch_end(self, iteration:int, smooth_loss:TensorOrNumber, **kwargs:Any)->None:\n        ""Determine if loss has runaway and we should stop.""\n        if iteration==0 or smooth_loss < self.best_loss: self.best_loss = smooth_loss\n        self.opt.lr = self.sched.step()\n        if self.sched.is_done or (self.stop_div and (smooth_loss > 4*self.best_loss or torch.isnan(smooth_loss))):\n            #We use the smoothed loss to decide on the stopping since it\'s less shaky.\n            if not self.stop: self.stop = iteration\n            if num_distrib() <= 1: return { \'stop_epoch\': True, \'stop_training\' : True }\n    \n    def on_epoch_end(self, **kwargs:Any)->None:\n        if self.stop: return { \'stop_training\' : True }\n\n    def on_train_end(self, epoch:int, num_batch:int, **kwargs:Any)->None:\n        ""Cleanup learn model weights disturbed during LRFinder exploration.""\n        self.learn.load(\'tmp\', purge=False)\n        if hasattr(self.learn.model, \'reset\'): self.learn.model.reset()\n        for cb in self.callbacks:\n            if hasattr(cb, \'reset\'): cb.reset()\n        print(\'LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\')\n        total_batches = epoch * num_batch\n        if total_batches - self.stop > 10:\n            print(f""Best loss at batch #{self.stop}/{total_batches}, may consider .plot(skip_end={total_batches-self.stop+3})"")\n'"
fastai/callbacks/mem.py,2,"b'"" Memory profiling callbacks ""\n\nimport tracemalloc, threading, torch, time\nfrom ..utils.mem import *\nfrom ..basic_train import *\nfrom ..torch_core import *\nfrom ..utils.pynvml_gate import *\n\nif use_gpu: pynvml = load_pynvml_env()\n\nclass PeakMemMetric(LearnerCallback):\n    ""Callback that measures used and peaked general and GPU memory.""\n\n    _order=-20 # Needs to run before the recorder\n\n    def __init__(self, learn:Learner):\n        super().__init__(learn)\n        assert torch.cuda.is_available(), ""pytorch CUDA is required""\n        preload_pytorch()\n\n    def peak_monitor_start(self):\n        self.peak_monitoring = True\n\n        # start RAM tracing\n        tracemalloc.start()\n\n        # this thread samples RAM usage as long as the current epoch of the fit loop is running\n        peak_monitor_thread = threading.Thread(target=self.peak_monitor_func)\n        peak_monitor_thread.daemon = True\n        peak_monitor_thread.start()\n\n    def peak_monitor_stop(self):\n        tracemalloc.stop()\n        self.peak_monitoring = False\n\n    def peak_monitor_func(self):\n        self.gpu_mem_used_peak = -1\n\n        gpu_id = torch.cuda.current_device()\n        gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)\n\n        while True:\n            gpu_mem_used = gpu_mem_get_used_fast(gpu_handle)\n            self.gpu_mem_used_peak = max(gpu_mem_used, self.gpu_mem_used_peak)\n            if not self.peak_monitoring: break\n            time.sleep(0.001) # 1msec\n\n    def on_train_begin(self, **kwargs):\n        self.learn.recorder.add_metric_names([\'cpu used\',  \'peak\', \'gpu used\',  \'peak\'])\n\n    def on_epoch_begin(self, **kwargs):\n        self.peak_monitor_start()\n        self.gpu_before = gpu_mem_get_used_no_cache()\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        cpu_used, cpu_peak =  list(map(lambda x: int(x/2**20), tracemalloc.get_traced_memory()))\n        self.peak_monitor_stop()\n        gpu_used = gpu_mem_get_used_no_cache() - self.gpu_before\n        gpu_peak = self.gpu_mem_used_peak      - self.gpu_before\n        # can be negative, due to unreliable peak monitor thread\n        if gpu_peak < 0:   gpu_peak = 0\n        # since we want the overhead only, subtract delta used if it\'s positive\n        elif gpu_used > 0: gpu_peak -= gpu_used\n        # The numbers are deltas in MBs (beginning of the epoch and the end)\n        return add_metrics(last_metrics, [cpu_used, cpu_peak, gpu_used, gpu_peak])\n'"
fastai/callbacks/misc.py,0,"b'"" Miscellaneous callbacks ""\n\nfrom fastai.callback import Callback\n\nclass StopAfterNBatches(Callback):\n    ""Stop training after n batches of the first epoch.""\n    def __init__(self, n_batches:int=2):\n        self.stop,self.n_batches = False,n_batches-1 # iteration starts from 0\n\n    def on_batch_end(self, iteration, **kwargs):\n        if iteration == self.n_batches:\n            return {\'stop_epoch\': True, \'stop_training\': True, \'skip_validate\': True}\n'"
fastai/callbacks/mixup.py,2,"b'""Implements [mixup](https://arxiv.org/abs/1710.09412) training method""\nfrom ..torch_core import *\nfrom ..callback import *\nfrom ..basic_train import Learner, LearnerCallback\n\n__all__ = [""MixUpCallback"", ""MixUpLoss""]\n\nclass MixUpCallback(LearnerCallback):\n    ""Callback that creates the mixed-up input and target.""\n    def __init__(self, learn:Learner, alpha:float=0.4, stack_x:bool=False, stack_y:bool=True):\n        super().__init__(learn)\n        self.alpha,self.stack_x,self.stack_y = alpha,stack_x,stack_y\n    \n    def on_train_begin(self, **kwargs):\n        if self.stack_y: self.learn.loss_func = MixUpLoss(self.learn.loss_func)\n        \n    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n        ""Applies mixup to `last_input` and `last_target` if `train`.""\n        if not train: return\n        lambd = np.random.beta(self.alpha, self.alpha, last_target.size(0))\n        lambd = np.concatenate([lambd[:,None], 1-lambd[:,None]], 1).max(1)\n        lambd = last_input.new(lambd)\n        shuffle = torch.randperm(last_target.size(0)).to(last_input.device)\n        x1, y1 = last_input[shuffle], last_target[shuffle]\n        if self.stack_x:\n            new_input = [last_input, last_input[shuffle], lambd]\n        else: \n            out_shape = [lambd.size(0)] + [1 for _ in range(len(x1.shape) - 1)]\n            new_input = (last_input * lambd.view(out_shape) + x1 * (1-lambd).view(out_shape))\n        if self.stack_y:\n            new_target = torch.cat([last_target[:,None].float(), y1[:,None].float(), lambd[:,None].float()], 1)\n        else:\n            if len(last_target.shape) == 2:\n                lambd = lambd.unsqueeze(1).float()\n            new_target = last_target.float() * lambd + y1.float() * (1-lambd)\n        return {\'last_input\': new_input, \'last_target\': new_target}  \n    \n    def on_train_end(self, **kwargs):\n        if self.stack_y: self.learn.loss_func = self.learn.loss_func.get_old()\n        \n\nclass MixUpLoss(Module):\n    ""Adapt the loss function `crit` to go with mixup.""\n    \n    def __init__(self, crit, reduction=\'mean\'):\n        super().__init__()\n        if hasattr(crit, \'reduction\'): \n            self.crit = crit\n            self.old_red = crit.reduction\n            setattr(self.crit, \'reduction\', \'none\')\n        else: \n            self.crit = partial(crit, reduction=\'none\')\n            self.old_crit = crit\n        self.reduction = reduction\n        \n    def forward(self, output, target):\n        if len(target.size()) == 2:\n            loss1, loss2 = self.crit(output,target[:,0].long()), self.crit(output,target[:,1].long())\n            d = loss1 * target[:,2] + loss2 * (1-target[:,2])\n        else:  d = self.crit(output, target)\n        if self.reduction == \'mean\':    return d.mean()\n        elif self.reduction == \'sum\':   return d.sum()\n        return d\n    \n    def get_old(self):\n        if hasattr(self, \'old_crit\'):  return self.old_crit\n        elif hasattr(self, \'old_red\'): \n            setattr(self.crit, \'reduction\', self.old_red)\n            return self.crit\n'"
fastai/callbacks/mlflow.py,0,"b'""A `Callback` that saves tracked metrics and notebook file into MLflow server.""\nfrom ..torch_core import *\nfrom ..callback import *\nfrom ..basic_train import Learner, LearnerCallback\n#This is an optional dependency in fastai.  Must install separately.\ntry: import mlflow\nexcept: print(""To use this tracker, please run \'pip install mlflow\'"")\n\nclass MLFlowTracker(LearnerCallback):\n    ""A `TrackerCallback` that tracks the loss and metrics into MLFlow""\n    def __init__(self, learn:Learner, exp_name: str, params: dict, nb_path: str, uri: str = ""http://localhost:5000""):\n        super().__init__(learn)\n        self.learn,self.exp_name,self.params,self.nb_path,self.uri = learn,exp_name,params,nb_path,uri\n        self.metrics_names = [\'train_loss\', \'valid_loss\'] + [o.__name__ for o in learn.metrics]\n\n    def on_train_begin(self, **kwargs: Any) -> None:\n        ""Prepare MLflow experiment and log params""\n        self.client = mlflow.tracking.MlflowClient(self.uri)\n        exp = self.client.get_experiment_by_name(self.exp_name)\n        self.exp_id = self.client.create_experiment(self.exp_name) if exp is None else exp.experiment_id\n        run = self.client.create_run(experiment_id=self.exp_id)\n        self.run = run.info.run_uuid\n        for k,v in self.params.items():\n            self.client.log_param(run_id=self.run, key=k, value=v)\n\n    def on_epoch_end(self, epoch, **kwargs:Any)->None:\n        ""Send loss and metrics values to MLFlow after each epoch""\n        if kwargs[\'smooth_loss\'] is None or kwargs[""last_metrics""] is None: return\n        metrics = [kwargs[\'smooth_loss\']] + kwargs[""last_metrics""]\n        for name, val in zip(self.metrics_names, metrics):\n            self.client.log_metric(self.run, name, np.float(val), step=epoch)\n        \n    def on_train_end(self, **kwargs: Any) -> None:  \n        ""Store the notebook and stop run""\n        self.client.log_artifact(run_id=self.run, local_path=self.nb_path)\n        self.client.set_terminated(run_id=self.run)\n'"
fastai/callbacks/one_cycle.py,0,"b'""Supports 1-Cycle style training""\nfrom ..core import *\nfrom ..callback import *\nfrom ..basic_train import Learner,LearnerCallback\n\n__all__ = [\'OneCycleScheduler\']\n\nclass OneCycleScheduler(LearnerCallback):\n    ""Manage 1-Cycle style training as outlined in Leslie Smith\'s [paper](https://arxiv.org/pdf/1803.09820.pdf).""\n    def __init__(self, learn:Learner, lr_max:float, moms:Floats=(0.95,0.85), div_factor:float=25., pct_start:float=0.3,\n                 final_div:float=None, tot_epochs:int=None, start_epoch:int=None):\n        super().__init__(learn)\n        self.lr_max,self.div_factor,self.pct_start,self.final_div = lr_max,div_factor,pct_start,final_div\n        if self.final_div is None: self.final_div = div_factor*1e4\n        self.moms=tuple(listify(moms,2))\n        if is_listy(self.lr_max): self.lr_max = np.array(self.lr_max)\n        self.start_epoch, self.tot_epochs = start_epoch, tot_epochs\n\n    def steps(self, *steps_cfg:StartOptEnd):\n        ""Build anneal schedule for all of the parameters.""\n        return [Scheduler(step, n_iter, func=func)\n                for (step,(n_iter,func)) in zip(steps_cfg, self.phases)]\n\n    def on_train_begin(self, n_epochs:int, epoch:int, **kwargs:Any)->None:\n        ""Initialize our optimization params based on our annealing schedule.""\n        res = {\'epoch\':self.start_epoch} if self.start_epoch is not None else None\n        self.start_epoch = ifnone(self.start_epoch, epoch)\n        self.tot_epochs = ifnone(self.tot_epochs, n_epochs)\n        n = len(self.learn.data.train_dl) * self.tot_epochs\n        a1 = int(n * self.pct_start)\n        a2 = n-a1\n        self.phases = ((a1, annealing_cos), (a2, annealing_cos))\n        low_lr = self.lr_max/self.div_factor\n        self.lr_scheds = self.steps((low_lr, self.lr_max), (self.lr_max, self.lr_max/self.final_div))\n        self.mom_scheds = self.steps(self.moms, (self.moms[1], self.moms[0]))\n        self.opt = self.learn.opt\n        self.opt.lr,self.opt.mom = self.lr_scheds[0].start,self.mom_scheds[0].start\n        self.idx_s = 0\n        return res\n    \n    def jump_to_epoch(self, epoch:int)->None:\n        for _ in range(len(self.learn.data.train_dl) * epoch):\n            self.on_batch_end(True)\n\n    def on_batch_end(self, train, **kwargs:Any)->None:\n        ""Take one step forward on the annealing schedule for the optim params.""\n        if train:\n            if self.idx_s >= len(self.lr_scheds): return {\'stop_training\': True, \'stop_epoch\': True}\n            self.opt.lr = self.lr_scheds[self.idx_s].step()\n            self.opt.mom = self.mom_scheds[self.idx_s].step()\n            # when the current schedule is complete we move onto the next\n            # schedule. (in 1-cycle there are two schedules)\n            if self.lr_scheds[self.idx_s].is_done:\n                self.idx_s += 1\n\n    def on_epoch_end(self, epoch, **kwargs:Any)->None:\n        ""Tell Learner to stop if the cycle is finished.""\n        if epoch > self.tot_epochs: return {\'stop_training\': True}\n'"
fastai/callbacks/oversampling.py,3,"b'from ..torch_core import *\nfrom ..basic_data import DataBunch\nfrom ..callback import *\nfrom ..basic_train import Learner,LearnerCallback\nfrom torch.utils.data.sampler import WeightedRandomSampler\n\n__all__ = [\'OverSamplingCallback\']\n\nclass OverSamplingCallback(LearnerCallback):\n    def __init__(self,learn:Learner,weights:torch.Tensor=None):\n        super().__init__(learn)\n        self.weights = weights\n\n    def on_train_begin(self, **kwargs):\n        self.old_dl = self.data.train_dl\n        self.labels = self.data.train_dl.y.items\n        assert np.issubdtype(self.labels.dtype, np.integer), ""Can only oversample integer values""\n        _,self.label_counts = np.unique(self.labels,return_counts=True)\n        if self.weights is None: self.weights = torch.DoubleTensor((1/self.label_counts)[self.labels])\n        self.total_len_oversample = int(self.data.c*np.max(self.label_counts))\n        sampler = WeightedRandomSampler(self.weights, self.total_len_oversample)\n        self.data.train_dl = self.data.train_dl.new(shuffle=False, sampler=sampler)\n\n    def on_train_end(self, **kwargs):\n        ""Reset dataloader to its original state""\n        self.data.train_dl = self.old_dl\n'"
fastai/callbacks/rnn.py,0,"b'""Regroups lr adjustment to seq_len, AR and TAR""\nfrom ..torch_core import *\nfrom ..callback import *\nfrom ..basic_train import Learner, LearnerCallback\n\n__all__ = [\'RNNTrainer\']\n\nclass RNNTrainer(LearnerCallback):\n    ""`Callback` that regroups lr adjustment to seq_len, AR and TAR.""\n    def __init__(self, learn:Learner, alpha:float=0., beta:float=0.):\n        super().__init__(learn)\n        self.not_min += [\'raw_out\', \'out\']\n        self.alpha,self.beta = alpha,beta\n        \n    def on_epoch_begin(self, **kwargs):\n        ""Reset the hidden state of the model.""\n        self.learn.model.reset()\n\n    def on_loss_begin(self, last_output:Tuple[Tensor,Sequence[Tensor],Sequence[Tensor]], **kwargs):\n        ""Save the extra outputs for later and only returns the true output.""\n        self.raw_out,self.out = last_output[1],last_output[2]\n        return {\'last_output\': last_output[0]}\n\n    def on_backward_begin(self, last_loss:Rank0Tensor, last_input:Tensor, **kwargs):\n        ""Apply AR and TAR to `last_loss`.""\n        #AR and TAR\n        if self.alpha != 0.:  last_loss += self.alpha * self.out[-1].float().pow(2).mean()\n        if self.beta != 0.:\n            h = self.raw_out[-1]\n            if len(h)>1: last_loss += self.beta * (h[:,1:] - h[:,:-1]).float().pow(2).mean()\n        return {\'last_loss\': last_loss}\n'"
fastai/callbacks/tensorboard.py,2,"b'""Provides convenient callbacks for Learners that write model images, metrics/losses, stats and histograms to Tensorboard""\nfrom ..basic_train import Learner\nfrom ..basic_data import DatasetType, DataBunch\nfrom ..vision import Image\nfrom ..vision.gan import GANLearner\nfrom ..basic_train import LearnerCallback\nfrom ..core import *\nfrom ..torch_core import *\nfrom threading import Thread, Event\nfrom time import sleep\nfrom queue import Queue\nimport statistics\nimport torchvision.utils as vutils\nfrom abc import ABC\n#This is an optional dependency in fastai.  Must install separately.\ntry: from tensorboardX import SummaryWriter\nexcept: print(""To use this tracker, please run \'pip install tensorboardx\'. Also you must have Tensorboard running to see results"")\n\n__all__=[\'LearnerTensorboardWriter\', \'GANTensorboardWriter\', \'ImageGenTensorboardWriter\']\n\n#---Example usage (applies to any of the callbacks)--- \n# proj_id = \'Colorize\'\n# tboard_path = Path(\'data/tensorboard/\' + proj_id)\n# learn.callback_fns.append(partial(GANTensorboardWriter, base_dir=tboard_path, name=\'GanLearner\'))\n\nclass LearnerTensorboardWriter(LearnerCallback):\n    ""Broadly useful callback for Learners that writes to Tensorboard.  Writes model histograms, losses/metrics, and gradient stats.""\n    def __init__(self, learn:Learner, base_dir:Path, name:str, loss_iters:int=25, hist_iters:int=500, stats_iters:int=100):\n        super().__init__(learn=learn)\n        self.base_dir,self.name,self.loss_iters,self.hist_iters,self.stats_iters  = base_dir,name,loss_iters,hist_iters,stats_iters\n        log_dir = base_dir/name\n        self.tbwriter = SummaryWriter(str(log_dir))\n        self.hist_writer = HistogramTBWriter()\n        self.stats_writer = ModelStatsTBWriter()\n        self.graph_writer = GraphTBWriter()\n        self.data = None\n        self.metrics_root = \'/metrics/\'\n        self._update_batches_if_needed()\n\n    def _get_new_batch(self, ds_type:DatasetType)->Collection[Tensor]:\n        ""Retrieves new batch of DatasetType, and detaches it.""\n        return self.learn.data.one_batch(ds_type=ds_type, detach=True, denorm=False, cpu=False)\n\n    def _update_batches_if_needed(self)->None:\n        ""one_batch function is extremely slow with large datasets.  This is caching the result as an optimization.""\n        if self.learn.data.valid_dl is None: return # Running learning rate finder, so return\n        update_batches = self.data is not self.learn.data\n        if not update_batches: return\n        self.data = self.learn.data\n        self.trn_batch = self._get_new_batch(ds_type=DatasetType.Train)\n        self.val_batch = self._get_new_batch(ds_type=DatasetType.Valid)\n\n    def _write_model_stats(self, iteration:int)->None:\n        ""Writes gradient statistics to Tensorboard.""\n        self.stats_writer.write(model=self.learn.model, iteration=iteration, tbwriter=self.tbwriter)\n\n    def _write_training_loss(self, iteration:int, last_loss:Tensor)->None:\n        ""Writes training loss to Tensorboard.""\n        scalar_value = to_np(last_loss)\n        tag = self.metrics_root + \'train_loss\'\n        self.tbwriter.add_scalar(tag=tag, scalar_value=scalar_value, global_step=iteration)\n\n    def _write_weight_histograms(self, iteration:int)->None:\n        ""Writes model weight histograms to Tensorboard.""\n        self.hist_writer.write(model=self.learn.model, iteration=iteration, tbwriter=self.tbwriter)\n\n    def _write_scalar(self, name:str, scalar_value, iteration:int)->None:\n        ""Writes single scalar value to Tensorboard.""\n        tag = self.metrics_root + name\n        self.tbwriter.add_scalar(tag=tag, scalar_value=scalar_value, global_step=iteration)\n\n    #TODO:  Relying on a specific hardcoded start_idx here isn\'t great.  Is there a better solution?\n    def _write_metrics(self, iteration:int, last_metrics:MetricsList, start_idx:int=2)->None:\n        ""Writes training metrics to Tensorboard.""\n        recorder = self.learn.recorder\n        for i, name in enumerate(recorder.names[start_idx:]):\n            if last_metrics is None or len(last_metrics) < i+1: return\n            scalar_value = last_metrics[i]\n            self._write_scalar(name=name, scalar_value=scalar_value, iteration=iteration)\n\n    def _write_embedding(self, iteration:int)->None:\n        ""Writes embedding to Tensorboard.""\n        for name, emb in self.learn.model.named_children():\n            if isinstance(emb, nn.Embedding):\n                self.tbwriter.add_embedding(list(emb.parameters())[0], global_step=iteration, tag=name)\n\n    def on_train_begin(self, **kwargs: Any) -> None:\n        self.graph_writer.write(model=self.learn.model, tbwriter=self.tbwriter,\n                                input_to_model=next(iter(self.learn.data.dl(DatasetType.Single)))[0])\n\n    def on_batch_end(self, last_loss:Tensor, iteration:int, train:bool, **kwargs)->None:\n        ""Callback function that writes batch end appropriate data to Tensorboard.""\n        if iteration == 0 or not train: return\n        self._update_batches_if_needed()\n        if iteration % self.loss_iters == 0: self._write_training_loss(iteration=iteration, last_loss=last_loss)\n        if iteration % self.hist_iters == 0: self._write_weight_histograms(iteration=iteration)\n\n    # Doing stuff here that requires gradient info, because they get zeroed out afterwards in training loop\n    def on_backward_end(self, iteration:int, train:bool, **kwargs)->None:\n        ""Callback function that writes backward end appropriate data to Tensorboard.""\n        if iteration == 0 and not train: return\n        self._update_batches_if_needed()\n        if iteration % self.stats_iters == 0: self._write_model_stats(iteration=iteration)\n\n    def on_epoch_end(self, last_metrics:MetricsList, iteration:int, **kwargs)->None:\n        ""Callback function that writes epoch end appropriate data to Tensorboard.""\n        self._write_metrics(iteration=iteration, last_metrics=last_metrics)\n        self._write_embedding(iteration=iteration)\n\n# TODO:  We\'re overriding almost everything here.  Seems like a good idea to question that (""is a"" vs ""has a"")\nclass GANTensorboardWriter(LearnerTensorboardWriter):\n    ""Callback for GANLearners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.""\n    def __init__(self, learn:GANLearner, base_dir:Path, name:str, loss_iters:int=25, hist_iters:int=500, \n                stats_iters:int=100, visual_iters:int=100):\n        super().__init__(learn=learn, base_dir=base_dir, name=name, loss_iters=loss_iters, hist_iters=hist_iters, stats_iters=stats_iters)\n        self.visual_iters = visual_iters\n        self.img_gen_vis = ImageTBWriter()\n        self.gen_stats_updated = True\n        self.crit_stats_updated = True\n\n    def _write_weight_histograms(self, iteration:int)->None:\n        ""Writes model weight histograms to Tensorboard.""\n        generator, critic = self.learn.gan_trainer.generator, self.learn.gan_trainer.critic\n        self.hist_writer.write(model=generator, iteration=iteration, tbwriter=self.tbwriter, name=\'generator\')\n        self.hist_writer.write(model=critic,    iteration=iteration, tbwriter=self.tbwriter, name=\'critic\')\n\n    def _write_gen_model_stats(self, iteration:int)->None:\n        ""Writes gradient statistics for generator to Tensorboard.""\n        generator = self.learn.gan_trainer.generator\n        self.stats_writer.write(model=generator, iteration=iteration, tbwriter=self.tbwriter, name=\'gen_model_stats\')\n        self.gen_stats_updated = True\n\n    def _write_critic_model_stats(self, iteration:int)->None:\n        ""Writes gradient statistics for critic to Tensorboard.""\n        critic = self.learn.gan_trainer.critic\n        self.stats_writer.write(model=critic, iteration=iteration, tbwriter=self.tbwriter, name=\'crit_model_stats\')\n        self.crit_stats_updated = True\n\n    def _write_model_stats(self, iteration:int)->None:\n        ""Writes gradient statistics to Tensorboard.""\n        # We don\'t want to write stats when model is not iterated on and hence has zeroed out gradients\n        gen_mode = self.learn.gan_trainer.gen_mode\n        if gen_mode and not self.gen_stats_updated: self._write_gen_model_stats(iteration=iteration)\n        if not gen_mode and not self.crit_stats_updated: self._write_critic_model_stats(iteration=iteration)\n\n    def _write_training_loss(self, iteration:int, last_loss:Tensor)->None:\n        ""Writes training loss to Tensorboard.""\n        recorder = self.learn.gan_trainer.recorder\n        if len(recorder.losses) == 0: return\n        scalar_value = to_np((recorder.losses[-1:])[0])\n        tag = self.metrics_root + \'train_loss\'\n        self.tbwriter.add_scalar(tag=tag, scalar_value=scalar_value, global_step=iteration)\n\n    def _write_images(self, iteration:int)->None:\n        ""Writes model generated, original and real images to Tensorboard.""\n        trainer = self.learn.gan_trainer\n        #TODO:  Switching gen_mode temporarily seems a bit hacky here.  Certainly not a good side-effect.  Is there a better way?\n        gen_mode = trainer.gen_mode\n        try:\n            trainer.switch(gen_mode=True)\n            self.img_gen_vis.write(learn=self.learn, trn_batch=self.trn_batch, val_batch=self.val_batch, \n                                    iteration=iteration, tbwriter=self.tbwriter)\n        finally: trainer.switch(gen_mode=gen_mode)\n\n    def on_batch_end(self, iteration:int, train:bool, **kwargs)->None:\n        ""Callback function that writes batch end appropriate data to Tensorboard.""\n        super().on_batch_end(iteration=iteration, train=train, **kwargs)\n        if iteration == 0 and not train: return\n        if iteration % self.visual_iters == 0: self._write_images(iteration=iteration)\n\n    def on_backward_end(self, iteration:int, train:bool, **kwargs)->None:\n        ""Callback function that writes backward end appropriate data to Tensorboard.""\n        if iteration == 0 and not train: return\n        self._update_batches_if_needed()\n        #TODO:  This could perhaps be implemented as queues of requests instead but that seemed like overkill. \n        # But I\'m not the biggest fan of maintaining these boolean flags either... Review pls.\n        if iteration % self.stats_iters == 0: self.gen_stats_updated, self.crit_stats_updated = False, False\n        if not (self.gen_stats_updated and self.crit_stats_updated): self._write_model_stats(iteration=iteration)\n\nclass ImageGenTensorboardWriter(LearnerTensorboardWriter):\n    ""Callback for non-GAN image generating Learners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.""\n    def __init__(self, learn:Learner, base_dir:Path, name:str, loss_iters:int=25, hist_iters:int=500, stats_iters:int=100, \n                 visual_iters:int=100):\n        super().__init__(learn=learn, base_dir=base_dir, name=name, loss_iters=loss_iters, hist_iters=hist_iters, \n                         stats_iters=stats_iters)\n        self.visual_iters = visual_iters\n        self.img_gen_vis = ImageTBWriter()\n\n    def _write_images(self, iteration:int)->None:\n        ""Writes model generated, original and real images to Tensorboard""\n        self.img_gen_vis.write(learn=self.learn, trn_batch=self.trn_batch, val_batch=self.val_batch, iteration=iteration, \n                               tbwriter=self.tbwriter)\n\n    def on_batch_end(self, iteration:int, train:bool, **kwargs)->None:\n        ""Callback function that writes batch end appropriate data to Tensorboard.""\n        super().on_batch_end(iteration=iteration, train=train, **kwargs)\n        if iteration == 0 and not train: return\n        if iteration % self.visual_iters == 0: self._write_images(iteration=iteration)\n\nclass TBWriteRequest(ABC):\n    ""A request object for Tensorboard writes.  Useful for queuing up and executing asynchronous writes.""\n    def __init__(self, tbwriter: SummaryWriter, iteration:int):\n        super().__init__()\n        self.tbwriter = tbwriter\n        self.iteration = iteration\n\n    @abstractmethod\n    def write(self)->None: pass   \n\n# SummaryWriter writes tend to block quite a bit.  This gets around that and greatly boosts performance.\n# Not all tensorboard writes are using this- just the ones that take a long time.  Note that the \n# SummaryWriter does actually use a threadsafe consumer/producer design ultimately to write to Tensorboard, \n# so writes done outside of this async loop should be fine.\nclass AsyncTBWriter():\n    ""Callback for GANLearners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.""\n    def __init__(self):\n        super().__init__()\n        self.stop_request = Event()\n        self.queue = Queue()\n        self.thread = Thread(target=self._queue_processor, daemon=True)\n        self.thread.start()\n\n    def request_write(self, request: TBWriteRequest)->None:\n        ""Queues up an asynchronous write request to Tensorboard.""\n        if self.stop_request.isSet(): return\n        self.queue.put(request)\n\n    def _queue_processor(self)->None:\n        ""Processes queued up write requests asynchronously to Tensorboard.""\n        while not self.stop_request.isSet():\n            while not self.queue.empty():\n                if self.stop_request.isSet(): return\n                request = self.queue.get()\n                request.write()\n            sleep(0.2)\n\n    #Provided this to stop thread explicitly or by context management (with statement) but thread should end on its own \n    # upon program exit, due to being a daemon.  So using this is probably unecessary.\n    def close(self)->None:\n        ""Stops asynchronous request queue processing thread.""\n        self.stop_request.set()\n        self.thread.join()\n\n    # Nothing to do, thread already started.  Could start thread here to enforce use of context manager \n    # (but that sounds like a pain and a bit unweildy and unecessary for actual usage)\n    def __enter__(self): pass\n\n    def __exit__(self, exc_type, exc_value, traceback): self.close()\n\nasyncTBWriter = AsyncTBWriter() \n\nclass ModelImageSet():\n    ""Convenience object that holds the original, real(target) and generated versions of a single image fed to a model.""\n    @staticmethod\n    def get_list_from_model(learn:Learner, ds_type:DatasetType, batch:Tuple)->[]:\n        ""Factory method to convert a batch of model images to a list of ModelImageSet.""\n        image_sets = []\n        x,y = batch[0],batch[1]\n        preds = learn.pred_batch(ds_type=ds_type, batch=(x,y), reconstruct=True)  \n        for orig_px, real_px, gen in zip(x,y,preds):\n            orig, real = Image(px=orig_px), Image(px=real_px)\n            image_set = ModelImageSet(orig=orig, real=real, gen=gen)\n            image_sets.append(image_set)\n        return image_sets  \n\n    def __init__(self, orig:Image, real:Image, gen:Image): self.orig, self.real, self.gen = orig, real, gen\n\nclass HistogramTBRequest(TBWriteRequest):\n    ""Request object for model histogram writes to Tensorboard.""\n    def __init__(self, model:nn.Module, iteration:int, tbwriter:SummaryWriter, name:str):\n        super().__init__(tbwriter=tbwriter, iteration=iteration)\n        self.params = [(name, values.clone().detach().cpu()) for (name, values) in model.named_parameters()]\n        self.name = name\n\n    def _write_histogram(self, param_name:str, values)->None:\n        ""Writes single model histogram to Tensorboard.""\n        tag = self.name + \'/weights/\' + param_name\n        self.tbwriter.add_histogram(tag=tag, values=values, global_step=self.iteration)\n\n    def write(self)->None:\n        ""Writes model histograms to Tensorboard.""\n        for param_name, values in self.params: self._write_histogram(param_name=param_name, values=values)\n\n#If this isn\'t done async then this is sloooooow\nclass HistogramTBWriter():\n    ""Writes model histograms to Tensorboard.""\n    def __init__(self): super().__init__()\n\n    def write(self, model:nn.Module, iteration:int, tbwriter:SummaryWriter, name:str=\'model\')->None:\n        ""Writes model histograms to Tensorboard.""\n        request = HistogramTBRequest(model=model, iteration=iteration, tbwriter=tbwriter, name=name)\n        asyncTBWriter.request_write(request)\n\nclass ModelStatsTBRequest(TBWriteRequest):\n    ""Request object for model gradient statistics writes to Tensorboard.""\n    def __init__(self, model:nn.Module, iteration:int, tbwriter:SummaryWriter, name:str):\n        super().__init__(tbwriter=tbwriter, iteration=iteration)\n        self.gradients = [x.grad.clone().detach().cpu() for x in model.parameters() if x.grad is not None]\n        self.name = name\n\n    def _add_gradient_scalar(self, name:str, scalar_value)->None:\n        ""Writes a single scalar value for a gradient statistic to Tensorboard.""\n        tag = self.name + \'/gradients/\' + name\n        self.tbwriter.add_scalar(tag=tag, scalar_value=scalar_value, global_step=self.iteration)\n\n    def _write_avg_norm(self, norms:[])->None:\n        ""Writes the average norm of the gradients to Tensorboard.""\n        avg_norm = sum(norms)/len(self.gradients)\n        self._add_gradient_scalar(\'avg_norm\', scalar_value=avg_norm)\n\n    def _write_median_norm(self, norms:[])->None:\n        ""Writes the median norm of the gradients to Tensorboard.""\n        median_norm = statistics.median(norms)\n        self._add_gradient_scalar(\'median_norm\', scalar_value=median_norm)\n\n    def _write_max_norm(self, norms:[])->None:\n        ""Writes the maximum norm of the gradients to Tensorboard.""\n        max_norm = max(norms)\n        self._add_gradient_scalar(\'max_norm\', scalar_value=max_norm)\n\n    def _write_min_norm(self, norms:[])->None:\n        ""Writes the minimum norm of the gradients to Tensorboard.""\n        min_norm = min(norms)\n        self._add_gradient_scalar(\'min_norm\', scalar_value=min_norm)\n\n    def _write_num_zeros(self)->None:\n        ""Writes the number of zeroes in the gradients to Tensorboard.""\n        gradient_nps = [to_np(x.data) for x in self.gradients]\n        num_zeros = sum((np.asarray(x) == 0.0).sum() for x in gradient_nps)\n        self._add_gradient_scalar(\'num_zeros\', scalar_value=num_zeros)\n\n    def _write_avg_gradient(self)->None:\n        ""Writes the average of the gradients to Tensorboard.""\n        avg_gradient = sum(x.data.mean() for x in self.gradients)/len(self.gradients)\n        self._add_gradient_scalar(\'avg_gradient\', scalar_value=avg_gradient)\n\n    def _write_median_gradient(self)->None:\n        ""Writes the median of the gradients to Tensorboard.""\n        median_gradient = statistics.median(x.data.median() for x in self.gradients)\n        self._add_gradient_scalar(\'median_gradient\', scalar_value=median_gradient)\n\n    def _write_max_gradient(self)->None:\n        ""Writes the maximum of the gradients to Tensorboard.""\n        max_gradient = max(x.data.max() for x in self.gradients)\n        self._add_gradient_scalar(\'max_gradient\', scalar_value=max_gradient)\n\n    def _write_min_gradient(self)->None:\n        ""Writes the minimum of the gradients to Tensorboard.""\n        min_gradient = min(x.data.min() for x in self.gradients)\n        self._add_gradient_scalar(\'min_gradient\', scalar_value=min_gradient)\n\n    def write(self)->None:\n        ""Writes model gradient statistics to Tensorboard.""\n        if len(self.gradients) == 0: return\n        norms = [x.data.norm() for x in self.gradients]\n        self._write_avg_norm(norms=norms)\n        self._write_median_norm(norms=norms)\n        self._write_max_norm(norms=norms)\n        self._write_min_norm(norms=norms)\n        self._write_num_zeros()\n        self._write_avg_gradient()\n        self._write_median_gradient()\n        self._write_max_gradient()\n        self._write_min_gradient()\n\nclass ModelStatsTBWriter():\n    ""Writes model gradient statistics to Tensorboard.""\n    def write(self, model:nn.Module, iteration:int, tbwriter:SummaryWriter, name:str=\'model_stats\')->None:\n        ""Writes model gradient statistics to Tensorboard.""\n        request = ModelStatsTBRequest(model=model, iteration=iteration, tbwriter=tbwriter, name=name)\n        asyncTBWriter.request_write(request)\n\nclass ImageTBRequest(TBWriteRequest):\n    ""Request object for model image output writes to Tensorboard.""\n    def __init__(self, learn:Learner, batch:Tuple, iteration:int, tbwriter:SummaryWriter, ds_type:DatasetType):\n        super().__init__(tbwriter=tbwriter, iteration=iteration)\n        self.image_sets = ModelImageSet.get_list_from_model(learn=learn, batch=batch, ds_type=ds_type)\n        self.ds_type = ds_type\n\n    def _write_images(self, name:str, images:[Tensor])->None:\n        ""Writes list of images as tensors to Tensorboard.""\n        tag = self.ds_type.name + \' \' + name\n        self.tbwriter.add_image(tag=tag, img_tensor=vutils.make_grid(images, normalize=True), global_step=self.iteration)\n\n    def _get_image_tensors(self)->([Tensor], [Tensor], [Tensor]):\n        ""Gets list of image tensors from lists of Image objects, as a tuple of original, generated and real(target) images.""\n        orig_images, gen_images, real_images = [], [], []\n        for image_set in self.image_sets:\n            orig_images.append(image_set.orig.px)\n            gen_images.append(image_set.gen.px)\n            real_images.append(image_set.real.px) \n        return orig_images, gen_images, real_images  \n\n    def write(self)->None:\n        ""Writes original, generated and real(target) images to Tensorboard.""\n        orig_images, gen_images, real_images = self._get_image_tensors()\n        self._write_images(name=\'orig images\', images=orig_images)\n        self._write_images(name=\'gen images\',  images=gen_images)\n        self._write_images(name=\'real images\', images=real_images)\n\n#If this isn\'t done async then this is noticeably slower\nclass ImageTBWriter():\n    ""Writes model image output to Tensorboard.""\n    def __init__(self): super().__init__()\n\n    def write(self, learn:Learner, trn_batch:Tuple, val_batch:Tuple, iteration:int, tbwriter:SummaryWriter)->None:\n        ""Writes training and validation batch images to Tensorboard.""\n        self._write_for_dstype(learn=learn, batch=val_batch, iteration=iteration, tbwriter=tbwriter, ds_type=DatasetType.Valid)\n        self._write_for_dstype(learn=learn, batch=trn_batch, iteration=iteration, tbwriter=tbwriter, ds_type=DatasetType.Train)\n\n    def _write_for_dstype(self, learn:Learner, batch:Tuple, iteration:int, tbwriter:SummaryWriter, ds_type:DatasetType)->None:\n        ""Writes batch images of specified DatasetType to Tensorboard.""\n        request = ImageTBRequest(learn=learn, batch=batch, iteration=iteration, tbwriter=tbwriter, ds_type=ds_type)\n        asyncTBWriter.request_write(request)\n\nclass GraphTBRequest(TBWriteRequest):\n    ""Request object for model histogram writes to Tensorboard.""\n    def __init__(self, model:nn.Module, tbwriter:SummaryWriter, input_to_model:torch.Tensor):\n        super().__init__(tbwriter=tbwriter, iteration=0)\n        self.model,self.input_to_model = model,input_to_model\n\n    def write(self)->None:\n        ""Writes single model graph to Tensorboard.""\n        self.tbwriter.add_graph(model=self.model, input_to_model=self.input_to_model)\n\nclass GraphTBWriter():\n    ""Writes model network graph to Tensorboard.""\n    def write(self, model:nn.Module, tbwriter:SummaryWriter, input_to_model:torch.Tensor)->None:\n        ""Writes model graph to Tensorboard.""\n        request = GraphTBRequest(model=model, tbwriter=tbwriter, input_to_model=input_to_model)\n        asyncTBWriter.request_write(request)\n'"
fastai/callbacks/tracker.py,1,"b'# Contribution from @fredguth, https://github.com/fredguth/fastai_playground.\n\nfrom ..torch_core import *\nfrom ..callback import *\nfrom ..basic_train import *\n\n__all__ = [\'TerminateOnNaNCallback\', \'EarlyStoppingCallback\', \'SaveModelCallback\', \'TrackerCallback\',\n        \'ReduceLROnPlateauCallback\', \'TrackEpochCallback\' ]\n\nclass TerminateOnNaNCallback(Callback):\n    ""A `Callback` that terminates training if loss is NaN.""\n\n    def __init__(self):\n        self.stop = False\n\n    def on_batch_end(self, last_loss, epoch, num_batch, **kwargs:Any)->None:\n        ""Test if `last_loss` is NaN and interrupts training.""\n        if self.stop: return True #to skip validation after stopping during training\n        if torch.isnan(last_loss):\n            print (f\'Epoch/Batch ({epoch}/{num_batch}): Invalid loss, terminating training.\')\n            return {\'stop_epoch\': True, \'stop_training\': True, \'skip_validate\': True}\n\nclass TrackerCallback(LearnerCallback):\n    ""A `LearnerCallback` that keeps track of the best value in `monitor`.""\n    def __init__(self, learn:Learner, monitor:str=\'valid_loss\', mode:str=\'auto\'):\n        super().__init__(learn)\n        self.monitor,self.mode = monitor,mode\n        if self.mode not in [\'auto\', \'min\', \'max\']:\n            warn(f\'{self.__class__} mode {self.mode} is invalid, falling back to ""auto"" mode.\')\n            self.mode = \'auto\'\n        mode_dict = {\'min\': np.less, \'max\':np.greater}\n        mode_dict[\'auto\'] = np.less if \'loss\' in self.monitor or \'error\' in self.monitor else np.greater\n        self.operator = mode_dict[self.mode]\n\n    def on_train_begin(self, **kwargs:Any)->None:\n        ""Initializes the best value.""\n        self.best = float(\'inf\') if self.operator == np.less else -float(\'inf\')\n\n    def get_monitor_value(self):\n        ""Pick the monitored value.""\n        if self.monitor==\'trn_loss\' and len(self.learn.recorder.losses) == 0: return None\n        elif len(self.learn.recorder.val_losses) == 0: return None\n        values = {\'train_loss\':self.learn.recorder.losses[-1].cpu().numpy(),\n                  \'valid_loss\':self.learn.recorder.val_losses[-1]}\n        if values[\'valid_loss\'] is None: return\n        if self.learn.recorder.metrics:\n            for m, n in zip(self.learn.recorder.metrics[-1],self.learn.recorder.names[3:-1]):\n                values[n] = m\n        if values.get(self.monitor) is None:\n            warn(f\'{self.__class__} conditioned on metric `{self.monitor}` which is not available. Available metrics are: {"", "".join(map(str, self.learn.recorder.names[1:-1]))}\')\n        return values.get(self.monitor)\n\nclass EarlyStoppingCallback(TrackerCallback):\n    ""A `TrackerCallback` that terminates training when monitored quantity stops improving.""\n    def __init__(self, learn:Learner, monitor:str=\'valid_loss\', mode:str=\'auto\', min_delta:int=0, patience:int=0):\n        super().__init__(learn, monitor=monitor, mode=mode)\n        self.min_delta,self.patience = min_delta,patience\n        if self.operator == np.less:  self.min_delta *= -1\n\n    def on_train_begin(self, **kwargs:Any)->None:\n        ""Initialize inner arguments.""\n        self.wait = 0\n        super().on_train_begin(**kwargs)\n\n    def on_epoch_end(self, epoch, **kwargs:Any)->None:\n        ""Compare the value monitored to its best score and maybe stop training.""\n        current = self.get_monitor_value()\n        if current is None: return\n        if self.operator(current - self.min_delta, self.best):\n            self.best,self.wait = current,0\n        else:\n            self.wait += 1\n            if self.wait > self.patience:\n                print(f\'Epoch {epoch}: early stopping\')\n                return {""stop_training"":True}\n\nclass SaveModelCallback(TrackerCallback):\n    ""A `TrackerCallback` that saves the model when monitored quantity is best.""\n    def __init__(self, learn:Learner, monitor:str=\'valid_loss\', mode:str=\'auto\', every:str=\'improvement\', name:str=\'bestmodel\'):\n        super().__init__(learn, monitor=monitor, mode=mode)\n        self.every,self.name = every,name\n        if self.every not in [\'improvement\', \'epoch\']:\n            warn(f\'SaveModel every {self.every} is invalid, falling back to ""improvement"".\')\n            self.every = \'improvement\'\n\n    def jump_to_epoch(self, epoch:int)->None:\n        try:\n            self.learn.load(f\'{self.name}_{epoch-1}\', purge=False)\n            print(f""Loaded {self.name}_{epoch-1}"")\n        except: print(f\'Model {self.name}_{epoch-1} not found.\')\n\n    def on_epoch_end(self, epoch:int, **kwargs:Any)->None:\n        ""Compare the value monitored to its best score and maybe save the model.""\n        if self.every==""epoch"": self.learn.save(f\'{self.name}_{epoch}\')\n        else: #every=""improvement""\n            current = self.get_monitor_value()\n            if isinstance(current, Tensor): current = current.cpu()\n            if current is not None and self.operator(current, self.best):\n                print(f\'Better model found at epoch {epoch} with {self.monitor} value: {current}.\')\n                self.best = current\n                self.learn.save(f\'{self.name}\')\n\n    def on_train_end(self, **kwargs):\n        ""Load the best model.""\n        if self.every==""improvement"" and os.path.isfile(self.path/self.model_dir/f\'{self.name}.pth\'):\n            self.learn.load(f\'{self.name}\', purge=False)\n\nclass ReduceLROnPlateauCallback(TrackerCallback):\n    ""A `TrackerCallback` that reduces learning rate when a metric has stopped improving.""\n    def __init__(self, learn:Learner, monitor:str=\'valid_loss\', mode:str=\'auto\', patience:int=0, factor:float=0.2,\n                 min_delta:int=0, min_lr:float=0.001):\n        super().__init__(learn, monitor=monitor, mode=mode)\n        self.patience,self.factor,self.min_delta,self.min_lr = patience,factor,min_delta,min_lr\n        if self.operator == np.less:  self.min_delta *= -1\n\n    def on_train_begin(self, **kwargs:Any)->None:\n        ""Initialize inner arguments.""\n        self.wait, self.opt = 0, self.learn.opt\n        super().on_train_begin(**kwargs)\n\n    def on_epoch_end(self, epoch, **kwargs:Any)->None:\n        ""Compare the value monitored to its best and maybe reduce lr.""\n        current = self.get_monitor_value()\n        if current is None: return\n        if self.operator(current - self.min_delta, self.best): self.best,self.wait = current,0\n        else:\n            self.wait += 1\n            if self.wait > self.patience and self.opt.lr > self.min_lr:\n                self.opt.lr *= self.factor\n                self.wait = 0\n                print(f\'Epoch {epoch}: reducing lr to {self.opt.lr}\')\n\n\nclass TrackEpochCallback(LearnerCallback):\n    _order = -20 #Need to run before fit_one_cycle\n    def __init__(self, learn:Learner, name:str=\'epoch\', epoch_offset:int=None):\n        ""Store completed epoch number in `learn.model_dir/name`.""\n        super().__init__(learn)\n        learn._test_writeable_path()\n        self.path = learn.path/learn.model_dir/name\n        if epoch_offset is None:\n            if os.path.isfile(self.path):\n                 with self.path.open(\'r\') as f:\n                     try:    self.start_epoch = int(f.read())+1\n                     except: self.start_epoch = 0\n            else: self.start_epoch = 0\n\n    def on_train_begin(self, **kwargs:Any):\n        return {\'epoch\': self.start_epoch}\n\n    def on_epoch_end(self, epoch, **kwargs:Any)->None:\n        with self.path.open(\'w\') as f: f.write(f\'{epoch}\')\n\n    def restart(self): os.remove(self.path)\n'"
fastai/callbacks/undersampling.py,3,"b'from ..torch_core import *\nfrom ..basic_data import DataBunch\nfrom ..callback import *\nfrom ..basic_train import Learner,LearnerCallback\nfrom torch.utils.data.sampler import WeightedRandomSampler\n\n__all__ = [\'UnderSamplingCallback\']\n\nclass UnderSamplingCallback(LearnerCallback):\n    def __init__(self,learn:Learner,weights:torch.Tensor=None):\n        super().__init__(learn)\n        self.weights = weights\n\n    def on_train_begin(self, **kwargs):\n        self.old_dl = self.data.train_dl\n        self.labels = self.data.train_dl.y.items\n        assert np.issubdtype(self.labels.dtype, np.integer), ""Can only undersample integer values""\n        _,self.label_counts = np.unique(self.labels,return_counts=True)\n        if self.weights is None: self.weights = torch.DoubleTensor((1/self.label_counts)[self.labels])\n        self.total_len_undersample = int(self.data.c*np.min(self.label_counts))\n        sampler = WeightedRandomSampler(self.weights, self.total_len_undersample)\n        self.data.train_dl = self.data.train_dl.new(shuffle=False, sampler=sampler)\n    \n    def on_train_end(self, **kwargs):\n        ""Reset dataloader to its original state""\n        self.data.train_dl = self.old_dl\n'"
fastai/gen_doc/__init__.py,0,"b'from . import gen_notebooks, nbdoc, core, doctest, nbtest\n'"
fastai/gen_doc/convert2html.py,0,"b'import os.path, re, nbformat, jupyter_contrib_nbextensions\nfrom nbconvert.preprocessors import Preprocessor\nfrom nbconvert import HTMLExporter\nfrom traitlets.config import Config\nfrom pathlib import Path\n\n__all__ = [\'read_nb\', \'convert_nb\', \'convert_all\']\n\nexporter = HTMLExporter(Config())\nexporter.exclude_input_prompt=True\nexporter.exclude_output_prompt=True\n#Loads the template to deal with hidden cells.\nexporter.template_file = \'jekyll.tpl\'\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\n\ndef read_nb(fname):\n    ""Read the notebook in `fname`.""\n    with open(fname,\'r\') as f: return nbformat.reads(f.read(), as_version=4)\n\ndef convert_nb(fname, dest_path=\'.\'):\n    ""Convert a notebook `fname` to html file in `dest_path`.""\n    from .gen_notebooks import remove_undoc_cells, remove_code_cell_jupyter_widget_state_elem\n    nb = read_nb(fname)\n    nb[\'cells\'] = remove_undoc_cells(nb[\'cells\'])\n    nb[\'cells\'] = remove_code_cell_jupyter_widget_state_elem(nb[\'cells\'])\n    fname = Path(fname).absolute()\n    dest_name = fname.with_suffix(\'.html\').name\n    meta = nb[\'metadata\']\n    meta_jekyll = meta[\'jekyll\'] if \'jekyll\' in meta else {\'title\': fname.with_suffix(\'\').name}\n    meta_jekyll[\'nb_path\'] = f\'{fname.parent.name}/{fname.name}\'\n    with open(f\'{dest_path}/{dest_name}\',\'w\') as f:\n        f.write(exporter.from_notebook_node(nb, resources=meta_jekyll)[0])\n\ndef convert_all(folder, dest_path=\'.\', force_all=False):\n    ""Convert modified notebooks in `folder` to html pages in `dest_path`.""\n    path = Path(folder)\n\n    changed_cnt = 0\n    for fname in path.glob(""*.ipynb""):\n        # only rebuild modified files\n        fname_out = Path(dest_path)/fname.with_suffix(\'.html\').name\n        if not force_all and fname_out.exists():\n            in_mod  = os.path.getmtime(fname)\n            out_mod = os.path.getmtime(fname_out)\n            if in_mod < out_mod: continue\n\n        print(f""converting: {fname} => {fname_out}"")\n        changed_cnt += 1\n        convert_nb(fname, dest_path=dest_path)\n    if not changed_cnt: print(""No notebooks were modified"")\n'"
fastai/gen_doc/core.py,0,"b""from ..core import *\nimport re\n\ndef strip_fastai(s):  return re.sub(r'^fastai\\.', '', s)\n\n"""
fastai/gen_doc/docstrings.py,0,"b'# https://github.com/openstack/rally/blob/master/rally/common/plugin/info.py\n# Copyright 2015: Mirantis Inc.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the ""License""); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nimport re\nimport sys\n\n__all__ = [\'parse_docstring\']\n\n\nFIELDS = \'param|val\' # supported fields\nPARAM_OR_RETURN_REGEX = re.compile(f"":(?:{FIELDS}|return)"")\nRETURN_REGEX = re.compile("":return: (?P<doc>.*)"", re.S)\nNEW_REGEX = re.compile(f"":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)""\n                         f""(?:(?=:(?:{FIELDS}|return|raises))|\\Z)"", re.S)\n\ndef trim(docstring):\n    """"""trim function from PEP-257""""""\n    if not docstring:\n        return """"\n    # Convert tabs to spaces (following the normal Python rules)\n    # and split into a list of lines:\n    lines = docstring.expandtabs().splitlines()\n    # Determine minimum indentation (first line doesn\'t count):\n    indent = sys.maxsize\n    for line in lines[1:]:\n        stripped = line.lstrip()\n        if stripped:\n            indent = min(indent, len(line) - len(stripped))\n    # Remove indentation (first line is special):\n    trimmed = [lines[0].strip()]\n    if indent < sys.maxsize:\n        for line in lines[1:]:\n            trimmed.append(line[indent:].rstrip())\n    # Strip off trailing and leading blank lines:\n    while trimmed and not trimmed[-1]:\n        trimmed.pop()\n    while trimmed and not trimmed[0]:\n        trimmed.pop(0)\n\n    # Current code/unittests expects a line return at\n    # end of multiline docstrings\n    # workaround expected behavior from unittests\n    if ""\\n"" in docstring:\n        trimmed.append("""")\n\n    # Return a single string:\n    return ""\\n"".join(trimmed)\n\n\ndef reindent(string):\n    return ""\\n"".join(l.strip() for l in string.strip().split(""\\n""))\n\n\ndef parse_docstring(docstring):\n    """"""Parse the docstring into its components.\n\n    :return: a dictionary of form\n              {\n                  ""short_description"": ...,\n                  ""long_description"": ...,\n                  ""params"": [{""name"": ..., ""doc"": ...}, ...],\n                  ""vals"": [{""name"": ..., ""doc"": ...}, ...],\n                  ""return"": ...\n              }\n    """"""\n\n    short_description = long_description = return_str = """"\n    args = []\n\n    if docstring:\n        docstring = trim(docstring.lstrip(""\\n""))\n\n        lines = docstring.split(""\\n"", 1)\n        short_description = lines[0]\n\n        if len(lines) > 1:\n            long_description = lines[1].strip()\n\n            params_return_desc = None\n\n            match = PARAM_OR_RETURN_REGEX.search(long_description)\n            if match:\n                long_desc_end = match.start()\n                params_return_desc = long_description[long_desc_end:].strip()\n                long_description = long_description[:long_desc_end].rstrip()\n\n            if params_return_desc:\n                args = [\n                    {""name"": name, ""doc"": trim(doc), ""field"": field}\n                    for field, name, doc in NEW_REGEX.findall(params_return_desc)\n                ]\n                match = RETURN_REGEX.search(params_return_desc)\n                if match:\n                    return_str = reindent(match.group(""doc""))\n    comments = {p[\'name\']: p[\'doc\'] for p in args}\n    return {\n        ""short_description"": short_description,\n        ""long_description"": long_description,\n        ""args"": args,\n        ""comments"": comments,\n        ""return"": return_str\n    }\n\n\nclass InfoMixin(object):\n\n    @classmethod\n    def _get_doc(cls):\n        """"""Return documentary of class\n\n        By default it returns docstring of class, but it can be overridden\n        for example for cases like merging own docstring with parent\n        """"""\n        return cls.__doc__\n\n    @classmethod\n    def get_info(cls):\n        doc = parse_docstring(cls._get_doc())\n\n        return {\n            ""name"": cls.get_name(),\n            ""platform"": cls.get_platform(),\n            ""module"": cls.__module__,\n            ""title"": doc[""short_description""],\n            ""description"": doc[""long_description""],\n            ""parameters"": doc[""params""],\n            ""schema"": getattr(cls, ""CONFIG_SCHEMA"", None),\n            ""return"": doc[""return""]\n        }\n'"
fastai/gen_doc/doctest.py,0,"b'import sys, re, json, pprint\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom inspect import currentframe, getframeinfo, ismodule\n\n__all__ = [\'this_tests\']\n\nDB_NAME = \'test_registry.json\'\n\ndef _json_set_default(obj):\n    if isinstance(obj, set): return list(obj)\n    raise TypeError\n\nclass TestRegistry:\n    ""Tests register which API they validate using this class.""\n    registry = defaultdict(list)\n    this_tests_check = None\n    missing_this_tests = set()\n\n    # logic for checking whether each test calls `this_tests`:\n    # 1. `this_tests_check` is set to True during test\'s \'setup\' stage if it wasn\'t skipped\n    # 2. if the test is dynamically skipped `this_tests_check` is set to False\n    # 3. `this_tests` sets this flag to False when it\'s successfully completes\n    # 4. if during the \'teardown\' stage `this_tests_check` is still True then we\n    # know that this test needs `this_tests_check`\n\n    @staticmethod\n    def this_tests(*funcs):\n        prev_frame = currentframe().f_back.f_back\n        file_name, lineno, test_name, _, _ = getframeinfo(prev_frame)\n        parent_func_lineno, _ = get_parent_func(lineno, get_lines(file_name))\n        entry = {\'file\': relative_test_path(file_name), \'test\': test_name , \'line\': parent_func_lineno}\n        for func in funcs:\n            if func == \'na\':\n                # special case when we can\'t find a function to declare, e.g.\n                # when attributes are tested\n                continue\n            try:\n                func_fq = get_func_fq_name(func)\n            except:\n                raise Exception(f""\'{func}\' is not a function"") from None\n            if re.match(r\'fastai\\.\', func_fq):\n                if entry not in TestRegistry.registry[func_fq]:\n                    TestRegistry.registry[func_fq].append(entry)\n            else:\n                raise Exception(f""\'{func}\' is not in the fastai API"") from None\n        TestRegistry.this_tests_check = False\n\n    def this_tests_check_on():\n        TestRegistry.this_tests_check = True\n\n    def this_tests_check_off():\n        TestRegistry.this_tests_check = False\n\n    def this_tests_check_run(file_name, test_name):\n        if TestRegistry.this_tests_check:\n            TestRegistry.missing_this_tests.add(f""{file_name}::{test_name}"")\n\n    def registry_save():\n        if TestRegistry.registry:\n            path = Path(__file__).parent.parent.resolve()/DB_NAME\n            if path.exists():\n                #print(""\\n*** Merging with the existing test registry"")\n                with open(path, \'r\') as f: old_registry = json.load(f)\n                TestRegistry.registry = merge_registries(old_registry, TestRegistry.registry)\n            #print(f""\\n*** Saving test registry @ {path}"")\n            with open(path, \'w\') as f:\n                json.dump(obj=TestRegistry.registry, fp=f, indent=4, sort_keys=True, default=_json_set_default)\n\n    def missing_this_tests_alert():\n        if TestRegistry.missing_this_tests:\n            tests = \'\\n  \'.join(sorted(TestRegistry.missing_this_tests))\n            print(f""""""\n*** Attention ***\nPlease include `this_tests` call in each of the following tests:\n  {tests}\nFor details see: https://docs.fast.ai/dev/test.html#test-registry"""""")\n\n# merge_registries helpers\n# merge dict of lists of dict\ndef a2k(a): return \'::\'.join([a[\'file\'], a[\'test\']]), a[\'line\']\ndef k2a(k, v): f,t = k.split(\'::\'); return {""file"": f, ""line"": v, ""test"": t}\n# merge by key that is a combination of 2 values: test, file\ndef merge_lists(a, b):\n    x = dict(map(a2k, [*a, *b]))            # pack + merge\n    return [k2a(k, v) for k,v in x.items()] # unpack\ndef merge_registries(a, b):\n    for i in b: a[i] = merge_lists(a[i], b[i]) if i in a else b[i]\n    return a\n\ndef this_tests(*funcs): TestRegistry.this_tests(*funcs)\n\ndef str2func(name):\n    ""Converts \'fastai.foo.bar\' into an function \'object\' if such exists""\n    if isinstance(name, str): subpaths = name.split(\'.\')\n    else:                     return None\n\n    module = subpaths.pop(0)\n    if module in sys.modules: obj = sys.modules[module]\n    else:                     return None\n\n    for subpath in subpaths:\n        obj = getattr(obj, subpath, None)\n        if obj == None: return None\n    return obj\n\ndef get_func_fq_name(func):\n    if ismodule(func): return func.__name__\n    if isinstance(func, str): func = str2func(func)\n    name = None\n    if   hasattr(func, \'__qualname__\'): name = func.__qualname__\n    elif hasattr(func, \'__name__\'):     name = func.__name__\n    elif hasattr(func, \'__wrapped__\'):  return get_func_fq_name(func.__wrapped__)\n    elif hasattr(func, \'__class__\'):    name = func.__class__.__name__\n    else: raise Exception(f""\'{func}\' is not a func or class"")\n    return f\'{func.__module__}.{name}\'\n\ndef get_parent_func(lineno, lines, ignore_missing=False):\n    ""Find any lines where `elt` is called and return the parent test function""\n    for idx,l in enumerate(reversed(lines[:lineno])):\n        if re.match(f\'\\s*def test\', l):  return (lineno - idx), l # 1 based index for github\n        if re.match(f\'\\w+\', l):  break # top level indent - out of function scope\n    if ignore_missing: return None\n    raise LookupError(\'Could not find parent function for line:\', lineno, lines[:lineno])\n\ndef relative_test_path(test_file:Path)->str:\n    ""Path relative to the `fastai` parent directory""\n    test_file = Path(test_file)\n    testdir_idx = list(reversed(test_file.parts)).index(\'tests\')\n    return \'/\'.join(test_file.parts[-(testdir_idx+1):])\n\ndef get_lines(file):\n    with open(file, \'r\') as f: return f.readlines()\n'"
fastai/gen_doc/gen_notebooks.py,0,"b'""`gen_doc.nbdoc` generates notebook documentation from module functions and links to correct places""\nimport pkgutil, inspect, sys,os, importlib,json,enum,warnings,nbformat,re\nfrom IPython.core.display import display, Markdown\nfrom nbconvert.preprocessors import ExecutePreprocessor\nfrom nbformat.sign import NotebookNotary\nfrom pathlib import Path\nfrom .core import *\nfrom .nbdoc import *\n\n__all__ = [\'create_module_page\', \'update_module_page\', \'import_mod\',\n           \'link_nb\', \'update_notebooks\', \'generate_missing_metadata\', \'update_nb_metadata\']\n\ndef get_empty_notebook():\n    ""Default notbook with the minimum metadata.""\n    #TODO: check python version and nbformat\n    return {\'metadata\': {\'kernelspec\': {\'display_name\': \'Python 3\',\n                                        \'language\': \'python\',\n                                        \'name\': \'python3\'},\n                         \'language_info\': {\'codemirror_mode\': {\'name\': \'ipython\', \'version\': 3},\n                         \'file_extension\': \'.py\',\n                         \'mimetype\': \'text/x-python\',\n                         \'name\': \'python\',\n                         \'nbconvert_exporter\': \'python\',\n                         \'pygments_lexer\': \'ipython3\',\n                         \'version\': \'3.6.6\'}},\n            \'nbformat\': 4,\n            \'nbformat_minor\': 2}\n\ndef get_md_cell(source, metadata=None):\n    ""Markdown cell containing `source` with `metadata`.""\n    return {\'cell_type\': \'markdown\',\n            \'metadata\': {} if metadata is None else metadata,\n            \'source\': source}\n\ndef get_empty_cell(ctype=\'markdown\'):\n    ""Empty cell of type `ctype`.""\n    return {\'cell_type\': ctype, \'metadata\': {}, \'source\': []}\n\ndef get_code_cell(code, hidden=False):\n    ""Code cell containing `code` that may be `hidden`.""\n    return {\'cell_type\' : \'code\',\n            \'execution_count\': 0,\n            \'metadata\' : {\'hide_input\': hidden, \'trusted\':True},\n            \'source\' : code,\n            \'outputs\': []}\n\ndef get_doc_cell(func_name):\n    ""Code cell with the command to show the doc of `func_name`.""\n    code = f""show_doc({func_name})""\n    return get_code_cell(code, True)\n\ndef get_global_vars(mod):\n    ""Return globally assigned variables.""\n    # https://stackoverflow.com/questions/8820276/docstring-for-variable/31764368#31764368\n    import ast,re\n    with open(mod.__file__, \'r\') as f: fstr = f.read()\n    flines = fstr.splitlines()\n    d = {}\n    for node in ast.walk(ast.parse(fstr)):\n        if isinstance(node,ast.Assign) and hasattr(node.targets[0], \'id\'):\n            key,lineno = node.targets[0].id,node.targets[0].lineno\n            codestr = flines[lineno]\n            match = re.match(f""^({key})\\s*=\\s*.*"", codestr)\n            if match and match.group(1) != \'__all__\': # only top level assignment\n                d[key] = f\'`{codestr}` {get_source_link(mod, lineno)}\'\n    return d\n\ndef write_nb(nb, nb_path, mode=\'w\'):\n    with open(nb_path, mode) as f: f.write(nbformat.writes(nbformat.from_dict(nb), version=4))\n\nclass ExecuteShowDocPreprocessor(ExecutePreprocessor):\n    ""An ExecutePreprocessor that only executes show_doc cells""\n    def preprocess_cell(self, cell, resources, index):\n        if \'source\' in cell and cell.cell_type == ""code"":\n            if IMPORT_RE.search(cell[\'source\']) or SHOW_DOC_RE.search(cell[\'source\']):\n                return super().preprocess_cell(cell, resources, index)\n        return cell, resources\n\ndef execute_nb(fname, metadata=None, save=True, show_doc_only=False):\n    ""Execute notebook `fname` with `metadata` for preprocessing.""\n    # Any module used in the notebook that isn\'t inside must be in the same directory as this script\n    with open(fname) as f: nb = nbformat.read(f, as_version=4)\n    ep_class = ExecuteShowDocPreprocessor if show_doc_only else ExecutePreprocessor\n    ep = ep_class(timeout=600, kernel_name=\'python3\')\n    metadata = metadata or {}\n    ep.preprocess(nb, metadata)\n    if save:\n        with open(fname, \'wt\', encoding=\'utf-8\') as f: nbformat.write(nb, f)\n        NotebookNotary().sign(nb)\n\ndef _symbol_skeleton(name): return [get_doc_cell(name), get_md_cell(f""`{name}`"")]\n\ndef create_module_page(mod, dest_path, force=False):\n    ""Create the documentation notebook for module `mod_name` in path `dest_path`""\n    nb = get_empty_notebook()\n    mod_name = mod.__name__\n    strip_name = strip_fastai(mod_name)\n    init_cell = [get_md_cell(f\'## Title for {strip_name} (use plain english, not module name!)\'), get_md_cell(\'Type an introduction of the package here.\')]\n    cells = [get_code_cell(f\'from fastai.gen_doc.nbdoc import *\\nfrom {mod_name} import * \', True)]\n\n    gvar_map = get_global_vars(mod)\n    if gvar_map: cells.append(get_md_cell(\'### Global Variable Definitions:\'))\n    for name in get_exports(mod):\n        if name in gvar_map: cells.append(get_md_cell(gvar_map[name]))\n\n    for ft_name in get_ft_names(mod, include_inner=True):\n        if not hasattr(mod, ft_name):\n            warnings.warn(f""Module {strip_name} doesn\'t have a function named {ft_name}."")\n            continue\n        cells += _symbol_skeleton(ft_name)\n        elt = getattr(mod, ft_name)\n    nb[\'cells\'] = init_cell + cells + [get_md_cell(UNDOC_HEADER)]\n\n    doc_path = get_doc_path(mod, dest_path)\n    write_nb(nb, doc_path, \'w\' if force else \'x\')\n    execute_nb(doc_path)\n    return doc_path\n\n_default_exclude = [\'.ipynb_checkpoints\', \'__pycache__\', \'__init__.py\', \'imports\']\n\ndef get_module_names(path_dir, exclude=None):\n    if exclude is None: exclude = _default_exclude\n    ""Search a given `path_dir` and return all the modules contained inside except those in `exclude`""\n    files = sorted(path_dir.glob(\'*\'), key=lambda x: (x.is_dir(), x.name), reverse=True) # directories first\n    res = [f\'{path_dir.name}\']\n    for f in files:\n        if f.is_dir() and f.name in exclude: continue # exclude directories\n        if any([f.name.endswith(ex) for ex in exclude]): continue # exclude extensions\n\n        if f.suffix == \'.py\': res.append(f\'{path_dir.name}.{f.stem}\')\n        elif f.is_dir(): res += [f\'{path_dir.name}.{name}\' for name in get_module_names(f)]\n    return res\n\ndef read_nb(fname):\n    ""Read a notebook in `fname` and return its corresponding json""\n    with open(fname,\'r\') as f: return nbformat.reads(f.read(), as_version=4)\n\nSHOW_DOC_RE = re.compile(r""show_doc\\(([\\w\\.]*)"")\ndef read_nb_content(cells, mod_name):\n    ""Build a dictionary containing the position of the `cells`.""\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\'cell_type\'] == \'code\':\n            for match in SHOW_DOC_RE.findall(cell[\'source\']):\n                doc_fns[match] = i\n    return doc_fns\n\ndef read_nb_types(cells):\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\'cell_type\'] == \'markdown\':\n            match = re.match(r""^(?:<code>|`)?(\\w*)\\s*=\\s*"", cell[\'source\'])\n            if match is not None: doc_fns[match.group(1)] = i\n    return doc_fns\n\ndef link_markdown_cells(cells, modules):\n    ""Create documentation links for all cells in markdown with backticks.""\n    for i, cell in enumerate(cells):\n        if cell[\'cell_type\'] == \'markdown\':\n            cell[\'source\'] = link_docstring(modules, cell[\'source\'])\n\ndef get_insert_idx(pos_dict, name):\n    ""Return the position to insert a given function doc in a notebook.""\n    keys,i = list(pos_dict.keys()),0\n    while i < len(keys) and str.lower(keys[i]) < str.lower(name): i+=1\n    if i == len(keys): return -1\n    else:              return pos_dict[keys[i]]\n\ndef update_pos(pos_dict, start_key, nbr=2):\n    ""Update the `pos_dict` by moving all positions after `start_key` by `nbr`.""\n    for key,idx in pos_dict.items():\n        if str.lower(key) >= str.lower(start_key): pos_dict[key] += nbr\n    return pos_dict\n\ndef insert_cells(cells, pos_dict, ft_name, append=False):\n    ""Insert the function doc `cells` at their correct position and updates `pos_dict`.""\n    idx = get_insert_idx(pos_dict, ft_name)\n    if append or idx == -1: cells += [get_doc_cell(ft_name), get_empty_cell()]\n    else:\n        cells.insert(idx, get_doc_cell(ft_name))\n        cells.insert(idx+1, get_empty_cell())\n        pos_dict = update_pos(pos_dict, ft_name, 2)\n    return cells, pos_dict\n\ndef get_doc_path(mod, dest_path):\n    strip_name = strip_fastai(mod.__name__)\n    return os.path.join(dest_path,f\'{strip_name}.ipynb\')\n\ndef generate_missing_metadata(dest_file):\n    fn = Path(dest_file)\n    meta_fn = fn.parent/\'jekyll_metadata.ipynb\'\n    if not fn.exists() or not meta_fn.exists(): return print(\'Could not find notebooks:\', fn, meta_fn)\n    metadata_nb = read_nb(meta_fn)\n\n    if has_metadata_cell(metadata_nb[\'cells\'], fn.name): return\n    nb = read_nb(fn)\n    jmd = nb[\'metadata\'].get(\'jekyll\', {})\n    fmt_params = \'\'\n    for k,v in jmd.items(): fmt_params += f\',\\n    {k}={stringify(v)}\'\n    metadata_cell = get_code_cell(f""update_nb_metadata(\'{Path(fn).name}\'{fmt_params})"", hidden=False)\n    metadata_nb[\'cells\'].append(metadata_cell)\n    write_nb(metadata_nb, meta_fn)\n\ndef update_nb_metadata(nb_path=None, title=None, summary=None, keywords=\'fastai\', overwrite=True, **kwargs):\n    ""Creates jekyll metadata for given notebook path.""\n    nb = read_nb(nb_path)\n    data = {\'title\': title, \'summary\': summary, \'keywords\': keywords, **kwargs}\n    data = {k:v for (k,v) in data.items() if v is not None} # remove none values\n    if not data: return\n    nb[\'metadata\'][\'jekyll\'] = data\n    write_nb(nb, nb_path)\n    NotebookNotary().sign(nb)\n\ndef has_metadata_cell(cells, fn):\n    for c in cells:\n        if re.search(f""update_nb_metadata\\(\'{fn}\'"", c[\'source\']): return c\n\ndef stringify(s): return f\'\\\'{s}\\\'\' if isinstance(s, str) else s\n\nIMPORT_RE = re.compile(r""from (fastai[\\.\\w_]*)"")\ndef get_imported_modules(cells, nb_module_name=\'\'):\n    ""Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority""\n    module_names = get_top_level_modules()\n    nb_imports = [match.group(1) for cell in cells for match in IMPORT_RE.finditer(cell[\'source\']) if cell[\'cell_type\'] == \'code\']\n    parts = nb_module_name.split(\'.\')\n    parent_modules = [\'.\'.join(parts[:(x+1)]) for x in range_of(parts)] # Imports parent modules - a.b.c = [a, a.b, a.b.c]\n    all_modules = module_names + nb_imports + parent_modules\n    mods = [import_mod(m, ignore_errors=True) for m in all_modules]\n    return [m for m in mods if m is not None]\n\ndef get_top_level_modules(num_levels=1):\n    mod_dir = Path(import_mod(\'fastai\').__file__).parent\n    filtered_n = filter(lambda x: x.count(\'.\')<=num_levels, get_module_names(mod_dir))\n    return sorted(filtered_n, key=lambda s: s.count(\'.\'), reverse=True) # Submodules first (sorted by periods)\n\nNEW_FT_HEADER = \'## New Methods - Please document or move to the undocumented section\'\nUNDOC_HEADER = \'## Undocumented Methods - Methods moved below this line will intentionally be hidden\'\ndef parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []\n    current_section = old_cells\n    for cell in cells:\n        if cell[\'cell_type\'] == \'markdown\':\n            if re.match(UNDOC_HEADER, cell[\'source\']): current_section = undoc_cells\n            if re.match(NEW_FT_HEADER, cell[\'source\']): current_section = new_cells\n        current_section.append(cell)\n    undoc_cells = undoc_cells or [get_md_cell(UNDOC_HEADER)]\n    new_cells = new_cells or [get_md_cell(NEW_FT_HEADER)]\n    return old_cells, undoc_cells, new_cells\n\ndef remove_undoc_cells(cells):\n    old, _, _ = parse_sections(cells)\n    return old\n\n# currently code vbox sub-cells mainly\ndef remove_code_cell_jupyter_widget_state_elem(cells):\n    for c in cells:\n        if c[\'cell_type\'] == \'code\':\n            if \'outputs\' in c:\n                c[\'outputs\'] = [l for l in c[\'outputs\'] if not (\'data\' in l and \'application/vnd.jupyter.widget-view+json\' in l.data)]\n    return cells\n\ndef update_module_page(mod, dest_path=\'.\'):\n    ""Update the documentation notebook of a given module.""\n    doc_path = get_doc_path(mod, dest_path)\n    strip_name = strip_fastai(mod.__name__)\n    nb = read_nb(doc_path)\n    cells = nb[\'cells\']\n\n    link_markdown_cells(cells, get_imported_modules(cells, mod.__name__))\n\n    type_dict = read_nb_types(cells)\n    gvar_map = get_global_vars(mod)\n    for name in get_exports(mod):\n        if name not in gvar_map: continue\n        code = gvar_map[name]\n        if name in type_dict: cells[type_dict[name]] = get_md_cell(code)\n        else: cells.append(get_md_cell(code))\n\n    pos_dict = read_nb_content(cells, strip_name)\n    ft_names = get_ft_names(mod, include_inner=True)\n    new_fts = list(set(ft_names) - set(pos_dict.keys()))\n    if new_fts: print(f\'Found new fuctions for {mod}. Please document:\\n{new_fts}\')\n    existing, undoc_cells, new_cells = parse_sections(cells)\n    for ft_name in new_fts: new_cells.extend([get_doc_cell(ft_name), get_empty_cell()])\n    if len(new_cells) > 1: nb[\'cells\'] = existing + undoc_cells + new_cells\n\n    write_nb(nb, doc_path)\n    return doc_path\n\ndef link_nb(nb_path):\n    nb = read_nb(nb_path)\n    cells = nb[\'cells\']\n    link_markdown_cells(cells, get_imported_modules(cells, Path(nb_path).stem))\n    write_nb(nb, nb_path)\n    NotebookNotary().sign(read_nb(nb_path))\n\ndef get_module_from_notebook(doc_path):\n    ""Find module given a source path. Assume it belongs to fastai directory""\n    return f\'fastai.{Path(doc_path).stem}\'\n\ndef check_nbconvert_version():\n    import nbconvert\n    assert nbconvert.version_info >= (5,4,0), ""Please update nbconvert to >=5.4 for consistent .html output""\n\ndef update_notebooks(source_path, dest_path=None, update_html=True, document_new_fns=False,\n                     update_nb_links=True, html_path=None, force=False):\n    ""`source_path` can be a directory or a file. Assume all modules reside in the fastai directory.""\n    from .convert2html import convert_nb\n    source_path = Path(source_path)\n\n    if source_path.is_file():\n        dest_path = source_path.parent if dest_path is None else Path(dest_path)\n        html_path = dest_path/\'..\'/\'docs\' if html_path is None else Path(html_path)\n        doc_path = source_path\n        assert source_path.suffix == \'.ipynb\', \'Must update from notebook or module\'\n        if document_new_fns:\n            mod = import_mod(get_module_from_notebook(source_path))\n            if not mod: print(\'Could not find module for path:\', source_path)\n            elif mod.__file__.endswith(\'__init__.py\'): pass\n            else: update_module_page(mod, dest_path)\n        generate_missing_metadata(doc_path)\n        if update_nb_links:\n            print(f\'Updating notebook {doc_path}. Please wait...\')\n            link_nb(doc_path)\n            execute_nb(doc_path, {\'metadata\': {\'path\': doc_path.parent}}, show_doc_only=True)\n        if update_html:\n            check_nbconvert_version()\n            html_fn = html_path/doc_path.with_suffix(\'.html\').name\n            if not force and html_fn.is_file():\n                in_mod  = os.path.getmtime(doc_path)\n                out_mod = os.path.getmtime(html_fn)\n                if in_mod < out_mod: return\n            convert_nb(doc_path, html_path)\n\n    elif (source_path.name.startswith(\'fastai.\')):\n        # Do module update\n        assert dest_path is not None, \'To update a module, you must specify a destination folder for where notebook resides\'\n        mod = import_mod(source_path.name)\n        if not mod: return print(\'Could not find module for:\', source_path)\n        doc_path = Path(dest_path)/(strip_fastai(mod.__name__)+\'.ipynb\')\n        if not doc_path.exists():\n            print(\'Notebook does not exist. Creating:\', doc_path)\n            create_module_page(mod, dest_path)\n        update_notebooks(doc_path, dest_path=dest_path, update_html=update_html, document_new_fns=document_new_fns,\n                         update_nb_links=update_nb_links, html_path=html_path)\n    elif source_path.is_dir():\n        for f in sorted(Path(source_path).glob(\'*.ipynb\')):\n            update_notebooks(f, dest_path=dest_path, update_html=update_html, document_new_fns=document_new_fns,\n                             update_nb_links=update_nb_links, html_path=html_path)\n    else: print(\'Could not resolve source file:\', source_path)\n'"
fastai/gen_doc/nbdoc.py,2,"b'# -*- coding: utf-8 -*-\n""`gen_doc.nbdoc` generates notebook documentation from module functions and links to correct places""\n\nimport inspect,importlib,enum,os,re,nbconvert\nfrom IPython.core.display import display, Markdown, HTML\nfrom nbconvert import HTMLExporter\nfrom IPython.core import page\nfrom IPython import get_ipython\nfrom typing import Dict, Any, AnyStr, List, Sequence, TypeVar, Tuple, Optional, Union\nfrom .docstrings import *\nfrom .core import *\nfrom ..torch_core import *\nfrom .nbtest import get_pytest_html\nfrom ..utils.ipython import IS_IN_COLAB\n\n__all__ = [\'get_fn_link\', \'link_docstring\', \'show_doc\', \'get_ft_names\', \'md2html\',\n           \'get_exports\', \'show_video\', \'show_video_from_youtube\', \'import_mod\', \'get_source_link\',\n           \'is_enum\', \'jekyll_note\', \'jekyll_warn\', \'jekyll_important\', \'doc\']\n\nMODULE_NAME = \'fastai\'\nSOURCE_URL = \'https://github.com/fastai/fastai/blob/master/\'\nPYTORCH_DOCS = \'https://pytorch.org/docs/stable/\'\nFASTAI_DOCS = \'https://docs.fast.ai\'\nuse_relative_links = True\n\n_typing_names = {t:n for t,n in fastai_types.items() if t.__module__==\'typing\'}\narg_prefixes = {inspect._VAR_POSITIONAL: \'\\*\', inspect._VAR_KEYWORD:\'\\*\\*\'}\n\n\ndef is_enum(cls): return cls == enum.Enum or cls == enum.EnumMeta\n\ndef link_type(arg_type, arg_name=None, include_bt:bool=True):\n    ""Create link to documentation.""\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt: arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \'torch\') and (\'Tensor\' not in arg_name): return f\'[{arg_name}]({get_pytorch_link(arg_type)})\'\n    if is_fastai_class(arg_type): return f\'[{arg_name}]({get_fn_link(arg_type)})\'\n    return arg_name\n\ndef is_fastai_class(t): return belongs_to_module(t, MODULE_NAME)\n\ndef belongs_to_module(t, module_name):\n    ""Check if `t` belongs to `module_name`.""\n    if hasattr(t, \'__func__\'): return belongs_to_module(t.__func__, module_name)\n    if not inspect.getmodule(t): return False\n    return inspect.getmodule(t).__name__.startswith(module_name)\n\ndef code_esc(s): return f\'`{s}`\'\n\ndef type_repr(t):\n    if t in _typing_names: return link_type(t, _typing_names[t])\n    if isinstance(t, partial): return partial_repr(t)\n    if hasattr(t, \'__forward_arg__\'): return link_type(t.__forward_arg__)\n    elif getattr(t, \'__args__\', None):\n        args = t.__args__\n        if len(args)==2 and args[1] == type(None):\n            return f\'`Optional`\\[{type_repr(args[0])}\\]\'\n        reprs = \', \'.join([type_repr(o) for o in args])\n        return f\'{link_type(t)}\\[{reprs}\\]\'\n    else: return link_type(t)\n\ndef partial_repr(t):\n    args = (t.func,) + t.args + tuple([f\'{k}={v}\' for k,v in t.keywords.items()])\n    reprs = \', \'.join([link_type(o) for o in args])\n    return f\'<code>partial(</code>{reprs}<code>)</code>\'\n\ndef anno_repr(a): return type_repr(a)\n\ndef format_param(p):\n    ""Formats function param to `param1:Type=val`. Font weights: param1=bold, val=bold+italic""\n    arg_prefix = arg_prefixes.get(p.kind, \'\') # asterisk prefix for *args and **kwargs\n    res = f""**{arg_prefix}{code_esc(p.name)}**""\n    if hasattr(p, \'annotation\') and p.annotation != p.empty: res += f\':{anno_repr(p.annotation)}\'\n    if p.default != p.empty:\n        default = getattr(p.default, \'func\', p.default)\n        default = getattr(default, \'__name__\', default)\n        res += f\'=***`{repr(default)}`***\'\n    return res\n\ndef format_ft_def(func, full_name:str=None)->str:\n    ""Format and link `func` definition to show in documentation""\n    sig = inspect.signature(func)\n    name = f\'<code>{full_name or func.__name__}</code>\'\n    fmt_params = [format_param(param) for name,param\n                  in sig.parameters.items() if name not in (\'self\',\'cls\')]\n    arg_str = f""({\', \'.join(fmt_params)})""\n    if sig.return_annotation and (sig.return_annotation != sig.empty): arg_str += f"" \xe2\x86\x92 {anno_repr(sig.return_annotation)}""\n    if is_fastai_class(type(func)):        arg_str += f"" :: {link_type(type(func))}""\n    f_name = f""<code>class</code> {name}"" if inspect.isclass(func) else name\n    return f\'{f_name}\',f\'{name}{arg_str}\'\n\ndef get_enum_doc(elt, full_name:str)->str:\n    ""Formatted enum documentation.""\n    vals = \', \'.join(elt.__members__.keys())\n    return f\'{code_esc(full_name)}\',f\'<code>Enum</code> = [{vals}]\'\n\ndef get_cls_doc(elt, full_name:str)->str:\n    ""Class definition.""\n    parent_class = inspect.getclasstree([elt])[-1][0][1][0]\n    name,args = format_ft_def(elt, full_name)\n    if parent_class != object: args += f\' :: {link_type(parent_class, include_bt=True)}\'\n    return name,args\n\ndef show_doc(elt, doc_string:bool=True, full_name:str=None, arg_comments:dict=None, title_level=None, alt_doc_string:str=\'\',\n             ignore_warn:bool=False, markdown=True, show_tests=True):\n    ""Show documentation for element `elt`. Supported types: class, Callable, and enum.""\n    arg_comments = ifnone(arg_comments, {})\n    anchor_id = get_anchor(elt)\n    elt = getattr(elt, \'__func__\', elt)\n    full_name = full_name or fn_name(elt)\n    if inspect.isclass(elt):\n        if is_enum(elt.__class__):   name,args = get_enum_doc(elt, full_name)\n        else:                        name,args = get_cls_doc(elt, full_name)\n    elif isinstance(elt, Callable):  name,args = format_ft_def(elt, full_name)\n    else: raise Exception(f\'doc definition not supported for {full_name}\')\n    source_link = get_function_source(elt) if is_fastai_class(elt) else """"\n    test_link, test_modal = get_pytest_html(elt, anchor_id=anchor_id) if show_tests else (\'\', \'\')\n    title_level = ifnone(title_level, 2 if inspect.isclass(elt) else 4)\n    doc =  f\'<h{title_level} id=""{anchor_id}"" class=""doc_header"">{name}{source_link}{test_link}</h{title_level}>\'\n    doc += f\'\\n\\n> {args}\\n\\n\'\n    doc += f\'{test_modal}\'\n    if doc_string and (inspect.getdoc(elt) or arg_comments):\n        doc += format_docstring(elt, arg_comments, alt_doc_string, ignore_warn) + \' \'\n    if markdown: display(Markdown(doc))\n    else: return doc\n\ndef md2html(md):\n    if nbconvert.__version__ < \'5.5.0\': return HTMLExporter().markdown2html(md)\n    else: return HTMLExporter().markdown2html(defaultdict(lambda: defaultdict(dict)), md)\n\ndef doc(elt):\n    ""Show `show_doc` info in preview window along with link to full docs.""\n    global use_relative_links\n    use_relative_links = False\n    elt = getattr(elt, \'__func__\', elt)\n    md = show_doc(elt, markdown=False)\n    if is_fastai_class(elt):\n        md += f\'\\n\\n<a href=""{get_fn_link(elt)}"" target=""_blank"" rel=""noreferrer noopener"">Show in docs</a>\'\n    output = md2html(md)\n    use_relative_links = True\n    if IS_IN_COLAB: get_ipython().run_cell_magic(u\'html\', u\'\', output)\n    else:\n        try: page.page({\'text/html\': output})\n        except: display(Markdown(md))\n\ndef format_docstring(elt, arg_comments:dict={}, alt_doc_string:str=\'\', ignore_warn:bool=False)->str:\n    ""Merge and format the docstring definition with `arg_comments` and `alt_doc_string`.""\n    parsed = """"\n    doc = parse_docstring(inspect.getdoc(elt))\n    description = alt_doc_string or f""{doc[\'short_description\']} {doc[\'long_description\']}""\n    if description: parsed += f\'\\n\\n{link_docstring(inspect.getmodule(elt), description)}\'\n\n    resolved_comments = {**doc.get(\'comments\', {}), **arg_comments} # arg_comments takes priority\n    args = inspect.getfullargspec(elt).args if not is_enum(elt.__class__) else elt.__members__.keys()\n    if resolved_comments: parsed += \'\\n\'\n    for a in resolved_comments:\n        parsed += f\'\\n- *{a}*: {resolved_comments[a]}\'\n        if a not in args and not ignore_warn: warn(f\'Doc arg mismatch: {a}\')\n\n    return_comment = arg_comments.get(\'return\') or doc.get(\'return\')\n    if return_comment: parsed += f\'\\n\\n*return*: {return_comment}\'\n    return parsed\n\n_modvars = {}\n\ndef replace_link(m):\n    keyword = m.group(1) or m.group(2)\n    elt = find_elt(_modvars, keyword)\n    if elt is None: return m.group()\n    return link_type(elt, arg_name=keyword)\n\n# Finds all places with a backtick but only if it hasn\'t already been linked\nBT_REGEX = re.compile(""\\[`([^`]*)`\\](?:\\([^)]*\\))|`([^`]*)`"") # matches [`key`](link) or `key`\ndef link_docstring(modules, docstring:str, overwrite:bool=False)->str:\n    ""Search `docstring` for backticks and attempt to link those functions to respective documentation.""\n    mods = listify(modules)\n    for mod in mods: _modvars.update(mod.__dict__) # concat all module definitions\n    return re.sub(BT_REGEX, replace_link, docstring)\n\ndef find_elt(modvars, keyword, match_last=False):\n    ""Attempt to resolve keywords such as Learner.lr_find. `match_last` starts matching from last component.""\n    keyword = strip_fastai(keyword)\n    if keyword in modvars: return modvars[keyword]\n    comps = keyword.split(\'.\')\n    comp_elt = modvars.get(comps[0])\n    if hasattr(comp_elt, \'__dict__\'): return find_elt(comp_elt.__dict__, \'.\'.join(comps[1:]), match_last=match_last)\n\ndef import_mod(mod_name:str, ignore_errors=False):\n    ""Return module from `mod_name`.""\n    splits = str.split(mod_name, \'.\')\n    try:\n        if len(splits) > 1 : mod = importlib.import_module(\'.\' + \'.\'.join(splits[1:]), splits[0])\n        else: mod = importlib.import_module(mod_name)\n        return mod\n    except:\n        if not ignore_errors: print(f""Module {mod_name} doesn\'t exist."")\n\ndef show_doc_from_name(mod_name, ft_name:str, doc_string:bool=True, arg_comments:dict={}, alt_doc_string:str=\'\'):\n    ""Show documentation for `ft_name`, see `show_doc`.""\n    mod = import_mod(mod_name)\n    splits = str.split(ft_name, \'.\')\n    assert hasattr(mod, splits[0]), print(f""Module {mod_name} doesn\'t have a function named {splits[0]}."")\n    elt = getattr(mod, splits[0])\n    for i,split in enumerate(splits[1:]):\n        assert hasattr(elt, split), print(f""Class {\'.\'.join(splits[:i+1])} doesn\'t have a function named {split}."")\n        elt = getattr(elt, split)\n    show_doc(elt, doc_string, ft_name, arg_comments, alt_doc_string)\n\ndef get_exports(mod):\n    public_names = mod.__all__ if hasattr(mod, \'__all__\') else dir(mod)\n    #public_names.sort(key=str.lower)\n    return [o for o in public_names if not o.startswith(\'_\')]\n\ndef get_ft_names(mod, include_inner=False)->List[str]:\n    ""Return all the functions of module `mod`.""\n    # If the module has an attribute __all__, it picks those.\n    # Otherwise, it returns all the functions defined inside a module.\n    fn_names = []\n    for elt_name in get_exports(mod):\n        elt = getattr(mod,elt_name)\n        #This removes the files imported from elsewhere\n        try:    fname = inspect.getfile(elt)\n        except: continue\n        if mod.__file__.endswith(\'__init__.py\'):\n            if inspect.ismodule(elt): fn_names.append(elt_name)\n            else: continue\n        else:\n            if (fname != mod.__file__): continue\n            if inspect.isclass(elt) or inspect.isfunction(elt): fn_names.append(elt_name)\n            else: continue\n        if include_inner and inspect.isclass(elt) and not is_enum(elt.__class__):\n            fn_names.extend(get_inner_fts(elt))\n    return fn_names\n\ndef get_inner_fts(elt)->List[str]:\n    ""List the inner functions of a class.""\n    fts = []\n    for ft_name in elt.__dict__.keys():\n        if ft_name.startswith(\'_\'): continue\n        ft = getattr(elt, ft_name)\n        if inspect.isfunction(ft): fts.append(f\'{elt.__name__}.{ft_name}\')\n        if inspect.ismethod(ft): fts.append(f\'{elt.__name__}.{ft_name}\')\n        if inspect.isclass(ft): fts += [f\'{elt.__name__}.{n}\' for n in get_inner_fts(ft)]\n    return fts\n\ndef get_module_toc(mod_name):\n    ""Display table of contents for given `mod_name`.""\n    mod = import_mod(mod_name)\n    ft_names = mod.__all__ if hasattr(mod,\'__all__\') else get_ft_names(mod)\n    ft_names.sort(key = str.lower)\n    tabmat = \'\'\n    for ft_name in ft_names:\n        tabmat += f\'- [{ft_name}](#{ft_name})\\n\'\n        elt = getattr(mod, ft_name)\n        if inspect.isclass(elt) and not is_enum(elt.__class__):\n            in_ft_names = get_inner_fts(elt)\n            for name in in_ft_names:\n                tabmat += f\'  - [{name}](#{name})\\n\'\n    display(Markdown(tabmat))\n\ndef show_video(url):\n    ""Display video in `url`.""\n    data = f\'<iframe width=""560"" height=""315"" src=""{url}"" frameborder=""0"" allowfullscreen></iframe>\'\n    return display(HTML(data))\n\ndef show_video_from_youtube(code, start=0):\n    ""Display video from Youtube with a `code` and a `start` time.""\n    url = f\'https://www.youtube.com/embed/{code}?start={start}&amp;rel=0&amp;controls=0&amp;showinfo=0\'\n    return show_video(url)\n\ndef get_anchor(fn)->str:\n    if hasattr(fn,\'__qualname__\'): return fn.__qualname__\n    if inspect.ismethod(fn): return fn_name(fn.__self__) + \'.\' + fn_name(fn)\n    return fn_name(fn)\n\ndef fn_name(ft)->str:\n    if ft.__hash__ and ft in _typing_names: return _typing_names[ft]\n    if hasattr(ft, \'__name__\'):   return ft.__name__\n    elif hasattr(ft,\'_name\') and ft._name: return ft._name\n    elif hasattr(ft,\'__origin__\'): return str(ft.__origin__).split(\'.\')[-1]\n    else:                          return str(ft).split(\'.\')[-1]\n\ndef get_fn_link(ft)->str:\n    ""Return function link to notebook documentation of `ft`. Private functions link to source code""\n    ft = getattr(ft, \'__func__\', ft)\n    anchor = strip_fastai(get_anchor(ft))\n    module_name = strip_fastai(get_module_name(ft))\n    base = \'\' if use_relative_links else FASTAI_DOCS\n    return f\'{base}/{module_name}.html#{anchor}\'\n\ndef get_module_name(ft)->str: return inspect.getmodule(ft).__name__\n\ndef get_pytorch_link(ft)->str:\n    ""Returns link to pytorch docs of `ft`.""\n    name = ft.__name__\n    ext = \'.html\'\n    if name == \'device\': return f\'{PYTORCH_DOCS}tensor_attributes{ext}#torch-device\'\n    if name == \'Tensor\': return f\'{PYTORCH_DOCS}tensors{ext}#torch-tensor\'\n    if name.startswith(\'torchvision\'):\n        doc_path = get_module_name(ft).replace(\'.\', \'/\')\n        if inspect.ismodule(ft): name = name.replace(\'.\', \'-\')\n        return f\'{PYTORCH_DOCS}{doc_path}{ext}#{name}\'\n    if name.startswith(\'torch.nn\') and inspect.ismodule(ft): # nn.functional is special case\n        nn_link = name.replace(\'.\', \'-\')\n        return f\'{PYTORCH_DOCS}nn{ext}#{nn_link}\'\n    paths = get_module_name(ft).split(\'.\')\n    if len(paths) == 1: return f\'{PYTORCH_DOCS}{paths[0]}{ext}#{paths[0]}.{name}\'\n\n    offset = 1 if paths[1] == \'utils\' else 0 # utils is a pytorch special case\n    doc_path = paths[1+offset]\n    if inspect.ismodule(ft): return f\'{PYTORCH_DOCS}{doc_path}{ext}#module-{name}\'\n    fnlink = \'.\'.join(paths[:(2+offset)]+[name])\n    return f\'{PYTORCH_DOCS}{doc_path}{ext}#{fnlink}\'\n\ndef get_source_link(file, line, display_text=""[source]"", **kwargs)->str:\n    ""Returns github link for given file""\n    link = f""{SOURCE_URL}{file}#L{line}""\n    if display_text is None: return link\n    return f\'<a href=""{link}"" class=""source_link"" style=""float:right"">{display_text}</a>\'\n\ndef get_function_source(ft, **kwargs)->str:\n    ""Returns link to `ft` in source code.""\n    try: line = inspect.getsourcelines(ft)[1]\n    except Exception: return \'\'\n    mod_path = get_module_name(ft).replace(\'.\', \'/\') + \'.py\'\n    return get_source_link(mod_path, line, **kwargs)\n\ndef title_md(s:str, title_level:int, markdown=True):\n    res = \'#\' * title_level\n    if title_level: res += \' \'\n    return Markdown(res+s) if markdown else (res+s)\n\ndef jekyll_div(s,c,h,icon=None):\n    icon = ifnone(icon,c)\n    res = f\'<div markdown=""span"" class=""alert alert-{c}"" role=""alert""><i class=""fa fa-{c}-circle""></i> <b>{h}: </b>{s}</div>\'\n    display(Markdown(res))\n\ndef jekyll_note(s): return jekyll_div(s,\'info\',\'Note\')\ndef jekyll_warn(s): return jekyll_div(s,\'danger\',\'Warning\', \'exclamation\')\ndef jekyll_important(s): return jekyll_div(s,\'warning\',\'Important\')\n'"
fastai/gen_doc/nbtest.py,0,"b'""`gen_doc.nbtest` shows pytest documentation for module functions""\n\nimport inspect, os, re\nfrom os.path import abspath, dirname, join\nfrom collections import namedtuple\n\nfrom fastai.gen_doc import nbdoc\nfrom ..imports.core import *\nfrom .core import ifnone\nfrom .doctest import get_parent_func, relative_test_path, get_func_fq_name, DB_NAME\n\nfrom nbconvert import HTMLExporter\nfrom IPython.core import page\nfrom IPython.core.display import display, Markdown, HTML\n\n__all__ = [\'show_test\', \'doctest\', \'find_related_tests\', \'lookup_db\', \'find_test_matches\', \'find_test_files\', \'fuzzy_test_match\', \'get_pytest_html\']\n\nTestFunctionMatch = namedtuple(\'TestFunctionMatch\', [\'line_number\', \'line\'])\n\ndef show_test(elt)->str:\n    ""Show associated tests for a fastai function/class""\n    md = build_tests_markdown(elt)\n    display(Markdown(md))\n\ndef doctest(elt):\n    ""Inline notebook popup for `show_test`""\n    md = build_tests_markdown(elt)\n    output = nbdoc.md2html(md)\n    try:    page.page({\'text/html\': output})\n    except: display(Markdown(md))\n\ndef build_tests_markdown(elt):\n    fn_name = nbdoc.fn_name(elt)\n    md = \'\'\n    db_matches = [get_links(t) for t in lookup_db(elt)]\n    md += tests2md(db_matches, \'\')\n    try:\n        related = [get_links(t) for t in find_related_tests(elt)]\n        other_tests = [k for k in OrderedDict.fromkeys(related) if k not in db_matches]\n        md += tests2md(other_tests, f\'Some other tests where `{fn_name}` is used:\')\n    except OSError as e: pass\n\n    if len(md.strip())==0:\n        return (f\'No tests found for `{fn_name}`.\'\n                \' To contribute a test please refer to [this guide](/dev/test.html)\'\n                \' and [this discussion](https://forums.fast.ai/t/improving-expanding-functional-tests/32929).\')\n    return (f\'Tests found for `{fn_name}`: {md}\'\n            \'\\n\\nTo run tests please refer to this [guide](/dev/test.html#quick-guide).\')\n\ndef tests2md(tests, type_label:str):\n    if not tests: return \'\'\n    md = [f\'\\n\\n{type_label}\'] + [f\'* `{cmd}` {link}\' for link,cmd in sorted(tests, key=lambda k: k[1])]\n    return \'\\n\'.join(md)\n\ndef get_pytest_html(elt, anchor_id:str)->Tuple[str,str]:\n    md = build_tests_markdown(elt)\n    html = nbdoc.md2html(md).replace(\'\\n\',\'\') # nbconverter fails to parse markdown if it has both html and \'\\n\'\n    anchor_id = anchor_id.replace(\'.\', \'-\') + \'-pytest\'\n    link, body = get_pytest_card(html, anchor_id)\n    return link, body\n\ndef get_pytest_card(html, anchor_id):\n    ""creates a collapsible bootstrap card for `show_test`""\n    link = f\'<a class=""source_link"" data-toggle=""collapse"" data-target=""#{anchor_id}"" style=""float:right; padding-right:10px"">[test]</a>\'\n    body = (f\'<div class=""collapse"" id=""{anchor_id}""><div class=""card card-body pytest_card"">\'\n                f\'<a type=""button"" data-toggle=""collapse"" data-target=""#{anchor_id}"" class=""close"" aria-label=""Close""><span aria-hidden=""true"">&times;</span></a>\'\n                f\'{html}\'\n            \'</div></div>\')\n    return link, body\n\ndef lookup_db(elt)->List[Dict]:\n    ""Finds `this_test` entries from test_registry.json""\n    db_file = Path(abspath(join(dirname( __file__ ), \'..\')))/DB_NAME\n    if not db_file.exists():\n        raise Exception(f\'Could not find {db_file}. Please make sure it exists at ""{db_file}"" or run `make test`\')\n    with open(db_file, \'r\') as f:\n        db = json.load(f)\n    key = get_func_fq_name(elt)\n    return db.get(key, [])\n\ndef find_related_tests(elt)->Tuple[List[Dict],List[Dict]]:\n    ""Searches `fastai/tests` folder for any test functions related to `elt`""\n    related_matches = []\n    for test_file in find_test_files(elt):\n        fuzzy_matches = find_test_matches(elt, test_file)\n        related_matches.extend(fuzzy_matches)\n    return related_matches\n\ndef get_tests_dir(elt)->Path:\n    ""Absolute path of `fastai/tests` directory""\n    test_dir = Path(__file__).parent.parent.parent.resolve()/\'tests\'\n    if not test_dir.exists(): raise OSError(\'Could not find test directory at this location:\', test_dir)\n    return test_dir\n\ndef get_file(elt)->str:\n    if hasattr(elt, \'__wrapped__\'): elt = elt.__wrapped__\n    if not nbdoc.is_fastai_class(elt): return None\n    return inspect.getfile(elt)\n\ndef find_test_files(elt, exact_match:bool=False)->List[Path]:\n    ""Searches in `fastai/tests` directory for module tests""\n    test_dir = get_tests_dir(elt)\n    matches = [test_dir/o.name for o in os.scandir(test_dir) if _is_file_match(elt, o.name)]\n    # if len(matches) != 1: raise Error(\'Could not find exact file match:\', matches)\n    return matches\n\ndef _is_file_match(elt, file_name:str, exact_match:bool=False)->bool:\n    fp = get_file(elt)\n    if fp is None: return False\n    subdir = ifnone(_submodule_name(elt), \'\')\n    exact_re = \'\' if exact_match else \'\\w*\'\n    return re.match(f\'test_{subdir}\\w*{Path(fp).stem}{exact_re}\\.py\', file_name)\n\ndef _submodule_name(elt)->str:\n    ""Returns submodule - utils, text, vision, imports, etc.""\n    if inspect.ismodule(elt): return None\n    modules = elt.__module__.split(\'.\')\n    if len(modules) > 2:\n        return modules[1]\n    return None\n\ndef find_test_matches(elt, test_file:Path)->Tuple[List[Dict],List[Dict]]:\n    ""Find all functions in `test_file` related to `elt`""\n    lines = get_lines(test_file)\n    rel_path = relative_test_path(test_file)\n    fn_name = get_qualname(elt) if not inspect.ismodule(elt) else \'\'\n    return fuzzy_test_match(fn_name, lines, rel_path)\n\ndef get_qualname(elt):\n    return elt.__qualname__ if hasattr(elt, \'__qualname__\') else fn_name(elt)\n\ndef separate_comp(qualname:str):\n    if not isinstance(qualname, str): qualname = get_qualname(qualname)\n    parts = qualname.split(\'.\')\n    parts[-1] = remove_underscore(parts[-1])\n    if len(parts) == 1: return [], parts[0]\n    return parts[:-1], parts[-1]\n\ndef remove_underscore(fn_name):\n    if fn_name and fn_name[0] == \'_\': return fn_name[1:] # remove private method underscore prefix\n    return fn_name\n\ndef fuzzy_test_match(fn_name:str, lines:List[Dict], rel_path:str)->List[TestFunctionMatch]:\n    ""Find any lines where `fn_name` is invoked and return the parent test function""\n    fuzzy_line_matches = _fuzzy_line_match(fn_name, lines)\n    fuzzy_matches = [get_parent_func(lno, lines, ignore_missing=True) for lno,_ in fuzzy_line_matches]\n    fuzzy_matches = list(filter(None.__ne__, fuzzy_matches))\n    return [map_test(rel_path, lno, l) for lno,l in fuzzy_matches]\n\ndef _fuzzy_line_match(fn_name:str, lines)->List[TestFunctionMatch]:\n    ""Find any lines where `fn_name` is called""\n    result = []\n    _,fn_name = separate_comp(fn_name)\n    for idx,line in enumerate(lines):\n        if re.match(f\'.*[\\s\\.\\(]{fn_name}[\\.\\(]\', line):\n            result.append((idx,line))\n    return result\n\ndef get_lines(file:Path)->List[str]:\n    with open(file, \'r\') as f: return f.readlines()\n\ndef map_test(test_file, line, line_text):\n    ""Creates dictionary test format to match doctest api""\n    test_name = re.match(f\'\\s*def (test_\\w*)\', line_text).groups(0)[0]\n    return { \'file\': test_file, \'line\': line, \'test\': test_name }\n\ndef get_links(metadata)->Tuple[str,str]:\n    ""Returns source code link and pytest command""\n    return nbdoc.get_source_link(**metadata), pytest_command(**metadata)\n\ndef pytest_command(file:str, test:str, **kwargs)->str:\n    ""Returns CLI command to run specific test function""\n    return f\'pytest -sv {file}::{test}\'\n'"
fastai/imports/__init__.py,0,b'from .core import *\nfrom .torch import *\n'
fastai/imports/core.py,0,"b'import csv, gc, gzip, os, pickle, shutil, sys, warnings, yaml, io, subprocess\nimport math, matplotlib.pyplot as plt, numpy as np, pandas as pd, random\nimport scipy.stats, scipy.special\nimport abc, collections, hashlib, itertools, json, operator, pathlib\nimport mimetypes, inspect, typing, functools, importlib, weakref\nimport html, re, requests, tarfile, numbers, tempfile, bz2\n\nfrom abc import abstractmethod, abstractproperty\nfrom collections import Counter, defaultdict, namedtuple, OrderedDict\nfrom collections.abc import Iterable, Sized\nimport concurrent\nfrom concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\nfrom copy import copy, deepcopy\nfrom dataclasses import dataclass, field, InitVar\nfrom enum import Enum, IntEnum\nfrom functools import partial, reduce\nfrom pdb import set_trace\nfrom matplotlib import patches, patheffects\nfrom numpy import array, cos, exp, log, sin, tan, tanh\nfrom operator import attrgetter, itemgetter\nfrom pathlib import Path\nfrom warnings import warn\nfrom contextlib import contextmanager\nfrom fastprogress.fastprogress import MasterBar, ProgressBar\nfrom matplotlib.patches import Patch\nfrom pandas import Series, DataFrame\nfrom io import BufferedWriter, BytesIO\n\nimport pkg_resources\npkg_resources.require(""fastprogress>=0.2.1"")\nfrom fastprogress.fastprogress import master_bar, progress_bar\n\n#for type annotations\nfrom numbers import Number\nfrom typing import Any, AnyStr, Callable, Collection, Dict, Hashable, Iterator, List, Mapping, NewType, Optional\nfrom typing import Sequence, Tuple, TypeVar, Union\nfrom types import SimpleNamespace\n\ndef pd_max_colwidth(): return None if pd.__version__ >= ""1.0.0"" else -1\n\n\ndef try_import(module):\n    ""Try to import `module`. Returns module\'s object on success, None on failure""\n    try: return importlib.import_module(module)\n    except: return None\n\ndef have_min_pkg_version(package, version):\n    ""Check whether we have at least `version` of `package`. Returns True on success, False otherwise.""\n    try:\n        pkg_resources.require(f""{package}>={version}"")\n        return True\n    except:\n        return False\n'"
fastai/imports/torch.py,3,"b'import torch, torch.nn.functional as F\nfrom torch import ByteTensor, DoubleTensor, FloatTensor, HalfTensor, LongTensor, ShortTensor, Tensor\nfrom torch import nn, optim, as_tensor\nfrom torch.utils.data import BatchSampler, DataLoader, Dataset, Sampler, TensorDataset\nfrom torch.nn.utils import weight_norm, spectral_norm\n'"
fastai/tabular/__init__.py,0,"b""from .. import basics\nfrom ..basics import *\nfrom .data import *\nfrom .transform import *\nfrom .models import *\nfrom .learner import *\nfrom .. import tabular\n\n__all__ = [*basics.__all__, *data.__all__, *transform.__all__, *models.__all__, *learner.__all__, 'tabular']\n\n"""
fastai/tabular/data.py,1,"b'""Data loading pipeline for structured data support. Loads from pandas DataFrame""\nfrom ..torch_core import *\nfrom .transform import *\nfrom ..basic_data import *\nfrom ..data_block import *\nfrom pandas.api.types import is_numeric_dtype, is_categorical_dtype\n\n__all__ = [\'TabularDataBunch\', \'TabularLine\', \'TabularList\', \'TabularProcessor\']\n\nOptTabTfms = Optional[Collection[TabularProc]]\n\n#def emb_sz_rule(n_cat:int)->int: return min(50, (n_cat//2)+1)\ndef emb_sz_rule(n_cat:int)->int: return min(600, round(1.6 * n_cat**0.56))\n\ndef def_emb_sz(classes, n, sz_dict=None):\n    ""Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.""\n    sz_dict = ifnone(sz_dict, {})\n    n_cat = len(classes[n])\n    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n    return n_cat,sz\n\nclass TabularLine(ItemBase):\n    ""Basic item for tabular data.""\n    def __init__(self, cats, conts, classes, names):\n        self.cats,self.conts,self.classes,self.names = cats,conts,classes,names\n        self.data = [tensor(cats), tensor(conts)]\n\n    def __str__(self):\n        res = \'\'\n        for c, n in zip(self.cats, self.names[:len(self.cats)]):\n            res += f""{n} {(self.classes[n][c])}; ""\n        for c,n in zip(self.conts, self.names[len(self.cats):]):\n            res += f\'{n} {c:.4f}; \'\n        return res\n\nclass TabularProcessor(PreProcessor):\n    ""Regroup the `procs` in one `PreProcessor`.""\n    def __init__(self, ds:ItemBase=None, procs=None):\n        procs = ifnone(procs, ds.procs if ds is not None else None)\n        self.procs = listify(procs)\n\n    def process_one(self, item):\n        df = pd.DataFrame([item,item])\n        for proc in self.procs: proc(df, test=True)\n        if len(self.cat_names) != 0:\n            codes = np.stack([c.cat.codes.values for n,c in df[self.cat_names].items()], 1).astype(np.int64) + 1\n        else: codes = [[]]\n        if len(self.cont_names) != 0:\n            conts = np.stack([c.astype(\'float32\').values for n,c in df[self.cont_names].items()], 1)\n        else: conts = [[]]\n        classes = None\n        col_names = list(df[self.cat_names].columns.values) + list(df[self.cont_names].columns.values)\n        return TabularLine(codes[0], conts[0], classes, col_names)\n\n    def process(self, ds):\n        if ds.inner_df is None:\n            ds.classes,ds.cat_names,ds.cont_names = self.classes,self.cat_names,self.cont_names\n            ds.col_names = self.cat_names + self.cont_names\n            ds.preprocessed = True\n            return\n        for i,proc in enumerate(self.procs):\n            if isinstance(proc, TabularProc): proc(ds.inner_df, test=True)\n            else:\n                #cat and cont names may have been changed by transform (like Fill_NA)\n                proc = proc(ds.cat_names, ds.cont_names)\n                proc(ds.inner_df)\n                ds.cat_names,ds.cont_names = proc.cat_names,proc.cont_names\n                self.procs[i] = proc\n        self.cat_names,self.cont_names = ds.cat_names,ds.cont_names\n        if len(ds.cat_names) != 0:\n            ds.codes = np.stack([c.cat.codes.values for n,c in ds.inner_df[ds.cat_names].items()], 1).astype(np.int64) + 1\n            self.classes = ds.classes = OrderedDict({n:np.concatenate([[\'#na#\'],c.cat.categories.values])\n                                      for n,c in ds.inner_df[ds.cat_names].items()})\n            cat_cols = list(ds.inner_df[ds.cat_names].columns.values)\n        else: ds.codes,ds.classes,self.classes,cat_cols = None,None,None,[]\n        if len(ds.cont_names) != 0:\n            ds.conts = np.stack([c.astype(\'float32\').values for n,c in ds.inner_df[ds.cont_names].items()], 1)\n            cont_cols = list(ds.inner_df[ds.cont_names].columns.values)\n        else: ds.conts,cont_cols = None,[]\n        ds.col_names = cat_cols + cont_cols\n        ds.preprocessed = True\n\nclass TabularDataBunch(DataBunch):\n    ""Create a `DataBunch` suitable for tabular data.""\n    @classmethod\n    def from_df(cls, path, df:DataFrame, dep_var:str, valid_idx:Collection[int], procs:OptTabTfms=None,\n                cat_names:OptStrList=None, cont_names:OptStrList=None, classes:Collection=None, \n                test_df=None, bs:int=64, val_bs:int=None, num_workers:int=defaults.cpus, dl_tfms:Optional[Collection[Callable]]=None, \n                device:torch.device=None, collate_fn:Callable=data_collate, no_check:bool=False)->DataBunch:\n        ""Create a `DataBunch` from `df` and `valid_idx` with `dep_var`. `kwargs` are passed to `DataBunch.create`.""\n        cat_names = ifnone(cat_names, []).copy()\n        cont_names = ifnone(cont_names, list(set(df)-set(cat_names)-set(dep_var)))\n        procs = listify(procs)\n        src = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n                           .split_by_idx(valid_idx))\n        src = src.label_from_df(cols=dep_var) if classes is None else src.label_from_df(cols=dep_var, classes=classes)\n        if test_df is not None: src.add_test(TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names,\n                                                                 processor = src.train.x.processor))\n        return src.databunch(path=path, bs=bs, val_bs=val_bs, num_workers=num_workers, device=device, \n                             collate_fn=collate_fn, no_check=no_check)\n\nclass TabularList(ItemList):\n    ""Basic `ItemList` for tabular data.""\n    _item_cls=TabularLine\n    _processor=TabularProcessor\n    _bunch=TabularDataBunch\n    def __init__(self, items:Iterator, cat_names:OptStrList=None, cont_names:OptStrList=None,\n                 procs=None, **kwargs)->\'TabularList\':\n        super().__init__(range_of(items), **kwargs)\n        #dataframe is in inner_df, items is just a range of index\n        if cat_names is None:  cat_names = []\n        if cont_names is None: cont_names = []\n        self.cat_names,self.cont_names,self.procs = cat_names,cont_names,procs\n        self.copy_new += [\'cat_names\', \'cont_names\', \'procs\']\n        self.preprocessed = False\n\n    @classmethod\n    def from_df(cls, df:DataFrame, cat_names:OptStrList=None, cont_names:OptStrList=None, procs=None, **kwargs)->\'ItemList\':\n        ""Get the list of inputs in the `col` of `path/csv_name`.""\n        return cls(items=range(len(df)), cat_names=cat_names, cont_names=cont_names, procs=procs, inner_df=df.copy(), **kwargs)\n\n    def get(self, o):\n        if not self.preprocessed: return self.inner_df.iloc[o] if hasattr(self, \'inner_df\') else self.items[o]\n        codes = [] if self.codes is None else self.codes[o]\n        conts = [] if self.conts is None else self.conts[o]\n        return self._item_cls(codes, conts, self.classes, self.col_names)\n\n    def get_emb_szs(self, sz_dict=None):\n        ""Return the default embedding sizes suitable for this data or takes the ones in `sz_dict`.""\n        return [def_emb_sz(self.classes, n, sz_dict) for n in self.cat_names]\n\n    def reconstruct(self, t:Tensor):\n        return self._item_cls(t[0], t[1], self.classes, self.col_names)\n\n    def show_xys(self, xs, ys)->None:\n        ""Show the `xs` (inputs) and `ys` (targets).""\n        from IPython.display import display, HTML\n        items,names = [], xs[0].names + [\'target\']\n        for i, (x,y) in enumerate(zip(xs,ys)):\n            res = []\n            cats = x.cats if len(x.cats.size()) > 0 else []\n            conts = x.conts if len(x.conts.size()) > 0 else []\n            for c, n in zip(cats, x.names[:len(cats)]):\n                res.append(x.classes[n][c])\n            res += [f\'{c:.4f}\' for c in conts] + [y]\n            items.append(res)\n        items = np.array(items)\n        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)}, columns=names)\n        with pd.option_context(\'display.max_colwidth\', pd_max_colwidth()):\n            display(HTML(df.to_html(index=False)))\n\n    def show_xyzs(self, xs, ys, zs):\n        ""Show `xs` (inputs), `ys` (targets) and `zs` (predictions).""\n        from IPython.display import display, HTML\n        items,names = [], xs[0].names + [\'target\', \'prediction\']\n        for i, (x,y,z) in enumerate(zip(xs,ys,zs)):\n            res = []\n            cats = x.cats if len(x.cats.size()) > 0 else []\n            conts = x.conts if len(x.conts.size()) > 0 else []\n            for c, n in zip(cats, x.names[:len(cats)]):\n                res.append(str(x.classes[n][c]))\n            res += [f\'{c:.4f}\' for c in conts] + [y, z]\n            items.append(res)\n        items = np.array(items)\n        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)}, columns=names)\n        with pd.option_context(\'display.max_colwidth\', pd_max_colwidth()):\n            display(HTML(df.to_html(index=False)))\n'"
fastai/tabular/learner.py,0,"b'""`Learner` support for tabular data.""\nfrom ..torch_core import *\nfrom .transform import *\nfrom .data import *\nfrom .models import *\nfrom ..basic_data import *\nfrom ..basic_train import *\nfrom ..train import ClassificationInterpretation\n\n__all__ = [\'tabular_learner\']\n\ndef tabular_learner(data:DataBunch, layers:Collection[int], emb_szs:Dict[str,int]=None, metrics=None,\n        ps:Collection[float]=None, emb_drop:float=0., y_range:OptRange=None, use_bn:bool=True, **learn_kwargs):\n    ""Get a `Learner` using `data`, with `metrics`, including a `TabularModel` created using the remaining params.""\n    emb_szs = data.get_emb_szs(ifnone(emb_szs, {}))\n    model = TabularModel(emb_szs, len(data.cont_names), out_sz=data.c, layers=layers, ps=ps, emb_drop=emb_drop,\n                         y_range=y_range, use_bn=use_bn)\n    return Learner(data, model, metrics=metrics, **learn_kwargs)\n\n@classmethod\ndef _cl_int_from_learner(cls, learn:Learner, ds_type=DatasetType.Valid, activ:nn.Module=None):\n    ""Creates an instance of \'ClassificationInterpretation""\n    preds = learn.get_preds(ds_type=ds_type, activ=activ, with_loss=True)\n    return cls(learn, *preds, ds_type=ds_type)\n\ndef _cl_int_plot_tab_top_losses(self, k, largest:bool=True, return_table:bool=False)->Optional[plt.Figure]:\n    ""Generates a dataframe of \'top_losses\' along with their prediction, actual, loss, and probability of the actual class.""\n    tl_val, tl_idx = self.top_losses(k, largest)\n    classes = self.data.classes\n    cat_names = self.data.x.cat_names\n    cont_names = self.data.x.cont_names\n    df = pd.DataFrame(columns=[[\'Prediction\', \'Actual\', \'Loss\', \'Probability\'] + cat_names + cont_names])\n    for i, idx in enumerate(tl_idx):\n        da, cl = self.data.dl(self.ds_type).dataset[idx]\n        cl = int(cl)\n        t1 = str(da)\n        t1 = t1.split(\';\')\n        arr = []\n        arr.extend([classes[self.pred_class[idx]], classes[cl], f\'{self.losses[idx]:.2f}\',\n                    f\'{self.preds[idx][cl]:.2f}\'])\n        for x in range(len(t1)-1):\n            _, value = t1[x].rsplit(\' \', 1)\n            arr.append(value)\n        df.loc[i] = arr\n    display(df)\n    return_fig = return_table\n    if ifnone(return_fig, defaults.return_fig): return df\n\n\nClassificationInterpretation.from_learner = _cl_int_from_learner\nClassificationInterpretation.plot_tab_top_losses = _cl_int_plot_tab_top_losses\n\ndef _learner_interpret(learn:Learner, ds_type:DatasetType = DatasetType.Valid):\n    ""Create a \'ClassificationInterpretation\' object from \'learner\' on \'ds_type\'.""\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type)\n\nLearner.interpret = _learner_interpret'"
fastai/tabular/models.py,3,"b'from ..torch_core import *\nfrom ..layers import *\n\n__all__ = [\'TabularModel\']\n\nclass TabularModel(Module):\n    ""Basic model for tabular data.""\n    def __init__(self, emb_szs:ListSizes, n_cont:int, out_sz:int, layers:Collection[int], ps:Collection[float]=None,\n                 emb_drop:float=0., y_range:OptRange=None, use_bn:bool=True, bn_final:bool=False):\n        super().__init__()\n        ps = ifnone(ps, [0]*len(layers))\n        ps = listify(ps, layers)\n        self.embeds = nn.ModuleList([embedding(ni, nf) for ni,nf in emb_szs])\n        self.emb_drop = nn.Dropout(emb_drop)\n        self.bn_cont = nn.BatchNorm1d(n_cont)\n        n_emb = sum(e.embedding_dim for e in self.embeds)\n        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range\n        sizes = self.get_sizes(layers, out_sz)\n        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n        layers = []\n        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+ps,actns)):\n            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n        if bn_final: layers.append(nn.BatchNorm1d(sizes[-1]))\n        self.layers = nn.Sequential(*layers)\n\n    def get_sizes(self, layers, out_sz):\n        return [self.n_emb + self.n_cont] + layers + [out_sz]\n\n    def forward(self, x_cat:Tensor, x_cont:Tensor) -> Tensor:\n        if self.n_emb != 0:\n            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n            x = torch.cat(x, 1)\n            x = self.emb_drop(x)\n        if self.n_cont != 0:\n            x_cont = self.bn_cont(x_cont)\n            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n        x = self.layers(x)\n        if self.y_range is not None:\n            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n        return x'"
fastai/tabular/transform.py,0,"b'""Cleaning and feature engineering functions for structured data""\nfrom ..torch_core import *\nfrom pandas.api.types import is_numeric_dtype\nfrom datetime import date, datetime\nimport calendar\n\n__all__ = [\'add_datepart\', \'cont_cat_split\', \'Categorify\', \'FillMissing\', \'FillStrategy\', \'Normalize\', \'TabularProc\',\n           \'add_elapsed_times\', \'make_date\', \'add_cyclic_datepart\']\n\ndef make_date(df:DataFrame, date_field:str):\n    ""Make sure `df[field_name]` is of the right date type.""\n    field_dtype = df[date_field].dtype\n    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        field_dtype = np.datetime64\n    if not np.issubdtype(field_dtype, np.datetime64):\n        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n\ndef cyclic_dt_feat_names(time:bool=True, add_linear:bool=False)->List[str]:\n    ""Return feature names of date/time cycles as produced by `cyclic_dt_features`.""\n    fs = [\'cos\',\'sin\']\n    attr = [f\'{r}_{f}\' for r in \'weekday day_month month_year day_year\'.split() for f in fs]\n    if time: attr += [f\'{r}_{f}\' for r in \'hour clock min sec\'.split() for f in fs]\n    if add_linear: attr.append(\'year_lin\')\n    return attr\n\ndef cyclic_dt_features(d:Union[date,datetime], time:bool=True, add_linear:bool=False)->List[float]:\n    ""Calculate the cos and sin of date/time cycles.""\n    tt,fs = d.timetuple(), [np.cos, np.sin]\n    day_year,days_month = tt.tm_yday, calendar.monthrange(d.year, d.month)[1]\n    days_year = 366 if calendar.isleap(d.year) else 365\n    rs = d.weekday()/7, (d.day-1)/days_month, (d.month-1)/12, (day_year-1)/days_year\n    feats = [f(r * 2 * np.pi) for r in rs for f in fs]\n    if time and isinstance(d, datetime) and type(d) != date:\n        rs = tt.tm_hour/24, tt.tm_hour%12/12, tt.tm_min/60, tt.tm_sec/60\n        feats += [f(r * 2 * np.pi) for r in rs for f in fs]\n    if add_linear:\n        if type(d) == date: feats.append(d.year + rs[-1])\n        else:\n            secs_in_year = (datetime(d.year+1, 1, 1) - datetime(d.year, 1, 1)).total_seconds()\n            feats.append(d.year + ((d - datetime(d.year, 1, 1)).total_seconds() / secs_in_year))\n    return feats\n\ndef add_cyclic_datepart(df:DataFrame, field_name:str, prefix:str=None, drop:bool=True, time:bool=False, add_linear:bool=False):\n    ""Helper function that adds trigonometric date/time features to a date in the column `field_name` of `df`.""\n    make_date(df, field_name)\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub(\'[Dd]ate$\', \'\', field_name))\n    series = field.apply(partial(cyclic_dt_features, time=time, add_linear=add_linear))\n    columns = [prefix + c for c in cyclic_dt_feat_names(time, add_linear)]\n    df_feats = pd.DataFrame([item for item in series], columns=columns, index=series.index)\n    for column in columns: df[column] = df_feats[column]\n    if drop: df.drop(field_name, axis=1, inplace=True)\n    return df\n\ndef add_datepart(df:DataFrame, field_name:str, prefix:str=None, drop:bool=True, time:bool=False):\n    ""Helper function that adds columns relevant to a date in the column `field_name` of `df`.""\n    make_date(df, field_name)\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub(\'[Dd]ate$\', \'\', field_name))\n    attr = [\'Year\', \'Month\', \'Week\', \'Day\', \'Dayofweek\', \'Dayofyear\', \'Is_month_end\', \'Is_month_start\', \n            \'Is_quarter_end\', \'Is_quarter_start\', \'Is_year_end\', \'Is_year_start\']\n    if time: attr = attr + [\'Hour\', \'Minute\', \'Second\']\n    for n in attr: df[prefix + n] = getattr(field.dt, n.lower())\n    df[prefix + \'Elapsed\'] = field.astype(np.int64) // 10 ** 9\n    if drop: df.drop(field_name, axis=1, inplace=True)\n    return df\n\ndef _get_elapsed(df:DataFrame,field_names:Collection[str], date_field:str, base_field:str, prefix:str):\n    for f in field_names:\n        day1 = np.timedelta64(1, \'D\')\n        last_date,last_base,res = np.datetime64(),None,[]\n        for b,v,d in zip(df[base_field].values, df[f].values, df[date_field].values):\n            if last_base is None or b != last_base:\n                last_date,last_base = np.datetime64(),b\n            if v: last_date = d\n            res.append(((d-last_date).astype(\'timedelta64[D]\') / day1))\n        df[prefix + f] = res\n    return df\n\ndef add_elapsed_times(df:DataFrame, field_names:Collection[str], date_field:str, base_field:str):\n    field_names = listify(field_names)\n    #Make sure date_field is a date and base_field a bool\n    df[field_names] = df[field_names].astype(\'bool\')\n    make_date(df, date_field)\n    \n    work_df = df[field_names + [date_field, base_field]]\n    work_df = work_df.sort_values([base_field, date_field])\n    work_df = _get_elapsed(work_df, field_names, date_field, base_field, \'After\')\n    work_df = work_df.sort_values([base_field, date_field], ascending=[True, False])\n    work_df = _get_elapsed(work_df, field_names, date_field, base_field, \'Before\')\n    \n    for a in [\'After\' + f for f in field_names] + [\'Before\' + f for f in field_names]:\n        work_df[a] = work_df[a].fillna(0).astype(int)  \n    \n    for a,s in zip([True, False], [\'_bw\', \'_fw\']):\n        work_df = work_df.set_index(date_field)\n        tmp = (work_df[[base_field] + field_names].sort_index(ascending=a)\n                      .groupby(base_field).rolling(7, min_periods=1).sum())\n        tmp.drop(base_field,1,inplace=True)\n        tmp.reset_index(inplace=True)\n        work_df.reset_index(inplace=True)\n        work_df = work_df.merge(tmp, \'left\', [date_field, base_field], suffixes=[\'\', s])\n    work_df.drop(field_names,1,inplace=True)\n    return df.merge(work_df, \'left\', [date_field, base_field])\n\ndef cont_cat_split(df, max_card=20, dep_var=None)->Tuple[List,List]:\n    ""Helper function that returns column names of cont and cat variables from given df.""\n    cont_names, cat_names = [], []\n    for label in df:\n        if label == dep_var: continue\n        if df[label].dtype == int and df[label].unique().shape[0] > max_card or df[label].dtype == float: cont_names.append(label)\n        else: cat_names.append(label)\n    return cont_names, cat_names\n        \n@dataclass\nclass TabularProc():\n    ""A processor for tabular dataframes.""\n    cat_names:StrList\n    cont_names:StrList\n\n    def __call__(self, df:DataFrame, test:bool=False):\n        ""Apply the correct function to `df` depending on `test`.""\n        func = self.apply_test if test else self.apply_train\n        func(df)\n\n    def apply_train(self, df:DataFrame):\n        ""Function applied to `df` if it\'s the train set.""\n        raise NotImplementedError\n    def apply_test(self, df:DataFrame):\n        ""Function applied to `df` if it\'s the test set.""\n        self.apply_train(df)\n\nclass Categorify(TabularProc):\n    ""Transform the categorical variables to that type.""\n    def apply_train(self, df:DataFrame):\n        ""Transform `self.cat_names` columns in categorical.""\n        self.categories = {}\n        for n in self.cat_names:\n            df.loc[:,n] = df.loc[:,n].astype(\'category\').cat.as_ordered()\n            self.categories[n] = df[n].cat.categories\n\n    def apply_test(self, df:DataFrame):\n        ""Transform `self.cat_names` columns in categorical using the codes decided in `apply_train`.""\n        for n in self.cat_names:\n            df.loc[:,n] = pd.Categorical(df[n], categories=self.categories[n], ordered=True)\n\nFillStrategy = IntEnum(\'FillStrategy\', \'MEDIAN COMMON CONSTANT\')\n\n@dataclass\nclass FillMissing(TabularProc):\n    ""Fill the missing values in continuous columns.""\n    fill_strategy:FillStrategy=FillStrategy.MEDIAN\n    add_col:bool=True\n    fill_val:float=0.\n    def apply_train(self, df:DataFrame):\n        ""Fill missing values in `self.cont_names` according to `self.fill_strategy`.""\n        self.na_dict = {}\n        for name in self.cont_names:\n            if pd.isnull(df[name]).sum():\n                if self.add_col:\n                    df[name+\'_na\'] = pd.isnull(df[name])\n                    if name+\'_na\' not in self.cat_names: self.cat_names.append(name+\'_na\')\n                if self.fill_strategy == FillStrategy.MEDIAN: filler = df[name].median()\n                elif self.fill_strategy == FillStrategy.CONSTANT: filler = self.fill_val\n                else: filler = df[name].dropna().value_counts().idxmax()\n                df[name] = df[name].fillna(filler)\n                self.na_dict[name] = filler\n\n    def apply_test(self, df:DataFrame):\n        ""Fill missing values in `self.cont_names` like in `apply_train`.""\n        for name in self.cont_names:\n            if name in self.na_dict:\n                if self.add_col:\n                    df[name+\'_na\'] = pd.isnull(df[name])\n                    if name+\'_na\' not in self.cat_names: self.cat_names.append(name+\'_na\')\n                df[name] = df[name].fillna(self.na_dict[name])\n            elif pd.isnull(df[name]).sum() != 0:\n                raise Exception(f""""""There are nan values in field {name} but there were none in the training set. \n                Please fix those manually."""""")\n\nclass Normalize(TabularProc):\n    ""Normalize the continuous variables.""\n    def apply_train(self, df:DataFrame):\n        ""Compute the means and stds of `self.cont_names` columns to normalize them.""\n        self.means,self.stds = {},{}\n        for n in self.cont_names:\n            assert is_numeric_dtype(df[n]), (f""""""Cannot normalize \'{n}\' column as it isn\'t numerical.\n                Are you sure it doesn\'t belong in the categorical set of columns?"""""")\n            self.means[n],self.stds[n] = df[n].mean(),df[n].std()\n            df[n] = (df[n]-self.means[n]) / (1e-7 + self.stds[n])\n\n    def apply_test(self, df:DataFrame):\n        ""Normalize `self.cont_names` with the same statistics as in `apply_train`.""\n        for n in self.cont_names:\n            df[n] = (df[n]-self.means[n]) / (1e-7 + self.stds[n])\n'"
fastai/text/__init__.py,0,"b""from .. import basics\nfrom ..basics import *\nfrom .learner import *\nfrom .data import *\nfrom .transform import *\nfrom .interpret import *\nfrom .models import *\nfrom .. import text\n\n__all__ =  [*basics.__all__, *learner.__all__, *data.__all__, *transform.__all__, *models.__all__, *interpret.__all__, 'text']\n\n"""
fastai/text/data.py,3,"b'""NLP data loading pipeline. Supports csv, folders, and preprocessed data.""\nfrom ..torch_core import *\nfrom .transform import *\nfrom ..basic_data import *\nfrom ..data_block import *\nfrom ..layers import *\nfrom ..callback import Callback\n\n__all__ = [\'LanguageModelPreLoader\', \'SortSampler\', \'SortishSampler\', \'TextList\', \'pad_collate\', \'TextDataBunch\',\n           \'TextLMDataBunch\', \'TextClasDataBunch\', \'Text\', \'open_text\', \'TokenizeProcessor\', \'NumericalizeProcessor\',\n           \'OpenFileProcessor\', \'LMLabelList\', \'LMTextList\', \'SPProcessor\']\n\nTextMtd = IntEnum(\'TextMtd\', \'DF TOK IDS\')\ntext_extensions = {\'.txt\'}\n\nclass LanguageModelPreLoader(Callback):\n    ""Transforms the tokens in `dataset` to a stream of contiguous batches for language modelling.""\n\n    class CircularIndex():\n        ""Handles shuffle, direction of indexing, wraps around to head tail in the ragged array as needed""\n        def __init__(self, length:int, forward:bool): self.idx, self.forward = np.arange(length), forward\n        def __getitem__(self, i):\n            return self.idx[ i%len(self.idx) if self.forward else len(self.idx)-1-i%len(self.idx)]\n        def __len__(self) -> int: return len(self.idx)\n        def shuffle(self): np.random.shuffle(self.idx)\n\n    def __init__(self, dataset:LabelList, lengths:Collection[int]=None, bs:int=32, bptt:int=70, backwards:bool=False,\n                 shuffle:bool=False):\n        self.dataset,self.bs,self.bptt,self.shuffle,self.backwards,self.lengths = dataset,bs,bptt,shuffle,backwards,lengths\n        self.bs *= num_distrib() or 1\n        self.totalToks,self.ite_len,self.idx = int(0),None,None\n\n    def __len__(self):\n        if self.ite_len is None:\n            if self.lengths is None: self.lengths = np.array([len(item) for item in self.dataset.x.items])\n            self.totalToks = self.lengths.sum()\n            self.ite_len   = self.bs*int( math.ceil( self.totalToks/(self.bptt*self.bs) )) if self.item is None else 1\n        return self.ite_len\n\n    def __getattr__(self,k:str)->Any: return getattr(self.dataset, k)\n\n    def allocate_buffers(self):\n        ""Create the ragged array that will be filled when we ask for items.""\n        if self.ite_len is None: len(self)\n        self.idx   = LanguageModelPreLoader.CircularIndex(len(self.dataset.x.items), not self.backwards)\n        self.batch = np.zeros((self.bs, self.bptt+1), dtype=np.int64)\n        self.batch_x, self.batch_y = self.batch[:,0:self.bptt], self.batch[:,1:self.bptt+1]\n        #ro: index of the text we\'re at inside our datasets for the various batches\n        self.ro    = np.zeros(self.bs, dtype=np.int64)\n        #ri: index of the token we\'re at inside our current text for the various batches\n        self.ri    = np.zeros(self.bs, dtype=np.int)\n\n    def on_epoch_begin(self, **kwargs):\n        if self.idx is None or len(self.idx) != len(self.dataset.x.items): self.allocate_buffers()\n        elif self.shuffle:   self.idx.shuffle()\n        self.idx.forward = not self.backwards\n\n        step = self.totalToks / self.bs\n        ln_rag, countTokens, i_rag = 0, 0, -1\n        for i in range(0,self.bs):\n            #Compute the initial values for ro and ri\n            while ln_rag + countTokens <= int(step * i):\n                countTokens += ln_rag\n                i_rag       += 1\n                ln_rag       = self.lengths[self.idx[i_rag]]\n            self.ro[i] = i_rag\n            self.ri[i] = ( ln_rag - int(step * i - countTokens) ) if self.backwards else int(step * i - countTokens)\n\n    #Training dl gets on_epoch_begin called, val_dl, on_epoch_end\n    def on_epoch_end(self, **kwargs): self.on_epoch_begin()\n\n    def __getitem__(self, k:int):\n        j = k % self.bs\n        if self.item is not None: return self.dataset[0]\n        if self.idx is None: self.on_epoch_begin()\n        self.ro[j],self.ri[j] = self.fill_row(not self.backwards, self.dataset.x.items, self.idx, self.batch[j],\n                                              self.ro[j], self.ri[j], overlap=1, lengths=self.lengths)\n        return self.batch_x[j], self.batch_y[j]\n\n    def fill_row(self, forward, items, idx, row, ro, ri, overlap,lengths):\n        ""Fill the row with tokens from the ragged array. --OBS-- overlap != 1 has not been implemented""\n        ibuf = n = 0\n        ro  -= 1\n        while ibuf < row.size:\n            ro   += 1\n            ix    = idx[ro]\n            rag   = items[ix]\n            if forward:\n                ri = 0 if ibuf else ri\n                n  = min(lengths[ix] - ri, row.size - ibuf)\n                row[ibuf:ibuf+n] = rag[ri:ri+n]\n            else:\n                ri = lengths[ix] if ibuf else ri\n                n  = min(ri, row.size - ibuf)\n                row[ibuf:ibuf+n] = rag[ri-n:ri][::-1]\n            ibuf += n\n        return ro, ri + ((n-overlap) if forward else -(n-overlap))\n\nclass SortSampler(Sampler):\n    ""Go through the text data by order of length.""\n\n    def __init__(self, data_source:NPArrayList, key:KeyFunc): self.data_source,self.key = data_source,key\n    def __len__(self) -> int: return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range_of(self.data_source), key=self.key, reverse=True))\n\nclass SortishSampler(Sampler):\n    ""Go through the text data by order of length with a bit of randomness.""\n\n    def __init__(self, data_source:NPArrayList, key:KeyFunc, bs:int):\n        self.data_source,self.key,self.bs = data_source,key,bs\n\n    def __len__(self) -> int: return len(self.data_source)\n\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs*50\n        ck_idx = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n        sort_idx = np.concatenate([sorted(s, key=self.key, reverse=True) for s in ck_idx])\n        sz = self.bs\n        ck_idx = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n        max_ck = np.argmax([self.key(ck[0]) for ck in ck_idx])  # find the chunk with the largest key,\n        ck_idx[0],ck_idx[max_ck] = ck_idx[max_ck],ck_idx[0]     # then make sure it goes first.\n        sort_idx = np.concatenate(np.random.permutation(ck_idx[1:])) if len(ck_idx) > 1 else np.array([],dtype=np.int)\n        sort_idx = np.concatenate((ck_idx[0], sort_idx))\n        return iter(sort_idx)\n\ndef pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n    ""Function that collect samples and adds padding. Flips token order if needed""\n    samples = to_data(samples)\n    max_len = max([len(s[0]) for s in samples])\n    res = torch.zeros(len(samples), max_len).long() + pad_idx\n    if backwards: pad_first = not pad_first\n    for i,s in enumerate(samples):\n        if pad_first: res[i,-len(s[0]):] = LongTensor(s[0])\n        else:         res[i,:len(s[0]):] = LongTensor(s[0])\n    if backwards: res = res.flip(1)\n    return res, tensor(np.array([s[1] for s in samples]))\n\ndef _get_processor(tokenizer:Tokenizer=None, vocab:Vocab=None, chunksize:int=10000, max_vocab:int=60000,\n                   min_freq:int=2, mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False):\n    return [TokenizeProcessor(tokenizer=tokenizer, chunksize=chunksize, \n                              mark_fields=mark_fields, include_bos=include_bos, include_eos=include_eos),\n            NumericalizeProcessor(vocab=vocab, max_vocab=max_vocab, min_freq=min_freq)]\n\nclass TextDataBunch(DataBunch):\n    ""General class to get a `DataBunch` for NLP. Subclassed by `TextLMDataBunch` and `TextClasDataBunch`.""\n\n    @classmethod\n    def from_ids(cls, path:PathOrStr, vocab:Vocab, train_ids:Collection[Collection[int]], valid_ids:Collection[Collection[int]],\n                 test_ids:Collection[Collection[int]]=None, train_lbls:Collection[Union[int,float]]=None,\n                 valid_lbls:Collection[Union[int,float]]=None, classes:Collection[Any]=None,\n                 processor:PreProcessor=None, **kwargs) -> DataBunch:\n        ""Create a `TextDataBunch` from ids, labels and a `vocab`. `kwargs` are passed to the dataloader creation.""\n        src = ItemLists(path, TextList(train_ids, vocab, path=path, processor=[]),\n                        TextList(valid_ids, vocab, path=path, processor=[]))\n        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_lists(train_lbls, valid_lbls, classes=classes, processor=[])\n        if not is1d(train_lbls): src.train.y.one_hot,src.valid.y.one_hot = True,True\n        if test_ids is not None: src.add_test(TextList(test_ids, vocab, path=path), label=train_lbls[0])\n        src.valid.x.processor = ifnone(processor, [TokenizeProcessor(), NumericalizeProcessor(vocab=vocab)])\n        if classes is not None: src.valid.y.processor = ifnone(processor, [CategoryProcessor(src.valid.y)])\n        return src.databunch(**kwargs)\n\n    @classmethod\n    def load(cls, path:PathOrStr, cache_name:PathOrStr=\'tmp\', processor:PreProcessor=None, **kwargs):\n        ""Load a `TextDataBunch` from `path/cache_name`. `kwargs` are passed to the dataloader creation.""\n        warn(""""""This method is deprecated and only kept to load data serialized in v1.0.43 or earlier.\n                Use `load_data` for data saved with v1.0.44 or later."""""", DeprecationWarning)\n        cache_path = Path(path)/cache_name\n        vocab = Vocab(pickle.load(open(cache_path/\'itos.pkl\',\'rb\')))\n        train_ids,train_lbls = np.load(cache_path/f\'train_ids.npy\'), np.load(cache_path/f\'train_lbl.npy\')\n        valid_ids,valid_lbls = np.load(cache_path/f\'valid_ids.npy\'), np.load(cache_path/f\'valid_lbl.npy\')\n        test_ids = np.load(cache_path/f\'test_ids.npy\') if os.path.isfile(cache_path/f\'test_ids.npy\') else None\n        classes = loadtxt_str(cache_path/\'classes.txt\') if os.path.isfile(cache_path/\'classes.txt\') else None\n        return cls.from_ids(path, vocab, train_ids, valid_ids, test_ids, train_lbls, valid_lbls, classes, processor, **kwargs)\n\n    @classmethod#TODO: test\n    def from_tokens(cls, path:PathOrStr, trn_tok:Collection[Collection[str]], trn_lbls:Collection[Union[int,float]],\n                 val_tok:Collection[Collection[str]], val_lbls:Collection[Union[int,float]], vocab:Vocab=None,\n                 tst_tok:Collection[Collection[str]]=None, classes:Collection[Any]=None, max_vocab:int=60000, min_freq:int=3,\n                 **kwargs) -> DataBunch:\n        ""Create a `TextDataBunch` from tokens and labels. `kwargs` are passed to the dataloader creation.""\n        processor = NumericalizeProcessor(vocab=vocab, max_vocab=max_vocab, min_freq=min_freq)\n        src = ItemLists(path, TextList(trn_tok, path=path, processor=processor),\n                        TextList(val_tok, path=path, processor=processor))\n        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_lists(trn_lbls, val_lbls, classes=classes)\n        if tst_tok is not None: src.add_test(TextList(tst_tok, path=path))\n        return src.databunch(**kwargs)\n\n    @classmethod\n    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n                label_cols:IntsOrStrs=0, label_delim:str=None, chunksize:int=10000, max_vocab:int=60000,\n                min_freq:int=2, mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False, **kwargs) -> DataBunch:\n        ""Create a `TextDataBunch` from DataFrames. `kwargs` are passed to the dataloader creation.""\n        processor = _get_processor(tokenizer=tokenizer, vocab=vocab, chunksize=chunksize, max_vocab=max_vocab,\n                                   min_freq=min_freq, mark_fields=mark_fields, \n                                   include_bos=include_bos, include_eos=include_eos)\n        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n        if cls==TextLMDataBunch: src = src.label_for_lm()\n        else: \n            if label_delim is not None: src = src.label_from_df(cols=label_cols, classes=classes, label_delim=label_delim)\n            else: src = src.label_from_df(cols=label_cols, classes=classes)\n        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n        return src.databunch(**kwargs)\n\n    @classmethod\n    def from_csv(cls, path:PathOrStr, csv_name, valid_pct:float=0.2, test:Optional[str]=None,\n                 tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, delimiter:str=None, header=\'infer\',\n                 text_cols:IntsOrStrs=1, label_cols:IntsOrStrs=0, label_delim:str=None,\n                 chunksize:int=10000, max_vocab:int=60000, min_freq:int=2, \n                 mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False, **kwargs) -> DataBunch:\n        ""Create a `TextDataBunch` from texts in csv files. `kwargs` are passed to the dataloader creation.""\n        df = pd.read_csv(Path(path)/csv_name, header=header, delimiter=delimiter)\n        df = df.iloc[np.random.permutation(len(df))]\n        cut = int(valid_pct * len(df)) + 1\n        train_df, valid_df = df[cut:], df[:cut]\n        test_df = None if test is None else pd.read_csv(Path(path)/test, header=header, delimiter=delimiter)\n        return cls.from_df(path, train_df, valid_df, test_df, tokenizer=tokenizer, vocab=vocab, classes=classes, text_cols=text_cols,\n                           label_cols=label_cols, label_delim=label_delim, chunksize=chunksize, max_vocab=max_vocab,\n                           min_freq=min_freq, mark_fields=mark_fields, \n                           include_bos=include_bos, include_eos=include_eos, **kwargs)\n\n    @classmethod\n    def from_folder(cls, path:PathOrStr, train:str=\'train\', valid:str=\'valid\', test:Optional[str]=None,\n                    classes:Collection[Any]=None, tokenizer:Tokenizer=None, vocab:Vocab=None, chunksize:int=10000, max_vocab:int=60000,\n                    min_freq:int=2, mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False, **kwargs):\n        ""Create a `TextDataBunch` from text files in folders.""\n        path = Path(path).absolute()\n        processor = [OpenFileProcessor()] + _get_processor(tokenizer=tokenizer, vocab=vocab, chunksize=chunksize, max_vocab=max_vocab,\n                                   min_freq=min_freq, mark_fields=mark_fields, include_bos=include_bos, include_eos=include_eos)\n        src = (TextList.from_folder(path, processor=processor)\n                       .split_by_folder(train=train, valid=valid))\n        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_folder(classes=classes)\n        if test is not None: src.add_test_folder(path/test)\n        return src.databunch(**kwargs)\n\nclass TextLMDataBunch(TextDataBunch):\n    ""Create a `TextDataBunch` suitable for training a language model.""\n    @classmethod\n    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr=\'.\', no_check:bool=False, bs=64, val_bs:int=None,\n               num_workers:int=0, device:torch.device=None, collate_fn:Callable=data_collate,\n               dl_tfms:Optional[Collection[Callable]]=None, bptt:int=70, backwards:bool=False, **dl_kwargs) -> DataBunch:\n        ""Create a `TextDataBunch` in `path` from the `datasets` for language modelling. Passes `**dl_kwargs` on to `DataLoader()`""\n        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n        val_bs = ifnone(val_bs, bs)\n        datasets = [LanguageModelPreLoader(ds, shuffle=(i==0), bs=(bs if i==0 else val_bs), bptt=bptt, backwards=backwards)\n                    for i,ds in enumerate(datasets)]\n        val_bs = bs\n        dls = [DataLoader(d, b, shuffle=False, **dl_kwargs) for d,b in zip(datasets, (bs,val_bs,val_bs,val_bs)) if d is not None]\n        return cls(*dls, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)\n\nclass TextClasDataBunch(TextDataBunch):\n    ""Create a `TextDataBunch` suitable for training an RNN classifier.""\n    @classmethod\n    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr=\'.\', bs:int=32, val_bs:int=None, pad_idx=1,\n               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:\n        ""Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`""\n        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n        val_bs = ifnone(val_bs, bs)\n        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\n        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n        dataloaders = [train_dl]\n        for ds in datasets[1:]:\n            lengths = [len(t) for t in ds.x.items]\n            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)\n\ndef open_text(fn:PathOrStr, enc=\'utf-8\'):\n    ""Read the text in `fn`.""\n    with open(fn,\'r\', encoding = enc) as f: return \'\'.join(f.readlines())\n\nclass Text(ItemBase):\n    ""Basic item for <code>text</code> data in numericalized `ids`.""\n    def __init__(self, ids, text): self.data,self.text = np.array(ids, dtype=np.int64),text\n    def __str__(self):  return str(self.text)\n\nclass TokenizeProcessor(PreProcessor):\n    ""`PreProcessor` that tokenizes the texts in `ds`.""\n    def __init__(self, ds:ItemList=None, tokenizer:Tokenizer=None, chunksize:int=10000, \n                 mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False):\n        self.tokenizer,self.chunksize,self.mark_fields = ifnone(tokenizer, Tokenizer()),chunksize,mark_fields\n        self.include_bos, self.include_eos = include_bos, include_eos\n\n    def process_one(self, item):\n        return self.tokenizer._process_all_1(_join_texts([item], self.mark_fields, self.include_bos, self.include_eos))[0]\n\n    def process(self, ds):\n        ds.items = _join_texts(ds.items, self.mark_fields, self.include_bos, self.include_eos)\n        tokens = []\n        for i in progress_bar(range(0,len(ds),self.chunksize), leave=False):\n            tokens += self.tokenizer.process_all(ds.items[i:i+self.chunksize])\n        ds.items = tokens\n\nclass NumericalizeProcessor(PreProcessor):\n    ""`PreProcessor` that numericalizes the tokens in `ds`.""\n    def __init__(self, ds:ItemList=None, vocab:Vocab=None, max_vocab:int=60000, min_freq:int=3):\n        vocab = ifnone(vocab, ds.vocab if ds is not None else None)\n        self.vocab,self.max_vocab,self.min_freq = vocab,max_vocab,min_freq\n\n    def process_one(self,item): return np.array(self.vocab.numericalize(item), dtype=np.int64)\n    def process(self, ds):\n        if self.vocab is None: self.vocab = Vocab.create(ds.items, self.max_vocab, self.min_freq)\n        ds.vocab = self.vocab\n        super().process(ds)\n\nclass OpenFileProcessor(PreProcessor):\n    ""`PreProcessor` that opens the filenames and read the texts.""\n    def process(self, ds:Collection): ds.items = array([self.process_one(item) for item in ds.items], dtype=np.object)\n    def process_one(self,item): return open_text(item) if isinstance(item, Path) else item\n\nclass TextList(ItemList):\n    ""Basic `ItemList` for text data.""\n    _bunch = TextClasDataBunch\n    _processor = [TokenizeProcessor, NumericalizeProcessor]\n    _is_lm = False\n\n    def __init__(self, items:Iterator, vocab:Vocab=None, pad_idx:int=1, sep=\' \', **kwargs):\n        super().__init__(items, **kwargs)\n        self.vocab,self.pad_idx,self.sep = vocab,pad_idx,sep\n        self.copy_new += [\'vocab\', \'pad_idx\', \'sep\']\n\n    def get(self, i):\n        o = super().get(i)\n        return o if self.vocab is None else Text(o, self.vocab.textify(o, self.sep))\n\n    def label_for_lm(self, **kwargs):\n        ""A special labelling method for language models.""\n        self.__class__ = LMTextList\n        kwargs[\'label_cls\'] = LMLabelList\n        return self.label_const(0, **kwargs)\n\n    def reconstruct(self, t:Tensor):\n        idx_min = (t != self.pad_idx).nonzero().min()\n        idx_max = (t != self.pad_idx).nonzero().max()\n        return Text(t[idx_min:idx_max+1], self.vocab.textify(t[idx_min:idx_max+1]))\n\n    @classmethod\n    def from_folder(cls, path:PathOrStr=\'.\', extensions:Collection[str]=text_extensions, vocab:Vocab=None,\n                    processor:PreProcessor=None, **kwargs)->\'TextList\':\n        ""Get the list of files in `path` that have a text suffix. `recurse` determines if we search subfolders.""\n        processor = ifnone(processor, [OpenFileProcessor(), TokenizeProcessor(), NumericalizeProcessor(vocab=vocab)])\n        return super().from_folder(path=path, extensions=extensions, processor=processor, **kwargs)\n\n    def show_xys(self, xs, ys, max_len:int=70)->None:\n        ""Show the `xs` (inputs) and `ys` (targets). `max_len` is the maximum number of tokens displayed.""\n        from IPython.display import display, HTML\n        names = [\'idx\',\'text\'] if self._is_lm else [\'text\',\'target\']\n        items = []\n        for i, (x,y) in enumerate(zip(xs,ys)):\n            txt_x = \' \'.join(x.text.split(\' \')[:max_len]) if max_len is not None else x.text\n            items.append([i, txt_x] if self._is_lm else [txt_x, y])\n        items = np.array(items)\n        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)}, columns=names)\n        with pd.option_context(\'display.max_colwidth\', pd_max_colwidth()):\n            display(HTML(df.to_html(index=False)))\n\n    def show_xyzs(self, xs, ys, zs, max_len:int=70):\n        ""Show `xs` (inputs), `ys` (targets) and `zs` (predictions). `max_len` is the maximum number of tokens displayed.""\n        from IPython.display import display, HTML\n        items,names = [],[\'text\',\'target\',\'prediction\']\n        for i, (x,y,z) in enumerate(zip(xs,ys,zs)):\n            txt_x = \' \'.join(x.text.split(\' \')[:max_len]) if max_len is not None else x.text\n            items.append([txt_x, y, z])\n        items = np.array(items)\n        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)}, columns=names)\n        with pd.option_context(\'display.max_colwidth\', pd_max_colwidth()):\n            display(HTML(df.to_html(index=False)))\n\nclass LMLabelList(EmptyLabelList):\n    ""Basic `ItemList` for dummy labels.""\n    def __init__(self, items:Iterator, **kwargs):\n        super().__init__(items, **kwargs)\n        self.loss_func = CrossEntropyFlat()\n\nclass LMTextList(TextList):\n    ""Special `TextList` for a language model.""\n    _bunch = TextLMDataBunch\n    _is_lm = True\n\ndef _join_texts(texts:Collection[str], mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False):\n    if not isinstance(texts, np.ndarray): texts = np.array(texts)\n    if is1d(texts): texts = texts[:,None]\n    df = pd.DataFrame({i:texts[:,i] for i in range(texts.shape[1])})\n    bos_tok = f\'{BOS} \' if include_bos else \'\'\n    text_col = f\'{bos_tok}{FLD} {1} \' + df[0].astype(str) if mark_fields else f\'{bos_tok}\' + df[0].astype(str)\n    for i in range(1,len(df.columns)):\n        text_col += (f\' {FLD} {i+1} \' if mark_fields else \' \') + df[i].astype(str)\n    if include_eos: text_col = text_col + f\' {EOS}\'\n    return text_col.values\n\ndef apply_rules(text, pre_rules=None, post_rules=None):\n    ""Apply `pre_rules` and `post_rules` to `text`""\n    text = text.strip(\' \')\n    for r in ifnone(pre_rules, defaults.text_pre_rules): text = r(text)\n    toks = text.split()\n    for r in ifnone(post_rules, defaults.text_post_rules): toks = r(toks)\n    return \' \'.join(toks) \n\ndef get_default_size(texts, max_vocab_sz):\n    ""Either max_vocab_sz or one quarter of the number of unique words in `texts`""\n    cnt = Counter()\n    for t in texts: \n        cnt.update(t.split())\n        if len(cnt)//4 > max_vocab_sz: return max_vocab_sz\n    res = len(cnt)//4\n    while res%8 != 0: res+=1\n    return res\n\nfull_char_coverage_langs = [""bg"", ""cs"", ""da"", ""de"", ""el"", ""en"", ""es"", ""et"", ""fi"", ""fr"", ""ga"", ""hr"", ""hu"",\n                       ""it"",""lt"",""lv"",""mt"",""nl"",""pl"",""pt"",""ro"",""sk"",""sl"",""sv""] # all European langs\n\nquotemark = \'\\""\'\n\ndef train_sentencepiece(texts:Collection[str], path:PathOrStr, pre_rules: ListRules=None, post_rules:ListRules=None, \n    vocab_sz:int=None, max_vocab_sz:int=30000, model_type:str=\'unigram\', max_sentence_len:int=20480, lang=\'en\',\n    char_coverage=None, tmp_dir=\'tmp\', enc=\'utf8\'):\n    ""Train a sentencepiece tokenizer on `texts` and save it in `path/tmp_dir`""\n    from sentencepiece import SentencePieceTrainer\n    cache_dir = Path(path)/tmp_dir\n    os.makedirs(cache_dir, exist_ok=True)\n    if vocab_sz is None: vocab_sz=get_default_size(texts, max_vocab_sz)\n    raw_text_path = cache_dir / \'all_text.out\'\n    with open(raw_text_path, \'w\', encoding=enc) as f: f.write(""\\n"".join(texts))\n    spec_tokens = [\'\\u2581\'+s for s in defaults.text_spec_tok]\n    SentencePieceTrainer.Train("" "".join([\n        f""--input={quotemark}{raw_text_path}{quotemark} --max_sentence_length={max_sentence_len}"",\n        f""--character_coverage={ifnone(char_coverage, 0.99999 if lang in full_char_coverage_langs else 0.9998)}"",\n        f""--unk_id={len(defaults.text_spec_tok)} --pad_id=-1 --bos_id=-1 --eos_id=-1"",\n        f""--user_defined_symbols={\',\'.join(spec_tokens)}"",\n        f""--model_prefix={quotemark}{cache_dir/\'spm\'}{quotemark} --vocab_size={vocab_sz} --model_type={model_type}""]))\n    raw_text_path.unlink()\n    return cache_dir\n\nclass SPProcessor(PreProcessor):\n    ""`PreProcessor` that tokenizes and numericalizes with `sentencepiece`""\n    def __init__(self, ds:ItemList=None, pre_rules: ListRules=None, post_rules:ListRules=None, vocab_sz:int=None,\n                 max_vocab_sz:int=30000, model_type:str=\'unigram\', max_sentence_len:int=20480, lang=\'en\',\n                 char_coverage=None, tmp_dir=\'tmp\', mark_fields:bool=False, include_bos:bool=True, \n                 include_eos:bool=False, sp_model=None, sp_vocab=None, n_cpus:int=None, enc=\'utf8\'):\n        try: from sentencepiece import SentencePieceTrainer,SentencePieceProcessor\n        except ImportError:\n            raise Exception(\'sentencepiece module is missing: run `pip install sentencepiece`\')\n        self.pre_rules,self.post_rules,self.enc = pre_rules,post_rules,enc\n        self.mark_fields,self.include_bos,self.include_eos = mark_fields,include_bos,include_eos\n        self.sp_model,self.sp_vocab,self.n_cpus = sp_model,sp_vocab,ifnone(n_cpus,defaults.cpus)\n        self.train_func = partial(train_sentencepiece, pre_rules=pre_rules, post_rules=post_rules, vocab_sz=vocab_sz,\n                max_vocab_sz=max_vocab_sz, model_type=model_type, max_sentence_len=max_sentence_len, lang=lang,\n                char_coverage=char_coverage, tmp_dir=tmp_dir, enc=enc)\n\n    def process_one(self, item, join=True):\n        if join: text = _join_texts([item], self.mark_fields, self.include_bos, self.include_eos)[0]\n        text = apply_rules(text, pre_rules=self.pre_rules, post_rules=self.post_rules)\n        return self._encode_batch([text])[0]\n\n    def process(self, ds):\n        ds.items = _join_texts(ds.items, self.mark_fields, self.include_bos, self.include_eos)\n        ds.items = [apply_rules(t, pre_rules=self.pre_rules, post_rules=self.post_rules) \n                    for t in progress_bar(ds.items, leave=False)]\n        if self.sp_model is None or self.sp_vocab is None:\n            cache_dir = self.train_func(ds.items, ds.path)\n            self.sp_model,self.sp_vocab = cache_dir/\'spm.model\',cache_dir/\'spm.vocab\'\n        if not getattr(self, \'vocab\', False): \n            with open(self.sp_vocab, \'r\', encoding=self.enc) as f: self.vocab = Vocab([line.split(\'\\t\')[0] for line in f.readlines()])\n        if self.n_cpus <= 1: ds.items = self._encode_batch(ds.items)\n        else:\n            with ProcessPoolExecutor(self.n_cpus) as e:\n                ds.items = np.array(sum(e.map(self._encode_batch, partition_by_cores(ds.items, self.n_cpus)), []))\n        ds.vocab = self.vocab\n\n    def _encode_batch(self, texts):\n        from sentencepiece import SentencePieceProcessor\n        tok = SentencePieceProcessor()\n        tok.Load(str(self.sp_model))\n        return [np.array(tok.EncodeAsIds(t)) for t in texts]\n\n    @classmethod\n    def load(cls, path:PathOrStr, tmp_dir:PathOrStr=\'tmp\', name:str=\'spm\'):\n        cache_dir = Path(path)/tmp_dir\n        return cls(sp_model=cache_dir/f\'{name}.model\', sp_vocab=cache_dir/f\'{name}.vocab\')\n'"
fastai/text/interpret.py,1,"b'from ..torch_core import *\nfrom ..basic_data import *\nfrom ..basic_train import *\nfrom ..train import ClassificationInterpretation\nimport matplotlib.cm as cm\n\n__all__ = [\'TextClassificationInterpretation\']\n\ndef value2rgba(x:float, cmap:Callable=cm.RdYlGn, alpha_mult:float=1.0)->Tuple:\n    ""Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.""\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])\n\ndef piece_attn_html(pieces:List[str], attns:List[float], sep:str=\' \', **kwargs)->str:\n    html_code,spans = [\'<span style=""font-family: monospace;"">\'], []\n    for p, a in zip(pieces, attns):\n        p = html.escape(p)\n        c = str(value2rgba(a, alpha_mult=0.5, **kwargs))\n        spans.append(f\'<span title=""{a:.3f}"" style=""background-color: rgba{c};"">{p}</span>\')\n    html_code.append(sep.join(spans))\n    html_code.append(\'</span>\')\n    return \'\'.join(html_code)\n\ndef show_piece_attn(*args, **kwargs):\n    from IPython.display import display, HTML\n    display(HTML(piece_attn_html(*args, **kwargs)))\n\ndef _eval_dropouts(mod):\n        module_name =  mod.__class__.__name__\n        if \'Dropout\' in module_name or \'BatchNorm\' in module_name: mod.training = False\n        for module in mod.children(): _eval_dropouts(module)\n\nclass TextClassificationInterpretation(ClassificationInterpretation):\n    """"""Provides an interpretation of classification based on input sensitivity.\n    This was designed for AWD-LSTM only for the moment, because Transformer already has its own attentional model.\n    """"""\n\n    def __init__(self, learn: Learner, preds: Tensor, y_true: Tensor, losses: Tensor, ds_type: DatasetType = DatasetType.Valid):\n        super().__init__(learn,preds,y_true,losses,ds_type)\n        self.model = learn.model\n\n    @classmethod\n    def from_learner(cls, learn: Learner,  ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None):\n        ""Gets preds, y_true, losses to construct base class from a learner""\n        return cls(learn, *learn.get_preds(ds_type=ds_type, activ=activ, with_loss=True, ordered=True), ds_type=ds_type)\n\n    def intrinsic_attention(self, text:str, class_id:int=None):\n        """"""Calculate the intrinsic attention of the input w.r.t to an output `class_id`, or the classification given by the model if `None`.\n        For reference, see the Sequential Jacobian session at https://www.cs.toronto.edu/~graves/preprint.pdf\n        """"""\n        self.model.train()\n        _eval_dropouts(self.model)\n        self.model.zero_grad()\n        self.model.reset()\n        ids = self.data.one_item(text)[0]\n        emb = self.model[0].module.encoder(ids).detach().requires_grad_(True)\n        lstm_output = self.model[0].module(emb, from_embeddings=True)\n        self.model.eval()\n        cl = self.model[1](lstm_output + (torch.zeros_like(ids).byte(),))[0].softmax(dim=-1)\n        if class_id is None: class_id = cl.argmax()\n        cl[0][class_id].backward()\n        attn = emb.grad.squeeze().abs().sum(dim=-1)\n        attn /= attn.max()\n        tokens = self.data.single_ds.reconstruct(ids[0].cpu())\n        return tokens, attn\n\n    def html_intrinsic_attention(self, text:str, class_id:int=None, **kwargs)->str:\n        text, attn = self.intrinsic_attention(text, class_id)\n        return piece_attn_html(text.text.split(), to_np(attn), **kwargs)\n\n    def show_intrinsic_attention(self, text:str, class_id:int=None, **kwargs)->None:\n        text, attn = self.intrinsic_attention(text, class_id)\n        show_piece_attn(text.text.split(), to_np(attn), **kwargs)\n\n    def show_top_losses(self, k:int, max_len:int=70)->None:\n        """"""\n        Create a tabulation showing the first `k` texts in top_losses along with their prediction, actual,loss, and probability of\n        actual class. `max_len` is the maximum number of tokens displayed.\n        """"""\n        from IPython.display import display, HTML\n        items = []\n        tl_val,tl_idx = self.top_losses()\n        for i,idx in enumerate(tl_idx):\n            if k <= 0: break\n            k -= 1\n            tx,cl = self.data.dl(self.ds_type).dataset[idx]\n            cl = cl.data\n            classes = self.data.classes\n            txt = \' \'.join(tx.text.split(\' \')[:max_len]) if max_len is not None else tx.text\n            tmp = [txt, f\'{classes[self.pred_class[idx]]}\', f\'{classes[cl]}\', f\'{self.losses[idx]:.2f}\',\n                   f\'{self.preds[idx][cl]:.2f}\']\n            items.append(tmp)\n        items = np.array(items)\n        names = [\'Text\', \'Prediction\', \'Actual\', \'Loss\', \'Probability\']\n        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)}, columns=names)\n        with pd.option_context(\'display.max_colwidth\', pd_max_colwidth()):\n            display(HTML(df.to_html(index=False)))\n'"
fastai/text/learner.py,12,"b'\'Model training for NLP\'\nfrom ..torch_core import *\nfrom ..basic_train import *\nfrom ..callbacks import *\nfrom ..data_block import CategoryList\nfrom ..basic_data import *\nfrom ..datasets import *\nfrom ..metrics import accuracy\nfrom ..train import GradientClipping\nfrom ..layers import *\nfrom .models import *\nfrom .transform import *\nfrom .data import *\n\n__all__ = [\'RNNLearner\', \'LanguageLearner\', \'convert_weights\', \'decode_spec_tokens\', \'get_language_model\', \'language_model_learner\',\n           \'MultiBatchEncoder\', \'get_text_classifier\', \'text_classifier_learner\', \'PoolingLinearClassifier\']\n\n_model_meta = {AWD_LSTM: {\'hid_name\':\'emb_sz\', \'url\':URLs.WT103_FWD, \'url_bwd\':URLs.WT103_BWD,\n                          \'config_lm\':awd_lstm_lm_config, \'split_lm\': awd_lstm_lm_split,\n                          \'config_clas\':awd_lstm_clas_config, \'split_clas\': awd_lstm_clas_split},\n               Transformer: {\'hid_name\':\'d_model\', \'url\':URLs.OPENAI_TRANSFORMER,\n                             \'config_lm\':tfmer_lm_config, \'split_lm\': tfmer_lm_split,\n                             \'config_clas\':tfmer_clas_config, \'split_clas\': tfmer_clas_split},\n               TransformerXL: {\'hid_name\':\'d_model\',\n                              \'config_lm\':tfmerXL_lm_config, \'split_lm\': tfmerXL_lm_split,\n                              \'config_clas\':tfmerXL_clas_config, \'split_clas\': tfmerXL_clas_split}}\n\ndef convert_weights(wgts:Weights, stoi_wgts:Dict[str,int], itos_new:Collection[str]) -> Weights:\n    ""Convert the model `wgts` to go with a new vocabulary.""\n    dec_bias, enc_wgts = wgts.get(\'1.decoder.bias\', None), wgts[\'0.encoder.weight\']\n    wgts_m = enc_wgts.mean(0)\n    if dec_bias is not None: bias_m = dec_bias.mean(0)\n    new_w = enc_wgts.new_zeros((len(itos_new),enc_wgts.size(1))).zero_()\n    if dec_bias is not None: new_b = dec_bias.new_zeros((len(itos_new),)).zero_()\n    for i,w in enumerate(itos_new):\n        r = stoi_wgts[w] if w in stoi_wgts else -1\n        new_w[i] = enc_wgts[r] if r>=0 else wgts_m\n        if dec_bias is not None: new_b[i] = dec_bias[r] if r>=0 else bias_m\n    wgts[\'0.encoder.weight\'] = new_w\n    if \'0.encoder_dp.emb.weight\' in wgts: wgts[\'0.encoder_dp.emb.weight\'] = new_w.clone()\n    wgts[\'1.decoder.weight\'] = new_w.clone()\n    if dec_bias is not None: wgts[\'1.decoder.bias\'] = new_b\n    return wgts\n\nclass RNNLearner(Learner):\n    ""Basic class for a `Learner` in NLP.""\n    def __init__(self, data:DataBunch, model:nn.Module, split_func:OptSplitFunc=None, clip:float=None,\n                 alpha:float=2., beta:float=1., metrics=None, **learn_kwargs):\n        is_class = (hasattr(data.train_ds, \'y\') and (isinstance(data.train_ds.y, CategoryList) or\n                                                     isinstance(data.train_ds.y, LMLabelList)))\n        metrics = ifnone(metrics, ([accuracy] if is_class else []))\n        super().__init__(data, model, metrics=metrics, **learn_kwargs)\n        self.callbacks.append(RNNTrainer(self, alpha=alpha, beta=beta))\n        if clip: self.callback_fns.append(partial(GradientClipping, clip=clip))\n        if split_func: self.split(split_func)\n\n    def save_encoder(self, name:str):\n        ""Save the encoder to `name` inside the model directory.""\n        if rank_distrib(): return # don\'t save if slave proc\n        if is_pathlike(name): self._test_writeable_path()\n        encoder = get_model(self.model)[0]\n        if hasattr(encoder, \'module\'): encoder = encoder.module\n        torch.save(encoder.state_dict(), self.path/self.model_dir/f\'{name}.pth\')\n\n    def load_encoder(self, name:str, device:torch.device=None):\n        ""Load the encoder `name` from the model directory.""\n        encoder = get_model(self.model)[0]\n        if device is None: device = self.data.device\n        if hasattr(encoder, \'module\'): encoder = encoder.module\n        distrib_barrier()\n        encoder.load_state_dict(torch.load(self.path/self.model_dir/f\'{name}.pth\', map_location=device))\n        self.freeze()\n        return self\n\n    def load_pretrained(self, wgts_fname:str, itos_fname:str, strict:bool=True):\n        ""Load a pretrained model and adapts it to the data vocabulary.""\n        old_itos = pickle.load(open(itos_fname, \'rb\'))\n        old_stoi = {v:k for k,v in enumerate(old_itos)}\n        wgts = torch.load(wgts_fname, map_location=lambda storage, loc: storage)\n        if \'model\' in wgts: wgts = wgts[\'model\']\n        wgts = convert_weights(wgts, old_stoi, self.data.train_ds.vocab.itos)\n        self.model.load_state_dict(wgts, strict=strict)\n        return self\n\n    def get_preds(self, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None, with_loss:bool=False, n_batch:Optional[int]=None,\n                  pbar:Optional[PBar]=None, ordered:bool=True) -> List[Tensor]:\n        ""Return predictions and targets on the valid, train, or test set, depending on `ds_type`.""\n        self.model.reset()\n        if ordered: np.random.seed(42)\n        preds = super().get_preds(ds_type=ds_type, activ=activ, with_loss=with_loss, n_batch=n_batch, pbar=pbar)\n        if ordered and hasattr(self.dl(ds_type), \'sampler\'):\n            np.random.seed(42)\n            sampler = [i for i in self.dl(ds_type).sampler]\n            reverse_sampler = np.argsort(sampler)\n            preds = [p[reverse_sampler] for p in preds]\n        return preds\n\ndef decode_spec_tokens(tokens):\n    new_toks,rule,arg = [],None,None\n    for t in tokens:\n        if t in [TK_MAJ, TK_UP, TK_REP, TK_WREP]: rule = t\n        elif rule is None: new_toks.append(t)\n        elif rule == TK_MAJ:\n            new_toks.append(t[:1].upper() + t[1:].lower())\n            rule = None\n        elif rule == TK_UP:\n            new_toks.append(t.upper())\n            rule = None\n        elif arg is None:\n            try:    arg = int(t)\n            except: rule = None\n        else:\n            if rule == TK_REP: new_toks.append(t * arg)\n            else:              new_toks += [t] * arg\n    return new_toks\n\nclass LanguageLearner(RNNLearner):\n    ""Subclass of RNNLearner for predictions.""\n\n    def predict(self, text:str, n_words:int=1, no_unk:bool=True, temperature:float=1., min_p:float=None, sep:str=\' \',\n                decoder=decode_spec_tokens):\n        ""Return `text` and the `n_words` that come after""\n        self.model.reset()\n        xb,yb = self.data.one_item(text)\n        new_idx = []\n        for _ in range(n_words): #progress_bar(range(n_words), leave=False):\n            res = self.pred_batch(batch=(xb,yb))[0][-1]\n            #if len(new_idx) == 0: self.model[0].select_hidden([0])\n            if no_unk: res[self.data.vocab.stoi[UNK]] = 0.\n            if min_p is not None:\n                if (res >= min_p).float().sum() == 0:\n                    warn(f""There is no item with probability >= {min_p}, try a lower value."")\n                else: res[res < min_p] = 0.\n            if temperature != 1.: res.pow_(1 / temperature)\n            idx = torch.multinomial(res, 1).item()\n            new_idx.append(idx)\n            xb = xb.new_tensor([idx])[None]\n        return text + sep + sep.join(decoder(self.data.vocab.textify(new_idx, sep=None)))\n\n    def beam_search(self, text:str, n_words:int, no_unk:bool=True, top_k:int=10, beam_sz:int=1000, temperature:float=1.,\n                    sep:str=\' \', decoder=decode_spec_tokens):\n        ""Return the `n_words` that come after `text` using beam search.""\n        self.model.reset()\n        self.model.eval()\n        xb, yb = self.data.one_item(text)\n        nodes = None\n        nodes = xb.clone()\n        scores = xb.new_zeros(1).float()\n        with torch.no_grad():\n            for k in progress_bar(range(n_words), leave=False):\n                out = F.log_softmax(self.model(xb)[0][:,-1], dim=-1)\n                if no_unk: out[:,self.data.vocab.stoi[UNK]] = -float(\'Inf\')\n                values, indices = out.topk(top_k, dim=-1)\n                scores = (-values + scores[:,None]).view(-1)\n                indices_idx = torch.arange(0,nodes.size(0))[:,None].expand(nodes.size(0), top_k).contiguous().view(-1)\n                sort_idx = scores.argsort()[:beam_sz]\n                scores = scores[sort_idx]\n                nodes = torch.cat([nodes[:,None].expand(nodes.size(0),top_k,nodes.size(1)),\n                                indices[:,:,None].expand(nodes.size(0),top_k,1),], dim=2)\n                nodes = nodes.view(-1, nodes.size(2))[sort_idx]\n                self.model[0].select_hidden(indices_idx[sort_idx])\n                xb = nodes[:,-1][:,None]\n        if temperature != 1.: scores.div_(temperature)\n        node_idx = torch.multinomial(torch.exp(-scores), 1).item()\n        return text + sep + sep.join(decoder(self.data.vocab.textify([i.item() for i in nodes[node_idx][1:] ], sep=None)))\n\n    def show_results(self, ds_type=DatasetType.Valid, rows:int=5, max_len:int=20):\n        from IPython.display import display, HTML\n        ""Show `rows` result of predictions on `ds_type` dataset.""\n        ds = self.dl(ds_type).dataset\n        x,y = self.data.one_batch(ds_type, detach=False, denorm=False)\n        preds = self.pred_batch(batch=(x,y))\n        y = y.view(*x.size())\n        z = preds.view(*x.size(),-1).argmax(dim=2)\n        xs = [ds.x.reconstruct(grab_idx(x, i)) for i in range(rows)]\n        ys = [ds.x.reconstruct(grab_idx(y, i)) for i in range(rows)]\n        zs = [ds.x.reconstruct(grab_idx(z, i)) for i in range(rows)]\n        items,names = [],[\'text\', \'target\', \'pred\']\n        for i, (x,y,z) in enumerate(zip(xs,ys,zs)):\n            txt_x = \' \'.join(x.text.split(\' \')[:max_len])\n            txt_y = \' \'.join(y.text.split(\' \')[max_len-1:2*max_len-1])\n            txt_z = \' \'.join(z.text.split(\' \')[max_len-1:2*max_len-1])\n            items.append([txt_x, txt_y, txt_z])\n        items = np.array(items)\n        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)}, columns=names)\n        with pd.option_context(\'display.max_colwidth\', pd_max_colwidth()):\n            display(HTML(df.to_html(index=False)))\n\ndef get_language_model(arch:Callable, vocab_sz:int, config:dict=None, drop_mult:float=1.):\n    ""Create a language model from `arch` and its `config`, maybe `pretrained`.""\n    meta = _model_meta[arch]\n    config = ifnone(config, meta[\'config_lm\']).copy()\n    for k in config.keys():\n        if k.endswith(\'_p\'): config[k] *= drop_mult\n    tie_weights,output_p,out_bias = map(config.pop, [\'tie_weights\', \'output_p\', \'out_bias\'])\n    init = config.pop(\'init\') if \'init\' in config else None\n    encoder = arch(vocab_sz, **config)\n    enc = encoder.encoder if tie_weights else None\n    decoder = LinearDecoder(vocab_sz, config[meta[\'hid_name\']], output_p, tie_encoder=enc, bias=out_bias)\n    model = SequentialRNN(encoder, decoder)\n    return model if init is None else model.apply(init)\n\ndef language_model_learner(data:DataBunch, arch, config:dict=None, drop_mult:float=1., pretrained:bool=True,\n                           pretrained_fnames:OptStrTuple=None, **learn_kwargs) -> \'LanguageLearner\':\n    ""Create a `Learner` with a language model from `data` and `arch`.""\n    model = get_language_model(arch, len(data.vocab.itos), config=config, drop_mult=drop_mult)\n    meta = _model_meta[arch]\n    learn = LanguageLearner(data, model, split_func=meta[\'split_lm\'], **learn_kwargs)\n    url = \'url_bwd\' if data.backwards else \'url\'\n    if pretrained or pretrained_fnames:\n        if pretrained_fnames is not None:\n            fnames = [learn.path/learn.model_dir/f\'{fn}.{ext}\' for fn,ext in zip(pretrained_fnames, [\'pth\', \'pkl\'])]\n        else:\n            if url not in meta:\n                warn(""There are no pretrained weights for that architecture yet!"")\n                return learn\n            model_path = untar_data(meta[url] , data=False)\n            fnames = [list(model_path.glob(f\'*.{ext}\'))[0] for ext in [\'pth\', \'pkl\']]\n        learn = learn.load_pretrained(*fnames)\n        learn.freeze()\n    return learn\n\ndef masked_concat_pool(outputs:Sequence[Tensor], mask:Tensor)->Tensor:\n    ""Pool MultiBatchEncoder outputs into one vector [last_hidden, max_pool, avg_pool].""\n    output = outputs[-1]\n    avg_pool = output.masked_fill(mask[:, :, None], 0).mean(dim=1)\n    avg_pool *= output.size(1) / (output.size(1)-mask.type(avg_pool.dtype).sum(dim=1))[:,None]\n    max_pool = output.masked_fill(mask[:,:,None], -float(\'inf\')).max(dim=1)[0]\n    x = torch.cat([output[:,-1], max_pool, avg_pool], 1)\n    return x\n\nclass PoolingLinearClassifier(Module):\n    ""Create a linear classifier with pooling.""\n    def __init__(self, layers:Collection[int], drops:Collection[float]):\n        mod_layers = []\n        if len(drops) != len(layers)-1: raise ValueError(""Number of layers and dropout values do not match."")\n        activs = [nn.ReLU(inplace=True)] * (len(layers) - 2) + [None]\n        for n_in, n_out, p, actn in zip(layers[:-1], layers[1:], drops, activs):\n            mod_layers += bn_drop_lin(n_in, n_out, p=p, actn=actn)\n        self.layers = nn.Sequential(*mod_layers)\n\n    def forward(self, input:Tuple[Tensor,Tensor, Tensor])->Tuple[Tensor,Tensor,Tensor]:\n        raw_outputs,outputs,mask = input\n        x = masked_concat_pool(outputs, mask)\n        x = self.layers(x)\n        return x, raw_outputs, outputs\n\nclass MultiBatchEncoder(Module):\n    ""Create an encoder over `module` that can process a full sentence.""\n    def __init__(self, bptt:int, max_len:int, module:nn.Module, pad_idx:int=1):\n        self.max_len,self.bptt,self.module,self.pad_idx = max_len,bptt,module,pad_idx\n\n    def concat(self, arrs:Sequence[Sequence[Tensor]])->List[Tensor]:\n        ""Concatenate the `arrs` along the batch dimension.""\n        return [torch.cat([l[si] for l in arrs], dim=1) for si in range_of(arrs[0])]\n\n    def reset(self):\n        if hasattr(self.module, \'reset\'): self.module.reset()\n\n    def forward(self, input:LongTensor)->Tuple[List[Tensor],List[Tensor],Tensor]:\n        bs,sl = input.size()\n        self.reset()\n        raw_outputs,outputs,masks = [],[],[]\n        for i in range(0, sl, self.bptt):\n            r, o = self.module(input[:,i: min(i+self.bptt, sl)])\n            if i>(sl-self.max_len):\n                masks.append(input[:,i: min(i+self.bptt, sl)] == self.pad_idx)\n                raw_outputs.append(r)\n                outputs.append(o)\n        return self.concat(raw_outputs),self.concat(outputs),torch.cat(masks,dim=1)\n\ndef get_text_classifier(arch:Callable, vocab_sz:int, n_class:int, bptt:int=70, max_len:int=20*70, config:dict=None,\n                        drop_mult:float=1., lin_ftrs:Collection[int]=None, ps:Collection[float]=None,\n                        pad_idx:int=1) -> nn.Module:\n    ""Create a text classifier from `arch` and its `config`, maybe `pretrained`.""\n    meta = _model_meta[arch]\n    config = ifnone(config, meta[\'config_clas\']).copy()\n    for k in config.keys():\n        if k.endswith(\'_p\'): config[k] *= drop_mult\n    if lin_ftrs is None: lin_ftrs = [50]\n    if ps is None:  ps = [0.1]*len(lin_ftrs)\n    layers = [config[meta[\'hid_name\']] * 3] + lin_ftrs + [n_class]\n    ps = [config.pop(\'output_p\')] + ps\n    init = config.pop(\'init\') if \'init\' in config else None\n    encoder = MultiBatchEncoder(bptt, max_len, arch(vocab_sz, **config), pad_idx=pad_idx)\n    model = SequentialRNN(encoder, PoolingLinearClassifier(layers, ps))\n    return model if init is None else model.apply(init)\n\ndef text_classifier_learner(data:DataBunch, arch:Callable, bptt:int=70, max_len:int=70*20, config:dict=None,\n                            pretrained:bool=True, drop_mult:float=1., lin_ftrs:Collection[int]=None,\n                            ps:Collection[float]=None, **learn_kwargs) -> \'TextClassifierLearner\':\n    ""Create a `Learner` with a text classifier from `data` and `arch`.""\n    model = get_text_classifier(arch, len(data.vocab.itos), data.c, bptt=bptt, max_len=max_len,\n                                config=config, drop_mult=drop_mult, lin_ftrs=lin_ftrs, ps=ps)\n    meta = _model_meta[arch]\n    learn = RNNLearner(data, model, split_func=meta[\'split_clas\'], **learn_kwargs)\n    if pretrained:\n        if \'url\' not in meta:\n            warn(""There are no pretrained weights for that architecture yet!"")\n            return learn\n        model_path = untar_data(meta[\'url\'], data=False)\n        fnames = [list(model_path.glob(f\'*.{ext}\'))[0] for ext in [\'pth\', \'pkl\']]\n        learn = learn.load_pretrained(*fnames, strict=False)\n        learn.freeze()\n    return learn\n'"
fastai/text/transform.py,0,"b'""NLP data processing; tokenizes text and creates vocab indexes""\nfrom ..torch_core import *\n\nimport spacy\nfrom spacy.symbols import ORTH\n\n__all__ = [\'BaseTokenizer\', \'SpacyTokenizer\', \'Tokenizer\', \'Vocab\', \'fix_html\', \'replace_all_caps\', \'replace_rep\', \'replace_wrep\',\n           \'rm_useless_spaces\', \'spec_add_spaces\', \'BOS\', \'EOS\', \'FLD\', \'UNK\', \'PAD\', \'TK_MAJ\', \'TK_UP\', \'TK_REP\', \'TK_REP\', \'TK_WREP\',\n           \'deal_caps\']\n\nBOS,EOS,FLD,UNK,PAD = \'xxbos\',\'xxeos\',\'xxfld\',\'xxunk\',\'xxpad\'\nTK_MAJ,TK_UP,TK_REP,TK_WREP = \'xxmaj\',\'xxup\',\'xxrep\',\'xxwrep\'\ndefaults.text_spec_tok = [UNK,PAD,BOS,EOS,FLD,TK_MAJ,TK_UP,TK_REP,TK_WREP]\n\n\nclass BaseTokenizer():\n    ""Basic class for a tokenizer function.""\n    def __init__(self, lang:str):                      self.lang = lang\n    def tokenizer(self, t:str) -> List[str]:           return t.split(\' \')\n    def add_special_cases(self, toks:Collection[str]): pass\n\nclass SpacyTokenizer(BaseTokenizer):\n    ""Wrapper around a spacy tokenizer to make it a `BaseTokenizer`.""\n    def __init__(self, lang:str):\n        self.tok = spacy.blank(lang, disable=[""parser"",""tagger"",""ner""])\n\n    def tokenizer(self, t:str) -> List[str]:\n        return [t.text for t in self.tok.tokenizer(t)]\n\n    def add_special_cases(self, toks:Collection[str]):\n        for w in toks:\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\n\ndef spec_add_spaces(t:str) -> str:\n    ""Add spaces around / and # in `t`. \\n""\n    return re.sub(r\'([/#\\n])\', r\' \\1 \', t)\n\ndef rm_useless_spaces(t:str) -> str:\n    ""Remove multiple spaces in `t`.""\n    return re.sub(\' {2,}\', \' \', t)\n\ndef replace_rep(t:str) -> str:\n    ""Replace repetitions at the character level in `t`.""\n    def _replace_rep(m:Collection[str]) -> str:\n        c,cc = m.groups()\n        return f\' {TK_REP} {len(cc)+1} {c} \'\n    re_rep = re.compile(r\'(\\S)(\\1{3,})\')\n    return re_rep.sub(_replace_rep, t)\n\ndef replace_wrep(t:str) -> str:\n    ""Replace word repetitions in `t`.""\n    def _replace_wrep(m:Collection[str]) -> str:\n        c,cc = m.groups()\n        return f\' {TK_WREP} {len(cc.split())+1} {c} \'\n    re_wrep = re.compile(r\'(\\b\\w+\\W+)(\\1{3,})\')\n    return re_wrep.sub(_replace_wrep, t)\n\ndef fix_html(x:str) -> str:\n    ""List of replacements from html strings in `x`.""\n    re1 = re.compile(r\'  +\')\n    x = x.replace(\'#39;\', ""\'"").replace(\'amp;\', \'&\').replace(\'#146;\', ""\'"").replace(\n        \'nbsp;\', \' \').replace(\'#36;\', \'$\').replace(\'\\\\n\', ""\\n"").replace(\'quot;\', ""\'"").replace(\n        \'<br />\', ""\\n"").replace(\'\\\\""\', \'""\').replace(\'<unk>\',UNK).replace(\' @.@ \',\'.\').replace(\n        \' @-@ \',\'-\').replace(\' @,@ \',\',\').replace(\'\\\\\', \' \\\\ \')\n    return re1.sub(\' \', html.unescape(x))\n\ndef replace_all_caps(x:Collection[str]) -> Collection[str]:\n    ""Replace tokens in ALL CAPS in `x` by their lower version and add `TK_UP` before.""\n    res = []\n    for t in x:\n        if t.isupper() and len(t) > 1: res.append(TK_UP); res.append(t.lower())\n        else: res.append(t)\n    return res\n\ndef deal_caps(x:Collection[str]) -> Collection[str]:\n    ""Replace all Capitalized tokens in `x` by their lower version and add `TK_MAJ` before.""\n    res = []\n    for t in x:\n        if t == \'\': continue\n        if t[0].isupper() and len(t) > 1 and t[1:].islower(): res.append(TK_MAJ)\n        res.append(t.lower())\n    return res\n\ndefaults.text_pre_rules = [fix_html, replace_rep, replace_wrep, spec_add_spaces, rm_useless_spaces]\ndefaults.text_post_rules = [replace_all_caps, deal_caps]\n\nclass Tokenizer():\n    ""Put together rules and a tokenizer function to tokenize text with multiprocessing.""\n    def __init__(self, tok_func:Callable=SpacyTokenizer, lang:str=\'en\', pre_rules:ListRules=None,\n                 post_rules:ListRules=None, special_cases:Collection[str]=None, n_cpus:int=None):\n        self.tok_func,self.lang,self.special_cases = tok_func,lang,special_cases\n        self.pre_rules  = ifnone(pre_rules,  defaults.text_pre_rules )\n        self.post_rules = ifnone(post_rules, defaults.text_post_rules)\n        self.special_cases = special_cases if special_cases is not None else defaults.text_spec_tok\n        self.n_cpus = ifnone(n_cpus, defaults.cpus)\n\n    def __repr__(self) -> str:\n        res = f\'Tokenizer {self.tok_func.__name__} in {self.lang} with the following rules:\\n\'\n        for rule in self.pre_rules: res += f\' - {rule.__name__}\\n\'\n        for rule in self.post_rules: res += f\' - {rule.__name__}\\n\'\n        return res\n\n    def process_text(self, t:str, tok:BaseTokenizer) -> List[str]:\n        ""Process one text `t` with tokenizer `tok`.""\n        for rule in self.pre_rules: t = rule(t)\n        toks = tok.tokenizer(t)\n        for rule in self.post_rules: toks = rule(toks)\n        return toks\n\n    def _process_all_1(self, texts:Collection[str]) -> List[List[str]]:\n        ""Process a list of `texts` in one process.""\n        tok = self.tok_func(self.lang)\n        if self.special_cases: tok.add_special_cases(self.special_cases)\n        return [self.process_text(str(t), tok) for t in texts]\n\n    def process_all(self, texts:Collection[str]) -> List[List[str]]:\n        ""Process a list of `texts`.""\n        if self.n_cpus <= 1: return self._process_all_1(texts)\n        with ProcessPoolExecutor(self.n_cpus) as e:\n            return sum(e.map(self._process_all_1, partition_by_cores(texts, self.n_cpus)), [])\n\nclass Vocab():\n    ""Contain the correspondence between numbers and tokens and numericalize.""\n    def __init__(self, itos:Collection[str]):\n        self.itos = itos\n        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})\n\n    def numericalize(self, t:Collection[str]) -> List[int]:\n        ""Convert a list of tokens `t` to their ids.""\n        return [self.stoi[w] for w in t]\n\n    def textify(self, nums:Collection[int], sep=\' \') -> List[str]:\n        ""Convert a list of `nums` to their tokens.""\n        return sep.join([self.itos[i] for i in nums]) if sep is not None else [self.itos[i] for i in nums]\n\n    def __getstate__(self):\n        return {\'itos\':self.itos}\n\n    def __setstate__(self, state:dict):\n        self.itos = state[\'itos\']\n        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})\n\n    def save(self, path):\n        ""Save `self.itos` in `path`""\n        if rank_distrib(): return # don\'t save if slave proc\n        pickle.dump(self.itos, open(path, \'wb\'))\n\n    @classmethod\n    def create(cls, tokens:Tokens, max_vocab:int, min_freq:int) -> \'Vocab\':\n        ""Create a vocabulary from a set of `tokens`.""\n        freq = Counter(p for o in tokens for p in o)\n        itos = [o for o,c in freq.most_common(max_vocab) if c >= min_freq]\n        for o in reversed(defaults.text_spec_tok):\n            if o in itos: itos.remove(o)\n            itos.insert(0, o)\n        itos = itos[:max_vocab]\n        if len(itos) < max_vocab: #Make sure vocab size is a multiple of 8 for fast mixed precision training\n            while len(itos)%8 !=0: itos.append(\'xxfake\')\n        return cls(itos)\n    \n    @classmethod\n    def load(cls, path):\n        ""Load the `Vocab` contained in `path`""\n        itos = pickle.load(open(path, \'rb\'))\n        return cls(itos)\n'"
fastai/utils/__init__.py,0,b'from .collect_env import *\n\n__all__ = [*collect_env.__all__]\n'
fastai/utils/check_perf.py,0,b'from ..script import *\nfrom .collect_env import *\n\n# Temporary POC for module-based script\ncall_parse(check_perf)\n\n'
fastai/utils/collect_env.py,11,"b'# -*- coding: utf-8 -*-\n""Utility functions to help deal with user environment""\n\nfrom ..imports.torch import *\nfrom ..core import *\nfrom ..script import *\nfrom .pynvml_gate import *\nimport fastprogress, subprocess, platform\n\n__all__ = [\'show_install\', \'check_perf\', \'pillow_version\']\n\ndef pillow_version():\n    import PIL.Image\n    try:    return PIL.Image.__version__    # PIL >= 7\n    except: return PIL.Image.PILLOW_VERSION # PIL <  7\n\ndef get_env(name):\n    ""Return env var value if it\'s defined and not an empty string, or return Unknown""\n    res = os.environ.get(name,\'\')\n    return res if len(res) else ""Unknown""\n\ndef show_install(show_nvidia_smi:bool=False):\n    ""Print user\'s setup information""\n\n    import platform, fastai.version\n\n    rep = []\n    opt_mods = []\n\n    rep.append([""=== Software ==="", None])\n    rep.append([""python"", platform.python_version()])\n    rep.append([""fastai"", fastai.__version__])\n    rep.append([""fastprogress"", fastprogress.__version__])\n    rep.append([""torch"",  torch.__version__])\n\n    # nvidia-smi\n    cmd = ""nvidia-smi""\n    have_nvidia_smi = False\n    try: result = subprocess.run(cmd.split(), shell=False, check=False, stdout=subprocess.PIPE)\n    except: pass\n    else:\n        if result.returncode == 0 and result.stdout: have_nvidia_smi = True\n\n    # XXX: if nvidia-smi is not available, another check could be:\n    # /proc/driver/nvidia/version on most systems, since it\'s the\n    # currently active version\n\n    if have_nvidia_smi:\n        smi = result.stdout.decode(\'utf-8\')\n        # matching: ""Driver Version: 396.44""\n        match = re.findall(r\'Driver Version: +(\\d+\\.\\d+)\', smi)\n        if match: rep.append([""nvidia driver"", match[0]])\n\n    available = ""available"" if torch.cuda.is_available() else ""**Not available** ""\n    rep.append([""torch cuda"", f""{torch.version.cuda} / is {available}""])\n\n    # no point reporting on cudnn if cuda is not available, as it\n    # seems to be enabled at times even on cpu-only setups\n    if torch.cuda.is_available():\n        enabled = ""enabled"" if torch.backends.cudnn.enabled else ""**Not enabled** ""\n        rep.append([""torch cudnn"", f""{torch.backends.cudnn.version()} / is {enabled}""])\n\n    rep.append([""\\n=== Hardware ==="", None])\n\n    # it\'s possible that torch might not see what nvidia-smi sees?\n    gpu_total_mem = []\n    nvidia_gpu_cnt = 0\n    if have_nvidia_smi:\n        try:\n            cmd = ""nvidia-smi --query-gpu=memory.total --format=csv,nounits,noheader""\n            result = subprocess.run(cmd.split(), shell=False, check=False, stdout=subprocess.PIPE)\n        except:\n            print(""have nvidia-smi, but failed to query it"")\n        else:\n            if result.returncode == 0 and result.stdout:\n                output = result.stdout.decode(\'utf-8\')\n                gpu_total_mem = [int(x) for x in output.strip().split(\'\\n\')]\n                nvidia_gpu_cnt = len(gpu_total_mem)\n\n\n    if nvidia_gpu_cnt: rep.append([""nvidia gpus"", nvidia_gpu_cnt])\n\n    torch_gpu_cnt = torch.cuda.device_count()\n    if torch_gpu_cnt:\n        rep.append([""torch devices"", torch_gpu_cnt])\n        # information for each gpu\n        for i in range(torch_gpu_cnt):\n            rep.append([f""  - gpu{i}"", (f""{gpu_total_mem[i]}MB | "" if gpu_total_mem else """") + torch.cuda.get_device_name(i)])\n    else:\n        if nvidia_gpu_cnt:\n            rep.append([f""Have {nvidia_gpu_cnt} GPU(s), but torch can\'t use them (check nvidia driver)"", None])\n        else:\n            rep.append([f""No GPUs available"", None])\n\n\n    rep.append([""\\n=== Environment ==="", None])\n\n    rep.append([""platform"", platform.platform()])\n\n    if platform.system() == \'Linux\':\n        distro = try_import(\'distro\')\n        if distro:\n            # full distro info\n            rep.append([""distro"", \' \'.join(distro.linux_distribution())])\n        else:\n            opt_mods.append(\'distro\');\n            # partial distro info\n            rep.append([""distro"", platform.uname().version])\n\n    rep.append([""conda env"", get_env(\'CONDA_DEFAULT_ENV\')])\n    rep.append([""python"", sys.executable])\n    rep.append([""sys.path"", ""\\n"".join(sys.path)])\n\n    print(""\\n\\n```text"")\n\n    keylen = max([len(e[0]) for e in rep if e[1] is not None])\n    for e in rep:\n        print(f""{e[0]:{keylen}}"", (f"": {e[1]}"" if e[1] is not None else """"))\n\n    if have_nvidia_smi:\n        if show_nvidia_smi: print(f""\\n{smi}"")\n    else:\n        if torch_gpu_cnt: print(""no nvidia-smi is found"")\n        else: print(""no supported gpus found on this system"")\n\n    print(""```\\n"")\n\n    print(""Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\\n"")\n\n    if opt_mods:\n        print(""Optional package(s) to enhance the diagnostics can be installed with:"")\n        print(f""pip install {\' \'.join(opt_mods)}"")\n        print(""Once installed, re-run this utility to get the additional information"")\n\ndef pypi_module_version_is_available(module, version):\n    ""Check whether module==version is available on pypi""\n    # returns True/False (or None if failed to execute the check)\n\n    # using a hack that when passing ""module=="" w/ no version number to pip\n    # it ""fails"" and returns all the available versions in stderr\n    try:\n        cmd = f""pip install {module}==""\n        result = subprocess.run(cmd.split(), shell=False, check=False,\n                                stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    except Exception as e:\n        print(f""Error: {e}"")\n        return None\n    else:\n        if result.returncode == 1 and result.stderr:\n            output = result.stderr.decode(\'utf-8\')\n            return True if version in output else False\n        else:\n            print(f""Some error in {cmd}"")\n            return None\n\ndef check_perf():\n    ""Suggest how to improve the setup to speed things up""\n\n    from PIL import features, Image\n    from packaging import version\n\n    print(""Running performance checks."")\n\n    # libjpeg_turbo check\n    print(""\\n*** libjpeg-turbo status"")\n    #TODO: do some workarounf for later versions of Pillow\n    pil_version = pillow_version()\n    if version.parse(pil_version) >= version.parse(""5.3.9""):\n        if features.check_feature(\'libjpeg_turbo\'):\n            print(""\xe2\x9c\x94 libjpeg-turbo is on"")\n        else:\n            print(""\xe2\x9c\x98 libjpeg-turbo is not on. It\'s recommended you install libjpeg-turbo to speed up JPEG decoding. See https://docs.fast.ai/performance.html#libjpeg-turbo"")\n    else:\n        print(f""\xe2\x9d\x93 libjpeg-turbo\'s status can\'t be derived - need Pillow(-SIMD)? >= 5.4.0 to tell, current version {Image.PILLOW_VERSION}"")\n        # XXX: remove this check/note once Pillow and Pillow-SIMD 5.4.0 is available\n        pillow_ver_5_4_is_avail = pypi_module_version_is_available(""Pillow"", ""5.4.0"")\n        if pillow_ver_5_4_is_avail == False:\n            print(""5.4.0 is not yet available, other than the dev version on github, which can be installed via pip from git+https://github.com/python-pillow/Pillow. See https://docs.fast.ai/performance.html#libjpeg-turbo"")\n\n    # Pillow-SIMD check\n    #TODO: same as above\n    print(""\\n*** Pillow-SIMD status"")\n    if re.search(r\'\\.post\\d+\', pil_version):\n        print(f""\xe2\x9c\x94 Running Pillow-SIMD {pil_version}"")\n    else:\n        print(f""\xe2\x9c\x98 Running Pillow {pil_version}; It\'s recommended you install Pillow-SIMD to speed up image resizing and other operations. See https://docs.fast.ai/performance.html#pillow-simd"")\n\n    # CUDA version check\n    # compatibility table: k: min nvidia ver is required for v: cuda ver\n    # note: windows nvidia driver version is slightly higher, see:\n    # https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html\n    # note: add new entries if pytorch starts supporting new cudaXX\n    nvidia2cuda = {\n        ""410.00"": ""10.0"",\n        ""384.81"":  ""9.0"",\n        ""367.48"":  ""8.0"",\n    }\n    print(""\\n*** CUDA status"")\n    if torch.cuda.is_available():\n        pynvml = load_pynvml_env()\n        nvidia_ver = (pynvml.nvmlSystemGetDriverVersion().decode(\'utf-8\') if platform.system() != ""Darwin"" else ""Cannot be determined on OSX yet"")\n        cuda_ver   = torch.version.cuda\n        max_cuda = ""8.0""\n        for k in sorted(nvidia2cuda.keys()):\n            if version.parse(nvidia_ver) > version.parse(k): max_cuda = nvidia2cuda[k]\n        if version.parse(str(max_cuda)) <= version.parse(cuda_ver):\n            print(f""\xe2\x9c\x94 Running the latest CUDA {cuda_ver} with NVIDIA driver {nvidia_ver}"")\n        else:\n            print(f""\xe2\x9c\x98 You are running pytorch built against cuda {cuda_ver}, your NVIDIA driver {nvidia_ver} supports cuda10. See https://pytorch.org/get-started/locally/ to install pytorch built against the faster CUDA version."")\n    else:\n        print(f""\xe2\x9d\x93 Running cpu-only torch version, CUDA check is not relevant"")\n\n    print(""\\nRefer to https://docs.fast.ai/performance.html to make sense out of these checks and suggestions."")\n'"
fastai/utils/ipython.py,0,"b'""ipython utils""\n\nimport os, functools, traceback, gc\n\ndef is_in_ipython():\n    ""Is the code running in the ipython environment (jupyter including)""\n\n    program_name = os.path.basename(os.getenv(\'_\', \'\'))\n\n    if (\'jupyter-notebook\' in program_name or # jupyter-notebook\n        \'ipython\'          in program_name or # ipython\n        \'JPY_PARENT_PID\'   in os.environ):    # ipython-notebook\n        return True\n    else:\n        return False\n\nIS_IN_IPYTHON = is_in_ipython()\n\ndef is_in_colab():\n    ""Is the code running in Google Colaboratory?""\n    if not IS_IN_IPYTHON: return False\n    try:\n        from google import colab\n        return True\n    except: return False\n\nIS_IN_COLAB = is_in_colab()\n\ndef get_ref_free_exc_info():\n    ""Free traceback from references to locals() in each frame to avoid circular reference leading to gc.collect() unable to reclaim memory""\n    type, val, tb = sys.exc_info()\n    traceback.clear_frames(tb)\n    return (type, val, tb)\n\ndef gpu_mem_restore(func):\n    ""Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted""\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        tb_clear_frames = os.environ.get(\'FASTAI_TB_CLEAR_FRAMES\', None)\n        if not IS_IN_IPYTHON or tb_clear_frames==""0"":\n            return func(*args, **kwargs)\n\n        try:\n            return func(*args, **kwargs)\n        except Exception as e:\n            if (""CUDA out of memory"" in str(e) or\n                ""device-side assert triggered"" in str(e) or\n                tb_clear_frames == ""1""):\n                type, val, tb = get_ref_free_exc_info() # must!\n                gc.collect()\n                if ""device-side assert triggered"" in str(e):\n                    warn(""""""When \'device-side assert triggered\' error happens, it\'s not possible to recover and you must restart the kernel to continue. Use os.environ[\'CUDA_LAUNCH_BLOCKING\']=""1"" before restarting to debug"""""")\n                raise type(val).with_traceback(tb) from None\n            else: raise # re-raises the exact last exception\n    return wrapper\n\nclass gpu_mem_restore_ctx():\n    ""context manager to reclaim RAM if an exception happened under ipython""\n    def __enter__(self): return self\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if not exc_val: return True\n        traceback.clear_frames(exc_tb)\n        gc.collect()\n        raise exc_type(exc_val).with_traceback(exc_tb) from None\n'"
fastai/utils/mem.py,7,"b'""Utility functions for memory management""\n\nfrom ..imports.torch import *\nfrom ..core import *\nfrom ..script import *\nimport functools, threading, time\nfrom .pynvml_gate import *\nfrom collections import namedtuple\n\n#is_osx = platform.system() == ""Darwin""\nuse_gpu = torch.cuda.is_available()\n\nGPUMemory = namedtuple(\'GPUMemory\', [\'total\', \'free\', \'used\'])\n\nif use_gpu:\n    pynvml = load_pynvml_env()\n\ndef preload_pytorch():\n    torch.ones((1, 1)).cuda()\n\ndef b2mb(num):\n    """""" convert Bs to MBs and round down """"""\n    return int(num/2**20)\n\ndef gpu_mem_get(id=None):\n    ""get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used""\n    if not use_gpu: return GPUMemory(0, 0, 0)\n    if id is None: id = torch.cuda.current_device()\n    try:\n        handle = pynvml.nvmlDeviceGetHandleByIndex(id)\n        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n        return GPUMemory(*(map(b2mb, [info.total, info.free, info.used])))\n    except:\n        return GPUMemory(0, 0, 0)\n\ndef gpu_mem_get_all():\n    ""get total, used and free memory (in MBs) for each available gpu""\n    if not use_gpu: return []\n    return list(map(gpu_mem_get, range(pynvml.nvmlDeviceGetCount())))\n\ndef gpu_mem_get_free():\n    ""get free memory (in MBs) for the currently selected gpu id, w/o emptying the cache""\n    return gpu_mem_get().free\n\ndef gpu_mem_get_free_no_cache():\n    ""get free memory (in MBs) for the currently selected gpu id, after emptying the cache""\n    torch.cuda.empty_cache()\n    return gpu_mem_get().free\n\ndef gpu_mem_get_used():\n    ""get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache""\n    return gpu_mem_get().used\n\ndef gpu_mem_get_used_fast(gpu_handle):\n    ""get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the `gpu_handle` arg""\n    info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n    return b2mb(info.used)\n\ndef gpu_mem_get_used_no_cache():\n    ""get used memory (in MBs) for the currently selected gpu id, after emptying the cache""\n    torch.cuda.empty_cache()\n    return gpu_mem_get().used\n\ndef gpu_with_max_free_mem():\n    ""get [gpu_id, its_free_ram] for the first gpu with highest available RAM""\n    mem_all = gpu_mem_get_all()\n    if not len(mem_all): return None, 0\n    free_all = np.array([x.free for x in mem_all])\n    id = np.argmax(free_all)\n    return id, free_all[id]\n\nclass GPUMemTrace():\n    ""Trace allocated and peaked GPU memory usage (deltas).""\n    def __init__(self, silent=False, ctx=None, on_exit_report=True):\n        assert torch.cuda.is_available(), ""pytorch CUDA is required""\n        self.silent = silent # shortcut to turn off all reports from constructor\n        self.ctx    = ctx    # default context note in report\n        self.on_exit_report = on_exit_report # auto-report on ctx manager exit (default: True)\n        self.start()\n\n    def reset(self):\n        self.used_start = gpu_mem_get_used_no_cache()\n        self.used_peak  = self.used_start\n\n    def data_set(self):\n        # delta_used is the difference between current used mem and used mem at the start\n        self.delta_used = gpu_mem_get_used_no_cache() - self.used_start\n\n        # delta_peaked is the overhead if any. It is calculated as follows:\n        #\n        # 1. The difference between the peak memory and the used memory at the\n        # start is measured:\n        # 2a. If it\'s negative, then delta_peaked is 0\n        # 2b. Otherwise, if used_delta is positive it gets subtracted from delta_peaked\n        # XXX: 2a shouldn\'t be needed once we have a reliable peak counter\n        self.delta_peaked = self.used_peak - self.used_start\n        if self.delta_peaked < 0: self.delta_peaked = 0\n        elif self.delta_used > 0: self.delta_peaked -= self.delta_used\n\n    def data(self):\n        if self.is_running: self.data_set()\n        return self.delta_used, self.delta_peaked\n\n    def start(self):\n        self.is_running = True\n        self.reset()\n        self.peak_monitor_start()\n\n    def stop(self):\n        self.peak_monitor_stop()\n        self.data_set()\n        self.is_running = False\n\n    def __enter__(self):\n        self.start()\n        return self\n\n    def __exit__(self, *exc):\n        self.stop()\n        if self.on_exit_report: self.report(\'exit\')\n\n    def __del__(self):\n        self.stop()\n\n    def __repr__(self):\n        delta_used, delta_peaked = self.data()\n        return f""\xe2\x96\xb3Used Peaked MB: {delta_used:6,.0f} {delta_peaked:6,.0f}""\n\n    def _get_ctx(self, subctx=None):\n        ""Return \' (ctx: subctx)\' or \' (ctx)\' or \' (subctx)\' or \'\' depending on this and constructor arguments""\n        l = []\n        if self.ctx is not None:      l.append(self.ctx)\n        if subctx is not None:        l.append(subctx)\n        return \'\' if len(l) == 0 else f"" ({\': \'.join(l)})""\n\n    def silent(self, silent=True):\n        self.silent = silent\n\n    def report(self, subctx=None):\n        ""Print delta used+peaked, and an optional context note, which can also be preset in constructor""\n        if self.silent: return\n        print(f""{ self.__repr__() }{ self._get_ctx(subctx) }"")\n\n    def report_n_reset(self, subctx=None):\n        ""Print delta used+peaked, and an optional context note. Then reset counters""\n        self.report(subctx)\n        self.reset()\n\n    def peak_monitor_start(self):\n        self.peak_monitoring = True\n\n        # continually sample GPU RAM usage\n        peak_monitor_thread = threading.Thread(target=self.peak_monitor_func)\n        peak_monitor_thread.daemon = True\n        peak_monitor_thread.start()\n\n    def peak_monitor_stop(self):\n        self.peak_monitoring = False\n\n    # XXX: this is an unreliable function, since there is no thread priority\n    # control and it may not run enough or not run at all\n    def peak_monitor_func(self):\n        gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(torch.cuda.current_device())\n        while True:\n            self.used_peak = max(gpu_mem_get_used_fast(gpu_handle), self.used_peak)\n            if not self.peak_monitoring: break\n            time.sleep(0.001) # 1msec\n\ndef gpu_mem_trace(func):\n    ""A decorator that runs `GPUMemTrace` w/ report on func""\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        with GPUMemTrace(ctx=func.__qualname__, on_exit_report=True):\n            return func(*args, **kwargs)\n    return wrapper\n\ndef reduce_mem_usage(df):\n    """""" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    """"""\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\'Memory usage of dataframe is {:.2f} MB\'.format(start_mem))\n\n    #Removed from debugging\n    columns = df.columns\n    #.drop(\'index\')\n\n    for col in columns:\n        col_type = df[col].dtype\n        if str(col_type) != \'category\' and col_type != \'datetime64[ns]\' and col_type != bool:\n            if col_type != object:\n                c_min = df[col].min()\n                c_max = df[col].max()\n                if str(col_type)[:3] == \'int\':\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)\n                else:\n                    #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                        #df[col] = df[col].astype(np.float16)\n                    #Sometimes causes and error and had to remove\n                    if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                        df[col] = df[col].astype(np.float32)\n                    else:\n                        print(\'Error \'+col+\' Value would be a float64. Disregarding.\')\n            else:\n                df[col] = df[col].astype(\'category\')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(\'Memory usage after optimization is: {:.2f} MB\'.format(end_mem))\n    print(\'Decreased by {:.1f}%\'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\n'"
fastai/utils/mod_display.py,0,"b'"" Utils for modifying what is displayed in notebooks and command line""\nimport fastai\nimport fastprogress\nfrom fastprogress.fastprogress import force_console_behavior\n\nfrom ..basic_train import *\nfrom ..core import *\n\n__all__ = [\'progress_disabled_ctx\']\n\nclass progress_disabled_ctx():\n    ""Context manager to disable the progress update bar and Recorder print.""\n    def __init__(self,learn:Learner):\n        self.learn = learn\n\n    def __enter__(self):\n        #silence progress bar\n        fastprogress.fastprogress.NO_BAR = True\n        fastai.basic_train.master_bar,fastai.basic_train.progress_bar = force_console_behavior()\n        self.orig_callback_fns = copy(self.learn.callback_fns)\n        rec_name = [x for x in self.learn.callback_fns if hasattr(x, \'func\') and x.func == Recorder]\n        if len(rec_name):\n            rec_idx = self.learn.callback_fns.index(rec_name[0])\n            self.learn.callback_fns[rec_idx] = partial(Recorder, add_time=True, silent=True) #silence recorder\n        return self.learn\n\n    def __exit__(self, *args):\n        fastai.basic_train.master_bar,fastai.basic_train.progress_bar = master_bar,progress_bar\n        self.learn.callback_fns = self.orig_callback_fns\n'"
fastai/utils/pynvml_gate.py,0,"b'""""""Get OS specific nvml wrapper. On OSX we use pynvx as drop in replacement for pynvml""""""\n\nimport platform\nfrom ..script import *\n\n#\n# BEGIN: Temporary workaround for nvml.dll load issue in Win10\n#\n# Remove once nicolargo/nvidia-ml-py3#2 and a new version of the module is released \n# (OR fbcotter/py3nvml#10 but will require extra work to rename things)\n# Refer https://forums.fast.ai/t/nvml-dll-loading-issue-in-nvidia-ml-py3-7-352-0-py-0/39684/8\nimport threading\nfrom ctypes import *\n\nnvmlLib = None\nlibLoadLock = threading.Lock()\n\ndef _LoadNvmlLibrary():\n    \'\'\'\n    Load the library if it isn\'t loaded already\n    \'\'\'\n\n    global nvmlLib\n\n    if (nvmlLib == None):\n        libLoadLock.acquire()\n\n        try:\n            if (nvmlLib == None):\n                try:\n                    if (sys.platform[:3] == ""win""):\n                        searchPaths = [\n                            os.path.join(os.getenv(""ProgramFiles"", r""C:\\Program Files""), r""NVIDIA Corporation\\NVSMI\\nvml.dll""),\n                            os.path.join(os.getenv(""WinDir"", r""C:\\Windows""), r""System32\\nvml.dll""),\n                        ]\n                        nvmlPath = next((x for x in searchPaths if os.path.isfile(x)), None)\n                        if (nvmlPath == None):\n                            nvmlLib = None\n                        else:\n                            nvmlLib = CDLL(nvmlPath)\n                    else:\n                        nvmlLib = None\n                except OSError as ose:\n                    nvmlLib = None\n        finally:\n            libLoadLock.release()\n#\n# END: Temporary workaround for nvml.dll load issue in Win10\n#\n\ndef load_pynvml_env():\n    import pynvml # nvidia-ml-py3\n\n    #\n    # BEGIN: Temporary workaround for nvml.dll load issue in Win10 (continued)\n    _LoadNvmlLibrary()\n    pynvml.nvmlLib = nvmlLib\n    #\n    # END: Temporary workaround for nvml.dll load issue in Win10\n    #\n\n    if platform.system() == ""Darwin"":\n        try:\n            from pynvx import pynvml\n        except:\n            print(""please install pynvx on OSX: pip install pynvx"")\n            sys.exit(1)\n\n        pynvml.nvmlInit()\n        return pynvml\n\n    pynvml.nvmlInit()\n\n    return pynvml\n'"
fastai/utils/show_install.py,0,"b""from ..script import *\nfrom .collect_env import *\n\n# Temporary POC for module-based script\n@call_parse\ndef main(show_nvidia_smi:Param(opt=False, nargs='?', type=bool)=False):\n    return show_install(show_nvidia_smi)\n\n"""
fastai/vision/__init__.py,0,"b""from .. import basics\nfrom ..basics import *\nfrom .learner import *\nfrom .image import *\nfrom .data import *\nfrom .transform import *\nfrom .tta import *\nfrom . import models\n\nfrom .. import vision\n\n__all__ = [*basics.__all__, *learner.__all__, *data.__all__, *image.__all__, *transform.__all__, *tta.__all__, 'models', 'vision']\n\n"""
fastai/vision/cyclegan.py,1,"b'from ..torch_core import *\nfrom ..layers import *\nfrom ..callback import *\nfrom ..basic_train import Learner, LearnerCallback\n\n__all__ = [\'CycleGAN\', \'CycleGanLoss\', \'AdaptiveLoss\', \'CycleGANTrainer\']\n\ndef convT_norm_relu(ch_in:int, ch_out:int, norm_layer:nn.Module, ks:int=3, stride:int=2, bias:bool=True):\n    return [nn.ConvTranspose2d(ch_in, ch_out, kernel_size=ks, stride=stride, padding=1, output_padding=1, bias=bias),\n            norm_layer(ch_out), nn.ReLU(True)]\n\ndef pad_conv_norm_relu(ch_in:int, ch_out:int, pad_mode:str, norm_layer:nn.Module, ks:int=3, bias:bool=True,\n                       pad=1, stride:int=1, activ:bool=True, init:Callable=nn.init.kaiming_normal_)->List[nn.Module]:\n    layers = []\n    if pad_mode == \'reflection\': layers.append(nn.ReflectionPad2d(pad))\n    elif pad_mode == \'border\':   layers.append(nn.ReplicationPad2d(pad))\n    p = pad if pad_mode == \'zeros\' else 0\n    conv = nn.Conv2d(ch_in, ch_out, kernel_size=ks, padding=p, stride=stride, bias=bias)\n    if init:\n        init(conv.weight)\n        if hasattr(conv, \'bias\') and hasattr(conv.bias, \'data\'): conv.bias.data.fill_(0.)\n    layers += [conv, norm_layer(ch_out)]\n    if activ: layers.append(nn.ReLU(inplace=True))\n    return layers\n\nclass ResnetBlock(Module):\n    def __init__(self, dim:int, pad_mode:str=\'reflection\', norm_layer:nn.Module=None, dropout:float=0., bias:bool=True):\n        assert pad_mode in [\'zeros\', \'reflection\', \'border\'], f\'padding {pad_mode} not implemented.\'\n        norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n        layers = pad_conv_norm_relu(dim, dim, pad_mode, norm_layer, bias=bias)\n        if dropout != 0: layers.append(nn.Dropout(dropout))\n        layers += pad_conv_norm_relu(dim, dim, pad_mode, norm_layer, bias=bias, activ=False)\n        self.conv_block = nn.Sequential(*layers)\n\n    def forward(self, x): return x + self.conv_block(x)\n\ndef resnet_generator(ch_in:int, ch_out:int, n_ftrs:int=64, norm_layer:nn.Module=None,\n                     dropout:float=0., n_blocks:int=6, pad_mode:str=\'reflection\')->nn.Module:\n    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n    bias = (norm_layer == nn.InstanceNorm2d)\n    layers = pad_conv_norm_relu(ch_in, n_ftrs, \'reflection\', norm_layer, pad=3, ks=7, bias=bias)\n    for i in range(2):\n        layers += pad_conv_norm_relu(n_ftrs, n_ftrs *2, \'zeros\', norm_layer, stride=2, bias=bias)\n        n_ftrs *= 2\n    layers += [ResnetBlock(n_ftrs, pad_mode, norm_layer, dropout, bias) for _ in range(n_blocks)]\n    for i in range(2):\n        layers += convT_norm_relu(n_ftrs, n_ftrs//2, norm_layer, bias=bias)\n        n_ftrs //= 2\n    layers += [nn.ReflectionPad2d(3), nn.Conv2d(n_ftrs, ch_out, kernel_size=7, padding=0), nn.Tanh()]\n    return nn.Sequential(*layers)\n\ndef conv_norm_lr(ch_in:int, ch_out:int, norm_layer:nn.Module=None, ks:int=3, bias:bool=True, pad:int=1, stride:int=1,\n                 activ:bool=True, slope:float=0.2, init:Callable=nn.init.kaiming_normal_)->List[nn.Module]:\n    conv = nn.Conv2d(ch_in, ch_out, kernel_size=ks, padding=pad, stride=stride, bias=bias)\n    if init:\n        init(conv.weight)\n        if hasattr(conv, \'bias\') and hasattr(conv.bias, \'data\'): conv.bias.data.fill_(0.)\n    layers = [conv]\n    if norm_layer is not None: layers.append(norm_layer(ch_out))\n    if activ: layers.append(nn.LeakyReLU(slope, inplace=True))\n    return layers\n\ndef critic(ch_in:int, n_ftrs:int=64, n_layers:int=3, norm_layer:nn.Module=None, sigmoid:bool=False)->nn.Module:\n    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n    bias = (norm_layer == nn.InstanceNorm2d)\n    layers = conv_norm_lr(ch_in, n_ftrs, ks=4, stride=2, pad=1)\n    for i in range(n_layers-1):\n        new_ftrs = 2*n_ftrs if i <= 3 else n_ftrs\n        layers += conv_norm_lr(n_ftrs, new_ftrs, norm_layer, ks=4, stride=2, pad=1, bias=bias)\n        n_ftrs = new_ftrs\n    new_ftrs = 2*n_ftrs if n_layers <=3 else n_ftrs\n    layers += conv_norm_lr(n_ftrs, new_ftrs, norm_layer, ks=4, stride=1, pad=1, bias=bias)\n    layers.append(nn.Conv2d(new_ftrs, 1, kernel_size=4, stride=1, padding=1))\n    if sigmoid: layers.append(nn.Sigmoid())\n    return nn.Sequential(*layers)\n\nclass CycleGAN(Module):\n\n    def __init__(self, ch_in:int, ch_out:int, n_features:int=64, disc_layers:int=3, gen_blocks:int=6, lsgan:bool=True,\n                 drop:float=0., norm_layer:nn.Module=None):\n        self.D_A = critic(ch_in, n_features, disc_layers, norm_layer, sigmoid=not lsgan)\n        self.D_B = critic(ch_in, n_features, disc_layers, norm_layer, sigmoid=not lsgan)\n        self.G_A = resnet_generator(ch_in, ch_out, n_features, norm_layer, drop, gen_blocks)\n        self.G_B = resnet_generator(ch_in, ch_out, n_features, norm_layer, drop, gen_blocks)\n        #G_A: takes real input B and generates fake input A\n        #G_B: takes real input A and generates fake input B\n        #D_A: trained to make the difference between real input A and fake input A\n        #D_B: trained to make the difference between real input B and fake input B\n\n    def forward(self, real_A, real_B):\n        fake_A, fake_B = self.G_A(real_B), self.G_B(real_A)\n        if not self.training: return torch.cat([fake_A[:,None],fake_B[:,None]], 1)\n        idt_A, idt_B = self.G_A(real_A), self.G_B(real_B)\n        return [fake_A, fake_B, idt_A, idt_B]\n\nclass AdaptiveLoss(Module):\n    def __init__(self, crit): self.crit = crit\n\n    def forward(self, output, target:bool):\n        targ = output.new_ones(*output.size()) if target else output.new_zeros(*output.size())\n        return self.crit(output, targ)\n\nclass CycleGanLoss(Module):\n    def __init__(self, cgan:nn.Module, lambda_A:float=10., lambda_B:float=10, lambda_idt:float=0.5, lsgan:bool=True):\n        self.cgan,self.l_A,self.l_B,self.l_idt = cgan,lambda_A,lambda_B,lambda_idt\n        #self.crit = F.mse_loss if lsgan else F.binary_cross_entropy\n        self.crit = AdaptiveLoss(F.mse_loss if lsgan else F.binary_cross_entropy)\n\n    def set_input(self, input):\n        self.real_A,self.real_B = input\n\n    def forward(self, output, target):\n        fake_A, fake_B, idt_A, idt_B = output\n        #Generators should return identity on the datasets they try to convert to\n        idt_loss = self.l_idt * (self.l_B * F.l1_loss(idt_A, self.real_B) + self.l_A * F.l1_loss(idt_B, self.real_A))\n        #Generators are trained to trick the critics so the following should be ones\n        gen_loss = self.crit(self.cgan.D_A(fake_A), True) + self.crit(self.cgan.D_B(fake_B), True)\n        #Cycle loss\n        cycle_loss = self.l_A * F.l1_loss(self.cgan.G_A(fake_B), self.real_A)\n        cycle_loss += self.l_B * F.l1_loss(self.cgan.G_B(fake_A), self.real_B)\n        self.metrics = [idt_loss, gen_loss, cycle_loss]\n        return idt_loss + gen_loss + cycle_loss\n\nclass CycleGANTrainer(LearnerCallback):\n    ""`LearnerCallback` that handles cycleGAN Training.""\n    _order=-20\n    def _set_trainable(self, D_A=False, D_B=False):\n        gen = (not D_A) and (not D_B)\n        requires_grad(self.learn.model.G_A, gen)\n        requires_grad(self.learn.model.G_B, gen)\n        requires_grad(self.learn.model.D_A, D_A)\n        requires_grad(self.learn.model.D_B, D_B)\n        if not gen:\n            self.opt_D_A.lr, self.opt_D_A.mom = self.learn.opt.lr, self.learn.opt.mom\n            self.opt_D_A.wd, self.opt_D_A.beta = self.learn.opt.wd, self.learn.opt.beta\n            self.opt_D_B.lr, self.opt_D_B.mom = self.learn.opt.lr, self.learn.opt.mom\n            self.opt_D_B.wd, self.opt_D_B.beta = self.learn.opt.wd, self.learn.opt.beta\n\n    def on_train_begin(self, **kwargs):\n        ""Create the various optimizers.""\n        self.G_A,self.G_B = self.learn.model.G_A,self.learn.model.G_B\n        self.D_A,self.D_B = self.learn.model.D_A,self.learn.model.D_B\n        self.crit = self.learn.loss_func.crit\n        self.opt_G = self.learn.opt.new([nn.Sequential(*flatten_model(self.G_A), *flatten_model(self.G_B))])\n        self.opt_D_A = self.learn.opt.new([nn.Sequential(*flatten_model(self.D_A))])\n        self.opt_D_B = self.learn.opt.new([nn.Sequential(*flatten_model(self.D_B))])\n        self.learn.opt.opt = self.opt_G.opt\n        self._set_trainable()\n        self.names = [\'idt_loss\', \'gen_loss\', \'cyc_loss\', \'da_loss\', \'db_loss\']\n        self.learn.recorder.no_val=True\n        self.learn.recorder.add_metric_names(self.names)\n        self.smootheners = {n:SmoothenValue(0.98) for n in self.names}\n\n    def on_batch_begin(self, last_input, **kwargs):\n        ""Register the `last_input` in the loss function.""\n        self.learn.loss_func.set_input(last_input)\n\n    def on_batch_end(self, last_input, last_output, **kwargs):\n        ""Steps through the generators then each of the critics.""\n        self.G_A.zero_grad(); self.G_B.zero_grad()\n        fake_A, fake_B = last_output[0].detach(), last_output[1].detach()\n        real_A, real_B = last_input\n        self._set_trainable(D_A=True)\n        self.D_A.zero_grad()\n        loss_D_A = 0.5 * (self.crit(self.D_A(real_A), True) + self.crit(self.D_A(fake_A), False))\n        loss_D_A.backward()\n        self.opt_D_A.step()\n        self._set_trainable(D_B=True)\n        self.D_B.zero_grad()\n        loss_D_B = 0.5 * (self.crit(self.D_B(real_B), True) + self.crit(self.D_B(fake_B), False))\n        loss_D_B.backward()\n        self.opt_D_B.step()\n        self._set_trainable()\n        metrics = self.learn.loss_func.metrics + [loss_D_A, loss_D_B]\n        for n,m in zip(self.names,metrics): self.smootheners[n].add_value(m)\n\n    def on_epoch_end(self, last_metrics, **kwargs):\n        ""Put the various losses in the recorder.""\n        return add_metrics(last_metrics, [s.smooth for k,s in self.smootheners.items()])\n\n'"
fastai/vision/data.py,5,"b'""Manages data input pipeline - folderstransformbatch input. Includes support for classification, segmentation and bounding boxes""\nfrom ..torch_core import *\nfrom .image import *\nfrom .transform import *\nfrom ..data_block import *\nfrom ..basic_data import *\nfrom ..layers import *\nfrom .learner import *\nfrom torchvision import transforms as tvt\n\n__all__ = [\'get_image_files\', \'denormalize\', \'get_annotations\', \'ImageDataBunch\',\n           \'ImageList\', \'normalize\', \'normalize_funcs\', \'resize_to\',\n           \'channel_view\', \'mnist_stats\', \'cifar_stats\', \'imagenet_stats\', \'download_images\',\n           \'verify_images\', \'bb_pad_collate\', \'ImageImageList\', \'PointsLabelList\',\n           \'ObjectCategoryList\', \'ObjectItemList\', \'SegmentationLabelList\', \'SegmentationItemList\', \'PointsItemList\']\n\nimage_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith(\'image/\'))\n\ndef get_image_files(c:PathOrStr, check_ext:bool=True, recurse=False)->FilePathList:\n    ""Return list of files in `c` that are images. `check_ext` will filter to `image_extensions`.""\n    return get_files(c, extensions=(image_extensions if check_ext else None), recurse=recurse)\n\ndef get_annotations(fname, prefix=None):\n    ""Open a COCO style json in `fname` and returns the lists of filenames (with maybe `prefix`) and labelled bboxes.""\n    annot_dict = json.load(open(fname))\n    id2images, id2bboxes, id2cats = {}, collections.defaultdict(list), collections.defaultdict(list)\n    classes = {}\n    for o in annot_dict[\'categories\']:\n        classes[o[\'id\']] = o[\'name\']\n    for o in annot_dict[\'annotations\']:\n        bb = o[\'bbox\']\n        id2bboxes[o[\'image_id\']].append([bb[1],bb[0], bb[3]+bb[1], bb[2]+bb[0]])\n        id2cats[o[\'image_id\']].append(classes[o[\'category_id\']])\n    for o in annot_dict[\'images\']:\n        if o[\'id\'] in id2bboxes:\n            id2images[o[\'id\']] = ifnone(prefix, \'\') + o[\'file_name\']\n    ids = list(id2images.keys())\n    return [id2images[k] for k in ids], [[id2bboxes[k], id2cats[k]] for k in ids]\n\ndef bb_pad_collate(samples:BatchSamples, pad_idx:int=0) -> Tuple[FloatTensor, Tuple[LongTensor, LongTensor]]:\n    ""Function that collect `samples` of labelled bboxes and adds padding with `pad_idx`.""\n    if isinstance(samples[0][1], int): return data_collate(samples)\n    max_len = max([len(s[1].data[1]) for s in samples])\n    bboxes = torch.zeros(len(samples), max_len, 4)\n    labels = torch.zeros(len(samples), max_len).long() + pad_idx\n    imgs = []\n    for i,s in enumerate(samples):\n        imgs.append(s[0].data[None])\n        bbs, lbls = s[1].data\n        if not (bbs.nelement() == 0):\n            bboxes[i,-len(lbls):] = bbs\n            labels[i,-len(lbls):] = tensor(lbls)\n    return torch.cat(imgs,0), (bboxes,labels)\n\ndef normalize(x:TensorImage, mean:FloatTensor,std:FloatTensor)->TensorImage:\n    ""Normalize `x` with `mean` and `std`.""\n    return (x-mean[...,None,None]) / std[...,None,None]\n\ndef denormalize(x:TensorImage, mean:FloatTensor,std:FloatTensor, do_x:bool=True)->TensorImage:\n    ""Denormalize `x` with `mean` and `std`.""\n    return x.cpu().float()*std[...,None,None] + mean[...,None,None] if do_x else x.cpu()\n\ndef _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Tensor,Tensor]:\n    ""`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.""\n    x,y = b\n    mean,std = mean.to(x.device),std.to(x.device)\n    if do_x: x = normalize(x,mean,std)\n    if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n    return x,y\n\ndef normalize_funcs(mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Callable,Callable]:\n    ""Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.""\n    mean,std = tensor(mean),tensor(std)\n    return (partial(_normalize_batch, mean=mean, std=std, do_x=do_x, do_y=do_y),\n            partial(denormalize,      mean=mean, std=std, do_x=do_x))\n\ncifar_stats = ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nmnist_stats = ([0.131], [0.308])\n\ndef channel_view(x:Tensor)->Tensor:\n    ""Make channel the first axis of `x` and flatten remaining axes""\n    return x.transpose(0,1).contiguous().view(x.shape[1],-1)\n\nclass ImageDataBunch(DataBunch):\n    ""DataBunch suitable for computer vision.""\n    _square_show = True\n\n    @classmethod\n    def create_from_ll(cls, lls:LabelLists, bs:int=64, val_bs:int=None, ds_tfms:Optional[TfmList]=None,\n                num_workers:int=defaults.cpus, dl_tfms:Optional[Collection[Callable]]=None, device:torch.device=None,\n                test:Optional[PathOrStr]=None, collate_fn:Callable=data_collate, size:int=None, no_check:bool=False,\n                resize_method:ResizeMethod=None, mult:int=None, padding_mode:str=\'reflection\',\n                mode:str=\'bilinear\', tfm_y:bool=False)->\'ImageDataBunch\':\n        ""Create an `ImageDataBunch` from `LabelLists` `lls` with potential `ds_tfms`.""\n        lls = lls.transform(tfms=ds_tfms, size=size, resize_method=resize_method, mult=mult, padding_mode=padding_mode,\n                            mode=mode, tfm_y=tfm_y)\n        if test is not None: lls.add_test_folder(test)\n        return lls.databunch(bs=bs, val_bs=val_bs, dl_tfms=dl_tfms, num_workers=num_workers, collate_fn=collate_fn,\n                             device=device, no_check=no_check)\n\n    @classmethod\n    def from_folder(cls, path:PathOrStr, train:PathOrStr=\'train\', valid:PathOrStr=\'valid\', test:Optional[PathOrStr]=None,\n                    valid_pct=None, seed:int=None, classes:Collection=None, **kwargs:Any)->\'ImageDataBunch\':\n        ""Create from imagenet style dataset in `path` with `train`,`valid`,`test` subfolders (or provide `valid_pct`).""\n        path=Path(path)\n        il = ImageList.from_folder(path, exclude=test)\n        if valid_pct is None: src = il.split_by_folder(train=train, valid=valid)\n        else: src = il.split_by_rand_pct(valid_pct, seed)\n        src = src.label_from_folder(classes=classes)\n        return cls.create_from_ll(src, test=test, **kwargs)\n\n    @classmethod\n    def from_df(cls, path:PathOrStr, df:pd.DataFrame, folder:PathOrStr=None, label_delim:str=None, valid_pct:float=0.2,\n                seed:int=None, fn_col:IntsOrStrs=0, label_col:IntsOrStrs=1, suffix:str=\'\', **kwargs:Any)->\'ImageDataBunch\':\n        ""Create from a `DataFrame` `df`.""\n        src = (ImageList.from_df(df, path=path, folder=folder, suffix=suffix, cols=fn_col)\n                .split_by_rand_pct(valid_pct, seed)\n                .label_from_df(label_delim=label_delim, cols=label_col))\n        return cls.create_from_ll(src, **kwargs)\n\n    @classmethod\n    def from_csv(cls, path:PathOrStr, folder:PathOrStr=None, label_delim:str=None, csv_labels:PathOrStr=\'labels.csv\',\n                 valid_pct:float=0.2, seed:int=None, fn_col:int=0, label_col:int=1, suffix:str=\'\', delimiter:str=None,\n                 header:Optional[Union[int,str]]=\'infer\', **kwargs:Any)->\'ImageDataBunch\':\n        ""Create from a csv file in `path/csv_labels`.""\n        path = Path(path)\n        df = pd.read_csv(path/csv_labels, header=header, delimiter=delimiter)\n        return cls.from_df(path, df, folder=folder, label_delim=label_delim, valid_pct=valid_pct, seed=seed,\n                fn_col=fn_col, label_col=label_col, suffix=suffix, **kwargs)\n\n    @classmethod\n    def from_lists(cls, path:PathOrStr, fnames:FilePathList, labels:Collection[str], valid_pct:float=0.2, seed:int=None,\n                   item_cls:Callable=None, **kwargs):\n        ""Create from list of `fnames` in `path`.""\n        item_cls = ifnone(item_cls, ImageList)\n        fname2label = {f:l for (f,l) in zip(fnames, labels)}\n        src = (item_cls(fnames, path=path).split_by_rand_pct(valid_pct, seed)\n                                .label_from_func(lambda x:fname2label[x]))\n        return cls.create_from_ll(src, **kwargs)\n\n    @classmethod\n    def from_name_func(cls, path:PathOrStr, fnames:FilePathList, label_func:Callable, valid_pct:float=0.2, seed:int=None,\n                       **kwargs):\n        ""Create from list of `fnames` in `path` with `label_func`.""\n        src = ImageList(fnames, path=path).split_by_rand_pct(valid_pct, seed)\n        return cls.create_from_ll(src.label_from_func(label_func), **kwargs)\n\n    @classmethod\n    def from_name_re(cls, path:PathOrStr, fnames:FilePathList, pat:str, valid_pct:float=0.2, **kwargs):\n        ""Create from list of `fnames` in `path` with re expression `pat`.""\n        pat = re.compile(pat)\n        def _get_label(fn):\n            if isinstance(fn, Path): fn = fn.as_posix()\n            res = pat.search(str(fn))\n            assert res,f\'Failed to find ""{pat}"" in ""{fn}""\'\n            return res.group(1)\n        return cls.from_name_func(path, fnames, _get_label, valid_pct=valid_pct, **kwargs)\n\n    @staticmethod\n    def single_from_classes(path:Union[Path, str], classes:Collection[str], ds_tfms:TfmList=None, **kwargs):\n        ""Create an empty `ImageDataBunch` in `path` with `classes`. Typically used for inference.""\n        warn(""""""This method is deprecated and will be removed in a future version, use `load_learner` after\n             `Learner.export()`"""""", DeprecationWarning)\n        sd = ImageList([], path=path, ignore_empty=True).split_none()\n        return sd.label_const(0, label_cls=CategoryList, classes=classes).transform(ds_tfms, **kwargs).databunch()\n\n    def batch_stats(self, funcs:Collection[Callable]=None, ds_type:DatasetType=DatasetType.Train)->Tensor:\n        ""Grab a batch of data and call reduction function `func` per channel""\n        funcs = ifnone(funcs, [torch.mean,torch.std])\n        x = self.one_batch(ds_type=ds_type, denorm=False)[0].cpu()\n        return [func(channel_view(x), 1) for func in funcs]\n\n    def normalize(self, stats:Collection[Tensor]=None, do_x:bool=True, do_y:bool=False)->None:\n        ""Add normalize transform using `stats` (defaults to `DataBunch.batch_stats`)""\n        if getattr(self,\'norm\',False): raise Exception(\'Can not call normalize twice\')\n        if stats is None: self.stats = self.batch_stats()\n        else:             self.stats = stats\n        self.norm,self.denorm = normalize_funcs(*self.stats, do_x=do_x, do_y=do_y)\n        self.add_tfm(self.norm)\n        return self\n\ndef download_image(url,dest, timeout=4):\n    try: r = download_url(url, dest, overwrite=True, show_progress=False, timeout=timeout)\n    except Exception as e: print(f""Error {url} {e}"")\n\ndef _download_image_inner(dest, url, i, timeout=4):\n    suffix = re.findall(r\'\\.\\w+?(?=(?:\\?|$))\', url)\n    suffix = suffix[0] if len(suffix)>0  else \'.jpg\'\n    download_image(url, dest/f""{i:08d}{suffix}"", timeout=timeout)\n\ndef download_images(urls:Union[Path, str], dest:PathOrStr, max_pics:int=1000, max_workers:int=8, timeout=4):\n    ""Download images listed in text file `urls` to path `dest`, at most `max_pics`""\n    urls = list(filter(None, open(urls).read().strip().split(""\\n"")))[:max_pics]       \n    dest = Path(dest)\n    dest.mkdir(exist_ok=True)\n    parallel(partial(_download_image_inner, dest, timeout=timeout), urls, max_workers=max_workers)\n\ndef resize_to(img, targ_sz:int, use_min:bool=False):\n    ""Size to resize to, to hit `targ_sz` at same aspect ratio, in PIL coords (i.e w*h)""\n    w,h = img.size\n    min_sz = (min if use_min else max)(w,h)\n    ratio = targ_sz/min_sz\n    return int(w*ratio),int(h*ratio)\n\ndef verify_image(file:Path, idx:int, delete:bool, max_size:Union[int,Tuple[int,int]]=None, dest:Path=None, n_channels:int=3,\n                 interp=PIL.Image.BILINEAR, ext:str=None, img_format:str=None, resume:bool=False, **kwargs):\n    ""Check if the image in `file` exists, maybe resize it and copy it in `dest`.""\n    try:\n        # deal with partially broken images as indicated by PIL warnings\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\'error\')\n            try:\n                with open(file, \'rb\') as img_file: PIL.Image.open(img_file)\n            except Warning as w:\n                if ""Possibly corrupt EXIF data"" in str(w):\n                    if delete: # green light to modify files\n                        print(f""{file}: Removing corrupt EXIF data"")\n                        warnings.simplefilter(""ignore"")\n                        # save EXIF-cleaned up image, which happens automatically\n                        PIL.Image.open(file).save(file)\n                    else: # keep user\'s files intact\n                        print(f""{file}: Not removing corrupt EXIF data, pass `delete=True` to do that"")\n                else: warnings.warn(w)\n\n        img = PIL.Image.open(file)\n        imgarr = np.array(img)\n        img_channels = 1 if len(imgarr.shape) == 2 else imgarr.shape[2]\n        if (max_size is not None and (img.height > max_size or img.width > max_size)) or img_channels != n_channels:\n            assert isinstance(dest, Path), ""You should provide `dest` Path to save resized image""\n            dest_fname = dest/file.name\n            if ext is not None: dest_fname=dest_fname.with_suffix(ext)\n            if resume and os.path.isfile(dest_fname): return\n            if max_size is not None:\n                new_sz = resize_to(img, max_size)\n                img = img.resize(new_sz, resample=interp)\n            if n_channels == 3: img = img.convert(""RGB"")\n            img.save(dest_fname, img_format, **kwargs)\n    except Exception as e:\n        print(f\'{e}\')\n        if delete: file.unlink()\n\ndef verify_images(path:PathOrStr, delete:bool=True, max_workers:int=4, max_size:Union[int]=None, recurse:bool=False,\n                  dest:PathOrStr=\'.\', n_channels:int=3, interp=PIL.Image.BILINEAR, ext:str=None, img_format:str=None,\n                  resume:bool=None, **kwargs):\n    ""Check if the images in `path` aren\'t broken, maybe resize them and copy it in `dest`.""\n    path = Path(path)\n    if resume is None and dest == \'.\': resume=False\n    dest = path/Path(dest)\n    os.makedirs(dest, exist_ok=True)\n    files = get_image_files(path, recurse=recurse)\n    func = partial(verify_image, delete=delete, max_size=max_size, dest=dest, n_channels=n_channels, interp=interp,\n                   ext=ext, img_format=img_format, resume=resume, **kwargs)\n    parallel(func, files, max_workers=max_workers)\n\nclass ImageList(ItemList):\n    ""`ItemList` suitable for computer vision.""\n    _bunch,_square_show,_square_show_res = ImageDataBunch,True,True\n    def __init__(self, *args, convert_mode=\'RGB\', after_open:Callable=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.convert_mode,self.after_open = convert_mode,after_open\n        self.copy_new += [\'convert_mode\', \'after_open\']\n        self.c,self.sizes = 3,{}\n\n    def open(self, fn):\n        ""Open image in `fn`, subclass and overwrite for custom behavior.""\n        return open_image(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n\n    def get(self, i):\n        fn = super().get(i)\n        res = self.open(fn)\n        self.sizes[i] = res.size\n        return res\n    \n    @classmethod\n    def from_folder(cls, path:PathOrStr=\'.\', extensions:Collection[str]=None, **kwargs)->ItemList:\n        ""Get the list of files in `path` that have an image suffix. `recurse` determines if we search subfolders.""\n        extensions = ifnone(extensions, image_extensions)\n        return super().from_folder(path=path, extensions=extensions, **kwargs)\n\n    @classmethod\n    def from_df(cls, df:DataFrame, path:PathOrStr, cols:IntsOrStrs=0, folder:PathOrStr=None, suffix:str=\'\', **kwargs)->\'ItemList\':\n        ""Get the filenames in `cols` of `df` with `folder` in front of them, `suffix` at the end.""\n        suffix = suffix or \'\'\n        res = super().from_df(df, path=path, cols=cols, **kwargs)\n        pref = f\'{res.path}{os.path.sep}\'\n        if folder is not None: pref += f\'{folder}{os.path.sep}\'\n        res.items = np.char.add(np.char.add(pref, res.items.astype(str)), suffix)\n        return res\n\n    @classmethod\n    def from_csv(cls, path:PathOrStr, csv_name:str, header:str=\'infer\', delimiter:str=None, **kwargs)->\'ItemList\':\n        ""Get the filenames in `path/csv_name` opened with `header`.""\n        path = Path(path)\n        df = pd.read_csv(path/csv_name, header=header, delimiter=delimiter)\n        return cls.from_df(df, path=path, **kwargs)\n\n    def reconstruct(self, t:Tensor): return Image(t.float().clamp(min=0,max=1))\n\n    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        ""Show the `xs` (inputs) and `ys` (targets) on a figure of `figsize`.""\n        rows = int(np.ceil(math.sqrt(len(xs))))\n        axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)\n        for x,y,ax in zip(xs, ys, axs.flatten()): x.show(ax=ax, y=y, **kwargs)\n        for ax in axs.flatten()[len(xs):]: ax.axis(\'off\')\n        plt.tight_layout()\n\n    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        ""Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.""\n        if self._square_show_res:\n            title = \'Ground truth\\nPredictions\'\n            rows = int(np.ceil(math.sqrt(len(xs))))\n            axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize, title=title, weight=\'bold\', size=12)\n            for x,y,z,ax in zip(xs,ys,zs,axs.flatten()): x.show(ax=ax, title=f\'{str(y)}\\n{str(z)}\', **kwargs)\n            for ax in axs.flatten()[len(xs):]: ax.axis(\'off\')\n        else:\n            title = \'Ground truth/Predictions\'\n            axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize, title=title, weight=\'bold\', size=14)\n            for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n                x.show(ax=axs[i,0], y=y, **kwargs)\n                x.show(ax=axs[i,1], y=z, **kwargs)\n\nclass ObjectCategoryProcessor(MultiCategoryProcessor):\n    ""`PreProcessor` for labelled bounding boxes.""\n    def __init__(self, ds:ItemList, pad_idx:int=0):\n        super().__init__(ds)\n        self.pad_idx = pad_idx\n        self.state_attrs.append(\'pad_idx\')\n\n    def process(self, ds:ItemList):\n        ds.pad_idx = self.pad_idx\n        super().process(ds)\n\n    def process_one(self,item): return [item[0], [self.c2i.get(o,None) for o in item[1]]]\n\n    def generate_classes(self, items):\n        ""Generate classes from unique `items` and add `background`.""\n        classes = super().generate_classes([o[1] for o in items])\n        classes = [\'background\'] + list(classes)\n        return classes\n\ndef _get_size(xs,i):\n    size = xs.sizes.get(i,None)\n    if size is None:\n        # Image hasn\'t been accessed yet, so we don\'t know its size\n        _ = xs[i]\n        size = xs.sizes[i]\n    return size\n\nclass ObjectCategoryList(MultiCategoryList):\n    ""`ItemList` for labelled bounding boxes.""\n    _processor = ObjectCategoryProcessor\n\n    def get(self, i):\n        return ImageBBox.create(*_get_size(self.x,i), *self.items[i], classes=self.classes, pad_idx=self.pad_idx)\n\n    def analyze_pred(self, pred): return pred\n\n    def reconstruct(self, t, x):\n        (bboxes, labels) = t\n        if len((labels - self.pad_idx).nonzero()) == 0: return\n        i = (labels - self.pad_idx).nonzero().min()\n        bboxes,labels = bboxes[i:],labels[i:]\n        return ImageBBox.create(*x.size, bboxes, labels=labels, classes=self.classes, scale=False)\n\nclass ObjectItemList(ImageList):\n    ""`ItemList` suitable for object detection.""\n    _label_cls,_square_show_res = ObjectCategoryList,False\n\nclass SegmentationProcessor(PreProcessor):\n    ""`PreProcessor` that stores the classes for segmentation.""\n    def __init__(self, ds:ItemList): self.classes = ds.classes\n    def process(self, ds:ItemList):  ds.classes,ds.c = self.classes,len(self.classes)\n\nclass SegmentationLabelList(ImageList):\n    ""`ItemList` for segmentation masks.""\n    _processor=SegmentationProcessor\n    def __init__(self, items:Iterator, classes:Collection=None, **kwargs):\n        super().__init__(items, **kwargs)\n        self.copy_new.append(\'classes\')\n        self.classes,self.loss_func = classes,CrossEntropyFlat(axis=1)\n\n    def open(self, fn): return open_mask(fn, after_open=self.after_open)\n    def analyze_pred(self, pred, thresh:float=0.5): return pred.argmax(dim=0)[None]\n    def reconstruct(self, t:Tensor): return ImageSegment(t)\n\nclass SegmentationItemList(ImageList):\n    ""`ItemList` suitable for segmentation tasks.""\n    _label_cls,_square_show_res = SegmentationLabelList,False\n\nclass PointsProcessor(PreProcessor):\n    ""`PreProcessor` that stores the number of targets for point regression.""\n    def __init__(self, ds:ItemList): self.c = len(ds.items[0].reshape(-1))\n    def process(self, ds:ItemList):  ds.c = self.c\n\nclass PointsLabelList(ItemList):\n    ""`ItemList` for points.""\n    _processor = PointsProcessor\n    def __init__(self, items:Iterator, **kwargs):\n        super().__init__(items, **kwargs)\n        self.loss_func = MSELossFlat()\n\n    def get(self, i):\n        o = super().get(i)\n        return ImagePoints(FlowField(_get_size(self.x,i), o), scale=True)\n\n    def analyze_pred(self, pred, thresh:float=0.5): return pred.view(-1,2)\n    def reconstruct(self, t, x): return ImagePoints(FlowField(x.size, t), scale=False)\n\nclass PointsItemList(ImageList):\n    ""`ItemList` for `Image` to `ImagePoints` tasks.""\n    _label_cls,_square_show_res = PointsLabelList,False\n\nclass ImageImageList(ImageList):\n    ""`ItemList` suitable for `Image` to `Image` tasks.""\n    _label_cls,_square_show,_square_show_res = ImageList,False,False\n\n    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        ""Show the `xs` (inputs) and `ys`(targets)  on a figure of `figsize`.""\n        axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize)\n        for i, (x,y) in enumerate(zip(xs,ys)):\n            x.show(ax=axs[i,0], **kwargs)\n            y.show(ax=axs[i,1], **kwargs)\n        plt.tight_layout()\n\n    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        ""Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.""\n        title = \'Input / Prediction / Target\'\n        axs = subplots(len(xs), 3, imgsize=imgsize, figsize=figsize, title=title, weight=\'bold\', size=14)\n        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n            x.show(ax=axs[i,0], **kwargs)\n            y.show(ax=axs[i,2], **kwargs)\n            z.show(ax=axs[i,1], **kwargs)\n\n\ndef _ll_pre_transform(self, train_tfm:List[Callable], valid_tfm:List[Callable]):\n    ""Call `train_tfm` and `valid_tfm` after opening image, before converting from `PIL.Image`""\n    self.train.x.after_open = compose(train_tfm)\n    self.valid.x.after_open = compose(valid_tfm)\n    return self\n\ndef _db_pre_transform(self, train_tfm:List[Callable], valid_tfm:List[Callable]):\n    ""Call `train_tfm` and `valid_tfm` after opening image, before converting from `PIL.Image`""\n    self.train_ds.x.after_open = compose(train_tfm)\n    self.valid_ds.x.after_open = compose(valid_tfm)\n    return self\n\ndef _presize(self, size:int, val_xtra_size:int=32, scale:Tuple[float]=(0.08, 1.0), ratio:Tuple[float]=(0.75, 4./3.),\n             interpolation:int=2):\n    ""Resize images to `size` using `RandomResizedCrop`, passing along `kwargs` to train transform""\n    return self.pre_transform(\n        tvt.RandomResizedCrop(size, scale=scale, ratio=ratio, interpolation=interpolation), \n        [tvt.Resize(size+val_xtra_size), tvt.CenterCrop(size)])\n\nLabelLists.pre_transform = _ll_pre_transform\nDataBunch.pre_transform = _db_pre_transform\nLabelLists.presize = _presize\nDataBunch.presize = _presize\n\n'"
fastai/vision/gan.py,2,"b'from ..torch_core import *\nfrom ..layers import *\nfrom ..callback import *\nfrom ..basic_data import *\nfrom ..basic_train import Learner, LearnerCallback\nfrom .image import Image\nfrom .data import ImageList\n\n__all__ = [\'basic_critic\', \'basic_generator\', \'GANModule\', \'GANLoss\', \'GANTrainer\', \'FixedGANSwitcher\', \'AdaptiveGANSwitcher\',\n           \'GANLearner\', \'NoisyItem\', \'GANItemList\', \'gan_critic\', \'AdaptiveLoss\', \'accuracy_thresh_expand\',\n           \'GANDiscriminativeLR\']\n\ndef AvgFlatten():\n    ""Takes the average of the input.""\n    return Lambda(lambda x: x.mean(0).view(1))\n\ndef basic_critic(in_size:int, n_channels:int, n_features:int=64, n_extra_layers:int=0, **conv_kwargs):\n    ""A basic critic for images `n_channels` x `in_size` x `in_size`.""\n    layers = [conv_layer(n_channels, n_features, 4, 2, 1, leaky=0.2, norm_type=None, **conv_kwargs)]#norm_type=None?\n    cur_size, cur_ftrs = in_size//2, n_features\n    layers.append(nn.Sequential(*[conv_layer(cur_ftrs, cur_ftrs, 3, 1, leaky=0.2, **conv_kwargs) for _ in range(n_extra_layers)]))\n    while cur_size > 4:\n        layers.append(conv_layer(cur_ftrs, cur_ftrs*2, 4, 2, 1, leaky=0.2, **conv_kwargs))\n        cur_ftrs *= 2 ; cur_size //= 2\n    layers += [conv2d(cur_ftrs, 1, 4, padding=0), AvgFlatten()]\n    return nn.Sequential(*layers)\n\ndef basic_generator(in_size:int, n_channels:int, noise_sz:int=100, n_features:int=64, n_extra_layers=0, **conv_kwargs):\n    ""A basic generator from `noise_sz` to images `n_channels` x `in_size` x `in_size`.""\n    cur_size, cur_ftrs = 4, n_features//2\n    while cur_size < in_size:  cur_size *= 2; cur_ftrs *= 2\n    layers = [conv_layer(noise_sz, cur_ftrs, 4, 1, transpose=True, **conv_kwargs)]\n    cur_size = 4\n    while cur_size < in_size // 2:\n        layers.append(conv_layer(cur_ftrs, cur_ftrs//2, 4, 2, 1, transpose=True, **conv_kwargs))\n        cur_ftrs //= 2; cur_size *= 2\n    layers += [conv_layer(cur_ftrs, cur_ftrs, 3, 1, 1, transpose=True, **conv_kwargs) for _ in range(n_extra_layers)]\n    layers += [conv2d_trans(cur_ftrs, n_channels, 4, 2, 1, bias=False), nn.Tanh()]\n    return nn.Sequential(*layers)\n\nclass GANModule(Module):\n    ""Wrapper around a `generator` and a `critic` to create a GAN.""\n    def __init__(self, generator:nn.Module=None, critic:nn.Module=None, gen_mode:bool=False):\n        self.gen_mode = gen_mode\n        if generator: self.generator,self.critic = generator,critic\n\n    def forward(self, *args):\n        return self.generator(*args) if self.gen_mode else self.critic(*args)\n\n    def switch(self, gen_mode:bool=None):\n        ""Put the model in generator mode if `gen_mode`, in critic mode otherwise.""\n        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode\n\nclass GANLoss(GANModule):\n    ""Wrapper around `loss_funcC` (for the critic) and `loss_funcG` (for the generator).""\n    def __init__(self, loss_funcG:Callable, loss_funcC:Callable, gan_model:GANModule):\n        super().__init__()\n        self.loss_funcG,self.loss_funcC,self.gan_model = loss_funcG,loss_funcC,gan_model\n\n    def generator(self, output, target):\n        ""Evaluate the `output` with the critic then uses `self.loss_funcG` to combine it with `target`.""\n        fake_pred = self.gan_model.critic(output)\n        return self.loss_funcG(fake_pred, target, output)\n\n    def critic(self, real_pred, input):\n        ""Create some `fake_pred` with the generator from `input` and compare them to `real_pred` in `self.loss_funcD`.""\n        fake = self.gan_model.generator(input.requires_grad_(False)).requires_grad_(True)\n        fake_pred = self.gan_model.critic(fake)\n        return self.loss_funcC(real_pred, fake_pred)\n\nclass GANTrainer(LearnerCallback):\n    ""Handles GAN Training.""\n    _order=-20\n    def __init__(self, learn:Learner, switch_eval:bool=False, clip:float=None, beta:float=0.98, gen_first:bool=False,\n                 show_img:bool=True):\n        super().__init__(learn)\n        self.switch_eval,self.clip,self.beta,self.gen_first,self.show_img = switch_eval,clip,beta,gen_first,show_img\n        self.generator,self.critic,self.switch_model = self.model.generator,self.model.critic,self.model.switch\n\n    def _set_trainable(self):\n        train_model = self.generator if     self.gen_mode else self.critic\n        loss_model  = self.generator if not self.gen_mode else self.critic\n        requires_grad(train_model, True)\n        requires_grad(loss_model, False)\n        if self.switch_eval:\n            train_model.train()\n            loss_model.eval()\n\n    def on_train_begin(self, **kwargs):\n        ""Create the optimizers for the generator and critic if necessary, initialize smootheners.""\n        if not getattr(self,\'opt_gen\',None):\n            self.opt_gen = self.opt.new([nn.Sequential(*flatten_model(self.generator))])\n        else: self.opt_gen.lr,self.opt_gen.wd = self.opt.lr,self.opt.wd\n        if not getattr(self,\'opt_critic\',None):\n            self.opt_critic = self.opt.new([nn.Sequential(*flatten_model(self.critic))])\n        else: self.opt_critic.lr,self.opt_critic.wd = self.opt.lr,self.opt.wd\n        self.gen_mode = self.gen_first\n        self.switch(self.gen_mode)\n        self.closses,self.glosses = [],[]\n        self.smoothenerG,self.smoothenerC = SmoothenValue(self.beta),SmoothenValue(self.beta)\n        #self.recorder.no_val=True\n        self.recorder.add_metric_names([\'gen_loss\', \'disc_loss\'])\n        self.imgs,self.titles = [],[]\n\n    def on_train_end(self, **kwargs):\n        ""Switch in generator mode for showing results.""\n        self.switch(gen_mode=True)\n\n    def on_batch_begin(self, last_input, last_target, **kwargs):\n        ""Clamp the weights with `self.clip` if it\'s not None, return the correct input.""\n        if self.clip is not None:\n            for p in self.critic.parameters(): p.data.clamp_(-self.clip, self.clip)\n        if last_input.dtype == torch.float16: last_target = to_half(last_target)\n        return {\'last_input\':last_input,\'last_target\':last_target} if self.gen_mode else {\'last_input\':last_target,\'last_target\':last_input}\n\n    def on_backward_begin(self, last_loss, last_output, **kwargs):\n        ""Record `last_loss` in the proper list.""\n        last_loss = last_loss.float().detach().cpu()\n        if self.gen_mode:\n            self.smoothenerG.add_value(last_loss)\n            self.glosses.append(self.smoothenerG.smooth)\n            self.last_gen = last_output.detach().cpu()\n        else:\n            self.smoothenerC.add_value(last_loss)\n            self.closses.append(self.smoothenerC.smooth)\n    \n    def on_batch_end(self, **kwargs):\n        self.opt_critic.zero_grad()\n        self.opt_gen.zero_grad()\n    \n    def on_epoch_begin(self, epoch, **kwargs):\n        ""Put the critic or the generator back to eval if necessary.""\n        self.switch(self.gen_mode)\n\n    def on_epoch_end(self, pbar, epoch, last_metrics, **kwargs):\n        ""Put the various losses in the recorder and show a sample image.""\n        if not hasattr(self, \'last_gen\') or not self.show_img: return\n        data = self.learn.data\n        img = self.last_gen[0]\n        norm = getattr(data,\'norm\',False)\n        if norm and norm.keywords.get(\'do_y\',False): img = data.denorm(img)\n        img = data.train_ds.y.reconstruct(img)\n        self.imgs.append(img)\n        self.titles.append(f\'Epoch {epoch}\')\n        pbar.show_imgs(self.imgs, self.titles)\n        return add_metrics(last_metrics, [getattr(self.smoothenerG,\'smooth\',None),getattr(self.smoothenerC,\'smooth\',None)])\n\n    def switch(self, gen_mode:bool=None):\n        ""Switch the model, if `gen_mode` is provided, in the desired mode.""\n        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode\n        self.opt.opt = self.opt_gen.opt if self.gen_mode else self.opt_critic.opt\n        self._set_trainable()\n        self.switch_model(gen_mode)\n        self.loss_func.switch(gen_mode)\n\nclass FixedGANSwitcher(LearnerCallback):\n    ""Switcher to do `n_crit` iterations of the critic then `n_gen` iterations of the generator.""\n    def __init__(self, learn:Learner, n_crit:Union[int,Callable]=1, n_gen:Union[int,Callable]=1):\n        super().__init__(learn)\n        self.n_crit,self.n_gen = n_crit,n_gen\n\n    def on_train_begin(self, **kwargs):\n        ""Initiate the iteration counts.""\n        self.n_c,self.n_g = 0,0\n\n    def on_batch_end(self, iteration, **kwargs):\n        ""Switch the model if necessary.""\n        if self.learn.gan_trainer.gen_mode:\n            self.n_g += 1\n            n_iter,n_in,n_out = self.n_gen,self.n_c,self.n_g\n        else:\n            self.n_c += 1\n            n_iter,n_in,n_out = self.n_crit,self.n_g,self.n_c\n        target = n_iter if isinstance(n_iter, int) else n_iter(n_in)\n        if target == n_out:\n            self.learn.gan_trainer.switch()\n            self.n_c,self.n_g = 0,0\n\n@dataclass\nclass AdaptiveGANSwitcher(LearnerCallback):\n    ""Switcher that goes back to generator/critic when the loss goes below `gen_thresh`/`crit_thresh`.""\n    def __init__(self, learn:Learner, gen_thresh:float=None, critic_thresh:float=None):\n        super().__init__(learn)\n        self.gen_thresh,self.critic_thresh = gen_thresh,critic_thresh\n\n    def on_batch_end(self, last_loss, **kwargs):\n        ""Switch the model if necessary.""\n        if self.gan_trainer.gen_mode:\n            if self.gen_thresh  is None:      self.gan_trainer.switch()\n            elif last_loss < self.gen_thresh: self.gan_trainer.switch()\n        else:\n            if self.critic_thresh is None:       self.gan_trainer.switch()\n            elif last_loss < self.critic_thresh: self.gan_trainer.switch()\n\ndef gan_loss_from_func(loss_gen, loss_crit, weights_gen:Tuple[float,float]=None):\n    ""Define loss functions for a GAN from `loss_gen` and `loss_crit`.""\n    def _loss_G(fake_pred, output, target, weights_gen=weights_gen):\n        ones = fake_pred.new_ones(fake_pred.shape[0])\n        weights_gen = ifnone(weights_gen, (1.,1.))\n        return weights_gen[0] * loss_crit(fake_pred, ones) + weights_gen[1] * loss_gen(output, target)\n\n    def _loss_C(real_pred, fake_pred):\n        ones  = real_pred.new_ones (real_pred.shape[0])\n        zeros = fake_pred.new_zeros(fake_pred.shape[0])\n        return (loss_crit(real_pred, ones) + loss_crit(fake_pred, zeros)) / 2\n\n    return _loss_G, _loss_C\n\nclass GANLearner(Learner):\n    ""A `Learner` suitable for GANs.""\n    def __init__(self, data:DataBunch, generator:nn.Module, critic:nn.Module, gen_loss_func:LossFunction,\n                 crit_loss_func:LossFunction, switcher:Callback=None, gen_first:bool=False, switch_eval:bool=True,\n                 show_img:bool=True, clip:float=None, **learn_kwargs):\n        gan = GANModule(generator, critic)\n        loss_func = GANLoss(gen_loss_func, crit_loss_func, gan)\n        switcher = ifnone(switcher, partial(FixedGANSwitcher, n_crit=5, n_gen=1))\n        super().__init__(data, gan, loss_func=loss_func, callback_fns=[switcher], **learn_kwargs)\n        trainer = GANTrainer(self, clip=clip, switch_eval=switch_eval, show_img=show_img)\n        self.gan_trainer = trainer\n        self.callbacks.append(trainer)\n\n    @classmethod\n    def from_learners(cls, learn_gen:Learner, learn_crit:Learner, switcher:Callback=None,\n                      weights_gen:Tuple[float,float]=None, **learn_kwargs):\n        ""Create a GAN from `learn_gen` and `learn_crit`.""\n        losses = gan_loss_from_func(learn_gen.loss_func, learn_crit.loss_func, weights_gen=weights_gen)\n        return cls(learn_gen.data, learn_gen.model, learn_crit.model, *losses, switcher=switcher, **learn_kwargs)\n\n    @classmethod\n    def wgan(cls, data:DataBunch, generator:nn.Module, critic:nn.Module, switcher:Callback=None, clip:float=0.01, **learn_kwargs):\n        ""Create a WGAN from `data`, `generator` and `critic`.""\n        return cls(data, generator, critic, NoopLoss(), WassersteinLoss(), switcher=switcher, clip=clip, **learn_kwargs)\n\nclass NoisyItem(ItemBase):\n    ""An random `ItemBase` of size `noise_sz`.""\n    def __init__(self, noise_sz): self.obj,self.data = noise_sz,torch.randn(noise_sz, 1, 1)\n    def __str__(self):  return \'\'\n    def apply_tfms(self, tfms, **kwargs): \n        for f in listify(tfms): f.resolve()\n        return self\n\nclass GANItemList(ImageList):\n    ""`ItemList` suitable for GANs.""\n    _label_cls = ImageList\n\n    def __init__(self, items, noise_sz:int=100, **kwargs):\n        super().__init__(items, **kwargs)\n        self.noise_sz = noise_sz\n        self.copy_new.append(\'noise_sz\')\n\n    def get(self, i): return NoisyItem(self.noise_sz)\n    def reconstruct(self, t): return NoisyItem(t.size(0))\n\n    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        ""Shows `ys` (target images) on a figure of `figsize`.""\n        super().show_xys(ys, xs, imgsize=imgsize, figsize=figsize, **kwargs)\n\n    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        ""Shows `zs` (generated images) on a figure of `figsize`.""\n        super().show_xys(zs, xs, imgsize=imgsize, figsize=figsize, **kwargs)\n\n_conv_args = dict(leaky=0.2, norm_type=NormType.Spectral)\n\ndef _conv(ni:int, nf:int, ks:int=3, stride:int=1, **kwargs):\n    return conv_layer(ni, nf, ks=ks, stride=stride, **_conv_args, **kwargs)\n\ndef gan_critic(n_channels:int=3, nf:int=128, n_blocks:int=3, p:int=0.15):\n    ""Critic to train a `GAN`.""\n    layers = [\n        _conv(n_channels, nf, ks=4, stride=2),\n        nn.Dropout2d(p/2),\n        res_block(nf, dense=True,**_conv_args)]\n    nf *= 2 # after dense block\n    for i in range(n_blocks):\n        layers += [\n            nn.Dropout2d(p),\n            _conv(nf, nf*2, ks=4, stride=2, self_attention=(i==0))]\n        nf *= 2\n    layers += [\n        _conv(nf, 1, ks=4, bias=False, padding=0, use_activ=False),\n        Flatten()]\n    return nn.Sequential(*layers)\n\nclass GANDiscriminativeLR(LearnerCallback):\n    ""`Callback` that handles multiplying the learning rate by `mult_lr` for the critic.""\n    def __init__(self, learn:Learner, mult_lr:float = 5.):\n        super().__init__(learn)\n        self.mult_lr = mult_lr\n\n    def on_batch_begin(self, train, **kwargs):\n        ""Multiply the current lr if necessary.""\n        if not self.learn.gan_trainer.gen_mode and train: self.learn.opt.lr *= self.mult_lr\n\n    def on_step_end(self, **kwargs):\n        ""Put the LR back to its value if necessary.""\n        if not self.learn.gan_trainer.gen_mode: self.learn.opt.lr /= self.mult_lr\n\nclass AdaptiveLoss(Module):\n    ""Expand the `target` to match the `output` size before applying `crit`.""\n    def __init__(self, crit):\n        self.crit = crit\n\n    def forward(self, output, target):\n        return self.crit(output, target[:,None].expand_as(output).float())\n\ndef accuracy_thresh_expand(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True)->Rank0Tensor:\n    ""Compute accuracy after expanding `y_true` to the size of `y_pred`.""\n    if sigmoid: y_pred = y_pred.sigmoid()\n    return ((y_pred>thresh).byte()==y_true[:,None].expand_as(y_pred).byte()).float().mean()\n'"
fastai/vision/image.py,19,"b'""`Image` provides support to convert, transform and show images""\nfrom ..torch_core import *\nfrom ..basic_data import *\nfrom ..layers import MSELossFlat\nfrom io import BytesIO\nimport PIL\n\n__all__ = [\'PIL\', \'Image\', \'ImageBBox\', \'ImageSegment\', \'ImagePoints\', \'FlowField\', \'RandTransform\', \'TfmAffine\', \'TfmCoord\',\n           \'TfmCrop\', \'TfmLighting\', \'TfmPixel\', \'Transform\', \'bb2hw\', \'image2np\', \'open_image\', \'open_mask\', \'tis2hw\',\n           \'pil2tensor\', \'scale_flow\', \'show_image\', \'CoordFunc\', \'TfmList\', \'open_mask_rle\', \'rle_encode\',\n           \'rle_decode\', \'ResizeMethod\', \'plot_flat\', \'plot_multi\', \'show_multi\', \'show_all\']\n\nResizeMethod = IntEnum(\'ResizeMethod\', \'CROP PAD SQUISH NO\')\ndef pil2tensor(image:Union[NPImage,NPArray],dtype:np.dtype)->TensorImage:\n    ""Convert PIL style `image` array to torch style image tensor.""\n    a = np.asarray(image)\n    if a.ndim==2 : a = np.expand_dims(a,2)\n    a = np.transpose(a, (1, 0, 2))\n    a = np.transpose(a, (2, 1, 0))\n    return torch.from_numpy(a.astype(dtype, copy=False) )\n\ndef image2np(image:Tensor)->np.ndarray:\n    ""Convert from torch style `image` to numpy/matplotlib style.""\n    res = image.cpu().permute(1,2,0).numpy()\n    return res[...,0] if res.shape[2]==1 else res\n\ndef bb2hw(a:Collection[int])->np.ndarray:\n    ""Convert bounding box points from (width,height,center) to (height,width,top,left).""\n    return np.array([a[1],a[0],a[3]-a[1],a[2]-a[0]])\n\ndef tis2hw(size:Union[int,TensorImageSize]) -> Tuple[int,int]:\n    ""Convert `int` or `TensorImageSize` to (height,width) of an image.""\n    if type(size) is str: raise RuntimeError(""Expected size to be an int or a tuple, got a string."")\n    return listify(size, 2) if isinstance(size, int) else listify(size[-2:],2)\n\ndef _draw_outline(o:Patch, lw:int):\n    ""Outline bounding box onto image `Patch`.""\n    o.set_path_effects([patheffects.Stroke(\n        linewidth=lw, foreground=\'black\'), patheffects.Normal()])\n\ndef _draw_rect(ax:plt.Axes, b:Collection[int], color:str=\'white\', text=None, text_size=14):\n    ""Draw bounding box on `ax`.""\n    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n    _draw_outline(patch, 4)\n    if text is not None:\n        patch = ax.text(*b[:2], text, verticalalignment=\'top\', color=color, fontsize=text_size, weight=\'bold\')\n        _draw_outline(patch,1)\n\ndef _get_default_args(func:Callable):\n    return {k: v.default\n            for k, v in inspect.signature(func).parameters.items()\n            if v.default is not inspect.Parameter.empty}\n\n@dataclass\nclass FlowField():\n    ""Wrap together some coords `flow` with a `size`.""\n    size:Tuple[int,int]\n    flow:Tensor\n\nCoordFunc = Callable[[FlowField, ArgStar, KWArgs], LogitTensorImage]\n\nclass Image(ItemBase):\n    ""Support applying transforms to image data in `px`.""\n    def __init__(self, px:Tensor):\n        self._px = px\n        self._logit_px=None\n        self._flow=None\n        self._affine_mat=None\n        self.sample_kwargs = {}\n\n    def set_sample(self, **kwargs)->\'ImageBase\':\n        ""Set parameters that control how we `grid_sample` the image after transforms are applied.""\n        self.sample_kwargs = kwargs\n        return self\n\n    def clone(self):\n        ""Mimic the behavior of torch.clone for `Image` objects.""\n        return self.__class__(self.px.clone())\n\n    @property\n    def shape(self)->Tuple[int,int,int]: return self._px.shape\n    @property\n    def size(self)->Tuple[int,int]: return self.shape[-2:]\n    @property\n    def device(self)->torch.device: return self._px.device\n\n    def __repr__(self): return f\'{self.__class__.__name__} {tuple(self.shape)}\'\n    def _repr_png_(self): return self._repr_image_format(\'png\')\n    def _repr_jpeg_(self): return self._repr_image_format(\'jpeg\')\n\n    def _repr_image_format(self, format_str):\n        with BytesIO() as str_buffer:\n            plt.imsave(str_buffer, image2np(self.px), format=format_str)\n            return str_buffer.getvalue()\n\n    def apply_tfms(self, tfms:TfmList, do_resolve:bool=True, xtra:Optional[Dict[Callable,dict]]=None,\n                   size:Optional[Union[int,TensorImageSize]]=None, resize_method:ResizeMethod=None,\n                   mult:int=None, padding_mode:str=\'reflection\', mode:str=\'bilinear\', remove_out:bool=True)->TensorImage:\n        ""Apply all `tfms` to the `Image`, if `do_resolve` picks value for random args.""\n        if not (tfms or xtra or size): return self\n        tfms = listify(tfms)\n        xtra = ifnone(xtra, {})\n        default_rsz = ResizeMethod.SQUISH if (size is not None and is_listy(size)) else ResizeMethod.CROP\n        resize_method = ifnone(resize_method, default_rsz)\n        if resize_method <= 2 and size is not None: tfms = self._maybe_add_crop_pad(tfms)\n        tfms = sorted(tfms, key=lambda o: o.tfm.order)\n        if do_resolve: _resolve_tfms(tfms)\n        x = self.clone()\n        x.set_sample(padding_mode=padding_mode, mode=mode, remove_out=remove_out)\n        if size is not None:\n            crop_target = _get_crop_target(size, mult=mult)\n            if resize_method in (ResizeMethod.CROP,ResizeMethod.PAD):\n                target = _get_resize_target(x, crop_target, do_crop=(resize_method==ResizeMethod.CROP))\n                x.resize(target)\n            elif resize_method==ResizeMethod.SQUISH: x.resize((x.shape[0],) + crop_target)\n        else: size = x.size\n        size_tfms = [o for o in tfms if isinstance(o.tfm,TfmCrop)]\n        for tfm in tfms:\n            if tfm.tfm in xtra: x = tfm(x, **xtra[tfm.tfm])\n            elif tfm in size_tfms:\n                if resize_method in (ResizeMethod.CROP,ResizeMethod.PAD):\n                    x = tfm(x, size=_get_crop_target(size,mult=mult), padding_mode=padding_mode)\n            else: x = tfm(x)\n        return x.refresh()\n\n    def refresh(self)->None:\n        ""Apply any logit, flow, or affine transfers that have been sent to the `Image`.""\n        if self._logit_px is not None:\n            self._px = self._logit_px.sigmoid_()\n            self._logit_px = None\n        if self._affine_mat is not None or self._flow is not None:\n            self._px = _grid_sample(self._px, self.flow, **self.sample_kwargs)\n            self.sample_kwargs = {}\n            self._flow = None\n        return self\n\n    def save(self, fn:PathOrStr):\n        ""Save the image to `fn`.""\n        x = image2np(self.data*255).astype(np.uint8)\n        PIL.Image.fromarray(x).save(fn)\n\n    @property\n    def px(self)->TensorImage:\n        ""Get the tensor pixel buffer.""\n        self.refresh()\n        return self._px\n    @px.setter\n    def px(self,v:TensorImage)->None:\n        ""Set the pixel buffer to `v`.""\n        self._px=v\n\n    @property\n    def flow(self)->FlowField:\n        ""Access the flow-field grid after applying queued affine transforms.""\n        if self._flow is None:\n            self._flow = _affine_grid(self.shape)\n        if self._affine_mat is not None:\n            self._flow = _affine_mult(self._flow,self._affine_mat)\n            self._affine_mat = None\n        return self._flow\n\n    @flow.setter\n    def flow(self,v:FlowField): self._flow=v\n\n    def lighting(self, func:LightingFunc, *args:Any, **kwargs:Any):\n        ""Equivalent to `image = sigmoid(func(logit(image)))`.""\n        self.logit_px = func(self.logit_px, *args, **kwargs)\n        return self\n\n    def pixel(self, func:PixelFunc, *args, **kwargs)->\'Image\':\n        ""Equivalent to `image.px = func(image.px)`.""\n        self.px = func(self.px, *args, **kwargs)\n        return self\n\n    def coord(self, func:CoordFunc, *args, **kwargs)->\'Image\':\n        ""Equivalent to `image.flow = func(image.flow, image.size)`.""\n        self.flow = func(self.flow, *args, **kwargs)\n        return self\n\n    def affine(self, func:AffineFunc, *args, **kwargs)->\'Image\':\n        ""Equivalent to `image.affine_mat = image.affine_mat @ func()`.""\n        m = tensor(func(*args, **kwargs)).to(self.device).float()\n        self.affine_mat = self.affine_mat @ m\n        return self\n\n    def resize(self, size:Union[int,TensorImageSize])->\'Image\':\n        ""Resize the image to `size`, size can be a single int.""\n        assert self._flow is None\n        if isinstance(size, int): size=(self.shape[0], size, size)\n        if tuple(size)==tuple(self.shape): return self\n        self.flow = _affine_grid(size)\n        return self\n\n    @property\n    def affine_mat(self)->AffineMatrix:\n        ""Get the affine matrix that will be applied by `refresh`.""\n        if self._affine_mat is None:\n            self._affine_mat = torch.eye(3).to(self.device)\n        return self._affine_mat\n    @affine_mat.setter\n    def affine_mat(self,v)->None: self._affine_mat=v\n\n    @property\n    def logit_px(self)->LogitTensorImage:\n        ""Get logit(image.px).""\n        if self._logit_px is None: self._logit_px = logit_(self.px)\n        return self._logit_px\n    @logit_px.setter\n    def logit_px(self,v:LogitTensorImage)->None: self._logit_px=v\n\n    @property\n    def data(self)->TensorImage:\n        ""Return this images pixels as a tensor.""\n        return self.px\n\n    def show(self, ax:plt.Axes=None, figsize:tuple=(3,3), title:Optional[str]=None, hide_axis:bool=True,\n              cmap:str=None, y:Any=None, **kwargs):\n        ""Show image on `ax` with `title`, using `cmap` if single-channel, overlaid with optional `y`""\n        cmap = ifnone(cmap, defaults.cmap)\n        ax = show_image(self, ax=ax, hide_axis=hide_axis, cmap=cmap, figsize=figsize)\n        if y is not None: y.show(ax=ax, **kwargs)\n        if title is not None: ax.set_title(title)\n\nclass ImageSegment(Image):\n    ""Support applying transforms to segmentation masks data in `px`.""\n    def lighting(self, func:LightingFunc, *args:Any, **kwargs:Any)->\'Image\': return self\n\n    def refresh(self):\n        self.sample_kwargs[\'mode\'] = \'nearest\'\n        return super().refresh()\n\n    @property\n    def data(self)->TensorImage:\n        ""Return this image pixels as a `LongTensor`.""\n        return self.px.long()\n\n    def show(self, ax:plt.Axes=None, figsize:tuple=(3,3), title:Optional[str]=None, hide_axis:bool=True,\n        cmap:str=\'tab20\', alpha:float=0.5, **kwargs):\n        ""Show the `ImageSegment` on `ax`.""\n        ax = show_image(self, ax=ax, hide_axis=hide_axis, cmap=cmap, figsize=figsize,\n                        interpolation=\'nearest\', alpha=alpha, vmin=0, **kwargs)\n        if title: ax.set_title(title)\n\n    def save(self, fn:PathOrStr):\n        ""Save the image segment to `fn`.""\n        x = image2np(self.data).astype(np.uint8)\n        PIL.Image.fromarray(x).save(fn)\n\n    def reconstruct(self, t:Tensor): return ImageSegment(t)\n\nclass ImagePoints(Image):\n    ""Support applying transforms to a `flow` of points.""\n    def __init__(self, flow:FlowField, scale:bool=True, y_first:bool=True):\n        if scale: flow = scale_flow(flow)\n        if y_first: flow.flow = flow.flow.flip(1).float()\n        self._flow = flow\n        self._affine_mat = None\n        self.flow_func = []\n        self.sample_kwargs = {}\n        self.transformed = False\n        self.loss_func = MSELossFlat()\n\n    def clone(self):\n        ""Mimic the behavior of torch.clone for `ImagePoints` objects.""\n        return self.__class__(FlowField(self.size, self.flow.flow.clone()), scale=False, y_first=False)\n\n    @property\n    def shape(self)->Tuple[int,int,int]: return (1, *self._flow.size)\n    @property\n    def size(self)->Tuple[int,int]: return self._flow.size\n    @size.setter\n    def size(self, sz:int): self._flow.size=sz\n    @property\n    def device(self)->torch.device: return self._flow.flow.device\n\n    def __repr__(self): return f\'{self.__class__.__name__} {tuple(self.size)}\'\n    def _repr_image_format(self, format_str): return None\n\n    @property\n    def flow(self)->FlowField:\n        ""Access the flow-field grid after applying queued affine and coord transforms.""\n        if self._affine_mat is not None:\n            self._flow = _affine_inv_mult(self._flow, self._affine_mat)\n            self._affine_mat = None\n            self.transformed = True\n        if len(self.flow_func) != 0:\n            for f in self.flow_func[::-1]: self._flow = f(self._flow)\n            self.transformed = True\n            self.flow_func = []\n        return self._flow\n\n    @flow.setter\n    def flow(self,v:FlowField):  self._flow=v\n\n    def coord(self, func:CoordFunc, *args, **kwargs)->\'ImagePoints\':\n        ""Put `func` with `args` and `kwargs` in `self.flow_func` for later.""\n        if \'invert\' in kwargs: kwargs[\'invert\'] = True\n        else: warn(f""{func.__name__} isn\'t implemented for {self.__class__}."")\n        self.flow_func.append(partial(func, *args, **kwargs))\n        return self\n\n    def lighting(self, func:LightingFunc, *args:Any, **kwargs:Any)->\'ImagePoints\': return self\n\n    def pixel(self, func:PixelFunc, *args, **kwargs)->\'ImagePoints\':\n        ""Equivalent to `self = func_flow(self)`.""\n        self = func(self, *args, **kwargs)\n        self.transformed=True\n        return self\n\n    def refresh(self) -> \'ImagePoints\':\n        return self\n\n    def resize(self, size:Union[int,TensorImageSize]) -> \'ImagePoints\':\n        ""Resize the image to `size`, size can be a single int.""\n        if isinstance(size, int): size=(1, size, size)\n        self._flow.size = size[1:]\n        return self\n\n    @property\n    def data(self)->Tensor:\n        ""Return the points associated to this object.""\n        flow = self.flow #This updates flow before we test if some transforms happened\n        if self.transformed:\n            if \'remove_out\' not in self.sample_kwargs or self.sample_kwargs[\'remove_out\']:\n                flow = _remove_points_out(flow)\n            self.transformed=False\n        return flow.flow.flip(1)\n\n    def show(self, ax:plt.Axes=None, figsize:tuple=(3,3), title:Optional[str]=None, hide_axis:bool=True, **kwargs):\n        ""Show the `ImagePoints` on `ax`.""\n        if ax is None: _,ax = plt.subplots(figsize=figsize)\n        pnt = scale_flow(FlowField(self.size, self.data), to_unit=False).flow.flip(1)\n        params = {\'s\': 10, \'marker\': \'.\', \'c\': \'r\', **kwargs}\n        ax.scatter(pnt[:, 0], pnt[:, 1], **params)\n        if hide_axis: ax.axis(\'off\')\n        if title: ax.set_title(title)\n\nclass ImageBBox(ImagePoints):\n    ""Support applying transforms to a `flow` of bounding boxes.""\n    def __init__(self, flow:FlowField, scale:bool=True, y_first:bool=True, labels:Collection=None,\n                 classes:dict=None, pad_idx:int=0):\n        super().__init__(flow, scale, y_first)\n        self.pad_idx = pad_idx\n        if labels is not None and len(labels)>0 and not isinstance(labels[0],Category):\n            labels = array([Category(l,classes[l]) for l in labels])\n        self.labels = labels\n\n    def clone(self) -> \'ImageBBox\':\n        ""Mimic the behavior of torch.clone for `Image` objects.""\n        flow = FlowField(self.size, self.flow.flow.clone())\n        return self.__class__(flow, scale=False, y_first=False, labels=self.labels, pad_idx=self.pad_idx)\n\n    @classmethod\n    def create(cls, h:int, w:int, bboxes:Collection[Collection[int]], labels:Collection=None, classes:dict=None,\n               pad_idx:int=0, scale:bool=True)->\'ImageBBox\':\n        ""Create an ImageBBox object from `bboxes`.""\n        if isinstance(bboxes, np.ndarray) and bboxes.dtype == np.object: bboxes = np.array([bb for bb in bboxes])\n        bboxes = tensor(bboxes).float()\n        tr_corners = torch.cat([bboxes[:,0][:,None], bboxes[:,3][:,None]], 1)\n        bl_corners = bboxes[:,1:3].flip(1)\n        bboxes = torch.cat([bboxes[:,:2], tr_corners, bl_corners, bboxes[:,2:]], 1)\n        flow = FlowField((h,w), bboxes.view(-1,2))\n        return cls(flow, labels=labels, classes=classes, pad_idx=pad_idx, y_first=True, scale=scale)\n\n    def _compute_boxes(self) -> Tuple[LongTensor, LongTensor]:\n        bboxes = self.flow.flow.flip(1).view(-1, 4, 2).contiguous().clamp(min=-1, max=1)\n        mins, maxes = bboxes.min(dim=1)[0], bboxes.max(dim=1)[0]\n        bboxes = torch.cat([mins, maxes], 1)\n        mask = (bboxes[:,2]-bboxes[:,0] > 0) * (bboxes[:,3]-bboxes[:,1] > 0)\n        if len(mask) == 0: return tensor([self.pad_idx] * 4), tensor([self.pad_idx])\n        res = bboxes[mask]\n        if self.labels is None: return res,None\n        return res, self.labels[to_np(mask).astype(bool)]\n\n    @property\n    def data(self)->Union[FloatTensor, Tuple[FloatTensor,LongTensor]]:\n        bboxes,lbls = self._compute_boxes()\n        lbls = np.array([o.data for o in lbls]) if lbls is not None else None\n        return bboxes if lbls is None else (bboxes, lbls)\n\n    def show(self, y:Image=None, ax:plt.Axes=None, figsize:tuple=(3,3), title:Optional[str]=None, hide_axis:bool=True,\n        color:str=\'white\', **kwargs):\n        ""Show the `ImageBBox` on `ax`.""\n        if ax is None: _,ax = plt.subplots(figsize=figsize)\n        bboxes, lbls = self._compute_boxes()\n        h,w = self.flow.size\n        bboxes.add_(1).mul_(torch.tensor([h/2, w/2, h/2, w/2])).long()\n        for i, bbox in enumerate(bboxes):\n            if lbls is not None: text = str(lbls[i])\n            else: text=None\n            _draw_rect(ax, bb2hw(bbox), text=text, color=color)\n\ndef open_image(fn:PathOrStr, div:bool=True, convert_mode:str=\'RGB\', cls:type=Image,\n        after_open:Callable=None)->Image:\n    ""Return `Image` object created from image in file `fn`.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"", UserWarning) # EXIF warning from TiffPlugin\n        x = PIL.Image.open(fn).convert(convert_mode)\n    if after_open: x = after_open(x)\n    x = pil2tensor(x,np.float32)\n    if div: x.div_(255)\n    return cls(x)\n\ndef open_mask(fn:PathOrStr, div=False, convert_mode=\'L\', after_open:Callable=None)->ImageSegment:\n    ""Return `ImageSegment` object create from mask in file `fn`. If `div`, divides pixel values by 255.""\n    return open_image(fn, div=div, convert_mode=convert_mode, cls=ImageSegment, after_open=after_open)\n\ndef open_mask_rle(mask_rle:str, shape:Tuple[int, int])->ImageSegment:\n    ""Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.""\n    x = FloatTensor(rle_decode(str(mask_rle), shape).astype(np.uint8))\n    x = x.view(shape[1], shape[0], -1)\n    return ImageSegment(x.permute(2,0,1))\n\ndef rle_encode(img:NPArrayMask)->str:\n    ""Return run-length encoding string from `img`.""\n    pixels = np.concatenate([[0], img.flatten() , [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \' \'.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle:str, shape:Tuple[int,int])->NPArrayMask:\n    ""Return an image array from run-length encoded string `mask_rle` with `shape`.""\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint)\n    for low, up in zip(starts, ends): img[low:up] = 1\n    return img.reshape(shape)\n\ndef show_image(img:Image, ax:plt.Axes=None, figsize:tuple=(3,3), hide_axis:bool=True, cmap:str=\'binary\',\n                alpha:float=None, **kwargs)->plt.Axes:\n    ""Display `Image` in notebook.""\n    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n    xtr = dict(cmap=cmap, alpha=alpha, **kwargs)\n    ax.imshow(image2np(img.data), **xtr) if (hasattr(img, \'data\')) else ax.imshow(img, **xtr)\n    if hide_axis: ax.axis(\'off\')\n    return ax\n\ndef scale_flow(flow, to_unit=True):\n    ""Scale the coords in `flow` to -1/1 or the image size depending on `to_unit`.""\n    s = tensor([flow.size[0]/2,flow.size[1]/2])[None]\n    if to_unit: flow.flow = flow.flow/s-1\n    else:       flow.flow = (flow.flow+1)*s\n    return flow\n\ndef _remove_points_out(flow:FlowField):\n    pad_mask = (flow.flow[:,0] >= -1) * (flow.flow[:,0] <= 1) * (flow.flow[:,1] >= -1) * (flow.flow[:,1] <= 1)\n    flow.flow = flow.flow[pad_mask]\n    return flow\n\nclass Transform():\n    ""Utility class for adding probability and wrapping support to transform `func`.""\n    _wrap=None\n    order=0\n    def __init__(self, func:Callable, order:Optional[int]=None):\n        ""Create a transform for `func` and assign it an priority `order`, attach to `Image` class.""\n        if order is not None: self.order=order\n        self.func=func\n        self.func.__name__ = func.__name__[1:] #To remove the _ that begins every transform function.\n        functools.update_wrapper(self, self.func)\n        self.func.__annotations__[\'return\'] = Image\n        self.params = copy(func.__annotations__)\n        self.def_args = _get_default_args(func)\n        setattr(Image, func.__name__,\n                lambda x, *args, **kwargs: self.calc(x, *args, **kwargs))\n\n    def __call__(self, *args:Any, p:float=1., is_random:bool=True, use_on_y:bool=True, **kwargs:Any)->Image:\n        ""Calc now if `args` passed; else create a transform called prob `p` if `random`.""\n        if args: return self.calc(*args, **kwargs)\n        else: return RandTransform(self, kwargs=kwargs, is_random=is_random, use_on_y=use_on_y, p=p)\n\n    def calc(self, x:Image, *args:Any, **kwargs:Any)->Image:\n        ""Apply to image `x`, wrapping it if necessary.""\n        if self._wrap: return getattr(x, self._wrap)(self.func, *args, **kwargs)\n        else:          return self.func(x, *args, **kwargs)\n\n    @property\n    def name(self)->str: return self.__class__.__name__\n\n    def __repr__(self)->str: return f\'{self.name} ({self.func.__name__})\'\n\n@dataclass\nclass RandTransform():\n    ""Wrap `Transform` to add randomized execution.""\n    tfm:Transform\n    kwargs:dict\n    p:float=1.0\n    resolved:dict = field(default_factory=dict)\n    do_run:bool = True\n    is_random:bool = True\n    use_on_y:bool = True\n    def __post_init__(self): functools.update_wrapper(self, self.tfm)\n\n    def resolve(self)->None:\n        ""Bind any random variables in the transform.""\n        if not self.is_random:\n            self.resolved = {**self.tfm.def_args, **self.kwargs}\n            return\n\n        self.resolved = {}\n        # for each param passed to tfm...\n        for k,v in self.kwargs.items():\n            # ...if it\'s annotated, call that fn...\n            if k in self.tfm.params:\n                rand_func = self.tfm.params[k]\n                self.resolved[k] = rand_func(*listify(v))\n            # ...otherwise use the value directly\n            else: self.resolved[k] = v\n        # use defaults for any args not filled in yet\n        for k,v in self.tfm.def_args.items():\n            if k not in self.resolved: self.resolved[k]=v\n        # anything left over must be callable without params\n        for k,v in self.tfm.params.items():\n            if k not in self.resolved and k!=\'return\': self.resolved[k]=v()\n\n        self.do_run = rand_bool(self.p)\n\n    @property\n    def order(self)->int: return self.tfm.order\n\n    def __call__(self, x:Image, *args, **kwargs)->Image:\n        ""Randomly execute our tfm on `x`.""\n        return self.tfm(x, *args, **{**self.resolved, **kwargs}) if self.do_run else x\n\ndef _resolve_tfms(tfms:TfmList):\n    ""Resolve every tfm in `tfms`.""\n    for f in listify(tfms): f.resolve()\n\ndef _grid_sample(x:TensorImage, coords:FlowField, mode:str=\'bilinear\', padding_mode:str=\'reflection\', remove_out:bool=True)->TensorImage:\n    ""Resample pixels in `coords` from `x` by `mode`, with `padding_mode` in (\'reflection\',\'border\',\'zeros\').""\n    coords = coords.flow.permute(0, 3, 1, 2).contiguous().permute(0, 2, 3, 1) # optimize layout for grid_sample\n    if mode==\'bilinear\': # hack to get smoother downwards resampling\n        mn,mx = coords.min(),coords.max()\n        # max amount we\'re affine zooming by (>1 means zooming in)\n        z = 1/(mx-mn).item()*2\n        # amount we\'re resizing by, with 100% extra margin\n        d = min(x.shape[1]/coords.shape[1], x.shape[2]/coords.shape[2])/2\n        # If we\'re resizing up by >200%, and we\'re zooming less than that, interpolate first\n        if d>1 and d>z: x = F.interpolate(x[None], scale_factor=1/d, mode=\'area\')[0]\n    kwargs = {\'mode\': mode, \'padding_mode\': padding_mode}\n    if torch.__version__ > ""1.2.0"": kwargs[\'align_corners\'] = True\n    return F.grid_sample(x[None], coords, **kwargs)[0]\n\ndef _affine_grid(size:TensorImageSize)->FlowField:\n    size = ((1,)+size)\n    N, C, H, W = size\n    grid = FloatTensor(N, H, W, 2)\n    linear_points = torch.linspace(-1, 1, W) if W > 1 else tensor([-1.])\n    grid[:, :, :, 0] = torch.ger(torch.ones(H), linear_points).expand_as(grid[:, :, :, 0])\n    linear_points = torch.linspace(-1, 1, H) if H > 1 else tensor([-1.])\n    grid[:, :, :, 1] = torch.ger(linear_points, torch.ones(W)).expand_as(grid[:, :, :, 1])\n    return FlowField(size[2:], grid)\n\ndef _affine_mult(c:FlowField,m:AffineMatrix)->FlowField:\n    ""Multiply `c` by `m` - can adjust for rectangular shaped `c`.""\n    if m is None: return c\n    size = c.flow.size()\n    h,w = c.size\n    m[0,1] *= h/w\n    m[1,0] *= w/h\n    c.flow = c.flow.view(-1,2)\n    c.flow = torch.addmm(m[:2,2], c.flow,  m[:2,:2].t()).view(size)\n    return c\n\ndef _affine_inv_mult(c, m):\n    ""Applies the inverse affine transform described in `m` to `c`.""\n    size = c.flow.size()\n    h,w = c.size\n    m[0,1] *= h/w\n    m[1,0] *= w/h\n    c.flow = c.flow.view(-1,2)\n    a = torch.inverse(m[:2,:2].t())\n    c.flow = torch.mm(c.flow - m[:2,2], a).view(size)\n    return c\n\nclass TfmAffine(Transform):\n    ""Decorator for affine tfm funcs.""\n    order,_wrap = 5,\'affine\'\nclass TfmPixel(Transform):\n    ""Decorator for pixel tfm funcs.""\n    order,_wrap = 10,\'pixel\'\nclass TfmCoord(Transform):\n    ""Decorator for coord tfm funcs.""\n    order,_wrap = 4,\'coord\'\nclass TfmCrop(TfmPixel):\n    ""Decorator for crop tfm funcs.""\n    order=99\nclass TfmLighting(Transform):\n    ""Decorator for lighting tfm funcs.""\n    order,_wrap = 8,\'lighting\'\n\ndef _round_multiple(x:int, mult:int=None)->int:\n    ""Calc `x` to nearest multiple of `mult`.""\n    return (int(x/mult+0.5)*mult) if mult is not None else x\n\ndef _get_crop_target(target_px:Union[int,TensorImageSize], mult:int=None)->Tuple[int,int]:\n    ""Calc crop shape of `target_px` to nearest multiple of `mult`.""\n    target_r,target_c = tis2hw(target_px)\n    return _round_multiple(target_r,mult),_round_multiple(target_c,mult)\n\ndef _get_resize_target(img, crop_target, do_crop=False)->TensorImageSize:\n    ""Calc size of `img` to fit in `crop_target` - adjust based on `do_crop`.""\n    if crop_target is None: return None\n    ch,r,c = img.shape\n    target_r,target_c = crop_target\n    ratio = (min if do_crop else max)(r/target_r, c/target_c)\n    return ch,int(round(r/ratio)),int(round(c/ratio)) #Sometimes those are numpy numbers and round doesn\'t return an int.\n\ndef plot_flat(r, c, figsize):\n    ""Shortcut for `enumerate(subplots.flatten())`""\n    return enumerate(plt.subplots(r, c, figsize=figsize)[1].flatten())\n\ndef plot_multi(func:Callable[[int,int,plt.Axes],None], r:int=1, c:int=1, figsize:Tuple=(12,6)):\n    ""Call `func` for every combination of `r,c` on a subplot""\n    axes = plt.subplots(r, c, figsize=figsize)[1]\n    for i in range(r):\n        for j in range(c): func(i,j,axes[i,j])\n\ndef show_multi(func:Callable[[int,int],Image], r:int=1, c:int=1, figsize:Tuple=(9,9)):\n    ""Call `func(i,j).show(ax)` for every combination of `r,c`""\n    plot_multi(lambda i,j,ax: func(i,j).show(ax), r, c, figsize=figsize)\n\ndef show_all(imgs:Collection[Image], r:int=1, c:Optional[int]=None, figsize=(12,6)):\n    ""Show all `imgs` using `r` rows""\n    imgs = listify(imgs)\n    if c is None: c = len(imgs)//r\n    for i,ax in plot_flat(r,c,figsize): imgs[i].show(ax)\n'"
fastai/vision/interpret.py,3,"b'from ..torch_core import *\nfrom ..basic_data import *\nfrom ..basic_train import *\nfrom .image import *\nfrom ..train import Interpretation\nfrom textwrap import wrap\n\n__all__ = [\'SegmentationInterpretation\', \'ObjectDetectionInterpretation\']\n\nclass SegmentationInterpretation(Interpretation):\n    ""Interpretation methods for segmenatation models.""\n    def __init__(self, learn:Learner, preds:Tensor, y_true:Tensor, losses:Tensor,\n                 ds_type:DatasetType=DatasetType.Valid):\n        super(SegmentationInterpretation, self).__init__(learn,preds,y_true,losses,ds_type)\n        self.pred_class = self.preds.argmax(dim=1)\n        self.c2i = {c:i for i,c in enumerate(self.data.classes)}\n        self.i2c = {i:c for c,i in self.c2i.items()}\n    \n    def top_losses(self, sizes:Tuple, k:int=None, largest=True):\n        ""Reduce flatten loss to give a single loss value for each image""\n        losses = self.losses.view(-1, np.prod(sizes)).mean(-1)\n        return losses.topk(ifnone(k, len(losses)), largest=largest)\n    \n    def _interp_show(self, ims:ImageSegment, classes:Collection=None, sz:int=20, cmap=\'tab20\',\n                    title_suffix:str=None):\n        ""Show ImageSegment with color mapping labels""\n        fig,axes=plt.subplots(1,2,figsize=(sz,sz))\n        np_im = to_np(ims.data).copy()\n        # tab20 - qualitative colormaps support max of 20 distinc colors\n        # if len(classes) > 20 close idxs map to same color\n        # image\n        if classes is not None:\n            class_idxs = [self.c2i[c] for c in classes]\n            mask = np.max(np.stack([np_im==i for i in class_idxs]),axis=0)\n            np_im = (np_im*mask).astype(np.float)\n            np_im[np.where(mask==0)] = np.nan\n        im=axes[0].imshow(np_im[0], cmap=cmap)\n\n        # labels\n        np_im_labels = list(np.unique(np_im[~np.isnan(np_im)]))\n        c = len(np_im_labels); n = math.ceil(np.sqrt(c))\n        label_im = np.array(np_im_labels + [np.nan]*(n**2-c)).reshape(n,n)\n        axes[1].imshow(label_im, cmap=cmap)\n        for i,l in enumerate([self.i2c[l] for l in np_im_labels]):\n            div,mod=divmod(i,n)\n            l = ""\\n"".join(wrap(l,10)) if len(l) > 10 else l\n            axes[1].text(mod, div, f""{l}"", ha=\'center\', color=\'white\', fontdict={\'size\':sz})\n\n        if title_suffix:\n            axes[0].set_title(f""{title_suffix}_imsegment"")\n            axes[1].set_title(f""{title_suffix}_labels"")\n\n    def show_xyz(self, i, classes:list=None, sz=10):\n        \'show (image, true and pred) from self.ds with color mappings, optionally only plot\'\n        x,y = self.ds[i]\n        self.ds.show_xys([x],[y], figsize=(sz/2,sz/2))\n        self._interp_show(ImageSegment(self.y_true[i]), classes, sz=sz, title_suffix=\'true\')\n        self._interp_show(ImageSegment(self.pred_class[i][None,:]), classes, sz=sz, title_suffix=\'pred\')\n\n    def _generate_confusion(self):\n        ""Average and Per Image Confusion: intersection of pixels given a true label, true label sums to 1""\n        single_img_confusion = []\n        mean_confusion = []\n        n =  self.pred_class.shape[0]\n        for c_j in range(self.data.c):\n            true_binary = self.y_true.squeeze(1) == c_j\n            total_true = true_binary.view(n,-1).sum(dim=1).float()\n            for c_i in range(self.data.c):\n                pred_binary = self.pred_class == c_i\n                total_intersect = (true_binary*pred_binary).view(n,-1).sum(dim=1).float()\n                p_given_t = (total_intersect / (total_true))\n                p_given_t_mean = p_given_t[~torch.isnan(p_given_t)].mean()\n                single_img_confusion.append(p_given_t)\n                mean_confusion.append(p_given_t_mean)\n        self.single_img_cm = to_np(torch.stack(single_img_confusion).permute(1,0).view(-1, self.data.c, self.data.c))\n        self.mean_cm = to_np(torch.tensor(mean_confusion).view(self.data.c, self.data.c))\n        return self.mean_cm, self.single_img_cm\n\n    def _plot_intersect_cm(self, cm, title=""Intersection with Predict given True""):\n        ""Plot confusion matrices: self.mean_cm or self.single_img_cm generated by `_generate_confusion`""\n        from IPython.display import display, HTML\n        fig,ax=plt.subplots(1,1,figsize=(10,10))\n        im=ax.imshow(cm, cmap=""Blues"")\n        ax.set_xlabel(""Predicted"")\n        ax.set_ylabel(""True"")\n        ax.set_title(f""{title}"")\n        ax.set_xticks(range(self.data.c))\n        ax.set_yticks(range(self.data.c))\n        ax.set_xticklabels(self.data.classes, rotation=\'vertical\')\n        ax.set_yticklabels(self.data.classes)\n        fig.colorbar(im)\n        \n        df = (pd.DataFrame([self.data.classes, cm.diagonal()], index=[\'label\', \'score\'])\n            .T.sort_values(\'score\', ascending=False))\n        with pd.option_context(\'display.max_colwidth\', pd_max_colwidth()):\n            display(HTML(df.to_html(index=False)))\n        return df\n\n\n\nclass ObjectDetectionInterpretation(Interpretation):\n    ""Interpretation methods for classification models.""\n    def __init__(self, learn:Learner, preds:Tensor, y_true:Tensor, losses:Tensor, ds_type:DatasetType=DatasetType.Valid):\n        raise NotImplementedError\n        super(ObjectDetectionInterpretation, self).__init__(learn,preds,y_true,losses,ds_type)\n\n'"
fastai/vision/learner.py,1,"b'""`Learner` support for computer vision""\nfrom ..torch_core import *\nfrom ..basic_train import *\nfrom ..basic_data import *\nfrom .image import *\nfrom . import models\nfrom ..callback import *\nfrom ..layers import *\nfrom ..callbacks.hooks import *\nfrom ..train import ClassificationInterpretation\n\n__all__ = [\'cnn_learner\', \'create_cnn\', \'create_cnn_model\', \'create_body\', \'create_head\', \'unet_learner\']\n# By default split models between first and second layer\ndef _default_split(m:nn.Module): return (m[1],)\n# Split a resnet style model\ndef _resnet_split(m:nn.Module): return (m[0][6],m[1])\n# Split squeezenet model on maxpool layers\ndef _squeezenet_split(m:nn.Module): return (m[0][0][5], m[0][0][8], m[1])\ndef _densenet_split(m:nn.Module): return (m[0][0][7],m[1])\ndef _vgg_split(m:nn.Module): return (m[0][0][22],m[1])\ndef _alexnet_split(m:nn.Module): return (m[0][0][6],m[1])\ndef _mobilenetv2_split(m:nn.Module): return (m[0][0][10],m[1])\n\n_default_meta     = {\'cut\':None, \'split\':_default_split}\n_resnet_meta      = {\'cut\':-2, \'split\':_resnet_split }\n_squeezenet_meta  = {\'cut\':-1, \'split\': _squeezenet_split}\n_densenet_meta    = {\'cut\':-1, \'split\':_densenet_split}\n_vgg_meta         = {\'cut\':-1, \'split\':_vgg_split}\n_alexnet_meta     = {\'cut\':-1, \'split\':_alexnet_split}\n_mobilenetv2_meta = {\'cut\':-1, \'split\':_mobilenetv2_split}\n\nmodel_meta = {\n    models.resnet18 :{**_resnet_meta}, models.resnet34: {**_resnet_meta},\n    models.resnet50 :{**_resnet_meta}, models.resnet101:{**_resnet_meta},\n    models.resnet152:{**_resnet_meta},\n\n    models.squeezenet1_0:{**_squeezenet_meta},\n    models.squeezenet1_1:{**_squeezenet_meta},\n\n    models.densenet121:{**_densenet_meta}, models.densenet169:{**_densenet_meta},\n    models.densenet201:{**_densenet_meta}, models.densenet161:{**_densenet_meta},\n    models.vgg11_bn:{**_vgg_meta}, models.vgg13_bn:{**_vgg_meta}, models.vgg16_bn:{**_vgg_meta}, models.vgg19_bn:{**_vgg_meta},\n    models.alexnet:{**_alexnet_meta},\n    models.mobilenet_v2:{**_mobilenetv2_meta}}\n\ndef cnn_config(arch):\n    ""Get the metadata associated with `arch`.""\n    torch.backends.cudnn.benchmark = True\n    return model_meta.get(arch, _default_meta)\n\ndef has_pool_type(m):\n    if is_pool_type(m): return True\n    for l in m.children():\n        if has_pool_type(l): return True\n    return False\n\ndef create_body(arch:Callable, pretrained:bool=True, cut:Optional[Union[int, Callable]]=None):\n    ""Cut off the body of a typically pretrained `model` at `cut` (int) or cut the model as specified by `cut(model)` (function).""\n    model = arch(pretrained)\n    cut = ifnone(cut, cnn_config(arch)[\'cut\'])\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    if   isinstance(cut, int):      return nn.Sequential(*list(model.children())[:cut])\n    elif isinstance(cut, Callable): return cut(model)\n    else:                           raise NamedError(""cut must be either integer or a function"")\n\n\ndef create_head(nf:int, nc:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5,\n                concat_pool:bool=True, bn_final:bool=False):\n    ""Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.""\n    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n    ps = listify(ps)\n    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n    layers = [pool, Flatten()]\n    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n        layers += bn_drop_lin(ni, no, True, p, actn)\n    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n    return nn.Sequential(*layers)\n\ndef create_cnn_model(base_arch:Callable, nc:int, cut:Union[int,Callable]=None, pretrained:bool=True,\n                     lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, custom_head:Optional[nn.Module]=None,\n                     bn_final:bool=False, concat_pool:bool=True):\n    ""Create custom convnet architecture""\n    body = create_body(base_arch, pretrained, cut)\n    if custom_head is None:\n        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n        head = create_head(nf, nc, lin_ftrs, ps=ps, concat_pool=concat_pool, bn_final=bn_final)\n    else: head = custom_head\n    return nn.Sequential(body, head)\n\ndef cnn_learner(data:DataBunch, base_arch:Callable, cut:Union[int,Callable]=None, pretrained:bool=True,\n                lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, custom_head:Optional[nn.Module]=None,\n                split_on:Optional[SplitFuncOrIdxList]=None, bn_final:bool=False, init=nn.init.kaiming_normal_,\n                concat_pool:bool=True, **kwargs:Any)->Learner:\n    ""Build convnet style learner.""\n    meta = cnn_config(base_arch)\n    model = create_cnn_model(base_arch, data.c, cut, pretrained, lin_ftrs, ps=ps, custom_head=custom_head,\n        bn_final=bn_final, concat_pool=concat_pool)\n    learn = Learner(data, model, **kwargs)\n    learn.split(split_on or meta[\'split\'])\n    if pretrained: learn.freeze()\n    if init: apply_init(model[1], init)\n    return learn\n\ndef create_cnn(data, base_arch, **kwargs):\n    warn(""`create_cnn` is deprecated and is now named `cnn_learner`."")\n    return cnn_learner(data, base_arch, **kwargs)\n\ndef unet_learner(data:DataBunch, arch:Callable, pretrained:bool=True, blur_final:bool=True,\n                 norm_type:Optional[NormType]=None, split_on:Optional[SplitFuncOrIdxList]=None, blur:bool=False,\n                 self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, last_cross:bool=True,\n                 bottle:bool=False, cut:Union[int,Callable]=None, **learn_kwargs:Any)->Learner:\n    ""Build Unet learner from `data` and `arch`.""\n    meta = cnn_config(arch)\n    body = create_body(arch, pretrained, cut)\n    try:    size = data.train_ds[0][0].size\n    except: size = next(iter(data.train_dl))[0].shape[-2:]\n    model = to_device(models.unet.DynamicUnet(body, n_classes=data.c, img_size=size, blur=blur, blur_final=blur_final,\n          self_attention=self_attention, y_range=y_range, norm_type=norm_type, last_cross=last_cross,\n          bottle=bottle), data.device)\n    learn = Learner(data, model, **learn_kwargs)\n    learn.split(ifnone(split_on, meta[\'split\']))\n    if pretrained: learn.freeze()\n    apply_init(model[2], nn.init.kaiming_normal_)\n    return learn\n\n@classmethod\ndef _cl_int_from_learner(cls, learn:Learner, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None, tta=False):\n    ""Create an instance of `ClassificationInterpretation`. `tta` indicates if we want to use Test Time Augmentation.""\n    preds = learn.TTA(ds_type=ds_type, with_loss=True) if tta else learn.get_preds(ds_type=ds_type, activ=activ, with_loss=True)\n\n    return cls(learn, *preds, ds_type=ds_type)\n\ndef _test_cnn(m):\n    if not isinstance(m, nn.Sequential) or not len(m) == 2: return False\n    return isinstance(m[1][0], (AdaptiveConcatPool2d, nn.AdaptiveAvgPool2d))\n\ndef _cl_int_gradcam(self, idx, ds_type:DatasetType=DatasetType.Valid, heatmap_thresh:int=16, image:bool=True):\n    m = self.learn.model.eval()\n    im,cl = self.learn.data.dl(ds_type).dataset[idx]\n    cl = int(cl)\n    xb,_ = self.data.one_item(im, detach=False, denorm=False) #put into a minibatch of batch size = 1\n    with hook_output(m[0]) as hook_a:\n        with hook_output(m[0], grad=True) as hook_g:\n            preds = m(xb)\n            preds[0,int(cl)].backward()\n    acts  = hook_a.stored[0].cpu() #activation maps\n    if (acts.shape[-1]*acts.shape[-2]) >= heatmap_thresh:\n        grad = hook_g.stored[0][0].cpu()\n        grad_chan = grad.mean(1).mean(1)\n        mult = F.relu(((acts*grad_chan[...,None,None])).sum(0))\n        if image:\n            xb_im = Image(xb[0])\n            _,ax = plt.subplots()\n            sz = list(xb_im.shape[-2:])\n            xb_im.show(ax,title=f""pred. class: {self.pred_class[idx]}, actual class: {self.learn.data.classes[cl]}"")\n            ax.imshow(mult, alpha=0.4, extent=(0,*sz[::-1],0),\n              interpolation=\'bilinear\', cmap=\'magma\')\n        return mult\n\nClassificationInterpretation.GradCAM =_cl_int_gradcam\n\ndef _cl_int_plot_top_losses(self, k, largest=True, figsize=(12,12), heatmap:bool=False, heatmap_thresh:int=16,\n                            alpha:float=0.6, cmap:str=""magma"", show_text:bool=True,\n                            return_fig:bool=None)->Optional[plt.Figure]:\n    ""Show images in `top_losses` along with their prediction, actual, loss, and probability of actual class.""\n    assert not heatmap or _test_cnn(self.learn.model), ""`heatmap=True` requires a model like `cnn_learner` produces.""\n    if heatmap is None: heatmap = _test_cnn(self.learn.model)\n    tl_val,tl_idx = self.top_losses(k, largest)\n    classes = self.data.classes\n    cols = math.ceil(math.sqrt(k))\n    rows = math.ceil(k/cols)\n    fig,axes = plt.subplots(rows, cols, figsize=figsize)\n    if show_text: fig.suptitle(\'Prediction/Actual/Loss/Probability\', weight=\'bold\', size=14)\n    for i,idx in enumerate(tl_idx):\n        im,cl = self.data.dl(self.ds_type).dataset[idx]\n        cl = int(cl)\n        title = f\'{classes[self.pred_class[idx]]}/{classes[cl]} / {self.losses[idx]:.2f} / {self.preds[idx][cl]:.2f}\' if show_text else None\n        im.show(ax=axes.flat[i], title=title)\n        if heatmap:\n            mult = self.GradCAM(idx,self.ds_type,heatmap_thresh,image=False)\n            if mult is not None:\n                sz = list(im.shape[-2:])\n                axes.flat[i].imshow(mult, alpha=alpha, extent=(0,*sz[::-1],0), interpolation=\'bilinear\', cmap=cmap)\n    if ifnone(return_fig, defaults.return_fig): return fig\n\ndef _cl_int_plot_multi_top_losses(self, samples:int=3, figsize:Tuple[int,int]=(8,8), save_misclassified:bool=False):\n    ""Show images in `top_losses` along with their prediction, actual, loss, and probability of predicted class in a multilabeled dataset.""\n    if samples >20:\n        print(""Max 20 samples"")\n        return\n    losses, idxs = self.top_losses(self.data.c)\n    l_dim = len(losses.size())\n    if l_dim == 1: losses, idxs = self.top_losses()\n    infolist, ordlosses_idxs, mismatches_idxs, mismatches, losses_mismatches, mismatchescontainer = [],[],[],[],[],[]\n    truthlabels = np.asarray(self.y_true, dtype=int)\n    classes_ids = [k for k in enumerate(self.data.classes)]\n    predclass = np.asarray(self.pred_class)\n    for i,pred in enumerate(predclass):\n        where_truth = np.nonzero((truthlabels[i]>0))[0]\n        mismatch = np.all(pred!=where_truth)\n        if mismatch:\n            mismatches_idxs.append(i)\n            if l_dim > 1 : losses_mismatches.append((losses[i][pred], i))\n            else: losses_mismatches.append((losses[i], i))\n        if l_dim > 1: infotup = (i, pred, where_truth, losses[i][pred], np.round(self.preds[i], decimals=3)[pred], mismatch)\n        else: infotup = (i, pred, where_truth, losses[i], np.round(self.preds[i], decimals=3)[pred], mismatch)\n        infolist.append(infotup)\n    ds = self.data.dl(self.ds_type).dataset\n    mismatches = ds[mismatches_idxs]\n    ordlosses = sorted(losses_mismatches, key = lambda x: x[0], reverse=True)\n    for w in ordlosses: ordlosses_idxs.append(w[1])\n    mismatches_ordered_byloss = ds[ordlosses_idxs]\n    print(f\'{str(len(mismatches))} misclassified samples over {str(len(self.data.valid_ds))} samples in the validation set.\')\n    samples = min(samples, len(mismatches))\n    for ima in range(len(mismatches_ordered_byloss)):\n        mismatchescontainer.append(mismatches_ordered_byloss[ima][0])\n    for sampleN in range(samples):\n        actualclasses = \'\'\n        for clas in infolist[ordlosses_idxs[sampleN]][2]:\n            actualclasses = f\'{actualclasses} -- {str(classes_ids[clas][1])}\'\n        imag = mismatches_ordered_byloss[sampleN][0]\n        imag = show_image(imag, figsize=figsize)\n        imag.set_title(f""""""Predicted: {classes_ids[infolist[ordlosses_idxs[sampleN]][1]][1]} \\nActual: {actualclasses}\\nLoss: {infolist[ordlosses_idxs[sampleN]][3]}\\nProbability: {infolist[ordlosses_idxs[sampleN]][4]}"""""",\n                        loc=\'left\')\n        plt.show()\n        if save_misclassified: return mismatchescontainer\n\nClassificationInterpretation.from_learner          = _cl_int_from_learner\nClassificationInterpretation.plot_top_losses       = _cl_int_plot_top_losses\nClassificationInterpretation.plot_multi_top_losses = _cl_int_plot_multi_top_losses\n\n\ndef _learner_interpret(learn:Learner, ds_type:DatasetType=DatasetType.Valid, tta=False):\n    ""Create a `ClassificationInterpretation` object from `learner` on `ds_type` with `tta`.""\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type, tta=tta)\nLearner.interpret = _learner_interpret\n'"
fastai/vision/transform.py,10,"b'""Image transformations for data augmentation. All transforms are done on the tensor level""\nfrom ..torch_core import *\nfrom .image import *\nfrom .image import _affine_mult\n\n__all__ = [\'brightness\', \'contrast\', \'crop\', \'crop_pad\', \'cutout\', \'dihedral\', \'dihedral_affine\', \'flip_affine\', \'flip_lr\',\n           \'get_transforms\', \'jitter\', \'pad\', \'perspective_warp\', \'rand_pad\', \'rand_crop\', \'rand_zoom\', \'rgb_randomize\', \'rotate\', \'skew\', \'squish\',\n           \'rand_resize_crop\', \'symmetric_warp\', \'tilt\', \'zoom\', \'zoom_crop\']\n\n_pad_mode_convert = {\'reflection\':\'reflect\', \'zeros\':\'constant\', \'border\':\'replicate\'}\n\n#NB: Although TfmLighting etc can be used as decorators, that doesn\'t work in Windows,\n#    so we do it manually for now.\n\ndef _brightness(x, change:uniform):\n    ""Apply `change` in brightness of image `x`.""\n    return x.add_(scipy.special.logit(change))\nbrightness = TfmLighting(_brightness)\n\ndef _contrast(x, scale:log_uniform):\n    ""Apply `scale` to contrast of image `x`.""\n    return x.mul_(scale)\ncontrast = TfmLighting(_contrast)\n\ndef _rotate(degrees:uniform):\n    ""Rotate image by `degrees`.""\n    angle = degrees * math.pi / 180\n    return [[cos(angle), -sin(angle), 0.],\n            [sin(angle),  cos(angle), 0.],\n            [0.        ,  0.        , 1.]]\nrotate = TfmAffine(_rotate)\n\ndef _get_zoom_mat(sw:float, sh:float, c:float, r:float)->AffineMatrix:\n    ""`sw`,`sh` scale width,height - `c`,`r` focus col,row.""\n    return [[sw, 0,  c],\n            [0, sh,  r],\n            [0,  0, 1.]]\n\ndef _zoom(scale:uniform=1.0, row_pct:uniform=0.5, col_pct:uniform=0.5):\n    ""Zoom image by `scale`. `row_pct`,`col_pct` select focal point of zoom.""\n    s = 1-1/scale\n    col_c = s * (2*col_pct - 1)\n    row_c = s * (2*row_pct - 1)\n    return _get_zoom_mat(1/scale, 1/scale, col_c, row_c)\nzoom = TfmAffine(_zoom)\n\ndef _squish(scale:uniform=1.0, row_pct:uniform=0.5, col_pct:uniform=0.5):\n    ""Squish image by `scale`. `row_pct`,`col_pct` select focal point of zoom.""\n    if scale <= 1:\n        col_c = (1-scale) * (2*col_pct - 1)\n        return _get_zoom_mat(scale, 1, col_c, 0.)\n    else:\n        row_c = (1-1/scale) * (2*row_pct - 1)\n        return _get_zoom_mat(1, 1/scale, 0., row_c)\nsquish = TfmAffine(_squish)\n\ndef _jitter(c, magnitude:uniform):\n    ""Replace pixels by random neighbors at `magnitude`.""\n    c.flow.add_((torch.rand_like(c.flow)-0.5)*magnitude*2)\n    return c\njitter = TfmCoord(_jitter)\n\ndef _flip_lr(x):\n    ""Flip `x` horizontally.""\n    #return x.flip(2)\n    if isinstance(x, ImagePoints):\n        x.flow.flow[...,0] *= -1\n        return x\n    return tensor(np.ascontiguousarray(np.array(x)[...,::-1]))\nflip_lr = TfmPixel(_flip_lr)\n\ndef _flip_affine() -> TfmAffine:\n    ""Flip `x` horizontally.""\n    return [[-1, 0, 0.],\n            [0,  1, 0],\n            [0,  0, 1.]]\nflip_affine = TfmAffine(_flip_affine)\n\ndef _dihedral(x, k:partial(uniform_int,0,7)):\n    ""Randomly flip `x` image based on `k`.""\n    flips=[]\n    if k&1: flips.append(1)\n    if k&2: flips.append(2)\n    if flips: x = torch.flip(x,flips)\n    if k&4: x = x.transpose(1,2)\n    return x.contiguous()\ndihedral = TfmPixel(_dihedral)\n\ndef _dihedral_affine(k:partial(uniform_int,0,7)):\n    ""Randomly flip `x` image based on `k`.""\n    x = -1 if k&1 else 1\n    y = -1 if k&2 else 1\n    if k&4: return [[0, x, 0.],\n                    [y, 0, 0],\n                    [0, 0, 1.]]\n    return [[x, 0, 0.],\n            [0, y, 0],\n            [0, 0, 1.]]\ndihedral_affine = TfmAffine(_dihedral_affine)\n\ndef _pad_coord(x, row_pad:int, col_pad:int, mode=\'zeros\'):\n    #TODO: implement other padding modes than zeros?\n    h,w = x.size\n    pad = torch.Tensor([w/(w + 2*col_pad), h/(h + 2*row_pad)])\n    x.flow = FlowField((h+2*row_pad, w+2*col_pad) , x.flow.flow * pad[None])\n    return x\n\ndef _pad_default(x, padding:int, mode=\'reflection\'):\n    ""Pad `x` with `padding` pixels. `mode` fills in space (\'zeros\',\'reflection\',\'border\').""\n    mode = _pad_mode_convert[mode]\n    return F.pad(x[None], (padding,)*4, mode=mode)[0]\n\ndef _pad_image_points(x, padding:int, mode=\'reflection\'):\n    return _pad_coord(x, padding, padding, mode)\n\ndef _pad(x, padding:int, mode=\'reflection\'):\n    f_pad = _pad_image_points if isinstance(x, ImagePoints) else  _pad_default\n    return f_pad(x, padding, mode)\n\npad = TfmPixel(_pad, order=-10)\n\ndef _cutout(x, n_holes:uniform_int=1, length:uniform_int=40):\n    ""Cut out `n_holes` number of square holes of size `length` in image at random locations.""\n    h,w = x.shape[1:]\n    for n in range(n_holes):\n        h_y = np.random.randint(0, h)\n        h_x = np.random.randint(0, w)\n        y1 = int(np.clip(h_y - length / 2, 0, h))\n        y2 = int(np.clip(h_y + length / 2, 0, h))\n        x1 = int(np.clip(h_x - length / 2, 0, w))\n        x2 = int(np.clip(h_x + length / 2, 0, w))\n        x[:, y1:y2, x1:x2] = 0\n    return x\n\ncutout = TfmPixel(_cutout, order=20)\n\ndef _rgb_randomize(x, channel:int=None, thresh:float=0.3):\n    ""Randomize one of the channels of the input image""\n    if channel is None: channel = np.random.randint(0, x.shape[0] - 1)\n    x[channel] = torch.rand(x.shape[1:]) * np.random.uniform(0, thresh)\n    return x\n\nrgb_randomize = TfmPixel(_rgb_randomize)\n\ndef _minus_epsilon(row_pct:float, col_pct:float, eps:float=1e-7):\n    if row_pct==1.: row_pct -= 1e-7\n    if col_pct==1.: col_pct -= 1e-7\n    return row_pct,col_pct\n\ndef _crop_default(x, size, row_pct:uniform=0.5, col_pct:uniform=0.5):\n    ""Crop `x` to `size` pixels. `row_pct`,`col_pct` select focal point of crop.""\n    rows,cols = tis2hw(size)\n    row_pct,col_pct = _minus_epsilon(row_pct,col_pct)\n    row = int((x.size(1)-rows+1) * row_pct)\n    col = int((x.size(2)-cols+1) * col_pct)\n    return x[:, row:row+rows, col:col+cols].contiguous()\n\ndef _crop_image_points(x, size, row_pct=0.5, col_pct=0.5):\n    h,w = x.size\n    rows,cols = tis2hw(size)\n    row_pct,col_pct = _minus_epsilon(row_pct,col_pct)\n    x.flow.flow.mul_(torch.Tensor([w/cols, h/rows])[None])\n    row = int((h-rows+1) * row_pct)\n    col = int((w-cols+1) * col_pct)\n    x.flow.flow.add_(-1 + torch.Tensor([w/cols-2*col/cols, h/rows-2*row/rows])[None])\n    x.size = (rows, cols)\n    return x\n\ndef _crop(x, size, row_pct:uniform=0.5, col_pct:uniform=0.5):\n    f_crop = _crop_image_points if isinstance(x, ImagePoints) else _crop_default\n    return f_crop(x, size, row_pct, col_pct)\n\ncrop = TfmPixel(_crop)\n\ndef _crop_pad_default(x, size, padding_mode=\'reflection\', row_pct:uniform = 0.5, col_pct:uniform = 0.5):\n    ""Crop and pad tfm - `row_pct`,`col_pct` sets focal point.""\n    padding_mode = _pad_mode_convert[padding_mode]\n    size = tis2hw(size)\n    if x.shape[1:] == torch.Size(size): return x\n    rows,cols = size\n    row_pct,col_pct = _minus_epsilon(row_pct,col_pct)\n    if x.size(1)<rows or x.size(2)<cols:\n        row_pad = max((rows-x.size(1)+1)//2, 0)\n        col_pad = max((cols-x.size(2)+1)//2, 0)\n        x = F.pad(x[None], (col_pad,col_pad,row_pad,row_pad), mode=padding_mode)[0]\n    row = int((x.size(1)-rows+1)*row_pct)\n    col = int((x.size(2)-cols+1)*col_pct)\n    x = x[:, row:row+rows, col:col+cols]\n    return x.contiguous() # without this, get NaN later - don\'t know why\n\ndef _crop_pad_image_points(x, size, padding_mode=\'reflection\', row_pct = 0.5, col_pct = 0.5):\n    size = tis2hw(size)\n    rows,cols = size\n    if x.size[0]<rows or x.size[1]<cols:\n        row_pad = max((rows-x.size[0]+1)//2, 0)\n        col_pad = max((cols-x.size[1]+1)//2, 0)\n        x = _pad_coord(x, row_pad, col_pad)\n    return crop(x,(rows,cols), row_pct, col_pct)\n\ndef _crop_pad(x, size, padding_mode=\'reflection\', row_pct:uniform = 0.5, col_pct:uniform = 0.5):\n    f_crop_pad = _crop_pad_image_points if isinstance(x, ImagePoints) else _crop_pad_default\n    return f_crop_pad(x, size, padding_mode, row_pct, col_pct)\n\ncrop_pad = TfmCrop(_crop_pad)\n\ndef _image_maybe_add_crop_pad(img, tfms):\n    tfm_names = [tfm.__name__ for tfm in tfms]\n    return [crop_pad()] + tfms if \'crop_pad\' not in tfm_names else tfms\nImage._maybe_add_crop_pad = _image_maybe_add_crop_pad\n\nrand_pos = {\'row_pct\':(0,1), \'col_pct\':(0,1)}\n\ndef rand_pad(padding:int, size:int, mode:str=\'reflection\'):\n    ""Fixed `mode` `padding` and random crop of `size`""\n    return [pad(padding=padding,mode=mode),\n            crop(size=size, **rand_pos)]\n\ndef rand_zoom(scale:uniform=1.0, p:float=1.):\n    ""Randomized version of `zoom`.""\n    return zoom(scale=scale, **rand_pos, p=p)\n\ndef rand_crop(*args, padding_mode=\'reflection\', p:float=1.):\n    ""Randomized version of `crop_pad`.""\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)\n\ndef zoom_crop(scale:float, do_rand:bool=False, p:float=1.0):\n    ""Randomly zoom and/or crop.""\n    zoom_fn = rand_zoom if do_rand else zoom\n    crop_fn = rand_crop if do_rand else crop_pad\n    return [zoom_fn(scale=scale, p=p), crop_fn()]\n\n# XXX: replace this with direct usage of `solve` once fastai requires pytorch 1.1+\n_solve_func = getattr(torch, \'solve\', None)\nif _solve_func is None: _solve_func = torch.gesv\n\ndef _find_coeffs(orig_pts:Points, targ_pts:Points)->Tensor:\n    ""Find 8 coeff mentioned [here](https://web.archive.org/web/20150222120106/xenia.media.mit.edu/~cwren/interpolator/).""\n    matrix = []\n    #The equations we\'ll need to solve.\n    for p1, p2 in zip(targ_pts, orig_pts):\n        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n\n    A = FloatTensor(matrix)\n    B = FloatTensor(orig_pts).view(8, 1)\n    #The 8 scalars we seek are solution of AX = B\n    return _solve_func(B,A)[0][:,0]\n\ndef _apply_perspective(coords:FlowField, coeffs:Points)->FlowField:\n    ""Transform `coords` with `coeffs`.""\n    size = coords.flow.size()\n    #compress all the dims expect the last one ang adds ones, coords become N * 3\n    coords.flow = coords.flow.view(-1,2)\n    #Transform the coeffs in a 3*3 matrix with a 1 at the bottom left\n    coeffs = torch.cat([coeffs, FloatTensor([1])]).view(3,3)\n    coords.flow = torch.addmm(coeffs[:,2], coords.flow, coeffs[:,:2].t())\n    coords.flow.mul_(1/coords.flow[:,2].unsqueeze(1))\n    coords.flow = coords.flow[:,:2].view(size)\n    return coords\n\n_orig_pts = [[-1,-1], [-1,1], [1,-1], [1,1]]\n\ndef _do_perspective_warp(c:FlowField, targ_pts:Points, invert=False):\n    ""Apply warp to `targ_pts` from `_orig_pts` to `c` `FlowField`.""\n    if invert: return _apply_perspective(c, _find_coeffs(targ_pts, _orig_pts))\n    return _apply_perspective(c, _find_coeffs(_orig_pts, targ_pts))\n\ndef _perspective_warp(c, magnitude:partial(uniform,size=8)=0, invert=False):\n    ""Apply warp of `magnitude` to `c`.""\n    magnitude = magnitude.view(4,2)\n    targ_pts = [[x+m for x,m in zip(xs, ms)] for xs, ms in zip(_orig_pts, magnitude)]\n    return _do_perspective_warp(c, targ_pts, invert)\nperspective_warp = TfmCoord(_perspective_warp)\n\ndef _symmetric_warp(c, magnitude:partial(uniform,size=4)=0, invert=False):\n    ""Apply symmetric warp of `magnitude` to `c`.""\n    m = listify(magnitude, 4)\n    targ_pts = [[-1-m[3],-1-m[1]], [-1-m[2],1+m[1]], [1+m[3],-1-m[0]], [1+m[2],1+m[0]]]\n    return _do_perspective_warp(c, targ_pts, invert)\nsymmetric_warp = TfmCoord(_symmetric_warp)\n\ndef _tilt(c, direction:uniform_int, magnitude:uniform=0, invert=False):\n    ""Tilt `c` field with random `direction` and `magnitude`.""\n    orig_pts = [[-1,-1], [-1,1], [1,-1], [1,1]]\n    if direction == 0:   targ_pts = [[-1,-1], [-1,1], [1,-1-magnitude], [1,1+magnitude]]\n    elif direction == 1: targ_pts = [[-1,-1-magnitude], [-1,1+magnitude], [1,-1], [1,1]]\n    elif direction == 2: targ_pts = [[-1,-1], [-1-magnitude,1], [1,-1], [1+magnitude,1]]\n    elif direction == 3: targ_pts = [[-1-magnitude,-1], [-1,1], [1+magnitude,-1], [1,1]]\n    coeffs = _find_coeffs(targ_pts, _orig_pts) if invert else _find_coeffs(_orig_pts, targ_pts)\n    return _apply_perspective(c, coeffs)\ntilt = TfmCoord(_tilt)\n\ndef _skew(c, direction:uniform_int, magnitude:uniform=0, invert=False):\n    ""Skew `c` field with random `direction` and `magnitude`.""\n    orig_pts = [[-1,-1], [-1,1], [1,-1], [1,1]]\n    if direction == 0:   targ_pts = [[-1-magnitude,-1], [-1,1], [1,-1], [1,1]]\n    elif direction == 1: targ_pts = [[-1,-1-magnitude], [-1,1], [1,-1], [1,1]]\n    elif direction == 2: targ_pts = [[-1,-1], [-1-magnitude,1], [1,-1], [1,1]]\n    elif direction == 3: targ_pts = [[-1,-1], [-1,1+magnitude], [1,-1], [1,1]]\n    elif direction == 4: targ_pts = [[-1,-1], [-1,1], [1+magnitude,-1], [1,1]]\n    elif direction == 5: targ_pts = [[-1,-1], [-1,1], [1,-1-magnitude], [1,1]]\n    elif direction == 6: targ_pts = [[-1,-1], [-1,1], [1,-1], [1+magnitude,1]]\n    elif direction == 7: targ_pts = [[-1,-1], [-1,1], [1,-1], [1,1+magnitude]]\n    coeffs = _find_coeffs(targ_pts, _orig_pts) if invert else _find_coeffs(_orig_pts, targ_pts)\n    return _apply_perspective(c, coeffs)\nskew = TfmCoord(_skew)\n\ndef get_transforms(do_flip:bool=True, flip_vert:bool=False, max_rotate:float=10., max_zoom:float=1.1,\n                   max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n                   p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n    ""Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.""\n    res = [rand_crop()]\n    if do_flip:    res.append(dihedral_affine() if flip_vert else flip_lr(p=0.5))\n    if max_warp:   res.append(symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine))\n    if max_rotate: res.append(rotate(degrees=(-max_rotate,max_rotate), p=p_affine))\n    if max_zoom>1: res.append(rand_zoom(scale=(1.,max_zoom), p=p_affine))\n    if max_lighting:\n        res.append(brightness(change=(0.5*(1-max_lighting), 0.5*(1+max_lighting)), p=p_lighting))\n        res.append(contrast(scale=(1-max_lighting, 1/(1-max_lighting)), p=p_lighting))\n    #       train                   , valid\n    return (res + listify(xtra_tfms), [crop_pad()])\n\ndef _compute_zs_mat(sz:TensorImageSize, scale:float, squish:float,\n                   invert:bool, row_pct:float, col_pct:float)->AffineMatrix:\n    ""Utility routine to compute zoom/squish matrix.""\n    orig_ratio = math.sqrt(sz[1]/sz[0])\n    for s,r,i in zip(scale,squish, invert):\n        s,r = 1/math.sqrt(s),math.sqrt(r)\n        if s * r <= 1 and s / r <= 1: #Test if we are completely inside the picture\n            w,h = (s/r, s*r) if i else (s*r,s/r)\n            col_c = (1-w) * (2*col_pct - 1)\n            row_c = (1-h) * (2*row_pct - 1)\n            return _get_zoom_mat(w, h, col_c, row_c)\n\n    #Fallback, hack to emulate a center crop without cropping anything yet.\n    if orig_ratio > 1: return _get_zoom_mat(1/orig_ratio**2, 1, 0, 0.)\n    else:              return _get_zoom_mat(1, orig_ratio**2, 0, 0.)\n\ndef _zoom_squish(c, scale:uniform=1.0, squish:uniform=1.0, invert:rand_bool=False,\n                row_pct:uniform=0.5, col_pct:uniform=0.5):\n    #This is intended for scale, squish and invert to be of size 10 (or whatever) so that the transform\n    #can try a few zoom/squishes before falling back to center crop (like torchvision.RandomResizedCrop)\n    m = _compute_zs_mat(c.size, scale, squish, invert, row_pct, col_pct)\n    return _affine_mult(c, FloatTensor(m))\nzoom_squish = TfmCoord(_zoom_squish)\n\ndef rand_resize_crop(size:int, max_scale:float=2., ratios:Tuple[float,float]=(0.75,1.33)):\n    ""Randomly resize and crop the image to a ratio in `ratios` after a zoom of `max_scale`.""\n    return [zoom_squish(scale=(1.,max_scale,8), squish=(*ratios,8), invert=(0.5,8), row_pct=(0.,1.), col_pct=(0.,1.)),\n            crop(size=size)]\n'"
fastai/vision/tta.py,1,"b'""Brings TTA (Test Time Functionality) to the `Learner` class. Use `learner.TTA()` instead""\nfrom ..torch_core import *\nfrom ..basic_train import *\nfrom ..basic_train import _loss_func2activ\nfrom ..basic_data import DatasetType\nfrom .transform import *\n\n__all__ = []\n\ndef _tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None, scale:float=1.35) -> Iterator[List[Tensor]]:\n    ""Computes the outputs for several augmented inputs for TTA""\n    dl = learn.dl(ds_type)\n    ds = dl.dataset\n    old = ds.tfms\n    activ = ifnone(activ, _loss_func2activ(learn.loss_func))\n    augm_tfm = [o for o in learn.data.train_ds.tfms if o.tfm not in\n               (crop_pad, flip_lr, dihedral, zoom)]\n    try:\n        pbar = master_bar(range(8))\n        for i in pbar:\n            row = 1 if i&1 else 0\n            col = 1 if i&2 else 0\n            flip = i&4\n            d = {\'row_pct\':row, \'col_pct\':col, \'is_random\':False}\n            tfm = [*augm_tfm, zoom(scale=scale, **d), crop_pad(**d)]\n            if flip: tfm.append(flip_lr(p=1.))\n            ds.tfms = tfm\n            yield get_preds(learn.model, dl, pbar=pbar, activ=activ)[0]\n    finally: ds.tfms = old\n\nLearner.tta_only = _tta_only\n\ndef _TTA(learn:Learner, beta:float=0.4, scale:float=1.35, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None, with_loss:bool=False) -> Tensors:\n    ""Applies TTA to predict on `ds_type` dataset.""\n    preds,y = learn.get_preds(ds_type, activ=activ)\n    all_preds = list(learn.tta_only(ds_type=ds_type, activ=activ, scale=scale))\n    avg_preds = torch.stack(all_preds).mean(0)\n    if beta is None: return preds,avg_preds,y\n    else:\n        final_preds = preds*beta + avg_preds*(1-beta)\n        if with_loss:\n            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)\n            return final_preds, y, loss\n        return final_preds, y\n\nLearner.TTA = _TTA\n'"
fastai/widgets/__init__.py,0,b'from .class_confusion import *\nfrom .image_cleaner import *\nfrom .image_downloader import *\n'
fastai/widgets/class_confusion.py,0,"b'import math, re\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom itertools import permutations\nfrom ..tabular.data import TabularDataBunch\nfrom ..train import ClassificationInterpretation\nimport ipywidgets as widgets\nfrom pathlib import Path\n\nclass ClassConfusion():\n    ""Plot the most confused datapoints and statistics for the models misses."" \n    def __init__(self, interp:ClassificationInterpretation, classlist:list, \n               is_ordered:bool=False, cut_off:int=100, varlist:list=None,\n               figsize:tuple=(8,8)):\n        self.interp = interp\n        self._is_tab = isinstance(interp.learn.data, TabularDataBunch)\n        if self._is_tab:\n            if interp.learn.data.train_ds.x.cont_names != []: \n                for x in range(len(interp.learn.data.procs)):\n                      if ""Normalize"" in str(interp.learn.data.procs[x]):\n                            self.means = interp.learn.data.train_ds.x.processor[0].procs[x].means\n                            self.stds = interp.learn.data.train_ds.x.processor[0].procs[x].stds\n        self.is_ordered = is_ordered\n        self.cut_off = cut_off\n        self.figsize = figsize\n        self.varlist = varlist\n        self.classl = classlist\n        self._show_losses(classlist)\n        \n    def _show_losses(self, classl:list, **kwargs):\n        ""Checks if the model is for Tabular or Images and gathers top losses""\n        _, self.tl_idx = self.interp.top_losses(len(self.interp.losses))\n        self._tab_losses() if self._is_tab else self._create_tabs()\n        \n    def _create_tabs(self):\n        ""Creates a tab for each variable""\n        self.lis = self.classl if self.is_ordered else list(permutations(self.classl, 2))\n        if self._is_tab:\n            self._boxes = len(self.df_list)\n            self._cols = math.ceil(math.sqrt(self._boxes))\n            self._rows = math.ceil(self._boxes/self._cols)\n            self.tbnames = list(self.df_list[0].columns)[:-1] if self.varlist is None else self.varlist\n        else:\n            vals = self.interp.most_confused()\n            self._ranges = []\n            self.tbnames = []\n            self._boxes = int(input(\'Please enter a value for `k`, or the top images you will see: \'))\n            for x in iter(vals):\n                for y in range(len(self.lis)):\n                    if x[0:2] == self.lis[y]:\n                        self._ranges.append(x[2])\n                        self.tbnames.append(str(x[0] + \' | \' + x[1]))\n        items = [widgets.Output() for i, tab in enumerate(self.tbnames)]\n        self.tabs = widgets.Tab()\n        self.tabs.children = items\n        for i in range(len(items)):\n            self.tabs.set_title(i, self.tbnames[i])\n        self._populate_tabs()\n        \n    def _populate_tabs(self):\n        ""Adds relevant graphs to each tab""\n        with tqdm(total=len(self.tbnames)) as pbar:\n            for i, tab in enumerate(self.tbnames):\n                with self.tabs.children[i]:\n                    self._plot_tab(tab) if self._is_tab else self._plot_imgs(tab, i)\n                pbar.update(1)\n        display(self.tabs)\n        \n    def _plot_tab(self, tab:str):\n        ""Generates graphs""\n        if self._boxes is not None:\n            fig, ax = plt.subplots(self._boxes, figsize=self.figsize)\n        else:\n            fig, ax = plt.subplots(self._cols, self._rows, figsize=self.figsize)\n        fig.subplots_adjust(hspace=.5)\n        for j, x in enumerate(self.df_list):\n            title = f\'{"""".join(x.columns[-1])} {tab} distribution\'\n            \n            if self._boxes is None:\n                row = int(j / self._cols)\n                col = j % row\n            if tab in self.cat_names:\n                vals = pd.value_counts(x[tab].values)\n                if self._boxes is not None:\n                    if vals.nunique() < 10:\n                        fig = vals.plot(kind=\'bar\', title=title,  ax=ax[j], rot=0, width=.75)\n                    elif vals.nunique() > self.cut_off:\n                        print(f\'Number of values is above {self.cut_off}\')\n                    else:\n                        fig = vals.plot(kind=\'barh\', title=title,  ax=ax[j], width=.75)   \n                else:\n                    fig = vals.plot(kind=\'barh\', title=title,  ax=ax[row, col], width=.75)\n            else:\n                vals = x[tab]\n                if self._boxes is not None:\n                    axs = vals.plot(kind=\'hist\', ax=ax[j], title=title, y=\'Frequency\')\n                else:\n                    axs = vals.plot(kind=\'hist\', ax=ax[row, col], title=title, y=\'Frequency\')\n                axs.set_ylabel(\'Frequency\')\n                if len(set(vals)) > 1:\n                    vals.plot(kind=\'kde\', ax=axs, title=title, secondary_y=True)\n                else:\n                    print(\'Less than two unique values, cannot graph the KDE\')\n        plt.show(fig)\n        plt.tight_layout()\n\n    def _plot_imgs(self, tab:str, i:int ,**kwargs):\n        ""Plots the most confused images""\n        classes_gnd = self.interp.data.classes\n        x = 0\n        if self._ranges[i] < self._boxes:\n            cols = math.ceil(math.sqrt(self._ranges[i]))\n            rows = math.ceil(self._ranges[i]/cols)\n        if self._ranges[i] < 4 or self._boxes < 4:\n            cols = 2\n            rows = 2\n        else:\n            cols = math.ceil(math.sqrt(self._boxes))\n            rows = math.ceil(self._boxes/cols)\n        fig, ax = plt.subplots(rows, cols, figsize=self.figsize)\n        [axi.set_axis_off() for axi in ax.ravel()]\n        for j, idx in enumerate(self.tl_idx):\n            if self._boxes < x+1 or x > self._ranges[i]:\n                break\n            da, cl = self.interp.data.dl(self.interp.ds_type).dataset[idx]\n            row = (int)(x / cols)\n            col = x % cols\n            if str(cl) == tab.split(\' \')[0] and str(classes_gnd[self.interp.pred_class[idx]]) == tab.split(\' \')[2]:\n                img, lbl = self.interp.data.valid_ds[idx]\n                fn = self.interp.data.valid_ds.x.items[idx]\n                fn = Path(fn).name\n                img.show(ax=ax[row, col])\n                ax[row,col].set_title(fn)\n                x += 1\n        plt.show(fig)\n        plt.tight_layout()\n\n    def _tab_losses(self, **kwargs):\n        ""Gathers dataframes of the combinations data""\n        classes = self.interp.data.classes\n        cat_names = self.interp.data.x.cat_names\n        cont_names = self.interp.data.x.cont_names\n        comb = self.classl if self.is_ordered else list(permutations(self.classl,2))\n        self.df_list = []\n        arr = []\n        for i, idx in enumerate(self.tl_idx):\n            da, _ = self.interp.data.dl(self.interp.ds_type).dataset[idx]\n            res = \'\'\n            for c, n in zip(da.cats, da.names[:len(da.cats)]):\n                string = f\'{da.classes[n][c]}\'\n                if string == \'True\' or string == \'False\':\n                    string += \';\'\n                    res += string\n                else:\n                    string = string[1:]\n                    res += string + \';\'\n            for c, n in zip(da.conts, da.names[len(da.cats):]):\n                res += f\'{c:.4f};\'\n            arr.append(res)\n        f = pd.DataFrame([ x.split(\';\')[:-1] for x in arr], columns=da.names)\n        for i, var in enumerate(self.interp.data.cont_names):\n            f[var] = f[var].apply(lambda x: float(x) * self.stds[var] + self.means[var])\n        f[\'Original\'] = \'Original\'\n        self.df_list.append(f)\n        for j, x in enumerate(comb):\n            arr = []\n            for i, idx in enumerate(self.tl_idx):\n                da, cl = self.interp.data.dl(self.interp.ds_type).dataset[idx]\n                cl = int(cl)\n                if classes[self.interp.pred_class[idx]] == comb[j][0] and classes[cl] == comb[j][1]:\n                    res = \'\'\n                    for c, n in zip(da.cats, da.names[:len(da.cats)]):\n                        string = f\'{da.classes[n][c]}\'\n                        if string == \'True\' or string == \'False\':\n                            string += \';\'\n                            res += string\n                        else:\n                            string = string[1:]\n                            res += string + \';\'\n                    for c, n in zip(da.conts, da.names[len(da.cats):]):\n                        res += f\'{c:.4f};\'\n                    arr.append(res)      \n            f = pd.DataFrame([ x.split(\';\')[:-1] for x in arr], columns=da.names)\n            for i, var in enumerate(self.interp.data.cont_names):\n                f[var] = f[var].apply(lambda x: float(x) * self.stds[var] + self.means[var])\n            f[str(x)] = str(x)\n            self.df_list.append(f)\n        self.cat_names = cat_names\n        self._create_tabs()\n'"
fastai/widgets/image_cleaner.py,8,"b'from abc import ABC\nfrom itertools import chain, islice\nfrom math import ceil\n\nfrom ..torch_core import *\nfrom ..basic_train import *\nfrom ..basic_data import *\nfrom ..data_block import LabelLists\nfrom ..vision.transform import *\nfrom ..vision.image import *\nfrom ..callbacks.hooks import *\nfrom ..layers import *\nfrom ipywidgets import widgets, Layout\nfrom IPython.display import clear_output, display\n\n__all__ = [\'DatasetFormatter\', \'ImageCleaner\', \'PredictionsCorrector\', \'data_deleter\']\n\nclass DatasetFormatter():\n    ""Returns a dataset with the appropriate format and file indices to be displayed.""\n    @classmethod\n    def from_toplosses(cls, learn, n_imgs=None, **kwargs):\n        ""Gets indices with top losses.""\n        train_ds, train_idxs = cls.get_toplosses_idxs(learn, n_imgs, **kwargs)\n        return train_ds, train_idxs\n\n    @classmethod\n    def get_toplosses_idxs(cls, learn, n_imgs, **kwargs):\n        ""Sorts `ds_type` dataset by top losses and returns dataset and sorted indices.""\n        dl = learn.data.fix_dl\n        if not n_imgs: n_imgs = len(dl.dataset)\n        _,_,top_losses = learn.get_preds(ds_type=DatasetType.Fix, with_loss=True)\n        idxs = torch.topk(top_losses, n_imgs)[1]\n        return cls.padded_ds(dl.dataset, **kwargs), idxs\n\n    @staticmethod\n    def padded_ds(ll_input, size=(250, 300), resize_method=ResizeMethod.CROP, padding_mode=\'zeros\', **kwargs):\n        ""For a LabelList `ll_input`, resize each image to `size` using `resize_method` and `padding_mode`.""\n        return ll_input.transform(tfms=crop_pad(), size=size, resize_method=resize_method, padding_mode=padding_mode)\n\n    @classmethod\n    def from_similars(cls, learn, layer_ls:list=[0, 7, 2], **kwargs):\n        ""Gets the indices for the most similar images.""\n        train_ds, train_idxs = cls.get_similars_idxs(learn, layer_ls, **kwargs)\n        return train_ds, train_idxs\n\n    @classmethod\n    def get_similars_idxs(cls, learn, layer_ls, **kwargs):\n        ""Gets the indices for the most similar images in `ds_type` dataset""\n        hook = hook_output(learn.model[layer_ls[0]][layer_ls[1]][layer_ls[2]])\n        dl = learn.data.fix_dl\n\n        ds_actns = cls.get_actns(learn, hook=hook, dl=dl, **kwargs)\n        similarities = cls.comb_similarity(ds_actns, ds_actns, **kwargs)\n        idxs = cls.sort_idxs(similarities)\n        return cls.padded_ds(dl, **kwargs), idxs\n\n    @staticmethod\n    def get_actns(learn, hook:Hook, dl:DataLoader, pool=AdaptiveConcatPool2d, pool_dim:int=4, **kwargs):\n        ""Gets activations at the layer specified by `hook`, applies `pool` of dim `pool_dim` and concatenates""\n        print(\'Getting activations...\')\n\n        actns = []\n        learn.model.eval()\n        with torch.no_grad():\n            for (xb,yb) in progress_bar(dl):\n                learn.model(xb)\n                actns.append((hook.stored).cpu())\n\n        if pool:\n            pool = pool(pool_dim)\n            return pool(torch.cat(actns)).view(len(dl.x),-1)\n        else: return torch.cat(actns).view(len(dl.x),-1)\n\n\n    @staticmethod\n    def comb_similarity(t1: torch.Tensor, t2: torch.Tensor, **kwargs):\n        # https://github.com/pytorch/pytorch/issues/11202\n        ""Computes the similarity function between each embedding of `t1` and `t2` matrices.""\n\n        w1 = t1.norm(p=2, dim=1, keepdim=True)\n        w2 = w1 if t2 is t1 else t2.norm(p=2, dim=1, keepdim=True)\n\n        t = torch.mm(t1, t2.t()) / (w1 * w2.t()).clamp(min=1e-8)\n        return torch.tril(t, diagonal=-1)\n\n    def largest_indices(arr, n):\n        ""Returns the `n` largest indices from a numpy array `arr`.""\n        #https://stackoverflow.com/questions/6910641/how-do-i-get-indices-of-n-maximum-values-in-a-numpy-array\n        flat = arr.flatten()\n        indices = np.argpartition(flat, -n)[-n:]\n        indices = indices[np.argsort(-flat[indices])]\n        return np.unravel_index(indices, arr.shape)\n\n    @classmethod\n    def sort_idxs(cls, similarities):\n        ""Sorts `similarities` and return the indexes in pairs ordered by highest similarity.""\n        idxs = cls.largest_indices(similarities, len(similarities))\n        idxs = [(idxs[0][i], idxs[1][i]) for i in range(len(idxs[0]))]\n        return [e for l in idxs for e in l]\n\n    @classmethod\n    def from_most_unsure(cls, learn:Learner, num=50) -> Tuple[DataLoader, List[int], Sequence[str], List[str]]:\n        """"""\n        Gets `num` items from the test set, for which the difference in probabilities between\n        the most probable and second most probable classes is minimal.\n        """"""\n        preds, _ = learn.get_preds(DatasetType.Test)\n        classes = learn.data.train_dl.classes\n        labels = [classes[i] for i in preds.argmax(dim=1)]\n\n        most_unsure = preds.topk(2, dim=1)[0] @ torch.tensor([1.0, -1.0])\n        most_unsure.abs_()\n        idxs = most_unsure.argsort()[:num].tolist()\n        return cls.padded_ds(learn.data.test_dl), idxs, classes, labels\n\n@dataclass\nclass ImgData:\n    jpg_blob: bytes\n    label: str\n    payload: Mapping\n\nclass BasicImageWidget(ABC):\n    def __init__(self, dataset:LabelLists, fns_idxs:Collection[int], batch_size=5, drop_batch_on_nonfile=False,\n                 classes:Optional[Sequence[str]]=None, labels:Optional[Sequence[str]]=None,\n                 before_next_batch:Optional[Callable[[Tuple[Mapping, ...]], Any]]=None):\n        super().__init__()\n        self._dataset,self.batch_size,self._labels,self.before_next_batch = dataset,batch_size,labels,before_next_batch\n        self._classes = classes or dataset.classes\n        self._all_images = self.create_image_list(fns_idxs, drop_batch_on_nonfile)\n\n    @staticmethod\n    def make_img_widget(img:bytes, layout=Layout(height=\'250px\', width=\'300px\'), format=\'jpg\') -> widgets.Image:\n        ""Returns an image widget for specified file name `img`.""\n        return widgets.Image(value=img, format=format, layout=layout)\n\n    @staticmethod\n    def make_button_widget(label:str, handler:Callable, img_idx:Optional[int]=None,\n                           style:str=None, layout=Layout(width=\'auto\')) -> widgets.Button:\n        ""Return a Button widget with specified `handler`.""\n        btn = widgets.Button(description=label, layout=layout)\n        btn.on_click(handler)\n        if style is not None: btn.button_style = style\n        if img_idx is not None: btn.img_idx = img_idx\n        return btn\n\n    @staticmethod\n    def make_dropdown_widget(options:Collection, value, handler:Callable, img_idx:Optional[int]=None,\n                             description=\'\', layout=Layout(width=\'auto\')) -> widgets.Dropdown:\n        ""Return a Dropdown widget with specified `handler`.""\n        dd = widgets.Dropdown(description=description, options=options, value=value, layout=layout)\n        dd.observe(handler, names=\'value\')\n        if img_idx is not None: dd.img_idx = img_idx\n        return dd\n\n    @staticmethod\n    def make_horizontal_box(children:Collection[widgets.Widget], layout=Layout()) -> widgets.HBox:\n        ""Make a horizontal box with `children` and `layout`.""\n        return widgets.HBox(children, layout=layout)\n\n    @staticmethod\n    def make_vertical_box(children:Collection[widgets.Widget],\n                          layout=Layout(width=\'auto\', height=\'300px\', overflow_x=""hidden"")) -> widgets.VBox:\n        ""Make a vertical box with `children` and `layout`.""\n        return widgets.VBox(children, layout=layout)\n\n    def create_image_list(self, fns_idxs:Collection[int], drop_batch_on_nonfile=False) -> Iterator[ImgData]:\n        ""Create a list of images, filenames and labels but first removing files that are not supposed to be displayed.""\n        items = self._dataset.x.items\n        idxs = ((i for i in fns_idxs if Path(items[i]).is_file())\n                if not drop_batch_on_nonfile\n                else chain.from_iterable(c for c in chunks(fns_idxs, self.batch_size)\n                                           if all(Path(items[i]).is_file() for i in c)))\n        for i in idxs: yield ImgData(self._dataset.x[i]._repr_jpeg_(), self._get_label(i), self.make_payload(i))\n\n    def _get_label(self, idx):\n        ""Returns a label for an image with the given `idx`.""\n        return self._labels[idx] if self._labels is not None else self._classes[self._dataset.y[idx].data]\n\n    @abstractmethod\n    def make_payload(self, idx:int) -> Mapping:\n        ""Override in a subclass to associate an image with the given `idx` with a custom payload.""\n        pass\n\n    def _get_change_payload(self, change_owner):\n        """"""\n        Call in widget\'s on change handler to retrieve the payload.\n        Assumes the widget was created by a factory method taking `img_idx` parameter.\n        """"""\n        return self._batch_payloads[change_owner.img_idx]\n\n    def next_batch(self, _=None):\n        ""Fetches a next batch of images for rendering.""\n        if self.before_next_batch and hasattr(self, \'_batch_payloads\'): self.before_next_batch(self._batch_payloads)\n        batch = tuple(islice(self._all_images, self.batch_size))\n        self._batch_payloads = tuple(b.payload for b in batch)\n        self.render(batch)\n\n    @abstractmethod\n    def render(self, batch:Tuple[ImgData]):\n        ""Override in a subclass to render the widgets for a batch of images.""\n        pass\n\ndef data_deleter(path:PathOrStr, dataset:LabelLists, del_idx:Collection[int]):\n    ""Delete the data you want by index.Save changes in path as \'cleaned.csv\'.""\n    csv_dict = {dataset.x.items[i]: dataset.y[i] for i in range(len(dataset))}\n    for del_path in dataset.x.items[del_idx]:\n        del csv_dict[del_path]\n    csv_path = Path(path) / \'cleaned.csv\'\n    with open(csv_path, \'w\') as f:\n        csv_writer = csv.writer(f)\n        csv_writer.writerow([\'name\', \'label\'])\n        for pair in csv_dict.items():\n            pair = [os.path.relpath(pair[0], path), pair[1]]\n            csv_writer.writerow(pair)\n    return csv_path\n\nclass ImageCleaner(BasicImageWidget):\n    ""Displays images for relabeling or deletion and saves changes in `path` as \'cleaned.csv\'.""\n    def __init__(self, dataset:LabelLists, fns_idxs:Collection[int], path:PathOrStr, batch_size=5, duplicates=False):\n        super().__init__(dataset, fns_idxs, batch_size=(2 if duplicates else batch_size),\n                         drop_batch_on_nonfile=duplicates, before_next_batch=self.before_next_batch)\n        self._duplicates,self._path,self._skipped = duplicates,Path(path),0\n        self._csv_dict = {dataset.x.items[i]: dataset.y[i] for i in range(len(dataset))}\n        self._deleted_fns:List[Path] = []\n        self.next_batch()\n\n    def make_payload(self, idx:int): return {\'file_path\': self._dataset.x.items[idx]}\n\n    def before_next_batch(self, payloads:Tuple[Mapping]):\n        for p in payloads:\n            fp = p[\'file_path\']\n            if p.get(\'flagged_for_delete\'):\n                self.delete_image(fp)\n                self._deleted_fns.append(fp)\n\n    def get_widgets(self, batch:Tuple[ImgData]) -> List[widgets.Widget]:\n        ""Create and format widget set.""\n        widgets = []\n        for i, img in enumerate(batch):\n            img_widget = self.make_img_widget(img.jpg_blob)\n            if not self._duplicates:\n                dropdown = self.make_dropdown_widget(options=self._classes, value=img.label,\n                                                     handler=self.relabel, img_idx=i)\n            delete_btn = self.make_button_widget(\'Delete\', handler=self.on_delete, img_idx=i)\n            widgets.append(self.make_vertical_box(\n                (img_widget, delete_btn) if self._duplicates else (img_widget, dropdown, delete_btn)))\n        return widgets\n\n    def relabel(self, change):\n        ""Relabel images by moving from parent dir with old label `class_old` to parent dir with new label `class_new`.""\n        class_new,class_old = change.new,change.old\n        fp = self._get_change_payload(change.owner)[\'file_path\']\n        self._csv_dict[fp] = class_new\n\n    def on_delete(self, btn: widgets.Button):\n        ""Flag this image as delete or keep.""\n        payload = self._get_change_payload(btn)\n        flagged = payload.get(\'flagged_for_delete\', False)\n        btn.button_style = """" if flagged else ""danger""\n        payload[\'flagged_for_delete\'] = not flagged\n\n    def delete_image(self, file_path): del self._csv_dict[file_path]\n\n    def batch_contains_deleted(self, batch:Tuple[ImgData]):\n        ""Check if current batch contains already deleted images.""\n        return self._duplicates and any(img.payload[\'file_path\'] in self._deleted_fns for img in batch)\n\n    def write_csv(self):\n        # Get first element\'s file path so we write CSV to same directory as our data\n        csv_path = self._path/\'cleaned.csv\'\n        with open(csv_path, \'w\') as f:\n            csv_writer = csv.writer(f)\n            csv_writer.writerow([\'name\',\'label\'])\n            for pair in self._csv_dict.items():\n                pair = [os.path.relpath(pair[0], self._path), pair[1]]\n                csv_writer.writerow(pair)\n        return csv_path\n\n    def render(self, batch:Tuple[ImgData]):\n        ""Re-render Jupyter cell for batch of images.""\n        clear_output()\n        self.write_csv()\n        if not batch:\n            if self._skipped>0:\n                return display(f\'No images to show :). {self._skipped} pairs were \'\n                    f\'skipped since at least one of the images was deleted by the user.\')\n            return display(\'No images to show :)\')\n        if self.batch_contains_deleted(batch):\n            self.next_batch()\n            self._skipped += 1\n        else:\n            display(self.make_horizontal_box(self.get_widgets(batch)))\n            display(self.make_button_widget(\'Next Batch\', handler=self.next_batch, style=""primary""))\n\nclass PredictionsCorrector(BasicImageWidget):\n    ""Displays images for manual inspection and relabelling.""\n    def __init__(self, dataset:LabelLists, fns_idxs:Collection[int],\n                 classes:Sequence[str], labels:Sequence[str], batch_size:int=5):\n        super().__init__(dataset, fns_idxs, batch_size, classes=classes, labels=labels)\n        self.corrections:Dict[int, str] = {}\n        self.next_batch()\n\n    def show_corrections(self, ncols:int, **fig_kw):\n        ""Shows a grid of images whose predictions have been corrected.""\n        nrows = ceil(len(self.corrections) / ncols)\n        fig, axs = plt.subplots(nrows, ncols, **fig_kw)\n        axs, extra_axs = np.split(axs.flatten(), (len(self.corrections),))\n\n        for (idx, new), ax in zip(sorted(self.corrections.items()), axs):\n            old = self._get_label(idx)\n            self._dataset.x[idx].show(ax=ax, title=f\'{idx}: {old} -> {new}\')\n\n        for ax in extra_axs:\n            ax.axis(\'off\')\n            ax.axes.get_xaxis().set_visible(False)\n            ax.axes.get_yaxis().set_visible(False)\n\n    def corrected_labels(self) -> List[str]:\n        ""Returns labels for the entire test set with corrections applied.""\n        corrected = list(self._labels)\n        for i, l in self.corrections.items(): corrected[i] = l\n        return corrected\n\n    def make_payload(self, idx:int): return {\'idx\': idx}\n\n    def render(self, batch:Tuple[ImgData]):\n        clear_output()\n        if not batch:\n            return display(\'No images to show :)\')\n        else:\n            display(self.make_horizontal_box(self.get_widgets(batch)))\n            display(self.make_button_widget(\'Next Batch\', handler=self.next_batch, style=\'primary\'))\n\n    def get_widgets(self, batch:Tuple[ImgData]):\n        widgets = []\n        for i, img in enumerate(batch):\n            img_widget = self.make_img_widget(img.jpg_blob)\n            dropdown = self.make_dropdown_widget(options=self._classes, value=img.label,\n                                                 handler=self.relabel, img_idx=i)\n            widgets.append(self.make_vertical_box((img_widget, dropdown)))\n        return widgets\n\n    def relabel(self, change):\n        self.corrections[self._get_change_payload(change.owner)[\'idx\']] = change.new\n'"
fastai/widgets/image_downloader.py,0,"b'from ..core import *\nfrom ..vision.data import *\nfrom ipywidgets import widgets, Layout, Output, HBox, VBox, Text, BoundedIntText, Button, Dropdown, Box\nfrom IPython.display import clear_output, display\nfrom urllib.parse import quote\nfrom bs4 import BeautifulSoup\nimport time\n\n__all__ = [\'ImageDownloader\', \'download_google_images\']\n\n_img_sizes = {\'>400*300\':\'isz:lt,islt:qsvga\',\'>640*480\':\'isz:lt,islt:vga\',\'>800*600\':\'isz:lt,islt:svga\',\n              \'>1024*768\':\'visz:lt,islt:xga\', \'>2MP\':\'isz:lt,islt:2mp\',\'>4MP\':\'isz:lt,islt:4mp\',\'>6MP\':\'isz:lt,islt:6mp\',\n              \'>8MP\':\'isz:lt,islt:8mp\', \'>10MP\':\'isz:lt,islt:10mp\',\'>12MP\':\'isz:lt,islt:12mp\',\'>15MP\':\'isz:lt,islt:15mp\',\n              \'>20MP\':\'isz:lt,islt:20mp\',\'>40MP\':\'isz:lt,islt:40mp\',\'>70MP\':\'isz:lt,islt:70mp\'}\n\nclass ImageDownloader():\n    """"""\n    Displays a widget that allows searching and downloading images from google images search\n    in a Jupyter Notebook or Lab.\n    """"""\n    def __init__(self, path:Union[Path,str]=\'data\'):\n        ""Setup path to save images to, init the UI, and render the widgets.""\n        self._path = Path(path)\n        self._ui = self._init_ui()\n        self.render()\n\n    def _init_ui(self) -> VBox:\n        ""Initialize the widget UI and return the UI.""\n        self._search_input = Text(placeholder=""What images to search for?"")\n        self._count_input = BoundedIntText(placeholder=""How many pics?"", value=10, min=1, max=5000, step=1,\n                                           layout=Layout(width=\'60px\'))\n        self._size_input = Dropdown(options= _img_sizes.keys(), value=\'>400*300\', layout=Layout(width=\'120px\'))\n        self._download_button = Button(description=""Search & Download"", icon=""download"", layout=Layout(width=\'200px\'))\n        self._download_button.on_click(self.on_download_button_click)\n        self._output = Output()\n        self._controls_pane  = HBox([self._search_input, self._count_input, self._size_input, self._download_button],\n                                    layout=Layout(width=\'auto\', height=\'40px\'))\n        self._heading = """"\n        self._download_complete_heading = ""<h3>Download complete. Here are a few images</h3>""\n        self._preview_header = widgets.HTML(self._heading, layout=Layout(height=\'60px\'))\n        self._img_pane = Box(layout=Layout(display=\'inline\'))\n        return VBox([self._controls_pane, self._preview_header, self._img_pane])\n\n    def render(self) -> None:\n        clear_output()\n        display(self._ui)\n\n    def clear_imgs(self) -> None:\n        ""Clear the widget\'s images preview pane.""\n        self._preview_header.value = self._heading\n        self._img_pane.children = tuple()\n\n    def validate_search_input(self) -> bool:\n        ""Check if input value is empty.""\n        input = self._search_input\n        if input.value == str(): input.layout = Layout(border=""solid 2px red"", height=\'auto\')\n        else:                    self._search_input.layout = Layout()\n        return input.value != str()\n\n    def on_download_button_click(self, btn) -> None:\n        ""Download button click handler: validate search term and download images.""\n        term = self._search_input.value\n        limit = int(self._count_input.value)\n        size = self._size_input.value\n        if not self.validate_search_input(): return\n        self.clear_imgs()\n        downloaded_images = download_google_images(self._path, term, n_images=limit, size=size)\n        self.display_images_widgets(downloaded_images[:min(limit, 12)])\n        self._preview_header.value = self._download_complete_heading\n        self.render()\n\n    def display_images_widgets(self, fnames:list) -> None:\n        ""Display a few preview images in the notebook""\n        imgs = [widgets.Image(value=open(f, \'rb\').read(), width=\'200px\') for f in fnames]\n        self._img_pane.children = tuple(imgs)\n\n\ndef download_google_images(path:PathOrStr, search_term:str, size:str=\'>400*300\', n_images:int=10, format:str=\'jpg\',\n                            max_workers:int=defaults.cpus, timeout:int=4) -> FilePathList:\n    """"""\n    Search for `n_images` images on Google, matching `search_term` and `size` requirements,\n    download them into `path`/`search_term` and verify them, using `max_workers` threads.\n    """"""\n    label_path = Path(path)/search_term\n    search_url = _search_url(search_term, size=size, format=format)\n    if n_images <= 100: img_tuples = _fetch_img_tuples(search_url, format=format, n_images=n_images)\n    else:               img_tuples = _fetch_img_tuples_webdriver(search_url, format=format, n_images=n_images)\n    downloaded_images = _download_images(label_path, img_tuples, max_workers=max_workers, timeout=timeout)\n    if len(downloaded_images) == 0: raise RuntimeError(f""Couldn\'t download any images."")\n    verify_images(label_path, max_workers=max_workers)\n    return get_image_files(label_path)\n    \ndef _url_params(size:str=\'>400*300\', format:str=\'jpg\') -> str:\n    ""Build Google Images Search Url params and return them as a string.""\n    _fmts = {\'jpg\':\'ift:jpg\',\'gif\':\'ift:gif\',\'png\':\'ift:png\',\'bmp\':\'ift:bmp\', \'svg\':\'ift:svg\',\'webp\':\'webp\',\'ico\':\'ift:ico\'}\n    if size not in _img_sizes: \n        raise RuntimeError(f""""""Unexpected size argument value: {size}.\n                    See `widgets.image_downloader._img_sizes` for supported sizes."""""") \n    if format not in _fmts: \n        raise RuntimeError(f""Unexpected image file format: {format}. Use jpg, gif, png, bmp, svg, webp, or ico."")\n    return ""&tbs="" + _img_sizes[size] + "","" + _fmts[format]\n\ndef _search_url(search_term:str, size:str=\'>400*300\', format:str=\'jpg\') -> str:\n    ""Return a Google Images Search URL for a given search term.""\n    return (\'https://www.google.com/search?q=\' + quote(search_term) +\n            \'&espv=2&biw=1366&bih=667&site=webhp&source=lnms&tbm=isch\' +\n            _url_params(size, format) + \'&sa=X&ei=XosDVaCXD8TasATItgE&ved=0CAcQ_AUoAg\')\n\ndef _img_fname(img_url:str) -> str:\n    ""Return image file name including the extension given its url.""\n    return img_url.split(\'/\')[-1]\n\ndef _fetch_img_tuples(url:str, format:str=\'jpg\', n_images:int=10) -> list:\n    ""Parse the Google Images Search for urls and return the image metadata as tuples (fname, url).""\n    headers = {\'User-Agent\': \'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\'}\n    html = requests.get(url, headers=headers).text\n    return _html_to_img_tuples(html, format=format, n_images=n_images)\n\ndef _html_to_img_tuples(html:str, format:str=\'jpg\', n_images:int=10) -> list:    \n    ""Parse the google images html to img tuples containining `(fname, url)`""\n    bs = BeautifulSoup(html, \'html.parser\')\n    img_tags = bs.find_all(\'div\', {\'class\': \'rg_meta\'})\n    metadata_dicts = (json.loads(e.text) for e in img_tags)\n    img_tuples = ((_img_fname(d[\'ou\']), d[\'ou\']) for d in metadata_dicts if d[\'ity\'] == format)\n    return list(itertools.islice(img_tuples, n_images))\n\ndef _fetch_img_tuples_webdriver(url:str, format:str=\'jpg\', n_images:int=150) -> list:\n    """"""\n    Parse the Google Images Search for urls and return the image metadata as tuples (fname, url).\n    Use this for downloads of >100 images. Requires `selenium`.\n    """"""\n    try:\n        from selenium import webdriver\n        from selenium.webdriver.common.keys import Keys\n    except:\n        print(""""""Looks like you\'re trying to download > 100 images and `selenium`\n                is not installed. Try running `pip install selenium` to fix this. \n                You\'ll also need chrome and `chromedriver` installed."""""")\n    options = webdriver.ChromeOptions()\n    options.add_argument(""--headless"")\n    try: driver = webdriver.Chrome(chrome_options=options)\n    except: print(""""""Error initializing chromedriver. \n                    Check if it\'s in your path by running `which chromedriver`"""""")\n    driver.set_window_size(1440, 900)\n    driver.get(url)\n\n    for i in range(n_images // 100 + 1):\n        driver.execute_script(""window.scrollTo(0, document.body.scrollHeight)"")\n        time.sleep(0.5 + random.random()/2.0)\n\n    n_available = len(driver.find_elements_by_css_selector(""div.rg_meta""))\n    if n_available < n_images:\n        raise ValueError(f""Requested {n_images} images, but only found {n_available}."")\n\n    html = driver.page_source\n    driver.close()\n    return _html_to_img_tuples(html, format=format, n_images=n_images)\n\ndef _download_images(label_path:PathOrStr, img_tuples:list, max_workers:int=defaults.cpus, timeout:int=4) -> FilePathList:\n    """"""\n    Downloads images in `img_tuples` to `label_path`. \n    If the directory doesn\'t exist, it\'ll be created automatically.\n    Uses `parallel` to speed things up in `max_workers` when the system has enough CPU cores.\n    If something doesn\'t work, try setting up `max_workers=0` to debug.\n    """"""\n    os.makedirs(Path(label_path), exist_ok=True)\n    parallel( partial(_download_single_image, label_path, timeout=timeout), img_tuples, max_workers=max_workers)\n    return get_image_files(label_path)\n\ndef _download_single_image(label_path:Path, img_tuple:tuple, i:int, timeout:int=4) -> None:\n    """"""\n    Downloads a single image from Google Search results to `label_path`\n    given an `img_tuple` that contains `(fname, url)` of an image to download.\n    `i` is just an iteration number `int`. \n    """"""\n    suffix = re.findall(r\'\\.\\w+?(?=(?:\\?|$))\', img_tuple[1])\n    suffix = suffix[0].lower() if len(suffix)>0  else \'.jpg\'\n    fname = f""{i:08d}{suffix}""\n    download_url(img_tuple[1], label_path/fname, timeout=timeout)\n'"
old/docs/__init__.py,0,b''
old/docs/gen_ascii_docs.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport os\nimport ast\nimport re\nimport contextlib\nfrom pathlib import Path\nimport subprocess\nfrom .templates import *\nimport fire\n\n\ndef get_cls_str(ps):\n    cls_name = ps[0]\n    return f""Class {cls_name}""\n\ndef get_sub_arg(ps):\n    arg_name, arg_type, arg_default = \'\'.join(ps).split(\',\', 2)\n    if arg_type and arg_default:\n        return f\'*{arg_name}* (type {arg_type}, default {arg_default})\'\n    elif arg_type:\n        return f\'*{arg_name}* (type {arg_type})\'\n    elif arg_default:\n        return f\'*{arg_name}* (default {arg_default})\'\n    else:\n        return f\'*{arg_name}*\'\n\ndef get_xref_str(ps):\n    xref_id, xref_cap = ps if len(ps) == 2 else ps*2\n    return f""xref:{xref_id}[{xref_cap}]""\n\ndef get_method_str(ps):\n    method_name, doc_string = \'\'.join(ps).split(\',\', 1)\n    result = f\'*{method_name}*\'\n\n    if doc_string:\n        result += f\':: {doc_string}\' if doc_string else \'\'\n    return result\n\ndef parse_tmpl(s):\n    inner = s.group(1)\n    fn_name,*params = inner.split(\' \', 1)\n    fn = _fn_lu[fn_name]\n    return fn(params)\n\ndef parse_module(file_path):\n    module = ast.parse(file_path.read_text())\n    tmpl_str = HEADER.format(file_path.name.rsplit(\'.\',1)[0])\n    cls_defs = [node for node in module.body if isinstance(node, ast.ClassDef)]\n    mod_func_defs = [node for node in module.body if isinstance(node, ast.FunctionDef)]\n    for cls_def in cls_defs:\n        cls_name = cls_def.name\n        cls_bases = \',\'.join([parse(each) for each in cls_def.bases])\n        tmpl_str += f\'== {{{{class {cls_name}{"":"" + cls_bases if cls_bases else """"}}}}}\\n\\n\'\n        method_str = None\n        for fn_def in (fn_def for fn_def in cls_def.body if isinstance(fn_def, ast.FunctionDef)):\n            if fn_def.name == \'__init__\':\n                tmpl_str += ""=== Arguments\\n"" + parse_args(fn_def.args) + ""\\n\\n""\n            else:\n                if not method_str:\n                    method_str = \'=== Methods\\n\\n\'\n                doc_str = ast.get_docstring(fn_def)\n                method_str += f\'{{{{method {fn_def.name},{doc_str if doc_str else """"}}}}}\\n\\n\'\n        tmpl_str += method_str if method_str else \'\'\n    method_str = None\n    for fn_def in mod_func_defs:\n        if not method_str:\n            method_str = \'== Module Functions\\n\\n\'\n        doc_str = ast.get_docstring(fn_def)\n        method_str += f\'{{{{method {fn_def.name},{doc_str if doc_str else """"}}}}}\\n\\n\'\n    tmpl_str += method_str if method_str else \'\'\n    return tmpl_str\n\ndef parse_args(args):\n    arg_strs = [f\'{arg.arg},{arg.annotation.id if arg.annotation else """"}\' for arg in args.args if arg.arg != \'self\']\n    defaults = parse_defaults(args.defaults)\n    defaults = [None]*(len(arg_strs)-len(defaults)) + defaults\n    return \'\\n\\n\'.join([\'{{\' + f\'arg {arg},{default if default else """"}\' + \'}}\' for arg, default in zip(arg_strs, defaults)])\n\ndef parse_defaults(defs):\n    return [parse(each) for each in defs]\n\ndef parse_num(o):\n    return str(o.n)\n\ndef parse_str(o):\n    return o.s\n\ndef parse_call(o):\n    return o.func.id + \'()\'\n\ndef parse(o):\n    return _parser_dict.get(type(o), lambda x: str(x))(o)\n\n@contextlib.contextmanager\ndef working_directory(path):\n    prev_cwd = Path.cwd()\n    os.chdir(str(path))\n    try:\n        yield\n    finally:\n        os.chdir(str(prev_cwd))\n\ndef gen_ascii_docs(src=\'fastai\'):\n    """"""Generate documentation for fastai library in HTML (asciidoctor required)\n    :param str src: The absolute/relative path of source file/dir\n    """"""\n    os.chdir(Path(__file__).absolute().parent)\n    with working_directory(\'..\'):\n        path = Path(src)\n        if path.is_dir():\n            file_paths = list(path.glob(\'**/*.py\'))\n        else:\n            file_paths = [path]\n\n    pat = re.compile(\'^(?!__init__).*.py\\Z\')\n    for file_path in file_paths:\n        if pat.match(file_path.name):\n            file_path.parent.mkdir(parents=True, exist_ok=True)\n            with working_directory(\'..\'):\n                tmpl_str = parse_module(file_path)\n\n            (file_path.parent/(file_path.name.rsplit(\'.\',1)[0] + \'.adoc.tmpl\')).write_text(tmpl_str)\n            (file_path.parent/(file_path.name.rsplit(\'.\',1)[0] + \'.adoc\')).write_text(re.sub(r""{{(.*?)}}"", parse_tmpl, tmpl_str, flags=re.DOTALL))\n    if path.is_dir():\n        subprocess.call([\'asciidoctor\', str(path) + \'/**/*.adoc\'])\n    else:\n        subprocess.call([\'asciidoctor\', str(path).rsplit(\'.\',1)[0] + \'.adoc\'])\n\n\n_fn_lu = {\n    \'class\': get_cls_str,\n     \'arg\': get_sub_arg,\n     \'xref\': get_xref_str,\n     \'method\': get_method_str\n}\n\n_parser_dict = {\n    ast.Dict:lambda x: \'{}\',\n    ast.arguments: parse_args,\n    ast.Call: parse_call,\n    ast.Num: parse_num,\n    ast.Str: parse_str,\n    ast.Name: lambda x: x.id,\n    ast.NameConstant: lambda x: str(x.value),\n    ast.Attribute: lambda x: x.attr,\n    ast.List: lambda x: \'[]\',\n    list: lambda x: list(map(parse, x))\n}\n\nif __name__ == \'__main__\':\n    fire.Fire(gen_ascii_docs)'"
old/docs/md_expander.py,0,"b'import sys\r\nimport re\r\n\r\n\r\n\r\n\r\ndef expand(filename):\r\n\r\n    f = open(filename, ""r"")\r\n    contents = f.read()\r\n\r\n    regex_inside = r""\\{\\{(.*?)\\}\\}""\r\n    regex_outside = r""(^|\\}\\})(.*?)(\\{\\{|$)""\r\n\r\n    within = re.finditer(regex_inside, contents, re.MULTILINE | re.DOTALL)\r\n    outside = re.finditer(regex_outside, contents, re.MULTILINE | re.DOTALL) \r\n\r\n    for matchNum, match in enumerate(within):\r\n        for groupNum in range(0, len(match.groups())):\r\n            group = match.group(1)\r\n            if group.startswith(""class""):\r\n                classname = re.search(r"" (.*?),"", group).groups()[0]\r\n                params = re.search(r"",(.*)"", group).groups()[0]\r\n                print(\'<h2 id=""\' + classname + \'"" class=""class"">Class: \' + classname + \'(<span class=""params"">\' + params + \'</span></h2>\')\r\n\r\n            print (match.group(1))\r\n\r\n#    split = re.split(regex_inside, contents)\r\n#\r\n#    for i, item in enumerate(split):\r\n\r\n\r\n\r\nif __name__ == \'__main__\':\r\n\r\n    expand(sys.argv[1])\r\n\r\n'"
old/docs/templates.py,0,"b""HEADER = '''\n= fastai.{}\n\n== Introduction and overview\n\n```\n...example...\n```\n\n\n'''"""
old/fastai/__init__.py,0,b''
old/fastai/adaptive_softmax.py,1,"b'from .lm_rnn import *\n\nclass AdaptiveSoftmax(nn.Module):\n    def __init__(self, input_size, cutoff):\n        super().__init__()\n        self.input_size,self.cutoff = input_size,cutoff\n        self.output_size = cutoff[0] + len(cutoff) - 1\n        self.head = nn.Linear(input_size, self.output_size)\n        self.tail = nn.ModuleList()\n        for i in range(len(cutoff) - 1):\n            seq = nn.Sequential(nn.Linear(input_size, input_size // 4 ** i, False),\n                nn.Linear(input_size // 4 ** i, cutoff[i + 1] - cutoff[i], False))\n            self.tail.append(seq)\n\n    def reset(self):\n        nn.init.xavier_normal(self.head.weight)\n        for tail in self.tail:\n            nn.init.xavier_normal(tail[0].weight)\n            nn.init.xavier_normal(tail[1].weight)\n\n    def set_target(self, target):\n        self.id = []\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            if mask.sum() > 0:\n                self.id.append(Variable(mask.float().nonzero().squeeze(1)))\n            else: self.id.append(None)\n\n    def forward(self, input):\n        output = [self.head(input)]\n        for i in range(len(self.id)):\n            if self.id[i] is not None:\n                output.append(self.tail[i](input.index_select(0, self.id[i])))\n            else: output.append(None)\n        return output\n\n    def log_prob(self, input):\n        lsm = nn.LogSoftmax().cuda()\n        head_out = self.head(input)\n        batch_size = head_out.size(0)\n        prob = torch.zeros(batch_size, self.cutoff[-1]).cuda()\n        lsm_head = lsm(head_out)\n        prob.narrow(1, 0, self.output_size).add_(lsm_head.narrow(1, 0, self.output_size).data)\n        for i in range(len(self.tail)):\n            pos = self.cutoff[i]\n            i_size = self.cutoff[i + 1] - pos\n            buffer = lsm_head.narrow(1, self.cutoff[0] + i, 1)\n            buffer = buffer.expand(batch_size, i_size)\n            lsm_tail = lsm(self.tail[i](input))\n            prob.narrow(1, pos, i_size).copy_(buffer.data).add_(lsm_tail.data)\n        return prob\n\n\nclass AdaptiveLoss(nn.Module):\n    def __init__(self, cutoff):\n        super().__init__()\n        self.cutoff = cutoff\n        self.criterions = nn.ModuleList([nn.CrossEntropyLoss(size_average=False) for i in self.cutoff])\n\n    def remap_target(self, target):\n        new_target = [target.clone()]\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            new_target[0][mask] = self.cutoff[0] + i\n            if mask.sum() > 0: new_target.append(target[mask].add(-self.cutoff[i]))\n            else: new_target.append(None)\n        return new_target\n\n    def forward(self, input, target):\n        batch_size = input[0].size(0)\n        target = self.remap_target(target.data)\n        output = 0.0\n        for i in range(len(input)):\n            if input[i] is not None:\n                assert(target[i].min() >= 0 and target[i].max() <= input[i].size(1))\n                criterion = self.criterions[i]\n                output += criterion(input[i], Variable(target[i]))\n        output /= batch_size\n        return output\n\n'"
old/fastai/column_data.py,4,"b'from .imports import *\nfrom .torch_imports import *\nfrom .dataset import *\nfrom .learner import *\n\n\nclass PassthruDataset(Dataset):\n    def __init__(self,*args, is_reg=True, is_multi=False):\n        *xs,y=args\n        self.xs,self.y = xs,y\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n    def __getitem__(self, idx): return [o[idx] for o in self.xs] + [self.y[idx]]\n\n    @classmethod\n    def from_data_frame(cls, df, cols_x, col_y, is_reg=True, is_multi=False):\n        cols = [df[o] for o in cols_x+[col_y]]\n        return cls(*cols, is_reg=is_reg, is_multi=is_multi)\n\n\nclass ColumnarDataset(Dataset):\n    """"""Dataset class for column dataset.\n    Args:\n       cats (list of str): List of the name of columns contain categorical variables.\n       conts (list of str): List of the name of columns which contain continuous variables.\n       y (Tensor, optional): Target variables.\n       is_reg (bool): If the task is regression, set ``True``, otherwise (classification) ``False``.\n       is_multi (bool): If the task is multi-label classification, set ``True``.\n    """"""\n    def __init__(self, cats, conts, y, is_reg, is_multi):\n        n = len(cats[0]) if cats else len(conts[0])\n        self.cats  = np.stack(cats,  1).astype(np.int64)   if cats  else np.zeros((n,1))\n        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n        self.y     = np.zeros((n,1))                       if y is None else y\n        if is_reg:\n            self.y =  self.y[:,None]\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n\n    def __getitem__(self, idx):\n        return [self.cats[idx], self.conts[idx], self.y[idx]]\n\n    @classmethod\n    def from_data_frames(cls, df_cat, df_cont, y=None, is_reg=True, is_multi=False):\n        cat_cols = [c.values for n,c in df_cat.items()]\n        cont_cols = [c.values for n,c in df_cont.items()]\n        return cls(cat_cols, cont_cols, y, is_reg, is_multi)\n\n    @classmethod\n    def from_data_frame(cls, df, cat_flds, y=None, is_reg=True, is_multi=False):\n        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y, is_reg, is_multi)\n\n\nclass ColumnarModelData(ModelData):\n    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n            DataLoader(val_ds, bs*2, shuffle=False, num_workers=1), test_dl)\n\n    @classmethod\n    def from_arrays(cls, path, val_idxs, xs, y, is_reg=True, is_multi=False, bs=64, test_xs=None, shuffle=True):\n        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs), is_reg=is_reg, is_multi=is_multi) if test_xs is not None else None\n        return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n                   PassthruDataset(*(val_xs.T), val_y, is_reg=is_reg, is_multi=is_multi),\n                   bs=bs, shuffle=shuffle, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs=64, is_reg=True, is_multi=False, test_df=None, shuffle=True):\n        trn_ds  = ColumnarDataset.from_data_frame(trn_df,  cat_flds, trn_y, is_reg, is_multi)\n        val_ds  = ColumnarDataset.from_data_frame(val_df,  cat_flds, val_y, is_reg, is_multi)\n        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, None,  is_reg, is_multi) if test_df is not None else None\n        return cls(path, trn_ds, val_ds, bs, test_ds=test_ds, shuffle=shuffle)\n\n    @classmethod\n    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs=64, is_reg=True, is_multi=False, test_df=None, shuffle=True):\n        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=test_df, shuffle=shuffle)\n\n    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                    y_range=None, use_bn=False, **kwargs):\n        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn, self.is_reg, self.is_multi)\n        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n\n\ndef emb_init(x):\n    x = x.weight.data\n    sc = 2/(x.size(1)+1)\n    x.uniform_(-sc,sc)\n\n\nclass MixedInputModel(nn.Module):\n    """"""Model able to handle inputs consisting of both categorical and continuous variables.\n    Args:\n       emb_szs (list of int): List of embedding size\n       n_cont (int): Number of continuous variables in inputs\n       emb_drop (float): Dropout applied to the output of embedding\n       out_sz (int): Size of model\'s output.\n       szs (list of int): List of hidden variables sizes\n       drops (list of float): List of dropout applied to hidden variables\n       y_range (list of float): Min and max of `y`. y_range[0] = min, y_range[1] = max.\n       use_bn (bool): If use BatchNorm, set ``True``\n       is_reg (bool): If regression, set ``True``\n       is_multi (bool): If multi-label classification, set ``True``\n    """"""\n    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                 y_range=None, use_bn=False, is_reg=True, is_multi=False):\n        super().__init__()\n        for i,(c,s) in enumerate(emb_szs): assert c > 1, f""cardinality must be >=2, got emb_szs[{i}]: ({c},{s})""\n        if is_reg==False and is_multi==False: assert out_sz >= 2, ""For classification with out_sz=1, use is_multi=True""\n        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n        for emb in self.embs: emb_init(emb)\n        n_emb = sum(e.embedding_dim for e in self.embs)\n        self.n_emb, self.n_cont=n_emb, n_cont\n        \n        szs = [n_emb+n_cont] + szs\n        self.lins = nn.ModuleList([\n            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n        self.bns = nn.ModuleList([\n            nn.BatchNorm1d(sz) for sz in szs[1:]])\n        for o in self.lins: kaiming_normal(o.weight.data)\n        self.outp = nn.Linear(szs[-1], out_sz)\n        kaiming_normal(self.outp.weight.data)\n\n        self.emb_drop = nn.Dropout(emb_drop)\n        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n        self.bn = nn.BatchNorm1d(n_cont)\n        self.use_bn,self.y_range = use_bn,y_range\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def forward(self, x_cat, x_cont):\n        if self.n_emb != 0:\n            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n            x = torch.cat(x, 1)\n            x = self.emb_drop(x)\n        if self.n_cont != 0:\n            x2 = self.bn(x_cont)\n            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n        for l,d,b in zip(self.lins, self.drops, self.bns):\n            x = F.relu(l(x))\n            if self.use_bn: x = b(x)\n            x = d(x)\n        x = self.outp(x)\n        if not self.is_reg:\n            if self.is_multi:\n                x = F.sigmoid(x)\n            else:\n                x = F.log_softmax(x)\n        elif self.y_range:\n            x = F.sigmoid(x)\n            x = x*(self.y_range[1] - self.y_range[0])\n            x = x+self.y_range[0]\n        return x\n\n\nclass StructuredLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    def predict_array(self,x_cat,x_cont):\n        self.model.eval()\n        return to_np(self.model(to_gpu(V(T(x_cat))),to_gpu(V(T(x_cont)))))\n\n    def summary(self):\n        x = [torch.ones(3, self.data.trn_ds.cats.shape[1]).long(), torch.rand(3, self.data.trn_ds.conts.shape[1])]\n        return model_summary(self.model, x)\n\n\nclass StructuredModel(BasicModel):\n    def get_layer_groups(self):\n        m=self.model\n        return [m.embs, children(m.lins)+children(m.bns), m.outp]\n\n\nclass CollabFilterDataset(Dataset):\n    def __init__(self, path, user_col, item_col, ratings):\n        self.ratings,self.path = ratings.values.astype(np.float32),path\n        self.n = len(ratings)\n        (self.users,self.user2idx,self.user_col,self.n_users) = self.proc_col(user_col)\n        (self.items,self.item2idx,self.item_col,self.n_items) = self.proc_col(item_col)\n        self.min_score,self.max_score = min(ratings),max(ratings)\n        self.cols = [self.user_col,self.item_col,self.ratings]\n\n    @classmethod\n    def from_data_frame(cls, path, df, user_name, item_name, rating_name):\n        return cls(path, df[user_name], df[item_name], df[rating_name])\n\n    @classmethod\n    def from_csv(cls, path, csv, user_name, item_name, rating_name):\n        df = pd.read_csv(os.path.join(path,csv))\n        return cls.from_data_frame(path, df, user_name, item_name, rating_name)\n\n    def proc_col(self,col):\n        uniq = col.unique()\n        name2idx = {o:i for i,o in enumerate(uniq)}\n        return (uniq, name2idx, np.array([name2idx[x] for x in col]), len(uniq))\n\n    def __len__(self): return self.n\n    def __getitem__(self, idx): return [o[idx] for o in self.cols]\n\n    def get_data(self, val_idxs, bs):\n        val, trn = zip(*split_by_idx(val_idxs, *self.cols))\n        return ColumnarModelData(self.path, PassthruDataset(*trn), PassthruDataset(*val), bs)\n\n    def get_model(self, n_factors):\n        model = EmbeddingDotBias(n_factors, self.n_users, self.n_items, self.min_score, self.max_score)\n        return CollabFilterModel(to_gpu(model))\n\n    def get_learner(self, n_factors, val_idxs, bs, **kwargs):\n        return CollabFilterLearner(self.get_data(val_idxs, bs), self.get_model(n_factors), **kwargs)\n\n\ndef get_emb(ni,nf):\n    e = nn.Embedding(ni, nf)\n    e.weight.data.uniform_(-0.05,0.05)\n    return e\n\n\nclass EmbeddingDotBias(nn.Module):\n    def __init__(self, n_factors, n_users, n_items, min_score, max_score):\n        super().__init__()\n        self.min_score,self.max_score = min_score,max_score\n        (self.u, self.i, self.ub, self.ib) = [get_emb(*o) for o in [\n            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n        ]]\n\n    def forward(self, users, items):\n        um = self.u(users)* self.i(items)\n        res = um.sum(1) + self.ub(users).squeeze() + self.ib(items).squeeze()\n        return F.sigmoid(res) * (self.max_score-self.min_score) + self.min_score\n\n\nclass CollabFilterLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n    def summary(self): return model_summary(self.model, [torch.ones(3).long(), torch.ones(3).long()])\n\n\nclass CollabFilterModel(BasicModel):\n    def get_layer_groups(self): return self.model\n\n'"
old/fastai/conv_learner.py,0,"b'from .core import *\nfrom .layers import *\nfrom .learner import *\nfrom .initializers import *\n\nmodel_meta = {\n    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n    vgg16:[0,22], vgg19:[0,22],\n    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n}\nmodel_features = {inception_4: 3072, dn121: 2048, dn161: 4416,} # nasnetalarge: 4032*2}\n\nclass ConvnetBuilder():\n    """"""Class representing a convolutional network.\n\n    Arguments:\n        f: a model creation function (e.g. resnet34, vgg16, etc)\n        c (int): size of the last layer\n        is_multi (bool): is multilabel classification?\n            (def here http://scikit-learn.org/stable/modules/multiclass.html)\n        is_reg (bool): is a regression?\n        ps (float or array of float): dropout parameters\n        xtra_fc (list of ints): list of hidden layers with # hidden neurons\n        xtra_cut (int): # layers earlier than default to cut the model, default is 0\n        custom_head : add custom model classes that are inherited from nn.modules at the end of the model\n                      that is mentioned on Argument \'f\' \n    """"""\n\n    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, pretrained=True):\n        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n        if xtra_fc is None: xtra_fc = [512]\n        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n        self.ps,self.xtra_fc = ps,xtra_fc\n\n        if f in model_meta: cut,self.lr_cut = model_meta[f]\n        else: cut,self.lr_cut = 0,0\n        cut-=xtra_cut\n        layers = cut_model(f(pretrained), cut)\n        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n        self.top_model = nn.Sequential(*layers)\n\n        n_fc = len(self.xtra_fc)+1\n        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n\n        if custom_head: fc_layers = [custom_head]\n        else: fc_layers = self.get_fc_layers()\n        self.n_fc = len(fc_layers)\n        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n\n    @property\n    def name(self): return f\'{self.f.__name__}_{self.xtra_cut}\'\n\n    def create_fc_layer(self, ni, nf, p, actn=None):\n        res=[nn.BatchNorm1d(num_features=ni)]\n        if p: res.append(nn.Dropout(p=p))\n        res.append(nn.Linear(in_features=ni, out_features=nf))\n        if actn: res.append(actn)\n        return res\n\n    def get_fc_layers(self):\n        res=[]\n        ni=self.nf\n        for i,nf in enumerate(self.xtra_fc):\n            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n            ni=nf\n        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n        if self.is_reg: final_actn = None\n        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n        return res\n\n    def get_layer_groups(self, do_fc=False):\n        if do_fc:\n            return [self.fc_model]\n        idxs = [self.lr_cut]\n        c = children(self.top_model)\n        if len(c)==3: c = children(c[0])+c[1:]\n        lgs = list(split_by_idxs(c,idxs))\n        return lgs+[self.fc_model]\n\n\nclass ConvLearner(Learner):\n    """"""\n    Class used to train a chosen supported covnet model. Eg. ResNet-34, etc.\n    Arguments:\n        data: training data for model\n        models: model architectures to base learner\n        precompute: bool to reuse precomputed activations\n        **kwargs: parameters from Learner() class\n    """"""\n    def __init__(self, data, models, precompute=False, **kwargs):\n        self.precompute = False\n        super().__init__(data, models, **kwargs)\n        if hasattr(data, \'is_multi\') and not data.is_reg and self.metrics is None:\n            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n        if precompute: self.save_fc1()\n        self.freeze()\n        self.precompute = precompute\n\n    def _get_crit(self, data):\n        if not hasattr(data, \'is_multi\'): return super()._get_crit(data)\n\n        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    @classmethod\n    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                   pretrained=True, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n        return cls(data, models, precompute, **kwargs)\n\n    @classmethod\n    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n        convlearn=cls(data, models, precompute, **kwargs)\n        convlearn.lsuv_init()\n        return convlearn\n    \n    @property\n    def model(self): return self.models.fc_model if self.precompute else self.models.model\n    \n    def half(self):\n        if self.fp16: return\n        self.fp16 = True\n        if type(self.model) != FP16: self.models.model = FP16(self.model)\n        if not isinstance(self.models.fc_model, FP16): self.models.fc_model = FP16(self.models.fc_model)\n    def float(self):\n        if not self.fp16: return\n        self.fp16 = False\n        if type(self.models.model) == FP16: self.models.model = self.model.module.float()\n        if type(self.models.fc_model) == FP16: self.models.fc_model = self.models.fc_model.module.float()\n\n    @property\n    def data(self): return self.fc_data if self.precompute else self.data_\n\n    def create_empty_bcolz(self, n, name):\n        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode=\'w\', rootdir=name)\n\n    def set_data(self, data, precompute=False):\n        super().set_data(data)\n        if precompute:\n            self.unfreeze()\n            self.save_fc1()\n            self.freeze()\n            self.precompute = True\n        else:\n            self.freeze()\n\n    def get_layer_groups(self):\n        return self.models.get_layer_groups(self.precompute)\n\n    def summary(self):\n        precompute = self.precompute\n        self.precompute = False\n        res = super().summary()\n        self.precompute = precompute\n        return res\n\n    def get_activations(self, force=False):\n        tmpl = f\'_{self.models.name}_{self.data.sz}.bc\'\n        # TODO: Somehow check that directory names haven\'t changed (e.g. added test set)\n        names = [os.path.join(self.tmp_path, p+tmpl) for p in (\'x_act\', \'x_act_val\', \'x_act_test\')]\n        if os.path.exists(names[0]) and not force:\n            self.activations = [bcolz.open(p) for p in names]\n        else:\n            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n\n    def save_fc1(self):\n        self.get_activations()\n        act, val_act, test_act = self.activations\n        m=self.models.top_model\n        if len(self.activations[0])!=len(self.data.trn_ds):\n            predict_to_bcolz(m, self.data.fix_dl, act)\n        if len(self.activations[1])!=len(self.data.val_ds):\n            predict_to_bcolz(m, self.data.val_dl, val_act)\n        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n\n        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n                test = test_act if self.data.test_dl else None, num_workers=8)\n\n    def freeze(self):\n        """""" Freeze all but the very last layer.\n\n        Make all layers untrainable (i.e. frozen) except for the last layer.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(-1)\n\n    def unfreeze(self):\n        """""" Unfreeze all layers.\n\n        Make all layers trainable by unfreezing. This will also set the `precompute` to `False` since we can\n        no longer pre-calculate the activation of frozen layers.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(0)\n        self.precompute = False\n\n    def predict_array(self, arr):\n        """"""\n        This over-ride is necessary because otherwise the learner method accesses the wrong model when it is called\n        with precompute set to true\n\n        Args:\n            arr: a numpy array to be used as input to the model for prediction purposes\n        Returns:\n            a numpy array containing the predictions from the model\n        """"""\n        precompute = self.precompute\n        self.precompute = False\n        pred = super().predict_array(arr)\n        self.precompute = precompute\n        return pred\n'"
old/fastai/core.py,16,"b'from .imports import *\nfrom .torch_imports import *\n\ndef sum_geom(a,r,n): return a*n if r==1 else math.ceil(a*(1-r**n)/(1-r))\n\ndef is_listy(x): return isinstance(x, (list,tuple))\ndef is_iter(x): return isinstance(x, collections.Iterable)\ndef map_over(x, f): return [f(o) for o in x] if is_listy(x) else f(x)\ndef map_none(x, f): return None if x is None else f(x)\ndef delistify(x): return x[0] if is_listy(x) else x\ndef listify(x, y):\n    if not is_iter(x): x=[x]\n    n = y if type(y)==int else len(y)\n    if len(x)==1: x = x * n\n    return x\n\ndef datafy(x):\n    if is_listy(x): return [o.data for o in x]\n    else:           return x.data\n\nconv_dict = {np.dtype(\'int8\'): torch.LongTensor, np.dtype(\'int16\'): torch.LongTensor,\n    np.dtype(\'int32\'): torch.LongTensor, np.dtype(\'int64\'): torch.LongTensor,\n    np.dtype(\'float32\'): torch.FloatTensor, np.dtype(\'float64\'): torch.FloatTensor}\n\ndef A(*a):\n    """"""convert iterable object into numpy array""""""\n    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]\n\ndef T(a, half=False, cuda=True):\n    """"""\n    Convert numpy array into a pytorch tensor. \n    if Cuda is available and USE_GPU=True, store resulting tensor in GPU.\n    """"""\n    if not torch.is_tensor(a):\n        a = np.array(np.ascontiguousarray(a))\n        if a.dtype in (np.int8, np.int16, np.int32, np.int64):\n            a = torch.LongTensor(a.astype(np.int64))\n        elif a.dtype in (np.float32, np.float64):\n            a = to_half(a) if half else torch.FloatTensor(a)\n        else: raise NotImplementedError(a.dtype)\n    if cuda: a = to_gpu(a)\n    return a\n\ndef to_half(tensor):\n    if torch.cuda.is_available():\n        return torch.cuda.HalfTensor(tensor)\n    else:\n        return torch.FloatTensor(tensor)\n\ndef create_variable(x, volatile, requires_grad=False):\n    if type (x) != Variable:\n        if IS_TORCH_04: x = Variable(T(x), requires_grad=requires_grad)\n        else:           x = Variable(T(x), requires_grad=requires_grad, volatile=volatile)\n    return x\n\ndef V_(x, requires_grad=False, volatile=False):\n    \'\'\'equivalent to create_variable, which creates a pytorch tensor\'\'\'\n    return create_variable(x, volatile=volatile, requires_grad=requires_grad)\ndef V(x, requires_grad=False, volatile=False):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, lambda o: V_(o, requires_grad, volatile))\n\ndef VV_(x): \n    \'\'\'creates a volatile tensor, which does not require gradients. \'\'\'\n    return create_variable(x, True)\n\ndef VV(x):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, VV_)\n\ndef to_np(v):\n    \'\'\'returns an np.array object given an input of np.array, list, tuple, torch variable or tensor.\'\'\'\n    if isinstance(v, float): return np.array(v)\n    if isinstance(v, (np.ndarray, np.generic)): return v\n    if isinstance(v, (list,tuple)): return [to_np(o) for o in v]\n    if isinstance(v, Variable): v=v.data\n    if torch.cuda.is_available():\n        if is_half_tensor(v): v=v.float()\n    if isinstance(v, torch.FloatTensor): v=v.float()\n    return v.cpu().numpy()\n\ndef is_half_tensor(v):\n    return isinstance(v, torch.cuda.HalfTensor)\n\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\nUSE_GPU = torch.cuda.is_available()\ndef to_gpu(x, *args, **kwargs):\n    \'\'\'puts pytorch variable to gpu, if cuda is available and USE_GPU is set to true. \'\'\'\n    return x.cuda(*args, **kwargs) if USE_GPU else x\n\ndef noop(*args, **kwargs): return\n\ndef split_by_idxs(seq, idxs):\n    \'\'\'A generator that returns sequence pieces, seperated by indexes specified in idxs. \'\'\'\n    last = 0\n    for idx in idxs:\n        if not (-len(seq) <= idx < len(seq)):\n          raise KeyError(f\'Idx {idx} is out-of-bounds\')\n        yield seq[last:idx]\n        last = idx\n    yield seq[last:]\n\ndef trainable_params_(m):\n    \'\'\'Returns a list of trainable parameters in the model m. (i.e., those that require gradients.)\'\'\'\n    return [p for p in m.parameters() if p.requires_grad]\n\ndef chain_params(p):\n    if is_listy(p):\n        return list(chain(*[trainable_params_(o) for o in p]))\n    return trainable_params_(p)\n\ndef set_trainable_attr(m,b):\n    m.trainable=b\n    for p in m.parameters(): p.requires_grad=b\n\ndef apply_leaf(m, f):\n    c = children(m)\n    if isinstance(m, nn.Module): f(m)\n    if len(c)>0:\n        for l in c: apply_leaf(l,f)\n\ndef set_trainable(l, b):\n    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n\ndef SGD_Momentum(momentum):\n    return lambda *args, **kwargs: optim.SGD(*args, momentum=momentum, **kwargs)\n\ndef one_hot(a,c): return np.eye(c)[a]\n\ndef partition(a, sz): \n    """"""splits iterables a in equal parts of size sz""""""\n    return [a[i:i+sz] for i in range(0, len(a), sz)]\n\ndef partition_by_cores(a):\n    return partition(a, len(a)//num_cpus() + 1)\n\ndef num_cpus():\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n\n\nclass BasicModel():\n    def __init__(self,model,name=\'unnamed\'): self.model,self.name = model,name\n    def get_layer_groups(self, do_fc=False): return children(self.model)\n\nclass SingleModel(BasicModel):\n    def get_layer_groups(self): return [self.model]\n\nclass SimpleNet(nn.Module):\n    def __init__(self, layers):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return F.log_softmax(l_x, dim=-1)\n\n\ndef save(fn, a): \n    """"""Utility function that savess model, function, etc as pickle""""""    \n    pickle.dump(a, open(fn,\'wb\'))\ndef load(fn): \n    """"""Utility function that loads model, function, etc as pickle""""""\n    return pickle.load(open(fn,\'rb\'))\ndef load2(fn):\n    """"""Utility function allowing model piclking across Python2 and Python3""""""\n    return pickle.load(open(fn,\'rb\'), encoding=\'iso-8859-1\')\n\ndef load_array(fname): \n    \'\'\'\n    Load array using bcolz, which is based on numpy, for fast array saving and loading operations. \n    https://github.com/Blosc/bcolz\n    \'\'\'\n    return bcolz.open(fname)[:]\n\n\ndef chunk_iter(iterable, chunk_size):\n    \'\'\'A generator that yields chunks of iterable, chunk_size at a time. \'\'\'\n    while True:\n        chunk = []\n        try:\n            for _ in range(chunk_size): chunk.append(next(iterable))\n            yield chunk\n        except StopIteration:\n            if chunk: yield chunk\n            break\n\ndef set_grad_enabled(mode): return torch.set_grad_enabled(mode) if IS_TORCH_04 else contextlib.suppress()\n\ndef no_grad_context(): return torch.no_grad() if IS_TORCH_04 else contextlib.suppress()\n'"
old/fastai/dataloader.py,1,"b'import torch, queue\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler\nfrom .imports import *\nfrom .core import *\nimport collections,sys,traceback,threading\n\nstring_classes = (str, bytes)\n\n\ndef get_tensor(batch, pin, half=False):\n    if isinstance(batch, (np.ndarray, np.generic)):\n        batch = T(batch, half=half, cuda=False).contiguous()\n        if pin: batch = batch.pin_memory()\n        return to_gpu(batch)\n    elif isinstance(batch, string_classes):\n        return batch\n    elif isinstance(batch, collections.Mapping):\n        return {k: get_tensor(sample, pin, half) for k, sample in batch.items()}\n    elif isinstance(batch, collections.Sequence):\n        return [get_tensor(sample, pin, half) for sample in batch]\n    raise TypeError(f""batch must contain numbers, dicts or lists; found {type(batch)}"")\n\n\nclass DataLoader(object):\n    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, pad_idx=0,\n                 num_workers=None, pin_memory=False, drop_last=False, pre_pad=True, half=False,\n                 transpose=False, transpose_y=False):\n        self.dataset,self.batch_size,self.num_workers = dataset,batch_size,num_workers\n        self.pin_memory,self.drop_last,self.pre_pad = pin_memory,drop_last,pre_pad\n        self.transpose,self.transpose_y,self.pad_idx,self.half = transpose,transpose_y,pad_idx,half\n\n        if batch_sampler is not None:\n            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n                raise ValueError(\'batch_sampler is mutually exclusive with \'\n                                 \'batch_size, shuffle, sampler, and drop_last\')\n\n        if sampler is not None and shuffle:\n            raise ValueError(\'sampler is mutually exclusive with shuffle\')\n\n        if batch_sampler is None:\n            if sampler is None:\n                sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n\n        if num_workers is None:\n            self.num_workers = num_cpus()\n\n        self.sampler = sampler\n        self.batch_sampler = batch_sampler\n\n    def __len__(self): return len(self.batch_sampler)\n\n    def jag_stack(self, b):\n        if len(b[0].shape) not in (1,2): return np.stack(b)\n        ml = max(len(o) for o in b)\n        if min(len(o) for o in b)==ml: return np.stack(b)\n        res = np.zeros((len(b), ml), dtype=b[0].dtype) + self.pad_idx\n        for i,o in enumerate(b):\n            if self.pre_pad: res[i, -len(o):] = o\n            else:            res[i,  :len(o)] = o\n        return res\n\n    def np_collate(self, batch):\n        b = batch[0]\n        if isinstance(b, (np.ndarray, np.generic)): return self.jag_stack(batch)\n        elif isinstance(b, (int, float)): return np.array(batch)\n        elif isinstance(b, string_classes): return batch\n        elif isinstance(b, collections.Mapping):\n            return {key: self.np_collate([d[key] for d in batch]) for key in b}\n        elif isinstance(b, collections.Sequence):\n            return [self.np_collate(samples) for samples in zip(*batch)]\n        raise TypeError((""batch must contain numbers, dicts or lists; found {}"".format(type(b))))\n\n    def get_batch(self, indices):\n        res = self.np_collate([self.dataset[i] for i in indices])\n        if self.transpose:   res[0] = res[0].T\n        if self.transpose_y: res[1] = res[1].T\n        return res\n\n    def __iter__(self):\n        if self.num_workers==0:\n            for batch in map(self.get_batch, iter(self.batch_sampler)):\n                yield get_tensor(batch, self.pin_memory, self.half)\n        else:\n            with ThreadPoolExecutor(max_workers=self.num_workers) as e:\n                # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n                for c in chunk_iter(iter(self.batch_sampler), self.num_workers*10):\n                    for batch in e.map(self.get_batch, c):\n                        yield get_tensor(batch, self.pin_memory, self.half)\n\n'"
old/fastai/dataset.py,1,"b'from PIL.ImageFile import ImageFile\nfrom .dataloader import DataLoader\nfrom .transforms import *\n\n# Try to import pydicom for dicom support, but ignore failures which\n# will cause exceptions to be caught when actually trying to read\n# a dicom image.\ntry:\n    import pydicom\nexcept:\n    pass\n\ndef get_cv_idxs(n, cv_idx=0, val_pct=0.2, seed=42):\n    """""" Get a list of index values for Validation set from a dataset\n    \n    Arguments:\n        n : int, Total number of elements in the data set.\n        cv_idx : int, starting index [idx_start = cv_idx*int(val_pct*n)] \n        val_pct : (int, float), validation set percentage \n        seed : seed value for RandomState\n        \n    Returns:\n        list of indexes \n    """"""\n    np.random.seed(seed)\n    n_val = int(val_pct*n)\n    idx_start = cv_idx*n_val\n    idxs = np.random.permutation(n)\n    return idxs[idx_start:idx_start+n_val]\n\ndef path_for(root_path, new_path, targ):\n    return os.path.join(root_path, new_path, str(targ))\n\ndef resize_img(fname, targ, path, new_path, fn=None):\n    """"""\n    Enlarge or shrink a single image to scale, such that the smaller of the height or width dimension is equal to targ.\n    """"""\n    if fn is None:\n        fn = resize_fn(targ)\n    dest = os.path.join(path_for(path, new_path, targ), fname)\n    if os.path.exists(dest): return\n    im = Image.open(os.path.join(path, fname)).convert(\'RGB\')\n    os.makedirs(os.path.split(dest)[0], exist_ok=True)\n    fn(im).save(dest)\n\ndef resize_fn(targ):\n    def resize(im):\n        r,c = im.size\n        ratio = targ/min(r,c)\n        sz = (scale_to(r, ratio, targ), scale_to(c, ratio, targ))\n        return im.resize(sz, Image.LINEAR)\n    return resize\n\n\ndef resize_imgs(fnames, targ, path, new_path, resume=True, fn=None):\n    """"""\n    Enlarge or shrink a set of images in the same directory to scale, such that the smaller of the height or width dimension is equal to targ.\n    Note: \n    -- This function is multithreaded for efficiency. \n    -- When destination file or folder already exist, function exists without raising an error. \n    """"""\n    target_path = path_for(path, new_path, targ)\n    if resume:\n        subdirs = {os.path.dirname(p) for p in fnames}\n        subdirs = {s for s in subdirs if os.path.exists(os.path.join(target_path, s))}\n        already_resized_fnames = set()\n        for subdir in subdirs:\n            files = [os.path.join(subdir, file) for file in os.listdir(os.path.join(target_path, subdir))]\n            already_resized_fnames.update(set(files))\n        original_fnames = set(fnames)\n        fnames = list(original_fnames - already_resized_fnames)\n    \n    errors = {}\n    def safely_process(fname):\n        try:\n            resize_img(fname, targ, path, new_path, fn=fn)\n        except Exception as ex:\n            errors[fname] = str(ex)\n\n    if len(fnames) > 0:\n        with ThreadPoolExecutor(num_cpus()) as e:\n            ims = e.map(lambda fname: safely_process(fname), fnames)\n            for _ in tqdm(ims, total=len(fnames), leave=False): pass\n    if errors:\n        print(\'Some images failed to process:\')\n        print(json.dumps(errors, indent=2))\n    return os.path.join(path,new_path,str(targ))\n\ndef read_dir(path, folder):\n    """""" Returns a list of relative file paths to `path` for all files within `folder` """"""\n    full_path = os.path.join(path, folder)\n    fnames = glob(f""{full_path}/*.*"")\n    directories = glob(f""{full_path}/*/"")\n    if any(fnames):\n        return [os.path.relpath(f,path) for f in fnames]\n    elif any(directories):\n        raise FileNotFoundError(""{} has subdirectories but contains no files. Is your directory structure is correct?"".format(full_path))\n    else:\n        raise FileNotFoundError(""{} folder doesn\'t exist or is empty"".format(full_path))\n\ndef read_dirs(path, folder):\n    \'\'\'\n    Fetches name of all files in path in long form, and labels associated by extrapolation of directory names. \n    \'\'\'\n    lbls, fnames, all_lbls = [], [], []\n    full_path = os.path.join(path, folder)\n    for lbl in sorted(os.listdir(full_path)):\n        if lbl not in (\'.ipynb_checkpoints\',\'.DS_Store\'):\n            all_lbls.append(lbl)\n            for fname in os.listdir(os.path.join(full_path, lbl)):\n                if fname not in (\'.DS_Store\'):\n                    fnames.append(os.path.join(folder, lbl, fname))\n                    lbls.append(lbl)\n    return fnames, lbls, all_lbls\n\ndef n_hot(ids, c):\n    \'\'\'\n    one hot encoding by index. Returns array of length c, where all entries are 0, except for the indecies in ids\n    \'\'\'\n    res = np.zeros((c,), dtype=np.float32)\n    res[ids] = 1\n    return res\n\ndef folder_source(path, folder):\n    """"""\n    Returns the filenames and labels for a folder within a path\n    \n    Returns:\n    -------\n    fnames: a list of the filenames within `folder`\n    all_lbls: a list of all of the labels in `folder`, where the # of labels is determined by the # of directories within `folder`\n    lbl_arr: a numpy array of the label indices in `all_lbls`\n    """"""\n    fnames, lbls, all_lbls = read_dirs(path, folder)\n    lbl2idx = {lbl:idx for idx,lbl in enumerate(all_lbls)}\n    idxs = [lbl2idx[lbl] for lbl in lbls]\n    lbl_arr = np.array(idxs, dtype=int)\n    return fnames, lbl_arr, all_lbls\n\ndef parse_csv_labels(fn, skip_header=True, cat_separator = \' \'):\n    """"""Parse filenames and label sets from a CSV file.\n\n    This method expects that the csv file at path :fn: has two columns. If it\n    has a header, :skip_header: should be set to True. The labels in the\n    label set are expected to be space separated.\n\n    Arguments:\n        fn: Path to a CSV file.\n        skip_header: A boolean flag indicating whether to skip the header.\n\n    Returns:\n        a two-tuple of (\n            image filenames,\n            a dictionary of filenames and corresponding labels\n        )\n    .\n    :param cat_separator: the separator for the categories column\n    """"""\n    df = pd.read_csv(fn, index_col=0, header=0 if skip_header else None, dtype=str)\n    fnames = df.index.values\n    df.iloc[:,0] = df.iloc[:,0].str.split(cat_separator)\n    return fnames, list(df.to_dict().values())[0]\n\ndef nhot_labels(label2idx, csv_labels, fnames, c):\n\t\t\t    \n    all_idx = {k: n_hot([label2idx[o] for o in ([] if type(v) == float else v)], c)\n               for k,v in csv_labels.items()}\n    return np.stack([all_idx[o] for o in fnames])\n\ndef csv_source(folder, csv_file, skip_header=True, suffix=\'\', continuous=False, cat_separator=\' \'):\n    fnames,csv_labels = parse_csv_labels(csv_file, skip_header, cat_separator)\n    return dict_source(folder, fnames, csv_labels, suffix, continuous)\n\ndef dict_source(folder, fnames, csv_labels, suffix=\'\', continuous=False):\n    all_labels = sorted(list(set(p for o in csv_labels.values() for p in ([] if type(o) == float else o))))\n    full_names = [os.path.join(folder,str(fn)+suffix) for fn in fnames]\n    if continuous:\n        label_arr = np.array([np.array(csv_labels[i]).astype(np.float32)\n                for i in fnames])\n    else:\n        label2idx = {v:k for k,v in enumerate(all_labels)}\n        label_arr = nhot_labels(label2idx, csv_labels, fnames, len(all_labels))\n        is_single = np.all(label_arr.sum(axis=1)==1)\n        if is_single: label_arr = np.argmax(label_arr, axis=1)\n    return full_names, label_arr, all_labels\n\nclass BaseDataset(Dataset):\n    """"""An abstract class representing a fastai dataset. Extends torch.utils.data.Dataset.""""""\n    def __init__(self, transform=None):\n        self.transform = transform\n        self.n = self.get_n()\n        self.c = self.get_c()\n        self.sz = self.get_sz()\n\n    def get1item(self, idx):\n        x,y = self.get_x(idx),self.get_y(idx)\n        return self.get(self.transform, x, y)\n\n    def __getitem__(self, idx):\n        if isinstance(idx,slice):\n            xs,ys = zip(*[self.get1item(i) for i in range(*idx.indices(self.n))])\n            return np.stack(xs),ys\n        return self.get1item(idx)\n\n    def __len__(self): return self.n\n\n    def get(self, tfm, x, y):\n        return (x,y) if tfm is None else tfm(x,y)\n\n    @abstractmethod\n    def get_n(self):\n        """"""Return number of elements in the dataset == len(self).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_c(self):\n        """"""Return number of classes in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_sz(self):\n        """"""Return maximum size of an image in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_x(self, i):\n        """"""Return i-th example (image, wav, etc).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_y(self, i):\n        """"""Return i-th label.""""""\n        raise NotImplementedError\n\n    @property\n    def is_multi(self):\n        """"""Returns true if this data set contains multiple labels per sample.""""""\n        return False\n\n    @property\n    def is_reg(self):\n        """"""True if the data set is used to train regression models.""""""\n        return False\n\ndef isdicom(fn):\n    \'\'\'True if the fn points to a DICOM image\'\'\'\n    fn = str(fn)\n    if fn.endswith(\'.dcm\'):\n        return True\n    # Dicom signature from the dicom spec.\n    with open(fn,\'rb\') as fh:\n        fh.seek(0x80)\n        return fh.read(4)==b\'DICM\'\n\ndef open_image(fn):\n    """""" Opens an image using OpenCV given the file path.\n\n    Arguments:\n        fn: the file path of the image\n\n    Returns:\n        The image in RGB format as numpy array of floats normalized to range between 0.0 - 1.0\n    """"""\n    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n    if not os.path.exists(fn) and not str(fn).startswith(""http""):\n        raise OSError(\'No such file or directory: {}\'.format(fn))\n    elif os.path.isdir(fn) and not str(fn).startswith(""http""):\n        raise OSError(\'Is a directory: {}\'.format(fn))\n    elif isdicom(fn):\n        slice = pydicom.read_file(fn)\n        if slice.PhotometricInterpretation.startswith(\'MONOCHROME\'):\n            # Make a fake RGB image\n            im = np.stack([slice.pixel_array]*3,-1)\n            return im / ((1 << slice.BitsStored)-1)\n        else:\n            # No support for RGB yet, as it involves various color spaces.\n            # It shouldn\'t be too difficult to add though, if needed.\n            raise OSError(\'Unsupported DICOM image with PhotometricInterpretation=={}\'.format(slice.PhotometricInterpretation))\n    else:\n        #res = np.array(Image.open(fn), dtype=np.float32)/255\n        #if len(res.shape)==2: res = np.repeat(res[...,None],3,2)\n        #return res\n        try:\n            if str(fn).startswith(""http""):\n                req = urllib.urlopen(str(fn))\n                image = np.asarray(bytearray(req.read()), dtype=""uint8"")\n                im = cv2.imdecode(image, flags).astype(np.float32)/255\n            else:\n                im = cv2.imread(str(fn), flags).astype(np.float32)/255\n            if im is None: raise OSError(f\'File not recognized by opencv: {fn}\')\n            return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        except Exception as e:\n            raise OSError(\'Error handling image at: {}\'.format(fn)) from e\n\nclass FilesDataset(BaseDataset):\n    def __init__(self, fnames, transform, path):\n        self.path,self.fnames = path,fnames\n        super().__init__(transform)\n    def get_sz(self): return self.transform.sz\n    def get_x(self, i): return open_image(os.path.join(self.path, self.fnames[i]))\n    def get_n(self): return len(self.fnames)\n\n    def resize_imgs(self, targ, new_path, resume=True, fn=None):\n        """"""\n        resize all images in the dataset and save them to `new_path`\n        \n        Arguments:\n        targ (int): the target size\n        new_path (string): the new folder to save the images\n        resume (bool): if true (default), allow resuming a partial resize operation by checking for the existence\n        of individual images rather than the existence of the directory\n        fn (function): custom resizing function Img -> Img\n        """"""\n        dest = resize_imgs(self.fnames, targ, self.path, new_path, resume, fn)\n        return self.__class__(self.fnames, self.y, self.transform, dest)\n\n    def denorm(self,arr):\n        """"""Reverse the normalization done to a batch of images.\n\n        Arguments:\n            arr: of shape/size (N,3,sz,sz)\n        """"""\n        if type(arr) is not np.ndarray: arr = to_np(arr)\n        if len(arr.shape)==3: arr = arr[None]\n        return self.transform.denorm(np.rollaxis(arr,1,4))\n\n\nclass FilesArrayDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    def get_y(self, i): return self.y[i]\n    def get_c(self):\n        return self.y.shape[1] if len(self.y.shape)>1 else 0\n\nclass FilesIndexArrayDataset(FilesArrayDataset):\n    def get_c(self): return int(self.y.max())+1\n\n\nclass FilesNhotArrayDataset(FilesArrayDataset):\n    @property\n    def is_multi(self): return True\n\n\nclass FilesIndexArrayRegressionDataset(FilesArrayDataset):\n    def is_reg(self): return True\n\nclass ArraysDataset(BaseDataset):\n    def __init__(self, x, y, transform):\n        self.x,self.y=x,y\n        assert(len(x)==len(y))\n        super().__init__(transform)\n    def get_x(self, i): return self.x[i]\n    def get_y(self, i): return self.y[i]\n    def get_n(self): return len(self.y)\n    def get_sz(self): return self.x.shape[1]\n\n\nclass ArraysIndexDataset(ArraysDataset):\n    def get_c(self): return int(self.y.max())+1\n    def get_y(self, i): return self.y[i]\n\n\nclass ArraysIndexRegressionDataset(ArraysIndexDataset):\n    def is_reg(self): return True\n\n\nclass ArraysNhotDataset(ArraysDataset):\n    def get_c(self): return self.y.shape[1]\n    @property\n    def is_multi(self): return True\n\n\nclass ModelData():\n    """"""Encapsulates DataLoaders and Datasets for training, validation, test. Base class for fastai *Data classes.""""""\n    def __init__(self, path, trn_dl, val_dl, test_dl=None):\n        self.path,self.trn_dl,self.val_dl,self.test_dl = path,trn_dl,val_dl,test_dl\n\n    @classmethod\n    def from_dls(cls, path,trn_dl,val_dl,test_dl=None):\n        #trn_dl,val_dl = DataLoader(trn_dl),DataLoader(val_dl)\n        #if test_dl: test_dl = DataLoader(test_dl)\n        return cls(path, trn_dl, val_dl, test_dl)\n\n    @property\n    def is_reg(self): return self.trn_ds.is_reg\n    @property\n    def is_multi(self): return self.trn_ds.is_multi\n    @property\n    def trn_ds(self): return self.trn_dl.dataset\n    @property\n    def val_ds(self): return self.val_dl.dataset\n    @property\n    def test_ds(self): return self.test_dl.dataset\n    @property\n    def trn_y(self): return self.trn_ds.y\n    @property\n    def val_y(self): return self.val_ds.y\n\n\nclass ImageData(ModelData):\n    def __init__(self, path, datasets, bs, num_workers, classes):\n        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n            self.get_dl(ds,shuf) for ds,shuf in [\n                (trn_ds,True),(val_ds,False),(fix_ds,False),(aug_ds,False),\n                (test_ds,False),(test_aug_ds,False)\n            ]\n        ]\n\n    def get_dl(self, ds, shuffle):\n        if ds is None: return None\n        return DataLoader(ds, batch_size=self.bs, shuffle=shuffle,\n            num_workers=self.num_workers, pin_memory=False)\n\n    @property\n    def sz(self): return self.trn_ds.sz\n    @property\n    def c(self): return self.trn_ds.c\n\n    def resized(self, dl, targ, new_path, resume = True, fn=None):\n        """"""\n        Return a copy of this dataset resized\n        """"""\n        return dl.dataset.resize_imgs(targ, new_path, resume=resume, fn=fn) if dl else None\n\n    def resize(self, targ_sz, new_path=\'tmp\', resume=True, fn=None):\n        """"""\n        Resizes all the images in the train, valid, test folders to a given size.\n\n        Arguments:\n        targ_sz (int): the target size\n        new_path (str): the path to save the resized images (default tmp)\n        resume (bool): if True, check for images in the DataSet that haven\'t been resized yet (useful if a previous resize\n        operation was aborted)\n        fn (function): optional custom resizing function\n        """"""\n        new_ds = []\n        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n        else: dls += [None,None]\n        t = tqdm_notebook(dls)\n        for dl in t: new_ds.append(self.resized(dl, targ_sz, new_path, resume, fn))\n        t.close()\n        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)\n\n    @staticmethod\n    def get_ds(fn, trn, val, tfms, test=None, **kwargs):\n        res = [\n            fn(trn[0], trn[1], tfms[0], **kwargs), # train\n            fn(val[0], val[1], tfms[1], **kwargs), # val\n            fn(trn[0], trn[1], tfms[1], **kwargs), # fix\n            fn(val[0], val[1], tfms[0], **kwargs)  # aug\n        ]\n        if test is not None:\n            if isinstance(test, tuple):\n                test_lbls = test[1]\n                test = test[0]\n            else:\n                if len(trn[1].shape) == 1:\n                    test_lbls = np.zeros((len(test),1))\n                else:\n                    test_lbls = np.zeros((len(test),trn[1].shape[1]))\n            res += [\n                fn(test, test_lbls, tfms[1], **kwargs), # test\n                fn(test, test_lbls, tfms[0], **kwargs)  # test_aug\n            ]\n        else: res += [None,None]\n        return res\n\n\nclass ImageClassifierData(ImageData):\n    @classmethod\n    def from_arrays(cls, path, trn, val, bs=64, tfms=(None,None), classes=None, num_workers=4, test=None, continuous=False):\n        """""" Read in images and their labels given as numpy arrays\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            trn: a tuple of training data matrix and target label/classification array (e.g. `trn=(x,y)` where `x` has the\n                shape of `(5000, 784)` and `y` has the shape of `(5000,)`)\n            val: a tuple of validation data matrix and target label/classification array.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            classes: a list of all labels/classifications\n            num_workers: a number of workers\n            test: a matrix of test data (the shape should match `trn[0]`)\n\n        Returns:\n            ImageClassifierData\n        """"""\n        f = ArraysIndexRegressionDataset if continuous else ArraysIndexDataset\n        datasets = cls.get_ds(f, trn, val, tfms, test=test)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\n    @classmethod\n    def from_paths(cls, path, bs=64, tfms=(None,None), trn_name=\'train\', val_name=\'valid\', test_name=None, test_with_labels=False, num_workers=8):\n        """""" Read in images and their labels given as sub-folder names\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            trn_name: a name of the folder that contains training images.\n            val_name:  a name of the folder that contains validation images.\n            test_name:  a name of the folder that contains test images.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not(tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        trn,val = [folder_source(path, o) for o in (trn_name, val_name)]\n        if test_name:\n            test = folder_source(path, test_name) if test_with_labels else read_dir(path, test_name)\n        else: test = None\n        datasets = cls.get_ds(FilesIndexArrayDataset, trn, val, tfms, path=path, test=test)\n        return cls(path, datasets, bs, num_workers, classes=trn[2])\n\n    @classmethod\n    def from_csv(cls, path, folder, csv_fname, bs=64, tfms=(None,None),\n               val_idxs=None, suffix=\'\', test_name=None, continuous=False, skip_header=True, num_workers=8, cat_separator=\' \'):\n        """""" Read in images and their labels given as a CSV file.\n\n        This method should be used when training image labels are given in an CSV file as opposed to\n        sub-directories with label names.\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            folder: a name of the folder in which training images are contained.\n            csv_fname: a name of the CSV file which contains target labels.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            val_idxs: index of images to be used for validation. e.g. output of `get_cv_idxs`.\n                If None, default arguments to get_cv_idxs are used.\n            suffix: suffix to add to image names in CSV file (sometimes CSV only contains the file name without file\n                    extension e.g. \'.jpg\' - in which case, you can set suffix as \'.jpg\')\n            test_name: a name of the folder which contains test images.\n            continuous: if True, the data set is used to train regression models. If False, it is used \n                to train classification models.\n            skip_header: skip the first row of the CSV file.\n            num_workers: number of workers\n            cat_separator: Labels category separator\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not (tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        assert not (os.path.isabs(folder)), ""folder needs to be a relative path""\n        fnames,y,classes = csv_source(folder, csv_fname, skip_header, suffix, continuous=continuous, cat_separator=cat_separator)\n        return cls.from_names_and_array(path, fnames, y, classes, val_idxs, test_name,\n                num_workers=num_workers, suffix=suffix, tfms=tfms, bs=bs, continuous=continuous)\n\n    @classmethod\n    def from_path_and_array(cls, path, folder, y, classes=None, val_idxs=None, test_name=None,\n            num_workers=8, tfms=(None,None), bs=64):\n        """""" Read in images given a sub-folder and their labels given a numpy array\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            folder: a name of the folder in which training images are contained.\n            y: numpy array which contains target labels ordered by filenames.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            val_idxs: index of images to be used for validation. e.g. output of `get_cv_idxs`.\n                If None, default arguments to get_cv_idxs are used.\n            test_name: a name of the folder which contains test images.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not (tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        assert not (os.path.isabs(folder)), ""folder needs to be a relative path""\n        fnames = np.core.defchararray.add(f\'{folder}/\', sorted(os.listdir(f\'{path}{folder}\')))\n        return cls.from_names_and_array(path, fnames, y, classes, val_idxs, test_name,\n                num_workers=num_workers, tfms=tfms, bs=bs)\n\n    @classmethod\n    def from_names_and_array(cls, path, fnames, y, classes, val_idxs=None, test_name=None,\n            num_workers=8, suffix=\'\', tfms=(None,None), bs=64, continuous=False):\n        val_idxs = get_cv_idxs(len(fnames)) if val_idxs is None else val_idxs\n        ((val_fnames,trn_fnames),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), y)\n\n        test_fnames = read_dir(path, test_name) if test_name else None\n        if continuous: f = FilesIndexArrayRegressionDataset\n        else:\n            f = FilesIndexArrayDataset if len(trn_y.shape)==1 else FilesNhotArrayDataset\n        datasets = cls.get_ds(f, (trn_fnames,trn_y), (val_fnames,val_y), tfms,\n                               path=path, test=test_fnames)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\ndef split_by_idx(idxs, *a):\n    """"""\n    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n    This can be used to split multiple arrays containing training data to validation and training set.\n\n    :param idxs [int]: list of indexes selected\n    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n    :return: list of tuples, each containing a split of corresponding array from *a.\n            First element of each tuple is an array composed from elements selected by idxs,\n            second element is an array of remaining elements.\n    """"""\n    mask = np.zeros(len(a[0]),dtype=bool)\n    mask[np.array(idxs)] = True\n    return [(o[mask],o[~mask]) for o in a]\n\n'"
old/fastai/executors.py,0,"b'import collections\nimport itertools\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\nclass LazyThreadPoolExecutor(ThreadPoolExecutor):\n    def map(self, fn, *iterables, timeout=None, chunksize=1, prefetch=None):\n        """"""\n        Collects iterables lazily, rather than immediately.\n        Docstring same as parent: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor\n        Implmentation taken from this PR: https://github.com/python/cpython/pull/707\n        """"""\n        if timeout is not None: end_time = timeout + time.time()\n        if prefetch is None: prefetch = self._max_workers\n        if prefetch < 0: raise ValueError(""prefetch count may not be negative"")\n        argsiter = zip(*iterables)\n        fs = collections.deque(self.submit(fn, *args) for args in itertools.islice(argsiter, self._max_workers+prefetch))\n        # Yield must be hidden in closure so that the futures are submitted before the first iterator value is required.\n        def result_iterator():\n            nonlocal argsiter\n            try:\n                while fs:\n                    res = fs[0].result() if timeout is None else fs[0].result(end_time-time.time())\n                    # Got a result, future needn\'t be cancelled\n                    del fs[0]\n                    # Dispatch next task before yielding to keep pipeline full\n                    if argsiter:\n                        try:\n                            args = next(argsiter)\n                        except StopIteration:\n                            argsiter = None\n                        else:\n                            fs.append(self.submit(fn, *args))\n                    yield res\n            finally:\n                for future in fs: future.cancel()\n        return result_iterator()'"
old/fastai/fp16.py,4,"b'import torch\nimport torch.nn as nn\nfrom .core import trainable_params_\nfrom .torch_imports import *\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\nclass FP16(nn.Module):\n    def __init__(self, module): \n        super().__init__()\n        self.module = batchnorm_to_fp32(module.half())\n        \n    def forward(self, input):\n        if is_float(input): input = input.half()\n        return self.module(input)\n    \n    def load_state_dict(self, *inputs, **kwargs):\n        self.module.load_state_dict(*inputs, **kwargs)\n\n    def state_dict(self, *inputs, **kwargs):\n        return self.module.state_dict(*inputs, **kwargs)\n    \n    def __getitem__(self, idx):\n        return self.module[idx]\n\ndef is_float(tensor):\n    if IS_TORCH_04: return tensor.is_floating_point()\n    if isinstance(tensor, Variable): tensor = tensor.data\n    return isinstance(tensor, torch.cuda.FloatTensor)\n\ndef batchnorm_to_fp32(module):\n    \'\'\'\n    BatchNorm layers to have parameters in single precision.\n    Find all layers and convert them back to float. This can\'t\n    be done with built in .apply as that function will apply\n    fn to all modules, parameters, and buffers. Thus we wouldn\'t\n    be able to guard the float conversion based on the module type.\n    \'\'\'\n    if isinstance(module, nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        batchnorm_to_fp32(child)\n    return module\n\ndef copy_model_to_fp32(m, optim):\n    """"""  Creates a fp32 copy of model parameters and sets optimizer parameters\n    """"""\n    fp32_params = [m_param.clone().type(torch.cuda.FloatTensor).detach() for m_param in trainable_params_(m)]\n    optim_groups = [group[\'params\'] for group in optim.param_groups]\n    iter_fp32_params = iter(fp32_params)\n    for group_params in optim_groups:\n        for i in range(len(group_params)):\n            if not group_params[i].requires_grad: continue # only update trainable_params_\n            fp32_param = next(iter_fp32_params)\n            assert(fp32_param.shape == group_params[i].shape)\n            fp32_param.requires_grad = group_params[i].requires_grad\n            group_params[i] = fp32_param\n    return fp32_params\n\ndef copy_fp32_to_model(m, fp32_params):\n    m_params = trainable_params_(m)\n    assert(len(m_params) == len(fp32_params))\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        m_param.data.copy_(fp32_param.data)\n\ndef update_fp32_grads(fp32_params, m):\n    m_params = trainable_params_(m)\n    assert(len(m_params) == len(fp32_params))\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        if fp32_param.grad is None:\n            fp32_param.grad = nn.Parameter(fp32_param.data.new().resize_(*fp32_param.data.size()))\n        fp32_param.grad.data.copy_(m_param.grad.data)\n\n'"
old/fastai/imports.py,0,"b""from IPython.lib.deepreload import reload as dreload\nimport PIL, os, numpy as np, math, collections, threading, json, bcolz, random, scipy, cv2\nimport pandas as pd, pickle, sys, itertools, string, sys, re, datetime, time, shutil, copy\nimport seaborn as sns, matplotlib\nimport IPython, graphviz, sklearn_pandas, sklearn, warnings, pdb\nimport contextlib\nfrom abc import abstractmethod\nfrom glob import glob, iglob\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom itertools import chain\nfrom functools import partial\nfrom collections import Iterable, Counter, OrderedDict\nfrom isoweek import Week\nfrom pandas_summary import DataFrameSummary\nfrom IPython.lib.display import FileLink\nfrom PIL import Image, ImageEnhance, ImageOps\nfrom sklearn import metrics, ensemble, preprocessing\nfrom operator import itemgetter, attrgetter\nfrom pathlib import Path\nfrom distutils.version import LooseVersion\n\nfrom matplotlib import pyplot as plt, rcParams, animation\nfrom ipywidgets import interact, interactive, fixed, widgets\nmatplotlib.rc('animation', html='html5')\nnp.set_printoptions(precision=5, linewidth=110, suppress=True)\n\nfrom ipykernel.kernelapp import IPKernelApp\ndef in_notebook(): return IPKernelApp.initialized()\n\ndef in_ipynb():\n    try:\n        cls = get_ipython().__class__.__name__\n        return cls == 'ZMQInteractiveShell'\n    except NameError:\n        return False\n\nimport tqdm as tq\nfrom tqdm import tqdm_notebook, tnrange\n\ndef clear_tqdm():\n    inst = getattr(tq.tqdm, '_instances', None)\n    if not inst: return\n    try:\n        for i in range(len(inst)): inst.pop().close()\n    except Exception:\n        pass\n\nif in_notebook():\n    def tqdm(*args, **kwargs):\n        clear_tqdm()\n        return tq.tqdm(*args, file=sys.stdout, **kwargs)\n    def trange(*args, **kwargs):\n        clear_tqdm()\n        return tq.trange(*args, file=sys.stdout, **kwargs)\nelse:\n    from tqdm import tqdm, trange\n    tnrange=trange\n    tqdm_notebook=tqdm\n\n"""
old/fastai/initializers.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\ndef cond_init(m, init_fn):\n    if not isinstance(m, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):\n        if hasattr(m, 'weight'): init_fn(m.weight)\n        if hasattr(m, 'bias') and hasattr(m.bias, 'data'): m.bias.data.fill_(0.)\n\ndef apply_init(m, init_fn):\n    m.apply(lambda x: cond_init(x, init_fn))\n\n\n"""
old/fastai/io.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\nimport gzip\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\n\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None: self.total = tsize\n        self.update(b * bsize - self.n)\n\ndef get_data(url, filename):\n    if not os.path.exists(filename):\n\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n\n"""
old/fastai/layer_optimizer.py,0,"b""from .imports import *\nfrom .torch_imports import *\nfrom .core import *\n\ndef opt_params(parm, lr, wd):\n    return {'params': chain_params(parm), 'lr':lr, 'weight_decay':wd}\n\nclass LayerOptimizer():\n    def __init__(self, opt_fn, layer_groups, lrs, wds=None):\n        if not isinstance(layer_groups, (list,tuple)): layer_groups=[layer_groups]\n        lrs = listify(lrs, layer_groups)\n        if wds is None: wds=0.\n        wds = listify(wds, layer_groups)\n        self.layer_groups,self.lrs,self.wds = layer_groups,lrs,wds\n        self.opt = opt_fn(self.opt_params())\n\n    def opt_params(self):\n        assert len(self.layer_groups) == len(self.lrs), f'size mismatch, expected {len(self.layer_groups)} lrs, but got {len(self.lrs)}'\n        assert len(self.layer_groups) == len(self.wds), f'size mismatch, expected {len(self.layer_groups)} wds, but got {len(self.wds)}'\n        params = list(zip(self.layer_groups,self.lrs,self.wds))\n        return [opt_params(*p) for p in params]\n\n    @property\n    def lr(self): return self.lrs[-1]\n\n    @property\n    def mom(self):\n        if 'betas' in self.opt.param_groups[0]:\n            return self.opt.param_groups[0]['betas'][0]\n        else:\n            return self.opt.param_groups[0]['momentum']\n\n    def set_lrs(self, lrs):\n        lrs = listify(lrs, self.layer_groups)\n        set_lrs(self.opt, lrs)\n        self.lrs=lrs\n\n    def set_wds_out(self, wds):\n        wds = listify(wds, self.layer_groups)\n        set_wds_out(self.opt, wds)\n        set_wds(self.opt, [0] * len(self.layer_groups))\n        self.wds=wds\n\n    def set_wds(self, wds):\n        wds = listify(wds, self.layer_groups)\n        set_wds(self.opt, wds)\n        set_wds_out(self.opt, [0] * len(self.layer_groups))\n        self.wds=wds\n    \n    def set_mom(self,momentum):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (momentum, pg['betas'][1])\n        else:\n            for pg in self.opt.param_groups: pg['momentum'] = momentum\n    \n    def set_beta(self,beta):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (pg['betas'][0],beta)\n        elif 'alpha' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['alpha'] = beta\n\n    def set_opt_fn(self, opt_fn):\n        if type(self.opt) != type(opt_fn(self.opt_params())):\n            self.opt = opt_fn(self.opt_params())\n\ndef zip_strict_(l, r):\n    assert len(l) == len(r), f'size mismatch, expected lengths {len(l)}, but got {len(l)} and {len(r)} instead.'\n    return zip(l, r)\n\ndef set_lrs(opt, lrs):\n    lrs = listify(lrs, opt.param_groups)\n    for pg,lr in zip_strict_(opt.param_groups,lrs): pg['lr'] = lr\n\ndef set_wds_out(opt, wds):\n    wds = listify(wds, opt.param_groups)\n    for pg,wd in zip_strict_(opt.param_groups,wds): pg['wd'] = wd\n\ndef set_wds(opt, wds):\n    wds = listify(wds, opt.param_groups)\n    for pg,wd in zip_strict_(opt.param_groups,wds): pg['weight_decay'] = wd\n\n"""
old/fastai/layers.py,1,"b'import torch\nfrom torch import nn\n\nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1,1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n\nclass Lambda(nn.Module):\n    def __init__(self, f): super().__init__(); self.f=f\n    def forward(self, x): return self.f(x)\n\nclass Flatten(nn.Module):\n    def __init__(self): super().__init__()\n    def forward(self, x): return x.view(x.size(0), -1)\n\n'"
old/fastai/learner.py,2,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .model import *\nfrom .dataset import *\nfrom .sgdr import *\nfrom .layer_optimizer import *\nfrom .layers import *\nfrom .metrics import *\nfrom .swa import *\nfrom .fp16 import *\nfrom .lsuv_initializer import apply_lsuv_init\nimport time\n\n\nclass Learner():\n    def __init__(self, data, models, opt_fn=None, tmp_name=\'tmp\', models_name=\'models\', metrics=None, clip=None, crit=None):\n        """"""\n        Combines a ModelData object with a nn.Module object, such that you can train that\n        module.\n        data (ModelData): An instance of ModelData.\n        models(module): chosen neural architecture for solving a supported problem.\n        opt_fn(function): optimizer function, uses SGD with Momentum of .9 if none.\n        tmp_name(str): output name of the directory containing temporary files from training process\n        models_name(str): output name of the directory containing the trained model\n        metrics(list): array of functions for evaluating a desired metric. Eg. accuracy.\n        clip(float): gradient clip chosen to limit the change in the gradient to prevent exploding gradients Eg. .3\n        """"""\n        self.data_,self.models,self.metrics,self.clip = data,models,metrics,clip\n        self.sched=None\n        self.wd_sched = None\n        self.opt_fn = opt_fn or SGD_Momentum(0.9)\n        self.tmp_path = tmp_name if os.path.isabs(tmp_name) else os.path.join(self.data.path, tmp_name)\n        self.models_path = models_name if os.path.isabs(models_name) else os.path.join(self.data.path, models_name)\n        os.makedirs(self.tmp_path, exist_ok=True)\n        os.makedirs(self.models_path, exist_ok=True)\n        self.crit = crit if crit else self._get_crit(data)\n        self.reg_fn = None\n        self.fp16 = False\n\n    @classmethod\n    def from_model_data(cls, m, data, **kwargs):\n        self = cls(data, BasicModel(to_gpu(m)), **kwargs)\n        self.unfreeze()\n        return self\n\n    def __getitem__(self,i): return self.children[i]\n\n    @property\n    def children(self): return children(self.model)\n\n    @property\n    def model(self): return self.models.model\n\n    @property\n    def data(self): return self.data_\n\n    def summary(self): return model_summary(self.model, [torch.rand(3, 3, self.data.sz,self.data.sz)])\n\n    def __repr__(self): return self.model.__repr__()\n    \n    def lsuv_init(self, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False):         \n        x = V(next(iter(self.data.trn_dl))[0])\n        self.models.model=apply_lsuv_init(self.model, x, needed_std=needed_std, std_tol=std_tol,\n                            max_attempts=max_attempts, do_orthonorm=do_orthonorm, \n                            cuda=USE_GPU and torch.cuda.is_available())\n\n    def set_bn_freeze(self, m, do_freeze):\n        if hasattr(m, \'running_mean\'): m.bn_freeze = do_freeze\n\n    def bn_freeze(self, do_freeze):\n        apply_leaf(self.model, lambda m: self.set_bn_freeze(m, do_freeze))\n\n    def freeze_to(self, n):\n        c=self.get_layer_groups()\n        for l in c:     set_trainable(l, False)\n        for l in c[n:]: set_trainable(l, True)\n\n    def freeze_all_but(self, n):\n        c=self.get_layer_groups()\n        for l in c: set_trainable(l, False)\n        set_trainable(c[n], True)\n        \n    def freeze_groups(self, groups):\n        c = self.get_layer_groups()\n        self.unfreeze()\n        for g in groups:\n            set_trainable(c[g], False)\n            \n    def unfreeze_groups(self, groups):\n        c = self.get_layer_groups()\n        for g in groups:\n            set_trainable(c[g], True)\n\n    def unfreeze(self): self.freeze_to(0)\n\n    def get_model_path(self, name): return os.path.join(self.models_path,name)+\'.h5\'\n    \n    def save(self, name): \n        save_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): save_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n                       \n    def load(self, name): \n        load_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): load_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n\n    def set_data(self, data): self.data_ = data\n\n    def get_cycle_end(self, name):\n        if name is None: return None\n        return lambda sched, cycle: self.save_cycle(name, cycle)\n\n    def save_cycle(self, name, cycle): self.save(f\'{name}_cyc_{cycle}\')\n    def load_cycle(self, name, cycle): self.load(f\'{name}_cyc_{cycle}\')\n\n    def half(self):\n        if self.fp16: return\n        self.fp16 = True\n        if type(self.model) != FP16: self.models.model = FP16(self.model)\n    def float(self):\n        if not self.fp16: return\n        self.fp16 = False\n        if type(self.model) == FP16: self.models.model = self.model.module\n        self.model.float()\n\n    def fit_gen(self, model, data, layer_opt, n_cycle, cycle_len=None, cycle_mult=1, cycle_save_name=None, best_save_name=None,\n                use_clr=None, use_clr_beta=None, metrics=None, callbacks=None, use_wd_sched=False, norm_wds=False,             \n                wds_sched_mult=None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n\n        """"""Method does some preparation before finally delegating to the \'fit\' method for\n        fitting the model. Namely, if cycle_len is defined, it adds a \'Cosine Annealing\'\n        scheduler for varying the learning rate across iterations.\n\n        Method also computes the total number of epochs to fit based on provided \'cycle_len\',\n        \'cycle_mult\', and \'n_cycle\' parameters.\n\n        Args:\n            model (Learner):  Any neural architecture for solving a supported problem.\n                Eg. ResNet-34, RNN_Learner etc.\n\n            data (ModelData): An instance of ModelData.\n\n            layer_opt (LayerOptimizer): An instance of the LayerOptimizer class\n\n            n_cycle (int): number of cycles\n\n            cycle_len (int):  number of epochs before lr is reset to the initial value.\n                E.g if cycle_len = 3, then the lr is varied between a maximum\n                and minimum value over 3 epochs.\n\n            cycle_mult (int): additional parameter for influencing how the lr resets over\n                the cycles. For an intuitive explanation, please see\n                https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb\n\n            cycle_save_name (str): use to save the weights at end of each cycle (requires\n                use_clr, use_clr_beta or cycle_len arg)\n\n            best_save_name (str): use to save weights of best model during training.\n\n            metrics (function): some function for evaluating a desired metric. Eg. accuracy.\n\n            callbacks (list(Callback)): callbacks to apply during the training.\n\n            use_wd_sched (bool, optional): set to True to enable weight regularization using\n                the technique mentioned in https://arxiv.org/abs/1711.05101. When this is True\n                alone (see below), the regularization is detached from gradient update and\n                applied directly to the weights.\n\n            norm_wds (bool, optional): when this is set to True along with use_wd_sched, the\n                regularization factor is normalized with each training cycle.\n\n            wds_sched_mult (function, optional): when this is provided along with use_wd_sched\n                as True, the value computed by this function is multiplied with the regularization\n                strength. This function is passed the WeightDecaySchedule object. And example\n                function that can be passed is:\n                            f = lambda x: np.array(x.layer_opt.lrs) / x.init_lrs\n                            \n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work.\n                \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n                \n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n\n        Returns:\n            None\n        """"""\n\n        if cycle_save_name:\n            assert use_clr or use_clr_beta or cycle_len, ""cycle_save_name argument requires either of the following arguments use_clr, use_clr_beta, cycle_len""\n\n        if callbacks is None: callbacks=[]\n        if metrics is None: metrics=self.metrics\n\n        if use_wd_sched:\n            # This needs to come before CosAnneal() because we need to read the initial learning rate from\n            # layer_opt.lrs - but CosAnneal() alters the layer_opt.lrs value initially (divides by 100)\n            if np.sum(layer_opt.wds) == 0:\n                print(\'fit() warning: use_wd_sched is set to True, but weight decay(s) passed are 0. Use wds to \'\n                      \'pass weight decay values.\')\n            batch_per_epoch = len(data.trn_dl)\n            cl = cycle_len if cycle_len else 1\n            self.wd_sched = WeightDecaySchedule(layer_opt, batch_per_epoch, cl, cycle_mult, n_cycle,\n                                                norm_wds, wds_sched_mult)\n            callbacks += [self.wd_sched]\n\n        if use_clr is not None:\n            clr_div,cut_div = use_clr[:2]\n            moms = use_clr[2:] if len(use_clr) > 2 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            assert cycle_len, ""use_clr requires cycle_len arg""\n            self.sched = CircularLR(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=clr_div, cut_div=cut_div,\n                                    momentums=moms)\n        elif use_clr_beta is not None:\n            div,pct = use_clr_beta[:2]\n            moms = use_clr_beta[2:] if len(use_clr_beta) > 3 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            assert cycle_len, ""use_clr_beta requires cycle_len arg""\n            self.sched = CircularLR_beta(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=div,\n                                    pct=pct, momentums=moms)\n        elif cycle_len:\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            cycle_batches = len(data.trn_dl)*cycle_len\n            self.sched = CosAnneal(layer_opt, cycle_batches, on_cycle_end=cycle_end, cycle_mult=cycle_mult)\n        elif not self.sched: self.sched=LossRecorder(layer_opt)\n        callbacks+=[self.sched]\n\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(model)\n            callbacks+=[SWA(model, self.swa_model, swa_start)]\n\n        n_epoch = int(sum_geom(cycle_len if cycle_len else 1, cycle_mult, n_cycle))\n        return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def get_layer_groups(self): return self.models.get_layer_groups()\n\n    def get_layer_opt(self, lrs, wds):\n\n        """"""Method returns an instance of the LayerOptimizer class, which\n        allows for setting differential learning rates for different\n        parts of the model.\n\n        An example of how a model maybe differentiated into different parts\n        for application of differential learning rates and weight decays is\n        seen in ../.../courses/dl1/fastai/conv_learner.py, using the dict\n        \'model_meta\'. Currently, this seems supported only for convolutional\n        networks such as VGG-19, ResNet-XX etc.\n\n        Args:\n            lrs (float or list(float)): learning rate(s) for the model\n\n            wds (float or list(float)): weight decay parameter(s).\n\n        Returns:\n            An instance of a LayerOptimizer\n        """"""\n        return LayerOptimizer(self.opt_fn, self.get_layer_groups(), lrs, wds)\n\n    def fit(self, lrs, n_cycle, wds=None, **kwargs):\n\n        """"""Method gets an instance of LayerOptimizer and delegates to self.fit_gen(..)\n\n        Note that one can specify a list of learning rates which, when appropriately\n        defined, will be applied to different segments of an architecture. This seems\n        mostly relevant to ImageNet-trained models, where we want to alter the layers\n        closest to the images by much smaller amounts.\n\n        Likewise, a single or list of weight decay parameters can be specified, which\n        if appropriate for a model, will apply variable weight decay parameters to\n        different segments of the model.\n\n        Args:\n            lrs (float or list(float)): learning rate for the model\n\n            n_cycle (int): number of cycles (or iterations) to fit the model for\n\n            wds (float or list(float)): weight decay parameter(s).\n\n            kwargs: other arguments\n\n        Returns:\n            None\n        """"""\n        self.sched = None\n        layer_opt = self.get_layer_opt(lrs, wds)\n        return self.fit_gen(self.model, self.data, layer_opt, n_cycle, **kwargs)\n\n    def warm_up(self, lr, wds=None):\n        layer_opt = self.get_layer_opt(lr/4, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), lr, linear=True)\n        return self.fit_gen(self.model, self.data, layer_opt, 1)\n\n    def lr_find(self, start_lr=1e-5, end_lr=10, wds=None, linear=False, **kwargs):\n        """"""Helps you find an optimal learning rate for a model.\n\n         It uses the technique developed in the 2015 paper\n         `Cyclical Learning Rates for Training Neural Networks`, where\n         we simply keep increasing the learning rate from a very small value,\n         until the loss starts decreasing.\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            wds (iterable/float)\n\n        Examples:\n            As training moves us closer to the optimal weights for a model,\n            the optimal learning rate will be smaller. We can take advantage of\n            that knowledge and provide lr_find() with a starting learning rate\n            1000x smaller than the model\'s current learning rate as such:\n\n            >> learn.lr_find(lr/1000)\n\n            >> lrs = np.array([ 1e-4, 1e-3, 1e-2 ])\n            >> learn.lr_find(lrs / 1000)\n\n        Notes:\n            lr_find() may finish before going through each batch of examples if\n            the loss decreases enough.\n\n        .. _Cyclical Learning Rates for Training Neural Networks:\n            http://arxiv.org/abs/1506.01186\n\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), end_lr, linear=linear)\n        self.fit_gen(self.model, self.data, layer_opt, 1, **kwargs)\n        self.load(\'tmp\')\n\n    def lr_find2(self, start_lr=1e-5, end_lr=10, num_it = 100, wds=None, linear=False, stop_dv=True, **kwargs):\n        """"""A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n        At each step, it computes the validation loss and the metrics on the next\n        batch of the validation data, so it\'s slower than lr_find().\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            num_it : the number of iterations you want it to run\n            wds (iterable/float)\n            stop_dv : stops (or not) when the losses starts to explode.\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder2(layer_opt, num_it, end_lr, linear=linear, metrics=self.metrics, stop_dv=stop_dv)\n        self.fit_gen(self.model, self.data, layer_opt, num_it//len(self.data.trn_dl) + 1, all_val=True, **kwargs)\n        self.load(\'tmp\')\n\n    def predict(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict(m, dl)\n\n    def predict_with_targs(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict_with_targs(m, dl)\n\n    def predict_dl(self, dl): return predict_with_targs(self.model, dl)[0]\n\n    def predict_array(self, arr):\n        """"""\n        Args:\n            arr: a numpy array to be used as input to the model for prediction purposes\n        Returns:\n            a numpy array containing the predictions from the model\n        """"""\n        if not isinstance(arr, np.ndarray): raise OSError(f\'Not valid numpy array\')\n        self.model.eval()\n        return to_np(self.model(to_gpu(V(T(arr)))))\n\n    def TTA(self, n_aug=4, is_test=False):\n        """""" Predict with Test Time Augmentation (TTA)\n\n        Additional to the original test/validation images, apply image augmentation to them\n        (just like for training images) and calculate the mean of predictions. The intent\n        is to increase the accuracy of predictions by examining the images using multiple\n        perspectives.\n\n\n            n_aug: a number of augmentation images to use per original image\n            is_test: indicate to use test images; otherwise use validation images\n\n        Returns:\n            (tuple): a tuple containing:\n\n                log predictions (numpy.ndarray): log predictions (i.e. `np.exp(log_preds)` will return probabilities)\n                targs (numpy.ndarray): target values when `is_test==False`; zeros otherwise.\n        """"""\n        dl1 = self.data.test_dl     if is_test else self.data.val_dl\n        dl2 = self.data.test_aug_dl if is_test else self.data.aug_dl\n        preds1,targs = predict_with_targs(self.model, dl1)\n        preds1 = [preds1]*math.ceil(n_aug/4)\n        preds2 = [predict_with_targs(self.model, dl2)[0] for i in tqdm(range(n_aug), leave=False)]\n        return np.stack(preds1+preds2), targs\n\n    def fit_opt_sched(self, phases, cycle_save_name=None, best_save_name=None, stop_div=False, data_list=None, callbacks=None, \n                      cut = None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n        """"""Wraps us the content of phases to send them to model.fit(..)\n\n        This will split the training in several parts, each with their own learning rates/\n        wds/momentums/optimizer detailed in phases.\n\n        Additionaly we can add a list of different data objets in data_list to train\n        on different datasets (to change the size for instance) for each of these groups.\n\n        Args:\n            phases: a list of TrainingPhase objects\n            stop_div: when True, stops the training if the loss goes too high\n            data_list: a list of different Data objects.\n            kwargs: other arguments\n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work. \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n        Returns:\n            None\n        """"""\n        if data_list is None: data_list=[]\n        if callbacks is None: callbacks=[]\n        layer_opt = LayerOptimizer(phases[0].opt_fn, self.get_layer_groups(), 1e-2, phases[0].wds)\n        if len(data_list) == 0: nb_batches = [len(self.data.trn_dl)] * len(phases)\n        else: nb_batches = [len(data.trn_dl) for data in data_list] \n        self.sched = OptimScheduler(layer_opt, phases, nb_batches, stop_div)\n        callbacks.append(self.sched)\n        metrics = self.metrics\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(self.model)\n            callbacks+=[SWA(self.model, self.swa_model, swa_start)]\n        n_epochs = [phase.epochs for phase in phases] if cut is None else cut\n        if len(data_list)==0: data_list = [self.data]\n        return fit(self.model, data_list, n_epochs,layer_opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n'"
old/fastai/lm_rnn.py,5,"b'import warnings\nfrom .imports import *\nfrom .torch_imports import *\nfrom .rnn_reg import LockedDropout,WeightDrop,EmbeddingDropout\nfrom .model import Stepper\nfrom .core import set_grad_enabled\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef seq2seq_reg(output, xtra, loss, alpha=0, beta=0):\n    hs,dropped_hs = xtra\n    if alpha:  # Activation Regularization\n        loss = loss + (alpha * dropped_hs[-1].pow(2).mean()).sum()\n    if beta:   # Temporal Activation Regularization (slowness)\n        h = hs[-1]\n        if len(h)>1: loss = loss + (beta * (h[1:] - h[:-1]).pow(2).mean()).sum()\n    return loss\n\n\ndef repackage_var(h):\n    """"""Wraps h in new Variables, to detach them from their history.""""""\n    if IS_TORCH_04: return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)\n    else: return Variable(h.data) if type(h) == Variable else tuple(repackage_var(v) for v in h)\n\n\nclass RNN_Encoder(nn.Module):\n\n    """"""A custom RNN encoder network that uses\n        - an embedding matrix to encode input,\n        - a stack of LSTM or QRNN layers to drive the network, and\n        - variational dropouts in the embedding and LSTM/QRNN layers\n\n        The architecture for this network was inspired by the work done in\n        ""Regularizing and Optimizing LSTM Language Models"".\n        (https://arxiv.org/pdf/1708.02182.pdf)\n    """"""\n\n    initrange=0.1\n\n    def __init__(self, ntoken, emb_sz, n_hid, n_layers, pad_token, bidir=False,\n                 dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5, qrnn=False):\n        """""" Default constructor for the RNN_Encoder class\n\n            Args:\n                bs (int): batch size of input data\n                ntoken (int): number of vocabulary (or tokens) in the source dataset\n                emb_sz (int): the embedding size to use to encode each token\n                n_hid (int): number of hidden activation per LSTM layer\n                n_layers (int): number of LSTM layers to use in the architecture\n                pad_token (int): the int value used for padding text.\n                dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n                dropouti (float): dropout to apply to the input layer.\n                dropoute (float): dropout to apply to the embedding layer.\n                wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n\n            Returns:\n                None\n          """"""\n\n        super().__init__()\n        self.ndir = 2 if bidir else 1\n        self.bs, self.qrnn = 1, qrnn\n        self.encoder = nn.Embedding(ntoken, emb_sz, padding_idx=pad_token)\n        self.encoder_with_dropout = EmbeddingDropout(self.encoder)\n        if self.qrnn:\n            #Using QRNN requires cupy: https://github.com/cupy/cupy\n            from .torchqrnn.qrnn import QRNNLayer\n            self.rnns = [QRNNLayer(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n                save_prev_x=True, zoneout=0, window=2 if l == 0 else 1, output_gate=True) for l in range(n_layers)]\n            if wdrop:\n                for rnn in self.rnns:\n                    rnn.linear = WeightDrop(rnn.linear, wdrop, weights=[\'weight\'])\n        else:\n            self.rnns = [nn.LSTM(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n                1, bidirectional=bidir) for l in range(n_layers)]\n            if wdrop: self.rnns = [WeightDrop(rnn, wdrop) for rnn in self.rnns]\n        self.rnns = torch.nn.ModuleList(self.rnns)\n        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n\n        self.emb_sz,self.n_hid,self.n_layers,self.dropoute = emb_sz,n_hid,n_layers,dropoute\n        self.dropouti = LockedDropout(dropouti)\n        self.dropouths = nn.ModuleList([LockedDropout(dropouth) for l in range(n_layers)])\n\n    def forward(self, input):\n        """""" Invoked during the forward propagation of the RNN_Encoder module.\n        Args:\n            input (Tensor): input of shape (sentence length x batch_size)\n\n        Returns:\n            raw_outputs (tuple(list (Tensor), list(Tensor)): list of tensors evaluated from each RNN layer without using\n            dropouth, list of tensors evaluated from each RNN layer using dropouth,\n        """"""\n        sl,bs = input.size()\n        if bs!=self.bs:\n            self.bs=bs\n            self.reset()\n        with set_grad_enabled(self.training):\n            emb = self.encoder_with_dropout(input, dropout=self.dropoute if self.training else 0)\n            emb = self.dropouti(emb)\n            raw_output = emb\n            new_hidden,raw_outputs,outputs = [],[],[]\n            for l, (rnn,drop) in enumerate(zip(self.rnns, self.dropouths)):\n                current_input = raw_output\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    raw_output, new_h = rnn(raw_output, self.hidden[l])\n                new_hidden.append(new_h)\n                raw_outputs.append(raw_output)\n                if l != self.n_layers - 1: raw_output = drop(raw_output)\n                outputs.append(raw_output)\n\n            self.hidden = repackage_var(new_hidden)\n        return raw_outputs, outputs\n\n    def one_hidden(self, l):\n        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz)//self.ndir\n        if IS_TORCH_04: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_())\n        else: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_(), volatile=not self.training)\n\n    def reset(self):\n        if self.qrnn: [r.reset() for r in self.rnns]\n        self.weights = next(self.parameters()).data\n        if self.qrnn: self.hidden = [self.one_hidden(l) for l in range(self.n_layers)]\n        else: self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.n_layers)]\n\n\nclass MultiBatchRNN(RNN_Encoder):\n    def __init__(self, bptt, max_seq, *args, **kwargs):\n        self.max_seq,self.bptt = max_seq,bptt\n        super().__init__(*args, **kwargs)\n\n    def concat(self, arrs):\n        return [torch.cat([l[si] for l in arrs]) for si in range(len(arrs[0]))]\n\n    def forward(self, input):\n        sl,bs = input.size()\n        for l in self.hidden:\n            for h in l: h.data.zero_()\n        raw_outputs, outputs = [],[]\n        for i in range(0, sl, self.bptt):\n            r, o = super().forward(input[i: min(i+self.bptt, sl)])\n            if i>(sl-self.max_seq):\n                raw_outputs.append(r)\n                outputs.append(o)\n        return self.concat(raw_outputs), self.concat(outputs)\n\nclass LinearDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, n_out, n_hid, dropout, tie_encoder=None, bias=False):\n        super().__init__()\n        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.dropout = LockedDropout(dropout)\n        if bias: self.decoder.bias.data.zero_()\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = self.dropout(outputs[-1])\n        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n        result = decoded.view(-1, decoded.size(1))\n        return result, raw_outputs, outputs\n\n\nclass LinearBlock(nn.Module):\n    def __init__(self, ni, nf, drop):\n        super().__init__()\n        self.lin = nn.Linear(ni, nf)\n        self.drop = nn.Dropout(drop)\n        self.bn = nn.BatchNorm1d(ni)\n\n    def forward(self, x): return self.lin(self.drop(self.bn(x)))\n\n\nclass PoolingLinearClassifier(nn.Module):\n    def __init__(self, layers, drops):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            LinearBlock(layers[i], layers[i + 1], drops[i]) for i in range(len(layers) - 1)])\n\n    def pool(self, x, bs, is_max):\n        f = F.adaptive_max_pool1d if is_max else F.adaptive_avg_pool1d\n        return f(x.permute(1,2,0), (1,)).view(bs,-1)\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = outputs[-1]\n        sl,bs,_ = output.size()\n        avgpool = self.pool(output, bs, False)\n        mxpool = self.pool(output, bs, True)\n        x = torch.cat([output[-1], mxpool, avgpool], 1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return l_x, raw_outputs, outputs\n\n\nclass SequentialRNN(nn.Sequential):\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \'reset\'): c.reset()\n\n\ndef get_language_model(n_tok, emb_sz, n_hid, n_layers, pad_token,\n                 dropout=0.4, dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5, tie_weights=True, qrnn=False, bias=False):\n    """"""Returns a SequentialRNN model.\n\n    A RNN_Encoder layer is instantiated using the parameters provided.\n\n    This is followed by the creation of a LinearDecoder layer.\n\n    Also by default (i.e. tie_weights = True), the embedding matrix used in the RNN_Encoder\n    is used to  instantiate the weights for the LinearDecoder layer.\n\n    The SequentialRNN layer is the native torch\'s Sequential wrapper that puts the RNN_Encoder and\n    LinearDecoder layers sequentially in the model.\n\n    Args:\n        n_tok (int): number of unique vocabulary words (or tokens) in the source dataset\n        emb_sz (int): the embedding size to use to encode each token\n        n_hid (int): number of hidden activation per LSTM layer\n        n_layers (int): number of LSTM layers to use in the architecture\n        pad_token (int): the int value used for padding text.\n        dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n        dropouti (float): dropout to apply to the input layer.\n        dropoute (float): dropout to apply to the embedding layer.\n        wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n        tie_weights (bool): decide if the weights of the embedding matrix in the RNN encoder should be tied to the\n            weights of the LinearDecoder layer.\n        qrnn (bool): decide if the model is composed of LSTMS (False) or QRNNs (True).\n        bias (bool): decide if the decoder should have a bias layer or not.\n    Returns:\n        A SequentialRNN model\n    """"""\n    rnn_enc = RNN_Encoder(n_tok, emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=pad_token,\n                 dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop, qrnn=qrnn)\n    enc = rnn_enc.encoder if tie_weights else None\n    return SequentialRNN(rnn_enc, LinearDecoder(n_tok, emb_sz, dropout, tie_encoder=enc, bias=bias))\n\n\ndef get_rnn_classifier(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n                      dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5, qrnn=False):\n    rnn_enc = MultiBatchRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir,\n                      dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop, qrnn=qrnn)\n    return SequentialRNN(rnn_enc, PoolingLinearClassifier(layers, drops))\n\nget_rnn_classifer=get_rnn_classifier\n'"
old/fastai/lsuv_initializer.py,4,"b'""""""\nFrom https://github.com/ducha-aiki/LSUV-pytorch\n\nCopyright (C) 2017, Dmytro Mishkin\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the\n   distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\nimport numpy as np\nimport torch\nimport torch.nn.init\nimport torch.nn as nn\n\ngg = {}\ngg[\'hook_position\'] = 0\ngg[\'total_fc_conv_layers\'] = 0\ngg[\'done_counter\'] = -1\ngg[\'hook\'] = None\ngg[\'act_dict\'] = {}\ngg[\'counter_to_apply_correction\'] = 0\ngg[\'correction_needed\'] = False\ngg[\'current_coef\'] = 1.0\n\n# Orthonorm init code is taked from Lasagne\n# https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\ndef svd_orthonormal(w):\n    shape = w.shape\n    if len(shape) < 2:\n        raise RuntimeError(""Only shapes of length 2 or more are supported."")\n    flat_shape = (shape[0], np.prod(shape[1:]))\n    a = np.random.normal(0.0, 1.0, flat_shape)#w;\n    u, _, v = np.linalg.svd(a, full_matrices=False)\n    q = u if u.shape == flat_shape else v\n    q = q.reshape(shape)\n    return q.astype(np.float32)\n\ndef store_activations(self, input, output):\n    gg[\'act_dict\'] = output.data.cpu().numpy();\n    return\n\ndef add_current_hook(m):\n    if gg[\'hook\'] is not None:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'hook_position\'] > gg[\'done_counter\']:\n            gg[\'hook\'] = m.register_forward_hook(store_activations)\n        else:\n            gg[\'hook_position\'] += 1\n    return\n\ndef count_conv_fc_layers(m):\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        gg[\'total_fc_conv_layers\'] +=1\n    return\n\ndef remove_hooks(hooks):\n    for h in hooks:\n        h.remove()\n    return\n\ndef orthogonal_weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        if hasattr(m, \'weight_v\'):\n            w_ortho = svd_orthonormal(m.weight_v.data.cpu().numpy())\n            m.weight_v.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n        else:\n            w_ortho = svd_orthonormal(m.weight.data.cpu().numpy())\n            m.weight.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n    return\n\ndef apply_weights_correction(m):\n    if gg[\'hook\'] is None:\n        return\n    if not gg[\'correction_needed\']:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'counter_to_apply_correction\'] < gg[\'hook_position\']:\n            gg[\'counter_to_apply_correction\'] += 1\n        else:\n            if hasattr(m, \'weight_g\'):\n                m.weight_g.data *= float(gg[\'current_coef\'])\n                gg[\'correction_needed\'] = False\n            else:\n                m.weight.data *= gg[\'current_coef\']\n                gg[\'correction_needed\'] = False\n            return\n    return\n\ndef apply_lsuv_init(model, data, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=True, cuda=True):\n    model.eval();\n    if cuda:\n        model=model.cuda()\n        data=data.cuda()\n    else:\n        model=model.cpu()\n        data=data.cpu()        \n        \n    model.apply(count_conv_fc_layers)\n    if do_orthonorm:\n        model.apply(orthogonal_weights_init)\n        if cuda:\n            model=model.cuda()\n    for layer_idx in range(gg[\'total_fc_conv_layers\']):\n        model.apply(add_current_hook)\n        out = model(data)\n        current_std = gg[\'act_dict\'].std()\n        attempts = 0\n        while (np.abs(current_std - needed_std) > std_tol):\n            gg[\'current_coef\'] =  needed_std / (current_std  + 1e-8);\n            gg[\'correction_needed\'] = True\n            model.apply(apply_weights_correction)\n            if cuda:\n                model=model.cuda()\n            out = model(data)\n            current_std = gg[\'act_dict\'].std()\n            attempts+=1\n            if attempts > max_attempts:\n                print(f\'Cannot converge in {max_attempts} iterations\')\n                break\n        if gg[\'hook\'] is not None:\n           gg[\'hook\'].remove()\n        gg[\'done_counter\']+=1\n        gg[\'counter_to_apply_correction\'] = 0\n        gg[\'hook_position\'] = 0\n        gg[\'hook\']  = None\n    if not cuda:\n        model=model.cpu()\n    return model\n'"
old/fastai/metrics.py,9,"b'from .imports import *\nfrom .torch_imports import *\n\n# There are 2 versions of each metrics function, depending on the type of the prediction tensor:\n# *    torch preds/log_preds\n# *_np numpy preds/log_preds\n#\n\ndef accuracy(preds, targs):\n    preds = torch.max(preds, dim=1)[1]\n    return (preds==targs).float().mean()\n\ndef accuracy_np(preds, targs):\n    preds = np.argmax(preds, 1)\n    return (preds==targs).mean()\n\ndef accuracy_thresh(thresh):\n    return lambda preds,targs: accuracy_multi(preds, targs, thresh)\n\ndef accuracy_multi(preds, targs, thresh):\n    return ((preds>thresh).float()==targs).float().mean()\n\ndef accuracy_multi_np(preds, targs, thresh):\n    return ((preds>thresh)==targs).mean()\n\ndef recall(log_preds, targs, thresh=0.5, epsilon=1e-8):\n    preds = torch.exp(log_preds)\n    pred_pos = torch.max(preds > thresh, dim=1)[1]\n    tpos = torch.mul((targs.byte() == pred_pos.byte()), targs.byte())\n    return tpos.sum()/(targs.sum() + epsilon)\n\ndef recall_np(preds, targs, thresh=0.5, epsilon=1e-8):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/(targs.sum() + epsilon)\n\ndef precision(log_preds, targs, thresh=0.5, epsilon=1e-8):\n    preds = torch.exp(log_preds)\n    pred_pos = torch.max(preds > thresh, dim=1)[1]\n    tpos = torch.mul((targs.byte() == pred_pos.byte()), targs.byte())\n    return tpos.sum()/(pred_pos.sum() + epsilon)\n\ndef precision_np(preds, targs, thresh=0.5, epsilon=1e-8):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/(pred_pos.sum() + epsilon)\n\ndef fbeta(log_preds, targs, beta, thresh=0.5, epsilon=1e-8):\n    """"""Calculates the F-beta score (the weighted harmonic mean of precision and recall).\n    This is the micro averaged version where the true positives, false negatives and\n    false positives are calculated globally (as opposed to on a per label basis).\n\n    beta == 1 places equal weight on precision and recall, b < 1 emphasizes precision and\n    beta > 1 favors recall.\n    """"""\n    assert beta > 0, \'beta needs to be greater than 0\'\n    beta2 = beta ** 2\n    rec = recall(log_preds, targs, thresh)\n    prec = precision(log_preds, targs, thresh)\n    return (1 + beta2) * prec * rec / (beta2 * prec + rec + epsilon)\n\ndef fbeta_np(preds, targs, beta, thresh=0.5, epsilon=1e-8):\n    """""" see fbeta """"""\n    assert beta > 0, \'beta needs to be greater than 0\'\n    beta2 = beta ** 2\n    rec = recall_np(preds, targs, thresh)\n    prec = precision_np(preds, targs, thresh)\n    return (1 + beta2) * prec * rec / (beta2 * prec + rec + epsilon)\n\ndef f1(log_preds, targs, thresh=0.5): return fbeta(log_preds, targs, 1, thresh)\ndef f1_np(preds, targs, thresh=0.5): return fbeta_np(preds, targs, 1, thresh)\n'"
old/fastai/model.py,4,"b'# -*- coding: utf-8 -*-\nfrom .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .layer_optimizer import *\nfrom .swa import *\nfrom .fp16 import *\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef cut_model(m, cut):\n    return list(m.children())[:cut] if cut else [m]\n\ndef predict_to_bcolz(m, gen, arr, workers=4):\n    arr.trim(len(arr))\n    lock=threading.Lock()\n    m.eval()\n    for x,*_ in tqdm(gen):\n        y = to_np(m(VV(x)).data)\n        with lock:\n            arr.append(y)\n            arr.flush()\n\ndef num_features(m):\n    c=children(m)\n    if len(c)==0: return None\n    for l in reversed(c):\n        if hasattr(l, \'num_features\'): return l.num_features\n        res = num_features(l)\n        if res is not None: return res\n\ndef torch_item(x): return x.item() if hasattr(x,\'item\') else x[0]\n\nclass Stepper():\n    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n        self.fp16 = fp16\n        self.reset(True)\n        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n        self.loss_scale = loss_scale\n\n    def reset(self, train=True):\n        if train: apply_leaf(self.m, set_train_mode)\n        else: self.m.eval()\n        if hasattr(self.m, \'reset\'):\n            self.m.reset()\n            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n\n    def step(self, xs, y, epoch):\n        xtra = []\n        output = self.m(*xs)\n        if isinstance(output,tuple): output,*xtra = output\n        if self.fp16: self.m.zero_grad()\n        else: self.opt.zero_grad() \n        loss = raw_loss = self.crit(output, y)\n        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n        loss.backward()\n        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n        if self.loss_scale != 1:\n            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n        if self.clip:   # Gradient clipping\n            if IS_TORCH_04: nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n            else:           nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n        if \'wd\' in self.opt.param_groups[0] and self.opt.param_groups[0][\'wd\'] != 0: \n            #Weight decay out of the loss. After the gradient computation but before the step.\n            for group in self.opt.param_groups:\n                lr, wd = group[\'lr\'], group[\'wd\']\n                for p in group[\'params\']:\n                    if p.grad is not None: p.data = p.data.add(-wd * lr, p.data)\n        self.opt.step()\n        if self.fp16: \n            copy_fp32_to_model(self.m, self.fp32_params)\n            torch.cuda.synchronize()\n        return torch_item(raw_loss.data)\n\n    def evaluate(self, xs, y):\n        preds = self.m(*xs)\n        if isinstance(preds,tuple): preds=preds[0]\n        return preds, self.crit(preds, y)\n\ndef set_train_mode(m):\n    if (hasattr(m, \'running_mean\') and (getattr(m,\'bn_freeze\',False)\n              or not getattr(m,\'trainable\',False))): m.eval()\n    elif (getattr(m,\'drop_freeze\',False) and hasattr(m, \'p\')\n          and (\'drop\' in type(m).__name__.lower())): m.eval()\n    else: m.train()\n\ndef fit(model, data, n_epochs, opt, crit, metrics=None, callbacks=None, stepper=Stepper,\n        swa_model=None, swa_start=None, swa_eval_freq=None, visualize=False, **kwargs):\n    """""" Fits a model\n\n    Arguments:\n       model (model): any pytorch module\n           net = to_gpu(net)\n       data (ModelData): see ModelData class and subclasses (can be a list)\n       opts: an optimizer. Example: optim.Adam. \n       If n_epochs is a list, it needs to be the layer_optimizer to get the optimizer as it changes.\n       n_epochs(int or list): number of epochs (or list of number of epochs)\n       crit: loss function to optimize. Example: F.cross_entropy\n    """"""\n\n    seq_first = kwargs.pop(\'seq_first\', False)\n    all_val = kwargs.pop(\'all_val\', False)\n    get_ep_vals = kwargs.pop(\'get_ep_vals\', False)\n    validate_skip = kwargs.pop(\'validate_skip\', 0)\n    metrics = metrics or []\n    callbacks = callbacks or []\n    avg_mom=0.98\n    batch_num,avg_loss=0,0.\n    for cb in callbacks: cb.on_train_begin()\n    names = [""epoch"", ""trn_loss"", ""val_loss""] + [f.__name__ for f in metrics]\n    if swa_model is not None:\n        swa_names = [\'swa_loss\'] + [f\'swa_{f.__name__}\' for f in metrics]\n        names += swa_names\n        # will use this to call evaluate later\n        swa_stepper = stepper(swa_model, None, crit, **kwargs)\n\n    layout = ""{!s:10} "" * len(names)\n    if not isinstance(n_epochs, Iterable): n_epochs=[n_epochs]\n    if not isinstance(data, Iterable): data = [data]\n    if len(data) == 1: data = data * len(n_epochs)\n    for cb in callbacks: cb.on_phase_begin()\n    model_stepper = stepper(model, opt.opt if hasattr(opt,\'opt\') else opt, crit, **kwargs)\n    ep_vals = collections.OrderedDict()\n    tot_epochs = int(np.ceil(np.array(n_epochs).sum()))\n    cnt_phases = np.array([ep * len(dat.trn_dl) for (ep,dat) in zip(n_epochs,data)]).cumsum()\n    phase = 0\n    for epoch in tnrange(tot_epochs, desc=\'Epoch\'):\n        if phase >= len(n_epochs): break #Sometimes cumulated errors make this append.\n        model_stepper.reset(True)\n        cur_data = data[phase]\n        if hasattr(cur_data, \'trn_sampler\'): cur_data.trn_sampler.set_epoch(epoch)\n        if hasattr(cur_data, \'val_sampler\'): cur_data.val_sampler.set_epoch(epoch)\n        num_batch = len(cur_data.trn_dl)\n        t = tqdm(iter(cur_data.trn_dl), leave=False, total=num_batch, miniters=0)\n        if all_val: val_iter = IterBatch(cur_data.val_dl)\n\n        for (*x,y) in t:\n            batch_num += 1\n            for cb in callbacks: cb.on_batch_begin()\n            loss = model_stepper.step(V(x),V(y), epoch)\n            avg_loss = avg_loss * avg_mom + loss * (1-avg_mom)\n            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n            t.set_postfix(loss=debias_loss, refresh=False)\n            stop=False\n            los = debias_loss if not all_val else [debias_loss] + validate_next(model_stepper,metrics, val_iter)\n            for cb in callbacks: stop = stop or cb.on_batch_end(los)\n            if stop: return\n            if batch_num >= cnt_phases[phase]:\n                for cb in callbacks: cb.on_phase_end()\n                phase += 1\n                if phase >= len(n_epochs):\n                    t.close()\n                    break\n                for cb in callbacks: cb.on_phase_begin()\n                if isinstance(opt, LayerOptimizer): model_stepper.opt = opt.opt\n                if cur_data != data[phase]:\n                    t.close()\n                    break\n\n        if not all_val:\n            vals = validate(model_stepper, cur_data.val_dl, metrics, epoch, seq_first=seq_first, validate_skip = validate_skip)\n            stop=False\n            for cb in callbacks: stop = stop or cb.on_epoch_end(vals)\n            if swa_model is not None:\n                if (epoch + 1) >= swa_start and ((epoch + 1 - swa_start) % swa_eval_freq == 0 or epoch == tot_epochs - 1):\n                    fix_batchnorm(swa_model, cur_data.trn_dl)\n                    swa_vals = validate(swa_stepper, cur_data.val_dl, metrics, epoch, validate_skip = validate_skip)\n                    vals += swa_vals\n\n            if epoch > 0: \n                print_stats(epoch, [debias_loss] + vals, visualize, prev_val)\n            else:\n                print(layout.format(*names))\n                print_stats(epoch, [debias_loss] + vals, visualize)\n            prev_val = [debias_loss] + vals\n            ep_vals = append_stats(ep_vals, epoch, [debias_loss] + vals)\n        if stop: break\n    for cb in callbacks: cb.on_train_end()\n    if get_ep_vals: return vals, ep_vals\n    else: return vals\n\ndef append_stats(ep_vals, epoch, values, decimals=6):\n    ep_vals[epoch]=list(np.round(values, decimals))\n    return ep_vals\n\ndef print_stats(epoch, values, visualize, prev_val=[], decimals=6):\n    layout = ""{!s:^10}"" + "" {!s:10}"" * len(values)\n    values = [epoch] + list(np.round(values, decimals))\n    sym = """"\n    if visualize:\n        if epoch == 0:                                             pass        \n        elif values[1] > prev_val[0] and values[2] > prev_val[1]:  sym = "" \xe2\x96\xb3 \xe2\x96\xb3""\n        elif values[1] > prev_val[0] and values[2] < prev_val[1]:  sym = "" \xe2\x96\xb3 \xe2\x96\xbc""            \n        elif values[1] < prev_val[0] and values[2] > prev_val[1]:  sym = "" \xe2\x96\xbc \xe2\x96\xb3""            \n        elif values[1] < prev_val[0] and values[2] < prev_val[1]:  sym = "" \xe2\x96\xbc \xe2\x96\xbc""\n    print(layout.format(*values) + sym)\n\nclass IterBatch():\n    def __init__(self, dl):\n        self.idx = 0\n        self.dl = dl\n        self.iter = iter(dl)\n\n    def __iter__(self): return self\n\n    def next(self):\n        res = next(self.iter)\n        self.idx += 1\n        if self.idx == len(self.dl):\n            self.iter = iter(self.dl)\n            self.idx=0\n        return res\n\ndef validate_next(stepper, metrics, val_iter):\n    """"""Computes the loss on the next minibatch of the validation set.""""""\n    stepper.reset(False)\n    with no_grad_context():\n        (*x,y) = val_iter.next()\n        preds,l = stepper.evaluate(VV(x), VV(y))\n        res = [delistify(to_np(l))]\n        res += [f(datafy(preds), datafy(y)) for f in metrics]\n    stepper.reset(True)\n    return res\n\ndef batch_sz(x, seq_first=False):\n    if is_listy(x): x = x[0]\n    return x.shape[1 if seq_first else 0]\n\ndef validate(stepper, dl, metrics, epoch, seq_first=False, validate_skip = 0):\n    if epoch < validate_skip: return [float(\'nan\')] + [float(\'nan\')] * len(metrics)\n    batch_cnts,loss,res = [],[],[]\n    stepper.reset(False)\n    with no_grad_context():\n        t = tqdm(iter(dl), leave=False, total=len(dl), miniters=0, desc=\'Validation\')\n        for (*x,y) in t:\n            y = VV(y)\n            preds, l = stepper.evaluate(VV(x), y)\n            batch_cnts.append(batch_sz(x, seq_first=seq_first))\n            loss.append(to_np(l))\n            res.append([to_np(f(datafy(preds), datafy(y))) for f in metrics])\n    return [np.average(loss, 0, weights=batch_cnts)[0]] + list(np.average(np.stack(res), 0, weights=batch_cnts))\n\ndef get_prediction(x):\n    if is_listy(x): x=x[0]\n    return x.data\n\ndef predict(m, dl):\n    preda,_ = predict_with_targs_(m, dl)\n    return np.concatenate(preda)\n\ndef predict_batch(m, x):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    return m(VV(x))\n\ndef predict_with_targs_(m, dl):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    res = []\n    for *x,y in iter(dl): res.append([get_prediction(to_np(m(*VV(x)))),to_np(y)])\n    return zip(*res)\n\ndef predict_with_targs(m, dl):\n    preda,targa = predict_with_targs_(m, dl)\n    return np.concatenate(preda), np.concatenate(targa)\n\n# From https://github.com/ncullen93/torchsample\ndef model_summary(m, inputs):\n    def register_hook(module):\n        def hook(module, input, output):\n            class_name = str(module.__class__).split(\'.\')[-1].split(""\'"")[0]\n            module_idx = len(summary)\n\n            m_key = \'%s-%i\' % (class_name, module_idx+1)\n            summary[m_key] = OrderedDict()\n            summary[m_key][\'input_shape\'] = list(input[0].size())\n            summary[m_key][\'input_shape\'][0] = -1\n            if is_listy(output):\n                summary[m_key][\'output_shape\'] = [[-1] + list(o.size())[1:] for o in output]\n            else:\n                summary[m_key][\'output_shape\'] = list(output.size())\n                summary[m_key][\'output_shape\'][0] = -1\n\n            params = 0\n            if hasattr(module, \'weight\'):\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n                summary[m_key][\'trainable\'] = module.weight.requires_grad\n            if hasattr(module, \'bias\') and module.bias is not None:\n                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n            summary[m_key][\'nb_params\'] = params\n\n        if (not isinstance(module, nn.Sequential) and\n           not isinstance(module, nn.ModuleList) and\n           not (module == m)):\n            hooks.append(module.register_forward_hook(hook))\n\n    summary = OrderedDict()\n    hooks = []\n    m.apply(register_hook)\n    xs = [to_gpu(Variable(x)) for x in inputs]\n    m(*xs)\n\n    for h in hooks: h.remove()\n    return summary\n'"
old/fastai/nlp.py,4,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .model import *\nfrom .dataset import *\nfrom .learner import *\nfrom .text import *\nfrom .lm_rnn import *\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.datasets import language_modeling\n\nclass DotProdNB(nn.Module):\n    def __init__(self, nf, ny, w_adj=0.4, r_adj=10):\n        super().__init__()\n        self.w_adj,self.r_adj = w_adj,r_adj\n        self.w = nn.Embedding(nf+1, 1, padding_idx=0)\n        self.w.weight.data.uniform_(-0.1,0.1)\n        self.r = nn.Embedding(nf+1, ny)\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        w = self.w(feat_idx)\n        r = self.r(feat_idx)\n        x = ((w+self.w_adj)*r/self.r_adj).sum(1)\n        return F.softmax(x)\n\nclass SimpleNB(nn.Module):\n    def __init__(self, nf, ny):\n        super().__init__()\n        self.r = nn.Embedding(nf+1, ny, padding_idx=0)\n        self.b = nn.Parameter(torch.zeros(ny,))\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        r = self.r(feat_idx)\n        x = r.sum(1)+self.b\n        return F.softmax(x)\n\nclass BOW_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.l1_loss\n\ndef calc_pr(y_i, x, y, b):\n    idx = np.argwhere((y==y_i)==b)\n    ct = x[idx[:,0]].sum(0)+1\n    tot = ((y==y_i)==b).sum()+1\n    return ct/tot\n\ndef calc_r(y_i, x, y):\n    return np.log(calc_pr(y_i, x, y, True) / calc_pr(y_i, x, y, False))\n\nclass BOW_Dataset(Dataset):\n    def __init__(self, bow, y, max_len):\n        self.bow,self.max_len = bow,max_len\n        self.c = int(y.max())+1\n        self.n,self.vocab_size = bow.shape\n        self.y = one_hot(y,self.c).astype(np.float32)\n        x = self.bow.sign()\n        self.r = np.stack([calc_r(i, x, y).A1 for i in range(self.c)]).T\n\n    def __getitem__(self, i):\n        row = self.bow.getrow(i)\n\n        num_row_entries = row.indices.shape[0]\n        indices = (row.indices + 1).astype(np.int64)\n        data = (row.data).astype(np.int64)\n\n        if num_row_entries < self.max_len:\n            # If short, pad\n            indices = np.pad(indices, (self.max_len - num_row_entries, 0), mode=\'constant\')\n            data = np.pad(data, (self.max_len - num_row_entries, 0), mode=\'constant\')\n        else:\n            # If long, truncate\n            indices, data = indices[-self.max_len:], data[-self.max_len:]\n\n        return indices, data, min(self.max_len, num_row_entries), self.y[i]\n\n    def __len__(self): return len(self.bow.indptr)-1\n\n\nclass TextClassifierData(ModelData):\n    @property\n    def c(self): return self.trn_ds.c\n\n    @property\n    def r(self):\n        return torch.Tensor(np.concatenate([np.zeros((1,self.c)), self.trn_ds.r]))\n\n    def get_model(self, f, **kwargs):\n        m = to_gpu(f(self.trn_ds.vocab_size, self.c, **kwargs))\n        m.r.weight.data = to_gpu(self.r)\n        m.r.weight.requires_grad = False\n        model = BasicModel(m)\n        return BOW_Learner(self, model, metrics=[accuracy_thresh(0.5)], opt_fn=optim.Adam)\n\n    def dotprod_nb_learner(self, **kwargs): return self.get_model(DotProdNB, **kwargs)\n    def nb_learner(self, **kwargs): return self.get_model(SimpleNB, **kwargs)\n\n    @classmethod\n    def from_bow(cls, trn_bow, trn_y, val_bow, val_y, sl):\n        trn_ds = BOW_Dataset(trn_bow, trn_y, sl)\n        val_ds = BOW_Dataset(val_bow, val_y, sl)\n        trn_dl = DataLoader(trn_ds, 64, True)\n        val_dl = DataLoader(val_ds, 64, False)\n        return cls(\'.\', trn_dl, val_dl)\n\n\ndef flip_tensor(x, dim):\n    xsize = x.size()\n    dim = x.dim() + dim if dim < 0 else dim\n    x = x.view(-1, *xsize[dim:])\n    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1,\n                      -1, -1), (\'cpu\',\'cuda\')[x.is_cuda])().long(), :]\n    return x.view(xsize)\n\n\nclass LanguageModelLoader():\n\n    def __init__(self, ds, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        text = sum([o.text for o in ds], [])\n        fld = ds.fields[\'text\']\n        nums = fld.numericalize([text],device=None if torch.cuda.is_available() else -1)\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        return self\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def __next__(self):\n        if self.i >= self.n-1 or self.iter>=len(self): raise StopIteration\n        bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n        seq_len = max(5, int(np.random.normal(bptt, 5)))\n        res = self.get_batch(self.i, seq_len)\n        self.i += seq_len\n        self.iter += 1\n        return res\n\n    def batchify(self, data):\n        nb = data.size(0) // self.bs\n        data = data[:nb*self.bs]\n        data = data.view(self.bs, -1).t().contiguous()\n        if self.backwards: data=flip_tensor(data, 0)\n        return to_gpu(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass ConcatTextDataset(torchtext.data.Dataset):\n    def __init__(self, path, text_field, newline_eos=True, encoding=\'utf-8\', **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n        if os.path.isdir(path): paths=glob(f\'{path}/*.*\')\n        else: paths=[path]\n        for p in paths:\n            for line in open(p, encoding=encoding): text += text_field.preprocess(line)\n            if newline_eos: text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n        super().__init__(examples, fields, **kwargs)\n\n\nclass ConcatTextDatasetFromDataFrames(torchtext.data.Dataset):\n    def __init__(self, df, text_field, col, newline_eos=True, **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n\n        text += text_field.preprocess(df[col].str.cat(sep=\' <eos> \'))\n        if (newline_eos): text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n\n        super().__init__(examples, fields, **kwargs)\n\n    @classmethod\n    def splits(cls, train_df=None, val_df=None, test_df=None, keep_nones=False, **kwargs):\n        res = (\n            cls(train_df, **kwargs),\n            cls(val_df, **kwargs),\n            map_none(test_df, partial(cls, **kwargs)))  # not required\n        return res if keep_nones else tuple(d for d in res if d is not None)\n\n\nclass LanguageModelData():\n    """"""\n    This class provides the entry point for dealing with supported NLP tasks.\n    Usage:\n    1.  Use one of the factory constructors (from_dataframes, from_text_files) to\n        obtain an instance of the class.\n    2.  Use the get_model method to return a RNN_Learner instance (a network suited\n        for NLP tasks), then proceed with training.\n\n        Example:\n            >> TEXT = data.Field(lower=True, tokenize=spacy_tok)\n            >> FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n            >> md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=64, bptt=70, min_freq=10)\n\n            >> em_sz = 200  # size of each embedding vector\n            >> nh = 500     # number of hidden activations per layer\n            >> nl = 3       # number of layers\n\n            >> opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n            >> learner = md.get_model(opt_fn, em_sz, nh, nl,\n                           dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n            >> learner.reg_fn = seq2seq_reg\n            >> learner.clip=0.3\n\n            >> learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n\n    """"""\n    def __init__(self, path, field, trn_ds, val_ds, test_ds, bs, bptt, backwards=False, **kwargs):\n        """""" Constructor for the class. An important thing that happens here is\n            that the field\'s ""build_vocab"" method is invoked, which builds the vocabulary\n            for this NLP model.\n\n            Also, three instances of the LanguageModelLoader are constructed; one each\n            for training data (self.trn_dl), validation data (self.val_dl), and the\n            testing data (self.test_dl)\n\n            Args:\n                path (str): testing path\n                field (Field): torchtext field object\n                trn_ds (Dataset): training dataset\n                val_ds (Dataset): validation dataset\n                test_ds (Dataset): testing dataset\n                bs (int): batch size\n                bptt (int): back propagation through time\n                kwargs: other arguments\n        """"""\n        self.bs = bs\n        self.path = path\n        self.trn_ds = trn_ds; self.val_ds = val_ds; self.test_ds = test_ds\n        if not hasattr(field, \'vocab\'): field.build_vocab(self.trn_ds, **kwargs)\n\n        self.pad_idx = field.vocab.stoi[field.pad_token]\n        self.nt = len(field.vocab)\n\n        factory = lambda ds: LanguageModelLoader(ds, bs, bptt, backwards=backwards)\n        self.trn_dl = factory(self.trn_ds)\n        self.val_dl = factory(self.val_ds)\n        self.test_dl = map_none(self.test_ds, factory)  # not required\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        """""" Method returns a RNN_Learner object, that wraps an instance of the RNN_Encoder module.\n\n        Args:\n            opt_fn (Optimizer): the torch optimizer function to use\n            emb_sz (int): embedding size\n            n_hid (int): number of hidden inputs\n            n_layers (int): number of hidden layers\n            kwargs: other arguments\n\n        Returns:\n            An instance of the RNN_Learner class.\n\n        """"""\n        m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = SingleModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    @classmethod\n    def from_dataframes(cls, path, field, col, train_df, val_df, test_df=None, bs=64, bptt=70, **kwargs):\n        trn_ds, val_ds, test_ds = ConcatTextDatasetFromDataFrames.splits(\n            text_field=field, col=col, train_df=train_df, val_df=val_df, test_df=test_df, keep_nones=True)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n    @classmethod\n    def from_text_files(cls, path, field, train, validation, test=None, bs=64, bptt=70, **kwargs):\n        """""" Method used to instantiate a LanguageModelData object that can be used for a\n            supported nlp task.\n\n        Args:\n            path (str): the absolute path in which temporary model data will be saved\n            field (Field): torchtext field\n            train (str): file location of the training data\n            validation (str): file location of the validation data\n            test (str): file location of the testing data\n            bs (int): batch size to use\n            bptt (int): back propagation through time hyper-parameter\n            kwargs: other arguments\n\n        Returns:\n            a LanguageModelData instance, which most importantly, provides us the datasets for training,\n                validation, and testing\n\n        Note:\n            The train, validation, and test path can be pointed to any file (or folder) that contains a valid\n                text corpus.\n\n        """"""\n        trn_ds, val_ds, test_ds = ConcatTextDataset.splits(\n            path, text_field=field, train=train, validation=validation, test=test)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n\nclass TextDataLoader():\n    def __init__(self, src, x_fld, y_fld):\n        self.src,self.x_fld,self.y_fld = src,x_fld,y_fld\n\n    def __len__(self): return len(self.src)\n\n    def __iter__(self):\n        it = iter(self.src)\n        for i in range(len(self)):\n            b = next(it)\n            yield getattr(b, self.x_fld).data, getattr(b, self.y_fld).data\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n\nclass TextData(ModelData):\n    def create_td(self, it): return TextDataLoader(it, self.text_fld, self.label_fld)\n\n    @classmethod\n    def from_splits(cls, path, splits, bs, text_name=\'text\', label_name=\'label\'):\n        text_fld = splits[0].fields[text_name]\n        label_fld = splits[0].fields[label_name]\n        if hasattr(label_fld, \'build_vocab\'): label_fld.build_vocab(splits[0])\n        iters = torchtext.data.BucketIterator.splits(splits, batch_size=bs)\n        trn_iter,val_iter,test_iter = iters[0],iters[1],None\n        test_dl = None\n        if len(iters) == 3:\n            test_iter = iters[2]\n            test_dl = TextDataLoader(test_iter, text_name, label_name)\n        trn_dl = TextDataLoader(trn_iter, text_name, label_name)\n        val_dl = TextDataLoader(val_iter, text_name, label_name)\n        obj = cls.from_dls(path, trn_dl, val_dl, test_dl)\n        obj.bs = bs\n        obj.pad_idx = text_fld.vocab.stoi[text_fld.pad_token]\n        obj.nt = len(text_fld.vocab)\n        obj.c = (len(label_fld.vocab) if hasattr(label_fld, \'vocab\')\n                 else len(getattr(splits[0][0], label_name)))\n        return obj\n\n    def to_model(self, m, opt_fn):\n        model = TextModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    def get_model(self, opt_fn, max_sl, bptt, emb_sz, n_hid, n_layers, dropout, **kwargs):\n        m = get_rnn_classifier(bptt, max_sl, self.c, self.nt,\n              layers=[emb_sz*3, self.c], drops=[dropout],\n              emb_sz=emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=self.pad_idx, **kwargs)\n        return self.to_model(m, opt_fn)\n\n'"
old/fastai/plots.py,0,"b'from .imports import *\nfrom .torch_imports import *\nfrom sklearn.metrics import confusion_matrix\n\ndef ceildiv(a, b):\n    return -(-a // b)\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None, maintitle=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None:\n        plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else \'none\')\n\n\ndef plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n    """"""Plots images given image files.\n\n    Arguments:\n        im_paths (list): list of paths\n        figsize (tuple): figure size\n        rows (int): number of rows\n        titles (list): list of titles\n        maintitle (string): main title\n    """"""\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(imspaths)):\n        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        img = plt.imread(imspaths[i])\n        plt.imshow(img)\n\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title=\'Confusion matrix\', cmap=plt.cm.Blues, figsize=None):\n    """"""\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    (This function is copied from the scikit docs.)\n    """"""\n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize: cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=""center"", color=""white"" if cm[i, j] > thresh else ""black"")\n\n    plt.tight_layout()\n    plt.ylabel(\'True label\')\n    plt.xlabel(\'Predicted label\')\n\ndef plots_raw(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])\n\ndef load_img_id(ds, idx, path): return np.array(PIL.Image.open(os.path.join(path, ds.fnames[idx])))\n\n\nclass ImageModelResults():\n    """""" Visualize the results of an image model\n\n    Arguments:\n        ds (dataset): a dataset which contains the images\n        log_preds (numpy.ndarray): predictions for the dataset in log scale\n\n    Returns:\n        ImageModelResults\n    """"""\n    def __init__(self, ds, log_preds):\n        """"""Initialize an ImageModelResults class instance""""""\n        self.ds = ds\n        # returns the indices of the maximum value of predictions along axis 1, representing the predicted class\n        # log_preds.shape = (number_of_samples, number_of_classes);\n        # preds.shape = (number_of_samples,)\n        self.preds = np.argmax(log_preds, axis=1)\n        # computes the probabilities\n        self.probs = np.exp(log_preds)\n        # extracts the number of classes\n        self.num_classes = log_preds.shape[1]\n\n    def plot_val_with_title(self, idxs, y):\n        """""" Displays the images and their probabilities of belonging to a certain class\n\n            Arguments:\n                idxs (numpy.ndarray): indexes of the image samples from the dataset\n                y (int): the selected class\n\n            Returns:\n                Plots the images in n rows [rows = n]\n        """"""\n        # if there are any samples to be displayed\n        if len(idxs) > 0:\n            imgs = np.stack([self.ds[x][0] for x in idxs])\n            title_probs = [self.probs[x,y] for x in idxs]\n\n            return plots(self.ds.denorm(imgs), rows=1, titles=title_probs)\n        # if idxs is empty return false\n        else:\n            return False;\n\n    def most_by_mask(self, mask, y, mult):\n        """""" Extracts the first 4 most correct/incorrect indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n                mult (int): sets the ordering; -1 descending, 1 ascending\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        cnt = min(4, len(idxs))\n        return idxs[np.argsort(mult * self.probs[idxs,y])[:cnt]]\n\n    def most_uncertain_by_mask(self, mask, y):\n        """""" Extracts the first 4 most uncertain indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        # the most uncertain samples will have abs(probs-1/num_classes) close to 0;\n        return idxs[np.argsort(np.abs(self.probs[idxs,y]-(1/self.num_classes)))[:4]]\n\n    def most_by_correct(self, y, is_correct):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        # mult=-1 when the is_correct flag is true -> when we want to display the most correct classes we will make a descending sorting (argsort) because we want that the biggest probabilities to be displayed first.\n        # When is_correct is false, we want to display the most incorrect classes, so we want an ascending sorting since our interest is in the smallest probabilities.\n        mult = -1 if is_correct==True else 1\n        return self.most_by_mask(((self.preds == self.ds.y)==is_correct)\n                                 & (self.ds.y == y), y, mult)\n\n    def plot_by_correct(self, y, is_correct):\n        """""" Plots the images which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n        """"""\n        return self.plot_val_with_title(self.most_by_correct(y, is_correct), y)\n\n    def most_by_uncertain(self, y):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and have probabilities nearest to 1/number_of_classes (eg. 0.5 for 2 classes, 0.33 for 3 classes) for the selected class.\n\n            Arguments:\n                y (int): the selected class\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        return self.most_uncertain_by_mask((self.ds.y == y), y)\n\n    def plot_most_correct(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most correct.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, True)\n    def plot_most_incorrect(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most incorrect.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, False)\n    def plot_most_uncertain(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most uncertain i.e have probabilities nearest to 1/number_of_classes.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_val_with_title(self.most_by_uncertain(y), y)\n'"
old/fastai/rnn_reg.py,16,"b'from .torch_imports import *\nfrom .core import *\nfrom functools import wraps\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef dropout_mask(x, sz, dropout):\n    """""" Applies a dropout mask whose size is determined by passed argument \'sz\'.\n    Args:\n        x (nn.Variable): A torch Variable object\n        sz (tuple(int, int, int)): The expected size of the new tensor\n        dropout (float): The dropout fraction to apply\n\n    This method uses the bernoulli distribution to decide which activations to keep.\n    Additionally, the sampled activations is rescaled is using the factor 1/(1 - dropout).\n\n    In the example given below, one can see that approximately .8 fraction of the\n    returned tensors are zero. Rescaling with the factor 1/(1 - 0.8) returns a tensor\n    with 5\'s in the unit places.\n\n    The official link to the pytorch bernoulli function is here:\n        http://pytorch.org/docs/master/torch.html#torch.bernoulli\n\n    Examples:\n        >>> a_Var = torch.autograd.Variable(torch.Tensor(2, 3, 4).uniform_(0, 1), requires_grad=False)\n        >>> a_Var\n            Variable containing:\n            (0 ,.,.) =\n              0.6890  0.5412  0.4303  0.8918\n              0.3871  0.7944  0.0791  0.5979\n              0.4575  0.7036  0.6186  0.7217\n            (1 ,.,.) =\n              0.8354  0.1690  0.1734  0.8099\n              0.6002  0.2602  0.7907  0.4446\n              0.5877  0.7464  0.4257  0.3386\n            [torch.FloatTensor of size 2x3x4]\n        >>> a_mask = dropout_mask(a_Var.data, (1,a_Var.size(1),a_Var.size(2)), dropout=0.8)\n        >>> a_mask\n            (0 ,.,.) =\n              0  5  0  0\n              0  0  0  5\n              5  0  5  0\n            [torch.FloatTensor of size 1x3x4]\n    """"""\n    return x.new(*sz).bernoulli_(1-dropout)/(1-dropout)\n\n\nclass LockedDropout(nn.Module):\n    def __init__(self, p=0.5):\n        super().__init__()\n        self.p=p\n\n    def forward(self, x):\n        if not self.training or not self.p: return x\n        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n        return Variable(m, requires_grad=False) * x\n\n\nclass WeightDrop(torch.nn.Module):\n    """"""A custom torch layer that serves as a wrapper on another torch layer.\n    Primarily responsible for updating the weights in the wrapped module based\n    on a specified dropout.\n    """"""\n    def __init__(self, module, dropout, weights=[\'weight_hh_l0\']):\n        """""" Default constructor for the WeightDrop module\n\n        Args:\n            module (torch.nn.Module): A pytorch layer being wrapped\n            dropout (float): a dropout value to apply\n            weights (list(str)): the parameters of the wrapped **module**\n                which should be fractionally dropped.\n        """"""\n        super().__init__()\n        self.module,self.weights,self.dropout = module,weights,dropout\n        self._setup()\n\n    def _setup(self):\n        """""" for each string defined in self.weights, the corresponding\n        attribute in the wrapped module is referenced, then deleted, and subsequently\n        registered as a new parameter with a slightly modified name.\n\n        Args:\n            None\n\n         Returns:\n             None\n        """"""\n        if isinstance(self.module, torch.nn.RNNBase): self.module.flatten_parameters = noop\n        for name_w in self.weights:\n            w = getattr(self.module, name_w)\n            del self.module._parameters[name_w]\n            self.module.register_parameter(name_w + \'_raw\', nn.Parameter(w.data))\n\n\n    def _setweights(self):\n        """""" Uses pytorch\'s built-in dropout function to apply dropout to the parameters of\n        the wrapped module.\n\n        Args:\n            None\n        Returns:\n            None\n        """"""\n        for name_w in self.weights:\n            raw_w = getattr(self.module, name_w + \'_raw\')\n            w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n            if hasattr(self.module, name_w):\n                delattr(self.module, name_w)\n            setattr(self.module, name_w, w)\n\n    def forward(self, *args):\n        """""" updates weights and delegates the propagation of the tensor to the wrapped module\'s\n        forward method\n\n        Args:\n            *args: supplied arguments\n\n        Returns:\n            tensor obtained by running the forward method on the wrapped module.\n        """"""\n        self._setweights()\n        return self.module.forward(*args)\n\nclass EmbeddingDropout(nn.Module):\n\n    """""" Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\n    Uses the dropout_mask custom layer to achieve this.\n\n    Args:\n        embed (torch.nn.Embedding): An embedding torch layer\n        words (torch.nn.Variable): A torch variable\n        dropout (float): dropout fraction to apply to the embedding weights\n        scale (float): additional scaling to apply to the modified embedding weights\n\n    Returns:\n        tensor of size: (batch_size x seq_length x embedding_size)\n\n    Example:\n\n    >> embed = torch.nn.Embedding(10,3)\n    >> words = Variable(torch.LongTensor([[1,2,4,5] ,[4,3,2,9]]))\n    >> words.size()\n        (2,4)\n    >> embed_dropout_layer = EmbeddingDropout(embed)\n    >> dropout_out_ = embed_dropout_layer(embed, words, dropout=0.40)\n    >> dropout_out_\n        Variable containing:\n        (0 ,.,.) =\n          1.2549  1.8230  1.9367\n          0.0000 -0.0000  0.0000\n          2.2540 -0.1299  1.5448\n          0.0000 -0.0000 -0.0000\n\n        (1 ,.,.) =\n          2.2540 -0.1299  1.5448\n         -4.0457  2.4815 -0.2897\n          0.0000 -0.0000  0.0000\n          1.8796 -0.4022  3.8773\n        [torch.FloatTensor of size 2x4x3]\n    """"""\n\n    def __init__(self, embed):\n        super().__init__()\n        self.embed = embed\n\n    def forward(self, words, dropout=0.1, scale=None):\n        if dropout:\n            size = (self.embed.weight.size(0),1)\n            mask = Variable(dropout_mask(self.embed.weight.data, size, dropout))\n            masked_embed_weight = mask * self.embed.weight\n        else: masked_embed_weight = self.embed.weight\n\n        if scale: masked_embed_weight = scale * masked_embed_weight\n\n        padding_idx = self.embed.padding_idx\n        if padding_idx is None: padding_idx = -1\n\n        \n        if IS_TORCH_04:\n            X = F.embedding(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n        else:\n            X = self.embed._backend.Embedding.apply(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n\n        return X\n'"
old/fastai/rnn_train.py,2,b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom .core import *\n\n'
old/fastai/set_spawn.py,0,"b""from multiprocessing import set_start_method\nset_start_method('spawn')\n\n"""
old/fastai/sgdr.py,0,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\nfrom timeit import default_timer as timer\nimport copy\nimport math\n\n\nclass Callback:\n    \'\'\'\n    An abstract class that all callback(e.g., LossRecorder) classes extends from. \n    Must be extended before usage.\n    \'\'\'\n    def on_train_begin(self): pass\n    def on_batch_begin(self): pass\n    def on_phase_begin(self): pass\n    def on_epoch_end(self, metrics): pass\n    def on_phase_end(self): pass\n    def on_batch_end(self, metrics): pass\n    def on_train_end(self): pass\n\n# Useful for maintaining status of a long-running job.\n# \n# Usage:\n# learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\nclass LoggingCallback(Callback):\n    \'\'\'\n    A class useful for maintaining status of a long-running job.\n    e.g.: learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\n    \'\'\'\n    def __init__(self, save_path):\n        super().__init__()\n        self.save_path=save_path\n    def on_train_begin(self):\n        self.batch = 0\n        self.epoch = 0\n        self.phase = 0\n        self.f = open(self.save_path, ""a"", 1)\n        self.log(""\\ton_train_begin"")\n    def on_batch_begin(self):\n        self.log(str(self.batch)+""\\ton_batch_begin"")\n    def on_phase_begin(self):\n        self.log(str(self.phase)+""\\ton_phase_begin"")\n    def on_epoch_end(self, metrics):\n        self.log(str(self.epoch)+""\\ton_epoch_end: ""+str(metrics))\n        self.epoch += 1\n    def on_phase_end(self):\n        self.log(str(self.phase)+""\\ton_phase_end"")\n        self.phase+=1\n    def on_batch_end(self, metrics):\n        self.log(str(self.batch)+""\\ton_batch_end: ""+str(metrics))\n        self.batch += 1\n    def on_train_end(self):\n        self.log(""\\ton_train_end"")\n        self.f.close()\n    def log(self, string):\n        self.f.write(time.strftime(""%Y-%m-%dT%H:%M:%S"")+""\\t""+string+""\\n"")\n        \nclass LossRecorder(Callback):\n    \'\'\'\n    Saves and displays loss functions and other metrics. \n    Default sched when none is specified in a learner. \n    \'\'\'\n    def __init__(self, layer_opt, save_path=\'\', record_mom=False, metrics=[]):\n        super().__init__()\n        self.layer_opt=layer_opt\n        self.init_lrs=np.array(layer_opt.lrs)\n        self.save_path, self.record_mom, self.metrics = save_path, record_mom, metrics\n\n    def on_train_begin(self):\n        self.losses,self.lrs,self.iterations,self.epochs,self.times = [],[],[],[],[]\n        self.start_at = timer()\n        self.val_losses, self.rec_metrics = [], []\n        if self.record_mom:\n            self.momentums = []\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n        self.epochs.append(self.iteration)\n        self.times.append(timer() - self.start_at)\n        self.save_metrics(metrics)\n\n    def on_batch_end(self, loss):\n        self.iteration += 1\n        self.lrs.append(self.layer_opt.lr)\n        self.iterations.append(self.iteration)\n        if isinstance(loss, list):\n            self.losses.append(loss[0])\n            self.save_metrics(loss[1:])\n        else: self.losses.append(loss)\n        if self.record_mom: self.momentums.append(self.layer_opt.mom)\n\n    def save_metrics(self,vals):\n        self.val_losses.append(delistify(vals[0]))\n        if len(vals) > 2: self.rec_metrics.append(vals[1:])\n        elif len(vals) == 2: self.rec_metrics.append(vals[1])\n\n    def plot_loss(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        plots loss function as function of iterations. \n        When used in Jupyternotebook, plot will be displayed in notebook. Else, plot will be displayed in console and both plot and loss are saved in save_path. \n        \'\'\'\n        if not in_ipynb(): plt.switch_backend(\'agg\')\n        plt.plot(self.iterations[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'loss_plot.png\'))\n            np.save(os.path.join(self.save_path, \'losses.npy\'), self.losses[10:])\n\n    def plot_lr(self):\n        \'\'\'Plots learning rate in jupyter notebook or console, depending on the enviroment of the learner.\'\'\'\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        if self.record_mom:\n            fig, axs = plt.subplots(1,2,figsize=(12,4))\n            for i in range(0,2): axs[i].set_xlabel(\'iterations\')\n            axs[0].set_ylabel(\'learning rate\')\n            axs[1].set_ylabel(\'momentum\')\n            axs[0].plot(self.iterations,self.lrs)\n            axs[1].plot(self.iterations,self.momentums)   \n        else:\n            plt.xlabel(""iterations"")\n            plt.ylabel(""learning rate"")\n            plt.plot(self.iterations, self.lrs)\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n\n\nclass LR_Updater(LossRecorder):\n    \'\'\'\n    Abstract class where all Learning Rate updaters inherit from. (e.g., CirularLR)\n    Calculates and updates new learning rate and momentum at the end of each batch. \n    Have to be extended. \n    \'\'\'\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n\n    def on_batch_end(self, loss):\n        res = super().on_batch_end(loss)\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n        return res\n\n    def update_lr(self):\n        new_lrs = self.calc_lr(self.init_lrs)\n        self.layer_opt.set_lrs(new_lrs)\n    \n    def update_mom(self):\n        new_mom = self.calc_mom()\n        self.layer_opt.set_mom(new_mom)\n\n    @abstractmethod\n    def calc_lr(self, init_lrs): raise NotImplementedError\n    \n    @abstractmethod\n    def calc_mom(self): raise NotImplementedError\n\n\nclass LR_Finder(LR_Updater):\n    \'\'\'\n    Helps you find an optimal learning rate for a model, as per suggetion of 2015 CLR paper. \n    Learning rate is increased in linear or log scale, depending on user input, and the result of the loss funciton is retained and can be plotted later. \n    \'\'\'\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics = []):\n        self.linear, self.stop_dv = linear, True\n        ratio = end_lr/layer_opt.lr\n        self.lr_mult = (ratio/nb) if linear else ratio**(1/nb)\n        super().__init__(layer_opt,metrics=metrics)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.best=1e9\n\n    def calc_lr(self, init_lrs):\n        mult = self.lr_mult*self.iteration if self.linear else self.lr_mult**self.iteration\n        return init_lrs * mult\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_dv and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        return super().on_batch_end(metrics)\n\n    def plot(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        Plots the loss function with respect to learning rate, in log scale. \n        \'\'\'\n        plt.ylabel(""validation loss"")\n        plt.xlabel(""learning rate (log scale)"")\n        plt.plot(self.lrs[n_skip:-(n_skip_end+1)], self.losses[n_skip:-(n_skip_end+1)])\n        plt.xscale(\'log\')\n\nclass LR_Finder2(LR_Finder):\n    """"""\n        A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n    """"""\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics=[], stop_dv=True):\n        self.nb, self.metrics = nb, metrics\n        super().__init__(layer_opt, nb, end_lr, linear, metrics)\n        self.stop_dv = stop_dv\n\n    def on_batch_end(self, loss):\n        if self.iteration == self.nb:\n            return True\n        return super().on_batch_end(loss)\n\n    def plot(self, n_skip=10, n_skip_end=5, smoothed=True):\n        if self.metrics is None: self.metrics = []\n        n_plots = len(self.metrics)+2\n        fig, axs = plt.subplots(n_plots,figsize=(6,4*n_plots))\n        for i in range(0,n_plots): axs[i].set_xlabel(\'learning rate\')\n        axs[0].set_ylabel(\'training loss\')\n        axs[1].set_ylabel(\'validation loss\')\n        for i,m in enumerate(self.metrics): \n            axs[i+2].set_ylabel(m.__name__)\n            if len(self.metrics) == 1:\n                values = self.rec_metrics\n            else:\n                values = [rec[i] for rec in self.rec_metrics]\n            if smoothed: values = smooth_curve(values,0.98)\n            axs[i+2].plot(self.lrs[n_skip:-n_skip_end], values[n_skip:-n_skip_end])\n        plt_val_l = smooth_curve(self.val_losses, 0.98) if smoothed else self.val_losses\n        axs[0].plot(self.lrs[n_skip:-n_skip_end],self.losses[n_skip:-n_skip_end])\n        axs[1].plot(self.lrs[n_skip:-n_skip_end],plt_val_l[n_skip:-n_skip_end])\n\nclass CosAnneal(LR_Updater):\n    \'\'\' Learning rate scheduler that implements a cosine annealation schedule. \'\'\'\n    def __init__(self, layer_opt, nb, on_cycle_end=None, cycle_mult=1):\n        self.nb,self.on_cycle_end,self.cycle_mult = nb,on_cycle_end,cycle_mult\n        super().__init__(layer_opt)\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.iteration<self.nb/20:\n            self.cycle_iter += 1\n            return init_lrs/100.\n\n        cos_out = np.cos(np.pi*(self.cycle_iter)/self.nb) + 1\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            self.nb *= self.cycle_mult\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return init_lrs / 2 * cos_out\n\n\nclass CircularLR(LR_Updater):\n    \'\'\'\n    A learning rate updater that implements the CircularLearningRate (CLR) scheme. \n    Learning rate is increased then decreased linearly. \n    \'\'\'\n    def __init__(self, layer_opt, nb, div=4, cut_div=8, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.cut_div,self.on_cycle_end = nb,div,cut_div,on_cycle_end\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = 1 - (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = self.cycle_iter/cut_pt\n        res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n    \n    def calc_mom(self):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = 1 - self.cycle_iter/cut_pt\n        res = self.moms[1] + pct * (self.moms[0] - self.moms[1])\n        return res\n\nclass CircularLR_beta(LR_Updater):\n    def __init__(self, layer_opt, nb, div=10, pct=10, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.pct,self.on_cycle_end = nb,div,pct,on_cycle_end\n        self.cycle_nb = int(nb * (1-pct/100) / 2)\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.cycle_iter>2 * self.cycle_nb:\n            pct = (self.cycle_iter - 2*self.cycle_nb)/(self.nb - 2*self.cycle_nb)\n            res = init_lrs * (1 + (pct * (1-100)/100)) / self.div\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n\n    def calc_mom(self):\n        if self.cycle_iter>2*self.cycle_nb:\n            res = self.moms[0]\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        return res\n\n\nclass SaveBestModel(LossRecorder):\n    \n    """""" Save weights of the best model based during training.\n        If metrics are provided, the first metric in the list is used to\n        find the best model. \n        If no metrics are provided, the loss is used.\n        \n        Args:\n            model: the fastai model\n            lr: indicate to use test images; otherwise use validation images\n            name: the name of filename of the weights without \'.h5\'\n        \n        Usage:\n            Briefly, you have your model \'learn\' variable and call fit.\n            >>> learn.fit(lr, 2, cycle_len=2, cycle_mult=1, best_save_name=\'mybestmodel\')\n            ....\n            >>> learn.load(\'mybestmodel\')\n            \n            For more details see http://forums.fast.ai/t/a-code-snippet-to-save-the-best-model-during-training/12066\n \n    """"""\n    def __init__(self, model, layer_opt, metrics, name=\'best_model\'):\n        super().__init__(layer_opt)\n        self.name = name\n        self.model = model\n        self.best_loss = None\n        self.best_acc = None\n        self.save_method = self.save_when_only_loss if metrics==None else self.save_when_acc\n        \n    def save_when_only_loss(self, metrics):\n        loss = metrics[0]\n        if self.best_loss == None or loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n    \n    def save_when_acc(self, metrics):\n        loss, acc = metrics[0], metrics[1]\n        if self.best_acc == None or acc > self.best_acc:\n            self.best_acc = acc\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        elif acc == self.best_acc and  loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        \n    def on_epoch_end(self, metrics):\n        super().on_epoch_end(metrics)\n        if math.isnan(metrics[0]): return\n        self.save_method(metrics)\n\n\nclass WeightDecaySchedule(Callback):\n    def __init__(self, layer_opt, batch_per_epoch, cycle_len, cycle_mult, n_cycles, norm_wds=False, wds_sched_mult=None):\n        """"""\n        Implements the weight decay schedule as mentioned in https://arxiv.org/abs/1711.05101\n\n        :param layer_opt: The LayerOptimizer\n        :param batch_per_epoch: Num batches in 1 epoch\n        :param cycle_len: Num epochs in initial cycle. Subsequent cycle_len = previous cycle_len * cycle_mult\n        :param cycle_mult: Cycle multiplier\n        :param n_cycles: Number of cycles to be executed\n        """"""\n        super().__init__()\n\n        self.layer_opt = layer_opt\n        self.batch_per_epoch = batch_per_epoch\n        self.init_wds = np.array(layer_opt.wds)  # Weights as set by user\n        self.init_lrs = np.array(layer_opt.lrs)  # Learning rates as set by user\n        self.new_wds = None                      # Holds the new weight decay factors, calculated in on_batch_begin()\n        self.iteration = 0\n        self.epoch = 0\n        self.wds_sched_mult = wds_sched_mult\n        self.norm_wds = norm_wds\n        self.wds_history = list()\n\n        # Pre calculating the number of epochs in the cycle of current running epoch\n        self.epoch_to_num_cycles, i = dict(), 0\n        for cycle in range(n_cycles):\n            for _ in range(cycle_len):\n                self.epoch_to_num_cycles[i] = cycle_len\n                i += 1\n            cycle_len *= cycle_mult\n\n    def on_train_begin(self):\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_batch_begin(self):\n        # Prepare for decay of weights\n\n        # Default weight decay (as provided by user)\n        wdn = self.init_wds\n\n        # Weight decay multiplier (The \'eta\' in the paper). Optional.\n        wdm = 1.0\n        if self.wds_sched_mult is not None:\n            wdm = self.wds_sched_mult(self)\n\n        # Weight decay normalized. Optional.\n        if self.norm_wds:\n            wdn = wdn / np.sqrt(self.batch_per_epoch * self.epoch_to_num_cycles[self.epoch])\n\n        # Final wds\n        self.new_wds = wdm * wdn\n\n        # Set weight_decay with zeros so that it is not applied in Adam, we will apply it outside in on_batch_end()\n        self.layer_opt.set_wds_out(self.new_wds)\n        # We have to save the existing weights before the optimizer changes the values\n        self.iteration += 1\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n\nclass DecayType(IntEnum):\n    \'\'\' Data class, each decay type is assigned a number. \'\'\'\n    NO = 1\n    LINEAR = 2\n    COSINE = 3\n    EXPONENTIAL = 4\n    POLYNOMIAL = 5\n\nclass DecayScheduler():\n    \'\'\'Given initial and endvalue, this class generates the next value depending on decay type and number of iterations. (by calling next_val().) \'\'\'\n\n    def __init__(self, dec_type, num_it, start_val, end_val=None, extra=None):\n        self.dec_type, self.nb, self.start_val, self.end_val, self.extra = dec_type, num_it, start_val, end_val, extra\n        self.it = 0\n        if self.end_val is None and not (self.dec_type in [1,4]): self.end_val = 0\n    \n    def next_val(self):\n        self.it += 1\n        if self.dec_type == DecayType.NO:\n            return self.start_val\n        elif self.dec_type == DecayType.LINEAR:\n            pct = self.it/self.nb\n            return self.start_val + pct * (self.end_val-self.start_val)\n        elif self.dec_type == DecayType.COSINE:\n            cos_out = np.cos(np.pi*(self.it)/self.nb) + 1\n            return self.end_val + (self.start_val-self.end_val) / 2 * cos_out\n        elif self.dec_type == DecayType.EXPONENTIAL:\n            ratio = self.end_val / self.start_val\n            return self.start_val * (ratio **  (self.it/self.nb))\n        elif self.dec_type == DecayType.POLYNOMIAL:\n            return self.end_val + (self.start_val-self.end_val) * (1 - self.it/self.nb)**self.extra\n        \n\nclass TrainingPhase():\n    \'\'\'\n    Object with training information for each phase, when multiple phases are involved during training.  \n    Used in fit_opt_sched in learner.py\n    \'\'\'\n    def __init__(self, epochs=1, opt_fn=optim.SGD, lr=1e-2, lr_decay=DecayType.NO, momentum=0.9,\n                momentum_decay=DecayType.NO, beta=None, wds=None, wd_loss=True):\n        """"""\n        Creates an object containing all the relevant informations for one part of a model training.\n\n        Args\n        epochs: number of epochs to train like this\n        opt_fn: an optimizer (example optim.Adam)\n        lr: one learning rate or a tuple of the form (start_lr,end_lr)\n          each of those can be a list/numpy array for differential learning rates\n        lr_decay: a DecayType object specifying how the learning rate should change\n        momentum: one momentum (or beta1 in case of Adam), or a tuple of the form (start_mom,end_mom)\n        momentum_decay: a DecayType object specifying how the momentum should change\n        beta: beta2 parameter of Adam or alpha parameter of RMSProp\n        wds: weight decay (can be an array for differential wds)\n        """"""\n        self.epochs, self.opt_fn, self.lr, self.momentum, self.beta, self.wds = epochs, opt_fn, lr, momentum, beta, wds\n        if isinstance(lr_decay,tuple): self.lr_decay, self.extra_lr = lr_decay\n        else: self.lr_decay, self.extra_lr = lr_decay, None\n        if isinstance(momentum_decay,tuple): self.mom_decay, self.extra_mom = momentum_decay\n        else: self.mom_decay, self.extra_mom = momentum_decay, None\n        self.wd_loss = wd_loss\n\n    def phase_begin(self, layer_opt, nb_batches):\n        self.layer_opt = layer_opt\n        if isinstance(self.lr, tuple): start_lr,end_lr = self.lr\n        else: start_lr, end_lr = self.lr, None\n        self.lr_sched = DecayScheduler(self.lr_decay, nb_batches * self.epochs, start_lr, end_lr, extra=self.extra_lr)\n        if isinstance(self.momentum, tuple): start_mom,end_mom = self.momentum\n        else: start_mom, end_mom = self.momentum, None\n        self.mom_sched = DecayScheduler(self.mom_decay, nb_batches * self.epochs, start_mom, end_mom, extra=self.extra_mom)\n        self.layer_opt.set_opt_fn(self.opt_fn)\n        self.layer_opt.set_lrs(start_lr)\n        self.layer_opt.set_mom(start_mom)\n        if self.beta is not None: self.layer_opt.set_beta(self.beta)\n        if self.wds is not None:\n            if self.wd_loss: self.layer_opt.set_wds(self.wds)\n            else: self.layer_opt.set_wds_out(self.wds)\n    \n    def update(self):\n        new_lr, new_mom = self.lr_sched.next_val(), self.mom_sched.next_val()\n        self.layer_opt.set_lrs(new_lr)\n        self.layer_opt.set_mom(new_mom)\n    \n\nclass OptimScheduler(LossRecorder):\n    \'\'\'Learning rate Scheduler for training involving multiple phases.\'\'\'\n\n    def __init__(self, layer_opt, phases, nb_batches, stop_div = False):\n        self.phases, self.nb_batches, self.stop_div = phases, nb_batches, stop_div\n        super().__init__(layer_opt, record_mom=True)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.phase,self.best=0,1e9\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_div and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        super().on_batch_end(metrics)\n        self.phases[self.phase].update()\n    \n    def on_phase_begin(self):\n        self.phases[self.phase].phase_begin(self.layer_opt, self.nb_batches[self.phase])\n\n    def on_phase_end(self):\n        self.phase += 1\n\n    def plot_lr(self, show_text=True, show_moms=True):\n        """"""Plots the lr rate/momentum schedule""""""\n        phase_limits = [0]\n        for nb_batch, phase in zip(self.nb_batches, self.phases):\n            phase_limits.append(phase_limits[-1] + nb_batch * phase.epochs)\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        np_plts = 2 if show_moms else 1\n        fig, axs = plt.subplots(1,np_plts,figsize=(6*np_plts,4))\n        if not show_moms: axs = [axs]\n        for i in range(np_plts): axs[i].set_xlabel(\'iterations\')\n        axs[0].set_ylabel(\'learning rate\')\n        axs[0].plot(self.iterations,self.lrs)\n        if show_moms:\n            axs[1].set_ylabel(\'momentum\')\n            axs[1].plot(self.iterations,self.momentums)\n        if show_text:   \n            for i, phase in enumerate(self.phases):\n                text = phase.opt_fn.__name__\n                if phase.wds is not None: text+=\'\\nwds=\'+str(phase.wds)\n                if phase.beta is not None: text+=\'\\nbeta=\'+str(phase.beta)\n                for k in range(np_plts):\n                    if i < len(self.phases)-1:\n                        draw_line(axs[k], phase_limits[i+1])\n                    draw_text(axs[k], (phase_limits[i]+phase_limits[i+1])/2, text) \n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n    \n    def plot(self, n_skip=10, n_skip_end=5, linear=None):\n        if linear is None: linear = self.phases[-1].lr_decay == DecayType.LINEAR\n        plt.ylabel(""loss"")\n        plt.plot(self.lrs[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if linear: plt.xlabel(""learning rate"")\n        else:\n            plt.xlabel(""learning rate (log scale)"")\n            plt.xscale(\'log\')\n\ndef draw_line(ax,x):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.plot([x,x],[ymin,ymax], color=\'red\', linestyle=\'dashed\')\n\ndef draw_text(ax,x, text):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.text(x,(ymin+ymax)/2,text, horizontalalignment=\'center\', verticalalignment=\'center\', fontsize=14, alpha=0.5)\n\ndef smooth_curve(vals, beta):\n    avg_val = 0\n    smoothed = []\n    for (i,v) in enumerate(vals):\n        avg_val = beta * avg_val + (1-beta) * v\n        smoothed.append(avg_val/(1-beta**(i+1)))\n    return smoothed\n'"
old/fastai/structured.py,0,"b'from .imports import *\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.impute._base import SimpleImputer as Imputer\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\ndef set_plot_sizes(sml, med, big):\n    plt.rc(\'font\', size=sml)          # controls default text sizes\n    plt.rc(\'axes\', titlesize=sml)     # fontsize of the axes title\n    plt.rc(\'axes\', labelsize=med)    # fontsize of the x and y labels\n    plt.rc(\'xtick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'ytick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'legend\', fontsize=sml)    # legend fontsize\n    plt.rc(\'figure\', titlesize=big)  # fontsize of the figure title\n\ndef parallel_trees(m, fn, n_jobs=8):\n        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    """""" Draws a representation of a random forest in IPython.\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    """"""\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub(\'Tree {\',\n       f\'Tree {{ size={size}; ratio={ratio}\', s)))\n\ndef combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = (\'<M8[Y]\', \'<m8[M]\', \'<m8[D]\', \'<m8[W]\', \'<m8[h]\',\n             \'<m8[m]\', \'<m8[s]\', \'<m8[ms]\', \'<m8[us]\', \'<m8[ns]\')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\ndef get_sample(df,n):\n    """""" Gets a random sample of n rows from df, without replacement.\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    >>> get_sample(df, 2)\n       col1 col2\n    1     2    b\n    2     3    a\n    """"""\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef add_datepart(df, fldnames, drop=True, time=False, errors=""raise""):\t\n    """"""add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string or list of strings that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({ \'A\' : pd.to_datetime([\'3/11/2000\', \'3/12/2000\', \'3/13/2000\'], infer_datetime_format=False) })\n    >>> df\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n    >>> add_datepart(df, \'A\')\n    >>> df\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    >>>df2 = pd.DataFrame({\'start_date\' : pd.to_datetime([\'3/11/2000\',\'3/13/2000\',\'3/15/2000\']),\n                            \'end_date\':pd.to_datetime([\'3/17/2000\',\'3/18/2000\',\'4/1/2000\'],infer_datetime_format=True)})\n    >>>df2\n        start_date\tend_date    \n    0\t2000-03-11\t2000-03-17\n    1\t2000-03-13\t2000-03-18\n    2\t2000-03-15\t2000-04-01\n    >>>add_datepart(df2,[\'start_date\',\'end_date\'])\n    >>>df2\n    \tstart_Year\tstart_Month\tstart_Week\tstart_Day\tstart_Dayofweek\tstart_Dayofyear\tstart_Is_month_end\tstart_Is_month_start\tstart_Is_quarter_end\tstart_Is_quarter_start\tstart_Is_year_end\tstart_Is_year_start\tstart_Elapsed\tend_Year\tend_Month\tend_Week\tend_Day\tend_Dayofweek\tend_Dayofyear\tend_Is_month_end\tend_Is_month_start\tend_Is_quarter_end\tend_Is_quarter_start\tend_Is_year_end\tend_Is_year_start\tend_Elapsed\n    0\t2000\t    3\t        10\t        11\t        5\t            71\t            False\t            False\t                False\t                False\t                False\t            False\t            952732800\t    2000\t    3\t        11\t        17\t    4\t            77\t            False\t            False\t            False\t            False\t                False\t        False\t            953251200\n    1\t2000\t    3\t        11\t        13\t        0\t            73\t            False\t            False\t                False\t                False               \tFalse           \tFalse           \t952905600     \t2000       \t3\t        11      \t18  \t5           \t78          \tFalse\t            False           \tFalse           \tFalse               \tFalse          \tFalse           \t953337600\n    2\t2000\t    3\t        11\t        15\t        2           \t75          \tFalse           \tFalse               \tFalse               \tFalse               \tFalse               False           \t953078400      \t2000    \t4          \t13      \t1   \t5           \t92          \tFalse           \tTrue            \tFalse           \tTrue                \tFalse          \tFalse           \t954547200\n    """"""\n    if isinstance(fldnames,str): \n        fldnames = [fldnames]\n    for fldname in fldnames:\n        fld = df[fldname]\n        fld_dtype = fld.dtype\n        if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n            fld_dtype = np.datetime64\n\n        if not np.issubdtype(fld_dtype, np.datetime64):\n            df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True, errors=errors)\n        targ_pre = re.sub(\'[Dd]ate$\', \'\', fldname)\n        attr = [\'Year\', \'Month\', \'Week\', \'Day\', \'Dayofweek\', \'Dayofyear\',\n                \'Is_month_end\', \'Is_month_start\', \'Is_quarter_end\', \'Is_quarter_start\', \'Is_year_end\', \'Is_year_start\']\n        if time: attr = attr + [\'Hour\', \'Minute\', \'Second\']\n        for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n        df[targ_pre + \'Elapsed\'] = fld.astype(np.int64) // 10 ** 9\n        if drop: df.drop(fldname, axis=1, inplace=True)\n\ndef is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n\ndef train_cats(df):\n    """"""Change any columns of strings in a panda\'s dataframe to a column of\n    categorical values. This applies the changes inplace.\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    note the type of col2 is string\n    >>> train_cats(df)\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    now the type of col2 is category\n    """"""\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype(\'category\').cat.as_ordered()\n\ndef apply_cats(df, trn):\n    """"""Changes any columns of strings in df into categorical variables using trn as\n    a template for the category codes.\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values. The category codes are determined by trn.\n    trn: A pandas dataframe. When creating a category for df, it looks up the\n        what the category\'s code were in trn and makes those the category codes\n        for df.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    note the type of col2 is string\n    >>> train_cats(df)\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    now the type of col2 is category {a : 1, b : 2}\n    >>> df2 = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'b\', \'a\', \'a\']})\n    >>> apply_cats(df2, df)\n           col1 col2\n        0     1    b\n        1     2    a\n        2     3    a\n    now the type of col is category {a : 1, b : 2}\n    """"""\n    for n,c in df.items():\n        if (n in trn.columns) and (trn[n].dtype.name==\'category\'):\n            df[n] = c.astype(\'category\').cat.as_ordered()\n            df[n].cat.set_categories(trn[n].cat.categories, ordered=True, inplace=True)\n\ndef fix_missing(df, col, name, na_dict):\n    """""" Fill missing data in a column of df with the median, and add a {name}_na column\n    which specifies if the data was missing.\n    Parameters:\n    -----------\n    df: The data frame that will be changed.\n    col: The column of data to fix by filling in missing data.\n    name: The name of the new filled column in df.\n    na_dict: A dictionary of values to create na\'s of and the value to insert. If\n        name is not a key of na_dict the median will fill any missing data. Also\n        if name is not a key of na_dict and there is no missing data in col, then\n        no {name}_na column is not created.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1     2    2    True\n    2     3    2   False\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n    >>> fix_missing(df, df[\'col2\'], \'col2\', {})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {\'col1\' : 500})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1   500    2    True\n    2     3    2   False\n    """"""\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+\'_na\'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    """""" Changes the column col from a categorical type to it\'s integer codes.\n    Parameters:\n    -----------\n    df: A pandas dataframe. df[name] will be filled with the integer codes from\n        col.\n    col: The column you wish to change into the categories.\n    name: The column name you wish to insert into df. This column will hold the\n        integer codes.\n    max_n_cat: If col has more categories than max_n_cat it will not change the\n        it to its integer codes. If max_n_cat is None, then col will always be\n        converted.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    note the type of col2 is string\n    >>> train_cats(df)\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    now the type of col2 is category { a : 1, b : 2}\n    >>> numericalize(df, df[\'col2\'], \'col3\', None)\n       col1 col2 col3\n    0     1    a    1\n    1     2    b    2\n    2     3    a    1\n    """"""\n    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n        df[name] = pd.Categorical(col).codes+1\n\ndef scale_vars(df, mapper):\n    warnings.filterwarnings(\'ignore\', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper\n\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    """""" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe. For each column of df \n    which is not in skip_flds nor in ignore_flds, na values are replaced by the\n    median value of the column.\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n    y_fld: The name of the response variable\n    skip_flds: A list of fields that dropped from df.\n    ignore_flds: A list of fields that are ignored during processing.\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n    preproc_fn: A function that gets applied to df.\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n    subset: Takes a random subset of size subset from df.\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n        y: y is the response variable\n        nas: returns a dictionary of which nas it created, and the associated median.\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    note the type of col2 is string\n    >>> train_cats(df)\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    now the type of col2 is category { a : 1, b : 2}\n    >>> x, y, nas = proc_df(df, \'col1\')\n    >>> x\n       col2\n    0     1\n    1     2\n    2     1\n    >>> data = DataFrame(pet=[""cat"", ""dog"", ""dog"", ""fish"", ""cat"", ""dog"", ""cat"", ""fish""],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    """"""\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    else: df = df.copy()\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = pd.Categorical(df[y_fld]).codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    else: na_dict = na_dict.copy()\n    na_dict_initial = na_dict.copy()\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if len(na_dict_initial.keys()) > 0:\n        df.drop([a + \'_na\' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({\'cols\':df.columns, \'imp\':m.feature_importances_}\n                       ).sort_values(\'imp\', ascending=False)\n\ndef set_rf_samples(n):\n    """""" Changes Scikit learn\'s random forests to give each tree a random sample of\n    n random rows.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    """""" Undoes the changes produced by set_rf_samples.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\ndef get_nn_mappers(df, cat_vars, contin_vars):\n    # Replace nulls with 0 for continuous, """" for categorical.\n    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n    for v in cat_vars: df[v].fillna(\'#NA#\', inplace=True)\n\n    # list of tuples, containing variable and instance of a transformer for that variable\n    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n'"
old/fastai/swa.py,3,"b'""""""\n    From the paper:\n        Averaging Weights Leads to Wider Optima and Better Generalization\n        Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, Andrew Gordon Wilson\n        https://arxiv.org/abs/1803.05407\n        2018\n        \n    Author\'s implementation: https://github.com/timgaripov/swa\n""""""\n\nimport torch\nfrom .sgdr import *\nfrom .core import *\n\n\nclass SWA(Callback):\n    def __init__(self, model, swa_model, swa_start):\n        super().__init__()\n        self.model,self.swa_model,self.swa_start=model,swa_model,swa_start\n        \n    def on_train_begin(self):\n        self.epoch = 0\n        self.swa_n = 0\n\n    def on_epoch_end(self, metrics):\n        if (self.epoch + 1) >= self.swa_start:\n            self.update_average_model()\n            self.swa_n += 1\n            \n        self.epoch += 1\n            \n    def update_average_model(self):\n        # update running average of parameters\n        model_params = self.model.parameters()\n        swa_params = self.swa_model.parameters()\n        for model_param, swa_param in zip(model_params, swa_params):\n            swa_param.data *= self.swa_n\n            swa_param.data += model_param.data\n            swa_param.data /= (self.swa_n + 1)            \n    \ndef collect_bn_modules(module, bn_modules):\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        bn_modules.append(module)\n\ndef fix_batchnorm(swa_model, train_dl):\n    """"""\n    During training, batch norm layers keep track of a running mean and\n    variance of the previous layer\'s activations. Because the parameters\n    of the SWA model are computed as the average of other models\' parameters,\n    the SWA model never sees the training data itself, and therefore has no\n    opportunity to compute the correct batch norm statistics. Before performing \n    inference with the SWA model, we perform a single pass over the training data\n    to calculate an accurate running mean and variance for each batch norm layer.\n    """"""\n    bn_modules = []\n    swa_model.apply(lambda module: collect_bn_modules(module, bn_modules))\n    \n    if not bn_modules: return\n\n    swa_model.train()\n\n    for module in bn_modules:\n        module.running_mean = torch.zeros_like(module.running_mean)\n        module.running_var = torch.ones_like(module.running_var)\n    \n    momenta = [m.momentum for m in bn_modules]\n\n    inputs_seen = 0\n\n    for (*x,y) in iter(train_dl):        \n        xs = V(x)\n        batch_size = xs[0].size(0)\n\n        momentum = batch_size / (inputs_seen + batch_size)\n        for module in bn_modules:\n            module.momentum = momentum\n                            \n        res = swa_model(*xs)        \n        \n        inputs_seen += batch_size\n                \n    for module, momentum in zip(bn_modules, momenta):\n        module.momentum = momentum    '"
old/fastai/text.py,1,"b'from .core import *\nfrom .learner import *\nfrom .lm_rnn import *\nfrom torch.utils.data.sampler import Sampler\nimport spacy\nfrom spacy.symbols import ORTH\n\nre_tok = re.compile(f\'([{string.punctuation}\xe2\x80\x9c\xe2\x80\x9d\xc2\xa8\xc2\xab\xc2\xbb\xc2\xae\xc2\xb4\xc2\xb7\xc2\xba\xc2\xbd\xc2\xbe\xc2\xbf\xc2\xa1\xc2\xa7\xc2\xa3\xe2\x82\xa4\xe2\x80\x98\xe2\x80\x99])\')\ndef tokenize(s): return re_tok.sub(r\' \\1 \', s).split()\n\ndef texts_labels_from_folders(path, folders):\n    texts,labels = [],[]\n    for idx,label in enumerate(folders):\n        for fname in glob(os.path.join(path, label, \'*.*\')):\n            texts.append(open(fname, \'r\').read())\n            labels.append(idx)\n    return texts, np.array(labels).astype(np.int64)\n\ndef numericalize_tok(tokens, max_vocab=50000, min_freq=0, unk_tok=""_unk_"", pad_tok=""_pad_"", bos_tok=""_bos_"", eos_tok=""_eos_""):\n    """"""Takes in text tokens and returns int2tok and tok2int converters\n\n        Arguments:\n        tokens(list): List of tokens. Can be a list of strings, or a list of lists of strings.\n        max_vocab(int): Number of tokens to return in the vocab (sorted by frequency)\n        min_freq(int): Minimum number of instances a token must be present in order to be preserved.\n        unk_tok(str): Token to use when unknown tokens are encountered in the source text.\n        pad_tok(str): Token to use when padding sequences.\n    """"""\n    if isinstance(tokens, str):\n        raise ValueError(""Expected to receive a list of tokens. Received a string instead"")\n    if isinstance(tokens[0], list):\n        tokens = [p for o in tokens for p in o]\n    freq = Counter(tokens)\n    int2tok = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n    unk_id = 3\n    int2tok.insert(0, bos_tok)\n    int2tok.insert(1, pad_tok)\n    int2tok.insert(2, eos_tok)\n    int2tok.insert(unk_id, unk_tok)\n    tok2int = collections.defaultdict(lambda:unk_id, {v:k for k,v in enumerate(int2tok)})\n    return int2tok, tok2int\n\nclass Tokenizer():\n    def __init__(self, lang=\'en\'):\n        self.re_br = re.compile(r\'<\\s*br\\s*/?>\', re.IGNORECASE)\n        self.tok = spacy.load(lang)\n        for w in (\'<eos>\',\'<bos>\',\'<unk>\'):\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\n\n    def sub_br(self,x): return self.re_br.sub(""\\n"", x)\n\n    def spacy_tok(self,x):\n        return [t.text for t in self.tok.tokenizer(self.sub_br(x))]\n\n    re_rep = re.compile(r\'(\\S)(\\1{3,})\')\n    re_word_rep = re.compile(r\'(\\b\\w+\\W+)(\\1{3,})\')\n\n    @staticmethod\n    def replace_rep(m):\n        TK_REP = \'tk_rep\'\n        c,cc = m.groups()\n        return f\' {TK_REP} {len(cc)+1} {c} \'\n\n    @staticmethod\n    def replace_wrep(m):\n        TK_WREP = \'tk_wrep\'\n        c,cc = m.groups()\n        return f\' {TK_WREP} {len(cc.split())+1} {c} \'\n\n    @staticmethod\n    def do_caps(ss):\n        TOK_UP,TOK_SENT,TOK_MIX = \' t_up \',\' t_st \',\' t_mx \'\n        res = []\n        prev=\'.\'\n        re_word = re.compile(\'\\w\')\n        re_nonsp = re.compile(\'\\S\')\n        for s in re.findall(r\'\\w+|\\W+\', ss):\n            res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n    #                 else [TOK_SENT,s.lower()] if (s.istitle() and re_word.search(prev))\n                    else [s.lower()])\n    #         if re_nonsp.search(s): prev = s\n        return \'\'.join(res)\n\n    def proc_text(self, s):\n        s = self.re_rep.sub(Tokenizer.replace_rep, s)\n        s = self.re_word_rep.sub(Tokenizer.replace_wrep, s)\n        s = Tokenizer.do_caps(s)\n        s = re.sub(r\'([/#])\', r\' \\1 \', s)\n        s = re.sub(\' {2,}\', \' \', s)\n        return self.spacy_tok(s)\n\n    @staticmethod\n    def proc_all(ss, lang):\n        tok = Tokenizer(lang)\n        return [tok.proc_text(s) for s in ss]\n\n    @staticmethod\n    def proc_all_mp(ss, lang=\'en\', ncpus = None):\n        ncpus = ncpus or num_cpus()//2\n        with ProcessPoolExecutor(ncpus) as e:\n            return sum(e.map(Tokenizer.proc_all, ss, [lang]*len(ss)), [])\n\n\nclass TextDataset(Dataset):\n    def __init__(self, x, y, backwards=False, sos=None, eos=None):\n        self.x,self.y,self.backwards,self.sos,self.eos = x,y,backwards,sos,eos\n\n    def __getitem__(self, idx):\n        x = self.x[idx]\n        if self.backwards: x = list(reversed(x))\n        if self.eos is not None: x = x + [self.eos]\n        if self.sos is not None: x = [self.sos]+x\n        return np.array(x),self.y[idx]\n\n    def __len__(self): return len(self.x)\n\n\nclass SortSampler(Sampler):\n    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n    def __len__(self): return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range(len(self.data_source)), key=self.key, reverse=True))\n\n\nclass SortishSampler(Sampler):\n    """"""Returns an iterator that traverses the the data in randomly ordered batches that are approximately the same size.\n    The max key size batch is always returned in the first call because of pytorch cuda memory allocation sequencing.\n    Without that max key returned first multiple buffers may be allocated when the first created isn\'t large enough\n    to hold the next in the sequence.\n    """"""\n    def __init__(self, data_source, key, bs):\n        self.data_source,self.key,self.bs = data_source,key,bs\n\n    def __len__(self): return len(self.data_source)\n\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs*50\n        ck_idx = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n        sort_idx = np.concatenate([sorted(s, key=self.key, reverse=True) for s in ck_idx])\n        sz = self.bs\n        ck_idx = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n        max_ck = np.argmax([self.key(ck[0]) for ck in ck_idx])  # find the chunk with the largest key,\n        ck_idx[0],ck_idx[max_ck] = ck_idx[max_ck],ck_idx[0]     # then make sure it goes first.\n        sort_idx = np.concatenate(np.random.permutation(ck_idx[1:]))\n        sort_idx = np.concatenate((ck_idx[0], sort_idx))\n        return iter(sort_idx)\n\n\nclass LanguageModelLoader():\n    """""" Returns a language model iterator that iterates through batches that are of length N(bptt,5)\n    The first batch returned is always bptt+25; the max possible width.  This is done because of the way that pytorch\n    allocates cuda memory in order to prevent multiple buffers from being created as the batch width grows.\n    """"""\n    def __init__(self, nums, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        while self.i < self.n-1 and self.iter<len(self):\n            if self.i == 0:\n                seq_len = self.bptt + 5 * 5\n            else:\n                bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n                seq_len = max(5, int(np.random.normal(bptt, 5)))\n            res = self.get_batch(self.i, seq_len)\n            self.i += seq_len\n            self.iter += 1\n            yield res\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def batchify(self, data):\n        nb = data.shape[0] // self.bs\n        data = np.array(data[:nb*self.bs])\n        data = data.reshape(self.bs, -1).T\n        if self.backwards: data=data[::-1]\n        return T(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass LanguageModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [*zip(m.rnns, m.dropouths), (self.model[1], m.dropouti)]\n\n\nclass LanguageModelData():\n    def __init__(self, path, pad_idx, n_tok, trn_dl, val_dl, test_dl=None, **kwargs):\n        self.path,self.pad_idx,self.n_tok = path,pad_idx,n_tok\n        self.trn_dl,self.val_dl,self.test_dl = trn_dl,val_dl,test_dl\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        m = get_language_model(self.n_tok, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = LanguageModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n    def fit(self, *args, **kwargs): return super().fit(*args, **kwargs, seq_first=True)\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n'"
old/fastai/torch_imports.py,9,"b'import os\nfrom distutils.version import LooseVersion\nimport torch, torchvision, torchtext\nfrom torch import nn, cuda, backends, FloatTensor, LongTensor, optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.nn.init import kaiming_uniform, kaiming_normal\nfrom torchvision.transforms import Compose\nfrom torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\nfrom torchvision.models import vgg16_bn, vgg19_bn\nfrom torchvision.models import densenet121, densenet161, densenet169, densenet201\n\nfrom .models.resnext_50_32x4d import resnext_50_32x4d\nfrom .models.resnext_101_32x4d import resnext_101_32x4d\nfrom .models.resnext_101_64x4d import resnext_101_64x4d\nfrom .models.wrn_50_2f import wrn_50_2f\nfrom .models.inceptionresnetv2 import InceptionResnetV2\nfrom .models.inceptionv4 import inceptionv4\nfrom .models.nasnet import nasnetalarge\nfrom .models.fa_resnet import *\n\nimport warnings\nwarnings.filterwarnings(\'ignore\', message=\'Implicit dimension choice\', category=UserWarning)\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\nif IS_TORCH_04:\n    from torch.nn.init import kaiming_uniform_ as kaiming_uniform\n    from torch.nn.init import kaiming_normal_ as kaiming_normal\n\ndef children(m): return m if isinstance(m, (list, tuple)) else list(m.children())\ndef save_model(m, p): torch.save(m.state_dict(), p)\ndef load_model(m, p):\n    sd = torch.load(p, map_location=lambda storage, loc: storage)\n    names = set(m.state_dict().keys())\n    for n in list(sd.keys()): # list ""detatches"" the iterator\n        if n not in names and n+\'_raw\' in names:\n            if n+\'_raw\' not in sd: sd[n+\'_raw\'] = sd[n]\n            del sd[n]\n    m.load_state_dict(sd)\n\ndef load_pre(pre, f, fn):\n    m = f()\n    path = os.path.dirname(__file__)\n    if pre: load_model(m, f\'{path}/weights/{fn}.pth\')\n    return m\n\ndef _fastai_model(name, paper_title, paper_href):\n    def add_docs_wrapper(f):\n        f.__doc__ = f""""""{name} model from\n        `""{paper_title}"" <{paper_href}>`_\n\n        Args:\n           pre (bool): If True, returns a model pre-trained on ImageNet\n        """"""\n        return f\n    return add_docs_wrapper\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inception_4(pre): return children(inceptionv4(pretrained=pre))[0]\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inceptionresnet_2(pre): return load_pre(pre, InceptionResnetV2, \'inceptionresnetv2-520b38e4\')\n\n@_fastai_model(\'ResNeXt 50\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext50(pre): return load_pre(pre, resnext_50_32x4d, \'resnext_50_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_32\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101(pre): return load_pre(pre, resnext_101_32x4d, \'resnext_101_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_64\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101_64(pre): return load_pre(pre, resnext_101_64x4d, \'resnext_101_64x4d\')\n\n@_fastai_model(\'Wide Residual Networks\', \'Wide Residual Networks\',\n               \'https://arxiv.org/pdf/1605.07146.pdf\')\ndef wrn(pre): return load_pre(pre, wrn_50_2f, \'wrn_50_2f\')\n\n@_fastai_model(\'Densenet-121\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn121(pre): return children(densenet121(pre))[0]\n\n@_fastai_model(\'Densenet-169\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn161(pre): return children(densenet161(pre))[0]\n\n@_fastai_model(\'Densenet-161\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn169(pre): return children(densenet169(pre))[0]\n\n@_fastai_model(\'Densenet-201\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn201(pre): return children(densenet201(pre))[0]\n\n@_fastai_model(\'Vgg-16 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg16(pre): return children(vgg16_bn(pre))[0]\n\n@_fastai_model(\'Vgg-19 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg19(pre): return children(vgg19_bn(pre))[0]\n\n'"
old/fastai/transforms.py,0,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\n\ndef scale_min(im, targ, interpolation=cv2.INTER_AREA):\n    """""" Scale the image so that the smallest axis is of size targ.\n\n    Arguments:\n        im (array): image\n        targ (int): target size\n    """"""\n    r,c,*_ = im.shape\n    ratio = targ/min(r,c)\n    sz = (scale_to(c, ratio, targ), scale_to(r, ratio, targ))\n    return cv2.resize(im, sz, interpolation=interpolation)\n\ndef zoom_cv(x,z):\n    """""" Zoom the center of image x by a factor of z+1 while retaining the original image size and proportion. """"""\n    if z==0: return x\n    r,c,*_ = x.shape\n    M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)\n    return cv2.warpAffine(x,M,(c,r))\n\ndef stretch_cv(x,sr,sc,interpolation=cv2.INTER_AREA):\n    """""" Stretches image x horizontally by sr+1, and vertically by sc+1 while retaining the original image size and proportion. """"""\n    if sr==0 and sc==0: return x\n    r,c,*_ = x.shape\n    x = cv2.resize(x, None, fx=sr+1, fy=sc+1, interpolation=interpolation)\n    nr,nc,*_ = x.shape\n    cr = (nr-r)//2; cc = (nc-c)//2\n    return x[cr:r+cr, cc:c+cc]\n\ndef dihedral(x, dih):\n    """""" Perform any of 8 permutations of 90-degrees rotations or flips for image x. """"""\n    x = np.rot90(x, dih%4)\n    return x if dih<4 else np.fliplr(x)\n\ndef lighting(im, b, c):\n    """""" Adjust image balance and contrast """"""\n    if b==0 and c==1: return im\n    mu = np.average(im)\n    return np.clip((im-mu)*c+mu+b,0.,1.).astype(np.float32)\n\ndef rotate_cv(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n    """""" Rotate an image by deg degrees\n\n    Arguments:\n        deg (float): degree to rotate.\n    """"""\n    r,c,*_ = im.shape\n    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n\ndef no_crop(im, min_sz=None, interpolation=cv2.INTER_AREA):\n    """""" Return a squared resized image """"""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    return cv2.resize(im, (min_sz, min_sz), interpolation=interpolation)\n\ndef center_crop(im, min_sz=None):\n    """""" Return a center crop of an image """"""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    start_r = math.ceil((r-min_sz)/2)\n    start_c = math.ceil((c-min_sz)/2)\n    return crop(im, start_r, start_c, min_sz)\n\ndef googlenet_resize(im, targ, min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p, interpolation=cv2.INTER_AREA):\n    """""" Randomly crop an image with an aspect ratio and returns a squared resized image of size targ\n    \n    References:\n    1. https://arxiv.org/pdf/1409.4842.pdf\n    2. https://arxiv.org/pdf/1802.07888.pdf\n    """"""\n    h,w,*_ = im.shape\n    area = h*w\n    for _ in range(10):\n        targetArea = random.uniform(min_area_frac, 1.0) * area\n        aspectR = random.uniform(min_aspect_ratio, max_aspect_ratio)\n        ww = int(np.sqrt(targetArea * aspectR) + 0.5)\n        hh = int(np.sqrt(targetArea / aspectR) + 0.5)\n        if flip_hw_p:\n            ww, hh = hh, ww\n        if hh <= h and ww <= w:\n            x1 = 0 if w == ww else random.randint(0, w - ww)\n            y1 = 0 if h == hh else random.randint(0, h - hh)\n            out = im[y1:y1 + hh, x1:x1 + ww]\n            out = cv2.resize(out, (targ, targ), interpolation=interpolation)\n            return out\n    out = scale_min(im, targ, interpolation=interpolation)\n    out = center_crop(out)\n    return out\n\ndef cutout(im, n_holes, length):\n    """""" Cut out n_holes number of square holes of size length in image at random locations. Holes may overlap. """"""\n    r,c,*_ = im.shape\n    mask = np.ones((r, c), np.int32)\n    for n in range(n_holes):\n        y = np.random.randint(0, r)\n        x = np.random.randint(0, c)\n\n        y1 = int(np.clip(y - length / 2, 0, r))\n        y2 = int(np.clip(y + length / 2, 0, r))\n        x1 = int(np.clip(x - length / 2, 0, c))\n        x2 = int(np.clip(x + length / 2, 0, c))\n        mask[y1: y2, x1: x2] = 0.\n    \n    mask = mask[:,:,None]\n    im = im * mask\n    return im\n\ndef scale_to(x, ratio, targ): \n    \'\'\'Calculate dimension of an image during scaling with aspect ratio\'\'\'\n    return max(math.floor(x*ratio), targ)\n\ndef crop(im, r, c, sz): \n    \'\'\'\n    crop image into a square of size sz, \n    \'\'\'\n    return im[r:r+sz, c:c+sz]\n\ndef det_dihedral(dih): return lambda x: dihedral(x, dih)\ndef det_stretch(sr, sc): return lambda x: stretch_cv(x, sr, sc)\ndef det_lighting(b, c): return lambda x: lighting(x, b, c)\ndef det_rotate(deg): return lambda x: rotate_cv(x, deg)\ndef det_zoom(zoom): return lambda x: zoom_cv(x, zoom)\n\ndef rand0(s): return random.random()*(s*2)-s\n\n\nclass TfmType(IntEnum):\n    """""" Type of transformation.\n    Parameters\n        IntEnum: predefined types of transformations\n            NO:    the default, y does not get transformed when x is transformed.\n            PIXEL: x and y are images and should be transformed in the same way.\n                   Example: image segmentation.\n            COORD: y are coordinates (i.e bounding boxes)\n            CLASS: y are class labels (same behaviour as PIXEL, except no normalization)\n    """"""\n    NO = 1\n    PIXEL = 2\n    COORD = 3\n    CLASS = 4\n\n\nclass Denormalize():\n    """""" De-normalizes an image, returning it to original format.\n    """"""\n    def __init__(self, m, s):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n    def __call__(self, x): return x*self.s+self.m\n\n\nclass Normalize():\n    """""" Normalizes an image to zero mean and unit standard deviation, given the mean m and std s of the original image """"""\n    def __init__(self, m, s, tfm_y=TfmType.NO):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n        self.tfm_y=tfm_y\n\n    def __call__(self, x, y=None):\n        x = (x-self.m)/self.s\n        if self.tfm_y==TfmType.PIXEL and y is not None: y = (y-self.m)/self.s\n        return x,y\n\nclass ChannelOrder():\n    \'\'\'\n    changes image array shape from (h, w, 3) to (3, h, w). \n    tfm_y decides the transformation done to the y element. \n    \'\'\'\n    def __init__(self, tfm_y=TfmType.NO): self.tfm_y=tfm_y\n\n    def __call__(self, x, y):\n        x = np.rollaxis(x, 2)\n        #if isinstance(y,np.ndarray) and (len(y.shape)==3):\n        if self.tfm_y==TfmType.PIXEL: y = np.rollaxis(y, 2)\n        elif self.tfm_y==TfmType.CLASS: y = y[...,0]\n        return x,y\n\n\ndef to_bb(YY, y=""deprecated""):\n    """"""Convert mask YY to a bounding box, assumes 0 as background nonzero object""""""\n    cols,rows = np.nonzero(YY)\n    if len(cols)==0: return np.zeros(4, dtype=np.float32)\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n\ndef coords2px(y, x):\n    """""" Transforming coordinates to pixels.\n\n    Arguments:\n        y : np array\n            vector in which (y[0], y[1]) and (y[2], y[3]) are the\n            the corners of a bounding box.\n        x : image\n            an image\n    Returns:\n        Y : image\n            of shape x.shape\n    """"""\n    rows = np.rint([y[0], y[0], y[2], y[2]]).astype(int)\n    cols = np.rint([y[1], y[3], y[1], y[3]]).astype(int)\n    r,c,*_ = x.shape\n    Y = np.zeros((r, c))\n    Y[rows, cols] = 1\n    return Y\n\n\nclass Transform():\n    """""" A class that represents a transform.\n\n    All other transforms should subclass it. All subclasses should override\n    do_transform.\n\n    Arguments\n    ---------\n        tfm_y : TfmType\n            type of transform\n    """"""\n    def __init__(self, tfm_y=TfmType.NO):\n        self.tfm_y=tfm_y\n        self.store = threading.local()\n\n    def set_state(self): pass\n    def __call__(self, x, y):\n        self.set_state()\n        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n                else self.transform_coord(x,y))\n        return x, y\n\n    def transform_coord(self, x, y): return self.transform(x),y\n\n    def transform(self, x, y=None):\n        x = self.do_transform(x,False)\n        return (x, self.do_transform(y,True)) if y is not None else x\n\n    @abstractmethod\n    def do_transform(self, x, is_y): raise NotImplementedError\n\n\nclass CoordTransform(Transform):\n    """""" A coordinate transform.  """"""\n\n    @staticmethod\n    def make_square(y, x):\n        r,c,*_ = x.shape\n        y1 = np.zeros((r, c))\n        y = y.astype(np.int)\n        y1[y[0]:y[2], y[1]:y[3]] = 1.\n        return y1\n\n    def map_y(self, y0, x):\n        y = CoordTransform.make_square(y0, x)\n        y_tr = self.do_transform(y, True)\n        return to_bb(y_tr)\n\n    def transform_coord(self, x, ys):\n        yp = partition(ys, 4)\n        y2 = [self.map_y(y,x) for y in yp]\n        x = self.do_transform(x, False)\n        return x, np.concatenate(y2)\n\n\nclass AddPadding(CoordTransform):\n    """""" A class that represents adding paddings to an image.\n\n    The default padding is border_reflect\n    Arguments\n    ---------\n        pad : int\n            size of padding on top, bottom, left and right\n        mode:\n            type of cv2 padding modes. (e.g., constant, reflect, wrap, replicate. etc. )\n    """"""\n    def __init__(self, pad, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.pad,self.mode = pad,mode\n\n    def do_transform(self, im, is_y):\n        return cv2.copyMakeBorder(im, self.pad, self.pad, self.pad, self.pad, self.mode)\n\nclass CenterCrop(CoordTransform):\n    """""" A class that represents a Center Crop.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        sz: int\n            size of the crop.\n        tfm_y : TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.min_sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        return center_crop(x, self.sz_y if is_y else self.min_sz)\n\n\nclass RandomCrop(CoordTransform):\n    """""" A class that represents a Random Crop transformation.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        targ: int\n            target size of the crop.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, targ_sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz,self.sz_y = targ_sz,sz_y\n\n    def set_state(self):\n        self.store.rand_r = random.uniform(0, 1)\n        self.store.rand_c = random.uniform(0, 1)\n\n    def do_transform(self, x, is_y):\n        r,c,*_ = x.shape\n        sz = self.sz_y if is_y else self.targ_sz\n        start_r = np.floor(self.store.rand_r*(r-sz)).astype(int)\n        start_c = np.floor(self.store.rand_c*(c-sz)).astype(int)\n        return crop(x, start_r, start_c, sz)\n\nclass CropNoop(CoordTransform):\n    """""" Does not resize and does not scale """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n    def do_transform(self, x, is_y):\n        return x\n    \nclass NoCrop(CoordTransform):\n    """"""  A transformation that resize to a square image without cropping.\n\n    This transforms (optionally) resizes x,y at with the same parameters.\n    Arguments:\n        targ: int\n            target size of the crop.\n        tfm_y (TfmType): type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return no_crop(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return no_crop(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass Scale(CoordTransform):\n    """""" A transformation that scales the min size to sz.\n\n    Arguments:\n        sz: int\n            target size to scale minimum size.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass RandomScale(CoordTransform):\n    """""" Scales an image so that the min size is a random number between [sz, sz*max_zoom]\n\n    This transforms (optionally) scales x,y at with the same parameters.\n    Arguments:\n        sz: int\n            target size\n        max_zoom: float\n            float >= 1.0\n        p : float\n            a probability for doing the random sizing\n        tfm_y: TfmType\n            type of y transform\n    """"""\n    def __init__(self, sz, max_zoom, p=0.75, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.max_zoom,self.p,self.sz_y = sz,max_zoom,p,sz_y\n\n    def set_state(self):\n        min_z = 1.\n        max_z = self.max_zoom\n        if isinstance(self.max_zoom, collections.Iterable):\n            min_z, max_z = self.max_zoom\n        self.store.mult = random.uniform(min_z, max_z) if random.random()<self.p else 1\n        self.store.new_sz = int(self.store.mult*self.sz)\n        if self.sz_y is not None: self.store.new_sz_y = int(self.store.mult*self.sz_y)\n\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.store.new_sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.store.new_sz,   cv2.INTER_AREA   )\n\n\nclass RandomRotate(CoordTransform):\n    """""" Rotates images and (optionally) target y.\n\n    Rotating coordinates is treated differently for x and y on this\n    transform.\n     Arguments:\n        deg (float): degree to rotate.\n        p (float): probability of rotation\n        mode: type of border\n        tfm_y (TfmType): type of y transform\n    """"""\n    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.deg,self.p = deg,p\n        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n            self.modes = (mode,cv2.BORDER_CONSTANT)\n        else:\n            self.modes = (mode,mode)\n\n    def set_state(self):\n        self.store.rdeg = rand0(self.deg)\n        self.store.rp = random.random()<self.p\n\n    def do_transform(self, x, is_y):\n        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n                mode= self.modes[1] if is_y else self.modes[0],\n                interpolation=cv2.INTER_NEAREST if is_y else cv2.INTER_AREA)\n        return x\n\n\nclass RandomDihedral(CoordTransform):\n    """"""\n    Rotates images by random multiples of 90 degrees and/or reflection.\n    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n    """"""\n    def set_state(self):\n        self.store.rot_times = random.randint(0,3)\n        self.store.do_flip = random.random()<0.5\n\n    def do_transform(self, x, is_y):\n        x = np.rot90(x, self.store.rot_times)\n        return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomFlip(CoordTransform):\n    def __init__(self, tfm_y=TfmType.NO, p=0.5):\n        super().__init__(tfm_y=tfm_y)\n        self.p=p\n\n    def set_state(self): self.store.do_flip = random.random()<self.p\n    def do_transform(self, x, is_y): return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomLighting(Transform):\n    def __init__(self, b, c, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.b,self.c = b,c\n\n    def set_state(self):\n        self.store.b_rand = rand0(self.b)\n        self.store.c_rand = rand0(self.c)\n\n    def do_transform(self, x, is_y):\n        if is_y and self.tfm_y != TfmType.PIXEL: return x\n        b = self.store.b_rand\n        c = self.store.c_rand\n        c = -1/(c-1) if c<0 else c+1\n        x = lighting(x, b, c)\n        return x\n\nclass RandomRotateZoom(CoordTransform):\n    """""" \n        Selects between a rotate, zoom, stretch, or no transform.\n        Arguments:\n            deg - maximum degrees of rotation.\n            zoom - maximum fraction of zoom.\n            stretch - maximum fraction of stretch.\n            ps - probabilities for each transform. List of length 4. The order for these probabilities is as listed respectively (4th probability is \'no transform\'.\n    """"""\n    def __init__(self, deg, zoom, stretch, ps=None, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        if ps is None: ps = [0.25,0.25,0.25,0.25]\n        assert len(ps) == 4, \'does not have 4 probabilities for p, it has %d\' % len(ps)\n        self.transforms = RandomRotate(deg, p=1, mode=mode, tfm_y=tfm_y), RandomZoom(zoom, tfm_y=tfm_y), RandomStretch(stretch,tfm_y=tfm_y)\n        self.pass_t = PassThru()\n        self.cum_ps = np.cumsum(ps)\n        assert self.cum_ps[3]==1, \'probabilites do not sum to 1; they sum to %d\' % self.cum_ps[3]\n\n    def set_state(self):\n        self.store.trans = self.pass_t\n        self.store.choice = self.cum_ps[3]*random.random()\n        for i in range(len(self.transforms)):\n            if self.store.choice < self.cum_ps[i]:\n                self.store.trans = self.transforms[i]\n                break\n        self.store.trans.set_state()\n\n    def do_transform(self, x, is_y): return self.store.trans.do_transform(x, is_y)\n\nclass RandomZoom(CoordTransform):\n    def __init__(self, zoom_max, zoom_min=0, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.zoom_max, self.zoom_min = zoom_max, zoom_min\n\n    def set_state(self):\n        self.store.zoom = self.zoom_min+(self.zoom_max-self.zoom_min)*random.random()\n\n    def do_transform(self, x, is_y):\n        return zoom_cv(x, self.store.zoom)\n\nclass RandomStretch(CoordTransform):\n    def __init__(self, max_stretch, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.max_stretch = max_stretch\n\n    def set_state(self):\n        self.store.stretch = self.max_stretch*random.random()\n        self.store.stretch_dir = random.randint(0,1)\n\n    def do_transform(self, x, is_y):\n        if self.store.stretch_dir==0: x = stretch_cv(x, self.store.stretch, 0)\n        else:                         x = stretch_cv(x, 0, self.store.stretch)\n        return x\n\nclass PassThru(CoordTransform):\n    def do_transform(self, x, is_y):\n        return x\n\nclass RandomBlur(Transform):\n    """"""\n    Adds a gaussian blur to the image at chance.\n    Multiple blur strengths can be configured, one of them is used by random chance.\n    """"""\n\n    def __init__(self, blur_strengths=5, probability=0.5, tfm_y=TfmType.NO):\n        # Blur strength must be an odd number, because it is used as a kernel size.\n        super().__init__(tfm_y)\n        self.blur_strengths = (np.array(blur_strengths, ndmin=1) * 2) - 1\n        if np.any(self.blur_strengths < 0):\n            raise ValueError(""all blur_strengths must be > 0"")\n        self.probability = probability\n        self.store.apply_transform = False\n\n    def set_state(self):\n        self.store.apply_transform = random.random() < self.probability\n        kernel_size = np.random.choice(self.blur_strengths)\n        self.store.kernel = (kernel_size, kernel_size)\n\n    def do_transform(self, x, is_y):\n        return cv2.GaussianBlur(src=x, ksize=self.store.kernel, sigmaX=0) if self.store.apply_transform else x\n\nclass Cutout(Transform):\n    """""" Randomly masks squares of size length on the image.\n    https://arxiv.org/pdf/1708.04552.pdf\n    \n    Arguments:\n    n_holes: number of squares\n    length: size of the square\n    p: probability to apply cutout\n    tfm_y: type of y transform\n    """"""\n    def __init__(self, n_holes, length, p=0.5, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.n_holes, self.length, self.p = n_holes, length, p\n\n    def set_state(self):\n        self.apply_transform = random.random() < self.p\n\n    def do_transform(self, img, is_y):\n        return cutout(img, self.n_holes, self.length) if self.apply_transform else img\n\nclass GoogleNetResize(CoordTransform):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ \n    \n    Arguments:\n        targ_sz: int\n            target size\n        min_area_frac: float < 1.0\n            minimum area of the original image for cropping\n        min_aspect_ratio : float\n            minimum aspect ratio\n        max_aspect_ratio : float\n            maximum aspect ratio\n        flip_hw_p : float\n            probability for flipping magnitudes of height and width\n        tfm_y: TfmType\n            type of y transform\n    """"""\n\n    def __init__(self, targ_sz,\n                 min_area_frac=0.08, min_aspect_ratio=0.75, max_aspect_ratio=1.333, flip_hw_p=0.5,\n                 tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz, self.tfm_y, self.sz_y = targ_sz, tfm_y, sz_y\n        self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.flip_hw_p = min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p\n\n    def set_state(self):\n        # if self.random_state: random.seed(self.random_state)\n        self.store.fp = random.random()<self.flip_hw_p\n\n    def do_transform(self, x, is_y):\n        sz = self.sz_y if is_y else self.targ_sz\n        if is_y:\n            interpolation = cv2.INTER_NEAREST if self.tfm_y in (TfmType.COORD, TfmType.CLASS) else cv2.INTER_AREA\n        else:\n            interpolation = cv2.INTER_AREA\n        return googlenet_resize(x, sz, self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.store.fp, interpolation=interpolation)\n\n\ndef compose(im, y, fns):\n    """""" Apply a collection of transformation functions :fns: to images """"""\n    for fn in fns:\n        #pdb.set_trace()\n        im, y =fn(im, y)\n    return im if y is None else (im, y)\n\n\nclass CropType(IntEnum):\n    """""" Type of image cropping. """"""\n    RANDOM = 1\n    CENTER = 2\n    NO = 3\n    GOOGLENET = 4\n    NOOP = 5\n\ncrop_fn_lu = {CropType.RANDOM: RandomCrop, CropType.CENTER: CenterCrop, CropType.NO: NoCrop, CropType.GOOGLENET: GoogleNetResize, CropType.NOOP: CropNoop}\n\nclass Transforms():\n    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n                 tfm_y=TfmType.NO, sz_y=None):\n        if sz_y is None: sz_y = sz\n        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n        self.tfms = tfms\n        self.tfms.append(crop_tfm)\n        if normalizer is not None: self.tfms.append(normalizer)\n        self.tfms.append(ChannelOrder(tfm_y))\n\n    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n    def __repr__(self): return str(self.tfms)\n\n\ndef image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n    """"""\n    Generate a standard set of transformations\n\n    Arguments\n    ---------\n     normalizer :\n         image normalizing function\n     denorm :\n         image denormalizing function\n     sz :\n         size, sz_y = sz if not specified.\n     tfms :\n         iterable collection of transformation functions\n     max_zoom : float,\n         maximum zoom\n     pad : int,\n         padding on top, left, right and bottom\n     crop_type :\n         crop type\n     tfm_y :\n         y axis specific transformations\n     sz_y :\n         y size, height\n     pad_mode :\n         cv2 padding style: repeat, reflect, etc.\n\n    Returns\n    -------\n     type : ``Transforms``\n         transformer for specified image operations.\n\n    See Also\n    --------\n     Transforms: the transformer object returned by this function\n    """"""\n    if tfm_y is None: tfm_y=TfmType.NO\n    if tfms is None: tfms=[]\n    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n    if sz_y is None: sz_y = sz\n    if scale is None:\n        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n                 else Scale(sz, tfm_y, sz_y=sz_y)]\n    elif not is_listy(scale): scale = [scale]\n    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n                      tfm_y=tfm_y, sz_y=sz_y)\n\ndef noop(x):\n    """"""dummy function for do-nothing.\n    equivalent to: lambda x: x""""""\n    return x\n\ntransforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)]\ntransforms_side_on  = transforms_basic + [RandomFlip()]\ntransforms_top_down = transforms_basic + [RandomDihedral()]\n\nimagenet_stats = A([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n""""""Statistics pertaining to image data from image net. mean and std of the images of each color channel""""""\ninception_stats = A([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\ninception_models = (inception_4, inceptionresnet_2)\n\ndef tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Given the statistics of the training image sets, returns separate training and validation transform functions\n    """"""\n    if aug_tfms is None: aug_tfms=[]\n    tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n    tfm_denorm = Denormalize(*stats) if stats is not None else None\n    val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n    val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n            tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n    trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n            tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n    return trn_tfm, val_tfm\n\n\ndef tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Returns separate transformers of images for training and validation.\n    Transformers are constructed according to the image statistics given by the model. (See tfms_from_stats)\n\n    Arguments:\n        f_model: model, pretrained or not pretrained\n    """"""\n    stats = inception_stats if f_model in inception_models else imagenet_stats\n    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)\n\n'"
old/fastai/transforms_pil.py,1,"b'import torch\nimport numpy as np\n\n\nclass Cutout(object):\n    """"""Randomly mask out one or more patches from an image.\n\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    """"""\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (Tensor): Tensor image of size (C, H, W).\n        Returns:\n            Tensor: Image with n_holes of dimension length x length cut out of it.\n        """"""\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length / 2, 0, h)\n            y2 = np.clip(y + self.length / 2, 0, h)\n            x1 = np.clip(x - self.length / 2, 0, w)\n            x2 = np.clip(x + self.length / 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n'"
old/tests/__init__.py,0,"b""import matplotlib\nmatplotlib.use('agg')\nimport cv2,torch\n\n# the above imports are fixing the TLS issue:\n# ```ImportError: dlopen: cannot load any more object with static TLS```\n# they were set after experimenting with the test sets on ubuntu 16.04\n"""
old/tests/test_core.py,22,"b'import pytest, torch, unittest, bcolz\nimport numpy as np\nfrom fastai import core\nfrom unittest import mock\nfrom unittest.mock import Mock\nfrom testfixtures import tempdir\n\ndef test_sum_geom():\n    assert core.sum_geom(1, 1, 1) == 1\n    assert core.sum_geom(1, 1, 3) == 3\n    assert core.sum_geom(3, 10, 4) == 3333\n    assert core.sum_geom(0, 2, 3) == 0\n    assert core.sum_geom(1, 0, 3) == 1\n    assert core.sum_geom(1, 2, 0) == 0\n\ndef test_map_none():\n  def fn(x): return x\n  assert core.map_none(None, fn) == None\n  assert core.map_none(""not none"", fn) == ""not none""\n\ndef test_delistify():\n  assert core.delistify([1]) == 1\n  assert core.delistify((1)) == 1\n  assert core.delistify(""non list"") == ""non list""\n  assert core.delistify(object) == object\n\n  with pytest.raises(IndexError):\n    assert core.delistify([])\n\ndef test_datafy():\n  x = Mock(data={})\n  assert core.datafy(x) == {}\n  assert core.datafy([x]) == [{}]\n  assert core.datafy([x, x]) == [{}, {}]\n\n@mock.patch(""fastai.core.to_gpu"", lambda x, *args, **kwargs: x)\ndef test_T():\n  tensor = torch.ones([1, 2])\n  np.testing.assert_equal(core.to_np(core.T(tensor)), [[1, 1]])\n\n  array = np.arange(0, 5)\n  assert core.T(array.astype(np.int)).type() == ""torch.LongTensor""\n  assert core.T(array.astype(np.float)).type() == ""torch.FloatTensor""\n\n  with mock.patch(""fastai.core.to_half"") as to_half_mock:\n    core.T(array.astype(np.float), half=True)\n    to_half_mock.assert_called_once()\n\n  with pytest.raises(NotImplementedError):\n    assert core.T(array.astype(np.object))\n\ndef test_create_variable_passing_Variable_object():\n  v = torch.autograd.Variable(core.T(np.arange(0, 3)))\n  cv = core.create_variable(v, volatile=True)\n  if core.IS_TORCH_04: assert (cv == v).all()\n  else: assert cv is v\n\n@mock.patch(""fastai.core.Variable"")\ndef test_create_variable(VariableMock):\n  v = np.arange(0, 3)\n\n  with mock.patch(""fastai.core.IS_TORCH_04"", True):\n    core.create_variable(v, volatile=True)\n    assert VariableMock.call_args[1] == {""requires_grad"": False}\n  \n  with mock.patch(""fastai.core.IS_TORCH_04"", False):\n    core.create_variable(v, volatile=True)\n    assert VariableMock.call_args[1] == {""requires_grad"": False, ""volatile"": True}\n\n@mock.patch(""fastai.core.create_variable"")\ndef test_V_(create_variable_mock):\n  core.V_(""foo"")\n\n  create_variable_mock.assert_called_with(\'foo\', requires_grad=False, volatile=False)\n\n@mock.patch(""fastai.core.map_over"")\ndef test_V(map_over_mock):\n  core.V(""foo"")\n\n  assert map_over_mock.call_args[0][0] == \'foo\'\n  assert type(map_over_mock.call_args[0][1]) == type(lambda:0)\n\ndef test_to_np():\n  array = np.arange(0, 3).astype(np.float)\n  assert core.to_np(array) is array\n\n  tensor = core.T(array)\n  result = core.to_np([tensor, tensor])\n  np.testing.assert_equal(result[0], array)\n  np.testing.assert_equal(result[1], array)\n\n  variable = core.V(array)\n  np.testing.assert_equal(core.to_np(variable), array)\n\n  with mock.patch(""torch.cuda.is_available"") as is_available_mock:\n    with mock.patch(""fastai.core.is_half_tensor"") as is_half_tensor_mock:\n      is_available_mock.return_value=True\n      is_half_tensor_mock.return_value=True\n\n      tensor = core.T(array.astype(np.int))\n\n      array = core.to_np(tensor)\n      np.testing.assert_equal(array, [0., 1., 2.])\n      assert array.dtype in (np.float32, np.float64)\n\n\ndef test_noop():\n  assert core.noop() is None\n\ndef test_chain_params():\n  modules = [torch.nn.Linear(3, 2), torch.nn.Linear(2, 1)]\n\n  params = core.chain_params(modules)\n  assert len(params) == 4\n  assert list(params[0].size()) == [2, 3]\n  assert list(params[1].size()) == [2]\n  assert list(params[2].size()) == [1, 2]\n  assert list(params[3].size()) == [1]\n\n  params = core.chain_params(torch.nn.Linear(2, 2))\n  assert list(params[0].size()) == [2, 2]\n  assert list(params[1].size()) == [2]\n\ndef test_set_trainable_attr():\n  linear = torch.nn.Linear(2, 1)\n  core.set_trainable_attr(linear, False)\n\n  assert linear.trainable == False\n  for param in linear.parameters():\n    assert param.requires_grad == False\n\ndef test_apply_leaf():\n  spy = Mock(name=""apply_leaf_spy"")\n  fn = lambda x: spy(x)\n  layer1 = torch.nn.Linear(2, 2)\n  layer2 = torch.nn.Linear(2, 1)\n  model = torch.nn.Sequential(layer1, layer2)\n\n  core.apply_leaf(model, fn)\n\n  assert spy.call_count == 3\n  assert spy.call_args_list[0][0][0] is model\n  assert spy.call_args_list[1][0][0] is layer1\n  assert spy.call_args_list[2][0][0] is layer2\n\ndef test_set_trainable():\n  layer1 = torch.nn.Linear(2, 2)\n  layer2 = torch.nn.Linear(2, 1)\n  model = torch.nn.Sequential(layer1, layer2)\n\n  params_require_grad_before = list(filter(lambda param: param.requires_grad == True,\n                                    model.parameters()))\n\n  core.set_trainable(model, False)\n\n  params_require_grad_after = list(filter(lambda param: param.requires_grad == True,\n                                    model.parameters()))\n\n  assert len(params_require_grad_before) == 4\n  assert len(params_require_grad_after) == 0\n\n  assert model.trainable == False\n  assert layer1.trainable == False\n  assert layer2.trainable == False\n\n@mock.patch(""fastai.core.optim.SGD"")\ndef test_SGD_Momentum(sgd_mock):\n  sgd = core.SGD_Momentum(0.2)\n  sgd(""foo"", param1=1, param2=2)\n\n  sgd_mock.assert_called_with(\'foo\', momentum=0.2, param1=1, param2=2)\n\ndef test_one_hot():\n  labels = [0, 1, 0, 2, 0, 3]\n  num_classes = 4\n  one_hot = core.one_hot(labels, num_classes)\n\n  np.testing.assert_equal(one_hot, [\n    [1, 0, 0, 0],\n    [0, 1, 0, 0],\n    [1, 0, 0, 0],\n    [0, 0, 1, 0],\n    [1, 0, 0, 0],\n    [0, 0, 0, 1],\n  ])\n\n@mock.patch(""fastai.core.num_cpus"")\ndef test_partition_by_cores(num_cpus_mock):\n  x = [0, 1, 2, 3, 4]\n\n  num_cpus_mock.return_value = 1\n  assert core.partition_by_cores(x) == [[0, 1, 2, 3, 4]]\n\n  num_cpus_mock.return_value = 2\n  assert core.partition_by_cores(x) == [[0, 1, 2], [3, 4]]\n\n  num_cpus_mock.return_value = 3\n  assert core.partition_by_cores(x) == [[0, 1], [2, 3], [4]]\n\n  num_cpus_mock.return_value = 4\n  assert core.partition_by_cores(x) == [[0, 1], [2, 3], [4]]\n\n@mock.patch(""fastai.core.os"")\ndef test_num_cpus_with_sched_getaffinity(os_mock):\n  os_mock.sched_getaffinity = Mock(return_value=[""foo"", ""bar""])\n\n  assert core.num_cpus() == 2\n\n@mock.patch(""fastai.core.os"")\ndef test_num_cpus_without_sched_getaffinity(os_mock):\n  os_mock.sched_getaffinity = Mock(side_effect=AttributeError)\n  os_mock.cpu_count = Mock(return_value=3)\n\n  assert core.num_cpus() == 3\n\ndef test_partition_functionality():\n\n  def test_partition(a, sz, ex):\n    result = core.partition(a, sz)\n    assert len(result) == len(ex)\n    assert all([a == b for a, b in zip(result, ex)])\n\n  a = [1,2,3,4,5]\n  \n  sz = 2\n  ex = [[1,2],[3,4],[5]]\n  test_partition(a, sz, ex)\n\n  sz = 3\n  ex = [[1,2,3],[4,5]]\n  test_partition(a, sz, ex)\n\n  sz = 1\n  ex = [[1],[2],[3],[4],[5]]\n  test_partition(a, sz, ex)\n\n  sz = 6\n  ex = [[1,2,3,4,5]]\n  test_partition(a, sz, ex)\n\n  sz = 3\n  a = []\n  result = core.partition(a, sz)\n  assert len(result) == 0\n\n\ndef test_partition_error_handling():\n  sz = 0\n  a = [1,2,3,4,5]\n  with pytest.raises(ValueError):\n    core.partition(a, sz)\n\n\ndef test_split_by_idxs_functionality():\n\n  seq = [1,2,3,4,5,6]\n  \n  def test_split_by_idxs(seq, idxs, ex):\n    test_result = []\n    for item in core.split_by_idxs(seq, idxs):\n      test_result.append(item)\n    \n    assert len(test_result) == len(ex)\n    assert all([a == b for a,b in zip(test_result, ex)])\n  \n  idxs = [2]\n  ex = [[1,2],[3,4,5,6]]\n\n  test_split_by_idxs(seq, idxs, ex)\n  \n  idxs = [1,2]\n  ex = [[1],[2],[3,4,5,6]]\n  test_split_by_idxs(seq, idxs, ex)\n\n  idxs = [2,4,5]\n  ex = [[1,2],[3,4],[5],[6]]\n  test_split_by_idxs(seq, idxs, ex)\n\n  idxs = []\n  ex = [[1,2,3,4,5,6]]\n  test_split_by_idxs(seq, idxs, ex)\n\n\ndef test_split_by_idxs_error_handling():\n  seq = [1,2,3,4]\n  idxs = [5]\n\n  gen = core.split_by_idxs(seq, idxs)\n  with pytest.raises(KeyError):\n    next(gen)\n\ndef test_BasicModel():\n  layer_1 = torch.nn.Linear(2, 2)\n  layer_2 = torch.nn.Linear(2, 1)\n  model = torch.nn.Sequential(layer_1, layer_2)\n  basic = core.BasicModel(model, name=""foo"")\n\n  assert basic.model is model\n  assert basic.name == ""foo""\n\n  layers = basic.get_layer_groups()\n  assert layers == [layer_1, layer_2]\n\ndef test_SingleModel():\n  layer_1 = torch.nn.Linear(2, 2)\n  layer_2 = torch.nn.Linear(2, 1)\n  model = torch.nn.Sequential(layer_1, layer_2)\n  single_model = core.SingleModel(model, name=""foo"")\n\n  assert single_model.get_layer_groups() == [model]\n\nclass TestSimpleNet(unittest.TestCase):\n  def setUp(self):\n    torch.manual_seed(42)\n    self.layers = [2, 3, 2]\n    self.simple_net = core.SimpleNet(self.layers)\n  \n  def test__init__(self):\n    assert isinstance(self.simple_net.layers, torch.nn.ModuleList)\n    assert len(self.simple_net.layers) == 2\n\n    assert self.simple_net.layers[0].in_features == 2\n    assert self.simple_net.layers[0].out_features == 3\n\n    assert self.simple_net.layers[1].in_features == 3\n    assert self.simple_net.layers[1].out_features == 2\n\n  @mock.patch(""fastai.core.to_gpu"", lambda x, *args, **kwargs: x)\n  def test_forward(self):\n    x = core.V(np.array([[1., 2.]]), requires_grad=False)\n    output = core.to_np(self.simple_net.forward(x))\n\n    np.testing.assert_almost_equal(output, [[-1.435481, -0.27181]], decimal=4)\n\n@tempdir()\ndef test_save_load(tempdir):\n  array = np.arange(0, 5)\n  core.save(f""{tempdir.path}/data.pk"", array)\n\n  data = core.load(f""{tempdir.path}/data.pk"")\n  np.testing.assert_equal(data, [0, 1, 2, 3, 4])\n\n@mock.patch(""pickle.load"")\n@mock.patch(""builtins.open"")\ndef test_load2(open_mock, load_mock):\n  core.load2(""filename.pk"")\n\n  assert load_mock.call_args[1][\'encoding\'] == \'iso-8859-1\'\n\n@tempdir()\ndef test_load_array(tempdir):\n  rootdir=tempdir.path\n  bcolz.carray(np.arange(0,5), mode=\'w\', rootdir=rootdir)\n\n  array = core.load_array(rootdir)\n  np.testing.assert_equal(array, [0, 1, 2, 3, 4])\n\ndef test_chunk_iter():\n  nums = iter(range(10))\n\n  chunks = core.chunk_iter(nums, chunk_size=3)\n  assert list(chunks) == [\n    [0, 1, 2],\n    [3, 4, 5],\n    [6, 7, 8],\n    [9]\n  ]\n\n@mock.patch(""fastai.core.torch"")\n@mock.patch(""contextlib.suppress"")\ndef test_set_grad_enabled(suppress_mock, torch_mock):\n  torch_mock.set_grad_enabled = Mock()\n\n  with mock.patch(""fastai.core.IS_TORCH_04"", True):\n    core.set_grad_enabled(""foo"")\n    torch_mock.set_grad_enabled.assert_called_with(""foo"")\n\n  with mock.patch(""fastai.core.IS_TORCH_04"", False):\n    core.set_grad_enabled(""foo"")\n    suppress_mock.assert_called_once()\n\n@mock.patch(""fastai.core.torch"")\n@mock.patch(""contextlib.suppress"")\ndef test_no_grad(suppress_mock, torch_mock):\n  torch_mock.no_grad = Mock()\n\n  with mock.patch(""fastai.core.IS_TORCH_04"", True):\n    core.no_grad_context()\n    torch_mock.no_grad.assert_called_once()\n\n  with mock.patch(""fastai.core.IS_TORCH_04"", False):\n    core.no_grad_context()\n    suppress_mock.assert_called_once()\n\n'"
old/tests/test_dataset.py,0,"b'from pathlib import Path\nimport pytest\n\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport os\n\nfrom fastai.dataset import ImageClassifierData\nfrom fastai.model import resnet34\nfrom fastai.transforms import tfms_from_model\n\n\n@pytest.fixture(scope=\'module\')\ndef root_folder(tmpdir_factory):\n    return tmpdir_factory.mktemp(\'tmp_img_data\')\n\n\n@pytest.fixture(scope=\'module\')\ndef csv_file(root_folder):\n    tmp_csv_file = root_folder.mkdir(\n        \'tmp_csv_folder\').join(\'tmp_csv_file.csv\')\n    df_list = [{\'id\': 11-i, \'label\': chr(ord(\'a\') + 10 - i)}\n               for i in range(1, 11)]  # Create CSV with rows as (10, \'j\'), (9, \'i\') .. (1, \'a\')\n    df = pd.DataFrame(df_list)\n    df.to_csv(str(tmp_csv_file), index=False)\n    return tmp_csv_file\n\n\n@pytest.fixture(scope=\'module\')\ndef data_folder(root_folder):\n    folder = root_folder.mkdir(\'tmp_data_folder\')\n    for i in range(1, 11):  # Create folder with images ""1.png"", ""2.png""..""10.png""\n        img_array = np.random.rand(100, 100, 3) * 255\n        img = Image.fromarray(img_array.astype(\'uint8\')).convert(\'RGBA\')\n        img.save(str(folder.join(str(i) + \'.png\')))\n    return folder\n\n\ndef test_image_classifier_data_from_csv_unsorted(root_folder, csv_file, data_folder):\n    val_idxs = [2, 3]\n    tfms = tfms_from_model(resnet34, 224)\n    path = str(root_folder)\n    folder = \'tmp_data_folder\'\n    csv_fname = Path(str(csv_file))\n    data = ImageClassifierData.from_csv(path=Path(\n        path), folder=folder, csv_fname=csv_fname, val_idxs=val_idxs, suffix=\'.png\', tfms=tfms)\n    val_fnames = [\'8.png\', \'7.png\']\n    assert [os.path.split(o)[-1]\n            for o in data.val_ds.fnames.tolist()] == val_fnames\n'"
old/tests/test_layer_optimizer.py,0,"b""import pytest\n\nfrom fastai.layer_optimizer import LayerOptimizer\n\n\nclass Par(object):\n    def __init__(self, x, grad=True):\n        self.x = x\n        self.requires_grad = grad\n    def parameters(self): return [self]\n\nclass FakeOpt(object):\n    def __init__(self, params): self.param_groups = params\n\ndef params_(*names): return [Par(nm) for nm in names]\n\ndef check_optimizer_(opt, expected):\n    actual = opt.param_groups\n    assert len(actual) == len(expected)\n    for (a, e) in zip(actual, expected): check_param_(a, *e)\n    \ndef check_param_(par, nm, lr, wd):\n    assert par['params'][0].x == nm\n    assert par['lr'] == lr\n    assert par['weight_decay'] == wd\n\n\ndef test_construction_with_singleton_lr_and_wd():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    check_optimizer_(lo.opt, [(nm, 1e-2, 1e-4) for nm in 'ABC'])\n\ndef test_construction_with_lists_of_lrs_and_wds():\n    lo = LayerOptimizer(\n        FakeOpt,\n        params_('A', 'B', 'C'),\n        (1e-2, 2e-2, 3e-2),\n        (9e-3, 8e-3, 7e-3),\n    )\n    check_optimizer_(\n        lo.opt,\n        [('A', 1e-2, 9e-3), ('B', 2e-2, 8e-3), ('C', 3e-2, 7e-3)],\n    )\n\ndef test_construction_with_too_few_lrs():\n    with pytest.raises(AssertionError):\n        LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), (1e-2, 2e-2), 1e-4)\n\ndef test_construction_with_too_few_wds():\n    with pytest.raises(AssertionError):\n        LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, (9e-3, 8e-3))\n\ndef test_set_lrs_with_single_value():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    lo.set_lrs(1e-3)\n    check_optimizer_(lo.opt, [(nm, 1e-3, 1e-4) for nm in 'ABC'])\n\ndef test_set_lrs_with_list_of_values():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    lo.set_lrs([2e-2, 3e-2, 4e-2])\n    check_optimizer_(\n        lo.opt,\n        [('A', 2e-2, 1e-4), ('B', 3e-2, 1e-4), ('C', 4e-2, 1e-4)],\n    )\n\ndef test_set_lrs_with_too_few_values():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    with pytest.raises(AssertionError):\n        lo.set_lrs([2e-2, 3e-2])\n    # Also make sure the optimizer didn't change.\n    check_optimizer_(lo.opt, [(nm, 1e-2, 1e-4) for nm in 'ABC'])\n    \ndef test_set_wds_with_single_value():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    lo.set_wds(1e-5)\n    check_optimizer_(lo.opt, [(nm, 1e-2, 1e-5) for nm in 'ABC'])\n\ndef test_set_wds_with_list_of_values():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    lo.set_wds([9e-3, 8e-3, 7e-3])\n    check_optimizer_(\n        lo.opt,\n        [('A', 1e-2, 9e-3), ('B', 1e-2, 8e-3), ('C', 1e-2, 7e-3)],\n    )\n\ndef test_set_wds_with_too_few_values():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    with pytest.raises(AssertionError):\n        lo.set_wds([9e-3, 8e-3])\n    # Also make sure the optimizer didn't change.\n    check_optimizer_(lo.opt, [(nm, 1e-2, 1e-4) for nm in 'ABC'])\n"""
old/tests/test_lsuv_initializer.py,2,"b""import pytest\n\nfrom fastai.core import VV\nfrom fastai.lsuv_initializer import apply_lsuv_init\n\nimport cv2\nimport numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n\n@pytest.fixture\ndef image_data():\n    images_to_process = []\n    for img_fname in os.listdir('fastai/images'):\n        img = cv2.imread(os.path.join('fastai/images', img_fname))\n        images_to_process.append(np.transpose(cv2.resize(img, (224,224)), (2,0,1)))\n    data = np.array(images_to_process).astype(np.float32)\n    return VV(torch.from_numpy(data)).cpu()\n\n\ndef add_hooks(m, fn):\n    hooks = []\n    def add_hook(m):\n        if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n            hooks.append(m.register_forward_hook(fn))\n    m.apply(add_hook)\n    return hooks\ndef remove_hooks(hooks): [h.remove() for h in hooks]\n\ndef run_with_capture(m, data):\n    activation_variances = []\n    def capture_hook(self, input, output):\n        activation_variances.append(np.var(output.data.cpu().numpy()))\n    hooks = add_hooks(m, capture_hook)\n    m(data)\n    remove_hooks(hooks)\n    return activation_variances\n\ndef test_fast_initialization_without_orthonormal(image_data):\n    alexnet = models.alexnet(pretrained=False)\n    pre_init_var = run_with_capture(alexnet, image_data)\n    assert pre_init_var[0] >= 1000  # the first few pre-init variances are huge,\n    assert pre_init_var[1] >= 100   # even larger than these conservative tests.\n\n    tol = 0.1\n    alexnet = apply_lsuv_init(alexnet, image_data, std_tol=tol, do_orthonorm=False, cuda=False)\n    *post_init_var, final_var = run_with_capture(alexnet, image_data)\n    for var in post_init_var:\n        assert 2 <= var <= 4\n    assert final_var == pytest.approx(1, tol**2)\n"""
old/tests/test_samplers.py,0,"b'import numpy as np\n\nfrom fastai.text import SortSampler, SortishSampler\n\n\ndef test_sort_sampler_sorts_all_descending():\n    bs = 4\n    n = bs*100\n    data = 2 * np.arange(n)\n    samp = list(SortSampler(data, lambda i: data[i]))\n\n    # The sample is a permutation of the indices.\n    assert sorted(samp) == list(range(n))\n    # And that ""permutation"" is for descending data order.\n    assert all(s1 > s2 for s1, s2 in zip(samp, samp[1:]))\n\n\ndef test_sortish_sampler_sorts_each_batch_descending():\n    bs = 4\n    n = bs*100\n    data = 2 * np.arange(n)\n    samp = list(SortishSampler(data, lambda i: data[i], bs))\n\n    # The sample is a permutation of the indices.\n    assert sorted(samp) == list(range(n))\n    # And that permutation is kind of reverse sorted.\n    assert all(\n        s1 > s2 or (i+1) % bs == 0  # don\'t check batch boundaries\n        for i, (s1, s2) in enumerate(zip(samp, samp[1:]))\n    )\n    assert samp[0] == max(samp)\n'"
old/tests/test_structured.py,0,"b""import pytest\nfrom fastai.structured import proc_df\nimport pandas as pd\nimport numpy as np\n\ndef test_proc_df_fix_missing():\n    y_col = 'target'\n\n    df_train = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2], 'target': [1, 0, 1]})\n    df_test = pd.DataFrame({'col1' : [1, 2, np.NaN], 'col2' : [5, np.NaN, 2]})\n\n    # Assume test is the same as train but without target column\n    assert len(set(df_train.columns) - set([y_col])) == len(set(df_test.columns))\n\n    X_train, y_train, nas_train = proc_df(df_train, y_fld=y_col)\n    # We are expecting nas_train to contain one column\n    assert len(nas_train) == 1\n\n    original_nas_length = len(nas_train)\n    X_test, _, nas_test = proc_df(df_test, y_fld=None, na_dict=nas_train)\n    # We expect nas_train to be unchanged\n    assert len(nas_train) == original_nas_length\n\n    # We are expecting nas_test to contain two columns\n    assert len(nas_test) == 2\n\n    # We are expecting the test set to have the same columns as train set because we have used the na_dict from train set\n    assert set(X_train.columns) == set(X_test.columns)\n"""
old/tests/test_transform.py,0,"b'import numpy as np\nimport pytest\n\nfrom fastai.transforms import *\n\nt_rand_img128x128x1 = np.random.uniform(size=[128,128,1])\nt_rand_img128x128x3 = np.random.uniform(size=[128,128,3])\n#\n# # as per https://stackoverflow.com/questions/7100242/python-numpy-first-occurrence-of-subarray\n# def rolling_window(a, size):\n#     shape = a.shape[:-1] + (a.shape[-1] - size + 1, size)\n#     strides = a.strides + (a. strides[-1],)\n#     return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n\n\ndef test_scale_min_works_with_masks():\n    mask = np.ones([128, 256], dtype=np.float32)\n    mask[0:64,0:128] = 20\n\n    em = np.array([[20., 20., 1., 1.],\n                   [1., 1., 1., 1.]], dtype=np.float32)\n    msmall = scale_min(mask, 2, cv2.INTER_NEAREST)\n    np.testing.assert_equal(msmall, em, ""sacle_min can scale down a mask"")\n    \n    mlarge = scale_min(msmall, 128, cv2.INTER_NEAREST)\n    np.testing.assert_equal(mlarge, mask, ""sacle_min can scale up a mask"")\n\ndef test_scale_min_works_with_rgb():\n    r_layer = np.ones([128, 256], dtype=np.float32)\n    r_layer[0:64, 0:128] = 0.5\n    im = np.stack([r_layer, np.zeros_like(r_layer), np.ones_like(r_layer)], axis=-1)\n\n    r_layer_small = np.array([[0.5, 0.5, 1., 1.],\n                              [1., 1., 1., 1.]])\n    im_small = scale_min(im, 2, cv2.INTER_AREA)\n    np.testing.assert_equal(im_small[..., 0], r_layer_small, ""sacle_min can scale down an rgb image"")\n    assert im_small[..., 1].sum() == 0, ""sacle_min can scale down an rgb image""\n    assert im_small[..., 2].max() == im_small[..., 2].min() == 1, ""sacle_min can scale down an rgb image""\n\n    im_large = scale_min(im_small, 128, cv2.INTER_AREA)\n    np.testing.assert_equal(im_large[..., 0], r_layer, ""sacle_min can scale up an rgb image"")\n    assert im_large[..., 1].sum() == 0, ""sacle_min can scale down an rgb image""\n    assert im_large[..., 2].max() == im_large[..., 2].min() == 1, ""sacle_min can scale down an rgb image""\n    \n\ndef test_zoom_cv():\n    r_layer = np.array([[0, 0, 0, 0, 0],\n                        [0, 0, 0, 0, 0],\n                        [0, 0, 1, 0, 0],\n                        [0, 0, 0, 0, 0],\n                        [0, 0, 0, 0, 0], ], dtype=np.float32)\n    im = np.stack([r_layer, np.zeros_like(r_layer), np.ones_like(r_layer)], axis=-1)\n    np.testing.assert_equal(zoom_cv(im, 0), im, ""Z==0 leaves image unchanged"")\n    # TODO: Figure out why the circle is moved slightly to the top left corner.\n    expect = np.array([[0,      0,       0,       0,       0.],\n                       [0,      0.01562, 0.12109, 0.00391, 0.],\n                       [0,      0.12109, 0.93848, 0.03027, 0.],\n                       [0,      0.00391, 0.03027, 0.00098, 0.],\n                       [0,      0,       0,       0,       0.],], dtype=np.float32)\n    actual = zoom_cv(im, 0.1)[..., 0]\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\ndef test_stretch_cv():\n    im = np.array([[0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0],\n                   [0, 0, 1, 0, 0],\n                   [0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0], ], dtype=np.float32)\n    np.testing.assert_equal(stretch_cv(im, sr=0, sc=0), im, ""sr==0 && sc==0 leaves image unchanged"")\n\n    expect = np.array([[0,      0,      0,       0,       0.],\n                       [0,      0.,     0,       0,       0.],\n                       [0,      0.,     0.64,    0.24,    0.],\n                       [0,      0.,     0.24,    0.09,    0.],\n                       [0,      0,      0,       0,       0.],], dtype=np.float32)\n    actual = stretch_cv(im, 0.1, 0.1)\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\n    expect = np.array([[0, 0, 0, 0, 0],\n                       [0, 0, 0, 0, 0],\n                       [0, 0, 1, 1, 0],\n                       [0, 0, 0, 0, 0],\n                       [0, 0, 0, 0, 0], ], dtype=np.float32)\n    actual = stretch_cv(im, 1, 0)\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\n    expect = np.array([[0, 0, 0, 0, 0],\n                       [0, 0, 0, 0, 0],\n                       [0, 0, 1, 1, 0],\n                       [0, 0, 1, 1, 0],\n                       [0, 0, 0, 0, 0], ], dtype=np.float32)\n    actual = stretch_cv(im, 1, 1)\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\n    expect = np.array([[0, 0, 0, 0, 0],\n                       [0, 1, 1, 1, 0],\n                       [0, 1, 1, 1, 0],\n                       [0, 1, 1, 1, 0],\n                       [0, 0, 0, 0, 0], ], dtype=np.float32)\n    actual = stretch_cv(im, 2, 2)\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\n@pytest.mark.skip(reason=""It does not work for some reason see #429"")\ndef test_zoom_cv_equals_stretch_cv():\n    im = np.array([[0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0],\n                   [0, 0, 1, 0, 0],\n                   [0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0], ], dtype=np.float32)\n\n    np.testing.assert_array_almost_equal(zoom_cv(im, 2), stretch_cv(im, 2, 2), decimal=4)\n\ndef test_dihedral():\n    im = np.array([\n        [0.,   0.1,  0.,  ],\n        [0.01, 0.2,  0.03,],\n        [0.,   0.3,  0.,  ],])\n    e = im\n    a = dihedral(im, 0)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.03, 0.,  ],\n        [0.1,  0.2,  0.3, ],\n        [0.,   0.01, 0.,  ]])\n    a = dihedral(im, 1)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.3,  0.,  ],\n        [0.03, 0.2,  0.01,],\n        [0.,   0.1,  0.,  ]])\n    a = dihedral(im, 2)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.01, 0.,  ],\n        [0.3,  0.2,  0.1, ],\n        [0.,   0.03, 0.,  ]])\n    a = dihedral(im, 3)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.1,  0.,  ],\n        [0.03, 0.2,  0.01,],\n        [0.,   0.3,  0.,  ]])\n    a = dihedral(im, 4)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.03, 0.,  ],\n        [0.3,  0.2,  0.1, ],\n        [0.,   0.01, 0.,  ]])\n    a = dihedral(im, 5)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.3,  0.,  ],\n        [0.01, 0.2,  0.03,],\n        [0.,   0.1,  0.,  ]])\n    a = dihedral(im, 6)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.01, 0.,  ],\n        [0.1,  0.2,  0.3, ],\n        [0.,   0.03, 0.,  ]])\n    a = dihedral(im, 7)\n    np.testing.assert_array_equal(a, e)\n\ndef test_lighting():\n    im = np.array([\n        [0.,   0.1,  0.,  ],\n        [0.01, 0.2,  0.03,],\n        [0.,   0.3,  0.,  ],])\n    e = im\n    a = lighting(im, 0, 1)\n    # TODO: better test taht allows for visual inspection\n    np.testing.assert_array_equal(a, e)\n    e =np.array([[0.5 , 0.6 , 0.5 ],\n                [0.51, 0.7 , 0.53],\n                [0.5 , 0.8 , 0.5 ]], dtype=np.float32)\n    a = lighting(im, 0.5, 1)\n    np.testing.assert_array_equal(a, e)\n\ndef test_rotate_cv():\n    im = np.array([\n        [0.,   0.1,  0., ],\n        [0.,   0.2,  0., ],\n        [0.,   0.3,  0., ],])\n    a = rotate_cv(im, 90)\n    e = np.array([[0. , 0. , 0. ],\n                  [0.1, 0.2, 0.3],\n                  [0. , 0. , 0. ],])\n    np.testing.assert_array_equal(a, e)\n\ndef test_rotate_cv_vs_dihedral():\n    im = np.array([\n        [0.,   0.1,  0., ],\n        [0.,   0.2,  0., ],\n        [0.,   0.3,  0., ],])\n    a = rotate_cv(im, 180)\n    e = dihedral(im, 6)\n    np.testing.assert_array_equal(a, e)\n\ndef test_no_crop():\n    im = np.array([\n        [0.,   0.1,  0., ],\n        [0.,   0.2,  0., ],])\n    a = no_crop(im, 4)\n    e = np.array([[0. , 0.066 , 0.066, 0 ],\n                  [0,   0.066,  0.066, 0 ],\n                  [0. , 0.133 , 0.133, 0 ],\n                  [0. , 0.133 , 0.133, 0 ]])\n    np.testing.assert_array_almost_equal(a, e, decimal=3)\n\ndef test_center_crop():\n    im = np.array([\n        [0.,   0.1,  0.,  ],\n        [0.01, 0.2,  0.03,],\n        [0.,   0.3,  0.,  ],])\n    a = center_crop(im, 1)\n    e = np.array([[0.2]])\n    np.testing.assert_array_equal(a, e)\n    im = np.array([\n        [0.,   0.1,  0.,  0],\n        [0.01, 0.2,  0.9, 0.04],\n        [0.,   0.3,  0.,  0],])\n    a = center_crop(im, 1)\n    e = np.array([[0.9]])\n    np.testing.assert_array_equal(a, e)\n\ndef test_googlenet_resize():\n    # TODO: figure out how to test this in a way it make sense\n    pass\n\n#This test will fail because the hole cut out can be near the edage of the picture.\n#TODO: figure out how to test this better.\n#def test_cutout():\n#    im = np.ones([128,128,3], np.float32)\n#    with_holes = cutout(im, 1, 10)\n#    assert (with_holes == 0).sum() == 300, ""There is one cut out hole 10px x 10px in size (over 3 channels)""\n\ndef test_scale_to():\n    h=10\n    w=20\n    ratio = 127./h\n    assert scale_to(h, ratio, 127) == 127\n    assert scale_to(w, ratio, 127) == 254\n\ndef test_crop():\n    im = np.ones([128,128,3], np.float32)\n    assert crop(im, 1, 1, 10).shape == (10,10,3)\n\ndef test_to_bb():\n    im = np.array([[0, 0, 0, 0, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 0, 0, 0, 0], ], dtype=np.float32)\n    expect = [1,1,3,3]\n    np.testing.assert_array_equal(to_bb(im, ""not used""), expect)\n\n### tests for transformation objects\ndef test_RandomCrop():\n    tfm = RandomCrop(23)\n    x = t_rand_img128x128x1\n    x2, cls = tfm(x, None)\n    assert x2.shape == (23,23,1)\n\ndef test_AddPadding():\n    tfm = AddPadding(1)\n    x = t_rand_img128x128x3\n    x2, cls = tfm(x, None)\n    assert x2.shape == (130,130,3)\n\ndef test_CenterCrop():\n    tfm = CenterCrop(10)\n    x = t_rand_img128x128x3\n    x2, cls = tfm(x, None)\n    assert x2.shape == (10,10,3)\n\ndef test_NoCrop():\n    tfm = NoCrop(10)\n    x = t_rand_img128x128x3\n    x2, cls = tfm(x, None)\n    assert x2.shape == (10,10,3)\n\ndef test_applying_tranfrom_multiple_times_reset_the_state():\n    tfm = RandomScale(10, 1000, p=1)\n    x1,_ = tfm(t_rand_img128x128x3, None)\n    x2,_ = tfm(t_rand_img128x128x3, None)\n    x3,_ = tfm(t_rand_img128x128x3, None)\n    assert x1.shape[0] != x2.shape[0] or x1.shape[0] != x3.shape[0], ""Each transfromation should give a bit different shape""\n    assert x1.shape[0] < 10000\n    assert x2.shape[0] < 10000\n    assert x3.shape[0] < 10000\n\nstats = inception_stats\ntfm_norm = Normalize(*stats, tfm_y=TfmType.COORD)\ntfm_denorm = Denormalize(*stats)\nbuggy_offset = 2  # This is a bug in the current transform_coord, I will fix it in the next commit\n\ndef test_transforms_works_with_coords(): # test of backward compatible behavior\n    sz = 16\n    transforms = image_gen(tfm_norm, tfm_denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=CropType.NO,\n              tfm_y=TfmType.COORD, sz_y=sz, pad_mode=cv2.BORDER_REFLECT)\n\n    x, y = transforms(t_rand_img128x128x3, np.array([0,0,128,128, 0,0,64,64]))\n    bbs = partition(y, 4)\n    assert x.shape[0] == 3, ""The image was converted from NHWC to NCHW (channle first pytorch format)""\n\n    h,w = x.shape[1:]\n    np.testing.assert_equal(bbs[0], [0, 0, h-buggy_offset, w-buggy_offset], ""The outer bounding box was converted correctly"")\n    np.testing.assert_equal(bbs[1], [0, 0, h/2-buggy_offset, w/2-buggy_offset], ""The inner bounding box was converted correctly"")\n'"
old/tutorials/__init__.py,0,"b""import sys\nsys.path.insert(0, '../')\n\n"""
old/tutorials/kmeans.py,0,"b'import tensorflow as tf\nimport math, numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef plot_data(centroids, data, n_samples):\n    colour = plt.cm.rainbow(np.linspace(0,1,len(centroids)))\n    for i, centroid in enumerate(centroids):\n        samples = data[i*n_samples:(i+1)*n_samples]\n        plt.scatter(samples[:,0], samples[:,1], c=colour[i], s=1)\n        plt.plot(centroid[0], centroid[1], markersize=10, marker=""x"", color=\'k\', mew=5)\n        plt.plot(centroid[0], centroid[1], markersize=5, marker=""x"", color=\'m\', mew=2)\n\n        \ndef all_distances(a, b):\n    diff = tf.squared_difference(tf.expand_dims(a, 0), tf.expand_dims(b,1))\n    return tf.reduce_sum(diff, axis=2)\n        \n        \nclass Kmeans(object):\n\n    def __init__(self, data, n_clusters):\n        self.n_data, self.n_dim = data.shape\n        self.n_clusters = n_clusters\n        self.data = data\n        self.v_data = tf.Variable(data)\n        self.n_samples = self.n_data//self.n_clusters\n\n    def run(self):\n        tf.global_variables_initializer().run()\n        initial_centroids = self.find_initial_centroids(self.n_clusters).eval()\n        curr_centroids = tf.Variable(initial_centroids)\n        nearest_indices = self.assign_to_nearest(curr_centroids)\n        updated_centroids = self.update_centroids(nearest_indices)\n        # Begin main algorithm\n        tf.global_variables_initializer().run()\n        c = initial_centroids\n        for i in range(10):\n            c2 = curr_centroids.assign(updated_centroids).eval()\n            if np.allclose(c,c2): break\n            c=c2\n        return c2\n\n\n    def find_initial_centroids(self, k):\n        r_index = tf.random_uniform([1], 0, self.n_data, dtype=tf.int32)\n        r = tf.expand_dims(self.v_data[tf.squeeze(r_index)], dim=1)\n        initial_centroids = []\n        for i in range(k):\n            dist = all_distances(self.v_data, r)\n            farthest_index = tf.argmax(tf.reduce_min(dist, axis=0), 0)\n            farthest_point = self.v_data[tf.to_int32(farthest_index)]\n            initial_centroids.append(farthest_point)\n            r = tf.stack(initial_centroids)\n        return r\n\n    def choose_random_centroids(self):\n        n_samples = tf.shape(v_data)[0]\n        random_indices = tf.random_shuffle(tf.range(0, n_samples))\n        centroid_indices = random_indices[:self.n_clusters]\n        return tf.gather(self.v_data, centroid_indices)\n\n    def assign_to_nearest(self, centroids):\n        return tf.argmin(all_distances(self.v_data, centroids), 0)\n\n    def update_centroids(self, nearest_indices):\n        partitions = tf.dynamic_partition(self.v_data, tf.to_int32(nearest_indices), self.n_clusters)\n        return tf.concat([tf.expand_dims(tf.reduce_mean(partition, 0), 0)\n                                      for partition in partitions], 0)\n   \n        '"
tests/utils/fakes.py,3,"b'from fastai.basics import *\n\nclass RandomItem(ItemBase):\n    ""An random `ItemBase` of size `noise_sz`.""\n    def __init__(self, *sizes): self.obj,self.data = sizes,torch.randn(*sizes)\n    def __str__(self):  return f\'Size {self.obj}\\n{self.data}\'\n\n    @classmethod\n    def from_val(cls, t):\n        res = cls(*t.size())\n        res.data = t\n        return res\n\nclass RandomLabel(ItemBase):\n    ""An random `ItemBase` of size `noise_sz`.""\n    def __init__(self, y_range): self.obj,self.data = y_range,torch.randint(*y_range, ())\n    def __str__(self):  return f\'{self.data.item()}\'\n\n    @classmethod\n    def from_val(cls, t):\n        res = cls([0,t.item()+1])\n        res.data = t\n        return res\n\nclass RandomLabelList(ItemList):\n    ""An random `ItemBase` of size `noise_sz`.""\n    def __init__(self, items, y_range:Collection[int]=None, **kwargs):\n        super().__init__(items, **kwargs)\n        self.y_range = y_range\n        self.copy_new.append(\'y_range\')\n\n    def get(self, i):  return RandomLabel(self.y_range)\n    def reconstruct(self, t): return RandomLabel.from_val(t)\n\nclass RandomItemList(ItemList):\n    _label_cls = RandomLabelList\n    def __init__(self, items, sizes:Collection[int]=None, **kwargs):\n        super().__init__(items, **kwargs)\n        self.sizes = sizes\n        self.copy_new.append(\'sizes\')\n\n    def get(self, i): return RandomItem(*self.sizes)\n    def reconstruct(self, t): return RandomItem.from_val(t)\n\n    def show_xys(self, xs, ys, **kwargs):\n        res = [f\'{x},{y}\' for x,y in zip(xs, ys)]\n        print(\'\\n\'.join(res))\n\n    def show_xyzs(self, xs, ys, zs, **kwargs):\n        res = [f\'{x},{y},{z}\' for x,y,z in zip(xs, ys, zs)]\n        print(\'\\n\'.join(res))\n\ndef fake_basedata(n_in:int=5,batch_size:int=5, train_length:int=None, valid_length:int=None):\n    if train_length is None: train_length = 2 * batch_size\n    if valid_length is None: valid_length = batch_size\n\n    return torch.empty([train_length+valid_length, n_in]).random_(-10, 10)\n\n\ndef fake_data(n_in:int=5, n_out:int=4, batch_size:int=5, train_length:int=None, valid_length:int=None) -> DataBunch:\n    if train_length is None: train_length = 2 * batch_size\n    if valid_length is None: valid_length = batch_size\n    return (RandomItemList([0] * (train_length+valid_length), sizes=[n_in])\n                .split_by_idx(list(range(valid_length)))\n                .label_const(0., y_range=[0,n_out])\n                .databunch(bs=batch_size))\n\ndef fake_learner(n_in:int=5, n_out:int=4, batch_size:int=5, train_length:int=None, valid_length:int=None, layer_group_count:int=1) -> Learner:\n    data = fake_data(n_in=n_in, n_out=n_out, batch_size=batch_size, train_length=train_length, valid_length=valid_length)\n    additional = [nn.Sequential(nn.Linear(n_in, n_in)) for _ in range(layer_group_count - 1)]\n    final = [nn.Sequential(nn.Linear(n_in, n_out))]\n    layer_groups = additional + final \n    model = nn.Sequential(*layer_groups)\n    learner = Learner(data, model)\n    learner.layer_groups = layer_groups\n    return learner\n'"
tests/utils/mem.py,6,"b'"""""" Helper functions for dealing with memory usage testing """"""\n\nimport pytest, torch, time\nfrom fastai.utils.mem import *\nfrom math import isclose\n\n# torch.cuda.is_available() checks if we can use NVIDIA GPU. It automatically\n# handles the case when CUDA_VISIBLE_DEVICES="""" env var is set, so even if CUDA\n# is available it will return False, thus we can emulate non-CUDA environment.\nuse_gpu = torch.cuda.is_available()\n\n# This must run before any tests that measure gpu RAM\n# force pytorch to load cuDNN and its kernels to claim unreclaimable memory (~0.5GB) if it hasn\'t done so already, so that we get correct measurements\ndef torch_preload_mem():\n    if use_gpu: torch.ones((1, 1)).cuda()\n\ndef gpu_mem_consume_some(n): return torch.ones((n, n)).cuda()\ndef gpu_mem_consume_16mb(): return gpu_mem_consume_some(2000)\ndef gpu_cache_clear(): torch.cuda.empty_cache()\ndef gpu_mem_reclaim(): gc.collect(); gpu_cache_clear()\n\ndef gpu_mem_allocate_mbs(n):\n    ""Allocate `n` MBs, return the var holding it on success, None on failure. Granularity is of 2MB (mem page size)""\n    try:    return torch.ones((n*2**18)).cuda().contiguous()\n    except: return None\n\n# this is very useful if the test needs to hit OOM, so this function will leave\n# just the requested amount of GPU free, regardless of GPU utilization or size\n# of the card\ndef gpu_mem_leave_free_mbs(n):\n    "" consume whatever memory is needed so that n MBs are left free ""\n    avail = gpu_mem_get_free()\n    assert avail > n, f""already have less available mem than desired {n}MBs""\n    consume = avail - n\n    #print(f""consuming {consume}MB to bring free mem to {n}MBs"")\n    return gpu_mem_allocate_mbs(consume, fatal=True)\n\n# must cleanup after some previously run tests that may leaked memory,\n# before starting this sensitive measurement-wise test\ndef gpu_prepare_clean_slate(): gc.collect()\n\n# ensure a thread gets a chance to run by creating a tiny pause\ndef yield_to_thread(): time.sleep(0.001)\n\n########################## validation helpers ###############################\n# these functions are for checking expected vs received (actual) memory usage in tests\n\n# number strings can be 1,000.05, so strip commas and convert to float\ndef str2flt(s): return float(s.replace(\',\',\'\'))\n\n# mtrace is GPUMemTrace.data output\n# ctx is useful as a hint for telling where in the test the trace was measured\ndef check_mtrace(used_exp, peaked_exp, mtrace, abs_tol=2, ctx=None):\n    used_rcv, peaked_rcv = mtrace.data()\n    check_mem(used_exp, peaked_exp, used_rcv, peaked_rcv, abs_tol=abs_tol, ctx=ctx)\n\ndef check_mem(used_exp, peaked_exp, used_rcv, peaked_rcv, abs_tol=2, ctx=None):\n    ctx = f"" ({ctx})"" if ctx is not None else """"\n    assert isclose(used_exp,   used_rcv,   abs_tol=abs_tol), f""used mem: expected={used_exp} received={used_rcv}{ctx}""\n    assert isclose(peaked_exp, peaked_rcv, abs_tol=abs_tol), f""peaked mem: expected={peaked_exp} received={peaked_rcv}{ctx}""\n\n# instead of asserting the following print outs the actual mem usage, to aid in debug\n# in order not to the change tests simply override `check_mem` with `report_mem` below\ndef report_mem(used_exp, peaked_exp, used_rcv, peaked_rcv, abs_tol=2, ctx=None):\n    ctx = f"" ({ctx})"" if ctx is not None else """"\n    print(f""got:\xe2\x96\xb3used={used_rcv}MBs, \xe2\x96\xb3peaked={peaked_rcv}MBs{ctx}"")\n\n# parses mtrace repr and also asserts that the `ctx` is in the repr\ndef parse_mtrace_repr(mtrace_repr, ctx):\n    ""parse the `mtrace` repr and return `used`, `peaked` ints""\n    # extract numbers + check ctx matches\n    match = re.findall(fr\'\xe2\x96\xb3Used Peaked MB: +([\\d,]+) +([\\d,]+) +\\({ctx}\\)\', mtrace_repr)\n    assert match, f""input: cs.out={mtrace_repr}, ctx={ctx}""\n    used, peaked = map(str2flt, match[0])\n    return used, peaked\n\n\n#check_mem = report_mem\n'"
tests/utils/text.py,0,"b'"""""" Helper functions for dealing with testing text outputs """"""\n\nimport sys, re\nfrom io import StringIO\n\n# When any function contains print() calls that get overwritten, like progress bars,\n# a special care needs to be applied, since under pytest -s captured output (capsys\n# or contextlib.redirect_stdout) contains any temporary printed strings, followed by\n# \\r\'s. This helper function ensures that the buffer will contain the same output\n# with and without -s in pytest, by turning:\n# foo bar\\r tar mar\\r final message\n# into:\n# final message\n# it can handle a single string or a multiline buffer\ndef apply_print_resets(buf):\n    return re.sub(r\'^.*\\r\', \'\', buf, 0, re.M)\n\ndef assert_screenout(out, what):\n    out_pr = apply_print_resets(out).lower()\n    match_str = out_pr.find(what.lower())\n    assert match_str != -1, f""expecting to find {what} in output: f{out_pr}""\n\nclass CaptureStd():\n    """""" Context manager to capture:\n    stdout, clean it up and make it available via obj.out\n    stderr, and make it available via obj.err\n\n    init arguments:\n    - out - capture stdout: True/False, default True\n    - err - capture stdout: True/False, default True\n\n    Examples:\n\n    with CaptureStdout() as cs:\n        print(""Secret message"")\n    print(f""captured: {cs.out}"")\n\n    import sys\n    with CaptureStdout() as cs:\n        print(""Warning: "", file=sys.stderr)\n    print(f""captured: {cs.err}"")\n\n    # to capture just one of the streams, but not the other\n    with CaptureStdout(err=False) as cs:\n        print(""Secret message"")\n    print(f""captured: {cs.out}"")\n    # but best use the stream-specific subclasses\n\n    """"""\n    def __init__(self, out=True, err=True):\n        if out:\n            self.out_buf = StringIO()\n            self.out = \'error: CaptureStd context is unfinished yet, called too early\'\n        else:\n            self.out_buf = None\n            self.out = \'not capturing stdout\'\n\n        if err:\n            self.err_buf = StringIO()\n            self.err = \'error: CaptureStd context is unfinished yet, called too early\'\n        else:\n            self.err_buf = None\n            self.err = \'not capturing stderr\'\n\n    def __enter__(self):\n        if self.out_buf:\n            self.out_old = sys.stdout\n            sys.stdout = self.out_buf\n\n        if self.err_buf:\n            self.err_old = sys.stderr\n            sys.stderr = self.err_buf\n\n        return self\n\n    def __exit__(self, *exc):\n        if self.out_buf:\n            sys.stdout = self.out_old\n            self.out = apply_print_resets(self.out_buf.getvalue())\n\n        if self.err_buf:\n            sys.stderr = self.err_old\n            self.err = self.err_buf.getvalue()\n\n    def __repr__(self):\n        msg = \'\'\n        if self.out_buf: msg += f""stdout: {self.out}\\n""\n        if self.err_buf: msg += f""stderr: {self.err}\\n""\n        return msg\n\n# in tests it\'s the best to capture only the stream that\'s wanted, otherwise\n# it\'s easy to miss things, so unless you need to capture both streams, use the\n# subclasses below (less typing). Or alternatively, configure `CaptureStd` to\n# disable the stream you don\'t need to test.\n\nclass CaptureStdout(CaptureStd):\n    """""" Same as CaptureStd but captures only stdout """"""\n    def __init__(self):\n        super().__init__(err=False)\n\nclass CaptureStderr(CaptureStd):\n    """""" Same as CaptureStd but captures only stderr """"""\n    def __init__(self):\n        super().__init__(out=False)\n'"
builds/custom-pip-builds/torchvision/setup.py,1,"b'#!/usr/bin/env python\nimport os\nimport io\nimport re\nimport shutil\nimport sys\nfrom setuptools import setup, find_packages\nfrom pkg_resources import get_distribution, DistributionNotFound\n\n\ndef read(*names, **kwargs):\n    with io.open(\n        os.path.join(os.path.dirname(__file__), *names),\n        encoding=kwargs.get(""encoding"", ""utf8"")\n    ) as fp:\n        return fp.read()\n\n\ndef get_dist(pkgname):\n    try:\n        return get_distribution(pkgname)\n    except DistributionNotFound:\n        return None\n\n\ndef find_version(*file_paths):\n    version_file = read(*file_paths)\n    version_match = re.search(r""^__version__ = [\'\\""]([^\'\\""]*)[\'\\""]"",\n                              version_file, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(""Unable to find version string."")\n\n\nreadme = open(\'README.rst\').read()\n\nVERSION = find_version(\'torchvision\', \'__init__.py\')\n#VERSION = find_version(\'torchvision\', \'__init__.py\') + "".post2""\n\nrequirements = [\n    \'numpy\',\n    \'six\',\n]\n#    \'torch\',\n\npillow_ver = \' >= 4.1.1\'\npillow_req = \'pillow-simd\' if get_dist(\'pillow-simd\') is not None else \'pillow\'\nrequirements.append(pillow_req + pillow_ver)\n\ntqdm_ver = \' == 4.19.9\' if sys.version_info[0] < 3 else \'\'\nrequirements.append(\'tqdm\' + tqdm_ver)\n\nsetup(\n    # Metadata\n    name=\'torchvision-nightly\',\n    version=VERSION,\n    author=\'PyTorch Core Team\',\n    author_email=\'soumith@pytorch.org\',\n    url=\'https://github.com/pytorch/vision\',\n    description=\'image and video datasets and models for torch deep learning\',\n    long_description=readme,\n    license=\'BSD\',\n\n    # Package info\n    packages=find_packages(exclude=(\'test\',)),\n\n    zip_safe=True,\n    install_requires=requirements,\n)\n'"
courses/dl1/scripts/train_planet.py,2,"b'from fast_gen import *\nfrom learner import *\nfrom pt_models import *\nfrom dataset_pt import *\nfrom sgdr_pt import *\nfrom planet import *\n\nbs=64; f_model = resnet34\npath = ""/data/jhoward/fast/planet/""\ncv_idx = int(sys.argv[1])\ntorch.cuda.set_device(cv_idx % 4)\nif cv_idx==1: torch.cuda.set_device(2)\nn=len(list(open(f\'{path}train_v2.csv\')))-1\n\ndef train_sz(sz, load=None, save_name=None, suf=None):\n    print(f\'\\n***** {sz} *****\')\n    #data=get_data_pad(f_model, path, sz, bs, n, cv_idx)\n    data=get_data_zoom(f_model, path, sz, bs, n, cv_idx)\n    learn = Learner.pretrained_convnet(f_model, data, metrics=[f2])\n    if load: learn.load(f\'{load}_{cv_idx}{suf}\')\n    print(\'--- FC\')\n    learn.fit(0.3, 2, cycle_len=1)\n    print(\'--- Gradual\')\n    for i in range(6,3,-1):\n        learn.freeze_to(i)\n        learn.fit(0.1*(i-3), 1, cycle_len=1)\n    learn.unfreeze()\n    print(\'--- All\')\n    learn.fit(0.2, 15, cycle_len=3, cycle_save_name=f\'{save_name}{suf}\')\n    learn.save(f\'{sz}_{cv_idx}{suf}\')\n\nsuf=\'_zoom\'\ntrain_sz(64, suf=suf)\ntrain_sz(128, load=64, suf=suf)\ntrain_sz(244, load=128, save_name=f\'170809_{cv_idx}\', suf=suf)\n\n'"
courses/dl2/cgan/__init__.py,0,b''
courses/dl2/cgan/test.py,0,"b""import os\nfrom options.test_options import TestOptions\nfrom data.data_loader import CreateDataLoader\nfrom models.models import create_model\nfrom util.visualizer import Visualizer\nfrom util import html\n\nopt = TestOptions().parse()\nopt.nThreads = 1   # test code only supports nThreads = 1\nopt.batchSize = 1  # test code only supports batchSize = 1\nopt.serial_batches = True  # no shuffle\nopt.no_flip = True  # no flip\n\ndata_loader = CreateDataLoader(opt)\ndataset = data_loader.load_data()\nmodel = create_model(opt)\nvisualizer = Visualizer(opt)\n# create website\nweb_dir = os.path.join(opt.results_dir, opt.name, '%s_%s' % (opt.phase, opt.which_epoch))\nwebpage = html.HTML(web_dir, 'Experiment = %s, Phase = %s, Epoch = %s' % (opt.name, opt.phase, opt.which_epoch))\n# test\nfor i, data in enumerate(dataset):\n    if i >= opt.how_many: break\n    model.set_input(data)\n    model.test()\n    visuals = model.get_current_visuals()\n    img_path = model.get_image_paths()\n    print('%04d: process image... %s' % (i, img_path))\n    visualizer.save_images(webpage, visuals, img_path, aspect_ratio=opt.aspect_ratio)\n\nwebpage.save()\n"""
courses/dl2/cgan/train.py,0,"b""import time\nfrom options.train_options import TrainOptions\nfrom data.data_loader import CreateDataLoader\nfrom models.models import create_model\nfrom util.visualizer import Visualizer\n\nopt = TrainOptions().parse()\ndata_loader = CreateDataLoader(opt)\ndataset = data_loader.load_data()\ndataset_size = len(data_loader)\nprint('#training images = %d' % dataset_size)\n\nmodel = create_model(opt)\nvisualizer = Visualizer(opt)\ntotal_steps = 0\n\nfor epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n    epoch_start_time = time.time()\n    iter_data_time = time.time()\n    epoch_iter = 0\n\n    for i, data in enumerate(dataset):\n        iter_start_time = time.time()\n        if total_steps % opt.print_freq == 0:\n            t_data = iter_start_time - iter_data_time\n        visualizer.reset()\n        total_steps += opt.batchSize\n        epoch_iter += opt.batchSize\n        model.set_input(data)\n        model.optimize_parameters()\n\n        if total_steps % opt.display_freq == 0:\n            save_result = total_steps % opt.update_html_freq == 0\n            visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)\n\n        if total_steps % opt.print_freq == 0:\n            errors = model.get_current_errors()\n            t = (time.time() - iter_start_time) / opt.batchSize\n            visualizer.print_current_errors(epoch, epoch_iter, errors, t, t_data)\n            if opt.display_id > 0:\n                visualizer.plot_current_errors(epoch, float(epoch_iter) / dataset_size, opt, errors)\n\n        if total_steps % opt.save_latest_freq == 0:\n            print('saving the latest model (epoch %d, total_steps %d)' %\n                  (epoch, total_steps))\n            model.save('latest')\n\n        iter_data_time = time.time()\n    if epoch % opt.save_epoch_freq == 0:\n        print('saving the model at the end of epoch %d, iters %d' %\n              (epoch, total_steps))\n        model.save('latest')\n        model.save(epoch)\n\n    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n    model.update_learning_rate()\n"""
courses/dl2/imdb_scripts/create_toks.py,0,"b'from fastai.text import *\nimport html\nimport fire\n\nBOS = \'xbos\'  # beginning-of-sentence tag\nFLD = \'xfld\'  # data field tag\n\nre1 = re.compile(r\'  +\')\n\n\ndef fixup(x):\n    x = x.replace(\'#39;\', ""\'"").replace(\'amp;\', \'&\').replace(\'#146;\', ""\'"").replace(\n        \'nbsp;\', \' \').replace(\'#36;\', \'$\').replace(\'\\\\n\', ""\\n"").replace(\'quot;\', ""\'"").replace(\n        \'<br />\', ""\\n"").replace(\'\\\\""\', \'""\').replace(\'<unk>\',\'u_n\').replace(\' @.@ \',\'.\').replace(\n        \' @-@ \',\'-\').replace(\'\\\\\', \' \\\\ \')\n    return re1.sub(\' \', html.unescape(x))\n\n\ndef get_texts(df, n_lbls, lang=\'en\'):\n    if len(df.columns) == 1:\n        labels = []\n        texts = f\'\\n{BOS} {FLD} 1 \' + df[0].astype(str)\n    else:\n        labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n        texts = f\'\\n{BOS} {FLD} 1 \' + df[n_lbls].astype(str)\n        for i in range(n_lbls+1, len(df.columns)): texts += f\' {FLD} {i-n_lbls+1} \' + df[i].astype(str)\n    texts = list(texts.apply(fixup).values)\n\n    tok = Tokenizer(lang=lang).proc_all_mp(partition_by_cores(texts), lang=lang)\n    return tok, list(labels)\n\n\ndef get_all(df, n_lbls, lang=\'en\'):\n    tok, labels = [], []\n    for i, r in enumerate(df):\n        print(i)\n        tok_, labels_ = get_texts(r, n_lbls, lang=lang)\n        tok += tok_\n        labels += labels_\n    return tok, labels\n\n\ndef create_toks(dir_path, chunksize=24000, n_lbls=1, lang=\'en\'):\n    print(f\'dir_path {dir_path} chunksize {chunksize} n_lbls {n_lbls} lang {lang}\')\n    try:\n        spacy.load(lang)\n    except OSError:\n        # TODO handle tokenization of Chinese, Japanese, Korean\n        print(f\'spacy tokenization model is not installed for {lang}.\')\n        lang = lang if lang in [\'en\', \'de\', \'es\', \'pt\', \'fr\', \'it\', \'nl\'] else \'xx\'\n        print(f\'Command: python -m spacy download {lang}\')\n        sys.exit(1)\n    dir_path = Path(dir_path)\n    assert dir_path.exists(), f\'Error: {dir_path} does not exist.\'\n    df_trn = pd.read_csv(dir_path / \'train.csv\', header=None, chunksize=chunksize)\n    df_val = pd.read_csv(dir_path / \'val.csv\', header=None, chunksize=chunksize)\n\n    tmp_path = dir_path / \'tmp\'\n    tmp_path.mkdir(exist_ok=True)\n    tok_trn, trn_labels = get_all(df_trn, n_lbls, lang=lang)\n    tok_val, val_labels = get_all(df_val, n_lbls, lang=lang)\n\n    np.save(tmp_path / \'tok_trn.npy\', tok_trn)\n    np.save(tmp_path / \'tok_val.npy\', tok_val)\n    np.save(tmp_path / \'lbl_trn.npy\', trn_labels)\n    np.save(tmp_path / \'lbl_val.npy\', val_labels)\n\n    trn_joined = [\' \'.join(o) for o in tok_trn]\n    open(tmp_path / \'joined.txt\', \'w\', encoding=\'utf-8\').writelines(trn_joined)\n\n\nif __name__ == \'__main__\': fire.Fire(create_toks)\n'"
courses/dl2/imdb_scripts/eval_clas.py,2,"b""import fire\nfrom fastai.text import *\nfrom fastai.lm_rnn import *\nfrom sklearn.metrics import confusion_matrix\n\ndef eval_clas(dir_path, cuda_id, lm_id='', clas_id=None, bs=64, backwards=False,\n              bpe=False):\n    print(f'dir_path {dir_path}; cuda_id {cuda_id}; lm_id {lm_id}; '\n         f'clas_id {clas_id}; bs {bs}; backwards {backwards}; bpe {bpe}')\n    if not hasattr(torch._C, '_cuda_setDevice'):\n        print('CUDA not available. Setting device=-1.')\n        cuda_id = -1\n    torch.cuda.set_device(cuda_id)\n\n    PRE = 'bwd_' if backwards else 'fwd_'\n    PRE = 'bpe_' + PRE if bpe else PRE\n    IDS = 'bpe' if bpe else 'ids'\n    dir_path = Path(dir_path)\n    lm_id = lm_id if lm_id == '' else f'{lm_id}_'\n    clas_id = lm_id if clas_id is None else clas_id\n    clas_id = clas_id if clas_id == '' else f'{clas_id}_'\n    final_clas_file = f'{PRE}{clas_id}clas_1'\n    lm_file = f'{PRE}{lm_id}lm_enc'\n    lm_path = dir_path / 'models' / f'{lm_file}.h5'\n    assert lm_path.exists(), f'Error: {lm_path} does not exist.'\n\n    bptt,em_sz,nh,nl = 70,400,1150,3\n\n    if backwards:\n        val_sent = np.load(dir_path / 'tmp' / f'val_{IDS}_bwd.npy')\n    else:\n        val_sent = np.load(dir_path / 'tmp' / f'val_{IDS}.npy')\n    val_lbls = np.load(dir_path / 'tmp' / 'lbl_val.npy').flatten()\n    val_lbls = val_lbls.flatten()\n    val_lbls -= val_lbls.min()\n    c=int(val_lbls.max())+1\n\n    val_ds = TextDataset(val_sent, val_lbls)\n    val_samp = SortSampler(val_sent, key=lambda x: len(val_sent[x]))\n    val_lbls_sampled = val_lbls[list(val_samp)]\n    val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n    md = ModelData(dir_path, None, val_dl)\n\n    if bpe: vs=30002\n    else:\n        itos = pickle.load(open(dir_path / 'tmp' / 'itos.pkl', 'rb'))\n        vs = len(itos)\n\n    m = get_rnn_classifier(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n                layers=[em_sz*3, 50, c], drops=[0., 0.])\n    learn = RNN_Learner(md, TextModel(to_gpu(m)))\n    learn.load_encoder(lm_file)\n    learn.load(final_clas_file)\n    predictions = np.argmax(learn.predict(), axis=1)\n    acc = (val_lbls_sampled == predictions).mean()\n    print('Accuracy =', acc, 'Confusion Matrix =')\n    print(confusion_matrix(val_lbls_sampled, predictions))\n\nif __name__ == '__main__': fire.Fire(eval_clas)\n\n"""
courses/dl2/imdb_scripts/finetune_lm.py,3,"b""import fire\nfrom fastai.text import *\nfrom fastai.lm_rnn import *\n\n\nclass EarlyStopping(Callback):\n    def __init__(self, learner, save_path, enc_path=None, patience=5):\n        super().__init__()\n        self.learner=learner\n        self.save_path=save_path\n        self.enc_path=enc_path\n        self.patience=patience\n    def on_train_begin(self):\n        self.best_val_loss=100\n        self.num_epochs_no_improvement=0\n    def on_epoch_end(self, metrics):\n        val_loss = metrics[0]\n        if val_loss < self.best_val_loss:\n            self.best_val_loss = val_loss\n            self.num_epochs_no_improvement = 0\n            self.learner.save(self.save_path)\n            if self.enc_path is not None:\n                self.learner.save_encoder(self.enc_path)\n        else:\n            self.num_epochs_no_improvement += 1\n        if self.num_epochs_no_improvement > self.patience:\n            print(f'Stopping - no improvement after {self.patience+1} epochs')\n            return True\n    def on_train_end(self):\n        print(f'Loading best model from {self.save_path}')\n        self.learner.load(self.save_path)\n\n\ndef train_lm(dir_path, pretrain_path, cuda_id=0, cl=25, pretrain_id='wt103', lm_id='', bs=64,\n             dropmult=1.0, backwards=False, lr=4e-3, preload=True, bpe=False, startat=0,\n             use_clr=True, use_regular_schedule=False, use_discriminative=True, notrain=False, joined=False,\n             train_file_id='', early_stopping=False):\n    print(f'dir_path {dir_path}; pretrain_path {pretrain_path}; cuda_id {cuda_id}; '\n          f'pretrain_id {pretrain_id}; cl {cl}; bs {bs}; backwards {backwards} '\n          f'dropmult {dropmult}; lr {lr}; preload {preload}; bpe {bpe};'\n          f'startat {startat}; use_clr {use_clr}; notrain {notrain}; joined {joined} '\n          f'early stopping {early_stopping}')\n\n    if not hasattr(torch._C, '_cuda_setDevice'):\n        print('CUDA not available. Setting device=-1.')\n        cuda_id = -1\n    torch.cuda.set_device(cuda_id)\n\n    PRE  = 'bwd_' if backwards else 'fwd_'\n    PRE = 'bpe_' + PRE if bpe else PRE\n    IDS = 'bpe' if bpe else 'ids'\n    train_file_id = train_file_id if train_file_id == '' else f'_{train_file_id}'\n    joined_id = 'lm_' if joined else ''\n    lm_id = lm_id if lm_id == '' else f'{lm_id}_'\n    lm_path=f'{PRE}{lm_id}lm'\n    enc_path=f'{PRE}{lm_id}lm_enc'\n\n    dir_path = Path(dir_path)\n    pretrain_path = Path(pretrain_path)\n    pre_lm_path = pretrain_path / 'models' / f'{PRE}{pretrain_id}.h5'\n    for p in [dir_path, pretrain_path, pre_lm_path]:\n        assert p.exists(), f'Error: {p} does not exist.'\n\n    bptt=70\n    em_sz,nh,nl = 400,1150,3\n    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n\n    if backwards:\n        trn_lm_path = dir_path / 'tmp' / f'trn_{joined_id}{IDS}{train_file_id}_bwd.npy'\n        val_lm_path = dir_path / 'tmp' / f'val_{joined_id}{IDS}_bwd.npy'\n    else:\n        trn_lm_path = dir_path / 'tmp' / f'trn_{joined_id}{IDS}{train_file_id}.npy'\n        val_lm_path = dir_path / 'tmp' / f'val_{joined_id}{IDS}.npy'\n\n    print(f'Loading {trn_lm_path} and {val_lm_path}')\n    trn_lm = np.load(trn_lm_path)\n    trn_lm = np.concatenate(trn_lm)\n    val_lm = np.load(val_lm_path)\n    val_lm = np.concatenate(val_lm)\n\n    if bpe:\n        vs=30002\n    else:\n        itos = pickle.load(open(dir_path / 'tmp' / 'itos.pkl', 'rb'))\n        vs = len(itos)\n\n    trn_dl = LanguageModelLoader(trn_lm, bs, bptt)\n    val_dl = LanguageModelLoader(val_lm, bs, bptt)\n    md = LanguageModelData(dir_path, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)\n\n    drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*dropmult\n\n    learner = md.get_model(opt_fn, em_sz, nh, nl,\n        dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n    learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n    learner.clip=0.3\n    learner.metrics = [accuracy]\n    wd=1e-7\n\n    lrs = np.array([lr/6,lr/3,lr,lr/2]) if use_discriminative else lr\n    if preload and startat == 0:\n        wgts = torch.load(pre_lm_path, map_location=lambda storage, loc: storage)\n        if bpe:\n            learner.model.load_state_dict(wgts)\n        else:\n            print(f'Loading pretrained weights...')\n            ew = to_np(wgts['0.encoder.weight'])\n            row_m = ew.mean(0)\n\n            itos2 = pickle.load(open(pretrain_path / 'tmp' / f'itos.pkl', 'rb'))\n            stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})\n            nw = np.zeros((vs, em_sz), dtype=np.float32)\n            nb = np.zeros((vs,), dtype=np.float32)\n            for i,w in enumerate(itos):\n                r = stoi2[w]\n                if r>=0:\n                    nw[i] = ew[r]\n                else:\n                    nw[i] = row_m\n\n            wgts['0.encoder.weight'] = T(nw)\n            wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(nw))\n            wgts['1.decoder.weight'] = T(np.copy(nw))\n            learner.model.load_state_dict(wgts)\n            #learner.freeze_to(-1)\n            #learner.fit(lrs, 1, wds=wd, use_clr=(6,4), cycle_len=1)\n    elif preload:\n        print('Loading LM that was already fine-tuned on the target data...')\n        learner.load(lm_path)\n\n    if not notrain:\n        learner.unfreeze()\n        if use_regular_schedule:\n            print('Using regular schedule. Setting use_clr=None, n_cycles=cl, cycle_len=None.')\n            use_clr = None\n            n_cycles=cl\n            cl=None\n        else:\n            n_cycles=1\n        callbacks = []\n        if early_stopping:\n            callbacks.append(EarlyStopping(learner, lm_path, enc_path, patience=5))\n            print('Using early stopping...')\n        learner.fit(lrs, n_cycles, wds=wd, use_clr=(32,10) if use_clr else None, cycle_len=cl,\n                    callbacks=callbacks)\n        learner.save(lm_path)\n        learner.save_encoder(enc_path)\n    else:\n        print('No more fine-tuning used. Saving original LM...')\n        learner.save(lm_path)\n        learner.save_encoder(enc_path)\n\nif __name__ == '__main__': fire.Fire(train_lm)\n"""
courses/dl2/imdb_scripts/merge_wiki.py,0,"b'""""""\nScript to merge\n""""""\n\nimport argparse\nfrom pathlib import Path\nimport json\nimport csv\n\n\ndef get_texts(root):\n    for dir_ in root.iterdir():\n        for wiki_file in dir_.iterdir():\n            with open(wiki_file, encoding=\'utf-8\') as f_in:\n                for line in f_in:\n                    article = json.loads(line)\n                    text = article[\'text\']\n                    yield text\n\n\ndef write_file(file_path, text_iter, num_tokens):\n    total_num_tokens = 0\n    print(f\'Writing to {file_path}...\')\n    j = 0\n    with open(file_path, \'w\', encoding=\'utf-8\') as f_out:\n        writer = csv.writer(f_out)\n        for i, text in enumerate(text_iter):\n            j += 1\n            writer.writerow([text])\n            # f_out.write(text)\n\n            # calculate approximate length based on tokens\n            total_num_tokens += len(text.split())\n            if total_num_tokens > num_tokens:\n                break\n            if i % 10000 == 0:\n                print(\'Processed {:,} documents. Total # tokens: {:,}.\'.format(i, total_num_tokens))\n    print(\'{}. # documents: {:,}. # tokens: {:,}.\'.format(\n        file_path, j, total_num_tokens))\n\n\ndef main(args):\n\n    input_path = Path(args.input)\n    output = Path(args.output)\n    assert input_path.exists(), f\'Error: {input_path} does not exist.\'\n    output.mkdir(exist_ok=True)\n\n    train_path = output.joinpath(\'train.csv\')\n    val_path = output.joinpath(\'val.csv\')\n    text_iter = get_texts(input_path)\n    write_file(train_path, text_iter, args.num_tokens)\n    write_file(val_path, text_iter, args.num_tokens / 10)\n\n\nif __name__ == \'__main__\':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-i\', \'--input\', required=True,\n                        help=\'the directory where the Wikipedia data extracted \'\n                             \'with WikiExtractor.py is located. Consists of \'\n                             \'directories AA, AB, AC, etc.\')\n    parser.add_argument(\'-o\', \'--output\', required=True,\n                        help=\'the output directory where the merged Wikipedia \'\n                             \'documents should be saved\')\n    parser.add_argument(\'-n\', \'--num-tokens\', type=int, default=100000000,\n                        help=\'the #\xc2\xa0of tokens that the merged document should \'\n                             \'contain (default: 100M)\')\n    args = parser.parse_args()\n    main(args)\n'"
courses/dl2/imdb_scripts/predict_with_classifier.py,2,"b'from fastai.text import *\n\nimport fire\n\n\ndef load_model(itos_filename, classifier_filename, num_classes):\n    """"""Load the classifier and int to string mapping\n\n    Args:\n        itos_filename (str): The filename of the int to string mapping file (usually called itos.pkl)\n        classifier_filename (str): The filename of the trained classifier\n\n    Returns:\n        string to int mapping, trained classifer model\n    """"""\n\n    # load the int to string mapping file\n    itos = pickle.load(Path(itos_filename).open(\'rb\'))\n    # turn it into a string to int mapping (which is what we need)\n    stoi = collections.defaultdict(lambda:0, {str(v):int(k) for k,v in enumerate(itos)})\n\n    # these parameters aren\'t used, but this is the easiest way to get a model\n    bptt,em_sz,nh,nl = 70,400,1150,3\n    dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5\n    vs = len(itos)\n\n    model = get_rnn_classifer(bptt, 20*70, num_classes, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n            layers=[em_sz*3, 50, num_classes], drops=[dps[4], 0.1],\n            dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n\n    # load the trained classifier\n    model.load_state_dict(torch.load(classifier_filename, map_location=lambda storage, loc: storage))\n\n    # put the classifier into evaluation mode\n    model.reset()\n    model.eval()\n\n    return stoi, model\n\n\ndef softmax(x):\n    \'\'\'\n    Numpy Softmax, via comments on https://gist.github.com/stober/1946926\n\n    >>> res = softmax(np.array([0, 200, 10]))\n    >>> np.sum(res)\n    1.0\n    >>> np.all(np.abs(res - np.array([0, 1, 0])) < 0.0001)\n    True\n    >>> res = softmax(np.array([[0, 200, 10], [0, 10, 200], [200, 0, 10]]))\n    >>> np.sum(res, axis=1)\n    array([ 1.,  1.,  1.])\n    >>> res = softmax(np.array([[0, 200, 10], [0, 10, 200]]))\n    >>> np.sum(res, axis=1)\n    array([ 1.,  1.])\n    \'\'\'\n    if x.ndim == 1:\n        x = x.reshape((1, -1))\n    max_x = np.max(x, axis=1).reshape((-1, 1))\n    exp_x = np.exp(x - max_x)\n    return exp_x / np.sum(exp_x, axis=1).reshape((-1, 1))\n\n\ndef predict_text(stoi, model, text):\n    """"""Do the actual prediction on the text using the\n        model and mapping files passed\n    """"""\n\n    # prefix text with tokens:\n    #   xbos: beginning of sentence\n    #   xfld 1: we are using a single field here\n    input_str = \'xbos xfld 1 \' + text\n\n    # predictions are done on arrays of input.\n    # We only have a single input, so turn it into a 1x1 array\n    texts = [input_str]\n\n    # tokenize using the fastai wrapper around spacy\n    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n\n    # turn into integers for each word\n    encoded = [stoi[p] for p in tok[0]]\n\n    # we want a [x,1] array where x is the number\n    #  of words inputted (including the prefix tokens)\n    ary = np.reshape(np.array(encoded),(-1,1))\n\n    # turn this array into a tensor\n    tensor = torch.from_numpy(ary)\n\n    # wrap in a torch Variable\n    variable = Variable(tensor)\n\n    # do the predictions\n    predictions = model(variable)\n\n    # convert back to numpy\n    numpy_preds = predictions[0].data.numpy()\n\n    return softmax(numpy_preds[0])[0]\n\n\ndef predict_input(itos_filename, trained_classifier_filename, num_classes=2):\n    """"""\n    Loads a model and produces predictions on arbitrary input.\n    :param itos_filename: the path to the id-to-string mapping file\n    :param trained_classifier_filename: the filename of the trained classifier;\n                                        typically ends with ""clas_1.h5""\n    :param num_classes: the number of classes that the model predicts\n    """"""\n    # Check the itos file exists\n    if not os.path.exists(itos_filename):\n        print(""Could not find "" + itos_filename)\n        exit(-1)\n\n    # Check the classifier file exists\n    if not os.path.exists(trained_classifier_filename):\n        print(""Could not find "" + trained_classifier_filename)\n        exit(-1)\n\n    stoi, model = load_model(itos_filename, trained_classifier_filename, num_classes)\n\n    while True:\n        text = input(""Enter text to analyse (or q to quit): "")\n        if text.strip() == \'q\':\n            break\n        else:\n            scores = predict_text(stoi, model, text)\n            print(""Result id {0}, Scores: {1}"".format(np.argmax(scores), scores))\n\n\nif __name__ == \'__main__\':\n    fire.Fire(predict_input)\n'"
courses/dl2/imdb_scripts/pretrain_lm.py,2,"b""import fire\nfrom fastai.text import *\n\nfrom sampled_sm import *\n\n\ndef train_lm(dir_path, cuda_id, cl=1, bs=64, backwards=False, lr=3e-4, sampled=True,\n             pretrain_id=''):\n    print(f'dir_path {dir_path}; cuda_id {cuda_id}; cl {cl}; bs {bs}; '\n          f'backwards {backwards}; lr {lr}; sampled {sampled}; '\n          f'pretrain_id {pretrain_id}')\n    if not hasattr(torch._C, '_cuda_setDevice'):\n        print('CUDA not available. Setting device=-1.')\n        cuda_id = -1\n    torch.cuda.set_device(cuda_id)\n    PRE  = 'bwd_' if backwards else 'fwd_'\n    IDS = 'ids'\n    p = Path(dir_path)\n    assert p.exists(), f'Error: {p} does not exist.'\n    bptt=70\n    em_sz,nh,nl = 400,1150,3\n    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n\n    if backwards:\n        trn_lm = np.load(p / f'tmp/trn_{IDS}_bwd.npy')\n        val_lm = np.load(p / f'tmp/val_{IDS}_bwd.npy')\n    else:\n        trn_lm = np.load(p / f'tmp/trn_{IDS}.npy')\n        val_lm = np.load(p / f'tmp/val_{IDS}.npy')\n    trn_lm = np.concatenate(trn_lm)\n    val_lm = np.concatenate(val_lm)\n\n    itos = pickle.load(open(p / 'tmp/itos.pkl', 'rb'))\n    vs = len(itos)\n\n    trn_dl = LanguageModelLoader(trn_lm, bs, bptt)\n    val_dl = LanguageModelLoader(val_lm, bs//5 if sampled else bs, bptt)\n    md = LanguageModelData(p, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)\n\n    tprs = get_prs(trn_lm, vs)\n    drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.5\n    learner,crit = get_learner(drops, 15000, sampled, md, em_sz, nh, nl, opt_fn, tprs)\n    wd=1e-7\n    learner.metrics = [accuracy]\n\n    lrs = np.array([lr/6,lr/3,lr,lr])\n    #lrs=lr\n\n    learner.fit(lrs, 1, wds=wd, use_clr=(32,10), cycle_len=cl)\n    learner.save(f'{PRE}{pretrain_id}')\n    learner.save_encoder(f'{PRE}{pretrain_id}_enc')\n\nif __name__ == '__main__': fire.Fire(train_lm)\n"""
courses/dl2/imdb_scripts/sampled_sm.py,4,"b'from fastai.learner import *\nfrom fastai.text import *\n\ndef resample_vocab(itos, trn, val, sz):\n    freqs = Counter(trn)\n    itos2 = [o for o,p in freqs.most_common()][:sz]\n    itos2.insert(0,1)\n    itos2.insert(0,0)\n    stoi2 = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos2)})\n\n    trn = np.array([stoi2[o] for o in trn])\n    val = np.array([stoi2[o] for o in val])\n\n    itos3 = [itos[o] for o in itos2]\n    stoi3 = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos3)})\n    return trn,val,itos3,stoi3\n\n\ndef get_prs(c, nt):\n    uni_counter = Counter(c)\n    uni_counts = np.array([uni_counter[o] for o in range(nt)])\n    return uni_counts/uni_counts.sum()\n\nclass LinearDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, n_out, nhid, dropout, tie_encoder=None, decode_train=True):\n        super().__init__()\n        self.decode_train = decode_train\n        self.decoder = nn.Linear(nhid, n_out, bias=False)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.dropout = LockedDropout(dropout)\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = self.dropout(outputs[-1])\n        output = output.view(output.size(0)*output.size(1), output.size(2))\n        if self.decode_train or not self.training:\n            decoded = self.decoder(output)\n            output = decoded.view(-1, decoded.size(1))\n        return output, raw_outputs, outputs\n\n\ndef get_language_model(n_tok, em_sz, nhid, nlayers, pad_token, decode_train=True, dropouts=None):\n    if dropouts is None: dropouts = [0.5,0.4,0.5,0.05,0.3]\n    rnn_enc = RNN_Encoder(n_tok, em_sz, n_hid=nhid, n_layers=nlayers, pad_token=pad_token,\n                 dropouti=dropouts[0], wdrop=dropouts[2], dropoute=dropouts[3], dropouth=dropouts[4])\n    rnn_dec = LinearDecoder(n_tok, em_sz, dropouts[1], decode_train=decode_train, tie_encoder=rnn_enc.encoder)\n    return SequentialRNN(rnn_enc, rnn_dec)\n\n\ndef pt_sample(pr, ns):\n    w = -torch.log(cuda.FloatTensor(len(pr)).uniform_())/(pr+1e-10)\n    return torch.topk(w, ns, largest=False)[1]\n\n\nclass CrossEntDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, prs, decoder, n_neg=4000, sampled=True):\n        super().__init__()\n        self.prs,self.decoder,self.sampled = T(prs).cuda(),decoder,sampled\n        self.set_n_neg(n_neg)\n\n    def set_n_neg(self, n_neg): self.n_neg = n_neg\n\n    def get_rand_idxs(self): return pt_sample(self.prs, self.n_neg)\n\n    def sampled_softmax(self, input, target):\n        idxs = V(self.get_rand_idxs())\n        dw = self.decoder.weight\n        #db = self.decoder.bias\n        output = input @ dw[idxs].t() #+ db[idxs]\n        max_output = output.max()\n        output = output - max_output\n        num = (dw[target] * input).sum(1) - max_output\n        negs = torch.exp(num) + (torch.exp(output)*2).sum(1)\n        return (torch.log(negs) - num).mean()\n\n    def forward(self, input, target):\n        if self.decoder.training:\n            if self.sampled: return self.sampled_softmax(input, target)\n            else: input = self.decoder(input)\n        return F.cross_entropy(input, target)\n\ndef get_learner(drops, n_neg, sampled, md, em_sz, nh, nl, opt_fn, prs):\n    m = to_gpu(get_language_model(md.n_tok, em_sz, nh, nl, md.pad_idx, decode_train=False, dropouts=drops))\n    crit = CrossEntDecoder(prs, m[1].decoder, n_neg=n_neg, sampled=sampled).cuda()\n    learner = RNN_Learner(md, LanguageModel(m), opt_fn=opt_fn)\n    crit.dw = learner.model[0].encoder.weight\n    learner.crit = crit\n    learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n    learner.clip=0.3\n    return learner,crit\n\n'"
courses/dl2/imdb_scripts/tok2id.py,0,"b""from fastai.text import *\nimport fire\n\n\ndef tok2id(dir_path, max_vocab=30000, min_freq=1):\n    print(f'dir_path {dir_path} max_vocab {max_vocab} min_freq {min_freq}')\n    p = Path(dir_path)\n    assert p.exists(), f'Error: {p} does not exist.'\n    tmp_path = p / 'tmp'\n    assert tmp_path.exists(), f'Error: {tmp_path} does not exist.'\n\n    trn_tok = np.load(tmp_path / 'tok_trn.npy')\n    val_tok = np.load(tmp_path / 'tok_val.npy')\n\n    freq = Counter(p for o in trn_tok for p in o)\n    print(freq.most_common(25))\n    itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n    itos.insert(0, '_pad_')\n    itos.insert(0, '_unk_')\n    stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n    print(len(itos))\n\n    trn_lm = np.array([[stoi[o] for o in p] for p in trn_tok])\n    val_lm = np.array([[stoi[o] for o in p] for p in val_tok])\n\n    np.save(tmp_path / 'trn_ids.npy', trn_lm)\n    np.save(tmp_path / 'val_ids.npy', val_lm)\n    pickle.dump(itos, open(tmp_path / 'itos.pkl', 'wb'))\n\nif __name__ == '__main__': fire.Fire(tok2id)\n"""
courses/dl2/imdb_scripts/train_clas.py,2,"b""import fire\nfrom fastai.text import *\nfrom fastai.lm_rnn import *\n\n\ndef freeze_all_but(learner, n):\n    c=learner.get_layer_groups()\n    for l in c: set_trainable(l, False)\n    set_trainable(c[n], True)\n\n\ndef train_clas(dir_path, cuda_id, lm_id='', clas_id=None, bs=64, cl=1, backwards=False, startat=0, unfreeze=True,\n               lr=0.01, dropmult=1.0, bpe=False, use_clr=True,\n               use_regular_schedule=False, use_discriminative=True, last=False, chain_thaw=False,\n               from_scratch=False, train_file_id=''):\n    print(f'dir_path {dir_path}; cuda_id {cuda_id}; lm_id {lm_id}; clas_id {clas_id}; bs {bs}; cl {cl}; backwards {backwards}; '\n        f'dropmult {dropmult} unfreeze {unfreeze} startat {startat}; bpe {bpe}; use_clr {use_clr};'\n        f'use_regular_schedule {use_regular_schedule}; use_discriminative {use_discriminative}; last {last};'\n        f'chain_thaw {chain_thaw}; from_scratch {from_scratch}; train_file_id {train_file_id}')\n    if not hasattr(torch._C, '_cuda_setDevice'):\n        print('CUDA not available. Setting device=-1.')\n        cuda_id = -1\n    torch.cuda.set_device(cuda_id)\n\n    PRE = 'bwd_' if backwards else 'fwd_'\n    PRE = 'bpe_' + PRE if bpe else PRE\n    IDS = 'bpe' if bpe else 'ids'\n    train_file_id = train_file_id if train_file_id == '' else f'_{train_file_id}'\n    dir_path = Path(dir_path)\n    lm_id = lm_id if lm_id == '' else f'{lm_id}_'\n    clas_id = lm_id if clas_id is None else clas_id\n    clas_id = clas_id if clas_id == '' else f'{clas_id}_'\n    intermediate_clas_file = f'{PRE}{clas_id}clas_0'\n    final_clas_file = f'{PRE}{clas_id}clas_1'\n    lm_file = f'{PRE}{lm_id}lm_enc'\n    lm_path = dir_path / 'models' / f'{lm_file}.h5'\n    assert lm_path.exists(), f'Error: {lm_path} does not exist.'\n\n    bptt,em_sz,nh,nl = 70,400,1150,3\n    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n\n    if backwards:\n        trn_sent = np.load(dir_path / 'tmp' / f'trn_{IDS}{train_file_id}_bwd.npy')\n        val_sent = np.load(dir_path / 'tmp' / f'val_{IDS}_bwd.npy')\n    else:\n        trn_sent = np.load(dir_path / 'tmp' / f'trn_{IDS}{train_file_id}.npy')\n        val_sent = np.load(dir_path / 'tmp' / f'val_{IDS}.npy')\n\n    trn_lbls = np.load(dir_path / 'tmp' / f'lbl_trn{train_file_id}.npy')\n    val_lbls = np.load(dir_path / 'tmp' / f'lbl_val.npy')\n    assert trn_lbls.shape[1] == 1 and val_lbls.shape[1] == 1, 'This classifier uses cross entropy loss and only support single label samples'\n    trn_lbls = trn_lbls.flatten()\n    val_lbls = val_lbls.flatten()\n    print('Trn lbls shape:', trn_lbls.shape)\n    trn_lbls -= trn_lbls.min()\n    val_lbls -= val_lbls.min()\n    c=int(trn_lbls.max())+1\n    print('Number of labels:', c)\n\n    if bpe: vs=30002\n    else:\n        itos = pickle.load(open(dir_path / 'tmp' / 'itos.pkl', 'rb'))\n        vs = len(itos)\n\n    trn_ds = TextDataset(trn_sent, trn_lbls)\n    val_ds = TextDataset(val_sent, val_lbls)\n    trn_samp = SortishSampler(trn_sent, key=lambda x: len(trn_sent[x]), bs=bs//2)\n    val_samp = SortSampler(val_sent, key=lambda x: len(val_sent[x]))\n    trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n    val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n    md = ModelData(dir_path, trn_dl, val_dl)\n\n    dps = np.array([0.4,0.5,0.05,0.3,0.4])*dropmult\n    #dps = np.array([0.5, 0.4, 0.04, 0.3, 0.6])*dropmult\n    #dps = np.array([0.65,0.48,0.039,0.335,0.34])*dropmult\n    #dps = np.array([0.6,0.5,0.04,0.3,0.4])*dropmult\n\n    m = get_rnn_classifier(bptt, 20*bptt, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n              layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n              dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n\n    learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n    learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n    learn.clip=25.\n    learn.metrics = [accuracy]\n\n    lrm = 2.6\n    if use_discriminative:\n        lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n    else:\n        lrs = lr\n    wd = 1e-6\n    if not from_scratch:\n        learn.load_encoder(lm_file)\n    else:\n        print('Training classifier from scratch. LM encoder is not loaded.')\n        use_regular_schedule = True\n\n    if (startat<1) and not last and not chain_thaw and not from_scratch:\n        learn.freeze_to(-1)\n        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n                  use_clr=None if use_regular_schedule or not use_clr else (8,3))\n        learn.freeze_to(-2)\n        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n                  use_clr=None if use_regular_schedule or not use_clr else (8, 3))\n        learn.save(intermediate_clas_file)\n    elif startat==1:\n        learn.load(intermediate_clas_file)\n\n    if chain_thaw:\n        lrs = np.array([0.0001, 0.0001, 0.0001, 0.0001, 0.001])\n        print('Using chain-thaw. Unfreezing all layers one at a time...')\n        n_layers = len(learn.get_layer_groups())\n        print('#\xc2\xa0of layers:', n_layers)\n        # fine-tune last layer\n        learn.freeze_to(-1)\n        print('Fine-tuning last layer...')\n        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n                  use_clr=None if use_regular_schedule or not use_clr else (8,3))\n        n = 0\n        # fine-tune all layers up to the second-last one\n        while n < n_layers-1:\n            print('Fine-tuning layer #%d.' % n)\n            freeze_all_but(learn, n)\n            learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n                      use_clr=None if use_regular_schedule or not use_clr else (8,3))\n            n += 1\n\n    if unfreeze:\n        learn.unfreeze()\n    else:\n        learn.freeze_to(-3)\n\n    if last:\n        print('Fine-tuning only the last layer...')\n        learn.freeze_to(-1)\n\n    if use_regular_schedule:\n        print('Using regular schedule. Setting use_clr=None, n_cycles=cl, cycle_len=None.')\n        use_clr = None\n        n_cycles = cl\n        cl = None\n    else:\n        n_cycles = 1\n    learn.fit(lrs, n_cycles, wds=wd, cycle_len=cl, use_clr=(8,8) if use_clr else None)\n    print('Plotting lrs...')\n    learn.sched.plot_lr()\n    learn.save(final_clas_file)\n\nif __name__ == '__main__': fire.Fire(train_clas)\n\n"""
courses/dl2/lsun_scripts/lsun-data.py,0,"b""from __future__ import print_function\nfrom tqdm import tqdm\nimport argparse, cv2, lmdb, numpy, os\nfrom os.path import exists, join\n\n__author__ = 'Fisher Yu'\n__email__ = 'fy@cs.princeton.edu'\n__license__ = 'MIT'\n# (Minor edits by Jeremy Howard)\n\n\ndef export_images(db_path, out_dir, flat=False):\n    print('Exporting', db_path, 'to', out_dir)\n    env = lmdb.open(db_path, map_size=1099511627776,\n                    max_readers=100, readonly=True)\n    with env.begin(write=False) as txn:\n        cursor = txn.cursor()\n        for key, val in tqdm(cursor):\n            key = key.decode()\n            if not flat: image_out_dir = join(out_dir, '/'.join(key[:3]))\n            else: image_out_dir = out_dir\n            if not exists(image_out_dir): os.makedirs(image_out_dir)\n            image_out_path = join(image_out_dir, key + '.jpg')\n            with open(image_out_path, 'wb') as fp: fp.write(val)\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('lmdb_path', nargs='+', type=str,\n                        help='The path to the lmdb database folder. '\n                             'Support multiple database paths.')\n    parser.add_argument('--out_dir', type=str, default='')\n    parser.add_argument('--flat', action='store_true',\n                        help='If enabled, the images are imported into output '\n                             'directory directly instead of hierarchical '\n                             'directories.')\n    args = parser.parse_args()\n    lmdb_paths = args.lmdb_path\n    for lmdb_path in lmdb_paths: export_images(lmdb_path, args.out_dir, args.flat)\n\n\nif __name__ == '__main__': main()\n"""
courses/dl2/lsun_scripts/lsun-download.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom __future__ import print_function, division\nimport argparse\nimport json\nfrom os.path import join\n\nimport subprocess\nfrom six.moves.urllib.request import urlopen\n\n__author__ = \'Fisher Yu\'\n__email__ = \'fy@cs.princeton.edu\'\n__license__ = \'MIT\'\n\n\ndef list_categories(tag):\n    url = \'http://lsun.cs.princeton.edu/htbin/list.cgi?tag=\' + tag\n    f = urlopen(url)\n    return json.loads(f.read())\n\n\ndef download(out_dir, category, set_name, tag):\n    url = \'http://lsun.cs.princeton.edu/htbin/download.cgi?tag={tag}\' \\\n          \'&category={category}&set={set_name}\'.format(**locals())\n    if set_name == \'test\':\n        out_name = \'test_lmdb.zip\'\n    else:\n        out_name = \'{category}_{set_name}_lmdb.zip\'.format(**locals())\n    out_path = join(out_dir, out_name)\n    cmd = [\'curl\', url, \'-o\', out_path]\n    print(\'Downloading\', category, set_name, \'set\')\n    subprocess.call(cmd)\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--tag\', type=str, default=\'latest\')\n    parser.add_argument(\'-o\', \'--out_dir\', default=\'\')\n    parser.add_argument(\'-c\', \'--category\', default=None)\n    args = parser.parse_args()\n\n    categories = list_categories(args.tag)\n    if args.category is None:\n        print(\'Downloading\', len(categories), \'categories\')\n        for category in categories:\n            download(args.out_dir, category, \'train\', args.tag)\n            download(args.out_dir, category, \'val\', args.tag)\n        download(args.out_dir, \'\', \'test\', args.tag)\n    else:\n        if args.category == \'test\':\n            download(args.out_dir, \'\', \'test\', args.tag)\n        elif args.category not in categories:\n            print(\'Error:\', args.category, ""doesn\'t exist in"",\n                  args.tag, \'LSUN release\')\n        else:\n            download(args.out_dir, args.category, \'train\', args.tag)\n            download(args.out_dir, args.category, \'val\', args.tag)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
fastai/text/models/__init__.py,0,"b'from .awd_lstm import *\nfrom .transformer import *\n__all__ = [*awd_lstm.__all__, *transformer.__all__]\n'"
fastai/text/models/awd_lstm.py,0,"b'from ...torch_core import *\nfrom ...layers import *\nfrom ...train import ClassificationInterpretation\nfrom ...basic_train import *\nfrom ...basic_data import *\nfrom ..data import TextClasDataBunch\nimport matplotlib.cm as cm\n\n__all__ = [\'EmbeddingDropout\', \'LinearDecoder\', \'AWD_LSTM\', \'RNNDropout\',\n           \'SequentialRNN\', \'WeightDropout\', \'dropout_mask\', \'awd_lstm_lm_split\', \'awd_lstm_clas_split\',\n           \'awd_lstm_lm_config\', \'awd_lstm_clas_config\']\n\ndef dropout_mask(x:Tensor, sz:Collection[int], p:float):\n    ""Return a dropout mask of the same type as `x`, size `sz`, with probability `p` to cancel an element.""\n    return x.new(*sz).bernoulli_(1-p).div_(1-p)\n\nclass RNNDropout(Module):\n    ""Dropout with probability `p` that is consistent on the seq_len dimension.""\n\n    def __init__(self, p:float=0.5): self.p=p\n\n    def forward(self, x:Tensor)->Tensor:\n        if not self.training or self.p == 0.: return x\n        m = dropout_mask(x.data, (x.size(0), 1, x.size(2)), self.p)\n        return x * m\n\nclass WeightDropout(Module):\n    ""A module that warps another layer in which some weights will be replaced by 0 during training.""\n\n    def __init__(self, module:nn.Module, weight_p:float, layer_names:Collection[str]=[\'weight_hh_l0\']):\n        self.module,self.weight_p,self.layer_names = module,weight_p,layer_names\n        self.idxs = [] if hasattr(self.module, \'_flat_weights_names\') else None\n        for layer in self.layer_names:\n            #Makes a copy of the weights of the selected layers.\n            w = getattr(self.module, layer)\n            self.register_parameter(f\'{layer}_raw\', nn.Parameter(w.data))\n            self.module._parameters[layer] = F.dropout(w, p=self.weight_p, training=False)\n            if self.idxs is not None: self.idxs.append(self.module._flat_weights_names.index(layer))\n        if isinstance(self.module, (nn.RNNBase, nn.modules.rnn.RNNBase)):\n            self.module.flatten_parameters = self._do_nothing\n\n    def _setweights(self):\n        ""Apply dropout to the raw weights.""\n        for i,layer in enumerate(self.layer_names):\n            raw_w = getattr(self, f\'{layer}_raw\')\n            self.module._parameters[layer] = F.dropout(raw_w, p=self.weight_p, training=self.training)\n            if self.idxs is not None: self.module._flat_weights[self.idxs[i]] = self.module._parameters[layer]\n\n    def forward(self, *args):\n        self._setweights()\n        with warnings.catch_warnings():\n            #To avoid the warning that comes because the weights aren\'t flattened.\n            warnings.simplefilter(""ignore"")\n            return self.module.forward(*args)\n\n    def reset(self):\n        for layer in self.layer_names:\n            raw_w = getattr(self, f\'{layer}_raw\')\n            self.module._parameters[layer] = F.dropout(raw_w, p=self.weight_p, training=False)\n        if hasattr(self.module, \'reset\'): self.module.reset()    \n    \n    def _do_nothing(self): pass\n\nclass EmbeddingDropout(Module):\n    ""Apply dropout with probabily `embed_p` to an embedding layer `emb`.""\n\n    def __init__(self, emb:nn.Module, embed_p:float):\n        self.emb,self.embed_p = emb,embed_p\n        self.pad_idx = self.emb.padding_idx\n        if self.pad_idx is None: self.pad_idx = -1\n\n    def forward(self, words:LongTensor, scale:Optional[float]=None)->Tensor:\n        if self.training and self.embed_p != 0:\n            size = (self.emb.weight.size(0),1)\n            mask = dropout_mask(self.emb.weight.data, size, self.embed_p)\n            masked_embed = self.emb.weight * mask\n        else: masked_embed = self.emb.weight\n        if scale: masked_embed.mul_(scale)\n        return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\n                           self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)\n\nclass AWD_LSTM(Module):\n    ""AWD-LSTM/QRNN inspired by https://arxiv.org/abs/1708.02182.""\n\n    initrange=0.1\n\n    def __init__(self, vocab_sz:int, emb_sz:int, n_hid:int, n_layers:int, pad_token:int=1, hidden_p:float=0.2,\n                 input_p:float=0.6, embed_p:float=0.1, weight_p:float=0.5, qrnn:bool=False, bidir:bool=False):\n        self.bs,self.qrnn,self.emb_sz,self.n_hid,self.n_layers = 1,qrnn,emb_sz,n_hid,n_layers\n        self.n_dir = 2 if bidir else 1\n        self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n        self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)\n        if self.qrnn:\n            #Using QRNN requires an installation of cuda\n            from .qrnn import QRNN\n            self.rnns = [QRNN(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir, 1,\n                              save_prev_x=True, zoneout=0, window=2 if l == 0 else 1, output_gate=True, bidirectional=bidir) \n                         for l in range(n_layers)]\n            for rnn in self.rnns: \n                rnn.layers[0].linear = WeightDropout(rnn.layers[0].linear, weight_p, layer_names=[\'weight\'])\n        else:\n            self.rnns = [nn.LSTM(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir, 1,\n                                 batch_first=True, bidirectional=bidir) for l in range(n_layers)]\n            self.rnns = [WeightDropout(rnn, weight_p) for rnn in self.rnns]\n        self.rnns = nn.ModuleList(self.rnns)\n        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n        if self.encoder.padding_idx is not None:\n                self.encoder.weight.data[self.encoder.padding_idx] = 0.\n        self.input_dp = RNNDropout(input_p)\n        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n\n    def forward(self, input:Tensor, from_embeddings:bool=False)->Tuple[List[Tensor],List[Tensor]]:\n        if from_embeddings: bs,sl,es = input.size()\n        else: bs,sl = input.size()\n        if bs!=self.bs:\n            self.bs=bs\n            self.reset()\n        raw_output = self.input_dp(input if from_embeddings else self.encoder_dp(input))\n        new_hidden,raw_outputs,outputs = [],[],[]\n        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n            raw_output, new_h = rnn(raw_output, self.hidden[l])\n            new_hidden.append(new_h)\n            raw_outputs.append(raw_output)\n            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n            outputs.append(raw_output)\n        self.hidden = to_detach(new_hidden, cpu=False)\n        return raw_outputs, outputs\n\n    def _one_hidden(self, l:int)->Tensor:\n        ""Return one hidden state.""\n        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir\n        return one_param(self).new(self.n_dir, self.bs, nh).zero_()\n\n    def select_hidden(self, idxs):\n        if self.qrnn: self.hidden = [h[:,idxs,:] for h in self.hidden]\n        else: self.hidden = [(h[0][:,idxs,:],h[1][:,idxs,:]) for h in self.hidden]\n        self.bs = len(idxs)\n\n    def reset(self):\n        ""Reset the hidden states.""\n        [r.reset() for r in self.rnns if hasattr(r, \'reset\')]\n        if self.qrnn: self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]\n        else: self.hidden = [(self._one_hidden(l), self._one_hidden(l)) for l in range(self.n_layers)]\n\nclass LinearDecoder(Module):\n    ""To go on top of a RNNCore module and create a Language Model.""\n    initrange=0.1\n\n    def __init__(self, n_out:int, n_hid:int, output_p:float, tie_encoder:nn.Module=None, bias:bool=True):\n        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.output_dp = RNNDropout(output_p)\n        if bias: self.decoder.bias.data.zero_()\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input:Tuple[Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n        raw_outputs, outputs = input\n        output = self.output_dp(outputs[-1])\n        decoded = self.decoder(output)\n        return decoded, raw_outputs, outputs\n\nclass SequentialRNN(nn.Sequential):\n    ""A sequential module that passes the reset call to its children.""\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \'reset\'): c.reset()\n\ndef awd_lstm_lm_split(model:nn.Module) -> List[List[nn.Module]]:\n    ""Split a RNN `model` in groups for differential learning rates.""\n    groups = [[rnn, dp] for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)]\n    return groups + [[model[0].encoder, model[0].encoder_dp, model[1]]]\n\ndef awd_lstm_clas_split(model:nn.Module) -> List[List[nn.Module]]:\n    ""Split a RNN `model` in groups for differential learning rates.""\n    groups = [[model[0].module.encoder, model[0].module.encoder_dp]]\n    groups += [[rnn, dp] for rnn, dp in zip(model[0].module.rnns, model[0].module.hidden_dps)]\n    return groups + [[model[1]]]\n\nawd_lstm_lm_config = dict(emb_sz=400, n_hid=1152, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.1,\n                          hidden_p=0.15, input_p=0.25, embed_p=0.02, weight_p=0.2, tie_weights=True, out_bias=True)\n\nawd_lstm_clas_config = dict(emb_sz=400, n_hid=1152, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.4,\n                       hidden_p=0.3, input_p=0.4, embed_p=0.05, weight_p=0.5)\n\ndef value2rgba(x:float, cmap:Callable=cm.RdYlGn, alpha_mult:float=1.0)->Tuple:\n    ""Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.""\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])\n\ndef piece_attn_html(pieces:List[str], attns:List[float], sep:str=\' \', **kwargs)->str:\n    html_code,spans = [\'<span style=""font-family: monospace;"">\'], []\n    for p, a in zip(pieces, attns):\n        p = html.escape(p)\n        c = str(value2rgba(a, alpha_mult=0.5, **kwargs))\n        spans.append(f\'<span title=""{a:.3f}"" style=""background-color: rgba{c};"">{p}</span>\')\n    html_code.append(sep.join(spans))\n    html_code.append(\'</span>\')\n    return \'\'.join(html_code)\n\ndef show_piece_attn(*args, **kwargs):\n    from IPython.display import display, HTML\n    display(HTML(piece_attn_html(*args, **kwargs)))\n\ndef _eval_dropouts(mod):\n        module_name =  mod.__class__.__name__\n        if \'Dropout\' in module_name or \'BatchNorm\' in module_name: mod.training = False\n        for module in mod.children(): _eval_dropouts(module)\n'"
fastai/text/models/qrnn.py,10,"b'from ...torch_core import *\nfrom torch.utils.cpp_extension import load\nfrom torch.autograd import Function\n\n__all__ = [\'QRNNLayer\', \'QRNN\']\n\nimport fastai\nif torch.cuda.is_available():\n    fastai_path = Path(fastai.__path__[0])/\'text\'/\'models\'\n    files = [\'forget_mult_cuda.cpp\', \'forget_mult_cuda_kernel.cu\']\n    forget_mult_cuda = load(name=\'forget_mult_cuda\', sources=[fastai_path/f for f in files])\n    files = [\'bwd_forget_mult_cuda.cpp\', \'bwd_forget_mult_cuda_kernel.cu\']\n    bwd_forget_mult_cuda = load(name=\'bwd_forget_mult_cuda\', sources=[fastai_path/f for f in files])\n\ndef dispatch_cuda(cuda_class, cpu_func, x):\n    return cuda_class.apply if x.device.type == \'cuda\' else cpu_func\n    \nclass ForgetMultGPU(Function):\n    \n    @staticmethod\n    def forward(ctx, x:Tensor, f:Tensor, hidden_init:Optional[Tensor]=None, batch_first:bool=True):\n        if batch_first:\n            batch_size, seq_size, hidden_size = f.size()\n            output = f.new_zeros(batch_size, seq_size + 1, hidden_size)\n            if hidden_init is not None: output[:, 0] = hidden_init\n            else: output.zero_()\n        else: \n            seq_size, batch_size, hidden_size = f.size()\n            output = f.new(seq_size + 1, batch_size, hidden_size)\n            if hidden_init is not None: output[0] = hidden_init\n            else: output.zero_()\n        output = forget_mult_cuda.forward(x, f, output, batch_first)\n        ctx.save_for_backward(x, f, hidden_init, output)\n        ctx.batch_first = batch_first\n        return output[:,1:] if batch_first else output[1:]\n    \n    @staticmethod\n    def backward(ctx, grad_output):\n        x, f, hidden_init, output = ctx.saved_tensors\n        grad_x, grad_f, grad_h = forget_mult_cuda.backward(x, f, output, grad_output, ctx.batch_first)\n        return (grad_x, grad_f, (None if hidden_init is None else grad_h), None)\n    \nclass BwdForgetMultGPU(Function):\n    \n    @staticmethod\n    def forward(ctx, x:Tensor, f:Tensor, hidden_init:Optional[Tensor]=None, batch_first:bool=True):\n        if batch_first:\n            batch_size, seq_size, hidden_size = f.size()\n            output = f.new(batch_size, seq_size + 1, hidden_size)\n            if hidden_init is not None: output[:, -1] = hidden_init\n            else: output.zero_()\n        else: \n            seq_size, batch_size, hidden_size = f.size()\n            output = f.new(seq_size + 1, batch_size, hidden_size)\n            if hidden_init is not None: output[-1] = hidden_init\n            else: output.zero_()\n        output = bwd_forget_mult_cuda.forward(x, f, output, batch_first)\n        ctx.save_for_backward(x, f, hidden_init, output)\n        ctx.batch_first = batch_first\n        return output[:,:-1] if batch_first else output[:-1]\n    \n    @staticmethod\n    def backward(ctx, grad_output:Tensor):\n        x, f, hidden_init, output = ctx.saved_tensors\n        grad_x, grad_f, grad_h = bwd_forget_mult_cuda.backward(x, f, output, grad_output, ctx.batch_first)\n        return (grad_x, grad_f, (None if hidden_init is None else grad_h), None)\n    \ndef forget_mult_CPU(x:Tensor, f:Tensor, hidden_init:Optional[Tensor]=None, batch_first:bool=True, backward:bool=False):\n    result = []\n    dim = (1 if batch_first else 0)\n    forgets = f.split(1, dim=dim)\n    inputs =  x.split(1, dim=dim)\n    prev_h = None if hidden_init is None else hidden_init.unsqueeze(1 if batch_first else 0)\n    idx_range = range(len(inputs)-1,-1,-1) if backward else range(len(inputs))\n    for i in idx_range:\n        prev_h = inputs[i] * forgets[i] if prev_h is None else inputs[i] * forgets[i] + (1-forgets[i]) * prev_h\n        if backward: result.insert(0, prev_h)\n        else:        result.append(prev_h)\n    return torch.cat(result, dim=dim)\n\nclass QRNNLayer(Module):\n    ""Apply a single layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.""\n\n    def __init__(self, input_size:int, hidden_size:int=None, save_prev_x:bool=False, zoneout:float=0, window:int=1, \n                 output_gate:bool=True, batch_first:bool=True, backward:bool=False):\n        super().__init__()\n        assert window in [1, 2], ""This QRNN implementation currently only handles convolutional window of size 1 or size 2""\n        self.save_prev_x,self.zoneout,self.window = save_prev_x,zoneout,window\n        self.output_gate,self.batch_first,self.backward = output_gate,batch_first,backward\n        hidden_size = ifnone(hidden_size, input_size)\n        #One large matmul with concat is faster than N small matmuls and no concat\n        mult = (3 if output_gate else 2)\n        self.linear = nn.Linear(window * input_size, mult * hidden_size)\n        self.prevX = None\n\n    def reset(self):\n        # If you are saving the previous value of x, you should call this when starting with a new state\n        self.prevX = None\n        \n    def forward(self, inp, hid=None):\n        y = self.linear(self._get_source(inp))\n        if self.output_gate: z_gate,f_gate,o_gate = y.chunk(3, dim=2)\n        else:                z_gate,f_gate        = y.chunk(2, dim=2)\n        z_gate.tanh_()\n        f_gate.sigmoid_()\n        if self.zoneout and self.training:\n            mask = dropout_mask(f_gate, f_gate.size(), self.zoneout).requires_grad_(False)\n            f_gate = f_gate * mask\n        z_gate,f_gate = z_gate.contiguous(),f_gate.contiguous()\n        if self.backward: forget_mult = dispatch_cuda(BwdForgetMultGPU, partial(forget_mult_CPU, backward=True), inp)\n        else:             forget_mult = dispatch_cuda(ForgetMultGPU, forget_mult_CPU, inp)\n        c_gate = forget_mult(z_gate, f_gate, hid, self.batch_first)\n        output = torch.sigmoid(o_gate) * c_gate if self.output_gate else c_gate\n        if self.window > 1 and self.save_prev_x: \n            if self.backward: self.prevX = (inp[:, :1] if self.batch_first else inp[:1]).detach()\n            else:             self.prevX = (inp[:, -1:] if self.batch_first else inp[-1:]).detach()\n        idx = 0 if self.backward else -1\n        return output, (c_gate[:, idx] if self.batch_first else c_gate[idx])\n\n    def _get_source(self, inp):\n        if self.window == 1: return inp\n        dim = (1 if self.batch_first else 0)\n        inp_shift = [torch.zeros_like(inp[:,:1] if self.batch_first else inp[:1]) if self.prevX is None else self.prevX]\n        if self.backward: inp_shift.insert(0,inp[:,1:] if self.batch_first else inp[1:])\n        else:             inp_shift.append(inp[:,:-1] if self.batch_first else inp[:-1])\n        inp_shift = torch.cat(inp_shift, dim)\n        return torch.cat([inp, inp_shift], 2)\n    \nclass QRNN(Module):\n    ""Apply a multiple layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.""\n\n    def __init__(self, input_size:int, hidden_size:int, n_layers:int=1, bias:bool=True, batch_first:bool=True,\n                 dropout:float=0, bidirectional:bool=False, save_prev_x:bool=False, zoneout:float=0, window:int=None, \n                 output_gate:bool=True):\n        assert not (save_prev_x and bidirectional), ""Can\'t save the previous X with bidirectional.""\n        assert bias == True, \'Removing underlying bias is not yet supported\'\n        super().__init__()\n        kwargs = dict(batch_first=batch_first, zoneout=zoneout, output_gate=output_gate)\n        self.layers = nn.ModuleList([QRNNLayer(input_size if l == 0 else hidden_size, hidden_size, save_prev_x=save_prev_x, \n                                               window=((2 if l ==0 else 1) if window is None else window), **kwargs) \n                                     for l in range(n_layers)])\n        if bidirectional:\n            self.layers_bwd = nn.ModuleList([QRNNLayer(input_size if l == 0 else hidden_size, hidden_size, \n                                                       backward=True, window=((2 if l ==0 else 1) if window is None else window), \n                                                       **kwargs) for l in range(n_layers)])\n        self.n_layers,self.batch_first,self.dropout,self.bidirectional = n_layers,batch_first,dropout,bidirectional\n        \n    def reset(self):\n        ""If your convolutional window is greater than 1 and you save previous xs, you must reset at the beginning of each new sequence.""\n        for layer in self.layers:     layer.reset()\n        if self.bidirectional:\n            for layer in self.layers_bwd: layer.reset()    \n\n    def forward(self, inp, hid=None):\n        new_hid = []\n        if self.bidirectional: inp_bwd = inp.clone()\n        for i, layer in enumerate(self.layers):\n            inp, h = layer(inp, None if hid is None else hid[2*i if self.bidirectional else i])\n            new_hid.append(h)\n            if self.bidirectional:\n                inp_bwd, h_bwd = self.layers_bwd[i](inp_bwd, None if hid is None else hid[2*i+1])\n                new_hid.append(h_bwd)\n            if self.dropout != 0 and i < len(self.layers) - 1:\n                for o in ([inp, inp_bwd] if self.bidirectional else [inp]):\n                    o = F.dropout(o, p=self.dropout, training=self.training, inplace=False)\n        if self.bidirectional: inp = torch.cat([inp, inp_bwd], dim=2)\n        return inp, torch.stack(new_hid, 0)'"
fastai/text/models/transformer.py,33,"b'from ...torch_core import *\nfrom ...layers import *\nfrom .awd_lstm import RNNDropout, LinearDecoder, SequentialRNN\n\n__all__ = [\'Activation\', \'PositionalEncoding\', \'GeLU\', \'Swish\', \'feed_forward\', \'MultiHeadAttention\', \'MultiHeadRelativeAttention\',\n           \'DecoderLayer\', \'Transformer\', \'TransformerXL\', \'tfmer_lm_config\', \'tfmer_clas_config\', \'tfmer_lm_split\', \'tfmer_clas_split\',\n           \'tfmerXL_lm_config\', \'tfmerXL_clas_config\', \'tfmerXL_lm_split\', \'tfmerXL_clas_split\']\n\nActivation = Enum(\'Activation\', \'ReLU Swish GeLU\')\n\nclass PositionalEncoding(Module):\n    ""Encode the position with a sinusoid.""\n    def __init__(self, d:int): self.register_buffer(\'freq\', 1 / (10000 ** (torch.arange(0., d, 2.)/d)))\n\n    def forward(self, pos:Tensor):\n        inp = torch.ger(pos, self.freq)\n        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n        return enc\n\nclass GeLU(Module):\n    def forward(self, x): return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n\nclass Swish(Module):\n    def forward(self, x): return x * torch.sigmoid(x)\n\n_activ_func = {Activation.ReLU:nn.ReLU(inplace=True), Activation.GeLU:GeLU(), Activation.Swish: Swish()}\n\ndef feed_forward(d_model:int, d_ff:int, ff_p:float=0., act:Activation=Activation.ReLU, double_drop:bool=True):\n    layers = [nn.Linear(d_model, d_ff), _activ_func[act]]\n    if double_drop: layers.append(nn.Dropout(ff_p))\n    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), MergeLayer(), nn.LayerNorm(d_model))\n\nclass MultiHeadAttention(Module):\n    ""MutiHeadAttention.""\n    def __init__(self, n_heads:int, d_model:int, d_head:int=None, resid_p:float=0., attn_p:float=0., bias:bool=True,\n                 scale:bool=True):\n        d_head = ifnone(d_head, d_model//n_heads)\n        self.n_heads,self.d_head,self.scale = n_heads,d_head,scale\n        self.attention = nn.Linear(d_model, 3 * n_heads * d_head, bias=bias)\n        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)\n        self.drop_att,self.drop_res = nn.Dropout(attn_p),nn.Dropout(resid_p)\n        self.ln = nn.LayerNorm(d_model)\n\n    def forward(self, x:Tensor, mask:Tensor=None, **kwargs):\n        return self.ln(x + self.drop_res(self.out(self._apply_attention(x, mask=mask, **kwargs))))\n\n    def _apply_attention(self, x:Tensor, mask:Tensor=None):\n        bs,x_len = x.size(0),x.size(1)\n        wq,wk,wv = torch.chunk(self.attention(x), 3, dim=-1)\n        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n        wq,wk,wv = wq.permute(0, 2, 1, 3),wk.permute(0, 2, 3, 1),wv.permute(0, 2, 1, 3)\n        attn_score = torch.matmul(wq, wk)\n        if self.scale: attn_score.div_(self.d_head ** 0.5)\n        if mask is not None:\n            attn_score = attn_score.float().masked_fill(mask, -float(\'inf\')).type_as(attn_score)\n        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n        attn_vec = torch.matmul(attn_prob, wv)\n        return attn_vec.permute(0, 2, 1, 3).contiguous().contiguous().view(bs, x_len, -1)\n\n    def _attention_einsum(self, x, mask=None):\n        # Permute and matmul is a little bit faster but this implementation is more readable\n        bs,x_len = x.size(0),x.size(1)\n        wq,wk,wv = torch.chunk(self.attention(x), 3, dim=-1)\n        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n        attn_score = torch.einsum(\'bind,bjnd->bijn\', (wq, wk))\n        if self.scale: attn_score.mul_(1/(self.d_head ** 0.5))\n        if mask is not None:\n            attn_score = attn_score.float().masked_fill(mask, -float(\'inf\')).type_as(attn_score)\n        attn_prob = self.drop_att(F.softmax(attn_score, dim=2))\n        attn_vec = torch.einsum(\'bijn,bjnd->bind\', (attn_prob, wv))\n        return attn_vec.contiguous().view(bs, x_len, -1)\n\n#def _line_shift1(x:Tensor, mask:bool=False):\n#    ""Shift the line i of `x` by p-i elements to the left, is `mask` puts 0s on the diagonal.""\n#    bs,n,p,nh = x.size()\n#    x_pad = torch.cat([x.new_zeros(bs,n,1,nh), x], dim=2)\n#    x_shift = x_pad.view(bs,p + 1,n,nh)[:,1:].view_as(x)\n#    if mask: x_shift.mul_(torch.tril(x.new_ones(n,p), p-n)[None,:,:,None])\n#    return x_shift\n\ndef _line_shift(x:Tensor, mask:bool=False):\n    ""Shift the line i of `x` by p-i elements to the left, is `mask` puts 0s on the diagonal.""\n    bs,nh,n,p = x.size()\n    x_pad = torch.cat([x.new_zeros(bs,nh,n,1), x], dim=3)\n    x_shift = x_pad.view(bs,nh,p + 1,n)[:,:,1:].view_as(x)\n    if mask: x_shift.mul_(torch.tril(x.new_ones(n,p), p-n)[None,None,])\n    return x_shift\n\nclass MultiHeadRelativeAttention(MultiHeadAttention):\n    ""MutiHeadAttention with relative positional encoding.""\n\n    def __init__(self, n_heads:int, d_model:int, d_head:int, resid_p:float=0., attn_p:float=0., bias:bool=True,\n                 scale:bool=True):\n        super().__init__(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n        self.r_attn = nn.Linear(d_model, n_heads * d_head, bias=bias)\n\n    def _apply_attention(self, x:Tensor, r:Tensor=None, u:Tensor=None, v:Tensor=None, mask:Tensor=None, mem:Tensor=None):\n        #Notations from the paper: x input, r vector of relative distance between two elements, u et v learnable\n        #parameters of the model common between all layers, mask to avoid cheating and mem the previous hidden states.\n        bs,x_len,seq_len = x.size(0),x.size(1),r.size(0)\n        context = x if mem is None else torch.cat([mem, x], dim=1)\n        wq,wk,wv = torch.chunk(self.attention(context), 3, dim=-1)\n        wq = wq[:,-x_len:]\n        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n        wq,wk,wv = wq.permute(0, 2, 1, 3),wk.permute(0, 2, 3, 1),wv.permute(0, 2, 1, 3)\n        wkr = self.r_attn(r)\n        wkr = wkr.view(seq_len, self.n_heads, self.d_head)\n        wkr = wkr.permute(1,2,0)\n        #### compute attention score (AC is (a) + (c) and BS is (b) + (d) in the paper)\n        AC = torch.matmul(wq+u,wk)\n        BD = _line_shift(torch.matmul(wq+v, wkr))\n        if self.scale: attn_score = (AC + BD).mul_(1/(self.d_head ** 0.5))\n        if mask is not None:\n            attn_score = attn_score.float().masked_fill(mask, -float(\'inf\')).type_as(attn_score)\n        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n        attn_vec = torch.matmul(attn_prob, wv)\n        return attn_vec.permute(0, 2, 1, 3).contiguous().view(bs, x_len, -1)\n\n    def _attention_einsum(self, x:Tensor, r:Tensor=None, u:Tensor=None, v:Tensor=None, mask:Tensor=None, mem:Tensor=None):\n        # Permute and matmul is a little bit faster but this implementation is more readable\n        bs,x_len,seq_len = x.size(0),x.size(1),r.size(0)\n        context = x if mem is None else torch.cat([mem, x], dim=1)\n        wq,wk,wv = torch.chunk(self.attention(context), 3, dim=-1)\n        wq = wq[:,-x_len:]\n        wkr = self.r_attn(r)\n        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n        wkr = wkr.view(seq_len, self.n_heads, self.d_head)\n        #### compute attention score (AC is (a) + (c) and BS is (b) + (d) in the paper)\n        AC = torch.einsum(\'bind,bjnd->bijn\', (wq+u, wk))\n        BD = _line_shift1(torch.einsum(\'bind,jnd->bijn\', (wq+v, wkr)))\n        attn_score = (AC + BD).mul_(1/(self.d_head ** 0.5))\n        if mask is not None:\n            attn_score = attn_score.float().masked_fill(mask, -float(\'inf\')).type_as(attn_score)\n        attn_prob = self.drop_att(F.softmax(attn_score, dim=2))\n        attn_vec = torch.einsum(\'bijn,bjnd->bind\', (attn_prob, wv))\n        return attn_vec.contiguous().view(bs, x_len, -1)\n\nclass DecoderLayer(Module):\n    ""Basic block of a Transformer model.""\n    #Can\'t use Sequential directly cause more than one input...\n    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n                 bias:bool=True, scale:bool=True, act:Activation=Activation.ReLU, double_drop:bool=True,\n                 attn_cls:Callable=MultiHeadAttention):\n        self.mhra = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, act=act, double_drop=double_drop)\n\n    def forward(self, x:Tensor, mask:Tensor=None, **kwargs): return self.ff(self.mhra(x, mask=mask, **kwargs))\n\nclass Transformer(Module):\n    ""Transformer model: https://arxiv.org/abs/1706.03762.""\n    def __init__(self, vocab_sz:int, ctx_len:int, n_layers:int, n_heads:int, d_model:int, d_head:int, d_inner:int,\n                 resid_p:float=0., attn_p:float=0., ff_p:float=0., embed_p:float=0., bias:bool=True, scale:bool=True,\n                 act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=MultiHeadAttention,\n                 learned_pos_enc:bool=True, mask:bool=True):\n        self.mask = mask\n        self.encoder = nn.Embedding(vocab_sz, d_model)\n        self.pos_enc = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n        self.drop_emb = nn.Dropout(embed_p)\n        self.layers = nn.ModuleList([DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n                      ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop,\n                      attn_cls=attn_cls) for k in range(n_layers)])\n\n    def reset(self): pass\n    def select_hidden(self, idxs): pass\n\n    def forward(self, x):\n        bs, x_len = x.size()\n        pos = torch.arange(0, x_len, device=x.device, dtype=x.dtype)\n        inp = self.drop_emb(self.encoder(x) + self.pos_enc(pos)[None]) #.mul_(self.d_model ** 0.5)\n        mask = torch.triu(x.new_ones(x_len, x_len), diagonal=1).byte()[None,None] if self.mask else None\n        #[None,:,:None] for einsum implementation of attention\n        for layer in self.layers: inp = layer(inp, mask=mask)\n        return ([inp],[inp]) #For the LinearDecoder\n\nclass TransformerXL(Module):\n    ""TransformerXL model: https://arxiv.org/abs/1901.02860.""\n    def __init__(self, vocab_sz:int, ctx_len:int, n_layers:int, n_heads:int, d_model:int, d_head:int, d_inner:int,\n                 resid_p:float=0., attn_p:float=0., ff_p:float=0., embed_p:float=0., bias:bool=False, scale:bool=True,\n                 act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=MultiHeadRelativeAttention,\n                 learned_pos_enc:bool=False, mask:bool=True, mem_len:int=0):\n        self.encoder = nn.Embedding(vocab_sz, d_model)\n        self.pos_enc = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n        self.drop_emb = nn.Dropout(embed_p)\n        self.u = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n        self.v = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n        self.mem_len,self.n_layers,self.d_model,self.mask = mem_len,n_layers,d_model,mask\n        self.init = False\n        self.layers = nn.ModuleList([DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n                      ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop,\n                      attn_cls=attn_cls) for k in range(n_layers)])\n\n    def reset(self):\n        ""Reset the internal memory.""\n        self.hidden = [next(self.parameters()).data.new(0) for i in range(self.n_layers+1)]\n\n    def _update_mems(self, hids):\n        if not getattr(self, \'hidden\', False): return None\n        assert len(hids) == len(self.hidden), \'len(hids) != len(self.hidden)\'\n        with torch.no_grad():\n            for i in range(len(hids)):\n                cat = torch.cat([self.hidden[i], hids[i]], dim=1)\n                self.hidden[i] = cat[:,-self.mem_len:].detach()\n\n    def select_hidden(self, idxs): self.hidden = [h[idxs] for h in self.hidden]\n\n    def forward(self, x):\n        #The hidden state has to be initiliazed in the forward pass for nn.DataParallel\n        if self.mem_len > 0 and not self.init:\n            self.reset()\n            self.init = True\n        bs,x_len = x.size()\n        inp = self.drop_emb(self.encoder(x)) #.mul_(self.d_model ** 0.5)\n        m_len = self.hidden[0].size(1) if hasattr(self, \'hidden\') and len(self.hidden[0].size()) > 1 else 0\n        seq_len = m_len + x_len\n        mask = torch.triu(x.new_ones(x_len, seq_len), diagonal=1+m_len).byte()[None,None] if self.mask else None\n        #[None,:,:None] for einsum implementation of attention\n        hids = []\n        pos = torch.arange(seq_len-1, -1, -1, device=inp.device, dtype=inp.dtype)\n        pos_enc = self.pos_enc(pos)\n        hids.append(inp)\n        for i, layer in enumerate(self.layers):\n            mem = self.hidden[i] if self.mem_len > 0 else None\n            inp = layer(inp, r=pos_enc, u=self.u, v=self.v, mask=mask, mem=mem)\n            hids.append(inp)\n        core_out = inp[:,-x_len:]\n        if self.mem_len > 0 : self._update_mems(hids)\n        return (self.hidden if self.mem_len > 0 else [core_out]),[core_out]\n\ndef init_transformer(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Linear\') != -1:\n        if hasattr(m, \'weight\') and m.weight is not None: nn.init.normal_(m.weight, 0., 0.02)\n        if hasattr(m, \'bias\') and m.bias is not None:     nn.init.constant_(m.bias, 0.)\n    elif classname.find(\'LayerNorm\') != -1:\n        if hasattr(m, \'weight\') and m.weight is not None: nn.init.normal_(m.weight, 1., 0.02)\n        if hasattr(m, \'bias\') and m.bias is not None:     nn.init.constant_(m.bias, 0.)\n    elif classname.find(\'TransformerXL\') != -1:\n        if hasattr(m, \'u\'): nn.init.normal_(m.u, 0., 0.02)\n        if hasattr(m, \'v\'): nn.init.normal_(m.v, 0., 0.02)\n\ntfmer_lm_config = dict(ctx_len=512, n_layers=12, n_heads=12, d_model=768, d_head=64, d_inner=3072, resid_p=0.1, attn_p=0.1,\n                         ff_p=0.1, embed_p=0.1, output_p=0., bias=True, scale=True, act=Activation.GeLU, double_drop=False,\n                         tie_weights=True, out_bias=False, init=init_transformer, mask=True)\n\ntfmer_clas_config = dict(ctx_len=512, n_layers=12, n_heads=12, d_model=768, d_head=64, d_inner=3072, resid_p=0.1, attn_p=0.1,\n                         ff_p=0.1, embed_p=0.1, output_p=0., bias=True, scale=True, act=Activation.GeLU, double_drop=False,\n                         init=init_transformer, mask=False)\n\ndef tfmer_lm_split(model:nn.Module) -> List[nn.Module]:\n    ""Split a RNN `model` in groups for differential learning rates.""\n    encoder = model[0]\n    n = len(encoder.layers)//3\n    groups = [list(encoder.layers[:n]), list(encoder.layers[n:2*n]), list(encoder.layers[2*n:])]\n    return groups + [[encoder.encoder, model[1]]]\n\ndef tfmer_clas_split(model:nn.Module) -> List[nn.Module]:\n    ""Split a RNN `model` in groups for differential learning rates.""\n    encoder = model[0].module\n    n = len(encoder.layers)//3\n    groups = [[encoder.encoder], list(encoder.layers[:n]), list(encoder.layers[n:2*n]), list(encoder.layers[2*n:])]\n    return groups + [[model[1]]]\n\ntfmerXL_lm_config = dict(ctx_len=150, n_layers=12, n_heads=10, d_model=410, d_head=41, d_inner=2100, resid_p=0.1, attn_p=0.1,\n                         ff_p=0.1, embed_p=0.1, output_p=0.1, bias=False, scale=True, act=Activation.ReLU, double_drop=True,\n                         tie_weights=True, out_bias=True, init=init_transformer, mem_len=150, mask=True)\n\ntfmerXL_clas_config = dict(ctx_len=150, n_layers=12, n_heads=10, d_model=410, d_head=41, d_inner=2100, resid_p=0.1, attn_p=0.1,\n                         ff_p=0.1, embed_p=0.1, output_p=0.1, bias=False, scale=True, act=Activation.ReLU, double_drop=True,\n                         init=init_transformer, mem_len=150, mask=False)\n\ndef tfmerXL_lm_split(model:nn.Module) -> List[nn.Module]:\n    ""Split a RNN `model` in groups for differential learning rates.""\n    encoder = model[0]\n    n = len(encoder.layers)//3\n    groups = [list(encoder.layers[:n]) + [ParameterModule(encoder.u), ParameterModule(encoder.v)]]\n    return groups + [list(encoder.layers[n:2*n]), list(encoder.layers[2*n:]), [encoder.encoder, model[1]]]\n\ndef tfmerXL_clas_split(model:nn.Module) -> List[nn.Module]:\n    ""Split a RNN `model` in groups for differential learning rates.""\n    encoder = model[0].module\n    n = len(encoder.layers)//3\n    groups = [[encoder.encoder], list(encoder.layers[:n]) + [ParameterModule(encoder.u), ParameterModule(encoder.v)]]\n    return groups + [list(encoder.layers[n:2*n]), list(encoder.layers[2*n:]), [model[1]]]\n'"
fastai/vision/models/__init__.py,0,"b'from .xresnet import *\nfrom torchvision.models import ResNet,resnet18,resnet34,resnet50,resnet101,resnet152\nfrom torchvision.models import mobilenet_v2\nfrom torchvision.models import SqueezeNet,squeezenet1_0,squeezenet1_1\nfrom torchvision.models import densenet121,densenet169,densenet201,densenet161\nfrom torchvision.models import vgg11_bn,vgg13_bn,vgg16_bn,vgg19_bn,alexnet\nfrom .darknet import *\nfrom .unet import *\nfrom .wrn import *\nfrom .xception import *\n'"
fastai/vision/models/cadene_models.py,0,"b'#These models are dowloaded via the repo https://github.com/Cadene/pretrained-models.pytorch\n#See licence here: https://github.com/Cadene/pretrained-models.pytorch/blob/master/LICENSE.txt\nfrom torch import nn\nfrom ..learner import model_meta\nfrom ...core import *\n\npretrainedmodels = try_import(\'pretrainedmodels\')\nif not pretrainedmodels:\n    raise Exception(\'Error: `pretrainedmodels` is needed. `pip install pretrainedmodels`\')\n\n__all__ = [\'inceptionv4\', \'inceptionresnetv2\', \'nasnetamobile\', \'dpn92\', \'xception_cadene\', \'se_resnet50\',\n           \'se_resnet101\', \'se_resnext50_32x4d\', \'senet154\', \'pnasnet5large\']\n\ndef get_model(model_name:str, pretrained:bool, seq:bool=False, pname:str=\'imagenet\', **kwargs):\n    pretrained = pname if pretrained else None\n    model = getattr(pretrainedmodels, model_name)(pretrained=pretrained, **kwargs)\n    return nn.Sequential(*model.children()) if seq else model\n\ndef inceptionv4(pretrained:bool=False):\n    model = get_model(\'inceptionv4\', pretrained)\n    all_layers = list(model.children())\n    return nn.Sequential(*all_layers[0], *all_layers[1:])\nmodel_meta[inceptionv4] = {\'cut\': -2, \'split\': lambda m: (m[0][11], m[1])}\n\ndef nasnetamobile(pretrained:bool=False):\n    model = get_model(\'nasnetamobile\', pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[nasnetamobile] = {\'cut\': noop, \'split\': lambda m: (list(m[0][0].children())[8], m[1])}\n\ndef pnasnet5large(pretrained:bool=False):\n    model = get_model(\'pnasnet5large\', pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[pnasnet5large] = {\'cut\': noop, \'split\': lambda m: (list(m[0][0].children())[8], m[1])}\n\ndef inceptionresnetv2(pretrained:bool=False):   return get_model(\'inceptionresnetv2\', pretrained, seq=True)\ndef dpn92(pretrained:bool=False):               return get_model(\'dpn92\', pretrained, pname=\'imagenet+5k\', seq=True)\ndef xception_cadene(pretrained=False):          return get_model(\'xception\', pretrained, seq=True)\ndef se_resnet50(pretrained:bool=False):         return get_model(\'se_resnet50\', pretrained)\ndef se_resnet101(pretrained:bool=False):        return get_model(\'se_resnet101\', pretrained)\ndef se_resnext50_32x4d(pretrained:bool=False):  return get_model(\'se_resnext50_32x4d\', pretrained)\ndef se_resnext101_32x4d(pretrained:bool=False): return get_model(\'se_resnext101_32x4d\', pretrained)\ndef senet154(pretrained:bool=False):            return get_model(\'senet154\', pretrained)\n\nmodel_meta[inceptionresnetv2] = {\'cut\': -2, \'split\': lambda m: (m[0][9],     m[1])}\nmodel_meta[dpn92]             = {\'cut\': -1, \'split\': lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene]   = {\'cut\': -1, \'split\': lambda m: (m[0][11],    m[1])}\nmodel_meta[senet154]          = {\'cut\': -3, \'split\': lambda m: (m[0][3],     m[1])}\n_se_resnet_meta               = {\'cut\': -2, \'split\': lambda m: (m[0][3],     m[1])}\nmodel_meta[se_resnet50]         = _se_resnet_meta\nmodel_meta[se_resnet101]        = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d]  = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n\n# TODO: add ""resnext101_32x4d"" ""resnext101_64x4d"" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128\n'"
fastai/vision/models/darknet.py,0,"b'from ...torch_core import *\nfrom ...layers import *\n\n__all__ = [\'Darknet\', \'ResLayer\']\n\ndef conv_bn_lrelu(ni:int, nf:int, ks:int=3, stride:int=1)->nn.Sequential:\n    ""Create a seuence Conv2d->BatchNorm2d->LeakyReLu layer.""\n    return nn.Sequential(\n        nn.Conv2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks//2),\n        nn.BatchNorm2d(nf),\n        nn.LeakyReLU(negative_slope=0.1, inplace=True))\n\nclass ResLayer(Module):\n    ""Resnet style layer with `ni` inputs.""\n    def __init__(self, ni:int):\n        self.conv1 = conv_bn_lrelu(ni, ni//2, ks=1)\n        self.conv2 = conv_bn_lrelu(ni//2, ni, ks=3)\n\n    def forward(self, x): return x + self.conv2(self.conv1(x))\n\nclass Darknet(Module):\n    ""https://github.com/pjreddie/darknet""\n    def make_group_layer(self, ch_in:int, num_blocks:int, stride:int=1):\n        ""starts with conv layer - `ch_in` channels in - then has `num_blocks` `ResLayer`""\n        return [conv_bn_lrelu(ch_in, ch_in*2,stride=stride)\n               ] + [(ResLayer(ch_in*2)) for i in range(num_blocks)]\n\n    def __init__(self, num_blocks:Collection[int], num_classes:int, nf=32):\n        ""create darknet with `nf` and `num_blocks` layers""\n        layers = [conv_bn_lrelu(3, nf, ks=3, stride=1)]\n        for i,nb in enumerate(num_blocks):\n            layers += self.make_group_layer(nf, nb, stride=2)\n            nf *= 2\n        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x): return self.layers(x)\n'"
fastai/vision/models/efficientnet.py,0,"b""from ...core import *\r\n\r\npretrainedmodels = try_import('efficientnet_pytorch') \r\n\r\nif not pretrainedmodels:\r\n    raise Exception('Error: efficientnet-pytorch is needed. pip install efficientnet-pytorch')\r\nfrom efficientnet_pytorch import EfficientNet\r\n\r\ndef EfficientNetB1(data): return EfficientNet.from_pretrained('efficientnet-b1', num_classes=data.c)\r\ndef EfficientNetB2(data): return EfficientNet.from_pretrained('efficientnet-b2', num_classes=data.c)\r\ndef EfficientNetB3(data): return EfficientNet.from_pretrained('efficientnet-b3', num_classes=data.c)\r\ndef EfficientNetB4(data): return EfficientNet.from_pretrained('efficientnet-b4', num_classes=data.c)\r\ndef EfficientNetB5(data): return EfficientNet.from_pretrained('efficientnet-b5', num_classes=data.c)\r\ndef EfficientNetB6(data): return EfficientNet.from_pretrained('efficientnet-b6', num_classes=data.c)\r\ndef EfficientNetB7(data): return EfficientNet.from_pretrained('efficientnet-b7', num_classes=data.c)\r\n"""
fastai/vision/models/presnet.py,4,"b""from pdb import set_trace\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ...torch_core import Module\n\n__all__ = ['PResNet', 'presnet18', 'presnet34', 'presnet50', 'presnet101', 'presnet152']\n\nact_fn = nn.ReLU\n\ndef init_cnn(m):\n    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n    if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, nn.Linear): m.weight.data.normal_(0, 0.01)\n    for l in m.children(): init_cnn(l)\n\ndef conv(ni, nf, ks=3, stride=1, bias=False):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n\ndef conv_layer(conv_1st, ni, nf, ks=3, stride=1, zero_bn=False, bias=False):\n    bn = nn.BatchNorm2d(nf if conv_1st else ni)\n    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n    res = [act_fn(), bn]\n    cn = conv(ni, nf, ks, stride=stride, bias=bias)\n    res.insert(0 if conv_1st else 2, cn)\n    return nn.Sequential(*res)\n\ndef conv_act(*args, **kwargs): return conv_layer(True , *args, **kwargs)\ndef act_conv(*args, **kwargs): return conv_layer(False, *args, **kwargs)\n\nclass BasicBlock(Module):\n    expansion = 1\n\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = act_conv(ni, nf, stride=stride)\n        self.conv2 = act_conv(nf, nf, zero_bn=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x if self.downsample is None else self.downsample(x)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x += identity\n        return x\n\nclass Bottleneck(Module):\n    expansion = 4\n\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = act_conv(ni, nf, 1)\n        self.conv2 = act_conv(nf, nf, stride=stride)\n        self.conv3 = act_conv(nf, nf*self.expansion, 1)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x if self.downsample is None else self.downsample(x)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x += identity\n        return x\n\nclass PResNet(Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.ni = 64\n        super().__init__()\n        self.conv1 = conv_act(3, 16, stride=2)\n        self.conv2 = conv_act(16, 32)\n        self.conv3 = conv_act(32, 64)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        ni = 512*block.expansion\n        self.avgpool = nn.Sequential(\n            act_fn(), nn.BatchNorm2d(ni), nn.AdaptiveAvgPool2d(1))\n        self.fc = nn.Linear(ni, num_classes)\n\n        init_cnn(self)\n\n    def _make_layer(self, block, nf, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.ni != nf*block.expansion:\n            layers = [act_fn(), nn.BatchNorm2d(self.ni),\n                      nn.AvgPool2d(kernel_size=2)] if stride==2 else []\n            layers.append(conv(self.ni, nf*block.expansion))\n            downsample = nn.Sequential(*layers)\n\n        layers = [block(self.ni, nf, stride, downsample)]\n        self.ni = nf*block.expansion\n        for i in range(1, blocks): layers.append(block(self.ni, nf))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\nmodel_urls = dict(presnet34='presnet34', presnet50='presnet50')\n\ndef presnet(block, n_layers, name, pre=False, **kwargs):\n    model = PResNet(block, n_layers, **kwargs)\n    #if pre: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    if pre: model.load_state_dict(torch.load(model_urls[name]))\n    return model\n\ndef presnet18(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [2, 2, 2, 2], 'presnet18', pre=pretrained, **kwargs)\n\ndef presnet34(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [3, 4, 6, 3], 'presnet34', pre=pretrained, **kwargs)\n\ndef presnet50(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 6, 3], 'presnet50', pre=pretrained, **kwargs)\n\ndef presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], 'presnet101', pre=pretrained, **kwargs)\n\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], 'presnet152', pre=pretrained, **kwargs)\n\n"""
fastai/vision/models/unet.py,1,"b'from ...torch_core import *\nfrom ...layers import *\nfrom ...callbacks.hooks import *\n\n__all__ = [\'DynamicUnet\', \'UnetBlock\']\n\ndef _get_sfs_idxs(sizes:Sizes) -> List[int]:\n    ""Get the indexes of the layers where the size of the activation changes.""\n    feature_szs = [size[-1] for size in sizes]\n    sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n    if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n    return sfs_idxs\n\nclass UnetBlock(Module):\n    ""A quasi-UNet block, using `PixelShuffle_ICNR upsampling`.""\n    def __init__(self, up_in_c:int, x_in_c:int, hook:Hook, final_div:bool=True, blur:bool=False, leaky:float=None,\n                 self_attention:bool=False, **kwargs):\n        self.hook = hook\n        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, leaky=leaky, **kwargs)\n        self.bn = batchnorm_2d(x_in_c)\n        ni = up_in_c//2 + x_in_c\n        nf = ni if final_div else ni//2\n        self.conv1 = conv_layer(ni, nf, leaky=leaky, **kwargs)\n        self.conv2 = conv_layer(nf, nf, leaky=leaky, self_attention=self_attention, **kwargs)\n        self.relu = relu(leaky=leaky)\n\n    def forward(self, up_in:Tensor) -> Tensor:\n        s = self.hook.stored\n        up_out = self.shuf(up_in)\n        ssh = s.shape[-2:]\n        if ssh != up_out.shape[-2:]:\n            up_out = F.interpolate(up_out, s.shape[-2:], mode=\'nearest\')\n        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n        return self.conv2(self.conv1(cat_x))\n\n\nclass DynamicUnet(SequentialEx):\n    ""Create a U-Net from a given architecture.""\n    def __init__(self, encoder:nn.Module, n_classes:int, img_size:Tuple[int,int]=(256,256), blur:bool=False, blur_final=True, self_attention:bool=False,\n                 y_range:Optional[Tuple[float,float]]=None,\n                 last_cross:bool=True, bottle:bool=False, **kwargs):\n        imsize = img_size\n        sfs_szs = model_sizes(encoder, size=imsize)\n        sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\n        self.sfs = hook_outputs([encoder[i] for i in sfs_idxs], detach=False)\n        x = dummy_eval(encoder, imsize).detach()\n\n        ni = sfs_szs[-1][1]\n        middle_conv = nn.Sequential(conv_layer(ni, ni*2, **kwargs),\n                                    conv_layer(ni*2, ni, **kwargs)).eval()\n        x = middle_conv(x)\n        layers = [encoder, batchnorm_2d(ni), nn.ReLU(), middle_conv]\n\n        for i,idx in enumerate(sfs_idxs):\n            not_final = i!=len(sfs_idxs)-1\n            up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\n            do_blur = blur and (not_final or blur_final)\n            sa = self_attention and (i==len(sfs_idxs)-3)\n            unet_block = UnetBlock(up_in_c, x_in_c, self.sfs[i], final_div=not_final, blur=do_blur, self_attention=sa,\n                                   **kwargs).eval()\n            layers.append(unet_block)\n            x = unet_block(x)\n\n        ni = x.shape[1]\n        if imsize != sfs_szs[0][-2:]: layers.append(PixelShuffle_ICNR(ni, **kwargs))\n        x = PixelShuffle_ICNR(ni)(x)\n        if imsize != x.shape[-2:]: layers.append(Lambda(lambda x: F.interpolate(x, imsize, mode=\'nearest\')))\n        if last_cross:\n            layers.append(MergeLayer(dense=True))\n            ni += in_channels(encoder)\n            layers.append(res_block(ni, bottle=bottle, **kwargs))\n        layers += [conv_layer(ni, n_classes, ks=1, use_activ=False, **kwargs)]\n        if y_range is not None: layers.append(SigmoidRange(*y_range))\n        super().__init__(*layers)\n\n    def __del__(self):\n        if hasattr(self, ""sfs""): self.sfs.remove()\n\n'"
fastai/vision/models/wrn.py,0,"b'from ...layers import *\nfrom ...torch_core import *\n\n__all__ = [\'BasicBlock\', \'WideResNet\', \'wrn_22\']\n\ndef _bn(ni, init_zero=False):\n    ""Batchnorm layer with 0 initialization""\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = _bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv2d(ni, nf, ks, stride))\n\nclass BasicBlock(Module):\n    ""Block to from a wide ResNet.""\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv2d(ni, nf, 1, stride) if ni != nf else noop\n\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)\n        r = self.shortcut(x2)\n        x = self.conv1(x2)\n        if self.drop: x = self.drop(x)\n        x = self.conv2(x) * 0.2\n        return x.add_(r)\n\ndef _make_group(N, ni, nf, block, stride, drop_p):\n    return [block(ni if i == 0 else nf, nf, stride if i == 0 else 1, drop_p) for i in range(N)]\n\nclass WideResNet(Module):\n    ""Wide ResNet with `num_groups` and a width of `k`.""\n    def __init__(self, num_groups:int, N:int, num_classes:int, k:int=1, drop_p:float=0.0, start_nf:int=16, n_in_channels:int=3):\n        n_channels = [start_nf]\n        for i in range(num_groups): n_channels.append(start_nf*(2**i)*k)\n\n        layers = [conv2d(n_in_channels, n_channels[0], 3, 1)]  # conv1\n        for i in range(num_groups):\n            layers += _make_group(N, n_channels[i], n_channels[i+1], BasicBlock, (1 if i==0 else 2), drop_p)\n\n        layers += [nn.BatchNorm2d(n_channels[num_groups]), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),\n                   Flatten(), nn.Linear(n_channels[num_groups], num_classes)]\n        self.features = nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef wrn_22(): \n    ""Wide ResNet with 22 layers.""\n    return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.)\n'"
fastai/vision/models/xception.py,0,"b'from ...vision import *\n\n__all__ = [\'xception\']\n\ndef sep_conv(ni,nf,pad=None,pool=False,act=True):\n    layers =  [nn.ReLU()] if act else []\n    layers += [\n        nn.Conv2d(ni,ni,3,1,1,groups=ni,bias=False),\n        nn.Conv2d(ni,nf,1,bias=False),\n        nn.BatchNorm2d(nf)\n    ]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n\ndef conv(ni,nf,ks=1,stride=1, pad=None, act=True):\n    if pad is None: pad=ks//2\n    layers = [\n        nn.Conv2d(ni,nf,ks,stride,pad,bias=False),\n        nn.BatchNorm2d(nf),\n    ]\n    if act: layers.append(nn.ReLU())\n    return nn.Sequential(*layers)\n\nclass ConvSkip(Module):\n    def __init__(self,ni,nf=None,act=True):\n        self.nf,self.ni = nf,ni\n        if self.nf is None: self.nf = ni\n        self.conv = conv(ni,nf,stride=2, act=False)\n        self.m = nn.Sequential(\n            sep_conv(ni,ni,act=act),\n            sep_conv(ni,nf,pool=True)\n        )\n\n    def forward(self,x): return self.conv(x) + self.m(x)\n\ndef middle_flow(nf):\n    layers = [sep_conv(nf,nf) for i in range(3)]\n    return SequentialEx(*layers, MergeLayer())\n\ndef xception(c, k=8, n_middle=8):\n    ""Preview version of Xception network. Not tested yet - use at own risk. No pretrained model yet.""\n    layers = [\n        conv(3, k*4, 3, 2),\n        conv(k*4, k*8, 3),\n        ConvSkip(k*8, k*16, act=False),\n        ConvSkip(k*16, k*32),\n        ConvSkip(k*32, k*91),\n    ]\n    for i in range(n_middle): layers.append(middle_flow(k*91))\n    layers += [\n        ConvSkip(k*91,k*128),\n        sep_conv(k*128,k*192,act=False),\n        sep_conv(k*192,k*256),\n        nn.ReLU(),\n        nn.AdaptiveAvgPool2d(1),\n        Flatten(),\n        nn.Linear(k*256,c)\n    ]\n    return nn.Sequential(*layers)\n\n'"
fastai/vision/models/xresnet.py,2,"b""import torch.nn as nn\nimport torch,math,sys\nimport torch.utils.model_zoo as model_zoo\nfrom functools import partial\nfrom ...torch_core import Module\n\n__all__ = ['XResNet', 'xresnet18', 'xresnet34', 'xresnet50', 'xresnet101', 'xresnet152',\n           'xresnet18_deep', 'xresnet34_deep', 'xresnet50_deep']\n\n# or: ELU+init (a=0.54; gain=1.55)\nact_fn = nn.ReLU(inplace=True)\n\nclass Flatten(Module):\n    def forward(self, x): return x.view(x.size(0), -1)\n\ndef init_cnn(m):\n    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n    for l in m.children(): init_cnn(l)\n\ndef conv(ni, nf, ks=3, stride=1, bias=False):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n\ndef noop(x): return x\n\ndef conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n    bn = nn.BatchNorm2d(nf)\n    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n    layers = [conv(ni, nf, ks, stride=stride), bn]\n    if act: layers.append(act_fn)\n    return nn.Sequential(*layers)\n\nclass ResBlock(Module):\n    def __init__(self, expansion, ni, nh, stride=1):\n        nf,ni = nh*expansion,ni*expansion\n        layers  = [conv_layer(ni, nh, 3, stride=stride),\n                   conv_layer(nh, nf, 3, zero_bn=True, act=False)\n        ] if expansion == 1 else [\n                   conv_layer(ni, nh, 1),\n                   conv_layer(nh, nh, 3, stride=stride),\n                   conv_layer(nh, nf, 1, zero_bn=True, act=False)\n        ]\n        self.convs = nn.Sequential(*layers)\n        # TODO: check whether act=True works better\n        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False)\n        self.pool = noop if stride==1 else nn.AvgPool2d(stride, ceil_mode=True)\n\n    def forward(self, x): return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n\ndef filt_sz(recep): return min(64, 2**math.floor(math.log2(recep*0.75)))\n\nclass XResNet(nn.Sequential):\n    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n        stem = []\n        sizes = [c_in,32,32,64]\n        for i in range(3):\n            stem.append(conv_layer(sizes[i], sizes[i+1], stride=2 if i==0 else 1))\n            #nf = filt_sz(c_in*9)\n            #stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))\n            #c_in = nf\n\n        block_szs = [64//expansion,64,128,256,512] +[256]*(len(layers)-4)\n        blocks = [self._make_layer(expansion, block_szs[i], block_szs[i+1], l, 1 if i==0 else 2)\n                  for i,l in enumerate(layers)]\n        super().__init__(\n            *stem,\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            *blocks,\n            nn.AdaptiveAvgPool2d(1), Flatten(),\n            nn.Linear(block_szs[-1]*expansion, c_out),\n        )\n        init_cnn(self)\n\n    def _make_layer(self, expansion, ni, nf, blocks, stride):\n        return nn.Sequential(\n            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n              for i in range(blocks)])\n\ndef xresnet(expansion, n_layers, name, c_out=1000, pretrained=False, **kwargs):\n    model = XResNet(expansion, n_layers, c_out=c_out, **kwargs)\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    return model\n\nme = sys.modules[__name__]\nfor n,e,l in [\n    [ 18 , 1, [2,2,2 ,2] ],\n    [ 34 , 1, [3,4,6 ,3] ],\n    [ 50 , 4, [3,4,6 ,3] ],\n    [ 101, 4, [3,4,23,3] ],\n    [ 152, 4, [3,8,36,3] ],\n]:\n    name = f'xresnet{n}'\n    setattr(me, name, partial(xresnet, expansion=e, n_layers=l, name=name))\n\nxresnet18_deep = partial(xresnet, expansion=1, n_layers=[2, 2,  2, 2,1,1], name='xresnet18_deep')\nxresnet34_deep = partial(xresnet, expansion=1, n_layers=[3, 4,  6, 3,1,1], name='xresnet34_deep')\nxresnet50_deep = partial(xresnet, expansion=4, n_layers=[3, 4,  6, 3,1,1], name='xresnet50_deep')\n\n"""
fastai/vision/models/xresnet2.py,4,"b'import torch.nn as nn\nimport torch\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ...torch_core import Module\n\n\n__all__ = [\'XResNet\', \'xresnet18\', \'xresnet34_2\', \'xresnet50_2\', \'xresnet101\', \'xresnet152\']\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n\nclass BasicBlock(Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\ndef conv2d(ni, nf, stride):\n    return nn.Sequential(nn.Conv2d(ni, nf, kernel_size=3, stride=stride, padding=1, bias=False),\n                         nn.BatchNorm2d(nf), nn.ReLU(inplace=True))\n\nclass XResNet(Module):\n\n    def __init__(self, block, layers, c_out=1000):\n        self.inplanes = 64\n        super(XResNet, self).__init__()\n        self.conv1 = conv2d(3, 32, 2)\n        self.conv2 = conv2d(32, 32, 1)\n        self.conv3 = conv2d(32, 64, 1)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(512 * block.expansion, c_out)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\'fan_out\', nonlinearity=\'relu\')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        for m in self.modules():\n            if isinstance(m, BasicBlock): m.bn2.weight = nn.Parameter(torch.zeros_like(m.bn2.weight))\n            if isinstance(m, Bottleneck): m.bn3.weight = nn.Parameter(torch.zeros_like(m.bn3.weight))\n            if isinstance(m, nn.Linear): m.weight.data.normal_(0, 0.01)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            layers = []\n            if stride==2: layers.append(nn.AvgPool2d(kernel_size=2, stride=2))\n            layers += [\n                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=1, bias=False),\n                nn.BatchNorm2d(planes * block.expansion) ]\n            downsample = nn.Sequential(*layers)\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef xresnet18(pretrained=False, **kwargs):\n    """"""Constructs a XResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = XResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[\'xresnet18\']))\n    return model\n\n\ndef xresnet34_2(pretrained=False, **kwargs):\n    """"""Constructs a XResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = XResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[\'xresnet34\']))\n    return model\n\n\ndef xresnet50_2(pretrained=False, **kwargs):\n    """"""Constructs a XResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = XResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[\'xresnet50\']))\n    return model\n\n\ndef xresnet101(pretrained=False, **kwargs):\n    """"""Constructs a XResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = XResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[\'xresnet101\']))\n    return model\n\n\ndef xresnet152(pretrained=False, **kwargs):\n    """"""Constructs a XResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = XResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[\'xresnet152\']))\n    return model\n\n'"
old/fastai/models/convert_torch.py,13,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.serialization import load_lua\n\nimport numpy as np\nimport os\nimport math\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        # result is Variables list [Variable1, Variable2, ...]\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        # result is a Variable\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef copy_param(m,n):\n    if m.weight is not None: n.weight.data.copy_(m.weight)\n    if m.bias is not None: n.bias.data.copy_(m.bias)\n    if hasattr(n,\'running_mean\'): n.running_mean.copy_(m.running_mean)\n    if hasattr(n,\'running_var\'): n.running_var.copy_(m.running_var)\n\ndef add_submodule(seq, *args):\n    for n in args:\n        seq.add_module(str(len(seq._modules)),n)\n\ndef lua_recursive_model(module,seq):\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            n = nn.Conv2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,bias=(m.bias is not None))\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'SpatialBatchNormalization\':\n            n = nn.BatchNorm2d(m.running_mean.size(0), m.eps, m.momentum, m.affine)\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'ReLU\':\n            n = nn.ReLU()\n            add_submodule(seq,n)\n        elif name == \'SpatialMaxPooling\':\n            n = nn.MaxPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialAveragePooling\':\n            n = nn.AvgPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialUpSamplingNearest\':\n            n = nn.UpsamplingNearest2d(scale_factor=m.scale_factor)\n            add_submodule(seq,n)\n        elif name == \'View\':\n            n = Lambda(lambda x: x.view(x.size(0),-1))\n            add_submodule(seq,n)\n        elif name == \'Linear\':\n            # Linear in pytorch only accept 2D input\n            n1 = Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\n            n2 = nn.Linear(m.weight.size(1),m.weight.size(0),bias=(m.bias is not None))\n            copy_param(m,n2)\n            n = nn.Sequential(n1,n2)\n            add_submodule(seq,n)\n        elif name == \'Dropout\':\n            m.inplace = False\n            n = nn.Dropout(m.p)\n            add_submodule(seq,n)\n        elif name == \'SoftMax\':\n            n = nn.Softmax()\n            add_submodule(seq,n)\n        elif name == \'Identity\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'SpatialFullConvolution\':\n            n = nn.ConvTranspose2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))\n            add_submodule(seq,n)\n        elif name == \'SpatialReplicationPadding\':\n            n = nn.ReplicationPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'SpatialReflectionPadding\':\n            n = nn.ReflectionPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'Copy\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'Narrow\':\n            n = Lambda(lambda x,a=(m.dimension,m.index,m.length): x.narrow(*a))\n            add_submodule(seq,n)\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = torch.legacy.nn.SpatialCrossMapLRN(m.size,m.alpha,m.beta,m.k)\n            n = Lambda(lambda x,lrn=lrn: Variable(lrn.forward(x.data)))\n            add_submodule(seq,n)\n        elif name == \'Sequential\':\n            n = nn.Sequential()\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'ConcatTable\': # output is list\n            n = LambdaMap(lambda x: x)\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'CAddTable\': # input is list\n            n = LambdaReduce(lambda x,y: x+y)\n            add_submodule(seq,n)\n        elif name == \'Concat\':\n            dim = m.dimension\n            n = LambdaReduce(lambda x,y,dim=dim: torch.cat((x,y),dim))\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'TorchObject\':\n            print(\'Not Implement\',name,real._typename)\n        else:\n            print(\'Not Implement\',name)\n\n\ndef lua_recursive_source(module):\n    s = []\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            s += [\'nn.Conv2d({},{},{},{},{},{},{},bias={}),#Conv2d\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,m.bias is not None)]\n        elif name == \'SpatialBatchNormalization\':\n            s += [\'nn.BatchNorm2d({},{},{},{}),#BatchNorm2d\'.format(m.running_mean.size(0), m.eps, m.momentum, m.affine)]\n        elif name == \'ReLU\':\n            s += [\'nn.ReLU()\']\n        elif name == \'SpatialMaxPooling\':\n            s += [\'nn.MaxPool2d({},{},{},ceil_mode={}),#MaxPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialAveragePooling\':\n            s += [\'nn.AvgPool2d({},{},{},ceil_mode={}),#AvgPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialUpSamplingNearest\':\n            s += [\'nn.UpsamplingNearest2d(scale_factor={})\'.format(m.scale_factor)]\n        elif name == \'View\':\n            s += [\'Lambda(lambda x: x.view(x.size(0),-1)), # View\']\n        elif name == \'Linear\':\n            s1 = \'Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\'\n            s2 = \'nn.Linear({},{},bias={})\'.format(m.weight.size(1),m.weight.size(0),(m.bias is not None))\n            s += [\'nn.Sequential({},{}),#Linear\'.format(s1,s2)]\n        elif name == \'Dropout\':\n            s += [\'nn.Dropout({})\'.format(m.p)]\n        elif name == \'SoftMax\':\n            s += [\'nn.Softmax()\']\n        elif name == \'Identity\':\n            s += [\'Lambda(lambda x: x), # Identity\']\n        elif name == \'SpatialFullConvolution\':\n            s += [\'nn.ConvTranspose2d({},{},{},{},{})\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))]\n        elif name == \'SpatialReplicationPadding\':\n            s += [\'nn.ReplicationPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'SpatialReflectionPadding\':\n            s += [\'nn.ReflectionPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'Copy\':\n            s += [\'Lambda(lambda x: x), # Copy\']\n        elif name == \'Narrow\':\n            s += [\'Lambda(lambda x,a={}: x.narrow(*a))\'.format((m.dimension,m.index,m.length))]\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = \'torch.legacy.nn.SpatialCrossMapLRN(*{})\'.format((m.size,m.alpha,m.beta,m.k))\n            s += [\'Lambda(lambda x,lrn={}: Variable(lrn.forward(x.data)))\'.format(lrn)]\n\n        elif name == \'Sequential\':\n            s += [\'nn.Sequential( # Sequential\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'ConcatTable\':\n            s += [\'LambdaMap(lambda x: x, # ConcatTable\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'CAddTable\':\n            s += [\'LambdaReduce(lambda x,y: x+y), # CAddTable\']\n        elif name == \'Concat\':\n            dim = m.dimension\n            s += [\'LambdaReduce(lambda x,y,dim={}: torch.cat((x,y),dim), # Concat\'.format(m.dimension)]\n            s += lua_recursive_source(m)\n            s += [\')\']\n        else:\n            s += \'# \' + name + \' Not Implement,\\n\'\n    s = map(lambda x: \'\\t{}\'.format(x),s)\n    return s\n\ndef simplify_source(s):\n    s = map(lambda x: x.replace(\',(1, 1),(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1e-05,0.1,True),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True)),#Linear\',\')), # Linear\'),s)\n    s = map(lambda x: x.replace(\')),#Linear\',\')), # Linear\'),s)\n    \n    s = map(lambda x: \'{},\\n\'.format(x),s)\n    s = map(lambda x: x[1:],s)\n    s = reduce(lambda x,y: x+y, s)\n    return s\n\ndef torch_to_pytorch(t7_filename,outputname=None):\n    model = load_lua(t7_filename,unknown_classes=True)\n    if type(model).__name__==\'hashable_uniq_dict\': model=model.model\n    model.gradInput = None\n    slist = lua_recursive_source(torch.legacy.nn.Sequential().add(model))\n    s = simplify_source(slist)\n    header = \'\'\'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\'\'\'\n    varname = t7_filename.replace(\'.t7\',\'\').replace(\'.\',\'_\').replace(\'-\',\'_\')\n    s = \'{}\\n\\n{} = {}\'.format(header,varname,s[:-2])\n\n    if outputname is None: outputname=varname\n    with open(outputname+\'.py\', ""w"") as pyfile:\n        pyfile.write(s)\n\n    n = nn.Sequential()\n    lua_recursive_model(model,n)\n    torch.save(n.state_dict(),outputname+\'.pth\')\n\n\nparser = argparse.ArgumentParser(description=\'Convert torch t7 model to pytorch\')\nparser.add_argument(\'--model\',\'-m\', type=str, required=True,\n                    help=\'torch model file in t7 format\')\nparser.add_argument(\'--output\', \'-o\', type=str, default=None,\n                    help=\'output file name prefix, xxx.py xxx.pth\')\nargs = parser.parse_args()\n\ntorch_to_pytorch(args.model,args.output)\n'"
old/fastai/models/darknet.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ..layers import *\n\nclass ConvBN(nn.Module):\n    ""convolutional layer then batchnorm""\n\n    def __init__(self, ch_in, ch_out, kernel_size = 3, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(ch_out, momentum=0.01)\n        self.relu = nn.LeakyReLU(0.1, inplace=True)\n\n    def forward(self, x): return self.relu(self.bn(self.conv(x)))\n\nclass DarknetBlock(nn.Module):\n    def __init__(self, ch_in):\n        super().__init__()\n        ch_hid = ch_in//2\n        self.conv1 = ConvBN(ch_in, ch_hid, kernel_size=1, stride=1, padding=0)\n        self.conv2 = ConvBN(ch_hid, ch_in, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x): return self.conv2(self.conv1(x)) + x\n\nclass Darknet(nn.Module):\n    ""Replicates the darknet classifier from the YOLOv3 paper (table 1)""\n\n    def make_group_layer(self, ch_in, num_blocks, stride=1):\n        layers = [ConvBN(ch_in,ch_in*2,stride=stride)]\n        for i in range(num_blocks): layers.append(DarknetBlock(ch_in*2))\n        return layers\n\n    def __init__(self, num_blocks, num_classes=1000, start_nf=32):\n        super().__init__()\n        nf = start_nf\n        layers = [ConvBN(3, nf, kernel_size=3, stride=1, padding=1)]\n        for i,nb in enumerate(num_blocks):\n            layers += self.make_group_layer(nf, nb, stride=(1 if i==1 else 2))\n            nf *= 2\n        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x): return self.layers(x)\n\ndef darknet_53(num_classes=1000):    return Darknet([1,2,8,8,4], num_classes)\ndef darknet_small(num_classes=1000): return Darknet([1,2,4,8,4], num_classes)\ndef darknet_mini(num_classes=1000): return Darknet([1,2,4,4,2], num_classes, start_nf=24)\ndef darknet_mini2(num_classes=1000): return Darknet([1,2,8,8,4], num_classes, start_nf=16)\ndef darknet_mini3(num_classes=1000): return Darknet([1,2,4,4], num_classes)\n\n'"
old/fastai/models/fa_resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\nfrom collections import OrderedDict\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out += residual\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out += residual\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\ndef load(model, pretrained, name):\n    if pretrained: model.load_state_dict(updated_dict(model_zoo.load_url(model_urls[name]),model.state_dict()))\n    return model\n\ndef updated_dict(pre_dict,current_dict):\n    new_dict = OrderedDict()\n    for current_dict_key,pre_dic_val in zip(current_dict.keys(),pre_dict.values()):\n        new_dict[current_dict_key] = pre_dict_val\n    return new_dict \n    \ndef fa_resnet18(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [2, 2, 2, 2], **kwargs), pretrained, \'resnet18\')\ndef fa_resnet34(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [3, 4, 6, 3], **kwargs), pretrained, \'resnet34\')\ndef fa_resnet50(pretrained=False, **kwargs):  return load(ResNet(Bottleneck, [3, 4, 6, 3], **kwargs), pretrained, \'resnet50\')\ndef fa_resnet101(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 4, 23, 3], **kwargs), pretrained, \'resnet101\')\ndef fa_resnet152(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 8, 36, 3], **kwargs), pretrained, \'resnet152\')\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 ():  return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50():  return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck,[3, 4, 6, 3], k=1.125)\ndef vgg_resnet50():  return ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n\n'"
old/fastai/models/inceptionresnetv2.py,8,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'http://data.lip6.fr/cadene/pretrainedmodels/inceptionresnetv2-520b38e4.pth\'\n}\n\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes,\n                              kernel_size=kernel_size, stride=stride,\n                              padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes,\n                                 eps=0.001, # value found in tensorflow\n                                 momentum=0.1, # default pytorch value\n                                 affine=True)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass Mixed_5b(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5b, self).__init__()\n\n        self.branch0 = BasicConv2d(192, 96, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(192, 48, kernel_size=1, stride=1),\n            BasicConv2d(48, 64, kernel_size=5, stride=1, padding=2)\n        ) \n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(192, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(192, 64, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\n\nclass Block35(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block35, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(320, 32, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 48, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(48, 64, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.conv2d = nn.Conv2d(128, 320, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\n\nclass Mixed_6a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_6a, self).__init__()\n        \n        self.branch0 = BasicConv2d(320, 384, kernel_size=3, stride=2)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\n\nclass Block17(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block17, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(1088, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 128, kernel_size=1, stride=1),\n            BasicConv2d(128, 160, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(160, 192, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.conv2d = nn.Conv2d(384, 1088, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\n\nclass Mixed_7a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_7a, self).__init__()\n        \n        self.branch0 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(288, 320, kernel_size=3, stride=2)\n        )\n\n        self.branch3 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\n\nclass Block8(nn.Module):\n\n    def __init__(self, scale=1.0, noReLU=False):\n        super(Block8, self).__init__()\n\n        self.scale = scale\n        self.noReLU = noReLU\n\n        self.branch0 = BasicConv2d(2080, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(2080, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,3), stride=1, padding=(0,1)),\n            BasicConv2d(224, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        )\n\n        self.conv2d = nn.Conv2d(448, 2080, kernel_size=1, stride=1)\n        if not self.noReLU:\n            self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        if not self.noReLU:\n            out = self.relu(out)\n        return out\n\n\nclass InceptionResnetV2(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionResnetV2, self).__init__()\n        # Special attributs\n        self.input_space = None\n        self.input_size = (299, 299, 3)\n        self.mean = None\n        self.std = None\n        # Modules\n        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n        self.maxpool_5a = nn.MaxPool2d(3, stride=2)\n        self.mixed_5b = Mixed_5b()\n        self.repeat = nn.Sequential(\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17)\n        )\n        self.mixed_6a = Mixed_6a()\n        self.repeat_1 = nn.Sequential(\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10)\n        )\n        self.mixed_7a = Mixed_7a()\n        self.repeat_2 = nn.Sequential(\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20)\n        )\n        self.block8 = Block8(noReLU=True)\n        self.conv2d_7b = BasicConv2d(2080, 1536, kernel_size=1, stride=1)\n        self.avgpool_1a = nn.AvgPool2d(8, count_include_pad=False)\n        self.last_linear = nn.Linear(1536, num_classes)\n\n    def features(self, input):\n        x = self.conv2d_1a(input)\n        x = self.conv2d_2a(x)\n        x = self.conv2d_2b(x)\n        x = self.maxpool_3a(x)\n        x = self.conv2d_3b(x)\n        x = self.conv2d_4a(x)\n        x = self.maxpool_5a(x)\n        x = self.mixed_5b(x)\n        x = self.repeat(x)\n        x = self.mixed_6a(x)\n        x = self.repeat_1(x)\n        x = self.mixed_7a(x)\n        x = self.repeat_2(x)\n        x = self.block8(x)\n        x = self.conv2d_7b(x)\n        return x\n\n    def logits(self, features):\n        x = self.avgpool_1a(features)\n        x = x.view(x.size(0), -1)\n        x = self.last_linear(x) \n        return x\n\n    def forward(self, input):\n        x = self.features(input)\n        x = self.logits(x)\n        return x\n\ndef inceptionresnetv2(num_classes=1000, pretrained=\'imagenet\'):\n    r""""""InceptionResNetV2 model architecture from the\n    `""InceptionV4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n    """"""\n    if pretrained:\n        settings = pretrained_settings[\'inceptionresnetv2\'][pretrained]\n        assert num_classes == settings[\'num_classes\'], \\\n            ""num_classes should be {}, but is {}"".format(settings[\'num_classes\'], num_classes)\n\n        # both \'imagenet\'&\'imagenet+background\' are loaded from same parameters\n        model = InceptionResNetV2(num_classes=1001)\n        model.load_state_dict(model_zoo.load_url(settings[\'url\']))\n        \n        if pretrained == \'imagenet\':\n            new_last_linear = nn.Linear(1536, 1000)\n            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n            model.last_linear = new_last_linear\n        \n        model.input_space = settings[\'input_space\']\n        model.input_size = settings[\'input_size\']\n        model.input_range = settings[\'input_range\']\n        \n        model.mean = settings[\'mean\']\n        model.std = settings[\'std\']\n    else:\n        model = InceptionResNetV2(num_classes=num_classes)\n    return model\n\n\'\'\'\nTEST\nRun this code with:\n```\ncd $HOME/pretrained-models.pytorch\npython -m pretrainedmodels.inceptionresnetv2\n```\n\'\'\'\nif __name__ == \'__main__\':\n\n    assert inceptionresnetv2(num_classes=10, pretrained=None)\n    print(\'success\')\n    assert inceptionresnetv2(num_classes=1000, pretrained=\'imagenet\')\n    print(\'success\')\n    assert inceptionresnetv2(num_classes=1001, pretrained=\'imagenet+background\')\n    print(\'success\')\n\n    # fail\n    assert inceptionresnetv2(num_classes=1001, pretrained=\'imagenet\')\n'"
old/fastai/models/inceptionv4.py,29,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'https://s3.amazonaws.com/pytorch/models/inceptionv4-58153ba9.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_3a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_3a, self).__init__()\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n\n    def forward(self, x):\n        x0 = self.maxpool(x)\n        x1 = self.conv(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_4a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_4a, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(64, 96, kernel_size=(3,3), stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_5a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5a, self).__init__()\n        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.conv(x)\n        x1 = self.maxpool(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Inception_A(nn.Module):\n\n    def __init__(self):\n        super(Inception_A, self).__init__()\n        self.block0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(384, 96, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_A(nn.Module):\n\n    def __init__(self):\n        super(Reduction_A, self).__init__()\n        self.block0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(224, 256, kernel_size=3, stride=2)\n        )\n        \n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_B(nn.Module):\n\n    def __init__(self):\n        super(Inception_B, self).__init__()\n        self.block0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n        \n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_B(nn.Module):\n\n    def __init__(self):\n        super(Reduction_B, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=3, stride=2)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(320, 320, kernel_size=3, stride=2)\n        )\n\n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_C(nn.Module):\n\n    def __init__(self):\n        super(Inception_C, self).__init__()\n        self.block0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        \n        self.block1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n        self.block2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3a = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3b = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        \n        x1_0 = self.block1_0(x)\n        x1_1a = self.block1_1a(x1_0)\n        x1_1b = self.block1_1b(x1_0)\n        x1 = torch.cat((x1_1a, x1_1b), 1)\n\n        x2_0 = self.block2_0(x)\n        x2_1 = self.block2_1(x2_0)\n        x2_2 = self.block2_2(x2_1)\n        x2_3a = self.block2_3a(x2_2)\n        x2_3b = self.block2_3b(x2_2)\n        x2 = torch.cat((x2_3a, x2_3b), 1)\n\n        x3 = self.block3(x)\n\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass InceptionV4(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionV4, self).__init__()\n        self.features = nn.Sequential(\n            BasicConv2d(3, 32, kernel_size=3, stride=2),\n            BasicConv2d(32, 32, kernel_size=3, stride=1),\n            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            Mixed_3a(),\n            Mixed_4a(),\n            Mixed_5a(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Reduction_A(), # Mixed_6a\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Reduction_B(), # Mixed_7a\n            Inception_C(),\n            Inception_C(),\n            Inception_C(),\n            nn.AdaptiveAvgPool2d((1,1))\n        )\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\n\ndef inceptionv4(pretrained=True):\n    r""""""InceptionV4 model architecture from the\n    `""Inception-v4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionV4()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_4a_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.3\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_mixed_5(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_6(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch2.3\', name_tf+\'/Branch_2/Conv2d_0d_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.4\', name_tf+\'/Branch_2/Conv2d_0e_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_7(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1a\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1b\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_1\', name_tf+\'/Branch_2/Conv2d_0b_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_2\', name_tf+\'/Branch_2/Conv2d_0c_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3a\', name_tf+\'/Branch_2/Conv2d_0d_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3b\', name_tf+\'/Branch_2/Conv2d_0e_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'features.0\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.1\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.2\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'features.3.conv\', name_tf=\'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.4\', name_tf=\'Mixed_4a\')\n\n    load_conv2d(state_dict, name_pth=\'features.5.conv\', name_tf=\'Mixed_5a/Branch_0/Conv2d_1a_3x3\')\n\n    load_mixed_5(state_dict, name_pth=\'features.6\', name_tf=\'Mixed_5b\')\n    load_mixed_5(state_dict, name_pth=\'features.7\', name_tf=\'Mixed_5c\')\n    load_mixed_5(state_dict, name_pth=\'features.8\', name_tf=\'Mixed_5d\')\n    load_mixed_5(state_dict, name_pth=\'features.9\', name_tf=\'Mixed_5e\')\n\n    load_conv2d(state_dict, name_pth=\'features.10.branch0\', name_tf=\'Mixed_6a/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.0\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.1\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.2\', name_tf=\'Mixed_6a/Branch_1/Conv2d_1a_3x3\')\n\n    load_mixed_6(state_dict, name_pth=\'features.11\', name_tf=\'Mixed_6b\')\n    load_mixed_6(state_dict, name_pth=\'features.12\', name_tf=\'Mixed_6c\')\n    load_mixed_6(state_dict, name_pth=\'features.13\', name_tf=\'Mixed_6d\')\n    load_mixed_6(state_dict, name_pth=\'features.14\', name_tf=\'Mixed_6e\')\n    load_mixed_6(state_dict, name_pth=\'features.15\', name_tf=\'Mixed_6f\')\n    load_mixed_6(state_dict, name_pth=\'features.16\', name_tf=\'Mixed_6g\')\n    load_mixed_6(state_dict, name_pth=\'features.17\', name_tf=\'Mixed_6h\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.18\', name_tf=\'Mixed_7a\')\n\n    load_mixed_7(state_dict, name_pth=\'features.19\', name_tf=\'Mixed_7b\')\n    load_mixed_7(state_dict, name_pth=\'features.20\', name_tf=\'Mixed_7c\')\n    load_mixed_7(state_dict, name_pth=\'features.21\', name_tf=\'Mixed_7d\')\n\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    model.eval()\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.zeros(1,299,299,3)\n    inputs[0] = torch.from_numpy(img)\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n    # 1, 3, 299, 299\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionV4/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionV4/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_4a_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d(module.branch1[3], name+\'/Branch_1/Conv2d_1a_3x3\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionV4()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n\n    # test_conv2d(model.features[0], \'Conv2d_1a_3x3\')\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    # test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n    \n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionv4.pth\')\n    torch.save(state_dict, \'save/inceptionv4_state.pth\')\n\n    outputs = test(model)\n\n\n'"
old/fastai/models/nasnet.py,12,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\npretrained_settings = {\n    \'nasnetalarge\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1000\n        },\n        \'imagenet+background\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1001\n        }\n    }\n}\n\nclass MaxPoolPad(nn.Module):\n\n    def __init__(self):\n        super(MaxPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass AvgPoolPad(nn.Module):\n\n    def __init__(self, stride=2, padding=1):\n        super(AvgPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass SeparableConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n                                          stride=dw_stride,\n                                          padding=dw_padding,\n                                          bias=bias,\n                                          groups=in_channels)\n        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise_conv2d(x)\n        x = self.pointwise_conv2d(x)\n        return x\n\n\nclass BranchSeparables(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparables, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesStem(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparablesStem, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesReduction(BranchSeparables):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.padding(x)\n        x = self.separable_1(x)\n        x = x[:, :, 1:, 1:].contiguous()\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass CellStem0(nn.Module):\n\n    def __init__(self):\n        super(CellStem0, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(42, 42, 5, 2, 2)\n        self.comb_iter_0_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparablesStem(96, 42, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(42, 42, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x1 = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n        x_comb_iter_0_right = self.comb_iter_0_right(x)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n        x_comb_iter_1_right = self.comb_iter_1_right(x)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n        x_comb_iter_2_right = self.comb_iter_2_right(x)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass CellStem1(nn.Module):\n\n    def __init__(self):\n        super(CellStem1, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(168, 84, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(84, 84, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x_conv0, x_stem_0):\n        x_left = self.conv_1x1(x_stem_0)\n\n        x_relu = self.relu(x_conv0)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass FirstCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(FirstCell, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_relu = self.relu(x_prev)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NormalCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(NormalCell, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell0(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell0, self).__init__() \n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = MaxPoolPad()\n        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = AvgPoolPad()\n        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = MaxPoolPad()\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell1(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell1, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NASNetALarge(nn.Module):\n\n    def __init__(self, use_classifier=False, num_classes=1001):\n        super(NASNetALarge, self).__init__()\n        self.use_classifier,self.num_classes = use_classifier,num_classes\n\n        self.conv0 = nn.Sequential()\n        self.conv0.add_module(\'conv\', nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, padding=0, stride=2,\n                                                bias=False))\n        self.conv0.add_module(\'bn\', nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True))\n\n        self.cell_stem_0 = CellStem0()\n        self.cell_stem_1 = CellStem1()\n\n        self.cell_0 = FirstCell(in_channels_left=168, out_channels_left=84,\n                                in_channels_right=336, out_channels_right=168)\n        self.cell_1 = NormalCell(in_channels_left=336, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_2 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_3 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_4 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_5 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n\n        self.reduction_cell_0 = ReductionCell0(in_channels_left=1008, out_channels_left=336,\n                                               in_channels_right=1008, out_channels_right=336)\n\n        self.cell_6 = FirstCell(in_channels_left=1008, out_channels_left=168,\n                                in_channels_right=1344, out_channels_right=336)\n        self.cell_7 = NormalCell(in_channels_left=1344, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_8 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_9 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_10 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n        self.cell_11 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n\n        self.reduction_cell_1 = ReductionCell1(in_channels_left=2016, out_channels_left=672,\n                                               in_channels_right=2016, out_channels_right=672)\n\n        self.cell_12 = FirstCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2688, out_channels_right=672)\n        self.cell_13 = NormalCell(in_channels_left=2688, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_14 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_15 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_16 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_17 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout()\n        self.last_linear = nn.Linear(4032, self.num_classes)\n\n    def features(self, x):\n        x_conv0 = self.conv0(x)\n        x_stem_0 = self.cell_stem_0(x_conv0)\n        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n\n        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n        x_cell_4 = self.cell_4(x_cell_3, x_cell_2)\n        x_cell_5 = self.cell_5(x_cell_4, x_cell_3)\n\n        x_reduction_cell_0 = self.reduction_cell_0(x_cell_5, x_cell_4)\n\n        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_4)\n        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n        x_cell_10 = self.cell_10(x_cell_9, x_cell_8)\n        x_cell_11 = self.cell_11(x_cell_10, x_cell_9)\n\n        x_reduction_cell_1 = self.reduction_cell_1(x_cell_11, x_cell_10)\n\n        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_10)\n        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n        x_cell_16 = self.cell_16(x_cell_15, x_cell_14)\n        x_cell_17 = self.cell_17(x_cell_16, x_cell_15)\n        return self.relu(x_cell_17)\n\n    def classifier(self, x):\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        return F.log_softmax(self.linear(x))\n\n    def forward(self, x):\n        x = self.features(x)\n        if self.use_classifier: x = self.classifier(x)\n        return x\n\n\ndef nasnetalarge(num_classes=1000, pretrained=\'imagenet\'):\n    r""""""NASNetALarge model architecture from the\n    `""NASNet"" <https://arxiv.org/abs/1707.07012>`_ paper.\n    """"""\n    if pretrained:\n        settings = pretrained_settings[\'nasnetalarge\'][pretrained]\n        assert num_classes == settings[\'num_classes\'], \\\n            ""num_classes should be {}, but is {}"".format(settings[\'num_classes\'], num_classes)\n\n        # both \'imagenet\'&\'imagenet+background\' are loaded from same parameters\n        model = NASNetALarge(num_classes=1001)\n        model.load_state_dict(model_zoo.load_url(settings[\'url\']))\n\n        if pretrained == \'imagenet\':\n            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n            model.last_linear = new_last_linear\n\n        model.input_space = settings[\'input_space\']\n        model.input_size = settings[\'input_size\']\n        model.input_range = settings[\'input_range\']\n\n        model.mean = settings[\'mean\']\n        model.std = settings[\'std\']\n    else:\n        model = NASNetALarge(num_classes=num_classes)\n    return model\n'"
old/fastai/models/resnet.py,4,"b""import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n__all__ = ['vgg_resnet50']\n\nmodel_urls = {\n    'vgg_resnet50': 'https://download.pytorch.org/models/vggresnet.pth',\n}\n\n\ndef conv(ni, nf, ks=3, stride=1):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, stride=stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out = residual + out\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out = residual + out\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [conv(3, 64, ks=7, stride=2)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv(self.inplanes, planes*block.expansion, ks=1, stride=stride),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 (): return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50(): return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck, [3, 4, 6, 3], k=1.125)\ndef vgg_resnet34(): return ResNet(BasicBlock, [3, 4, 6, 3], vgg_head=True)\ndef vgg_resnet50(pretrained=False):\n    model = ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n    if pretrained: model.load_state_dict(torch.load('/home/jhoward/.torch/models/vgg_resnet50.pth'))\n    return model\n\n"""
old/fastai/models/resnext_101_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
old/fastai/models/resnext_101_64x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_64x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
old/fastai/models/resnext_50_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_50_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AdaptiveAvgPool2d(1),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)\n'"
old/fastai/models/senet.py,3,"b'\'\'\'\n    File name: senet.py\n    Squeeze-and-Excitation Networks (SeNet) implementation for fast.ai/pytorch with pretrained model\n    Credit https://github.com/hujie-frank/SENet\n    SENet is the winner of ImageNet-2017 (https://arxiv.org/pdf/1709.01507.pdf).\n\'\'\'\n\nfrom collections import OrderedDict\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\nimport torch.nn as nn\nfrom torch.utils import model_zoo\n\n__all__ = [\'SENet\', \'senet154\', \'se_resnet50\', \'se_resnet101\', \'se_resnet152\',\n           \'se_resnext50_32x4d\', \'se_resnext101_32x4d\']\n\npretrained_settings = {\n    \'senet154\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 224, 224],\n            \'input_range\': [0, 1],\n            \'mean\': [0.485, 0.456, 0.406],\n            \'std\': [0.229, 0.224, 0.225],\n            \'num_classes\': 1000\n        }\n    },\n    \'se_resnet50\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 224, 224],\n            \'input_range\': [0, 1],\n            \'mean\': [0.485, 0.456, 0.406],\n            \'std\': [0.229, 0.224, 0.225],\n            \'num_classes\': 1000\n        }\n    },\n    \'se_resnet101\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 224, 224],\n            \'input_range\': [0, 1],\n            \'mean\': [0.485, 0.456, 0.406],\n            \'std\': [0.229, 0.224, 0.225],\n            \'num_classes\': 1000\n        }\n    },\n    \'se_resnet152\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 224, 224],\n            \'input_range\': [0, 1],\n            \'mean\': [0.485, 0.456, 0.406],\n            \'std\': [0.229, 0.224, 0.225],\n            \'num_classes\': 1000\n        }\n    },\n    \'se_resnext50_32x4d\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 224, 224],\n            \'input_range\': [0, 1],\n            \'mean\': [0.485, 0.456, 0.406],\n            \'std\': [0.229, 0.224, 0.225],\n            \'num_classes\': 1000\n        }\n    },\n    \'se_resnext101_32x4d\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 224, 224],\n            \'input_range\': [0, 1],\n            \'mean\': [0.485, 0.456, 0.406],\n            \'std\': [0.229, 0.224, 0.225],\n            \'num_classes\': 1000\n        }\n    },\n}\n\n\nclass SEModule(nn.Module):\n\n    def __init__(self, channels, reduction):\n        super(SEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n                             padding=0)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n                             padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        module_input = x\n        x = self.avg_pool(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return module_input * x\n\n\nclass Bottleneck(nn.Module):\n    """"""\n    Base class for bottlenecks that implements `forward()` method.\n    """"""\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out = self.se_module(out) + residual\n        out = self.relu(out)\n\n        return out\n\n\nclass SEBottleneck(Bottleneck):\n    """"""\n    Bottleneck for SENet154.\n    """"""\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes * 2)\n        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n                               stride=stride, padding=1, groups=groups,\n                               bias=False)\n        self.bn2 = nn.BatchNorm2d(planes * 4)\n        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n                               bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SEResNetBottleneck(Bottleneck):\n    """"""\n    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n    (the latter is used in the torchvision implementation of ResNet).\n    """"""\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEResNetBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n                               stride=stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n                               groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SEResNeXtBottleneck(Bottleneck):\n    """"""\n    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n    """"""\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None, base_width=4):\n        super(SEResNeXtBottleneck, self).__init__()\n        width = math.floor(planes * (base_width / 64)) * groups\n        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n                               stride=1)\n        self.bn1 = nn.BatchNorm2d(width)\n        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n                               padding=1, groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(width)\n        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SENet(nn.Module):\n\n    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n                 downsample_padding=1, num_classes=1000):\n        """"""\n        Parameters\n        ----------\n        block (nn.Module): Bottleneck class.\n            - For SENet154: SEBottleneck\n            - For SE-ResNet models: SEResNetBottleneck\n            - For SE-ResNeXt models:  SEResNeXtBottleneck\n        layers (list of ints): Number of residual blocks for 4 layers of the\n            network (layer1...layer4).\n        groups (int): Number of groups for the 3x3 convolution in each\n            bottleneck block.\n            - For SENet154: 64\n            - For SE-ResNet models: 1\n            - For SE-ResNeXt models:  32\n        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n            - For all models: 16\n        dropout_p (float or None): Drop probability for the Dropout layer.\n            If `None` the Dropout layer is not used.\n            - For SENet154: 0.2\n            - For SE-ResNet models: None\n            - For SE-ResNeXt models: None\n        inplanes (int):  Number of input channels for layer1.\n            - For SENet154: 128\n            - For SE-ResNet models: 64\n            - For SE-ResNeXt models: 64\n        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n            a single 7x7 convolution in layer0.\n            - For SENet154: True\n            - For SE-ResNet models: False\n            - For SE-ResNeXt models: False\n        downsample_kernel_size (int): Kernel size for downsampling convolutions\n            in layer2, layer3 and layer4.\n            - For SENet154: 3\n            - For SE-ResNet models: 1\n            - For SE-ResNeXt models: 1\n        downsample_padding (int): Padding for downsampling convolutions in\n            layer2, layer3 and layer4.\n            - For SENet154: 1\n            - For SE-ResNet models: 0\n            - For SE-ResNeXt models: 0\n        num_classes (int): Number of outputs in `last_linear` layer.\n            - For all models: 1000\n        """"""\n        super(SENet, self).__init__()\n        self.inplanes = inplanes\n        if input_3x3:\n            layer0_modules = [\n                (\'conv1\', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n                                    bias=False)),\n                (\'bn1\', nn.BatchNorm2d(64)),\n                (\'relu1\', nn.ReLU(inplace=True)),\n                (\'conv2\', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n                                    bias=False)),\n                (\'bn2\', nn.BatchNorm2d(64)),\n                (\'relu2\', nn.ReLU(inplace=True)),\n                (\'conv3\', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n                                    bias=False)),\n                (\'bn3\', nn.BatchNorm2d(inplanes)),\n                (\'relu3\', nn.ReLU(inplace=True)),\n            ]\n        else:\n            layer0_modules = [\n                (\'conv1\', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n                                    padding=3, bias=False)),\n                (\'bn1\', nn.BatchNorm2d(inplanes)),\n                (\'relu1\', nn.ReLU(inplace=True)),\n            ]\n        # To preserve compatibility with Caffe weights `ceil_mode=True`\n        # is used instead of `padding=1`.\n        layer0_modules.append((\'pool\', nn.MaxPool2d(3, stride=2,\n                                                    ceil_mode=True)))\n        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n        self.layer1 = self._make_layer(\n            block,\n            planes=64,\n            blocks=layers[0],\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=1,\n            downsample_padding=0\n        )\n        self.layer2 = self._make_layer(\n            block,\n            planes=128,\n            blocks=layers[1],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.layer3 = self._make_layer(\n            block,\n            planes=256,\n            blocks=layers[2],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.layer4 = self._make_layer(\n            block,\n            planes=512,\n            blocks=layers[3],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.avg_pool = nn.AvgPool2d(7, stride=1)\n        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n                    downsample_kernel_size=1, downsample_padding=0):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=downsample_kernel_size, stride=stride,\n                          padding=downsample_padding, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n                            downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups, reduction))\n\n        return nn.Sequential(*layers)\n\n    def features(self, x):\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\n    def logits(self, x):\n        x = self.avg_pool(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.last_linear(x)\n        return x\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.logits(x)\n        return x\n\n\ndef initialize_pretrained_model(model, num_classes, settings):\n    assert num_classes == settings[\'num_classes\'], \\\n        \'num_classes should be {}, but is {}\'.format(\n            settings[\'num_classes\'], num_classes)\n    model.load_state_dict(model_zoo.load_url(settings[\'url\']))\n    model.input_space = settings[\'input_space\']\n    model.input_size = settings[\'input_size\']\n    model.input_range = settings[\'input_range\']\n    model.mean = settings[\'mean\']\n    model.std = settings[\'std\']\n\n\ndef senet154(num_classes=1000, pretrained=\'imagenet\'):\n    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n                  dropout_p=0.2, num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings[\'senet154\'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\n\ndef se_resnet50(num_classes=1000, pretrained=\'imagenet\'):\n    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings[\'se_resnet50\'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\n\ndef se_resnet101(num_classes=1000, pretrained=\'imagenet\'):\n    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings[\'se_resnet101\'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\n\ndef se_resnet152(num_classes=1000, pretrained=\'imagenet\'):\n    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings[\'se_resnet152\'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\n\ndef se_resnext50_32x4d(num_classes=1000, pretrained=\'imagenet\'):\n    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings[\'se_resnext50_32x4d\'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\n\ndef se_resnext101_32x4d(num_classes=1000, pretrained=\'imagenet\'):\n    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings[\'se_resnext101_32x4d\'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n'"
old/fastai/models/unet.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\n\ndef get_sfs_idxs(sfs, last=True):\n    """"""\n    Return the saved feature indexes that will be concatenated\n    Inputs:\n        sfs (list): saved features by hook function, in other words intermediate activations\n        last (bool): whether to concatenate only last different activation, or all from the encoder model\n    """"""\n    if last:\n        feature_szs = [sfs_feats.features.size()[-1] for sfs_feats in sfs]\n        sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n        if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n    else: sfs_idxs = list(range(len(sfs)))\n    return sfs_idxs\n\n\ndef conv_bn_relu(in_c, out_c, kernel_size, stride, padding):\n    return [\n        nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=stride, padding=padding),\n        nn.ReLU(),\n        nn.BatchNorm2d(out_c)]\n\n\nclass UnetBlock(nn.Module):\n    #TODO: ADAPT KERNEL SIZE, STRIDE AND PADDING SO THAT ANY SIZE DECAY WILL BE SUPPORTED\n    def __init__(self, up_in_c, x_in_c):\n        super().__init__()\n        self.upconv = nn.ConvTranspose2d(up_in_c, up_in_c // 2, 2, 2) # H, W -> 2H, 2W\n        self.conv1 = nn.Conv2d(x_in_c + up_in_c // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.conv2 = nn.Conv2d((x_in_c + up_in_c // 2) // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.bn = nn.BatchNorm2d((x_in_c + up_in_c // 2) // 2)\n\n    def forward(self, up_in, x_in):\n        up_out = self.upconv(up_in)\n        cat_x = torch.cat([up_out, x_in], dim=1)\n        x = F.relu(self.conv1(cat_x))\n        x = F.relu(self.conv2(x))\n        return self.bn(x)\n\nclass SaveFeatures():\n    """""" Extract pretrained activations""""""\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()\n\n\nclass DynamicUnet(nn.Module):\n    """"""\n    A dynamic implementation of Unet architecture, because calculating connections\n    and channels suck!. When an encoder is passed, this network will\n    automatically construct a decoder after the first single forward pass for any\n    given encoder architecture.\n\n    Decoder part is heavily based on the original Unet paper:\n    https://arxiv.org/abs/1505.04597.\n\n    Inputs:\n        encoder(nn.Module): Preferably a pretrained model, such as VGG or ResNet\n        last (bool): Whether to concat only last activation just before a size change\n        n_classes (int): Number of classes to output in final step of decoder\n\n    Important Note: If architecture directly reduces the dimension of an image as soon as the\n    first forward pass then output size will not be same as the input size, e.g. ResNet.\n    In order to resolve this problem architecture will add an additional extra conv transpose\n    layer. Also, currently Dynamic Unet expects size change to be H,W -> H/2, W/2. This is\n    not a problem for state-of-the-art architectures as they follow this pattern but it should\n    be changed for custom encoders that might have a different size decay.\n    """"""\n\n    def __init__(self, encoder, last=True, n_classes=3):\n        super().__init__()\n        self.encoder = encoder\n        self.n_children = len(list(encoder.children()))\n        self.sfs = [SaveFeatures(encoder[i]) for i in range(self.n_children)]\n        self.last = last\n        self.n_classes = n_classes\n\n    def forward(self, x):\n        dtype = x.data.type()\n\n        # get imsize\n        imsize = x.size()[-2:]\n\n        # encoder output\n        x = F.relu(self.encoder(x))\n\n        # initialize sfs_idxs, sfs_szs, middle_in_c and middle_conv only once\n        if not hasattr(self, \'middle_conv\'):\n            self.sfs_szs = [sfs_feats.features.size() for sfs_feats in self.sfs]\n            self.sfs_idxs = get_sfs_idxs(self.sfs, self.last)\n            middle_in_c = self.sfs_szs[-1][1]\n            middle_conv = nn.Sequential(*conv_bn_relu(middle_in_c, middle_in_c * 2, 3, 1, 1),\n                                        *conv_bn_relu(middle_in_c * 2, middle_in_c, 3, 1, 1))\n            self.middle_conv = middle_conv.type(dtype)\n\n        # middle conv\n        x = self.middle_conv(x)\n\n        # initialize upmodel, extra_block and 1x1 final conv\n        if not hasattr(self, \'upmodel\'):\n            x_copy = Variable(x.data, requires_grad=False)\n            upmodel = []\n            for idx in self.sfs_idxs[::-1]:\n                up_in_c, x_in_c = int(x_copy.size()[1]), int(self.sfs_szs[idx][1])\n                unet_block = UnetBlock(up_in_c, x_in_c).type(dtype)\n                upmodel.append(unet_block)\n                x_copy = unet_block(x_copy, self.sfs[idx].features)\n                self.upmodel = nn.Sequential(*upmodel)\n\n            if imsize != self.sfs_szs[0][-2:]:\n                extra_in_c = self.upmodel[-1].conv2.out_channels\n                self.extra_block = nn.ConvTranspose2d(extra_in_c, extra_in_c, 2, 2).type(dtype)\n\n            final_in_c = self.upmodel[-1].conv2.out_channels\n            self.final_conv = nn.Conv2d(final_in_c, self.n_classes, 1).type(dtype)\n\n        # run upsample\n        for block, idx in zip(self.upmodel, self.sfs_idxs[::-1]):\n            x = block(x, self.sfs[idx].features)\n        if hasattr(self, \'extra_block\'):\n            x = self.extra_block(x)\n\n        out = self.final_conv(x)\n        return out\n'"
old/fastai/models/wideresnet.py,3,"b'# https://github.com/uoguelph-mlrg/Cutout\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super().__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut: x   = self.relu1(self.bn1(x))\n        else:                   out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super().__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x): return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super().__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert((depth - 4) % 6 == 0)\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear): m.bias.data.zero_()\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.adaptive_avg_pool2d(out, 1)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n'"
old/fastai/models/wrn_50_2f.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef wrn_50_2f(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
old/fastai/torchqrnn/forget_mult.py,10,"b'import math\nimport torch\nfrom torch.autograd import Variable\nfrom cupy.cuda import function\nfrom cupy.cuda.compiler import _NVRTCProgram\nfrom collections import namedtuple\n\n##Adapted from the code here https://github.com/salesforce/pytorch-qrnn, implementation of the QRNN by\n##Bradbury, James and Merity, Stephen and Xiong, Caiming and Socher, Richard \n##https://arxiv.org/abs/1611.01576\n\nkernel = \'\'\'\nextern ""C""\n__global__ void recurrent_forget_mult(float *dst, const float *f, const float *x, int SEQ, int BATCH, int HIDDEN)\n{\n  /*\n  Note: destination is assumed to be one timestep longer than f or x where dst[0] = h_{-1}\n  This means dst array has a separate index than that of f or x\n  */\n  int hid = blockIdx.x * blockDim.x + threadIdx.x;\n  int bid = blockIdx.y * blockDim.y + threadIdx.y;\n  if(hid >= HIDDEN || bid >= BATCH)\n     return;\n  //\n  for (int ts = 0 + 1; ts < SEQ + 1; ts++) {\n     // Good sanity check for debugging - only perform additions to a zeroed chunk of memory\n     // Addition seems atomic or near atomic - you should get incorrect answers if doubling up via threads\n     // Note: the index i needs to be offset by one as f[0] (f_t) is used for dst[1] (h_t) etc\n\n     // To move timesteps, we step HIDDEN * BATCH\n     // To move batches, we move HIDDEN\n     // To move neurons, we move +- 1\n     // Note: dst[dst_i] = ts * 100 + bid * 10 + hid; is useful for debugging\n\n     int i           = (ts - 1) * HIDDEN * BATCH + bid * HIDDEN + hid;\n     int dst_i       = (ts - 0) * HIDDEN * BATCH + bid * HIDDEN + hid;\n     int dst_iminus1 = (ts - 1) * HIDDEN * BATCH + bid * HIDDEN + hid;\n     dst[dst_i]      = f[i] * x[i];\n     dst[dst_i]      += (1 - f[i]) * dst[dst_iminus1];\n  }\n}\n\nextern ""C""\n__global__ void bwd_recurrent_forget_mult(const float *h, const float *f, const float *x, const float *gh, float *gf, float *gx, float *ghinit, int SEQ, int BATCH, int HIDDEN)\n{\n  /*\n  Note: h is assumed to be one timestep longer than f, x, gf, gx, or gh where dst[0] = h_{-1}\n  This means dst array has a separate index than that of f or x\n  */\n  int hid = blockIdx.x * blockDim.x + threadIdx.x;\n  int bid = blockIdx.y * blockDim.y + threadIdx.y;\n  if(hid >= HIDDEN || bid >= BATCH)\n     return;\n  //\n  double running_f = 0;\n  for (int ts = SEQ - 1 + 1; ts >= 0 + 1; ts--) {\n     int i           = (ts - 1) * HIDDEN * BATCH + bid * HIDDEN + hid;\n     int dst_i       = (ts - 0) * HIDDEN * BATCH + bid * HIDDEN + hid;\n     int dst_iminus1 = (ts - 1) * HIDDEN * BATCH + bid * HIDDEN + hid;\n     //\n     running_f       += gh[dst_iminus1];\n     // Gradient of X\n     gx[i]           = f[i] * running_f;\n     // Gradient of F\n     gf[i]           = (x[i] - h[dst_iminus1]) * running_f;\n     //\n     // The line below is likely more numerically stable than (1 - f[i]) * running_f;\n     running_f       = running_f - f[i] * running_f;\n  }\n  ghinit[bid * HIDDEN + hid] = running_f;\n}\n\'\'\'\n\n###\n\nclass CPUForgetMult(torch.nn.Module):\n    def __init__(self):\n        super(CPUForgetMult, self).__init__()\n\n    def forward(self, f, x, hidden_init=None):\n        result = []\n        ###\n        forgets = f.split(1, dim=0)\n        prev_h = hidden_init\n        for i, h in enumerate((f * x).split(1, dim=0)):\n            if prev_h is not None: h = h + (1 - forgets[i]) * prev_h\n            # h is (1, batch, hidden) when it needs to be (batch_hidden)\n            # Calling squeeze will result in badness if batch size is 1\n            h = h.view(h.size()[1:])\n            result.append(h)\n            prev_h = h\n        ###\n        return torch.stack(result)\n\n\nclass GPUForgetMult(torch.autograd.Function):\n    configured_gpus = {}\n    ptx = None\n    def __init__(self):\n        super(GPUForgetMult, self).__init__()\n\n    def compile(self):\n        if self.ptx is None:\n            \n            program = _NVRTCProgram(kernel.encode(), \'recurrent_forget_mult.cu\'.encode())\n            GPUForgetMult.ptx = program.compile()\n\n        if torch.cuda.current_device() not in GPUForgetMult.configured_gpus:\n            m = function.Module()\n            m.load(bytes(self.ptx.encode()))\n\n            self.forget_mult = m.get_function(\'recurrent_forget_mult\')\n            self.bwd_forget_mult = m.get_function(\'bwd_recurrent_forget_mult\')\n\n            Stream = namedtuple(\'Stream\', [\'ptr\'])\n            self.stream = Stream(ptr=torch.cuda.current_stream().cuda_stream)\n\n            GPUForgetMult.configured_gpus[torch.cuda.current_device()] = (self.forget_mult, self.bwd_forget_mult, self.stream)\n\n        self.forget_mult, self.bwd_forget_mult, self.stream = GPUForgetMult.configured_gpus[torch.cuda.current_device()]\n\n    def forward(self, f, x, hidden_init=None):\n        self.compile()\n        seq_size, batch_size, hidden_size = f.size()\n        result = f.new(seq_size + 1, batch_size, hidden_size)\n        # We only zero the result array (result[0]) if we don\'t set a hidden initial state\n        # All other values (result[1:]) are overwritten by default\n        if hidden_init is not None: result[0, :, :] = hidden_init\n        else: result = result.zero_()\n        ###\n        grid_hidden_size = min(hidden_size, 512)\n        grid = (math.ceil(hidden_size / grid_hidden_size), batch_size)\n        self.forget_mult(grid=grid, block=(grid_hidden_size, 1), args=[result.data_ptr(), f.data_ptr(), x.data_ptr(), seq_size, batch_size, hidden_size], stream=self.stream)\n        self.save_for_backward(f, x, hidden_init)\n        self.result = result\n        return result[1:, :, :]\n\n    def backward(self, grad_h):\n        self.compile()\n        f, x, hidden_init = self.saved_tensors\n        h = self.result\n        ###\n        seq_size, batch_size, hidden_size = f.size()\n        # Zeroing is not necessary as these will be overwritten\n        grad_f = f.new(*f.size())\n        grad_x = f.new(*f.size())\n        grad_h_init = f.new(batch_size, hidden_size)\n        ###\n        grid_hidden_size = min(hidden_size, 512)\n        grid = (math.ceil(hidden_size / grid_hidden_size), batch_size)\n        self.bwd_forget_mult(grid=grid, block=(grid_hidden_size, 1), args=[h.data_ptr(), f.data_ptr(), x.data_ptr(), grad_h.data_ptr(), grad_f.data_ptr(), grad_x.data_ptr(), grad_h_init.data_ptr(), seq_size, batch_size, hidden_size], stream=self.stream)\n        ###\n        if hidden_init is not None:\n            return grad_f, grad_x, grad_h_init\n        return grad_f, grad_x\n\n\nclass ForgetMult(torch.nn.Module):\n    r""""""ForgetMult computes a simple recurrent equation:\n    h_t = f_t * x_t + (1 - f_t) * h_{t-1}\n\n    This equation is equivalent to dynamic weighted averaging.\n\n    Inputs: X, hidden\n        - X (seq_len, batch, input_size): tensor containing the features of the input sequence.\n        - F (seq_len, batch, input_size): tensor containing the forget gate values, assumed in range [0, 1].\n        - hidden_init (batch, input_size): tensor containing the initial hidden state for the recurrence (h_{t-1}).\n        - use_cuda: If True, use the fast element-wise CUDA kernel for recurrence. If False, uses naive for loop. Default: True.\n    """"""\n\n    def __init__(self):\n        super(ForgetMult, self).__init__()\n\n    def forward(self, f, x, hidden_init=None, use_cuda=True):\n        # Use CUDA by default unless it\'s available\n        use_cuda = use_cuda and torch.cuda.is_available()\n        # Ensure the user is aware when ForgetMult is not GPU version as it\'s far faster\n        if use_cuda: assert f.is_cuda and x.is_cuda, \'GPU ForgetMult with fast element-wise CUDA kernel requested but tensors not on GPU\'\n        ###\n        # Avoiding \'RuntimeError: expected a Variable argument, but got NoneType\' when hidden_init is None\n        if hidden_init is None: return GPUForgetMult()(f, x) if use_cuda else CPUForgetMult()(f, x)\n        return GPUForgetMult()(f, x, hidden_init) if use_cuda else CPUForgetMult()(f, x, hidden_init)\n'"
old/fastai/torchqrnn/qrnn.py,10,"b'import torch\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom .forget_mult import ForgetMult\n\n\n##Adapted from the code here https://github.com/salesforce/pytorch-qrnn, implementation of the QRNN by\n##Bradbury, James and Merity, Stephen and Xiong, Caiming and Socher, Richard \n##https://arxiv.org/abs/1611.01576\n\nclass QRNNLayer(nn.Module):\n    r""""""Applies a single layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\n\n    Args:\n        input_size: The number of expected features in the input x.\n        hidden_size: The number of features in the hidden state h. If not specified, the input size is used.\n        save_prev_x: Whether to store previous inputs for use in future convolutional windows (i.e. for a continuing sequence such as in language modeling). If true, you must call reset to remove cached previous values of x. Default: False.\n        window: Defines the size of the convolutional window (how many previous tokens to look when computing the QRNN values). Supports 1 and 2. Default: 1.\n        zoneout: Whether to apply zoneout (i.e. failing to update elements in the hidden state) to the hidden state updates. Default: 0.\n        output_gate: If True, performs QRNN-fo (applying an output gate to the output). If False, performs QRNN-f. Default: True.\n        use_cuda: If True, uses fast custom CUDA kernel. If False, uses naive for loop. Default: True.\n\n    Inputs: X, hidden\n        - X (seq_len, batch, input_size): tensor containing the features of the input sequence.\n        - hidden (batch, hidden_size): tensor containing the initial hidden state for the QRNN.\n\n    Outputs: output, h_n\n        - output (seq_len, batch, hidden_size): tensor containing the output of the QRNN for each timestep.\n        - h_n (batch, hidden_size): tensor containing the hidden state for t=seq_len\n    """"""\n\n    def __init__(self, input_size, hidden_size=None, save_prev_x=False, zoneout=0, window=1, output_gate=True, use_cuda=True):\n        super(QRNNLayer, self).__init__()\n\n        assert window in [1, 2], ""This QRNN implementation currently only handles convolutional window of size 1 or size 2""\n        self.window = window\n        self.input_size = input_size\n        self.hidden_size = hidden_size if hidden_size else input_size\n        self.zoneout = zoneout\n        self.save_prev_x = save_prev_x\n        self.prevX = None\n        self.output_gate = output_gate\n        self.use_cuda = use_cuda\n\n        # One large matmul with concat is faster than N small matmuls and no concat\n        self.linear = nn.Linear(self.window * self.input_size, 3 * self.hidden_size if self.output_gate else 2 * self.hidden_size)\n\n    def reset(self):\n        # If you are saving the previous value of x, you should call this when starting with a new state\n        self.prevX = None\n\n    def forward(self, X, hidden=None):\n        seq_len, batch_size, _ = X.size()\n\n        source = None\n        if self.window == 1:\n            source = X\n        elif self.window == 2:\n            # Construct the x_{t-1} tensor with optional x_{-1}, otherwise a zeroed out value for x_{-1}\n            Xm1 = []\n            Xm1.append(self.prevX if self.prevX is not None else X[:1, :, :] * 0)\n            # Note: in case of len(X) == 1, X[:-1, :, :] results in slicing of empty tensor == bad\n            if len(X) > 1:\n                Xm1.append(X[:-1, :, :])\n            Xm1 = torch.cat(Xm1, 0)\n            # Convert two (seq_len, batch_size, hidden) tensors to (seq_len, batch_size, 2 * hidden)\n            source = torch.cat([X, Xm1], 2)\n\n        # Matrix multiplication for the three outputs: Z, F, O\n        Y = self.linear(source)\n        # Convert the tensor back to (batch, seq_len, len([Z, F, O]) * hidden_size)\n        if self.output_gate:\n            Y = Y.view(seq_len, batch_size, 3 * self.hidden_size)\n            Z, F, O = Y.chunk(3, dim=2)\n        else:\n            Y = Y.view(seq_len, batch_size, 2 * self.hidden_size)\n            Z, F = Y.chunk(2, dim=2)\n        ###\n        Z = torch.nn.functional.tanh(Z)\n        F = torch.nn.functional.sigmoid(F)\n\n        # If zoneout is specified, we perform dropout on the forget gates in F\n        # If an element of F is zero, that means the corresponding neuron keeps the old value\n        if self.zoneout:\n            if self.training:\n                mask = Variable(F.data.new(*F.size()).bernoulli_(1 - self.zoneout), requires_grad=False)\n                F = F * mask\n            else:\n                F *= 1 - self.zoneout\n\n        # Ensure the memory is laid out as expected for the CUDA kernel\n        # This is a null op if the tensor is already contiguous\n        Z = Z.contiguous()\n        F = F.contiguous()\n        # The O gate doesn\'t need to be contiguous as it isn\'t used in the CUDA kernel\n\n        # Forget Mult\n        # For testing QRNN without ForgetMult CUDA kernel, C = Z * F may be useful\n        C = ForgetMult()(F, Z, hidden, use_cuda=self.use_cuda)\n\n        # Apply (potentially optional) output gate\n        if self.output_gate:\n            H = torch.nn.functional.sigmoid(O) * C\n        else:\n            H = C\n\n        # In an optimal world we may want to backprop to x_{t-1} but ...\n        if self.window > 1 and self.save_prev_x:\n            self.prevX = Variable(X[-1:, :, :].data, requires_grad=False)\n\n        return H, C[-1:, :, :]\n\n\nclass QRNN(torch.nn.Module):\n    r""""""Applies a multiple layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\n\n    Args:\n        input_size: The number of expected features in the input x.\n        hidden_size: The number of features in the hidden state h. If not specified, the input size is used.\n        num_layers: The number of QRNN layers to produce.\n        layers: List of preconstructed QRNN layers to use for the QRNN module (optional).\n        save_prev_x: Whether to store previous inputs for use in future convolutional windows (i.e. for a continuing sequence such as in language modeling). If true, you must call reset to remove cached previous values of x. Default: False.\n        window: Defines the size of the convolutional window (how many previous tokens to look when computing the QRNN values). Supports 1 and 2. Default: 1.\n        zoneout: Whether to apply zoneout (i.e. failing to update elements in the hidden state) to the hidden state updates. Default: 0.\n        output_gate: If True, performs QRNN-fo (applying an output gate to the output). If False, performs QRNN-f. Default: True.\n        use_cuda: If True, uses fast custom CUDA kernel. If False, uses naive for loop. Default: True.\n\n    Inputs: X, hidden\n        - X (seq_len, batch, input_size): tensor containing the features of the input sequence.\n        - hidden (layers, batch, hidden_size): tensor containing the initial hidden state for the QRNN.\n\n    Outputs: output, h_n\n        - output (seq_len, batch, hidden_size): tensor containing the output of the QRNN for each timestep.\n        - h_n (layers, batch, hidden_size): tensor containing the hidden state for t=seq_len\n    """"""\n\n    def __init__(self, input_size, hidden_size,\n                 num_layers=1, bias=True, batch_first=False,\n                 dropout=0, bidirectional=False, layers=None, **kwargs):\n        assert bidirectional == False, \'Bidirectional QRNN is not yet supported\'\n        assert batch_first == False, \'Batch first mode is not yet supported\'\n        assert bias == True, \'Removing underlying bias is not yet supported\'\n\n        super(QRNN, self).__init__()\n\n        self.layers = torch.nn.ModuleList(layers if layers else [QRNNLayer(input_size if l == 0 else hidden_size, hidden_size, **kwargs) for l in range(num_layers)])\n\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = len(layers) if layers else num_layers\n        self.bias = bias\n        self.batch_first = batch_first\n        self.dropout = dropout\n        self.bidirectional = bidirectional\n\n    def reset(self):\n        r\'\'\'If your convolutional window is greater than 1, you must reset at the beginning of each new sequence\'\'\'\n        [layer.reset() for layer in self.layers]\n\n    def forward(self, input, hidden=None):\n        next_hidden = []\n\n        for i, layer in enumerate(self.layers):\n            input, hn = layer(input, None if hidden is None else hidden[i])\n            next_hidden.append(hn)\n\n            if self.dropout != 0 and i < len(self.layers) - 1:\n                input = torch.nn.functional.dropout(input, p=self.dropout, training=self.training, inplace=False)\n\n        next_hidden = torch.cat(next_hidden, 0).view(self.num_layers, *next_hidden[0].size()[-2:])\n\n        return input, next_hidden\n'"
courses/dl2/cgan/data/__init__.py,0,b''
courses/dl2/cgan/data/aligned_dataset.py,1,"b""import os.path\nimport random\nimport torchvision.transforms as transforms\nimport torch\nfrom .base_dataset import BaseDataset\nfrom .image_folder import make_dataset\nfrom PIL import Image\n\n\nclass AlignedDataset(BaseDataset):\n    def initialize(self, opt):\n        self.opt = opt\n        self.root = opt.dataroot\n        self.dir_AB = os.path.join(opt.dataroot, opt.phase)\n        self.AB_paths = sorted(make_dataset(self.dir_AB))\n        assert(opt.resize_or_crop == 'resize_and_crop')\n\n    def __getitem__(self, index):\n        AB_path = self.AB_paths[index]\n        AB = Image.open(AB_path).convert('RGB')\n        w, h = AB.size\n        w2 = int(w / 2)\n        A = AB.crop((0, 0, w2, h)).resize((self.opt.loadSize, self.opt.loadSize), Image.BICUBIC)\n        B = AB.crop((w2, 0, w, h)).resize((self.opt.loadSize, self.opt.loadSize), Image.BICUBIC)\n        A = transforms.ToTensor()(A)\n        B = transforms.ToTensor()(B)\n        w_offset = random.randint(0, max(0, self.opt.loadSize - self.opt.fineSize - 1))\n        h_offset = random.randint(0, max(0, self.opt.loadSize - self.opt.fineSize - 1))\n\n        A = A[:, h_offset:h_offset + self.opt.fineSize, w_offset:w_offset + self.opt.fineSize]\n        B = B[:, h_offset:h_offset + self.opt.fineSize, w_offset:w_offset + self.opt.fineSize]\n\n        A = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(A)\n        B = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(B)\n\n        if self.opt.which_direction == 'BtoA':\n            input_nc = self.opt.output_nc\n            output_nc = self.opt.input_nc\n        else:\n            input_nc = self.opt.input_nc\n            output_nc = self.opt.output_nc\n\n        if (not self.opt.no_flip) and random.random() < 0.5:\n            idx = [i for i in range(A.size(2) - 1, -1, -1)]\n            idx = torch.LongTensor(idx)\n            A = A.index_select(2, idx)\n            B = B.index_select(2, idx)\n\n        if input_nc == 1:  # RGB to gray\n            tmp = A[0, ...] * 0.299 + A[1, ...] * 0.587 + A[2, ...] * 0.114\n            A = tmp.unsqueeze(0)\n\n        if output_nc == 1:  # RGB to gray\n            tmp = B[0, ...] * 0.299 + B[1, ...] * 0.587 + B[2, ...] * 0.114\n            B = tmp.unsqueeze(0)\n\n        return {'A': A, 'B': B,\n                'A_paths': AB_path, 'B_paths': AB_path}\n\n    def __len__(self):\n        return len(self.AB_paths)\n\n    def name(self):\n        return 'AlignedDataset'\n"""
courses/dl2/cgan/data/base_data_loader.py,0,"b'class BaseDataLoader():\n    def __init__(self): pass\n    def load_data(): return None\n    def initialize(self, opt): self.opt = opt\n\n'"
courses/dl2/cgan/data/base_dataset.py,1,"b""import torch.utils.data as data\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n\nclass BaseDataset(data.Dataset):\n    def __init__(self):\n        super(BaseDataset, self).__init__()\n\n    def name(self):\n        return 'BaseDataset'\n\n    def initialize(self, opt):\n        pass\n\n\ndef get_transform(opt):\n    transform_list = []\n    if opt.resize_or_crop == 'resize_and_crop':\n        osize = [opt.loadSize, opt.loadSize]\n        transform_list.append(transforms.Scale(osize, Image.BICUBIC))\n        transform_list.append(transforms.RandomCrop(opt.fineSize))\n    elif opt.resize_or_crop == 'crop':\n        transform_list.append(transforms.RandomCrop(opt.fineSize))\n    elif opt.resize_or_crop == 'scale_width':\n        transform_list.append(transforms.Lambda(\n            lambda img: __scale_width(img, opt.fineSize)))\n    elif opt.resize_or_crop == 'scale_width_and_crop':\n        transform_list.append(transforms.Lambda(\n            lambda img: __scale_width(img, opt.loadSize)))\n        transform_list.append(transforms.RandomCrop(opt.fineSize))\n\n    if opt.isTrain and not opt.no_flip:\n        transform_list.append(transforms.RandomHorizontalFlip())\n\n    transform_list += [transforms.ToTensor(),\n                       transforms.Normalize((0.5, 0.5, 0.5),\n                                            (0.5, 0.5, 0.5))]\n    return transforms.Compose(transform_list)\n\n\ndef __scale_width(img, target_width):\n    ow, oh = img.size\n    if (ow == target_width):\n        return img\n    w = target_width\n    h = int(target_width * oh / ow)\n    return img.resize((w, h), Image.BICUBIC)\n"""
courses/dl2/cgan/data/custom_dataset_data_loader.py,2,"b'import torch.utils.data\nfrom .base_data_loader import BaseDataLoader\n\n\ndef CreateDataset(opt):\n    dataset = None\n    if opt.dataset_mode == \'aligned\':\n        from .aligned_dataset import AlignedDataset\n        dataset = AlignedDataset()\n    elif opt.dataset_mode == \'unaligned\':\n        from .unaligned_dataset import UnalignedDataset\n        dataset = UnalignedDataset()\n    elif opt.dataset_mode == \'single\':\n        from .single_dataset import SingleDataset\n        dataset = SingleDataset()\n    else:\n        raise ValueError(""Dataset [%s] not recognized."" % opt.dataset_mode)\n\n    print(""dataset [%s] was created"" % (dataset.name()))\n    dataset.initialize(opt)\n    return dataset\n\n\nclass CustomDatasetDataLoader(BaseDataLoader):\n    def initialize(self, opt):\n        BaseDataLoader.initialize(self, opt)\n        self.dataset = CreateDataset(opt)\n        self.dataloader = torch.utils.data.DataLoader(\n            self.dataset, batch_size=opt.batchSize,\n            shuffle=not opt.serial_batches, num_workers=int(opt.nThreads))\n\n    def __iter__(self):\n        for i, data in enumerate(self.dataloader):\n            if i >= self.opt.max_dataset_size: break\n            yield data\n\n    def name(self): return \'CustomDatasetDataLoader\'\n    def load_data(self): return self\n    def __len__(self): return min(len(self.dataset), self.opt.max_dataset_size)\n\n'"
courses/dl2/cgan/data/data_loader.py,0,b'from ..data.custom_dataset_data_loader import CustomDatasetDataLoader\n\ndef CreateDataLoader(opt):\n    data_loader = CustomDatasetDataLoader()\n    print(data_loader.name())\n    data_loader.initialize(opt)\n    return data_loader\n'
courses/dl2/cgan/data/image_folder.py,1,"b'###############################################################################\n# Code from\n# https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py\n# Modified the original code so that it also loads images from the current\n# directory as well as the subdirectories\n###############################################################################\n\nimport torch.utils.data as data\n\nfrom PIL import Image\nimport os\nimport os.path\n\nIMG_EXTENSIONS = [\n    \'.jpg\', \'.JPG\', \'.jpeg\', \'.JPEG\',\n    \'.png\', \'.PNG\', \'.ppm\', \'.PPM\', \'.bmp\', \'.BMP\',\n]\n\n\ndef is_image_file(filename):\n    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n\n\ndef make_dataset(dir):\n    images = []\n    assert os.path.isdir(dir), \'%s is not a valid directory\' % dir\n\n    for root, _, fnames in sorted(os.walk(dir)):\n        for fname in fnames:\n            if is_image_file(fname):\n                path = os.path.join(root, fname)\n                images.append(path)\n\n    return images\n\n\ndef default_loader(path):\n    return Image.open(path).convert(\'RGB\')\n\n\nclass ImageFolder(data.Dataset):\n\n    def __init__(self, root, transform=None, return_paths=False,\n                 loader=default_loader):\n        imgs = make_dataset(root)\n        if len(imgs) == 0:\n            raise(RuntimeError(""Found 0 images in: "" + root + ""\\n""\n                               ""Supported image extensions are: "" +\n                               "","".join(IMG_EXTENSIONS)))\n\n        self.root = root\n        self.imgs = imgs\n        self.transform = transform\n        self.return_paths = return_paths\n        self.loader = loader\n\n    def __getitem__(self, index):\n        path = self.imgs[index]\n        img = self.loader(path)\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.return_paths:\n            return img, path\n        else:\n            return img\n\n    def __len__(self):\n        return len(self.imgs)\n'"
courses/dl2/cgan/data/single_dataset.py,0,"b""import os.path\nfrom .base_dataset import BaseDataset, get_transform\nfrom .image_folder import make_dataset\nfrom PIL import Image\n\n\nclass SingleDataset(BaseDataset):\n    def initialize(self, opt):\n        self.opt = opt\n        self.root = opt.dataroot\n        self.dir_A = os.path.join(opt.dataroot)\n\n        self.A_paths = make_dataset(self.dir_A)\n\n        self.A_paths = sorted(self.A_paths)\n\n        self.transform = get_transform(opt)\n\n    def __getitem__(self, index):\n        A_path = self.A_paths[index]\n        A_img = Image.open(A_path).convert('RGB')\n        A = self.transform(A_img)\n        if self.opt.which_direction == 'BtoA':\n            input_nc = self.opt.output_nc\n        else:\n            input_nc = self.opt.input_nc\n\n        if input_nc == 1:  # RGB to gray\n            tmp = A[0, ...] * 0.299 + A[1, ...] * 0.587 + A[2, ...] * 0.114\n            A = tmp.unsqueeze(0)\n\n        return {'A': A, 'A_paths': A_path}\n\n    def __len__(self):\n        return len(self.A_paths)\n\n    def name(self):\n        return 'SingleImageDataset'\n"""
courses/dl2/cgan/data/unaligned_dataset.py,0,"b""import os.path\nfrom .base_dataset import BaseDataset, get_transform\nfrom .image_folder import make_dataset\nfrom PIL import Image\nimport random\n\n\nclass UnalignedDataset(BaseDataset):\n    def initialize(self, opt):\n        self.opt = opt\n        self.root = opt.dataroot\n        self.dir_A = os.path.join(opt.dataroot, opt.phase + 'A')\n        self.dir_B = os.path.join(opt.dataroot, opt.phase + 'B')\n\n        self.A_paths = make_dataset(self.dir_A)\n        self.B_paths = make_dataset(self.dir_B)\n\n        self.A_paths = sorted(self.A_paths)\n        self.B_paths = sorted(self.B_paths)\n        self.A_size = len(self.A_paths)\n        self.B_size = len(self.B_paths)\n        self.transform = get_transform(opt)\n\n    def __getitem__(self, index):\n        A_path = self.A_paths[index % self.A_size]\n        if self.opt.serial_batches:\n            index_B = index % self.B_size\n        else:\n            index_B = random.randint(0, self.B_size - 1)\n        B_path = self.B_paths[index_B]\n        # print('(A, B) = (%d, %d)' % (index_A, index_B))\n        A_img = Image.open(A_path).convert('RGB')\n        B_img = Image.open(B_path).convert('RGB')\n\n        A = self.transform(A_img)\n        B = self.transform(B_img)\n        if self.opt.which_direction == 'BtoA':\n            input_nc = self.opt.output_nc\n            output_nc = self.opt.input_nc\n        else:\n            input_nc = self.opt.input_nc\n            output_nc = self.opt.output_nc\n\n        if input_nc == 1:  # RGB to gray\n            tmp = A[0, ...] * 0.299 + A[1, ...] * 0.587 + A[2, ...] * 0.114\n            A = tmp.unsqueeze(0)\n\n        if output_nc == 1:  # RGB to gray\n            tmp = B[0, ...] * 0.299 + B[1, ...] * 0.587 + B[2, ...] * 0.114\n            B = tmp.unsqueeze(0)\n\n        return {'A': A, 'B': B, 'A_paths': A_path, 'B_paths': B_path}\n\n    def __len__(self): return max(self.A_size, self.B_size)\n\n    def name(self): return 'UnalignedDataset'\n"""
courses/dl2/cgan/models/__init__.py,0,b''
courses/dl2/cgan/models/base_model.py,4,"b""import os\nimport torch\n\n\nclass BaseModel():\n    def name(self): return 'BaseModel'\n\n    def initialize(self, opt):\n        self.opt = opt\n        self.gpu_ids = opt.gpu_ids\n        self.isTrain = opt.isTrain\n        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n\n    def set_input(self, input): self.input = input\n    def forward(self): pass\n    def test(self): pass\n    def get_image_paths(self): pass\n    def optimize_parameters(self): pass\n    def get_current_visuals(self): return self.input\n    def get_current_errors(self): return {}\n    def save(self, label): pass\n\n    # helper saving function that can be used by subclasses\n    def save_network(self, network, network_label, epoch_label, gpu_ids):\n        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n        save_path = os.path.join(self.save_dir, save_filename)\n        torch.save(network.cpu().state_dict(), save_path)\n        if len(gpu_ids) and torch.cuda.is_available(): network.cuda(gpu_ids[0])\n\n    # helper loading function that can be used by subclasses\n    def load_network(self, network, network_label, epoch_label):\n        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n        save_path = os.path.join(self.save_dir, save_filename)\n        network.load_state_dict(torch.load(save_path))\n\n    # update learning rate (called once every epoch)\n    def update_learning_rate(self):\n        for scheduler in self.schedulers: scheduler.step()\n        lr = self.optimizers[0].param_groups[0]['lr']\n        print('learning rate = %.7f' % lr)\n\n"""
courses/dl2/cgan/models/cycle_gan_model.py,6,"b""import torch\nfrom collections import OrderedDict\nfrom torch.autograd import Variable\nimport itertools\nfrom ..util import util\nfrom ..util.image_pool import ImagePool\nfrom .base_model import BaseModel\nfrom . import networks\n\n\nclass CycleGANModel(BaseModel):\n    def name(self):\n        return 'CycleGANModel'\n\n    def initialize(self, opt):\n        BaseModel.initialize(self, opt)\n        # load/define networks\n        # The naming conversion is different from those used in the paper\n        # Code (paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)\n\n        self.netG_A = networks.define_G(opt.input_nc, opt.output_nc,\n                                        opt.ngf, opt.which_model_netG, opt.norm, not opt.no_dropout, opt.init_type, self.gpu_ids)\n        self.netG_B = networks.define_G(opt.output_nc, opt.input_nc,\n                                        opt.ngf, opt.which_model_netG, opt.norm, not opt.no_dropout, opt.init_type, self.gpu_ids)\n\n        if self.isTrain:\n            use_sigmoid = opt.no_lsgan\n            self.netD_A = networks.define_D(opt.output_nc, opt.ndf,\n                                            opt.which_model_netD,\n                                            opt.n_layers_D, opt.norm, use_sigmoid, opt.init_type, self.gpu_ids)\n            self.netD_B = networks.define_D(opt.input_nc, opt.ndf,\n                                            opt.which_model_netD,\n                                            opt.n_layers_D, opt.norm, use_sigmoid, opt.init_type, self.gpu_ids)\n        if not self.isTrain or opt.continue_train:\n            which_epoch = opt.which_epoch\n            self.load_network(self.netG_A, 'G_A', which_epoch)\n            self.load_network(self.netG_B, 'G_B', which_epoch)\n            if self.isTrain:\n                self.load_network(self.netD_A, 'D_A', which_epoch)\n                self.load_network(self.netD_B, 'D_B', which_epoch)\n\n        if self.isTrain:\n            self.fake_A_pool = ImagePool(opt.pool_size)\n            self.fake_B_pool = ImagePool(opt.pool_size)\n            # define loss functions\n            self.criterionGAN = networks.GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n            self.criterionCycle = torch.nn.L1Loss()\n            self.criterionIdt = torch.nn.L1Loss()\n            # initialize optimizers\n            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()),\n                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizers = []\n            self.schedulers = []\n            self.optimizers.append(self.optimizer_G)\n            self.optimizers.append(self.optimizer_D_A)\n            self.optimizers.append(self.optimizer_D_B)\n            for optimizer in self.optimizers:\n                self.schedulers.append(networks.get_scheduler(optimizer, opt))\n\n        print('---------- Networks initialized -------------')\n        networks.print_network(self.netG_A)\n        networks.print_network(self.netG_B)\n        if self.isTrain:\n            networks.print_network(self.netD_A)\n            networks.print_network(self.netD_B)\n        print('-----------------------------------------------')\n\n    def set_input(self, input):\n        AtoB = self.opt.which_direction == 'AtoB'\n        input_A = input['A' if AtoB else 'B']\n        input_B = input['B' if AtoB else 'A']\n        if len(self.gpu_ids) > 0:\n            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n            input_B = input_B.cuda(self.gpu_ids[0], async=True)\n        self.input_A = input_A\n        self.input_B = input_B\n        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n\n    def forward(self):\n        self.real_A = Variable(self.input_A)\n        self.real_B = Variable(self.input_B)\n\n    def test(self):\n        real_A = Variable(self.input_A, volatile=True)\n        fake_B = self.netG_A(real_A)\n        self.rec_A = self.netG_B(fake_B).data\n        self.fake_B = fake_B.data\n\n        real_B = Variable(self.input_B, volatile=True)\n        fake_A = self.netG_B(real_B)\n        self.rec_B = self.netG_A(fake_A).data\n        self.fake_A = fake_A.data\n\n    # get image paths\n    def get_image_paths(self):\n        return self.image_paths\n\n    def backward_D_basic(self, netD, real, fake):\n        # Real\n        pred_real = netD(real)\n        loss_D_real = self.criterionGAN(pred_real, True)\n        # Fake\n        pred_fake = netD(fake.detach())\n        loss_D_fake = self.criterionGAN(pred_fake, False)\n        # Combined loss\n        loss_D = (loss_D_real + loss_D_fake) * 0.5\n        # backward\n        loss_D.backward()\n        return loss_D\n\n    def backward_D_A(self):\n        fake_B = self.fake_B_pool.query(self.fake_B)\n        loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n        self.loss_D_A = loss_D_A.data[0]\n\n    def backward_D_B(self):\n        fake_A = self.fake_A_pool.query(self.fake_A)\n        loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n        self.loss_D_B = loss_D_B.data[0]\n\n    def backward_G(self):\n        lambda_idt = self.opt.lambda_identity\n        lambda_A = self.opt.lambda_A\n        lambda_B = self.opt.lambda_B\n        # Identity loss\n        if lambda_idt > 0:\n            # G_A should be identity if real_B is fed.\n            idt_A = self.netG_A(self.real_B)\n            loss_idt_A = self.criterionIdt(idt_A, self.real_B) * lambda_B * lambda_idt\n            # G_B should be identity if real_A is fed.\n            idt_B = self.netG_B(self.real_A)\n            loss_idt_B = self.criterionIdt(idt_B, self.real_A) * lambda_A * lambda_idt\n\n            self.idt_A = idt_A.data\n            self.idt_B = idt_B.data\n            self.loss_idt_A = loss_idt_A.data[0]\n            self.loss_idt_B = loss_idt_B.data[0]\n        else:\n            loss_idt_A = 0\n            loss_idt_B = 0\n            self.loss_idt_A = 0\n            self.loss_idt_B = 0\n\n        # GAN loss D_A(G_A(A))\n        fake_B = self.netG_A(self.real_A)\n        pred_fake = self.netD_A(fake_B)\n        loss_G_A = self.criterionGAN(pred_fake, True)\n\n        # GAN loss D_B(G_B(B))\n        fake_A = self.netG_B(self.real_B)\n        pred_fake = self.netD_B(fake_A)\n        loss_G_B = self.criterionGAN(pred_fake, True)\n\n        # Forward cycle loss\n        rec_A = self.netG_B(fake_B)\n        loss_cycle_A = self.criterionCycle(rec_A, self.real_A) * lambda_A\n\n        # Backward cycle loss\n        rec_B = self.netG_A(fake_A)\n        loss_cycle_B = self.criterionCycle(rec_B, self.real_B) * lambda_B\n        # combined loss\n        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_idt_A + loss_idt_B\n        loss_G.backward()\n\n        self.fake_B = fake_B.data\n        self.fake_A = fake_A.data\n        self.rec_A = rec_A.data\n        self.rec_B = rec_B.data\n\n        self.loss_G_A = loss_G_A.data[0]\n        self.loss_G_B = loss_G_B.data[0]\n        self.loss_cycle_A = loss_cycle_A.data[0]\n        self.loss_cycle_B = loss_cycle_B.data[0]\n\n    def optimize_parameters(self):\n        # forward\n        self.forward()\n        # G_A and G_B\n        self.optimizer_G.zero_grad()\n        self.backward_G()\n        self.optimizer_G.step()\n        # D_A\n        self.optimizer_D_A.zero_grad()\n        self.backward_D_A()\n        self.optimizer_D_A.step()\n        # D_B\n        self.optimizer_D_B.zero_grad()\n        self.backward_D_B()\n        self.optimizer_D_B.step()\n\n    def get_current_errors(self):\n        ret_errors = OrderedDict([('D_A', self.loss_D_A), ('G_A', self.loss_G_A), ('Cyc_A', self.loss_cycle_A),\n                                  ('D_B', self.loss_D_B), ('G_B', self.loss_G_B), ('Cyc_B', self.loss_cycle_B)])\n        if self.opt.lambda_identity > 0.0:\n            ret_errors['idt_A'] = self.loss_idt_A\n            ret_errors['idt_B'] = self.loss_idt_B\n        return ret_errors\n\n    def get_current_visuals(self):\n        real_A = util.tensor2im(self.input_A)\n        fake_B = util.tensor2im(self.fake_B)\n        rec_A = util.tensor2im(self.rec_A)\n        real_B = util.tensor2im(self.input_B)\n        fake_A = util.tensor2im(self.fake_A)\n        rec_B = util.tensor2im(self.rec_B)\n        ret_visuals = OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('rec_A', rec_A),\n                                   ('real_B', real_B), ('fake_A', fake_A), ('rec_B', rec_B)])\n        if self.opt.isTrain and self.opt.lambda_identity > 0.0:\n            ret_visuals['idt_A'] = util.tensor2im(self.idt_A)\n            ret_visuals['idt_B'] = util.tensor2im(self.idt_B)\n        return ret_visuals\n\n    def save(self, label):\n        self.save_network(self.netG_A, 'G_A', label, self.gpu_ids)\n        self.save_network(self.netD_A, 'D_A', label, self.gpu_ids)\n        self.save_network(self.netG_B, 'G_B', label, self.gpu_ids)\n        self.save_network(self.netD_B, 'D_B', label, self.gpu_ids)\n\n    def load(self, label):\n        self.load_network(self.netG_A, 'G_A', label)\n        self.load_network(self.netD_A, 'D_A', label)\n        self.load_network(self.netG_B, 'G_B', label)\n        self.load_network(self.netD_B, 'D_B', label)"""
courses/dl2/cgan/models/models.py,0,"b'def create_model(opt):\n    model = None\n    print(opt.model)\n    if opt.model == \'cycle_gan\':\n        assert(opt.dataset_mode == \'unaligned\')\n        from .cycle_gan_model import CycleGANModel\n        model = CycleGANModel()\n    elif opt.model == \'pix2pix\':\n        assert(opt.dataset_mode == \'aligned\')\n        from .pix2pix_model import Pix2PixModel\n        model = Pix2PixModel()\n    elif opt.model == \'test\':\n        assert(opt.dataset_mode == \'single\')\n        from .test_model import TestModel\n        model = TestModel()\n    else:\n        raise ValueError(""Model [%s] not recognized."" % opt.model)\n    model.initialize(opt)\n    print(""model [%s] was created"" % (model.name()))\n    return model\n'"
courses/dl2/cgan/models/networks.py,12,"b""import torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport functools\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\n###############################################################################\n# Functions\n###############################################################################\n\n\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('Linear') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef weights_init_xavier(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.xavier_normal(m.weight.data, gain=0.02)\n    elif classname.find('Linear') != -1:\n        init.xavier_normal(m.weight.data, gain=0.02)\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('Linear') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef weights_init_orthogonal(m):\n    classname = m.__class__.__name__\n    print(classname)\n    if classname.find('Conv') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef init_weights(net, init_type='normal'):\n    print('initialization method [%s]' % init_type)\n    if init_type == 'normal':\n        net.apply(weights_init_normal)\n    elif init_type == 'xavier':\n        net.apply(weights_init_xavier)\n    elif init_type == 'kaiming':\n        net.apply(weights_init_kaiming)\n    elif init_type == 'orthogonal':\n        net.apply(weights_init_orthogonal)\n    else:\n        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n\n\ndef get_norm_layer(norm_type='instance'):\n    if norm_type == 'batch':\n        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n    elif norm_type == 'instance':\n        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n    elif norm_type == 'none':\n        norm_layer = None\n    else:\n        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n    return norm_layer\n\n\ndef get_scheduler(optimizer, opt):\n    if opt.lr_policy == 'lambda':\n        def lambda_rule(epoch):\n            lr_l = 1.0 - max(0, epoch + 1 + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)\n            return lr_l\n        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n    elif opt.lr_policy == 'step':\n        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n    elif opt.lr_policy == 'plateau':\n        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n    else:\n        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n    return scheduler\n\n\ndef define_G(input_nc, output_nc, ngf, which_model_netG, norm='batch', use_dropout=False, init_type='normal', gpu_ids=[]):\n    netG = None\n    use_gpu = len(gpu_ids) > 0\n    norm_layer = get_norm_layer(norm_type=norm)\n\n    if use_gpu:\n        assert(torch.cuda.is_available())\n\n    if which_model_netG == 'resnet_9blocks':\n        netG = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9, gpu_ids=gpu_ids)\n    elif which_model_netG == 'resnet_6blocks':\n        netG = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=6, gpu_ids=gpu_ids)\n    elif which_model_netG == 'unet_128':\n        netG = UnetGenerator(input_nc, output_nc, 7, ngf, norm_layer=norm_layer, use_dropout=use_dropout, gpu_ids=gpu_ids)\n    elif which_model_netG == 'unet_256':\n        netG = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout, gpu_ids=gpu_ids)\n    else:\n        raise NotImplementedError('Generator model name [%s] is not recognized' % which_model_netG)\n    if len(gpu_ids) > 0:\n        netG.cuda(gpu_ids[0])\n    init_weights(netG, init_type=init_type)\n    return netG\n\n\ndef define_D(input_nc, ndf, which_model_netD,\n             n_layers_D=3, norm='batch', use_sigmoid=False, init_type='normal', gpu_ids=[]):\n    netD = None\n    use_gpu = len(gpu_ids) > 0\n    norm_layer = get_norm_layer(norm_type=norm)\n\n    if use_gpu:\n        assert(torch.cuda.is_available())\n    if which_model_netD == 'basic':\n        netD = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer, use_sigmoid=use_sigmoid, gpu_ids=gpu_ids)\n    elif which_model_netD == 'n_layers':\n        netD = NLayerDiscriminator(input_nc, ndf, n_layers_D, norm_layer=norm_layer, use_sigmoid=use_sigmoid, gpu_ids=gpu_ids)\n    elif which_model_netD == 'pixel':\n        netD = PixelDiscriminator(input_nc, ndf, norm_layer=norm_layer, use_sigmoid=use_sigmoid, gpu_ids=gpu_ids)\n    else:\n        raise NotImplementedError('Discriminator model name [%s] is not recognized' %\n                                  which_model_netD)\n    if use_gpu:\n        netD.cuda(gpu_ids[0])\n    init_weights(netD, init_type=init_type)\n    return netD\n\n\ndef print_network(net):\n    num_params = 0\n    for param in net.parameters():\n        num_params += param.numel()\n    print(net)\n    print('Total number of parameters: %d' % num_params)\n\n\n##############################################################################\n# Classes\n##############################################################################\n\n\n# Defines the GAN loss which uses either LSGAN or the regular GAN.\n# When LSGAN is used, it is basically same as MSELoss,\n# but it abstracts away the need to create the target label tensor\n# that has the same size as the input\nclass GANLoss(nn.Module):\n    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,\n                 tensor=torch.FloatTensor):\n        super(GANLoss, self).__init__()\n        self.real_label = target_real_label\n        self.fake_label = target_fake_label\n        self.real_label_var = None\n        self.fake_label_var = None\n        self.Tensor = tensor\n        if use_lsgan:\n            self.loss = nn.MSELoss()\n        else:\n            self.loss = nn.BCELoss()\n\n    def get_target_tensor(self, input, target_is_real):\n        target_tensor = None\n        if target_is_real:\n            create_label = ((self.real_label_var is None) or\n                            (self.real_label_var.numel() != input.numel()))\n            if create_label:\n                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n                self.real_label_var = Variable(real_tensor, requires_grad=False)\n            target_tensor = self.real_label_var\n        else:\n            create_label = ((self.fake_label_var is None) or\n                            (self.fake_label_var.numel() != input.numel()))\n            if create_label:\n                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n            target_tensor = self.fake_label_var\n        return target_tensor\n\n    def __call__(self, input, target_is_real):\n        target_tensor = self.get_target_tensor(input, target_is_real)\n        return self.loss(input, target_tensor)\n\n\n# Defines the generator that consists of Resnet blocks between a few\n# downsampling/upsampling operations.\n# Code and idea originally from Justin Johnson's architecture.\n# https://github.com/jcjohnson/fast-neural-style/\nclass ResnetGenerator(nn.Module):\n    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, gpu_ids=[], padding_type='reflect'):\n        assert(n_blocks >= 0)\n        super(ResnetGenerator, self).__init__()\n        self.input_nc = input_nc\n        self.output_nc = output_nc\n        self.ngf = ngf\n        self.gpu_ids = gpu_ids\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n\n        model = [nn.ReflectionPad2d(3),\n                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0,\n                           bias=use_bias),\n                 norm_layer(ngf),\n                 nn.ReLU(True)]\n\n        n_downsampling = 2\n        for i in range(n_downsampling):\n            mult = 2**i\n            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n                                stride=2, padding=1, bias=use_bias),\n                      norm_layer(ngf * mult * 2),\n                      nn.ReLU(True)]\n\n        mult = 2**n_downsampling\n        for i in range(n_blocks):\n            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n\n        for i in range(n_downsampling):\n            mult = 2**(n_downsampling - i)\n            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n                                         kernel_size=3, stride=2,\n                                         padding=1, output_padding=1,\n                                         bias=use_bias),\n                      norm_layer(int(ngf * mult / 2)),\n                      nn.ReLU(True)]\n        model += [nn.ReflectionPad2d(3)]\n        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n        model += [nn.Tanh()]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, input):\n        if self.gpu_ids and isinstance(input.data, torch.cuda.FloatTensor):\n            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n        else:\n            return self.model(input)\n\n\n# Define a resnet block\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n        super(ResnetBlock, self).__init__()\n        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n\n    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n        conv_block = []\n        p = 0\n        if padding_type == 'reflect':\n            conv_block += [nn.ReflectionPad2d(1)]\n        elif padding_type == 'replicate':\n            conv_block += [nn.ReplicationPad2d(1)]\n        elif padding_type == 'zero':\n            p = 1\n        else:\n            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n\n        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n                       norm_layer(dim),\n                       nn.ReLU(True)]\n        if use_dropout:\n            conv_block += [nn.Dropout(0.5)]\n\n        p = 0\n        if padding_type == 'reflect':\n            conv_block += [nn.ReflectionPad2d(1)]\n        elif padding_type == 'replicate':\n            conv_block += [nn.ReplicationPad2d(1)]\n        elif padding_type == 'zero':\n            p = 1\n        else:\n            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n                       norm_layer(dim)]\n\n        return nn.Sequential(*conv_block)\n\n    def forward(self, x):\n        out = x + self.conv_block(x)\n        return out\n\n\n# Defines the Unet generator.\n# |num_downs|: number of downsamplings in UNet. For example,\n# if |num_downs| == 7, image of size 128x128 will become of size 1x1\n# at the bottleneck\nclass UnetGenerator(nn.Module):\n    def __init__(self, input_nc, output_nc, num_downs, ngf=64,\n                 norm_layer=nn.BatchNorm2d, use_dropout=False, gpu_ids=[]):\n        super(UnetGenerator, self).__init__()\n        self.gpu_ids = gpu_ids\n\n        # construct unet structure\n        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n        for i in range(num_downs - 5):\n            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n        unet_block = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n\n        self.model = unet_block\n\n    def forward(self, input):\n        if self.gpu_ids and isinstance(input.data, torch.cuda.FloatTensor):\n            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n        else:\n            return self.model(input)\n\n\n# Defines the submodule with skip connection.\n# X -------------------identity---------------------- X\n#   |-- downsampling -- |submodule| -- upsampling --|\nclass UnetSkipConnectionBlock(nn.Module):\n    def __init__(self, outer_nc, inner_nc, input_nc=None,\n                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n        super(UnetSkipConnectionBlock, self).__init__()\n        self.outermost = outermost\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n        if input_nc is None:\n            input_nc = outer_nc\n        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n                             stride=2, padding=1, bias=use_bias)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = norm_layer(inner_nc)\n        uprelu = nn.ReLU(True)\n        upnorm = norm_layer(outer_nc)\n\n        if outermost:\n            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n                                        kernel_size=4, stride=2,\n                                        padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n                                        kernel_size=4, stride=2,\n                                        padding=1, bias=use_bias)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n                                        kernel_size=4, stride=2,\n                                        padding=1, bias=use_bias)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n\n            if use_dropout:\n                model = down + [submodule] + up + [nn.Dropout(0.5)]\n            else:\n                model = down + [submodule] + up\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\n\n# Defines the PatchGAN discriminator with the specified arguments.\nclass NLayerDiscriminator(nn.Module):\n    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, gpu_ids=[]):\n        super(NLayerDiscriminator, self).__init__()\n        self.gpu_ids = gpu_ids\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n\n        kw = 4\n        padw = 1\n        sequence = [\n            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        nf_mult = 1\n        nf_mult_prev = 1\n        for n in range(1, n_layers):\n            nf_mult_prev = nf_mult\n            nf_mult = min(2**n, 8)\n            sequence += [\n                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n                norm_layer(ndf * nf_mult),\n                nn.LeakyReLU(0.2, True)\n            ]\n\n        nf_mult_prev = nf_mult\n        nf_mult = min(2**n_layers, 8)\n        sequence += [\n            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n            norm_layer(ndf * nf_mult),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n\n        if use_sigmoid:\n            sequence += [nn.Sigmoid()]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, input):\n        if len(self.gpu_ids) and isinstance(input.data, torch.cuda.FloatTensor):\n            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n        else:\n            return self.model(input)\n\n\nclass PixelDiscriminator(nn.Module):\n    def __init__(self, input_nc, ndf=64, norm_layer=nn.BatchNorm2d, use_sigmoid=False, gpu_ids=[]):\n        super(PixelDiscriminator, self).__init__()\n        self.gpu_ids = gpu_ids\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n\n        self.net = [\n            nn.Conv2d(input_nc, ndf, kernel_size=1, stride=1, padding=0),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(ndf, ndf * 2, kernel_size=1, stride=1, padding=0, bias=use_bias),\n            norm_layer(ndf * 2),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(ndf * 2, 1, kernel_size=1, stride=1, padding=0, bias=use_bias)]\n\n        if use_sigmoid:\n            self.net.append(nn.Sigmoid())\n\n        self.net = nn.Sequential(*self.net)\n\n    def forward(self, input):\n        if len(self.gpu_ids) and isinstance(input.data, torch.cuda.FloatTensor):\n            return nn.parallel.data_parallel(self.net, input, self.gpu_ids)\n        else:\n            return self.net(input)\n"""
courses/dl2/cgan/models/pix2pix_model.py,7,"b""import torch\nfrom collections import OrderedDict\nfrom torch.autograd import Variable\nfrom ..util import * \nfrom ..util.image_pool import ImagePool\nfrom .base_model import BaseModel\nfrom . import networks\n\nclass Pix2PixModel(BaseModel):\n    def name(self):\n        return 'Pix2PixModel'\n\n    def initialize(self, opt):\n        BaseModel.initialize(self, opt)\n        self.isTrain = opt.isTrain\n\n        # load/define networks\n        self.netG = networks.define_G(opt.input_nc, opt.output_nc, opt.ngf,\n                                      opt.which_model_netG, opt.norm, not opt.no_dropout, opt.init_type, self.gpu_ids)\n        if self.isTrain:\n            use_sigmoid = opt.no_lsgan\n            self.netD = networks.define_D(opt.input_nc + opt.output_nc, opt.ndf,\n                                          opt.which_model_netD,\n                                          opt.n_layers_D, opt.norm, use_sigmoid, opt.init_type, self.gpu_ids)\n        if not self.isTrain or opt.continue_train:\n            self.load_network(self.netG, 'G', opt.which_epoch)\n            if self.isTrain:\n                self.load_network(self.netD, 'D', opt.which_epoch)\n\n        if self.isTrain:\n            self.fake_AB_pool = ImagePool(opt.pool_size)\n            # define loss functions\n            self.criterionGAN = networks.GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n            self.criterionL1 = torch.nn.L1Loss()\n\n            # initialize optimizers\n            self.schedulers = []\n            self.optimizers = []\n            self.optimizer_G = torch.optim.Adam(self.netG.parameters(),\n                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizer_D = torch.optim.Adam(self.netD.parameters(),\n                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizers.append(self.optimizer_G)\n            self.optimizers.append(self.optimizer_D)\n            for optimizer in self.optimizers:\n                self.schedulers.append(networks.get_scheduler(optimizer, opt))\n\n        print('---------- Networks initialized -------------')\n        networks.print_network(self.netG)\n        if self.isTrain:\n            networks.print_network(self.netD)\n        print('-----------------------------------------------')\n\n    def set_input(self, input):\n        AtoB = self.opt.which_direction == 'AtoB'\n        input_A = input['A' if AtoB else 'B']\n        input_B = input['B' if AtoB else 'A']\n        if len(self.gpu_ids) > 0:\n            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n            input_B = input_B.cuda(self.gpu_ids[0], async=True)\n        self.input_A = input_A\n        self.input_B = input_B\n        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n\n    def forward(self):\n        self.real_A = Variable(self.input_A)\n        self.fake_B = self.netG(self.real_A)\n        self.real_B = Variable(self.input_B)\n\n    # no backprop gradients\n    def test(self):\n        self.real_A = Variable(self.input_A, volatile=True)\n        self.fake_B = self.netG(self.real_A)\n        self.real_B = Variable(self.input_B, volatile=True)\n\n    # get image paths\n    def get_image_paths(self):\n        return self.image_paths\n\n    def backward_D(self):\n        # Fake\n        # stop backprop to the generator by detaching fake_B\n        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1).data)\n        pred_fake = self.netD(fake_AB.detach())\n        self.loss_D_fake = self.criterionGAN(pred_fake, False)\n\n        # Real\n        real_AB = torch.cat((self.real_A, self.real_B), 1)\n        pred_real = self.netD(real_AB)\n        self.loss_D_real = self.criterionGAN(pred_real, True)\n\n        # Combined loss\n        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n\n        self.loss_D.backward()\n\n    def backward_G(self):\n        # First, G(A) should fake the discriminator\n        fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n        pred_fake = self.netD(fake_AB)\n        self.loss_G_GAN = self.criterionGAN(pred_fake, True)\n\n        # Second, G(A) = B\n        self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B) * self.opt.lambda_A\n\n        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n\n        self.loss_G.backward()\n\n    def optimize_parameters(self):\n        self.forward()\n\n        self.optimizer_D.zero_grad()\n        self.backward_D()\n        self.optimizer_D.step()\n\n        self.optimizer_G.zero_grad()\n        self.backward_G()\n        self.optimizer_G.step()\n\n    def get_current_errors(self):\n        return OrderedDict([('G_GAN', self.loss_G_GAN.data[0]),\n                            ('G_L1', self.loss_G_L1.data[0]),\n                            ('D_real', self.loss_D_real.data[0]),\n                            ('D_fake', self.loss_D_fake.data[0])\n                            ])\n\n    def get_current_visuals(self):\n        real_A = util.tensor2im(self.real_A.data)\n        fake_B = util.tensor2im(self.fake_B.data)\n        real_B = util.tensor2im(self.real_B.data)\n        return OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('real_B', real_B)])\n\n    def save(self, label):\n        self.save_network(self.netG, 'G', label, self.gpu_ids)\n        self.save_network(self.netD, 'D', label, self.gpu_ids)\n\n    def load(self, label):\n        self.load_network(self.netG, 'G', label)\n        self.load_network(self.netD, 'D', label)\n"""
courses/dl2/cgan/models/test_model.py,1,"b""from torch.autograd import Variable\nfrom collections import OrderedDict\nfrom ..util import *\nfrom .base_model import BaseModel\nfrom . import networks\n\n\nclass TestModel(BaseModel):\n    def name(self):\n        return 'TestModel'\n\n    def initialize(self, opt):\n        assert(not opt.isTrain)\n        BaseModel.initialize(self, opt)\n        self.netG = networks.define_G(opt.input_nc, opt.output_nc,\n                                      opt.ngf, opt.which_model_netG,\n                                      opt.norm, not opt.no_dropout,\n                                      opt.init_type,\n                                      self.gpu_ids)\n        which_epoch = opt.which_epoch\n        self.load_network(self.netG, 'G', which_epoch)\n\n        print('---------- Networks initialized -------------')\n        networks.print_network(self.netG)\n        print('-----------------------------------------------')\n\n    def set_input(self, input):\n        # we need to use single_dataset mode\n        input_A = input['A']\n        if len(self.gpu_ids) > 0:\n            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n        self.input_A = input_A\n        self.image_paths = input['A_paths']\n\n    def test(self):\n        self.real_A = Variable(self.input_A)\n        self.fake_B = self.netG(self.real_A)\n\n    # get image paths\n    def get_image_paths(self):\n        return self.image_paths\n\n    def get_current_visuals(self):\n        real_A = util.tensor2im(self.real_A.data)\n        fake_B = util.tensor2im(self.fake_B.data)\n        return OrderedDict([('real_A', real_A), ('fake_B', fake_B)])\n"""
courses/dl2/cgan/options/__init__.py,0,b''
courses/dl2/cgan/options/base_options.py,1,"b'import argparse\nimport os\nfrom ..util import util\nimport torch\n\n\nclass BaseOptions():\n    def __init__(self):\n        self.parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n        self.initialized = False\n\n    def initialize(self):\n        self.parser.add_argument(\'--dataroot\', required=True, help=\'path to images (should have subfolders trainA, trainB, valA, valB, etc)\')\n        self.parser.add_argument(\'--batchSize\', type=int, default=1, help=\'input batch size\')\n        self.parser.add_argument(\'--loadSize\', type=int, default=286, help=\'scale images to this size\')\n        self.parser.add_argument(\'--fineSize\', type=int, default=256, help=\'then crop to this size\')\n        self.parser.add_argument(\'--input_nc\', type=int, default=3, help=\'# of input image channels\')\n        self.parser.add_argument(\'--output_nc\', type=int, default=3, help=\'# of output image channels\')\n        self.parser.add_argument(\'--ngf\', type=int, default=64, help=\'# of gen filters in first conv layer\')\n        self.parser.add_argument(\'--ndf\', type=int, default=64, help=\'# of discrim filters in first conv layer\')\n        self.parser.add_argument(\'--which_model_netD\', type=str, default=\'basic\', help=\'selects model to use for netD\')\n        self.parser.add_argument(\'--which_model_netG\', type=str, default=\'resnet_9blocks\', help=\'selects model to use for netG\')\n        self.parser.add_argument(\'--n_layers_D\', type=int, default=3, help=\'only used if which_model_netD==n_layers\')\n        self.parser.add_argument(\'--gpu_ids\', type=str, default=\'0\', help=\'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU\')\n        self.parser.add_argument(\'--name\', type=str, default=\'experiment_name\', help=\'name of the experiment. It decides where to store samples and models\')\n        self.parser.add_argument(\'--dataset_mode\', type=str, default=\'unaligned\', help=\'chooses how datasets are loaded. [unaligned | aligned | single]\')\n        self.parser.add_argument(\'--model\', type=str, default=\'cycle_gan\',\n                                 help=\'chooses which model to use. cycle_gan, pix2pix, test\')\n        self.parser.add_argument(\'--which_direction\', type=str, default=\'AtoB\', help=\'AtoB or BtoA\')\n        self.parser.add_argument(\'--nThreads\', default=2, type=int, help=\'# threads for loading data\')\n        self.parser.add_argument(\'--checkpoints_dir\', type=str, default=\'./checkpoints\', help=\'models are saved here\')\n        self.parser.add_argument(\'--norm\', type=str, default=\'instance\', help=\'instance normalization or batch normalization\')\n        self.parser.add_argument(\'--serial_batches\', action=\'store_true\', help=\'if true, takes images in order to make batches, otherwise takes them randomly\')\n        self.parser.add_argument(\'--display_winsize\', type=int, default=256, help=\'display window size\')\n        self.parser.add_argument(\'--display_id\', type=int, default=1, help=\'window id of the web display\')\n        self.parser.add_argument(\'--display_port\', type=int, default=8097, help=\'visdom port of the web display\')\n        self.parser.add_argument(\'--no_dropout\', action=\'store_true\', help=\'no dropout for the generator\')\n        self.parser.add_argument(\'--max_dataset_size\', type=int, default=float(""inf""),\n                                 help=\'Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.\')\n        self.parser.add_argument(\'--resize_or_crop\', type=str, default=\'resize_and_crop\', help=\'scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]\')\n        self.parser.add_argument(\'--no_flip\', action=\'store_true\', help=\'if specified, do not flip the images for data augmentation\')\n        self.parser.add_argument(\'--init_type\', type=str, default=\'normal\', help=\'network initialization [normal|xavier|kaiming|orthogonal]\')\n\n        self.initialized = True\n\n    def parse(self, args=None):\n        if not self.initialized:\n            self.initialize()\n        self.opt = self.parser.parse_args(args)\n        self.opt.isTrain = self.isTrain   # train or test\n\n        str_ids = self.opt.gpu_ids.split(\',\')\n        self.opt.gpu_ids = []\n        for str_id in str_ids:\n            id = int(str_id)\n            if id >= 0:\n                self.opt.gpu_ids.append(id)\n\n        # set gpu ids\n        if len(self.opt.gpu_ids) > 0:\n            torch.cuda.set_device(self.opt.gpu_ids[0])\n\n        args = vars(self.opt)\n\n        print(\'------------ Options -------------\')\n        for k, v in sorted(args.items()):\n            print(\'%s: %s\' % (str(k), str(v)))\n        print(\'-------------- End ----------------\')\n\n        # save to the disk\n        expr_dir = os.path.join(self.opt.checkpoints_dir, self.opt.name)\n        util.mkdirs(expr_dir)\n        file_name = os.path.join(expr_dir, \'opt.txt\')\n        with open(file_name, \'wt\') as opt_file:\n            opt_file.write(\'------------ Options -------------\\n\')\n            for k, v in sorted(args.items()):\n                opt_file.write(\'%s: %s\\n\' % (str(k), str(v)))\n            opt_file.write(\'-------------- End ----------------\\n\')\n        return self.opt\n'"
courses/dl2/cgan/options/test_options.py,0,"b'from .base_options import BaseOptions\n\n\nclass TestOptions(BaseOptions):\n    def initialize(self):\n        BaseOptions.initialize(self)\n        self.parser.add_argument(\'--ntest\', type=int, default=float(""inf""), help=\'# of test examples.\')\n        self.parser.add_argument(\'--results_dir\', type=str, default=\'./results/\', help=\'saves results here.\')\n        self.parser.add_argument(\'--aspect_ratio\', type=float, default=1.0, help=\'aspect ratio of result images\')\n        self.parser.add_argument(\'--phase\', type=str, default=\'test\', help=\'train, val, test, etc\')\n        self.parser.add_argument(\'--which_epoch\', type=str, default=\'latest\', help=\'which epoch to load? set to latest to use latest cached model\')\n        self.parser.add_argument(\'--how_many\', type=int, default=50, help=\'how many test images to run\')\n        self.isTrain = False\n'"
courses/dl2/cgan/options/train_options.py,0,"b""from .base_options import BaseOptions\n\n\nclass TrainOptions(BaseOptions):\n    def initialize(self):\n        BaseOptions.initialize(self)\n        self.parser.add_argument('--display_freq', type=int, default=100, help='frequency of showing training results on screen')\n        self.parser.add_argument('--display_single_pane_ncols', type=int, default=0, help='if positive, display all images in a single visdom web panel with certain number of images per row.')\n        self.parser.add_argument('--update_html_freq', type=int, default=1000, help='frequency of saving training results to html')\n        self.parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n        self.parser.add_argument('--save_latest_freq', type=int, default=5000, help='frequency of saving the latest results')\n        self.parser.add_argument('--save_epoch_freq', type=int, default=5, help='frequency of saving checkpoints at the end of epochs')\n        self.parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n        self.parser.add_argument('--epoch_count', type=int, default=1, help='the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...')\n        self.parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n        self.parser.add_argument('--which_epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\n        self.parser.add_argument('--niter', type=int, default=100, help='# of iter at starting learning rate')\n        self.parser.add_argument('--niter_decay', type=int, default=100, help='# of iter to linearly decay learning rate to zero')\n        self.parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n        self.parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n        self.parser.add_argument('--no_lsgan', action='store_true', help='do *not* use least square GAN, if false, use vanilla GAN')\n        self.parser.add_argument('--lambda_A', type=float, default=10.0, help='weight for cycle loss (A -> B -> A)')\n        self.parser.add_argument('--lambda_B', type=float, default=10.0, help='weight for cycle loss (B -> A -> B)')\n        self.parser.add_argument('--lambda_identity', type=float, default=0.5,\n                                 help='use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss.'\n                                 'For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1')\n        self.parser.add_argument('--pool_size', type=int, default=50, help='the size of image buffer that stores previously generated images')\n        self.parser.add_argument('--no_html', action='store_true', help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/')\n        self.parser.add_argument('--lr_policy', type=str, default='lambda', help='learning rate policy: lambda|step|plateau')\n        self.parser.add_argument('--lr_decay_iters', type=int, default=50, help='multiply by a gamma every lr_decay_iters iterations')\n\n        self.isTrain = True\n"""
courses/dl2/cgan/util/__init__.py,0,b''
courses/dl2/cgan/util/get_data.py,0,"b'from __future__ import print_function\nimport os\nimport tarfile\nimport requests\nfrom warnings import warn\nfrom zipfile import ZipFile\nfrom bs4 import BeautifulSoup\nfrom os.path import abspath, isdir, join, basename\n\n\nclass GetData(object):\n    """"""\n\n    Download CycleGAN or Pix2Pix Data.\n\n    Args:\n        technique : str\n            One of: \'cyclegan\' or \'pix2pix\'.\n        verbose : bool\n            If True, print additional information.\n\n    Examples:\n        >>> from util.get_data import GetData\n        >>> gd = GetData(technique=\'cyclegan\')\n        >>> new_data_path = gd.get(save_path=\'./datasets\')  # options will be displayed.\n\n    """"""\n\n    def __init__(self, technique=\'cyclegan\', verbose=True):\n        url_dict = {\n            \'pix2pix\': \'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets\',\n            \'cyclegan\': \'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets\'\n        }\n        self.url = url_dict.get(technique.lower())\n        self._verbose = verbose\n\n    def _print(self, text):\n        if self._verbose:\n            print(text)\n\n    @staticmethod\n    def _get_options(r):\n        soup = BeautifulSoup(r.text, \'lxml\')\n        options = [h.text for h in soup.find_all(\'a\', href=True)\n                   if h.text.endswith((\'.zip\', \'tar.gz\'))]\n        return options\n\n    def _present_options(self):\n        r = requests.get(self.url)\n        options = self._get_options(r)\n        print(\'Options:\\n\')\n        for i, o in enumerate(options):\n            print(""{0}: {1}"".format(i, o))\n        choice = input(""\\nPlease enter the number of the ""\n                       ""dataset above you wish to download:"")\n        return options[int(choice)]\n\n    def _download_data(self, dataset_url, save_path):\n        if not isdir(save_path):\n            os.makedirs(save_path)\n\n        base = basename(dataset_url)\n        temp_save_path = join(save_path, base)\n\n        with open(temp_save_path, ""wb"") as f:\n            r = requests.get(dataset_url)\n            f.write(r.content)\n\n        if base.endswith(\'.tar.gz\'):\n            obj = tarfile.open(temp_save_path)\n        elif base.endswith(\'.zip\'):\n            obj = ZipFile(temp_save_path, \'r\')\n        else:\n            raise ValueError(""Unknown File Type: {0}."".format(base))\n\n        self._print(""Unpacking Data..."")\n        obj.extractall(save_path)\n        obj.close()\n        os.remove(temp_save_path)\n\n    def get(self, save_path, dataset=None):\n        """"""\n\n        Download a dataset.\n\n        Args:\n            save_path : str\n                A directory to save the data to.\n            dataset : str, optional\n                A specific dataset to download.\n                Note: this must include the file extension.\n                If None, options will be presented for you\n                to choose from.\n\n        Returns:\n            save_path_full : str\n                The absolute path to the downloaded data.\n\n        """"""\n        if dataset is None:\n            selected_dataset = self._present_options()\n        else:\n            selected_dataset = dataset\n\n        save_path_full = join(save_path, selected_dataset.split(\'.\')[0])\n\n        if isdir(save_path_full):\n            warn(""\\n\'{0}\' already exists. Voiding Download."".format(\n                save_path_full))\n        else:\n            self._print(\'Downloading Data...\')\n            url = ""{0}/{1}"".format(self.url, selected_dataset)\n            self._download_data(url, save_path=save_path)\n\n        return abspath(save_path_full)\n'"
courses/dl2/cgan/util/html.py,0,"b'import dominate\nfrom dominate.tags import *\nimport os\n\n\nclass HTML:\n    def __init__(self, web_dir, title, refresh=0):\n        self.title = title\n        self.web_dir = web_dir\n        self.img_dir = os.path.join(self.web_dir, \'images\')\n        if not os.path.exists(self.web_dir):\n            os.makedirs(self.web_dir)\n        if not os.path.exists(self.img_dir):\n            os.makedirs(self.img_dir)\n        # print(self.img_dir)\n\n        self.doc = dominate.document(title=title)\n        if refresh > 0:\n            with self.doc.head:\n                meta(http_equiv=""refresh"", content=str(refresh))\n\n    def get_image_dir(self):\n        return self.img_dir\n\n    def add_header(self, str):\n        with self.doc:\n            h3(str)\n\n    def add_table(self, border=1):\n        self.t = table(border=border, style=""table-layout: fixed;"")\n        self.doc.add(self.t)\n\n    def add_images(self, ims, txts, links, width=400):\n        self.add_table()\n        with self.t:\n            with tr():\n                for im, txt, link in zip(ims, txts, links):\n                    with td(style=""word-wrap: break-word;"", halign=""center"", valign=""top""):\n                        with p():\n                            with a(href=os.path.join(\'images\', link)):\n                                img(style=""width:%dpx"" % width, src=os.path.join(\'images\', im))\n                            br()\n                            p(txt)\n\n    def save(self):\n        html_file = \'%s/index.html\' % self.web_dir\n        f = open(html_file, \'wt\')\n        f.write(self.doc.render())\n        f.close()\n\n\nif __name__ == \'__main__\':\n    html = HTML(\'web/\', \'test_html\')\n    html.add_header(\'hello world\')\n\n    ims = []\n    txts = []\n    links = []\n    for n in range(4):\n        ims.append(\'image_%d.png\' % n)\n        txts.append(\'text_%d\' % n)\n        links.append(\'image_%d.png\' % n)\n    html.add_images(ims, txts, links)\n    html.save()\n'"
courses/dl2/cgan/util/image_pool.py,3,"b'import random\nimport torch\nfrom torch.autograd import Variable\n\n\nclass ImagePool():\n    def __init__(self, pool_size):\n        self.pool_size = pool_size\n        if self.pool_size > 0:\n            self.num_imgs = 0\n            self.images = []\n\n    def query(self, images):\n        if self.pool_size == 0:\n            return Variable(images)\n        return_images = []\n        for image in images:\n            image = torch.unsqueeze(image, 0)\n            if self.num_imgs < self.pool_size:\n                self.num_imgs = self.num_imgs + 1\n                self.images.append(image)\n                return_images.append(image)\n            else:\n                p = random.uniform(0, 1)\n                if p > 0.5:\n                    random_id = random.randint(0, self.pool_size - 1)\n                    tmp = self.images[random_id].clone()\n                    self.images[random_id] = image\n                    return_images.append(tmp)\n                else:\n                    return_images.append(image)\n        return_images = Variable(torch.cat(return_images, 0))\n        return return_images\n'"
courses/dl2/cgan/util/util.py,1,"b""from __future__ import print_function\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport os\n\n\n# Converts a Tensor into a Numpy array\n# |imtype|: the desired type of the converted numpy array\ndef tensor2im(image_tensor, imtype=np.uint8):\n    image_numpy = image_tensor[0].cpu().float().numpy()\n    if image_numpy.shape[0] == 1:\n        image_numpy = np.tile(image_numpy, (3, 1, 1))\n    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n    return image_numpy.astype(imtype)\n\n\ndef diagnose_network(net, name='network'):\n    mean = 0.0\n    count = 0\n    for param in net.parameters():\n        if param.grad is not None:\n            mean += torch.mean(torch.abs(param.grad.data))\n            count += 1\n    if count > 0:\n        mean = mean / count\n    print(name)\n    print(mean)\n\n\ndef save_image(image_numpy, image_path):\n    image_pil = Image.fromarray(image_numpy)\n    image_pil.save(image_path)\n\n\ndef print_numpy(x, val=True, shp=False):\n    x = x.astype(np.float64)\n    if shp:\n        print('shape,', x.shape)\n    if val:\n        x = x.flatten()\n        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))\n\n\ndef mkdirs(paths):\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)\n\n\ndef mkdir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n"""
courses/dl2/cgan/util/visualizer.py,0,"b'import numpy as np\nimport os\nimport ntpath\nimport time\nfrom . import util\nfrom . import html\n#from scipy.misc import imresize\nfrom skimage.transform import resize as imresize\n\nclass Visualizer():\n    def __init__(self, opt):\n        # self.opt = opt\n        self.display_id = opt.display_id\n        self.use_html = opt.isTrain and not opt.no_html\n        self.win_size = opt.display_winsize\n        self.name = opt.name\n        self.opt = opt\n        self.saved = False\n        if self.display_id > 0:\n            import visdom\n            self.vis = visdom.Visdom(port=opt.display_port)\n\n        if self.use_html:\n            self.web_dir = os.path.join(opt.checkpoints_dir, opt.name, \'web\')\n            self.img_dir = os.path.join(self.web_dir, \'images\')\n            print(\'create web directory %s...\' % self.web_dir)\n            util.mkdirs([self.web_dir, self.img_dir])\n        self.log_name = os.path.join(opt.checkpoints_dir, opt.name, \'loss_log.txt\')\n        with open(self.log_name, ""a"") as log_file:\n            now = time.strftime(""%c"")\n            log_file.write(\'================ Training Loss (%s) ================\\n\' % now)\n\n    def reset(self):\n        self.saved = False\n\n    # |visuals|: dictionary of images to display or save\n    def display_current_results(self, visuals, epoch, save_result):\n        if self.display_id > 0:  # show images in the browser\n            ncols = self.opt.display_single_pane_ncols\n            if ncols > 0:\n                h, w = next(iter(visuals.values())).shape[:2]\n                table_css = """"""<style>\n                        table {border-collapse: separate; border-spacing:4px; white-space:nowrap; text-align:center}\n                        table td {width: %dpx; height: %dpx; padding: 4px; outline: 4px solid black}\n                        </style>"""""" % (w, h)\n                title = self.name\n                label_html = \'\'\n                label_html_row = \'\'\n                nrows = int(np.ceil(len(visuals.items()) / ncols))\n                images = []\n                idx = 0\n                for label, image_numpy in visuals.items():\n                    label_html_row += \'<td>%s</td>\' % label\n                    images.append(image_numpy.transpose([2, 0, 1]))\n                    idx += 1\n                    if idx % ncols == 0:\n                        label_html += \'<tr>%s</tr>\' % label_html_row\n                        label_html_row = \'\'\n                white_image = np.ones_like(image_numpy.transpose([2, 0, 1])) * 255\n                while idx % ncols != 0:\n                    images.append(white_image)\n                    label_html_row += \'<td></td>\'\n                    idx += 1\n                if label_html_row != \'\':\n                    label_html += \'<tr>%s</tr>\' % label_html_row\n                # pane col = image row\n                self.vis.images(images, nrow=ncols, win=self.display_id + 1,\n                                padding=2, opts=dict(title=title + \' images\'))\n                label_html = \'<table>%s</table>\' % label_html\n                self.vis.text(table_css + label_html, win=self.display_id + 2,\n                              opts=dict(title=title + \' labels\'))\n            else:\n                idx = 1\n                for label, image_numpy in visuals.items():\n                    self.vis.image(image_numpy.transpose([2, 0, 1]), opts=dict(title=label),\n                                   win=self.display_id + idx)\n                    idx += 1\n\n        if self.use_html and (save_result or not self.saved):  # save images to a html file\n            self.saved = True\n            for label, image_numpy in visuals.items():\n                img_path = os.path.join(self.img_dir, \'epoch%.3d_%s.png\' % (epoch, label))\n                util.save_image(image_numpy, img_path)\n            # update website\n            webpage = html.HTML(self.web_dir, \'Experiment name = %s\' % self.name, refresh=1)\n            for n in range(epoch, 0, -1):\n                webpage.add_header(\'epoch [%d]\' % n)\n                ims = []\n                txts = []\n                links = []\n\n                for label, image_numpy in visuals.items():\n                    img_path = \'epoch%.3d_%s.png\' % (n, label)\n                    ims.append(img_path)\n                    txts.append(label)\n                    links.append(img_path)\n                webpage.add_images(ims, txts, links, width=self.win_size)\n            webpage.save()\n\n    # errors: dictionary of error labels and values\n    def plot_current_errors(self, epoch, counter_ratio, opt, errors):\n        if not hasattr(self, \'plot_data\'):\n            self.plot_data = {\'X\': [], \'Y\': [], \'legend\': list(errors.keys())}\n        self.plot_data[\'X\'].append(epoch + counter_ratio)\n        self.plot_data[\'Y\'].append([errors[k] for k in self.plot_data[\'legend\']])\n        self.vis.line(\n            X=np.stack([np.array(self.plot_data[\'X\'])] * len(self.plot_data[\'legend\']), 1),\n            Y=np.array(self.plot_data[\'Y\']),\n            opts={\n                \'title\': self.name + \' loss over time\',\n                \'legend\': self.plot_data[\'legend\'],\n                \'xlabel\': \'epoch\',\n                \'ylabel\': \'loss\'},\n            win=self.display_id)\n\n    # errors: same format as |errors| of plotCurrentErrors\n    def print_current_errors(self, epoch, i, errors, t, t_data):\n        message = \'(epoch: %d, iters: %d, time: %.3f, data: %.3f) \' % (epoch, i, t, t_data)\n        for k, v in errors.items():\n            message += \'%s: %.3f \' % (k, v)\n\n        print(message)\n        with open(self.log_name, ""a"") as log_file:\n            log_file.write(\'%s\\n\' % message)\n\n    # save image to the disk\n    def save_images(self, webpage, visuals, image_path, aspect_ratio=1.0):\n        image_dir = webpage.get_image_dir()\n        short_path = ntpath.basename(image_path[0])\n        name = os.path.splitext(short_path)[0]\n\n        webpage.add_header(name)\n        ims = []\n        txts = []\n        links = []\n\n        for label, im in visuals.items():\n            image_name = \'%s_%s.png\' % (name, label)\n            save_path = os.path.join(image_dir, image_name)\n            h, w, _ = im.shape\n            if aspect_ratio > 1.0:\n                im = imresize(im, (h, int(w * aspect_ratio)), interp=\'bicubic\')\n            if aspect_ratio < 1.0:\n                im = imresize(im, (int(h / aspect_ratio), w), interp=\'bicubic\')\n            util.save_image(im, save_path)\n\n            ims.append(image_name)\n            txts.append(label)\n            links.append(image_name)\n        webpage.add_images(ims, txts, links, width=self.win_size)\n'"
old/fastai/models/cifar10/main_dxy.py,16,"b'from __future__ import division\n\nfrom senet import *\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--data_path\', default=\'./data\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', default=\'cifar10\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=64, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.05, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(0)\n\nif args.manualSeed is None: args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda: torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n  if not os.path.isdir(args.save_path): os.makedirs(args.save_path)\n  log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n  print_log(\'save path : {}\'.format(args.save_path), log)\n  state = {k: v for k, v in args._get_kwargs()}\n  print_log(state, log)\n  print_log(""Random Seed: {}"".format(args.manualSeed), log)\n  print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n  print_log(""torch  version : {}"".format(torch.__version__), log)\n  print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n\n  # Init dataset\n  if not os.path.isdir(args.data_path):\n    os.makedirs(args.data_path)\n\n  if args.dataset == \'cifar10\':\n    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n  elif args.dataset == \'cifar100\':\n    mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n    std = [x / 255 for x in [68.2, 65.4, 70.4]]\n  else:\n    assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n  train_transform = transforms.Compose(\n    [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n     transforms.Normalize(mean, std)])\n  test_transform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n  if args.dataset == \'cifar10\':\n    train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'cifar100\':\n    train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 100\n  elif args.dataset == \'svhn\':\n    train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'stl10\':\n    train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'imagenet\':\n    assert False, \'Do not finish imagenet code\'\n  else:\n    assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n  train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                         num_workers=args.workers, pin_memory=True)\n  test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                        num_workers=args.workers, pin_memory=True)\n\n  # Init model, criterion, and optimizer\n  #net = models.__dict__[args.arch](num_classes).cuda()\n  net = SENet34()\n\n  # define loss function (criterion) and optimizer\n  criterion = F.nll_loss\n  optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                weight_decay=state[\'decay\'], nesterov=True)\n\n  if args.use_cuda: net.cuda()\n\n  recorder = RecorderMeter(args.epochs)\n  # optionally resume from a checkpoint\n  if args.resume:\n    if os.path.isfile(args.resume):\n      print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n      checkpoint = torch.load(args.resume)\n      recorder = checkpoint[\'recorder\']\n      args.start_epoch = checkpoint[\'epoch\']\n      net.load_state_dict(checkpoint[\'state_dict\'])\n      optimizer.load_state_dict(checkpoint[\'optimizer\'])\n      print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n    else:\n      print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n  else:\n    print_log(""=> do not use any checkpoint for model"", log)\n\n  if args.evaluate:\n    validate(test_loader, net, criterion, log)\n    return\n\n  # Main loop\n  start_time = time.time()\n  epoch_time = AverageMeter()\n  for epoch in range(args.start_epoch, args.epochs):\n    current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n    need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n    print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n    # train for one epoch\n    train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n    # evaluate on validation set\n    val_acc,   val_los   = validate(test_loader, net, criterion, log)\n    is_best = recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n\n    save_checkpoint({\n      \'epoch\': epoch + 1,\n      \'state_dict\': net.state_dict(),\n      \'recorder\': recorder,\n      \'optimizer\' : optimizer.state_dict(),\n    }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    recorder.plot_curve( os.path.join(args.save_path, \'curve.png\') )\n\n  log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n  batch_time = AverageMeter()\n  data_time = AverageMeter()\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n  # switch to train mode\n  model.train()\n\n  end = time.time()\n  for i, (input, target) in enumerate(train_loader):\n    # measure data loading time\n    data_time.update(time.time() - end)\n\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input)\n    target_var = torch.autograd.Variable(target)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n    # compute gradient and do SGD step\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n  print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n        epoch, i, len(train_loader), batch_time=batch_time,\n        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n  return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n\n  # switch to evaluate mode\n  model.eval()\n\n  for i, (input, target) in enumerate(val_loader):\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input, volatile=True)\n    target_var = torch.autograd.Variable(target, volatile=True)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n  print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n  return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n  print(""{}"".format(print_string))\n  log.write(\'{}\\n\'.format(print_string))\n  log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n  filename = os.path.join(save_path, filename)\n  torch.save(state, filename)\n  if is_best:\n    bestname = os.path.join(save_path, \'model_best.pth.tar\')\n    shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n  """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n  lr = args.learning_rate\n  assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n  for (gamma, step) in zip(gammas, schedule):\n    if (epoch >= step):\n      lr = lr * gamma\n    else:\n      break\n  for param_group in optimizer.param_groups:\n    param_group[\'lr\'] = lr\n  return lr\n\ndef accuracy(output, target, topk=(1,)):\n  """"""Computes the precision@k for the specified values of k""""""\n  maxk = max(topk)\n  batch_size = target.size(0)\n\n  _, pred = output.topk(maxk, 1, True, True)\n  pred = pred.t()\n  correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n  res = []\n  for k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0)\n    res.append(correct_k.mul_(100.0 / batch_size))\n  return res\n\nif __name__ == \'__main__\':\n  main()\n'"
old/fastai/models/cifar10/main_kuangliu.py,15,"b""'''Train CIFAR10 with PyTorch.'''\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\n\nfrom senet import *\nfrom utils import progress_bar\nfrom torch.autograd import Variable\n\n\nparser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\nparser.add_argument('--lr', default=0.1, type=float, help='learning rate')\nparser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\nargs = parser.parse_args()\n\nuse_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(3)\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/ckpt.t7')\n    net = checkpoint['net']\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']\nelse:\n    print('==> Building model..')\n    # net = VGG('VGG19')\n    # net = ResNet18()\n    # net = PreActResNet18()\n    # net = GoogLeNet()\n    # net = DenseNet121()\n    # net = ResNeXt29_2x64d()\n    # net = MobileNet()\n    # net = DPN92()\n    # net = ShuffleNetG2()\n    net = SENet18()\n\nif use_cuda:\n    net.cuda()\n    #net = torch.nn.DataParallel(net, device_ids=(0,3))\n    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n    cudnn.benchmark = True\n\ncriterion = F.nll_loss\noptimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n\n# Training\ndef train(epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        optimizer.zero_grad()\n        inputs, targets = Variable(inputs), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n\n        test_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\n            'net': net,\n            'acc': acc,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt.t7')\n        best_acc = acc\n\n\nfor epoch in range(start_epoch, start_epoch+100):\n    train(epoch)\n    test(epoch)\n"""
old/fastai/models/cifar10/preact_resnet.py,3,"b""'''Pre-activation ResNet in PyTorch.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass PreActResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(PreActResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        return F.log_softmax(self.linear(out))\n\ndef PreActResNet18(): return PreActResNet(PreActBlock, [2,2,2,2])\ndef PreActResNet34(): return PreActResNet(PreActBlock, [3,4,6,3])\ndef PreActResNet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\ndef PreActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\ndef PreActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n\n"""
old/fastai/models/cifar10/resnext.py,3,"b'import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\nclass ResNeXtBottleneck(nn.Module):\n  expansion = 4\n  """"""\n  RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n  """"""\n  def __init__(self, inplanes, planes, cardinality, base_width, stride=1, downsample=None):\n    super(ResNeXtBottleneck, self).__init__()\n    self.downsample = downsample\n\n    D = int(math.floor(planes * (base_width/64.0)))\n    C = cardinality\n    self.conv_reduce = nn.Conv2d(inplanes, D*C, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_reduce = nn.BatchNorm2d(D*C)\n\n    self.conv_conv = nn.Conv2d(D*C, D*C, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n    self.bn = nn.BatchNorm2d(D*C)\n    self.conv_expand = nn.Conv2d(D*C, planes*4, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_expand = nn.BatchNorm2d(planes*4)\n\n  def forward(self, x):\n    residual = x\n\n    bottleneck = self.conv_reduce(x)\n    bottleneck = F.relu(self.bn_reduce(bottleneck), inplace=True)\n\n    bottleneck = self.conv_conv(bottleneck)\n    bottleneck = F.relu(self.bn(bottleneck), inplace=True)\n\n    bottleneck = self.conv_expand(bottleneck)\n    bottleneck = self.bn_expand(bottleneck)\n\n    if self.downsample is not None: residual = self.downsample(x)\n    return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n  """"""\n  ResNext optimized for the Cifar dataset, as specified in\n  https://arxiv.org/pdf/1611.05431.pdf\n  """"""\n  def __init__(self, block, depth, cardinality, base_width, num_classes):\n    super(CifarResNeXt, self).__init__()\n\n    # Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 9 == 0, \'depth should be one of 29, 38, 47, 56, 101\'\n    self.layer_blocks = (depth - 2) // 9\n\n    self.cardinality,self.base_width,self.num_classes,self.block = cardinality,base_width,num_classes,block\n\n    self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(64)\n\n    self.inplanes = 64\n    self.stage_1 = self._make_layer(64 , 1)\n    self.stage_2 = self._make_layer(128, 2)\n    self.stage_3 = self._make_layer(256, 2)\n    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n    self.classifier = nn.Linear(256*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, planes, stride=1):\n    downsample = None\n    exp_planes = planes * self.block.expansion\n    if stride != 1 or self.inplanes != exp_planes:\n      downsample = nn.Sequential(\n        nn.Conv2d(self.inplanes, exp_planes, kernel_size=1, stride=stride, bias=False),\n        nn.BatchNorm2d(exp_planes),\n      )\n\n    layers = []\n    layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width, stride, downsample))\n    self.inplanes = exp_planes\n    for i in range(1, self.layer_blocks):\n      layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return F.log_softmax(self.classifier(x))\n\ndef resnext29_16_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 16*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 16, 64, num_classes)\n  return model\n\ndef resnext29_8_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 8*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 8, 64, num_classes)\n  return model\n'"
old/fastai/models/cifar10/senet.py,3,"b""'''SENet in PyTorch.\n\nSENet is the winner of ImageNet-2017 (https://arxiv.org/abs/1709.01507).\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w  # New broadcasting feature from v0.2!\n\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w\n\n        out += shortcut\n        return out\n\n\nclass SENet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(SENet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        out = F.log_softmax(self.linear(out))\n        return out\n\n\ndef SENet18(): return SENet(PreActBlock, [2,2,2,2])\ndef SENet34(): return SENet(PreActBlock, [3,4,6,3])\n\n"""
old/fastai/models/cifar10/utils.py,0,"b'import os, sys, time\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n'"
old/fastai/models/cifar10/utils_kuangliu.py,5,"b""'''Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n'''\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\ndef get_mean_and_std(dataset):\n    '''Compute the mean and std value of dataset.'''\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print('==> Computing mean and std..')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    '''Init layer parameters.'''\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode='fan_out')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\n\n_, term_width = os.popen('stty size', 'r').read().split()\nterm_width = int(term_width)\n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f\n"""
old/fastai/models/cifar10/wideresnet.py,2,"b'# Cifar10 Wideresnet for Dawn Submission\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ...layers import *\n\ndef conv_2d(ni, nf, ks, stride): return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn(ni, init_zero=False):\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv_2d(ni, nf, ks, stride))\n\ndef noop(x): return x\n\nclass BasicBlock(nn.Module):\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        super().__init__()\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv_2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv_2d(ni, nf, 1, stride) if ni != nf else noop\n\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)\n        r = self.shortcut(x2)\n        x = self.conv1(x2)\n        if self.drop: x = self.drop(x)\n        x = self.conv2(x) * 0.2\n        return x.add_(r)\n\n\ndef _make_group(N, ni, nf, block, stride, drop_p):\n    return [block(ni if i == 0 else nf, nf, stride if i == 0 else 1, drop_p) for i in range(N)]\n\nclass WideResNet(nn.Module):\n    def __init__(self, num_groups, N, num_classes, k=1, drop_p=0.0, start_nf=16):\n        super().__init__()\n        n_channels = [start_nf]\n        for i in range(num_groups): n_channels.append(start_nf*(2**i)*k)\n\n        layers = [conv_2d(3, n_channels[0], 3, 1)]  # conv1\n        for i in range(num_groups):\n            layers += _make_group(N, n_channels[i], n_channels[i+1], BasicBlock, (1 if i==0 else 2), drop_p)\n\n        layers += [nn.BatchNorm2d(n_channels[3]), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),\n                   Flatten(), nn.Linear(n_channels[3], num_classes)]\n        self.features = nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef wrn_22(): return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.)\ndef wrn_22_k8(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.)\ndef wrn_22_k10(): return WideResNet(num_groups=3, N=3, num_classes=10, k=10, drop_p=0.)\ndef wrn_22_k8_p2(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.)\ndef wrn_28_k8(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.)\ndef wrn_28_k8_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.2)\n\n'"
