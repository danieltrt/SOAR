file_path,api_count,code
setup.py,0,"b'from setuptools import setup, find_packages\nfrom io import open\n\nsetup(\n    name=\'transfer_nlp\',\n    packages=find_packages(exclude=[""*.tests"", ""*.tests.*"",\n                                    ""tests.*"", ""tests""]),\n    version=\'0.1.6\',\n    license=\'MIT\',\n    description=\'NLP library designed for flexible research and development\',\n    long_description=open(""README.md"", ""r"", encoding=\'utf-8\').read(),\n    long_description_content_type=\'text/markdown\',\n    author=\'Peter Martigny\',\n    author_email=\'peter.martigny@gmail.com\',\n    url=\'https://github.com/feedly/transfer-nlp\',\n    download_url=\'https://github.com/feedly/transfer-nlp/archive/v0.1.6.tar.gz\',\n    keywords=[\'NLP\', \'transfer learning\', \'language models\', \'NLU\'],\n    install_requires=[\n        \'numpy>=1.16.2\',\n        \'pyaml>=19.4.1\',\n        \'toml>=0.10.0\'\n    ],\n    extras_require={\n        \'torch\': [\n            \'torch>=1.1.0\',\n            \'pytorch-ignite>=0.2.0\',\n        ]\n    },\n    classifiers=[\n        \'Development Status :: 3 - Alpha\',\n        \'Intended Audience :: Science/Research\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n        \'License :: OSI Approved :: MIT License\',\n        \'Programming Language :: Python :: 3.6\',\n    ],\n)\n'"
data/download.py,0,"b'#\n# CREDIT: https://stackoverflow.com/a/39225039\n#\n\nimport requests\n\ndef progress_bar(some_iter):\n    try:\n        from tqdm import tqdm\n        return tqdm(some_iter)\n    except ModuleNotFoundError:\n        return some_iter\n\ndef download_file_from_google_drive(id, destination):\n    print(""Trying to fetch {}"".format(destination))\n\n    def get_confirm_token(response):\n        for key, value in response.cookies.items():\n            if key.startswith(\'download_warning\'):\n                return value\n\n        return None\n\n    def save_response_content(response, destination):\n        CHUNK_SIZE = 32768\n\n        with open(destination, ""wb"") as f:\n            for chunk in progress_bar(response.iter_content(CHUNK_SIZE)):\n                if chunk: # filter out keep-alive new chunks\n                    f.write(chunk)\n\n    URL = ""https://docs.google.com/uc?export=download""\n\n    session = requests.Session()\n\n    response = session.get(URL, params={ \'id\' : id }, stream=True)\n    token = get_confirm_token(response)\n\n    if token:\n        params = { \'id\' : id, \'confirm\' : token }\n        response = session.get(URL, params=params, stream=True)\n\n    save_response_content(response, destination)\n\n\nif __name__ == ""__main__"":\n    import sys\n    if len(sys.argv) is not 3:\n        print(""Usage: python download.py drive_file_id destination_file_path"")\n    else:\n        # TAKE ID FROM SHAREABLE LINK\n        file_id = sys.argv[1]\n        # DESTINATION FILE ON YOUR DISK\n        destination = sys.argv[2]\n        download_file_from_google_drive(file_id, destination)\n'"
data/feedly_data.py,0,"b'""""""\nThis file aims at using the python wrapper around the Feedly API to build a dataset of articles given a feed name\nNote: You need a Feedly account and a token to use this script.\nVisit the Feedly API page to generate a token: https://developer.feedly.com/\n""""""\n\nimport os\nfrom pathlib import Path\nfrom random import shuffle\nfrom typing import List\n\nimport numpy as np\nimport pandas as pd\nimport urllib3\nfrom bs4 import BeautifulSoup\nfrom feedly.api_client.stream import StreamOptions\nfrom feedly.api_client.data import Entry\nfrom feedly.api_client.session import FeedlySession\n\nurllib3.disable_warnings()\n\n\ndef get_text(entry: Entry) -> BeautifulSoup:\n\n  full_content = entry.json[""fullContent""] if ""fullContent"" in entry.json else """"\n  content = entry.json[""content""][""content""] if ""content"" in entry.json else """"\n  summary = entry.json[""summary""][""content""] if ""summary"" in entry.json else """"\n  title = entry.json[""title""]\n  best = max(full_content, content, summary, title, key=len)\n\n  return BeautifulSoup(best.replace(""\\n"", """"), \'html.parser\').text\n\n\ndef build_dataframe(entries: List[Entry]) -> pd.DataFrame:\n\n    eid = [e.json.get(""id"") for e in entries]  # id of the entry\n    title = [e.json[""title""] for e in entries]  # title of the entry\n    content = [get_text(e) for e in entries]  # text content of the entry\n    data = {\n        \'eid\': eid,\n        \'title\': title,\n        \'content\': content}\n\n    return pd.DataFrame(data=data)\n\n\nclass FeedlyDownloader:\n\n    def __init__(self, token: str):\n\n        self.token = token\n        self.df: pd.DataFrame = None\n\n    def get_category_entries(self, category: str, max_count: int, account: str=\'enterprise\') -> List[Entry]:\n\n        with FeedlySession(auth=self.token) as sess:\n            if account == \'enterprise\':\n                feeds = sess.user.get_enterprise_categories()\n            elif account == \'personal\':\n                feeds = sess.user.get_categories()\n            else:\n                raise ValueError(""Only enterprise and personal account are taken into account"")\n            keep = None\n            for feed in feeds:\n                if feeds[feed].json[\'label\'] == category:\n                    keep = feeds[feed]\n            print(keep)\n            category_id = keep.stream_id.content_id\n            entries = []\n            if account == \'enterprise\':\n                entries = sess.user.get_enterprise_category(category_id).stream_contents(options=StreamOptions(max_count=max_count))\n            elif account == \'personal\':\n                entries = sess.user.get_category(category_id).stream_contents(options=StreamOptions(max_count=max_count))\n            else:\n                raise ValueError(""Only enterprise and personal account are taken into account"")\n            entries = list(entries)\n\n        return entries\n\n\n    def get_board_entries(self, board: str, max_count: int, account: str=\'enterprise\') -> List[Entry]:\n\n        with FeedlySession(auth=self.token) as sess:\n            if account == \'enterprise\':\n                feeds = sess.user.get_enterprise_tags()\n            elif account == \'personal\':\n                feeds = sess.user.get_tags()\n            else:\n                raise ValueError(""Only enterprise and personal account are taken into account"")\n            keep = None\n            for feed in feeds:\n                if feeds[feed].json[\'label\'] == board:\n                    keep = feeds[feed]\n            print(keep)\n            category_id = keep.stream_id.content_id\n            entries = []\n            if account == \'enterprise\':\n                entries = sess.user.get_enterprise_tag(category_id).stream_contents(options=StreamOptions(max_count=max_count))\n            elif account == \'personal\':\n                entries = sess.user.get_tag(category_id).stream_contents(options=StreamOptions(max_count=max_count))\n            else:\n                raise ValueError(""Only enterprise and personal account are taken into account"")\n            entries = list(entries)\n\n        return entries\n\n\n    def build_dataset(self, category: str, max_count: int, save_path: Path):\n\n        entries = self.get_category_entries(category=category, max_count=max_count)\n        shuffle(entries)\n        self.df = build_dataframe(entries)\n        limits = [int(0.8*len(entries)), int(0.1*len(entries))]\n        split = [\'train\'] * limits[0] + [\'val\'] * limits[1]\n        split.extend([\'test\'] * (len(entries) - len(split)))\n        self.df[\'split\'] = split\n        self.df[\'nationality\'] = [\'en\'] * len(entries)\n\n        self.df.to_csv(path_or_buf=save_path)\n\n    def build_multi_class_dataset(self, categories: List[str], max_count: int, save_path: Path):\n\n        entries = {category: self.get_category_entries(category=category, max_count=max_count, account=\'personal\') for category in categories}\n        [shuffle(entries[category]) for category in entries]\n        entries = {category: build_dataframe(entries[category]) for category in entries}\n        for category in entries:\n            entries[category][\'class\'] = category\n        df = pd.concat([entries[category] for category in entries])\n        np.random.shuffle(df.values)\n        limits = [int(0.8*len(df)), int(0.1*len(df))]\n        split = [\'train\'] * limits[0] + [\'val\'] * limits[1]\n        split.extend([\'test\'] * (len(df) - len(split)))\n        df[\'split\'] = split\n        self.df = df\n        self.df.to_csv(path_or_buf=save_path)\n\n    def build_like_board_dataset(self, category: str, boards: List[str], max_count: int, save_path: Path, name: str):\n\n        category_entries = self.get_category_entries(category=category, max_count=max_count)\n        shuffle(category_entries)\n        df_category = build_dataframe(entries=category_entries)\n        df_category[\'category\'] = [\'category\'] * len(category_entries)\n        boards_entries = []\n        for board in boards:\n            boards_entries.extend(self.get_board_entries(board=board, max_count=max_count))\n        shuffle(boards_entries)\n        df_boards = build_dataframe(entries=boards_entries)\n        df_boards[\'category\'] = [\'board\'] * len(df_boards)\n\n        for df in [df_category, df_boards]:\n            limits = [int(0.8 * len(df)), int(0.1 * len(df))]\n            split = [\'train\'] * limits[0] + [\'val\'] * limits[1]\n            split.extend([\'test\'] * (len(df) - len(split)))\n            df[\'split\'] = split\n\n        df = pd.concat([df_category, df_boards])\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n        df.to_csv(path_or_buf=save_path + name)\n\n\nif __name__ == ""__main__"":\n\n    token = ""YourToken""\n    downloader = FeedlyDownloader(token=token)\n\n    # # One category\n    # save_path = Path.home() / \'work/experiments/nlp/data\'\n    # category = \'YourFeed\'\n    # max_count = 10000\n    # save_path = save_path / \'feedly_data10000.csv\'\n    # downloader.build_dataset(category=category, max_count=max_count, save_path=save_path)\n    #\n    # #Multilingual\n    # token = ""YourToken""\n    # downloader = FeedlyDownloader(token=token)\n    # categories = [""Category1"", ""Category2""]\n    # max_count = 1000\n    # save_path = Path.home() / \'work/experiments/nlp/data/feedly_multilingual.csv\'\n    # downloader.build_multi_class_dataset(categories=categories, max_count=max_count, save_path=save_path)\n\n    # # One category, One board\n    # category = ""YourCategory""\n    # boards = [\'YourFirstBoard\', \'YourSecondBoard\']\n    # max_count = 100\n    # save_path = save_path / \'feedly_data_lb.csv\'\n    # downloader.build_dataset(category=category, boards=boards, max_count=max_count, save_path=save_path)\n'"
experiments/utils.py,2,"b'import ignite.metrics as metrics\nimport torch.nn as nn\nimport torch.optim as optim\n\nPLUGINS = {\n    \'CrossEntropyLoss\': nn.CrossEntropyLoss,\n    \'BCEWithLogitsLoss\': nn.BCEWithLogitsLoss,\n    ""Adam"": optim.Adam,\n    ""SGD"": optim.SGD,\n    ""AdaDelta"": optim.Adadelta,\n    ""AdaGrad"": optim.Adagrad,\n    ""SparseAdam"": optim.SparseAdam,\n    ""AdaMax"": optim.Adamax,\n    ""ASGD"": optim.ASGD,\n    ""LBFGS"": optim.LBFGS,\n    ""RMSPROP"": optim.RMSprop,\n    ""Rprop"": optim.Rprop,\n    ""ReduceLROnPlateau"": optim.lr_scheduler.ReduceLROnPlateau,\n    ""MultiStepLR"": optim.lr_scheduler.MultiStepLR,\n    ""ExponentialLR"": optim.lr_scheduler.ExponentialLR,\n    ""CosineAnnealingLR"": optim.lr_scheduler.CosineAnnealingLR,\n    ""LambdaLR"": optim.lr_scheduler.LambdaLR,\n    ""ReLU"": nn.functional.relu,\n    ""LeakyReLU"": nn.functional.leaky_relu,\n    ""Tanh"": nn.functional.tanh,\n    ""Softsign"": nn.functional.softsign,\n    ""Softshrink"": nn.functional.softshrink,\n    ""Softplus"": nn.functional.softplus,\n    ""Sigmoid"": nn.Sigmoid,\n    ""CELU"": nn.CELU,\n    ""SELU"": nn.functional.selu,\n    ""RReLU"": nn.functional.rrelu,\n    ""ReLU6"": nn.functional.relu6,\n    ""PReLU"": nn.functional.prelu,\n    ""LogSigmoid"": nn.functional.logsigmoid,\n    ""Hardtanh"": nn.functional.hardtanh,\n    ""Hardshrink"": nn.functional.hardshrink,\n    ""ELU"": nn.functional.elu,\n    ""Softmin"": nn.functional.softmin,\n    ""Softmax"": nn.functional.softmax,\n    ""LogSoftmax"": nn.functional.log_softmax,\n    ""GLU"": nn.functional.glu,\n    ""TanhShrink"": nn.functional.tanhshrink,\n    ""Accuracy"": metrics.Accuracy,\n}\n'"
transfer_nlp/__init__.py,0,"b'import logging\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    from transfer_nlp.plugins import metrics, regularizers, helpers, trainers\n    logger.debug(""Using trainers with Torch utilities"")\nexcept ImportError as e:\n    logger.debug(""Using trainers without Torch utilities"")\n'"
docs/source/conf.py,2,"b'# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nimport sphinx_rtd_theme\n\nsys.path.insert(0, os.path.abspath(\'.\'))\nsys.path.insert(0, os.path.abspath(\'../..\'))\n\nautodoc_mock_imports = [\'ignite\', \'ignite.metrics\', \'ignite.utils\', \'ignite.contrib.handlers.tqdm_logger\', \'ignite.engine\',\n                \'ignite.engine.engine\', \'ignite.contrib.handlers.tensorboard_logger\', \'torch\', \'torch.nn\', \'torch.optim\',\n                \'smart_open\', \'tensorboardX\', \'pandas\', \'numpy\', \'torch.utils.data\']\n\n# -- Project information -----------------------------------------------------\n\nproject = \'Transfer NLP\'\ncopyright = \'2019, Peter Martigny\'\nauthor = \'Peter Martigny\'\n\n# The full version, including alpha/beta/rc tags\nrelease = \'0.0.3\'\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\'sphinxcontrib.napoleon\']\n\nextensions = [\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.doctest\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.todo\',\n    \'sphinx.ext.coverage\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx.ext.viewcode\'\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\npygments_style = \'sphinx\'\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_theme_options = {\n    \'collapse_navigation\': False,\n    \'display_version\': True,\n    \'logo_only\': True,\n}\nhtml_logo = \'_static/TransferNLP_Logo.jpg \'\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\nhtml_context = {\n    \'css_files\': [\n        \'https://fonts.googleapis.com/css?family=Lato\',\n        \'_static/css/pytorch_theme.css\'\n    ],\n}\n'"
experiments/bert/bert.py,0,"b'import logging\nfrom pathlib import Path\nfrom typing import Tuple\n\nimport numpy as np\nimport pandas as pd\nfrom pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\nfrom tqdm import tqdm\n\nfrom transfer_nlp.loaders.loaders import DatasetSplits, DataFrameDataset\nfrom transfer_nlp.loaders.vectorizers import Vectorizer\nfrom transfer_nlp.loaders.vocabulary import Vocabulary\nfrom transfer_nlp.plugins.config import register_plugin, ExperimentConfig\n\ntqdm.pandas()\n\n\n@register_plugin\nclass BertVectorizer(Vectorizer):\n    def __init__(self, data_file: str, bert_version: str):\n        super().__init__(data_file=data_file)\n        self.tokenizer = BertTokenizer.from_pretrained(bert_version)\n        df = pd.read_csv(data_file)\n        self.target_vocab = Vocabulary(add_unk=False)\n        self.target_vocab.add_many(set(df.category))\n\n    def vectorize(self, title: str, max_seq_length: int) -> Tuple[np.array, np.array, np.array]:\n        tokens = [""[CLS]""] + self.tokenizer.tokenize(title) + [""[SEP]""]\n        token_type_ids, input_ids = [0] * len(tokens), self.tokenizer.convert_tokens_to_ids(tokens)\n        attention_mask, padding = [1] * len(input_ids), [0] * (max_seq_length - len(input_ids))\n        input_ids, attention_mask, token_type_ids = [x + padding for x in [input_ids, attention_mask, token_type_ids]]\n        return np.array(input_ids), np.array(attention_mask), np.array(token_type_ids)\n\n\n@register_plugin\nclass BertDataloader(DatasetSplits):\n\n    def __init__(self, data_file: str, batch_size: int, max_sequence: int, vectorizer: Vectorizer):\n        self.vectorizer: Vectorizer = vectorizer\n        self.max_sequence: int = max_sequence + 2\n        df = pd.read_csv(data_file)\n        df[[\'input_ids\', \'attention_mask\', \'token_type_ids\']] = df.progress_apply(\n            lambda row: pd.Series(self.vectorizer.vectorize(title=row[\'title\'], max_seq_length=self.max_sequence)), axis=1)\n        df[\'y_target\'] = df[\'category\'].progress_apply(lambda x: self.vectorizer.target_vocab.lookup_token(x))\n        train_df, val_df, test_df = (df[df.split == mode][[\'input_ids\', \'attention_mask\', \'token_type_ids\', \'y_target\']] for mode in [\'train\', \'val\', \'test\'])\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size, val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\n@register_plugin\ndef bert_model(pretrained_model_name_or_path: str = \'bert-base-uncased\', num_labels: int = 4):\n    return BertForSequenceClassification.from_pretrained(pretrained_model_name_or_path=pretrained_model_name_or_path, num_labels=num_labels)\n\n\nregister_plugin(BertAdam)\n\nif __name__ == ""__main__"":\n    logging.basicConfig(level=logging.INFO)\n    home_env = str(Path.home() / \'work/transfer-nlp-data\')\n    path = \'./bert.json\'\n    experiment = ExperimentConfig(path, HOME=home_env)\n    experiment.experiment[\'trainer\'].train()\n'"
experiments/bert/runner.py,0,"b'from experiments.bert.bert import *\nfrom transfer_nlp.plugins.config import ExperimentConfig\n\nfrom ..utils import PLUGINS\n\nlogger = logging.getLogger(__name__)\n\nfor plugin_name, plugin in PLUGINS.items():\n    register_plugin(registrable=plugin, alias=plugin_name)\n\nif __name__ == ""__main__"":\n    logging.basicConfig(level=logging.INFO)\n    home_env = str(Path.home() / \'work/transfer-nlp-data\')\n\n    path = \'./bert.json\'\n    experiment = ExperimentConfig(path, HOME=home_env)\n    experiment.experiment[\'trainer\'].train()\n'"
experiments/deep_learning_with_pytorch/cbow.py,11,"b'import logging\nfrom typing import Dict, List, Any\n\nimport numpy as np\nimport pandas as pd\nimport torch\n\nfrom transfer_nlp.common.tokenizers import CustomTokenizer\nfrom transfer_nlp.embeddings.embeddings import Embedding\nfrom transfer_nlp.loaders.loaders import DatasetSplits, DataFrameDataset\nfrom transfer_nlp.loaders.vectorizers import Vectorizer\nfrom transfer_nlp.loaders.vocabulary import CBOWVocabulary\nfrom transfer_nlp.plugins.config import register_plugin\nfrom transfer_nlp.plugins.predictors import PredictorABC\n\nlogger = logging.getLogger(__name__)\n\n\n# Vectorizer\n@register_plugin\nclass CBOWVectorizer(Vectorizer):\n\n    def __init__(self, data_file: str):\n\n        super().__init__(data_file=data_file)\n\n        self.tokenizer = CustomTokenizer()\n        df = pd.read_csv(data_file)\n\n        data_vocab = CBOWVocabulary()\n        max_context = 0\n        for index, row in df.iterrows():\n            tokens = self.tokenizer.tokenize(text=row.context)\n            max_context = max(max_context, len(tokens))\n            for token in tokens:\n                data_vocab.add_token(token)\n                data_vocab.add_token(row.target)\n        self.data_vocab = data_vocab\n        self.target_vocab = data_vocab\n        self.max_context = max_context\n\n    def vectorize(self, context: str) -> np.array:\n\n        tokens = self.tokenizer.tokenize(text=context)\n        indices = [self.data_vocab.lookup_token(token) for token in tokens]\n        vector_length = self.max_context\n\n        out_vector = np.zeros(vector_length, dtype=np.int64)\n        out_vector[:len(indices)] = indices\n        out_vector[len(indices):] = self.data_vocab.mask_index\n\n        return out_vector\n\n\n# Dataset\n@register_plugin\nclass CBOWDataset(DatasetSplits):\n\n    def __init__(self, data_file: str, batch_size: int, vectorizer: Vectorizer):\n        self.df = pd.read_csv(data_file)\n\n        # preprocessing\n        self.vectorizer: Vectorizer = vectorizer\n\n        self.df[\'x_in\'] = self.df.apply(lambda row: self.vectorizer.vectorize(row.context), axis=1)\n        self.df[\'y_target\'] = self.df.apply(lambda row: self.vectorizer.target_vocab.lookup_token(row.target), axis=1)\n\n        train_df = self.df[self.df.split == \'train\'][[\'x_in\', \'y_target\']]\n        val_df = self.df[self.df.split == \'val\'][[\'x_in\', \'y_target\']]\n        test_df = self.df[self.df.split == \'test\'][[\'x_in\', \'y_target\']]\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size,\n                         val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\n@register_plugin\nclass CBOWClassifier(torch.nn.Module):  # Simplified cbow Model\n\n    def __init__(self, data: DatasetSplits, embedding_size: int, glove_path: str = None, padding_idx: int = 0):\n        super(CBOWClassifier, self).__init__()\n        self.num_embeddings = len(data.vectorizer.data_vocab)\n        self.embedding_size = embedding_size\n        self.padding_idx = padding_idx\n\n        if glove_path:\n            logger.info(""Using pre-trained word embeddings..."")\n            self.embeddings = Embedding(glove_filepath=glove_path, data=data).embeddings\n            self.embeddings = torch.from_numpy(self.embeddings).float()\n            glove_size = len(self.embeddings[0])\n            self.embedding: torch.nn.Embedding = torch.nn.Embedding(embedding_dim=glove_size,\n                                                                    num_embeddings=self.num_embeddings,\n                                                                    padding_idx=self.padding_idx,\n                                                                    _weight=self.embeddings)\n\n        else:\n            logger.info(""Not using pre-trained word embeddings..."")\n            self.embedding: torch.nn.Embedding = torch.nn.Embedding(embedding_dim=self.embedding_size,\n                                                                    num_embeddings=self.num_embeddings,\n                                                                    padding_idx=self.padding_idx)\n\n        self.fc1 = torch.nn.Linear(in_features=embedding_size,\n                                   out_features=self.num_embeddings)\n        self.dropout = torch.nn.Dropout(p=0.3)\n\n    def forward(self, x_in: torch.Tensor) -> torch.Tensor:\n        """"""\n\n        :param x_in: input data tensor. x_in.shape should be (batch, input_dim)\n        :param apply_softmax: flag for the softmax activation\n                should be false if used with the Cross Entropy losses\n        :return: the resulting tensor. tensor.shape should be (batch, output_dim)\n        """"""\n\n        x_embedded_sum = self.dropout(self.embedding(x_in).sum(dim=1))\n        y_out = self.fc1(x_embedded_sum)\n\n        return y_out\n\n\n# Predictor\n@register_plugin\nclass CBOWPredictor(PredictorABC):\n    """"""\n    Toy example: we want to make predictions on inputs of the form {""inputs"": [""hello world"", ""foo"", ""bar""]}\n    """"""\n\n    def __init__(self, data: DatasetSplits, model: torch.nn.Module):\n        super().__init__(vectorizer=data.vectorizer, model=model)\n\n    def json_to_data(self, input_json: Dict) -> Dict:\n        return {\n            \'x_in\': torch.LongTensor([self.vectorizer.vectorize(context=input_string) for input_string in input_json[\'inputs\']])}\n\n    def output_to_json(self, outputs: List[Dict[str, Any]]) -> Dict[str, Any]:\n        return {\n            ""outputs"": outputs}\n\n    def decode(self, output: torch.tensor) -> List[Dict[str, Any]]:\n        probabilities = torch.nn.functional.softmax(output, dim=1)\n        probability_values, indices = probabilities.max(dim=1)\n\n        return [{\n            ""class"": self.vectorizer.data_vocab.lookup_index(index=int(res[1])),\n            ""probability"": float(res[0])} for res in zip(probability_values, indices)]\n'"
experiments/deep_learning_with_pytorch/mlp_parameter_tuning.py,1,"b'from datetime import datetime\nfrom pathlib import Path\n\nfrom smart_open import open\n\nfrom experiments.deep_learning_with_pytorch.surnames import *\nfrom transfer_nlp.plugins.config import register_plugin, ExperimentConfig\nfrom transfer_nlp.plugins.reporters import ReporterABC\nfrom transfer_nlp.runner.experiment_runner import ExperimentRunner\n\n\n@register_plugin\nclass MyReporter(ReporterABC):\n    def __init__(self):\n        self.reported = False\n\n    def report(self, name: str, experiment: ExperimentConfig, report_dir: Path):\n\n        with open(report_dir / \'metrics_report.txt\', \'w\') as reporting:\n            reporting.write(f""Metrics reporting for experiment {name}\\n"")\n            reporting.write(""#""*50 + \'\\n\')\n\n            for mode, metrics in experiment[\'trainer\'].metrics_history.items():\n                reporting.write(f""Reporting metrics in {mode} mode\\n"")\n                for metric, values in metrics.items():\n                    reporting.write(f""{metric}: [{\', \'.join([str(value) for value in values])}]\\n"")\n\n\nif __name__ == ""__main__"":\n    logging.basicConfig(level=logging.INFO)\n    parent_dir = Path(__file__).parent\n    home_env = str(Path.home() / \'work/transfer-nlp-data\')\n    date = \'_\'.join(str(datetime.today()).split(\' \'))\n\n    # # Uncomment to run the sequential Runner without caching read-only objects\n    # ExperimentRunner.run_all(experiment=parent_dir / \'mlp_parameter_tuning.json\',\n    #                          experiment_config=parent_dir / \'mlp_parameter_tuning.cfg\',\n    #                          report_dir=f""{home_env}/mlp_parameter_fine_tuning/{date}"",\n    #                          trainer_config_name=\'trainer\',\n    #                          reporter_config_name=\'reporter\', HOME=home_env)\n\n\n    # # Uncomment to run the sequential Runner with caching read-only objects\n    # ExperimentRunner.run_all(experiment=parent_dir / \'mlp_parameter_tuning_uncached.json\',\n    #                          experiment_config=parent_dir / \'mlp_parameter_tuning.cfg\',\n    #                          report_dir=f""{home_env}/mlp_parameter_fine_tuning/{date}"",\n    #                          trainer_config_name=\'trainer\',\n    #                          reporter_config_name=\'reporter\',\n    #                          experiment_cache=parent_dir / \'mlp_parameter_tuning_cache.json\',\n    #                          HOME=home_env)\n'"
experiments/deep_learning_with_pytorch/news.py,24,"b'import logging\nimport string\nfrom collections import Counter\nfrom typing import Dict, List, Any\n\nimport numpy as np\nimport pandas as pd\nimport torch\n\nfrom transfer_nlp.common.tokenizers import CustomTokenizer\nfrom transfer_nlp.embeddings.embeddings import Embedding\nfrom transfer_nlp.loaders.loaders import DatasetSplits, DataFrameDataset\nfrom transfer_nlp.loaders.vectorizers import Vectorizer\nfrom transfer_nlp.loaders.vocabulary import Vocabulary, SequenceVocabulary\nfrom transfer_nlp.plugins.config import register_plugin\nfrom transfer_nlp.plugins.predictors import PredictorABC\n\nlogger = logging.getLogger(__name__)\n\n\n# Vectorizer class\n@register_plugin\nclass NewsVectorizer(Vectorizer):\n    def __init__(self, data_file: str, cutoff: int):\n\n        super().__init__(data_file=data_file)\n        self.cutoff = cutoff\n\n        self.tokenizer = CustomTokenizer()\n        df = pd.read_csv(data_file)\n\n        target_vocab = Vocabulary(add_unk=False)\n        for category in sorted(set(df.category)):\n            target_vocab.add_token(category)\n\n        word_counts = Counter()\n        max_title = 0\n        for title in df.title:\n            tokens = self.tokenizer.tokenize(text=title)\n            max_title = max(max_title, len(tokens))\n            for token in tokens:\n                if token not in string.punctuation:\n                    word_counts[token] += 1\n\n        data_vocab = SequenceVocabulary()\n        for word, word_count in word_counts.items():\n            if word_count >= self.cutoff:\n                data_vocab.add_token(word)\n\n        self.data_vocab = data_vocab\n        self.target_vocab = target_vocab\n        self.max_title = max_title + 2\n\n    def vectorize(self, title: str) -> np.array:\n\n        tokens = self.tokenizer.tokenize(text=title)\n        indices = [self.data_vocab.begin_seq_index]\n        indices.extend(self.data_vocab.lookup_token(token)\n                       for token in tokens)\n        indices.append(self.data_vocab.end_seq_index)\n        vector_length = self.max_title\n\n        out_vector = np.zeros(vector_length, dtype=np.int64)\n        out_vector[:len(indices)] = indices\n        out_vector[len(indices):] = self.data_vocab.mask_index\n\n        return out_vector\n\n\n# Dataset class\n@register_plugin\nclass NewsDataset(DatasetSplits):\n\n    def __init__(self, data_file: str, batch_size: int, vectorizer: Vectorizer):\n        self.df = pd.read_csv(data_file)\n\n        # preprocessing\n        self.vectorizer: Vectorizer = vectorizer\n\n        self.df[\'x_in\'] = self.df.apply(lambda row: self.vectorizer.vectorize(row.title), axis=1)\n        self.df[\'y_target\'] = self.df.apply(lambda row: self.vectorizer.target_vocab.lookup_token(row.category), axis=1)\n\n        train_df = self.df[self.df.split == \'train\'][[\'x_in\', \'y_target\']]\n        val_df = self.df[self.df.split == \'val\'][[\'x_in\', \'y_target\']]\n        test_df = self.df[self.df.split == \'test\'][[\'x_in\', \'y_target\']]\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size,\n                         val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\n@register_plugin\nclass NewsClassifier(torch.nn.Module):\n\n    def __init__(self, data: DatasetSplits, embedding_size: int, num_channels: int,\n                 hidden_dim: int, dropout_p: float, padding_idx: int = 0, glove_path: str = None):\n        super(NewsClassifier, self).__init__()\n\n        self.num_embeddings = len(data.vectorizer.data_vocab)\n        self.num_classes = len(data.vectorizer.target_vocab)\n\n        self.num_channels: int = num_channels\n        self.embedding_size: int = embedding_size\n        self.hidden_dim: int = hidden_dim\n        self.padding_idx: int = padding_idx\n\n        if glove_path:\n            logger.info(""Using pre-trained word embeddings..."")\n            self.embeddings = Embedding(glove_filepath=glove_path, data=data).embeddings\n            self.embeddings = torch.from_numpy(self.embeddings).float()\n            glove_size = len(self.embeddings[0])\n            self.emb: torch.nn.Embedding = torch.nn.Embedding(embedding_dim=glove_size,\n                                                              num_embeddings=self.num_embeddings,\n                                                              padding_idx=self.padding_idx,\n                                                              _weight=self.embeddings)\n\n        else:\n            logger.info(""Not using pre-trained word embeddings..."")\n            self.emb: torch.nn.Embedding = torch.nn.Embedding(embedding_dim=self.embedding_size,\n                                                              num_embeddings=self.num_embeddings,\n                                                              padding_idx=self.padding_idx)\n\n        self.convnet = torch.nn.Sequential(\n            torch.nn.Conv1d(in_channels=self.embedding_size,\n                            out_channels=self.num_channels, kernel_size=3),\n            torch.nn.ELU(),\n            torch.nn.Conv1d(in_channels=self.num_channels, out_channels=self.num_channels,\n                            kernel_size=3, stride=2),\n            torch.nn.ELU(),\n            torch.nn.Conv1d(in_channels=self.num_channels, out_channels=self.num_channels,\n                            kernel_size=3, stride=1),\n            torch.nn.ELU(),\n            torch.nn.Conv1d(in_channels=self.num_channels, out_channels=self.num_channels,\n                            kernel_size=3),  # Experimental change from 3 to 2\n            torch.nn.ELU()\n        )\n\n        self._dropout_p: float = dropout_p\n        self.dropout = torch.nn.Dropout(p=dropout_p)\n        self.fc1: torch.nn.Linear = torch.nn.Linear(self.num_channels, self.hidden_dim)\n        self.fc2: torch.nn.Linear = torch.nn.Linear(self.hidden_dim, self.num_classes)\n\n    def forward(self, x_in: torch.Tensor, apply_softmax: bool = False) -> torch.Tensor:\n        """"""\n\n        :param x_in: input data tensor\n        :param apply_softmax: flag for the softmax activation\n                should be false if used with the Cross Entropy losses\n        :return: the resulting tensor. tensor.shape should be (batch, num_classes)\n        """"""\n\n        # embed and permute so features are channels\n        x_embedded = self.emb(x_in).permute(0, 2, 1)\n\n        features = self.convnet(x_embedded)\n\n        # average and remove the extra dimension\n        remaining_size = features.size(dim=2)\n        features = torch.nn.functional.avg_pool1d(features, remaining_size).squeeze(dim=2)\n        features = self.dropout(features)\n\n        # mlp classifier\n        intermediate_vector = torch.nn.functional.relu(self.dropout(self.fc1(features)))\n        prediction_vector = self.fc2(intermediate_vector)\n\n        if apply_softmax:\n            prediction_vector = torch.nn.functional.softmax(prediction_vector, dim=1)\n\n        return prediction_vector\n\n\n# Predictors\n@register_plugin\nclass NewsPredictor(PredictorABC):\n    """"""\n    Toy example: we want to make predictions on inputs of the form {""inputs"": [""hello world"", ""foo"", ""bar""]}\n    """"""\n\n    def __init__(self, data: DatasetSplits, model: torch.nn.Module):\n        super().__init__(vectorizer=data.vectorizer, model=model)\n\n    def json_to_data(self, input_json: Dict) -> Dict:\n        return {\n            \'x_in\': torch.LongTensor([self.vectorizer.vectorize(title=input_string) for input_string in input_json[\'inputs\']])}\n\n    def output_to_json(self, outputs: List[Dict[str, Any]]) -> Dict[str, Any]:\n        return {\n            ""outputs"": outputs}\n\n    def decode(self, output: torch.tensor) -> List[Dict[str, Any]]:\n        probabilities = torch.nn.functional.softmax(output, dim=1)\n        probability_values, indices = probabilities.max(dim=1)\n\n        return [{\n            ""class"": self.vectorizer.target_vocab.lookup_index(index=int(res[1])),\n            ""probability"": float(res[0])} for res in zip(probability_values, indices)]\n'"
experiments/deep_learning_with_pytorch/surnames.py,60,"b'import logging\nfrom typing import Any, Tuple, List, Dict\n\nimport numpy as np\nimport pandas as pd\nimport torch\n\nfrom transfer_nlp.common.tokenizers import CharacterTokenizer\nfrom transfer_nlp.loaders.loaders import DatasetSplits, DataFrameDataset\nfrom transfer_nlp.loaders.vectorizers import Vectorizer\nfrom transfer_nlp.loaders.vocabulary import Vocabulary, SequenceVocabulary\nfrom transfer_nlp.plugins.config import register_plugin\nfrom transfer_nlp.plugins.helpers import ObjectHyperParams\nfrom transfer_nlp.plugins.predictors import PredictorABC\n\nlogger = logging.getLogger(__name__)\n\n\n#### Surnames MLP ####\n@register_plugin\nclass SurnamesVectorizerMLP(Vectorizer):\n\n    def __init__(self, data_file: str):\n\n        super().__init__(data_file=data_file)\n        self.tokenizer = CharacterTokenizer()\n\n        df = pd.read_csv(data_file)\n        data_vocab = Vocabulary(unk_token=\'@\')\n        target_vocab = Vocabulary(add_unk=False)\n\n        # Add surnames and nationalities to vocabulary\n        for index, row in df.iterrows():\n            surname = row.surname\n            nationality = row.nationality\n            data_vocab.add_many(tokens=self.tokenizer.tokenize(text=surname))\n            target_vocab.add_token(token=nationality)\n\n        self.data_vocab = data_vocab\n        self.target_vocab = target_vocab\n\n    def vectorize(self, input_string: str) -> np.array:\n\n        encoding = np.zeros(shape=len(self.data_vocab), dtype=np.float32)\n        tokens = self.tokenizer.tokenize(text=input_string)\n        for character in tokens:\n            encoding[self.data_vocab.lookup_token(token=character)] = 1\n\n        return encoding\n\n\n@register_plugin\nclass SurnamesDatasetMLP(DatasetSplits):\n\n    def __init__(self, data_file: str, batch_size: int, vectorizer: Vectorizer):\n        self.df = pd.read_csv(data_file)\n\n        # preprocessing\n        self.vectorizer: Vectorizer = vectorizer\n\n        self.df[\'x_in\'] = self.df.apply(lambda row: self.vectorizer.vectorize(row.surname), axis=1)\n        self.df[\'y_target\'] = self.df.apply(lambda row: self.vectorizer.target_vocab.lookup_token(row.nationality), axis=1)\n\n        train_df = self.df[self.df.split == \'train\'][[\'x_in\', \'y_target\']]\n        val_df = self.df[self.df.split == \'val\'][[\'x_in\', \'y_target\']]\n        test_df = self.df[self.df.split == \'test\'][[\'x_in\', \'y_target\']]\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size,\n                         val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n@register_plugin\nclass MultiLayerPerceptron(torch.nn.Module):\n\n    def __init__(self, data: DatasetSplits, hidden_dim: int):\n        super(MultiLayerPerceptron, self).__init__()\n\n        self.input_dim = len(data.vectorizer.data_vocab)\n        self.hidden_dim = hidden_dim\n        self.output_dim = len(data.vectorizer.target_vocab)\n\n        self.fc = torch.nn.Linear(in_features=self.input_dim, out_features=hidden_dim)\n        self.fc2 = torch.nn.Linear(in_features=hidden_dim, out_features=self.output_dim)\n        # TODO: experiment with more layers\n\n    def forward(self, x_in: torch.Tensor, apply_softmax: bool = False) -> torch.Tensor:\n        """"""\n        Linear -> ReLu -> Linear (+ softmax if probabilities needed)\n        :param x_in: size (batch, input_dim)\n        :param apply_softmax: False if used with the cross entropy loss, True if probability wanted\n        :return:\n        """"""\n        # TODO: experiment with other activation functions\n\n        intermediate = torch.nn.functional.relu(self.fc(x_in))\n        output = self.fc2(intermediate)\n\n        if self.output_dim == 1:\n            output = output.squeeze()\n\n        if apply_softmax:\n            output = torch.nn.functional.softmax(output, dim=1)\n\n        return output\n\n\n@register_plugin\nclass MLPPredictor(PredictorABC):\n    """"""\n    Toy example: we want to make predictions on inputs of the form {""inputs"": [""hello world"", ""foo"", ""bar""]}\n    """"""\n\n    def __init__(self, data: DatasetSplits, model: torch.nn.Module):\n        super().__init__(vectorizer=data.vectorizer, model=model)\n\n    def json_to_data(self, input_json: Dict):\n        return {\n            \'x_in\': torch.tensor([self.vectorizer.vectorize(input_string=input_string) for input_string in input_json[\'inputs\']])}\n\n    def output_to_json(self, outputs: List) -> Dict[str, Any]:\n        return {\n            ""outputs"": outputs}\n\n    def decode(self, output: torch.tensor) -> List[Dict[str, Any]]:\n        probabilities = torch.nn.functional.softmax(output, dim=1)\n        probability_values, indices = probabilities.max(dim=1)\n        return [{\n            ""class"": self.vectorizer.target_vocab.lookup_index(index=int(res[1])),\n            ""probability"": float(res[0])} for res in zip(probability_values, indices)]\n\n\n#### Surnames CNN ####\n@register_plugin\nclass SurnamesVectorizerCNN(Vectorizer):\n\n    def __init__(self, data_file: str):\n\n        super().__init__(data_file=data_file)\n\n        self.tokenizer = CharacterTokenizer()\n        df = pd.read_csv(data_file)\n        data_vocab = Vocabulary(unk_token=\'@\')\n        target_vocab = Vocabulary(add_unk=False)\n        max_surname = 0\n\n        # Add surnames and nationalities to vocabulary\n        for index, row in df.iterrows():\n            surname = row.surname\n            nationality = row.nationality\n            data_vocab.add_many(tokens=self.tokenizer.tokenize(text=surname))\n            target_vocab.add_token(token=nationality)\n            max_surname = max(max_surname, len(surname))\n        self.data_vocab = data_vocab\n        self.target_vocab = target_vocab\n        self._max_surname = max_surname\n\n    def vectorize(self, input_string: str) -> np.array:\n\n        encoding = np.zeros(shape=(len(self.data_vocab), self._max_surname), dtype=np.float32)\n        tokens = self.tokenizer.tokenize(text=input_string)\n        for char_index, character in enumerate(tokens):\n            encoding[self.data_vocab.lookup_token(token=character)][char_index] = 1\n\n        return encoding\n\n\n@register_plugin\nclass SurnamesCNN(DatasetSplits):\n\n    def __init__(self, data_file: str, batch_size: int, vectorizer: Vectorizer):\n        self.df = pd.read_csv(data_file)\n\n        # preprocessing\n        self.vectorizer: Vectorizer = vectorizer\n\n        self.df[\'x_in\'] = self.df.apply(lambda row: self.vectorizer.vectorize(row.surname), axis=1)\n        self.df[\'y_target\'] = self.df.apply(lambda row: self.vectorizer.target_vocab.lookup_token(row.nationality), axis=1)\n\n        train_df = self.df[self.df.split == \'train\'][[\'x_in\', \'y_target\']]\n        val_df = self.df[self.df.split == \'val\'][[\'x_in\', \'y_target\']]\n        test_df = self.df[self.df.split == \'test\'][[\'x_in\', \'y_target\']]\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size,\n                         val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\n@register_plugin\nclass SurnameClassifierCNN(torch.nn.Module):\n\n    def __init__(self, data: DatasetSplits, num_channels: int):\n        super(SurnameClassifierCNN, self).__init__()\n\n        self.initial_num_channels = len(data.vectorizer.data_vocab)\n        self.num_classes = len(data.vectorizer.target_vocab)\n        self.num_channels: int = num_channels\n\n        self.convnet = torch.nn.Sequential(\n            torch.nn.Conv1d(in_channels=self.initial_num_channels,\n                            out_channels=self.num_channels, kernel_size=3),\n            torch.nn.ELU(),\n            torch.nn.Conv1d(in_channels=self.num_channels, out_channels=self.num_channels,\n                            kernel_size=3, stride=2),\n            torch.nn.ELU(),\n            torch.nn.Conv1d(in_channels=self.num_channels, out_channels=self.num_channels,\n                            kernel_size=3, stride=2),\n            torch.nn.ELU(),\n            torch.nn.Conv1d(in_channels=self.num_channels, out_channels=self.num_channels,\n                            kernel_size=3),\n            torch.nn.ELU()\n        )\n        self.fc = torch.nn.Linear(self.num_channels, self.num_classes)\n\n    def forward(self, x_in: torch.Tensor, apply_softmax: bool = False) -> torch.Tensor:\n        """"""\n        Conv -> ELU -> ELU -> Conv -> ELU -> Linear\n        :param x_in: size (batch, initial_num_channels, max_sequence)\n        :param apply_softmax: False if used with the cross entropy loss, True if probability wanted\n        :return:\n        """"""\n        features = self.convnet(x_in).squeeze(dim=2)\n\n        prediction_vector = self.fc(features)\n\n        if apply_softmax:\n            prediction_vector = torch.nn.functional.softmax(prediction_vector, dim=1)\n\n        return prediction_vector\n\n\n@register_plugin\nclass SurnameCNNPredictor(PredictorABC):\n    """"""\n    Toy example: we want to make predictions on inputs of the form {""inputs"": [""hello world"", ""foo"", ""bar""]}\n    """"""\n\n    def __init__(self, data: DatasetSplits, model: torch.nn.Module):\n        super().__init__(vectorizer=data.vectorizer, model=model)\n\n    def json_to_data(self, input_json: Dict) -> Dict:\n        return {\n            \'x_in\': torch.Tensor([self.vectorizer.vectorize(input_string=input_string) for input_string in input_json[\'inputs\']])}\n\n    def output_to_json(self, outputs: List[Dict[str, Any]]) -> Dict[str, Any]:\n        return {\n            ""outputs"": outputs}\n\n    def decode(self, output: torch.tensor) -> List[Dict[str, Any]]:\n        probabilities = torch.nn.functional.softmax(output, dim=1)\n        probability_values, indices = probabilities.max(dim=1)\n        return [{\n            ""class"": self.vectorizer.target_vocab.lookup_index(index=int(res[1])),\n            ""probability"": float(res[0])} for res in zip(probability_values, indices)]\n\n#### Surnames RNN ####\n@register_plugin\nclass SurnameVectorizerRNN(Vectorizer):\n\n    def __init__(self, data_file: str):\n        super().__init__(data_file=data_file)\n        self.tokenizer = CharacterTokenizer()\n        df = pd.read_csv(data_file)\n\n        data_vocab = SequenceVocabulary()\n        target_vocab = Vocabulary(add_unk=False)\n\n        max_surname = 0\n        for index, row in df.iterrows():\n            data_vocab.add_many(tokens=self.tokenizer.tokenize(text=row.surname))\n            target_vocab.add_token(row.nationality)\n            max_surname = max(max_surname, len(row.surname))\n\n        self.data_vocab = data_vocab\n        self.target_vocab = target_vocab\n        self._max_surname = max_surname + 2\n\n    def vectorize(self, surname: str) -> Tuple[np.array, int]:\n        tokens = self.tokenizer.tokenize(text=surname)\n        indices = [self.data_vocab.begin_seq_index]\n        indices.extend(self.data_vocab.lookup_token(token)\n                       for token in tokens)\n        indices.append(self.data_vocab.end_seq_index)\n        vector_length = self._max_surname\n\n        out_vector = np.zeros(vector_length, dtype=np.int64)\n        out_vector[:len(indices)] = indices\n        out_vector[len(indices):] = self.data_vocab.mask_index\n\n        return out_vector, len(indices)\n\n\n@register_plugin\nclass SurnamesRNNDataset(DatasetSplits):\n\n    def __init__(self, data_file: str, batch_size: int, vectorizer: Vectorizer):\n        self.df = pd.read_csv(data_file)\n\n        # preprocessing\n        self.vectorizer: Vectorizer = vectorizer\n\n        self.df[\'x_in\'] = self.df.apply(lambda row: self.vectorizer.vectorize(row.surname), axis=1)\n        self.df[\'x_lengths\'] = self.df.apply(lambda row: row.x_in[1], axis=1)\n        self.df[\'x_in\'] = self.df.apply(lambda row: row.x_in[0], axis=1)\n\n        self.df[\'y_target\'] = self.df.apply(lambda row: self.vectorizer.target_vocab.lookup_token(row.nationality), axis=1)\n\n        train_df = self.df[self.df.split == \'train\'][[\'x_in\', \'y_target\', \'x_lengths\']]\n        val_df = self.df[self.df.split == \'val\'][[\'x_in\', \'y_target\', \'x_lengths\']]\n        test_df = self.df[self.df.split == \'test\'][[\'x_in\', \'y_target\', \'x_lengths\']]\n\n        self.tokenizer = CharacterTokenizer()\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size,\n                         val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\ndef column_gather(y_out: torch.FloatTensor, x_lengths: torch.LongTensor) -> torch.FloatTensor:\n    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n\n    out = []\n    for batch_index, column_index in enumerate(x_lengths):\n        out.append(y_out[batch_index, column_index])\n\n    return torch.stack(out)\n\n\nclass ElmanRNN(torch.nn.Module):\n\n    def __init__(self, input_size: int, hidden_size: int, batch_first: bool = False):\n\n        super(ElmanRNN, self).__init__()\n\n        self.rnn_cell: torch.nn.RNNCell = torch.nn.RNNCell(input_size, hidden_size)\n\n        self.batch_first: bool = batch_first\n        self.hidden_size: int = hidden_size\n\n    def _initial_hidden(self, batch_size: int) -> torch.tensor:\n        return torch.zeros((batch_size, self.hidden_size))\n\n    def forward(self, x_in: torch.Tensor, initial_hidden: torch.Tensor = None) -> torch.Tensor:\n        """"""\n\n        :param x_in: an input data tensor.\n                If self.batch_first: x_in.shape = (batch, seq_size, feat_size)\n                Else: x_in.shape = (seq_size, batch, feat_size)\n        :param initial_hidden: the initial hidden state for the RNN\n        :return: The outputs of the RNN at each time step.\n                If self.batch_first: hiddens.shape = (batch, seq_size, hidden_size)\n                Else: hiddens.shape = (seq_size, batch, hidden_size)\n        """"""\n\n        if self.batch_first:\n            batch_size, seq_size, feat_size = x_in.size()\n            x_in = x_in.permute(1, 0, 2)\n        else:\n            seq_size, batch_size, feat_size = x_in.size()\n\n        hiddens = []\n\n        if initial_hidden is None:\n            initial_hidden = self._initial_hidden(batch_size)\n            initial_hidden = initial_hidden.to(x_in.device)\n\n        hidden_t = initial_hidden\n\n        for t in range(seq_size):\n            hidden_t = self.rnn_cell(x_in[t], hidden_t)\n            hiddens.append(hidden_t)\n\n        hiddens = torch.stack(hiddens)\n\n        if self.batch_first:\n            hiddens = hiddens.permute(1, 0, 2)\n\n        return hiddens\n\n\n@register_plugin\nclass SurnameClassifierRNN(torch.nn.Module):\n\n    def __init__(self, data: DatasetSplits, embedding_size: int,\n                 rnn_hidden_size: int, batch_first: bool = True, padding_idx: int = 0):\n\n        super(SurnameClassifierRNN, self).__init__()\n        self.num_embeddings = len(data.vectorizer.data_vocab)\n        self.num_classes = len(data.vectorizer.target_vocab)\n\n\n        self.emb: torch.nn.Embedding = torch.nn.Embedding(num_embeddings=self.num_embeddings,\n                                                          embedding_dim=embedding_size,\n                                                          padding_idx=padding_idx)\n        self.rnn: ElmanRNN = ElmanRNN(input_size=embedding_size,\n                                      hidden_size=rnn_hidden_size,\n                                      batch_first=batch_first)\n        self.fc1: torch.nn.Linear = torch.nn.Linear(in_features=rnn_hidden_size,\n                                                    out_features=rnn_hidden_size)\n        self.fc2: torch.nn.Linear = torch.nn.Linear(in_features=rnn_hidden_size,\n                                                    out_features=self.num_classes)\n        self.dropout = torch.nn.Dropout(p=0.5)\n\n    def forward(self, x_in: torch.Tensor, x_lengths: torch.Tensor = None, apply_softmax: bool = False) -> torch.Tensor:\n        """"""\n\n        :param x_in: an input data tensor.\n                 x_in.shape should be (batch, input_dim)\n        :param x_lengths: the lengths of each sequence in the batch.\n                 They are used to find the final vector of each sequence\n        :param apply_softmax: a flag for the softmax activation\n                 should be false if used with the Cross Entropy losses\n        :return: the resulting tensor. tensor.shape should be (batch, output_dim)\n        """"""\n\n        x_embedded = self.emb(x_in)\n        y_out = self.rnn(x_embedded)\n\n        if x_lengths is not None:\n            y_out = column_gather(y_out, x_lengths)\n        else:\n            y_out = y_out[:, -1, :]\n\n        y_out = torch.nn.functional.relu(self.fc1(self.dropout(y_out)))\n        y_out = self.fc2(self.dropout(y_out))\n\n        if apply_softmax:\n            y_out = torch.nn.functional.softmax(y_out, dim=1)\n\n        return y_out\n\n\n@register_plugin\nclass SurnameRNNPredictor(PredictorABC):\n    """"""\n    Toy example: we want to make predictions on inputs of the form {""inputs"": [""hello world"", ""foo"", ""bar""]}\n    """"""\n\n    def __init__(self, data: DatasetSplits, model: torch.nn.Module):\n        super().__init__(vectorizer=data.vectorizer, model=model)\n\n    def json_to_data(self, input_json: Dict) -> Dict:\n        # vector_length = 30\n\n        return {\n            \'x_in\': torch.LongTensor([self.vectorizer.vectorize(surname=input_string)[0] for input_string in input_json[\'inputs\']]),\n            \'x_lengths\': torch.Tensor([self.vectorizer.vectorize(surname=input_string)[1] for input_string in input_json[\'inputs\']])\n        }\n\n    def output_to_json(self, outputs: List[Dict[str, Any]]) -> Dict[str, Any]:\n        return {\n            ""outputs"": outputs}\n\n    def decode(self, output):\n        probabilities = torch.nn.functional.softmax(output, dim=1)\n        probability_values, indices = probabilities.max(dim=1)\n        return [{\n            ""class"": self.vectorizer.target_vocab.lookup_index(index=int(res[1])),\n            ""probability"": float(res[0])} for res in zip(probability_values, indices)]\n\n\n#### Surnames Generation ####\n@register_plugin\nclass SurnameVectorizerGeneration(Vectorizer):\n\n    def __init__(self, data_file: str):\n        super().__init__(data_file=data_file)\n        self.tokenizer = CharacterTokenizer()\n        df = pd.read_csv(data_file)\n\n        data_vocab = SequenceVocabulary()\n        target_vocab = Vocabulary(add_unk=False)\n\n        max_surname = 0\n        for index, row in df.iterrows():\n            tokens = self.tokenizer.tokenize(row.surname)\n            max_surname = max(max_surname, len(tokens))\n            data_vocab.add_many(tokens=tokens)\n            target_vocab.add_token(row.nationality)\n\n        self.data_vocab = data_vocab\n        self.target_vocab = target_vocab\n        self._max_surname = max_surname + 2\n\n    def vectorize(self, surname: str) -> Tuple[np.array, np.array]:\n        tokens = self.tokenizer.tokenize(text=surname)\n\n        indices = [self.data_vocab.begin_seq_index]\n        indices.extend(self.data_vocab.lookup_token(token)\n                       for token in tokens)\n        indices.append(self.data_vocab.end_seq_index)\n\n        vector_length = self._max_surname\n\n        from_vector = np.empty(shape=vector_length, dtype=np.int64)\n        from_indices = indices[:-1]\n        from_vector[:len(from_indices)] = from_indices\n        from_vector[len(from_indices):] = self.data_vocab.mask_index\n\n        to_vector = np.empty(shape=vector_length, dtype=np.int64)\n        to_indices = indices[1:]\n        to_vector[:len(to_indices)] = to_indices\n        to_vector[len(to_indices):] = self.data_vocab.mask_index\n\n        return from_vector, to_vector\n\n\n@register_plugin\nclass SurnameDatasetGeneration(DatasetSplits):\n\n    def __init__(self, data_file: str, batch_size: int, vectorizer: Vectorizer):\n        self.df = pd.read_csv(data_file)\n\n        # preprocessing\n        self.vectorizer: Vectorizer = vectorizer\n\n        self.df[\'x_in\'] = self.df.apply(lambda row: self.vectorizer.vectorize(row.surname), axis=1)\n        self.df[\'y_target\'] = self.df.apply(lambda row: row.x_in[1], axis=1)\n        self.df[\'x_in\'] = self.df.apply(lambda row: row.x_in[0], axis=1)\n\n        self.df[\'nationality_index\'] = self.df.apply(lambda row: self.vectorizer.target_vocab.lookup_token(row.nationality), axis=1)\n\n        train_df = self.df[self.df.split == \'train\'][[\'x_in\', \'y_target\', \'nationality_index\']]\n        val_df = self.df[self.df.split == \'val\'][[\'x_in\', \'y_target\', \'nationality_index\']]\n        test_df = self.df[self.df.split == \'test\'][[\'x_in\', \'y_target\', \'nationality_index\']]\n\n        self.tokenizer = CharacterTokenizer()\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size,\n                         val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\n@register_plugin\nclass SurnameConditionedGenerationModel(torch.nn.Module):\n\n    def __init__(self, data: DatasetSplits, char_embedding_size: int, rnn_hidden_size: int, batch_first: bool = True, padding_idx: int = 0,\n                 dropout_p: float = 0.5,\n                 conditioned: bool = False):\n\n        super(SurnameConditionedGenerationModel, self).__init__()\n        self.char_vocab_size = len(data.vectorizer.data_vocab)\n        self.num_nationalities = len(data.vectorizer.target_vocab)\n\n        self.char_emb: torch.nn.Embedding = torch.nn.Embedding(num_embeddings=self.char_vocab_size,\n                                                               embedding_dim=char_embedding_size,\n                                                               padding_idx=padding_idx)\n        self.nation_emb: torch.nn.Embedding = None\n        self.conditioned = conditioned\n        if self.conditioned:\n            self.nation_emb = torch.nn.Embedding(num_embeddings=self.num_nationalities,\n                                                 embedding_dim=rnn_hidden_size)\n        self.rnn: torch.nn.GRU = torch.nn.GRU(input_size=char_embedding_size,\n                                              hidden_size=rnn_hidden_size,\n                                              batch_first=batch_first)\n        self.fc: torch.nn.Linear = torch.nn.Linear(in_features=rnn_hidden_size,\n                                                   out_features=self.char_vocab_size)\n        self.dropout = torch.nn.Dropout(p=dropout_p)\n\n    def forward(self, x_in: torch.Tensor, nationality_index: int = 0, apply_softmax: bool = False) -> torch.Tensor:\n        """"""\n\n        :param x_in: input data tensor, x_in.shape should be (batch, max_seq_size)\n        :param nationality_index: The index of the nationality for each data point\n                Used to initialize the hidden state of the RNN\n        :param apply_softmax: flag for the softmax activation\n                should be false if used with the Cross Entropy losses\n        :return: the resulting tensor. tensor.shape should be (batch, char_vocab_size)\n        """"""\n\n        x_embedded = self.char_emb(x_in)\n        # hidden_size: (num_layers * num_directions, batch_size, rnn_hidden_size)\n        if self.conditioned:\n            nationality_embedded = self.nation_emb(nationality_index).unsqueeze(0)\n            y_out, _ = self.rnn(x_embedded, nationality_embedded)\n        else:\n            y_out, _ = self.rnn(x_embedded)\n\n        batch_size, seq_size, feat_size = y_out.shape\n        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n        y_out = self.fc(self.dropout(y_out))\n\n        if apply_softmax:\n            y_out = torch.nn.functional.softmax(y_out, dim=1)\n\n        new_feat_size = y_out.shape[-1]\n        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n\n        return y_out\n\n\n# Customization for loss and accuracy\ndef normalize_sizes(y_pred: torch.Tensor, y_true: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    """"""Normalize tensor sizes\n\n    Args:\n        y_pred (torch.Tensor): the output of the model\n            If a 3-dimensional tensor, reshapes to a matrix\n        y_true (torch.Tensor): the target predictions\n            If a matrix, reshapes to be a vector\n    """"""\n    if len(y_pred.size()) == 3:\n        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n    if len(y_true.size()) == 2:\n        y_true = y_true.contiguous().view(-1)\n    return y_pred, y_true\n\n\n@register_plugin\nclass OutputTransformSequence:\n    def __init__(self):\n        pass\n\n    def __call__(self, *args):\n\n        if len(args) == 3:\n            y_pred, y_target, loss = args\n            y_pred, y_target = normalize_sizes(y_pred=y_pred, y_true=y_target)\n\n            return y_pred, y_target, loss\n\n        elif len(args) == 2:\n            y_pred, y_target = args\n            y_pred, y_target = normalize_sizes(y_pred=y_pred, y_true=y_target)\n\n            return y_pred, y_target\n\n        else:\n            try:\n                y_pred, y_target = args[0]  # Not sure what\'s happening here but the validation mode outputs ((0, 1))\n                y_pred, y_target = normalize_sizes(y_pred=y_pred, y_true=y_target)\n\n                return y_pred, y_target\n            except Exception as e:\n                raise ValueError(e)\n\n\ndef sequence_loss(input, target, mask_index):\n    y_pred, y_true = normalize_sizes(y_pred=input, y_true=target)\n    return torch.nn.functional.cross_entropy(input=y_pred, target=y_true, ignore_index=mask_index)\n\n\n@register_plugin\nclass SequenceLossHyperParams(ObjectHyperParams):\n\n    def __init__(self, dataset_splits: DatasetSplits):\n        super().__init__()\n        self.mask_index = dataset_splits.vectorizer.data_vocab.mask_index\n\n\n@register_plugin\nclass SequenceLoss:\n\n    def __init__(self, loss_hyper_params: SequenceLossHyperParams):\n        self.mask_index = loss_hyper_params.mask_index\n\n    def __call__(self, *args, **kwargs):\n        return sequence_loss(*args, **kwargs, mask_index=self.mask_index)\n'"
experiments/deep_learning_with_pytorch/training.py,3,"b'from pathlib import Path\n\nfrom experiments.deep_learning_with_pytorch.surnames import *\nfrom experiments.deep_learning_with_pytorch.cbow import *\nfrom experiments.deep_learning_with_pytorch.news import *\nfrom transfer_nlp.plugins.config import ExperimentConfig\n\nfrom experiments.utils import PLUGINS\n\nlogger = logging.getLogger(__name__)\n\nfor plugin_name, plugin in PLUGINS.items():\n    register_plugin(registrable=plugin, alias=plugin_name)\n\nif __name__ == ""__main__"":\n    logging.basicConfig(level=logging.INFO)\n    home_env = str(Path.home() / \'work/transfer-nlp-data\')\n    surname_paths = [\'./deep_learning_with_pytorch/mlp.json\',\n                     \'./deep_learning_with_pytorch/surnamesRNN.json\',\n                     \'./deep_learning_with_pytorch/surnameClassifier.json\',\n                     \'./deep_learning_with_pytorch/surnamesGeneration.json\'\n                     ]\n    cbow_path = \'./deep_learning_with_pytorch/cbow.json\'\n    news_path = \'./deep_learning_with_pytorch/newsClassifier.json\'\n\n    for path in surname_paths:\n        logger.info(f""Launching test for experiment {path}"")\n        experiment = ExperimentConfig(path, HOME=home_env)\n        experiment[\'trainer\'].train()\n        if \'predictor\' in experiment:\n            input_json = {\n                ""inputs"": [""Zhang"",\n                           ""Mueller"", \'Mahmoud\', ""Rastapopoulos""]}\n            output_json = experiment[\'predictor\'].json_to_json(input_json=input_json)\n            logger.info(input_json)\n            logger.info(output_json)\n\n    logger.info(f""Launching test for experiment {cbow_path}"")\n    path = cbow_path\n    experiment = ExperimentConfig(path, HOME=home_env)\n    experiment[\'trainer\'].train()\n    input_json = {\n        ""inputs"": [""I go to and take notes""]}\n    output_json = experiment[\'predictor\'].json_to_json(input_json=input_json)\n    logger.info(input_json)\n    logger.info(output_json)\n\n    logger.info(f""Launching test for experiment {news_path}"")\n    path = news_path\n    experiment = ExperimentConfig(path, HOME=home_env)\n    experiment[\'trainer\'].train()\n    input_json = {\n        ""inputs"": [""Banking financing Asset Manager Gets OK To Appeal \xe2\x82\xac15M Fee Payout Ruling"",\n                   ""NASA\'s New Planet-Hunting Telescope Just Found Its First Earth-Sized World""]}\n    output_json = experiment[\'predictor\'].json_to_json(input_json=input_json)\n    logger.info(input_json)\n    logger.info(output_json)\n'"
experiments/transformers/dataset.py,4,"b'import random\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom pytorch_pretrained_bert import cached_path, BertTokenizer\n\nfrom transfer_nlp.loaders.loaders import DatasetSplits, DataFrameDataset\nfrom transfer_nlp.plugins.config import register_plugin\n\n\ndef load_data_lm():\n    dataset_file = cached_path(""https://s3.amazonaws.com/datasets.huggingface.co/wikitext-103/""\n                               ""wikitext-103-train-tokenized-bert.bin"")\n    datasets = torch.load(dataset_file)\n\n    # Convert our encoded dataset to torch.tensors and reshape in blocks of the transformer\'s input length\n    for split_name in [\'train\', \'valid\']:\n        tensor = torch.tensor(datasets[split_name], dtype=torch.long)\n        num_sequences = (tensor.size(0) // 256) * 256\n        datasets[split_name] = tensor.narrow(0, 0, num_sequences).view(-1, 256)\n\n    n = len(datasets[\'valid\']) // 2\n    datasets[\'test\'] = datasets[\'valid\'][n:]\n    datasets[\'valid\'] = datasets[\'valid\'][:n]\n    datasets[\'train\'] = datasets[\'train\'][:1000]\n    return datasets\n\n\ndef integerify(l):\n    return [x.numpy() for x in l]\n\n\n@register_plugin\nclass BertLMTuningDataset(DatasetSplits):\n\n    def __init__(self, batch_size: int):\n        datasets = load_data_lm()\n        self.data = datasets\n\n        train_df = pd.DataFrame(data={\n            ""x"": integerify(datasets[\'train\']),\n            ""y_target"": integerify(datasets[\'train\'])})\n        val_df = pd.DataFrame(data={\n            ""x"": integerify(datasets[\'valid\']),\n            ""y_target"": integerify(datasets[\'valid\'])})\n        test_df = pd.DataFrame(data={\n            ""x"": integerify(datasets[\'test\']),\n            ""y_target"": integerify(datasets[\'test\'])})\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size, val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\n@register_plugin\nclass BertCLFFinetuningDataset(DatasetSplits):\n\n    def __init__(self, batch_size: int):\n        dataset_file = cached_path(""https://s3.amazonaws.com/datasets.huggingface.co/trec/""\n                                   ""trec-tokenized-bert.bin"")\n        datasets = torch.load(dataset_file)\n        tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n\n        for split_name in [\'train\', \'test\']:\n            # Trim the samples to the transformer\'s input length minus 1 & add a classification token\n            datasets[split_name] = [x[:256 - 1] + [tokenizer.vocab[\'[CLS]\']]\n                                    for x in datasets[split_name]]\n\n            # Pad the dataset to max length\n            padding_length = max(len(x) for x in datasets[split_name])\n            datasets[split_name] = [np.array(x + [tokenizer.vocab[\'[PAD]\']] * (padding_length - len(x)))\n                                    for x in datasets[split_name]]\n\n        valid_size = int(0.1 * len(datasets[\'train\']))\n        c = list(zip(datasets[\'train\'], datasets[\'train_labels\']))\n        random.shuffle(c)\n        datasets[\'train\'], datasets[\'train_labels\'] = zip(*c)\n        datasets[\'train\'], datasets[\'train_labels\'] = list(datasets[\'train\']), list(datasets[\'train_labels\'])\n\n        datasets[\'valid\'], datasets[\'valid_labels\'] = datasets[\'train\'][:valid_size], datasets[\'train_labels\'][:valid_size]\n        datasets[\'train\'], datasets[\'train_labels\'] = datasets[\'train\'][valid_size:], datasets[\'train_labels\'][valid_size:]\n\n        train_df = pd.DataFrame(data={\n            ""x"": datasets[\'train\'],\n            ""y_target"": datasets[\'train_labels\']\n        })\n        val_df = pd.DataFrame(data={\n            ""x"": datasets[\'valid\'],\n            ""y_target"": datasets[\'valid_labels\']\n        })\n        test_df = pd.DataFrame(data={\n            ""x"": datasets[\'test\'],\n            ""y_target"": datasets[\'test_labels\']\n        })\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size, val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n'"
experiments/transformers/lm_tuner_runner.py,0,"b'import logging\nfrom pathlib import Path\n\nfrom experiments.transformers.model import *\nfrom transfer_nlp.plugins.config import ExperimentConfig\nfrom ..utils import PLUGINS\n\nlogger = logging.getLogger(__name__)\n\nfor plugin_name, plugin in PLUGINS.items():\n    register_plugin(registrable=plugin, alias=plugin_name)\n\nif __name__ == ""__main__"":\n    logging.basicConfig(level=logging.INFO)\n    home_env = str(Path.home() / \'work/transfer-nlp-data\')\n\n    # # Train a language model on large dataset\n    # experiment = ExperimentConfig(\'./lm_fine_tuning.json\', HOME=home_env)\n    # experiment.experiment[\'trainer\'].train()\n\n    # # Fine-tune the LM on a classification task\n    # experiment = ExperimentConfig(\'./lm_clf_fine_tuning.json\', HOME=home_env)\n    # experiment.experiment[\'trainer\'].train()\n\n    # # Fine-tune the LM on a classification task with an adapted Transformer\n    # # You can change the trainers param ""adaptation"" to experiment with several\n    # # adaptation schemes\n    # experiment = ExperimentConfig(\'./lm_clf_adaptation.json\', HOME=home_env)\n    # experiment.experiment[\'trainer\'].train()\n\n    # Train jointly the LM and the classifier, branched on the same\n    # transformer backbone\n    experiment = ExperimentConfig(\'./multitask.json\', HOME=home_env)\n    experiment.experiment[\'trainer\'].train()\n'"
experiments/transformers/model.py,47,"b'""""""\nThis file contains models presented in the Transfer Learning for NLP Tutorial at NAACL 2019\nModels are adapted from https://colab.research.google.com/drive/1iDHCYIrWswIKp-n-pOg69xLoZO09MEgf#scrollTo=_FfRT6GTjHhC&forceEdit=true&offline=true&sandboxMode=true\n\nThis is a WIP document and work is needed so that we don\'t have to replicate so many transformer classes\nIdeally we\'d like to have flexible transformer classes from which we can easily add\ntask-dependent heads and add adapter tools, e.g. freezing the backbone and add\nresidual connexion between layers. \n""""""\n\nimport torch\nfrom pytorch_pretrained_bert import BertTokenizer\n\nfrom transfer_nlp.plugins.config import register_plugin\n\n\n@register_plugin\nclass Transformer(torch.nn.Module):\n    def __init__(self, embed_dim: int, hidden_dim: int, num_embeddings: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float,\n                 causal: bool):\n        super().__init__()\n        self.causal: bool = causal\n        self.tokens_embeddings: torch.nn.Embedding = torch.nn.Embedding(num_embeddings, embed_dim)\n        self.position_embeddings: torch.nn.Embedding = torch.nn.Embedding(num_max_positions, embed_dim)\n        self.dropout: torch.nn.Dropout = torch.nn.Dropout(dropout)\n\n        self.attentions, self.feed_forwards = torch.nn.ModuleList(), torch.nn.ModuleList()\n        self.layer_norms_1, self.layer_norms_2 = torch.nn.ModuleList(), torch.nn.ModuleList()\n        for _ in range(num_layers):\n            self.attentions.append(torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout))\n            self.feed_forwards.append(torch.nn.Sequential(torch.nn.Linear(embed_dim, hidden_dim),\n                                                          torch.nn.ReLU(),\n                                                          torch.nn.Linear(hidden_dim, embed_dim)))\n            self.layer_norms_1.append(torch.nn.LayerNorm(embed_dim, eps=1e-12))\n            self.layer_norms_2.append(torch.nn.LayerNorm(embed_dim, eps=1e-12))\n\n        self.attn_mask = None\n        self.tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n\n    def forward(self, x):\n        """""" x has shape [batch, seq length]""""""\n\n        padding_mask = (x == self.tokenizer.vocab[\'[PAD]\'])\n\n        x = x.transpose(0, 1).contiguous()\n\n        positions = torch.arange(len(x), device=x.device).unsqueeze(-1)\n        h = self.tokens_embeddings(x)\n        h = h + self.position_embeddings(positions).expand_as(h)\n        h = self.dropout(h)\n\n        attn_mask = None\n        if self.causal:\n            attn_mask = torch.full((len(x), len(x)), -float(\'Inf\'), device=h.device, dtype=h.dtype)\n            attn_mask = torch.triu(attn_mask, diagonal=1)\n\n        for layer_norm_1, attention, layer_norm_2, feed_forward in zip(self.layer_norms_1, self.attentions,\n                                                                       self.layer_norms_2, self.feed_forwards):\n            h = layer_norm_1(h)\n            x, _ = attention(h, h, h, attn_mask=attn_mask, need_weights=False, key_padding_mask=padding_mask)\n            x = self.dropout(x)\n            h = x + h\n\n            h = layer_norm_2(h)\n            x = feed_forward(h)\n            x = self.dropout(x)\n            h = x + h\n        return h\n\n\n@register_plugin\nclass TransformerWithLMHead(torch.nn.Module):\n    def __init__(self, embed_dim: int, hidden_dim: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float, causal: bool,\n                 initializer_range: float):\n        """""" Transformer with a language modeling head on top (tied weights) """"""\n        super().__init__()\n        tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n        num_embeddings = len(tokenizer.vocab)\n        self.initializer_range = initializer_range\n        self.transformer = Transformer(embed_dim, hidden_dim, num_embeddings,\n                                       num_max_positions, num_heads, num_layers,\n                                       dropout, causal=causal)\n\n        self.lm_head = torch.nn.Linear(embed_dim, num_embeddings, bias=False)\n        self.apply(self.init_weights)\n        self.tie_weights()\n\n    def tie_weights(self):\n        self.lm_head.weight = self.transformer.tokens_embeddings.weight\n\n    def init_weights(self, module):\n        """""" initialize weights - nn.MultiheadAttention is already initalized by PyTorch (xavier) """"""\n        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm)):\n            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n        if isinstance(module, (torch.nn.Linear, torch.nn.LayerNorm)) and module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, x):\n        """""" x has shape [batch, seq length]""""""\n        hidden_states = self.transformer(x)\n        logits = self.lm_head(hidden_states)\n\n        return logits\n\n\n@register_plugin\nclass LMLoss:\n\n    def __init__(self, causal: bool):\n        self.causal: bool = causal\n\n    def __call__(self, input, target):\n        input = input.transpose(0, 1).contiguous()\n        shift_logits = input[:-1] if self.causal else input\n        shift_labels = target[1:] if self.causal else target\n        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n        return loss\n\n\n@register_plugin\nclass TransformerWithClfHead(torch.nn.Module):\n    def __init__(self,\n                 embed_dim: int, hidden_dim: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float, causal: bool,\n                 initializer_range: float, num_classes: int):\n        super().__init__()\n        self.tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n        num_embeddings = len(self.tokenizer.vocab)\n        self.initializer_range = initializer_range\n        self.transformer = Transformer(embed_dim, hidden_dim, num_embeddings,\n                                       num_max_positions, num_heads, num_layers,\n                                       dropout, causal=causal)\n\n        self.classification_head = torch.nn.Linear(embed_dim, num_classes)\n\n        self.apply(self.init_weights)\n\n    def init_weights(self, module):\n        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm)):\n            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n        if isinstance(module, (torch.nn.Linear, torch.nn.LayerNorm)) and module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, x):\n\n        # x = x.transpose(0, 1).contiguous().to(\'cpu\')\n        clf_tokens_mask = (x.transpose(0, 1).contiguous().to(\'cpu\') == self.tokenizer.vocab[\'[CLS]\'])\n\n        hidden_states = self.transformer(x)\n        msk = clf_tokens_mask.unsqueeze(-1).float()\n        clf_tokens_states = (hidden_states * msk).sum(dim=0)\n        clf_logits = self.classification_head(clf_tokens_states)\n\n        return clf_logits\n\n\n@register_plugin\nclass FineTuningLoss:\n\n    def __call__(self, input, target):\n        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        loss = loss_fct(input.view(-1, input.size(-1)), target.view(-1))\n        return loss\n\n\nclass TransformerWithAdapters(Transformer):\n    def __init__(self, adapters_dim, embed_dim, hidden_dim, num_embeddings, num_max_positions,\n                 num_heads, num_layers, dropout, causal):\n        """""" Transformer with adapters (small bottleneck layers) """"""\n        super().__init__(embed_dim, hidden_dim, num_embeddings, num_max_positions, num_heads, num_layers,\n                         dropout, causal)\n        self.adapters_1 = torch.nn.ModuleList()\n        self.adapters_2 = torch.nn.ModuleList()\n        for _ in range(num_layers):\n            self.adapters_1.append(torch.nn.Sequential(torch.nn.Linear(embed_dim, adapters_dim),\n                                                       torch.nn.ReLU(),\n                                                       torch.nn.Linear(adapters_dim, embed_dim)))\n\n            self.adapters_2.append(torch.nn.Sequential(torch.nn.Linear(embed_dim, adapters_dim),\n                                                       torch.nn.ReLU(),\n                                                       torch.nn.Linear(adapters_dim, embed_dim)))\n\n    def forward(self, x):\n        """""" x has shape [batch, seq length]""""""\n\n        padding_mask = (x == self.tokenizer.vocab[\'[PAD]\'])\n\n        x = x.transpose(0, 1).contiguous()\n\n        positions = torch.arange(len(x), device=x.device).unsqueeze(-1)\n        h = self.tokens_embeddings(x)\n        h = h + self.position_embeddings(positions).expand_as(h)\n        h = self.dropout(h)\n\n        attn_mask = None\n        if self.causal:\n            attn_mask = torch.full((len(x), len(x)), -float(\'Inf\'), device=h.device, dtype=h.dtype)\n            attn_mask = torch.triu(attn_mask, diagonal=1)\n\n        for (layer_norm_1, attention, adapter_1, layer_norm_2, feed_forward, adapter_2) \\\n                in zip(self.layer_norms_1, self.attentions, self.adapters_1,\n                       self.layer_norms_2, self.feed_forwards, self.adapters_2):\n            h = layer_norm_1(h)\n            x, _ = attention(h, h, h, attn_mask=attn_mask, need_weights=False, key_padding_mask=padding_mask)\n            x = self.dropout(x)\n\n            x = adapter_1(x) + x  # Add an adapter with a skip-connection after attention module\n\n            h = x + h\n\n            h = layer_norm_2(h)\n            x = feed_forward(h)\n            x = self.dropout(x)\n\n            x = adapter_2(x) + x  # Add an adapter with a skip-connection after feed-forward module\n\n            h = x + h\n        return h\n\n\n@register_plugin\nclass TransformerWithClfHeadAndAdapters(torch.nn.Module):\n    def __init__(self, adapters_dim: int,\n                 embed_dim: int, hidden_dim: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float, causal: bool,\n                 initializer_range: float, num_classes: int):\n        """""" Transformer with a classification head and adapters. """"""\n        super().__init__()\n        self.initializer_range: float = initializer_range\n        self.tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n        num_embeddings = len(self.tokenizer.vocab)\n        self.num_layers = num_layers\n        self.transformer: TransformerWithAdapters = TransformerWithAdapters(adapters_dim, embed_dim, hidden_dim, num_embeddings,\n                                       num_max_positions, num_heads, num_layers,\n                                       dropout, causal=causal)\n\n        self.classification_head = torch.nn.Linear(embed_dim, num_classes)\n        self.apply(self.init_weights)\n\n    def init_weights(self, module):\n        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm)):\n            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n        if isinstance(module, (torch.nn.Linear, torch.nn.LayerNorm)) and module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, x):\n\n        clf_tokens_mask = (x.transpose(0, 1).contiguous().to(\'cpu\') == self.tokenizer.vocab[\'[CLS]\'])\n        hidden_states = self.transformer(x)\n        clf_tokens_states = (hidden_states * clf_tokens_mask.unsqueeze(-1).float()).sum(dim=0)\n        clf_logits = self.classification_head(clf_tokens_states)\n\n        return clf_logits\n\n\n@register_plugin\nclass TransformerWithClfHeadAndLMHead(torch.nn.Module):\n    def __init__(self, embed_dim: int, hidden_dim: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float, causal: bool,\n                 initializer_range: float, num_classes: int):\n        super().__init__()\n        self.initializer_range: float = initializer_range\n        self.tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n        num_embeddings = len(self.tokenizer.vocab)\n        self.num_layers = num_layers\n        self.transformer = Transformer(embed_dim, hidden_dim, num_embeddings,\n                                       num_max_positions, num_heads, num_layers,\n                                       dropout, causal=causal)\n\n        self.lm_head = torch.nn.Linear(embed_dim, num_embeddings, bias=False)\n        self.classification_head = torch.nn.Linear(embed_dim, num_classes)\n\n        self.apply(self.init_weights)\n        self.tie_weights()\n\n    def tie_weights(self):\n        self.lm_head.weight = self.transformer.tokens_embeddings.weight\n\n    def init_weights(self, module):\n        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm)):\n            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n        if isinstance(module, (torch.nn.Linear, torch.nn.LayerNorm)) and module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, x):\n        """""" x and clf_tokens_mask have shape [seq length, batch] padding_mask has shape [batch, seq length] """"""\n        clf_tokens_mask = (x.transpose(0, 1).contiguous().to(\'cpu\') == self.tokenizer.vocab[\'[CLS]\'])\n        hidden_states = self.transformer(x)\n\n        lm_logits = self.lm_head(hidden_states)\n        clf_tokens_states = (hidden_states * clf_tokens_mask.unsqueeze(-1).float()).sum(dim=0)\n        clf_logits = self.classification_head(clf_tokens_states)\n\n        return lm_logits, clf_logits\n    \n@register_plugin\nclass MultiTaskLoss:\n    \n    def __init__(self, causal: bool):\n        self.causal: bool = causal\n\n    def __call__(self, lm_logits, clf_logits, lm_labels, clf_labels):\n        lm_logits = lm_logits.transpose(0, 1).contiguous()\n\n        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        loss_clf = loss_fct(clf_logits.view(-1, clf_logits.size(-1)), clf_labels.view(-1))\n\n        shift_logits = lm_logits[:-1] if self.causal else lm_logits\n        shift_labels = lm_labels[1:] if self.causal else lm_labels\n        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        loss_lm = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n\n        return loss_lm, loss_clf'"
tests/loaders/test_vocabulary.py,0,"b""import logging\nimport unittest\n\nfrom transfer_nlp.loaders.vocabulary import Vocabulary\n\n\nclass VocabularyTest(unittest.TestCase):\n\n    def test_vocabulary(self):\n        voc = Vocabulary()\n        self.assertEqual(first=voc.to_serializable(), second={\n            'token2id': {\n                '<UNK>': 0},\n            'add_unk': True,\n            'unk_token': '<UNK>'})\n\n        voc = Vocabulary()\n        token = 'Feedly'\n        voc.add_token(token=token)\n        self.assertEqual(first=voc.lookup_token(token=token), second=1)\n        self.assertEqual(first=voc.lookup_index(index=1), second=token)\n\n        voc = Vocabulary()\n        tokens = ['Feedly', 'NLP']\n        voc.add_many(tokens=tokens)\n        self.assertEqual(first=voc.lookup_token(token='Feedly'), second=1)\n        self.assertEqual(first=voc.lookup_index(index=1), second='Feedly')\n        self.assertEqual(first=voc.lookup_token(token='NLP'), second=2)\n        self.assertEqual(first=voc.lookup_index(index=2), second='NLP')\n        self.assertEqual(first=voc.to_serializable(), second={\n            'token2id': {\n                '<UNK>': 0,\n                'Feedly': 1,\n                'NLP': 2},\n            'add_unk': True,\n            'unk_token': '<UNK>'})\n\n        voc = Vocabulary.from_serializable(contents={\n            'token2id': {\n                '<UNK>': 0,\n                'Feedly': 1,\n                'NLP': 2},\n            'add_unk': True,\n            'unk_token': '<UNK>'})\n        self.assertEqual(first=voc.to_serializable(), second={\n            'token2id': {\n                '<UNK>': 0,\n                'Feedly': 1,\n                'NLP': 2},\n            'add_unk': True,\n            'unk_token': '<UNK>'})\n\n        self.assertEqual(first=len(voc), second=3)\n\n\nif __name__ == '__main__':\n    logging.basicConfig(level=logging.INFO)\n    unittest.main(exit=False)\n"""
tests/plugins/__init__.py,0,b''
tests/plugins/test_config.py,0,"b'import unittest\nfrom pathlib import Path\nfrom typing import Any, Dict, List\n\nfrom transfer_nlp.plugins.config import CallableInstantiationError, ExperimentConfig, LoopInConfigError, UnknownPluginException, UnknownReferenceError, register_plugin\n\n\n@register_plugin\nclass DemoWithVal:\n\n    def __init__(self, val: Any):\n        self.val = val\n\n\n@register_plugin\nclass DemoWithStr:\n\n    def __init__(self, strval: str):\n        self.strval = strval\n\n\n@register_plugin\ndef demo_method_with_str(str_val: str):\n    return DemoWithStr(strval=str_val)\n\n\n@register_plugin\nclass DemoWithInt:\n\n    def __init__(self, intval: str):\n        self.intval = intval\n\n\n@register_plugin\nclass DemoDefaults:\n\n    def __init__(self, strval: str, intval1: int = 5, intval2: int = None):\n        self.strval = strval\n        self.intval1 = intval1\n        self.intval2 = intval2\n\n\n@register_plugin\nclass DemoDefaultsList:\n\n    def __init__(self, strval: str, intval1: int = 5, intval2: int = None, param_list: List = [0]):\n        self.strval = strval\n        self.intval1 = intval1\n        self.intval2 = intval2\n        self.param_list = param_list\n\n\n@register_plugin\nclass DemoIsAvailable:\n\n    def __init__(self, is_available: bool = False):\n        self.is_available = is_available\n\n\n@register_plugin\nclass DemoComplexDefaults:\n\n    def __init__(self, strval: str, obj: DemoDefaults = None):  # use different param and property names as additonal check\n        self.simple = strval\n        self.complex = obj\n\n\n@register_plugin\nclass Demo:\n\n    def __init__(self, demo2, demo3):\n        self.demo2 = demo2\n        self.demo3 = demo3\n\n\n@register_plugin\nclass DemoWithConfig:\n\n    def __init__(self, demo2, intval: int):\n        self.demo2 = demo2\n        self.intval = intval\n\n\n@register_plugin\nclass DemoA:\n    def __init__(self, simple_int: int, attra: int = None):\n        self.simple_int = simple_int\n        self.attra = attra\n\n\n@register_plugin\nclass DemoB:\n\n    def __init__(self, demoa: DemoA, attrb: int = 2):\n        self.demoa = demoa\n        self.attrb = attrb\n\n\n@register_plugin\nclass DemoC:\n    def __init__(self, demob: DemoB, attrc: int = 3):\n        self.demob = demob\n        self.attrc = attrc\n\n\n@register_plugin\nclass DemoWithList:\n    def __init__(self, children: List[Any], simple_int: int = 3):\n        self.children = children\n        self.simple_int = simple_int\n\n\n@register_plugin\nclass DemoWithDict:\n    def __init__(self, children: Dict[str, Any], simple_int: int = 3):\n        self.children = children\n        self.simple_int = simple_int\n\n\n@register_plugin\nclass Pipeline:\n\n    def __init__(self, steps: List):\n        self.steps = steps\n\n\nclass DemoClassMethod:\n\n    def __init__(self, param: int):\n        self.param = param\n\n    @classmethod\n    def from_example(cls):\n        return cls(1)\n\n\nregister_plugin(DemoClassMethod.from_example, alias=\'from_example_alias_name\')\n\n\n@register_plugin\ndef mock_function():\n    return 5\n\n\n@register_plugin\ndef mock_function2():\n    return 2\n\n\n@register_plugin\nclass ClassWithUnInstantiatedObject:\n\n    def __init__(self, my_function):\n        self.my_function = my_function\n\n\nclass RegistryTest(unittest.TestCase):\n\n    def test_dict_of_registrables(self):\n\n        experiment = {\n            ""first_object"": {\n                ""_name"": ""DemoWithVal"",\n                ""val"": 2\n            },\n            ""dict_of_objects"": {\n\n                ""first_object"":\n                    {\n                        ""_name"": ""DemoWithVal"",\n                        ""val"": 1\n                    },\n                ""second_object"":\n                    {\n                        ""_name"": ""DemoWithStr"",\n                        ""strval"": ""foo""\n                    },\n                ""simple_object"": 1,\n                ""last_object"": ""$first_object""\n\n            }\n        }\n\n        e = ExperimentConfig(experiment)\n        self.assertEqual(e[\'dict_of_objects\'][\'first_object\'].val, 1)\n        self.assertEqual(e[\'dict_of_objects\'][\'second_object\'].strval, \'foo\')\n        self.assertEqual(e[\'dict_of_objects\'][\'simple_object\'], 1)\n        self.assertEqual(e[\'dict_of_objects\'][\'last_object\'].val, 2)\n\n    def test_list_of_registrables(self):\n        experiment = {\n            ""first_object"": {\n                ""_name"": ""DemoWithVal"",\n                ""val"": 2\n            },\n            ""list_of_objects"": [\n                {\n                    ""_name"": ""DemoWithVal"",\n                    ""val"": 1\n                },\n                {\n                    ""_name"": ""DemoWithStr"",\n                    ""strval"": ""foo""\n                },\n                4,\n                ""$first_object"",\n                ""feedly"",\n                ""$mock_function"",\n                ""$mock_function2""\n            ]\n        }\n\n        e = ExperimentConfig(experiment)\n        self.assertEqual(len(e[\'list_of_objects\']), 7)\n        self.assertEqual(e[\'list_of_objects\'][0].val, 1)\n        self.assertEqual(e[\'list_of_objects\'][1].strval, ""foo"")\n        self.assertEqual(e[\'list_of_objects\'][2], 4)\n        self.assertIsInstance(e[\'list_of_objects\'][3], DemoWithVal)\n        self.assertEqual(e[\'list_of_objects\'][3].val, 2)\n        self.assertEqual(e[\'list_of_objects\'][4], \'feedly\')\n        self.assertEqual(e[\'list_of_objects\'][5](), 5)\n        self.assertEqual(e[\'list_of_objects\'][6](), 2)\n\n    def test_all_string_with_dollars(self):\n\n        experiment = {\n            ""first_object"": {\n                ""_name"": ""DemoWithVal"",\n                ""val"": 2\n            },\n            ""list_of_objects"": [\n                ""$mock_function"",\n                ""$mock_function2"",\n                ""$first_object""\n            ]\n        }\n        e = ExperimentConfig(experiment)\n        self.assertEqual(len(e[\'list_of_objects\']), 3)\n        self.assertEqual(e[\'list_of_objects\'][0](), 5)\n        self.assertEqual(e[\'list_of_objects\'][1](), 2)\n        self.assertEqual(e[\'list_of_objects\'][2].val, 2)\n\n    def test_uninstantiated_registrable(self):\n\n        experiment = {\n            ""my_registrable"": {\n                ""_name"": ""ClassWithUnInstantiatedObject"",\n                ""my_function"": ""$mock_function""\n            }\n        }\n        e = ExperimentConfig(experiment)\n        self.assertEqual(e[\'my_registrable\'].my_function, mock_function)\n        self.assertEqual(e[\'my_registrable\'].my_function(), 5)\n\n    def test_class_method(self):\n\n        experiment = {\n            ""my_object"": {\n                ""_name"": ""from_example_alias_name""\n            }\n        }\n        e = ExperimentConfig(experiment)\n        self.assertEqual(e[\'my_object\'].param, 1)\n\n    def test_recursive_definition(self):\n        experiment = {\n            \'demo\': {\n                \'_name\': \'Demo\',\n                \'demo2\': {\n                    \'_name\': \'DemoWithStr\',\n                    \'strval\': \'foo\'\n                },\n                \'demo3\': {\n                    \'_name\': \'DemoWithInt\',\n                    \'intval\': 2\n                }\n            }\n        }\n        e = ExperimentConfig(experiment)\n        self.assertIsInstance(e.experiment[\'demo\'].demo2, DemoWithStr)\n        self.assertIsInstance(e.experiment[\'demo\'].demo3, DemoWithInt)\n        self.assertEqual(e.experiment[\'demo\'].demo2.strval, \'foo\')\n        self.assertEqual(e.experiment[\'demo\'].demo3.intval, 2)\n\n    def test_child_injection(self):\n        experiment = {\n            \'demo\': {\n                \'_name\': \'Demo\',\n                \'demo2\': \'$demo2\',\n                \'demo3\': \'$demo3\'\n            },\n            \'demo2\': {\n                \'_name\': \'DemoWithStr\',\n                \'strval\': \'$strval\'\n            },\n            \'demo3\': {\n                \'_name\': \'DemoWithInt\',\n                \'intval\': \'$intval\'\n            },\n            \'strval\': \'dummy\',\n            \'intval\': 5\n        }\n        e = ExperimentConfig(experiment)\n\n        self.assertTrue(isinstance(e[\'demo\'], Demo))\n        self.assertTrue(isinstance(e[\'demo2\'], DemoWithStr))\n        self.assertTrue(isinstance(e[\'demo3\'], DemoWithInt))\n\n        self.assertEqual(e[\'demo2\'].strval, \'dummy\')\n        self.assertEqual(e[\'demo3\'].intval, 5)\n\n    def test_child_named_injection(self):\n        experiment = {\n            \'demo\': {\n                \'_name\': \'Demo\',\n                \'demo3\': \'$demo3a\',\n                \'demo2\': \'$demo2\'\n\n            },\n            \'demo2\': {\n                \'_name\': \'DemoWithStr\',\n                \'strval\': \'$strval\'\n            },\n            \'demo3\': {\n                \'_name\': \'DemoWithInt\',\n                \'intval\': \'$intval\'\n            },\n            \'demo3a\': {\n                \'_name\': \'DemoWithInt\',\n                \'intval\': \'$simple_inta\'\n            },\n            \'strval\': \'dummy\',\n            \'intval\': 5,\n            \'simple_inta\': 6,\n        }\n        e = ExperimentConfig(experiment)\n\n        self.assertTrue(isinstance(e[\'demo\'], Demo))\n        self.assertTrue(isinstance(e[\'demo2\'], DemoWithStr))\n        self.assertTrue(isinstance(e[\'demo3\'], DemoWithInt))\n        self.assertTrue(isinstance(e[\'demo3a\'], DemoWithInt))\n\n        self.assertEqual(e[\'demo2\'].strval, \'dummy\')\n        self.assertEqual(e[\'demo3\'].intval, 5)\n        self.assertEqual(e[\'demo3a\'].intval, 6)\n        self.assertEqual(e[\'demo\'].demo3.intval, 6)\n\n    def test_env(self):\n        experiment = {\n            \'path\': ""$HOME/foo/bar"",\n            \'path2\': ""$HOMEPATH/foo/bar"",\n            \'data\': {\n                \'_name\': ""DemoWithStr"",\n                \'strval\': ""$HOME/foo/bar/bis""\n            },\n            \'data2\': {\n                \'_name\': ""DemoDefaults"",\n                \'strval\': ""foo"",\n                \'intval1\': ""$SVAL""\n            }\n        }\n        e = ExperimentConfig(experiment, HOME=\'/tmp\', HOMEPATH=Path(\'/tmp2\'), SVAL=7)\n        self.assertEqual(e[\'path\'], \'/tmp/foo/bar\')\n        self.assertEqual(e[\'path2\'], \'/tmp2/foo/bar\')\n\n        self.assertEqual(e[\'data\'].strval, \'/tmp/foo/bar/bis\')\n\n        self.assertEqual(e[\'data2\'].strval, \'foo\')\n        self.assertEqual(e[\'data2\'].intval1, 7)\n        self.assertIsNone(e[\'data2\'].intval2)\n\n        experiment = {\n            \'path\': ""$HOME/foo/bar"",\n            \'path2\': ""$HOMEPATH/foo/bar"",\n            \'data\': {\n                \'_name\': ""DemoWithStr"",\n                \'strval\': ""$HOME/foo/bar/bis""\n            },\n            \'data2\': {\n                \'_name\': ""DemoDefaultsList"",\n                \'strval\': ""foo"",\n                \'intval1\': ""$SVAL"",\n                \'param_list\': [\n                    {\n                        ""_name"": ""DemoIsAvailable"",\n                        ""is_available"": ""$HOME""},\n                    {\n                        ""_name"": ""DemoIsAvailable"",\n                        ""is_available"": ""$VAL""},\n                    ""$HOMEPATH""\n                ]\n            }\n        }\n        e = ExperimentConfig(experiment, HOME=\'/tmp\', HOMEPATH=Path(\'/tmp2\'), SVAL=7, VAL=True)\n        self.assertEqual(e[\'data2\'].param_list[0].is_available, \'/tmp\')\n        self.assertEqual(e[\'data2\'].param_list[1].is_available, True)\n        self.assertEqual(e[\'data2\'].param_list[2], Path(\'/tmp2\'))\n\n    def test_literal_injection(self):\n        experiment = {\n            \'demo2\': {\n                \'_name\': \'DemoWithStr\',\n                \'strval\': \'dummy\'\n            },\n            \'demo3\': {\n                \'_name\': \'DemoWithInt\',\n                \'intval\': 5\n            }\n        }\n        e = ExperimentConfig(experiment)\n\n        self.assertTrue(isinstance(e[\'demo2\'], DemoWithStr))\n        self.assertTrue(isinstance(e[\'demo3\'], DemoWithInt))\n\n        self.assertEqual(e[\'demo2\'].strval, \'dummy\')\n        self.assertEqual(e[\'demo3\'].intval, 5)\n\n    def test_unconfigured(self):\n        experiment = {\n            \'demo\': {\n                \'_name\': \'Demo\',\n            },\n            \'demo2\': {\n                \'_name\': \'DemoWithStr\',\n            },\n            \'demo3\': {\n                \'_name\': \'DemoWithInt\',\n            }\n        }\n\n        with self.assertRaises(CallableInstantiationError) as cm:\n            ExperimentConfig(experiment)\n\n        self.assertEqual(cm.exception.obj_name, \'demo\')\n        self.assertEqual(cm.exception.callable_name, \'Demo\')\n        self.assertListEqual(cm.exception.arg_names, [])\n\n    def test_defaults(self):\n        experiment = {\n            \'demoa\': {\n                \'_name\': \'DemoDefaults\',\n                \'strval\': \'a\',\n            },\n            \'demob\': {\n                \'_name\': \'DemoDefaults\',\n                \'strval\': \'b\',\n                \'intval1\': 1\n            },\n            \'democ\': {\n                \'_name\': \'DemoDefaults\',\n                \'strval\': \'c\',\n                \'intval2\': 2\n            },\n            \'demod\': {\n                \'_name\': \'DemoDefaults\',\n                \'strval\': \'d\',\n                \'intval1\': 3,\n                \'intval2\': 4\n            },\n            \'demoe\': {\n                \'_name\': \'DemoDefaults\',\n                \'strval\': \'e\',\n                \'intval1\': None,\n                \'intval2\': None\n            },\n        }\n        e = ExperimentConfig(experiment)\n\n        for c in \'abcde\':\n            self.assertTrue(isinstance(e[f\'demo{c}\'], DemoDefaults))\n            self.assertEqual(e[f\'demo{c}\'].strval, c)\n\n        self.assertEqual(e[\'demoa\'].intval1, 5)\n        self.assertEqual(e[\'demoa\'].intval2, None)\n\n        self.assertEqual(e[\'demob\'].intval1, 1)\n        self.assertEqual(e[\'demob\'].intval2, None)\n\n        self.assertEqual(e[\'democ\'].intval1, 5)\n        self.assertEqual(e[\'democ\'].intval2, 2)\n\n        self.assertEqual(e[\'demod\'].intval1, 3)\n        self.assertEqual(e[\'demod\'].intval2, 4)\n\n        self.assertEqual(e[\'demoe\'].intval1, None)\n        self.assertEqual(e[\'demoe\'].intval2, None)\n\n    def test_complex_defaults(self):\n        ### test that demod gets created first and then is used to create demo instead of the None default\n        experiment = {\n            \'demo\': {\n                \'_name\': \'DemoComplexDefaults\',\n                \'strval\': \'foo\',\n                \'obj\': \'$obj\'\n            },\n            \'obj\': {\n                \'_name\': \'DemoDefaults\',\n                \'strval\': \'bar\',\n                \'intval1\': 20\n            }\n        }\n        e = ExperimentConfig(experiment)\n\n        self.assertTrue(isinstance(e[\'demo\'], DemoComplexDefaults))\n        self.assertTrue(isinstance(e[\'obj\'], DemoDefaults))\n\n        self.assertEqual(e[\'obj\'].strval, \'bar\')\n        self.assertEqual(e[\'obj\'].intval1, 20)\n        self.assertEqual(e[\'obj\'].intval2, None)\n\n        self.assertEqual(e[\'demo\'].simple, \'foo\')\n        self.assertEqual(e[\'demo\'].complex.strval, \'bar\')\n        self.assertEqual(e[\'demo\'].complex.intval1, 20)\n        self.assertEqual(e[\'demo\'].complex.intval2, None)\n\n    def test_unordered_nested_config(self):\n        experiment = {\n            \'democ\': {\n                \'_name\': \'DemoC\',\n                \'demob\': \'$demob\'\n            },\n            \'demob\': {\n                \'_name\': \'DemoB\',\n                \'demoa\': \'$demoa\'\n            },\n            \'demoa\': {\n                \'_name\': \'DemoA\',\n                \'simple_int\': \'$simple_int\'\n            },\n            \'simple_int\': 2\n        }\n\n        e = ExperimentConfig(experiment)\n        self.assertEqual(e[\'demoa\'].simple_int, 2)\n        self.assertEqual(e[\'demoa\'].attra, None)\n        self.assertIsInstance(e[\'demob\'].demoa, DemoA)\n        self.assertIsInstance(e[\'democ\'].demob, DemoB)\n        self.assertIsInstance(e[\'democ\'].demob.demoa, DemoA)\n\n    def test_nesting_two_levels(self):\n        experiment = {\n            \'democ\': {\n                \'_name\': \'DemoC\',\n                \'demob\': {\n                    \'_name\': \'DemoB\',\n                    \'attrb\': 10,\n                    \'demoa\': {\n                        \'_name\': \'DemoA\',\n                        \'simple_int\': \'$simple_int\'\n                    }\n                }\n            },\n            \'simple_int\': 2\n        }\n\n        e = ExperimentConfig(experiment)\n        self.assertEqual(e[\'democ\'].demob.attrb, 10)\n        self.assertEqual(e[\'democ\'].attrc, 3)\n        self.assertEqual(e[\'democ\'].demob.demoa.simple_int, 2)\n\n    def test_unsubstituted_param(self):\n\n        experiment = {\n            ""bar"": \'foo\',\n            ""item"": {\n                ""_name"": ""DemoWithStr"",\n                ""strval"": ""$bar""\n            }\n        }\n        e = ExperimentConfig(experiment)\n        self.assertEqual(e[\'item\'].strval, \'foo\')\n\n        #########\n\n        experiment = {\n            ""item"": {\n                ""_name"": ""DemoWithStr"",\n                ""strval"": ""$bar""\n            }\n        }\n\n        with self.assertRaises(UnknownReferenceError) as cm:\n            ExperimentConfig(experiment)\n\n        self.assertEqual(""item.strval"", cm.exception.obj_name)\n        self.assertEqual(\'$bar\', cm.exception.reference_name)\n\n        #########\n\n        experiment = {\n            \'demo\': {\n                \'_name\': \'DemoWithDict\',\n                \'simple_int\': 22,\n                \'children\': {\n                    \'child0\': ""$demo3""\n                }\n            }\n        }\n\n        with self.assertRaises(UnknownReferenceError) as cm:\n            ExperimentConfig(experiment)\n\n        self.assertEqual(\'demo.children.child0\', cm.exception.obj_name)\n        self.assertEqual(\'$demo3\', cm.exception.reference_name)\n\n        #########\n\n        experiment = {\n            \'demo\': {\n                \'_name\': \'DemoWithList\',\n                \'simple_int\': 22,\n                \'children\': [""$demo3""]\n            }\n        }\n\n        with self.assertRaises(UnknownReferenceError) as cm:\n            ExperimentConfig(experiment)\n\n        self.assertEqual(\'demo.children.0\', cm.exception.obj_name)\n        self.assertEqual(\'$demo3\', cm.exception.reference_name)\n\n    def test_additional_params(self):\n\n        experiment = {\n            ""bar"": 5,\n            ""item"": {\n                ""_name"": ""DemoWithInt"",\n                ""intval"": ""$bar"",\n                ""bad_param"": 2\n            }\n        }\n\n        with self.assertRaises(CallableInstantiationError) as cm:\n            ExperimentConfig(experiment)\n\n        self.assertEqual(\'item\', cm.exception.obj_name)\n        self.assertEqual(\'DemoWithInt\', cm.exception.callable_name)\n        self.assertListEqual([\'intval\', \'bad_param\'], cm.exception.arg_names)\n\n    def test_bad_plugin(self):\n\n        experiment = {\n            ""item"": {\n                ""_name"": ""NoConfig"",\n            }\n        }\n\n        with self.assertRaises(UnknownPluginException) as cm:\n            ExperimentConfig(experiment)\n\n        self.assertEqual(\'NoConfig\', cm.exception.registrable)\n        self.assertEqual(\'item\', cm.exception.obj_name)\n\n        #########\n\n        experiment = {\n            ""item"": {\n                ""_name"": ""DemoWithDict"",\n                \'children\': {\n                    \'child\': {\n                        ""_name"": ""NoConfig""\n                    }\n                }\n            }\n        }\n\n        with self.assertRaises(UnknownPluginException) as cm:\n            ExperimentConfig(experiment)\n\n        self.assertEqual(\'NoConfig\', cm.exception.registrable)\n        self.assertEqual(\'item.children.child\', cm.exception.obj_name)\n\n        #########\n\n        experiment = {\n            ""item"": {\n                ""_name"": ""DemoWithList"",\n                \'children\': [\n                    {\n                        ""_name"": ""NoConfig""\n                    }\n                ]\n            }\n        }\n\n        with self.assertRaises(UnknownPluginException) as cm:\n            ExperimentConfig(experiment)\n\n        self.assertEqual(\'NoConfig\', cm.exception.registrable)\n        self.assertEqual(\'item.children.0\', cm.exception.obj_name)\n\n    def test_recursive_list(self):\n        experiment = {\n            \'demo\': {\n                \'_name\': \'DemoWithList\',\n                \'simple_int\': 22,\n                \'children\': [\n                    {\n                        \'_name\': \'DemoWithStr\',\n                        \'strval\': \'foo\'\n                    },\n                    \'$demo3\']\n            },\n            \'demo3\': {\n                \'_name\': \'DemoWithInt\',\n                \'intval\': 2\n            }\n        }\n        e = ExperimentConfig(experiment)\n        demo: DemoWithList = e.experiment[\'demo\']\n        self.assertEqual(22, demo.simple_int)\n\n        self.assertIsInstance(demo.children[0], DemoWithStr)\n        self.assertEqual(demo.children[0].strval, \'foo\')\n\n        self.assertIsInstance(demo.children[1], DemoWithInt)\n        self.assertEqual(demo.children[1].intval, 2)\n\n    def test_recursive_dict(self):\n        experiment = {\n            \'demo\': {\n                \'_name\': \'DemoWithDict\',\n                \'simple_int\': 22,\n                \'children\': {\n                    \'child0\': {\n                        \'_name\': \'DemoWithStr\',\n                        \'strval\': \'foo\'\n                    },\n                    \'child1\': ""$demo3""\n                }\n            },\n            \'demo3\': {\n                \'_name\': \'DemoWithInt\',\n                \'intval\': 2\n            }\n        }\n\n        e = ExperimentConfig(experiment)\n        demo: DemoWithDict = e.experiment[\'demo\']\n        self.assertEqual(22, demo.simple_int)\n\n        self.assertIsInstance(demo.children[\'child0\'], DemoWithStr)\n        self.assertEqual(demo.children[\'child0\'].strval, \'foo\')\n\n        self.assertIsInstance(demo.children[\'child1\'], DemoWithInt)\n        self.assertEqual(demo.children[\'child1\'].intval, 2)\n\n    def test_method_config(self):\n        experiment = {\n            \'demo\': {\n                \'_name\': \'DemoWithStr\',\n                \'strval\': ""foo"",\n            },\n            ""object_from_method"": {\n                ""_name"": ""demo_method_with_str"",\n                ""str_val"": 5\n            }\n        }\n\n        # Test that the initialization is correct\n        e = ExperimentConfig(experiment)\n        self.assertIsInstance(e[\'object_from_method\'], DemoWithStr)\n        self.assertEqual(e[\'object_from_method\'].strval, 5)\n\n    def test_nested_lists_dicts(self):\n\n        experiment = {\n            \'pipeline\': {\n                \'_name\': \'Pipeline\',\n                \'steps\': [\n                    [[\'first\', \'$first\'], \'$first\'],\n                    [\'second\', \'$second\'],\n                ]\n            },\n            \'first\': {\n                \'_name\': \'DemoWithInt\',\n                ""intval"": 2\n            },\n            \'second\': {\n                \'_name\': \'DemoWithInt\',\n                ""intval"": 1\n            },\n            \'pipeline_list_of_dict_objects\': {\n                ""_name"": ""Pipeline"",\n                ""steps"": [{\n                    \'_name\': \'DemoWithInt\',\n                    ""intval"": 10\n                },\n                    {\n                        \'_name\': \'DemoWithInt\',\n                        ""intval"": 20\n                    },\n                    {\n                        ""k1"": ""v1"",\n                        ""k2"": {\n                            ""_name"": ""DemoWithInt"",\n                            ""intval"": 0\n                        },\n                        ""k3"": [\'second\', \'$second\']},\n                    {\n                        ""k1"": 1,\n                        ""k2"": 2},\n                    [1, 2, 3]\n                ]\n            }\n        }\n        e = ExperimentConfig(experiment)\n\n        self.assertEqual(e[\'pipeline\'].steps[0][0][0], \'first\')\n        self.assertIsInstance(e[\'pipeline\'].steps[0][0][1], DemoWithInt)\n        self.assertIsInstance(e[\'pipeline\'].steps[0][1], DemoWithInt)\n        self.assertIsInstance(e[\'pipeline\'].steps[1][1], DemoWithInt)\n        self.assertEqual(e[\'pipeline\'].steps[1][0], \'second\')\n\n        self.assertIsInstance(e[\'pipeline_list_of_dict_objects\'].steps[0], DemoWithInt)\n        self.assertIsInstance(e[\'pipeline_list_of_dict_objects\'].steps[1], DemoWithInt)\n        self.assertIsInstance(e[\'pipeline_list_of_dict_objects\'].steps[2][\'k2\'], DemoWithInt)\n        self.assertEqual(e[\'pipeline_list_of_dict_objects\'].steps[3], {\n            ""k1"": 1,\n            ""k2"": 2})\n\n    def test_loop_in_config(self):\n\n        experiment1 = {\n            \'item1\': {\n                \'item\': \'$item2\'\n            },\n            \'item2\': {\n                \'item\': \'$item3\'\n            },\n            \'item3\': {\n                \'item\': \'$item1\',\n            },\n        }\n\n        experiment2 = {\n            \'item\': {\n                \'key\': [\n                    {\n                        \'key\': \'$item\'\n                    }\n                ]\n            }\n        }\n\n        self.assertRaises(LoopInConfigError, lambda: ExperimentConfig(experiment1))\n        self.assertRaises(LoopInConfigError, lambda: ExperimentConfig(experiment2))\n'"
tests/plugins/test_trainer.py,7,"b'import copy\nimport unittest\nfrom pathlib import Path\n\nimport ignite\nimport ignite.metrics as metrics\nimport torch.nn as nn\nimport torch.optim as optim\nfrom ignite.metrics import Precision, Recall, MetricsLambda\n\nfrom transfer_nlp.plugins.config import ExperimentConfig\nfrom transfer_nlp.plugins.regularizers import L1\nfrom .trainer_utils import *\n\nPLUGINS = {\n    \'CrossEntropyLoss\': nn.CrossEntropyLoss,\n    \'BCEWithLogitsLoss\': nn.BCEWithLogitsLoss,\n    ""Adam"": optim.Adam,\n    ""SGD"": optim.SGD,\n    ""AdaDelta"": optim.Adadelta,\n    ""AdaGrad"": optim.Adagrad,\n    ""SparseAdam"": optim.SparseAdam,\n    ""AdaMax"": optim.Adamax,\n    ""ASGD"": optim.ASGD,\n    ""LBFGS"": optim.LBFGS,\n    ""RMSPROP"": optim.RMSprop,\n    ""Rprop"": optim.Rprop,\n    ""ReduceLROnPlateau"": optim.lr_scheduler.ReduceLROnPlateau,\n    ""MultiStepLR"": optim.lr_scheduler.MultiStepLR,\n    ""ExponentialLR"": optim.lr_scheduler.ExponentialLR,\n    ""CosineAnnealingLR"": optim.lr_scheduler.CosineAnnealingLR,\n    ""LambdaLR"": optim.lr_scheduler.LambdaLR,\n    ""ReLU"": nn.functional.relu,\n    ""LeakyReLU"": nn.functional.leaky_relu,\n    ""Tanh"": nn.functional.tanh,\n    ""Softsign"": nn.functional.softsign,\n    ""Softshrink"": nn.functional.softshrink,\n    ""Softplus"": nn.functional.softplus,\n    ""Sigmoid"": nn.Sigmoid,\n    ""CELU"": nn.CELU,\n    ""SELU"": nn.functional.selu,\n    ""RReLU"": nn.functional.rrelu,\n    ""ReLU6"": nn.functional.relu6,\n    ""PReLU"": nn.functional.prelu,\n    ""LogSigmoid"": nn.functional.logsigmoid,\n    ""Hardtanh"": nn.functional.hardtanh,\n    ""Hardshrink"": nn.functional.hardshrink,\n    ""ELU"": nn.functional.elu,\n    ""Softmin"": nn.functional.softmin,\n    ""Softmax"": nn.functional.softmax,\n    ""LogSoftmax"": nn.functional.log_softmax,\n    ""GLU"": nn.functional.glu,\n    ""TanhShrink"": nn.functional.tanhshrink,\n    ""Accuracy"": metrics.Accuracy,\n}\nfor plugin_name, plugin in PLUGINS.items():\n    register_plugin(registrable=plugin, alias=plugin_name)\n\n\ndef fbeta(r, p, beta, average):\n    if average:\n        return (1 + beta ** 2) * p * r / (beta ** 2 * p + r + 1e-20)\n    else:\n        return torch.mean((1 + beta ** 2) * p * r / (beta ** 2 * p + r + 1e-20)).item()\n\n\n@register_plugin\ndef create_fbeta():\n    return MetricsLambda(fbeta, Recall(average=True), Precision(average=True), 0.5, True)\n\n\nEXPERIMENT = {\n    ""my_dataset_splits"": {\n        ""_name"": ""TestDataset"",\n        ""data_file"": Path(__file__).parent.resolve() / ""sample_data.csv"",\n        ""batch_size"": 128,\n        ""vectorizer"": {\n            ""_name"": ""TestVectorizer"",\n            ""data_file"": Path(__file__).parent.resolve() / ""sample_data.csv""\n        }\n    },\n    ""model"": {\n        ""_name"": ""TestModel"",\n        ""hidden_dim"": 100,\n        ""data"": ""$my_dataset_splits""\n    },\n    ""optimizer"": {\n        ""_name"": ""Adam"",\n        ""lr"": 0.01,\n        ""params"": {\n            ""_name"": ""TrainableParameters"",\n            ""model"": ""$model""\n        }\n    },\n    ""scheduler"": {\n        ""_name"": ""ReduceLROnPlateau"",\n        ""patience"": 1,\n        ""mode"": ""min"",\n        ""factor"": 0.5,\n        ""optimizer"": ""$optimizer""\n    },\n    ""trainer"": {\n        ""_name"": ""SingleTaskTrainer"",\n        ""model"": ""$model"",\n        ""dataset_splits"": ""$my_dataset_splits"",\n        ""loss"": {\n            ""_name"": ""CrossEntropyLoss""\n        },\n        ""optimizer"": ""$optimizer"",\n        ""gradient_clipping"": 0.25,\n        ""num_epochs"": 5,\n        ""seed"": 1337,\n        ""scheduler"": ""$scheduler"",\n        ""regularizer"": {\n            ""_name"": ""L1""\n        },\n        ""metrics"": {\n            ""accuracy"": {\n                ""_name"": ""Accuracy""\n            },\n            ""fbeta"": {\n                ""_name"": ""create_fbeta""\n            },\n            ""loss"": {\n                ""_name"": ""LossMetric"",\n                ""loss_fn"": {\n                    ""_name"": ""CrossEntropyLoss""\n                }\n            }\n        }\n    }\n\n}\n\n\nclass RegistryTest(unittest.TestCase):\n\n    def test_config(self):\n        e = copy.deepcopy(EXPERIMENT)\n        e = ExperimentConfig(e)\n        trainer = e.experiment[\'trainer\']\n\n        self.assertIsInstance(trainer.model, TestModel)\n        self.assertIsInstance(trainer.dataset_splits, TestDataset)\n        self.assertIsInstance(trainer.loss, torch.nn.modules.loss.CrossEntropyLoss)\n        self.assertIsInstance(trainer.optimizer, torch.optim.Adam)\n        self.assertEqual(len(trainer.metrics), 3)\n        self.assertEqual(trainer.device, torch.device(type=\'cpu\'))\n        self.assertEqual(trainer.seed, 1337)\n        self.assertEqual(trainer.loss_accumulation_steps, 4)\n        self.assertIsInstance(trainer.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)\n        self.assertEqual(trainer.num_epochs, 5)\n        self.assertIsInstance(trainer.regularizer, L1)\n        self.assertEqual(trainer.gradient_clipping, 0.25)\n        self.assertEqual(trainer.embeddings_name, None)\n        self.assertEqual(trainer.forward_params, [\'x_in\', \'apply_softmax\'])\n\n    def test_setup(self):\n        e = copy.deepcopy(EXPERIMENT)\n        e = ExperimentConfig(e)\n        trainer = e.experiment[\'trainer\']\n        trainer.setup(training_metrics=trainer.training_metrics)\n\n        self.assertEqual(len(trainer.trainer._event_handlers[ignite.engine.Events.EPOCH_COMPLETED]), 6)\n        self.assertEqual(len(trainer.trainer._event_handlers[ignite.engine.Events.ITERATION_COMPLETED]), 16)\n        self.assertEqual(len(trainer.trainer._event_handlers[ignite.engine.Events.COMPLETED]), 2)\n        self.assertEqual(len(trainer.trainer._event_handlers[ignite.engine.Events.STARTED]), 0)\n        self.assertEqual(len(trainer.trainer._event_handlers[ignite.engine.Events.EPOCH_STARTED]), 8)\n        self.assertEqual(len(trainer.trainer._event_handlers[ignite.engine.Events.ITERATION_STARTED]), 0)\n\n    def test_forward(self):\n        e = copy.deepcopy(EXPERIMENT)\n        e = ExperimentConfig(e)\n        trainer = e.experiment[\'trainer\']\n        trainer.setup(training_metrics=trainer.training_metrics)\n\n        batch = next(iter(trainer.dataset_splits.train_data_loader()))\n        self.assertEqual(list(batch.keys()), [\'x_in\', \'y_target\'])\n        output = trainer._forward(batch=batch)\n        self.assertEqual(output.size()[0], min(len(trainer.dataset_splits.train_set), 128))\n        self.assertEqual(output.size()[1], trainer.model.output_dim)\n'"
tests/plugins/trainer_utils.py,6,"b""import numpy as np\nimport pandas as pd\nimport torch\n\nfrom transfer_nlp.common.tokenizers import CharacterTokenizer\nfrom transfer_nlp.loaders.loaders import DatasetSplits, DataFrameDataset\nfrom transfer_nlp.loaders.vectorizers import Vectorizer\nfrom transfer_nlp.loaders.vocabulary import Vocabulary\nfrom transfer_nlp.plugins.config import register_plugin\nfrom transfer_nlp.plugins.helpers import ObjectHyperParams\n\n\n@register_plugin\nclass TestVectorizer(Vectorizer):\n\n    def __init__(self, data_file: str):\n\n        super().__init__(data_file=data_file)\n        self.tokenizer = CharacterTokenizer()\n\n        df = pd.read_csv(data_file)\n        data_vocab = Vocabulary(unk_token='@')\n        target_vocab = Vocabulary(add_unk=False)\n\n        # Add surnames and nationalities to vocabulary\n        for index, row in df.iterrows():\n            surname = row.surname\n            nationality = row.nationality\n            data_vocab.add_many(tokens=self.tokenizer.tokenize(text=surname))\n            target_vocab.add_token(token=nationality)\n\n        self.data_vocab = data_vocab\n        self.target_vocab = target_vocab\n\n    def vectorize(self, input_string: str) -> np.array:\n\n        encoding = np.zeros(shape=len(self.data_vocab), dtype=np.float32)\n        tokens = self.tokenizer.tokenize(text=input_string)\n        for character in tokens:\n            encoding[self.data_vocab.lookup_token(token=character)] = 1\n\n        return encoding\n\n@register_plugin\nclass TestDataset(DatasetSplits):\n\n    def __init__(self, data_file: str, batch_size: int, vectorizer: Vectorizer):\n        self.df = pd.read_csv(data_file)\n\n        # preprocessing\n        self.vectorizer: Vectorizer = vectorizer\n\n        self.df['x_in'] = self.df.apply(lambda row: self.vectorizer.vectorize(row.surname), axis=1)\n        self.df['y_target'] = self.df.apply(lambda row: self.vectorizer.target_vocab.lookup_token(row.nationality), axis=1)\n\n        train_df = self.df[self.df.split == 'train'][['x_in', 'y_target']]\n        val_df = self.df[self.df.split == 'val'][['x_in', 'y_target']]\n        test_df = self.df[self.df.split == 'test'][['x_in', 'y_target']]\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size,\n                         val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\n@register_plugin\nclass TestHyperParams(ObjectHyperParams):\n\n    def __init__(self, dataset_splits: DatasetSplits):\n        super().__init__()\n        self.input_dim = len(dataset_splits.vectorizer.data_vocab)\n        self.output_dim = len(dataset_splits.vectorizer.target_vocab)\n\n\n@register_plugin\nclass TestModel(torch.nn.Module):\n\n    def __init__(self, data: DatasetSplits, hidden_dim: int):\n        super(TestModel, self).__init__()\n\n        self.input_dim = len(data.vectorizer.data_vocab)\n        self.output_dim = len(data.vectorizer.target_vocab)\n        self.hidden_dim = hidden_dim\n\n        self.fc = torch.nn.Linear(in_features=self.input_dim, out_features=hidden_dim)\n        self.fc2 = torch.nn.Linear(in_features=hidden_dim, out_features=self.output_dim)\n\n    def forward(self, x_in: torch.Tensor, apply_softmax: bool = False) -> torch.Tensor:\n\n        intermediate = torch.nn.functional.relu(self.fc(x_in))\n        output = self.fc2(intermediate)\n\n        if self.output_dim == 1:\n            output = output.squeeze()\n\n        if apply_softmax:\n            output = torch.nn.functional.softmax(output, dim=1)\n\n        return output\n"""
tests/runner/__init__.py,0,b''
tests/runner/test_config_loader.py,0,"b'from pathlib import Path\nfrom unittest import TestCase\n\nfrom transfer_nlp.runner.experiment_runner import load_config\n\n\nclass ConfigLoaderTest(TestCase):\n\n    def test_loader(self):\n        pkg_dir = Path(__file__).parent\n\n        # Test the load_config works for both cfg and toml files\n        cfg_config = load_config(p=pkg_dir / \'test_experiment.cfg\')\n        toml_config = load_config(p=pkg_dir / \'test_experiment.toml\')\n        self.assertIsInstance(cfg_config, dict)\n        self.assertIsInstance(toml_config, dict)\n\n        # Test that TOML is able to deal with lists, whereas cfg considers lists as a string\n        # This is the main reason to prefere using TOML\n        self.assertIsInstance(cfg_config[""config1""][\'lparam\'], str)\n        self.assertIsInstance(toml_config[""config1""][\'lparam\'], list)\n'"
tests/runner/test_experiment_runner.py,0,"b'import io\nimport json\nimport logging\nimport shutil\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict, Any\nfrom unittest import TestCase\n\nimport toml\n\nfrom transfer_nlp.plugins.config import register_plugin, ExperimentConfig\nfrom transfer_nlp.plugins.reporters import ReporterABC\nfrom transfer_nlp.plugins.trainer_abc import TrainerABC\nfrom transfer_nlp.runner.experiment_runner import ExperimentRunner\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(level=logging.INFO)\n\n# Source to keep logs: http://alanwsmith.com/capturing-python-log-output-in-a-variable\nlog_capture_string = io.StringIO()\nch = logging.StreamHandler(log_capture_string)\nch.setLevel(logging.INFO)\nlogger.addHandler(ch)\n\n\n@register_plugin\nclass MockTrainer(TrainerABC):\n    def __init__(self, bool_param, int_param, str_param, float_param, env_param):\n        self.bool_param = bool_param\n        self.int_param = int_param\n        self.str_param = str_param\n        self.float_param = float_param\n        self.env_param = env_param\n        self.trained = False\n\n    def train(self):\n        ExperimentRunnerTest._trainer_calls += 1\n        if self.trained:\n            raise ValueError()\n        self.trained = True\n\n\n@register_plugin\nclass MockReporter(ReporterABC):\n    def __init__(self):\n        self.reported = False\n\n    def report(self, name: str, experiment: ExperimentConfig, report_dir: Path):\n        ExperimentRunnerTest._configs[name] = experiment\n        ExperimentRunnerTest._reporter_calls += 1\n        if self.reported:\n            raise ValueError()\n\n        self.reported = True\n        logger.info(experiment.experiment)\n        return experiment.experiment  # ExperimentRunnerTest._reporter_calls\n\n    @staticmethod\n    def report_globally(aggregate_reports: Dict, report_dir: Path) -> Any:\n        logger.info(""global reporting message"")\n\n\nclass ExperimentRunnerTest(TestCase):\n    _reporter_calls = 0\n    _trainer_calls = 0\n    _configs = {}\n\n    def setUp(self):\n        _reporter_calls = 0\n        self.test_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.test_dir)\n\n    def test_run_all(self):\n        pkg_dir = Path(__file__).parent\n\n        experiment_cache = ExperimentRunner.run_all(experiment=pkg_dir / \'test_experiment.yml\',\n                                                    experiment_config=pkg_dir / \'test_experiment.toml\',\n                                                    report_dir=self.test_dir + \'/reports\',\n                                                    trainer_config_name=\'the_trainer\',\n                                                    reporter_config_name=\'the_reporter\', ENV_PARAM=\'my_env_param\',\n                                                    experiment_cache=pkg_dir / \'test_read_only.json\')\n        log_contents = log_capture_string.getvalue()\n        log_capture_string.close()\n\n        exp1_logs = log_contents.split(""\\n"")[0]\n        exp2_logs = log_contents.split(""\\n"")[1]\n        global_reporting_logs = log_contents.split(""\\n"")[2]\n\n        exp1_logs = exp1_logs.replace(""<"", ""\\"""").replace("">"", ""\\"""").replace(""\\\'"", ""\\"""")\n        exp1_logs = json.loads(exp1_logs)\n        exp2_logs = exp2_logs.replace(""<"", ""\\"""").replace("">"", ""\\"""").replace(""\\\'"", ""\\"""")\n        exp2_logs = json.loads(exp2_logs)\n\n        # Check that the reference values we\'ve put in the config file have been\n        # replaced in the experiment file\n\n        # exp1_logs has only 2 objects in lparams\n        self.assertEqual(len(exp1_logs[\'lobjects\']), 2)\n        self.assertIn(\'MockTrainer\', exp1_logs[\'lobjects\'][0])\n        self.assertIn(\'MockReporter\', exp1_logs[\'lobjects\'][1])\n\n        # exp2_logs has only one object\n        self.assertEqual(len(exp2_logs[\'lobjects\']), 1)\n        self.assertIn(\'MockTrainer\', exp2_logs[\'lobjects\'][0])\n\n        # Check the global reporting\n        self.assertEqual(global_reporting_logs, ""global reporting message"")\n\n        self.assertIsInstance(experiment_cache[\'another_trainer\'], MockTrainer)\n        self.assertEqual(experiment_cache[\'another_trainer\'].int_param, 1)\n        self.assertEqual(experiment_cache[\'another_trainer\'].bool_param, True)\n\n        self.assertEqual(2, ExperimentRunnerTest._reporter_calls)\n        self.assertEqual(2, ExperimentRunnerTest._trainer_calls)\n\n        self.assertEqual(2, len(ExperimentRunnerTest._configs))\n\n        for name, bparam, iparam, fparam, sparam in [(\'config1\', True, 1, 1.5, \'hello\'), (\'config2\', False, 2, 2.5, \'world\')]:\n            # assert params where substituted into the experiment properly\n            cfg = ExperimentRunnerTest._configs[name][\'the_trainer\']\n            self.assertEqual(bparam, cfg.bool_param)\n            self.assertEqual(iparam, cfg.int_param)\n            self.assertEqual(fparam, cfg.float_param)\n            self.assertEqual(sparam, cfg.str_param)\n            self.assertEqual(\'my_env_param\', cfg.env_param)\n\n            # assert params were recorded in the reports directory\n            config = toml.load(f\'{self.test_dir}/reports/{name}/experiment_config.toml\')\n            self.assertEqual(1, len(config))\n            self.assertEqual(bparam, config[name][\'bparam\'])\n            self.assertEqual(iparam, config[name][\'iparam\'])\n            self.assertEqual(fparam, config[name][\'fparam\'])\n            self.assertEqual(sparam, config[name][\'sparam\'])\n            self.assertEqual(\'my_env_param\', config[name][\'ENV_PARAM\'])\n\n            self.assertEqual(ExperimentConfig.load_experiment_config(pkg_dir / \'test_experiment.yml\'),\n                             ExperimentConfig.load_experiment_config(f\'{self.test_dir}/reports/global-reporting/test_experiment.yml\'))\n'"
transfer_nlp/common/__init__.py,0,b''
transfer_nlp/common/tokenizers.py,0,"b'import logging\nimport re\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\n\nclass TokenizerABC:\n\n    def __init__(self):\n        pass\n\n    def tokenize(self, text: str):\n        raise NotImplementedError\n\n\nclass CustomTokenizer(TokenizerABC):\n\n    def __init__(self):\n        super().__init__()\n\n    def tokenize(self, text: str) -> List[str]:\n        """"""\n        Basic text preprocessing\n        :param text:\n        :return:\n        """"""\n\n        text = text.lower()\n        text = re.sub(r""([.,!?])"", r"" \\1 "", text)\n        text = re.sub(r""[^a-zA-Z.,!?]+"", r"" "", text)\n        tokens = text.split("" "")\n        if not tokens[-1]:\n            tokens = tokens[:-1]\n\n        return tokens\n\n\nclass CharacterTokenizer(TokenizerABC):\n\n    def __init__(self):\n        super().__init__()\n\n    def tokenize(self, text: str) -> List[str]:\n        """"""\n\n        :param text:\n        :return:\n        """"""\n\n        return [char for char in text.lower()]\n\n\nif __name__ == ""__main__"":\n    logging.info(\'\')\n\n    example = ""Hello world!""\n    tokenizer = CustomTokenizer()\n    tokenized = tokenizer.tokenize(text=example)\n    logger.info(f""{tokenized}"")\n'"
transfer_nlp/common/utils.py,2,"b'import logging\n\nimport torch\n\n\ndef describe(x: torch.Tensor):\n\n    print(""Type: {}"".format(x.type()))\n    print(""Shape/size: {}"".format(x.shape))\n    print(""Values: \\n{}"".format(x))\n\n\nif __name__ == ""__main__"":\n\n    tensor = torch.rand(size=(3, 4), dtype=torch.float64)\n    describe(x=tensor)\n'"
transfer_nlp/embeddings/__init__.py,0,b''
transfer_nlp/embeddings/embeddings.py,2,"b'import logging\nfrom pathlib import Path\nfrom typing import Dict, Tuple, Union\n\nimport numpy as np\nimport torch\nfrom smart_open import open\n\nfrom transfer_nlp.loaders.loaders import DatasetSplits\nfrom transfer_nlp.plugins.config import register_plugin\nfrom transfer_nlp.plugins.helpers import ObjectHyperParams\n\nlogger = logging.getLogger(__name__)\n\n\nTQDM = True\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    logger.debug(""To use tqdm in the embedding loader, pip install tqdm"")\n    TQDM = False\n\n\ndef load_glove_from_file(glove_filepath: Path) -> Tuple[Dict[str, int], np.array]:\n    w2i = {}\n    embeddings = []\n\n    with open(glove_filepath, ""r"") as fp:\n        iterator = tqdm(enumerate(fp), ""Embeddings"") if TQDM else enumerate(fp)\n        for index, line in iterator:\n            line = line.split("" "")  # each line: word num1 num2 ...\n            w2i[line[0]] = index  # word = line[0]\n            embedding_i = np.array([float(val) for val in line[1:]])\n            embeddings.append(embedding_i)\n\n    return w2i, np.stack(embeddings)\n\n\n@register_plugin\nclass EmbeddingsHyperParams(ObjectHyperParams):\n\n    def __init__(self, dataset_splits: DatasetSplits):\n        super().__init__()\n        self.words = dataset_splits.vectorizer.data_vocab._token2id.keys()\n\n\n@register_plugin\nclass Embedding:\n\n    def __init__(self, glove_filepath: Union[Path, str], data: DatasetSplits):\n\n        words = data.vectorizer.data_vocab._token2id.keys()\n\n        w2i, glove_embeddings = load_glove_from_file(glove_filepath=glove_filepath)\n        embedding_size = glove_embeddings.shape[1]\n\n        final_embeddings = np.zeros((len(words), embedding_size))\n\n        for i, word in tqdm(enumerate(words), total=len(words), desc=\'Loading pre-trained word embeddings\'):\n            if word in w2i:\n                final_embeddings[i, :] = glove_embeddings[w2i[word]]\n            else:\n                embedding_i = torch.ones(1, embedding_size)\n                torch.nn.init.xavier_uniform_(embedding_i)\n                final_embeddings[i, :] = embedding_i\n\n        self.embeddings = final_embeddings\n'"
transfer_nlp/embeddings/utils.py,3,"b'from typing import Dict, List, Tuple\n\nimport torch\n\n\ndef pretty_print(results: List[Tuple[str, torch.Tensor]]):\n    """"""\n    Pretty print embedding results.\n    """"""\n    for item in results:\n        print(""...[%.2f] - %s"" % (item[1], item[0]))\n\n\ndef get_closest(target_word: str, word_to_idx: Dict, embeddings: torch.Tensor, n: int = 5) -> List[Tuple[str, torch.Tensor]]:\n    """"""\n    Get the n closest\n    words to your word.\n    """"""\n\n    # Calculate distances to all other words\n\n    word_embedding = embeddings[word_to_idx[target_word.lower()]]\n    distances = []\n    for word, index in word_to_idx.items():\n        if word == ""<MASK>"" or word == target_word:\n            continue\n        distances.append((word, torch.dist(word_embedding, embeddings[index])))\n\n    results = sorted(distances, key=lambda x: x[1])[1:n + 2]\n    return results\n'"
transfer_nlp/loaders/__init__.py,0,b''
transfer_nlp/loaders/loaders.py,1,"b'from torch.utils.data import Dataset, DataLoader\n\n\nclass DatasetSplits:\n    def __init__(self,\n                 train_set: Dataset, train_batch_size: int,\n                 val_set: Dataset, val_batch_size: int,\n                 test_set: Dataset = None, test_batch_size: int = None):\n        self.train_set: Dataset = train_set\n        self.train_batch_size: int = train_batch_size\n\n        self.val_set: Dataset = val_set\n        self.val_batch_size: int = val_batch_size\n\n        self.test_set: Dataset = test_set\n        self.test_batch_size: int = test_batch_size\n\n    def train_data_loader(self):\n        return DataLoader(self.train_set, self.train_batch_size, shuffle=True)\n\n    def val_data_loader(self):\n        return DataLoader(self.val_set, self.val_batch_size, shuffle=False)\n\n    def test_data_loader(self):\n        return DataLoader(self.test_set, self.test_batch_size, shuffle=False)\n\n\n# To use this class you will need to manually install pandas\nclass DataFrameDataset(Dataset):\n\n    def __init__(self, df):\n        self.df = df\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, item):\n        row = self.df.iloc[item, :]\n        return {col: row[col] for col in self.df.columns}\n\n\nclass DataProps:\n    def __init__(self):\n        self.input_dims: int = None\n        self.output_dims: int = None\n'"
transfer_nlp/loaders/vectorizers.py,0,"b'class Vectorizer:\n\n    def __init__(self, data_file: str):\n        self.data_file = data_file\n\n    def vectorize(self, input_string: str):\n        raise NotImplementedError\n'"
transfer_nlp/loaders/vocabulary.py,0,"b'from typing import Dict\n\n\nclass Vocabulary:\n\n    def __init__(self, token2id: Dict = None, add_unk: bool = True, unk_token: str = ""<UNK>""):\n\n        if token2id is None:\n            token2id = {}\n\n        self._token2id: Dict = token2id\n        self._id2token = {idx: token for token, idx in self._token2id.items()}\n\n        self._add_unk: bool = add_unk\n        self._unk_token: str = unk_token\n        self.unk_index: int = -1\n        if add_unk:\n            self.unk_index = self.add_token(unk_token)\n\n    @classmethod\n    def from_serializable(cls, contents):\n\n        return cls(**contents)\n\n    def to_serializable(self):\n\n        return {\n            \'token2id\': self._token2id,\n            \'add_unk\': self._add_unk,\n            \'unk_token\': self._unk_token}\n\n    def add_token(self, token: str):\n\n        if token in self._token2id:\n            index = self._token2id[token]\n        else:\n            index = len(self._token2id)\n            self._token2id[token] = index\n            self._id2token[index] = token\n        return index\n\n    def add_many(self, tokens):\n\n        return [self.add_token(token) for token in tokens]\n\n    def lookup_token(self, token: str):\n\n        if self._add_unk:\n            return self._token2id.get(token, self.unk_index)\n        else:\n            return self._token2id.get(token, None)\n\n    def lookup_index(self, index: int):\n\n        if index not in self._id2token:\n            raise ValueError(f""Index {index} is not present in the Vocabulary"")\n\n        else:\n            return self._id2token[index]\n\n    def __str__(self):\n        return f""Vocabulary(size={len(self)})""\n\n    def __len__(self):\n        return len(self._token2id)\n\n\nclass CBOWVocabulary(Vocabulary):\n\n    def __init__(self, token2id: Dict = None, add_unk: bool = True, unk_token: str = ""<UNK>"", mask_token: str = ""<MASK>""):\n        super().__init__(token2id=token2id, add_unk=add_unk, unk_token=unk_token)\n        self._mask_token = mask_token\n        self.mask_index = self.add_token(self._mask_token)\n\n    def to_serializable(self):\n        contents = super(CBOWVocabulary, self).to_serializable()\n        contents.update({\n            \'mask_token\': self._mask_token})\n        return contents\n\n\nclass SequenceVocabulary(Vocabulary):\n\n    def __init__(self, token2id: Dict = None, unk_token: str = ""<UNK>"",\n                 mask_token: str = ""<MASK>"", begin_seq_token: str = ""<BEGIN>"",\n                 end_seq_token: str = ""<END>""):\n\n        super(SequenceVocabulary, self).__init__(token2id=token2id, add_unk=True, unk_token=unk_token)\n\n        self._mask_token: str = mask_token\n        self._begin_seq_token: str = begin_seq_token\n        self._end_seq_token: str = end_seq_token\n\n        self.mask_index: int = self.add_token(self._mask_token)\n        self.begin_seq_index: int = self.add_token(self._begin_seq_token)\n        self.end_seq_index: int = self.add_token(self._end_seq_token)\n\n    def to_serializable(self):\n\n        contents = super(SequenceVocabulary, self).to_serializable()\n\n        contents.update({\n            \'mask_token\': self._mask_token,\n            \'begin_seq_token\': self._begin_seq_token,\n            \'end_seq_token\': self._end_seq_token})\n        del contents[\'add_unk\']\n        return contents\n\n    @classmethod\n    def from_serializable(cls, contents):\n\n        return cls(**contents)\n\n    def lookup_token(self, token):\n\n        if self.unk_index >= 0:\n            return self._token2id.get(token, self.unk_index)\n        else:\n            return self._token2id[token]\n'"
transfer_nlp/plugins/__init__.py,0,b''
transfer_nlp/plugins/config.py,0,"b'""""""\nThis file contains all necessary plugins classes that the framework will use to let a user interact with custom models, data loaders, etc...\nThe Registry pattern used here is inspired from this post: https://realpython.com/primer-on-python-decorators/\n""""""\nimport logging\nimport os\nimport traceback\nfrom abc import ABCMeta, abstractmethod\nfrom pathlib import Path\nfrom typing import Any, Callable, Dict, List, Mapping, Type, Union\n\nimport toml\nimport yaml\n\nlogger = logging.getLogger(__name__)\nREGISTRY = {}\n\n\ndef register_plugin(registrable: Any, alias: str = None):\n    """"""\n    Register a class, a function or a method to REGISTRY\n    Args:\n        registrable:\n        alias:\n    Returns:\n    """"""\n    alias = alias or registrable.__name__\n\n    if alias in REGISTRY:\n        raise ValueError(f""{alias} is already registered to registrable {REGISTRY[alias]}. Please select another name"")\n\n    REGISTRY[alias] = registrable\n    return registrable\n\n\nclass InstantiationError(Exception):\n    """"""\n    An error happened while instantiating an experiment\n    """"""\n\n    def __init__(self, obj_name: str):\n        """"""\n        :param obj_name: The name of the object that couldn\'t be instantiated\n        """"""\n        self.obj_name: str = obj_name\n\n    def __str__(self) -> str:\n        return f""Failed to instantiate `{self.obj_name}`""\n\n\nclass CallableInstantiationError(InstantiationError):\n    """"""\n    An error happened while instantiating a callable\n    """"""\n\n    def __init__(self, obj_name: str, callable_name: str, arg_names: List[str]):\n        """"""\n        :param obj_name: The name of the object that couldn\'t be instantiated \n        :param callable_name: The callable\'s name that failed when called\n        :param arg_names: The names of the arguments that were passed to the callable\n        """"""\n        super().__init__(obj_name)\n        self.callable_name: str = callable_name\n        self.arg_names: List[str] = arg_names\n\n    def __str__(self) -> str:\n        return f""{super().__str__()} calling `{self.callable_name}` using the arguments "" + \', \'.join(self.arg_names) + \'; see exception raised above\'\n\n\nclass LoopInConfigError(InstantiationError):\n    """"""\n    An object refers to itself\n    """"""\n\n    def __str__(self) -> str:\n        return f""{super().__str__()} because it refers to itself""\n\n\nclass UnknownPluginException(InstantiationError):\n    """"""\n    A registrable has not been registred\n    """"""\n    def __init__(self, object_name: str, registrable: str):\n        super().__init__(object_name)\n        self.registrable: str = registrable\n\n    def __str__(self) -> str:\n        return f""{super().__str__()} because registrable `{self.registrable}` isn\'t registred""\n\n\nclass UnknownReferenceError(InstantiationError):\n    """"""\n    An object that is referenced does not exist\n    """"""\n    def __init__(self, object_name: str, reference_name: str):\n        super().__init__(object_name)\n        self.reference_name: str = reference_name\n\n    def __str__(self) -> str:\n        return f""{super().__str__()} because it reference to `{self.reference_name}` that doesn\'t exist""\n\n\nclass InstantiationImpossible(Exception):\n    pass\n\n\nclass ObjectInstantiator(metaclass=ABCMeta):\n    """"""\n    An instantiator that knows how to instantiate 1 kind of object\n    """"""\n\n    def __init__(self):\n        self.builder: ObjectBuilder = None\n\n    def set_builder(self, builder: ""ObjectBuilder"") -> None:\n        """"""\n        Set the builder, for recursive puposes\n\n        :param builder: The main builder to use when recursivity is needed\n        :return: None\n        """"""\n        self.builder: ObjectBuilder = builder\n\n    @abstractmethod\n    def instantiate(self, config: Union[Dict, str, List], name: str) -> Any:\n        """"""\n        :param config: The config from which we want to instantiate the object\n        :param name: The full name of the object to instantiate\n        :return: The instantiated object\n        """"""\n        raise InstantiationImpossible\n\n\nclass ObjectBuilder:\n    """"""\n    The main builder class\n    """"""\n    def __init__(self, instantiators: List[ObjectInstantiator]):\n        """"""\n        :param instantiators: The ordered list of instantiators that can be used to instantiate the objects\n        """"""\n        self.instantiators: List[ObjectInstantiator] = instantiators\n        for instantiator in instantiators:\n            instantiator.set_builder(self)\n\n    def instantiate(self, config: Union[Dict, str, List], name: str) -> Any:\n        """"""\n        build the object trying to use all the instantiators in a row, until one works\n\n        :param config: The config of the object to instantiate\n        :param name: The full name of this object\n        :return: The instantiated object\n        """"""\n\n        for instantiator in self.instantiators:\n            try:\n                return instantiator.instantiate(config, name)\n            except InstantiationImpossible:\n                pass\n\n        logger.info(f\'instantiating ""{name}"" as a simple object, {config}\')\n\n        return config\n\n\nclass DictInstantiator(ObjectInstantiator):\n    """"""\n    Instantiate a dictionary\n    """"""\n\n    def instantiate(self, config: Union[Dict, str, List], name: str) -> Dict:\n        """"""\n        :param config: The config for the object to instantiate\n        :param name: The full name of the object we try to instantiate\n        :return: The resulting object\n        :raise InstantiationImpossible: If the instantiator cannot handle this config\n        """"""\n        if not isinstance(config, dict):\n            raise InstantiationImpossible()\n\n        logger.info(f\'instantiating ""{name}"" as a dictionary\')\n\n        return {\n            key: self.builder.instantiate(value_config, f\'{name}.{key}\')\n            for key, value_config in config.items()\n        }\n\n\nclass ListInstantiator(ObjectInstantiator):\n    """"""\n    Instantiate a list\n    """"""\n\n    def instantiate(self, config: Union[Dict, str, List], name: str) -> List:\n        """"""\n        :param config: The config for the object to instantiate\n        :param name: The full name of the object we try to instantiate\n        :return: The resulting object\n        :raise InstantiationImpossible: If the instantiator cannot handle this config\n        """"""\n        if not isinstance(config, list):\n            raise InstantiationImpossible()\n\n        logger.info(f\'instantiating ""{name}"" as a list\')\n\n        return [\n            self.builder.instantiate(value_config, f\'{name}.{i}\')\n            for i, value_config in enumerate(config)\n        ]\n\n\nclass FromMappingInstantiator(ObjectInstantiator):\n    """"""\n    Instantiate an object looking for its reference in a Mapping object\n    """"""\n\n    def __init__(self, mapping: Mapping[str, Any], mapping_name: str):\n        """"""\n        :param mapping: The mapping to use to look for references \n        :param mapping_name: The mapping name, for logs\n        """"""\n        self.env: Mapping[str, Any] = mapping\n        self.mapping_name: str = mapping_name\n\n        super().__init__()\n\n    def instantiate(self, config: Union[Dict, str, List], name: str) -> Any:\n        """"""\n        :param config: The config for the object to instantiate\n        :param name: The full name of the object we try to instantiate\n        :return: The resulting object\n        :raise InstantiationImpossible: If the instantiator cannot handle this config\n        """"""\n\n        if not isinstance(config, str) or not config.startswith(\'$\'):\n            raise InstantiationImpossible\n        try:\n            instance = self.env[config[1:]]\n            logger.info(f\'instantiating ""{name}"" using value {instance} from key {config} in {self.mapping_name}\')\n            return instance\n        except KeyError:\n            raise InstantiationImpossible\n\n\nclass FromEnvironmentVariableInstantiator(FromMappingInstantiator):\n    """"""\n    Instantiate an object from the environment variables\n    """"""\n\n    def __init__(self, env: Dict[str, Any]):\n        """"""\n        :param env: The dictionary of the environment variables\n        """"""\n        super().__init__(env, \'Environment\')\n\n        self.strings_to_replace: List[str, str] = [\n            key\n            for key, value in self.env.items()\n            if isinstance(value, str) or isinstance(value, os.PathLike)\n        ]\n        self.strings_to_replace.sort(key=len, reverse=True)\n\n    def instantiate(self, config: Union[Dict, str, List], name: str) -> Any:\n        """"""\n        :param config: The config for the object to instantiate\n        :param name: The full name of the object we try to instantiate\n        :return: The resulting object\n        :raise InstantiationImpossible: If the instantiator cannot handle this config\n        :raise UnknownReferenceError: If the config refers to an unknown object\n        """"""\n        try:\n            return self.builder.instantiate(super().instantiate(config, name), f\'{name}\')\n        except InstantiationImpossible:\n            if not isinstance(config, str):\n                raise InstantiationImpossible()\n\n            v_upd: str = config\n            for key in self.strings_to_replace:\n                v_upd = v_upd.replace(f\'${key}\', str(self.env[key]))\n\n            if v_upd.startswith(\'$\'):\n                raise UnknownReferenceError(name, config) from None\n\n            logger.info(f\'instantiating ""{name}"" using value {v_upd}\')\n\n            return v_upd\n\n\nclass CallableInstantiator(DictInstantiator):\n    """"""\n    Instantiate an object calling a registered callable\n    """"""\n\n    def instantiate(self, config: Union[Dict, str, List], name: str) -> Any:\n        """"""\n        :param config: The config for the object to instantiate\n        :param name: The full name of the object we try to instantiate\n        :return: The instantiated object\n        :raise InstantiationImpossible: If the instantiator cannot handle this config\n        :raise UnknownPluginException: If the callable is not registered\n        :raise CallableInstantiationError: If an error occurred while calling the callable\n        """"""\n        if not isinstance(config, dict) or not \'_name\' in config:\n            raise InstantiationImpossible()\n\n        klass_name: str = config[\'_name\']\n\n        if klass_name not in REGISTRY:\n            raise UnknownPluginException(object_name=name, registrable=klass_name)\n\n        klass: Union[Type, Callable] = REGISTRY[klass_name]\n\n        logger.info(f\'instantiating ""{name}"" calling {klass_name}\')\n\n        param_instances: Dict[str, Any] = {\n            key: self.builder.instantiate(value_config, f\'{name}.{key}\')\n            for key, value_config in config.items()\n            if key != \'_name\'\n        }\n\n        try:\n            return klass(**param_instances)\n        except Exception:\n            raise CallableInstantiationError(obj_name=name, callable_name=klass_name, arg_names=list(param_instances.keys()))\n\n\nclass ExperimentConfig(Mapping[str, Any]):\n\n    @staticmethod\n    def load_experiment_config(experiment: Union[str, Path, Dict]) -> Dict:\n        config = {}\n        if isinstance(experiment, dict):\n            config = dict(experiment)\n        else:\n            experiment_path = Path(str(experiment)).expanduser()\n            with experiment_path.open() as f:\n                if experiment_path.suffix in {\'.json\', \'.yaml\', \'.yml\'}:\n                    config = yaml.safe_load(f)\n                elif experiment_path.suffix in {\'.toml\'}:\n                    config = toml.load(f)\n                else:\n                    raise ValueError(""Only Dict, json, yaml and toml experiment files are supported"")\n        return config\n\n    def __init__(self, experiment: Union[str, Path, Dict], **env):\n        """"""\n        :param experiment: the experiment config\n        :param env: substitution variables, e.g. a HOME directory. generally use all caps.\n        :return: the experiment\n        """"""\n\n        self.config: Dict[str, Any] = ExperimentConfig.load_experiment_config(experiment)\n\n        self.builds_started: List[str] = []\n        self.builders = [\n            CallableInstantiator(),\n            DictInstantiator(),\n            ListInstantiator(),\n            FromMappingInstantiator(REGISTRY, \'Registry\'),\n            FromMappingInstantiator(self, \'Experiment objects\'),\n            FromEnvironmentVariableInstantiator(env),\n        ]\n\n        self.builder: ObjectBuilder = ObjectBuilder(self.builders)\n\n        self.experiment: Dict[str, Any] = {}\n\n        for key, value_config in self.config.items():\n            if key not in self.experiment:\n                self.build(key)\n\n    def _check_init(self):\n        if self.experiment is None:\n            raise ValueError(\'experiment config is not setup yet!\')\n\n    def build(self, key: str) -> Any:\n        if key not in self.config:\n            raise KeyError()\n        if key in self.builds_started:\n            raise LoopInConfigError(key)\n        self.builds_started.append(key)\n        self.experiment[key] = self.builder.instantiate(self.config[key], name=key)\n        return self.experiment[key]\n\n    # map-like methods\n    def __getitem__(self, item):\n        self._check_init()\n        if item in self.experiment:\n            return self.experiment[item]\n        return self.build(item)\n\n    def get(self, item, default=None):\n        self._check_init()\n        return self.experiment.get(item, default)\n\n    def __iter__(self):\n        self._check_init()\n        return iter(self.experiment)\n\n    def items(self):\n        self._check_init()\n        return self.experiment.items()\n\n    def values(self):\n        self._check_init()\n        return self.experiment.values()\n\n    def keys(self):\n        self._check_init()\n        return self.experiment.keys()\n\n    def __setitem__(self, key, value):\n        raise ValueError(""cannot update experiment!"")\n\n    def __len__(self) -> int:\n        return len(self.experiment)\n'"
transfer_nlp/plugins/helpers.py,1,"b'import torch.nn as nn\n\nfrom transfer_nlp.plugins.config import register_plugin\n\n\n@register_plugin\nclass ObjectHyperParams:\n    """"""\n    Use or extend this class to configure model hyper parameters that cannot be predetermined. E.g.\n    a model input size that depends on the data set composition.\n    """"""\n\n    def __init__(self):\n        self.input_dim: int = None\n        self.output_dim: int = None\n\n\n@register_plugin\nclass TrainableParameters:\n    """"""\n    Use this class to configure optimizer parameters.\n    """"""\n\n    def __init__(self, model):\n        self.model: nn.Module = model\n\n    def __iter__(self):\n        for p in self.model.parameters():\n            if p.requires_grad:\n                yield p\n'"
transfer_nlp/plugins/metrics.py,0,"b'""""""\nThis class aims at using a pytorch loss function into ignite Metrics\n""""""\n\nimport logging\n\nfrom ignite.metrics import Loss\n\nfrom transfer_nlp.plugins.config import register_plugin\n\nlogger = logging.getLogger(__name__)\n\n\n@register_plugin\nclass LossMetric(Loss):\n    """"""\n    avoid name collision on batch size param of super class\n    """"""\n\n    def __init__(self, loss_fn):\n        super().__init__(loss_fn)\n'"
transfer_nlp/plugins/predictors.py,4,"b'import inspect\nimport logging\nfrom itertools import zip_longest\nfrom typing import Dict, List, Any\n\nimport torch\nfrom ignite.utils import convert_tensor\n\nfrom transfer_nlp.loaders.vectorizers import Vectorizer\n\nlogger = logging.getLogger(__name__)\n\n\ndef _prepare_batch(batch: Dict, device=None, non_blocking: bool = False):\n    """"""Prepare batch for training: pass to a device with options.\n\n    """"""\n    result = {key: convert_tensor(value, device=device, non_blocking=non_blocking) for key, value in batch.items()}\n    return result\n\n\nclass PredictorABC:\n\n    def __init__(self, vectorizer: Vectorizer, model: torch.nn.Module):\n\n        self.model: torch.nn.Module = model\n        self.model.eval()\n        self.forward_params = {}\n        model_spec = inspect.getfullargspec(self.model.forward)\n        for fparam, pdefault in zip_longest(reversed(model_spec.args[1:]), reversed(model_spec.defaults if model_spec.defaults else [])):\n            self.forward_params[fparam] = pdefault\n\n        self.vectorizer: Vectorizer = vectorizer\n\n    def forward(self, batch: Dict[str, Any]) -> torch.tensor:\n        """"""\n        Do the forward pass\n        :param batch:\n        :return:\n        """"""\n        with torch.no_grad():\n            batch = _prepare_batch(batch, device=""cpu"", non_blocking=False)\n            model_inputs = {}\n            for p, pdefault in self.forward_params.items():\n                val = batch.get(p)\n                if val is None:\n                    if pdefault is None:\n                        raise ValueError(f\'missing model parameter ""{p}""\')\n                    else:\n                        val = pdefault\n\n                model_inputs[p] = val\n            y_pred = self.model(**model_inputs)\n\n        return y_pred\n\n    def json_to_data(self, input_json: Dict) -> Dict:\n        """"""\n        Transform a json entry into a data example, which is the same that what the __getitem__ method in the\n        data loader, except that this does not output any expected label as in supervised setting\n        :param input_json:\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def output_to_json(self, *args, **kwargs) -> Dict[str, Any]:\n        """"""\n        Convert the result into a proper json\n        :param args:\n        :param kwargs:\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def decode(self, *args, **kwargs) -> List[Dict]:\n        """"""\n        Return an output dictionary for every example in the batch\n        :param args:\n        :param kwargs:\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def predict(self, batch: Dict[str, Any]) -> List[Dict]:\n        """"""\n        Decode the output of the forward pass\n        :param batch:\n        :return:\n        """"""\n        forward = self.forward(batch=batch)\n        return self.decode(forward)\n\n    def json_to_json(self, input_json: Dict) -> Dict[str, Any]:\n        """"""\n        Full prediction: input_json --> data example --> predictions --> json output\n        :param input_json:\n        :return:\n        """"""\n        json2data = self.json_to_data(input_json=input_json)\n        predictions = self.predict(batch=json2data)\n        predictions2json = self.output_to_json(predictions)\n\n        return predictions2json\n'"
transfer_nlp/plugins/regularizers.py,7,"b'import torch\n\nfrom transfer_nlp.plugins.config import register_plugin\n\n\nclass RegularizerABC:\n\n    def __call__(self, *args, **kwargs):\n        raise NotImplementedError\n\n    def __str__(self):\n        raise NotImplemented\n\n    def compute_penalty(self, model: torch.nn.Module):\n        raise NotImplementedError\n\n\n@register_plugin\nclass L1(RegularizerABC):\n\n    def __init__(self, alpha: float = 0.01) -> None:\n        self.alpha = alpha\n\n    def __call__(self, parameter: torch.Tensor) -> torch.Tensor:\n        return self.alpha * torch.sum(torch.abs(parameter))\n\n    def __str__(self):\n        return f""L1(alpha={self.alpha})""\n\n    def compute_penalty(self, model: torch.nn.Module):\n        """"""\n        Compute a penalty value uniformly over layers\n        :param self:\n        :param model:\n        :return:\n        """"""\n\n        penalty = 0\n\n        for name, parameter in model.named_parameters():\n            penalty += self(parameter)\n\n        return penalty\n\n\n@register_plugin\nclass L2(RegularizerABC):\n\n    def __init__(self, alpha: float = 0.01) -> None:\n        self.alpha = alpha\n\n    def __str__(self):\n        return f""L2(alpha={self.alpha})""\n\n    def __call__(self, parameter: torch.Tensor) -> torch.Tensor:\n        return self.alpha * torch.sum(torch.pow(parameter, 2))\n\n    def compute_penalty(self, model: torch.nn.Module):\n        """"""\n        Compute a penalty value uniformly over layers\n        :param self:\n        :param model:\n        :return:\n        """"""\n\n        penalty = 0\n\n        for name, parameter in model.named_parameters():\n            penalty += self(parameter)\n\n        return penalty\n'"
transfer_nlp/plugins/reporters.py,0,"b'from abc import ABC\nfrom pathlib import Path\nfrom typing import Any, Dict\n\nfrom transfer_nlp.plugins.config import ExperimentConfig\n\n\nclass ReporterABC(ABC):\n    """"""\n    Reporter implementations write reports about trained models. They should at least produce human readable reports,\n    but can additionally produce reports that are easily machine-parsable.\n    """"""\n\n    def report(self, experiment_name: str, experiment: ExperimentConfig, report_dir: Path) -> Any:\n        """"""\n        report the results of an experiment\n        :param experiment_name: the name of the experiment.\n        :param experiment: the completed experiment.\n        :param report_dir: the directory in which to write the report\n        :return: the key metric value, it\'s assumed higher is better.\n        """"""\n\n        pass\n\n    @staticmethod\n    def report_globally(aggregate_reports: Dict, report_dir: Path) -> Any:\n        """"""\n        do a global reporting for multiple experiment configurations\n        :param aggregate_reports: the result of report() on each experiment config.\n        :param report_dir: the directory in which to write the report\n        :return: a global reporting of the key metric values along different configurations.\n        """"""\n        pass\n'"
transfer_nlp/plugins/trainer_abc.py,0,"b'from abc import ABC, abstractmethod\n\n\nclass TrainerABC(ABC):\n\n    @abstractmethod\n    def train(self):\n        pass\n'"
transfer_nlp/plugins/trainers.py,12,"b'""""""\nThis class contains the abstraction interface to customize runners.\nFor the training loop, we use the engine logic from pytorch-ignite\n\nCheck experiments for examples of experiment json files\n\nExamples using gradual unfreezing and adaptation methods in general are adapted from\nthe NAACL 2019 tutorial on TRansfer Learning for NLP https://colab.research.google.com/drive/1iDHCYIrWswIKp-n-pOg69xLoZO09MEgf#scrollTo=GObQkkttljWv&forceEdit=true&offline=true&sandboxMode=true\n""""""\n\nimport inspect\nimport logging\nimport re\nfrom abc import abstractmethod\nfrom collections import defaultdict\nfrom typing import Dict, List, Any, Union, Tuple\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom ignite.contrib.handlers.tensorboard_logger import TensorboardLogger, OutputHandler, OptimizerParamsHandler, WeightsScalarHandler, WeightsHistHandler, \\\n    GradsScalarHandler\nfrom ignite.contrib.handlers.tqdm_logger import ProgressBar\nfrom ignite.engine import Events\nfrom ignite.engine.engine import Engine\nfrom ignite.metrics import Loss, Metric, RunningAverage, MetricsLambda, Accuracy\nfrom ignite.utils import convert_tensor\n\nfrom transfer_nlp.loaders.loaders import DatasetSplits\nfrom transfer_nlp.plugins.config import register_plugin\nfrom transfer_nlp.plugins.regularizers import RegularizerABC\nfrom transfer_nlp.plugins.trainer_abc import TrainerABC\n\nlogger = logging.getLogger(__name__)\n\n# Tensorboard is used within PyTorch but is not a dependency, so it should be installed manually by users\nTENSORBOARD = True\ntry:\n    from torch.utils.tensorboard import SummaryWriter\nexcept ImportError:\n    logger.debug(""To use torch.utils.tensorboard, please install tensorboard>=1.14, and future"")\n    TENSORBOARD = False\n\n\ndef set_seed_everywhere(seed: int, cuda: bool):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if cuda:\n        torch.cuda.manual_seed_all(seed)\n\n\ndef _prepare_batch(batch: Union[Dict, List, Tuple], device=None, non_blocking: bool = False):\n    """"""Prepare batch for training: pass to a device with options.\n\n    """"""\n    if isinstance(batch, dict):\n        result = {key: convert_tensor(value, device=device, non_blocking=non_blocking) for key, value in batch.items()}\n        return result\n    elif isinstance(batch, tuple):\n        result = (convert_tensor(value, device=device, non_blocking=non_blocking) for value in batch)\n        return result\n    elif isinstance(batch, list):\n        result = [convert_tensor(value, device=device, non_blocking=non_blocking) for value in batch]\n        return result\n    else:\n        raise ValueError(""Only dict, tuples and lists are valid for batch"")\n\n\nclass TrainingMetric(Metric):\n\n    def __init__(self, metric: Metric):\n        self.source_metric = metric\n        self.reset()\n\n        super().__init__(lambda x: x[:-1])\n\n    def reset(self):\n        self.source_metric.reset()\n\n    def update(self, output):\n\n        if not isinstance(self.source_metric, MetricsLambda):\n            self.source_metric.update(output)\n            return\n\n        # If a source metric is made of several metrics, e.g. MetricsLambda\n        # metrics, we need to update each sub-metrics separately\n        for source in self.source_metric.args:\n            if isinstance(source, Metric):\n                source.update(output)\n        return\n\n    def compute(self):\n        return self.source_metric.compute()\n\n\n@register_plugin\nclass BaseIgniteTrainer(TrainerABC):\n\n    def __init__(self,\n                 model: nn.Module,\n                 dataset_splits: DatasetSplits,\n                 loss: nn.Module,\n                 optimizer: optim.Optimizer,\n                 metrics: Dict[str, Metric],\n                 device: str = None,\n                 num_epochs: int = 1,\n                 seed: int = None,\n                 cuda: bool = None,\n                 loss_accumulation_steps: int = 4,\n                 scheduler: Any = None,\n                 regularizer: RegularizerABC = None,\n                 gradient_clipping: float = 1.0,\n                 output_transform=None,\n                 tensorboard_logs: str = None):\n\n        self.model: nn.Module = model\n\n        self.forward_param_defaults = {}\n\n        model_spec = inspect.getfullargspec(model.forward)\n        self.forward_params: List[str] = model_spec.args[1:]\n        for fparam, pdefault in zip(reversed(model_spec.args[1:]), reversed(model_spec.defaults if model_spec.defaults else [])):\n            self.forward_param_defaults[fparam] = pdefault\n\n        self.dataset_splits: DatasetSplits = dataset_splits\n        self.loss: nn.Module = loss\n        self.optimizer: optim.Optimizer = optimizer\n        self.metrics: Dict[str, Metric] = metrics\n        self.metrics: List[Metric] = [metric for _, metric in self.metrics.items()]\n        self.device: str = device\n        self.num_epochs: int = num_epochs\n        self.scheduler: Any = scheduler\n        self.seed: int = seed\n        self.cuda: bool = cuda\n        if self.cuda is None:  # If cuda not specified, just check if the cuda is available and use accordingly\n            self.device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n        self.loss_accumulation_steps: int = loss_accumulation_steps\n        self.regularizer: RegularizerABC = regularizer\n        self.gradient_clipping: float = gradient_clipping\n        self.output_transform = output_transform\n        self.tensorboard_logs: str = tensorboard_logs\n        if self.tensorboard_logs and TENSORBOARD:\n            self.writer = SummaryWriter(log_dir=self.tensorboard_logs)\n\n        if not self.output_transform:\n            self.output_transform = lambda y_pred, y_target, loss: (y_pred, y_target, loss)\n\n        self.eval_output_transform = lambda y, y_pred: (y, y_pred)\n\n        self.trainer, self.training_metrics = self.create_supervised_trainer()\n        self.evaluator = self.create_supervised_evaluator()\n\n        loss_metrics = [m for m in self.metrics if isinstance(m, Loss)]\n\n        if self.scheduler:\n            if not loss_metrics:\n                raise ValueError(\'A loss metric must be configured\')\n            elif len(loss_metrics) > 1:\n                logging.warning(\'multiple loss metrics detected, using %s for LR scheduling\', loss_metrics[0])\n            self.loss_metric = loss_metrics[0]\n\n        self.metrics_history = {\n            ""training"": defaultdict(list),\n            ""validation"": defaultdict(list),\n            ""test"": defaultdict(list)}\n\n        self.setup(self.training_metrics)\n\n    def setup(self, training_metrics: Dict):\n        def metric_name(n) -> str:\n            if n.endswith(\'Accuracy\'):\n                n = \'acc\'\n            else:\n                n = n[:-6] if n.endswith(\'Metric\') else n\n            return n\n\n        def print_metrics(metrics) -> str:\n            rv = \'\'\n            metric_keys = sorted(k for k in metrics)\n            for k in metric_keys:\n                if k == \'Accuracy\':\n                    rv += f\'{metric_name(k)}: {metrics[k]:.3} | \'\n                else:\n                    rv += f\'{metric_name(k)}: {metrics[k]} | \'\n            return rv\n\n        def store_metrics(metrics: Dict, mode: str):\n            metric_keys = sorted(k for k in metrics)\n            for k in metric_keys:\n                self.metrics_history[mode][metric_name(k)].append(metrics[k])\n\n        if self.seed:\n            set_seed_everywhere(self.seed, self.cuda)\n\n        pbar = ProgressBar(persist=True)\n\n        names = []\n        for k, v in training_metrics.items():\n            name = f\'r{k}\'\n            names.append(name)\n            RunningAverage(v).attach(self.trainer, name)\n        RunningAverage(None, output_transform=lambda x: x[-1]).attach(self.trainer, \'rloss\')\n\n        names.append(\'rloss\')\n        pbar.attach(self.trainer, names)\n\n        ProgressBar(persist=True).attach(engine=self.evaluator, metric_names=names)\n\n        # A few events handler. To add / modify the events handler, you need to extend the __init__ method of RunnerABC\n        # Ignite provides the necessary abstractions and a furnished repository of useful tools\n\n        @self.trainer.on(Events.EPOCH_COMPLETED)\n        def log_training_validation_results(trainer):\n\n            self.evaluator.run(self.dataset_splits.train_data_loader())\n            metrics = self.evaluator.state.metrics\n            store_metrics(metrics=metrics, mode=""training"")\n            logger.info(f""Training Results - Epoch: {trainer.state.epoch} {print_metrics(metrics)}"")\n\n            self.evaluator.run(self.dataset_splits.val_data_loader())\n            metrics = self.evaluator.state.metrics\n            store_metrics(metrics=metrics, mode=""validation"")\n            logger.info(f""Validation Results - Epoch: {trainer.state.epoch} {print_metrics(metrics)}"")\n\n            metrics = self.trainer.state.metrics\n            if self.scheduler:\n                self.scheduler.step(metrics[""rloss""])\n                # self.scheduler.step(metrics[self.loss_metric.__class__.__name__])\n\n        @self.trainer.on(Events.COMPLETED)\n        def log_test_results(trainer):\n            if self.dataset_splits.test_set:\n                self.evaluator.run(self.dataset_splits.test_data_loader())\n                metrics = self.evaluator.state.metrics\n                store_metrics(metrics=metrics, mode=""test"")\n                logger.info(f""Test Results - Epoch: {trainer.state.epoch} {print_metrics(metrics)}"")\n\n    def _forward(self, batch):\n        model_inputs = {}\n        for p in self.forward_params:\n            val = batch.get(p)\n            if val is None:\n                if p in self.forward_param_defaults:\n                    val = self.forward_param_defaults[p]\n                else:\n                    raise ValueError(f\'missing model parameter ""{p}""\')\n\n            model_inputs[p] = val\n\n        return self.model(**model_inputs)\n\n    @abstractmethod\n    def update_engine(self, engine, batch):\n        raise NotImplementedError\n\n    @abstractmethod\n    def infer_engine(self, engine, batch):\n        raise NotImplementedError\n\n    def create_supervised_trainer(self):\n\n        if self.device:\n            self.model.to(self.device)\n\n        engine = Engine(self.update_engine)\n        metrics = {}\n        for i, metric in enumerate(self.metrics):\n            if not isinstance(metric, Loss):\n                n = metric.__class__.__name__\n                tm = TrainingMetric(metric)\n                metrics[n] = tm\n                tm.attach(engine, n)\n\n        return engine, metrics\n\n    def create_supervised_evaluator(self):\n\n        if self.device:\n            self.model.to(self.device)\n\n        engine = Engine(self.infer_engine)\n\n        for i, metric in enumerate(self.metrics):\n            metric.attach(engine, f\'{str(metric.__class__.__name__)}\')\n\n        return engine\n\n    def train(self):\n        raise NotImplementedError\n\n\n@register_plugin\nclass SingleTaskTrainer(BaseIgniteTrainer):\n\n    def __init__(self,\n                 model: nn.Module,\n                 dataset_splits: DatasetSplits,\n                 loss: nn.Module,\n                 optimizer: optim.Optimizer,\n                 metrics: Dict[str, Metric],\n                 device: str = None,\n                 num_epochs: int = 1,\n                 seed: int = None,\n                 cuda: bool = None,\n                 loss_accumulation_steps: int = 4,\n                 scheduler: Any = None,\n                 regularizer: RegularizerABC = None,\n                 gradient_clipping: float = 1.0,\n                 output_transform=None,\n                 tensorboard_logs: str = None,\n                 optional_tensorboard_features: bool = False,\n                 embeddings_name: str = None):\n\n        super().__init__(\n            model=model,\n            dataset_splits=dataset_splits,\n            loss=loss,\n            optimizer=optimizer,\n            metrics=metrics,\n            device=device,\n            num_epochs=num_epochs,\n            seed=seed,\n            cuda=cuda,\n            loss_accumulation_steps=loss_accumulation_steps,\n            scheduler=scheduler,\n            regularizer=regularizer,\n            gradient_clipping=gradient_clipping,\n            output_transform=output_transform,\n            tensorboard_logs=tensorboard_logs)\n\n        self.optional_tensorboard_features: bool = optional_tensorboard_features\n        self.embeddings_name: str = embeddings_name\n\n        self.custom_setup()\n\n    def custom_setup(self):\n\n        if self.tensorboard_logs:\n            tb_logger = TensorboardLogger(log_dir=self.tensorboard_logs)\n            tb_logger.attach(self.trainer,\n                             log_handler=OutputHandler(tag=""training"", output_transform=lambda loss: {\n                                 \'loss\': loss}),\n                             event_name=Events.ITERATION_COMPLETED)\n            tb_logger.attach(self.evaluator,\n                             log_handler=OutputHandler(tag=""validation"",\n                                                       metric_names=[""LossMetric""],\n                                                       another_engine=self.trainer),\n                             event_name=Events.EPOCH_COMPLETED)\n\n            if self.optional_tensorboard_features:\n                tb_logger.attach(self.trainer,\n                                 log_handler=OptimizerParamsHandler(self.optimizer),\n                                 event_name=Events.ITERATION_STARTED)\n                tb_logger.attach(self.trainer,\n                                 log_handler=WeightsScalarHandler(self.model),\n                                 event_name=Events.ITERATION_COMPLETED)\n                tb_logger.attach(self.trainer,\n                                 log_handler=WeightsHistHandler(self.model),\n                                 event_name=Events.EPOCH_COMPLETED)\n                tb_logger.attach(self.trainer,\n                                 log_handler=GradsScalarHandler(self.model),\n                                 event_name=Events.ITERATION_COMPLETED)\n\n            # This is important to close the tensorboard file logger\n            @self.trainer.on(Events.COMPLETED)\n            def end_tensorboard(trainer):\n                logger.info(""Training completed"")\n                tb_logger.close()\n\n        if self.embeddings_name:\n            @self.trainer.on(Events.COMPLETED)\n            def log_embeddings(trainer):\n                if hasattr(self.model, self.embeddings_name) and hasattr(self.dataset_splits, ""vectorizer"") and TENSORBOARD:\n                    logger.info(f""Logging embeddings ({self.embeddings_name}) to Tensorboard!"")\n                    embeddings = getattr(self.model, self.embeddings_name).weight.data\n                    metadata = [str(self.dataset_splits.vectorizer.data_vocab._id2token[token_index]).encode(\'utf-8\') for token_index in\n                                range(embeddings.shape[0])]\n                    self.writer.add_embedding(mat=embeddings, metadata=metadata, global_step=self.trainer.state.epoch)\n\n    def update_engine(self, engine, batch):\n\n        # Gradient accumulation trick adapted from :\n        # https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255\n\n        self.model.train()\n        batch = _prepare_batch(batch, device=self.device, non_blocking=False)\n        if isinstance(batch, dict):\n            y_pred = self._forward(batch)\n            loss = self.loss(input=y_pred, target=batch[\'y_target\'])\n        elif isinstance(batch, tuple) or isinstance(batch, list):\n            y_pred = self.model.forward(*batch[:-1])\n            loss = self.loss(input=y_pred, target=batch[-1])\n        else:\n            raise ValueError(""Only dict, tuples and lists are valid for batch"")\n\n        # Add a regularisation term at train time only\n        if self.regularizer:\n            loss += self.regularizer.compute_penalty(model=self.model)\n\n        loss /= self.loss_accumulation_steps\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clipping)\n\n        if engine.state.iteration % self.loss_accumulation_steps == 0:\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n        if isinstance(batch, dict):\n            return self.output_transform(y_pred, batch[\'y_target\'], loss.item())\n        elif isinstance(batch, tuple) or isinstance(batch, list):\n            return self.output_transform(y_pred, batch[-1], loss.item())\n        else:\n            raise ValueError(""Only dict, tuples and lists are valid for batch"")\n\n    def infer_engine(self, engine, batch):\n\n        self.model.eval()\n        with torch.no_grad():\n            batch = _prepare_batch(batch, device=self.device, non_blocking=False)\n            if isinstance(batch, dict):\n                y_pred = self._forward(batch)\n                return self.eval_output_transform(y_pred, batch[\'y_target\'])\n            elif isinstance(batch, tuple) or isinstance(batch, list):\n                y_pred = self.model.forward(*batch[:-1])\n                return self.eval_output_transform(y_pred, batch[-1])\n            else:\n                raise ValueError(""Only dict, tuples and lists are valid for batch"")\n\n    def train(self):\n        """"""\n        Launch the ignite training pipeline\n        If fine-tuning mode is granted in the config file, freeze all layers, replace classification layer by a Linear layer\n        and reset the optimizer\n        :return:\n        """"""\n\n        self.trainer.run(self.dataset_splits.train_data_loader(), max_epochs=self.num_epochs)\n\n\n@register_plugin\nclass SingleTaskFineTuner(SingleTaskTrainer):\n\n    def __init__(self,\n                 model: nn.Module,\n                 dataset_splits: DatasetSplits,\n                 loss: nn.Module,\n                 optimizer: optim.Optimizer,\n                 metrics: Dict[str, Metric],\n                 device: str = None,\n                 num_epochs: int = 1,\n                 seed: int = None,\n                 cuda: bool = None,\n                 loss_accumulation_steps: int = 4,\n                 scheduler: Any = None,\n                 regularizer: RegularizerABC = None,\n                 gradient_clipping: float = 1.0,\n                 output_transform=None,\n                 tensorboard_logs: str = None,\n                 optional_tensorboard_features: bool = False,\n                 embeddings_name: str = None,\n                 adaptation: str = \'hard-freezing\',\n                 decreasing_factor: int = 2.6,\n                 pretrained: bool = False):\n        super().__init__(\n            model=model,\n            dataset_splits=dataset_splits,\n            loss=loss,\n            optimizer=optimizer,\n            metrics=metrics,\n            device=device,\n            num_epochs=num_epochs,\n            seed=seed,\n            cuda=cuda,\n            loss_accumulation_steps=loss_accumulation_steps,\n            scheduler=scheduler,\n            regularizer=regularizer,\n            gradient_clipping=gradient_clipping,\n            output_transform=output_transform,\n            tensorboard_logs=tensorboard_logs,\n            optional_tensorboard_features=optional_tensorboard_features,\n            embeddings_name=embeddings_name\n        )\n        self.adaptation: str = adaptation\n        self.decreasing_factor: int = decreasing_factor\n        self.pretrained: bool = pretrained\n\n    def load_pretrained_model(self):\n        """"""\n        This methid is not implemented so that pytorch_pretrained_bert is not a \n        required dependency. Use these lines to implement the method if using\n        pytorch_pretrained_bert\n        Returns:\n\n        """"""\n        # from pytorch_pretrained_bert import cached_path\n        # logger.info(""Loading pretrained model"")\n        # state_dict = torch.load(cached_path(""https://s3.amazonaws.com/models.huggingface.co/""\n        #                                     ""naacl-2019-tutorial/model_checkpoint.pth""), map_location=self.device)\n        # self.model.load_state_dict(state_dict, strict=False)\n        # logger.info(""Pretrained model loaded!"")\n\n        raise NotImplementedError\n\n    def freeze_params(self):\n\n        for name, param in self.model.named_parameters():\n            if \'embeddings\' not in name and \'classification\' not in name and \'adapters_1\' not in name and \'adapters_2\' not in name:\n                param.detach_()\n                param.requires_grad = False\n\n            else:\n                param.requires_grad = True\n\n        full_parameters = sum(p.numel() for p in self.model.parameters())\n        trained_parameters = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n\n        logger.info(f""We will train {trained_parameters:3e} parameters out of {full_parameters:3e},""\n                    f"" i.e. {100 * trained_parameters / full_parameters:.2f}%"")\n\n    def gradual_unfreezing(self):\n\n        for name, param in self.model.named_parameters():\n            if \'embeddings\' not in name and \'classification\' not in name:\n                param.detach_()\n                param.requires_grad = False\n\n            else:\n                param.requires_grad = True\n\n        full_parameters = sum(p.numel() for p in self.model.parameters())\n        trained_parameters = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n\n        logger.info(f""We will start by training {trained_parameters:3e} parameters out of {full_parameters:3e},""\n                    f"" i.e. {100 * trained_parameters / full_parameters:.2f}%"")\n\n        # We will unfreeze blocks regularly along the training: one block every `unfreezing_interval` step\n        unfreezing_interval = int(len(self.dataset_splits.train_data_loader()) * self.num_epochs / (self.model.num_layers + 1))\n\n        @self.trainer.on(Events.ITERATION_COMPLETED)\n        def unfreeze_layer_if_needed(engine):\n            if engine.state.iteration % unfreezing_interval == 0:\n                # Which layer should we unfreeze now\n                unfreezing_index = self.model.num_layers - (engine.state.iteration // unfreezing_interval)\n\n                # Let\'s unfreeze it\n                unfreezed = []\n                for name, param in self.model.named_parameters():\n                    if re.match(r""transformer\\.[^\\.]*\\."" + str(unfreezing_index) + r""\\."", name):\n                        unfreezed.append(name)\n                        param.require_grad = True\n                logger.info(f""Unfreezing block {unfreezing_index} with {unfreezed}"")\n\n    def discriminative_learning(self):\n\n        logger.info(""Using discriminative learning as adaptation strategy"")\n        # Build parameters groups by layer, numbered from the top [\'1\', \'2\', ..., \'15\']\n        parameter_groups = []\n        for i in range(self.model.num_layers):\n            name_pattern = r""transformer\\.[^\\.]*\\."" + str(i) + r""\\.""\n            group = {\n                \'name\': str(self.model.num_layers - i),\n                \'params\': [p for n, p in self.model.named_parameters() if re.match(name_pattern, n)]}\n            parameter_groups.append(group)\n\n        # Add the rest of the parameters (embeddings and classification layer) in a group labeled \'0\'\n        name_pattern = r""transformer\\.[^\\.]*\\.\\d*\\.""\n        group = {\n            \'name\': \'0\',\n            \'params\': [p for n, p in self.model.named_parameters() if not re.match(name_pattern, n)]}\n        parameter_groups.append(group)\n\n        # Sanity check that we still have the same number of parameters\n        assert sum(p.numel() for g in parameter_groups for p in g[\'params\']) \\\n               == sum(p.numel() for p in self.model.parameters())\n\n        @self.trainer.on(Events.ITERATION_STARTED)\n        def update_layer_learning_rates(engine):\n            for param_group in self.optimizer.param_groups:\n                layer_index = int(param_group[""name""])\n                param_group[""lr""] = param_group[""lr""] / (self.decreasing_factor ** layer_index)\n\n        return parameter_groups\n\n    def train(self):\n\n        # if self.pretrained:\n        #     self.load_pretrained_model()\n        #\n        # if self.adaptation == \'hard-freezing\':\n        #     self.freeze_params()\n        # elif self.adaptation == \'gradual-unfreezing\':\n        #     self.gradual_unfreezing()\n        # elif self.adaptation == \'discriminative-learning\':\n        #     parameter_groups = self.discriminative_learning()\n        #     self.experiment_config.factories[\'optimizer\'].kwargs[\'params\'] = parameter_groups\n        #     self.experiment_config.factories[\'optimizer\'].param2config_key[\'params\'] = parameter_groups\n        # else:\n        #     raise ValueError(""Transfer NLP supports only hard freezing, gradual unfreezing and discriminative learning"")\n        #\n        # self.optimizer = self.experiment_config.factories[\'optimizer\'].create()\n        # self.trainer.run(self.dataset_splits.train_data_loader(), max_epochs=self.num_epochs)\n        raise NotImplementedError\n\n\n@register_plugin\nclass MultiTaskTrainer(BaseIgniteTrainer):\n\n    def __init__(self,\n                 model: nn.Module,\n                 dataset_splits: DatasetSplits,\n                 loss: nn.Module,\n                 optimizer: optim.Optimizer,\n                 metrics: Dict[str, Metric],\n                 device: str = None,\n                 num_epochs: int = 1,\n                 seed: int = None,\n                 cuda: bool = None,\n                 loss_accumulation_steps: int = 4,\n                 scheduler: Any = None,\n                 regularizer: RegularizerABC = None,\n                 gradient_clipping: float = 1.0,\n                 output_transform=None,\n                 tensorboard_logs: str = None,\n                 clf_loss_coef: float = 0.1,\n                 lm_loss_coef: float = 0.9\n                 ):\n\n        super().__init__(\n            model=model,\n            dataset_splits=dataset_splits,\n            loss=loss,\n            optimizer=optimizer,\n            metrics=metrics,\n            device=device,\n            num_epochs=num_epochs,\n            seed=seed,\n            cuda=cuda,\n            loss_accumulation_steps=loss_accumulation_steps,\n            scheduler=scheduler,\n            regularizer=regularizer,\n            gradient_clipping=gradient_clipping,\n            output_transform=output_transform,\n            tensorboard_logs=tensorboard_logs)\n        self.clf_loss_coef = clf_loss_coef\n        self.lm_loss_coef = lm_loss_coef\n        RunningAverage(Accuracy(output_transform=lambda x: (x[0], x[1]))).attach(self.trainer, \'acc\')\n\n    def update_engine(self, engine, batch):\n        self.model.train()\n        batch = _prepare_batch(batch, device=self.device, non_blocking=False)\n        lm_logits, clf_logits = self._forward(batch)\n        loss_lm, loss_clf = self.loss(lm_logits=lm_logits, clf_logits=clf_logits, lm_labels=batch[\'x\'], clf_labels=batch[\'y_target\'])\n        loss = (self.clf_loss_coef * loss_clf\n                + self.lm_loss_coef * loss_lm) / self.loss_accumulation_steps\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clipping)\n\n        if engine.state.iteration % self.loss_accumulation_steps == 0:\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n\n        return clf_logits, batch[\'y_target\'], loss.item()\n\n    def infer_engine(self, engine, batch):\n\n        self.model.eval()\n        with torch.no_grad():\n            batch = _prepare_batch(batch, device=self.device, non_blocking=False)\n            lm_logits, clf_logits = self._forward(batch)\n            return clf_logits, batch[\'y_target\']\n\n    def create_supervised_evaluator(self):\n\n        if self.device:\n            self.model.to(self.device)\n\n        engine = Engine(self.infer_engine)\n\n        Accuracy().attach(engine, ""accuracy"")\n\n        return engine\n\n    def train(self):\n        self.trainer.run(self.dataset_splits.train_data_loader(), max_epochs=self.num_epochs)\n'"
transfer_nlp/runner/__init__.py,0,b''
transfer_nlp/runner/experiment_runner.py,0,"b'import configparser\nimport logging\nimport shutil\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom typing import Dict, Any, Union\n\nimport toml\n\nfrom transfer_nlp.plugins.config import ExperimentConfig\nfrom transfer_nlp.plugins.reporters import ReporterABC\nfrom transfer_nlp.plugins.trainer_abc import TrainerABC\n\nConfigEnv = Dict[str, Any]\n\n\ndef load_config(p: Path) -> Dict[str, ConfigEnv]:\n    p = Path(str(p)).expanduser()\n    if p.suffix == \'.toml\':\n        rv = toml.load(p)\n        return rv\n\n    if p.suffix != \'.cfg\':\n        raise ValueError(""Config files should be either .cfg or .toml files"")\n\n    def get_val(cfg: configparser.ConfigParser, section: str, key):\n        try:\n            return cfg.getint(section, key)\n        except ValueError:\n            pass\n        try:\n            return cfg.getfloat(section, key)\n        except ValueError:\n            pass\n        try:\n            return cfg.getboolean(section, key)\n        except ValueError:\n            pass\n\n        return cfg[section][key]\n\n    cfg = configparser.ConfigParser()\n    cfg.optionxform = str\n    cfg.read(p)\n\n    rv = {}\n\n    for exp_name in cfg.sections():\n        exp = {}\n        for key in cfg[exp_name].keys():\n            exp[key] = get_val(cfg, exp_name, key)\n        rv[exp_name] = exp\n\n    return rv\n\n\nclass ExperimentRunner:\n    """"""\n    Run an experiment several times with varying configurations.\n\n    This class facilitates reusing a single json experiment file across several different configuations.\n    """"""\n\n    @staticmethod\n    def _capture_logs(report_path: Path):\n        logger = logging.getLogger(\'\')\n        handler = logging.FileHandler(str(report_path / \'runner.log\'))\n        fmt = logging.Formatter(\'%(asctime)s %(levelname)s: %(message)s\')  # TODO configurable?\n        handler.setFormatter(fmt)\n        logger.addHandler(handler)\n        return handler\n\n    @staticmethod\n    def _stop_log_capture(handler):\n        logger = logging.getLogger(\'\')\n        logger.removeHandler(handler)\n\n    @staticmethod\n    def run_all(experiment: Union[str, Path],\n                experiment_config: Union[str, Path],\n                report_dir: Union[str, Path],\n                trainer_config_name: str = \'trainer\',\n                reporter_config_name: str = \'reporter\',\n                experiment_cache: Union[str, Path, Dict] = None,\n                **env_vars) -> ExperimentConfig:\n        """"""\n        :param experiment: the experiment config\n        :param experiment_config: the experiment config file. The cfg file should be defined in `ConfigParser\n               <https://docs.python.org/3/library/configparser.html#module-configparser>`_ format such that\n               each section is an experiment configuration.\n        :param report_dir: the directory in which to produce the reports. It\'s recommended to include a timestamp your report directory so you\n               can preserve previous reports across code changes. E.g. $HOME/reports/run_2019_02_22.\n        :param trainer_config_name: the name of the trainer configuration object. The referenced object should implement `TrainerABC`.\n        :param reporter_config_name: the name of the reporter configuration object. The referenced object should implement `ReporterABC`.\n        :param experiment_cache: the experiment config with cached objects\n        :param env_vars: any additional environment variables, like file system paths\n        :return: the experiment cache\n        """"""\n\n        envs: Dict[str, ConfigEnv] = load_config(Path(experiment_config))\n\n        report_path = Path(report_dir)\n        report_path.mkdir(parents=True)\n\n        # Before starting, save the 3 global files: experiment, configs and cache\n        global_report_dir = report_path / \'global-reporting\'\n        global_report_dir.mkdir(parents=True)\n        shutil.copy(src=str(experiment), dst=str(global_report_dir / str(Path(experiment).name)))\n        shutil.copy(src=str(experiment), dst=str(global_report_dir / str(Path(experiment_cache).name)))\n        shutil.copy(src=str(experiment_config), dst=str(global_report_dir / str(Path(experiment_config).name)))\n\n        experiment_config_cache = {}\n        if experiment_cache:\n            logging.info(""#"" * 5 + f""Building a set of read-only objects and cache them for use in different experiment settings"" + ""#"" * 5)\n            experiment_config_cache = ExperimentConfig(experiment_cache, **env_vars)\n            logging.info(""#"" * 5 + f""Read-only objects are built and cached for use in different experiment settings"" + ""#"" * 5)\n\n        aggregate_reports = {}\n        for exp_name, env in envs.items():\n            exp_report_path = report_path / exp_name\n            exp_report_path.mkdir()\n            log_handler = ExperimentRunner._capture_logs(exp_report_path)\n            try:\n                logging.info(\'running %s\', exp_name)\n                all_vars = dict(env_vars)\n                all_vars.update(env)\n\n                exp = deepcopy(experiment)\n                if experiment_cache:\n                    exp = ExperimentConfig.load_experiment_config(exp)\n                    exp.update(experiment_config_cache)\n\n                experiment_config = ExperimentConfig(exp, **all_vars)\n                trainer: TrainerABC = experiment_config[trainer_config_name]\n                reporter: ReporterABC = experiment_config[reporter_config_name]\n                trainer.train()\n\n                # Save the config for this particular experiment\n                exp_config = {\n                    exp_name: all_vars}\n                with (exp_report_path / \'experiment_config.toml\').open(\'w\') as expfile:\n                    toml.dump(exp_config, expfile)\n\n                # Get this particular config reporting and store it in the\n                # aggregated reportings\n                report = reporter.report(exp_name, experiment_config, exp_report_path)\n                aggregate_reports[exp_name] = report\n            finally:\n                ExperimentRunner._stop_log_capture(log_handler)\n\n        reporter_class = experiment_config[reporter_config_name].__class__\n        if issubclass(reporter_class, ReporterABC):\n            reporter_class.report_globally(aggregate_reports=aggregate_reports, report_dir=global_report_dir)\n\n        return experiment_config_cache\n'"
experiments/transfer_learning/transformers/dataset.py,4,"b'import random\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom pytorch_pretrained_bert import cached_path, BertTokenizer\n\nfrom transfer_nlp.loaders.loaders import DatasetSplits, DataFrameDataset\nfrom transfer_nlp.plugins.config import register_plugin\n\n\ndef load_data_lm():\n    dataset_file = cached_path(""https://s3.amazonaws.com/datasets.huggingface.co/wikitext-103/""\n                               ""wikitext-103-train-tokenized-bert.bin"")\n    datasets = torch.load(dataset_file)\n\n    # Convert our encoded dataset to torch.tensors and reshape in blocks of the transformer\'s input length\n    for split_name in [\'train\', \'valid\']:\n        tensor = torch.tensor(datasets[split_name], dtype=torch.long)\n        num_sequences = (tensor.size(0) // 256) * 256\n        datasets[split_name] = tensor.narrow(0, 0, num_sequences).view(-1, 256)\n\n    n = len(datasets[\'valid\']) // 2\n    datasets[\'test\'] = datasets[\'valid\'][n:]\n    datasets[\'valid\'] = datasets[\'valid\'][:n]\n    datasets[\'train\'] = datasets[\'train\'][:1000]\n    return datasets\n\n\ndef integerify(l):\n    return [x.numpy() for x in l]\n\n\n@register_plugin\nclass BertLMTuningDataset(DatasetSplits):\n\n    def __init__(self, batch_size: int):\n        datasets = load_data_lm()\n        self.data = datasets\n\n        train_df = pd.DataFrame(data={\n            ""x"": integerify(datasets[\'train\']),\n            ""y_target"": integerify(datasets[\'train\'])})\n        val_df = pd.DataFrame(data={\n            ""x"": integerify(datasets[\'valid\']),\n            ""y_target"": integerify(datasets[\'valid\'])})\n        test_df = pd.DataFrame(data={\n            ""x"": integerify(datasets[\'test\']),\n            ""y_target"": integerify(datasets[\'test\'])})\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size, val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n\n\n@register_plugin\nclass BertCLFFinetuningDataset(DatasetSplits):\n\n    def __init__(self, batch_size: int):\n        dataset_file = cached_path(""https://s3.amazonaws.com/datasets.huggingface.co/trec/""\n                                   ""trec-tokenized-bert.bin"")\n        datasets = torch.load(dataset_file)\n        tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n\n        for split_name in [\'train\', \'test\']:\n            # Trim the samples to the transformer\'s input length minus 1 & add a classification token\n            datasets[split_name] = [x[:256 - 1] + [tokenizer.vocab[\'[CLS]\']]\n                                    for x in datasets[split_name]]\n\n            # Pad the dataset to max length\n            padding_length = max(len(x) for x in datasets[split_name])\n            datasets[split_name] = [np.array(x + [tokenizer.vocab[\'[PAD]\']] * (padding_length - len(x)))\n                                    for x in datasets[split_name]]\n\n        valid_size = int(0.1 * len(datasets[\'train\']))\n        c = list(zip(datasets[\'train\'], datasets[\'train_labels\']))\n        random.shuffle(c)\n        datasets[\'train\'], datasets[\'train_labels\'] = zip(*c)\n        datasets[\'train\'], datasets[\'train_labels\'] = list(datasets[\'train\']), list(datasets[\'train_labels\'])\n\n        datasets[\'valid\'], datasets[\'valid_labels\'] = datasets[\'train\'][:valid_size], datasets[\'train_labels\'][:valid_size]\n        datasets[\'train\'], datasets[\'train_labels\'] = datasets[\'train\'][valid_size:], datasets[\'train_labels\'][valid_size:]\n\n        train_df = pd.DataFrame(data={\n            ""x"": datasets[\'train\'],\n            ""y_target"": datasets[\'train_labels\']\n        })\n        val_df = pd.DataFrame(data={\n            ""x"": datasets[\'valid\'],\n            ""y_target"": datasets[\'valid_labels\']\n        })\n        test_df = pd.DataFrame(data={\n            ""x"": datasets[\'test\'],\n            ""y_target"": datasets[\'test_labels\']\n        })\n\n        super().__init__(train_set=DataFrameDataset(train_df), train_batch_size=batch_size, val_set=DataFrameDataset(val_df), val_batch_size=batch_size,\n                         test_set=DataFrameDataset(test_df), test_batch_size=batch_size)\n'"
experiments/transfer_learning/transformers/lm_tuner_runner.py,0,"b'import logging\nfrom pathlib import Path\n\nfrom experiments.transfer_learning.transformers.dataset import *\nfrom experiments.transfer_learning.transformers.model import *\nfrom transfer_nlp.plugins.config import ExperimentConfig\n\nfrom experiments.utils import PLUGINS\n\nlogger = logging.getLogger(__name__)\n\nfor plugin_name, plugin in PLUGINS.items():\n    register_plugin(registrable=plugin, alias=plugin_name)\n\nif __name__ == ""__main__"":\n    logging.basicConfig(level=logging.INFO)\n    home_env = str(Path.home() / \'work/transfer-nlp-data\')\n\n    # # Train a language model on large dataset\n    # experiment = ExperimentConfig(\'./lm_fine_tuning.json\', HOME=home_env)\n    # experiment.experiment[\'trainer\'].train()\n\n    # # Fine-tune the LM on a classification task\n    # experiment = ExperimentConfig(\'./lm_clf_fine_tuning.json\', HOME=home_env)\n    # experiment.experiment[\'trainer\'].train()\n\n    # # Fine-tune the LM on a classification task with an adapted Transformer\n    # # You can change the trainers param ""adaptation"" to experiment with several\n    # # adaptation schemes\n    # experiment = ExperimentConfig(\'./lm_clf_adaptation.json\', HOME=home_env)\n    # experiment.experiment[\'trainer\'].train()\n\n    # Train jointly the LM and the classifier, branched on the same\n    # transformer backbone\n    experiment = ExperimentConfig(\'./multitask.json\', HOME=home_env)\n    experiment.experiment[\'trainer\'].train()'"
experiments/transfer_learning/transformers/model.py,47,"b'""""""\nThis file contains models presented in the Transfer Learning for NLP Tutorial at NAACL 2019\nModels are adapted from https://colab.research.google.com/drive/1iDHCYIrWswIKp-n-pOg69xLoZO09MEgf#scrollTo=_FfRT6GTjHhC&forceEdit=true&offline=true&sandboxMode=true\n\nThis is a WIP document and work is needed so that we don\'t have to replicate so many transformer classes\nIdeally we\'d like to have flexible transformer classes from which we can easily add\ntask-dependent heads and add adapter tools, e.g. freezing the backbone and add\nresidual connexion between layers. \n""""""\n\nimport torch\nfrom pytorch_pretrained_bert import BertTokenizer\n\nfrom transfer_nlp.plugins.config import register_plugin\n\n\n@register_plugin\nclass Transformer(torch.nn.Module):\n    def __init__(self, embed_dim: int, hidden_dim: int, num_embeddings: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float,\n                 causal: bool):\n        super().__init__()\n        self.causal: bool = causal\n        self.tokens_embeddings: torch.nn.Embedding = torch.nn.Embedding(num_embeddings, embed_dim)\n        self.position_embeddings: torch.nn.Embedding = torch.nn.Embedding(num_max_positions, embed_dim)\n        self.dropout: torch.nn.Dropout = torch.nn.Dropout(dropout)\n\n        self.attentions, self.feed_forwards = torch.nn.ModuleList(), torch.nn.ModuleList()\n        self.layer_norms_1, self.layer_norms_2 = torch.nn.ModuleList(), torch.nn.ModuleList()\n        for _ in range(num_layers):\n            self.attentions.append(torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout))\n            self.feed_forwards.append(torch.nn.Sequential(torch.nn.Linear(embed_dim, hidden_dim),\n                                                          torch.nn.ReLU(),\n                                                          torch.nn.Linear(hidden_dim, embed_dim)))\n            self.layer_norms_1.append(torch.nn.LayerNorm(embed_dim, eps=1e-12))\n            self.layer_norms_2.append(torch.nn.LayerNorm(embed_dim, eps=1e-12))\n\n        self.attn_mask = None\n        self.tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n\n    def forward(self, x):\n        """""" x has shape [batch, seq length]""""""\n\n        padding_mask = (x == self.tokenizer.vocab[\'[PAD]\'])\n\n        x = x.transpose(0, 1).contiguous()\n\n        positions = torch.arange(len(x), device=x.device).unsqueeze(-1)\n        h = self.tokens_embeddings(x)\n        h = h + self.position_embeddings(positions).expand_as(h)\n        h = self.dropout(h)\n\n        attn_mask = None\n        if self.causal:\n            attn_mask = torch.full((len(x), len(x)), -float(\'Inf\'), device=h.device, dtype=h.dtype)\n            attn_mask = torch.triu(attn_mask, diagonal=1)\n\n        for layer_norm_1, attention, layer_norm_2, feed_forward in zip(self.layer_norms_1, self.attentions,\n                                                                       self.layer_norms_2, self.feed_forwards):\n            h = layer_norm_1(h)\n            x, _ = attention(h, h, h, attn_mask=attn_mask, need_weights=False, key_padding_mask=padding_mask)\n            x = self.dropout(x)\n            h = x + h\n\n            h = layer_norm_2(h)\n            x = feed_forward(h)\n            x = self.dropout(x)\n            h = x + h\n        return h\n\n\n@register_plugin\nclass TransformerWithLMHead(torch.nn.Module):\n    def __init__(self, embed_dim: int, hidden_dim: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float, causal: bool,\n                 initializer_range: float):\n        """""" Transformer with a language modeling head on top (tied weights) """"""\n        super().__init__()\n        tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n        num_embeddings = len(tokenizer.vocab)\n        self.initializer_range = initializer_range\n        self.transformer = Transformer(embed_dim, hidden_dim, num_embeddings,\n                                       num_max_positions, num_heads, num_layers,\n                                       dropout, causal=causal)\n\n        self.lm_head = torch.nn.Linear(embed_dim, num_embeddings, bias=False)\n        self.apply(self.init_weights)\n        self.tie_weights()\n\n    def tie_weights(self):\n        self.lm_head.weight = self.transformer.tokens_embeddings.weight\n\n    def init_weights(self, module):\n        """""" initialize weights - nn.MultiheadAttention is already initalized by PyTorch (xavier) """"""\n        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm)):\n            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n        if isinstance(module, (torch.nn.Linear, torch.nn.LayerNorm)) and module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, x):\n        """""" x has shape [batch, seq length]""""""\n        hidden_states = self.transformer(x)\n        logits = self.lm_head(hidden_states)\n\n        return logits\n\n\n@register_plugin\nclass LMLoss:\n\n    def __init__(self, causal: bool):\n        self.causal: bool = causal\n\n    def __call__(self, input, target):\n        input = input.transpose(0, 1).contiguous()\n        shift_logits = input[:-1] if self.causal else input\n        shift_labels = target[1:] if self.causal else target\n        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n        return loss\n\n\n@register_plugin\nclass TransformerWithClfHead(torch.nn.Module):\n    def __init__(self,\n                 embed_dim: int, hidden_dim: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float, causal: bool,\n                 initializer_range: float, num_classes: int):\n        super().__init__()\n        self.tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n        num_embeddings = len(self.tokenizer.vocab)\n        self.initializer_range = initializer_range\n        self.transformer = Transformer(embed_dim, hidden_dim, num_embeddings,\n                                       num_max_positions, num_heads, num_layers,\n                                       dropout, causal=causal)\n\n        self.classification_head = torch.nn.Linear(embed_dim, num_classes)\n\n        self.apply(self.init_weights)\n\n    def init_weights(self, module):\n        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm)):\n            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n        if isinstance(module, (torch.nn.Linear, torch.nn.LayerNorm)) and module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, x):\n\n        clf_tokens_mask = (x.transpose(0, 1).contiguous() == self.tokenizer.vocab[\'[CLS]\'])\n\n        hidden_states = self.transformer(x)\n        msk = clf_tokens_mask.unsqueeze(-1).float()\n        clf_tokens_states = (hidden_states * msk).sum(dim=0)\n        clf_logits = self.classification_head(clf_tokens_states)\n\n        return clf_logits\n\n\n@register_plugin\nclass FineTuningLoss:\n\n    def __call__(self, input, target):\n        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        loss = loss_fct(input.view(-1, input.size(-1)), target.view(-1))\n        return loss\n\n\nclass TransformerWithAdapters(Transformer):\n    def __init__(self, adapters_dim, embed_dim, hidden_dim, num_embeddings, num_max_positions,\n                 num_heads, num_layers, dropout, causal):\n        """""" Transformer with adapters (small bottleneck layers) """"""\n        super().__init__(embed_dim, hidden_dim, num_embeddings, num_max_positions, num_heads, num_layers,\n                         dropout, causal)\n        self.adapters_1 = torch.nn.ModuleList()\n        self.adapters_2 = torch.nn.ModuleList()\n        for _ in range(num_layers):\n            self.adapters_1.append(torch.nn.Sequential(torch.nn.Linear(embed_dim, adapters_dim),\n                                                       torch.nn.ReLU(),\n                                                       torch.nn.Linear(adapters_dim, embed_dim)))\n\n            self.adapters_2.append(torch.nn.Sequential(torch.nn.Linear(embed_dim, adapters_dim),\n                                                       torch.nn.ReLU(),\n                                                       torch.nn.Linear(adapters_dim, embed_dim)))\n\n    def forward(self, x):\n        """""" x has shape [batch, seq length]""""""\n\n        padding_mask = (x == self.tokenizer.vocab[\'[PAD]\'])\n\n        x = x.transpose(0, 1).contiguous()\n\n        positions = torch.arange(len(x), device=x.device).unsqueeze(-1)\n        h = self.tokens_embeddings(x)\n        h = h + self.position_embeddings(positions).expand_as(h)\n        h = self.dropout(h)\n\n        attn_mask = None\n        if self.causal:\n            attn_mask = torch.full((len(x), len(x)), -float(\'Inf\'), device=h.device, dtype=h.dtype)\n            attn_mask = torch.triu(attn_mask, diagonal=1)\n\n        for (layer_norm_1, attention, adapter_1, layer_norm_2, feed_forward, adapter_2) \\\n                in zip(self.layer_norms_1, self.attentions, self.adapters_1,\n                       self.layer_norms_2, self.feed_forwards, self.adapters_2):\n            h = layer_norm_1(h)\n            x, _ = attention(h, h, h, attn_mask=attn_mask, need_weights=False, key_padding_mask=padding_mask)\n            x = self.dropout(x)\n\n            x = adapter_1(x) + x  # Add an adapter with a skip-connection after attention module\n\n            h = x + h\n\n            h = layer_norm_2(h)\n            x = feed_forward(h)\n            x = self.dropout(x)\n\n            x = adapter_2(x) + x  # Add an adapter with a skip-connection after feed-forward module\n\n            h = x + h\n        return h\n\n\n@register_plugin\nclass TransformerWithClfHeadAndAdapters(torch.nn.Module):\n    def __init__(self, adapters_dim: int,\n                 embed_dim: int, hidden_dim: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float, causal: bool,\n                 initializer_range: float, num_classes: int):\n        """""" Transformer with a classification head and adapters. """"""\n        super().__init__()\n        self.initializer_range: float = initializer_range\n        self.tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n        num_embeddings = len(self.tokenizer.vocab)\n        self.num_layers = num_layers\n        self.transformer: TransformerWithAdapters = TransformerWithAdapters(adapters_dim, embed_dim, hidden_dim, num_embeddings,\n                                       num_max_positions, num_heads, num_layers,\n                                       dropout, causal=causal)\n\n        self.classification_head = torch.nn.Linear(embed_dim, num_classes)\n        self.apply(self.init_weights)\n\n    def init_weights(self, module):\n        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm)):\n            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n        if isinstance(module, (torch.nn.Linear, torch.nn.LayerNorm)) and module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, x):\n\n        clf_tokens_mask = (x.transpose(0, 1).contiguous() == self.tokenizer.vocab[\'[CLS]\'])\n        hidden_states = self.transformer(x)\n        clf_tokens_states = (hidden_states * clf_tokens_mask.unsqueeze(-1).float()).sum(dim=0)\n        clf_logits = self.classification_head(clf_tokens_states)\n\n        return clf_logits\n\n\n@register_plugin\nclass TransformerWithClfHeadAndLMHead(torch.nn.Module):\n    def __init__(self, embed_dim: int, hidden_dim: int, num_max_positions: int, num_heads: int, num_layers: int, dropout: float, causal: bool,\n                 initializer_range: float, num_classes: int):\n        super().__init__()\n        self.initializer_range: float = initializer_range\n        self.tokenizer = BertTokenizer.from_pretrained(\'bert-base-cased\', do_lower_case=False)\n        num_embeddings = len(self.tokenizer.vocab)\n        self.num_layers = num_layers\n        self.transformer = Transformer(embed_dim, hidden_dim, num_embeddings,\n                                       num_max_positions, num_heads, num_layers,\n                                       dropout, causal=causal)\n\n        self.lm_head = torch.nn.Linear(embed_dim, num_embeddings, bias=False)\n        self.classification_head = torch.nn.Linear(embed_dim, num_classes)\n\n        self.apply(self.init_weights)\n        self.tie_weights()\n\n    def tie_weights(self):\n        self.lm_head.weight = self.transformer.tokens_embeddings.weight\n\n    def init_weights(self, module):\n        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm)):\n            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n        if isinstance(module, (torch.nn.Linear, torch.nn.LayerNorm)) and module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, x):\n        """""" x and clf_tokens_mask have shape [seq length, batch] padding_mask has shape [batch, seq length] """"""\n        clf_tokens_mask = (x.transpose(0, 1).contiguous() == self.tokenizer.vocab[\'[CLS]\'])\n        hidden_states = self.transformer(x)\n\n        lm_logits = self.lm_head(hidden_states)\n        clf_tokens_states = (hidden_states * clf_tokens_mask.unsqueeze(-1).float()).sum(dim=0)\n        clf_logits = self.classification_head(clf_tokens_states)\n\n        return lm_logits, clf_logits\n    \n@register_plugin\nclass MultiTaskLoss:\n    \n    def __init__(self, causal: bool):\n        self.causal: bool = causal\n\n    def __call__(self, lm_logits, clf_logits, lm_labels, clf_labels):\n        lm_logits = lm_logits.transpose(0, 1).contiguous()\n\n        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        loss_clf = loss_fct(clf_logits.view(-1, clf_logits.size(-1)), clf_labels.view(-1))\n\n        shift_logits = lm_logits[:-1] if self.causal else lm_logits\n        shift_labels = lm_labels[1:] if self.causal else lm_labels\n        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        loss_lm = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n\n        return loss_lm, loss_clf'"
