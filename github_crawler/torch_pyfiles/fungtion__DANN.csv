file_path,api_count,code
dataset/__init__.py,0,b''
dataset/data_loader.py,1,"b""import torch.utils.data as data\nfrom PIL import Image\nimport os\n\n\nclass GetLoader(data.Dataset):\n    def __init__(self, data_root, data_list, transform=None):\n        self.root = data_root\n        self.transform = transform\n\n        f = open(data_list, 'r')\n        data_list = f.readlines()\n        f.close()\n\n        self.n_data = len(data_list)\n\n        self.img_paths = []\n        self.img_labels = []\n\n        for data in data_list:\n            self.img_paths.append(data[:-3])\n            self.img_labels.append(data[-2])\n\n    def __getitem__(self, item):\n        img_paths, labels = self.img_paths[item], self.img_labels[item]\n        imgs = Image.open(os.path.join(self.root, img_paths)).convert('RGB')\n\n        if self.transform is not None:\n            imgs = self.transform(imgs)\n            labels = int(labels)\n\n        return imgs, labels\n\n    def __len__(self):\n        return self.n_data\n"""
models/__init__.py,0,b''
models/functions.py,1,"b'from torch.autograd import Function\n\n\nclass ReverseLayerF(Function):\n\n    @staticmethod\n    def forward(ctx, x, alpha):\n        ctx.alpha = alpha\n\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n\n        return output, None\n\n\n'"
models/model.py,1,"b""import torch.nn as nn\nfrom functions import ReverseLayerF\n\n\nclass CNNModel(nn.Module):\n\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.feature = nn.Sequential()\n        self.feature.add_module('f_conv1', nn.Conv2d(3, 64, kernel_size=5))\n        self.feature.add_module('f_bn1', nn.BatchNorm2d(64))\n        self.feature.add_module('f_pool1', nn.MaxPool2d(2))\n        self.feature.add_module('f_relu1', nn.ReLU(True))\n        self.feature.add_module('f_conv2', nn.Conv2d(64, 50, kernel_size=5))\n        self.feature.add_module('f_bn2', nn.BatchNorm2d(50))\n        self.feature.add_module('f_drop1', nn.Dropout2d())\n        self.feature.add_module('f_pool2', nn.MaxPool2d(2))\n        self.feature.add_module('f_relu2', nn.ReLU(True))\n\n        self.class_classifier = nn.Sequential()\n        self.class_classifier.add_module('c_fc1', nn.Linear(50 * 4 * 4, 100))\n        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(100))\n        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n        self.class_classifier.add_module('c_drop1', nn.Dropout2d())\n        self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))\n        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(100))\n        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n        self.class_classifier.add_module('c_fc3', nn.Linear(100, 10))\n        self.class_classifier.add_module('c_softmax', nn.LogSoftmax())\n\n        self.domain_classifier = nn.Sequential()\n        self.domain_classifier.add_module('d_fc1', nn.Linear(50 * 4 * 4, 100))\n        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n\n    def forward(self, input_data, alpha):\n        input_data = input_data.expand(input_data.data.shape[0], 3, 28, 28)\n        feature = self.feature(input_data)\n        feature = feature.view(-1, 50 * 4 * 4)\n        reverse_feature = ReverseLayerF.apply(feature, alpha)\n        class_output = self.class_classifier(feature)\n        domain_output = self.domain_classifier(reverse_feature)\n\n        return class_output, domain_output\n"""
train/__init__.py,0,b''
train/main.py,14,"b""import random\nimport os\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nfrom dataset.data_loader import GetLoader\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom models.model import CNNModel\nimport numpy as np\nfrom test import test\n\nsource_dataset_name = 'MNIST'\ntarget_dataset_name = 'mnist_m'\nsource_image_root = os.path.join('..', 'dataset', source_dataset_name)\ntarget_image_root = os.path.join('..', 'dataset', target_dataset_name)\nmodel_root = os.path.join('..', 'models')\ncuda = True\ncudnn.benchmark = True\nlr = 1e-3\nbatch_size = 128\nimage_size = 28\nn_epoch = 100\n\nmanual_seed = random.randint(1, 10000)\nrandom.seed(manual_seed)\ntorch.manual_seed(manual_seed)\n\n# load data\n\nimg_transform_source = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n])\n\nimg_transform_target = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n])\n\ndataset_source = datasets.MNIST(\n    root='../dataset',\n    train=True,\n    transform=img_transform_source,\n    download=True\n)\n\ndataloader_source = torch.utils.data.DataLoader(\n    dataset=dataset_source,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=8)\n\ntrain_list = os.path.join(target_image_root, 'mnist_m_train_labels.txt')\n\ndataset_target = GetLoader(\n    data_root=os.path.join(target_image_root, 'mnist_m_train'),\n    data_list=train_list,\n    transform=img_transform_target\n)\n\ndataloader_target = torch.utils.data.DataLoader(\n    dataset=dataset_target,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=8)\n\n# load model\n\nmy_net = CNNModel()\n\n# setup optimizer\n\noptimizer = optim.Adam(my_net.parameters(), lr=lr)\n\nloss_class = torch.nn.NLLLoss()\nloss_domain = torch.nn.NLLLoss()\n\nif cuda:\n    my_net = my_net.cuda()\n    loss_class = loss_class.cuda()\n    loss_domain = loss_domain.cuda()\n\nfor p in my_net.parameters():\n    p.requires_grad = True\n\n# training\n\nfor epoch in xrange(n_epoch):\n\n    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n    data_source_iter = iter(dataloader_source)\n    data_target_iter = iter(dataloader_target)\n\n    i = 0\n    while i < len_dataloader:\n\n        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n\n        # training model using source data\n        data_source = data_source_iter.next()\n        s_img, s_label = data_source\n\n        my_net.zero_grad()\n        batch_size = len(s_label)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        class_label = torch.LongTensor(batch_size)\n        domain_label = torch.zeros(batch_size)\n        domain_label = domain_label.long()\n\n        if cuda:\n            s_img = s_img.cuda()\n            s_label = s_label.cuda()\n            input_img = input_img.cuda()\n            class_label = class_label.cuda()\n            domain_label = domain_label.cuda()\n\n        input_img.resize_as_(s_img).copy_(s_img)\n        class_label.resize_as_(s_label).copy_(s_label)\n\n        class_output, domain_output = my_net(input_data=input_img, alpha=alpha)\n        err_s_label = loss_class(class_output, class_label)\n        err_s_domain = loss_domain(domain_output, domain_label)\n\n        # training model using target data\n        data_target = data_target_iter.next()\n        t_img, _ = data_target\n\n        batch_size = len(t_img)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        domain_label = torch.ones(batch_size)\n        domain_label = domain_label.long()\n\n        if cuda:\n            t_img = t_img.cuda()\n            input_img = input_img.cuda()\n            domain_label = domain_label.cuda()\n\n        input_img.resize_as_(t_img).copy_(t_img)\n\n        _, domain_output = my_net(input_data=input_img, alpha=alpha)\n        err_t_domain = loss_domain(domain_output, domain_label)\n        err = err_t_domain + err_s_domain + err_s_label\n        err.backward()\n        optimizer.step()\n\n        i += 1\n\n        print 'epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n              % (epoch, i, len_dataloader, err_s_label.cpu().data.numpy(),\n                 err_s_domain.cpu().data.numpy(), err_t_domain.cpu().data.numpy())\n\n    torch.save(my_net, '{0}/mnist_mnistm_model_epoch_{1}.pth'.format(model_root, epoch))\n    test(source_dataset_name, epoch)\n    test(target_dataset_name, epoch)\n\nprint 'done'\n"""
train/test.py,6,"b'import os\nimport torch.backends.cudnn as cudnn\nimport torch.utils.data\nfrom torchvision import transforms\nfrom dataset.data_loader import GetLoader\nfrom torchvision import datasets\n\n\ndef test(dataset_name, epoch):\n    assert dataset_name in [\'MNIST\', \'mnist_m\']\n\n    model_root = os.path.join(\'..\', \'models\')\n    image_root = os.path.join(\'..\', \'dataset\', dataset_name)\n\n    cuda = True\n    cudnn.benchmark = True\n    batch_size = 128\n    image_size = 28\n    alpha = 0\n\n    """"""load data""""""\n\n    img_transform_source = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n    ])\n\n    img_transform_target = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n    ])\n\n    if dataset_name == \'mnist_m\':\n        test_list = os.path.join(image_root, \'mnist_m_test_labels.txt\')\n\n        dataset = GetLoader(\n            data_root=os.path.join(image_root, \'mnist_m_test\'),\n            data_list=test_list,\n            transform=img_transform_target\n        )\n    else:\n        dataset = datasets.MNIST(\n            root=\'../dataset\',\n            train=False,\n            transform=img_transform_source,\n        )\n\n    dataloader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=8\n    )\n\n    """""" training """"""\n\n    my_net = torch.load(os.path.join(\n        model_root, \'mnist_mnistm_model_epoch_\' + str(epoch) + \'.pth\'\n    ))\n    my_net = my_net.eval()\n\n    if cuda:\n        my_net = my_net.cuda()\n\n    len_dataloader = len(dataloader)\n    data_target_iter = iter(dataloader)\n\n    i = 0\n    n_total = 0\n    n_correct = 0\n\n    while i < len_dataloader:\n\n        # test model using target data\n        data_target = data_target_iter.next()\n        t_img, t_label = data_target\n\n        batch_size = len(t_label)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        class_label = torch.LongTensor(batch_size)\n\n        if cuda:\n            t_img = t_img.cuda()\n            t_label = t_label.cuda()\n            input_img = input_img.cuda()\n            class_label = class_label.cuda()\n\n        input_img.resize_as_(t_img).copy_(t_img)\n        class_label.resize_as_(t_label).copy_(t_label)\n\n        class_output, _ = my_net(input_data=input_img, alpha=alpha)\n        pred = class_output.data.max(1, keepdim=True)[1]\n        n_correct += pred.eq(class_label.data.view_as(pred)).cpu().sum()\n        n_total += batch_size\n\n        i += 1\n\n    accu = n_correct.data.numpy() * 1.0 / n_total\n\n    print \'epoch: %d, accuracy of the %s dataset: %f\' % (epoch, dataset_name, accu)\n'"
