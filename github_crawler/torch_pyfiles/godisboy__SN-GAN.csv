file_path,api_count,code
test.py,29,"b'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\nimport torch.utils.data\nfrom torch.nn.modules import conv\nfrom torch.nn.modules.utils import _pair, _triple\nimport torch.backends.cudnn as cudnn\n\nimport random\nimport argparse\nimport os\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nparser = argparse.ArgumentParser(description=\'train SNDCGAN model\')\nparser.add_argument(\'--nz\', type=int, default=100, help=\'size of the latent z vector\')\nparser.add_argument(\'--cuda\', action=\'store_true\', help=\'enables cuda\')\nparser.add_argument(\'--gpu_ids\', default=[0,1,2,3], help=\'gpu ids: e.g. 0,1,2, 0,2.\')\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'--batchSize\', type=int, default=100, help=\'with batchSize=1 equivalent to instance normalization.\')\nparser.add_argument(\'--label_num\', type=int, default=200, help=\'number of labels.\')\nopt = parser.parse_args()\nprint(opt)\n\ndataset = datasets.ImageFolder(root=\'/media/scw4750/25a01ed5-a903-4298-87f2-a5836dcb6888/AIwalker/dataset/CUB200_object\',\n                           transform=transforms.Compose([\n                               transforms.Scale(64),\n                               transforms.CenterCrop(64),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ])\n                                      )\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=32,\n                                         shuffle=True, num_workers=int(2))\nif opt.manualSeed is None:\n    opt.manualSeed = random.randint(1, 10000)\nprint(""Random Seed: "", opt.manualSeed)\nrandom.seed(opt.manualSeed)\ntorch.manual_seed(opt.manualSeed)\n\nif opt.cuda:\n    torch.cuda.manual_seed_all(opt.manualSeed)\n    torch.cuda.set_device(opt.gpu_ids[2])\n\ncudnn.benchmark = True\n\ndef _l2normalize(v, eps=1e-12):\n    return v / (((v**2).sum())**0.5 + eps)\n\ndef max_singular_value(W, u=None, Ip=1):\n    """"""\n    power iteration for weight parameter\n    """"""\n    #xp = W.data\n    if u is None:\n        u = torch.FloatTensor(1, W.size(0)).normal_(0, 1).cuda()\n    _u = u\n    for _ in range(Ip):\n        #print(_u.size(), W.size())\n        _v = _l2normalize(torch.matmul(_u, W.data), eps=1e-12)\n        _u = _l2normalize(torch.matmul(_v, torch.transpose(W.data, 0, 1)), eps=1e-12)\n    sigma = torch.matmul(torch.matmul(_v, torch.transpose(W.data, 0, 1)), torch.transpose(_u, 0, 1))\n    return sigma, _v\n\nclass SNConv2d(conv._ConvNd):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n        kernel_size = _pair(kernel_size)\n        stride = _pair(stride)\n        padding = _pair(padding)\n        dilation = _pair(dilation)\n        super(SNConv2d, self).__init__(\n            in_channels, out_channels, kernel_size, stride, padding, dilation,\n            False, _pair(0), groups, bias)\n\n    def forward(self, input):\n        w_mat = self.weight.view(self.weight.size(0), -1)\n        sigma, _ = max_singular_value(w_mat)\n        #print(sigma.size())\n        self.weight.data = self.weight.data / sigma\n        #print(self.weight.data)\n        return F.conv2d(input, self.weight, self.bias, self.stride,\n                        self.padding, self.dilation, self.groups)\n\nclass _netG(nn.Module):\n    def __init__(self, nz, nc, ngf):\n        super(_netG, self).__init__()\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(nz+200, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output\n\nnz = opt.nz\n\nG = _netG(nz, 3, 64)\nprint(G)\nsave_path = \'log/netG_epoch_199.pth\'\nG.load_state_dict(torch.load(save_path))\n\ninput = torch.FloatTensor(opt.batchSize, 3, 64, 64)\nnoise = torch.FloatTensor(opt.batchSize, nz, 1, 1)\nlabel = torch.FloatTensor(opt.batchSize)\nreal_label = 1\nfake_label = 0\n\n#fixed label\nfix_label = torch.FloatTensor(opt.batchSize)\n\nfor i in range(0,100):\n    fix_label[i] = i;\n    #fix_label[i] = np.random.randint(1,200);\n\nfix = torch.LongTensor(opt.batchSize,1).copy_(fix_label)\nfix_onehot = torch.FloatTensor(opt.batchSize, 200)\nfix_onehot.zero_()\nfix_onehot.scatter_(1, fix, 1)\nfix_onehot.view(-1, 200, 1, 1)\n\nfixed_noise = torch.FloatTensor(opt.batchSize, nz, 1, 1).normal_(0, 1)\nfixed_input = torch.cat([fixed_noise, fix_onehot],1)\nfixed_input = Variable(fixed_input)\n\nprint(fixed_input.size())\ncriterion = nn.BCELoss()\n\nfill = torch.zeros([200, 200, 64, 64])\nfor i in range(200):\n    fill[i, i, :, :] = 1\n\nif opt.cuda:\n    G.cuda()\n    input, label = input.cuda(), label.cuda()\n    noise, fixed_input = noise.cuda(), fixed_input.cuda()\n\n#for i, data in enumerate(dataloader, 0):\n############################\n# (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n###########################\n# train with real\n#real_cpu, labels = data\nbatch_size = opt.batchSize\n#if opt.cuda:\n#    real_cpu = real_cpu.cuda()\n\'\'\'\ny = torch.LongTensor(batch_size, 1).copy_(labels)\ny_onehot = torch.zeros(batch_size, 200)\ny_onehot.scatter_(1, y, 1)\ny_onehot.view(-1, batch_size, 1, 1)\ny_onehot = Variable(y_onehot.cuda())\n\'\'\'\n# train with fake\nnoise.resize_(batch_size, 100, 1, 1).normal_(0, 1)\nnoisev = Variable(noise)\n#y_nz = torch.cat([noisev, y_onehot], 1)\nfake = G(fixed_input)\n\nvutils.save_image(fake.data,\n        \'%s/conditional_fake.png\' % (\'log\'),\n        normalize=True, nrow=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
train-conditional.py,29,"b'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\nimport torch.utils.data\nimport torch.backends.cudnn as cudnn\n\nimport random\nimport argparse\nfrom models.models import SNConv2d\nimport os\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nparser = argparse.ArgumentParser(description=\'train SNDCGAN model\')\nparser.add_argument(\'--nz\', type=int, default=100, help=\'size of the latent z vector\')\nparser.add_argument(\'--cuda\', action=\'store_true\', help=\'enables cuda\')\nparser.add_argument(\'--gpu_ids\', default=[0,1,2,3], help=\'gpu ids: e.g. 0,1,2, 0,2.\')\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'--batchSize\', type=int, default=32, help=\'with batchSize=1 equivalent to instance normalization.\')\nparser.add_argument(\'--label_num\', type=int, default=200, help=\'number of labels.\')\nopt = parser.parse_args()\nprint(opt)\n\ndataset = datasets.ImageFolder(root=\'/home/chao/Downloads/AwA2-data/train-tiny\',\n                           transform=transforms.Compose([\n                               transforms.Scale(64),\n                               transforms.CenterCrop(64),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ])\n                                      )\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=32,\n                                         shuffle=True, num_workers=int(2))\nif opt.manualSeed is None:\n    opt.manualSeed = random.randint(1, 10000)\nprint(""Random Seed: "", opt.manualSeed)\nrandom.seed(opt.manualSeed)\ntorch.manual_seed(opt.manualSeed)\n\nif opt.cuda:\n    torch.cuda.manual_seed_all(opt.manualSeed)\n    torch.cuda.set_device(opt.gpu_ids[0])\n\ncudnn.benchmark = True\n\ndef weight_filler(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Conv\') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find(\'BatchNorm\') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\nclass _netG(nn.Module):\n    def __init__(self, nz, nc, ngf):\n        super(_netG, self).__init__()\n\n        self.convT1 = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True)\n        )\n        self.convT2 = nn.Sequential(\n            nn.ConvTranspose2d(10, ngf * 4, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True)\n        )\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n    def forward(self, input, input_c):\n        out1 = self.convT1(input)\n        out2 = self.convT2(input_c)\n        output = torch.cat([out1, out2], 1)\n        output = self.main(output)\n\n        return output\n\nclass _netD(nn.Module):\n    def __init__(self, nc, ndf):\n        super(_netD, self).__init__()\n\n        self.conv1_1 = SNConv2d(nc, ndf/2, 3, 1, 1, bias=False)\n        self.conv1_2 = SNConv2d(10, ndf/2, 3, 1, 1, bias=False)\n        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n        self.main = nn.Sequential(\n            # input is (nc) x 64 x 64\n            SNConv2d(ndf, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            SNConv2d(ndf, ndf * 2, 3, 1, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            SNConv2d(ndf *2 , ndf * 2, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            SNConv2d(ndf * 2, ndf * 4, 3, 1, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            SNConv2d(ndf * 4, ndf * 4, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            SNConv2d(ndf * 4, ndf * 8, 3, 1, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            SNConv2d(ndf * 8, ndf * 8, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            SNConv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            #nn.LeakyReLU(0.2, inplace=True)\n            #nn.Softplus()\n        )\n\n    def forward(self, input, input_c):\n        out1 = self.lrelu(self.conv1_1(input))\n        out2 = self.lrelu(self.conv1_2(input_c))\n        output = torch.cat([out1, out2], 1)\n        output = self.main(output)\n        return output.view(-1, 1).squeeze(1)\n\nnz = opt.nz\n\nG = _netG(nz, 3, 64)\nSND = _netD(3, 64)\nprint(G)\nprint(SND)\nG.apply(weight_filler)\nSND.apply(weight_filler)\n\ninput = torch.FloatTensor(32, 3, 64, 64)\nnoise = torch.FloatTensor(32, nz, 1, 1)\nlabel = torch.FloatTensor(32)\nreal_label = 1\nfake_label = 0\n\n#fixed label\nfix_label = torch.FloatTensor(opt.batchSize, 1)\n\nfor i in range(0, 4):\n    #label_y = np.random.randint(1,200)\n    for j in range(0, 8):\n        fix_label[i*8+j] = j\n    #fix_label[i] = np.random.randint(1,200);\n\nfix = torch.LongTensor(32,1).copy_(fix_label)\nfix_onehot = torch.FloatTensor(opt.batchSize, 10)\nfix_onehot.zero_()\nfix_onehot.scatter_(1, fix, 1)\nfix_onehot = fix_onehot.view(-1, 10, 1, 1)\n\nfixed_noise = torch.FloatTensor(32, nz, 1, 1).normal_(0, 1)\n#fixed_input = torch.cat([fixed_noise, fix_onehot],1)\nfixed_noise, fix_onehot = Variable(fixed_noise), Variable(fix_onehot)\n\ncriterion = nn.BCELoss()\n\nfill = torch.zeros([10, 10, 64, 64])\nfor i in range(10):\n    fill[i, i, :, :] = 1\n\nif opt.cuda:\n    G.cuda()\n    SND.cuda()\n    criterion.cuda()\n    input, label = input.cuda(), label.cuda()\n    noise, fixed_noise, fix_onehot = noise.cuda(), fixed_noise.cuda(), fix_onehot.cuda()\n\noptimizerG = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerSND = optim.Adam(SND.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\nfor epoch in range(300):\n    for i, data in enumerate(dataloader, 0):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        SND.zero_grad()\n        real_cpu, labels = data\n        batch_size = real_cpu.size(0)\n        #if opt.cuda:\n        #    real_cpu = real_cpu.cuda()\n        y = torch.LongTensor(batch_size, 1).copy_(labels.view(-1, 1))\n        y_onehot = torch.zeros(batch_size, 10)\n        y_onehot.scatter_(1, y, 1)\n        y_onehot_v = y_onehot.view(batch_size, -1, 1, 1)\n        #print(y_onehot_v.size())\n        y_onehot_v = Variable(y_onehot_v.cuda())\n\n        y_fill = fill[labels]\n        y_fill = Variable(y_fill.cuda())\n\n        input.resize_(real_cpu.size()).copy_(real_cpu)\n        label.resize_(batch_size).fill_(real_label)\n        inputv = Variable(input)\n        labelv = Variable(label)\n        output = SND(inputv, y_fill)\n        #print(output)\n        errD_real = torch.mean(F.softplus(-output).mean())\n        #errD_real = criterion(output, labelv)\n        errD_real.backward()\n        D_x = output.data.mean()\n\n        # train with fake\n        noise.resize_(batch_size, 100, 1, 1).normal_(0, 1)\n        noisev = Variable(noise)\n        #y_nz = torch.cat([noisev, y_onehot], 1)\n        fake = G(noisev, y_onehot_v)\n        labelv = Variable(label.fill_(fake_label))\n        output = SND(fake.detach(), y_fill)\n        errD_fake = torch.mean(F.softplus(output))\n        #errD_fake = criterion(output, labelv)\n        errD_fake.backward()\n        D_G_z1 = output.data.mean()\n        errD = errD_real + errD_fake\n        optimizerSND.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        G.zero_grad()\n        labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost\n        output = SND(fake, y_fill)\n        errG = torch.mean(F.softplus(-output))\n        #errG = criterion(output, labelv)\n        errG.backward()\n        D_G_z2 = output.data.mean()\n        optimizerG.step()\n        if i % 20 == 0:\n            print(\'[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f\'\n                  % (epoch, 200, i, len(dataloader),\n                     errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n        if i % 100 == 0:\n            vutils.save_image(real_cpu,\n                    \'%s/real_samples.png\' % \'log\',\n                    normalize=True)\n            fake = G(fixed_noise, fix_onehot)\n            vutils.save_image(fake.data,\n                    \'%s/fake_samples_epoch_%03d.png\' % (\'log\', epoch),\n                    normalize=True)\n\n    # do checkpointing\ntorch.save(G.state_dict(), \'%s/netG_epoch_%d.pth\' % (\'log\', epoch))\ntorch.save(SND.state_dict(), \'%s/netD_epoch_%d.pth\' % (\'log\', epoch))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
train-res.py,19,"b'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\nimport torch.utils.data\nimport torch.backends.cudnn as cudnn\n\nimport random\nimport argparse\nfrom models.snres_generator import SNResGenerator\nfrom models.snres_discriminator import SNResDiscriminator\n\nparser = argparse.ArgumentParser(description=\'train SNDCGAN model\')\nparser.add_argument(\'--dataPath\', required=True, help=\'path to dataset\')\nparser.add_argument(\'--cuda\', action=\'store_true\', help=\'enables cuda\')\nparser.add_argument(\'--gpu_ids\', default=[0,1,2,3], help=\'gpu ids: e.g. 0,1,2, 0,2.\')\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'--n_dis\', type=int, default=1, help=\'discriminator critic iters\')\nparser.add_argument(\'--nz\', type=int, default=128, help=\'dimention of lantent noise\')\nparser.add_argument(\'--batchsize\', type=int, default=32, help=\'training batch size\')\n\n\nopt = parser.parse_args()\nprint(opt)\n\ndataset = datasets.ImageFolder(root=opt.dataPath,\n                           transform=transforms.Compose([\n                               transforms.Scale(64),\n                               transforms.CenterCrop(64),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ])\n                                      )\n\'\'\'\ndataset = datasets.CIFAR10(root=\'dataset\', download=True,\n                           transform=transforms.Compose([\n                               transforms.Scale(32),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n]))\n\'\'\'\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchsize,\n                                         shuffle=True, num_workers=int(2))\n\nif opt.manualSeed is None:\n    opt.manualSeed = random.randint(1, 10000)\nprint(""Random Seed: "", opt.manualSeed)\nrandom.seed(opt.manualSeed)\ntorch.manual_seed(opt.manualSeed)\n\nif opt.cuda:\n    torch.cuda.manual_seed_all(opt.manualSeed)\n    torch.cuda.set_device(opt.gpu_ids[0])\n\ncudnn.benchmark = True\n\ndef weight_filler(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Conv\' or \'SNConv\') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find(\'BatchNorm\') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\nn_dis = opt.n_dis\nnz = opt.nz\n\nG = SNResGenerator(64, nz, 4)\nSND = SNResDiscriminator(64, 4)\nprint(G)\nprint(SND)\nG.apply(weight_filler)\nSND.apply(weight_filler)\n\ninput = torch.FloatTensor(opt.batchsize, 3, 64, 64)\nnoise = torch.FloatTensor(opt.batchsize, nz)\nfixed_noise = torch.FloatTensor(opt.batchsize, nz).normal_(0, 1)\nlabel = torch.FloatTensor(opt.batchsize)\nreal_label = 1\nfake_label = 0\n\nfixed_noise = Variable(fixed_noise)\ncriterion = nn.BCELoss()\n\nif opt.cuda:\n    G.cuda()\n    SND.cuda()\n    criterion.cuda()\n    input, label = input.cuda(), label.cuda()\n    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n\noptimizerG = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerSND = optim.Adam(SND.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\nfor epoch in range(200):\n    for i, data in enumerate(dataloader, 0):\n        step = epoch * len(dataloader) + i\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        SND.zero_grad()\n        real_cpu, _ = data\n        batch_size = real_cpu.size(0)\n        #if opt.cuda:\n        #    real_cpu = real_cpu.cuda()\n        input.resize_(real_cpu.size()).copy_(real_cpu)\n        label.resize_(batch_size).fill_(real_label)\n        inputv = Variable(input)\n        labelv = Variable(label)\n        output = SND(inputv)\n\n        #errD_real = torch.mean(F.softplus(-output))\n        errD_real = criterion(output, labelv)\n        errD_real.backward()\n\n        D_x = output.data.mean()\n        # train with fake\n        noise.resize_(batch_size, nz).normal_(0, 1)\n        noisev = Variable(noise)\n        fake = G(noisev)\n        labelv = Variable(label.fill_(fake_label))\n        output = SND(fake.detach())\n        #errD_fake = torch.mean(F.softplus(output))\n        errD_fake = criterion(output, labelv)\n        errD_fake.backward()\n        D_G_z1 = output.data.mean()\n        errD = errD_real + errD_fake\n\n        optimizerSND.step()\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        if step % n_dis == 0:\n            G.zero_grad()\n            labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost\n            output = SND(fake)\n            #errG = torch.mean(F.softplus(-output))\n            errG = criterion(output, labelv)\n            errG.backward()\n            D_G_z2 = output.data.mean()\n            optimizerG.step()\n        if i % 20 == 0:\n            print(\'[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f\'\n                  % (epoch, 200, i, len(dataloader),\n                     errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n        if i % 100 == 0:\n            vutils.save_image(real_cpu,\n                    \'%s/real_samples.png\' % \'log\',\n                    normalize=True)\n            fake = G(fixed_noise)\n            vutils.save_image(fake.data,\n                    \'%s/fake_samples_epoch_%03d.png\' % (\'log\', epoch),\n                    normalize=True)\n\n    # do checkpointing\ntorch.save(G.state_dict(), \'%s/netG_epoch_%d.pth\' % (\'log\', epoch))\ntorch.save(SND.state_dict(), \'%s/netD_epoch_%d.pth\' % (\'log\', epoch))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
train.py,19,"b'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\nimport torch.utils.data\nimport torch.backends.cudnn as cudnn\n\nimport random\nimport argparse\nfrom models.models import _netG, _netD\n\nparser = argparse.ArgumentParser(description=\'train SNDCGAN model\')\nparser.add_argument(\'--cuda\', action=\'store_true\', help=\'enables cuda\')\nparser.add_argument(\'--gpu_ids\', default=[0,1,2,3], help=\'gpu ids: e.g. 0,1,2, 0,2.\')\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nparser.add_argument(\'--n_dis\', type=int, default=1, help=\'discriminator critic iters\')\nparser.add_argument(\'--nz\', type=int, default=128, help=\'dimention of lantent noise\')\nparser.add_argument(\'--batchsize\', type=int, default=64, help=\'training batch size\')\n\nopt = parser.parse_args()\nprint(opt)\n\n# dataset = datasets.ImageFolder(root=\'/home/chao/zero/datasets/cfp-dataset/Data/Images\',\n#                            transform=transforms.Compose([\n#                                transforms.Scale(32),\n#                                transforms.CenterCrop(32),\n#                                transforms.ToTensor(),\n#                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n#                            ])\n#                                       )\n\ndataset = datasets.CIFAR10(root=\'dataset\', download=True,\n                           transform=transforms.Compose([\n                               transforms.Scale(32),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n]))\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchsize,\n                                         shuffle=True, num_workers=int(2))\n\nif opt.manualSeed is None:\n    opt.manualSeed = random.randint(1, 10000)\nprint(""Random Seed: "", opt.manualSeed)\nrandom.seed(opt.manualSeed)\ntorch.manual_seed(opt.manualSeed)\n\nif opt.cuda:\n    torch.cuda.manual_seed_all(opt.manualSeed)\n    torch.cuda.set_device(opt.gpu_ids[0])\n\ncudnn.benchmark = True\n\ndef weight_filler(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Conv\' or \'SNConv\') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find(\'BatchNorm\') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\nn_dis = opt.n_dis\nnz = opt.nz\n\nG = _netG(nz, 3, 64)\nSND = _netD(3, 64)\nprint(G)\nprint(SND)\nG.apply(weight_filler)\nSND.apply(weight_filler)\n\ninput = torch.FloatTensor(opt.batchsize, 3, 32, 32)\nnoise = torch.FloatTensor(opt.batchsize, nz, 1, 1)\nfixed_noise = torch.FloatTensor(opt.batchsize, nz, 1, 1).normal_(0, 1)\nlabel = torch.FloatTensor(opt.batchsize)\nreal_label = 1\nfake_label = 0\n\nfixed_noise = Variable(fixed_noise)\ncriterion = nn.BCELoss()\n\nif opt.cuda:\n    G.cuda()\n    SND.cuda()\n    criterion.cuda()\n    input, label = input.cuda(), label.cuda()\n    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n\noptimizerG = optim.Adam(G.parameters(), lr=0.0002, betas=(0, 0.9))\noptimizerSND = optim.Adam(SND.parameters(), lr=0.0002, betas=(0, 0.9))\n\nfor epoch in range(200):\n    for i, data in enumerate(dataloader, 0):\n        step = epoch * len(dataloader) + i\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        SND.zero_grad()\n        real_cpu, _ = data\n        batch_size = real_cpu.size(0)\n        #if opt.cuda:\n        #    real_cpu = real_cpu.cuda()\n        input.resize_(real_cpu.size()).copy_(real_cpu)\n        label.resize_(batch_size).fill_(real_label)\n        inputv = Variable(input)\n        labelv = Variable(label)\n        output = SND(inputv)\n\n        #errD_real = torch.mean(F.softplus(-output))\n        errD_real = criterion(output, labelv)\n        errD_real.backward()\n\n        D_x = output.data.mean()\n        # train with fake\n        noise.resize_(batch_size, noise.size(1), noise.size(2), noise.size(3)).normal_(0, 1)\n        noisev = Variable(noise)\n        fake = G(noisev)\n        labelv = Variable(label.fill_(fake_label))\n        output = SND(fake.detach())\n        #errD_fake = torch.mean(F.softplus(output))\n        errD_fake = criterion(output, labelv)\n        errD_fake.backward()\n        D_G_z1 = output.data.mean()\n        errD = errD_real + errD_fake\n\n        optimizerSND.step()\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        if step % n_dis == 0:\n            G.zero_grad()\n            labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost\n            output = SND(fake)\n            #errG = torch.mean(F.softplus(-output))\n            errG = criterion(output, labelv)\n            errG.backward()\n            D_G_z2 = output.data.mean()\n            optimizerG.step()\n        if i % 20 == 0:\n            print(\'[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f\'\n                  % (epoch, 200, i, len(dataloader),\n                     errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n        if i % 100 == 0:\n            vutils.save_image(real_cpu,\n                    \'%s/real_samples.png\' % \'log\',\n                    normalize=True)\n            fake = G(fixed_noise)\n            vutils.save_image(fake.data,\n                    \'%s/fake_samples_epoch_%03d.png\' % (\'log\', epoch),\n                    normalize=True)\n\n    # do checkpointing\ntorch.save(G.state_dict(), \'%s/netG_epoch_%d.pth\' % (\'log\', epoch))\ntorch.save(SND.state_dict(), \'%s/netD_epoch_%d.pth\' % (\'log\', epoch))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
models/__init__.py,0,b''
models/models.py,3,"b'import torch.nn as nn\nimport torch\nfrom torch.nn.modules import conv, Linear\nimport torch.nn.functional as F\nfrom src.snlayers.snconv2d import SNConv2d\n\nclass _netG(nn.Module):\n    def __init__(self, nz, nc, ngf):\n        super(_netG, self).__init__()\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=True),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=True),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=True),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=True),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d(ngf, nc, 3, 1, 1, bias=True),\n            nn.Tanh()\n            # state size. (nc) x 32 x 32\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output\n\nclass _netD(nn.Module):\n    def __init__(self, nc, ndf):\n        super(_netD, self).__init__()\n\n        self.main = nn.Sequential(\n            # input is (nc) x 32 x 32\n            #SNConv2d()\n            SNConv2d(nc, ndf, 3, 1, 1, bias=True),\n            nn.LeakyReLU(0.1, inplace=True),\n            SNConv2d(ndf, ndf, 4, 2, 1, bias=True),\n            nn.LeakyReLU(0.1, inplace=True),\n            # state size. (ndf) x 1 x 32\n            SNConv2d(ndf, ndf * 2, 3, 1, 1, bias=True),\n            nn.LeakyReLU(0.1, inplace=True),\n            SNConv2d(ndf*2, ndf * 2, 4, 2, 1, bias=True),\n            #nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.1, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            SNConv2d(ndf * 2, ndf * 4, 3, 1, 1, bias=True),\n            nn.LeakyReLU(0.1, inplace=True),\n            SNConv2d(ndf * 4, ndf * 4, 4, 2, 1, bias=True),\n            nn.LeakyReLU(0.1, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            SNConv2d(ndf * 4, ndf * 8, 3, 1, 1, bias=True),\n            nn.LeakyReLU(0.1, inplace=True),\n            SNConv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n        #self.snlinear = nn.Sequential(SNLinear(ndf * 4 * 4 * 4, 1),\n        #                              nn.Sigmoid())\n\n    def forward(self, input):\n        output = self.main(input)\n        #output = output.view(output.size(0), -1)\n        #output = self.snlinear(output)\n        return output.view(-1, 1).squeeze(1)'"
models/snres_discriminator.py,2,"b'import torch.nn as nn\nfrom src.snlayers.snconv2d import SNConv2d\nfrom src.snlayers.snlinear import SNLinear\nimport torch.nn.functional as F\n\nclass ResBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, hidden_channels=None, use_BN = False, downsample=False):\n        super(ResBlock, self).__init__()\n        #self.conv1 = SNConv2d(n_dim, n_out, kernel_size=3, stride=2)\n        hidden_channels = in_channels\n        self.downsample = downsample\n\n        self.resblock = self.make_res_block(in_channels, out_channels, hidden_channels, use_BN, downsample)\n        self.residual_connect = self.make_residual_connect(in_channels, out_channels)\n    def make_res_block(self, in_channels, out_channels, hidden_channels, use_BN, downsample):\n        model = []\n        if use_BN:\n            model += [nn.BatchNorm2d(in_channels)]\n\n        model += [nn.ReLU()]\n        model += [SNConv2d(in_channels, hidden_channels, kernel_size=3, padding=1)]\n        model += [nn.ReLU()]\n        model += [SNConv2d(hidden_channels, out_channels, kernel_size=3, padding=1)]\n        if downsample:\n            model += [nn.AvgPool2d(2)]\n        return nn.Sequential(*model)\n    def make_residual_connect(self, in_channels, out_channels):\n        model = []\n        model += [SNConv2d(in_channels, out_channels, kernel_size=1, padding=0)]\n        if self.downsample:\n            model += [nn.AvgPool2d(2)]\n            return nn.Sequential(*model)\n        else:\n            return nn.Sequential(*model)\n\n    def forward(self, input):\n        return self.resblock(input) + self.residual_connect(input)\n\nclass OptimizedBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OptimizedBlock, self).__init__()\n        self.res_block = self.make_res_block(in_channels, out_channels)\n        self.residual_connect = self.make_residual_connect(in_channels, out_channels)\n    def make_res_block(self, in_channels, out_channels):\n        model = []\n        model += [SNConv2d(in_channels, out_channels, kernel_size=3, padding=1)]\n        model += [nn.ReLU()]\n        model += [SNConv2d(out_channels, out_channels, kernel_size=3, padding=1)]\n        model += [nn.AvgPool2d(2)]\n        return nn.Sequential(*model)\n    def make_residual_connect(self, in_channels, out_channels):\n        model = []\n        model += [SNConv2d(in_channels, out_channels, kernel_size=1, padding=0)]\n        model += [nn.AvgPool2d(2)]\n        return nn.Sequential(*model)\n    def forward(self, input):\n        return self.res_block(input) + self.residual_connect(input)\n\nclass SNResDiscriminator(nn.Module):\n    def __init__(self, ndf=64, ndlayers=4):\n        super(SNResDiscriminator, self).__init__()\n        self.res_d = self.make_model(ndf, ndlayers)\n        self.fc = nn.Sequential(SNLinear(ndf*16, 1), nn.Sigmoid())\n    def make_model(self, ndf, ndlayers):\n        model = []\n        model += [OptimizedBlock(3, ndf)]\n        tndf = ndf\n        for i in range(ndlayers):\n            model += [ResBlock(tndf, tndf*2, downsample=True)]\n            tndf *= 2\n        model += [nn.ReLU()]\n        return nn.Sequential(*model)\n    def forward(self, input):\n        out = self.res_d(input)\n        out = F.avg_pool2d(out, out.size(3), stride=1)\n        out = out.view(-1, 1024)\n        return self.fc(out)\n'"
models/snres_generator.py,2,"b'import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass ResBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, hidden_channels=None, upsample=False):\n        super(ResBlock, self).__init__()\n        #self.conv1 = SNConv2d(n_dim, n_out, kernel_size=3, stride=2)\n        hidden_channels = in_channels\n        self.upsample = upsample\n        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(hidden_channels, out_channels, kernel_size=3, padding=1)\n        self.conv_sc = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n        self.upsampling = nn.UpsamplingBilinear2d(scale_factor=2)\n        self.bn1 = nn.BatchNorm2d(in_channels)\n        self.bn2 = nn.BatchNorm2d(hidden_channels)\n        self.relu = nn.ReLU()\n    def forward_residual_connect(self, input):\n        out = self.conv_sc(input)\n        if self.upsample:\n             out = self.upsampling(out)\n            #out = self.upconv2(out)\n        return out\n    def forward(self, input):\n        out = self.relu(self.bn1(input))\n        out = self.conv1(out)\n        if self.upsample:\n             out = self.upsampling(out)\n             #out = self.upconv1(out)\n        out = self.relu(self.bn2(out))\n        out = self.conv2(out)\n        out_res = self.forward_residual_connect(input)\n        return out + out_res\n\nclass SNResGenerator(nn.Module):\n    def __init__(self, ngf, z=128, nlayers=4):\n        super(SNResGenerator, self).__init__()\n        self.input_layer = nn.Linear(z, (4 ** 2) * ngf * 16)\n        self.generator = self.make_model(ngf, nlayers)\n\n    def make_model(self, ngf, nlayers):\n        model = []\n        tngf = ngf*16\n        for i in range(nlayers):\n            model += [ResBlock(tngf, tngf/2, upsample=True)]\n            tngf /= 2\n        model += [nn.BatchNorm2d(ngf)]\n        model += [nn.ReLU()]\n        model += [nn.Conv2d(ngf, 3, kernel_size=3, stride=1, padding=1)]\n        model += [nn.Tanh()]\n        return nn.Sequential(*model)\n\n    def forward(self, z):\n        out = self.input_layer(z)\n        out = out.view(z.size(0), -1, 4, 4)\n        out = self.generator(out)\n\n        return out'"
src/__init__.py,0,b''
src/functions/__init__.py,0,b''
src/functions/max_sv.py,6,"b'import torch\nimport torch.nn.functional as F\n\n#define _l2normalization\ndef _l2normalize(v, eps=1e-12):\n    return v / (torch.norm(v) + eps)\n\ndef max_singular_value(W, u=None, Ip=1):\n    """"""\n    power iteration for weight parameter\n    """"""\n    #xp = W.data\n    if not Ip >= 1:\n        raise ValueError(""Power iteration should be a positive integer"")\n    if u is None:\n        u = torch.FloatTensor(1, W.size(0)).normal_(0, 1).cuda()\n    _u = u\n    for _ in range(Ip):\n        _v = _l2normalize(torch.matmul(_u, W.data), eps=1e-12)\n        _u = _l2normalize(torch.matmul(_v, torch.transpose(W.data, 0, 1)), eps=1e-12)\n    sigma = torch.sum(F.linear(_u, torch.transpose(W.data, 0, 1)) * _v)\n    return sigma, _u\n'"
src/snlayers/__init__.py,0,b''
src/snlayers/snconv2d.py,5,"b'# coding=utf-8\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.modules import conv\nfrom torch.nn.modules.utils import _pair\nfrom ..functions.max_sv import max_singular_value\n\nclass SNConv2d(conv._ConvNd):\n\n    r""""""Applies a 2D convolution over an input signal composed of several input\n    planes.\n\n    In the simplest case, the output value of the layer with input size\n    :math:`(N, C_{in}, H, W)` and output :math:`(N, C_{out}, H_{out}, W_{out})`\n    can be precisely described as:\n\n    .. math::\n\n        \\begin{array}{ll}\n        out(N_i, C_{out_j})  = bias(C_{out_j})\n                       + \\sum_{{k}=0}^{C_{in}-1} weight(C_{out_j}, k)  \\star input(N_i, k)\n        \\end{array}\n\n    where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n    :math:`N` is a batch size, :math:`C` denotes a number of channels,\n    :math:`H` is a height of input planes in pixels, and :math:`W` is\n    width in pixels.\n\n    | :attr:`stride` controls the stride for the cross-correlation, a single\n      number or a tuple.\n    | :attr:`padding` controls the amount of implicit zero-paddings on both\n    |  sides for :attr:`padding` number of points for each dimension.\n    | :attr:`dilation` controls the spacing between the kernel points; also\n      known as the \xc3\xa0 trous algorithm. It is harder to describe, but this `link`_\n      has a nice visualization of what :attr:`dilation` does.\n    | :attr:`groups` controls the connections between inputs and outputs.\n      `in_channels` and `out_channels` must both be divisible by `groups`.\n    |       At groups=1, all inputs are convolved to all outputs.\n    |       At groups=2, the operation becomes equivalent to having two conv\n                 layers side by side, each seeing half the input channels,\n                 and producing half the output channels, and both subsequently\n                 concatenated.\n            At groups=`in_channels`, each input channel is convolved with its\n                 own set of filters (of size `out_channels // in_channels`).\n\n    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n\n        - a single ``int`` -- in which case the same value is used for the height and width dimension\n        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n          and the second `int` for the width dimension\n\n    .. note::\n\n         Depending of the size of your kernel, several (of the last)\n         columns of the input might be lost, because it is a valid `cross-correlation`_,\n         and not a full `cross-correlation`_.\n         It is up to the user to add proper padding.\n\n    .. note::\n\n         The configuration when `groups == in_channels` and `out_channels = K * in_channels`\n         where `K` is a positive integer is termed in literature as depthwise convolution.\n\n         In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`, if you want a\n         depthwise convolution with a depthwise multiplier `K`,\n         then you use the constructor arguments\n         :math:`(in\\_channels=C_{in}, out\\_channels=C_{in} * K, ..., groups=C_{in})`\n\n    Args:\n        in_channels (int): Number of channels in the input image\n        out_channels (int): Number of channels produced by the convolution\n        kernel_size (int or tuple): Size of the convolving kernel\n        stride (int or tuple, optional): Stride of the convolution. Default: 1\n        padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n\n    Shape:\n        - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n          :math:`H_{out} = floor((H_{in}  + 2 * padding[0] - dilation[0] * (kernel\\_size[0] - 1) - 1) / stride[0] + 1)`\n          :math:`W_{out} = floor((W_{in}  + 2 * padding[1] - dilation[1] * (kernel\\_size[1] - 1) - 1) / stride[1] + 1)`\n\n    Attributes:\n        weight (Tensor): the learnable weights of the module of shape\n                         (out_channels, in_channels, kernel_size[0], kernel_size[1])\n        bias (Tensor):   the learnable bias of the module of shape (out_channels)\n\n        W(Tensor): Spectrally normalized weight\n\n        u (Tensor): the right largest singular value of W.\n\n    .. _cross-correlation:\n        https://en.wikipedia.org/wiki/Cross-correlation\n\n    .. _link:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n    """"""\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n        kernel_size = _pair(kernel_size)\n        stride = _pair(stride)\n        padding = _pair(padding)\n        dilation = _pair(dilation)\n        super(SNConv2d, self).__init__(\n            in_channels, out_channels, kernel_size, stride, padding, dilation,\n            False, _pair(0), groups, bias)\n        self.register_buffer(\'u\', torch.Tensor(1, out_channels).normal_())\n\n    @property\n    def W_(self):\n        w_mat = self.weight.view(self.weight.size(0), -1)\n        sigma, _u = max_singular_value(w_mat, self.u)\n        self.u.copy_(_u)\n        return self.weight / sigma\n\n    def forward(self, input):\n        return F.conv2d(input, self.W_, self.bias, self.stride,\n                        self.padding, self.dilation, self.groups)\n'"
src/snlayers/snlinear.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.modules import Linear\nfrom ..functions.max_sv import max_singular_value\n\nclass SNLinear(Linear):\n    r""""""Applies a linear transformation to the incoming data: :math:`y = Ax + b`\n       Args:\n           in_features: size of each input sample\n           out_features: size of each output sample\n           bias: If set to False, the layer will not learn an additive bias.\n               Default: ``True``\n       Shape:\n           - Input: :math:`(N, *, in\\_features)` where :math:`*` means any number of\n             additional dimensions\n           - Output: :math:`(N, *, out\\_features)` where all but the last dimension\n             are the same shape as the input.\n       Attributes:\n           weight: the learnable weights of the module of shape\n               `(out_features x in_features)`\n           bias:   the learnable bias of the module of shape `(out_features)`\n\n           W(Tensor): Spectrally normalized weight\n\n           u (Tensor): the right largest singular value of W.\n       """"""\n    def __init__(self, in_features, out_features, bias=True):\n        super(SNLinear, self).__init__(in_features, out_features, bias)\n        self.register_buffer(\'u\', torch.Tensor(1, out_features).normal_())\n\n    @property\n    def W_(self):\n        w_mat = self.weight.view(self.weight.size(0), -1)\n        sigma, _u = max_singular_value(w_mat, self.u)\n        self.u.copy_(_u)\n        return self.weight / sigma\n\n    def forward(self, input):\n        return F.linear(input, self.W_, self.bias)\n'"
