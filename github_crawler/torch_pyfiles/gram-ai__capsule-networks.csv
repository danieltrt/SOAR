file_path,api_count,code
capsule_network.py,16,"b'""""""\nDynamic Routing Between Capsules\nhttps://arxiv.org/abs/1710.09829\n\nPyTorch implementation by Kenta Iwasaki @ Gram.AI.\n""""""\nimport sys\nsys.setrecursionlimit(15000)\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nimport numpy as np\n\nBATCH_SIZE = 100\nNUM_CLASSES = 10\nNUM_EPOCHS = 500\nNUM_ROUTING_ITERATIONS = 3\n\n\ndef softmax(input, dim=1):\n    transposed_input = input.transpose(dim, len(input.size()) - 1)\n    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)), dim=-1)\n    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input.size()) - 1)\n\n\ndef augmentation(x, max_shift=2):\n    _, _, height, width = x.size()\n\n    h_shift, w_shift = np.random.randint(-max_shift, max_shift + 1, size=2)\n    source_height_slice = slice(max(0, h_shift), h_shift + height)\n    source_width_slice = slice(max(0, w_shift), w_shift + width)\n    target_height_slice = slice(max(0, -h_shift), -h_shift + height)\n    target_width_slice = slice(max(0, -w_shift), -w_shift + width)\n\n    shifted_image = torch.zeros(*x.size())\n    shifted_image[:, :, source_height_slice, source_width_slice] = x[:, :, target_height_slice, target_width_slice]\n    return shifted_image.float()\n\n\nclass CapsuleLayer(nn.Module):\n    def __init__(self, num_capsules, num_route_nodes, in_channels, out_channels, kernel_size=None, stride=None,\n                 num_iterations=NUM_ROUTING_ITERATIONS):\n        super(CapsuleLayer, self).__init__()\n\n        self.num_route_nodes = num_route_nodes\n        self.num_iterations = num_iterations\n\n        self.num_capsules = num_capsules\n\n        if num_route_nodes != -1:\n            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_route_nodes, in_channels, out_channels))\n        else:\n            self.capsules = nn.ModuleList(\n                [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) for _ in\n                 range(num_capsules)])\n\n    def squash(self, tensor, dim=-1):\n        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n        scale = squared_norm / (1 + squared_norm)\n        return scale * tensor / torch.sqrt(squared_norm)\n\n    def forward(self, x):\n        if self.num_route_nodes != -1:\n            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n\n            logits = Variable(torch.zeros(*priors.size())).cuda()\n            for i in range(self.num_iterations):\n                probs = softmax(logits, dim=2)\n                outputs = self.squash((probs * priors).sum(dim=2, keepdim=True))\n\n                if i != self.num_iterations - 1:\n                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n                    logits = logits + delta_logits\n        else:\n            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n            outputs = torch.cat(outputs, dim=-1)\n            outputs = self.squash(outputs)\n\n        return outputs\n\n\nclass CapsuleNet(nn.Module):\n    def __init__(self):\n        super(CapsuleNet, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n        self.primary_capsules = CapsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=32,\n                                             kernel_size=9, stride=2)\n        self.digit_capsules = CapsuleLayer(num_capsules=NUM_CLASSES, num_route_nodes=32 * 6 * 6, in_channels=8,\n                                           out_channels=16)\n\n        self.decoder = nn.Sequential(\n            nn.Linear(16 * NUM_CLASSES, 512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, 1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024, 784),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x, y=None):\n        x = F.relu(self.conv1(x), inplace=True)\n        x = self.primary_capsules(x)\n        x = self.digit_capsules(x).squeeze().transpose(0, 1)\n\n        classes = (x ** 2).sum(dim=-1) ** 0.5\n        classes = F.softmax(classes, dim=-1)\n\n        if y is None:\n            # In all batches, get the most active capsule.\n            _, max_length_indices = classes.max(dim=1)\n            y = Variable(torch.eye(NUM_CLASSES)).cuda().index_select(dim=0, index=max_length_indices.data)\n\n        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n\n        return classes, reconstructions\n\n\nclass CapsuleLoss(nn.Module):\n    def __init__(self):\n        super(CapsuleLoss, self).__init__()\n        self.reconstruction_loss = nn.MSELoss(size_average=False)\n\n    def forward(self, images, labels, classes, reconstructions):\n        left = F.relu(0.9 - classes, inplace=True) ** 2\n        right = F.relu(classes - 0.1, inplace=True) ** 2\n\n        margin_loss = labels * left + 0.5 * (1. - labels) * right\n        margin_loss = margin_loss.sum()\n\n        assert torch.numel(images) == torch.numel(reconstructions)\n        images = images.view(reconstructions.size()[0], -1)\n        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n\n        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)\n\n\nif __name__ == ""__main__"":\n    from torch.autograd import Variable\n    from torch.optim import Adam\n    from torchnet.engine import Engine\n    from torchnet.logger import VisdomPlotLogger, VisdomLogger\n    from torchvision.utils import make_grid\n    from torchvision.datasets.mnist import MNIST\n    from tqdm import tqdm\n    import torchnet as tnt\n\n    model = CapsuleNet()\n    # model.load_state_dict(torch.load(\'epochs/epoch_327.pt\'))\n    model.cuda()\n\n    print(""# parameters:"", sum(param.numel() for param in model.parameters()))\n\n    optimizer = Adam(model.parameters())\n\n    engine = Engine()\n    meter_loss = tnt.meter.AverageValueMeter()\n    meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n    confusion_meter = tnt.meter.ConfusionMeter(NUM_CLASSES, normalized=True)\n\n    train_loss_logger = VisdomPlotLogger(\'line\', opts={\'title\': \'Train Loss\'})\n    train_error_logger = VisdomPlotLogger(\'line\', opts={\'title\': \'Train Accuracy\'})\n    test_loss_logger = VisdomPlotLogger(\'line\', opts={\'title\': \'Test Loss\'})\n    test_accuracy_logger = VisdomPlotLogger(\'line\', opts={\'title\': \'Test Accuracy\'})\n    confusion_logger = VisdomLogger(\'heatmap\', opts={\'title\': \'Confusion matrix\',\n                                                     \'columnnames\': list(range(NUM_CLASSES)),\n                                                     \'rownames\': list(range(NUM_CLASSES))})\n    ground_truth_logger = VisdomLogger(\'image\', opts={\'title\': \'Ground Truth\'})\n    reconstruction_logger = VisdomLogger(\'image\', opts={\'title\': \'Reconstruction\'})\n\n    capsule_loss = CapsuleLoss()\n\n\n    def get_iterator(mode):\n        dataset = MNIST(root=\'./data\', download=True, train=mode)\n        data = getattr(dataset, \'train_data\' if mode else \'test_data\')\n        labels = getattr(dataset, \'train_labels\' if mode else \'test_labels\')\n        tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n\n        return tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode)\n\n\n    def processor(sample):\n        data, labels, training = sample\n\n        data = augmentation(data.unsqueeze(1).float() / 255.0)\n        labels = torch.LongTensor(labels)\n\n        labels = torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n\n        data = Variable(data).cuda()\n        labels = Variable(labels).cuda()\n\n        if training:\n            classes, reconstructions = model(data, labels)\n        else:\n            classes, reconstructions = model(data)\n\n        loss = capsule_loss(data, labels, classes, reconstructions)\n\n        return loss, classes\n\n\n    def reset_meters():\n        meter_accuracy.reset()\n        meter_loss.reset()\n        confusion_meter.reset()\n\n\n    def on_sample(state):\n        state[\'sample\'].append(state[\'train\'])\n\n\n    def on_forward(state):\n        meter_accuracy.add(state[\'output\'].data, torch.LongTensor(state[\'sample\'][1]))\n        confusion_meter.add(state[\'output\'].data, torch.LongTensor(state[\'sample\'][1]))\n        meter_loss.add(state[\'loss\'].item())\n\n\n    def on_start_epoch(state):\n        reset_meters()\n        state[\'iterator\'] = tqdm(state[\'iterator\'])\n\n\n    def on_end_epoch(state):\n        print(\'[Epoch %d] Training Loss: %.4f (Accuracy: %.2f%%)\' % (\n            state[\'epoch\'], meter_loss.value()[0], meter_accuracy.value()[0]))\n\n        train_loss_logger.log(state[\'epoch\'], meter_loss.value()[0])\n        train_error_logger.log(state[\'epoch\'], meter_accuracy.value()[0])\n\n        reset_meters()\n\n        engine.test(processor, get_iterator(False))\n        test_loss_logger.log(state[\'epoch\'], meter_loss.value()[0])\n        test_accuracy_logger.log(state[\'epoch\'], meter_accuracy.value()[0])\n        confusion_logger.log(confusion_meter.value())\n\n        print(\'[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)\' % (\n            state[\'epoch\'], meter_loss.value()[0], meter_accuracy.value()[0]))\n\n        torch.save(model.state_dict(), \'epochs/epoch_%d.pt\' % state[\'epoch\'])\n\n        # Reconstruction visualization.\n\n        test_sample = next(iter(get_iterator(False)))\n\n        ground_truth = (test_sample[0].unsqueeze(1).float() / 255.0)\n        _, reconstructions = model(Variable(ground_truth).cuda())\n        reconstruction = reconstructions.cpu().view_as(ground_truth).data\n\n        ground_truth_logger.log(\n            make_grid(ground_truth, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n        reconstruction_logger.log(\n            make_grid(reconstruction, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n\n    # def on_start(state):\n    #     state[\'epoch\'] = 327\n    #\n    # engine.hooks[\'on_start\'] = on_start\n    engine.hooks[\'on_sample\'] = on_sample\n    engine.hooks[\'on_forward\'] = on_forward\n    engine.hooks[\'on_start_epoch\'] = on_start_epoch\n    engine.hooks[\'on_end_epoch\'] = on_end_epoch\n\n    engine.train(processor, get_iterator(True), maxepoch=NUM_EPOCHS, optimizer=optimizer)\n'"
capsule_network_svhn.py,16,"b'""""""\nDynamic Routing Between Capsules\nhttps://arxiv.org/abs/1710.09829\n\nPyTorch implementation by Kenta Iwasaki @ Gram.AI.\n""""""\nimport sys\nsys.setrecursionlimit(15000)\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nimport numpy as np\n\nBATCH_SIZE = 100\nNUM_CLASSES = 10\nNUM_EPOCHS = 500\nNUM_ROUTING_ITERATIONS = 3\n\n\ndef softmax(input, dim=1):\n    transposed_input = input.transpose(dim, len(input.size()) - 1)\n    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)), dim=-1)\n    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input.size()) - 1)\n\n\ndef augmentation(x, max_shift=2):\n    _, _, height, width = x.size()\n\n    h_shift, w_shift = np.random.randint(-max_shift, max_shift + 1, size=2)\n    source_height_slice = slice(max(0, h_shift), h_shift + height)\n    source_width_slice = slice(max(0, w_shift), w_shift + width)\n    target_height_slice = slice(max(0, -h_shift), -h_shift + height)\n    target_width_slice = slice(max(0, -w_shift), -w_shift + width)\n\n    shifted_image = torch.zeros(*x.size())\n    shifted_image[ :, :, source_height_slice, source_width_slice] = x[:, :, target_height_slice, target_width_slice]\n    return shifted_image.float()\n\n\nclass CapsuleLayer(nn.Module):\n    def __init__(self, num_capsules, num_route_nodes, in_channels, out_channels, kernel_size=None, stride=None,\n                 num_iterations=NUM_ROUTING_ITERATIONS):\n        super(CapsuleLayer, self).__init__()\n\n        self.num_route_nodes = num_route_nodes\n        self.num_iterations = num_iterations\n\n        self.num_capsules = num_capsules\n\n        if num_route_nodes != -1:\n            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_route_nodes, in_channels, out_channels))\n        else:\n            self.capsules = nn.ModuleList(\n                [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) for _ in\n                 range(num_capsules)])\n\n    def squash(self, tensor, dim=-1):\n        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n        scale = squared_norm / (1 + squared_norm)\n        return scale * tensor / torch.sqrt(squared_norm)\n\n    def forward(self, x):\n        if self.num_route_nodes != -1:\n            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n\n            logits = Variable(torch.zeros(*priors.size())).cuda()\n            for i in range(self.num_iterations):\n                probs = softmax(logits, dim=2)\n                outputs = self.squash((probs * priors).sum(dim=2, keepdim=True))\n\n                if i != self.num_iterations - 1:\n                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n                    logits = logits + delta_logits\n        else:\n            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n            outputs = torch.cat(outputs, dim=-1)\n            outputs = self.squash(outputs)\n\n        return outputs\n\n\nclass CapsuleNet(nn.Module):\n    def __init__(self):\n        super(CapsuleNet, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=9, stride=1)\n        self.primary_capsules = CapsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=32,\n                                             kernel_size=9, stride=2)\n        self.digit_capsules = CapsuleLayer(num_capsules=NUM_CLASSES, num_route_nodes=2048, in_channels=8,\n                                           out_channels=16)\n\n        self.decoder = nn.Sequential(\n            nn.Linear(16 * NUM_CLASSES, 512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, 1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024, 3072),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x, y=None):\n        x = F.relu(self.conv1(x), inplace=True)\n        x = self.primary_capsules(x)\n        x = self.digit_capsules(x).squeeze().transpose(0, 1)\n\n        classes = (x ** 2).sum(dim=-1) ** 0.5\n        classes = F.softmax(classes, dim=-1)\n\n        if y is None:\n            # In all batches, get the most active capsule.\n            _, max_length_indices = classes.max(dim=1)\n            y = Variable(torch.eye(NUM_CLASSES)).cuda().index_select(dim=0, index=max_length_indices.data)\n\n        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n\n        return classes, reconstructions\n\n\nclass CapsuleLoss(nn.Module):\n    def __init__(self):\n        super(CapsuleLoss, self).__init__()\n        self.reconstruction_loss = nn.MSELoss(size_average=False)\n\n    def forward(self, images, labels, classes, reconstructions):\n        left = F.relu(0.9 - classes, inplace=True) ** 2\n        right = F.relu(classes - 0.1, inplace=True) ** 2\n\n        margin_loss = labels * left + 0.5 * (1. - labels) * right\n        margin_loss = margin_loss.sum()\n\n        assert torch.numel(images) == torch.numel(reconstructions)\n        images = images.view(reconstructions.size()[0], -1)\n        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n\n        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)\n\n\nif __name__ == ""__main__"":\n    from torch.autograd import Variable\n    from torch.optim import Adam\n    from torchnet.engine import Engine\n    from torchnet.logger import VisdomPlotLogger, VisdomLogger\n    from torchvision.utils import make_grid\n    from torchvision.datasets.svhn import SVHN\n    from tqdm import tqdm\n    import torchnet as tnt\n\n    model = CapsuleNet()\n    # model.load_state_dict(torch.load(\'epochs/epoch_327.pt\'))\n    model.cuda()\n\n    print(""# parameters:"", sum(param.numel() for param in model.parameters()))\n\n    optimizer = Adam(model.parameters())\n\n    engine = Engine()\n    meter_loss = tnt.meter.AverageValueMeter()\n    meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n    confusion_meter = tnt.meter.ConfusionMeter(NUM_CLASSES, normalized=True)\n\n    train_loss_logger = VisdomPlotLogger(\'line\', opts={\'title\': \'Train Loss\'})\n    train_error_logger = VisdomPlotLogger(\'line\', opts={\'title\': \'Train Accuracy\'})\n    test_loss_logger = VisdomPlotLogger(\'line\', opts={\'title\': \'Test Loss\'})\n    test_accuracy_logger = VisdomPlotLogger(\'line\', opts={\'title\': \'Test Accuracy\'})\n    confusion_logger = VisdomLogger(\'heatmap\', opts={\'title\': \'Confusion matrix\',\n                                                     \'columnnames\': list(range(NUM_CLASSES)),\n                                                     \'rownames\': list(range(NUM_CLASSES))})\n    ground_truth_logger = VisdomLogger(\'image\', opts={\'title\': \'Ground Truth\'})\n    reconstruction_logger = VisdomLogger(\'image\', opts={\'title\': \'Reconstruction\'})\n\n    capsule_loss = CapsuleLoss()\n\n\n    def get_iterator(mode):\n        if mode is True:\n            dataset = SVHN(root=\'./data\', download=True, split=""train"")\n        elif mode is False:\n            dataset = SVHN(root=\'./data\', download=True, split=""test"")\n        data = dataset.data\n        labels = dataset.labels\n\n        tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n\n        return tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode)\n\n\n    def processor(sample):\n        data, labels, training = sample\n\n        data = augmentation(data)\n        labels = torch.LongTensor(labels)\n\n        labels = torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n\n        data = Variable(data).cuda()\n        labels = Variable(labels).cuda()\n\n        if training:\n            classes, reconstructions = model(data, labels)\n        else:\n            classes, reconstructions = model(data)\n\n        loss = capsule_loss(data, labels, classes, reconstructions)\n\n        return loss, classes\n\n\n    def reset_meters():\n        meter_accuracy.reset()\n        meter_loss.reset()\n        confusion_meter.reset()\n\n\n    def on_sample(state):\n        state[\'sample\'].append(state[\'train\'])\n\n\n    def on_forward(state):\n        meter_accuracy.add(state[\'output\'].data, torch.LongTensor(state[\'sample\'][1]))\n        confusion_meter.add(state[\'output\'].data, torch.LongTensor(state[\'sample\'][1]))\n        meter_loss.add(state[\'loss\'].item())\n\n\n    def on_start_epoch(state):\n        reset_meters()\n        state[\'iterator\'] = tqdm(state[\'iterator\'])\n\n\n    def on_end_epoch(state):\n        print(\'[Epoch %d] Training Loss: %.4f (Accuracy: %.2f%%)\' % (\n            state[\'epoch\'], meter_loss.value()[0], meter_accuracy.value()[0]))\n\n        train_loss_logger.log(state[\'epoch\'], meter_loss.value()[0])\n        train_error_logger.log(state[\'epoch\'], meter_accuracy.value()[0])\n\n        reset_meters()\n\n        engine.test(processor, get_iterator(False))\n        test_loss_logger.log(state[\'epoch\'], meter_loss.value()[0])\n        test_accuracy_logger.log(state[\'epoch\'], meter_accuracy.value()[0])\n        confusion_logger.log(confusion_meter.value())\n\n        print(\'[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)\' % (\n            state[\'epoch\'], meter_loss.value()[0], meter_accuracy.value()[0]))\n\n        torch.save(model.state_dict(), \'epochs/epoch_%d.pt\' % state[\'epoch\'])\n\n        # Reconstruction visualization.\n\n        test_sample = next(iter(get_iterator(False)))\n\n        ground_truth = (test_sample[0])\n        _, reconstructions = model(Variable(ground_truth).cuda())\n        reconstruction = reconstructions.cpu().view_as(ground_truth).data\n\n        ground_truth_logger.log(\n            make_grid(ground_truth, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n        reconstruction_logger.log(\n            make_grid(reconstruction, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n\n    # def on_start(state):\n    #     state[\'epoch\'] = 327\n    #\n    # engine.hooks[\'on_start\'] = on_start\n    engine.hooks[\'on_sample\'] = on_sample\n    engine.hooks[\'on_forward\'] = on_forward\n    engine.hooks[\'on_start_epoch\'] = on_start_epoch\n    engine.hooks[\'on_end_epoch\'] = on_end_epoch\n\n    engine.train(processor, get_iterator(True), maxepoch=NUM_EPOCHS, optimizer=optimizer)\n'"
