file_path,api_count,code
hnn.py,11,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport torch\nimport numpy as np\n\nfrom nn_models import MLP\nfrom utils import rk4\n\nclass HNN(torch.nn.Module):\n    \'\'\'Learn arbitrary vector fields that are sums of conservative and solenoidal fields\'\'\'\n    def __init__(self, input_dim, differentiable_model, field_type=\'solenoidal\',\n                    baseline=False, assume_canonical_coords=True):\n        super(HNN, self).__init__()\n        self.baseline = baseline\n        self.differentiable_model = differentiable_model\n        self.assume_canonical_coords = assume_canonical_coords\n        self.M = self.permutation_tensor(input_dim) # Levi-Civita permutation tensor\n        self.field_type = field_type\n\n    def forward(self, x):\n        # traditional forward pass\n        if self.baseline:\n            return self.differentiable_model(x)\n\n        y = self.differentiable_model(x)\n        assert y.dim() == 2 and y.shape[1] == 2, ""Output tensor should have shape [batch_size, 2]""\n        return y.split(1,1)\n\n    def rk4_time_derivative(self, x, dt):\n        return rk4(fun=self.time_derivative, y0=x, t=0, dt=dt)\n\n    def time_derivative(self, x, t=None, separate_fields=False):\n        \'\'\'NEURAL ODE-STLE VECTOR FIELD\'\'\'\n        if self.baseline:\n            return self.differentiable_model(x)\n\n        \'\'\'NEURAL HAMILTONIAN-STLE VECTOR FIELD\'\'\'\n        F1, F2 = self.forward(x) # traditional forward pass\n\n        conservative_field = torch.zeros_like(x) # start out with both components set to 0\n        solenoidal_field = torch.zeros_like(x)\n\n        if self.field_type != \'solenoidal\':\n            dF1 = torch.autograd.grad(F1.sum(), x, create_graph=True)[0] # gradients for conservative field\n            conservative_field = dF1 @ torch.eye(*self.M.shape)\n\n        if self.field_type != \'conservative\':\n            dF2 = torch.autograd.grad(F2.sum(), x, create_graph=True)[0] # gradients for solenoidal field\n            solenoidal_field = dF2 @ self.M.t()\n\n        if separate_fields:\n            return [conservative_field, solenoidal_field]\n\n        return conservative_field + solenoidal_field\n\n    def permutation_tensor(self,n):\n        M = None\n        if self.assume_canonical_coords:\n            M = torch.eye(n)\n            M = torch.cat([M[n//2:], -M[:n//2]])\n        else:\n            \'\'\'Constructs the Levi-Civita permutation tensor\'\'\'\n            M = torch.ones(n,n) # matrix of ones\n            M *= 1 - torch.eye(n) # clear diagonals\n            M[::2] *= -1 # pattern of signs\n            M[:,::2] *= -1\n    \n            for i in range(n): # make asymmetric\n                for j in range(i+1, n):\n                    M[i,j] *= -1\n        return M\n\n\nclass PixelHNN(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, autoencoder,\n                 field_type=\'solenoidal\', nonlinearity=\'tanh\', baseline=False):\n        super(PixelHNN, self).__init__()\n        self.autoencoder = autoencoder\n        self.baseline = baseline\n\n        output_dim = input_dim if baseline else 2\n        nn_model = MLP(input_dim, hidden_dim, output_dim, nonlinearity)\n        self.hnn = HNN(input_dim, differentiable_model=nn_model, field_type=field_type, baseline=baseline)\n\n    def encode(self, x):\n        return self.autoencoder.encode(x)\n\n    def decode(self, z):\n        return self.autoencoder.decode(z)\n\n    def time_derivative(self, z, separate_fields=False):\n        return self.hnn.time_derivative(z, separate_fields)\n\n    def forward(self, x):\n        z = self.encode(x)\n        z_next = z + self.time_derivative(z)\n        return self.decode(z_next)\n'"
nn_models.py,15,"b""# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport torch\nimport numpy as np\nfrom utils import choose_nonlinearity\n\nclass MLP(torch.nn.Module):\n  '''Just a salt-of-the-earth MLP'''\n  def __init__(self, input_dim, hidden_dim, output_dim, nonlinearity='tanh'):\n    super(MLP, self).__init__()\n    self.linear1 = torch.nn.Linear(input_dim, hidden_dim)\n    self.linear2 = torch.nn.Linear(hidden_dim, hidden_dim)\n    self.linear3 = torch.nn.Linear(hidden_dim, output_dim, bias=None)\n\n    for l in [self.linear1, self.linear2, self.linear3]:\n      torch.nn.init.orthogonal_(l.weight) # use a principled initialization\n\n    self.nonlinearity = choose_nonlinearity(nonlinearity)\n\n  def forward(self, x, separate_fields=False):\n    h = self.nonlinearity( self.linear1(x) )\n    h = self.nonlinearity( self.linear2(h) )\n    return self.linear3(h)\n\nclass MLPAutoencoder(torch.nn.Module):\n  '''A salt-of-the-earth MLP Autoencoder + some edgy res connections'''\n  def __init__(self, input_dim, hidden_dim, latent_dim, nonlinearity='tanh'):\n    super(MLPAutoencoder, self).__init__()\n    self.linear1 = torch.nn.Linear(input_dim, hidden_dim)\n    self.linear2 = torch.nn.Linear(hidden_dim, hidden_dim)\n    self.linear3 = torch.nn.Linear(hidden_dim, hidden_dim)\n    self.linear4 = torch.nn.Linear(hidden_dim, latent_dim)\n\n    self.linear5 = torch.nn.Linear(latent_dim, hidden_dim)\n    self.linear6 = torch.nn.Linear(hidden_dim, hidden_dim)\n    self.linear7 = torch.nn.Linear(hidden_dim, hidden_dim)\n    self.linear8 = torch.nn.Linear(hidden_dim, input_dim)\n\n    for l in [self.linear1, self.linear2, self.linear3, self.linear4, \\\n              self.linear5, self.linear6, self.linear7, self.linear8]:\n      torch.nn.init.orthogonal_(l.weight)  # use a principled initialization\n\n    self.nonlinearity = choose_nonlinearity(nonlinearity)\n\n  def encode(self, x):\n    h = self.nonlinearity( self.linear1(x) )\n    h = h + self.nonlinearity( self.linear2(h) )\n    h = h + self.nonlinearity( self.linear3(h) )\n    return self.linear4(h)\n\n  def decode(self, z):\n    h = self.nonlinearity( self.linear5(z) )\n    h = h + self.nonlinearity( self.linear6(h) )\n    h = h + self.nonlinearity( self.linear7(h) )\n    return self.linear8(h)\n\n  def forward(self, x):\n    z = self.encode(x)\n    x_hat = self.decode(z)\n    return x_hat"""
utils.py,8,"b'# Sam Greydanus, Misko Dzama, Jason Yosinski\n# 2019 | Google AI Residency Project ""Hamiltonian Neural Networks""\n\nimport numpy as np\nimport os, torch, pickle, zipfile\nimport imageio, shutil\nimport scipy, scipy.misc, scipy.integrate\nsolve_ivp = scipy.integrate.solve_ivp\n\n\ndef integrate_model(model, t_span, y0, fun=None, **kwargs):\n  def default_fun(t, np_x):\n      x = torch.tensor( np_x, requires_grad=True, dtype=torch.float32)\n      x = x.view(1, np.size(np_x)) # batch size of 1\n      dx = model.time_derivative(x).data.numpy().reshape(-1)\n      return dx\n  fun = default_fun if fun is None else fun\n  return solve_ivp(fun=fun, t_span=t_span, y0=y0, **kwargs)\n\n\ndef rk4(fun, y0, t, dt, *args, **kwargs):\n  dt2 = dt / 2.0\n  k1 = fun(y0, t, *args, **kwargs)\n  k2 = fun(y0 + dt2 * k1, t + dt2, *args, **kwargs)\n  k3 = fun(y0 + dt2 * k2, t + dt2, *args, **kwargs)\n  k4 = fun(y0 + dt * k3, t + dt, *args, **kwargs)\n  dy = dt / 6.0 * (k1 + 2 * k2 + 2 * k3 + k4)\n  return dy\n\n\ndef L2_loss(u, v):\n  return (u-v).pow(2).mean()\n\n\ndef read_lipson(experiment_name, save_dir):\n  desired_file = experiment_name + "".txt""\n  with zipfile.ZipFile(\'{}/invar_datasets.zip\'.format(save_dir)) as z:\n    for filename in z.namelist():\n      if desired_file == filename and not os.path.isdir(filename):\n        with z.open(filename) as f:\n            data = f.read()\n  return str(data)\n\n\ndef str2array(string):\n  lines = string.split(\'\\\\n\')\n  names = lines[0].strip(""b\'% \\\\r"").split(\' \')\n  dnames = [\'d\' + n for n in names]\n  names = [\'trial\', \'t\'] + names + dnames\n  data = [[float(s) for s in l.strip(""\' \\\\r,"").split( )] for l in lines[1:-1]]\n\n  return np.asarray(data), names\n\n\ndef to_pickle(thing, path): # save something\n    with open(path, \'wb\') as handle:\n        pickle.dump(thing, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n\ndef from_pickle(path): # load something\n    thing = None\n    with open(path, \'rb\') as handle:\n        thing = pickle.load(handle)\n    return thing\n\n\ndef choose_nonlinearity(name):\n  nl = None\n  if name == \'tanh\':\n    nl = torch.tanh\n  elif name == \'relu\':\n    nl = torch.relu\n  elif name == \'sigmoid\':\n    nl = torch.sigmoid\n  elif name == \'softplus\':\n    nl = torch.nn.functional.softplus\n  elif name == \'selu\':\n    nl = torch.nn.functional.selu\n  elif name == \'elu\':\n    nl = torch.nn.functional.elu\n  elif name == \'swish\':\n    nl = lambda x: x * torch.sigmoid(x)\n  else:\n    raise ValueError(""nonlinearity not recognized"")\n  return nl\n\n\ndef make_gif(frames, save_dir, name=\'pendulum\', duration=1e-1, pixels=None, divider=0):\n    \'\'\'Given a three dimensional array [frames, height, width], make\n    a gif and save it.\'\'\'\n    temp_dir = \'./_temp\'\n    os.mkdir(temp_dir) if not os.path.exists(temp_dir) else None\n    for i in range(len(frames)):\n        im = (frames[i].clip(-.5,.5) + .5)*255\n        im[divider,:] = 0\n        im[divider + 1,:] = 255\n        if pixels is not None:\n          im = scipy.misc.imresize(im, pixels)\n        scipy.misc.imsave(temp_dir + \'/f_{:04d}.png\'.format(i), im)\n\n    images = []\n    for file_name in sorted(os.listdir(temp_dir)):\n        if file_name.endswith(\'.png\'):\n            file_path = os.path.join(temp_dir, file_name)\n            images.append(imageio.imread(file_path))\n    save_path = \'{}/{}.gif\'.format(save_dir, name)\n    png_save_path = \'{}.png\'.format(save_path)\n    imageio.mimsave(save_path, images, duration=duration)\n    os.rename(save_path, png_save_path)\n\n    shutil.rmtree(temp_dir) # remove all the images\n    return png_save_path'"
experiment-2body/data.py,0,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport numpy as np\nimport scipy\nsolve_ivp = scipy.integrate.solve_ivp\n\nimport os, sys\nparent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(parent_dir)\n\nfrom utils import to_pickle, from_pickle\n\n##### ENERGY #####\ndef potential_energy(state):\n    \'\'\'U=sum_i,j>i G m_i m_j / r_ij\'\'\'\n    tot_energy = np.zeros((1,1,state.shape[2]))\n    for i in range(state.shape[0]):\n        for j in range(i+1,state.shape[0]):\n            r_ij = ((state[i:i+1,1:3] - state[j:j+1,1:3])**2).sum(1, keepdims=True)**.5\n            m_i = state[i:i+1,0:1]\n            m_j = state[j:j+1,0:1]\n    tot_energy += m_i * m_j / r_ij\n    U = -tot_energy.sum(0).squeeze()\n    return U\n\ndef kinetic_energy(state):\n    \'\'\'T=sum_i .5*m*v^2\'\'\'\n    energies = .5 * state[:,0:1] * (state[:,3:5]**2).sum(1, keepdims=True)\n    T = energies.sum(0).squeeze()\n    return T\n\ndef total_energy(state):\n    return potential_energy(state) + kinetic_energy(state)\n\n\n##### DYNAMICS #####\ndef get_accelerations(state, epsilon=0):\n    # shape of state is [bodies x properties]\n    net_accs = [] # [nbodies x 2]\n    for i in range(state.shape[0]): # number of bodies\n        other_bodies = np.concatenate([state[:i, :], state[i+1:, :]], axis=0)\n        displacements = other_bodies[:, 1:3] - state[i, 1:3] # indexes 1:3 -> pxs, pys\n        distances = (displacements**2).sum(1, keepdims=True)**0.5\n        masses = other_bodies[:, 0:1] # index 0 -> mass\n        pointwise_accs = masses * displacements / (distances**3 + epsilon) # G=1\n        net_acc = pointwise_accs.sum(0, keepdims=True)\n        net_accs.append(net_acc)\n    net_accs = np.concatenate(net_accs, axis=0)\n    return net_accs\n  \ndef update(t, state):\n    state = state.reshape(-1,5) # [bodies, properties]\n    deriv = np.zeros_like(state)\n    deriv[:,1:3] = state[:,3:5] # dx, dy = vx, vy\n    deriv[:,3:5] = get_accelerations(state)\n    return deriv.reshape(-1)\n\n\n##### INTEGRATION SETTINGS #####\ndef get_orbit(state, update_fn=update, t_points=100, t_span=[0,2], **kwargs):\n    if not \'rtol\' in kwargs.keys():\n        kwargs[\'rtol\'] = 1e-9\n\n    orbit_settings = locals()\n\n    nbodies = state.shape[0]\n    t_eval = np.linspace(t_span[0], t_span[1], t_points)\n    orbit_settings[\'t_eval\'] = t_eval\n\n    path = solve_ivp(fun=update_fn, t_span=t_span, y0=state.flatten(),\n                     t_eval=t_eval, **kwargs)\n    orbit = path[\'y\'].reshape(nbodies, 5, t_points)\n    return orbit, orbit_settings\n\n\n##### INITIALIZE THE TWO BODIES #####\ndef random_config(orbit_noise=5e-2, min_radius=0.5, max_radius=1.5):\n    state = np.zeros((2,5))\n    state[:,0] = 1\n    pos = np.random.rand(2) * (max_radius-min_radius) + min_radius\n    r = np.sqrt( np.sum((pos**2)) )\n\n    # velocity that yields a circular orbit\n    vel = np.flipud(pos) / (2 * r**1.5)\n    vel[0] *= -1\n    vel *= 1 + orbit_noise*np.random.randn()\n\n    # make the circular orbits SLIGHTLY elliptical\n    state[:,1:3] = pos\n    state[:,3:5] = vel\n    state[1,1:] *= -1\n    return state\n\n\n##### HELPER FUNCTION #####\ndef coords2state(coords, nbodies=2, mass=1):\n    timesteps = coords.shape[0]\n    state = coords.T\n    state = state.reshape(-1, nbodies, timesteps).transpose(1,0,2)\n    mass_vec = mass * np.ones((nbodies, 1, timesteps))\n    state = np.concatenate([mass_vec, state], axis=1)\n    return state\n\n\n##### INTEGRATE AN ORBIT OR TWO #####\ndef sample_orbits(timesteps=50, trials=1000, nbodies=2, orbit_noise=5e-2,\n                  min_radius=0.5, max_radius=1.5, t_span=[0, 20], verbose=False, **kwargs):\n    \n    orbit_settings = locals()\n    if verbose:\n        print(""Making a dataset of near-circular 2-body orbits:"")\n    \n    x, dx, e = [], [], []\n    N = timesteps*trials\n    while len(x) < N:\n\n        state = random_config(orbit_noise, min_radius, max_radius)\n        orbit, settings = get_orbit(state, t_points=timesteps, t_span=t_span, **kwargs)\n        batch = orbit.transpose(2,0,1).reshape(-1,10)\n\n        for state in batch:\n            dstate = update(None, state)\n            \n            # reshape from [nbodies, state] where state=[m, qx, qy, px, py]\n            # to [canonical_coords] = [qx1, qx2, qy1, qy2, px1,px2,....]\n            coords = state.reshape(nbodies,5).T[1:].flatten()\n            dcoords = dstate.reshape(nbodies,5).T[1:].flatten()\n            x.append(coords)\n            dx.append(dcoords)\n\n            shaped_state = state.copy().reshape(2,5,1)\n            e.append(total_energy(shaped_state))\n\n    data = {\'coords\': np.stack(x)[:N],\n            \'dcoords\': np.stack(dx)[:N],\n            \'energy\': np.stack(e)[:N] }\n    return data, orbit_settings\n\n\n##### MAKE A DATASET #####\ndef make_orbits_dataset(test_split=0.2, **kwargs):\n    data, orbit_settings = sample_orbits(**kwargs)\n    \n    # make a train/test split\n    split_ix = int(data[\'coords\'].shape[0] * test_split)\n    split_data = {}\n    for k, v in data.items():\n        split_data[k], split_data[\'test_\' + k] = v[split_ix:], v[:split_ix]\n    data = split_data\n\n    data[\'meta\'] = orbit_settings\n    return data\n\n\n##### LOAD OR SAVE THE DATASET #####\ndef get_dataset(experiment_name, save_dir, **kwargs):\n    \'\'\'Returns an orbital dataset. Also constructs\n    the dataset if no saved version is available.\'\'\'\n\n    path = \'{}/{}-orbits-dataset.pkl\'.format(save_dir, experiment_name)\n\n    try:\n        data = from_pickle(path)\n        print(""Successfully loaded data from {}"".format(path))\n    except:\n        print(""Had a problem loading data from {}. Rebuilding dataset..."".format(path))\n        data = make_orbits_dataset(**kwargs)\n        to_pickle(data, path)\n\n    return data'"
experiment-2body/train.py,12,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport torch, argparse\nimport numpy as np\n\nimport os, sys\nTHIS_DIR = os.path.dirname(os.path.abspath(__file__))\nPARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(PARENT_DIR)\n\nfrom nn_models import MLP\nfrom hnn import HNN\nfrom data import get_dataset\nfrom utils import L2_loss, to_pickle, from_pickle\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=None)\n    parser.add_argument(\'--input_dim\', default=2*4, type=int, help=\'dimensionality of input tensor\')\n    parser.add_argument(\'--hidden_dim\', default=200, type=int, help=\'hidden dimension of mlp\')\n    parser.add_argument(\'--learn_rate\', default=1e-3, type=float, help=\'learning rate\')\n    parser.add_argument(\'--batch_size\', default=200, type=int, help=\'batch_size\')\n    parser.add_argument(\'--input_noise\', default=0.0, type=int, help=\'std of noise added to inputs\')\n    parser.add_argument(\'--nonlinearity\', default=\'tanh\', type=str, help=\'neural net nonlinearity\')\n    parser.add_argument(\'--total_steps\', default=10000, type=int, help=\'number of gradient steps\')\n    parser.add_argument(\'--print_every\', default=200, type=int, help=\'number of gradient steps between prints\')\n    parser.add_argument(\'--name\', default=\'2body\', type=str, help=\'only one option right now\')\n    parser.add_argument(\'--baseline\', dest=\'baseline\', action=\'store_true\', help=\'run baseline or experiment?\')\n    parser.add_argument(\'--verbose\', dest=\'verbose\', action=\'store_true\', help=\'verbose?\')\n    parser.add_argument(\'--field_type\', default=\'solenoidal\', type=str, help=\'type of vector field to learn\')\n    parser.add_argument(\'--seed\', default=0, type=int, help=\'random seed\')\n    parser.add_argument(\'--save_dir\', default=THIS_DIR, type=str, help=\'where to save the trained model\')\n    parser.set_defaults(feature=True)\n    return parser.parse_args()\n\ndef train(args):\n  # set random seed\n  torch.manual_seed(args.seed)\n  np.random.seed(args.seed)\n\n  # init model and optimizer\n  if args.verbose:\n    print(""Training baseline model:"" if args.baseline else ""Training HNN model:"")\n\n  output_dim = args.input_dim if args.baseline else 2\n  nn_model = MLP(args.input_dim, args.hidden_dim, output_dim, args.nonlinearity)\n  model = HNN(args.input_dim, differentiable_model=nn_model,\n            field_type=args.field_type, baseline=args.baseline)\n  optim = torch.optim.Adam(model.parameters(), args.learn_rate, weight_decay=0)\n\n  # arrange data\n  data = get_dataset(args.name, args.save_dir, verbose=True)\n  x = torch.tensor( data[\'coords\'], requires_grad=True, dtype=torch.float32)\n  test_x = torch.tensor( data[\'test_coords\'], requires_grad=True, dtype=torch.float32)\n  dxdt = torch.Tensor(data[\'dcoords\'])\n  test_dxdt = torch.Tensor(data[\'test_dcoords\'])\n\n  # vanilla train loop\n  stats = {\'train_loss\': [], \'test_loss\': []}\n  for step in range(args.total_steps+1):\n\n    # train step\n    ixs = torch.randperm(x.shape[0])[:args.batch_size]\n    dxdt_hat = model.time_derivative(x[ixs])\n    dxdt_hat += args.input_noise * torch.randn(*x[ixs].shape) # add noise, maybe\n    loss = L2_loss(dxdt[ixs], dxdt_hat)\n    loss.backward()\n    grad = torch.cat([p.grad.flatten() for p in model.parameters()]).clone()\n    optim.step() ; optim.zero_grad()\n\n    # run test data\n    test_ixs = torch.randperm(test_x.shape[0])[:args.batch_size]\n    test_dxdt_hat = model.time_derivative(test_x[test_ixs])\n    test_dxdt_hat += args.input_noise * torch.randn(*test_x[test_ixs].shape) # add noise, maybe\n    test_loss = L2_loss(test_dxdt[test_ixs], test_dxdt_hat)\n\n    # logging\n    stats[\'train_loss\'].append(loss.item())\n    stats[\'test_loss\'].append(test_loss.item())\n    if args.verbose and step % args.print_every == 0:\n      print(""step {}, train_loss {:.4e}, test_loss {:.4e}, grad norm {:.4e}, grad std {:.4e}""\n          .format(step, loss.item(), test_loss.item(), grad@grad, grad.std()))\n\n  train_dxdt_hat = model.time_derivative(x)\n  train_dist = (dxdt - train_dxdt_hat)**2\n  test_dxdt_hat = model.time_derivative(test_x)\n  test_dist = (test_dxdt - test_dxdt_hat)**2\n  print(\'Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}\'\n    .format(train_dist.mean().item(), train_dist.std().item()/np.sqrt(train_dist.shape[0]),\n            test_dist.mean().item(), test_dist.std().item()/np.sqrt(test_dist.shape[0])))\n  return model, stats\n\nif __name__ == ""__main__"":\n    args = get_args()\n    model, stats = train(args)\n\n    # save\n    os.makedirs(args.save_dir) if not os.path.exists(args.save_dir) else None\n    label = \'baseline\' if args.baseline else \'hnn\'\n    path = \'{}/{}-orbits-{}.tar\'.format(args.save_dir, args.name, label)\n    torch.save(model.state_dict(), path)\n'"
experiment-3body/data.py,0,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport numpy as np\nimport scipy\nsolve_ivp = scipy.integrate.solve_ivp\n\nimport os, sys\nparent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(parent_dir)\n\nfrom utils import to_pickle, from_pickle\n\n##### ENERGY #####\ndef potential_energy(state):\n    \'\'\'U=\\sum_i,j>i G m_i m_j / r_ij\'\'\'\n    tot_energy = np.zeros((1,1,state.shape[2]))\n    for i in range(state.shape[0]):\n        for j in range(i+1,state.shape[0]):\n            r_ij = ((state[i:i+1,1:3] - state[j:j+1,1:3])**2).sum(1, keepdims=True)**.5\n            m_i = state[i:i+1,0:1]\n            m_j = state[j:j+1,0:1]\n            tot_energy += m_i * m_j / r_ij\n    U = -tot_energy.sum(0).squeeze()\n    return U\n\ndef kinetic_energy(state):\n    \'\'\'T=\\sum_i .5*m*v^2\'\'\'\n    energies = .5 * state[:,0:1] * (state[:,3:5]**2).sum(1, keepdims=True)\n    T = energies.sum(0).squeeze()\n    return T\n\ndef total_energy(state):\n    return potential_energy(state) + kinetic_energy(state)\n\n\n##### DYNAMICS #####\ndef get_accelerations(state, epsilon=0):\n    # shape of state is [bodies x properties]\n    net_accs = [] # [nbodies x 2]\n    for i in range(state.shape[0]): # number of bodies\n        other_bodies = np.concatenate([state[:i, :], state[i+1:, :]], axis=0)\n        displacements = other_bodies[:, 1:3] - state[i, 1:3] # indexes 1:3 -> pxs, pys\n        distances = (displacements**2).sum(1, keepdims=True)**0.5\n        masses = other_bodies[:, 0:1] # index 0 -> mass\n        pointwise_accs = masses * displacements / (distances**3 + epsilon) # G=1\n        net_acc = pointwise_accs.sum(0, keepdims=True)\n        net_accs.append(net_acc)\n    net_accs = np.concatenate(net_accs, axis=0)\n    return net_accs\n  \ndef update(t, state):\n    state = state.reshape(-1,5) # [bodies, properties]\n    deriv = np.zeros_like(state)\n    deriv[:,1:3] = state[:,3:5] # dx, dy = vx, vy\n    deriv[:,3:5] = get_accelerations(state)\n    return deriv.reshape(-1)\n\n\n##### INTEGRATION SETTINGS #####\ndef get_orbit(state, update_fn=update, t_points=100, t_span=[0,2], nbodies=3, **kwargs):\n    if not \'rtol\' in kwargs.keys():\n        kwargs[\'rtol\'] = 1e-9\n\n    orbit_settings = locals()\n\n    nbodies = state.shape[0]\n    t_eval = np.linspace(t_span[0], t_span[1], t_points)\n    orbit_settings[\'t_eval\'] = t_eval\n\n    path = solve_ivp(fun=update_fn, t_span=t_span, y0=state.flatten(),\n                     t_eval=t_eval, **kwargs)\n    orbit = path[\'y\'].reshape(nbodies, 5, t_points)\n    return orbit, orbit_settings\n\n\n##### INITIALIZE THE TWO BODIES #####\ndef rotate2d(p, theta):\n  c, s = np.cos(theta), np.sin(theta)\n  R = np.array([[c, -s],[s, c]])\n  return (R @ p.reshape(2,1)).squeeze()\n\ndef random_config(nu=2e-1, min_radius=0.9, max_radius=1.2):\n  \'\'\'This is not principled at all yet\'\'\'\n  state = np.zeros((3,5))\n  state[:,0] = 1\n  p1 = 2*np.random.rand(2) - 1\n  r = np.random.rand() * (max_radius-min_radius) + min_radius\n  \n  p1 *= r/np.sqrt( np.sum((p1**2)) )\n  p2 = rotate2d(p1, theta=2*np.pi/3)\n  p3 = rotate2d(p2, theta=2*np.pi/3)\n\n  # # velocity that yields a circular orbit\n  v1 = rotate2d(p1, theta=np.pi/2)\n  v1 = v1 / r**1.5\n  v1 = v1 * np.sqrt(np.sin(np.pi/3)/(2*np.cos(np.pi/6)**2)) # scale factor to get circular trajectories\n  v2 = rotate2d(v1, theta=2*np.pi/3)\n  v3 = rotate2d(v2, theta=2*np.pi/3)\n  \n  # make the circular orbits slightly chaotic\n  v1 *= 1 + nu*(2*np.random.rand(2) - 1)\n  v2 *= 1 + nu*(2*np.random.rand(2) - 1)\n  v3 *= 1 + nu*(2*np.random.rand(2) - 1)\n\n  state[0,1:3], state[0,3:5] = p1, v1\n  state[1,1:3], state[1,3:5] = p2, v2\n  state[2,1:3], state[2,3:5] = p3, v3\n  return state\n\n\n##### INTEGRATE AN ORBIT OR TWO #####\ndef sample_orbits(timesteps=20, trials=5000, nbodies=3, orbit_noise=2e-1,\n                  min_radius=0.9, max_radius=1.2, t_span=[0, 5], verbose=False, **kwargs):\n    \n    orbit_settings = locals()\n    if verbose:\n        print(""Making a dataset of near-circular 3-body orbits:"")\n    \n    x, dx, e = [], [], []\n    N = timesteps*trials\n    while len(x) < N:\n\n        state = random_config(nu=orbit_noise, min_radius=min_radius, max_radius=max_radius)\n        orbit, settings = get_orbit(state, t_points=timesteps, t_span=t_span, nbodies=nbodies, **kwargs)\n        batch = orbit.transpose(2,0,1).reshape(-1,nbodies*5)\n\n        for state in batch:\n            dstate = update(None, state)\n            \n            # reshape from [nbodies, state] where state=[m, qx, qy, px, py]\n            # to [canonical_coords] = [qx1, qx2, qy1, qy2, px1,px2,....]\n            coords = state.reshape(nbodies,5).T[1:].flatten()\n            dcoords = dstate.reshape(nbodies,5).T[1:].flatten()\n            x.append(coords)\n            dx.append(dcoords)\n\n            shaped_state = state.copy().reshape(nbodies,5,1)\n            e.append(total_energy(shaped_state))\n\n    data = {\'coords\': np.stack(x)[:N],\n            \'dcoords\': np.stack(dx)[:N],\n            \'energy\': np.stack(e)[:N] }\n    return data, orbit_settings\n\n\n##### MAKE A DATASET #####\ndef make_orbits_dataset(test_split=0.2, **kwargs):\n    data, orbit_settings = sample_orbits(**kwargs)\n    \n    # make a train/test split\n    split_ix = int(data[\'coords\'].shape[0] * test_split)\n    split_data = {}\n    for k, v in data.items():\n        split_data[k], split_data[\'test_\' + k] = v[split_ix:], v[:split_ix]\n    data = split_data\n\n    data[\'meta\'] = orbit_settings\n    return data\n\n\n##### LOAD OR SAVE THE DATASET #####\ndef get_dataset(experiment_name, save_dir, **kwargs):\n    \'\'\'Returns an orbital dataset. Also constructs\n    the dataset if no saved version is available.\'\'\'\n\n    path = \'{}/{}-orbits-dataset.pkl\'.format(save_dir, experiment_name)\n\n    try:\n        data = from_pickle(path)\n        print(""Successfully loaded data from {}"".format(path))\n    except:\n        print(""Had a problem loading data from {}. Rebuilding dataset..."".format(path))\n        data = make_orbits_dataset(**kwargs)\n        to_pickle(data, path)\n\n    return data'"
experiment-3body/train.py,10,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport torch, argparse\nimport numpy as np\n\nimport os, sys\nTHIS_DIR = os.path.dirname(os.path.abspath(__file__))\nPARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(PARENT_DIR)\n\nfrom nn_models import MLP\nfrom hnn import HNN\nfrom data import get_dataset\nfrom utils import L2_loss, to_pickle, from_pickle\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=None)\n    parser.add_argument(\'--input_dim\', default=3*4, type=int, help=\'dimensionality of input tensor\')\n    parser.add_argument(\'--hidden_dim\', default=200, type=int, help=\'hidden dimension of mlp\')\n    parser.add_argument(\'--learn_rate\', default=1e-3, type=float, help=\'learning rate\')\n    parser.add_argument(\'--batch_size\', default=600, type=int, help=\'batch_size\')\n    parser.add_argument(\'--nonlinearity\', default=\'tanh\', type=str, help=\'neural net nonlinearity\')\n    parser.add_argument(\'--total_steps\', default=10000, type=int, help=\'number of gradient steps\')\n    parser.add_argument(\'--print_every\', default=200, type=int, help=\'number of gradient steps between prints\')\n    parser.add_argument(\'--name\', default=\'3body\', type=str, help=\'only one option right now\')\n    parser.add_argument(\'--baseline\', dest=\'baseline\', action=\'store_true\', help=\'run baseline or experiment?\')\n    parser.add_argument(\'--verbose\', dest=\'verbose\', action=\'store_true\', help=\'verbose?\')\n    parser.add_argument(\'--field_type\', default=\'solenoidal\', type=str, help=\'type of vector field to learn\')\n    parser.add_argument(\'--seed\', default=0, type=int, help=\'random seed\')\n    parser.add_argument(\'--save_dir\', default=THIS_DIR, type=str, help=\'where to save the trained model\')\n    parser.set_defaults(feature=True)\n    return parser.parse_args()\n\ndef train(args):\n  # set random seed\n  torch.manual_seed(args.seed)\n  np.random.seed(args.seed)\n\n  # init model and optimizer\n  if args.verbose:\n    print(""Training baseline model:"" if args.baseline else ""Training HNN model:"")\n\n  output_dim = args.input_dim if args.baseline else 2\n  nn_model = MLP(args.input_dim, args.hidden_dim, output_dim, args.nonlinearity)\n  model = HNN(args.input_dim, differentiable_model=nn_model,\n            field_type=args.field_type, baseline=args.baseline)\n  optim = torch.optim.Adam(model.parameters(), args.learn_rate, weight_decay=1e-4)\n\n  # arrange data\n  data = get_dataset(args.name, args.save_dir, verbose=True)\n  x = torch.tensor( data[\'coords\'], requires_grad=True, dtype=torch.float32)\n  test_x = torch.tensor( data[\'test_coords\'], requires_grad=True, dtype=torch.float32)\n  dxdt = torch.Tensor(data[\'dcoords\'])\n  test_dxdt = torch.Tensor(data[\'test_dcoords\'])\n\n  # vanilla train loop\n  stats = {\'train_loss\': [], \'test_loss\': []}\n  for step in range(args.total_steps+1):\n\n    # train step\n    ixs = torch.randperm(x.shape[0])[:args.batch_size]\n    dxdt_hat = model.time_derivative(x[ixs])\n    loss = L2_loss(dxdt[ixs], dxdt_hat)\n    loss.backward()\n    grad = torch.cat([p.grad.flatten() for p in model.parameters()]).clone()\n    optim.step() ; optim.zero_grad()\n\n    # run test data\n    test_ixs = torch.randperm(test_x.shape[0])[:args.batch_size]\n    test_dxdt_hat = model.time_derivative(test_x[test_ixs])\n    test_loss = L2_loss(test_dxdt[test_ixs], test_dxdt_hat)\n\n    # logging\n    stats[\'train_loss\'].append(loss.item())\n    stats[\'test_loss\'].append(test_loss.item())\n    if args.verbose and step % args.print_every == 0:\n      print(""step {}, train_loss {:.4e}, test_loss {:.4e}, grad norm {:.4e}, grad std {:.4e}""\n          .format(step, loss.item(), test_loss.item(), grad@grad, grad.std()))\n\n  train_dxdt_hat = model.time_derivative(x)\n  train_dist = (dxdt - train_dxdt_hat)**2\n  test_dxdt_hat = model.time_derivative(test_x)\n  test_dist = (test_dxdt - test_dxdt_hat)**2\n  print(\'Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}\'\n    .format(train_dist.mean().item(), train_dist.std().item()/np.sqrt(train_dist.shape[0]),\n            test_dist.mean().item(), test_dist.std().item()/np.sqrt(test_dist.shape[0])))\n  return model, stats\n\nif __name__ == ""__main__"":\n    args = get_args()\n    model, stats = train(args)\n\n    # save model\n    os.makedirs(args.save_dir) if not os.path.exists(args.save_dir) else None\n    label = \'baseline\' if args.baseline else \'hnn\'\n    model_path = \'{}/{}-orbits-{}.tar\'.format(args.save_dir, args.name, label)\n    torch.save(model.state_dict(), model_path)\n\n    # save stats\n    stats_path = \'{}/{}-orbits-{}.pkl\'.format(args.save_dir, args.name, label)\n    to_pickle(stats, stats_path)\n'"
experiment-pend/data.py,0,"b""# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport autograd\nimport autograd.numpy as np\n\nimport scipy.integrate\nsolve_ivp = scipy.integrate.solve_ivp\n\ndef hamiltonian_fn(coords):\n    q, p = np.split(coords,2)\n    H = 3*(1-np.cos(q)) + p**2 # pendulum hamiltonian\n    return H\n\ndef dynamics_fn(t, coords):\n    dcoords = autograd.grad(hamiltonian_fn)(coords)\n    dqdt, dpdt = np.split(dcoords,2)\n    S = np.concatenate([dpdt, -dqdt], axis=-1)\n    return S\n\ndef get_trajectory(t_span=[0,3], timescale=15, radius=None, y0=None, noise_std=0.1, **kwargs):\n    t_eval = np.linspace(t_span[0], t_span[1], int(timescale*(t_span[1]-t_span[0])))\n    \n    # get initial state\n    if y0 is None:\n        y0 = np.random.rand(2)*2.-1\n    if radius is None:\n        radius = np.random.rand() + 1.3 # sample a range of radii\n    y0 = y0 / np.sqrt((y0**2).sum()) * radius ## set the appropriate radius\n\n    spring_ivp = solve_ivp(fun=dynamics_fn, t_span=t_span, y0=y0, t_eval=t_eval, rtol=1e-10, **kwargs)\n    q, p = spring_ivp['y'][0], spring_ivp['y'][1]\n    dydt = [dynamics_fn(None, y) for y in spring_ivp['y'].T]\n    dydt = np.stack(dydt).T\n    dqdt, dpdt = np.split(dydt,2)\n    \n    # add noise\n    q += np.random.randn(*q.shape)*noise_std\n    p += np.random.randn(*p.shape)*noise_std\n    return q, p, dqdt, dpdt, t_eval\n\ndef get_dataset(seed=0, samples=50, test_split=0.5, **kwargs):\n    data = {'meta': locals()}\n\n    # randomly sample inputs\n    np.random.seed(seed)\n    xs, dxs = [], []\n    for s in range(samples):\n        x, y, dx, dy, t = get_trajectory(**kwargs)\n        xs.append( np.stack( [x, y]).T )\n        dxs.append( np.stack( [dx, dy]).T )\n        \n    data['x'] = np.concatenate(xs)\n    data['dx'] = np.concatenate(dxs).squeeze()\n\n    # make a train/test split\n    split_ix = int(len(data['x']) * test_split)\n    split_data = {}\n    for k in ['x', 'dx']:\n        split_data[k], split_data['test_' + k] = data[k][:split_ix], data[k][split_ix:]\n    data = split_data\n    return data\n\ndef get_field(xmin=-1.2, xmax=1.2, ymin=-1.2, ymax=1.2, gridsize=20):\n    field = {'meta': locals()}\n\n    # meshgrid to get vector field\n    b, a = np.meshgrid(np.linspace(xmin, xmax, gridsize), np.linspace(ymin, ymax, gridsize))\n    ys = np.stack([b.flatten(), a.flatten()])\n    \n    # get vector directions\n    dydt = [dynamics_fn(None, y) for y in ys.T]\n    dydt = np.stack(dydt).T\n\n    field['x'] = ys.T\n    field['dx'] = dydt.T\n    return field"""
experiment-pend/train.py,7,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport torch, argparse\nimport numpy as np\n\nimport os, sys\nTHIS_DIR = os.path.dirname(os.path.abspath(__file__))\nPARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(PARENT_DIR)\n\nfrom nn_models import MLP\nfrom hnn import HNN\nfrom data import get_dataset\nfrom utils import L2_loss, rk4\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=None)\n    parser.add_argument(\'--input_dim\', default=2, type=int, help=\'dimensionality of input tensor\')\n    parser.add_argument(\'--hidden_dim\', default=200, type=int, help=\'hidden dimension of mlp\')\n    parser.add_argument(\'--learn_rate\', default=1e-3, type=float, help=\'learning rate\')\n    parser.add_argument(\'--nonlinearity\', default=\'tanh\', type=str, help=\'neural net nonlinearity\')\n    parser.add_argument(\'--total_steps\', default=2000, type=int, help=\'number of gradient steps\')\n    parser.add_argument(\'--print_every\', default=200, type=int, help=\'number of gradient steps between prints\')\n    parser.add_argument(\'--name\', default=\'pend\', type=str, help=\'only one option right now\')\n    parser.add_argument(\'--baseline\', dest=\'baseline\', action=\'store_true\', help=\'run baseline or experiment?\')\n    parser.add_argument(\'--use_rk4\', dest=\'use_rk4\', action=\'store_true\', help=\'integrate derivative with RK4\')\n    parser.add_argument(\'--verbose\', dest=\'verbose\', action=\'store_true\', help=\'verbose?\')\n    parser.add_argument(\'--field_type\', default=\'solenoidal\', type=str, help=\'type of vector field to learn\')\n    parser.add_argument(\'--seed\', default=0, type=int, help=\'random seed\')\n    parser.add_argument(\'--save_dir\', default=THIS_DIR, type=str, help=\'where to save the trained model\')\n    parser.set_defaults(feature=True)\n    return parser.parse_args()\n\ndef train(args):\n  # set random seed\n  torch.manual_seed(args.seed)\n  np.random.seed(args.seed)\n\n  # init model and optimizer\n  if args.verbose:\n    print(""Training baseline model:"" if args.baseline else ""Training HNN model:"")\n\n  output_dim = args.input_dim if args.baseline else 2\n  nn_model = MLP(args.input_dim, args.hidden_dim, output_dim, args.nonlinearity)\n  model = HNN(args.input_dim, differentiable_model=nn_model,\n              field_type=args.field_type, baseline=args.baseline)\n  optim = torch.optim.Adam(model.parameters(), args.learn_rate, weight_decay=1e-4)\n\n  # arrange data\n  data = get_dataset(seed=args.seed)\n  x = torch.tensor( data[\'x\'], requires_grad=True, dtype=torch.float32)\n  test_x = torch.tensor( data[\'test_x\'], requires_grad=True, dtype=torch.float32)\n  dxdt = torch.Tensor(data[\'dx\'])\n  test_dxdt = torch.Tensor(data[\'test_dx\'])\n\n  # vanilla train loop\n  stats = {\'train_loss\': [], \'test_loss\': []}\n  for step in range(args.total_steps+1):\n    \n    # train step\n    dxdt_hat = model.rk4_time_derivative(x) if args.use_rk4 else model.time_derivative(x)\n    loss = L2_loss(dxdt, dxdt_hat)\n    loss.backward() ; optim.step() ; optim.zero_grad()\n    \n    # run test data\n    test_dxdt_hat = model.rk4_time_derivative(test_x) if args.use_rk4 else model.time_derivative(test_x)\n    test_loss = L2_loss(test_dxdt, test_dxdt_hat)\n\n    # logging\n    stats[\'train_loss\'].append(loss.item())\n    stats[\'test_loss\'].append(test_loss.item())\n    if args.verbose and step % args.print_every == 0:\n      print(""step {}, train_loss {:.4e}, test_loss {:.4e}"".format(step, loss.item(), test_loss.item()))\n\n  train_dxdt_hat = model.time_derivative(x)\n  train_dist = (dxdt - train_dxdt_hat)**2\n  test_dxdt_hat = model.time_derivative(test_x)\n  test_dist = (test_dxdt - test_dxdt_hat)**2\n  print(\'Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}\'\n    .format(train_dist.mean().item(), train_dist.std().item()/np.sqrt(train_dist.shape[0]),\n            test_dist.mean().item(), test_dist.std().item()/np.sqrt(test_dist.shape[0])))\n\n  return model, stats\n\nif __name__ == ""__main__"":\n    args = get_args()\n    model, stats = train(args)\n\n    # save\n    os.makedirs(args.save_dir) if not os.path.exists(args.save_dir) else None\n    label = \'-baseline\' if args.baseline else \'-hnn\'\n    label = \'-rk4\' + label if args.use_rk4 else label\n    path = \'{}/{}{}.tar\'.format(args.save_dir, args.name, label)\n    torch.save(model.state_dict(), path)'"
experiment-pixels/data.py,0,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport numpy as np\nimport gym\nimport scipy, scipy.misc\n\nimport os, sys\nparent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(parent_dir)\n\nfrom utils import to_pickle, from_pickle\n\ndef get_theta(obs):\n    \'\'\'Transforms coordinate basis from the defaults of the gym pendulum env.\'\'\'\n    theta = np.arctan2(obs[0], -obs[1])\n    theta = theta + np.pi/2\n    theta = theta + 2*np.pi if theta < -np.pi else theta\n    theta = theta - 2*np.pi if theta > np.pi else theta\n    return theta\n    \n# def preproc(X, side):\n#     \'\'\'Crops, downsamples, desaturates, etc. the rgb pendulum observation.\'\'\'\n#     X = X[...,0][240:-120,120:-120] - X[...,1][240:-120,120:-120]\n#     return scipy.misc.imresize(X, [int(side/2), side]) / 255.\n\n\ndef preproc(X, side):\n    \'\'\'Crops, downsamples, desaturates, etc. the rgb pendulum observation.\'\'\'\n    X = X[...,0][440:-220,330:-330] - X[...,1][440:-220,330:-330]\n    return scipy.misc.imresize(X, [int(side), side]) / 255.\n\ndef sample_gym(seed=0, timesteps=103, trials=200, side=28, min_angle=0., max_angle=np.pi/6, \n              verbose=False, env_name=\'Pendulum-v0\'):\n\n    gym_settings = locals()\n    if verbose:\n        print(""Making a dataset of pendulum pixel observations."")\n        print(""Edit 5/20/19: you may have to rewrite the `preproc` function depending on your screen size."")\n    env = gym.make(env_name)\n    env.reset() ; env.seed(seed)\n\n    canonical_coords, frames = [], []\n    for step in range(trials*timesteps):\n\n        if step % timesteps == 0:\n            angle_ok = False\n\n            while not angle_ok:\n                obs = env.reset()\n                theta_init = np.abs(get_theta(obs))\n                if verbose:\n                    print(""\\tCalled reset. Max angle= {:.3f}"".format(theta_init))\n                if theta_init > min_angle and theta_init < max_angle:\n                    angle_ok = True\n                  \n            if verbose:\n                print(""\\tRunning environment..."")\n                \n        frames.append(preproc(env.render(\'rgb_array\'), side))\n        obs, _, _, _ = env.step([0.])\n        theta, dtheta = get_theta(obs), obs[-1]\n\n        # The constant factor of 0.25 comes from saying plotting H = PE + KE*c\n        # and choosing c such that total energy is as close to constant as\n        # possible. It\'s not perfect, but the best we can do.\n        canonical_coords.append( np.array([theta, 0.25 * dtheta]) )\n    \n    canonical_coords = np.stack(canonical_coords).reshape(trials*timesteps, -1)\n    frames = np.stack(frames).reshape(trials*timesteps, -1)\n    return canonical_coords, frames, gym_settings\n\ndef make_gym_dataset(test_split=0.2, **kwargs):\n    \'\'\'Constructs a dataset of observations from an OpenAI Gym env\'\'\'\n    canonical_coords, frames, gym_settings = sample_gym(**kwargs)\n    \n    coords, dcoords = [], [] # position and velocity data (canonical coordinates)\n    pixels, dpixels = [], [] # position and velocity data (pixel space)\n    next_pixels, next_dpixels = [], [] # (pixel space measurements, 1 timestep in future)\n\n    trials = gym_settings[\'trials\']\n    for cc, pix in zip(np.split(canonical_coords, trials), np.split(frames, trials)):\n        # calculate cc offsets\n        cc = cc[1:]\n        dcc = cc[1:] - cc[:-1]\n        cc = cc[1:]\n\n        # concat adjacent frames to get velocity information\n        # now the pixel arrays have same information as canonical coords\n        # ...but in a different (highly nonlinear) basis\n        p = np.concatenate([pix[:-1], pix[1:]], axis=-1)\n        \n        dp = p[1:] - p[:-1]\n        p = p[1:]\n\n        # calculate the same quantities, one timestep in the future\n        next_p, next_dp = p[1:], dp[1:]\n        p, dp = p[:-1], dp[:-1]\n        cc, dcc = cc[:-1], dcc[:-1]\n\n        # append to lists\n        coords.append(cc) ; dcoords.append(dcc)\n        pixels.append(p) ; dpixels.append(dp)\n        next_pixels.append(next_p) ; next_dpixels.append(next_dp)\n\n    # concatenate across trials\n    data = {\'coords\': coords, \'dcoords\': dcoords,\n            \'pixels\': pixels, \'dpixels\': dpixels, \n            \'next_pixels\': next_pixels, \'next_dpixels\': next_dpixels}\n    data = {k: np.concatenate(v) for k, v in data.items()}\n\n    # make a train/test split\n    split_ix = int(data[\'coords\'].shape[0]* test_split)\n    split_data = {}\n    for k, v in data.items():\n      split_data[k], split_data[\'test_\' + k] = v[split_ix:], v[:split_ix]\n    data = split_data\n\n    gym_settings[\'timesteps\'] -= 3 # from all the offsets computed above\n    data[\'meta\'] = gym_settings\n\n    return data\n\ndef get_dataset(experiment_name, save_dir, **kwargs):\n  \'\'\'Returns a dataset bult on top of OpenAI Gym observations. Also constructs\n  the dataset if no saved version is available.\'\'\'\n  \n  if experiment_name == ""pendulum"":\n    env_name = ""Pendulum-v0""\n  elif experiment_name == ""acrobot"":\n    env_name = ""Acrobot-v1""\n  else:\n    assert experiment_name in [\'pendulum\']\n\n  path = \'{}/{}-pixels-dataset.pkl\'.format(save_dir, experiment_name)\n\n  try:\n      data = from_pickle(path)\n      print(""Successfully loaded data from {}"".format(path))\n  except:\n      print(""Had a problem loading data from {}. Rebuilding dataset..."".format(path))\n      data = make_gym_dataset(**kwargs)\n      to_pickle(data, path)\n\n  return data\n\n\n### FOR DYNAMICS IN ANALYSIS SECTION ###\ndef hamiltonian_fn(coords):\n  k = 1.9  # this coefficient must be fit to the data\n  q, p = np.split(coords,2)\n  H = k*(1-np.cos(q)) + p**2 # pendulum hamiltonian\n  return H\n\ndef dynamics_fn(t, coords):\n  dcoords = autograd.grad(hamiltonian_fn)(coords)\n  dqdt, dpdt = np.split(dcoords,2)\n  S = -np.concatenate([dpdt, -dqdt], axis=-1)\n  return S'"
experiment-pixels/train.py,10,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport autograd\nimport autograd.numpy as np\nimport scipy.integrate\nsolve_ivp = scipy.integrate.solve_ivp\n\nimport torch, argparse\n\nimport os, sys\nTHIS_DIR = os.path.dirname(os.path.abspath(__file__))\nPARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(PARENT_DIR)\n\nfrom nn_models import MLPAutoencoder, MLP\nfrom hnn import HNN, PixelHNN\nfrom data import get_dataset\nfrom utils import L2_loss\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=None)\n    parser.add_argument(\'--input_dim\', default=2*28**2, type=int, help=\'dimensionality of input tensor\')\n    parser.add_argument(\'--hidden_dim\', default=200, type=int, help=\'hidden dimension of mlp\')\n    parser.add_argument(\'--latent_dim\', default=2, type=int, help=\'latent dimension of autoencoder\')\n    parser.add_argument(\'--learn_rate\', default=1e-3, type=float, help=\'learning rate\')\n    parser.add_argument(\'--input_noise\', default=0.0, type=float, help=\'std of noise added to HNN inputs\')\n    parser.add_argument(\'--batch_size\', default=200, type=int, help=\'batch size\')\n    parser.add_argument(\'--nonlinearity\', default=\'tanh\', type=str, help=\'neural net nonlinearity\')\n    parser.add_argument(\'--total_steps\', default=10000, type=int, help=\'number of gradient steps\')\n    parser.add_argument(\'--print_every\', default=200, type=int, help=\'number of gradient steps between prints\')\n    parser.add_argument(\'--verbose\', dest=\'verbose\', action=\'store_true\', help=\'verbose?\')\n    parser.add_argument(\'--name\', default=\'pixels\', type=str, help=\'either ""real"" or ""sim"" data\')\n    parser.add_argument(\'--baseline\', dest=\'baseline\', action=\'store_true\', help=\'run baseline or experiment?\')\n    parser.add_argument(\'--seed\', default=0, type=int, help=\'random seed\')\n    parser.add_argument(\'--save_dir\', default=THIS_DIR, type=str, help=\'where to save the trained model\')\n    parser.set_defaults(feature=True)\n    return parser.parse_args()\n\n\'\'\'The loss for this model is a bit complicated, so we\'ll\n    define it in a separate function for clarity.\'\'\'\ndef pixelhnn_loss(x, x_next, model, return_scalar=True):\n  # encode pixel space -> latent dimension\n  z = model.encode(x)\n  z_next = model.encode(x_next)\n\n  # autoencoder loss\n  x_hat = model.decode(z)\n  ae_loss = ((x - x_hat)**2).mean(1)\n\n  # hnn vector field loss\n  noise = args.input_noise * torch.randn(*z.shape)\n  z_hat_next = z + model.time_derivative(z + noise) # replace with rk4\n  hnn_loss = ((z_next - z_hat_next)**2).mean(1)\n\n  # canonical coordinate loss\n  # -> makes latent space look like (x, v) coordinates\n  w, dw = z.split(1,1)\n  w_next, _ = z_next.split(1,1)\n  cc_loss = ((dw-(w_next - w))**2).mean(1)\n\n  # sum losses and take a gradient step\n  loss = ae_loss + cc_loss + 1e-1 * hnn_loss\n  if return_scalar:\n    return loss.mean()\n  return loss\n\ndef train(args):\n  # set random seed\n  torch.manual_seed(args.seed)\n  np.random.seed(args.seed)\n\n  # init model and optimizer\n  autoencoder = MLPAutoencoder(args.input_dim, args.hidden_dim, args.latent_dim,\n                               nonlinearity=\'relu\')\n  model = PixelHNN(args.latent_dim, args.hidden_dim,\n                   autoencoder=autoencoder, nonlinearity=args.nonlinearity,\n                   baseline=args.baseline)\n  if args.verbose:\n    print(""Training baseline model:"" if args.baseline else ""Training HNN model:"")\n  optim = torch.optim.Adam(model.parameters(), args.learn_rate, weight_decay=1e-5)\n\n  # get dataset\n  data = get_dataset(\'pendulum\', args.save_dir, verbose=True, seed=args.seed)\n\n  x = torch.tensor( data[\'pixels\'], dtype=torch.float32)\n  test_x = torch.tensor( data[\'test_pixels\'], dtype=torch.float32)\n  next_x = torch.tensor( data[\'next_pixels\'], dtype=torch.float32)\n  test_next_x = torch.tensor( data[\'test_next_pixels\'], dtype=torch.float32)\n\n  # vanilla ae train loop\n  stats = {\'train_loss\': [], \'test_loss\': []}\n  for step in range(args.total_steps+1):\n    \n    # train step\n    ixs = torch.randperm(x.shape[0])[:args.batch_size]\n    loss = pixelhnn_loss(x[ixs], next_x[ixs], model)\n    loss.backward() ; optim.step() ; optim.zero_grad()\n\n    stats[\'train_loss\'].append(loss.item())\n    if args.verbose and step % args.print_every == 0:\n      # run validation\n      test_ixs = torch.randperm(test_x.shape[0])[:args.batch_size]\n      test_loss = pixelhnn_loss(test_x[test_ixs], test_next_x[test_ixs], model)\n      stats[\'test_loss\'].append(test_loss.item())\n\n      print(""step {}, train_loss {:.4e}, test_loss {:.4e}""\n        .format(step, loss.item(), test_loss.item()))\n\n  train_dist = pixelhnn_loss(x, next_x, model, return_scalar=False)\n  test_dist = pixelhnn_loss(test_x, test_next_x, model, return_scalar=False)\n  print(\'Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}\'\n    .format(train_dist.mean().item(), train_dist.std().item()/np.sqrt(train_dist.shape[0]),\n            test_dist.mean().item(), test_dist.std().item()/np.sqrt(test_dist.shape[0])))\n  return model, stats\n\nif __name__ == ""__main__"":\n    args = get_args()\n    model, stats = train(args)\n\n    # save\n    os.makedirs(args.save_dir) if not os.path.exists(args.save_dir) else None\n    label = \'baseline\' if args.baseline else \'hnn\'\n    path = \'{}/{}-pixels-{}.tar\'.format(args.save_dir, args.name, label)\n    torch.save(model.state_dict(), path)'"
experiment-real/data.py,0,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport os, sys\nfrom urllib.request import urlretrieve\nimport autograd\nimport autograd.numpy as np\n\nimport scipy.integrate\nsolve_ivp = scipy.integrate.solve_ivp\n\nparent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(parent_dir)\n\nfrom utils import read_lipson, str2array\n\ndef get_dataset(experiment_name, save_dir, test_split=0.8):\n  \'\'\'Downloads and formats the datasets provided in the supplementary materials of\n  the 2009 Lipson Science article ""Distilling Free-Form Natural Laws from\n  Experimental Data.""\n  Link to supplementary materials: https://bit.ly/2JNhyQ8\n  Link to article: https://bit.ly/2I2TqXn\n  \'\'\'\n  if experiment_name == ""pend-sim"":\n    dataset_name = ""pendulum_h_1""\n  elif experiment_name == ""pend-real"":\n    dataset_name = ""real_pend_h_1""\n  else:\n    assert experiment_name in [\'sim\', \'real\']\n\n  url = \'http://science.sciencemag.org/highwire/filestream/590089/field_highwire_adjunct_files/2/\'\n  os.makedirs(save_dir) if not os.path.exists(save_dir) else None\n  out_file = \'{}/invar_datasets.zip\'.format(save_dir)\n  \n  urlretrieve(url, out_file)\n\n  data_str = read_lipson(dataset_name, save_dir)\n  state, names = str2array(data_str)\n\n  # put data in a dictionary structure\n  data = {k: state[:,i:i+1] for i, k in enumerate(names)}\n  data[\'x\'] = state[:,2:4]\n  data[\'dx\'] = (data[\'x\'][1:] - data[\'x\'][:-1]) / (data[\'t\'][1:] - data[\'t\'][:-1])\n  data[\'x\'] = data[\'x\'][:-1]\n\n  # make a train/test split while preserving order of data\n  # there\'s no great way to do this.\n  # here we just put the test set in the middle of the sequence\n  train_set_size = int(len(data[\'x\']) * test_split)\n  test_set_size = int(len(data[\'x\']) * (1-test_split))\n  test_start_ix = train_set_size#int(train_set_size/2)\n  a = test_start_ix\n  b = test_start_ix + test_set_size\n\n  split_data = {}\n  for k, v in data.items():\n    split_data[k] = np.concatenate([v[:a],v[b:]], axis=0)\n    split_data[\'test_\' + k] = v[a:b]\n  data = split_data\n  return data\n\n### FOR DYNAMICS IN ANALYSIS SECTION ###\ndef hamiltonian_fn(coords):\n  k = 2.4  # this coefficient must be fit to the data\n  q, p = np.split(coords,2)\n  H = k*(1-np.cos(q)) + p**2 # pendulum hamiltonian\n  return H\n\ndef dynamics_fn(t, coords):\n  dcoords = autograd.grad(hamiltonian_fn)(coords)\n  dqdt, dpdt = np.split(dcoords,2)\n  S = -np.concatenate([dpdt, -dqdt], axis=-1)\n  return S'"
experiment-real/train.py,7,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport torch, argparse, os\nimport numpy as np\n\nimport os, sys\nTHIS_DIR = os.path.dirname(os.path.abspath(__file__))\nPARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(PARENT_DIR)\n\nfrom nn_models import MLP\nfrom hnn import HNN\nfrom data import get_dataset\nfrom utils import L2_loss, rk4\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=None)\n    parser.add_argument(\'--input_dim\', default=2, type=int, help=\'dimensionality of input tensor\')\n    parser.add_argument(\'--hidden_dim\', default=200, type=int, help=\'hidden dimension of mlp\')\n    parser.add_argument(\'--learn_rate\', default=1e-3, type=float, help=\'learning rate\')\n    parser.add_argument(\'--nonlinearity\', default=\'tanh\', type=str, help=\'neural net nonlinearity\')\n    parser.add_argument(\'--total_steps\', default=2000, type=int, help=\'number of gradient steps\')\n    parser.add_argument(\'--print_every\', default=200, type=int, help=\'number of gradient steps between prints\')\n    parser.add_argument(\'--verbose\', dest=\'verbose\', action=\'store_true\', help=\'verbose?\')\n    parser.add_argument(\'--name\', default=\'real\', type=str, help=\'name of the task\')\n    parser.add_argument(\'--field_type\', default=\'solenoidal\', type=str, help=\'type of vector field to learn\')\n    parser.add_argument(\'--baseline\', dest=\'baseline\', action=\'store_true\', help=\'run baseline or experiment?\')\n    parser.add_argument(\'--use_rk4\', dest=\'use_rk4\', action=\'store_true\', help=\'integrate derivative with RK4\')\n    parser.add_argument(\'--seed\', default=0, type=int, help=\'random seed\')\n    parser.add_argument(\'--save_dir\', default=THIS_DIR, type=str, help=\'where to save the trained model\')\n    parser.set_defaults(feature=True)\n    return parser.parse_args()\n\ndef train(args):\n  # set random seed\n  torch.manual_seed(args.seed)\n  np.random.seed(args.seed)\n\n  # init model and optimizer\n  if args.verbose:\n    print(""Training baseline model:"" if args.baseline else ""Training HNN model:"")\n  output_dim = args.input_dim if args.baseline else 2\n  nn_model = MLP(args.input_dim, args.hidden_dim, output_dim, args.nonlinearity)\n  model = HNN(args.input_dim, differentiable_model=nn_model,\n              field_type=args.field_type, baseline=args.baseline)\n  optim = torch.optim.Adam(model.parameters(), args.learn_rate, weight_decay=1e-5)\n\n  # arrange data\n  data = get_dataset(\'pend-real\', args.save_dir)\n  x = torch.tensor( data[\'x\'], requires_grad=True, dtype=torch.float32)\n  test_x = torch.tensor( data[\'test_x\'], requires_grad=True, dtype=torch.float32)\n  dxdt = torch.Tensor(data[\'dx\'])\n  test_dxdt = torch.Tensor(data[\'test_dx\'])\n\n  # vanilla train loop\n  stats = {\'train_loss\': [], \'test_loss\': []}\n  for step in range(args.total_steps+1):\n\n    # train step\n    dxdt_hat = model.rk4_time_derivative(x, dt=1/6.) if args.use_rk4 else model.time_derivative(x)\n    loss = L2_loss(dxdt, dxdt_hat)\n    loss.backward() ; optim.step() ; optim.zero_grad()\n\n    # run validation\n    test_dxdt_hat = model.time_derivative(test_x)\n    test_loss = L2_loss(test_dxdt, test_dxdt_hat)\n\n    # logging\n    stats[\'train_loss\'].append(loss.item())\n    stats[\'test_loss\'].append(test_loss.item())\n    if args.verbose and step % args.print_every == 0:\n      print(""step {}, train_loss {:.4e}, test_loss {:.4e}"".format(step, loss.item(), test_loss.item()))\n\n  train_dxdt_hat = model.time_derivative(x)\n  train_dist = (dxdt - train_dxdt_hat)**2\n  test_dxdt_hat = model.time_derivative(test_x)\n  test_dist = (test_dxdt - test_dxdt_hat)**2\n  print(\'Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}\'\n    .format(train_dist.mean().item(), train_dist.std().item()/np.sqrt(train_dist.shape[0]),\n            test_dist.mean().item(), test_dist.std().item()/np.sqrt(test_dist.shape[0])))\n\n  return model, stats\n\nif __name__ == ""__main__"":\n    args = get_args()\n    model, stats = train(args)\n\n    # save\n    os.makedirs(args.save_dir) if not os.path.exists(args.save_dir) else None\n    label = \'-baseline\' if args.baseline else \'-hnn\'\n    label = \'-rk4\' + label if args.use_rk4 else label\n    path = \'{}/{}{}.tar\'.format(args.save_dir, args.name, label)\n    torch.save(model.state_dict(), path)'"
experiment-spring/data.py,0,"b""# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport autograd\nimport autograd.numpy as np\n\nimport scipy.integrate\nsolve_ivp = scipy.integrate.solve_ivp\n\ndef hamiltonian_fn(coords):\n    q, p = np.split(coords,2)\n    H = p**2 + q**2 # spring hamiltonian (linear oscillator)\n    return H\n\ndef dynamics_fn(t, coords):\n    dcoords = autograd.grad(hamiltonian_fn)(coords)\n    dqdt, dpdt = np.split(dcoords,2)\n    S = np.concatenate([dpdt, -dqdt], axis=-1)\n    return S\n\ndef get_trajectory(t_span=[0,3], timescale=10, radius=None, y0=None, noise_std=0.1, **kwargs):\n    t_eval = np.linspace(t_span[0], t_span[1], int(timescale*(t_span[1]-t_span[0])))\n    \n    # get initial state\n    if y0 is None:\n        y0 = np.random.rand(2)*2-1\n    if radius is None:\n        radius = np.random.rand()*0.9 + 0.1 # sample a range of radii\n    y0 = y0 / np.sqrt((y0**2).sum()) * radius ## set the appropriate radius\n\n    spring_ivp = solve_ivp(fun=dynamics_fn, t_span=t_span, y0=y0, t_eval=t_eval, rtol=1e-10, **kwargs)\n    q, p = spring_ivp['y'][0], spring_ivp['y'][1]\n    dydt = [dynamics_fn(None, y) for y in spring_ivp['y'].T]\n    dydt = np.stack(dydt).T\n    dqdt, dpdt = np.split(dydt,2)\n    \n    # add noise\n    q += np.random.randn(*q.shape)*noise_std\n    p += np.random.randn(*p.shape)*noise_std\n    return q, p, dqdt, dpdt, t_eval\n\ndef get_dataset(seed=0, samples=50, test_split=0.5, **kwargs):\n    data = {'meta': locals()}\n\n    # randomly sample inputs\n    np.random.seed(seed)\n    xs, dxs = [], []\n    for s in range(samples):\n        x, y, dx, dy, t = get_trajectory(**kwargs)\n        xs.append( np.stack( [x, y]).T )\n        dxs.append( np.stack( [dx, dy]).T )\n        \n    data['x'] = np.concatenate(xs)\n    data['dx'] = np.concatenate(dxs).squeeze()\n\n    # make a train/test split\n    split_ix = int(len(data['x']) * test_split)\n    split_data = {}\n    for k in ['x', 'dx']:\n        split_data[k], split_data['test_' + k] = data[k][:split_ix], data[k][split_ix:]\n    data = split_data\n    return data\n\ndef get_field(xmin=-1.2, xmax=1.2, ymin=-1.2, ymax=1.2, gridsize=20):\n    field = {'meta': locals()}\n\n    # meshgrid to get vector field\n    b, a = np.meshgrid(np.linspace(xmin, xmax, gridsize), np.linspace(ymin, ymax, gridsize))\n    ys = np.stack([b.flatten(), a.flatten()])\n    \n    # get vector directions\n    dydt = [dynamics_fn(None, y) for y in ys.T]\n    dydt = np.stack(dydt).T\n\n    field['x'] = ys.T\n    field['dx'] = dydt.T\n    return field"""
experiment-spring/train.py,7,"b'# Hamiltonian Neural Networks | 2019\n# Sam Greydanus, Misko Dzamba, Jason Yosinski\n\nimport torch, argparse\nimport numpy as np\n\nimport os, sys\nTHIS_DIR = os.path.dirname(os.path.abspath(__file__))\nPARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(PARENT_DIR)\n\nfrom nn_models import MLP\nfrom hnn import HNN\nfrom data import get_dataset\nfrom utils import L2_loss, rk4\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=None)\n    parser.add_argument(\'--input_dim\', default=2, type=int, help=\'dimensionality of input tensor\')\n    parser.add_argument(\'--hidden_dim\', default=200, type=int, help=\'hidden dimension of mlp\')\n    parser.add_argument(\'--learn_rate\', default=1e-3, type=float, help=\'learning rate\')\n    parser.add_argument(\'--nonlinearity\', default=\'tanh\', type=str, help=\'neural net nonlinearity\')\n    parser.add_argument(\'--total_steps\', default=2000, type=int, help=\'number of gradient steps\')\n    parser.add_argument(\'--print_every\', default=200, type=int, help=\'number of gradient steps between prints\')\n    parser.add_argument(\'--name\', default=\'spring\', type=str, help=\'only one option right now\')\n    parser.add_argument(\'--baseline\', dest=\'baseline\', action=\'store_true\', help=\'run baseline or experiment?\')\n    parser.add_argument(\'--use_rk4\', dest=\'use_rk4\', action=\'store_true\', help=\'integrate derivative with RK4\')\n    parser.add_argument(\'--verbose\', dest=\'verbose\', action=\'store_true\', help=\'verbose?\')\n    parser.add_argument(\'--field_type\', default=\'solenoidal\', type=str, help=\'type of vector field to learn\')\n    parser.add_argument(\'--seed\', default=0, type=int, help=\'random seed\')\n    parser.add_argument(\'--save_dir\', default=THIS_DIR, type=str, help=\'where to save the trained model\')\n    parser.set_defaults(feature=True)\n    return parser.parse_args()\n\ndef train(args):\n  # set random seed\n  torch.manual_seed(args.seed)\n  np.random.seed(args.seed)\n\n  # init model and optimizer\n  if args.verbose:\n    print(""Training baseline model:"" if args.baseline else ""Training HNN model:"")\n\n  output_dim = args.input_dim if args.baseline else 2\n  nn_model = MLP(args.input_dim, args.hidden_dim, output_dim, args.nonlinearity)\n  model = HNN(args.input_dim, differentiable_model=nn_model,\n              field_type=args.field_type, baseline=args.baseline)\n  optim = torch.optim.Adam(model.parameters(), args.learn_rate, weight_decay=1e-4)\n\n  # arrange data\n  data = get_dataset(seed=args.seed)\n  x = torch.tensor( data[\'x\'], requires_grad=True, dtype=torch.float32)\n  test_x = torch.tensor( data[\'test_x\'], requires_grad=True, dtype=torch.float32)\n  dxdt = torch.Tensor(data[\'dx\'])\n  test_dxdt = torch.Tensor(data[\'test_dx\'])\n\n  # vanilla train loop\n  stats = {\'train_loss\': [], \'test_loss\': []}\n  for step in range(args.total_steps+1):\n    \n    # train step\n    dxdt_hat = model.rk4_time_derivative(x) if args.use_rk4 else model.time_derivative(x)\n    loss = L2_loss(dxdt, dxdt_hat)\n    loss.backward() ; optim.step() ; optim.zero_grad()\n    \n    # run test data\n    test_dxdt_hat = model.rk4_time_derivative(test_x) if args.use_rk4 else model.time_derivative(test_x)\n    test_loss = L2_loss(test_dxdt, test_dxdt_hat)\n\n    # logging\n    stats[\'train_loss\'].append(loss.item())\n    stats[\'test_loss\'].append(test_loss.item())\n    if args.verbose and step % args.print_every == 0:\n      print(""step {}, train_loss {:.4e}, test_loss {:.4e}"".format(step, loss.item(), test_loss.item()))\n\n  train_dxdt_hat = model.time_derivative(x)\n  train_dist = (dxdt - train_dxdt_hat)**2\n  test_dxdt_hat = model.time_derivative(test_x)\n  test_dist = (test_dxdt - test_dxdt_hat)**2\n  print(\'Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}\'\n    .format(train_dist.mean().item(), train_dist.std().item()/np.sqrt(train_dist.shape[0]),\n            test_dist.mean().item(), test_dist.std().item()/np.sqrt(test_dist.shape[0])))\n\n  return model, stats\n\nif __name__ == ""__main__"":\n    args = get_args()\n    model, stats = train(args)\n\n    # save\n    os.makedirs(args.save_dir) if not os.path.exists(args.save_dir) else None\n    label = \'-baseline\' if args.baseline else \'-hnn\'\n    label = \'-rk4\' + label if args.use_rk4 else label\n    path = \'{}/{}{}.tar\'.format(args.save_dir, args.name, label)\n    torch.save(model.state_dict(), path)'"
